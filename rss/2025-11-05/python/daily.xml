<rss version="2.0">
  <channel>
    <title>GitHub Python Daily Trending</title>
    <description>Daily Trending of Python in GitHub</description>
    <pubDate>Tue, 04 Nov 2025 01:38:32 GMT</pubDate>
    <link>http://mshibanami.github.io/GitHubTrendingRSS</link>
    
    <item>
      <title>666ghj/BettaFish</title>
      <link>https://github.com/666ghj/BettaFish</link>
      <description>&lt;p&gt;å¾®èˆ†ï¼šäººäººå¯ç”¨çš„å¤šAgentèˆ†æƒ…åˆ†æåŠ©æ‰‹ï¼Œæ‰“ç ´ä¿¡æ¯èŒ§æˆ¿ï¼Œè¿˜åŸèˆ†æƒ…åŸè²Œï¼Œé¢„æµ‹æœªæ¥èµ°å‘ï¼Œè¾…åŠ©å†³ç­–ï¼ä»0å®ç°ï¼Œä¸ä¾èµ–ä»»ä½•æ¡†æ¶ã€‚&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/666ghj/BettaFish/main/static/image/logo_compressed.png" alt="Weibo Public Opinion Analysis System Logo" width="100%" /&gt; 
 &lt;p&gt;&lt;a href="https://trendshift.io/repositories/15286" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/15286" alt="666ghj%2FBettaFish | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://leaflow.net/" target="_blank"&gt;&lt;img src="https://raw.githubusercontent.com/666ghj/BettaFish/main/static/image/Leaflow_logo.png" alt="666ghj%2FWeibo_PublicOpinion_AnalysisSystem | Leaflow" style="width: 150px;" width="150" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://github.com/666ghj/Weibo_PublicOpinion_AnalysisSystem/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/666ghj/Weibo_PublicOpinion_AnalysisSystem?style=flat-square" alt="GitHub Stars" /&gt;&lt;/a&gt; &lt;a href="https://github.com/666ghj/Weibo_PublicOpinion_AnalysisSystem/watchers"&gt;&lt;img src="https://img.shields.io/github/watchers/666ghj/Weibo_PublicOpinion_AnalysisSystem?style=flat-square" alt="GitHub Watchers" /&gt;&lt;/a&gt; &lt;a href="https://github.com/666ghj/Weibo_PublicOpinion_AnalysisSystem/network"&gt;&lt;img src="https://img.shields.io/github/forks/666ghj/Weibo_PublicOpinion_AnalysisSystem?style=flat-square" alt="GitHub Forks" /&gt;&lt;/a&gt; &lt;a href="https://github.com/666ghj/Weibo_PublicOpinion_AnalysisSystem/issues"&gt;&lt;img src="https://img.shields.io/github/issues/666ghj/Weibo_PublicOpinion_AnalysisSystem?style=flat-square" alt="GitHub Issues" /&gt;&lt;/a&gt; &lt;a href="https://github.com/666ghj/Weibo_PublicOpinion_AnalysisSystem/pulls"&gt;&lt;img src="https://img.shields.io/github/issues-pr/666ghj/Weibo_PublicOpinion_AnalysisSystem?style=flat-square" alt="GitHub Pull Requests" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://github.com/666ghj/Weibo_PublicOpinion_AnalysisSystem/raw/main/LICENSE"&gt;&lt;img src="https://img.shields.io/github/license/666ghj/Weibo_PublicOpinion_AnalysisSystem?style=flat-square" alt="GitHub License" /&gt;&lt;/a&gt; &lt;a href="https://github.com/666ghj/Weibo_PublicOpinion_AnalysisSystem"&gt;&lt;img src="https://img.shields.io/badge/version-v1.0.0-green.svg?style=flat-square" alt="Version" /&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/"&gt;&lt;img src="https://img.shields.io/badge/Docker-Build-2496ED?style=flat-square&amp;amp;logo=docker&amp;amp;logoColor=white" alt="Docker" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/666ghj/BettaFish/main/README-EN.md"&gt;English&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/666ghj/BettaFish/main/README.md"&gt;ä¸­æ–‡æ–‡æ¡£&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] æŠ±æ­‰å‡ºäº†ç‚¹çŠ¶å†µï¼Œå‘¨äºŒï¼ˆ11.4ï¼‰ä¼šä¸Š&lt;strong&gt;åœ¨çº¿ä¸€é”®éƒ¨ç½²ä½“éªŒ&lt;/strong&gt;ï¼Œæ¬¢è¿æŒç»­å…³æ³¨ï¼&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;âš¡ é¡¹ç›®æ¦‚è¿°&lt;/h2&gt; 
&lt;p&gt;â€œ&lt;strong&gt;å¾®èˆ†&lt;/strong&gt;â€ æ˜¯ä¸€ä¸ªä»0å®ç°çš„åˆ›æ–°å‹ å¤šæ™ºèƒ½ä½“ èˆ†æƒ…åˆ†æç³»ç»Ÿï¼Œå¸®åŠ©å¤§å®¶ç ´é™¤ä¿¡æ¯èŒ§æˆ¿ï¼Œè¿˜åŸèˆ†æƒ…åŸè²Œï¼Œé¢„æµ‹æœªæ¥èµ°å‘ï¼Œè¾…åŠ©å†³ç­–ã€‚ç”¨æˆ·åªéœ€åƒèŠå¤©ä¸€æ ·æå‡ºåˆ†æéœ€æ±‚ï¼Œæ™ºèƒ½ä½“å¼€å§‹å…¨è‡ªåŠ¨åˆ†æ å›½å†…å¤–30+ä¸»æµç¤¾åª’ ä¸ æ•°ç™¾ä¸‡æ¡å¤§ä¼—è¯„è®ºã€‚&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;â€œå¾®èˆ†â€è°éŸ³â€œå¾®é±¼â€ï¼ŒBettaFishæ˜¯ä¸€ç§ä½“å‹å¾ˆå°ä½†éå¸¸å¥½æ–—ã€æ¼‚äº®çš„é±¼ï¼Œå®ƒè±¡å¾ç€â€œå°è€Œå¼ºå¤§ï¼Œä¸ç•æŒ‘æˆ˜â€&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;æŸ¥çœ‹ç³»ç»Ÿä»¥â€œæ­¦æ±‰å¤§å­¦èˆ†æƒ…â€ä¸ºä¾‹ï¼Œç”Ÿæˆçš„ç ”ç©¶æŠ¥å‘Šï¼š&lt;a href="https://raw.githubusercontent.com/666ghj/BettaFish/main/final_reports/final_report__20250827_131630.html"&gt;æ­¦æ±‰å¤§å­¦å“ç‰Œå£°èª‰æ·±åº¦åˆ†ææŠ¥å‘Š&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;ä¸ä»…ä»…ä½“ç°åœ¨æŠ¥å‘Šè´¨é‡ä¸Šï¼Œç›¸æ¯”åŒç±»äº§å“ï¼Œæˆ‘ä»¬æ‹¥æœ‰ğŸš€å…­å¤§ä¼˜åŠ¿ï¼š&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;AIé©±åŠ¨çš„å…¨åŸŸç›‘æ§&lt;/strong&gt;ï¼šAIçˆ¬è™«é›†ç¾¤7x24å°æ—¶ä¸é—´æ–­ä½œä¸šï¼Œå…¨é¢è¦†ç›–å¾®åšã€å°çº¢ä¹¦ã€æŠ–éŸ³ã€å¿«æ‰‹ç­‰10+å›½å†…å¤–å…³é”®ç¤¾åª’ã€‚ä¸ä»…å®æ—¶æ•è·çƒ­ç‚¹å†…å®¹ï¼Œæ›´èƒ½ä¸‹é’»è‡³æµ·é‡ç”¨æˆ·è¯„è®ºï¼Œè®©æ‚¨å¬åˆ°æœ€çœŸå®ã€æœ€å¹¿æ³›çš„å¤§ä¼—å£°éŸ³ã€‚&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;è¶…è¶ŠLLMçš„å¤åˆåˆ†æå¼•æ“&lt;/strong&gt;ï¼šæˆ‘ä»¬ä¸ä»…ä¾èµ–è®¾è®¡çš„5ç±»ä¸“ä¸šAgentï¼Œæ›´èåˆäº†å¾®è°ƒæ¨¡å‹ã€ç»Ÿè®¡æ¨¡å‹ç­‰ä¸­é—´ä»¶ã€‚é€šè¿‡å¤šæ¨¡å‹ååŒå·¥ä½œï¼Œç¡®ä¿äº†åˆ†æç»“æœçš„æ·±åº¦ã€å‡†åº¦ä¸å¤šç»´è§†è§’ã€‚&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;å¼ºå¤§çš„å¤šæ¨¡æ€èƒ½åŠ›&lt;/strong&gt;ï¼šçªç ´å›¾æ–‡é™åˆ¶ï¼Œèƒ½æ·±åº¦è§£ææŠ–éŸ³ã€å¿«æ‰‹ç­‰çŸ­è§†é¢‘å†…å®¹ï¼Œå¹¶ç²¾å‡†æå–ç°ä»£æœç´¢å¼•æ“ä¸­çš„å¤©æ°”ã€æ—¥å†ã€è‚¡ç¥¨ç­‰ç»“æ„åŒ–å¤šæ¨¡æ€ä¿¡æ¯å¡ç‰‡ï¼Œè®©æ‚¨å…¨é¢æŒæ¡èˆ†æƒ…åŠ¨æ€ã€‚&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Agentâ€œè®ºå›â€åä½œæœºåˆ¶&lt;/strong&gt;ï¼šä¸ºä¸åŒAgentèµ‹äºˆç‹¬ç‰¹çš„å·¥å…·é›†ä¸æ€ç»´æ¨¡å¼ï¼Œå¼•å…¥è¾©è®ºä¸»æŒäººæ¨¡å‹ï¼Œé€šè¿‡â€œè®ºå›â€æœºåˆ¶è¿›è¡Œé“¾å¼æ€ç»´ç¢°æ’ä¸è¾©è®ºã€‚è¿™ä¸ä»…é¿å…äº†å•ä¸€æ¨¡å‹çš„æ€ç»´å±€é™ä¸äº¤æµå¯¼è‡´çš„åŒè´¨åŒ–ï¼Œæ›´å‚¬ç”Ÿå‡ºæ›´é«˜è´¨é‡çš„é›†ä½“æ™ºèƒ½ä¸å†³ç­–æ”¯æŒã€‚&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;å…¬ç§åŸŸæ•°æ®æ— ç¼èåˆ&lt;/strong&gt;ï¼šå¹³å°ä¸ä»…åˆ†æå…¬å¼€èˆ†æƒ…ï¼Œè¿˜æä¾›é«˜å®‰å…¨æ€§çš„æ¥å£ï¼Œæ”¯æŒæ‚¨å°†å†…éƒ¨ä¸šåŠ¡æ•°æ®åº“ä¸èˆ†æƒ…æ•°æ®æ— ç¼é›†æˆã€‚æ‰“é€šæ•°æ®å£å’ï¼Œä¸ºå‚ç›´ä¸šåŠ¡æä¾›â€œå¤–éƒ¨è¶‹åŠ¿+å†…éƒ¨æ´å¯Ÿâ€çš„å¼ºå¤§åˆ†æèƒ½åŠ›ã€‚&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;è½»é‡åŒ–ä¸é«˜æ‰©å±•æ€§æ¡†æ¶&lt;/strong&gt;ï¼šåŸºäºçº¯Pythonæ¨¡å—åŒ–è®¾è®¡ï¼Œå®ç°è½»é‡åŒ–ã€ä¸€é”®å¼éƒ¨ç½²ã€‚ä»£ç ç»“æ„æ¸…æ™°ï¼Œå¼€å‘è€…å¯è½»æ¾é›†æˆè‡ªå®šä¹‰æ¨¡å‹ä¸ä¸šåŠ¡é€»è¾‘ï¼Œå®ç°å¹³å°çš„å¿«é€Ÿæ‰©å±•ä¸æ·±åº¦å®šåˆ¶ã€‚&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;å§‹äºèˆ†æƒ…ï¼Œè€Œä¸æ­¢äºèˆ†æƒ…&lt;/strong&gt;ã€‚â€œå¾®èˆ†â€çš„ç›®æ ‡ï¼Œæ˜¯æˆä¸ºé©±åŠ¨ä¸€åˆ‡ä¸šåŠ¡åœºæ™¯çš„ç®€æ´é€šç”¨çš„æ•°æ®åˆ†æå¼•æ“ã€‚&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;ä¸¾ä¸ªä¾‹å­. ä½ åªéœ€ç®€å•ä¿®æ”¹Agentå·¥å…·é›†çš„apiå‚æ•°ä¸promptï¼Œå°±å¯ä»¥æŠŠä»–å˜æˆä¸€ä¸ªé‡‘èé¢†åŸŸçš„å¸‚åœºåˆ†æç³»ç»Ÿ&lt;/p&gt; 
 &lt;p&gt;é™„ä¸€ä¸ªæ¯”è¾ƒæ´»è·ƒçš„Lç«™é¡¹ç›®è®¨è®ºå¸–ï¼š&lt;a href="https://linux.do/t/topic/1009280"&gt;https://linux.do/t/topic/1009280&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/666ghj/BettaFish/main/static/image/system_schematic.png" alt="banner" width="800" /&gt; 
 &lt;p&gt;å‘Šåˆ«ä¼ ç»Ÿçš„æ•°æ®çœ‹æ¿ï¼Œåœ¨â€œå¾®èˆ†â€ï¼Œä¸€åˆ‡ç”±ä¸€ä¸ªç®€å•çš„é—®é¢˜å¼€å§‹ï¼Œæ‚¨åªéœ€åƒå¯¹è¯ä¸€æ ·ï¼Œæå‡ºæ‚¨çš„åˆ†æéœ€æ±‚&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;ğŸ—ï¸ ç³»ç»Ÿæ¶æ„&lt;/h2&gt; 
&lt;h3&gt;æ•´ä½“æ¶æ„å›¾&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Insight Agent&lt;/strong&gt; ç§æœ‰æ•°æ®åº“æŒ–æ˜ï¼šç§æœ‰èˆ†æƒ…æ•°æ®åº“æ·±åº¦åˆ†æAIä»£ç†&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Media Agent&lt;/strong&gt; å¤šæ¨¡æ€å†…å®¹åˆ†æï¼šå…·å¤‡å¼ºå¤§å¤šæ¨¡æ€èƒ½åŠ›çš„AIä»£ç†&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Query Agent&lt;/strong&gt; ç²¾å‡†ä¿¡æ¯æœç´¢ï¼šå…·å¤‡å›½å†…å¤–ç½‘é¡µæœç´¢èƒ½åŠ›çš„AIä»£ç†&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Report Agent&lt;/strong&gt; æ™ºèƒ½æŠ¥å‘Šç”Ÿæˆï¼šå†…ç½®æ¨¡æ¿çš„å¤šè½®æŠ¥å‘Šç”ŸæˆAIä»£ç†&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/666ghj/BettaFish/main/static/image/framework.png" alt="banner" width="800" /&gt; 
&lt;/div&gt; 
&lt;h3&gt;ä¸€æ¬¡å®Œæ•´åˆ†ææµç¨‹&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;æ­¥éª¤&lt;/th&gt; 
   &lt;th&gt;é˜¶æ®µåç§°&lt;/th&gt; 
   &lt;th&gt;ä¸»è¦æ“ä½œ&lt;/th&gt; 
   &lt;th&gt;å‚ä¸ç»„ä»¶&lt;/th&gt; 
   &lt;th&gt;å¾ªç¯ç‰¹æ€§&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;1&lt;/td&gt; 
   &lt;td&gt;ç”¨æˆ·æé—®&lt;/td&gt; 
   &lt;td&gt;Flaskä¸»åº”ç”¨æ¥æ”¶æŸ¥è¯¢&lt;/td&gt; 
   &lt;td&gt;Flaskä¸»åº”ç”¨&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;2&lt;/td&gt; 
   &lt;td&gt;å¹¶è¡Œå¯åŠ¨&lt;/td&gt; 
   &lt;td&gt;ä¸‰ä¸ªAgentåŒæ—¶å¼€å§‹å·¥ä½œ&lt;/td&gt; 
   &lt;td&gt;Query Agentã€Media Agentã€Insight Agent&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;3&lt;/td&gt; 
   &lt;td&gt;åˆæ­¥åˆ†æ&lt;/td&gt; 
   &lt;td&gt;å„Agentä½¿ç”¨ä¸“å±å·¥å…·è¿›è¡Œæ¦‚è§ˆæœç´¢&lt;/td&gt; 
   &lt;td&gt;å„Agent + ä¸“å±å·¥å…·é›†&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;4&lt;/td&gt; 
   &lt;td&gt;ç­–ç•¥åˆ¶å®š&lt;/td&gt; 
   &lt;td&gt;åŸºäºåˆæ­¥ç»“æœåˆ¶å®šåˆ†å—ç ”ç©¶ç­–ç•¥&lt;/td&gt; 
   &lt;td&gt;å„Agentå†…éƒ¨å†³ç­–æ¨¡å—&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;5-N&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;å¾ªç¯é˜¶æ®µ&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;è®ºå›åä½œ + æ·±åº¦ç ”ç©¶&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;ForumEngine + æ‰€æœ‰Agent&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;å¤šè½®å¾ªç¯&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;5.1&lt;/td&gt; 
   &lt;td&gt;æ·±åº¦ç ”ç©¶&lt;/td&gt; 
   &lt;td&gt;å„AgentåŸºäºè®ºå›ä¸»æŒäººå¼•å¯¼è¿›è¡Œä¸“é¡¹æœç´¢&lt;/td&gt; 
   &lt;td&gt;å„Agent + åæ€æœºåˆ¶ + è®ºå›å¼•å¯¼&lt;/td&gt; 
   &lt;td&gt;æ¯è½®å¾ªç¯&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;5.2&lt;/td&gt; 
   &lt;td&gt;è®ºå›åä½œ&lt;/td&gt; 
   &lt;td&gt;ForumEngineç›‘æ§Agentå‘è¨€å¹¶ç”Ÿæˆä¸»æŒäººæ€»ç»“&lt;/td&gt; 
   &lt;td&gt;ForumEngine + LLMä¸»æŒäºº&lt;/td&gt; 
   &lt;td&gt;æ¯è½®å¾ªç¯&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;5.3&lt;/td&gt; 
   &lt;td&gt;äº¤æµèåˆ&lt;/td&gt; 
   &lt;td&gt;å„Agentæ ¹æ®è®¨è®ºè°ƒæ•´ç ”ç©¶æ–¹å‘&lt;/td&gt; 
   &lt;td&gt;å„Agent + forum_readerå·¥å…·&lt;/td&gt; 
   &lt;td&gt;æ¯è½®å¾ªç¯&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;N+1&lt;/td&gt; 
   &lt;td&gt;ç»“æœæ•´åˆ&lt;/td&gt; 
   &lt;td&gt;Report Agentæ”¶é›†æ‰€æœ‰åˆ†æç»“æœå’Œè®ºå›å†…å®¹&lt;/td&gt; 
   &lt;td&gt;Report Agent&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;N+2&lt;/td&gt; 
   &lt;td&gt;æŠ¥å‘Šç”Ÿæˆ&lt;/td&gt; 
   &lt;td&gt;åŠ¨æ€é€‰æ‹©æ¨¡æ¿å’Œæ ·å¼ï¼Œå¤šè½®ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š&lt;/td&gt; 
   &lt;td&gt;Report Agent + æ¨¡æ¿å¼•æ“&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;é¡¹ç›®ä»£ç ç»“æ„æ ‘&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;Weibo_PublicOpinion_AnalysisSystem/
â”œâ”€â”€ QueryEngine/                   # å›½å†…å¤–æ–°é—»å¹¿åº¦æœç´¢Agent
â”‚   â”œâ”€â”€ agent.py                   # Agentä¸»é€»è¾‘
â”‚   â”œâ”€â”€ llms/                      # LLMæ¥å£å°è£…
â”‚   â”œâ”€â”€ nodes/                     # å¤„ç†èŠ‚ç‚¹
â”‚   â”œâ”€â”€ tools/                     # æœç´¢å·¥å…·
â”‚   â”œâ”€â”€ utils/                     # å·¥å…·å‡½æ•°
â”‚   â””â”€â”€ ...                        # å…¶ä»–æ¨¡å—
â”œâ”€â”€ MediaEngine/                   # å¼ºå¤§çš„å¤šæ¨¡æ€ç†è§£Agent
â”‚   â”œâ”€â”€ agent.py                   # Agentä¸»é€»è¾‘
â”‚   â”œâ”€â”€ nodes/                     # å¤„ç†èŠ‚ç‚¹
â”‚   â”œâ”€â”€ llms/                      # LLMæ¥å£
â”‚   â”œâ”€â”€ tools/                     # æœç´¢å·¥å…·
â”‚   â”œâ”€â”€ utils/                     # å·¥å…·å‡½æ•°
â”‚   â””â”€â”€ ...                        # å…¶ä»–æ¨¡å—
â”œâ”€â”€ InsightEngine/                 # ç§æœ‰æ•°æ®åº“æŒ–æ˜Agent
â”‚   â”œâ”€â”€ agent.py                   # Agentä¸»é€»è¾‘
â”‚   â”œâ”€â”€ llms/                      # LLMæ¥å£å°è£…
â”‚   â”‚   â””â”€â”€ base.py                # ç»Ÿä¸€çš„ OpenAI å…¼å®¹å®¢æˆ·ç«¯
â”‚   â”œâ”€â”€ nodes/                     # å¤„ç†èŠ‚ç‚¹
â”‚   â”‚   â”œâ”€â”€ base_node.py           # åŸºç¡€èŠ‚ç‚¹ç±»
â”‚   â”‚   â”œâ”€â”€ formatting_node.py     # æ ¼å¼åŒ–èŠ‚ç‚¹
â”‚   â”‚   â”œâ”€â”€ report_structure_node.py # æŠ¥å‘Šç»“æ„èŠ‚ç‚¹
â”‚   â”‚   â”œâ”€â”€ search_node.py         # æœç´¢èŠ‚ç‚¹
â”‚   â”‚   â””â”€â”€ summary_node.py        # æ€»ç»“èŠ‚ç‚¹
â”‚   â”œâ”€â”€ tools/                     # æ•°æ®åº“æŸ¥è¯¢å’Œåˆ†æå·¥å…·
â”‚   â”‚   â”œâ”€â”€ keyword_optimizer.py   # Qwenå…³é”®è¯ä¼˜åŒ–ä¸­é—´ä»¶
â”‚   â”‚   â”œâ”€â”€ search.py              # æ•°æ®åº“æ“ä½œå·¥å…·é›†
â”‚   â”‚   â””â”€â”€ sentiment_analyzer.py  # æƒ…æ„Ÿåˆ†æé›†æˆå·¥å…·
â”‚   â”œâ”€â”€ state/                     # çŠ¶æ€ç®¡ç†
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ state.py               # AgentçŠ¶æ€å®šä¹‰
â”‚   â”œâ”€â”€ prompts/                   # æç¤ºè¯æ¨¡æ¿
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ prompts.py             # å„ç±»æç¤ºè¯
â”‚   â””â”€â”€ utils/                     # å·¥å…·å‡½æ•°
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ config.py              # é…ç½®ç®¡ç†
â”‚       â””â”€â”€ text_processing.py     # æ–‡æœ¬å¤„ç†å·¥å…·
â”œâ”€â”€ ReportEngine/                  # å¤šè½®æŠ¥å‘Šç”ŸæˆAgent
â”‚   â”œâ”€â”€ agent.py                   # Agentä¸»é€»è¾‘
â”‚   â”œâ”€â”€ llms/                      # LLMæ¥å£
â”‚   â”œâ”€â”€ nodes/                     # æŠ¥å‘Šç”ŸæˆèŠ‚ç‚¹
â”‚   â”‚   â”œâ”€â”€ template_selection.py  # æ¨¡æ¿é€‰æ‹©èŠ‚ç‚¹
â”‚   â”‚   â””â”€â”€ html_generation.py     # HTMLç”ŸæˆèŠ‚ç‚¹
â”‚   â”œâ”€â”€ report_template/           # æŠ¥å‘Šæ¨¡æ¿åº“
â”‚   â”‚   â”œâ”€â”€ ç¤¾ä¼šå…¬å…±çƒ­ç‚¹äº‹ä»¶åˆ†æ.md
â”‚   â”‚   â”œâ”€â”€ å•†ä¸šå“ç‰Œèˆ†æƒ…ç›‘æµ‹.md
â”‚   â”‚   â””â”€â”€ ...                    # æ›´å¤šæ¨¡æ¿
â”‚   â””â”€â”€ flask_interface.py         # Flask APIæ¥å£
â”œâ”€â”€ ForumEngine/                   # è®ºå›å¼•æ“ç®€æ˜“å®ç°
â”‚   â”œâ”€â”€ monitor.py                 # æ—¥å¿—ç›‘æ§å’Œè®ºå›ç®¡ç†
â”‚   â””â”€â”€ llm_host.py                # è®ºå›ä¸»æŒäººLLMæ¨¡å—
â”œâ”€â”€ MindSpider/                    # å¾®åšçˆ¬è™«ç³»ç»Ÿ
â”‚   â”œâ”€â”€ main.py                    # çˆ¬è™«ä¸»ç¨‹åº
â”‚   â”œâ”€â”€ config.py                  # çˆ¬è™«é…ç½®æ–‡ä»¶
â”‚   â”œâ”€â”€ BroadTopicExtraction/      # è¯é¢˜æå–æ¨¡å—
â”‚   â”‚   â”œâ”€â”€ database_manager.py    # æ•°æ®åº“ç®¡ç†å™¨
â”‚   â”‚   â”œâ”€â”€ get_today_news.py      # ä»Šæ—¥æ–°é—»è·å–
â”‚   â”‚   â”œâ”€â”€ main.py                # è¯é¢˜æå–ä¸»ç¨‹åº
â”‚   â”‚   â””â”€â”€ topic_extractor.py     # è¯é¢˜æå–å™¨
â”‚   â”œâ”€â”€ DeepSentimentCrawling/     # æ·±åº¦èˆ†æƒ…çˆ¬å–
â”‚   â”‚   â”œâ”€â”€ keyword_manager.py     # å…³é”®è¯ç®¡ç†å™¨
â”‚   â”‚   â”œâ”€â”€ main.py                # æ·±åº¦çˆ¬å–ä¸»ç¨‹åº
â”‚   â”‚   â”œâ”€â”€ MediaCrawler/          # åª’ä½“çˆ¬è™«æ ¸å¿ƒ
â”‚   â”‚   â””â”€â”€ platform_crawler.py    # å¹³å°çˆ¬è™«ç®¡ç†
â”‚   â””â”€â”€ schema/                    # æ•°æ®åº“ç»“æ„
â”‚       â”œâ”€â”€ db_manager.py          # æ•°æ®åº“ç®¡ç†å™¨
â”‚       â”œâ”€â”€ init_database.py       # æ•°æ®åº“åˆå§‹åŒ–
â”‚       â””â”€â”€ mindspider_tables.sql  # æ•°æ®åº“è¡¨ç»“æ„
â”œâ”€â”€ SentimentAnalysisModel/        # æƒ…æ„Ÿåˆ†ææ¨¡å‹é›†åˆ
â”‚   â”œâ”€â”€ WeiboSentiment_Finetuned/  # å¾®è°ƒBERT/GPT-2æ¨¡å‹
â”‚   â”œâ”€â”€ WeiboMultilingualSentiment/# å¤šè¯­è¨€æƒ…æ„Ÿåˆ†æï¼ˆæ¨èï¼‰
â”‚   â”œâ”€â”€ WeiboSentiment_SmallQwen/  # å°å‚æ•°Qwen3å¾®è°ƒ
â”‚   â””â”€â”€ WeiboSentiment_MachineLearning/ # ä¼ ç»Ÿæœºå™¨å­¦ä¹ æ–¹æ³•
â”œâ”€â”€ SingleEngineApp/               # å•ç‹¬Agentçš„Streamlitåº”ç”¨
â”‚   â”œâ”€â”€ query_engine_streamlit_app.py
â”‚   â”œâ”€â”€ media_engine_streamlit_app.py
â”‚   â””â”€â”€ insight_engine_streamlit_app.py
â”œâ”€â”€ templates/                     # Flaskæ¨¡æ¿
â”‚   â””â”€â”€ index.html                 # ä¸»ç•Œé¢å‰ç«¯
â”œâ”€â”€ static/                        # é™æ€èµ„æº
â”œâ”€â”€ logs/                          # è¿è¡Œæ—¥å¿—ç›®å½•
â”œâ”€â”€ final_reports/                 # æœ€ç»ˆç”Ÿæˆçš„HTMLæŠ¥å‘Šæ–‡ä»¶
â”œâ”€â”€ utils/                         # é€šç”¨å·¥å…·å‡½æ•°
â”‚   â”œâ”€â”€ forum_reader.py            # Agenté—´è®ºå›é€šä¿¡
â”‚   â””â”€â”€ retry_helper.py            # ç½‘ç»œè¯·æ±‚é‡è¯•æœºåˆ¶å·¥å…·
â”œâ”€â”€ app.py                         # Flaskä¸»åº”ç”¨å…¥å£
â”œâ”€â”€ config.py                      # å…¨å±€é…ç½®æ–‡ä»¶
â””â”€â”€ requirements.txt               # Pythonä¾èµ–åŒ…æ¸…å•
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;ğŸš€ å¿«é€Ÿå¼€å§‹&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;å¦‚æœä½ æ˜¯åˆæ¬¡å­¦ä¹ ä¸€ä¸ªAgentç³»ç»Ÿçš„æ­å»ºï¼Œå¯ä»¥ä»ä¸€ä¸ªéå¸¸ç®€å•çš„demoå¼€å§‹ï¼š&lt;a href="https://github.com/666ghj/DeepSearchAgent-Demo"&gt;Deep Search Agent Demo&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;ç¯å¢ƒè¦æ±‚&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;æ“ä½œç³»ç»Ÿ&lt;/strong&gt;: Windowsã€Linuxã€MacOS&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Pythonç‰ˆæœ¬&lt;/strong&gt;: 3.9+&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Conda&lt;/strong&gt;: Anacondaæˆ–Miniconda&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;æ•°æ®åº“&lt;/strong&gt;: MySQLï¼ˆå¯é€‰æ‹©æˆ‘ä»¬çš„äº‘æ•°æ®åº“æœåŠ¡ï¼‰&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;å†…å­˜&lt;/strong&gt;: å»ºè®®2GBä»¥ä¸Š&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;1. åˆ›å»ºCondaç¯å¢ƒ&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# åˆ›å»ºcondaç¯å¢ƒ
conda create -n your_conda_name python=3.11
conda activate your_conda_name
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;2. å®‰è£…ä¾èµ–åŒ…&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# åŸºç¡€ä¾èµ–å®‰è£…
pip install -r requirements.txt
# å¦‚æœä¸æƒ³ä½¿ç”¨æœ¬åœ°æƒ…æ„Ÿåˆ†ææ¨¡å‹ï¼ˆç®—åŠ›éœ€æ±‚å¾ˆå°ï¼Œé»˜è®¤å®‰è£…cpuç‰ˆæœ¬ï¼‰ï¼Œå¯ä»¥å°†è¯¥æ–‡ä»¶ä¸­çš„â€œæœºå™¨å­¦ä¹ â€éƒ¨åˆ†æ³¨é‡Šæ‰å†æ‰§è¡ŒæŒ‡ä»¤
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;3. å®‰è£…Playwrightæµè§ˆå™¨é©±åŠ¨&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# å®‰è£…æµè§ˆå™¨é©±åŠ¨ï¼ˆç”¨äºçˆ¬è™«åŠŸèƒ½ï¼‰
playwright install chromium
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;4. é…ç½®ç³»ç»Ÿ&lt;/h3&gt; 
&lt;h4&gt;4.1 é…ç½®APIå¯†é’¥&lt;/h4&gt; 
&lt;p&gt;å¤åˆ¶ä¸€ä»½ &lt;code&gt;config.py.example&lt;/code&gt; æ–‡ä»¶ï¼Œå‘½åä¸º &lt;code&gt;config.py&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;ç¼–è¾‘ &lt;code&gt;config.py&lt;/code&gt; æ–‡ä»¶ï¼Œå¡«å…¥æ‚¨çš„APIå¯†é’¥ï¼ˆæ‚¨ä¹Ÿå¯ä»¥é€‰æ‹©è‡ªå·±çš„æ¨¡å‹ã€æœç´¢ä»£ç†ï¼Œè¯¦æƒ…è§configæ–‡ä»¶å†…ï¼‰ï¼š&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# MySQLæ•°æ®åº“é…ç½®
DB_HOST = "localhost"
DB_PORT = 3306
DB_USER = "your_username"
DB_PASSWORD = "your_password"
DB_NAME = "your_db_name"
DB_CHARSET = "utf8mb4"

# LLMé…ç½®
# æ‚¨å¯ä»¥æ›´æ”¹æ¯ä¸ªéƒ¨åˆ†LLMä½¿ç”¨çš„APIï¼Œåªè¦å…¼å®¹OpenAIè¯·æ±‚æ ¼å¼éƒ½å¯ä»¥

# Insight Agent
INSIGHT_ENGINE_API_KEY = "your_api_key"
INSIGHT_ENGINE_BASE_URL = "https://api.moonshot.cn/v1"
INSIGHT_ENGINE_MODEL_NAME = "kimi-k2-0711-preview"
# Media Agent
...
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;4.2 æ•°æ®åº“åˆå§‹åŒ–&lt;/h4&gt; 
&lt;p&gt;&lt;strong&gt;é€‰æ‹©1ï¼šä½¿ç”¨æœ¬åœ°æ•°æ®åº“&lt;/strong&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;MindSpiderçˆ¬è™«ç³»ç»Ÿè·Ÿèˆ†æƒ…ç³»ç»Ÿæ˜¯å„è‡ªç‹¬ç«‹çš„ï¼Œæ‰€ä»¥éœ€è¦å†å»&lt;code&gt;MindSpider\config.py&lt;/code&gt;é…ç½®ä¸€ä¸‹ï¼Œå¤åˆ¶&lt;code&gt;MindSpider&lt;/code&gt;æ–‡ä»¶å¤¹ä¸‹çš„ &lt;code&gt;config.py.example&lt;/code&gt; æ–‡ä»¶ï¼Œå‘½åä¸º &lt;code&gt;config.py&lt;/code&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# æœ¬åœ°MySQLæ•°æ®åº“åˆå§‹åŒ–
cd MindSpider
python schema/init_database.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;é€‰æ‹©2ï¼šä½¿ç”¨äº‘æ•°æ®åº“æœåŠ¡ï¼ˆæ¨èï¼‰&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;æˆ‘ä»¬æä¾›ä¾¿æ·çš„äº‘æ•°æ®åº“æœåŠ¡ï¼ŒåŒ…å«æ—¥å‡10ä¸‡+çœŸå®èˆ†æƒ…æ•°æ®ï¼Œç›®å‰&lt;strong&gt;å…è´¹ç”³è¯·&lt;/strong&gt;ï¼&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;çœŸå®èˆ†æƒ…æ•°æ®ï¼Œå®æ—¶æ›´æ–°&lt;/li&gt; 
 &lt;li&gt;å¤šç»´åº¦æ ‡ç­¾åˆ†ç±»&lt;/li&gt; 
 &lt;li&gt;é«˜å¯ç”¨äº‘ç«¯æœåŠ¡&lt;/li&gt; 
 &lt;li&gt;ä¸“ä¸šæŠ€æœ¯æ”¯æŒ&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;è”ç³»æˆ‘ä»¬ç”³è¯·å…è´¹äº‘æ•°æ®åº“è®¿é—®ï¼šğŸ“§ &lt;a href="mailto:670939375@qq.com"&gt;670939375@qq.com&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;ä¸ºè¿›è¡Œæ•°æ®åˆè§„æ€§å®¡æŸ¥ä¸æœåŠ¡å‡çº§ï¼Œäº‘æ•°æ®åº“è‡ª2025å¹´10æœˆ1æ—¥èµ·æš‚åœæ¥æ”¶æ–°çš„ä½¿ç”¨ç”³è¯·&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;5. å¯åŠ¨ç³»ç»Ÿ&lt;/h3&gt; 
&lt;h4&gt;5.1 å®Œæ•´ç³»ç»Ÿå¯åŠ¨ï¼ˆæ¨èï¼‰&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# åœ¨é¡¹ç›®æ ¹ç›®å½•ä¸‹ï¼Œæ¿€æ´»condaç¯å¢ƒ
conda activate your_conda_name

# å¯åŠ¨ä¸»åº”ç”¨å³å¯
python app.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;æ³¨1ï¼šä¸€æ¬¡è¿è¡Œç»ˆæ­¢åï¼Œstreamlit appå¯èƒ½ç»“æŸå¼‚å¸¸ä»ç„¶å ç”¨ç«¯å£ï¼Œæ­¤æ—¶æœç´¢å ç”¨ç«¯å£çš„è¿›ç¨‹killæ‰å³å¯&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;æ³¨2ï¼šæ•°æ®çˆ¬å–éœ€è¦å•ç‹¬æ“ä½œï¼Œè§5.3æŒ‡å¼•&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;æ³¨3ï¼šå¦‚æœæœåŠ¡å™¨è¿œç¨‹éƒ¨ç½²å‡ºç°é¡µé¢æ˜¾ç¤ºé—®é¢˜ï¼Œè§&lt;a href="https://github.com/666ghj/BettaFish/pull/45"&gt;PR#45&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;è®¿é—® &lt;a href="http://localhost:5000"&gt;http://localhost:5000&lt;/a&gt; å³å¯ä½¿ç”¨å®Œæ•´ç³»ç»Ÿ&lt;/p&gt; 
&lt;h4&gt;5.2 å•ç‹¬å¯åŠ¨æŸä¸ªAgent&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# å¯åŠ¨QueryEngine
streamlit run SingleEngineApp/query_engine_streamlit_app.py --server.port 8503

# å¯åŠ¨MediaEngine  
streamlit run SingleEngineApp/media_engine_streamlit_app.py --server.port 8502

# å¯åŠ¨InsightEngine
streamlit run SingleEngineApp/insight_engine_streamlit_app.py --server.port 8501
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;5.3 çˆ¬è™«ç³»ç»Ÿå•ç‹¬ä½¿ç”¨&lt;/h4&gt; 
&lt;p&gt;è¿™éƒ¨åˆ†æœ‰è¯¦ç»†çš„é…ç½®æ–‡æ¡£ï¼š&lt;a href="https://raw.githubusercontent.com/666ghj/BettaFish/main/MindSpider/README.md"&gt;MindeSpiderä½¿ç”¨è¯´æ˜&lt;/a&gt;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;img src="MindSpider\img\example.png" alt="banner" width="600" /&gt; 
 &lt;p&gt;MindSpider è¿è¡Œç¤ºä¾‹&lt;/p&gt; 
&lt;/div&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# è¿›å…¥çˆ¬è™«ç›®å½•
cd MindSpider

# é¡¹ç›®åˆå§‹åŒ–
python main.py --setup

# è¿è¡Œå®Œæ•´çˆ¬è™«æµç¨‹
python main.py --complete --date 2024-01-20

# ä»…è¿è¡Œè¯é¢˜æå–
python main.py --broad-topic --date 2024-01-20

# ä»…è¿è¡Œæ·±åº¦çˆ¬å–
python main.py --deep-sentiment --platforms xhs dy wb
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;âš™ï¸ é«˜çº§é…ç½®&lt;/h2&gt; 
&lt;h3&gt;ä¿®æ”¹å…³é”®å‚æ•°&lt;/h3&gt; 
&lt;h4&gt;Agenté…ç½®å‚æ•°&lt;/h4&gt; 
&lt;p&gt;æ¯ä¸ªAgentéƒ½æœ‰ä¸“é—¨çš„é…ç½®æ–‡ä»¶ï¼Œå¯æ ¹æ®éœ€æ±‚è°ƒæ•´ï¼Œä¸‹é¢æ˜¯éƒ¨åˆ†ç¤ºä¾‹ï¼š&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# QueryEngine/utils/config.py
class Config:
    max_reflections = 2           # åæ€è½®æ¬¡
    max_search_results = 15       # æœ€å¤§æœç´¢ç»“æœæ•°
    max_content_length = 8000     # æœ€å¤§å†…å®¹é•¿åº¦
    
# MediaEngine/utils/config.py  
class Config:
    comprehensive_search_limit = 10  # ç»¼åˆæœç´¢é™åˆ¶
    web_search_limit = 15           # ç½‘é¡µæœç´¢é™åˆ¶
    
# InsightEngine/utils/config.py
class Config:
    default_search_topic_globally_limit = 200    # å…¨å±€æœç´¢é™åˆ¶
    default_get_comments_limit = 500             # è¯„è®ºè·å–é™åˆ¶
    max_search_results_for_llm = 50              # ä¼ ç»™LLMçš„æœ€å¤§ç»“æœæ•°
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;æƒ…æ„Ÿåˆ†ææ¨¡å‹é…ç½®&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# InsightEngine/tools/sentiment_analyzer.py
SENTIMENT_CONFIG = {
    'model_type': 'multilingual',     # å¯é€‰: 'bert', 'multilingual', 'qwen'ç­‰
    'confidence_threshold': 0.8,      # ç½®ä¿¡åº¦é˜ˆå€¼
    'batch_size': 32,                 # æ‰¹å¤„ç†å¤§å°
    'max_sequence_length': 512,       # æœ€å¤§åºåˆ—é•¿åº¦
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;æ¥å…¥ä¸åŒçš„LLMæ¨¡å‹&lt;/h3&gt; 
&lt;p&gt;æ”¯æŒä»»æ„openAIè°ƒç”¨æ ¼å¼çš„LLMæä¾›å•†ï¼Œåªéœ€è¦åœ¨/config.pyä¸­å¡«å†™å¯¹åº”çš„KEYã€BASE_URLã€MODEL_NAMEå³å¯ã€‚&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;ä»€ä¹ˆæ˜¯openAIè°ƒç”¨æ ¼å¼ï¼Ÿä¸‹é¢æä¾›ä¸€ä¸ªç®€å•çš„ä¾‹å­ï¼š&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;from openai import OpenAI

client = OpenAI(api_key="your_api_key", 
               base_url="https://api.siliconflow.cn/v1")

response = client.chat.completions.create(
   model="Qwen/Qwen2.5-72B-Instruct",
   messages=[
       {'role': 'user', 
        'content': "æ¨ç†æ¨¡å‹ä¼šç»™å¸‚åœºå¸¦æ¥å“ªäº›æ–°çš„æœºä¼š"}
   ],
)

complete_response = response.choices[0].message.content
print(complete_response)
&lt;/code&gt;&lt;/pre&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;æ›´æ”¹æƒ…æ„Ÿåˆ†ææ¨¡å‹&lt;/h3&gt; 
&lt;p&gt;ç³»ç»Ÿé›†æˆäº†å¤šç§æƒ…æ„Ÿåˆ†ææ–¹æ³•ï¼Œå¯æ ¹æ®éœ€æ±‚é€‰æ‹©ï¼š&lt;/p&gt; 
&lt;h4&gt;1. å¤šè¯­è¨€æƒ…æ„Ÿåˆ†æ&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd SentimentAnalysisModel/WeiboMultilingualSentiment
python predict.py --text "This product is amazing!" --lang "en"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;2. å°å‚æ•°Qwen3å¾®è°ƒ&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd SentimentAnalysisModel/WeiboSentiment_SmallQwen
python predict_universal.py --text "è¿™æ¬¡æ´»åŠ¨åŠå¾—å¾ˆæˆåŠŸ"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;3. åŸºäºBERTçš„å¾®è°ƒæ¨¡å‹&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# ä½¿ç”¨BERTä¸­æ–‡æ¨¡å‹
cd SentimentAnalysisModel/WeiboSentiment_Finetuned/BertChinese-Lora
python predict.py --text "è¿™ä¸ªäº§å“çœŸçš„å¾ˆä¸é”™"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;4. GPT-2 LoRAå¾®è°ƒæ¨¡å‹&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd SentimentAnalysisModel/WeiboSentiment_Finetuned/GPT2-Lora
python predict.py --text "ä»Šå¤©å¿ƒæƒ…ä¸å¤ªå¥½"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;5. ä¼ ç»Ÿæœºå™¨å­¦ä¹ æ–¹æ³•&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd SentimentAnalysisModel/WeiboSentiment_MachineLearning
python predict.py --model_type "svm" --text "æœåŠ¡æ€åº¦éœ€è¦æ”¹è¿›"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;æ¥å…¥è‡ªå®šä¹‰ä¸šåŠ¡æ•°æ®åº“&lt;/h3&gt; 
&lt;h4&gt;1. ä¿®æ”¹æ•°æ®åº“è¿æ¥é…ç½®&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# config.py ä¸­æ·»åŠ æ‚¨çš„ä¸šåŠ¡æ•°æ®åº“é…ç½®
BUSINESS_DB_HOST = "your_business_db_host"
BUSINESS_DB_PORT = 3306
BUSINESS_DB_USER = "your_business_user"
BUSINESS_DB_PASSWORD = "your_business_password"
BUSINESS_DB_NAME = "your_business_database"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;2. åˆ›å»ºè‡ªå®šä¹‰æ•°æ®è®¿é—®å·¥å…·&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# InsightEngine/tools/custom_db_tool.py
class CustomBusinessDBTool:
    """è‡ªå®šä¹‰ä¸šåŠ¡æ•°æ®åº“æŸ¥è¯¢å·¥å…·"""
    
    def __init__(self):
        self.connection_config = {
            'host': config.BUSINESS_DB_HOST,
            'port': config.BUSINESS_DB_PORT,
            'user': config.BUSINESS_DB_USER,
            'password': config.BUSINESS_DB_PASSWORD,
            'database': config.BUSINESS_DB_NAME,
        }
    
    def search_business_data(self, query: str, table: str):
        """æŸ¥è¯¢ä¸šåŠ¡æ•°æ®"""
        # å®ç°æ‚¨çš„ä¸šåŠ¡é€»è¾‘
        pass
    
    def get_customer_feedback(self, product_id: str):
        """è·å–å®¢æˆ·åé¦ˆæ•°æ®"""
        # å®ç°å®¢æˆ·åé¦ˆæŸ¥è¯¢é€»è¾‘
        pass
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;3. é›†æˆåˆ°InsightEngine&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# InsightEngine/agent.py ä¸­é›†æˆè‡ªå®šä¹‰å·¥å…·
from .tools.custom_db_tool import CustomBusinessDBTool

class DeepSearchAgent:
    def __init__(self, config=None):
        # ... å…¶ä»–åˆå§‹åŒ–ä»£ç 
        self.custom_db_tool = CustomBusinessDBTool()
    
    def execute_custom_search(self, query: str):
        """æ‰§è¡Œè‡ªå®šä¹‰ä¸šåŠ¡æ•°æ®æœç´¢"""
        return self.custom_db_tool.search_business_data(query, "your_table")
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;è‡ªå®šä¹‰æŠ¥å‘Šæ¨¡æ¿&lt;/h3&gt; 
&lt;h4&gt;1. åœ¨Webç•Œé¢ä¸­ä¸Šä¼ &lt;/h4&gt; 
&lt;p&gt;ç³»ç»Ÿæ”¯æŒä¸Šä¼ è‡ªå®šä¹‰æ¨¡æ¿æ–‡ä»¶ï¼ˆ.mdæˆ–.txtæ ¼å¼ï¼‰ï¼Œå¯åœ¨ç”ŸæˆæŠ¥å‘Šæ—¶é€‰æ‹©ä½¿ç”¨ã€‚&lt;/p&gt; 
&lt;h4&gt;2. åˆ›å»ºæ¨¡æ¿æ–‡ä»¶&lt;/h4&gt; 
&lt;p&gt;åœ¨ &lt;code&gt;ReportEngine/report_template/&lt;/code&gt; ç›®å½•ä¸‹åˆ›å»ºæ–°çš„æ¨¡æ¿ï¼Œæˆ‘ä»¬çš„Agentä¼šè‡ªè¡Œé€‰ç”¨æœ€åˆé€‚çš„æ¨¡æ¿ã€‚&lt;/p&gt; 
&lt;h2&gt;ğŸ¤ è´¡çŒ®æŒ‡å—&lt;/h2&gt; 
&lt;p&gt;æˆ‘ä»¬æ¬¢è¿æ‰€æœ‰å½¢å¼çš„è´¡çŒ®ï¼&lt;/p&gt; 
&lt;h3&gt;å¦‚ä½•è´¡çŒ®&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Forké¡¹ç›®&lt;/strong&gt;åˆ°æ‚¨çš„GitHubè´¦å·&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;åˆ›å»ºFeatureåˆ†æ”¯&lt;/strong&gt;ï¼š&lt;code&gt;git checkout -b feature/AmazingFeature&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;æäº¤æ›´æ”¹&lt;/strong&gt;ï¼š&lt;code&gt;git commit -m 'Add some AmazingFeature'&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;æ¨é€åˆ°åˆ†æ”¯&lt;/strong&gt;ï¼š&lt;code&gt;git push origin feature/AmazingFeature&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;å¼€å¯Pull Request&lt;/strong&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;å¼€å‘è§„èŒƒ&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;ä»£ç éµå¾ªPEP8è§„èŒƒ&lt;/li&gt; 
 &lt;li&gt;æäº¤ä¿¡æ¯ä½¿ç”¨æ¸…æ™°çš„ä¸­è‹±æ–‡æè¿°&lt;/li&gt; 
 &lt;li&gt;æ–°åŠŸèƒ½éœ€è¦åŒ…å«ç›¸åº”çš„æµ‹è¯•ç”¨ä¾‹&lt;/li&gt; 
 &lt;li&gt;æ›´æ–°ç›¸å…³æ–‡æ¡£&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ğŸ¦– ä¸‹ä¸€æ­¥å¼€å‘è®¡åˆ’&lt;/h2&gt; 
&lt;p&gt;ç°åœ¨ç³»ç»Ÿåªå®Œæˆäº†"ä¸‰æ¿æ–§"ä¸­çš„å‰ä¸¤æ­¥ï¼Œå³ï¼šè¾“å…¥è¦æ±‚-&amp;gt;è¯¦ç»†åˆ†æï¼Œè¿˜ç¼ºå°‘ä¸€æ­¥é¢„æµ‹ï¼Œç›´æ¥å°†ä»–ç»§ç»­äº¤ç»™LLMæ˜¯ä¸å…·æœ‰è¯´æœåŠ›çš„ã€‚&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/666ghj/BettaFish/main/static/image/banner_compressed.png" alt="banner" width="800" /&gt; 
&lt;/div&gt; 
&lt;p&gt;ç›®å‰æˆ‘ä»¬ç»è¿‡å¾ˆé•¿ä¸€æ®µæ—¶é—´çš„çˆ¬å–æ”¶é›†ï¼Œæ‹¥æœ‰äº†å¤§é‡å…¨ç½‘è¯é¢˜çƒ­åº¦éšæ—¶é—´ã€çˆ†ç‚¹ç­‰çš„å˜åŒ–è¶‹åŠ¿çƒ­åº¦æ•°æ®ï¼Œå·²ç»å…·å¤‡äº†å¯ä»¥å¼€å‘é¢„æµ‹æ¨¡å‹çš„æ¡ä»¶ã€‚æˆ‘ä»¬å›¢é˜Ÿå°†è¿ç”¨æ—¶åºæ¨¡å‹ã€å›¾ç¥ç»ç½‘ç»œã€å¤šæ¨¡æ€èåˆç­‰é¢„æµ‹æ¨¡å‹æŠ€æœ¯å‚¨å¤‡äºæ­¤ï¼Œå®ç°çœŸæ­£åŸºäºæ•°æ®é©±åŠ¨çš„èˆ†æƒ…é¢„æµ‹åŠŸèƒ½ã€‚&lt;/p&gt; 
&lt;h2&gt;âš ï¸ å…è´£å£°æ˜&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;é‡è¦æé†’ï¼šæœ¬é¡¹ç›®ä»…ä¾›å­¦ä¹ ã€å­¦æœ¯ç ”ç©¶å’Œæ•™è‚²ç›®çš„ä½¿ç”¨&lt;/strong&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;åˆè§„æ€§å£°æ˜&lt;/strong&gt;ï¼š&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;æœ¬é¡¹ç›®ä¸­çš„æ‰€æœ‰ä»£ç ã€å·¥å…·å’ŒåŠŸèƒ½å‡ä»…ä¾›å­¦ä¹ ã€å­¦æœ¯ç ”ç©¶å’Œæ•™è‚²ç›®çš„ä½¿ç”¨&lt;/li&gt; 
   &lt;li&gt;ä¸¥ç¦å°†æœ¬é¡¹ç›®ç”¨äºä»»ä½•å•†ä¸šç”¨é€”æˆ–ç›ˆåˆ©æ€§æ´»åŠ¨&lt;/li&gt; 
   &lt;li&gt;ä¸¥ç¦å°†æœ¬é¡¹ç›®ç”¨äºä»»ä½•è¿æ³•ã€è¿è§„æˆ–ä¾µçŠ¯ä»–äººæƒç›Šçš„è¡Œä¸º&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;çˆ¬è™«åŠŸèƒ½å…è´£&lt;/strong&gt;ï¼š&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;é¡¹ç›®ä¸­çš„çˆ¬è™«åŠŸèƒ½ä»…ç”¨äºæŠ€æœ¯å­¦ä¹ å’Œç ”ç©¶ç›®çš„&lt;/li&gt; 
   &lt;li&gt;ä½¿ç”¨è€…å¿…é¡»éµå®ˆç›®æ ‡ç½‘ç«™çš„robots.txtåè®®å’Œä½¿ç”¨æ¡æ¬¾&lt;/li&gt; 
   &lt;li&gt;ä½¿ç”¨è€…å¿…é¡»éµå®ˆç›¸å…³æ³•å¾‹æ³•è§„ï¼Œä¸å¾—è¿›è¡Œæ¶æ„çˆ¬å–æˆ–æ•°æ®æ»¥ç”¨&lt;/li&gt; 
   &lt;li&gt;å› ä½¿ç”¨çˆ¬è™«åŠŸèƒ½äº§ç”Ÿçš„ä»»ä½•æ³•å¾‹åæœç”±ä½¿ç”¨è€…è‡ªè¡Œæ‰¿æ‹…&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;æ•°æ®ä½¿ç”¨å…è´£&lt;/strong&gt;ï¼š&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;é¡¹ç›®æ¶‰åŠçš„æ•°æ®åˆ†æåŠŸèƒ½ä»…ä¾›å­¦æœ¯ç ”ç©¶ä½¿ç”¨&lt;/li&gt; 
   &lt;li&gt;ä¸¥ç¦å°†åˆ†æç»“æœç”¨äºå•†ä¸šå†³ç­–æˆ–ç›ˆåˆ©ç›®çš„&lt;/li&gt; 
   &lt;li&gt;ä½¿ç”¨è€…åº”ç¡®ä¿æ‰€åˆ†ææ•°æ®çš„åˆæ³•æ€§å’Œåˆè§„æ€§&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;æŠ€æœ¯å…è´£&lt;/strong&gt;ï¼š&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;æœ¬é¡¹ç›®æŒ‰"ç°çŠ¶"æä¾›ï¼Œä¸æä¾›ä»»ä½•æ˜ç¤ºæˆ–æš—ç¤ºçš„ä¿è¯&lt;/li&gt; 
   &lt;li&gt;ä½œè€…ä¸å¯¹ä½¿ç”¨æœ¬é¡¹ç›®é€ æˆçš„ä»»ä½•ç›´æ¥æˆ–é—´æ¥æŸå¤±æ‰¿æ‹…è´£ä»»&lt;/li&gt; 
   &lt;li&gt;ä½¿ç”¨è€…åº”è‡ªè¡Œè¯„ä¼°é¡¹ç›®çš„é€‚ç”¨æ€§å’Œé£é™©&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;è´£ä»»é™åˆ¶&lt;/strong&gt;ï¼š&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;ä½¿ç”¨è€…åœ¨ä½¿ç”¨æœ¬é¡¹ç›®å‰åº”å……åˆ†äº†è§£ç›¸å…³æ³•å¾‹æ³•è§„&lt;/li&gt; 
   &lt;li&gt;ä½¿ç”¨è€…åº”ç¡®ä¿å…¶ä½¿ç”¨è¡Œä¸ºç¬¦åˆå½“åœ°æ³•å¾‹æ³•è§„è¦æ±‚&lt;/li&gt; 
   &lt;li&gt;å› è¿åæ³•å¾‹æ³•è§„ä½¿ç”¨æœ¬é¡¹ç›®è€Œäº§ç”Ÿçš„ä»»ä½•åæœç”±ä½¿ç”¨è€…è‡ªè¡Œæ‰¿æ‹…&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;è¯·åœ¨ä½¿ç”¨æœ¬é¡¹ç›®å‰ä»”ç»†é˜…è¯»å¹¶ç†è§£ä¸Šè¿°å…è´£å£°æ˜ã€‚ä½¿ç”¨æœ¬é¡¹ç›®å³è¡¨ç¤ºæ‚¨å·²åŒæ„å¹¶æ¥å—ä¸Šè¿°æ‰€æœ‰æ¡æ¬¾ã€‚&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;ğŸ“„ è®¸å¯è¯&lt;/h2&gt; 
&lt;p&gt;æœ¬é¡¹ç›®é‡‡ç”¨ &lt;a href="https://raw.githubusercontent.com/666ghj/BettaFish/main/LICENSE"&gt;GPL-2.0è®¸å¯è¯&lt;/a&gt;ã€‚è¯¦ç»†ä¿¡æ¯è¯·å‚é˜…LICENSEæ–‡ä»¶ã€‚&lt;/p&gt; 
&lt;h2&gt;ğŸ‰ æ”¯æŒä¸è”ç³»&lt;/h2&gt; 
&lt;h3&gt;è·å–å¸®åŠ©&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;é¡¹ç›®ä¸»é¡µ&lt;/strong&gt;ï¼š&lt;a href="https://github.com/666ghj/Weibo_PublicOpinion_AnalysisSystem"&gt;GitHubä»“åº“&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;é—®é¢˜åé¦ˆ&lt;/strong&gt;ï¼š&lt;a href="https://github.com/666ghj/Weibo_PublicOpinion_AnalysisSystem/issues"&gt;Issuesé¡µé¢&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;åŠŸèƒ½å»ºè®®&lt;/strong&gt;ï¼š&lt;a href="https://github.com/666ghj/Weibo_PublicOpinion_AnalysisSystem/discussions"&gt;Discussionsé¡µé¢&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;è”ç³»æ–¹å¼&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;ğŸ“§ &lt;strong&gt;é‚®ç®±&lt;/strong&gt;ï¼š&lt;a href="mailto:670939375@qq.com"&gt;670939375@qq.com&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;å•†åŠ¡åˆä½œ&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;ä¼ä¸šå®šåˆ¶å¼€å‘&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;å¤§æ•°æ®æœåŠ¡&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;å­¦æœ¯åˆä½œ&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;æŠ€æœ¯åŸ¹è®­&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ğŸ‘¥ è´¡çŒ®è€…&lt;/h2&gt; 
&lt;p&gt;æ„Ÿè°¢ä»¥ä¸‹ä¼˜ç§€çš„è´¡çŒ®è€…ä»¬ï¼š&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/666ghj/Weibo_PublicOpinion_AnalysisSystem/graphs/contributors"&gt;&lt;img src="https://contrib.rocks/image?repo=666ghj/Weibo_PublicOpinion_AnalysisSystem" alt="Contributors" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;ğŸ“ˆ é¡¹ç›®ç»Ÿè®¡&lt;/h2&gt; 
&lt;a href="https://www.star-history.com/#666ghj/BettaFish&amp;amp;type=date&amp;amp;legend=top-left"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://api.star-history.com/svg?repos=666ghj/BettaFish&amp;amp;type=date&amp;amp;theme=dark&amp;amp;legend=top-left" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://api.star-history.com/svg?repos=666ghj/BettaFish&amp;amp;type=date&amp;amp;legend=top-left" /&gt; 
  &lt;img alt="Star History Chart" src="https://api.star-history.com/svg?repos=666ghj/BettaFish&amp;amp;type=date&amp;amp;legend=top-left" /&gt; 
 &lt;/picture&gt; &lt;/a&gt; 
&lt;p&gt;&lt;img src="https://repobeats.axiom.co/api/embed/e04e3eea4674edc39c148a7845c8d09c1b7b1922.svg?sanitize=true" alt="Alt" title="Repobeats analytics image" /&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>inventree/InvenTree</title>
      <link>https://github.com/inventree/InvenTree</link>
      <description>&lt;p&gt;Open Source Inventory Management System&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/inventree/InvenTree/master/assets/images/logo/inventree.png" alt="InvenTree logo" width="200" height="auto" /&gt; 
 &lt;h1&gt;InvenTree&lt;/h1&gt; 
 &lt;p&gt;Open Source Inventory Management System &lt;/p&gt; 
 &lt;!-- Badges --&gt; 
 &lt;p&gt;&lt;a href="https://opensource.org/license/MIT"&gt;&lt;img src="https://img.shields.io/badge/License-MIT-yellow.svg?sanitize=true" alt="License: MIT" /&gt;&lt;/a&gt;&lt;img src="https://img.shields.io/github/v/tag/inventree/inventree" alt="GitHub tag (latest SemVer)" /&gt; &lt;img src="https://github.com/inventree/inventree/actions/workflows/qc_checks.yaml/badge.svg?sanitize=true" alt="CI" /&gt; &lt;a href="https://inventree.readthedocs.io/en/latest/?badge=latest"&gt;&lt;img src="https://readthedocs.org/projects/inventree/badge/?version=latest" alt="Documentation Status" /&gt;&lt;/a&gt; &lt;img src="https://github.com/inventree/inventree/actions/workflows/docker.yaml/badge.svg?sanitize=true" alt="Docker Build" /&gt; &lt;a href="https://app.netlify.com/sites/inventree/deploys"&gt;&lt;img src="https://api.netlify.com/api/v1/badges/9bbb2101-0a4d-41e7-ad56-b63fb6053094/deploy-status" alt="Netlify Status" /&gt;&lt;/a&gt; &lt;a href="https://dev.azure.com/InvenTree/InvenTree%20test%20statistics/_build/latest?definitionId=3&amp;amp;branchName=testing"&gt;&lt;img src="https://dev.azure.com/InvenTree/InvenTree%20test%20statistics/_apis/build/status%2Fmatmair.InvenTree?branchName=testing" alt="Performance Testing" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://bestpractices.coreinfrastructure.org/projects/7179"&gt;&lt;img src="https://bestpractices.coreinfrastructure.org/projects/7179/badge" alt="OpenSSF Best Practices" /&gt;&lt;/a&gt; &lt;a href="https://securityscorecards.dev/viewer/?uri=github.com/inventree/InvenTree"&gt;&lt;img src="https://api.securityscorecards.dev/projects/github.com/inventree/InvenTree/badge" alt="OpenSSF Scorecard" /&gt;&lt;/a&gt; &lt;a href="https://sonarcloud.io/summary/new_code?id=inventree_InvenTree"&gt;&lt;img src="https://sonarcloud.io/api/project_badges/measure?project=inventree_InvenTree&amp;amp;metric=sqale_rating" alt="Maintainability Rating" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://codecov.io/gh/inventree/InvenTree"&gt;&lt;img src="https://codecov.io/gh/inventree/InvenTree/graph/badge.svg?token=9DZRGUUV7B" alt="codecov" /&gt;&lt;/a&gt; &lt;a href="https://crowdin.com/project/inventree"&gt;&lt;img src="https://badges.crowdin.net/inventree/localized.svg?sanitize=true" alt="Crowdin" /&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/github/commit-activity/m/inventree/inventree" alt="GitHub commit activity" /&gt; &lt;a href="https://hub.docker.com/r/inventree/inventree"&gt;&lt;img src="https://img.shields.io/docker/pulls/inventree/inventree" alt="Docker Pulls" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://github.com/inventree/InvenTree/"&gt;&lt;img src="https://img.shields.io/github/stars/inventree?style=social" alt="GitHub Org's stars" /&gt;&lt;/a&gt; &lt;a href="https://twitter.com/inventreedb"&gt;&lt;img src="https://img.shields.io/twitter/follow/inventreedb?style=social" alt="Twitter Follow" /&gt;&lt;/a&gt; &lt;a href="https://www.reddit.com/r/InvenTree/"&gt;&lt;img src="https://img.shields.io/reddit/subreddit-subscribers/inventree?style=social" alt="Subreddit subscribers" /&gt;&lt;/a&gt; &lt;a href="https://chaos.social/@InvenTree"&gt;&lt;img src="https://img.shields.io/badge/dynamic/json?label=Mastodon&amp;amp;query=followers_count&amp;amp;url=https%3A%2F%2Fchaos.social%2Fapi%2Fv1%2Faccounts%2Flookup%3Facct=InvenTree&amp;amp;logo=mastodon&amp;amp;style=social" alt="Mastdon" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;h4&gt; &lt;a href="https://demo.inventree.org/"&gt;View Demo&lt;/a&gt; &lt;span&gt; Â· &lt;/span&gt; &lt;a href="https://docs.inventree.org/en/latest/"&gt;Documentation&lt;/a&gt; &lt;span&gt; Â· &lt;/span&gt; &lt;a href="https://github.com/inventree/InvenTree/issues/new?template=bug_report.md&amp;amp;title=%5BBUG%5D"&gt;Report Bug&lt;/a&gt; &lt;span&gt; Â· &lt;/span&gt; &lt;a href="https://github.com/inventree/InvenTree/issues/new?template=feature_request.md&amp;amp;title=%5BFR%5D"&gt;Request Feature&lt;/a&gt; &lt;/h4&gt; 
&lt;/div&gt; 
&lt;!-- About the Project --&gt; 
&lt;h2&gt;&lt;span&gt;ğŸŒŸ&lt;/span&gt; About the Project&lt;/h2&gt; 
&lt;p&gt;InvenTree is an open-source Inventory Management System which provides powerful low-level stock control and part tracking. The core of the InvenTree system is a Python/Django database backend which provides an admin interface (web-based) and a REST API for interaction with external interfaces and applications. A powerful plugin system provides support for custom applications and extensions.&lt;/p&gt; 
&lt;p&gt;Check out &lt;a href="https://inventree.org"&gt;our website&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;!-- Roadmap --&gt; 
&lt;h3&gt;&lt;span&gt;ğŸ§­&lt;/span&gt; Roadmap&lt;/h3&gt; 
&lt;p&gt;Want to see what we are working on? Check out the &lt;a href="https://github.com/inventree/InvenTree/issues?q=is%3Aopen+is%3Aissue+label%3Aroadmap"&gt;roadmap tag&lt;/a&gt; and &lt;a href="https://github.com/inventree/InvenTree/milestone/42"&gt;horizon milestone&lt;/a&gt;.&lt;/p&gt; 
&lt;!-- Integration --&gt; 
&lt;h3&gt;&lt;span&gt;ğŸ› &lt;/span&gt; Integration&lt;/h3&gt; 
&lt;p&gt;InvenTree is designed to be &lt;strong&gt;extensible&lt;/strong&gt;, and provides multiple options for &lt;strong&gt;integration&lt;/strong&gt; with external applications or addition of custom plugins:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.inventree.org/en/latest/api/"&gt;InvenTree API&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.inventree.org/en/latest/api/python/"&gt;Python module&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.inventree.org/en/latest/plugins/"&gt;Plugin interface&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.inventree.org/en/latest/plugins/integrate/"&gt;Third party tools&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;!-- TechStack --&gt; 
&lt;h3&gt;&lt;span&gt;ğŸ‘¾&lt;/span&gt; Tech Stack&lt;/h3&gt; 
&lt;details&gt; 
 &lt;summary&gt;Server&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://www.python.org/"&gt;Python&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.djangoproject.com/"&gt;Django&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.django-rest-framework.org/"&gt;DRF&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://django-q.readthedocs.io/"&gt;Django Q&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://docs.allauth.org/"&gt;Django-Allauth&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Database&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://www.postgresql.org/"&gt;PostgreSQL&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.mysql.com/"&gt;MySQL&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.sqlite.org/"&gt;SQLite&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://redis.io/"&gt;Redis&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Client&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://react.dev/"&gt;React&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://lingui.dev/"&gt;Lingui&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://reactrouter.com/"&gt;React Router&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://tanstack.com/query/"&gt;TanStack Query&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/pmndrs/zustand"&gt;Zustand&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://mantine.dev/"&gt;Mantine&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://icflorescu.github.io/mantine-datatable/"&gt;Mantine Data Table&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://codemirror.net/"&gt;CodeMirror&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;DevOps&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://hub.docker.com/r/inventree/inventree"&gt;Docker&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://crowdin.com/project/inventree"&gt;Crowdin&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://app.codecov.io/gh/inventree/InvenTree"&gt;Codecov&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://sonarcloud.io/project/overview?id=inventree_InvenTree"&gt;SonarCloud&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://packager.io/gh/inventree/InvenTree"&gt;Packager.io&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;!-- Getting Started --&gt; 
&lt;h2&gt;&lt;span&gt;ğŸ§°&lt;/span&gt; Deployment / Getting Started&lt;/h2&gt; 
&lt;p&gt;There are several options to deploy InvenTree.&lt;/p&gt; 
&lt;div align="center"&gt;
 &lt;h4&gt; &lt;a href="https://docs.inventree.org/en/latest/start/docker/"&gt;Docker&lt;/a&gt; &lt;span&gt; Â· &lt;/span&gt; &lt;a href="https://inventree.org/digitalocean"&gt;&lt;img src="https://www.deploytodo.com/do-btn-blue-ghost.svg?sanitize=true" alt="Deploy to DO" width="auto" height="40" /&gt;&lt;/a&gt; &lt;span&gt; Â· &lt;/span&gt; &lt;a href="https://docs.inventree.org/en/latest/start/install/"&gt;Bare Metal&lt;/a&gt; &lt;/h4&gt;
&lt;/div&gt; 
&lt;p&gt;Single line install - read &lt;a href="https://docs.inventree.org/en/latest/start/installer/"&gt;the docs&lt;/a&gt; for supported distros and details about the function:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;wget -qO install.sh https://get.inventree.org &amp;amp;&amp;amp; bash install.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Refer to the &lt;a href="https://docs.inventree.org/en/latest/start/install/"&gt;getting started guide&lt;/a&gt; for a full set of installation and setup instructions.&lt;/p&gt; 
&lt;!-- Mobile App --&gt; 
&lt;h2&gt;&lt;span&gt;ğŸ“±&lt;/span&gt; Mobile App&lt;/h2&gt; 
&lt;p&gt;InvenTree is supported by a &lt;a href="https://docs.inventree.org/en/latest/app/"&gt;companion mobile app&lt;/a&gt; which allows users access to stock control information and functionality.&lt;/p&gt; 
&lt;div align="center"&gt;
 &lt;h4&gt; &lt;a href="https://play.google.com/store/apps/details?id=inventree.inventree_app"&gt;Android Play Store&lt;/a&gt; &lt;span&gt; Â· &lt;/span&gt; &lt;a href="https://apps.apple.com/au/app/inventree/id1581731101#?platform=iphone"&gt;Apple App Store&lt;/a&gt; &lt;/h4&gt;
&lt;/div&gt; 
&lt;!-- Security --&gt; 
&lt;h2&gt;&lt;span&gt;ğŸ”’&lt;/span&gt; Code of Conduct &amp;amp; Security Policy&lt;/h2&gt; 
&lt;p&gt;The InvenTree project team is committed to providing a safe and welcoming environment for all users. Please read our &lt;a href="https://raw.githubusercontent.com/inventree/InvenTree/master/CODE_OF_CONDUCT.md"&gt;Code of Conduct&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;p&gt;InvenTree is following industry best practices for security. Our security policy is included &lt;a href="https://raw.githubusercontent.com/inventree/InvenTree/master/SECURITY.md"&gt;in this repo&lt;/a&gt;. We provide dedicated security pages on &lt;a href="https://docs.inventree.org/en/latest/security/"&gt;our documentation site&lt;/a&gt;.&lt;/p&gt; 
&lt;!-- Contributing --&gt; 
&lt;h2&gt;&lt;span&gt;ğŸ‘‹&lt;/span&gt; Contributing&lt;/h2&gt; 
&lt;p&gt;Contributions are welcomed and encouraged. Please help to make this project even better! Refer to the &lt;a href="https://docs.inventree.org/en/latest/develop/contributing/"&gt;contribution page&lt;/a&gt;.&lt;/p&gt; 
&lt;!-- Translation --&gt; 
&lt;h2&gt;&lt;span&gt;ğŸ“œ&lt;/span&gt; Translation&lt;/h2&gt; 
&lt;p&gt;Native language translation of the InvenTree web application is &lt;a href="https://crowdin.com/project/inventree"&gt;community contributed via crowdin&lt;/a&gt;. &lt;strong&gt;Contributions are welcomed and encouraged&lt;/strong&gt;.&lt;/p&gt; 
&lt;!-- Sponsor --&gt; 
&lt;h2&gt;&lt;span&gt;ğŸ’¸&lt;/span&gt; Sponsor&lt;/h2&gt; 
&lt;p&gt;If you use InvenTree and find it to be useful, please consider &lt;a href="https://github.com/sponsors/inventree"&gt;sponsoring the project&lt;/a&gt;.&lt;/p&gt; 
&lt;!-- Acknowledgments --&gt; 
&lt;h2&gt;&lt;span&gt;ğŸ’&lt;/span&gt; Acknowledgements&lt;/h2&gt; 
&lt;p&gt;We want to acknowledge &lt;a href="https://github.com/partkeepr/PartKeepr"&gt;PartKeepr&lt;/a&gt; as a valuable predecessor and inspiration. Find a full list of used third-party libraries in the license information dialog of your instance.&lt;/p&gt; 
&lt;h2&gt;&lt;span&gt;â¤ï¸&lt;/span&gt; Support&lt;/h2&gt; 
&lt;p&gt;This project is supported by the following sponsors:&lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/MartinLoeper"&gt;&lt;img src="https://github.com/MartinLoeper.png" width="60px" alt="Martin LÃ¶per" /&gt;&lt;/a&gt; &lt;a href="https://github.com/lippoliv"&gt;&lt;img src="https://github.com/lippoliv.png" width="60px" alt="Oliver Lippert" /&gt;&lt;/a&gt; &lt;a href="https://github.com/lfg-seth"&gt;&lt;img src="https://github.com/lfg-seth.png" width="60px" alt="Seth Smith" /&gt;&lt;/a&gt; &lt;a href="https://github.com/snorkrat"&gt;&lt;img src="https://github.com/snorkrat.png" width="60px" alt="" /&gt;&lt;/a&gt; &lt;a href="https://github.com/spacequest-ltd"&gt;&lt;img src="https://github.com/spacequest-ltd.png" width="60px" alt="SpaceQuest Ltd" /&gt;&lt;/a&gt; &lt;a href="https://github.com/appwrite"&gt;&lt;img src="https://github.com/appwrite.png" width="60px" alt="Appwrite" /&gt;&lt;/a&gt; &lt;a href="https://github.com/PricelessToolkit"&gt;&lt;img src="https://github.com/PricelessToolkit.png" width="60px" alt="" /&gt;&lt;/a&gt; &lt;a href="https://github.com/cabottech"&gt;&lt;img src="https://github.com/cabottech.png" width="60px" alt="Cabot Technologies" /&gt;&lt;/a&gt; &lt;a href="https://github.com/markus-k"&gt;&lt;img src="https://github.com/markus-k.png" width="60px" alt="Markus Kasten" /&gt;&lt;/a&gt; &lt;a href="https://github.com/jefffhaynes"&gt;&lt;img src="https://github.com/jefffhaynes.png" width="60px" alt="Jeff Haynes" /&gt;&lt;/a&gt; &lt;a href="https://github.com/dnviti"&gt;&lt;img src="https://github.com/dnviti.png" width="60px" alt="Daniele Viti" /&gt;&lt;/a&gt; &lt;a href="https://github.com/Islendur"&gt;&lt;img src="https://github.com/Islendur.png" width="60px" alt="Islendur" /&gt;&lt;/a&gt; &lt;a href="https://github.com/Gibeon-NL"&gt;&lt;img src="https://github.com/Gibeon-NL.png" width="60px" alt="Gibeon-NL" /&gt;&lt;/a&gt; &lt;a href="https://github.com/Motrac-Research-Engineering"&gt;&lt;img src="https://github.com/Motrac-Research-Engineering.png" width="60px" alt="Motrac Research" /&gt;&lt;/a&gt; &lt;a href="https://github.com/trytuna"&gt;&lt;img src="https://github.com/trytuna.png" width="60px" alt="Timo Scrappe" /&gt;&lt;/a&gt; &lt;a href="https://github.com/ATLAS2246"&gt;&lt;img src="https://github.com/ATLAS2246.png" width="60px" alt="ATLAS2246" /&gt;&lt;/a&gt; &lt;a href="https://github.com/Kedarius"&gt;&lt;img src="https://github.com/Kedarius.png" width="60px" alt="Radek Hladik" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p&gt;With ongoing resources provided by:&lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://depot.dev?utm_source=inventree"&gt;&lt;img src="https://depot.dev/badges/built-with-depot.svg?sanitize=true" alt="Built with Depot" /&gt;&lt;/a&gt; &lt;a href="https://inventree.org/digitalocean"&gt; &lt;img src="https://opensource.nyc3.cdn.digitaloceanspaces.com/attribution/assets/SVG/DO_Logo_horizontal_blue.svg?sanitize=true" width="201px" alt="Servers by Digital Ocean" /&gt; &lt;/a&gt; &lt;a href="https://www.netlify.com"&gt; &lt;img src="https://www.netlify.com/v3/img/components/netlify-color-bg.svg?sanitize=true" alt="Deploys by Netlify" /&gt; &lt;/a&gt; &lt;a href="https://crowdin.com"&gt; &lt;img src="https://crowdin.com/images/crowdin-logo.svg?sanitize=true" alt="Translation by Crowdin" /&gt; &lt;/a&gt; &lt;br /&gt; &lt;/p&gt; 
&lt;!-- License --&gt; 
&lt;h2&gt;&lt;span&gt;âš &lt;/span&gt; License&lt;/h2&gt; 
&lt;p&gt;Distributed under the &lt;a href="https://choosealicense.com/licenses/mit/"&gt;MIT&lt;/a&gt; License. See &lt;a href="https://github.com/inventree/InvenTree/raw/master/LICENSE"&gt;LICENSE.txt&lt;/a&gt; for more information.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>hacksider/Deep-Live-Cam</title>
      <link>https://github.com/hacksider/Deep-Live-Cam</link>
      <description>&lt;p&gt;real time face swap and one-click video deepfake with only a single image&lt;/p&gt;&lt;hr&gt;&lt;h1 align="center"&gt;Deep-Live-Cam&lt;/h1&gt; 
&lt;p align="center"&gt; Real-time face swap and video deepfake with a single click and only a single image. &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://trendshift.io/repositories/11395" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/11395" alt="hacksider%2FDeep-Live-Cam | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/hacksider/Deep-Live-Cam/main/media/demo.gif" alt="Demo GIF" width="800" /&gt; &lt;/p&gt; 
&lt;h2&gt;Disclaimer&lt;/h2&gt; 
&lt;p&gt;This deepfake software is designed to be a productive tool for the AI-generated media industry. It can assist artists in animating custom characters, creating engaging content, and even using models for clothing design.&lt;/p&gt; 
&lt;p&gt;We are aware of the potential for unethical applications and are committed to preventative measures. A built-in check prevents the program from processing inappropriate media (nudity, graphic content, sensitive material like war footage, etc.). We will continue to develop this project responsibly, adhering to the law and ethics. We may shut down the project or add watermarks if legally required.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Ethical Use: Users are expected to use this software responsibly and legally. If using a real person's face, obtain their consent and clearly label any output as a deepfake when sharing online.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Content Restrictions: The software includes built-in checks to prevent processing inappropriate media, such as nudity, graphic content, or sensitive material.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Legal Compliance: We adhere to all relevant laws and ethical guidelines. If legally required, we may shut down the project or add watermarks to the output.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;User Responsibility: We are not responsible for end-user actions. Users must ensure their use of the software aligns with ethical standards and legal requirements.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;By using this software, you agree to these terms and commit to using it in a manner that respects the rights and dignity of others.&lt;/p&gt; 
&lt;p&gt;Users are expected to use this software responsibly and legally. If using a real person's face, obtain their consent and clearly label any output as a deepfake when sharing online. We are not responsible for end-user actions.&lt;/p&gt; 
&lt;h2&gt;Exclusive v2.3 Quick Start - Pre-built (Windows/Mac Silicon)&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://deeplivecam.net/index.php/quickstart"&gt; &lt;img src="https://raw.githubusercontent.com/hacksider/Deep-Live-Cam/main/media/Download.png" width="285" height="77" /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;a href="https://deeplivecam.net/index.php/quickstart"&gt; &lt;h5&gt;This is the fastest build you can get if you have a discrete NVIDIA or AMD GPU or Mac Silicon, And you'll receive special priority support.&lt;/h5&gt; &lt;h6&gt;These Pre-builts are perfect for non-technical users or those who don't have time to, or can't manually install all the requirements. Just a heads-up: this is an open-source project, so you can also install it manually.&lt;/h6&gt; &lt;h2&gt;TLDR; Live Deepfake in just 3 Clicks&lt;/h2&gt; &lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/af825228-852c-411b-b787-ffd9aac72fc6" alt="easysteps" /&gt;&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;Select a face&lt;/li&gt; 
  &lt;li&gt;Select which camera to use&lt;/li&gt; 
  &lt;li&gt;Press live!&lt;/li&gt; 
 &lt;/ol&gt; &lt;h2&gt;Features &amp;amp; Uses - Everything is in real-time&lt;/h2&gt; &lt;h3&gt;Mouth Mask&lt;/h3&gt; &lt;p&gt;&lt;strong&gt;Retain your original mouth for accurate movement using Mouth Mask&lt;/strong&gt;&lt;/p&gt; &lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/hacksider/Deep-Live-Cam/main/media/ludwig.gif" alt="resizable-gif" /&gt; &lt;/p&gt; &lt;h3&gt;Face Mapping&lt;/h3&gt; &lt;p&gt;&lt;strong&gt;Use different faces on multiple subjects simultaneously&lt;/strong&gt;&lt;/p&gt; &lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/hacksider/Deep-Live-Cam/main/media/streamers.gif" alt="face_mapping_source" /&gt; &lt;/p&gt; &lt;h3&gt;Your Movie, Your Face&lt;/h3&gt; &lt;p&gt;&lt;strong&gt;Watch movies with any face in real-time&lt;/strong&gt;&lt;/p&gt; &lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/hacksider/Deep-Live-Cam/main/media/movie.gif" alt="movie" /&gt; &lt;/p&gt; &lt;h3&gt;Live Show&lt;/h3&gt; &lt;p&gt;&lt;strong&gt;Run Live shows and performances&lt;/strong&gt;&lt;/p&gt; &lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/hacksider/Deep-Live-Cam/main/media/live_show.gif" alt="show" /&gt; &lt;/p&gt; &lt;h3&gt;Memes&lt;/h3&gt; &lt;p&gt;&lt;strong&gt;Create Your Most Viral Meme Yet&lt;/strong&gt;&lt;/p&gt; &lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/hacksider/Deep-Live-Cam/main/media/meme.gif" alt="show" width="450" /&gt; &lt;br /&gt; &lt;sub&gt;Created using Many Faces feature in Deep-Live-Cam&lt;/sub&gt; &lt;/p&gt; &lt;h3&gt;Omegle&lt;/h3&gt; &lt;p&gt;&lt;strong&gt;Surprise people on Omegle&lt;/strong&gt;&lt;/p&gt; &lt;p align="center"&gt; 
  &lt;video src="https://github.com/user-attachments/assets/2e9b9b82-fa04-4b70-9f56-b1f68e7672d0" width="450" controls&gt;&lt;/video&gt; &lt;/p&gt; &lt;h2&gt;Installation (Manual)&lt;/h2&gt; &lt;p&gt;&lt;strong&gt;Please be aware that the installation requires technical skills and is not for beginners. Consider downloading the quickstart version.&lt;/strong&gt;&lt;/p&gt; &lt;/a&gt;
&lt;details&gt;
 &lt;a href="https://deeplivecam.net/index.php/quickstart"&gt; &lt;summary&gt;Click to see the process&lt;/summary&gt; &lt;h3&gt;Installation&lt;/h3&gt; &lt;p&gt;This is more likely to work on your computer but will be slower as it utilizes the CPU.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;1. Set up Your Platform&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Python (3.11 recommended)&lt;/li&gt; 
   &lt;li&gt;pip&lt;/li&gt; 
   &lt;li&gt;git&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=OlNWCpFdVMA"&gt;ffmpeg&lt;/a&gt; - &lt;code&gt;iex (irm ffmpeg.tc.ht)&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://visualstudio.microsoft.com/visual-cpp-build-tools/"&gt;Visual Studio 2022 Runtimes (Windows)&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt;&lt;/a&gt; 
 &lt;p&gt;&lt;strong&gt;2. Clone the Repository&lt;/strong&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/hacksider/Deep-Live-Cam.git
cd Deep-Live-Cam
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;3. Download the Models&lt;/strong&gt;&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/hacksider/deep-live-cam/resolve/main/GFPGANv1.4.pth"&gt;GFPGANv1.4&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/hacksider/deep-live-cam/resolve/main/inswapper_128_fp16.onnx"&gt;inswapper_128_fp16.onnx&lt;/a&gt;&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;p&gt;Place these files in the "&lt;strong&gt;models&lt;/strong&gt;" folder.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;4. Install Dependencies&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;We highly recommend using a &lt;code&gt;venv&lt;/code&gt; to avoid issues.&lt;/p&gt; 
 &lt;p&gt;For Windows:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;python -m venv venv
venv\Scripts\activate
pip install -r requirements.txt
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;For Linux:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# Ensure you use the installed Python 3.10
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;For macOS:&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;Apple Silicon (M1/M2/M3) requires specific setup:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# Install Python 3.11 (specific version is important)
brew install python@3.11

# Install tkinter package (required for the GUI)
brew install python-tk@3.10

# Create and activate virtual environment with Python 3.11
python3.11 -m venv venv
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;** In case something goes wrong and you need to reinstall the virtual environment **&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# Deactivate the virtual environment
rm -rf venv

# Reinstall the virtual environment
python -m venv venv
source venv/bin/activate

# install the dependencies again
pip install -r requirements.txt

# gfpgan and basicsrs issue fix
pip install git+https://github.com/xinntao/BasicSR.git@master
pip uninstall gfpgan -y
pip install git+https://github.com/TencentARC/GFPGAN.git@master
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;Run:&lt;/strong&gt; If you don't have a GPU, you can run Deep-Live-Cam using &lt;code&gt;python run.py&lt;/code&gt;. Note that initial execution will download models (~300MB).&lt;/p&gt; 
 &lt;h3&gt;GPU Acceleration&lt;/h3&gt; 
 &lt;p&gt;&lt;strong&gt;CUDA Execution Provider (Nvidia)&lt;/strong&gt;&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;Install &lt;a href="https://developer.nvidia.com/cuda-12-8-0-download-archive"&gt;CUDA Toolkit 12.8.0&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Install &lt;a href="https://developer.nvidia.com/rdp/cudnn-archive"&gt;cuDNN v8.9.7 for CUDA 12.x&lt;/a&gt; (required for onnxruntime-gpu): 
   &lt;ul&gt; 
    &lt;li&gt;Download cuDNN v8.9.7 for CUDA 12.x&lt;/li&gt; 
    &lt;li&gt;Make sure the cuDNN bin directory is in your system PATH&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;Install dependencies:&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;pip install -U torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu128
pip uninstall onnxruntime onnxruntime-gpu
pip install onnxruntime-gpu==1.21.0
&lt;/code&gt;&lt;/pre&gt; 
 &lt;ol start="3"&gt; 
  &lt;li&gt;Usage:&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;python run.py --execution-provider cuda
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;CoreML Execution Provider (Apple Silicon)&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;Apple Silicon (M1/M2/M3) specific installation:&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;Make sure you've completed the macOS setup above using Python 3.10.&lt;/li&gt; 
  &lt;li&gt;Install dependencies:&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;pip uninstall onnxruntime onnxruntime-silicon
pip install onnxruntime-silicon==1.13.1
&lt;/code&gt;&lt;/pre&gt; 
 &lt;ol start="3"&gt; 
  &lt;li&gt;Usage (important: specify Python 3.10):&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;python3.10 run.py --execution-provider coreml
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;Important Notes for macOS:&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;You &lt;strong&gt;must&lt;/strong&gt; use Python 3.10, not newer versions like 3.11 or 3.13&lt;/li&gt; 
  &lt;li&gt;Always run with &lt;code&gt;python3.10&lt;/code&gt; command not just &lt;code&gt;python&lt;/code&gt; if you have multiple Python versions installed&lt;/li&gt; 
  &lt;li&gt;If you get error about &lt;code&gt;_tkinter&lt;/code&gt; missing, reinstall the tkinter package: &lt;code&gt;brew reinstall python-tk@3.10&lt;/code&gt;&lt;/li&gt; 
  &lt;li&gt;If you get model loading errors, check that your models are in the correct folder&lt;/li&gt; 
  &lt;li&gt;If you encounter conflicts with other Python versions, consider uninstalling them: &lt;pre&gt;&lt;code class="language-bash"&gt;# List all installed Python versions
brew list | grep python

# Uninstall conflicting versions if needed
brew uninstall --ignore-dependencies python@3.11 python@3.13

# Keep only Python 3.11
brew cleanup
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;CoreML Execution Provider (Apple Legacy)&lt;/strong&gt;&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;Install dependencies:&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;pip uninstall onnxruntime onnxruntime-coreml
pip install onnxruntime-coreml==1.21.0
&lt;/code&gt;&lt;/pre&gt; 
 &lt;ol start="2"&gt; 
  &lt;li&gt;Usage:&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;python run.py --execution-provider coreml
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;DirectML Execution Provider (Windows)&lt;/strong&gt;&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;Install dependencies:&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;pip uninstall onnxruntime onnxruntime-directml
pip install onnxruntime-directml==1.21.0
&lt;/code&gt;&lt;/pre&gt; 
 &lt;ol start="2"&gt; 
  &lt;li&gt;Usage:&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;python run.py --execution-provider directml
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;OpenVINOâ„¢ Execution Provider (Intel)&lt;/strong&gt;&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;Install dependencies:&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;pip uninstall onnxruntime onnxruntime-openvino
pip install onnxruntime-openvino==1.21.0
&lt;/code&gt;&lt;/pre&gt; 
 &lt;ol start="2"&gt; 
  &lt;li&gt;Usage:&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;python run.py --execution-provider openvino
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;1. Image/Video Mode&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Execute &lt;code&gt;python run.py&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Choose a source face image and a target image/video.&lt;/li&gt; 
 &lt;li&gt;Click "Start".&lt;/li&gt; 
 &lt;li&gt;The output will be saved in a directory named after the target video.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;2. Webcam Mode&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Execute &lt;code&gt;python run.py&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Select a source face image.&lt;/li&gt; 
 &lt;li&gt;Click "Live".&lt;/li&gt; 
 &lt;li&gt;Wait for the preview to appear (10-30 seconds).&lt;/li&gt; 
 &lt;li&gt;Use a screen capture tool like OBS to stream.&lt;/li&gt; 
 &lt;li&gt;To change the face, select a new source image.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Command Line Arguments (Unmaintained)&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;options:
  -h, --help                                               show this help message and exit
  -s SOURCE_PATH, --source SOURCE_PATH                     select a source image
  -t TARGET_PATH, --target TARGET_PATH                     select a target image or video
  -o OUTPUT_PATH, --output OUTPUT_PATH                     select output file or directory
  --frame-processor FRAME_PROCESSOR [FRAME_PROCESSOR ...]  frame processors (choices: face_swapper, face_enhancer, ...)
  --keep-fps                                               keep original fps
  --keep-audio                                             keep original audio
  --keep-frames                                            keep temporary frames
  --many-faces                                             process every face
  --map-faces                                              map source target faces
  --mouth-mask                                             mask the mouth region
  --video-encoder {libx264,libx265,libvpx-vp9}             adjust output video encoder
  --video-quality [0-51]                                   adjust output video quality
  --live-mirror                                            the live camera display as you see it in the front-facing camera frame
  --live-resizable                                         the live camera frame is resizable
  --max-memory MAX_MEMORY                                  maximum amount of RAM in GB
  --execution-provider {cpu} [{cpu} ...]                   available execution provider (choices: cpu, ...)
  --execution-threads EXECUTION_THREADS                    number of execution threads
  -v, --version                                            show program's version number and exit
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Looking for a CLI mode? Using the -s/--source argument will make the run program in cli mode.&lt;/p&gt; 
&lt;h2&gt;Press&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;We are always open to criticism and are ready to improve, that's why we didn't cherry-pick anything.&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://arstechnica.com/information-technology/2024/08/new-ai-tool-enables-real-time-face-swapping-on-webcams-raising-fraud-concerns/"&gt;&lt;em&gt;"Deep-Live-Cam goes viral, allowing anyone to become a digital doppelganger"&lt;/em&gt;&lt;/a&gt; - Ars Technica&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://dataconomy.com/2024/08/15/what-is-deep-live-cam-github-deepfake/"&gt;&lt;em&gt;"Thanks Deep Live Cam, shapeshifters are among us now"&lt;/em&gt;&lt;/a&gt; - Dataconomy&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.newsbytesapp.com/news/science/deep-live-cam-ai-impersonation-tool-goes-viral/story"&gt;&lt;em&gt;"This free AI tool lets you become anyone during video-calls"&lt;/em&gt;&lt;/a&gt; - NewsBytes&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.creativebloq.com/ai/ok-this-viral-ai-live-stream-software-is-truly-terrifying"&gt;&lt;em&gt;"OK, this viral AI live stream software is truly terrifying"&lt;/em&gt;&lt;/a&gt; - Creative Bloq&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://petapixel.com/2024/08/14/deep-live-cam-deepfake-ai-tool-lets-you-become-anyone-in-a-video-call-with-single-photo-mark-zuckerberg-jd-vance-elon-musk/"&gt;&lt;em&gt;"Deepfake AI Tool Lets You Become Anyone in a Video Call With Single Photo"&lt;/em&gt;&lt;/a&gt; - PetaPixel&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.techeblog.com/deep-live-cam-ai-transform-face/"&gt;&lt;em&gt;"Deep-Live-Cam Uses AI to Transform Your Face in Real-Time, Celebrities Included"&lt;/em&gt;&lt;/a&gt; - TechEBlog&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://telegrafi.com/en/a-tool-that-makes-you-look-like-anyone-during-a-video-call-is-going-viral-on-the-Internet/"&gt;&lt;em&gt;"An AI tool that "makes you look like anyone" during a video call is going viral online"&lt;/em&gt;&lt;/a&gt; - Telegrafi&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://decrypt.co/244565/this-deepfake-tool-turning-images-into-livestreams-is-topping-the-github-charts"&gt;&lt;em&gt;"This Deepfake Tool Turning Images Into Livestreams is Topping the GitHub Charts"&lt;/em&gt;&lt;/a&gt; - Emerge&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.digitalmusicnews.com/2024/08/15/face-swapping-ai-real-time-mimic/"&gt;&lt;em&gt;"New Real-Time Face-Swapping AI Allows Anyone to Mimic Famous Faces"&lt;/em&gt;&lt;/a&gt; - Digital Music News&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.diyphotography.net/this-real-time-webcam-deepfake-tool-raises-alarms-about-the-future-of-identity-theft/"&gt;&lt;em&gt;"This real-time webcam deepfake tool raises alarms about the future of identity theft"&lt;/em&gt;&lt;/a&gt; - DIYPhotography&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/watch?time_continue=1074&amp;amp;v=py4Tc-Y8BcY"&gt;&lt;em&gt;"That's Crazy, Oh God. That's Fucking Freaky Dude... That's So Wild Dude"&lt;/em&gt;&lt;/a&gt; - SomeOrdinaryGamers&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/live/mFsCe7AIxq8?feature=shared&amp;amp;t=2686"&gt;&lt;em&gt;"Alright look look look, now look chat, we can do any face we want to look like chat"&lt;/em&gt;&lt;/a&gt; - IShowSpeed&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=wnCghLjqv3s&amp;amp;t=551s"&gt;&lt;em&gt;"They do a pretty good job matching poses, expression and even the lighting"&lt;/em&gt;&lt;/a&gt; - TechLinked (LTT)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.golem.de/news/deepfakes-als-sean-connery-an-der-redaktionskonferenz-teilnahm-2408-188172.html"&gt;&lt;em&gt;"Als Sean Connery an der Redaktionskonferenz teilnahm"&lt;/em&gt;&lt;/a&gt; - Golem.de (German)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Credits&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://ffmpeg.org/"&gt;ffmpeg&lt;/a&gt;: for making video-related operations easy&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/deepinsight"&gt;deepinsight&lt;/a&gt;: for their &lt;a href="https://github.com/deepinsight/insightface"&gt;insightface&lt;/a&gt; project which provided a well-made library and models. Please be reminded that the &lt;a href="https://github.com/deepinsight/insightface?tab=readme-ov-file#license"&gt;use of the model is for non-commercial research purposes only&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/havok2-htwo"&gt;havok2-htwo&lt;/a&gt;: for sharing the code for webcam&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/GosuDRM"&gt;GosuDRM&lt;/a&gt;: for the open version of roop&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pereiraroland26"&gt;pereiraroland26&lt;/a&gt;: Multiple faces support&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/vic4key"&gt;vic4key&lt;/a&gt;: For supporting/contributing to this project&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/kier007"&gt;kier007&lt;/a&gt;: for improving the user experience&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/qitianai"&gt;qitianai&lt;/a&gt;: for multi-lingual support&lt;/li&gt; 
 &lt;li&gt;and &lt;a href="https://github.com/hacksider/Deep-Live-Cam/graphs/contributors"&gt;all developers&lt;/a&gt; behind libraries used in this project.&lt;/li&gt; 
 &lt;li&gt;Footnote: Please be informed that the base author of the code is &lt;a href="https://github.com/s0md3v/roop"&gt;s0md3v&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;All the wonderful users who helped make this project go viral by starring the repo â¤ï¸&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://github.com/hacksider/Deep-Live-Cam/stargazers"&gt;&lt;img src="https://reporoster.com/stars/hacksider/Deep-Live-Cam" alt="Stargazers" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Contributions&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://repobeats.axiom.co/api/embed/fec8e29c45dfdb9c5916f3a7830e1249308d20e1.svg?sanitize=true" alt="Alt" title="Repobeats analytics image" /&gt;&lt;/p&gt; 
&lt;h2&gt;Stars to the Moon ğŸš€&lt;/h2&gt; 
&lt;a href="https://star-history.com/#hacksider/deep-live-cam&amp;amp;Date"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://api.star-history.com/svg?repos=hacksider/deep-live-cam&amp;amp;type=Date&amp;amp;theme=dark" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://api.star-history.com/svg?repos=hacksider/deep-live-cam&amp;amp;type=Date" /&gt; 
  &lt;img alt="Star History Chart" src="https://api.star-history.com/svg?repos=hacksider/deep-live-cam&amp;amp;type=Date" /&gt; 
 &lt;/picture&gt; &lt;/a&gt;</description>
    </item>
    
    <item>
      <title>GeeeekExplorer/nano-vllm</title>
      <link>https://github.com/GeeeekExplorer/nano-vllm</link>
      <description>&lt;p&gt;Nano vLLM&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;img width="300" src="https://raw.githubusercontent.com/GeeeekExplorer/nano-vllm/main/assets/logo.png" /&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://trendshift.io/repositories/15323" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/15323" alt="GeeeekExplorer%2Fnano-vllm | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;h1&gt;Nano-vLLM&lt;/h1&gt; 
&lt;p&gt;A lightweight vLLM implementation built from scratch.&lt;/p&gt; 
&lt;h2&gt;Key Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;ğŸš€ &lt;strong&gt;Fast offline inference&lt;/strong&gt; - Comparable inference speeds to vLLM&lt;/li&gt; 
 &lt;li&gt;ğŸ“– &lt;strong&gt;Readable codebase&lt;/strong&gt; - Clean implementation in ~ 1,200 lines of Python code&lt;/li&gt; 
 &lt;li&gt;âš¡ &lt;strong&gt;Optimization Suite&lt;/strong&gt; - Prefix caching, Tensor Parallelism, Torch compilation, CUDA graph, etc.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install git+https://github.com/GeeeekExplorer/nano-vllm.git
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Model Download&lt;/h2&gt; 
&lt;p&gt;To download the model weights manually, use the following command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;huggingface-cli download --resume-download Qwen/Qwen3-0.6B \
  --local-dir ~/huggingface/Qwen3-0.6B/ \
  --local-dir-use-symlinks False
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;p&gt;See &lt;code&gt;example.py&lt;/code&gt; for usage. The API mirrors vLLM's interface with minor differences in the &lt;code&gt;LLM.generate&lt;/code&gt; method:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from nanovllm import LLM, SamplingParams
llm = LLM("/YOUR/MODEL/PATH", enforce_eager=True, tensor_parallel_size=1)
sampling_params = SamplingParams(temperature=0.6, max_tokens=256)
prompts = ["Hello, Nano-vLLM."]
outputs = llm.generate(prompts, sampling_params)
outputs[0]["text"]
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Benchmark&lt;/h2&gt; 
&lt;p&gt;See &lt;code&gt;bench.py&lt;/code&gt; for benchmark.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Test Configuration:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Hardware: RTX 4070 Laptop (8GB)&lt;/li&gt; 
 &lt;li&gt;Model: Qwen3-0.6B&lt;/li&gt; 
 &lt;li&gt;Total Requests: 256 sequences&lt;/li&gt; 
 &lt;li&gt;Input Length: Randomly sampled between 100â€“1024 tokens&lt;/li&gt; 
 &lt;li&gt;Output Length: Randomly sampled between 100â€“1024 tokens&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Performance Results:&lt;/strong&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Inference Engine&lt;/th&gt; 
   &lt;th&gt;Output Tokens&lt;/th&gt; 
   &lt;th&gt;Time (s)&lt;/th&gt; 
   &lt;th&gt;Throughput (tokens/s)&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;vLLM&lt;/td&gt; 
   &lt;td&gt;133,966&lt;/td&gt; 
   &lt;td&gt;98.37&lt;/td&gt; 
   &lt;td&gt;1361.84&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Nano-vLLM&lt;/td&gt; 
   &lt;td&gt;133,966&lt;/td&gt; 
   &lt;td&gt;93.41&lt;/td&gt; 
   &lt;td&gt;1434.13&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Star History&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://www.star-history.com/#GeeeekExplorer/nano-vllm&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=GeeeekExplorer/nano-vllm&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>moondevonyt/moon-dev-ai-agents</title>
      <link>https://github.com/moondevonyt/moon-dev-ai-agents</link>
      <description>&lt;p&gt;autonomous ai agents for trading in python&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;ğŸ¤– AI AGENTS FOR TRADING&lt;/h1&gt; 
&lt;p align="center"&gt; &lt;a href="https://www.moondev.com/"&gt;&lt;img src="https://raw.githubusercontent.com/moondevonyt/moon-dev-ai-agents/main/moondev.png" width="300" alt="Moon Dev" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;h2&gt;ğŸ¯ Vision&lt;/h2&gt; 
&lt;p&gt;ai agents are clearly the future and the entire workforce will be replaced or atleast using ai agents. while i am a quant and building agents for algo trading i will be contributing to all different types of ai agent flows and placing all of the agents here for free, 100% open sourced because i believe code is the great equalizer and we have never seen a regime shift like this so i need to get this code to the people&lt;/p&gt; 
&lt;p&gt;feel free to join &lt;a href="https://discord.gg/8UPuVZ53bh"&gt;our discord&lt;/a&gt; if you beleive ai agents will be integrated into the workforce&lt;/p&gt; 
&lt;h2&gt;Video Updates &amp;amp; Training&lt;/h2&gt; 
&lt;p&gt;â­ï¸ &lt;a href="https://youtu.be/RlqzkSgDKDc"&gt;first full concise documentation video (watch here)&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;â­ï¸ &lt;a href="https://youtu.be/tjY24JR8Cso?si=Za-PQ2L79US6cu2T"&gt;second full walkthrough video(watch here)&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;â­ï¸ &lt;a href="https://youtu.be/qZv6IFIkk6I"&gt;third full walkthrough w/ big updates, new models, new agents(watch here)&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;â­ï¸ &lt;a href="https://youtu.be/D0VRQj0tuCI"&gt;forth full walkthrough w/ new agents &amp;amp; ai models&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;ğŸ“€ follow all updates here on youtube in this playlist: &lt;a href="https://www.youtube.com/playlist?list=PLXrNVMjRZUJg4M4uz52iGd1LhXXGVbIFz"&gt;https://www.youtube.com/playlist?list=PLXrNVMjRZUJg4M4uz52iGd1LhXXGVbIFz&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ğŸ¤– All Available Agents&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;âš ï¸ For live trading agents: Only use these AFTER thoroughly backtesting your strategies!&lt;/strong&gt;&lt;/p&gt; 
&lt;h3&gt;Backtesting &amp;amp; Research Agents&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;RBI Agent&lt;/strong&gt; (&lt;code&gt;rbi_agent.py&lt;/code&gt;): Uses DeepSeek to research trading strategies based on YouTube videos, PDFs, or text you provide, then codes out the backtest automatically&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;RBI Parallel Agent&lt;/strong&gt; (&lt;code&gt;rbi_agent_pp_multi.py&lt;/code&gt;): Parallel version with 18 threads, tests across 20+ data sources, web dashboard included&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Research Agent&lt;/strong&gt; (&lt;code&gt;research_agent.py&lt;/code&gt;): Fills the ideas.txt file so the RBI agent can run forever&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Websearch Agent&lt;/strong&gt; (&lt;code&gt;websearch_agent.py&lt;/code&gt;): This agent searches the web, in my use case for trading strategy resources and then uses other ai's to split the website ideas into strategy files i can have my &lt;code&gt;rbi_agent_pp_multi.py&lt;/code&gt; process and build out backtests&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Live Trading Agents&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Trading Agent&lt;/strong&gt; (&lt;code&gt;trading_agent.py&lt;/code&gt;): &lt;strong&gt;DUAL-MODE AI trading system&lt;/strong&gt; - Toggle between single model (fast ~10s) or swarm mode (6-model consensus ~45-60s). Swarm mode queries Claude 4.5, GPT-5, Gemini 2.5, Grok-4, DeepSeek, and DeepSeek-R1 local for majority vote trading decisions. Configure via &lt;code&gt;USE_SWARM_MODE&lt;/code&gt; in config.py&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Strategy Agent&lt;/strong&gt; (&lt;code&gt;strategy_agent.py&lt;/code&gt;): Manages and executes trading strategies placed in the strategies folder&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Risk Agent&lt;/strong&gt; (&lt;code&gt;risk_agent.py&lt;/code&gt;): Monitors and manages portfolio risk, enforcing position limits and PnL thresholds&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Copy Agent&lt;/strong&gt; (&lt;code&gt;copy_agent.py&lt;/code&gt;): Monitors copy bot for potential trades&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Swarm Agent&lt;/strong&gt; (&lt;code&gt;swarm_agent.py&lt;/code&gt;): Queries 6 AI models in parallel (Claude 4.5, GPT-5, Gemini 2.5, Grok-4, DeepSeek, DeepSeek-R1 local), generates AI consensus summary, returns clean JSON with model mapping for easy parsing ğŸ&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Market Analysis Agents&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Whale Agent&lt;/strong&gt; (&lt;code&gt;whale_agent.py&lt;/code&gt;): Monitors whale activity and announces when a whale enters the market&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Sentiment Agent&lt;/strong&gt; (&lt;code&gt;sentiment_agent.py&lt;/code&gt;): Analyzes Twitter sentiment for crypto tokens with voice announcements&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Chart Agent&lt;/strong&gt; (&lt;code&gt;chartanalysis_agent.py&lt;/code&gt;): Looks at any crypto chart and analyzes it with AI to make a buy/sell/nothing recommendation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Funding Agent&lt;/strong&gt; (&lt;code&gt;funding_agent.py&lt;/code&gt;): Monitors funding rates across exchanges and uses AI to analyze opportunities, providing voice alerts for extreme funding situations with technical context ğŸŒ™&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Liquidation Agent&lt;/strong&gt; (&lt;code&gt;liquidation_agent.py&lt;/code&gt;): Tracks liquidation events with configurable time windows (15min/1hr/4hr), providing AI analysis and voice alerts for significant liquidation spikes ğŸ’¦&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Listing Arbitrage Agent&lt;/strong&gt; (&lt;code&gt;listingarb_agent.py&lt;/code&gt;): Identifies promising Solana tokens on CoinGecko before they reach major exchanges like Binance and Coinbase, using parallel AI analysis for technical and fundamental insights&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Funding Arbitrage Agent&lt;/strong&gt; (&lt;code&gt;fundingarb_agent.py&lt;/code&gt;): Tracks the funding rate on HyperLiquid to find funding rate arbitrage opportunities between HL and Solana&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;New or Top Tokens Agent&lt;/strong&gt; (&lt;code&gt;new_or_top_agent.py&lt;/code&gt;): Looks at the new tokens and the top tokens from CoinGecko API&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Solana-Specific Agents&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Sniper Agent&lt;/strong&gt; (&lt;code&gt;sniper_agent.py&lt;/code&gt;): Watches for new Solana token launches, analyzes them, and maybe snipes&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;TX Agent&lt;/strong&gt; (&lt;code&gt;tx_agent.py&lt;/code&gt;): Watches transactions made by your copy list and prints them out with optional auto tab open&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Solana Agent&lt;/strong&gt; (&lt;code&gt;solana_agent.py&lt;/code&gt;): Looks at the sniper agent and the TX agent to select which memes may be interesting&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Content Creation Agents&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Chat Agent&lt;/strong&gt; (&lt;code&gt;chat_agent.py&lt;/code&gt;): Monitors YouTube live stream chat, moderates &amp;amp; responds to known questions. Absolute fire.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Twitter Agent&lt;/strong&gt; (&lt;code&gt;tweet_agent.py&lt;/code&gt;): Takes in text and creates tweets using DeepSeek or other models&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Video Agent&lt;/strong&gt; (&lt;code&gt;video_agent.py&lt;/code&gt;): ğŸ¬ Parallel AI video generation using OpenAI's Sora 2 API - create videos directly from text prompts with 9 concurrent workers, configurable resolutions (720p/1080p), durations (4/8/12s), and aspect ratios (9:16 for TikTok/Reels, 16:9 for YouTube, 1:1 for Instagram). &lt;a href="https://raw.githubusercontent.com/moondevonyt/moon-dev-ai-agents/main/docs/video_agent.md"&gt;See full docs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Clips Agent&lt;/strong&gt; (&lt;code&gt;clips_agent.py&lt;/code&gt;): Helps clip long videos into shorter ones so you can upload to your YouTube and get paid. More info: &lt;a href="https://discord.gg/XAw8US9aHT"&gt;https://discord.gg/XAw8US9aHT&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Real-Time Clips Agent&lt;/strong&gt; (&lt;code&gt;realtime_clips_agent.py&lt;/code&gt;): Makes real-time clips of streamers using OBS&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Phone Agent&lt;/strong&gt; (&lt;code&gt;phone_agent.py&lt;/code&gt;): An AI agent that can take phone calls for you&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Specialized Agents&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Prompt Agent&lt;/strong&gt; (&lt;code&gt;prompt_agent.py&lt;/code&gt;): ğŸ¯ Interactive prompt enhancement tool that transforms basic prompts into professional, production-ready prompts using best practices from Parahelp &amp;amp; Cursor. Stays open in terminal, continuously ready to enhance your prompts with expert design principles (role-based prompting, structured formatting, explicit thinking order). Auto-saves and copies enhanced prompts. Perfect for improving prompts for any AI task. &lt;a href="https://raw.githubusercontent.com/moondevonyt/moon-dev-ai-agents/main/docs/prompt_agent.md"&gt;See full docs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Focus Agent&lt;/strong&gt; (&lt;code&gt;focus_agent.py&lt;/code&gt;): Randomly samples audio during coding sessions to maintain productivity, providing focus scores and voice alerts when focus drops (~$10/month, perfect for voice-to-code workflows)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Million Agent&lt;/strong&gt; (&lt;code&gt;million_agent.py&lt;/code&gt;): Uses million context window from Gemini to pull in a knowledge base&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;TikTok Agent&lt;/strong&gt; (&lt;code&gt;tiktok_agent.py&lt;/code&gt;): Scrolls TikTok and gets screenshots of the video + comments to extract consumer data to feed into algos. Sometimes called social arbitrage&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Compliance Agent&lt;/strong&gt; (&lt;code&gt;compliance_agent.py&lt;/code&gt;): Analyzes TikTok ads for Facebook advertising compliance, extracting frames and transcribing audio to check against FB guidelines&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Housecoin Agent&lt;/strong&gt; (&lt;code&gt;housecoin_agent.py&lt;/code&gt;): DCA (dollar cost average) agent with AI confirmation layer using Grok-4 for the thesis: 1 House = 1 Housecoin ğŸ &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Polymarket Agent&lt;/strong&gt; (&lt;code&gt;polymarket_agent.py&lt;/code&gt;): Connects to the live trades feed via WebSocket and analyzes with the swarm agent to see which markets could be interesting to trade&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;âš ï¸ Critical Disclaimers&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;There is no token associated with this project and there never will be. any token launched is not affiliated with this project, moon dev will never dm you. be careful. don't send funds anywhere&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;PLEASE READ CAREFULLY:&lt;/strong&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;This is an experimental research project, NOT a trading system&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;There are NO plug-and-play solutions for guaranteed profits&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;We do NOT provide trading strategies&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Success depends entirely on YOUR:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Trading strategy&lt;/li&gt; 
   &lt;li&gt;Risk management&lt;/li&gt; 
   &lt;li&gt;Market research&lt;/li&gt; 
   &lt;li&gt;Testing and validation&lt;/li&gt; 
   &lt;li&gt;Overall trading approach&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;NO AI agent can guarantee profitable trading&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;You MUST develop and validate your own trading approach&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Trading involves substantial risk of loss&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Past performance does not indicate future results&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;âš ï¸ IMPORTANT: This is an experimental project. There are NO guarantees of profitability. Trading involves substantial risk of loss.&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;ğŸ‘‚ Looking for Updates?&lt;/h2&gt; 
&lt;p&gt;Project updates will be posted in Discord, join here: &lt;a href="https://discord.gg/8UPuVZ53bh"&gt;discord.gg/8UPuVZ53bh&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;ğŸ”— Links&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Free Algo Trading Roadmap: &lt;a href="https://moondev.com"&gt;moondev.com&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Algo Trading Education: &lt;a href="https://algotradecamp.com"&gt;algotradecamp.com&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Business Contact &lt;a href="mailto:moon@algotradecamp.com"&gt;moon@algotradecamp.com&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ğŸš€ Quick Start Guide - RBI Backtesting Agent&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Why Start with Backtesting?&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Before running ANY trading algorithm or AI agent with real money, you MUST backtest your strategies. Backtesting shows you how a strategy would have performed on historical data. The RBI (Research-Based Inference) Agent automates this entire process for you.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;What is the RBI Agent?&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;The RBI Agent takes your trading ideas (from YouTube videos, PDFs, or plain text) and:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;ğŸ§  Uses AI to understand the trading strategy&lt;/li&gt; 
 &lt;li&gt;ğŸ’» Codes a complete backtest using the &lt;code&gt;backtesting.py&lt;/code&gt; library&lt;/li&gt; 
 &lt;li&gt;ğŸ“Š Tests across 20+ different market data sources&lt;/li&gt; 
 &lt;li&gt;âœ… Only saves strategies that pass a 1% return threshold&lt;/li&gt; 
 &lt;li&gt;ğŸ¯ Tries to optimize strategies to hit a 50% target return&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;Python Version:&lt;/strong&gt; 3.10.9 was used during development&lt;/p&gt; 
&lt;h3&gt;Step 1: â­ Star &amp;amp; Fork the Repo&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Click the star button to save it to your GitHub favorites&lt;/li&gt; 
 &lt;li&gt;Fork to your GitHub account to get your own copy&lt;/li&gt; 
 &lt;li&gt;This lets you make changes and track updates&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Step 2: ğŸ’» Clone to Your Machine&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/YOUR_USERNAME/moon-dev-ai-agents-for-trading.git
cd moon-dev-ai-agents-for-trading
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Recommended IDEs:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.cursor.com/"&gt;Cursor&lt;/a&gt; - AI-enabled coding&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://codeium.com/"&gt;Windsurfer&lt;/a&gt; - AI-enabled coding&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Step 3: ğŸ”‘ Set Up Environment Variables&lt;/h3&gt; 
&lt;p&gt;The RBI Agent needs API keys to function. Create a &lt;code&gt;.env&lt;/code&gt; file in the root directory:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Copy the example file
cp .env.example .env
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Required API Keys for RBI Agent:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# AI Model APIs (you need at least ONE of these)
ANTHROPIC_KEY=your_anthropic_api_key_here          # Claude models (recommended)
OPENAI_KEY=your_openai_api_key_here                # GPT models
DEEPSEEK_KEY=your_deepseek_api_key_here            # DeepSeek models (cheap!)
GROQ_API_KEY=your_groq_api_key_here                # Groq (fast inference)
GEMINI_KEY=your_gemini_api_key_here                # Google Gemini
XAI_API_KEY=your_xai_api_key_here                  # Grok models
OPENROUTER_API_KEY=your_openrouter_api_key_here    # OpenRouter (200+ models!)

# Market Data APIs (for downloading price data)
BIRDEYE_API_KEY=your_birdeye_api_key_here          # Solana token data
COINGECKO_API_KEY=your_coingecko_api_key_here      # Crypto market data
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Where to Get API Keys:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Anthropic Claude&lt;/strong&gt;: &lt;a href="https://console.anthropic.com/"&gt;https://console.anthropic.com/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;OpenAI GPT&lt;/strong&gt;: &lt;a href="https://platform.openai.com/api-keys"&gt;https://platform.openai.com/api-keys&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;DeepSeek&lt;/strong&gt;: &lt;a href="https://platform.deepseek.com/"&gt;https://platform.deepseek.com/&lt;/a&gt; (very cheap, great for backtesting)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Groq&lt;/strong&gt;: &lt;a href="https://console.groq.com/"&gt;https://console.groq.com/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Google Gemini&lt;/strong&gt;: &lt;a href="https://aistudio.google.com/app/apikey"&gt;https://aistudio.google.com/app/apikey&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;xAI Grok&lt;/strong&gt;: &lt;a href="https://console.x.ai/"&gt;https://console.x.ai/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;OpenRouter&lt;/strong&gt;: &lt;a href="https://openrouter.ai/keys"&gt;https://openrouter.ai/keys&lt;/a&gt; (access 200+ models including Qwen, GLM, and more!)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;BirdEye&lt;/strong&gt;: &lt;a href="https://birdeye.so/"&gt;https://birdeye.so/&lt;/a&gt; (Solana data)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;CoinGecko&lt;/strong&gt;: &lt;a href="https://www.coingecko.com/en/api"&gt;https://www.coingecko.com/en/api&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;âš ï¸ &lt;strong&gt;Never commit or share your &lt;code&gt;.env&lt;/code&gt; file! It's in .gitignore for your safety.&lt;/strong&gt;&lt;/p&gt; 
&lt;h3&gt;Step 4: ğŸ“¦ Install Dependencies&lt;/h3&gt; 
&lt;p&gt;Using conda (recommended):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;conda create -n tflow python=3.10.9
conda activate tflow
pip install -r requirements.txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or using pip directly:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install -r requirements.txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Step 5: ğŸ§ª Run Your First Backtest&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Option A: Single Strategy Test&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Create a file called &lt;code&gt;ideas.txt&lt;/code&gt; in &lt;code&gt;src/data/rbi_pp_multi/&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Buy when RSI &amp;lt; 30 and sell when RSI &amp;gt; 70
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then run:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python src/agents/rbi_agent_pp_multi.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Option B: Use the Web Dashboard&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Start the dashboard:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd src/data/rbi_pp_multi
python app.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Open browser to: &lt;code&gt;http://localhost:8001&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;Click "New Backtests" and enter your strategy ideas!&lt;/p&gt; 
&lt;h3&gt;Step 6: ğŸ“Š Understanding Results&lt;/h3&gt; 
&lt;p&gt;The agent will:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Process your strategy idea&lt;/li&gt; 
 &lt;li&gt;Generate backtest code&lt;/li&gt; 
 &lt;li&gt;Test across 20+ market datasets (BTC, ETH, SOL, etc.)&lt;/li&gt; 
 &lt;li&gt;Show results in a table with: 
  &lt;ul&gt; 
   &lt;li&gt;Return %&lt;/li&gt; 
   &lt;li&gt;Buy &amp;amp; Hold %&lt;/li&gt; 
   &lt;li&gt;Max Drawdown&lt;/li&gt; 
   &lt;li&gt;Sharpe Ratio&lt;/li&gt; 
   &lt;li&gt;Sortino Ratio&lt;/li&gt; 
   &lt;li&gt;Number of Trades&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Only strategies returning &amp;gt; 1% are saved to the CSV.&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Results are saved to:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;src/data/rbi_pp_multi/backtest_stats.csv&lt;/code&gt; - All passing backtests&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;src/data/rbi_pp_multi/user_folders/&lt;/code&gt; - Organized by run name&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Step 7: ğŸ” Analyze Backtest Code&lt;/h3&gt; 
&lt;p&gt;Find your strategy files in:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;src/data/rbi_pp_multi/10_25_2025_09_08/
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Each successful backtest has:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Python file&lt;/strong&gt;: The actual backtest code you can review and modify&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Results&lt;/strong&gt;: Performance metrics&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Read the code!&lt;/strong&gt; This is how you learn what works and what doesn't.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ğŸ¯ Configuration - RBI Agent&lt;/h2&gt; 
&lt;p&gt;All settings are in &lt;code&gt;src/agents/rbi_agent_pp_multi.py&lt;/code&gt; (lines 130-132):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# ğŸ¯ PROFIT TARGET CONFIGURATION
TARGET_RETURN = 50  # Target return in % (AI tries to optimize to this)
SAVE_IF_OVER_RETURN = 1.0  # Save backtest to CSV if return &amp;gt; this %
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;How it works:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;AI tries to optimize strategies to hit &lt;strong&gt;50% return&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;But ANY backtest returning &lt;strong&gt;&amp;gt; 1%&lt;/strong&gt; gets saved to CSV&lt;/li&gt; 
 &lt;li&gt;This way you can review all decent strategies, not just perfect ones&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Other Settings:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;MAX_WORKERS = 18  # Number of parallel threads (adjust based on your CPU)
DEBUG_BACKTEST_ERRORS = True  # Auto-fix coding errors with AI
MAX_DEBUG_ITERATIONS = 10  # How many times to try fixing errors
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ğŸ“š Advanced: Adding Custom Data Sources&lt;/h2&gt; 
&lt;p&gt;Want to test on your own tokens? Edit the data list in &lt;code&gt;rbi_agent_pp_multi.py&lt;/code&gt; (lines 157-178):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;ALL_DATA_CONFIGS = [
    # Crypto data from CoinGecko/BirdEye
    {'symbol': 'BTC-USD', 'timeframe': '15m', 'days_back': 90},
    {'symbol': 'ETH-USD', 'timeframe': '15m', 'days_back': 90},
    {'symbol': 'SOL-USD', 'timeframe': '15m', 'days_back': 90},

    # Add your own token (Solana contract address)
    {'symbol': 'YOUR_TOKEN_ADDRESS', 'timeframe': '1H', 'days_back': 30},
]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The agent will automatically download and cache the data.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ğŸ—ºï¸ ROADMAP&lt;/h2&gt; 
&lt;h3&gt;In Progress&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;HyperLiquid Perps Integration&lt;/strong&gt; âœ…&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;Swarm Consensus Trading&lt;/strong&gt; âœ…&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;RBI Parallel Backtesting&lt;/strong&gt; âœ…&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Coming Soon&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;strong&gt;Polymarket Integration&lt;/strong&gt; - Prediction market trading&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;strong&gt;Base Chain Integration&lt;/strong&gt; - L2 network support&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;strong&gt;Extended Integration&lt;/strong&gt; - Additional exchange support&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;strong&gt;HyperLiquid Spot Trading&lt;/strong&gt; - Spot market support&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;strong&gt;Trending Agent&lt;/strong&gt; - Spots leaders on HyperLiquid&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;strong&gt;Position Sizing Agent&lt;/strong&gt; - Volume/liquidation-based sizing&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;strong&gt;Regime Agents&lt;/strong&gt; - Adaptive strategy switching&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;strong&gt;Polymarket Sweeper Agent&lt;/strong&gt; - Follow successful prediction traders&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Future Ideas&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;strong&gt;Lighter Integration&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;strong&gt;Pacifica Integration&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;strong&gt;Hibachi Integration&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;strong&gt;Aster Integration&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;strong&gt;HyperEVM Support&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;em&gt;Built with love by Moon Dev - Pioneering the future of AI-powered trading&lt;/em&gt;&lt;/p&gt; 
&lt;h2&gt;ğŸ“œ Detailed Disclaimer&lt;/h2&gt; 
&lt;p&gt;The content presented is for educational and informational purposes only and does not constitute financial advice. All trading involves risk and may not be suitable for all investors. You should carefully consider your investment objectives, level of experience, and risk appetite before investing.&lt;/p&gt; 
&lt;p&gt;Past performance is not indicative of future results. There is no guarantee that any trading strategy or algorithm discussed will result in profits or will not incur losses.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;CFTC Disclaimer:&lt;/strong&gt; Commodity Futures Trading Commission (CFTC) regulations require disclosure of the risks associated with trading commodities and derivatives. There is a substantial risk of loss in trading and investing.&lt;/p&gt; 
&lt;p&gt;I am not a licensed financial advisor or a registered broker-dealer. Content &amp;amp; code is based on personal research perspectives and should not be relied upon as a guarantee of success in trading.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>1Panel-dev/MaxKB</title>
      <link>https://github.com/1Panel-dev/MaxKB</link>
      <description>&lt;p&gt;ğŸ”¥ MaxKB is an open-source platform for building enterprise-grade agents. MaxKB æ˜¯å¼ºå¤§æ˜“ç”¨çš„å¼€æºä¼ä¸šçº§æ™ºèƒ½ä½“å¹³å°ã€‚&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt;&lt;img src="https://github.com/1Panel-dev/maxkb/assets/52996290/c0694996-0eed-40d8-b369-322bf2a380bf" alt="MaxKB" width="300" /&gt;&lt;/p&gt; 
&lt;h3 align="center"&gt;Open-source platform for building enterprise-grade agents&lt;/h3&gt; 
&lt;h3 align="center"&gt;å¼ºå¤§æ˜“ç”¨çš„ä¼ä¸šçº§æ™ºèƒ½ä½“å¹³å°&lt;/h3&gt; 
&lt;p align="center"&gt;&lt;a href="https://trendshift.io/repositories/9113" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/9113" alt="1Panel-dev%2FMaxKB | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://www.gnu.org/licenses/gpl-3.0.html#license-text"&gt;&lt;img src="https://img.shields.io/github/license/1Panel-dev/maxkb?color=%231890FF" alt="License: GPL v3" /&gt;&lt;/a&gt; &lt;a href="https://github.com/1Panel-dev/maxkb/releases/latest"&gt;&lt;img src="https://img.shields.io/github/v/release/1Panel-dev/maxkb" alt="Latest release" /&gt;&lt;/a&gt; &lt;a href="https://github.com/1Panel-dev/maxkb"&gt;&lt;img src="https://img.shields.io/github/stars/1Panel-dev/maxkb?color=%231890FF&amp;amp;style=flat-square" alt="Stars" /&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/r/1panel/maxkb"&gt;&lt;img src="https://img.shields.io/docker/pulls/1panel/maxkb?label=downloads" alt="Download" /&gt;&lt;/a&gt;&lt;br /&gt; [&lt;a href="https://raw.githubusercontent.com/1Panel-dev/MaxKB/v2/README_CN.md"&gt;ä¸­æ–‡(ç®€ä½“)&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/1Panel-dev/MaxKB/v2/README.md"&gt;English&lt;/a&gt;] &lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;MaxKB = Max Knowledge Brain, it is an open-source platform for building enterprise-grade agents. MaxKB integrates Retrieval-Augmented Generation (RAG) pipelines, supports robust workflows, and provides advanced MCP tool-use capabilities. MaxKB is widely applied in scenarios such as intelligent customer service, corporate internal knowledge bases, academic research, and education.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;RAG Pipeline&lt;/strong&gt;: Supports direct uploading of documents / automatic crawling of online documents, with features for automatic text splitting, vectorization. This effectively reduces hallucinations in large models, providing a superior smart Q&amp;amp;A interaction experience.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Agentic Workflow&lt;/strong&gt;: Equipped with a powerful workflow engine, function library and MCP tool-use, enabling the orchestration of AI processes to meet the needs of complex business scenarios.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Seamless Integration&lt;/strong&gt;: Facilitates zero-coding rapid integration into third-party business systems, quickly equipping existing systems with intelligent Q&amp;amp;A capabilities to enhance user satisfaction.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Model-Agnostic&lt;/strong&gt;: Supports various large models, including private models (such as DeepSeek, Llama, Qwen, etc.) and public models (like OpenAI, Claude, Gemini, etc.).&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Multi Modal&lt;/strong&gt;: Native support for input and output text, image, audio and video.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Quick start&lt;/h2&gt; 
&lt;p&gt;Execute the script below to start a MaxKB container using Docker:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run -d --name=maxkb --restart=always -p 8080:8080 -v ~/.maxkb:/opt/maxkb 1panel/maxkb
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Access MaxKB web interface at &lt;code&gt;http://your_server_ip:8080&lt;/code&gt; with default admin credentials:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;username: admin&lt;/li&gt; 
 &lt;li&gt;password: MaxKB@123..&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;ä¸­å›½ç”¨æˆ·å¦‚é‡åˆ° Docker é•œåƒ Pull å¤±è´¥é—®é¢˜ï¼Œè¯·å‚ç…§è¯¥ &lt;a href="https://maxkb.cn/docs/v2/installation/offline_installtion/"&gt;ç¦»çº¿å®‰è£…æ–‡æ¡£&lt;/a&gt; è¿›è¡Œå®‰è£…ã€‚&lt;/p&gt; 
&lt;h2&gt;Screenshots&lt;/h2&gt; 
&lt;table style="border-collapse: collapse; border: 1px solid black;"&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td style="padding: 5px;background-color:#fff;"&gt;&lt;img src="https://github.com/user-attachments/assets/eb285512-a66a-4752-8941-c65ed1592238" alt="MaxKB Demo1" /&gt;&lt;/td&gt; 
   &lt;td style="padding: 5px;background-color:#fff;"&gt;&lt;img src="https://github.com/user-attachments/assets/f732f1f5-472c-4fd2-93c1-a277eda83d04" alt="MaxKB Demo2" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td style="padding: 5px;background-color:#fff;"&gt;&lt;img src="https://github.com/user-attachments/assets/c927474a-9a23-4830-822f-5db26025c9b2" alt="MaxKB Demo3" /&gt;&lt;/td&gt; 
   &lt;td style="padding: 5px;background-color:#fff;"&gt;&lt;img src="https://github.com/user-attachments/assets/e6268996-a46d-4e58-9f30-31139df78ad2" alt="MaxKB Demo4" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h2&gt;Technical stack&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Frontendï¼š&lt;a href="https://vuejs.org/"&gt;Vue.js&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Backendï¼š&lt;a href="https://www.djangoproject.com/"&gt;Python / Django&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;LLM Frameworkï¼š&lt;a href="https://www.langchain.com/"&gt;LangChain&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Databaseï¼š&lt;a href="https://www.postgresql.org/"&gt;PostgreSQL + pgvector&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Star History&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://star-history.com/#1Panel-dev/MaxKB&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=1Panel-dev/MaxKB&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Licensed under The GNU General Public License version 3 (GPLv3) (the "License"); you may not use this file except in compliance with the License. You may obtain a copy of the License at&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.gnu.org/licenses/gpl-3.0.html"&gt;https://www.gnu.org/licenses/gpl-3.0.html&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>VectifyAI/PageIndex</title>
      <link>https://github.com/VectifyAI/PageIndex</link>
      <description>&lt;p&gt;ğŸ“„ğŸ§  PageIndex: Document Index for Reasoning-based RAG&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;a href="https://vectify.ai/pageindex" target="_blank"&gt; &lt;img src="https://github.com/user-attachments/assets/46201e72-675b-43bc-bfbd-081cc6b65a1d" alt="PageIndex Banner" /&gt; &lt;/a&gt; 
 &lt;br /&gt; 
 &lt;br /&gt; 
 &lt;p align="center"&gt; &lt;a href="https://trendshift.io/repositories/14736" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/14736" alt="VectifyAI%2FPageIndex | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt; &lt;/p&gt; 
 &lt;p align="center"&gt;&lt;i&gt;Reasoning-based RAG&amp;nbsp; â—¦ &amp;nbsp;No Vector DB&amp;nbsp; â—¦ &amp;nbsp;No Chunking&amp;nbsp; â—¦ &amp;nbsp;Human-like Retrieval&lt;/i&gt;&lt;/p&gt; 
 &lt;h4 align="center"&gt; &lt;a href="https://vectify.ai"&gt;ğŸ  Homepage&lt;/a&gt;&amp;nbsp; â€¢ &amp;nbsp; &lt;a href="https://chat.pageindex.ai"&gt;ğŸš€ Agent&lt;/a&gt;&amp;nbsp; â€¢ &amp;nbsp; &lt;a href="https://pageindex.ai/mcp"&gt;ğŸ”Œ MCP&lt;/a&gt;&amp;nbsp; â€¢ &amp;nbsp; &lt;a href="https://dash.pageindex.ai"&gt;ğŸ–¥ï¸ Dashboard&lt;/a&gt;&amp;nbsp; â€¢ &amp;nbsp; &lt;a href="https://docs.pageindex.ai/quickstart"&gt;ğŸ“š API&lt;/a&gt;&amp;nbsp; â€¢ &amp;nbsp; &lt;a href="https://discord.com/invite/VuXuf29EUj"&gt;ğŸ’¬ Discord&lt;/a&gt;&amp;nbsp; â€¢ &amp;nbsp; &lt;a href="https://ii2abc2jejf.typeform.com/to/tK3AXl8T"&gt;âœ‰ï¸ Contact&lt;/a&gt;&amp;nbsp; &lt;/h4&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h3&gt;ğŸš¨ &lt;strong&gt;New Releases:&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;ğŸ“‘ &lt;a href="https://chat.pageindex.ai"&gt;PageIndex Chat&lt;/a&gt;: The world's first human-like document analyst agent, designed for professional long documents.&lt;/li&gt; 
 &lt;li&gt;ğŸ”Œ &lt;a href="https://github.com/VectifyAI/pageindex-mcp"&gt;PageIndex MCP&lt;/a&gt;: Bring PageIndex into Claude, Cursor, or any MCP-enabled agents. Chat to long PDFs the human-like, reasoning-based way ğŸ“–&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;ğŸ“„ Introduction to PageIndex&lt;/h1&gt; 
&lt;p&gt;Are you frustrated with vector database retrieval accuracy for long professional documents? Traditional vector-based RAG relies on semantic &lt;em&gt;similarity&lt;/em&gt; rather than true &lt;em&gt;relevance&lt;/em&gt;. But &lt;strong&gt;similarity â‰  relevance&lt;/strong&gt; â€” what we truly need in retrieval is &lt;strong&gt;relevance&lt;/strong&gt;, and that requires &lt;strong&gt;reasoning&lt;/strong&gt;. When working with professional documents that demand domain expertise and multi-step reasoning, similarity search often falls short.&lt;/p&gt; 
&lt;p&gt;Inspired by AlphaGo, we propose &lt;strong&gt;&lt;a href="https://vectify.ai/pageindex"&gt;PageIndex&lt;/a&gt;&lt;/strong&gt;, a &lt;strong&gt;reasoning-based RAG&lt;/strong&gt; system that builds a tree index over long documents and reasons over that index for retrieval. It simulates how &lt;strong&gt;human experts&lt;/strong&gt; navigate and extract knowledge from long documents through &lt;strong&gt;tree search&lt;/strong&gt;, enabling LLMs to &lt;em&gt;think&lt;/em&gt; and &lt;em&gt;reason&lt;/em&gt; their way to the most relevant document sections. It performs retrieval in two steps:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Generate a "Table-of-Contents" &lt;strong&gt;tree structure index&lt;/strong&gt; of documents&lt;/li&gt; 
 &lt;li&gt;Perform reasoning-based retrieval through &lt;strong&gt;tree search&lt;/strong&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://docs.pageindex.ai/images/cookbook/vectorless-rag.png" width="90%" /&gt; 
&lt;/div&gt; 
&lt;h3&gt;ğŸ’¡ Features&lt;/h3&gt; 
&lt;p&gt;Compared to traditional vector-based RAG, PageIndex features:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;No Vectors Needed&lt;/strong&gt;: Uses document structure and LLM reasoning for retrieval.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;No Chunking Needed&lt;/strong&gt;: Documents are organized into natural sections, not artificial chunks.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Human-like Retrieval&lt;/strong&gt;: Simulates how human experts navigate and extract knowledge from complex documents.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Transparent Retrieval Process&lt;/strong&gt;: Retrieval based on reasoning â€” say goodbye to approximate vector search ("vibe retrieval").&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;PageIndex powers a reasoning-based RAG system that achieved &lt;a href="https://github.com/VectifyAI/Mafin2.5-FinanceBench"&gt;98.7% accuracy&lt;/a&gt; on FinanceBench, showing state-of-the-art performance in professional document analysis (see our &lt;a href="https://vectify.ai/blog/Mafin2.5"&gt;blog post&lt;/a&gt; for details).&lt;/p&gt; 
&lt;h3&gt;âš™ï¸ Deployment Options&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;ğŸ› ï¸ Self-host â€” run locally with this open-source repo&lt;/li&gt; 
 &lt;li&gt;â˜ï¸ &lt;strong&gt;&lt;a href="https://dash.pageindex.ai/"&gt;Cloud Service&lt;/a&gt;&lt;/strong&gt; â€” try instantly with our ğŸš€ &lt;a href="https://chat.pageindex.ai/"&gt;Agent&lt;/a&gt;, ğŸ–¥ï¸ &lt;a href="https://dash.pageindex.ai/"&gt;Dashboard&lt;/a&gt; or ğŸ”Œ &lt;a href="https://docs.pageindex.ai/quickstart"&gt;API&lt;/a&gt;, no setup required&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;âš¡ Quick Hands-on&lt;/h3&gt; 
&lt;p&gt;Check out this simple &lt;a href="https://github.com/VectifyAI/PageIndex/raw/main/cookbook/pageindex_RAG_simple.ipynb"&gt;&lt;em&gt;Vectorless RAG Notebook&lt;/em&gt;&lt;/a&gt; â€” a minimal, hands-on, reasoning-based RAG pipeline using &lt;strong&gt;PageIndex&lt;/strong&gt;.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://colab.research.google.com/github/VectifyAI/PageIndex/blob/main/cookbook/pageindex_RAG_simple.ipynb"&gt; &lt;img src="https://img.shields.io/badge/Open_In_Colab-Vectorless_RAG_With_PageIndex-orange?style=for-the-badge&amp;amp;logo=googlecolab" alt="Open in Colab" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;hr /&gt; 
&lt;h1&gt;ğŸ“¦ PageIndex Tree Structure&lt;/h1&gt; 
&lt;p&gt;PageIndex can transform lengthy PDF documents into a semantic &lt;strong&gt;tree structure&lt;/strong&gt;, similar to a &lt;em&gt;"table of contents"&lt;/em&gt; but optimized for use with Large Language Models (LLMs). It's ideal for: financial reports, regulatory filings, academic textbooks, legal or technical manuals, and any document that exceeds LLM context limits.&lt;/p&gt; 
&lt;p&gt;Here is an example output. See more &lt;a href="https://github.com/VectifyAI/PageIndex/tree/main/tests/pdfs"&gt;example documents&lt;/a&gt; and &lt;a href="https://github.com/VectifyAI/PageIndex/tree/main/tests/results"&gt;generated trees&lt;/a&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;...
{
  "title": "Financial Stability",
  "node_id": "0006",
  "start_index": 21,
  "end_index": 22,
  "summary": "The Federal Reserve ...",
  "nodes": [
    {
      "title": "Monitoring Financial Vulnerabilities",
      "node_id": "0007",
      "start_index": 22,
      "end_index": 28,
      "summary": "The Federal Reserve's monitoring ..."
    },
    {
      "title": "Domestic and International Cooperation and Coordination",
      "node_id": "0008",
      "start_index": 28,
      "end_index": 31,
      "summary": "In 2023, the Federal Reserve collaborated ..."
    }
  ]
}
...
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can either generate the PageIndex tree structure with this open-source repo or try our â˜ï¸ &lt;strong&gt;&lt;a href="https://dash.pageindex.ai/"&gt;Cloud Service&lt;/a&gt;&lt;/strong&gt; â€” instantly accessible via our ğŸš€ &lt;a href="https://chat.pageindex.ai/"&gt;Agent&lt;/a&gt;, ğŸ–¥ï¸ &lt;a href="https://dash.pageindex.ai/"&gt;Dashboard&lt;/a&gt; or ğŸ”Œ &lt;a href="https://docs.pageindex.ai/quickstart"&gt;API&lt;/a&gt;, with no setup required.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h1&gt;Package Usage&lt;/h1&gt; 
&lt;p&gt;You can follow these steps to generate a PageIndex tree from a PDF document.&lt;/p&gt; 
&lt;h3&gt;1. Install dependencies&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip3 install --upgrade -r requirements.txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;2. Set your OpenAI API key&lt;/h3&gt; 
&lt;p&gt;Create a &lt;code&gt;.env&lt;/code&gt; file in the root directory and add your API key:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;CHATGPT_API_KEY=your_openai_key_here
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;3. Run PageIndex on your PDF&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python3 run_pageindex.py --pdf_path /path/to/your/document.pdf
&lt;/code&gt;&lt;/pre&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;Optional parameters&lt;/strong&gt;&lt;/summary&gt; 
 &lt;br /&gt; You can customize the processing with additional optional arguments: 
 &lt;pre&gt;&lt;code&gt;--model                 OpenAI model to use (default: gpt-4o-2024-11-20)
--toc-check-pages       Pages to check for table of contents (default: 20)
--max-pages-per-node    Max pages per node (default: 10)
--max-tokens-per-node   Max tokens per node (default: 20000)
--if-add-node-id        Add node ID (yes/no, default: yes)
--if-add-node-summary   Add node summary (yes/no, default: yes)
--if-add-doc-description Add doc description (yes/no, default: yes)
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;Markdown support&lt;/strong&gt;&lt;/summary&gt; 
 &lt;br /&gt; We also provide a markdown support for PageIndex. You can use the `-md` flag to generate a tree structure for a markdown file. 
 &lt;pre&gt;&lt;code class="language-bash"&gt;python3 run_pageindex.py --md_path /path/to/your/document.md
&lt;/code&gt;&lt;/pre&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;Notice: in this function, we use "#" to determine node heading and their levels. For example, "##" is level 2, "###" is level 3, etc. Make sure your markdown file is formatted correctly. If your Markdown file was converted from a PDF or HTML, we donâ€™t recommend using this function, since most existing conversion tools cannot preserve the original hierarchy. Instead, use our &lt;a href="https://pageindex.ai/blog/ocr"&gt;PageIndex OCR&lt;/a&gt;, which is designed to preserve the original hierarchy, to convert the PDF to a markdown file and then use this function.&lt;/p&gt; 
 &lt;/blockquote&gt; 
&lt;/details&gt; 
&lt;hr /&gt; 
&lt;h1&gt;â˜ï¸ Improved Tree Generation with PageIndex OCR&lt;/h1&gt; 
&lt;p&gt;This repo is designed for generating PageIndex tree structure for simple PDFs, but many real-world use cases involve complex PDFs that are hard to parsed by classic python tools. However, extracting high-quality text from PDF documents remains a non-trivial challenge. Most OCR tools only extract page-level content, losing the broader document context and hierarchy.&lt;/p&gt; 
&lt;p&gt;To address this, we introduced PageIndex OCR â€” the first long-context OCR model designed to preserve the global structure of documents. PageIndex OCR significantly outperforms other leading OCR tools, such as those from Mistral and Contextual AI, in recognizing true hierarchy and semantic relationships across document pages.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Experience next-level OCR quality with PageIndex OCR at our &lt;a href="https://dash.pageindex.ai/"&gt;Dashboard&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Integrate seamlessly PageIndex OCR into your stack via our &lt;a href="https://docs.pageindex.ai/quickstart"&gt;API&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p align="center"&gt; &lt;img src="https://github.com/user-attachments/assets/eb35d8ae-865c-4e60-a33b-ebbd00c41732" width="90%" /&gt; &lt;/p&gt; 
&lt;hr /&gt; 
&lt;h1&gt;ğŸ“ˆ Case Study: Mafin 2.5 on FinanceBench&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://vectify.ai/mafin"&gt;Mafin 2.5&lt;/a&gt; is a state-of-the-art reasoning-based RAG model designed specifically for financial document analysis. Powered by &lt;strong&gt;PageIndex&lt;/strong&gt;, it achieved a market-leading &lt;a href="https://vectify.ai/blog/Mafin2.5"&gt;&lt;strong&gt;98.7% accuracy&lt;/strong&gt;&lt;/a&gt; on the &lt;a href="https://arxiv.org/abs/2311.11944"&gt;FinanceBench&lt;/a&gt; benchmark â€” significantly outperforming traditional vector-based RAG systems.&lt;/p&gt; 
&lt;p&gt;PageIndex's hierarchical indexing enabled precise navigation and extraction of relevant content from complex financial reports, such as SEC filings and earnings disclosures.&lt;/p&gt; 
&lt;p&gt;ğŸ‘‰ See the full &lt;a href="https://github.com/VectifyAI/Mafin2.5-FinanceBench"&gt;benchmark results&lt;/a&gt; and our &lt;a href="https://vectify.ai/blog/Mafin2.5"&gt;blog post&lt;/a&gt; for detailed comparisons and performance metrics.&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://github.com/VectifyAI/Mafin2.5-FinanceBench"&gt; &lt;img src="https://github.com/user-attachments/assets/571aa074-d803-43c7-80c4-a04254b782a3" width="90%" /&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h1&gt;ğŸ” Learn More about PageIndex&lt;/h1&gt; 
&lt;h3&gt;Resources &amp;amp; Guides&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;ğŸ“– Explore our &lt;a href="https://docs.pageindex.ai/doc-search"&gt;Tutorials&lt;/a&gt; for practical guides and strategies, including &lt;em&gt;Document Search&lt;/em&gt; and &lt;em&gt;Tree Search&lt;/em&gt;.&lt;/li&gt; 
 &lt;li&gt;ğŸ§ª Browse the &lt;a href="https://docs.pageindex.ai/cookbook/vectorless-rag-pageindex"&gt;Cookbook&lt;/a&gt; for practical recipes and advanced use cases.&lt;/li&gt; 
 &lt;li&gt;âš™ï¸ Refer to the &lt;a href="https://docs.pageindex.ai/quickstart"&gt;API Documentation&lt;/a&gt; for integration details and configuration options.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;â­ Support Us&lt;/h3&gt; 
&lt;p&gt;Leave a star if you like our project. Thank you!&lt;/p&gt; 
&lt;p&gt; &lt;img src="https://github.com/user-attachments/assets/eae4ff38-48ae-4a7c-b19f-eab81201d794" width="60%" /&gt; &lt;/p&gt; 
&lt;h3&gt;Connect with Us&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://x.com/VectifyAI"&gt;&lt;img src="https://img.shields.io/badge/Twitter-000000?style=for-the-badge&amp;amp;logo=x&amp;amp;logoColor=white" alt="Twitter" /&gt;&lt;/a&gt;&amp;nbsp; &lt;a href="https://www.linkedin.com/company/vectify-ai/"&gt;&lt;img src="https://img.shields.io/badge/LinkedIn-0077B5?style=for-the-badge&amp;amp;logo=linkedin&amp;amp;logoColor=white" alt="LinkedIn" /&gt;&lt;/a&gt;&amp;nbsp; &lt;a href="https://discord.com/invite/VuXuf29EUj"&gt;&lt;img src="https://img.shields.io/badge/Discord-5865F2?style=for-the-badge&amp;amp;logo=discord&amp;amp;logoColor=white" alt="Discord" /&gt;&lt;/a&gt;&amp;nbsp; &lt;a href="https://ii2abc2jejf.typeform.com/to/tK3AXl8T"&gt;&lt;img src="https://img.shields.io/badge/Contact_Us-3B82F6?style=for-the-badge&amp;amp;logo=envelope&amp;amp;logoColor=white" alt="Contact Us" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;Â© 2025 &lt;a href="https://vectify.ai"&gt;Vectify AI&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>MetaCubeX/mihomo</title>
      <link>https://github.com/MetaCubeX/mihomo</link>
      <description>&lt;p&gt;A simple Python Pydantic model for Honkai: Star Rail parsed data from the Mihomo API.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;mihomo&lt;/h1&gt; 
&lt;p&gt;A simple python pydantic model (type hint and autocompletion support) for Honkai: Star Rail parsed data from the Mihomo API.&lt;/p&gt; 
&lt;p&gt;API url: &lt;a href="https://api.mihomo.me/sr_info_parsed/%7BUID%7D?lang=%7BLANG%7D"&gt;https://api.mihomo.me/sr_info_parsed/{UID}?lang={LANG}&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;pip install -U git+https://github.com/KT-Yeh/mihomo.git
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;h3&gt;Basic&lt;/h3&gt; 
&lt;p&gt;There are two parsed data formats:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;V1: 
  &lt;ul&gt; 
   &lt;li&gt;URL: &lt;a href="https://api.mihomo.me/sr_info_parsed/800333171?lang=en&amp;amp;version=v1"&gt;https://api.mihomo.me/sr_info_parsed/800333171?lang=en&amp;amp;version=v1&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;Fetching: use &lt;code&gt;client.fetch_user_v1(800333171)&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;Data model: &lt;code&gt;mihomo.models.v1.StarrailInfoParsedV1&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;All models defined in &lt;code&gt;mihomo/models/v1&lt;/code&gt; directory.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;V2: 
  &lt;ul&gt; 
   &lt;li&gt;URL: &lt;a href="https://api.mihomo.me/sr_info_parsed/800333171?lang=en"&gt;https://api.mihomo.me/sr_info_parsed/800333171?lang=en&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;Fetching: use &lt;code&gt;client.fetch_user(800333171)&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;Data model: &lt;code&gt;mihomo.models.StarrailInfoParsed&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;All models defined in &lt;code&gt;mihomo/models&lt;/code&gt; directory.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;If you don't want to use &lt;code&gt;client.get_icon_url&lt;/code&gt; to get the image url everytime, you can use &lt;code&gt;client.fetch_user(800333171, replace_icon_name_with_url=True)&lt;/code&gt; to get the parsed data with asset urls.&lt;/p&gt; 
&lt;h3&gt;Example&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-py"&gt;import asyncio

from mihomo import Language, MihomoAPI
from mihomo.models import StarrailInfoParsed
from mihomo.models.v1 import StarrailInfoParsedV1

client = MihomoAPI(language=Language.EN)


async def v1():
    data: StarrailInfoParsedV1 = await client.fetch_user_v1(800333171)

    print(f"Name: {data.player.name}")
    print(f"Level: {data.player.level}")
    print(f"Signature: {data.player.signature}")
    print(f"Achievements: {data.player_details.achievements}")
    print(f"Characters count: {data.player_details.characters}")
    print(f"Profile picture url: {client.get_icon_url(data.player.icon)}")
    for character in data.characters:
        print("-----------")
        print(f"Name: {character.name}")
        print(f"Rarity: {character.rarity}")
        print(f"Level: {character.level}")
        print(f"Avatar url: {client.get_icon_url(character.icon)}")
        print(f"Preview url: {client.get_icon_url(character.preview)}")
        print(f"Portrait url: {client.get_icon_url(character.portrait)}")


async def v2():
    data: StarrailInfoParsed = await client.fetch_user(800333171, replace_icon_name_with_url=True)

    print(f"Name: {data.player.name}")
    print(f"Level: {data.player.level}")
    print(f"Signature: {data.player.signature}")
    print(f"Profile picture url: {data.player.avatar.icon}")
    for character in data.characters:
        print("-----------")
        print(f"Name: {character.name}")
        print(f"Rarity: {character.rarity}")
        print(f"Portrait url: {character.portrait}")

asyncio.run(v1())
asyncio.run(v2())
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Tools&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;from mihomo import tools&lt;/code&gt;&lt;/p&gt; 
&lt;h4&gt;Remove Duplicate Character&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-py"&gt;    data = await client.fetch_user(800333171)
    data = tools.remove_duplicate_character(data)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Merge Character Data&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-py"&gt;    old_data = await client.fetch_user(800333171)

    # Change characters in game and wait for the API to refresh
    # ...

    new_data = await client.fetch_user(800333171)
    data = tools.merge_character_data(new_data, old_data)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Data Persistence&lt;/h3&gt; 
&lt;p&gt;Take pickle and json as an example&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-py"&gt;import pickle
import zlib
from mihomo import MihomoAPI, Language, StarrailInfoParsed

client = MihomoAPI(language=Language.EN)
data = await client.fetch_user(800333171)

# Save
pickle_data = zlib.compress(pickle.dumps(data))
print(len(pickle_data))
json_data = data.json(by_alias=True, ensure_ascii=False)
print(len(json_data))

# Load
data_from_pickle = pickle.loads(zlib.decompress(pickle_data))
data_from_json = StarrailInfoParsed.parse_raw(json_data)
print(type(data_from_pickle))
print(type(data_from_json))
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>HKUDS/DeepCode</title>
      <link>https://github.com/HKUDS/DeepCode</link>
      <description>&lt;p&gt;"DeepCode: Open Agentic Coding (Paper2Code &amp; Text2Web &amp; Text2Backend)"&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;table style="border: none; margin: 0 auto; padding: 0; border-collapse: collapse;"&gt; 
  &lt;tbody&gt;
   &lt;tr&gt; 
    &lt;td align="center" style="vertical-align: middle; padding: 10px; border: none; width: 250px;"&gt; &lt;img src="https://raw.githubusercontent.com/HKUDS/DeepCode/main/assets/logo.png" alt="DeepCode Logo" width="200" style="margin: 0; padding: 0; display: block;" /&gt; &lt;/td&gt; 
    &lt;td align="left" style="vertical-align: middle; padding: 10px 0 10px 30px; border: none;"&gt; &lt;pre style="font-family: 'Courier New', monospace; font-size: 16px; color: #0EA5E9; margin: 0; padding: 0; text-shadow: 0 0 10px #0EA5E9, 0 0 20px rgba(14,165,233,0.5); line-height: 1.2; transform: skew(-1deg, 0deg); display: block;"&gt;    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—
    â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â•â•â•
    â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—
    â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•  â–ˆâ–ˆâ•”â•â•â•  â–ˆâ–ˆâ•”â•â•â•â• â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•
    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘     â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—
    â•šâ•â•â•â•â•â• â•šâ•â•â•â•â•â•â•â•šâ•â•â•â•â•â•â•â•šâ•â•      â•šâ•â•â•â•â•â• â•šâ•â•â•â•â•â• â•šâ•â•â•â•â•â• â•šâ•â•â•â•â•â•â•&lt;/pre&gt; &lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt;
 &lt;/table&gt; 
 &lt;div align="center"&gt; 
  &lt;a href="https://trendshift.io/repositories/14665" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/14665" alt="HKUDS%2FDeepCode | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt; 
 &lt;/div&gt; 
 &lt;!-- &lt;img src="https://readme-typing-svg.herokuapp.com?font=Russo+One&amp;size=28&amp;duration=2000&amp;pause=800&amp;color=06B6D4&amp;background=00000000&amp;center=true&amp;vCenter=true&amp;width=800&amp;height=50&amp;lines=%E2%9A%A1+OPEN+AGENTIC+CODING+%E2%9A%A1" alt="DeepCode Tech Subtitle" style="margin-top: 5px; filter: drop-shadow(0 0 12px #06B6D4) drop-shadow(0 0 24px rgba(6,182,212,0.4));"/&gt; --&gt; 
 &lt;h1&gt;&lt;img src="https://github.com/Zongwei9888/Experiment_Images/raw/43c585dca3d21b8e4b6390d835cdd34dc4b4b23d/DeepCode_images/title_logo.svg?sanitize=true" alt="DeepCode Logo" width="32" height="32" style="vertical-align: middle; margin-right: 8px;" /&gt; DeepCode: Open Agentic Coding&lt;/h1&gt; 
 &lt;h3&gt;&lt;em&gt;Advancing Code Generation with Multi-Agent Systems&lt;/em&gt;&lt;/h3&gt; 
 &lt;!-- &lt;p align="center"&gt;
  &lt;img src="https://img.shields.io/badge/Version-1.0.0-00d4ff?style=for-the-badge&amp;logo=rocket&amp;logoColor=white" alt="Version"&gt;

  &lt;img src="https://img.shields.io/badge/License-MIT-4ecdc4?style=for-the-badge&amp;logo=opensourceinitiative&amp;logoColor=white" alt="License"&gt;
  &lt;img src="https://img.shields.io/badge/AI-Multi--Agent-9b59b6?style=for-the-badge&amp;logo=brain&amp;logoColor=white" alt="AI"&gt;
  &lt;img src="https://img.shields.io/badge/HKU-Data_Intelligence_Lab-f39c12?style=for-the-badge&amp;logo=university&amp;logoColor=white" alt="HKU"&gt;
&lt;/p&gt; --&gt; 
 &lt;p&gt; &lt;a href="https://github.com/HKUDS/DeepCode/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/HKUDS/DeepCode?color=00d9ff&amp;amp;style=for-the-badge&amp;amp;logo=star&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/badge/ğŸPython-3.13-4ecdc4?style=for-the-badge&amp;amp;logo=python&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt; &lt;a href="https://pypi.org/project/deepcode-hku/"&gt;&lt;img src="https://img.shields.io/pypi/v/deepcode-hku.svg?style=for-the-badge&amp;amp;logo=pypi&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e&amp;amp;color=ff6b6b" /&gt;&lt;/a&gt; &lt;/p&gt; 
 &lt;p&gt; &lt;a href="https://discord.gg/yF2MmDJyGJ"&gt;&lt;img src="https://img.shields.io/badge/ğŸ’¬Discord-Community-7289da?style=for-the-badge&amp;amp;logo=discord&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt;&lt;/a&gt; &lt;a href="https://github.com/HKUDS/DeepCode/issues/11"&gt;&lt;img src="https://img.shields.io/badge/ğŸ’¬WeChat-Group-07c160?style=for-the-badge&amp;amp;logo=wechat&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt;&lt;/a&gt; &lt;/p&gt; 
 &lt;div align="center"&gt; 
  &lt;div style="width: 100%; height: 2px; margin: 20px 0; background: linear-gradient(90deg, transparent, #00d9ff, transparent);"&gt;&lt;/div&gt; 
 &lt;/div&gt; 
 &lt;div align="center"&gt; 
  &lt;a href="https://raw.githubusercontent.com/HKUDS/DeepCode/main/#-quick-start" style="text-decoration: none;"&gt; &lt;img src="https://img.shields.io/badge/Quick%20Start-Get%20Started%20Now-00d9ff?style=for-the-badge&amp;amp;logo=rocket&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt; &lt;/a&gt; 
 &lt;/div&gt; 
 &lt;div align="center" style="margin-top: 10px;"&gt; 
  &lt;a href="https://raw.githubusercontent.com/HKUDS/DeepCode/main/README.md"&gt; &lt;img src="https://img.shields.io/badge/English-00d4ff?style=for-the-badge&amp;amp;logo=readme&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" alt="English" /&gt; &lt;/a&gt; 
  &lt;a href="https://raw.githubusercontent.com/HKUDS/DeepCode/main/README_ZH.md"&gt; &lt;img src="https://img.shields.io/badge/ä¸­æ–‡-00d4ff?style=for-the-badge&amp;amp;logo=readme&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" alt="ä¸­æ–‡" /&gt; &lt;/a&gt; 
 &lt;/div&gt; 
 &lt;h3&gt;ğŸ–¥ï¸ &lt;strong&gt;Interface Showcase&lt;/strong&gt;&lt;/h3&gt; 
 &lt;table align="center" width="100%" style="border: none; border-collapse: collapse; margin: 30px 0;"&gt; 
  &lt;tbody&gt;
   &lt;tr&gt; 
    &lt;td width="50%" align="center" style="vertical-align: top; padding: 20px;"&gt; &lt;h4&gt;ğŸ–¥ï¸ &lt;strong&gt;CLI Interface&lt;/strong&gt;&lt;/h4&gt; &lt;p&gt;&lt;strong&gt;Terminal-Based Development&lt;/strong&gt;&lt;/p&gt; 
     &lt;div align="center"&gt; 
      &lt;img src="https://github.com/Zongwei9888/Experiment_Images/raw/8882a7313c504ca97ead6e7b36c51aa761b6a4f3/DeepCode_images/CLI.gif" alt="CLI Interface Demo" width="100%" style="border-radius: 10px; box-shadow: 0 8px 20px rgba(45,55,72,0.3); margin: 15px 0;" /&gt; 
      &lt;div style="background: linear-gradient(135deg, #2D3748 0%, #4A5568 100%); border-radius: 12px; padding: 15px; margin: 15px 0; color: white;"&gt; 
       &lt;strong&gt;ğŸš€ Advanced Terminal Experience&lt;/strong&gt;
       &lt;br /&gt; 
       &lt;small&gt;âš¡ Fast command-line workflow&lt;br /&gt;ğŸ”§ Developer-friendly interface&lt;br /&gt;ğŸ“Š Real-time progress tracking&lt;/small&gt; 
      &lt;/div&gt; 
      &lt;p&gt;&lt;em&gt;Professional terminal interface for advanced users and CI/CD integration&lt;/em&gt;&lt;/p&gt; 
     &lt;/div&gt; &lt;/td&gt; 
    &lt;td width="50%" align="center" style="vertical-align: top; padding: 20px;"&gt; &lt;h4&gt;ğŸŒ &lt;strong&gt;Web Interface&lt;/strong&gt;&lt;/h4&gt; &lt;p&gt;&lt;strong&gt;Visual Interactive Experience&lt;/strong&gt;&lt;/p&gt; 
     &lt;div align="center"&gt; 
      &lt;img src="https://github.com/Zongwei9888/Experiment_Images/raw/8882a7313c504ca97ead6e7b36c51aa761b6a4f3/DeepCode_images/UI.gif" alt="Web Interface Demo" width="100%" style="border-radius: 10px; box-shadow: 0 8px 20px rgba(14,165,233,0.3); margin: 15px 0;" /&gt; 
      &lt;div style="background: linear-gradient(135deg, #0EA5E9 0%, #00D4FF 100%); border-radius: 12px; padding: 15px; margin: 15px 0; color: white;"&gt; 
       &lt;strong&gt;ğŸ¨ Modern Web Dashboard&lt;/strong&gt;
       &lt;br /&gt; 
       &lt;small&gt;ğŸ–±ï¸ Intuitive drag-and-drop&lt;br /&gt;ğŸ“± Responsive design&lt;br /&gt;ğŸ¯ Visual progress tracking&lt;/small&gt; 
      &lt;/div&gt; 
      &lt;p&gt;&lt;em&gt;Beautiful web interface with streamlined workflow for all skill levels&lt;/em&gt;&lt;/p&gt; 
     &lt;/div&gt; &lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt;
 &lt;/table&gt; 
 &lt;hr /&gt; 
 &lt;div align="center"&gt; 
  &lt;h3&gt;ğŸ¬ &lt;strong&gt;Introduction Video&lt;/strong&gt;&lt;/h3&gt; 
  &lt;div style="margin: 20px 0;"&gt; 
   &lt;a href="https://youtu.be/PRgmP8pOI08" target="_blank"&gt; &lt;img src="https://img.youtube.com/vi/PRgmP8pOI08/maxresdefault.jpg" alt="DeepCode Introduction Video" width="75%" style="border-radius: 12px; box-shadow: 0 8px 25px rgba(0,0,0,0.15); transition: transform 0.3s ease;" /&gt; &lt;/a&gt; 
  &lt;/div&gt; 
  &lt;p&gt;&lt;em&gt;ğŸ¯ &lt;strong&gt;Watch our complete introduction&lt;/strong&gt; - See how DeepCode transforms research papers and natural language into production-ready code&lt;/em&gt;&lt;/p&gt; 
  &lt;p&gt; &lt;a href="https://youtu.be/PRgmP8pOI08" target="_blank"&gt; &lt;img src="https://img.shields.io/badge/â–¶ï¸_Watch_Video-FF0000?style=for-the-badge&amp;amp;logo=youtube&amp;amp;logoColor=white" alt="Watch Video" /&gt; &lt;/a&gt; &lt;/p&gt; 
 &lt;/div&gt; 
 &lt;hr /&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;&lt;em&gt;"Where AI Agents Transform Ideas into Production-Ready Code"&lt;/em&gt;&lt;/p&gt; 
 &lt;/blockquote&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ğŸ“‘ Table of Contents&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/DeepCode/main/#-news"&gt;ğŸ“° News&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/DeepCode/main/#-key-features"&gt;ğŸš€ Key Features&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/DeepCode/main/#%EF%B8%8F-architecture"&gt;ğŸ—ï¸ Architecture&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/DeepCode/main/#-experimental-results"&gt;ğŸ“Š Experimental Results&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/DeepCode/main/#-quick-start"&gt;ğŸš€ Quick Start&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/DeepCode/main/#-examples"&gt;ğŸ’¡ Examples&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/DeepCode/main/#-live-demonstrations"&gt;ğŸ¬ Live Demonstrations&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/DeepCode/main/#-star-history"&gt;â­ Star History&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/DeepCode/main/#-license"&gt;ğŸ“„ License&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ğŸ“° News&lt;/h2&gt; 
&lt;p&gt;ğŸ‰ &lt;strong&gt;[2025-10] ğŸ‰ [2025-10-28] DeepCode Achieves SOTA on PaperBench!&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;DeepCode sets new benchmarks on OpenAI's PaperBench Code-Dev across all categories:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;ğŸ† &lt;strong&gt;Surpasses Human Experts&lt;/strong&gt;: &lt;strong&gt;75.9%&lt;/strong&gt; (DeepCode) vs Top Machine Learning PhDs 72.4% (+3.5%).&lt;/li&gt; 
 &lt;li&gt;ğŸ¥‡ &lt;strong&gt;Outperforms SOTA Commercial Code Agents&lt;/strong&gt;: &lt;strong&gt;84.8%&lt;/strong&gt; (DeepCode) vs Leading Commercial Code Agents (+26.1%) (Cursor, Claude Code, and Codex).&lt;/li&gt; 
 &lt;li&gt;ğŸ”¬ &lt;strong&gt;Advances Scientific Coding&lt;/strong&gt;: &lt;strong&gt;73.5%&lt;/strong&gt; (DeepCode) vs PaperCoder 51.1% (+22.4%).&lt;/li&gt; 
 &lt;li&gt;ğŸš€ &lt;strong&gt;Beats LLM Agents&lt;/strong&gt;: &lt;strong&gt;73.5%&lt;/strong&gt; (DeepCode) vs best LLM frameworks 43.3% (+30.2%).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ğŸš€ Key Features&lt;/h2&gt; 
&lt;br /&gt; 
&lt;table align="center" width="100%" style="border: none; table-layout: fixed;"&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td width="30%" align="center" style="vertical-align: top; padding: 20px;"&gt; 
    &lt;div style="height: 80px; display: flex; align-items: center; justify-content: center;"&gt; 
     &lt;h3 style="margin: 0; padding: 0;"&gt;ğŸš€ &lt;strong&gt;Paper2Code&lt;/strong&gt;&lt;/h3&gt; 
    &lt;/div&gt; 
    &lt;div align="center" style="margin: 15px 0;"&gt; 
     &lt;img src="https://img.shields.io/badge/ALGORITHM-IMPLEMENTATION-ff6b6b?style=for-the-badge&amp;amp;logo=algorithm&amp;amp;logoColor=white" alt="Algorithm Badge" /&gt; 
    &lt;/div&gt; 
    &lt;div style="height: 80px; display: flex; align-items: center; justify-content: center;"&gt; 
     &lt;p align="center"&gt;&lt;strong&gt;Automated Implementation of Complex Algorithms&lt;/strong&gt;&lt;/p&gt; 
    &lt;/div&gt; 
    &lt;div style="height: 60px; display: flex; align-items: center; justify-content: center;"&gt; 
     &lt;p align="center"&gt;Effortlessly converts complex algorithms from research papers into &lt;strong&gt;high-quality&lt;/strong&gt;, &lt;strong&gt;production-ready&lt;/strong&gt; code, accelerating algorithm reproduction.&lt;/p&gt; 
    &lt;/div&gt; &lt;/td&gt; 
   &lt;td width="30%" align="center" style="vertical-align: top; padding: 20px;"&gt; 
    &lt;div style="height: 80px; display: flex; align-items: center; justify-content: center;"&gt; 
     &lt;h3 style="margin: 0; padding: 0;"&gt;ğŸ¨ &lt;strong&gt;Text2Web&lt;/strong&gt;&lt;/h3&gt; 
    &lt;/div&gt; 
    &lt;div align="center" style="margin: 15px 0;"&gt; 
     &lt;img src="https://img.shields.io/badge/FRONTEND-DEVELOPMENT-4ecdc4?style=for-the-badge&amp;amp;logo=react&amp;amp;logoColor=white" alt="Frontend Badge" /&gt; 
    &lt;/div&gt; 
    &lt;div style="height: 80px; display: flex; align-items: center; justify-content: center;"&gt; 
     &lt;p align="center"&gt;&lt;strong&gt;Automated Front-End Web Development&lt;/strong&gt;&lt;/p&gt; 
    &lt;/div&gt; 
    &lt;div style="height: 60px; display: flex; align-items: center; justify-content: center;"&gt; 
     &lt;p align="center"&gt;Translates plain textual descriptions into &lt;strong&gt;fully functional&lt;/strong&gt;, &lt;strong&gt;visually appealing&lt;/strong&gt; front-end web code for rapid interface creation.&lt;/p&gt; 
    &lt;/div&gt; &lt;/td&gt; 
   &lt;td width="30%" align="center" style="vertical-align: top; padding: 20px;"&gt; 
    &lt;div style="height: 80px; display: flex; align-items: center; justify-content: center;"&gt; 
     &lt;h3 style="margin: 0; padding: 0;"&gt;âš™ï¸ &lt;strong&gt;Text2Backend&lt;/strong&gt;&lt;/h3&gt; 
    &lt;/div&gt; 
    &lt;div align="center" style="margin: 15px 0;"&gt; 
     &lt;img src="https://img.shields.io/badge/BACKEND-DEVELOPMENT-9b59b6?style=for-the-badge&amp;amp;logo=server&amp;amp;logoColor=white" alt="Backend Badge" /&gt; 
    &lt;/div&gt; 
    &lt;div style="height: 80px; display: flex; align-items: center; justify-content: center;"&gt; 
     &lt;p align="center"&gt;&lt;strong&gt;Automated Back-End Development&lt;/strong&gt;&lt;/p&gt; 
    &lt;/div&gt; 
    &lt;div style="height: 60px; display: flex; align-items: center; justify-content: center;"&gt; 
     &lt;p align="center"&gt;Generates &lt;strong&gt;efficient&lt;/strong&gt;, &lt;strong&gt;scalable&lt;/strong&gt;, and &lt;strong&gt;feature-rich&lt;/strong&gt; back-end code from simple text inputs, streamlining server-side development.&lt;/p&gt; 
    &lt;/div&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;br /&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ğŸ“Š Experimental Results&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/HKUDS/DeepCode/main/assets/result_main02.jpg" /&gt;
 &lt;br /&gt; 
&lt;/div&gt; 
&lt;br /&gt; 
&lt;p&gt;We evaluate &lt;strong&gt;DeepCode&lt;/strong&gt; on the &lt;a href="https://openai.com/index/paperbench/"&gt;&lt;em&gt;PaperBench&lt;/em&gt;&lt;/a&gt; benchmark (released by OpenAI), a rigorous testbed requiring AI agents to independently reproduce 20 ICML 2024 papers from scratch. The benchmark comprises 8,316 gradable components assessed using SimpleJudge with hierarchical weighting.&lt;/p&gt; 
&lt;p&gt;Our experiments compare DeepCode against four baseline categories: &lt;strong&gt;(1) Human Experts&lt;/strong&gt;, &lt;strong&gt;(2) State-of-the-Art Commercial Code Agents&lt;/strong&gt;, &lt;strong&gt;(3) Scientific Code Agents&lt;/strong&gt;, and &lt;strong&gt;(4) LLM-Based Agents&lt;/strong&gt;.&lt;/p&gt; 
&lt;h3&gt;â‘  ğŸ§  Human Expert Performance (Top Machine Learning PhD)&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;DeepCode: 75.9% vs. Top Machine Learning PhD: 72.4% (+3.5%)&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;DeepCode achieves &lt;strong&gt;75.9%&lt;/strong&gt; on the 3-paper human evaluation subset, &lt;strong&gt;surpassing the best-of-3 human expert baseline (72.4%) by +3.5 percentage points&lt;/strong&gt;. This demonstrates that our framework not only matches but exceeds expert-level code reproduction capabilities, representing a significant milestone in autonomous scientific software engineering.&lt;/p&gt; 
&lt;h3&gt;â‘¡ ğŸ’¼ State-of-the-Art Commercial Code Agents&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;DeepCode: 84.8% vs. Best Commercial Agent: 58.7% (+26.1%)&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;On the 5-paper subset, DeepCode substantially outperforms leading commercial coding tools:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Cursor: 58.4%&lt;/li&gt; 
 &lt;li&gt;Claude Code: 58.7%&lt;/li&gt; 
 &lt;li&gt;Codex: 40.0%&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;DeepCode: 84.8%&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;This represents a &lt;strong&gt;+26.1% improvement&lt;/strong&gt; over the leading commercial code agent. All commercial agents utilize Claude Sonnet 4.5 or GPT-5 Codex-high, highlighting that &lt;strong&gt;DeepCode's superior architecture&lt;/strong&gt;â€”rather than base model capabilityâ€”drives this performance gap.&lt;/p&gt; 
&lt;h3&gt;â‘¢ ğŸ”¬ Scientific Code Agents&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;DeepCode: 73.5% vs. PaperCoder: 51.1% (+22.4%)&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Compared to PaperCoder (&lt;strong&gt;51.1%&lt;/strong&gt;), the state-of-the-art scientific code reproduction framework, DeepCode achieves &lt;strong&gt;73.5%&lt;/strong&gt;, demonstrating a &lt;strong&gt;+22.4% relative improvement&lt;/strong&gt;. This substantial margin validates our multi-module architecture combining planning, hierarchical task decomposition, code generation, and iterative debugging over simpler pipeline-based approaches.&lt;/p&gt; 
&lt;h3&gt;â‘£ ğŸ¤– LLM-Based Agents&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;DeepCode: 73.5% vs. Best LLM Agent: 43.3% (+30.2%)&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;DeepCode significantly outperforms all tested LLM agents:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Claude 3.5 Sonnet + IterativeAgent: 27.5%&lt;/li&gt; 
 &lt;li&gt;o1 + IterativeAgent (36 hours): 42.4%&lt;/li&gt; 
 &lt;li&gt;o1 BasicAgent: 43.3%&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;DeepCode: 73.5%&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The &lt;strong&gt;+30.2% improvement&lt;/strong&gt; over the best-performing LLM agent demonstrates that sophisticated agent scaffolding, rather than extended inference time or larger models, is critical for complex code reproduction tasks.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h3&gt;ğŸ¯ &lt;strong&gt;Autonomous Self-Orchestrating Multi-Agent Architecture&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;The Challenges&lt;/strong&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;ğŸ“„ &lt;strong&gt;Implementation Complexity&lt;/strong&gt;: Converting academic papers and complex algorithms into working code requires significant technical effort and domain expertise&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;ğŸ”¬ &lt;strong&gt;Research Bottleneck&lt;/strong&gt;: Researchers spend valuable time implementing algorithms instead of focusing on their core research and discovery work&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;â±ï¸ &lt;strong&gt;Development Delays&lt;/strong&gt;: Product teams experience long wait times between concept and testable prototypes, slowing down innovation cycles&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;ğŸ”„ &lt;strong&gt;Repetitive Coding&lt;/strong&gt;: Developers repeatedly implement similar patterns and functionality instead of building on existing solutions&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;DeepCode&lt;/strong&gt; addresses these workflow inefficiencies by providing reliable automation for common development tasks, streamlining your development workflow from concept to code.&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;pre&gt;&lt;code class="language-mermaid"&gt;flowchart LR
    A["ğŸ“„ Research Papers&amp;lt;br/&amp;gt;ğŸ’¬ Text Prompts&amp;lt;br/&amp;gt;ğŸŒ URLs &amp;amp; Document&amp;lt;br/&amp;gt;ğŸ“ Files: PDF, DOC, PPTX, TXT, HTML"] --&amp;gt; B["ğŸ§  DeepCode&amp;lt;br/&amp;gt;Multi-Agent Engine"]
    B --&amp;gt; C["ğŸš€ Algorithm Implementation &amp;lt;br/&amp;gt;ğŸ¨ Frontend Development &amp;lt;br/&amp;gt;âš™ï¸ Backend Development"]

    style A fill:#ff6b6b,stroke:#c0392b,stroke-width:2px,color:#000
    style B fill:#00d4ff,stroke:#0984e3,stroke-width:3px,color:#000
    style C fill:#00b894,stroke:#00a085,stroke-width:2px,color:#000
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ğŸ—ï¸ Architecture&lt;/h2&gt; 
&lt;h3&gt;ğŸ“Š &lt;strong&gt;System Overview&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;DeepCode&lt;/strong&gt; is an AI-powered development platform that automates code generation and implementation tasks. Our multi-agent system handles the complexity of translating requirements into functional, well-structured code, allowing you to focus on innovation rather than implementation details.&lt;/p&gt; 
&lt;p&gt;ğŸ¯ &lt;strong&gt;Technical Capabilities&lt;/strong&gt;:&lt;/p&gt; 
&lt;p&gt;ğŸ§¬ &lt;strong&gt;Research-to-Production Pipeline&lt;/strong&gt;&lt;br /&gt; Multi-modal document analysis engine that extracts algorithmic logic and mathematical models from academic papers. Generates optimized implementations with proper data structures while preserving computational complexity characteristics.&lt;/p&gt; 
&lt;p&gt;ğŸª„ &lt;strong&gt;Natural Language Code Synthesis&lt;/strong&gt;&lt;br /&gt; Context-aware code generation using fine-tuned language models trained on curated code repositories. Maintains architectural consistency across modules while supporting multiple programming languages and frameworks.&lt;/p&gt; 
&lt;p&gt;âš¡ &lt;strong&gt;Automated Prototyping Engine&lt;/strong&gt;&lt;br /&gt; Intelligent scaffolding system generating complete application structures including database schemas, API endpoints, and frontend components. Uses dependency analysis to ensure scalable architecture from initial generation.&lt;/p&gt; 
&lt;p&gt;ğŸ’ &lt;strong&gt;Quality Assurance Automation&lt;/strong&gt;&lt;br /&gt; Integrated static analysis with automated unit test generation and documentation synthesis. Employs AST analysis for code correctness and property-based testing for comprehensive coverage.&lt;/p&gt; 
&lt;p&gt;ğŸ”® &lt;strong&gt;CodeRAG Integration System&lt;/strong&gt;&lt;br /&gt; Advanced retrieval-augmented generation combining semantic vector embeddings with graph-based dependency analysis. Automatically discovers optimal libraries and implementation patterns from large-scale code corpus.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h3&gt;ğŸ”§ &lt;strong&gt;Core Techniques&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;ğŸ§  &lt;strong&gt;Intelligent Orchestration Agent&lt;/strong&gt;: Central decision-making system that coordinates workflow phases and analyzes requirements. Employs dynamic planning algorithms to adapt execution strategies in real-time based on evolving project complexity. Dynamically selects optimal processing strategies for each implementation step. &lt;br /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;ğŸ’¾ &lt;strong&gt;Efficient Memory Mechanism&lt;/strong&gt;: Advanced context engineering system that manages large-scale code contexts efficiently. Implements hierarchical memory structures with intelligent compression for handling complex codebases. This component enables instant retrieval of implementation patterns and maintains semantic coherence across extended development sessions. &lt;br /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;ğŸ” &lt;strong&gt;Advanced CodeRAG System&lt;/strong&gt;: Global code comprehension engine that analyzes complex inter-dependencies across repositories. Performs cross-codebase relationship mapping to understand architectural patterns from a holistic perspective. This module leverages dependency graphs and semantic analysis to provide globally-aware code recommendations during implementation.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h3&gt;ğŸ¤– &lt;strong&gt;Multi-Agent Architecture of DeepCode&lt;/strong&gt;:&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;ğŸ¯ Central Orchestrating Agent&lt;/strong&gt;: Orchestrates entire workflow execution and makes strategic decisions. Coordinates specialized agents based on input complexity analysis. Implements dynamic task planning and resource allocation algorithms. &lt;br /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;ğŸ“ Intent Understanding Agent&lt;/strong&gt;: Performs deep semantic analysis of user requirements to decode complex intentions. Extracts functional specifications and technical constraints through advanced NLP processing. Transforms ambiguous human descriptions into precise, actionable development specifications with structured task decomposition. &lt;br /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;ğŸ“„ Document Parsing Agent&lt;/strong&gt;: Processes complex technical documents and research papers with advanced parsing capabilities. Extracts algorithms and methodologies using document understanding models. Converts academic concepts into practical implementation specifications through intelligent content analysis. &lt;br /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;ğŸ—ï¸ Code Planning Agent&lt;/strong&gt;: Performs architectural design and technology stack optimization. Dynamic planning for adaptive development roadmaps. Enforces coding standards and generates modular structures through automated design pattern selection.&lt;br /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;ğŸ” Code Reference Mining Agent&lt;/strong&gt;: Discovers relevant repositories and frameworks through intelligent search algorithms. Analyzes codebases for compatibility and integration potential. Provides recommendations based on similarity metrics and automated dependency analysis. &lt;br /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;ğŸ“š Code Indexing Agent&lt;/strong&gt;: Builds comprehensive knowledge graphs of discovered codebases. Maintains semantic relationships between code components. Enables intelligent retrieval and cross-reference capabilities. &lt;br /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;ğŸ§¬ Code Generation Agent&lt;/strong&gt;: Synthesizes gathered information into executable code implementations. Creates functional interfaces and integrates discovered components. Generates comprehensive test suites and documentation for reproducibility.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h4&gt;ğŸ› ï¸ &lt;strong&gt;Implementation Tools Matrix&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;&lt;strong&gt;ğŸ”§ Powered by MCP (Model Context Protocol)&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;DeepCode leverages the &lt;strong&gt;Model Context Protocol (MCP)&lt;/strong&gt; standard to seamlessly integrate with various tools and services. This standardized approach ensures reliable communication between AI agents and external systems, enabling powerful automation capabilities.&lt;/p&gt; 
&lt;h5&gt;ğŸ“¡ &lt;strong&gt;MCP Servers &amp;amp; Tools&lt;/strong&gt;&lt;/h5&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;ğŸ› ï¸ &lt;strong&gt;MCP Server&lt;/strong&gt;&lt;/th&gt; 
   &lt;th&gt;ğŸ”§ &lt;strong&gt;Primary Function&lt;/strong&gt;&lt;/th&gt; 
   &lt;th&gt;ğŸ’¡ &lt;strong&gt;Purpose &amp;amp; Capabilities&lt;/strong&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;ğŸ” brave&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Web Search Engine&lt;/td&gt; 
   &lt;td&gt;Real-time information retrieval via Brave Search API&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;ğŸŒ bocha-mcp&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Alternative Search&lt;/td&gt; 
   &lt;td&gt;Secondary search option with independent API access&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;ğŸ“‚ filesystem&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;File System Operations&lt;/td&gt; 
   &lt;td&gt;Local file and directory management, read/write operations&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;ğŸŒ fetch&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Web Content Retrieval&lt;/td&gt; 
   &lt;td&gt;Fetch and extract content from URLs and web resources&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;ğŸ“¥ github-downloader&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Repository Management&lt;/td&gt; 
   &lt;td&gt;Clone and download GitHub repositories for analysis&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;ğŸ“‹ file-downloader&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Document Processing&lt;/td&gt; 
   &lt;td&gt;Download and convert files (PDF, DOCX, etc.) to Markdown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;âš¡ command-executor&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;System Commands&lt;/td&gt; 
   &lt;td&gt;Execute bash/shell commands for environment management&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;ğŸ§¬ code-implementation&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Code Generation Hub&lt;/td&gt; 
   &lt;td&gt;Comprehensive code reproduction with execution and testing&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;ğŸ“š code-reference-indexer&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Smart Code Search&lt;/td&gt; 
   &lt;td&gt;Intelligent indexing and search of code repositories&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;ğŸ“„ document-segmentation&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Smart Document Analysis&lt;/td&gt; 
   &lt;td&gt;Intelligent document segmentation for large papers and technical documents&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h5&gt;ğŸ”§ &lt;strong&gt;Legacy Tool Functions&lt;/strong&gt; &lt;em&gt;(for reference)&lt;/em&gt;&lt;/h5&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;ğŸ› ï¸ &lt;strong&gt;Function&lt;/strong&gt;&lt;/th&gt; 
   &lt;th&gt;ğŸ¯ &lt;strong&gt;Usage Context&lt;/strong&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;ğŸ“„ read_code_mem&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Efficient code context retrieval from memory&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;âœï¸ write_file&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Direct file content generation and modification&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;ğŸ execute_python&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Python code testing and validation&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;ğŸ“ get_file_structure&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Project structure analysis and organization&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;âš™ï¸ set_workspace&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Dynamic workspace and environment configuration&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;ğŸ“Š get_operation_history&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Process monitoring and operation tracking&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;hr /&gt; 
&lt;p&gt;ğŸ›ï¸ &lt;strong&gt;Multi-Interface Framework&lt;/strong&gt;&lt;br /&gt; RESTful API with CLI and web frontends featuring real-time code streaming, interactive debugging, and extensible plugin architecture for CI/CD integration.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;ğŸš€ Multi-Agent Intelligent Pipeline:&lt;/strong&gt;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;h3&gt;ğŸŒŸ &lt;strong&gt;Intelligence Processing Flow&lt;/strong&gt;&lt;/h3&gt; 
 &lt;table align="center" width="100%" style="border: none; border-collapse: collapse;"&gt; 
  &lt;tbody&gt;
   &lt;tr&gt; 
    &lt;td colspan="3" align="center" style="padding: 20px; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); border-radius: 15px; color: white; font-weight: bold;"&gt; ğŸ’¡ &lt;strong&gt;INPUT LAYER&lt;/strong&gt;&lt;br /&gt; ğŸ“„ Research Papers â€¢ ğŸ’¬ Natural Language â€¢ ğŸŒ URLs â€¢ ğŸ“‹ Requirements &lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt;
    &lt;td colspan="3" height="20"&gt;&lt;/td&gt;
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td colspan="3" align="center" style="padding: 15px; background: linear-gradient(135deg, #ff6b6b 0%, #ee5a24 100%); border-radius: 12px; color: white; font-weight: bold;"&gt; ğŸ¯ &lt;strong&gt;CENTRAL ORCHESTRATION&lt;/strong&gt;&lt;br /&gt; Strategic Decision Making â€¢ Workflow Coordination â€¢ Agent Management &lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt;
    &lt;td colspan="3" height="15"&gt;&lt;/td&gt;
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center" style="padding: 12px; background: linear-gradient(135deg, #3742fa 0%, #2f3542 100%); border-radius: 10px; color: white; width: 50%;"&gt; ğŸ“ &lt;strong&gt;TEXT ANALYSIS&lt;/strong&gt;&lt;br /&gt; &lt;small&gt;Requirement Processing&lt;/small&gt; &lt;/td&gt; 
    &lt;td width="10"&gt;&lt;/td&gt; 
    &lt;td align="center" style="padding: 12px; background: linear-gradient(135deg, #8c7ae6 0%, #9c88ff 100%); border-radius: 10px; color: white; width: 50%;"&gt; ğŸ“„ &lt;strong&gt;DOCUMENT ANALYSIS&lt;/strong&gt;&lt;br /&gt; &lt;small&gt;Paper &amp;amp; Spec Processing&lt;/small&gt; &lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt;
    &lt;td colspan="3" height="15"&gt;&lt;/td&gt;
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td colspan="3" align="center" style="padding: 15px; background: linear-gradient(135deg, #00d2d3 0%, #54a0ff 100%); border-radius: 12px; color: white; font-weight: bold;"&gt; ğŸ“‹ &lt;strong&gt;REPRODUCTION PLANNING&lt;/strong&gt;&lt;br /&gt; Deep Paper Analysis â€¢ Code Requirements Parsing â€¢ Reproduction Strategy Development &lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt;
    &lt;td colspan="3" height="15"&gt;&lt;/td&gt;
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center" style="padding: 12px; background: linear-gradient(135deg, #ffa726 0%, #ff7043 100%); border-radius: 10px; color: white; width: 50%;"&gt; ğŸ” &lt;strong&gt;REFERENCE ANALYSIS&lt;/strong&gt;&lt;br /&gt; &lt;small&gt;Repository Discovery&lt;/small&gt; &lt;/td&gt; 
    &lt;td width="10"&gt;&lt;/td&gt; 
    &lt;td align="center" style="padding: 12px; background: linear-gradient(135deg, #e056fd 0%, #f368e0 100%); border-radius: 10px; color: white; width: 50%;"&gt; ğŸ“š &lt;strong&gt;CODE INDEXING&lt;/strong&gt;&lt;br /&gt; &lt;small&gt;Knowledge Graph Building&lt;/small&gt; &lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt;
    &lt;td colspan="3" height="15"&gt;&lt;/td&gt;
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td colspan="3" align="center" style="padding: 15px; background: linear-gradient(135deg, #26de81 0%, #20bf6b 100%); border-radius: 12px; color: white; font-weight: bold;"&gt; ğŸ§¬ &lt;strong&gt;CODE IMPLEMENTATION&lt;/strong&gt;&lt;br /&gt; Implementation Generation â€¢ Testing â€¢ Documentation &lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt;
    &lt;td colspan="3" height="15"&gt;&lt;/td&gt;
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td colspan="3" align="center" style="padding: 20px; background: linear-gradient(135deg, #045de9 0%, #09c6f9 100%); border-radius: 15px; color: white; font-weight: bold;"&gt; âš¡ &lt;strong&gt;OUTPUT DELIVERY&lt;/strong&gt;&lt;br /&gt; ğŸ“¦ Complete Codebase â€¢ ğŸ§ª Test Suite â€¢ ğŸ“š Documentation â€¢ ğŸš€ Deployment Ready &lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt;
 &lt;/table&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;br /&gt; 
 &lt;h3&gt;ğŸ”„ &lt;strong&gt;Process Intelligence Features&lt;/strong&gt;&lt;/h3&gt; 
 &lt;table align="center" style="border: none;"&gt; 
  &lt;tbody&gt;
   &lt;tr&gt; 
    &lt;td align="center" width="25%" style="padding: 15px;"&gt; 
     &lt;div style="background: #f8f9fa; border-radius: 10px; padding: 15px; border-left: 4px solid #ff6b6b;"&gt; 
      &lt;h4&gt;ğŸ¯ Adaptive Flow&lt;/h4&gt; 
      &lt;p&gt;&lt;small&gt;Dynamic agent selection based on input complexity&lt;/small&gt;&lt;/p&gt; 
     &lt;/div&gt; &lt;/td&gt; 
    &lt;td align="center" width="25%" style="padding: 15px;"&gt; 
     &lt;div style="background: #f8f9fa; border-radius: 10px; padding: 15px; border-left: 4px solid #4ecdc4;"&gt; 
      &lt;h4&gt;ğŸ§  Smart Coordination&lt;/h4&gt; 
      &lt;p&gt;&lt;small&gt;Intelligent task distribution and parallel processing&lt;/small&gt;&lt;/p&gt; 
     &lt;/div&gt; &lt;/td&gt; 
    &lt;td align="center" width="25%" style="padding: 15px;"&gt; 
     &lt;div style="background: #f8f9fa; border-radius: 10px; padding: 15px; border-left: 4px solid #45b7d1;"&gt; 
      &lt;h4&gt;ğŸ” Context Awareness&lt;/h4&gt; 
      &lt;p&gt;&lt;small&gt;Deep understanding through CodeRAG integration&lt;/small&gt;&lt;/p&gt; 
     &lt;/div&gt; &lt;/td&gt; 
    &lt;td align="center" width="25%" style="padding: 15px;"&gt; 
     &lt;div style="background: #f8f9fa; border-radius: 10px; padding: 15px; border-left: 4px solid #96ceb4;"&gt; 
      &lt;h4&gt;âš¡ Quality Assurance&lt;/h4&gt; 
      &lt;p&gt;&lt;small&gt;Automated testing and validation throughout&lt;/small&gt;&lt;/p&gt; 
     &lt;/div&gt; &lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt;
 &lt;/table&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ğŸš€ Quick Start&lt;/h2&gt; 
&lt;h3&gt;ğŸ“¦ &lt;strong&gt;Step 1: Installation&lt;/strong&gt;&lt;/h3&gt; 
&lt;h4&gt;âš¡ &lt;strong&gt;Direct Installation (Recommended)&lt;/strong&gt;&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# ğŸš€ Install DeepCode package directly
pip install deepcode-hku

# ğŸ”‘ Download configuration files
curl -O https://raw.githubusercontent.com/HKUDS/DeepCode/main/mcp_agent.config.yaml
curl -O https://raw.githubusercontent.com/HKUDS/DeepCode/main/mcp_agent.secrets.yaml

# ğŸ”‘ Configure API keys (required)
# Edit mcp_agent.secrets.yaml with your API keys and base_url:
# - openai: api_key, base_url (for OpenAI/custom endpoints)
# - anthropic: api_key (for Claude models)

# ğŸ”‘ Configure search API keys for web search (optional)
# Edit mcp_agent.config.yaml to set your API keys:
# - For Brave Search: Set BRAVE_API_KEY: "your_key_here" in brave.env section (line ~28)
# - For Bocha-MCP: Set BOCHA_API_KEY: "your_key_here" in bocha-mcp.env section (line ~74)

# ğŸ“„ Configure document segmentation (optional)
# Edit mcp_agent.config.yaml to control document processing:
# - enabled: true/false (whether to use intelligent document segmentation)
# - size_threshold_chars: 50000 (document size threshold to trigger segmentation)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;ğŸ”§ &lt;strong&gt;Development Installation (From Source)&lt;/strong&gt;&lt;/h4&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;ğŸ“‚ Click to expand development installation options&lt;/strong&gt;&lt;/summary&gt; 
 &lt;h5&gt;ğŸ”¥ &lt;strong&gt;Using UV (Recommended for Development)&lt;/strong&gt;&lt;/h5&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# ğŸ”½ Clone the repository
git clone https://github.com/HKUDS/DeepCode.git
cd DeepCode/

# ğŸ“¦ Install UV package manager
curl -LsSf https://astral.sh/uv/install.sh | sh

# ğŸ”§ Install dependencies with UV
uv venv --python=3.13
source .venv/bin/activate  # On Windows: .venv\Scripts\activate
uv pip install -r requirements.txt

# ğŸ”‘ Configure API keys (required)
# Edit mcp_agent.secrets.yaml with your API keys and base_url:
# - openai: api_key, base_url (for OpenAI/custom endpoints)
# - anthropic: api_key (for Claude models)

# ğŸ”‘ Configure search API keys for web search (optional)
# Edit mcp_agent.config.yaml to set your API keys:
# - For Brave Search: Set BRAVE_API_KEY: "your_key_here" in brave.env section (line ~28)
# - For Bocha-MCP: Set BOCHA_API_KEY: "your_key_here" in bocha-mcp.env section (line ~74)

# ğŸ“„ Configure document segmentation (optional)
# Edit mcp_agent.config.yaml to control document processing:
# - enabled: true/false (whether to use intelligent document segmentation)
# - size_threshold_chars: 50000 (document size threshold to trigger segmentation)
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h5&gt;ğŸ &lt;strong&gt;Using Traditional pip&lt;/strong&gt;&lt;/h5&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# ğŸ”½ Clone the repository
git clone https://github.com/HKUDS/DeepCode.git
cd DeepCode/

# ğŸ“¦ Install dependencies
pip install -r requirements.txt

# ğŸ”‘ Configure API keys (required)
# Edit mcp_agent.secrets.yaml with your API keys and base_url:
# - openai: api_key, base_url (for OpenAI/custom endpoints)
# - anthropic: api_key (for Claude models)

# ğŸ”‘ Configure search API keys for web search (optional)
# Edit mcp_agent.config.yaml to set your API keys:
# - For Brave Search: Set BRAVE_API_KEY: "your_key_here" in brave.env section (line ~28)
# - For Bocha-MCP: Set BOCHA_API_KEY: "your_key_here" in bocha-mcp.env section (line ~74)

# ğŸ“„ Configure document segmentation (optional)
# Edit mcp_agent.config.yaml to control document processing:
# - enabled: true/false (whether to use intelligent document segmentation)
# - size_threshold_chars: 50000 (document size threshold to trigger segmentation)
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h4&gt;ğŸªŸ &lt;strong&gt;Windows Users: Additional MCP Server Configuration&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;If you're using Windows, you may need to configure MCP servers manually in &lt;code&gt;mcp_agent.config.yaml&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# 1. Install MCP servers globally
npm i -g @modelcontextprotocol/server-brave-search
npm i -g @modelcontextprotocol/server-filesystem

# 2. Find your global node_modules path
npm -g root
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then update your &lt;code&gt;mcp_agent.config.yaml&lt;/code&gt; to use absolute paths:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;mcp:
  servers:
    brave:
      command: "node"
      args: ["C:/Program Files/nodejs/node_modules/@modelcontextprotocol/server-brave-search/dist/index.js"]
    filesystem:
      command: "node"
      args: ["C:/Program Files/nodejs/node_modules/@modelcontextprotocol/server-filesystem/dist/index.js", "."]
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: Replace the path with your actual global node_modules path from step 2.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;ğŸ” &lt;strong&gt;Search Server Configuration (Optional)&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;DeepCode supports multiple search servers for web search functionality. You can configure your preferred option in &lt;code&gt;mcp_agent.config.yaml&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;# Default search server configuration
# Options: "brave" or "bocha-mcp"
default_search_server: "brave"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Available Options:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;ğŸ” Brave Search&lt;/strong&gt; (&lt;code&gt;"brave"&lt;/code&gt;):&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Default option with high-quality search results&lt;/li&gt; 
   &lt;li&gt;Requires BRAVE_API_KEY configuration&lt;/li&gt; 
   &lt;li&gt;Recommended for most users&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;ğŸŒ Bocha-MCP&lt;/strong&gt; (&lt;code&gt;"bocha-mcp"&lt;/code&gt;):&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Alternative search server option&lt;/li&gt; 
   &lt;li&gt;Requires BOCHA_API_KEY configuration&lt;/li&gt; 
   &lt;li&gt;Uses local Python server implementation&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;API Key Configuration in mcp_agent.config.yaml:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;# For Brave Search (default) - around line 28
brave:
  command: "npx"
  args: ["-y", "@modelcontextprotocol/server-brave-search"]
  env:
    BRAVE_API_KEY: "your_brave_api_key_here"

# For Bocha-MCP (alternative) - around line 74
bocha-mcp:
  command: "python"
  args: ["tools/bocha_search_server.py"]
  env:
    PYTHONPATH: "."
    BOCHA_API_KEY: "your_bocha_api_key_here"
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;ğŸ’¡ Tip&lt;/strong&gt;: Both search servers require API key configuration. Choose the one that best fits your API access and requirements.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;âš¡ &lt;strong&gt;Step 2: Launch Application&lt;/strong&gt;&lt;/h3&gt; 
&lt;h4&gt;ğŸš€ &lt;strong&gt;Using Installed Package (Recommended)&lt;/strong&gt;&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# ğŸŒ Launch web interface directly
deepcode

# The application will automatically start at http://localhost:8501
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;ğŸ› ï¸ &lt;strong&gt;Using Source Code&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;Choose your preferred interface:&lt;/p&gt; 
&lt;h5&gt;ğŸŒ &lt;strong&gt;Web Interface&lt;/strong&gt; (Recommended)&lt;/h5&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Using UV
uv run streamlit run ui/streamlit_app.py
# Or using traditional Python
streamlit run ui/streamlit_app.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://img.shields.io/badge/Access-localhost:8501-00d4ff?style=flat-square&amp;amp;logo=streamlit&amp;amp;logoColor=white" alt="Web Access" /&gt; 
&lt;/div&gt; 
&lt;h5&gt;ğŸ–¥ï¸ &lt;strong&gt;CLI Interface&lt;/strong&gt; (Advanced Users)&lt;/h5&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Using UV
uv run python cli/main_cli.py
# Or using traditional Python
python cli/main_cli.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://img.shields.io/badge/Mode-Interactive_Terminal-9b59b6?style=flat-square&amp;amp;logo=terminal&amp;amp;logoColor=white" alt="CLI Mode" /&gt; 
&lt;/div&gt; 
&lt;h3&gt;ğŸ¯ &lt;strong&gt;Step 3: Generate Code&lt;/strong&gt;&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ“„ Input&lt;/strong&gt;: Upload your research paper, provide requirements, or paste a URL&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ¤– Processing&lt;/strong&gt;: Watch the multi-agent system analyze and plan&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;âš¡ Output&lt;/strong&gt;: Receive production-ready code with tests and documentation&lt;/li&gt; 
&lt;/ol&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ğŸ’¡ Examples&lt;/h2&gt; 
&lt;h3&gt;ğŸ¬ &lt;strong&gt;Live Demonstrations&lt;/strong&gt;&lt;/h3&gt; 
&lt;table align="center"&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td width="33%" align="center"&gt; &lt;h4&gt;ğŸ“„ &lt;strong&gt;Paper2Code Demo&lt;/strong&gt;&lt;/h4&gt; &lt;p&gt;&lt;strong&gt;Research to Implementation&lt;/strong&gt;&lt;/p&gt; 
    &lt;div align="center"&gt; 
     &lt;a href="https://www.youtube.com/watch?v=MQZYpLkzsbw"&gt; &lt;img src="https://img.youtube.com/vi/MQZYpLkzsbw/maxresdefault.jpg" alt="Paper2Code Demo" width="100%" style="border-radius: 10px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);" /&gt; &lt;/a&gt; 
     &lt;p&gt;&lt;strong&gt;&lt;a href="https://www.youtube.com/watch?v=MQZYpLkzsbw"&gt;â–¶ï¸ Watch Demo&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
     &lt;p&gt;&lt;em&gt;Transform academic papers into production-ready code automatically&lt;/em&gt;&lt;/p&gt; 
    &lt;/div&gt; &lt;/td&gt; 
   &lt;td width="33%" align="center"&gt; &lt;h4&gt;ğŸ–¼ï¸ &lt;strong&gt;Image Processing Demo&lt;/strong&gt;&lt;/h4&gt; &lt;p&gt;&lt;strong&gt;AI-Powered Image Tools&lt;/strong&gt;&lt;/p&gt; 
    &lt;div align="center"&gt; 
     &lt;a href="https://www.youtube.com/watch?v=nFt5mLaMEac"&gt; &lt;img src="https://img.youtube.com/vi/nFt5mLaMEac/maxresdefault.jpg" alt="Image Processing Demo" width="100%" style="border-radius: 10px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);" /&gt; &lt;/a&gt; 
     &lt;p&gt;&lt;strong&gt;&lt;a href="https://www.youtube.com/watch?v=nFt5mLaMEac"&gt;â–¶ï¸ Watch Demo&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
     &lt;p&gt;&lt;em&gt;Intelligent image processing with background removal and enhancement&lt;/em&gt;&lt;/p&gt; 
    &lt;/div&gt; &lt;/td&gt; 
   &lt;td width="33%" align="center"&gt; &lt;h4&gt;ğŸŒ &lt;strong&gt;Frontend Implementation&lt;/strong&gt;&lt;/h4&gt; &lt;p&gt;&lt;strong&gt;Complete Web Application&lt;/strong&gt;&lt;/p&gt; 
    &lt;div align="center"&gt; 
     &lt;a href="https://www.youtube.com/watch?v=78wx3dkTaAU"&gt; &lt;img src="https://img.youtube.com/vi/78wx3dkTaAU/maxresdefault.jpg" alt="Frontend Demo" width="100%" style="border-radius: 10px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);" /&gt; &lt;/a&gt; 
     &lt;p&gt;&lt;strong&gt;&lt;a href="https://www.youtube.com/watch?v=78wx3dkTaAU"&gt;â–¶ï¸ Watch Demo&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
     &lt;p&gt;&lt;em&gt;Full-stack web development from concept to deployment&lt;/em&gt;&lt;/p&gt; 
    &lt;/div&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h3&gt;ğŸ†• &lt;strong&gt;Recent Updates&lt;/strong&gt;&lt;/h3&gt; 
&lt;h4&gt;ğŸ“„ &lt;strong&gt;Smart Document Segmentation (v1.2.0)&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Intelligent Processing&lt;/strong&gt;: Automatically handles large research papers and technical documents that exceed LLM token limits&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Configurable Control&lt;/strong&gt;: Toggle segmentation via configuration with size-based thresholds&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Semantic Analysis&lt;/strong&gt;: Advanced content understanding with algorithm, concept, and formula preservation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Backward Compatibility&lt;/strong&gt;: Seamlessly falls back to traditional processing for smaller documents&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;ğŸš€ &lt;strong&gt;Coming Soon&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;We're continuously enhancing DeepCode with exciting new features:&lt;/p&gt; 
&lt;h4&gt;ğŸ”§ &lt;strong&gt;Enhanced Code Reliability &amp;amp; Validation&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Automated Testing&lt;/strong&gt;: Comprehensive functionality testing with execution verification and error detection.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Code Quality Assurance&lt;/strong&gt;: Multi-level validation through static analysis, dynamic testing, and performance benchmarking.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Smart Debugging&lt;/strong&gt;: AI-powered error detection with automatic correction suggestions&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;ğŸ“Š &lt;strong&gt;PaperBench Performance Showcase&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Benchmark Dashboard&lt;/strong&gt;: Comprehensive performance metrics on the PaperBench evaluation suite.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Accuracy Metrics&lt;/strong&gt;: Detailed comparison with state-of-the-art paper reproduction systems.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Success Analytics&lt;/strong&gt;: Statistical analysis across paper categories and complexity levels.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;âš¡ &lt;strong&gt;System-wide Optimizations&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Performance Boost&lt;/strong&gt;: Multi-threaded processing and optimized agent coordination for faster generation.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Enhanced Reasoning&lt;/strong&gt;: Advanced reasoning capabilities with improved context understanding.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Expanded Support&lt;/strong&gt;: Extended compatibility with additional programming languages and frameworks.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;â­ Star History&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;em&gt;Community Growth Trajectory&lt;/em&gt;&lt;/p&gt; 
 &lt;a href="https://star-history.com/#HKUDS/DeepCode&amp;amp;Date"&gt; 
  &lt;picture&gt; 
   &lt;source media="(prefers-color-scheme: dark)" srcset="https://api.star-history.com/svg?repos=HKUDS/DeepCode&amp;amp;type=Date&amp;amp;theme=dark" /&gt; 
   &lt;source media="(prefers-color-scheme: light)" srcset="https://api.star-history.com/svg?repos=HKUDS/DeepCode&amp;amp;type=Date" /&gt; 
   &lt;img alt="Star History Chart" src="https://api.star-history.com/svg?repos=HKUDS/DeepCode&amp;amp;type=Date" style="border-radius: 15px; box-shadow: 0 0 30px rgba(0, 217, 255, 0.3);" /&gt; 
  &lt;/picture&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h3&gt;ğŸš€ &lt;strong&gt;Ready to Transform Development?&lt;/strong&gt;&lt;/h3&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt; &lt;a href="https://raw.githubusercontent.com/HKUDS/DeepCode/main/#-quick-start"&gt;&lt;img src="https://img.shields.io/badge/ğŸš€_Get_Started-00d4ff?style=for-the-badge&amp;amp;logo=rocket&amp;amp;logoColor=white" alt="Get Started" /&gt;&lt;/a&gt; &lt;a href="https://github.com/HKUDS"&gt;&lt;img src="https://img.shields.io/badge/ğŸ›ï¸_View_on_GitHub-00d4ff?style=for-the-badge&amp;amp;logo=github&amp;amp;logoColor=white" alt="View on GitHub" /&gt;&lt;/a&gt; &lt;a href="https://github.com/HKUDS/deepcode-agent"&gt;&lt;img src="https://img.shields.io/badge/â­_Star_Project-00d4ff?style=for-the-badge&amp;amp;logo=star&amp;amp;logoColor=white" alt="Star Project" /&gt;&lt;/a&gt; &lt;/p&gt; 
 &lt;hr /&gt; 
 &lt;h3&gt;ğŸ“„ &lt;strong&gt;License&lt;/strong&gt;&lt;/h3&gt; 
 &lt;img src="https://img.shields.io/badge/License-MIT-4ecdc4?style=for-the-badge&amp;amp;logo=opensourceinitiative&amp;amp;logoColor=white" alt="MIT License" /&gt; 
 &lt;p&gt;&lt;strong&gt;MIT License&lt;/strong&gt; - Copyright (c) 2025 Data Intelligence Lab, The University of Hong Kong&lt;/p&gt; 
 &lt;hr /&gt; 
 &lt;img src="https://visitor-badge.laobi.icu/badge?page_id=deepcode.readme&amp;amp;style=for-the-badge&amp;amp;color=00d4ff" alt="Visitors" /&gt; 
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>pytorch/pytorch</title>
      <link>https://github.com/pytorch/pytorch</link>
      <description>&lt;p&gt;Tensors and Dynamic neural networks in Python with strong GPU acceleration&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src="https://github.com/pytorch/pytorch/raw/main/docs/source/_static/img/pytorch-logo-dark.png" alt="PyTorch Logo" /&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;PyTorch is a Python package that provides two high-level features:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Tensor computation (like NumPy) with strong GPU acceleration&lt;/li&gt; 
 &lt;li&gt;Deep neural networks built on a tape-based autograd system&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;You can reuse your favorite Python packages such as NumPy, SciPy, and Cython to extend PyTorch when needed.&lt;/p&gt; 
&lt;p&gt;Our trunk health (Continuous Integration signals) can be found at &lt;a href="https://hud.pytorch.org/ci/pytorch/pytorch/main"&gt;hud.pytorch.org&lt;/a&gt;.&lt;/p&gt; 
&lt;!-- toc --&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/pytorch/pytorch/main/#more-about-pytorch"&gt;More About PyTorch&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/pytorch/pytorch/main/#a-gpu-ready-tensor-library"&gt;A GPU-Ready Tensor Library&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/pytorch/pytorch/main/#dynamic-neural-networks-tape-based-autograd"&gt;Dynamic Neural Networks: Tape-Based Autograd&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/pytorch/pytorch/main/#python-first"&gt;Python First&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/pytorch/pytorch/main/#imperative-experiences"&gt;Imperative Experiences&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/pytorch/pytorch/main/#fast-and-lean"&gt;Fast and Lean&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/pytorch/pytorch/main/#extensions-without-pain"&gt;Extensions Without Pain&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/pytorch/pytorch/main/#installation"&gt;Installation&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/pytorch/pytorch/main/#binaries"&gt;Binaries&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/pytorch/pytorch/main/#nvidia-jetson-platforms"&gt;NVIDIA Jetson Platforms&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/pytorch/pytorch/main/#from-source"&gt;From Source&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/pytorch/pytorch/main/#prerequisites"&gt;Prerequisites&lt;/a&gt; 
      &lt;ul&gt; 
       &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/pytorch/pytorch/main/#nvidia-cuda-support"&gt;NVIDIA CUDA Support&lt;/a&gt;&lt;/li&gt; 
       &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/pytorch/pytorch/main/#amd-rocm-support"&gt;AMD ROCm Support&lt;/a&gt;&lt;/li&gt; 
       &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/pytorch/pytorch/main/#intel-gpu-support"&gt;Intel GPU Support&lt;/a&gt;&lt;/li&gt; 
      &lt;/ul&gt; &lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/pytorch/pytorch/main/#get-the-pytorch-source"&gt;Get the PyTorch Source&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/pytorch/pytorch/main/#install-dependencies"&gt;Install Dependencies&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/pytorch/pytorch/main/#install-pytorch"&gt;Install PyTorch&lt;/a&gt; 
      &lt;ul&gt; 
       &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/pytorch/pytorch/main/#adjust-build-options-optional"&gt;Adjust Build Options (Optional)&lt;/a&gt;&lt;/li&gt; 
      &lt;/ul&gt; &lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/pytorch/pytorch/main/#docker-image"&gt;Docker Image&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/pytorch/pytorch/main/#using-pre-built-images"&gt;Using pre-built images&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/pytorch/pytorch/main/#building-the-image-yourself"&gt;Building the image yourself&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/pytorch/pytorch/main/#building-the-documentation"&gt;Building the Documentation&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/pytorch/pytorch/main/#building-a-pdf"&gt;Building a PDF&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/pytorch/pytorch/main/#previous-versions"&gt;Previous Versions&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/pytorch/pytorch/main/#getting-started"&gt;Getting Started&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/pytorch/pytorch/main/#resources"&gt;Resources&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/pytorch/pytorch/main/#communication"&gt;Communication&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/pytorch/pytorch/main/#releases-and-contributing"&gt;Releases and Contributing&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/pytorch/pytorch/main/#the-team"&gt;The Team&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/pytorch/pytorch/main/#license"&gt;License&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;!-- tocstop --&gt; 
&lt;h2&gt;More About PyTorch&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://pytorch.org/tutorials/beginner/basics/intro.html"&gt;Learn the basics of PyTorch&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;At a granular level, PyTorch is a library that consists of the following components:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Component&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://pytorch.org/docs/stable/torch.html"&gt;&lt;strong&gt;torch&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;A Tensor library like NumPy, with strong GPU support&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://pytorch.org/docs/stable/autograd.html"&gt;&lt;strong&gt;torch.autograd&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;A tape-based automatic differentiation library that supports all differentiable Tensor operations in torch&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://pytorch.org/docs/stable/jit.html"&gt;&lt;strong&gt;torch.jit&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;A compilation stack (TorchScript) to create serializable and optimizable models from PyTorch code&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://pytorch.org/docs/stable/nn.html"&gt;&lt;strong&gt;torch.nn&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;A neural networks library deeply integrated with autograd designed for maximum flexibility&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://pytorch.org/docs/stable/multiprocessing.html"&gt;&lt;strong&gt;torch.multiprocessing&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Python multiprocessing, but with magical memory sharing of torch Tensors across processes. Useful for data loading and Hogwild training&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://pytorch.org/docs/stable/data.html"&gt;&lt;strong&gt;torch.utils&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;DataLoader and other utility functions for convenience&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Usually, PyTorch is used either as:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;A replacement for NumPy to use the power of GPUs.&lt;/li&gt; 
 &lt;li&gt;A deep learning research platform that provides maximum flexibility and speed.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Elaborating Further:&lt;/p&gt; 
&lt;h3&gt;A GPU-Ready Tensor Library&lt;/h3&gt; 
&lt;p&gt;If you use NumPy, then you have used Tensors (a.k.a. ndarray).&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/pytorch/pytorch/raw/main/docs/source/_static/img/tensor_illustration.png" alt="Tensor illustration" /&gt;&lt;/p&gt; 
&lt;p&gt;PyTorch provides Tensors that can live either on the CPU or the GPU and accelerates the computation by a huge amount.&lt;/p&gt; 
&lt;p&gt;We provide a wide variety of tensor routines to accelerate and fit your scientific computation needs such as slicing, indexing, mathematical operations, linear algebra, reductions. And they are fast!&lt;/p&gt; 
&lt;h3&gt;Dynamic Neural Networks: Tape-Based Autograd&lt;/h3&gt; 
&lt;p&gt;PyTorch has a unique way of building neural networks: using and replaying a tape recorder.&lt;/p&gt; 
&lt;p&gt;Most frameworks such as TensorFlow, Theano, Caffe, and CNTK have a static view of the world. One has to build a neural network and reuse the same structure again and again. Changing the way the network behaves means that one has to start from scratch.&lt;/p&gt; 
&lt;p&gt;With PyTorch, we use a technique called reverse-mode auto-differentiation, which allows you to change the way your network behaves arbitrarily with zero lag or overhead. Our inspiration comes from several research papers on this topic, as well as current and past work such as &lt;a href="https://github.com/twitter/torch-autograd"&gt;torch-autograd&lt;/a&gt;, &lt;a href="https://github.com/HIPS/autograd"&gt;autograd&lt;/a&gt;, &lt;a href="https://chainer.org"&gt;Chainer&lt;/a&gt;, etc.&lt;/p&gt; 
&lt;p&gt;While this technique is not unique to PyTorch, it's one of the fastest implementations of it to date. You get the best of speed and flexibility for your crazy research.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/pytorch/pytorch/raw/main/docs/source/_static/img/dynamic_graph.gif" alt="Dynamic graph" /&gt;&lt;/p&gt; 
&lt;h3&gt;Python First&lt;/h3&gt; 
&lt;p&gt;PyTorch is not a Python binding into a monolithic C++ framework. It is built to be deeply integrated into Python. You can use it naturally like you would use &lt;a href="https://www.numpy.org/"&gt;NumPy&lt;/a&gt; / &lt;a href="https://www.scipy.org/"&gt;SciPy&lt;/a&gt; / &lt;a href="https://scikit-learn.org"&gt;scikit-learn&lt;/a&gt; etc. You can write your new neural network layers in Python itself, using your favorite libraries and use packages such as &lt;a href="https://cython.org/"&gt;Cython&lt;/a&gt; and &lt;a href="http://numba.pydata.org/"&gt;Numba&lt;/a&gt;. Our goal is to not reinvent the wheel where appropriate.&lt;/p&gt; 
&lt;h3&gt;Imperative Experiences&lt;/h3&gt; 
&lt;p&gt;PyTorch is designed to be intuitive, linear in thought, and easy to use. When you execute a line of code, it gets executed. There isn't an asynchronous view of the world. When you drop into a debugger or receive error messages and stack traces, understanding them is straightforward. The stack trace points to exactly where your code was defined. We hope you never spend hours debugging your code because of bad stack traces or asynchronous and opaque execution engines.&lt;/p&gt; 
&lt;h3&gt;Fast and Lean&lt;/h3&gt; 
&lt;p&gt;PyTorch has minimal framework overhead. We integrate acceleration libraries such as &lt;a href="https://software.intel.com/mkl"&gt;Intel MKL&lt;/a&gt; and NVIDIA (&lt;a href="https://developer.nvidia.com/cudnn"&gt;cuDNN&lt;/a&gt;, &lt;a href="https://developer.nvidia.com/nccl"&gt;NCCL&lt;/a&gt;) to maximize speed. At the core, its CPU and GPU Tensor and neural network backends are mature and have been tested for years.&lt;/p&gt; 
&lt;p&gt;Hence, PyTorch is quite fast â€” whether you run small or large neural networks.&lt;/p&gt; 
&lt;p&gt;The memory usage in PyTorch is extremely efficient compared to Torch or some of the alternatives. We've written custom memory allocators for the GPU to make sure that your deep learning models are maximally memory efficient. This enables you to train bigger deep learning models than before.&lt;/p&gt; 
&lt;h3&gt;Extensions Without Pain&lt;/h3&gt; 
&lt;p&gt;Writing new neural network modules, or interfacing with PyTorch's Tensor API was designed to be straightforward and with minimal abstractions.&lt;/p&gt; 
&lt;p&gt;You can write new neural network layers in Python using the torch API &lt;a href="https://pytorch.org/tutorials/advanced/numpy_extensions_tutorial.html"&gt;or your favorite NumPy-based libraries such as SciPy&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;If you want to write your layers in C/C++, we provide a convenient extension API that is efficient and with minimal boilerplate. No wrapper code needs to be written. You can see &lt;a href="https://pytorch.org/tutorials/advanced/cpp_extension.html"&gt;a tutorial here&lt;/a&gt; and &lt;a href="https://github.com/pytorch/extension-cpp"&gt;an example here&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;h3&gt;Binaries&lt;/h3&gt; 
&lt;p&gt;Commands to install binaries via Conda or pip wheels are on our website: &lt;a href="https://pytorch.org/get-started/locally/"&gt;https://pytorch.org/get-started/locally/&lt;/a&gt;&lt;/p&gt; 
&lt;h4&gt;NVIDIA Jetson Platforms&lt;/h4&gt; 
&lt;p&gt;Python wheels for NVIDIA's Jetson Nano, Jetson TX1/TX2, Jetson Xavier NX/AGX, and Jetson AGX Orin are provided &lt;a href="https://forums.developer.nvidia.com/t/pytorch-for-jetson-version-1-10-now-available/72048"&gt;here&lt;/a&gt; and the L4T container is published &lt;a href="https://catalog.ngc.nvidia.com/orgs/nvidia/containers/l4t-pytorch"&gt;here&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;They require JetPack 4.2 and above, and &lt;a href="https://github.com/dusty-nv"&gt;@dusty-nv&lt;/a&gt; and &lt;a href="https://github.com/ptrblck"&gt;@ptrblck&lt;/a&gt; are maintaining them.&lt;/p&gt; 
&lt;h3&gt;From Source&lt;/h3&gt; 
&lt;h4&gt;Prerequisites&lt;/h4&gt; 
&lt;p&gt;If you are installing from source, you will need:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Python 3.10 or later&lt;/li&gt; 
 &lt;li&gt;A compiler that fully supports C++17, such as clang or gcc (gcc 9.4.0 or newer is required, on Linux)&lt;/li&gt; 
 &lt;li&gt;Visual Studio or Visual Studio Build Tool (Windows only)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;* PyTorch CI uses Visual C++ BuildTools, which come with Visual Studio Enterprise, Professional, or Community Editions. You can also install the build tools from &lt;a href="https://visualstudio.microsoft.com/visual-cpp-build-tools/"&gt;https://visualstudio.microsoft.com/visual-cpp-build-tools/&lt;/a&gt;. The build tools &lt;em&gt;do not&lt;/em&gt; come with Visual Studio Code by default.&lt;/p&gt; 
&lt;p&gt;An example of environment setup is shown below:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Linux:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;$ source &amp;lt;CONDA_INSTALL_DIR&amp;gt;/bin/activate
$ conda create -y -n &amp;lt;CONDA_NAME&amp;gt;
$ conda activate &amp;lt;CONDA_NAME&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;Windows:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;$ source &amp;lt;CONDA_INSTALL_DIR&amp;gt;\Scripts\activate.bat
$ conda create -y -n &amp;lt;CONDA_NAME&amp;gt;
$ conda activate &amp;lt;CONDA_NAME&amp;gt;
$ call "C:\Program Files\Microsoft Visual Studio\&amp;lt;VERSION&amp;gt;\Community\VC\Auxiliary\Build\vcvarsall.bat" x64
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;A conda environment is not required. You can also do a PyTorch build in a standard virtual environment, e.g., created with tools like &lt;code&gt;uv&lt;/code&gt;, provided your system has installed all the necessary dependencies unavailable as pip packages (e.g., CUDA, MKL.)&lt;/p&gt; 
&lt;h5&gt;NVIDIA CUDA Support&lt;/h5&gt; 
&lt;p&gt;If you want to compile with CUDA support, &lt;a href="https://pytorch.org/get-started/locally/"&gt;select a supported version of CUDA from our support matrix&lt;/a&gt;, then install the following:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://developer.nvidia.com/cuda-downloads"&gt;NVIDIA CUDA&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://developer.nvidia.com/cudnn"&gt;NVIDIA cuDNN&lt;/a&gt; v8.5 or above&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://gist.github.com/ax3l/9489132"&gt;Compiler&lt;/a&gt; compatible with CUDA&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Note: You could refer to the &lt;a href="https://docs.nvidia.com/deeplearning/cudnn/backend/latest/reference/support-matrix.html"&gt;cuDNN Support Matrix&lt;/a&gt; for cuDNN versions with the various supported CUDA, CUDA driver, and NVIDIA hardware.&lt;/p&gt; 
&lt;p&gt;If you want to disable CUDA support, export the environment variable &lt;code&gt;USE_CUDA=0&lt;/code&gt;. Other potentially useful environment variables may be found in &lt;code&gt;setup.py&lt;/code&gt;. If CUDA is installed in a non-standard location, set PATH so that the nvcc you want to use can be found (e.g., &lt;code&gt;export PATH=/usr/local/cuda-12.8/bin:$PATH&lt;/code&gt;).&lt;/p&gt; 
&lt;p&gt;If you are building for NVIDIA's Jetson platforms (Jetson Nano, TX1, TX2, AGX Xavier), Instructions to install PyTorch for Jetson Nano are &lt;a href="https://devtalk.nvidia.com/default/topic/1049071/jetson-nano/pytorch-for-jetson-nano/"&gt;available here&lt;/a&gt;&lt;/p&gt; 
&lt;h5&gt;AMD ROCm Support&lt;/h5&gt; 
&lt;p&gt;If you want to compile with ROCm support, install&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://rocm.docs.amd.com/en/latest/deploy/linux/quick_start.html"&gt;AMD ROCm&lt;/a&gt; 4.0 and above installation&lt;/li&gt; 
 &lt;li&gt;ROCm is currently supported only for Linux systems.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;By default the build system expects ROCm to be installed in &lt;code&gt;/opt/rocm&lt;/code&gt;. If ROCm is installed in a different directory, the &lt;code&gt;ROCM_PATH&lt;/code&gt; environment variable must be set to the ROCm installation directory. The build system automatically detects the AMD GPU architecture. Optionally, the AMD GPU architecture can be explicitly set with the &lt;code&gt;PYTORCH_ROCM_ARCH&lt;/code&gt; environment variable &lt;a href="https://rocm.docs.amd.com/projects/install-on-linux/en/latest/reference/system-requirements.html#supported-gpus"&gt;AMD GPU architecture&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;If you want to disable ROCm support, export the environment variable &lt;code&gt;USE_ROCM=0&lt;/code&gt;. Other potentially useful environment variables may be found in &lt;code&gt;setup.py&lt;/code&gt;.&lt;/p&gt; 
&lt;h5&gt;Intel GPU Support&lt;/h5&gt; 
&lt;p&gt;If you want to compile with Intel GPU support, follow these&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.intel.com/content/www/us/en/developer/articles/tool/pytorch-prerequisites-for-intel-gpus.html"&gt;PyTorch Prerequisites for Intel GPUs&lt;/a&gt; instructions.&lt;/li&gt; 
 &lt;li&gt;Intel GPU is supported for Linux and Windows.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;If you want to disable Intel GPU support, export the environment variable &lt;code&gt;USE_XPU=0&lt;/code&gt;. Other potentially useful environment variables may be found in &lt;code&gt;setup.py&lt;/code&gt;.&lt;/p&gt; 
&lt;h4&gt;Get the PyTorch Source&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/pytorch/pytorch
cd pytorch
# if you are updating an existing checkout
git submodule sync
git submodule update --init --recursive
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Install Dependencies&lt;/h4&gt; 
&lt;p&gt;&lt;strong&gt;Common&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Run this command from the PyTorch directory after cloning the source code using the â€œGet the PyTorch Sourceâ€œ section above
pip install --group dev
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;On Linux&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install mkl-static mkl-include
# CUDA only: Add LAPACK support for the GPU if needed
# magma installation: run with active conda environment. specify CUDA version to install
.ci/docker/common/install_magma_conda.sh 12.4

# (optional) If using torch.compile with inductor/triton, install the matching version of triton
# Run from the pytorch directory after cloning
# For Intel GPU support, please explicitly `export USE_XPU=1` before running command.
make triton
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;On MacOS&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Add this package on intel x86 processor machines only
pip install mkl-static mkl-include
# Add these packages if torch.distributed is needed
conda install pkg-config libuv
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;On Windows&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install mkl-static mkl-include
# Add these packages if torch.distributed is needed.
# Distributed package support on Windows is a prototype feature and is subject to changes.
conda install -c conda-forge libuv=1.51
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Install PyTorch&lt;/h4&gt; 
&lt;p&gt;&lt;strong&gt;On Linux&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;If you're compiling for AMD ROCm then first run this command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Only run this if you're compiling for ROCm
python tools/amd_build/build_amd.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Install PyTorch&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;export CMAKE_PREFIX_PATH="${CONDA_PREFIX:-'$(dirname $(which conda))/../'}:${CMAKE_PREFIX_PATH}"
python -m pip install --no-build-isolation -v -e .
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;On macOS&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python -m pip install --no-build-isolation -v -e .
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;On Windows&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;If you want to build legacy python code, please refer to &lt;a href="https://github.com/pytorch/pytorch/raw/main/CONTRIBUTING.md#building-on-legacy-code-and-cuda"&gt;Building on legacy code and CUDA&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;CPU-only builds&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;In this mode PyTorch computations will run on your CPU, not your GPU.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-cmd"&gt;python -m pip install --no-build-isolation -v -e .
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Note on OpenMP: The desired OpenMP implementation is Intel OpenMP (iomp). In order to link against iomp, you'll need to manually download the library and set up the building environment by tweaking &lt;code&gt;CMAKE_INCLUDE_PATH&lt;/code&gt; and &lt;code&gt;LIB&lt;/code&gt;. The instruction &lt;a href="https://github.com/pytorch/pytorch/raw/main/docs/source/notes/windows.rst#building-from-source"&gt;here&lt;/a&gt; is an example for setting up both MKL and Intel OpenMP. Without these configurations for CMake, Microsoft Visual C OpenMP runtime (vcomp) will be used.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;CUDA based build&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;In this mode PyTorch computations will leverage your GPU via CUDA for faster number crunching&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://docs.nvidia.com/gameworks/content/gameworkslibrary/nvtx/nvidia_tools_extension_library_nvtx.htm"&gt;NVTX&lt;/a&gt; is needed to build Pytorch with CUDA. NVTX is a part of CUDA distributive, where it is called "Nsight Compute". To install it onto an already installed CUDA run CUDA installation once again and check the corresponding checkbox. Make sure that CUDA with Nsight Compute is installed after Visual Studio.&lt;/p&gt; 
&lt;p&gt;Currently, VS 2017 / 2019, and Ninja are supported as the generator of CMake. If &lt;code&gt;ninja.exe&lt;/code&gt; is detected in &lt;code&gt;PATH&lt;/code&gt;, then Ninja will be used as the default generator, otherwise, it will use VS 2017 / 2019. &lt;br /&gt; If Ninja is selected as the generator, the latest MSVC will get selected as the underlying toolchain.&lt;/p&gt; 
&lt;p&gt;Additional libraries such as &lt;a href="https://developer.nvidia.com/magma"&gt;Magma&lt;/a&gt;, &lt;a href="https://github.com/oneapi-src/oneDNN"&gt;oneDNN, a.k.a. MKLDNN or DNNL&lt;/a&gt;, and &lt;a href="https://github.com/mozilla/sccache"&gt;Sccache&lt;/a&gt; are often needed. Please refer to the &lt;a href="https://github.com/pytorch/pytorch/tree/main/.ci/pytorch/win-test-helpers/installation-helpers"&gt;installation-helper&lt;/a&gt; to install them.&lt;/p&gt; 
&lt;p&gt;You can refer to the &lt;a href="https://github.com/pytorch/pytorch/raw/main/.ci/pytorch/win-test-helpers/build_pytorch.bat"&gt;build_pytorch.bat&lt;/a&gt; script for some other environment variables configurations&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-cmd"&gt;cmd

:: Set the environment variables after you have downloaded and unzipped the mkl package,
:: else CMake would throw an error as `Could NOT find OpenMP`.
set CMAKE_INCLUDE_PATH={Your directory}\mkl\include
set LIB={Your directory}\mkl\lib;%LIB%

:: Read the content in the previous section carefully before you proceed.
:: [Optional] If you want to override the underlying toolset used by Ninja and Visual Studio with CUDA, please run the following script block.
:: "Visual Studio 2019 Developer Command Prompt" will be run automatically.
:: Make sure you have CMake &amp;gt;= 3.12 before you do this when you use the Visual Studio generator.
set CMAKE_GENERATOR_TOOLSET_VERSION=14.27
set DISTUTILS_USE_SDK=1
for /f "usebackq tokens=*" %i in (`"%ProgramFiles(x86)%\Microsoft Visual Studio\Installer\vswhere.exe" -version [15^,17^) -products * -latest -property installationPath`) do call "%i\VC\Auxiliary\Build\vcvarsall.bat" x64 -vcvars_ver=%CMAKE_GENERATOR_TOOLSET_VERSION%

:: [Optional] If you want to override the CUDA host compiler
set CUDAHOSTCXX=C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.27.29110\bin\HostX64\x64\cl.exe

python -m pip install --no-build-isolation -v -e .
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Intel GPU builds&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;In this mode PyTorch with Intel GPU support will be built.&lt;/p&gt; 
&lt;p&gt;Please make sure &lt;a href="https://raw.githubusercontent.com/pytorch/pytorch/main/#prerequisites"&gt;the common prerequisites&lt;/a&gt; as well as &lt;a href="https://raw.githubusercontent.com/pytorch/pytorch/main/#intel-gpu-support"&gt;the prerequisites for Intel GPU&lt;/a&gt; are properly installed and the environment variables are configured prior to starting the build. For build tool support, &lt;code&gt;Visual Studio 2022&lt;/code&gt; is required.&lt;/p&gt; 
&lt;p&gt;Then PyTorch can be built with the command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-cmd"&gt;:: CMD Commands:
:: Set the CMAKE_PREFIX_PATH to help find corresponding packages
:: %CONDA_PREFIX% only works after `conda activate custom_env`

if defined CMAKE_PREFIX_PATH (
    set "CMAKE_PREFIX_PATH=%CONDA_PREFIX%\Library;%CMAKE_PREFIX_PATH%"
) else (
    set "CMAKE_PREFIX_PATH=%CONDA_PREFIX%\Library"
)

python -m pip install --no-build-isolation -v -e .
&lt;/code&gt;&lt;/pre&gt; 
&lt;h5&gt;Adjust Build Options (Optional)&lt;/h5&gt; 
&lt;p&gt;You can adjust the configuration of cmake variables optionally (without building first), by doing the following. For example, adjusting the pre-detected directories for CuDNN or BLAS can be done with such a step.&lt;/p&gt; 
&lt;p&gt;On Linux&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;export CMAKE_PREFIX_PATH="${CONDA_PREFIX:-'$(dirname $(which conda))/../'}:${CMAKE_PREFIX_PATH}"
CMAKE_ONLY=1 python setup.py build
ccmake build  # or cmake-gui build
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;On macOS&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;export CMAKE_PREFIX_PATH="${CONDA_PREFIX:-'$(dirname $(which conda))/../'}:${CMAKE_PREFIX_PATH}"
MACOSX_DEPLOYMENT_TARGET=11.0 CMAKE_ONLY=1 python setup.py build
ccmake build  # or cmake-gui build
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Docker Image&lt;/h3&gt; 
&lt;h4&gt;Using pre-built images&lt;/h4&gt; 
&lt;p&gt;You can also pull a pre-built docker image from Docker Hub and run with docker v19.03+&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run --gpus all --rm -ti --ipc=host pytorch/pytorch:latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Please note that PyTorch uses shared memory to share data between processes, so if torch multiprocessing is used (e.g. for multithreaded data loaders) the default shared memory segment size that container runs with is not enough, and you should increase shared memory size either with &lt;code&gt;--ipc=host&lt;/code&gt; or &lt;code&gt;--shm-size&lt;/code&gt; command line options to &lt;code&gt;nvidia-docker run&lt;/code&gt;.&lt;/p&gt; 
&lt;h4&gt;Building the image yourself&lt;/h4&gt; 
&lt;p&gt;&lt;strong&gt;NOTE:&lt;/strong&gt; Must be built with a docker version &amp;gt; 18.06&lt;/p&gt; 
&lt;p&gt;The &lt;code&gt;Dockerfile&lt;/code&gt; is supplied to build images with CUDA 11.1 support and cuDNN v8. You can pass &lt;code&gt;PYTHON_VERSION=x.y&lt;/code&gt; make variable to specify which Python version is to be used by Miniconda, or leave it unset to use the default.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;make -f docker.Makefile
# images are tagged as docker.io/${your_docker_username}/pytorch
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can also pass the &lt;code&gt;CMAKE_VARS="..."&lt;/code&gt; environment variable to specify additional CMake variables to be passed to CMake during the build. See &lt;a href="https://raw.githubusercontent.com/pytorch/pytorch/main/setup.py"&gt;setup.py&lt;/a&gt; for the list of available variables.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;make -f docker.Makefile
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Building the Documentation&lt;/h3&gt; 
&lt;p&gt;To build documentation in various formats, you will need &lt;a href="http://www.sphinx-doc.org"&gt;Sphinx&lt;/a&gt; and the pytorch_sphinx_theme2.&lt;/p&gt; 
&lt;p&gt;Before you build the documentation locally, ensure &lt;code&gt;torch&lt;/code&gt; is installed in your environment. For small fixes, you can install the nightly version as described in &lt;a href="https://pytorch.org/get-started/locally/"&gt;Getting Started&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;For more complex fixes, such as adding a new module and docstrings for the new module, you might need to install torch &lt;a href="https://raw.githubusercontent.com/pytorch/pytorch/main/#from-source"&gt;from source&lt;/a&gt;. See &lt;a href="https://github.com/pytorch/pytorch/wiki/Docstring-Guidelines"&gt;Docstring Guidelines&lt;/a&gt; for docstring conventions.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd docs/
pip install -r requirements.txt
make html
make serve
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Run &lt;code&gt;make&lt;/code&gt; to get a list of all available output formats.&lt;/p&gt; 
&lt;p&gt;If you get a katex error run &lt;code&gt;npm install katex&lt;/code&gt;. If it persists, try &lt;code&gt;npm install -g katex&lt;/code&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] If you installed &lt;code&gt;nodejs&lt;/code&gt; with a different package manager (e.g., &lt;code&gt;conda&lt;/code&gt;) then &lt;code&gt;npm&lt;/code&gt; will probably install a version of &lt;code&gt;katex&lt;/code&gt; that is not compatible with your version of &lt;code&gt;nodejs&lt;/code&gt; and doc builds will fail. A combination of versions that is known to work is &lt;code&gt;node@6.13.1&lt;/code&gt; and &lt;code&gt;katex@0.13.18&lt;/code&gt;. To install the latter with &lt;code&gt;npm&lt;/code&gt; you can run &lt;code&gt;npm install -g katex@0.13.18&lt;/code&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] If you see a numpy incompatibility error, run:&lt;/p&gt; 
 &lt;pre&gt;&lt;code&gt;pip install 'numpy&amp;lt;2'
&lt;/code&gt;&lt;/pre&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;When you make changes to the dependencies run by CI, edit the &lt;code&gt;.ci/docker/requirements-docs.txt&lt;/code&gt; file.&lt;/p&gt; 
&lt;h4&gt;Building a PDF&lt;/h4&gt; 
&lt;p&gt;To compile a PDF of all PyTorch documentation, ensure you have &lt;code&gt;texlive&lt;/code&gt; and LaTeX installed. On macOS, you can install them using:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;brew install --cask mactex
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To create the PDF:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Run:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;make latexpdf
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;This will generate the necessary files in the &lt;code&gt;build/latex&lt;/code&gt; directory.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Navigate to this directory and execute:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;make LATEXOPTS="-interaction=nonstopmode"
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;This will produce a &lt;code&gt;pytorch.pdf&lt;/code&gt; with the desired content. Run this command one more time so that it generates the correct table of contents and index.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] To view the Table of Contents, switch to the &lt;strong&gt;Table of Contents&lt;/strong&gt; view in your PDF viewer.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Previous Versions&lt;/h3&gt; 
&lt;p&gt;Installation instructions and binaries for previous PyTorch versions may be found on &lt;a href="https://pytorch.org/get-started/previous-versions"&gt;our website&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;p&gt;Three pointers to get you started:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://pytorch.org/tutorials/"&gt;Tutorials: get you started with understanding and using PyTorch&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pytorch/examples"&gt;Examples: easy to understand PyTorch code across all domains&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pytorch.org/docs/"&gt;The API Reference&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pytorch/pytorch/raw/main/GLOSSARY.md"&gt;Glossary&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Resources&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://pytorch.org/"&gt;PyTorch.org&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pytorch.org/tutorials/"&gt;PyTorch Tutorials&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pytorch/examples"&gt;PyTorch Examples&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pytorch.org/hub/"&gt;PyTorch Models&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.udacity.com/course/deep-learning-pytorch--ud188"&gt;Intro to Deep Learning with PyTorch from Udacity&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.udacity.com/course/intro-to-machine-learning-nanodegree--nd229"&gt;Intro to Machine Learning with PyTorch from Udacity&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.coursera.org/learn/deep-neural-networks-with-pytorch"&gt;Deep Neural Networks with PyTorch from Coursera&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://twitter.com/PyTorch"&gt;PyTorch Twitter&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pytorch.org/blog/"&gt;PyTorch Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/channel/UCWXI5YeOsh03QvJ59PMaXFw"&gt;PyTorch YouTube&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Communication&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Forums: Discuss implementations, research, etc. &lt;a href="https://discuss.pytorch.org"&gt;https://discuss.pytorch.org&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;GitHub Issues: Bug reports, feature requests, install issues, RFCs, thoughts, etc.&lt;/li&gt; 
 &lt;li&gt;Slack: The &lt;a href="https://pytorch.slack.com/"&gt;PyTorch Slack&lt;/a&gt; hosts a primary audience of moderate to experienced PyTorch users and developers for general chat, online discussions, collaboration, etc. If you are a beginner looking for help, the primary medium is &lt;a href="https://discuss.pytorch.org"&gt;PyTorch Forums&lt;/a&gt;. If you need a slack invite, please fill this form: &lt;a href="https://goo.gl/forms/PP1AGvNHpSaJP8to1"&gt;https://goo.gl/forms/PP1AGvNHpSaJP8to1&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Newsletter: No-noise, a one-way email newsletter with important announcements about PyTorch. You can sign-up here: &lt;a href="https://eepurl.com/cbG0rv"&gt;https://eepurl.com/cbG0rv&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Facebook Page: Important announcements about PyTorch. &lt;a href="https://www.facebook.com/pytorch"&gt;https://www.facebook.com/pytorch&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;For brand guidelines, please visit our website at &lt;a href="https://pytorch.org/"&gt;pytorch.org&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Releases and Contributing&lt;/h2&gt; 
&lt;p&gt;Typically, PyTorch has three minor releases a year. Please let us know if you encounter a bug by &lt;a href="https://github.com/pytorch/pytorch/issues"&gt;filing an issue&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;We appreciate all contributions. If you are planning to contribute back bug-fixes, please do so without any further discussion.&lt;/p&gt; 
&lt;p&gt;If you plan to contribute new features, utility functions, or extensions to the core, please first open an issue and discuss the feature with us. Sending a PR without discussion might end up resulting in a rejected PR because we might be taking the core in a different direction than you might be aware of.&lt;/p&gt; 
&lt;p&gt;To learn more about making a contribution to Pytorch, please see our &lt;a href="https://raw.githubusercontent.com/pytorch/pytorch/main/CONTRIBUTING.md"&gt;Contribution page&lt;/a&gt;. For more information about PyTorch releases, see &lt;a href="https://raw.githubusercontent.com/pytorch/pytorch/main/RELEASE.md"&gt;Release page&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;The Team&lt;/h2&gt; 
&lt;p&gt;PyTorch is a community-driven project with several skillful engineers and researchers contributing to it.&lt;/p&gt; 
&lt;p&gt;PyTorch is currently maintained by &lt;a href="http://soumith.ch"&gt;Soumith Chintala&lt;/a&gt;, &lt;a href="https://github.com/gchanan"&gt;Gregory Chanan&lt;/a&gt;, &lt;a href="https://github.com/dzhulgakov"&gt;Dmytro Dzhulgakov&lt;/a&gt;, &lt;a href="https://github.com/ezyang"&gt;Edward Yang&lt;/a&gt;, &lt;a href="https://github.com/albanD"&gt;Alban Desmaison&lt;/a&gt;, &lt;a href="https://github.com/ptrblck"&gt;Piotr Bialecki&lt;/a&gt; and &lt;a href="https://github.com/malfet"&gt;Nikita Shulga&lt;/a&gt; with major contributions coming from hundreds of talented individuals in various forms and means. A non-exhaustive but growing list needs to mention: &lt;a href="https://github.com/killeent"&gt;Trevor Killeen&lt;/a&gt;, &lt;a href="https://github.com/chsasank"&gt;Sasank Chilamkurthy&lt;/a&gt;, &lt;a href="https://github.com/szagoruyko"&gt;Sergey Zagoruyko&lt;/a&gt;, &lt;a href="https://github.com/adamlerer"&gt;Adam Lerer&lt;/a&gt;, &lt;a href="https://github.com/fmassa"&gt;Francisco Massa&lt;/a&gt;, &lt;a href="https://github.com/alykhantejani"&gt;Alykhan Tejani&lt;/a&gt;, &lt;a href="https://github.com/lantiga"&gt;Luca Antiga&lt;/a&gt;, &lt;a href="https://github.com/albanD"&gt;Alban Desmaison&lt;/a&gt;, &lt;a href="https://github.com/andreaskoepf"&gt;Andreas Koepf&lt;/a&gt;, &lt;a href="https://github.com/jekbradbury"&gt;James Bradbury&lt;/a&gt;, &lt;a href="https://github.com/ebetica"&gt;Zeming Lin&lt;/a&gt;, &lt;a href="https://github.com/yuandong-tian"&gt;Yuandong Tian&lt;/a&gt;, &lt;a href="https://github.com/glample"&gt;Guillaume Lample&lt;/a&gt;, &lt;a href="https://github.com/Maratyszcza"&gt;Marat Dukhan&lt;/a&gt;, &lt;a href="https://github.com/ngimel"&gt;Natalia Gimelshein&lt;/a&gt;, &lt;a href="https://github.com/csarofeen"&gt;Christian Sarofeen&lt;/a&gt;, &lt;a href="https://github.com/martinraison"&gt;Martin Raison&lt;/a&gt;, &lt;a href="https://github.com/ezyang"&gt;Edward Yang&lt;/a&gt;, &lt;a href="https://github.com/zdevito"&gt;Zachary Devito&lt;/a&gt;. 
 &lt;!-- codespell:ignore --&gt;&lt;/p&gt; 
&lt;p&gt;Note: This project is unrelated to &lt;a href="https://github.com/hughperkins/pytorch"&gt;hughperkins/pytorch&lt;/a&gt; with the same name. Hugh is a valuable contributor to the Torch community and has helped with many things Torch and PyTorch.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;PyTorch has a BSD-style license, as found in the &lt;a href="https://raw.githubusercontent.com/pytorch/pytorch/main/LICENSE"&gt;LICENSE&lt;/a&gt; file.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>lllyasviel/Fooocus</title>
      <link>https://github.com/lllyasviel/Fooocus</link>
      <description>&lt;p&gt;Focus on prompting and generating&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;img src="https://github.com/lllyasviel/Fooocus/assets/19834515/483fb86d-c9a2-4c20-997c-46dafc124f25" /&gt; 
&lt;/div&gt; 
&lt;h1&gt;Fooocus&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/lllyasviel/Fooocus/main/#download"&gt;&amp;gt;&amp;gt;&amp;gt; Click Here to Install Fooocus &amp;lt;&amp;lt;&amp;lt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Fooocus is an image generating software (based on &lt;a href="https://www.gradio.app/"&gt;Gradio&lt;/a&gt; &lt;a href="https://github.com/gradio-app/gradio"&gt;&lt;img src="https://img.shields.io/github/stars/gradio-app/gradio" /&gt;&lt;/a&gt;).&lt;/p&gt; 
&lt;p&gt;Fooocus presents a rethinking of image generator designs. The software is offline, open source, and free, while at the same time, similar to many online image generators like Midjourney, the manual tweaking is not needed, and users only need to focus on the prompts and images. Fooocus has also simplified the installation: between pressing "download" and generating the first image, the number of needed mouse clicks is strictly limited to less than 3. Minimal GPU memory requirement is 4GB (Nvidia).&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Recently many fake websites exist on Google when you search â€œfooocusâ€. Do not trust those â€“ here is the only official source of Fooocus.&lt;/strong&gt;&lt;/p&gt; 
&lt;h1&gt;Project Status: Limited Long-Term Support (LTS) with Bug Fixes Only&lt;/h1&gt; 
&lt;p&gt;The Fooocus project, built entirely on the &lt;strong&gt;Stable Diffusion XL&lt;/strong&gt; architecture, is now in a state of limited long-term support (LTS) with bug fixes only. As the existing functionalities are considered as nearly free of programmartic issues (Thanks to &lt;a href="https://github.com/mashb1t"&gt;mashb1t&lt;/a&gt;'s huge efforts), future updates will focus exclusively on addressing any bugs that may arise.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;There are no current plans to migrate to or incorporate newer model architectures.&lt;/strong&gt; However, this may change during time with the development of open-source community. For example, if the community converge to one single dominant method for image generation (which may really happen in half or one years given the current status), Fooocus may also migrate to that exact method.&lt;/p&gt; 
&lt;p&gt;For those interested in utilizing newer models such as &lt;strong&gt;Flux&lt;/strong&gt;, we recommend exploring alternative platforms such as &lt;a href="https://github.com/lllyasviel/stable-diffusion-webui-forge"&gt;WebUI Forge&lt;/a&gt; (also from us), &lt;a href="https://github.com/comfyanonymous/ComfyUI"&gt;ComfyUI/SwarmUI&lt;/a&gt;. Additionally, several &lt;a href="https://github.com/lllyasviel/Fooocus?tab=readme-ov-file#forks"&gt;excellent forks of Fooocus&lt;/a&gt; are available for experimentation.&lt;/p&gt; 
&lt;p&gt;Again, recently many fake websites exist on Google when you search â€œfooocusâ€. Do &lt;strong&gt;NOT&lt;/strong&gt; get Fooocus from those websites â€“ this page is the only official source of Fooocus. We never have any website like such as â€œfooocus.comâ€, â€œfooocus.netâ€, â€œfooocus.coâ€, â€œfooocus.aiâ€, â€œfooocus.orgâ€, â€œfooocus.proâ€, â€œfooocus.oneâ€. Those websites are ALL FAKE. &lt;strong&gt;They have ABSOLUTLY no relationship to us. Fooocus is a 100% non-commercial offline open-source software.&lt;/strong&gt;&lt;/p&gt; 
&lt;h1&gt;Features&lt;/h1&gt; 
&lt;p&gt;Below is a quick list using Midjourney's examples:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Midjourney&lt;/th&gt; 
   &lt;th&gt;Fooocus&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;High-quality text-to-image without needing much prompt engineering or parameter tuning. &lt;br /&gt; (Unknown method)&lt;/td&gt; 
   &lt;td&gt;High-quality text-to-image without needing much prompt engineering or parameter tuning. &lt;br /&gt; (Fooocus has an offline GPT-2 based prompt processing engine and lots of sampling improvements so that results are always beautiful, no matter if your prompt is as short as â€œhouse in gardenâ€ or as long as 1000 words)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;V1 V2 V3 V4&lt;/td&gt; 
   &lt;td&gt;Input Image -&amp;gt; Upscale or Variation -&amp;gt; Vary (Subtle) / Vary (Strong)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;U1 U2 U3 U4&lt;/td&gt; 
   &lt;td&gt;Input Image -&amp;gt; Upscale or Variation -&amp;gt; Upscale (1.5x) / Upscale (2x)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Inpaint / Up / Down / Left / Right (Pan)&lt;/td&gt; 
   &lt;td&gt;Input Image -&amp;gt; Inpaint or Outpaint -&amp;gt; Inpaint / Up / Down / Left / Right &lt;br /&gt; (Fooocus uses its own inpaint algorithm and inpaint models so that results are more satisfying than all other software that uses standard SDXL inpaint method/model)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Image Prompt&lt;/td&gt; 
   &lt;td&gt;Input Image -&amp;gt; Image Prompt &lt;br /&gt; (Fooocus uses its own image prompt algorithm so that result quality and prompt understanding are more satisfying than all other software that uses standard SDXL methods like standard IP-Adapters or Revisions)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;--style&lt;/td&gt; 
   &lt;td&gt;Advanced -&amp;gt; Style&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;--stylize&lt;/td&gt; 
   &lt;td&gt;Advanced -&amp;gt; Advanced -&amp;gt; Guidance&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;--niji&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/lllyasviel/Fooocus/discussions/679"&gt;Multiple launchers: "run.bat", "run_anime.bat", and "run_realistic.bat".&lt;/a&gt; &lt;br /&gt; Fooocus support SDXL models on Civitai &lt;br /&gt; (You can google search â€œCivitaiâ€ if you do not know about it)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;--quality&lt;/td&gt; 
   &lt;td&gt;Advanced -&amp;gt; Quality&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;--repeat&lt;/td&gt; 
   &lt;td&gt;Advanced -&amp;gt; Image Number&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Multi Prompts (::)&lt;/td&gt; 
   &lt;td&gt;Just use multiple lines of prompts&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Prompt Weights&lt;/td&gt; 
   &lt;td&gt;You can use " I am (happy:1.5)". &lt;br /&gt; Fooocus uses A1111's reweighting algorithm so that results are better than ComfyUI if users directly copy prompts from Civitai. (Because if prompts are written in ComfyUI's reweighting, users are less likely to copy prompt texts as they prefer dragging files) &lt;br /&gt; To use embedding, you can use "(embedding:file_name:1.1)"&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;--no&lt;/td&gt; 
   &lt;td&gt;Advanced -&amp;gt; Negative Prompt&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;--ar&lt;/td&gt; 
   &lt;td&gt;Advanced -&amp;gt; Aspect Ratios&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;InsightFace&lt;/td&gt; 
   &lt;td&gt;Input Image -&amp;gt; Image Prompt -&amp;gt; Advanced -&amp;gt; FaceSwap&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Describe&lt;/td&gt; 
   &lt;td&gt;Input Image -&amp;gt; Describe&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Below is a quick list using LeonardoAI's examples:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;LeonardoAI&lt;/th&gt; 
   &lt;th&gt;Fooocus&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Prompt Magic&lt;/td&gt; 
   &lt;td&gt;Advanced -&amp;gt; Style -&amp;gt; Fooocus V2&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Advanced Sampler Parameters (like Contrast/Sharpness/etc)&lt;/td&gt; 
   &lt;td&gt;Advanced -&amp;gt; Advanced -&amp;gt; Sampling Sharpness / etc&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;User-friendly ControlNets&lt;/td&gt; 
   &lt;td&gt;Input Image -&amp;gt; Image Prompt -&amp;gt; Advanced&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Also, &lt;a href="https://github.com/lllyasviel/Fooocus/discussions/117"&gt;click here to browse the advanced features.&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Download&lt;/h1&gt; 
&lt;h3&gt;Windows&lt;/h3&gt; 
&lt;p&gt;You can directly download Fooocus with:&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://github.com/lllyasviel/Fooocus/releases/download/v2.5.0/Fooocus_win64_2-5-0.7z"&gt;&amp;gt;&amp;gt;&amp;gt; Click here to download &amp;lt;&amp;lt;&amp;lt;&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;After you download the file, please uncompress it and then run the "run.bat".&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/lllyasviel/Fooocus/assets/19834515/c49269c4-c274-4893-b368-047c401cc58c" alt="image" /&gt;&lt;/p&gt; 
&lt;p&gt;The first time you launch the software, it will automatically download models:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;It will download &lt;a href="https://raw.githubusercontent.com/lllyasviel/Fooocus/main/#models"&gt;default models&lt;/a&gt; to the folder "Fooocus\models\checkpoints" given different presets. You can download them in advance if you do not want automatic download.&lt;/li&gt; 
 &lt;li&gt;Note that if you use inpaint, at the first time you inpaint an image, it will download &lt;a href="https://huggingface.co/lllyasviel/fooocus_inpaint/resolve/main/inpaint_v26.fooocus.patch"&gt;Fooocus's own inpaint control model from here&lt;/a&gt; as the file "Fooocus\models\inpaint\inpaint_v26.fooocus.patch" (the size of this file is 1.28GB).&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;After Fooocus 2.1.60, you will also have &lt;code&gt;run_anime.bat&lt;/code&gt; and &lt;code&gt;run_realistic.bat&lt;/code&gt;. They are different model presets (and require different models, but they will be automatically downloaded). &lt;a href="https://github.com/lllyasviel/Fooocus/discussions/679"&gt;Check here for more details&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;After Fooocus 2.3.0 you can also switch presets directly in the browser. Keep in mind to add these arguments if you want to change the default behavior:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Use &lt;code&gt;--disable-preset-selection&lt;/code&gt; to disable preset selection in the browser.&lt;/li&gt; 
 &lt;li&gt;Use &lt;code&gt;--always-download-new-model&lt;/code&gt; to download missing models on preset switch. Default is fallback to &lt;code&gt;previous_default_models&lt;/code&gt; defined in the corresponding preset, also see terminal output.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://github.com/lllyasviel/Fooocus/assets/19834515/d386f817-4bd7-490c-ad89-c1e228c23447" alt="image" /&gt;&lt;/p&gt; 
&lt;p&gt;If you already have these files, you can copy them to the above locations to speed up installation.&lt;/p&gt; 
&lt;p&gt;Note that if you see &lt;strong&gt;"MetadataIncompleteBuffer" or "PytorchStreamReader"&lt;/strong&gt;, then your model files are corrupted. Please download models again.&lt;/p&gt; 
&lt;p&gt;Below is a test on a relatively low-end laptop with &lt;strong&gt;16GB System RAM&lt;/strong&gt; and &lt;strong&gt;6GB VRAM&lt;/strong&gt; (Nvidia 3060 laptop). The speed on this machine is about 1.35 seconds per iteration. Pretty impressive â€“ nowadays laptops with 3060 are usually at very acceptable price.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/lllyasviel/Fooocus/assets/19834515/938737a5-b105-4f19-b051-81356cb7c495" alt="image" /&gt;&lt;/p&gt; 
&lt;p&gt;Besides, recently many other software report that Nvidia driver above 532 is sometimes 10x slower than Nvidia driver 531. If your generation time is very long, consider download &lt;a href="https://www.nvidia.com/download/driverResults.aspx/199991/en-us/"&gt;Nvidia Driver 531 Laptop&lt;/a&gt; or &lt;a href="https://www.nvidia.com/download/driverResults.aspx/199990/en-us/"&gt;Nvidia Driver 531 Desktop&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Note that the minimal requirement is &lt;strong&gt;4GB Nvidia GPU memory (4GB VRAM)&lt;/strong&gt; and &lt;strong&gt;8GB system memory (8GB RAM)&lt;/strong&gt;. This requires using Microsoftâ€™s Virtual Swap technique, which is automatically enabled by your Windows installation in most cases, so you often do not need to do anything about it. However, if you are not sure, or if you manually turned it off (would anyone really do that?), or &lt;strong&gt;if you see any "RuntimeError: CPUAllocator"&lt;/strong&gt;, you can enable it here:&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;Click here to see the image instructions. &lt;/summary&gt; 
 &lt;p&gt;&lt;img src="https://github.com/lllyasviel/Fooocus/assets/19834515/2a06b130-fe9b-4504-94f1-2763be4476e9" alt="image" /&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;And make sure that you have at least 40GB free space on each drive if you still see "RuntimeError: CPUAllocator" !&lt;/strong&gt;&lt;/p&gt; 
&lt;/details&gt; 
&lt;p&gt;Please open an issue if you use similar devices but still cannot achieve acceptable performances.&lt;/p&gt; 
&lt;p&gt;Note that the &lt;a href="https://raw.githubusercontent.com/lllyasviel/Fooocus/main/#minimal-requirement"&gt;minimal requirement&lt;/a&gt; for different platforms is different.&lt;/p&gt; 
&lt;p&gt;See also the common problems and troubleshoots &lt;a href="https://raw.githubusercontent.com/lllyasviel/Fooocus/main/troubleshoot.md"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Colab&lt;/h3&gt; 
&lt;p&gt;(Last tested - 2024 Aug 12 by &lt;a href="https://github.com/mashb1t"&gt;mashb1t&lt;/a&gt;)&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Colab&lt;/th&gt; 
   &lt;th&gt;Info&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://colab.research.google.com/github/lllyasviel/Fooocus/blob/main/fooocus_colab.ipynb"&gt;&lt;img src="https://colab.research.google.com/assets/colab-badge.svg?sanitize=true" alt="Open In Colab" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Fooocus Official&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;In Colab, you can modify the last line to &lt;code&gt;!python entry_with_update.py --share --always-high-vram&lt;/code&gt; or &lt;code&gt;!python entry_with_update.py --share --always-high-vram --preset anime&lt;/code&gt; or &lt;code&gt;!python entry_with_update.py --share --always-high-vram --preset realistic&lt;/code&gt; for Fooocus Default/Anime/Realistic Edition.&lt;/p&gt; 
&lt;p&gt;You can also change the preset in the UI. Please be aware that this may lead to timeouts after 60 seconds. If this is the case, please wait until the download has finished, change the preset to initial and back to the one you've selected or reload the page.&lt;/p&gt; 
&lt;p&gt;Note that this Colab will disable refiner by default because Colab free's resources are relatively limited (and some "big" features like image prompt may cause free-tier Colab to disconnect). We make sure that basic text-to-image is always working on free-tier Colab.&lt;/p&gt; 
&lt;p&gt;Using &lt;code&gt;--always-high-vram&lt;/code&gt; shifts resource allocation from RAM to VRAM and achieves the overall best balance between performance, flexibility and stability on the default T4 instance. Please find more information &lt;a href="https://github.com/lllyasviel/Fooocus/pull/1710#issuecomment-1989185346"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Thanks to &lt;a href="https://github.com/camenduru"&gt;camenduru&lt;/a&gt; for the template!&lt;/p&gt; 
&lt;h3&gt;Linux (Using Anaconda)&lt;/h3&gt; 
&lt;p&gt;If you want to use Anaconda/Miniconda, you can&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;git clone https://github.com/lllyasviel/Fooocus.git
cd Fooocus
conda env create -f environment.yaml
conda activate fooocus
pip install -r requirements_versions.txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then download the models: download &lt;a href="https://raw.githubusercontent.com/lllyasviel/Fooocus/main/#models"&gt;default models&lt;/a&gt; to the folder "Fooocus\models\checkpoints". &lt;strong&gt;Or let Fooocus automatically download the models&lt;/strong&gt; using the launcher:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;conda activate fooocus
python entry_with_update.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or, if you want to open a remote port, use&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;conda activate fooocus
python entry_with_update.py --listen
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Use &lt;code&gt;python entry_with_update.py --preset anime&lt;/code&gt; or &lt;code&gt;python entry_with_update.py --preset realistic&lt;/code&gt; for Fooocus Anime/Realistic Edition.&lt;/p&gt; 
&lt;h3&gt;Linux (Using Python Venv)&lt;/h3&gt; 
&lt;p&gt;Your Linux needs to have &lt;strong&gt;Python 3.10&lt;/strong&gt; installed, and let's say your Python can be called with the command &lt;strong&gt;python3&lt;/strong&gt; with your venv system working; you can&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;git clone https://github.com/lllyasviel/Fooocus.git
cd Fooocus
python3 -m venv fooocus_env
source fooocus_env/bin/activate
pip install -r requirements_versions.txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See the above sections for model downloads. You can launch the software with:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;source fooocus_env/bin/activate
python entry_with_update.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or, if you want to open a remote port, use&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;source fooocus_env/bin/activate
python entry_with_update.py --listen
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Use &lt;code&gt;python entry_with_update.py --preset anime&lt;/code&gt; or &lt;code&gt;python entry_with_update.py --preset realistic&lt;/code&gt; for Fooocus Anime/Realistic Edition.&lt;/p&gt; 
&lt;h3&gt;Linux (Using native system Python)&lt;/h3&gt; 
&lt;p&gt;If you know what you are doing, and your Linux already has &lt;strong&gt;Python 3.10&lt;/strong&gt; installed, and your Python can be called with the command &lt;strong&gt;python3&lt;/strong&gt; (and Pip with &lt;strong&gt;pip3&lt;/strong&gt;), you can&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;git clone https://github.com/lllyasviel/Fooocus.git
cd Fooocus
pip3 install -r requirements_versions.txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See the above sections for model downloads. You can launch the software with:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;python3 entry_with_update.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or, if you want to open a remote port, use&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;python3 entry_with_update.py --listen
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Use &lt;code&gt;python entry_with_update.py --preset anime&lt;/code&gt; or &lt;code&gt;python entry_with_update.py --preset realistic&lt;/code&gt; for Fooocus Anime/Realistic Edition.&lt;/p&gt; 
&lt;h3&gt;Linux (AMD GPUs)&lt;/h3&gt; 
&lt;p&gt;Note that the &lt;a href="https://raw.githubusercontent.com/lllyasviel/Fooocus/main/#minimal-requirement"&gt;minimal requirement&lt;/a&gt; for different platforms is different.&lt;/p&gt; 
&lt;p&gt;Same with the above instructions. You need to change torch to the AMD version&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;pip uninstall torch torchvision torchaudio torchtext functorch xformers 
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/rocm5.6
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;AMD is not intensively tested, however. The AMD support is in beta.&lt;/p&gt; 
&lt;p&gt;Use &lt;code&gt;python entry_with_update.py --preset anime&lt;/code&gt; or &lt;code&gt;python entry_with_update.py --preset realistic&lt;/code&gt; for Fooocus Anime/Realistic Edition.&lt;/p&gt; 
&lt;h3&gt;Windows (AMD GPUs)&lt;/h3&gt; 
&lt;p&gt;Note that the &lt;a href="https://raw.githubusercontent.com/lllyasviel/Fooocus/main/#minimal-requirement"&gt;minimal requirement&lt;/a&gt; for different platforms is different.&lt;/p&gt; 
&lt;p&gt;Same with Windows. Download the software and edit the content of &lt;code&gt;run.bat&lt;/code&gt; as:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;.\python_embeded\python.exe -m pip uninstall torch torchvision torchaudio torchtext functorch xformers -y
.\python_embeded\python.exe -m pip install torch-directml
.\python_embeded\python.exe -s Fooocus\entry_with_update.py --directml
pause
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then run the &lt;code&gt;run.bat&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;AMD is not intensively tested, however. The AMD support is in beta.&lt;/p&gt; 
&lt;p&gt;For AMD, use &lt;code&gt;.\python_embeded\python.exe Fooocus\entry_with_update.py --directml --preset anime&lt;/code&gt; or &lt;code&gt;.\python_embeded\python.exe Fooocus\entry_with_update.py --directml --preset realistic&lt;/code&gt; for Fooocus Anime/Realistic Edition.&lt;/p&gt; 
&lt;h3&gt;Mac&lt;/h3&gt; 
&lt;p&gt;Note that the &lt;a href="https://raw.githubusercontent.com/lllyasviel/Fooocus/main/#minimal-requirement"&gt;minimal requirement&lt;/a&gt; for different platforms is different.&lt;/p&gt; 
&lt;p&gt;Mac is not intensively tested. Below is an unofficial guideline for using Mac. You can discuss problems &lt;a href="https://github.com/lllyasviel/Fooocus/pull/129"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;You can install Fooocus on Apple Mac silicon (M1 or M2) with macOS 'Catalina' or a newer version. Fooocus runs on Apple silicon computers via &lt;a href="https://pytorch.org/get-started/locally/"&gt;PyTorch&lt;/a&gt; MPS device acceleration. Mac Silicon computers don't come with a dedicated graphics card, resulting in significantly longer image processing times compared to computers with dedicated graphics cards.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Install the conda package manager and pytorch nightly. Read the &lt;a href="https://developer.apple.com/metal/pytorch/"&gt;Accelerated PyTorch training on Mac&lt;/a&gt; Apple Developer guide for instructions. Make sure pytorch recognizes your MPS device.&lt;/li&gt; 
 &lt;li&gt;Open the macOS Terminal app and clone this repository with &lt;code&gt;git clone https://github.com/lllyasviel/Fooocus.git&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Change to the new Fooocus directory, &lt;code&gt;cd Fooocus&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Create a new conda environment, &lt;code&gt;conda env create -f environment.yaml&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Activate your new conda environment, &lt;code&gt;conda activate fooocus&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Install the packages required by Fooocus, &lt;code&gt;pip install -r requirements_versions.txt&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Launch Fooocus by running &lt;code&gt;python entry_with_update.py&lt;/code&gt;. (Some Mac M2 users may need &lt;code&gt;python entry_with_update.py --disable-offload-from-vram&lt;/code&gt; to speed up model loading/unloading.) The first time you run Fooocus, it will automatically download the Stable Diffusion SDXL models and will take a significant amount of time, depending on your internet connection.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Use &lt;code&gt;python entry_with_update.py --preset anime&lt;/code&gt; or &lt;code&gt;python entry_with_update.py --preset realistic&lt;/code&gt; for Fooocus Anime/Realistic Edition.&lt;/p&gt; 
&lt;h3&gt;Docker&lt;/h3&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/lllyasviel/Fooocus/main/docker.md"&gt;docker.md&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Download Previous Version&lt;/h3&gt; 
&lt;p&gt;See the guidelines &lt;a href="https://github.com/lllyasviel/Fooocus/discussions/1405"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Minimal Requirement&lt;/h2&gt; 
&lt;p&gt;Below is the minimal requirement for running Fooocus locally. If your device capability is lower than this spec, you may not be able to use Fooocus locally. (Please let us know, in any case, if your device capability is lower but Fooocus still works.)&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Operating System&lt;/th&gt; 
   &lt;th&gt;GPU&lt;/th&gt; 
   &lt;th&gt;Minimal GPU Memory&lt;/th&gt; 
   &lt;th&gt;Minimal System Memory&lt;/th&gt; 
   &lt;th&gt;&lt;a href="https://raw.githubusercontent.com/lllyasviel/Fooocus/main/troubleshoot.md"&gt;System Swap&lt;/a&gt;&lt;/th&gt; 
   &lt;th&gt;Note&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Windows/Linux&lt;/td&gt; 
   &lt;td&gt;Nvidia RTX 4XXX&lt;/td&gt; 
   &lt;td&gt;4GB&lt;/td&gt; 
   &lt;td&gt;8GB&lt;/td&gt; 
   &lt;td&gt;Required&lt;/td&gt; 
   &lt;td&gt;fastest&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Windows/Linux&lt;/td&gt; 
   &lt;td&gt;Nvidia RTX 3XXX&lt;/td&gt; 
   &lt;td&gt;4GB&lt;/td&gt; 
   &lt;td&gt;8GB&lt;/td&gt; 
   &lt;td&gt;Required&lt;/td&gt; 
   &lt;td&gt;usually faster than RTX 2XXX&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Windows/Linux&lt;/td&gt; 
   &lt;td&gt;Nvidia RTX 2XXX&lt;/td&gt; 
   &lt;td&gt;4GB&lt;/td&gt; 
   &lt;td&gt;8GB&lt;/td&gt; 
   &lt;td&gt;Required&lt;/td&gt; 
   &lt;td&gt;usually faster than GTX 1XXX&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Windows/Linux&lt;/td&gt; 
   &lt;td&gt;Nvidia GTX 1XXX&lt;/td&gt; 
   &lt;td&gt;8GB (* 6GB uncertain)&lt;/td&gt; 
   &lt;td&gt;8GB&lt;/td&gt; 
   &lt;td&gt;Required&lt;/td&gt; 
   &lt;td&gt;only marginally faster than CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Windows/Linux&lt;/td&gt; 
   &lt;td&gt;Nvidia GTX 9XX&lt;/td&gt; 
   &lt;td&gt;8GB&lt;/td&gt; 
   &lt;td&gt;8GB&lt;/td&gt; 
   &lt;td&gt;Required&lt;/td&gt; 
   &lt;td&gt;faster or slower than CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Windows/Linux&lt;/td&gt; 
   &lt;td&gt;Nvidia GTX &amp;lt; 9XX&lt;/td&gt; 
   &lt;td&gt;Not supported&lt;/td&gt; 
   &lt;td&gt;/&lt;/td&gt; 
   &lt;td&gt;/&lt;/td&gt; 
   &lt;td&gt;/&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Windows&lt;/td&gt; 
   &lt;td&gt;AMD GPU&lt;/td&gt; 
   &lt;td&gt;8GB (updated 2023 Dec 30)&lt;/td&gt; 
   &lt;td&gt;8GB&lt;/td&gt; 
   &lt;td&gt;Required&lt;/td&gt; 
   &lt;td&gt;via DirectML (* ROCm is on hold), about 3x slower than Nvidia RTX 3XXX&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
   &lt;td&gt;AMD GPU&lt;/td&gt; 
   &lt;td&gt;8GB&lt;/td&gt; 
   &lt;td&gt;8GB&lt;/td&gt; 
   &lt;td&gt;Required&lt;/td&gt; 
   &lt;td&gt;via ROCm, about 1.5x slower than Nvidia RTX 3XXX&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Mac&lt;/td&gt; 
   &lt;td&gt;M1/M2 MPS&lt;/td&gt; 
   &lt;td&gt;Shared&lt;/td&gt; 
   &lt;td&gt;Shared&lt;/td&gt; 
   &lt;td&gt;Shared&lt;/td&gt; 
   &lt;td&gt;about 9x slower than Nvidia RTX 3XXX&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Windows/Linux/Mac&lt;/td&gt; 
   &lt;td&gt;only use CPU&lt;/td&gt; 
   &lt;td&gt;0GB&lt;/td&gt; 
   &lt;td&gt;32GB&lt;/td&gt; 
   &lt;td&gt;Required&lt;/td&gt; 
   &lt;td&gt;about 17x slower than Nvidia RTX 3XXX&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;* AMD GPU ROCm (on hold): The AMD is still working on supporting ROCm on Windows.&lt;/p&gt; 
&lt;p&gt;* Nvidia GTX 1XXX 6GB uncertain: Some people report 6GB success on GTX 10XX, but some other people report failure cases.&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;Note that Fooocus is only for extremely high quality image generating. We will not support smaller models to reduce the requirement and sacrifice result quality.&lt;/em&gt;&lt;/p&gt; 
&lt;h2&gt;Troubleshoot&lt;/h2&gt; 
&lt;p&gt;See the common problems &lt;a href="https://raw.githubusercontent.com/lllyasviel/Fooocus/main/troubleshoot.md"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Default Models&lt;/h2&gt; 
&lt;p&gt;&lt;a name="models"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Given different goals, the default models and configs of Fooocus are different:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Task&lt;/th&gt; 
   &lt;th&gt;Windows&lt;/th&gt; 
   &lt;th&gt;Linux args&lt;/th&gt; 
   &lt;th&gt;Main Model&lt;/th&gt; 
   &lt;th&gt;Refiner&lt;/th&gt; 
   &lt;th&gt;Config&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;General&lt;/td&gt; 
   &lt;td&gt;run.bat&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;juggernautXL_v8Rundiffusion&lt;/td&gt; 
   &lt;td&gt;not used&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/lllyasviel/Fooocus/raw/main/presets/default.json"&gt;here&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Realistic&lt;/td&gt; 
   &lt;td&gt;run_realistic.bat&lt;/td&gt; 
   &lt;td&gt;--preset realistic&lt;/td&gt; 
   &lt;td&gt;realisticStockPhoto_v20&lt;/td&gt; 
   &lt;td&gt;not used&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/lllyasviel/Fooocus/raw/main/presets/realistic.json"&gt;here&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Anime&lt;/td&gt; 
   &lt;td&gt;run_anime.bat&lt;/td&gt; 
   &lt;td&gt;--preset anime&lt;/td&gt; 
   &lt;td&gt;animaPencilXL_v500&lt;/td&gt; 
   &lt;td&gt;not used&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/lllyasviel/Fooocus/raw/main/presets/anime.json"&gt;here&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Note that the download is &lt;strong&gt;automatic&lt;/strong&gt; - you do not need to do anything if the internet connection is okay. However, you can download them manually if you (or move them from somewhere else) have your own preparation.&lt;/p&gt; 
&lt;h2&gt;UI Access and Authentication&lt;/h2&gt; 
&lt;p&gt;In addition to running on localhost, Fooocus can also expose its UI in two ways:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Local UI listener: use &lt;code&gt;--listen&lt;/code&gt; (specify port e.g. with &lt;code&gt;--port 8888&lt;/code&gt;).&lt;/li&gt; 
 &lt;li&gt;API access: use &lt;code&gt;--share&lt;/code&gt; (registers an endpoint at &lt;code&gt;.gradio.live&lt;/code&gt;).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;In both ways the access is unauthenticated by default. You can add basic authentication by creating a file called &lt;code&gt;auth.json&lt;/code&gt; in the main directory, which contains a list of JSON objects with the keys &lt;code&gt;user&lt;/code&gt; and &lt;code&gt;pass&lt;/code&gt; (see example in &lt;a href="https://raw.githubusercontent.com/lllyasviel/Fooocus/main/auth-example.json"&gt;auth-example.json&lt;/a&gt;).&lt;/p&gt; 
&lt;h2&gt;List of "Hidden" Tricks&lt;/h2&gt; 
&lt;p&gt;&lt;a name="tech_list"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;Click to see a list of tricks. Those are based on SDXL and are not very up-to-date with latest models.&lt;/summary&gt; 
 &lt;ol&gt; 
  &lt;li&gt;GPT2-based &lt;a href="https://github.com/lllyasviel/Fooocus/discussions/117#raw"&gt;prompt expansion as a dynamic style "Fooocus V2".&lt;/a&gt; (similar to Midjourney's hidden pre-processing and "raw" mode, or the LeonardoAI's Prompt Magic).&lt;/li&gt; 
  &lt;li&gt;Native refiner swap inside one single k-sampler. The advantage is that the refiner model can now reuse the base model's momentum (or ODE's history parameters) collected from k-sampling to achieve more coherent sampling. In Automatic1111's high-res fix and ComfyUI's node system, the base model and refiner use two independent k-samplers, which means the momentum is largely wasted, and the sampling continuity is broken. Fooocus uses its own advanced k-diffusion sampling that ensures seamless, native, and continuous swap in a refiner setup. (Update Aug 13: Actually, I discussed this with Automatic1111 several days ago, and it seems that the â€œnative refiner swap inside one single k-samplerâ€ is &lt;a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/pull/12371"&gt;merged&lt;/a&gt; into the dev branch of webui. Great!)&lt;/li&gt; 
  &lt;li&gt;Negative ADM guidance. Because the highest resolution level of XL Base does not have cross attentions, the positive and negative signals for XL's highest resolution level cannot receive enough contrasts during the CFG sampling, causing the results to look a bit plastic or overly smooth in certain cases. Fortunately, since the XL's highest resolution level is still conditioned on image aspect ratios (ADM), we can modify the adm on the positive/negative side to compensate for the lack of CFG contrast in the highest resolution level. (Update Aug 16, the IOS App &lt;a href="https://apps.apple.com/us/app/draw-things-ai-generation/id6444050820"&gt;Draw Things&lt;/a&gt; will support Negative ADM Guidance. Great!)&lt;/li&gt; 
  &lt;li&gt;We implemented a carefully tuned variation of Section 5.1 of &lt;a href="https://arxiv.org/pdf/2210.00939.pdf"&gt;"Improving Sample Quality of Diffusion Models Using Self-Attention Guidance"&lt;/a&gt;. The weight is set to very low, but this is Fooocus's final guarantee to make sure that the XL will never yield an overly smooth or plastic appearance (examples &lt;a href="https://github.com/lllyasviel/Fooocus/discussions/117#sharpness"&gt;here&lt;/a&gt;). This can almost eliminate all cases for which XL still occasionally produces overly smooth results, even with negative ADM guidance. (Update 2023 Aug 18, the Gaussian kernel of SAG is changed to an anisotropic kernel for better structure preservation and fewer artifacts.)&lt;/li&gt; 
  &lt;li&gt;We modified the style templates a bit and added the "cinematic-default".&lt;/li&gt; 
  &lt;li&gt;We tested the "sd_xl_offset_example-lora_1.0.safetensors" and it seems that when the lora weight is below 0.5, the results are always better than XL without lora.&lt;/li&gt; 
  &lt;li&gt;The parameters of samplers are carefully tuned.&lt;/li&gt; 
  &lt;li&gt;Because XL uses positional encoding for generation resolution, images generated by several fixed resolutions look a bit better than those from arbitrary resolutions (because the positional encoding is not very good at handling int numbers that are unseen during training). This suggests that the resolutions in UI may be hard coded for best results.&lt;/li&gt; 
  &lt;li&gt;Separated prompts for two different text encoders seem unnecessary. Separated prompts for the base model and refiner may work, but the effects are random, and we refrain from implementing this.&lt;/li&gt; 
  &lt;li&gt;The DPM family seems well-suited for XL since XL sometimes generates overly smooth texture, but the DPM family sometimes generates overly dense detail in texture. Their joint effect looks neutral and appealing to human perception.&lt;/li&gt; 
  &lt;li&gt;A carefully designed system for balancing multiple styles as well as prompt expansion.&lt;/li&gt; 
  &lt;li&gt;Using automatic1111's method to normalize prompt emphasizing. This significantly improves results when users directly copy prompts from civitai.&lt;/li&gt; 
  &lt;li&gt;The joint swap system of the refiner now also supports img2img and upscale in a seamless way.&lt;/li&gt; 
  &lt;li&gt;CFG Scale and TSNR correction (tuned for SDXL) when CFG is bigger than 10.&lt;/li&gt; 
 &lt;/ol&gt; 
&lt;/details&gt; 
&lt;h2&gt;Customization&lt;/h2&gt; 
&lt;p&gt;After the first time you run Fooocus, a config file will be generated at &lt;code&gt;Fooocus\config.txt&lt;/code&gt;. This file can be edited to change the model path or default parameters.&lt;/p&gt; 
&lt;p&gt;For example, an edited &lt;code&gt;Fooocus\config.txt&lt;/code&gt; (this file will be generated after the first launch) may look like this:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
    "path_checkpoints": "D:\\Fooocus\\models\\checkpoints",
    "path_loras": "D:\\Fooocus\\models\\loras",
    "path_embeddings": "D:\\Fooocus\\models\\embeddings",
    "path_vae_approx": "D:\\Fooocus\\models\\vae_approx",
    "path_upscale_models": "D:\\Fooocus\\models\\upscale_models",
    "path_inpaint": "D:\\Fooocus\\models\\inpaint",
    "path_controlnet": "D:\\Fooocus\\models\\controlnet",
    "path_clip_vision": "D:\\Fooocus\\models\\clip_vision",
    "path_fooocus_expansion": "D:\\Fooocus\\models\\prompt_expansion\\fooocus_expansion",
    "path_outputs": "D:\\Fooocus\\outputs",
    "default_model": "realisticStockPhoto_v10.safetensors",
    "default_refiner": "",
    "default_loras": [["lora_filename_1.safetensors", 0.5], ["lora_filename_2.safetensors", 0.5]],
    "default_cfg_scale": 3.0,
    "default_sampler": "dpmpp_2m",
    "default_scheduler": "karras",
    "default_negative_prompt": "low quality",
    "default_positive_prompt": "",
    "default_styles": [
        "Fooocus V2",
        "Fooocus Photograph",
        "Fooocus Negative"
    ]
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Many other keys, formats, and examples are in &lt;code&gt;Fooocus\config_modification_tutorial.txt&lt;/code&gt; (this file will be generated after the first launch).&lt;/p&gt; 
&lt;p&gt;Consider twice before you really change the config. If you find yourself breaking things, just delete &lt;code&gt;Fooocus\config.txt&lt;/code&gt;. Fooocus will go back to default.&lt;/p&gt; 
&lt;p&gt;A safer way is just to try "run_anime.bat" or "run_realistic.bat" - they should already be good enough for different tasks.&lt;/p&gt; 
&lt;p&gt;&lt;del&gt;Note that &lt;code&gt;user_path_config.txt&lt;/code&gt; is deprecated and will be removed soon.&lt;/del&gt; (Edit: it is already removed.)&lt;/p&gt; 
&lt;h3&gt;All CMD Flags&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;entry_with_update.py  [-h] [--listen [IP]] [--port PORT]
                      [--disable-header-check [ORIGIN]]
                      [--web-upload-size WEB_UPLOAD_SIZE]
                      [--hf-mirror HF_MIRROR]
                      [--external-working-path PATH [PATH ...]]
                      [--output-path OUTPUT_PATH]
                      [--temp-path TEMP_PATH] [--cache-path CACHE_PATH]
                      [--in-browser] [--disable-in-browser]
                      [--gpu-device-id DEVICE_ID]
                      [--async-cuda-allocation | --disable-async-cuda-allocation]
                      [--disable-attention-upcast]
                      [--all-in-fp32 | --all-in-fp16]
                      [--unet-in-bf16 | --unet-in-fp16 | --unet-in-fp8-e4m3fn | --unet-in-fp8-e5m2]
                      [--vae-in-fp16 | --vae-in-fp32 | --vae-in-bf16]
                      [--vae-in-cpu]
                      [--clip-in-fp8-e4m3fn | --clip-in-fp8-e5m2 | --clip-in-fp16 | --clip-in-fp32]
                      [--directml [DIRECTML_DEVICE]]
                      [--disable-ipex-hijack]
                      [--preview-option [none,auto,fast,taesd]]
                      [--attention-split | --attention-quad | --attention-pytorch]
                      [--disable-xformers]
                      [--always-gpu | --always-high-vram | --always-normal-vram | --always-low-vram | --always-no-vram | --always-cpu [CPU_NUM_THREADS]]
                      [--always-offload-from-vram]
                      [--pytorch-deterministic] [--disable-server-log]
                      [--debug-mode] [--is-windows-embedded-python]
                      [--disable-server-info] [--multi-user] [--share]
                      [--preset PRESET] [--disable-preset-selection]
                      [--language LANGUAGE]
                      [--disable-offload-from-vram] [--theme THEME]
                      [--disable-image-log] [--disable-analytics]
                      [--disable-metadata] [--disable-preset-download]
                      [--disable-enhance-output-sorting]
                      [--enable-auto-describe-image]
                      [--always-download-new-model]
                      [--rebuild-hash-cache [CPU_NUM_THREADS]]
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Inline Prompt Features&lt;/h2&gt; 
&lt;h3&gt;Wildcards&lt;/h3&gt; 
&lt;p&gt;Example prompt: &lt;code&gt;__color__ flower&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;Processed for positive and negative prompt.&lt;/p&gt; 
&lt;p&gt;Selects a random wildcard from a predefined list of options, in this case the &lt;code&gt;wildcards/color.txt&lt;/code&gt; file. The wildcard will be replaced with a random color (randomness based on seed). You can also disable randomness and process a wildcard file from top to bottom by enabling the checkbox &lt;code&gt;Read wildcards in order&lt;/code&gt; in Developer Debug Mode.&lt;/p&gt; 
&lt;p&gt;Wildcards can be nested and combined, and multiple wildcards can be used in the same prompt (example see &lt;code&gt;wildcards/color_flower.txt&lt;/code&gt;).&lt;/p&gt; 
&lt;h3&gt;Array Processing&lt;/h3&gt; 
&lt;p&gt;Example prompt: &lt;code&gt;[[red, green, blue]] flower&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;Processed only for positive prompt.&lt;/p&gt; 
&lt;p&gt;Processes the array from left to right, generating a separate image for each element in the array. In this case 3 images would be generated, one for each color. Increase the image number to 3 to generate all 3 variants.&lt;/p&gt; 
&lt;p&gt;Arrays can not be nested, but multiple arrays can be used in the same prompt. Does support inline LoRAs as array elements!&lt;/p&gt; 
&lt;h3&gt;Inline LoRAs&lt;/h3&gt; 
&lt;p&gt;Example prompt: &lt;code&gt;flower &amp;lt;lora:sunflowers:1.2&amp;gt;&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;Processed only for positive prompt.&lt;/p&gt; 
&lt;p&gt;Applies a LoRA to the prompt. The LoRA file must be located in the &lt;code&gt;models/loras&lt;/code&gt; directory.&lt;/p&gt; 
&lt;h2&gt;Advanced Features&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://github.com/lllyasviel/Fooocus/discussions/117"&gt;Click here to browse the advanced features.&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Forks&lt;/h2&gt; 
&lt;p&gt;Below are some Forks to Fooocus:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Fooocus' forks&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/fenneishi/Fooocus-Control"&gt;fenneishi/Fooocus-Control&lt;/a&gt; &lt;br /&gt;&lt;a href="https://github.com/runew0lf/RuinedFooocus"&gt;runew0lf/RuinedFooocus&lt;/a&gt; &lt;br /&gt; &lt;a href="https://github.com/MoonRide303/Fooocus-MRE"&gt;MoonRide303/Fooocus-MRE&lt;/a&gt; &lt;br /&gt; &lt;a href="https://github.com/mashb1t/Fooocus"&gt;mashb1t/Fooocus&lt;/a&gt; &lt;br /&gt; and so on ...&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Thanks&lt;/h2&gt; 
&lt;p&gt;Many thanks to &lt;a href="https://github.com/twri"&gt;twri&lt;/a&gt; and &lt;a href="https://github.com/3Diva"&gt;3Diva&lt;/a&gt; and &lt;a href="https://github.com/K3nt3L"&gt;Marc K3nt3L&lt;/a&gt; for creating additional SDXL styles available in Fooocus.&lt;/p&gt; 
&lt;p&gt;The project starts from a mixture of &lt;a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui"&gt;Stable Diffusion WebUI&lt;/a&gt; and &lt;a href="https://github.com/comfyanonymous/ComfyUI"&gt;ComfyUI&lt;/a&gt; codebases.&lt;/p&gt; 
&lt;p&gt;Also, thanks &lt;a href="https://github.com/daswer123"&gt;daswer123&lt;/a&gt; for contributing the Canvas Zoom!&lt;/p&gt; 
&lt;h2&gt;Update Log&lt;/h2&gt; 
&lt;p&gt;The log is &lt;a href="https://raw.githubusercontent.com/lllyasviel/Fooocus/main/update_log.md"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Localization/Translation/I18N&lt;/h2&gt; 
&lt;p&gt;You can put json files in the &lt;code&gt;language&lt;/code&gt; folder to translate the user interface.&lt;/p&gt; 
&lt;p&gt;For example, below is the content of &lt;code&gt;Fooocus/language/example.json&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "Generate": "ç”Ÿæˆ",
  "Input Image": "å…¥åŠ›ç”»åƒ",
  "Advanced": "ê³ ê¸‰",
  "SAI 3D Model": "SAI 3D ModÃ¨le"
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you add &lt;code&gt;--language example&lt;/code&gt; arg, Fooocus will read &lt;code&gt;Fooocus/language/example.json&lt;/code&gt; to translate the UI.&lt;/p&gt; 
&lt;p&gt;For example, you can edit the ending line of Windows &lt;code&gt;run.bat&lt;/code&gt; as&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;.\python_embeded\python.exe -s Fooocus\entry_with_update.py --language example
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or &lt;code&gt;run_anime.bat&lt;/code&gt; as&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;.\python_embeded\python.exe -s Fooocus\entry_with_update.py --language example --preset anime
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or &lt;code&gt;run_realistic.bat&lt;/code&gt; as&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;.\python_embeded\python.exe -s Fooocus\entry_with_update.py --language example --preset realistic
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For practical translation, you may create your own file like &lt;code&gt;Fooocus/language/jp.json&lt;/code&gt; or &lt;code&gt;Fooocus/language/cn.json&lt;/code&gt; and then use flag &lt;code&gt;--language jp&lt;/code&gt; or &lt;code&gt;--language cn&lt;/code&gt;. Apparently, these files do not exist now. &lt;strong&gt;We need your help to create these files!&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Note that if no &lt;code&gt;--language&lt;/code&gt; is given and at the same time &lt;code&gt;Fooocus/language/default.json&lt;/code&gt; exists, Fooocus will always load &lt;code&gt;Fooocus/language/default.json&lt;/code&gt; for translation. By default, the file &lt;code&gt;Fooocus/language/default.json&lt;/code&gt; does not exist.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>myshell-ai/OpenVoice</title>
      <link>https://github.com/myshell-ai/OpenVoice</link>
      <description>&lt;p&gt;Instant voice cloning by MIT and MyShell. Audio foundation model.&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;img src="https://raw.githubusercontent.com/myshell-ai/OpenVoice/main/resources/openvoicelogo.jpg" width="400" /&gt; 
 &lt;p&gt;&lt;a href="https://arxiv.org/abs/2312.01479"&gt;Paper&lt;/a&gt; | &lt;a href="https://research.myshell.ai/open-voice"&gt;Website&lt;/a&gt; &lt;br /&gt; &lt;br /&gt; &lt;a href="https://trendshift.io/repositories/6161" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/6161" alt="myshell-ai%2FOpenVoice | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;Introduction&lt;/h2&gt; 
&lt;h3&gt;OpenVoice V1&lt;/h3&gt; 
&lt;p&gt;As we detailed in our &lt;a href="https://arxiv.org/abs/2312.01479"&gt;paper&lt;/a&gt; and &lt;a href="https://research.myshell.ai/open-voice"&gt;website&lt;/a&gt;, the advantages of OpenVoice are three-fold:&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;1. Accurate Tone Color Cloning.&lt;/strong&gt; OpenVoice can accurately clone the reference tone color and generate speech in multiple languages and accents.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2. Flexible Voice Style Control.&lt;/strong&gt; OpenVoice enables granular control over voice styles, such as emotion and accent, as well as other style parameters including rhythm, pauses, and intonation.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;3. Zero-shot Cross-lingual Voice Cloning.&lt;/strong&gt; Neither of the language of the generated speech nor the language of the reference speech needs to be presented in the massive-speaker multi-lingual training dataset.&lt;/p&gt; 
&lt;h3&gt;OpenVoice V2&lt;/h3&gt; 
&lt;p&gt;In April 2024, we released OpenVoice V2, which includes all features in V1 and has:&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;1. Better Audio Quality.&lt;/strong&gt; OpenVoice V2 adopts a different training strategy that delivers better audio quality.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2. Native Multi-lingual Support.&lt;/strong&gt; English, Spanish, French, Chinese, Japanese and Korean are natively supported in OpenVoice V2.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;3. Free Commercial Use.&lt;/strong&gt; Starting from April 2024, both V2 and V1 are released under MIT License. Free for commercial use.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/myshell-ai/OpenVoice/assets/40556743/3cba936f-82bf-476c-9e52-09f0f417bb2f"&gt;Video&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;OpenVoice has been powering the instant voice cloning capability of &lt;a href="https://app.myshell.ai/explore"&gt;myshell.ai&lt;/a&gt; since May 2023. Until Nov 2023, the voice cloning model has been used tens of millions of times by users worldwide, and witnessed the explosive user growth on the platform.&lt;/p&gt; 
&lt;h2&gt;Main Contributors&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.qinzy.tech"&gt;Zengyi Qin&lt;/a&gt; at MIT&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://wl-zhao.github.io"&gt;Wenliang Zhao&lt;/a&gt; at Tsinghua University&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://yuxumin.github.io"&gt;Xumin Yu&lt;/a&gt; at Tsinghua University&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://twitter.com/ethan_myshell"&gt;Ethan Sun&lt;/a&gt; at MyShell&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;How to Use&lt;/h2&gt; 
&lt;p&gt;Please see &lt;a href="https://raw.githubusercontent.com/myshell-ai/OpenVoice/main/docs/USAGE.md"&gt;usage&lt;/a&gt; for detailed instructions.&lt;/p&gt; 
&lt;h2&gt;Common Issues&lt;/h2&gt; 
&lt;p&gt;Please see &lt;a href="https://raw.githubusercontent.com/myshell-ai/OpenVoice/main/docs/QA.md"&gt;QA&lt;/a&gt; for common questions and answers. We will regularly update the question and answer list.&lt;/p&gt; 
&lt;h2&gt;Citation&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;@article{qin2023openvoice,
  title={OpenVoice: Versatile Instant Voice Cloning},
  author={Qin, Zengyi and Zhao, Wenliang and Yu, Xumin and Sun, Xin},
  journal={arXiv preprint arXiv:2312.01479},
  year={2023}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;OpenVoice V1 and V2 are MIT Licensed. Free for both commercial and research use.&lt;/p&gt; 
&lt;h2&gt;Acknowledgements&lt;/h2&gt; 
&lt;p&gt;This implementation is based on several excellent projects, &lt;a href="https://github.com/coqui-ai/TTS"&gt;TTS&lt;/a&gt;, &lt;a href="https://github.com/jaywalnut310/vits"&gt;VITS&lt;/a&gt;, and &lt;a href="https://github.com/daniilrobnikov/vits2"&gt;VITS2&lt;/a&gt;. Thanks for their awesome work!&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>searxng/searxng</title>
      <link>https://github.com/searxng/searxng</link>
      <description>&lt;p&gt;SearXNG is a free internet metasearch engine which aggregates results from various search services and databases. Users are neither tracked nor profiled.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;.. SPDX-License-Identifier: AGPL-3.0-or-later&lt;/p&gt; 
&lt;p&gt;.. _metasearch engine: &lt;a href="https://en.wikipedia.org/wiki/Metasearch_engine"&gt;https://en.wikipedia.org/wiki/Metasearch_engine&lt;/a&gt; .. _Installation guide: &lt;a href="https://docs.searxng.org/admin/installation.html"&gt;https://docs.searxng.org/admin/installation.html&lt;/a&gt; .. _Configuration guide: &lt;a href="https://docs.searxng.org/admin/settings/index.html"&gt;https://docs.searxng.org/admin/settings/index.html&lt;/a&gt; .. _CONTRIBUTING: &lt;a href="https://github.com/searxng/searxng/raw/master/CONTRIBUTING.rst"&gt;https://github.com/searxng/searxng/blob/master/CONTRIBUTING.rst&lt;/a&gt; .. _LICENSE: &lt;a href="https://github.com/searxng/searxng/raw/master/LICENSE"&gt;https://github.com/searxng/searxng/blob/master/LICENSE&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;.. figure:: &lt;a href="https://raw.githubusercontent.com/searxng/searxng/master/client/simple/src/brand/searxng.svg"&gt;https://raw.githubusercontent.com/searxng/searxng/master/client/simple/src/brand/searxng.svg&lt;/a&gt; :target: &lt;a href="https://searxng.org"&gt;https://searxng.org&lt;/a&gt; :alt: SearXNG :width: 512px&lt;/p&gt; 
&lt;p&gt;SearXNG is a &lt;code&gt;metasearch engine&lt;/code&gt;_. Users are neither tracked nor profiled.&lt;/p&gt; 
&lt;p&gt;.. image:: &lt;a href="https://img.shields.io/badge/organization-3050ff?style=flat-square&amp;amp;logo=searxng&amp;amp;logoColor=fff&amp;amp;cacheSeconds=86400"&gt;https://img.shields.io/badge/organization-3050ff?style=flat-square&amp;amp;logo=searxng&amp;amp;logoColor=fff&amp;amp;cacheSeconds=86400&lt;/a&gt; :target: &lt;a href="https://github.com/searxng"&gt;https://github.com/searxng&lt;/a&gt; :alt: Organization&lt;/p&gt; 
&lt;p&gt;.. image:: &lt;a href="https://img.shields.io/badge/documentation-3050ff?style=flat-square&amp;amp;logo=readthedocs&amp;amp;logoColor=fff&amp;amp;cacheSeconds=86400"&gt;https://img.shields.io/badge/documentation-3050ff?style=flat-square&amp;amp;logo=readthedocs&amp;amp;logoColor=fff&amp;amp;cacheSeconds=86400&lt;/a&gt; :target: &lt;a href="https://docs.searxng.org"&gt;https://docs.searxng.org&lt;/a&gt; :alt: Documentation&lt;/p&gt; 
&lt;p&gt;.. image:: &lt;a href="https://img.shields.io/github/license/searxng/searxng?style=flat-square&amp;amp;label=license&amp;amp;color=3050ff&amp;amp;cacheSeconds=86400"&gt;https://img.shields.io/github/license/searxng/searxng?style=flat-square&amp;amp;label=license&amp;amp;color=3050ff&amp;amp;cacheSeconds=86400&lt;/a&gt; :target: &lt;a href="https://github.com/searxng/searxng/raw/master/LICENSE"&gt;https://github.com/searxng/searxng/blob/master/LICENSE&lt;/a&gt; :alt: License&lt;/p&gt; 
&lt;p&gt;.. image:: &lt;a href="https://img.shields.io/github/commit-activity/y/searxng/searxng/master?style=flat-square&amp;amp;label=commits&amp;amp;color=3050ff&amp;amp;cacheSeconds=3600"&gt;https://img.shields.io/github/commit-activity/y/searxng/searxng/master?style=flat-square&amp;amp;label=commits&amp;amp;color=3050ff&amp;amp;cacheSeconds=3600&lt;/a&gt; :target: &lt;a href="https://github.com/searxng/searxng/commits/master/"&gt;https://github.com/searxng/searxng/commits/master/&lt;/a&gt; :alt: Commits&lt;/p&gt; 
&lt;p&gt;.. image:: &lt;a href="https://img.shields.io/weblate/progress/searxng?server=https%3A%2F%2Ftranslate.codeberg.org&amp;amp;style=flat-square&amp;amp;label=translated&amp;amp;color=3050ff&amp;amp;cacheSeconds=86400"&gt;https://img.shields.io/weblate/progress/searxng?server=https%3A%2F%2Ftranslate.codeberg.org&amp;amp;style=flat-square&amp;amp;label=translated&amp;amp;color=3050ff&amp;amp;cacheSeconds=86400&lt;/a&gt; :target: &lt;a href="https://translate.codeberg.org/projects/searxng/"&gt;https://translate.codeberg.org/projects/searxng/&lt;/a&gt; :alt: Translated&lt;/p&gt; 
&lt;h1&gt;Setup&lt;/h1&gt; 
&lt;p&gt;To install SearXNG, see &lt;code&gt;Installation guide&lt;/code&gt;_.&lt;/p&gt; 
&lt;p&gt;To fine-tune SearXNG, see &lt;code&gt;Configuration guide&lt;/code&gt;_.&lt;/p&gt; 
&lt;p&gt;Further information on &lt;em&gt;how-to&lt;/em&gt; can be found &lt;code&gt;here &amp;lt;https://docs.searxng.org/admin/index.html&amp;gt;&lt;/code&gt;_.&lt;/p&gt; 
&lt;h1&gt;Connect&lt;/h1&gt; 
&lt;p&gt;If you have questions or want to connect with others in the community, we have two official channels:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;#searxng:matrix.org &amp;lt;https://matrix.to/#/#searxng:matrix.org&amp;gt;&lt;/code&gt;_&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;#searxng @ libera.chat &amp;lt;https://web.libera.chat/?channel=#searxng&amp;gt;&lt;/code&gt;_ (bridged to Matrix)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Contributing&lt;/h1&gt; 
&lt;p&gt;See CONTRIBUTING_ for more details.&lt;/p&gt; 
&lt;h1&gt;License&lt;/h1&gt; 
&lt;p&gt;This project is licensed under the GNU Affero General Public License (AGPL-3.0). See LICENSE_ for more details.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>RVC-Project/Retrieval-based-Voice-Conversion-WebUI</title>
      <link>https://github.com/RVC-Project/Retrieval-based-Voice-Conversion-WebUI</link>
      <description>&lt;p&gt;Easily train a good VC model with voice data &lt;= 10 mins!&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;h1&gt;Retrieval-based-Voice-Conversion-WebUI&lt;/h1&gt; ä¸€ä¸ªåŸºäºVITSçš„ç®€å•æ˜“ç”¨çš„å˜å£°æ¡†æ¶
 &lt;br /&gt;
 &lt;br /&gt; 
 &lt;p&gt;&lt;a href="https://github.com/RVC-Project/Retrieval-based-Voice-Conversion-WebUI"&gt;&lt;img src="https://img.shields.io/badge/made_with-%E2%9D%A4-red?style=for-the-badge&amp;amp;labelColor=orange" alt="madewithlove" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;img src="https://counter.seku.su/cmoe?name=rvc&amp;amp;theme=r34" /&gt;&lt;br /&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://colab.research.google.com/github/RVC-Project/Retrieval-based-Voice-Conversion-WebUI/blob/main/Retrieval_based_Voice_Conversion_WebUI.ipynb"&gt;&lt;img src="https://img.shields.io/badge/Colab-F9AB00?style=for-the-badge&amp;amp;logo=googlecolab&amp;amp;color=525252" alt="Open In Colab" /&gt;&lt;/a&gt; &lt;a href="https://github.com/RVC-Project/Retrieval-based-Voice-Conversion-WebUI/raw/main/LICENSE"&gt;&lt;img src="https://img.shields.io/badge/LICENSE-MIT-green.svg?style=for-the-badge" alt="Licence" /&gt;&lt;/a&gt; &lt;a href="https://huggingface.co/lj1995/VoiceConversionWebUI/tree/main/"&gt;&lt;img src="https://img.shields.io/badge/%F0%9F%A4%97%20-Spaces-yellow.svg?style=for-the-badge" alt="Huggingface" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://discord.gg/HcsmBBGyVk"&gt;&lt;img src="https://img.shields.io/badge/RVC%20Developers-Discord-7289DA?style=for-the-badge&amp;amp;logo=discord&amp;amp;logoColor=white" alt="Discord" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://github.com/RVC-Project/Retrieval-based-Voice-Conversion-WebUI/raw/main/docs/Changelog_CN.md"&gt;&lt;strong&gt;æ›´æ–°æ—¥å¿—&lt;/strong&gt;&lt;/a&gt; | &lt;a href="https://github.com/RVC-Project/Retrieval-based-Voice-Conversion-WebUI/wiki/%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E8%A7%A3%E7%AD%94"&gt;&lt;strong&gt;å¸¸è§é—®é¢˜è§£ç­”&lt;/strong&gt;&lt;/a&gt; | &lt;a href="https://github.com/RVC-Project/Retrieval-based-Voice-Conversion-WebUI/wiki/Autodl%E8%AE%AD%E7%BB%83RVC%C2%B7AI%E6%AD%8C%E6%89%8B%E6%95%99%E7%A8%8B"&gt;&lt;strong&gt;AutoDLÂ·5æ¯›é’±è®­ç»ƒAIæ­Œæ‰‹&lt;/strong&gt;&lt;/a&gt; | &lt;a href="https://github.com/RVC-Project/Retrieval-based-Voice-Conversion-WebUI/wiki/Autodl%E8%AE%AD%E7%BB%83RVC%C2%B7AI%E6%AD%8C%E6%89%8B%E6%95%99%E7%A8%8B%5D(https://github.com/RVC-Project/Retrieval-based-Voice-Conversion-WebUI/wiki/%E5%AF%B9%E7%85%A7%E5%AE%9E%E9%AA%8C%C2%B7%E5%AE%9E%E9%AA%8C%E8%AE%B0%E5%BD%95)"&gt;&lt;strong&gt;å¯¹ç…§å®éªŒè®°å½•&lt;/strong&gt;&lt;/a&gt; | &lt;a href="https://modelscope.cn/studios/FlowerCry/RVCv2demo"&gt;&lt;strong&gt;åœ¨çº¿æ¼”ç¤º&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/RVC-Project/Retrieval-based-Voice-Conversion-WebUI/main/docs/en/README.en.md"&gt;&lt;strong&gt;English&lt;/strong&gt;&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/RVC-Project/Retrieval-based-Voice-Conversion-WebUI/main/README.md"&gt;&lt;strong&gt;ä¸­æ–‡ç®€ä½“&lt;/strong&gt;&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/RVC-Project/Retrieval-based-Voice-Conversion-WebUI/main/docs/jp/README.ja.md"&gt;&lt;strong&gt;æ—¥æœ¬èª&lt;/strong&gt;&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/RVC-Project/Retrieval-based-Voice-Conversion-WebUI/main/docs/kr/README.ko.md"&gt;&lt;strong&gt;í•œêµ­ì–´&lt;/strong&gt;&lt;/a&gt; (&lt;a href="https://raw.githubusercontent.com/RVC-Project/Retrieval-based-Voice-Conversion-WebUI/main/docs/kr/README.ko.han.md"&gt;&lt;strong&gt;éŸ“åœ‹èª&lt;/strong&gt;&lt;/a&gt;) | &lt;a href="https://raw.githubusercontent.com/RVC-Project/Retrieval-based-Voice-Conversion-WebUI/main/docs/fr/README.fr.md"&gt;&lt;strong&gt;FranÃ§ais&lt;/strong&gt;&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/RVC-Project/Retrieval-based-Voice-Conversion-WebUI/main/docs/tr/README.tr.md"&gt;&lt;strong&gt;TÃ¼rkÃ§e&lt;/strong&gt;&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/RVC-Project/Retrieval-based-Voice-Conversion-WebUI/main/docs/pt/README.pt.md"&gt;&lt;strong&gt;PortuguÃªs&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;åº•æ¨¡ä½¿ç”¨æ¥è¿‘50å°æ—¶çš„å¼€æºé«˜è´¨é‡VCTKè®­ç»ƒé›†è®­ç»ƒï¼Œæ— ç‰ˆæƒæ–¹é¢çš„é¡¾è™‘ï¼Œè¯·å¤§å®¶æ”¾å¿ƒä½¿ç”¨&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;è¯·æœŸå¾…RVCv3çš„åº•æ¨¡ï¼Œå‚æ•°æ›´å¤§ï¼Œæ•°æ®æ›´å¤§ï¼Œæ•ˆæœæ›´å¥½ï¼ŒåŸºæœ¬æŒå¹³çš„æ¨ç†é€Ÿåº¦ï¼Œéœ€è¦è®­ç»ƒæ•°æ®é‡æ›´å°‘ã€‚&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td align="center"&gt;è®­ç»ƒæ¨ç†ç•Œé¢&lt;/td&gt; 
   &lt;td align="center"&gt;å®æ—¶å˜å£°ç•Œé¢&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;img src="https://github.com/RVC-Project/Retrieval-based-Voice-Conversion-WebUI/assets/129054828/092e5c12-0d49-4168-a590-0b0ef6a4f630" /&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;img src="https://github.com/RVC-Project/Retrieval-based-Voice-Conversion-WebUI/assets/129054828/730b4114-8805-44a1-ab1a-04668f3c30a6" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;go-web.bat&lt;/td&gt; 
   &lt;td align="center"&gt;go-realtime-gui.bat&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;å¯ä»¥è‡ªç”±é€‰æ‹©æƒ³è¦æ‰§è¡Œçš„æ“ä½œã€‚&lt;/td&gt; 
   &lt;td align="center"&gt;æˆ‘ä»¬å·²ç»å®ç°ç«¯åˆ°ç«¯170mså»¶è¿Ÿã€‚å¦‚ä½¿ç”¨ASIOè¾“å…¥è¾“å‡ºè®¾å¤‡ï¼Œå·²èƒ½å®ç°ç«¯åˆ°ç«¯90mså»¶è¿Ÿï¼Œä½†éå¸¸ä¾èµ–ç¡¬ä»¶é©±åŠ¨æ”¯æŒã€‚&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h2&gt;ç®€ä»‹&lt;/h2&gt; 
&lt;p&gt;æœ¬ä»“åº“å…·æœ‰ä»¥ä¸‹ç‰¹ç‚¹&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;ä½¿ç”¨top1æ£€ç´¢æ›¿æ¢è¾“å…¥æºç‰¹å¾ä¸ºè®­ç»ƒé›†ç‰¹å¾æ¥æœç»éŸ³è‰²æ³„æ¼&lt;/li&gt; 
 &lt;li&gt;å³ä¾¿åœ¨ç›¸å¯¹è¾ƒå·®çš„æ˜¾å¡ä¸Šä¹Ÿèƒ½å¿«é€Ÿè®­ç»ƒ&lt;/li&gt; 
 &lt;li&gt;ä½¿ç”¨å°‘é‡æ•°æ®è¿›è¡Œè®­ç»ƒä¹Ÿèƒ½å¾—åˆ°è¾ƒå¥½ç»“æœ(æ¨èè‡³å°‘æ”¶é›†10åˆ†é’Ÿä½åº•å™ªè¯­éŸ³æ•°æ®)&lt;/li&gt; 
 &lt;li&gt;å¯ä»¥é€šè¿‡æ¨¡å‹èåˆæ¥æ”¹å˜éŸ³è‰²(å€ŸåŠ©ckptå¤„ç†é€‰é¡¹å¡ä¸­çš„ckpt-merge)&lt;/li&gt; 
 &lt;li&gt;ç®€å•æ˜“ç”¨çš„ç½‘é¡µç•Œé¢&lt;/li&gt; 
 &lt;li&gt;å¯è°ƒç”¨UVR5æ¨¡å‹æ¥å¿«é€Ÿåˆ†ç¦»äººå£°å’Œä¼´å¥&lt;/li&gt; 
 &lt;li&gt;ä½¿ç”¨æœ€å…ˆè¿›çš„&lt;a href="https://raw.githubusercontent.com/RVC-Project/Retrieval-based-Voice-Conversion-WebUI/main/#%E5%8F%82%E8%80%83%E9%A1%B9%E7%9B%AE"&gt;äººå£°éŸ³é«˜æå–ç®—æ³•InterSpeech2023-RMVPE&lt;/a&gt;æ ¹ç»å“‘éŸ³é—®é¢˜ã€‚æ•ˆæœæœ€å¥½ï¼ˆæ˜¾è‘—åœ°ï¼‰ä½†æ¯”crepe_fullæ›´å¿«ã€èµ„æºå ç”¨æ›´å°&lt;/li&gt; 
 &lt;li&gt;Aå¡Iå¡åŠ é€Ÿæ”¯æŒ&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;ç‚¹æ­¤æŸ¥çœ‹æˆ‘ä»¬çš„&lt;a href="https://www.bilibili.com/video/BV1pm4y1z7Gm/"&gt;æ¼”ç¤ºè§†é¢‘&lt;/a&gt; !&lt;/p&gt; 
&lt;h2&gt;ç¯å¢ƒé…ç½®&lt;/h2&gt; 
&lt;p&gt;ä»¥ä¸‹æŒ‡ä»¤éœ€åœ¨ Python ç‰ˆæœ¬å¤§äº3.8çš„ç¯å¢ƒä¸­æ‰§è¡Œã€‚&lt;/p&gt; 
&lt;h3&gt;Windows/Linux/MacOSç­‰å¹³å°é€šç”¨æ–¹æ³•&lt;/h3&gt; 
&lt;p&gt;ä¸‹åˆ—æ–¹æ³•ä»»é€‰å…¶ä¸€ã€‚&lt;/p&gt; 
&lt;h4&gt;1. é€šè¿‡ pip å®‰è£…ä¾èµ–&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;å®‰è£…PytorchåŠå…¶æ ¸å¿ƒä¾èµ–ï¼Œè‹¥å·²å®‰è£…åˆ™è·³è¿‡ã€‚å‚è€ƒè‡ª: &lt;a href="https://pytorch.org/get-started/locally/"&gt;https://pytorch.org/get-started/locally/&lt;/a&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install torch torchvision torchaudio
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;å¦‚æœæ˜¯ win ç³»ç»Ÿ + Nvidia Ampere æ¶æ„(RTX30xx)ï¼Œæ ¹æ® #21 çš„ç»éªŒï¼Œéœ€è¦æŒ‡å®š pytorch å¯¹åº”çš„ cuda ç‰ˆæœ¬&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu117
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt;æ ¹æ®è‡ªå·±çš„æ˜¾å¡å®‰è£…å¯¹åº”ä¾èµ–&lt;/li&gt; 
&lt;/ol&gt; 
&lt;ul&gt; 
 &lt;li&gt;Nå¡&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install -r requirements.txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;Aå¡/Iå¡&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install -r requirements-dml.txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;Aå¡ROCM(Linux)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install -r requirements-amd.txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;Iå¡IPEX(Linux)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install -r requirements-ipex.txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;2. é€šè¿‡ poetry æ¥å®‰è£…ä¾èµ–&lt;/h4&gt; 
&lt;p&gt;å®‰è£… Poetry ä¾èµ–ç®¡ç†å·¥å…·ï¼Œè‹¥å·²å®‰è£…åˆ™è·³è¿‡ã€‚å‚è€ƒè‡ª: &lt;a href="https://python-poetry.org/docs/#installation"&gt;https://python-poetry.org/docs/#installation&lt;/a&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -sSL https://install.python-poetry.org | python3 -
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;é€šè¿‡ Poetry å®‰è£…ä¾èµ–æ—¶ï¼Œpython å»ºè®®ä½¿ç”¨ 3.7-3.10 ç‰ˆæœ¬ï¼Œå…¶ä½™ç‰ˆæœ¬åœ¨å®‰è£… llvmlite==0.39.0 æ—¶ä¼šå‡ºç°å†²çª&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;poetry init -n
poetry env use "path to your python.exe"
poetry run pip install -r requirments.txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;MacOS&lt;/h3&gt; 
&lt;p&gt;å¯ä»¥é€šè¿‡ &lt;code&gt;run.sh&lt;/code&gt; æ¥å®‰è£…ä¾èµ–&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;sh ./run.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;å…¶ä»–é¢„æ¨¡å‹å‡†å¤‡&lt;/h2&gt; 
&lt;p&gt;RVCéœ€è¦å…¶ä»–ä¸€äº›é¢„æ¨¡å‹æ¥æ¨ç†å’Œè®­ç»ƒã€‚&lt;/p&gt; 
&lt;p&gt;ä½ å¯ä»¥ä»æˆ‘ä»¬çš„&lt;a href="https://huggingface.co/lj1995/VoiceConversionWebUI/tree/main/"&gt;Hugging Face space&lt;/a&gt;ä¸‹è½½åˆ°è¿™äº›æ¨¡å‹ã€‚&lt;/p&gt; 
&lt;h3&gt;1. ä¸‹è½½ assets&lt;/h3&gt; 
&lt;p&gt;ä»¥ä¸‹æ˜¯ä¸€ä»½æ¸…å•ï¼ŒåŒ…æ‹¬äº†æ‰€æœ‰RVCæ‰€éœ€çš„é¢„æ¨¡å‹å’Œå…¶ä»–æ–‡ä»¶çš„åç§°ã€‚ä½ å¯ä»¥åœ¨&lt;code&gt;tools&lt;/code&gt;æ–‡ä»¶å¤¹æ‰¾åˆ°ä¸‹è½½å®ƒä»¬çš„è„šæœ¬ã€‚&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;./assets/hubert/hubert_base.pt&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;./assets/pretrained&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;./assets/uvr5_weights&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;æƒ³ä½¿ç”¨v2ç‰ˆæœ¬æ¨¡å‹çš„è¯ï¼Œéœ€è¦é¢å¤–ä¸‹è½½&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;./assets/pretrained_v2&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;2. å®‰è£… ffmpeg&lt;/h3&gt; 
&lt;p&gt;è‹¥ffmpegå’Œffprobeå·²å®‰è£…åˆ™è·³è¿‡ã€‚&lt;/p&gt; 
&lt;h4&gt;Ubuntu/Debian ç”¨æˆ·&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;sudo apt install ffmpeg
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;MacOS ç”¨æˆ·&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;brew install ffmpeg
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Windows ç”¨æˆ·&lt;/h4&gt; 
&lt;p&gt;ä¸‹è½½åæ”¾ç½®åœ¨æ ¹ç›®å½•ã€‚&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;ä¸‹è½½&lt;a href="https://huggingface.co/lj1995/VoiceConversionWebUI/blob/main/ffmpeg.exe"&gt;ffmpeg.exe&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;ä¸‹è½½&lt;a href="https://huggingface.co/lj1995/VoiceConversionWebUI/blob/main/ffprobe.exe"&gt;ffprobe.exe&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;3. ä¸‹è½½ rmvpe äººå£°éŸ³é«˜æå–ç®—æ³•æ‰€éœ€æ–‡ä»¶&lt;/h3&gt; 
&lt;p&gt;å¦‚æœä½ æƒ³ä½¿ç”¨æœ€æ–°çš„RMVPEäººå£°éŸ³é«˜æå–ç®—æ³•ï¼Œåˆ™ä½ éœ€è¦ä¸‹è½½éŸ³é«˜æå–æ¨¡å‹å‚æ•°å¹¶æ”¾ç½®äºRVCæ ¹ç›®å½•ã€‚&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;ä¸‹è½½&lt;a href="https://huggingface.co/lj1995/VoiceConversionWebUI/blob/main/rmvpe.pt"&gt;rmvpe.pt&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;ä¸‹è½½ rmvpe çš„ dml ç¯å¢ƒ(å¯é€‰, Aå¡/Iå¡ç”¨æˆ·)&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;ä¸‹è½½&lt;a href="https://huggingface.co/lj1995/VoiceConversionWebUI/blob/main/rmvpe.onnx"&gt;rmvpe.onnx&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;4. AMDæ˜¾å¡Rocm(å¯é€‰, ä»…Linux)&lt;/h3&gt; 
&lt;p&gt;å¦‚æœä½ æƒ³åŸºäºAMDçš„RocmæŠ€æœ¯åœ¨Linuxç³»ç»Ÿä¸Šè¿è¡ŒRVCï¼Œè¯·å…ˆåœ¨&lt;a href="https://rocm.docs.amd.com/en/latest/deploy/linux/os-native/install.html"&gt;è¿™é‡Œ&lt;/a&gt;å®‰è£…æ‰€éœ€çš„é©±åŠ¨ã€‚&lt;/p&gt; 
&lt;p&gt;è‹¥ä½ ä½¿ç”¨çš„æ˜¯Arch Linuxï¼Œå¯ä»¥ä½¿ç”¨pacmanæ¥å®‰è£…æ‰€éœ€é©±åŠ¨ï¼š&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;pacman -S rocm-hip-sdk rocm-opencl-sdk
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;å¯¹äºæŸäº›å‹å·çš„æ˜¾å¡ï¼Œä½ å¯èƒ½éœ€è¦é¢å¤–é…ç½®å¦‚ä¸‹çš„ç¯å¢ƒå˜é‡ï¼ˆå¦‚ï¼šRX6700XTï¼‰ï¼š&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;export ROCM_PATH=/opt/rocm
export HSA_OVERRIDE_GFX_VERSION=10.3.0
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;åŒæ—¶ç¡®ä¿ä½ çš„å½“å‰ç”¨æˆ·å¤„äº&lt;code&gt;render&lt;/code&gt;ä¸&lt;code&gt;video&lt;/code&gt;ç”¨æˆ·ç»„å†…ï¼š&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;sudo usermod -aG render $USERNAME
sudo usermod -aG video $USERNAME
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;å¼€å§‹ä½¿ç”¨&lt;/h2&gt; 
&lt;h3&gt;ç›´æ¥å¯åŠ¨&lt;/h3&gt; 
&lt;p&gt;ä½¿ç”¨ä»¥ä¸‹æŒ‡ä»¤æ¥å¯åŠ¨ WebUI&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python infer-web.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;è‹¥å…ˆå‰ä½¿ç”¨ Poetry å®‰è£…ä¾èµ–ï¼Œåˆ™å¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼å¯åŠ¨WebUI&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;poetry run python infer-web.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;ä½¿ç”¨æ•´åˆåŒ…&lt;/h3&gt; 
&lt;p&gt;ä¸‹è½½å¹¶è§£å‹&lt;code&gt;RVC-beta.7z&lt;/code&gt;&lt;/p&gt; 
&lt;h4&gt;Windows ç”¨æˆ·&lt;/h4&gt; 
&lt;p&gt;åŒå‡»&lt;code&gt;go-web.bat&lt;/code&gt;&lt;/p&gt; 
&lt;h4&gt;MacOS ç”¨æˆ·&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;sh ./run.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;å¯¹äºéœ€è¦ä½¿ç”¨IPEXæŠ€æœ¯çš„Iå¡ç”¨æˆ·(ä»…Linux)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;source /opt/intel/oneapi/setvars.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;å‚è€ƒé¡¹ç›®&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/auspicious3000/contentvec/"&gt;ContentVec&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jaywalnut310/vits"&gt;VITS&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jik876/hifi-gan"&gt;HIFIGAN&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/gradio-app/gradio"&gt;Gradio&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/FFmpeg/FFmpeg"&gt;FFmpeg&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Anjok07/ultimatevocalremovergui"&gt;Ultimate Vocal Remover&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/openvpi/audio-slicer"&gt;audio-slicer&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Dream-High/RMVPE"&gt;Vocal pitch extraction:RMVPE&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;The pretrained model is trained and tested by &lt;a href="https://github.com/yxlllc/RMVPE"&gt;yxlllc&lt;/a&gt; and &lt;a href="https://github.com/RVC-Boss"&gt;RVC-Boss&lt;/a&gt;.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;æ„Ÿè°¢æ‰€æœ‰è´¡çŒ®è€…ä½œå‡ºçš„åŠªåŠ›&lt;/h2&gt; 
&lt;a href="https://github.com/RVC-Project/Retrieval-based-Voice-Conversion-WebUI/graphs/contributors" target="_blank"&gt; &lt;img src="https://contrib.rocks/image?repo=RVC-Project/Retrieval-based-Voice-Conversion-WebUI" /&gt; &lt;/a&gt;</description>
    </item>
    
    <item>
      <title>Fosowl/agenticSeek</title>
      <link>https://github.com/Fosowl/agenticSeek</link>
      <description>&lt;p&gt;Fully Local Manus AI. No APIs, No $200 monthly bills. Enjoy an autonomous agent that thinks, browses the web, and code for the sole cost of electricity. ğŸ”” Official updates only via twitter @Martin993886460 (Beware of fake account)&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;AgenticSeek: Private, Local Manus Alternative.&lt;/h1&gt; 
&lt;p align="center"&gt; &lt;img align="center" src="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/media/agentic_seek_logo.png" width="300" height="300" alt="Agentic Seek Logo" /&gt; &lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;English | &lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_CHS.md"&gt;ä¸­æ–‡&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_CHT.md"&gt;ç¹é«”ä¸­æ–‡&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_FR.md"&gt;FranÃ§ais&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_JP.md"&gt;æ—¥æœ¬èª&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_PTBR.md"&gt;PortuguÃªs (Brasil)&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_ES.md"&gt;EspaÃ±ol&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;A &lt;strong&gt;100% local alternative to Manus AI&lt;/strong&gt;, this voice-enabled AI assistant autonomously browses the web, writes code, and plans tasks while keeping all data on your device. Tailored for local reasoning models, it runs entirely on your hardware, ensuring complete privacy and zero cloud dependency.&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://fosowl.github.io/agenticSeek.html"&gt;&lt;img src="https://img.shields.io/static/v1?label=Website&amp;amp;message=AgenticSeek&amp;amp;color=blue&amp;amp;style=flat-square" alt="Visit AgenticSeek" /&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/badge/license-GPL--3.0-green" alt="License" /&gt; &lt;a href="https://discord.gg/8hGDaME3TC"&gt;&lt;img src="https://img.shields.io/badge/Discord-Join%20Us-7289DA?logo=discord&amp;amp;logoColor=white" alt="Discord" /&gt;&lt;/a&gt; &lt;a href="https://x.com/Martin993886460"&gt;&lt;img src="https://img.shields.io/twitter/url/https/twitter.com/fosowl.svg?style=social&amp;amp;label=Update%20%40Fosowl" alt="Twitter" /&gt;&lt;/a&gt; &lt;a href="https://github.com/Fosowl/agenticSeek/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/Fosowl/agenticSeek?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Why AgenticSeek ?&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;ğŸ”’ Fully Local &amp;amp; Private - Everything runs on your machine â€” no cloud, no data sharing. Your files, conversations, and searches stay private.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;ğŸŒ Smart Web Browsing - AgenticSeek can browse the internet by itself â€” search, read, extract info, fill web form â€” all hands-free.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;ğŸ’» Autonomous Coding Assistant - Need code? It can write, debug, and run programs in Python, C, Go, Java, and more â€” all without supervision.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;ğŸ§  Smart Agent Selection - You ask, it figures out the best agent for the job automatically. Like having a team of experts ready to help.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;ğŸ“‹ Plans &amp;amp; Executes Complex Tasks - From trip planning to complex projects â€” it can split big tasks into steps and get things done using multiple AI agents.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;ğŸ™ï¸ Voice-Enabled - Clean, fast, futuristic voice and speech to text allowing you to talk to it like it's your personal AI from a sci-fi movie. (In progress)&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;strong&gt;Demo&lt;/strong&gt;&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;em&gt;Can you search for the agenticSeek project, learn what skills are required, then open the CV_candidates.zip and then tell me which match best the project&lt;/em&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/b8ca60e9-7b3b-4533-840e-08f9ac426316"&gt;https://github.com/user-attachments/assets/b8ca60e9-7b3b-4533-840e-08f9ac426316&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Disclaimer: This demo, including all the files that appear (e.g: CV_candidates.zip), are entirely fictional. We are not a corporation, we seek open-source contributors not candidates.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;ğŸ› âš ï¸ï¸ &lt;strong&gt;Active Work in Progress&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;ğŸ™ This project started as a side-project and has zero roadmap and zero funding. It's grown way beyond what I expected by ending in GitHub Trending. Contributions, feedback, and patience are deeply appreciated.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Prerequisites&lt;/h2&gt; 
&lt;p&gt;Before you begin, ensure you have the following software installed:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Git:&lt;/strong&gt; For cloning the repository. &lt;a href="https://git-scm.com/downloads"&gt;Download Git&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Python 3.10.x:&lt;/strong&gt; We strongly recommend using Python version 3.10.x. Using other versions might lead to dependency errors. &lt;a href="https://www.python.org/downloads/release/python-3100/"&gt;Download Python 3.10&lt;/a&gt; (pick a 3.10.x version).&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Docker Engine &amp;amp; Docker Compose:&lt;/strong&gt; For running bundled services like SearxNG. 
  &lt;ul&gt; 
   &lt;li&gt;Install Docker Desktop (which includes Docker Compose V2): &lt;a href="https://docs.docker.com/desktop/install/windows-install/"&gt;Windows&lt;/a&gt; | &lt;a href="https://docs.docker.com/desktop/install/mac-install/"&gt;Mac&lt;/a&gt; | &lt;a href="https://docs.docker.com/desktop/install/linux-install/"&gt;Linux&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;Alternatively, install Docker Engine and Docker Compose separately on Linux: &lt;a href="https://docs.docker.com/engine/install/"&gt;Docker Engine&lt;/a&gt; | &lt;a href="https://docs.docker.com/compose/install/"&gt;Docker Compose&lt;/a&gt; (ensure you install Compose V2, e.g., &lt;code&gt;sudo apt-get install docker-compose-plugin&lt;/code&gt;).&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;1. &lt;strong&gt;Clone the repository and setup&lt;/strong&gt;&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;git clone https://github.com/Fosowl/agenticSeek.git
cd agenticSeek
mv .env.example .env
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;2. Change the .env file content&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;SEARXNG_BASE_URL="http://searxng:8080" # http://127.0.0.1:8080 if running on host
REDIS_BASE_URL="redis://redis:6379/0"
WORK_DIR="/Users/mlg/Documents/workspace_for_ai"
OLLAMA_PORT="11434"
LM_STUDIO_PORT="1234"
CUSTOM_ADDITIONAL_LLM_PORT="11435"
OPENAI_API_KEY='optional'
DEEPSEEK_API_KEY='optional'
OPENROUTER_API_KEY='optional'
TOGETHER_API_KEY='optional'
GOOGLE_API_KEY='optional'
ANTHROPIC_API_KEY='optional'
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Update the &lt;code&gt;.env&lt;/code&gt; file with your own values as needed:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;SEARXNG_BASE_URL&lt;/strong&gt;: Leave unchanged unless running on host with CLI mode.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;REDIS_BASE_URL&lt;/strong&gt;: Leave unchanged&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;WORK_DIR&lt;/strong&gt;: Path to your working directory on your local machine. AgenticSeek will be able to read and interact with these files.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;OLLAMA_PORT&lt;/strong&gt;: Port number for the Ollama service.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;LM_STUDIO_PORT&lt;/strong&gt;: Port number for the LM Studio service.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;CUSTOM_ADDITIONAL_LLM_PORT&lt;/strong&gt;: Port for any additional custom LLM service.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;API Key are totally optional for user who choose to run LLM locally. Which is the primary purpose of this project. Leave empty if you have sufficient hardware&lt;/strong&gt;&lt;/p&gt; 
&lt;h3&gt;3. &lt;strong&gt;Start Docker&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;Make sure Docker is installed and running on your system. You can start Docker using the following commands:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;On Linux/macOS:&lt;/strong&gt;&lt;br /&gt; Open a terminal and run:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-sh"&gt;sudo systemctl start docker
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Or launch Docker Desktop from your applications menu if installed.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;On Windows:&lt;/strong&gt;&lt;br /&gt; Start Docker Desktop from the Start menu.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;You can verify Docker is running by executing:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;docker info
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you see information about your Docker installation, it is running correctly.&lt;/p&gt; 
&lt;p&gt;See the table of &lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#list-of-local-providers"&gt;Local Providers&lt;/a&gt; below for a summary.&lt;/p&gt; 
&lt;p&gt;Next step: &lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#start-services-and-run"&gt;Run AgenticSeek locally&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;See the &lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#troubleshooting"&gt;Troubleshooting&lt;/a&gt; section if you are having issues.&lt;/em&gt; &lt;em&gt;If your hardware can't run LLMs locally, see &lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#setup-to-run-with-an-api"&gt;Setup to run with an API&lt;/a&gt;.&lt;/em&gt; &lt;em&gt;For detailed &lt;code&gt;config.ini&lt;/code&gt; explanations, see &lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#config"&gt;Config Section&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Setup for running LLM locally on your machine&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Hardware Requirements:&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;To run LLMs locally, you'll need sufficient hardware. At a minimum, a GPU capable of running Magistral, Qwen or Deepseek 14B is required. See the FAQ for detailed model/performance recommendations.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Setup your local provider&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Start your local provider (for example with ollama):&lt;/p&gt; 
&lt;p&gt;Unless you wish to to run AgenticSeek on host (CLI mode), export or set the provider listen address:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;export OLLAMA_HOST=0.0.0.0:11434
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then, start you provider:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;ollama serve
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See below for a list of local supported provider.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Update the config.ini&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Change the config.ini file to set the provider_name to a supported provider and provider_model to a LLM supported by your provider. We recommend reasoning model such as &lt;em&gt;Magistral&lt;/em&gt; or &lt;em&gt;Deepseek&lt;/em&gt;.&lt;/p&gt; 
&lt;p&gt;See the &lt;strong&gt;FAQ&lt;/strong&gt; at the end of the README for required hardware.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;[MAIN]
is_local = True # Whenever you are running locally or with remote provider.
provider_name = ollama # or lm-studio, openai, etc..
provider_model = deepseek-r1:14b # choose a model that fit your hardware
provider_server_address = 127.0.0.1:11434
agent_name = Jarvis # name of your AI
recover_last_session = True # whenever to recover the previous session
save_session = True # whenever to remember the current session
speak = False # text to speech
listen = False # Speech to text, only for CLI, experimental
jarvis_personality = False # Whenever to use a more "Jarvis" like personality (experimental)
languages = en zh # The list of languages, Text to speech will default to the first language on the list
[BROWSER]
headless_browser = True # leave unchanged unless using CLI on host.
stealth_mode = True # Use undetected selenium to reduce browser detection
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Warning&lt;/strong&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;The &lt;code&gt;config.ini&lt;/code&gt; file format does not support comments. Do not copy and paste the example configuration directly, as comments will cause errors. Instead, manually modify the &lt;code&gt;config.ini&lt;/code&gt; file with your desired settings, excluding any comments.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Do &lt;em&gt;NOT&lt;/em&gt; set provider_name to &lt;code&gt;openai&lt;/code&gt; if using LM-studio for running LLMs. Set it to &lt;code&gt;lm-studio&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Some provider (eg: lm-studio) require you to have &lt;code&gt;http://&lt;/code&gt; in front of the IP. For example &lt;code&gt;http://127.0.0.1:1234&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;List of local providers&lt;/strong&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Provider&lt;/th&gt; 
   &lt;th&gt;Local?&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ollama&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Run LLMs locally with ease using ollama as a LLM provider&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;lm-studio&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Run LLM locally with LM studio (set &lt;code&gt;provider_name&lt;/code&gt; to &lt;code&gt;lm-studio&lt;/code&gt;)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;openai&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Use openai compatible API (eg: llama.cpp server)&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Next step: &lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#Start-services-and-Run"&gt;Start services and run AgenticSeek&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;See the &lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#troubleshooting"&gt;Troubleshooting&lt;/a&gt; section if you are having issues.&lt;/em&gt; &lt;em&gt;If your hardware can't run LLMs locally, see &lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#setup-to-run-with-an-api"&gt;Setup to run with an API&lt;/a&gt;.&lt;/em&gt; &lt;em&gt;For detailed &lt;code&gt;config.ini&lt;/code&gt; explanations, see &lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#config"&gt;Config Section&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt; 
&lt;h2&gt;Setup to run with an API&lt;/h2&gt; 
&lt;p&gt;This setup uses external, cloud-based LLM providers. You'll need an API key from your chosen service.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;1. Choose an API Provider and Get an API Key:&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Refer to the &lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#list-of-api-providers"&gt;List of API Providers&lt;/a&gt; below. Visit their websites to sign up and obtain an API key.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2. Set Your API Key as an Environment Variable:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Linux/macOS:&lt;/strong&gt; Open your terminal and use the &lt;code&gt;export&lt;/code&gt; command. It's best to add this to your shell's profile file (e.g., &lt;code&gt;~/.bashrc&lt;/code&gt;, &lt;code&gt;~/.zshrc&lt;/code&gt;) for persistence.&lt;/p&gt; &lt;pre&gt;&lt;code class="language-sh"&gt;export PROVIDER_API_KEY="your_api_key_here" 
# Replace PROVIDER_API_KEY with the specific variable name, e.g., OPENAI_API_KEY, GOOGLE_API_KEY
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Example for TogetherAI:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-sh"&gt;export TOGETHER_API_KEY="xxxxxxxxxxxxxxxxxxxxxx"
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Windows:&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Command Prompt (Temporary for current session):&lt;/strong&gt; &lt;pre&gt;&lt;code class="language-cmd"&gt;set PROVIDER_API_KEY=your_api_key_here
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;PowerShell (Temporary for current session):&lt;/strong&gt; &lt;pre&gt;&lt;code class="language-powershell"&gt;$env:PROVIDER_API_KEY="your_api_key_here"
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Permanently:&lt;/strong&gt; Search for "environment variables" in the Windows search bar, click "Edit the system environment variables," then click the "Environment Variables..." button. Add a new User variable with the appropriate name (e.g., &lt;code&gt;OPENAI_API_KEY&lt;/code&gt;) and your key as the value.&lt;/li&gt; 
  &lt;/ul&gt; &lt;p&gt;&lt;em&gt;(See FAQ: &lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#how-do-i-set-api-keys"&gt;How do I set API keys?&lt;/a&gt; for more details).&lt;/em&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;3. Update &lt;code&gt;config.ini&lt;/code&gt;:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-ini"&gt;[MAIN]
is_local = False
provider_name = openai # Or google, deepseek, togetherAI, huggingface
provider_model = gpt-3.5-turbo # Or gemini-1.5-flash, deepseek-chat, mistralai/Mixtral-8x7B-Instruct-v0.1 etc.
provider_server_address = # Typically ignored or can be left blank when is_local = False for most APIs
# ... other settings ...
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;em&gt;Warning:&lt;/em&gt; Make sure there are no trailing spaces in the &lt;code&gt;config.ini&lt;/code&gt; values.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;List of API Providers&lt;/strong&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Provider&lt;/th&gt; 
   &lt;th&gt;&lt;code&gt;provider_name&lt;/code&gt;&lt;/th&gt; 
   &lt;th&gt;Local?&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;API Key Link (Examples)&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;OpenAI&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;openai&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;Use ChatGPT models via OpenAI's API.&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://platform.openai.com/signup"&gt;platform.openai.com/signup&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Google Gemini&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;google&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;Use Google Gemini models via Google AI Studio.&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aistudio.google.com/keys"&gt;aistudio.google.com/keys&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Deepseek&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;deepseek&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;Use Deepseek models via their API.&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://platform.deepseek.com"&gt;platform.deepseek.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Hugging Face&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;huggingface&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;Use models from Hugging Face Inference API.&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/settings/tokens"&gt;huggingface.co/settings/tokens&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;TogetherAI&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;togetherAI&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;Use various open-source models via TogetherAI API.&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://api.together.ai/settings/api-keys"&gt;api.together.ai/settings/api-keys&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;OpenRouter&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;openrouter&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;Use OpenRouter Models&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://openrouter.ai/"&gt;https://openrouter.ai/&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;em&gt;Note:&lt;/em&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;We advise against using &lt;code&gt;gpt-4o&lt;/code&gt; or other OpenAI models for complex web browsing and task planning as current prompt optimizations are geared towards models like Deepseek.&lt;/li&gt; 
 &lt;li&gt;Coding/bash tasks might encounter issues with Gemini, as it may not strictly follow formatting prompts optimized for Deepseek.&lt;/li&gt; 
 &lt;li&gt;The &lt;code&gt;provider_server_address&lt;/code&gt; in &lt;code&gt;config.ini&lt;/code&gt; is generally not used when &lt;code&gt;is_local = False&lt;/code&gt; as the API endpoint is usually hardcoded in the respective provider's library.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Next step: &lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#Start-services-and-Run"&gt;Start services and run AgenticSeek&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;See the &lt;strong&gt;Known issues&lt;/strong&gt; section if you are having issues&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;See the &lt;strong&gt;Config&lt;/strong&gt; section for detailed config file explanation.&lt;/em&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Start services and Run&lt;/h2&gt; 
&lt;p&gt;By default AgenticSeek is run fully in docker.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Option 1:&lt;/strong&gt; Run in Docker, use web interface:&lt;/p&gt; 
&lt;p&gt;Start required services. This will start all services from the docker-compose.yml, including: - searxng - redis (required by searxng) - frontend - backend (if using &lt;code&gt;full&lt;/code&gt; when using the web interface)&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;./start_services.sh full # MacOS
start start_services.cmd full # Window
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Warning:&lt;/strong&gt; This step will download and load all Docker images, which may take up to 30 minutes. After starting the services, please wait until the backend service is fully running (you should see &lt;strong&gt;backend: "GET /health HTTP/1.1" 200 OK&lt;/strong&gt; in the log) before sending any messages. The backend services might take 5 minute to start on first run.&lt;/p&gt; 
&lt;p&gt;Go to &lt;code&gt;http://localhost:3000/&lt;/code&gt; and you should see the web interface.&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;Troubleshooting service start:&lt;/em&gt; If these scripts fail, ensure Docker Engine is running and Docker Compose (V2, &lt;code&gt;docker compose&lt;/code&gt;) is correctly installed. Check the output in the terminal for error messages. See &lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#faq-troubleshooting"&gt;FAQ: Help! I get an error when running AgenticSeek or its scripts.&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Option 2:&lt;/strong&gt; CLI mode:&lt;/p&gt; 
&lt;p&gt;To run with CLI interface you would have to install package on host:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;./install.sh
./install.bat # windows
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then you must change the SEARXNG_BASE_URL in &lt;code&gt;config.ini&lt;/code&gt; to:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;SEARXNG_BASE_URL="http://localhost:8080"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Start required services. This will start some services from the docker-compose.yml, including: - searxng - redis (required by searxng) - frontend&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;./start_services.sh # MacOS
start start_services.cmd # Window
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Run: uv run: &lt;code&gt;uv run python -m ensurepip&lt;/code&gt; to ensure uv has pip enabled.&lt;/p&gt; 
&lt;p&gt;Use the CLI: &lt;code&gt;uv run cli.py&lt;/code&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;p&gt;Make sure the services are up and running with &lt;code&gt;./start_services.sh full&lt;/code&gt; and go to &lt;code&gt;localhost:3000&lt;/code&gt; for web interface.&lt;/p&gt; 
&lt;p&gt;You can also use speech to text by setting &lt;code&gt;listen = True&lt;/code&gt; in the config. Only for CLI mode.&lt;/p&gt; 
&lt;p&gt;To exit, simply say/type &lt;code&gt;goodbye&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Here are some example usage:&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;em&gt;Make a snake game in python!&lt;/em&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;em&gt;Search the web for top cafes in Rennes, France, and save a list of three with their addresses in rennes_cafes.txt.&lt;/em&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;em&gt;Write a Go program to calculate the factorial of a number, save it as factorial.go in your workspace&lt;/em&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;em&gt;Search my summer_pictures folder for all JPG files, rename them with todayâ€™s date, and save a list of renamed files in photos_list.txt&lt;/em&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;em&gt;Search online for popular sci-fi movies from 2024 and pick three to watch tonight. Save the list in movie_night.txt.&lt;/em&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;em&gt;Search the web for the latest AI news articles from 2025, select three, and write a Python script to scrape their titles and summaries. Save the script as news_scraper.py and the summaries in ai_news.txt in /home/projects&lt;/em&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;em&gt;Friday, search the web for a free stock price API, register with &lt;a href="mailto:supersuper7434567@gmail.com"&gt;supersuper7434567@gmail.com&lt;/a&gt; then write a Python script to fetch using the API daily prices for Tesla, and save the results in stock_prices.csv&lt;/em&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;em&gt;Note that form filling capabilities are still experimental and might fail.&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;After you type your query, AgenticSeek will allocate the best agent for the task.&lt;/p&gt; 
&lt;p&gt;Because this is an early prototype, the agent routing system might not always allocate the right agent based on your query.&lt;/p&gt; 
&lt;p&gt;Therefore, you should be very explicit in what you want and how the AI might proceed for example if you want it to conduct a web search, do not say:&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;Do you know some good countries for solo-travel?&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;Instead, ask:&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;Do a web search and find out which are the best country for solo-travel&lt;/code&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;&lt;strong&gt;Setup to run the LLM on your own server&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;If you have a powerful computer or a server that you can use, but you want to use it from your laptop you have the options to run the LLM on a remote server using our custom llm server.&lt;/p&gt; 
&lt;p&gt;On your "server" that will run the AI model, get the ip address&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;ip a | grep "inet " | grep -v 127.0.0.1 | awk '{print $2}' | cut -d/ -f1 # local ip
curl https://ipinfo.io/ip # public ip
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Note: For Windows or macOS, use ipconfig or ifconfig respectively to find the IP address.&lt;/p&gt; 
&lt;p&gt;Clone the repository and enter the &lt;code&gt;server/&lt;/code&gt;folder.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;git clone --depth 1 https://github.com/Fosowl/agenticSeek.git
cd agenticSeek/llm_server/
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Install server specific requirements:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;pip3 install -r requirements.txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Run the server script.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;python3 app.py --provider ollama --port 3333
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You have the choice between using &lt;code&gt;ollama&lt;/code&gt; and &lt;code&gt;llamacpp&lt;/code&gt; as a LLM service.&lt;/p&gt; 
&lt;p&gt;Now on your personal computer:&lt;/p&gt; 
&lt;p&gt;Change the &lt;code&gt;config.ini&lt;/code&gt; file to set the &lt;code&gt;provider_name&lt;/code&gt; to &lt;code&gt;server&lt;/code&gt; and &lt;code&gt;provider_model&lt;/code&gt; to &lt;code&gt;deepseek-r1:xxb&lt;/code&gt;. Set the &lt;code&gt;provider_server_address&lt;/code&gt; to the ip address of the machine that will run the model.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;[MAIN]
is_local = False
provider_name = server
provider_model = deepseek-r1:70b
provider_server_address = http://x.x.x.x:3333
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Next step: &lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#Start-services-and-Run"&gt;Start services and run AgenticSeek&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Speech to Text&lt;/h2&gt; 
&lt;p&gt;Warning: speech to text only work in CLI mode at the moment.&lt;/p&gt; 
&lt;p&gt;Please note that currently speech to text only work in english.&lt;/p&gt; 
&lt;p&gt;The speech-to-text functionality is disabled by default. To enable it, set the listen option to True in the config.ini file:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;listen = True
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;When enabled, the speech-to-text feature listens for a trigger keyword, which is the agent's name, before it begins processing your input. You can customize the agent's name by updating the &lt;code&gt;agent_name&lt;/code&gt; value in the &lt;em&gt;config.ini&lt;/em&gt; file:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;agent_name = Friday
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For optimal recognition, we recommend using a common English name like "John" or "Emma" as the agent name&lt;/p&gt; 
&lt;p&gt;Once you see the transcript start to appear, say the agent's name aloud to wake it up (e.g., "Friday").&lt;/p&gt; 
&lt;p&gt;Speak your query clearly.&lt;/p&gt; 
&lt;p&gt;End your request with a confirmation phrase to signal the system to proceed. Examples of confirmation phrases include:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;"do it", "go ahead", "execute", "run", "start", "thanks", "would ya", "please", "okay?", "proceed", "continue", "go on", "do that", "go it", "do you understand?"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Config&lt;/h2&gt; 
&lt;p&gt;Example config:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;[MAIN]
is_local = True
provider_name = ollama
provider_model = deepseek-r1:32b
provider_server_address = http://127.0.0.1:11434 # Example for Ollama; use http://127.0.0.1:1234 for LM-Studio
agent_name = Friday
recover_last_session = False
save_session = False
speak = False
listen = False

jarvis_personality = False
languages = en zh # List of languages for TTS and potentially routing.
[BROWSER]
headless_browser = False
stealth_mode = False
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Explanation of &lt;code&gt;config.ini&lt;/code&gt; Settings&lt;/strong&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;[MAIN]&lt;/code&gt; Section:&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;is_local&lt;/code&gt;: &lt;code&gt;True&lt;/code&gt; if using a local LLM provider (Ollama, LM-Studio, local OpenAI-compatible server) or the self-hosted server option. &lt;code&gt;False&lt;/code&gt; if using a cloud-based API (OpenAI, Google, etc.).&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;provider_name&lt;/code&gt;: Specifies the LLM provider. 
    &lt;ul&gt; 
     &lt;li&gt;Local options: &lt;code&gt;ollama&lt;/code&gt;, &lt;code&gt;lm-studio&lt;/code&gt;, &lt;code&gt;openai&lt;/code&gt; (for local OpenAI-compatible servers), &lt;code&gt;server&lt;/code&gt; (for the self-hosted server setup).&lt;/li&gt; 
     &lt;li&gt;API options: &lt;code&gt;openai&lt;/code&gt;, &lt;code&gt;google&lt;/code&gt;, &lt;code&gt;deepseek&lt;/code&gt;, &lt;code&gt;huggingface&lt;/code&gt;, &lt;code&gt;togetherAI&lt;/code&gt;.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;provider_model&lt;/code&gt;: The specific model name or ID for the chosen provider (e.g., &lt;code&gt;deepseekcoder:6.7b&lt;/code&gt; for Ollama, &lt;code&gt;gpt-3.5-turbo&lt;/code&gt; for OpenAI API, &lt;code&gt;mistralai/Mixtral-8x7B-Instruct-v0.1&lt;/code&gt; for TogetherAI).&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;provider_server_address&lt;/code&gt;: The address of your LLM provider. 
    &lt;ul&gt; 
     &lt;li&gt;For local providers: e.g., &lt;code&gt;http://127.0.0.1:11434&lt;/code&gt; for Ollama, &lt;code&gt;http://127.0.0.1:1234&lt;/code&gt; for LM-Studio.&lt;/li&gt; 
     &lt;li&gt;For the &lt;code&gt;server&lt;/code&gt; provider type: The address of your self-hosted LLM server (e.g., &lt;code&gt;http://your_server_ip:3333&lt;/code&gt;).&lt;/li&gt; 
     &lt;li&gt;For cloud APIs (&lt;code&gt;is_local = False&lt;/code&gt;): This is often ignored or can be left blank, as the API endpoint is usually handled by the client library.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;agent_name&lt;/code&gt;: Name of the AI assistant (e.g., Friday). Used as a trigger word for speech-to-text if enabled.&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;recover_last_session&lt;/code&gt;: &lt;code&gt;True&lt;/code&gt; to attempt to restore the previous session's state, &lt;code&gt;False&lt;/code&gt; to start fresh.&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;save_session&lt;/code&gt;: &lt;code&gt;True&lt;/code&gt; to save the current session's state for potential recovery, &lt;code&gt;False&lt;/code&gt; otherwise.&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;speak&lt;/code&gt;: &lt;code&gt;True&lt;/code&gt; to enable text-to-speech voice output, &lt;code&gt;False&lt;/code&gt; to disable.&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;listen&lt;/code&gt;: &lt;code&gt;True&lt;/code&gt; to enable speech-to-text voice input (CLI mode only), &lt;code&gt;False&lt;/code&gt; to disable.&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;work_dir&lt;/code&gt;: &lt;strong&gt;Crucial:&lt;/strong&gt; The directory where AgenticSeek will read/write files. &lt;strong&gt;Ensure this path is valid and accessible on your system.&lt;/strong&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;jarvis_personality&lt;/code&gt;: &lt;code&gt;True&lt;/code&gt; to use a more "Jarvis-like" system prompt (experimental), &lt;code&gt;False&lt;/code&gt; for the standard prompt.&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;languages&lt;/code&gt;: A comma-separated list of languages (e.g., &lt;code&gt;en, zh, fr&lt;/code&gt;). Used for TTS voice selection (defaults to the first) and can assist the LLM router. Avoid too many or very similar languages for router efficiency.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;[BROWSER]&lt;/code&gt; Section:&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;headless_browser&lt;/code&gt;: &lt;code&gt;True&lt;/code&gt; to run the automated browser without a visible window (recommended for web interface or non-interactive use). &lt;code&gt;False&lt;/code&gt; to show the browser window (useful for CLI mode or debugging).&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;stealth_mode&lt;/code&gt;: &lt;code&gt;True&lt;/code&gt; to enable measures to make browser automation harder to detect. May require manual installation of browser extensions like anticaptcha.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;This section summarizes the supported LLM provider types. Configure them in &lt;code&gt;config.ini&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Local Providers (Run on Your Own Hardware):&lt;/strong&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Provider Name in &lt;code&gt;config.ini&lt;/code&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;code&gt;is_local&lt;/code&gt;&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Setup Section&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;ollama&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;True&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Use Ollama to serve local LLMs.&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#setup-for-running-llm-locally-on-your-machine"&gt;Setup for running LLM locally&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;lm-studio&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;True&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Use LM-Studio to serve local LLMs.&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#setup-for-running-llm-locally-on-your-machine"&gt;Setup for running LLM locally&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;openai&lt;/code&gt; (for local server)&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;True&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Connect to a local server that exposes an OpenAI-compatible API (e.g., llama.cpp).&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#setup-for-running-llm-locally-on-your-machine"&gt;Setup for running LLM locally&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;server&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;False&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Connect to the AgenticSeek self-hosted LLM server running on another machine.&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#setup-to-run-the-llm-on-your-own-server"&gt;Setup to run the LLM on your own server&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;API Providers (Cloud-Based):&lt;/strong&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Provider Name in &lt;code&gt;config.ini&lt;/code&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;code&gt;is_local&lt;/code&gt;&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Setup Section&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;openai&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;False&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Use OpenAI's official API (e.g., GPT-3.5, GPT-4).&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#setup-to-run-with-an-api"&gt;Setup to run with an API&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;google&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;False&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Use Google's Gemini models via API.&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#setup-to-run-with-an-api"&gt;Setup to run with an API&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;deepseek&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;False&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Use Deepseek's official API.&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#setup-to-run-with-an-api"&gt;Setup to run with an API&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;huggingface&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;False&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Use Hugging Face Inference API.&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#setup-to-run-with-an-api"&gt;Setup to run with an API&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;togetherAI&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;False&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Use TogetherAI's API for various open models.&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#setup-to-run-with-an-api"&gt;Setup to run with an API&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Troubleshooting&lt;/h2&gt; 
&lt;p&gt;If you encounter issues, this section provides guidance.&lt;/p&gt; 
&lt;h1&gt;Known Issues&lt;/h1&gt; 
&lt;h2&gt;ChromeDriver Issues&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Error Example:&lt;/strong&gt; &lt;code&gt;SessionNotCreatedException: Message: session not created: This version of ChromeDriver only supports Chrome version XXX&lt;/code&gt;&lt;/p&gt; 
&lt;h3&gt;Root Cause&lt;/h3&gt; 
&lt;p&gt;ChromeDriver version incompatibility occurs when:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Your installed ChromeDriver version doesn't match your Chrome browser version&lt;/li&gt; 
 &lt;li&gt;In Docker environments, &lt;code&gt;undetected_chromedriver&lt;/code&gt; may download its own ChromeDriver version, bypassing the mounted binary&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Solution Steps&lt;/h3&gt; 
&lt;h4&gt;1. Check Your Chrome Version&lt;/h4&gt; 
&lt;p&gt;Open Google Chrome â†’ &lt;code&gt;Settings &amp;gt; About Chrome&lt;/code&gt; to find your version (e.g., "Version 134.0.6998.88")&lt;/p&gt; 
&lt;h4&gt;2. Download Matching ChromeDriver&lt;/h4&gt; 
&lt;p&gt;&lt;strong&gt;For Chrome 115 and newer:&lt;/strong&gt; Use the &lt;a href="https://googlechromelabs.github.io/chrome-for-testing/"&gt;Chrome for Testing API&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Visit the Chrome for Testing availability dashboard&lt;/li&gt; 
 &lt;li&gt;Find your Chrome version or the closest available match&lt;/li&gt; 
 &lt;li&gt;Download the ChromeDriver for your OS (Linux64 for Docker environments)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;For older Chrome versions:&lt;/strong&gt; Use the &lt;a href="https://chromedriver.chromium.org/downloads"&gt;legacy ChromeDriver downloads&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/media/chromedriver_readme.png" alt="Download ChromeDriver from Chrome for Testing" /&gt;&lt;/p&gt; 
&lt;h4&gt;3. Install ChromeDriver (Choose One Method)&lt;/h4&gt; 
&lt;p&gt;&lt;strong&gt;Method A: Project Root Directory (Recommended for Docker)&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Place the downloaded chromedriver binary in your project root
cp path/to/downloaded/chromedriver ./chromedriver
chmod +x ./chromedriver  # Make executable on Linux/macOS
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Method B: System PATH&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Linux/macOS
sudo mv chromedriver /usr/local/bin/
sudo chmod +x /usr/local/bin/chromedriver

# Windows: Place chromedriver.exe in a folder that's in your PATH
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;4. Verify Installation&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Test the ChromeDriver version
./chromedriver --version
# OR if in PATH:
chromedriver --version
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Docker-Specific Notes&lt;/h3&gt; 
&lt;p&gt;âš ï¸ &lt;strong&gt;Important for Docker Users:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;The Docker volume mount approach may not work with stealth mode (&lt;code&gt;undetected_chromedriver&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Solution&lt;/strong&gt;: Place ChromeDriver in the project root directory as &lt;code&gt;./chromedriver&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;The application will automatically detect and use this binary&lt;/li&gt; 
 &lt;li&gt;You should see: &lt;code&gt;"Using ChromeDriver from project root: ./chromedriver"&lt;/code&gt; in the logs&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Troubleshooting Tips&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Still getting version mismatch?&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Verify the ChromeDriver is executable: &lt;code&gt;ls -la ./chromedriver&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;Check the ChromeDriver version: &lt;code&gt;./chromedriver --version&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;Ensure it matches your Chrome browser version&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Docker container issues?&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Check backend logs: &lt;code&gt;docker logs backend&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;Look for the message: &lt;code&gt;"Using ChromeDriver from project root"&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;If not found, verify the file exists and is executable&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Chrome for Testing versions&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Use the exact version match when possible&lt;/li&gt; 
   &lt;li&gt;For version 134.0.6998.88, use ChromeDriver 134.0.6998.165 (closest available)&lt;/li&gt; 
   &lt;li&gt;Major version numbers must match (134 = 134)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Version Compatibility Matrix&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Chrome Version&lt;/th&gt; 
   &lt;th&gt;ChromeDriver Version&lt;/th&gt; 
   &lt;th&gt;Status&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;134.0.6998.x&lt;/td&gt; 
   &lt;td&gt;134.0.6998.165&lt;/td&gt; 
   &lt;td&gt;âœ… Works&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;133.0.6943.x&lt;/td&gt; 
   &lt;td&gt;133.0.6943.141&lt;/td&gt; 
   &lt;td&gt;âœ… Works&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;132.0.6834.x&lt;/td&gt; 
   &lt;td&gt;132.0.6834.159&lt;/td&gt; 
   &lt;td&gt;âœ… Works&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;em&gt;For the latest compatibility, check the &lt;a href="https://googlechromelabs.github.io/chrome-for-testing/"&gt;Chrome for Testing dashboard&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;Exception: Failed to initialize browser: Message: session not created: This version of ChromeDriver only supports Chrome version 113 Current browser version is 134.0.6998.89 with binary path&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;This happen if there is a mismatch between your browser and chromedriver version.&lt;/p&gt; 
&lt;p&gt;You need to navigate to download the latest version:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://developer.chrome.com/docs/chromedriver/downloads"&gt;https://developer.chrome.com/docs/chromedriver/downloads&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;If you're using Chrome version 115 or newer go to:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://googlechromelabs.github.io/chrome-for-testing/"&gt;https://googlechromelabs.github.io/chrome-for-testing/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;And download the chromedriver version matching your OS.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/media/chromedriver_readme.png" alt="alt text" /&gt;&lt;/p&gt; 
&lt;p&gt;If this section is incomplete please raise an issue.&lt;/p&gt; 
&lt;h2&gt;connection adapters Issues&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;Exception: Provider lm-studio failed: HTTP request failed: No connection adapters were found for '127.0.0.1:1234/v1/chat/completions'` (Note: port may vary)
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Cause:&lt;/strong&gt; The &lt;code&gt;provider_server_address&lt;/code&gt; in &lt;code&gt;config.ini&lt;/code&gt; for &lt;code&gt;lm-studio&lt;/code&gt; (or other similar local OpenAI-compatible servers) is missing the &lt;code&gt;http://&lt;/code&gt; prefix or is pointing to the wrong port.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Solution:&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Ensure the address includes &lt;code&gt;http://&lt;/code&gt;. LM-Studio typically defaults to &lt;code&gt;http://127.0.0.1:1234&lt;/code&gt;.&lt;/li&gt; 
   &lt;li&gt;Correct &lt;code&gt;config.ini&lt;/code&gt;: &lt;code&gt;provider_server_address = http://127.0.0.1:1234&lt;/code&gt; (or your actual LM-Studio server port).&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;SearxNG Base URL Not Provided&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;raise ValueError("SearxNG base URL must be provided either as an argument or via the SEARXNG_BASE_URL environment variable.")
ValueError: SearxNG base URL must be provided either as an argument or via the SEARXNG_BASE_URL environment variable.`
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This might arise if you are running the CLI mode with the wrong base url for searxng.&lt;/p&gt; 
&lt;p&gt;The SEARXNG_BASE_URL should be depending on whenever you run in docker or on host:&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Run on host&lt;/strong&gt;: &lt;code&gt;SEARXNG_BASE_URL="http://localhost:8080"&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Run fully in docker (web interface)&lt;/strong&gt;: &lt;code&gt;SEARXNG_BASE_URL="http://searxng:8080"&lt;/code&gt;&lt;/p&gt; 
&lt;h2&gt;FAQ&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Q: What hardware do I need?&lt;/strong&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Model Size&lt;/th&gt; 
   &lt;th&gt;GPU&lt;/th&gt; 
   &lt;th&gt;Comment&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;7B&lt;/td&gt; 
   &lt;td&gt;8GB Vram&lt;/td&gt; 
   &lt;td&gt;âš ï¸ Not recommended. Performance is poor, frequent hallucinations, and planner agents will likely fail.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;14B&lt;/td&gt; 
   &lt;td&gt;12 GB VRAM (e.g. RTX 3060)&lt;/td&gt; 
   &lt;td&gt;âœ… Usable for simple tasks. May struggle with web browsing and planning tasks.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;32B&lt;/td&gt; 
   &lt;td&gt;24+ GB VRAM (e.g. RTX 4090)&lt;/td&gt; 
   &lt;td&gt;ğŸš€ Success with most tasks, might still struggle with task planning&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;70B+&lt;/td&gt; 
   &lt;td&gt;48+ GB Vram&lt;/td&gt; 
   &lt;td&gt;ğŸ’ª Excellent. Recommended for advanced use cases.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;Q: I get an error what do I do?&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Ensure local is running (&lt;code&gt;ollama serve&lt;/code&gt;), your &lt;code&gt;config.ini&lt;/code&gt; matches your provider, and dependencies are installed. If none work feel free to raise an issue.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Q: Can it really run 100% locally?&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Yes with Ollama, lm-studio or server providers, all speech to text, LLM and text to speech model run locally. Non-local options (OpenAI or others API) are optional.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Q: Why should I use AgenticSeek when I have Manus?&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Unlike Manus, AgenticSeek prioritizes independence from external systems, giving you more control, privacy and avoid api cost.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Q: Who is behind the project ?&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;The project was created by me, along with two friends who serve as maintainers and contributors from the open-source community on GitHub. Weâ€™re just a group of passionate individuals, not a startup or affiliated with any organization.&lt;/p&gt; 
&lt;p&gt;Any AgenticSeek account on X other than my personal account (&lt;a href="https://x.com/Martin993886460"&gt;https://x.com/Martin993886460&lt;/a&gt;) is an impersonation.&lt;/p&gt; 
&lt;h2&gt;Contribute&lt;/h2&gt; 
&lt;p&gt;Weâ€™re looking for developers to improve AgenticSeek! Check out open issues or discussion.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/docs/CONTRIBUTING.md"&gt;Contribution guide&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Sponsors:&lt;/h2&gt; 
&lt;p&gt;Want to level up AgenticSeek capabilities with features like flight search, trip planning, or snagging the best shopping deals? Consider crafting a custom tool with SerpApi to unlock more Jarvis-like capabilities. With SerpApi, you can turbocharge your agent for specialized tasks while staying in full control.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://serpapi.com/"&gt;&lt;img src="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/media/banners/sponsor_banner_serpapi.png" height="350" alt="SerpApi Banner" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/docs/CONTRIBUTING.md"&gt;Contributing.md&lt;/a&gt; to learn how to integrate custom tools!&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;Patron sponsor&lt;/strong&gt;:&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tatra-labs"&gt;tatra-labs&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Maintainers:&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;a href="https://github.com/Fosowl"&gt;Fosowl&lt;/a&gt; | Paris Time&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;a href="https://github.com/antoineVIVIES"&gt;antoineVIVIES&lt;/a&gt; | Taipei Time&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Special Thanks:&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;a href="https://github.com/tcsenpai"&gt;tcsenpai&lt;/a&gt; and &lt;a href="https://github.com/plitc"&gt;plitc&lt;/a&gt; For helping with backend dockerization&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;a href="https://www.star-history.com/#Fosowl/agenticSeek&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=Fosowl/agenticSeek&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>microsoft/qlib</title>
      <link>https://github.com/microsoft/qlib</link>
      <description>&lt;p&gt;Qlib is an AI-oriented Quant investment platform that aims to use AI tech to empower Quant Research, from exploring ideas to implementing productions. Qlib supports diverse ML modeling paradigms, including supervised learning, market dynamics modeling, and RL, and is now equipped with https://github.com/microsoft/RD-Agent to automate R&amp;D process.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href="https://pypi.org/project/pyqlib/#files"&gt;&lt;img src="https://img.shields.io/pypi/pyversions/pyqlib.svg?logo=python&amp;amp;logoColor=white" alt="Python Versions" /&gt;&lt;/a&gt; &lt;a href="https://pypi.org/project/pyqlib/#files"&gt;&lt;img src="https://img.shields.io/badge/platform-linux%20%7C%20windows%20%7C%20macos-lightgrey" alt="Platform" /&gt;&lt;/a&gt; &lt;a href="https://pypi.org/project/pyqlib/#history"&gt;&lt;img src="https://img.shields.io/pypi/v/pyqlib" alt="PypI Versions" /&gt;&lt;/a&gt; &lt;a href="https://pypi.org/project/pyqlib/"&gt;&lt;img src="https://github.com/microsoft/qlib/workflows/Upload%20Python%20Package/badge.svg?sanitize=true" alt="Upload Python Package" /&gt;&lt;/a&gt; &lt;a href="https://github.com/microsoft/qlib/actions"&gt;&lt;img src="https://github.com/microsoft/qlib/workflows/Test/badge.svg?branch=main" alt="Github Actions Test Status" /&gt;&lt;/a&gt; &lt;a href="https://qlib.readthedocs.io/en/latest/?badge=latest"&gt;&lt;img src="https://readthedocs.org/projects/qlib/badge/?version=latest" alt="Documentation Status" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/LICENSE"&gt;&lt;img src="https://img.shields.io/pypi/l/pyqlib" alt="License" /&gt;&lt;/a&gt; &lt;a href="https://gitter.im/Microsoft/qlib?utm_source=badge&amp;amp;utm_medium=badge&amp;amp;utm_campaign=pr-badge&amp;amp;utm_content=badge"&gt;&lt;img src="https://badges.gitter.im/Microsoft/qlib.svg?sanitize=true" alt="Join the chat at https://gitter.im/Microsoft/qlib" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;&lt;span&gt;ğŸ“°&lt;/span&gt; &lt;strong&gt;What's NEW!&lt;/strong&gt; &amp;nbsp; &lt;span&gt;ğŸ’–&lt;/span&gt;&lt;/h2&gt; 
&lt;p&gt;Recent released features&lt;/p&gt; 
&lt;h3&gt;Introducing &lt;a href="https://github.com/microsoft/RD-Agent"&gt;&lt;img src="https://raw.githubusercontent.com/microsoft/qlib/main/docs/_static/img/rdagent_logo.png" alt="RD_Agent" style="height: 2em" /&gt;&lt;/a&gt;: LLM-Based Autonomous Evolving Agents for Industrial Data-Driven R&amp;amp;D&lt;/h3&gt; 
&lt;p&gt;We are excited to announce the release of &lt;strong&gt;RD-Agent&lt;/strong&gt;ğŸ“¢, a powerful tool that supports automated factor mining and model optimization in quant investment R&amp;amp;D.&lt;/p&gt; 
&lt;p&gt;RD-Agent is now available on &lt;a href="https://github.com/microsoft/RD-Agent"&gt;GitHub&lt;/a&gt;, and we welcome your starğŸŒŸ!&lt;/p&gt; 
&lt;p&gt;To learn more, please visit our &lt;a href="https://rdagent.azurewebsites.net/"&gt;â™¾ï¸Demo page&lt;/a&gt;. Here, you will find demo videos in both English and Chinese to help you better understand the scenario and usage of RD-Agent.&lt;/p&gt; 
&lt;p&gt;We have prepared several demo videos for you:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Scenario&lt;/th&gt; 
   &lt;th&gt;Demo video (English)&lt;/th&gt; 
   &lt;th&gt;Demo video (ä¸­æ–‡)&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Quant Factor Mining&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://rdagent.azurewebsites.net/factor_loop?lang=en"&gt;Link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://rdagent.azurewebsites.net/factor_loop?lang=zh"&gt;Link&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Quant Factor Mining from reports&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://rdagent.azurewebsites.net/report_factor?lang=en"&gt;Link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://rdagent.azurewebsites.net/report_factor?lang=zh"&gt;Link&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Quant Model Optimization&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://rdagent.azurewebsites.net/model_loop?lang=en"&gt;Link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://rdagent.azurewebsites.net/model_loop?lang=zh"&gt;Link&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;ul&gt; 
 &lt;li&gt;ğŸ“ƒ&lt;strong&gt;Paper&lt;/strong&gt;: &lt;a href="https://arxiv.org/abs/2505.15155"&gt;R&amp;amp;D-Agent-Quant: A Multi-Agent Framework for Data-Centric Factors and Model Joint Optimization&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;ğŸ‘¾&lt;strong&gt;Code&lt;/strong&gt;: &lt;a href="https://github.com/microsoft/RD-Agent/"&gt;https://github.com/microsoft/RD-Agent/&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-BibTeX"&gt;@misc{li2025rdagentquant,
    title={R\&amp;amp;D-Agent-Quant: A Multi-Agent Framework for Data-Centric Factors and Model Joint Optimization},
    author={Yuante Li and Xu Yang and Xiao Yang and Minrui Xu and Xisen Wang and Weiqing Liu and Jiang Bian},
    year={2025},
    eprint={2505.15155},
    archivePrefix={arXiv},
    primaryClass={cs.AI}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/3198bc10-47ba-4ee0-8a8e-46d5ce44f45d" alt="image" /&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Feature&lt;/th&gt; 
   &lt;th&gt;Status&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://arxiv.org/abs/2505.15155"&gt;R&amp;amp;D-Agent-Quant&lt;/a&gt; Published&lt;/td&gt; 
   &lt;td&gt;Apply R&amp;amp;D-Agent to Qlib for quant trading&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BPQP for End-to-end learning&lt;/td&gt; 
   &lt;td&gt;ğŸ“ˆComing soon!(&lt;a href="https://github.com/microsoft/qlib/pull/1863"&gt;Under review&lt;/a&gt;)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ğŸ”¥LLM-driven Auto Quant FactoryğŸ”¥&lt;/td&gt; 
   &lt;td&gt;ğŸš€ Released in &lt;a href="https://github.com/microsoft/RD-Agent"&gt;â™¾ï¸RD-Agent&lt;/a&gt; on Aug 8, 2024&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;KRNN and Sandwich models&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;ğŸ“ˆ&lt;/span&gt; &lt;a href="https://github.com/microsoft/qlib/pull/1414/"&gt;Released&lt;/a&gt; on May 26, 2023&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Release Qlib v0.9.0&lt;/td&gt; 
   &lt;td&gt;&lt;img alt="octocat" src="https://github.githubassets.com/images/icons/emoji/octocat.png?v8" /&gt;) &lt;a href="https://github.com/microsoft/qlib/releases/tag/v0.9.0"&gt;Released&lt;/a&gt; on Dec 9, 2022&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;RL Learning Framework&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;ğŸ”¨&lt;/span&gt; &lt;span&gt;ğŸ“ˆ&lt;/span&gt; Released on Nov 10, 2022. &lt;a href="https://github.com/microsoft/qlib/pull/1332"&gt;#1332&lt;/a&gt;, &lt;a href="https://github.com/microsoft/qlib/pull/1322"&gt;#1322&lt;/a&gt;, &lt;a href="https://github.com/microsoft/qlib/pull/1316"&gt;#1316&lt;/a&gt;,&lt;a href="https://github.com/microsoft/qlib/pull/1299"&gt;#1299&lt;/a&gt;,&lt;a href="https://github.com/microsoft/qlib/pull/1263"&gt;#1263&lt;/a&gt;, &lt;a href="https://github.com/microsoft/qlib/pull/1244"&gt;#1244&lt;/a&gt;, &lt;a href="https://github.com/microsoft/qlib/pull/1169"&gt;#1169&lt;/a&gt;, &lt;a href="https://github.com/microsoft/qlib/pull/1125"&gt;#1125&lt;/a&gt;, &lt;a href="https://github.com/microsoft/qlib/pull/1076"&gt;#1076&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;HIST and IGMTF models&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;ğŸ“ˆ&lt;/span&gt; &lt;a href="https://github.com/microsoft/qlib/pull/1040"&gt;Released&lt;/a&gt; on Apr 10, 2022&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Qlib &lt;a href="https://github.com/microsoft/qlib/tree/main/examples/tutorial"&gt;notebook tutorial&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;ğŸ“– &lt;a href="https://github.com/microsoft/qlib/pull/1037"&gt;Released&lt;/a&gt; on Apr 7, 2022&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Ibovespa index data&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;ğŸš&lt;/span&gt; &lt;a href="https://github.com/microsoft/qlib/pull/990"&gt;Released&lt;/a&gt; on Apr 6, 2022&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Point-in-Time database&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;ğŸ”¨&lt;/span&gt; &lt;a href="https://github.com/microsoft/qlib/pull/343"&gt;Released&lt;/a&gt; on Mar 10, 2022&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Arctic Provider Backend &amp;amp; Orderbook data example&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;ğŸ”¨&lt;/span&gt; &lt;a href="https://github.com/microsoft/qlib/pull/744"&gt;Released&lt;/a&gt; on Jan 17, 2022&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Meta-Learning-based framework &amp;amp; DDG-DA&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;ğŸ“ˆ&lt;/span&gt; &lt;span&gt;ğŸ”¨&lt;/span&gt; &lt;a href="https://github.com/microsoft/qlib/pull/743"&gt;Released&lt;/a&gt; on Jan 10, 2022&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Planning-based portfolio optimization&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;ğŸ”¨&lt;/span&gt; &lt;a href="https://github.com/microsoft/qlib/pull/754"&gt;Released&lt;/a&gt; on Dec 28, 2021&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Release Qlib v0.8.0&lt;/td&gt; 
   &lt;td&gt;&lt;img alt="octocat" src="https://github.githubassets.com/images/icons/emoji/octocat.png?v8" /&gt;) &lt;a href="https://github.com/microsoft/qlib/releases/tag/v0.8.0"&gt;Released&lt;/a&gt; on Dec 8, 2021&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ADD model&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;ğŸ“ˆ&lt;/span&gt; &lt;a href="https://github.com/microsoft/qlib/pull/704"&gt;Released&lt;/a&gt; on Nov 22, 2021&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ADARNN model&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;ğŸ“ˆ&lt;/span&gt; &lt;a href="https://github.com/microsoft/qlib/pull/689"&gt;Released&lt;/a&gt; on Nov 14, 2021&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;TCN model&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;ğŸ“ˆ&lt;/span&gt; &lt;a href="https://github.com/microsoft/qlib/pull/668"&gt;Released&lt;/a&gt; on Nov 4, 2021&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Nested Decision Framework&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;ğŸ”¨&lt;/span&gt; &lt;a href="https://github.com/microsoft/qlib/pull/438"&gt;Released&lt;/a&gt; on Oct 1, 2021. &lt;a href="https://github.com/microsoft/qlib/raw/main/examples/nested_decision_execution/workflow.py"&gt;Example&lt;/a&gt; and &lt;a href="https://qlib.readthedocs.io/en/latest/component/highfreq.html"&gt;Doc&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Temporal Routing Adaptor (TRA)&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;ğŸ“ˆ&lt;/span&gt; &lt;a href="https://github.com/microsoft/qlib/pull/531"&gt;Released&lt;/a&gt; on July 30, 2021&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Transformer &amp;amp; Localformer&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;ğŸ“ˆ&lt;/span&gt; &lt;a href="https://github.com/microsoft/qlib/pull/508"&gt;Released&lt;/a&gt; on July 22, 2021&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Release Qlib v0.7.0&lt;/td&gt; 
   &lt;td&gt;&lt;img alt="octocat" src="https://github.githubassets.com/images/icons/emoji/octocat.png?v8" /&gt;) &lt;a href="https://github.com/microsoft/qlib/releases/tag/v0.7.0"&gt;Released&lt;/a&gt; on July 12, 2021&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;TCTS Model&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;ğŸ“ˆ&lt;/span&gt; &lt;a href="https://github.com/microsoft/qlib/pull/491"&gt;Released&lt;/a&gt; on July 1, 2021&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Online serving and automatic model rolling&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;ğŸ”¨&lt;/span&gt; &lt;a href="https://github.com/microsoft/qlib/pull/290"&gt;Released&lt;/a&gt; on May 17, 2021&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;DoubleEnsemble Model&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;ğŸ“ˆ&lt;/span&gt; &lt;a href="https://github.com/microsoft/qlib/pull/286"&gt;Released&lt;/a&gt; on Mar 2, 2021&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;High-frequency data processing example&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;ğŸ”¨&lt;/span&gt; &lt;a href="https://github.com/microsoft/qlib/pull/257"&gt;Released&lt;/a&gt; on Feb 5, 2021&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;High-frequency trading example&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;ğŸ“ˆ&lt;/span&gt; &lt;a href="https://github.com/microsoft/qlib/pull/227"&gt;Part of code released&lt;/a&gt; on Jan 28, 2021&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;High-frequency data(1min)&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;ğŸš&lt;/span&gt; &lt;a href="https://github.com/microsoft/qlib/pull/221"&gt;Released&lt;/a&gt; on Jan 27, 2021&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Tabnet Model&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;ğŸ“ˆ&lt;/span&gt; &lt;a href="https://github.com/microsoft/qlib/pull/205"&gt;Released&lt;/a&gt; on Jan 22, 2021&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Features released before 2021 are not listed here.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/microsoft/qlib/main/docs/_static/img/logo/1.png" /&gt; &lt;/p&gt; 
&lt;p&gt;Qlib is an open-source, AI-oriented quantitative investment platform that aims to realize the potential, empower research, and create value using AI technologies in quantitative investment, from exploring ideas to implementing productions. Qlib supports diverse machine learning modeling paradigms, including supervised learning, market dynamics modeling, and reinforcement learning.&lt;/p&gt; 
&lt;p&gt;An increasing number of SOTA Quant research works/papers in diverse paradigms are being released in Qlib to collaboratively solve key challenges in quantitative investment. For example, 1) using supervised learning to mine the market's complex non-linear patterns from rich and heterogeneous financial data, 2) modeling the dynamic nature of the financial market using adaptive concept drift technology, and 3) using reinforcement learning to model continuous investment decisions and assist investors in optimizing their trading strategies.&lt;/p&gt; 
&lt;p&gt;It contains the full ML pipeline of data processing, model training, back-testing; and covers the entire chain of quantitative investment: alpha seeking, risk modeling, portfolio optimization, and order execution. For more details, please refer to our paper &lt;a href="https://arxiv.org/abs/2009.11189"&gt;"Qlib: An AI-oriented Quantitative Investment Platform"&lt;/a&gt;.&lt;/p&gt; 
&lt;table&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Frameworks, Tutorial, Data &amp;amp; DevOps&lt;/th&gt; 
   &lt;th&gt;Main Challenges &amp;amp; Solutions in Quant Research&lt;/th&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/#plans"&gt;&lt;strong&gt;Plans&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/#framework-of-qlib"&gt;Framework of Qlib&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/#quick-start"&gt;Quick Start&lt;/a&gt;&lt;/li&gt; 
    &lt;ul dir="auto"&gt; 
     &lt;li type="circle"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/#installation"&gt;Installation&lt;/a&gt; &lt;/li&gt; 
     &lt;li type="circle"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/#data-preparation"&gt;Data Preparation&lt;/a&gt;&lt;/li&gt; 
     &lt;li type="circle"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/#auto-quant-research-workflow"&gt;Auto Quant Research Workflow&lt;/a&gt;&lt;/li&gt; 
     &lt;li type="circle"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/#building-customized-quant-research-workflow-by-code"&gt;Building Customized Quant Research Workflow by Code&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt; &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/#quant-dataset-zoo"&gt;&lt;strong&gt;Quant Dataset Zoo&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/#learning-framework"&gt;Learning Framework&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/#more-about-qlib"&gt;More About Qlib&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/#offline-mode-and-online-mode"&gt;Offline Mode and Online Mode&lt;/a&gt; 
     &lt;ul&gt; 
      &lt;li type="circle"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/#performance-of-qlib-data-server"&gt;Performance of Qlib Data Server&lt;/a&gt;&lt;/li&gt;
     &lt;/ul&gt; &lt;/li&gt;&lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/#related-reports"&gt;Related Reports&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/#contact-us"&gt;Contact Us&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/#contributing"&gt;Contributing&lt;/a&gt;&lt;/li&gt; &lt;/td&gt; 
   &lt;td valign="baseline"&gt; &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/#main-challenges--solutions-in-quant-research"&gt;Main Challenges &amp;amp; Solutions in Quant Research&lt;/a&gt; 
     &lt;ul&gt; 
      &lt;li type="circle"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/#forecasting-finding-valuable-signalspatterns"&gt;Forecasting: Finding Valuable Signals/Patterns&lt;/a&gt; 
       &lt;ul&gt; 
        &lt;li type="disc"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/#quant-model-paper-zoo"&gt;&lt;strong&gt;Quant Model (Paper) Zoo&lt;/strong&gt;&lt;/a&gt; 
         &lt;ul&gt; 
          &lt;li type="circle"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/#run-a-single-model"&gt;Run a Single Model&lt;/a&gt;&lt;/li&gt; 
          &lt;li type="circle"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/#run-multiple-models"&gt;Run Multiple Models&lt;/a&gt;&lt;/li&gt; 
         &lt;/ul&gt; &lt;/li&gt; 
       &lt;/ul&gt; &lt;/li&gt; 
      &lt;li type="circle"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/#adapting-to-market-dynamics"&gt;Adapting to Market Dynamics&lt;/a&gt;&lt;/li&gt; 
      &lt;li type="circle"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/#reinforcement-learning-modeling-continuous-decisions"&gt;Reinforcement Learning: modeling continuous decisions&lt;/a&gt;&lt;/li&gt; 
     &lt;/ul&gt; &lt;/li&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h1&gt;Plans&lt;/h1&gt; 
&lt;p&gt;New features under development(order by estimated release time). Your feedbacks about the features are very important.&lt;/p&gt; 
&lt;!-- | Feature                        | Status      | --&gt; 
&lt;!-- | --                      | ------    | --&gt; 
&lt;h1&gt;Framework of Qlib&lt;/h1&gt; 
&lt;div style="align: center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/microsoft/qlib/main/docs/_static/img/framework-abstract.jpg" /&gt; 
&lt;/div&gt; 
&lt;p&gt;The high-level framework of Qlib can be found above(users can find the &lt;a href="https://qlib.readthedocs.io/en/latest/introduction/introduction.html#framework"&gt;detailed framework&lt;/a&gt; of Qlib's design when getting into nitty gritty). The components are designed as loose-coupled modules, and each component could be used stand-alone.&lt;/p&gt; 
&lt;p&gt;Qlib provides a strong infrastructure to support Quant research. &lt;a href="https://qlib.readthedocs.io/en/latest/component/data.html"&gt;Data&lt;/a&gt; is always an important part. A strong learning framework is designed to support diverse learning paradigms (e.g. &lt;a href="https://qlib.readthedocs.io/en/latest/component/rl.html"&gt;reinforcement learning&lt;/a&gt;, &lt;a href="https://qlib.readthedocs.io/en/latest/component/workflow.html#model-section"&gt;supervised learning&lt;/a&gt;) and patterns at different levels(e.g. &lt;a href="https://qlib.readthedocs.io/en/latest/component/meta.html"&gt;market dynamic modeling&lt;/a&gt;). By modeling the market, &lt;a href="https://qlib.readthedocs.io/en/latest/component/strategy.html"&gt;trading strategies&lt;/a&gt; will generate trade decisions that will be executed. Multiple trading strategies and executors in different levels or granularities can be &lt;a href="https://qlib.readthedocs.io/en/latest/component/highfreq.html"&gt;nested to be optimized and run together&lt;/a&gt;. At last, a comprehensive &lt;a href="https://qlib.readthedocs.io/en/latest/component/report.html"&gt;analysis&lt;/a&gt; will be provided and the model can be &lt;a href="https://qlib.readthedocs.io/en/latest/component/online.html"&gt;served online&lt;/a&gt; in a low cost.&lt;/p&gt; 
&lt;h1&gt;Quick Start&lt;/h1&gt; 
&lt;p&gt;This quick start guide tries to demonstrate&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;It's very easy to build a complete Quant research workflow and try your ideas with &lt;em&gt;Qlib&lt;/em&gt;.&lt;/li&gt; 
 &lt;li&gt;Though with &lt;em&gt;public data&lt;/em&gt; and &lt;em&gt;simple models&lt;/em&gt;, machine learning technologies &lt;strong&gt;work very well&lt;/strong&gt; in practical Quant investment.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Here is a quick &lt;strong&gt;&lt;a href="https://terminalizer.com/view/3f24561a4470"&gt;demo&lt;/a&gt;&lt;/strong&gt; shows how to install &lt;code&gt;Qlib&lt;/code&gt;, and run LightGBM with &lt;code&gt;qrun&lt;/code&gt;. &lt;strong&gt;But&lt;/strong&gt;, please make sure you have already prepared the data following the &lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/#data-preparation"&gt;instruction&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;This table demonstrates the supported Python version of &lt;code&gt;Qlib&lt;/code&gt;:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;&lt;/th&gt; 
   &lt;th align="center"&gt;install with pip&lt;/th&gt; 
   &lt;th align="center"&gt;install from source&lt;/th&gt; 
   &lt;th align="center"&gt;plot&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Python 3.8&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;span&gt;âœ”&lt;/span&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;span&gt;âœ”&lt;/span&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;span&gt;âœ”&lt;/span&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Python 3.9&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;span&gt;âœ”&lt;/span&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;span&gt;âœ”&lt;/span&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;span&gt;âœ”&lt;/span&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Python 3.10&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;span&gt;âœ”&lt;/span&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;span&gt;âœ”&lt;/span&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;span&gt;âœ”&lt;/span&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Python 3.11&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;span&gt;âœ”&lt;/span&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;span&gt;âœ”&lt;/span&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;span&gt;âœ”&lt;/span&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Python 3.12&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;span&gt;âœ”&lt;/span&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;span&gt;âœ”&lt;/span&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;span&gt;âœ”&lt;/span&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Conda&lt;/strong&gt; is suggested for managing your Python environment. In some cases, using Python outside of a &lt;code&gt;conda&lt;/code&gt; environment may result in missing header files, causing the installation failure of certain packages.&lt;/li&gt; 
 &lt;li&gt;Please pay attention that installing cython in Python 3.6 will raise some error when installing &lt;code&gt;Qlib&lt;/code&gt; from source. If users use Python 3.6 on their machines, it is recommended to &lt;em&gt;upgrade&lt;/em&gt; Python to version 3.8 or higher, or use &lt;code&gt;conda&lt;/code&gt;'s Python to install &lt;code&gt;Qlib&lt;/code&gt; from source.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Install with pip&lt;/h3&gt; 
&lt;p&gt;Users can easily install &lt;code&gt;Qlib&lt;/code&gt; by pip according to the following command.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;  pip install pyqlib
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: pip will install the latest stable qlib. However, the main branch of qlib is in active development. If you want to test the latest scripts or functions in the main branch. Please install qlib with the methods below.&lt;/p&gt; 
&lt;h3&gt;Install from source&lt;/h3&gt; 
&lt;p&gt;Also, users can install the latest dev version &lt;code&gt;Qlib&lt;/code&gt; by the source code according to the following steps:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Before installing &lt;code&gt;Qlib&lt;/code&gt; from source, users need to install some dependencies:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;pip install numpy
pip install --upgrade cython
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Clone the repository and install &lt;code&gt;Qlib&lt;/code&gt; as follows.&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/microsoft/qlib.git &amp;amp;&amp;amp; cd qlib
pip install .  # `pip install -e .[dev]` is recommended for development. check details in docs/developer/code_standard_and_dev_guide.rst
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Tips&lt;/strong&gt;: If you fail to install &lt;code&gt;Qlib&lt;/code&gt; or run the examples in your environment, comparing your steps and the &lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/.github/workflows/test_qlib_from_source.yml"&gt;CI workflow&lt;/a&gt; may help you find the problem.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Tips for Mac&lt;/strong&gt;: If you are using Mac with M1, you might encounter issues in building the wheel for LightGBM, which is due to missing dependencies from OpenMP. To solve the problem, install openmp first with &lt;code&gt;brew install libomp&lt;/code&gt; and then run &lt;code&gt;pip install .&lt;/code&gt; to build it successfully.&lt;/p&gt; 
&lt;h2&gt;Data Preparation&lt;/h2&gt; 
&lt;p&gt;â— Due to more restrict data security policy. The official dataset is disabled temporarily. You can try &lt;a href="https://github.com/chenditc/investment_data/releases"&gt;this data source&lt;/a&gt; contributed by the community. Here is an example to download the latest data.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;wget https://github.com/chenditc/investment_data/releases/latest/download/qlib_bin.tar.gz
mkdir -p ~/.qlib/qlib_data/cn_data
tar -zxvf qlib_bin.tar.gz -C ~/.qlib/qlib_data/cn_data --strip-components=1
rm -f qlib_bin.tar.gz
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The official dataset below will resume in short future.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;Load and prepare data by running the following code:&lt;/p&gt; 
&lt;h3&gt;Get with module&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# get 1d data
python -m qlib.cli.data qlib_data --target_dir ~/.qlib/qlib_data/cn_data --region cn

# get 1min data
python -m qlib.cli.data qlib_data --target_dir ~/.qlib/qlib_data/cn_data_1min --region cn --interval 1min

&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Get from source&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# get 1d data
python scripts/get_data.py qlib_data --target_dir ~/.qlib/qlib_data/cn_data --region cn

# get 1min data
python scripts/get_data.py qlib_data --target_dir ~/.qlib/qlib_data/cn_data_1min --region cn --interval 1min

&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This dataset is created by public data collected by &lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/scripts/data_collector/"&gt;crawler scripts&lt;/a&gt;, which have been released in the same repository. Users could create the same dataset with it. &lt;a href="https://github.com/microsoft/qlib/tree/main/scripts/data_collector#description-of-dataset"&gt;Description of dataset&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;Please pay &lt;strong&gt;ATTENTION&lt;/strong&gt; that the data is collected from &lt;a href="https://finance.yahoo.com/lookup"&gt;Yahoo Finance&lt;/a&gt;, and the data might not be perfect. We recommend users to prepare their own data if they have a high-quality dataset. For more information, users can refer to the &lt;a href="https://qlib.readthedocs.io/en/latest/component/data.html#converting-csv-format-into-qlib-format"&gt;related document&lt;/a&gt;&lt;/em&gt;.&lt;/p&gt; 
&lt;h3&gt;Automatic update of daily frequency data (from yahoo finance)&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;This step is &lt;em&gt;Optional&lt;/em&gt; if users only want to try their models and strategies on history data.&lt;/p&gt; 
 &lt;p&gt;It is recommended that users update the data manually once (--trading_date 2021-05-25) and then set it to update automatically.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: Users can't incrementally update data based on the offline data provided by Qlib(some fields are removed to reduce the data size). Users should use &lt;a href="https://github.com/microsoft/qlib/tree/main/scripts/data_collector/yahoo#automatic-update-of-daily-frequency-datafrom-yahoo-finance"&gt;yahoo collector&lt;/a&gt; to download Yahoo data from scratch and then incrementally update it.&lt;/p&gt; 
 &lt;p&gt;For more information, please refer to: &lt;a href="https://github.com/microsoft/qlib/tree/main/scripts/data_collector/yahoo#automatic-update-of-daily-frequency-datafrom-yahoo-finance"&gt;yahoo collector&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Automatic update of data to the "qlib" directory each trading day(Linux)&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;use &lt;em&gt;crontab&lt;/em&gt;: &lt;code&gt;crontab -e&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;set up timed tasks:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;* * * * 1-5 python &amp;lt;script path&amp;gt; update_data_to_bin --qlib_data_1d_dir &amp;lt;user data dir&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;strong&gt;script path&lt;/strong&gt;: &lt;em&gt;scripts/data_collector/yahoo/collector.py&lt;/em&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Manual update of data&lt;/p&gt; &lt;pre&gt;&lt;code&gt;python scripts/data_collector/yahoo/collector.py update_data_to_bin --qlib_data_1d_dir &amp;lt;user data dir&amp;gt; --trading_date &amp;lt;start date&amp;gt; --end_date &amp;lt;end date&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;em&gt;trading_date&lt;/em&gt;: start of trading day&lt;/li&gt; 
   &lt;li&gt;&lt;em&gt;end_date&lt;/em&gt;: end of trading day(not included)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Checking the health of the data&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;We provide a script to check the health of the data, you can run the following commands to check whether the data is healthy or not. &lt;pre&gt;&lt;code&gt;python scripts/check_data_health.py check_data --qlib_dir ~/.qlib/qlib_data/cn_data
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;Of course, you can also add some parameters to adjust the test results, such as this. &lt;pre&gt;&lt;code&gt;python scripts/check_data_health.py check_data --qlib_dir ~/.qlib/qlib_data/cn_data --missing_data_num 30055 --large_step_threshold_volume 94485 --large_step_threshold_price 20
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;If you want more information about &lt;code&gt;check_data_health&lt;/code&gt;, please refer to the &lt;a href="https://qlib.readthedocs.io/en/latest/component/data.html#checking-the-health-of-the-data"&gt;documentation&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;!-- 
- Run the initialization code and get stock data:

  ```python
  import qlib
  from qlib.data import D
  from qlib.constant import REG_CN

  # Initialization
  mount_path = "~/.qlib/qlib_data/cn_data"  # target_dir
  qlib.init(mount_path=mount_path, region=REG_CN)

  # Get stock data by Qlib
  # Load trading calendar with the given time range and frequency
  print(D.calendar(start_time='2010-01-01', end_time='2017-12-31', freq='day')[:2])

  # Parse a given market name into a stockpool config
  instruments = D.instruments('csi500')
  print(D.list_instruments(instruments=instruments, start_time='2010-01-01', end_time='2017-12-31', as_list=True)[:6])

  # Load features of certain instruments in given time range
  instruments = ['SH600000']
  fields = ['$close', '$volume', 'Ref($close, 1)', 'Mean($close, 3)', '$high-$low']
  print(D.features(instruments, fields, start_time='2010-01-01', end_time='2017-12-31', freq='day').head())
  ```
 --&gt; 
&lt;h2&gt;Docker images&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;Pulling a docker image from a docker hub repository &lt;pre&gt;&lt;code class="language-bash"&gt;docker pull pyqlib/qlib_image_stable:stable
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;Start a new Docker container &lt;pre&gt;&lt;code class="language-bash"&gt;docker run -it --name &amp;lt;container name&amp;gt; -v &amp;lt;Mounted local directory&amp;gt;:/app pyqlib/qlib_image_stable:stable
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;At this point you are in the docker environment and can run the qlib scripts. An example: &lt;pre&gt;&lt;code class="language-bash"&gt;&amp;gt;&amp;gt;&amp;gt; python scripts/get_data.py qlib_data --name qlib_data_simple --target_dir ~/.qlib/qlib_data/cn_data --interval 1d --region cn
&amp;gt;&amp;gt;&amp;gt; python qlib/cli/run.py examples/benchmarks/LightGBM/workflow_config_lightgbm_Alpha158.yaml
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;Exit the container &lt;pre&gt;&lt;code class="language-bash"&gt;&amp;gt;&amp;gt;&amp;gt; exit
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;Restart the container &lt;pre&gt;&lt;code class="language-bash"&gt;docker start -i -a &amp;lt;container name&amp;gt;
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;Stop the container &lt;pre&gt;&lt;code class="language-bash"&gt;docker stop &amp;lt;container name&amp;gt;
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;Delete the container &lt;pre&gt;&lt;code class="language-bash"&gt;docker rm &amp;lt;container name&amp;gt;
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;If you want to know more information, please refer to the &lt;a href="https://qlib.readthedocs.io/en/latest/developer/how_to_build_image.html"&gt;documentation&lt;/a&gt;.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Auto Quant Research Workflow&lt;/h2&gt; 
&lt;p&gt;Qlib provides a tool named &lt;code&gt;qrun&lt;/code&gt; to run the whole workflow automatically (including building dataset, training models, backtest and evaluation). You can start an auto quant research workflow and have a graphical reports analysis according to the following steps:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Quant Research Workflow: Run &lt;code&gt;qrun&lt;/code&gt; with lightgbm workflow config (&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/benchmarks/LightGBM/workflow_config_lightgbm_Alpha158.yaml"&gt;workflow_config_lightgbm_Alpha158.yaml&lt;/a&gt; as following.&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;  cd examples  # Avoid running program under the directory contains `qlib`
  qrun benchmarks/LightGBM/workflow_config_lightgbm_Alpha158.yaml
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;If users want to use &lt;code&gt;qrun&lt;/code&gt; under debug mode, please use the following command:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;python -m pdb qlib/cli/run.py examples/benchmarks/LightGBM/workflow_config_lightgbm_Alpha158.yaml
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The result of &lt;code&gt;qrun&lt;/code&gt; is as follows, please refer to &lt;a href="https://qlib.readthedocs.io/en/latest/component/strategy.html#result"&gt;docs&lt;/a&gt; for more explanations about the result.&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;
'The following are analysis results of the excess return without cost.'
                       risk
mean               0.000708
std                0.005626
annualized_return  0.178316
information_ratio  1.996555
max_drawdown      -0.081806
'The following are analysis results of the excess return with cost.'
                       risk
mean               0.000512
std                0.005626
annualized_return  0.128982
information_ratio  1.444287
max_drawdown      -0.091078
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Here are detailed documents for &lt;code&gt;qrun&lt;/code&gt; and &lt;a href="https://qlib.readthedocs.io/en/latest/component/workflow.html"&gt;workflow&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Graphical Reports Analysis: First, run &lt;code&gt;python -m pip install .[analysis]&lt;/code&gt; to install the required dependencies. Then run &lt;code&gt;examples/workflow_by_code.ipynb&lt;/code&gt; with &lt;code&gt;jupyter notebook&lt;/code&gt; to get graphical reports.&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;Forecasting signal (model prediction) analysis&lt;/p&gt; 
    &lt;ul&gt; 
     &lt;li&gt;Cumulative Return of groups &lt;img src="https://github.com/microsoft/qlib/raw/main/docs/_static/img/analysis/analysis_model_cumulative_return.png" alt="Cumulative Return" /&gt;&lt;/li&gt; 
     &lt;li&gt;Return distribution &lt;img src="https://github.com/microsoft/qlib/raw/main/docs/_static/img/analysis/analysis_model_long_short.png" alt="long_short" /&gt;&lt;/li&gt; 
     &lt;li&gt;Information Coefficient (IC) &lt;img src="https://github.com/microsoft/qlib/raw/main/docs/_static/img/analysis/analysis_model_IC.png" alt="Information Coefficient" /&gt; &lt;img src="https://github.com/microsoft/qlib/raw/main/docs/_static/img/analysis/analysis_model_monthly_IC.png" alt="Monthly IC" /&gt; &lt;img src="https://github.com/microsoft/qlib/raw/main/docs/_static/img/analysis/analysis_model_NDQ.png" alt="IC" /&gt;&lt;/li&gt; 
     &lt;li&gt;Auto Correlation of forecasting signal (model prediction) &lt;img src="https://github.com/microsoft/qlib/raw/main/docs/_static/img/analysis/analysis_model_auto_correlation.png" alt="Auto Correlation" /&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;Portfolio analysis&lt;/p&gt; 
    &lt;ul&gt; 
     &lt;li&gt;Backtest return &lt;img src="https://github.com/microsoft/qlib/raw/main/docs/_static/img/analysis/report.png" alt="Report" /&gt;&lt;/li&gt; 
    &lt;/ul&gt; 
    &lt;!-- 
- Score IC
![Score IC](docs/_static/img/score_ic.png)
- Cumulative Return
![Cumulative Return](docs/_static/img/cumulative_return.png)
- Risk Analysis
![Risk Analysis](docs/_static/img/risk_analysis.png)
- Rank Label
![Rank Label](docs/_static/img/rank_label.png)
--&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;a href="https://qlib.readthedocs.io/en/latest/component/report.html"&gt;Explanation&lt;/a&gt; of above results&lt;/p&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Building Customized Quant Research Workflow by Code&lt;/h2&gt; 
&lt;p&gt;The automatic workflow may not suit the research workflow of all Quant researchers. To support a flexible Quant research workflow, Qlib also provides a modularized interface to allow researchers to build their own workflow by code. &lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/workflow_by_code.ipynb"&gt;Here&lt;/a&gt; is a demo for customized Quant research workflow by code.&lt;/p&gt; 
&lt;h1&gt;Main Challenges &amp;amp; Solutions in Quant Research&lt;/h1&gt; 
&lt;p&gt;Quant investment is a very unique scenario with lots of key challenges to be solved. Currently, Qlib provides some solutions for several of them.&lt;/p&gt; 
&lt;h2&gt;Forecasting: Finding Valuable Signals/Patterns&lt;/h2&gt; 
&lt;p&gt;Accurate forecasting of the stock price trend is a very important part to construct profitable portfolios. However, huge amount of data with various formats in the financial market which make it challenging to build forecasting models.&lt;/p&gt; 
&lt;p&gt;An increasing number of SOTA Quant research works/papers, which focus on building forecasting models to mine valuable signals/patterns in complex financial data, are released in &lt;code&gt;Qlib&lt;/code&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/benchmarks"&gt;Quant Model (Paper) Zoo&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;Here is a list of models built on &lt;code&gt;Qlib&lt;/code&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/benchmarks/XGBoost/"&gt;GBDT based on XGBoost (Tianqi Chen, et al. KDD 2016)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/benchmarks/LightGBM/"&gt;GBDT based on LightGBM (Guolin Ke, et al. NIPS 2017)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/benchmarks/CatBoost/"&gt;GBDT based on Catboost (Liudmila Prokhorenkova, et al. NIPS 2018)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/benchmarks/MLP/"&gt;MLP based on pytorch&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/benchmarks/LSTM/"&gt;LSTM based on pytorch (Sepp Hochreiter, et al. Neural computation 1997)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/benchmarks/GRU/"&gt;GRU based on pytorch (Kyunghyun Cho, et al. 2014)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/benchmarks/ALSTM"&gt;ALSTM based on pytorch (Yao Qin, et al. IJCAI 2017)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/benchmarks/GATs/"&gt;GATs based on pytorch (Petar Velickovic, et al. 2017)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/benchmarks/SFM/"&gt;SFM based on pytorch (Liheng Zhang, et al. KDD 2017)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/benchmarks/TFT/"&gt;TFT based on tensorflow (Bryan Lim, et al. International Journal of Forecasting 2019)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/benchmarks/TabNet/"&gt;TabNet based on pytorch (Sercan O. Arik, et al. AAAI 2019)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/benchmarks/DoubleEnsemble/"&gt;DoubleEnsemble based on LightGBM (Chuheng Zhang, et al. ICDM 2020)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/benchmarks/TCTS/"&gt;TCTS based on pytorch (Xueqing Wu, et al. ICML 2021)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/benchmarks/Transformer/"&gt;Transformer based on pytorch (Ashish Vaswani, et al. NeurIPS 2017)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/benchmarks/Localformer/"&gt;Localformer based on pytorch (Juyong Jiang, et al.)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/benchmarks/TRA/"&gt;TRA based on pytorch (Hengxu, Dong, et al. KDD 2021)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/benchmarks/TCN/"&gt;TCN based on pytorch (Shaojie Bai, et al. 2018)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/benchmarks/ADARNN/"&gt;ADARNN based on pytorch (YunTao Du, et al. 2021)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/benchmarks/ADD/"&gt;ADD based on pytorch (Hongshun Tang, et al.2020)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/benchmarks/IGMTF/"&gt;IGMTF based on pytorch (Wentao Xu, et al.2021)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/benchmarks/HIST/"&gt;HIST based on pytorch (Wentao Xu, et al.2021)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/benchmarks/KRNN/"&gt;KRNN based on pytorch&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/benchmarks/Sandwich/"&gt;Sandwich based on pytorch&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Your PR of new Quant models is highly welcomed.&lt;/p&gt; 
&lt;p&gt;The performance of each model on the &lt;code&gt;Alpha158&lt;/code&gt; and &lt;code&gt;Alpha360&lt;/code&gt; datasets can be found &lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/benchmarks/README.md"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Run a single model&lt;/h3&gt; 
&lt;p&gt;All the models listed above are runnable with &lt;code&gt;Qlib&lt;/code&gt;. Users can find the config files we provide and some details about the model through the &lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/benchmarks"&gt;benchmarks&lt;/a&gt; folder. More information can be retrieved at the model files listed above.&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;Qlib&lt;/code&gt; provides three different ways to run a single model, users can pick the one that fits their cases best:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Users can use the tool &lt;code&gt;qrun&lt;/code&gt; mentioned above to run a model's workflow based from a config file.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Users can create a &lt;code&gt;workflow_by_code&lt;/code&gt; python script based on the &lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/workflow_by_code.py"&gt;one&lt;/a&gt; listed in the &lt;code&gt;examples&lt;/code&gt; folder.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Users can use the script &lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/run_all_model.py"&gt;&lt;code&gt;run_all_model.py&lt;/code&gt;&lt;/a&gt; listed in the &lt;code&gt;examples&lt;/code&gt; folder to run a model. Here is an example of the specific shell command to be used: &lt;code&gt;python run_all_model.py run --models=lightgbm&lt;/code&gt;, where the &lt;code&gt;--models&lt;/code&gt; arguments can take any number of models listed above(the available models can be found in &lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/benchmarks/"&gt;benchmarks&lt;/a&gt;). For more use cases, please refer to the file's &lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/run_all_model.py"&gt;docstrings&lt;/a&gt;.&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: Each baseline has different environment dependencies, please make sure that your python version aligns with the requirements(e.g. TFT only supports Python 3.6~3.7 due to the limitation of &lt;code&gt;tensorflow==1.15.0&lt;/code&gt;)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Run multiple models&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;Qlib&lt;/code&gt; also provides a script &lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/run_all_model.py"&gt;&lt;code&gt;run_all_model.py&lt;/code&gt;&lt;/a&gt; which can run multiple models for several iterations. (&lt;strong&gt;Note&lt;/strong&gt;: the script only support &lt;em&gt;Linux&lt;/em&gt; for now. Other OS will be supported in the future. Besides, it doesn't support parallel running the same model for multiple times as well, and this will be fixed in the future development too.)&lt;/p&gt; 
&lt;p&gt;The script will create a unique virtual environment for each model, and delete the environments after training. Thus, only experiment results such as &lt;code&gt;IC&lt;/code&gt; and &lt;code&gt;backtest&lt;/code&gt; results will be generated and stored.&lt;/p&gt; 
&lt;p&gt;Here is an example of running all the models for 10 iterations:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;python run_all_model.py run 10
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;It also provides the API to run specific models at once. For more use cases, please refer to the file's &lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/run_all_model.py"&gt;docstrings&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Break change&lt;/h3&gt; 
&lt;p&gt;In &lt;code&gt;pandas&lt;/code&gt;, &lt;code&gt;group_key&lt;/code&gt; is one of the parameters of the &lt;code&gt;groupby&lt;/code&gt; method. From version 1.5 to 2.0 of &lt;code&gt;pandas&lt;/code&gt;, the default value of &lt;code&gt;group_key&lt;/code&gt; has been changed from &lt;code&gt;no default&lt;/code&gt; to &lt;code&gt;True&lt;/code&gt;, which will cause qlib to report an error during operation. So we set &lt;code&gt;group_key=False&lt;/code&gt;, but it doesn't guarantee that some programmes will run correctly, including:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;qlib\examples\rl_order_execution\scripts\gen_training_orders.py&lt;/li&gt; 
 &lt;li&gt;qlib\examples\benchmarks\TRA\src\dataset.MTSDatasetH.py&lt;/li&gt; 
 &lt;li&gt;qlib\examples\benchmarks\TFT\tft.py&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/benchmarks_dynamic"&gt;Adapting to Market Dynamics&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Due to the non-stationary nature of the environment of the financial market, the data distribution may change in different periods, which makes the performance of models build on training data decays in the future test data. So adapting the forecasting models/strategies to market dynamics is very important to the model/strategies' performance.&lt;/p&gt; 
&lt;p&gt;Here is a list of solutions built on &lt;code&gt;Qlib&lt;/code&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/benchmarks_dynamic/baseline/"&gt;Rolling Retraining&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/benchmarks_dynamic/DDG-DA/"&gt;DDG-DA on pytorch (Wendi, et al. AAAI 2022)&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Reinforcement Learning: modeling continuous decisions&lt;/h2&gt; 
&lt;p&gt;Qlib now supports reinforcement learning, a feature designed to model continuous investment decisions. This functionality assists investors in optimizing their trading strategies by learning from interactions with the environment to maximize some notion of cumulative reward.&lt;/p&gt; 
&lt;p&gt;Here is a list of solutions built on &lt;code&gt;Qlib&lt;/code&gt; categorized by scenarios.&lt;/p&gt; 
&lt;h3&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/rl_order_execution"&gt;RL for order execution&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://qlib.readthedocs.io/en/latest/component/rl/overall.html#order-execution"&gt;Here&lt;/a&gt; is the introduction of this scenario. All the methods below are compared &lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/rl_order_execution"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/rl_order_execution/exp_configs/backtest_twap.yml"&gt;TWAP&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/rl_order_execution/exp_configs/backtest_ppo.yml"&gt;PPO: "An End-to-End Optimal Trade Execution Framework based on Proximal Policy Optimization", IJCAL 2020&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/rl_order_execution/exp_configs/backtest_opds.yml"&gt;OPDS: "Universal Trading for Order Execution with Oracle Policy Distillation", AAAI 2021&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Quant Dataset Zoo&lt;/h1&gt; 
&lt;p&gt;Dataset plays a very important role in Quant. Here is a list of the datasets built on &lt;code&gt;Qlib&lt;/code&gt;:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Dataset&lt;/th&gt; 
   &lt;th&gt;US Market&lt;/th&gt; 
   &lt;th&gt;China Market&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/qlib/contrib/data/handler.py"&gt;Alpha360&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;âˆš&lt;/td&gt; 
   &lt;td&gt;âˆš&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/qlib/contrib/data/handler.py"&gt;Alpha158&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;âˆš&lt;/td&gt; 
   &lt;td&gt;âˆš&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;a href="https://qlib.readthedocs.io/en/latest/advanced/alpha.html"&gt;Here&lt;/a&gt; is a tutorial to build dataset with &lt;code&gt;Qlib&lt;/code&gt;. Your PR to build new Quant dataset is highly welcomed.&lt;/p&gt; 
&lt;h1&gt;Learning Framework&lt;/h1&gt; 
&lt;p&gt;Qlib is high customizable and a lot of its components are learnable. The learnable components are instances of &lt;code&gt;Forecast Model&lt;/code&gt; and &lt;code&gt;Trading Agent&lt;/code&gt;. They are learned based on the &lt;code&gt;Learning Framework&lt;/code&gt; layer and then applied to multiple scenarios in &lt;code&gt;Workflow&lt;/code&gt; layer. The learning framework leverages the &lt;code&gt;Workflow&lt;/code&gt; layer as well(e.g. sharing &lt;code&gt;Information Extractor&lt;/code&gt;, creating environments based on &lt;code&gt;Execution Env&lt;/code&gt;).&lt;/p&gt; 
&lt;p&gt;Based on learning paradigms, they can be categorized into reinforcement learning and supervised learning.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;For supervised learning, the detailed docs can be found &lt;a href="https://qlib.readthedocs.io/en/latest/component/model.html"&gt;here&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;For reinforcement learning, the detailed docs can be found &lt;a href="https://qlib.readthedocs.io/en/latest/component/rl.html"&gt;here&lt;/a&gt;. Qlib's RL learning framework leverages &lt;code&gt;Execution Env&lt;/code&gt; in &lt;code&gt;Workflow&lt;/code&gt; layer to create environments. It's worth noting that &lt;code&gt;NestedExecutor&lt;/code&gt; is supported as well. This empowers users to optimize different level of strategies/models/agents together (e.g. optimizing an order execution strategy for a specific portfolio management strategy).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;More About Qlib&lt;/h1&gt; 
&lt;p&gt;If you want to have a quick glance at the most frequently used components of qlib, you can try notebooks &lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/tutorial/"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;The detailed documents are organized in &lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/docs/"&gt;docs&lt;/a&gt;. &lt;a href="http://www.sphinx-doc.org"&gt;Sphinx&lt;/a&gt; and the readthedocs theme is required to build the documentation in html formats.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd docs/
conda install sphinx sphinx_rtd_theme -y
# Otherwise, you can install them with pip
# pip install sphinx sphinx_rtd_theme
make html
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can also view the &lt;a href="http://qlib.readthedocs.io/"&gt;latest document&lt;/a&gt; online directly.&lt;/p&gt; 
&lt;p&gt;Qlib is in active and continuing development. Our plan is in the roadmap, which is managed as a &lt;a href="https://github.com/microsoft/qlib/projects/1"&gt;github project&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;Offline Mode and Online Mode&lt;/h1&gt; 
&lt;p&gt;The data server of Qlib can either deployed as &lt;code&gt;Offline&lt;/code&gt; mode or &lt;code&gt;Online&lt;/code&gt; mode. The default mode is offline mode.&lt;/p&gt; 
&lt;p&gt;Under &lt;code&gt;Offline&lt;/code&gt; mode, the data will be deployed locally.&lt;/p&gt; 
&lt;p&gt;Under &lt;code&gt;Online&lt;/code&gt; mode, the data will be deployed as a shared data service. The data and their cache will be shared by all the clients. The data retrieval performance is expected to be improved due to a higher rate of cache hits. It will consume less disk space, too. The documents of the online mode can be found in &lt;a href="https://qlib-server.readthedocs.io/"&gt;Qlib-Server&lt;/a&gt;. The online mode can be deployed automatically with &lt;a href="https://qlib-server.readthedocs.io/en/latest/build.html#one-click-deployment-in-azure"&gt;Azure CLI based scripts&lt;/a&gt;. The source code of online data server can be found in &lt;a href="https://github.com/microsoft/qlib-server"&gt;Qlib-Server repository&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Performance of Qlib Data Server&lt;/h2&gt; 
&lt;p&gt;The performance of data processing is important to data-driven methods like AI technologies. As an AI-oriented platform, Qlib provides a solution for data storage and data processing. To demonstrate the performance of Qlib data server, we compare it with several other data storage solutions.&lt;/p&gt; 
&lt;p&gt;We evaluate the performance of several storage solutions by finishing the same task, which creates a dataset (14 features/factors) from the basic OHLCV daily data of a stock market (800 stocks each day from 2007 to 2020). The task involves data queries and processing.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;&lt;/th&gt; 
   &lt;th&gt;HDF5&lt;/th&gt; 
   &lt;th&gt;MySQL&lt;/th&gt; 
   &lt;th&gt;MongoDB&lt;/th&gt; 
   &lt;th&gt;InfluxDB&lt;/th&gt; 
   &lt;th&gt;Qlib -E -D&lt;/th&gt; 
   &lt;th&gt;Qlib +E -D&lt;/th&gt; 
   &lt;th&gt;Qlib +E +D&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Total (1CPU) (seconds)&lt;/td&gt; 
   &lt;td&gt;184.4Â±3.7&lt;/td&gt; 
   &lt;td&gt;365.3Â±7.5&lt;/td&gt; 
   &lt;td&gt;253.6Â±6.7&lt;/td&gt; 
   &lt;td&gt;368.2Â±3.6&lt;/td&gt; 
   &lt;td&gt;147.0Â±8.8&lt;/td&gt; 
   &lt;td&gt;47.6Â±1.0&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;7.4Â±0.3&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Total (64CPU) (seconds)&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;8.8Â±0.6&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;4.2Â±0.2&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;+(-)E&lt;/code&gt; indicates with (out) &lt;code&gt;ExpressionCache&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;+(-)D&lt;/code&gt; indicates with (out) &lt;code&gt;DatasetCache&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Most general-purpose databases take too much time to load data. After looking into the underlying implementation, we find that data go through too many layers of interfaces and unnecessary format transformations in general-purpose database solutions. Such overheads greatly slow down the data loading process. Qlib data are stored in a compact format, which is efficient to be combined into arrays for scientific computation.&lt;/p&gt; 
&lt;h1&gt;Related Reports&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://analyticsindiamag.com/qlib/"&gt;Guide To Qlib: Microsoftâ€™s AI Investment Platform&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://mp.weixin.qq.com/s/47bP5YwxfTp2uTHjUBzJQQ"&gt;å¾®è½¯ä¹ŸæAIé‡åŒ–å¹³å°ï¼Ÿè¿˜æ˜¯å¼€æºçš„ï¼&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://mp.weixin.qq.com/s/vsJv7lsgjEi-ALYUz4CvtQ"&gt;å¾®çŸ¿Qlibï¼šä¸šå†…é¦–ä¸ªAIé‡åŒ–æŠ•èµ„å¼€æºå¹³å°&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Contact Us&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;If you have any issues, please create issue &lt;a href="https://github.com/microsoft/qlib/issues/new/choose"&gt;here&lt;/a&gt; or send messages in &lt;a href="https://gitter.im/Microsoft/qlib"&gt;gitter&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;If you want to make contributions to &lt;code&gt;Qlib&lt;/code&gt;, please &lt;a href="https://github.com/microsoft/qlib/compare"&gt;create pull requests&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;For other reasons, you are welcome to contact us by email(&lt;a href="mailto:qlib@microsoft.com"&gt;qlib@microsoft.com&lt;/a&gt;). 
  &lt;ul&gt; 
   &lt;li&gt;We are recruiting new members(both FTEs and interns), your resumes are welcome!&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Join IM discussion groups:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;&lt;a href="https://gitter.im/Microsoft/qlib"&gt;Gitter&lt;/a&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src="https://github.com/microsoft/qlib/raw/main/docs/_static/img/qrcode/gitter_qr.png" alt="image" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h1&gt;Contributing&lt;/h1&gt; 
&lt;p&gt;We appreciate all contributions and thank all the contributors! &lt;a href="https://github.com/microsoft/qlib/graphs/contributors"&gt;&lt;img src="https://contrib.rocks/image?repo=microsoft/qlib" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Before we released Qlib as an open-source project on Github in Sep 2020, Qlib is an internal project in our group. Unfortunately, the internal commit history is not kept. A lot of members in our group have also contributed a lot to Qlib, which includes Ruihua Wang, Yinda Zhang, Haisu Yu, Shuyu Wang, Bochen Pang, and &lt;a href="https://github.com/evanzd/evanzd"&gt;Dong Zhou&lt;/a&gt;. Especially thanks to &lt;a href="https://github.com/evanzd/evanzd"&gt;Dong Zhou&lt;/a&gt; due to his initial version of Qlib.&lt;/p&gt; 
&lt;h2&gt;Guidance&lt;/h2&gt; 
&lt;p&gt;This project welcomes contributions and suggestions.&lt;br /&gt; &lt;strong&gt;Here are some &lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/docs/developer/code_standard_and_dev_guide.rst"&gt;code standards and development guidance&lt;/a&gt; for submiting a pull request.&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Making contributions is not a hard thing. Solving an issue(maybe just answering a question raised in &lt;a href="https://github.com/microsoft/qlib/issues"&gt;issues list&lt;/a&gt; or &lt;a href="https://gitter.im/Microsoft/qlib"&gt;gitter&lt;/a&gt;), fixing/issuing a bug, improving the documents and even fixing a typo are important contributions to Qlib.&lt;/p&gt; 
&lt;p&gt;For example, if you want to contribute to Qlib's document/code, you can follow the steps in the figure below.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://github.com/demon143/qlib/raw/main/docs/_static/img/change%20doc.gif" /&gt; &lt;/p&gt; 
&lt;p&gt;If you don't know how to start to contribute, you can refer to the following examples.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Type&lt;/th&gt; 
   &lt;th&gt;Examples&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Solving issues&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/microsoft/qlib/issues/749"&gt;Answer a question&lt;/a&gt;; &lt;a href="https://github.com/microsoft/qlib/issues/765"&gt;issuing&lt;/a&gt; or &lt;a href="https://github.com/microsoft/qlib/pull/792"&gt;fixing&lt;/a&gt; a bug&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Docs&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/microsoft/qlib/pull/797/files"&gt;Improve docs quality&lt;/a&gt; ; &lt;a href="https://github.com/microsoft/qlib/pull/774"&gt;Fix a typo&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Feature&lt;/td&gt; 
   &lt;td&gt;Implement a &lt;a href="https://github.com/microsoft/qlib/projects"&gt;requested feature&lt;/a&gt; like &lt;a href="https://github.com/microsoft/qlib/pull/754"&gt;this&lt;/a&gt;; &lt;a href="https://github.com/microsoft/qlib/pull/539/files"&gt;Refactor interfaces&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Dataset&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/microsoft/qlib/pull/733"&gt;Add a dataset&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Models&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/microsoft/qlib/pull/689"&gt;Implement a new model&lt;/a&gt;, &lt;a href="https://github.com/microsoft/qlib/tree/main/examples/benchmarks#contributing"&gt;some instructions to contribute models&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;a href="https://github.com/microsoft/qlib/labels/good%20first%20issue"&gt;Good first issues&lt;/a&gt; are labelled to indicate that they are easy to start your contributions.&lt;/p&gt; 
&lt;p&gt;You can find some impefect implementation in Qlib by &lt;code&gt;rg 'TODO|FIXME' qlib&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;If you would like to become one of Qlib's maintainers to contribute more (e.g. help merge PR, triage issues), please contact us by email(&lt;a href="mailto:qlib@microsoft.com"&gt;qlib@microsoft.com&lt;/a&gt;). We are glad to help to upgrade your permission.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Most contributions require you to agree to a Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us the right to use your contribution. For details, visit &lt;a href="https://cla.opensource.microsoft.com"&gt;https://cla.opensource.microsoft.com&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;When you submit a pull request, a CLA bot will automatically determine whether you need to provide a CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions provided by the bot. You will only need to do this once across all repos using our CLA.&lt;/p&gt; 
&lt;p&gt;This project has adopted the &lt;a href="https://opensource.microsoft.com/codeofconduct/"&gt;Microsoft Open Source Code of Conduct&lt;/a&gt;. For more information see the &lt;a href="https://opensource.microsoft.com/codeofconduct/faq/"&gt;Code of Conduct FAQ&lt;/a&gt; or contact &lt;a href="mailto:opencode@microsoft.com"&gt;opencode@microsoft.com&lt;/a&gt; with any additional questions or comments.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>donnemartin/system-design-primer</title>
      <link>https://github.com/donnemartin/system-design-primer</link>
      <description>&lt;p&gt;Learn how to design large-scale systems. Prep for the system design interview. Includes Anki flashcards.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;em&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/README.md"&gt;English&lt;/a&gt; âˆ™ &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/README-ja.md"&gt;æ—¥æœ¬èª&lt;/a&gt; âˆ™ &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/README-zh-Hans.md"&gt;ç®€ä½“ä¸­æ–‡&lt;/a&gt; âˆ™ &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/README-zh-TW.md"&gt;ç¹é«”ä¸­æ–‡&lt;/a&gt; | &lt;a href="https://github.com/donnemartin/system-design-primer/issues/170"&gt;Ø§Ù„Ø¹ÙØ±ÙØ¨ÙÙŠÙÙ‘Ø©â€&lt;/a&gt; âˆ™ &lt;a href="https://github.com/donnemartin/system-design-primer/issues/220"&gt;à¦¬à¦¾à¦‚à¦²à¦¾&lt;/a&gt; âˆ™ &lt;a href="https://github.com/donnemartin/system-design-primer/issues/40"&gt;PortuguÃªs do Brasil&lt;/a&gt; âˆ™ &lt;a href="https://github.com/donnemartin/system-design-primer/issues/186"&gt;Deutsch&lt;/a&gt; âˆ™ &lt;a href="https://github.com/donnemartin/system-design-primer/issues/130"&gt;ÎµÎ»Î»Î·Î½Î¹ÎºÎ¬&lt;/a&gt; âˆ™ &lt;a href="https://github.com/donnemartin/system-design-primer/issues/272"&gt;×¢×‘×¨×™×ª&lt;/a&gt; âˆ™ &lt;a href="https://github.com/donnemartin/system-design-primer/issues/104"&gt;Italiano&lt;/a&gt; âˆ™ &lt;a href="https://github.com/donnemartin/system-design-primer/issues/102"&gt;í•œêµ­ì–´&lt;/a&gt; âˆ™ &lt;a href="https://github.com/donnemartin/system-design-primer/issues/110"&gt;ÙØ§Ø±Ø³ÛŒ&lt;/a&gt; âˆ™ &lt;a href="https://github.com/donnemartin/system-design-primer/issues/68"&gt;Polski&lt;/a&gt; âˆ™ &lt;a href="https://github.com/donnemartin/system-design-primer/issues/87"&gt;Ñ€ÑƒÑÑĞºĞ¸Ğ¹ ÑĞ·Ñ‹Ğº&lt;/a&gt; âˆ™ &lt;a href="https://github.com/donnemartin/system-design-primer/issues/136"&gt;EspaÃ±ol&lt;/a&gt; âˆ™ &lt;a href="https://github.com/donnemartin/system-design-primer/issues/187"&gt;à¸ à¸²à¸©à¸²à¹„à¸—à¸¢&lt;/a&gt; âˆ™ &lt;a href="https://github.com/donnemartin/system-design-primer/issues/39"&gt;TÃ¼rkÃ§e&lt;/a&gt; âˆ™ &lt;a href="https://github.com/donnemartin/system-design-primer/issues/127"&gt;tiáº¿ng Viá»‡t&lt;/a&gt; âˆ™ &lt;a href="https://github.com/donnemartin/system-design-primer/issues/250"&gt;FranÃ§ais&lt;/a&gt; | &lt;a href="https://github.com/donnemartin/system-design-primer/issues/28"&gt;Add Translation&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Help &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/TRANSLATIONS.md"&gt;translate&lt;/a&gt; this guide!&lt;/strong&gt;&lt;/p&gt; 
&lt;h1&gt;The System Design Primer&lt;/h1&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/jj3A5N8.png" /&gt; &lt;br /&gt; &lt;/p&gt; 
&lt;h2&gt;Motivation&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Learn how to design large-scale systems.&lt;/p&gt; 
 &lt;p&gt;Prep for the system design interview.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Learn how to design large-scale systems&lt;/h3&gt; 
&lt;p&gt;Learning how to design scalable systems will help you become a better engineer.&lt;/p&gt; 
&lt;p&gt;System design is a broad topic. There is a &lt;strong&gt;vast amount of resources scattered throughout the web&lt;/strong&gt; on system design principles.&lt;/p&gt; 
&lt;p&gt;This repo is an &lt;strong&gt;organized collection&lt;/strong&gt; of resources to help you learn how to build systems at scale.&lt;/p&gt; 
&lt;h3&gt;Learn from the open source community&lt;/h3&gt; 
&lt;p&gt;This is a continually updated, open source project.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#contributing"&gt;Contributions&lt;/a&gt; are welcome!&lt;/p&gt; 
&lt;h3&gt;Prep for the system design interview&lt;/h3&gt; 
&lt;p&gt;In addition to coding interviews, system design is a &lt;strong&gt;required component&lt;/strong&gt; of the &lt;strong&gt;technical interview process&lt;/strong&gt; at many tech companies.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Practice common system design interview questions&lt;/strong&gt; and &lt;strong&gt;compare&lt;/strong&gt; your results with &lt;strong&gt;sample solutions&lt;/strong&gt;: discussions, code, and diagrams.&lt;/p&gt; 
&lt;p&gt;Additional topics for interview prep:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#study-guide"&gt;Study guide&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#how-to-approach-a-system-design-interview-question"&gt;How to approach a system design interview question&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#system-design-interview-questions-with-solutions"&gt;System design interview questions, &lt;strong&gt;with solutions&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#object-oriented-design-interview-questions-with-solutions"&gt;Object-oriented design interview questions, &lt;strong&gt;with solutions&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#additional-system-design-interview-questions"&gt;Additional system design interview questions&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Anki flashcards&lt;/h2&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/zdCAkB3.png" /&gt; &lt;br /&gt; &lt;/p&gt; 
&lt;p&gt;The provided &lt;a href="https://apps.ankiweb.net/"&gt;Anki flashcard decks&lt;/a&gt; use spaced repetition to help you retain key system design concepts.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/donnemartin/system-design-primer/tree/master/resources/flash_cards/System%20Design.apkg"&gt;System design deck&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/donnemartin/system-design-primer/tree/master/resources/flash_cards/System%20Design%20Exercises.apkg"&gt;System design exercises deck&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/donnemartin/system-design-primer/tree/master/resources/flash_cards/OO%20Design.apkg"&gt;Object oriented design exercises deck&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Great for use while on-the-go.&lt;/p&gt; 
&lt;h3&gt;Coding Resource: Interactive Coding Challenges&lt;/h3&gt; 
&lt;p&gt;Looking for resources to help you prep for the &lt;a href="https://github.com/donnemartin/interactive-coding-challenges"&gt;&lt;strong&gt;Coding Interview&lt;/strong&gt;&lt;/a&gt;?&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/b4YtAEN.png" /&gt; &lt;br /&gt; &lt;/p&gt; 
&lt;p&gt;Check out the sister repo &lt;a href="https://github.com/donnemartin/interactive-coding-challenges"&gt;&lt;strong&gt;Interactive Coding Challenges&lt;/strong&gt;&lt;/a&gt;, which contains an additional Anki deck:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/donnemartin/interactive-coding-challenges/tree/master/anki_cards/Coding.apkg"&gt;Coding deck&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Learn from the community.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Feel free to submit pull requests to help:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Fix errors&lt;/li&gt; 
 &lt;li&gt;Improve sections&lt;/li&gt; 
 &lt;li&gt;Add new sections&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/donnemartin/system-design-primer/issues/28"&gt;Translate&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Content that needs some polishing is placed &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#under-development"&gt;under development&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Review the &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/CONTRIBUTING.md"&gt;Contributing Guidelines&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Index of system design topics&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Summaries of various system design topics, including pros and cons. &lt;strong&gt;Everything is a trade-off&lt;/strong&gt;.&lt;/p&gt; 
 &lt;p&gt;Each section contains links to more in-depth resources.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/jrUBAF7.png" /&gt; &lt;br /&gt; &lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#system-design-topics-start-here"&gt;System design topics: start here&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#step-1-review-the-scalability-video-lecture"&gt;Step 1: Review the scalability video lecture&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#step-2-review-the-scalability-article"&gt;Step 2: Review the scalability article&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#next-steps"&gt;Next steps&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#performance-vs-scalability"&gt;Performance vs scalability&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#latency-vs-throughput"&gt;Latency vs throughput&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#availability-vs-consistency"&gt;Availability vs consistency&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#cap-theorem"&gt;CAP theorem&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#cp---consistency-and-partition-tolerance"&gt;CP - consistency and partition tolerance&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#ap---availability-and-partition-tolerance"&gt;AP - availability and partition tolerance&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#consistency-patterns"&gt;Consistency patterns&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#weak-consistency"&gt;Weak consistency&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#eventual-consistency"&gt;Eventual consistency&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#strong-consistency"&gt;Strong consistency&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#availability-patterns"&gt;Availability patterns&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#fail-over"&gt;Fail-over&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#replication"&gt;Replication&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#availability-in-numbers"&gt;Availability in numbers&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#domain-name-system"&gt;Domain name system&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#content-delivery-network"&gt;Content delivery network&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#push-cdns"&gt;Push CDNs&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#pull-cdns"&gt;Pull CDNs&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#load-balancer"&gt;Load balancer&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#active-passive"&gt;Active-passive&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#active-active"&gt;Active-active&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#layer-4-load-balancing"&gt;Layer 4 load balancing&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#layer-7-load-balancing"&gt;Layer 7 load balancing&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#horizontal-scaling"&gt;Horizontal scaling&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#reverse-proxy-web-server"&gt;Reverse proxy (web server)&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#load-balancer-vs-reverse-proxy"&gt;Load balancer vs reverse proxy&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#application-layer"&gt;Application layer&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#microservices"&gt;Microservices&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#service-discovery"&gt;Service discovery&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#database"&gt;Database&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#relational-database-management-system-rdbms"&gt;Relational database management system (RDBMS)&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#master-slave-replication"&gt;Master-slave replication&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#master-master-replication"&gt;Master-master replication&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#federation"&gt;Federation&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#sharding"&gt;Sharding&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#denormalization"&gt;Denormalization&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#sql-tuning"&gt;SQL tuning&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#nosql"&gt;NoSQL&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#key-value-store"&gt;Key-value store&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#document-store"&gt;Document store&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#wide-column-store"&gt;Wide column store&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#graph-database"&gt;Graph Database&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#sql-or-nosql"&gt;SQL or NoSQL&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#cache"&gt;Cache&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#client-caching"&gt;Client caching&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#cdn-caching"&gt;CDN caching&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#web-server-caching"&gt;Web server caching&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#database-caching"&gt;Database caching&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#application-caching"&gt;Application caching&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#caching-at-the-database-query-level"&gt;Caching at the database query level&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#caching-at-the-object-level"&gt;Caching at the object level&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#when-to-update-the-cache"&gt;When to update the cache&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#cache-aside"&gt;Cache-aside&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#write-through"&gt;Write-through&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#write-behind-write-back"&gt;Write-behind (write-back)&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#refresh-ahead"&gt;Refresh-ahead&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#asynchronism"&gt;Asynchronism&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#message-queues"&gt;Message queues&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#task-queues"&gt;Task queues&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#back-pressure"&gt;Back pressure&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#communication"&gt;Communication&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#transmission-control-protocol-tcp"&gt;Transmission control protocol (TCP)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#user-datagram-protocol-udp"&gt;User datagram protocol (UDP)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#remote-procedure-call-rpc"&gt;Remote procedure call (RPC)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#representational-state-transfer-rest"&gt;Representational state transfer (REST)&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#security"&gt;Security&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#appendix"&gt;Appendix&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#powers-of-two-table"&gt;Powers of two table&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#latency-numbers-every-programmer-should-know"&gt;Latency numbers every programmer should know&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#additional-system-design-interview-questions"&gt;Additional system design interview questions&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#real-world-architectures"&gt;Real world architectures&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#company-architectures"&gt;Company architectures&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#company-engineering-blogs"&gt;Company engineering blogs&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#under-development"&gt;Under development&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#credits"&gt;Credits&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#contact-info"&gt;Contact info&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#license"&gt;License&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Study guide&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Suggested topics to review based on your interview timeline (short, medium, long).&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/OfVllex.png" alt="Imgur" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Q: For interviews, do I need to know everything here?&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;A: No, you don't need to know everything here to prepare for the interview&lt;/strong&gt;.&lt;/p&gt; 
&lt;p&gt;What you are asked in an interview depends on variables such as:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;How much experience you have&lt;/li&gt; 
 &lt;li&gt;What your technical background is&lt;/li&gt; 
 &lt;li&gt;What positions you are interviewing for&lt;/li&gt; 
 &lt;li&gt;Which companies you are interviewing with&lt;/li&gt; 
 &lt;li&gt;Luck&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;More experienced candidates are generally expected to know more about system design. Architects or team leads might be expected to know more than individual contributors. Top tech companies are likely to have one or more design interview rounds.&lt;/p&gt; 
&lt;p&gt;Start broad and go deeper in a few areas. It helps to know a little about various key system design topics. Adjust the following guide based on your timeline, experience, what positions you are interviewing for, and which companies you are interviewing with.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Short timeline&lt;/strong&gt; - Aim for &lt;strong&gt;breadth&lt;/strong&gt; with system design topics. Practice by solving &lt;strong&gt;some&lt;/strong&gt; interview questions.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Medium timeline&lt;/strong&gt; - Aim for &lt;strong&gt;breadth&lt;/strong&gt; and &lt;strong&gt;some depth&lt;/strong&gt; with system design topics. Practice by solving &lt;strong&gt;many&lt;/strong&gt; interview questions.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Long timeline&lt;/strong&gt; - Aim for &lt;strong&gt;breadth&lt;/strong&gt; and &lt;strong&gt;more depth&lt;/strong&gt; with system design topics. Practice by solving &lt;strong&gt;most&lt;/strong&gt; interview questions.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;&lt;/th&gt; 
   &lt;th&gt;Short&lt;/th&gt; 
   &lt;th&gt;Medium&lt;/th&gt; 
   &lt;th&gt;Long&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Read through the &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#index-of-system-design-topics"&gt;System design topics&lt;/a&gt; to get a broad understanding of how systems work&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;ğŸ‘&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;ğŸ‘&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;ğŸ‘&lt;/span&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Read through a few articles in the &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#company-engineering-blogs"&gt;Company engineering blogs&lt;/a&gt; for the companies you are interviewing with&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;ğŸ‘&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;ğŸ‘&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;ğŸ‘&lt;/span&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Read through a few &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#real-world-architectures"&gt;Real world architectures&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;ğŸ‘&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;ğŸ‘&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;ğŸ‘&lt;/span&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Review &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#how-to-approach-a-system-design-interview-question"&gt;How to approach a system design interview question&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;ğŸ‘&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;ğŸ‘&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;ğŸ‘&lt;/span&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Work through &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#system-design-interview-questions-with-solutions"&gt;System design interview questions with solutions&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Some&lt;/td&gt; 
   &lt;td&gt;Many&lt;/td&gt; 
   &lt;td&gt;Most&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Work through &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#object-oriented-design-interview-questions-with-solutions"&gt;Object-oriented design interview questions with solutions&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Some&lt;/td&gt; 
   &lt;td&gt;Many&lt;/td&gt; 
   &lt;td&gt;Most&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Review &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#additional-system-design-interview-questions"&gt;Additional system design interview questions&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Some&lt;/td&gt; 
   &lt;td&gt;Many&lt;/td&gt; 
   &lt;td&gt;Most&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;How to approach a system design interview question&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;How to tackle a system design interview question.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;The system design interview is an &lt;strong&gt;open-ended conversation&lt;/strong&gt;. You are expected to lead it.&lt;/p&gt; 
&lt;p&gt;You can use the following steps to guide the discussion. To help solidify this process, work through the &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#system-design-interview-questions-with-solutions"&gt;System design interview questions with solutions&lt;/a&gt; section using the following steps.&lt;/p&gt; 
&lt;h3&gt;Step 1: Outline use cases, constraints, and assumptions&lt;/h3&gt; 
&lt;p&gt;Gather requirements and scope the problem. Ask questions to clarify use cases and constraints. Discuss assumptions.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Who is going to use it?&lt;/li&gt; 
 &lt;li&gt;How are they going to use it?&lt;/li&gt; 
 &lt;li&gt;How many users are there?&lt;/li&gt; 
 &lt;li&gt;What does the system do?&lt;/li&gt; 
 &lt;li&gt;What are the inputs and outputs of the system?&lt;/li&gt; 
 &lt;li&gt;How much data do we expect to handle?&lt;/li&gt; 
 &lt;li&gt;How many requests per second do we expect?&lt;/li&gt; 
 &lt;li&gt;What is the expected read to write ratio?&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Step 2: Create a high level design&lt;/h3&gt; 
&lt;p&gt;Outline a high level design with all important components.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Sketch the main components and connections&lt;/li&gt; 
 &lt;li&gt;Justify your ideas&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Step 3: Design core components&lt;/h3&gt; 
&lt;p&gt;Dive into details for each core component. For example, if you were asked to &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/system_design/pastebin/README.md"&gt;design a url shortening service&lt;/a&gt;, discuss:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Generating and storing a hash of the full url 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/system_design/pastebin/README.md"&gt;MD5&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/system_design/pastebin/README.md"&gt;Base62&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;Hash collisions&lt;/li&gt; 
   &lt;li&gt;SQL or NoSQL&lt;/li&gt; 
   &lt;li&gt;Database schema&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Translating a hashed url to the full url 
  &lt;ul&gt; 
   &lt;li&gt;Database lookup&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;API and object-oriented design&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Step 4: Scale the design&lt;/h3&gt; 
&lt;p&gt;Identify and address bottlenecks, given the constraints. For example, do you need the following to address scalability issues?&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Load balancer&lt;/li&gt; 
 &lt;li&gt;Horizontal scaling&lt;/li&gt; 
 &lt;li&gt;Caching&lt;/li&gt; 
 &lt;li&gt;Database sharding&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Discuss potential solutions and trade-offs. Everything is a trade-off. Address bottlenecks using &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#index-of-system-design-topics"&gt;principles of scalable system design&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Back-of-the-envelope calculations&lt;/h3&gt; 
&lt;p&gt;You might be asked to do some estimates by hand. Refer to the &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#appendix"&gt;Appendix&lt;/a&gt; for the following resources:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="http://highscalability.com/blog/2011/1/26/google-pro-tip-use-back-of-the-envelope-calculations-to-choo.html"&gt;Use back of the envelope calculations&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#powers-of-two-table"&gt;Powers of two table&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#latency-numbers-every-programmer-should-know"&gt;Latency numbers every programmer should know&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Source(s) and further reading&lt;/h3&gt; 
&lt;p&gt;Check out the following links to get a better idea of what to expect:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://web.archive.org/web/20210505130322/https://www.palantir.com/2011/10/how-to-rock-a-systems-design-interview/"&gt;How to ace a systems design interview&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://www.hiredintech.com/system-design"&gt;The system design interview&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=ZgdS0EUmn70"&gt;Intro to Architecture and Systems Design Interviews&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://leetcode.com/discuss/career/229177/My-System-Design-Template"&gt;System design template&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;System design interview questions with solutions&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Common system design interview questions with sample discussions, code, and diagrams.&lt;/p&gt; 
 &lt;p&gt;Solutions linked to content in the &lt;code&gt;solutions/&lt;/code&gt; folder.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Question&lt;/th&gt; 
   &lt;th&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design Pastebin.com (or Bit.ly)&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/system_design/pastebin/README.md"&gt;Solution&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design the Twitter timeline and search (or Facebook feed and search)&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/system_design/twitter/README.md"&gt;Solution&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a web crawler&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/system_design/web_crawler/README.md"&gt;Solution&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design Mint.com&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/system_design/mint/README.md"&gt;Solution&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design the data structures for a social network&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/system_design/social_graph/README.md"&gt;Solution&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a key-value store for a search engine&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/system_design/query_cache/README.md"&gt;Solution&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design Amazon's sales ranking by category feature&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/system_design/sales_rank/README.md"&gt;Solution&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a system that scales to millions of users on AWS&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/system_design/scaling_aws/README.md"&gt;Solution&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Add a system design question&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#contributing"&gt;Contribute&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Design Pastebin.com (or Bit.ly)&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/system_design/pastebin/README.md"&gt;View exercise and solution&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/4edXG0T.png" alt="Imgur" /&gt;&lt;/p&gt; 
&lt;h3&gt;Design the Twitter timeline and search (or Facebook feed and search)&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/system_design/twitter/README.md"&gt;View exercise and solution&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/jrUBAF7.png" alt="Imgur" /&gt;&lt;/p&gt; 
&lt;h3&gt;Design a web crawler&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/system_design/web_crawler/README.md"&gt;View exercise and solution&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/bWxPtQA.png" alt="Imgur" /&gt;&lt;/p&gt; 
&lt;h3&gt;Design Mint.com&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/system_design/mint/README.md"&gt;View exercise and solution&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/V5q57vU.png" alt="Imgur" /&gt;&lt;/p&gt; 
&lt;h3&gt;Design the data structures for a social network&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/system_design/social_graph/README.md"&gt;View exercise and solution&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/cdCv5g7.png" alt="Imgur" /&gt;&lt;/p&gt; 
&lt;h3&gt;Design a key-value store for a search engine&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/system_design/query_cache/README.md"&gt;View exercise and solution&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/4j99mhe.png" alt="Imgur" /&gt;&lt;/p&gt; 
&lt;h3&gt;Design Amazon's sales ranking by category feature&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/system_design/sales_rank/README.md"&gt;View exercise and solution&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/MzExP06.png" alt="Imgur" /&gt;&lt;/p&gt; 
&lt;h3&gt;Design a system that scales to millions of users on AWS&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/system_design/scaling_aws/README.md"&gt;View exercise and solution&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/jj3A5N8.png" alt="Imgur" /&gt;&lt;/p&gt; 
&lt;h2&gt;Object-oriented design interview questions with solutions&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Common object-oriented design interview questions with sample discussions, code, and diagrams.&lt;/p&gt; 
 &lt;p&gt;Solutions linked to content in the &lt;code&gt;solutions/&lt;/code&gt; folder.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note: This section is under development&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Question&lt;/th&gt; 
   &lt;th&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a hash map&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/object_oriented_design/hash_table/hash_map.ipynb"&gt;Solution&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a least recently used cache&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/object_oriented_design/lru_cache/lru_cache.ipynb"&gt;Solution&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a call center&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/object_oriented_design/call_center/call_center.ipynb"&gt;Solution&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a deck of cards&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/object_oriented_design/deck_of_cards/deck_of_cards.ipynb"&gt;Solution&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a parking lot&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/object_oriented_design/parking_lot/parking_lot.ipynb"&gt;Solution&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a chat server&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/object_oriented_design/online_chat/online_chat.ipynb"&gt;Solution&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a circular array&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#contributing"&gt;Contribute&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Add an object-oriented design question&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#contributing"&gt;Contribute&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;System design topics: start here&lt;/h2&gt; 
&lt;p&gt;New to system design?&lt;/p&gt; 
&lt;p&gt;First, you'll need a basic understanding of common principles, learning about what they are, how they are used, and their pros and cons.&lt;/p&gt; 
&lt;h3&gt;Step 1: Review the scalability video lecture&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=-W9F__D3oY4"&gt;Scalability Lecture at Harvard&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Topics covered: 
  &lt;ul&gt; 
   &lt;li&gt;Vertical scaling&lt;/li&gt; 
   &lt;li&gt;Horizontal scaling&lt;/li&gt; 
   &lt;li&gt;Caching&lt;/li&gt; 
   &lt;li&gt;Load balancing&lt;/li&gt; 
   &lt;li&gt;Database replication&lt;/li&gt; 
   &lt;li&gt;Database partitioning&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Step 2: Review the scalability article&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://web.archive.org/web/20221030091841/http://www.lecloud.net/tagged/scalability/chrono"&gt;Scalability&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Topics covered: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://web.archive.org/web/20220530193911/https://www.lecloud.net/post/7295452622/scalability-for-dummies-part-1-clones"&gt;Clones&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://web.archive.org/web/20220602114024/https://www.lecloud.net/post/7994751381/scalability-for-dummies-part-2-database"&gt;Databases&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://web.archive.org/web/20230126233752/https://www.lecloud.net/post/9246290032/scalability-for-dummies-part-3-cache"&gt;Caches&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://web.archive.org/web/20220926171507/https://www.lecloud.net/post/9699762917/scalability-for-dummies-part-4-asynchronism"&gt;Asynchronism&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Next steps&lt;/h3&gt; 
&lt;p&gt;Next, we'll look at high-level trade-offs:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Performance&lt;/strong&gt; vs &lt;strong&gt;scalability&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Latency&lt;/strong&gt; vs &lt;strong&gt;throughput&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Availability&lt;/strong&gt; vs &lt;strong&gt;consistency&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Keep in mind that &lt;strong&gt;everything is a trade-off&lt;/strong&gt;.&lt;/p&gt; 
&lt;p&gt;Then we'll dive into more specific topics such as DNS, CDNs, and load balancers.&lt;/p&gt; 
&lt;h2&gt;Performance vs scalability&lt;/h2&gt; 
&lt;p&gt;A service is &lt;strong&gt;scalable&lt;/strong&gt; if it results in increased &lt;strong&gt;performance&lt;/strong&gt; in a manner proportional to resources added. Generally, increasing performance means serving more units of work, but it can also be to handle larger units of work, such as when datasets grow.&lt;sup&gt;&lt;a href="http://www.allthingsdistributed.com/2006/03/a_word_on_scalability.html"&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt; 
&lt;p&gt;Another way to look at performance vs scalability:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;If you have a &lt;strong&gt;performance&lt;/strong&gt; problem, your system is slow for a single user.&lt;/li&gt; 
 &lt;li&gt;If you have a &lt;strong&gt;scalability&lt;/strong&gt; problem, your system is fast for a single user but slow under heavy load.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Source(s) and further reading&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="http://www.allthingsdistributed.com/2006/03/a_word_on_scalability.html"&gt;A word on scalability&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://www.slideshare.net/jboner/scalability-availability-stability-patterns/"&gt;Scalability, availability, stability, patterns&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Latency vs throughput&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Latency&lt;/strong&gt; is the time to perform some action or to produce some result.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Throughput&lt;/strong&gt; is the number of such actions or results per unit of time.&lt;/p&gt; 
&lt;p&gt;Generally, you should aim for &lt;strong&gt;maximal throughput&lt;/strong&gt; with &lt;strong&gt;acceptable latency&lt;/strong&gt;.&lt;/p&gt; 
&lt;h3&gt;Source(s) and further reading&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://community.cadence.com/cadence_blogs_8/b/fv/posts/understanding-latency-vs-throughput"&gt;Understanding latency vs throughput&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Availability vs consistency&lt;/h2&gt; 
&lt;h3&gt;CAP theorem&lt;/h3&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/bgLMI2u.png" /&gt; &lt;br /&gt; &lt;i&gt;&lt;a href="https://robertgreiner.com/cap-theorem-revisited"&gt;Source: CAP theorem revisited&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;p&gt;In a distributed computer system, you can only support two of the following guarantees:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Consistency&lt;/strong&gt; - Every read receives the most recent write or an error&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Availability&lt;/strong&gt; - Every request receives a response, without guarantee that it contains the most recent version of the information&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Partition Tolerance&lt;/strong&gt; - The system continues to operate despite arbitrary partitioning due to network failures&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;em&gt;Networks aren't reliable, so you'll need to support partition tolerance. You'll need to make a software tradeoff between consistency and availability.&lt;/em&gt;&lt;/p&gt; 
&lt;h4&gt;CP - consistency and partition tolerance&lt;/h4&gt; 
&lt;p&gt;Waiting for a response from the partitioned node might result in a timeout error. CP is a good choice if your business needs require atomic reads and writes.&lt;/p&gt; 
&lt;h4&gt;AP - availability and partition tolerance&lt;/h4&gt; 
&lt;p&gt;Responses return the most readily available version of the data available on any node, which might not be the latest. Writes might take some time to propagate when the partition is resolved.&lt;/p&gt; 
&lt;p&gt;AP is a good choice if the business needs to allow for &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#eventual-consistency"&gt;eventual consistency&lt;/a&gt; or when the system needs to continue working despite external errors.&lt;/p&gt; 
&lt;h3&gt;Source(s) and further reading&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://robertgreiner.com/cap-theorem-revisited/"&gt;CAP theorem revisited&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://ksat.me/a-plain-english-introduction-to-cap-theorem"&gt;A plain english introduction to CAP theorem&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/henryr/cap-faq"&gt;CAP FAQ&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=k-Yaq8AHlFA"&gt;The CAP theorem&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Consistency patterns&lt;/h2&gt; 
&lt;p&gt;With multiple copies of the same data, we are faced with options on how to synchronize them so clients have a consistent view of the data. Recall the definition of consistency from the &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#cap-theorem"&gt;CAP theorem&lt;/a&gt; - Every read receives the most recent write or an error.&lt;/p&gt; 
&lt;h3&gt;Weak consistency&lt;/h3&gt; 
&lt;p&gt;After a write, reads may or may not see it. A best effort approach is taken.&lt;/p&gt; 
&lt;p&gt;This approach is seen in systems such as memcached. Weak consistency works well in real time use cases such as VoIP, video chat, and realtime multiplayer games. For example, if you are on a phone call and lose reception for a few seconds, when you regain connection you do not hear what was spoken during connection loss.&lt;/p&gt; 
&lt;h3&gt;Eventual consistency&lt;/h3&gt; 
&lt;p&gt;After a write, reads will eventually see it (typically within milliseconds). Data is replicated asynchronously.&lt;/p&gt; 
&lt;p&gt;This approach is seen in systems such as DNS and email. Eventual consistency works well in highly available systems.&lt;/p&gt; 
&lt;h3&gt;Strong consistency&lt;/h3&gt; 
&lt;p&gt;After a write, reads will see it. Data is replicated synchronously.&lt;/p&gt; 
&lt;p&gt;This approach is seen in file systems and RDBMSes. Strong consistency works well in systems that need transactions.&lt;/p&gt; 
&lt;h3&gt;Source(s) and further reading&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="http://snarfed.org/transactions_across_datacenters_io.html"&gt;Transactions across data centers&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Availability patterns&lt;/h2&gt; 
&lt;p&gt;There are two complementary patterns to support high availability: &lt;strong&gt;fail-over&lt;/strong&gt; and &lt;strong&gt;replication&lt;/strong&gt;.&lt;/p&gt; 
&lt;h3&gt;Fail-over&lt;/h3&gt; 
&lt;h4&gt;Active-passive&lt;/h4&gt; 
&lt;p&gt;With active-passive fail-over, heartbeats are sent between the active and the passive server on standby. If the heartbeat is interrupted, the passive server takes over the active's IP address and resumes service.&lt;/p&gt; 
&lt;p&gt;The length of downtime is determined by whether the passive server is already running in 'hot' standby or whether it needs to start up from 'cold' standby. Only the active server handles traffic.&lt;/p&gt; 
&lt;p&gt;Active-passive failover can also be referred to as master-slave failover.&lt;/p&gt; 
&lt;h4&gt;Active-active&lt;/h4&gt; 
&lt;p&gt;In active-active, both servers are managing traffic, spreading the load between them.&lt;/p&gt; 
&lt;p&gt;If the servers are public-facing, the DNS would need to know about the public IPs of both servers. If the servers are internal-facing, application logic would need to know about both servers.&lt;/p&gt; 
&lt;p&gt;Active-active failover can also be referred to as master-master failover.&lt;/p&gt; 
&lt;h3&gt;Disadvantage(s): failover&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Fail-over adds more hardware and additional complexity.&lt;/li&gt; 
 &lt;li&gt;There is a potential for loss of data if the active system fails before any newly written data can be replicated to the passive.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Replication&lt;/h3&gt; 
&lt;h4&gt;Master-slave and master-master&lt;/h4&gt; 
&lt;p&gt;This topic is further discussed in the &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#database"&gt;Database&lt;/a&gt; section:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#master-slave-replication"&gt;Master-slave replication&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#master-master-replication"&gt;Master-master replication&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Availability in numbers&lt;/h3&gt; 
&lt;p&gt;Availability is often quantified by uptime (or downtime) as a percentage of time the service is available. Availability is generally measured in number of 9s--a service with 99.99% availability is described as having four 9s.&lt;/p&gt; 
&lt;h4&gt;99.9% availability - three 9s&lt;/h4&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Duration&lt;/th&gt; 
   &lt;th&gt;Acceptable downtime&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Downtime per year&lt;/td&gt; 
   &lt;td&gt;8h 45min 57s&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Downtime per month&lt;/td&gt; 
   &lt;td&gt;43m 49.7s&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Downtime per week&lt;/td&gt; 
   &lt;td&gt;10m 4.8s&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Downtime per day&lt;/td&gt; 
   &lt;td&gt;1m 26.4s&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h4&gt;99.99% availability - four 9s&lt;/h4&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Duration&lt;/th&gt; 
   &lt;th&gt;Acceptable downtime&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Downtime per year&lt;/td&gt; 
   &lt;td&gt;52min 35.7s&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Downtime per month&lt;/td&gt; 
   &lt;td&gt;4m 23s&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Downtime per week&lt;/td&gt; 
   &lt;td&gt;1m 5s&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Downtime per day&lt;/td&gt; 
   &lt;td&gt;8.6s&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h4&gt;Availability in parallel vs in sequence&lt;/h4&gt; 
&lt;p&gt;If a service consists of multiple components prone to failure, the service's overall availability depends on whether the components are in sequence or in parallel.&lt;/p&gt; 
&lt;h6&gt;In sequence&lt;/h6&gt; 
&lt;p&gt;Overall availability decreases when two components with availability &amp;lt; 100% are in sequence:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Availability (Total) = Availability (Foo) * Availability (Bar)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If both &lt;code&gt;Foo&lt;/code&gt; and &lt;code&gt;Bar&lt;/code&gt; each had 99.9% availability, their total availability in sequence would be 99.8%.&lt;/p&gt; 
&lt;h6&gt;In parallel&lt;/h6&gt; 
&lt;p&gt;Overall availability increases when two components with availability &amp;lt; 100% are in parallel:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Availability (Total) = 1 - (1 - Availability (Foo)) * (1 - Availability (Bar))
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If both &lt;code&gt;Foo&lt;/code&gt; and &lt;code&gt;Bar&lt;/code&gt; each had 99.9% availability, their total availability in parallel would be 99.9999%.&lt;/p&gt; 
&lt;h2&gt;Domain name system&lt;/h2&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/IOyLj4i.jpg" /&gt; &lt;br /&gt; &lt;i&gt;&lt;a href="http://www.slideshare.net/srikrupa5/dns-security-presentation-issa"&gt;Source: DNS security presentation&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;p&gt;A Domain Name System (DNS) translates a domain name such as &lt;a href="http://www.example.com"&gt;www.example.com&lt;/a&gt; to an IP address.&lt;/p&gt; 
&lt;p&gt;DNS is hierarchical, with a few authoritative servers at the top level. Your router or ISP provides information about which DNS server(s) to contact when doing a lookup. Lower level DNS servers cache mappings, which could become stale due to DNS propagation delays. DNS results can also be cached by your browser or OS for a certain period of time, determined by the &lt;a href="https://en.wikipedia.org/wiki/Time_to_live"&gt;time to live (TTL)&lt;/a&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;NS record (name server)&lt;/strong&gt; - Specifies the DNS servers for your domain/subdomain.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;MX record (mail exchange)&lt;/strong&gt; - Specifies the mail servers for accepting messages.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;A record (address)&lt;/strong&gt; - Points a name to an IP address.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;CNAME (canonical)&lt;/strong&gt; - Points a name to another name or &lt;code&gt;CNAME&lt;/code&gt; (example.com to &lt;a href="http://www.example.com"&gt;www.example.com&lt;/a&gt;) or to an &lt;code&gt;A&lt;/code&gt; record.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Services such as &lt;a href="https://www.cloudflare.com/dns/"&gt;CloudFlare&lt;/a&gt; and &lt;a href="https://aws.amazon.com/route53/"&gt;Route 53&lt;/a&gt; provide managed DNS services. Some DNS services can route traffic through various methods:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.jscape.com/blog/load-balancing-algorithms"&gt;Weighted round robin&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Prevent traffic from going to servers under maintenance&lt;/li&gt; 
   &lt;li&gt;Balance between varying cluster sizes&lt;/li&gt; 
   &lt;li&gt;A/B testing&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-policy-latency.html"&gt;Latency-based&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-policy-geo.html"&gt;Geolocation-based&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Disadvantage(s): DNS&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Accessing a DNS server introduces a slight delay, although mitigated by caching described above.&lt;/li&gt; 
 &lt;li&gt;DNS server management could be complex and is generally managed by &lt;a href="http://superuser.com/questions/472695/who-controls-the-dns-servers/472729"&gt;governments, ISPs, and large companies&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;DNS services have recently come under &lt;a href="http://dyn.com/blog/dyn-analysis-summary-of-friday-october-21-attack/"&gt;DDoS attack&lt;/a&gt;, preventing users from accessing websites such as Twitter without knowing Twitter's IP address(es).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Source(s) and further reading&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://technet.microsoft.com/en-us/library/dd197427(v=ws.10).aspx"&gt;DNS architecture&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Domain_Name_System"&gt;Wikipedia&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://support.dnsimple.com/categories/dns/"&gt;DNS articles&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Content delivery network&lt;/h2&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/h9TAuGI.jpg" /&gt; &lt;br /&gt; &lt;i&gt;&lt;a href="https://www.creative-artworks.eu/why-use-a-content-delivery-network-cdn/"&gt;Source: Why use a CDN&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;p&gt;A content delivery network (CDN) is a globally distributed network of proxy servers, serving content from locations closer to the user. Generally, static files such as HTML/CSS/JS, photos, and videos are served from CDN, although some CDNs such as Amazon's CloudFront support dynamic content. The site's DNS resolution will tell clients which server to contact.&lt;/p&gt; 
&lt;p&gt;Serving content from CDNs can significantly improve performance in two ways:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Users receive content from data centers close to them&lt;/li&gt; 
 &lt;li&gt;Your servers do not have to serve requests that the CDN fulfills&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Push CDNs&lt;/h3&gt; 
&lt;p&gt;Push CDNs receive new content whenever changes occur on your server. You take full responsibility for providing content, uploading directly to the CDN and rewriting URLs to point to the CDN. You can configure when content expires and when it is updated. Content is uploaded only when it is new or changed, minimizing traffic, but maximizing storage.&lt;/p&gt; 
&lt;p&gt;Sites with a small amount of traffic or sites with content that isn't often updated work well with push CDNs. Content is placed on the CDNs once, instead of being re-pulled at regular intervals.&lt;/p&gt; 
&lt;h3&gt;Pull CDNs&lt;/h3&gt; 
&lt;p&gt;Pull CDNs grab new content from your server when the first user requests the content. You leave the content on your server and rewrite URLs to point to the CDN. This results in a slower request until the content is cached on the CDN.&lt;/p&gt; 
&lt;p&gt;A &lt;a href="https://en.wikipedia.org/wiki/Time_to_live"&gt;time-to-live (TTL)&lt;/a&gt; determines how long content is cached. Pull CDNs minimize storage space on the CDN, but can create redundant traffic if files expire and are pulled before they have actually changed.&lt;/p&gt; 
&lt;p&gt;Sites with heavy traffic work well with pull CDNs, as traffic is spread out more evenly with only recently-requested content remaining on the CDN.&lt;/p&gt; 
&lt;h3&gt;Disadvantage(s): CDN&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;CDN costs could be significant depending on traffic, although this should be weighed with additional costs you would incur not using a CDN.&lt;/li&gt; 
 &lt;li&gt;Content might be stale if it is updated before the TTL expires it.&lt;/li&gt; 
 &lt;li&gt;CDNs require changing URLs for static content to point to the CDN.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Source(s) and further reading&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://figshare.com/articles/Globally_distributed_content_delivery/6605972"&gt;Globally distributed content delivery&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://www.travelblogadvice.com/technical/the-differences-between-push-and-pull-cdns/"&gt;The differences between push and pull CDNs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Content_delivery_network"&gt;Wikipedia&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Load balancer&lt;/h2&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/h81n9iK.png" /&gt; &lt;br /&gt; &lt;i&gt;&lt;a href="http://horicky.blogspot.com/2010/10/scalable-system-design-patterns.html"&gt;Source: Scalable system design patterns&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;p&gt;Load balancers distribute incoming client requests to computing resources such as application servers and databases. In each case, the load balancer returns the response from the computing resource to the appropriate client. Load balancers are effective at:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Preventing requests from going to unhealthy servers&lt;/li&gt; 
 &lt;li&gt;Preventing overloading resources&lt;/li&gt; 
 &lt;li&gt;Helping to eliminate a single point of failure&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Load balancers can be implemented with hardware (expensive) or with software such as HAProxy.&lt;/p&gt; 
&lt;p&gt;Additional benefits include:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;SSL termination&lt;/strong&gt; - Decrypt incoming requests and encrypt server responses so backend servers do not have to perform these potentially expensive operations 
  &lt;ul&gt; 
   &lt;li&gt;Removes the need to install &lt;a href="https://en.wikipedia.org/wiki/X.509"&gt;X.509 certificates&lt;/a&gt; on each server&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Session persistence&lt;/strong&gt; - Issue cookies and route a specific client's requests to same instance if the web apps do not keep track of sessions&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;To protect against failures, it's common to set up multiple load balancers, either in &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#active-passive"&gt;active-passive&lt;/a&gt; or &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#active-active"&gt;active-active&lt;/a&gt; mode.&lt;/p&gt; 
&lt;p&gt;Load balancers can route traffic based on various metrics, including:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Random&lt;/li&gt; 
 &lt;li&gt;Least loaded&lt;/li&gt; 
 &lt;li&gt;Session/cookies&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.g33kinfo.com/info/round-robin-vs-weighted-round-robin-lb"&gt;Round robin or weighted round robin&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#layer-4-load-balancing"&gt;Layer 4&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#layer-7-load-balancing"&gt;Layer 7&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Layer 4 load balancing&lt;/h3&gt; 
&lt;p&gt;Layer 4 load balancers look at info at the &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#communication"&gt;transport layer&lt;/a&gt; to decide how to distribute requests. Generally, this involves the source, destination IP addresses, and ports in the header, but not the contents of the packet. Layer 4 load balancers forward network packets to and from the upstream server, performing &lt;a href="https://www.nginx.com/resources/glossary/layer-4-load-balancing/"&gt;Network Address Translation (NAT)&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Layer 7 load balancing&lt;/h3&gt; 
&lt;p&gt;Layer 7 load balancers look at the &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#communication"&gt;application layer&lt;/a&gt; to decide how to distribute requests. This can involve contents of the header, message, and cookies. Layer 7 load balancers terminate network traffic, reads the message, makes a load-balancing decision, then opens a connection to the selected server. For example, a layer 7 load balancer can direct video traffic to servers that host videos while directing more sensitive user billing traffic to security-hardened servers.&lt;/p&gt; 
&lt;p&gt;At the cost of flexibility, layer 4 load balancing requires less time and computing resources than Layer 7, although the performance impact can be minimal on modern commodity hardware.&lt;/p&gt; 
&lt;h3&gt;Horizontal scaling&lt;/h3&gt; 
&lt;p&gt;Load balancers can also help with horizontal scaling, improving performance and availability. Scaling out using commodity machines is more cost efficient and results in higher availability than scaling up a single server on more expensive hardware, called &lt;strong&gt;Vertical Scaling&lt;/strong&gt;. It is also easier to hire for talent working on commodity hardware than it is for specialized enterprise systems.&lt;/p&gt; 
&lt;h4&gt;Disadvantage(s): horizontal scaling&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Scaling horizontally introduces complexity and involves cloning servers 
  &lt;ul&gt; 
   &lt;li&gt;Servers should be stateless: they should not contain any user-related data like sessions or profile pictures&lt;/li&gt; 
   &lt;li&gt;Sessions can be stored in a centralized data store such as a &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#database"&gt;database&lt;/a&gt; (SQL, NoSQL) or a persistent &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#cache"&gt;cache&lt;/a&gt; (Redis, Memcached)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Downstream servers such as caches and databases need to handle more simultaneous connections as upstream servers scale out&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Disadvantage(s): load balancer&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;The load balancer can become a performance bottleneck if it does not have enough resources or if it is not configured properly.&lt;/li&gt; 
 &lt;li&gt;Introducing a load balancer to help eliminate a single point of failure results in increased complexity.&lt;/li&gt; 
 &lt;li&gt;A single load balancer is a single point of failure, configuring multiple load balancers further increases complexity.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Source(s) and further reading&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.nginx.com/blog/inside-nginx-how-we-designed-for-performance-scale/"&gt;NGINX architecture&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://www.haproxy.org/download/1.2/doc/architecture.txt"&gt;HAProxy architecture guide&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://web.archive.org/web/20220530193911/https://www.lecloud.net/post/7295452622/scalability-for-dummies-part-1-clones"&gt;Scalability&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Load_balancing_(computing)"&gt;Wikipedia&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.nginx.com/resources/glossary/layer-4-load-balancing/"&gt;Layer 4 load balancing&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.nginx.com/resources/glossary/layer-7-load-balancing/"&gt;Layer 7 load balancing&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://docs.aws.amazon.com/elasticloadbalancing/latest/classic/elb-listener-config.html"&gt;ELB listener config&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Reverse proxy (web server)&lt;/h2&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/n41Azff.png" /&gt; &lt;br /&gt; &lt;i&gt;&lt;a href="https://upload.wikimedia.org/wikipedia/commons/6/67/Reverse_proxy_h2g2bob.svg"&gt;Source: Wikipedia&lt;/a&gt;&lt;/i&gt; &lt;br /&gt; &lt;/p&gt; 
&lt;p&gt;A reverse proxy is a web server that centralizes internal services and provides unified interfaces to the public. Requests from clients are forwarded to a server that can fulfill it before the reverse proxy returns the server's response to the client.&lt;/p&gt; 
&lt;p&gt;Additional benefits include:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Increased security&lt;/strong&gt; - Hide information about backend servers, blacklist IPs, limit number of connections per client&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Increased scalability and flexibility&lt;/strong&gt; - Clients only see the reverse proxy's IP, allowing you to scale servers or change their configuration&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;SSL termination&lt;/strong&gt; - Decrypt incoming requests and encrypt server responses so backend servers do not have to perform these potentially expensive operations 
  &lt;ul&gt; 
   &lt;li&gt;Removes the need to install &lt;a href="https://en.wikipedia.org/wiki/X.509"&gt;X.509 certificates&lt;/a&gt; on each server&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Compression&lt;/strong&gt; - Compress server responses&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Caching&lt;/strong&gt; - Return the response for cached requests&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Static content&lt;/strong&gt; - Serve static content directly 
  &lt;ul&gt; 
   &lt;li&gt;HTML/CSS/JS&lt;/li&gt; 
   &lt;li&gt;Photos&lt;/li&gt; 
   &lt;li&gt;Videos&lt;/li&gt; 
   &lt;li&gt;Etc&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Load balancer vs reverse proxy&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Deploying a load balancer is useful when you have multiple servers. Often, load balancers route traffic to a set of servers serving the same function.&lt;/li&gt; 
 &lt;li&gt;Reverse proxies can be useful even with just one web server or application server, opening up the benefits described in the previous section.&lt;/li&gt; 
 &lt;li&gt;Solutions such as NGINX and HAProxy can support both layer 7 reverse proxying and load balancing.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Disadvantage(s): reverse proxy&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Introducing a reverse proxy results in increased complexity.&lt;/li&gt; 
 &lt;li&gt;A single reverse proxy is a single point of failure, configuring multiple reverse proxies (ie a &lt;a href="https://en.wikipedia.org/wiki/Failover"&gt;failover&lt;/a&gt;) further increases complexity.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Source(s) and further reading&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.nginx.com/resources/glossary/reverse-proxy-vs-load-balancer/"&gt;Reverse proxy vs load balancer&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.nginx.com/blog/inside-nginx-how-we-designed-for-performance-scale/"&gt;NGINX architecture&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://www.haproxy.org/download/1.2/doc/architecture.txt"&gt;HAProxy architecture guide&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Reverse_proxy"&gt;Wikipedia&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Application layer&lt;/h2&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/yB5SYwm.png" /&gt; &lt;br /&gt; &lt;i&gt;&lt;a href="http://lethain.com/introduction-to-architecting-systems-for-scale/#platform_layer"&gt;Source: Intro to architecting systems for scale&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;p&gt;Separating out the web layer from the application layer (also known as platform layer) allows you to scale and configure both layers independently. Adding a new API results in adding application servers without necessarily adding additional web servers. The &lt;strong&gt;single responsibility principle&lt;/strong&gt; advocates for small and autonomous services that work together. Small teams with small services can plan more aggressively for rapid growth.&lt;/p&gt; 
&lt;p&gt;Workers in the application layer also help enable &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#asynchronism"&gt;asynchronism&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Microservices&lt;/h3&gt; 
&lt;p&gt;Related to this discussion are &lt;a href="https://en.wikipedia.org/wiki/Microservices"&gt;microservices&lt;/a&gt;, which can be described as a suite of independently deployable, small, modular services. Each service runs a unique process and communicates through a well-defined, lightweight mechanism to serve a business goal. &lt;sup&gt;&lt;a href="https://smartbear.com/learn/api-design/what-are-microservices"&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt; 
&lt;p&gt;Pinterest, for example, could have the following microservices: user profile, follower, feed, search, photo upload, etc.&lt;/p&gt; 
&lt;h3&gt;Service Discovery&lt;/h3&gt; 
&lt;p&gt;Systems such as &lt;a href="https://www.consul.io/docs/index.html"&gt;Consul&lt;/a&gt;, &lt;a href="https://coreos.com/etcd/docs/latest"&gt;Etcd&lt;/a&gt;, and &lt;a href="http://www.slideshare.net/sauravhaloi/introduction-to-apache-zookeeper"&gt;Zookeeper&lt;/a&gt; can help services find each other by keeping track of registered names, addresses, and ports. &lt;a href="https://www.consul.io/intro/getting-started/checks.html"&gt;Health checks&lt;/a&gt; help verify service integrity and are often done using an &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#hypertext-transfer-protocol-http"&gt;HTTP&lt;/a&gt; endpoint. Both Consul and Etcd have a built in &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#key-value-store"&gt;key-value store&lt;/a&gt; that can be useful for storing config values and other shared data.&lt;/p&gt; 
&lt;h3&gt;Disadvantage(s): application layer&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Adding an application layer with loosely coupled services requires a different approach from an architectural, operations, and process viewpoint (vs a monolithic system).&lt;/li&gt; 
 &lt;li&gt;Microservices can add complexity in terms of deployments and operations.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Source(s) and further reading&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="http://lethain.com/introduction-to-architecting-systems-for-scale"&gt;Intro to architecting systems for scale&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://www.puncsky.com/blog/2016-02-13-crack-the-system-design-interview"&gt;Crack the system design interview&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Service-oriented_architecture"&gt;Service oriented architecture&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://www.slideshare.net/sauravhaloi/introduction-to-apache-zookeeper"&gt;Introduction to Zookeeper&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://cloudncode.wordpress.com/2016/07/22/msa-getting-started/"&gt;Here's what you need to know about building microservices&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Database&lt;/h2&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/Xkm5CXz.png" /&gt; &lt;br /&gt; &lt;i&gt;&lt;a href="https://www.youtube.com/watch?v=kKjm4ehYiMs"&gt;Source: Scaling up to your first 10 million users&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;h3&gt;Relational database management system (RDBMS)&lt;/h3&gt; 
&lt;p&gt;A relational database like SQL is a collection of data items organized in tables.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;ACID&lt;/strong&gt; is a set of properties of relational database &lt;a href="https://en.wikipedia.org/wiki/Database_transaction"&gt;transactions&lt;/a&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Atomicity&lt;/strong&gt; - Each transaction is all or nothing&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Consistency&lt;/strong&gt; - Any transaction will bring the database from one valid state to another&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Isolation&lt;/strong&gt; - Executing transactions concurrently has the same results as if the transactions were executed serially&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Durability&lt;/strong&gt; - Once a transaction has been committed, it will remain so&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;There are many techniques to scale a relational database: &lt;strong&gt;master-slave replication&lt;/strong&gt;, &lt;strong&gt;master-master replication&lt;/strong&gt;, &lt;strong&gt;federation&lt;/strong&gt;, &lt;strong&gt;sharding&lt;/strong&gt;, &lt;strong&gt;denormalization&lt;/strong&gt;, and &lt;strong&gt;SQL tuning&lt;/strong&gt;.&lt;/p&gt; 
&lt;h4&gt;Master-slave replication&lt;/h4&gt; 
&lt;p&gt;The master serves reads and writes, replicating writes to one or more slaves, which serve only reads. Slaves can also replicate to additional slaves in a tree-like fashion. If the master goes offline, the system can continue to operate in read-only mode until a slave is promoted to a master or a new master is provisioned.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/C9ioGtn.png" /&gt; &lt;br /&gt; &lt;i&gt;&lt;a href="http://www.slideshare.net/jboner/scalability-availability-stability-patterns/"&gt;Source: Scalability, availability, stability, patterns&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;h5&gt;Disadvantage(s): master-slave replication&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;Additional logic is needed to promote a slave to a master.&lt;/li&gt; 
 &lt;li&gt;See &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#disadvantages-replication"&gt;Disadvantage(s): replication&lt;/a&gt; for points related to &lt;strong&gt;both&lt;/strong&gt; master-slave and master-master.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Master-master replication&lt;/h4&gt; 
&lt;p&gt;Both masters serve reads and writes and coordinate with each other on writes. If either master goes down, the system can continue to operate with both reads and writes.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/krAHLGg.png" /&gt; &lt;br /&gt; &lt;i&gt;&lt;a href="http://www.slideshare.net/jboner/scalability-availability-stability-patterns/"&gt;Source: Scalability, availability, stability, patterns&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;h5&gt;Disadvantage(s): master-master replication&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;You'll need a load balancer or you'll need to make changes to your application logic to determine where to write.&lt;/li&gt; 
 &lt;li&gt;Most master-master systems are either loosely consistent (violating ACID) or have increased write latency due to synchronization.&lt;/li&gt; 
 &lt;li&gt;Conflict resolution comes more into play as more write nodes are added and as latency increases.&lt;/li&gt; 
 &lt;li&gt;See &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#disadvantages-replication"&gt;Disadvantage(s): replication&lt;/a&gt; for points related to &lt;strong&gt;both&lt;/strong&gt; master-slave and master-master.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h5&gt;Disadvantage(s): replication&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;There is a potential for loss of data if the master fails before any newly written data can be replicated to other nodes.&lt;/li&gt; 
 &lt;li&gt;Writes are replayed to the read replicas. If there are a lot of writes, the read replicas can get bogged down with replaying writes and can't do as many reads.&lt;/li&gt; 
 &lt;li&gt;The more read slaves, the more you have to replicate, which leads to greater replication lag.&lt;/li&gt; 
 &lt;li&gt;On some systems, writing to the master can spawn multiple threads to write in parallel, whereas read replicas only support writing sequentially with a single thread.&lt;/li&gt; 
 &lt;li&gt;Replication adds more hardware and additional complexity.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h5&gt;Source(s) and further reading: replication&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="http://www.slideshare.net/jboner/scalability-availability-stability-patterns/"&gt;Scalability, availability, stability, patterns&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Multi-master_replication"&gt;Multi-master replication&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Federation&lt;/h4&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/U3qV33e.png" /&gt; &lt;br /&gt; &lt;i&gt;&lt;a href="https://www.youtube.com/watch?v=kKjm4ehYiMs"&gt;Source: Scaling up to your first 10 million users&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;p&gt;Federation (or functional partitioning) splits up databases by function. For example, instead of a single, monolithic database, you could have three databases: &lt;strong&gt;forums&lt;/strong&gt;, &lt;strong&gt;users&lt;/strong&gt;, and &lt;strong&gt;products&lt;/strong&gt;, resulting in less read and write traffic to each database and therefore less replication lag. Smaller databases result in more data that can fit in memory, which in turn results in more cache hits due to improved cache locality. With no single central master serializing writes you can write in parallel, increasing throughput.&lt;/p&gt; 
&lt;h5&gt;Disadvantage(s): federation&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;Federation is not effective if your schema requires huge functions or tables.&lt;/li&gt; 
 &lt;li&gt;You'll need to update your application logic to determine which database to read and write.&lt;/li&gt; 
 &lt;li&gt;Joining data from two databases is more complex with a &lt;a href="http://stackoverflow.com/questions/5145637/querying-data-by-joining-two-tables-in-two-database-on-different-servers"&gt;server link&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Federation adds more hardware and additional complexity.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h5&gt;Source(s) and further reading: federation&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=kKjm4ehYiMs"&gt;Scaling up to your first 10 million users&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Sharding&lt;/h4&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/wU8x5Id.png" /&gt; &lt;br /&gt; &lt;i&gt;&lt;a href="http://www.slideshare.net/jboner/scalability-availability-stability-patterns/"&gt;Source: Scalability, availability, stability, patterns&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;p&gt;Sharding distributes data across different databases such that each database can only manage a subset of the data. Taking a users database as an example, as the number of users increases, more shards are added to the cluster.&lt;/p&gt; 
&lt;p&gt;Similar to the advantages of &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#federation"&gt;federation&lt;/a&gt;, sharding results in less read and write traffic, less replication, and more cache hits. Index size is also reduced, which generally improves performance with faster queries. If one shard goes down, the other shards are still operational, although you'll want to add some form of replication to avoid data loss. Like federation, there is no single central master serializing writes, allowing you to write in parallel with increased throughput.&lt;/p&gt; 
&lt;p&gt;Common ways to shard a table of users is either through the user's last name initial or the user's geographic location.&lt;/p&gt; 
&lt;h5&gt;Disadvantage(s): sharding&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;You'll need to update your application logic to work with shards, which could result in complex SQL queries.&lt;/li&gt; 
 &lt;li&gt;Data distribution can become lopsided in a shard. For example, a set of power users on a shard could result in increased load to that shard compared to others. 
  &lt;ul&gt; 
   &lt;li&gt;Rebalancing adds additional complexity. A sharding function based on &lt;a href="http://www.paperplanes.de/2011/12/9/the-magic-of-consistent-hashing.html"&gt;consistent hashing&lt;/a&gt; can reduce the amount of transferred data.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Joining data from multiple shards is more complex.&lt;/li&gt; 
 &lt;li&gt;Sharding adds more hardware and additional complexity.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h5&gt;Source(s) and further reading: sharding&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="http://highscalability.com/blog/2009/8/6/an-unorthodox-approach-to-database-design-the-coming-of-the.html"&gt;The coming of the shard&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Shard_(database_architecture)"&gt;Shard database architecture&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://www.paperplanes.de/2011/12/9/the-magic-of-consistent-hashing.html"&gt;Consistent hashing&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Denormalization&lt;/h4&gt; 
&lt;p&gt;Denormalization attempts to improve read performance at the expense of some write performance. Redundant copies of the data are written in multiple tables to avoid expensive joins. Some RDBMS such as &lt;a href="https://en.wikipedia.org/wiki/PostgreSQL"&gt;PostgreSQL&lt;/a&gt; and Oracle support &lt;a href="https://en.wikipedia.org/wiki/Materialized_view"&gt;materialized views&lt;/a&gt; which handle the work of storing redundant information and keeping redundant copies consistent.&lt;/p&gt; 
&lt;p&gt;Once data becomes distributed with techniques such as &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#federation"&gt;federation&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#sharding"&gt;sharding&lt;/a&gt;, managing joins across data centers further increases complexity. Denormalization might circumvent the need for such complex joins.&lt;/p&gt; 
&lt;p&gt;In most systems, reads can heavily outnumber writes 100:1 or even 1000:1. A read resulting in a complex database join can be very expensive, spending a significant amount of time on disk operations.&lt;/p&gt; 
&lt;h5&gt;Disadvantage(s): denormalization&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;Data is duplicated.&lt;/li&gt; 
 &lt;li&gt;Constraints can help redundant copies of information stay in sync, which increases complexity of the database design.&lt;/li&gt; 
 &lt;li&gt;A denormalized database under heavy write load might perform worse than its normalized counterpart.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h6&gt;Source(s) and further reading: denormalization&lt;/h6&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Denormalization"&gt;Denormalization&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;SQL tuning&lt;/h4&gt; 
&lt;p&gt;SQL tuning is a broad topic and many &lt;a href="https://www.amazon.com/s/ref=nb_sb_noss_2?url=search-alias%3Daps&amp;amp;field-keywords=sql+tuning"&gt;books&lt;/a&gt; have been written as reference.&lt;/p&gt; 
&lt;p&gt;It's important to &lt;strong&gt;benchmark&lt;/strong&gt; and &lt;strong&gt;profile&lt;/strong&gt; to simulate and uncover bottlenecks.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Benchmark&lt;/strong&gt; - Simulate high-load situations with tools such as &lt;a href="http://httpd.apache.org/docs/2.2/programs/ab.html"&gt;ab&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Profile&lt;/strong&gt; - Enable tools such as the &lt;a href="http://dev.mysql.com/doc/refman/5.7/en/slow-query-log.html"&gt;slow query log&lt;/a&gt; to help track performance issues.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Benchmarking and profiling might point you to the following optimizations.&lt;/p&gt; 
&lt;h5&gt;Tighten up the schema&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;MySQL dumps to disk in contiguous blocks for fast access.&lt;/li&gt; 
 &lt;li&gt;Use &lt;code&gt;CHAR&lt;/code&gt; instead of &lt;code&gt;VARCHAR&lt;/code&gt; for fixed-length fields. 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;CHAR&lt;/code&gt; effectively allows for fast, random access, whereas with &lt;code&gt;VARCHAR&lt;/code&gt;, you must find the end of a string before moving onto the next one.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Use &lt;code&gt;TEXT&lt;/code&gt; for large blocks of text such as blog posts. &lt;code&gt;TEXT&lt;/code&gt; also allows for boolean searches. Using a &lt;code&gt;TEXT&lt;/code&gt; field results in storing a pointer on disk that is used to locate the text block.&lt;/li&gt; 
 &lt;li&gt;Use &lt;code&gt;INT&lt;/code&gt; for larger numbers up to 2^32 or 4 billion.&lt;/li&gt; 
 &lt;li&gt;Use &lt;code&gt;DECIMAL&lt;/code&gt; for currency to avoid floating point representation errors.&lt;/li&gt; 
 &lt;li&gt;Avoid storing large &lt;code&gt;BLOBS&lt;/code&gt;, store the location of where to get the object instead.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;VARCHAR(255)&lt;/code&gt; is the largest number of characters that can be counted in an 8 bit number, often maximizing the use of a byte in some RDBMS.&lt;/li&gt; 
 &lt;li&gt;Set the &lt;code&gt;NOT NULL&lt;/code&gt; constraint where applicable to &lt;a href="http://stackoverflow.com/questions/1017239/how-do-null-values-affect-performance-in-a-database-search"&gt;improve search performance&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h5&gt;Use good indices&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;Columns that you are querying (&lt;code&gt;SELECT&lt;/code&gt;, &lt;code&gt;GROUP BY&lt;/code&gt;, &lt;code&gt;ORDER BY&lt;/code&gt;, &lt;code&gt;JOIN&lt;/code&gt;) could be faster with indices.&lt;/li&gt; 
 &lt;li&gt;Indices are usually represented as self-balancing &lt;a href="https://en.wikipedia.org/wiki/B-tree"&gt;B-tree&lt;/a&gt; that keeps data sorted and allows searches, sequential access, insertions, and deletions in logarithmic time.&lt;/li&gt; 
 &lt;li&gt;Placing an index can keep the data in memory, requiring more space.&lt;/li&gt; 
 &lt;li&gt;Writes could also be slower since the index also needs to be updated.&lt;/li&gt; 
 &lt;li&gt;When loading large amounts of data, it might be faster to disable indices, load the data, then rebuild the indices.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h5&gt;Avoid expensive joins&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#denormalization"&gt;Denormalize&lt;/a&gt; where performance demands it.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h5&gt;Partition tables&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;Break up a table by putting hot spots in a separate table to help keep it in memory.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h5&gt;Tune the query cache&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;In some cases, the &lt;a href="https://dev.mysql.com/doc/refman/5.7/en/query-cache.html"&gt;query cache&lt;/a&gt; could lead to &lt;a href="https://www.percona.com/blog/2016/10/12/mysql-5-7-performance-tuning-immediately-after-installation/"&gt;performance issues&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h5&gt;Source(s) and further reading: SQL tuning&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="http://aiddroid.com/10-tips-optimizing-mysql-queries-dont-suck/"&gt;Tips for optimizing MySQL queries&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://stackoverflow.com/questions/1217466/is-there-a-good-reason-i-see-varchar255-used-so-often-as-opposed-to-another-l"&gt;Is there a good reason i see VARCHAR(255) used so often?&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://stackoverflow.com/questions/1017239/how-do-null-values-affect-performance-in-a-database-search"&gt;How do null values affect performance?&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://dev.mysql.com/doc/refman/5.7/en/slow-query-log.html"&gt;Slow query log&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;NoSQL&lt;/h3&gt; 
&lt;p&gt;NoSQL is a collection of data items represented in a &lt;strong&gt;key-value store&lt;/strong&gt;, &lt;strong&gt;document store&lt;/strong&gt;, &lt;strong&gt;wide column store&lt;/strong&gt;, or a &lt;strong&gt;graph database&lt;/strong&gt;. Data is denormalized, and joins are generally done in the application code. Most NoSQL stores lack true ACID transactions and favor &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#eventual-consistency"&gt;eventual consistency&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;BASE&lt;/strong&gt; is often used to describe the properties of NoSQL databases. In comparison with the &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#cap-theorem"&gt;CAP Theorem&lt;/a&gt;, BASE chooses availability over consistency.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Basically available&lt;/strong&gt; - the system guarantees availability.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Soft state&lt;/strong&gt; - the state of the system may change over time, even without input.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Eventual consistency&lt;/strong&gt; - the system will become consistent over a period of time, given that the system doesn't receive input during that period.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;In addition to choosing between &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#sql-or-nosql"&gt;SQL or NoSQL&lt;/a&gt;, it is helpful to understand which type of NoSQL database best fits your use case(s). We'll review &lt;strong&gt;key-value stores&lt;/strong&gt;, &lt;strong&gt;document stores&lt;/strong&gt;, &lt;strong&gt;wide column stores&lt;/strong&gt;, and &lt;strong&gt;graph databases&lt;/strong&gt; in the next section.&lt;/p&gt; 
&lt;h4&gt;Key-value store&lt;/h4&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Abstraction: hash table&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;A key-value store generally allows for O(1) reads and writes and is often backed by memory or SSD. Data stores can maintain keys in &lt;a href="https://en.wikipedia.org/wiki/Lexicographical_order"&gt;lexicographic order&lt;/a&gt;, allowing efficient retrieval of key ranges. Key-value stores can allow for storing of metadata with a value.&lt;/p&gt; 
&lt;p&gt;Key-value stores provide high performance and are often used for simple data models or for rapidly-changing data, such as an in-memory cache layer. Since they offer only a limited set of operations, complexity is shifted to the application layer if additional operations are needed.&lt;/p&gt; 
&lt;p&gt;A key-value store is the basis for more complex systems such as a document store, and in some cases, a graph database.&lt;/p&gt; 
&lt;h5&gt;Source(s) and further reading: key-value store&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Key-value_database"&gt;Key-value database&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://stackoverflow.com/questions/4056093/what-are-the-disadvantages-of-using-a-key-value-table-over-nullable-columns-or"&gt;Disadvantages of key-value stores&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://qnimate.com/overview-of-redis-architecture/"&gt;Redis architecture&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://adayinthelifeof.nl/2011/02/06/memcache-internals/"&gt;Memcached architecture&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Document store&lt;/h4&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Abstraction: key-value store with documents stored as values&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;A document store is centered around documents (XML, JSON, binary, etc), where a document stores all information for a given object. Document stores provide APIs or a query language to query based on the internal structure of the document itself. &lt;em&gt;Note, many key-value stores include features for working with a value's metadata, blurring the lines between these two storage types.&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;Based on the underlying implementation, documents are organized by collections, tags, metadata, or directories. Although documents can be organized or grouped together, documents may have fields that are completely different from each other.&lt;/p&gt; 
&lt;p&gt;Some document stores like &lt;a href="https://www.mongodb.com/mongodb-architecture"&gt;MongoDB&lt;/a&gt; and &lt;a href="https://blog.couchdb.org/2016/08/01/couchdb-2-0-architecture/"&gt;CouchDB&lt;/a&gt; also provide a SQL-like language to perform complex queries. &lt;a href="http://www.read.seas.harvard.edu/~kohler/class/cs239-w08/decandia07dynamo.pdf"&gt;DynamoDB&lt;/a&gt; supports both key-values and documents.&lt;/p&gt; 
&lt;p&gt;Document stores provide high flexibility and are often used for working with occasionally changing data.&lt;/p&gt; 
&lt;h5&gt;Source(s) and further reading: document store&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Document-oriented_database"&gt;Document-oriented database&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.mongodb.com/mongodb-architecture"&gt;MongoDB architecture&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://blog.couchdb.org/2016/08/01/couchdb-2-0-architecture/"&gt;CouchDB architecture&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.elastic.co/blog/found-elasticsearch-from-the-bottom-up"&gt;Elasticsearch architecture&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Wide column store&lt;/h4&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/n16iOGk.png" /&gt; &lt;br /&gt; &lt;i&gt;&lt;a href="http://blog.grio.com/2015/11/sql-nosql-a-brief-history.html"&gt;Source: SQL &amp;amp; NoSQL, a brief history&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Abstraction: nested map &lt;code&gt;ColumnFamily&amp;lt;RowKey, Columns&amp;lt;ColKey, Value, Timestamp&amp;gt;&amp;gt;&lt;/code&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;A wide column store's basic unit of data is a column (name/value pair). A column can be grouped in column families (analogous to a SQL table). Super column families further group column families. You can access each column independently with a row key, and columns with the same row key form a row. Each value contains a timestamp for versioning and for conflict resolution.&lt;/p&gt; 
&lt;p&gt;Google introduced &lt;a href="http://www.read.seas.harvard.edu/~kohler/class/cs239-w08/chang06bigtable.pdf"&gt;Bigtable&lt;/a&gt; as the first wide column store, which influenced the open-source &lt;a href="https://www.edureka.co/blog/hbase-architecture/"&gt;HBase&lt;/a&gt; often-used in the Hadoop ecosystem, and &lt;a href="http://docs.datastax.com/en/cassandra/3.0/cassandra/architecture/archIntro.html"&gt;Cassandra&lt;/a&gt; from Facebook. Stores such as BigTable, HBase, and Cassandra maintain keys in lexicographic order, allowing efficient retrieval of selective key ranges.&lt;/p&gt; 
&lt;p&gt;Wide column stores offer high availability and high scalability. They are often used for very large data sets.&lt;/p&gt; 
&lt;h5&gt;Source(s) and further reading: wide column store&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="http://blog.grio.com/2015/11/sql-nosql-a-brief-history.html"&gt;SQL &amp;amp; NoSQL, a brief history&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://www.read.seas.harvard.edu/~kohler/class/cs239-w08/chang06bigtable.pdf"&gt;Bigtable architecture&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.edureka.co/blog/hbase-architecture/"&gt;HBase architecture&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://docs.datastax.com/en/cassandra/3.0/cassandra/architecture/archIntro.html"&gt;Cassandra architecture&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Graph database&lt;/h4&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/fNcl65g.png" /&gt; &lt;br /&gt; &lt;i&gt;&lt;a href="https://en.wikipedia.org/wiki/File:GraphDatabase_PropertyGraph.png"&gt;Source: Graph database&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Abstraction: graph&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;In a graph database, each node is a record and each arc is a relationship between two nodes. Graph databases are optimized to represent complex relationships with many foreign keys or many-to-many relationships.&lt;/p&gt; 
&lt;p&gt;Graphs databases offer high performance for data models with complex relationships, such as a social network. They are relatively new and are not yet widely-used; it might be more difficult to find development tools and resources. Many graphs can only be accessed with &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#representational-state-transfer-rest"&gt;REST APIs&lt;/a&gt;.&lt;/p&gt; 
&lt;h5&gt;Source(s) and further reading: graph&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Graph_database"&gt;Graph database&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://neo4j.com/"&gt;Neo4j&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://blog.twitter.com/2010/introducing-flockdb"&gt;FlockDB&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Source(s) and further reading: NoSQL&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="http://stackoverflow.com/questions/3342497/explanation-of-base-terminology"&gt;Explanation of base terminology&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://medium.com/baqend-blog/nosql-databases-a-survey-and-decision-guidance-ea7823a822d#.wskogqenq"&gt;NoSQL databases a survey and decision guidance&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://web.archive.org/web/20220602114024/https://www.lecloud.net/post/7994751381/scalability-for-dummies-part-2-database"&gt;Scalability&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=qI_g07C_Q5I"&gt;Introduction to NoSQL&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://horicky.blogspot.com/2009/11/nosql-patterns.html"&gt;NoSQL patterns&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;SQL or NoSQL&lt;/h3&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/wXGqG5f.png" /&gt; &lt;br /&gt; &lt;i&gt;&lt;a href="https://www.infoq.com/articles/Transition-RDBMS-NoSQL/"&gt;Source: Transitioning from RDBMS to NoSQL&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;p&gt;Reasons for &lt;strong&gt;SQL&lt;/strong&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Structured data&lt;/li&gt; 
 &lt;li&gt;Strict schema&lt;/li&gt; 
 &lt;li&gt;Relational data&lt;/li&gt; 
 &lt;li&gt;Need for complex joins&lt;/li&gt; 
 &lt;li&gt;Transactions&lt;/li&gt; 
 &lt;li&gt;Clear patterns for scaling&lt;/li&gt; 
 &lt;li&gt;More established: developers, community, code, tools, etc&lt;/li&gt; 
 &lt;li&gt;Lookups by index are very fast&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Reasons for &lt;strong&gt;NoSQL&lt;/strong&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Semi-structured data&lt;/li&gt; 
 &lt;li&gt;Dynamic or flexible schema&lt;/li&gt; 
 &lt;li&gt;Non-relational data&lt;/li&gt; 
 &lt;li&gt;No need for complex joins&lt;/li&gt; 
 &lt;li&gt;Store many TB (or PB) of data&lt;/li&gt; 
 &lt;li&gt;Very data intensive workload&lt;/li&gt; 
 &lt;li&gt;Very high throughput for IOPS&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Sample data well-suited for NoSQL:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Rapid ingest of clickstream and log data&lt;/li&gt; 
 &lt;li&gt;Leaderboard or scoring data&lt;/li&gt; 
 &lt;li&gt;Temporary data, such as a shopping cart&lt;/li&gt; 
 &lt;li&gt;Frequently accessed ('hot') tables&lt;/li&gt; 
 &lt;li&gt;Metadata/lookup tables&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h5&gt;Source(s) and further reading: SQL or NoSQL&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=kKjm4ehYiMs"&gt;Scaling up to your first 10 million users&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.sitepoint.com/sql-vs-nosql-differences/"&gt;SQL vs NoSQL differences&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Cache&lt;/h2&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/Q6z24La.png" /&gt; &lt;br /&gt; &lt;i&gt;&lt;a href="http://horicky.blogspot.com/2010/10/scalable-system-design-patterns.html"&gt;Source: Scalable system design patterns&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;p&gt;Caching improves page load times and can reduce the load on your servers and databases. In this model, the dispatcher will first lookup if the request has been made before and try to find the previous result to return, in order to save the actual execution.&lt;/p&gt; 
&lt;p&gt;Databases often benefit from a uniform distribution of reads and writes across its partitions. Popular items can skew the distribution, causing bottlenecks. Putting a cache in front of a database can help absorb uneven loads and spikes in traffic.&lt;/p&gt; 
&lt;h3&gt;Client caching&lt;/h3&gt; 
&lt;p&gt;Caches can be located on the client side (OS or browser), &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#reverse-proxy-web-server"&gt;server side&lt;/a&gt;, or in a distinct cache layer.&lt;/p&gt; 
&lt;h3&gt;CDN caching&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#content-delivery-network"&gt;CDNs&lt;/a&gt; are considered a type of cache.&lt;/p&gt; 
&lt;h3&gt;Web server caching&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#reverse-proxy-web-server"&gt;Reverse proxies&lt;/a&gt; and caches such as &lt;a href="https://www.varnish-cache.org/"&gt;Varnish&lt;/a&gt; can serve static and dynamic content directly. Web servers can also cache requests, returning responses without having to contact application servers.&lt;/p&gt; 
&lt;h3&gt;Database caching&lt;/h3&gt; 
&lt;p&gt;Your database usually includes some level of caching in a default configuration, optimized for a generic use case. Tweaking these settings for specific usage patterns can further boost performance.&lt;/p&gt; 
&lt;h3&gt;Application caching&lt;/h3&gt; 
&lt;p&gt;In-memory caches such as Memcached and Redis are key-value stores between your application and your data storage. Since the data is held in RAM, it is much faster than typical databases where data is stored on disk. RAM is more limited than disk, so &lt;a href="https://en.wikipedia.org/wiki/Cache_algorithms"&gt;cache invalidation&lt;/a&gt; algorithms such as &lt;a href="https://en.wikipedia.org/wiki/Cache_replacement_policies#Least_recently_used_(LRU)"&gt;least recently used (LRU)&lt;/a&gt; can help invalidate 'cold' entries and keep 'hot' data in RAM.&lt;/p&gt; 
&lt;p&gt;Redis has the following additional features:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Persistence option&lt;/li&gt; 
 &lt;li&gt;Built-in data structures such as sorted sets and lists&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;There are multiple levels you can cache that fall into two general categories: &lt;strong&gt;database queries&lt;/strong&gt; and &lt;strong&gt;objects&lt;/strong&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Row level&lt;/li&gt; 
 &lt;li&gt;Query-level&lt;/li&gt; 
 &lt;li&gt;Fully-formed serializable objects&lt;/li&gt; 
 &lt;li&gt;Fully-rendered HTML&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Generally, you should try to avoid file-based caching, as it makes cloning and auto-scaling more difficult.&lt;/p&gt; 
&lt;h3&gt;Caching at the database query level&lt;/h3&gt; 
&lt;p&gt;Whenever you query the database, hash the query as a key and store the result to the cache. This approach suffers from expiration issues:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Hard to delete a cached result with complex queries&lt;/li&gt; 
 &lt;li&gt;If one piece of data changes such as a table cell, you need to delete all cached queries that might include the changed cell&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Caching at the object level&lt;/h3&gt; 
&lt;p&gt;See your data as an object, similar to what you do with your application code. Have your application assemble the dataset from the database into a class instance or a data structure(s):&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Remove the object from cache if its underlying data has changed&lt;/li&gt; 
 &lt;li&gt;Allows for asynchronous processing: workers assemble objects by consuming the latest cached object&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Suggestions of what to cache:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;User sessions&lt;/li&gt; 
 &lt;li&gt;Fully rendered web pages&lt;/li&gt; 
 &lt;li&gt;Activity streams&lt;/li&gt; 
 &lt;li&gt;User graph data&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;When to update the cache&lt;/h3&gt; 
&lt;p&gt;Since you can only store a limited amount of data in cache, you'll need to determine which cache update strategy works best for your use case.&lt;/p&gt; 
&lt;h4&gt;Cache-aside&lt;/h4&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/ONjORqk.png" /&gt; &lt;br /&gt; &lt;i&gt;&lt;a href="http://www.slideshare.net/tmatyashovsky/from-cache-to-in-memory-data-grid-introduction-to-hazelcast"&gt;Source: From cache to in-memory data grid&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;p&gt;The application is responsible for reading and writing from storage. The cache does not interact with storage directly. The application does the following:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Look for entry in cache, resulting in a cache miss&lt;/li&gt; 
 &lt;li&gt;Load entry from the database&lt;/li&gt; 
 &lt;li&gt;Add entry to cache&lt;/li&gt; 
 &lt;li&gt;Return entry&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;def get_user(self, user_id):
    user = cache.get("user.{0}", user_id)
    if user is None:
        user = db.query("SELECT * FROM users WHERE user_id = {0}", user_id)
        if user is not None:
            key = "user.{0}".format(user_id)
            cache.set(key, json.dumps(user))
    return user
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;a href="https://memcached.org/"&gt;Memcached&lt;/a&gt; is generally used in this manner.&lt;/p&gt; 
&lt;p&gt;Subsequent reads of data added to cache are fast. Cache-aside is also referred to as lazy loading. Only requested data is cached, which avoids filling up the cache with data that isn't requested.&lt;/p&gt; 
&lt;h5&gt;Disadvantage(s): cache-aside&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;Each cache miss results in three trips, which can cause a noticeable delay.&lt;/li&gt; 
 &lt;li&gt;Data can become stale if it is updated in the database. This issue is mitigated by setting a time-to-live (TTL) which forces an update of the cache entry, or by using write-through.&lt;/li&gt; 
 &lt;li&gt;When a node fails, it is replaced by a new, empty node, increasing latency.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Write-through&lt;/h4&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/0vBc0hN.png" /&gt; &lt;br /&gt; &lt;i&gt;&lt;a href="http://www.slideshare.net/jboner/scalability-availability-stability-patterns/"&gt;Source: Scalability, availability, stability, patterns&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;p&gt;The application uses the cache as the main data store, reading and writing data to it, while the cache is responsible for reading and writing to the database:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Application adds/updates entry in cache&lt;/li&gt; 
 &lt;li&gt;Cache synchronously writes entry to data store&lt;/li&gt; 
 &lt;li&gt;Return&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Application code:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;set_user(12345, {"foo":"bar"})
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Cache code:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;def set_user(user_id, values):
    user = db.query("UPDATE Users WHERE id = {0}", user_id, values)
    cache.set(user_id, user)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Write-through is a slow overall operation due to the write operation, but subsequent reads of just written data are fast. Users are generally more tolerant of latency when updating data than reading data. Data in the cache is not stale.&lt;/p&gt; 
&lt;h5&gt;Disadvantage(s): write through&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;When a new node is created due to failure or scaling, the new node will not cache entries until the entry is updated in the database. Cache-aside in conjunction with write through can mitigate this issue.&lt;/li&gt; 
 &lt;li&gt;Most data written might never be read, which can be minimized with a TTL.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Write-behind (write-back)&lt;/h4&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/rgSrvjG.png" /&gt; &lt;br /&gt; &lt;i&gt;&lt;a href="http://www.slideshare.net/jboner/scalability-availability-stability-patterns/"&gt;Source: Scalability, availability, stability, patterns&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;p&gt;In write-behind, the application does the following:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Add/update entry in cache&lt;/li&gt; 
 &lt;li&gt;Asynchronously write entry to the data store, improving write performance&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h5&gt;Disadvantage(s): write-behind&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;There could be data loss if the cache goes down prior to its contents hitting the data store.&lt;/li&gt; 
 &lt;li&gt;It is more complex to implement write-behind than it is to implement cache-aside or write-through.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Refresh-ahead&lt;/h4&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/kxtjqgE.png" /&gt; &lt;br /&gt; &lt;i&gt;&lt;a href="http://www.slideshare.net/tmatyashovsky/from-cache-to-in-memory-data-grid-introduction-to-hazelcast"&gt;Source: From cache to in-memory data grid&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;p&gt;You can configure the cache to automatically refresh any recently accessed cache entry prior to its expiration.&lt;/p&gt; 
&lt;p&gt;Refresh-ahead can result in reduced latency vs read-through if the cache can accurately predict which items are likely to be needed in the future.&lt;/p&gt; 
&lt;h5&gt;Disadvantage(s): refresh-ahead&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;Not accurately predicting which items are likely to be needed in the future can result in reduced performance than without refresh-ahead.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Disadvantage(s): cache&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Need to maintain consistency between caches and the source of truth such as the database through &lt;a href="https://en.wikipedia.org/wiki/Cache_algorithms"&gt;cache invalidation&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Cache invalidation is a difficult problem, there is additional complexity associated with when to update the cache.&lt;/li&gt; 
 &lt;li&gt;Need to make application changes such as adding Redis or memcached.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Source(s) and further reading&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="http://www.slideshare.net/tmatyashovsky/from-cache-to-in-memory-data-grid-introduction-to-hazelcast"&gt;From cache to in-memory data grid&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://horicky.blogspot.com/2010/10/scalable-system-design-patterns.html"&gt;Scalable system design patterns&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://lethain.com/introduction-to-architecting-systems-for-scale/"&gt;Introduction to architecting systems for scale&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://www.slideshare.net/jboner/scalability-availability-stability-patterns/"&gt;Scalability, availability, stability, patterns&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://web.archive.org/web/20230126233752/https://www.lecloud.net/post/9246290032/scalability-for-dummies-part-3-cache"&gt;Scalability&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://docs.aws.amazon.com/AmazonElastiCache/latest/UserGuide/Strategies.html"&gt;AWS ElastiCache strategies&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Cache_(computing)"&gt;Wikipedia&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Asynchronism&lt;/h2&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/54GYsSx.png" /&gt; &lt;br /&gt; &lt;i&gt;&lt;a href="http://lethain.com/introduction-to-architecting-systems-for-scale/#platform_layer"&gt;Source: Intro to architecting systems for scale&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;p&gt;Asynchronous workflows help reduce request times for expensive operations that would otherwise be performed in-line. They can also help by doing time-consuming work in advance, such as periodic aggregation of data.&lt;/p&gt; 
&lt;h3&gt;Message queues&lt;/h3&gt; 
&lt;p&gt;Message queues receive, hold, and deliver messages. If an operation is too slow to perform inline, you can use a message queue with the following workflow:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;An application publishes a job to the queue, then notifies the user of job status&lt;/li&gt; 
 &lt;li&gt;A worker picks up the job from the queue, processes it, then signals the job is complete&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The user is not blocked and the job is processed in the background. During this time, the client might optionally do a small amount of processing to make it seem like the task has completed. For example, if posting a tweet, the tweet could be instantly posted to your timeline, but it could take some time before your tweet is actually delivered to all of your followers.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://redis.io/"&gt;Redis&lt;/a&gt;&lt;/strong&gt; is useful as a simple message broker but messages can be lost.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://www.rabbitmq.com/"&gt;RabbitMQ&lt;/a&gt;&lt;/strong&gt; is popular but requires you to adapt to the 'AMQP' protocol and manage your own nodes.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://aws.amazon.com/sqs/"&gt;Amazon SQS&lt;/a&gt;&lt;/strong&gt; is hosted but can have high latency and has the possibility of messages being delivered twice.&lt;/p&gt; 
&lt;h3&gt;Task queues&lt;/h3&gt; 
&lt;p&gt;Tasks queues receive tasks and their related data, runs them, then delivers their results. They can support scheduling and can be used to run computationally-intensive jobs in the background.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://docs.celeryproject.org/en/stable/"&gt;Celery&lt;/a&gt;&lt;/strong&gt; has support for scheduling and primarily has python support.&lt;/p&gt; 
&lt;h3&gt;Back pressure&lt;/h3&gt; 
&lt;p&gt;If queues start to grow significantly, the queue size can become larger than memory, resulting in cache misses, disk reads, and even slower performance. &lt;a href="http://mechanical-sympathy.blogspot.com/2012/05/apply-back-pressure-when-overloaded.html"&gt;Back pressure&lt;/a&gt; can help by limiting the queue size, thereby maintaining a high throughput rate and good response times for jobs already in the queue. Once the queue fills up, clients get a server busy or HTTP 503 status code to try again later. Clients can retry the request at a later time, perhaps with &lt;a href="https://en.wikipedia.org/wiki/Exponential_backoff"&gt;exponential backoff&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Disadvantage(s): asynchronism&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Use cases such as inexpensive calculations and realtime workflows might be better suited for synchronous operations, as introducing queues can add delays and complexity.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Source(s) and further reading&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=1KRYH75wgy4"&gt;It's all a numbers game&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://mechanical-sympathy.blogspot.com/2012/05/apply-back-pressure-when-overloaded.html"&gt;Applying back pressure when overloaded&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Little%27s_law"&gt;Little's law&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.quora.com/What-is-the-difference-between-a-message-queue-and-a-task-queue-Why-would-a-task-queue-require-a-message-broker-like-RabbitMQ-Redis-Celery-or-IronMQ-to-function"&gt;What is the difference between a message queue and a task queue?&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Communication&lt;/h2&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/5KeocQs.jpg" /&gt; &lt;br /&gt; &lt;i&gt;&lt;a href="http://www.escotal.com/osilayer.html"&gt;Source: OSI 7 layer model&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;h3&gt;Hypertext transfer protocol (HTTP)&lt;/h3&gt; 
&lt;p&gt;HTTP is a method for encoding and transporting data between a client and a server. It is a request/response protocol: clients issue requests and servers issue responses with relevant content and completion status info about the request. HTTP is self-contained, allowing requests and responses to flow through many intermediate routers and servers that perform load balancing, caching, encryption, and compression.&lt;/p&gt; 
&lt;p&gt;A basic HTTP request consists of a verb (method) and a resource (endpoint). Below are common HTTP verbs:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Verb&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Idempotent*&lt;/th&gt; 
   &lt;th&gt;Safe&lt;/th&gt; 
   &lt;th&gt;Cacheable&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GET&lt;/td&gt; 
   &lt;td&gt;Reads a resource&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;POST&lt;/td&gt; 
   &lt;td&gt;Creates a resource or trigger a process that handles data&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;Yes if response contains freshness info&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;PUT&lt;/td&gt; 
   &lt;td&gt;Creates or replace a resource&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;PATCH&lt;/td&gt; 
   &lt;td&gt;Partially updates a resource&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;Yes if response contains freshness info&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;DELETE&lt;/td&gt; 
   &lt;td&gt;Deletes a resource&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;*Can be called many times without different outcomes.&lt;/p&gt; 
&lt;p&gt;HTTP is an application layer protocol relying on lower-level protocols such as &lt;strong&gt;TCP&lt;/strong&gt; and &lt;strong&gt;UDP&lt;/strong&gt;.&lt;/p&gt; 
&lt;h4&gt;Source(s) and further reading: HTTP&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.nginx.com/resources/glossary/http/"&gt;What is HTTP?&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.quora.com/What-is-the-difference-between-HTTP-protocol-and-TCP-protocol"&gt;Difference between HTTP and TCP&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://laracasts.com/discuss/channels/general-discussion/whats-the-differences-between-put-and-patch?page=1"&gt;Difference between PUT and PATCH&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Transmission control protocol (TCP)&lt;/h3&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/JdAsdvG.jpg" /&gt; &lt;br /&gt; &lt;i&gt;&lt;a href="http://www.wildbunny.co.uk/blog/2012/10/09/how-to-make-a-multi-player-game-part-1/"&gt;Source: How to make a multiplayer game&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;p&gt;TCP is a connection-oriented protocol over an &lt;a href="https://en.wikipedia.org/wiki/Internet_Protocol"&gt;IP network&lt;/a&gt;. Connection is established and terminated using a &lt;a href="https://en.wikipedia.org/wiki/Handshaking"&gt;handshake&lt;/a&gt;. All packets sent are guaranteed to reach the destination in the original order and without corruption through:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Sequence numbers and &lt;a href="https://en.wikipedia.org/wiki/Transmission_Control_Protocol#Checksum_computation"&gt;checksum fields&lt;/a&gt; for each packet&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Acknowledgement_(data_networks)"&gt;Acknowledgement&lt;/a&gt; packets and automatic retransmission&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;If the sender does not receive a correct response, it will resend the packets. If there are multiple timeouts, the connection is dropped. TCP also implements &lt;a href="https://en.wikipedia.org/wiki/Flow_control_(data)"&gt;flow control&lt;/a&gt; and &lt;a href="https://en.wikipedia.org/wiki/Network_congestion#Congestion_control"&gt;congestion control&lt;/a&gt;. These guarantees cause delays and generally result in less efficient transmission than UDP.&lt;/p&gt; 
&lt;p&gt;To ensure high throughput, web servers can keep a large number of TCP connections open, resulting in high memory usage. It can be expensive to have a large number of open connections between web server threads and say, a &lt;a href="https://memcached.org/"&gt;memcached&lt;/a&gt; server. &lt;a href="https://en.wikipedia.org/wiki/Connection_pool"&gt;Connection pooling&lt;/a&gt; can help in addition to switching to UDP where applicable.&lt;/p&gt; 
&lt;p&gt;TCP is useful for applications that require high reliability but are less time critical. Some examples include web servers, database info, SMTP, FTP, and SSH.&lt;/p&gt; 
&lt;p&gt;Use TCP over UDP when:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;You need all of the data to arrive intact&lt;/li&gt; 
 &lt;li&gt;You want to automatically make a best estimate use of the network throughput&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;User datagram protocol (UDP)&lt;/h3&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/yzDrJtA.jpg" /&gt; &lt;br /&gt; &lt;i&gt;&lt;a href="http://www.wildbunny.co.uk/blog/2012/10/09/how-to-make-a-multi-player-game-part-1/"&gt;Source: How to make a multiplayer game&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;p&gt;UDP is connectionless. Datagrams (analogous to packets) are guaranteed only at the datagram level. Datagrams might reach their destination out of order or not at all. UDP does not support congestion control. Without the guarantees that TCP support, UDP is generally more efficient.&lt;/p&gt; 
&lt;p&gt;UDP can broadcast, sending datagrams to all devices on the subnet. This is useful with &lt;a href="https://en.wikipedia.org/wiki/Dynamic_Host_Configuration_Protocol"&gt;DHCP&lt;/a&gt; because the client has not yet received an IP address, thus preventing a way for TCP to stream without the IP address.&lt;/p&gt; 
&lt;p&gt;UDP is less reliable but works well in real time use cases such as VoIP, video chat, streaming, and realtime multiplayer games.&lt;/p&gt; 
&lt;p&gt;Use UDP over TCP when:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;You need the lowest latency&lt;/li&gt; 
 &lt;li&gt;Late data is worse than loss of data&lt;/li&gt; 
 &lt;li&gt;You want to implement your own error correction&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Source(s) and further reading: TCP and UDP&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="http://gafferongames.com/networking-for-game-programmers/udp-vs-tcp/"&gt;Networking for game programming&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://www.cyberciti.biz/faq/key-differences-between-tcp-and-udp-protocols/"&gt;Key differences between TCP and UDP protocols&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://stackoverflow.com/questions/5970383/difference-between-tcp-and-udp"&gt;Difference between TCP and UDP&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Transmission_Control_Protocol"&gt;Transmission control protocol&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/User_Datagram_Protocol"&gt;User datagram protocol&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://www.cs.bu.edu/~jappavoo/jappavoo.github.com/451/papers/memcache-fb.pdf"&gt;Scaling memcache at Facebook&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Remote procedure call (RPC)&lt;/h3&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/iF4Mkb5.png" /&gt; &lt;br /&gt; &lt;i&gt;&lt;a href="http://www.puncsky.com/blog/2016-02-13-crack-the-system-design-interview"&gt;Source: Crack the system design interview&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;p&gt;In an RPC, a client causes a procedure to execute on a different address space, usually a remote server. The procedure is coded as if it were a local procedure call, abstracting away the details of how to communicate with the server from the client program. Remote calls are usually slower and less reliable than local calls so it is helpful to distinguish RPC calls from local calls. Popular RPC frameworks include &lt;a href="https://developers.google.com/protocol-buffers/"&gt;Protobuf&lt;/a&gt;, &lt;a href="https://thrift.apache.org/"&gt;Thrift&lt;/a&gt;, and &lt;a href="https://avro.apache.org/docs/current/"&gt;Avro&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;RPC is a request-response protocol:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Client program&lt;/strong&gt; - Calls the client stub procedure. The parameters are pushed onto the stack like a local procedure call.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Client stub procedure&lt;/strong&gt; - Marshals (packs) procedure id and arguments into a request message.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Client communication module&lt;/strong&gt; - OS sends the message from the client to the server.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Server communication module&lt;/strong&gt; - OS passes the incoming packets to the server stub procedure.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Server stub procedure&lt;/strong&gt; - Unmarshalls the results, calls the server procedure matching the procedure id and passes the given arguments.&lt;/li&gt; 
 &lt;li&gt;The server response repeats the steps above in reverse order.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Sample RPC calls:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;GET /someoperation?data=anId

POST /anotheroperation
{
  "data":"anId";
  "anotherdata": "another value"
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;RPC is focused on exposing behaviors. RPCs are often used for performance reasons with internal communications, as you can hand-craft native calls to better fit your use cases.&lt;/p&gt; 
&lt;p&gt;Choose a native library (aka SDK) when:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;You know your target platform.&lt;/li&gt; 
 &lt;li&gt;You want to control how your "logic" is accessed.&lt;/li&gt; 
 &lt;li&gt;You want to control how error control happens off your library.&lt;/li&gt; 
 &lt;li&gt;Performance and end user experience is your primary concern.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;HTTP APIs following &lt;strong&gt;REST&lt;/strong&gt; tend to be used more often for public APIs.&lt;/p&gt; 
&lt;h4&gt;Disadvantage(s): RPC&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;RPC clients become tightly coupled to the service implementation.&lt;/li&gt; 
 &lt;li&gt;A new API must be defined for every new operation or use case.&lt;/li&gt; 
 &lt;li&gt;It can be difficult to debug RPC.&lt;/li&gt; 
 &lt;li&gt;You might not be able to leverage existing technologies out of the box. For example, it might require additional effort to ensure &lt;a href="https://web.archive.org/web/20170608193645/http://etherealbits.com/2012/12/debunking-the-myths-of-rpc-rest/"&gt;RPC calls are properly cached&lt;/a&gt; on caching servers such as &lt;a href="http://www.squid-cache.org/"&gt;Squid&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Representational state transfer (REST)&lt;/h3&gt; 
&lt;p&gt;REST is an architectural style enforcing a client/server model where the client acts on a set of resources managed by the server. The server provides a representation of resources and actions that can either manipulate or get a new representation of resources. All communication must be stateless and cacheable.&lt;/p&gt; 
&lt;p&gt;There are four qualities of a RESTful interface:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Identify resources (URI in HTTP)&lt;/strong&gt; - use the same URI regardless of any operation.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Change with representations (Verbs in HTTP)&lt;/strong&gt; - use verbs, headers, and body.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Self-descriptive error message (status response in HTTP)&lt;/strong&gt; - Use status codes, don't reinvent the wheel.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="http://restcookbook.com/Basics/hateoas/"&gt;HATEOAS&lt;/a&gt; (HTML interface for HTTP)&lt;/strong&gt; - your web service should be fully accessible in a browser.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Sample REST calls:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;GET /someresources/anId

PUT /someresources/anId
{"anotherdata": "another value"}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;REST is focused on exposing data. It minimizes the coupling between client/server and is often used for public HTTP APIs. REST uses a more generic and uniform method of exposing resources through URIs, &lt;a href="https://github.com/for-GET/know-your-http-well/raw/master/headers.md"&gt;representation through headers&lt;/a&gt;, and actions through verbs such as GET, POST, PUT, DELETE, and PATCH. Being stateless, REST is great for horizontal scaling and partitioning.&lt;/p&gt; 
&lt;h4&gt;Disadvantage(s): REST&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;With REST being focused on exposing data, it might not be a good fit if resources are not naturally organized or accessed in a simple hierarchy. For example, returning all updated records from the past hour matching a particular set of events is not easily expressed as a path. With REST, it is likely to be implemented with a combination of URI path, query parameters, and possibly the request body.&lt;/li&gt; 
 &lt;li&gt;REST typically relies on a few verbs (GET, POST, PUT, DELETE, and PATCH) which sometimes doesn't fit your use case. For example, moving expired documents to the archive folder might not cleanly fit within these verbs.&lt;/li&gt; 
 &lt;li&gt;Fetching complicated resources with nested hierarchies requires multiple round trips between the client and server to render single views, e.g. fetching content of a blog entry and the comments on that entry. For mobile applications operating in variable network conditions, these multiple roundtrips are highly undesirable.&lt;/li&gt; 
 &lt;li&gt;Over time, more fields might be added to an API response and older clients will receive all new data fields, even those that they do not need, as a result, it bloats the payload size and leads to larger latencies.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;RPC and REST calls comparison&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Operation&lt;/th&gt; 
   &lt;th&gt;RPC&lt;/th&gt; 
   &lt;th&gt;REST&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Signup&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;POST&lt;/strong&gt; /signup&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;POST&lt;/strong&gt; /persons&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Resign&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;POST&lt;/strong&gt; /resign&lt;br /&gt;{&lt;br /&gt;"personid": "1234"&lt;br /&gt;}&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;DELETE&lt;/strong&gt; /persons/1234&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Read a person&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;GET&lt;/strong&gt; /readPerson?personid=1234&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;GET&lt;/strong&gt; /persons/1234&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Read a personâ€™s items list&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;GET&lt;/strong&gt; /readUsersItemsList?personid=1234&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;GET&lt;/strong&gt; /persons/1234/items&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Add an item to a personâ€™s items&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;POST&lt;/strong&gt; /addItemToUsersItemsList&lt;br /&gt;{&lt;br /&gt;"personid": "1234";&lt;br /&gt;"itemid": "456"&lt;br /&gt;}&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;POST&lt;/strong&gt; /persons/1234/items&lt;br /&gt;{&lt;br /&gt;"itemid": "456"&lt;br /&gt;}&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Update an item&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;POST&lt;/strong&gt; /modifyItem&lt;br /&gt;{&lt;br /&gt;"itemid": "456";&lt;br /&gt;"key": "value"&lt;br /&gt;}&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;PUT&lt;/strong&gt; /items/456&lt;br /&gt;{&lt;br /&gt;"key": "value"&lt;br /&gt;}&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Delete an item&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;POST&lt;/strong&gt; /removeItem&lt;br /&gt;{&lt;br /&gt;"itemid": "456"&lt;br /&gt;}&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;DELETE&lt;/strong&gt; /items/456&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p align="center"&gt; &lt;i&gt;&lt;a href="https://apihandyman.io/do-you-really-know-why-you-prefer-rest-over-rpc/"&gt;Source: Do you really know why you prefer REST over RPC&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;h4&gt;Source(s) and further reading: REST and RPC&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://apihandyman.io/do-you-really-know-why-you-prefer-rest-over-rpc/"&gt;Do you really know why you prefer REST over RPC&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://programmers.stackexchange.com/a/181186"&gt;When are RPC-ish approaches more appropriate than REST?&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://stackoverflow.com/questions/15056878/rest-vs-json-rpc"&gt;REST vs JSON-RPC&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://web.archive.org/web/20170608193645/http://etherealbits.com/2012/12/debunking-the-myths-of-rpc-rest/"&gt;Debunking the myths of RPC and REST&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.quora.com/What-are-the-drawbacks-of-using-RESTful-APIs"&gt;What are the drawbacks of using REST&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://www.puncsky.com/blog/2016-02-13-crack-the-system-design-interview"&gt;Crack the system design interview&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://code.facebook.com/posts/1468950976659943/"&gt;Thrift&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://arstechnica.com/civis/viewtopic.php?t=1190508"&gt;Why REST for internal use and not RPC&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Security&lt;/h2&gt; 
&lt;p&gt;This section could use some updates. Consider &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#contributing"&gt;contributing&lt;/a&gt;!&lt;/p&gt; 
&lt;p&gt;Security is a broad topic. Unless you have considerable experience, a security background, or are applying for a position that requires knowledge of security, you probably won't need to know more than the basics:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Encrypt in transit and at rest.&lt;/li&gt; 
 &lt;li&gt;Sanitize all user inputs or any input parameters exposed to user to prevent &lt;a href="https://en.wikipedia.org/wiki/Cross-site_scripting"&gt;XSS&lt;/a&gt; and &lt;a href="https://en.wikipedia.org/wiki/SQL_injection"&gt;SQL injection&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Use parameterized queries to prevent SQL injection.&lt;/li&gt; 
 &lt;li&gt;Use the principle of &lt;a href="https://en.wikipedia.org/wiki/Principle_of_least_privilege"&gt;least privilege&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Source(s) and further reading&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/shieldfy/API-Security-Checklist"&gt;API security checklist&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/FallibleInc/security-guide-for-developers"&gt;Security guide for developers&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.owasp.org/index.php/OWASP_Top_Ten_Cheat_Sheet"&gt;OWASP top ten&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Appendix&lt;/h2&gt; 
&lt;p&gt;You'll sometimes be asked to do 'back-of-the-envelope' estimates. For example, you might need to determine how long it will take to generate 100 image thumbnails from disk or how much memory a data structure will take. The &lt;strong&gt;Powers of two table&lt;/strong&gt; and &lt;strong&gt;Latency numbers every programmer should know&lt;/strong&gt; are handy references.&lt;/p&gt; 
&lt;h3&gt;Powers of two table&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;Power           Exact Value         Approx Value        Bytes
---------------------------------------------------------------
7                             128
8                             256
10                           1024   1 thousand           1 KB
16                         65,536                       64 KB
20                      1,048,576   1 million            1 MB
30                  1,073,741,824   1 billion            1 GB
32                  4,294,967,296                        4 GB
40              1,099,511,627,776   1 trillion           1 TB
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Source(s) and further reading&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Power_of_two"&gt;Powers of two&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Latency numbers every programmer should know&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;Latency Comparison Numbers
--------------------------
L1 cache reference                           0.5 ns
Branch mispredict                            5   ns
L2 cache reference                           7   ns                      14x L1 cache
Mutex lock/unlock                           25   ns
Main memory reference                      100   ns                      20x L2 cache, 200x L1 cache
Compress 1K bytes with Zippy            10,000   ns       10 us
Send 1 KB bytes over 1 Gbps network     10,000   ns       10 us
Read 4 KB randomly from SSD*           150,000   ns      150 us          ~1GB/sec SSD
Read 1 MB sequentially from memory     250,000   ns      250 us
Round trip within same datacenter      500,000   ns      500 us
Read 1 MB sequentially from SSD*     1,000,000   ns    1,000 us    1 ms  ~1GB/sec SSD, 4X memory
HDD seek                            10,000,000   ns   10,000 us   10 ms  20x datacenter roundtrip
Read 1 MB sequentially from 1 Gbps  10,000,000   ns   10,000 us   10 ms  40x memory, 10X SSD
Read 1 MB sequentially from HDD     30,000,000   ns   30,000 us   30 ms 120x memory, 30X SSD
Send packet CA-&amp;gt;Netherlands-&amp;gt;CA    150,000,000   ns  150,000 us  150 ms

Notes
-----
1 ns = 10^-9 seconds
1 us = 10^-6 seconds = 1,000 ns
1 ms = 10^-3 seconds = 1,000 us = 1,000,000 ns
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Handy metrics based on numbers above:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Read sequentially from HDD at 30 MB/s&lt;/li&gt; 
 &lt;li&gt;Read sequentially from 1 Gbps Ethernet at 100 MB/s&lt;/li&gt; 
 &lt;li&gt;Read sequentially from SSD at 1 GB/s&lt;/li&gt; 
 &lt;li&gt;Read sequentially from main memory at 4 GB/s&lt;/li&gt; 
 &lt;li&gt;6-7 world-wide round trips per second&lt;/li&gt; 
 &lt;li&gt;2,000 round trips per second within a data center&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Latency numbers visualized&lt;/h4&gt; 
&lt;p&gt;&lt;img src="https://camo.githubusercontent.com/77f72259e1eb58596b564d1ad823af1853bc60a3/687474703a2f2f692e696d6775722e636f6d2f6b307431652e706e67" alt="" /&gt;&lt;/p&gt; 
&lt;h4&gt;Source(s) and further reading&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://gist.github.com/jboner/2841832"&gt;Latency numbers every programmer should know - 1&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://gist.github.com/hellerbarde/2843375"&gt;Latency numbers every programmer should know - 2&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://www.cs.cornell.edu/projects/ladis2009/talks/dean-keynote-ladis2009.pdf"&gt;Designs, lessons, and advice from building large distributed systems&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://static.googleusercontent.com/media/research.google.com/en//people/jeff/stanford-295-talk.pdf"&gt;Software Engineering Advice from Building Large-Scale Distributed Systems&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Additional system design interview questions&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Common system design interview questions, with links to resources on how to solve each.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Question&lt;/th&gt; 
   &lt;th&gt;Reference(s)&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a file sync service like Dropbox&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.youtube.com/watch?v=PE4gwstWhmc"&gt;youtube.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a search engine like Google&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://queue.acm.org/detail.cfm?id=988407"&gt;queue.acm.org&lt;/a&gt;&lt;br /&gt;&lt;a href="http://programmers.stackexchange.com/questions/38324/interview-question-how-would-you-implement-google-search"&gt;stackexchange.com&lt;/a&gt;&lt;br /&gt;&lt;a href="http://www.ardendertat.com/2012/01/11/implementing-search-engines/"&gt;ardendertat.com&lt;/a&gt;&lt;br /&gt;&lt;a href="http://infolab.stanford.edu/~backrub/google.html"&gt;stanford.edu&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a scalable web crawler like Google&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.quora.com/How-can-I-build-a-web-crawler-from-scratch"&gt;quora.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design Google docs&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://code.google.com/p/google-mobwrite/"&gt;code.google.com&lt;/a&gt;&lt;br /&gt;&lt;a href="https://neil.fraser.name/writing/sync/"&gt;neil.fraser.name&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a key-value store like Redis&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://www.slideshare.net/dvirsky/introduction-to-redis"&gt;slideshare.net&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a cache system like Memcached&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://www.slideshare.net/oemebamo/introduction-to-memcached"&gt;slideshare.net&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a recommendation system like Amazon's&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://web.archive.org/web/20170406065247/http://tech.hulu.com/blog/2011/09/19/recommendation-system.html"&gt;hulu.com&lt;/a&gt;&lt;br /&gt;&lt;a href="http://ijcai13.org/files/tutorial_slides/td3.pdf"&gt;ijcai13.org&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a tinyurl system like Bitly&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://n00tc0d3r.blogspot.com/"&gt;n00tc0d3r.blogspot.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a chat app like WhatsApp&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://highscalability.com/blog/2014/2/26/the-whatsapp-architecture-facebook-bought-for-19-billion.html"&gt;highscalability.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a picture sharing system like Instagram&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://highscalability.com/flickr-architecture"&gt;highscalability.com&lt;/a&gt;&lt;br /&gt;&lt;a href="http://highscalability.com/blog/2011/12/6/instagram-architecture-14-million-users-terabytes-of-photos.html"&gt;highscalability.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design the Facebook news feed function&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://www.quora.com/What-are-best-practices-for-building-something-like-a-News-Feed"&gt;quora.com&lt;/a&gt;&lt;br /&gt;&lt;a href="http://www.quora.com/Activity-Streams/What-are-the-scaling-issues-to-keep-in-mind-while-developing-a-social-network-feed"&gt;quora.com&lt;/a&gt;&lt;br /&gt;&lt;a href="http://www.slideshare.net/danmckinley/etsy-activity-feeds-architecture"&gt;slideshare.net&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design the Facebook timeline function&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.facebook.com/note.php?note_id=10150468255628920"&gt;facebook.com&lt;/a&gt;&lt;br /&gt;&lt;a href="http://highscalability.com/blog/2012/1/23/facebook-timeline-brought-to-you-by-the-power-of-denormaliza.html"&gt;highscalability.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design the Facebook chat function&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://www.erlang-factory.com/upload/presentations/31/EugeneLetuchy-ErlangatFacebook.pdf"&gt;erlang-factory.com&lt;/a&gt;&lt;br /&gt;&lt;a href="https://www.facebook.com/note.php?note_id=14218138919&amp;amp;id=9445547199&amp;amp;index=0"&gt;facebook.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a graph search function like Facebook's&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.facebook.com/notes/facebook-engineering/under-the-hood-building-out-the-infrastructure-for-graph-search/10151347573598920"&gt;facebook.com&lt;/a&gt;&lt;br /&gt;&lt;a href="https://www.facebook.com/notes/facebook-engineering/under-the-hood-indexing-and-ranking-in-graph-search/10151361720763920"&gt;facebook.com&lt;/a&gt;&lt;br /&gt;&lt;a href="https://www.facebook.com/notes/facebook-engineering/under-the-hood-the-natural-language-interface-of-graph-search/10151432733048920"&gt;facebook.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a content delivery network like CloudFlare&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://figshare.com/articles/Globally_distributed_content_delivery/6605972"&gt;figshare.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a trending topic system like Twitter's&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://www.michael-noll.com/blog/2013/01/18/implementing-real-time-trending-topics-in-storm/"&gt;michael-noll.com&lt;/a&gt;&lt;br /&gt;&lt;a href="http://snikolov.wordpress.com/2012/11/14/early-detection-of-twitter-trends/"&gt;snikolov .wordpress.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a random ID generation system&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://blog.twitter.com/2010/announcing-snowflake"&gt;blog.twitter.com&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/twitter/snowflake/"&gt;github.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Return the top k requests during a time interval&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.cs.ucsb.edu/sites/default/files/documents/2005-23.pdf"&gt;cs.ucsb.edu&lt;/a&gt;&lt;br /&gt;&lt;a href="http://davis.wpi.edu/xmdv/docs/EDBT11-diyang.pdf"&gt;wpi.edu&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a system that serves data from multiple data centers&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://highscalability.com/blog/2009/8/24/how-google-serves-data-from-multiple-datacenters.html"&gt;highscalability.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design an online multiplayer card game&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://web.archive.org/web/20180929181117/http://www.indieflashblog.com/how-to-create-an-asynchronous-multiplayer-game.html"&gt;indieflashblog.com&lt;/a&gt;&lt;br /&gt;&lt;a href="http://buildnewgames.com/real-time-multiplayer/"&gt;buildnewgames.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a garbage collection system&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://journal.stuffwithstuff.com/2013/12/08/babys-first-garbage-collector/"&gt;stuffwithstuff.com&lt;/a&gt;&lt;br /&gt;&lt;a href="http://courses.cs.washington.edu/courses/csep521/07wi/prj/rick.pdf"&gt;washington.edu&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design an API rate limiter&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://stripe.com/blog/rate-limiters"&gt;https://stripe.com/blog/&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a Stock Exchange (like NASDAQ or Binance)&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://youtu.be/b1e4t2k2KJY"&gt;Jane Street&lt;/a&gt;&lt;br /&gt;&lt;a href="https://around25.com/blog/building-a-trading-engine-for-a-crypto-exchange/"&gt;Golang Implementation&lt;/a&gt;&lt;br /&gt;&lt;a href="http://bhomnick.net/building-a-simple-limit-order-in-go/"&gt;Go Implementation&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Add a system design question&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#contributing"&gt;Contribute&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Real world architectures&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Articles on how real world systems are designed.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/TcUo2fw.png" /&gt; &lt;br /&gt; &lt;i&gt;&lt;a href="https://www.infoq.com/presentations/Twitter-Timeline-Scalability"&gt;Source: Twitter timelines at scale&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Don't focus on nitty gritty details for the following articles, instead:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Identify shared principles, common technologies, and patterns within these articles&lt;/li&gt; 
 &lt;li&gt;Study what problems are solved by each component, where it works, where it doesn't&lt;/li&gt; 
 &lt;li&gt;Review the lessons learned&lt;/li&gt; 
&lt;/ul&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Type&lt;/th&gt; 
   &lt;th&gt;System&lt;/th&gt; 
   &lt;th&gt;Reference(s)&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Data processing&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;MapReduce&lt;/strong&gt; - Distributed data processing from Google&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://static.googleusercontent.com/media/research.google.com/zh-CN/us/archive/mapreduce-osdi04.pdf"&gt;research.google.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Data processing&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Spark&lt;/strong&gt; - Distributed data processing from Databricks&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://www.slideshare.net/AGrishchenko/apache-spark-architecture"&gt;slideshare.net&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Data processing&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Storm&lt;/strong&gt; - Distributed data processing from Twitter&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://www.slideshare.net/previa/storm-16094009"&gt;slideshare.net&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Data store&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Bigtable&lt;/strong&gt; - Distributed column-oriented database from Google&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://www.read.seas.harvard.edu/~kohler/class/cs239-w08/chang06bigtable.pdf"&gt;harvard.edu&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Data store&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;HBase&lt;/strong&gt; - Open source implementation of Bigtable&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://www.slideshare.net/alexbaranau/intro-to-hbase"&gt;slideshare.net&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Data store&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Cassandra&lt;/strong&gt; - Distributed column-oriented database from Facebook&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://www.slideshare.net/planetcassandra/cassandra-introduction-features-30103666"&gt;slideshare.net&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Data store&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;DynamoDB&lt;/strong&gt; - Document-oriented database from Amazon&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://www.read.seas.harvard.edu/~kohler/class/cs239-w08/decandia07dynamo.pdf"&gt;harvard.edu&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Data store&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;MongoDB&lt;/strong&gt; - Document-oriented database&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://www.slideshare.net/mdirolf/introduction-to-mongodb"&gt;slideshare.net&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Data store&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Spanner&lt;/strong&gt; - Globally-distributed database from Google&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://research.google.com/archive/spanner-osdi2012.pdf"&gt;research.google.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Data store&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Memcached&lt;/strong&gt; - Distributed memory caching system&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://www.slideshare.net/oemebamo/introduction-to-memcached"&gt;slideshare.net&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Data store&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Redis&lt;/strong&gt; - Distributed memory caching system with persistence and value types&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://www.slideshare.net/dvirsky/introduction-to-redis"&gt;slideshare.net&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;File system&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Google File System (GFS)&lt;/strong&gt; - Distributed file system&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://static.googleusercontent.com/media/research.google.com/zh-CN/us/archive/gfs-sosp2003.pdf"&gt;research.google.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;File system&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Hadoop File System (HDFS)&lt;/strong&gt; - Open source implementation of GFS&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html"&gt;apache.org&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Misc&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Chubby&lt;/strong&gt; - Lock service for loosely-coupled distributed systems from Google&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://static.googleusercontent.com/external_content/untrusted_dlcp/research.google.com/en/us/archive/chubby-osdi06.pdf"&gt;research.google.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Misc&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Dapper&lt;/strong&gt; - Distributed systems tracing infrastructure&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://static.googleusercontent.com/media/research.google.com/en//pubs/archive/36356.pdf"&gt;research.google.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Misc&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Kafka&lt;/strong&gt; - Pub/sub message queue from LinkedIn&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://www.slideshare.net/mumrah/kafka-talk-tri-hug"&gt;slideshare.net&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Misc&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Zookeeper&lt;/strong&gt; - Centralized infrastructure and services enabling synchronization&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://www.slideshare.net/sauravhaloi/introduction-to-apache-zookeeper"&gt;slideshare.net&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;Add an architecture&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#contributing"&gt;Contribute&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Company architectures&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Company&lt;/th&gt; 
   &lt;th&gt;Reference(s)&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Amazon&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://highscalability.com/amazon-architecture"&gt;Amazon architecture&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Cinchcast&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://highscalability.com/blog/2012/7/16/cinchcast-architecture-producing-1500-hours-of-audio-every-d.html"&gt;Producing 1,500 hours of audio every day&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;DataSift&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://highscalability.com/blog/2011/11/29/datasift-architecture-realtime-datamining-at-120000-tweets-p.html"&gt;Realtime datamining At 120,000 tweets per second&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Dropbox&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.youtube.com/watch?v=PE4gwstWhmc"&gt;How we've scaled Dropbox&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ESPN&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://highscalability.com/blog/2013/11/4/espns-architecture-at-scale-operating-at-100000-duh-nuh-nuhs.html"&gt;Operating At 100,000 duh nuh nuhs per second&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Google&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://highscalability.com/google-architecture"&gt;Google architecture&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Instagram&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://highscalability.com/blog/2011/12/6/instagram-architecture-14-million-users-terabytes-of-photos.html"&gt;14 million users, terabytes of photos&lt;/a&gt;&lt;br /&gt;&lt;a href="http://instagram-engineering.tumblr.com/post/13649370142/what-powers-instagram-hundreds-of-instances"&gt;What powers Instagram&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Justin.tv&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://highscalability.com/blog/2010/3/16/justintvs-live-video-broadcasting-architecture.html"&gt;Justin.Tv's live video broadcasting architecture&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Facebook&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://cs.uwaterloo.ca/~brecht/courses/854-Emerging-2014/readings/key-value/fb-memcached-nsdi-2013.pdf"&gt;Scaling memcached at Facebook&lt;/a&gt;&lt;br /&gt;&lt;a href="https://cs.uwaterloo.ca/~brecht/courses/854-Emerging-2014/readings/data-store/tao-facebook-distributed-datastore-atc-2013.pdf"&gt;TAO: Facebookâ€™s distributed data store for the social graph&lt;/a&gt;&lt;br /&gt;&lt;a href="https://www.usenix.org/legacy/event/osdi10/tech/full_papers/Beaver.pdf"&gt;Facebookâ€™s photo storage&lt;/a&gt;&lt;br /&gt;&lt;a href="http://highscalability.com/blog/2016/6/27/how-facebook-live-streams-to-800000-simultaneous-viewers.html"&gt;How Facebook Live Streams To 800,000 Simultaneous Viewers&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Flickr&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://highscalability.com/flickr-architecture"&gt;Flickr architecture&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Mailbox&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://highscalability.com/blog/2013/6/18/scaling-mailbox-from-0-to-one-million-users-in-6-weeks-and-1.html"&gt;From 0 to one million users in 6 weeks&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Netflix&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://highscalability.com/blog/2015/11/9/a-360-degree-view-of-the-entire-netflix-stack.html"&gt;A 360 Degree View Of The Entire Netflix Stack&lt;/a&gt;&lt;br /&gt;&lt;a href="http://highscalability.com/blog/2017/12/11/netflix-what-happens-when-you-press-play.html"&gt;Netflix: What Happens When You Press Play?&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Pinterest&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://highscalability.com/blog/2013/4/15/scaling-pinterest-from-0-to-10s-of-billions-of-page-views-a.html"&gt;From 0 To 10s of billions of page views a month&lt;/a&gt;&lt;br /&gt;&lt;a href="http://highscalability.com/blog/2012/5/21/pinterest-architecture-update-18-million-visitors-10x-growth.html"&gt;18 million visitors, 10x growth, 12 employees&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Playfish&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://highscalability.com/blog/2010/9/21/playfishs-social-gaming-architecture-50-million-monthly-user.html"&gt;50 million monthly users and growing&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;PlentyOfFish&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://highscalability.com/plentyoffish-architecture"&gt;PlentyOfFish architecture&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Salesforce&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://highscalability.com/blog/2013/9/23/salesforce-architecture-how-they-handle-13-billion-transacti.html"&gt;How they handle 1.3 billion transactions a day&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Stack Overflow&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://highscalability.com/blog/2009/8/5/stack-overflow-architecture.html"&gt;Stack Overflow architecture&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;TripAdvisor&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://highscalability.com/blog/2011/6/27/tripadvisor-architecture-40m-visitors-200m-dynamic-page-view.html"&gt;40M visitors, 200M dynamic page views, 30TB data&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Tumblr&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://highscalability.com/blog/2012/2/13/tumblr-architecture-15-billion-page-views-a-month-and-harder.html"&gt;15 billion page views a month&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Twitter&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://highscalability.com/scaling-twitter-making-twitter-10000-percent-faster"&gt;Making Twitter 10000 percent faster&lt;/a&gt;&lt;br /&gt;&lt;a href="http://highscalability.com/blog/2011/12/19/how-twitter-stores-250-million-tweets-a-day-using-mysql.html"&gt;Storing 250 million tweets a day using MySQL&lt;/a&gt;&lt;br /&gt;&lt;a href="http://highscalability.com/blog/2013/7/8/the-architecture-twitter-uses-to-deal-with-150m-active-users.html"&gt;150M active users, 300K QPS, a 22 MB/S firehose&lt;/a&gt;&lt;br /&gt;&lt;a href="https://www.infoq.com/presentations/Twitter-Timeline-Scalability"&gt;Timelines at scale&lt;/a&gt;&lt;br /&gt;&lt;a href="https://www.youtube.com/watch?v=5cKTP36HVgI"&gt;Big and small data at Twitter&lt;/a&gt;&lt;br /&gt;&lt;a href="https://www.youtube.com/watch?v=z8LU0Cj6BOU"&gt;Operations at Twitter: scaling beyond 100 million users&lt;/a&gt;&lt;br /&gt;&lt;a href="http://highscalability.com/blog/2016/4/20/how-twitter-handles-3000-images-per-second.html"&gt;How Twitter Handles 3,000 Images Per Second&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Uber&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://highscalability.com/blog/2015/9/14/how-uber-scales-their-real-time-market-platform.html"&gt;How Uber scales their real-time market platform&lt;/a&gt;&lt;br /&gt;&lt;a href="http://highscalability.com/blog/2016/10/12/lessons-learned-from-scaling-uber-to-2000-engineers-1000-ser.html"&gt;Lessons Learned From Scaling Uber To 2000 Engineers, 1000 Services, And 8000 Git Repositories&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;WhatsApp&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://highscalability.com/blog/2014/2/26/the-whatsapp-architecture-facebook-bought-for-19-billion.html"&gt;The WhatsApp architecture Facebook bought for $19 billion&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;YouTube&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.youtube.com/watch?v=w5WVu624fY8"&gt;YouTube scalability&lt;/a&gt;&lt;br /&gt;&lt;a href="http://highscalability.com/youtube-architecture"&gt;YouTube architecture&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Company engineering blogs&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Architectures for companies you are interviewing with.&lt;/p&gt; 
 &lt;p&gt;Questions you encounter might be from the same domain.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="http://nerds.airbnb.com/"&gt;Airbnb Engineering&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://developer.atlassian.com/blog/"&gt;Atlassian Developers&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://aws.amazon.com/blogs/aws/"&gt;AWS Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://word.bitly.com/"&gt;Bitly Engineering Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://blog.box.com/blog/category/engineering"&gt;Box Blogs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://blog.cloudera.com/"&gt;Cloudera Developer Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://tech.dropbox.com/"&gt;Dropbox Tech Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.quora.com/q/quoraengineering"&gt;Engineering at Quora&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://www.ebaytechblog.com/"&gt;Ebay Tech Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://blog.evernote.com/tech/"&gt;Evernote Tech Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://codeascraft.com/"&gt;Etsy Code as Craft&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.facebook.com/Engineering"&gt;Facebook Engineering&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://code.flickr.net/"&gt;Flickr Code&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://engineering.foursquare.com/"&gt;Foursquare Engineering Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.blog/category/engineering"&gt;GitHub Engineering Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://googleresearch.blogspot.com/"&gt;Google Research Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://engineering.groupon.com/"&gt;Groupon Engineering Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://engineering.heroku.com/"&gt;Heroku Engineering Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://product.hubspot.com/blog/topic/engineering"&gt;Hubspot Engineering Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://highscalability.com/"&gt;High Scalability&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://instagram-engineering.tumblr.com/"&gt;Instagram Engineering&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://software.intel.com/en-us/blogs/"&gt;Intel Software Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://blogs.janestreet.com/category/ocaml/"&gt;Jane Street Tech Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://engineering.linkedin.com/blog"&gt;LinkedIn Engineering&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://engineering.microsoft.com/"&gt;Microsoft Engineering&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://blogs.msdn.microsoft.com/pythonengineering/"&gt;Microsoft Python Engineering&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://techblog.netflix.com/"&gt;Netflix Tech Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://medium.com/paypal-engineering"&gt;Paypal Developer Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://medium.com/@Pinterest_Engineering"&gt;Pinterest Engineering Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://www.redditblog.com/"&gt;Reddit Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://developer.salesforce.com/blogs/engineering/"&gt;Salesforce Engineering Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://slack.engineering/"&gt;Slack Engineering Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://labs.spotify.com/"&gt;Spotify Labs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://stripe.com/blog/engineering"&gt;Stripe Engineering Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://www.twilio.com/engineering"&gt;Twilio Engineering Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://blog.twitter.com/engineering/"&gt;Twitter Engineering&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://eng.uber.com/"&gt;Uber Engineering Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://yahooeng.tumblr.com/"&gt;Yahoo Engineering Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://engineeringblog.yelp.com/"&gt;Yelp Engineering Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.zynga.com/blogs/engineering"&gt;Zynga Engineering Blog&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Source(s) and further reading&lt;/h4&gt; 
&lt;p&gt;Looking to add a blog? To avoid duplicating work, consider adding your company blog to the following repo:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/kilimchoi/engineering-blogs"&gt;kilimchoi/engineering-blogs&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Under development&lt;/h2&gt; 
&lt;p&gt;Interested in adding a section or helping complete one in-progress? &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#contributing"&gt;Contribute&lt;/a&gt;!&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Distributed computing with MapReduce&lt;/li&gt; 
 &lt;li&gt;Consistent hashing&lt;/li&gt; 
 &lt;li&gt;Scatter gather&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#contributing"&gt;Contribute&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Credits&lt;/h2&gt; 
&lt;p&gt;Credits and sources are provided throughout this repo.&lt;/p&gt; 
&lt;p&gt;Special thanks to:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="http://www.hiredintech.com/system-design/the-system-design-process/"&gt;Hired in tech&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.amazon.com/dp/0984782850/"&gt;Cracking the coding interview&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://highscalability.com/"&gt;High scalability&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/checkcheckzz/system-design-interview"&gt;checkcheckzz/system-design-interview&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/shashank88/system_design"&gt;shashank88/system_design&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mmcgrana/services-engineering"&gt;mmcgrana/services-engineering&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://gist.github.com/vasanthk/485d1c25737e8e72759f"&gt;System design cheat sheet&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://dancres.github.io/Pages/"&gt;A distributed systems reading list&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://www.puncsky.com/blog/2016-02-13-crack-the-system-design-interview"&gt;Cracking the system design interview&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contact info&lt;/h2&gt; 
&lt;p&gt;Feel free to contact me to discuss any issues, questions, or comments.&lt;/p&gt; 
&lt;p&gt;My contact info can be found on my &lt;a href="https://github.com/donnemartin"&gt;GitHub page&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;I am providing code and resources in this repository to you under an open source license. Because this is my personal repository, the license you receive to my code and resources is from me and not my employer (Facebook).&lt;/em&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Copyright 2017 Donne Martin

Creative Commons Attribution 4.0 International License (CC BY 4.0)

http://creativecommons.org/licenses/by/4.0/
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
  </channel>
</rss>