<rss version="2.0">
  <channel>
    <title>GitHub Go Daily Trending</title>
    <description>Daily Trending of Go in GitHub</description>
    <pubDate>Tue, 04 Nov 2025 01:35:18 GMT</pubDate>
    <link>http://mshibanami.github.io/GitHubTrendingRSS</link>
    
    <item>
      <title>projectcalico/calico</title>
      <link>https://github.com/projectcalico/calico</link>
      <description>&lt;p&gt;Cloud native networking and network security&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href="https://goreportcard.com/report/github.com/projectcalico/calico"&gt;&lt;img src="https://goreportcard.com/badge/github.com/projectcalico/calico" alt="Go Report Card" /&gt;&lt;/a&gt; &lt;a href="https://artifacthub.io/packages/helm/projectcalico/tigera-operator"&gt;&lt;img src="https://img.shields.io/endpoint?url=https://artifacthub.io/badge/repository/tigera-operator" alt="ArtifactHub" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/projectcalico/calico/master/calico/LICENSE"&gt;&lt;img src="https://img.shields.io/badge/license-Apache-blue.svg?sanitize=true" alt="License" /&gt;&lt;/a&gt; &lt;a href="https://pkg.go.dev/github.com/projectcalico/api"&gt;&lt;img src="https://pkg.go.dev/badge/k8s.io/kubernetes.svg?sanitize=true" alt="GoPkg" /&gt;&lt;/a&gt; &lt;a href="https://bestpractices.coreinfrastructure.org/projects/6064"&gt;&lt;img src="https://bestpractices.coreinfrastructure.org/projects/6064/badge" alt="CII Best Practices" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;h1&gt;Calico&lt;/h1&gt; 
 &lt;h2&gt; &lt;a href="https://projectcalico.docs.tigera.io/getting-started/kubernetes/quickstart"&gt;Quickstart&lt;/a&gt; | &lt;a href="https://projectcalico.docs.tigera.io"&gt;Docs&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/projectcalico/calico/master/CONTRIBUTING.md"&gt;Contribute&lt;/a&gt; | &lt;a href="https://slack.projectcalico.org"&gt;Slack&lt;/a&gt; | &lt;a href="https://github.com/projectcalico/calico/releases"&gt;Releases&lt;/a&gt; &lt;/h2&gt; 
&lt;/div&gt; 
&lt;h2&gt;üêæ Welcome to Project Calico!&lt;/h2&gt; 
&lt;p&gt;Project Calico, created and maintained by &lt;a href="https://www.tigera.io/"&gt;Tigera&lt;/a&gt;, is an open-source project with an active development and user community. Calico Open Source has grown to be the most widely adopted solution for container networking and security, powering 8M+ nodes daily across 166 countries.&lt;/p&gt; 
&lt;h2&gt;üåü Why use Calico?&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Data Plane Choice&lt;/strong&gt;: eBPF, standard Linux, Windows, and VPP ‚Äî versatility in network solutions.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Interoperability&lt;/strong&gt;: Works across multiple distros, multiple clouds, bare metal, and VMs.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Optimized Performance&lt;/strong&gt;: Engineered for high speed and low CPU usage, maximizing your cluster investments.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Scalable Architecture&lt;/strong&gt;: Grows seamlessly with your Kubernetes clusters without sacrificing performance.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Advanced Security&lt;/strong&gt;: Get granular access controls and WireGuard encryption.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Kubernetes Networking Policy Support&lt;/strong&gt;: Continually defining excellence in Kubernetes network policy standards and support.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Vibrant Contributor Community&lt;/strong&gt;: Over 200 contributors from a wide array of global companies.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Flexible networking&lt;/strong&gt;: An array of networking tools at your disposal, including BGP, VXLAN, service advertisement, and more.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://www.tigera.io/app/uploads/2024/02/Ecosystem_shrunken_2023.svg?sanitize=true" /&gt; 
&lt;/div&gt; 
&lt;h2&gt;ü§ù Join the Calico Community&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.tigera.io/project-calico/calico-big-cats-ambassador-program/#meet-calico-big-cats"&gt;Calico Big Cats&lt;/a&gt;: Become an ambassador and share your journey&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://calendar.google.com/calendar/u/0/embed?src=tigera.io_uunmavdev5ndovf0hc4frtl0i0@group.calendar.google.com"&gt;Community Meetings&lt;/a&gt;: Engage and contribute&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/projectcalico/calico/labels/good%20first%20issue"&gt;Contribute on GitHub&lt;/a&gt;: Start with 'good first issues'&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://slack.projectcalico.org/"&gt;Connect on Slack&lt;/a&gt;: Join the conversation with fellow contributors and our developers&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üí° Contributing to Project Calico&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.tigera.io/calico/latest/about"&gt;Get Started with Project Calico&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/orgs/projectcalico/repositories"&gt;Repositories&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/projectcalico/calico/raw/master/CONTRIBUTING_DOCS.md"&gt;Contribute to our docs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Documentation: &lt;a href="https://docs.tigera.io/calico/latest/about/training-resources"&gt;Dive into our training and resources&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/projectcalico/calico/issues"&gt;Make Calico better&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üõ†Ô∏è Projects We Maintain&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/projectcalico/api"&gt;Calico Golang API&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tigera/operator"&gt;Calico operator&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/projectcalico/vpp-dataplane"&gt;VPP dataplane&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/projectcalico/bird"&gt;Calico BIRD&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üì¢ Stay Connected&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Subscribe: &lt;a href="https://www.tigera.io/project-calico/#:~:text=Join%20Calico%20Open%20Source%20community%20newsletter"&gt;Join our newsletter&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/channel/UCFpTnXDNcBoXI4gqCDmegFA"&gt;YouTube channel for updates &amp;amp; tutorials&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.tigera.io/blog/?_sft_category=technical-blog"&gt;Technical Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.tigera.io/careers/"&gt;Careers&lt;/a&gt;: Passionate about open source? Join our team.&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>Tencent/WeKnora</title>
      <link>https://github.com/Tencent/WeKnora</link>
      <description>&lt;p&gt;LLM-powered framework for deep document understanding, semantic retrieval, and context-aware answers using RAG paradigm.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; 
 &lt;picture&gt; 
  &lt;img src="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/images/logo.png" alt="WeKnora Logo" height="120" /&gt; 
 &lt;/picture&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://weknora.weixin.qq.com" target="_blank"&gt; &lt;img alt="ÂÆòÊñπÁΩëÁ´ô" src="https://img.shields.io/badge/ÂÆòÊñπÁΩëÁ´ô-WeKnora-4e6b99" /&gt; &lt;/a&gt; &lt;a href="https://chatbot.weixin.qq.com" target="_blank"&gt; &lt;img alt="ÂæÆ‰ø°ÂØπËØùÂºÄÊîæÂπ≥Âè∞" src="https://img.shields.io/badge/ÂæÆ‰ø°ÂØπËØùÂºÄÊîæÂπ≥Âè∞-5ac725" /&gt; &lt;/a&gt; &lt;a href="https://github.com/Tencent/WeKnora/raw/main/LICENSE"&gt; &lt;img src="https://img.shields.io/badge/License-MIT-ffffff?labelColor=d4eaf7&amp;amp;color=2e6cc4" alt="License" /&gt; &lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/CHANGELOG.md"&gt; &lt;img alt="Version" src="https://img.shields.io/badge/version-0.1.3-2e6cc4?labelColor=d4eaf7" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; | &lt;b&gt;English&lt;/b&gt; | &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/README_CN.md"&gt;&lt;b&gt;ÁÆÄ‰Ωì‰∏≠Êñá&lt;/b&gt;&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/README_JA.md"&gt;&lt;b&gt;Êó•Êú¨Ë™û&lt;/b&gt;&lt;/a&gt; | &lt;/p&gt; 
&lt;p align="center"&gt; &lt;/p&gt;
&lt;h4 align="center"&gt; &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/#-overview"&gt;Overview&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/#-architecture"&gt;Architecture&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/#-key-features"&gt;Key Features&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/#-getting-started"&gt;Getting Started&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/#-api-reference"&gt;API Reference&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/#-developer-guide"&gt;Developer Guide&lt;/a&gt;&lt;/p&gt; &lt;/h4&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;h1&gt;üí° WeKnora - LLM-Powered Document Understanding &amp;amp; Retrieval Framework&lt;/h1&gt; 
&lt;h2&gt;üìå Overview&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://weknora.weixin.qq.com"&gt;&lt;strong&gt;WeKnora&lt;/strong&gt;&lt;/a&gt; is an LLM-powered framework designed for deep document understanding and semantic retrieval, especially for handling complex, heterogeneous documents.&lt;/p&gt; 
&lt;p&gt;It adopts a modular architecture that combines multimodal preprocessing, semantic vector indexing, intelligent retrieval, and large language model inference. At its core, WeKnora follows the &lt;strong&gt;RAG (Retrieval-Augmented Generation)&lt;/strong&gt; paradigm, enabling high-quality, context-aware answers by combining relevant document chunks with model reasoning.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Website:&lt;/strong&gt; &lt;a href="https://weknora.weixin.qq.com"&gt;https://weknora.weixin.qq.com&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üîí Security Notice&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Important:&lt;/strong&gt; Starting from v0.1.3, WeKnora includes login authentication functionality to enhance system security. For production deployments, we strongly recommend:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Deploy WeKnora services in internal/private network environments rather than public internet&lt;/li&gt; 
 &lt;li&gt;Avoid exposing the service directly to public networks to prevent potential information leakage&lt;/li&gt; 
 &lt;li&gt;Configure proper firewall rules and access controls for your deployment environment&lt;/li&gt; 
 &lt;li&gt;Regularly update to the latest version for security patches and improvements&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üèóÔ∏è Architecture&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/images/pipeline.jpg" alt="weknora-pipeline.png" /&gt;&lt;/p&gt; 
&lt;p&gt;WeKnora employs a modern modular design to build a complete document understanding and retrieval pipeline. The system primarily includes document parsing, vector processing, retrieval engine, and large model inference as core modules, with each component being flexibly configurable and extendable.&lt;/p&gt; 
&lt;h2&gt;üéØ Key Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;üîç Precise Understanding&lt;/strong&gt;: Structured content extraction from PDFs, Word documents, images and more into unified semantic views&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üß† Intelligent Reasoning&lt;/strong&gt;: Leverages LLMs to understand document context and user intent for accurate Q&amp;amp;A and multi-turn conversations&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üîß Flexible Extension&lt;/strong&gt;: All components from parsing and embedding to retrieval and generation are decoupled for easy customization&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;‚ö° Efficient Retrieval&lt;/strong&gt;: Hybrid retrieval strategies combining keywords, vectors, and knowledge graphs&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üéØ User-Friendly&lt;/strong&gt;: Intuitive web interface and standardized APIs for zero technical barriers&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üîí Secure &amp;amp; Controlled&lt;/strong&gt;: Support for local deployment and private cloud, ensuring complete data sovereignty&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üìä Application Scenarios&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Scenario&lt;/th&gt; 
   &lt;th&gt;Applications&lt;/th&gt; 
   &lt;th&gt;Core Value&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Enterprise Knowledge Management&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Internal document retrieval, policy Q&amp;amp;A, operation manual search&lt;/td&gt; 
   &lt;td&gt;Improve knowledge discovery efficiency, reduce training costs&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Academic Research Analysis&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Paper retrieval, research report analysis, scholarly material organization&lt;/td&gt; 
   &lt;td&gt;Accelerate literature review, assist research decisions&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Product Technical Support&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Product manual Q&amp;amp;A, technical documentation search, troubleshooting&lt;/td&gt; 
   &lt;td&gt;Enhance customer service quality, reduce support burden&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Legal &amp;amp; Compliance Review&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Contract clause retrieval, regulatory policy search, case analysis&lt;/td&gt; 
   &lt;td&gt;Improve compliance efficiency, reduce legal risks&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Medical Knowledge Assistance&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Medical literature retrieval, treatment guideline search, case analysis&lt;/td&gt; 
   &lt;td&gt;Support clinical decisions, improve diagnosis quality&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;üß© Feature Matrix&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Module&lt;/th&gt; 
   &lt;th&gt;Support&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Document Formats&lt;/td&gt; 
   &lt;td&gt;‚úÖ PDF / Word / Txt / Markdown / Images (with OCR / Caption)&lt;/td&gt; 
   &lt;td&gt;Support for structured and unstructured documents with text extraction from images&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Embedding Models&lt;/td&gt; 
   &lt;td&gt;‚úÖ Local models, BGE / GTE APIs, etc.&lt;/td&gt; 
   &lt;td&gt;Customizable embedding models, compatible with local deployment and cloud vector generation APIs&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Vector DB Integration&lt;/td&gt; 
   &lt;td&gt;‚úÖ PostgreSQL (pgvector), Elasticsearch&lt;/td&gt; 
   &lt;td&gt;Support for mainstream vector index backends, flexible switching for different retrieval scenarios&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Retrieval Strategies&lt;/td&gt; 
   &lt;td&gt;‚úÖ BM25 / Dense Retrieval / GraphRAG&lt;/td&gt; 
   &lt;td&gt;Support for sparse/dense recall and knowledge graph-enhanced retrieval with customizable retrieve-rerank-generate pipelines&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;LLM Integration&lt;/td&gt; 
   &lt;td&gt;‚úÖ Support for Qwen, DeepSeek, etc., with thinking/non-thinking mode switching&lt;/td&gt; 
   &lt;td&gt;Compatible with local models (e.g., via Ollama) or external API services with flexible inference configuration&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;QA Capabilities&lt;/td&gt; 
   &lt;td&gt;‚úÖ Context-aware, multi-turn dialogue, prompt templates&lt;/td&gt; 
   &lt;td&gt;Support for complex semantic modeling, instruction control and chain-of-thought Q&amp;amp;A with configurable prompts and context windows&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;E2E Testing&lt;/td&gt; 
   &lt;td&gt;‚úÖ Retrieval+generation process visualization and metric evaluation&lt;/td&gt; 
   &lt;td&gt;End-to-end testing tools for evaluating recall hit rates, answer coverage, BLEU/ROUGE and other metrics&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Deployment Modes&lt;/td&gt; 
   &lt;td&gt;‚úÖ Support for local deployment / Docker images&lt;/td&gt; 
   &lt;td&gt;Meets private, offline deployment and flexible operation requirements&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;User Interfaces&lt;/td&gt; 
   &lt;td&gt;‚úÖ Web UI + RESTful API&lt;/td&gt; 
   &lt;td&gt;Interactive interface and standard API endpoints, suitable for both developers and business users&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;üöÄ Getting Started&lt;/h2&gt; 
&lt;h3&gt;üõ† Prerequisites&lt;/h3&gt; 
&lt;p&gt;Make sure the following tools are installed on your system:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.docker.com/"&gt;Docker&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.docker.com/compose/"&gt;Docker Compose&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://git-scm.com/"&gt;Git&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üì¶ Installation&lt;/h3&gt; 
&lt;h4&gt;‚ë† Clone the repository&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Clone the main repository
git clone https://github.com/Tencent/WeKnora.git
cd WeKnora
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;‚ë° Configure environment variables&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Copy example env file
cp .env.example .env

# Edit .env and set required values
# All variables are documented in the .env.example comments
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;‚ë¢ Start the services&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Start all services (Ollama + backend containers)
./scripts/start_all.sh
# Or
make start-all
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;‚ë¢ Start the services (backup)&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Start ollama services (Optional)
ollama serve &amp;gt; /dev/null 2&amp;gt;&amp;amp;1 &amp;amp;

# Start the service
docker compose up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;‚ë£ Stop the services&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;./scripts/start_all.sh --stop
# Or
make stop-all
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;üåê Access Services&lt;/h3&gt; 
&lt;p&gt;Once started, services will be available at:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Web UI: &lt;code&gt;http://localhost&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Backend API: &lt;code&gt;http://localhost:8080&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Jaeger Tracing: &lt;code&gt;http://localhost:16686&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üîå Using WeChat Dialog Open Platform&lt;/h3&gt; 
&lt;p&gt;WeKnora serves as the core technology framework for the &lt;a href="https://chatbot.weixin.qq.com"&gt;WeChat Dialog Open Platform&lt;/a&gt;, providing a more convenient usage approach:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Zero-code Deployment&lt;/strong&gt;: Simply upload knowledge to quickly deploy intelligent Q&amp;amp;A services within the WeChat ecosystem, achieving an "ask and answer" experience&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Efficient Question Management&lt;/strong&gt;: Support for categorized management of high-frequency questions, with rich data tools to ensure accurate, reliable, and easily maintainable answers&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;WeChat Ecosystem Integration&lt;/strong&gt;: Through the WeChat Dialog Open Platform, WeKnora's intelligent Q&amp;amp;A capabilities can be seamlessly integrated into WeChat Official Accounts, Mini Programs, and other WeChat scenarios, enhancing user interaction experiences&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üîó Access WeKnora via MCP Server&lt;/h3&gt; 
&lt;h4&gt;1Ô∏è‚É£ Clone the repository&lt;/h4&gt; 
&lt;pre&gt;&lt;code&gt;git clone https://github.com/Tencent/WeKnora
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;2Ô∏è‚É£ Configure MCP Server&lt;/h4&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;It is recommended to directly refer to the &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/mcp-server/MCP_CONFIG.md"&gt;MCP Configuration Guide&lt;/a&gt; for configuration.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Configure the MCP client to connect to the server:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "mcpServers": {
    "weknora": {
      "args": [
        "path/to/WeKnora/mcp-server/run_server.py"
      ],
      "command": "python",
      "env":{
        "WEKNORA_API_KEY":"Enter your WeKnora instance, open developer tools, check the request header x-api-key starting with sk",
        "WEKNORA_BASE_URL":"http(s)://your-weknora-address/api/v1"
      }
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Run directly using stdio command:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;pip install weknora-mcp-server
python -m weknora-mcp-server
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;üîß Initialization Configuration Guide&lt;/h2&gt; 
&lt;p&gt;To help users quickly configure various models and reduce trial-and-error costs, we've improved the original configuration file initialization method by adding a Web UI interface for model configuration. Before using, please ensure the code is updated to the latest version. The specific steps are as follows: If this is your first time using this project, you can skip steps ‚ë†‚ë° and go directly to steps ‚ë¢‚ë£.&lt;/p&gt; 
&lt;h3&gt;‚ë† Stop the services&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;./scripts/start_all.sh --stop
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;‚ë° Clear existing data tables (recommended when no important data exists)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;make clean-db
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;‚ë¢ Compile and start services&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;./scripts/start_all.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;‚ë£ Access Web UI&lt;/h3&gt; 
&lt;p&gt;&lt;a href="http://localhost"&gt;http://localhost&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;On first access, it will automatically redirect to the initialization configuration page. After configuration is complete, it will automatically redirect to the knowledge base page. Please follow the page instructions to complete model configuration.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/images/config.png" alt="Configuration Page" /&gt;&lt;/p&gt; 
&lt;h2&gt;üì± Interface Showcase&lt;/h2&gt; 
&lt;h3&gt;Web UI Interface&lt;/h3&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td&gt;&lt;b&gt;Knowledge Upload&lt;/b&gt;&lt;br /&gt;&lt;img src="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/images/knowledges.png" alt="Knowledge Upload Interface" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;b&gt;Q&amp;amp;A Entry&lt;/b&gt;&lt;br /&gt;&lt;img src="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/images/qa.png" alt="Q&amp;amp;A Entry Interface" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td colspan="2"&gt;&lt;b&gt;Rich Text &amp;amp; Image Responses&lt;/b&gt;&lt;br /&gt;&lt;img src="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/images/answer.png" alt="Rich Answer Interface" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;Knowledge Base Management:&lt;/strong&gt; Support for dragging and dropping various documents, automatically identifying document structures and extracting core knowledge to establish indexes. The system clearly displays processing progress and document status, achieving efficient knowledge base management.&lt;/p&gt; 
&lt;h3&gt;Document Knowledge Graph&lt;/h3&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/images/graph2.png" alt="Knowledge Graph View 1" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/images/graph1.png" alt="Knowledge Graph View 2" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;p&gt;WeKnora supports transforming documents into knowledge graphs, displaying the relationships between different sections of the documents. Once the knowledge graph feature is enabled, the system analyzes and constructs an internal semantic association network that not only helps users understand document content but also provides structured support for indexing and retrieval, enhancing the relevance and breadth of search results.&lt;/p&gt; 
&lt;h3&gt;MCP Server Integration Effects&lt;/h3&gt; 
&lt;img width="950" height="2063" alt="MCP Server Integration Demo" src="https://github.com/user-attachments/assets/09111ec8-0489-415c-969d-aa3835778e14" /&gt; 
&lt;h2&gt;üìò API Reference&lt;/h2&gt; 
&lt;p&gt;Troubleshooting FAQ: &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/QA.md"&gt;Troubleshooting FAQ&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Detailed API documentation is available at: &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/API.md"&gt;API Docs&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üß≠ Developer Guide&lt;/h2&gt; 
&lt;h3&gt;üìÅ Directory Structure&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;WeKnora/
‚îú‚îÄ‚îÄ cmd/         # Main entry point
‚îú‚îÄ‚îÄ internal/    # Core business logic
‚îú‚îÄ‚îÄ config/      # Configuration files
‚îú‚îÄ‚îÄ migrations/  # DB migration scripts
‚îú‚îÄ‚îÄ scripts/     # Shell scripts
‚îú‚îÄ‚îÄ services/    # Microservice logic
‚îú‚îÄ‚îÄ frontend/    # Frontend app
‚îî‚îÄ‚îÄ docs/        # Project documentation
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;üîß Common Commands&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Wipe all data from DB (use with caution)
make clean-db
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;ü§ù Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome community contributions! For suggestions, bugs, or feature requests, please submit an &lt;a href="https://github.com/Tencent/WeKnora/issues"&gt;Issue&lt;/a&gt; or directly create a Pull Request.&lt;/p&gt; 
&lt;h3&gt;üéØ How to Contribute&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;üêõ &lt;strong&gt;Bug Fixes&lt;/strong&gt;: Discover and fix system defects&lt;/li&gt; 
 &lt;li&gt;‚ú® &lt;strong&gt;New Features&lt;/strong&gt;: Propose and implement new capabilities&lt;/li&gt; 
 &lt;li&gt;üìö &lt;strong&gt;Documentation&lt;/strong&gt;: Improve project documentation&lt;/li&gt; 
 &lt;li&gt;üß™ &lt;strong&gt;Test Cases&lt;/strong&gt;: Write unit and integration tests&lt;/li&gt; 
 &lt;li&gt;üé® &lt;strong&gt;UI/UX Enhancements&lt;/strong&gt;: Improve user interface and experience&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üìã Contribution Process&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Fork the project&lt;/strong&gt; to your GitHub account&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Create a feature branch&lt;/strong&gt; &lt;code&gt;git checkout -b feature/amazing-feature&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Commit changes&lt;/strong&gt; &lt;code&gt;git commit -m 'Add amazing feature'&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Push branch&lt;/strong&gt; &lt;code&gt;git push origin feature/amazing-feature&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Create a Pull Request&lt;/strong&gt; with detailed description of changes&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;üé® Code Standards&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Follow &lt;a href="https://github.com/golang/go/wiki/CodeReviewComments"&gt;Go Code Review Comments&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Format code using &lt;code&gt;gofmt&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Add necessary unit tests&lt;/li&gt; 
 &lt;li&gt;Update relevant documentation&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üìù Commit Guidelines&lt;/h3&gt; 
&lt;p&gt;Use &lt;a href="https://www.conventionalcommits.org/"&gt;Conventional Commits&lt;/a&gt; standard:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;feat: Add document batch upload functionality
fix: Resolve vector retrieval precision issue
docs: Update API documentation
test: Add retrieval engine test cases
refactor: Restructure document parsing module
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;üë• Contributors&lt;/h2&gt; 
&lt;p&gt;Thanks to these excellent contributors:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/Tencent/WeKnora/graphs/contributors"&gt;&lt;img src="https://contrib.rocks/image?repo=Tencent/WeKnora" alt="Contributors" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üìÑ License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/LICENSE"&gt;MIT License&lt;/a&gt;. You are free to use, modify, and distribute the code with proper attribution.&lt;/p&gt; 
&lt;h2&gt;üìà Project Statistics&lt;/h2&gt; 
&lt;a href="https://www.star-history.com/#Tencent/WeKnora&amp;amp;type=date&amp;amp;legend=top-left"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://api.star-history.com/svg?repos=Tencent/WeKnora&amp;amp;type=date&amp;amp;theme=dark&amp;amp;legend=top-left" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://api.star-history.com/svg?repos=Tencent/WeKnora&amp;amp;type=date&amp;amp;legend=top-left" /&gt; 
  &lt;img alt="Star History Chart" src="https://api.star-history.com/svg?repos=Tencent/WeKnora&amp;amp;type=date&amp;amp;legend=top-left" /&gt; 
 &lt;/picture&gt; &lt;/a&gt;</description>
    </item>
    
    <item>
      <title>raghavyuva/nixopus</title>
      <link>https://github.com/raghavyuva/nixopus</link>
      <description>&lt;p&gt;Open Source Alternative to vercel, heroku, netlify with simplified workflows&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;a href="https://nixopus.com"&gt;&lt;img width="1800" height="520" alt="Heading(4)" src="https://github.com/user-attachments/assets/e103a9df-7abf-4f78-b75a-221331231247" /&gt;&lt;/a&gt; 
&lt;/div&gt; 
&lt;p align="center"&gt; Open Source alternative to vercel, heroku, netlify with Terminal integration, and Self Hosting capabilities. &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://nixopus.com"&gt;&lt;b&gt;Website&lt;/b&gt;&lt;/a&gt; ‚Ä¢ &lt;a href="https://docs.nixopus.com"&gt;&lt;b&gt;Documentation&lt;/b&gt;&lt;/a&gt; ‚Ä¢ &lt;a href="https://docs.nixopus.com/blog/"&gt;&lt;b&gt;Blog&lt;/b&gt;&lt;/a&gt; ‚Ä¢ &lt;a href="https://discord.gg/skdcq39Wpv"&gt;&lt;b&gt;Discord&lt;/b&gt;&lt;/a&gt; ‚Ä¢ &lt;a href="https://github.com/raghavyuva/nixopus/discussions/262"&gt;&lt;b&gt;Roadmap&lt;/b&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;img width="1210" height="764" alt="image" src="https://raw.githubusercontent.com/raghavyuva/nixopus/master/assets/nixopus_dashboard.png" /&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;‚ö†Ô∏è &lt;strong&gt;Important Note&lt;/strong&gt;: Nixopus is currently in alpha/pre-release stage and is not yet ready for production use. While you're welcome to try it out, we recommend waiting for the beta or stable release before using it in production environments. The platform is still undergoing testing and development.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h1&gt;Features&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Deploy apps with one click.&lt;/strong&gt; No config files, no SSH commands.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Manage files in your browser.&lt;/strong&gt; Drag, drop, edit. Like any file manager.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Built-in terminal.&lt;/strong&gt; Access your server without leaving the page.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Real-time monitoring.&lt;/strong&gt; See CPU, RAM, disk usage at a glance.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Auto SSL certificates.&lt;/strong&gt; Your domains get HTTPS automatically.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;GitHub integration.&lt;/strong&gt; Push code ‚Üí auto deploy.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Proxy management.&lt;/strong&gt; Route traffic with Caddy reverse proxy.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Smart alerts.&lt;/strong&gt; Get notified via Slack, Discord, or email when something's wrong.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Installation &amp;amp; Quick Start&lt;/h2&gt; 
&lt;p&gt;This section will help you set up Nixopus on your VPS quickly.&lt;/p&gt; 
&lt;h3&gt;Install Nixopus&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;To get started without domain names, and to try out over ip:port deployment:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -sSL https://install.nixopus.com | bash
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;To install only the CLI tool without running &lt;code&gt;nixopus install&lt;/code&gt;:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -sSL https://install.nixopus.com | bash -s -- --skip-nixopus-install
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Optional Parameters&lt;/h4&gt; 
&lt;p&gt;You can customize your installation by providing the following optional parameters:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;--api-domain&lt;/code&gt; or &lt;code&gt;-ad&lt;/code&gt;: Specify the domain where the Nixopus API will be accessible (e.g., &lt;code&gt;nixopusapi.example.tld&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--view-domain&lt;/code&gt; or &lt;code&gt;-vd&lt;/code&gt;: Specify the domain where the Nixopus app will be accessible (e.g., &lt;code&gt;nixopus.example.tld&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--verbose&lt;/code&gt; or &lt;code&gt;-v&lt;/code&gt;: Show more details while installing&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--timeout&lt;/code&gt; or &lt;code&gt;-t&lt;/code&gt;: Set timeout for each step (default: 300 seconds)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--force&lt;/code&gt; or &lt;code&gt;-f&lt;/code&gt;: Replace files if they already exist&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--dry-run&lt;/code&gt; or &lt;code&gt;-d&lt;/code&gt;: See what would happen without making changes&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--config-file&lt;/code&gt; or &lt;code&gt;-c&lt;/code&gt;: Path to custom config file (defaults to built-in &lt;a href="https://raw.githubusercontent.com/raghavyuva/nixopus/refs/heads/master/helpers/config.prod.yaml"&gt;&lt;code&gt;config.prod.yaml&lt;/code&gt;&lt;/a&gt;)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Example with optional parameters:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;nixopus install \
  --api-domain nixopusapi.example.tld \
  --view-domain nixopus.example.tld \
  --verbose \
  --timeout 600
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can also install the CLI and run &lt;code&gt;nixopus install&lt;/code&gt; with options in a single command, refer &lt;a href="https://docs.nixopus.com/install/#installation-options"&gt;installation documentation&lt;/a&gt; for more details on options&lt;/p&gt; 
&lt;h2&gt;About the Name&lt;/h2&gt; 
&lt;p&gt;Nixopus is derived from the combination of "octopus" and the Linux penguin (Tux). While the name might suggest a connection to &lt;a href="https://nixos.org/"&gt;NixOS&lt;/a&gt;, Nixopus is an independent project with no direct relation to NixOS or its ecosystem.&lt;/p&gt; 
&lt;h2&gt;Contributors&lt;/h2&gt; 
&lt;a href="https://github.com/raghavyuva/nixopus/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=raghavyuva/nixopus" alt="Nixopus project contributors" /&gt; &lt;/a&gt;</description>
    </item>
    
    <item>
      <title>weaviate/weaviate</title>
      <link>https://github.com/weaviate/weaviate</link>
      <description>&lt;p&gt;Weaviate is an open-source vector database that stores both objects and vectors, allowing for the combination of vector search with structured filtering with the fault tolerance and scalability of a cloud-native database‚Äã.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Weaviate &lt;img alt="Weaviate logo" src="https://weaviate.io/img/site/weaviate-logo-light.png" width="148" align="right" /&gt;&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://github.com/weaviate/weaviate"&gt;&lt;img src="https://img.shields.io/github/stars/weaviate/weaviate?style=social" alt="GitHub Repo stars" /&gt;&lt;/a&gt; &lt;a href="https://pkg.go.dev/github.com/weaviate/weaviate"&gt;&lt;img src="https://pkg.go.dev/badge/github.com/weaviate/weaviate.svg?sanitize=true" alt="Go Reference" /&gt;&lt;/a&gt; &lt;a href="https://github.com/weaviate/weaviate/actions/workflows/.github/workflows/pull_requests.yaml"&gt;&lt;img src="https://github.com/weaviate/weaviate/actions/workflows/.github/workflows/pull_requests.yaml/badge.svg?branch=main" alt="Build Status" /&gt;&lt;/a&gt; &lt;a href="https://goreportcard.com/report/github.com/weaviate/weaviate"&gt;&lt;img src="https://goreportcard.com/badge/github.com/weaviate/weaviate" alt="Go Report Card" /&gt;&lt;/a&gt; &lt;a href="https://codecov.io/gh/weaviate/weaviate"&gt;&lt;img src="https://codecov.io/gh/weaviate/weaviate/branch/main/graph/badge.svg?sanitize=true" alt="Coverage Status" /&gt;&lt;/a&gt; &lt;a href="https://weaviate.io/slack"&gt;&lt;img src="https://img.shields.io/badge/slack--channel-blue?logo=slack" alt="Slack" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Weaviate&lt;/strong&gt; is an open-source, cloud-native vector database that stores both objects and vectors, enabling semantic search at scale. It combines vector similarity search with keyword filtering, retrieval-augmented generation (RAG), and reranking in a single query interface. Common use cases include RAG systems, semantic and image search, recommendation engines, chatbots, and content classification.&lt;/p&gt; 
&lt;p&gt;Weaviate supports two approaches to store vectors: automatic vectorization at import using &lt;a href="https://docs.weaviate.io/weaviate/model-providers"&gt;integrated models&lt;/a&gt; (OpenAI, Cohere, HuggingFace, and others) or direct import of &lt;a href="https://docs.weaviate.io/weaviate/starter-guides/custom-vectors"&gt;pre-computed vector embeddings&lt;/a&gt;. Production deployments benefit from built-in multi-tenancy, replication, RBAC authorization, and &lt;a href="https://raw.githubusercontent.com/weaviate/weaviate/main/#weaviate-features"&gt;many other features&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;To get started quickly, have a look at one of these tutorials:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.weaviate.io/weaviate/quickstart"&gt;Quickstart - Weaviate Cloud&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.weaviate.io/weaviate/quickstart/local"&gt;Quickstart - local Docker instance&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;Weaviate offers multiple installation and deployment options:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.weaviate.io/deploy/installation-guides/docker-installation"&gt;Docker&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.weaviate.io/deploy/installation-guides/k8s-installation"&gt;Kubernetes&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://console.weaviate.cloud"&gt;Weaviate Cloud&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;See the &lt;a href="https://docs.weaviate.io/deploy"&gt;installation docs&lt;/a&gt; for more deployment options, such as &lt;a href="https://docs.weaviate.io/deploy/installation-guides/aws-marketplace"&gt;AWS&lt;/a&gt; and &lt;a href="https://docs.weaviate.io/deploy/installation-guides/gcp-marketplace"&gt;GCP&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Getting started&lt;/h2&gt; 
&lt;p&gt;You can easily start Weaviate and a local vector embedding model with &lt;a href="https://docs.docker.com/desktop/"&gt;Docker&lt;/a&gt;. Create a &lt;code&gt;docker-compose.yml&lt;/code&gt; file:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yml"&gt;services:
  weaviate:
    image: cr.weaviate.io/semitechnologies/weaviate:1.32.2
    ports:
      - "8080:8080"
      - "50051:50051"
    environment:
      ENABLE_MODULES: text2vec-model2vec
      MODEL2VEC_INFERENCE_API: http://text2vec-model2vec:8080

  # A lightweight embedding model that will generate vectors from objects during import
  text2vec-model2vec:
    image: cr.weaviate.io/semitechnologies/model2vec-inference:minishlab-potion-base-32M
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Start Weaviate and the embedding service with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker compose up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Install the Python client (or use another &lt;a href="https://raw.githubusercontent.com/weaviate/weaviate/main/#client-libraries-and-apis"&gt;client library&lt;/a&gt;):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install -U weaviate-client
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The following Python example shows how easy it is to populate a Weaviate database with data, create vector embeddings and perform semantic search:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import weaviate
from weaviate.classes.config import Configure, DataType, Property

# Connect to Weaviate
client = weaviate.connect_to_local()

# Create a collection
client.collections.create(
    name="Article",
    properties=[Property(name="content", data_type=DataType.TEXT)],
    vector_config=Configure.Vectors.text2vec_model2vec(),  # Use a vectorizer to generate embeddings during import
    # vector_config=Configure.Vectors.self_provided()  # If you want to import your own pre-generated embeddings
)

# Insert objects and generate embeddings
articles = client.collections.get("Article")
articles.data.insert_many(
    [
        {"content": "Vector databases enable semantic search"},
        {"content": "Machine learning models generate embeddings"},
        {"content": "Weaviate supports hybrid search capabilities"},
    ]
)

# Perform semantic search
results = articles.query.near_text(query="Search objects by meaning", limit=1)
print(results.objects[0])

client.close()
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This example uses the &lt;code&gt;Model2Vec&lt;/code&gt; vectorizer, but you can choose any other &lt;a href="https://docs.weaviate.io/weaviate/model-providers"&gt;embedding model provider&lt;/a&gt; or &lt;a href="https://docs.weaviate.io/weaviate/starter-guides/custom-vectors"&gt;bring your own pre-generated vectors&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Client libraries and APIs&lt;/h2&gt; 
&lt;p&gt;Weaviate provides client libraries for several programming languages:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.weaviate.io/weaviate/client-libraries/python"&gt;Python&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.weaviate.io/weaviate/client-libraries/typescript"&gt;JavaScript/TypeScript&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.weaviate.io/weaviate/client-libraries/java"&gt;Java&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.weaviate.io/weaviate/client-libraries/go"&gt;Go&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;C# (üöß Coming soon üöß)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;There are also additional &lt;a href="https://docs.weaviate.io/weaviate/client-libraries/community"&gt;community-maintained libraries&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Weaviate exposes &lt;a href="https://docs.weaviate.io/weaviate/api/rest"&gt;REST API&lt;/a&gt;, &lt;a href="https://docs.weaviate.io/weaviate/api/grpc"&gt;gRPC API&lt;/a&gt;, and &lt;a href="https://docs.weaviate.io/weaviate/api/graphql"&gt;GraphQL API&lt;/a&gt; to communicate with the database server.&lt;/p&gt; 
&lt;h2&gt;Weaviate features&lt;/h2&gt; 
&lt;p&gt;These features enable you to build AI-powered applications:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;‚ö° Fast Search Performance&lt;/strong&gt;: Perform complex semantic &lt;a href="https://docs.weaviate.io/weaviate/search/similarity"&gt;searches&lt;/a&gt; over billions of vectors in milliseconds. Weaviate's architecture is built in Go for speed and reliability, ensuring your AI applications are highly responsive even under heavy load. See our &lt;a href="https://docs.weaviate.io/weaviate/benchmarks/ann"&gt;ANN benchmarks&lt;/a&gt; for more info.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;üîå Flexible Vectorization&lt;/strong&gt;: Seamlessly vectorize data at import time with &lt;a href="https://docs.weaviate.io/weaviate/model-providers"&gt;integrated vectorizers&lt;/a&gt; from OpenAI, Cohere, HuggingFace, Google, and more. Or you can import &lt;a href="https://docs.weaviate.io/weaviate/starter-guides/custom-vectors"&gt;your own vector embeddings&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;üîç Advanced Hybrid &amp;amp; Image Search&lt;/strong&gt;: Combine the power of semantic search with traditional &lt;a href="https://docs.weaviate.io/weaviate/search/bm25"&gt;keyword (BM25) search&lt;/a&gt;, &lt;a href="https://docs.weaviate.io/weaviate/search/image"&gt;image search&lt;/a&gt; and &lt;a href="https://docs.weaviate.io/weaviate/search/filters"&gt;advanced filtering&lt;/a&gt; to get the best results with a single API call.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;ü§ñ Integrated RAG &amp;amp; Reranking&lt;/strong&gt;: Go beyond simple retrieval with built-in &lt;a href="https://docs.weaviate.io/weaviate/search/generative"&gt;generative search (RAG)&lt;/a&gt; and &lt;a href="https://docs.weaviate.io/weaviate/search/rerank"&gt;reranking&lt;/a&gt; capabilities. Power sophisticated Q&amp;amp;A systems, chatbots, and summarizers directly from your database without additional tooling.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;üìà Production-Ready &amp;amp; Scalable&lt;/strong&gt;: Weaviate is built for mission-critical applications. Go from rapid prototyping to production at scale with native support for &lt;a href="https://docs.weaviate.io/deploy/configuration/horizontal-scaling"&gt;horizontal scaling&lt;/a&gt;, &lt;a href="https://docs.weaviate.io/weaviate/manage-collections/multi-tenancy"&gt;multi-tenancy&lt;/a&gt;, &lt;a href="https://docs.weaviate.io/deploy/configuration/replication"&gt;replication&lt;/a&gt;, and fine-grained &lt;a href="https://docs.weaviate.io/weaviate/configuration/rbac"&gt;role-based access control (RBAC)&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;üí∞ Cost-Efficient Operations&lt;/strong&gt;: Radically lower resource consumption and operational costs with built-in &lt;a href="https://docs.weaviate.io/weaviate/configuration/compression"&gt;vector compression&lt;/a&gt;. Vector quantization and multi-vector encoding reduce memory usage with minimal impact on search performance.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For a complete list of all functionalities, visit the &lt;a href="https://docs.weaviate.io"&gt;official Weaviate documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Useful resources&lt;/h2&gt; 
&lt;h3&gt;Demo projects &amp;amp; recipes&lt;/h3&gt; 
&lt;p&gt;These demos are working applications that highlight some of Weaviate's capabilities. Their source code is available on GitHub.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://elysia.weaviate.io"&gt;Elysia&lt;/a&gt; (&lt;a href="https://github.com/weaviate/elysia"&gt;GitHub&lt;/a&gt;): Elysia is a decision tree based agentic system which intelligently decides what tools to use, what results have been obtained, whether it should continue the process or whether its goal has been completed.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://verba.weaviate.io"&gt;Verba&lt;/a&gt; (&lt;a href="https://github.com/weaviate/verba"&gt;GitHub&lt;/a&gt;): A community-driven open-source application designed to offer an end-to-end, streamlined, and user-friendly interface for Retrieval-Augmented Generation (RAG) out of the box.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://healthsearch.weaviate.io"&gt;Healthsearch&lt;/a&gt; (&lt;a href="https://github.com/weaviate/healthsearch-demo"&gt;GitHub&lt;/a&gt;): An open-source project aimed at showcasing the potential of leveraging user-written reviews and queries to retrieve supplement products based on specific health effects.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://awesome-moviate.weaviate.io/"&gt;Awesome-Moviate&lt;/a&gt; (&lt;a href="https://github.com/weaviate-tutorials/awesome-moviate"&gt;GitHub&lt;/a&gt;): A movie search and recommendation engine that allows keyword-based (BM25), semantic, and hybrid searches.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;We also maintain extensive repositories of &lt;strong&gt;Jupyter Notebooks&lt;/strong&gt; and &lt;strong&gt;TypeScript code snippets&lt;/strong&gt; that cover how to use Weaviate features and integrations:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/weaviate/recipes/"&gt;Weaviate Python Recipes&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/weaviate/recipes-ts/"&gt;Weaviate TypeScript Recipes&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Blog posts&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://weaviate.io/blog/what-is-a-vector-database"&gt;What is a Vector Database&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://weaviate.io/blog/vector-search-explained"&gt;What is Vector Search&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://weaviate.io/blog/hybrid-search-explained"&gt;What is Hybrid Search&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://weaviate.io/blog/how-to-choose-an-embedding-model"&gt;How to Choose an Embedding Model&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://weaviate.io/blog/introduction-to-rag"&gt;What is RAG&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://weaviate.io/blog/rag-evaluation"&gt;RAG Evaluation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://weaviate.io/blog/advanced-rag"&gt;Advanced RAG Techniques&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://weaviate.io/blog/multimodal-rag"&gt;What is Multimodal RAG&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://weaviate.io/blog/what-is-agentic-rag"&gt;What is Agentic RAG&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://weaviate.io/blog/graph-rag"&gt;What is Graph RAG&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://weaviate.io/blog/late-interaction-overview"&gt;Overview of Late Interaction Models&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Integrations&lt;/h3&gt; 
&lt;p&gt;Weaviate integrates with many external services:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Category&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Integrations&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;&lt;a href="https://docs.weaviate.io/integrations/cloud-hyperscalers"&gt;Cloud Hyperscalers&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Large-scale computing and storage&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://docs.weaviate.io/integrations/cloud-hyperscalers/aws"&gt;AWS&lt;/a&gt;, &lt;a href="https://docs.weaviate.io/integrations/cloud-hyperscalers/google"&gt;Google&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;&lt;a href="https://docs.weaviate.io/integrations/compute-infrastructure"&gt;Compute Infrastructure&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Run and scale containerized applications&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://docs.weaviate.io/integrations/compute-infrastructure/modal"&gt;Modal&lt;/a&gt;, &lt;a href="https://docs.weaviate.io/integrations/compute-infrastructure/replicate"&gt;Replicate&lt;/a&gt;, &lt;a href="https://docs.weaviate.io/integrations/compute-infrastructure/replicated"&gt;Replicated&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;&lt;a href="https://docs.weaviate.io/integrations/data-platforms"&gt;Data Platforms&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Data ingestion and web scraping&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://docs.weaviate.io/integrations/data-platforms/airbyte"&gt;Airbyte&lt;/a&gt;, &lt;a href="https://docs.weaviate.io/integrations/data-platforms/aryn"&gt;Aryn&lt;/a&gt;, &lt;a href="https://docs.weaviate.io/integrations/data-platforms/boomi"&gt;Boomi&lt;/a&gt;, &lt;a href="https://docs.weaviate.io/integrations/data-platforms/box"&gt;Box&lt;/a&gt;, &lt;a href="https://docs.weaviate.io/integrations/data-platforms/confluent"&gt;Confluent&lt;/a&gt;, &lt;a href="https://docs.weaviate.io/integrations/data-platforms/astronomer"&gt;Astronomer&lt;/a&gt;, &lt;a href="https://docs.weaviate.io/integrations/data-platforms/context-data"&gt;Context Data&lt;/a&gt;, &lt;a href="https://docs.weaviate.io/integrations/data-platforms/databricks"&gt;Databricks&lt;/a&gt;, &lt;a href="https://docs.weaviate.io/integrations/data-platforms/firecrawl"&gt;Firecrawl&lt;/a&gt;, &lt;a href="https://docs.weaviate.io/integrations/data-platforms/ibm"&gt;IBM&lt;/a&gt;, &lt;a href="https://docs.weaviate.io/integrations/data-platforms/unstructured"&gt;Unstructured&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;&lt;a href="https://docs.weaviate.io/integrations/llm-agent-frameworks"&gt;LLM and Agent Frameworks&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Build agents and generative AI applications&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://docs.weaviate.io/integrations/llm-agent-frameworks/agno"&gt;Agno&lt;/a&gt;, &lt;a href="https://docs.weaviate.io/integrations/llm-agent-frameworks/composio"&gt;Composio&lt;/a&gt;, &lt;a href="https://docs.weaviate.io/integrations/llm-agent-frameworks/crewai"&gt;CrewAI&lt;/a&gt;, &lt;a href="https://docs.weaviate.io/integrations/llm-agent-frameworks/dspy"&gt;DSPy&lt;/a&gt;, &lt;a href="https://docs.weaviate.io/integrations/llm-agent-frameworks/dynamiq"&gt;Dynamiq&lt;/a&gt;, &lt;a href="https://docs.weaviate.io/integrations/llm-agent-frameworks/haystack"&gt;Haystack&lt;/a&gt;, &lt;a href="https://docs.weaviate.io/integrations/llm-agent-frameworks/langchain"&gt;LangChain&lt;/a&gt;, &lt;a href="https://docs.weaviate.io/integrations/llm-agent-frameworks/llamaindex"&gt;LlamaIndex&lt;/a&gt;, &lt;a href="https://docs.weaviate.io/integrations/llm-agent-frameworks/n8n"&gt;N8n&lt;/a&gt;, &lt;a href="https://docs.weaviate.io/integrations/llm-agent-frameworks/semantic-kernel"&gt;Semantic Kernel&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;&lt;a href="https://docs.weaviate.io/integrations/operations"&gt;Operations&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Tools for monitoring and analyzing generative AI workflows&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://docs.weaviate.io/integrations/operations/aimon"&gt;AIMon&lt;/a&gt;, &lt;a href="https://docs.weaviate.io/integrations/operations/arize"&gt;Arize&lt;/a&gt;, &lt;a href="https://docs.weaviate.io/integrations/operations/cleanlab"&gt;Cleanlab&lt;/a&gt;, &lt;a href="https://docs.weaviate.io/integrations/operations/comet"&gt;Comet&lt;/a&gt;, &lt;a href="https://docs.weaviate.io/integrations/operations/deepeval"&gt;DeepEval&lt;/a&gt;, &lt;a href="https://docs.weaviate.io/integrations/operations/langtrace"&gt;Langtrace&lt;/a&gt;, &lt;a href="https://docs.weaviate.io/integrations/operations/langwatch"&gt;LangWatch&lt;/a&gt;, &lt;a href="https://docs.weaviate.io/integrations/operations/nomic"&gt;Nomic&lt;/a&gt;, &lt;a href="https://docs.weaviate.io/integrations/operations/patronus"&gt;Patronus AI&lt;/a&gt;, &lt;a href="https://docs.weaviate.io/integrations/operations/ragas"&gt;Ragas&lt;/a&gt;, &lt;a href="https://docs.weaviate.io/integrations/operations/trulens"&gt;TruLens&lt;/a&gt;, &lt;a href="https://docs.weaviate.io/integrations/operations/wandb"&gt;Weights &amp;amp; Biases&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome and appreciate contributions! Please see our &lt;a href="https://docs.weaviate.io/contributor-guide"&gt;Contributor guide&lt;/a&gt; for the development setup, code style guidelines, testing requirements and the pull request process.&lt;/p&gt; 
&lt;p&gt;Join our &lt;a href="https://weaviate.io/slack"&gt;Slack community&lt;/a&gt; or &lt;a href="https://forum.weaviate.io/"&gt;Community forum&lt;/a&gt; to discuss ideas and get help.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;BSD 3-Clause License. See &lt;a href="https://raw.githubusercontent.com/weaviate/weaviate/main/LICENSE"&gt;LICENSE&lt;/a&gt; for details.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>aaPanel/BillionMail</title>
      <link>https://github.com/aaPanel/BillionMail</link>
      <description>&lt;p&gt;BillionMail gives you open-source MailServer, NewsLetter, Email Marketing ‚Äî fully self-hosted, dev-friendly, and free from monthly fees. Join the discord: https://discord.gg/asfXzBUhZr&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;a name="readme-top"&gt;&lt;/a&gt; 
 &lt;h1&gt;&lt;a href="https://www.billionmail.com/" target="_blank"&gt;BillionMail üìß&lt;/a&gt;&lt;/h1&gt; 
 &lt;h2&gt;An Open-Source MailServer, NewsLetter, Email Marketing Solution for Smarter Campaigns&lt;/h2&gt; 
 &lt;p&gt;&lt;a href="https://www.gnu.org/licenses/agpl-3.0.html"&gt;&lt;img src="https://img.shields.io/github/license/aaPanel/BillionMail" alt="" /&gt;&lt;/a&gt; &lt;a href="https://www.billionmail.com/"&gt;&lt;img src="https://img.shields.io/badge/documentation-148F76" alt="" /&gt;&lt;/a&gt; &lt;a href="https://github.com/aaPanel/BillionMail/releases/latest"&gt;&lt;img src="https://img.shields.io/github/v/release/aaPanel/BillionMail" alt="" /&gt;&lt;/a&gt; &lt;a href="https://github.com/aaPanel/BillionMail"&gt;&lt;img src="https://img.shields.io/github/stars/aaPanel/BillionMail?color=%231890FF&amp;amp;style=flat-square%C2%A0%C2%A0%C2%A0" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;English | &lt;a href="https://raw.githubusercontent.com/aaPanel/BillionMail/dev/README-zh_CN.md"&gt;ÁÆÄ‰Ωì‰∏≠Êñá&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/aaPanel/BillionMail/dev/README-ja.md"&gt;Êó•Êú¨Ë™û&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/aaPanel/BillionMail/dev/README-ja.md"&gt;T√ºrk√ße&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;br /&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://trendshift.io/repositories/13842" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/13842" alt="aaPanel%2FBillionMail | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt; 
&lt;/div&gt; 
&lt;h2&gt;What is BillionMail?&lt;/h2&gt; 
&lt;p&gt;BillionMail is a &lt;strong&gt;future open-source Mail server, Email marketing platform&lt;/strong&gt; designed to help businesses and individuals manage their email campaigns with ease. Whether you're sending newsletters, promotional emails, or transactional messages, this tool will provide &lt;strong&gt;full control&lt;/strong&gt; over your email marketing efforts. With features like &lt;strong&gt;advanced analytics&lt;/strong&gt;, and &lt;strong&gt;customer management&lt;/strong&gt;, you'll be able to create, send, and track emails like a pro.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://www.billionmail.com/home.png?v1" alt="BillionMail Banner" /&gt;&lt;/p&gt; 
&lt;h1&gt;Just 3 steps to send a billion emails!&lt;/h1&gt; 
&lt;p&gt;&lt;strong&gt;Billion emails. Any business. Guaranteed.&lt;/strong&gt;&lt;/p&gt; 
&lt;h3&gt;Step 1Ô∏è‚É£ Install BillionMail:&lt;/h3&gt; 
&lt;p&gt;‚úÖ It takes &lt;strong&gt;only 8Ô∏è‚É£ minutes&lt;/strong&gt; from installation to &lt;strong&gt;‚úÖ successful email sending&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;cd /opt &amp;amp;&amp;amp; git clone https://github.com/aaPanel/BillionMail &amp;amp;&amp;amp; cd BillionMail &amp;amp;&amp;amp; bash install.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Step 2Ô∏è‚É£: Connect Your Domain&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Add the sending domain&lt;/li&gt; 
 &lt;li&gt;Verify DNS records&lt;/li&gt; 
 &lt;li&gt;Auto-enable free SSL&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Step 3Ô∏è‚É£: Build Your Campaign&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Write or paste your email&lt;/li&gt; 
 &lt;li&gt;Choose list &amp;amp; tags&lt;/li&gt; 
 &lt;li&gt;Set send time or send now&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://www.youtube.com/embed/UHgxZa_9jGs?si=0-f1B5hDtcWImvQv" target="_blank"&gt; &lt;img src="https://img.youtube.com/vi/UHgxZa_9jGs/maxresdefault.jpg" alt="" width="80%" /&gt; &lt;br /&gt; &lt;img src="https://www.iconfinder.com/icons/317714/download/png/16" alt="YouTube" width="16" /&gt; &lt;b&gt;Watch on Youtube&lt;/b&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;h2&gt;Other installation methods&lt;/h2&gt; 
&lt;h3&gt;One-click installation on aaPanel&lt;/h3&gt; 
&lt;p&gt;üëâ &lt;a href="https://www.aapanel.com/new/download.html"&gt;https://www.aapanel.com/new/download.html&lt;/a&gt; (Log in to ‚úÖaaPanel --&amp;gt; üê≥Docker --&amp;gt; 1Ô∏è‚É£OneClick install)&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Docker&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;cd /opt &amp;amp;&amp;amp; git clone https://github.com/aaPanel/BillionMail &amp;amp;&amp;amp; cd BillionMail &amp;amp;&amp;amp; cp env_init .env &amp;amp;&amp;amp; docker compose up -d || docker-compose up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Management script&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Management help&lt;/p&gt; &lt;p&gt;&lt;code&gt;bm help&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;View Login default info&lt;/p&gt; &lt;p&gt;&lt;code&gt;bm default&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Show domain DNS record&lt;/p&gt; &lt;p&gt;&lt;code&gt;bm show-record&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Update BillionMail&lt;/p&gt; &lt;p&gt;&lt;code&gt;bm update&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Live Demo&lt;/h2&gt; 
&lt;p&gt;BillionMail Demo: &lt;a href="https://demo.billionmail.com/billionmail"&gt;https://demo.billionmail.com/billionmail&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Username: &lt;code&gt;billionmail&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;Password: &lt;code&gt;billionmail&lt;/code&gt;&lt;/p&gt; 
&lt;h2&gt;WebMail&lt;/h2&gt; 
&lt;p&gt;BillionMail has integrated &lt;strong&gt;RoundCube&lt;/strong&gt;, you can access WebMail via &lt;code&gt;/roundcube/&lt;/code&gt;.&lt;/p&gt; 
&lt;h2&gt;Why BillionMail?&lt;/h2&gt; 
&lt;p&gt;Most email marketing platforms are either &lt;strong&gt;expensive&lt;/strong&gt;, &lt;strong&gt;closed-source&lt;/strong&gt;, or &lt;strong&gt;lack essential features&lt;/strong&gt;. BillionMail aims to be different:&lt;/p&gt; 
&lt;p&gt;‚úÖ &lt;strong&gt;Fully Open-Source&lt;/strong&gt; ‚Äì No hidden costs, no vendor lock-in.&lt;br /&gt; üìä &lt;strong&gt;Advanced Analytics&lt;/strong&gt; ‚Äì Track email delivery, open rates, click-through rates, and more.&lt;br /&gt; üìß &lt;strong&gt;Unlimited Sending&lt;/strong&gt; ‚Äì No restrictions on the number of emails you can send.&lt;br /&gt; üé® &lt;strong&gt;Customizable Templates&lt;/strong&gt; ‚Äì Custom professional marketing templates for reuse. üîí &lt;strong&gt;Privacy-First&lt;/strong&gt; ‚Äì Your data stays with you, no third-party tracking.&lt;br /&gt; üöÄ &lt;strong&gt;Self-Hosted&lt;/strong&gt; ‚Äì Run it on your own server for complete control.&lt;/p&gt; 
&lt;h2&gt;How You Can Help üåü&lt;/h2&gt; 
&lt;p&gt;BillionMail is a &lt;strong&gt;community-driven project&lt;/strong&gt;, and we need your support to get started! Here's how you can help:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Star This Repository&lt;/strong&gt;: Show your interest by starring this repo.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Spread the Word&lt;/strong&gt;: Share BillionMail with your network‚Äîdevelopers, marketers, and open-source enthusiasts.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Share Feedback&lt;/strong&gt;: Let us know what features you'd like to see in BillionMail by opening an issue or joining the discussion.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Contribute&lt;/strong&gt;: Once development begins, we'll welcome contributions from the community. Stay tuned for updates!&lt;/li&gt; 
&lt;/ol&gt; 
&lt;hr /&gt; 
&lt;p&gt;üìß &lt;strong&gt;BillionMail ‚Äì The Future of Open-Source Email Marketing.&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;Issues&lt;/h2&gt; 
&lt;p&gt;If you encounter any issues or have feature requests, please &lt;a href="https://github.com/aaPanel/BillionMail/issues"&gt;open an issue&lt;/a&gt;. Be sure to include:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;A clear description of the problem or request.&lt;/li&gt; 
 &lt;li&gt;Steps to reproduce the issue (if applicable).&lt;/li&gt; 
 &lt;li&gt;Screenshots or error logs (if applicable).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Install Now:&lt;/h2&gt; 
&lt;p&gt;‚úÖIt takes &lt;strong&gt;only 8 minutes&lt;/strong&gt; from installation to &lt;strong&gt;successful email sending&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;cd /opt &amp;amp;&amp;amp; git clone https://github.com/aaPanel/BillionMail &amp;amp;&amp;amp; cd BillionMail &amp;amp;&amp;amp; bash install.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Install with Docker:&lt;/strong&gt; (Please install Docker and docker-compose-plugin manually, and modify .env file)&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;cd /opt &amp;amp;&amp;amp; git clone https://github.com/aaPanel/BillionMail &amp;amp;&amp;amp; cd BillionMail &amp;amp;&amp;amp; cp env_init .env &amp;amp;&amp;amp; docker compose up -d || docker-compose up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Star History&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://www.star-history.com/#aapanel/billionmail&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=aapanel/billionmail&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;BillionMail is licensed under the &lt;strong&gt;AGPLv3 License&lt;/strong&gt;. This means you can:&lt;/p&gt; 
&lt;p&gt;‚úÖ Use the software for free.&lt;br /&gt; ‚úÖ Modify and distribute the code.&lt;br /&gt; ‚úÖ Use it privately without restrictions.&lt;/p&gt; 
&lt;p&gt;See the &lt;a href="https://raw.githubusercontent.com/aaPanel/BillionMail/dev/LICENSE"&gt;LICENSE&lt;/a&gt; file for more details.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;!-- BillionMail official link --&gt; 
&lt;!-- BillionMail Other link--&gt; 
&lt;!-- Shield link--&gt;</description>
    </item>
    
    <item>
      <title>SagerNet/sing-box</title>
      <link>https://github.com/SagerNet/sing-box</link>
      <description>&lt;p&gt;The universal proxy platform&lt;/p&gt;&lt;hr&gt;&lt;blockquote&gt; 
 &lt;p&gt;Sponsored by &lt;a href="https://go.warp.dev/sing-box"&gt;Warp&lt;/a&gt;, built for coding with multiple AI agents&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;a href="https://go.warp.dev/sing-box"&gt; &lt;img alt="Warp sponsorship" width="400" src="https://github.com/warpdotdev/brand-assets/raw/refs/heads/main/Github/Sponsor/Warp-Github-LG-02.png" /&gt; &lt;/a&gt; 
&lt;hr /&gt; 
&lt;h1&gt;sing-box&lt;/h1&gt; 
&lt;p&gt;The universal proxy platform.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://repology.org/project/sing-box/versions"&gt;&lt;img src="https://repology.org/badge/vertical-allrepos/sing-box.svg?sanitize=true" alt="Packaging status" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://sing-box.sagernet.org"&gt;https://sing-box.sagernet.org&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;Copyright (C) 2022 by nekohasekai &amp;lt;contact-sagernet@sekai.icu&amp;gt;

This program is free software: you can redistribute it and/or modify
it under the terms of the GNU General Public License as published by
the Free Software Foundation, either version 3 of the License, or
(at your option) any later version.

This program is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
GNU General Public License for more details.

You should have received a copy of the GNU General Public License
along with this program. If not, see &amp;lt;http://www.gnu.org/licenses/&amp;gt;.

In addition, no derivative work may use the name or imply association
with this application without prior consent.
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>1Panel-dev/1Panel</title>
      <link>https://github.com/1Panel-dev/1Panel</link>
      <description>&lt;p&gt;üî• 1Panel provides an intuitive web interface and MCP Server to manage websites, files, containers, databases, and LLMs on a Linux server.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt;&lt;a href="https://1panel.pro"&gt;&lt;img src="https://resource.1panel.pro/img/1panel-logo.png" alt="1Panel" width="300" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p align="center"&gt;&lt;b&gt;Top-Rated Web-based Linux Server Management Tool&lt;/b&gt;&lt;br /&gt;Best VPS control panel&lt;br /&gt;Êñ∞‰∏Ä‰ª£ÁöÑ Linux ÊúçÂä°Âô®ËøêÁª¥ÁÆ°ÁêÜÈù¢Êùø&lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://trendshift.io/repositories/2462" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/2462" alt="1Panel-dev%2F1Panel | Trendshift" style="width: 240px; height: auto;" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://www.gnu.org/licenses/gpl-3.0.html"&gt;&lt;img src="https://shields.io/github/license/1Panel-dev/1Panel?color=%231890FF" alt="License: GPL v3" /&gt;&lt;/a&gt; &lt;a href="https://app.codacy.com/gh/1Panel-dev/1Panel?utm_source=github.com&amp;amp;utm_medium=referral&amp;amp;utm_content=1Panel-dev/1Panel&amp;amp;utm_campaign=Badge_Grade_Dashboard"&gt;&lt;img src="https://app.codacy.com/project/badge/Grade/da67574fd82b473992781d1386b937ef" alt="Codacy" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/bUpUqWqdRr" target="_blank"&gt; &lt;img src="https://img.shields.io/discord/1318846410149335080?logo=discord&amp;amp;labelColor=%20%235462eb&amp;amp;logoColor=%20%23f5f5f5&amp;amp;color=%20%235462eb" alt="chat on Discord" /&gt;&lt;/a&gt; &lt;a href="https://github.com/1Panel-dev/1Panel/releases"&gt;&lt;img src="https://img.shields.io/github/v/release/1Panel-dev/1Panel" alt="GitHub release" /&gt;&lt;/a&gt; &lt;a href="https://github.com/1Panel-dev/1Panel"&gt;&lt;img src="https://img.shields.io/github/stars/1Panel-dev/1Panel?color=%231890FF&amp;amp;style=flat-square" alt="Stars" /&gt;&lt;/a&gt;&lt;br /&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://raw.githubusercontent.com/1Panel-dev/1Panel/dev-v2/README.md"&gt;&lt;img alt="English" src="https://img.shields.io/badge/English-d9d9d9" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/1Panel-dev/1Panel/dev-v2/docs/README.zh-Hans.md"&gt;&lt;img alt="‰∏≠Êñá(ÁÆÄ‰Ωì)" src="https://img.shields.io/badge/‰∏≠Êñá(ÁÆÄ‰Ωì)-d9d9d9" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/1Panel-dev/1Panel/dev-v2/docs/README.ja.md"&gt;&lt;img alt="Êó•Êú¨Ë™û" src="https://img.shields.io/badge/Êó•Êú¨Ë™û-d9d9d9" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/1Panel-dev/1Panel/dev-v2/docs/README.pt-br.md"&gt;&lt;img alt="Portugu√™s (Brasil)" src="https://img.shields.io/badge/Portugu√™s (Brasil)-d9d9d9" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/1Panel-dev/1Panel/dev-v2/docs/README.ar.md"&gt;&lt;img alt="ÿßŸÑÿπÿ±ÿ®Ÿäÿ©" src="https://img.shields.io/badge/ÿßŸÑÿπÿ±ÿ®Ÿäÿ©-d9d9d9" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/1Panel-dev/1Panel/dev-v2/docs/README.de.md"&gt;&lt;img alt="Deutsch" src="https://img.shields.io/badge/Deutsch-d9d9d9" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/1Panel-dev/1Panel/dev-v2/docs/README.es.md"&gt;&lt;img alt="Espa√±ol" src="https://img.shields.io/badge/Espa√±ol-d9d9d9" /&gt;&lt;/a&gt;&lt;br /&gt; &lt;a href="https://raw.githubusercontent.com/1Panel-dev/1Panel/dev-v2/docs/README.fr.md"&gt;&lt;img alt="fran√ßais" src="https://img.shields.io/badge/fran√ßais-d9d9d9" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/1Panel-dev/1Panel/dev-v2/docs/README.ko.md"&gt;&lt;img alt="ÌïúÍµ≠Ïñ¥" src="https://img.shields.io/badge/ÌïúÍµ≠Ïñ¥-d9d9d9" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/1Panel-dev/1Panel/dev-v2/docs/README.id.md"&gt;&lt;img alt="Bahasa Indonesia" src="https://img.shields.io/badge/Bahasa Indonesia-d9d9d9" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/1Panel-dev/1Panel/dev-v2/docs/README.zh-Hant.md"&gt;&lt;img alt="‰∏≠Êñá(ÁπÅÈ´î)" src="https://img.shields.io/badge/‰∏≠Êñá(ÁπÅÈ´î)-d9d9d9" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/1Panel-dev/1Panel/dev-v2/docs/README.tr.md"&gt;&lt;img alt="T√ºrk√ße" src="https://img.shields.io/badge/T√ºrk√ße-d9d9d9" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/1Panel-dev/1Panel/dev-v2/docs/README.ru.md"&gt;&lt;img alt="–†—É—Å—Å–∫–∏–π" src="https://img.shields.io/badge/%D0%A0%D1%83%D1%81%D1%81%D0%BA%D0%B8%D0%B9-d9d9d9" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/1Panel-dev/1Panel/dev-v2/docs/README.ms.md"&gt;&lt;img alt="Bahasa Melayu" src="https://img.shields.io/badge/Bahasa Melayu-d9d9d9" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;1Panel is an open-source, modern web-based control panel for Linux server management.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Efficient Management&lt;/strong&gt;: Through a user-friendly web graphical interface, 1Panel enables users to effortlessly manage their Linux servers. Key features include host monitoring, file management, database administration, container management, LLMs management.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Rapid Website Deployment&lt;/strong&gt;: With deep integration of the popular open-source website building software WordPress, 1Panel streamlines the process of domain binding and SSL certificate configuration, all achievable with just one click.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Application Store&lt;/strong&gt;: 1Panel curates a wide range of high-quality open-source tools and applications, facilitating easy installation and updates for its users.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Security and Reliability&lt;/strong&gt;: By leveraging containerization and secure application deployment practices, 1Panel minimizes vulnerability exposure. It further enhances security through integrated firewall management and log auditing capabilities.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;One-Click Backup &amp;amp; Restore&lt;/strong&gt;: Data protection is made simple with 1Panel's one-click backup and restore functionality, supporting various cloud storage solutions to ensure data integrity and availability.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;p&gt;Execute the script below and follow the prompts to install 1Panel:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -sSL https://resource.1panel.pro/quick_start.sh -o quick_start.sh &amp;amp;&amp;amp; bash quick_start.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Please refer to our &lt;a href="https://docs.1panel.pro/quick_start/"&gt;documentation&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;p&gt;‰∏≠ÂõΩÁî®Êà∑ËØ∑‰ΩøÁî®Ëøô‰∏™ &lt;a href="https://1panel.cn/docs/installation/online_installation/"&gt;ÂÆâË£ÖËÑöÊú¨&lt;/a&gt;ÔºåÂÖ∂Â∫îÁî®Êï∞ÈáèÊØîÂõΩÈôÖÁâàÊú¨Êõ¥‰∏∞ÂØå„ÄÇ&lt;/p&gt; 
&lt;h2&gt;Screenshot&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://resource.1panel.pro/img/1panel.png" alt="UI Display" /&gt;&lt;/p&gt; 
&lt;h2&gt;Star History&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://star-history.com/#1Panel-dev/1Panel&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=1Panel-dev/1Panel&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Pro Edition&lt;/h2&gt; 
&lt;p&gt;Compared to the OSS Edition, 1Panel Pro Edition provides users with a wealth of enhanced features and technical support services. Enhanced features include WAF enhancement, website tamper protection, website monitoring, GPU monitoring, custom logo and theme color, etc. &lt;a href="https://1panel.pro/pricing"&gt;Click to view the detailed introduction of the Pro Edition&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Security Information&lt;/h2&gt; 
&lt;p&gt;If you discover any security issues, please refer to &lt;a href="https://raw.githubusercontent.com/1Panel-dev/1Panel/dev-v2/SECURITY.md"&gt;SECURITY.md&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Licensed under The GNU General Public License version 3 (GPLv3) (the "License"); you may not use this file except in compliance with the License. You may obtain a copy of the License at&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.gnu.org/licenses/gpl-3.0.html"&gt;https://www.gnu.org/licenses/gpl-3.0.html&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>trustwallet/assets</title>
      <link>https://github.com/trustwallet/assets</link>
      <description>&lt;p&gt;A comprehensive, up-to-date collection of information about several thousands (!) of crypto tokens.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Trust Wallet Assets Info&lt;/h1&gt; 
&lt;p&gt;&lt;img src="https://github.com/trustwallet/assets/workflows/Check/badge.svg?sanitize=true" alt="Check" /&gt;&lt;/p&gt; 
&lt;h2&gt;Overview&lt;/h2&gt; 
&lt;p&gt;Trust Wallet token repository is a comprehensive, up-to-date collection of information about several thousands (!) of crypto tokens.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://trustwallet.com"&gt;Trust Wallet&lt;/a&gt; uses token logos from this source, alongside a number of other projects.&lt;/p&gt; 
&lt;p&gt;The repository contains token info from several blockchains, info on dApps, staking validators, etc. For every token a logo and optional additional information is available (such data is not available on-chain).&lt;/p&gt; 
&lt;p&gt;Such a large collection can be maintained only through a community effort, so &lt;em&gt;feel free to add your token&lt;/em&gt;.&lt;/p&gt; 
&lt;center&gt;
 &lt;img src="https://trustwallet.com/assets/images/media/assets/horizontal_blue.png" height="200" /&gt;
&lt;/center&gt; 
&lt;h2&gt;How to add token&lt;/h2&gt; 
&lt;p&gt;Please note that &lt;strong&gt;brand new tokens are not accepted&lt;/strong&gt;, the projects have to be sound, with information available, and &lt;strong&gt;non-minimal circulation&lt;/strong&gt; (for limit details see &lt;a href="https://developer.trustwallet.com/listing-new-assets/requirements"&gt;https://developer.trustwallet.com/listing-new-assets/requirements&lt;/a&gt;).&lt;/p&gt; 
&lt;h3&gt;Assets App&lt;/h3&gt; 
&lt;p&gt;The &lt;a href="https://assets.trustwallet.com"&gt;Assets web app&lt;/a&gt; can be used for most new token additions (Github account is needed).&lt;/p&gt; 
&lt;h3&gt;Quick starter&lt;/h3&gt; 
&lt;p&gt;Details of the repository structure and contribution guidelines are listed on the &lt;a href="https://developer.trustwallet.com/listing-new-assets/new-asset"&gt;Developers site&lt;/a&gt;. Here is a quick starter summary for the most common use case.&lt;/p&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;For details, see the &lt;a href="https://developer.trustwallet.com"&gt;Developers site&lt;/a&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://developer.trustwallet.com/listing-new-assets/repository_details"&gt;Contribution guidelines&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://developer.trustwallet.com/listing-new-assets/faq"&gt;FAQ&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Scripts&lt;/h2&gt; 
&lt;p&gt;There are several scripts available for maintainers:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;make check&lt;/code&gt; -- Execute validation checks; also used in continuous integration.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;make fix&lt;/code&gt; -- Perform automatic fixes where possible&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;make update-auto&lt;/code&gt; -- Run automatic updates from external sources, executed regularly (GitHub action)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;make add-token asset_id=c60_t0x4Fabb145d64652a948d72533023f6E7A623C7C53&lt;/code&gt; -- Create &lt;code&gt;info.json&lt;/code&gt; file as asset template.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;make add-tokenlist asset_id=c60_t0x4Fabb145d64652a948d72533023f6E7A623C7C53&lt;/code&gt; -- Adds a token to tokenlist.json.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;make add-tokenlist-extended asset_id=c60_t0x4Fabb145d64652a948d72533023f6E7A623C7C53&lt;/code&gt; -- Adds a token to tokenlist-extended.json.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;On Checks&lt;/h2&gt; 
&lt;p&gt;This repo contains a set of scripts for verification of all the information. Implemented as Golang scripts, available through &lt;code&gt;make check&lt;/code&gt;, and executed in CI build; checks the whole repo. There are similar check logic implemented:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;in assets-management app; for checking changed token files in PRs, or when creating a PR. Checks diffs, can be run from browser environment.&lt;/li&gt; 
 &lt;li&gt;in merge-fee-bot, which runs as a GitHub app shows result in PR comment. Executes in a non-browser environment.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Trading pair maintenance&lt;/h2&gt; 
&lt;p&gt;Info on supported trading pairs are stored in &lt;code&gt;tokenlist.json&lt;/code&gt; files. Trading pairs can be updated -- from Uniswap/Ethereum and PancakeSwap/Smartchain -- using update script (and checking in changes). Minimal limit values for trading pair inclusion are set in the &lt;a href="https://github.com/trustwallet/assets/raw/master/.github/assets.config.yaml"&gt;config file&lt;/a&gt;. There are also options for force-include and force-exclude in the config.&lt;/p&gt; 
&lt;h2&gt;Disclaimer&lt;/h2&gt; 
&lt;p&gt;Trust Wallet team allows anyone to submit new assets to this repository. However, this does not mean that we are in direct partnership with all of the projects.&lt;/p&gt; 
&lt;p&gt;Trust Wallet team will reject projects that are deemed as scam or fraudulent after careful review. Trust Wallet team reserves the right to change the terms of asset submissions at any time due to changing market conditions, risk of fraud, or any other factors we deem relevant.&lt;/p&gt; 
&lt;p&gt;Additionally, spam-like behavior, including but not limited to mass distribution of tokens to random addresses will result in the asset being flagged as spam and possible removal from the repository.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;The scripts and documentation in this project are released under the &lt;a href="https://raw.githubusercontent.com/trustwallet/assets/master/LICENSE"&gt;MIT License&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>charmbracelet/glow</title>
      <link>https://github.com/charmbracelet/glow</link>
      <description>&lt;p&gt;Render markdown on the CLI, with pizzazz! üíÖüèª&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Glow&lt;/h1&gt; 
&lt;p&gt;Render markdown on the CLI, with &lt;em&gt;pizzazz&lt;/em&gt;!&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://stuff.charm.sh/glow/glow-banner-github.gif" alt="Glow Logo" /&gt; &lt;a href="https://github.com/charmbracelet/glow/releases"&gt;&lt;img src="https://img.shields.io/github/release/charmbracelet/glow.svg?sanitize=true" alt="Latest Release" /&gt;&lt;/a&gt; &lt;a href="https://pkg.go.dev/github.com/charmbracelet/glow?tab=doc"&gt;&lt;img src="https://godoc.org/github.com/golang/gddo?status.svg?sanitize=true" alt="GoDoc" /&gt;&lt;/a&gt; &lt;a href="https://github.com/charmbracelet/glow/actions"&gt;&lt;img src="https://github.com/charmbracelet/glow/workflows/build/badge.svg?sanitize=true" alt="Build Status" /&gt;&lt;/a&gt; &lt;a href="https://goreportcard.com/report/github.com/charmbracelet/glow"&gt;&lt;img src="https://goreportcard.com/badge/charmbracelet/glow" alt="Go ReportCard" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://github.com/user-attachments/assets/c2246366-f84b-4847-b431-32a61ca07b74" width="800" alt="Glow UI Demo" /&gt; &lt;/p&gt; 
&lt;h2&gt;What is it?&lt;/h2&gt; 
&lt;p&gt;Glow is a terminal based markdown reader designed from the ground up to bring out the beauty‚Äîand power‚Äîof the CLI.&lt;/p&gt; 
&lt;p&gt;Use it to discover markdown files, read documentation directly on the command line. Glow will find local markdown files in subdirectories or a local Git repository.&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;h3&gt;Package Manager&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# macOS or Linux
brew install glow
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# macOS (with MacPorts)
sudo port install glow
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Arch Linux (btw)
pacman -S glow
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Void Linux
xbps-install -S glow
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Nix shell
nix-shell -p glow --command glow
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# FreeBSD
pkg install glow
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Solus
eopkg install glow
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Windows (with Chocolatey, Scoop, or Winget)
choco install glow
scoop install glow
winget install charmbracelet.glow
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Android (with termux)
pkg install glow
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Ubuntu (Snapcraft)
sudo snap install glow
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Debian/Ubuntu
sudo mkdir -p /etc/apt/keyrings
curl -fsSL https://repo.charm.sh/apt/gpg.key | sudo gpg --dearmor -o /etc/apt/keyrings/charm.gpg
echo "deb [signed-by=/etc/apt/keyrings/charm.gpg] https://repo.charm.sh/apt/ * *" | sudo tee /etc/apt/sources.list.d/charm.list
sudo apt update &amp;amp;&amp;amp; sudo apt install glow
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Fedora/RHEL
echo '[charm]
name=Charm
baseurl=https://repo.charm.sh/yum/
enabled=1
gpgcheck=1
gpgkey=https://repo.charm.sh/yum/gpg.key' | sudo tee /etc/yum.repos.d/charm.repo
sudo yum install glow
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or download a binary from the &lt;a href="https://github.com/charmbracelet/glow/releases"&gt;releases&lt;/a&gt; page. MacOS, Linux, Windows, FreeBSD and OpenBSD binaries are available, as well as Debian, RPM, and Alpine packages. ARM builds are also available for macOS, Linux, FreeBSD and OpenBSD.&lt;/p&gt; 
&lt;h3&gt;Go&lt;/h3&gt; 
&lt;p&gt;Or just install it with &lt;code&gt;go&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;go install github.com/charmbracelet/glow/v2@latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Build (requires Go 1.21+)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/charmbracelet/glow.git
cd glow
go build
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;The TUI&lt;/h2&gt; 
&lt;p&gt;Simply run &lt;code&gt;glow&lt;/code&gt; without arguments to start the textual user interface and browse local. Glow will find local markdown files in the current directory and below or, if you‚Äôre in a Git repository, Glow will search the repo.&lt;/p&gt; 
&lt;p&gt;Markdown files can be read with Glow's high-performance pager. Most of the keystrokes you know from &lt;code&gt;less&lt;/code&gt; are the same, but you can press &lt;code&gt;?&lt;/code&gt; to list the hotkeys.&lt;/p&gt; 
&lt;h2&gt;The CLI&lt;/h2&gt; 
&lt;p&gt;In addition to a TUI, Glow has a CLI for working with Markdown. To format a document use a markdown source as the primary argument:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Read from file
glow README.md

# Read from stdin
echo "[Glow](https://github.com/charmbracelet/glow)" | glow -

# Fetch README from GitHub / GitLab
glow github.com/charmbracelet/glow

# Fetch markdown from HTTP
glow https://host.tld/file.md
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Word Wrapping&lt;/h3&gt; 
&lt;p&gt;The &lt;code&gt;-w&lt;/code&gt; flag lets you set a maximum width at which the output will be wrapped:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;glow -w 60
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Paging&lt;/h3&gt; 
&lt;p&gt;CLI output can be displayed in your preferred pager with the &lt;code&gt;-p&lt;/code&gt; flag. This defaults to the ANSI-aware &lt;code&gt;less -r&lt;/code&gt; if &lt;code&gt;$PAGER&lt;/code&gt; is not explicitly set.&lt;/p&gt; 
&lt;h3&gt;Styles&lt;/h3&gt; 
&lt;p&gt;You can choose a style with the &lt;code&gt;-s&lt;/code&gt; flag. When no flag is provided &lt;code&gt;glow&lt;/code&gt; tries to detect your terminal's current background color and automatically picks either the &lt;code&gt;dark&lt;/code&gt; or the &lt;code&gt;light&lt;/code&gt; style for you.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;glow -s [dark|light]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Alternatively you can also supply a custom JSON stylesheet:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;glow -s mystyle.json
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For additional usage details see:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;glow --help
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Check out the &lt;a href="https://github.com/charmbracelet/glamour/raw/master/styles/gallery/README.md"&gt;Glamour Style Section&lt;/a&gt; to find more styles. Or &lt;a href="https://github.com/charmbracelet/glamour/tree/master/styles"&gt;make your own&lt;/a&gt;!&lt;/p&gt; 
&lt;h2&gt;The Config File&lt;/h2&gt; 
&lt;p&gt;If you find yourself supplying the same flags to &lt;code&gt;glow&lt;/code&gt; all the time, it's probably a good idea to create a config file. Run &lt;code&gt;glow config&lt;/code&gt;, which will open it in your favorite $EDITOR. Alternatively you can manually put a file named &lt;code&gt;glow.yml&lt;/code&gt; in the default config path of you platform. If you're not sure where that is, please refer to &lt;code&gt;glow --help&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Here's an example config:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;# style name or JSON path (default "auto")
style: "light"
# mouse wheel support (TUI-mode only)
mouse: true
# use pager to display markdown
pager: true
# at which column should we word wrap?
width: 80
# show all files, including hidden and ignored.
all: false
# show line numbers (TUI-mode only)
showLineNumbers: false
# preserve newlines in the output
preserveNewLines: false
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;See &lt;a href="https://github.com/charmbracelet/glow/contribute"&gt;contributing&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Feedback&lt;/h2&gt; 
&lt;p&gt;We‚Äôd love to hear your thoughts on this project. Feel free to drop us a note!&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://twitter.com/charmcli"&gt;Twitter&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://mastodon.social/@charmcli"&gt;The Fediverse&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://charm.sh/chat"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://github.com/charmbracelet/glow/raw/master/LICENSE"&gt;MIT&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;Part of &lt;a href="https://charm.sh"&gt;Charm&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://charm.sh/"&gt;&lt;img alt="The Charm logo" src="https://stuff.charm.sh/charm-badge.jpg" width="400" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;CharmÁÉ≠Áà±ÂºÄÊ∫ê ‚Ä¢ Charm loves open source&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>XTLS/Xray-core</title>
      <link>https://github.com/XTLS/Xray-core</link>
      <description>&lt;p&gt;Xray, Penetrates Everything. Also the best v2ray-core. Where the magic happens. An open platform for various uses.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Project X&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://github.com/XTLS"&gt;Project X&lt;/a&gt; originates from XTLS protocol, providing a set of network tools such as &lt;a href="https://github.com/XTLS/Xray-core"&gt;Xray-core&lt;/a&gt; and &lt;a href="https://github.com/XTLS/REALITY"&gt;REALITY&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/XTLS/Xray-core#readme"&gt;README&lt;/a&gt; is open, so feel free to submit your project &lt;a href="https://github.com/XTLS/Xray-core/pulls"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Donation &amp;amp; NFTs&lt;/h2&gt; 
&lt;h3&gt;&lt;a href="https://opensea.io/item/ethereum/0x5ee362866001613093361eb8569d59c4141b76d1/1"&gt;Collect a Project X NFT to support the development of Project X!&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://opensea.io/item/ethereum/0x5ee362866001613093361eb8569d59c4141b76d1/1"&gt;&lt;img alt="Project X NFT" width="150px" src="https://raw2.seadn.io/ethereum/0x5ee362866001613093361eb8569d59c4141b76d1/7fa9ce900fb39b44226348db330e32/8b7fa9ce900fb39b44226348db330e32.svg?sanitize=true" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;ETH/USDT/USDC: &lt;code&gt;0xDc3Fe44F0f25D13CACb1C4896CD0D321df3146Ee&lt;/code&gt;&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Project X NFT: &lt;a href="https://opensea.io/item/ethereum/0x5ee362866001613093361eb8569d59c4141b76d1/1"&gt;https://opensea.io/item/ethereum/0x5ee362866001613093361eb8569d59c4141b76d1/1&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;VLESS NFT: &lt;a href="https://opensea.io/collection/vless"&gt;https://opensea.io/collection/vless&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;REALITY NFT: &lt;a href="https://opensea.io/item/ethereum/0x5ee362866001613093361eb8569d59c4141b76d1/2"&gt;https://opensea.io/item/ethereum/0x5ee362866001613093361eb8569d59c4141b76d1/2&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Related links: &lt;a href="https://github.com/XTLS/Xray-core/pull/5067"&gt;VLESS Post-Quantum Encryption&lt;/a&gt;, &lt;a href="https://github.com/XTLS/Xray-core/discussions/4113"&gt;XHTTP: Beyond REALITY&lt;/a&gt;, &lt;a href="https://github.com/XTLS/Xray-core/discussions/3633"&gt;Announcement of NFTs by Project X&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://github.com/XTLS/Xray-core/raw/main/LICENSE"&gt;Mozilla Public License Version 2.0&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://xtls.github.io"&gt;Project X Official Website&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Telegram&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://t.me/projectXray"&gt;Project X&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://t.me/projectXtls"&gt;Project X Channel&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://t.me/projectVless"&gt;Project VLESS&lt;/a&gt; (–†—É—Å—Å–∫–∏–π)&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://t.me/projectXhttp"&gt;Project XHTTP&lt;/a&gt; (Persian)&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Linux Script 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/XTLS/Xray-install"&gt;XTLS/Xray-install&lt;/a&gt; (&lt;strong&gt;Official&lt;/strong&gt;)&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/team-cloudchaser/tempest"&gt;tempest&lt;/a&gt; (supports &lt;a href="https://systemd.io"&gt;&lt;code&gt;systemd&lt;/code&gt;&lt;/a&gt; and &lt;a href="https://github.com/OpenRC/openrc"&gt;OpenRC&lt;/a&gt;; Linux-only)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Docker 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://ghcr.io/xtls/xray-core"&gt;ghcr.io/xtls/xray-core&lt;/a&gt; (&lt;strong&gt;Official&lt;/strong&gt;)&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://hub.docker.com/r/teddysun/xray"&gt;teddysun/xray&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/wulabing/xray_docker"&gt;wulabing/xray_docker&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Web Panel - &lt;strong&gt;WARNING: Please DO NOT USE plain HTTP panels like 3X-UI&lt;/strong&gt;, as they are believed to be bribed by Iran GFW for supporting plain HTTP by default and refused to change (&lt;a href="https://github.com/XTLS/Xray-core/pull/3884#issuecomment-2439595331"&gt;https://github.com/XTLS/Xray-core/pull/3884#issuecomment-2439595331&lt;/a&gt;), which has already put many users' data security in danger in the past few years. &lt;strong&gt;If you are already using 3X-UI, please switch to the following panels, which are verified to support HTTPS and SSH port forwarding only:&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/xeefei/X-Panel"&gt;X-Panel&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/PasarGuard/panel"&gt;PasarGuard&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/remnawave/panel"&gt;Remnawave&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/Gozargah/Marzban"&gt;Marzban&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/qist/xray-ui"&gt;Xray-UI&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/hiddify/Hiddify-Manager"&gt;Hiddify&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;One Click 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/zxcvos/Xray-script"&gt;Xray-REALITY&lt;/a&gt;, &lt;a href="https://github.com/sajjaddg/xray-reality"&gt;xray-reality&lt;/a&gt;, &lt;a href="https://github.com/aleskxyz/reality-ezpz"&gt;reality-ezpz&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/hello-yunshu/Xray_bash_onekey"&gt;Xray_bash_onekey&lt;/a&gt;, &lt;a href="https://github.com/LordPenguin666/XTool"&gt;XTool&lt;/a&gt;, &lt;a href="https://github.com/vpainless/vpainless"&gt;VPainLess&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/mack-a/v2ray-agent"&gt;v2ray-agent&lt;/a&gt;, &lt;a href="https://github.com/wulabing/Xray_onekey"&gt;Xray_onekey&lt;/a&gt;, &lt;a href="https://github.com/proxysu/ProxySU"&gt;ProxySU&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Magisk 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/Asterisk4Magisk/Xray4Magisk"&gt;Xray4Magisk&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/E7KMbb/Xray_For_Magisk"&gt;Xray_For_Magisk&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Homebrew 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;brew install xray&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Example 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/XTLS/REALITY#readme"&gt;VLESS-XTLS-uTLS-REALITY&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/XTLS/Xray-examples/tree/main/VLESS-TCP-XTLS-Vision"&gt;VLESS-TCP-XTLS-Vision&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/XTLS/Xray-examples/tree/main/All-in-One-fallbacks-Nginx"&gt;All-in-One-fallbacks-Nginx&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Xray-examples 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/XTLS/Xray-examples"&gt;XTLS/Xray-examples&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/chika0801/Xray-examples"&gt;chika0801/Xray-examples&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/lxhao61/integrated-examples"&gt;lxhao61/integrated-examples&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Tutorial 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/chika0801/Xray-install"&gt;XTLS Vision&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://cscot.pages.dev/2023/03/02/Xray-REALITY-tutorial/"&gt;REALITY (English)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/SasukeFreestyle/XTLS-Iran-Reality"&gt;XTLS-Iran-Reality (English)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://computerscot.github.io/vless-xtls-utls-reality-steal-oneself.html"&gt;Xray REALITY with 'steal oneself' (English)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://g800.pages.dev/wireguard"&gt;Xray with WireGuard inbound (English)&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;GUI Clients&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;OpenWrt 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/xiaorouji/openwrt-passwall"&gt;PassWall&lt;/a&gt;, &lt;a href="https://github.com/xiaorouji/openwrt-passwall2"&gt;PassWall 2&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/fw876/helloworld"&gt;ShadowSocksR Plus+&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/yichya/luci-app-xray"&gt;luci-app-xray&lt;/a&gt; (&lt;a href="https://github.com/yichya/openwrt-xray"&gt;openwrt-xray&lt;/a&gt;)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Asuswrt-Merlin 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/DanielLavrushin/asuswrt-merlin-xrayui"&gt;XRAYUI&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Windows 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/2dust/v2rayN"&gt;v2rayN&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/LorenEteval/Furious"&gt;Furious&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/InvisibleManVPN/InvisibleMan-XRayClient"&gt;Invisible Man - Xray&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/AnyPortal/AnyPortal"&gt;AnyPortal&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Android 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/2dust/v2rayNG"&gt;v2rayNG&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/XTLS/X-flutter"&gt;X-flutter&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/SaeedDev94/Xray"&gt;SaeedDev94/Xray&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/lhear/SimpleXray"&gt;SimpleXray&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/AnyPortal/AnyPortal"&gt;AnyPortal&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;iOS &amp;amp; macOS arm64 &amp;amp; tvOS 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://apps.apple.com/app/happ-proxy-utility/id6504287215"&gt;Happ&lt;/a&gt; (&lt;a href="https://apps.apple.com/us/app/happ-proxy-utility-for-tv/id6748297274"&gt;tvOS&lt;/a&gt;)&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://apps.apple.com/app/streisand/id6450534064"&gt;Streisand&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/OneXray/OneXray"&gt;OneXray&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;macOS arm64 &amp;amp; x64 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://apps.apple.com/app/happ-proxy-utility/id6504287215"&gt;Happ&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/yanue/V2rayU"&gt;V2rayU&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/tzmax/V2RayXS"&gt;V2RayXS&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/LorenEteval/Furious"&gt;Furious&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/OneXray/OneXray"&gt;OneXray&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/goxray/desktop"&gt;GoXRay&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/AnyPortal/AnyPortal"&gt;AnyPortal&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Linux 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/v2rayA/v2rayA"&gt;v2rayA&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/LorenEteval/Furious"&gt;Furious&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/ketetefid/GorzRay"&gt;GorzRay&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/goxray/desktop"&gt;GoXRay&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/AnyPortal/AnyPortal"&gt;AnyPortal&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Others that support VLESS, XTLS, REALITY, XUDP, PLUX...&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;iOS &amp;amp; macOS arm64 &amp;amp; tvOS 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://apps.apple.com/app/shadowrocket/id932747118"&gt;Shadowrocket&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://apps.apple.com/us/app/loon/id1373567447"&gt;Loon&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Xray Tools 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/lilendian0x00/xray-knife"&gt;xray-knife&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/kutovoys/xray-checker"&gt;xray-checker&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Xray Wrapper 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/XTLS/libXray"&gt;XTLS/libXray&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/remnawave/xtls-sdk"&gt;xtls-sdk&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/hiddify/xtlsapi"&gt;xtlsapi&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/2dust/AndroidLibXrayLite"&gt;AndroidLibXrayLite&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/LorenEteval/Xray-core-python"&gt;Xray-core-python&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/XVGuardian/xray-api"&gt;xray-api&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/XrayR-project/XrayR"&gt;XrayR&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/XrayR-project/XrayR-release"&gt;XrayR-release&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/missuo/XrayR-V2Board"&gt;XrayR-V2Board&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Cores 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/amnezia-vpn"&gt;Amnezia VPN&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/MetaCubeX/mihomo"&gt;mihomo&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/SagerNet/sing-box"&gt;sing-box&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://github.com/XTLS/Xray-core/raw/main/CODE_OF_CONDUCT.md"&gt;Code of Conduct&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://deepwiki.com/XTLS/Xray-core"&gt;&lt;img src="https://deepwiki.com/badge.svg?sanitize=true" alt="Ask DeepWiki" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Credits&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/XTLS/Xray-core/releases/tag/v1.0.0"&gt;Xray-core v1.0.0&lt;/a&gt; was forked from &lt;a href="https://github.com/v2fly/v2ray-core/commit/9a03cc5c98d04cc28320fcee26dbc236b3291256"&gt;v2fly-core 9a03cc5&lt;/a&gt;, and we have made &amp;amp; accumulated a huge number of enhancements over time, check &lt;a href="https://github.com/XTLS/Xray-core/releases"&gt;the release notes for each version&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;For third-party projects used in &lt;a href="https://github.com/XTLS/Xray-core"&gt;Xray-core&lt;/a&gt;, check your local or &lt;a href="https://github.com/XTLS/Xray-core/raw/main/go.mod"&gt;the latest go.mod&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;One-line Compilation&lt;/h2&gt; 
&lt;h3&gt;Windows (PowerShell)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-powershell"&gt;$env:CGO_ENABLED=0
go build -o xray.exe -trimpath -buildvcs=false -ldflags="-s -w -buildid=" -v ./main
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Linux / macOS&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;CGO_ENABLED=0 go build -o xray -trimpath -buildvcs=false -ldflags="-s -w -buildid=" -v ./main
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Reproducible Releases&lt;/h3&gt; 
&lt;p&gt;Make sure that you are using the same Go version, and remember to set the git commit id (7 bytes):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;CGO_ENABLED=0 go build -o xray -trimpath -buildvcs=false -gcflags="all=-l=4" -ldflags="-X github.com/xtls/xray-core/core.build=REPLACE -s -w -buildid=" -v ./main
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you are compiling a 32-bit MIPS/MIPSLE target, use this command instead:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;CGO_ENABLED=0 go build -o xray -trimpath -buildvcs=false -gcflags="-l=4" -ldflags="-X github.com/xtls/xray-core/core.build=REPLACE -s -w -buildid=" -v ./main
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Stargazers over time&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://starchart.cc/XTLS/Xray-core"&gt;&lt;img src="https://starchart.cc/XTLS/Xray-core.svg?sanitize=true" alt="Stargazers over time" /&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>hajimehoshi/ebiten</title>
      <link>https://github.com/hajimehoshi/ebiten</link>
      <description>&lt;p&gt;A dead simple 2D game engine for Go&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Ebitengine (v2)&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://pkg.go.dev/github.com/hajimehoshi/ebiten/v2"&gt;&lt;img src="https://pkg.go.dev/badge/github.com/hajimehoshi/ebiten/v2.svg?sanitize=true" alt="Go Reference" /&gt;&lt;/a&gt; &lt;a href="https://github.com/hajimehoshi/ebiten/actions?query=workflow%3Atest"&gt;&lt;img src="https://github.com/hajimehoshi/ebiten/actions/workflows/test.yml/badge.svg?sanitize=true" alt="Build Status" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;A dead simple 2D game engine for Go&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Ebitengine (formerly known as Ebiten) is an open source game engine for the Go programming language. Ebitengine's simple API allows you to quickly and easily develop 2D games that can be deployed across multiple platforms.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://ebitengine.org"&gt;Website (ebitengine.org)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pkg.go.dev/github.com/hajimehoshi/ebiten/v2"&gt;API Reference&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://ebitengine.org/en/documents/cheatsheet.html"&gt;Cheat Sheet&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/sedyh/awesome-ebitengine"&gt;Awesome Ebitengine&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://ebitengine.org/images/overview2.png" alt="Overview" /&gt;&lt;/p&gt; 
&lt;h2&gt;Platforms&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://ebitengine.org/en/documents/install.html?os=windows"&gt;Windows&lt;/a&gt; (No Cgo required!)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://ebitengine.org/en/documents/install.html?os=darwin"&gt;macOS&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://ebitengine.org/en/documents/install.html?os=linux"&gt;Linux&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://ebitengine.org/en/documents/install.html?os=freebsd"&gt;FreeBSD&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://ebitengine.org/en/documents/mobile.html"&gt;Android&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://ebitengine.org/en/documents/mobile.html"&gt;iOS&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://ebitengine.org/en/documents/webassembly.html"&gt;WebAssembly&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Nintendo Switch&lt;/li&gt; 
 &lt;li&gt;Xbox (Xbox support is limited and not available to everyone. Negotiations are currently underway to make it accessible to all.)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For installation on desktops, see &lt;a href="https://ebitengine.org/en/documents/install.html"&gt;the installation instruction&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;2D Graphics (Geometry and color transformation by matrices, Various composition modes, Offscreen rendering, Text rendering, Automatic batches, Automatic texture atlas, Custom shaders)&lt;/li&gt; 
 &lt;li&gt;Input (Mouse, Keyboard, Gamepads, Touches)&lt;/li&gt; 
 &lt;li&gt;Audio (Ogg/Vorbis, MP3, WAV, PCM)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Packages&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://pkg.go.dev/github.com/hajimehoshi/ebiten/v2"&gt;ebiten&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://pkg.go.dev/github.com/hajimehoshi/ebiten/v2/audio"&gt;audio&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://pkg.go.dev/github.com/hajimehoshi/ebiten/v2/audio/mp3"&gt;mp3&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://pkg.go.dev/github.com/hajimehoshi/ebiten/v2/audio/vorbis"&gt;vorbis&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://pkg.go.dev/github.com/hajimehoshi/ebiten/v2/audio/wav"&gt;wav&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://pkg.go.dev/github.com/hajimehoshi/ebiten/v2/colorm"&gt;colorm&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://pkg.go.dev/github.com/hajimehoshi/ebiten/v2/ebitenutil"&gt;ebitenutil&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://pkg.go.dev/github.com/hajimehoshi/ebiten/v2/inpututil"&gt;inpututil&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://pkg.go.dev/github.com/hajimehoshi/ebiten/v2/mobile"&gt;mobile&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://pkg.go.dev/github.com/hajimehoshi/ebiten/v2/text/v2"&gt;text/v2&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://pkg.go.dev/github.com/hajimehoshi/ebiten/v2/vector"&gt;vector&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://pkg.go.dev/github.com/hajimehoshi/ebiten/v2/exp/textinput"&gt;exp/textinput&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Community&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://discord.gg/3tVdM5H8cC"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;#ebitengine&lt;/code&gt; channel in &lt;a href="https://blog.gopheracademy.com/gophers-slack-community/"&gt;Gophers Slack&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/hajimehoshi/ebiten/discussions"&gt;GitHub Discussion&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.reddit.com/r/ebitengine/"&gt;&lt;code&gt;r/ebitengine&lt;/code&gt; in Reddit&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Ebitengine is licensed under Apache license version 2.0. See &lt;a href="https://raw.githubusercontent.com/hajimehoshi/ebiten/main/LICENSE"&gt;LICENSE&lt;/a&gt; file.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://ebitengine.org/images/logo.png"&gt;The Ebitengine logo&lt;/a&gt; by Hajime Hoshi is licensed under &lt;a href="https://creativecommons.org/licenses/by/4.0/"&gt;the Creative Commons Attribution 4.0&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;GLFW&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://github.com/glfw/glfw"&gt;https://github.com/glfw/glfw&lt;/a&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Copyright (c) 2002-2006 Marcus Geelnard

Copyright (c) 2006-2019 Camilla L√∂wy

This software is provided 'as-is', without any express or implied
warranty. In no event will the authors be held liable for any damages
arising from the use of this software.

Permission is granted to anyone to use this software for any purpose,
including commercial applications, and to alter it and redistribute it
freely, subject to the following restrictions:

1. The origin of this software must not be misrepresented; you must not
   claim that you wrote the original software. If you use this software
   in a product, an acknowledgment in the product documentation would
   be appreciated but is not required.

2. Altered source versions must be plainly marked as such, and must not
   be misrepresented as being the original software.

3. This notice may not be removed or altered from any source
   distribution.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Go&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://cs.opensource.google/go/go"&gt;https://cs.opensource.google/go/go&lt;/a&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Copyright (c) 2009 The Go Authors. All rights reserved.

Redistribution and use in source and binary forms, with or without
modification, are permitted provided that the following conditions are
met:

   * Redistributions of source code must retain the above copyright
notice, this list of conditions and the following disclaimer.
   * Redistributions in binary form must reproduce the above
copyright notice, this list of conditions and the following disclaimer
in the documentation and/or other materials provided with the
distribution.
   * Neither the name of Google Inc. nor the names of its
contributors may be used to endorse or promote products derived from
this software without specific prior written permission.

THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
"AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;go-gl/gl&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://github.com/go-gl/gl"&gt;https://github.com/go-gl/gl&lt;/a&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;The MIT License (MIT)

Copyright (c) 2014 Eric Woroshow

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;go-gl/glfw&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://github.com/go-gl/glfw"&gt;https://github.com/go-gl/glfw&lt;/a&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Copyright (c) 2012 The glfw3-go Authors. All rights reserved.

Redistribution and use in source and binary forms, with or without
modification, are permitted provided that the following conditions are
met:

   * Redistributions of source code must retain the above copyright
notice, this list of conditions and the following disclaimer.
   * Redistributions in binary form must reproduce the above
copyright notice, this list of conditions and the following disclaimer
in the documentation and/or other materials provided with the
distribution.
   * Neither the name of Google Inc. nor the names of its
contributors may be used to endorse or promote products derived from
this software without specific prior written permission.

THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
"AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>hashicorp/terraform</title>
      <link>https://github.com/hashicorp/terraform</link>
      <description>&lt;p&gt;Terraform enables you to safely and predictably create, change, and improve infrastructure. It is a source-available tool that codifies APIs into declarative configuration files that can be shared amongst team members, treated as code, edited, reviewed, and versioned.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Terraform&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;Website: &lt;a href="https://developer.hashicorp.com/terraform"&gt;https://developer.hashicorp.com/terraform&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Forums: &lt;a href="https://discuss.hashicorp.com/c/terraform-core"&gt;HashiCorp Discuss&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Documentation: &lt;a href="https://developer.hashicorp.com/terraform/docs"&gt;https://developer.hashicorp.com/terraform/docs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Tutorials: &lt;a href="https://developer.hashicorp.com/terraform/tutorials"&gt;HashiCorp's Learn Platform&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Certification Exam: &lt;a href="https://www.hashicorp.com/certification/#hashicorp-certified-terraform-associate"&gt;HashiCorp Certified: Terraform Associate&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;img alt="Terraform" src="https://www.datocms-assets.com/2885/1731373310-terraform_white.svg?sanitize=true" width="600px" /&gt; 
&lt;p&gt;Terraform is a tool for building, changing, and versioning infrastructure safely and efficiently. Terraform can manage existing and popular service providers as well as custom in-house solutions.&lt;/p&gt; 
&lt;p&gt;The key features of Terraform are:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Infrastructure as Code&lt;/strong&gt;: Infrastructure is described using a high-level configuration syntax. This allows a blueprint of your datacenter to be versioned and treated as you would any other code. Additionally, infrastructure can be shared and re-used.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Execution Plans&lt;/strong&gt;: Terraform has a "planning" step where it generates an execution plan. The execution plan shows what Terraform will do when you call apply. This lets you avoid any surprises when Terraform manipulates infrastructure.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Resource Graph&lt;/strong&gt;: Terraform builds a graph of all your resources, and parallelizes the creation and modification of any non-dependent resources. Because of this, Terraform builds infrastructure as efficiently as possible, and operators get insight into dependencies in their infrastructure.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Change Automation&lt;/strong&gt;: Complex changesets can be applied to your infrastructure with minimal human interaction. With the previously mentioned execution plan and resource graph, you know exactly what Terraform will change and in what order, avoiding many possible human errors.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For more information, refer to the &lt;a href="https://www.terraform.io/intro"&gt;What is Terraform?&lt;/a&gt; page on the Terraform website.&lt;/p&gt; 
&lt;h2&gt;Getting Started &amp;amp; Documentation&lt;/h2&gt; 
&lt;p&gt;Documentation is available on the &lt;a href="https://developer.hashicorp.com/terraform"&gt;Terraform website&lt;/a&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://developer.hashicorp.com/terraform/intro"&gt;Introduction&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://developer.hashicorp.com/terraform/docs"&gt;Documentation&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;If you're new to Terraform and want to get started creating infrastructure, please check out our &lt;a href="https://learn.hashicorp.com/terraform#getting-started"&gt;Getting Started guides&lt;/a&gt; on HashiCorp's learning platform. There are also &lt;a href="https://learn.hashicorp.com/terraform#operations-and-development"&gt;additional guides&lt;/a&gt; to continue your learning.&lt;/p&gt; 
&lt;p&gt;Show off your Terraform knowledge by passing a certification exam. Visit the &lt;a href="https://www.hashicorp.com/certification/"&gt;certification page&lt;/a&gt; for information about exams and find &lt;a href="https://learn.hashicorp.com/terraform/certification/terraform-associate"&gt;study materials&lt;/a&gt; on HashiCorp's learning platform.&lt;/p&gt; 
&lt;h2&gt;Developing Terraform&lt;/h2&gt; 
&lt;p&gt;This repository contains only Terraform core, which includes the command line interface and the main graph engine. Providers are implemented as plugins, and Terraform can automatically download providers that are published on &lt;a href="https://registry.terraform.io"&gt;the Terraform Registry&lt;/a&gt;. HashiCorp develops some providers, and others are developed by other organizations. For more information, refer to &lt;a href="https://developer.hashicorp.com/terraform/plugin"&gt;Plugin development&lt;/a&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;To learn more about compiling Terraform and contributing suggested changes, refer to &lt;a href="https://raw.githubusercontent.com/hashicorp/terraform/main/.github/CONTRIBUTING.md"&gt;the contributing guide&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;To learn more about how we handle bug reports, refer to the &lt;a href="https://raw.githubusercontent.com/hashicorp/terraform/main/BUGPROCESS.md"&gt;bug triage guide&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;To learn how to contribute to the Terraform documentation, refer to the &lt;a href="https://github.com/hashicorp/web-unified-docs"&gt;Web Unified Docs repository&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://github.com/hashicorp/terraform/raw/main/LICENSE"&gt;Business Source License 1.1&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>mudler/LocalAI</title>
      <link>https://github.com/mudler/LocalAI</link>
      <description>&lt;p&gt;ü§ñ The free, Open Source alternative to OpenAI, Claude and others. Self-hosted and local-first. Drop-in replacement for OpenAI, running on consumer-grade hardware. No GPU required. Runs gguf, transformers, diffusers and many more. Features: Generate Text, Audio, Video, Images, Voice Cloning, Distributed, P2P and decentralized inference&lt;/p&gt;&lt;hr&gt;&lt;h1 align="center"&gt; &lt;br /&gt; &lt;img width="300" src="https://raw.githubusercontent.com/mudler/LocalAI/master/core/http/static/logo.png" /&gt; &lt;br /&gt; &lt;br /&gt; &lt;/h1&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/go-skynet/LocalAI/fork" target="blank"&gt; &lt;img src="https://img.shields.io/github/forks/go-skynet/LocalAI?style=for-the-badge" alt="LocalAI forks" /&gt; &lt;/a&gt; &lt;a href="https://github.com/go-skynet/LocalAI/stargazers" target="blank"&gt; &lt;img src="https://img.shields.io/github/stars/go-skynet/LocalAI?style=for-the-badge" alt="LocalAI stars" /&gt; &lt;/a&gt; &lt;a href="https://github.com/go-skynet/LocalAI/pulls" target="blank"&gt; &lt;img src="https://img.shields.io/github/issues-pr/go-skynet/LocalAI?style=for-the-badge" alt="LocalAI pull-requests" /&gt; &lt;/a&gt; &lt;a href="https://github.com/go-skynet/LocalAI/releases"&gt; &lt;img src="https://img.shields.io/github/release/go-skynet/LocalAI?&amp;amp;label=Latest&amp;amp;style=for-the-badge" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://hub.docker.com/r/localai/localai" target="blank"&gt; &lt;img src="https://img.shields.io/badge/dockerhub-images-important.svg?logo=Docker" alt="LocalAI Docker hub" /&gt; &lt;/a&gt; &lt;a href="https://quay.io/repository/go-skynet/local-ai?tab=tags&amp;amp;tag=latest" target="blank"&gt; &lt;img src="https://img.shields.io/badge/quay.io-images-important.svg?" alt="LocalAI Quay.io" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://twitter.com/LocalAI_API" target="blank"&gt; &lt;img src="https://img.shields.io/badge/X-%23000000.svg?style=for-the-badge&amp;amp;logo=X&amp;amp;logoColor=white&amp;amp;label=LocalAI_API" alt="Follow LocalAI_API" /&gt; &lt;/a&gt; &lt;a href="https://discord.gg/uJAeKSAGDy" target="blank"&gt; &lt;img src="https://dcbadge.vercel.app/api/server/uJAeKSAGDy?style=flat-square&amp;amp;theme=default-inverted" alt="Join LocalAI Discord Community" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://trendshift.io/repositories/5539" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/5539" alt="mudler%2FLocalAI | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;span&gt;üí°&lt;/span&gt; Get help - &lt;a href="https://localai.io/faq/"&gt;‚ùìFAQ&lt;/a&gt; &lt;a href="https://github.com/go-skynet/LocalAI/discussions"&gt;üí≠Discussions&lt;/a&gt; &lt;a href="https://discord.gg/uJAeKSAGDy"&gt;&lt;span&gt;üí¨&lt;/span&gt; Discord&lt;/a&gt; &lt;a href="https://localai.io/"&gt;&lt;span&gt;üìñ&lt;/span&gt; Documentation website&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://localai.io/basics/getting_started/"&gt;üíª Quickstart&lt;/a&gt; &lt;a href="https://models.localai.io/"&gt;üñºÔ∏è Models&lt;/a&gt; &lt;a href="https://github.com/mudler/LocalAI/issues?q=is%3Aissue+is%3Aopen+label%3Aroadmap"&gt;üöÄ Roadmap&lt;/a&gt; &lt;a href="https://explorer.localai.io"&gt;üåç Explorer&lt;/a&gt; &lt;a href="https://github.com/mudler/LocalAI-examples"&gt;üõ´ Examples&lt;/a&gt; Try on &lt;a href="https://t.me/localaiofficial_bot"&gt;&lt;img src="https://img.shields.io/badge/Telegram-2CA5E0?style=for-the-badge&amp;amp;logo=telegram&amp;amp;logoColor=white" alt="Telegram" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;a href="https://github.com/go-skynet/LocalAI/actions/workflows/test.yml"&gt;&lt;img src="https://github.com/go-skynet/LocalAI/actions/workflows/test.yml/badge.svg?sanitize=true" alt="tests" /&gt;&lt;/a&gt;&lt;a href="https://github.com/go-skynet/LocalAI/actions/workflows/release.yaml"&gt;&lt;img src="https://github.com/go-skynet/LocalAI/actions/workflows/release.yaml/badge.svg?sanitize=true" alt="Build and Release" /&gt;&lt;/a&gt;&lt;a href="https://github.com/go-skynet/LocalAI/actions/workflows/image.yml"&gt;&lt;img src="https://github.com/go-skynet/LocalAI/actions/workflows/image.yml/badge.svg?sanitize=true" alt="build container images" /&gt;&lt;/a&gt;&lt;a href="https://github.com/go-skynet/LocalAI/actions/workflows/bump_deps.yaml"&gt;&lt;img src="https://github.com/go-skynet/LocalAI/actions/workflows/bump_deps.yaml/badge.svg?sanitize=true" alt="Bump dependencies" /&gt;&lt;/a&gt;&lt;a href="https://artifacthub.io/packages/search?repo=localai"&gt;&lt;img src="https://img.shields.io/endpoint?url=https://artifacthub.io/badge/repository/localai" alt="Artifact Hub" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;LocalAI&lt;/strong&gt; is the free, Open Source OpenAI alternative. LocalAI act as a drop-in replacement REST API that's compatible with OpenAI (Elevenlabs, Anthropic... ) API specifications for local AI inferencing. It allows you to run LLMs, generate images, audio (and not only) locally or on-prem with consumer grade hardware, supporting multiple model families. Does not require GPU. It is created and maintained by &lt;a href="https://github.com/mudler"&gt;Ettore Di Giacinto&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;üìöüÜï Local Stack Family&lt;/h2&gt; 
&lt;p&gt;üÜï LocalAI is now part of a comprehensive suite of AI tools designed to work together:&lt;/p&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td width="50%" valign="top"&gt; &lt;a href="https://github.com/mudler/LocalAGI"&gt; &lt;img src="https://raw.githubusercontent.com/mudler/LocalAGI/refs/heads/main/webui/react-ui/public/logo_2.png" width="300" alt="LocalAGI Logo" /&gt; &lt;/a&gt; &lt;/td&gt; 
   &lt;td width="50%" valign="top"&gt; &lt;h3&gt;&lt;a href="https://github.com/mudler/LocalAGI"&gt;LocalAGI&lt;/a&gt;&lt;/h3&gt; &lt;p&gt;A powerful Local AI agent management platform that serves as a drop-in replacement for OpenAI's Responses API, enhanced with advanced agentic capabilities.&lt;/p&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="50%" valign="top"&gt; &lt;a href="https://github.com/mudler/LocalRecall"&gt; &lt;img src="https://raw.githubusercontent.com/mudler/LocalRecall/refs/heads/main/static/localrecall_horizontal.png" width="300" alt="LocalRecall Logo" /&gt; &lt;/a&gt; &lt;/td&gt; 
   &lt;td width="50%" valign="top"&gt; &lt;h3&gt;&lt;a href="https://github.com/mudler/LocalRecall"&gt;LocalRecall&lt;/a&gt;&lt;/h3&gt; &lt;p&gt;A REST-ful API and knowledge base management system that provides persistent memory and storage capabilities for AI agents.&lt;/p&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h2&gt;Screenshots&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Talk Interface&lt;/th&gt; 
   &lt;th&gt;Generate Audio&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/mudler/LocalAI/master/docs/assets/images/screenshots/screenshot_tts.png" alt="Screenshot 2025-03-31 at 12-01-36 LocalAI - Talk" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/mudler/LocalAI/master/docs/assets/images/screenshots/screenshot_tts.png" alt="Screenshot 2025-03-31 at 12-01-29 LocalAI - Generate audio with voice-en-us-ryan-low" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Models Overview&lt;/th&gt; 
   &lt;th&gt;Generate Images&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/mudler/LocalAI/master/docs/assets/images/screenshots/screenshot_gallery.png" alt="Screenshot 2025-03-31 at 12-01-20 LocalAI - Models" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/mudler/LocalAI/master/docs/assets/images/screenshots/screenshot_image.png" alt="Screenshot 2025-03-31 at 12-31-41 LocalAI - Generate images with flux 1-dev" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Chat Interface&lt;/th&gt; 
   &lt;th&gt;Home&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/mudler/LocalAI/master/docs/assets/images/screenshots/screenshot_chat.png" alt="Screenshot 2025-03-31 at 11-57-44 LocalAI - Chat with localai-functioncall-qwen2 5-7b-v0 5" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/mudler/LocalAI/master/docs/assets/images/screenshots/screenshot_home.png" alt="Screenshot 2025-03-31 at 11-57-23 LocalAI API - c2a39e3 (c2a39e3639227cfd94ffffe9f5691239acc275a8)" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Login&lt;/th&gt; 
   &lt;th&gt;Swarm&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/mudler/LocalAI/master/docs/assets/images/screenshots/screenshot_login.png" alt="Screenshot 2025-03-31 at 12-09-59 " /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/mudler/LocalAI/master/docs/assets/images/screenshots/screenshot_p2p.png" alt="Screenshot 2025-03-31 at 12-10-39 LocalAI - P2P dashboard" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;üíª Quickstart&lt;/h2&gt; 
&lt;p&gt;Run the installer script:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Basic installation
curl https://localai.io/install.sh | sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For more installation options, see &lt;a href="https://localai.io/docs/advanced/installer/"&gt;Installer Options&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;macOS Download:&lt;/h3&gt; 
&lt;a href="https://github.com/mudler/LocalAI/releases/latest/download/LocalAI.dmg"&gt; &lt;img src="https://img.shields.io/badge/Download-macOS-blue?style=for-the-badge&amp;amp;logo=apple&amp;amp;logoColor=white" alt="Download LocalAI for macOS" /&gt; &lt;/a&gt; 
&lt;p&gt;Or run with docker:&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;üí° Docker Run vs Docker Start&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;code&gt;docker run&lt;/code&gt; creates and starts a new container. If a container with the same name already exists, this command will fail.&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;docker start&lt;/code&gt; starts an existing container that was previously created with &lt;code&gt;docker run&lt;/code&gt;.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;If you've already run LocalAI before and want to start it again, use: &lt;code&gt;docker start -i local-ai&lt;/code&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;CPU only image:&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run -ti --name local-ai -p 8080:8080 localai/localai:latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;NVIDIA GPU Images:&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# CUDA 12.0
docker run -ti --name local-ai -p 8080:8080 --gpus all localai/localai:latest-gpu-nvidia-cuda-12

# CUDA 11.7
docker run -ti --name local-ai -p 8080:8080 --gpus all localai/localai:latest-gpu-nvidia-cuda-11

# NVIDIA Jetson (L4T) ARM64
docker run -ti --name local-ai -p 8080:8080 --gpus all localai/localai:latest-nvidia-l4t-arm64
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;AMD GPU Images (ROCm):&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run -ti --name local-ai -p 8080:8080 --device=/dev/kfd --device=/dev/dri --group-add=video localai/localai:latest-gpu-hipblas
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Intel GPU Images (oneAPI):&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run -ti --name local-ai -p 8080:8080 --device=/dev/dri/card1 --device=/dev/dri/renderD128 localai/localai:latest-gpu-intel
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Vulkan GPU Images:&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run -ti --name local-ai -p 8080:8080 localai/localai:latest-gpu-vulkan
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;AIO Images (pre-downloaded models):&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# CPU version
docker run -ti --name local-ai -p 8080:8080 localai/localai:latest-aio-cpu

# NVIDIA CUDA 12 version
docker run -ti --name local-ai -p 8080:8080 --gpus all localai/localai:latest-aio-gpu-nvidia-cuda-12

# NVIDIA CUDA 11 version
docker run -ti --name local-ai -p 8080:8080 --gpus all localai/localai:latest-aio-gpu-nvidia-cuda-11

# Intel GPU version
docker run -ti --name local-ai -p 8080:8080 localai/localai:latest-aio-gpu-intel

# AMD GPU version
docker run -ti --name local-ai -p 8080:8080 --device=/dev/kfd --device=/dev/dri --group-add=video localai/localai:latest-aio-gpu-hipblas
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For more information about the AIO images and pre-downloaded models, see &lt;a href="https://localai.io/basics/container/"&gt;Container Documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;To load models:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# From the model gallery (see available models with `local-ai models list`, in the WebUI from the model tab, or visiting https://models.localai.io)
local-ai run llama-3.2-1b-instruct:q4_k_m
# Start LocalAI with the phi-2 model directly from huggingface
local-ai run huggingface://TheBloke/phi-2-GGUF/phi-2.Q8_0.gguf
# Install and run a model from the Ollama OCI registry
local-ai run ollama://gemma:2b
# Run a model from a configuration file
local-ai run https://gist.githubusercontent.com/.../phi-2.yaml
# Install and run a model from a standard OCI registry (e.g., Docker Hub)
local-ai run oci://localai/phi-2:latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;‚ö° &lt;strong&gt;Automatic Backend Detection&lt;/strong&gt;: When you install models from the gallery or YAML files, LocalAI automatically detects your system's GPU capabilities (NVIDIA, AMD, Intel) and downloads the appropriate backend. For advanced configuration options, see &lt;a href="https://localai.io/features/gpu-acceleration/#automatic-backend-detection"&gt;GPU Acceleration&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;For more information, see &lt;a href="https://localai.io/basics/getting_started/index.html"&gt;üíª Getting started&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üì∞ Latest project news&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;October 2025: üîå &lt;a href="https://localai.io/docs/features/mcp/"&gt;Model Context Protocol (MCP)&lt;/a&gt; support added for agentic capabilities with external tools&lt;/li&gt; 
 &lt;li&gt;September 2025: New Launcher application for MacOS and Linux, extended support to many backends for Mac and Nvidia L4T devices. Models: Added MLX-Audio, WAN 2.2. WebUI improvements and Python-based backends now ships portable python environments.&lt;/li&gt; 
 &lt;li&gt;August 2025: MLX, MLX-VLM, Diffusers and llama.cpp are now supported on Mac M1/M2/M3+ chips ( with &lt;code&gt;development&lt;/code&gt; suffix in the gallery ): &lt;a href="https://github.com/mudler/LocalAI/pull/6049"&gt;https://github.com/mudler/LocalAI/pull/6049&lt;/a&gt; &lt;a href="https://github.com/mudler/LocalAI/pull/6119"&gt;https://github.com/mudler/LocalAI/pull/6119&lt;/a&gt; &lt;a href="https://github.com/mudler/LocalAI/pull/6121"&gt;https://github.com/mudler/LocalAI/pull/6121&lt;/a&gt; &lt;a href="https://github.com/mudler/LocalAI/pull/6060"&gt;https://github.com/mudler/LocalAI/pull/6060&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;July/August 2025: üîç &lt;a href="https://localai.io/features/object-detection/"&gt;Object Detection&lt;/a&gt; added to the API featuring &lt;a href="https://github.com/roboflow/rf-detr"&gt;rf-detr&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;July 2025: All backends migrated outside of the main binary. LocalAI is now more lightweight, small, and automatically downloads the required backend to run the model. &lt;a href="https://github.com/mudler/LocalAI/releases/tag/v3.2.0"&gt;Read the release notes&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;June 2025: &lt;a href="https://github.com/mudler/LocalAI/pull/5607"&gt;Backend management&lt;/a&gt; has been added. Attention: extras images are going to be deprecated from the next release! Read &lt;a href="https://github.com/mudler/LocalAI/pull/5607"&gt;the backend management PR&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;May 2025: &lt;a href="https://github.com/mudler/LocalAI/pull/5466"&gt;Audio input&lt;/a&gt; and &lt;a href="https://github.com/mudler/LocalAI/pull/5396"&gt;Reranking&lt;/a&gt; in llama.cpp backend, &lt;a href="https://github.com/mudler/LocalAI/pull/5392"&gt;Realtime API&lt;/a&gt;, Support to Gemma, SmollVLM, and more multimodal models (available in the gallery).&lt;/li&gt; 
 &lt;li&gt;May 2025: Important: image name changes &lt;a href="https://github.com/mudler/LocalAI/releases/tag/v2.29.0"&gt;See release&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Apr 2025: Rebrand, WebUI enhancements&lt;/li&gt; 
 &lt;li&gt;Apr 2025: &lt;a href="https://github.com/mudler/LocalAGI"&gt;LocalAGI&lt;/a&gt; and &lt;a href="https://github.com/mudler/LocalRecall"&gt;LocalRecall&lt;/a&gt; join the LocalAI family stack.&lt;/li&gt; 
 &lt;li&gt;Apr 2025: WebUI overhaul, AIO images updates&lt;/li&gt; 
 &lt;li&gt;Feb 2025: Backend cleanup, Breaking changes, new backends (kokoro, OutelTTS, faster-whisper), Nvidia L4T images&lt;/li&gt; 
 &lt;li&gt;Jan 2025: LocalAI model release: &lt;a href="https://huggingface.co/mudler/LocalAI-functioncall-phi-4-v0.3"&gt;https://huggingface.co/mudler/LocalAI-functioncall-phi-4-v0.3&lt;/a&gt;, SANA support in diffusers: &lt;a href="https://github.com/mudler/LocalAI/pull/4603"&gt;https://github.com/mudler/LocalAI/pull/4603&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Dec 2024: stablediffusion.cpp backend (ggml) added ( &lt;a href="https://github.com/mudler/LocalAI/pull/4289"&gt;https://github.com/mudler/LocalAI/pull/4289&lt;/a&gt; )&lt;/li&gt; 
 &lt;li&gt;Nov 2024: Bark.cpp backend added ( &lt;a href="https://github.com/mudler/LocalAI/pull/4287"&gt;https://github.com/mudler/LocalAI/pull/4287&lt;/a&gt; )&lt;/li&gt; 
 &lt;li&gt;Nov 2024: Voice activity detection models (&lt;strong&gt;VAD&lt;/strong&gt;) added to the API: &lt;a href="https://github.com/mudler/LocalAI/pull/4204"&gt;https://github.com/mudler/LocalAI/pull/4204&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Oct 2024: examples moved to &lt;a href="https://github.com/mudler/LocalAI-examples"&gt;LocalAI-examples&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Aug 2024: üÜï FLUX-1, &lt;a href="https://explorer.localai.io"&gt;P2P Explorer&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;July 2024: üî•üî• üÜï P2P Dashboard, LocalAI Federated mode and AI Swarms: &lt;a href="https://github.com/mudler/LocalAI/pull/2723"&gt;https://github.com/mudler/LocalAI/pull/2723&lt;/a&gt;. P2P Global community pools: &lt;a href="https://github.com/mudler/LocalAI/issues/3113"&gt;https://github.com/mudler/LocalAI/issues/3113&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;May 2024: üî•üî• Decentralized P2P llama.cpp: &lt;a href="https://github.com/mudler/LocalAI/pull/2343"&gt;https://github.com/mudler/LocalAI/pull/2343&lt;/a&gt; (peer2peer llama.cpp!) üëâ Docs &lt;a href="https://localai.io/features/distribute/"&gt;https://localai.io/features/distribute/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;May 2024: üî•üî• Distributed inferencing: &lt;a href="https://github.com/mudler/LocalAI/pull/2324"&gt;https://github.com/mudler/LocalAI/pull/2324&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;April 2024: Reranker API: &lt;a href="https://github.com/mudler/LocalAI/pull/2121"&gt;https://github.com/mudler/LocalAI/pull/2121&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Roadmap items: &lt;a href="https://github.com/mudler/LocalAI/issues?q=is%3Aissue+is%3Aopen+label%3Aroadmap"&gt;List of issues&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üöÄ &lt;a href="https://localai.io/features/"&gt;Features&lt;/a&gt;&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;üß© &lt;a href="https://localai.io/backends/"&gt;Backend Gallery&lt;/a&gt;: Install/remove backends on the fly, powered by OCI images ‚Äî fully customizable and API-driven.&lt;/li&gt; 
 &lt;li&gt;üìñ &lt;a href="https://localai.io/features/text-generation/"&gt;Text generation with GPTs&lt;/a&gt; (&lt;code&gt;llama.cpp&lt;/code&gt;, &lt;code&gt;transformers&lt;/code&gt;, &lt;code&gt;vllm&lt;/code&gt; ... &lt;a href="https://localai.io/model-compatibility/index.html#model-compatibility-table"&gt;&lt;span&gt;üìñ&lt;/span&gt; and more&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;üó£ &lt;a href="https://localai.io/features/text-to-audio/"&gt;Text to Audio&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üîà &lt;a href="https://localai.io/features/audio-to-text/"&gt;Audio to Text&lt;/a&gt; (Audio transcription with &lt;code&gt;whisper.cpp&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;üé® &lt;a href="https://localai.io/features/image-generation"&gt;Image generation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üî• &lt;a href="https://localai.io/features/openai-functions/"&gt;OpenAI-alike tools API&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üß† &lt;a href="https://localai.io/features/embeddings/"&gt;Embeddings generation for vector databases&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;‚úçÔ∏è &lt;a href="https://localai.io/features/constrained_grammars/"&gt;Constrained grammars&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üñºÔ∏è &lt;a href="https://localai.io/models/"&gt;Download Models directly from Huggingface &lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;ü•Ω &lt;a href="https://localai.io/features/gpt-vision/"&gt;Vision API&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üîç &lt;a href="https://localai.io/features/object-detection/"&gt;Object Detection&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üìà &lt;a href="https://localai.io/features/reranker/"&gt;Reranker API&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üÜïüñß &lt;a href="https://localai.io/features/distribute/"&gt;P2P Inferencing&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üÜïüîå &lt;a href="https://localai.io/docs/features/mcp/"&gt;Model Context Protocol (MCP)&lt;/a&gt; - Agentic capabilities with external tools and &lt;a href="https://github.com/mudler/LocalAGI"&gt;LocalAGI's Agentic capabilities&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üîä Voice activity detection (Silero-VAD support)&lt;/li&gt; 
 &lt;li&gt;üåç Integrated WebUI!&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üß© Supported Backends &amp;amp; Acceleration&lt;/h2&gt; 
&lt;p&gt;LocalAI supports a comprehensive range of AI backends with multiple acceleration options:&lt;/p&gt; 
&lt;h3&gt;Text Generation &amp;amp; Language Models&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Backend&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Acceleration Support&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;llama.cpp&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;LLM inference in C/C++&lt;/td&gt; 
   &lt;td&gt;CUDA 11/12, ROCm, Intel SYCL, Vulkan, Metal, CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;vLLM&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Fast LLM inference with PagedAttention&lt;/td&gt; 
   &lt;td&gt;CUDA 12, ROCm, Intel&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;transformers&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;HuggingFace transformers framework&lt;/td&gt; 
   &lt;td&gt;CUDA 11/12, ROCm, Intel, CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;exllama2&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;GPTQ inference library&lt;/td&gt; 
   &lt;td&gt;CUDA 12&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;MLX&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Apple Silicon LLM inference&lt;/td&gt; 
   &lt;td&gt;Metal (M1/M2/M3+)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;MLX-VLM&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Apple Silicon Vision-Language Models&lt;/td&gt; 
   &lt;td&gt;Metal (M1/M2/M3+)&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Audio &amp;amp; Speech Processing&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Backend&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Acceleration Support&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;whisper.cpp&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;OpenAI Whisper in C/C++&lt;/td&gt; 
   &lt;td&gt;CUDA 12, ROCm, Intel SYCL, Vulkan, CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;faster-whisper&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Fast Whisper with CTranslate2&lt;/td&gt; 
   &lt;td&gt;CUDA 12, ROCm, Intel, CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;bark&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Text-to-audio generation&lt;/td&gt; 
   &lt;td&gt;CUDA 12, ROCm, Intel&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;bark-cpp&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;C++ implementation of Bark&lt;/td&gt; 
   &lt;td&gt;CUDA, Metal, CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;coqui&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Advanced TTS with 1100+ languages&lt;/td&gt; 
   &lt;td&gt;CUDA 12, ROCm, Intel, CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;kokoro&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Lightweight TTS model&lt;/td&gt; 
   &lt;td&gt;CUDA 12, ROCm, Intel, CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;chatterbox&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Production-grade TTS&lt;/td&gt; 
   &lt;td&gt;CUDA 11/12, CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;piper&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Fast neural TTS system&lt;/td&gt; 
   &lt;td&gt;CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;kitten-tts&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Kitten TTS models&lt;/td&gt; 
   &lt;td&gt;CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;silero-vad&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Voice Activity Detection&lt;/td&gt; 
   &lt;td&gt;CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;neutts&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Text-to-speech with voice cloning&lt;/td&gt; 
   &lt;td&gt;CUDA 12, ROCm, CPU&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Image &amp;amp; Video Generation&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Backend&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Acceleration Support&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;stablediffusion.cpp&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Stable Diffusion in C/C++&lt;/td&gt; 
   &lt;td&gt;CUDA 12, Intel SYCL, Vulkan, CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;diffusers&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;HuggingFace diffusion models&lt;/td&gt; 
   &lt;td&gt;CUDA 11/12, ROCm, Intel, Metal, CPU&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Specialized AI Tasks&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Backend&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Acceleration Support&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;rfdetr&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Real-time object detection&lt;/td&gt; 
   &lt;td&gt;CUDA 12, Intel, CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;rerankers&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Document reranking API&lt;/td&gt; 
   &lt;td&gt;CUDA 11/12, ROCm, Intel, CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;local-store&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Vector database&lt;/td&gt; 
   &lt;td&gt;CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;huggingface&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;HuggingFace API integration&lt;/td&gt; 
   &lt;td&gt;API-based&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Hardware Acceleration Matrix&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Acceleration Type&lt;/th&gt; 
   &lt;th&gt;Supported Backends&lt;/th&gt; 
   &lt;th&gt;Hardware Support&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;NVIDIA CUDA 11&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;llama.cpp, whisper, stablediffusion, diffusers, rerankers, bark, chatterbox&lt;/td&gt; 
   &lt;td&gt;Nvidia hardware&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;NVIDIA CUDA 12&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;All CUDA-compatible backends&lt;/td&gt; 
   &lt;td&gt;Nvidia hardware&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;AMD ROCm&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;llama.cpp, whisper, vllm, transformers, diffusers, rerankers, coqui, kokoro, bark, neutts&lt;/td&gt; 
   &lt;td&gt;AMD Graphics&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Intel oneAPI&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;llama.cpp, whisper, stablediffusion, vllm, transformers, diffusers, rfdetr, rerankers, exllama2, coqui, kokoro, bark&lt;/td&gt; 
   &lt;td&gt;Intel Arc, Intel iGPUs&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Apple Metal&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;llama.cpp, whisper, diffusers, MLX, MLX-VLM, bark-cpp&lt;/td&gt; 
   &lt;td&gt;Apple M1/M2/M3+&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Vulkan&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;llama.cpp, whisper, stablediffusion&lt;/td&gt; 
   &lt;td&gt;Cross-platform GPUs&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;NVIDIA Jetson&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;llama.cpp, whisper, stablediffusion, diffusers, rfdetr&lt;/td&gt; 
   &lt;td&gt;ARM64 embedded AI&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;CPU Optimized&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;All backends&lt;/td&gt; 
   &lt;td&gt;AVX/AVX2/AVX512, quantization support&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;üîó Community and integrations&lt;/h3&gt; 
&lt;p&gt;Build and deploy custom containers:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/sozercan/aikit"&gt;https://github.com/sozercan/aikit&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;WebUIs:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Jirubizu/localai-admin"&gt;https://github.com/Jirubizu/localai-admin&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/go-skynet/LocalAI-frontend"&gt;https://github.com/go-skynet/LocalAI-frontend&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;QA-Pilot(An interactive chat project that leverages LocalAI LLMs for rapid understanding and navigation of GitHub code repository) &lt;a href="https://github.com/reid41/QA-Pilot"&gt;https://github.com/reid41/QA-Pilot&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Agentic Libraries:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mudler/cogito"&gt;https://github.com/mudler/cogito&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;MCPs:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mudler/MCPs"&gt;https://github.com/mudler/MCPs&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Model galleries&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/go-skynet/model-gallery"&gt;https://github.com/go-skynet/model-gallery&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Voice:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/richiejp/VoxInput"&gt;https://github.com/richiejp/VoxInput&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Other:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Helm chart &lt;a href="https://github.com/go-skynet/helm-charts"&gt;https://github.com/go-skynet/helm-charts&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;VSCode extension &lt;a href="https://github.com/badgooooor/localai-vscode-plugin"&gt;https://github.com/badgooooor/localai-vscode-plugin&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Langchain: &lt;a href="https://python.langchain.com/docs/integrations/providers/localai/"&gt;https://python.langchain.com/docs/integrations/providers/localai/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Terminal utility &lt;a href="https://github.com/djcopley/ShellOracle"&gt;https://github.com/djcopley/ShellOracle&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Local Smart assistant &lt;a href="https://github.com/mudler/LocalAGI"&gt;https://github.com/mudler/LocalAGI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Home Assistant &lt;a href="https://github.com/sammcj/homeassistant-localai"&gt;https://github.com/sammcj/homeassistant-localai&lt;/a&gt; / &lt;a href="https://github.com/drndos/hass-openai-custom-conversation"&gt;https://github.com/drndos/hass-openai-custom-conversation&lt;/a&gt; / &lt;a href="https://github.com/valentinfrlch/ha-gpt4vision"&gt;https://github.com/valentinfrlch/ha-gpt4vision&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Discord bot &lt;a href="https://github.com/mudler/LocalAGI/tree/main/examples/discord"&gt;https://github.com/mudler/LocalAGI/tree/main/examples/discord&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Slack bot &lt;a href="https://github.com/mudler/LocalAGI/tree/main/examples/slack"&gt;https://github.com/mudler/LocalAGI/tree/main/examples/slack&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Shell-Pilot(Interact with LLM using LocalAI models via pure shell scripts on your Linux or MacOS system) &lt;a href="https://github.com/reid41/shell-pilot"&gt;https://github.com/reid41/shell-pilot&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Telegram bot &lt;a href="https://github.com/mudler/LocalAI/tree/master/examples/telegram-bot"&gt;https://github.com/mudler/LocalAI/tree/master/examples/telegram-bot&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Another Telegram Bot &lt;a href="https://github.com/JackBekket/Hellper"&gt;https://github.com/JackBekket/Hellper&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Auto-documentation &lt;a href="https://github.com/JackBekket/Reflexia"&gt;https://github.com/JackBekket/Reflexia&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Github bot which answer on issues, with code and documentation as context &lt;a href="https://github.com/JackBekket/GitHelper"&gt;https://github.com/JackBekket/GitHelper&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Github Actions: &lt;a href="https://github.com/marketplace/actions/start-localai"&gt;https://github.com/marketplace/actions/start-localai&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Examples: &lt;a href="https://github.com/mudler/LocalAI/tree/master/examples/"&gt;https://github.com/mudler/LocalAI/tree/master/examples/&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üîó Resources&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://localai.io/docs/advanced/fine-tuning/"&gt;LLM finetuning guide&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://localai.io/basics/build/index.html"&gt;How to build locally&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://localai.io/basics/getting_started/index.html#run-localai-in-kubernetes"&gt;How to install in Kubernetes&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://localai.io/docs/integrations/"&gt;Projects integrating LocalAI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://io.midori-ai.xyz/howtos/"&gt;How tos section&lt;/a&gt; (curated by our community)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;&lt;span&gt;üìñ&lt;/span&gt; üé• &lt;a href="https://localai.io/basics/news/#media-blogs-social"&gt;Media, Blogs, Social&lt;/a&gt;&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.suse.com/c/running-ai-locally/"&gt;Run Visual studio code with LocalAI (SUSE)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üÜï &lt;a href="https://mudler.pm/posts/local-ai-jetson-nano-devkit/"&gt;Run LocalAI on Jetson Nano Devkit&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.pulumi.com/blog/low-code-llm-apps-with-local-ai-flowise-and-pulumi/"&gt;Run LocalAI on AWS EKS with Pulumi&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://staleks.hashnode.dev/installing-localai-on-aws-ec2-instance"&gt;Run LocalAI on AWS&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://mudler.pm/posts/smart-slackbot-for-teams/"&gt;Create a slackbot for teams and OSS projects that answer to documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=PKrDNuJ_dfE"&gt;LocalAI meets k8sgpt&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://mudler.pm/posts/localai-question-answering/"&gt;Question Answering on Documents locally with LangChain, LocalAI, Chroma, and GPT4All&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://medium.com/@tyler_97636/k8sgpt-localai-unlock-kubernetes-superpowers-for-free-584790de9b65"&gt;Tutorial to use k8sgpt with LocalAI&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Citation&lt;/h2&gt; 
&lt;p&gt;If you utilize this repository, data in a downstream project, please consider citing it with:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;@misc{localai,
  author = {Ettore Di Giacinto},
  title = {LocalAI: The free, Open source OpenAI alternative},
  year = {2023},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/go-skynet/LocalAI}},
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;‚ù§Ô∏è Sponsors&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Do you find LocalAI useful?&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Support the project by becoming &lt;a href="https://github.com/sponsors/mudler"&gt;a backer or sponsor&lt;/a&gt;. Your logo will show up here with a link to your website.&lt;/p&gt; 
&lt;p&gt;A huge thank you to our generous sponsors who support this project covering CI expenses, and our &lt;a href="https://github.com/sponsors/mudler"&gt;Sponsor list&lt;/a&gt;:&lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://www.spectrocloud.com/" target="blank"&gt; &lt;img height="200" src="https://github.com/user-attachments/assets/72eab1dd-8b93-4fc0-9ade-84db49f24962" /&gt; &lt;/a&gt; &lt;a href="https://www.premai.io/" target="blank"&gt; &lt;img height="200" src="https://github.com/mudler/LocalAI/assets/2420543/42e4ca83-661e-4f79-8e46-ae43689683d6" /&gt; &lt;br /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;h2&gt;üåü Star history&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://star-history.com/#go-skynet/LocalAI&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=go-skynet/LocalAI&amp;amp;type=Date" alt="LocalAI Star history Chart" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üìñ License&lt;/h2&gt; 
&lt;p&gt;LocalAI is a community-driven project created by &lt;a href="https://github.com/mudler/"&gt;Ettore Di Giacinto&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;MIT - Author Ettore Di Giacinto &lt;a href="mailto:mudler@localai.io"&gt;mudler@localai.io&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üôá Acknowledgements&lt;/h2&gt; 
&lt;p&gt;LocalAI couldn't have been built without the help of great software already available from the community. Thank you!&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ggerganov/llama.cpp"&gt;llama.cpp&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tatsu-lab/stanford_alpaca"&gt;https://github.com/tatsu-lab/stanford_alpaca&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/cornelk/llama-go"&gt;https://github.com/cornelk/llama-go&lt;/a&gt; for the initial ideas&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/antimatter15/alpaca.cpp"&gt;https://github.com/antimatter15/alpaca.cpp&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/EdVince/Stable-Diffusion-NCNN"&gt;https://github.com/EdVince/Stable-Diffusion-NCNN&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ggerganov/whisper.cpp"&gt;https://github.com/ggerganov/whisper.cpp&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/rhasspy/piper"&gt;https://github.com/rhasspy/piper&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ü§ó Contributors&lt;/h2&gt; 
&lt;p&gt;This is a community project, a special thanks to our contributors! ü§ó &lt;a href="https://github.com/go-skynet/LocalAI/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=go-skynet/LocalAI" /&gt; &lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>navidrome/navidrome</title>
      <link>https://github.com/navidrome/navidrome</link>
      <description>&lt;p&gt;üéß‚òÅÔ∏è Your Personal Streaming Service&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href="https://www.navidrome.org"&gt;&lt;img src="https://raw.githubusercontent.com/navidrome/navidrome/master/resources/logo-192x192.png" alt="Navidrome logo" title="navidrome" align="right" height="60px" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Navidrome Music Server &amp;nbsp;&lt;a href="https://twitter.com/intent/tweet?text=Tired%20of%20paying%20for%20music%20subscriptions%2C%20and%20not%20finding%20what%20you%20really%20like%3F%20Roll%20your%20own%20streaming%20service%21&amp;amp;url=https://navidrome.org&amp;amp;via=navidrome"&gt;&lt;img src="https://img.shields.io/twitter/url/http/shields.io.svg?style=social" alt="Tweet" /&gt;&lt;/a&gt;&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://github.com/navidrome/navidrome/releases"&gt;&lt;img src="https://img.shields.io/github/v/release/navidrome/navidrome?logo=github&amp;amp;label=latest&amp;amp;style=flat-square" alt="Last Release" /&gt;&lt;/a&gt; &lt;a href="https://nightly.link/navidrome/navidrome/workflows/pipeline/master"&gt;&lt;img src="https://img.shields.io/github/actions/workflow/status/navidrome/navidrome/pipeline.yml?branch=master&amp;amp;logo=github&amp;amp;style=flat-square" alt="Build" /&gt;&lt;/a&gt; &lt;a href="https://github.com/navidrome/navidrome/releases/latest"&gt;&lt;img src="https://img.shields.io/github/downloads/navidrome/navidrome/total?logo=github&amp;amp;style=flat-square" alt="Downloads" /&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/r/deluan/navidrome"&gt;&lt;img src="https://img.shields.io/docker/pulls/deluan/navidrome?logo=docker&amp;amp;label=pulls&amp;amp;style=flat-square" alt="Docker Pulls" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/xh7j7yF"&gt;&lt;img src="https://img.shields.io/discord/671335427726114836?logo=discord&amp;amp;label=discord&amp;amp;style=flat-square" alt="Dev Chat" /&gt;&lt;/a&gt; &lt;a href="https://www.reddit.com/r/navidrome/"&gt;&lt;img src="https://img.shields.io/reddit/subreddit-subscribers/navidrome?logo=reddit&amp;amp;label=/r/navidrome&amp;amp;style=flat-square" alt="Subreddit" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/navidrome/navidrome/master/CODE_OF_CONDUCT.md"&gt;&lt;img src="https://img.shields.io/badge/Contributor%20Covenant-v2.0-ff69b4.svg?style=flat-square" alt="Contributor Covenant" /&gt;&lt;/a&gt; &lt;a href="https://gurubase.io/g/navidrome"&gt;&lt;img src="https://img.shields.io/badge/Gurubase-Ask%20Navidrome%20Guru-006BFF?style=flat-square" alt="Gurubase" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Navidrome is an open source web-based music collection server and streamer. It gives you freedom to listen to your music collection from any browser or mobile device. It's like your personal Spotify!&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: The &lt;code&gt;master&lt;/code&gt; branch may be in an unstable or even broken state during development. Please use &lt;a href="https://github.com/navidrome/navidrome/releases"&gt;releases&lt;/a&gt; instead of the &lt;code&gt;master&lt;/code&gt; branch in order to get a stable set of binaries.&lt;/p&gt; 
&lt;h2&gt;&lt;a href="https://www.navidrome.org/demo/"&gt;Check out our Live Demo!&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Any feedback is welcome!&lt;/strong&gt; If you need/want a new feature, find a bug or think of any way to improve Navidrome, please file a &lt;a href="https://github.com/navidrome/navidrome/issues"&gt;GitHub issue&lt;/a&gt; or join the discussion in our &lt;a href="https://www.reddit.com/r/navidrome/"&gt;Subreddit&lt;/a&gt;. If you want to contribute to the project in any other way (&lt;a href="https://www.navidrome.org/docs/developers/"&gt;ui/backend dev&lt;/a&gt;, &lt;a href="https://www.navidrome.org/docs/developers/translations/"&gt;translations&lt;/a&gt;, &lt;a href="https://www.navidrome.org/docs/developers/creating-themes"&gt;themes&lt;/a&gt;), please join the chat in our &lt;a href="https://discord.gg/xh7j7yF"&gt;Discord server&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;See instructions on the &lt;a href="https://www.navidrome.org/docs/installation/"&gt;project's website&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Cloud Hosting&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://www.pikapods.com"&gt;PikaPods&lt;/a&gt; has partnered with us to offer you an &lt;a href="https://www.navidrome.org/docs/installation/managed/#pikapods"&gt;officially supported, cloud-hosted solution&lt;/a&gt;. A share of the revenue helps fund the development of Navidrome at no additional cost for you.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.pikapods.com/pods?run=navidrome"&gt;&lt;img src="https://www.pikapods.com/static/run-button.svg?sanitize=true" alt="PikaPods" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Handles very &lt;strong&gt;large music collections&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;Streams virtually &lt;strong&gt;any audio format&lt;/strong&gt; available&lt;/li&gt; 
 &lt;li&gt;Reads and uses all your beautifully curated &lt;strong&gt;metadata&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;Great support for &lt;strong&gt;compilations&lt;/strong&gt; (Various Artists albums) and &lt;strong&gt;box sets&lt;/strong&gt; (multi-disc albums)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Multi-user&lt;/strong&gt;, each user has their own play counts, playlists, favourites, etc...&lt;/li&gt; 
 &lt;li&gt;Very &lt;strong&gt;low resource usage&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Multi-platform&lt;/strong&gt;, runs on macOS, Linux and Windows. &lt;strong&gt;Docker&lt;/strong&gt; images are also provided&lt;/li&gt; 
 &lt;li&gt;Ready to use binaries for all major platforms, including &lt;strong&gt;Raspberry Pi&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;Automatically &lt;strong&gt;monitors your library&lt;/strong&gt; for changes, importing new files and reloading new metadata&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Themeable&lt;/strong&gt;, modern and responsive &lt;strong&gt;Web interface&lt;/strong&gt; based on &lt;a href="https://material-ui.com"&gt;Material UI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Compatible&lt;/strong&gt; with all Subsonic/Madsonic/Airsonic &lt;a href="https://www.navidrome.org/docs/overview/#apps"&gt;clients&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Transcoding&lt;/strong&gt; on the fly. Can be set per user/player. &lt;strong&gt;Opus encoding is supported&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;Translated to &lt;strong&gt;various languages&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Translations&lt;/h2&gt; 
&lt;p&gt;Navidrome uses &lt;a href="https://poeditor.com/"&gt;POEditor&lt;/a&gt; for translations, and we are always looking for &lt;a href="https://www.navidrome.org/docs/developers/translations/"&gt;more contributors&lt;/a&gt;&lt;/p&gt; 
&lt;a href="https://poeditor.com/"&gt; &lt;img height="32" src="https://github.com/user-attachments/assets/c19b1d2b-01e1-4682-a007-12356c42147c" /&gt; &lt;/a&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;All documentation can be found in the project's website: &lt;a href="https://www.navidrome.org/docs"&gt;https://www.navidrome.org/docs&lt;/a&gt;. Here are some useful direct links:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.navidrome.org/docs/overview/"&gt;Overview&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.navidrome.org/docs/installation/"&gt;Installation&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://www.navidrome.org/docs/installation/docker/"&gt;Docker&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.navidrome.org/docs/installation/pre-built-binaries/"&gt;Binaries&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.navidrome.org/docs/installation/build-from-source/"&gt;Build from source&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.navidrome.org/docs/developers/"&gt;Development&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.navidrome.org/docs/developers/subsonic-api/"&gt;Subsonic API Compatibility&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Screenshots&lt;/h2&gt; 
&lt;p align="left"&gt; &lt;img height="550" src="https://raw.githubusercontent.com/navidrome/navidrome/master/.github/screenshots/ss-mobile-login.png" /&gt; &lt;img height="550" src="https://raw.githubusercontent.com/navidrome/navidrome/master/.github/screenshots/ss-mobile-player.png" /&gt; &lt;img height="550" src="https://raw.githubusercontent.com/navidrome/navidrome/master/.github/screenshots/ss-mobile-album-view.png" /&gt; &lt;img width="550" src="https://raw.githubusercontent.com/navidrome/navidrome/master/.github/screenshots/ss-desktop-player.png" /&gt; &lt;/p&gt;</description>
    </item>
    
    <item>
      <title>aquasecurity/trivy</title>
      <link>https://github.com/aquasecurity/trivy</link>
      <description>&lt;p&gt;Find vulnerabilities, misconfigurations, secrets, SBOM in containers, Kubernetes, code repositories, clouds and more&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/aquasecurity/trivy/main/docs/imgs/logo.png" width="200" /&gt; 
 &lt;p&gt;&lt;a href="https://github.com/aquasecurity/trivy/releases"&gt;&lt;img src="https://img.shields.io/github/release/aquasecurity/trivy.svg?logo=github" alt="GitHub Release" /&gt;&lt;/a&gt; &lt;a href="https://github.com/aquasecurity/trivy/actions/workflows/test.yaml"&gt;&lt;img src="https://github.com/aquasecurity/trivy/actions/workflows/test.yaml/badge.svg?sanitize=true" alt="Test" /&gt;&lt;/a&gt; &lt;a href="https://goreportcard.com/report/github.com/aquasecurity/trivy"&gt;&lt;img src="https://goreportcard.com/badge/github.com/aquasecurity/trivy" alt="Go Report Card" /&gt;&lt;/a&gt; &lt;a href="https://github.com/aquasecurity/trivy/raw/main/LICENSE"&gt;&lt;img src="https://img.shields.io/badge/License-Apache%202.0-blue.svg?sanitize=true" alt="License: Apache-2.0" /&gt;&lt;/a&gt; &lt;a href="https://github.com/aquasecurity/trivy/releases"&gt;&lt;img src="https://img.shields.io/github/downloads/aquasecurity/trivy/total?logo=github" alt="GitHub Downloads" /&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/docker/pulls/aquasec/trivy?logo=docker&amp;amp;label=docker%20pulls%20%2F%20trivy" alt="Docker Pulls" /&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://trivy.dev/latest/docs/"&gt;üìñ Documentation&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;Trivy (&lt;a href="https://raw.githubusercontent.com/aquasecurity/trivy/main/#how-to-pronounce-the-name-trivy"&gt;pronunciation&lt;/a&gt;) is a comprehensive and versatile security scanner. Trivy has &lt;em&gt;scanners&lt;/em&gt; that look for security issues, and &lt;em&gt;targets&lt;/em&gt; where it can find those issues.&lt;/p&gt; 
&lt;p&gt;Targets (what Trivy can scan):&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Container Image&lt;/li&gt; 
 &lt;li&gt;Filesystem&lt;/li&gt; 
 &lt;li&gt;Git Repository (remote)&lt;/li&gt; 
 &lt;li&gt;Virtual Machine Image&lt;/li&gt; 
 &lt;li&gt;Kubernetes&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Scanners (what Trivy can find there):&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;OS packages and software dependencies in use (SBOM)&lt;/li&gt; 
 &lt;li&gt;Known vulnerabilities (CVEs)&lt;/li&gt; 
 &lt;li&gt;IaC issues and misconfigurations&lt;/li&gt; 
 &lt;li&gt;Sensitive information and secrets&lt;/li&gt; 
 &lt;li&gt;Software licenses&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Trivy supports most popular programming languages, operating systems, and platforms. For a complete list, see the &lt;a href="https://trivy.dev/latest/docs/coverage/"&gt;Scanning Coverage&lt;/a&gt; page.&lt;/p&gt; 
&lt;p&gt;To learn more, go to the &lt;a href="https://trivy.dev"&gt;Trivy homepage&lt;/a&gt; for feature highlights, or to the &lt;a href="https://trivy.dev/latest/docs/"&gt;Documentation site&lt;/a&gt; for detailed information.&lt;/p&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;h3&gt;Get Trivy&lt;/h3&gt; 
&lt;p&gt;Trivy is available in most common distribution channels. The full list of installation options is available in the &lt;a href="https://trivy.dev/latest/getting-started/installation/"&gt;Installation&lt;/a&gt; page. Here are a few popular examples:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;brew install trivy&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;docker run aquasec/trivy&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Download binary from &lt;a href="https://github.com/aquasecurity/trivy/releases/latest/"&gt;https://github.com/aquasecurity/trivy/releases/latest/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;See &lt;a href="https://trivy.dev/latest/getting-started/installation/"&gt;Installation&lt;/a&gt; for more&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Trivy is integrated with many popular platforms and applications. The complete list of integrations is available in the &lt;a href="https://trivy.dev/latest/ecosystem/"&gt;Ecosystem&lt;/a&gt; page. Here are a few popular examples:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/aquasecurity/trivy-action"&gt;GitHub Actions&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/aquasecurity/trivy-operator"&gt;Kubernetes operator&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/aquasecurity/trivy-vscode-extension"&gt;VS Code plugin&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;See &lt;a href="https://trivy.dev/latest/ecosystem/"&gt;Ecosystem&lt;/a&gt; for more&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Canary builds&lt;/h3&gt; 
&lt;p&gt;There are canary builds (&lt;a href="https://hub.docker.com/r/aquasec/trivy/tags?page=1&amp;amp;name=canary"&gt;Docker Hub&lt;/a&gt;, &lt;a href="https://github.com/aquasecurity/trivy/pkgs/container/trivy/75776514?tag=canary"&gt;GitHub&lt;/a&gt;, &lt;a href="https://gallery.ecr.aws/aquasecurity/trivy#canary"&gt;ECR&lt;/a&gt; images and &lt;a href="https://github.com/aquasecurity/trivy/actions/workflows/canary.yaml"&gt;binaries&lt;/a&gt;) as generated every push to main branch.&lt;/p&gt; 
&lt;p&gt;Please be aware: canary builds might have critical bugs, it's not recommended for use in production.&lt;/p&gt; 
&lt;h3&gt;General usage&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;trivy &amp;lt;target&amp;gt; [--scanners &amp;lt;scanner1,scanner2&amp;gt;] &amp;lt;subject&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Examples:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;trivy image python:3.4-alpine
&lt;/code&gt;&lt;/pre&gt; 
&lt;details&gt; 
 &lt;summary&gt;Result&lt;/summary&gt; 
 &lt;p&gt;&lt;a href="https://user-images.githubusercontent.com/1161307/171013513-95f18734-233d-45d3-aaf5-d6aec687db0e.mov"&gt;https://user-images.githubusercontent.com/1161307/171013513-95f18734-233d-45d3-aaf5-d6aec687db0e.mov&lt;/a&gt;&lt;/p&gt; 
&lt;/details&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;trivy fs --scanners vuln,secret,misconfig myproject/
&lt;/code&gt;&lt;/pre&gt; 
&lt;details&gt; 
 &lt;summary&gt;Result&lt;/summary&gt; 
 &lt;p&gt;&lt;a href="https://user-images.githubusercontent.com/1161307/171013917-b1f37810-f434-465c-b01a-22de036bd9b3.mov"&gt;https://user-images.githubusercontent.com/1161307/171013917-b1f37810-f434-465c-b01a-22de036bd9b3.mov&lt;/a&gt;&lt;/p&gt; 
&lt;/details&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;trivy k8s --report summary cluster
&lt;/code&gt;&lt;/pre&gt; 
&lt;details&gt; 
 &lt;summary&gt;Result&lt;/summary&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/aquasecurity/trivy/main/docs/imgs/trivy-k8s.png" alt="k8s summary" /&gt;&lt;/p&gt; 
&lt;/details&gt; 
&lt;h2&gt;FAQ&lt;/h2&gt; 
&lt;h3&gt;How to pronounce the name "Trivy"?&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;tri&lt;/code&gt; is pronounced like &lt;strong&gt;tri&lt;/strong&gt;gger, &lt;code&gt;vy&lt;/code&gt; is pronounced like en&lt;strong&gt;vy&lt;/strong&gt;.&lt;/p&gt; 
&lt;h2&gt;Want more? Check out Aqua&lt;/h2&gt; 
&lt;p&gt;If you liked Trivy, you will love Aqua which builds on top of Trivy to provide even more enhanced capabilities for a complete security management offering.&lt;br /&gt; You can find a high level comparison table specific to Trivy users &lt;a href="https://trivy.dev/latest/commercial/compare/"&gt;here&lt;/a&gt;. In addition check out the &lt;a href="https://aquasec.com"&gt;https://aquasec.com&lt;/a&gt; website for more information about our products and services. If you'd like to contact Aqua or request a demo, please use this form: &lt;a href="https://www.aquasec.com/demo"&gt;https://www.aquasec.com/demo&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Community&lt;/h2&gt; 
&lt;p&gt;Trivy is an &lt;a href="https://aquasec.com"&gt;Aqua Security&lt;/a&gt; open source project.&lt;br /&gt; Learn about our open source work and portfolio &lt;a href="https://www.aquasec.com/products/open-source-projects/"&gt;here&lt;/a&gt;.&lt;br /&gt; Contact us about any matter by opening a GitHub Discussion &lt;a href="https://github.com/aquasecurity/trivy/discussions"&gt;here&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Please ensure to abide by our &lt;a href="https://github.com/aquasecurity/community/raw/main/CODE_OF_CONDUCT.md"&gt;Code of Conduct&lt;/a&gt; during all interactions.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>microsoft/typescript-go</title>
      <link>https://github.com/microsoft/typescript-go</link>
      <description>&lt;p&gt;Staging repo for development of native port of TypeScript&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;TypeScript 7&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://devblogs.microsoft.com/typescript/typescript-native-port/"&gt;Not sure what this is? Read the announcement post!&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Preview&lt;/h2&gt; 
&lt;p&gt;A preview build is available on npm as &lt;a href="https://www.npmjs.com/package/@typescript/native-preview"&gt;&lt;code&gt;@typescript/native-preview&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;npm install @typescript/native-preview
npx tsgo # Use this as you would tsc.
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;A preview VS Code extension is &lt;a href="https://marketplace.visualstudio.com/items?itemName=TypeScriptTeam.native-preview"&gt;available on the VS Code marketplace&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;To use this, set this in your VS Code settings:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
    "typescript.experimental.useTsgo": true
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;What Works So Far?&lt;/h2&gt; 
&lt;p&gt;This is still a work in progress and is not yet at full feature parity with TypeScript. Bugs may exist. Please check this list carefully before logging a new issue or assuming an intentional change.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Feature&lt;/th&gt; 
   &lt;th&gt;Status&lt;/th&gt; 
   &lt;th&gt;Notes&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Program creation&lt;/td&gt; 
   &lt;td&gt;done&lt;/td&gt; 
   &lt;td&gt;Same files and module resolution as TS 5.8. Not all resolution modes supported yet.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Parsing/scanning&lt;/td&gt; 
   &lt;td&gt;done&lt;/td&gt; 
   &lt;td&gt;Exact same syntax errors as TS 5.8&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Commandline and &lt;code&gt;tsconfig.json&lt;/code&gt; parsing&lt;/td&gt; 
   &lt;td&gt;mostly done&lt;/td&gt; 
   &lt;td&gt;Missing --help, --init.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Type resolution&lt;/td&gt; 
   &lt;td&gt;done&lt;/td&gt; 
   &lt;td&gt;Same types as TS 5.8.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Type checking&lt;/td&gt; 
   &lt;td&gt;done&lt;/td&gt; 
   &lt;td&gt;Same errors, locations, and messages as TS 5.8. Types printback in errors may display differently.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;JavaScript-specific inference and JSDoc&lt;/td&gt; 
   &lt;td&gt;in progress&lt;/td&gt; 
   &lt;td&gt;Mostly complete, but intentionally lacking some features. Declaration emit not complete.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;JSX&lt;/td&gt; 
   &lt;td&gt;done&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Declaration emit&lt;/td&gt; 
   &lt;td&gt;in progress&lt;/td&gt; 
   &lt;td&gt;Most common features are in place, but some edge cases and feature flags are still unhandled.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Emit (JS output)&lt;/td&gt; 
   &lt;td&gt;in progress&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;target: esnext&lt;/code&gt; well-supported, other targets may have gaps.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Watch mode&lt;/td&gt; 
   &lt;td&gt;prototype&lt;/td&gt; 
   &lt;td&gt;Watches files and rebuilds, but no incremental rechecking. Not optimized.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Build mode / project references&lt;/td&gt; 
   &lt;td&gt;done&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Incremental build&lt;/td&gt; 
   &lt;td&gt;done&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Language service (LSP)&lt;/td&gt; 
   &lt;td&gt;in progress&lt;/td&gt; 
   &lt;td&gt;Some functionality (errors, hover, go to def, refs, sig help). More features coming soon.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;API&lt;/td&gt; 
   &lt;td&gt;not ready&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Definitions:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;done&lt;/strong&gt; aka "believed done": We're not currently aware of any deficits or major left work to do. OK to log bugs&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;in progress&lt;/strong&gt;: currently being worked on; some features may work and some might not. OK to log panics, but nothing else please&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;prototype&lt;/strong&gt;: proof-of-concept only; do not log bugs&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;not ready&lt;/strong&gt;: either haven't even started yet, or far enough from ready that you shouldn't bother messing with it yet&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Other Notes&lt;/h2&gt; 
&lt;p&gt;Long-term, we expect that this repo and its contents will be merged into &lt;code&gt;microsoft/TypeScript&lt;/code&gt;. As a result, the repo and issue tracker for typescript-go will eventually be closed, so treat discussions/issues accordingly.&lt;/p&gt; 
&lt;p&gt;For a list of intentional changes with respect to TypeScript 5.7, see CHANGES.md.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;This project welcomes contributions and suggestions. Most contributions require you to agree to a Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us the rights to use your contribution. For details, visit &lt;a href="https://cla.opensource.microsoft.com"&gt;Contributor License Agreements&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;When you submit a pull request, a CLA bot will automatically determine whether you need to provide a CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions provided by the bot. You will only need to do this once across all repos using our CLA.&lt;/p&gt; 
&lt;p&gt;This project has adopted the &lt;a href="https://opensource.microsoft.com/codeofconduct/"&gt;Microsoft Open Source Code of Conduct&lt;/a&gt;. For more information see the &lt;a href="https://opensource.microsoft.com/codeofconduct/faq/"&gt;Code of Conduct FAQ&lt;/a&gt; or contact &lt;a href="mailto:opencode@microsoft.com"&gt;opencode@microsoft.com&lt;/a&gt; with any additional questions or comments.&lt;/p&gt; 
&lt;h2&gt;Trademarks&lt;/h2&gt; 
&lt;p&gt;This project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft trademarks or logos is subject to and must follow &lt;a href="https://www.microsoft.com/legal/intellectualproperty/trademarks/usage/general"&gt;Microsoft's Trademark &amp;amp; Brand Guidelines&lt;/a&gt;. Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship. Any use of third-party trademarks or logos are subject to those third-party's policies.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>netbirdio/netbird</title>
      <link>https://github.com/netbirdio/netbird</link>
      <description>&lt;p&gt;Connect your devices into a secure WireGuard¬Æ-based overlay network with SSO, MFA and granular access controls.&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;br /&gt; 
 &lt;br /&gt; 
 &lt;p align="center"&gt; &lt;img width="234" src="https://raw.githubusercontent.com/netbirdio/netbird/main/docs/media/logo-full.png" /&gt; &lt;/p&gt; 
 &lt;p&gt; &lt;a href="https://img.shields.io/badge/license-BSD--3-blue)"&gt; &lt;img src="https://sonarcloud.io/api/project_badges/measure?project=netbirdio_netbird&amp;amp;metric=alert_status" /&gt; &lt;/a&gt; &lt;a href="https://github.com/netbirdio/netbird/raw/main/LICENSE"&gt; &lt;img src="https://img.shields.io/badge/license-BSD--3-blue" /&gt; &lt;/a&gt; &lt;br /&gt; &lt;a href="https://docs.netbird.io/slack-url"&gt; &lt;img src="https://img.shields.io/badge/slack-@netbird-red.svg?logo=slack" /&gt; &lt;/a&gt; &lt;a href="https://forum.netbird.io"&gt; &lt;img src="https://img.shields.io/badge/community forum-@netbird-red.svg?logo=discourse" /&gt; &lt;/a&gt; &lt;br /&gt; &lt;a href="https://gurubase.io/g/netbird"&gt; &lt;img src="https://img.shields.io/badge/Gurubase-Ask%20NetBird%20Guru-006BFF" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;/div&gt; 
&lt;p align="center"&gt; &lt;strong&gt; Start using NetBird at &lt;a href="https://netbird.io/pricing"&gt;netbird.io&lt;/a&gt; &lt;br /&gt; See &lt;a href="https://netbird.io/docs/"&gt;Documentation&lt;/a&gt; &lt;br /&gt; Join our &lt;a href="https://docs.netbird.io/slack-url"&gt;Slack channel&lt;/a&gt; or our &lt;a href="https://forum.netbird.io"&gt;Community forum&lt;/a&gt; &lt;br /&gt; &lt;/strong&gt; &lt;br /&gt; &lt;a href="https://registry.terraform.io/providers/netbirdio/netbird/latest"&gt; New: NetBird terraform provider &lt;/a&gt; &lt;/p&gt; 
&lt;br /&gt; 
&lt;p&gt;&lt;strong&gt;NetBird combines a configuration-free peer-to-peer private network and a centralized access control system in a single platform, making it easy to create secure private networks for your organization or home.&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Connect.&lt;/strong&gt; NetBird creates a WireGuard-based overlay network that automatically connects your machines over an encrypted tunnel, leaving behind the hassle of opening ports, complex firewall rules, VPN gateways, and so forth.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Secure.&lt;/strong&gt; NetBird enables secure remote access by applying granular access policies while allowing you to manage them intuitively from a single place. Works universally on any infrastructure.&lt;/p&gt; 
&lt;h3&gt;Open Source Network Security in a Single Platform&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/10cec749-bb56-4ab3-97af-4e38850108d2"&gt;https://github.com/user-attachments/assets/10cec749-bb56-4ab3-97af-4e38850108d2&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;NetBird on Lawrence Systems (Video)&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=Kwrff6h0rEw"&gt;&lt;img src="https://img.youtube.com/vi/Kwrff6h0rEw/0.jpg" alt="Watch the video" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Key features&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Connectivity&lt;/th&gt; 
   &lt;th&gt;Management&lt;/th&gt; 
   &lt;th&gt;Security&lt;/th&gt; 
   &lt;th&gt;Automation&lt;/th&gt; 
   &lt;th&gt;Platforms&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] Kernel WireGuard&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] &lt;a href="https://github.com/netbirdio/dashboard"&gt;Admin Web UI&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] &lt;a href="https://docs.netbird.io/how-to/installation#running-net-bird-with-sso-login"&gt;SSO &amp;amp; MFA support&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] &lt;a href="https://docs.netbird.io/api"&gt;Public API&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] Linux&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] Peer-to-peer connections&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] Auto peer discovery and configuration&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] &lt;a href="https://docs.netbird.io/how-to/manage-network-access"&gt;Access control - groups &amp;amp; rules&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] &lt;a href="https://docs.netbird.io/how-to/register-machines-using-setup-keys"&gt;Setup keys for bulk network provisioning&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] Mac&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] Connection relay fallback&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] &lt;a href="https://docs.netbird.io/selfhosted/identity-providers"&gt;IdP integrations&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] &lt;a href="https://docs.netbird.io/how-to/audit-events-logging"&gt;Activity logging&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] &lt;a href="https://docs.netbird.io/selfhosted/selfhosted-quickstart"&gt;Self-hosting quickstart script&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] Windows&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] &lt;a href="https://docs.netbird.io/how-to/routing-traffic-to-private-networks"&gt;Routes to external networks&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] &lt;a href="https://docs.netbird.io/how-to/manage-dns-in-your-network"&gt;Private DNS&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] &lt;a href="https://docs.netbird.io/how-to/manage-posture-checks"&gt;Device posture checks&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] IdP groups sync with JWT&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] Android&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] NAT traversal with BPF&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] &lt;a href="https://docs.netbird.io/how-to/add-users-to-your-network"&gt;Multiuser support&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] Peer-to-peer encryption&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] iOS&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] &lt;a href="https://netbird.io/knowledge-hub/the-first-quantum-resistant-mesh-vpn"&gt;Quantum-resistance with Rosenpass&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] OpenWRT&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] &lt;a href="https://docs.netbird.io/how-to/enforce-periodic-user-authentication"&gt;Periodic re-authentication&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] &lt;a href="https://docs.netbird.io/how-to/netbird-on-faas"&gt;Serverless&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] Docker&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Quickstart with NetBird Cloud&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Download and install NetBird at &lt;a href="https://app.netbird.io/install"&gt;https://app.netbird.io/install&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Follow the steps to sign-up with Google, Microsoft, GitHub or your email address.&lt;/li&gt; 
 &lt;li&gt;Check NetBird &lt;a href="https://app.netbird.io/"&gt;admin UI&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Add more machines.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Quickstart with self-hosted NetBird&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;This is the quickest way to try self-hosted NetBird. It should take around 5 minutes to get started if you already have a public domain and a VM. Follow the &lt;a href="https://docs.netbird.io/selfhosted/selfhosted-guide#advanced-guide-with-a-custom-identity-provider"&gt;Advanced guide with a custom identity provider&lt;/a&gt; for installations with different IDPs.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;Infrastructure requirements:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;A Linux VM with at least &lt;strong&gt;1CPU&lt;/strong&gt; and &lt;strong&gt;2GB&lt;/strong&gt; of memory.&lt;/li&gt; 
 &lt;li&gt;The VM should be publicly accessible on TCP ports &lt;strong&gt;80&lt;/strong&gt; and &lt;strong&gt;443&lt;/strong&gt; and UDP ports: &lt;strong&gt;3478&lt;/strong&gt;, &lt;strong&gt;49152-65535&lt;/strong&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Public domain&lt;/strong&gt; name pointing to the VM.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Software requirements:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Docker installed on the VM with the docker-compose plugin (&lt;a href="https://docs.docker.com/engine/install/"&gt;Docker installation guide&lt;/a&gt;) or docker with docker-compose in version 2 or higher.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://jqlang.github.io/jq/"&gt;jq&lt;/a&gt; installed. In most distributions Usually available in the official repositories and can be installed with &lt;code&gt;sudo apt install jq&lt;/code&gt; or &lt;code&gt;sudo yum install jq&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://curl.se/"&gt;curl&lt;/a&gt; installed. Usually available in the official repositories and can be installed with &lt;code&gt;sudo apt install curl&lt;/code&gt; or &lt;code&gt;sudo yum install curl&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Steps&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Download and run the installation script:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;export NETBIRD_DOMAIN=netbird.example.com; curl -fsSL https://github.com/netbirdio/netbird/releases/latest/download/getting-started-with-zitadel.sh | bash
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;Once finished, you can manage the resources via &lt;code&gt;docker-compose&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;A bit on NetBird internals&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Every machine in the network runs &lt;a href="https://raw.githubusercontent.com/netbirdio/netbird/main/client/"&gt;NetBird Agent (or Client)&lt;/a&gt; that manages WireGuard.&lt;/li&gt; 
 &lt;li&gt;Every agent connects to &lt;a href="https://raw.githubusercontent.com/netbirdio/netbird/main/management/"&gt;Management Service&lt;/a&gt; that holds network state, manages peer IPs, and distributes network updates to agents (peers).&lt;/li&gt; 
 &lt;li&gt;NetBird agent uses WebRTC ICE implemented in &lt;a href="https://github.com/pion/ice"&gt;pion/ice library&lt;/a&gt; to discover connection candidates when establishing a peer-to-peer connection between machines.&lt;/li&gt; 
 &lt;li&gt;Connection candidates are discovered with the help of &lt;a href="https://en.wikipedia.org/wiki/STUN"&gt;STUN&lt;/a&gt; servers.&lt;/li&gt; 
 &lt;li&gt;Agents negotiate a connection through &lt;a href="https://raw.githubusercontent.com/netbirdio/netbird/main/signal/"&gt;Signal Service&lt;/a&gt; passing p2p encrypted messages with candidates.&lt;/li&gt; 
 &lt;li&gt;Sometimes the NAT traversal is unsuccessful due to strict NATs (e.g. mobile carrier-grade NAT) and a p2p connection isn't possible. When this occurs the system falls back to a relay server called &lt;a href="https://en.wikipedia.org/wiki/Traversal_Using_Relays_around_NAT"&gt;TURN&lt;/a&gt;, and a secure WireGuard tunnel is established via the TURN server.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://github.com/coturn/coturn"&gt;Coturn&lt;/a&gt; is the one that has been successfully used for STUN and TURN in NetBird setups.&lt;/p&gt; 
&lt;p float="left" align="middle"&gt; &lt;img src="https://docs.netbird.io/docs-static/img/architecture/high-level-dia.png" width="700" /&gt; &lt;/p&gt; 
&lt;p&gt;See a complete &lt;a href="https://docs.netbird.io/about-netbird/how-netbird-works#architecture"&gt;architecture overview&lt;/a&gt; for details.&lt;/p&gt; 
&lt;h3&gt;Community projects&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/physk/netbird-installer"&gt;NetBird installer script&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://galaxy.ansible.com/ui/repo/published/dominion_solutions/netbird/"&gt;NetBird ansible collection by Dominion Solutions&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: The &lt;code&gt;main&lt;/code&gt; branch may be in an &lt;em&gt;unstable or even broken state&lt;/em&gt; during development. For stable versions, see &lt;a href="https://github.com/netbirdio/netbird/releases"&gt;releases&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Support acknowledgement&lt;/h3&gt; 
&lt;p&gt;In November 2022, NetBird joined the &lt;a href="https://www.forschung-it-sicherheit-kommunikationssysteme.de/foerderung/bekanntmachungen/startup-secure"&gt;StartUpSecure program&lt;/a&gt; sponsored by The Federal Ministry of Education and Research of The Federal Republic of Germany. Together with &lt;a href="https://cispa.de/en"&gt;CISPA Helmholtz Center for Information Security&lt;/a&gt; NetBird brings the security best practices and simplicity to private networking.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://user-images.githubusercontent.com/700848/203091324-c6d311a0-22b5-4b05-a288-91cbc6cdcc46.png" alt="CISPA_Logo_BLACK_EN_RZ_RGB (1)" /&gt;&lt;/p&gt; 
&lt;h3&gt;Testimonials&lt;/h3&gt; 
&lt;p&gt;We use open-source technologies like &lt;a href="https://www.wireguard.com/"&gt;WireGuard¬Æ&lt;/a&gt;, &lt;a href="https://github.com/pion/ice"&gt;Pion ICE (WebRTC)&lt;/a&gt;, &lt;a href="https://github.com/coturn/coturn"&gt;Coturn&lt;/a&gt;, and &lt;a href="https://rosenpass.eu"&gt;Rosenpass&lt;/a&gt;. We very much appreciate the work these guys are doing and we'd greatly appreciate if you could support them in any way (e.g., by giving a star or a contribution).&lt;/p&gt; 
&lt;h3&gt;Legal&lt;/h3&gt; 
&lt;p&gt;This repository is licensed under BSD-3-Clause license that applies to all parts of the repository except for the directories management/, signal/ and relay/. Those directories are licensed under the GNU Affero General Public License version 3.0 (AGPLv3). See the respective LICENSE files inside each directory.&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;WireGuard&lt;/em&gt; and the &lt;em&gt;WireGuard&lt;/em&gt; logo are &lt;a href="https://www.wireguard.com/trademark-policy/"&gt;registered trademarks&lt;/a&gt; of Jason A. Donenfeld.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>fyne-io/fyne</title>
      <link>https://github.com/fyne-io/fyne</link>
      <description>&lt;p&gt;Cross platform GUI toolkit in Go inspired by Material Design&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;a href="https://pkg.go.dev/fyne.io/fyne/v2?tab=doc" title="Go API Reference" rel="nofollow"&gt;&lt;img src="https://img.shields.io/badge/go-documentation-blue.svg?style=flat" alt="Go API Reference" /&gt;&lt;/a&gt; &lt;a href="https://img.shields.io/github/v/release/fyne-io/fyne?include_prereleases" title="Latest Release" rel="nofollow"&gt;&lt;img src="https://img.shields.io/github/v/release/fyne-io/fyne?include_prereleases" alt="Latest Release" /&gt;&lt;/a&gt; &lt;a href="https://gophers.slack.com/messages/fyne"&gt;&lt;img src="https://img.shields.io/badge/join-us%20on%20slack-gray.svg?longCache=true&amp;amp;logo=slack&amp;amp;colorB=blue" alt="Join us on Slack" /&gt;&lt;/a&gt; &lt;br /&gt; &lt;a href="https://goreportcard.com/report/fyne.io/fyne/v2"&gt;&lt;img src="https://goreportcard.com/badge/fyne.io/fyne/v2" alt="Code Status" /&gt;&lt;/a&gt; &lt;a href="https://github.com/fyne-io/fyne/actions"&gt;&lt;img src="https://github.com/fyne-io/fyne/workflows/Platform%20Tests/badge.svg?sanitize=true" alt="Build Status" /&gt;&lt;/a&gt; &lt;a href="https://coveralls.io/github/fyne-io/fyne?branch=develop"&gt;&lt;img src="https://coveralls.io/repos/github/fyne-io/fyne/badge.svg?branch=develop" alt="Coverage Status" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;h1&gt;About&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://fyne.io"&gt;Fyne&lt;/a&gt; is an easy-to-use UI toolkit and app API written in Go. It is designed to build applications that run on desktop and mobile devices with a single codebase.&lt;/p&gt; 
&lt;h1&gt;Prerequisites&lt;/h1&gt; 
&lt;p&gt;To develop apps using Fyne you will need Go version 1.17 or later, a C compiler and your system's development tools. If you're not sure if that's all installed or you don't know how then check out our &lt;a href="https://fyne.io/develop/"&gt;Getting Started&lt;/a&gt; document.&lt;/p&gt; 
&lt;p&gt;Using the standard go tools you can install Fyne's core library using:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;go get fyne.io/fyne/v2@latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;After importing a new module, run the following command before compiling the code for the first time. Avoid running it before writing code that uses the module to prevent accidental removal of dependencies:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;go mod tidy
&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;Widget demo&lt;/h1&gt; 
&lt;p&gt;To run a showcase of the features of Fyne execute the following:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;go install fyne.io/fyne/v2/cmd/fyne_demo@latest
fyne_demo
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;And you should see something like this (after you click a few buttons):&lt;/p&gt; 
&lt;p align="center" markdown="1" style="max-width: 100%"&gt; &lt;img src="https://raw.githubusercontent.com/fyne-io/fyne/master/img/widgets-dark.png" width="752" alt="Fyne Demo Dark Theme" style="max-width: 100%" /&gt; &lt;/p&gt; 
&lt;p&gt;Or if you are using the light theme:&lt;/p&gt; 
&lt;p align="center" markdown="1" style="max-width: 100%"&gt; &lt;img src="https://raw.githubusercontent.com/fyne-io/fyne/master/img/widgets-light.png" width="752" alt="Fyne Demo Light Theme" style="max-width: 100%" /&gt; &lt;/p&gt; 
&lt;p&gt;And even running on a mobile device:&lt;/p&gt; 
&lt;p align="center" markdown="1" style="max-width: 100%"&gt; &lt;img src="https://raw.githubusercontent.com/fyne-io/fyne/master/img/widgets-mobile-light.png" width="348" alt="Fyne Demo Mobile Light Theme" style="max-width: 100%" /&gt; &lt;/p&gt; 
&lt;h1&gt;Getting Started&lt;/h1&gt; 
&lt;p&gt;Fyne is designed to be really easy to code with. If you have followed the prerequisite steps above then all you need is a Go IDE (or a text editor).&lt;/p&gt; 
&lt;p&gt;Open a new file and you're ready to write your first app!&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;package main

import (
	"fyne.io/fyne/v2/app"
	"fyne.io/fyne/v2/container"
	"fyne.io/fyne/v2/widget"
)

func main() {
	a := app.New()
	w := a.NewWindow("Hello")

	hello := widget.NewLabel("Hello Fyne!")
	w.SetContent(container.NewVBox(
		hello,
		widget.NewButton("Hi!", func() {
			hello.SetText("Welcome :)")
		}),
	))

	w.ShowAndRun()
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;And you can run that simply as:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;go run main.go
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE]&lt;br /&gt; The first compilation of Fyne on Windows &lt;em&gt;can&lt;/em&gt; take up to 10 minutes, depending on your hardware. Subsequent builds will be fast.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;It should look like this:&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;table cellpadding="0" cellspacing="0" style="margin: auto; border-collapse: collapse;"&gt; 
  &lt;tbody&gt;
   &lt;tr style="border: none;"&gt;
    &lt;td style="border: none;"&gt; &lt;img src="https://raw.githubusercontent.com/fyne-io/fyne/master/img/hello-light.png" width="207" alt="Fyne Hello Dark Theme" /&gt; &lt;/td&gt;
    &lt;td style="border: none;"&gt; &lt;img src="https://raw.githubusercontent.com/fyne-io/fyne/master/img/hello-dark.png" width="207" alt="Fyne Hello Dark Theme" /&gt; &lt;/td&gt;
   &lt;/tr&gt; 
  &lt;/tbody&gt;
 &lt;/table&gt; 
&lt;/div&gt; 
&lt;h2&gt;Run in mobile simulation&lt;/h2&gt; 
&lt;p&gt;There is a helpful mobile simulation mode that gives a hint of how your app would work on a mobile device:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;go run -tags mobile main.go
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Another option is to use &lt;code&gt;fyne&lt;/code&gt; command, see &lt;a href="https://raw.githubusercontent.com/fyne-io/fyne/master/#packaging-for-mobile"&gt;Packaging for mobile&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;Installing&lt;/h1&gt; 
&lt;p&gt;Using &lt;code&gt;go install&lt;/code&gt; will copy the executable into your go &lt;code&gt;bin&lt;/code&gt; dir. To install the application with icons etc into your operating system's standard application location you can use the fyne utility and the "install" subcommand.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;go install fyne.io/tools/cmd/fyne@latest
fyne install
&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;Packaging for mobile&lt;/h1&gt; 
&lt;p&gt;To run on a mobile device it is necessary to package up the application. To do this we can use the fyne utility "package" subcommand. You will need to add appropriate parameters as prompted, but the basic command is shown below. Once packaged you can install using the platform development tools or the fyne "install" subcommand.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;fyne package -os android -appID my.domain.appname
fyne install -os android
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The built Android application can run either in a real device or an Android emulator. However, building for iOS is slightly different. If the "-os" argument is "ios", it is build only for a real iOS device. Specify "-os" to "iossimulator" allows the application be able to run in an iOS simulator:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;fyne package -os ios -appID my.domain.appname
fyne package -os iossimulator -appID my.domain.appname
&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;Preparing a release&lt;/h1&gt; 
&lt;p&gt;Using the fyne utility "release" subcommand you can package up your app for release to app stores and market places. Make sure you have the standard build tools installed and have followed the platform documentation for setting up accounts and signing. Then you can execute something like the following, notice the &lt;code&gt;-os ios&lt;/code&gt; parameter allows building an iOS app from macOS computer. Other combinations work as well :)&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ fyne release -os ios -certificate "Apple Distribution" -profile "My App Distribution" -appID "com.example.myapp"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The above command will create a '.ipa' file that can then be uploaded to the iOS App Store.&lt;/p&gt; 
&lt;h1&gt;Documentation&lt;/h1&gt; 
&lt;p&gt;More documentation is available at the &lt;a href="https://developer.fyne.io/"&gt;Fyne developer website&lt;/a&gt; or on &lt;a href="https://pkg.go.dev/fyne.io/fyne/v2?tab=doc"&gt;pkg.go.dev&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;Examples&lt;/h1&gt; 
&lt;p&gt;You can find many example applications in the &lt;a href="https://github.com/fyne-io/examples/"&gt;examples repository&lt;/a&gt;. Alternatively a list of applications using fyne can be found at &lt;a href="https://apps.fyne.io/"&gt;our website&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;Shipping the Fyne Toolkit&lt;/h1&gt; 
&lt;p&gt;All Fyne apps will work without pre-installed libraries, this is one reason the apps are so portable. However, if looking to support Fyne in a bigger way on your operating system then you can install some utilities that help to make a more complete experience.&lt;/p&gt; 
&lt;h2&gt;Additional apps&lt;/h2&gt; 
&lt;p&gt;It is recommended that you install the following additional apps:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;app&lt;/th&gt; 
   &lt;th&gt;go install&lt;/th&gt; 
   &lt;th&gt;description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;fyne_settings&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;fyne.io/fyne/v2/cmd/fyne_settings&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;A GUI for managing your global Fyne settings like theme and scaling&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;apps&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;github.com/fyne-io/apps&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;A graphical installer for the Fyne apps listed at &lt;a href="https://apps.fyne.io"&gt;https://apps.fyne.io&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;These are optional applications but can help to create a more complete desktop experience.&lt;/p&gt; 
&lt;h2&gt;FyneDesk (Linux / BSD)&lt;/h2&gt; 
&lt;p&gt;To go all the way with Fyne on your desktop / laptop computer you could install &lt;a href="https://github.com/fyshos/fynedesk"&gt;FyneDesk&lt;/a&gt; as well :)&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://fyshos.com/img/desktop.png" alt="FyneDesk screenshopt in dark mode" /&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>glanceapp/glance</title>
      <link>https://github.com/glanceapp/glance</link>
      <description>&lt;p&gt;A self-hosted dashboard that puts all your feeds in one place&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt;&lt;img src="https://raw.githubusercontent.com/glanceapp/glance/main/docs/logo.png" /&gt;&lt;/p&gt; 
&lt;h1 align="center"&gt;Glance&lt;/h1&gt; 
&lt;p align="center"&gt; &lt;a href="https://raw.githubusercontent.com/glanceapp/glance/main/#installation"&gt;Install&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/glanceapp/glance/main/docs/configuration.md#configuring-glance"&gt;Configuration&lt;/a&gt; ‚Ä¢ &lt;a href="https://discord.com/invite/7KQ7Xa9kJd"&gt;Discord&lt;/a&gt; ‚Ä¢ &lt;a href="https://github.com/sponsors/glanceapp"&gt;Sponsor&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/glanceapp/community-widgets"&gt;Community widgets&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/glanceapp/glance/main/docs/preconfigured-pages.md"&gt;Preconfigured pages&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/glanceapp/glance/main/docs/themes.md"&gt;Themes&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt;A lightweight, highly customizable dashboard that displays&lt;br /&gt; your feeds in a beautiful, streamlined interface&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/glanceapp/glance/main/docs/images/readme-main-image.png" alt="" /&gt;&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;h3&gt;Various widgets&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;RSS feeds&lt;/li&gt; 
 &lt;li&gt;Subreddit posts&lt;/li&gt; 
 &lt;li&gt;Hacker News posts&lt;/li&gt; 
 &lt;li&gt;Weather forecasts&lt;/li&gt; 
 &lt;li&gt;YouTube channel uploads&lt;/li&gt; 
 &lt;li&gt;Twitch channels&lt;/li&gt; 
 &lt;li&gt;Market prices&lt;/li&gt; 
 &lt;li&gt;Docker containers status&lt;/li&gt; 
 &lt;li&gt;Server stats&lt;/li&gt; 
 &lt;li&gt;Custom widgets&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/glanceapp/glance/main/docs/configuration.md#configuring-glance"&gt;and many more...&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Fast and lightweight&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Low memory usage&lt;/li&gt; 
 &lt;li&gt;Few dependencies&lt;/li&gt; 
 &lt;li&gt;Minimal vanilla JS&lt;/li&gt; 
 &lt;li&gt;Single &amp;lt;20mb binary available for multiple OSs &amp;amp; architectures and just as small Docker container&lt;/li&gt; 
 &lt;li&gt;Uncached pages usually load within ~1s (depending on internet speed and number of widgets)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Tons of customizability&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Different layouts&lt;/li&gt; 
 &lt;li&gt;As many pages/tabs as you need&lt;/li&gt; 
 &lt;li&gt;Numerous configuration options for each widget&lt;/li&gt; 
 &lt;li&gt;Multiple styles for some widgets&lt;/li&gt; 
 &lt;li&gt;Custom CSS&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Optimized for mobile devices&lt;/h3&gt; 
&lt;p&gt;Because you'll want to take it with you on the go.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/glanceapp/glance/main/docs/images/mobile-preview.png" alt="" /&gt;&lt;/p&gt; 
&lt;h3&gt;Themeable&lt;/h3&gt; 
&lt;p&gt;Easily create your own theme by tweaking a few numbers or choose from one of the &lt;a href="https://raw.githubusercontent.com/glanceapp/glance/main/docs/themes.md"&gt;already available themes&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/glanceapp/glance/main/docs/images/themes-example.png" alt="" /&gt;&lt;/p&gt; 
&lt;br /&gt; 
&lt;h2&gt;Configuration&lt;/h2&gt; 
&lt;p&gt;Configuration is done through YAML files, to learn more about how the layout works, how to add more pages and how to configure widgets, visit the &lt;a href="https://raw.githubusercontent.com/glanceapp/glance/main/docs/configuration.md#configuring-glance"&gt;configuration documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;Preview example configuration file&lt;/strong&gt;&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;pre&gt;&lt;code class="language-yaml"&gt;pages:
  - name: Home
    columns:
      - size: small
        widgets:
          - type: calendar
            first-day-of-week: monday

          - type: rss
            limit: 10
            collapse-after: 3
            cache: 12h
            feeds:
              - url: https://selfh.st/rss/
                title: selfh.st
                limit: 4
              - url: https://ciechanow.ski/atom.xml
              - url: https://www.joshwcomeau.com/rss.xml
                title: Josh Comeau
              - url: https://samwho.dev/rss.xml
              - url: https://ishadeed.com/feed.xml
                title: Ahmad Shadeed

          - type: twitch-channels
            channels:
              - theprimeagen
              - j_blow
              - piratesoftware
              - cohhcarnage
              - christitustech
              - EJ_SA

      - size: full
        widgets:
          - type: group
            widgets:
              - type: hacker-news
              - type: lobsters

          - type: videos
            channels:
              - UCXuqSBlHAE6Xw-yeJA0Tunw # Linus Tech Tips
              - UCR-DXc1voovS8nhAvccRZhg # Jeff Geerling
              - UCsBjURrPoezykLs9EqgamOA # Fireship
              - UCBJycsmduvYEL83R_U4JriQ # Marques Brownlee
              - UCHnyfMqiRRG1u-2MsSQLbXA # Veritasium

          - type: group
            widgets:
              - type: reddit
                subreddit: technology
                show-thumbnails: true
              - type: reddit
                subreddit: selfhosted
                show-thumbnails: true

      - size: small
        widgets:
          - type: weather
            location: London, United Kingdom
            units: metric
            hour-format: 12h

          - type: markets
            markets:
              - symbol: SPY
                name: S&amp;amp;P 500
              - symbol: BTC-USD
                name: Bitcoin
              - symbol: NVDA
                name: NVIDIA
              - symbol: AAPL
                name: Apple
              - symbol: MSFT
                name: Microsoft

          - type: releases
            cache: 1d
            repositories:
              - glanceapp/glance
              - go-gitea/gitea
              - immich-app/immich
              - syncthing/syncthing
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;br /&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;Choose one of the following methods:&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;Docker compose using provided directory structure (recommended)&lt;/strong&gt;&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;p&gt;Create a new directory called &lt;code&gt;glance&lt;/code&gt; as well as the template files within it by running:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;mkdir glance &amp;amp;&amp;amp; cd glance &amp;amp;&amp;amp; curl -sL https://github.com/glanceapp/docker-compose-template/archive/refs/heads/main.tar.gz | tar -xzf - --strip-components 2
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;em&gt;&lt;a href="https://github.com/glanceapp/docker-compose-template/tree/main/root"&gt;click here to view the files that will be created&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
 &lt;p&gt;Then, edit the following files as desired:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;code&gt;docker-compose.yml&lt;/code&gt; to configure the port, volumes and other containery things&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;config/home.yml&lt;/code&gt; to configure the widgets or layout of the home page&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;config/glance.yml&lt;/code&gt; if you want to change the theme or add more pages&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;details&gt; 
  &lt;summary&gt;Other files you may want to edit&lt;/summary&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;.env&lt;/code&gt; to configure environment variables that will be available inside configuration files&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;assets/user.css&lt;/code&gt; to add custom CSS&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/details&gt; 
 &lt;p&gt;When ready, run:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;docker compose up -d
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;If you encounter any issues, you can check the logs by running:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;docker compose logs
&lt;/code&gt;&lt;/pre&gt; 
 &lt;hr /&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;Docker compose manual&lt;/strong&gt;&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;p&gt;Create a &lt;code&gt;docker-compose.yml&lt;/code&gt; file with the following contents:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-yaml"&gt;services:
  glance:
    container_name: glance
    image: glanceapp/glance
    restart: unless-stopped
    volumes:
      - ./config:/app/config
    ports:
      - 8080:8080
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Then, create a new directory called &lt;code&gt;config&lt;/code&gt; and download the example starting &lt;a href="https://github.com/glanceapp/glance/raw/main/docs/glance.yml"&gt;&lt;code&gt;glance.yml&lt;/code&gt;&lt;/a&gt; file into it by running:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;mkdir config &amp;amp;&amp;amp; wget -O config/glance.yml https://raw.githubusercontent.com/glanceapp/glance/refs/heads/main/docs/glance.yml
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Feel free to edit the &lt;code&gt;glance.yml&lt;/code&gt; file to your liking, and when ready run:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;docker compose up -d
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;If you encounter any issues, you can check the logs by running:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;docker logs glance
&lt;/code&gt;&lt;/pre&gt; 
 &lt;hr /&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;Manual binary installation&lt;/strong&gt;&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;p&gt;Precompiled binaries are available for Linux, Windows and macOS (x86, x86_64, ARM and ARM64 architectures).&lt;/p&gt; 
 &lt;h3&gt;Linux&lt;/h3&gt; 
 &lt;p&gt;Visit the &lt;a href="https://github.com/glanceapp/glance/releases/latest"&gt;latest release page&lt;/a&gt; for available binaries. You can place the binary in &lt;code&gt;/opt/glance/&lt;/code&gt; and have it start with your server via a &lt;a href="https://linuxhandbook.com/create-systemd-services/"&gt;systemd service&lt;/a&gt;. By default, when running the binary, it will look for a &lt;code&gt;glance.yml&lt;/code&gt; file in the directory it's placed in. To specify a different path for the config file, use the &lt;code&gt;--config&lt;/code&gt; option:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;/opt/glance/glance --config /etc/glance.yml
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;To grab a starting template for the config file, run:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;wget https://raw.githubusercontent.com/glanceapp/glance/refs/heads/main/docs/glance.yml
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h3&gt;Windows&lt;/h3&gt; 
 &lt;p&gt;Download and extract the executable from the &lt;a href="https://github.com/glanceapp/glance/releases/latest"&gt;latest release&lt;/a&gt; (most likely the file called &lt;code&gt;glance-windows-amd64.zip&lt;/code&gt; if you're on a 64-bit system) and place it in a folder of your choice. Then, create a new text file called &lt;code&gt;glance.yml&lt;/code&gt; in the same folder and paste the content from &lt;a href="https://raw.githubusercontent.com/glanceapp/glance/refs/heads/main/docs/glance.yml"&gt;here&lt;/a&gt; in it. You should then be able to run the executable and access the dashboard by visiting &lt;code&gt;http://localhost:8080&lt;/code&gt; in your browser.&lt;/p&gt; 
 &lt;hr /&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;Other&lt;/strong&gt;&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;p&gt;Glance can also be installed through the following 3rd party channels:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://community-scripts.github.io/ProxmoxVE/scripts?id=glance"&gt;Proxmox VE Helper Script&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://search.nixos.org/packages?channel=unstable&amp;amp;show=glance"&gt;NixOS package&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://coolify.io/docs/services/glance/"&gt;Coolify.io&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;hr /&gt; 
&lt;/details&gt; 
&lt;br /&gt; 
&lt;h2&gt;Common issues&lt;/h2&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;Requests timing out&lt;/strong&gt;&lt;/summary&gt; 
 &lt;p&gt;The most common cause of this is when using Pi-Hole, AdGuard Home or other ad-blocking DNS services, which by default have a fairly low rate limit. Depending on the number of widgets you have in a single page, this limit can very easily be exceeded. To fix this, increase the rate limit in the settings of your DNS service.&lt;/p&gt; 
 &lt;p&gt;If using Podman, in some rare cases the timeout can be caused by an unknown issue, in which case it may be resolved by adding the following to the bottom of your &lt;code&gt;docker-compose.yml&lt;/code&gt; file:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-yaml"&gt;networks:
  podman:
    external: true
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;Broken layout for markets, bookmarks or other widgets&lt;/strong&gt;&lt;/summary&gt; 
 &lt;p&gt;This is almost always caused by the browser extension Dark Reader. To fix this, disable dark mode for the domain where Glance is hosted.&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;cannot unmarshal !!map into []glance.page&lt;/strong&gt;&lt;/summary&gt; 
 &lt;p&gt;The most common cause of this is having a &lt;code&gt;pages&lt;/code&gt; key in your &lt;code&gt;glance.yml&lt;/code&gt; and then also having a &lt;code&gt;pages&lt;/code&gt; key inside one of your included pages. To fix this, remove the &lt;code&gt;pages&lt;/code&gt; key from the top of your included pages.&lt;/p&gt; 
&lt;/details&gt; 
&lt;br /&gt; 
&lt;h2&gt;FAQ&lt;/h2&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;Does the information on the page update automatically?&lt;/strong&gt;&lt;/summary&gt; No, a page refresh is required to update the information. Some things do dynamically update where it makes sense, like the clock widget and the relative time showing how long ago something happened. 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;How frequently do widgets update?&lt;/strong&gt;&lt;/summary&gt; No requests are made periodically in the background, information is only fetched upon loading the page and then cached. The default cache lifetime is different for each widget and can be configured. 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;Can I create my own widgets?&lt;/strong&gt;&lt;/summary&gt; 
 &lt;p&gt;Yes, there are multiple ways to create custom widgets:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;code&gt;iframe&lt;/code&gt; widget - allows you to embed things from other websites&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;html&lt;/code&gt; widget - allows you to insert your own static HTML&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;extension&lt;/code&gt; widget - fetch HTML from a URL&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;custom-api&lt;/code&gt; widget - fetch JSON from a URL and render it using custom HTML&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;Can I change the title of a widget?&lt;/strong&gt;&lt;/summary&gt; 
 &lt;p&gt;Yes, the title of all widgets can be changed by specifying the &lt;code&gt;title&lt;/code&gt; property in the widget's configuration:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-yaml"&gt;- type: rss
  title: My custom title

- type: markets
  title: My custom title

- type: videos
  title: My custom title

# and so on for all widgets...
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;br /&gt; 
&lt;h2&gt;Feature requests&lt;/h2&gt; 
&lt;p&gt;New feature suggestions are always welcome and will be considered, though please keep in mind that some of them may be out of scope for what the project is trying to achieve (or is reasonably capable of). If you have an idea for a new feature and would like to share it, you can do so &lt;a href="https://github.com/glanceapp/glance/issues/new?template=feature_request.yml"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Feature requests are tagged with one of the following:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/glanceapp/glance/labels/roadmap"&gt;Roadmap&lt;/a&gt; - will be implemented in a future release&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/glanceapp/glance/labels/backlog"&gt;Backlog&lt;/a&gt; - may be implemented in the future but needs further feedback or interest from the community&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/glanceapp/glance/labels/icebox"&gt;Icebox&lt;/a&gt; - no plans to implement as it doesn't currently align with the project's goals or capabilities, may be revised at a later date&lt;/li&gt; 
&lt;/ul&gt; 
&lt;br /&gt; 
&lt;h2&gt;Building from source&lt;/h2&gt; 
&lt;p&gt;Choose one of the following methods:&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;Build binary with Go&lt;/strong&gt;&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;p&gt;Requirements: &lt;a href="https://go.dev/dl/"&gt;Go&lt;/a&gt; &amp;gt;= v1.23&lt;/p&gt; 
 &lt;p&gt;To build the project for your current OS and architecture, run:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;go build -o build/glance .
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;To build for a specific OS and architecture, run:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;GOOS=linux GOARCH=amd64 go build -o build/glance .
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;a href="https://go.dev/doc/install/source#:~:text=$GOOS%20and%20$GOARCH"&gt;&lt;em&gt;click here for a full list of GOOS and GOARCH combinations&lt;/em&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;Alternatively, if you just want to run the app without creating a binary, like when you're testing out changes, you can run:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;go run .
&lt;/code&gt;&lt;/pre&gt; 
 &lt;hr /&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;Build project and Docker image with Docker&lt;/strong&gt;&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;p&gt;Requirements: &lt;a href="https://docs.docker.com/engine/install/"&gt;Docker&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;To build the project and image using just Docker, run:&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;(replace &lt;code&gt;owner&lt;/code&gt; with your name or organization)&lt;/em&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;docker build -t owner/glance:latest .
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;If you wish to push the image to a registry (by default Docker Hub), run:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;docker push owner/glance:latest
&lt;/code&gt;&lt;/pre&gt; 
 &lt;hr /&gt; 
&lt;/details&gt; 
&lt;br /&gt; 
&lt;h2&gt;Contributing guidelines&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Before working on a new feature it's preferable to submit a feature request first and state that you'd like to implement it yourself&lt;/li&gt; 
 &lt;li&gt;Please don't submit PRs for feature requests that are either in the roadmap&lt;sup&gt;[1]&lt;/sup&gt;, backlog&lt;sup&gt;[2]&lt;/sup&gt; or icebox&lt;sup&gt;[3]&lt;/sup&gt;&lt;/li&gt; 
 &lt;li&gt;Use &lt;code&gt;dev&lt;/code&gt; for the base branch if you're adding new features or fixing bugs, otherwise use &lt;code&gt;main&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Avoid introducing new dependencies&lt;/li&gt; 
 &lt;li&gt;Avoid making backwards-incompatible configuration changes&lt;/li&gt; 
 &lt;li&gt;Avoid introducing new colors or hard-coding colors, use the standard &lt;code&gt;primary&lt;/code&gt;, &lt;code&gt;positive&lt;/code&gt; and &lt;code&gt;negative&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;For icons, try to use &lt;a href="https://heroicons.com/"&gt;heroicons&lt;/a&gt; where applicable&lt;/li&gt; 
 &lt;li&gt;Provide a screenshot of the changes if UI related where possible&lt;/li&gt; 
 &lt;li&gt;No &lt;code&gt;package.json&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;&lt;sup&gt;[1] [2] [3]&lt;/sup&gt;&lt;/strong&gt;&lt;/summary&gt; 
 &lt;p&gt;[1] The feature likely already has work put into it that may conflict with your implementation&lt;/p&gt; 
 &lt;p&gt;[2] The demand, implementation or functionality for this feature is not yet clear&lt;/p&gt; 
 &lt;p&gt;[3] No plans to add this feature for the time being&lt;/p&gt; 
&lt;/details&gt; 
&lt;br /&gt; 
&lt;h2&gt;Thank you&lt;/h2&gt; 
&lt;p&gt;To all the people who were generous enough to &lt;a href="https://github.com/sponsors/glanceapp"&gt;sponsor&lt;/a&gt; the project and to everyone who has contributed in any way, be it PRs, submitting issues, helping others in the discussions or Discord server, creating guides and tools or just mentioning Glance on social media. Your support is greatly appreciated and helps keep the project going.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>kubevirt/kubevirt</title>
      <link>https://github.com/kubevirt/kubevirt</link>
      <description>&lt;p&gt;Kubernetes Virtualization API and runtime in order to define and manage virtual machines.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;KubeVirt&lt;/h1&gt; 
&lt;p align="center"&gt; &lt;img src="https://github.com/kubevirt/community/raw/main/logo/KubeVirt_icon.png" width="100" /&gt; &lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://prow.ci.kubevirt.io/?job=push-kubevirt-main"&gt;&lt;img src="https://prow.ci.kubevirt.io/badge.svg?jobs=push-kubevirt-main" alt="Build Status" /&gt;&lt;/a&gt; &lt;a href="https://goreportcard.com/report/github.com/kubevirt/kubevirt"&gt;&lt;img src="https://goreportcard.com/badge/github.com/kubevirt/kubevirt" alt="Go Report Card" /&gt;&lt;/a&gt; &lt;a href="https://www.apache.org/licenses/LICENSE-2.0"&gt;&lt;img src="https://img.shields.io/github/license/kubevirt/kubevirt.svg?sanitize=true" alt="Licensed under Apache License version 2.0" /&gt;&lt;/a&gt; &lt;a href="https://coveralls.io/github/kubevirt/kubevirt?branch=main"&gt;&lt;img src="https://img.shields.io/coveralls/kubevirt/kubevirt/main.svg?sanitize=true" alt="Coverage Status" /&gt;&lt;/a&gt; &lt;a href="https://bestpractices.coreinfrastructure.org/projects/3203"&gt;&lt;img src="https://bestpractices.coreinfrastructure.org/projects/3203/badge" alt="CII Best Practices" /&gt;&lt;/a&gt; &lt;a href="https://kubernetes.slack.com/?redir=%2Farchives%2FC0163DT0R8X"&gt;&lt;img src="https://img.shields.io/badge/slack-@kubernetes/kubevirt--dev-40abb8.svg?logo=slack" alt="Visit our Slack channel" /&gt;&lt;/a&gt; &lt;a href="https://app.fossa.com/projects/custom%2B13072%2Fgit%40github.com%3Akubevirt%2Fkubevirt.git?ref=badge_shield"&gt;&lt;img src="https://app.fossa.com/api/projects/custom%2B13072%2Fgit%40github.com%3Akubevirt%2Fkubevirt.git.svg?type=shield" alt="FOSSA Status" /&gt;&lt;/a&gt; &lt;a href="https://sonarcloud.io/summary/new_code?id=kubevirt_kubevirt"&gt;&lt;img src="https://sonarcloud.io/api/project_badges/measure?project=kubevirt_kubevirt&amp;amp;metric=alert_status" alt="Quality Gate Status" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;strong&gt;KubeVirt&lt;/strong&gt; is a virtual machine management add-on for Kubernetes. The aim is to provide a common ground for virtualization solutions on top of Kubernetes.&lt;/p&gt; 
&lt;h2&gt;Introduction&lt;/h2&gt; 
&lt;h3&gt;Virtualization extension for Kubernetes&lt;/h3&gt; 
&lt;p&gt;At its core, KubeVirt extends &lt;a href="https://kubernetes.io"&gt;Kubernetes&lt;/a&gt; by adding additional virtualization resource types (especially the &lt;code&gt;VM&lt;/code&gt; type) through &lt;a href="https://kubernetes.io/docs/tasks/access-kubernetes-api/extend-api-custom-resource-definitions/"&gt;Kubernetes's Custom Resource Definitions API&lt;/a&gt;. By using this mechanism, the Kubernetes API can be used to manage these &lt;code&gt;VM&lt;/code&gt; resources alongside all other resources Kubernetes provides.&lt;/p&gt; 
&lt;p&gt;The resources themselves are not enough to launch virtual machines. For this to happen the &lt;em&gt;functionality and business logic&lt;/em&gt; needs to be added to the cluster. The functionality is not added to Kubernetes itself, but rather added to a Kubernetes cluster by &lt;em&gt;running&lt;/em&gt; additional controllers and agents on an existing cluster.&lt;/p&gt; 
&lt;p&gt;The necessary controllers and agents are provided by KubeVirt.&lt;/p&gt; 
&lt;p&gt;As of today KubeVirt can be used to declaratively&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Create a predefined VM&lt;/li&gt; 
 &lt;li&gt;Schedule a VM on a Kubernetes cluster&lt;/li&gt; 
 &lt;li&gt;Launch a VM&lt;/li&gt; 
 &lt;li&gt;Stop a VM&lt;/li&gt; 
 &lt;li&gt;Delete a VM&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://asciinema.org/a/497168"&gt;&lt;img src="https://asciinema.org/a/497168.svg?sanitize=true" width="50%" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;To start using KubeVirt&lt;/h2&gt; 
&lt;p&gt;Try our quickstart at &lt;a href="https://kubevirt.io/get_kubevirt/"&gt;kubevirt.io&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;See our user documentation at &lt;a href="https://kubevirt.io/user-guide"&gt;kubevirt.io/docs&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Once you have the basics, you can learn more about how to run KubeVirt and its newest features by taking a look at:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://kubevirt.io/blogs/"&gt;KubeVirt blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/channel/UC2FH36TbZizw25pVT1P3C3g"&gt;KubeVirt Youtube channel&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;To start developing KubeVirt&lt;/h2&gt; 
&lt;p&gt;To set up a development environment please read our &lt;a href="https://raw.githubusercontent.com/kubevirt/kubevirt/main/docs/getting-started.md"&gt;Getting Started Guide&lt;/a&gt;. To learn how to contribute, please read our &lt;a href="https://github.com/kubevirt/kubevirt/raw/main/CONTRIBUTING.md"&gt;contribution guide&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;You can learn more about how KubeVirt is designed (and why it is that way), and learn more about the major components by taking a look at &lt;a href="https://raw.githubusercontent.com/kubevirt/kubevirt/main/docs/"&gt;our developer documentation&lt;/a&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/kubevirt/kubevirt/main/docs/architecture.md"&gt;Architecture&lt;/a&gt; - High-level view on the architecture&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/kubevirt/kubevirt/main/docs/components.md"&gt;Components&lt;/a&gt; - Detailed look at all components&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://kubevirt.io/api-reference/"&gt;API Reference&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Useful links&lt;/h2&gt; 
&lt;p&gt;The KubeVirt SIG-release repo is responsible for information regarding upcoming and previous releases.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/kubevirt/sig-release/raw/main/releases/k8s-support-matrix.md"&gt;KubeVirt to Kubernetes version support matrix&lt;/a&gt; - Verify the versions of KubeVirt that are built and supported for your version of Kubernetes&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/kubevirt/sig-release/raw/main/upcoming-changes.md"&gt;Noteworthy changes for the next KubeVirt release&lt;/a&gt; - Pre-release notes for the upcoming release&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/kubevirt/sig-release/raw/main/releases/"&gt;Release schedule&lt;/a&gt; - For our current and previous releases&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Community&lt;/h2&gt; 
&lt;p&gt;If you got enough of code and want to speak to people, then you got a couple of options:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Follow us on &lt;a href="https://twitter.com/kubevirt"&gt;Twitter&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Chat with us on Slack via &lt;a href="https://kubernetes.slack.com/?redir=%2Farchives%2FC8ED7RKFE"&gt;#virtualization @ kubernetes.slack.com&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Discuss with us on the &lt;a href="https://groups.google.com/forum/#!forum/kubevirt-dev"&gt;kubevirt-dev Google Group&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Stay informed about designs and upcoming events by watching our &lt;a href="https://github.com/kubevirt/community/"&gt;community content&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Related resources&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://kubernetes.io"&gt;Kubernetes&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.libvirt.org"&gt;Libvirt&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://cockpit-project.org/"&gt;Cockpit&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/kubevirt/kubevirt.core"&gt;kubevirt.core&lt;/a&gt; Ansible collection&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Submitting patches&lt;/h3&gt; 
&lt;p&gt;When sending patches to the project, the submitter is required to certify that they have the legal right to submit the code. This is achieved by adding a line&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Signed-off-by: Real Name &amp;lt;email@address.com&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;to the bottom of every commit message. Existence of such a line certifies that the submitter has complied with the Developer's Certificate of Origin 1.1, (as defined in the file docs/developer-certificate-of-origin).&lt;/p&gt; 
&lt;p&gt;This line can be automatically added to a commit in the correct format, by using the '-s' option to 'git commit'.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;KubeVirt is distributed under the &lt;a href="http://www.apache.org/licenses/LICENSE-2.0.txt"&gt;Apache License, Version 2.0&lt;/a&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;This file is part of the KubeVirt project

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.

Copyright The KubeVirt Authors.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;FOSSA Status&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://app.fossa.com/projects/custom%2B13072%2Fgit%40github.com%3Akubevirt%2Fkubevirt.git?ref=badge_large"&gt;&lt;img src="https://app.fossa.com/api/projects/custom%2B13072%2Fgit%40github.com%3Akubevirt%2Fkubevirt.git.svg?type=large" alt="FOSSA Status" /&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>qualifire-dev/rogue</title>
      <link>https://github.com/qualifire-dev/rogue</link>
      <description>&lt;p&gt;Agents testing framework made easy&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Rogue - The AI Agent Evaluator&lt;/h1&gt; 
&lt;p&gt;&lt;img src="https://pixel.qualifire.ai/api/record/rogue" alt="" /&gt;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;img src="https://github.com/qualifire-dev/rogue/actions/workflows/test.yml/badge.svg?branch=main" alt="Tests" /&gt;&lt;/p&gt; 
 &lt;img src="https://raw.githubusercontent.com/qualifire-dev/rogue/main/freddy-rogue.png" width="200" /&gt; 
 &lt;p&gt;Join our &lt;a href="https://discord.gg/EUfAt7ZDeK"&gt;Discord community&lt;/a&gt;!&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;Rogue is a powerful tool designed to evaluate the performance, compliance, and reliability of AI agents. It pits a dynamic &lt;code&gt;EvaluatorAgent&lt;/code&gt; against your agent using various protocols, testing it with a range of scenarios to ensure it behaves exactly as intended.&lt;/p&gt; 
&lt;h2&gt;Architecture&lt;/h2&gt; 
&lt;p&gt;Rogue operates on a &lt;strong&gt;client-server architecture&lt;/strong&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Rogue Server&lt;/strong&gt;: Contains the core evaluation logic&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Client Interfaces&lt;/strong&gt;: Multiple interfaces that connect to the server: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;TUI (Terminal UI)&lt;/strong&gt;: Modern terminal interface built with Go and Bubble Tea&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Web UI&lt;/strong&gt;: Gradio-based web interface&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;CLI&lt;/strong&gt;: Command-line interface for automated evaluation and CI/CD&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;This architecture allows for flexible deployment and usage patterns, where the server can run independently and multiple clients can connect to it simultaneously.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/b5c04772-6916-4aab-825b-6a7476d77787"&gt;https://github.com/user-attachments/assets/b5c04772-6916-4aab-825b-6a7476d77787&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Supported Protocols &amp;amp; Transports:&lt;/h3&gt; 
&lt;p&gt;Rogue can communicate with your agent using various protocols and transports:&lt;/p&gt; 
&lt;h4&gt;A2A&lt;/h4&gt; 
&lt;p&gt;Rogue supports &lt;a href="https://a2a-protocol.org/latest/"&gt;Google's A2A&lt;/a&gt; protocol over these transports:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;HTTP&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;To integrate your agent with Rogue via A2A:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Build your agent using any framework of your choice&lt;/li&gt; 
 &lt;li&gt;Expose your agent through an A2A-compliant HTTP server&lt;/li&gt; 
 &lt;li&gt;Rogue will communicate with your agent using the standardized A2A protocol&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;The A2A protocol provides a standardized way for agents to communicate, including support for streaming responses, task management, and agent capabilities discovery.&lt;/p&gt; 
&lt;p&gt;For reference implementations, check out the A2A examples in the &lt;a href="https://raw.githubusercontent.com/qualifire-dev/rogue/main/examples/tshirt_store_agent/"&gt;&lt;code&gt;examples/tshirt_store_agent/&lt;/code&gt;&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/qualifire-dev/rogue/main/examples/tshirt_store_langgraph_agent/"&gt;&lt;code&gt;examples/tshirt_store_langgraph_agent/&lt;/code&gt;&lt;/a&gt; directories.&lt;/p&gt; 
&lt;h4&gt;MCP&lt;/h4&gt; 
&lt;p&gt;Rogue supports the &lt;a href="https://modelcontextprotocol.io/docs/getting-started/intro"&gt;Model Context Protocol (MCP)&lt;/a&gt; over these transports:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;SSE (Server-Sent Events)&lt;/li&gt; 
 &lt;li&gt;STREAMABLE_HTTP&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;To integrate your agent with Rogue via MCP:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Build your agent using any framework of your choice&lt;/li&gt; 
 &lt;li&gt;Wrap your agent with an MCP server that exposes a tool named &lt;code&gt;send_message&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Rogue will invoke this tool to communicate with and evaluate your agent&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;The &lt;code&gt;send_message&lt;/code&gt; tool should accept a message from Rogue and return your agent's response. This simple interface allows Rogue to interact with your agent regardless of its internal implementation.&lt;/p&gt; 
&lt;p&gt;For reference implementations, check out the MCP examples in the &lt;a href="https://raw.githubusercontent.com/qualifire-dev/rogue/main/examples/mcp/"&gt;&lt;code&gt;examples/mcp/&lt;/code&gt;&lt;/a&gt; directory, which demonstrates how to wrap a LangGraph agent with MCP for use with Rogue.&lt;/p&gt; 
&lt;h2&gt;üî• Quick Start&lt;/h2&gt; 
&lt;h3&gt;Prerequisites&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;uvx&lt;/code&gt; - If not installed, follow &lt;a href="https://docs.astral.sh/uv/getting-started/installation/"&gt;uv installation guide&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Python 3.10+&lt;/li&gt; 
 &lt;li&gt;An API key for an LLM provider (e.g., OpenAI, Google, Anthropic).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Installation&lt;/h3&gt; 
&lt;h4&gt;Option 1: Quick Install (Recommended)&lt;/h4&gt; 
&lt;p&gt;Use our automated install script to get up and running quickly:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# TUI
uvx rogue-ai

# Web UI
uvx rogue-ai ui

# CLI / CI/CD
uvx rogue-ai cli
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Option 2: Manual Installation&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Clone the repository:&lt;/strong&gt;&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/qualifire-dev/rogue.git
cd rogue
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Install dependencies:&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;If you are using uv:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;uv sync
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Or, if you are using pip:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;pip install -e .
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;OPTIONALLY: Set up your environment variables:&lt;/strong&gt; Create a &lt;code&gt;.env&lt;/code&gt; file in the root directory and add your API keys. Rogue uses &lt;code&gt;LiteLLM&lt;/code&gt;, so you can set keys for various providers.&lt;/p&gt; &lt;pre&gt;&lt;code class="language-env"&gt;OPENAI_API_KEY="sk-..."
ANTHROPIC_API_KEY="sk-..."
GOOGLE_API_KEY="..."
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Running Rogue&lt;/h3&gt; 
&lt;p&gt;Rogue operates on a client-server architecture where the core evaluation logic runs in a backend server, and various clients connect to it for different interfaces.&lt;/p&gt; 
&lt;h4&gt;Default Behavior&lt;/h4&gt; 
&lt;p&gt;When you run &lt;code&gt;uvx rogue-ai&lt;/code&gt; without any mode specified, it:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Starts the Rogue server in the background&lt;/li&gt; 
 &lt;li&gt;Launches the TUI (Terminal User Interface) client&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uvx rogue-ai
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Available Modes&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Default (Server + TUI)&lt;/strong&gt;: &lt;code&gt;uvx rogue-ai&lt;/code&gt; - Starts server in background + TUI client&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Server&lt;/strong&gt;: &lt;code&gt;uvx rogue-ai server&lt;/code&gt; - Runs only the backend server&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;TUI&lt;/strong&gt;: &lt;code&gt;uvx rogue-ai tui&lt;/code&gt; - Runs only the TUI client (requires server running)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Web UI&lt;/strong&gt;: &lt;code&gt;uvx rogue-ai ui&lt;/code&gt; - Runs only the Gradio web interface client (requires server running)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;CLI&lt;/strong&gt;: &lt;code&gt;uvx rogue-ai cli&lt;/code&gt; - Runs non-interactive command-line evaluation (requires server running, ideal for CI/CD)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Mode Arguments&lt;/h4&gt; 
&lt;h5&gt;Server Mode&lt;/h5&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uvx rogue-ai server [OPTIONS]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Options:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;--host HOST&lt;/code&gt; - Host to run the server on (default: 127.0.0.1 or HOST env var)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--port PORT&lt;/code&gt; - Port to run the server on (default: 8000 or PORT env var)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--debug&lt;/code&gt; - Enable debug logging&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h5&gt;TUI Mode&lt;/h5&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uvx rogue-ai tui [OPTIONS]
&lt;/code&gt;&lt;/pre&gt; 
&lt;h5&gt;Web UI Mode&lt;/h5&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uvx rogue-ai ui [OPTIONS]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Options:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;--rogue-server-url URL&lt;/code&gt; - Rogue server URL (default: &lt;a href="http://localhost:8000"&gt;http://localhost:8000&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--port PORT&lt;/code&gt; - Port to run the UI on&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--workdir WORKDIR&lt;/code&gt; - Working directory (default: ./.rogue)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--debug&lt;/code&gt; - Enable debug logging&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h5&gt;CLI Mode&lt;/h5&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uvx rogue-ai cli [OPTIONS]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Options:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;--config-file FILE&lt;/code&gt; - Path to config file&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--rogue-server-url URL&lt;/code&gt; - Rogue server URL (default: &lt;a href="http://localhost:8000"&gt;http://localhost:8000&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--evaluated-agent-url URL&lt;/code&gt; - URL of the agent to evaluate&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--evaluated-agent-auth-type TYPE&lt;/code&gt; - Auth method (no_auth, api_key, bearer_token, basic)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--evaluated-agent-credentials CREDS&lt;/code&gt; - Credentials for the agent&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--input-scenarios-file FILE&lt;/code&gt; - Path to scenarios file (default: 
  &lt;workdir&gt;
   /scenarios.json)
  &lt;/workdir&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--output-report-file FILE&lt;/code&gt; - Path to output report file&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--judge-llm MODEL&lt;/code&gt; - Model for evaluation and report generation&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--judge-llm-api-key KEY&lt;/code&gt; - API key for LLM provider&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--business-context TEXT&lt;/code&gt; - Business context description&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--business-context-file FILE&lt;/code&gt; - Path to business context file&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--deep-test-mode&lt;/code&gt; - Enable deep test mode&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--workdir WORKDIR&lt;/code&gt; - Working directory (default: ./.rogue)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--debug&lt;/code&gt; - Enable debug logging&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Web UI Mode&lt;/h4&gt; 
&lt;p&gt;To launch the Gradio web UI specifically:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uvx rogue-ai ui
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Navigate to the URL displayed in your terminal (usually &lt;code&gt;http://127.0.0.1:7860&lt;/code&gt;) to begin.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Example: Testing the T-Shirt Store Agent&lt;/h2&gt; 
&lt;p&gt;This repository includes a simple example agent that sells T-shirts. You can use it to see Rogue in action.&lt;/p&gt; 
&lt;h3&gt;Option 1: All-in-One (Recommended)&lt;/h3&gt; 
&lt;p&gt;The easiest way to try Rogue with the example agent is to use the &lt;code&gt;--example&lt;/code&gt; flag, which starts both Rogue and the example agent automatically:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uvx rogue-ai --example=tshirt_store
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This will:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Start the T-Shirt Store agent on &lt;code&gt;http://localhost:10001&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Launch Rogue with the TUI interface&lt;/li&gt; 
 &lt;li&gt;Automatically clean up when you exit&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;You can customize the host and port:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uvx rogue-ai --example=tshirt_store --example-host localhost --example-port 10001
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Option 2: Manual Setup&lt;/h3&gt; 
&lt;p&gt;If you prefer to run the example agent separately:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Install example dependencies:&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;If you are using uv:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;uv sync --group examples
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;or, if you are using pip:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;pip install -e .[examples]
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Start the example agent server&lt;/strong&gt; in a separate terminal:&lt;/p&gt; &lt;p&gt;If you are using uv:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;uv run python -m examples.tshirt_store_agent
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Or using the script command:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;uv run rogue-ai-example-tshirt
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Or if installed:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;uvx rogue-ai-example-tshirt
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;This will start the agent on &lt;code&gt;http://localhost:10001&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Configure Rogue&lt;/strong&gt; in the UI to point to the example agent:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Agent URL&lt;/strong&gt;: &lt;code&gt;http://localhost:10001&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Authentication&lt;/strong&gt;: &lt;code&gt;no-auth&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Run the evaluation&lt;/strong&gt; and watch Rogue test the T-Shirt agent's policies!&lt;/p&gt; &lt;p&gt;You can use either the TUI (&lt;code&gt;uvx rogue-ai&lt;/code&gt;) or Web UI (&lt;code&gt;uvx rogue-ai ui&lt;/code&gt;) mode.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üîß CLI Mode&lt;/h2&gt; 
&lt;p&gt;The CLI mode provides a &lt;strong&gt;non-interactive&lt;/strong&gt; command-line interface for evaluating AI agents against predefined scenarios. It connects to the Rogue server to perform evaluations and is &lt;strong&gt;ideal for CI/CD pipelines&lt;/strong&gt; and automated testing workflows.&lt;/p&gt; 
&lt;h3&gt;üöÄ Usage&lt;/h3&gt; 
&lt;p&gt;The CLI mode requires the Rogue server to be running. You can either:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Start server separately:&lt;/strong&gt;&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;# Terminal 1: Start the server
uvx rogue-ai server

# Terminal 2: Run CLI evaluation
uvx rogue-ai cli [OPTIONS]
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Use the default mode (starts server + TUI, then use TUI for evaluation)&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;For development or if you prefer to install locally:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/qualifire-dev/rogue.git
cd rogue
uv sync
uv run -m rogue cli [OPTIONS]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or, if you are using pip:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/qualifire-dev/rogue.git
cd rogue
pip install -e .
uv run -m rogue cli [OPTIONS]
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h3&gt;üìì CLI Arguments&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: CLI mode is &lt;strong&gt;non-interactive&lt;/strong&gt; and designed for automated evaluation workflows, making it perfect for CI/CD pipelines.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Argument&lt;/th&gt; 
   &lt;th&gt;Required&lt;/th&gt; 
   &lt;th&gt;Default Value&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;--workdir&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;./.rogue&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Directory to store outputs and defaults.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;--config-file&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;&amp;lt;workdir&amp;gt;/user_config.json&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Path to a config file generated by the UI. Values from this file are used unless overridden via CLI. If the file does not exist, only cli will be used.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;--rogue-server-url&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;http://localhost:8000&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;URL of the Rogue server to connect to.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;--evaluated-agent-url&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;The URL of the agent to evaluate.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;--evaluated-agent-auth-type&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;no_auth&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Auth method. Can be one of: &lt;code&gt;no_auth&lt;/code&gt;, &lt;code&gt;api_key&lt;/code&gt;, &lt;code&gt;bearer_token&lt;/code&gt;, &lt;code&gt;basic&lt;/code&gt;.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;--evaluated-agent-credentials&lt;/td&gt; 
   &lt;td&gt;Yes*&lt;br /&gt;if &lt;code&gt;auth_type&lt;/code&gt; is not &lt;code&gt;no_auth&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;Credentials for the agent (if required).&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;--input-scenarios-file&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;&amp;lt;workdir&amp;gt;/scenarios.json&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Path to scenarios file.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;--output-report-file&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;&amp;lt;workdir&amp;gt;/report.md&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Where to save the markdown report.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;--judge-llm&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;Model name for LLM evaluation (Litellm format).&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;--judge-llm-api-key&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;API key for LLM (see environment section).&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;--business-context&lt;/td&gt; 
   &lt;td&gt;Yes*&lt;br /&gt;Unless &lt;code&gt;--business-context-file&lt;/code&gt; is supplied&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;Business context as a string.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;--business-context-file&lt;/td&gt; 
   &lt;td&gt;Yes*&lt;br /&gt;Unless &lt;code&gt;--business-context&lt;/code&gt; is supplied&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;&amp;lt;workdir&amp;gt;/business_context.md&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;OR path to file containing the business context.&lt;br /&gt;If both given, &lt;code&gt;--business-context&lt;/code&gt; has priority&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;--deep-test-mode&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;False&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Enables extended testing behavior.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;--debug&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;False&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Enable verbose logging.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;üìä Config file&lt;/h3&gt; 
&lt;p&gt;The config file is automatically generated when running the UI. &lt;br /&gt; We will check for a config file in &lt;code&gt;&amp;lt;workdir&amp;gt;/user_config.json&lt;/code&gt; and use it if it exists. &lt;br /&gt; The config file is a JSON object that can contain all or a subset of the fields from the CLI arguments, except for &lt;code&gt;--config-file&lt;/code&gt;. &lt;br /&gt; Other keys in the config file are ignored. &lt;br /&gt; Just remember to use snake_case keys. (e.g. &lt;code&gt;--evaluated-agent-url&lt;/code&gt; becomes &lt;code&gt;evaluated_agent_url&lt;/code&gt;).&lt;/p&gt; 
&lt;h3&gt;Notes&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;‚ö†Ô∏è Either &lt;code&gt;--business-context&lt;/code&gt; or &lt;code&gt;--business-context-file&lt;/code&gt; must be provided.&lt;/li&gt; 
 &lt;li&gt;‚ö†Ô∏è Fields marked as Required are required unless supplied via the config file.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;hr /&gt; 
&lt;h3&gt;Examples&lt;/h3&gt; 
&lt;h3&gt;With only a config file:&lt;/h3&gt; 
&lt;p&gt;with our business context located at &lt;code&gt;./.rogue/business_context.md&lt;/code&gt;&lt;/p&gt; 
&lt;h4&gt;&lt;code&gt;./.rogue/user_config.json&lt;/code&gt;&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "evaluated_agent_url": "http://localhost:10001",
  "judge_llm": "openai/o4-mini"
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Execution&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uvx rogue-ai cli
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Same example without a config file:&lt;/h3&gt; 
&lt;h4&gt;Execution&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uvx rogue-ai cli \
    --evaluated-agent-url http://localhost:10001 \
    --judge-llm openai/o4-mini \
    --business-context-file './.rogue/business_context.md'
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Key Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;üîÑ Dynamic Scenario Generation&lt;/strong&gt;: Automatically creates a comprehensive test suite from your high-level business context.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üëÄ Live Evaluation Monitoring&lt;/strong&gt;: Watch the interaction between the Evaluator and your agent in a real-time chat interface.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üìä Comprehensive Reporting&lt;/strong&gt;: Generates a detailed summary of the evaluation, including pass/fail rates, key findings, and recommendations.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üîç Multi-Faceted Testing&lt;/strong&gt;: Natively supports testing for policy compliance, with a flexible framework to expand to other areas like prompt injection or safety.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ü§ñ Broad Model Support&lt;/strong&gt;: Compatible with a wide range of models from providers like OpenAI, Google (Gemini), and Anthropic.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üéØ User-Friendly Interface&lt;/strong&gt;: A simple, step-by-step Gradio UI guides you through configuration, execution, and reporting.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;How It Works&lt;/h2&gt; 
&lt;p&gt;Rogue's workflow is designed to be simple and intuitive, managed entirely through its web interface.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Configure&lt;/strong&gt;: You provide the endpoint and authentication details for the agent you want to test, and select the LLMs you want Rogue to use for its services (scenario generation, judging).&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Generate Scenarios&lt;/strong&gt;: You input the "business context" or a high-level description of what your agent is supposed to do. Rogue's &lt;code&gt;LLM Service&lt;/code&gt; uses this context to generate a list of relevant test scenarios. You can review and edit these scenarios.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Run &amp;amp; Evaluate&lt;/strong&gt;: You start the evaluation. The &lt;code&gt;Scenario Evaluation Service&lt;/code&gt; spins up the &lt;code&gt;EvaluatorAgent&lt;/code&gt;, which begins a conversation with your agent for each scenario. You can watch this conversation happen live.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;View Report&lt;/strong&gt;: Once all scenarios are complete, the &lt;code&gt;LLM Service&lt;/code&gt; analyzes the results and generates a Markdown-formatted report, giving you a clear summary of your agent's performance.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Contributions are welcome! If you'd like to contribute, please follow these steps:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Fork the repository.&lt;/li&gt; 
 &lt;li&gt;Create a new branch (&lt;code&gt;git checkout -b feature/your-feature-name&lt;/code&gt;).&lt;/li&gt; 
 &lt;li&gt;Make your changes and commit them (&lt;code&gt;git commit -m 'Add some feature'&lt;/code&gt;).&lt;/li&gt; 
 &lt;li&gt;Push to the branch (&lt;code&gt;git push origin feature/your-feature-name&lt;/code&gt;).&lt;/li&gt; 
 &lt;li&gt;Open a pull request.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Please make sure to update tests as appropriate.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under a License - see the &lt;a href="https://raw.githubusercontent.com/qualifire-dev/rogue/main/LICENSE.md"&gt;LICENSE&lt;/a&gt; file for details. This means that you can use this freely and forever but you are not allowed to host and sell this software.&lt;/p&gt; 
&lt;p&gt;If you have any queries about the license and commercial use for this project please email &lt;code&gt;admin@qualifire.ai&lt;/code&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>ollama/ollama</title>
      <link>https://github.com/ollama/ollama</link>
      <description>&lt;p&gt;Get up and running with OpenAI gpt-oss, DeepSeek-R1, Gemma 3 and other models.&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt;
  &amp;nbsp; 
 &lt;a href="https://ollama.com"&gt; &lt;img alt="ollama" width="240" src="https://github.com/ollama/ollama/assets/3325447/0d0b44e2-8f4a-4e99-9b52-a5c1c741c8f7" /&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;h1&gt;Ollama&lt;/h1&gt; 
&lt;p&gt;Get up and running with large language models.&lt;/p&gt; 
&lt;h3&gt;macOS&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://ollama.com/download/Ollama.dmg"&gt;Download&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Windows&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://ollama.com/download/OllamaSetup.exe"&gt;Download&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Linux&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;curl -fsSL https://ollama.com/install.sh | sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;a href="https://docs.ollama.com/linux#manual-install"&gt;Manual install instructions&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Docker&lt;/h3&gt; 
&lt;p&gt;The official &lt;a href="https://hub.docker.com/r/ollama/ollama"&gt;Ollama Docker image&lt;/a&gt; &lt;code&gt;ollama/ollama&lt;/code&gt; is available on Docker Hub.&lt;/p&gt; 
&lt;h3&gt;Libraries&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ollama/ollama-python"&gt;ollama-python&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ollama/ollama-js"&gt;ollama-js&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Community&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://discord.gg/ollama"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://reddit.com/r/ollama"&gt;Reddit&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Quickstart&lt;/h2&gt; 
&lt;p&gt;To run and chat with &lt;a href="https://ollama.com/library/gemma3"&gt;Gemma 3&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;ollama run gemma3
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Model library&lt;/h2&gt; 
&lt;p&gt;Ollama supports a list of models available on &lt;a href="https://ollama.com/library" title="ollama model library"&gt;ollama.com/library&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Here are some example models that can be downloaded:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Model&lt;/th&gt; 
   &lt;th&gt;Parameters&lt;/th&gt; 
   &lt;th&gt;Size&lt;/th&gt; 
   &lt;th&gt;Download&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Gemma 3&lt;/td&gt; 
   &lt;td&gt;1B&lt;/td&gt; 
   &lt;td&gt;815MB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run gemma3:1b&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Gemma 3&lt;/td&gt; 
   &lt;td&gt;4B&lt;/td&gt; 
   &lt;td&gt;3.3GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run gemma3&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Gemma 3&lt;/td&gt; 
   &lt;td&gt;12B&lt;/td&gt; 
   &lt;td&gt;8.1GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run gemma3:12b&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Gemma 3&lt;/td&gt; 
   &lt;td&gt;27B&lt;/td&gt; 
   &lt;td&gt;17GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run gemma3:27b&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;QwQ&lt;/td&gt; 
   &lt;td&gt;32B&lt;/td&gt; 
   &lt;td&gt;20GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run qwq&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;DeepSeek-R1&lt;/td&gt; 
   &lt;td&gt;7B&lt;/td&gt; 
   &lt;td&gt;4.7GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run deepseek-r1&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;DeepSeek-R1&lt;/td&gt; 
   &lt;td&gt;671B&lt;/td&gt; 
   &lt;td&gt;404GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run deepseek-r1:671b&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Llama 4&lt;/td&gt; 
   &lt;td&gt;109B&lt;/td&gt; 
   &lt;td&gt;67GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run llama4:scout&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Llama 4&lt;/td&gt; 
   &lt;td&gt;400B&lt;/td&gt; 
   &lt;td&gt;245GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run llama4:maverick&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Llama 3.3&lt;/td&gt; 
   &lt;td&gt;70B&lt;/td&gt; 
   &lt;td&gt;43GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run llama3.3&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Llama 3.2&lt;/td&gt; 
   &lt;td&gt;3B&lt;/td&gt; 
   &lt;td&gt;2.0GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run llama3.2&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Llama 3.2&lt;/td&gt; 
   &lt;td&gt;1B&lt;/td&gt; 
   &lt;td&gt;1.3GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run llama3.2:1b&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Llama 3.2 Vision&lt;/td&gt; 
   &lt;td&gt;11B&lt;/td&gt; 
   &lt;td&gt;7.9GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run llama3.2-vision&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Llama 3.2 Vision&lt;/td&gt; 
   &lt;td&gt;90B&lt;/td&gt; 
   &lt;td&gt;55GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run llama3.2-vision:90b&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Llama 3.1&lt;/td&gt; 
   &lt;td&gt;8B&lt;/td&gt; 
   &lt;td&gt;4.7GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run llama3.1&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Llama 3.1&lt;/td&gt; 
   &lt;td&gt;405B&lt;/td&gt; 
   &lt;td&gt;231GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run llama3.1:405b&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Phi 4&lt;/td&gt; 
   &lt;td&gt;14B&lt;/td&gt; 
   &lt;td&gt;9.1GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run phi4&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Phi 4 Mini&lt;/td&gt; 
   &lt;td&gt;3.8B&lt;/td&gt; 
   &lt;td&gt;2.5GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run phi4-mini&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Mistral&lt;/td&gt; 
   &lt;td&gt;7B&lt;/td&gt; 
   &lt;td&gt;4.1GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run mistral&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Moondream 2&lt;/td&gt; 
   &lt;td&gt;1.4B&lt;/td&gt; 
   &lt;td&gt;829MB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run moondream&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Neural Chat&lt;/td&gt; 
   &lt;td&gt;7B&lt;/td&gt; 
   &lt;td&gt;4.1GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run neural-chat&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Starling&lt;/td&gt; 
   &lt;td&gt;7B&lt;/td&gt; 
   &lt;td&gt;4.1GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run starling-lm&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Code Llama&lt;/td&gt; 
   &lt;td&gt;7B&lt;/td&gt; 
   &lt;td&gt;3.8GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run codellama&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Llama 2 Uncensored&lt;/td&gt; 
   &lt;td&gt;7B&lt;/td&gt; 
   &lt;td&gt;3.8GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run llama2-uncensored&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;LLaVA&lt;/td&gt; 
   &lt;td&gt;7B&lt;/td&gt; 
   &lt;td&gt;4.5GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run llava&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Granite-3.3&lt;/td&gt; 
   &lt;td&gt;8B&lt;/td&gt; 
   &lt;td&gt;4.9GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run granite3.3&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] You should have at least 8 GB of RAM available to run the 7B models, 16 GB to run the 13B models, and 32 GB to run the 33B models.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Customize a model&lt;/h2&gt; 
&lt;h3&gt;Import from GGUF&lt;/h3&gt; 
&lt;p&gt;Ollama supports importing GGUF models in the Modelfile:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Create a file named &lt;code&gt;Modelfile&lt;/code&gt;, with a &lt;code&gt;FROM&lt;/code&gt; instruction with the local filepath to the model you want to import.&lt;/p&gt; &lt;pre&gt;&lt;code&gt;FROM ./vicuna-33b.Q4_0.gguf
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Create the model in Ollama&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;ollama create example -f Modelfile
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Run the model&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;ollama run example
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Import from Safetensors&lt;/h3&gt; 
&lt;p&gt;See the &lt;a href="https://docs.ollama.com/import"&gt;guide&lt;/a&gt; on importing models for more information.&lt;/p&gt; 
&lt;h3&gt;Customize a prompt&lt;/h3&gt; 
&lt;p&gt;Models from the Ollama library can be customized with a prompt. For example, to customize the &lt;code&gt;llama3.2&lt;/code&gt; model:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;ollama pull llama3.2
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Create a &lt;code&gt;Modelfile&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;FROM llama3.2

# set the temperature to 1 [higher is more creative, lower is more coherent]
PARAMETER temperature 1

# set the system message
SYSTEM """
You are Mario from Super Mario Bros. Answer as Mario, the assistant, only.
"""
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Next, create and run the model:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;ollama create mario -f ./Modelfile
ollama run mario
&amp;gt;&amp;gt;&amp;gt; hi
Hello! It's your friend Mario.
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For more information on working with a Modelfile, see the &lt;a href="https://docs.ollama.com/modelfile"&gt;Modelfile&lt;/a&gt; documentation.&lt;/p&gt; 
&lt;h2&gt;CLI Reference&lt;/h2&gt; 
&lt;h3&gt;Create a model&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;ollama create&lt;/code&gt; is used to create a model from a Modelfile.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;ollama create mymodel -f ./Modelfile
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Pull a model&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;ollama pull llama3.2
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;This command can also be used to update a local model. Only the diff will be pulled.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Remove a model&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;ollama rm llama3.2
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Copy a model&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;ollama cp llama3.2 my-model
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Multiline input&lt;/h3&gt; 
&lt;p&gt;For multiline input, you can wrap text with &lt;code&gt;"""&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt; """Hello,
... world!
... """
I'm a basic program that prints the famous "Hello, world!" message to the console.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Multimodal models&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;ollama run llava "What's in this image? /Users/jmorgan/Desktop/smile.png"
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Output&lt;/strong&gt;: The image features a yellow smiley face, which is likely the central focus of the picture.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Pass the prompt as an argument&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;ollama run llama3.2 "Summarize this file: $(cat README.md)"
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Output&lt;/strong&gt;: Ollama is a lightweight, extensible framework for building and running language models on the local machine. It provides a simple API for creating, running, and managing models, as well as a library of pre-built models that can be easily used in a variety of applications.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Show model information&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;ollama show llama3.2
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;List models on your computer&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;ollama list
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;List which models are currently loaded&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;ollama ps
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Stop a model which is currently running&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;ollama stop llama3.2
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Start Ollama&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;ollama serve&lt;/code&gt; is used when you want to start ollama without running the desktop application.&lt;/p&gt; 
&lt;h2&gt;Building&lt;/h2&gt; 
&lt;p&gt;See the &lt;a href="https://github.com/ollama/ollama/raw/main/docs/development.md"&gt;developer guide&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Running local builds&lt;/h3&gt; 
&lt;p&gt;Next, start the server:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;./ollama serve
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Finally, in a separate shell, run a model:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;./ollama run llama3.2
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;REST API&lt;/h2&gt; 
&lt;p&gt;Ollama has a REST API for running and managing models.&lt;/p&gt; 
&lt;h3&gt;Generate a response&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;curl http://localhost:11434/api/generate -d '{
  "model": "llama3.2",
  "prompt":"Why is the sky blue?"
}'
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Chat with a model&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;curl http://localhost:11434/api/chat -d '{
  "model": "llama3.2",
  "messages": [
    { "role": "user", "content": "why is the sky blue?" }
  ]
}'
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See the &lt;a href="https://raw.githubusercontent.com/ollama/ollama/main/docs/api.md"&gt;API documentation&lt;/a&gt; for all endpoints.&lt;/p&gt; 
&lt;h2&gt;Community Integrations&lt;/h2&gt; 
&lt;h3&gt;Web &amp;amp; Desktop&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/open-webui/open-webui"&gt;Open WebUI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/aws-samples/swift-chat"&gt;SwiftChat (macOS with ReactNative)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/AugustDev/enchanted"&gt;Enchanted (macOS native)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/fmaclen/hollama"&gt;Hollama&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ParisNeo/lollms-webui"&gt;Lollms-Webui&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/danny-avila/LibreChat"&gt;LibreChat&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/bionic-gpt/bionic-gpt"&gt;Bionic GPT&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/rtcfirefly/ollama-ui"&gt;HTML UI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jikkuatwork/saddle"&gt;Saddle&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.tagspaces.org"&gt;TagSpaces&lt;/a&gt; (A platform for file-based apps, &lt;a href="https://docs.tagspaces.org/ai/"&gt;utilizing Ollama&lt;/a&gt; for the generation of tags and descriptions)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ivanfioravanti/chatbot-ollama"&gt;Chatbot UI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mckaywrigley/chatbot-ui"&gt;Chatbot UI v2&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ollama-interface/Ollama-Gui?tab=readme-ov-file"&gt;Typescript UI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/richawo/minimal-llm-ui"&gt;Minimalistic React UI for Ollama Models&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/kevinhermawan/Ollamac"&gt;Ollamac&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/enricoros/big-AGI"&gt;big-AGI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/cheshire-cat-ai/core"&gt;Cheshire Cat assistant framework&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/semperai/amica"&gt;Amica&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/BruceMacD/chatd"&gt;chatd&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/kghandour/Ollama-SwiftUI"&gt;Ollama-SwiftUI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/langgenius/dify"&gt;Dify.AI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://mindmac.app"&gt;MindMac&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jakobhoeg/nextjs-ollama-llm-ui"&gt;NextJS Web Interface for Ollama&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://msty.app"&gt;Msty&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Bin-Huang/Chatbox"&gt;Chatbox&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tgraupmann/WinForm_Ollama_Copilot"&gt;WinForm Ollama Copilot&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ChatGPTNextWeb/ChatGPT-Next-Web"&gt;NextChat&lt;/a&gt; with &lt;a href="https://docs.nextchat.dev/models/ollama"&gt;Get Started Doc&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mmo80/alpaca-webui"&gt;Alpaca WebUI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/enoch1118/ollamaGUI"&gt;OllamaGUI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/InternLM/OpenAOE"&gt;OpenAOE&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/leonid20000/OdinRunes"&gt;Odin Runes&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mrdjohnson/llm-x"&gt;LLM-X&lt;/a&gt; (Progressive Web App)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Mintplex-Labs/anything-llm"&gt;AnythingLLM (Docker + MacOs/Windows/Linux native app)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/rapidarchitect/ollama_basic_chat"&gt;Ollama Basic Chat: Uses HyperDiv Reactive UI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/drazdra/ollama-chats"&gt;Ollama-chats RPG&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://intellibar.app/"&gt;IntelliBar&lt;/a&gt; (AI-powered assistant for macOS)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/AliAhmedNada/jirapt"&gt;Jirapt&lt;/a&gt; (Jira Integration to generate issues, tasks, epics)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/AliAhmedNada/ojira"&gt;ojira&lt;/a&gt; (Jira chrome plugin to easily generate descriptions for tasks)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/reid41/QA-Pilot"&gt;QA-Pilot&lt;/a&gt; (Interactive chat tool that can leverage Ollama models for rapid understanding and navigation of GitHub code repositories)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/sugarforever/chat-ollama"&gt;ChatOllama&lt;/a&gt; (Open Source Chatbot based on Ollama with Knowledge Bases)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Nagi-ovo/CRAG-Ollama-Chat"&gt;CRAG Ollama Chat&lt;/a&gt; (Simple Web Search with Corrective RAG)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/infiniflow/ragflow"&gt;RAGFlow&lt;/a&gt; (Open-source Retrieval-Augmented Generation engine based on deep document understanding)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/StreamDeploy-DevRel/streamdeploy-llm-app-scaffold"&gt;StreamDeploy&lt;/a&gt; (LLM Application Scaffold)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/swuecho/chat"&gt;chat&lt;/a&gt; (chat web app for teams)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/lobehub/lobe-chat"&gt;Lobe Chat&lt;/a&gt; with &lt;a href="https://lobehub.com/docs/self-hosting/examples/ollama"&gt;Integrating Doc&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/datvodinh/rag-chatbot.git"&gt;Ollama RAG Chatbot&lt;/a&gt; (Local Chat with multiple PDFs using Ollama and RAG)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.nurgo-software.com/products/brainsoup"&gt;BrainSoup&lt;/a&gt; (Flexible native client with RAG &amp;amp; multi-agent automation)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Renset/macai"&gt;macai&lt;/a&gt; (macOS client for Ollama, ChatGPT, and other compatible API back-ends)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/josStorer/RWKV-Runner"&gt;RWKV-Runner&lt;/a&gt; (RWKV offline LLM deployment tool, also usable as a client for ChatGPT and Ollama)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/dezoito/ollama-grid-search"&gt;Ollama Grid Search&lt;/a&gt; (app to evaluate and compare models)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Otacon/olpaka"&gt;Olpaka&lt;/a&gt; (User-friendly Flutter Web App for Ollama)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://casibase.org"&gt;Casibase&lt;/a&gt; (An open source AI knowledge base and dialogue system combining the latest RAG, SSO, ollama support, and multiple large language models.)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/CrazyNeil/OllamaSpring"&gt;OllamaSpring&lt;/a&gt; (Ollama Client for macOS)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/kartikm7/llocal"&gt;LLocal.in&lt;/a&gt; (Easy to use Electron Desktop Client for Ollama)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/dcSpark/shinkai-apps"&gt;Shinkai Desktop&lt;/a&gt; (Two click install Local AI using Ollama + Files + RAG)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/zeyoyt/ailama"&gt;AiLama&lt;/a&gt; (A Discord User App that allows you to interact with Ollama anywhere in Discord)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/rapidarchitect/ollama_mesop/"&gt;Ollama with Google Mesop&lt;/a&gt; (Mesop Chat Client implementation with Ollama)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/SciPhi-AI/R2R"&gt;R2R&lt;/a&gt; (Open-source RAG engine)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/elearningshow/ollama-kis"&gt;Ollama-Kis&lt;/a&gt; (A simple easy-to-use GUI with sample custom LLM for Drivers Education)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://opengpa.org"&gt;OpenGPA&lt;/a&gt; (Open-source offline-first Enterprise Agentic Application)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mateuszmigas/painting-droid"&gt;Painting Droid&lt;/a&gt; (Painting app with AI integrations)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.kerlig.com/"&gt;Kerlig AI&lt;/a&gt; (AI writing assistant for macOS)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/MindWorkAI/AI-Studio"&gt;AI Studio&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/gyopak/sidellama"&gt;Sidellama&lt;/a&gt; (browser-based LLM client)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/trypromptly/LLMStack"&gt;LLMStack&lt;/a&gt; (No-code multi-agent framework to build LLM agents and workflows)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://boltai.com"&gt;BoltAI for Mac&lt;/a&gt; (AI Chat Client for Mac)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/av/harbor"&gt;Harbor&lt;/a&gt; (Containerized LLM Toolkit with Ollama as default backend)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/szczyglis-dev/py-gpt"&gt;PyGPT&lt;/a&gt; (AI desktop assistant for Linux, Windows, and Mac)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Jeffser/Alpaca"&gt;Alpaca&lt;/a&gt; (An Ollama client application for Linux and macOS made with GTK4 and Adwaita)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Significant-Gravitas/AutoGPT/raw/master/docs/content/platform/ollama.md"&gt;AutoGPT&lt;/a&gt; (AutoGPT Ollama integration)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.jonathanhecl.com/go-crew/"&gt;Go-CREW&lt;/a&gt; (Powerful Offline RAG in Golang)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/openvmp/partcad/"&gt;PartCAD&lt;/a&gt; (CAD model generation with OpenSCAD and CadQuery)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ollama4j/ollama4j-web-ui"&gt;Ollama4j Web UI&lt;/a&gt; - Java-based Web UI for Ollama built with Vaadin, Spring Boot, and Ollama4j&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/kspviswa/pyOllaMx"&gt;PyOllaMx&lt;/a&gt; - macOS application capable of chatting with both Ollama and Apple MLX models.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/cline/cline"&gt;Cline&lt;/a&gt; - Formerly known as Claude Dev is a VSCode extension for multi-file/whole-repo coding&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/kangfenmao/cherry-studio"&gt;Cherry Studio&lt;/a&gt; (Desktop client with Ollama support)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/1runeberg/confichat"&gt;ConfiChat&lt;/a&gt; (Lightweight, standalone, multi-platform, and privacy-focused LLM chat interface with optional encryption)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/nickthecook/archyve"&gt;Archyve&lt;/a&gt; (RAG-enabling document library)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/rapidarchitect/ollama-crew-mesop"&gt;crewAI with Mesop&lt;/a&gt; (Mesop Web Interface to run crewAI with Ollama)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/chyok/ollama-gui"&gt;Tkinter-based client&lt;/a&gt; (Python tkinter-based Client for Ollama)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/trendy-design/llmchat"&gt;LLMChat&lt;/a&gt; (Privacy focused, 100% local, intuitive all-in-one chat interface)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Leon-Sander/Local-Multimodal-AI-Chat"&gt;Local Multimodal AI Chat&lt;/a&gt; (Ollama-based LLM Chat with support for multiple features, including PDF RAG, voice chat, image-based interactions, and integration with OpenAI.)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/xark-argo/argo"&gt;ARGO&lt;/a&gt; (Locally download and run Ollama and Huggingface models with RAG and deep research on Mac/Windows/Linux)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/EliasPereirah/OrionChat"&gt;OrionChat&lt;/a&gt; - OrionChat is a web interface for chatting with different AI providers&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/bklieger-groq/g1"&gt;G1&lt;/a&gt; (Prototype of using prompting strategies to improve the LLM's reasoning through o1-like reasoning chains.)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/lemonit-eric-mao/ollama-web-management"&gt;Web management&lt;/a&gt; (Web management page)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/promptery/promptery"&gt;Promptery&lt;/a&gt; (desktop client for Ollama.)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/JHubi1/ollama-app"&gt;Ollama App&lt;/a&gt; (Modern and easy-to-use multi-platform client for Ollama)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/annilq/chat-ollama"&gt;chat-ollama&lt;/a&gt; (a React Native client for Ollama)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tcsenpai/spacellama"&gt;SpaceLlama&lt;/a&gt; (Firefox and Chrome extension to quickly summarize web pages with ollama in a sidebar)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tcsenpai/youlama"&gt;YouLama&lt;/a&gt; (Webapp to quickly summarize any YouTube video, supporting Invidious as well)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tcsenpai/dualmind"&gt;DualMind&lt;/a&gt; (Experimental app allowing two models to talk to each other in the terminal or in a web interface)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/h1ddenpr0cess20/ollamarama-matrix"&gt;ollamarama-matrix&lt;/a&gt; (Ollama chatbot for the Matrix chat protocol)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/anan1213095357/ollama-chat-app"&gt;ollama-chat-app&lt;/a&gt; (Flutter-based chat app)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.perfectmemory.ai/"&gt;Perfect Memory AI&lt;/a&gt; (Productivity AI assists personalized by what you have seen on your screen, heard, and said in the meetings)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/hexastack/hexabot"&gt;Hexabot&lt;/a&gt; (A conversational AI builder)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/rapidarchitect/reddit_analyzer"&gt;Reddit Rate&lt;/a&gt; (Search and Rate Reddit topics with a weighted summation)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/adarshM84/OpenTalkGpt"&gt;OpenTalkGpt&lt;/a&gt; (Chrome Extension to manage open-source models supported by Ollama, create custom models, and chat with models from a user-friendly UI)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/vinhnx/vt.ai"&gt;VT&lt;/a&gt; (A minimal multimodal AI chat app, with dynamic conversation routing. Supports local models via Ollama)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/nosia-ai/nosia"&gt;Nosia&lt;/a&gt; (Easy to install and use RAG platform based on Ollama)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/nbonamy/witsy"&gt;Witsy&lt;/a&gt; (An AI Desktop application available for Mac/Windows/Linux)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/US-Artificial-Intelligence/abbey"&gt;Abbey&lt;/a&gt; (A configurable AI interface server with notebooks, document storage, and YouTube support)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/dmayboroda/minima"&gt;Minima&lt;/a&gt; (RAG with on-premises or fully local workflow)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/AidfulAI/aidful-ollama-model-delete"&gt;aidful-ollama-model-delete&lt;/a&gt; (User interface for simplified model cleanup)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ItzCrazyKns/Perplexica"&gt;Perplexica&lt;/a&gt; (An AI-powered search engine &amp;amp; an open-source alternative to Perplexity AI)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/oslook/ollama-webui"&gt;Ollama Chat WebUI for Docker &lt;/a&gt; (Support for local docker deployment, lightweight ollama webui)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://aka.ms/ai-tooklit/ollama-docs"&gt;AI Toolkit for Visual Studio Code&lt;/a&gt; (Microsoft-official VSCode extension to chat, test, evaluate models with Ollama support, and use them in your AI applications.)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/anilkay/MinimalNextOllamaChat"&gt;MinimalNextOllamaChat&lt;/a&gt; (Minimal Web UI for Chat and Model Control)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/TilmanGriesel/chipper"&gt;Chipper&lt;/a&gt; AI interface for tinkerers (Ollama, Haystack RAG, Python)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/CosmicEventHorizon/ChibiChat"&gt;ChibiChat&lt;/a&gt; (Kotlin-based Android app to chat with Ollama and Koboldcpp API endpoints)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/qusaismael/localllm"&gt;LocalLLM&lt;/a&gt; (Minimal Web-App to run ollama models on it with a GUI)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/buiducnhat/ollamazing"&gt;Ollamazing&lt;/a&gt; (Web extension to run Ollama models)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/benhaotang/OpenDeepResearcher-via-searxng"&gt;OpenDeepResearcher-via-searxng&lt;/a&gt; (A Deep Research equivalent endpoint with Ollama support for running locally)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/AIDotNet/AntSK"&gt;AntSK&lt;/a&gt; (Out-of-the-box &amp;amp; Adaptable RAG Chatbot)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/1Panel-dev/MaxKB/"&gt;MaxKB&lt;/a&gt; (Ready-to-use &amp;amp; flexible RAG Chatbot)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/danielekp/yla"&gt;yla&lt;/a&gt; (Web interface to freely interact with your customized models)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/RockChinQ/LangBot"&gt;LangBot&lt;/a&gt; (LLM-based instant messaging bots platform, with Agents, RAG features, supports multiple platforms)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/1Panel-dev/1Panel/"&gt;1Panel&lt;/a&gt; (Web-based Linux Server Management Tool)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Soulter/AstrBot/"&gt;AstrBot&lt;/a&gt; (User-friendly LLM-based multi-platform chatbot with a WebUI, supporting RAG, LLM agents, and plugins integration)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ibrahimcetin/reins"&gt;Reins&lt;/a&gt; (Easily tweak parameters, customize system prompts per chat, and enhance your AI experiments with reasoning model support.)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Aharon-Bensadoun/Flufy"&gt;Flufy&lt;/a&gt; (A beautiful chat interface for interacting with Ollama's API. Built with React, TypeScript, and Material-UI.)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/zeozeozeo/ellama"&gt;Ellama&lt;/a&gt; (Friendly native app to chat with an Ollama instance)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mediar-ai/screenpipe"&gt;screenpipe&lt;/a&gt; Build agents powered by your screen history&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/hengkysteen/ollamb"&gt;Ollamb&lt;/a&gt; (Simple yet rich in features, cross-platform built with Flutter and designed for Ollama. Try the &lt;a href="https://hengkysteen.github.io/demo/ollamb/"&gt;web demo&lt;/a&gt;.)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Writeopia/Writeopia"&gt;Writeopia&lt;/a&gt; (Text editor with integration with Ollama)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/AppFlowy-IO/AppFlowy"&gt;AppFlowy&lt;/a&gt; (AI collaborative workspace with Ollama, cross-platform and self-hostable)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/cushydigit/lumina.git"&gt;Lumina&lt;/a&gt; (A lightweight, minimal React.js frontend for interacting with Ollama servers)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pypi.org/project/tiny-notepad"&gt;Tiny Notepad&lt;/a&gt; (A lightweight, notepad-like interface to chat with ollama available on PyPI)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/hellotunamayo/macLlama"&gt;macLlama (macOS native)&lt;/a&gt; (A native macOS GUI application for interacting with Ollama models, featuring a chat interface.)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/philberndt/GPTranslate"&gt;GPTranslate&lt;/a&gt; (A fast and lightweight, AI powered desktop translation application written with Rust and Tauri. Features real-time translation with OpenAI/Azure/Ollama.)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/NGC13009/ollama-launcher"&gt;ollama launcher&lt;/a&gt; (A launcher for Ollama, aiming to provide users with convenient functions such as ollama server launching, management, or configuration.)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Aj-Seven/ai-hub"&gt;ai-hub&lt;/a&gt; (AI Hub supports multiple models via API keys and Chat support via Ollama API.)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://gitlab.com/mayan-edms/mayan-edms"&gt;Mayan EDMS&lt;/a&gt; (Open source document management system to organize, tag, search, and automate your files with powerful Ollama driven workflows.)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/doolijb/serene-pub"&gt;Serene Pub&lt;/a&gt; (Beginner friendly, open source AI Roleplaying App for Windows, Mac OS and Linux. Search, download and use models with Ollama all inside the app.)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/aqerd/andes"&gt;Andes&lt;/a&gt; (A Visual Studio Code extension that provides a local UI interface for Ollama models)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/KashyapTan/clueless"&gt;Clueless&lt;/a&gt; (Open Source &amp;amp; Local Cluely: A desktop application LLM assistant to help you talk to anything on your screen using locally served Ollama models. Also undetectable to screenshare)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/carbonatedWaterOrg/ollama-co2"&gt;ollama-co2&lt;/a&gt; (FastAPI web interface for monitoring and managing local and remote Ollama servers with real-time model monitoring and concurrent downloads)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://hillnote.com"&gt;Hillnote&lt;/a&gt; (A Markdown-first workspace designed to supercharge your AI workflow. Create documents ready to integrate with Claude, ChatGPT, Gemini, Cursor, and more - all while keeping your work on your device.)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Cloud&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://cloud.google.com/run/docs/tutorials/gpu-gemma2-with-ollama"&gt;Google Cloud&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://fly.io/docs/python/do-more/add-ollama/"&gt;Fly.io&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.koyeb.com/deploy/ollama"&gt;Koyeb&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Terminal&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ggozad/oterm"&gt;oterm&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/s-kostyaev/ellama"&gt;Ellama Emacs client&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/zweifisch/ollama"&gt;Emacs client&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/paradoxical-dev/neollama"&gt;neollama&lt;/a&gt; UI client for interacting with models from within Neovim&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/David-Kunz/gen.nvim"&gt;gen.nvim&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/nomnivore/ollama.nvim"&gt;ollama.nvim&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/marco-souza/ollero.nvim"&gt;ollero.nvim&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/gerazov/ollama-chat.nvim"&gt;ollama-chat.nvim&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/huynle/ogpt.nvim"&gt;ogpt.nvim&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/karthink/gptel"&gt;gptel Emacs client&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/dustinblackman/oatmeal"&gt;Oatmeal&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pgibler/cmdh"&gt;cmdh&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/npahlfer/ooo"&gt;ooo&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/reid41/shell-pilot"&gt;shell-pilot&lt;/a&gt;(Interact with models via pure shell scripts on Linux or macOS)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pythops/tenere"&gt;tenere&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/taketwo/llm-ollama"&gt;llm-ollama&lt;/a&gt; for &lt;a href="https://llm.datasette.io/en/stable/"&gt;Datasette's LLM CLI&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/anaisbetts/typechat-cli"&gt;typechat-cli&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/djcopley/ShellOracle"&gt;ShellOracle&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/yusufcanb/tlm"&gt;tlm&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ericcurtin/podman-ollama"&gt;podman-ollama&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/sammcj/gollama"&gt;gollama&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/paulrobello/parllama"&gt;ParLlama&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/cognitivetech/ollama-ebook-summary/"&gt;Ollama eBook Summary&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/rapidarchitect/ollama_moe"&gt;Ollama Mixture of Experts (MOE) in 50 lines of code&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pepo-ec/vim-intelligence-bridge"&gt;vim-intelligence-bridge&lt;/a&gt; Simple interaction of "Ollama" with the Vim editor&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://x-cmd.com/mod/ollama"&gt;x-cmd ollama&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/drunkwcodes/bb7"&gt;bb7&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/marcusziade/Swollama"&gt;SwollamaCLI&lt;/a&gt; bundled with the Swollama Swift package. &lt;a href="https://github.com/marcusziade/Swollama?tab=readme-ov-file#cli-usage"&gt;Demo&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/sigoden/aichat"&gt;aichat&lt;/a&gt; All-in-one LLM CLI tool featuring Shell Assistant, Chat-REPL, RAG, AI tools &amp;amp; agents, with access to OpenAI, Claude, Gemini, Ollama, Groq, and more.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/rrg92/powershai"&gt;PowershAI&lt;/a&gt; PowerShell module that brings AI to terminal on Windows, including support for Ollama&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Abyss-c0re/deepshell"&gt;DeepShell&lt;/a&gt; Your self-hosted AI assistant. Interactive Shell, Files and Folders analysis.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/xyproto/orbiton"&gt;orbiton&lt;/a&gt; Configuration-free text editor and IDE with support for tab completion with Ollama.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/molbal/orca-cli"&gt;orca-cli&lt;/a&gt; Ollama Registry CLI Application - Browse, pull, and download models from Ollama Registry in your terminal.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jonathanhecl/gguf-to-ollama"&gt;GGUF-to-Ollama&lt;/a&gt; - Importing GGUF to Ollama made easy (multiplatform)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/rapidarchitect/ollama_strands"&gt;AWS-Strands-With-Ollama&lt;/a&gt; - AWS Strands Agents with Ollama Examples&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/attogram/ollama-multirun"&gt;ollama-multirun&lt;/a&gt; - A bash shell script to run a single prompt against any or all of your locally installed ollama models, saving the output and performance statistics as easily navigable web pages. (&lt;a href="https://attogram.github.io/ai_test_zone/"&gt;Demo&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/attogram/ollama-bash-toolshed"&gt;ollama-bash-toolshed&lt;/a&gt; - Bash scripts to chat with tool using models. Add new tools to your shed with ease. Runs on Ollama.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/vinhnx/vtcode"&gt;VT Code&lt;/a&gt; - VT Code is a Rust-based terminal coding agent with semantic code intelligence via Tree-sitter. Ollama integration for running local/cloud models with configurable endpoints.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Apple Vision Pro&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/aws-samples/swift-chat"&gt;SwiftChat&lt;/a&gt; (Cross-platform AI chat app supporting Apple Vision Pro via "Designed for iPad")&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/AugustDev/enchanted"&gt;Enchanted&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Database&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/timescale/pgai"&gt;pgai&lt;/a&gt; - PostgreSQL as a vector database (Create and search embeddings from Ollama models using pgvector) 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/timescale/pgai/raw/main/docs/vectorizer-quick-start.md"&gt;Get started guide&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mindsdb/mindsdb/raw/staging/mindsdb/integrations/handlers/ollama_handler/README.md"&gt;MindsDB&lt;/a&gt; (Connects Ollama models with nearly 200 data platforms and apps)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/philippgille/chromem-go/raw/v0.5.0/embed_ollama.go"&gt;chromem-go&lt;/a&gt; with &lt;a href="https://github.com/philippgille/chromem-go/tree/v0.5.0/examples/rag-wikipedia-ollama"&gt;example&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/dbkangaroo/kangaroo"&gt;Kangaroo&lt;/a&gt; (AI-powered SQL client and admin tool for popular databases)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Package managers&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://archlinux.org/packages/extra/x86_64/ollama/"&gt;Pacman&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/gentoo/guru/tree/master/app-misc/ollama"&gt;Gentoo&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://formulae.brew.sh/formula/ollama"&gt;Homebrew&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://artifacthub.io/packages/helm/ollama-helm/ollama"&gt;Helm Chart&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://codeberg.org/tusharhero/ollama-guix"&gt;Guix channel&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://search.nixos.org/packages?show=ollama&amp;amp;from=0&amp;amp;size=50&amp;amp;sort=relevance&amp;amp;type=packages&amp;amp;query=ollama"&gt;Nix package&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://flox.dev/blog/ollama-part-one"&gt;Flox&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Libraries&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://python.langchain.com/docs/integrations/chat/ollama/"&gt;LangChain&lt;/a&gt; and &lt;a href="https://js.langchain.com/docs/integrations/chat/ollama/"&gt;LangChain.js&lt;/a&gt; with &lt;a href="https://js.langchain.com/docs/tutorials/local_rag/"&gt;example&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://firebase.google.com/docs/genkit/plugins/ollama"&gt;Firebase Genkit&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/crewAIInc/crewAI"&gt;crewAI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://remembersoftwares.github.io/yacana/"&gt;Yacana&lt;/a&gt; (User-friendly multi-agent framework for brainstorming and executing predetermined flows with built-in tool integration)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/strands-agents/sdk-python"&gt;Strands Agents&lt;/a&gt; (A model-driven approach to building AI agents in just a few lines of code)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/spring-projects/spring-ai"&gt;Spring AI&lt;/a&gt; with &lt;a href="https://docs.spring.io/spring-ai/reference/api/chat/ollama-chat.html"&gt;reference&lt;/a&gt; and &lt;a href="https://github.com/tzolov/ollama-tools"&gt;example&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tmc/langchaingo/"&gt;LangChainGo&lt;/a&gt; with &lt;a href="https://github.com/tmc/langchaingo/tree/main/examples/ollama-completion-example"&gt;example&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/langchain4j/langchain4j"&gt;LangChain4j&lt;/a&gt; with &lt;a href="https://github.com/langchain4j/langchain4j-examples/tree/main/ollama-examples/src/main/java"&gt;example&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Abraxas-365/langchain-rust"&gt;LangChainRust&lt;/a&gt; with &lt;a href="https://github.com/Abraxas-365/langchain-rust/raw/main/examples/llm_ollama.rs"&gt;example&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tryAGI/LangChain"&gt;LangChain for .NET&lt;/a&gt; with &lt;a href="https://github.com/tryAGI/LangChain/raw/main/examples/LangChain.Samples.OpenAI/Program.cs"&gt;example&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/theodo-group/LLPhant?tab=readme-ov-file#ollama"&gt;LLPhant&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.llamaindex.ai/en/stable/examples/llm/ollama/"&gt;LlamaIndex&lt;/a&gt; and &lt;a href="https://ts.llamaindex.ai/modules/llms/available_llms/ollama"&gt;LlamaIndexTS&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/BerriAI/litellm"&gt;LiteLLM&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/presbrey/ollamafarm"&gt;OllamaFarm for Go&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/awaescher/OllamaSharp"&gt;OllamaSharp for .NET&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/gbaptista/ollama-ai"&gt;Ollama for Ruby&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pepperoni21/ollama-rs"&gt;Ollama-rs for Rust&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jmont-dev/ollama-hpp"&gt;Ollama-hpp for C++&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ollama4j/ollama4j"&gt;Ollama4j for Java&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://modelfusion.dev/integration/model-provider/ollama"&gt;ModelFusion Typescript Library&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/kevinhermawan/OllamaKit"&gt;OllamaKit for Swift&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/breitburg/dart-ollama"&gt;Ollama for Dart&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/cloudstudio/ollama-laravel"&gt;Ollama for Laravel&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/davidmigloz/langchain_dart"&gt;LangChainDart&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/microsoft/semantic-kernel/tree/main/python/semantic_kernel/connectors/ai/ollama"&gt;Semantic Kernel - Python&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/deepset-ai/haystack-integrations/raw/main/integrations/ollama.md"&gt;Haystack&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/brainlid/langchain"&gt;Elixir LangChain&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/JBGruber/rollama"&gt;Ollama for R - rollama&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/hauselin/ollama-r"&gt;Ollama for R - ollama-r&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/lebrunel/ollama-ex"&gt;Ollama-ex for Elixir&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/b-tocs/abap_btocs_ollama"&gt;Ollama Connector for SAP ABAP&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://testcontainers.com/modules/ollama/"&gt;Testcontainers&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://portkey.ai/docs/welcome/integration-guides/ollama"&gt;Portkey&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/svilupp/PromptingTools.jl"&gt;PromptingTools.jl&lt;/a&gt; with an &lt;a href="https://svilupp.github.io/PromptingTools.jl/dev/examples/working_with_ollama"&gt;example&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Project-Llama/llamascript"&gt;LlamaScript&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/emirsahin1/llm-axe"&gt;llm-axe&lt;/a&gt; (Python Toolkit for Building LLM Powered Apps)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.gollm.co/examples/ollama-example"&gt;Gollm&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jonathanhecl/gollama"&gt;Gollama for Golang&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/xyproto/ollamaclient"&gt;Ollamaclient for Golang&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://gitlab.com/tozd/go/fun"&gt;High-level function abstraction in Go&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ArdaGnsrn/ollama-php"&gt;Ollama PHP&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/agents-flex/agents-flex"&gt;Agents-Flex for Java&lt;/a&gt; with &lt;a href="https://github.com/agents-flex/agents-flex/tree/main/agents-flex-llm/agents-flex-llm-ollama/src/test/java/com/agentsflex/llm/ollama"&gt;example&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/parakeet-nest/parakeet"&gt;Parakeet&lt;/a&gt; is a GoLang library, made to simplify the development of small generative AI applications with Ollama.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/andygill/haverscript"&gt;Haverscript&lt;/a&gt; with &lt;a href="https://github.com/andygill/haverscript/tree/main/examples"&gt;examples&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mattt/ollama-swift"&gt;Ollama for Swift&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/marcusziade/Swollama"&gt;Swollama for Swift&lt;/a&gt; with &lt;a href="https://marcusziade.github.io/Swollama/documentation/swollama/"&gt;DocC&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/prasad89/golamify"&gt;GoLamify&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tusharad/ollama-haskell"&gt;Ollama for Haskell&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/nbonamy/multi-llm-ts"&gt;multi-llm-ts&lt;/a&gt; (A Typescript/JavaScript library allowing access to different LLM in a unified API)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/lofcz/llmtornado"&gt;LlmTornado&lt;/a&gt; (C# library providing a unified interface for major FOSS &amp;amp; Commercial inference APIs)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/dravenk/ollama-zig"&gt;Ollama for Zig&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/lunary-ai/abso"&gt;Abso&lt;/a&gt; (OpenAI-compatible TypeScript SDK for any LLM provider)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/goodreasonai/nichey"&gt;Nichey&lt;/a&gt; is a Python package for generating custom wikis for your research topic&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/kassane/ollama-d"&gt;Ollama for D&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/HardCodeDev777/OllamaPlusPlus"&gt;OllamaPlusPlus&lt;/a&gt; (Very simple C++ library for Ollama)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mozilla-ai/any-llm"&gt;any-llm&lt;/a&gt; (A single interface to use different llm providers by &lt;a href="https://www.mozilla.ai/"&gt;mozilla.ai&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mozilla-ai/any-agent"&gt;any-agent&lt;/a&gt; (A single interface to use and evaluate different agent frameworks by &lt;a href="https://www.mozilla.ai/"&gt;mozilla.ai&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/cognizant-ai-lab/neuro-san-studio"&gt;Neuro SAN&lt;/a&gt; (Data-driven multi-agent orchestration framework) with &lt;a href="https://github.com/cognizant-ai-lab/neuro-san-studio/raw/main/docs/user_guide.md#ollama"&gt;example&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ai-bot-pro/achatbot-go"&gt;achatbot-go&lt;/a&gt; a multimodal(text/audio/image) chatbot.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/attogram/ollama-bash-lib"&gt;Ollama Bash Lib&lt;/a&gt; - A Bash Library for Ollama. Run LLM prompts straight from your shell, and more&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Mobile&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/aws-samples/swift-chat"&gt;SwiftChat&lt;/a&gt; (Lightning-fast Cross-platform AI chat app with native UI for Android, iOS, and iPad)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/AugustDev/enchanted"&gt;Enchanted&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Mobile-Artificial-Intelligence/maid"&gt;Maid&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/JHubi1/ollama-app"&gt;Ollama App&lt;/a&gt; (Modern and easy-to-use multi-platform client for Ollama)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/1runeberg/confichat"&gt;ConfiChat&lt;/a&gt; (Lightweight, standalone, multi-platform, and privacy-focused LLM chat interface with optional encryption)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/sunshine0523/OllamaServer"&gt;Ollama Android Chat&lt;/a&gt; (No need for Termux, start the Ollama service with one click on an Android device)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ibrahimcetin/reins"&gt;Reins&lt;/a&gt; (Easily tweak parameters, customize system prompts per chat, and enhance your AI experiments with reasoning model support.)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Extensions &amp;amp; Plugins&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/MassimilianoPasquini97/raycast_ollama"&gt;Raycast extension&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mxyng/discollama"&gt;Discollama&lt;/a&gt; (Discord bot inside the Ollama discord channel)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/continuedev/continue"&gt;Continue&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/thewh1teagle/vibe"&gt;Vibe&lt;/a&gt; (Transcribe and analyze meetings with Ollama)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/hinterdupfinger/obsidian-ollama"&gt;Obsidian Ollama plugin&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/omagdy7/ollama-logseq"&gt;Logseq Ollama plugin&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/andersrex/notesollama"&gt;NotesOllama&lt;/a&gt; (Apple Notes Ollama plugin)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/samalba/dagger-chatbot"&gt;Dagger Chatbot&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mekb-turtle/discord-ai-bot"&gt;Discord AI Bot&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ruecat/ollama-telegram"&gt;Ollama Telegram Bot&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ej52/hass-ollama-conversation"&gt;Hass Ollama Conversation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/abrenneke/rivet-plugin-ollama"&gt;Rivet plugin&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/longy2k/obsidian-bmo-chatbot"&gt;Obsidian BMO Chatbot plugin&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/herval/cliobot"&gt;Cliobot&lt;/a&gt; (Telegram bot with Ollama support)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/logancyang/obsidian-copilot"&gt;Copilot for Obsidian plugin&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pfrankov/obsidian-local-gpt"&gt;Obsidian Local GPT plugin&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.openinterpreter.com/language-model-setup/local-models/ollama"&gt;Open Interpreter&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ex3ndr/llama-coder"&gt;Llama Coder&lt;/a&gt; (Copilot alternative using Ollama)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/bernardo-bruning/ollama-copilot"&gt;Ollama Copilot&lt;/a&gt; (Proxy that allows you to use Ollama as a copilot like GitHub Copilot)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/rjmacarthy/twinny"&gt;twinny&lt;/a&gt; (Copilot and Copilot chat alternative using Ollama)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/RussellCanfield/wingman-ai"&gt;Wingman-AI&lt;/a&gt; (Copilot code and chat alternative using Ollama and Hugging Face)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/n4ze3m/page-assist"&gt;Page Assist&lt;/a&gt; (Chrome Extension)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/imoize/plasmoid-ollamacontrol"&gt;Plasmoid Ollama Control&lt;/a&gt; (KDE Plasma extension that allows you to quickly manage/control Ollama model)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tusharhero/aitelegrambot"&gt;AI Telegram Bot&lt;/a&gt; (Telegram bot using Ollama in backend)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/yaroslavyaroslav/OpenAI-sublime-text"&gt;AI ST Completion&lt;/a&gt; (Sublime Text 4 AI assistant plugin with Ollama support)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/kevinthedang/discord-ollama"&gt;Discord-Ollama Chat Bot&lt;/a&gt; (Generalized TypeScript Discord Bot w/ Tuning Documentation)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/josStorer/chatGPTBox"&gt;ChatGPTBox: All in one browser extension&lt;/a&gt; with &lt;a href="https://github.com/josStorer/chatGPTBox/issues/616#issuecomment-1975186467"&gt;Integrating Tutorial&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/rapmd73/Companion"&gt;Discord AI chat/moderation bot&lt;/a&gt; Chat/moderation bot written in python. Uses Ollama to create personalities.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/nischalj10/headless-ollama"&gt;Headless Ollama&lt;/a&gt; (Scripts to automatically install ollama client &amp;amp; models on any OS for apps that depend on ollama server)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/xuyangbocn/terraform-aws-self-host-llm"&gt;Terraform AWS Ollama &amp;amp; Open WebUI&lt;/a&gt; (A Terraform module to deploy on AWS a ready-to-use Ollama service, together with its front-end Open WebUI service.)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jakubburkiewicz/node-red-contrib-ollama"&gt;node-red-contrib-ollama&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ivostoykov/localAI"&gt;Local AI Helper&lt;/a&gt; (Chrome and Firefox extensions that enable interactions with the active tab and customisable API endpoints. Includes secure storage for user prompts.)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jake83741/vnc-lm"&gt;vnc-lm&lt;/a&gt; (Discord bot for messaging with LLMs through Ollama and LiteLLM. Seamlessly move between local and flagship models.)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/SilasMarvin/lsp-ai"&gt;LSP-AI&lt;/a&gt; (Open-source language server for AI-powered functionality)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Palm1r/QodeAssist"&gt;QodeAssist&lt;/a&gt; (AI-powered coding assistant plugin for Qt Creator)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ECuiDev/obsidian-quiz-generator"&gt;Obsidian Quiz Generator plugin&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/philffm/ai-summary-helper"&gt;AI Summmary Helper plugin&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/suncloudsmoon/TextCraft"&gt;TextCraft&lt;/a&gt; (Copilot in Word alternative using Ollama)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/zeitlings/alfred-ollama"&gt;Alfred Ollama&lt;/a&gt; (Alfred Workflow)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/adarshM84/TextLLaMA"&gt;TextLLaMA&lt;/a&gt; A Chrome Extension that helps you write emails, correct grammar, and translate into any language&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/zyphixor/simple-discord-ai"&gt;Simple-Discord-AI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/innightwolfsleep/llm_telegram_bot"&gt;LLM Telegram Bot&lt;/a&gt; (telegram bot, primary for RP. Oobabooga-like buttons, &lt;a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui"&gt;A1111&lt;/a&gt; API integration e.t.c)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/sammcj/mcp-llm"&gt;mcp-llm&lt;/a&gt; (MCP Server to allow LLMs to call other LLMs)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/HardCodeDev777/SimpleOllamaUnity"&gt;SimpleOllamaUnity&lt;/a&gt; (Unity Engine extension for communicating with Ollama in a few lines of code. Also works at runtime)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/HardCodeDev777/UnityCodeLama"&gt;UnityCodeLama&lt;/a&gt; (Unity Edtior tool to analyze scripts via Ollama)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/NativeMindBrowser/NativeMindExtension"&gt;NativeMind&lt;/a&gt; (Private, on-device AI Assistant, no cloud dependencies)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://gmai.premex.se/"&gt;GMAI - Gradle Managed AI&lt;/a&gt; (Gradle plugin for automated Ollama lifecycle management during build phases)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/nomyo-ai/nomyo-router"&gt;NOMYO Router&lt;/a&gt; (A transparent Ollama proxy with model deployment aware routing which auto-manages multiple Ollama instances in a given network)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Supported backends&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ggml-org/llama.cpp"&gt;llama.cpp&lt;/a&gt; project founded by Georgi Gerganov.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Observability&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.comet.com/docs/opik/cookbook/ollama"&gt;Opik&lt;/a&gt; is an open-source platform to debug, evaluate, and monitor your LLM applications, RAG systems, and agentic workflows with comprehensive tracing, automated evaluations, and production-ready dashboards. Opik supports native intergration to Ollama.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://lunary.ai/docs/integrations/ollama"&gt;Lunary&lt;/a&gt; is the leading open-source LLM observability platform. It provides a variety of enterprise-grade features such as real-time analytics, prompt templates management, PII masking, and comprehensive agent tracing.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/openlit/openlit"&gt;OpenLIT&lt;/a&gt; is an OpenTelemetry-native tool for monitoring Ollama Applications &amp;amp; GPUs using traces and metrics.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.honeyhive.ai/integrations/ollama"&gt;HoneyHive&lt;/a&gt; is an AI observability and evaluation platform for AI agents. Use HoneyHive to evaluate agent performance, interrogate failures, and monitor quality in production.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://langfuse.com/docs/integrations/ollama"&gt;Langfuse&lt;/a&gt; is an open source LLM observability platform that enables teams to collaboratively monitor, evaluate and debug AI applications.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://mlflow.org/docs/latest/llms/tracing/index.html#automatic-tracing"&gt;MLflow Tracing&lt;/a&gt; is an open source LLM observability tool with a convenient API to log and visualize traces, making it easy to debug and evaluate GenAI applications.&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
  </channel>
</rss>