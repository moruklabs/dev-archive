<rss version="2.0">
  <channel>
    <title>GitHub Python Daily Trending</title>
    <description>Daily Trending of Python in GitHub</description>
    <pubDate>Fri, 05 Sep 2025 01:36:40 GMT</pubDate>
    <link>http://mshibanami.github.io/GitHubTrendingRSS</link>
    
    <item>
      <title>socfortress/Wazuh-Rules</title>
      <link>https://github.com/socfortress/Wazuh-Rules</link>
      <description>&lt;p&gt;Advanced Wazuh Rules for more accurate threat detection. Feel free to implement within your own Wazuh environment, contribute, or fork!&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href="https://www.socfortress.co/"&gt;&lt;img src="https://raw.githubusercontent.com/socfortress/Wazuh-Rules/main/images/logo_orange.svg?sanitize=true" align="right" width="100" height="100" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Advanced Wazuh Detection Rules &lt;a href="https://www.socfortress.co/trial.html"&gt;&lt;img src="https://img.shields.io/badge/SOCFortress-Worlds%20First%20Free%20Cloud%20SOC-orange" alt="Awesome" /&gt;&lt;/a&gt;&lt;/h1&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;The SOCFortress Team has committed to contributing to the Open Source community. We hope you find these rulesets helpful and robust as you work to keep your networks secure.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;a href="https://github.com/socfortress/Wazuh-Rules/network/members"&gt;&lt;img src="https://img.shields.io/github/forks/socfortress/Wazuh-Rules" alt="Forks" /&gt;&lt;/a&gt; &lt;a href="https://github.com/socfortress/Wazuh-Rules/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/socfortress/Wazuh-Rules" alt="Stargazers" /&gt;&lt;/a&gt; &lt;a href="https://socfortress.supportbench.net"&gt;&lt;img src="https://img.shields.io/badge/Help%20Desk-Help%20Desk-blue" alt="MIT License" /&gt;&lt;/a&gt; &lt;a href="https://www.socfortress.co/"&gt;&lt;img src="https://img.shields.io/badge/Visit%20Us-www.socfortress.co-orange" alt="LinkedIn" /&gt;&lt;/a&gt; &lt;a href="https://www.socfortress.co/trial.html"&gt;&lt;img src="https://img.shields.io/badge/Get%20Started-FREE%20FOR%20LIFE%20TIER-orange" alt="your-own-soc-free-for-life-tier" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;!-- PROJECT LOGO --&gt; 
&lt;br /&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://github.com/socfortress/Wazuh-Rules"&gt; &lt;img src="https://raw.githubusercontent.com/socfortress/Wazuh-Rules/main/images/logo_orange.svg?sanitize=true" alt="Logo" width="100" height="100" /&gt; &lt;img src="https://raw.githubusercontent.com/socfortress/Wazuh-Rules/main/images/wazuh_logo.png" alt="Logo" /&gt; &lt;/a&gt; 
 &lt;h3 align="center"&gt;Advanced Wazuh Detection Rules&lt;/h3&gt; 
 &lt;p align="center"&gt; Have Wazuh deployed and ingesting your logs but looking for some better detection rules? Look no further. The objective for this repo is to provide the Wazuh community with rulesets that are more accurate, descriptive, and enriched from various sources and integrations. &lt;br /&gt; &lt;a href="https://www.socfortress.co/index.html"&gt;&lt;strong&gt;Worlds First Open Source Cloud SOC ¬ª&lt;/strong&gt;&lt;/a&gt; &lt;br /&gt; &lt;br /&gt; &lt;a href="https://documentation.wazuh.com/current/index.html"&gt;Wazuh Docs&lt;/a&gt; ¬∑ &lt;a href="https://www.socfortress.co/trial.html"&gt;FREE FOR LIFE TIER&lt;/a&gt; ¬∑ &lt;a href="https://socfortress.medium.com/"&gt;Our Blog&lt;/a&gt; &lt;/p&gt; 
&lt;/div&gt; 
&lt;!-- TABLE OF CONTENTS --&gt; 
&lt;details&gt; 
 &lt;summary&gt;Table of Contents&lt;/summary&gt; 
 &lt;ol&gt; 
  &lt;li&gt; &lt;a href="https://raw.githubusercontent.com/socfortress/Wazuh-Rules/main/#about-this-repo"&gt;About This Repo&lt;/a&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/socfortress/Wazuh-Rules/main/#supported-rules-and-integrations"&gt;Supported Rules and Integrations&lt;/a&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;a href="https://raw.githubusercontent.com/socfortress/Wazuh-Rules/main/#getting-started"&gt;Getting Started&lt;/a&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/socfortress/Wazuh-Rules/main/#prerequisites"&gt;Prerequisites&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/socfortress/Wazuh-Rules/main/#installation"&gt;Installation&lt;/a&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/socfortress/Wazuh-Rules/main/#contributing"&gt;Contributing&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/socfortress/Wazuh-Rules/main/#contact"&gt;Contact&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/socfortress/Wazuh-Rules/main/#acknowledgments"&gt;Acknowledgments&lt;/a&gt;&lt;/li&gt; 
 &lt;/ol&gt; 
&lt;/details&gt; 
&lt;!-- ABOUT THE PROJECT --&gt; 
&lt;h2&gt;About This Repo&lt;/h2&gt; 
&lt;p&gt;The objective for this repo is to provide the Wazuh community with rulesets that are more accurate, descriptive, and enriched from various sources and integrations.&lt;/p&gt; 
&lt;p&gt;Here's why:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Detection rules can be a tricky business and we believe everyone should have access to a strong and growing ruleset.&lt;/li&gt; 
 &lt;li&gt;Wazuh serves as a great EDR agent, however the default rulesets are rather laxed (in our opinion). We wanted to start building a strong repo of Wazuh rules for the community to implement themselves and expand upon as new threats arise.&lt;/li&gt; 
 &lt;li&gt;Cybersecurity is hard enough, let's work together &lt;span&gt;üòÑ&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p align="right"&gt;(&lt;a href="https://raw.githubusercontent.com/socfortress/Wazuh-Rules/main/#readme-top"&gt;back to top&lt;/a&gt;)&lt;/p&gt; 
&lt;h3&gt;Supported Rules and Integrations&lt;/h3&gt; 
&lt;p&gt;Below are the current rules and integrations currently contained within this repo. Integrations, such as Office365, Trend Micro, etc. will have scripts provided within their respective folders for use. Feel free to build upon these scripts and contribute back &lt;span&gt;üòÑ&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/socfortress/Wazuh-Rules/tree/main/Windows_Sysmon"&gt;Sysmon for Windows&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/socfortress/Wazuh-Rules/tree/main/Sysmon%20Linux"&gt;Sysmon for Linux&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/socfortress/Wazuh-Rules/tree/main/Office%20365"&gt;Office365&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/socfortress/Wazuh-Rules/tree/main/Office%20Defender"&gt;Microsoft Defender&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/socfortress/Wazuh-Rules/tree/main/Sophos"&gt;Sophos&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/socfortress/Wazuh-Rules/tree/main/MISP"&gt;MISP&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/socfortress/Wazuh-Rules/tree/main/Osquery"&gt;Osquery&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/socfortress/Wazuh-Rules/tree/main/Yara"&gt;Yara&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/socfortress/Wazuh-Rules/tree/main/Suricata"&gt;Suricata&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/socfortress/Wazuh-Rules/tree/main/Packetbeat"&gt;Packetbeat&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/socfortress/Wazuh-Rules/tree/main/Falco"&gt;Falco&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/socfortress/Wazuh-Rules/tree/main/Modsecurity"&gt;Modsecurity&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/socfortress/Wazuh-Rules/tree/main/F-Secure"&gt;F-Secure&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/socfortress/Wazuh-Rules/tree/main/Domain%20Stats"&gt;Domain Stats&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/socfortress/Wazuh-Rules/tree/main/Snyk"&gt;Snyk&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/socfortress/Wazuh-Rules/tree/main/Windows%20Autoruns"&gt;Autoruns&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/socfortress/Wazuh-Rules/tree/main/Windows%20Sysinternals%20Sigcheck"&gt;Sigcheck&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/socfortress/Wazuh-Rules/tree/main/Windows%20Powershell"&gt;Powershell&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/socfortress/Wazuh-Rules/tree/main/Crowdstrike"&gt;Crowdstrike&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/socfortress/Wazuh-Rules/tree/main/Domain%20Stats"&gt;Alienvault&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Tessian - WIP&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Roadmap&lt;/h3&gt; 
&lt;p&gt;Have an Integration already configured that you'd like to share? Or have an idea for an Integration that you would like help on? Feel free to add it to the Roadmap.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Feel free to bring ideas &lt;span&gt;üòÑ&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p align="right"&gt;(&lt;a href="https://raw.githubusercontent.com/socfortress/Wazuh-Rules/main/#readme-top"&gt;back to top&lt;/a&gt;)&lt;/p&gt; 
&lt;!-- GETTING STARTED --&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;p&gt;Feel free to implement all of the rules that are contained within this repo, or pick and choose as you see fit. See our Installation section below for a bash script that can be ran on your Wazuh Manager to quickly put these rules to work!&lt;/p&gt; 
&lt;h3&gt;Prerequisites&lt;/h3&gt; 
&lt;p&gt;Wazuh-Manager Version 4.x Required.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://documentation.wazuh.com/current/index.html"&gt;Wazuh Install Docs&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.socfortress.co/contact_form.html"&gt;Need Assitance? - Hire SOCFortress&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Installation&lt;/h3&gt; 
&lt;p&gt;&lt;em&gt;You can either manually download the .xml rule files onto your Wazuh Manager or make use of our wazuh_socfortress_rules.sh script&lt;/em&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;span&gt;‚ö†&lt;/span&gt; &lt;strong&gt;USE AT OWN RISK&lt;/strong&gt;: If you already have custom rules built out, there is a good chance duplicate Rule IDs will exists. This will casue the Wazuh-Manager service to fail! Ensure there are no conflicting Rule IDs and your custom rules are backed up prior to running the wazuh_socfortress_rules.sh script!&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ol&gt; 
 &lt;li&gt;Become Root User&lt;/li&gt; 
 &lt;li&gt;Run the Script &lt;pre&gt;&lt;code class="language-sh"&gt;curl -so ~/wazuh_socfortress_rules.sh https://raw.githubusercontent.com/socfortress/Wazuh-Rules/main/wazuh_socfortress_rules.sh &amp;amp;&amp;amp; bash ~/wazuh_socfortress_rules.sh
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;img src="https://github.com/socfortress/Wazuh-Rules/raw/main/images/run%20install.gif" alt="Alt Text" /&gt;&lt;/p&gt; 
&lt;p align="right"&gt;(&lt;a href="https://raw.githubusercontent.com/socfortress/Wazuh-Rules/main/#readme-top"&gt;back to top&lt;/a&gt;)&lt;/p&gt; 
&lt;!-- CONTRIBUTING --&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Contributions are what make the open source community such an amazing place to learn, inspire, and create. Any contributions you make are &lt;strong&gt;greatly appreciated&lt;/strong&gt;.&lt;/p&gt; 
&lt;p&gt;If you have a suggestion that would make this better, please fork the repo and create a pull request. You can also simply open an issue with the tag "enhancement". Don't forget to give the project a star! Thanks again!&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Fork the Project&lt;/li&gt; 
 &lt;li&gt;Create your Feature Branch (&lt;code&gt;git checkout -b ruleCategory/DetectionRule&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;Commit your Changes (&lt;code&gt;git commit -m 'Add some DetectionRules'&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;Push to the Branch (&lt;code&gt;git push origin ruleCategory/DetectionRule&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;Open a Pull Request&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p align="right"&gt;(&lt;a href="https://raw.githubusercontent.com/socfortress/Wazuh-Rules/main/#readme-top"&gt;back to top&lt;/a&gt;)&lt;/p&gt; 
&lt;!-- CONTACT --&gt; 
&lt;h2&gt;Contact&lt;/h2&gt; 
&lt;p&gt;SOCFortress - &lt;a href="https://www.socfortress.co/"&gt;&lt;img src="https://img.shields.io/badge/Visit%20Us-www.socfortress.co-orange" alt="LinkedIn" /&gt;&lt;/a&gt; - &lt;a href="mailto:info@socfortress.co"&gt;info@socfortress.co&lt;/a&gt;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;h2 align="center"&gt;Let SOCFortress Take Your Open Source SIEM to the Next Level&lt;/h2&gt; 
 &lt;a href="https://www.socfortress.co/contact_form.html"&gt; &lt;img src="https://raw.githubusercontent.com/socfortress/Wazuh-Rules/main/images/Email%20Banner.png" alt="Banner" /&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;p align="right"&gt;(&lt;a href="https://raw.githubusercontent.com/socfortress/Wazuh-Rules/main/#readme-top"&gt;back to top&lt;/a&gt;)&lt;/p&gt; 
&lt;!-- ACKNOWLEDGMENTS --&gt; 
&lt;h2&gt;Acknowledgments&lt;/h2&gt; 
&lt;p&gt;Security is best when we work together! Huge thank you to those supporting and those future supporters!&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://documentation.wazuh.com/current/index.html"&gt;Wazuh Team&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/channel/UC4EUQtTxeC8wGrKRafI6pZg"&gt;Taylor Walton&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/juaromu"&gt;Juan Romero&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;!-- MARKDOWN LINKS &amp; IMAGES --&gt; 
&lt;!-- https://www.markdownguide.org/basic-syntax/#reference-style-links --&gt;</description>
    </item>
    
    <item>
      <title>slavakurilyak/awesome-ai-agents</title>
      <link>https://github.com/slavakurilyak/awesome-ai-agents</link>
      <description>&lt;p&gt;Awesome list of 300+ agentic AI resources&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;img src="https://github.com/slavakurilyak/awesome-ai-agents/assets/6625584/f37cd4ef-84e7-424d-93d7-40a3086e3c95" height="300" alt="Awesome List of AI Agents" /&gt; &lt;/p&gt; 
&lt;h1 align="center"&gt;Awesome List of AI Agents&lt;/h1&gt; 
&lt;p align="center"&gt; üîó Follow Slava for more agentic AI resources &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://twitter.com/slavakurilyak"&gt;üê¶ Twitter&lt;/a&gt; | &lt;a href="https://linkedin.com/in/slavakurilyak"&gt;üíº LinkedIn&lt;/a&gt; | &lt;a href="https://github.com/slavakurilyak"&gt;üêô Github&lt;/a&gt; &lt;/p&gt; 
&lt;p&gt;This project tracks the latest agentic AI projects and provides a list of 200+ resources, curated by Slava Kurilyak&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Wait But Why&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;AI agents outperform traditional LLMs&lt;/p&gt; 
&lt;p&gt;According to &lt;a href="https://github.com/andrewyng"&gt;Andrew Ng (@andrewyng)&lt;/a&gt;:&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;"GPT-3.5 with an agentic workflow actually outperforms GPT-4"&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;üèÜ Top 10 Projects&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Significant-Gravitas/AutoGPT"&gt;&lt;strong&gt;AutoGPT&lt;/strong&gt;&lt;/a&gt; - 177,350 stars (Updated: 2025-07-30)&lt;br /&gt;AutoGPT provides accessible AI tools for building and using AI agents, offering a comprehensive framework including Forge for agent creation, agbenchmark for performance evaluation, a leaderboard for competition, a user-friendly UI, and CLI for seamless integration and management&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ollama/ollama"&gt;&lt;strong&gt;Ollama&lt;/strong&gt;&lt;/a&gt; - 147,994 stars (Updated: 2025-07-30)&lt;br /&gt;Ollama is a tool for running large language models locally, offering easy setup for macOS, Windows, Linux, and Docker, along with a library of models and quickstart guides for customization and integration&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/langchain-ai/langchain"&gt;&lt;strong&gt;LangChain&lt;/strong&gt;&lt;/a&gt; - 112,549 stars (Updated: 2025-07-30)&lt;br /&gt;LangChain is a framework enabling context-aware reasoning applications with integrated libraries, templates, and developer tools&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/langchain-ai/langchain/"&gt;&lt;strong&gt;LangChain Tools&lt;/strong&gt;&lt;/a&gt; - 112,549 stars (Updated: 2025-07-30)&lt;br /&gt;Langchain integrates various providers like Anthropic, AWS, and OpenAI, and offers tools for components such as LLMs, chat models, and data analysis, supporting functionalities from Alpha Vantage to YouTube&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/lobehub/lobe-chat"&gt;&lt;strong&gt;Lobe Chat&lt;/strong&gt;&lt;/a&gt; - 63,923 stars (Updated: 2025-07-30)&lt;br /&gt;Lobe Chat is an open-source UI framework for building ChatGPT/LLM-based chat applications, featuring modern design, speech synthesis, multi-modal support, extensible plugins, and free one-click deployment for various AI agents&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/OpenDevin/OpenDevin"&gt;&lt;strong&gt;OpenDevin&lt;/strong&gt;&lt;/a&gt; - 61,429 stars (Updated: 2025-07-30)&lt;br /&gt;OpenDevin is an open-source initiative aimed at replicating and enhancing the autonomous AI software engineer Devin, focusing on collaboration and complex task execution in software development, emphasizing its relevance to advancing agentic AI technologies&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/OpenInterpreter/open-interpreter"&gt;&lt;strong&gt;Open Interpreter&lt;/strong&gt;&lt;/a&gt; - 60,095 stars (Updated: 2025-07-30)&lt;br /&gt;Open Interpreter is a coding agent enabling language models to execute code locally, facilitating natural-language interaction with your computer's capabilities, overcoming limitations of hosted solutions like internet access and package restrictions. It features interactive and programmatic chats, system message customization, and can control your computer's keyboard and mouse, allowing for enhanced control and flexibility in development environments&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/OpenInterpreter/open-interpreter"&gt;&lt;strong&gt;Open Interpreter&lt;/strong&gt;&lt;/a&gt; - 60,095 stars (Updated: 2025-07-30)&lt;br /&gt;Open Interpreter is a coding agent enabling language models to execute code locally, facilitating natural-language interaction with your computer's capabilities, overcoming limitations of hosted solutions like internet access and package restrictions. It features interactive and programmatic chats, system message customization, and can control your computer's keyboard and mouse, allowing for enhanced control and flexibility in development environments&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/geekan/MetaGPT"&gt;&lt;strong&gt;MetaGPT&lt;/strong&gt;&lt;/a&gt; - 57,568 stars (Updated: 2025-07-30)&lt;br /&gt;MetaGPT is a multi-agent framework enabling GPT to collaborate within a software company, facilitating complex tasks by assigning different roles to GPTs&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/zylon-ai/private-gpt/"&gt;&lt;strong&gt;PrivateGPT&lt;/strong&gt;&lt;/a&gt; - 56,373 stars (Updated: 2025-07-30)&lt;br /&gt;PrivateGPT is a secure, offline-capable AI tool for querying documents with Large Language Models, offering high-level and low-level APIs for privacy-conscious, context-aware application development&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;üöÄ Rising 10 Projects (Recently Active, Excluding Top 10)&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;a href="https://github.com/gpt-engineer-org/gpt-engineer"&gt;&lt;strong&gt;GPT Engineer&lt;/strong&gt;&lt;/a&gt; - 54,614 stars (Updated: 2025-07-30)&lt;br /&gt;GPT-Engineer is an AI-powered tool allowing users to specify software in natural language, automatically generating and executing code, with options for improvement suggestions, and fostering collaboration within the open-source community&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/microsoft/autogen"&gt;&lt;strong&gt;AutoGen by Microsoft&lt;/strong&gt;&lt;/a&gt; - 48,077 stars (Updated: 2025-07-30)&lt;br /&gt;AutoGen is a multi-agent conversation framework facilitating the development of next-gen LLM applications, highlighted by various accomplishments and offering enhanced LLM inferences, customizable agents, and comprehensive documentation&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/microsoft/autogen"&gt;&lt;strong&gt;AutoGen Studio by Microsoft&lt;/strong&gt;&lt;/a&gt; - 48,077 stars (Updated: 2025-07-30)&lt;br /&gt;AutoGen Studio 2.0 is Microsoft's advanced AI development tool, offering a user-friendly interface, powerful Python API, and comprehensive features for creating and controlling AI agents and workflows&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/run-llama/llama_index"&gt;&lt;strong&gt;LlamaIndex Tools&lt;/strong&gt;&lt;/a&gt; - 43,398 stars (Updated: 2025-07-30)&lt;br /&gt;LlamaIndex offers a variety of tools for building data agents, with top downloads including IonicShoppingToolSpec, OpenAPIToolSpec, WikipediaToolSpec, GmailToolSpec, and GoogleCalendarToolSpec, enabling seamless integration with user-defined functions, query engines, and third-party services&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/FlowiseAI/Flowise"&gt;&lt;strong&gt;Flowise&lt;/strong&gt;&lt;/a&gt; - 42,100 stars (Updated: 2025-07-30)&lt;br /&gt;Flowise simplifies the creation of applications leveraging large language models (LLMs) by providing a drag-and-drop interface for customizing AI workflows, offering easy installation, Docker support, development tools, and documentation for integrating various functionalities such as authentication, streaming, and custom tools to enhance AI agents' capabilities&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/lm-sys/FastChat"&gt;&lt;strong&gt;FastChat&lt;/strong&gt;&lt;/a&gt; - 38,916 stars (Updated: 2025-07-30)&lt;br /&gt;FastChat is a platform for training, serving, and evaluating large language model chatbots, featuring an open-source distributed multi-model system, API compatibility, and a dataset for LLM conversations&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mem0ai/mem0"&gt;&lt;strong&gt;mem0&lt;/strong&gt;&lt;/a&gt; - 37,574 stars (Updated: 2025-07-30)&lt;br /&gt;Mem0 is an intelligent memory layer for Large Language Models that enhances personalized AI experiences by retaining and utilizing contextual information across various applications.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/calcom/cal.com/tree/main/apps/ai"&gt;&lt;strong&gt;Cal.ai&lt;/strong&gt;&lt;/a&gt; - 37,384 stars (Updated: 2025-07-30)&lt;br /&gt;Cal.ai is an open-source AI scheduling assistant that manages email communications for booking, rearranging, and inquiring about meetings, leveraging a LangChain Agent Executor and MailParser for efficient scheduling without API key exposure&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/paul-gauthier/aider"&gt;&lt;strong&gt;Aider&lt;/strong&gt;&lt;/a&gt; - 36,185 stars (Updated: 2025-07-30)&lt;br /&gt;Aider is a command-line tool for AI-assisted pair programming, allowing code editing in local git repositories with GPT-3.5/GPT-4, featuring direct file edits, automatic git commits, and support for most popular programming languages&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/janhq/jan"&gt;&lt;strong&gt;Jan&lt;/strong&gt;&lt;/a&gt; - 35,212 stars (Updated: 2025-07-30)&lt;br /&gt;Jan is an open-source, development-stage ChatGPT alternative that operates fully offline on diverse hardware platforms, supporting universal architectures from PCs to multi-GPU clusters&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;‚úçÔ∏è All Projects&lt;/h2&gt; 
&lt;p&gt;Here's an awesome list of AI agents:&lt;/p&gt; 
&lt;h3&gt;01&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/OpenInterpreter/01"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/OpenInterpreter/01"&gt;&lt;img src="https://img.shields.io/github/stars/OpenInterpreter/01?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 5,080 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;‚åö Hardware (Wearables)&lt;/p&gt; 
&lt;p&gt;The '01 Project' by Open Interpreter is an open-source initiative focused on creating an ecosystem for AI devices, aiming to become the GNU/Linux in this domain, with details on its experimental status, software, hardware, and a speech-to-speech interface based on a code-interpreting language model for dynamic interactions&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://changes.openinterpreter.com/log/introducing-the-01-developer-preview"&gt;announcement&lt;/a&gt; | &lt;a href="https://twitter.com/OpenInterpreter/status/1770821439458840846"&gt;demo&lt;/a&gt; | &lt;a href="https://github.com/OpenInterpreter/01"&gt;github&lt;/a&gt; | &lt;a href="http://openinterpreter.com/01"&gt;website&lt;/a&gt; | &lt;a href="https://01.openinterpreter.com/"&gt;docs&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;Adala&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/HumanSignal/Adala"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/HumanSignal/Adala"&gt;&lt;img src="https://img.shields.io/github/stars/HumanSignal/Adala?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 1,228 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;‚öôÔ∏è Development Frameworks&lt;/p&gt; 
&lt;p&gt;Adala is a framework for autonomous data labeling agents, supporting Python 3.8 to 3.11, with features for customizable, intelligent data processing and integration into Python Notebooks&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/HumanSignal/Adala"&gt;github&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;Agency Swarm by VRSEN&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/VRSEN/agency-swarm"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/VRSEN/agency-swarm"&gt;&lt;img src="https://img.shields.io/github/stars/VRSEN/agency-swarm?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 3,729 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;‚öôÔ∏è Development Frameworks&lt;/p&gt; 
&lt;p&gt;Agency Swarm is a framework designed to automate AI agencies by creating a swarm of collaborative agents with customizable roles and functionalities, aiming to simplify the agent creation process and make automation more intuitive&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/VRSEN/agency-swarm"&gt;github&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;Agent by Stately AI&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/statelyai/agent/"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/statelyai/agent/"&gt;&lt;img src="https://img.shields.io/github/stars/statelyai/agent?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 299 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;ü§ñ AI Agents&lt;/p&gt; 
&lt;p&gt;Stately Agent is a software for building intelligent agents that interact via chat and events, with examples including joke generation, tic-tac-toe, and weather querying, requiring installation and an OpenAI API key&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/statelyai/agent/"&gt;github&lt;/a&gt; | &lt;a href="https://stately.ai/agent"&gt;website&lt;/a&gt; | &lt;a href="https://twitter.com/statelyai"&gt;twitter&lt;/a&gt; | &lt;a href="https://discord.gg/xstate"&gt;discord&lt;/a&gt; | &lt;a href="https://youtube.com/c/statelyai"&gt;youtube&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;Agent Protocol&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/AI-Engineer-Foundation/agent-protocol"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-No-red" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/AI-Engineer-Foundation/agent-protocol"&gt;&lt;img src="https://img.shields.io/github/stars/AI-Engineer-Foundation/agent-protocol?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 1,427 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;üìè Standardization&lt;/p&gt; 
&lt;p&gt;The Agent Protocol establishes a unified API standard for seamless interaction and integration across diverse AI agents, promoting ecosystem growth and simplification of agent development and benchmarking&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.aie.foundation/"&gt;website&lt;/a&gt; | &lt;a href="https://www.aie.foundation/"&gt;website&lt;/a&gt; | &lt;a href="https://github.com/AI-Engineer-Foundation/agent-protocol"&gt;github&lt;/a&gt; | &lt;a href="https://github.com/AI-Engineer-Foundation"&gt;github profile&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;Agent Tools&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/aibtcdev/agent-tools-ts"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/aibtcdev/agent-tools-ts"&gt;&lt;img src="https://img.shields.io/github/stars/aibtcdev/agent-tools-ts?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 16 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;‚Çø Bitcoin&lt;/p&gt; 
&lt;p&gt;Typescript tools for Bitcoin/Stacks blockchain interaction, utilizing Bun.js and Stacks.js, with a focus on AI integration&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/aibtcdev/agent-tools-ts"&gt;github&lt;/a&gt; | &lt;a href="https://github.com/aibtcdev"&gt;github profile&lt;/a&gt; | &lt;a href="https://aibtc.dev/"&gt;website&lt;/a&gt; | &lt;a href="https://discord.gg/5DJaBrf"&gt;discord&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;AgentBench&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/THUDM/AgentBench"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/THUDM/AgentBench"&gt;&lt;img src="https://img.shields.io/github/stars/THUDM/AgentBench?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 2,711 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;üìä Evaluation Frameworks&lt;/p&gt; 
&lt;p&gt;AgentBench v0.2 is a benchmark designed to evaluate Large Language Models as agents across a diverse set of environments, enhancing framework usability and extending model evaluations&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/THUDM/AgentBench"&gt;github&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;AgentGPT by Reworkd&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/reworkd/AgentGPT"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/reworkd/AgentGPT"&gt;&lt;img src="https://img.shields.io/github/stars/reworkd/AgentGPT?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 34,613 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;‚öôÔ∏è Development Frameworks&lt;/p&gt; 
&lt;p&gt;AgentGPT allows users to configure and deploy autonomous AI agents, enabling them to name their own custom AI and guide it towards any desired goal through task execution and learning&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/reworkd/AgentGPT"&gt;github&lt;/a&gt; | &lt;a href="https://github.com/reworkd"&gt;github profile&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;Agentive&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://agentivehub.com/"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-No-red" alt="Open Source" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚öôÔ∏è Development Frameworks&lt;/p&gt; 
&lt;p&gt;Agentive is a platform for AI Automation Agency owners, offering tools for creating, managing, and deploying custom AI solutions, with features like model selection, tool integration, prompt crafting, versioning, and training with own data, designed to simplify AI agent delivery&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://agentivehub.com/"&gt;website&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;AgentLabs&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/agentlabs-inc/agentlabs"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/agentlabs-inc/agentlabs"&gt;&lt;img src="https://img.shields.io/github/stars/agentlabs-inc/agentlabs?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 498 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;‚öôÔ∏è Development Frameworks&lt;/p&gt; 
&lt;p&gt;AgentLabs is an open-source, universal frontend solution for AI agents, offering an authentication portal, chat interface, analytics, and payment features to streamline the deployment of AI agents to public users&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/agentlabs-inc/agentlabs"&gt;github&lt;/a&gt; | &lt;a href="https://www.agentlabs.dev/"&gt;website&lt;/a&gt; | &lt;a href="https://docs.agentlabs.dev/"&gt;docs&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;AgentOps&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/AgentOps-AI/agentops"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/AgentOps-AI/agentops"&gt;&lt;img src="https://img.shields.io/github/stars/AgentOps-AI/agentops?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 4,716 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;üìä Evaluation Frameworks&lt;/p&gt; 
&lt;p&gt;AgentOps aims to improve AI agent development with tools for observability, evaluations, and replay analytics, offering a streamlined process for testing and debugging compliant AI agents through a user-friendly interface and comprehensive documentation&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/AgentOps-AI/agentops"&gt;github&lt;/a&gt; | &lt;a href="https://www.agentops.ai/"&gt;website&lt;/a&gt; | &lt;a href="https://docs.agentops.ai"&gt;docs&lt;/a&gt; | &lt;a href="https://discord.gg/mKW3ZhN9p2"&gt;discord&lt;/a&gt; | &lt;a href="https://x.com/AlexReibman/status/1772771418780176674"&gt;demo&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;AgentOS&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/smartcomputer-ai/agent-os"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/smartcomputer-ai/agent-os"&gt;&lt;img src="https://img.shields.io/github/stars/smartcomputer-ai/agent-os?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 125 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;‚öôÔ∏è Development Frameworks&lt;/p&gt; 
&lt;p&gt;The Agent OS is an experimental platform for creating self-evolving, autonomous AI agents capable of writing and executing their own code, designed to be a long-term environment for such agents and supports various programming languages&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/smartcomputer-ai/agent-os"&gt;github&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;Agents by AI Waves&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/aiwaves-cn/agents"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/aiwaves-cn/agents"&gt;&lt;img src="https://img.shields.io/github/stars/aiwaves-cn/agents?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 5,666 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;‚öôÔ∏è Development Frameworks&lt;/p&gt; 
&lt;p&gt;Agents is an open-source framework for building autonomous language agents with features including long-short term memory, tool usage, web navigation, multi-agent communication, human-agent interaction, and symbolic control, allowing customization through natural language config files and deployment in various interfaces&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/aiwaves-cn/agents"&gt;github&lt;/a&gt; | &lt;a href="https://github.com/aiwaves-cn"&gt;github profile&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;Agents by Hugging Face&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://huggingface.co/docs/transformers/main_classes/agent"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-No-red" alt="Open Source" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚öôÔ∏è Development Frameworks&lt;/p&gt; 
&lt;p&gt;Hugging Face's Transformers Agents provide three main types: HfAgent for inference with open-source models, LocalAgent for using local models and tokenizers, and OpenAiAgent for access to OpenAI's closed models, enabling code generation and other AI tasks with varying levels of customization and local or remote execution&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://huggingface.co/docs/transformers/main_classes/agent"&gt;website&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;Agentsy&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://x.com/AnnieLiao_2000/status/1792175318595453046"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-No-red" alt="Open Source" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;üõ†Ô∏è Build Club&lt;/p&gt; 
&lt;p&gt;Agentsy is an AI-driven platform designed to double team capacity by enhancing efficiency and creativity, starting with operations use cases like real estate&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://x.com/AnnieLiao_2000/status/1792175318595453046"&gt;demo&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;AgentVerse&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/OpenBMB/AgentVerse"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/OpenBMB/AgentVerse"&gt;&lt;img src="https://img.shields.io/github/stars/OpenBMB/AgentVerse?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 4,680 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;‚öôÔ∏è Development Frameworks&lt;/p&gt; 
&lt;p&gt;AgentVerse is an Apache2-licensed Python framework for deploying multiple LLM-based agents in various applications, offering task-solving and simulation frameworks for collaborative task accomplishment and behavior observation among agents&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/OpenBMB/AgentVerse"&gt;github&lt;/a&gt; | &lt;a href="https://github.com/OpenBMB"&gt;github profile&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;AgentX&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://chatagentx.com/"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-No-red" alt="Open Source" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;ü§ñ AI Agents&lt;/p&gt; 
&lt;p&gt;AgentX is an AI-powered sales assistant designed to enhance sales strategies and efficiency through advanced features like a Memory Module and Online Mode, leveraging industry best practices for smarter selling&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://chatagentx.com/"&gt;website&lt;/a&gt; | &lt;a href="https://twitter.com/agentxai"&gt;twitter&lt;/a&gt; | &lt;a href="https://buttondown.email/agentx"&gt;newsletter&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;AGiXT&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/Josh-XT/AGiXT"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/Josh-XT/AGiXT"&gt;&lt;img src="https://img.shields.io/github/stars/Josh-XT/AGiXT?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 3,052 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;‚öôÔ∏è Development Frameworks&lt;/p&gt; 
&lt;p&gt;AGiXT is an advanced AI Automation Platform designed to enhance AI instruction management and task execution across various providers, incorporating features like adaptive memory, smart instruct, and a versatile plugin system to push the boundaries of AI technology towards achieving Artificial General Intelligence (AGI)&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/Josh-XT/AGiXT"&gt;github&lt;/a&gt; | &lt;a href="https://agixt.com/"&gt;website&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;AI Agent Assist by DialPad&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://www.dialpad.com/ai-labs/ai-agent-assist/"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-No-red" alt="Open Source" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;ü§ñ AI Agents&lt;/p&gt; 
&lt;p&gt;Dialpad introduces Ai Agent Assist, offering real-time, Ai-powered answers to enhance customer service through deep integrations, reducing agent ramp time, and providing actionable insights with out-of-the-box productivity&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.dialpad.com/ai-labs/ai-agent-assist/"&gt;landing page&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;AI Agent Crew&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/aibtcdev/ai-agent-crew"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/aibtcdev/ai-agent-crew"&gt;&lt;img src="https://img.shields.io/github/stars/aibtcdev/ai-agent-crew?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 46 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;‚Çø Bitcoin&lt;/p&gt; 
&lt;p&gt;Langchain and CrewAI have launched AI agents equipped with Bitcoin wallets, facilitating automated operations within a blockchain environment&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/aibtcdev/ai-agent-crew"&gt;github&lt;/a&gt; | &lt;a href="https://github.com/aibtcdev"&gt;github profile&lt;/a&gt; | &lt;a href="https://aibtc.dev/"&gt;website&lt;/a&gt; | &lt;a href="https://discord.gg/5DJaBrf"&gt;discord&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;AI Assistant by Deco&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://deco.cx/ai-assistant"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-No-red" alt="Open Source" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;ü§ñ AI Agents&lt;/p&gt; 
&lt;p&gt;Deco provides a GPT-powered, multilingual AI Sales Assistant designed to personalize and automate the shopping experience, boost sales, and increase operational efficiency for online stores&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://deco.cx/ai-assistant"&gt;website&lt;/a&gt; | &lt;a href="https://github.com/deco-cx"&gt;github profile&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;AI Researcher&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/mshumer/ai-researcher"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/mshumer/ai-researcher"&gt;&lt;img src="https://img.shields.io/github/stars/mshumer/ai-researcher?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 932 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;ü§ñ AI Agents&lt;/p&gt; 
&lt;p&gt;The AI Researcher is an AI agent leveraging Claude 3 and SERPAPI for in-depth topic research, refining subtopic analyses into a comprehensive report, customizable and requiring API keys for functionality&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/mshumer/ai-researcher"&gt;github&lt;/a&gt; | &lt;a href="https://twitter.com/i/web/status/1776341679617745126"&gt;announcement&lt;/a&gt; | &lt;a href="https://app.hyperwriteai.com/personalassistant/tool/b40d5925-4780-4eed-9f69-a03ae931de37"&gt;website&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;AI SDK by Vercel&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/vercel/ai"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/vercel/ai"&gt;&lt;img src="https://img.shields.io/github/stars/vercel/ai?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 16,133 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;üñ•Ô∏è UI Development&lt;/p&gt; 
&lt;p&gt;The Vercel AI SDK is an open-source library for creating AI-powered conversational interfaces, supporting multiple frameworks and languages, with built-in adapters for major AI services&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://vercel.com/blog/introducing-the-vercel-ai-sdk"&gt;announcement&lt;/a&gt; | &lt;a href="https://sdk.vercel.ai/docs"&gt;website&lt;/a&gt; | &lt;a href="https://github.com/vercel/ai"&gt;github&lt;/a&gt; | &lt;a href="https://github.com/vercel/ai/tree/main/examples"&gt;github examples&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;AI Studio by Azure&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://azure.microsoft.com/en-us/products/ai-studio"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-No-red" alt="Open Source" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;üö´üíª No-Code Development Frameworks&lt;/p&gt; 
&lt;p&gt;Azure AI Studio offers a platform for developing generative AI applications and custom copilots, featuring prebuilt models, training capabilities, free Azure Cosmos DB access for 90 days, and built-in security with no extra charge during preview&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://azure.microsoft.com/en-us/products/ai-studio"&gt;website&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;ai-artifacts&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/e2b-dev/ai-artifacts"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/e2b-dev/ai-artifacts"&gt;&lt;img src="https://img.shields.io/github/stars/e2b-dev/ai-artifacts?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 5,681 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;üñ•Ô∏è UI Development&lt;/p&gt; 
&lt;p&gt;This project implements Anthropic's Artifacts UI, using E2B's Code Interpreter SDK for secure AI code execution and Claude Sonnet 3.5 for code generation&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/e2b-dev/ai-artifacts"&gt;github example&lt;/a&gt; | &lt;a href="https://www.reddit.com/r/ClaudeAI/comments/1dmy6y2/open_source_version_of_anthropics_artifacts_ui/"&gt;reddit announcement&lt;/a&gt; | &lt;a href="https://github.com/e2b-dev/ai-artifacts"&gt;github&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;Aider&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/paul-gauthier/aider"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/paul-gauthier/aider"&gt;&lt;img src="https://img.shields.io/github/stars/paul-gauthier/aider?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 36,185 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;ü§ñ AI Agents&lt;/p&gt; 
&lt;p&gt;Aider is a command-line tool for AI-assisted pair programming, allowing code editing in local git repositories with GPT-3.5/GPT-4, featuring direct file edits, automatic git commits, and support for most popular programming languages&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/paul-gauthier/aider"&gt;github&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;aifs&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/OpenInterpreter/aifs"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/OpenInterpreter/aifs"&gt;&lt;img src="https://img.shields.io/github/stars/OpenInterpreter/aifs?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 433 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt; Function Calling&lt;/p&gt; 
&lt;p&gt;AIFS offers a simple and efficient local semantic search capability for folders, leveraging Unstructured.IO for advanced data processing and ChromaDB for fast, similarity-based searching of embeddings&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/OpenInterpreter/aifs"&gt;github&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;AIOS&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/agiresearch/AIOS"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/agiresearch/AIOS"&gt;&lt;img src="https://img.shields.io/github/stars/agiresearch/AIOS?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 4,439 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;‚öôÔ∏è Development Frameworks&lt;/p&gt; 
&lt;p&gt;AIOS by AGI Research is an LLM Agent Operating System which enables an operating system 'with soul' -- an important step towards AGI&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/agiresearch/AIOS"&gt;github&lt;/a&gt; | &lt;a href="https://github.com/agiresearch"&gt;github profile&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;Anthropic&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://www.anthropic.com/"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-No-red" alt="Open Source" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;üß† Model Providers&lt;/p&gt; 
&lt;p&gt;Anthropic's new suite of Claud 3 models improves AI agents with superior reasoning, rapid responses, and diverse cognitive capabilities without compromising user privacy&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.anthropic.com/"&gt;website&lt;/a&gt; | &lt;a href="https://docs.anthropic.com/claude/"&gt;docs&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;AnyBiz&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://anybiz.io"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-No-red" alt="Open Source" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;ü§ñ AI Agents&lt;/p&gt; 
&lt;p&gt;AnyBiz offers AI-driven sales agents that enhance sales strategies through intelligent automation, continuous learning, and hyper-personalization, operating 24/7 without breaks&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://anybiz.io"&gt;website&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;Anyscale&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://www.anyscale.com/"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-No-red" alt="Open Source" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;üß† Model Providers&lt;/p&gt; 
&lt;p&gt;The Anyscale platform utilizes large language models (LLMs) for summarization, comparing the summarization quality of human, Llama 2 70b, and GPT-4, with GPT-4 demonstrating superior performance&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.anyscale.com/"&gt;website&lt;/a&gt; | &lt;a href="https://docs.anyscale.com/"&gt;docs&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;Aomni&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://www.aomni.com/"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-No-red" alt="Open Source" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;ü§ñ AI Agents&lt;/p&gt; 
&lt;p&gt;This AI agent streamlines the process of researching prospective customers, potentially saving business development representatives hundreds of hours per year&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.aomni.com/"&gt;website&lt;/a&gt; | &lt;a href="https://twitter.com/aomniapp"&gt;twitter&lt;/a&gt; | &lt;a href="https://x.com/AtomSilverman/status/1781402688078622874"&gt;demo&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;AppAgent&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/mnotgod96/AppAgent"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/mnotgod96/AppAgent"&gt;&lt;img src="https://img.shields.io/github/stars/mnotgod96/AppAgent?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 6,049 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;üì± Mobile-Friendly Frameworks&lt;/p&gt; 
&lt;p&gt;AppAgent is a mobile-friendly LLM-based multimodal agent framework developed to operate smartphone apps, enabling human-like interactions for a wide range of applications without system back-end access&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/mnotgod96/AppAgent"&gt;github&lt;/a&gt; | &lt;a href="https://github.com/mnotgod96"&gt;github profile&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;Assistants API by OpenAI&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://platform.openai.com/docs/assistants/overview"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-No-red" alt="Open Source" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;ü§ñ Assistants API&lt;/p&gt; 
&lt;p&gt;The Assistants API facilitates the development of AI agents, offering tools such as Code Interpretation and Function calling for embedding advanced, intelligent functionalities within applications&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://platform.openai.com/docs/assistants/overview"&gt;docs&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;Astra Assistants API&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/datastax/astra-assistants-api"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/datastax/astra-assistants-api"&gt;&lt;img src="https://img.shields.io/github/stars/datastax/astra-assistants-api?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 203 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;ü§ñ Assistants API&lt;/p&gt; 
&lt;p&gt;The `astra-assistants-api` provides a backend implementation of the OpenAI Assistants API with support for various features like persistent threads, files, assistants, streaming, function calling, and more, utilizing AstraDB powered by Apache Cassandra and jvector, and is compatible with existing OpenAI apps by changing a single line of code&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/datastax/astra-assistants-api"&gt;github&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;AutoAct&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/zjunlp/AutoAct"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/zjunlp/AutoAct"&gt;&lt;img src="https://img.shields.io/github/stars/zjunlp/AutoAct?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 229 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;‚öôÔ∏è Development Frameworks&lt;/p&gt; 
&lt;p&gt;AutoAct is an automatic agent learning framework that synthesizes planning trajectories without large-scale data or closed-source models, using a division-of-labor strategy for task completion, demonstrating superior or comparable performance in experiments&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/zjunlp/AutoAct"&gt;github&lt;/a&gt; | &lt;a href="https://www.zjukg.org/project/AutoAct/"&gt;website&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;AutoDev&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/unit-mesh/auto-dev"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/unit-mesh/auto-dev"&gt;&lt;img src="https://img.shields.io/github/stars/unit-mesh/auto-dev?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 4,039 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;ü§ñ AI Agents&lt;/p&gt; 
&lt;p&gt;AutoDev is an AI-powered coding assistant offering multilingual support, automatic code generation, and debugging assistance, featuring customizable prompts and specialized tools for development, testing, documentation, and the integration of custom AI agents, with a focus on experimenting and building AI agents using its UI framework&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/unit-mesh/auto-dev"&gt;github&lt;/a&gt; | &lt;a href="https://ide.unitmesh.cc"&gt;docs&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;AutoGen by Microsoft&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/microsoft/autogen"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/microsoft/autogen"&gt;&lt;img src="https://img.shields.io/github/stars/microsoft/autogen?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 48,077 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;‚öôÔ∏è Development Frameworks&lt;/p&gt; 
&lt;p&gt;AutoGen is a multi-agent conversation framework facilitating the development of next-gen LLM applications, highlighted by various accomplishments and offering enhanced LLM inferences, customizable agents, and comprehensive documentation&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/microsoft/autogen"&gt;github&lt;/a&gt; | &lt;a href="https://www.youtube.com/watch?v=DXhqhpHWRuM"&gt;video&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;AutoGen Studio by Microsoft&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/microsoft/autogen"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/microsoft/autogen"&gt;&lt;img src="https://img.shields.io/github/stars/microsoft/autogen?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 48,077 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;‚öôÔ∏è Development Frameworks&lt;/p&gt; 
&lt;p&gt;AutoGen Studio 2.0 is Microsoft's advanced AI development tool, offering a user-friendly interface, powerful Python API, and comprehensive features for creating and controlling AI agents and workflows&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/microsoft/autogen"&gt;github&lt;/a&gt; | &lt;a href="https://autogen-studio.com"&gt;website&lt;/a&gt; | &lt;a href="https://www.microsoft.com/en-us/research/project/autogen/"&gt;landing page&lt;/a&gt; | &lt;a href="https://www.microsoft.com/en-us/research/publication/autogen-enabling-next-gen-llm-applications-via-multi-agent-conversation-framework/"&gt;research paper&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;AutoGPT&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/Significant-Gravitas/AutoGPT"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/Significant-Gravitas/AutoGPT"&gt;&lt;img src="https://img.shields.io/github/stars/Significant-Gravitas/AutoGPT?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 177,350 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;ü§ñ AI Agents&lt;/p&gt; 
&lt;p&gt;AutoGPT provides accessible AI tools for building and using AI agents, offering a comprehensive framework including Forge for agent creation, agbenchmark for performance evaluation, a leaderboard for competition, a user-friendly UI, and CLI for seamless integration and management&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/Significant-Gravitas/AutoGPT"&gt;github&lt;/a&gt; | &lt;a href="https://github.com/Significant-Gravitas"&gt;github profile&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;Axflow&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/axflow/axflow"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/axflow/axflow"&gt;&lt;img src="https://img.shields.io/github/stars/axflow/axflow?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 1,122 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;‚öôÔ∏è Development Frameworks&lt;/p&gt; 
&lt;p&gt;Axflow is a TypeScript framework designed for AI development, offering a modular collection of tools for building natural language applications, and it emphasizes a code-first approach to simplify the integration of LLMs into scalable solutions&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://axflow.dev/"&gt;website&lt;/a&gt; | &lt;a href="https://github.com/axflow/axflow"&gt;github&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;Azure Speech Service&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://learn.microsoft.com/en-us/azure/ai-services/speech-service"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-No-red" alt="Open Source" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;üó£Ô∏è Voice Providers&lt;/p&gt; 
&lt;p&gt;The Azure Speech service supports a wide range of languages and locales, with over 400 neural voices available in more than 140 languages and locales, including multilingual voices that can speak multiple languages&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://learn.microsoft.com/en-us/azure/ai-services/speech-service"&gt;docs&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;BabyAGI&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/yoheinakajima/babyagi"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/yoheinakajima/babyagi"&gt;&lt;img src="https://img.shields.io/github/stars/yoheinakajima/babyagi?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 21,686 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;ü§ñ AI Agents&lt;/p&gt; 
&lt;p&gt;BabyAGI exemplifies an AI-powered task management system utilizing OpenAI and vector databases like Chroma or Weaviate, creating, prioritizing, and executing tasks based on previous outcomes and predefined objectives, with the main function involving an infinite loop where tasks are processed, enriched, and stored using OpenAI's NLP capabilities and Chroma/Weaviate, inspired by the Task-Driven Autonomous Agent concept&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/yoheinakajima/babyagi"&gt;github&lt;/a&gt; | &lt;a href="https://github.com/yoheinakajima"&gt;github profile&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;Bananalyzer by Reworkd&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/reworkd/bananalyzer"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/reworkd/bananalyzer"&gt;&lt;img src="https://img.shields.io/github/stars/reworkd/bananalyzer?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 304 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;üìä Evaluation Frameworks&lt;/p&gt; 
&lt;p&gt;Bananalyzer is a framework for evaluating AI agents on web tasks, utilizing Playwright for creating diverse datasets of website snapshots for reliable and varied web task assessments&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://reworkd.ai"&gt;website&lt;/a&gt; | &lt;a href="https://github.com/reworkd/bananalyzer"&gt;github&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;Bazed&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/bazed-ai/bazed-af"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/bazed-ai/bazed-af"&gt;&lt;img src="https://img.shields.io/github/stars/bazed-ai/bazed-af?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 73 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;‚öôÔ∏è Development Frameworks&lt;/p&gt; 
&lt;p&gt;Bazed Agent Framework, aimed at empowering developers to build autonomous agent swarms without requiring deep Python ML knowledge, is facilitating the creation of sophisticated systems through TypeScript for enhanced autonomy and reliability&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/bazed-ai/bazed-af"&gt;github&lt;/a&gt; | &lt;a href="https://bazed.ai/"&gt;website&lt;/a&gt; | &lt;a href="https://discord.gg/VmEEUrc7dg"&gt;discord&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;BDR Agent by Relevance&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://relevanceai.com/agents/bdr-agent"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-No-red" alt="Open Source" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚öôÔ∏è Development Frameworks&lt;/p&gt; 
&lt;p&gt;Relevance AI's flagship BDR Agent is designed to assist sales teams by researching and qualifying leads, engaging in personalized prospecting according to your playbook 24x7, and booking meetings to grow your business without increasing headcount&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://relevanceai.com/agents/bdr-agent"&gt;website&lt;/a&gt; | &lt;a href="https://twitter.com/RelevanceAI"&gt;twitter&lt;/a&gt; | &lt;a href="https://github.com/RelevanceAI"&gt;github profile&lt;/a&gt; | &lt;a href="https://www.linkedin.com/company/relevanceai/"&gt;linkedin&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;Beam&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://beam.ai/"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-No-red" alt="Open Source" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚öôÔ∏è Development Frameworks&lt;/p&gt; 
&lt;p&gt;Beam AI offers a platform for Agentic Process Automation, using AI agents to automate workflows, enhancing productivity for businesses of all sizes with features like pre-trained agents, seamless integrations, and industry-specific solutions&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://beam.ai/"&gt;website&lt;/a&gt; | &lt;a href="https://twitter.com/join__beam"&gt;twitter&lt;/a&gt; | &lt;a href="https://www.linkedin.com/company/beam-ai"&gt;linkedin&lt;/a&gt; | &lt;a href="https://www.youtube.com/@beam-ai"&gt;youtube&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;Bland&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://www.bland.ai/"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-No-red" alt="Open Source" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;üìû Phone Calling&lt;/p&gt; 
&lt;p&gt;Bland AI offers a platform for building and scaling AI-powered phone agents, featuring easy integration, live data context, custom voices, and dedicated infrastructure. Tech stack includes LLM: Claude Instant (Anthropic), Transcription: Whisper (OpenAI), TTS: ElevenLabs&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.bland.ai/"&gt;website&lt;/a&gt; | &lt;a href="https://twitter.com/usebland"&gt;twitter&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;Bloop&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/BloopAI/bloop"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/BloopAI/bloop"&gt;&lt;img src="https://img.shields.io/github/stars/BloopAI/bloop?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 9,480 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;ü§ñ AI Agents&lt;/p&gt; 
&lt;p&gt;Bloop is a GPT-4-based coding assistant that boosts engineer productivity by allowing natural language interactions with codebases for explanations, feature writing, error troubleshooting, and more, featuring a code-centric AI playground, fast regex search, and comprehensive code navigation tools&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/BloopAI/bloop"&gt;github&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;BrainSoup&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://www.nurgo-software.com/products/brainsoup"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-No-red" alt="Open Source" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;ü§ñ AI Agents&lt;/p&gt; 
&lt;p&gt;BrainSoup is a multi-agent and multi-LLM native client, enabling users to create a team of personalized AI agents that can learn, remember, react to events, use tools, leverage the local resources of the user's computer, and work together to solve tasks autonomously&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.nurgo-software.com/products/brainsoup"&gt;website&lt;/a&gt; | &lt;a href="https://help.nurgo-software.com/collection/148-brainsoup"&gt;docs&lt;/a&gt; | &lt;a href="https://twitter.com/Nurgo"&gt;twitter&lt;/a&gt; | &lt;a href="https://discord.gg/xt7PyCnH9S"&gt;discord&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;BrainSoup Custom Tools&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://www.nurgo-software.com/products/brainsoup"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-No-red" alt="Open Source" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt; Function Calling&lt;/p&gt; 
&lt;p&gt;BrainSoup is a multi-agent and multi-LLM native client where users can easily create custom tools for their agents, in any programming language, enabling them to interact with the user's system or any other external service&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.nurgo-software.com/products/brainsoup"&gt;website&lt;/a&gt; | &lt;a href="https://help.nurgo-software.com/collection/148-brainsoup"&gt;docs&lt;/a&gt; | &lt;a href="https://twitter.com/Nurgo"&gt;twitter&lt;/a&gt; | &lt;a href="https://discord.gg/xt7PyCnH9S"&gt;discord&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;Browserbase&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://twitter.com/browserbasehq"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-No-red" alt="Open Source" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;üåê Web Browsing Frameworks&lt;/p&gt; 
&lt;p&gt;Browserbase offers a managed headless web browser API with robust features like session recording, logging, and debugging, ensuring secure connections to isolated web browsers for efficient issue resolution&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://twitter.com/browserbasehq"&gt;twitter&lt;/a&gt; | &lt;a href="https://www.browserbase.com/"&gt;website&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;BrowserGPT&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/mayt/BrowserGPT"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/mayt/BrowserGPT"&gt;&lt;img src="https://img.shields.io/github/stars/mayt/BrowserGPT?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 419 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;ü§ñ AI Agents&lt;/p&gt; 
&lt;p&gt;BrowserGPT is a project that combines OpenAI's GPT-4 and the Playwright library to control browsers via natural language, enabling code snippet generation for browser tasks&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/mayt/BrowserGPT"&gt;github&lt;/a&gt; | &lt;a href="https://github.com/mayt"&gt;github profile&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;BrowsingAgent by Agency Swarm&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/VRSEN/agency-swarm/tree/main/agency_swarm/agents/BrowsingAgent"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;ü§ñ AI Agents&lt;/p&gt; 
&lt;p&gt;BrowsingAgent, an AI web navigation tool, has been integrated into the Agency Swarm framework to enable human-like browsing capabilities for automated AI operations&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/VRSEN/agency-swarm/tree/main/agency_swarm/agents/BrowsingAgent"&gt;code&lt;/a&gt; | &lt;a href="https://www.youtube.com/watch?v=Yidy_ePo7pE"&gt;video&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;Cadea&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://www.cadea.ai/"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-No-red" alt="Open Source" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;üõ°Ô∏è Safety Guardrails (Safeguarding)&lt;/p&gt; 
&lt;p&gt;Cadea offers a secure AI platform for businesses, providing solutions against prompt injection, data breaches, and ensuring content safety through end-to-end security, access controls, and integration with major identity providers&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.cadea.ai/"&gt;website&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;Cal.ai&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/calcom/cal.com/tree/main/apps/ai"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/calcom/cal.com/tree/main/apps/ai"&gt;&lt;img src="https://img.shields.io/github/stars/calcom/cal.com?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 37,384 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;ü§ñ AI Agents&lt;/p&gt; 
&lt;p&gt;Cal.ai is an open-source AI scheduling assistant that manages email communications for booking, rearranging, and inquiring about meetings, leveraging a LangChain Agent Executor and MailParser for efficient scheduling without API key exposure&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://cal.com/ai"&gt;website&lt;/a&gt; | &lt;a href="https://github.com/calcom/cal.com/tree/main/apps/ai"&gt;github&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;CAMEL&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/camel-ai/camel"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/camel-ai/camel"&gt;&lt;img src="https://img.shields.io/github/stars/camel-ai/camel?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 13,571 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;‚öôÔ∏è Development Frameworks&lt;/p&gt; 
&lt;p&gt;CAMEL (Communicative Agents for Mind Exploration of Large Language Model Society) is an open-source library designed for studying autonomous and communicative agents, facilitating research in understanding their behaviors, capabilities, and potential risks through scalable techniques and cooperative frameworks, including role-playing, with extensive documentation, examples, and datasets, while also supporting integration with open-source models as backends for diverse applications&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/camel-ai/camel"&gt;github&lt;/a&gt; | &lt;a href="https://github.com/camel-ai"&gt;github profile&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;Central by Zapier&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://zapier.com/blog/introducing-zapier-central-ai-bots/"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-No-red" alt="Open Source" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚öôÔ∏è Development Frameworks&lt;/p&gt; 
&lt;p&gt;Zapier Central is an AI workspace designed to automate tasks across 6,000+ apps with AI bots, offering capabilities like live data connection, AI automation, and interaction with data sources for businesses and individual productivity enhancements&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://zapier.com/blog/introducing-zapier-central-ai-bots/"&gt;announcement&lt;/a&gt; | &lt;a href="https://zapier.com/central"&gt;website&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;ChartGPT&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://chartgpt.io"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-No-red" alt="Open Source" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;ü§ñ AI Agents&lt;/p&gt; 
&lt;p&gt;ChartGPT offers AI-driven services like table summarization, charting, and code generation, featuring pay-as-you-go pricing, trusted by major companies, emphasizing data security, ease of use, and 24/7 customer support&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://chartgpt.io"&gt;website&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;ChatDev&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/OpenBMB/ChatDev"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/OpenBMB/ChatDev"&gt;&lt;img src="https://img.shields.io/github/stars/OpenBMB/ChatDev?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 27,226 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;‚öôÔ∏è Development Frameworks&lt;/p&gt; 
&lt;p&gt;ChatDev is a virtual software company utilizing intelligent agents to revolutionize the digital world through programming, offering a highly customizable framework and integrating innovative approaches like Experiential Co-Learning, Docker support, Git management, and Human-Agent Interaction&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/OpenBMB/ChatDev"&gt;github&lt;/a&gt; | &lt;a href="https://github.com/OpenBMB"&gt;github profile&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;ChatGPT&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://chatgpt.com/"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-No-red" alt="Open Source" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;ü§ñ AI Agents&lt;/p&gt; 
&lt;p&gt;ChatGPT is an AI language model designed to understand and generate human-like text, facilitating conversation and assisting with various tasks&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://chatgpt.com/"&gt;website&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;chatgpt-artifacts&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/ozgrozer/chatgpt-artifacts"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/ozgrozer/chatgpt-artifacts"&gt;&lt;img src="https://img.shields.io/github/stars/ozgrozer/chatgpt-artifacts?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 508 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;üñ•Ô∏è UI Development&lt;/p&gt; 
&lt;p&gt;Bring Claude's Artifacts feature to ChatGPT which allows you to execute Node.js commands on your ChatGPT Artifacts projects, inspired by Claude's Artifacts&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/ozgrozer/chatgpt-artifacts"&gt;github&lt;/a&gt; | &lt;a href="https://x.com/ozgrozer/status/1808677091996541251"&gt;twitter announcement&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;ChatGPT-code-preview&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/ykyritsis/ChatGPT-code-preview"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/ykyritsis/ChatGPT-code-preview"&gt;&lt;img src="https://img.shields.io/github/stars/ykyritsis/ChatGPT-code-preview?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 117 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;üñ•Ô∏è UI Development&lt;/p&gt; 
&lt;p&gt;Artifacts-like chrome extension for ChatGPT, inspired by Claude 3.5 Sonnet, which requires CSP unblocker for JS to function&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/ykyritsis/ChatGPT-code-preview"&gt;github&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;Claude 3 Artifacts by PierrunoYT&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/PierrunoYT/claude-3-artifacts"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/PierrunoYT/claude-3-artifacts"&gt;&lt;img src="https://img.shields.io/github/stars/PierrunoYT/claude-3-artifacts?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 14 stars (Updated: 2024-08-05)&lt;/p&gt; 
&lt;p&gt;üñ•Ô∏è UI Development&lt;/p&gt; 
&lt;p&gt;An open-source Flask-React chat application that interacts with Claude AI, featuring file uploads, Markdown rendering, and code highlighting, seeking contributors to expand its capabilities, inspired by Claude Artifacts&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/PierrunoYT/claude-3-artifacts"&gt;github&lt;/a&gt; | &lt;a href="https://www.reddit.com/r/ClaudeAI/comments/1dqhta5/help_me_buiild_claude_3_artifacs_opensource/"&gt;reddit announcement&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;Claude models by Anthropic&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://docs.anthropic.com/claude/docs/tool-use"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-No-red" alt="Open Source" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;üß†üîß Model Providers With Function Calling Support&lt;/p&gt; 
&lt;p&gt;Function calling or tool use is supported with the following models: `claude-3-opus-20240229`, `claude-3-sonnet-20240229`, and `claude-3-haiku-20240307`&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://docs.anthropic.com/claude/docs/tool-use"&gt;docs&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;claude-artifacts-react&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/risonsimon/claude-artifacts-react"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/risonsimon/claude-artifacts-react"&gt;&lt;img src="https://img.shields.io/github/stars/risonsimon/claude-artifacts-react?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 50 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;üñ•Ô∏è UI Development&lt;/p&gt; 
&lt;p&gt;This project provides a streamlined solution for deploying and testing React code generated by Claude Artifacts, offering one-click deployment options to Vercel or Cloudflare Pages and easy code editing through a central ArtifactCode.jsx file&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/risonsimon/claude-artifacts-react"&gt;github&lt;/a&gt; | &lt;a href="https://www.reddit.com/r/ClaudeAI/comments/1dtquuh/i_made_an_opensource_template_for_sharing_claudes/"&gt;reddit announcement&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;Claude-React-Jumpstart&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/Bklieger/Claude-React-Jumpstart"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/Bklieger/Claude-React-Jumpstart"&gt;&lt;img src="https://img.shields.io/github/stars/Bklieger/Claude-React-Jumpstart?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 115 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;üñ•Ô∏è UI Development&lt;/p&gt; 
&lt;p&gt;This project offers a tutorial for beginners to set up and run React code generated by Claude's Artifacts feature locally, providing step-by-step instructions for creating a React app with Vite, installing necessary dependencies, and integrating Claude-generated code&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/Bklieger/Claude-React-Jumpstart"&gt;github&lt;/a&gt; | &lt;a href="https://x.com/BenjaminKlieger/status/1804264035464155220"&gt;twitter announcement&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;CLIN&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/allenai/clin"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/allenai/clin"&gt;&lt;img src="https://img.shields.io/github/stars/allenai/clin?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 83 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;ü§ñ AI Agents&lt;/p&gt; 
&lt;p&gt;CLIN by Allen Institute for AI is an interactive continual learning agent that adapts rapidly to tasks, using a setup process involving Java, Python, and the ScienceWorld environment, supported by models like GPT-3.5-turbo and GPT-4&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://allenai.github.io/clin/"&gt;website&lt;/a&gt; | &lt;a href="https://github.com/allenai/clin"&gt;github&lt;/a&gt; | &lt;a href="https://arxiv.org/pdf/2310.10134.pdf"&gt;research paper&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;CodeActAgent&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/xingyaoww/code-act"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/xingyaoww/code-act"&gt;&lt;img src="https://img.shields.io/github/stars/xingyaoww/code-act?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 1,312 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;‚öôÔ∏è Development Frameworks&lt;/p&gt; 
&lt;p&gt;CodeActAgent, trained on CodeActInstruct, showcases superior performance in both in-domain and out-of-domain tasks, enabling dynamic code execution and multi-turn interactions for more effective LLM agents&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/xingyaoww/code-act"&gt;github&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;Codel&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/semanser/codel"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/semanser/codel"&gt;&lt;img src="https://img.shields.io/github/stars/semanser/codel?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 2,372 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;ü§ñ AI Agents&lt;/p&gt; 
&lt;p&gt;Autonomous AI agent, inspired by Devin, designed for complex task execution with features like a secure sandboxed Docker environment, integrated browser for real-time web information, text editor, and PostgreSQL database for history tracking, highlighting its relevance to agentic AI through its ability to autonomously navigate and perform actions across terminal, browser, and editor interfaces&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/semanser/codel"&gt;github&lt;/a&gt; | &lt;a href="https://news.ycombinator.com/item?id=39799296"&gt;announcement&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;Cody&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/sourcegraph/cody"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/sourcegraph/cody"&gt;&lt;img src="https://img.shields.io/github/stars/sourcegraph/cody?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 3,793 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;ü§ñ AI Agents&lt;/p&gt; 
&lt;p&gt;Cody, an AI coding assistant, now offers an enterprise version with enhanced security, scalability, and control for organizations, supporting various IDEs and providing AI-powered autocomplete, chat assistance, and custom command capabilities&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://sourcegraph.com/cody"&gt;website&lt;/a&gt; | &lt;a href="https://github.com/sourcegraph/cody"&gt;github&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;Cognee&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/topoteretes/cognee"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/topoteretes/cognee"&gt;&lt;img src="https://img.shields.io/github/stars/topoteretes/cognee?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 6,513 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;‚öôÔ∏è Development Frameworks&lt;/p&gt; 
&lt;p&gt;Cognee is an open-source framework aimed at simplifying data processing for large language models (LLMs) by creating knowledge graphs and data models, offering tools for information addition, knowledge creation, and similarity-based search&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/topoteretes/cognee"&gt;github&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;Command R+ by Cohere&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://txt.cohere.com/command-r-plus-microsoft-azure/"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-No-red" alt="Open Source" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;üß†üîß Model Providers With Function Calling Support&lt;/p&gt; 
&lt;p&gt;Cohere introduces Command R+, an advanced, scalable LLM optimized for enterprise needs with advanced RAG, multilingual support, and sophisticated tool-use capabilities for automating complex business workflows, available first on Microsoft Azure&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://txt.cohere.com/command-r-plus-microsoft-azure/"&gt;announcement&lt;/a&gt; | &lt;a href="https://docs.cohere.com/docs/command-r"&gt;docs&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;Composio&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://www.youtube.com/watch?v=ujxKzS0b5qg"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-No-red" alt="Open Source" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt; Function Calling&lt;/p&gt; 
&lt;p&gt;Composio enables quick integration of 90+ tools for developers and agents, offering managed authentication, easy testing, and up-to-date APIs to simplify development and enhance functionality&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=ujxKzS0b5qg"&gt;demo&lt;/a&gt; | &lt;a href="https://www.youtube.com/watch?v=ujxKzS0b5qg"&gt;demo&lt;/a&gt; | &lt;a href="https://www.composio.dev/"&gt;website&lt;/a&gt; | &lt;a href="https://docs.composio.dev/"&gt;docs&lt;/a&gt; | &lt;a href="https://blog.composio.dev/"&gt;blog&lt;/a&gt; | &lt;a href="https://github.com/SamparkAI"&gt;github profile&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;Context&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://context.ai/"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-No-red" alt="Open Source" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;üëÅÔ∏è Observability Frameworks&lt;/p&gt; 
&lt;p&gt;Context.ai is a tool for evaluating and analyzing products with LLMs, aiming to improve user experience and performance&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://context.ai/"&gt;website&lt;/a&gt; | &lt;a href="https://docs.context.ai/"&gt;docs&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;Continue&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/continuedev/continue"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/continuedev/continue"&gt;&lt;img src="https://img.shields.io/github/stars/continuedev/continue?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 27,982 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;ü§ñ AI Agents&lt;/p&gt; 
&lt;p&gt;Continue is an open-source autopilot plugin for VS Code and JetBrains, enhancing coding with LLMs through features like task and tab autocomplete, natural language edits, file generation, and customization options, available under the Apache 2.0 license&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/continuedev/continue"&gt;github&lt;/a&gt; | &lt;a href="https://continue.dev"&gt;website&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;Cosmo&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://meetcosmo.ai/"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-No-red" alt="Open Source" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;ü§ñ AI Agents&lt;/p&gt; 
&lt;p&gt;Cosmo offers an all-inclusive AI agent for merchants on WhatsApp, enabling order placements, customer interaction, automatic question answering, inventory and CRM integration, with features like instant payments, customer insights, dynamic order fulfillment, and a comprehensive merchant web app for online transaction management, aimed at simplifying shopping and boosting sales by 57%&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://meetcosmo.ai/"&gt;website&lt;/a&gt; | &lt;a href="https://x.com/AlexReibman/status/1772775416044126608"&gt;demo&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;crewAI by Jo√£o Moura&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/joaomdmoura/crewai"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/joaomdmoura/crewai"&gt;&lt;img src="https://img.shields.io/github/stars/joaomdmoura/crewai?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 35,054 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;‚öôÔ∏è Development Frameworks&lt;/p&gt; 
&lt;p&gt;crewAI is a cutting-edge AI framework designed for orchestrating role-playing, autonomous AI agents, enabling seamless collaboration and complex task handling&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/joaomdmoura/crewai"&gt;github&lt;/a&gt; | &lt;a href="https://github.com/joaomdmoura"&gt;github profile&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;crewAI Tools&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/joaomdmoura/crewai-tools"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/joaomdmoura/crewai-tools"&gt;&lt;img src="https://img.shields.io/github/stars/joaomdmoura/crewai-tools?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 1,176 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt; Function Calling&lt;/p&gt; 
&lt;p&gt;crewAI Tools is a library that provides a framework for developing sophisticated tools to enhance crewAI agents, with methods for subclassing BaseTool, utilizing the tool decorator, and guidelines for contributing to the ecosystem&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/joaomdmoura/crewai-tools"&gt;github&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;crewAI+ by Jo√£o Moura&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://www.crewai.com/crewaiplus"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-No-red" alt="Open Source" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚öôÔ∏è Development Frameworks&lt;/p&gt; 
&lt;p&gt;CrewAI+ is in beta, offering seamless API integration, business support, and early access for design partners; apply now to shape future features&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.crewai.com/crewaiplus"&gt;website&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;Cursor&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/getcursor/cursor/issues"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-No-red" alt="Open Source" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;ü§ñ AI Agents&lt;/p&gt; 
&lt;p&gt;Cursor is an AI-enhanced programming editor focusing on code discussion, editing, and debugging, with plans for advanced features like repository healing and AI-generated documentation&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/getcursor/cursor/issues"&gt;issue tracker&lt;/a&gt; | &lt;a href="https://cursor.sh/"&gt;website&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;Custom Tools by Bland AI&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://docs.bland.ai/tutorials/custom-tools#creating-your-custom-tool"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-No-red" alt="Open Source" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt; Function Calling&lt;/p&gt; 
&lt;p&gt;Custom tools by Bland AI enable an agent to interact with any web API mid-call to perform actions like sending messages, scheduling appointments, creating support tickets, or updating CRM systems&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://docs.bland.ai/tutorials/custom-tools#creating-your-custom-tool"&gt;docs&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;Data Questionnaire Agent&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/onepointconsulting/data-questionnaire-agent"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/onepointconsulting/data-questionnaire-agent"&gt;&lt;img src="https://img.shields.io/github/stars/onepointconsulting/data-questionnaire-agent?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 67 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;ü§ñ AI Agents&lt;/p&gt; 
&lt;p&gt;A chatbot designed to query users on data integration practices, offering advice based on responses, utilizing a modified Chainlit library for operation&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/onepointconsulting/data-questionnaire-agent"&gt;github&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;databerry&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/gmpetrov/databerry/"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/gmpetrov/databerry/"&gt;&lt;img src="https://img.shields.io/github/stars/gmpetrov/databerry?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 2,935 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;‚öôÔ∏è Development Frameworks&lt;/p&gt; 
&lt;p&gt;Chaindesk is a no-code platform for building custom LLM Agents, enabling users to quickly set up a semantic search system over personal data without technical knowledge&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/gmpetrov/databerry/"&gt;github&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;DB-GPT&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/eosphoros-ai/DB-GPT"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/eosphoros-ai/DB-GPT"&gt;&lt;img src="https://img.shields.io/github/stars/eosphoros-ai/DB-GPT?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 17,056 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;‚öôÔ∏è Development Frameworks&lt;/p&gt; 
&lt;p&gt;DB-GPT revolutionizes database interactions using private LLM technology, enabling streamlined AI-native data app development with multi-model management, Text2SQL optimization, and fine-tuning, facilitating enterprises and developers to create bespoke applications in the Data 3.0 era&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/eosphoros-ai/DB-GPT"&gt;github&lt;/a&gt; | &lt;a href="https://github.com/eosphoros-ai"&gt;github profile&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;Deepgram&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://x.com/AlexReibman/status/1772774552260788296"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-No-red" alt="Open Source" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;ü§ñ AI Agents | üéôÔ∏è Transcriber Providers&lt;/p&gt; 
&lt;p&gt;Conversational AI tools designed for creating voice bots and agents, featuring realistic, low-latency voice technology&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://x.com/AlexReibman/status/1772774552260788296"&gt;demo&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;DeepInfra&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://deepinfra.com"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-No-red" alt="Open Source" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;üß† Model Providers&lt;/p&gt; 
&lt;p&gt;DeepInfra is a comprehensive platform that simplifies the deployment and management of machine learning models, offering a range of open-source models for tasks like text generation and embeddings, with easy integration through REST API calls&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://deepinfra.com"&gt;website&lt;/a&gt; | &lt;a href="https://deepinfra.com/docs/"&gt;docs&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;Deepunit&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://x.com/AlexReibman/status/1772773773772779533"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-No-red" alt="Open Source" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;ü§ñ AI Agents&lt;/p&gt; 
&lt;p&gt;An AI agent designed to generate unit tests for complete code coverage across your project, requiring only your repository as input&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://x.com/AlexReibman/status/1772773773772779533"&gt;demo&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;Devid by Agency Swarm&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/VRSEN/agency-swarm/tree/main/agency_swarm/agents/Devid"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;ü§ñ AI Agents&lt;/p&gt; 
&lt;p&gt;Devid Agent, a new AI software development tool, has been integrated into the Agency Swarm framework to enhance automated AI agency operations, alternative to Cognition AI's Devin&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/VRSEN/agency-swarm/tree/main/agency_swarm/agents/Devid"&gt;code&lt;/a&gt; | &lt;a href="https://www.youtube.com/watch?v=BEpDRj9H3zE"&gt;video&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;Devika&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/stitionai/devika"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/stitionai/devika"&gt;&lt;img src="https://img.shields.io/github/stars/stitionai/devika?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 19,431 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;ü§ñ AI Agents&lt;/p&gt; 
&lt;p&gt;Devika is an open-source AI software engineer designed to understand and execute high-level coding tasks by researching, planning, and writing code, aiming to be a competitive alternative to Cognition AI's Devin&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/stitionai/devika"&gt;github&lt;/a&gt; | &lt;a href="https://github.com/stitionai/devika?tab=readme-ov-file#demos"&gt;demo&lt;/a&gt; | &lt;a href="https://discord.com/invite/8eYNbPuB"&gt;discord&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;Devin by Cognition&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://www.cognition-labs.com/introducing-devin"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-No-red" alt="Open Source" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;ü§ñ AI Agents&lt;/p&gt; 
&lt;p&gt;Devin is a fully autonomous AI software engineer, revolutionizing coding with advanced reasoning and planning capabilities&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.cognition-labs.com/introducing-devin"&gt;announcement&lt;/a&gt; | &lt;a href="https://www.cognition-labs.com/"&gt;website&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;Devon (previously Gilfoyle)&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/entropy-research/Devon"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/entropy-research/Devon"&gt;&lt;img src="https://img.shields.io/github/stars/entropy-research/Devon?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 3,443 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;ü§ñ AI Agents&lt;/p&gt; 
&lt;p&gt;Devon, not Devin, aims to perfect code correction for fill-in-the-middle, bug spotting, and completion tasks, using JSON for metadata in edits, and incorporates looping until user termination in function updates&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/entropy-research/Devon"&gt;github&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;DevOpsGPT&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/kuafuai/DevOpsGPT"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/kuafuai/DevOpsGPT"&gt;&lt;img src="https://img.shields.io/github/stars/kuafuai/DevOpsGPT?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 5,951 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;‚öôÔ∏è Development Frameworks&lt;/p&gt; 
&lt;p&gt;DevOpsGPT is an AI-driven software development automation solution that combines large language models with DevOps tools to convert natural language requirements into working software, enhancing development efficiency, shortening cycles, and reducing communication costs&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/kuafuai/DevOpsGPT"&gt;github&lt;/a&gt; | &lt;a href="https://github.com/kuafuai"&gt;github profile&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;DSPY&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/stanfordnlp/dspy"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/stanfordnlp/dspy"&gt;&lt;img src="https://img.shields.io/github/stars/stanfordnlp/dspy?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 26,786 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;üîÑ Flow Engineering (Platform Engineering)&lt;/p&gt; 
&lt;p&gt;A cutting-edge framework that compiles declarative language model calls into self-improving pipelines, enabling the systematic and efficient optimization of LM prompts and weights within complex systems&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/stanfordnlp/dspy"&gt;github&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;E2B&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/e2b-dev/E2B"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/e2b-dev/E2B"&gt;&lt;img src="https://img.shields.io/github/stars/e2b-dev/E2B?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 9,112 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;‚öôÔ∏è Development Frameworks&lt;/p&gt; 
&lt;p&gt;E2B Sandbox offers secure cloud environments tailored for AI agents and apps, facilitating long-running sessions with various tools and can be integrated with any large language model&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/e2b-dev/E2B"&gt;github&lt;/a&gt; | &lt;a href="https://github.com/e2b-dev"&gt;github profile&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;ElevenLabs&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://elevenlabs.io/"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-No-red" alt="Open Source" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;üó£Ô∏è Voice Providers&lt;/p&gt; 
&lt;p&gt;ElevenLabs is a software company that develops AI-powered, natural-sounding speech synthesis and text-to-speech software, with the mission of making content universally accessible in any language and voice&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://elevenlabs.io/"&gt;website&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;elia&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/darrenburns/elia"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/darrenburns/elia"&gt;&lt;img src="https://img.shields.io/github/stars/darrenburns/elia?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 2,238 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;üíª Terminal-Friendly&lt;/p&gt; 
&lt;p&gt;Keyboard-centric terminal user interface for interacting with large language models (LLMs) like ChatGPT, Claude, Llama 3, Phi 3, Mistral, and Gemma, offering benefits such as efficient, terminal-based interaction, easy switching between multiple models, local model support, and the ability to store conversations in a local SQLite database&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/darrenburns/elia"&gt;github&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;Enact&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/agentic-ai/enact"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/agentic-ai/enact"&gt;&lt;img src="https://img.shields.io/github/stars/agentic-ai/enact?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 113 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;‚öôÔ∏è Development Frameworks&lt;/p&gt; 
&lt;p&gt;Enact is a Python framework for building generative software that integrates machine learning models or APIs, offering features like tracking and replaying executions, asynchronous flows, and higher-order generative processes&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/agentic-ai/enact"&gt;github&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;Evolutionary Model Merge&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/SakanaAI/evolutionary-model-merge/"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/SakanaAI/evolutionary-model-merge/"&gt;&lt;img src="https://img.shields.io/github/stars/SakanaAI/evolutionary-model-merge?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 1,353 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;üîÄ Model Merges&lt;/p&gt; 
&lt;p&gt;Sakana AI's evolutionary model merge (EMM) combines 500,000 open-source models using evolutionary techniques to create new foundation models, achieving groundbreaking results without being explicitly optimized for specific benchmarks, marking a significant step toward AGI by empowering AI with combined knowledge akin to Retrieval Augmented Generation&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://twitter.com/AlphaSignalAI/status/1771201081734811797"&gt;announcement&lt;/a&gt; | &lt;a href="https://github.com/SakanaAI/evolutionary-model-merge/"&gt;github&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;Fairgo&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://x.com/AnnieLiao_2000/status/1792175460044193992"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-No-red" alt="Open Source" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;üõ†Ô∏è Build Club&lt;/p&gt; 
&lt;p&gt;Fairgo.ai is a platform built by Julian to streamline and scale hiring processes using real-time AI video interviews, tackling unconscious biases and ensuring all candidates are interviewed without human input&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://x.com/AnnieLiao_2000/status/1792175460044193992"&gt;demo&lt;/a&gt; | &lt;a href="https://fairgo.ai/"&gt;website&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;FastChat&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/lm-sys/FastChat"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/lm-sys/FastChat"&gt;&lt;img src="https://img.shields.io/github/stars/lm-sys/FastChat?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 38,916 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;üíª Local Inference&lt;/p&gt; 
&lt;p&gt;FastChat is a platform for training, serving, and evaluating large language model chatbots, featuring an open-source distributed multi-model system, API compatibility, and a dataset for LLM conversations&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/lm-sys/FastChat"&gt;github&lt;/a&gt; | &lt;a href="https://chat.lmsys.org/"&gt;demo&lt;/a&gt; | &lt;a href="https://discord.gg/HSWAKCrnFx"&gt;discord&lt;/a&gt; | &lt;a href="https://x.com/lmsysorg"&gt;twitter&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;Fetch&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://fetch.ai"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-No-red" alt="Open Source" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚öôÔ∏è Development Frameworks&lt;/p&gt; 
&lt;p&gt;Fetch by Fetch AI offers a platform for launching AI apps and services, including agent hosting, analytics, IoT gateways, and a Web3-based open network, alongside an open network for AI Agents that allows for connectivity, transactions, and the formation of dynamic marketplaces, facilitating the deployment and monetization of AI and ML models through agent technology&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://fetch.ai"&gt;website&lt;/a&gt; | &lt;a href="https://github.com/fetchai"&gt;github profile&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;Fine&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://www.fine.dev"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-No-red" alt="Open Source" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;ü§ñ AI Agents&lt;/p&gt; 
&lt;p&gt;Fine.dev offers AI-powered agents designed to automate software development tasks, seamlessly integrating into engineering teams to manage tedious tasks, technical debt, code reviews, and migrations, while customizing to project needs and learning from team feedback for improved efficiency&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.fine.dev"&gt;website&lt;/a&gt; | &lt;a href="https://discord.gg/nxW8sA5yqe"&gt;discord&lt;/a&gt; | &lt;a href="https://docs.fine.dev/"&gt;docs&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;FinGen&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/sullyo/fingen"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/sullyo/fingen"&gt;&lt;img src="https://img.shields.io/github/stars/sullyo/fingen?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 100 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;ü§ñ AI Agents&lt;/p&gt; 
&lt;p&gt;FinGen is a financial analysis agent using RSC, LangChain, and Polygon finance API, emphasizing it's not financial advice and requires API keys for use&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://twitter.com/SullyOmarr/status/1772282548841791730"&gt;announcement&lt;/a&gt; | &lt;a href="https://github.com/sullyo/fingen"&gt;github&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;Flowise&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/FlowiseAI/Flowise"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/FlowiseAI/Flowise"&gt;&lt;img src="https://img.shields.io/github/stars/FlowiseAI/Flowise?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 42,100 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;‚öôÔ∏è Development Frameworks&lt;/p&gt; 
&lt;p&gt;Flowise simplifies the creation of applications leveraging large language models (LLMs) by providing a drag-and-drop interface for customizing AI workflows, offering easy installation, Docker support, development tools, and documentation for integrating various functionalities such as authentication, streaming, and custom tools to enhance AI agents' capabilities&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/FlowiseAI/Flowise"&gt;github&lt;/a&gt; | &lt;a href="https://flowiseai.com/"&gt;website&lt;/a&gt; | &lt;a href="https://docs.flowiseai.com/"&gt;docs&lt;/a&gt; | &lt;a href="https://github.com/FlowiseAI"&gt;github profile&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;FuzzTypes&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/genomoncology/FuzzTypes"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/genomoncology/FuzzTypes"&gt;&lt;img src="https://img.shields.io/github/stars/genomoncology/FuzzTypes?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 222 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;üèóÔ∏è Structured Outputs&lt;/p&gt; 
&lt;p&gt;FuzzTypes is a Pydantic extension library providing autocorrecting annotation types, enhancing Pydantic's data conversions for AI agents by enabling powerful normalization capabilities like named entity linking to ensure structured data consists of 'smart things' instead of 'dumb strings'&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/genomoncology/FuzzTypes"&gt;github&lt;/a&gt; | &lt;a href="https://www.genomoncology.com/"&gt;website&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;Gated 402 API&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/aibtcdev/gated-402-api"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/aibtcdev/gated-402-api"&gt;&lt;img src="https://img.shields.io/github/stars/aibtcdev/gated-402-api?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 1 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;‚Çø Bitcoin&lt;/p&gt; 
&lt;p&gt;An API using a Stacks smart contract to control access, issuing a 200 status for access approval and a 402 with payment instructions for denial&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/aibtcdev/gated-402-api"&gt;github&lt;/a&gt; | &lt;a href="https://github.com/aibtcdev"&gt;github profile&lt;/a&gt; | &lt;a href="https://aibtc.dev/"&gt;website&lt;/a&gt; | &lt;a href="https://discord.gg/5DJaBrf"&gt;discord&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;GitWit&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://gitwit.dev/"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-No-red" alt="Open Source" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;ü§ñ AI Agents&lt;/p&gt; 
&lt;p&gt;GitWit is an online tool that accelerates web app development with AI, supporting React, Tailwind, and NodeJS, boasting a 3X speed increase and over 1000 projects generated&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://gitwit.dev/"&gt;website&lt;/a&gt; | &lt;a href="https://discord.gitwit.dev/"&gt;discord&lt;/a&gt; | &lt;a href="https://github.com/gitwitorg"&gt;github profile&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;Google STT&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://cloud.google.com/speech-to-text"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-No-red" alt="Open Source" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;üó£Ô∏è Voice Providers&lt;/p&gt; 
&lt;p&gt;Google Cloud Speech-to-Text is a comprehensive speech recognition service that leverages Google's years of research in automatic speech recognition and transcription technology to provide developers with a high-quality, easy-to-use speech-to-text API&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://cloud.google.com/speech-to-text"&gt;website&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;GPT Computer Assistant&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/onuratakan/gpt-computer-assistant"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/onuratakan/gpt-computer-assistant"&gt;&lt;img src="https://img.shields.io/github/stars/onuratakan/gpt-computer-assistant?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 7,625 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;üíª Operating System (OS)&lt;/p&gt; 
&lt;p&gt;GPT Computer Assistant is an unofficial app that brings ChatGPT functionality to Windows and Linux, allowing for screen reading, microphone use, system audio interaction, clipboard management, script execution, and more&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/onuratakan/gpt-computer-assistant"&gt;github&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;GPT Engineer&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/gpt-engineer-org/gpt-engineer"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/gpt-engineer-org/gpt-engineer"&gt;&lt;img src="https://img.shields.io/github/stars/gpt-engineer-org/gpt-engineer?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 54,614 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;ü§ñ AI Agents&lt;/p&gt; 
&lt;p&gt;GPT-Engineer is an AI-powered tool allowing users to specify software in natural language, automatically generating and executing code, with options for improvement suggestions, and fostering collaboration within the open-source community&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/gpt-engineer-org/gpt-engineer"&gt;github&lt;/a&gt; | &lt;a href="https://github.com/gpt-engineer-org"&gt;github profile&lt;/a&gt; | &lt;a href="https://gptengineer.app"&gt;website&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;GPT models by OpenAI&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://platform.openai.com/docs/guides/function-calling"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-No-red" alt="Open Source" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;üß†üîß Model Providers With Function Calling Support&lt;/p&gt; 
&lt;p&gt;Function calling or tool use is supported with the following models: `gpt-4-turbo`, `gpt-4-turbo-2024-04-09`, `gpt-4-turbo-preview`, `gpt-4-0125-preview`, `gpt-4-1106-preview`, `gpt-4`, `gpt-4-0613`, `gpt-3.5-turbo`, `gpt-3.5-turbo-0125`, `gpt-3.5-turbo-1106`, and `gpt-3.5-turbo-0613`&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://platform.openai.com/docs/guides/function-calling"&gt;docs&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;GPT Newspaper by Tavily&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/rotemweiss57/gpt-newspaper"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/rotemweiss57/gpt-newspaper"&gt;&lt;img src="https://img.shields.io/github/stars/rotemweiss57/gpt-newspaper?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 1,345 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;ü§ñ AI Agents&lt;/p&gt; 
&lt;p&gt;GPT Newspaper is an autonomous agent project using AI to create personalized newspapers based on user preferences, featuring six specialized sub-agents for searching, curating, writing, designing, editing, and publishing content tailored to individual interests&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/rotemweiss57/gpt-newspaper"&gt;github&lt;/a&gt; | &lt;a href="https://github.com/rotemweiss57"&gt;github profile&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;GPT Pilot&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/Pythagora-io/gpt-pilot"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/Pythagora-io/gpt-pilot"&gt;&lt;img src="https://img.shields.io/github/stars/Pythagora-io/gpt-pilot?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 33,246 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;ü§ñ AI Agents&lt;/p&gt; 
&lt;p&gt;GPT Pilot is an open-source AI developer tool that aims to provide a comprehensive development companion, capable of writing features, debugging, and interacting with users, presenting itself as an alternative to Devin, the world's first AI software engineer developed by Cognition Labs&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/Pythagora-io/gpt-pilot"&gt;github&lt;/a&gt; | &lt;a href="https://discord.gg/RzvCYRgUkx"&gt;discord&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;GPT Researcher by Tavily&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/assafelovic/gpt-researcher"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/assafelovic/gpt-researcher"&gt;&lt;img src="https://img.shields.io/github/stars/assafelovic/gpt-researcher?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 22,597 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;ü§ñ AI Agents&lt;/p&gt; 
&lt;p&gt;GPT Researcher is an AI-powered autonomous agent designed for efficient and unbiased online research, generating detailed reports by leveraging recent advancements in AI and web scraping, with a focus on speed, reliability, and cost-effectiveness&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/assafelovic/gpt-researcher"&gt;github&lt;/a&gt; | &lt;a href="https://github.com/assafelovic"&gt;github profile&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;GPTeam&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/101dotxyz/GPTeam"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/101dotxyz/GPTeam"&gt;&lt;img src="https://img.shields.io/github/stars/101dotxyz/GPTeam?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 1,696 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;‚öôÔ∏è Development Frameworks&lt;/p&gt; 
&lt;p&gt;GPTeam is a collaborative AI project utilizing GPT-4 to create multi-agent systems aimed at enhancing productivity and communication, with features including agent memory and interaction, alongside instructions for setup and integration with third-party services&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/101dotxyz/GPTeam"&gt;github&lt;/a&gt; | &lt;a href="https://github.com/101dotxyz"&gt;github profile&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;Groq&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://groq.com/"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-No-red" alt="Open Source" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;üß†üîß Model Providers With Function Calling Support | üß† Model Providers&lt;/p&gt; 
&lt;p&gt;GroqCloud API endpoints support tool use for programmatic execution of specified operations through requests with explicitly defined operations, allowing Groq API model endpoints to deliver structured JSON output that can be used to directly invoke functions from desired codebases; these following models powered by Groq all support tool use: `llama3-70b`, `llama3-8b`, `mixtral-8x7b`, `gemma-7b-it`; parallel tool calling is enabled for both Llama3 models&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://groq.com/"&gt;website&lt;/a&gt; | &lt;a href="https://console.groq.com/docs"&gt;docs&lt;/a&gt; | &lt;a href="https://console.groq.com/docs/tool-use"&gt;tool use docs&lt;/a&gt; | &lt;a href="https://twitter.com/GroqInc/status/1775634099849322632"&gt;tool use announcement&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;Guardrails&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/guardrails-ai/guardrails"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/guardrails-ai/guardrails"&gt;&lt;img src="https://img.shields.io/github/stars/guardrails-ai/guardrails?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 5,352 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;üõ°Ô∏è Safety Guardrails (Safeguarding)&lt;/p&gt; 
&lt;p&gt;Guardrails is a Python framework for building reliable AI applications, offering Input/Output Guards to detect and mitigate risks, along with structured data generation from large language models (LLMs)&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/guardrails-ai/guardrails"&gt;github&lt;/a&gt; | &lt;a href="https://twitter.com/guardrails_ai"&gt;twitter&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;Guidance&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/guidance-ai/guidance"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/guidance-ai/guidance"&gt;&lt;img src="https://img.shields.io/github/stars/guidance-ai/guidance?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 20,537 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;üõ°Ô∏è Safety Guardrails (Safeguarding)&lt;/p&gt; 
&lt;p&gt;The text describes 'guidance,' a programming paradigm that enhances control and efficiency in model generation by allowing for constraints like regex and CFGs, integrating stateful control, and offering a simplified interface for complex generation scenarios&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/guidance-ai/guidance"&gt;github&lt;/a&gt; | &lt;a href="https://guidance.readthedocs.org/"&gt;docs&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;Harpa&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://harpa.ai/"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-No-red" alt="Open Source" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;ü§ñ AI Agents&lt;/p&gt; 
&lt;p&gt;Harpa is a versatile Chrome extension that integrates AI capabilities, such as summarizing content, automating workflows, and enhancing productivity, supported by GPT-4 and Claude 2, trusted by 300,000+ professionals&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://harpa.ai/"&gt;website&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;Haystack&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/deepset-ai/haystack"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/deepset-ai/haystack"&gt;&lt;img src="https://img.shields.io/github/stars/deepset-ai/haystack?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 21,701 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;‚öôÔ∏è Development Frameworks&lt;/p&gt; 
&lt;p&gt;Haystack is an end-to-end LLM framework facilitating the construction of applications powered by LLMs, Transformer models, vector search, and more, offering flexibility, transparency, and extensibility, with features including retrieval-augmented generation, document search, question answering, and semantic search, along with a diverse user base including companies like Airbus, Apple, and Netflix&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/deepset-ai/haystack"&gt;github&lt;/a&gt; | &lt;a href="https://github.com/deepset-ai"&gt;github profile&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;Helicone&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/Helicone/helicone"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/Helicone/helicone"&gt;&lt;img src="https://img.shields.io/github/stars/Helicone/helicone?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 4,253 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;üëÅÔ∏è Observability Frameworks&lt;/p&gt; 
&lt;p&gt;Helicone is an open-source observability platform for Language Learning Models (LLMs), providing features like request logging, caching, rate limiting, cost and latency tracking, UI-based prompt iteration, and collaboration tools&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.helicone.ai/"&gt;website&lt;/a&gt; | &lt;a href="https://github.com/Helicone/helicone"&gt;github&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;Humane&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://humane.com/"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-No-red" alt="Open Source" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚åö Hardware (Wearables)&lt;/p&gt; 
&lt;p&gt;AI Pin, a wearable, multi-modal device, enhances ambient computing in the real world, offering a suite of AI digital assistants for various tasks while prioritizing user privacy for a more intuitive, human-centered experience&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://humane.com/"&gt;website&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;Hume AI&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://www.hume.ai/"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-No-red" alt="Open Source" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;ü§ñ AI Agents&lt;/p&gt; 
&lt;p&gt;Hume AI offers empathic AI solutions with emotional intelligence through APIs for interpreting emotional expressions and generating empathic responses, aimed at enhancing human well-being and enabling developers to create AI agents with improved understanding and engagement&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.hume.ai/"&gt;website&lt;/a&gt; | &lt;a href="https://discord.com/invite/WPRSugvAm6"&gt;discord&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;Imbue&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://imbue.com/"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-No-red" alt="Open Source" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;ü§ñ AI Agents&lt;/p&gt; 
&lt;p&gt;Imbue, previously known as Generally Intelligent, is developing AI systems designed for reasoning and coding, aiming to create truly personal computers that enhance human freedom, dignity, and agency, supported by a $200M funding round to advance their technology&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://imbue.com/"&gt;website&lt;/a&gt; | &lt;a href="https://twitter.com/imbue_ai/"&gt;twitter&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;Instructor&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/jxnl/instructor"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/jxnl/instructor"&gt;&lt;img src="https://img.shields.io/github/stars/jxnl/instructor?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 11,088 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;üèóÔ∏è Structured Outputs&lt;/p&gt; 
&lt;p&gt;Instructor, a Python library, facilitates working with structured outputs from large language models (LLMs), offering features like response model specification, retry management, validation, and streaming support, primarily aimed at enhancing workflows of AI agents utilizing LLMs&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/jxnl/instructor"&gt;github&lt;/a&gt; | &lt;a href="https://python.useinstructor.com/"&gt;website&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;Instructor Cloud&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/instructor-ai/cloud"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/instructor-ai/cloud"&gt;&lt;img src="https://img.shields.io/github/stars/instructor-ai/cloud?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 36 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;üèóÔ∏è Structured Outputs&lt;/p&gt; 
&lt;p&gt;Instructor Cloud offers a platform for extracting models from text rapidly, with real-time streaming and the potential to utilize GPT-4*, encouraging engagement through contributions and adaptation of its FastAPI-based service&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/instructor-ai/cloud"&gt;github&lt;/a&gt; | &lt;a href="https://twitter.com/jxnlco/status/1774822440922763707"&gt;announcement&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;IvyCheck&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/ivycheck/ivycheck-python-sdk"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/ivycheck/ivycheck-python-sdk"&gt;&lt;img src="https://img.shields.io/github/stars/ivycheck/ivycheck-python-sdk?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 2 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;üõ°Ô∏è Safety Guardrails (Safeguarding)&lt;/p&gt; 
&lt;p&gt;IvyCheck offers an API for real-time AI application safety checks, preventing prompt injection attacks, PII data leakage, and hallucinations in agentic AI development&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/ivycheck/ivycheck-python-sdk"&gt;github&lt;/a&gt; | &lt;a href="https://www.ycombinator.com/launches/KkA-ivycheck-guard-against-ai-risks-with-real-time-checks"&gt;announcement&lt;/a&gt; | &lt;a href="https://ivycheck.com"&gt;website&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;Jaiqu&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/AgentOps-AI/Jaiqu"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/AgentOps-AI/Jaiqu"&gt;&lt;img src="https://img.shields.io/github/stars/AgentOps-AI/Jaiqu?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 333 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;üèóÔ∏è Structured Outputs&lt;/p&gt; 
&lt;p&gt;Jaiqu is an AI-powered tool for automatically transforming any JSON schema using GPT-4, featuring schema validation, fuzzy term matching, and repeatable jq query generation&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/AgentOps-AI/Jaiqu"&gt;github&lt;/a&gt; | &lt;a href="https://x.com/AlexReibman/status/1774314258379190770"&gt;demo&lt;/a&gt; | &lt;a href="https://jaiqu-agent.streamlit.app/"&gt;website&lt;/a&gt; | &lt;a href="https://twitter.com/agentopsai/"&gt;twitter&lt;/a&gt; | &lt;a href="https://discord.gg/JHPt4C7r"&gt;discord&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;Jan&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/janhq/jan"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/janhq/jan"&gt;&lt;img src="https://img.shields.io/github/stars/janhq/jan?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 35,212 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;üíª Local Inference&lt;/p&gt; 
&lt;p&gt;Jan is an open-source, development-stage ChatGPT alternative that operates fully offline on diverse hardware platforms, supporting universal architectures from PCs to multi-GPU clusters&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/janhq/jan"&gt;github&lt;/a&gt; | &lt;a href="https://github.com/janhq"&gt;github profile&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;JARVIS by Microsoft&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/microsoft/JARVIS"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/microsoft/JARVIS"&gt;&lt;img src="https://img.shields.io/github/stars/microsoft/JARVIS?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 24,248 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;‚öôÔ∏è Development Frameworks&lt;/p&gt; 
&lt;p&gt;JARVIS aims to advance artificial general intelligence (AGI) through cutting-edge research and facilitate broader community engagement&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/microsoft/JARVIS"&gt;github&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;Jsonify&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://jsonify.com/"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-No-red" alt="Open Source" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;üèóÔ∏è Structured Outputs&lt;/p&gt; 
&lt;p&gt;Jsonify provides a no-code platform for AI data agents that convert webpages and documents into structured JSON, enhancing efficiency and customer satisfaction, with use cases including scraping webpages, extracting document data, and building structured datasets&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://jsonify.com/"&gt;website&lt;/a&gt; | &lt;a href="https://twitter.com/jsonifyco"&gt;twitter&lt;/a&gt; | &lt;a href="https://www.linkedin.com/company/jsonify/"&gt;linkedin&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;Kapa&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://www.kapa.ai/"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-No-red" alt="Open Source" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;üö´üíª No-Code Development Frameworks&lt;/p&gt; 
&lt;p&gt;Kapa.ai is an AI-powered chatbot service for developers that automates answering technical questions by learning from technical resources, thus helping identify gaps in documentation, with features including data security, PII anonymization, and continuous updating from a range of knowledge sources&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.kapa.ai/"&gt;website&lt;/a&gt; | &lt;a href="https://docs.kapa.ai/"&gt;docs&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;LangChain&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/langchain-ai/langchain"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/langchain-ai/langchain"&gt;&lt;img src="https://img.shields.io/github/stars/langchain-ai/langchain?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 112,549 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;‚öôÔ∏è Development Frameworks&lt;/p&gt; 
&lt;p&gt;LangChain is a framework enabling context-aware reasoning applications with integrated libraries, templates, and developer tools&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/langchain-ai/langchain"&gt;github&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;LangChain JS&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/langchain-ai/langchainjs"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/langchain-ai/langchainjs"&gt;&lt;img src="https://img.shields.io/github/stars/langchain-ai/langchainjs?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 15,289 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;‚öôÔ∏è Development Frameworks&lt;/p&gt; 
&lt;p&gt;LangChain JS is a framework for developing applications powered by language models, enabling context-aware and reasoning-based applications through composable tools and off-the-shelf chains, with seamless integration with the LangChain Python package&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/langchain-ai/langchainjs"&gt;github&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;LangChain JS Tools&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/langchain-ai/langchainjs"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/langchain-ai/langchainjs"&gt;&lt;img src="https://img.shields.io/github/stars/langchain-ai/langchainjs?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 15,289 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt; Function Calling&lt;/p&gt; 
&lt;p&gt;Langchain features VectorDBQAChain, which integrates LLMs and vector databases into agent tools for enhanced question-answering capabilities by leveraging data ingested into vector stores&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/langchain-ai/langchainjs"&gt;github&lt;/a&gt; | &lt;a href="https://js.langchain.com/v0.2/docs/integrations/tools/"&gt;docs&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;LangChain Tools&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/langchain-ai/langchain/"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/langchain-ai/langchain/"&gt;&lt;img src="https://img.shields.io/github/stars/langchain-ai/langchain?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 112,549 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt; Function Calling&lt;/p&gt; 
&lt;p&gt;Langchain integrates various providers like Anthropic, AWS, and OpenAI, and offers tools for components such as LLMs, chat models, and data analysis, supporting functionalities from Alpha Vantage to YouTube&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/langchain-ai/langchain/"&gt;github&lt;/a&gt; | &lt;a href="https://python.langchain.com/docs/integrations/tools"&gt;docs&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;LangChainBitcoin&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/lightninglabs/LangChainBitcoin"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/lightninglabs/LangChainBitcoin"&gt;&lt;img src="https://img.shields.io/github/stars/lightninglabs/LangChainBitcoin?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 141 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;‚Çø Bitcoin&lt;/p&gt; 
&lt;p&gt;LangChainBitcoin is a toolset for enabling LangChain agents to interact with Bitcoin, the Lightning Network, and APIs requiring L402-based authentication, including features for Bitcoin transactions and API traversal with automated Lightning payments&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://lightning.engineering/posts/2023-07-05-l402-langchain/"&gt;announcement&lt;/a&gt; | &lt;a href="https://github.com/lightninglabs/LangChainBitcoin"&gt;github&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;LangFuse&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/langfuse/langfuse"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/langfuse/langfuse"&gt;&lt;img src="https://img.shields.io/github/stars/langfuse/langfuse?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 14,432 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;üìä Evaluation Frameworks&lt;/p&gt; 
&lt;p&gt;Langfuse, an open-source LLM engineering platform, offers debugging, prompt management, metrics for LLM apps improvement, and won the #1 Golden Kitty in the AI Infra Category from Product Hunt&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/langfuse/langfuse"&gt;github&lt;/a&gt; | &lt;a href="https://langfuse.com/"&gt;website&lt;/a&gt; | &lt;a href="https://x.com/langfuse"&gt;twitter&lt;/a&gt; | &lt;a href="https://langfuse.com/discord"&gt;discord&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;LangGraph&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/langchain-ai/langgraph"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/langchain-ai/langgraph"&gt;&lt;img src="https://img.shields.io/github/stars/langchain-ai/langgraph?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 16,529 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;‚öôÔ∏è Development Frameworks&lt;/p&gt; 
&lt;p&gt;LangGraph is a Python library facilitating the construction of stateful, multi-actor applications with LLMs, enabling cyclic coordination across multiple computation steps, particularly suited for agent-like behaviors, while also providing streaming support, and various guides and examples for implementation and usage&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/langchain-ai/langgraph"&gt;github&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;LangGraph.js&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/langchain-ai/langgraphjs"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/langchain-ai/langgraphjs"&gt;&lt;img src="https://img.shields.io/github/stars/langchain-ai/langgraphjs?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 1,842 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;‚öôÔ∏è Development Frameworks&lt;/p&gt; 
&lt;p&gt;LangGraph.js is a TypeScript and JavaScript library enabling the development of stateful, multi-actor applications with LLMs, featuring capabilities to construct cyclic coordination across multiple computation steps for complex agent-like behaviors, with support for conditional edges and cycles, not limited to DAGs, and extensive documentation with examples on implementation&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/langchain-ai/langgraphjs"&gt;github&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;LangServe&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/langchain-ai/langserve"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/langchain-ai/langserve"&gt;&lt;img src="https://img.shields.io/github/stars/langchain-ai/langserve?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 2,137 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;‚öôÔ∏è Development Frameworks&lt;/p&gt; 
&lt;p&gt;LangServe facilitates the deployment of LangChain runnables and chains as a REST API, providing features like automatic schema inference, efficient endpoints, and a playground page, with plans for a hosted version for one-click deployments&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/langchain-ai/langserve"&gt;github&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;LangSmith by LangChain&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/langchain-ai/langsmith-sdk"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/langchain-ai/langsmith-sdk"&gt;&lt;img src="https://img.shields.io/github/stars/langchain-ai/langsmith-sdk?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 605 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;üëÅÔ∏è Observability Frameworks&lt;/p&gt; 
&lt;p&gt;LangSmith provides tools for debugging, testing, evaluating, and monitoring LLM applications, integrating seamlessly with LangChain for comprehensive AI agent observability&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/langchain-ai/langsmith-sdk"&gt;github&lt;/a&gt; | &lt;a href="https://docs.smith.langchain.com"&gt;docs&lt;/a&gt; | &lt;a href="https://smith.langchain.com"&gt;website&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;Libraria&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://libraria.ai/"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-No-red" alt="Open Source" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;üö´üíª No-Code Development Frameworks&lt;/p&gt; 
&lt;p&gt;Libraria AI offers a platform to create, manage, and embed custom AI chatbots with natural language processing and features like call-to-actions, link carousels, and analytics for enhanced customer interactions and satisfaction, alongside free and paid plans tailored for different business needs&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://libraria.ai/"&gt;website&lt;/a&gt; | &lt;a href="https://x.com/librariaai"&gt;twitter&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;LiteLLM&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/BerriAI/litellm"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/BerriAI/litellm"&gt;&lt;img src="https://img.shields.io/github/stars/BerriAI/litellm?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 26,572 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;ü§ñ Assistants API&lt;/p&gt; 
&lt;p&gt;LiteLLM has added support for the OpenAI Assistants API, enabling seamless integration of stateful operations and automatic RAG pipelines into existing chatbots&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/BerriAI/litellm"&gt;github&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;LiveKit Agents&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/livekit/agents"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚ö° Real-Time&lt;/p&gt; 
&lt;p&gt;An open-source framework for building real-time, programmable participants that run on servers, enabling easy integration with LiveKit WebRTC sessions for processing or generating audio, video, and data streams&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/livekit/agents"&gt;GitHub&lt;/a&gt; | &lt;a href="https://docs.livekit.io/agents/"&gt;docs&lt;/a&gt; | &lt;a href="https://kitt.livekit.io"&gt;demo&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;LiveRecall&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/VedankPurohit/LiveRecall"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;üë§ Personal Assistants&lt;/p&gt; 
&lt;p&gt;LiveRecall, an open-source alternative to Microsoft's Recall, utilizes semantic search and encryption to capture and retrieve screen snapshots, enabling AI agents to assist creators in researching and augmenting tasks like journaling or blog post creation based on indexed personal activities&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/VedankPurohit/LiveRecall"&gt;GitHub&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;LlamaCloud by LlamaIndex&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://www.llamaindex.ai/enterprise"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-No-red" alt="Open Source" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;üö´üíª No-Code Development Frameworks&lt;/p&gt; 
&lt;p&gt;LlamaCloud by LlamaIndex streamlines AI development by enabling developers to minimize infrastructure management and parameter tuning, focusing instead on creating AI products, with features for proprietary parsing of complex documents, easy data ingestion and storage, and advanced data retrieval&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.llamaindex.ai/enterprise"&gt;website&lt;/a&gt; | &lt;a href="https://github.com/run-llama"&gt;github profile&lt;/a&gt; | &lt;a href="https://discord.com/invite/eN6D2HQ4aX"&gt;discord&lt;/a&gt; | &lt;a href="https://www.linkedin.com/company/91154103/"&gt;linkedin&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;LlamaGym&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/KhoomeiK/LlamaGym"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/KhoomeiK/LlamaGym"&gt;&lt;img src="https://img.shields.io/github/stars/KhoomeiK/LlamaGym?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 1,208 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt; Reinforcement Learning&lt;/p&gt; 
&lt;p&gt;LlamaGym simplifies the fine-tuning of LLM agents with online reinforcement learning, providing a framework to iterate and experiment across Gym environments for efficient agent prompting and hyperparameter tuning&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/KhoomeiK/LlamaGym"&gt;github&lt;/a&gt; | &lt;a href="https://github.com/KhoomeiK"&gt;github profile&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;LlamaIndex Tools&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/run-llama/llama_index"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/run-llama/llama_index"&gt;&lt;img src="https://img.shields.io/github/stars/run-llama/llama_index?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 43,398 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt; Function Calling&lt;/p&gt; 
&lt;p&gt;LlamaIndex offers a variety of tools for building data agents, with top downloads including IonicShoppingToolSpec, OpenAPIToolSpec, WikipediaToolSpec, GmailToolSpec, and GoogleCalendarToolSpec, enabling seamless integration with user-defined functions, query engines, and third-party services&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/run-llama/llama_index"&gt;github&lt;/a&gt; | &lt;a href="https://llamahub.ai/?tab=tools"&gt;website&lt;/a&gt; | &lt;a href="https://docs.llamaindex.ai/en/latest/module_guides/deploying/agents/tools/"&gt;docs&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;LM Studio&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://lmstudio.ai/"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-No-red" alt="Open Source" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;üíª Local Inference&lt;/p&gt; 
&lt;p&gt;LM Studio offers a platform for running various local LLMs like LLaMa, Falcon, MPT, and others offline, featuring a Chat UI, OpenAI-compatible server, and model downloads from Hugging Face, with support for Mac, Windows, and Linux, emphasizing privacy and no data collection, free for personal use&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://lmstudio.ai/"&gt;website&lt;/a&gt; | &lt;a href="https://github.com/lmstudio-ai"&gt;github profile&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;LMNT&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://www.lmnt.com"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-No-red" alt="Open Source" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;üó£Ô∏è Voice Providers&lt;/p&gt; 
&lt;p&gt;LMNT is an AI-powered text-to-speech platform that offers ultrafast, lifelike, and reliable voice cloning and generation services for conversational apps, agents, and content creation at scale&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.lmnt.com"&gt;website&lt;/a&gt; | &lt;a href="https://docs.lmnt.com/"&gt;docs&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;LMQL&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/eth-sri/lmql"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/eth-sri/lmql"&gt;&lt;img src="https://img.shields.io/github/stars/eth-sri/lmql?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 4,017 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;üó£Ô∏è LLM-Friendly Languages&lt;/p&gt; 
&lt;p&gt;LMQL is a Python-based programming language for large language models, allowing seamless integration of LLMs into code with advanced features like conditional logic, constraints, and multi-model support&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/eth-sri/lmql"&gt;github&lt;/a&gt; | &lt;a href="https://lmql.ai/"&gt;website&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;Lobe Chat&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/lobehub/lobe-chat"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/lobehub/lobe-chat"&gt;&lt;img src="https://img.shields.io/github/stars/lobehub/lobe-chat?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 63,923 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;‚öôÔ∏è Development Frameworks&lt;/p&gt; 
&lt;p&gt;Lobe Chat is an open-source UI framework for building ChatGPT/LLM-based chat applications, featuring modern design, speech synthesis, multi-modal support, extensible plugins, and free one-click deployment for various AI agents&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/lobehub/lobe-chat"&gt;github&lt;/a&gt; | &lt;a href="https://chat-preview.lobehub.com/"&gt;website&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;LocalGPT&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/PromtEngineer/localGPT"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/PromtEngineer/localGPT"&gt;&lt;img src="https://img.shields.io/github/stars/PromtEngineer/localGPT?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 21,748 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;üíª Local Inference&lt;/p&gt; 
&lt;p&gt;LocalGPT is an open-source project for secure, private interactions with documents locally, featuring comprehensive model support, embeddings, API for RAG applications, and GUI options, with a focus on privacy and local data processing&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/PromtEngineer/localGPT"&gt;github&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;LoopGPT&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/farizrahman4u/loopgpt"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/farizrahman4u/loopgpt"&gt;&lt;img src="https://img.shields.io/github/stars/farizrahman4u/loopgpt?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 1,458 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;‚öôÔ∏è Development Frameworks&lt;/p&gt; 
&lt;p&gt;LoopGPT is a modular auto-GPT framework with features such as a 'Plug N Play' API, GPT 3.5 compatibility, minimal prompt overhead, human-in-the-loop capability, and full state serialization, facilitating easy installation and usage through Python code, CLI, or Docker, with the ability to add custom tools and course correction, along with saving and loading agent state, requiring Python 3.8+ and an OpenAI API Key, and optional setup for Google search support&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/farizrahman4u/loopgpt"&gt;github&lt;/a&gt; | &lt;a href="https://github.com/farizrahman4u"&gt;github profile&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;Lumos&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/allenai/lumos"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/allenai/lumos"&gt;&lt;img src="https://img.shields.io/github/stars/allenai/lumos?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 467 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;‚öôÔ∏è Development Frameworks&lt;/p&gt; 
&lt;p&gt;Lumos introduces a modular, open-source language agent framework with unified data formats that competes with or outperforms GPT-series and larger agents across various complex interactive tasks&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/allenai/lumos"&gt;github&lt;/a&gt; | &lt;a href="https://allenai.github.io/lumos/"&gt;website&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;Lyzr&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://www.lyzr.ai/"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-No-red" alt="Open Source" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚öôÔ∏è Development Frameworks&lt;/p&gt; 
&lt;p&gt;Lyzr provides an enterprise-grade AI agent framework for easy configuration, deployment, and management of AI agents, supporting integration with multiple LLMs and databases, and offers ISO-compliant safety, white-glove onboarding, and 24/7 enterprise support&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.lyzr.ai/"&gt;website&lt;/a&gt; | &lt;a href="https://www.lyzr.ai/blog/"&gt;blog&lt;/a&gt; | &lt;a href="https://twitter.com/lyzrai"&gt;twitter&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;Marvin&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/PrefectHQ/marvin/"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/PrefectHQ/marvin/"&gt;&lt;img src="https://img.shields.io/github/stars/PrefectHQ/marvin?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 5,830 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;üèóÔ∏è Structured Outputs&lt;/p&gt; 
&lt;p&gt;Marvin is an open-source AI toolkit designed for developers focused on enhancing AI agent capabilities, offering tools for natural language interfaces, image and audio generation, and entity extraction, scalable and easy to integrate into existing projects&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/PrefectHQ/marvin/"&gt;github&lt;/a&gt; | &lt;a href="https://askmarvin.ai/"&gt;website&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;mem0&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/mem0ai/mem0"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/mem0ai/mem0"&gt;&lt;img src="https://img.shields.io/github/stars/mem0ai/mem0?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 37,574 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;üß† Long-Term Memory&lt;/p&gt; 
&lt;p&gt;Mem0 is an intelligent memory layer for Large Language Models that enhances personalized AI experiences by retaining and utilizing contextual information across various applications.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/mem0ai/mem0"&gt;github&lt;/a&gt; | &lt;a href="https://app.mem0.ai/"&gt;website&lt;/a&gt; | &lt;a href="https://docs.mem0.ai/"&gt;docs&lt;/a&gt; | &lt;a href="https://mem0.ai/discord"&gt;discord&lt;/a&gt; | &lt;a href="https://x.com/mem0ai"&gt;twitter&lt;/a&gt; | &lt;a href="https://github.com/mem0ai"&gt;github profile&lt;/a&gt; | &lt;a href="https://www.linkedin.com/company/mem0/"&gt;linkedin&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;MemGPT&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/cpacker/MemGPT/"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/cpacker/MemGPT/"&gt;&lt;img src="https://img.shields.io/github/stars/cpacker/MemGPT?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 17,568 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;üß† Long-Term Memory&lt;/p&gt; 
&lt;p&gt;MemGPT introduces a customizable AI chatbot framework with self-editing memory and access to unlimited data, promoting perpetual, context-rich conversations&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://memgpt.ai/"&gt;website&lt;/a&gt; | &lt;a href="https://github.com/cpacker/MemGPT/"&gt;github&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;Mendable&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://www.mendable.ai/"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-No-red" alt="Open Source" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;üö´üíª No-Code Development Frameworks&lt;/p&gt; 
&lt;p&gt;Mendable offers an AI chatbot solution that enables companies to build and deploy technical assistants trained on their specific documentation and resources, aiming to improve customer and employee support, with features including enterprise-grade security, continuous model training, and integration with a wide range of data sources and APIs&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.mendable.ai/"&gt;website&lt;/a&gt; | &lt;a href="https://docs.mendable.ai/"&gt;docs&lt;/a&gt; | &lt;a href="https://twitter.com/mendableai"&gt;twitter&lt;/a&gt; | &lt;a href="https://github.com/sideguide"&gt;github profile&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;MergeKit&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/arcee-ai/mergekit"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/arcee-ai/mergekit"&gt;&lt;img src="https://img.shields.io/github/stars/arcee-ai/mergekit?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 6,120 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;üîÄ Model Merges&lt;/p&gt; 
&lt;p&gt;Arcee AI's MergeKit offers tools for merging pre-trained large language models, enabling the creation of more versatile AI agents by combining knowledge from different sources, akin to Retrieval Augmented Generation (RAG)&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/arcee-ai/mergekit"&gt;github&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;MetaGPT&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/geekan/MetaGPT"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/geekan/MetaGPT"&gt;&lt;img src="https://img.shields.io/github/stars/geekan/MetaGPT?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 57,568 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;‚öôÔ∏è Development Frameworks&lt;/p&gt; 
&lt;p&gt;MetaGPT is a multi-agent framework enabling GPT to collaborate within a software company, facilitating complex tasks by assigning different roles to GPTs&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/geekan/MetaGPT"&gt;github&lt;/a&gt; | &lt;a href="https://github.com/geekan"&gt;github profile&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;Miranda&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://x.com/AnnieLiao_2000/status/1792175658178855112"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-No-red" alt="Open Source" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;üõ†Ô∏è Build Club&lt;/p&gt; 
&lt;p&gt;Miranda is a platform that simplifies dashboard creation, aiming to be the 'Canva for dashboards'&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://x.com/AnnieLiao_2000/status/1792175658178855112"&gt;demo&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;MultiOn&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://www.multion.ai/"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-No-red" alt="Open Source" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;ü§ñ AI Agents&lt;/p&gt; 
&lt;p&gt;MultiOn utilizes AI to automate actions within web browsers, such as form filling, data retrieval, and executing web searches, mimicking human interaction but without manual input, facilitated through a Chrome extension and API for developers&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.multion.ai/"&gt;website&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;NavAIGuide&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/francedot/NavAIGuide-TS"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/francedot/NavAIGuide-TS"&gt;&lt;img src="https://img.shields.io/github/stars/francedot/NavAIGuide-TS?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 114 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;üì± Mobile-Friendly Frameworks&lt;/p&gt; 
&lt;p&gt;NavAIGuide is an extensible, mobile-friendly, multi-modal agentic framework designed to integrate with mobile and desktop apps, featuring visual task detection, advanced code selectors, action-oriented execution, and resilient error handling&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/francedot/NavAIGuide-TS"&gt;github&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;Neets&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://neets.ai/"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-No-red" alt="Open Source" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;üó£Ô∏è Voice Providers&lt;/p&gt; 
&lt;p&gt;Neets.ai is a text-to-speech (TTS) API that offers a wide range of voices and languages, allowing users to easily integrate TTS capabilities into their applications&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://neets.ai/"&gt;website&lt;/a&gt; | &lt;a href="https://docs.neets.ai/"&gt;docs&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;NeMo Guardrails&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/NVIDIA/NeMo-Guardrails"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/NVIDIA/NeMo-Guardrails"&gt;&lt;img src="https://img.shields.io/github/stars/NVIDIA/NeMo-Guardrails?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 4,937 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;üõ°Ô∏è Safety Guardrails (Safeguarding)&lt;/p&gt; 
&lt;p&gt;NeMo Guardrails is an open-source toolkit facilitating the integration of programmable guardrails, essential for steering and safeguarding AI agents' conversational outputs, into large language model-based applications&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/NVIDIA/NeMo-Guardrails"&gt;github&lt;/a&gt; | &lt;a href="https://arxiv.org/abs/2310.10501"&gt;research paper&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;NexusGPT&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://gpt.nexus/"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-No-red" alt="Open Source" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;ü§ñ AI Agents&lt;/p&gt; 
&lt;p&gt;NexusGPT offers a no-code platform to build and integrate AI agents that automate workflows, featuring a marketplace of tools and integrations, with easy customization and deployment across various applications&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://gpt.nexus/"&gt;website&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;NPI&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/npi-ai/npi"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/npi-ai/npi"&gt;&lt;img src="https://img.shields.io/github/stars/npi-ai/npi?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 222 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt; Function Calling&lt;/p&gt; 
&lt;p&gt;NPi is an open-source platform providing tool-use APIs for AI agents, with installation and setup instructions available&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/npi-ai/npi"&gt;github&lt;/a&gt; | &lt;a href="https://www.npi.ai/"&gt;website&lt;/a&gt; | &lt;a href="https://www.npi.ai/docs"&gt;docs&lt;/a&gt; | &lt;a href="https://www.npi.ai/blog"&gt;blog&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;Ollama&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/ollama/ollama"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/ollama/ollama"&gt;&lt;img src="https://img.shields.io/github/stars/ollama/ollama?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 147,994 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;üíª Local Inference&lt;/p&gt; 
&lt;p&gt;Ollama is a tool for running large language models locally, offering easy setup for macOS, Windows, Linux, and Docker, along with a library of models and quickstart guides for customization and integration&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/ollama/ollama"&gt;github&lt;/a&gt; | &lt;a href="https://github.com/ollama"&gt;github profile&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;Open Assistant API&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/MLT-OSS/open-assistant-api"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/MLT-OSS/open-assistant-api"&gt;&lt;img src="https://img.shields.io/github/stars/MLT-OSS/open-assistant-api?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 347 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;ü§ñ Assistants API&lt;/p&gt; 
&lt;p&gt;The Open Assistant API is a self-hosted, open-source framework that enables the creation of customized AI assistants, supporting integration with OpenAI's LLM and LangChain SDK, and is compatible with OpenAI's Assistants API, allowing for seamless orchestration and extension capabilities&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/MLT-OSS/open-assistant-api"&gt;github&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;Open Interpreter&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/OpenInterpreter/open-interpreter"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/OpenInterpreter/open-interpreter"&gt;&lt;img src="https://img.shields.io/github/stars/OpenInterpreter/open-interpreter?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 60,095 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;üíª Operating System (OS)&lt;/p&gt; 
&lt;p&gt;Open Interpreter is a coding agent enabling language models to execute code locally, facilitating natural-language interaction with your computer's capabilities, overcoming limitations of hosted solutions like internet access and package restrictions. It features interactive and programmatic chats, system message customization, and can control your computer's keyboard and mouse, allowing for enhanced control and flexibility in development environments&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/OpenInterpreter/open-interpreter"&gt;github&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;OpenAGI&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/agiresearch/OpenAGI"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/agiresearch/OpenAGI"&gt;&lt;img src="https://img.shields.io/github/stars/agiresearch/OpenAGI?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 2,175 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;‚öôÔ∏è Development Frameworks&lt;/p&gt; 
&lt;p&gt;OpenAGI by AGI Research is an open-source platform integrating Large Language Models (LLMs) with domain-specific expert models for complex task-solving, fostering a paradigm where LLMs operate various external models, accompanied by a Reinforcement Learning from Task Feedback (RLTF) mechanism for self-improvement&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/agiresearch/OpenAGI"&gt;github&lt;/a&gt; | &lt;a href="https://github.com/agiresearch"&gt;github profile&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;OpenAI&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://openai.com"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-No-red" alt="Open Source" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;üß† Model Providers&lt;/p&gt; 
&lt;p&gt;OpenAI's GPT models, including GPT-3 and GPT-4, are large language models that can be used to summarize text in a concise and accurate manner, though the quality of the summaries may vary depending on the complexity and length of the input text&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://openai.com"&gt;website&lt;/a&gt; | &lt;a href="https://platform.openai.com/docs/overview"&gt;docs&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;OpenAI TTS&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://platform.openai.com/docs/guides/text-to-speech"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-No-red" alt="Open Source" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;üó£Ô∏è Voice Providers&lt;/p&gt; 
&lt;p&gt;The OpenAI Text-to-Speech (TTS) API allows users to convert text into high-quality, natural-sounding spoken audio in multiple languages, with various voice options and customization capabilities&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://platform.openai.com/docs/guides/text-to-speech"&gt;docs&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;OpenDevin&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/OpenDevin/OpenDevin"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/OpenDevin/OpenDevin"&gt;&lt;img src="https://img.shields.io/github/stars/OpenDevin/OpenDevin?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 61,429 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;ü§ñ AI Agents&lt;/p&gt; 
&lt;p&gt;OpenDevin is an open-source initiative aimed at replicating and enhancing the autonomous AI software engineer Devin, focusing on collaboration and complex task execution in software development, emphasizing its relevance to advancing agentic AI technologies&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/OpenDevin/OpenDevin"&gt;github&lt;/a&gt; | &lt;a href="https://github.com/OpenDevin"&gt;github profile&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;OpenGPTs&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/langchain-ai/opengpts"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/langchain-ai/opengpts"&gt;&lt;img src="https://img.shields.io/github/stars/langchain-ai/opengpts?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 6,673 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;‚öôÔ∏è Development Frameworks&lt;/p&gt; 
&lt;p&gt;OpenGPTs is an open-source project providing customizable GPT-based experiences, offering control over language models, prompts, tools, vector databases, retrieval algorithms, and chat history databases, featuring three cognitive architectures: Assistant, RAG, and Chatbot, with support for various language models and deployment options including Docker, Cloud Run, and Kubernetes&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/langchain-ai/opengpts"&gt;github&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;OpenPipe&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://x.com/AlexReibman/status/1772782206957895797"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-No-red" alt="Open Source" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;ü§ñ AI Agents&lt;/p&gt; 
&lt;p&gt;Optimize AI agents with language models that are faster and 14x more cost-effective than OpenAI's solutions&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://x.com/AlexReibman/status/1772782206957895797"&gt;demo&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;OpenRecall&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/openrecall/openrecall"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;üë§ Personal Assistants&lt;/p&gt; 
&lt;p&gt;OpenRecall is an open-source, privacy-focused digital memory tool capturing and indexing screenshots to enhance productivity without compromising privacy, usable across Windows, macOS, and Linux, and compatible with AI agents for personal assistance&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/openrecall/openrecall"&gt;GitHub&lt;/a&gt; | &lt;a href="https://discord.gg/RzvCYRgUkx"&gt;Discord&lt;/a&gt; | &lt;a href="https://t.me/+5DULWTesqUYwYjY0"&gt;Telegram&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;OpenRouter&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://openrouter.ai/"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-No-red" alt="Open Source" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;üß† Model Providers&lt;/p&gt; 
&lt;p&gt;OpenRouter.ai is a platform that provides access to a wide range of large language models, including open-source and proprietary options like ChatGPT, Gemini, and Perplexity, allowing users to find the best models and pricing for their prompts and use cases&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://openrouter.ai/"&gt;website&lt;/a&gt; | &lt;a href="https://openrouter.ai/docs"&gt;docs&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;Outlines&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/outlines-dev/outlines"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/outlines-dev/outlines"&gt;&lt;img src="https://img.shields.io/github/stars/outlines-dev/outlines?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 12,182 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;üèóÔ∏è Structured Outputs&lt;/p&gt; 
&lt;p&gt;Outlines is a robust text generation library designed for agentic AI developers, featuring support for multiple model integrations, advanced prompting with Jinja, efficient structured generation through regex, JSON schema, context-free grammars, and more, enabling the creation of predictable and structured AI agent outputs&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/outlines-dev/outlines"&gt;github&lt;/a&gt; | &lt;a href="https://outlines-dev.github.io/outlines/"&gt;website&lt;/a&gt; | &lt;a href="https://discord.gg/ZxBxyWmW5n"&gt;discord&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;Perplexity&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://www.perplexity.ai/"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-No-red" alt="Open Source" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;üß† Model Providers&lt;/p&gt; 
&lt;p&gt;Perplexity AI is an AI-powered search engine that offers summarized answers with cited sources, content generation, accurate information retrieval, user-friendly interface, and versatility, making it a valuable tool for various users&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.perplexity.ai/"&gt;website&lt;/a&gt; | &lt;a href="https://docs.perplexity.ai/"&gt;docs&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;Perplexity-Inspired LLM Answer Engine&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/developersdigest/llm-answer-engine"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/developersdigest/llm-answer-engine"&gt;&lt;img src="https://img.shields.io/github/stars/developersdigest/llm-answer-engine?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 4,911 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;üèóÔ∏è Structured Outputs&lt;/p&gt; 
&lt;p&gt;A versatile answer engine leveraging Groq, Mistral AI, Langchain.JS, Brave Search, Serper API, and OpenAI to deliver efficient and sophisticated responses with reduced hallucination through RAG for citation-backed search queries&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/developersdigest/llm-answer-engine"&gt;github&lt;/a&gt; | &lt;a href="https://github.com/developersdigest"&gt;github profile&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;Personal Assistant by HyperWrite&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://www.hyperwriteai.com/personal-assistant"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-No-red" alt="Open Source" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;ü§ñ AI Agents&lt;/p&gt; 
&lt;p&gt;HyperWrite offers a Personal Assistant AI agent for everyday tasks, seamlessly integrating into workflows to automate tedious tasks, optimize planning, and inform decision-making, while also providing personalized suggestions and transforming wishes into commands across various platforms&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.hyperwriteai.com/personal-assistant"&gt;website&lt;/a&gt; | &lt;a href="https://github.com/OthersideAI"&gt;github profile&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;Pieces&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://pieces.app/"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-No-red" alt="Open Source" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;ü§ñ AI Agents&lt;/p&gt; 
&lt;p&gt;Pieces is an AI-powered productivity tool for developers that enhances efficiency through a unified toolchain, offering on-device workflow assistance, intelligent code snippet management, and seamless integration with development tools and plugins&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://pieces.app/"&gt;website&lt;/a&gt; | &lt;a href="https://discord.gg/getpieces"&gt;discord&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;Pinokio&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/pinokiocomputer/pinokio"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/pinokiocomputer/pinokio"&gt;&lt;img src="https://img.shields.io/github/stars/pinokiocomputer/pinokio?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 5,349 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;üíª Local Inference&lt;/p&gt; 
&lt;p&gt;Pinokio is a browser that enables the installation, running, and programmable control of any application with one click, supporting any open-source repo locally, including LLM or AI agent-based projects&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://pinokio.computer/"&gt;website&lt;/a&gt; | &lt;a href="https://github.com/pinokiocomputer/pinokio"&gt;github&lt;/a&gt; | &lt;a href="https://github.com/pinokiocomputer"&gt;github profile&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;PlayAI&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://play.ai/"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-No-red" alt="Open Source" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;üìû Phone Calling&lt;/p&gt; 
&lt;p&gt;Play.ai offers conversational AI voice solutions, with a mission to enable customizable, natural language-based user interfaces, promoting rapid innovation and a performance-driven culture&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://play.ai/"&gt;website&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;PlayHT&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://play.ht/"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-No-red" alt="Open Source" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;üó£Ô∏è Voice Providers&lt;/p&gt; 
&lt;p&gt;PlayHT's AI Voice Generator offers a state-of-the-art TTS service that creates natural, humanlike voiceovers in multiple languages and accents, ideal for various audio content needs with full commercial rights&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://play.ht/"&gt;website&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;PraisonAI&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/MervinPraison/PraisonAI/"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/MervinPraison/PraisonAI/"&gt;&lt;img src="https://img.shields.io/github/stars/MervinPraison/PraisonAI?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 5,237 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;‚öôÔ∏è Development Frameworks&lt;/p&gt; 
&lt;p&gt;Praison AI is a low-code, centralized framework leveraging AutoGen and CrewAI to simplify creating and orchestrating multi-agent systems for LLM applications, emphasizing customization and ease of human-agent interaction&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/MervinPraison/PraisonAI/"&gt;github&lt;/a&gt; | &lt;a href="https://www.youtube.com/watch?v=Fn1lQjC0GO0"&gt;demo&lt;/a&gt; | &lt;a href="https://mer.vin/2024/03/praison-ai-agents-yml/"&gt;website&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;Priompt&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/anysphere/priompt"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/anysphere/priompt"&gt;&lt;img src="https://img.shields.io/github/stars/anysphere/priompt?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 2,651 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;‚úçÔ∏è Prompt Engineering&lt;/p&gt; 
&lt;p&gt;Priompt is a JSX-based library for designing prompts with priorities, aiming to optimize inclusion of content within token limits, inspired by React and detailed with installation instructions, examples, principles, and future considerations&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/anysphere/priompt"&gt;github&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;PrivateGPT&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/zylon-ai/private-gpt/"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/zylon-ai/private-gpt/"&gt;&lt;img src="https://img.shields.io/github/stars/zylon-ai/private-gpt?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 56,373 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;üíª Local Inference&lt;/p&gt; 
&lt;p&gt;PrivateGPT is a secure, offline-capable AI tool for querying documents with Large Language Models, offering high-level and low-level APIs for privacy-conscious, context-aware application development&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/zylon-ai/private-gpt/"&gt;github&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;Produvia&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://produvia.com/"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-No-red" alt="Open Source" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;üõ†Ô∏è Custom Development&lt;/p&gt; 
&lt;p&gt;Since 2013, Produvia Inc. has served $7M+ in revenue brands by developing custom agentic AI solutions powered by state-of-the-art function calling LLMs including but not limited to: Claude 3 Opus, GPT-4, Bard (Gemini Pro), Claude 3 Sonnet, Claude 3 Haiku, Mistral Medium, Command R, Mistral-Next, Starling-LM-7B-beta&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://produvia.com/"&gt;website&lt;/a&gt; | &lt;a href="https://twitter.com/produvia"&gt;twitter&lt;/a&gt; | &lt;a href="https://linkedin.com/company/produvia"&gt;linkedin&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;Prompt2UI by sullyo&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/sullyo/prompt2ui"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/sullyo/prompt2ui"&gt;&lt;img src="https://img.shields.io/github/stars/sullyo/prompt2ui?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 232 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;üñ•Ô∏è UI Development&lt;/p&gt; 
&lt;p&gt;An open-source project that converts prompts to user interfaces, demonstrated by creating a basic Google Calendar clone using Claude in about 2 hours, inspired by Claude Artifacts&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/sullyo/prompt2ui"&gt;github&lt;/a&gt; | &lt;a href="https://x.com/SullyOmarr/status/1804997474761003327"&gt;twitter announcement&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;Pydantic&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/pydantic/pydantic"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/pydantic/pydantic"&gt;&lt;img src="https://img.shields.io/github/stars/pydantic/pydantic?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 24,701 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;üèóÔ∏è Structured Outputs&lt;/p&gt; 
&lt;p&gt;Pydantic is a Python library facilitating data validation through type hints, particularly useful for AI agents, offering fast validation capabilities and compatibility with various development tools&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/pydantic/pydantic"&gt;github&lt;/a&gt; | &lt;a href="https://docs.pydantic.dev/"&gt;website&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;Relevance&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://relevanceai.com/"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-No-red" alt="Open Source" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;üö´üíª No-Code Development Frameworks&lt;/p&gt; 
&lt;p&gt;Relevance AI offers a platform for building and deploying AI workers to automate tasks, integrate with tech stacks, and manage security, aiming to enhance business efficiency without increasing headcount&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://relevanceai.com/"&gt;website&lt;/a&gt; | &lt;a href="https://twitter.com/RelevanceAI"&gt;twitter&lt;/a&gt; | &lt;a href="https://github.com/RelevanceAI"&gt;github profile&lt;/a&gt; | &lt;a href="https://www.linkedin.com/company/relevanceai/"&gt;linkedin&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;Rime AI&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://rime.ai/"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-No-red" alt="Open Source" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;üó£Ô∏è Voice Providers&lt;/p&gt; 
&lt;p&gt;Rime is a speech synthesis API offering natural-sounding, demographically tailored voices with fast response times for various uses, including customer service and narration&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://rime.ai/"&gt;website&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;ScrapeGraphAI&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/VinciGit00/Scrapegraph-ai"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/VinciGit00/Scrapegraph-ai"&gt;&lt;img src="https://img.shields.io/github/stars/VinciGit00/Scrapegraph-ai?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 20,809 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;üåê Web Browsing Frameworks&lt;/p&gt; 
&lt;p&gt;ScrapeGraph AI provides a tool for creating AI agents that can automate web scraping tasks efficiently, enhancing data extraction capabilities through the use of LangGraph, function calls, and web scraping techniques&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/VinciGit00/Scrapegraph-ai"&gt;github&lt;/a&gt; | &lt;a href="https://scrapegraph-doc.onrender.com/"&gt;docs&lt;/a&gt; | &lt;a href="https://scrapegraph-ai-demo.streamlit.appn/"&gt;demo&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;Self Operating Computer&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/OthersideAI/self-operating-computer"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/OthersideAI/self-operating-computer"&gt;&lt;img src="https://img.shields.io/github/stars/OthersideAI/self-operating-computer?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 9,808 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;üíª Operating System (OS)&lt;/p&gt; 
&lt;p&gt;Self Operating Computer (SOC) enables multimodal models to autonomously interact with a computer using human-like inputs and outputs, including controlling the keyboard and mouse. It is compatible with various models and under ongoing development for more accurate functionalities&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.hyperwriteai.com/self-operating-computer"&gt;landing page&lt;/a&gt; | &lt;a href="https://github.com/OthersideAI/self-operating-computer"&gt;github&lt;/a&gt; | &lt;a href="https://github.com/OthersideAI"&gt;github profile&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;Self Operating Computer by Otherside&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/OthersideAI/self-operating-computer"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/OthersideAI/self-operating-computer"&gt;&lt;img src="https://img.shields.io/github/stars/OthersideAI/self-operating-computer?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 9,808 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;ü§ñ AI Agents&lt;/p&gt; 
&lt;p&gt;SOC is a framework enabling multimodal models to operate a computer using human-like inputs and outputs, with compatibility for various models such as GPT-4v, Gemini Pro Vision, and LLaVA, offering future support for additional models and featuring various modes including voice and optical character recognition&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/OthersideAI/self-operating-computer"&gt;github&lt;/a&gt; | &lt;a href="https://github.com/OthersideAI"&gt;github profile&lt;/a&gt; | &lt;a href="https://www.hyperwriteai.com/self-operating-computer"&gt;landing page&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;ShortGPT by RayVentura&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/RayVentura/ShortGPT"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/RayVentura/ShortGPT"&gt;&lt;img src="https://img.shields.io/github/stars/RayVentura/ShortGPT?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 6,679 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;ü§ñ AI Agents&lt;/p&gt; 
&lt;p&gt;ShortGPT is an AI-powered framework for automating content creation, including video editing, voiceover synthesis, caption generation, and asset sourcing, with support for multiple languages and seamless integration with Google Colab and Docker for easy deployment&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/RayVentura/ShortGPT"&gt;github&lt;/a&gt; | &lt;a href="https://github.com/RayVentura"&gt;github profile&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;ShortX by RayVentura&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://shortx.ai/"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-No-red" alt="Open Source" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;ü§ñ AI Agents&lt;/p&gt; 
&lt;p&gt;ShortX is a AI-powered video automation platform for YouTube Shorts, Instagram Reels, TikTok, and Snapchat, offering customizable templates, AI services, and a subscription model with an affiliate program and user testimonials&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://shortx.ai/"&gt;website&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;Streaming Assistants&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/phact/streaming-assistants"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/phact/streaming-assistants"&gt;&lt;img src="https://img.shields.io/github/stars/phact/streaming-assistants?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 8 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;ü§ñ Assistants API&lt;/p&gt; 
&lt;p&gt;The `streaming-assistants` library on GitHub enables streaming for OpenAI Assistants API using Astra Assistants, providing a workaround for the lack of streaming support in the official OpenAI Assistants API&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/phact/streaming-assistants"&gt;github&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;Streamlit Agent by Langchain&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/langchain-ai/streamlit-agent"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/langchain-ai/streamlit-agent"&gt;&lt;img src="https://img.shields.io/github/stars/langchain-ai/streamlit-agent?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 1,520 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;‚öôÔ∏è Development Frameworks&lt;/p&gt; 
&lt;p&gt;This repository showcases various LangChain agents as Streamlit apps, including a basic streaming app, a memory-based conversation app, a demo replicating MRKL functionality, a minimal agent with search capability, chatbots with feedback options, document querying, database communication, and pandas DataFrame interaction, featuring LangChain and Streamlit integrations&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/langchain-ai/streamlit-agent"&gt;github&lt;/a&gt; | &lt;a href="https://github.com/langchain-ai"&gt;github profile&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;Streamship&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/steamship-core/python-client"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/steamship-core/python-client"&gt;&lt;img src="https://img.shields.io/github/stars/steamship-core/python-client?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 324 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;‚öôÔ∏è Development Frameworks&lt;/p&gt; 
&lt;p&gt;A development platform for AI Agents offering Python SDK, cloud deployment, serverless hosting, vector search, webhooks, and media generation, with a focus on simplicity, scalability, and integration with popular models and services&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/steamship-core/python-client"&gt;github&lt;/a&gt; | &lt;a href="https://www.steamship.com/"&gt;website&lt;/a&gt; | &lt;a href="https://www.twitter.com/GetSteamship"&gt;twitter&lt;/a&gt; | &lt;a href="https://steamship.com/discord"&gt;discord&lt;/a&gt; | &lt;a href="https://www.github.com/steamship-core"&gt;github profile&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;Superagent&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/superagent-ai/superagent"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/superagent-ai/superagent"&gt;&lt;img src="https://img.shields.io/github/stars/superagent-ai/superagent?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 6,062 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;‚öôÔ∏è Development Frameworks&lt;/p&gt; 
&lt;p&gt;Superagent is an open-source AI assistant framework backed by Y Combinator, facilitating the integration of large language models (LLM) and generative AI into applications, supporting various use cases such as question answering, chatbots, and content generation&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/superagent-ai/superagent"&gt;github&lt;/a&gt; | &lt;a href="https://github.com/superagent-ai"&gt;github profile&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;SuperAGI&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/TransformerOptimus/SuperAGI"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/TransformerOptimus/SuperAGI"&gt;&lt;img src="https://img.shields.io/github/stars/TransformerOptimus/SuperAGI?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 16,585 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;‚öôÔ∏è Development Frameworks&lt;/p&gt; 
&lt;p&gt;SuperAGI is an open-source framework facilitating the development, management, and operation of useful Autonomous AI Agents with a variety of features and toolkits available, including a graphical user interface, action console, and multiple vector databases&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/TransformerOptimus/SuperAGI"&gt;github&lt;/a&gt; | &lt;a href="https://github.com/TransformerOptimus"&gt;github profile&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;Swarms&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/kyegomez/swarms/"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/kyegomez/swarms/"&gt;&lt;img src="https://img.shields.io/github/stars/kyegomez/swarms?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 5,068 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;‚öôÔ∏è Development Frameworks&lt;/p&gt; 
&lt;p&gt;Swarms orchestrates multi-agent collaboration for production-grade applications, solving issues like short memory and high costs, with customizable tools for specific needs, currently used by RBC, John Deere, and AI startups&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/kyegomez/swarms/"&gt;github&lt;/a&gt; | &lt;a href="https://discord.gg/DbjBMJTSWD"&gt;discord&lt;/a&gt; | &lt;a href="https://swarms.apac.ai/"&gt;docs&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;SWE-agent&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/princeton-nlp/SWE-agent"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/princeton-nlp/SWE-agent"&gt;&lt;img src="https://img.shields.io/github/stars/princeton-nlp/SWE-agent?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 16,847 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;‚öôÔ∏è Development Frameworks&lt;/p&gt; 
&lt;p&gt;This open source project introduces SWE-agent, a software engineering agent for LMs like GPT-4, enhancing bug and issue resolution in GitHub repositories with state-of-the-art performance, facilitated by a well-designed Agent-Computer Interface (ACI) and support for OpenAI and Anthropic Claude models&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/princeton-nlp/SWE-agent"&gt;github&lt;/a&gt; | &lt;a href="https://swe-agent.com/"&gt;website&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;Sweep&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/sweepai/sweep"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/sweepai/sweep"&gt;&lt;img src="https://img.shields.io/github/stars/sweepai/sweep?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 7,577 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;ü§ñ AI Agents&lt;/p&gt; 
&lt;p&gt;Sweep is an AI tool that automates the transformation of GitHub issues into pull requests, streamlining code improvements and bug fixes, supported by a suite of features like codebase understanding, test running, and a developer-friendly interface for installation and usage&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/sweepai/sweep"&gt;github&lt;/a&gt; | &lt;a href="https://sweep.dev/"&gt;website&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;Synthflow AI&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://synthflow.ai/"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-No-red" alt="Open Source" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;üìû Phone Calling&lt;/p&gt; 
&lt;p&gt;Synthflow is a platform enabling the creation of human-like conversational AI voice agents with no-code customization, integrating directly with apps like HubSpot and Eleven Labs for voice services&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://synthflow.ai/"&gt;website&lt;/a&gt; | &lt;a href="https://docs.synthflow.ai/"&gt;docs&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;Tabby&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/TabbyML/tabby"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/TabbyML/tabby"&gt;&lt;img src="https://img.shields.io/github/stars/TabbyML/tabby?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 31,853 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;ü§ñ AI Agents&lt;/p&gt; 
&lt;p&gt;Tabby is a self-hosted, open-source AI coding assistant similar to GitHub Copilot, featuring a self-contained setup with no DBMS/cloud dependency, OpenAPI for easy integration, consumer-grade GPU support, and a full-feature admin UI in its latest release&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/TabbyML/tabby"&gt;github&lt;/a&gt; | &lt;a href="https://tabby.tabbyml.com/"&gt;website&lt;/a&gt; | &lt;a href="https://tabby.tabbyml.com/docs"&gt;docs&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;Talkscriber&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://www.talkscriber.com"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-No-red" alt="Open Source" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;üéôÔ∏è Transcriber Providers&lt;/p&gt; 
&lt;p&gt;Talkscriber is an enterprise-grade speech-to-text (STT) platform that offers industry-leading accuracy, security, and cost-effectiveness, enabling organizations to transform spoken language into digital text and unlock new possibilities in data analysis while hosting Whisper (OpenAI) model&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.talkscriber.com"&gt;website&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;Tarsier by Reworkd&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/reworkd/tarsier"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/reworkd/tarsier"&gt;&lt;img src="https://img.shields.io/github/stars/reworkd/tarsier?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 1,713 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;‚öôÔ∏è Development Frameworks&lt;/p&gt; 
&lt;p&gt;Tarsier is an open-source utility library by Reworkd, aimed at enhancing web interaction for AI agents by visually tagging interactable elements, facilitating actions based on text or screenshots for GPT-4(V) and providing OCR utilities&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/reworkd/tarsier"&gt;github&lt;/a&gt; | &lt;a href="https://reworkd.ai/"&gt;website&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;Taskade AI&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://www.taskade.com/"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-No-red" alt="Open Source" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;ü§ñ AI Agents&lt;/p&gt; 
&lt;p&gt;Taskade AI is an AI-powered productivity suite offering tools like task and project management, notes, docs, mind maps, and AI chat to enhance team productivity and automate over 700 tasks&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.taskade.com/"&gt;website&lt;/a&gt; | &lt;a href="https://twitter.com/Taskade"&gt;twitter&lt;/a&gt; | &lt;a href="https://youtube.com/taskade"&gt;youtube&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;TaskingAI&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/TaskingAI/TaskingAI"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/TaskingAI/TaskingAI"&gt;&lt;img src="https://img.shields.io/github/stars/TaskingAI/TaskingAI?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 5,274 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;‚öôÔ∏è Development Frameworks&lt;/p&gt; 
&lt;p&gt;TaskingAI is a platform enhancing AI-native app development with Firebase-like simplicity, offering an all-in-one LLM platform with intuitive project management, BaaS-inspired workflow, and customizable integration for developing GPTs-like multi-tenant applications&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/TaskingAI/TaskingAI"&gt;github&lt;/a&gt; | &lt;a href="https://www.tasking.ai/"&gt;website&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;Tavily&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://tavily.com/"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-No-red" alt="Open Source" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;ü§ñ AI Agents&lt;/p&gt; 
&lt;p&gt;Tavily AI is your comprehensive research assistant, offering a platform for rapid insights with a Search API for LLMs, ensuring real-time, accurate, and bias-reduced data gathering and organization, suitable for both individual and enterprise needs&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://tavily.com/"&gt;website&lt;/a&gt; | &lt;a href="https://github.com/assafelovic"&gt;github profile&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;TeamX&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://teamx.work/"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-No-red" alt="Open Source" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;ü§ñ AI Agents&lt;/p&gt; 
&lt;p&gt;TeamX is an Agents-as-a-Service (AaaS) by Produvia which scales businesses with AI agent teams, offering custom solutions focused on automation, efficiency, and scalability&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://teamx.work/"&gt;website&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;TogetherAI&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://www.together.ai/"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-No-red" alt="Open Source" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;üß† Model Providers&lt;/p&gt; 
&lt;p&gt;TogetherAI is a platform that facilitates efficient and accurate summarization of text using advanced AI algorithms and user-friendly tools&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.together.ai/"&gt;website&lt;/a&gt; | &lt;a href="https://docs.together.ai/docs/quickstart"&gt;docs&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;Tools by Taskade&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://help.taskade.com/en/articles/8958457-custom-ai-agents#h_c9a93fc5b9"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-No-red" alt="Open Source" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt; Function Calling&lt;/p&gt; 
&lt;p&gt;Enable your agents with the right set of tools to get the job done: web search (allow the agent to browse the web), WolframAlpha (enhance the agent's computational skills), add-ons (enable additional tools and extensions)&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://help.taskade.com/en/articles/8958457-custom-ai-agents#h_c9a93fc5b9"&gt;docs&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;tortoise-tts&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/neonbjb/tortoise-tts"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/neonbjb/tortoise-tts"&gt;&lt;img src="https://img.shields.io/github/stars/neonbjb/tortoise-tts?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 14,463 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt; Voice Providers (TTS Models)&lt;/p&gt; 
&lt;p&gt;A multi-voice TTS system trained with an emphasis on quality&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/neonbjb/tortoise-tts"&gt;github&lt;/a&gt; | &lt;a href="https://arxiv.org/abs/2305.07243"&gt;research paper&lt;/a&gt; | &lt;a href="https://huggingface.co/spaces/Manmay/tortoise-tts"&gt;demo&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;Traces by Weights &amp;amp; Biases&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://wandb.ai/site/traces"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-No-red" alt="Open Source" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;üëÅÔ∏è Observability Frameworks&lt;/p&gt; 
&lt;p&gt;W&amp;amp;B Traces enhances AI agent observability by providing intuitive visualizations for debugging LLMs, allowing practitioners to review past results, debug errors, and gain insights into model behavior&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://wandb.ai/site/traces"&gt;website&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;Twilio&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://www.twilio.com"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-No-red" alt="Open Source" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚òéÔ∏è Phone Number Providers&lt;/p&gt; 
&lt;p&gt;Twilio is a cloud communications platform that enables developers to programmatically make phone calls, send and receive text messages, and integrate other communication features into their applications using its web APIs&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.twilio.com"&gt;website&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;TypeChat&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/microsoft/TypeChat"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/microsoft/TypeChat"&gt;&lt;img src="https://img.shields.io/github/stars/microsoft/TypeChat?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 8,536 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt; Function Calling&lt;/p&gt; 
&lt;p&gt;TypeChat is a library that facilitates building natural language interfaces by using schema engineering as an alternative to traditional function calling in LLMs, avoiding JSON schema-based constraints&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/microsoft/TypeChat"&gt;github&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;uAgents by Fetch AI&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/fetchai/uAgents"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/fetchai/uAgents"&gt;&lt;img src="https://img.shields.io/github/stars/fetchai/uAgents?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 1,468 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;‚öôÔ∏è Development Frameworks&lt;/p&gt; 
&lt;p&gt;uAgents is a Python library by Fetch AI for creating autonomous AI agents with features like easy creation, blockchain network connectivity, and cryptographic security&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/fetchai/uAgents"&gt;github&lt;/a&gt; | &lt;a href="https://github.com/fetchai"&gt;github profile&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;VacAIgent&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/tonykipkemboi/trip_planner_agent"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/tonykipkemboi/trip_planner_agent"&gt;&lt;img src="https://img.shields.io/github/stars/tonykipkemboi/trip_planner_agent?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 133 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;ü§ñ AI Agents&lt;/p&gt; 
&lt;p&gt;VacAIgent is a Streamlit-integrated, CrewAI framework-based AI application (Trip Planner Agent) that automates and enhances trip planning through a user-friendly interface, demonstrating collaborative AI agent task execution and offering an interactive web app experience for tailoring travel plans&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/tonykipkemboi/trip_planner_agent"&gt;github&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;Vapi&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://vapi.ai/"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-No-red" alt="Open Source" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;üìû Phone Calling&lt;/p&gt; 
&lt;p&gt;Vapi is a developer-friendly platform that enables the rapid creation, testing, and deployment of voicebots, revolutionizing voice AI integration with seamless support from voice providers&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://vapi.ai/"&gt;website&lt;/a&gt; | &lt;a href="https://discord.gg/pUFNcf2WmH"&gt;discord&lt;/a&gt; | &lt;a href="https://twitter.com/Vapi_AI"&gt;twitter&lt;/a&gt; | &lt;a href="https://www.linkedin.com/company/vapi-ai"&gt;linkedin&lt;/a&gt; | &lt;a href="https://docs.vapi.ai"&gt;docs&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;Vertex AI by Google&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://cloud.google.com/vertex-ai"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-No-red" alt="Open Source" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;üö´üíª No-Code Development Frameworks&lt;/p&gt; 
&lt;p&gt;Vertex AI, enhanced by Gemini models, offers comprehensive generative AI solutions for rapid application development, data processing, custom model training with minimal ML expertise, and production deployment, aimed at accelerating innovation and reducing costs in enterprise environments&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://cloud.google.com/vertex-ai"&gt;website&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;Verve&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://x.com/AnnieLiao_2000/status/1792175562712285645"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-No-red" alt="Open Source" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;üõ†Ô∏è Build Club&lt;/p&gt; 
&lt;p&gt;Verve is an AI data copilot that aims to streamline analytics and significantly reduce manual work for growing organizations&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://x.com/AnnieLiao_2000/status/1792175562712285645"&gt;demo&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;vimGPT&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/ishan0102/vimGPT"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/ishan0102/vimGPT"&gt;&lt;img src="https://img.shields.io/github/stars/ishan0102/vimGPT?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 2,669 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;ü§ñ AI Agents&lt;/p&gt; 
&lt;p&gt;vimGPT is a project that integrates GPT-4V's vision capabilities with the Vimium extension to enable web browsing and interaction through keyboard navigation and voice commands, offering innovative solutions and improvements for accessibility and efficiency&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/ishan0102/vimGPT"&gt;github&lt;/a&gt; | &lt;a href="https://github.com/ishan0102/vimGPT/tree/main?tab=readme-ov-file#vimgpt"&gt;demo&lt;/a&gt; | &lt;a href="https://news.ycombinator.com/item?id=38200308"&gt;hackernews&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;Vonage&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://vonage.com/"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-No-red" alt="Open Source" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚òéÔ∏è Phone Number Providers&lt;/p&gt; 
&lt;p&gt;Vonage is a leading provider of phone services that offers a range of features and options for residential and business customers, including local, toll-free, and international numbers, as well as virtual receptionist and call management capabilities&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://vonage.com/"&gt;website&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;Waii&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://x.com/AlexReibman/status/1772777493122163107"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-No-red" alt="Open Source" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;ü§ñ AI Agents&lt;/p&gt; 
&lt;p&gt;A swift and straightforward AI agent for converting natural language to SQL queries, seamlessly integrable with your application&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://x.com/AlexReibman/status/1772777493122163107"&gt;demo&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;XAgent&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/OpenBMB/XAgent"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/OpenBMB/XAgent"&gt;&lt;img src="https://img.shields.io/github/stars/OpenBMB/XAgent?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 8,404 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;ü§ñ AI Agents&lt;/p&gt; 
&lt;p&gt;XAgent is an open-source, experimental Large Language Model-driven autonomous agent designed to autonomously solve a wide range of tasks with features like autonomy, safety, extensibility, a GUI for easy interaction, and the ability to cooperate with humans&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/OpenBMB/XAgent"&gt;github&lt;/a&gt; | &lt;a href="https://www.youtube.com/watch?v=QGkpd-tsFPA"&gt;demo&lt;/a&gt; | &lt;a href="https://xagent-doc.readthedocs.io/en/latest/"&gt;docs&lt;/a&gt; | &lt;a href="https://blog.x-agent.net/blog/xagent/"&gt;blog&lt;/a&gt;&lt;/p&gt;  
&lt;h3&gt;Zep&lt;/h3&gt; 
&lt;div&gt;
 &lt;a href="https://github.com/getzep/zep/"&gt;&lt;img src="https://img.shields.io/badge/Open%20Source-Yes-green" alt="Open Source" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/getzep/zep/"&gt;&lt;img src="https://img.shields.io/github/stars/getzep/zep?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;
&lt;/div&gt; 
&lt;p&gt;‚≠ê 3,447 stars (Updated: 2025-07-30)&lt;/p&gt; 
&lt;p&gt;üß† Long-Term Memory&lt;/p&gt; 
&lt;p&gt;Zep is a long-term memory service for AI assistants that enhances recall, understanding, and data extraction from chat histories to power personalized AI experiences&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.getzep.com/"&gt;website&lt;/a&gt; | &lt;a href="https://github.com/getzep/zep/"&gt;github&lt;/a&gt;&lt;/p&gt;  
&lt;h2&gt;üôã‚Äç‚ôÇÔ∏è Hire Me&lt;/h2&gt; 
&lt;p&gt;Do you want to develop a custom agentic AI solution or looking launch your own AI agent?&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://cal.com/slavakurilyak/discovery-call"&gt;Schedule a discovery call&lt;/a&gt; with me&lt;/p&gt; 
&lt;p&gt;Disclaimer: Slava Kurilyak is the Founder/CEO at Produvia&lt;/p&gt; 
&lt;p&gt;At Produvia, we partner with $7M+ in revenue brands to develop custom AI agents&lt;/p&gt; 
&lt;h2&gt;‚ù§Ô∏è Show Your Support&lt;/h2&gt; 
&lt;p&gt;To express your support, you can take the following actions:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Star the Repository&lt;/strong&gt;: This helps increase its visibility.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Submit Suggestions&lt;/strong&gt;: If you have any ideas or feedback, please open a new issue &lt;a href="https://github.com/slavakurilyak/awesome-ai-agents/issues/new"&gt;here&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Contribute Directly&lt;/strong&gt;: You can contribute by forking this repository and then submitting your contributions through a new pull request &lt;a href="https://github.com/slavakurilyak/awesome-ai-agents/fork"&gt;here&lt;/a&gt;.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;üöÄ Star History&lt;/h2&gt; 
&lt;a href="https://star-history.com/#slavakurilyak/awesome-ai-agents&amp;amp;Date"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://api.star-history.com/svg?repos=slavakurilyak/awesome-ai-agents&amp;amp;type=Date&amp;amp;theme=dark" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://api.star-history.com/svg?repos=slavakurilyak/awesome-ai-agents&amp;amp;type=Date" /&gt; 
  &lt;img alt="Star History Chart" src="https://api.star-history.com/svg?repos=slavakurilyak/awesome-ai-agents&amp;amp;type=Date" /&gt; 
 &lt;/picture&gt; &lt;/a&gt;</description>
    </item>
    
    <item>
      <title>weaviate/elysia</title>
      <link>https://github.com/weaviate/elysia</link>
      <description>&lt;p&gt;Python package and backend for the Elysia platform app.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Elysia: Agentic Framework Powered by Decision Trees&lt;/h1&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;‚ö†Ô∏è Elysia is in beta!&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;If you encounter any issues, please &lt;a href="https://github.com/weaviate/elysia/issues"&gt;open an issue on GitHub&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;a href="https://pepy.tech/projects/elysia-ai"&gt;&lt;img src="https://static.pepy.tech/badge/elysia-ai" alt="PyPI Downloads" /&gt;&lt;/a&gt; &lt;a href="https://elysia.weaviate.io/"&gt;&lt;img src="https://img.shields.io/badge/Check%20out%20the%20demo!-yellow?&amp;amp;style=flat-square&amp;amp;logo=react&amp;amp;logoColor=white" alt="Demo" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Elysia is an agentic platform designed to use tools in a decision tree. A decision agent decides which tools to use dynamically based on its environment and context. You can use custom tools or use the pre-built tools designed to retrieve your data in a Weaviate cluster.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://weaviate.github.io/elysia/"&gt;Read the docs!&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Installation is as simple as:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install elysia-ai
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Get started (App)&lt;/h2&gt; 
&lt;p&gt;Run the app via&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;elysia start
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then navigate to the settings page, add your required API keys, Weaviate cloud cluster details and specify your models.&lt;/p&gt; 
&lt;p&gt;Don't forget to check out &lt;a href="https://github.com/weaviate/elysia-frontend"&gt;the Github Repository for the Frontend&lt;/a&gt;!&lt;/p&gt; 
&lt;p&gt;Alternatively, we have created a demo version of Elysia (rate-limited, fixed datasets) to experiment with. Find it at: &lt;a href="https://elysia.weaviate.io/"&gt;https://elysia.weaviate.io/&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Get Started (Python)&lt;/h2&gt; 
&lt;p&gt;To use Elysia, you need to either set up your models and API keys in your &lt;code&gt;.env&lt;/code&gt; file, or specify them in the config. &lt;a href="https://weaviate.github.io/elysia/setting_up/"&gt;See the setup page to get started.&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Elysia can be used very simply:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from elysia import tool, Tree

tree = Tree()

@tool(tree=tree)
async def add(x: int, y: int) -&amp;gt; int:
    return x + y

tree("What is the sum of 9009 and 6006?")
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Elysia is pre-configured to be capable of connecting to and interacting with your &lt;a href="https://weaviate.io/deployment/serverless"&gt;Weaviate&lt;/a&gt; clusters!&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import elysia
tree = elysia.Tree()
response, objects = tree(
    "What are the 10 most expensive items in the Ecommerce collection?",
    collection_names = ["Ecommerce"]
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This will use the built-in open source &lt;em&gt;query&lt;/em&gt; tool or &lt;em&gt;aggregate&lt;/em&gt; tool to interact with your Weaviate collections. To get started connecting to Weaviate, &lt;a href="https://weaviate.github.io/elysia/setting_up/"&gt;see the setting up page in the docs&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Installation (bash) (Linux/MacOS)&lt;/h2&gt; 
&lt;h3&gt;PyPi (Recommended)&lt;/h3&gt; 
&lt;p&gt;Elysia requires Python 3.12:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://formulae.brew.sh/formula/python@3.12"&gt;Installation via brew (macOS)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.python.org/downloads/release/python-3120/"&gt;Installation via installer (Windows)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://ubuntuhandbook.org/index.php/2023/05/install-python-3-12-ubuntu/"&gt;Installation (Ubuntu)&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Optionally create a virtual environment via&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python3.12 -m venv .venv
source .venv/bin/activate
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then simply run&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install elysia-ai
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;to install straight away!&lt;/p&gt; 
&lt;h3&gt;GitHub&lt;/h3&gt; 
&lt;p&gt;To get the latest development version, you can clone the github repo by running&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/weaviate/elysia
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;move to the working directory via&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd elysia
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Create a virtual environment with Python (version 3.10 - 3.12)&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python3.12 -m venv .venv
source .venv/bin/activate
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;and then install Elysia via pip&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install -e .
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Done! You can now use the Elysia python package&lt;/p&gt; 
&lt;h3&gt;Configuring Settings&lt;/h3&gt; 
&lt;p&gt;To use Elysia with Weaviate, i.e. for agentic searching and retrieval, you need a Weaviate cluster api key and URL. This can be specific in the app directly, or by creating a &lt;code&gt;.env&lt;/code&gt; file with&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;WCD_URL=...
WCD_API_KEY=...
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Elysia will automatically detect these when running locally, and this will be the default Weaviate cluster for all users logging into the Elysia app. But these can be configured on a user-by-user basis through the config.&lt;/p&gt; 
&lt;p&gt;Whichever vectoriser you use for your Weaviate collection you will need to specify your corresponding API key, e.g.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;OPENAI_API_KEY=...
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;These will automatically be added to the headers for the Weaviate client.&lt;/p&gt; 
&lt;p&gt;Same for whichever model you choose for the LLM in Elysia, so if you are using GPT-4o, for example, specify an &lt;code&gt;OPENAI_API_KEY&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Elysia's recommended config is to use &lt;a href="https://openrouter.ai/"&gt;OpenRouter&lt;/a&gt; to give easy access to a variety of models. So this requires&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;OPENROUTER_API_KEY=...
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;FAQ&lt;/h2&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;b&gt;How do I use Elysia with my own data?&lt;/b&gt;&lt;/summary&gt; 
 &lt;p&gt;You can connect to your own Weaviate cloud cluster, which will automatically identify any collections that exist in the cluster.&lt;/p&gt; 
 &lt;p&gt;Collections require being &lt;em&gt;preprocessed&lt;/em&gt; for Elysia. In the app, you just click the 'analyze' button in the Data tab. In Python you can do:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;from elysia.preprocessing.collection import preprocess

preprocess(collection_names=["YourCollectionName"])
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;b&gt;Can I use a locally running version of Weaviate such as with Docker?&lt;/b&gt;&lt;/summary&gt; Locally running versions of Weaviate are currently not implemented in the current version of the app but this is planned for a future release. Stay tuned! 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;b&gt;How do I clear all my Elysia data?&lt;/b&gt;&lt;/summary&gt; 
 &lt;p&gt;Everything Elysia doesn't store locally will be a collection in your Weaviate cluster. You can delete any collections that start with &lt;code&gt;ELYSIA_&lt;/code&gt; to reset all your Elysia data.&lt;/p&gt; 
 &lt;p&gt;For example, in Python:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;from elysia.util.client import ClientManager()
with ClientManager().connect_to_client() as client:
    for collection_name in client.collections.list_all():
        if collection_name.startswith("ELYSIA_"):
            client.collections.delete(collection_name)
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;b&gt;Can I contribute to Elysia?&lt;/b&gt;&lt;/summary&gt; 
 &lt;p&gt;Elysia is &lt;strong&gt;fully open source&lt;/strong&gt;, so yes of course you can! Clone and create a new branch of Elysia via&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/weaviate/elysia
git checkout -b &amp;lt;branch_name&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Make your changes, push them to your branch, go to GitHub and submit a pull request.&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;b&gt;Where is the best place I can start contributing?&lt;/b&gt;&lt;/summary&gt; 
 &lt;p&gt;There are no 'huge' new features we are planning for Elysia (for the moment). You could start with creating a new tool, or multiple new tools to create a custom workflow for something specific. Look for pain points you experience from your user journey and find what exactly is causing these. Then try to fix them or create an alternative way of doing things!&lt;/p&gt; 
&lt;/details&gt;</description>
    </item>
    
    <item>
      <title>eriklindernoren/ML-From-Scratch</title>
      <link>https://github.com/eriklindernoren/ML-From-Scratch</link>
      <description>&lt;p&gt;Machine Learning From Scratch. Bare bones NumPy implementations of machine learning models and algorithms with a focus on accessibility. Aims to cover everything from linear regression to deep learning.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Machine Learning From Scratch&lt;/h1&gt; 
&lt;h2&gt;About&lt;/h2&gt; 
&lt;p&gt;Python implementations of some of the fundamental Machine Learning models and algorithms from scratch.&lt;/p&gt; 
&lt;p&gt;The purpose of this project is not to produce as optimized and computationally efficient algorithms as possible but rather to present the inner workings of them in a transparent and accessible way.&lt;/p&gt; 
&lt;h2&gt;Table of Contents&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/eriklindernoren/ML-From-Scratch/master/#machine-learning-from-scratch"&gt;Machine Learning From Scratch&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/eriklindernoren/ML-From-Scratch/master/#about"&gt;About&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/eriklindernoren/ML-From-Scratch/master/#table-of-contents"&gt;Table of Contents&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/eriklindernoren/ML-From-Scratch/master/#installation"&gt;Installation&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/eriklindernoren/ML-From-Scratch/master/#examples"&gt;Examples&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/eriklindernoren/ML-From-Scratch/master/#polynomial-regression"&gt;Polynomial Regression&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/eriklindernoren/ML-From-Scratch/master/#classification-with-cnn"&gt;Classification With CNN&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/eriklindernoren/ML-From-Scratch/master/#density-based-clustering"&gt;Density-Based Clustering&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/eriklindernoren/ML-From-Scratch/master/#generating-handwritten-digits"&gt;Generating Handwritten Digits&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/eriklindernoren/ML-From-Scratch/master/#deep-reinforcement-learning"&gt;Deep Reinforcement Learning&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/eriklindernoren/ML-From-Scratch/master/#image-reconstruction-with-rbm"&gt;Image Reconstruction With RBM&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/eriklindernoren/ML-From-Scratch/master/#evolutionary-evolved-neural-network"&gt;Evolutionary Evolved Neural Network&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/eriklindernoren/ML-From-Scratch/master/#genetic-algorithm"&gt;Genetic Algorithm&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/eriklindernoren/ML-From-Scratch/master/#association-analysis"&gt;Association Analysis&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/eriklindernoren/ML-From-Scratch/master/#implementations"&gt;Implementations&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/eriklindernoren/ML-From-Scratch/master/#supervised-learning"&gt;Supervised Learning&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/eriklindernoren/ML-From-Scratch/master/#unsupervised-learning"&gt;Unsupervised Learning&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/eriklindernoren/ML-From-Scratch/master/#reinforcement-learning"&gt;Reinforcement Learning&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/eriklindernoren/ML-From-Scratch/master/#deep-learning"&gt;Deep Learning&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/eriklindernoren/ML-From-Scratch/master/#contact"&gt;Contact&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;$ git clone https://github.com/eriklindernoren/ML-From-Scratch
$ cd ML-From-Scratch
$ python setup.py install
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Examples&lt;/h2&gt; 
&lt;h3&gt;Polynomial Regression&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;$ python mlfromscratch/examples/polynomial_regression.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p align="center"&gt; &lt;img src="http://eriklindernoren.se/images/p_reg.gif" width="640" \ /&gt; &lt;/p&gt; 
&lt;p align="center"&gt; Figure: Training progress of a regularized polynomial regression model fitting &lt;br /&gt; temperature data measured in Link√∂ping, Sweden 2016. &lt;/p&gt; 
&lt;h3&gt;Classification With CNN&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;$ python mlfromscratch/examples/convolutional_neural_network.py

+---------+
| ConvNet |
+---------+
Input Shape: (1, 8, 8)
+----------------------+------------+--------------+
| Layer Type           | Parameters | Output Shape |
+----------------------+------------+--------------+
| Conv2D               | 160        | (16, 8, 8)   |
| Activation (ReLU)    | 0          | (16, 8, 8)   |
| Dropout              | 0          | (16, 8, 8)   |
| BatchNormalization   | 2048       | (16, 8, 8)   |
| Conv2D               | 4640       | (32, 8, 8)   |
| Activation (ReLU)    | 0          | (32, 8, 8)   |
| Dropout              | 0          | (32, 8, 8)   |
| BatchNormalization   | 4096       | (32, 8, 8)   |
| Flatten              | 0          | (2048,)      |
| Dense                | 524544     | (256,)       |
| Activation (ReLU)    | 0          | (256,)       |
| Dropout              | 0          | (256,)       |
| BatchNormalization   | 512        | (256,)       |
| Dense                | 2570       | (10,)        |
| Activation (Softmax) | 0          | (10,)        |
+----------------------+------------+--------------+
Total Parameters: 538570

Training: 100% [------------------------------------------------------------------------] Time: 0:01:55
Accuracy: 0.987465181058
&lt;/code&gt;&lt;/pre&gt; 
&lt;p align="center"&gt; &lt;img src="http://eriklindernoren.se/images/mlfs_cnn1.png" width="640" /&gt; &lt;/p&gt; 
&lt;p align="center"&gt; Figure: Classification of the digit dataset using CNN. &lt;/p&gt; 
&lt;h3&gt;Density-Based Clustering&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;$ python mlfromscratch/examples/dbscan.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p align="center"&gt; &lt;img src="http://eriklindernoren.se/images/mlfs_dbscan.png" width="640" /&gt; &lt;/p&gt; 
&lt;p align="center"&gt; Figure: Clustering of the moons dataset using DBSCAN. &lt;/p&gt; 
&lt;h3&gt;Generating Handwritten Digits&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;$ python mlfromscratch/unsupervised_learning/generative_adversarial_network.py

+-----------+
| Generator |
+-----------+
Input Shape: (100,)
+------------------------+------------+--------------+
| Layer Type             | Parameters | Output Shape |
+------------------------+------------+--------------+
| Dense                  | 25856      | (256,)       |
| Activation (LeakyReLU) | 0          | (256,)       |
| BatchNormalization     | 512        | (256,)       |
| Dense                  | 131584     | (512,)       |
| Activation (LeakyReLU) | 0          | (512,)       |
| BatchNormalization     | 1024       | (512,)       |
| Dense                  | 525312     | (1024,)      |
| Activation (LeakyReLU) | 0          | (1024,)      |
| BatchNormalization     | 2048       | (1024,)      |
| Dense                  | 803600     | (784,)       |
| Activation (TanH)      | 0          | (784,)       |
+------------------------+------------+--------------+
Total Parameters: 1489936

+---------------+
| Discriminator |
+---------------+
Input Shape: (784,)
+------------------------+------------+--------------+
| Layer Type             | Parameters | Output Shape |
+------------------------+------------+--------------+
| Dense                  | 401920     | (512,)       |
| Activation (LeakyReLU) | 0          | (512,)       |
| Dropout                | 0          | (512,)       |
| Dense                  | 131328     | (256,)       |
| Activation (LeakyReLU) | 0          | (256,)       |
| Dropout                | 0          | (256,)       |
| Dense                  | 514        | (2,)         |
| Activation (Softmax)   | 0          | (2,)         |
+------------------------+------------+--------------+
Total Parameters: 533762
&lt;/code&gt;&lt;/pre&gt; 
&lt;p align="center"&gt; &lt;img src="http://eriklindernoren.se/images/gan_mnist5.gif" width="640" /&gt; &lt;/p&gt; 
&lt;p align="center"&gt; Figure: Training progress of a Generative Adversarial Network generating &lt;br /&gt; handwritten digits. &lt;/p&gt; 
&lt;h3&gt;Deep Reinforcement Learning&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;$ python mlfromscratch/examples/deep_q_network.py

+----------------+
| Deep Q-Network |
+----------------+
Input Shape: (4,)
+-------------------+------------+--------------+
| Layer Type        | Parameters | Output Shape |
+-------------------+------------+--------------+
| Dense             | 320        | (64,)        |
| Activation (ReLU) | 0          | (64,)        |
| Dense             | 130        | (2,)         |
+-------------------+------------+--------------+
Total Parameters: 450
&lt;/code&gt;&lt;/pre&gt; 
&lt;p align="center"&gt; &lt;img src="http://eriklindernoren.se/images/mlfs_dql1.gif" width="640" /&gt; &lt;/p&gt; 
&lt;p align="center"&gt; Figure: Deep Q-Network solution to the CartPole-v1 environment in OpenAI gym. &lt;/p&gt; 
&lt;h3&gt;Image Reconstruction With RBM&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;$ python mlfromscratch/examples/restricted_boltzmann_machine.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p align="center"&gt; &lt;img src="http://eriklindernoren.se/images/rbm_digits1.gif" width="640" /&gt; &lt;/p&gt; 
&lt;p align="center"&gt; Figure: Shows how the network gets better during training at reconstructing &lt;br /&gt; the digit 2 in the MNIST dataset. &lt;/p&gt; 
&lt;h3&gt;Evolutionary Evolved Neural Network&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;$ python mlfromscratch/examples/neuroevolution.py

+---------------+
| Model Summary |
+---------------+
Input Shape: (64,)
+----------------------+------------+--------------+
| Layer Type           | Parameters | Output Shape |
+----------------------+------------+--------------+
| Dense                | 1040       | (16,)        |
| Activation (ReLU)    | 0          | (16,)        |
| Dense                | 170        | (10,)        |
| Activation (Softmax) | 0          | (10,)        |
+----------------------+------------+--------------+
Total Parameters: 1210

Population Size: 100
Generations: 3000
Mutation Rate: 0.01

[0 Best Individual - Fitness: 3.08301, Accuracy: 10.5%]
[1 Best Individual - Fitness: 3.08746, Accuracy: 12.0%]
...
[2999 Best Individual - Fitness: 94.08513, Accuracy: 98.5%]
Test set accuracy: 96.7%
&lt;/code&gt;&lt;/pre&gt; 
&lt;p align="center"&gt; &lt;img src="http://eriklindernoren.se/images/evo_nn4.png" width="640" /&gt; &lt;/p&gt; 
&lt;p align="center"&gt; Figure: Classification of the digit dataset by a neural network which has&lt;br /&gt; been evolutionary evolved. &lt;/p&gt; 
&lt;h3&gt;Genetic Algorithm&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;$ python mlfromscratch/examples/genetic_algorithm.py

+--------+
|   GA   |
+--------+
Description: Implementation of a Genetic Algorithm which aims to produce
the user specified target string. This implementation calculates each
candidate's fitness based on the alphabetical distance between the candidate
and the target. A candidate is selected as a parent with probabilities proportional
to the candidate's fitness. Reproduction is implemented as a single-point
crossover between pairs of parents. Mutation is done by randomly assigning
new characters with uniform probability.

Parameters
----------
Target String: 'Genetic Algorithm'
Population Size: 100
Mutation Rate: 0.05

[0 Closest Candidate: 'CJqlJguPlqzvpoJmb', Fitness: 0.00]
[1 Closest Candidate: 'MCxZxdr nlfiwwGEk', Fitness: 0.01]
[2 Closest Candidate: 'MCxZxdm nlfiwwGcx', Fitness: 0.01]
[3 Closest Candidate: 'SmdsAklMHn kBIwKn', Fitness: 0.01]
[4 Closest Candidate: '  lotneaJOasWfu Z', Fitness: 0.01]
...
[292 Closest Candidate: 'GeneticaAlgorithm', Fitness: 1.00]
[293 Closest Candidate: 'GeneticaAlgorithm', Fitness: 1.00]
[294 Answer: 'Genetic Algorithm']
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Association Analysis&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;$ python mlfromscratch/examples/apriori.py
+-------------+
|   Apriori   |
+-------------+
Minimum Support: 0.25
Minimum Confidence: 0.8
Transactions:
    [1, 2, 3, 4]
    [1, 2, 4]
    [1, 2]
    [2, 3, 4]
    [2, 3]
    [3, 4]
    [2, 4]
Frequent Itemsets:
    [1, 2, 3, 4, [1, 2], [1, 4], [2, 3], [2, 4], [3, 4], [1, 2, 4], [2, 3, 4]]
Rules:
    1 -&amp;gt; 2 (support: 0.43, confidence: 1.0)
    4 -&amp;gt; 2 (support: 0.57, confidence: 0.8)
    [1, 4] -&amp;gt; 2 (support: 0.29, confidence: 1.0)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Implementations&lt;/h2&gt; 
&lt;h3&gt;Supervised Learning&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/eriklindernoren/ML-From-Scratch/master/mlfromscratch/supervised_learning/adaboost.py"&gt;Adaboost&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/eriklindernoren/ML-From-Scratch/master/mlfromscratch/supervised_learning/bayesian_regression.py"&gt;Bayesian Regression&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/eriklindernoren/ML-From-Scratch/master/mlfromscratch/supervised_learning/decision_tree.py"&gt;Decision Tree&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/eriklindernoren/ML-From-Scratch/master/mlfromscratch/supervised_learning/regression.py"&gt;Elastic Net&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/eriklindernoren/ML-From-Scratch/master/mlfromscratch/supervised_learning/gradient_boosting.py"&gt;Gradient Boosting&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/eriklindernoren/ML-From-Scratch/master/mlfromscratch/supervised_learning/k_nearest_neighbors.py"&gt;K Nearest Neighbors&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/eriklindernoren/ML-From-Scratch/master/mlfromscratch/supervised_learning/regression.py"&gt;Lasso Regression&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/eriklindernoren/ML-From-Scratch/master/mlfromscratch/supervised_learning/linear_discriminant_analysis.py"&gt;Linear Discriminant Analysis&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/eriklindernoren/ML-From-Scratch/master/mlfromscratch/supervised_learning/regression.py"&gt;Linear Regression&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/eriklindernoren/ML-From-Scratch/master/mlfromscratch/supervised_learning/logistic_regression.py"&gt;Logistic Regression&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/eriklindernoren/ML-From-Scratch/master/mlfromscratch/supervised_learning/multi_class_lda.py"&gt;Multi-class Linear Discriminant Analysis&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/eriklindernoren/ML-From-Scratch/master/mlfromscratch/supervised_learning/multilayer_perceptron.py"&gt;Multilayer Perceptron&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/eriklindernoren/ML-From-Scratch/master/mlfromscratch/supervised_learning/naive_bayes.py"&gt;Naive Bayes&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/eriklindernoren/ML-From-Scratch/master/mlfromscratch/supervised_learning/neuroevolution.py"&gt;Neuroevolution&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/eriklindernoren/ML-From-Scratch/master/mlfromscratch/supervised_learning/particle_swarm_optimization.py"&gt;Particle Swarm Optimization of Neural Network&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/eriklindernoren/ML-From-Scratch/master/mlfromscratch/supervised_learning/perceptron.py"&gt;Perceptron&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/eriklindernoren/ML-From-Scratch/master/mlfromscratch/supervised_learning/regression.py"&gt;Polynomial Regression&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/eriklindernoren/ML-From-Scratch/master/mlfromscratch/supervised_learning/random_forest.py"&gt;Random Forest&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/eriklindernoren/ML-From-Scratch/master/mlfromscratch/supervised_learning/regression.py"&gt;Ridge Regression&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/eriklindernoren/ML-From-Scratch/master/mlfromscratch/supervised_learning/support_vector_machine.py"&gt;Support Vector Machine&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/eriklindernoren/ML-From-Scratch/master/mlfromscratch/supervised_learning/xgboost.py"&gt;XGBoost&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Unsupervised Learning&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/eriklindernoren/ML-From-Scratch/master/mlfromscratch/unsupervised_learning/apriori.py"&gt;Apriori&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/eriklindernoren/ML-From-Scratch/master/mlfromscratch/unsupervised_learning/autoencoder.py"&gt;Autoencoder&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/eriklindernoren/ML-From-Scratch/master/mlfromscratch/unsupervised_learning/dbscan.py"&gt;DBSCAN&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/eriklindernoren/ML-From-Scratch/master/mlfromscratch/unsupervised_learning/fp_growth.py"&gt;FP-Growth&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/eriklindernoren/ML-From-Scratch/master/mlfromscratch/unsupervised_learning/gaussian_mixture_model.py"&gt;Gaussian Mixture Model&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/eriklindernoren/ML-From-Scratch/master/mlfromscratch/unsupervised_learning/generative_adversarial_network.py"&gt;Generative Adversarial Network&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/eriklindernoren/ML-From-Scratch/master/mlfromscratch/unsupervised_learning/genetic_algorithm.py"&gt;Genetic Algorithm&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/eriklindernoren/ML-From-Scratch/master/mlfromscratch/unsupervised_learning/k_means.py"&gt;K-Means&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/eriklindernoren/ML-From-Scratch/master/mlfromscratch/unsupervised_learning/partitioning_around_medoids.py"&gt;Partitioning Around Medoids&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/eriklindernoren/ML-From-Scratch/master/mlfromscratch/unsupervised_learning/principal_component_analysis.py"&gt;Principal Component Analysis&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/eriklindernoren/ML-From-Scratch/master/mlfromscratch/unsupervised_learning/restricted_boltzmann_machine.py"&gt;Restricted Boltzmann Machine&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Reinforcement Learning&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/eriklindernoren/ML-From-Scratch/master/mlfromscratch/reinforcement_learning/deep_q_network.py"&gt;Deep Q-Network&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Deep Learning&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/eriklindernoren/ML-From-Scratch/master/mlfromscratch/deep_learning/neural_network.py"&gt;Neural Network&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/eriklindernoren/ML-From-Scratch/master/mlfromscratch/deep_learning/layers.py"&gt;Layers&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Activation Layer&lt;/li&gt; 
   &lt;li&gt;Average Pooling Layer&lt;/li&gt; 
   &lt;li&gt;Batch Normalization Layer&lt;/li&gt; 
   &lt;li&gt;Constant Padding Layer&lt;/li&gt; 
   &lt;li&gt;Convolutional Layer&lt;/li&gt; 
   &lt;li&gt;Dropout Layer&lt;/li&gt; 
   &lt;li&gt;Flatten Layer&lt;/li&gt; 
   &lt;li&gt;Fully-Connected (Dense) Layer&lt;/li&gt; 
   &lt;li&gt;Fully-Connected RNN Layer&lt;/li&gt; 
   &lt;li&gt;Max Pooling Layer&lt;/li&gt; 
   &lt;li&gt;Reshape Layer&lt;/li&gt; 
   &lt;li&gt;Up Sampling Layer&lt;/li&gt; 
   &lt;li&gt;Zero Padding Layer&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Model Types 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/eriklindernoren/ML-From-Scratch/master/mlfromscratch/examples/convolutional_neural_network.py"&gt;Convolutional Neural Network&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/eriklindernoren/ML-From-Scratch/master/mlfromscratch/examples/multilayer_perceptron.py"&gt;Multilayer Perceptron&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/eriklindernoren/ML-From-Scratch/master/mlfromscratch/examples/recurrent_neural_network.py"&gt;Recurrent Neural Network&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contact&lt;/h2&gt; 
&lt;p&gt;If there's some implementation you would like to see here or if you're just feeling social, feel free to &lt;a href="mailto:eriklindernoren@gmail.com"&gt;email&lt;/a&gt; me or connect with me on &lt;a href="https://www.linkedin.com/in/eriklindernoren/"&gt;LinkedIn&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>oraios/serena</title>
      <link>https://github.com/oraios/serena</link>
      <description>&lt;p&gt;A powerful coding agent toolkit providing semantic retrieval and editing capabilities (MCP server &amp; other integrations)&lt;/p&gt;&lt;hr&gt;&lt;p align="center" style="text-align:center"&gt; &lt;img src="https://raw.githubusercontent.com/oraios/serena/main/resources/serena-logo.svg#gh-light-mode-only" style="width:500px" /&gt; &lt;img src="https://raw.githubusercontent.com/oraios/serena/main/resources/serena-logo-dark-mode.svg#gh-dark-mode-only" style="width:500px" /&gt; &lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span&gt;üöÄ&lt;/span&gt; Serena is a powerful &lt;strong&gt;coding agent toolkit&lt;/strong&gt; capable of turning an LLM into a fully-featured agent that works &lt;strong&gt;directly on your codebase&lt;/strong&gt;. Unlike most other tools, it is not tied to an LLM, framework or an interface, making it easy to use it in a variety of ways.&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üîß&lt;/span&gt; Serena provides essential &lt;strong&gt;semantic code retrieval and editing tools&lt;/strong&gt; that are akin to an IDE's capabilities, extracting code entities at the symbol level and exploiting relational structure. When combined with an existing coding agent, these tools greatly enhance (token) efficiency.&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üÜì&lt;/span&gt; Serena is &lt;strong&gt;free &amp;amp; open-source&lt;/strong&gt;, enhancing the capabilities of LLMs you already have access to free of charge.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;You can think of Serena as providing IDE-like tools to your LLM/coding agent. With it, the agent no longer needs to read entire files, perform grep-like searches or string replacements to find and edit the right code. Instead, it can use code centered tools like &lt;code&gt;find_symbol&lt;/code&gt;, &lt;code&gt;find_referencing_symbols&lt;/code&gt; and &lt;code&gt;insert_after_symbol&lt;/code&gt;.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;em&gt;Serena is under active development! See the latest updates, upcoming features, and lessons learned to stay up to date.&lt;/em&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://raw.githubusercontent.com/oraios/serena/main/CHANGELOG.md"&gt; &lt;img src="https://img.shields.io/badge/Updates-1e293b?style=flat&amp;amp;logo=rss&amp;amp;logoColor=white&amp;amp;labelColor=1e293b" alt="Changelog" /&gt; &lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/oraios/serena/main/roadmap.md"&gt; &lt;img src="https://img.shields.io/badge/Roadmap-14532d?style=flat&amp;amp;logo=target&amp;amp;logoColor=white&amp;amp;labelColor=14532d" alt="Roadmap" /&gt; &lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/oraios/serena/main/lessons_learned.md"&gt; &lt;img src="https://img.shields.io/badge/Lessons-Learned-7c4700?style=flat&amp;amp;logo=readthedocs&amp;amp;logoColor=white&amp;amp;labelColor=7c4700" alt="Lessons Learned" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;h3&gt;LLM Integration&lt;/h3&gt; 
&lt;p&gt;Serena provides the necessary &lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#list-of-tools"&gt;tools&lt;/a&gt; for coding workflows, but an LLM is required to do the actual work, orchestrating tool use.&lt;/p&gt; 
&lt;p&gt;For example, &lt;strong&gt;supercharge the performance of Claude Code&lt;/strong&gt; with a &lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#claude-code"&gt;one-line shell command&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;In general, Serena can be integrated with an LLM in several ways:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;by using the &lt;strong&gt;model context protocol (MCP)&lt;/strong&gt;. Serena provides an MCP server which integrates with 
  &lt;ul&gt; 
   &lt;li&gt;Claude Code and Claude Desktop,&lt;/li&gt; 
   &lt;li&gt;Terminal-based clients like Codex, Gemini-CLI, Qwen3-Coder, rovodev, OpenHands CLI and others,&lt;/li&gt; 
   &lt;li&gt;IDEs like VSCode, Cursor or IntelliJ,&lt;/li&gt; 
   &lt;li&gt;Extensions like Cline or Roo Code&lt;/li&gt; 
   &lt;li&gt;Local clients like &lt;a href="https://docs.openwebui.com/openapi-servers/mcp"&gt;OpenWebUI&lt;/a&gt;, &lt;a href="https://jan.ai/docs/mcp-examples/browser/browserbase#enable-mcp"&gt;Jan&lt;/a&gt;, &lt;a href="https://docs.agno.com/introduction/playground"&gt;Agno&lt;/a&gt; and others&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;by using &lt;a href="https://raw.githubusercontent.com/oraios/serena/main/docs/serena_on_chatgpt.md"&gt;mcpo to connect it to ChatGPT&lt;/a&gt; or other clients that don't support MCP but do support tool calling via OpenAPI.&lt;/li&gt; 
 &lt;li&gt;by incorporating Serena's tools into an agent framework of your choice, as illustrated &lt;a href="https://raw.githubusercontent.com/oraios/serena/main/docs/custom_agent.md"&gt;here&lt;/a&gt;. Serena's tool implementation is decoupled from the framework-specific code and can thus easily be adapted to any agent framework.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Serena in Action&lt;/h3&gt; 
&lt;h4&gt;Demonstration 1: Efficient Operation in Claude Code&lt;/h4&gt; 
&lt;p&gt;A demonstration of Serena efficiently retrieving and editing code within Claude Code, thereby saving tokens and time. Efficient operations are not only useful for saving costs, but also for generally improving the generated code's quality. This effect may be less pronounced in very small projects, but often becomes of crucial importance in larger ones.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/ab78ebe0-f77d-43cc-879a-cc399efefd87"&gt;https://github.com/user-attachments/assets/ab78ebe0-f77d-43cc-879a-cc399efefd87&lt;/a&gt;&lt;/p&gt; 
&lt;h4&gt;Demonstration 2: Serena in Claude Desktop&lt;/h4&gt; 
&lt;p&gt;A demonstration of Serena implementing a small feature for itself (a better log GUI) with Claude Desktop. Note how Serena's tools enable Claude to find and edit the right symbols.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/6eaa9aa1-610d-4723-a2d6-bf1e487ba753"&gt;https://github.com/user-attachments/assets/6eaa9aa1-610d-4723-a2d6-bf1e487ba753&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Programming Language Support &amp;amp; Semantic Analysis Capabilities&lt;/h3&gt; 
&lt;p&gt;Serena's semantic code analysis capabilities build on &lt;strong&gt;language servers&lt;/strong&gt; using the widely implemented language server protocol (LSP). The LSP provides a set of versatile code querying and editing functionalities based on symbolic understanding of the code. Equipped with these capabilities, Serena discovers and edits code just like a seasoned developer making use of an IDE's capabilities would. Serena can efficiently find the right context and do the right thing even in very large and complex projects! So not only is it free and open-source, it frequently achieves better results than existing solutions that charge a premium.&lt;/p&gt; 
&lt;p&gt;Language servers provide support for a wide range of programming languages. With Serena, we provide direct, out-of-the-box support for:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Python&lt;/li&gt; 
 &lt;li&gt;TypeScript/Javascript&lt;/li&gt; 
 &lt;li&gt;PHP (uses Intelephense LSP; set &lt;code&gt;INTELEPHENSE_LICENSE_KEY&lt;/code&gt; environment variable for premium features)&lt;/li&gt; 
 &lt;li&gt;Go (requires installation of gopls)&lt;/li&gt; 
 &lt;li&gt;R (requires installation of the &lt;code&gt;languageserver&lt;/code&gt; R package)&lt;/li&gt; 
 &lt;li&gt;Rust (requires &lt;a href="https://rustup.rs/"&gt;rustup&lt;/a&gt; - uses rust-analyzer from your toolchain)&lt;/li&gt; 
 &lt;li&gt;C/C++ (you may experience issues with finding references, we are working on it)&lt;/li&gt; 
 &lt;li&gt;Zig (requires installation of ZLS - Zig Language Server)&lt;/li&gt; 
 &lt;li&gt;C#&lt;/li&gt; 
 &lt;li&gt;Ruby (by default, uses &lt;a href="https://github.com/Shopify/ruby-lsp"&gt;ruby-lsp&lt;/a&gt;, specify ruby_solargraph as your language to use the previous solargraph based implementation)&lt;/li&gt; 
 &lt;li&gt;Swift&lt;/li&gt; 
 &lt;li&gt;Kotlin (uses the pre-alpha &lt;a href="https://github.com/Kotlin/kotlin-lsp"&gt;official kotlin LS&lt;/a&gt;, some issues may appear)&lt;/li&gt; 
 &lt;li&gt;Java (&lt;em&gt;Note&lt;/em&gt;: startup is slow, initial startup especially so. There may be issues with java on macos and linux, we are working on it.)&lt;/li&gt; 
 &lt;li&gt;Clojure&lt;/li&gt; 
 &lt;li&gt;Dart&lt;/li&gt; 
 &lt;li&gt;Bash&lt;/li&gt; 
 &lt;li&gt;Lua (automatically downloads lua-language-server if not installed)&lt;/li&gt; 
 &lt;li&gt;Nix (requires nixd installation)&lt;/li&gt; 
 &lt;li&gt;Elixir (requires installation of NextLS and Elixir; &lt;strong&gt;Windows not supported&lt;/strong&gt;)&lt;/li&gt; 
 &lt;li&gt;Erlang (requires installation of beam and &lt;a href="https://github.com/erlang-ls/erlang_ls"&gt;erlang_ls&lt;/a&gt;, experimental, might be slow or hang)&lt;/li&gt; 
 &lt;li&gt;AL&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Support for further languages can easily be added by providing a shallow adapter for a new language server implementation, see Serena's &lt;a href="https://raw.githubusercontent.com/oraios/serena/main/.serena/memories/adding_new_language_support_guide.md"&gt;memory on that&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Community Feedback&lt;/h3&gt; 
&lt;p&gt;Most users report that Serena has strong positive effects on the results of their coding agents, even when used within very capable agents like Claude Code. Serena is often described to be a &lt;a href="https://www.reddit.com/r/ClaudeAI/comments/1lfsdll/try_out_serena_mcp_thank_me_later/"&gt;game changer&lt;/a&gt;, providing an enormous &lt;a href="https://www.reddit.com/r/ClaudeCode/comments/1mguoia/absolutely_insane_improvement_of_claude_code"&gt;productivity boost&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Serena excels at navigating and manipulating complex codebases, providing tools that support precise code retrieval and editing in the presence of large, strongly structured codebases. However, when dealing with tasks that involve only very few/small files, you may not benefit from including Serena on top of your existing coding agent. In particular, when writing code from scratch, Serena will not provide much value initially, as the more complex structures that Serena handles more gracefully than simplistic, file-based approaches are yet to be created.&lt;/p&gt; 
&lt;p&gt;Several videos and blog posts have talked about Serena:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;YouTube:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=wYWyJNs1HVk&amp;amp;t=1s"&gt;AI Labs&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=UqfxuQKuMo8&amp;amp;t=45s"&gt;Yo Van Eyck&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=fzPnM3ySmjE&amp;amp;t=32s"&gt;JeredBlu&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Blog posts:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://medium.com/@souradip1000/deconstructing-serenas-mcp-powered-semantic-code-understanding-architecture-75802515d116"&gt;Serena's Design Principles&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://blog.lai.so/serena/"&gt;Serena with Claude Code (in Japanese)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://robertmarshall.dev/blog/turning-claude-code-into-a-development-powerhouse/"&gt;Turning Claude Code into a Development Powerhouse&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Table of Contents&lt;/h2&gt; 
&lt;!-- Created with markdown-toc -i README.md --&gt; 
&lt;!-- Install it with npm install -g markdown-toc --&gt; 
&lt;!-- toc --&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#quick-start"&gt;Quick Start&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#running-the-serena-mcp-server"&gt;Running the Serena MCP Server&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#usage"&gt;Usage&lt;/a&gt; 
      &lt;ul&gt; 
       &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#using-uvx"&gt;Using uvx&lt;/a&gt; 
        &lt;ul&gt; 
         &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#local-installation"&gt;Local Installation&lt;/a&gt;&lt;/li&gt; 
        &lt;/ul&gt; &lt;/li&gt; 
       &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#using-docker-experimental"&gt;Using Docker (Experimental)&lt;/a&gt;&lt;/li&gt; 
      &lt;/ul&gt; &lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#sse-mode"&gt;SSE Mode&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#command-line-arguments"&gt;Command-Line Arguments&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#configuration"&gt;Configuration&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#project-activation--indexing"&gt;Project Activation &amp;amp; Indexing&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#claude-code"&gt;Claude Code&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#codex"&gt;Codex&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#other-terminal-based-clients"&gt;Other Terminal-Based Clients&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#claude-desktop"&gt;Claude Desktop&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#mcp-coding-clients-cline-roo-code-cursor-windsurf-etc"&gt;MCP Coding Clients (Cline, Roo-Code, Cursor, Windsurf, etc.)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#local-guis-and-frameworks"&gt;Local GUIs and Frameworks&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#detailed-usage-and-recommendations"&gt;Detailed Usage and Recommendations&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#tool-execution"&gt;Tool Execution&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#shell-execution-and-editing-tools"&gt;Shell Execution and Editing Tools&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#modes-and-contexts"&gt;Modes and Contexts&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#contexts"&gt;Contexts&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#modes"&gt;Modes&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#customization"&gt;Customization&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#onboarding-and-memories"&gt;Onboarding and Memories&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#prepare-your-project"&gt;Prepare Your Project&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#structure-your-codebase"&gt;Structure Your Codebase&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#start-from-a-clean-state"&gt;Start from a Clean State&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#logging-linting-and-automated-tests"&gt;Logging, Linting, and Automated Tests&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#prompting-strategies"&gt;Prompting Strategies&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#potential-issues-in-code-editing"&gt;Potential Issues in Code Editing&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#running-out-of-context"&gt;Running Out of Context&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#combining-serena-with-other-mcp-servers"&gt;Combining Serena with Other MCP Servers&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#serenas-logs-the-dashboard-and-gui-tool"&gt;Serena's Logs: The Dashboard and GUI Tool&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#troubleshooting"&gt;Troubleshooting&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#comparison-with-other-coding-agents"&gt;Comparison with Other Coding Agents&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#subscription-based-coding-agents"&gt;Subscription-Based Coding Agents&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#api-based-coding-agents"&gt;API-Based Coding Agents&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#other-mcp-based-coding-agents"&gt;Other MCP-Based Coding Agents&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#acknowledgements"&gt;Acknowledgements&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#customizing-and-extending-serena"&gt;Customizing and Extending Serena&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#list-of-tools"&gt;List of Tools&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;!-- tocstop --&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;p&gt;Serena can be used in various ways, below you will find instructions for selected integrations.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;For coding with Claude, we recommend using Serena through &lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#claude-code"&gt;Claude Code&lt;/a&gt; or &lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#claude-desktop"&gt;Claude Desktop&lt;/a&gt;. You can also use Serena in most other &lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#other-terminal-based-clients"&gt;terminal-based clients&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;If you want a GUI experience outside an IDE, you can use one of the many &lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#local-guis-and-frameworks"&gt;local GUIs&lt;/a&gt; that support MCP servers. You can also connect Serena to many web clients (including ChatGPT) using &lt;a href="https://raw.githubusercontent.com/oraios/serena/main/docs/serena_on_chatgpt.md"&gt;mcpo&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;If you want to use Serena integrated in your IDE, see the section on &lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#other-mcp-clients---cline-roo-code-cursor-windsurf-etc"&gt;other MCP clients&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;You can use Serena as a library for building your own applications. We try to keep the public API stable, but you should still expect breaking changes and pin Serena to a fixed version if you use it as a dependency.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Serena is managed by &lt;code&gt;uv&lt;/code&gt;, so you will need to &lt;a href="https://docs.astral.sh/uv/getting-started/installation/"&gt;install it&lt;/a&gt;).&lt;/p&gt; 
&lt;h3&gt;Running the Serena MCP Server&lt;/h3&gt; 
&lt;p&gt;You have several options for running the MCP server, which are explained in the subsections below.&lt;/p&gt; 
&lt;h4&gt;Usage&lt;/h4&gt; 
&lt;p&gt;The typical usage involves the client (Claude Code, Claude Desktop, etc.) running the MCP server as a subprocess (using stdio communication), so the client needs to be provided with the command to run the MCP server. (Alternatively, you can run the MCP server in SSE mode and tell your client how to connect to it.)&lt;/p&gt; 
&lt;p&gt;Note that no matter how you run the MCP server, Serena will, by default, start a small web-based dashboard on localhost that will display logs and allow shutting down the MCP server (since many clients fail to clean up processes correctly). This and other settings can be adjusted in the &lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#configuration"&gt;configuration&lt;/a&gt; and/or by providing &lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#command-line-arguments"&gt;command-line arguments&lt;/a&gt;.&lt;/p&gt; 
&lt;h5&gt;Using uvx&lt;/h5&gt; 
&lt;p&gt;&lt;code&gt;uvx&lt;/code&gt; can be used to run the latest version of Serena directly from the repository, without an explicit local installation.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;uvx --from git+https://github.com/oraios/serena serena start-mcp-server
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Explore the CLI to see some of the customization options that serena provides (more info on them below).&lt;/p&gt; 
&lt;h6&gt;Local Installation&lt;/h6&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Clone the repository and change into it.&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;git clone https://github.com/oraios/serena
cd serena
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Optionally edit the configuration file in your home directory with&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;uv run serena config edit
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;If you just want the default config, you can skip this part, and a config file will be created when you first run Serena.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Run the server with &lt;code&gt;uv&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;uv run serena start-mcp-server
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;When running from outside the serena installation directory, be sure to pass it, i.e., use&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt; uv run --directory /abs/path/to/serena serena start-mcp-server
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h5&gt;Using Docker (Experimental)&lt;/h5&gt; 
&lt;p&gt;‚ö†Ô∏è Docker support is currently experimental with several limitations. Please read the &lt;a href="https://raw.githubusercontent.com/oraios/serena/main/DOCKER.md"&gt;Docker documentation&lt;/a&gt; for important caveats before using it.&lt;/p&gt; 
&lt;p&gt;You can run the Serena MCP server directly via docker as follows, assuming that the projects you want to work on are all located in &lt;code&gt;/path/to/your/projects&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;docker run --rm -i --network host -v /path/to/your/projects:/workspaces/projects ghcr.io/oraios/serena:latest serena start-mcp-server --transport stdio
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Replace &lt;code&gt;/path/to/your/projects&lt;/code&gt; with the absolute path to your projects directory. The Docker approach provides:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Better security isolation for shell command execution&lt;/li&gt; 
 &lt;li&gt;No need to install language servers and dependencies locally&lt;/li&gt; 
 &lt;li&gt;Consistent environment across different systems&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Alternatively, use docker compose with the &lt;code&gt;compose.yml&lt;/code&gt; file provided in the repository.&lt;/p&gt; 
&lt;p&gt;See the &lt;a href="https://raw.githubusercontent.com/oraios/serena/main/DOCKER.md"&gt;Docker documentation&lt;/a&gt; for detailed setup instructions, configuration options, and known limitations.&lt;/p&gt; 
&lt;h5&gt;Using Nix&lt;/h5&gt; 
&lt;p&gt;If you are using Nix and &lt;a href="https://nixos.wiki/wiki/flakes"&gt;have enabled the &lt;code&gt;nix-command&lt;/code&gt; and &lt;code&gt;flakes&lt;/code&gt; features&lt;/a&gt;, you can run Serena using the following command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;nix run github:oraios/serena -- start-mcp-server --transport stdio
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can also install Serena by referencing this repo (&lt;code&gt;github:oraios/serena&lt;/code&gt;) and using it in your Nix flake. The package is exported as &lt;code&gt;serena&lt;/code&gt;.&lt;/p&gt; 
&lt;h4&gt;SSE Mode&lt;/h4&gt; 
&lt;p&gt;‚ÑπÔ∏è Note that MCP servers which use stdio as a protocol are somewhat unusual as far as client/server architectures go, as the server necessarily has to be started by the client in order for communication to take place via the server's standard input/output stream. In other words, you do not need to start the server yourself. The client application (e.g. Claude Desktop) takes care of this and therefore needs to be configured with a launch command.&lt;/p&gt; 
&lt;p&gt;When using instead the SSE mode, which uses HTTP-based communication, you control the server lifecycle yourself, i.e. you start the server and provide the client with the URL to connect to it.&lt;/p&gt; 
&lt;p&gt;Simply provide &lt;code&gt;start-mcp-server&lt;/code&gt; with the &lt;code&gt;--transport sse&lt;/code&gt; option and optionally provide the port. For example, to run the Serena MCP server in SSE mode on port 9121 using a local installation, you would run this command from the Serena directory,&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;uv run serena start-mcp-server --transport sse --port 9121
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;and then configure your client to connect to &lt;code&gt;http://localhost:9121/sse&lt;/code&gt;.&lt;/p&gt; 
&lt;h4&gt;Command-Line Arguments&lt;/h4&gt; 
&lt;p&gt;The Serena MCP server supports a wide range of additional command-line options, including the option to run in SSE mode and to adapt Serena to various &lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#modes-and-contexts"&gt;contexts and modes of operation&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Run with parameter &lt;code&gt;--help&lt;/code&gt; to get a list of available options.&lt;/p&gt; 
&lt;h3&gt;Configuration&lt;/h3&gt; 
&lt;p&gt;Serena is very flexible in terms of configuration. While for most users, the default configurations will work, you can fully adjust it to your needs by editing a few yaml files. You can disable tools, change Serena's instructions (what we denote as the &lt;code&gt;system_prompt&lt;/code&gt;), adjust the output of tools that just provide a prompt, and even adjust tool descriptions.&lt;/p&gt; 
&lt;p&gt;Serena is configured in four places:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;The &lt;code&gt;serena_config.yml&lt;/code&gt; for general settings that apply to all clients and projects. It is located in your user directory under &lt;code&gt;.serena/serena_config.yml&lt;/code&gt;. If you do not explicitly create the file, it will be auto-generated when you first run Serena. You can edit it directly or use&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;uvx --from git+https://github.com/oraios/serena serena config edit
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;(or use the &lt;code&gt;--directory&lt;/code&gt; command version).&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;In the arguments passed to the &lt;code&gt;start-mcp-server&lt;/code&gt; in your client's config (see below), which will apply to all sessions started by the respective client. In particular, the &lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#contexts"&gt;context&lt;/a&gt; parameter should be set appropriately for Serena to be best adjusted to existing tools and capabilities of your client. See for a detailed explanation. You can override all entries from the &lt;code&gt;serena_config.yml&lt;/code&gt; through command line arguments.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;In the &lt;code&gt;.serena/project.yml&lt;/code&gt; file within your project. This will hold project-level configuration that is used whenever that project is activated. This file will be autogenerated when you first use Serena on that project, but you can also generate it explicitly with&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;uvx --from git+https://github.com/oraios/serena serena project generate-yml
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;(or use the &lt;code&gt;--directory&lt;/code&gt; command version).&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Through the context and modes. Explore the &lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#modes-and-contexts"&gt;modes and contexts&lt;/a&gt; section for more details.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;After the initial setup, continue with one of the sections below, depending on how you want to use Serena.&lt;/p&gt; 
&lt;h3&gt;Project Activation &amp;amp; Indexing&lt;/h3&gt; 
&lt;p&gt;If you are mostly working with the same project, you can configure to always activate it at startup by passing &lt;code&gt;--project &amp;lt;path_or_name&amp;gt;&lt;/code&gt; to the &lt;code&gt;start-mcp-server&lt;/code&gt; command in your client's MCP config. This is especially useful for clients which configure MCP servers on a per-project basis, like Claude Code.&lt;/p&gt; 
&lt;p&gt;Otherwise, the recommended way is to just ask the LLM to activate a project by providing it an absolute path to, or, in case the project was activated in the past, by its name. The default project name is the directory name.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;"Activate the project /path/to/my_project"&lt;/li&gt; 
 &lt;li&gt;"Activate the project my_project"&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;All projects that have been activated will be automatically added to your &lt;code&gt;serena_config.yml&lt;/code&gt;, and for each project, the file &lt;code&gt;.serena/project.yml&lt;/code&gt; will be generated. You can adjust the latter, e.g., by changing the name (which you refer to during the activation) or other options. Make sure to not have two different projects with the same name.&lt;/p&gt; 
&lt;p&gt;‚ÑπÔ∏è For larger projects, we recommend that you index your project to accelerate Serena's tools; otherwise the first tool application may be very slow. To do so, run this from the project directory (or pass the path to the project as an argument):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;uvx --from git+https://github.com/oraios/serena serena project index
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;(or use the &lt;code&gt;--directory&lt;/code&gt; command version).&lt;/p&gt; 
&lt;h3&gt;Claude Code&lt;/h3&gt; 
&lt;p&gt;Serena is a great way to make Claude Code both cheaper and more powerful!&lt;/p&gt; 
&lt;p&gt;From your project directory, add serena with a command like this,&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;claude mcp add serena -- &amp;lt;serena-mcp-server&amp;gt; --context ide-assistant --project $(pwd)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;where &lt;code&gt;&amp;lt;serena-mcp-server&amp;gt;&lt;/code&gt; is your way of &lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#running-the-serena-mcp-server"&gt;running the Serena MCP server&lt;/a&gt;. For example, when using &lt;code&gt;uvx&lt;/code&gt;, you would run&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;claude mcp add serena -- uvx --from git+https://github.com/oraios/serena serena start-mcp-server --context ide-assistant --project $(pwd)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;‚ÑπÔ∏è Serena comes with an instruction text, and Claude needs to read it to properly use Serena's tools. As of version &lt;code&gt;v1.0.52&lt;/code&gt;, claude code reads the instructions of the MCP server, so this &lt;strong&gt;is handled automatically&lt;/strong&gt;. If you are using an older version, or if Claude fails to read the instructions, you can ask it explicitly to "read Serena's initial instructions" or run &lt;code&gt;/mcp__serena__initial_instructions&lt;/code&gt; to load the instruction text. If you want to make use of that, you will have to enable the corresponding tool explicitly by adding &lt;code&gt;initial_instructions&lt;/code&gt; to the &lt;code&gt;included_optional_tools&lt;/code&gt; in your config. Note that you may have to make Claude read the instructions when you start a new conversation and after any compacting operation to ensure Claude remains properly configured to use Serena's tools.&lt;/p&gt; 
&lt;h3&gt;Codex&lt;/h3&gt; 
&lt;p&gt;Serena works with OpenAI's Codex CLI out of the box, but you have to use the &lt;code&gt;codex&lt;/code&gt; context for it to work properly. (The technical reason is that Codex doesn't fully support the MCP specifications, so some massaging of tools is required.).&lt;/p&gt; 
&lt;p&gt;Unlike Claude Code, in Codex you add an MCP server globally and not per project. Add the following to &lt;code&gt;~/.codex/config.toml&lt;/code&gt; (create the file if it does not exist):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;[mcp_servers.serena]
command = "uvx"
args = ["--from", "git+https://github.com/oraios/serena", "serena", "start-mcp-server", "--context", "codex"]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;After codex has started, you need to activate the project, which you can do by saying:&lt;/p&gt; 
&lt;p&gt;"Activate the current dir as project using serena"&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;If you don't activate the project, you will not be able to use Serena's tools!&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;That's it! Have a look at &lt;code&gt;~/.codex/log/codex-tui.log&lt;/code&gt; to see if any errors occurred.&lt;/p&gt; 
&lt;p&gt;The Serena dashboard will run if you have not disabled it in the configuration, but due to Codex's sandboxing the webbrowser may not open automatically. You can open it manually by going to &lt;code&gt;http://localhost:24282/dashboard/index.html&lt;/code&gt; (or a higher port, if that was already taken).&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Codex will often show the tools as &lt;code&gt;failed&lt;/code&gt; even though they are successfully executed. This is not a problem, seems to be a bug in Codex. Despite the error message, everything works as expected.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Other Terminal-Based Clients&lt;/h3&gt; 
&lt;p&gt;There are many terminal-based coding assistants that support MCP servers, such as &lt;a href="https://github.com/openai/codex?tab=readme-ov-file#model-context-protocol-mcp"&gt;Codex&lt;/a&gt;, &lt;a href="https://github.com/google-gemini/gemini-cli"&gt;Gemini-CLI&lt;/a&gt;, &lt;a href="https://github.com/QwenLM/Qwen3-Coder"&gt;Qwen3-Coder&lt;/a&gt;, &lt;a href="https://community.atlassian.com/forums/Rovo-for-Software-Teams-Beta/Introducing-Rovo-Dev-CLI-AI-Powered-Development-in-your-terminal/ba-p/3043623"&gt;rovodev&lt;/a&gt;, the &lt;a href="https://docs.all-hands.dev/usage/how-to/cli-mode"&gt;OpenHands CLI&lt;/a&gt; and &lt;a href="https://github.com/sst/opencode"&gt;opencode&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;They generally benefit from the symbolic tools provided by Serena. You might want to customize some aspects of Serena by writing your own context, modes or prompts to adjust it to your workflow, to other MCP servers you are using, and to the client's internal capabilities.&lt;/p&gt; 
&lt;h3&gt;Claude Desktop&lt;/h3&gt; 
&lt;p&gt;For &lt;a href="https://claude.ai/download"&gt;Claude Desktop&lt;/a&gt; (available for Windows and macOS), go to File / Settings / Developer / MCP Servers / Edit Config, which will let you open the JSON file &lt;code&gt;claude_desktop_config.json&lt;/code&gt;. Add the &lt;code&gt;serena&lt;/code&gt; MCP server configuration, using a &lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#running-the-serena-mcp-server"&gt;run command&lt;/a&gt; depending on your setup.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;local installation:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-json"&gt;{
    "mcpServers": {
        "serena": {
            "command": "/abs/path/to/uv",
            "args": ["run", "--directory", "/abs/path/to/serena", "serena", "start-mcp-server"]
        }
    }
}
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;uvx:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-json"&gt;{
    "mcpServers": {
        "serena": {
            "command": "/abs/path/to/uvx",
            "args": ["--from", "git+https://github.com/oraios/serena", "serena", "start-mcp-server"]
        }
    }
}
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;docker:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-json"&gt; {
     "mcpServers": {
         "serena": {
             "command": "docker",
             "args": ["run", "--rm", "-i", "--network", "host", "-v", "/path/to/your/projects:/workspaces/projects", "ghcr.io/oraios/serena:latest", "serena", "start-mcp-server", "--transport", "stdio"]
         }
     }
 }
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;If you are using paths containing backslashes for paths on Windows (note that you can also just use forward slashes), be sure to escape them correctly (&lt;code&gt;\\&lt;/code&gt;).&lt;/p&gt; 
&lt;p&gt;That's it! Save the config and then restart Claude Desktop. You are ready for activating your first project.&lt;/p&gt; 
&lt;p&gt;‚ÑπÔ∏è You can further customize the run command using additional arguments (see &lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#command-line-arguments"&gt;above&lt;/a&gt;).&lt;/p&gt; 
&lt;p&gt;Note: on Windows and macOS there are official Claude Desktop applications by Anthropic, for Linux there is an &lt;a href="https://github.com/aaddrick/claude-desktop-debian"&gt;open-source community version&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;‚ö†Ô∏è Be sure to fully quit the Claude Desktop application, as closing Claude will just minimize it to the system tray ‚Äì at least on Windows.&lt;/p&gt; 
&lt;p&gt;‚ö†Ô∏è Some clients may leave behind zombie processes. You will have to find and terminate them manually then. With Serena, you can activate the &lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#serenas-logs-the-dashboard-and-gui-tool"&gt;dashboard&lt;/a&gt; to prevent unnoted processes and also use the dashboard for shutting down Serena.&lt;/p&gt; 
&lt;p&gt;After restarting, you should see Serena's tools in your chat interface (notice the small hammer icon).&lt;/p&gt; 
&lt;p&gt;For more information on MCP servers with Claude Desktop, see &lt;a href="https://modelcontextprotocol.io/quickstart/user"&gt;the official quick start guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;MCP Coding Clients (Cline, Roo-Code, Cursor, Windsurf, etc.)&lt;/h3&gt; 
&lt;p&gt;Being an MCP Server, Serena can be included in any MCP Client. The same configuration as above, perhaps with small client-specific modifications, should work. Most of the popular existing coding assistants (IDE extensions or VSCode-like IDEs) support connections to MCP Servers. It is &lt;strong&gt;recommended to use the &lt;code&gt;ide-assistant&lt;/code&gt; context&lt;/strong&gt; for these integrations by adding &lt;code&gt;"--context", "ide-assistant"&lt;/code&gt; to the &lt;code&gt;args&lt;/code&gt; in your MCP client's configuration. Including Serena generally boosts their performance by providing them tools for symbolic operations.&lt;/p&gt; 
&lt;p&gt;In this case, the billing for the usage continues to be controlled by the client of your choice (unlike with the Claude Desktop client). But you may still want to use Serena through such an approach, e.g., for one of the following reasons:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;You are already using a coding assistant (say Cline or Cursor) and just want to make it more powerful.&lt;/li&gt; 
 &lt;li&gt;You are on Linux and don't want to use the &lt;a href="https://github.com/aaddrick/claude-desktop-debian"&gt;community-created Claude Desktop&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;You want tighter integration of Serena into your IDE and don't mind paying for that.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Local GUIs and Frameworks&lt;/h3&gt; 
&lt;p&gt;Over the last months, several technologies have emerged that allow you to run a powerful local GUI and connect it to an MCP server. They will work with Serena out of the box. Some of the leading open source GUI technologies offering this are &lt;a href="https://jan.ai/docs/mcp"&gt;Jan&lt;/a&gt;, &lt;a href="https://github.com/All-Hands-AI/OpenHands/"&gt;OpenHands&lt;/a&gt;, &lt;a href="https://docs.openwebui.com/openapi-servers/mcp"&gt;OpenWebUI&lt;/a&gt; and &lt;a href="https://docs.agno.com/introduction/playground"&gt;Agno&lt;/a&gt;. They allow combining Serena with almost any LLM (including locally running ones) and offer various other integrations.&lt;/p&gt; 
&lt;h2&gt;Detailed Usage and Recommendations&lt;/h2&gt; 
&lt;h3&gt;Tool Execution&lt;/h3&gt; 
&lt;p&gt;Serena combines tools for semantic code retrieval with editing capabilities and shell execution. Serena's behavior can be further customized through &lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#modes-and-contexts"&gt;Modes and Contexts&lt;/a&gt;. Find the complete list of tools &lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#full-list-of-tools"&gt;below&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;The use of all tools is generally recommended, as this allows Serena to provide the most value: Only by executing shell commands (in particular, tests) can Serena identify and correct mistakes autonomously.&lt;/p&gt; 
&lt;h4&gt;Shell Execution and Editing Tools&lt;/h4&gt; 
&lt;p&gt;However, it should be noted that the &lt;code&gt;execute_shell_command&lt;/code&gt; tool allows for arbitrary code execution. When using Serena as an MCP Server, clients will typically ask the user for permission before executing a tool, so as long as the user inspects execution parameters beforehand, this should not be a problem. However, if you have concerns, you can choose to disable certain commands in your project's .yml configuration file. If you only want to use Serena purely for analyzing code and suggesting implementations without modifying the codebase, you can enable read-only mode by setting &lt;code&gt;read_only: true&lt;/code&gt; in your project configuration file. This will automatically disable all editing tools and prevent any modifications to your codebase while still allowing all analysis and exploration capabilities.&lt;/p&gt; 
&lt;p&gt;In general, be sure to back up your work and use a version control system in order to avoid losing any work.&lt;/p&gt; 
&lt;h3&gt;Modes and Contexts&lt;/h3&gt; 
&lt;p&gt;Serena's behavior and toolset can be adjusted using contexts and modes. These allow for a high degree of customization to best suit your workflow and the environment Serena is operating in.&lt;/p&gt; 
&lt;h4&gt;Contexts&lt;/h4&gt; 
&lt;p&gt;A context defines the general environment in which Serena is operating. It influences the initial system prompt and the set of available tools. A context is set at startup when launching Serena (e.g., via CLI options for an MCP server or in the agent script) and cannot be changed during an active session.&lt;/p&gt; 
&lt;p&gt;Serena comes with pre-defined contexts:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;desktop-app&lt;/code&gt;: Tailored for use with desktop applications like Claude Desktop. This is the default.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;agent&lt;/code&gt;: Designed for scenarios where Serena acts as a more autonomous agent, for example, when used with Agno.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;ide-assistant&lt;/code&gt;: Optimized for integration into IDEs like VSCode, Cursor, or Cline, focusing on in-editor coding assistance. Choose the context that best matches the type of integration you are using.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;When launching Serena, specify the context using &lt;code&gt;--context &amp;lt;context-name&amp;gt;&lt;/code&gt;. Note that for cases where parameter lists are specified (e.g. Claude Desktop), you must add two parameters to the list.&lt;/p&gt; 
&lt;p&gt;If you are using a local server (such as Llama.cpp) which requires you to use OpenAI-compatible tool descriptions, use context &lt;code&gt;oaicompat-agent&lt;/code&gt; instead of &lt;code&gt;agent&lt;/code&gt;.&lt;/p&gt; 
&lt;h4&gt;Modes&lt;/h4&gt; 
&lt;p&gt;Modes further refine Serena's behavior for specific types of tasks or interaction styles. Multiple modes can be active simultaneously, allowing you to combine their effects. Modes influence the system prompt and can also alter the set of available tools by excluding certain ones.&lt;/p&gt; 
&lt;p&gt;Examples of built-in modes include:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;planning&lt;/code&gt;: Focuses Serena on planning and analysis tasks.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;editing&lt;/code&gt;: Optimizes Serena for direct code modification tasks.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;interactive&lt;/code&gt;: Suitable for a conversational, back-and-forth interaction style.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;one-shot&lt;/code&gt;: Configures Serena for tasks that should be completed in a single response, often used with &lt;code&gt;planning&lt;/code&gt; for generating reports or initial plans.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;no-onboarding&lt;/code&gt;: Skips the initial onboarding process if it's not needed for a particular session.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;onboarding&lt;/code&gt;: (Usually triggered automatically) Focuses on the project onboarding process.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Modes can be set at startup (similar to contexts) but can also be &lt;em&gt;switched dynamically&lt;/em&gt; during a session. You can instruct the LLM to use the &lt;code&gt;switch_modes&lt;/code&gt; tool to activate a different set of modes (e.g., "switch to planning and one-shot modes").&lt;/p&gt; 
&lt;p&gt;When launching Serena, specify modes using &lt;code&gt;--mode &amp;lt;mode-name&amp;gt;&lt;/code&gt;; multiple modes can be specified, e.g. &lt;code&gt;--mode planning --mode no-onboarding&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;‚ö†&lt;/span&gt; &lt;strong&gt;Mode Compatibility&lt;/strong&gt;: While you can combine modes, some may be semantically incompatible (e.g., &lt;code&gt;interactive&lt;/code&gt; and &lt;code&gt;one-shot&lt;/code&gt;). Serena currently does not prevent incompatible combinations; it is up to the user to choose sensible mode configurations.&lt;/p&gt; 
&lt;h4&gt;Customization&lt;/h4&gt; 
&lt;p&gt;You can create your own contexts and modes to precisely tailor Serena to your needs in two ways:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;You can use Serena's CLI to manage modes and contexts. Check out&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;uvx --from git+https://github.com/oraios/serena serena mode --help
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;and&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;uvx --from git+https://github.com/oraios/serena serena context --help
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&lt;em&gt;NOTE&lt;/em&gt;: Custom contexts/modes are simply YAML files in &lt;code&gt;&amp;lt;home&amp;gt;/.serena&lt;/code&gt;, they are automatically registered and available for use by their name (filename without the &lt;code&gt;.yml&lt;/code&gt; extension). If you don't want to use Serena's CLI, you can create and manage them in any way you see fit.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Using external YAML files&lt;/strong&gt;: When starting Serena, you can also provide an absolute path to a custom &lt;code&gt;.yml&lt;/code&gt; file for a context or mode.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;This customization allows for deep integration and adaptation of Serena to specific project requirements or personal preferences.&lt;/p&gt; 
&lt;h3&gt;Onboarding and Memories&lt;/h3&gt; 
&lt;p&gt;By default, Serena will perform an &lt;strong&gt;onboarding process&lt;/strong&gt; when it is started for the first time for a project. The goal of the onboarding is for Serena to get familiar with the project and to store memories, which it can then draw upon in future interactions. If an LLM should fail to complete the onboarding and does not actually write the respective memories to disk, you may need to ask it to do so explicitly.&lt;/p&gt; 
&lt;p&gt;The onboarding will usually read a lot of content from the project, thus filling up the context. It can therefore be advisable to switch to another conversation once the onboarding is complete. After the onboarding, we recommend that you have a quick look at the memories and, if necessary, edit them or add additional ones.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Memories&lt;/strong&gt; are files stored in &lt;code&gt;.serena/memories/&lt;/code&gt; in the project directory, which the agent can choose to read in subsequent interactions. Feel free to read and adjust them as needed; you can also add new ones manually. Every file in the &lt;code&gt;.serena/memories/&lt;/code&gt; directory is a memory file. Whenever Serena starts working on a project, the list of memories is provided, and the agent can decide to read them. We found that memories can significantly improve the user experience with Serena.&lt;/p&gt; 
&lt;h3&gt;Prepare Your Project&lt;/h3&gt; 
&lt;h4&gt;Structure Your Codebase&lt;/h4&gt; 
&lt;p&gt;Serena uses the code structure for finding, reading and editing code. This means that it will work well with well-structured code but may perform poorly on fully unstructured one (like a "God class" with enormous, non-modular functions). Furthermore, for languages that are not statically typed, type annotations are highly beneficial.&lt;/p&gt; 
&lt;h4&gt;Start from a Clean State&lt;/h4&gt; 
&lt;p&gt;It is best to start a code generation task from a clean git state. Not only will this make it easier for you to inspect the changes, but also the model itself will have a chance of seeing what it has changed by calling &lt;code&gt;git diff&lt;/code&gt; and thereby correct itself or continue working in a followup conversation if needed.&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;‚ö†&lt;/span&gt; &lt;strong&gt;Important&lt;/strong&gt;: since Serena will write to files using the system-native line endings and it might want to look at the git diff, it is important to set &lt;code&gt;git config core.autocrlf&lt;/code&gt; to &lt;code&gt;true&lt;/code&gt; on Windows. With &lt;code&gt;git config core.autocrlf&lt;/code&gt; set to &lt;code&gt;false&lt;/code&gt; on Windows, you may end up with huge diffs only due to line endings. It is generally a good idea to globally enable this git setting on Windows:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;git config --global core.autocrlf true
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Logging, Linting, and Automated Tests&lt;/h4&gt; 
&lt;p&gt;Serena can successfully complete tasks in an &lt;em&gt;agent loop&lt;/em&gt;, where it iteratively acquires information, performs actions, and reflects on the results. However, Serena cannot use a debugger; it must rely on the results of program executions, linting results, and test results to assess the correctness of its actions. Therefore, software that is designed to meaningful interpretable outputs (e.g. log messages) and that has a good test coverage is much easier to work with for Serena.&lt;/p&gt; 
&lt;p&gt;We generally recommend to start an editing task from a state where all linting checks and tests pass.&lt;/p&gt; 
&lt;h3&gt;Prompting Strategies&lt;/h3&gt; 
&lt;p&gt;We found that it is often a good idea to spend some time conceptualizing and planning a task before actually implementing it, especially for non-trivial task. This helps both in achieving better results and in increasing the feeling of control and staying in the loop. You can make a detailed plan in one session, where Serena may read a lot of your code to build up the context, and then continue with the implementation in another (potentially after creating suitable memories).&lt;/p&gt; 
&lt;h3&gt;Potential Issues in Code Editing&lt;/h3&gt; 
&lt;p&gt;In our experience, LLMs are bad at counting, i.e. they have problems inserting blocks of code in the right place. Most editing operations can be performed at the symbolic level, allowing this problem is overcome. However, sometimes, line-level insertions are useful.&lt;/p&gt; 
&lt;p&gt;Serena is instructed to double-check the line numbers and any code blocks that it will edit, but you may find it useful to explicitly tell it how to edit code if you run into problems. We are working on making Serena's editing capabilities more robust.&lt;/p&gt; 
&lt;h3&gt;Running Out of Context&lt;/h3&gt; 
&lt;p&gt;For long and complicated tasks, or tasks where Serena has read a lot of content, you may come close to the limits of context tokens. In that case, it is often a good idea to continue in a new conversation. Serena has a dedicated tool to create a summary of the current state of the progress and all relevant info for continuing it. You can request to create this summary and write it to a memory. Then, in a new conversation, you can just ask Serena to read the memory and continue with the task. In our experience, this worked really well. On the up-side, since in a single session there is no summarization involved, Serena does not usually get lost (unlike some other agents that summarize under the hood), and it is also instructed to occasionally check whether it's on the right track.&lt;/p&gt; 
&lt;p&gt;Moreover, Serena is instructed to be frugal with context (e.g., to not read bodies of code symbols unnecessarily), but we found that Claude is not always very good in being frugal (Gemini seemed better at it). You can explicitly instruct it to not read the bodies if you know that it's not needed.&lt;/p&gt; 
&lt;h3&gt;Combining Serena with Other MCP Servers&lt;/h3&gt; 
&lt;p&gt;When using Serena through an MCP Client, you can use it together with other MCP servers. However, beware of tool name collisions! See info on that above.&lt;/p&gt; 
&lt;p&gt;Currently, there is a collision with the popular Filesystem MCP Server. Since Serena also provides filesystem operations, there is likely no need to ever enable these two simultaneously.&lt;/p&gt; 
&lt;h3&gt;Serena's Logs: The Dashboard and GUI Tool&lt;/h3&gt; 
&lt;p&gt;Serena provides two convenient ways of accessing the logs of the current session:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;via the &lt;strong&gt;web-based dashboard&lt;/strong&gt; (enabled by default)&lt;/p&gt; &lt;p&gt;This is supported on all platforms. By default, it will be accessible at &lt;code&gt;http://localhost:24282/dashboard/index.html&lt;/code&gt;, but a higher port may be used if the default port is unavailable/multiple instances are running.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;via the &lt;strong&gt;GUI tool&lt;/strong&gt; (disabled by default)&lt;/p&gt; &lt;p&gt;This is mainly supported on Windows, but it may also work on Linux; macOS is unsupported.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Both can be enabled, configured or disabled in Serena's configuration file (&lt;code&gt;serena_config.yml&lt;/code&gt;, see above). If enabled, they will automatically be opened as soon as the Serena agent/MCP server is started. The web dashboard will display usage statistics of Serena's tools if you set &lt;code&gt;record_tool_usage_stats: True&lt;/code&gt; in your config.&lt;/p&gt; 
&lt;p&gt;In addition to viewing logs, both tools allow to shut down the Serena agent. This function is provided, because clients like Claude Desktop may fail to terminate the MCP server subprocess when they themselves are closed.&lt;/p&gt; 
&lt;h3&gt;Troubleshooting&lt;/h3&gt; 
&lt;p&gt;Support for MCP Servers in Claude Desktop and the various MCP Server SDKs are relatively new developments and may display instabilities.&lt;/p&gt; 
&lt;p&gt;The working configuration of an MCP server may vary from platform to platform and from client to client. We recommend always using absolute paths, as relative paths may be sources of errors. The language server is running in a separate sub-process and is called with asyncio ‚Äì sometimes a client may make it crash. If you have Serena's log window enabled, and it disappears, you'll know what happened.&lt;/p&gt; 
&lt;p&gt;Some clients may not properly terminate MCP servers, look out for hanging python processes and terminate them manually, if needed.&lt;/p&gt; 
&lt;h2&gt;Comparison with Other Coding Agents&lt;/h2&gt; 
&lt;p&gt;To our knowledge, Serena is the first fully-featured coding agent where the entire functionality is available through an MCP server, thus not requiring API keys or subscriptions.&lt;/p&gt; 
&lt;h3&gt;Subscription-Based Coding Agents&lt;/h3&gt; 
&lt;p&gt;Many prominent subscription-based coding agents are parts of IDEs like Windsurf, Cursor and VSCode. Serena's functionality is similar to Cursor's Agent, Windsurf's Cascade or VSCode's agent mode.&lt;/p&gt; 
&lt;p&gt;Serena has the advantage of not requiring a subscription. A potential disadvantage is that it is not directly integrated into an IDE, so the inspection of newly written code is not as seamless.&lt;/p&gt; 
&lt;p&gt;More technical differences are:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Serena is not bound to a specific IDE or CLI. Serena's MCP server can be used with any MCP client (including some IDEs), and the Agno-based agent provides additional ways of applying its functionality.&lt;/li&gt; 
 &lt;li&gt;Serena is not bound to a specific large language model or API.&lt;/li&gt; 
 &lt;li&gt;Serena navigates and edits code using a language server, so it has a symbolic understanding of the code. IDE-based tools often use a RAG-based or purely text-based approach, which is often less powerful, especially for large codebases.&lt;/li&gt; 
 &lt;li&gt;Serena is open-source and has a small codebase, so it can be easily extended and modified.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;API-Based Coding Agents&lt;/h3&gt; 
&lt;p&gt;An alternative to subscription-based agents are API-based agents like Claude Code, Cline, Aider, Roo Code and others, where the usage costs map directly to the API costs of the underlying LLM. Some of them (like Cline) can even be included in IDEs as an extension. They are often very powerful and their main downside are the (potentially very high) API costs.&lt;/p&gt; 
&lt;p&gt;Serena itself can be used as an API-based agent (see the section on Agno above). We have not yet written a CLI tool or a dedicated IDE extension for Serena (and there is probably no need for the latter, as Serena can already be used with any IDE that supports MCP servers). If there is demand for a Serena as a CLI tool like Claude Code, we will consider writing one.&lt;/p&gt; 
&lt;p&gt;The main difference between Serena and other API-based agents is that Serena can also be used as an MCP server, thus not requiring an API key and bypassing the API costs. This is a unique feature of Serena.&lt;/p&gt; 
&lt;h3&gt;Other MCP-Based Coding Agents&lt;/h3&gt; 
&lt;p&gt;There are other MCP servers designed for coding, like &lt;a href="https://github.com/wonderwhy-er/DesktopCommanderMCP"&gt;DesktopCommander&lt;/a&gt; and &lt;a href="https://github.com/ezyang/codemcp"&gt;codemcp&lt;/a&gt;. However, to the best of our knowledge, none of them provide semantic code retrieval and editing tools; they rely purely on text-based analysis. It is the integration of language servers and the MCP that makes Serena unique and so powerful for challenging coding tasks, especially in the context of larger codebases.&lt;/p&gt; 
&lt;h2&gt;Acknowledgements&lt;/h2&gt; 
&lt;p&gt;We built Serena on top of multiple existing open-source technologies, the most important ones being:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;a href="https://github.com/microsoft/multilspy"&gt;multilspy&lt;/a&gt;. A library which wraps language server implementations and adapts them for interaction via Python and which provided the basis for our library Solid-LSP (src/solidlsp). Solid-LSP provides pure synchronous LSP calls and extends the original library with the symbolic logic that Serena required.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/modelcontextprotocol/python-sdk"&gt;Python MCP SDK&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/agno-agi/agno"&gt;Agno&lt;/a&gt; and the associated &lt;a href="https://github.com/agno-agi/agent-ui"&gt;agent-ui&lt;/a&gt;, which we use to allow Serena to work with any model, beyond the ones supporting the MCP.&lt;/li&gt; 
 &lt;li&gt;All the language servers that we use through Solid-LSP.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Without these projects, Serena would not have been possible (or would have been significantly more difficult to build).&lt;/p&gt; 
&lt;h2&gt;Customizing and Extending Serena&lt;/h2&gt; 
&lt;p&gt;It is straightforward to extend Serena's AI functionality with your own ideas. Simply implement a new tool by subclassing &lt;code&gt;serena.agent.Tool&lt;/code&gt; and implement the &lt;code&gt;apply&lt;/code&gt; method with a signature that matches the tool's requirements. Once implemented, &lt;code&gt;SerenaAgent&lt;/code&gt; will automatically have access to the new tool.&lt;/p&gt; 
&lt;p&gt;It is also relatively straightforward to add &lt;a href="https://raw.githubusercontent.com/oraios/serena/main/.serena/memories/adding_new_language_support_guide.md"&gt;support for a new programming language&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;We look forward to seeing what the community will come up with! For details on contributing, see &lt;a href="https://raw.githubusercontent.com/oraios/serena/main/CONTRIBUTING.md"&gt;contributing guidelines&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;List of Tools&lt;/h2&gt; 
&lt;p&gt;Here is the list of Serena's default tools with a short description (output of &lt;code&gt;uv run serena tools list&lt;/code&gt;):&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;activate_project&lt;/code&gt;: Activates a project by name.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;check_onboarding_performed&lt;/code&gt;: Checks whether project onboarding was already performed.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;create_text_file&lt;/code&gt;: Creates/overwrites a file in the project directory.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;delete_memory&lt;/code&gt;: Deletes a memory from Serena's project-specific memory store.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;execute_shell_command&lt;/code&gt;: Executes a shell command.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;find_file&lt;/code&gt;: Finds files in the given relative paths&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;find_referencing_symbols&lt;/code&gt;: Finds symbols that reference the symbol at the given location (optionally filtered by type).&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;find_symbol&lt;/code&gt;: Performs a global (or local) search for symbols with/containing a given name/substring (optionally filtered by type).&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;get_symbols_overview&lt;/code&gt;: Gets an overview of the top-level symbols defined in a given file.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;insert_after_symbol&lt;/code&gt;: Inserts content after the end of the definition of a given symbol.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;insert_before_symbol&lt;/code&gt;: Inserts content before the beginning of the definition of a given symbol.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;list_dir&lt;/code&gt;: Lists files and directories in the given directory (optionally with recursion).&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;list_memories&lt;/code&gt;: Lists memories in Serena's project-specific memory store.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;onboarding&lt;/code&gt;: Performs onboarding (identifying the project structure and essential tasks, e.g. for testing or building).&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;prepare_for_new_conversation&lt;/code&gt;: Provides instructions for preparing for a new conversation (in order to continue with the necessary context).&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;read_file&lt;/code&gt;: Reads a file within the project directory.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;read_memory&lt;/code&gt;: Reads the memory with the given name from Serena's project-specific memory store.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;replace_regex&lt;/code&gt;: Replaces content in a file by using regular expressions.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;replace_symbol_body&lt;/code&gt;: Replaces the full definition of a symbol.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;search_for_pattern&lt;/code&gt;: Performs a search for a pattern in the project.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;think_about_collected_information&lt;/code&gt;: Thinking tool for pondering the completeness of collected information.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;think_about_task_adherence&lt;/code&gt;: Thinking tool for determining whether the agent is still on track with the current task.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;think_about_whether_you_are_done&lt;/code&gt;: Thinking tool for determining whether the task is truly completed.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;write_memory&lt;/code&gt;: Writes a named memory (for future reference) to Serena's project-specific memory store.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;There are several tools that are disabled by default, and have to be enabled explicitly, e.g., through the context or modes. Note that several of our default contexts do enable some of these tools. For example, the &lt;code&gt;desktop-app&lt;/code&gt; context enables the &lt;code&gt;execute_shell_command&lt;/code&gt; tool.&lt;/p&gt; 
&lt;p&gt;The full list of optional tools is (output of &lt;code&gt;uv run serena tools list --only-optional&lt;/code&gt;):&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;delete_lines&lt;/code&gt;: Deletes a range of lines within a file.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;get_current_config&lt;/code&gt;: Prints the current configuration of the agent, including the active and available projects, tools, contexts, and modes.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;initial_instructions&lt;/code&gt;: Gets the initial instructions for the current project. Should only be used in settings where the system prompt cannot be set, e.g. in clients you have no control over, like Claude Desktop.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;insert_at_line&lt;/code&gt;: Inserts content at a given line in a file.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;jet_brains_find_referencing_symbols&lt;/code&gt;: Finds symbols that reference the given symbol&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;jet_brains_find_symbol&lt;/code&gt;: Performs a global (or local) search for symbols with/containing a given name/substring (optionally filtered by type).&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;jet_brains_get_symbols_overview&lt;/code&gt;: Retrieves an overview of the top-level symbols within a specified file&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;remove_project&lt;/code&gt;: Removes a project from the Serena configuration.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;replace_lines&lt;/code&gt;: Replaces a range of lines within a file with new content.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;restart_language_server&lt;/code&gt;: Restarts the language server, may be necessary when edits not through Serena happen.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;summarize_changes&lt;/code&gt;: Provides instructions for summarizing the changes made to the codebase.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;switch_modes&lt;/code&gt;: Activates modes by providing a list of their names&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>SigmaHQ/sigma</title>
      <link>https://github.com/SigmaHQ/sigma</link>
      <description>&lt;p&gt;Main Sigma Rule Repository&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Sigma - Generic Signature Format for SIEM Systems&lt;/h1&gt; 
&lt;a href="https://sigmahq.io/"&gt; &lt;p align="center"&gt; &lt;br /&gt; 
  &lt;picture&gt; 
   &lt;source media="(prefers-color-scheme: dark)" srcset="./images/sigma_logo_dark.png" /&gt; 
   &lt;img width="454" alt="Sigma Logo" src="https://raw.githubusercontent.com/SigmaHQ/sigma/master/images/sigma_logo_light.png" /&gt; 
  &lt;/picture&gt; &lt;/p&gt; &lt;/a&gt; 
&lt;br /&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/SigmaHQ/sigma/actions?query=branch%3Amaster"&gt;&lt;img src="https://github.com/SigmaHQ/sigma/actions/workflows/sigma-test.yml/badge.svg?branch=master" alt="Sigma Build Status" /&gt;&lt;/a&gt; &lt;a href="https://sigmahq.io/"&gt;&lt;img src="https://cdn.jsdelivr.net/gh/SigmaHQ/sigmahq.github.io@master/images/Sigma%20Official%20Badge.svg?sanitize=true" alt="Sigma Official Badge" /&gt;&lt;/a&gt; &lt;img alt="GitHub Repo stars" src="https://img.shields.io/github/stars/SigmaHQ/sigma" /&gt; &lt;img alt="GitHub all releases" src="https://img.shields.io/github/downloads/SigmaHq/Sigma/total" /&gt; &lt;br /&gt; &lt;a href="https://opensourcesecurityindex.io/" target="_blank" rel="noopener"&gt; &lt;img style="width: 170px;" src="https://opensourcesecurityindex.io/badge.svg?sanitize=true" alt="Open Source Security Index - Fastest Growing Open Source Security Projects" width="170" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p&gt;Welcome to the Sigma main rule repository. The place where detection engineers, threat hunters and all defensive security practitioners collaborate on detection rules. The repository offers more than 3000 detection rules of different type and aims to make reliable detections accessible to all at no cost.&lt;/p&gt; 
&lt;p&gt;Currently the repository offers three types of rules:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/SigmaHQ/sigma/master/rules/"&gt;Generic Detection Rules&lt;/a&gt; - Are threat agnostic, their aim is to detect a behavior or an implementation of a technique or procedure that was, can or will be used by a potential threat actor.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/SigmaHQ/sigma/master/rules-threat-hunting/"&gt;Threat Hunting Rules&lt;/a&gt; - Are broader in scope and are meant to give the analyst a starting point to hunt for potential suspicious or malicious activity&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/SigmaHQ/sigma/master/rules-emerging-threats/"&gt;Emerging Threat Rules&lt;/a&gt; - Are rules that cover specific threats, that are timely and relevant for certain periods of time. These threats include specific APT campaigns, exploitation of Zero-Day vulnerabilities, specific malware used during an attack,...etc.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Explore Sigma&lt;/h2&gt; 
&lt;p&gt;To start exploring the Sigma ecosystem, please visit the official website &lt;a href="https://sigmahq.io"&gt;sigmahq.io&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;What is Sigma&lt;/h3&gt; 
&lt;p&gt;Sigma is a generic and open signature format that allows you to describe relevant log events in a straightforward manner. The rule format is very flexible, easy to write and applicable to any type of log file.&lt;/p&gt; 
&lt;p&gt;The main purpose of this project is to provide a structured form in which researchers or analysts can describe their once developed detection methods and make them shareable with others.&lt;/p&gt; 
&lt;p&gt;Sigma is for log files what &lt;a href="https://www.snort.org/"&gt;Snort&lt;/a&gt; is for network traffic and &lt;a href="https://github.com/VirusTotal/yara"&gt;YARA&lt;/a&gt; is for files.&lt;/p&gt; 
&lt;picture&gt; 
 &lt;source media="(prefers-color-scheme: dark)" srcset="./images/Sigma_description_dark.png" /&gt; 
 &lt;img alt="Sigma Description - A diagram showing Yaml Files (Sigma Rules) moving through a Sigma Convertor, and coming out as many SIEM logos, showing how Sigma rules can be converted to many different available SIEM query languages" src="https://raw.githubusercontent.com/SigmaHQ/sigma/master/images/Sigma_description_light.png" /&gt; 
&lt;/picture&gt; 
&lt;h3&gt;Why Sigma&lt;/h3&gt; 
&lt;p&gt;Today, everyone collects log data for analysis. People start working on their own, processing numerous white papers, blog posts and log analysis guidelines, extracting the necessary information and build their own searches and dashboard. Some of their searches and correlations are great and very useful but they lack a standardized format in which they can share their work with others.&lt;/p&gt; 
&lt;p&gt;Others provide excellent analyses, include IOCs and YARA rules to detect the malicious files and network connections, but have no way to describe a specific or generic detection method in log events. Sigma is meant to be an open standard in which such detection mechanisms can be defined, shared and collected in order to improve the detection capabilities for everyone.&lt;/p&gt; 
&lt;h3&gt;üåü Key Features&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;A continuously growing list of detection and hunting rules, peer reviewed by a community of professional Detection Engineers.&lt;/li&gt; 
 &lt;li&gt;Vendor agnostic detection rules.&lt;/li&gt; 
 &lt;li&gt;Easily shareable across communities and reports&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üèóÔ∏è Rule Creation&lt;/h2&gt; 
&lt;p&gt;To start writing Sigma rules please check the following guides:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/SigmaHQ/sigma/wiki/Rule-Creation-Guide"&gt;Rule Creation Guide&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.nextron-systems.com/2018/02/10/write-sigma-rules/"&gt;How to Write Sigma Rules - Nextron Systems&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üîé Contributing &amp;amp; Making PRs&lt;/h2&gt; 
&lt;p&gt;Please refer to the &lt;a href="https://raw.githubusercontent.com/SigmaHQ/sigma/master/CONTRIBUTING.md"&gt;CONTRIBUTING&lt;/a&gt; guide for detailed instructions on how you can start contributing new rules.&lt;/p&gt; 
&lt;h2&gt;üì¶ Rule Packages&lt;/h2&gt; 
&lt;p&gt;You can download the latest rule packages from the &lt;a href="https://github.com/SigmaHQ/sigma/releases/latest"&gt;release page&lt;/a&gt; and start leveraging Sigma rules today.&lt;/p&gt; 
&lt;h2&gt;üß¨ Rule Usage and Conversion&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;You can start converting Sigma rules today using &lt;a href="https://github.com/SigmaHQ/sigma-cli"&gt;Sigma CLI&lt;/a&gt; or &lt;a href="https://sigconverter.io"&gt;sigconverter.io&lt;/a&gt; the GUI interface&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;To integrate Sigma rules in your own toolchain or products use &lt;a href="https://github.com/SigmaHQ/pySigma"&gt;pySigma&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üö® Reporting False Positives or New Rule Ideas&lt;/h2&gt; 
&lt;p&gt;If you find a false positive or would like to propose a new detection rule idea but do not have the time to create one, please create a new issue on the &lt;a href="https://github.com/SigmaHQ/sigma/issues/new/choose"&gt;GitHub repository&lt;/a&gt; by selecting one of the available templates.&lt;/p&gt; 
&lt;h2&gt;üìö Resources &amp;amp; Further Reading&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=OheVuE9Ifhs"&gt;Hack.lu 2017 Sigma - Generic Signatures for Log Events by Thomas Patzke&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.sans.org/webcasts/mitre-att-ck-sigma-alerting-110010" title="MITRE ATT&amp;amp;CK¬Æ and Sigma Alerting"&gt;MITRE ATT&amp;amp;CK¬Æ and Sigma Alerting SANS Webcast Recording&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.slideshare.net/secret/gvgxeXoKblXRcA"&gt;Sigma - Generic Signatures for SIEM Systems by Florian Roth&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Projects or Products that use or integrate Sigma rules&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.alphasoc.com/detections_and_findings/sigma_community/"&gt;AlphaSOC&lt;/a&gt; - Leverages Sigma rules to increase coverage across all supported log sources&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mtnmunuklu/alterix"&gt;alterix&lt;/a&gt; - Converts Sigma rules to the query language of CRYPTTECH's SIEM&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.attackiq.com/2024/01/10/sigmaiq-attackiqs-latest-innovation-for-actionable-detections/"&gt;AttackIQ&lt;/a&gt; - Sigma Rules integrated in AttackIQ's platform, and &lt;a href="https://github.com/AttackIQ/SigmAIQ"&gt;SigmAIQ&lt;/a&gt; for Sigma rule conversion and LLM apps&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/atc-project/atomic-threat-coverage"&gt;Atomic Threat Coverage&lt;/a&gt; (Since December 2018)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://attackrulemap.com/"&gt;AttackRuleMap - Mapping of Atomic Red Team tests and Sigma Rules&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/confluentinc/confluent-sigma"&gt;Confluent Sigma&lt;/a&gt; - Kafka Streams supported Sigma rules&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://detection.studio/?ref=sigmahq_readme"&gt;Detection Studio&lt;/a&gt; - Convert Sigma rules to any supported SIEM.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://community.ibm.com/community/user/security/blogs/gladys-koskas1/2023/08/02/qradar-natively-supports-sigma-for-rules-creation"&gt;IBM QRadar&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://impede.ai/"&gt;Impede Detection Platform&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.joesecurity.org/blog/8225577975210857708"&gt;Joe Sandbox&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://limacharlie.io/"&gt;LimaCharlie&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://www.misp-project.org/2017/03/26/MISP.2.4.70.released.html"&gt;MISP&lt;/a&gt; (Since Version 2.4.70, March 2017)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.nextron-systems.com/aurora/"&gt;Nextron's Aurora Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.nextron-systems.com/thor/"&gt;Nextron's THOR Scanner&lt;/a&gt; - Scan with Sigma rules on endpoints&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://globenewswire.com/news-release/2019/03/04/1745907/0/en/RANK-Software-to-Help-MSSPs-Scale-Cybersecurity-Offerings.html"&gt;RANK VASA&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.securityonion.net/en/latest/sigma.html"&gt;Security Onion&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.sekoia.io"&gt;Sekoia.io XDR&lt;/a&gt; - XDR supporting Sigma and Sigma Correlation rules languages&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/muchdogesec/sigma2stix"&gt;sigma2stix&lt;/a&gt; - Converts the entire SigmaHQ Ruleset into STIX 2.1 Objects. 
  &lt;ul&gt; 
   &lt;li&gt;A versioned archive of sigma2stix STIX 2.1 data is also available to &lt;a href="https://github.com/muchdogesec/cti_knowledge_base_store/tree/main/sigma-rules"&gt;download here&lt;/a&gt;.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/3CORESec/SIEGMA"&gt;SIŒ£GMA&lt;/a&gt; - SIEM consumable generator that utilizes Sigma for query conversion&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://tdm.socprime.com/sigma/"&gt;SOC Prime&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/dstaulcu/TA-Sigma-Searches"&gt;TA-Sigma-Searches&lt;/a&gt; (Splunk App)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/google/timesketch/commit/0c6c4b65a6c0f2051d074e87bbb2da2424fa6c35"&gt;TimeSketch&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/P4T12ICK/ypsilon"&gt;ypsilon&lt;/a&gt; - Automated Use Case Testing&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üìú Maintainers&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://twitter.com/nas_bench"&gt;Nasreddine Bencherchali (@nas_bench)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://twitter.com/cyb3rops"&gt;Florian Roth (@cyb3rops)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://twitter.com/phantinuss"&gt;Christian Burkard (@phantinuss)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://twitter.com/frack113"&gt;Fran√ßois Hubaut (@frack113)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://twitter.com/blubbfiction"&gt;Thomas Patzke (@blubbfiction)&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Credits&lt;/h2&gt; 
&lt;p&gt;This project would've never reached this height without the help of the hundreds of contributors. Thanks to all past and present contributors for their help.&lt;/p&gt; 
&lt;h2&gt;Licenses&lt;/h2&gt; 
&lt;p&gt;The content of this repository is released under the &lt;a href="https://github.com/SigmaHQ/Detection-Rule-License"&gt;Detection Rule License (DRL) 1.1&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>getsentry/sentry</title>
      <link>https://github.com/getsentry/sentry</link>
      <description>&lt;p&gt;Developer-first error tracking and performance monitoring&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;/p&gt;
&lt;p align="center"&gt; &lt;a href="https://sentry.io/?utm_source=github&amp;amp;utm_medium=logo" target="_blank"&gt; &lt;img src="https://sentry-brand.storage.googleapis.com/sentry-wordmark-dark-280x84.png" alt="Sentry" width="280" height="84" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; Users and logs provide clues. Sentry provides answers. &lt;/p&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;h1&gt;What's Sentry?&lt;/h1&gt; 
&lt;p&gt;Sentry is the debugging platform that helps every developer detect, trace, and fix issues. Code breaks, fix it faster.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://github.com/getsentry/sentry/raw/master/.github/screenshots/issue-details.png" width="270" /&gt; &lt;img src="https://github.com/getsentry/sentry/raw/master/.github/screenshots/seer.png" width="270" /&gt; &lt;img src="https://github.com/getsentry/sentry/raw/master/.github/screenshots/insights.png" width="270" /&gt; &lt;img src="https://github.com/getsentry/sentry/raw/master/.github/screenshots/traces.png" width="270" /&gt; &lt;img src="https://github.com/getsentry/sentry/raw/master/.github/screenshots/trace-explorer.png" width="270" /&gt; &lt;img src="https://github.com/getsentry/sentry/raw/master/.github/screenshots/replays.png" width="270" /&gt; &lt;img src="https://github.com/getsentry/sentry/raw/master/.github/screenshots/insights.png" width="270" /&gt; &lt;img src="https://github.com/getsentry/sentry/raw/master/.github/screenshots/logs.png" width="270" /&gt; &lt;img src="https://github.com/getsentry/sentry/raw/master/.github/screenshots/uptime.png" width="270" /&gt; &lt;/p&gt; 
&lt;h2&gt;Official Sentry SDKs&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/getsentry/sentry-javascript"&gt;JavaScript&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/getsentry/sentry-electron/"&gt;Electron&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/getsentry/sentry-react-native"&gt;React-Native&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/getsentry/sentry-python"&gt;Python&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/getsentry/sentry-ruby"&gt;Ruby&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/getsentry/sentry-php"&gt;PHP&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/getsentry/sentry-laravel"&gt;Laravel&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/getsentry/sentry-go"&gt;Go&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/getsentry/sentry-rust"&gt;Rust&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/getsentry/sentry-java"&gt;Java/Kotlin&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/getsentry/sentry-cocoa"&gt;Objective-C/Swift&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/getsentry/sentry-dotnet"&gt;C#/F#&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/getsentry/sentry-native"&gt;C/C++&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/getsentry/sentry-dart"&gt;Dart/Flutter&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/getsentry/perl-raven"&gt;Perl&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/getsentry/sentry-clj/"&gt;Clojure&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/getsentry/sentry-elixir"&gt;Elixir&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/getsentry/sentry-unity"&gt;Unity&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/getsentry/sentry-unreal"&gt;Unreal Engine&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/getsentry/sentry-godot"&gt;Godot Engine&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/getsentry/sentry-powershell"&gt;PowerShell&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Resources&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.sentry.io/"&gt;Documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/getsentry/sentry/discussions"&gt;Discussions&lt;/a&gt; (Bugs, feature requests, general questions)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://discord.gg/PXa5Apfe7K"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.sentry.io/internal/contributing/"&gt;Contributing&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/getsentry/sentry/issues"&gt;Bug Tracker&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/getsentry/sentry"&gt;Code&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://explore.transifex.com/getsentry/sentry/"&gt;Transifex&lt;/a&gt; (Translate Sentry!)&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>crewAIInc/crewAI</title>
      <link>https://github.com/crewAIInc/crewAI</link>
      <description>&lt;p&gt;Framework for orchestrating role-playing, autonomous AI agents. By fostering collaborative intelligence, CrewAI empowers agents to work together seamlessly, tackling complex tasks.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;a href="https://github.com/crewAIInc/crewAI"&gt; &lt;img src="https://raw.githubusercontent.com/crewAIInc/crewAI/main/docs/images/crewai_logo.png" width="600px" alt="Open source Multi-AI Agent orchestration framework" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center" style="display: flex; justify-content: center; gap: 20px; align-items: center;"&gt; &lt;a href="https://trendshift.io/repositories/11239" target="_blank"&gt; &lt;img src="https://trendshift.io/api/badge/repositories/11239" alt="crewAIInc%2FcrewAI | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://crewai.com"&gt;Homepage&lt;/a&gt; ¬∑ &lt;a href="https://docs.crewai.com"&gt;Docs&lt;/a&gt; ¬∑ &lt;a href="https://app.crewai.com"&gt;Start Cloud Trial&lt;/a&gt; ¬∑ &lt;a href="https://blog.crewai.com"&gt;Blog&lt;/a&gt; ¬∑ &lt;a href="https://community.crewai.com"&gt;Forum&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/crewAIInc/crewAI"&gt; &lt;img src="https://img.shields.io/github/stars/crewAIInc/crewAI" alt="GitHub Repo stars" /&gt; &lt;/a&gt; &lt;a href="https://github.com/crewAIInc/crewAI/network/members"&gt; &lt;img src="https://img.shields.io/github/forks/crewAIInc/crewAI" alt="GitHub forks" /&gt; &lt;/a&gt; &lt;a href="https://github.com/crewAIInc/crewAI/issues"&gt; &lt;img src="https://img.shields.io/github/issues/crewAIInc/crewAI" alt="GitHub issues" /&gt; &lt;/a&gt; &lt;a href="https://github.com/crewAIInc/crewAI/pulls"&gt; &lt;img src="https://img.shields.io/github/issues-pr/crewAIInc/crewAI" alt="GitHub pull requests" /&gt; &lt;/a&gt; &lt;a href="https://opensource.org/licenses/MIT"&gt; &lt;img src="https://img.shields.io/badge/License-MIT-green.svg?sanitize=true" alt="License: MIT" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://pypi.org/project/crewai/"&gt; &lt;img src="https://img.shields.io/pypi/v/crewai" alt="PyPI version" /&gt; &lt;/a&gt; &lt;a href="https://pypi.org/project/crewai/"&gt; &lt;img src="https://img.shields.io/pypi/dm/crewai" alt="PyPI downloads" /&gt; &lt;/a&gt; &lt;a href="https://twitter.com/crewAIInc"&gt; &lt;img src="https://img.shields.io/twitter/follow/crewAIInc?style=social" alt="Twitter Follow" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;h3&gt;Fast and Flexible Multi-Agent Automation Framework&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;CrewAI is a lean, lightning-fast Python framework built entirely from scratch‚Äîcompletely &lt;strong&gt;independent of LangChain or other agent frameworks&lt;/strong&gt;. It empowers developers with both high-level simplicity and precise low-level control, ideal for creating autonomous AI agents tailored to any scenario.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;CrewAI Crews&lt;/strong&gt;: Optimize for autonomy and collaborative intelligence.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;CrewAI Flows&lt;/strong&gt;: Enable granular, event-driven control, single LLM calls for precise task orchestration and supports Crews natively&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;With over 100,000 developers certified through our community courses at &lt;a href="https://learn.crewai.com"&gt;learn.crewai.com&lt;/a&gt;, CrewAI is rapidly becoming the standard for enterprise-ready AI automation.&lt;/p&gt; 
&lt;h1&gt;CrewAI Enterprise Suite&lt;/h1&gt; 
&lt;p&gt;CrewAI Enterprise Suite is a comprehensive bundle tailored for organizations that require secure, scalable, and easy-to-manage agent-driven automation.&lt;/p&gt; 
&lt;p&gt;You can try one part of the suite the &lt;a href="https://app.crewai.com"&gt;Crew Control Plane for free&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Crew Control Plane Key Features:&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Tracing &amp;amp; Observability&lt;/strong&gt;: Monitor and track your AI agents and workflows in real-time, including metrics, logs, and traces.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Unified Control Plane&lt;/strong&gt;: A centralized platform for managing, monitoring, and scaling your AI agents and workflows.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Seamless Integrations&lt;/strong&gt;: Easily connect with existing enterprise systems, data sources, and cloud infrastructure.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Advanced Security&lt;/strong&gt;: Built-in robust security and compliance measures ensuring safe deployment and management.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Actionable Insights&lt;/strong&gt;: Real-time analytics and reporting to optimize performance and decision-making.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;24/7 Support&lt;/strong&gt;: Dedicated enterprise support to ensure uninterrupted operation and quick resolution of issues.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;On-premise and Cloud Deployment Options&lt;/strong&gt;: Deploy CrewAI Enterprise on-premise or in the cloud, depending on your security and compliance requirements.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;CrewAI Enterprise is designed for enterprises seeking a powerful, reliable solution to transform complex business processes into efficient, intelligent automations.&lt;/p&gt; 
&lt;h2&gt;Table of contents&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/crewAIInc/crewAI/main/#why-crewai"&gt;Why CrewAI?&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/crewAIInc/crewAI/main/#getting-started"&gt;Getting Started&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/crewAIInc/crewAI/main/#key-features"&gt;Key Features&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/crewAIInc/crewAI/main/#understanding-flows-and-crews"&gt;Understanding Flows and Crews&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/crewAIInc/crewAI/main/#how-crewai-compares"&gt;CrewAI vs LangGraph&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/crewAIInc/crewAI/main/#examples"&gt;Examples&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/crewAIInc/crewAI/main/#quick-tutorial"&gt;Quick Tutorial&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/crewAIInc/crewAI/main/#write-job-descriptions"&gt;Write Job Descriptions&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/crewAIInc/crewAI/main/#trip-planner"&gt;Trip Planner&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/crewAIInc/crewAI/main/#stock-analysis"&gt;Stock Analysis&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/crewAIInc/crewAI/main/#using-crews-and-flows-together"&gt;Using Crews and Flows Together&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/crewAIInc/crewAI/main/#connecting-your-crew-to-a-model"&gt;Connecting Your Crew to a Model&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/crewAIInc/crewAI/main/#how-crewai-compares"&gt;How CrewAI Compares&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/crewAIInc/crewAI/main/#frequently-asked-questions-faq"&gt;Frequently Asked Questions (FAQ)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/crewAIInc/crewAI/main/#contribution"&gt;Contribution&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/crewAIInc/crewAI/main/#telemetry"&gt;Telemetry&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/crewAIInc/crewAI/main/#license"&gt;License&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Why CrewAI?&lt;/h2&gt; 
&lt;div align="center" style="margin-bottom: 30px;"&gt; 
 &lt;img src="https://raw.githubusercontent.com/crewAIInc/crewAI/main/docs/images/asset.png" alt="CrewAI Logo" width="100%" /&gt; 
&lt;/div&gt; 
&lt;p&gt;CrewAI unlocks the true potential of multi-agent automation, delivering the best-in-class combination of speed, flexibility, and control with either Crews of AI Agents or Flows of Events:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Standalone Framework&lt;/strong&gt;: Built from scratch, independent of LangChain or any other agent framework.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;High Performance&lt;/strong&gt;: Optimized for speed and minimal resource usage, enabling faster execution.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Flexible Low Level Customization&lt;/strong&gt;: Complete freedom to customize at both high and low levels - from overall workflows and system architecture to granular agent behaviors, internal prompts, and execution logic.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Ideal for Every Use Case&lt;/strong&gt;: Proven effective for both simple tasks and highly complex, real-world, enterprise-grade scenarios.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Robust Community&lt;/strong&gt;: Backed by a rapidly growing community of over &lt;strong&gt;100,000 certified&lt;/strong&gt; developers offering comprehensive support and resources.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;CrewAI empowers developers and enterprises to confidently build intelligent automations, bridging the gap between simplicity, flexibility, and performance.&lt;/p&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;p&gt;Setup and run your first CrewAI agents by following this tutorial.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=-kSOTtYzgEw" title="CrewAI Getting Started Tutorial"&gt;&lt;img src="https://img.youtube.com/vi/-kSOTtYzgEw/hqdefault.jpg" alt="CrewAI Getting Started Tutorial" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;/h3&gt; 
&lt;p&gt;Learning Resources&lt;/p&gt; 
&lt;p&gt;Learn CrewAI through our comprehensive courses:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.deeplearning.ai/short-courses/multi-ai-agent-systems-with-crewai/"&gt;Multi AI Agent Systems with CrewAI&lt;/a&gt; - Master the fundamentals of multi-agent systems&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.deeplearning.ai/short-courses/practical-multi-ai-agents-and-advanced-use-cases-with-crewai/"&gt;Practical Multi AI Agents and Advanced Use Cases&lt;/a&gt; - Deep dive into advanced implementations&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Understanding Flows and Crews&lt;/h3&gt; 
&lt;p&gt;CrewAI offers two powerful, complementary approaches that work seamlessly together to build sophisticated AI applications:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Crews&lt;/strong&gt;: Teams of AI agents with true autonomy and agency, working together to accomplish complex tasks through role-based collaboration. Crews enable:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Natural, autonomous decision-making between agents&lt;/li&gt; 
   &lt;li&gt;Dynamic task delegation and collaboration&lt;/li&gt; 
   &lt;li&gt;Specialized roles with defined goals and expertise&lt;/li&gt; 
   &lt;li&gt;Flexible problem-solving approaches&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Flows&lt;/strong&gt;: Production-ready, event-driven workflows that deliver precise control over complex automations. Flows provide:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Fine-grained control over execution paths for real-world scenarios&lt;/li&gt; 
   &lt;li&gt;Secure, consistent state management between tasks&lt;/li&gt; 
   &lt;li&gt;Clean integration of AI agents with production Python code&lt;/li&gt; 
   &lt;li&gt;Conditional branching for complex business logic&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;The true power of CrewAI emerges when combining Crews and Flows. This synergy allows you to:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Build complex, production-grade applications&lt;/li&gt; 
 &lt;li&gt;Balance autonomy with precise control&lt;/li&gt; 
 &lt;li&gt;Handle sophisticated real-world scenarios&lt;/li&gt; 
 &lt;li&gt;Maintain clean, maintainable code structure&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Getting Started with Installation&lt;/h3&gt; 
&lt;p&gt;To get started with CrewAI, follow these simple steps:&lt;/p&gt; 
&lt;h3&gt;1. Installation&lt;/h3&gt; 
&lt;p&gt;Ensure you have Python &amp;gt;=3.10 &amp;lt;3.14 installed on your system. CrewAI uses &lt;a href="https://docs.astral.sh/uv/"&gt;UV&lt;/a&gt; for dependency management and package handling, offering a seamless setup and execution experience.&lt;/p&gt; 
&lt;p&gt;First, install CrewAI:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;pip install crewai
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you want to install the 'crewai' package along with its optional features that include additional tools for agents, you can do so by using the following command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;pip install 'crewai[tools]'
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The command above installs the basic package and also adds extra components which require more dependencies to function.&lt;/p&gt; 
&lt;h3&gt;Troubleshooting Dependencies&lt;/h3&gt; 
&lt;p&gt;If you encounter issues during installation or usage, here are some common solutions:&lt;/p&gt; 
&lt;h4&gt;Common Issues&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;ModuleNotFoundError: No module named 'tiktoken'&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Install tiktoken explicitly: &lt;code&gt;pip install 'crewai[embeddings]'&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;If using embedchain or other tools: &lt;code&gt;pip install 'crewai[tools]'&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Failed building wheel for tiktoken&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Ensure Rust compiler is installed (see installation steps above)&lt;/li&gt; 
   &lt;li&gt;For Windows: Verify Visual C++ Build Tools are installed&lt;/li&gt; 
   &lt;li&gt;Try upgrading pip: &lt;code&gt;pip install --upgrade pip&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;If issues persist, use a pre-built wheel: &lt;code&gt;pip install tiktoken --prefer-binary&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;2. Setting Up Your Crew with the YAML Configuration&lt;/h3&gt; 
&lt;p&gt;To create a new CrewAI project, run the following CLI (Command Line Interface) command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;crewai create crew &amp;lt;project_name&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This command creates a new project folder with the following structure:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;my_project/
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ pyproject.toml
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ .env
‚îî‚îÄ‚îÄ src/
    ‚îî‚îÄ‚îÄ my_project/
        ‚îú‚îÄ‚îÄ __init__.py
        ‚îú‚îÄ‚îÄ main.py
        ‚îú‚îÄ‚îÄ crew.py
        ‚îú‚îÄ‚îÄ tools/
        ‚îÇ   ‚îú‚îÄ‚îÄ custom_tool.py
        ‚îÇ   ‚îî‚îÄ‚îÄ __init__.py
        ‚îî‚îÄ‚îÄ config/
            ‚îú‚îÄ‚îÄ agents.yaml
            ‚îî‚îÄ‚îÄ tasks.yaml
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can now start developing your crew by editing the files in the &lt;code&gt;src/my_project&lt;/code&gt; folder. The &lt;code&gt;main.py&lt;/code&gt; file is the entry point of the project, the &lt;code&gt;crew.py&lt;/code&gt; file is where you define your crew, the &lt;code&gt;agents.yaml&lt;/code&gt; file is where you define your agents, and the &lt;code&gt;tasks.yaml&lt;/code&gt; file is where you define your tasks.&lt;/p&gt; 
&lt;h4&gt;To customize your project, you can:&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Modify &lt;code&gt;src/my_project/config/agents.yaml&lt;/code&gt; to define your agents.&lt;/li&gt; 
 &lt;li&gt;Modify &lt;code&gt;src/my_project/config/tasks.yaml&lt;/code&gt; to define your tasks.&lt;/li&gt; 
 &lt;li&gt;Modify &lt;code&gt;src/my_project/crew.py&lt;/code&gt; to add your own logic, tools, and specific arguments.&lt;/li&gt; 
 &lt;li&gt;Modify &lt;code&gt;src/my_project/main.py&lt;/code&gt; to add custom inputs for your agents and tasks.&lt;/li&gt; 
 &lt;li&gt;Add your environment variables into the &lt;code&gt;.env&lt;/code&gt; file.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Example of a simple crew with a sequential process:&lt;/h4&gt; 
&lt;p&gt;Instantiate your crew:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;crewai create crew latest-ai-development
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Modify the files as needed to fit your use case:&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;agents.yaml&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;# src/my_project/config/agents.yaml
researcher:
  role: &amp;gt;
    {topic} Senior Data Researcher
  goal: &amp;gt;
    Uncover cutting-edge developments in {topic}
  backstory: &amp;gt;
    You're a seasoned researcher with a knack for uncovering the latest
    developments in {topic}. Known for your ability to find the most relevant
    information and present it in a clear and concise manner.

reporting_analyst:
  role: &amp;gt;
    {topic} Reporting Analyst
  goal: &amp;gt;
    Create detailed reports based on {topic} data analysis and research findings
  backstory: &amp;gt;
    You're a meticulous analyst with a keen eye for detail. You're known for
    your ability to turn complex data into clear and concise reports, making
    it easy for others to understand and act on the information you provide.
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;tasks.yaml&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;# src/my_project/config/tasks.yaml
research_task:
  description: &amp;gt;
    Conduct a thorough research about {topic}
    Make sure you find any interesting and relevant information given
    the current year is 2025.
  expected_output: &amp;gt;
    A list with 10 bullet points of the most relevant information about {topic}
  agent: researcher

reporting_task:
  description: &amp;gt;
    Review the context you got and expand each topic into a full section for a report.
    Make sure the report is detailed and contains any and all relevant information.
  expected_output: &amp;gt;
    A fully fledge reports with the mains topics, each with a full section of information.
    Formatted as markdown without '```'
  agent: reporting_analyst
  output_file: report.md
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;crew.py&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# src/my_project/crew.py
from crewai import Agent, Crew, Process, Task
from crewai.project import CrewBase, agent, crew, task
from crewai_tools import SerperDevTool
from crewai.agents.agent_builder.base_agent import BaseAgent
from typing import List

@CrewBase
class LatestAiDevelopmentCrew():
	"""LatestAiDevelopment crew"""
	agents: List[BaseAgent]
	tasks: List[Task]

	@agent
	def researcher(self) -&amp;gt; Agent:
		return Agent(
			config=self.agents_config['researcher'],
			verbose=True,
			tools=[SerperDevTool()]
		)

	@agent
	def reporting_analyst(self) -&amp;gt; Agent:
		return Agent(
			config=self.agents_config['reporting_analyst'],
			verbose=True
		)

	@task
	def research_task(self) -&amp;gt; Task:
		return Task(
			config=self.tasks_config['research_task'],
		)

	@task
	def reporting_task(self) -&amp;gt; Task:
		return Task(
			config=self.tasks_config['reporting_task'],
			output_file='report.md'
		)

	@crew
	def crew(self) -&amp;gt; Crew:
		"""Creates the LatestAiDevelopment crew"""
		return Crew(
			agents=self.agents, # Automatically created by the @agent decorator
			tasks=self.tasks, # Automatically created by the @task decorator
			process=Process.sequential,
			verbose=True,
		)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;main.py&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;#!/usr/bin/env python
# src/my_project/main.py
import sys
from latest_ai_development.crew import LatestAiDevelopmentCrew

def run():
    """
    Run the crew.
    """
    inputs = {
        'topic': 'AI Agents'
    }
    LatestAiDevelopmentCrew().crew().kickoff(inputs=inputs)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;3. Running Your Crew&lt;/h3&gt; 
&lt;p&gt;Before running your crew, make sure you have the following keys set as environment variables in your &lt;code&gt;.env&lt;/code&gt; file:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;An &lt;a href="https://platform.openai.com/account/api-keys"&gt;OpenAI API key&lt;/a&gt; (or other LLM API key): &lt;code&gt;OPENAI_API_KEY=sk-...&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;A &lt;a href="https://serper.dev/"&gt;Serper.dev&lt;/a&gt; API key: &lt;code&gt;SERPER_API_KEY=YOUR_KEY_HERE&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Lock the dependencies and install them by using the CLI command but first, navigate to your project directory:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;cd my_project
crewai install (Optional)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To run your crew, execute the following command in the root of your project:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;crewai run
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;or&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python src/my_project/main.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If an error happens due to the usage of poetry, please run the following command to update your crewai package:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;crewai update
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You should see the output in the console and the &lt;code&gt;report.md&lt;/code&gt; file should be created in the root of your project with the full final report.&lt;/p&gt; 
&lt;p&gt;In addition to the sequential process, you can use the hierarchical process, which automatically assigns a manager to the defined crew to properly coordinate the planning and execution of tasks through delegation and validation of results. &lt;a href="https://docs.crewai.com/core-concepts/Processes/"&gt;See more about the processes here&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Key Features&lt;/h2&gt; 
&lt;p&gt;CrewAI stands apart as a lean, standalone, high-performance multi-AI Agent framework delivering simplicity, flexibility, and precise control‚Äîfree from the complexity and limitations found in other agent frameworks.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Standalone &amp;amp; Lean&lt;/strong&gt;: Completely independent from other frameworks like LangChain, offering faster execution and lighter resource demands.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Flexible &amp;amp; Precise&lt;/strong&gt;: Easily orchestrate autonomous agents through intuitive &lt;a href="https://docs.crewai.com/concepts/crews"&gt;Crews&lt;/a&gt; or precise &lt;a href="https://docs.crewai.com/concepts/flows"&gt;Flows&lt;/a&gt;, achieving perfect balance for your needs.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Seamless Integration&lt;/strong&gt;: Effortlessly combine Crews (autonomy) and Flows (precision) to create complex, real-world automations.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Deep Customization&lt;/strong&gt;: Tailor every aspect‚Äîfrom high-level workflows down to low-level internal prompts and agent behaviors.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Reliable Performance&lt;/strong&gt;: Consistent results across simple tasks and complex, enterprise-level automations.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Thriving Community&lt;/strong&gt;: Backed by robust documentation and over 100,000 certified developers, providing exceptional support and guidance.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Choose CrewAI to easily build powerful, adaptable, and production-ready AI automations.&lt;/p&gt; 
&lt;h2&gt;Examples&lt;/h2&gt; 
&lt;p&gt;You can test different real life examples of AI crews in the &lt;a href="https://github.com/crewAIInc/crewAI-examples?tab=readme-ov-file"&gt;CrewAI-examples repo&lt;/a&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/crewAIInc/crewAI-examples/tree/main/crews/landing_page_generator"&gt;Landing Page Generator&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.crewai.com/how-to/Human-Input-on-Execution"&gt;Having Human input on the execution&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/crewAIInc/crewAI-examples/tree/main/crews/trip_planner"&gt;Trip Planner&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/crewAIInc/crewAI-examples/tree/main/crews/stock_analysis"&gt;Stock Analysis&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Quick Tutorial&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=tnejrr-0a94" title="CrewAI Tutorial"&gt;&lt;img src="https://img.youtube.com/vi/tnejrr-0a94/maxresdefault.jpg" alt="CrewAI Tutorial" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Write Job Descriptions&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://github.com/crewAIInc/crewAI-examples/tree/main/crews/job-posting"&gt;Check out code for this example&lt;/a&gt; or watch a video below:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=u98wEMz-9to" title="Jobs postings"&gt;&lt;img src="https://img.youtube.com/vi/u98wEMz-9to/maxresdefault.jpg" alt="Jobs postings" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Trip Planner&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://github.com/crewAIInc/crewAI-examples/tree/main/crews/trip_planner"&gt;Check out code for this example&lt;/a&gt; or watch a video below:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=xis7rWp-hjs" title="Trip Planner"&gt;&lt;img src="https://img.youtube.com/vi/xis7rWp-hjs/maxresdefault.jpg" alt="Trip Planner" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Stock Analysis&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://github.com/crewAIInc/crewAI-examples/tree/main/crews/stock_analysis"&gt;Check out code for this example&lt;/a&gt; or watch a video below:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=e0Uj4yWdaAg" title="Stock Analysis"&gt;&lt;img src="https://img.youtube.com/vi/e0Uj4yWdaAg/maxresdefault.jpg" alt="Stock Analysis" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Using Crews and Flows Together&lt;/h3&gt; 
&lt;p&gt;CrewAI's power truly shines when combining Crews with Flows to create sophisticated automation pipelines. CrewAI flows support logical operators like &lt;code&gt;or_&lt;/code&gt; and &lt;code&gt;and_&lt;/code&gt; to combine multiple conditions. This can be used with &lt;code&gt;@start&lt;/code&gt;, &lt;code&gt;@listen&lt;/code&gt;, or &lt;code&gt;@router&lt;/code&gt; decorators to create complex triggering conditions.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;or_&lt;/code&gt;: Triggers when any of the specified conditions are met.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;and_&lt;/code&gt;Triggers when all of the specified conditions are met.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Here's how you can orchestrate multiple Crews within a Flow:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from crewai.flow.flow import Flow, listen, start, router, or_
from crewai import Crew, Agent, Task, Process
from pydantic import BaseModel

# Define structured state for precise control
class MarketState(BaseModel):
    sentiment: str = "neutral"
    confidence: float = 0.0
    recommendations: list = []

class AdvancedAnalysisFlow(Flow[MarketState]):
    @start()
    def fetch_market_data(self):
        # Demonstrate low-level control with structured state
        self.state.sentiment = "analyzing"
        return {"sector": "tech", "timeframe": "1W"}  # These parameters match the task description template

    @listen(fetch_market_data)
    def analyze_with_crew(self, market_data):
        # Show crew agency through specialized roles
        analyst = Agent(
            role="Senior Market Analyst",
            goal="Conduct deep market analysis with expert insight",
            backstory="You're a veteran analyst known for identifying subtle market patterns"
        )
        researcher = Agent(
            role="Data Researcher",
            goal="Gather and validate supporting market data",
            backstory="You excel at finding and correlating multiple data sources"
        )

        analysis_task = Task(
            description="Analyze {sector} sector data for the past {timeframe}",
            expected_output="Detailed market analysis with confidence score",
            agent=analyst
        )
        research_task = Task(
            description="Find supporting data to validate the analysis",
            expected_output="Corroborating evidence and potential contradictions",
            agent=researcher
        )

        # Demonstrate crew autonomy
        analysis_crew = Crew(
            agents=[analyst, researcher],
            tasks=[analysis_task, research_task],
            process=Process.sequential,
            verbose=True
        )
        return analysis_crew.kickoff(inputs=market_data)  # Pass market_data as named inputs

    @router(analyze_with_crew)
    def determine_next_steps(self):
        # Show flow control with conditional routing
        if self.state.confidence &amp;gt; 0.8:
            return "high_confidence"
        elif self.state.confidence &amp;gt; 0.5:
            return "medium_confidence"
        return "low_confidence"

    @listen("high_confidence")
    def execute_strategy(self):
        # Demonstrate complex decision making
        strategy_crew = Crew(
            agents=[
                Agent(role="Strategy Expert",
                      goal="Develop optimal market strategy")
            ],
            tasks=[
                Task(description="Create detailed strategy based on analysis",
                     expected_output="Step-by-step action plan")
            ]
        )
        return strategy_crew.kickoff()

    @listen(or_("medium_confidence", "low_confidence"))
    def request_additional_analysis(self):
        self.state.recommendations.append("Gather more data")
        return "Additional analysis required"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This example demonstrates how to:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Use Python code for basic data operations&lt;/li&gt; 
 &lt;li&gt;Create and execute Crews as steps in your workflow&lt;/li&gt; 
 &lt;li&gt;Use Flow decorators to manage the sequence of operations&lt;/li&gt; 
 &lt;li&gt;Implement conditional branching based on Crew results&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Connecting Your Crew to a Model&lt;/h2&gt; 
&lt;p&gt;CrewAI supports using various LLMs through a variety of connection options. By default your agents will use the OpenAI API when querying the model. However, there are several other ways to allow your agents to connect to models. For example, you can configure your agents to use a local model via the Ollama tool.&lt;/p&gt; 
&lt;p&gt;Please refer to the &lt;a href="https://docs.crewai.com/how-to/LLM-Connections/"&gt;Connect CrewAI to LLMs&lt;/a&gt; page for details on configuring your agents' connections to models.&lt;/p&gt; 
&lt;h2&gt;How CrewAI Compares&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;CrewAI's Advantage&lt;/strong&gt;: CrewAI combines autonomous agent intelligence with precise workflow control through its unique Crews and Flows architecture. The framework excels at both high-level orchestration and low-level customization, enabling complex, production-grade systems with granular control.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;LangGraph&lt;/strong&gt;: While LangGraph provides a foundation for building agent workflows, its approach requires significant boilerplate code and complex state management patterns. The framework's tight coupling with LangChain can limit flexibility when implementing custom agent behaviors or integrating with external systems.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;em&gt;P.S. CrewAI demonstrates significant performance advantages over LangGraph, executing 5.76x faster in certain cases like this QA task example (&lt;a href="https://github.com/crewAIInc/crewAI-examples/tree/main/Notebooks/CrewAI%20Flows%20%26%20Langgraph/QA%20Agent"&gt;see comparison&lt;/a&gt;) while achieving higher evaluation scores with faster completion times in certain coding tasks, like in this example (&lt;a href="https://github.com/crewAIInc/crewAI-examples/raw/main/Notebooks/CrewAI%20Flows%20%26%20Langgraph/Coding%20Assistant/coding_assistant_eval.ipynb"&gt;detailed analysis&lt;/a&gt;).&lt;/em&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Autogen&lt;/strong&gt;: While Autogen excels at creating conversational agents capable of working together, it lacks an inherent concept of process. In Autogen, orchestrating agents' interactions requires additional programming, which can become complex and cumbersome as the scale of tasks grows.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ChatDev&lt;/strong&gt;: ChatDev introduced the idea of processes into the realm of AI agents, but its implementation is quite rigid. Customizations in ChatDev are limited and not geared towards production environments, which can hinder scalability and flexibility in real-world applications.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contribution&lt;/h2&gt; 
&lt;p&gt;CrewAI is open-source and we welcome contributions. If you're looking to contribute, please:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Fork the repository.&lt;/li&gt; 
 &lt;li&gt;Create a new branch for your feature.&lt;/li&gt; 
 &lt;li&gt;Add your feature or improvement.&lt;/li&gt; 
 &lt;li&gt;Send a pull request.&lt;/li&gt; 
 &lt;li&gt;We appreciate your input!&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Installing Dependencies&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uv lock
uv sync
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Virtual Env&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uv venv
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Pre-commit hooks&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pre-commit install
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Running Tests&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uv run pytest .
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Running static type checks&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uvx mypy src
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Packaging&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uv build
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Installing Locally&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install dist/*.tar.gz
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Telemetry&lt;/h2&gt; 
&lt;p&gt;CrewAI uses anonymous telemetry to collect usage data with the main purpose of helping us improve the library by focusing our efforts on the most used features, integrations and tools.&lt;/p&gt; 
&lt;p&gt;It's pivotal to understand that &lt;strong&gt;NO data is collected&lt;/strong&gt; concerning prompts, task descriptions, agents' backstories or goals, usage of tools, API calls, responses, any data processed by the agents, or secrets and environment variables, with the exception of the conditions mentioned. When the &lt;code&gt;share_crew&lt;/code&gt; feature is enabled, detailed data including task descriptions, agents' backstories or goals, and other specific attributes are collected to provide deeper insights while respecting user privacy. Users can disable telemetry by setting the environment variable OTEL_SDK_DISABLED to true.&lt;/p&gt; 
&lt;p&gt;Data collected includes:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Version of CrewAI 
  &lt;ul&gt; 
   &lt;li&gt;So we can understand how many users are using the latest version&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Version of Python 
  &lt;ul&gt; 
   &lt;li&gt;So we can decide on what versions to better support&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;General OS (e.g. number of CPUs, macOS/Windows/Linux) 
  &lt;ul&gt; 
   &lt;li&gt;So we know what OS we should focus on and if we could build specific OS related features&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Number of agents and tasks in a crew 
  &lt;ul&gt; 
   &lt;li&gt;So we make sure we are testing internally with similar use cases and educate people on the best practices&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Crew Process being used 
  &lt;ul&gt; 
   &lt;li&gt;Understand where we should focus our efforts&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;If Agents are using memory or allowing delegation 
  &lt;ul&gt; 
   &lt;li&gt;Understand if we improved the features or maybe even drop them&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;If Tasks are being executed in parallel or sequentially 
  &lt;ul&gt; 
   &lt;li&gt;Understand if we should focus more on parallel execution&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Language model being used 
  &lt;ul&gt; 
   &lt;li&gt;Improved support on most used languages&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Roles of agents in a crew 
  &lt;ul&gt; 
   &lt;li&gt;Understand high level use cases so we can build better tools, integrations and examples about it&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Tools names available 
  &lt;ul&gt; 
   &lt;li&gt;Understand out of the publicly available tools, which ones are being used the most so we can improve them&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Users can opt-in to Further Telemetry, sharing the complete telemetry data by setting the &lt;code&gt;share_crew&lt;/code&gt; attribute to &lt;code&gt;True&lt;/code&gt; on their Crews. Enabling &lt;code&gt;share_crew&lt;/code&gt; results in the collection of detailed crew and task execution data, including &lt;code&gt;goal&lt;/code&gt;, &lt;code&gt;backstory&lt;/code&gt;, &lt;code&gt;context&lt;/code&gt;, and &lt;code&gt;output&lt;/code&gt; of tasks. This enables a deeper insight into usage patterns while respecting the user's choice to share.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;CrewAI is released under the &lt;a href="https://github.com/crewAIInc/crewAI/raw/main/LICENSE"&gt;MIT License&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Frequently Asked Questions (FAQ)&lt;/h2&gt; 
&lt;h3&gt;General&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/crewAIInc/crewAI/main/#q-what-exactly-is-crewai"&gt;What exactly is CrewAI?&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/crewAIInc/crewAI/main/#q-how-do-i-install-crewai"&gt;How do I install CrewAI?&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/crewAIInc/crewAI/main/#q-does-crewai-depend-on-langchain"&gt;Does CrewAI depend on LangChain?&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/crewAIInc/crewAI/main/#q-is-crewai-open-source"&gt;Is CrewAI open-source?&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/crewAIInc/crewAI/main/#q-does-crewai-collect-data-from-users"&gt;Does CrewAI collect data from users?&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Features and Capabilities&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/crewAIInc/crewAI/main/#q-can-crewai-handle-complex-use-cases"&gt;Can CrewAI handle complex use cases?&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/crewAIInc/crewAI/main/#q-can-i-use-crewai-with-local-ai-models"&gt;Can I use CrewAI with local AI models?&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/crewAIInc/crewAI/main/#q-what-makes-crews-different-from-flows"&gt;What makes Crews different from Flows?&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/crewAIInc/crewAI/main/#q-how-is-crewai-better-than-langchain"&gt;How is CrewAI better than LangChain?&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/crewAIInc/crewAI/main/#q-does-crewai-support-fine-tuning-or-training-custom-models"&gt;Does CrewAI support fine-tuning or training custom models?&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Resources and Community&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/crewAIInc/crewAI/main/#q-where-can-i-find-real-world-crewai-examples"&gt;Where can I find real-world CrewAI examples?&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/crewAIInc/crewAI/main/#q-how-can-i-contribute-to-crewai"&gt;How can I contribute to CrewAI?&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Enterprise Features&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/crewAIInc/crewAI/main/#q-what-additional-features-does-crewai-enterprise-offer"&gt;What additional features does CrewAI Enterprise offer?&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/crewAIInc/crewAI/main/#q-is-crewai-enterprise-available-for-cloud-and-on-premise-deployments"&gt;Is CrewAI Enterprise available for cloud and on-premise deployments?&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/crewAIInc/crewAI/main/#q-can-i-try-crewai-enterprise-for-free"&gt;Can I try CrewAI Enterprise for free?&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Q: What exactly is CrewAI?&lt;/h3&gt; 
&lt;p&gt;A: CrewAI is a standalone, lean, and fast Python framework built specifically for orchestrating autonomous AI agents. Unlike frameworks like LangChain, CrewAI does not rely on external dependencies, making it leaner, faster, and simpler.&lt;/p&gt; 
&lt;h3&gt;Q: How do I install CrewAI?&lt;/h3&gt; 
&lt;p&gt;A: Install CrewAI using pip:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;pip install crewai
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For additional tools, use:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;pip install 'crewai[tools]'
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Q: Does CrewAI depend on LangChain?&lt;/h3&gt; 
&lt;p&gt;A: No. CrewAI is built entirely from the ground up, with no dependencies on LangChain or other agent frameworks. This ensures a lean, fast, and flexible experience.&lt;/p&gt; 
&lt;h3&gt;Q: Can CrewAI handle complex use cases?&lt;/h3&gt; 
&lt;p&gt;A: Yes. CrewAI excels at both simple and highly complex real-world scenarios, offering deep customization options at both high and low levels, from internal prompts to sophisticated workflow orchestration.&lt;/p&gt; 
&lt;h3&gt;Q: Can I use CrewAI with local AI models?&lt;/h3&gt; 
&lt;p&gt;A: Absolutely! CrewAI supports various language models, including local ones. Tools like Ollama and LM Studio allow seamless integration. Check the &lt;a href="https://docs.crewai.com/how-to/LLM-Connections/"&gt;LLM Connections documentation&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;h3&gt;Q: What makes Crews different from Flows?&lt;/h3&gt; 
&lt;p&gt;A: Crews provide autonomous agent collaboration, ideal for tasks requiring flexible decision-making and dynamic interaction. Flows offer precise, event-driven control, ideal for managing detailed execution paths and secure state management. You can seamlessly combine both for maximum effectiveness.&lt;/p&gt; 
&lt;h3&gt;Q: How is CrewAI better than LangChain?&lt;/h3&gt; 
&lt;p&gt;A: CrewAI provides simpler, more intuitive APIs, faster execution speeds, more reliable and consistent results, robust documentation, and an active community‚Äîaddressing common criticisms and limitations associated with LangChain.&lt;/p&gt; 
&lt;h3&gt;Q: Is CrewAI open-source?&lt;/h3&gt; 
&lt;p&gt;A: Yes, CrewAI is open-source and actively encourages community contributions and collaboration.&lt;/p&gt; 
&lt;h3&gt;Q: Does CrewAI collect data from users?&lt;/h3&gt; 
&lt;p&gt;A: CrewAI collects anonymous telemetry data strictly for improvement purposes. Sensitive data such as prompts, tasks, or API responses are never collected unless explicitly enabled by the user.&lt;/p&gt; 
&lt;h3&gt;Q: Where can I find real-world CrewAI examples?&lt;/h3&gt; 
&lt;p&gt;A: Check out practical examples in the &lt;a href="https://github.com/crewAIInc/crewAI-examples"&gt;CrewAI-examples repository&lt;/a&gt;, covering use cases like trip planners, stock analysis, and job postings.&lt;/p&gt; 
&lt;h3&gt;Q: How can I contribute to CrewAI?&lt;/h3&gt; 
&lt;p&gt;A: Contributions are warmly welcomed! Fork the repository, create your branch, implement your changes, and submit a pull request. See the Contribution section of the README for detailed guidelines.&lt;/p&gt; 
&lt;h3&gt;Q: What additional features does CrewAI Enterprise offer?&lt;/h3&gt; 
&lt;p&gt;A: CrewAI Enterprise provides advanced features such as a unified control plane, real-time observability, secure integrations, advanced security, actionable insights, and dedicated 24/7 enterprise support.&lt;/p&gt; 
&lt;h3&gt;Q: Is CrewAI Enterprise available for cloud and on-premise deployments?&lt;/h3&gt; 
&lt;p&gt;A: Yes, CrewAI Enterprise supports both cloud-based and on-premise deployment options, allowing enterprises to meet their specific security and compliance requirements.&lt;/p&gt; 
&lt;h3&gt;Q: Can I try CrewAI Enterprise for free?&lt;/h3&gt; 
&lt;p&gt;A: Yes, you can explore part of the CrewAI Enterprise Suite by accessing the &lt;a href="https://app.crewai.com"&gt;Crew Control Plane&lt;/a&gt; for free.&lt;/p&gt; 
&lt;h3&gt;Q: Does CrewAI support fine-tuning or training custom models?&lt;/h3&gt; 
&lt;p&gt;A: Yes, CrewAI can integrate with custom-trained or fine-tuned models, allowing you to enhance your agents with domain-specific knowledge and accuracy.&lt;/p&gt; 
&lt;h3&gt;Q: Can CrewAI agents interact with external tools and APIs?&lt;/h3&gt; 
&lt;p&gt;A: Absolutely! CrewAI agents can easily integrate with external tools, APIs, and databases, empowering them to leverage real-world data and resources.&lt;/p&gt; 
&lt;h3&gt;Q: Is CrewAI suitable for production environments?&lt;/h3&gt; 
&lt;p&gt;A: Yes, CrewAI is explicitly designed with production-grade standards, ensuring reliability, stability, and scalability for enterprise deployments.&lt;/p&gt; 
&lt;h3&gt;Q: How scalable is CrewAI?&lt;/h3&gt; 
&lt;p&gt;A: CrewAI is highly scalable, supporting simple automations and large-scale enterprise workflows involving numerous agents and complex tasks simultaneously.&lt;/p&gt; 
&lt;h3&gt;Q: Does CrewAI offer debugging and monitoring tools?&lt;/h3&gt; 
&lt;p&gt;A: Yes, CrewAI Enterprise includes advanced debugging, tracing, and real-time observability features, simplifying the management and troubleshooting of your automations.&lt;/p&gt; 
&lt;h3&gt;Q: What programming languages does CrewAI support?&lt;/h3&gt; 
&lt;p&gt;A: CrewAI is primarily Python-based but easily integrates with services and APIs written in any programming language through its flexible API integration capabilities.&lt;/p&gt; 
&lt;h3&gt;Q: Does CrewAI offer educational resources for beginners?&lt;/h3&gt; 
&lt;p&gt;A: Yes, CrewAI provides extensive beginner-friendly tutorials, courses, and documentation through learn.crewai.com, supporting developers at all skill levels.&lt;/p&gt; 
&lt;h3&gt;Q: Can CrewAI automate human-in-the-loop workflows?&lt;/h3&gt; 
&lt;p&gt;A: Yes, CrewAI fully supports human-in-the-loop workflows, allowing seamless collaboration between human experts and AI agents for enhanced decision-making.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>NVIDIA-NeMo/NeMo</title>
      <link>https://github.com/NVIDIA-NeMo/NeMo</link>
      <description>&lt;p&gt;A scalable generative AI framework built for researchers and developers working on Large Language Models, Multimodal, and Speech AI (Automatic Speech Recognition and Text-to-Speech)&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href="http://www.repostatus.org/#active"&gt;&lt;img src="http://www.repostatus.org/badges/latest/active.svg?sanitize=true" alt="Project Status: Active -- The project has reached a stable, usable state and is being actively developed." /&gt;&lt;/a&gt; &lt;a href="https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/main/"&gt;&lt;img src="https://readthedocs.com/projects/nvidia-nemo/badge/?version=main" alt="Documentation" /&gt;&lt;/a&gt; &lt;a href="https://github.com/nvidia/nemo/actions/workflows/codeql.yml"&gt;&lt;img src="https://github.com/nvidia/nemo/actions/workflows/codeql.yml/badge.svg?branch=main&amp;amp;event=push" alt="CodeQL" /&gt;&lt;/a&gt; &lt;a href="https://github.com/NVIDIA/NeMo/raw/master/LICENSE"&gt;&lt;img src="https://img.shields.io/badge/License-Apache%202.0-brightgreen.svg?sanitize=true" alt="NeMo core license and license for collections in this repo" /&gt;&lt;/a&gt; &lt;a href="https://badge.fury.io/py/nemo-toolkit"&gt;&lt;img src="https://badge.fury.io/py/nemo-toolkit.svg?sanitize=true" alt="Release version" /&gt;&lt;/a&gt; &lt;a href="https://badge.fury.io/py/nemo-toolkit"&gt;&lt;img src="https://img.shields.io/pypi/pyversions/nemo-toolkit.svg?sanitize=true" alt="Python version" /&gt;&lt;/a&gt; &lt;a href="https://pepy.tech/project/nemo-toolkit"&gt;&lt;img src="https://static.pepy.tech/personalized-badge/nemo-toolkit?period=total&amp;amp;units=international_system&amp;amp;left_color=grey&amp;amp;right_color=brightgreen&amp;amp;left_text=downloads" alt="PyPi total downloads" /&gt;&lt;/a&gt; &lt;a href="https://github.com/psf/black"&gt;&lt;img src="https://img.shields.io/badge/code%20style-black-000000.svg?sanitize=true" alt="Code style: black" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;NVIDIA NeMo Framework&lt;/strong&gt;&lt;/h1&gt; 
&lt;h2&gt;Latest News&lt;/h2&gt; 
&lt;!-- markdownlint-disable --&gt; 
&lt;details open&gt; 
 &lt;summary&gt;&lt;b&gt;Pretrain and finetune &lt;span&gt;ü§ó&lt;/span&gt;Hugging Face models via AutoModel&lt;/b&gt;&lt;/summary&gt; Nemo Framework's latest feature AutoModel enables broad support for 
 &lt;span&gt;ü§ó&lt;/span&gt;Hugging Face models, with 25.04 focusing on 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/transformers/v3.5.1/model_doc/auto.html#automodelforcausallm"&gt;AutoModelForCausalLM&lt;/a&gt;&lt;a&gt; in the &lt;/a&gt;&lt;a href="https://huggingface.co/models?pipeline_tag=text-generation&amp;amp;sort=trending"&gt;Text Generation&lt;/a&gt;&lt;a&gt; category&lt;/a&gt;&lt;/li&gt;
  &lt;a&gt; &lt;/a&gt;
  &lt;li&gt;&lt;a&gt;&lt;/a&gt;&lt;a href="https://huggingface.co/docs/transformers/main/model_doc/auto#transformers.AutoModelForImageTextToText"&gt;AutoModelForImageTextToText&lt;/a&gt;&lt;a&gt; in the &lt;/a&gt;&lt;a href="https://huggingface.co/models?pipeline_tag=image-text-to-text&amp;amp;sort=trending"&gt;Image-Text-to-Text&lt;/a&gt;&lt;a&gt; category&lt;/a&gt;&lt;/li&gt;
  &lt;a&gt; &lt;/a&gt;
 &lt;/ul&gt;
 &lt;a&gt; &lt;/a&gt;
 &lt;p&gt;&lt;a&gt;More Details in Blog: &lt;/a&gt;&lt;a href="https://developer.nvidia.com/blog/run-hugging-face-models-instantly-with-day-0-support-from-nvidia-nemo-framework"&gt;Run Hugging Face Models Instantly with Day-0 Support from NVIDIA NeMo Framework&lt;/a&gt;&lt;a&gt;. Future releases will enable support for more model families such as Video Generation models.(2025-05-19)&lt;/a&gt;&lt;/p&gt;
 &lt;a&gt; &lt;/a&gt;
&lt;/details&gt;
&lt;a&gt; &lt;/a&gt;
&lt;details open&gt;
 &lt;a&gt; &lt;summary&gt;&lt;b&gt;Training on Blackwell using Nemo&lt;/b&gt;&lt;/summary&gt; NeMo Framework has added Blackwell support, with &lt;/a&gt;
 &lt;a href="https://docs.nvidia.com/nemo-framework/user-guide/latest/performance/performance_summary.html"&gt;performance benchmarks on GB200 &amp;amp; B200&lt;/a&gt;
 &lt;a&gt;. More optimizations to come in the upcoming releases.(2025-05-19) &lt;/a&gt;
&lt;/details&gt;
&lt;a&gt; &lt;/a&gt;
&lt;details open&gt;
 &lt;a&gt; &lt;summary&gt;&lt;b&gt;Training Performance on GPU Tuning Guide&lt;/b&gt;&lt;/summary&gt; NeMo Framework has published &lt;/a&gt;
 &lt;a href="https://docs.nvidia.com/nemo-framework/user-guide/latest/performance/performance-guide.html"&gt;a comprehensive guide for performance tuning to achieve optimal throughput&lt;/a&gt;
 &lt;a&gt;! (2025-05-19) &lt;/a&gt;
&lt;/details&gt;
&lt;a&gt; &lt;/a&gt;
&lt;details open&gt;
 &lt;a&gt; &lt;summary&gt;&lt;b&gt;New Models Support&lt;/b&gt;&lt;/summary&gt; NeMo Framework has added support for latest community models - &lt;/a&gt;
 &lt;a href="https://docs.nvidia.com/nemo-framework/user-guide/latest/vlms/llama4.html"&gt;Llama 4&lt;/a&gt;
 &lt;a&gt;, &lt;/a&gt;
 &lt;a href="https://docs.nvidia.com/nemo-framework/user-guide/latest/vision/diffusionmodels/flux.html"&gt;Flux&lt;/a&gt;
 &lt;a&gt;, &lt;/a&gt;
 &lt;a href="https://docs.nvidia.com/nemo-framework/user-guide/latest/llms/llama_nemotron.html"&gt;Llama Nemotron&lt;/a&gt;
 &lt;a&gt;, &lt;/a&gt;
 &lt;a href="https://docs.nvidia.com/nemo-framework/user-guide/latest/llms/hyena.html#"&gt;Hyena &amp;amp; Evo2&lt;/a&gt;
 &lt;a&gt;, &lt;/a&gt;
 &lt;a href="https://docs.nvidia.com/nemo-framework/user-guide/latest/vlms/qwen2vl.html"&gt;Qwen2-VL&lt;/a&gt;
 &lt;a&gt;, &lt;/a&gt;
 &lt;a href="https://docs.nvidia.com/nemo-framework/user-guide/latest/llms/qwen2.html"&gt;Qwen2.5&lt;/a&gt;
 &lt;a&gt;, Gemma3, Qwen3-30B&amp;amp;32B.(2025-05-19) &lt;/a&gt;
&lt;/details&gt;
&lt;a&gt; &lt;/a&gt;
&lt;details open&gt;
 &lt;a&gt; &lt;summary&gt;&lt;b&gt;NeMo Framework 2.0&lt;/b&gt;&lt;/summary&gt; We've released NeMo 2.0, an update on the NeMo Framework which prioritizes modularity and ease-of-use. Please refer to the &lt;/a&gt;
 &lt;a href="https://docs.nvidia.com/nemo-framework/user-guide/latest/nemo-2.0/index.html"&gt;NeMo Framework User Guide&lt;/a&gt; to get started. 
&lt;/details&gt; 
&lt;details open&gt; 
 &lt;summary&gt;&lt;b&gt;New Cosmos World Foundation Models Support&lt;/b&gt;&lt;/summary&gt; 
 &lt;details&gt; 
  &lt;summary&gt; &lt;a href="https://developer.nvidia.com/blog/advancing-physical-ai-with-nvidia-cosmos-world-foundation-model-platform"&gt;Advancing Physical AI with NVIDIA Cosmos World Foundation Model Platform &lt;/a&gt; (2025-01-09) &lt;/summary&gt; The end-to-end NVIDIA Cosmos platform accelerates world model development for physical AI systems. Built on CUDA, Cosmos combines state-of-the-art world foundation models, video tokenizers, and AI-accelerated data processing pipelines. Developers can accelerate world model development by fine-tuning Cosmos world foundation models or building new ones from the ground up. These models create realistic synthetic videos of environments and interactions, providing a scalable foundation for training complex systems, from simulating humanoid robots performing advanced actions to developing end-to-end autonomous driving models. 
  &lt;br /&gt;
  &lt;br /&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt; &lt;a href="https://developer.nvidia.com/blog/accelerate-custom-video-foundation-model-pipelines-with-new-nvidia-nemo-framework-capabilities/"&gt; Accelerate Custom Video Foundation Model Pipelines with New NVIDIA NeMo Framework Capabilities &lt;/a&gt; (2025-01-07) &lt;/summary&gt; The NeMo Framework now supports training and customizing the 
  &lt;a href="https://github.com/NVIDIA/Cosmos"&gt;NVIDIA Cosmos&lt;/a&gt; collection of world foundation models. Cosmos leverages advanced text-to-world generation techniques to create fluid, coherent video content from natural language prompts. 
  &lt;br /&gt;
  &lt;br /&gt; You can also now accelerate your video processing step using the 
  &lt;a href="https://developer.nvidia.com/nemo-curator-video-processing-early-access"&gt;NeMo Curator&lt;/a&gt; library, which provides optimized video processing and captioning features that can deliver up to 89x faster video processing when compared to an unoptimized CPU pipeline. 
  &lt;br /&gt;
  &lt;br /&gt; 
 &lt;/details&gt; 
&lt;/details&gt; 
&lt;details open&gt; 
 &lt;summary&gt;&lt;b&gt;Large Language Models and Multimodal Models&lt;/b&gt;&lt;/summary&gt; 
 &lt;details&gt; 
  &lt;summary&gt; &lt;a href="https://developer.nvidia.com/blog/state-of-the-art-multimodal-generative-ai-model-development-with-nvidia-nemo/"&gt; State-of-the-Art Multimodal Generative AI Model Development with NVIDIA NeMo &lt;/a&gt; (2024-11-06) &lt;/summary&gt; NVIDIA recently announced significant enhancements to the NeMo platform, focusing on multimodal generative AI models. The update includes NeMo Curator and the Cosmos tokenizer, which streamline the data curation process and enhance the quality of visual data. These tools are designed to handle large-scale data efficiently, making it easier to develop high-quality AI models for various applications, including robotics and autonomous driving. The Cosmos tokenizers, in particular, efficiently map visual data into compact, semantic tokens, which is crucial for training large-scale generative models. The tokenizer is available now on the 
  &lt;a href="http://github.com/NVIDIA/cosmos-tokenizer/NVIDIA/cosmos-tokenizer"&gt;NVIDIA/cosmos-tokenizer&lt;/a&gt; GitHub repo and on 
  &lt;a href="https://huggingface.co/nvidia/Cosmos-Tokenizer-CV8x8x8"&gt;Hugging Face&lt;/a&gt;. 
  &lt;br /&gt;
  &lt;br /&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt; &lt;a href="https://docs.nvidia.com/nemo-framework/user-guide/latest/llms/llama/index.html#new-llama-3-1-support for more information/"&gt; New Llama 3.1 Support &lt;/a&gt; (2024-07-23) &lt;/summary&gt; The NeMo Framework now supports training and customizing the Llama 3.1 collection of LLMs from Meta. 
  &lt;br /&gt;
  &lt;br /&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt; &lt;a href="https://aws.amazon.com/blogs/machine-learning/accelerate-your-generative-ai-distributed-training-workloads-with-the-nvidia-nemo-framework-on-amazon-eks/"&gt; Accelerate your Generative AI Distributed Training Workloads with the NVIDIA NeMo Framework on Amazon EKS &lt;/a&gt; (2024-07-16) &lt;/summary&gt; NVIDIA NeMo Framework now runs distributed training workloads on an Amazon Elastic Kubernetes Service (Amazon EKS) cluster. For step-by-step instructions on creating an EKS cluster and running distributed training workloads with NeMo, see the GitHub repository 
  &lt;a href="https://github.com/aws-samples/awsome-distributed-training/tree/main/3.test_cases/2.nemo-launcher/EKS/"&gt; here.&lt;/a&gt; 
  &lt;br /&gt;
  &lt;br /&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt; &lt;a href="https://developer.nvidia.com/blog/nvidia-nemo-accelerates-llm-innovation-with-hybrid-state-space-model-support/"&gt; NVIDIA NeMo Accelerates LLM Innovation with Hybrid State Space Model Support &lt;/a&gt; (2024/06/17) &lt;/summary&gt; NVIDIA NeMo and Megatron Core now support pre-training and fine-tuning of state space models (SSMs). NeMo also supports training models based on the Griffin architecture as described by Google DeepMind. 
  &lt;br /&gt;
  &lt;br /&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt; &lt;a href="https://huggingface.co/models?sort=trending&amp;amp;search=nvidia%2Fnemotron-4-340B"&gt; NVIDIA releases 340B base, instruct, and reward models pretrained on a total of 9T tokens. &lt;/a&gt; (2024-06-18) &lt;/summary&gt; See documentation and tutorials for SFT, PEFT, and PTQ with 
  &lt;a href="https://docs.nvidia.com/nemo-framework/user-guide/latest/llms/nemotron/index.html"&gt; Nemotron 340B &lt;/a&gt; in the NeMo Framework User Guide. 
  &lt;br /&gt;
  &lt;br /&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt; &lt;a href="https://developer.nvidia.com/blog/nvidia-sets-new-generative-ai-performance-and-scale-records-in-mlperf-training-v4-0/"&gt; NVIDIA sets new generative AI performance and scale records in MLPerf Training v4.0 &lt;/a&gt; (2024/06/12) &lt;/summary&gt; Using NVIDIA NeMo Framework and NVIDIA Hopper GPUs NVIDIA was able to scale to 11,616 H100 GPUs and achieve near-linear performance scaling on LLM pretraining. NVIDIA also achieved the highest LLM fine-tuning performance and raised the bar for text-to-image training. 
  &lt;br /&gt;
  &lt;br /&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt; &lt;a href="https://cloud.google.com/blog/products/compute/gke-and-nvidia-nemo-framework-to-train-generative-ai-models"&gt; Accelerate your generative AI journey with NVIDIA NeMo Framework on GKE &lt;/a&gt; (2024/03/16) &lt;/summary&gt; An end-to-end walkthrough to train generative AI models on the Google Kubernetes Engine (GKE) using the NVIDIA NeMo Framework is available at https://github.com/GoogleCloudPlatform/nvidia-nemo-on-gke. The walkthrough includes detailed instructions on how to set up a Google Cloud Project and pre-train a GPT model using the NeMo Framework. 
  &lt;br /&gt;
  &lt;br /&gt; 
 &lt;/details&gt; 
&lt;/details&gt; 
&lt;details open&gt; 
 &lt;summary&gt;&lt;b&gt;Speech Recognition&lt;/b&gt;&lt;/summary&gt; 
 &lt;details&gt; 
  &lt;summary&gt; &lt;a href="https://developer.nvidia.com/blog/accelerating-leaderboard-topping-asr-models-10x-with-nvidia-nemo/"&gt; Accelerating Leaderboard-Topping ASR Models 10x with NVIDIA NeMo &lt;/a&gt; (2024/09/24) &lt;/summary&gt; NVIDIA NeMo team released a number of inference optimizations for CTC, RNN-T, and TDT models that resulted in up to 10x inference speed-up. These models now exceed an inverse real-time factor (RTFx) of 2,000, with some reaching RTFx of even 6,000. 
  &lt;br /&gt;
  &lt;br /&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt; &lt;a href="https://developer.nvidia.com/blog/new-standard-for-speech-recognition-and-translation-from-the-nvidia-nemo-canary-model/"&gt; New Standard for Speech Recognition and Translation from the NVIDIA NeMo Canary Model &lt;/a&gt; (2024/04/18) &lt;/summary&gt; The NeMo team just released Canary, a multilingual model that transcribes speech in English, Spanish, German, and French with punctuation and capitalization. Canary also provides bi-directional translation, between English and the three other supported languages. 
  &lt;br /&gt;
  &lt;br /&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt; &lt;a href="https://developer.nvidia.com/blog/pushing-the-boundaries-of-speech-recognition-with-nemo-parakeet-asr-models/"&gt; Pushing the Boundaries of Speech Recognition with NVIDIA NeMo Parakeet ASR Models &lt;/a&gt; (2024/04/18) &lt;/summary&gt; NVIDIA NeMo, an end-to-end platform for the development of multimodal generative AI models at scale anywhere‚Äîon any cloud and on-premises‚Äîreleased the Parakeet family of automatic speech recognition (ASR) models. These state-of-the-art ASR models, developed in collaboration with Suno.ai, transcribe spoken English with exceptional accuracy. 
  &lt;br /&gt;
  &lt;br /&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt; &lt;a href="https://developer.nvidia.com/blog/turbocharge-asr-accuracy-and-speed-with-nvidia-nemo-parakeet-tdt/"&gt; Turbocharge ASR Accuracy and Speed with NVIDIA NeMo Parakeet-TDT &lt;/a&gt; (2024/04/18) &lt;/summary&gt; NVIDIA NeMo, an end-to-end platform for developing multimodal generative AI models at scale anywhere‚Äîon any cloud and on-premises‚Äîrecently released Parakeet-TDT. This new addition to the ‚ÄØNeMo ASR Parakeet model family boasts better accuracy and 64% greater speed over the previously best model, Parakeet-RNNT-1.1B. 
  &lt;br /&gt;
  &lt;br /&gt; 
 &lt;/details&gt; 
&lt;/details&gt; 
&lt;!-- markdownlint-enable --&gt; 
&lt;h2&gt;Introduction&lt;/h2&gt; 
&lt;p&gt;NVIDIA NeMo Framework is a scalable and cloud-native generative AI framework built for researchers and PyTorch developers working on Large Language Models (LLMs), Multimodal Models (MMs), Automatic Speech Recognition (ASR), Text to Speech (TTS), and Computer Vision (CV) domains. It is designed to help you efficiently create, customize, and deploy new generative AI models by leveraging existing code and pre-trained model checkpoints.&lt;/p&gt; 
&lt;p&gt;For technical documentation, please see the &lt;a href="https://docs.nvidia.com/nemo-framework/user-guide/latest/playbooks/index.html"&gt;NeMo Framework User Guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;What's New in NeMo 2.0&lt;/h2&gt; 
&lt;p&gt;NVIDIA NeMo 2.0 introduces several significant improvements over its predecessor, NeMo 1.0, enhancing flexibility, performance, and scalability.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Python-Based Configuration&lt;/strong&gt; - NeMo 2.0 transitions from YAML files to a Python-based configuration, providing more flexibility and control. This shift makes it easier to extend and customize configurations programmatically.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Modular Abstractions&lt;/strong&gt; - By adopting PyTorch Lightning‚Äôs modular abstractions, NeMo 2.0 simplifies adaptation and experimentation. This modular approach allows developers to more easily modify and experiment with different components of their models.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Scalability&lt;/strong&gt; - NeMo 2.0 seamlessly scaling large-scale experiments across thousands of GPUs using &lt;a href="https://github.com/NVIDIA/NeMo-Run"&gt;NeMo-Run&lt;/a&gt;, a powerful tool designed to streamline the configuration, execution, and management of machine learning experiments across computing environments.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Overall, these enhancements make NeMo 2.0 a powerful, scalable, and user-friendly framework for AI model development.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT]&lt;br /&gt; NeMo 2.0 is currently supported by the LLM (large language model) and VLM (vision language model) collections.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Get Started with NeMo 2.0&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Refer to the &lt;a href="https://docs.nvidia.com/nemo-framework/user-guide/latest/nemo-2.0/quickstart.html"&gt;Quickstart&lt;/a&gt; for examples of using NeMo-Run to launch NeMo 2.0 experiments locally and on a slurm cluster.&lt;/li&gt; 
 &lt;li&gt;For more information about NeMo 2.0, see the &lt;a href="https://docs.nvidia.com/nemo-framework/user-guide/latest/nemo-2.0/index.html"&gt;NeMo Framework User Guide&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/NVIDIA/NeMo/raw/main/nemo/collections/llm/recipes"&gt;NeMo 2.0 Recipes&lt;/a&gt; contains additional examples of launching large-scale runs using NeMo 2.0 and NeMo-Run.&lt;/li&gt; 
 &lt;li&gt;For an in-depth exploration of the main features of NeMo 2.0, see the &lt;a href="https://docs.nvidia.com/nemo-framework/user-guide/latest/nemo-2.0/features/index.html#feature-guide"&gt;Feature Guide&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;To transition from NeMo 1.0 to 2.0, see the &lt;a href="https://docs.nvidia.com/nemo-framework/user-guide/latest/nemo-2.0/migration/index.html#migration-guide"&gt;Migration Guide&lt;/a&gt; for step-by-step instructions.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Get Started with Cosmos&lt;/h3&gt; 
&lt;p&gt;NeMo Curator and NeMo Framework support video curation and post-training of the Cosmos World Foundation Models, which are open and available on &lt;a href="https://catalog.ngc.nvidia.com/orgs/nvidia/teams/cosmos/collections/cosmos"&gt;NGC&lt;/a&gt; and &lt;a href="https://huggingface.co/collections/nvidia/cosmos-6751e884dc10e013a0a0d8e6"&gt;Hugging Face&lt;/a&gt;. For more information on video datasets, refer to &lt;a href="https://developer.nvidia.com/nemo-curator"&gt;NeMo Curator&lt;/a&gt;. To post-train World Foundation Models using the NeMo Framework for your custom physical AI tasks, see the &lt;a href="https://github.com/NVIDIA/Cosmos/raw/main/cosmos1/models/diffusion/nemo/post_training/README.md"&gt;Cosmos Diffusion models&lt;/a&gt; and the &lt;a href="https://github.com/NVIDIA/Cosmos/raw/main/cosmos1/models/autoregressive/nemo/post_training/README.md"&gt;Cosmos Autoregressive models&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;LLMs and MMs Training, Alignment, and Customization&lt;/h2&gt; 
&lt;p&gt;All NeMo models are trained with &lt;a href="https://github.com/Lightning-AI/lightning"&gt;Lightning&lt;/a&gt;. Training is automatically scalable to 1000s of GPUs. You can check the performance benchmarks using the latest NeMo Framework container &lt;a href="https://docs.nvidia.com/nemo-framework/user-guide/latest/performance/performance_summary.html"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;When applicable, NeMo models leverage cutting-edge distributed training techniques, incorporating &lt;a href="https://docs.nvidia.com/nemo-framework/user-guide/latest/modeloverview.html"&gt;parallelism strategies&lt;/a&gt; to enable efficient training of very large models. These techniques include Tensor Parallelism (TP), Pipeline Parallelism (PP), Fully Sharded Data Parallelism (FSDP), Mixture-of-Experts (MoE), and Mixed Precision Training with BFloat16 and FP8, as well as others.&lt;/p&gt; 
&lt;p&gt;NeMo Transformer-based LLMs and MMs utilize &lt;a href="https://github.com/NVIDIA/TransformerEngine"&gt;NVIDIA Transformer Engine&lt;/a&gt; for FP8 training on NVIDIA Hopper GPUs, while leveraging &lt;a href="https://github.com/NVIDIA/Megatron-LM/tree/main/megatron/core"&gt;NVIDIA Megatron Core&lt;/a&gt; for scaling Transformer model training.&lt;/p&gt; 
&lt;p&gt;NeMo LLMs can be aligned with state-of-the-art methods such as SteerLM, Direct Preference Optimization (DPO), and Reinforcement Learning from Human Feedback (RLHF). See &lt;a href="https://github.com/NVIDIA/NeMo-Aligner"&gt;NVIDIA NeMo Aligner&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;p&gt;In addition to supervised fine-tuning (SFT), NeMo also supports the latest parameter efficient fine-tuning (PEFT) techniques such as LoRA, P-Tuning, Adapters, and IA3. Refer to the &lt;a href="https://docs.nvidia.com/nemo-framework/user-guide/latest/sft_peft/index.html"&gt;NeMo Framework User Guide&lt;/a&gt; for the full list of supported models and techniques.&lt;/p&gt; 
&lt;h2&gt;LLMs and MMs Deployment and Optimization&lt;/h2&gt; 
&lt;p&gt;NeMo LLMs and MMs can be deployed and optimized with &lt;a href="https://developer.nvidia.com/nemo-microservices-early-access"&gt;NVIDIA NeMo Microservices&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Speech AI&lt;/h2&gt; 
&lt;p&gt;NeMo ASR and TTS models can be optimized for inference and deployed for production use cases with &lt;a href="https://developer.nvidia.com/riva"&gt;NVIDIA Riva&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;NeMo Framework Launcher&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT]&lt;br /&gt; NeMo Framework Launcher is compatible with NeMo version 1.0 only. &lt;a href="https://github.com/NVIDIA/NeMo-Run"&gt;NeMo-Run&lt;/a&gt; is recommended for launching experiments using NeMo 2.0.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;a href="https://github.com/NVIDIA/NeMo-Megatron-Launcher"&gt;NeMo Framework Launcher&lt;/a&gt; is a cloud-native tool that streamlines the NeMo Framework experience. It is used for launching end-to-end NeMo Framework training jobs on CSPs and Slurm clusters.&lt;/p&gt; 
&lt;p&gt;The NeMo Framework Launcher includes extensive recipes, scripts, utilities, and documentation for training NeMo LLMs. It also includes the NeMo Framework &lt;a href="https://github.com/NVIDIA/NeMo-Megatron-Launcher#53-using-autoconfigurator-to-find-the-optimal-configuration"&gt;Autoconfigurator&lt;/a&gt;, which is designed to find the optimal model parallel configuration for training on a specific cluster.&lt;/p&gt; 
&lt;p&gt;To get started quickly with the NeMo Framework Launcher, please see the &lt;a href="https://docs.nvidia.com/nemo-framework/user-guide/latest/playbooks/index.html"&gt;NeMo Framework Playbooks&lt;/a&gt;. The NeMo Framework Launcher does not currently support ASR and TTS training, but it will soon.&lt;/p&gt; 
&lt;h2&gt;Get Started with NeMo Framework&lt;/h2&gt; 
&lt;p&gt;Getting started with NeMo Framework is easy. State-of-the-art pretrained NeMo models are freely available on &lt;a href="https://huggingface.co/models?library=nemo&amp;amp;sort=downloads&amp;amp;search=nvidia"&gt;Hugging Face Hub&lt;/a&gt; and &lt;a href="https://catalog.ngc.nvidia.com/models?query=nemo&amp;amp;orderBy=weightPopularDESC"&gt;NVIDIA NGC&lt;/a&gt;. These models can be used to generate text or images, transcribe audio, and synthesize speech in just a few lines of code.&lt;/p&gt; 
&lt;p&gt;We have extensive &lt;a href="https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/stable/starthere/tutorials.html"&gt;tutorials&lt;/a&gt; that can be run on &lt;a href="https://colab.research.google.com"&gt;Google Colab&lt;/a&gt; or with our &lt;a href="https://catalog.ngc.nvidia.com/orgs/nvidia/containers/nemo"&gt;NGC NeMo Framework Container&lt;/a&gt;. We also have &lt;a href="https://docs.nvidia.com/nemo-framework/user-guide/latest/playbooks/index.html"&gt;playbooks&lt;/a&gt; for users who want to train NeMo models with the NeMo Framework Launcher.&lt;/p&gt; 
&lt;p&gt;For advanced users who want to train NeMo models from scratch or fine-tune existing NeMo models, we have a full suite of &lt;a href="https://github.com/NVIDIA/NeMo/tree/main/examples"&gt;example scripts&lt;/a&gt; that support multi-GPU/multi-node training.&lt;/p&gt; 
&lt;h2&gt;Key Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/NVIDIA-NeMo/NeMo/main/nemo/collections/nlp/README.md"&gt;Large Language Models&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/NVIDIA-NeMo/NeMo/main/nemo/collections/multimodal/README.md"&gt;Multimodal&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/NVIDIA-NeMo/NeMo/main/nemo/collections/asr/README.md"&gt;Automatic Speech Recognition&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/NVIDIA-NeMo/NeMo/main/nemo/collections/tts/README.md"&gt;Text to Speech&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/NVIDIA-NeMo/NeMo/main/nemo/collections/vision/README.md"&gt;Computer Vision&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Requirements&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Python 3.10 or above&lt;/li&gt; 
 &lt;li&gt;Pytorch 2.5 or above&lt;/li&gt; 
 &lt;li&gt;NVIDIA GPU (if you intend to do model training)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Developer Documentation&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Version&lt;/th&gt; 
   &lt;th&gt;Status&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Latest&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/main/"&gt;&lt;img src="https://readthedocs.com/projects/nvidia-nemo/badge/?version=main" alt="Documentation Status" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/main/"&gt;Documentation of the latest (i.e. main) branch.&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Stable&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/stable/"&gt;&lt;img src="https://readthedocs.com/projects/nvidia-nemo/badge/?version=stable" alt="Documentation Status" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/stable/"&gt;Documentation of the stable (i.e. most recent release)&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Install NeMo Framework&lt;/h2&gt; 
&lt;p&gt;The NeMo Framework can be installed in a variety of ways, depending on your needs. Depending on the domain, you may find one of the following installation methods more suitable.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/NVIDIA-NeMo/NeMo/main/#conda--pip"&gt;Conda / Pip&lt;/a&gt;: Install NeMo-Framework with native Pip into a virtual environment. 
  &lt;ul&gt; 
   &lt;li&gt;Used to explore NeMo on any supported platform.&lt;/li&gt; 
   &lt;li&gt;This is the recommended method for ASR and TTS domains.&lt;/li&gt; 
   &lt;li&gt;Limited feature-completeness for other domains.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/NVIDIA-NeMo/NeMo/main/#ngc-pytorch-container"&gt;NGC PyTorch container&lt;/a&gt;: Install NeMo-Framework from source with feature-completeness into a highly optimized container. 
  &lt;ul&gt; 
   &lt;li&gt;For users that want to install from source in a highly optimized container.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/NVIDIA-NeMo/NeMo/main/#ngc-nemo-container"&gt;NGC NeMo container&lt;/a&gt;: Ready-to-go solution of NeMo-Framework 
  &lt;ul&gt; 
   &lt;li&gt;For users that seek highest performance.&lt;/li&gt; 
   &lt;li&gt;Contains all dependencies installed and tested for performance and convergence.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Support matrix&lt;/h3&gt; 
&lt;p&gt;NeMo-Framework provides tiers of support based on OS / Platform and mode of installation. Please refer the following overview of support levels:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Fully supported: Max performance and feature-completeness.&lt;/li&gt; 
 &lt;li&gt;Limited supported: Used to explore NeMo.&lt;/li&gt; 
 &lt;li&gt;No support yet: In development.&lt;/li&gt; 
 &lt;li&gt;Deprecated: Support has reached end of life.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Please refer to the following table for current support levels:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;OS / Platform&lt;/th&gt; 
   &lt;th&gt;Install from PyPi&lt;/th&gt; 
   &lt;th&gt;Source into NGC container&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;linux&lt;/code&gt; - &lt;code&gt;amd64/x84_64&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Limited support&lt;/td&gt; 
   &lt;td&gt;Full support&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;linux&lt;/code&gt; - &lt;code&gt;arm64&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Limited support&lt;/td&gt; 
   &lt;td&gt;Limited support&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;darwin&lt;/code&gt; - &lt;code&gt;amd64/x64_64&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Deprecated&lt;/td&gt; 
   &lt;td&gt;Deprecated&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;darwin&lt;/code&gt; - &lt;code&gt;arm64&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Limited support&lt;/td&gt; 
   &lt;td&gt;Limited support&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;windows&lt;/code&gt; - &lt;code&gt;amd64/x64_64&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;No support yet&lt;/td&gt; 
   &lt;td&gt;No support yet&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;windows&lt;/code&gt; - &lt;code&gt;arm64&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;No support yet&lt;/td&gt; 
   &lt;td&gt;No support yet&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Conda / Pip&lt;/h3&gt; 
&lt;p&gt;Install NeMo in a fresh Conda environment:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;conda create --name nemo python==3.10.12
conda activate nemo
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Pick the right version&lt;/h4&gt; 
&lt;p&gt;NeMo-Framework publishes pre-built wheels with each release. To install nemo_toolkit from such a wheel, use the following installation method:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install "nemo_toolkit[all]"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If a more specific version is desired, we recommend a Pip-VCS install. From &lt;a href="https://raw.githubusercontent.com/NVIDIA-NeMo/NeMo/main/github.com/NVIDIA/NeMo"&gt;NVIDIA/NeMo&lt;/a&gt;, fetch the commit, branch, or tag that you would like to install.&lt;br /&gt; To install nemo_toolkit from this Git reference &lt;code&gt;$REF&lt;/code&gt;, use the following installation method:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/NVIDIA/NeMo
cd NeMo
git checkout @${REF:-'main'}
pip install '.[all]'
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Install a specific Domain&lt;/h4&gt; 
&lt;p&gt;To install a specific domain of NeMo, you must first install the nemo_toolkit using the instructions listed above. Then, you run the following domain-specific commands:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install nemo_toolkit['all'] # or pip install "nemo_toolkit['all']@git+https://github.com/NVIDIA/NeMo@${REF:-'main'}"
pip install nemo_toolkit['asr'] # or pip install "nemo_toolkit['asr']@git+https://github.com/NVIDIA/NeMo@$REF:-'main'}"
pip install nemo_toolkit['nlp'] # or pip install "nemo_toolkit['nlp']@git+https://github.com/NVIDIA/NeMo@${REF:-'main'}"
pip install nemo_toolkit['tts'] # or pip install "nemo_toolkit['tts']@git+https://github.com/NVIDIA/NeMo@${REF:-'main'}"
pip install nemo_toolkit['vision'] # or pip install "nemo_toolkit['vision']@git+https://github.com/NVIDIA/NeMo@${REF:-'main'}"
pip install nemo_toolkit['multimodal'] # or pip install "nemo_toolkit['multimodal']@git+https://github.com/NVIDIA/NeMo@${REF:-'main'}"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;NGC PyTorch container&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;NOTE: The following steps are supported beginning with 24.04 (NeMo-Toolkit 2.3.0)&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;We recommended that you start with a base NVIDIA PyTorch container: nvcr.io/nvidia/pytorch:25.01-py3.&lt;/p&gt; 
&lt;p&gt;If starting with a base NVIDIA PyTorch container, you must first launch the container:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run \
  --gpus all \
  -it \
  --rm \
  --shm-size=16g \
  --ulimit memlock=-1 \
  --ulimit stack=67108864 \
  nvcr.io/nvidia/pytorch:${NV_PYTORCH_TAG:-'nvcr.io/nvidia/pytorch:25.01-py3'}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;From &lt;a href="https://raw.githubusercontent.com/NVIDIA-NeMo/NeMo/main/github.com/NVIDIA/NeMo"&gt;NVIDIA/NeMo&lt;/a&gt;, fetch the commit/branch/tag that you want to install.&lt;br /&gt; To install nemo_toolkit including all of its dependencies from this Git reference &lt;code&gt;$REF&lt;/code&gt;, use the following installation method:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd /opt
git clone https://github.com/NVIDIA/NeMo
cd NeMo
git checkout ${REF:-'main'}
bash docker/common/install_dep.sh --library all
pip install ".[all]"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;NGC NeMo container&lt;/h2&gt; 
&lt;p&gt;NeMo containers are launched concurrently with NeMo version updates. NeMo Framework now supports LLMs, MMs, ASR, and TTS in a single consolidated Docker container. You can find additional information about released containers on the &lt;a href="https://github.com/NVIDIA/NeMo/releases"&gt;NeMo releases page&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;To use a pre-built container, run the following code:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run \
  --gpus all \
  -it \
  --rm \
  --shm-size=16g \
  --ulimit memlock=-1 \
  --ulimit stack=67108864 \
  nvcr.io/nvidia/pytorch:${NV_PYTORCH_TAG:-'nvcr.io/nvidia/nemo:25.02'}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Future Work&lt;/h2&gt; 
&lt;p&gt;The NeMo Framework Launcher does not currently support ASR and TTS training, but it will soon.&lt;/p&gt; 
&lt;h2&gt;Discussions Board&lt;/h2&gt; 
&lt;p&gt;FAQ can be found on the NeMo &lt;a href="https://github.com/NVIDIA/NeMo/discussions"&gt;Discussions board&lt;/a&gt;. You are welcome to ask questions or start discussions on the board.&lt;/p&gt; 
&lt;h2&gt;Contribute to NeMo&lt;/h2&gt; 
&lt;p&gt;We welcome community contributions! Please refer to &lt;a href="https://github.com/NVIDIA/NeMo/raw/stable/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; for the process.&lt;/p&gt; 
&lt;h2&gt;Publications&lt;/h2&gt; 
&lt;p&gt;We provide an ever-growing list of &lt;a href="https://nvidia.github.io/NeMo/publications/"&gt;publications&lt;/a&gt; that utilize the NeMo Framework.&lt;/p&gt; 
&lt;p&gt;To contribute an article to the collection, please submit a pull request to the &lt;code&gt;gh-pages-src&lt;/code&gt; branch of this repository. For detailed information, please consult the README located at the &lt;a href="https://github.com/NVIDIA/NeMo/tree/gh-pages-src#readme"&gt;gh-pages-src branch&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Blogs&lt;/h2&gt; 
&lt;!-- markdownlint-disable --&gt; 
&lt;details open&gt; 
 &lt;summary&gt;&lt;b&gt;Large Language Models and Multimodal Models&lt;/b&gt;&lt;/summary&gt; 
 &lt;details&gt; 
  &lt;summary&gt; &lt;a href="https://blogs.nvidia.com/blog/bria-builds-responsible-generative-ai-using-nemo-picasso/"&gt; Bria Builds Responsible Generative AI for Enterprises Using NVIDIA NeMo, Picasso &lt;/a&gt; (2024/03/06) &lt;/summary&gt; Bria, a Tel Aviv startup at the forefront of visual generative AI for enterprises now leverages the NVIDIA NeMo Framework. The Bria.ai platform uses reference implementations from the NeMo Multimodal collection, trained on NVIDIA Tensor Core GPUs, to enable high-throughput and low-latency image generation. Bria has also adopted NVIDIA Picasso, a foundry for visual generative AI models, to run inference. 
  &lt;br /&gt;
  &lt;br /&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt; &lt;a href="https://developer.nvidia.com/blog/new-nvidia-nemo-framework-features-and-nvidia-h200-supercharge-llm-training-performance-and-versatility/"&gt; New NVIDIA NeMo Framework Features and NVIDIA H200 &lt;/a&gt; (2023/12/06) &lt;/summary&gt; NVIDIA NeMo Framework now includes several optimizations and enhancements, including: 1) Fully Sharded Data Parallelism (FSDP) to improve the efficiency of training large-scale AI models, 2) Mix of Experts (MoE)-based LLM architectures with expert parallelism for efficient LLM training at scale, 3) Reinforcement Learning from Human Feedback (RLHF) with TensorRT-LLM for inference stage acceleration, and 4) up to 4.2x speedups for Llama 2 pre-training on NVIDIA H200 Tensor Core GPUs. 
  &lt;br /&gt;
  &lt;br /&gt; 
  &lt;a href="https://developer.nvidia.com/blog/new-nvidia-nemo-framework-features-and-nvidia-h200-supercharge-llm-training-performance-and-versatility"&gt; &lt;img src="https://github.com/sbhavani/TransformerEngine/raw/main/docs/examples/H200-NeMo-performance.png" alt="H200-NeMo-performance" style="width: 600px;" /&gt;&lt;/a&gt; 
  &lt;br /&gt;
  &lt;br /&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt; &lt;a href="https://blogs.nvidia.com/blog/nemo-amazon-titan/"&gt; NVIDIA now powers training for Amazon Titan Foundation models &lt;/a&gt; (2023/11/28) &lt;/summary&gt; NVIDIA NeMo Framework now empowers the Amazon Titan foundation models (FM) with efficient training of large language models (LLMs). The Titan FMs form the basis of Amazon‚Äôs generative AI service, Amazon Bedrock. The NeMo Framework provides a versatile framework for building, customizing, and running LLMs. 
  &lt;br /&gt;
  &lt;br /&gt; 
 &lt;/details&gt; 
&lt;/details&gt; 
&lt;!-- markdownlint-enable --&gt; 
&lt;h2&gt;Licenses&lt;/h2&gt; 
&lt;p&gt;NeMo is licensed under the &lt;a href="https://github.com/NVIDIA/NeMo?tab=Apache-2.0-1-ov-file"&gt;Apache License 2.0&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>numpy/numpy</title>
      <link>https://github.com/numpy/numpy</link>
      <description>&lt;p&gt;The fundamental package for scientific computing with Python.&lt;/p&gt;&lt;hr&gt;&lt;h1 align="center"&gt; &lt;img src="https://raw.githubusercontent.com/numpy/numpy/main/branding/logo/primary/numpylogo.svg?sanitize=true" width="300" /&gt; &lt;/h1&gt;
&lt;br /&gt; 
&lt;p&gt;&lt;a href="https://numfocus.org"&gt;&lt;img src="https://img.shields.io/badge/powered%20by-NumFOCUS-orange.svg?style=flat&amp;amp;colorA=E1523D&amp;amp;colorB=007D8A" alt="Powered by NumFOCUS" /&gt;&lt;/a&gt; &lt;a href="https://pypi.org/project/numpy/"&gt;&lt;img src="https://img.shields.io/pypi/dm/numpy.svg?label=PyPI%20downloads" alt="PyPI Downloads" /&gt;&lt;/a&gt; &lt;a href="https://anaconda.org/conda-forge/numpy"&gt;&lt;img src="https://img.shields.io/conda/dn/conda-forge/numpy.svg?label=Conda%20downloads" alt="Conda Downloads" /&gt;&lt;/a&gt; &lt;a href="https://stackoverflow.com/questions/tagged/numpy"&gt;&lt;img src="https://img.shields.io/badge/stackoverflow-Ask%20questions-blue.svg?sanitize=true" alt="Stack Overflow" /&gt;&lt;/a&gt; &lt;a href="https://doi.org/10.1038/s41586-020-2649-2"&gt;&lt;img src="https://img.shields.io/badge/DOI-10.1038%2Fs41586--020--2649--2-blue" alt="Nature Paper" /&gt;&lt;/a&gt; &lt;a href="https://insights.linuxfoundation.org/project/numpy"&gt;&lt;img src="https://insights.linuxfoundation.org/api/badge/health-score?project=numpy" alt="LFX Health Score" /&gt;&lt;/a&gt; &lt;a href="https://securityscorecards.dev/viewer/?uri=github.com/numpy/numpy"&gt;&lt;img src="https://api.securityscorecards.dev/projects/github.com/numpy/numpy/badge" alt="OpenSSF Scorecard" /&gt;&lt;/a&gt; &lt;a href="https://pypi.org/project/numpy/"&gt;&lt;img src="https://img.shields.io/pypi/types/numpy" alt="Typing" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;NumPy is the fundamental package for scientific computing with Python.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Website:&lt;/strong&gt; &lt;a href="https://numpy.org"&gt;https://numpy.org&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Documentation:&lt;/strong&gt; &lt;a href="https://numpy.org/doc"&gt;https://numpy.org/doc&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Mailing list:&lt;/strong&gt; &lt;a href="https://mail.python.org/mailman/listinfo/numpy-discussion"&gt;https://mail.python.org/mailman/listinfo/numpy-discussion&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Source code:&lt;/strong&gt; &lt;a href="https://github.com/numpy/numpy"&gt;https://github.com/numpy/numpy&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Contributing:&lt;/strong&gt; &lt;a href="https://numpy.org/devdocs/dev/index.html"&gt;https://numpy.org/devdocs/dev/index.html&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Bug reports:&lt;/strong&gt; &lt;a href="https://github.com/numpy/numpy/issues"&gt;https://github.com/numpy/numpy/issues&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Report a security vulnerability:&lt;/strong&gt; &lt;a href="https://tidelift.com/docs/security"&gt;https://tidelift.com/docs/security&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;It provides:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;a powerful N-dimensional array object&lt;/li&gt; 
 &lt;li&gt;sophisticated (broadcasting) functions&lt;/li&gt; 
 &lt;li&gt;tools for integrating C/C++ and Fortran code&lt;/li&gt; 
 &lt;li&gt;useful linear algebra, Fourier transform, and random number capabilities&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Testing:&lt;/p&gt; 
&lt;p&gt;NumPy requires &lt;code&gt;pytest&lt;/code&gt; and &lt;code&gt;hypothesis&lt;/code&gt;. Tests can then be run after installation with:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;python -c "import numpy, sys; sys.exit(numpy.test() is False)"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Code of Conduct&lt;/h2&gt; 
&lt;p&gt;NumPy is a community-driven open source project developed by a diverse group of &lt;a href="https://numpy.org/teams/"&gt;contributors&lt;/a&gt;. The NumPy leadership has made a strong commitment to creating an open, inclusive, and positive community. Please read the &lt;a href="https://numpy.org/code-of-conduct/"&gt;NumPy Code of Conduct&lt;/a&gt; for guidance on how to interact with others in a way that makes our community thrive.&lt;/p&gt; 
&lt;h2&gt;Call for Contributions&lt;/h2&gt; 
&lt;p&gt;The NumPy project welcomes your expertise and enthusiasm!&lt;/p&gt; 
&lt;p&gt;Small improvements or fixes are always appreciated. If you are considering larger contributions to the source code, please contact us through the &lt;a href="https://mail.python.org/mailman/listinfo/numpy-discussion"&gt;mailing list&lt;/a&gt; first.&lt;/p&gt; 
&lt;p&gt;Writing code isn‚Äôt the only way to contribute to NumPy. You can also:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;review pull requests&lt;/li&gt; 
 &lt;li&gt;help us stay on top of new and old issues&lt;/li&gt; 
 &lt;li&gt;develop tutorials, presentations, and other educational materials&lt;/li&gt; 
 &lt;li&gt;maintain and improve &lt;a href="https://github.com/numpy/numpy.org"&gt;our website&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;develop graphic design for our brand assets and promotional materials&lt;/li&gt; 
 &lt;li&gt;translate website content&lt;/li&gt; 
 &lt;li&gt;help with outreach and onboard new contributors&lt;/li&gt; 
 &lt;li&gt;write grant proposals and help with other fundraising efforts&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For more information about the ways you can contribute to NumPy, visit &lt;a href="https://numpy.org/contribute/"&gt;our website&lt;/a&gt;. If you‚Äôre unsure where to start or how your skills fit in, reach out! You can ask on the mailing list or here, on GitHub, by opening a new issue or leaving a comment on a relevant issue that is already open.&lt;/p&gt; 
&lt;p&gt;Our preferred channels of communication are all public, but if you‚Äôd like to speak to us in private first, contact our community coordinators at &lt;a href="mailto:numpy-team@googlegroups.com"&gt;numpy-team@googlegroups.com&lt;/a&gt; or on Slack (write &lt;a href="mailto:numpy-team@googlegroups.com"&gt;numpy-team@googlegroups.com&lt;/a&gt; for an invitation).&lt;/p&gt; 
&lt;p&gt;We also have a biweekly community call, details of which are announced on the mailing list. You are very welcome to join.&lt;/p&gt; 
&lt;p&gt;If you are new to contributing to open source, &lt;a href="https://opensource.guide/how-to-contribute/"&gt;this guide&lt;/a&gt; helps explain why, what, and how to successfully get involved.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>ansible/ansible</title>
      <link>https://github.com/ansible/ansible</link>
      <description>&lt;p&gt;Ansible is a radically simple IT automation platform that makes your applications and systems easier to deploy and maintain. Automate everything from code deployment to network configuration to cloud management, in a language that approaches plain English, using SSH, with no agents to install on remote systems. https://docs.ansible.com.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href="https://pypi.org/project/ansible-core"&gt;&lt;img src="https://img.shields.io/pypi/v/ansible-core.svg?sanitize=true" alt="PyPI version" /&gt;&lt;/a&gt; &lt;a href="https://docs.ansible.com/ansible/latest/"&gt;&lt;img src="https://img.shields.io/badge/docs-latest-brightgreen.svg?sanitize=true" alt="Docs badge" /&gt;&lt;/a&gt; &lt;a href="https://docs.ansible.com/ansible/devel/community/communication.html"&gt;&lt;img src="https://img.shields.io/badge/chat-IRC-brightgreen.svg?sanitize=true" alt="Chat badge" /&gt;&lt;/a&gt; &lt;a href="https://dev.azure.com/ansible/ansible/_build/latest?definitionId=20&amp;amp;branchName=devel"&gt;&lt;img src="https://dev.azure.com/ansible/ansible/_apis/build/status/CI?branchName=devel" alt="Build Status" /&gt;&lt;/a&gt; &lt;a href="https://docs.ansible.com/ansible/devel/community/code_of_conduct.html"&gt;&lt;img src="https://img.shields.io/badge/code%20of%20conduct-Ansible-silver.svg?sanitize=true" alt="Ansible Code of Conduct" /&gt;&lt;/a&gt; &lt;a href="https://docs.ansible.com/ansible/devel/community/communication.html#mailing-list-information"&gt;&lt;img src="https://img.shields.io/badge/mailing%20lists-Ansible-orange.svg?sanitize=true" alt="Ansible mailing lists" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/ansible/ansible/devel/COPYING"&gt;&lt;img src="https://img.shields.io/badge/license-GPL%20v3.0-brightgreen.svg?sanitize=true" alt="Repository License" /&gt;&lt;/a&gt; &lt;a href="https://bestpractices.coreinfrastructure.org/projects/2372"&gt;&lt;img src="https://bestpractices.coreinfrastructure.org/projects/2372/badge" alt="Ansible CII Best Practices certification" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Ansible&lt;/h1&gt; 
&lt;p&gt;Ansible is a radically simple IT automation system. It handles configuration management, application deployment, cloud provisioning, ad-hoc task execution, network automation, and multi-node orchestration. Ansible makes complex changes like zero-downtime rolling updates with load balancers easy. More information on the Ansible &lt;a href="https://ansible.com/"&gt;website&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Design Principles&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Have an extremely simple setup process with a minimal learning curve.&lt;/li&gt; 
 &lt;li&gt;Manage machines quickly and in parallel.&lt;/li&gt; 
 &lt;li&gt;Avoid custom-agents and additional open ports, be agentless by leveraging the existing SSH daemon.&lt;/li&gt; 
 &lt;li&gt;Describe infrastructure in a language that is both machine and human friendly.&lt;/li&gt; 
 &lt;li&gt;Focus on security and easy auditability/review/rewriting of content.&lt;/li&gt; 
 &lt;li&gt;Manage new remote machines instantly, without bootstrapping any software.&lt;/li&gt; 
 &lt;li&gt;Allow module development in any dynamic language, not just Python.&lt;/li&gt; 
 &lt;li&gt;Be usable as non-root.&lt;/li&gt; 
 &lt;li&gt;Be the easiest IT automation system to use, ever.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Use Ansible&lt;/h2&gt; 
&lt;p&gt;You can install a released version of Ansible with &lt;code&gt;pip&lt;/code&gt; or a package manager. See our &lt;a href="https://docs.ansible.com/ansible/latest/installation_guide/intro_installation.html"&gt;installation guide&lt;/a&gt; for details on installing Ansible on a variety of platforms.&lt;/p&gt; 
&lt;p&gt;Power users and developers can run the &lt;code&gt;devel&lt;/code&gt; branch, which has the latest features and fixes, directly. Although it is reasonably stable, you are more likely to encounter breaking changes when running the &lt;code&gt;devel&lt;/code&gt; branch. We recommend getting involved in the Ansible community if you want to run the &lt;code&gt;devel&lt;/code&gt; branch.&lt;/p&gt; 
&lt;h2&gt;Communication&lt;/h2&gt; 
&lt;p&gt;Join the Ansible forum to ask questions, get help, and interact with the community.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://forum.ansible.com/c/help/6"&gt;Get Help&lt;/a&gt;: Find help or share your Ansible knowledge to help others. Use tags to filter and subscribe to posts, such as the following: 
  &lt;ul&gt; 
   &lt;li&gt;Posts tagged with &lt;a href="https://forum.ansible.com/tag/ansible"&gt;ansible&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;Posts tagged with &lt;a href="https://forum.ansible.com/tag/ansible-core"&gt;ansible-core&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;Posts tagged with &lt;a href="https://forum.ansible.com/tag/playbook"&gt;playbook&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://forum.ansible.com/c/chat/4"&gt;Social Spaces&lt;/a&gt;: Meet and interact with fellow enthusiasts.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://forum.ansible.com/c/news/5"&gt;News &amp;amp; Announcements&lt;/a&gt;: Track project-wide announcements including social events.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.ansible.com/ansible/devel/community/communication.html#the-bullhorn"&gt;Bullhorn newsletter&lt;/a&gt;: Get release announcements and important changes.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For more ways to get in touch, see &lt;a href="https://docs.ansible.com/ansible/devel/community/communication.html"&gt;Communicating with the Ansible community&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Contribute to Ansible&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Check out the &lt;a href="https://raw.githubusercontent.com/ansible/ansible/devel/.github/CONTRIBUTING.md"&gt;Contributor's Guide&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Read &lt;a href="https://docs.ansible.com/ansible/devel/community"&gt;Community Information&lt;/a&gt; for all kinds of ways to contribute to and interact with the project, including how to submit bug reports and code to Ansible.&lt;/li&gt; 
 &lt;li&gt;Submit a proposed code update through a pull request to the &lt;code&gt;devel&lt;/code&gt; branch.&lt;/li&gt; 
 &lt;li&gt;Talk to us before making larger changes to avoid duplicate efforts. This not only helps everyone know what is going on, but it also helps save time and effort if we decide some changes are needed.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Coding Guidelines&lt;/h2&gt; 
&lt;p&gt;We document our Coding Guidelines in the &lt;a href="https://docs.ansible.com/ansible/devel/dev_guide/"&gt;Developer Guide&lt;/a&gt;. We particularly suggest you review:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.ansible.com/ansible/devel/dev_guide/developing_modules_checklist.html"&gt;Contributing your module to Ansible&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.ansible.com/ansible/devel/dev_guide/developing_modules_best_practices.html"&gt;Conventions, tips, and pitfalls&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Branch Info&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;The &lt;code&gt;devel&lt;/code&gt; branch corresponds to the release actively under development.&lt;/li&gt; 
 &lt;li&gt;The &lt;code&gt;stable-2.X&lt;/code&gt; branches correspond to stable releases.&lt;/li&gt; 
 &lt;li&gt;Create a branch based on &lt;code&gt;devel&lt;/code&gt; and set up a &lt;a href="https://docs.ansible.com/ansible/devel/dev_guide/developing_modules_general.html#common-environment-setup"&gt;dev environment&lt;/a&gt; if you want to open a PR.&lt;/li&gt; 
 &lt;li&gt;See the &lt;a href="https://docs.ansible.com/ansible/devel/reference_appendices/release_and_maintenance.html"&gt;Ansible release and maintenance&lt;/a&gt; page for information about active branches.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Roadmap&lt;/h2&gt; 
&lt;p&gt;Based on team and community feedback, an initial roadmap will be published for a major or minor version (ex: 2.7, 2.8). The &lt;a href="https://docs.ansible.com/ansible/devel/roadmap/"&gt;Ansible Roadmap page&lt;/a&gt; details what is planned and how to influence the roadmap.&lt;/p&gt; 
&lt;h2&gt;Authors&lt;/h2&gt; 
&lt;p&gt;Ansible was created by &lt;a href="https://github.com/mpdehaan"&gt;Michael DeHaan&lt;/a&gt; and has contributions from over 5000 users (and growing). Thanks everyone!&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.ansible.com"&gt;Ansible&lt;/a&gt; is sponsored by &lt;a href="https://www.redhat.com"&gt;Red Hat, Inc.&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;GNU General Public License v3.0 or later&lt;/p&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/ansible/ansible/devel/COPYING"&gt;COPYING&lt;/a&gt; to see the full text.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>BerriAI/litellm</title>
      <link>https://github.com/BerriAI/litellm</link>
      <description>&lt;p&gt;Python SDK, Proxy Server (LLM Gateway) to call 100+ LLM APIs in OpenAI format - [Bedrock, Azure, OpenAI, VertexAI, Cohere, Anthropic, Sagemaker, HuggingFace, Replicate, Groq]&lt;/p&gt;&lt;hr&gt;&lt;h1 align="center"&gt; üöÖ LiteLLM &lt;/h1&gt; 
&lt;p align="center"&gt; &lt;/p&gt;
&lt;p align="center"&gt; &lt;a href="https://render.com/deploy?repo=https://github.com/BerriAI/litellm" target="_blank" rel="nofollow"&gt;&lt;img src="https://render.com/images/deploy-to-render-button.svg?sanitize=true" alt="Deploy to Render" /&gt;&lt;/a&gt; &lt;a href="https://railway.app/template/HLP0Ub?referralCode=jch2ME"&gt; &lt;img src="https://railway.app/button.svg?sanitize=true" alt="Deploy on Railway" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt;Call all LLM APIs using the OpenAI format [Bedrock, Huggingface, VertexAI, TogetherAI, Azure, OpenAI, Groq etc.] &lt;br /&gt; &lt;/p&gt; 
&lt;h4 align="center"&gt;&lt;a href="https://docs.litellm.ai/docs/simple_proxy" target="_blank"&gt;LiteLLM Proxy Server (LLM Gateway)&lt;/a&gt; | &lt;a href="https://docs.litellm.ai/docs/hosted" target="_blank"&gt; Hosted Proxy (Preview)&lt;/a&gt; | &lt;a href="https://docs.litellm.ai/docs/enterprise" target="_blank"&gt;Enterprise Tier&lt;/a&gt;&lt;/h4&gt; 
&lt;h4 align="center"&gt; &lt;a href="https://pypi.org/project/litellm/" target="_blank"&gt; &lt;img src="https://img.shields.io/pypi/v/litellm.svg?sanitize=true" alt="PyPI Version" /&gt; &lt;/a&gt; &lt;a href="https://www.ycombinator.com/companies/berriai"&gt; &lt;img src="https://img.shields.io/badge/Y%20Combinator-W23-orange?style=flat-square" alt="Y Combinator W23" /&gt; &lt;/a&gt; &lt;a href="https://wa.link/huol9n"&gt; &lt;img src="https://img.shields.io/static/v1?label=Chat%20on&amp;amp;message=WhatsApp&amp;amp;color=success&amp;amp;logo=WhatsApp&amp;amp;style=flat-square" alt="Whatsapp" /&gt; &lt;/a&gt; &lt;a href="https://discord.gg/wuPM9dRgDw"&gt; &lt;img src="https://img.shields.io/static/v1?label=Chat%20on&amp;amp;message=Discord&amp;amp;color=blue&amp;amp;logo=Discord&amp;amp;style=flat-square" alt="Discord" /&gt; &lt;/a&gt; &lt;a href="https://join.slack.com/share/enQtOTE0ODczMzk2Nzk4NC01YjUxNjY2YjBlYTFmNDRiZTM3NDFiYTM3MzVkODFiMDVjOGRjMmNmZTZkZTMzOWQzZGQyZWIwYjQ0MWExYmE3"&gt; &lt;img src="https://img.shields.io/static/v1?label=Chat%20on&amp;amp;message=Slack&amp;amp;color=black&amp;amp;logo=Slack&amp;amp;style=flat-square" alt="Slack" /&gt; &lt;/a&gt; &lt;/h4&gt; 
&lt;p&gt;LiteLLM manages:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Translate inputs to provider's &lt;code&gt;completion&lt;/code&gt;, &lt;code&gt;embedding&lt;/code&gt;, and &lt;code&gt;image_generation&lt;/code&gt; endpoints&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.litellm.ai/docs/completion/output"&gt;Consistent output&lt;/a&gt;, text responses will always be available at &lt;code&gt;['choices'][0]['message']['content']&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Retry/fallback logic across multiple deployments (e.g. Azure/OpenAI) - &lt;a href="https://docs.litellm.ai/docs/routing"&gt;Router&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Set Budgets &amp;amp; Rate limits per project, api key, model &lt;a href="https://docs.litellm.ai/docs/simple_proxy"&gt;LiteLLM Proxy Server (LLM Gateway)&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://github.com/BerriAI/litellm?tab=readme-ov-file#openai-proxy---docs"&gt;&lt;strong&gt;Jump to LiteLLM Proxy (LLM Gateway) Docs&lt;/strong&gt;&lt;/a&gt; &lt;br /&gt; &lt;a href="https://github.com/BerriAI/litellm?tab=readme-ov-file#supported-providers-docs"&gt;&lt;strong&gt;Jump to Supported LLM Providers&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;üö® &lt;strong&gt;Stable Release:&lt;/strong&gt; Use docker images with the &lt;code&gt;-stable&lt;/code&gt; tag. These have undergone 12 hour load tests, before being published. &lt;a href="https://docs.litellm.ai/docs/proxy/release_cycle"&gt;More information about the release cycle here&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Support for more providers. Missing a provider or LLM Platform, raise a &lt;a href="https://github.com/BerriAI/litellm/issues/new?assignees=&amp;amp;labels=enhancement&amp;amp;projects=&amp;amp;template=feature_request.yml&amp;amp;title=%5BFeature%5D%3A+"&gt;feature request&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;Usage (&lt;a href="https://docs.litellm.ai/docs/"&gt;&lt;strong&gt;Docs&lt;/strong&gt;&lt;/a&gt;)&lt;/h1&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] LiteLLM v1.0.0 now requires &lt;code&gt;openai&amp;gt;=1.0.0&lt;/code&gt;. Migration guide &lt;a href="https://docs.litellm.ai/docs/migration"&gt;here&lt;/a&gt; LiteLLM v1.40.14+ now requires &lt;code&gt;pydantic&amp;gt;=2.0.0&lt;/code&gt;. No changes required.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;a target="_blank" href="https://colab.research.google.com/github/BerriAI/litellm/blob/main/cookbook/liteLLM_Getting_Started.ipynb"&gt; &lt;img src="https://colab.research.google.com/assets/colab-badge.svg?sanitize=true" alt="Open In Colab" /&gt; &lt;/a&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;pip install litellm
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from litellm import completion
import os

## set ENV variables
os.environ["OPENAI_API_KEY"] = "your-openai-key"
os.environ["ANTHROPIC_API_KEY"] = "your-anthropic-key"

messages = [{ "content": "Hello, how are you?","role": "user"}]

# openai call
response = completion(model="openai/gpt-4o", messages=messages)

# anthropic call
response = completion(model="anthropic/claude-sonnet-4-20250514", messages=messages)
print(response)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Response (OpenAI Format)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
    "id": "chatcmpl-1214900a-6cdd-4148-b663-b5e2f642b4de",
    "created": 1751494488,
    "model": "claude-sonnet-4-20250514",
    "object": "chat.completion",
    "system_fingerprint": null,
    "choices": [
        {
            "finish_reason": "stop",
            "index": 0,
            "message": {
                "content": "Hello! I'm doing well, thank you for asking. I'm here and ready to help with whatever you'd like to discuss or work on. How are you doing today?",
                "role": "assistant",
                "tool_calls": null,
                "function_call": null
            }
        }
    ],
    "usage": {
        "completion_tokens": 39,
        "prompt_tokens": 13,
        "total_tokens": 52,
        "completion_tokens_details": null,
        "prompt_tokens_details": {
            "audio_tokens": null,
            "cached_tokens": 0
        },
        "cache_creation_input_tokens": 0,
        "cache_read_input_tokens": 0
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Call any model supported by a provider, with &lt;code&gt;model=&amp;lt;provider_name&amp;gt;/&amp;lt;model_name&amp;gt;&lt;/code&gt;. There might be provider-specific details here, so refer to &lt;a href="https://docs.litellm.ai/docs/providers"&gt;provider docs for more information&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Async (&lt;a href="https://docs.litellm.ai/docs/completion/stream#async-completion"&gt;Docs&lt;/a&gt;)&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from litellm import acompletion
import asyncio

async def test_get_response():
    user_message = "Hello, how are you?"
    messages = [{"content": user_message, "role": "user"}]
    response = await acompletion(model="openai/gpt-4o", messages=messages)
    return response

response = asyncio.run(test_get_response())
print(response)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Streaming (&lt;a href="https://docs.litellm.ai/docs/completion/stream"&gt;Docs&lt;/a&gt;)&lt;/h2&gt; 
&lt;p&gt;liteLLM supports streaming the model response back, pass &lt;code&gt;stream=True&lt;/code&gt; to get a streaming iterator in response. Streaming is supported for all models (Bedrock, Huggingface, TogetherAI, Azure, OpenAI, etc.)&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from litellm import completion
response = completion(model="openai/gpt-4o", messages=messages, stream=True)
for part in response:
    print(part.choices[0].delta.content or "")

# claude sonnet 4
response = completion('anthropic/claude-sonnet-4-20250514', messages, stream=True)
for part in response:
    print(part)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Response chunk (OpenAI Format)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
    "id": "chatcmpl-fe575c37-5004-4926-ae5e-bfbc31f356ca",
    "created": 1751494808,
    "model": "claude-sonnet-4-20250514",
    "object": "chat.completion.chunk",
    "system_fingerprint": null,
    "choices": [
        {
            "finish_reason": null,
            "index": 0,
            "delta": {
                "provider_specific_fields": null,
                "content": "Hello",
                "role": "assistant",
                "function_call": null,
                "tool_calls": null,
                "audio": null
            },
            "logprobs": null
        }
    ],
    "provider_specific_fields": null,
    "stream_options": null,
    "citations": null
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Logging Observability (&lt;a href="https://docs.litellm.ai/docs/observability/callbacks"&gt;Docs&lt;/a&gt;)&lt;/h2&gt; 
&lt;p&gt;LiteLLM exposes pre defined callbacks to send data to Lunary, MLflow, Langfuse, DynamoDB, s3 Buckets, Helicone, Promptlayer, Traceloop, Athina, Slack&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from litellm import completion

## set env variables for logging tools (when using MLflow, no API key set up is required)
os.environ["LUNARY_PUBLIC_KEY"] = "your-lunary-public-key"
os.environ["HELICONE_API_KEY"] = "your-helicone-auth-key"
os.environ["LANGFUSE_PUBLIC_KEY"] = ""
os.environ["LANGFUSE_SECRET_KEY"] = ""
os.environ["ATHINA_API_KEY"] = "your-athina-api-key"

os.environ["OPENAI_API_KEY"] = "your-openai-key"

# set callbacks
litellm.success_callback = ["lunary", "mlflow", "langfuse", "athina", "helicone"] # log input/output to lunary, langfuse, supabase, athina, helicone etc

#openai call
response = completion(model="openai/gpt-4o", messages=[{"role": "user", "content": "Hi üëã - i'm openai"}])
&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;LiteLLM Proxy Server (LLM Gateway) - (&lt;a href="https://docs.litellm.ai/docs/simple_proxy"&gt;Docs&lt;/a&gt;)&lt;/h1&gt; 
&lt;p&gt;Track spend + Load Balance across multiple projects&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://docs.litellm.ai/docs/hosted"&gt;Hosted Proxy (Preview)&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;The proxy provides:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;a href="https://docs.litellm.ai/docs/proxy/virtual_keys#custom-auth"&gt;Hooks for auth&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.litellm.ai/docs/proxy/logging#step-1---create-your-custom-litellm-callback-class"&gt;Hooks for logging&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.litellm.ai/docs/proxy/virtual_keys#tracking-spend"&gt;Cost tracking&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.litellm.ai/docs/proxy/users#set-rate-limits"&gt;Rate Limiting&lt;/a&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;üìñ Proxy Endpoints - &lt;a href="https://litellm-api.up.railway.app/"&gt;Swagger Docs&lt;/a&gt;&lt;/h2&gt; 
&lt;h2&gt;Quick Start Proxy - CLI&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;pip install 'litellm[proxy]'
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Step 1: Start litellm proxy&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;$ litellm --model huggingface/bigcode/starcoder

#INFO: Proxy running on http://0.0.0.0:4000
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Step 2: Make ChatCompletions Request to Proxy&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] üí° &lt;a href="https://docs.litellm.ai/docs/proxy/user_keys"&gt;Use LiteLLM Proxy with Langchain (Python, JS), OpenAI SDK (Python, JS) Anthropic SDK, Mistral SDK, LlamaIndex, Instructor, Curl&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import openai # openai v1.0.0+
client = openai.OpenAI(api_key="anything",base_url="http://0.0.0.0:4000") # set proxy to base_url
# request sent to model set on litellm proxy, `litellm --model`
response = client.chat.completions.create(model="gpt-3.5-turbo", messages = [
    {
        "role": "user",
        "content": "this is a test request, write a short poem"
    }
])

print(response)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Proxy Key Management (&lt;a href="https://docs.litellm.ai/docs/proxy/virtual_keys"&gt;Docs&lt;/a&gt;)&lt;/h2&gt; 
&lt;p&gt;Connect the proxy with a Postgres DB to create proxy keys&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Get the code
git clone https://github.com/BerriAI/litellm

# Go to folder
cd litellm

# Add the master key - you can change this after setup
echo 'LITELLM_MASTER_KEY="sk-1234"' &amp;gt; .env

# Add the litellm salt key - you cannot change this after adding a model
# It is used to encrypt / decrypt your LLM API Key credentials
# We recommend - https://1password.com/password-generator/
# password generator to get a random hash for litellm salt key
echo 'LITELLM_SALT_KEY="sk-1234"' &amp;gt;&amp;gt; .env

source .env

# Start
docker-compose up
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;UI on &lt;code&gt;/ui&lt;/code&gt; on your proxy server &lt;img src="https://github.com/BerriAI/litellm/assets/29436595/47c97d5e-b9be-4839-b28c-43d7f4f10033" alt="ui_3" /&gt;&lt;/p&gt; 
&lt;p&gt;Set budgets and rate limits across multiple projects &lt;code&gt;POST /key/generate&lt;/code&gt;&lt;/p&gt; 
&lt;h3&gt;Request&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;curl 'http://0.0.0.0:4000/key/generate' \
--header 'Authorization: Bearer sk-1234' \
--header 'Content-Type: application/json' \
--data-raw '{"models": ["gpt-3.5-turbo", "gpt-4", "claude-2"], "duration": "20m","metadata": {"user": "ishaan@berri.ai", "team": "core-infra"}}'
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Expected Response&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;{
    "key": "sk-kdEXbIqZRwEeEiHwdg7sFA", # Bearer token
    "expires": "2023-11-19T01:38:25.838000+00:00" # datetime object
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Supported Providers (&lt;a href="https://docs.litellm.ai/docs/providers"&gt;Docs&lt;/a&gt;)&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Provider&lt;/th&gt; 
   &lt;th&gt;&lt;a href="https://docs.litellm.ai/docs/#basic-usage"&gt;Completion&lt;/a&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;a href="https://docs.litellm.ai/docs/completion/stream#streaming-responses"&gt;Streaming&lt;/a&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;a href="https://docs.litellm.ai/docs/completion/stream#async-completion"&gt;Async Completion&lt;/a&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;a href="https://docs.litellm.ai/docs/completion/stream#async-streaming"&gt;Async Streaming&lt;/a&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;a href="https://docs.litellm.ai/docs/embedding/supported_embedding"&gt;Async Embedding&lt;/a&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;a href="https://docs.litellm.ai/docs/image_generation"&gt;Async Image Generation&lt;/a&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/openai"&gt;openai&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/meta_llama"&gt;Meta - Llama API&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/azure"&gt;azure&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/aiml"&gt;AI/ML API&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/aws_sagemaker"&gt;aws - sagemaker&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/bedrock"&gt;aws - bedrock&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/vertex"&gt;google - vertex_ai&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/palm"&gt;google - palm&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/gemini"&gt;google AI Studio - gemini&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/mistral"&gt;mistral ai api&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/cloudflare_workers"&gt;cloudflare AI Workers&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/cohere"&gt;cohere&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/anthropic"&gt;anthropic&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/empower"&gt;empower&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/huggingface"&gt;huggingface&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/replicate"&gt;replicate&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/togetherai"&gt;together_ai&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/openrouter"&gt;openrouter&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/ai21"&gt;ai21&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/baseten"&gt;baseten&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/vllm"&gt;vllm&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/nlp_cloud"&gt;nlp_cloud&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/aleph_alpha"&gt;aleph alpha&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/petals"&gt;petals&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/ollama"&gt;ollama&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/deepinfra"&gt;deepinfra&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/perplexity"&gt;perplexity-ai&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/groq"&gt;Groq AI&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/deepseek"&gt;Deepseek&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/anyscale"&gt;anyscale&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/watsonx"&gt;IBM - watsonx.ai&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/voyage"&gt;voyage ai&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/xinference"&gt;xinference [Xorbits Inference]&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/friendliai"&gt;FriendliAI&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/galadriel"&gt;Galadriel&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/gradient_ai"&gt;GradientAI&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://novita.ai/models/llm?utm_source=github_litellm&amp;amp;utm_medium=github_readme&amp;amp;utm_campaign=github_link"&gt;Novita AI&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/featherless_ai"&gt;Featherless AI&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/nebius"&gt;Nebius AI Studio&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;a href="https://docs.litellm.ai/docs/"&gt;&lt;strong&gt;Read the Docs&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Interested in contributing? Contributions to LiteLLM Python SDK, Proxy Server, and LLM integrations are both accepted and highly encouraged!&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Quick start:&lt;/strong&gt; &lt;code&gt;git clone&lt;/code&gt; ‚Üí &lt;code&gt;make install-dev&lt;/code&gt; ‚Üí &lt;code&gt;make format&lt;/code&gt; ‚Üí &lt;code&gt;make lint&lt;/code&gt; ‚Üí &lt;code&gt;make test-unit&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;See our comprehensive &lt;a href="https://raw.githubusercontent.com/BerriAI/litellm/main/CONTRIBUTING.md"&gt;Contributing Guide (CONTRIBUTING.md)&lt;/a&gt; for detailed instructions.&lt;/p&gt; 
&lt;h1&gt;Enterprise&lt;/h1&gt; 
&lt;p&gt;For companies that need better security, user management and professional support&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://calendly.com/d/4mp-gd3-k5k/litellm-1-1-onboarding-chat"&gt;Talk to founders&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;This covers:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;‚úÖ &lt;strong&gt;Features under the &lt;a href="https://docs.litellm.ai/docs/proxy/enterprise"&gt;LiteLLM Commercial License&lt;/a&gt;:&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;‚úÖ &lt;strong&gt;Feature Prioritization&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;‚úÖ &lt;strong&gt;Custom Integrations&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;‚úÖ &lt;strong&gt;Professional Support - Dedicated discord + slack&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;‚úÖ &lt;strong&gt;Custom SLAs&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;‚úÖ &lt;strong&gt;Secure access with Single Sign-On&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Contributing&lt;/h1&gt; 
&lt;p&gt;We welcome contributions to LiteLLM! Whether you're fixing bugs, adding features, or improving documentation, we appreciate your help.&lt;/p&gt; 
&lt;h2&gt;Quick Start for Contributors&lt;/h2&gt; 
&lt;p&gt;This requires poetry to be installed.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/BerriAI/litellm.git
cd litellm
make install-dev    # Install development dependencies
make format         # Format your code
make lint           # Run all linting checks
make test-unit      # Run unit tests
make format-check   # Check formatting only
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For detailed contributing guidelines, see &lt;a href="https://raw.githubusercontent.com/BerriAI/litellm/main/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Code Quality / Linting&lt;/h2&gt; 
&lt;p&gt;LiteLLM follows the &lt;a href="https://google.github.io/styleguide/pyguide.html"&gt;Google Python Style Guide&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Our automated checks include:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Black&lt;/strong&gt; for code formatting&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Ruff&lt;/strong&gt; for linting and code quality&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;MyPy&lt;/strong&gt; for type checking&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Circular import detection&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Import safety checks&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;All these checks must pass before your PR can be merged.&lt;/p&gt; 
&lt;h1&gt;Support / talk with founders&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://calendly.com/d/4mp-gd3-k5k/berriai-1-1-onboarding-litellm-hosted-version"&gt;Schedule Demo üëã&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://discord.gg/wuPM9dRgDw"&gt;Community Discord üí≠&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://join.slack.com/share/enQtOTE0ODczMzk2Nzk4NC01YjUxNjY2YjBlYTFmNDRiZTM3NDFiYTM3MzVkODFiMDVjOGRjMmNmZTZkZTMzOWQzZGQyZWIwYjQ0MWExYmE3"&gt;Community Slack üí≠&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Our numbers üìû +1 (770) 8783-106 / ‚Ä≠+1 (412) 618-6238‚Ä¨&lt;/li&gt; 
 &lt;li&gt;Our emails ‚úâÔ∏è &lt;a href="mailto:ishaan@berri.ai"&gt;ishaan@berri.ai&lt;/a&gt; / &lt;a href="mailto:krrish@berri.ai"&gt;krrish@berri.ai&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Why did we build this&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Need for simplicity&lt;/strong&gt;: Our code started to get extremely complicated managing &amp;amp; translating calls between Azure, OpenAI and Cohere.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Contributors&lt;/h1&gt; 
&lt;!-- ALL-CONTRIBUTORS-LIST:START - Do not remove or modify this section --&gt; 
&lt;!-- prettier-ignore-start --&gt; 
&lt;!-- markdownlint-disable --&gt; 
&lt;!-- markdownlint-restore --&gt; 
&lt;!-- prettier-ignore-end --&gt; 
&lt;!-- ALL-CONTRIBUTORS-LIST:END --&gt; 
&lt;a href="https://github.com/BerriAI/litellm/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=BerriAI/litellm" /&gt; &lt;/a&gt; 
&lt;h2&gt;Run in Developer mode&lt;/h2&gt; 
&lt;h3&gt;Services&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Setup .env file in root&lt;/li&gt; 
 &lt;li&gt;Run dependant services &lt;code&gt;docker-compose up db prometheus&lt;/code&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Backend&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;(In root) create virtual environment &lt;code&gt;python -m venv .venv&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Activate virtual environment &lt;code&gt;source .venv/bin/activate&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Install dependencies &lt;code&gt;pip install -e ".[all]"&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Start proxy backend &lt;code&gt;python3 /path/to/litellm/proxy_cli.py&lt;/code&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Frontend&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Navigate to &lt;code&gt;ui/litellm-dashboard&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Install dependencies &lt;code&gt;npm install&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Run &lt;code&gt;npm run dev&lt;/code&gt; to start the dashboard&lt;/li&gt; 
&lt;/ol&gt;</description>
    </item>
    
  </channel>
</rss>