<rss version="2.0">
  <channel>
    <title>GitHub Python Weekly Trending</title>
    <description>Weekly Trending of Python in GitHub</description>
    <pubDate>Sat, 30 Aug 2025 01:44:36 GMT</pubDate>
    <link>http://mshibanami.github.io/GitHubTrendingRSS</link>
    
    <item>
      <title>HKUDS/DeepCode</title>
      <link>https://github.com/HKUDS/DeepCode</link>
      <description>&lt;p&gt;"DeepCode: Open Agentic Coding (Paper2Code &amp; Text2Web &amp; Text2Backend)"&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;table style="border: none; margin: 0 auto; padding: 0; border-collapse: collapse;"&gt; 
  &lt;tbody&gt;
   &lt;tr&gt; 
    &lt;td align="center" style="vertical-align: middle; padding: 10px; border: none; width: 250px;"&gt; &lt;img src="https://raw.githubusercontent.com/HKUDS/DeepCode/main/assets/logo.png" alt="DeepCode Logo" width="200" style="margin: 0; padding: 0; display: block;" /&gt; &lt;/td&gt; 
    &lt;td align="left" style="vertical-align: middle; padding: 10px 0 10px 30px; border: none;"&gt; &lt;pre style="font-family: 'Courier New', monospace; font-size: 16px; color: #0EA5E9; margin: 0; padding: 0; text-shadow: 0 0 10px #0EA5E9, 0 0 20px rgba(14,165,233,0.5); line-height: 1.2; transform: skew(-1deg, 0deg); display: block;"&gt;    ██████╗ ███████╗███████╗██████╗  ██████╗ ██████╗ ██████╗ ███████╗
    ██╔══██╗██╔════╝██╔════╝██╔══██╗██╔════╝██╔═══██╗██╔══██╗██╔════╝
    ██║  ██║█████╗  █████╗  ██████╔╝██║     ██║   ██║██║  ██║█████╗
    ██║  ██║██╔══╝  ██╔══╝  ██╔═══╝ ██║     ██║   ██║██║  ██║██╔══╝
    ██████╔╝███████╗███████╗██║     ╚██████╗╚██████╔╝██████╔╝███████╗
    ╚═════╝ ╚══════╝╚══════╝╚═╝      ╚═════╝ ╚═════╝ ╚═════╝ ╚══════╝&lt;/pre&gt; &lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt;
 &lt;/table&gt; 
 &lt;div align="center"&gt; 
  &lt;a href="https://trendshift.io/repositories/14665" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/14665" alt="HKUDS%2FDeepCode | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt; 
 &lt;/div&gt; 
 &lt;!-- &lt;img src="https://readme-typing-svg.herokuapp.com?font=Russo+One&amp;size=28&amp;duration=2000&amp;pause=800&amp;color=06B6D4&amp;background=00000000&amp;center=true&amp;vCenter=true&amp;width=800&amp;height=50&amp;lines=%E2%9A%A1+OPEN+AGENTIC+CODING+%E2%9A%A1" alt="DeepCode Tech Subtitle" style="margin-top: 5px; filter: drop-shadow(0 0 12px #06B6D4) drop-shadow(0 0 24px rgba(6,182,212,0.4));"/&gt; --&gt; 
 &lt;h1&gt;&lt;img src="https://github.com/Zongwei9888/Experiment_Images/raw/43c585dca3d21b8e4b6390d835cdd34dc4b4b23d/DeepCode_images/title_logo.svg?sanitize=true" alt="DeepCode Logo" width="32" height="32" style="vertical-align: middle; margin-right: 8px;" /&gt; DeepCode: Open Agentic Coding&lt;/h1&gt; 
 &lt;h3&gt;&lt;em&gt;Advancing Code Generation with Multi-Agent Systems&lt;/em&gt;&lt;/h3&gt; 
 &lt;!-- &lt;p align="center"&gt;
  &lt;img src="https://img.shields.io/badge/Version-1.0.0-00d4ff?style=for-the-badge&amp;logo=rocket&amp;logoColor=white" alt="Version"&gt;

  &lt;img src="https://img.shields.io/badge/License-MIT-4ecdc4?style=for-the-badge&amp;logo=opensourceinitiative&amp;logoColor=white" alt="License"&gt;
  &lt;img src="https://img.shields.io/badge/AI-Multi--Agent-9b59b6?style=for-the-badge&amp;logo=brain&amp;logoColor=white" alt="AI"&gt;
  &lt;img src="https://img.shields.io/badge/HKU-Data_Intelligence_Lab-f39c12?style=for-the-badge&amp;logo=university&amp;logoColor=white" alt="HKU"&gt;
&lt;/p&gt; --&gt; 
 &lt;p&gt; &lt;a href="https://github.com/HKUDS/DeepCode/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/HKUDS/DeepCode?color=00d9ff&amp;amp;style=for-the-badge&amp;amp;logo=star&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/badge/🐍Python-3.13-4ecdc4?style=for-the-badge&amp;amp;logo=python&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt; &lt;a href="https://pypi.org/project/deepcode-hku/"&gt;&lt;img src="https://img.shields.io/pypi/v/deepcode-hku.svg?style=for-the-badge&amp;amp;logo=pypi&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e&amp;amp;color=ff6b6b" /&gt;&lt;/a&gt; &lt;/p&gt; 
 &lt;p&gt; &lt;a href="https://discord.gg/yF2MmDJyGJ"&gt;&lt;img src="https://img.shields.io/badge/💬Discord-Community-7289da?style=for-the-badge&amp;amp;logo=discord&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt;&lt;/a&gt; &lt;a href="https://github.com/HKUDS/DeepCode/issues/11"&gt;&lt;img src="https://img.shields.io/badge/💬WeChat-Group-07c160?style=for-the-badge&amp;amp;logo=wechat&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt;&lt;/a&gt; &lt;/p&gt; 
 &lt;div align="center"&gt; 
  &lt;div style="width: 100%; height: 2px; margin: 20px 0; background: linear-gradient(90deg, transparent, #00d9ff, transparent);"&gt;&lt;/div&gt; 
 &lt;/div&gt; 
 &lt;div align="center"&gt; 
  &lt;a href="https://raw.githubusercontent.com/HKUDS/DeepCode/main/#-quick-start" style="text-decoration: none;"&gt; &lt;img src="https://img.shields.io/badge/Quick%20Start-Get%20Started%20Now-00d9ff?style=for-the-badge&amp;amp;logo=rocket&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt; &lt;/a&gt; 
 &lt;/div&gt; 
 &lt;h3&gt;🖥️ &lt;strong&gt;Interface Showcase&lt;/strong&gt;&lt;/h3&gt; 
 &lt;table align="center" width="100%" style="border: none; border-collapse: collapse; margin: 30px 0;"&gt; 
  &lt;tbody&gt;
   &lt;tr&gt; 
    &lt;td width="50%" align="center" style="vertical-align: top; padding: 20px;"&gt; &lt;h4&gt;🖥️ &lt;strong&gt;CLI Interface&lt;/strong&gt;&lt;/h4&gt; &lt;p&gt;&lt;strong&gt;Terminal-Based Development&lt;/strong&gt;&lt;/p&gt; 
     &lt;div align="center"&gt; 
      &lt;img src="https://github.com/Zongwei9888/Experiment_Images/raw/8882a7313c504ca97ead6e7b36c51aa761b6a4f3/DeepCode_images/CLI.gif" alt="CLI Interface Demo" width="100%" style="border-radius: 10px; box-shadow: 0 8px 20px rgba(45,55,72,0.3); margin: 15px 0;" /&gt; 
      &lt;div style="background: linear-gradient(135deg, #2D3748 0%, #4A5568 100%); border-radius: 12px; padding: 15px; margin: 15px 0; color: white;"&gt; 
       &lt;strong&gt;🚀 Advanced Terminal Experience&lt;/strong&gt;
       &lt;br /&gt; 
       &lt;small&gt;⚡ Fast command-line workflow&lt;br /&gt;🔧 Developer-friendly interface&lt;br /&gt;📊 Real-time progress tracking&lt;/small&gt; 
      &lt;/div&gt; 
      &lt;p&gt;&lt;em&gt;Professional terminal interface for advanced users and CI/CD integration&lt;/em&gt;&lt;/p&gt; 
     &lt;/div&gt; &lt;/td&gt; 
    &lt;td width="50%" align="center" style="vertical-align: top; padding: 20px;"&gt; &lt;h4&gt;🌐 &lt;strong&gt;Web Interface&lt;/strong&gt;&lt;/h4&gt; &lt;p&gt;&lt;strong&gt;Visual Interactive Experience&lt;/strong&gt;&lt;/p&gt; 
     &lt;div align="center"&gt; 
      &lt;img src="https://github.com/Zongwei9888/Experiment_Images/raw/8882a7313c504ca97ead6e7b36c51aa761b6a4f3/DeepCode_images/UI.gif" alt="Web Interface Demo" width="100%" style="border-radius: 10px; box-shadow: 0 8px 20px rgba(14,165,233,0.3); margin: 15px 0;" /&gt; 
      &lt;div style="background: linear-gradient(135deg, #0EA5E9 0%, #00D4FF 100%); border-radius: 12px; padding: 15px; margin: 15px 0; color: white;"&gt; 
       &lt;strong&gt;🎨 Modern Web Dashboard&lt;/strong&gt;
       &lt;br /&gt; 
       &lt;small&gt;🖱️ Intuitive drag-and-drop&lt;br /&gt;📱 Responsive design&lt;br /&gt;🎯 Visual progress tracking&lt;/small&gt; 
      &lt;/div&gt; 
      &lt;p&gt;&lt;em&gt;Beautiful web interface with streamlined workflow for all skill levels&lt;/em&gt;&lt;/p&gt; 
     &lt;/div&gt; &lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt;
 &lt;/table&gt; 
 &lt;hr /&gt; 
 &lt;div align="center"&gt; 
  &lt;h3&gt;🎬 &lt;strong&gt;Introduction Video&lt;/strong&gt;&lt;/h3&gt; 
  &lt;div style="margin: 20px 0;"&gt; 
   &lt;a href="https://youtu.be/PRgmP8pOI08" target="_blank"&gt; &lt;img src="https://img.youtube.com/vi/PRgmP8pOI08/maxresdefault.jpg" alt="DeepCode Introduction Video" width="75%" style="border-radius: 12px; box-shadow: 0 8px 25px rgba(0,0,0,0.15); transition: transform 0.3s ease;" /&gt; &lt;/a&gt; 
  &lt;/div&gt; 
  &lt;p&gt;&lt;em&gt;🎯 &lt;strong&gt;Watch our complete introduction&lt;/strong&gt; - See how DeepCode transforms research papers and natural language into production-ready code&lt;/em&gt;&lt;/p&gt; 
  &lt;p&gt; &lt;a href="https://youtu.be/PRgmP8pOI08" target="_blank"&gt; &lt;img src="https://img.shields.io/badge/▶️_Watch_Video-FF0000?style=for-the-badge&amp;amp;logo=youtube&amp;amp;logoColor=white" alt="Watch Video" /&gt; &lt;/a&gt; &lt;/p&gt; 
 &lt;/div&gt; 
 &lt;hr /&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;&lt;em&gt;"Where AI Agents Transform Ideas into Production-Ready Code"&lt;/em&gt;&lt;/p&gt; 
 &lt;/blockquote&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h2&gt;📑 Table of Contents&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/DeepCode/main/#-key-features"&gt;🚀 Key Features&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/DeepCode/main/#%EF%B8%8F-architecture"&gt;🏗️ Architecture&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/DeepCode/main/#-quick-start"&gt;🚀 Quick Start&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/DeepCode/main/#-examples"&gt;💡 Examples&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/DeepCode/main/#-live-demonstrations"&gt;🎬 Live Demonstrations&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/DeepCode/main/#-star-history"&gt;⭐ Star History&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/DeepCode/main/#-license"&gt;📄 License&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;🚀 Key Features&lt;/h2&gt; 
&lt;br /&gt; 
&lt;table align="center" width="100%" style="border: none; table-layout: fixed;"&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td width="30%" align="center" style="vertical-align: top; padding: 20px;"&gt; 
    &lt;div style="height: 80px; display: flex; align-items: center; justify-content: center;"&gt; 
     &lt;h3 style="margin: 0; padding: 0;"&gt;🚀 &lt;strong&gt;Paper2Code&lt;/strong&gt;&lt;/h3&gt; 
    &lt;/div&gt; 
    &lt;div align="center" style="margin: 15px 0;"&gt; 
     &lt;img src="https://img.shields.io/badge/ALGORITHM-IMPLEMENTATION-ff6b6b?style=for-the-badge&amp;amp;logo=algorithm&amp;amp;logoColor=white" alt="Algorithm Badge" /&gt; 
    &lt;/div&gt; 
    &lt;div style="height: 80px; display: flex; align-items: center; justify-content: center;"&gt; 
     &lt;p align="center"&gt;&lt;strong&gt;Automated Implementation of Complex Algorithms&lt;/strong&gt;&lt;/p&gt; 
    &lt;/div&gt; 
    &lt;div style="height: 60px; display: flex; align-items: center; justify-content: center;"&gt; 
     &lt;p align="center"&gt;Effortlessly converts complex algorithms from research papers into &lt;strong&gt;high-quality&lt;/strong&gt;, &lt;strong&gt;production-ready&lt;/strong&gt; code, accelerating algorithm reproduction.&lt;/p&gt; 
    &lt;/div&gt; &lt;/td&gt; 
   &lt;td width="30%" align="center" style="vertical-align: top; padding: 20px;"&gt; 
    &lt;div style="height: 80px; display: flex; align-items: center; justify-content: center;"&gt; 
     &lt;h3 style="margin: 0; padding: 0;"&gt;🎨 &lt;strong&gt;Text2Web&lt;/strong&gt;&lt;/h3&gt; 
    &lt;/div&gt; 
    &lt;div align="center" style="margin: 15px 0;"&gt; 
     &lt;img src="https://img.shields.io/badge/FRONTEND-DEVELOPMENT-4ecdc4?style=for-the-badge&amp;amp;logo=react&amp;amp;logoColor=white" alt="Frontend Badge" /&gt; 
    &lt;/div&gt; 
    &lt;div style="height: 80px; display: flex; align-items: center; justify-content: center;"&gt; 
     &lt;p align="center"&gt;&lt;strong&gt;Automated Front-End Web Development&lt;/strong&gt;&lt;/p&gt; 
    &lt;/div&gt; 
    &lt;div style="height: 60px; display: flex; align-items: center; justify-content: center;"&gt; 
     &lt;p align="center"&gt;Translates plain textual descriptions into &lt;strong&gt;fully functional&lt;/strong&gt;, &lt;strong&gt;visually appealing&lt;/strong&gt; front-end web code for rapid interface creation.&lt;/p&gt; 
    &lt;/div&gt; &lt;/td&gt; 
   &lt;td width="30%" align="center" style="vertical-align: top; padding: 20px;"&gt; 
    &lt;div style="height: 80px; display: flex; align-items: center; justify-content: center;"&gt; 
     &lt;h3 style="margin: 0; padding: 0;"&gt;⚙️ &lt;strong&gt;Text2Backend&lt;/strong&gt;&lt;/h3&gt; 
    &lt;/div&gt; 
    &lt;div align="center" style="margin: 15px 0;"&gt; 
     &lt;img src="https://img.shields.io/badge/BACKEND-DEVELOPMENT-9b59b6?style=for-the-badge&amp;amp;logo=server&amp;amp;logoColor=white" alt="Backend Badge" /&gt; 
    &lt;/div&gt; 
    &lt;div style="height: 80px; display: flex; align-items: center; justify-content: center;"&gt; 
     &lt;p align="center"&gt;&lt;strong&gt;Automated Back-End Development&lt;/strong&gt;&lt;/p&gt; 
    &lt;/div&gt; 
    &lt;div style="height: 60px; display: flex; align-items: center; justify-content: center;"&gt; 
     &lt;p align="center"&gt;Generates &lt;strong&gt;efficient&lt;/strong&gt;, &lt;strong&gt;scalable&lt;/strong&gt;, and &lt;strong&gt;feature-rich&lt;/strong&gt; back-end code from simple text inputs, streamlining server-side development.&lt;/p&gt; 
    &lt;/div&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;br /&gt; 
&lt;h3&gt;🎯 &lt;strong&gt;Autonomous Multi-Agent Workflow&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;The Challenges&lt;/strong&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;📄 &lt;strong&gt;Implementation Complexity&lt;/strong&gt;: Converting academic papers and complex algorithms into working code requires significant technical effort and domain expertise&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;🔬 &lt;strong&gt;Research Bottleneck&lt;/strong&gt;: Researchers spend valuable time implementing algorithms instead of focusing on their core research and discovery work&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;⏱️ &lt;strong&gt;Development Delays&lt;/strong&gt;: Product teams experience long wait times between concept and testable prototypes, slowing down innovation cycles&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;🔄 &lt;strong&gt;Repetitive Coding&lt;/strong&gt;: Developers repeatedly implement similar patterns and functionality instead of building on existing solutions&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;DeepCode&lt;/strong&gt; addresses these workflow inefficiencies by providing reliable automation for common development tasks, streamlining your development workflow from concept to code.&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;pre&gt;&lt;code class="language-mermaid"&gt;flowchart LR
    A["📄 Research Papers&amp;lt;br/&amp;gt;💬 Text Prompts&amp;lt;br/&amp;gt;🌐 URLs &amp;amp; Document&amp;lt;br/&amp;gt;📎 Files: PDF, DOC, PPTX, TXT, HTML"] --&amp;gt; B["🧠 DeepCode&amp;lt;br/&amp;gt;Multi-Agent Engine"]
    B --&amp;gt; C["🚀 Algorithm Implementation &amp;lt;br/&amp;gt;🎨 Frontend Development &amp;lt;br/&amp;gt;⚙️ Backend Development"]

    style A fill:#ff6b6b,stroke:#c0392b,stroke-width:2px,color:#000
    style B fill:#00d4ff,stroke:#0984e3,stroke-width:3px,color:#000
    style C fill:#00b894,stroke:#00a085,stroke-width:2px,color:#000
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h2&gt;🏗️ Architecture&lt;/h2&gt; 
&lt;h3&gt;📊 &lt;strong&gt;System Overview&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;DeepCode&lt;/strong&gt; is an AI-powered development platform that automates code generation and implementation tasks. Our multi-agent system handles the complexity of translating requirements into functional, well-structured code, allowing you to focus on innovation rather than implementation details.&lt;/p&gt; 
&lt;p&gt;🎯 &lt;strong&gt;Technical Capabilities&lt;/strong&gt;:&lt;/p&gt; 
&lt;p&gt;🧬 &lt;strong&gt;Research-to-Production Pipeline&lt;/strong&gt;&lt;br /&gt; Multi-modal document analysis engine that extracts algorithmic logic and mathematical models from academic papers. Generates optimized implementations with proper data structures while preserving computational complexity characteristics.&lt;/p&gt; 
&lt;p&gt;🪄 &lt;strong&gt;Natural Language Code Synthesis&lt;/strong&gt;&lt;br /&gt; Context-aware code generation using fine-tuned language models trained on curated code repositories. Maintains architectural consistency across modules while supporting multiple programming languages and frameworks.&lt;/p&gt; 
&lt;p&gt;⚡ &lt;strong&gt;Automated Prototyping Engine&lt;/strong&gt;&lt;br /&gt; Intelligent scaffolding system generating complete application structures including database schemas, API endpoints, and frontend components. Uses dependency analysis to ensure scalable architecture from initial generation.&lt;/p&gt; 
&lt;p&gt;💎 &lt;strong&gt;Quality Assurance Automation&lt;/strong&gt;&lt;br /&gt; Integrated static analysis with automated unit test generation and documentation synthesis. Employs AST analysis for code correctness and property-based testing for comprehensive coverage.&lt;/p&gt; 
&lt;p&gt;🔮 &lt;strong&gt;CodeRAG Integration System&lt;/strong&gt;&lt;br /&gt; Advanced retrieval-augmented generation combining semantic vector embeddings with graph-based dependency analysis. Automatically discovers optimal libraries and implementation patterns from large-scale code corpus.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h3&gt;🔧 &lt;strong&gt;Core Techniques&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;🧠 &lt;strong&gt;Intelligent Orchestration Agent&lt;/strong&gt;: Central decision-making system that coordinates workflow phases and analyzes requirements. Employs dynamic planning algorithms to adapt execution strategies in real-time based on evolving project complexity. Dynamically selects optimal processing strategies for each implementation step. &lt;br /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;💾 &lt;strong&gt;Efficient Memory Mechanism&lt;/strong&gt;: Advanced context engineering system that manages large-scale code contexts efficiently. Implements hierarchical memory structures with intelligent compression for handling complex codebases. This component enables instant retrieval of implementation patterns and maintains semantic coherence across extended development sessions. &lt;br /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;🔍 &lt;strong&gt;Advanced CodeRAG System&lt;/strong&gt;: Global code comprehension engine that analyzes complex inter-dependencies across repositories. Performs cross-codebase relationship mapping to understand architectural patterns from a holistic perspective. This module leverages dependency graphs and semantic analysis to provide globally-aware code recommendations during implementation.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h3&gt;🤖 &lt;strong&gt;Multi-Agent Architecture of DeepCode&lt;/strong&gt;:&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;🎯 Central Orchestrating Agent&lt;/strong&gt;: Orchestrates entire workflow execution and makes strategic decisions. Coordinates specialized agents based on input complexity analysis. Implements dynamic task planning and resource allocation algorithms. &lt;br /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;📝 Intent Understanding Agent&lt;/strong&gt;: Performs deep semantic analysis of user requirements to decode complex intentions. Extracts functional specifications and technical constraints through advanced NLP processing. Transforms ambiguous human descriptions into precise, actionable development specifications with structured task decomposition. &lt;br /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;📄 Document Parsing Agent&lt;/strong&gt;: Processes complex technical documents and research papers with advanced parsing capabilities. Extracts algorithms and methodologies using document understanding models. Converts academic concepts into practical implementation specifications through intelligent content analysis. &lt;br /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;🏗️ Code Planning Agent&lt;/strong&gt;: Performs architectural design and technology stack optimization. Dynamic planning for adaptive development roadmaps. Enforces coding standards and generates modular structures through automated design pattern selection.&lt;br /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;🔍 Code Reference Mining Agent&lt;/strong&gt;: Discovers relevant repositories and frameworks through intelligent search algorithms. Analyzes codebases for compatibility and integration potential. Provides recommendations based on similarity metrics and automated dependency analysis. &lt;br /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;📚 Code Indexing Agent&lt;/strong&gt;: Builds comprehensive knowledge graphs of discovered codebases. Maintains semantic relationships between code components. Enables intelligent retrieval and cross-reference capabilities. &lt;br /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;🧬 Code Generation Agent&lt;/strong&gt;: Synthesizes gathered information into executable code implementations. Creates functional interfaces and integrates discovered components. Generates comprehensive test suites and documentation for reproducibility.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h4&gt;🛠️ &lt;strong&gt;Implementation Tools Matrix&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;&lt;strong&gt;🔧 Powered by MCP (Model Context Protocol)&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;DeepCode leverages the &lt;strong&gt;Model Context Protocol (MCP)&lt;/strong&gt; standard to seamlessly integrate with various tools and services. This standardized approach ensures reliable communication between AI agents and external systems, enabling powerful automation capabilities.&lt;/p&gt; 
&lt;h5&gt;📡 &lt;strong&gt;MCP Servers &amp;amp; Tools&lt;/strong&gt;&lt;/h5&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;🛠️ &lt;strong&gt;MCP Server&lt;/strong&gt;&lt;/th&gt; 
   &lt;th&gt;🔧 &lt;strong&gt;Primary Function&lt;/strong&gt;&lt;/th&gt; 
   &lt;th&gt;💡 &lt;strong&gt;Purpose &amp;amp; Capabilities&lt;/strong&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;🔍 brave&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Web Search Engine&lt;/td&gt; 
   &lt;td&gt;Real-time information retrieval via Brave Search API&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;🌐 bocha-mcp&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Alternative Search&lt;/td&gt; 
   &lt;td&gt;Secondary search option with independent API access&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;📂 filesystem&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;File System Operations&lt;/td&gt; 
   &lt;td&gt;Local file and directory management, read/write operations&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;🌐 fetch&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Web Content Retrieval&lt;/td&gt; 
   &lt;td&gt;Fetch and extract content from URLs and web resources&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;📥 github-downloader&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Repository Management&lt;/td&gt; 
   &lt;td&gt;Clone and download GitHub repositories for analysis&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;📋 file-downloader&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Document Processing&lt;/td&gt; 
   &lt;td&gt;Download and convert files (PDF, DOCX, etc.) to Markdown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;⚡ command-executor&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;System Commands&lt;/td&gt; 
   &lt;td&gt;Execute bash/shell commands for environment management&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;🧬 code-implementation&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Code Generation Hub&lt;/td&gt; 
   &lt;td&gt;Comprehensive code reproduction with execution and testing&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;📚 code-reference-indexer&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Smart Code Search&lt;/td&gt; 
   &lt;td&gt;Intelligent indexing and search of code repositories&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;📄 document-segmentation&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Smart Document Analysis&lt;/td&gt; 
   &lt;td&gt;Intelligent document segmentation for large papers and technical documents&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h5&gt;🔧 &lt;strong&gt;Legacy Tool Functions&lt;/strong&gt; &lt;em&gt;(for reference)&lt;/em&gt;&lt;/h5&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;🛠️ &lt;strong&gt;Function&lt;/strong&gt;&lt;/th&gt; 
   &lt;th&gt;🎯 &lt;strong&gt;Usage Context&lt;/strong&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;📄 read_code_mem&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Efficient code context retrieval from memory&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;✍️ write_file&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Direct file content generation and modification&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;🐍 execute_python&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Python code testing and validation&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;📁 get_file_structure&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Project structure analysis and organization&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;⚙️ set_workspace&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Dynamic workspace and environment configuration&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;📊 get_operation_history&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Process monitoring and operation tracking&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;hr /&gt; 
&lt;p&gt;🎛️ &lt;strong&gt;Multi-Interface Framework&lt;/strong&gt;&lt;br /&gt; RESTful API with CLI and web frontends featuring real-time code streaming, interactive debugging, and extensible plugin architecture for CI/CD integration.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;🚀 Multi-Agent Intelligent Pipeline:&lt;/strong&gt;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;h3&gt;🌟 &lt;strong&gt;Intelligence Processing Flow&lt;/strong&gt;&lt;/h3&gt; 
 &lt;table align="center" width="100%" style="border: none; border-collapse: collapse;"&gt; 
  &lt;tbody&gt;
   &lt;tr&gt; 
    &lt;td colspan="3" align="center" style="padding: 20px; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); border-radius: 15px; color: white; font-weight: bold;"&gt; 💡 &lt;strong&gt;INPUT LAYER&lt;/strong&gt;&lt;br /&gt; 📄 Research Papers • 💬 Natural Language • 🌐 URLs • 📋 Requirements &lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt;
    &lt;td colspan="3" height="20"&gt;&lt;/td&gt;
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td colspan="3" align="center" style="padding: 15px; background: linear-gradient(135deg, #ff6b6b 0%, #ee5a24 100%); border-radius: 12px; color: white; font-weight: bold;"&gt; 🎯 &lt;strong&gt;CENTRAL ORCHESTRATION&lt;/strong&gt;&lt;br /&gt; Strategic Decision Making • Workflow Coordination • Agent Management &lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt;
    &lt;td colspan="3" height="15"&gt;&lt;/td&gt;
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center" style="padding: 12px; background: linear-gradient(135deg, #3742fa 0%, #2f3542 100%); border-radius: 10px; color: white; width: 50%;"&gt; 📝 &lt;strong&gt;TEXT ANALYSIS&lt;/strong&gt;&lt;br /&gt; &lt;small&gt;Requirement Processing&lt;/small&gt; &lt;/td&gt; 
    &lt;td width="10"&gt;&lt;/td&gt; 
    &lt;td align="center" style="padding: 12px; background: linear-gradient(135deg, #8c7ae6 0%, #9c88ff 100%); border-radius: 10px; color: white; width: 50%;"&gt; 📄 &lt;strong&gt;DOCUMENT ANALYSIS&lt;/strong&gt;&lt;br /&gt; &lt;small&gt;Paper &amp;amp; Spec Processing&lt;/small&gt; &lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt;
    &lt;td colspan="3" height="15"&gt;&lt;/td&gt;
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td colspan="3" align="center" style="padding: 15px; background: linear-gradient(135deg, #00d2d3 0%, #54a0ff 100%); border-radius: 12px; color: white; font-weight: bold;"&gt; 📋 &lt;strong&gt;REPRODUCTION PLANNING&lt;/strong&gt;&lt;br /&gt; Deep Paper Analysis • Code Requirements Parsing • Reproduction Strategy Development &lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt;
    &lt;td colspan="3" height="15"&gt;&lt;/td&gt;
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center" style="padding: 12px; background: linear-gradient(135deg, #ffa726 0%, #ff7043 100%); border-radius: 10px; color: white; width: 50%;"&gt; 🔍 &lt;strong&gt;REFERENCE ANALYSIS&lt;/strong&gt;&lt;br /&gt; &lt;small&gt;Repository Discovery&lt;/small&gt; &lt;/td&gt; 
    &lt;td width="10"&gt;&lt;/td&gt; 
    &lt;td align="center" style="padding: 12px; background: linear-gradient(135deg, #e056fd 0%, #f368e0 100%); border-radius: 10px; color: white; width: 50%;"&gt; 📚 &lt;strong&gt;CODE INDEXING&lt;/strong&gt;&lt;br /&gt; &lt;small&gt;Knowledge Graph Building&lt;/small&gt; &lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt;
    &lt;td colspan="3" height="15"&gt;&lt;/td&gt;
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td colspan="3" align="center" style="padding: 15px; background: linear-gradient(135deg, #26de81 0%, #20bf6b 100%); border-radius: 12px; color: white; font-weight: bold;"&gt; 🧬 &lt;strong&gt;CODE IMPLEMENTATION&lt;/strong&gt;&lt;br /&gt; Implementation Generation • Testing • Documentation &lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt;
    &lt;td colspan="3" height="15"&gt;&lt;/td&gt;
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td colspan="3" align="center" style="padding: 20px; background: linear-gradient(135deg, #045de9 0%, #09c6f9 100%); border-radius: 15px; color: white; font-weight: bold;"&gt; ⚡ &lt;strong&gt;OUTPUT DELIVERY&lt;/strong&gt;&lt;br /&gt; 📦 Complete Codebase • 🧪 Test Suite • 📚 Documentation • 🚀 Deployment Ready &lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt;
 &lt;/table&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;br /&gt; 
 &lt;h3&gt;🔄 &lt;strong&gt;Process Intelligence Features&lt;/strong&gt;&lt;/h3&gt; 
 &lt;table align="center" style="border: none;"&gt; 
  &lt;tbody&gt;
   &lt;tr&gt; 
    &lt;td align="center" width="25%" style="padding: 15px;"&gt; 
     &lt;div style="background: #f8f9fa; border-radius: 10px; padding: 15px; border-left: 4px solid #ff6b6b;"&gt; 
      &lt;h4&gt;🎯 Adaptive Flow&lt;/h4&gt; 
      &lt;p&gt;&lt;small&gt;Dynamic agent selection based on input complexity&lt;/small&gt;&lt;/p&gt; 
     &lt;/div&gt; &lt;/td&gt; 
    &lt;td align="center" width="25%" style="padding: 15px;"&gt; 
     &lt;div style="background: #f8f9fa; border-radius: 10px; padding: 15px; border-left: 4px solid #4ecdc4;"&gt; 
      &lt;h4&gt;🧠 Smart Coordination&lt;/h4&gt; 
      &lt;p&gt;&lt;small&gt;Intelligent task distribution and parallel processing&lt;/small&gt;&lt;/p&gt; 
     &lt;/div&gt; &lt;/td&gt; 
    &lt;td align="center" width="25%" style="padding: 15px;"&gt; 
     &lt;div style="background: #f8f9fa; border-radius: 10px; padding: 15px; border-left: 4px solid #45b7d1;"&gt; 
      &lt;h4&gt;🔍 Context Awareness&lt;/h4&gt; 
      &lt;p&gt;&lt;small&gt;Deep understanding through CodeRAG integration&lt;/small&gt;&lt;/p&gt; 
     &lt;/div&gt; &lt;/td&gt; 
    &lt;td align="center" width="25%" style="padding: 15px;"&gt; 
     &lt;div style="background: #f8f9fa; border-radius: 10px; padding: 15px; border-left: 4px solid #96ceb4;"&gt; 
      &lt;h4&gt;⚡ Quality Assurance&lt;/h4&gt; 
      &lt;p&gt;&lt;small&gt;Automated testing and validation throughout&lt;/small&gt;&lt;/p&gt; 
     &lt;/div&gt; &lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt;
 &lt;/table&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h2&gt;🚀 Quick Start&lt;/h2&gt; 
&lt;h3&gt;📦 &lt;strong&gt;Step 1: Installation&lt;/strong&gt;&lt;/h3&gt; 
&lt;h4&gt;⚡ &lt;strong&gt;Direct Installation (Recommended)&lt;/strong&gt;&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# 🚀 Install DeepCode package directly
pip install deepcode-hku

# 🔑 Download configuration files
curl -O https://raw.githubusercontent.com/HKUDS/DeepCode/main/mcp_agent.config.yaml
curl -O https://raw.githubusercontent.com/HKUDS/DeepCode/main/mcp_agent.secrets.yaml

# 🔑 Configure API keys (required)
# Edit mcp_agent.secrets.yaml with your API keys and base_url:
# - openai: api_key, base_url (for OpenAI/custom endpoints)
# - anthropic: api_key (for Claude models)

# 🔑 Configure search API keys for web search (optional)
# Edit mcp_agent.config.yaml to set your API keys:
# - For Brave Search: Set BRAVE_API_KEY: "your_key_here" in brave.env section (line ~28)
# - For Bocha-MCP: Set BOCHA_API_KEY: "your_key_here" in bocha-mcp.env section (line ~74)

# 📄 Configure document segmentation (optional)
# Edit mcp_agent.config.yaml to control document processing:
# - enabled: true/false (whether to use intelligent document segmentation)
# - size_threshold_chars: 50000 (document size threshold to trigger segmentation)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;🔧 &lt;strong&gt;Development Installation (From Source)&lt;/strong&gt;&lt;/h4&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;📂 Click to expand development installation options&lt;/strong&gt;&lt;/summary&gt; 
 &lt;h5&gt;🔥 &lt;strong&gt;Using UV (Recommended for Development)&lt;/strong&gt;&lt;/h5&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# 🔽 Clone the repository
git clone https://github.com/HKUDS/DeepCode.git
cd DeepCode/

# 📦 Install UV package manager
curl -LsSf https://astral.sh/uv/install.sh | sh

# 🔧 Install dependencies with UV
uv venv --python=3.13
source .venv/bin/activate  # On Windows: .venv\Scripts\activate
uv pip install -r requirements.txt

# 🔑 Configure API keys (required)
# Edit mcp_agent.secrets.yaml with your API keys and base_url:
# - openai: api_key, base_url (for OpenAI/custom endpoints)
# - anthropic: api_key (for Claude models)

# 🔑 Configure search API keys for web search (optional)
# Edit mcp_agent.config.yaml to set your API keys:
# - For Brave Search: Set BRAVE_API_KEY: "your_key_here" in brave.env section (line ~28)
# - For Bocha-MCP: Set BOCHA_API_KEY: "your_key_here" in bocha-mcp.env section (line ~74)

# 📄 Configure document segmentation (optional)
# Edit mcp_agent.config.yaml to control document processing:
# - enabled: true/false (whether to use intelligent document segmentation)
# - size_threshold_chars: 50000 (document size threshold to trigger segmentation)
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h5&gt;🐍 &lt;strong&gt;Using Traditional pip&lt;/strong&gt;&lt;/h5&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# 🔽 Clone the repository
git clone https://github.com/HKUDS/DeepCode.git
cd DeepCode/

# 📦 Install dependencies
pip install -r requirements.txt

# 🔑 Configure API keys (required)
# Edit mcp_agent.secrets.yaml with your API keys and base_url:
# - openai: api_key, base_url (for OpenAI/custom endpoints)
# - anthropic: api_key (for Claude models)

# 🔑 Configure search API keys for web search (optional)
# Edit mcp_agent.config.yaml to set your API keys:
# - For Brave Search: Set BRAVE_API_KEY: "your_key_here" in brave.env section (line ~28)
# - For Bocha-MCP: Set BOCHA_API_KEY: "your_key_here" in bocha-mcp.env section (line ~74)

# 📄 Configure document segmentation (optional)
# Edit mcp_agent.config.yaml to control document processing:
# - enabled: true/false (whether to use intelligent document segmentation)
# - size_threshold_chars: 50000 (document size threshold to trigger segmentation)
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h4&gt;🪟 &lt;strong&gt;Windows Users: Additional MCP Server Configuration&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;If you're using Windows, you may need to configure MCP servers manually in &lt;code&gt;mcp_agent.config.yaml&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# 1. Install MCP servers globally
npm i -g @modelcontextprotocol/server-brave-search
npm i -g @modelcontextprotocol/server-filesystem

# 2. Find your global node_modules path
npm -g root
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then update your &lt;code&gt;mcp_agent.config.yaml&lt;/code&gt; to use absolute paths:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;mcp:
  servers:
    brave:
      command: "node"
      args: ["C:/Program Files/nodejs/node_modules/@modelcontextprotocol/server-brave-search/dist/index.js"]
    filesystem:
      command: "node"
      args: ["C:/Program Files/nodejs/node_modules/@modelcontextprotocol/server-filesystem/dist/index.js", "."]
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: Replace the path with your actual global node_modules path from step 2.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;🔍 &lt;strong&gt;Search Server Configuration (Optional)&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;DeepCode supports multiple search servers for web search functionality. You can configure your preferred option in &lt;code&gt;mcp_agent.config.yaml&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;# Default search server configuration
# Options: "brave" or "bocha-mcp"
default_search_server: "brave"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Available Options:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;🔍 Brave Search&lt;/strong&gt; (&lt;code&gt;"brave"&lt;/code&gt;):&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Default option with high-quality search results&lt;/li&gt; 
   &lt;li&gt;Requires BRAVE_API_KEY configuration&lt;/li&gt; 
   &lt;li&gt;Recommended for most users&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;🌐 Bocha-MCP&lt;/strong&gt; (&lt;code&gt;"bocha-mcp"&lt;/code&gt;):&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Alternative search server option&lt;/li&gt; 
   &lt;li&gt;Requires BOCHA_API_KEY configuration&lt;/li&gt; 
   &lt;li&gt;Uses local Python server implementation&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;API Key Configuration in mcp_agent.config.yaml:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;# For Brave Search (default) - around line 28
brave:
  command: "npx"
  args: ["-y", "@modelcontextprotocol/server-brave-search"]
  env:
    BRAVE_API_KEY: "your_brave_api_key_here"

# For Bocha-MCP (alternative) - around line 74
bocha-mcp:
  command: "python"
  args: ["tools/bocha_search_server.py"]
  env:
    PYTHONPATH: "."
    BOCHA_API_KEY: "your_bocha_api_key_here"
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;💡 Tip&lt;/strong&gt;: Both search servers require API key configuration. Choose the one that best fits your API access and requirements.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;⚡ &lt;strong&gt;Step 2: Launch Application&lt;/strong&gt;&lt;/h3&gt; 
&lt;h4&gt;🚀 &lt;strong&gt;Using Installed Package (Recommended)&lt;/strong&gt;&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# 🌐 Launch web interface directly
deepcode

# The application will automatically start at http://localhost:8501
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;🛠️ &lt;strong&gt;Using Source Code&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;Choose your preferred interface:&lt;/p&gt; 
&lt;h5&gt;🌐 &lt;strong&gt;Web Interface&lt;/strong&gt; (Recommended)&lt;/h5&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Using UV
uv run streamlit run ui/streamlit_app.py
# Or using traditional Python
streamlit run ui/streamlit_app.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://img.shields.io/badge/Access-localhost:8501-00d4ff?style=flat-square&amp;amp;logo=streamlit&amp;amp;logoColor=white" alt="Web Access" /&gt; 
&lt;/div&gt; 
&lt;h5&gt;🖥️ &lt;strong&gt;CLI Interface&lt;/strong&gt; (Advanced Users)&lt;/h5&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Using UV
uv run python cli/main_cli.py
# Or using traditional Python
python cli/main_cli.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://img.shields.io/badge/Mode-Interactive_Terminal-9b59b6?style=flat-square&amp;amp;logo=terminal&amp;amp;logoColor=white" alt="CLI Mode" /&gt; 
&lt;/div&gt; 
&lt;h3&gt;🎯 &lt;strong&gt;Step 3: Generate Code&lt;/strong&gt;&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;📄 Input&lt;/strong&gt;: Upload your research paper, provide requirements, or paste a URL&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;🤖 Processing&lt;/strong&gt;: Watch the multi-agent system analyze and plan&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;⚡ Output&lt;/strong&gt;: Receive production-ready code with tests and documentation&lt;/li&gt; 
&lt;/ol&gt; 
&lt;hr /&gt; 
&lt;h2&gt;💡 Examples&lt;/h2&gt; 
&lt;h3&gt;🎬 &lt;strong&gt;Live Demonstrations&lt;/strong&gt;&lt;/h3&gt; 
&lt;table align="center"&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td width="33%" align="center"&gt; &lt;h4&gt;📄 &lt;strong&gt;Paper2Code Demo&lt;/strong&gt;&lt;/h4&gt; &lt;p&gt;&lt;strong&gt;Research to Implementation&lt;/strong&gt;&lt;/p&gt; 
    &lt;div align="center"&gt; 
     &lt;a href="https://www.youtube.com/watch?v=MQZYpLkzsbw"&gt; &lt;img src="https://img.youtube.com/vi/MQZYpLkzsbw/maxresdefault.jpg" alt="Paper2Code Demo" width="100%" style="border-radius: 10px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);" /&gt; &lt;/a&gt; 
     &lt;p&gt;&lt;strong&gt;&lt;a href="https://www.youtube.com/watch?v=MQZYpLkzsbw"&gt;▶️ Watch Demo&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
     &lt;p&gt;&lt;em&gt;Transform academic papers into production-ready code automatically&lt;/em&gt;&lt;/p&gt; 
    &lt;/div&gt; &lt;/td&gt; 
   &lt;td width="33%" align="center"&gt; &lt;h4&gt;🖼️ &lt;strong&gt;Image Processing Demo&lt;/strong&gt;&lt;/h4&gt; &lt;p&gt;&lt;strong&gt;AI-Powered Image Tools&lt;/strong&gt;&lt;/p&gt; 
    &lt;div align="center"&gt; 
     &lt;a href="https://www.youtube.com/watch?v=nFt5mLaMEac"&gt; &lt;img src="https://img.youtube.com/vi/nFt5mLaMEac/maxresdefault.jpg" alt="Image Processing Demo" width="100%" style="border-radius: 10px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);" /&gt; &lt;/a&gt; 
     &lt;p&gt;&lt;strong&gt;&lt;a href="https://www.youtube.com/watch?v=nFt5mLaMEac"&gt;▶️ Watch Demo&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
     &lt;p&gt;&lt;em&gt;Intelligent image processing with background removal and enhancement&lt;/em&gt;&lt;/p&gt; 
    &lt;/div&gt; &lt;/td&gt; 
   &lt;td width="33%" align="center"&gt; &lt;h4&gt;🌐 &lt;strong&gt;Frontend Implementation&lt;/strong&gt;&lt;/h4&gt; &lt;p&gt;&lt;strong&gt;Complete Web Application&lt;/strong&gt;&lt;/p&gt; 
    &lt;div align="center"&gt; 
     &lt;a href="https://www.youtube.com/watch?v=78wx3dkTaAU"&gt; &lt;img src="https://img.youtube.com/vi/78wx3dkTaAU/maxresdefault.jpg" alt="Frontend Demo" width="100%" style="border-radius: 10px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);" /&gt; &lt;/a&gt; 
     &lt;p&gt;&lt;strong&gt;&lt;a href="https://www.youtube.com/watch?v=78wx3dkTaAU"&gt;▶️ Watch Demo&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
     &lt;p&gt;&lt;em&gt;Full-stack web development from concept to deployment&lt;/em&gt;&lt;/p&gt; 
    &lt;/div&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h3&gt;🆕 &lt;strong&gt;Recent Updates&lt;/strong&gt;&lt;/h3&gt; 
&lt;h4&gt;📄 &lt;strong&gt;Smart Document Segmentation (v1.2.0)&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Intelligent Processing&lt;/strong&gt;: Automatically handles large research papers and technical documents that exceed LLM token limits&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Configurable Control&lt;/strong&gt;: Toggle segmentation via configuration with size-based thresholds&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Semantic Analysis&lt;/strong&gt;: Advanced content understanding with algorithm, concept, and formula preservation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Backward Compatibility&lt;/strong&gt;: Seamlessly falls back to traditional processing for smaller documents&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;🚀 &lt;strong&gt;Coming Soon&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;We're continuously enhancing DeepCode with exciting new features:&lt;/p&gt; 
&lt;h4&gt;🔧 &lt;strong&gt;Enhanced Code Reliability &amp;amp; Validation&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Automated Testing&lt;/strong&gt;: Comprehensive functionality testing with execution verification and error detection.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Code Quality Assurance&lt;/strong&gt;: Multi-level validation through static analysis, dynamic testing, and performance benchmarking.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Smart Debugging&lt;/strong&gt;: AI-powered error detection with automatic correction suggestions&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;📊 &lt;strong&gt;PaperBench Performance Showcase&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Benchmark Dashboard&lt;/strong&gt;: Comprehensive performance metrics on the PaperBench evaluation suite.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Accuracy Metrics&lt;/strong&gt;: Detailed comparison with state-of-the-art paper reproduction systems.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Success Analytics&lt;/strong&gt;: Statistical analysis across paper categories and complexity levels.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;⚡ &lt;strong&gt;System-wide Optimizations&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Performance Boost&lt;/strong&gt;: Multi-threaded processing and optimized agent coordination for faster generation.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Enhanced Reasoning&lt;/strong&gt;: Advanced reasoning capabilities with improved context understanding.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Expanded Support&lt;/strong&gt;: Extended compatibility with additional programming languages and frameworks.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;⭐ Star History&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;em&gt;Community Growth Trajectory&lt;/em&gt;&lt;/p&gt; 
 &lt;a href="https://star-history.com/#HKUDS/DeepCode&amp;amp;Date"&gt; 
  &lt;picture&gt; 
   &lt;source media="(prefers-color-scheme: dark)" srcset="https://api.star-history.com/svg?repos=HKUDS/DeepCode&amp;amp;type=Date&amp;amp;theme=dark" /&gt; 
   &lt;source media="(prefers-color-scheme: light)" srcset="https://api.star-history.com/svg?repos=HKUDS/DeepCode&amp;amp;type=Date" /&gt; 
   &lt;img alt="Star History Chart" src="https://api.star-history.com/svg?repos=HKUDS/DeepCode&amp;amp;type=Date" style="border-radius: 15px; box-shadow: 0 0 30px rgba(0, 217, 255, 0.3);" /&gt; 
  &lt;/picture&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h3&gt;🚀 &lt;strong&gt;Ready to Transform Development?&lt;/strong&gt;&lt;/h3&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt; &lt;a href="https://raw.githubusercontent.com/HKUDS/DeepCode/main/#-quick-start"&gt;&lt;img src="https://img.shields.io/badge/🚀_Get_Started-00d4ff?style=for-the-badge&amp;amp;logo=rocket&amp;amp;logoColor=white" alt="Get Started" /&gt;&lt;/a&gt; &lt;a href="https://github.com/HKUDS"&gt;&lt;img src="https://img.shields.io/badge/🏛️_View_on_GitHub-00d4ff?style=for-the-badge&amp;amp;logo=github&amp;amp;logoColor=white" alt="View on GitHub" /&gt;&lt;/a&gt; &lt;a href="https://github.com/HKUDS/deepcode-agent"&gt;&lt;img src="https://img.shields.io/badge/⭐_Star_Project-00d4ff?style=for-the-badge&amp;amp;logo=star&amp;amp;logoColor=white" alt="Star Project" /&gt;&lt;/a&gt; &lt;/p&gt; 
 &lt;hr /&gt; 
 &lt;h3&gt;📄 &lt;strong&gt;License&lt;/strong&gt;&lt;/h3&gt; 
 &lt;img src="https://img.shields.io/badge/License-MIT-4ecdc4?style=for-the-badge&amp;amp;logo=opensourceinitiative&amp;amp;logoColor=white" alt="MIT License" /&gt; 
 &lt;p&gt;&lt;strong&gt;MIT License&lt;/strong&gt; - Copyright (c) 2025 Data Intelligence Lab, The University of Hong Kong&lt;/p&gt; 
 &lt;hr /&gt; 
 &lt;img src="https://visitor-badge.laobi.icu/badge?page_id=deepcode.readme&amp;amp;style=for-the-badge&amp;amp;color=00d4ff" alt="Visitors" /&gt; 
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>HunxByts/GhostTrack</title>
      <link>https://github.com/HunxByts/GhostTrack</link>
      <description>&lt;p&gt;Useful tool to track location or mobile number&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;GhostTrack&lt;/h1&gt; 
&lt;p&gt;Useful tool to track location or mobile number, so this tool can be called osint or also information gathering&lt;/p&gt; 
&lt;img src="https://github.com/HunxByts/GhostTrack/raw/main/asset/bn.png" /&gt; 
&lt;p&gt;New update : &lt;code&gt;Version 2.2&lt;/code&gt;&lt;/p&gt; 
&lt;h3&gt;Instalation on Linux (deb)&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;sudo apt-get install git
sudo apt-get install python3
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Instalation on Termux&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;pkg install git
pkg install python3
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Usage Tool&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;git clone https://github.com/HunxByts/GhostTrack.git
cd GhostTrack
pip3 install -r requirements.txt
python3 GhostTR.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Display on the menu &lt;code&gt;IP Tracker&lt;/code&gt;&lt;/p&gt; 
&lt;img src="https://github.com/HunxByts/GhostTrack/blob/main/asset/ip.png " /&gt; 
&lt;p&gt;on the IP Track menu, you can combo with the seeker tool to get the target IP&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;span&gt;⚡&lt;/span&gt; Install Seeker :&lt;/summary&gt; - 
 &lt;strong&gt;&lt;a href="https://github.com/thewhiteh4t/seeker"&gt;Get Seeker&lt;/a&gt;&lt;/strong&gt; 
&lt;/details&gt; 
&lt;p&gt;Display on the menu &lt;code&gt;Phone Tracker&lt;/code&gt;&lt;/p&gt; 
&lt;img src="https://github.com/HunxByts/GhostTrack/raw/main/asset/phone.png" /&gt; 
&lt;p&gt;on this menu you can search for information from the target phone number&lt;/p&gt; 
&lt;p&gt;Display on the menu &lt;code&gt;Username Tracker&lt;/code&gt;&lt;/p&gt; 
&lt;img src="https://github.com/HunxByts/GhostTrack/raw/main/asset/User.png" /&gt; on this menu you can search for information from the target username on social media 
&lt;details&gt; 
 &lt;summary&gt;&lt;span&gt;⚡&lt;/span&gt; Author :&lt;/summary&gt; - 
 &lt;strong&gt;&lt;a href="https://github.com/HunxByts"&gt;HunxByts&lt;/a&gt;&lt;/strong&gt; 
&lt;/details&gt;</description>
    </item>
    
    <item>
      <title>TheAlgorithms/Python</title>
      <link>https://github.com/TheAlgorithms/Python</link>
      <description>&lt;p&gt;All Algorithms implemented in Python&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;!-- Title: --&gt; 
 &lt;a href="https://github.com/TheAlgorithms/"&gt; &lt;img src="https://raw.githubusercontent.com/TheAlgorithms/website/1cd824df116b27029f17c2d1b42d81731f28a920/public/logo.svg?sanitize=true" height="100" /&gt; &lt;/a&gt; 
 &lt;h1&gt;&lt;a href="https://github.com/TheAlgorithms/"&gt;The Algorithms&lt;/a&gt; - Python&lt;/h1&gt; 
 &lt;!-- Labels: --&gt; 
 &lt;!-- First row: --&gt; 
 &lt;a href="https://gitpod.io/#https://github.com/TheAlgorithms/Python"&gt; &lt;img src="https://img.shields.io/badge/Gitpod-Ready--to--Code-blue?logo=gitpod&amp;amp;style=flat-square" height="20" alt="Gitpod Ready-to-Code" /&gt; &lt;/a&gt; 
 &lt;a href="https://github.com/TheAlgorithms/Python/raw/master/CONTRIBUTING.md"&gt; &lt;img src="https://img.shields.io/static/v1.svg?label=Contributions&amp;amp;message=Welcome&amp;amp;color=0059b3&amp;amp;style=flat-square" height="20" alt="Contributions Welcome" /&gt; &lt;/a&gt; 
 &lt;img src="https://img.shields.io/github/repo-size/TheAlgorithms/Python.svg?label=Repo%20size&amp;amp;style=flat-square" height="20" /&gt; 
 &lt;a href="https://the-algorithms.com/discord"&gt; &lt;img src="https://img.shields.io/discord/808045925556682782.svg?logo=discord&amp;amp;colorB=7289DA&amp;amp;style=flat-square" height="20" alt="Discord chat" /&gt; &lt;/a&gt; 
 &lt;a href="https://gitter.im/TheAlgorithms/community"&gt; &lt;img src="https://img.shields.io/badge/Chat-Gitter-ff69b4.svg?label=Chat&amp;amp;logo=gitter&amp;amp;style=flat-square" height="20" alt="Gitter chat" /&gt; &lt;/a&gt; 
 &lt;!-- Second row: --&gt; 
 &lt;br /&gt; 
 &lt;a href="https://github.com/TheAlgorithms/Python/actions"&gt; &lt;img src="https://img.shields.io/github/actions/workflow/status/TheAlgorithms/Python/build.yml?branch=master&amp;amp;label=CI&amp;amp;logo=github&amp;amp;style=flat-square" height="20" alt="GitHub Workflow Status" /&gt; &lt;/a&gt; 
 &lt;a href="https://github.com/pre-commit/pre-commit"&gt; &lt;img src="https://img.shields.io/badge/pre--commit-enabled-brightgreen?logo=pre-commit&amp;amp;logoColor=white&amp;amp;style=flat-square" height="20" alt="pre-commit" /&gt; &lt;/a&gt; 
 &lt;a href="https://docs.astral.sh/ruff/formatter/"&gt; &lt;img src="https://img.shields.io/static/v1?label=code%20style&amp;amp;message=ruff&amp;amp;color=black&amp;amp;style=flat-square" height="20" alt="code style: black" /&gt; &lt;/a&gt; 
 &lt;!-- Short description: --&gt; 
 &lt;h3&gt;All algorithms implemented in Python - for education&lt;/h3&gt; 
&lt;/div&gt; 
&lt;p&gt;Implementations are for learning purposes only. They may be less efficient than the implementations in the Python standard library. Use them at your discretion.&lt;/p&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;p&gt;Read through our &lt;a href="https://raw.githubusercontent.com/TheAlgorithms/Python/master/CONTRIBUTING.md"&gt;Contribution Guidelines&lt;/a&gt; before you contribute.&lt;/p&gt; 
&lt;h2&gt;Community Channels&lt;/h2&gt; 
&lt;p&gt;We are on &lt;a href="https://the-algorithms.com/discord"&gt;Discord&lt;/a&gt; and &lt;a href="https://gitter.im/TheAlgorithms/community"&gt;Gitter&lt;/a&gt;! Community channels are a great way for you to ask questions and get help. Please join us!&lt;/p&gt; 
&lt;h2&gt;List of Algorithms&lt;/h2&gt; 
&lt;p&gt;See our &lt;a href="https://raw.githubusercontent.com/TheAlgorithms/Python/master/DIRECTORY.md"&gt;directory&lt;/a&gt; for easier navigation and a better overview of the project.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>MODSetter/SurfSense</title>
      <link>https://github.com/MODSetter/SurfSense</link>
      <description>&lt;p&gt;Open Source Alternative to NotebookLM / Perplexity, connected to external sources such as Search Engines, Slack, Linear, Jira, ClickUp, Confluence, Notion, YouTube, GitHub, Discord and more. Join our discord: https://discord.gg/ejRNvftDp9&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/e236b764-0ddc-42ff-a1f1-8fbb3d2e0e65" alt="new_header" /&gt;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://discord.gg/ejRNvftDp9"&gt; &lt;img src="https://img.shields.io/discord/1359368468260192417" alt="Discord" /&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;h1&gt;SurfSense&lt;/h1&gt; 
&lt;p&gt;While tools like NotebookLM and Perplexity are impressive and highly effective for conducting research on any topic/query, SurfSense elevates this capability by integrating with your personal knowledge base. It is a highly customizable AI research agent, connected to external sources such as Search Engines (Tavily, LinkUp), Slack, Linear, Jira, ClickUp, Confluence, Gmail, Notion, YouTube, GitHub, Discord, Google Calendar and more to come.&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://trendshift.io/repositories/13606" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/13606" alt="MODSetter%2FSurfSense | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt; 
&lt;/div&gt; 
&lt;h1&gt;Video&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/d9221908-e0de-4b2f-ac3a-691cf4b202da"&gt;https://github.com/user-attachments/assets/d9221908-e0de-4b2f-ac3a-691cf4b202da&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Podcast Sample&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/a0a16566-6967-4374-ac51-9b3e07fbecd7"&gt;https://github.com/user-attachments/assets/a0a16566-6967-4374-ac51-9b3e07fbecd7&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Key Features&lt;/h2&gt; 
&lt;h3&gt;💡 &lt;strong&gt;Idea&lt;/strong&gt;:&lt;/h3&gt; 
&lt;p&gt;Have your own highly customizable private NotebookLM and Perplexity integrated with external sources.&lt;/p&gt; 
&lt;h3&gt;📁 &lt;strong&gt;Multiple File Format Uploading Support&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;Save content from your own personal files &lt;em&gt;(Documents, images, videos and supports &lt;strong&gt;50+ file extensions&lt;/strong&gt;)&lt;/em&gt; to your own personal knowledge base .&lt;/p&gt; 
&lt;h3&gt;🔍 &lt;strong&gt;Powerful Search&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;Quickly research or find anything in your saved content .&lt;/p&gt; 
&lt;h3&gt;💬 &lt;strong&gt;Chat with your Saved Content&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;Interact in Natural Language and get cited answers.&lt;/p&gt; 
&lt;h3&gt;📄 &lt;strong&gt;Cited Answers&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;Get Cited answers just like Perplexity.&lt;/p&gt; 
&lt;h3&gt;🔔 &lt;strong&gt;Privacy &amp;amp; Local LLM Support&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;Works Flawlessly with Ollama local LLMs.&lt;/p&gt; 
&lt;h3&gt;🏠 &lt;strong&gt;Self Hostable&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;Open source and easy to deploy locally.&lt;/p&gt; 
&lt;h3&gt;🎙️ Podcasts&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Blazingly fast podcast generation agent. (Creates a 3-minute podcast in under 20 seconds.)&lt;/li&gt; 
 &lt;li&gt;Convert your chat conversations into engaging audio content&lt;/li&gt; 
 &lt;li&gt;Support for local TTS providers (Kokoro TTS)&lt;/li&gt; 
 &lt;li&gt;Support for multiple TTS providers (OpenAI, Azure, Google Vertex AI)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;📊 &lt;strong&gt;Advanced RAG Techniques&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Supports 100+ LLM's&lt;/li&gt; 
 &lt;li&gt;Supports 6000+ Embedding Models.&lt;/li&gt; 
 &lt;li&gt;Supports all major Rerankers (Pinecode, Cohere, Flashrank etc)&lt;/li&gt; 
 &lt;li&gt;Uses Hierarchical Indices (2 tiered RAG setup).&lt;/li&gt; 
 &lt;li&gt;Utilizes Hybrid Search (Semantic + Full Text Search combined with Reciprocal Rank Fusion).&lt;/li&gt; 
 &lt;li&gt;RAG as a Service API Backend.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;ℹ️ &lt;strong&gt;External Sources&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Search Engines (Tavily, LinkUp)&lt;/li&gt; 
 &lt;li&gt;Slack&lt;/li&gt; 
 &lt;li&gt;Linear&lt;/li&gt; 
 &lt;li&gt;Jira&lt;/li&gt; 
 &lt;li&gt;ClickUp&lt;/li&gt; 
 &lt;li&gt;Confluence&lt;/li&gt; 
 &lt;li&gt;Notion&lt;/li&gt; 
 &lt;li&gt;Gmail&lt;/li&gt; 
 &lt;li&gt;Youtube Videos&lt;/li&gt; 
 &lt;li&gt;GitHub&lt;/li&gt; 
 &lt;li&gt;Discord&lt;/li&gt; 
 &lt;li&gt;Google Calendar&lt;/li&gt; 
 &lt;li&gt;and more to come.....&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;📄 &lt;strong&gt;Supported File Extensions&lt;/strong&gt;&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: File format support depends on your ETL service configuration. LlamaCloud supports 50+ formats, Unstructured supports 34+ core formats, and Docling (core formats, local processing, privacy-focused, no API key).&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Documents &amp;amp; Text&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;LlamaCloud&lt;/strong&gt;: &lt;code&gt;.pdf&lt;/code&gt;, &lt;code&gt;.doc&lt;/code&gt;, &lt;code&gt;.docx&lt;/code&gt;, &lt;code&gt;.docm&lt;/code&gt;, &lt;code&gt;.dot&lt;/code&gt;, &lt;code&gt;.dotm&lt;/code&gt;, &lt;code&gt;.rtf&lt;/code&gt;, &lt;code&gt;.txt&lt;/code&gt;, &lt;code&gt;.xml&lt;/code&gt;, &lt;code&gt;.epub&lt;/code&gt;, &lt;code&gt;.odt&lt;/code&gt;, &lt;code&gt;.wpd&lt;/code&gt;, &lt;code&gt;.pages&lt;/code&gt;, &lt;code&gt;.key&lt;/code&gt;, &lt;code&gt;.numbers&lt;/code&gt;, &lt;code&gt;.602&lt;/code&gt;, &lt;code&gt;.abw&lt;/code&gt;, &lt;code&gt;.cgm&lt;/code&gt;, &lt;code&gt;.cwk&lt;/code&gt;, &lt;code&gt;.hwp&lt;/code&gt;, &lt;code&gt;.lwp&lt;/code&gt;, &lt;code&gt;.mw&lt;/code&gt;, &lt;code&gt;.mcw&lt;/code&gt;, &lt;code&gt;.pbd&lt;/code&gt;, &lt;code&gt;.sda&lt;/code&gt;, &lt;code&gt;.sdd&lt;/code&gt;, &lt;code&gt;.sdp&lt;/code&gt;, &lt;code&gt;.sdw&lt;/code&gt;, &lt;code&gt;.sgl&lt;/code&gt;, &lt;code&gt;.sti&lt;/code&gt;, &lt;code&gt;.sxi&lt;/code&gt;, &lt;code&gt;.sxw&lt;/code&gt;, &lt;code&gt;.stw&lt;/code&gt;, &lt;code&gt;.sxg&lt;/code&gt;, &lt;code&gt;.uof&lt;/code&gt;, &lt;code&gt;.uop&lt;/code&gt;, &lt;code&gt;.uot&lt;/code&gt;, &lt;code&gt;.vor&lt;/code&gt;, &lt;code&gt;.wps&lt;/code&gt;, &lt;code&gt;.zabw&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Unstructured&lt;/strong&gt;: &lt;code&gt;.doc&lt;/code&gt;, &lt;code&gt;.docx&lt;/code&gt;, &lt;code&gt;.odt&lt;/code&gt;, &lt;code&gt;.rtf&lt;/code&gt;, &lt;code&gt;.pdf&lt;/code&gt;, &lt;code&gt;.xml&lt;/code&gt;, &lt;code&gt;.txt&lt;/code&gt;, &lt;code&gt;.md&lt;/code&gt;, &lt;code&gt;.markdown&lt;/code&gt;, &lt;code&gt;.rst&lt;/code&gt;, &lt;code&gt;.html&lt;/code&gt;, &lt;code&gt;.org&lt;/code&gt;, &lt;code&gt;.epub&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Docling&lt;/strong&gt;: &lt;code&gt;.pdf&lt;/code&gt;, &lt;code&gt;.docx&lt;/code&gt;, &lt;code&gt;.html&lt;/code&gt;, &lt;code&gt;.htm&lt;/code&gt;, &lt;code&gt;.xhtml&lt;/code&gt;, &lt;code&gt;.adoc&lt;/code&gt;, &lt;code&gt;.asciidoc&lt;/code&gt;&lt;/p&gt; 
&lt;h3&gt;Presentations&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;LlamaCloud&lt;/strong&gt;: &lt;code&gt;.ppt&lt;/code&gt;, &lt;code&gt;.pptx&lt;/code&gt;, &lt;code&gt;.pptm&lt;/code&gt;, &lt;code&gt;.pot&lt;/code&gt;, &lt;code&gt;.potm&lt;/code&gt;, &lt;code&gt;.potx&lt;/code&gt;, &lt;code&gt;.odp&lt;/code&gt;, &lt;code&gt;.key&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Unstructured&lt;/strong&gt;: &lt;code&gt;.ppt&lt;/code&gt;, &lt;code&gt;.pptx&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Docling&lt;/strong&gt;: &lt;code&gt;.pptx&lt;/code&gt;&lt;/p&gt; 
&lt;h3&gt;Spreadsheets &amp;amp; Data&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;LlamaCloud&lt;/strong&gt;: &lt;code&gt;.xlsx&lt;/code&gt;, &lt;code&gt;.xls&lt;/code&gt;, &lt;code&gt;.xlsm&lt;/code&gt;, &lt;code&gt;.xlsb&lt;/code&gt;, &lt;code&gt;.xlw&lt;/code&gt;, &lt;code&gt;.csv&lt;/code&gt;, &lt;code&gt;.tsv&lt;/code&gt;, &lt;code&gt;.ods&lt;/code&gt;, &lt;code&gt;.fods&lt;/code&gt;, &lt;code&gt;.numbers&lt;/code&gt;, &lt;code&gt;.dbf&lt;/code&gt;, &lt;code&gt;.123&lt;/code&gt;, &lt;code&gt;.dif&lt;/code&gt;, &lt;code&gt;.sylk&lt;/code&gt;, &lt;code&gt;.slk&lt;/code&gt;, &lt;code&gt;.prn&lt;/code&gt;, &lt;code&gt;.et&lt;/code&gt;, &lt;code&gt;.uos1&lt;/code&gt;, &lt;code&gt;.uos2&lt;/code&gt;, &lt;code&gt;.wk1&lt;/code&gt;, &lt;code&gt;.wk2&lt;/code&gt;, &lt;code&gt;.wk3&lt;/code&gt;, &lt;code&gt;.wk4&lt;/code&gt;, &lt;code&gt;.wks&lt;/code&gt;, &lt;code&gt;.wq1&lt;/code&gt;, &lt;code&gt;.wq2&lt;/code&gt;, &lt;code&gt;.wb1&lt;/code&gt;, &lt;code&gt;.wb2&lt;/code&gt;, &lt;code&gt;.wb3&lt;/code&gt;, &lt;code&gt;.qpw&lt;/code&gt;, &lt;code&gt;.xlr&lt;/code&gt;, &lt;code&gt;.eth&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Unstructured&lt;/strong&gt;: &lt;code&gt;.xls&lt;/code&gt;, &lt;code&gt;.xlsx&lt;/code&gt;, &lt;code&gt;.csv&lt;/code&gt;, &lt;code&gt;.tsv&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Docling&lt;/strong&gt;: &lt;code&gt;.xlsx&lt;/code&gt;, &lt;code&gt;.csv&lt;/code&gt;&lt;/p&gt; 
&lt;h3&gt;Images&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;LlamaCloud&lt;/strong&gt;: &lt;code&gt;.jpg&lt;/code&gt;, &lt;code&gt;.jpeg&lt;/code&gt;, &lt;code&gt;.png&lt;/code&gt;, &lt;code&gt;.gif&lt;/code&gt;, &lt;code&gt;.bmp&lt;/code&gt;, &lt;code&gt;.svg&lt;/code&gt;, &lt;code&gt;.tiff&lt;/code&gt;, &lt;code&gt;.webp&lt;/code&gt;, &lt;code&gt;.html&lt;/code&gt;, &lt;code&gt;.htm&lt;/code&gt;, &lt;code&gt;.web&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Unstructured&lt;/strong&gt;: &lt;code&gt;.jpg&lt;/code&gt;, &lt;code&gt;.jpeg&lt;/code&gt;, &lt;code&gt;.png&lt;/code&gt;, &lt;code&gt;.bmp&lt;/code&gt;, &lt;code&gt;.tiff&lt;/code&gt;, &lt;code&gt;.heic&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Docling&lt;/strong&gt;: &lt;code&gt;.jpg&lt;/code&gt;, &lt;code&gt;.jpeg&lt;/code&gt;, &lt;code&gt;.png&lt;/code&gt;, &lt;code&gt;.bmp&lt;/code&gt;, &lt;code&gt;.tiff&lt;/code&gt;, &lt;code&gt;.tif&lt;/code&gt;, &lt;code&gt;.webp&lt;/code&gt;&lt;/p&gt; 
&lt;h3&gt;Audio &amp;amp; Video &lt;em&gt;(Always Supported)&lt;/em&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;.mp3&lt;/code&gt;, &lt;code&gt;.mpga&lt;/code&gt;, &lt;code&gt;.m4a&lt;/code&gt;, &lt;code&gt;.wav&lt;/code&gt;, &lt;code&gt;.mp4&lt;/code&gt;, &lt;code&gt;.mpeg&lt;/code&gt;, &lt;code&gt;.webm&lt;/code&gt;&lt;/p&gt; 
&lt;h3&gt;Email &amp;amp; Communication&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Unstructured&lt;/strong&gt;: &lt;code&gt;.eml&lt;/code&gt;, &lt;code&gt;.msg&lt;/code&gt;, &lt;code&gt;.p7s&lt;/code&gt;&lt;/p&gt; 
&lt;h3&gt;🔖 Cross Browser Extension&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;The SurfSense extension can be used to save any webpage you like.&lt;/li&gt; 
 &lt;li&gt;Its main usecase is to save any webpages protected beyond authentication.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;hr /&gt; 
&lt;p align="center"&gt; &lt;a href="https://handbook.opencoreventures.com/catalyst-sponsorship-program/" target="_blank" rel="noopener noreferrer"&gt; &lt;img src="https://github.com/user-attachments/assets/329c9bc2-6005-4aed-a629-700b5ae296b4" alt="Catalyst Sponsorship Program" width="600" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;hr /&gt; 
&lt;hr /&gt; 
&lt;h2&gt;FEATURE REQUESTS AND FUTURE&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;SurfSense is actively being developed.&lt;/strong&gt; While it's not yet production-ready, you can help us speed up the process.&lt;/p&gt; 
&lt;p&gt;Join the &lt;a href="https://discord.gg/ejRNvftDp9"&gt;SurfSense Discord&lt;/a&gt; and help shape the future of SurfSense!&lt;/p&gt; 
&lt;h2&gt;🚀 Roadmap&lt;/h2&gt; 
&lt;p&gt;Stay up to date with our development progress and upcoming features!&lt;br /&gt; Check out our public roadmap and contribute your ideas or feedback:&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;View the Roadmap:&lt;/strong&gt; &lt;a href="https://github.com/users/MODSetter/projects/2"&gt;SurfSense Roadmap on GitHub Projects&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;How to get started?&lt;/h2&gt; 
&lt;h3&gt;Installation Options&lt;/h3&gt; 
&lt;p&gt;SurfSense provides two installation methods:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://www.surfsense.net/docs/docker-installation"&gt;Docker Installation&lt;/a&gt;&lt;/strong&gt; - The easiest way to get SurfSense up and running with all dependencies containerized.&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Includes pgAdmin for database management through a web UI&lt;/li&gt; 
   &lt;li&gt;Supports environment variable customization via &lt;code&gt;.env&lt;/code&gt; file&lt;/li&gt; 
   &lt;li&gt;Flexible deployment options (full stack or core services only)&lt;/li&gt; 
   &lt;li&gt;No need to manually edit configuration files between environments&lt;/li&gt; 
   &lt;li&gt;See &lt;a href="https://raw.githubusercontent.com/MODSetter/SurfSense/main/DOCKER_SETUP.md"&gt;Docker Setup Guide&lt;/a&gt; for detailed instructions&lt;/li&gt; 
   &lt;li&gt;For deployment scenarios and options, see &lt;a href="https://raw.githubusercontent.com/MODSetter/SurfSense/main/DEPLOYMENT_GUIDE.md"&gt;Deployment Guide&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://www.surfsense.net/docs/manual-installation"&gt;Manual Installation (Recommended)&lt;/a&gt;&lt;/strong&gt; - For users who prefer more control over their setup or need to customize their deployment.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Both installation guides include detailed OS-specific instructions for Windows, macOS, and Linux.&lt;/p&gt; 
&lt;p&gt;Before installation, make sure to complete the &lt;a href="https://www.surfsense.net/docs/"&gt;prerequisite setup steps&lt;/a&gt; including:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;PGVector setup&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;File Processing ETL Service&lt;/strong&gt; (choose one): 
  &lt;ul&gt; 
   &lt;li&gt;Unstructured.io API key (supports 34+ formats)&lt;/li&gt; 
   &lt;li&gt;LlamaIndex API key (enhanced parsing, supports 50+ formats)&lt;/li&gt; 
   &lt;li&gt;Docling (local processing, no API key required, supports PDF, Office docs, images, HTML, CSV)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Other required API keys&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Screenshots&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Research Agent&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/e22c5d86-f511-4c72-8c50-feba0c1561b4" alt="updated_researcher" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Search Spaces&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/e254c38c-f937-44b6-9e9d-770db583d099" alt="search_spaces" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Manage Documents&lt;/strong&gt; &lt;img src="https://github.com/user-attachments/assets/7001e306-eb06-4009-89c6-8fadfdc3fc4d" alt="documents" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Podcast Agent&lt;/strong&gt; &lt;img src="https://github.com/user-attachments/assets/6cb82ffd-9e14-4172-bc79-67faf34c4c1c" alt="podcasts" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Agent Chat&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/bb352d52-1c6d-4020-926b-722d0b98b491" alt="git_chat" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Browser Extension&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/1f042b7a-6349-422b-94fb-d40d0df16c40" alt="ext1" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/a9b9f1aa-2677-404d-b0a0-c1b2dddf24a7" alt="ext2" /&gt;&lt;/p&gt; 
&lt;h2&gt;Tech Stack&lt;/h2&gt; 
&lt;h3&gt;&lt;strong&gt;BackEnd&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;FastAPI&lt;/strong&gt;: Modern, fast web framework for building APIs with Python&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;PostgreSQL with pgvector&lt;/strong&gt;: Database with vector search capabilities for similarity searches&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;SQLAlchemy&lt;/strong&gt;: SQL toolkit and ORM (Object-Relational Mapping) for database interactions&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Alembic&lt;/strong&gt;: A database migrations tool for SQLAlchemy.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;FastAPI Users&lt;/strong&gt;: Authentication and user management with JWT and OAuth support&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;LangGraph&lt;/strong&gt;: Framework for developing AI-agents.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;LangChain&lt;/strong&gt;: Framework for developing AI-powered applications.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;LLM Integration&lt;/strong&gt;: Integration with LLM models through LiteLLM&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Rerankers&lt;/strong&gt;: Advanced result ranking for improved search relevance&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Hybrid Search&lt;/strong&gt;: Combines vector similarity and full-text search for optimal results using Reciprocal Rank Fusion (RRF)&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Vector Embeddings&lt;/strong&gt;: Document and text embeddings for semantic search&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;pgvector&lt;/strong&gt;: PostgreSQL extension for efficient vector similarity operations&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Chonkie&lt;/strong&gt;: Advanced document chunking and embedding library&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Uses &lt;code&gt;AutoEmbeddings&lt;/code&gt; for flexible embedding model selection&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;LateChunker&lt;/code&gt; for optimized document chunking based on embedding model's max sequence length&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h3&gt;&lt;strong&gt;FrontEnd&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Next.js 15.2.3&lt;/strong&gt;: React framework featuring App Router, server components, automatic code-splitting, and optimized rendering.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;React 19.0.0&lt;/strong&gt;: JavaScript library for building user interfaces.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;TypeScript&lt;/strong&gt;: Static type-checking for JavaScript, enhancing code quality and developer experience.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Vercel AI SDK Kit UI Stream Protocol&lt;/strong&gt;: To create scalable chat UI.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Tailwind CSS 4.x&lt;/strong&gt;: Utility-first CSS framework for building custom UI designs.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Shadcn&lt;/strong&gt;: Headless components library.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Lucide React&lt;/strong&gt;: Icon set implemented as React components.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Framer Motion&lt;/strong&gt;: Animation library for React.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Sonner&lt;/strong&gt;: Toast notification library.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Geist&lt;/strong&gt;: Font family from Vercel.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;React Hook Form&lt;/strong&gt;: Form state management and validation.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Zod&lt;/strong&gt;: TypeScript-first schema validation with static type inference.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;@hookform/resolvers&lt;/strong&gt;: Resolvers for using validation libraries with React Hook Form.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;@tanstack/react-table&lt;/strong&gt;: Headless UI for building powerful tables &amp;amp; datagrids.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;strong&gt;DevOps&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Docker&lt;/strong&gt;: Container platform for consistent deployment across environments&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Docker Compose&lt;/strong&gt;: Tool for defining and running multi-container Docker applications&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;pgAdmin&lt;/strong&gt;: Web-based PostgreSQL administration tool included in Docker setup&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;strong&gt;Extension&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;Manifest v3 on Plasmo&lt;/p&gt; 
&lt;h2&gt;Future Work&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Add More Connectors.&lt;/li&gt; 
 &lt;li&gt;Patch minor bugs.&lt;/li&gt; 
 &lt;li&gt;Document Podcasts&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contribute&lt;/h2&gt; 
&lt;p&gt;Contributions are very welcome! A contribution can be as small as a ⭐ or even finding and creating issues. Fine-tuning the Backend is always desired.&lt;/p&gt; 
&lt;p&gt;For detailed contribution guidelines, please see our &lt;a href="https://raw.githubusercontent.com/MODSetter/SurfSense/main/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; file.&lt;/p&gt; 
&lt;h2&gt;Star History&lt;/h2&gt; 
&lt;a href="https://www.star-history.com/#MODSetter/SurfSense&amp;amp;Date"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://api.star-history.com/svg?repos=MODSetter/SurfSense&amp;amp;type=Date&amp;amp;theme=dark" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://api.star-history.com/svg?repos=MODSetter/SurfSense&amp;amp;type=Date" /&gt; 
  &lt;img alt="Star History Chart" src="https://api.star-history.com/svg?repos=MODSetter/SurfSense&amp;amp;type=Date" /&gt; 
 &lt;/picture&gt; &lt;/a&gt;</description>
    </item>
    
    <item>
      <title>ag2ai/ag2</title>
      <link>https://github.com/ag2ai/ag2</link>
      <description>&lt;p&gt;AG2 (formerly AutoGen): The Open-Source AgentOS. Join us at: https://discord.gg/pAbnFJrkgZ&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a name="readme-top"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p align="center"&gt; 
 &lt;!-- The image URL points to the GitHub-hosted content, ensuring it displays correctly on the PyPI website.--&gt; &lt;img src="https://raw.githubusercontent.com/ag2ai/ag2/27b37494a6f72b1f8050f6bd7be9a7ff232cf749/website/static/img/ag2.svg?sanitize=true" width="150" title="hover text" /&gt; &lt;br /&gt; &lt;br /&gt; &lt;a href="https://www.pepy.tech/projects/ag2"&gt; &lt;img src="https://static.pepy.tech/personalized-badge/ag2?period=month&amp;amp;units=international_system&amp;amp;left_color=grey&amp;amp;right_color=green&amp;amp;left_text=downloads/month" alt="Downloads" /&gt; &lt;/a&gt; &lt;a href="https://pypi.org/project/autogen/"&gt; &lt;img src="https://img.shields.io/pypi/v/ag2?label=PyPI&amp;amp;color=green" /&gt; &lt;/a&gt; &lt;img src="https://img.shields.io/pypi/pyversions/ag2.svg?label=" /&gt; &lt;a href="https://github.com/ag2ai/ag2/actions/workflows/python-package.yml"&gt; &lt;img src="https://github.com/ag2ai/ag2/actions/workflows/python-package.yml/badge.svg?sanitize=true" /&gt; &lt;/a&gt; &lt;a href="https://discord.gg/pAbnFJrkgZ"&gt; &lt;img src="https://img.shields.io/discord/1153072414184452236?logo=discord&amp;amp;style=flat" /&gt; &lt;/a&gt; &lt;br /&gt; &lt;a href="https://x.com/ag2oss"&gt; &lt;img src="https://img.shields.io/twitter/url/https/twitter.com/cloudposse.svg?style=social&amp;amp;label=Follow%20%40ag2ai" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://docs.ag2.ai/"&gt;📚 Documentation&lt;/a&gt; | &lt;a href="https://github.com/ag2ai/build-with-ag2"&gt;💡 Examples&lt;/a&gt; | &lt;a href="https://docs.ag2.ai/latest/docs/contributor-guide/contributing"&gt;🤝 Contributing&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/ag2ai/ag2/main/#related-papers"&gt;📝 Cite paper&lt;/a&gt; | &lt;a href="https://discord.gg/pAbnFJrkgZ"&gt;💬 Join Discord&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; AG2 was evolved from AutoGen. Fully open-sourced. We invite collaborators from all organizations to contribute. &lt;/p&gt; 
&lt;h1&gt;AG2: Open-Source AgentOS for AI Agents&lt;/h1&gt; 
&lt;p&gt;AG2 (formerly AutoGen) is an open-source programming framework for building AI agents and facilitating cooperation among multiple agents to solve tasks. AG2 aims to streamline the development and research of agentic AI. It offers features such as agents capable of interacting with each other, facilitates the use of various large language models (LLMs) and tool use support, autonomous and human-in-the-loop workflows, and multi-agent conversation patterns.&lt;/p&gt; 
&lt;p&gt;The project is currently maintained by a &lt;a href="https://raw.githubusercontent.com/ag2ai/ag2/main/MAINTAINERS.md"&gt;dynamic group of volunteers&lt;/a&gt; from several organizations. Contact project administrators Chi Wang and Qingyun Wu via &lt;a href="mailto:support@ag2.ai"&gt;support@ag2.ai&lt;/a&gt; if you are interested in becoming a maintainer.&lt;/p&gt; 
&lt;h2&gt;Table of contents&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ag2ai/ag2/main/#ag2-open-source-agentos-for-ai-agents"&gt;AG2: Open-Source AgentOS for AI Agents&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ag2ai/ag2/main/#table-of-contents"&gt;Table of contents&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ag2ai/ag2/main/#getting-started"&gt;Getting started&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ag2ai/ag2/main/#installation"&gt;Installation&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ag2ai/ag2/main/#setup-your-api-keys"&gt;Setup your API keys&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ag2ai/ag2/main/#run-your-first-agent"&gt;Run your first agent&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ag2ai/ag2/main/#example-applications"&gt;Example applications&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ag2ai/ag2/main/#introduction-of-different-agent-concepts"&gt;Introduction of different agent concepts&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ag2ai/ag2/main/#conversable-agent"&gt;Conversable agent&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ag2ai/ag2/main/#human-in-the-loop"&gt;Human in the loop&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ag2ai/ag2/main/#orchestrating-multiple-agents"&gt;Orchestrating multiple agents&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ag2ai/ag2/main/#tools"&gt;Tools&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ag2ai/ag2/main/#advanced-agentic-design-patterns"&gt;Advanced agentic design patterns&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ag2ai/ag2/main/#announcements"&gt;Announcements&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ag2ai/ag2/main/#contributors-wall"&gt;Contributors Wall&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ag2ai/ag2/main/#code-style-and-linting"&gt;Code style and linting&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ag2ai/ag2/main/#related-papers"&gt;Related papers&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ag2ai/ag2/main/#cite-the-project"&gt;Cite the project&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ag2ai/ag2/main/#license"&gt;License&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Getting started&lt;/h2&gt; 
&lt;p&gt;For a step-by-step walk through of AG2 concepts and code, see &lt;a href="https://docs.ag2.ai/latest/docs/user-guide/basic-concepts/installing-ag2/"&gt;Basic Concepts&lt;/a&gt; in our documentation.&lt;/p&gt; 
&lt;h3&gt;Installation&lt;/h3&gt; 
&lt;p&gt;AG2 requires &lt;strong&gt;Python version &amp;gt;= 3.10, &amp;lt; 3.14&lt;/strong&gt;. AG2 is available via &lt;code&gt;ag2&lt;/code&gt; (or its alias &lt;code&gt;autogen&lt;/code&gt;) on PyPI.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install ag2[openai]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Minimal dependencies are installed by default. You can install extra options based on the features you need.&lt;/p&gt; 
&lt;h3&gt;Setup your API keys&lt;/h3&gt; 
&lt;p&gt;To keep your LLM dependencies neat we recommend using the &lt;code&gt;OAI_CONFIG_LIST&lt;/code&gt; file to store your API keys.&lt;/p&gt; 
&lt;p&gt;You can use the sample file &lt;code&gt;OAI_CONFIG_LIST_sample&lt;/code&gt; as a template.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;[
  {
    "model": "gpt-4o",
    "api_key": "&amp;lt;your OpenAI API key here&amp;gt;"
  }
]
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Run your first agent&lt;/h3&gt; 
&lt;p&gt;Create a script or a Jupyter Notebook and run your first agent.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from autogen import AssistantAgent, UserProxyAgent, LLMConfig

llm_config = LLMConfig.from_json(path="OAI_CONFIG_LIST")


with llm_config:
    assistant = AssistantAgent("assistant")
user_proxy = UserProxyAgent("user_proxy", code_execution_config={"work_dir": "coding", "use_docker": False})
user_proxy.initiate_chat(assistant, message="Plot a chart of NVDA and TESLA stock price change YTD.")
# This initiates an automated chat between the two agents to solve the task
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Example applications&lt;/h2&gt; 
&lt;p&gt;We maintain a dedicated repository with a wide range of applications to help you get started with various use cases or check out our collection of jupyter notebooks as a starting point.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ag2ai/build-with-ag2"&gt;Build with AG2&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ag2ai/ag2/main/notebook"&gt;Jupyter Notebooks&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Introduction of different agent concepts&lt;/h2&gt; 
&lt;p&gt;We have several agent concepts in AG2 to help you build your AI agents. We introduce the most common ones here.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Conversable Agent&lt;/strong&gt;: Agents that are able to send messages, receive messages and generate replies using GenAI models, non-GenAI tools, or human inputs.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Human in the loop&lt;/strong&gt;: Add human input to the conversation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Orchestrating multiple agents&lt;/strong&gt;: Users can orchestrate multiple agents with built-in conversation patterns such as swarms, group chats, nested chats, sequential chats or customize the orchestration by registering custom reply methods.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Tools&lt;/strong&gt;: Programs that can be registered, invoked and executed by agents&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Advanced Concepts&lt;/strong&gt;: AG2 supports more concepts such as structured outputs, rag, code execution, etc.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Conversable agent&lt;/h3&gt; 
&lt;p&gt;The &lt;a href="https://docs.ag2.ai/latest/docs/api-reference/autogen/ConversableAgent"&gt;ConversableAgent&lt;/a&gt; is the fundamental building block of AG2, designed to enable seamless communication between AI entities. This core agent type handles message exchange and response generation, serving as the base class for all agents in the framework.&lt;/p&gt; 
&lt;p&gt;In the example below, we'll create a simple information validation workflow with two specialized agents that communicate with each other:&lt;/p&gt; 
&lt;p&gt;Note: Before running this code, make sure to set your &lt;code&gt;OPENAI_API_KEY&lt;/code&gt; as an environment variable. This example uses &lt;code&gt;gpt-4o-mini&lt;/code&gt;, but you can replace it with any other &lt;a href="https://docs.ag2.ai/latest/docs/user-guide/models/amazon-bedrock"&gt;model&lt;/a&gt; supported by AG2.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# 1. Import ConversableAgent class
from autogen import ConversableAgent, LLMConfig

# 2. Define our LLM configuration for OpenAI's GPT-4o mini
#    uses the OPENAI_API_KEY environment variable
llm_config = LLMConfig(api_type="openai", model="gpt-4o-mini")


# 3. Create our LLM agent
with llm_config:
  # Create an AI agent
  assistant = ConversableAgent(
      name="assistant",
      system_message="You are an assistant that responds concisely.",
  )

  # Create another AI agent
  fact_checker = ConversableAgent(
      name="fact_checker",
      system_message="You are a fact-checking assistant.",
  )

# 4. Start the conversation
assistant.initiate_chat(
    recipient=fact_checker,
    message="What is AG2?",
    max_turns=2
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Human in the loop&lt;/h3&gt; 
&lt;p&gt;Human oversight is crucial for many AI workflows, especially when dealing with critical decisions, creative tasks, or situations requiring expert judgment. AG2 makes integrating human feedback seamless through its human-in-the-loop functionality. You can configure how and when human input is solicited using the &lt;code&gt;human_input_mode&lt;/code&gt; parameter:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;ALWAYS&lt;/code&gt;: Requires human input for every response&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;NEVER&lt;/code&gt;: Operates autonomously without human involvement&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;TERMINATE&lt;/code&gt;: Only requests human input to end conversations&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For convenience, AG2 provides the specialized &lt;code&gt;UserProxyAgent&lt;/code&gt; class that automatically sets &lt;code&gt;human_input_mode&lt;/code&gt; to &lt;code&gt;ALWAYS&lt;/code&gt; and supports code execution:&lt;/p&gt; 
&lt;p&gt;Note: Before running this code, make sure to set your &lt;code&gt;OPENAI_API_KEY&lt;/code&gt; as an environment variable. This example uses &lt;code&gt;gpt-4o-mini&lt;/code&gt;, but you can replace it with any other &lt;a href="https://docs.ag2.ai/latest/docs/user-guide/models/amazon-bedrock"&gt;model&lt;/a&gt; supported by AG2.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# 1. Import ConversableAgent and UserProxyAgent classes
from autogen import ConversableAgent, UserProxyAgent, LLMConfig

# 2. Define our LLM configuration for OpenAI's GPT-4o mini
#    uses the OPENAI_API_KEY environment variable
llm_config = LLMConfig(api_type="openai", model="gpt-4o-mini")


# 3. Create our LLM agent
with llm_config:
  assistant = ConversableAgent(
      name="assistant",
      system_message="You are a helpful assistant.",
  )

# 4. Create a human agent with manual input mode
human = ConversableAgent(
    name="human",
    human_input_mode="ALWAYS"
)
# or
human = UserProxyAgent(name="human", code_execution_config={"work_dir": "coding", "use_docker": False})

# 5. Start the chat
human.initiate_chat(
    recipient=assistant,
    message="Hello! What's 2 + 2?"
)

&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Orchestrating multiple agents&lt;/h3&gt; 
&lt;p&gt;AG2 enables sophisticated multi-agent collaboration through flexible orchestration patterns, allowing you to create dynamic systems where specialized agents work together to solve complex problems.&lt;/p&gt; 
&lt;p&gt;The framework offers both custom orchestration and several built-in collaboration patterns including &lt;code&gt;GroupChat&lt;/code&gt; and &lt;code&gt;Swarm&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Here's how to implement a collaborative team for curriculum development using GroupChat:&lt;/p&gt; 
&lt;p&gt;Note: Before running this code, make sure to set your &lt;code&gt;OPENAI_API_KEY&lt;/code&gt; as an environment variable. This example uses &lt;code&gt;gpt-4o-mini&lt;/code&gt;, but you can replace it with any other &lt;a href="https://docs.ag2.ai/latest/docs/user-guide/models/amazon-bedrock"&gt;model&lt;/a&gt; supported by AG2.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from autogen import ConversableAgent, GroupChat, GroupChatManager, LLMConfig

# Put your key in the OPENAI_API_KEY environment variable
llm_config = LLMConfig(api_type="openai", model="gpt-4o-mini")

planner_message = """You are a classroom lesson agent.
Given a topic, write a lesson plan for a fourth grade class.
Use the following format:
&amp;lt;title&amp;gt;Lesson plan title&amp;lt;/title&amp;gt;
&amp;lt;learning_objectives&amp;gt;Key learning objectives&amp;lt;/learning_objectives&amp;gt;
&amp;lt;script&amp;gt;How to introduce the topic to the kids&amp;lt;/script&amp;gt;
"""

reviewer_message = """You are a classroom lesson reviewer.
You compare the lesson plan to the fourth grade curriculum and provide a maximum of 3 recommended changes.
Provide only one round of reviews to a lesson plan.
"""

# 1. Add a separate 'description' for our planner and reviewer agents
planner_description = "Creates or revises lesson plans."

reviewer_description = """Provides one round of reviews to a lesson plan
for the lesson_planner to revise."""

with llm_config:
    lesson_planner = ConversableAgent(
        name="planner_agent",
        system_message=planner_message,
        description=planner_description,
    )

    lesson_reviewer = ConversableAgent(
        name="reviewer_agent",
        system_message=reviewer_message,
        description=reviewer_description,
    )

# 2. The teacher's system message can also be used as a description, so we don't define it
teacher_message = """You are a classroom teacher.
You decide topics for lessons and work with a lesson planner.
and reviewer to create and finalise lesson plans.
When you are happy with a lesson plan, output "DONE!".
"""

with llm_config:
    teacher = ConversableAgent(
        name="teacher_agent",
        system_message=teacher_message,
        # 3. Our teacher can end the conversation by saying DONE!
        is_termination_msg=lambda x: "DONE!" in (x.get("content", "") or "").upper(),
    )

# 4. Create the GroupChat with agents and selection method
groupchat = GroupChat(
    agents=[teacher, lesson_planner, lesson_reviewer],
    speaker_selection_method="auto",
    messages=[],
)

# 5. Our GroupChatManager will manage the conversation and uses an LLM to select the next agent
manager = GroupChatManager(
    name="group_manager",
    groupchat=groupchat,
    llm_config=llm_config,
)

# 6. Initiate the chat with the GroupChatManager as the recipient
teacher.initiate_chat(
    recipient=manager,
    message="Today, let's introduce our kids to the solar system."
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;When executed, this code creates a collaborative system where the teacher initiates the conversation, and the lesson planner and reviewer agents work together to create and refine a lesson plan. The GroupChatManager orchestrates the conversation, selecting the next agent to respond based on the context of the discussion.&lt;/p&gt; 
&lt;p&gt;For workflows requiring more structured processes, explore the Group Chat pattern in the detailed &lt;a href="https://docs.ag2.ai/latest/docs/user-guide/advanced-concepts/orchestration/group-chat/introduction"&gt;documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Tools&lt;/h3&gt; 
&lt;p&gt;Agents gain significant utility through tools as they provide access to external data, APIs, and functionality.&lt;/p&gt; 
&lt;p&gt;Note: Before running this code, make sure to set your &lt;code&gt;OPENAI_API_KEY&lt;/code&gt; as an environment variable. This example uses &lt;code&gt;gpt-4o-mini&lt;/code&gt;, but you can replace it with any other &lt;a href="https://docs.ag2.ai/latest/docs/user-guide/models/amazon-bedrock"&gt;model&lt;/a&gt; supported by AG2.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from datetime import datetime
from typing import Annotated

from autogen import ConversableAgent, register_function, LLMConfig

# Put your key in the OPENAI_API_KEY environment variable
llm_config = LLMConfig(api_type="openai", model="gpt-4o-mini")

# 1. Our tool, returns the day of the week for a given date
def get_weekday(date_string: Annotated[str, "Format: YYYY-MM-DD"]) -&amp;gt; str:
    date = datetime.strptime(date_string, "%Y-%m-%d")
    return date.strftime("%A")

# 2. Agent for determining whether to run the tool
with llm_config:
    date_agent = ConversableAgent(
        name="date_agent",
        system_message="You get the day of the week for a given date.",
    )

# 3. And an agent for executing the tool
executor_agent = ConversableAgent(
    name="executor_agent",
    human_input_mode="NEVER",
)

# 4. Registers the tool with the agents, the description will be used by the LLM
register_function(
    get_weekday,
    caller=date_agent,
    executor=executor_agent,
    description="Get the day of the week for a given date",
)

# 5. Two-way chat ensures the executor agent follows the suggesting agent
chat_result = executor_agent.initiate_chat(
    recipient=date_agent,
    message="I was born on the 25th of March 1995, what day was it?",
    max_turns=2,
)

print(chat_result.chat_history[-1]["content"])
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Advanced agentic design patterns&lt;/h3&gt; 
&lt;p&gt;AG2 supports more advanced concepts to help you build your AI agent workflows. You can find more information in the documentation.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.ag2.ai/latest/docs/user-guide/basic-concepts/structured-outputs"&gt;Structured Output&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.ag2.ai/latest/docs/user-guide/advanced-concepts/orchestration/ending-a-chat/"&gt;Ending a conversation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.ag2.ai/latest/docs/user-guide/advanced-concepts/rag/"&gt;Retrieval Augmented Generation (RAG)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.ag2.ai/latest/docs/user-guide/advanced-concepts/code-execution"&gt;Code Execution&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.ag2.ai/latest/docs/user-guide/advanced-concepts/tools/tools-with-secrets/"&gt;Tools with Secrets&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Announcements&lt;/h2&gt; 
&lt;p&gt;🔥 🎉 &lt;strong&gt;Nov 11, 2024:&lt;/strong&gt; We are evolving AutoGen into &lt;strong&gt;AG2&lt;/strong&gt;! A new organization &lt;a href="https://github.com/ag2ai"&gt;AG2AI&lt;/a&gt; is created to host the development of AG2 and related projects with open governance. Check &lt;a href="https://ag2.ai/"&gt;AG2's new look&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;📄 &lt;strong&gt;License:&lt;/strong&gt; We adopt the Apache 2.0 license from v0.3. This enhances our commitment to open-source collaboration while providing additional protections for contributors and users alike.&lt;/p&gt; 
&lt;p&gt;🎉 May 29, 2024: DeepLearning.ai launched a new short course &lt;a href="https://www.deeplearning.ai/short-courses/ai-agentic-design-patterns-with-autogen"&gt;AI Agentic Design Patterns with AutoGen&lt;/a&gt;, made in collaboration with Microsoft and Penn State University, and taught by AutoGen creators &lt;a href="https://github.com/sonichi"&gt;Chi Wang&lt;/a&gt; and &lt;a href="https://github.com/qingyun-wu"&gt;Qingyun Wu&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;🎉 May 24, 2024: Foundation Capital published an article on &lt;a href="https://www.forbes.com/sites/joannechen/2024/05/24/the-promise-of-multi-agent-ai/?sh=2c1e4f454d97"&gt;Forbes: The Promise of Multi-Agent AI&lt;/a&gt; and a video &lt;a href="https://www.youtube.com/watch?v=RLwyXRVvlNk"&gt;AI in the Real World Episode 2: Exploring Multi-Agent AI and AutoGen with Chi Wang&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;🎉 Apr 17, 2024: Andrew Ng cited AutoGen in &lt;a href="https://www.deeplearning.ai/the-batch/issue-245/"&gt;The Batch newsletter&lt;/a&gt; and &lt;a href="https://youtu.be/sal78ACtGTc?si=JduUzN_1kDnMq0vF"&gt;What's next for AI agentic workflows&lt;/a&gt; at Sequoia Capital's AI Ascent (Mar 26).&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/ag2ai/ag2/main/announcements.md"&gt;More Announcements&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Contributors Wall&lt;/h2&gt; 
&lt;a href="https://github.com/ag2ai/ag2/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=ag2ai/ag2&amp;amp;max=204" /&gt; &lt;/a&gt; 
&lt;h2&gt;Code style and linting&lt;/h2&gt; 
&lt;p&gt;This project uses pre-commit hooks to maintain code quality. Before contributing:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Install pre-commit:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install pre-commit
pre-commit install
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;The hooks will run automatically on commit, or you can run them manually:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pre-commit run --all-files
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Related papers&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://arxiv.org/abs/2308.08155"&gt;AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://arxiv.org/abs/2303.04673"&gt;EcoOptiGen: Hyperparameter Optimization for Large Language Model Generation Inference&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://arxiv.org/abs/2306.01337"&gt;MathChat: Converse to Tackle Challenging Math Problems with LLM Agents&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://arxiv.org/pdf/2402.11359"&gt;AgentOptimizer: Offline Training of Language Model Agents with Functions as Learnable Weights&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://arxiv.org/abs/2403.11322"&gt;StateFlow: Enhancing LLM Task-Solving through State-Driven Workflows&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Cite the project&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;@software{AG2_2024,
author = {Chi Wang and Qingyun Wu and the AG2 Community},
title = {AG2: Open-Source AgentOS for AI Agents},
year = {2024},
url = {https://github.com/ag2ai/ag2},
note = {Available at https://docs.ag2.ai/},
version = {latest}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the &lt;a href="https://raw.githubusercontent.com/ag2ai/ag2/main/LICENSE"&gt;Apache License, Version 2.0 (Apache-2.0)&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;This project is a spin-off of &lt;a href="https://github.com/microsoft/autogen"&gt;AutoGen&lt;/a&gt; and contains code under two licenses:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;The original code from &lt;a href="https://github.com/microsoft/autogen"&gt;https://github.com/microsoft/autogen&lt;/a&gt; is licensed under the MIT License. See the &lt;a href="https://raw.githubusercontent.com/ag2ai/ag2/main/license_original/LICENSE_original_MIT"&gt;LICENSE_original_MIT&lt;/a&gt; file for details.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Modifications and additions made in this fork are licensed under the Apache License, Version 2.0. See the &lt;a href="https://raw.githubusercontent.com/ag2ai/ag2/main/LICENSE"&gt;LICENSE&lt;/a&gt; file for the full license text.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;We have documented these changes for clarity and to ensure transparency with our user and contributor community. For more details, please see the &lt;a href="https://raw.githubusercontent.com/ag2ai/ag2/main/NOTICE.md"&gt;NOTICE&lt;/a&gt; file.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Fosowl/agenticSeek</title>
      <link>https://github.com/Fosowl/agenticSeek</link>
      <description>&lt;p&gt;Fully Local Manus AI. No APIs, No $200 monthly bills. Enjoy an autonomous agent that thinks, browses the web, and code for the sole cost of electricity. 🔔 Official updates only via twitter @Martin993886460 (Beware of fake account)&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;AgenticSeek: Private, Local Manus Alternative.&lt;/h1&gt; 
&lt;p align="center"&gt; &lt;img align="center" src="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/media/agentic_seek_logo.png" width="300" height="300" alt="Agentic Seek Logo" /&gt; &lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;English | &lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_CHS.md"&gt;中文&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_CHT.md"&gt;繁體中文&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_FR.md"&gt;Français&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_JP.md"&gt;日本語&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_PTBR.md"&gt;Português (Brasil)&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_ES.md"&gt;Español&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;A &lt;strong&gt;100% local alternative to Manus AI&lt;/strong&gt;, this voice-enabled AI assistant autonomously browses the web, writes code, and plans tasks while keeping all data on your device. Tailored for local reasoning models, it runs entirely on your hardware, ensuring complete privacy and zero cloud dependency.&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://fosowl.github.io/agenticSeek.html"&gt;&lt;img src="https://img.shields.io/static/v1?label=Website&amp;amp;message=AgenticSeek&amp;amp;color=blue&amp;amp;style=flat-square" alt="Visit AgenticSeek" /&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/badge/license-GPL--3.0-green" alt="License" /&gt; &lt;a href="https://discord.gg/8hGDaME3TC"&gt;&lt;img src="https://img.shields.io/badge/Discord-Join%20Us-7289DA?logo=discord&amp;amp;logoColor=white" alt="Discord" /&gt;&lt;/a&gt; &lt;a href="https://x.com/Martin993886460"&gt;&lt;img src="https://img.shields.io/twitter/url/https/twitter.com/fosowl.svg?style=social&amp;amp;label=Update%20%40Fosowl" alt="Twitter" /&gt;&lt;/a&gt; &lt;a href="https://github.com/Fosowl/agenticSeek/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/Fosowl/agenticSeek?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Why AgenticSeek ?&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;🔒 Fully Local &amp;amp; Private - Everything runs on your machine — no cloud, no data sharing. Your files, conversations, and searches stay private.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;🌐 Smart Web Browsing - AgenticSeek can browse the internet by itself — search, read, extract info, fill web form — all hands-free.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;💻 Autonomous Coding Assistant - Need code? It can write, debug, and run programs in Python, C, Go, Java, and more — all without supervision.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;🧠 Smart Agent Selection - You ask, it figures out the best agent for the job automatically. Like having a team of experts ready to help.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;📋 Plans &amp;amp; Executes Complex Tasks - From trip planning to complex projects — it can split big tasks into steps and get things done using multiple AI agents.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;🎙️ Voice-Enabled - Clean, fast, futuristic voice and speech to text allowing you to talk to it like it's your personal AI from a sci-fi movie. (In progress)&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;strong&gt;Demo&lt;/strong&gt;&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;em&gt;Can you search for the agenticSeek project, learn what skills are required, then open the CV_candidates.zip and then tell me which match best the project&lt;/em&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/b8ca60e9-7b3b-4533-840e-08f9ac426316"&gt;https://github.com/user-attachments/assets/b8ca60e9-7b3b-4533-840e-08f9ac426316&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Disclaimer: This demo, including all the files that appear (e.g: CV_candidates.zip), are entirely fictional. We are not a corporation, we seek open-source contributors not candidates.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;🛠⚠️️ &lt;strong&gt;Active Work in Progress&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;🙏 This project started as a side-project and has zero roadmap and zero funding. It's grown way beyond what I expected by ending in GitHub Trending. Contributions, feedback, and patience are deeply appreciated.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Prerequisites&lt;/h2&gt; 
&lt;p&gt;Before you begin, ensure you have the following software installed:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Git:&lt;/strong&gt; For cloning the repository. &lt;a href="https://git-scm.com/downloads"&gt;Download Git&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Python 3.10.x:&lt;/strong&gt; We strongly recommend using Python version 3.10.x. Using other versions might lead to dependency errors. &lt;a href="https://www.python.org/downloads/release/python-3100/"&gt;Download Python 3.10&lt;/a&gt; (pick a 3.10.x version).&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Docker Engine &amp;amp; Docker Compose:&lt;/strong&gt; For running bundled services like SearxNG. 
  &lt;ul&gt; 
   &lt;li&gt;Install Docker Desktop (which includes Docker Compose V2): &lt;a href="https://docs.docker.com/desktop/install/windows-install/"&gt;Windows&lt;/a&gt; | &lt;a href="https://docs.docker.com/desktop/install/mac-install/"&gt;Mac&lt;/a&gt; | &lt;a href="https://docs.docker.com/desktop/install/linux-install/"&gt;Linux&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;Alternatively, install Docker Engine and Docker Compose separately on Linux: &lt;a href="https://docs.docker.com/engine/install/"&gt;Docker Engine&lt;/a&gt; | &lt;a href="https://docs.docker.com/compose/install/"&gt;Docker Compose&lt;/a&gt; (ensure you install Compose V2, e.g., &lt;code&gt;sudo apt-get install docker-compose-plugin&lt;/code&gt;).&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;1. &lt;strong&gt;Clone the repository and setup&lt;/strong&gt;&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;git clone https://github.com/Fosowl/agenticSeek.git
cd agenticSeek
mv .env.example .env
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;2. Change the .env file content&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;SEARXNG_BASE_URL="http://127.0.0.1:8080"
REDIS_BASE_URL="redis://redis:6379/0"
WORK_DIR="/Users/mlg/Documents/workspace_for_ai"
OLLAMA_PORT="11434"
LM_STUDIO_PORT="1234"
CUSTOM_ADDITIONAL_LLM_PORT="11435"
OPENAI_API_KEY='optional'
DEEPSEEK_API_KEY='optional'
OPENROUTER_API_KEY='optional'
TOGETHER_API_KEY='optional'
GOOGLE_API_KEY='optional'
ANTHROPIC_API_KEY='optional'
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Update the &lt;code&gt;.env&lt;/code&gt; file with your own values as needed:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;SEARXNG_BASE_URL&lt;/strong&gt;: Leave unchanged&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;REDIS_BASE_URL&lt;/strong&gt;: Leave unchanged&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;WORK_DIR&lt;/strong&gt;: Path to your working directory on your local machine. AgenticSeek will be able to read and interact with these files.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;OLLAMA_PORT&lt;/strong&gt;: Port number for the Ollama service.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;LM_STUDIO_PORT&lt;/strong&gt;: Port number for the LM Studio service.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;CUSTOM_ADDITIONAL_LLM_PORT&lt;/strong&gt;: Port for any additional custom LLM service.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;API Key are totally optional for user who choose to run LLM locally. Which is the primary purpose of this project. Leave empty if you have sufficient hardware&lt;/strong&gt;&lt;/p&gt; 
&lt;h3&gt;3. &lt;strong&gt;Start Docker&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;Make sure Docker is installed and running on your system. You can start Docker using the following commands:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;On Linux/macOS:&lt;/strong&gt;&lt;br /&gt; Open a terminal and run:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-sh"&gt;sudo systemctl start docker
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Or launch Docker Desktop from your applications menu if installed.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;On Windows:&lt;/strong&gt;&lt;br /&gt; Start Docker Desktop from the Start menu.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;You can verify Docker is running by executing:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;docker info
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you see information about your Docker installation, it is running correctly.&lt;/p&gt; 
&lt;p&gt;See the table of &lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#list-of-local-providers"&gt;Local Providers&lt;/a&gt; below for a summary.&lt;/p&gt; 
&lt;p&gt;Next step: &lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#start-services-and-run"&gt;Run AgenticSeek locally&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;See the &lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#troubleshooting"&gt;Troubleshooting&lt;/a&gt; section if you are having issues.&lt;/em&gt; &lt;em&gt;If your hardware can't run LLMs locally, see &lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#setup-to-run-with-an-api"&gt;Setup to run with an API&lt;/a&gt;.&lt;/em&gt; &lt;em&gt;For detailed &lt;code&gt;config.ini&lt;/code&gt; explanations, see &lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#config"&gt;Config Section&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Setup for running LLM locally on your machine&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Hardware Requirements:&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;To run LLMs locally, you'll need sufficient hardware. At a minimum, a GPU capable of running Magistral, Qwen or Deepseek 14B is required. See the FAQ for detailed model/performance recommendations.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Setup your local provider&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Start your local provider, for example with ollama:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;ollama serve
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See below for a list of local supported provider.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Update the config.ini&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Change the config.ini file to set the provider_name to a supported provider and provider_model to a LLM supported by your provider. We recommend reasoning model such as &lt;em&gt;Magistral&lt;/em&gt; or &lt;em&gt;Deepseek&lt;/em&gt;.&lt;/p&gt; 
&lt;p&gt;See the &lt;strong&gt;FAQ&lt;/strong&gt; at the end of the README for required hardware.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;[MAIN]
is_local = True # Whenever you are running locally or with remote provider.
provider_name = ollama # or lm-studio, openai, etc..
provider_model = deepseek-r1:14b # choose a model that fit your hardware
provider_server_address = 127.0.0.1:11434
agent_name = Jarvis # name of your AI
recover_last_session = True # whenever to recover the previous session
save_session = True # whenever to remember the current session
speak = False # text to speech
listen = False # Speech to text, only for CLI, experimental
jarvis_personality = False # Whenever to use a more "Jarvis" like personality (experimental)
languages = en zh # The list of languages, Text to speech will default to the first language on the list
[BROWSER]
headless_browser = True # leave unchanged unless using CLI on host.
stealth_mode = True # Use undetected selenium to reduce browser detection
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Warning&lt;/strong&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;The &lt;code&gt;config.ini&lt;/code&gt; file format does not support comments. Do not copy and paste the example configuration directly, as comments will cause errors. Instead, manually modify the &lt;code&gt;config.ini&lt;/code&gt; file with your desired settings, excluding any comments.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Do &lt;em&gt;NOT&lt;/em&gt; set provider_name to &lt;code&gt;openai&lt;/code&gt; if using LM-studio for running LLMs. Set it to &lt;code&gt;lm-studio&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Some provider (eg: lm-studio) require you to have &lt;code&gt;http://&lt;/code&gt; in front of the IP. For example &lt;code&gt;http://127.0.0.1:1234&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;List of local providers&lt;/strong&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Provider&lt;/th&gt; 
   &lt;th&gt;Local?&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ollama&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Run LLMs locally with ease using ollama as a LLM provider&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;lm-studio&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Run LLM locally with LM studio (set &lt;code&gt;provider_name&lt;/code&gt; to &lt;code&gt;lm-studio&lt;/code&gt;)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;openai&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Use openai compatible API (eg: llama.cpp server)&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Next step: &lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#Start-services-and-Run"&gt;Start services and run AgenticSeek&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;See the &lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#troubleshooting"&gt;Troubleshooting&lt;/a&gt; section if you are having issues.&lt;/em&gt; &lt;em&gt;If your hardware can't run LLMs locally, see &lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#setup-to-run-with-an-api"&gt;Setup to run with an API&lt;/a&gt;.&lt;/em&gt; &lt;em&gt;For detailed &lt;code&gt;config.ini&lt;/code&gt; explanations, see &lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#config"&gt;Config Section&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt; 
&lt;h2&gt;Setup to run with an API&lt;/h2&gt; 
&lt;p&gt;This setup uses external, cloud-based LLM providers. You'll need an API key from your chosen service.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;1. Choose an API Provider and Get an API Key:&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Refer to the &lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#list-of-api-providers"&gt;List of API Providers&lt;/a&gt; below. Visit their websites to sign up and obtain an API key.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2. Set Your API Key as an Environment Variable:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Linux/macOS:&lt;/strong&gt; Open your terminal and use the &lt;code&gt;export&lt;/code&gt; command. It's best to add this to your shell's profile file (e.g., &lt;code&gt;~/.bashrc&lt;/code&gt;, &lt;code&gt;~/.zshrc&lt;/code&gt;) for persistence.&lt;/p&gt; &lt;pre&gt;&lt;code class="language-sh"&gt;export PROVIDER_API_KEY="your_api_key_here" 
# Replace PROVIDER_API_KEY with the specific variable name, e.g., OPENAI_API_KEY, GOOGLE_API_KEY
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Example for TogetherAI:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-sh"&gt;export TOGETHER_API_KEY="xxxxxxxxxxxxxxxxxxxxxx"
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Windows:&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Command Prompt (Temporary for current session):&lt;/strong&gt; &lt;pre&gt;&lt;code class="language-cmd"&gt;set PROVIDER_API_KEY=your_api_key_here
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;PowerShell (Temporary for current session):&lt;/strong&gt; &lt;pre&gt;&lt;code class="language-powershell"&gt;$env:PROVIDER_API_KEY="your_api_key_here"
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Permanently:&lt;/strong&gt; Search for "environment variables" in the Windows search bar, click "Edit the system environment variables," then click the "Environment Variables..." button. Add a new User variable with the appropriate name (e.g., &lt;code&gt;OPENAI_API_KEY&lt;/code&gt;) and your key as the value.&lt;/li&gt; 
  &lt;/ul&gt; &lt;p&gt;&lt;em&gt;(See FAQ: &lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#how-do-i-set-api-keys"&gt;How do I set API keys?&lt;/a&gt; for more details).&lt;/em&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;3. Update &lt;code&gt;config.ini&lt;/code&gt;:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-ini"&gt;[MAIN]
is_local = False
provider_name = openai # Or google, deepseek, togetherAI, huggingface
provider_model = gpt-3.5-turbo # Or gemini-1.5-flash, deepseek-chat, mistralai/Mixtral-8x7B-Instruct-v0.1 etc.
provider_server_address = # Typically ignored or can be left blank when is_local = False for most APIs
# ... other settings ...
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;em&gt;Warning:&lt;/em&gt; Make sure there are no trailing spaces in the &lt;code&gt;config.ini&lt;/code&gt; values.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;List of API Providers&lt;/strong&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Provider&lt;/th&gt; 
   &lt;th&gt;&lt;code&gt;provider_name&lt;/code&gt;&lt;/th&gt; 
   &lt;th&gt;Local?&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;API Key Link (Examples)&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;OpenAI&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;openai&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;Use ChatGPT models via OpenAI's API.&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://platform.openai.com/signup"&gt;platform.openai.com/signup&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Google Gemini&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;google&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;Use Google Gemini models via Google AI Studio.&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aistudio.google.com/keys"&gt;aistudio.google.com/keys&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Deepseek&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;deepseek&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;Use Deepseek models via their API.&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://platform.deepseek.com"&gt;platform.deepseek.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Hugging Face&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;huggingface&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;Use models from Hugging Face Inference API.&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/settings/tokens"&gt;huggingface.co/settings/tokens&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;TogetherAI&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;togetherAI&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;Use various open-source models via TogetherAI API.&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://api.together.ai/settings/api-keys"&gt;api.together.ai/settings/api-keys&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;em&gt;Note:&lt;/em&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;We advise against using &lt;code&gt;gpt-4o&lt;/code&gt; or other OpenAI models for complex web browsing and task planning as current prompt optimizations are geared towards models like Deepseek.&lt;/li&gt; 
 &lt;li&gt;Coding/bash tasks might encounter issues with Gemini, as it may not strictly follow formatting prompts optimized for Deepseek.&lt;/li&gt; 
 &lt;li&gt;The &lt;code&gt;provider_server_address&lt;/code&gt; in &lt;code&gt;config.ini&lt;/code&gt; is generally not used when &lt;code&gt;is_local = False&lt;/code&gt; as the API endpoint is usually hardcoded in the respective provider's library.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Next step: &lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#Start-services-and-Run"&gt;Start services and run AgenticSeek&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;See the &lt;strong&gt;Known issues&lt;/strong&gt; section if you are having issues&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;See the &lt;strong&gt;Config&lt;/strong&gt; section for detailed config file explanation.&lt;/em&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Start services and Run&lt;/h2&gt; 
&lt;p&gt;By default AgenticSeek is run fully in docker.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Option 1:&lt;/strong&gt; Run in Docker, use web interface:&lt;/p&gt; 
&lt;p&gt;Start required services. This will start all services from the docker-compose.yml, including: - searxng - redis (required by searxng) - frontend - backend (if using &lt;code&gt;full&lt;/code&gt; when using the web interface)&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;./start_services.sh full # MacOS
start start_services.cmd full # Window
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Warning:&lt;/strong&gt; This step will download and load all Docker images, which may take up to 30 minutes. After starting the services, please wait until the backend service is fully running (you should see &lt;strong&gt;backend: "GET /health HTTP/1.1" 200 OK&lt;/strong&gt; in the log) before sending any messages. The backend services might take 5 minute to start on first run.&lt;/p&gt; 
&lt;p&gt;Go to &lt;code&gt;http://localhost:3000/&lt;/code&gt; and you should see the web interface.&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;Troubleshooting service start:&lt;/em&gt; If these scripts fail, ensure Docker Engine is running and Docker Compose (V2, &lt;code&gt;docker compose&lt;/code&gt;) is correctly installed. Check the output in the terminal for error messages. See &lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#faq-troubleshooting"&gt;FAQ: Help! I get an error when running AgenticSeek or its scripts.&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Option 2:&lt;/strong&gt; CLI mode:&lt;/p&gt; 
&lt;p&gt;To run with CLI interface you would have to install package on host:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;./install.sh
./install.bat # windows
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Start required services. This will start some services from the docker-compose.yml, including: - searxng - redis (required by searxng) - frontend&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;./start_services.sh # MacOS
start start_services.cmd # Window
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Use the CLI: &lt;code&gt;uv run cli.py&lt;/code&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;p&gt;Make sure the services are up and running with &lt;code&gt;./start_services.sh full&lt;/code&gt; and go to &lt;code&gt;localhost:3000&lt;/code&gt; for web interface.&lt;/p&gt; 
&lt;p&gt;You can also use speech to text by setting &lt;code&gt;listen = True&lt;/code&gt; in the config. Only for CLI mode.&lt;/p&gt; 
&lt;p&gt;To exit, simply say/type &lt;code&gt;goodbye&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Here are some example usage:&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;em&gt;Make a snake game in python!&lt;/em&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;em&gt;Search the web for top cafes in Rennes, France, and save a list of three with their addresses in rennes_cafes.txt.&lt;/em&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;em&gt;Write a Go program to calculate the factorial of a number, save it as factorial.go in your workspace&lt;/em&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;em&gt;Search my summer_pictures folder for all JPG files, rename them with today’s date, and save a list of renamed files in photos_list.txt&lt;/em&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;em&gt;Search online for popular sci-fi movies from 2024 and pick three to watch tonight. Save the list in movie_night.txt.&lt;/em&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;em&gt;Search the web for the latest AI news articles from 2025, select three, and write a Python script to scrape their titles and summaries. Save the script as news_scraper.py and the summaries in ai_news.txt in /home/projects&lt;/em&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;em&gt;Friday, search the web for a free stock price API, register with &lt;a href="mailto:supersuper7434567@gmail.com"&gt;supersuper7434567@gmail.com&lt;/a&gt; then write a Python script to fetch using the API daily prices for Tesla, and save the results in stock_prices.csv&lt;/em&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;em&gt;Note that form filling capabilities are still experimental and might fail.&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;After you type your query, AgenticSeek will allocate the best agent for the task.&lt;/p&gt; 
&lt;p&gt;Because this is an early prototype, the agent routing system might not always allocate the right agent based on your query.&lt;/p&gt; 
&lt;p&gt;Therefore, you should be very explicit in what you want and how the AI might proceed for example if you want it to conduct a web search, do not say:&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;Do you know some good countries for solo-travel?&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;Instead, ask:&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;Do a web search and find out which are the best country for solo-travel&lt;/code&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;&lt;strong&gt;Setup to run the LLM on your own server&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;If you have a powerful computer or a server that you can use, but you want to use it from your laptop you have the options to run the LLM on a remote server using our custom llm server.&lt;/p&gt; 
&lt;p&gt;On your "server" that will run the AI model, get the ip address&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;ip a | grep "inet " | grep -v 127.0.0.1 | awk '{print $2}' | cut -d/ -f1 # local ip
curl https://ipinfo.io/ip # public ip
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Note: For Windows or macOS, use ipconfig or ifconfig respectively to find the IP address.&lt;/p&gt; 
&lt;p&gt;Clone the repository and enter the &lt;code&gt;server/&lt;/code&gt;folder.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;git clone --depth 1 https://github.com/Fosowl/agenticSeek.git
cd agenticSeek/llm_server/
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Install server specific requirements:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;pip3 install -r requirements.txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Run the server script.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;python3 app.py --provider ollama --port 3333
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You have the choice between using &lt;code&gt;ollama&lt;/code&gt; and &lt;code&gt;llamacpp&lt;/code&gt; as a LLM service.&lt;/p&gt; 
&lt;p&gt;Now on your personal computer:&lt;/p&gt; 
&lt;p&gt;Change the &lt;code&gt;config.ini&lt;/code&gt; file to set the &lt;code&gt;provider_name&lt;/code&gt; to &lt;code&gt;server&lt;/code&gt; and &lt;code&gt;provider_model&lt;/code&gt; to &lt;code&gt;deepseek-r1:xxb&lt;/code&gt;. Set the &lt;code&gt;provider_server_address&lt;/code&gt; to the ip address of the machine that will run the model.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;[MAIN]
is_local = False
provider_name = server
provider_model = deepseek-r1:70b
provider_server_address = http://x.x.x.x:3333
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Next step: &lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#Start-services-and-Run"&gt;Start services and run AgenticSeek&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Speech to Text&lt;/h2&gt; 
&lt;p&gt;Warning: speech to text only work in CLI mode at the moment.&lt;/p&gt; 
&lt;p&gt;Please note that currently speech to text only work in english.&lt;/p&gt; 
&lt;p&gt;The speech-to-text functionality is disabled by default. To enable it, set the listen option to True in the config.ini file:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;listen = True
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;When enabled, the speech-to-text feature listens for a trigger keyword, which is the agent's name, before it begins processing your input. You can customize the agent's name by updating the &lt;code&gt;agent_name&lt;/code&gt; value in the &lt;em&gt;config.ini&lt;/em&gt; file:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;agent_name = Friday
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For optimal recognition, we recommend using a common English name like "John" or "Emma" as the agent name&lt;/p&gt; 
&lt;p&gt;Once you see the transcript start to appear, say the agent's name aloud to wake it up (e.g., "Friday").&lt;/p&gt; 
&lt;p&gt;Speak your query clearly.&lt;/p&gt; 
&lt;p&gt;End your request with a confirmation phrase to signal the system to proceed. Examples of confirmation phrases include:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;"do it", "go ahead", "execute", "run", "start", "thanks", "would ya", "please", "okay?", "proceed", "continue", "go on", "do that", "go it", "do you understand?"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Config&lt;/h2&gt; 
&lt;p&gt;Example config:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;[MAIN]
is_local = True
provider_name = ollama
provider_model = deepseek-r1:32b
provider_server_address = http://127.0.0.1:11434 # Example for Ollama; use http://127.0.0.1:1234 for LM-Studio
agent_name = Friday
recover_last_session = False
save_session = False
speak = False
listen = False

jarvis_personality = False
languages = en zh # List of languages for TTS and potentially routing.
[BROWSER]
headless_browser = False
stealth_mode = False
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Explanation of &lt;code&gt;config.ini&lt;/code&gt; Settings&lt;/strong&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;[MAIN]&lt;/code&gt; Section:&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;is_local&lt;/code&gt;: &lt;code&gt;True&lt;/code&gt; if using a local LLM provider (Ollama, LM-Studio, local OpenAI-compatible server) or the self-hosted server option. &lt;code&gt;False&lt;/code&gt; if using a cloud-based API (OpenAI, Google, etc.).&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;provider_name&lt;/code&gt;: Specifies the LLM provider. 
    &lt;ul&gt; 
     &lt;li&gt;Local options: &lt;code&gt;ollama&lt;/code&gt;, &lt;code&gt;lm-studio&lt;/code&gt;, &lt;code&gt;openai&lt;/code&gt; (for local OpenAI-compatible servers), &lt;code&gt;server&lt;/code&gt; (for the self-hosted server setup).&lt;/li&gt; 
     &lt;li&gt;API options: &lt;code&gt;openai&lt;/code&gt;, &lt;code&gt;google&lt;/code&gt;, &lt;code&gt;deepseek&lt;/code&gt;, &lt;code&gt;huggingface&lt;/code&gt;, &lt;code&gt;togetherAI&lt;/code&gt;.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;provider_model&lt;/code&gt;: The specific model name or ID for the chosen provider (e.g., &lt;code&gt;deepseekcoder:6.7b&lt;/code&gt; for Ollama, &lt;code&gt;gpt-3.5-turbo&lt;/code&gt; for OpenAI API, &lt;code&gt;mistralai/Mixtral-8x7B-Instruct-v0.1&lt;/code&gt; for TogetherAI).&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;provider_server_address&lt;/code&gt;: The address of your LLM provider. 
    &lt;ul&gt; 
     &lt;li&gt;For local providers: e.g., &lt;code&gt;http://127.0.0.1:11434&lt;/code&gt; for Ollama, &lt;code&gt;http://127.0.0.1:1234&lt;/code&gt; for LM-Studio.&lt;/li&gt; 
     &lt;li&gt;For the &lt;code&gt;server&lt;/code&gt; provider type: The address of your self-hosted LLM server (e.g., &lt;code&gt;http://your_server_ip:3333&lt;/code&gt;).&lt;/li&gt; 
     &lt;li&gt;For cloud APIs (&lt;code&gt;is_local = False&lt;/code&gt;): This is often ignored or can be left blank, as the API endpoint is usually handled by the client library.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;agent_name&lt;/code&gt;: Name of the AI assistant (e.g., Friday). Used as a trigger word for speech-to-text if enabled.&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;recover_last_session&lt;/code&gt;: &lt;code&gt;True&lt;/code&gt; to attempt to restore the previous session's state, &lt;code&gt;False&lt;/code&gt; to start fresh.&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;save_session&lt;/code&gt;: &lt;code&gt;True&lt;/code&gt; to save the current session's state for potential recovery, &lt;code&gt;False&lt;/code&gt; otherwise.&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;speak&lt;/code&gt;: &lt;code&gt;True&lt;/code&gt; to enable text-to-speech voice output, &lt;code&gt;False&lt;/code&gt; to disable.&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;listen&lt;/code&gt;: &lt;code&gt;True&lt;/code&gt; to enable speech-to-text voice input (CLI mode only), &lt;code&gt;False&lt;/code&gt; to disable.&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;work_dir&lt;/code&gt;: &lt;strong&gt;Crucial:&lt;/strong&gt; The directory where AgenticSeek will read/write files. &lt;strong&gt;Ensure this path is valid and accessible on your system.&lt;/strong&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;jarvis_personality&lt;/code&gt;: &lt;code&gt;True&lt;/code&gt; to use a more "Jarvis-like" system prompt (experimental), &lt;code&gt;False&lt;/code&gt; for the standard prompt.&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;languages&lt;/code&gt;: A comma-separated list of languages (e.g., &lt;code&gt;en, zh, fr&lt;/code&gt;). Used for TTS voice selection (defaults to the first) and can assist the LLM router. Avoid too many or very similar languages for router efficiency.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;[BROWSER]&lt;/code&gt; Section:&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;headless_browser&lt;/code&gt;: &lt;code&gt;True&lt;/code&gt; to run the automated browser without a visible window (recommended for web interface or non-interactive use). &lt;code&gt;False&lt;/code&gt; to show the browser window (useful for CLI mode or debugging).&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;stealth_mode&lt;/code&gt;: &lt;code&gt;True&lt;/code&gt; to enable measures to make browser automation harder to detect. May require manual installation of browser extensions like anticaptcha.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;This section summarizes the supported LLM provider types. Configure them in &lt;code&gt;config.ini&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Local Providers (Run on Your Own Hardware):&lt;/strong&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Provider Name in &lt;code&gt;config.ini&lt;/code&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;code&gt;is_local&lt;/code&gt;&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Setup Section&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;ollama&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;True&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Use Ollama to serve local LLMs.&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#setup-for-running-llm-locally-on-your-machine"&gt;Setup for running LLM locally&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;lm-studio&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;True&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Use LM-Studio to serve local LLMs.&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#setup-for-running-llm-locally-on-your-machine"&gt;Setup for running LLM locally&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;openai&lt;/code&gt; (for local server)&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;True&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Connect to a local server that exposes an OpenAI-compatible API (e.g., llama.cpp).&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#setup-for-running-llm-locally-on-your-machine"&gt;Setup for running LLM locally&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;server&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;False&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Connect to the AgenticSeek self-hosted LLM server running on another machine.&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#setup-to-run-the-llm-on-your-own-server"&gt;Setup to run the LLM on your own server&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;API Providers (Cloud-Based):&lt;/strong&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Provider Name in &lt;code&gt;config.ini&lt;/code&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;code&gt;is_local&lt;/code&gt;&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Setup Section&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;openai&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;False&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Use OpenAI's official API (e.g., GPT-3.5, GPT-4).&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#setup-to-run-with-an-api"&gt;Setup to run with an API&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;google&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;False&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Use Google's Gemini models via API.&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#setup-to-run-with-an-api"&gt;Setup to run with an API&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;deepseek&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;False&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Use Deepseek's official API.&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#setup-to-run-with-an-api"&gt;Setup to run with an API&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;huggingface&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;False&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Use Hugging Face Inference API.&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#setup-to-run-with-an-api"&gt;Setup to run with an API&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;togetherAI&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;False&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Use TogetherAI's API for various open models.&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#setup-to-run-with-an-api"&gt;Setup to run with an API&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Troubleshooting&lt;/h2&gt; 
&lt;p&gt;If you encounter issues, this section provides guidance.&lt;/p&gt; 
&lt;h1&gt;Known Issues&lt;/h1&gt; 
&lt;h2&gt;ChromeDriver Issues&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Error Example:&lt;/strong&gt; &lt;code&gt;SessionNotCreatedException: Message: session not created: This version of ChromeDriver only supports Chrome version XXX&lt;/code&gt;&lt;/p&gt; 
&lt;h3&gt;Root Cause&lt;/h3&gt; 
&lt;p&gt;ChromeDriver version incompatibility occurs when:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Your installed ChromeDriver version doesn't match your Chrome browser version&lt;/li&gt; 
 &lt;li&gt;In Docker environments, &lt;code&gt;undetected_chromedriver&lt;/code&gt; may download its own ChromeDriver version, bypassing the mounted binary&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Solution Steps&lt;/h3&gt; 
&lt;h4&gt;1. Check Your Chrome Version&lt;/h4&gt; 
&lt;p&gt;Open Google Chrome → &lt;code&gt;Settings &amp;gt; About Chrome&lt;/code&gt; to find your version (e.g., "Version 134.0.6998.88")&lt;/p&gt; 
&lt;h4&gt;2. Download Matching ChromeDriver&lt;/h4&gt; 
&lt;p&gt;&lt;strong&gt;For Chrome 115 and newer:&lt;/strong&gt; Use the &lt;a href="https://googlechromelabs.github.io/chrome-for-testing/"&gt;Chrome for Testing API&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Visit the Chrome for Testing availability dashboard&lt;/li&gt; 
 &lt;li&gt;Find your Chrome version or the closest available match&lt;/li&gt; 
 &lt;li&gt;Download the ChromeDriver for your OS (Linux64 for Docker environments)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;For older Chrome versions:&lt;/strong&gt; Use the &lt;a href="https://chromedriver.chromium.org/downloads"&gt;legacy ChromeDriver downloads&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/media/chromedriver_readme.png" alt="Download ChromeDriver from Chrome for Testing" /&gt;&lt;/p&gt; 
&lt;h4&gt;3. Install ChromeDriver (Choose One Method)&lt;/h4&gt; 
&lt;p&gt;&lt;strong&gt;Method A: Project Root Directory (Recommended for Docker)&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Place the downloaded chromedriver binary in your project root
cp path/to/downloaded/chromedriver ./chromedriver
chmod +x ./chromedriver  # Make executable on Linux/macOS
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Method B: System PATH&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Linux/macOS
sudo mv chromedriver /usr/local/bin/
sudo chmod +x /usr/local/bin/chromedriver

# Windows: Place chromedriver.exe in a folder that's in your PATH
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;4. Verify Installation&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Test the ChromeDriver version
./chromedriver --version
# OR if in PATH:
chromedriver --version
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Docker-Specific Notes&lt;/h3&gt; 
&lt;p&gt;⚠️ &lt;strong&gt;Important for Docker Users:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;The Docker volume mount approach may not work with stealth mode (&lt;code&gt;undetected_chromedriver&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Solution&lt;/strong&gt;: Place ChromeDriver in the project root directory as &lt;code&gt;./chromedriver&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;The application will automatically detect and use this binary&lt;/li&gt; 
 &lt;li&gt;You should see: &lt;code&gt;"Using ChromeDriver from project root: ./chromedriver"&lt;/code&gt; in the logs&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Troubleshooting Tips&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Still getting version mismatch?&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Verify the ChromeDriver is executable: &lt;code&gt;ls -la ./chromedriver&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;Check the ChromeDriver version: &lt;code&gt;./chromedriver --version&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;Ensure it matches your Chrome browser version&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Docker container issues?&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Check backend logs: &lt;code&gt;docker logs backend&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;Look for the message: &lt;code&gt;"Using ChromeDriver from project root"&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;If not found, verify the file exists and is executable&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Chrome for Testing versions&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Use the exact version match when possible&lt;/li&gt; 
   &lt;li&gt;For version 134.0.6998.88, use ChromeDriver 134.0.6998.165 (closest available)&lt;/li&gt; 
   &lt;li&gt;Major version numbers must match (134 = 134)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Version Compatibility Matrix&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Chrome Version&lt;/th&gt; 
   &lt;th&gt;ChromeDriver Version&lt;/th&gt; 
   &lt;th&gt;Status&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;134.0.6998.x&lt;/td&gt; 
   &lt;td&gt;134.0.6998.165&lt;/td&gt; 
   &lt;td&gt;✅ Works&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;133.0.6943.x&lt;/td&gt; 
   &lt;td&gt;133.0.6943.141&lt;/td&gt; 
   &lt;td&gt;✅ Works&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;132.0.6834.x&lt;/td&gt; 
   &lt;td&gt;132.0.6834.159&lt;/td&gt; 
   &lt;td&gt;✅ Works&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;em&gt;For the latest compatibility, check the &lt;a href="https://googlechromelabs.github.io/chrome-for-testing/"&gt;Chrome for Testing dashboard&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;Exception: Failed to initialize browser: Message: session not created: This version of ChromeDriver only supports Chrome version 113 Current browser version is 134.0.6998.89 with binary path&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;This happen if there is a mismatch between your browser and chromedriver version.&lt;/p&gt; 
&lt;p&gt;You need to navigate to download the latest version:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://developer.chrome.com/docs/chromedriver/downloads"&gt;https://developer.chrome.com/docs/chromedriver/downloads&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;If you're using Chrome version 115 or newer go to:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://googlechromelabs.github.io/chrome-for-testing/"&gt;https://googlechromelabs.github.io/chrome-for-testing/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;And download the chromedriver version matching your OS.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/media/chromedriver_readme.png" alt="alt text" /&gt;&lt;/p&gt; 
&lt;p&gt;If this section is incomplete please raise an issue.&lt;/p&gt; 
&lt;h2&gt;connection adapters Issues&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;Exception: Provider lm-studio failed: HTTP request failed: No connection adapters were found for '127.0.0.1:1234/v1/chat/completions'` (Note: port may vary)
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Cause:&lt;/strong&gt; The &lt;code&gt;provider_server_address&lt;/code&gt; in &lt;code&gt;config.ini&lt;/code&gt; for &lt;code&gt;lm-studio&lt;/code&gt; (or other similar local OpenAI-compatible servers) is missing the &lt;code&gt;http://&lt;/code&gt; prefix or is pointing to the wrong port.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Solution:&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Ensure the address includes &lt;code&gt;http://&lt;/code&gt;. LM-Studio typically defaults to &lt;code&gt;http://127.0.0.1:1234&lt;/code&gt;.&lt;/li&gt; 
   &lt;li&gt;Correct &lt;code&gt;config.ini&lt;/code&gt;: &lt;code&gt;provider_server_address = http://127.0.0.1:1234&lt;/code&gt; (or your actual LM-Studio server port).&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;SearxNG Base URL Not Provided&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;raise ValueError("SearxNG base URL must be provided either as an argument or via the SEARXNG_BASE_URL environment variable.")
ValueError: SearxNG base URL must be provided either as an argument or via the SEARXNG_BASE_URL environment variable.`
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;FAQ&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Q: What hardware do I need?&lt;/strong&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Model Size&lt;/th&gt; 
   &lt;th&gt;GPU&lt;/th&gt; 
   &lt;th&gt;Comment&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;7B&lt;/td&gt; 
   &lt;td&gt;8GB Vram&lt;/td&gt; 
   &lt;td&gt;⚠️ Not recommended. Performance is poor, frequent hallucinations, and planner agents will likely fail.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;14B&lt;/td&gt; 
   &lt;td&gt;12 GB VRAM (e.g. RTX 3060)&lt;/td&gt; 
   &lt;td&gt;✅ Usable for simple tasks. May struggle with web browsing and planning tasks.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;32B&lt;/td&gt; 
   &lt;td&gt;24+ GB VRAM (e.g. RTX 4090)&lt;/td&gt; 
   &lt;td&gt;🚀 Success with most tasks, might still struggle with task planning&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;70B+&lt;/td&gt; 
   &lt;td&gt;48+ GB Vram&lt;/td&gt; 
   &lt;td&gt;💪 Excellent. Recommended for advanced use cases.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;Q: I get an error what do I do?&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Ensure local is running (&lt;code&gt;ollama serve&lt;/code&gt;), your &lt;code&gt;config.ini&lt;/code&gt; matches your provider, and dependencies are installed. If none work feel free to raise an issue.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Q: Can it really run 100% locally?&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Yes with Ollama, lm-studio or server providers, all speech to text, LLM and text to speech model run locally. Non-local options (OpenAI or others API) are optional.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Q: Why should I use AgenticSeek when I have Manus?&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Unlike Manus, AgenticSeek prioritizes independence from external systems, giving you more control, privacy and avoid api cost.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Q: Who is behind the project ?&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;The project was created by me, along with two friends who serve as maintainers and contributors from the open-source community on GitHub. We’re just a group of passionate individuals, not a startup or affiliated with any organization.&lt;/p&gt; 
&lt;p&gt;Any AgenticSeek account on X other than my personal account (&lt;a href="https://x.com/Martin993886460"&gt;https://x.com/Martin993886460&lt;/a&gt;) is an impersonation.&lt;/p&gt; 
&lt;h2&gt;Contribute&lt;/h2&gt; 
&lt;p&gt;We’re looking for developers to improve AgenticSeek! Check out open issues or discussion.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/docs/CONTRIBUTING.md"&gt;Contribution guide&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Sponsors:&lt;/h2&gt; 
&lt;p&gt;Want to level up AgenticSeek capabilities with features like flight search, trip planning, or snagging the best shopping deals? Consider crafting a custom tool with SerpApi to unlock more Jarvis-like capabilities. With SerpApi, you can turbocharge your agent for specialized tasks while staying in full control.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://serpapi.com/"&gt;&lt;img src="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/media/banners/sponsor_banner_serpapi.png" height="350" alt="SerpApi Banner" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/docs/CONTRIBUTING.md"&gt;Contributing.md&lt;/a&gt; to learn how to integrate custom tools!&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;Patron sponsor&lt;/strong&gt;:&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tatra-labs"&gt;tatra-labs&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Maintainers:&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;a href="https://github.com/Fosowl"&gt;Fosowl&lt;/a&gt; | Paris Time&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;a href="https://github.com/antoineVIVIES"&gt;antoineVIVIES&lt;/a&gt; | Taipei Time&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Special Thanks:&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;a href="https://github.com/tcsenpai"&gt;tcsenpai&lt;/a&gt; and &lt;a href="https://github.com/plitc"&gt;plitc&lt;/a&gt; For helping with backend dockerization&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;a href="https://www.star-history.com/#Fosowl/agenticSeek&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=Fosowl/agenticSeek&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>QuentinFuxa/WhisperLiveKit</title>
      <link>https://github.com/QuentinFuxa/WhisperLiveKit</link>
      <description>&lt;p&gt;Real-time &amp; local speech-to-text, translation, and speaker diarization. With server &amp; web UI.&lt;/p&gt;&lt;hr&gt;&lt;h1 align="center"&gt;WhisperLiveKit&lt;/h1&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/QuentinFuxa/WhisperLiveKit/refs/heads/main/demo.png" alt="WhisperLiveKit Demo" width="730" /&gt; &lt;/p&gt; 
&lt;p align="center"&gt;&lt;b&gt;Real-time, Fully Local Speech-to-Text with Speaker Identification&lt;/b&gt;&lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://pypi.org/project/whisperlivekit/"&gt;&lt;img alt="PyPI Version" src="https://img.shields.io/pypi/v/whisperlivekit?color=g" /&gt;&lt;/a&gt; &lt;a href="https://pepy.tech/project/whisperlivekit"&gt;&lt;img alt="PyPI Downloads" src="https://static.pepy.tech/personalized-badge/whisperlivekit?period=total&amp;amp;units=international_system&amp;amp;left_color=grey&amp;amp;right_color=brightgreen&amp;amp;left_text=installations" /&gt;&lt;/a&gt; &lt;a href="https://pypi.org/project/whisperlivekit/"&gt;&lt;img alt="Python Versions" src="https://img.shields.io/badge/python-3.9--3.13-dark_green" /&gt;&lt;/a&gt; &lt;a href="https://github.com/QuentinFuxa/WhisperLiveKit/raw/main/LICENSE"&gt;&lt;img alt="License" src="https://img.shields.io/badge/License-MIT/Dual Licensed-dark_green" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p&gt;Real-time speech transcription directly to your browser, with a ready-to-use backend+server and a simple frontend. ✨&lt;/p&gt; 
&lt;h4&gt;Powered by Leading Research:&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ufal/SimulStreaming"&gt;SimulStreaming&lt;/a&gt; (SOTA 2025) - Ultra-low latency transcription with AlignAtt policy&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ufal/whisper_streaming"&gt;WhisperStreaming&lt;/a&gt; (SOTA 2023) - Low latency transcription with LocalAgreement policy&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://arxiv.org/abs/2507.18446"&gt;Streaming Sortformer&lt;/a&gt; (SOTA 2025) - Advanced real-time speaker diarization&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/juanmc2005/diart"&gt;Diart&lt;/a&gt; (SOTA 2021) - Real-time speaker diarization&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/snakers4/silero-vad"&gt;Silero VAD&lt;/a&gt; (2024) - Enterprise-grade Voice Activity Detection&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Why not just run a simple Whisper model on every audio batch?&lt;/strong&gt; Whisper is designed for complete utterances, not real-time chunks. Processing small segments loses context, cuts off words mid-syllable, and produces poor transcription. WhisperLiveKit uses state-of-the-art simultaneous speech research for intelligent buffering and incremental processing.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Architecture&lt;/h3&gt; 
&lt;img alt="Architecture" src="https://raw.githubusercontent.com/QuentinFuxa/WhisperLiveKit/refs/heads/main/architecture.png" /&gt; 
&lt;p&gt;&lt;em&gt;The backend supports multiple concurrent users. Voice Activity Detection reduces overhead when no voice is detected.&lt;/em&gt;&lt;/p&gt; 
&lt;h3&gt;Installation &amp;amp; Quick Start&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install whisperlivekit
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;FFmpeg is required&lt;/strong&gt; and must be installed before using WhisperLiveKit&lt;/p&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;OS&lt;/th&gt; 
    &lt;th&gt;How to install&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;Ubuntu/Debian&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;sudo apt install ffmpeg&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;MacOS&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;brew install ffmpeg&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;Windows&lt;/td&gt; 
    &lt;td&gt;Download .exe from &lt;a href="https://ffmpeg.org/download.html"&gt;https://ffmpeg.org/download.html&lt;/a&gt; and add to PATH&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;Quick Start&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Start the transcription server:&lt;/strong&gt;&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;whisperlivekit-server --model base --language en
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Open your browser&lt;/strong&gt; and navigate to &lt;code&gt;http://localhost:8000&lt;/code&gt;. Start speaking and watch your words appear in real-time!&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;blockquote&gt; 
 &lt;ul&gt; 
  &lt;li&gt;See &lt;a href="https://github.com/QuentinFuxa/WhisperLiveKit/raw/main/whisperlivekit/simul_whisper/whisper/tokenizer.py"&gt;tokenizer.py&lt;/a&gt; for the list of all available languages.&lt;/li&gt; 
  &lt;li&gt;For HTTPS requirements, see the &lt;strong&gt;Parameters&lt;/strong&gt; section for SSL configuration options.&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;Optional Dependencies&lt;/h4&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Optional&lt;/th&gt; 
   &lt;th&gt;&lt;code&gt;pip install&lt;/code&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Speaker diarization with Sortformer&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;git+https://github.com/NVIDIA/NeMo.git@main#egg=nemo_toolkit[asr]&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Speaker diarization with Diart&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;diart&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Original Whisper backend&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;whisper&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Improved timestamps backend&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;whisper-timestamped&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Apple Silicon optimization backend&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;mlx-whisper&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;OpenAI API backend&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;openai&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;See &lt;strong&gt;Parameters &amp;amp; Configuration&lt;/strong&gt; below on how to use them.&lt;/p&gt; 
&lt;h3&gt;Usage Examples&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Command-line Interface&lt;/strong&gt;: Start the transcription server with various options:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Use better model than default (small)
whisperlivekit-server --model large-v3

# Advanced configuration with diarization and language
whisperlivekit-server --host 0.0.0.0 --port 8000 --model medium --diarization --language fr
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Python API Integration&lt;/strong&gt;: Check &lt;a href="https://github.com/QuentinFuxa/WhisperLiveKit/raw/main/whisperlivekit/basic_server.py"&gt;basic_server&lt;/a&gt; for a more complete example of how to use the functions and classes.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from whisperlivekit import TranscriptionEngine, AudioProcessor, parse_args
from fastapi import FastAPI, WebSocket, WebSocketDisconnect
from fastapi.responses import HTMLResponse
from contextlib import asynccontextmanager
import asyncio

transcription_engine = None

@asynccontextmanager
async def lifespan(app: FastAPI):
    global transcription_engine
    transcription_engine = TranscriptionEngine(model="medium", diarization=True, lan="en")
    yield

app = FastAPI(lifespan=lifespan)

async def handle_websocket_results(websocket: WebSocket, results_generator):
    async for response in results_generator:
        await websocket.send_json(response)
    await websocket.send_json({"type": "ready_to_stop"})

@app.websocket("/asr")
async def websocket_endpoint(websocket: WebSocket):
    global transcription_engine

    # Create a new AudioProcessor for each connection, passing the shared engine
    audio_processor = AudioProcessor(transcription_engine=transcription_engine)    
    results_generator = await audio_processor.create_tasks()
    results_task = asyncio.create_task(handle_websocket_results(websocket, results_generator))
    await websocket.accept()
    while True:
        message = await websocket.receive_bytes()
        await audio_processor.process_audio(message)        
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Frontend Implementation&lt;/strong&gt;: The package includes an HTML/JavaScript implementation &lt;a href="https://github.com/QuentinFuxa/WhisperLiveKit/raw/main/whisperlivekit/web/live_transcription.html"&gt;here&lt;/a&gt;. You can also import it using &lt;code&gt;from whisperlivekit import get_web_interface_html&lt;/code&gt; &amp;amp; &lt;code&gt;page = get_web_interface_html()&lt;/code&gt;&lt;/p&gt; 
&lt;h2&gt;Parameters &amp;amp; Configuration&lt;/h2&gt; 
&lt;p&gt;An important list of parameters can be changed. But what &lt;em&gt;should&lt;/em&gt; you change?&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;the &lt;code&gt;--model&lt;/code&gt; size. List and recommandations &lt;a href="https://github.com/QuentinFuxa/WhisperLiveKit/raw/main/available_models.md"&gt;here&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;the &lt;code&gt;--language&lt;/code&gt;. List &lt;a href="https://github.com/QuentinFuxa/WhisperLiveKit/raw/main/whisperlivekit/simul_whisper/whisper/tokenizer.py"&gt;here&lt;/a&gt;. If you use &lt;code&gt;auto&lt;/code&gt;, the model attempts to detect the language automatically, but it tends to bias towards English.&lt;/li&gt; 
 &lt;li&gt;the &lt;code&gt;--backend&lt;/code&gt; ? you can switch to &lt;code&gt;--backend faster-whisper&lt;/code&gt; if &lt;code&gt;simulstreaming&lt;/code&gt; does not work correctly or if you prefer to avoid the dual-license requirements.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--warmup-file&lt;/code&gt;, if you have one&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--host&lt;/code&gt;, &lt;code&gt;--port&lt;/code&gt;, &lt;code&gt;--ssl-certfile&lt;/code&gt;, &lt;code&gt;--ssl-keyfile&lt;/code&gt;, if you set up a server&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--diarization&lt;/code&gt;, if you want to use it.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The rest I don't recommend. But below are your options.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Parameter&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Default&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--model&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Whisper model size.&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;small&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--language&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Source language code or &lt;code&gt;auto&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;auto&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--task&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;transcribe&lt;/code&gt; or &lt;code&gt;translate&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;transcribe&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--backend&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Processing backend&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;simulstreaming&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--min-chunk-size&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Minimum audio chunk size (seconds)&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;1.0&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--no-vac&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Disable Voice Activity Controller&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;False&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--no-vad&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Disable Voice Activity Detection&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;False&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--warmup-file&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Audio file path for model warmup&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;jfk.wav&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--host&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Server host address&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;localhost&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--port&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Server port&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;8000&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--ssl-certfile&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Path to the SSL certificate file (for HTTPS support)&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;None&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--ssl-keyfile&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Path to the SSL private key file (for HTTPS support)&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;None&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;WhisperStreaming backend options&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Default&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--confidence-validation&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Use confidence scores for faster validation&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;False&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--buffer_trimming&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Buffer trimming strategy (&lt;code&gt;sentence&lt;/code&gt; or &lt;code&gt;segment&lt;/code&gt;)&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;segment&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;SimulStreaming backend options&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Default&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--frame-threshold&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;AlignAtt frame threshold (lower = faster, higher = more accurate)&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;25&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--beams&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Number of beams for beam search (1 = greedy decoding)&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;1&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--decoder&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Force decoder type (&lt;code&gt;beam&lt;/code&gt; or &lt;code&gt;greedy&lt;/code&gt;)&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;auto&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--audio-max-len&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Maximum audio buffer length (seconds)&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;30.0&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--audio-min-len&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Minimum audio length to process (seconds)&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;0.0&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--cif-ckpt-path&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Path to CIF model for word boundary detection&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;None&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--never-fire&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Never truncate incomplete words&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;False&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--init-prompt&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Initial prompt for the model&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;None&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--static-init-prompt&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Static prompt that doesn't scroll&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;None&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--max-context-tokens&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Maximum context tokens&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;None&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--model-path&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Direct path to .pt model file. Download it if not found&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;./base.pt&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--preloaded-model-count&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Optional. Number of models to preload in memory to speed up loading (set up to the expected number of concurrent users)&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;1&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Diarization options&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Default&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--diarization&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Enable speaker identification&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;False&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--diarization-backend&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;diart&lt;/code&gt; or &lt;code&gt;sortformer&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;sortformer&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--segmentation-model&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Hugging Face model ID for Diart segmentation model. &lt;a href="https://github.com/juanmc2005/diart/tree/main?tab=readme-ov-file#pre-trained-models"&gt;Available models&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;pyannote/segmentation-3.0&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--embedding-model&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Hugging Face model ID for Diart embedding model. &lt;a href="https://github.com/juanmc2005/diart/tree/main?tab=readme-ov-file#pre-trained-models"&gt;Available models&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;speechbrain/spkrec-ecapa-voxceleb&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;For diarization using Diart, you need access to pyannote.audio models:&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/pyannote/segmentation"&gt;Accept user conditions&lt;/a&gt; for the &lt;code&gt;pyannote/segmentation&lt;/code&gt; model&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/pyannote/segmentation-3.0"&gt;Accept user conditions&lt;/a&gt; for the &lt;code&gt;pyannote/segmentation-3.0&lt;/code&gt; model&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/pyannote/embedding"&gt;Accept user conditions&lt;/a&gt; for the &lt;code&gt;pyannote/embedding&lt;/code&gt; model&lt;/li&gt; 
  &lt;li&gt;Login with HuggingFace: &lt;code&gt;huggingface-cli login&lt;/code&gt;&lt;/li&gt; 
 &lt;/ol&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;🚀 Deployment Guide&lt;/h3&gt; 
&lt;p&gt;To deploy WhisperLiveKit in production:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Server Setup&lt;/strong&gt;: Install production ASGI server &amp;amp; launch with multiple workers&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;pip install uvicorn gunicorn
gunicorn -k uvicorn.workers.UvicornWorker -w 4 your_app:app
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Frontend&lt;/strong&gt;: Host your customized version of the &lt;code&gt;html&lt;/code&gt; example &amp;amp; ensure WebSocket connection points correctly&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Nginx Configuration&lt;/strong&gt; (recommended for production):&lt;/p&gt; &lt;pre&gt;&lt;code class="language-nginx"&gt;server {
   listen 80;
   server_name your-domain.com;
    location / {
        proxy_pass http://localhost:8000;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "upgrade";
        proxy_set_header Host $host;
}}
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;HTTPS Support&lt;/strong&gt;: For secure deployments, use "wss://" instead of "ws://" in WebSocket URL&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;🐋 Docker&lt;/h2&gt; 
&lt;p&gt;Deploy the application easily using Docker with GPU or CPU support.&lt;/p&gt; 
&lt;h3&gt;Prerequisites&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Docker installed on your system&lt;/li&gt; 
 &lt;li&gt;For GPU support: NVIDIA Docker runtime installed&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Quick Start&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;With GPU acceleration (recommended):&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker build -t wlk .
docker run --gpus all -p 8000:8000 --name wlk wlk
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;CPU only:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker build -f Dockerfile.cpu -t wlk .
docker run -p 8000:8000 --name wlk wlk
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Advanced Usage&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Custom configuration:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Example with custom model and language
docker run --gpus all -p 8000:8000 --name wlk wlk --model large-v3 --language fr
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Memory Requirements&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Large models&lt;/strong&gt;: Ensure your Docker runtime has sufficient memory allocated&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Customization&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;--build-arg&lt;/code&gt; Options: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;EXTRAS="whisper-timestamped"&lt;/code&gt; - Add extras to the image's installation (no spaces). Remember to set necessary container options!&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;HF_PRECACHE_DIR="./.cache/"&lt;/code&gt; - Pre-load a model cache for faster first-time start&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;HF_TKN_FILE="./token"&lt;/code&gt; - Add your Hugging Face Hub access token to download gated models&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;🔮 Use Cases&lt;/h2&gt; 
&lt;p&gt;Capture discussions in real-time for meeting transcription, help hearing-impaired users follow conversations through accessibility tools, transcribe podcasts or videos automatically for content creation, transcribe support calls with speaker identification for customer service...&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>spotDL/spotify-downloader</title>
      <link>https://github.com/spotDL/spotify-downloader</link>
      <description>&lt;p&gt;Download your Spotify playlists and songs along with album art and metadata (from YouTube if a match is found).&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;h1&gt;spotDL v4&lt;/h1&gt; 
 &lt;p&gt;&lt;strong&gt;spotDL&lt;/strong&gt; finds songs from Spotify playlists on YouTube and downloads them - along with album art, lyrics and metadata.&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://github.com/spotDL/spotify-downloader/raw/master/LICENSE"&gt;&lt;img src="https://img.shields.io/github/license/spotdl/spotify-downloader?color=44CC11&amp;amp;style=flat-square" alt="MIT License" /&gt;&lt;/a&gt; &lt;a href="https://pypi.org/project/spotdl/"&gt;&lt;img src="https://img.shields.io/pypi/pyversions/spotDL?color=%2344CC11&amp;amp;style=flat-square" alt="PyPI version" /&gt;&lt;/a&gt; &lt;a href="https://pypi.org/project/spotdl/"&gt;&lt;img src="https://img.shields.io/pypi/dw/spotDL?label=downloads@pypi&amp;amp;color=344CC11&amp;amp;style=flat-square" alt="PyPi downloads" /&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/github/contributors/spotDL/spotify-downloader?style=flat-square" alt="Contributors" /&gt; &lt;a href="https://discord.gg/xCa23pwJWY"&gt;&lt;img src="https://img.shields.io/discord/771628785447337985?label=discord&amp;amp;logo=discord&amp;amp;style=flat-square" alt="Discord" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;spotDL: The fastest, easiest and most accurate command-line music downloader.&lt;/p&gt; 
 &lt;/blockquote&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://spotdl.readthedocs.io"&gt;Read the documentation on ReadTheDocs!&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;Refer to our &lt;a href="https://raw.githubusercontent.com/spotDL/spotify-downloader/master/docs/installation.md"&gt;Installation Guide&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;h3&gt;Python (Recommended Method)&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;em&gt;spotDL&lt;/em&gt; can be installed by running &lt;code&gt;pip install spotdl&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;To update spotDL run &lt;code&gt;pip install --upgrade spotdl&lt;/code&gt;&lt;/p&gt; 
  &lt;blockquote&gt; 
   &lt;p&gt;On some systems you might have to change &lt;code&gt;pip&lt;/code&gt; to &lt;code&gt;pip3&lt;/code&gt;.&lt;/p&gt; 
  &lt;/blockquote&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;details&gt; 
 &lt;summary style="font-size:1.25em"&gt;&lt;strong&gt;Other options&lt;/strong&gt;&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Prebuilt executable 
   &lt;ul&gt; 
    &lt;li&gt;You can download the latest version from the &lt;a href="https://github.com/spotDL/spotify-downloader/releases"&gt;Releases Tab&lt;/a&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;On Termux 
   &lt;ul&gt; 
    &lt;li&gt;&lt;code&gt;curl -L https://raw.githubusercontent.com/spotDL/spotify-downloader/master/scripts/termux.sh | sh&lt;/code&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;Arch 
   &lt;ul&gt; 
    &lt;li&gt;There is an &lt;a href="https://aur.archlinux.org/packages/spotdl/"&gt;Arch User Repository (AUR) package&lt;/a&gt; for spotDL.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;Docker 
   &lt;ul&gt; 
    &lt;li&gt; &lt;p&gt;Build image:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;docker build -t spotdl .
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;Launch container with spotDL parameters (see section below). You need to create mapped volume to access song files&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;docker run --rm -v $(pwd):/music spotdl download [trackUrl]
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;Build from source&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/spotDL/spotify-downloader &amp;amp;&amp;amp; cd spotify-downloader
pip install uv
uv sync
uv run scripts/build.py
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;An executable is created in &lt;code&gt;spotify-downloader/dist/&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h3&gt;Installing FFmpeg&lt;/h3&gt; 
&lt;p&gt;FFmpeg is required for spotDL. If using FFmpeg only for spotDL, you can simply install FFmpeg to your spotDL installation directory: &lt;code&gt;spotdl --download-ffmpeg&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;We recommend the above option, but if you want to install FFmpeg system-wide, follow these instructions&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://windowsloop.com/install-ffmpeg-windows-10/"&gt;Windows Tutorial&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;OSX - &lt;code&gt;brew install ffmpeg&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Linux - &lt;code&gt;sudo apt install ffmpeg&lt;/code&gt; or use your distro's package manager&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;p&gt;Using SpotDL without options:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;spotdl [urls]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can run &lt;em&gt;spotDL&lt;/em&gt; as a package if running it as a script doesn't work:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;python -m spotdl [urls]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;General usage:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;spotdl [operation] [options] QUERY
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;There are different &lt;strong&gt;operations&lt;/strong&gt; spotDL can perform. The &lt;em&gt;default&lt;/em&gt; is &lt;code&gt;download&lt;/code&gt;, which simply downloads the songs from YouTube and embeds metadata.&lt;/p&gt; 
&lt;p&gt;The &lt;strong&gt;query&lt;/strong&gt; for spotDL is usually a list of Spotify URLs, but for some operations like &lt;strong&gt;sync&lt;/strong&gt;, only a single link or file is required. For a list of all &lt;strong&gt;options&lt;/strong&gt; use &lt;code&gt;spotdl -h&lt;/code&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary style="font-size:1em"&gt;&lt;strong&gt;Supported operations&lt;/strong&gt;&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;code&gt;save&lt;/code&gt;: Saves only the metadata from Spotify without downloading anything.&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Usage: &lt;code&gt;spotdl save [query] --save-file {filename}.spotdl&lt;/code&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;code&gt;web&lt;/code&gt;: Starts a web interface instead of using the command line. However, it has limited features and only supports downloading single songs.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;code&gt;url&lt;/code&gt;: Get direct download link for each song from the query.&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Usage: &lt;code&gt;spotdl url [query]&lt;/code&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;code&gt;sync&lt;/code&gt;: Updates directories. Compares the directory with the current state of the playlist. Newly added songs will be downloaded and removed songs will be deleted. No other songs will be downloaded and no other files will be deleted.&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt; &lt;p&gt;Usage: &lt;code&gt;spotdl sync [query] --save-file {filename}.spotdl&lt;/code&gt;&lt;/p&gt; &lt;p&gt;This create a new &lt;strong&gt;sync&lt;/strong&gt; file, to update the directory in the future, use:&lt;/p&gt; &lt;p&gt;&lt;code&gt;spotdl sync {filename}.spotdl&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;code&gt;meta&lt;/code&gt;: Updates metadata for the provided song files.&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;Music Sourcing and Audio Quality&lt;/h2&gt; 
&lt;p&gt;spotDL uses YouTube as a source for music downloads. This method is used to avoid any issues related to downloading music from Spotify.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt; Users are responsible for their actions and potential legal consequences. We do not support unauthorized downloading of copyrighted material and take no responsibility for user actions.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Audio Quality&lt;/h3&gt; 
&lt;p&gt;spotDL downloads music from YouTube and is designed to always download the highest possible bitrate; which is 128 kbps for regular users and 256 kbps for YouTube Music premium users.&lt;/p&gt; 
&lt;p&gt;Check the &lt;a href="https://raw.githubusercontent.com/spotDL/spotify-downloader/master/docs/usage.md#audio-formats-and-quality"&gt;Audio Formats&lt;/a&gt; page for more info.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Interested in contributing? Check out our &lt;a href="https://raw.githubusercontent.com/spotDL/spotify-downloader/master/docs/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; to find resources around contributing along with a guide on how to set up a development environment.&lt;/p&gt; 
&lt;h3&gt;Join our amazing community as a code contributor&lt;/h3&gt; 
&lt;a href="https://github.com/spotDL/spotify-downloader/graphs/contributors"&gt; &lt;img class="dark-light" src="https://contrib.rocks/image?repo=spotDL/spotify-downloader&amp;amp;anon=0&amp;amp;columns=25&amp;amp;max=100&amp;amp;r=true" /&gt; &lt;/a&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This project is Licensed under the &lt;a href="https://raw.githubusercontent.com/spotDL/spotify-downloader/master/LICENSE"&gt;MIT&lt;/a&gt; License.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>OpenBMB/MiniCPM-V</title>
      <link>https://github.com/OpenBMB/MiniCPM-V</link>
      <description>&lt;p&gt;MiniCPM-V 4.5: A GPT-4o Level MLLM for Single Image, Multi Image and Video Understanding on Your Phone&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/assets/minicpm_v_and_minicpm_o_title.png" width="500em" /&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;A GPT-4o Level MLLM for Single Image, Multi Image and Video Understanding on Your Phone&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/README_zh.md"&gt;中文&lt;/a&gt; | English&lt;/strong&gt;&lt;/p&gt; 
 &lt;span style="display: inline-flex; align-items: center; margin-right: 2px;"&gt; &lt;img src="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/assets/wechat.png" alt="WeChat" style="margin-right: 4px;" /&gt; &lt;a href="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/docs/wechat.md" target="_blank"&gt; WeChat&lt;/a&gt; &amp;nbsp;| &lt;/span&gt; &amp;nbsp; 
 &lt;span style="display: inline-flex; align-items: center; margin-left: -8px;"&gt; &lt;img src="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/assets/discord.png" alt="Discord" style="margin-right: 4px;" /&gt; &lt;a href="https://discord.gg/rftuRMbqzf" target="_blank"&gt; Discord&lt;/a&gt; &amp;nbsp; &lt;/span&gt; 
 &lt;p align="center"&gt; MiniCPM-V 4.5 &lt;a href="https://huggingface.co/openbmb/MiniCPM-V-4_5"&gt;🤗&lt;/a&gt; &lt;a href="http://101.126.42.235:30910/"&gt;🤖&lt;/a&gt; | MiniCPM-o 2.6 &lt;a href="https://huggingface.co/openbmb/MiniCPM-o-2_6"&gt;🤗&lt;/a&gt; &lt;a href="https://minicpm-omni-webdemo-us.modelbest.cn/"&gt; 🤖&lt;/a&gt; | &lt;a href="https://github.com/OpenSQZ/MiniCPM-V-Cookbook"&gt;🍳 Cookbook&lt;/a&gt; | 📄 Technical Report (Coming Soon) &lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;strong&gt;MiniCPM-V&lt;/strong&gt; is a series of efficient end-side multimodal LLMs (MLLMs), which accept images, videos and text as inputs and deliver high-quality text outputs. &lt;strong&gt;MiniCPM-o&lt;/strong&gt; additionally takes audio as inputs and provide high-quality speech outputs in an end-to-end fashion. Since February 2024, we have released 7 versions of the model, aiming to achieve &lt;strong&gt;strong performance and efficient deployment&lt;/strong&gt;. The most notable models in the series currently include:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;MiniCPM-V 4.5&lt;/strong&gt;: 🔥🔥🔥 The latest and most capable model in the MiniCPM-V series. With a total of 8B parameters, this model &lt;strong&gt;outperforms GPT-4o-latest, Gemini-2.0 Pro, and Qwen2.5-VL 72B&lt;/strong&gt; in vision-language capabilities, making it the most performant on-device multimodal model in the open-source community. This version brings &lt;strong&gt;new features including efficient high refresh rate and long video understanding (up to 96x compression rate for video tokens), controllable hybrid fast/deep thinking, strong handwritten OCR and complex table/document parsing&lt;/strong&gt;. It also advances MiniCPM-V's popular features such as trustworthy behavior, multilingual support and end-side deployability.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;MiniCPM-o 2.6&lt;/strong&gt;: ⭐️⭐️⭐️ The most capable model in the MiniCPM-o series. With a total of 8B parameters, this end-to-end model &lt;strong&gt;achieves comparable performance to GPT-4o-202405 in vision, speech, and multimodal live streaming&lt;/strong&gt;, making it one of the most versatile and performant models in the open-source community. For the new voice mode, MiniCPM-o 2.6 &lt;strong&gt;supports bilingual real-time speech conversation with configurable voices&lt;/strong&gt;, and also allows for fun capabilities such as emotion/speed/style control, end-to-end voice cloning, role play, etc. Due to its superior token density, MiniCPM-o 2.6 can for the first time &lt;strong&gt;support multimodal live streaming on end-side devices&lt;/strong&gt; such as iPad.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;News 
 &lt;!-- omit in toc --&gt;&lt;/h2&gt; 
&lt;h4&gt;📌 Pinned&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;[2025.08.26] 🔥🔥🔥 We open-source MiniCPM-V 4.5, which outperforms GPT-4o-latest, Gemini-2.0 Pro, and Qwen2.5-VL 72B. It advances popular capabilities of MiniCPM-V, and brings useful new features. Try it now!&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;[2025.08.01] ⭐️⭐️⭐️ We open-sourced the &lt;a href="https://github.com/OpenSQZ/MiniCPM-V-CookBook"&gt;MiniCPM-V &amp;amp; o Cookbook&lt;/a&gt;! It provides comprehensive guides for diverse user scenarios, paired with our new &lt;a href="https://minicpm-o.readthedocs.io/en/latest/index.html"&gt;Docs Site&lt;/a&gt; for smoother onboarding.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;[2025.06.20] ⭐️⭐️⭐️ Our official &lt;a href="https://ollama.com/openbmb"&gt;Ollama repository&lt;/a&gt; is released. Try our latest models with &lt;a href="https://ollama.com/openbmb/minicpm-o2.6"&gt;one click&lt;/a&gt;！&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;[2025.03.01] 🚀🚀🚀 RLAIF-V, the alignment technique of MiniCPM-o, is accepted by CVPR 2025 Highlights！The &lt;a href="https://github.com/RLHF-V/RLAIF-V"&gt;code&lt;/a&gt;, &lt;a href="https://huggingface.co/datasets/openbmb/RLAIF-V-Dataset"&gt;dataset&lt;/a&gt;, &lt;a href="https://arxiv.org/abs/2405.17220"&gt;paper&lt;/a&gt; are open-sourced!&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;[2025.01.24] 📢📢📢 MiniCPM-o 2.6 technical report is released! See &lt;a href="https://openbmb.notion.site/MiniCPM-o-2-6-A-GPT-4o-Level-MLLM-for-Vision-Speech-and-Multimodal-Live-Streaming-on-Your-Phone-185ede1b7a558042b5d5e45e6b237da9"&gt;here&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;[2025.01.19] 📢 &lt;strong&gt;ATTENTION!&lt;/strong&gt; We are currently working on merging MiniCPM-o 2.6 into the official repositories of llama.cpp, Ollama, and vllm. Until the merge is complete, please USE OUR LOCAL FORKS of &lt;a href="https://github.com/OpenBMB/llama.cpp/raw/minicpm-omni/examples/llava/README-minicpmo2.6.md"&gt;llama.cpp&lt;/a&gt;, &lt;a href="https://github.com/OpenBMB/ollama/raw/minicpm-v2.6/examples/minicpm-v2.6/README.md"&gt;Ollama&lt;/a&gt;, and &lt;a href="https://github.com/OpenBMB/MiniCPM-o?tab=readme-ov-file#efficient-inference-with-llamacpp-ollama-vllm"&gt;vllm&lt;/a&gt;. &lt;strong&gt;Using the official repositories before the merge may lead to unexpected issues&lt;/strong&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;[2025.01.19] ⭐️⭐️⭐️ MiniCPM-o tops GitHub Trending and reaches top-2 on Hugging Face Trending!&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;[2025.01.17] We have updated the usage of MiniCPM-o 2.6 int4 quantization version and resolved the model initialization error. Click &lt;a href="https://huggingface.co/openbmb/MiniCPM-o-2_6-int4"&gt;here&lt;/a&gt; and try it now!&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;[2025.01.13] 🔥🔥🔥 We open-source MiniCPM-o 2.6, which matches GPT-4o-202405 on vision, speech and multimodal live streaming. It advances popular capabilities of MiniCPM-V 2.6, and supports various new fun features. Try it now!&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;[2024.08.17] 🚀🚀🚀 MiniCPM-V 2.6 is now fully supported by &lt;a href="https://github.com/ggerganov/llama.cpp"&gt;official&lt;/a&gt; llama.cpp! GGUF models of various sizes are available &lt;a href="https://huggingface.co/openbmb/MiniCPM-V-2_6-gguf"&gt;here&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;[2024.08.06] 🔥🔥🔥 We open-source MiniCPM-V 2.6, which outperforms GPT-4V on single image, multi-image and video understanding. It advances popular features of MiniCPM-Llama3-V 2.5, and can support real-time video understanding on iPad. Try it now!&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;[2024.08.03] MiniCPM-Llama3-V 2.5 technical report is released! See &lt;a href="https://arxiv.org/abs/2408.01800"&gt;here&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;[2024.05.23] 🔥🔥🔥 MiniCPM-V tops GitHub Trending and Hugging Face Trending! Our demo, recommended by Hugging Face Gradio’s official account, is available &lt;a href="https://huggingface.co/spaces/openbmb/MiniCPM-Llama3-V-2_5"&gt;here&lt;/a&gt;. Come and try it out!&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;br /&gt; 
&lt;details&gt; 
 &lt;summary&gt;Click to view more news.&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;[2025.08.02] 🚀🚀🚀 We open-source MiniCPM-V 4.0, which outperforms GPT-4.1-mini-20250414 in image understanding. It advances popular features of MiniCPM-V 2.6, and largely improves the efficiency. We also open-source the iOS App on iPhone and iPad. Try it now!&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;[2025.01.23] 💡💡💡 MiniCPM-o 2.6 is now supported by &lt;a href="https://github.com/PKU-Alignment/align-anything"&gt;Align-Anything&lt;/a&gt;, a framework by PKU-Alignment Team for aligning any-to-any modality large models with human intentions. It supports DPO and SFT fine-tuning on both vision and audio. Try it now!&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;[2024.08.15] We now also support multi-image SFT. For more details, please refer to the &lt;a href="https://github.com/OpenBMB/MiniCPM-V/tree/main/finetune"&gt;document&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;[2024.08.14] MiniCPM-V 2.6 now also supports &lt;a href="https://github.com/modelscope/ms-swift/issues/1613"&gt;fine-tuning&lt;/a&gt; with the SWIFT framework!&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;[2024.08.10] 🚀🚀🚀 MiniCPM-Llama3-V 2.5 is now fully supported by &lt;a href="https://github.com/ggerganov/llama.cpp"&gt;official&lt;/a&gt; llama.cpp! GGUF models of various sizes are available &lt;a href="https://huggingface.co/openbmb/MiniCPM-Llama3-V-2_5-gguf"&gt;here&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;[2024.07.19] MiniCPM-Llama3-V 2.5 supports vLLM now! See &lt;a href="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/#inference-with-vllm"&gt;here&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;[2024.06.03] Now, you can run MiniCPM-Llama3-V 2.5 on multiple low VRAM GPUs(12 GB or 16 GB) by distributing the model's layers across multiple GPUs. For more details, Check this &lt;a href="https://github.com/OpenBMB/MiniCPM-V/raw/main/docs/inference_on_multiple_gpus.md"&gt;link&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;[2024.05.28] 🚀🚀🚀 MiniCPM-Llama3-V 2.5 now fully supports its feature in llama.cpp and Ollama! Please pull the latest code &lt;strong&gt;of our provided forks&lt;/strong&gt; (&lt;a href="https://github.com/OpenBMB/llama.cpp/raw/minicpm-v2.5/examples/minicpmv/README.md"&gt;llama.cpp&lt;/a&gt;, &lt;a href="https://github.com/OpenBMB/ollama/tree/minicpm-v2.5/examples/minicpm-v2.5"&gt;Ollama&lt;/a&gt;). GGUF models in various sizes are available &lt;a href="https://huggingface.co/openbmb/MiniCPM-Llama3-V-2_5-gguf/tree/main"&gt;here&lt;/a&gt;. MiniCPM-Llama3-V 2.5 series is &lt;strong&gt;not supported by the official repositories yet&lt;/strong&gt;, and we are working hard to merge PRs. Please stay tuned!&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;[2024.05.28] 💫 We now support LoRA fine-tuning for MiniCPM-Llama3-V 2.5, using only 2 V100 GPUs! See more statistics &lt;a href="https://github.com/OpenBMB/MiniCPM-V/tree/main/finetune#model-fine-tuning-memory-usage-statistics"&gt;here&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;[2024.05.25] MiniCPM-Llama3-V 2.5 now supports streaming outputs and customized system prompts. Try it &lt;a href="https://huggingface.co/openbmb/MiniCPM-Llama3-V-2_5#usage"&gt;here&lt;/a&gt;!&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;[2024.05.24] We release the MiniCPM-Llama3-V 2.5 &lt;a href="https://huggingface.co/openbmb/MiniCPM-Llama3-V-2_5-gguf"&gt;gguf&lt;/a&gt;, which supports &lt;a href="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/#inference-with-llamacpp"&gt;llama.cpp&lt;/a&gt; inference and provides a 6~8 token/s smooth decoding on mobile phones. Try it now!&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;[2024.05.23] 🔍 We've released a comprehensive comparison between Phi-3-vision-128k-instruct and MiniCPM-Llama3-V 2.5, including benchmarks evaluations, multilingual capabilities, and inference efficiency 🌟📊🌍🚀. Click &lt;a href="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/docs/compare_with_phi-3_vision.md"&gt;here&lt;/a&gt; to view more details.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;[2024.05.20] We open-soure MiniCPM-Llama3-V 2.5, it has improved OCR capability and supports 30+ languages, representing the first end-side MLLM achieving GPT-4V level performance! We provide &lt;a href="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/#deployment-on-mobile-phone"&gt;efficient inference&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/finetune/readme.md"&gt;simple fine-tuning&lt;/a&gt;. Try it now!&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;[2024.04.23] MiniCPM-V-2.0 supports vLLM now! Click &lt;a href="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/#inference-with-vllm"&gt;here&lt;/a&gt; to view more details.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;[2024.04.18] We create a HuggingFace Space to host the demo of MiniCPM-V 2.0 at &lt;a href="https://huggingface.co/spaces/openbmb/MiniCPM-V-2"&gt;here&lt;/a&gt;!&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;[2024.04.17] MiniCPM-V-2.0 supports deploying &lt;a href="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/#webui-demo"&gt;WebUI Demo&lt;/a&gt; now!&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;[2024.04.15] MiniCPM-V-2.0 now also supports &lt;a href="https://github.com/modelscope/swift/raw/main/docs/source/Multi-Modal/minicpm-v-2%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5.md"&gt;fine-tuning&lt;/a&gt; with the SWIFT framework!&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;[2024.04.12] We open-source MiniCPM-V 2.0, which achieves comparable performance with Gemini Pro in understanding scene text and outperforms strong Qwen-VL-Chat 9.6B and Yi-VL 34B on &lt;a href="https://rank.opencompass.org.cn/leaderboard-multimodal"&gt;OpenCompass&lt;/a&gt;, a comprehensive evaluation over 11 popular benchmarks. Click &lt;a href="https://openbmb.vercel.app/minicpm-v-2"&gt;here&lt;/a&gt; to view the MiniCPM-V 2.0 technical blog.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;[2024.03.14] MiniCPM-V now supports &lt;a href="https://github.com/modelscope/swift/raw/main/docs/source/Multi-Modal/minicpm-v%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5.md"&gt;fine-tuning&lt;/a&gt; with the SWIFT framework. Thanks to &lt;a href="https://github.com/Jintao-Huang"&gt;Jintao&lt;/a&gt; for the contribution！&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;[2024.03.01] MiniCPM-V now can be deployed on Mac!&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;[2024.02.01] We open-source MiniCPM-V and OmniLMM-12B, which support efficient end-side deployment and powerful multimodal capabilities correspondingly.&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;Contents 
 &lt;!-- omit in toc --&gt;&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/#minicpm-v-45"&gt;MiniCPM-V 4.5&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/#minicpm-o-26"&gt;MiniCPM-o 2.6&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/#minicpm-v--o-cookbook"&gt;MiniCPM-V &amp;amp; o Cookbook&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/#chat-with-our-demo-on-gradio-"&gt;Chat with Our Demo on Gradio 🤗&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/#inference"&gt;Inference&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/#model-zoo"&gt;Model Zoo&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/#multi-turn-conversation"&gt;Multi-turn Conversation&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/#chat-with-multiple-images"&gt;Chat with Multiple Images&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/#in-context-few-shot-learning"&gt;In-context Few-shot Learning&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/#chat-with-video"&gt;Chat with Video&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/#speech-and-audio-mode"&gt;Speech and Audio Mode&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/#multimodal-live-streaming"&gt;Multimodal Live Streaming&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/#inference-on-multiple-gpus"&gt;Inference on Multiple GPUs&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/#inference-on-mac"&gt;Inference on Mac&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/#efficient-inference-with-llamacpp-ollama-vllm"&gt;Efficient Inference with llama.cpp, Ollama, vLLM&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/#fine-tuning"&gt;Fine-tuning&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/#awesome-work-using-minicpm-v--minicpm-o"&gt;Awesome work using MiniCPM-V &amp;amp; MiniCPM-o&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/#faqs"&gt;FAQs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/#limitations"&gt;Limitations&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;MiniCPM-V 4.5&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;MiniCPM-V 4.5&lt;/strong&gt; is the latest and most capable model in the MiniCPM-V series. The model is built on Qwen3-8B and SigLIP2-400M with a total of 8B parameters. It exhibits a significant performance improvement over previous MiniCPM-V and MiniCPM-o models, and introduces new useful features. Notable features of MiniCPM-V 4.5 include:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;🔥 &lt;strong&gt;State-of-the-art Vision-Language Capability.&lt;/strong&gt; MiniCPM-V 4.5 achieves an average score of 77.0 on OpenCompass, a comprehensive evaluation of 8 popular benchmarks. &lt;strong&gt;With only 8B parameters, it surpasses widely used proprietary models like GPT-4o-latest, Gemini-2.0 Pro, and strong open-source models like Qwen2.5-VL 72B&lt;/strong&gt; for vision-language capabilities, making it the most performant MLLM under 30B parameters.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;🎬 &lt;strong&gt;Efficient High Refresh Rate and Long Video Understanding.&lt;/strong&gt; Powered by a new unified 3D-Resampler over images and videos, MiniCPM-V 4.5 can now achieve 96x compression rate for video tokens, where 6 448x448 video frames can be jointly compressed into 64 video tokens (normally 1,536 tokens for most MLLMs). This means that the model can percieve significantly more video frames without increasing the LLM inference cost. This brings state-of-the-art high refresh rate (up to 10FPS) video understanding and long video understanding capabilities on Video-MME, LVBench, MLVU, MotionBench, FavorBench, etc., efficiently.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;⚙️ &lt;strong&gt;Controllable Hybrid Fast/Deep Thinking.&lt;/strong&gt; MiniCPM-V 4.5 supports both fast thinking for efficient frequent usage with competitive performance, and deep thinking for more complex problem solving. To cover efficiency and performance trade-offs in different user scenarios, this fast/deep thinking mode can be switched in a highly controlled fashion.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;💪 &lt;strong&gt;Strong OCR, Document Parsing and Others.&lt;/strong&gt; Based on &lt;a href="https://arxiv.org/pdf/2403.11703"&gt;LLaVA-UHD&lt;/a&gt; architecture, MiniCPM-V 4.5 can process high-resolution images with any aspect ratio and up to 1.8 million pixels (e.g., 1344x1344), using 4x less visual tokens than most MLLMs. The model achieves &lt;strong&gt;leading performance on OCRBench, surpassing proprietary models such as GPT-4o-latest and Gemini 2.5&lt;/strong&gt;. It also achieves state-of-the-art performance for PDF document parsing capability on OmniDocBench among general MLLMs. Based on the the latest &lt;a href="https://github.com/RLHF-V/RLAIF-V/"&gt;RLAIF-V&lt;/a&gt; and &lt;a href="https://github.com/OpenBMB/VisCPM"&gt;VisCPM&lt;/a&gt; techniques, it features &lt;strong&gt;trustworthy behaviors&lt;/strong&gt;, outperforming GPT-4o-latest on MMHal-Bench, and supports &lt;strong&gt;multilingual capabilities&lt;/strong&gt; in more than 30 languages.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;💫 &lt;strong&gt;Easy Usage.&lt;/strong&gt; MiniCPM-V 4.5 can be easily used in various ways: (1) &lt;a href="https://github.com/tc-mb/llama.cpp/raw/Support-MiniCPM-V-4.5/docs/multimodal/minicpmv4.5.md"&gt;llama.cpp&lt;/a&gt; and &lt;a href="https://github.com/tc-mb/ollama/tree/MIniCPM-V"&gt;ollama&lt;/a&gt; support for efficient CPU inference on local devices, (2) &lt;a href="https://huggingface.co/openbmb/MiniCPM-V-4_5-int4"&gt;int4&lt;/a&gt;, &lt;a href="https://huggingface.co/openbmb/MiniCPM-V-4_5-gguf"&gt;GGUF&lt;/a&gt; and &lt;a href="https://github.com/tc-mb/AutoAWQ"&gt;AWQ&lt;/a&gt; format quantized models in 16 sizes, (3) &lt;a href="https://github.com/tc-mb/sglang/tree/main"&gt;SGLang&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/#efficient-inference-with-llamacpp-ollama-vllm"&gt;vLLM&lt;/a&gt; support for high-throughput and memory-efficient inference, (4) fine-tuning on new domains and tasks with &lt;a href="https://github.com/tc-mb/transformers/tree/main"&gt;Transformers&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/docs/llamafactory_train_and_infer.md"&gt;LLaMA-Factory&lt;/a&gt;, (5) quick &lt;a href="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/#chat-with-our-demo-on-gradio"&gt;local WebUI demo&lt;/a&gt;, (6) optimized &lt;a href="https://github.com/tc-mb/MiniCPM-o-demo-iOS"&gt;local iOS app&lt;/a&gt; on iPhone and iPad, and (7) online web demo on &lt;a href="http://101.126.42.235:30910/"&gt;server&lt;/a&gt;. See our &lt;a href="https://github.com/OpenSQZ/MiniCPM-V-CookBook"&gt;Cookbook&lt;/a&gt; for full usages!&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Key Techniques 
 &lt;!-- omit in toc --&gt;&lt;/h3&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/assets/minicpm-v-4dot5-framework.png" , width="100%" /&gt; 
&lt;/div&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Architechture: Unified 3D-Resampler for High-density Video Compression.&lt;/strong&gt; MiniCPM-V 4.5 introduces a 3D-Resampler that overcomes the performance-efficiency trade-off in video understanding. By grouping and jointly compressing up to 6 consecutive video frames into just 64 tokens (the same token count used for a single image in MiniCPM-V series), MiniCPM-V 4.5 achieves a 96× compression rate for video tokens. This allows the model to process more video frames without additional LLM computational cost, enabling high refresh rate video and long video understanding. The architecture supports unified encoding for images, multi-image inputs, and videos, ensuring seamless capability and knowledge transfer.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Pre-training: Unified Learning for OCR and Knowledge from Documents.&lt;/strong&gt; Existing MLLMs learn OCR capability and knowledge from documents in isolated training approaches. We observe the essential difference between these two training approaches is the visibility of the text in images. By dynamically corrupting text regions in documents with varying noise levels and asking the model to reconstruct the text, the model learns to adaptively and properly switch between accurate text recognition (when text is visible) and multimodal context-based knowledge reasoning (when text is heavily obscured). This eliminates reliance on error-prone document parsers in knowledge learning from documents, and prevents hallucinations from over-augmented OCR data, resulting in top-tier OCR and multimodal knowledge performance with minimal engineering overhead.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Post-training: Hybrid Fast/Deep Thinking with Multimodal RL.&lt;/strong&gt; MiniCPM-V 4.5 offers a balanced reasoning experience through two switchable modes: fast thinking for efficient daily use and deep thinking for complex tasks. Using a new hybrid reinforcement learning method, the model jointly optimizes both modes, significantly enhancing fast-mode performance without compromising deep-mode capability. Incorporated with &lt;a href="https://github.com/OpenBMB/RLPR"&gt;RLPR&lt;/a&gt; and &lt;a href="https://github.com/RLHF-V/RLAIF-V"&gt;RLAIF-V&lt;/a&gt;, it generalizes robust reasoning skills from broad multimodal data while effectively reducing hallucinations.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Evaluation 
 &lt;!-- omit in toc --&gt;&lt;/h3&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/assets/radar_minicpm_v45.png" , width="60%" /&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/assets/minicpmv_4_5_evaluation_result.png" , width="80%" /&gt; 
&lt;/div&gt; 
&lt;h3&gt;Inference Efficiency&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;OpenCompass&lt;/strong&gt;&lt;/p&gt; 
&lt;div align="left"&gt; 
 &lt;table style="margin: 0px auto;"&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th align="left"&gt;Model&lt;/th&gt; 
    &lt;th&gt;Size&lt;/th&gt; 
    &lt;th&gt;Avg Score ↑&lt;/th&gt; 
    &lt;th&gt;Total Inference Time ↓&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody align="center"&gt; 
   &lt;tr&gt; 
    &lt;td nowrap align="left"&gt;GLM-4.1V-9B-Thinking&lt;/td&gt; 
    &lt;td&gt;10.3B&lt;/td&gt; 
    &lt;td&gt;76.6&lt;/td&gt; 
    &lt;td&gt;17.5h&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td nowrap align="left"&gt;MiMo-VL-7B-RL&lt;/td&gt; 
    &lt;td&gt;8.3B&lt;/td&gt; 
    &lt;td&gt;76.4&lt;/td&gt; 
    &lt;td&gt;11h&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td nowrap align="left"&gt;MiniCPM-V 4.5&lt;/td&gt; 
    &lt;td&gt;8.7B&lt;/td&gt; 
    &lt;td&gt;&lt;b&gt;77.0&lt;/b&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;b&gt;7.5h&lt;/b&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;strong&gt;Video-MME&lt;/strong&gt;&lt;/p&gt; 
&lt;div align="left"&gt; 
 &lt;table style="margin: 0px auto;"&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th align="left"&gt;Model&lt;/th&gt; 
    &lt;th&gt;Size&lt;/th&gt; 
    &lt;th&gt;Avg Score ↑&lt;/th&gt; 
    &lt;th&gt;Total Inference Time ↓&lt;/th&gt; 
    &lt;th&gt;GPU Mem ↓&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody align="center"&gt; 
   &lt;tr&gt; 
    &lt;td nowrap align="left"&gt;Qwen2.5-VL-7B-Instruct&lt;/td&gt; 
    &lt;td&gt;8.3B&lt;/td&gt; 
    &lt;td&gt;71.6&lt;/td&gt; 
    &lt;td&gt;3h&lt;/td&gt; 
    &lt;td&gt;60G&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td nowrap align="left"&gt;GLM-4.1V-9B-Thinking&lt;/td&gt; 
    &lt;td&gt;10.3B&lt;/td&gt; 
    &lt;td&gt;&lt;b&gt;73.6&lt;/b&gt;&lt;/td&gt; 
    &lt;td&gt;2.63h&lt;/td&gt; 
    &lt;td&gt;32G&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td nowrap align="left"&gt;MiniCPM-V 4.5&lt;/td&gt; 
    &lt;td&gt;8.7B&lt;/td&gt; 
    &lt;td&gt;73.5&lt;/td&gt; 
    &lt;td&gt;&lt;b&gt;0.26h&lt;/b&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;b&gt;28G&lt;/b&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/div&gt; 
&lt;p&gt;Both Video-MME and OpenCompass were evaluated using 8×A100 GPUs for inference. The reported inference time of Video-MME excludes the cost of video frame extraction.&lt;/p&gt; 
&lt;h3&gt;Examples 
 &lt;!-- omit in toc --&gt;&lt;/h3&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://www.youtube.com/watch?v=Cn23FujYMMU"&gt;&lt;img src="./assets/minicpmv4_5/MiniCPM-V 4.5-8.26_img.jpeg" , width="70%" /&gt;&lt;/a&gt; 
&lt;/div&gt; 
&lt;div style="display: flex; flex-direction: column; align-items: center;"&gt; 
 &lt;img src="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/assets/minicpmv4_5/en_case1.png" alt="en_case1" style="margin-bottom: 5px;" /&gt; 
 &lt;img src="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/assets/minicpmv4_5/en_case2.png" alt="en_case2" style="margin-bottom: 5px;" /&gt; 
 &lt;img src="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/assets/minicpmv4_5/en_case3.jpeg" alt="en_case3" style="margin-bottom: 5px;" /&gt; 
&lt;/div&gt; 
&lt;details&gt; 
 &lt;summary&gt;Click to view more cases.&lt;/summary&gt; 
 &lt;div style="display: flex; flex-direction: column; align-items: center;"&gt; 
  &lt;img src="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/assets/minicpmv4_5/zh_extra.jpeg" alt="zh_extra" style="margin-bottom: 5px;" /&gt; 
 &lt;/div&gt; 
&lt;/details&gt; 
&lt;p&gt;We deploy MiniCPM-V 4.5 on iPad M4 with &lt;a href="https://github.com/tc-mb/MiniCPM-o-demo-iOS"&gt;iOS demo&lt;/a&gt;. The demo video is the raw screen recording without edition.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/assets/minicpmv4_5/v45_en_handwriting.gif" width="45%/" /&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &lt;img src="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/assets/minicpmv4_5/v45_en_cot.gif" width="45%/" /&gt; &lt;/p&gt;
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/assets/minicpmv4_5/v45_cn_handwriting.gif" width="45%/" /&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &lt;img src="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/assets/minicpmv4_5/v45_cn_travel.gif" width="45%/" /&gt; &lt;/p&gt;
&lt;table align="center"&gt;   
&lt;/table&gt; 
&lt;h2&gt;MiniCPM-o 2.6&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;MiniCPM-o 2.6&lt;/strong&gt; is the latest and most capable model in the MiniCPM-o series. The model is built in an end-to-end fashion based on SigLip-400M, Whisper-medium-300M, ChatTTS-200M, and Qwen2.5-7B with a total of 8B parameters. It exhibits a significant performance improvement over MiniCPM-V 2.6, and introduces new features for real-time speech conversation and multimodal live streaming. Notable features of MiniCPM-o 2.6 include:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;🔥 &lt;strong&gt;Leading Visual Capability.&lt;/strong&gt; MiniCPM-o 2.6 achieves an average score of 70.2 on OpenCompass, a comprehensive evaluation of 8 popular benchmarks. &lt;strong&gt;With only 8B parameters, it surpasses widely used proprietary models like GPT-4o-202405, Gemini 1.5 Pro, and Claude 3.5 Sonnet&lt;/strong&gt; for single image understanding. It also &lt;strong&gt;outperforms GPT-4V and Claude 3.5 Sonnet&lt;/strong&gt; in multi-image and video understanding, and shows promising in-context learning capability.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;🎙 &lt;strong&gt;State-of-the-art Speech Capability.&lt;/strong&gt; MiniCPM-o 2.6 supports &lt;strong&gt;bilingual real-time speech conversation with configurable voices&lt;/strong&gt; in English and Chinese. It &lt;strong&gt;outperforms GPT-4o-realtime on audio understanding tasks&lt;/strong&gt; such as ASR and STT translation, and shows &lt;strong&gt;state-of-the-art performance on speech conversation in both semantic and acoustic evaluations in the open-source community&lt;/strong&gt;. It also allows for fun features such as emotion/speed/style control, end-to-end voice cloning, role play, etc.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;🎬 &lt;strong&gt;Strong Multimodal Live Streaming Capability.&lt;/strong&gt; As a new feature, MiniCPM-o 2.6 can &lt;strong&gt;accept continuous video and audio streams independent of user queries, and support real-time speech interaction&lt;/strong&gt;. It &lt;strong&gt;outperforms GPT-4o-202408 and Claude 3.5 Sonnet and shows state-of-art performance in the open-source community on StreamingBench&lt;/strong&gt;, a comprehensive benchmark for real-time video understanding, omni-source (video &amp;amp; audio) understanding, and multimodal contextual understanding.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;💪 &lt;strong&gt;Strong OCR Capability and Others.&lt;/strong&gt; Advancing popular visual capabilities from MiniCPM-V series, MiniCPM-o 2.6 can process images with any aspect ratio and up to 1.8 million pixels (e.g., 1344x1344). It achieves &lt;strong&gt;state-of-the-art performance on OCRBench for models under 25B, surpassing proprietary models such as GPT-4o-202405&lt;/strong&gt;. Based on the the latest &lt;a href="https://github.com/RLHF-V/RLAIF-V/"&gt;RLAIF-V&lt;/a&gt; and &lt;a href="https://github.com/OpenBMB/VisCPM"&gt;VisCPM&lt;/a&gt; techniques, it features &lt;strong&gt;trustworthy behaviors&lt;/strong&gt;, outperforming GPT-4o and Claude 3.5 Sonnet on MMHal-Bench, and supports &lt;strong&gt;multilingual capabilities&lt;/strong&gt; on more than 30 languages.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;🚀 &lt;strong&gt;Superior Efficiency.&lt;/strong&gt; In addition to its friendly size, MiniCPM-o 2.6 also shows &lt;strong&gt;state-of-the-art token density&lt;/strong&gt; (i.e., the number of pixels encoded into each visual token). &lt;strong&gt;It produces only 640 tokens when processing a 1.8M pixel image, which is 75% fewer than most models&lt;/strong&gt;. This directly improves the inference speed, first-token latency, memory usage, and power consumption. As a result, MiniCPM-o 2.6 can efficiently support &lt;strong&gt;multimodal live streaming&lt;/strong&gt; on end-side devices such as iPads.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;💫 &lt;strong&gt;Easy Usage.&lt;/strong&gt; MiniCPM-o 2.6 can be easily used in various ways: (1) &lt;a href="https://github.com/OpenBMB/llama.cpp/raw/minicpm-omni/examples/llava/README-minicpmo2.6.md"&gt;llama.cpp&lt;/a&gt; support for efficient CPU inference on local devices, (2) &lt;a href="https://huggingface.co/openbmb/MiniCPM-o-2_6-int4"&gt;int4&lt;/a&gt; and &lt;a href="https://huggingface.co/openbmb/MiniCPM-o-2_6-gguf"&gt;GGUF&lt;/a&gt; format quantized models in 16 sizes, (3) &lt;a href="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/#efficient-inference-with-llamacpp-ollama-vllm"&gt;vLLM&lt;/a&gt; support for high-throughput and memory-efficient inference, (4) fine-tuning on new domains and tasks with &lt;a href="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/docs/llamafactory_train_and_infer.md"&gt;LLaMA-Factory&lt;/a&gt;, (5) quick &lt;a href="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/#chat-with-our-demo-on-gradio"&gt;local WebUI demo&lt;/a&gt;, and (6) online web demo on &lt;a href="https://minicpm-omni-webdemo-us.modelbest.cn/"&gt;server&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Model Architecture.&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;End-to-end Omni-modal Architecture.&lt;/strong&gt; Different modality encoders/decoders are connected and trained in an &lt;strong&gt;end-to-end&lt;/strong&gt; fashion to fully exploit rich multimodal knowledge. The model is trained in a fully end-to-end manner with only CE loss.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Omni-modal Live Streaming Mechanism.&lt;/strong&gt; (1) We change the offline modality encoder/decoders into online ones for &lt;strong&gt;streaming inputs/outputs.&lt;/strong&gt; (2) We devise a &lt;strong&gt;time-division multiplexing (TDM) mechanism&lt;/strong&gt; for omni-modality streaming processing in the LLM backbone. It divides parallel omni-modality streams into sequential info within small periodic time slices.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Configurable Speech Modeling Design.&lt;/strong&gt; We devise a multimodal system prompt, including traditional text system prompt, and &lt;strong&gt;a new audio system prompt to determine the assistant voice&lt;/strong&gt;. This enables flexible voice configurations in inference time, and also facilitates end-to-end voice cloning and description-based voice creation.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/assets/minicpm-o-26-framework-v2.png" , width="80%" /&gt; 
&lt;/div&gt; 
&lt;h3&gt;Evaluation 
 &lt;!-- omit in toc --&gt;&lt;/h3&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/assets/radar.jpg" , width="80%" /&gt; 
&lt;/div&gt; 
&lt;details&gt; 
 &lt;summary&gt;Click to view visual understanding results.&lt;/summary&gt; 
 &lt;p&gt;&lt;strong&gt;Image Understanding&lt;/strong&gt;&lt;/p&gt; 
 &lt;div align="center"&gt; 
  &lt;table style="margin: 0px auto;"&gt; 
   &lt;thead&gt; 
    &lt;tr&gt; 
     &lt;th align="left"&gt;Model&lt;/th&gt; 
     &lt;th&gt;Size&lt;/th&gt; 
     &lt;th&gt;Token Density&lt;sup&gt;+&lt;/sup&gt;&lt;/th&gt; 
     &lt;th&gt;OpenCompass&lt;/th&gt; 
     &lt;th&gt;OCRBench&lt;/th&gt; 
     &lt;th&gt;MathVista mini&lt;/th&gt; 
     &lt;th&gt;ChartQA&lt;/th&gt; 
     &lt;th&gt;MMVet&lt;/th&gt; 
     &lt;th&gt;MMStar&lt;/th&gt; 
     &lt;th&gt;MME&lt;/th&gt; 
     &lt;th&gt;MMB1.1 test&lt;/th&gt; 
     &lt;th&gt;AI2D&lt;/th&gt; 
     &lt;th&gt;MMMU val&lt;/th&gt; 
     &lt;th&gt;HallusionBench&lt;/th&gt; 
     &lt;th&gt;TextVQA val&lt;/th&gt; 
     &lt;th&gt;DocVQA test&lt;/th&gt; 
     &lt;th&gt;MathVerse mini&lt;/th&gt; 
     &lt;th&gt;MathVision&lt;/th&gt; 
     &lt;th&gt;MMHal Score&lt;/th&gt; 
    &lt;/tr&gt; 
   &lt;/thead&gt; 
   &lt;tbody align="center"&gt; 
    &lt;tr&gt; 
     &lt;td colspan="19" align="left"&gt;&lt;strong&gt;Proprietary&lt;/strong&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td nowrap align="left"&gt;GPT-4o-20240513&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;1088&lt;/td&gt; 
     &lt;td&gt;&lt;u&gt;69.9&lt;/u&gt;&lt;/td&gt; 
     &lt;td&gt;736&lt;/td&gt; 
     &lt;td&gt;61.3&lt;/td&gt; 
     &lt;td&gt;85.7&lt;/td&gt; 
     &lt;td&gt;&lt;strong&gt;69.1&lt;/strong&gt;&lt;/td&gt; 
     &lt;td&gt;63.9&lt;/td&gt; 
     &lt;td&gt;2328.7&lt;/td&gt; 
     &lt;td&gt;82.2&lt;/td&gt; 
     &lt;td&gt;84.6&lt;/td&gt; 
     &lt;td&gt;&lt;strong&gt;69.2&lt;/strong&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;strong&gt;55.0&lt;/strong&gt;&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;92.8&lt;/td&gt; 
     &lt;td&gt;&lt;strong&gt;50.2&lt;/strong&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;strong&gt;30.4&lt;/strong&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;u&gt;3.6&lt;/u&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td nowrap align="left"&gt;Claude3.5-Sonnet&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;750&lt;/td&gt; 
     &lt;td&gt;67.9&lt;/td&gt; 
     &lt;td&gt;788&lt;/td&gt; 
     &lt;td&gt;61.6&lt;/td&gt; 
     &lt;td&gt;&lt;strong&gt;90.8&lt;/strong&gt;&lt;/td&gt; 
     &lt;td&gt;66.0&lt;/td&gt; 
     &lt;td&gt;62.2&lt;/td&gt; 
     &lt;td&gt;1920.0&lt;/td&gt; 
     &lt;td&gt;78.5&lt;/td&gt; 
     &lt;td&gt;80.2&lt;/td&gt; 
     &lt;td&gt;&lt;u&gt;65.9&lt;/u&gt;&lt;/td&gt; 
     &lt;td&gt;49.9&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;&lt;strong&gt;95.2&lt;/strong&gt;&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;3.4&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td nowrap align="left"&gt;Gemini 1.5 Pro&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;64.4&lt;/td&gt; 
     &lt;td&gt;754&lt;/td&gt; 
     &lt;td&gt;57.7&lt;/td&gt; 
     &lt;td&gt;81.3&lt;/td&gt; 
     &lt;td&gt;64.0&lt;/td&gt; 
     &lt;td&gt;59.1&lt;/td&gt; 
     &lt;td&gt;2110.6&lt;/td&gt; 
     &lt;td&gt;73.9&lt;/td&gt; 
     &lt;td&gt;79.1&lt;/td&gt; 
     &lt;td&gt;60.6&lt;/td&gt; 
     &lt;td&gt;45.6&lt;/td&gt; 
     &lt;td&gt;73.5&lt;/td&gt; 
     &lt;td&gt;86.5&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;19.2&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td nowrap align="left"&gt;GPT-4o-mini-20240718&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;1088&lt;/td&gt; 
     &lt;td&gt;64.1&lt;/td&gt; 
     &lt;td&gt;785&lt;/td&gt; 
     &lt;td&gt;52.4&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;66.9&lt;/td&gt; 
     &lt;td&gt;54.8&lt;/td&gt; 
     &lt;td&gt;2003.4&lt;/td&gt; 
     &lt;td&gt;76.0&lt;/td&gt; 
     &lt;td&gt;77.8&lt;/td&gt; 
     &lt;td&gt;60.0&lt;/td&gt; 
     &lt;td&gt;46.1&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;3.3&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td colspan="19" align="left"&gt;&lt;strong&gt;Open Source&lt;/strong&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td nowrap align="left"&gt;Cambrian-34B&lt;/td&gt; 
     &lt;td&gt;34B&lt;/td&gt; 
     &lt;td&gt;&lt;u&gt;1820&lt;/u&gt;&lt;/td&gt; 
     &lt;td&gt;58.3&lt;/td&gt; 
     &lt;td&gt;591&lt;/td&gt; 
     &lt;td&gt;50.3&lt;/td&gt; 
     &lt;td&gt;75.6&lt;/td&gt; 
     &lt;td&gt;53.2&lt;/td&gt; 
     &lt;td&gt;54.2&lt;/td&gt; 
     &lt;td&gt;2049.9&lt;/td&gt; 
     &lt;td&gt;77.8&lt;/td&gt; 
     &lt;td&gt;79.5&lt;/td&gt; 
     &lt;td&gt;50.4&lt;/td&gt; 
     &lt;td&gt;41.6&lt;/td&gt; 
     &lt;td&gt;76.7&lt;/td&gt; 
     &lt;td&gt;75.5&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td nowrap align="left"&gt;GLM-4V-9B&lt;/td&gt; 
     &lt;td&gt;13B&lt;/td&gt; 
     &lt;td&gt;784&lt;/td&gt; 
     &lt;td&gt;59.1&lt;/td&gt; 
     &lt;td&gt;776&lt;/td&gt; 
     &lt;td&gt;51.1&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;58.0&lt;/td&gt; 
     &lt;td&gt;54.8&lt;/td&gt; 
     &lt;td&gt;2018.8&lt;/td&gt; 
     &lt;td&gt;67.9&lt;/td&gt; 
     &lt;td&gt;71.2&lt;/td&gt; 
     &lt;td&gt;46.9&lt;/td&gt; 
     &lt;td&gt;45.0&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td nowrap align="left"&gt;Pixtral-12B&lt;/td&gt; 
     &lt;td&gt;12B&lt;/td&gt; 
     &lt;td&gt;256&lt;/td&gt; 
     &lt;td&gt;61.0&lt;/td&gt; 
     &lt;td&gt;685&lt;/td&gt; 
     &lt;td&gt;56.9&lt;/td&gt; 
     &lt;td&gt;81.8&lt;/td&gt; 
     &lt;td&gt;58.5&lt;/td&gt; 
     &lt;td&gt;54.5&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;72.7&lt;/td&gt; 
     &lt;td&gt;79.0&lt;/td&gt; 
     &lt;td&gt;51.1&lt;/td&gt; 
     &lt;td&gt;47.0&lt;/td&gt; 
     &lt;td&gt;75.7&lt;/td&gt; 
     &lt;td&gt;90.7&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td nowrap align="left"&gt;VITA-1.5&lt;/td&gt; 
     &lt;td&gt;8B&lt;/td&gt; 
     &lt;td&gt;784&lt;/td&gt; 
     &lt;td&gt;63.3&lt;/td&gt; 
     &lt;td&gt;741&lt;/td&gt; 
     &lt;td&gt;66.2&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;52.7&lt;/td&gt; 
     &lt;td&gt;60.2&lt;/td&gt; 
     &lt;td&gt;2328.1&lt;/td&gt; 
     &lt;td&gt;76.8&lt;/td&gt; 
     &lt;td&gt;79.2&lt;/td&gt; 
     &lt;td&gt;52.6&lt;/td&gt; 
     &lt;td&gt;44.6&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td nowrap align="left"&gt;DeepSeek-VL2-27B (4B)&lt;/td&gt; 
     &lt;td&gt;27B&lt;/td&gt; 
     &lt;td&gt;672&lt;/td&gt; 
     &lt;td&gt;66.4&lt;/td&gt; 
     &lt;td&gt;809&lt;/td&gt; 
     &lt;td&gt;63.9&lt;/td&gt; 
     &lt;td&gt;86.0&lt;/td&gt; 
     &lt;td&gt;60.0&lt;/td&gt; 
     &lt;td&gt;61.9&lt;/td&gt; 
     &lt;td&gt;2253.0&lt;/td&gt; 
     &lt;td&gt;81.2&lt;/td&gt; 
     &lt;td&gt;83.8&lt;/td&gt; 
     &lt;td&gt;54.0&lt;/td&gt; 
     &lt;td&gt;45.3&lt;/td&gt; 
     &lt;td&gt;&lt;u&gt;84.2&lt;/u&gt;&lt;/td&gt; 
     &lt;td&gt;93.3&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;3.0&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td nowrap align="left"&gt;Qwen2-VL-7B&lt;/td&gt; 
     &lt;td&gt;8B&lt;/td&gt; 
     &lt;td&gt;784&lt;/td&gt; 
     &lt;td&gt;67.1&lt;/td&gt; 
     &lt;td&gt;&lt;u&gt;866&lt;/u&gt;&lt;/td&gt; 
     &lt;td&gt;58.2&lt;/td&gt; 
     &lt;td&gt;83.0&lt;/td&gt; 
     &lt;td&gt;62.0&lt;/td&gt; 
     &lt;td&gt;60.7&lt;/td&gt; 
     &lt;td&gt;2326.0&lt;/td&gt; 
     &lt;td&gt;81.8&lt;/td&gt; 
     &lt;td&gt;83.0&lt;/td&gt; 
     &lt;td&gt;54.1&lt;/td&gt; 
     &lt;td&gt;50.6&lt;/td&gt; 
     &lt;td&gt;&lt;strong&gt;84.3&lt;/strong&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;u&gt;94.5&lt;/u&gt;&lt;/td&gt; 
     &lt;td&gt;31.9&lt;/td&gt; 
     &lt;td&gt;16.3&lt;/td&gt; 
     &lt;td&gt;3.2&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td nowrap align="left"&gt;LLaVA-OneVision-72B&lt;/td&gt; 
     &lt;td&gt;72B&lt;/td&gt; 
     &lt;td&gt;182&lt;/td&gt; 
     &lt;td&gt;68.1&lt;/td&gt; 
     &lt;td&gt;741&lt;/td&gt; 
     &lt;td&gt;67.5&lt;/td&gt; 
     &lt;td&gt;83.7&lt;/td&gt; 
     &lt;td&gt;60.6&lt;/td&gt; 
     &lt;td&gt;&lt;strong&gt;65.8&lt;/strong&gt;&lt;/td&gt; 
     &lt;td&gt;2261.0&lt;/td&gt; 
     &lt;td&gt;&lt;strong&gt;85.0&lt;/strong&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;u&gt;85.6&lt;/u&gt;&lt;/td&gt; 
     &lt;td&gt;56.8&lt;/td&gt; 
     &lt;td&gt;49.0&lt;/td&gt; 
     &lt;td&gt;80.5&lt;/td&gt; 
     &lt;td&gt;91.3&lt;/td&gt; 
     &lt;td&gt;39.1&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;3.5&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td nowrap align="left"&gt;InternVL2.5-8B&lt;/td&gt; 
     &lt;td&gt;8B&lt;/td&gt; 
     &lt;td&gt;706&lt;/td&gt; 
     &lt;td&gt;68.3&lt;/td&gt; 
     &lt;td&gt;822&lt;/td&gt; 
     &lt;td&gt;&lt;u&gt;64.4&lt;/u&gt;&lt;/td&gt; 
     &lt;td&gt;84.8&lt;/td&gt; 
     &lt;td&gt;62.8&lt;/td&gt; 
     &lt;td&gt;62.8&lt;/td&gt; 
     &lt;td&gt;2344.0&lt;/td&gt; 
     &lt;td&gt;&lt;u&gt;83.6&lt;/u&gt;&lt;/td&gt; 
     &lt;td&gt;84.5&lt;/td&gt; 
     &lt;td&gt;56.0&lt;/td&gt; 
     &lt;td&gt;50.1&lt;/td&gt; 
     &lt;td&gt;79.1&lt;/td&gt; 
     &lt;td&gt;93.0&lt;/td&gt; 
     &lt;td&gt;39.5&lt;/td&gt; 
     &lt;td&gt;19.7&lt;/td&gt; 
     &lt;td&gt;3.4&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td nowrap align="left"&gt;MiniCPM-V 2.6&lt;/td&gt; 
     &lt;td&gt;8B&lt;/td&gt; 
     &lt;td&gt;&lt;strong&gt;2822&lt;/strong&gt;&lt;/td&gt; 
     &lt;td&gt;65.2&lt;/td&gt; 
     &lt;td&gt;852*&lt;/td&gt; 
     &lt;td&gt;60.6&lt;/td&gt; 
     &lt;td&gt;79.4&lt;/td&gt; 
     &lt;td&gt;60.0&lt;/td&gt; 
     &lt;td&gt;57.5&lt;/td&gt; 
     &lt;td&gt;&lt;u&gt;2348.4*&lt;/u&gt;&lt;/td&gt; 
     &lt;td&gt;78.0&lt;/td&gt; 
     &lt;td&gt;82.1&lt;/td&gt; 
     &lt;td&gt;49.8*&lt;/td&gt; 
     &lt;td&gt;48.1*&lt;/td&gt; 
     &lt;td&gt;80.1&lt;/td&gt; 
     &lt;td&gt;90.8&lt;/td&gt; 
     &lt;td&gt;25.7&lt;/td&gt; 
     &lt;td&gt;18.3&lt;/td&gt; 
     &lt;td&gt;3.6&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td nowrap align="left"&gt;MiniCPM-o 2.6&lt;/td&gt; 
     &lt;td&gt;8B&lt;/td&gt; 
     &lt;td&gt;&lt;strong&gt;2822&lt;/strong&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;strong&gt;70.2&lt;/strong&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;strong&gt;897*&lt;/strong&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;strong&gt;71.9*&lt;/strong&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;u&gt;86.9*&lt;/u&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;u&gt;67.5&lt;/u&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;u&gt;64.0&lt;/u&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;strong&gt;2372.0*&lt;/strong&gt;&lt;/td&gt; 
     &lt;td&gt;80.5&lt;/td&gt; 
     &lt;td&gt;&lt;strong&gt;85.8&lt;/strong&gt;&lt;/td&gt; 
     &lt;td&gt;50.4*&lt;/td&gt; 
     &lt;td&gt;&lt;u&gt;51.9&lt;/u&gt;&lt;/td&gt; 
     &lt;td&gt;82.0&lt;/td&gt; 
     &lt;td&gt;93.5&lt;/td&gt; 
     &lt;td&gt;&lt;u&gt;41.4*&lt;/u&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;u&gt;23.1*&lt;/u&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;strong&gt;3.8&lt;/strong&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
   &lt;/tbody&gt; 
  &lt;/table&gt; 
 &lt;/div&gt; * We evaluate this benchmark using chain-of-thought prompting. Specifically, for MME, we used this technique only for the Cognition set. 
 &lt;p&gt;&lt;sup&gt;+&lt;/sup&gt; Token Density: number of pixels encoded into each visual token at maximum resolution, i.e., # pixels at maximum resolution / # visual tokens.&lt;/p&gt; 
 &lt;p&gt;Note: For proprietary models, we calculate token density based on the image encoding charging strategy defined in the official API documentation, which provides an upper-bound estimation.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Multi-image and Video Understanding&lt;/strong&gt;&lt;/p&gt; 
 &lt;div align="center"&gt; 
  &lt;table style="margin: 0px auto;"&gt; 
   &lt;thead&gt; 
    &lt;tr&gt; 
     &lt;th align="left"&gt;Model&lt;/th&gt; 
     &lt;th&gt;Size&lt;/th&gt; 
     &lt;th&gt;BLINK val&lt;/th&gt; 
     &lt;th&gt;Mantis Eval&lt;/th&gt; 
     &lt;th&gt;MIRB&lt;/th&gt; 
     &lt;th&gt;Video-MME (wo / w subs)&lt;/th&gt; 
    &lt;/tr&gt; 
   &lt;/thead&gt; 
   &lt;tbody align="center"&gt; 
    &lt;tr&gt; 
     &lt;td colspan="6" align="left"&gt;&lt;strong&gt;Proprietary&lt;/strong&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td nowrap align="left"&gt;GPT-4o-20240513&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;&lt;strong&gt;68.0&lt;/strong&gt;&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;&lt;strong&gt;71.9/77.2&lt;strong&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td nowrap align="left"&gt;GPT4V&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;54.6&lt;/td&gt; 
     &lt;td&gt;62.7&lt;/td&gt; 
     &lt;td&gt;53.1&lt;/td&gt; 
     &lt;td&gt;59.9/63.3&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td colspan="6" align="left"&gt;&lt;strong&gt;Open-source&lt;/strong&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td nowrap align="left"&gt;VITA-1.5&lt;/td&gt; 
     &lt;td&gt;8B&lt;/td&gt; 
     &lt;td&gt;45.0&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;56.1/58.7&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td nowrap align="left"&gt;LLaVA-NeXT-Interleave 14B&lt;/td&gt; 
     &lt;td&gt;14B&lt;/td&gt; 
     &lt;td&gt;52.6&lt;/td&gt; 
     &lt;td&gt;66.4&lt;/td&gt; 
     &lt;td&gt;30.2&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td nowrap align="left"&gt;LLaVA-OneVision-72B&lt;/td&gt; 
     &lt;td&gt;72B&lt;/td&gt; 
     &lt;td&gt;55.4&lt;/td&gt; 
     &lt;td&gt;&lt;strong&gt;77.6&lt;/strong&gt;&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;&lt;u&gt;66.2/69.5&lt;/u&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td nowrap align="left"&gt;MANTIS 8B&lt;/td&gt; 
     &lt;td&gt;8B&lt;/td&gt; 
     &lt;td&gt;49.1&lt;/td&gt; 
     &lt;td&gt;59.5&lt;/td&gt; 
     &lt;td&gt;34.8&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td nowrap align="left"&gt;Qwen2-VL-7B&lt;/td&gt; 
     &lt;td&gt;8B&lt;/td&gt; 
     &lt;td&gt;53.2&lt;/td&gt; 
     &lt;td&gt;69.6*&lt;/td&gt; 
     &lt;td&gt;&lt;strong&gt;67.6*&lt;/strong&gt;&lt;/td&gt; 
     &lt;td&gt;63.3/69.0&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td nowrap align="left"&gt;InternVL2.5-8B&lt;/td&gt; 
     &lt;td&gt;8B&lt;/td&gt; 
     &lt;td&gt;54.8&lt;/td&gt; 
     &lt;td&gt;67.7&lt;/td&gt; 
     &lt;td&gt;52.5&lt;/td&gt; 
     &lt;td&gt;64.2/66.9&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td nowrap align="left"&gt;MiniCPM-V 2.6&lt;/td&gt; 
     &lt;td&gt;8B&lt;/td&gt; 
     &lt;td&gt;53.0&lt;/td&gt; 
     &lt;td&gt;69.1&lt;/td&gt; 
     &lt;td&gt;53.8&lt;/td&gt; 
     &lt;td&gt;60.9/63.6&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td nowrap align="left"&gt;MiniCPM-o 2.6&lt;/td&gt; 
     &lt;td&gt;8B&lt;/td&gt; 
     &lt;td&gt;&lt;u&gt;56.7&lt;/u&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;u&gt;71.9&lt;/u&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;u&gt;58.6&lt;/u&gt;&lt;/td&gt; 
     &lt;td&gt;63.9/67.9&lt;/td&gt; 
    &lt;/tr&gt; 
   &lt;/tbody&gt; 
  &lt;/table&gt; 
 &lt;/div&gt; * We evaluate officially released checkpoints by ourselves. 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Click to view audio understanding and speech conversation results.&lt;/summary&gt; 
 &lt;p&gt;&lt;strong&gt;Audio Understanding&lt;/strong&gt;&lt;/p&gt; 
 &lt;div align="center"&gt; 
  &lt;table style="margin: 0px auto;"&gt; 
   &lt;thead&gt; 
    &lt;tr&gt; 
     &lt;th align="left"&gt;Task&lt;/th&gt; 
     &lt;th&gt;Size&lt;/th&gt; 
     &lt;th colspan="3"&gt;ASR (zh)&lt;/th&gt; 
     &lt;th colspan="3"&gt;ASR (en)&lt;/th&gt; 
     &lt;th colspan="2"&gt;AST&lt;/th&gt; 
     &lt;th&gt;Emotion&lt;/th&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;th align="left"&gt;Metric&lt;/th&gt; 
     &lt;td&gt;&lt;/td&gt; 
     &lt;th colspan="3"&gt;CER↓&lt;/th&gt; 
     &lt;th colspan="3"&gt;WER↓&lt;/th&gt; 
     &lt;th colspan="2"&gt;BLEU↑&lt;/th&gt; 
     &lt;th&gt;ACC↑&lt;/th&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;th align="left"&gt;Dataset&lt;/th&gt; 
     &lt;td&gt;&lt;/td&gt; 
     &lt;th&gt;AISHELL-1&lt;/th&gt; 
     &lt;th&gt;Fleurs zh&lt;/th&gt; 
     &lt;th&gt;WenetSpeech test-net&lt;/th&gt; 
     &lt;th&gt;LibriSpeech test-clean&lt;/th&gt; 
     &lt;th&gt;GigaSpeech&lt;/th&gt; 
     &lt;th&gt;TED-LIUM&lt;/th&gt; 
     &lt;th&gt;CoVoST en2zh&lt;/th&gt; 
     &lt;th&gt;CoVoST zh2en&lt;/th&gt; 
     &lt;th&gt;MELD emotion&lt;/th&gt; 
    &lt;/tr&gt; 
   &lt;/thead&gt; 
   &lt;tbody align="center"&gt; 
    &lt;tr&gt; 
     &lt;td colspan="11" align="left"&gt;&lt;strong&gt;Proprietary&lt;/strong&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td nowrap align="left"&gt;GPT-4o-Realtime&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;7.3*&lt;/td&gt; 
     &lt;td&gt;&lt;u&gt;5.4*&lt;/u&gt;&lt;/td&gt; 
     &lt;td&gt;28.9*&lt;/td&gt; 
     &lt;td&gt;2.6*&lt;/td&gt; 
     &lt;td&gt;12.9*&lt;/td&gt; 
     &lt;td&gt;4.8*&lt;/td&gt; 
     &lt;td&gt;37.1*&lt;/td&gt; 
     &lt;td&gt;15.7*&lt;/td&gt; 
     &lt;td&gt;33.2*&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td nowrap align="left"&gt;Gemini 1.5 Pro&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;4.5*&lt;/td&gt; 
     &lt;td&gt;5.9*&lt;/td&gt; 
     &lt;td&gt;14.3*&lt;/td&gt; 
     &lt;td&gt;2.9*&lt;/td&gt; 
     &lt;td&gt;10.6*&lt;/td&gt; 
     &lt;td&gt;&lt;strong&gt;3.0*&lt;/strong&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;u&gt;47.3*&lt;/u&gt;&lt;/td&gt; 
     &lt;td&gt;22.6*&lt;/td&gt; 
     &lt;td&gt;48.4*&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td colspan="11" align="left"&gt;&lt;strong&gt;Open-Source&lt;/strong&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td nowrap align="left"&gt;Qwen2-Audio-7B&lt;/td&gt; 
     &lt;td&gt;8B&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;7.5&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;&lt;strong&gt;1.6&lt;/strong&gt;&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;45.2&lt;/td&gt; 
     &lt;td&gt;&lt;u&gt;24.4&lt;/u&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;strong&gt;55.3&lt;/strong&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td nowrap align="left"&gt;Qwen2-Audio-7B-Instruct&lt;/td&gt; 
     &lt;td&gt;8B&lt;/td&gt; 
     &lt;td&gt;2.6*&lt;/td&gt; 
     &lt;td&gt;6.9*&lt;/td&gt; 
     &lt;td&gt;&lt;u&gt;10.3*&lt;/u&gt;&lt;/td&gt; 
     &lt;td&gt;3.1*&lt;/td&gt; 
     &lt;td&gt;&lt;u&gt;9.7&lt;/u&gt;*&lt;/td&gt; 
     &lt;td&gt;5.9*&lt;/td&gt; 
     &lt;td&gt;39.5*&lt;/td&gt; 
     &lt;td&gt;22.9*&lt;/td&gt; 
     &lt;td&gt;17.4*&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td nowrap align="left"&gt;VITA-1.5&lt;/td&gt; 
     &lt;td&gt;8B&lt;/td&gt; 
     &lt;td&gt;2.16&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;8.4&lt;/td&gt; 
     &lt;td&gt;3.4&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td nowrap align="left"&gt;GLM-4-Voice-Base&lt;/td&gt; 
     &lt;td&gt;9B&lt;/td&gt; 
     &lt;td&gt;&lt;u&gt;2.5&lt;/u&gt;&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;2.8&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td nowrap align="left"&gt;MiniCPM-o 2.6&lt;/td&gt; 
     &lt;td&gt;8B&lt;/td&gt; 
     &lt;td&gt;&lt;strong&gt;1.6&lt;/strong&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;strong&gt;4.4&lt;/strong&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;strong&gt;6.9&lt;/strong&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;u&gt;1.7&lt;/u&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;strong&gt;8.7&lt;/strong&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;strong&gt;3.0&lt;/strong&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;strong&gt;48.2&lt;/strong&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;strong&gt;27.2&lt;/strong&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;u&gt;52.4&lt;/u&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
   &lt;/tbody&gt; 
  &lt;/table&gt; 
 &lt;/div&gt; * We evaluate officially released checkpoints by ourselves.
 &lt;br /&gt;
 &lt;br /&gt; 
 &lt;p&gt;&lt;strong&gt;Speech Generation&lt;/strong&gt;&lt;/p&gt; 
 &lt;div align="center"&gt; 
  &lt;table style="margin: 0px auto;"&gt; 
   &lt;thead&gt; 
    &lt;tr&gt; 
     &lt;th align="left"&gt;Task&lt;/th&gt; 
     &lt;th&gt;Size&lt;/th&gt; 
     &lt;th colspan="9"&gt;SpeechQA&lt;/th&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;th align="left"&gt;Metric&lt;/th&gt; 
     &lt;th&gt;&lt;/th&gt; 
     &lt;th colspan="3"&gt;ACC↑&lt;/th&gt; 
     &lt;th&gt;G-Eval (10 point)↑&lt;/th&gt; 
     &lt;th&gt;Semantic ELO score↑&lt;/th&gt; 
     &lt;th&gt;Acoustic ELO score↑&lt;/th&gt; 
     &lt;th&gt;Overall ELO score↑&lt;/th&gt; 
     &lt;th&gt;UTMOS↑&lt;/th&gt; 
     &lt;th&gt;ASR-WER↓&lt;/th&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;th align="left"&gt;Dataset&lt;/th&gt; 
     &lt;th&gt;&lt;/th&gt; 
     &lt;th&gt;Speech Llama Q.&lt;/th&gt; 
     &lt;th&gt;Speech Web Q.&lt;/th&gt; 
     &lt;th&gt;Speech Trivia QA&lt;/th&gt; 
     &lt;th&gt;Speech AlpacaEval&lt;/th&gt; 
     &lt;th colspan="5"&gt;AudioArena&lt;/th&gt; 
    &lt;/tr&gt; 
   &lt;/thead&gt; 
   &lt;tbody align="center"&gt; 
    &lt;tr&gt; 
     &lt;td colspan="11" align="left"&gt;&lt;strong&gt;Proprietary&lt;/strong&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td nowrap align="left"&gt;GPT-4o-Realtime&lt;/td&gt; 
     &lt;td&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;strong&gt;71.7&lt;/strong&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;strong&gt;51.6&lt;/strong&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;strong&gt;69.7&lt;/strong&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;strong&gt;7.4&lt;/strong&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;strong&gt;1157&lt;/strong&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;strong&gt;1203&lt;/strong&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;strong&gt;1200&lt;/strong&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;strong&gt;4.2&lt;/strong&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;strong&gt;2.3&lt;/strong&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td colspan="11" align="left"&gt;&lt;strong&gt;Open-Source&lt;/strong&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td nowrap align="left"&gt;GLM-4-Voice&lt;/td&gt; 
     &lt;td&gt;9B&lt;/td&gt; 
     &lt;td&gt;50.0&lt;/td&gt; 
     &lt;td&gt;32.0&lt;/td&gt; 
     &lt;td&gt;36.4&lt;/td&gt; 
     &lt;td&gt;&lt;u&gt;5.1&lt;/u&gt;&lt;/td&gt; 
     &lt;td&gt;999&lt;/td&gt; 
     &lt;td&gt;1147&lt;/td&gt; 
     &lt;td&gt;1035&lt;/td&gt; 
     &lt;td&gt;&lt;u&gt;4.1&lt;/u&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;u&gt;11.7&lt;/u&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td nowrap align="left"&gt;Llama-Omni&lt;/td&gt; 
     &lt;td&gt;8B&lt;/td&gt; 
     &lt;td&gt;45.3&lt;/td&gt; 
     &lt;td&gt;22.9&lt;/td&gt; 
     &lt;td&gt;10.7&lt;/td&gt; 
     &lt;td&gt;3.9&lt;/td&gt; 
     &lt;td&gt;960&lt;/td&gt; 
     &lt;td&gt;878&lt;/td&gt; 
     &lt;td&gt;897&lt;/td&gt; 
     &lt;td&gt;3.2&lt;/td&gt; 
     &lt;td&gt;24.3&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td nowrap align="left"&gt;VITA-1.5&lt;/td&gt; 
     &lt;td&gt;8B&lt;/td&gt; 
     &lt;td&gt;46.7&lt;/td&gt; 
     &lt;td&gt;28.1&lt;/td&gt; 
     &lt;td&gt;23.3&lt;/td&gt; 
     &lt;td&gt;2.0&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
     &lt;td&gt;-&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td nowrap align="left"&gt;Moshi&lt;/td&gt; 
     &lt;td&gt;7B&lt;/td&gt; 
     &lt;td&gt;43.7&lt;/td&gt; 
     &lt;td&gt;23.8&lt;/td&gt; 
     &lt;td&gt;16.7&lt;/td&gt; 
     &lt;td&gt;2.4&lt;/td&gt; 
     &lt;td&gt;871&lt;/td&gt; 
     &lt;td&gt;808&lt;/td&gt; 
     &lt;td&gt;875&lt;/td&gt; 
     &lt;td&gt;2.8&lt;/td&gt; 
     &lt;td&gt;8.2&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td nowrap align="left"&gt;Mini-Omni&lt;/td&gt; 
     &lt;td&gt;1B&lt;/td&gt; 
     &lt;td&gt;22.0&lt;/td&gt; 
     &lt;td&gt;12.8&lt;/td&gt; 
     &lt;td&gt;6.9&lt;/td&gt; 
     &lt;td&gt;2.5&lt;/td&gt; 
     &lt;td&gt;926&lt;/td&gt; 
     &lt;td&gt;803&lt;/td&gt; 
     &lt;td&gt;865&lt;/td&gt; 
     &lt;td&gt;3.4&lt;/td&gt; 
     &lt;td&gt;10.0&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td nowrap align="left"&gt;MiniCPM-o 2.6&lt;/td&gt; 
     &lt;td&gt;8B&lt;/td&gt; 
     &lt;td&gt;&lt;u&gt;61.0&lt;/u&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;u&gt;40.0&lt;/u&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;u&gt;40.2&lt;/u&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;u&gt;5.1&lt;/u&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;u&gt;1088&lt;/u&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;u&gt;1163&lt;/u&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;u&gt;1131&lt;/u&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;strong&gt;4.2&lt;/strong&gt;&lt;/td&gt; 
     &lt;td&gt;9.8&lt;/td&gt; 
    &lt;/tr&gt; 
   &lt;/tbody&gt; 
  &lt;/table&gt; 
 &lt;/div&gt; All results are from AudioEvals, and the evaluation methods along with further details can be found in 
 &lt;a href="https://github.com/OpenBMB/UltraEval-Audio" target="_blank"&gt;AudioEvals&lt;/a&gt;.
 &lt;br /&gt;
 &lt;br /&gt; 
 &lt;p&gt;&lt;strong&gt;End-to-end Voice Cloning&lt;/strong&gt;&lt;/p&gt; 
 &lt;div align="center"&gt; 
  &lt;table style="margin: 0px auto;"&gt; 
   &lt;thead&gt; 
    &lt;tr&gt; 
     &lt;th align="left"&gt;Task&lt;/th&gt; 
     &lt;th colspan="2"&gt;Voice cloning&lt;/th&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;th align="left"&gt;Metric&lt;/th&gt; 
     &lt;th&gt;SIMO↑&lt;/th&gt; 
     &lt;th&gt;SIMO↑&lt;/th&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;th align="left"&gt;Dataset&lt;/th&gt; 
     &lt;th&gt;Seed-TTS test-zh&lt;/th&gt; 
     &lt;th&gt;Seed-TTS test-en&lt;/th&gt; 
    &lt;/tr&gt; 
   &lt;/thead&gt; 
   &lt;tbody align="center"&gt; 
    &lt;tr&gt; 
     &lt;td nowrap align="left"&gt;F5-TTS&lt;/td&gt; 
     &lt;td&gt;&lt;strong&gt;76&lt;/strong&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;strong&gt;67&lt;/strong&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td nowrap align="left"&gt;CosyVoice&lt;/td&gt; 
     &lt;td&gt;&lt;u&gt;75&lt;/u&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;u&gt;64&lt;/u&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td nowrap align="left"&gt;FireRedTTS&lt;/td&gt; 
     &lt;td&gt;63&lt;/td&gt; 
     &lt;td&gt;46&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td nowrap align="left"&gt;MiniCPM-o 2.6&lt;/td&gt; 
     &lt;td&gt;57&lt;/td&gt; 
     &lt;td&gt;47&lt;/td&gt; 
    &lt;/tr&gt; 
   &lt;/tbody&gt; 
  &lt;/table&gt; 
 &lt;/div&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Click to view multimodal live streaming results.&lt;/summary&gt; 
 &lt;p&gt;&lt;strong&gt;Multimodal Live Streaming&lt;/strong&gt;: results on StreamingBench&lt;/p&gt; 
 &lt;table style="margin: 0px auto;"&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th align="left"&gt;Model&lt;/th&gt; 
    &lt;th&gt;Size&lt;/th&gt; 
    &lt;th&gt;Real-Time Video Understanding&lt;/th&gt; 
    &lt;th&gt;Omni-Source Understanding&lt;/th&gt; 
    &lt;th&gt;Contextual Understanding&lt;/th&gt; 
    &lt;th&gt;Overall&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody align="center"&gt; 
   &lt;tr&gt; 
    &lt;td colspan="7" align="left"&gt;&lt;strong&gt;Proprietary&lt;/strong&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td nowrap align="left"&gt;Gemini 1.5 Pro&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;&lt;u&gt;77.4&lt;/u&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;strong&gt;67.8&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;strong&gt;51.1&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;strong&gt;70.3&lt;/strong&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td nowrap align="left"&gt;GPT-4o-202408&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;74.5&lt;/td&gt; 
    &lt;td&gt;51.0&lt;/td&gt; 
    &lt;td&gt;&lt;u&gt;48.0&lt;/u&gt;&lt;/td&gt; 
    &lt;td&gt;64.1&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td nowrap align="left"&gt;Claude-3.5-Sonnet&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;74.0&lt;/td&gt; 
    &lt;td&gt;41.4&lt;/td&gt; 
    &lt;td&gt;37.8&lt;/td&gt; 
    &lt;td&gt;59.7&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td colspan="9" align="left"&gt;&lt;strong&gt;Open-source&lt;/strong&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td nowrap align="left"&gt;VILA-1.5&lt;/td&gt; 
    &lt;td&gt;8B&lt;/td&gt; 
    &lt;td&gt;61.5&lt;/td&gt; 
    &lt;td&gt;37.5&lt;/td&gt; 
    &lt;td&gt;26.7&lt;/td&gt; 
    &lt;td&gt;49.5&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td nowrap align="left"&gt;LongVA&lt;/td&gt; 
    &lt;td&gt;7B&lt;/td&gt; 
    &lt;td&gt;63.1&lt;/td&gt; 
    &lt;td&gt;35.9&lt;/td&gt; 
    &lt;td&gt;30.2&lt;/td&gt; 
    &lt;td&gt;50.7&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td nowrap align="left"&gt;LLaVA-Next-Video-34B&lt;/td&gt; 
    &lt;td&gt;34B&lt;/td&gt; 
    &lt;td&gt;69.8&lt;/td&gt; 
    &lt;td&gt;41.7&lt;/td&gt; 
    &lt;td&gt;34.3&lt;/td&gt; 
    &lt;td&gt;56.7&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td nowrap align="left"&gt;Qwen2-VL-7B&lt;/td&gt; 
    &lt;td&gt;8B&lt;/td&gt; 
    &lt;td&gt;71.2&lt;/td&gt; 
    &lt;td&gt;40.7&lt;/td&gt; 
    &lt;td&gt;33.1&lt;/td&gt; 
    &lt;td&gt;57.0&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td nowrap align="left"&gt;InternVL2-8B&lt;/td&gt; 
    &lt;td&gt;8B&lt;/td&gt; 
    &lt;td&gt;70.1&lt;/td&gt; 
    &lt;td&gt;42.7&lt;/td&gt; 
    &lt;td&gt;34.1&lt;/td&gt; 
    &lt;td&gt;57.0&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td nowrap align="left"&gt;VITA-1.5&lt;/td&gt; 
    &lt;td&gt;8B&lt;/td&gt; 
    &lt;td&gt;70.9&lt;/td&gt; 
    &lt;td&gt;40.8&lt;/td&gt; 
    &lt;td&gt;35.8&lt;/td&gt; 
    &lt;td&gt;57.4&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td nowrap align="left"&gt;LLaVA-OneVision-7B&lt;/td&gt; 
    &lt;td&gt;8B&lt;/td&gt; 
    &lt;td&gt;74.3&lt;/td&gt; 
    &lt;td&gt;40.8&lt;/td&gt; 
    &lt;td&gt;31.0&lt;/td&gt; 
    &lt;td&gt;58.4&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td nowrap align="left"&gt;InternLM-XC2.5-OL-7B&lt;/td&gt; 
    &lt;td&gt;8B&lt;/td&gt; 
    &lt;td&gt;75.4&lt;/td&gt; 
    &lt;td&gt;46.2&lt;/td&gt; 
    &lt;td&gt;33.6&lt;/td&gt; 
    &lt;td&gt;60.8&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td nowrap align="left"&gt;MiniCPM-V 2.6&lt;/td&gt; 
    &lt;td&gt;8B&lt;/td&gt; 
    &lt;td&gt;72.4&lt;/td&gt; 
    &lt;td&gt;40.2&lt;/td&gt; 
    &lt;td&gt;33.4&lt;/td&gt; 
    &lt;td&gt;57.7&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td nowrap align="left"&gt;MiniCPM-o 2.6&lt;/td&gt; 
    &lt;td&gt;8B&lt;/td&gt; 
    &lt;td&gt;&lt;strong&gt;79.9&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;u&gt;53.4&lt;/u&gt;&lt;/td&gt; 
    &lt;td&gt;38.5&lt;/td&gt; 
    &lt;td&gt;&lt;u&gt;66.0&lt;/u&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/details&gt; 
&lt;h3&gt;Examples 
 &lt;!-- omit in toc --&gt;&lt;/h3&gt; 
&lt;p&gt;We deploy MiniCPM-o 2.6 on end devices. The demo video is the raw-speed recording on an iPad Pro and a Web demo.&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://www.youtube.com/watch?v=vRIMbxJzStY&amp;amp;t=2s"&gt;&lt;img src="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/assets/minicpmo2_6/2dot6_o_demo_video_img.png" , width="70%" /&gt;&lt;/a&gt; 
&lt;/div&gt; 
&lt;br /&gt; 
&lt;div style="display: flex; flex-direction: column; align-items: center;"&gt; 
 &lt;img src="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/assets/minicpmo2_6/minicpmo2_6_math_intersect.png" alt="math" style="margin-bottom: 5px;" /&gt; 
 &lt;img src="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/assets/minicpmo2_6/minicpmo2_6_diagram_train_NN.png" alt="diagram" style="margin-bottom: 5px;" /&gt; 
 &lt;img src="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/assets/minicpmo2_6/minicpmo2_6_multi-image_bike.png" alt="bike" style="margin-bottom: 5px;" /&gt; 
&lt;/div&gt; 
&lt;h2&gt;Legacy Models 
 &lt;!-- omit in toc --&gt;&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Model&lt;/th&gt; 
   &lt;th align="center"&gt;Introduction and Guidance&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;MiniCPM-V 4.0&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/docs/minicpm_v4_en.md"&gt;Document&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;MiniCPM-V 2.6&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/docs/minicpm_v2dot6_en.md"&gt;Document&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;MiniCPM-Llama3-V 2.5&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/docs/minicpm_llama3_v2dot5.md"&gt;Document&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;MiniCPM-V 2.0&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/docs/minicpm_v2.md"&gt;Document&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;MiniCPM-V 1.0&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/docs/minicpm_v1.md"&gt;Document&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;OmniLMM-12B&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/docs/omnilmm_en.md"&gt;Document&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;MiniCPM-V &amp;amp; o Cookbook&lt;/h2&gt; 
&lt;p&gt;Discover comprehensive, ready-to-deploy solutions for the MiniCPM-V and MiniCPM-o model series in our structured &lt;a href="https://github.com/OpenSQZ/MiniCPM-V-CookBook"&gt;cookbook&lt;/a&gt;, which empowers developers to rapidly implement multimodal AI applications with integrated vision, speech, and live-streaming capabilities. Key features include:&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Easy Usage Documentation&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Our comprehensive &lt;a href="https://minicpm-o.readthedocs.io/en/latest/index.html"&gt;documentation website&lt;/a&gt; presents every recipe in a clear, well-organized manner. All features are displayed at a glance, making it easy for you to quickly find exactly what you need.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Broad User Spectrum&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;We support a wide range of users, from individuals to enterprises and researchers.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Individuals&lt;/strong&gt;: Enjoy effortless inference using &lt;a href="https://github.com/OpenSQZ/MiniCPM-V-CookBook/raw/main/deployment/ollama/minicpm-v4_ollama.md"&gt;Ollama&lt;/a&gt; and &lt;a href="https://github.com/OpenSQZ/MiniCPM-V-CookBook/raw/main/deployment/llama.cpp/minicpm-v4_llamacpp.md"&gt;Llama.cpp&lt;/a&gt; with minimal setup.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Enterprises&lt;/strong&gt;: Achieve high-throughput, scalable performance with &lt;a href="https://github.com/OpenSQZ/MiniCPM-V-CookBook/raw/main/deployment/vllm/minicpm-v4_vllm.md"&gt;vLLM&lt;/a&gt; and &lt;a href="https://github.com/OpenSQZ/MiniCPM-V-CookBook/raw/main/deployment/sglang/MiniCPM-v4_sglang.md"&gt;SGLang&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Researchers&lt;/strong&gt;: Leverage advanced frameworks including &lt;a href="https://github.com/OpenSQZ/MiniCPM-V-CookBook/raw/main/finetune/finetune_full.md"&gt;Transformers&lt;/a&gt;, &lt;a href="https://github.com/OpenSQZ/MiniCPM-V-CookBook/raw/main/finetune/finetune_llamafactory.md"&gt;LLaMA-Factory&lt;/a&gt;, &lt;a href="https://github.com/OpenSQZ/MiniCPM-V-CookBook/raw/main/finetune/swift.md"&gt;SWIFT&lt;/a&gt;, and &lt;a href="https://github.com/OpenSQZ/MiniCPM-V-CookBook/raw/main/finetune/align_anything.md"&gt;Align-anything&lt;/a&gt; to enable flexible model development and cutting-edge experimentation.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Versatile Deployment Scenarios&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Our ecosystem delivers optimal solution for a variety of hardware environments and deployment demands.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Web demo&lt;/strong&gt;: Launch interactive multimodal AI web demo with &lt;a href="https://github.com/OpenSQZ/MiniCPM-V-CookBook/raw/main/demo/README.md"&gt;FastAPI&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Quantized deployment&lt;/strong&gt;: Maximize efficiency and minimize resource consumption using &lt;a href="https://github.com/OpenSQZ/MiniCPM-V-CookBook/raw/main/quantization/gguf/minicpm-v4_gguf_quantize.md"&gt;GGUF&lt;/a&gt; and &lt;a href="https://github.com/OpenSQZ/MiniCPM-V-CookBook/raw/main/quantization/bnb/minicpm-v4_bnb_quantize.md"&gt;BNB&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;End devices&lt;/strong&gt;: Bring powerful AI experiences to &lt;a href="https://github.com/OpenSQZ/MiniCPM-V-CookBook/raw/main/demo/ios_demo/ios.md"&gt;iPhone and iPad&lt;/a&gt;, supporting offline and privacy-sensitive applications.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Chat with Our Demo on Gradio 🤗&lt;/h2&gt; 
&lt;p&gt;We provide online and local demos powered by Hugging Face Gradio &lt;a href="https://github.com/gradio-app/gradio"&gt;&lt;img src="https://img.shields.io/github/stars/gradio-app/gradio" /&gt;&lt;/a&gt;, the most popular model deployment framework nowadays. It supports streaming outputs, progress bars, queuing, alerts, and other useful features.&lt;/p&gt; 
&lt;h3&gt;Online Demo 
 &lt;!-- omit in toc --&gt;&lt;/h3&gt; 
&lt;p&gt;Click here to try out the online demo of &lt;a href="https://minicpm-omni-webdemo-us.modelbest.cn/"&gt;MiniCPM-o 2.6&lt;/a&gt; | &lt;a href="http://120.92.209.146:8887/"&gt;MiniCPM-V 2.6&lt;/a&gt; | &lt;a href="https://huggingface.co/spaces/openbmb/MiniCPM-Llama3-V-2_5"&gt;MiniCPM-Llama3-V 2.5&lt;/a&gt; | &lt;a href="https://huggingface.co/spaces/openbmb/MiniCPM-V-2"&gt;MiniCPM-V 2.0&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Local WebUI Demo 
 &lt;!-- omit in toc --&gt;&lt;/h3&gt; 
&lt;p&gt;You can easily build your own local WebUI demo using the following commands.&lt;/p&gt; 
&lt;p&gt;Please ensure that &lt;code&gt;transformers==4.44.2&lt;/code&gt; is installed, as other versions may have compatibility issues.&lt;/p&gt; 
&lt;p&gt;If you are using an older version of PyTorch, you might encounter this issue &lt;code&gt;"weight_norm_fwd_first_dim_kernel" not implemented for 'BFloat16'&lt;/code&gt;, Please add &lt;code&gt;self.minicpmo_model.tts.float()&lt;/code&gt; during the model initialization.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;For real-time voice/video call demo:&lt;/strong&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;launch model server:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;pip install -r requirements_o2.6.txt

python web_demos/minicpm-o_2.6/model_server.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;launch web server:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;# Make sure Node and PNPM is installed.
sudo apt-get update
sudo apt-get install nodejs npm
npm install -g pnpm


cd web_demos/minicpm-o_2.6/web_server
# create ssl cert for https, https is required to request camera and microphone permissions.
bash ./make_ssl_cert.sh  # output key.pem and cert.pem

pnpm install  # install requirements
pnpm run dev  # start server
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Open &lt;code&gt;https://localhost:8088/&lt;/code&gt; in browser and enjoy the real-time voice/video call.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;For chatbot demo:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;pip install -r requirements_o2.6.txt

python web_demos/minicpm-o_2.6/chatbot_web_demo_o2.6.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Open &lt;code&gt;http://localhost:8000/&lt;/code&gt; in browser and enjoy the vision mode chatbot.&lt;/p&gt; 
&lt;h2&gt;Inference&lt;/h2&gt; 
&lt;h3&gt;Model Zoo&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Model&lt;/th&gt; 
   &lt;th align="center"&gt;Device&lt;/th&gt; 
   &lt;th align="center"&gt;Memory&lt;/th&gt; 
   &lt;th align="left"&gt;         Description&lt;/th&gt; 
   &lt;th align="center"&gt;Download&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;MiniCPM-V 4.5&lt;/td&gt; 
   &lt;td align="center"&gt;GPU&lt;/td&gt; 
   &lt;td align="center"&gt;18 GB&lt;/td&gt; 
   &lt;td align="left"&gt;The latest version, strong end-side multimodal performance for single image, multi-image and video understanding.&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://huggingface.co/openbmb/MiniCPM-V-4_5"&gt;🤗&lt;/a&gt; &amp;nbsp;&amp;nbsp; &lt;a href="https://modelscope.cn/models/OpenBMB/MiniCPM-V-4_5"&gt;&lt;img src="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/assets/modelscope_logo.png" width="20px" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;MiniCPM-V 4.5 gguf&lt;/td&gt; 
   &lt;td align="center"&gt;CPU&lt;/td&gt; 
   &lt;td align="center"&gt;8 GB&lt;/td&gt; 
   &lt;td align="left"&gt;The gguf version, lower memory usage and faster inference.&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://huggingface.co/openbmb/MiniCPM-V-4_5-gguf"&gt;🤗&lt;/a&gt; &amp;nbsp;&amp;nbsp; &lt;a href="https://modelscope.cn/models/OpenBMB/MiniCPM-V-4_5-gguf"&gt;&lt;img src="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/assets/modelscope_logo.png" width="20px" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;MiniCPM-V 4.5 int4&lt;/td&gt; 
   &lt;td align="center"&gt;GPU&lt;/td&gt; 
   &lt;td align="center"&gt;9 GB&lt;/td&gt; 
   &lt;td align="left"&gt;The int4 quantized version, lower GPU memory usage.&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://huggingface.co/openbmb/MiniCPM-V-4_5-int4"&gt;🤗&lt;/a&gt; &amp;nbsp;&amp;nbsp; &lt;a href="https://modelscope.cn/models/OpenBMB/MiniCPM-V-4_5-int4"&gt;&lt;img src="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/assets/modelscope_logo.png" width="20px" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;MiniCPM-V 4.5 AWQ&lt;/td&gt; 
   &lt;td align="center"&gt;GPU&lt;/td&gt; 
   &lt;td align="center"&gt;9 GB&lt;/td&gt; 
   &lt;td align="left"&gt;The int4 quantized version, lower GPU memory usage.&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://huggingface.co/openbmb/MiniCPM-V-4_5-AWQ"&gt;🤗&lt;/a&gt; &amp;nbsp;&amp;nbsp; &lt;a href="https://modelscope.cn/models/OpenBMB/MiniCPM-V-4_5-AWQ"&gt;&lt;img src="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/assets/modelscope_logo.png" width="20px" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;MiniCPM-o 2.6&lt;/td&gt; 
   &lt;td align="center"&gt;GPU&lt;/td&gt; 
   &lt;td align="center"&gt;18 GB&lt;/td&gt; 
   &lt;td align="left"&gt;The latest version, achieving GPT-4o level performance for vision, speech and multimodal live streaming on end-side devices.&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://huggingface.co/openbmb/MiniCPM-o-2_6"&gt;🤗&lt;/a&gt; &amp;nbsp;&amp;nbsp; &lt;a href="https://modelscope.cn/models/OpenBMB/MiniCPM-o-2_6"&gt;&lt;img src="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/assets/modelscope_logo.png" width="20px" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;MiniCPM-o 2.6 gguf&lt;/td&gt; 
   &lt;td align="center"&gt;CPU&lt;/td&gt; 
   &lt;td align="center"&gt;8 GB&lt;/td&gt; 
   &lt;td align="left"&gt;The gguf version, lower memory usage and faster inference.&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://huggingface.co/openbmb/MiniCPM-o-2_6-gguf"&gt;🤗&lt;/a&gt; &amp;nbsp;&amp;nbsp; &lt;a href="https://modelscope.cn/models/OpenBMB/MiniCPM-o-2_6-gguf"&gt;&lt;img src="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/assets/modelscope_logo.png" width="20px" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;MiniCPM-o 2.6 int4&lt;/td&gt; 
   &lt;td align="center"&gt;GPU&lt;/td&gt; 
   &lt;td align="center"&gt;9 GB&lt;/td&gt; 
   &lt;td align="left"&gt;The int4 quantized version, lower GPU memory usage.&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://huggingface.co/openbmb/MiniCPM-o-2_6-int4"&gt;🤗&lt;/a&gt; &amp;nbsp;&amp;nbsp; &lt;a href="https://modelscope.cn/models/OpenBMB/MiniCPM-o-2_6-int4"&gt;&lt;img src="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/assets/modelscope_logo.png" width="20px" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Multi-turn Conversation&lt;/h3&gt; 
&lt;p&gt;If you wish to enable long-thinking mode, provide the argument &lt;code&gt;enable_thinking=True&lt;/code&gt; to the chat function.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;pip install -r requirements_o2.6.txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Please refer to the following codes to run.&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/assets/minicpmo2_6/show_demo.jpg" width="500px" /&gt; 
&lt;/div&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import torch
from PIL import Image
from transformers import AutoModel, AutoTokenizer

torch.manual_seed(100)

model = AutoModel.from_pretrained('openbmb/MiniCPM-V-4_5', trust_remote_code=True, # or openbmb/MiniCPM-o-2_6
    attn_implementation='sdpa', torch_dtype=torch.bfloat16) # sdpa or flash_attention_2, no eager
model = model.eval().cuda()
tokenizer = AutoTokenizer.from_pretrained('openbmb/MiniCPM-V-4_5', trust_remote_code=True) # or openbmb/MiniCPM-o-2_6

image = Image.open('./assets/minicpmo2_6/show_demo.jpg').convert('RGB')

enable_thinking=False # If `enable_thinking=True`, the long-thinking mode is enabled.

# First round chat 
question = "What is the landform in the picture?"
msgs = [{'role': 'user', 'content': [image, question]}]

answer = model.chat(
    msgs=msgs,
    tokenizer=tokenizer,
    enable_thinking=enable_thinking
)
print(answer)

# Second round chat, pass history context of multi-turn conversation
msgs.append({"role": "assistant", "content": [answer]})
msgs.append({"role": "user", "content": ["What should I pay attention to when traveling here?"]})

answer = model.chat(
    msgs=msgs,
    tokenizer=tokenizer
)
print(answer)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You will get the following output:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;# round1
The landform in the picture is karst topography. Karst landscapes are characterized by distinctive, jagged limestone hills or mountains with steep, irregular peaks and deep valleys—exactly what you see here These unique formations result from the dissolution of soluble rocks like limestone over millions of years through water erosion.

This scene closely resembles the famous karst landscape of Guilin and Yangshuo in China’s Guangxi Province. The area features dramatic, pointed limestone peaks rising dramatically above serene rivers and lush green forests, creating a breathtaking and iconic natural beauty that attracts millions of visitors each year for its picturesque views.

# round2
When traveling to a karst landscape like this, here are some important tips:

1. Wear comfortable shoes: The terrain can be uneven and hilly.
2. Bring water and snacks for energy during hikes or boat rides.
3. Protect yourself from the sun with sunscreen, hats, and sunglasses—especially since you’ll likely spend time outdoors exploring scenic spots.
4. Respect local customs and nature regulations by not littering or disturbing wildlife.

By following these guidelines, you'll have a safe and enjoyable trip while appreciating the stunning natural beauty of places such as Guilin’s karst mountains.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Chat with Multiple Images&lt;/h4&gt; 
&lt;details&gt; 
 &lt;summary&gt; Click to view Python code running MiniCPM-V-4_5 with multiple images input. &lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;import torch
from PIL import Image
from transformers import AutoModel, AutoTokenizer

model = AutoModel.from_pretrained('openbmb/MiniCPM-V-4_5', trust_remote_code=True,  # or openbmb/MiniCPM-o-2_6
    attn_implementation='sdpa', torch_dtype=torch.bfloat16) # sdpa or flash_attention_2, no eager
model = model.eval().cuda()
tokenizer = AutoTokenizer.from_pretrained('openbmb/MiniCPM-V-4_5', trust_remote_code=True)  # or openbmb/MiniCPM-o-2_6

image1 = Image.open('image1.jpg').convert('RGB')
image2 = Image.open('image2.jpg').convert('RGB')
question = 'Compare image 1 and image 2, tell me about the differences between image 1 and image 2.'

msgs = [{'role': 'user', 'content': [image1, image2, question]}]

answer = model.chat(
    msgs=msgs,
    tokenizer=tokenizer
)
print(answer)
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h4&gt;In-context Few-shot Learning&lt;/h4&gt; 
&lt;details&gt; 
 &lt;summary&gt; Click to view Python code running MiniCPM-V-4_5 with few-shot input. &lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;import torch
from PIL import Image
from transformers import AutoModel, AutoTokenizer

model = AutoModel.from_pretrained('openbmb/MiniCPM-V-4_5', trust_remote_code=True,  # or openbmb/MiniCPM-o-2_6
    attn_implementation='sdpa', torch_dtype=torch.bfloat16) # sdpa or flash_attention_2, no eager
model = model.eval().cuda()
tokenizer = AutoTokenizer.from_pretrained('openbmb/MiniCPM-V-4_5', trust_remote_code=True)  # or openbmb/MiniCPM-o-2_6

question = "production date" 
image1 = Image.open('example1.jpg').convert('RGB')
answer1 = "2023.08.04"
image2 = Image.open('example2.jpg').convert('RGB')
answer2 = "2007.04.24"
image_test = Image.open('test.jpg').convert('RGB')

msgs = [
    {'role': 'user', 'content': [image1, question]}, {'role': 'assistant', 'content': [answer1]},
    {'role': 'user', 'content': [image2, question]}, {'role': 'assistant', 'content': [answer2]},
    {'role': 'user', 'content': [image_test, question]}
]

answer = model.chat(
    msgs=msgs,
    tokenizer=tokenizer
)
print(answer)
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h4&gt;Chat with Video&lt;/h4&gt; 
&lt;details&gt; 
 &lt;summary&gt; Click to view Python code running MiniCPM-V-4_5 by with video input and 3D-Resampler. &lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;## The 3d-resampler compresses multiple frames into 64 tokens by introducing temporal_ids. 
# To achieve this, you need to organize your video data into two corresponding sequences: 
#   frames: List[Image]
#   temporal_ids: List[List[Int]].

import torch
from PIL import Image
from transformers import AutoModel, AutoTokenizer
from decord import VideoReader, cpu    # pip install decord
from scipy.spatial import cKDTree
import numpy as np
import math

model = AutoModel.from_pretrained('openbmb/MiniCPM-V-4_5', trust_remote_code=True,  # or openbmb/MiniCPM-o-2_6
    attn_implementation='sdpa', torch_dtype=torch.bfloat16) # sdpa or flash_attention_2, no eager
model = model.eval().cuda()
tokenizer = AutoTokenizer.from_pretrained('openbmb/MiniCPM-V-4_5', trust_remote_code=True)  # or openbmb/MiniCPM-o-2_6

MAX_NUM_FRAMES=180 # Indicates the maximum number of frames received after the videos are packed. The actual maximum number of valid frames is MAX_NUM_FRAMES * MAX_NUM_PACKING.
MAX_NUM_PACKING=3  # indicates the maximum packing number of video frames. valid range: 1-6
TIME_SCALE = 0.1 

def map_to_nearest_scale(values, scale):
    tree = cKDTree(np.asarray(scale)[:, None])
    _, indices = tree.query(np.asarray(values)[:, None])
    return np.asarray(scale)[indices]


def group_array(arr, size):
    return [arr[i:i+size] for i in range(0, len(arr), size)]

def encode_video(video_path, choose_fps=3, force_packing=None):
    def uniform_sample(l, n):
        gap = len(l) / n
        idxs = [int(i * gap + gap / 2) for i in range(n)]
        return [l[i] for i in idxs]
    vr = VideoReader(video_path, ctx=cpu(0))
    fps = vr.get_avg_fps()
    video_duration = len(vr) / fps
        
    if choose_fps * int(video_duration) &amp;lt;= MAX_NUM_FRAMES:
        packing_nums = 1
        choose_frames = round(min(choose_fps, round(fps)) * min(MAX_NUM_FRAMES, video_duration))
        
    else:
        packing_nums = math.ceil(video_duration * choose_fps / MAX_NUM_FRAMES)
        if packing_nums &amp;lt;= MAX_NUM_PACKING:
            choose_frames = round(video_duration * choose_fps)
        else:
            choose_frames = round(MAX_NUM_FRAMES * MAX_NUM_PACKING)
            packing_nums = MAX_NUM_PACKING

    frame_idx = [i for i in range(0, len(vr))]      
    frame_idx =  np.array(uniform_sample(frame_idx, choose_frames))

    if force_packing:
        packing_nums = min(force_packing, MAX_NUM_PACKING)
    
    print(video_path, ' duration:', video_duration)
    print(f'get video frames={len(frame_idx)}, packing_nums={packing_nums}')
    
    frames = vr.get_batch(frame_idx).asnumpy()

    frame_idx_ts = frame_idx / fps
    scale = np.arange(0, video_duration, TIME_SCALE)

    frame_ts_id = map_to_nearest_scale(frame_idx_ts, scale) / TIME_SCALE
    frame_ts_id = frame_ts_id.astype(np.int32)

    assert len(frames) == len(frame_ts_id)

    frames = [Image.fromarray(v.astype('uint8')).convert('RGB') for v in frames]
    frame_ts_id_group = group_array(frame_ts_id, packing_nums)
    
    return frames, frame_ts_id_group


video_path="video_test.mp4"
fps = 5 # fps for video
force_packing = None # You can set force_packing to ensure that 3D packing is forcibly enabled; otherwise, encode_video will dynamically set the packing quantity based on the duration.
frames, frame_ts_id_group = encode_video(video_path, fps, force_packing=force_packing)

question = "Describe the video"
msgs = [
    {'role': 'user', 'content': frames + [question]}, 
]


answer = model.chat(
    msgs=msgs,
    tokenizer=tokenizer,
    use_image_id=False,
    max_slice_nums=1,
    temporal_ids=frame_ts_id_group
)
print(answer)
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h4&gt;Speech and Audio Mode&lt;/h4&gt; 
&lt;p&gt;Model initialization&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import torch
import librosa
from transformers import AutoModel, AutoTokenizer

model = AutoModel.from_pretrained('openbmb/MiniCPM-o-2_6', trust_remote_code=True,
    attn_implementation='sdpa', torch_dtype=torch.bfloat16) # sdpa or flash_attention_2, no eager
model = model.eval().cuda()
tokenizer = AutoTokenizer.from_pretrained('openbmb/MiniCPM-o-2_6', trust_remote_code=True)

model.init_tts()
model.tts.float()
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h5&gt;Mimick 
 &lt;!-- omit in toc --&gt;&lt;/h5&gt; 
&lt;p&gt;&lt;code&gt;Mimick&lt;/code&gt; task reflects a model's end-to-end speech modeling capability. The model takes audio input, and outputs an ASR transcription and subsequently reconstructs the original audio with high similarity. The higher the similarity between the reconstructed audio and the original audio, the stronger the model's foundational capability in end-to-end speech modeling.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;mimick_prompt = "Please repeat each user's speech, including voice style and speech content."
audio_input, _ = librosa.load('./assets/input_examples/Trump_WEF_2018_10s.mp3', sr=16000, mono=True) # load the audio to be mimicked

# `./assets/input_examples/fast-pace.wav`, 
# `./assets/input_examples/chi-english-1.wav` 
# `./assets/input_examples/exciting-emotion.wav` 
# for different aspects of speech-centric features.

msgs = [{'role': 'user', 'content': [mimick_prompt, audio_input]}]
res = model.chat(
    msgs=msgs,
    tokenizer=tokenizer,
    sampling=True,
    max_new_tokens=128,
    use_tts_template=True,
    temperature=0.3,
    generate_audio=True,
    output_audio_path='output_mimick.wav', # save the tts result to output_audio_path
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h5&gt;General Speech Conversation with Configurable Voices 
 &lt;!-- omit in toc --&gt;&lt;/h5&gt; 
&lt;p&gt;A general usage scenario of &lt;code&gt;MiniCPM-o-2.6&lt;/code&gt; is role-playing a specific character based on the audio prompt. It will mimic the voice of the character to some extent and act like the character in text, including language style. In this mode, &lt;code&gt;MiniCPM-o-2.6&lt;/code&gt; sounds &lt;strong&gt;more natural and human-like&lt;/strong&gt;. Self-defined audio prompts can be used to customize the voice of the character in an end-to-end manner.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;ref_audio, _ = librosa.load('./assets/input_examples/icl_20.wav', sr=16000, mono=True) # load the reference audio
sys_prompt = model.get_sys_prompt(ref_audio=ref_audio, mode='audio_roleplay', language='en')

# round one
user_question = {'role': 'user', 'content': [librosa.load('xxx.wav', sr=16000, mono=True)[0]]}
msgs = [sys_prompt, user_question]
res = model.chat(
    msgs=msgs,
    tokenizer=tokenizer,
    sampling=True,
    max_new_tokens=128,
    use_tts_template=True,
    generate_audio=True,
    temperature=0.3,
    output_audio_path='result_roleplay_round_1.wav',
)

# round two
history = msgs.append({'role': 'assistant', 'content': res})
user_question = {'role': 'user', 'content': [librosa.load('xxx.wav', sr=16000, mono=True)[0]]}
msgs = history.append(user_question)
res = model.chat(
    msgs=msgs,
    tokenizer=tokenizer,
    sampling=True,
    max_new_tokens=128,
    use_tts_template=True,
    generate_audio=True,
    temperature=0.3,
    output_audio_path='result_roleplay_round_2.wav',
)
print(res)
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h5&gt;Speech Conversation as an AI Assistant 
 &lt;!-- omit in toc --&gt;&lt;/h5&gt; 
&lt;p&gt;An enhanced feature of &lt;code&gt;MiniCPM-o-2.6&lt;/code&gt; is to act as an AI assistant, but only with limited choice of voices. In this mode, &lt;code&gt;MiniCPM-o-2.6&lt;/code&gt; is &lt;strong&gt;less human-like and more like a voice assistant&lt;/strong&gt;. In this mode, the model is more instruction-following. For demo, you are suggested to use &lt;code&gt;assistant_female_voice&lt;/code&gt;, &lt;code&gt;assistant_male_voice&lt;/code&gt;, and &lt;code&gt;assistant_default_female_voice&lt;/code&gt;. Other voices may work but not as stable as the default voices.&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;Please note that, &lt;code&gt;assistant_female_voice&lt;/code&gt; and &lt;code&gt;assistant_male_voice&lt;/code&gt; are more stable but sounds like robots, while &lt;code&gt;assistant_default_female_voice&lt;/code&gt; is more human-alike but not stable, its voice often changes in multiple turns. We suggest you to try stable voices &lt;code&gt;assistant_female_voice&lt;/code&gt; and &lt;code&gt;assistant_male_voice&lt;/code&gt;.&lt;/em&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;ref_audio, _ = librosa.load('./assets/input_examples/assistant_female_voice.wav', sr=16000, mono=True) # or use `./assets/input_examples/assistant_male_voice.wav`
sys_prompt = model.get_sys_prompt(ref_audio=ref_audio, mode='audio_assistant', language='en') 
user_question = {'role': 'user', 'content': [librosa.load('xxx.wav', sr=16000, mono=True)[0]]} # load the user's audio question

# round one
msgs = [sys_prompt, user_question]
res = model.chat(
    msgs=msgs,
    tokenizer=tokenizer,
    sampling=True,
    max_new_tokens=128,
    use_tts_template=True,
    generate_audio=True,
    temperature=0.3,
    output_audio_path='result_assistant_round_1.wav',
)

# round two
history = msgs.append({'role': 'assistant', 'content': res})
user_question = {'role': 'user', 'content': [librosa.load('xxx.wav', sr=16000, mono=True)[0]]}
msgs = history.append(user_question)
res = model.chat(
    msgs=msgs,
    tokenizer=tokenizer,
    sampling=True,
    max_new_tokens=128,
    use_tts_template=True,
    generate_audio=True,
    temperature=0.3,
    output_audio_path='result_assistant_round_2.wav',
)
print(res)
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h5&gt;Instruction-to-Speech 
 &lt;!-- omit in toc --&gt;&lt;/h5&gt; 
&lt;p&gt;&lt;code&gt;MiniCPM-o-2.6&lt;/code&gt; can also do Instruction-to-Speech, aka &lt;strong&gt;Voice Creation&lt;/strong&gt;. You can describe a voice in detail, and the model will generate a voice that matches the description. For more Instruction-to-Speech sample instructions, you can refer to &lt;a href="https://voxinstruct.github.io/VoxInstruct/"&gt;https://voxinstruct.github.io/VoxInstruct/&lt;/a&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;instruction = 'Speak like a male charming superstar, radiating confidence and style in every word.'

msgs = [{'role': 'user', 'content': [instruction]}]

res = model.chat(
    msgs=msgs,
    tokenizer=tokenizer,
    sampling=True,
    max_new_tokens=128,
    use_tts_template=True,
    generate_audio=True,
    temperature=0.3,
    output_audio_path='result_voice_creation.wav',
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h5&gt;Voice Cloning 
 &lt;!-- omit in toc --&gt;&lt;/h5&gt; 
&lt;p&gt;&lt;code&gt;MiniCPM-o-2.6&lt;/code&gt; can also do zero-shot text-to-speech, aka &lt;strong&gt;Voice Cloning&lt;/strong&gt;. With this mode, model will act like a TTS model.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;ref_audio, _ = librosa.load('./assets/input_examples/icl_20.wav', sr=16000, mono=True) # load the reference audio
sys_prompt = model.get_sys_prompt(ref_audio=ref_audio, mode='voice_cloning', language='en')
text_prompt = f"Please read the text below."
user_question = {'role': 'user', 'content': [text_prompt, "content that you want to read"]}

msgs = [sys_prompt, user_question]
res = model.chat(
    msgs=msgs,
    tokenizer=tokenizer,
    sampling=True,
    max_new_tokens=128,
    use_tts_template=True,
    generate_audio=True,
    temperature=0.3,
    output_audio_path='result_voice_cloning.wav',
)

&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h5&gt;Addressing Various Audio Understanding Tasks 
 &lt;!-- omit in toc --&gt;&lt;/h5&gt; 
&lt;p&gt;&lt;code&gt;MiniCPM-o-2.6&lt;/code&gt; can also be used to address various audio understanding tasks, such as ASR, speaker analysis, general audio captioning, and sound scene tagging.&lt;/p&gt; 
&lt;p&gt;For audio-to-text tasks, you can use the following prompts:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;ASR with ZH(same as AST en2zh): &lt;code&gt;请仔细听这段音频片段，并将其内容逐字记录。&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;ASR with EN(same as AST zh2en): &lt;code&gt;Please listen to the audio snippet carefully and transcribe the content.&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Speaker Analysis: &lt;code&gt;Based on the speaker's content, speculate on their gender, condition, age range, and health status.&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;General Audio Caption: &lt;code&gt;Summarize the main content of the audio.&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;General Sound Scene Tagging: &lt;code&gt;Utilize one keyword to convey the audio's content or the associated scene.&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;task_prompt = "Please listen to the audio snippet carefully and transcribe the content." + "\n" # can change to other prompts.
audio_input, _ = librosa.load('./assets/input_examples/audio_understanding.mp3', sr=16000, mono=True) # load the audio to be captioned

msgs = [{'role': 'user', 'content': [task_prompt, audio_input]}]

res = model.chat(
    msgs=msgs,
    tokenizer=tokenizer,
    sampling=True,
    max_new_tokens=128,
    use_tts_template=True,
    generate_audio=True,
    temperature=0.3,
    output_audio_path='result_audio_understanding.wav',
)
print(res)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Multimodal Live Streaming&lt;/h4&gt; 
&lt;details&gt; 
 &lt;summary&gt; Click to view Python code running MiniCPM-o 2.6 with chat inference. &lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;import math
import numpy as np
from PIL import Image
from moviepy.editor import VideoFileClip
import tempfile
import librosa
import soundfile as sf
import torch
from transformers import AutoModel, AutoTokenizer

def get_video_chunk_content(video_path, flatten=True):
    video = VideoFileClip(video_path)
    print('video_duration:', video.duration)
    
    with tempfile.NamedTemporaryFile(suffix=".wav", delete=True) as temp_audio_file:
        temp_audio_file_path = temp_audio_file.name
        video.audio.write_audiofile(temp_audio_file_path, codec="pcm_s16le", fps=16000)
        audio_np, sr = librosa.load(temp_audio_file_path, sr=16000, mono=True)
    num_units = math.ceil(video.duration)
    
    # 1 frame + 1s audio chunk
    contents= []
    for i in range(num_units):
        frame = video.get_frame(i+1)
        image = Image.fromarray((frame).astype(np.uint8))
        audio = audio_np[sr*i:sr*(i+1)]
        if flatten:
            contents.extend(["&amp;lt;unit&amp;gt;", image, audio])
        else:
            contents.append(["&amp;lt;unit&amp;gt;", image, audio])
    
    return contents


model = AutoModel.from_pretrained('openbmb/MiniCPM-o-2_6', trust_remote_code=True,
    attn_implementation='sdpa', torch_dtype=torch.bfloat16)
model = model.eval().cuda()
tokenizer = AutoTokenizer.from_pretrained('openbmb/MiniCPM-o-2_6', trust_remote_code=True)

model.init_tts()

# If you are using an older version of PyTorch, you might encounter this issue "weight_norm_fwd_first_dim_kernel" not implemented for 'BFloat16', Please convert the TTS to float32 type.
# model.tts.float()

# https://huggingface.co/openbmb/MiniCPM-o-2_6/blob/main/assets/Skiing.mp4
video_path="assets/Skiing.mp4"
sys_msg = model.get_sys_prompt(mode='omni', language='en')
# if use voice clone prompt, please set ref_audio
# ref_audio_path = '/path/to/ref_audio'
# ref_audio, _ = librosa.load(ref_audio_path, sr=16000, mono=True)
# sys_msg = model.get_sys_prompt(ref_audio=ref_audio, mode='omni', language='en')

contents = get_video_chunk_content(video_path)
msg = {"role":"user", "content": contents}
msgs = [sys_msg, msg]

# please set generate_audio=True and output_audio_path to save the tts result
generate_audio = True
output_audio_path = 'output.wav'

res = model.chat(
    msgs=msgs,
    tokenizer=tokenizer,
    sampling=True,
    temperature=0.5,
    max_new_tokens=4096,
    omni_input=True, # please set omni_input=True when omni inference
    use_tts_template=True,
    generate_audio=generate_audio,
    output_audio_path=output_audio_path,
    max_slice_nums=1,
    use_image_id=False,
    return_dict=True
)
print(res)
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt; Click to view Python code running MiniCPM-o 2.6 with streaming inference. &lt;/summary&gt; 
 &lt;p&gt;Note: The streaming inference has a slight performance degradation because the audio encoding is not global.&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;# a new conversation need reset session first, it will reset the kv-cache
model.reset_session()

contents = get_video_chunk_content(video_path, flatten=False)
session_id = '123'
generate_audio = True

# 1. prefill system prompt
res = model.streaming_prefill(
    session_id=session_id,
    msgs=[sys_msg], 
    tokenizer=tokenizer
)

# 2. prefill video/audio chunks
for content in contents:
    msgs = [{"role":"user", "content": content}]
    res = model.streaming_prefill(
        session_id=session_id,
        msgs=msgs, 
        tokenizer=tokenizer
    )

# 3. generate
res = model.streaming_generate(
    session_id=session_id,
    tokenizer=tokenizer,
    temperature=0.5,
    generate_audio=generate_audio
)

audios = []
text = ""

if generate_audio:
    for r in res:
        audio_wav = r.audio_wav
        sampling_rate = r.sampling_rate
        txt = r.text

        audios.append(audio_wav)
        text += txt
        
    res = np.concatenate(audios)
    sf.write("output.wav", res, samplerate=sampling_rate)
    print("text:", text)
    print("audio saved to output.wav")
else:
    for r in res:
        text += r['text']
    print("text:", text)
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h3&gt;Inference on Multiple GPUs&lt;/h3&gt; 
&lt;p&gt;You can run MiniCPM-Llama3-V 2.5 on multiple low VRAM GPUs (12 GB or 16 GB) by distributing the model's layers across multiple GPUs. Please refer to this &lt;a href="https://github.com/OpenBMB/MiniCPM-V/raw/main/docs/inference_on_multiple_gpus.md"&gt;tutorial&lt;/a&gt; for detailed instructions on how to load the model and inference using multiple low VRAM GPUs.&lt;/p&gt; 
&lt;h3&gt;Inference on Mac&lt;/h3&gt; 
&lt;details&gt; 
 &lt;summary&gt;Click to view an example, to run MiniCPM-Llama3-V 2.5 on 💻 Mac with MPS (Apple silicon or AMD GPUs). &lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;# test.py  Need more than 16GB memory.
import torch
from PIL import Image
from transformers import AutoModel, AutoTokenizer

model = AutoModel.from_pretrained('openbmb/MiniCPM-Llama3-V-2_5', trust_remote_code=True, low_cpu_mem_usage=True)
model = model.to(device='mps')

tokenizer = AutoTokenizer.from_pretrained('openbmb/MiniCPM-Llama3-V-2_5', trust_remote_code=True)
model.eval()

image = Image.open('./assets/hk_OCR.jpg').convert('RGB')
question = 'Where is this photo taken?'
msgs = [{'role': 'user', 'content': question}]

answer, context, _ = model.chat(
    image=image,
    msgs=msgs,
    context=None,
    tokenizer=tokenizer,
    sampling=True
)
print(answer)
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Run with command:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;PYTORCH_ENABLE_MPS_FALLBACK=1 python test.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h3&gt;Efficient Inference with llama.cpp, Ollama, vLLM&lt;/h3&gt; 
&lt;p&gt;See &lt;a href="https://github.com/OpenBMB/llama.cpp/tree/minicpmv-main/examples/llava/README-minicpmv2.6.md"&gt;our fork of llama.cpp&lt;/a&gt; for more detail. This implementation supports smooth inference of 16~18 token/s on iPad (test environment：iPad Pro + M4).&lt;/p&gt; 
&lt;p&gt;See &lt;a href="https://github.com/OpenBMB/ollama/raw/minicpm-v2.6/examples/minicpm-v2.6/README.md"&gt;our fork of Ollama&lt;/a&gt; for more detail. This implementation supports smooth inference of 16~18 token/s on iPad (test environment：iPad Pro + M4).&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt; vLLM now officially supports MiniCPM-V 2.6, MiniCPM-Llama3-V 2.5 and MiniCPM-V 2.0. And you can use our fork to run MiniCPM-o 2.6 for now. Click to see. &lt;/summary&gt; 
 &lt;ol&gt; 
  &lt;li&gt;Install vLLM(&amp;gt;=0.7.1):&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;pip install vllm
&lt;/code&gt;&lt;/pre&gt; 
 &lt;ol start="2"&gt; 
  &lt;li&gt;Run Example:&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://docs.vllm.ai/en/latest/getting_started/examples/vision_language.html"&gt;Vision Language&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://docs.vllm.ai/en/latest/getting_started/examples/audio_language.html"&gt;Audio Language&lt;/a&gt; &lt;/li&gt;
 &lt;/ul&gt;
&lt;/details&gt;   
&lt;h2&gt;Fine-tuning&lt;/h2&gt; 
&lt;h3&gt;Simple Fine-tuning 
 &lt;!-- omit in toc --&gt;&lt;/h3&gt; 
&lt;p&gt;We support simple fine-tuning with Hugging Face for MiniCPM-o 2.6, MiniCPM-V 2.6, MiniCPM-Llama3-V 2.5 and MiniCPM-V 2.0.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/finetune/readme.md"&gt;Reference Document&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;With Align-Anything 
 &lt;!-- omit in toc --&gt;&lt;/h3&gt; 
&lt;p&gt;We support fine-tuning MiniCPM-o 2.6 by PKU-Alignment Team (both vision and audio, SFT and DPO) with the &lt;a href="https://github.com/PKU-Alignment/align-anything"&gt;Align-Anything framework&lt;/a&gt;. Align-Anything is a scalable framework that aims to align any-modality large models with human intentions, open-sourcing the &lt;a href="https://huggingface.co/datasets/PKU-Alignment/align-anything"&gt;datasets, models and benchmarks&lt;/a&gt;. Benefiting from its concise and modular design, it supports 30+ open-source benchmarks, 40+ models and algorithms including SFT, SimPO, RLHF, &lt;em&gt;etc&lt;/em&gt;. It also provides 30+ directly runnable scripts, making it suitable for beginners to quickly get started.&lt;/p&gt; 
&lt;p&gt;Best Practices: &lt;a href="https://github.com/PKU-Alignment/align-anything/tree/main/scripts"&gt;MiniCPM-o 2.6&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;With LLaMA-Factory 
 &lt;!-- omit in toc --&gt;&lt;/h3&gt; 
&lt;p&gt;We support fine-tuning MiniCPM-o 2.6 and MiniCPM-V 2.6 with the LLaMA-Factory framework. LLaMA-Factory provides a solution for flexibly customizing the fine-tuning (Lora/Full/Qlora) of 200+ LLMs without the need for coding through the built-in web UI LLaMABoard. It supports various training methods like sft/ppo/dpo/kto and advanced algorithms like Galore/BAdam/LLaMA-Pro/Pissa/LongLoRA.&lt;/p&gt; 
&lt;p&gt;Best Practices: &lt;a href="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/docs/llamafactory_train_and_infer.md"&gt;MiniCPM-o 2.6 | MiniCPM-V 2.6&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;With the SWIFT Framework 
 &lt;!-- omit in toc --&gt;&lt;/h3&gt; 
&lt;p&gt;We now support MiniCPM-V series fine-tuning with the SWIFT framework. SWIFT supports training, inference, evaluation and deployment of nearly 200 LLMs and MLLMs . It supports the lightweight training solutions provided by PEFT and a complete Adapters Library including techniques such as NEFTune, LoRA+ and LLaMA-PRO.&lt;/p&gt; 
&lt;p&gt;Best Practices：&lt;a href="https://github.com/modelscope/swift/raw/main/docs/source/Multi-Modal/minicpm-v%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5.md"&gt;MiniCPM-V 1.0&lt;/a&gt;, &lt;a href="https://github.com/modelscope/swift/raw/main/docs/source/Multi-Modal/minicpm-v-2%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5.md"&gt;MiniCPM-V 2.0&lt;/a&gt;, &lt;a href="https://github.com/modelscope/ms-swift/issues/1613"&gt;MiniCPM-V 2.6&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Awesome work using MiniCPM-V &amp;amp; MiniCPM-o&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/CatchTheTornado/text-extract-api"&gt;text-extract-api&lt;/a&gt;: Document extraction API using OCRs and Ollama supported models &lt;img src="https://img.shields.io/github/stars/CatchTheTornado/text-extract-api" alt="GitHub Repo stars" /&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/heshengtao/comfyui_LLM_party"&gt;comfyui_LLM_party&lt;/a&gt;: Build LLM workflows and integrate into existing image workflows &lt;img src="https://img.shields.io/github/stars/heshengtao/comfyui_LLM_party" alt="GitHub Repo stars" /&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/imanoop7/Ollama-OCR"&gt;Ollama-OCR&lt;/a&gt;: OCR package uses vlms through Ollama to extract text from images and PDF &lt;img src="https://img.shields.io/github/stars/imanoop7/Ollama-OCR" alt="GitHub Repo stars" /&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/MixLabPro/comfyui-mixlab-nodes"&gt;comfyui-mixlab-nodes&lt;/a&gt;: ComfyUI node suite supports Workflow-to-APP、GPT&amp;amp;3D and more &lt;img src="https://img.shields.io/github/stars/MixLabPro/comfyui-mixlab-nodes" alt="GitHub Repo stars" /&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/HumanAIGC-Engineering/OpenAvatarChat"&gt;OpenAvatarChat&lt;/a&gt;: Interactive digital human conversation implementation on single PC &lt;img src="https://img.shields.io/github/stars/HumanAIGC-Engineering/OpenAvatarChat" alt="GitHub Repo stars" /&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/arkohut/pensieve"&gt;pensieve&lt;/a&gt;: A privacy-focused passive recording project by recording screen content &lt;img src="https://img.shields.io/github/stars/arkohut/pensieve" alt="GitHub Repo stars" /&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/icereed/paperless-gpt"&gt;paperless-gpt&lt;/a&gt;: Use LLMs to handle paperless-ngx, AI-powered titles, tags and OCR &lt;img src="https://img.shields.io/github/stars/icereed/paperless-gpt" alt="GitHub Repo stars" /&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/kimjammer/Neuro"&gt;Neuro&lt;/a&gt;: A recreation of Neuro-Sama, but running on local models on consumer hardware &lt;img src="https://img.shields.io/github/stars/kimjammer/Neuro" alt="GitHub Repo stars" /&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;FAQs&lt;/h2&gt; 
&lt;p&gt;Click here to view the &lt;a href="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/docs/faqs.md"&gt;FAQs&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Limitations&lt;/h2&gt; 
&lt;p&gt;As an experimental trial, we find MiniCPM-o 2.6 has notable limitations worth further investigation and improvement.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Unstable speech output.&lt;/strong&gt; The speech generation can be flawed with noisy backgrounds and unmeaningful sounds.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Repeated response.&lt;/strong&gt; The model tends to repeat its response when encountering similar consecutive user queries.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;High-latency on Web Demo.&lt;/strong&gt; Users may experience unusual high-latency when using web demo hosted on overseas servers. We recommend deploying the demo locally or with good network connections.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Model License 
 &lt;!-- omit in toc --&gt;&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;This repository is released under the &lt;a href="https://github.com/OpenBMB/MiniCPM/raw/main/LICENSE"&gt;Apache-2.0&lt;/a&gt; License.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;The usage of MiniCPM-o/V model weights must strictly follow &lt;a href="https://github.com/OpenBMB/MiniCPM/raw/main/MiniCPM%20Model%20License.md"&gt;MiniCPM Model License.md&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;The models and weights of MiniCPM are completely free for academic research. after filling out a &lt;a href="https://modelbest.feishu.cn/share/base/form/shrcnpV5ZT9EJ6xYjh3Kx0J6v8g"&gt;"questionnaire"&lt;/a&gt; for registration, are also available for free commercial use.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Statement 
 &lt;!-- omit in toc --&gt;&lt;/h2&gt; 
&lt;p&gt;As MLLMs, MiniCPM-o/V models generate content by learning a large number of multimodal corpora, but they cannot comprehend, express personal opinions, or make value judgements. Anything generated by MiniCPM-o/V models does not represent the views and positions of the model developers&lt;/p&gt; 
&lt;p&gt;We will not be liable for any problems arising from the use of MiniCPM-o/V models, including but not limited to data security issues, risk of public opinion, or any risks and problems arising from the misdirection, misuse, dissemination, or misuse of the model.&lt;/p&gt; 
&lt;h2&gt;Institutions 
 &lt;!-- omit in toc --&gt;&lt;/h2&gt; 
&lt;p&gt;This project is developed by the following institutions:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;img src="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/assets/thunlp.png" width="28px" /&gt; &lt;a href="https://nlp.csai.tsinghua.edu.cn/"&gt;THUNLP&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;img src="https://raw.githubusercontent.com/OpenBMB/MiniCPM-V/main/assets/modelbest.png" width="28px" /&gt; &lt;a href="https://modelbest.cn/"&gt;ModelBest&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;🌟 Star History 
 &lt;!-- omit in toc --&gt;&lt;/h2&gt; 
&lt;!-- &lt;table align="center"&gt;
    &lt;p align="center"&gt;
      &lt;img src="assets/star_history.svg"/&gt;
    &lt;/p&gt;
&lt;/table&gt; --&gt; 
&lt;picture&gt; 
 &lt;source media="(prefers-color-scheme: dark)" srcset="
      https://api.star-history.com/svg?repos=OpenBMB/MiniCPM-o&amp;amp;type=Date&amp;amp;theme=dark
    " /&gt; 
 &lt;source media="(prefers-color-scheme: light)" srcset="
      https://api.star-history.com/svg?repos=OpenBMB/MiniCPM-o&amp;amp;type=Date
    " /&gt; 
 &lt;img alt="Star History Chart" src="https://api.star-history.com/svg?repos=OpenBMB/MiniCPM-o&amp;amp;type=Date" /&gt; 
&lt;/picture&gt; 
&lt;h2&gt;Key Techniques and Other Multimodal Projects 
 &lt;!-- omit in toc --&gt;&lt;/h2&gt; 
&lt;p&gt;👏 Welcome to explore key techniques of MiniCPM-o/V and other multimodal projects of our team:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/OpenBMB/VisCPM/tree/main"&gt;VisCPM&lt;/a&gt; | &lt;a href="https://github.com/OpenBMB/RLPR"&gt;RLPR&lt;/a&gt; | &lt;a href="https://github.com/RLHF-V/RLHF-V"&gt;RLHF-V&lt;/a&gt; | &lt;a href="https://github.com/thunlp/LLaVA-UHD"&gt;LLaVA-UHD&lt;/a&gt; | &lt;a href="https://github.com/RLHF-V/RLAIF-V"&gt;RLAIF-V&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Citation 
 &lt;!-- omit in toc --&gt;&lt;/h2&gt; 
&lt;p&gt;If you find our model/code/paper helpful, please consider citing our papers 📝 and staring us ⭐️！&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bib"&gt;@article{yao2024minicpm,
  title={MiniCPM-V: A GPT-4V Level MLLM on Your Phone},
  author={Yao, Yuan and Yu, Tianyu and Zhang, Ao and Wang, Chongyi and Cui, Junbo and Zhu, Hongji and Cai, Tianchi and Li, Haoyu and Zhao, Weilin and He, Zhihui and others},
  journal={arXiv preprint arXiv:2408.01800},
  year={2024}
}
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>dataease/SQLBot</title>
      <link>https://github.com/dataease/SQLBot</link>
      <description>&lt;p&gt;基于大模型和 RAG 的智能问数系统。Text-to-SQL Generation via LLMs using RAG.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt;&lt;img src="https://resource-fit2cloud-com.oss-cn-hangzhou.aliyuncs.com/sqlbot/sqlbot.png" alt="SQLBot" width="300" /&gt;&lt;/p&gt; 
&lt;h3 align="center"&gt;基于大模型和 RAG 的智能问数系统&lt;/h3&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/dataease/SQLBot/releases/latest"&gt;&lt;img src="https://img.shields.io/github/v/release/dataease/SQLBot" alt="Latest release" /&gt;&lt;/a&gt; &lt;a href="https://github.com/dataease/SQLBot"&gt;&lt;img src="https://img.shields.io/github/stars/dataease/SQLBot?color=%231890FF&amp;amp;style=flat-square" alt="Stars" /&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/r/dataease/SQLbot"&gt;&lt;img src="https://img.shields.io/docker/pulls/dataease/sqlbot?label=downloads" alt="Download" /&gt;&lt;/a&gt;&lt;br /&gt; &lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;SQLBot 是一款基于大模型和 RAG 的智能问数系统。SQLBot 的优势包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;开箱即用&lt;/strong&gt;: 只需配置大模型和数据源即可开启问数之旅，通过大模型和 RAG 的结合来实现高质量的 text2sql；&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;易于集成&lt;/strong&gt;: 支持快速嵌入到第三方业务系统，也支持被 n8n、MaxKB、Dify、Coze 等 AI 应用开发平台集成调用，让各类应用快速拥有智能问数能力；&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;安全可控&lt;/strong&gt;: 提供基于工作空间的资源隔离机制，能够实现细粒度的数据权限控制。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;快速开始&lt;/h2&gt; 
&lt;h3&gt;安装部署&lt;/h3&gt; 
&lt;p&gt;准备一台 Linux 服务器，执行以下一键安装脚本。&lt;br /&gt; 在运行 SQLBot 前，请确保已安装好 &lt;a href="https://docs.docker.com/get-docker/"&gt;Docker&lt;/a&gt; 和 &lt;a href="https://docs.docker.com/compose/install/"&gt;Docker Compose&lt;/a&gt;。&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# 创建目录
mkdir -p /opt/sqlbot
cd /opt/sqlbot

# 下载 docker-compose.yaml
curl -o docker-compose.yaml https://raw.githubusercontent.com/dataease/SQLBot/main/docker-compose.yaml

# 启动服务
docker compose up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;你也可以通过 &lt;a href="https://apps.fit2cloud.com/1panel"&gt;1Panel 应用商店&lt;/a&gt; 快速部署 SQLBot。&lt;/p&gt; 
&lt;p&gt;如果是内网环境，你可以通过 &lt;a href="https://community.fit2cloud.com/#/products/sqlbot/downloads"&gt;离线安装包方式&lt;/a&gt; 部署 SQLBot。&lt;/p&gt; 
&lt;h3&gt;访问方式&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;在浏览器中打开: http://&amp;lt;你的服务器IP&amp;gt;:8000/&lt;/li&gt; 
 &lt;li&gt;用户名: admin&lt;/li&gt; 
 &lt;li&gt;密码: SQLBot@123456&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;联系我们&lt;/h3&gt; 
&lt;p&gt;如你有更多问题，可以加入我们的技术交流群与我们交流。&lt;/p&gt; 
&lt;img width="180" height="180" alt="contact_me_qr" src="https://github.com/user-attachments/assets/2594ff29-5426-4457-b051-279855610030" /&gt; 
&lt;h2&gt;UI 展示&lt;/h2&gt;  
&lt;img alt="q&amp;amp;a" src="https://github.com/user-attachments/assets/55526514-52f3-4cfe-98ec-08a986259280" /&gt;  
&lt;h2&gt;Star History&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://www.star-history.com/#dataease/sqlbot&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=dataease/sqlbot&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;飞致云旗下的其他明星项目&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/dataease/dataease/"&gt;DataEase&lt;/a&gt; - 人人可用的开源 BI 工具&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/1panel-dev/1panel/"&gt;1Panel&lt;/a&gt; - 现代化、开源的 Linux 服务器运维管理面板&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/1panel-dev/MaxKB/"&gt;MaxKB&lt;/a&gt; - 强大易用的企业级智能体平台&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jumpserver/jumpserver/"&gt;JumpServer&lt;/a&gt; - 广受欢迎的开源堡垒机&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/halo-dev/halo/"&gt;Halo&lt;/a&gt; - 强大易用的开源建站工具&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/metersphere/metersphere/"&gt;MeterSphere&lt;/a&gt; - 新一代的开源持续测试工具&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;本仓库遵循 &lt;a href="https://raw.githubusercontent.com/dataease/SQLBot/main/LICENSE"&gt;FIT2CLOUD Open Source License&lt;/a&gt; 开源协议，该许可证本质上是 GPLv3，但有一些额外的限制。&lt;/p&gt; 
&lt;p&gt;你可以基于 SQLBot 的源代码进行二次开发，但是需要遵守以下规定：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;不能替换和修改 SQLBot 的 Logo 和版权信息；&lt;/li&gt; 
 &lt;li&gt;二次开发后的衍生作品必须遵守 GPL V3 的开源义务。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;如需商业授权，请联系 &lt;a href="mailto:support@fit2cloud.com"&gt;support@fit2cloud.com&lt;/a&gt; 。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>EbookFoundation/free-programming-books</title>
      <link>https://github.com/EbookFoundation/free-programming-books</link>
      <description>&lt;p&gt;📚 Freely available programming books&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;List of Free Learning Resources In Many Languages&lt;/h1&gt; 
&lt;div align="center" markdown="1"&gt; 
 &lt;p&gt;&lt;a href="https://github.com/sindresorhus/awesome"&gt;&lt;img src="https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg?sanitize=true" alt="Awesome" /&gt;&lt;/a&gt;&amp;nbsp; &lt;a href="https://creativecommons.org/licenses/by/4.0/"&gt;&lt;img src="https://img.shields.io/badge/License-CC%20BY%204.0-lightgrey.svg?sanitize=true" alt="License: CC BY 4.0" /&gt;&lt;/a&gt;&amp;nbsp; &lt;a href="https://github.com/EbookFoundation/free-programming-books/pulls?q=is%3Apr+is%3Amerged+created%3A2023-10-01..2023-10-31"&gt;&lt;img src="https://img.shields.io/github/hacktoberfest/2023/EbookFoundation/free-programming-books?label=Hacktoberfest+2023" alt="Hacktoberfest 2023 stats" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;Search the list at &lt;a href="https://ebookfoundation.github.io/free-programming-books-search/"&gt;https://ebookfoundation.github.io/free-programming-books-search/&lt;/a&gt; &lt;a href="https://ebookfoundation.github.io/free-programming-books-search/"&gt;&lt;img src="https://img.shields.io/website?style=flat&amp;amp;logo=www&amp;amp;logoColor=whitesmoke&amp;amp;label=Dynamic%20search%20site&amp;amp;down_color=red&amp;amp;down_message=down&amp;amp;up_color=green&amp;amp;up_message=up&amp;amp;url=https%3A%2F%2Febookfoundation.github.io%2Ffree-programming-books-search%2F" alt="https://ebookfoundation.github.io/free-programming-books-search/" /&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;This page is available as an easy-to-read website. Access it by clicking on &lt;a href="https://ebookfoundation.github.io/free-programming-books/"&gt;&lt;img src="https://img.shields.io/website?style=flat&amp;amp;logo=www&amp;amp;logoColor=whitesmoke&amp;amp;label=Static%20site&amp;amp;down_color=red&amp;amp;down_message=down&amp;amp;up_color=green&amp;amp;up_message=up&amp;amp;url=https%3A%2F%2Febookfoundation.github.io%2Ffree-programming-books%2F" alt="https://ebookfoundation.github.io/free-programming-books/" /&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;form action="https://ebookfoundation.github.io/free-programming-books-search"&gt; 
  &lt;input type="text" id="fpbSearch" name="search" required placeholder="Search Book or Author" /&gt; 
  &lt;label for="submit"&gt; &lt;/label&gt; 
  &lt;input type="submit" id="submit" name="submit" value="Search" /&gt; 
 &lt;/form&gt; 
&lt;/div&gt; 
&lt;h2&gt;Intro&lt;/h2&gt; 
&lt;p&gt;This list was originally a clone of &lt;a href="https://web.archive.org/web/20140606191453/http://stackoverflow.com/questions/194812/list-of-freely-available-programming-books/392926"&gt;StackOverflow - List of Freely Available Programming Books&lt;/a&gt; with contributions from Karan Bhangui and George Stocker.&lt;/p&gt; 
&lt;p&gt;The list was moved to GitHub by Victor Felder for collaborative updating and maintenance. It has grown to become one of &lt;a href="https://octoverse.github.com/"&gt;GitHub's most popular repositories&lt;/a&gt;.&lt;/p&gt; 
&lt;div align="center" markdown="1"&gt; 
 &lt;p&gt;&lt;a href="https://github.com/EbookFoundation/free-programming-books/network"&gt;&lt;img src="https://img.shields.io/github/forks/EbookFoundation/free-programming-books?style=flat&amp;amp;logo=github&amp;amp;logoColor=whitesmoke&amp;amp;label=Forks" alt="GitHub repo forks" /&gt;&lt;/a&gt;&amp;nbsp; &lt;a href="https://github.com/EbookFoundation/free-programming-books/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/EbookFoundation/free-programming-books?style=flat&amp;amp;logo=github&amp;amp;logoColor=whitesmoke&amp;amp;label=Stars" alt="GitHub repo stars" /&gt;&lt;/a&gt;&amp;nbsp; &lt;a href="https://github.com/EbookFoundation/free-programming-books/graphs/contributors"&gt;&lt;img src="https://img.shields.io/github/contributors-anon/EbookFoundation/free-programming-books?style=flat&amp;amp;logo=github&amp;amp;logoColor=whitesmoke&amp;amp;label=Contributors" alt="GitHub repo contributors" /&gt;&lt;/a&gt;&lt;br /&gt; &lt;a href="https://github.com/sponsors/EbookFoundation"&gt;&lt;img src="https://img.shields.io/github/sponsors/EbookFoundation?style=flat&amp;amp;logo=github&amp;amp;logoColor=whitesmoke&amp;amp;label=Sponsors" alt="GitHub org sponsors" /&gt;&lt;/a&gt;&amp;nbsp; &lt;a href="https://github.com/EbookFoundation/free-programming-books/watchers"&gt;&lt;img src="https://img.shields.io/github/watchers/EbookFoundation/free-programming-books?style=flat&amp;amp;logo=github&amp;amp;logoColor=whitesmoke&amp;amp;label=Watchers" alt="GitHub repo watchers" /&gt;&lt;/a&gt;&amp;nbsp; &lt;a href="https://github.com/EbookFoundation/free-programming-books/archive/refs/heads/main.zip"&gt;&lt;img src="https://img.shields.io/github/repo-size/EbookFoundation/free-programming-books?style=flat&amp;amp;logo=github&amp;amp;logoColor=whitesmoke&amp;amp;label=Repo%20Size" alt="GitHub repo size" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;The &lt;a href="https://ebookfoundation.org"&gt;Free Ebook Foundation&lt;/a&gt; now administers the repo, a not-for-profit organization devoted to promoting the creation, distribution, archiving, and sustainability of free ebooks. &lt;a href="https://ebookfoundation.org/contributions.html"&gt;Donations&lt;/a&gt; to the Free Ebook Foundation are tax-deductible in the US.&lt;/p&gt; 
&lt;h2&gt;How To Contribute&lt;/h2&gt; 
&lt;p&gt;Please read &lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/docs/CONTRIBUTING.md"&gt;CONTRIBUTING&lt;/a&gt;. If you're new to GitHub, &lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/docs/HOWTO.md"&gt;welcome&lt;/a&gt;! Remember to abide by our adapted from &lt;img src="https://img.shields.io/badge/Contributor%20Covenant-1.3-4baaaa.svg?sanitize=true" alt="Contributor Covenant 1.3" /&gt; &lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/docs/CODE_OF_CONDUCT.md"&gt;Code of Conduct&lt;/a&gt; too (&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/#translations"&gt;translations&lt;/a&gt; also available).&lt;/p&gt; 
&lt;p&gt;Click on these badges to see how you might be able to help:&lt;/p&gt; 
&lt;div align="center" markdown="1"&gt; 
 &lt;p&gt;&lt;a href="https://github.com/EbookFoundation/free-programming-books/issues"&gt;&lt;img src="https://img.shields.io/github/issues/EbookFoundation/free-programming-books?style=flat&amp;amp;logo=github&amp;amp;logoColor=red&amp;amp;label=Issues" alt="GitHub repo Issues" /&gt;&lt;/a&gt;&amp;nbsp; &lt;a href="https://github.com/EbookFoundation/free-programming-books/issues?q=is%3Aopen+is%3Aissue+label%3A%22good+first+issue%22"&gt;&lt;img src="https://img.shields.io/github/issues/EbookFoundation/free-programming-books/good%20first%20issue?style=flat&amp;amp;logo=github&amp;amp;logoColor=green&amp;amp;label=Good%20First%20issues" alt="GitHub repo Good Issues for newbies" /&gt;&lt;/a&gt;&amp;nbsp; &lt;a href="https://github.com/EbookFoundation/free-programming-books/issues?q=is%3Aopen+is%3Aissue+label%3A%22help+wanted%22"&gt;&lt;img src="https://img.shields.io/github/issues/EbookFoundation/free-programming-books/help%20wanted?style=flat&amp;amp;logo=github&amp;amp;logoColor=b545d1&amp;amp;label=%22Help%20Wanted%22%20issues" alt="GitHub Help Wanted issues" /&gt;&lt;/a&gt;&lt;br /&gt; &lt;a href="https://github.com/EbookFoundation/free-programming-books/pulls"&gt;&lt;img src="https://img.shields.io/github/issues-pr/EbookFoundation/free-programming-books?style=flat&amp;amp;logo=github&amp;amp;logoColor=orange&amp;amp;label=PRs" alt="GitHub repo PRs" /&gt;&lt;/a&gt;&amp;nbsp; &lt;a href="https://github.com/EbookFoundation/free-programming-books/pulls?q=is%3Apr+is%3Amerged"&gt;&lt;img src="https://img.shields.io/github/issues-search/EbookFoundation/free-programming-books?style=flat&amp;amp;logo=github&amp;amp;logoColor=green&amp;amp;label=Merged%20PRs&amp;amp;query=is%3Amerged" alt="GitHub repo Merged PRs" /&gt;&lt;/a&gt;&amp;nbsp; &lt;a href="https://github.com/EbookFoundation/free-programming-books/pulls?q=is%3Aopen+is%3Aissue+label%3A%22help+wanted%22"&gt;&lt;img src="https://img.shields.io/github/issues-pr/EbookFoundation/free-programming-books/help%20wanted?style=flat&amp;amp;logo=github&amp;amp;logoColor=b545d1&amp;amp;label=%22Help%20Wanted%22%20PRs" alt="GitHub Help Wanted PRs" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;How To Share&lt;/h2&gt; 
&lt;div align="left" markdown="1"&gt; 
 &lt;a href="https://www.facebook.com/share.php?u=https%3A%2F%2Fgithub.com%2FEbookFoundation%2Ffree-programming-books&amp;amp;p%5Bimages%5D%5B0%5D=&amp;amp;p%5Btitle%5D=Free%20Programming%20Books&amp;amp;p%5Bsummary%5D="&gt;Share on Facebook&lt;/a&gt;
 &lt;br /&gt; 
 &lt;a href="http://www.linkedin.com/shareArticle?mini=true&amp;amp;url=https://github.com/EbookFoundation/free-programming-books&amp;amp;title=Free%20Programming%20Books&amp;amp;summary=&amp;amp;source="&gt;Share on LinkedIn&lt;/a&gt;
 &lt;br /&gt; 
 &lt;a href="https://toot.kytta.dev/?mini=true&amp;amp;url=https://github.com/EbookFoundation/free-programming-books&amp;amp;title=Free%20Programming%20Books&amp;amp;summary=&amp;amp;source="&gt;Share on Mastodon/Fediverse&lt;/a&gt;
 &lt;br /&gt; 
 &lt;a href="https://t.me/share/url?url=https://github.com/EbookFoundation/free-programming-books"&gt;Share on Telegram&lt;/a&gt;
 &lt;br /&gt; 
 &lt;a href="https://twitter.com/intent/tweet?text=https://github.com/EbookFoundation/free-programming-books%0AFree%20Programming%20Books"&gt;Share on 𝕏 (Twitter)&lt;/a&gt;
 &lt;br /&gt; 
&lt;/div&gt; 
&lt;h2&gt;Resources&lt;/h2&gt; 
&lt;p&gt;This project lists books and other resources grouped by genres:&lt;/p&gt; 
&lt;h3&gt;Books&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-langs.md"&gt;English, By Programming Language&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-subjects.md"&gt;English, By Subject&lt;/a&gt;&lt;/p&gt; 
&lt;h4&gt;Other Languages&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-ar.md"&gt;Arabic / al arabiya / العربية&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-hy.md"&gt;Armenian / Հայերեն&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-az.md"&gt;Azerbaijani / Азәрбајҹан дили / آذربايجانجا ديلي&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-bn.md"&gt;Bengali / বাংলা&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-bg.md"&gt;Bulgarian / български&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-my.md"&gt;Burmese / မြန်မာဘာသာ&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-zh.md"&gt;Chinese / 中文&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-cs.md"&gt;Czech / čeština / český jazyk&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-ca.md"&gt;Catalan / catalan/ català&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-da.md"&gt;Danish / dansk&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-nl.md"&gt;Dutch / Nederlands&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-et.md"&gt;Estonian / eesti keel&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-fi.md"&gt;Finnish / suomi / suomen kieli&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-fr.md"&gt;French / français&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-de.md"&gt;German / Deutsch&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-el.md"&gt;Greek / ελληνικά&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-he.md"&gt;Hebrew / עברית&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-hi.md"&gt;Hindi / हिन्दी&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-hu.md"&gt;Hungarian / magyar / magyar nyelv&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-id.md"&gt;Indonesian / Bahasa Indonesia&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-it.md"&gt;Italian / italiano&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-ja.md"&gt;Japanese / 日本語&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-ko.md"&gt;Korean / 한국어&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-lv.md"&gt;Latvian / Latviešu&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-ml.md"&gt;Malayalam / മലയാളം&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-no.md"&gt;Norwegian / Norsk&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-fa_IR.md"&gt;Persian / Farsi (Iran) / فارسى&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-pl.md"&gt;Polish / polski / język polski / polszczyzna&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-pt_BR.md"&gt;Portuguese (Brazil)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-pt_PT.md"&gt;Portuguese (Portugal)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-ro.md"&gt;Romanian (Romania) / limba română / român&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-ru.md"&gt;Russian / Русский язык&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-sr.md"&gt;Serbian / српски језик / srpski jezik&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-sk.md"&gt;Slovak / slovenčina&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-es.md"&gt;Spanish / español / castellano&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-sv.md"&gt;Swedish / Svenska&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-ta.md"&gt;Tamil / தமிழ்&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-te.md"&gt;Telugu / తెలుగు&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-th.md"&gt;Thai / ไทย&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-tr.md"&gt;Turkish / Türkçe&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-uk.md"&gt;Ukrainian / Українська&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-vi.md"&gt;Vietnamese / Tiếng Việt&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Cheat Sheets&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/more/free-programming-cheatsheets.md"&gt;All Languages&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Free Online Courses&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-ar.md"&gt;Arabic / al arabiya / العربية&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-bn.md"&gt;Bengali / বাংলা&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-bg.md"&gt;Bulgarian / български&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-my.md"&gt;Burmese / မြန်မာဘာသာ&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-zh.md"&gt;Chinese / 中文&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-en.md"&gt;English&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-fi.md"&gt;Finnish / suomi / suomen kieli&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-fr.md"&gt;French / français&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-de.md"&gt;German / Deutsch&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-el.md"&gt;Greek / ελληνικά&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-he.md"&gt;Hebrew / עברית&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-hi.md"&gt;Hindi / हिंदी&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-id.md"&gt;Indonesian / Bahasa Indonesia&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-it.md"&gt;Italian / italiano&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-ja.md"&gt;Japanese / 日本語&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-kn.md"&gt;Kannada/ಕನ್ನಡ&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-kk.md"&gt;Kazakh / қазақша&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-km.md"&gt;Khmer / ភាសាខ្មែរ&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-ko.md"&gt;Korean / 한국어&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-ml.md"&gt;Malayalam / മലയാളം&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-mr.md"&gt;Marathi / मराठी&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-ne.md"&gt;Nepali / नेपाली&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-no.md"&gt;Norwegian / Norsk&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-fa_IR.md"&gt;Persian / Farsi (Iran) / فارسى&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-pl.md"&gt;Polish / polski / język polski / polszczyzna&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-pt_BR.md"&gt;Portuguese (Brazil)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-pt_PT.md"&gt;Portuguese (Portugal)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-ru.md"&gt;Russian / Русский язык&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-si.md"&gt;Sinhala / සිංහල&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-es.md"&gt;Spanish / español / castellano&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-sv.md"&gt;Swedish / svenska&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-ta.md"&gt;Tamil / தமிழ்&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-te.md"&gt;Telugu / తెలుగు&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-th.md"&gt;Thai / ภาษาไทย&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-tr.md"&gt;Turkish / Türkçe&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-uk.md"&gt;Ukrainian / Українська&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-ur.md"&gt;Urdu / اردو&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-vi.md"&gt;Vietnamese / Tiếng Việt&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Interactive Programming Resources&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/more/free-programming-interactive-tutorials-zh.md"&gt;Chinese / 中文&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/more/free-programming-interactive-tutorials-en.md"&gt;English&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/more/free-programming-interactive-tutorials-de.md"&gt;German / Deutsch&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/more/free-programming-interactive-tutorials-ja.md"&gt;Japanese / 日本語&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/more/free-programming-interactive-tutorials-ru.md"&gt;Russian / Русский язык&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Problem Sets and Competitive Programming&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/more/problem-sets-competitive-programming.md"&gt;Problem Sets&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Podcast - Screencast&lt;/h3&gt; 
&lt;p&gt;Free Podcasts and Screencasts:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-ar.md"&gt;Arabic / al Arabiya / العربية&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-my.md"&gt;Burmese / မြန်မာဘာသာ&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-zh.md"&gt;Chinese / 中文&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-cs.md"&gt;Czech / čeština / český jazyk&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-nl.md"&gt;Dutch / Nederlands&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-en.md"&gt;English&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-fi.md"&gt;Finnish / Suomi&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-fr.md"&gt;French / français&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-de.md"&gt;German / Deutsch&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-he.md"&gt;Hebrew / עברית&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-id.md"&gt;Indonesian / Bahasa Indonesia&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-fa_IR.md"&gt;Persian / Farsi (Iran) / فارسى&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-pl.md"&gt;Polish / polski / język polski / polszczyzna&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-pt_BR.md"&gt;Portuguese (Brazil)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-pt_PT.md"&gt;Portuguese (Portugal)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-ru.md"&gt;Russian / Русский язык&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-si.md"&gt;Sinhala / සිංහල&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-es.md"&gt;Spanish / español / castellano&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-sv.md"&gt;Swedish / Svenska&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-tr.md"&gt;Turkish / Türkçe&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-uk.md"&gt;Ukrainian / Українська&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Programming Playgrounds&lt;/h3&gt; 
&lt;p&gt;Write, compile, and run your code within a browser. Try it out!&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/more/free-programming-playgrounds-zh.md"&gt;Chinese / 中文&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/more/free-programming-playgrounds.md"&gt;English&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/more/free-programming-playgrounds-de.md"&gt;German / Deutsch&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Translations&lt;/h2&gt; 
&lt;p&gt;Volunteers have translated many of our Contributing, How-to, and Code of Conduct documents into languages covered by our lists.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;English 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/docs/CODE_OF_CONDUCT.md"&gt;Code of Conduct&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/docs/CONTRIBUTING.md"&gt;Contributing&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/docs/HOWTO.md"&gt;How-to&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;... &lt;em&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/docs/README.md#translations"&gt;More languages&lt;/a&gt;&lt;/em&gt; ...&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;You might notice that there are &lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/docs/README.md#translations"&gt;some missing translations here&lt;/a&gt; - perhaps you would like to help out by &lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/docs/CONTRIBUTING.md#help-out-by-contributing-a-translation"&gt;contributing a translation&lt;/a&gt;?&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Each file included in this repository is licensed under the &lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/LICENSE"&gt;CC BY License&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>willccbb/verifiers</title>
      <link>https://github.com/willccbb/verifiers</link>
      <description>&lt;p&gt;Verifiers for LLM Reinforcement Learning&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;p align="center"&gt; &lt;/p&gt;
 &lt;h1&gt;Verifiers&lt;/h1&gt; 
 &lt;p&gt;&lt;/p&gt; 
 &lt;p&gt; Environments for LLM Reinforcement Learning &lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;Overview&lt;/h2&gt; 
&lt;p&gt;Verifiers is a library of modular components for creating RL environments and training LLM agents. Verifiers includes an async GRPO implementation built around the &lt;code&gt;transformers&lt;/code&gt; Trainer, is supported by &lt;code&gt;prime-rl&lt;/code&gt; for large-scale FSDP training, and can easily be integrated into any RL framework which exposes an OpenAI-compatible inference client. In addition to RL training, Verifiers can be used directly for building LLM evaluations, creating synthetic data pipelines, and implementing agent harnesses.&lt;/p&gt; 
&lt;p&gt;Full documentation is available &lt;a href="https://verifiers.readthedocs.io/en/latest/"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Setup&lt;/h2&gt; 
&lt;p&gt;We recommend using &lt;code&gt;verifiers&lt;/code&gt; with along &lt;a href="https://docs.astral.sh/uv/getting-started/installation/"&gt;uv&lt;/a&gt; for dependency management in your own project:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -LsSf https://astral.sh/uv/install.sh | sh
uv init # create a fresh project
source .venv/bin/activate
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For local (CPU) development and evaluation with API models, do:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uv add verifiers # uv add 'verifiers[dev]' for Jupyter + testing support
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For training on GPUs with &lt;code&gt;vf.GRPOTrainer&lt;/code&gt;, do:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uv add 'verifiers[all]' &amp;amp;&amp;amp; uv pip install flash-attn --no-build-isolation
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To use the latest &lt;code&gt;main&lt;/code&gt; branch, do:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uv add verifiers @ git+https://github.com/willccbb/verifiers.git
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To use with &lt;code&gt;prime-rl&lt;/code&gt;, see &lt;a href="https://github.com/PrimeIntellect-ai/prime-rl"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;To install &lt;code&gt;verifiers&lt;/code&gt; from source for core library development, do:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/willccbb/verifiers.git
cd verifiers
uv sync --all-extras &amp;amp;&amp;amp; uv pip install flash-attn --no-build-isolation
uv run pre-commit install
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;In general, we recommend that you build and train Environments &lt;em&gt;with&lt;/em&gt; &lt;code&gt;verifiers&lt;/code&gt;, not &lt;em&gt;in&lt;/em&gt; &lt;code&gt;verifiers&lt;/code&gt;. If you find yourself needing to clone and modify the core library in order to implement key functionality for your project, we'd love for you to open an issue so that we can try and streamline the development experience. Our aim is for &lt;code&gt;verifiers&lt;/code&gt; to be a reliable toolkit to build on top of, and to minimize the "fork proliferation" which often pervades the RL infrastructure ecosystem.&lt;/p&gt; 
&lt;h2&gt;Environments&lt;/h2&gt; 
&lt;p&gt;Environments in Verifiers are installable Python modules which can specify dependencies in a &lt;code&gt;pyproject.toml&lt;/code&gt;, and which expose a &lt;code&gt;load_environment&lt;/code&gt; function for instantiation by downstream applications (e.g. trainers). See &lt;code&gt;environments/&lt;/code&gt; for examples.&lt;/p&gt; 
&lt;p&gt;To initialize a blank Environment module template, do:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;vf-init vf-environment-name # -p /path/to/environments (defaults to "./environments")
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To an install an Environment module into your project, do:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;vf-install vf-environment-name # -p /path/to/environments (defaults to "./environments") 
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To install an Environment module from this repo's &lt;code&gt;environments&lt;/code&gt; folder, do:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;vf-install vf-math-python --from-repo # -b branch_or_commit (defaults to "main")
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Once an Environment module is installed, you can create an instance of the Environment using &lt;code&gt;load_environment&lt;/code&gt;, passing any necessary args:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import verifiers as vf
vf_env = vf.load_environment("vf-environment-name", **env_args)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To run a quick evaluation of your Environment with an API-based model, do:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;vf-eval vf-environment-name # vf-eval -h for config options; defaults to gpt-4.1-mini, 5 prompts, 3 rollouts for each
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The core elements of Environments in are:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Datasets: a Hugging Face &lt;code&gt;Dataset&lt;/code&gt; with a &lt;code&gt;prompt&lt;/code&gt; column for inputs, and either &lt;code&gt;answer (str)&lt;/code&gt; or &lt;code&gt;info (dict)&lt;/code&gt; columns for evaluation&lt;/li&gt; 
 &lt;li&gt;Rollout logic: interactions between models and the environment (e.g. &lt;code&gt;env_response&lt;/code&gt; + &lt;code&gt;is_completed&lt;/code&gt; for any &lt;code&gt;MultiTurnEnv&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;Rubrics: an encapsulation for one or more reward functions&lt;/li&gt; 
 &lt;li&gt;Parsers: optional; an encapsulation for reusable parsing logic&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;We support both &lt;code&gt;/v1/chat/completions&lt;/code&gt;-style and &lt;code&gt;/v1/completions&lt;/code&gt;-style inference via OpenAI clients, though we generally recommend &lt;code&gt;/v1/chat/completions&lt;/code&gt;-style inference for the vast majority of applications. Both the included &lt;code&gt;GRPOTrainer&lt;/code&gt; as well as &lt;code&gt;prime-rl&lt;/code&gt; support the full set of &lt;a href="https://docs.vllm.ai/en/v0.6.0/dev/sampling_params.html"&gt;SamplingParams&lt;/a&gt; exposed by vLLM (via their OpenAI-compatible &lt;a href="https://docs.vllm.ai/en/latest/serving/openai_compatible_server.html"&gt;server&lt;/a&gt; interface), and leveraging this will often be the appropriate way to implement rollout strategies requiring finer-grained control, such as interrupting and resuming generations for interleaved tool use, or enforcing reasoning budgets.&lt;/p&gt; 
&lt;p&gt;The primary constraint we impose on rollout logic is that token sequences must be &lt;em&gt;increasing&lt;/em&gt;, i.e. once a token has been added to a model's context in a rollout, it must remain as the rollout progresses. Note that this causes issues with some popular reasoning models such as the Qwen3 and DeepSeek-R1-Distill series; see &lt;a href="https://raw.githubusercontent.com/willccbb/verifiers/main/#footguns"&gt;Footguns&lt;/a&gt; for guidance on adapting these models to support multi-turn rollouts.&lt;/p&gt; 
&lt;h3&gt;SingleTurnEnv&lt;/h3&gt; 
&lt;p&gt;For tasks requiring only a single response from a model for each prompt, you can use &lt;code&gt;SingleTurnEnv&lt;/code&gt; directly by specifying a Dataset and a Rubric. Rubrics are sets of reward functions, which can be either sync or async.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from datasets import load_dataset
import verifiers as vf

dataset = load_dataset("my-account/my-dataset", split="train")

def reward_A(prompt, completion, info) -&amp;gt; float:
	# reward fn, e.g. correctness
	...

def reward_B(parser, completion) -&amp;gt; float:
	# auxiliary reward fn, e.g. format
	...

async def metric(completion) -&amp;gt; float:
	# non-reward metric, e.g. proper noun count
	...

rubric = vf.Rubric(funcs=[reward_A, reward_B, metric], weights=[1.0, 0.5, 0.0])

vf_env = SingleTurnEnv(
	dataset=dataset,
	rubric=rubric
)
results = vf_env.evaluate(client=OpenAI(), model="gpt-4.1-mini", num_examples=100, rollouts_per_example=1)
vf_env.make_dataset(results) # HF dataset format
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Datasets should be formatted with columns for:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;'prompt' (List[ChatMessage])&lt;/code&gt; OR &lt;code&gt;'question' (str)&lt;/code&gt; fields 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;ChatMessage&lt;/code&gt; = e.g. &lt;code&gt;{'role': 'user', 'content': '...'}&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;if &lt;code&gt;question&lt;/code&gt; is set instead of &lt;code&gt;prompt&lt;/code&gt;, you can also pass &lt;code&gt;system_prompt (str)&lt;/code&gt; and/or &lt;code&gt;few_shot (List[ChatMessage])&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;answer (str)&lt;/code&gt; AND/OR &lt;code&gt;info (dict)&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;task (str)&lt;/code&gt;: optional, used by &lt;code&gt;EnvGroup&lt;/code&gt; and &lt;code&gt;RubricGroup&lt;/code&gt; for orchestrating composition of Environments and Rubrics&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The following named attributes available for use by reward functions in your Rubric:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;prompt&lt;/code&gt;: sequence of input messages&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;completion&lt;/code&gt;: sequence of messages generated during rollout by model and Environment&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;answer&lt;/code&gt;: primary answer column, optional if &lt;code&gt;info&lt;/code&gt; is used&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;state&lt;/code&gt;: can be modified during rollout to accumulate any metadata (&lt;code&gt;state['responses']&lt;/code&gt; includes full OpenAI response objects by default)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;info&lt;/code&gt;: auxiliary info needed for reward computation (e.g. test cases), optional if &lt;code&gt;answer&lt;/code&gt; is used&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;task&lt;/code&gt;: tag for task type (used by &lt;code&gt;EnvGroup&lt;/code&gt; and &lt;code&gt;RubricGroup&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;parser&lt;/code&gt;: the parser object declared. Note: &lt;code&gt;vf.Parser().get_format_reward_func()&lt;/code&gt; is a no-op (always 1.0); use &lt;code&gt;vf.ThinkParser&lt;/code&gt; or a custom parser if you want a real format adherence reward.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For tasks involving LLM judges, you may wish to use &lt;code&gt;vf.JudgeRubric()&lt;/code&gt; for managing requests to auxiliary models.&lt;/p&gt; 
&lt;p&gt;Note on concurrency: environment APIs accept &lt;code&gt;max_concurrent&lt;/code&gt; to control parallel rollouts. The &lt;code&gt;vf-eval&lt;/code&gt; CLI currently exposes &lt;code&gt;--max-concurrent-requests&lt;/code&gt;; ensure this maps to your environment’s concurrency as expected.&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;vf-eval&lt;/code&gt; also supports specifying &lt;code&gt;sampling_args&lt;/code&gt; as a JSON object, which is sent to the vLLM inference engine:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;vf-eval vf-environment-name --sampling-args '{"reasoning_effort": "low"}'
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Use &lt;code&gt;vf-eval -s&lt;/code&gt; to save outputs as dataset-formatted JSON, and view all locally-saved eval results with &lt;code&gt;vf-tui&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;ToolEnv&lt;/h3&gt; 
&lt;p&gt;For many applications involving tool use, you can use &lt;code&gt;ToolEnv&lt;/code&gt; to leverage models' native tool/function-calling capabilities in an agentic loop. Tools can be specified as generic Python functions (with type hints and docstrings), which will then be passed in JSON schema form to each inference request.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import verifiers as vf
vf_env = vf.ToolEnv(
	dataset= ... # HF Dataset with 'prompt'/'question' + 'answer'/'info' columns
	rubric= ... # Rubric object; vf.ToolRubric() can be optionally used for counting tool invocations in each rollout
	tools=[search_tool, read_article_tool, python_tool], # python functions with type hints + docstrings
	max_turns=10
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;In cases where your tools require heavy computational resources, we recommend hosting your tools as standalone servers (e.g. MCP servers) and creating lightweight wrapper functions to pass to &lt;code&gt;ToolEnv&lt;/code&gt;. Parallel tool call support is enabled by default.&lt;/p&gt; 
&lt;p&gt;For training, or self-hosted endpoints, you'll want to enable auto tool choice in &lt;a href="https://docs.vllm.ai/en/stable/features/tool_calling.html#automatic-function-calling"&gt;vLLM&lt;/a&gt; with the appropriate parser. If your model does not support native tool calling, you may find the &lt;code&gt;XMLParser&lt;/code&gt; abstraction useful for rolling your own tool call parsing on top of &lt;code&gt;MultiTurnEnv&lt;/code&gt;; see &lt;code&gt;environments/xml_tool_env&lt;/code&gt; for an example.&lt;/p&gt; 
&lt;h3&gt;MultiTurnEnv&lt;/h3&gt; 
&lt;p&gt;Both &lt;code&gt;SingleTurnEnv&lt;/code&gt; and &lt;code&gt;ToolEnv&lt;/code&gt; are instances of &lt;code&gt;MultiTurnEnv&lt;/code&gt;, which exposes an interface for writing custom Environment interaction protocols. The two methods you must override are&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from typing import Tuple
import verifiers as vf
from verifiers.types import Messages, State
class YourMultiTurnEnv(vf.MultiTurnEnv):
    def __init__(self,
                 dataset: Dataset,
                 rubric: Rubric,
				 max_turns: int,
                 **kwargs):
	
  async def is_completed(self, messages: Messages, state: State, **kwargs) -&amp;gt; bool:
    # return whether or not a rollout is completed

  async def env_response(self, messages: Messages, state: State, **kwargs) -&amp;gt; Tuple[Messages, State]:
    # return new environment message(s) + updated state
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If your application requires more fine-grained control than is allowed by &lt;code&gt;MultiTurnEnv&lt;/code&gt;, you may want to inherit from the base &lt;code&gt;Environment&lt;/code&gt; functionality directly and override the &lt;code&gt;rollout&lt;/code&gt; method.&lt;/p&gt; 
&lt;h2&gt;Training&lt;/h2&gt; 
&lt;h3&gt;GRPOTrainer&lt;/h3&gt; 
&lt;p&gt;The included trainer (&lt;code&gt;vf.GRPOTrainer&lt;/code&gt;) supports running GRPO-style RL training via Accelerate/DeepSpeed, and uses vLLM for inference. It supports both full-parameter finetuning, and is optimized for efficiently training dense transformer models on 2-16 GPUs.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# install environment
vf-install vf-wordle (-p /path/to/environments | --from-repo)

# quick eval
vf-eval vf-wordle -m (model_name in configs/endpoints.py) -n NUM_EXAMPLES -r ROLLOUTS_PER_EXAMPLE

# inference (shell 0)
CUDA_VISIBLE_DEVICES=0,1,2,3,4,5 vf-vllm --model willcb/Qwen3-1.7B-Wordle \
    --data-parallel-size 7 --enforce-eager --disable-log-requests

# training (shell 1)
CUDA_VISIBLE_DEVICES=6,7 accelerate launch --num-processes 2 \
    --config-file configs/zero3.yaml examples/grpo/train_wordle.py --size 1.7B
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Alternatively, you can train environments with the external &lt;code&gt;prime-rl&lt;/code&gt; project (FSDP-first orchestration). See the &lt;code&gt;prime-rl&lt;/code&gt; README for installation and examples. For example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# orchestrator config (prime-rl)
[environment]
id = "vf-math-python"  # or your environment ID
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# run (prime-rl)
uv run rl \
  --trainer @ configs/your_exp/train.toml \
  --orchestrator @ configs/your_exp/orch.toml \
  --inference @ configs/your_exp/infer.toml
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Troubleshooting&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Ensure your &lt;code&gt;wandb&lt;/code&gt; and &lt;code&gt;huggingface-cli&lt;/code&gt; logins are set up (or set &lt;code&gt;report_to=None&lt;/code&gt; in &lt;code&gt;training_args&lt;/code&gt;). You should also have something set as your &lt;code&gt;OPENAI_API_KEY&lt;/code&gt; in your environment (can be a dummy key for vLLM).&lt;/li&gt; 
 &lt;li&gt;If using high max concurrency, increase the number of allowed open sockets (e.g. &lt;code&gt;ulimit -n 4096&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;On some setups, inter-GPU communication can &lt;a href="https://github.com/huggingface/trl/issues/2923"&gt;hang&lt;/a&gt; or crash during vLLM weight syncing. This can usually be alleviated by setting (or unsetting) &lt;code&gt;NCCL_P2P_DISABLE=1&lt;/code&gt; in your environment (or potentially &lt;code&gt;NCCL_CUMEM_ENABLE=1&lt;/code&gt;). Try this as your first step if you experience NCCL-related issues.&lt;/li&gt; 
 &lt;li&gt;If problems persist, please open an &lt;a href="https://github.com/willccbb/verifiers/issues"&gt;issue&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Resource Requirements&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;GRPOTrainer&lt;/code&gt; is optimized for setups with at least 2 GPUs, scaling up to multiple nodes. 2-GPU setups with sufficient memory to enable small-scale experimentation can be &lt;a href="https://app.primeintellect.ai/dashboard/create-cluster?image=ubuntu_22_cuda_12"&gt;rented&lt;/a&gt; for &amp;lt;$1/hr.&lt;/p&gt; 
&lt;h3&gt;PRIME-RL&lt;/h3&gt; 
&lt;p&gt;If you do not require LoRA support, you may want to use the &lt;code&gt;prime-rl&lt;/code&gt; trainer, which natively supports Environments created using &lt;code&gt;verifiers&lt;/code&gt;, is more optimized for performance and scalability via FSDP, includes a broader set of configuration options and user experience features, and has more battle-tested defaults. Both trainers support asynchronous rollouts, and use a one-step off-policy delay by default for overlapping training and inference. See the &lt;code&gt;prime-rl&lt;/code&gt; &lt;a href="https://github.com/PrimeIntellect-ai/prime-rl"&gt;docs&lt;/a&gt; for usage instructions.&lt;/p&gt; 
&lt;h2&gt;Further Documentation&lt;/h2&gt; 
&lt;p&gt;See the full &lt;a href="https://verifiers.readthedocs.io/en/latest/"&gt;docs&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;h2&gt;Contributions&lt;/h2&gt; 
&lt;p&gt;Verifiers warmly welcomes community contributions! Please open an issue or PR if you encounter bugs or other pain points during your development, or start a discussion for more open-ended questions.&lt;/p&gt; 
&lt;p&gt;Please note that the core &lt;code&gt;verifiers/&lt;/code&gt; library is intended to be a relatively lightweight set of reusable components rather than an exhaustive catalog of RL environments. For &lt;em&gt;applications&lt;/em&gt; of &lt;code&gt;verifiers&lt;/code&gt; (e.g. "an Environment for XYZ task"), you are welcome to submit a PR for a self-contained module that lives within &lt;code&gt;environments/&lt;/code&gt; if it serves as a canonical example of a new pattern. Stay tuned for more info shortly about our plans for supporting community Environment contributions 🙂&lt;/p&gt; 
&lt;h2&gt;Citation&lt;/h2&gt; 
&lt;p&gt;If you use this code in your research, please cite:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bibtex"&gt;@misc{brown_verifiers_2025,
  author       = {William&amp;nbsp;Brown},
  title        = {{Verifiers}: Reinforcement Learning with LLMs in Verifiable Environments},
  howpublished = {\url{https://github.com/willccbb/verifiers}},
  note         = {Commit abcdefg • accessed DD Mon YYYY},
  year         = {2025}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Roadmap&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;A community Environments hub for crowdsourcing, sharing, and discovering new RL environments built with &lt;code&gt;verifiers&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Default patterns for hosted resources such as code sandboxes, auxiliary models, and MCP servers&lt;/li&gt; 
 &lt;li&gt;Multimodal input support&lt;/li&gt; 
 &lt;li&gt;Non-increasing token sequences via REINFORCE&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>Arindam200/awesome-ai-apps</title>
      <link>https://github.com/Arindam200/awesome-ai-apps</link>
      <description>&lt;p&gt;A collection of projects showcasing RAG, agents, workflows, and other AI use cases&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Awesome AI Apps &lt;a href="https://awesome.re"&gt;&lt;img src="https://awesome.re/badge.svg?sanitize=true" alt="Awesome" /&gt;&lt;/a&gt;&lt;/h1&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Arindam200/awesome-ai-apps/main/assets/banner_new.png" alt="Banner" /&gt;&lt;/p&gt; 
&lt;p&gt;This repository is a comprehensive collection of practical examples, tutorials, and recipes for building powerful LLM-powered applications. From simple chatbots to advanced AI agents, these projects serve as a guide for developers working with various AI frameworks and tools.&lt;/p&gt; 
&lt;p&gt;Powered by &lt;a href="https://dub.sh/nebius"&gt;Nebius AI Studio&lt;/a&gt; - your one-stop platform for building and deploying AI applications.&lt;/p&gt; 
&lt;h2&gt;🚀 Featured AI Agent Frameworks&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://google.github.io/adk-docs/"&gt;&lt;img src="https://raw.githubusercontent.com/google/adk-python/main/assets/agent-development-kit.png" alt="Google ADK logo" width="20" height="20" /&gt; Google Agent Development Kit (ADK)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://openai.github.io/openai-agents-python/"&gt;&lt;img src="https://avatars.githubusercontent.com/u/14957082?s=200&amp;amp;v=4" alt="OpenAI Agents SDK logo" width="20" height="20" /&gt; OpenAI Agents SDK&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://python.langchain.com/"&gt;&lt;img src="https://cdn.simpleicons.org/langchain" alt="LangChain logo" width="25" height="25" /&gt; LangChain &lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.llamaindex.ai/"&gt;&lt;img src="https://avatars.githubusercontent.com/u/130722866?s=200&amp;amp;v=4" alt="Llamaindex logo" width="20" height="20" /&gt; LlamaIndex&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.agno.com/"&gt;&lt;img src="https://avatars.githubusercontent.com/u/104874993?s=48&amp;amp;v=4" alt="Agno logo" width="20" height="20" /&gt; Agno&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.crewai.com/"&gt;&lt;img src="https://cdn.prod.website-files.com/66cf2bfc3ed15b02da0ca770/66d07240057721394308addd_Logo%20(1).svg?sanitize=true" alt="CrewAI logo" width="35" height="25" /&gt; CrewAI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://strandsagents.com/"&gt;&lt;img src="https://avatars.githubusercontent.com/u/209155962?s=200&amp;amp;v=4" alt="AWS Strands Agents logo" width="20" height="20" /&gt; AWS Strands Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://ai.pydantic.dev/"&gt;&lt;img src="https://avatars.githubusercontent.com/u/110818415?s=200&amp;amp;v=4" alt="Pydantic AI logo" width="20" height="20" /&gt; Pydantic AI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.camel-ai.org/"&gt;&lt;img src="https://avatars.githubusercontent.com/u/134388954?s=200&amp;amp;v=4" alt="Camel AI logo" width="20" height="20" /&gt; CAMEL‑AI&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;🧩 Starter Agents&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Quick-start agents for learning and extending:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Arindam200/awesome-ai-apps/main/starter_ai_agents/agno_starter"&gt;Agno HackerNews Analysis&lt;/a&gt; - Agno-based agent for trend analysis on HackerNews.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Arindam200/awesome-ai-apps/main/starter_ai_agents/openai_agents_sdk"&gt;OpenAI SDK Starter&lt;/a&gt; - OpenAI Agents SDK based email helper &amp;amp; haiku writer.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Arindam200/awesome-ai-apps/main/starter_ai_agents/llamaindex_starter"&gt;LlamaIndex Task Manager&lt;/a&gt; - LlamaIndex-powered task assistant.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Arindam200/awesome-ai-apps/main/starter_ai_agents/crewai_starter"&gt;CrewAI Research Crew&lt;/a&gt; - Multi-agent research team.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Arindam200/awesome-ai-apps/main/starter_ai_agents/pydantic_starter"&gt;PydanticAI Weather Bot&lt;/a&gt; - Real-time weather info.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Arindam200/awesome-ai-apps/main/starter_ai_agents/langchain_langgraph_starter"&gt;LangChain-LangGraph Starter&lt;/a&gt; - LangChain + LangGraph starter.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Arindam200/awesome-ai-apps/main/starter_ai_agents/aws_strands_starter"&gt;AWS Strands Agent Starter&lt;/a&gt; - Weather report Agent.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Arindam200/awesome-ai-apps/main/starter_ai_agents/camel_ai_starter"&gt;Camel AI Starter&lt;/a&gt; - Performance benchmarking tool that compares the performance of various AI models.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;🪶 Simple Agents&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Straightforward, practical use-cases:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Arindam200/awesome-ai-apps/main/simple_ai_agents/finance_agent"&gt;Finance Agent&lt;/a&gt; - Tracks live stock &amp;amp; market data.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Arindam200/awesome-ai-apps/main/simple_ai_agents/human_in_the_loop_agent"&gt;Human-in-the-Loop Agent&lt;/a&gt; - HITL actions for safe AI tasks.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Arindam200/awesome-ai-apps/main/simple_ai_agents/newsletter_agent"&gt;Newsletter Generator&lt;/a&gt; - AI newsletter builder with Firecrawl.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Arindam200/awesome-ai-apps/main/simple_ai_agents/reasoning_agent"&gt;Reasoning Agent&lt;/a&gt; - Financial reasoning step-by-step.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Arindam200/awesome-ai-apps/main/simple_ai_agents/agno_ui_agent"&gt;Agno UI Example&lt;/a&gt; - UI for web &amp;amp; finance agents.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Arindam200/awesome-ai-apps/main/simple_ai_agents/mastra_ai_weather_agent"&gt;Mastra Weather Bot&lt;/a&gt; - Weather updates with Mastra AI.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Arindam200/awesome-ai-apps/main/simple_ai_agents/cal_scheduling_agent"&gt;Calendar Assistant&lt;/a&gt; - Calendar scheduling with Cal.com.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Arindam200/awesome-ai-apps/main/simple_ai_agents/memory_agent"&gt;Memory Agent&lt;/a&gt; - Simple Memory Agent implementation with Agno.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Arindam200/awesome-ai-apps/main/simple_ai_agents/browser_agent"&gt;Web Automation Agent&lt;/a&gt; - Simple Browser Agent implementation with Nebius &amp;amp; browser use.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Arindam200/awesome-ai-apps/main/simple_ai_agents/nebius_chat"&gt;Nebius Chat&lt;/a&gt; - Nebius AI Studio Chat interface.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Arindam200/awesome-ai-apps/main/simple_ai_agents/talk_to_db"&gt;Talk to Your DB&lt;/a&gt; - Talk to your Database with GibsonAI &amp;amp; Langchain&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Arindam200/awesome-ai-apps/main/simple_ai_agents/blog_writing_agent"&gt;Blog Writing Agent&lt;/a&gt; - Personalized AI-powered blog writing agent.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Arindam200/awesome-ai-apps/main/simple_ai_agents/arxiv_researcher_agent_with_memori"&gt;arXiv Researcher Agent&lt;/a&gt; - AI research assistant built using OpenAI Agents and GibsonAI Memori.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;🗂️ MCP Agents&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Examples using Model Context Protocol:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Arindam200/awesome-ai-apps/main/mcp_ai_agents/doc_mcp"&gt;Doc-MCP&lt;/a&gt; - Semantic RAG docs &amp;amp; Q&amp;amp;A.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Arindam200/awesome-ai-apps/main/mcp_ai_agents/langchain_langgraph_mcp_agent"&gt;LangGraph MCP Agent&lt;/a&gt; - LangChain ReAct agent with Couchbase.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Arindam200/awesome-ai-apps/main/mcp_ai_agents/github_mcp_agent"&gt;GitHub MCP Agent&lt;/a&gt; - Repo insights via MCP.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Arindam200/awesome-ai-apps/main/mcp_ai_agents/mcp_starter"&gt;MCP Starter&lt;/a&gt; - GitHub repo analyzer starter.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Arindam200/awesome-ai-apps/main/mcp_ai_agents/docs_qna_agent"&gt;Talk to your Docs&lt;/a&gt; - Documentation QnA Agent&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;📚 RAG Applications&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Retrieve-augmented generation examples:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Arindam200/awesome-ai-apps/main/rag_apps/agentic_rag"&gt;Agentic RAG&lt;/a&gt; - Agentic RAG with Agno &amp;amp; GPT 5.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Arindam200/awesome-ai-apps/main/rag_apps/resume_optimizer"&gt;Resume Optimizer&lt;/a&gt; - Boost resumes with AI.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Arindam200/awesome-ai-apps/main/rag_apps/llamaIndex_starter"&gt;LlamaIndex RAG Starter&lt;/a&gt; - LlamaIndex + Nebius RAG starter.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Arindam200/awesome-ai-apps/main/rag_apps/pdf_rag_analyser"&gt;PDF RAG Analyzer&lt;/a&gt; - Chat with multiple PDFs.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Arindam200/awesome-ai-apps/main/rag_apps/qwen3_rag"&gt;Qwen3 RAG Chat&lt;/a&gt; - PDF chatbot with Streamlit.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Arindam200/awesome-ai-apps/main/rag_apps/chat_with_code"&gt;Chat with Code&lt;/a&gt; - Conversational code explorer.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Arindam200/awesome-ai-apps/main/rag_apps/gemma_ocr/"&gt;Gemma3 OCR&lt;/a&gt; - OCR-based document and image processor using Gemma3&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;🔬 Advanced Agents&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Complex pipelines for end-to-end workflows:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Arindam200/awesome-ai-apps/main/advance_ai_agents/deep_researcher_agent"&gt;Deep Researcher&lt;/a&gt; - Multi-stage research with Agno &amp;amp; Scrapegraph AI.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Arindam200/awesome-ai-apps/main/advance_ai_agents/candidate_analyser"&gt;Candilyzer&lt;/a&gt; - Analyze GitHub/LinkedIn profiles.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Arindam200/awesome-ai-apps/main/advance_ai_agents/job_finder_agent"&gt;Job Finder&lt;/a&gt; - LinkedIn job search with Bright Data.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Arindam200/awesome-ai-apps/main/advance_ai_agents/trend_analyzer_agent"&gt;AI Trend Analyzer&lt;/a&gt; - AI trend mining with Google ADK.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Arindam200/awesome-ai-apps/main/advance_ai_agents/conference_talk_abstract_generator"&gt;Conference Talk Generator&lt;/a&gt; - Draft talk abstracts with Google ADK &amp;amp; Couchbase.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Arindam200/awesome-ai-apps/main/advance_ai_agents/finance_service_agent"&gt;Finance Service Agent&lt;/a&gt; - FastAPI server for stock data and predictions with Agno.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Arindam200/awesome-ai-apps/main/advance_ai_agents/price_monitoring_agent"&gt;Price Monitoring Agent&lt;/a&gt; - Price monitoring and alerting Agent powered by CrewAi, Twilio &amp;amp; Nebius.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Arindam200/awesome-ai-apps/main/advance_ai_agents/startup_idea_validator_agent"&gt;Startup Idea Validator Agent&lt;/a&gt; - Agentic Workflow to validate and analyze startup ideas.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;📺 Playlist of Demo Videos &amp;amp; Tutorials&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/playlist?list=PLMZM1DAlf0Lolxax4L2HS54Me8gn1gkz4"&gt;Build with MCP&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/playlist?list=PLMZM1DAlf0LqixhAG9BDk4O_FjqnaogK8"&gt;Build AI Agents&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/playlist?list=PL2ambAOfYA6-LDz0KpVKu9vJKAqhv0KKI"&gt;AI Agents, MCP and more...&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;h3&gt;Prerequisites&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Python 3.10 or higher&lt;/li&gt; 
 &lt;li&gt;Git&lt;/li&gt; 
 &lt;li&gt;pip (Python package manager) or uv&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Installation Steps&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Clone the repository&lt;/strong&gt;&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/Arindam200/awesome-ai-apps.git
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Navigate to the desired project directory&lt;/strong&gt;&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;cd awesome-ai-apps/starter_ai_agents/agno_starter
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Install the required dependencies&lt;/strong&gt;&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;pip install -r requirements.txt
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Follow project-specific instructions&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Each project has its own README.md with detailed setup and usage instructions&lt;/li&gt; 
   &lt;li&gt;Make sure to read the project-specific documentation before running the application&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;🤝 Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome contributions from the community! Whether you're a beginner or an expert, your examples and tutorials can help others learn and grow. Here's how you can contribute:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Submit a Pull Request with your LLM application example&lt;/li&gt; 
 &lt;li&gt;Add detailed documentation and setup instructions&lt;/li&gt; 
 &lt;li&gt;Include requirements.txt or environment.yml&lt;/li&gt; 
 &lt;li&gt;Share your experience and best practices&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;📜 License&lt;/h2&gt; 
&lt;p&gt;This repository is licensed under the &lt;a href="https://raw.githubusercontent.com/Arindam200/awesome-ai-apps/main/LICENSE"&gt;MIT License&lt;/a&gt;. Feel free to use and modify the examples for your projects.&lt;/p&gt; 
&lt;h2&gt;Thank You for the Support! 🙏&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://www.star-history.com/#Arindam200/awesome-ai-apps&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=Arindam200/awesome-ai-apps&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>microsoft/qlib</title>
      <link>https://github.com/microsoft/qlib</link>
      <description>&lt;p&gt;Qlib is an AI-oriented Quant investment platform that aims to use AI tech to empower Quant Research, from exploring ideas to implementing productions. Qlib supports diverse ML modeling paradigms, including supervised learning, market dynamics modeling, and RL, and is now equipped with https://github.com/microsoft/RD-Agent to automate R&amp;D process.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href="https://pypi.org/project/pyqlib/#files"&gt;&lt;img src="https://img.shields.io/pypi/pyversions/pyqlib.svg?logo=python&amp;amp;logoColor=white" alt="Python Versions" /&gt;&lt;/a&gt; &lt;a href="https://pypi.org/project/pyqlib/#files"&gt;&lt;img src="https://img.shields.io/badge/platform-linux%20%7C%20windows%20%7C%20macos-lightgrey" alt="Platform" /&gt;&lt;/a&gt; &lt;a href="https://pypi.org/project/pyqlib/#history"&gt;&lt;img src="https://img.shields.io/pypi/v/pyqlib" alt="PypI Versions" /&gt;&lt;/a&gt; &lt;a href="https://pypi.org/project/pyqlib/"&gt;&lt;img src="https://github.com/microsoft/qlib/workflows/Upload%20Python%20Package/badge.svg?sanitize=true" alt="Upload Python Package" /&gt;&lt;/a&gt; &lt;a href="https://github.com/microsoft/qlib/actions"&gt;&lt;img src="https://github.com/microsoft/qlib/workflows/Test/badge.svg?branch=main" alt="Github Actions Test Status" /&gt;&lt;/a&gt; &lt;a href="https://qlib.readthedocs.io/en/latest/?badge=latest"&gt;&lt;img src="https://readthedocs.org/projects/qlib/badge/?version=latest" alt="Documentation Status" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/LICENSE"&gt;&lt;img src="https://img.shields.io/pypi/l/pyqlib" alt="License" /&gt;&lt;/a&gt; &lt;a href="https://gitter.im/Microsoft/qlib?utm_source=badge&amp;amp;utm_medium=badge&amp;amp;utm_campaign=pr-badge&amp;amp;utm_content=badge"&gt;&lt;img src="https://badges.gitter.im/Microsoft/qlib.svg?sanitize=true" alt="Join the chat at https://gitter.im/Microsoft/qlib" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;&lt;span&gt;📰&lt;/span&gt; &lt;strong&gt;What's NEW!&lt;/strong&gt; &amp;nbsp; &lt;span&gt;💖&lt;/span&gt;&lt;/h2&gt; 
&lt;p&gt;Recent released features&lt;/p&gt; 
&lt;h3&gt;Introducing &lt;a href="https://github.com/microsoft/RD-Agent"&gt;&lt;img src="https://raw.githubusercontent.com/microsoft/qlib/main/docs/_static/img/rdagent_logo.png" alt="RD_Agent" style="height: 2em" /&gt;&lt;/a&gt;: LLM-Based Autonomous Evolving Agents for Industrial Data-Driven R&amp;amp;D&lt;/h3&gt; 
&lt;p&gt;We are excited to announce the release of &lt;strong&gt;RD-Agent&lt;/strong&gt;📢, a powerful tool that supports automated factor mining and model optimization in quant investment R&amp;amp;D.&lt;/p&gt; 
&lt;p&gt;RD-Agent is now available on &lt;a href="https://github.com/microsoft/RD-Agent"&gt;GitHub&lt;/a&gt;, and we welcome your star🌟!&lt;/p&gt; 
&lt;p&gt;To learn more, please visit our &lt;a href="https://rdagent.azurewebsites.net/"&gt;♾️Demo page&lt;/a&gt;. Here, you will find demo videos in both English and Chinese to help you better understand the scenario and usage of RD-Agent.&lt;/p&gt; 
&lt;p&gt;We have prepared several demo videos for you:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Scenario&lt;/th&gt; 
   &lt;th&gt;Demo video (English)&lt;/th&gt; 
   &lt;th&gt;Demo video (中文)&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Quant Factor Mining&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://rdagent.azurewebsites.net/factor_loop?lang=en"&gt;Link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://rdagent.azurewebsites.net/factor_loop?lang=zh"&gt;Link&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Quant Factor Mining from reports&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://rdagent.azurewebsites.net/report_factor?lang=en"&gt;Link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://rdagent.azurewebsites.net/report_factor?lang=zh"&gt;Link&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Quant Model Optimization&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://rdagent.azurewebsites.net/model_loop?lang=en"&gt;Link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://rdagent.azurewebsites.net/model_loop?lang=zh"&gt;Link&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;ul&gt; 
 &lt;li&gt;📃&lt;strong&gt;Paper&lt;/strong&gt;: &lt;a href="https://arxiv.org/abs/2505.15155"&gt;R&amp;amp;D-Agent-Quant: A Multi-Agent Framework for Data-Centric Factors and Model Joint Optimization&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;👾&lt;strong&gt;Code&lt;/strong&gt;: &lt;a href="https://github.com/microsoft/RD-Agent/"&gt;https://github.com/microsoft/RD-Agent/&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-BibTeX"&gt;@misc{li2025rdagentquant,
    title={R\&amp;amp;D-Agent-Quant: A Multi-Agent Framework for Data-Centric Factors and Model Joint Optimization},
    author={Yuante Li and Xu Yang and Xiao Yang and Minrui Xu and Xisen Wang and Weiqing Liu and Jiang Bian},
    year={2025},
    eprint={2505.15155},
    archivePrefix={arXiv},
    primaryClass={cs.AI}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/3198bc10-47ba-4ee0-8a8e-46d5ce44f45d" alt="image" /&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Feature&lt;/th&gt; 
   &lt;th&gt;Status&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://arxiv.org/abs/2505.15155"&gt;R&amp;amp;D-Agent-Quant&lt;/a&gt; Published&lt;/td&gt; 
   &lt;td&gt;Apply R&amp;amp;D-Agent to Qlib for quant trading&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BPQP for End-to-end learning&lt;/td&gt; 
   &lt;td&gt;📈Coming soon!(&lt;a href="https://github.com/microsoft/qlib/pull/1863"&gt;Under review&lt;/a&gt;)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;🔥LLM-driven Auto Quant Factory🔥&lt;/td&gt; 
   &lt;td&gt;🚀 Released in &lt;a href="https://github.com/microsoft/RD-Agent"&gt;♾️RD-Agent&lt;/a&gt; on Aug 8, 2024&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;KRNN and Sandwich models&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;📈&lt;/span&gt; &lt;a href="https://github.com/microsoft/qlib/pull/1414/"&gt;Released&lt;/a&gt; on May 26, 2023&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Release Qlib v0.9.0&lt;/td&gt; 
   &lt;td&gt;&lt;img alt="octocat" src="https://github.githubassets.com/images/icons/emoji/octocat.png?v8" /&gt;) &lt;a href="https://github.com/microsoft/qlib/releases/tag/v0.9.0"&gt;Released&lt;/a&gt; on Dec 9, 2022&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;RL Learning Framework&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;🔨&lt;/span&gt; &lt;span&gt;📈&lt;/span&gt; Released on Nov 10, 2022. &lt;a href="https://github.com/microsoft/qlib/pull/1332"&gt;#1332&lt;/a&gt;, &lt;a href="https://github.com/microsoft/qlib/pull/1322"&gt;#1322&lt;/a&gt;, &lt;a href="https://github.com/microsoft/qlib/pull/1316"&gt;#1316&lt;/a&gt;,&lt;a href="https://github.com/microsoft/qlib/pull/1299"&gt;#1299&lt;/a&gt;,&lt;a href="https://github.com/microsoft/qlib/pull/1263"&gt;#1263&lt;/a&gt;, &lt;a href="https://github.com/microsoft/qlib/pull/1244"&gt;#1244&lt;/a&gt;, &lt;a href="https://github.com/microsoft/qlib/pull/1169"&gt;#1169&lt;/a&gt;, &lt;a href="https://github.com/microsoft/qlib/pull/1125"&gt;#1125&lt;/a&gt;, &lt;a href="https://github.com/microsoft/qlib/pull/1076"&gt;#1076&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;HIST and IGMTF models&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;📈&lt;/span&gt; &lt;a href="https://github.com/microsoft/qlib/pull/1040"&gt;Released&lt;/a&gt; on Apr 10, 2022&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Qlib &lt;a href="https://github.com/microsoft/qlib/tree/main/examples/tutorial"&gt;notebook tutorial&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;📖 &lt;a href="https://github.com/microsoft/qlib/pull/1037"&gt;Released&lt;/a&gt; on Apr 7, 2022&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Ibovespa index data&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;🍚&lt;/span&gt; &lt;a href="https://github.com/microsoft/qlib/pull/990"&gt;Released&lt;/a&gt; on Apr 6, 2022&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Point-in-Time database&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;🔨&lt;/span&gt; &lt;a href="https://github.com/microsoft/qlib/pull/343"&gt;Released&lt;/a&gt; on Mar 10, 2022&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Arctic Provider Backend &amp;amp; Orderbook data example&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;🔨&lt;/span&gt; &lt;a href="https://github.com/microsoft/qlib/pull/744"&gt;Released&lt;/a&gt; on Jan 17, 2022&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Meta-Learning-based framework &amp;amp; DDG-DA&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;📈&lt;/span&gt; &lt;span&gt;🔨&lt;/span&gt; &lt;a href="https://github.com/microsoft/qlib/pull/743"&gt;Released&lt;/a&gt; on Jan 10, 2022&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Planning-based portfolio optimization&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;🔨&lt;/span&gt; &lt;a href="https://github.com/microsoft/qlib/pull/754"&gt;Released&lt;/a&gt; on Dec 28, 2021&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Release Qlib v0.8.0&lt;/td&gt; 
   &lt;td&gt;&lt;img alt="octocat" src="https://github.githubassets.com/images/icons/emoji/octocat.png?v8" /&gt;) &lt;a href="https://github.com/microsoft/qlib/releases/tag/v0.8.0"&gt;Released&lt;/a&gt; on Dec 8, 2021&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ADD model&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;📈&lt;/span&gt; &lt;a href="https://github.com/microsoft/qlib/pull/704"&gt;Released&lt;/a&gt; on Nov 22, 2021&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ADARNN model&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;📈&lt;/span&gt; &lt;a href="https://github.com/microsoft/qlib/pull/689"&gt;Released&lt;/a&gt; on Nov 14, 2021&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;TCN model&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;📈&lt;/span&gt; &lt;a href="https://github.com/microsoft/qlib/pull/668"&gt;Released&lt;/a&gt; on Nov 4, 2021&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Nested Decision Framework&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;🔨&lt;/span&gt; &lt;a href="https://github.com/microsoft/qlib/pull/438"&gt;Released&lt;/a&gt; on Oct 1, 2021. &lt;a href="https://github.com/microsoft/qlib/raw/main/examples/nested_decision_execution/workflow.py"&gt;Example&lt;/a&gt; and &lt;a href="https://qlib.readthedocs.io/en/latest/component/highfreq.html"&gt;Doc&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Temporal Routing Adaptor (TRA)&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;📈&lt;/span&gt; &lt;a href="https://github.com/microsoft/qlib/pull/531"&gt;Released&lt;/a&gt; on July 30, 2021&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Transformer &amp;amp; Localformer&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;📈&lt;/span&gt; &lt;a href="https://github.com/microsoft/qlib/pull/508"&gt;Released&lt;/a&gt; on July 22, 2021&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Release Qlib v0.7.0&lt;/td&gt; 
   &lt;td&gt;&lt;img alt="octocat" src="https://github.githubassets.com/images/icons/emoji/octocat.png?v8" /&gt;) &lt;a href="https://github.com/microsoft/qlib/releases/tag/v0.7.0"&gt;Released&lt;/a&gt; on July 12, 2021&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;TCTS Model&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;📈&lt;/span&gt; &lt;a href="https://github.com/microsoft/qlib/pull/491"&gt;Released&lt;/a&gt; on July 1, 2021&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Online serving and automatic model rolling&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;🔨&lt;/span&gt; &lt;a href="https://github.com/microsoft/qlib/pull/290"&gt;Released&lt;/a&gt; on May 17, 2021&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;DoubleEnsemble Model&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;📈&lt;/span&gt; &lt;a href="https://github.com/microsoft/qlib/pull/286"&gt;Released&lt;/a&gt; on Mar 2, 2021&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;High-frequency data processing example&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;🔨&lt;/span&gt; &lt;a href="https://github.com/microsoft/qlib/pull/257"&gt;Released&lt;/a&gt; on Feb 5, 2021&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;High-frequency trading example&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;📈&lt;/span&gt; &lt;a href="https://github.com/microsoft/qlib/pull/227"&gt;Part of code released&lt;/a&gt; on Jan 28, 2021&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;High-frequency data(1min)&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;🍚&lt;/span&gt; &lt;a href="https://github.com/microsoft/qlib/pull/221"&gt;Released&lt;/a&gt; on Jan 27, 2021&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Tabnet Model&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;📈&lt;/span&gt; &lt;a href="https://github.com/microsoft/qlib/pull/205"&gt;Released&lt;/a&gt; on Jan 22, 2021&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Features released before 2021 are not listed here.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/microsoft/qlib/main/docs/_static/img/logo/1.png" /&gt; &lt;/p&gt; 
&lt;p&gt;Qlib is an open-source, AI-oriented quantitative investment platform that aims to realize the potential, empower research, and create value using AI technologies in quantitative investment, from exploring ideas to implementing productions. Qlib supports diverse machine learning modeling paradigms, including supervised learning, market dynamics modeling, and reinforcement learning.&lt;/p&gt; 
&lt;p&gt;An increasing number of SOTA Quant research works/papers in diverse paradigms are being released in Qlib to collaboratively solve key challenges in quantitative investment. For example, 1) using supervised learning to mine the market's complex non-linear patterns from rich and heterogeneous financial data, 2) modeling the dynamic nature of the financial market using adaptive concept drift technology, and 3) using reinforcement learning to model continuous investment decisions and assist investors in optimizing their trading strategies.&lt;/p&gt; 
&lt;p&gt;It contains the full ML pipeline of data processing, model training, back-testing; and covers the entire chain of quantitative investment: alpha seeking, risk modeling, portfolio optimization, and order execution. For more details, please refer to our paper &lt;a href="https://arxiv.org/abs/2009.11189"&gt;"Qlib: An AI-oriented Quantitative Investment Platform"&lt;/a&gt;.&lt;/p&gt; 
&lt;table&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Frameworks, Tutorial, Data &amp;amp; DevOps&lt;/th&gt; 
   &lt;th&gt;Main Challenges &amp;amp; Solutions in Quant Research&lt;/th&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/#plans"&gt;&lt;strong&gt;Plans&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/#framework-of-qlib"&gt;Framework of Qlib&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/#quick-start"&gt;Quick Start&lt;/a&gt;&lt;/li&gt; 
    &lt;ul dir="auto"&gt; 
     &lt;li type="circle"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/#installation"&gt;Installation&lt;/a&gt; &lt;/li&gt; 
     &lt;li type="circle"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/#data-preparation"&gt;Data Preparation&lt;/a&gt;&lt;/li&gt; 
     &lt;li type="circle"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/#auto-quant-research-workflow"&gt;Auto Quant Research Workflow&lt;/a&gt;&lt;/li&gt; 
     &lt;li type="circle"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/#building-customized-quant-research-workflow-by-code"&gt;Building Customized Quant Research Workflow by Code&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt; &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/#quant-dataset-zoo"&gt;&lt;strong&gt;Quant Dataset Zoo&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/#learning-framework"&gt;Learning Framework&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/#more-about-qlib"&gt;More About Qlib&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/#offline-mode-and-online-mode"&gt;Offline Mode and Online Mode&lt;/a&gt; 
     &lt;ul&gt; 
      &lt;li type="circle"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/#performance-of-qlib-data-server"&gt;Performance of Qlib Data Server&lt;/a&gt;&lt;/li&gt;
     &lt;/ul&gt; &lt;/li&gt;&lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/#related-reports"&gt;Related Reports&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/#contact-us"&gt;Contact Us&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/#contributing"&gt;Contributing&lt;/a&gt;&lt;/li&gt; &lt;/td&gt; 
   &lt;td valign="baseline"&gt; &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/#main-challenges--solutions-in-quant-research"&gt;Main Challenges &amp;amp; Solutions in Quant Research&lt;/a&gt; 
     &lt;ul&gt; 
      &lt;li type="circle"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/#forecasting-finding-valuable-signalspatterns"&gt;Forecasting: Finding Valuable Signals/Patterns&lt;/a&gt; 
       &lt;ul&gt; 
        &lt;li type="disc"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/#quant-model-paper-zoo"&gt;&lt;strong&gt;Quant Model (Paper) Zoo&lt;/strong&gt;&lt;/a&gt; 
         &lt;ul&gt; 
          &lt;li type="circle"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/#run-a-single-model"&gt;Run a Single Model&lt;/a&gt;&lt;/li&gt; 
          &lt;li type="circle"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/#run-multiple-models"&gt;Run Multiple Models&lt;/a&gt;&lt;/li&gt; 
         &lt;/ul&gt; &lt;/li&gt; 
       &lt;/ul&gt; &lt;/li&gt; 
      &lt;li type="circle"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/#adapting-to-market-dynamics"&gt;Adapting to Market Dynamics&lt;/a&gt;&lt;/li&gt; 
      &lt;li type="circle"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/#reinforcement-learning-modeling-continuous-decisions"&gt;Reinforcement Learning: modeling continuous decisions&lt;/a&gt;&lt;/li&gt; 
     &lt;/ul&gt; &lt;/li&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h1&gt;Plans&lt;/h1&gt; 
&lt;p&gt;New features under development(order by estimated release time). Your feedbacks about the features are very important.&lt;/p&gt; 
&lt;!-- | Feature                        | Status      | --&gt; 
&lt;!-- | --                      | ------    | --&gt; 
&lt;h1&gt;Framework of Qlib&lt;/h1&gt; 
&lt;div style="align: center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/microsoft/qlib/main/docs/_static/img/framework-abstract.jpg" /&gt; 
&lt;/div&gt; 
&lt;p&gt;The high-level framework of Qlib can be found above(users can find the &lt;a href="https://qlib.readthedocs.io/en/latest/introduction/introduction.html#framework"&gt;detailed framework&lt;/a&gt; of Qlib's design when getting into nitty gritty). The components are designed as loose-coupled modules, and each component could be used stand-alone.&lt;/p&gt; 
&lt;p&gt;Qlib provides a strong infrastructure to support Quant research. &lt;a href="https://qlib.readthedocs.io/en/latest/component/data.html"&gt;Data&lt;/a&gt; is always an important part. A strong learning framework is designed to support diverse learning paradigms (e.g. &lt;a href="https://qlib.readthedocs.io/en/latest/component/rl.html"&gt;reinforcement learning&lt;/a&gt;, &lt;a href="https://qlib.readthedocs.io/en/latest/component/workflow.html#model-section"&gt;supervised learning&lt;/a&gt;) and patterns at different levels(e.g. &lt;a href="https://qlib.readthedocs.io/en/latest/component/meta.html"&gt;market dynamic modeling&lt;/a&gt;). By modeling the market, &lt;a href="https://qlib.readthedocs.io/en/latest/component/strategy.html"&gt;trading strategies&lt;/a&gt; will generate trade decisions that will be executed. Multiple trading strategies and executors in different levels or granularities can be &lt;a href="https://qlib.readthedocs.io/en/latest/component/highfreq.html"&gt;nested to be optimized and run together&lt;/a&gt;. At last, a comprehensive &lt;a href="https://qlib.readthedocs.io/en/latest/component/report.html"&gt;analysis&lt;/a&gt; will be provided and the model can be &lt;a href="https://qlib.readthedocs.io/en/latest/component/online.html"&gt;served online&lt;/a&gt; in a low cost.&lt;/p&gt; 
&lt;h1&gt;Quick Start&lt;/h1&gt; 
&lt;p&gt;This quick start guide tries to demonstrate&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;It's very easy to build a complete Quant research workflow and try your ideas with &lt;em&gt;Qlib&lt;/em&gt;.&lt;/li&gt; 
 &lt;li&gt;Though with &lt;em&gt;public data&lt;/em&gt; and &lt;em&gt;simple models&lt;/em&gt;, machine learning technologies &lt;strong&gt;work very well&lt;/strong&gt; in practical Quant investment.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Here is a quick &lt;strong&gt;&lt;a href="https://terminalizer.com/view/3f24561a4470"&gt;demo&lt;/a&gt;&lt;/strong&gt; shows how to install &lt;code&gt;Qlib&lt;/code&gt;, and run LightGBM with &lt;code&gt;qrun&lt;/code&gt;. &lt;strong&gt;But&lt;/strong&gt;, please make sure you have already prepared the data following the &lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/#data-preparation"&gt;instruction&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;This table demonstrates the supported Python version of &lt;code&gt;Qlib&lt;/code&gt;:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;&lt;/th&gt; 
   &lt;th align="center"&gt;install with pip&lt;/th&gt; 
   &lt;th align="center"&gt;install from source&lt;/th&gt; 
   &lt;th align="center"&gt;plot&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Python 3.8&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;span&gt;✔&lt;/span&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;span&gt;✔&lt;/span&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;span&gt;✔&lt;/span&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Python 3.9&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;span&gt;✔&lt;/span&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;span&gt;✔&lt;/span&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;span&gt;✔&lt;/span&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Python 3.10&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;span&gt;✔&lt;/span&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;span&gt;✔&lt;/span&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;span&gt;✔&lt;/span&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Python 3.11&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;span&gt;✔&lt;/span&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;span&gt;✔&lt;/span&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;span&gt;✔&lt;/span&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Python 3.12&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;span&gt;✔&lt;/span&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;span&gt;✔&lt;/span&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;span&gt;✔&lt;/span&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Conda&lt;/strong&gt; is suggested for managing your Python environment. In some cases, using Python outside of a &lt;code&gt;conda&lt;/code&gt; environment may result in missing header files, causing the installation failure of certain packages.&lt;/li&gt; 
 &lt;li&gt;Please pay attention that installing cython in Python 3.6 will raise some error when installing &lt;code&gt;Qlib&lt;/code&gt; from source. If users use Python 3.6 on their machines, it is recommended to &lt;em&gt;upgrade&lt;/em&gt; Python to version 3.8 or higher, or use &lt;code&gt;conda&lt;/code&gt;'s Python to install &lt;code&gt;Qlib&lt;/code&gt; from source.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Install with pip&lt;/h3&gt; 
&lt;p&gt;Users can easily install &lt;code&gt;Qlib&lt;/code&gt; by pip according to the following command.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;  pip install pyqlib
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: pip will install the latest stable qlib. However, the main branch of qlib is in active development. If you want to test the latest scripts or functions in the main branch. Please install qlib with the methods below.&lt;/p&gt; 
&lt;h3&gt;Install from source&lt;/h3&gt; 
&lt;p&gt;Also, users can install the latest dev version &lt;code&gt;Qlib&lt;/code&gt; by the source code according to the following steps:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Before installing &lt;code&gt;Qlib&lt;/code&gt; from source, users need to install some dependencies:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;pip install numpy
pip install --upgrade cython
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Clone the repository and install &lt;code&gt;Qlib&lt;/code&gt; as follows.&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/microsoft/qlib.git &amp;amp;&amp;amp; cd qlib
pip install .  # `pip install -e .[dev]` is recommended for development. check details in docs/developer/code_standard_and_dev_guide.rst
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Tips&lt;/strong&gt;: If you fail to install &lt;code&gt;Qlib&lt;/code&gt; or run the examples in your environment, comparing your steps and the &lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/.github/workflows/test_qlib_from_source.yml"&gt;CI workflow&lt;/a&gt; may help you find the problem.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Tips for Mac&lt;/strong&gt;: If you are using Mac with M1, you might encounter issues in building the wheel for LightGBM, which is due to missing dependencies from OpenMP. To solve the problem, install openmp first with &lt;code&gt;brew install libomp&lt;/code&gt; and then run &lt;code&gt;pip install .&lt;/code&gt; to build it successfully.&lt;/p&gt; 
&lt;h2&gt;Data Preparation&lt;/h2&gt; 
&lt;p&gt;❗ Due to more restrict data security policy. The official dataset is disabled temporarily. You can try &lt;a href="https://github.com/chenditc/investment_data/releases"&gt;this data source&lt;/a&gt; contributed by the community. Here is an example to download the latest data.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;wget https://github.com/chenditc/investment_data/releases/latest/download/qlib_bin.tar.gz
mkdir -p ~/.qlib/qlib_data/cn_data
tar -zxvf qlib_bin.tar.gz -C ~/.qlib/qlib_data/cn_data --strip-components=1
rm -f qlib_bin.tar.gz
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The official dataset below will resume in short future.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;Load and prepare data by running the following code:&lt;/p&gt; 
&lt;h3&gt;Get with module&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# get 1d data
python -m qlib.cli.data qlib_data --target_dir ~/.qlib/qlib_data/cn_data --region cn

# get 1min data
python -m qlib.cli.data qlib_data --target_dir ~/.qlib/qlib_data/cn_data_1min --region cn --interval 1min

&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Get from source&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# get 1d data
python scripts/get_data.py qlib_data --target_dir ~/.qlib/qlib_data/cn_data --region cn

# get 1min data
python scripts/get_data.py qlib_data --target_dir ~/.qlib/qlib_data/cn_data_1min --region cn --interval 1min

&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This dataset is created by public data collected by &lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/scripts/data_collector/"&gt;crawler scripts&lt;/a&gt;, which have been released in the same repository. Users could create the same dataset with it. &lt;a href="https://github.com/microsoft/qlib/tree/main/scripts/data_collector#description-of-dataset"&gt;Description of dataset&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;Please pay &lt;strong&gt;ATTENTION&lt;/strong&gt; that the data is collected from &lt;a href="https://finance.yahoo.com/lookup"&gt;Yahoo Finance&lt;/a&gt;, and the data might not be perfect. We recommend users to prepare their own data if they have a high-quality dataset. For more information, users can refer to the &lt;a href="https://qlib.readthedocs.io/en/latest/component/data.html#converting-csv-format-into-qlib-format"&gt;related document&lt;/a&gt;&lt;/em&gt;.&lt;/p&gt; 
&lt;h3&gt;Automatic update of daily frequency data (from yahoo finance)&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;This step is &lt;em&gt;Optional&lt;/em&gt; if users only want to try their models and strategies on history data.&lt;/p&gt; 
 &lt;p&gt;It is recommended that users update the data manually once (--trading_date 2021-05-25) and then set it to update automatically.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: Users can't incrementally update data based on the offline data provided by Qlib(some fields are removed to reduce the data size). Users should use &lt;a href="https://github.com/microsoft/qlib/tree/main/scripts/data_collector/yahoo#automatic-update-of-daily-frequency-datafrom-yahoo-finance"&gt;yahoo collector&lt;/a&gt; to download Yahoo data from scratch and then incrementally update it.&lt;/p&gt; 
 &lt;p&gt;For more information, please refer to: &lt;a href="https://github.com/microsoft/qlib/tree/main/scripts/data_collector/yahoo#automatic-update-of-daily-frequency-datafrom-yahoo-finance"&gt;yahoo collector&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Automatic update of data to the "qlib" directory each trading day(Linux)&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;use &lt;em&gt;crontab&lt;/em&gt;: &lt;code&gt;crontab -e&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;set up timed tasks:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;* * * * 1-5 python &amp;lt;script path&amp;gt; update_data_to_bin --qlib_data_1d_dir &amp;lt;user data dir&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;strong&gt;script path&lt;/strong&gt;: &lt;em&gt;scripts/data_collector/yahoo/collector.py&lt;/em&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Manual update of data&lt;/p&gt; &lt;pre&gt;&lt;code&gt;python scripts/data_collector/yahoo/collector.py update_data_to_bin --qlib_data_1d_dir &amp;lt;user data dir&amp;gt; --trading_date &amp;lt;start date&amp;gt; --end_date &amp;lt;end date&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;em&gt;trading_date&lt;/em&gt;: start of trading day&lt;/li&gt; 
   &lt;li&gt;&lt;em&gt;end_date&lt;/em&gt;: end of trading day(not included)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Checking the health of the data&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;We provide a script to check the health of the data, you can run the following commands to check whether the data is healthy or not. &lt;pre&gt;&lt;code&gt;python scripts/check_data_health.py check_data --qlib_dir ~/.qlib/qlib_data/cn_data
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;Of course, you can also add some parameters to adjust the test results, such as this. &lt;pre&gt;&lt;code&gt;python scripts/check_data_health.py check_data --qlib_dir ~/.qlib/qlib_data/cn_data --missing_data_num 30055 --large_step_threshold_volume 94485 --large_step_threshold_price 20
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;If you want more information about &lt;code&gt;check_data_health&lt;/code&gt;, please refer to the &lt;a href="https://qlib.readthedocs.io/en/latest/component/data.html#checking-the-health-of-the-data"&gt;documentation&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;!-- 
- Run the initialization code and get stock data:

  ```python
  import qlib
  from qlib.data import D
  from qlib.constant import REG_CN

  # Initialization
  mount_path = "~/.qlib/qlib_data/cn_data"  # target_dir
  qlib.init(mount_path=mount_path, region=REG_CN)

  # Get stock data by Qlib
  # Load trading calendar with the given time range and frequency
  print(D.calendar(start_time='2010-01-01', end_time='2017-12-31', freq='day')[:2])

  # Parse a given market name into a stockpool config
  instruments = D.instruments('csi500')
  print(D.list_instruments(instruments=instruments, start_time='2010-01-01', end_time='2017-12-31', as_list=True)[:6])

  # Load features of certain instruments in given time range
  instruments = ['SH600000']
  fields = ['$close', '$volume', 'Ref($close, 1)', 'Mean($close, 3)', '$high-$low']
  print(D.features(instruments, fields, start_time='2010-01-01', end_time='2017-12-31', freq='day').head())
  ```
 --&gt; 
&lt;h2&gt;Docker images&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;Pulling a docker image from a docker hub repository &lt;pre&gt;&lt;code class="language-bash"&gt;docker pull pyqlib/qlib_image_stable:stable
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;Start a new Docker container &lt;pre&gt;&lt;code class="language-bash"&gt;docker run -it --name &amp;lt;container name&amp;gt; -v &amp;lt;Mounted local directory&amp;gt;:/app qlib_image_stable
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;At this point you are in the docker environment and can run the qlib scripts. An example: &lt;pre&gt;&lt;code class="language-bash"&gt;&amp;gt;&amp;gt;&amp;gt; python scripts/get_data.py qlib_data --name qlib_data_simple --target_dir ~/.qlib/qlib_data/cn_data --interval 1d --region cn
&amp;gt;&amp;gt;&amp;gt; python qlib/cli/run.py examples/benchmarks/LightGBM/workflow_config_lightgbm_Alpha158.yaml
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;Exit the container &lt;pre&gt;&lt;code class="language-bash"&gt;&amp;gt;&amp;gt;&amp;gt; exit
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;Restart the container &lt;pre&gt;&lt;code class="language-bash"&gt;docker start -i -a &amp;lt;container name&amp;gt;
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;Stop the container &lt;pre&gt;&lt;code class="language-bash"&gt;docker stop &amp;lt;container name&amp;gt;
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;Delete the container &lt;pre&gt;&lt;code class="language-bash"&gt;docker rm &amp;lt;container name&amp;gt;
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;If you want to know more information, please refer to the &lt;a href="https://qlib.readthedocs.io/en/latest/developer/how_to_build_image.html"&gt;documentation&lt;/a&gt;.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Auto Quant Research Workflow&lt;/h2&gt; 
&lt;p&gt;Qlib provides a tool named &lt;code&gt;qrun&lt;/code&gt; to run the whole workflow automatically (including building dataset, training models, backtest and evaluation). You can start an auto quant research workflow and have a graphical reports analysis according to the following steps:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Quant Research Workflow: Run &lt;code&gt;qrun&lt;/code&gt; with lightgbm workflow config (&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/benchmarks/LightGBM/workflow_config_lightgbm_Alpha158.yaml"&gt;workflow_config_lightgbm_Alpha158.yaml&lt;/a&gt; as following.&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;  cd examples  # Avoid running program under the directory contains `qlib`
  qrun benchmarks/LightGBM/workflow_config_lightgbm_Alpha158.yaml
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;If users want to use &lt;code&gt;qrun&lt;/code&gt; under debug mode, please use the following command:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;python -m pdb qlib/cli/run.py examples/benchmarks/LightGBM/workflow_config_lightgbm_Alpha158.yaml
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The result of &lt;code&gt;qrun&lt;/code&gt; is as follows, please refer to &lt;a href="https://qlib.readthedocs.io/en/latest/component/strategy.html#result"&gt;docs&lt;/a&gt; for more explanations about the result.&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;
'The following are analysis results of the excess return without cost.'
                       risk
mean               0.000708
std                0.005626
annualized_return  0.178316
information_ratio  1.996555
max_drawdown      -0.081806
'The following are analysis results of the excess return with cost.'
                       risk
mean               0.000512
std                0.005626
annualized_return  0.128982
information_ratio  1.444287
max_drawdown      -0.091078
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Here are detailed documents for &lt;code&gt;qrun&lt;/code&gt; and &lt;a href="https://qlib.readthedocs.io/en/latest/component/workflow.html"&gt;workflow&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Graphical Reports Analysis: First, run &lt;code&gt;python -m pip install .[analysis]&lt;/code&gt; to install the required dependencies. Then run &lt;code&gt;examples/workflow_by_code.ipynb&lt;/code&gt; with &lt;code&gt;jupyter notebook&lt;/code&gt; to get graphical reports.&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;Forecasting signal (model prediction) analysis&lt;/p&gt; 
    &lt;ul&gt; 
     &lt;li&gt;Cumulative Return of groups &lt;img src="https://github.com/microsoft/qlib/raw/main/docs/_static/img/analysis/analysis_model_cumulative_return.png" alt="Cumulative Return" /&gt;&lt;/li&gt; 
     &lt;li&gt;Return distribution &lt;img src="https://github.com/microsoft/qlib/raw/main/docs/_static/img/analysis/analysis_model_long_short.png" alt="long_short" /&gt;&lt;/li&gt; 
     &lt;li&gt;Information Coefficient (IC) &lt;img src="https://github.com/microsoft/qlib/raw/main/docs/_static/img/analysis/analysis_model_IC.png" alt="Information Coefficient" /&gt; &lt;img src="https://github.com/microsoft/qlib/raw/main/docs/_static/img/analysis/analysis_model_monthly_IC.png" alt="Monthly IC" /&gt; &lt;img src="https://github.com/microsoft/qlib/raw/main/docs/_static/img/analysis/analysis_model_NDQ.png" alt="IC" /&gt;&lt;/li&gt; 
     &lt;li&gt;Auto Correlation of forecasting signal (model prediction) &lt;img src="https://github.com/microsoft/qlib/raw/main/docs/_static/img/analysis/analysis_model_auto_correlation.png" alt="Auto Correlation" /&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;Portfolio analysis&lt;/p&gt; 
    &lt;ul&gt; 
     &lt;li&gt;Backtest return &lt;img src="https://github.com/microsoft/qlib/raw/main/docs/_static/img/analysis/report.png" alt="Report" /&gt;&lt;/li&gt; 
    &lt;/ul&gt; 
    &lt;!-- 
- Score IC
![Score IC](docs/_static/img/score_ic.png)
- Cumulative Return
![Cumulative Return](docs/_static/img/cumulative_return.png)
- Risk Analysis
![Risk Analysis](docs/_static/img/risk_analysis.png)
- Rank Label
![Rank Label](docs/_static/img/rank_label.png)
--&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;a href="https://qlib.readthedocs.io/en/latest/component/report.html"&gt;Explanation&lt;/a&gt; of above results&lt;/p&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Building Customized Quant Research Workflow by Code&lt;/h2&gt; 
&lt;p&gt;The automatic workflow may not suit the research workflow of all Quant researchers. To support a flexible Quant research workflow, Qlib also provides a modularized interface to allow researchers to build their own workflow by code. &lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/workflow_by_code.ipynb"&gt;Here&lt;/a&gt; is a demo for customized Quant research workflow by code.&lt;/p&gt; 
&lt;h1&gt;Main Challenges &amp;amp; Solutions in Quant Research&lt;/h1&gt; 
&lt;p&gt;Quant investment is a very unique scenario with lots of key challenges to be solved. Currently, Qlib provides some solutions for several of them.&lt;/p&gt; 
&lt;h2&gt;Forecasting: Finding Valuable Signals/Patterns&lt;/h2&gt; 
&lt;p&gt;Accurate forecasting of the stock price trend is a very important part to construct profitable portfolios. However, huge amount of data with various formats in the financial market which make it challenging to build forecasting models.&lt;/p&gt; 
&lt;p&gt;An increasing number of SOTA Quant research works/papers, which focus on building forecasting models to mine valuable signals/patterns in complex financial data, are released in &lt;code&gt;Qlib&lt;/code&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/benchmarks"&gt;Quant Model (Paper) Zoo&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;Here is a list of models built on &lt;code&gt;Qlib&lt;/code&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/benchmarks/XGBoost/"&gt;GBDT based on XGBoost (Tianqi Chen, et al. KDD 2016)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/benchmarks/LightGBM/"&gt;GBDT based on LightGBM (Guolin Ke, et al. NIPS 2017)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/benchmarks/CatBoost/"&gt;GBDT based on Catboost (Liudmila Prokhorenkova, et al. NIPS 2018)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/benchmarks/MLP/"&gt;MLP based on pytorch&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/benchmarks/LSTM/"&gt;LSTM based on pytorch (Sepp Hochreiter, et al. Neural computation 1997)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/benchmarks/GRU/"&gt;GRU based on pytorch (Kyunghyun Cho, et al. 2014)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/benchmarks/ALSTM"&gt;ALSTM based on pytorch (Yao Qin, et al. IJCAI 2017)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/benchmarks/GATs/"&gt;GATs based on pytorch (Petar Velickovic, et al. 2017)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/benchmarks/SFM/"&gt;SFM based on pytorch (Liheng Zhang, et al. KDD 2017)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/benchmarks/TFT/"&gt;TFT based on tensorflow (Bryan Lim, et al. International Journal of Forecasting 2019)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/benchmarks/TabNet/"&gt;TabNet based on pytorch (Sercan O. Arik, et al. AAAI 2019)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/benchmarks/DoubleEnsemble/"&gt;DoubleEnsemble based on LightGBM (Chuheng Zhang, et al. ICDM 2020)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/benchmarks/TCTS/"&gt;TCTS based on pytorch (Xueqing Wu, et al. ICML 2021)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/benchmarks/Transformer/"&gt;Transformer based on pytorch (Ashish Vaswani, et al. NeurIPS 2017)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/benchmarks/Localformer/"&gt;Localformer based on pytorch (Juyong Jiang, et al.)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/benchmarks/TRA/"&gt;TRA based on pytorch (Hengxu, Dong, et al. KDD 2021)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/benchmarks/TCN/"&gt;TCN based on pytorch (Shaojie Bai, et al. 2018)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/benchmarks/ADARNN/"&gt;ADARNN based on pytorch (YunTao Du, et al. 2021)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/benchmarks/ADD/"&gt;ADD based on pytorch (Hongshun Tang, et al.2020)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/benchmarks/IGMTF/"&gt;IGMTF based on pytorch (Wentao Xu, et al.2021)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/benchmarks/HIST/"&gt;HIST based on pytorch (Wentao Xu, et al.2021)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/benchmarks/KRNN/"&gt;KRNN based on pytorch&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/benchmarks/Sandwich/"&gt;Sandwich based on pytorch&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Your PR of new Quant models is highly welcomed.&lt;/p&gt; 
&lt;p&gt;The performance of each model on the &lt;code&gt;Alpha158&lt;/code&gt; and &lt;code&gt;Alpha360&lt;/code&gt; datasets can be found &lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/benchmarks/README.md"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Run a single model&lt;/h3&gt; 
&lt;p&gt;All the models listed above are runnable with &lt;code&gt;Qlib&lt;/code&gt;. Users can find the config files we provide and some details about the model through the &lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/benchmarks"&gt;benchmarks&lt;/a&gt; folder. More information can be retrieved at the model files listed above.&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;Qlib&lt;/code&gt; provides three different ways to run a single model, users can pick the one that fits their cases best:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Users can use the tool &lt;code&gt;qrun&lt;/code&gt; mentioned above to run a model's workflow based from a config file.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Users can create a &lt;code&gt;workflow_by_code&lt;/code&gt; python script based on the &lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/workflow_by_code.py"&gt;one&lt;/a&gt; listed in the &lt;code&gt;examples&lt;/code&gt; folder.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Users can use the script &lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/run_all_model.py"&gt;&lt;code&gt;run_all_model.py&lt;/code&gt;&lt;/a&gt; listed in the &lt;code&gt;examples&lt;/code&gt; folder to run a model. Here is an example of the specific shell command to be used: &lt;code&gt;python run_all_model.py run --models=lightgbm&lt;/code&gt;, where the &lt;code&gt;--models&lt;/code&gt; arguments can take any number of models listed above(the available models can be found in &lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/benchmarks/"&gt;benchmarks&lt;/a&gt;). For more use cases, please refer to the file's &lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/run_all_model.py"&gt;docstrings&lt;/a&gt;.&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: Each baseline has different environment dependencies, please make sure that your python version aligns with the requirements(e.g. TFT only supports Python 3.6~3.7 due to the limitation of &lt;code&gt;tensorflow==1.15.0&lt;/code&gt;)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Run multiple models&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;Qlib&lt;/code&gt; also provides a script &lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/run_all_model.py"&gt;&lt;code&gt;run_all_model.py&lt;/code&gt;&lt;/a&gt; which can run multiple models for several iterations. (&lt;strong&gt;Note&lt;/strong&gt;: the script only support &lt;em&gt;Linux&lt;/em&gt; for now. Other OS will be supported in the future. Besides, it doesn't support parallel running the same model for multiple times as well, and this will be fixed in the future development too.)&lt;/p&gt; 
&lt;p&gt;The script will create a unique virtual environment for each model, and delete the environments after training. Thus, only experiment results such as &lt;code&gt;IC&lt;/code&gt; and &lt;code&gt;backtest&lt;/code&gt; results will be generated and stored.&lt;/p&gt; 
&lt;p&gt;Here is an example of running all the models for 10 iterations:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;python run_all_model.py run 10
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;It also provides the API to run specific models at once. For more use cases, please refer to the file's &lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/run_all_model.py"&gt;docstrings&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Break change&lt;/h3&gt; 
&lt;p&gt;In &lt;code&gt;pandas&lt;/code&gt;, &lt;code&gt;group_key&lt;/code&gt; is one of the parameters of the &lt;code&gt;groupby&lt;/code&gt; method. From version 1.5 to 2.0 of &lt;code&gt;pandas&lt;/code&gt;, the default value of &lt;code&gt;group_key&lt;/code&gt; has been changed from &lt;code&gt;no default&lt;/code&gt; to &lt;code&gt;True&lt;/code&gt;, which will cause qlib to report an error during operation. So we set &lt;code&gt;group_key=False&lt;/code&gt;, but it doesn't guarantee that some programmes will run correctly, including:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;qlib\examples\rl_order_execution\scripts\gen_training_orders.py&lt;/li&gt; 
 &lt;li&gt;qlib\examples\benchmarks\TRA\src\dataset.MTSDatasetH.py&lt;/li&gt; 
 &lt;li&gt;qlib\examples\benchmarks\TFT\tft.py&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/benchmarks_dynamic"&gt;Adapting to Market Dynamics&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Due to the non-stationary nature of the environment of the financial market, the data distribution may change in different periods, which makes the performance of models build on training data decays in the future test data. So adapting the forecasting models/strategies to market dynamics is very important to the model/strategies' performance.&lt;/p&gt; 
&lt;p&gt;Here is a list of solutions built on &lt;code&gt;Qlib&lt;/code&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/benchmarks_dynamic/baseline/"&gt;Rolling Retraining&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/benchmarks_dynamic/DDG-DA/"&gt;DDG-DA on pytorch (Wendi, et al. AAAI 2022)&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Reinforcement Learning: modeling continuous decisions&lt;/h2&gt; 
&lt;p&gt;Qlib now supports reinforcement learning, a feature designed to model continuous investment decisions. This functionality assists investors in optimizing their trading strategies by learning from interactions with the environment to maximize some notion of cumulative reward.&lt;/p&gt; 
&lt;p&gt;Here is a list of solutions built on &lt;code&gt;Qlib&lt;/code&gt; categorized by scenarios.&lt;/p&gt; 
&lt;h3&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/rl_order_execution"&gt;RL for order execution&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://qlib.readthedocs.io/en/latest/component/rl/overall.html#order-execution"&gt;Here&lt;/a&gt; is the introduction of this scenario. All the methods below are compared &lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/rl_order_execution"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/rl_order_execution/exp_configs/backtest_twap.yml"&gt;TWAP&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/rl_order_execution/exp_configs/backtest_ppo.yml"&gt;PPO: "An End-to-End Optimal Trade Execution Framework based on Proximal Policy Optimization", IJCAL 2020&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/rl_order_execution/exp_configs/backtest_opds.yml"&gt;OPDS: "Universal Trading for Order Execution with Oracle Policy Distillation", AAAI 2021&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Quant Dataset Zoo&lt;/h1&gt; 
&lt;p&gt;Dataset plays a very important role in Quant. Here is a list of the datasets built on &lt;code&gt;Qlib&lt;/code&gt;:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Dataset&lt;/th&gt; 
   &lt;th&gt;US Market&lt;/th&gt; 
   &lt;th&gt;China Market&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/qlib/contrib/data/handler.py"&gt;Alpha360&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;√&lt;/td&gt; 
   &lt;td&gt;√&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/qlib/contrib/data/handler.py"&gt;Alpha158&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;√&lt;/td&gt; 
   &lt;td&gt;√&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;a href="https://qlib.readthedocs.io/en/latest/advanced/alpha.html"&gt;Here&lt;/a&gt; is a tutorial to build dataset with &lt;code&gt;Qlib&lt;/code&gt;. Your PR to build new Quant dataset is highly welcomed.&lt;/p&gt; 
&lt;h1&gt;Learning Framework&lt;/h1&gt; 
&lt;p&gt;Qlib is high customizable and a lot of its components are learnable. The learnable components are instances of &lt;code&gt;Forecast Model&lt;/code&gt; and &lt;code&gt;Trading Agent&lt;/code&gt;. They are learned based on the &lt;code&gt;Learning Framework&lt;/code&gt; layer and then applied to multiple scenarios in &lt;code&gt;Workflow&lt;/code&gt; layer. The learning framework leverages the &lt;code&gt;Workflow&lt;/code&gt; layer as well(e.g. sharing &lt;code&gt;Information Extractor&lt;/code&gt;, creating environments based on &lt;code&gt;Execution Env&lt;/code&gt;).&lt;/p&gt; 
&lt;p&gt;Based on learning paradigms, they can be categorized into reinforcement learning and supervised learning.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;For supervised learning, the detailed docs can be found &lt;a href="https://qlib.readthedocs.io/en/latest/component/model.html"&gt;here&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;For reinforcement learning, the detailed docs can be found &lt;a href="https://qlib.readthedocs.io/en/latest/component/rl.html"&gt;here&lt;/a&gt;. Qlib's RL learning framework leverages &lt;code&gt;Execution Env&lt;/code&gt; in &lt;code&gt;Workflow&lt;/code&gt; layer to create environments. It's worth noting that &lt;code&gt;NestedExecutor&lt;/code&gt; is supported as well. This empowers users to optimize different level of strategies/models/agents together (e.g. optimizing an order execution strategy for a specific portfolio management strategy).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;More About Qlib&lt;/h1&gt; 
&lt;p&gt;If you want to have a quick glance at the most frequently used components of qlib, you can try notebooks &lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/tutorial/"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;The detailed documents are organized in &lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/docs/"&gt;docs&lt;/a&gt;. &lt;a href="http://www.sphinx-doc.org"&gt;Sphinx&lt;/a&gt; and the readthedocs theme is required to build the documentation in html formats.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd docs/
conda install sphinx sphinx_rtd_theme -y
# Otherwise, you can install them with pip
# pip install sphinx sphinx_rtd_theme
make html
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can also view the &lt;a href="http://qlib.readthedocs.io/"&gt;latest document&lt;/a&gt; online directly.&lt;/p&gt; 
&lt;p&gt;Qlib is in active and continuing development. Our plan is in the roadmap, which is managed as a &lt;a href="https://github.com/microsoft/qlib/projects/1"&gt;github project&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;Offline Mode and Online Mode&lt;/h1&gt; 
&lt;p&gt;The data server of Qlib can either deployed as &lt;code&gt;Offline&lt;/code&gt; mode or &lt;code&gt;Online&lt;/code&gt; mode. The default mode is offline mode.&lt;/p&gt; 
&lt;p&gt;Under &lt;code&gt;Offline&lt;/code&gt; mode, the data will be deployed locally.&lt;/p&gt; 
&lt;p&gt;Under &lt;code&gt;Online&lt;/code&gt; mode, the data will be deployed as a shared data service. The data and their cache will be shared by all the clients. The data retrieval performance is expected to be improved due to a higher rate of cache hits. It will consume less disk space, too. The documents of the online mode can be found in &lt;a href="https://qlib-server.readthedocs.io/"&gt;Qlib-Server&lt;/a&gt;. The online mode can be deployed automatically with &lt;a href="https://qlib-server.readthedocs.io/en/latest/build.html#one-click-deployment-in-azure"&gt;Azure CLI based scripts&lt;/a&gt;. The source code of online data server can be found in &lt;a href="https://github.com/microsoft/qlib-server"&gt;Qlib-Server repository&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Performance of Qlib Data Server&lt;/h2&gt; 
&lt;p&gt;The performance of data processing is important to data-driven methods like AI technologies. As an AI-oriented platform, Qlib provides a solution for data storage and data processing. To demonstrate the performance of Qlib data server, we compare it with several other data storage solutions.&lt;/p&gt; 
&lt;p&gt;We evaluate the performance of several storage solutions by finishing the same task, which creates a dataset (14 features/factors) from the basic OHLCV daily data of a stock market (800 stocks each day from 2007 to 2020). The task involves data queries and processing.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;&lt;/th&gt; 
   &lt;th&gt;HDF5&lt;/th&gt; 
   &lt;th&gt;MySQL&lt;/th&gt; 
   &lt;th&gt;MongoDB&lt;/th&gt; 
   &lt;th&gt;InfluxDB&lt;/th&gt; 
   &lt;th&gt;Qlib -E -D&lt;/th&gt; 
   &lt;th&gt;Qlib +E -D&lt;/th&gt; 
   &lt;th&gt;Qlib +E +D&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Total (1CPU) (seconds)&lt;/td&gt; 
   &lt;td&gt;184.4±3.7&lt;/td&gt; 
   &lt;td&gt;365.3±7.5&lt;/td&gt; 
   &lt;td&gt;253.6±6.7&lt;/td&gt; 
   &lt;td&gt;368.2±3.6&lt;/td&gt; 
   &lt;td&gt;147.0±8.8&lt;/td&gt; 
   &lt;td&gt;47.6±1.0&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;7.4±0.3&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Total (64CPU) (seconds)&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;8.8±0.6&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;4.2±0.2&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;+(-)E&lt;/code&gt; indicates with (out) &lt;code&gt;ExpressionCache&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;+(-)D&lt;/code&gt; indicates with (out) &lt;code&gt;DatasetCache&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Most general-purpose databases take too much time to load data. After looking into the underlying implementation, we find that data go through too many layers of interfaces and unnecessary format transformations in general-purpose database solutions. Such overheads greatly slow down the data loading process. Qlib data are stored in a compact format, which is efficient to be combined into arrays for scientific computation.&lt;/p&gt; 
&lt;h1&gt;Related Reports&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://analyticsindiamag.com/qlib/"&gt;Guide To Qlib: Microsoft’s AI Investment Platform&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://mp.weixin.qq.com/s/47bP5YwxfTp2uTHjUBzJQQ"&gt;微软也搞AI量化平台？还是开源的！&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://mp.weixin.qq.com/s/vsJv7lsgjEi-ALYUz4CvtQ"&gt;微矿Qlib：业内首个AI量化投资开源平台&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Contact Us&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;If you have any issues, please create issue &lt;a href="https://github.com/microsoft/qlib/issues/new/choose"&gt;here&lt;/a&gt; or send messages in &lt;a href="https://gitter.im/Microsoft/qlib"&gt;gitter&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;If you want to make contributions to &lt;code&gt;Qlib&lt;/code&gt;, please &lt;a href="https://github.com/microsoft/qlib/compare"&gt;create pull requests&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;For other reasons, you are welcome to contact us by email(&lt;a href="mailto:qlib@microsoft.com"&gt;qlib@microsoft.com&lt;/a&gt;). 
  &lt;ul&gt; 
   &lt;li&gt;We are recruiting new members(both FTEs and interns), your resumes are welcome!&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Join IM discussion groups:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;&lt;a href="https://gitter.im/Microsoft/qlib"&gt;Gitter&lt;/a&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src="https://github.com/microsoft/qlib/raw/main/docs/_static/img/qrcode/gitter_qr.png" alt="image" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h1&gt;Contributing&lt;/h1&gt; 
&lt;p&gt;We appreciate all contributions and thank all the contributors! &lt;a href="https://github.com/microsoft/qlib/graphs/contributors"&gt;&lt;img src="https://contrib.rocks/image?repo=microsoft/qlib" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Before we released Qlib as an open-source project on Github in Sep 2020, Qlib is an internal project in our group. Unfortunately, the internal commit history is not kept. A lot of members in our group have also contributed a lot to Qlib, which includes Ruihua Wang, Yinda Zhang, Haisu Yu, Shuyu Wang, Bochen Pang, and &lt;a href="https://github.com/evanzd/evanzd"&gt;Dong Zhou&lt;/a&gt;. Especially thanks to &lt;a href="https://github.com/evanzd/evanzd"&gt;Dong Zhou&lt;/a&gt; due to his initial version of Qlib.&lt;/p&gt; 
&lt;h2&gt;Guidance&lt;/h2&gt; 
&lt;p&gt;This project welcomes contributions and suggestions.&lt;br /&gt; &lt;strong&gt;Here are some &lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/docs/developer/code_standard_and_dev_guide.rst"&gt;code standards and development guidance&lt;/a&gt; for submiting a pull request.&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Making contributions is not a hard thing. Solving an issue(maybe just answering a question raised in &lt;a href="https://github.com/microsoft/qlib/issues"&gt;issues list&lt;/a&gt; or &lt;a href="https://gitter.im/Microsoft/qlib"&gt;gitter&lt;/a&gt;), fixing/issuing a bug, improving the documents and even fixing a typo are important contributions to Qlib.&lt;/p&gt; 
&lt;p&gt;For example, if you want to contribute to Qlib's document/code, you can follow the steps in the figure below.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://github.com/demon143/qlib/raw/main/docs/_static/img/change%20doc.gif" /&gt; &lt;/p&gt; 
&lt;p&gt;If you don't know how to start to contribute, you can refer to the following examples.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Type&lt;/th&gt; 
   &lt;th&gt;Examples&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Solving issues&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/microsoft/qlib/issues/749"&gt;Answer a question&lt;/a&gt;; &lt;a href="https://github.com/microsoft/qlib/issues/765"&gt;issuing&lt;/a&gt; or &lt;a href="https://github.com/microsoft/qlib/pull/792"&gt;fixing&lt;/a&gt; a bug&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Docs&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/microsoft/qlib/pull/797/files"&gt;Improve docs quality&lt;/a&gt; ; &lt;a href="https://github.com/microsoft/qlib/pull/774"&gt;Fix a typo&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Feature&lt;/td&gt; 
   &lt;td&gt;Implement a &lt;a href="https://github.com/microsoft/qlib/projects"&gt;requested feature&lt;/a&gt; like &lt;a href="https://github.com/microsoft/qlib/pull/754"&gt;this&lt;/a&gt;; &lt;a href="https://github.com/microsoft/qlib/pull/539/files"&gt;Refactor interfaces&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Dataset&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/microsoft/qlib/pull/733"&gt;Add a dataset&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Models&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/microsoft/qlib/pull/689"&gt;Implement a new model&lt;/a&gt;, &lt;a href="https://github.com/microsoft/qlib/tree/main/examples/benchmarks#contributing"&gt;some instructions to contribute models&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;a href="https://github.com/microsoft/qlib/labels/good%20first%20issue"&gt;Good first issues&lt;/a&gt; are labelled to indicate that they are easy to start your contributions.&lt;/p&gt; 
&lt;p&gt;You can find some impefect implementation in Qlib by &lt;code&gt;rg 'TODO|FIXME' qlib&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;If you would like to become one of Qlib's maintainers to contribute more (e.g. help merge PR, triage issues), please contact us by email(&lt;a href="mailto:qlib@microsoft.com"&gt;qlib@microsoft.com&lt;/a&gt;). We are glad to help to upgrade your permission.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Most contributions require you to agree to a Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us the right to use your contribution. For details, visit &lt;a href="https://cla.opensource.microsoft.com"&gt;https://cla.opensource.microsoft.com&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;When you submit a pull request, a CLA bot will automatically determine whether you need to provide a CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions provided by the bot. You will only need to do this once across all repos using our CLA.&lt;/p&gt; 
&lt;p&gt;This project has adopted the &lt;a href="https://opensource.microsoft.com/codeofconduct/"&gt;Microsoft Open Source Code of Conduct&lt;/a&gt;. For more information see the &lt;a href="https://opensource.microsoft.com/codeofconduct/faq/"&gt;Code of Conduct FAQ&lt;/a&gt; or contact &lt;a href="mailto:opencode@microsoft.com"&gt;opencode@microsoft.com&lt;/a&gt; with any additional questions or comments.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>yt-dlp/yt-dlp</title>
      <link>https://github.com/yt-dlp/yt-dlp</link>
      <description>&lt;p&gt;A feature-rich command-line audio/video downloader&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#readme"&gt;&lt;img src="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/.github/banner.svg?sanitize=true" alt="YT-DLP" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#installation" title="Installation"&gt;&lt;img src="https://img.shields.io/github/v/release/yt-dlp/yt-dlp?color=brightgreen&amp;amp;label=Download&amp;amp;style=for-the-badge" alt="Release version" /&gt;&lt;/a&gt; &lt;a href="https://pypi.org/project/yt-dlp" title="PyPI"&gt;&lt;img src="https://img.shields.io/badge/-PyPI-blue.svg?logo=pypi&amp;amp;labelColor=555555&amp;amp;style=for-the-badge" alt="PyPI" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/Collaborators.md#collaborators" title="Donate"&gt;&lt;img src="https://img.shields.io/badge/_-Donate-red.svg?logo=githubsponsors&amp;amp;labelColor=555555&amp;amp;style=for-the-badge" alt="Donate" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/H5MNcFW63r" title="Discord"&gt;&lt;img src="https://img.shields.io/discord/807245652072857610?color=blue&amp;amp;labelColor=555555&amp;amp;label=&amp;amp;logo=discord&amp;amp;style=for-the-badge" alt="Discord" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/supportedsites.md" title="Supported Sites"&gt;&lt;img src="https://img.shields.io/badge/-Supported_Sites-brightgreen.svg?style=for-the-badge" alt="Supported Sites" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/LICENSE" title="License"&gt;&lt;img src="https://img.shields.io/badge/-Unlicense-blue.svg?style=for-the-badge" alt="License: Unlicense" /&gt;&lt;/a&gt; &lt;a href="https://github.com/yt-dlp/yt-dlp/actions" title="CI Status"&gt;&lt;img src="https://img.shields.io/github/actions/workflow/status/yt-dlp/yt-dlp/core.yml?branch=master&amp;amp;label=Tests&amp;amp;style=for-the-badge" alt="CI Status" /&gt;&lt;/a&gt; &lt;a href="https://github.com/yt-dlp/yt-dlp/commits" title="Commit History"&gt;&lt;img src="https://img.shields.io/github/commit-activity/m/yt-dlp/yt-dlp?label=commits&amp;amp;style=for-the-badge" alt="Commits" /&gt;&lt;/a&gt; &lt;a href="https://github.com/yt-dlp/yt-dlp/pulse/monthly" title="Last activity"&gt;&lt;img src="https://img.shields.io/github/last-commit/yt-dlp/yt-dlp/master?label=&amp;amp;style=for-the-badge&amp;amp;display_timestamp=committer" alt="Last Commit" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;!-- MANPAGE: END EXCLUDED SECTION --&gt; 
&lt;p&gt;yt-dlp is a feature-rich command-line audio/video downloader with support for &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/supportedsites.md"&gt;thousands of sites&lt;/a&gt;. The project is a fork of &lt;a href="https://github.com/ytdl-org/youtube-dl"&gt;youtube-dl&lt;/a&gt; based on the now inactive &lt;a href="https://github.com/blackjack4494/yt-dlc"&gt;youtube-dlc&lt;/a&gt;.&lt;/p&gt; 
&lt;!-- MANPAGE: MOVE "USAGE AND OPTIONS" SECTION HERE --&gt; 
&lt;!-- MANPAGE: BEGIN EXCLUDED SECTION --&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#installation"&gt;INSTALLATION&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/wiki/Installation"&gt;Detailed instructions&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#release-files"&gt;Release Files&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#update"&gt;Update&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#dependencies"&gt;Dependencies&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#compile"&gt;Compile&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#usage-and-options"&gt;USAGE AND OPTIONS&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#general-options"&gt;General Options&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#network-options"&gt;Network Options&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#geo-restriction"&gt;Geo-restriction&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#video-selection"&gt;Video Selection&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#download-options"&gt;Download Options&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#filesystem-options"&gt;Filesystem Options&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#thumbnail-options"&gt;Thumbnail Options&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#internet-shortcut-options"&gt;Internet Shortcut Options&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#verbosity-and-simulation-options"&gt;Verbosity and Simulation Options&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#workarounds"&gt;Workarounds&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#video-format-options"&gt;Video Format Options&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#subtitle-options"&gt;Subtitle Options&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#authentication-options"&gt;Authentication Options&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#post-processing-options"&gt;Post-processing Options&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#sponsorblock-options"&gt;SponsorBlock Options&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#extractor-options"&gt;Extractor Options&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#preset-aliases"&gt;Preset Aliases&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#configuration"&gt;CONFIGURATION&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#configuration-file-encoding"&gt;Configuration file encoding&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#authentication-with-netrc"&gt;Authentication with netrc&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#notes-about-environment-variables"&gt;Notes about environment variables&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#output-template"&gt;OUTPUT TEMPLATE&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#output-template-examples"&gt;Output template examples&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#format-selection"&gt;FORMAT SELECTION&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#filtering-formats"&gt;Filtering Formats&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#sorting-formats"&gt;Sorting Formats&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#format-selection-examples"&gt;Format Selection examples&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#modifying-metadata"&gt;MODIFYING METADATA&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#modifying-metadata-examples"&gt;Modifying metadata examples&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#extractor-arguments"&gt;EXTRACTOR ARGUMENTS&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#plugins"&gt;PLUGINS&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#installing-plugins"&gt;Installing Plugins&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#developing-plugins"&gt;Developing Plugins&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#embedding-yt-dlp"&gt;EMBEDDING YT-DLP&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#embedding-examples"&gt;Embedding examples&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#changes-from-youtube-dl"&gt;CHANGES FROM YOUTUBE-DL&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#new-features"&gt;New features&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#differences-in-default-behavior"&gt;Differences in default behavior&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#deprecated-options"&gt;Deprecated options&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/CONTRIBUTING.md#contributing-to-yt-dlp"&gt;CONTRIBUTING&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/CONTRIBUTING.md#opening-an-issue"&gt;Opening an Issue&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/CONTRIBUTING.md#developer-instructions"&gt;Developer Instructions&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/wiki"&gt;WIKI&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/wiki/FAQ"&gt;FAQ&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;!-- MANPAGE: END EXCLUDED SECTION --&gt; 
&lt;h1&gt;INSTALLATION&lt;/h1&gt; 
&lt;!-- MANPAGE: BEGIN EXCLUDED SECTION --&gt; 
&lt;p&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp.exe"&gt;&lt;img src="https://img.shields.io/badge/-Windows_x64-blue.svg?style=for-the-badge&amp;amp;logo=windows" alt="Windows" /&gt;&lt;/a&gt; &lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp"&gt;&lt;img src="https://img.shields.io/badge/-Linux/BSD-red.svg?style=for-the-badge&amp;amp;logo=linux" alt="Unix" /&gt;&lt;/a&gt; &lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_macos"&gt;&lt;img src="https://img.shields.io/badge/-MacOS-lightblue.svg?style=for-the-badge&amp;amp;logo=apple" alt="MacOS" /&gt;&lt;/a&gt; &lt;a href="https://pypi.org/project/yt-dlp"&gt;&lt;img src="https://img.shields.io/badge/-PyPI-blue.svg?logo=pypi&amp;amp;labelColor=555555&amp;amp;style=for-the-badge" alt="PyPI" /&gt;&lt;/a&gt; &lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp.tar.gz"&gt;&lt;img src="https://img.shields.io/badge/-Source_tar-green.svg?style=for-the-badge" alt="Source Tarball" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#release-files"&gt;&lt;img src="https://img.shields.io/badge/-Other-grey.svg?style=for-the-badge" alt="Other variants" /&gt;&lt;/a&gt; &lt;a href="https://github.com/yt-dlp/yt-dlp/releases"&gt;&lt;img src="https://img.shields.io/badge/-All_Versions-lightgrey.svg?style=for-the-badge" alt="All versions" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;!-- MANPAGE: END EXCLUDED SECTION --&gt; 
&lt;p&gt;You can install yt-dlp using &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#release-files"&gt;the binaries&lt;/a&gt;, &lt;a href="https://pypi.org/project/yt-dlp"&gt;pip&lt;/a&gt; or one using a third-party package manager. See &lt;a href="https://github.com/yt-dlp/yt-dlp/wiki/Installation"&gt;the wiki&lt;/a&gt; for detailed instructions&lt;/p&gt; 
&lt;!-- MANPAGE: BEGIN EXCLUDED SECTION --&gt; 
&lt;h2&gt;RELEASE FILES&lt;/h2&gt; 
&lt;h4&gt;Recommended&lt;/h4&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;File&lt;/th&gt; 
   &lt;th align="left"&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp"&gt;yt-dlp&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Platform-independent &lt;a href="https://docs.python.org/3/library/zipimport.html"&gt;zipimport&lt;/a&gt; binary. Needs Python (recommended for &lt;strong&gt;Linux/BSD&lt;/strong&gt;)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp.exe"&gt;yt-dlp.exe&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Windows (Win8+) standalone x64 binary (recommended for &lt;strong&gt;Windows&lt;/strong&gt;)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_macos"&gt;yt-dlp_macos&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Universal MacOS (10.15+) standalone executable (recommended for &lt;strong&gt;MacOS&lt;/strong&gt;)&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h4&gt;Alternatives&lt;/h4&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;File&lt;/th&gt; 
   &lt;th align="left"&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_x86.exe"&gt;yt-dlp_x86.exe&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Windows (Win8+) standalone x86 (32-bit) binary&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_arm64.exe"&gt;yt-dlp_arm64.exe&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Windows (Win10+) standalone arm64 (64-bit) binary&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_linux"&gt;yt-dlp_linux&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Linux standalone x64 binary&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_linux_armv7l"&gt;yt-dlp_linux_armv7l&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Linux standalone armv7l (32-bit) binary&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_linux_aarch64"&gt;yt-dlp_linux_aarch64&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Linux standalone aarch64 (64-bit) binary&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_win.zip"&gt;yt-dlp_win.zip&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Unpackaged Windows (Win8+) x64 executable (no auto-update)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_win_x86.zip"&gt;yt-dlp_win_x86.zip&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Unpackaged Windows (Win8+) x86 executable (no auto-update)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_win_arm64.zip"&gt;yt-dlp_win_arm64.zip&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Unpackaged Windows (Win10+) arm64 executable (no auto-update)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_macos.zip"&gt;yt-dlp_macos.zip&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Unpackaged MacOS (10.15+) executable (no auto-update)&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h4&gt;Misc&lt;/h4&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;File&lt;/th&gt; 
   &lt;th align="left"&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp.tar.gz"&gt;yt-dlp.tar.gz&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Source tarball&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/SHA2-512SUMS"&gt;SHA2-512SUMS&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;GNU-style SHA512 sums&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/SHA2-512SUMS.sig"&gt;SHA2-512SUMS.sig&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;GPG signature file for SHA512 sums&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/SHA2-256SUMS"&gt;SHA2-256SUMS&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;GNU-style SHA256 sums&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/SHA2-256SUMS.sig"&gt;SHA2-256SUMS.sig&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;GPG signature file for SHA256 sums&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;The public key that can be used to verify the GPG signatures is &lt;a href="https://github.com/yt-dlp/yt-dlp/raw/master/public.key"&gt;available here&lt;/a&gt; Example usage:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;curl -L https://github.com/yt-dlp/yt-dlp/raw/master/public.key | gpg --import
gpg --verify SHA2-256SUMS.sig SHA2-256SUMS
gpg --verify SHA2-512SUMS.sig SHA2-512SUMS
&lt;/code&gt;&lt;/pre&gt; 
&lt;!-- MANPAGE: END EXCLUDED SECTION --&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: The manpages, shell completion (autocomplete) files etc. are available inside the &lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp.tar.gz"&gt;source tarball&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;UPDATE&lt;/h2&gt; 
&lt;p&gt;You can use &lt;code&gt;yt-dlp -U&lt;/code&gt; to update if you are using the &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#release-files"&gt;release binaries&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;If you &lt;a href="https://github.com/yt-dlp/yt-dlp/wiki/Installation#with-pip"&gt;installed with pip&lt;/a&gt;, simply re-run the same command that was used to install the program&lt;/p&gt; 
&lt;p&gt;For other third-party package managers, see &lt;a href="https://github.com/yt-dlp/yt-dlp/wiki/Installation#third-party-package-managers"&gt;the wiki&lt;/a&gt; or refer to their documentation&lt;/p&gt; 
&lt;p&gt;&lt;a id="update-channels"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;There are currently three release channels for binaries: &lt;code&gt;stable&lt;/code&gt;, &lt;code&gt;nightly&lt;/code&gt; and &lt;code&gt;master&lt;/code&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;stable&lt;/code&gt; is the default channel, and many of its changes have been tested by users of the &lt;code&gt;nightly&lt;/code&gt; and &lt;code&gt;master&lt;/code&gt; channels.&lt;/li&gt; 
 &lt;li&gt;The &lt;code&gt;nightly&lt;/code&gt; channel has releases scheduled to build every day around midnight UTC, for a snapshot of the project's new patches and changes. This is the &lt;strong&gt;recommended channel for regular users&lt;/strong&gt; of yt-dlp. The &lt;code&gt;nightly&lt;/code&gt; releases are available from &lt;a href="https://github.com/yt-dlp/yt-dlp-nightly-builds/releases"&gt;yt-dlp/yt-dlp-nightly-builds&lt;/a&gt; or as development releases of the &lt;code&gt;yt-dlp&lt;/code&gt; PyPI package (which can be installed with pip's &lt;code&gt;--pre&lt;/code&gt; flag).&lt;/li&gt; 
 &lt;li&gt;The &lt;code&gt;master&lt;/code&gt; channel features releases that are built after each push to the master branch, and these will have the very latest fixes and additions, but may also be more prone to regressions. They are available from &lt;a href="https://github.com/yt-dlp/yt-dlp-master-builds/releases"&gt;yt-dlp/yt-dlp-master-builds&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;When using &lt;code&gt;--update&lt;/code&gt;/&lt;code&gt;-U&lt;/code&gt;, a release binary will only update to its current channel. &lt;code&gt;--update-to CHANNEL&lt;/code&gt; can be used to switch to a different channel when a newer version is available. &lt;code&gt;--update-to [CHANNEL@]TAG&lt;/code&gt; can also be used to upgrade or downgrade to specific tags from a channel.&lt;/p&gt; 
&lt;p&gt;You may also use &lt;code&gt;--update-to &amp;lt;repository&amp;gt;&lt;/code&gt; (&lt;code&gt;&amp;lt;owner&amp;gt;/&amp;lt;repository&amp;gt;&lt;/code&gt;) to update to a channel on a completely different repository. Be careful with what repository you are updating to though, there is no verification done for binaries from different repositories.&lt;/p&gt; 
&lt;p&gt;Example usage:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;yt-dlp --update-to master&lt;/code&gt; switch to the &lt;code&gt;master&lt;/code&gt; channel and update to its latest release&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;yt-dlp --update-to stable@2023.07.06&lt;/code&gt; upgrade/downgrade to release to &lt;code&gt;stable&lt;/code&gt; channel tag &lt;code&gt;2023.07.06&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;yt-dlp --update-to 2023.10.07&lt;/code&gt; upgrade/downgrade to tag &lt;code&gt;2023.10.07&lt;/code&gt; if it exists on the current channel&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;yt-dlp --update-to example/yt-dlp@2023.09.24&lt;/code&gt; upgrade/downgrade to the release from the &lt;code&gt;example/yt-dlp&lt;/code&gt; repository, tag &lt;code&gt;2023.09.24&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Important&lt;/strong&gt;: Any user experiencing an issue with the &lt;code&gt;stable&lt;/code&gt; release should install or update to the &lt;code&gt;nightly&lt;/code&gt; release before submitting a bug report:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;# To update to nightly from stable executable/binary:
yt-dlp --update-to nightly

# To install nightly with pip:
python3 -m pip install -U --pre "yt-dlp[default]"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;When running a yt-dlp version that is older than 90 days, you will see a warning message suggesting to update to the latest version. You can suppress this warning by adding &lt;code&gt;--no-update&lt;/code&gt; to your command or configuration file.&lt;/p&gt; 
&lt;h2&gt;DEPENDENCIES&lt;/h2&gt; 
&lt;p&gt;Python versions 3.9+ (CPython) and 3.11+ (PyPy) are supported. Other versions and implementations may or may not work correctly.&lt;/p&gt; 
&lt;!-- Python 3.5+ uses VC++14 and it is already embedded in the binary created
&lt;!x-- https://www.microsoft.com/en-us/download/details.aspx?id=26999 --x&gt;
On Windows, [Microsoft Visual C++ 2010 SP1 Redistributable Package (x86)](https://download.microsoft.com/download/1/6/5/165255E7-1014-4D0A-B094-B6A430A6BFFC/vcredist_x86.exe) is also necessary to run yt-dlp. You probably already have this, but if the executable throws an error due to missing `MSVCR100.dll` you need to install it manually.
--&gt; 
&lt;p&gt;While all the other dependencies are optional, &lt;code&gt;ffmpeg&lt;/code&gt; and &lt;code&gt;ffprobe&lt;/code&gt; are highly recommended&lt;/p&gt; 
&lt;h3&gt;Strongly recommended&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://www.ffmpeg.org"&gt;&lt;strong&gt;ffmpeg&lt;/strong&gt; and &lt;strong&gt;ffprobe&lt;/strong&gt;&lt;/a&gt; - Required for &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#format-selection"&gt;merging separate video and audio files&lt;/a&gt;, as well as for various &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#post-processing-options"&gt;post-processing&lt;/a&gt; tasks. License &lt;a href="https://www.ffmpeg.org/legal.html"&gt;depends on the build&lt;/a&gt;&lt;/p&gt; &lt;p&gt;There are bugs in ffmpeg that cause various issues when used alongside yt-dlp. Since ffmpeg is such an important dependency, we provide &lt;a href="https://github.com/yt-dlp/FFmpeg-Builds#ffmpeg-static-auto-builds"&gt;custom builds&lt;/a&gt; with patches for some of these issues at &lt;a href="https://github.com/yt-dlp/FFmpeg-Builds"&gt;yt-dlp/FFmpeg-Builds&lt;/a&gt;. See &lt;a href="https://github.com/yt-dlp/FFmpeg-Builds#patches-applied"&gt;the readme&lt;/a&gt; for details on the specific issues solved by these builds&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Important&lt;/strong&gt;: What you need is ffmpeg &lt;em&gt;binary&lt;/em&gt;, &lt;strong&gt;NOT&lt;/strong&gt; &lt;a href="https://pypi.org/project/ffmpeg"&gt;the Python package of the same name&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Networking&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/certifi/python-certifi"&gt;&lt;strong&gt;certifi&lt;/strong&gt;&lt;/a&gt;* - Provides Mozilla's root certificate bundle. Licensed under &lt;a href="https://github.com/certifi/python-certifi/raw/master/LICENSE"&gt;MPLv2&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/google/brotli"&gt;&lt;strong&gt;brotli&lt;/strong&gt;&lt;/a&gt;* or &lt;a href="https://github.com/python-hyper/brotlicffi"&gt;&lt;strong&gt;brotlicffi&lt;/strong&gt;&lt;/a&gt; - &lt;a href="https://en.wikipedia.org/wiki/Brotli"&gt;Brotli&lt;/a&gt; content encoding support. Both licensed under MIT &lt;sup&gt;&lt;a href="https://github.com/google/brotli/raw/master/LICENSE"&gt;1&lt;/a&gt; &lt;a href="https://github.com/python-hyper/brotlicffi/raw/master/LICENSE"&gt;2&lt;/a&gt; &lt;/sup&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/aaugustin/websockets"&gt;&lt;strong&gt;websockets&lt;/strong&gt;&lt;/a&gt;* - For downloading over websocket. Licensed under &lt;a href="https://github.com/aaugustin/websockets/raw/main/LICENSE"&gt;BSD-3-Clause&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/psf/requests"&gt;&lt;strong&gt;requests&lt;/strong&gt;&lt;/a&gt;* - HTTP library. For HTTPS proxy and persistent connections support. Licensed under &lt;a href="https://github.com/psf/requests/raw/main/LICENSE"&gt;Apache-2.0&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Impersonation&lt;/h4&gt; 
&lt;p&gt;The following provide support for impersonating browser requests. This may be required for some sites that employ TLS fingerprinting.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/lexiforest/curl_cffi"&gt;&lt;strong&gt;curl_cffi&lt;/strong&gt;&lt;/a&gt; (recommended) - Python binding for &lt;a href="https://github.com/lexiforest/curl-impersonate"&gt;curl-impersonate&lt;/a&gt;. Provides impersonation targets for Chrome, Edge and Safari. Licensed under &lt;a href="https://github.com/lexiforest/curl_cffi/raw/main/LICENSE"&gt;MIT&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Can be installed with the &lt;code&gt;curl-cffi&lt;/code&gt; group, e.g. &lt;code&gt;pip install "yt-dlp[default,curl-cffi]"&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;Currently included in &lt;code&gt;yt-dlp.exe&lt;/code&gt;, &lt;code&gt;yt-dlp_linux&lt;/code&gt; and &lt;code&gt;yt-dlp_macos&lt;/code&gt; builds&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Metadata&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/quodlibet/mutagen"&gt;&lt;strong&gt;mutagen&lt;/strong&gt;&lt;/a&gt;* - For &lt;code&gt;--embed-thumbnail&lt;/code&gt; in certain formats. Licensed under &lt;a href="https://github.com/quodlibet/mutagen/raw/master/COPYING"&gt;GPLv2+&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/wez/atomicparsley"&gt;&lt;strong&gt;AtomicParsley&lt;/strong&gt;&lt;/a&gt; - For &lt;code&gt;--embed-thumbnail&lt;/code&gt; in &lt;code&gt;mp4&lt;/code&gt;/&lt;code&gt;m4a&lt;/code&gt; files when &lt;code&gt;mutagen&lt;/code&gt;/&lt;code&gt;ffmpeg&lt;/code&gt; cannot. Licensed under &lt;a href="https://github.com/wez/atomicparsley/raw/master/COPYING"&gt;GPLv2+&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/xattr/xattr"&gt;&lt;strong&gt;xattr&lt;/strong&gt;&lt;/a&gt;, &lt;a href="https://github.com/iustin/pyxattr"&gt;&lt;strong&gt;pyxattr&lt;/strong&gt;&lt;/a&gt; or &lt;a href="http://savannah.nongnu.org/projects/attr"&gt;&lt;strong&gt;setfattr&lt;/strong&gt;&lt;/a&gt; - For writing xattr metadata (&lt;code&gt;--xattrs&lt;/code&gt;) on &lt;strong&gt;Mac&lt;/strong&gt; and &lt;strong&gt;BSD&lt;/strong&gt;. Licensed under &lt;a href="https://github.com/xattr/xattr/raw/master/LICENSE.txt"&gt;MIT&lt;/a&gt;, &lt;a href="https://github.com/iustin/pyxattr/raw/master/COPYING"&gt;LGPL2.1&lt;/a&gt; and &lt;a href="http://git.savannah.nongnu.org/cgit/attr.git/tree/doc/COPYING"&gt;GPLv2+&lt;/a&gt; respectively&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Misc&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Legrandin/pycryptodome"&gt;&lt;strong&gt;pycryptodomex&lt;/strong&gt;&lt;/a&gt;* - For decrypting AES-128 HLS streams and various other data. Licensed under &lt;a href="https://github.com/Legrandin/pycryptodome/raw/master/LICENSE.rst"&gt;BSD-2-Clause&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ariya/phantomjs"&gt;&lt;strong&gt;phantomjs&lt;/strong&gt;&lt;/a&gt; - Used in extractors where javascript needs to be run. Licensed under &lt;a href="https://github.com/ariya/phantomjs/raw/master/LICENSE.BSD"&gt;BSD-3-Clause&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mitya57/secretstorage"&gt;&lt;strong&gt;secretstorage&lt;/strong&gt;&lt;/a&gt;* - For &lt;code&gt;--cookies-from-browser&lt;/code&gt; to access the &lt;strong&gt;Gnome&lt;/strong&gt; keyring while decrypting cookies of &lt;strong&gt;Chromium&lt;/strong&gt;-based browsers on &lt;strong&gt;Linux&lt;/strong&gt;. Licensed under &lt;a href="https://github.com/mitya57/secretstorage/raw/master/LICENSE"&gt;BSD-3-Clause&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Any external downloader that you want to use with &lt;code&gt;--downloader&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Deprecated&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.libav.org"&gt;&lt;strong&gt;avconv&lt;/strong&gt; and &lt;strong&gt;avprobe&lt;/strong&gt;&lt;/a&gt; - Now &lt;strong&gt;deprecated&lt;/strong&gt; alternative to ffmpeg. License &lt;a href="https://libav.org/legal"&gt;depends on the build&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/faissaloo/SponSkrub"&gt;&lt;strong&gt;sponskrub&lt;/strong&gt;&lt;/a&gt; - For using the now &lt;strong&gt;deprecated&lt;/strong&gt; &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#sponskrub-options"&gt;sponskrub options&lt;/a&gt;. Licensed under &lt;a href="https://github.com/faissaloo/SponSkrub/raw/master/LICENCE.md"&gt;GPLv3+&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://rtmpdump.mplayerhq.hu"&gt;&lt;strong&gt;rtmpdump&lt;/strong&gt;&lt;/a&gt; - For downloading &lt;code&gt;rtmp&lt;/code&gt; streams. ffmpeg can be used instead with &lt;code&gt;--downloader ffmpeg&lt;/code&gt;. Licensed under &lt;a href="http://rtmpdump.mplayerhq.hu"&gt;GPLv2+&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://mplayerhq.hu/design7/info.html"&gt;&lt;strong&gt;mplayer&lt;/strong&gt;&lt;/a&gt; or &lt;a href="https://mpv.io"&gt;&lt;strong&gt;mpv&lt;/strong&gt;&lt;/a&gt; - For downloading &lt;code&gt;rstp&lt;/code&gt;/&lt;code&gt;mms&lt;/code&gt; streams. ffmpeg can be used instead with &lt;code&gt;--downloader ffmpeg&lt;/code&gt;. Licensed under &lt;a href="https://github.com/mpv-player/mpv/raw/master/Copyright"&gt;GPLv2+&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;To use or redistribute the dependencies, you must agree to their respective licensing terms.&lt;/p&gt; 
&lt;p&gt;The standalone release binaries are built with the Python interpreter and the packages marked with &lt;strong&gt;*&lt;/strong&gt; included.&lt;/p&gt; 
&lt;p&gt;If you do not have the necessary dependencies for a task you are attempting, yt-dlp will warn you. All the currently available dependencies are visible at the top of the &lt;code&gt;--verbose&lt;/code&gt; output&lt;/p&gt; 
&lt;h2&gt;COMPILE&lt;/h2&gt; 
&lt;h3&gt;Standalone PyInstaller Builds&lt;/h3&gt; 
&lt;p&gt;To build the standalone executable, you must have Python and &lt;code&gt;pyinstaller&lt;/code&gt; (plus any of yt-dlp's &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#dependencies"&gt;optional dependencies&lt;/a&gt; if needed). The executable will be built for the same CPU architecture as the Python used.&lt;/p&gt; 
&lt;p&gt;You can run the following commands:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;python3 devscripts/install_deps.py --include pyinstaller
python3 devscripts/make_lazy_extractors.py
python3 -m bundle.pyinstaller
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;On some systems, you may need to use &lt;code&gt;py&lt;/code&gt; or &lt;code&gt;python&lt;/code&gt; instead of &lt;code&gt;python3&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;python -m bundle.pyinstaller&lt;/code&gt; accepts any arguments that can be passed to &lt;code&gt;pyinstaller&lt;/code&gt;, such as &lt;code&gt;--onefile/-F&lt;/code&gt; or &lt;code&gt;--onedir/-D&lt;/code&gt;, which is further &lt;a href="https://pyinstaller.org/en/stable/usage.html#what-to-generate"&gt;documented here&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: Pyinstaller versions below 4.4 &lt;a href="https://github.com/pyinstaller/pyinstaller#requirements-and-tested-platforms"&gt;do not support&lt;/a&gt; Python installed from the Windows store without using a virtual environment.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Important&lt;/strong&gt;: Running &lt;code&gt;pyinstaller&lt;/code&gt; directly &lt;strong&gt;instead of&lt;/strong&gt; using &lt;code&gt;python -m bundle.pyinstaller&lt;/code&gt; is &lt;strong&gt;not&lt;/strong&gt; officially supported. This may or may not work correctly.&lt;/p&gt; 
&lt;h3&gt;Platform-independent Binary (UNIX)&lt;/h3&gt; 
&lt;p&gt;You will need the build tools &lt;code&gt;python&lt;/code&gt; (3.9+), &lt;code&gt;zip&lt;/code&gt;, &lt;code&gt;make&lt;/code&gt; (GNU), &lt;code&gt;pandoc&lt;/code&gt;* and &lt;code&gt;pytest&lt;/code&gt;*.&lt;/p&gt; 
&lt;p&gt;After installing these, simply run &lt;code&gt;make&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;You can also run &lt;code&gt;make yt-dlp&lt;/code&gt; instead to compile only the binary without updating any of the additional files. (The build tools marked with &lt;strong&gt;*&lt;/strong&gt; are not needed for this)&lt;/p&gt; 
&lt;h3&gt;Related scripts&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;devscripts/install_deps.py&lt;/code&gt;&lt;/strong&gt; - Install dependencies for yt-dlp.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;devscripts/update-version.py&lt;/code&gt;&lt;/strong&gt; - Update the version number based on the current date.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;devscripts/set-variant.py&lt;/code&gt;&lt;/strong&gt; - Set the build variant of the executable.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;devscripts/make_changelog.py&lt;/code&gt;&lt;/strong&gt; - Create a markdown changelog using short commit messages and update &lt;code&gt;CONTRIBUTORS&lt;/code&gt; file.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;devscripts/make_lazy_extractors.py&lt;/code&gt;&lt;/strong&gt; - Create lazy extractors. Running this before building the binaries (any variant) will improve their startup performance. Set the environment variable &lt;code&gt;YTDLP_NO_LAZY_EXTRACTORS&lt;/code&gt; to something nonempty to forcefully disable lazy extractor loading.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Note: See their &lt;code&gt;--help&lt;/code&gt; for more info.&lt;/p&gt; 
&lt;h3&gt;Forking the project&lt;/h3&gt; 
&lt;p&gt;If you fork the project on GitHub, you can run your fork's &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/.github/workflows/build.yml"&gt;build workflow&lt;/a&gt; to automatically build the selected version(s) as artifacts. Alternatively, you can run the &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/.github/workflows/release.yml"&gt;release workflow&lt;/a&gt; or enable the &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/.github/workflows/release-nightly.yml"&gt;nightly workflow&lt;/a&gt; to create full (pre-)releases.&lt;/p&gt; 
&lt;h1&gt;USAGE AND OPTIONS&lt;/h1&gt; 
&lt;!-- MANPAGE: BEGIN EXCLUDED SECTION --&gt; 
&lt;pre&gt;&lt;code&gt;yt-dlp [OPTIONS] [--] URL [URL...]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Tip: Use &lt;code&gt;CTRL&lt;/code&gt;+&lt;code&gt;F&lt;/code&gt; (or &lt;code&gt;Command&lt;/code&gt;+&lt;code&gt;F&lt;/code&gt;) to search by keywords&lt;/p&gt; 
&lt;!-- MANPAGE: END EXCLUDED SECTION --&gt; 
&lt;!-- Auto generated --&gt; 
&lt;h2&gt;General Options:&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;-h, --help                      Print this help text and exit
--version                       Print program version and exit
-U, --update                    Update this program to the latest version
--no-update                     Do not check for updates (default)
--update-to [CHANNEL]@[TAG]     Upgrade/downgrade to a specific version.
                                CHANNEL can be a repository as well. CHANNEL
                                and TAG default to "stable" and "latest"
                                respectively if omitted; See "UPDATE" for
                                details. Supported channels: stable,
                                nightly, master
-i, --ignore-errors             Ignore download and postprocessing errors.
                                The download will be considered successful
                                even if the postprocessing fails
--no-abort-on-error             Continue with next video on download errors;
                                e.g. to skip unavailable videos in a
                                playlist (default)
--abort-on-error                Abort downloading of further videos if an
                                error occurs (Alias: --no-ignore-errors)
--dump-user-agent               Display the current user-agent and exit
--list-extractors               List all supported extractors and exit
--extractor-descriptions        Output descriptions of all supported
                                extractors and exit
--use-extractors NAMES          Extractor names to use separated by commas.
                                You can also use regexes, "all", "default"
                                and "end" (end URL matching); e.g. --ies
                                "holodex.*,end,youtube". Prefix the name
                                with a "-" to exclude it, e.g. --ies
                                default,-generic. Use --list-extractors for
                                a list of extractor names. (Alias: --ies)
--default-search PREFIX         Use this prefix for unqualified URLs. E.g.
                                "gvsearch2:python" downloads two videos from
                                google videos for the search term "python".
                                Use the value "auto" to let yt-dlp guess
                                ("auto_warning" to emit a warning when
                                guessing). "error" just throws an error. The
                                default value "fixup_error" repairs broken
                                URLs, but emits an error if this is not
                                possible instead of searching
--ignore-config                 Don't load any more configuration files
                                except those given to --config-locations.
                                For backward compatibility, if this option
                                is found inside the system configuration
                                file, the user configuration is not loaded.
                                (Alias: --no-config)
--no-config-locations           Do not load any custom configuration files
                                (default). When given inside a configuration
                                file, ignore all previous --config-locations
                                defined in the current file
--config-locations PATH         Location of the main configuration file;
                                either the path to the config or its
                                containing directory ("-" for stdin). Can be
                                used multiple times and inside other
                                configuration files
--plugin-dirs PATH              Path to an additional directory to search
                                for plugins. This option can be used
                                multiple times to add multiple directories.
                                Use "default" to search the default plugin
                                directories (default)
--no-plugin-dirs                Clear plugin directories to search,
                                including defaults and those provided by
                                previous --plugin-dirs
--flat-playlist                 Do not extract a playlist's URL result
                                entries; some entry metadata may be missing
                                and downloading may be bypassed
--no-flat-playlist              Fully extract the videos of a playlist
                                (default)
--live-from-start               Download livestreams from the start.
                                Currently experimental and only supported
                                for YouTube and Twitch
--no-live-from-start            Download livestreams from the current time
                                (default)
--wait-for-video MIN[-MAX]      Wait for scheduled streams to become
                                available. Pass the minimum number of
                                seconds (or range) to wait between retries
--no-wait-for-video             Do not wait for scheduled streams (default)
--mark-watched                  Mark videos watched (even with --simulate)
--no-mark-watched               Do not mark videos watched (default)
--color [STREAM:]POLICY         Whether to emit color codes in output,
                                optionally prefixed by the STREAM (stdout or
                                stderr) to apply the setting to. Can be one
                                of "always", "auto" (default), "never", or
                                "no_color" (use non color terminal
                                sequences). Use "auto-tty" or "no_color-tty"
                                to decide based on terminal support only.
                                Can be used multiple times
--compat-options OPTS           Options that can help keep compatibility
                                with youtube-dl or youtube-dlc
                                configurations by reverting some of the
                                changes made in yt-dlp. See "Differences in
                                default behavior" for details
--alias ALIASES OPTIONS         Create aliases for an option string. Unless
                                an alias starts with a dash "-", it is
                                prefixed with "--". Arguments are parsed
                                according to the Python string formatting
                                mini-language. E.g. --alias get-audio,-X "-S
                                aext:{0},abr -x --audio-format {0}" creates
                                options "--get-audio" and "-X" that takes an
                                argument (ARG0) and expands to "-S
                                aext:ARG0,abr -x --audio-format ARG0". All
                                defined aliases are listed in the --help
                                output. Alias options can trigger more
                                aliases; so be careful to avoid defining
                                recursive options. As a safety measure, each
                                alias may be triggered a maximum of 100
                                times. This option can be used multiple times
-t, --preset-alias PRESET       Applies a predefined set of options. e.g.
                                --preset-alias mp3. The following presets
                                are available: mp3, aac, mp4, mkv, sleep.
                                See the "Preset Aliases" section at the end
                                for more info. This option can be used
                                multiple times
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Network Options:&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;--proxy URL                     Use the specified HTTP/HTTPS/SOCKS proxy. To
                                enable SOCKS proxy, specify a proper scheme,
                                e.g. socks5://user:pass@127.0.0.1:1080/.
                                Pass in an empty string (--proxy "") for
                                direct connection
--socket-timeout SECONDS        Time to wait before giving up, in seconds
--source-address IP             Client-side IP address to bind to
--impersonate CLIENT[:OS]       Client to impersonate for requests. E.g.
                                chrome, chrome-110, chrome:windows-10. Pass
                                --impersonate="" to impersonate any client.
                                Note that forcing impersonation for all
                                requests may have a detrimental impact on
                                download speed and stability
--list-impersonate-targets      List available clients to impersonate.
-4, --force-ipv4                Make all connections via IPv4
-6, --force-ipv6                Make all connections via IPv6
--enable-file-urls              Enable file:// URLs. This is disabled by
                                default for security reasons.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Geo-restriction:&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;--geo-verification-proxy URL    Use this proxy to verify the IP address for
                                some geo-restricted sites. The default proxy
                                specified by --proxy (or none, if the option
                                is not present) is used for the actual
                                downloading
--xff VALUE                     How to fake X-Forwarded-For HTTP header to
                                try bypassing geographic restriction. One of
                                "default" (only when known to be useful),
                                "never", an IP block in CIDR notation, or a
                                two-letter ISO 3166-2 country code
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Video Selection:&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;-I, --playlist-items ITEM_SPEC  Comma separated playlist_index of the items
                                to download. You can specify a range using
                                "[START]:[STOP][:STEP]". For backward
                                compatibility, START-STOP is also supported.
                                Use negative indices to count from the right
                                and negative STEP to download in reverse
                                order. E.g. "-I 1:3,7,-5::2" used on a
                                playlist of size 15 will download the items
                                at index 1,2,3,7,11,13,15
--min-filesize SIZE             Abort download if filesize is smaller than
                                SIZE, e.g. 50k or 44.6M
--max-filesize SIZE             Abort download if filesize is larger than
                                SIZE, e.g. 50k or 44.6M
--date DATE                     Download only videos uploaded on this date.
                                The date can be "YYYYMMDD" or in the format 
                                [now|today|yesterday][-N[day|week|month|year]].
                                E.g. "--date today-2weeks" downloads only
                                videos uploaded on the same day two weeks ago
--datebefore DATE               Download only videos uploaded on or before
                                this date. The date formats accepted are the
                                same as --date
--dateafter DATE                Download only videos uploaded on or after
                                this date. The date formats accepted are the
                                same as --date
--match-filters FILTER          Generic video filter. Any "OUTPUT TEMPLATE"
                                field can be compared with a number or a
                                string using the operators defined in
                                "Filtering Formats". You can also simply
                                specify a field to match if the field is
                                present, use "!field" to check if the field
                                is not present, and "&amp;amp;" to check multiple
                                conditions. Use a "\" to escape "&amp;amp;" or
                                quotes if needed. If used multiple times,
                                the filter matches if at least one of the
                                conditions is met. E.g. --match-filters
                                !is_live --match-filters "like_count&amp;gt;?100 &amp;amp;
                                description~='(?i)\bcats \&amp;amp; dogs\b'" matches
                                only videos that are not live OR those that
                                have a like count more than 100 (or the like
                                field is not available) and also has a
                                description that contains the phrase "cats &amp;amp;
                                dogs" (caseless). Use "--match-filters -" to
                                interactively ask whether to download each
                                video
--no-match-filters              Do not use any --match-filters (default)
--break-match-filters FILTER    Same as "--match-filters" but stops the
                                download process when a video is rejected
--no-break-match-filters        Do not use any --break-match-filters (default)
--no-playlist                   Download only the video, if the URL refers
                                to a video and a playlist
--yes-playlist                  Download the playlist, if the URL refers to
                                a video and a playlist
--age-limit YEARS               Download only videos suitable for the given
                                age
--download-archive FILE         Download only videos not listed in the
                                archive file. Record the IDs of all
                                downloaded videos in it
--no-download-archive           Do not use archive file (default)
--max-downloads NUMBER          Abort after downloading NUMBER files
--break-on-existing             Stop the download process when encountering
                                a file that is in the archive supplied with
                                the --download-archive option
--no-break-on-existing          Do not stop the download process when
                                encountering a file that is in the archive
                                (default)
--break-per-input               Alters --max-downloads, --break-on-existing,
                                --break-match-filters, and autonumber to
                                reset per input URL
--no-break-per-input            --break-on-existing and similar options
                                terminates the entire download queue
--skip-playlist-after-errors N  Number of allowed failures until the rest of
                                the playlist is skipped
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Download Options:&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;-N, --concurrent-fragments N    Number of fragments of a dash/hlsnative
                                video that should be downloaded concurrently
                                (default is 1)
-r, --limit-rate RATE           Maximum download rate in bytes per second,
                                e.g. 50K or 4.2M
--throttled-rate RATE           Minimum download rate in bytes per second
                                below which throttling is assumed and the
                                video data is re-extracted, e.g. 100K
-R, --retries RETRIES           Number of retries (default is 10), or
                                "infinite"
--file-access-retries RETRIES   Number of times to retry on file access
                                error (default is 3), or "infinite"
--fragment-retries RETRIES      Number of retries for a fragment (default is
                                10), or "infinite" (DASH, hlsnative and ISM)
--retry-sleep [TYPE:]EXPR       Time to sleep between retries in seconds
                                (optionally) prefixed by the type of retry
                                (http (default), fragment, file_access,
                                extractor) to apply the sleep to. EXPR can
                                be a number, linear=START[:END[:STEP=1]] or
                                exp=START[:END[:BASE=2]]. This option can be
                                used multiple times to set the sleep for the
                                different retry types, e.g. --retry-sleep
                                linear=1::2 --retry-sleep fragment:exp=1:20
--skip-unavailable-fragments    Skip unavailable fragments for DASH,
                                hlsnative and ISM downloads (default)
                                (Alias: --no-abort-on-unavailable-fragments)
--abort-on-unavailable-fragments
                                Abort download if a fragment is unavailable
                                (Alias: --no-skip-unavailable-fragments)
--keep-fragments                Keep downloaded fragments on disk after
                                downloading is finished
--no-keep-fragments             Delete downloaded fragments after
                                downloading is finished (default)
--buffer-size SIZE              Size of download buffer, e.g. 1024 or 16K
                                (default is 1024)
--resize-buffer                 The buffer size is automatically resized
                                from an initial value of --buffer-size
                                (default)
--no-resize-buffer              Do not automatically adjust the buffer size
--http-chunk-size SIZE          Size of a chunk for chunk-based HTTP
                                downloading, e.g. 10485760 or 10M (default
                                is disabled). May be useful for bypassing
                                bandwidth throttling imposed by a webserver
                                (experimental)
--playlist-random               Download playlist videos in random order
--lazy-playlist                 Process entries in the playlist as they are
                                received. This disables n_entries,
                                --playlist-random and --playlist-reverse
--no-lazy-playlist              Process videos in the playlist only after
                                the entire playlist is parsed (default)
--xattr-set-filesize            Set file xattribute ytdl.filesize with
                                expected file size
--hls-use-mpegts                Use the mpegts container for HLS videos;
                                allowing some players to play the video
                                while downloading, and reducing the chance
                                of file corruption if download is
                                interrupted. This is enabled by default for
                                live streams
--no-hls-use-mpegts             Do not use the mpegts container for HLS
                                videos. This is default when not downloading
                                live streams
--download-sections REGEX       Download only chapters that match the
                                regular expression. A "*" prefix denotes
                                time-range instead of chapter. Negative
                                timestamps are calculated from the end.
                                "*from-url" can be used to download between
                                the "start_time" and "end_time" extracted
                                from the URL. Needs ffmpeg. This option can
                                be used multiple times to download multiple
                                sections, e.g. --download-sections
                                "*10:15-inf" --download-sections "intro"
--downloader [PROTO:]NAME       Name or path of the external downloader to
                                use (optionally) prefixed by the protocols
                                (http, ftp, m3u8, dash, rstp, rtmp, mms) to
                                use it for. Currently supports native,
                                aria2c, avconv, axel, curl, ffmpeg, httpie,
                                wget. You can use this option multiple times
                                to set different downloaders for different
                                protocols. E.g. --downloader aria2c
                                --downloader "dash,m3u8:native" will use
                                aria2c for http/ftp downloads, and the
                                native downloader for dash/m3u8 downloads
                                (Alias: --external-downloader)
--downloader-args NAME:ARGS     Give these arguments to the external
                                downloader. Specify the downloader name and
                                the arguments separated by a colon ":". For
                                ffmpeg, arguments can be passed to different
                                positions using the same syntax as
                                --postprocessor-args. You can use this
                                option multiple times to give different
                                arguments to different downloaders (Alias:
                                --external-downloader-args)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Filesystem Options:&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;-a, --batch-file FILE           File containing URLs to download ("-" for
                                stdin), one URL per line. Lines starting
                                with "#", ";" or "]" are considered as
                                comments and ignored
--no-batch-file                 Do not read URLs from batch file (default)
-P, --paths [TYPES:]PATH        The paths where the files should be
                                downloaded. Specify the type of file and the
                                path separated by a colon ":". All the same
                                TYPES as --output are supported.
                                Additionally, you can also provide "home"
                                (default) and "temp" paths. All intermediary
                                files are first downloaded to the temp path
                                and then the final files are moved over to
                                the home path after download is finished.
                                This option is ignored if --output is an
                                absolute path
-o, --output [TYPES:]TEMPLATE   Output filename template; see "OUTPUT
                                TEMPLATE" for details
--output-na-placeholder TEXT    Placeholder for unavailable fields in
                                --output (default: "NA")
--restrict-filenames            Restrict filenames to only ASCII characters,
                                and avoid "&amp;amp;" and spaces in filenames
--no-restrict-filenames         Allow Unicode characters, "&amp;amp;" and spaces in
                                filenames (default)
--windows-filenames             Force filenames to be Windows-compatible
--no-windows-filenames          Sanitize filenames only minimally
--trim-filenames LENGTH         Limit the filename length (excluding
                                extension) to the specified number of
                                characters
-w, --no-overwrites             Do not overwrite any files
--force-overwrites              Overwrite all video and metadata files. This
                                option includes --no-continue
--no-force-overwrites           Do not overwrite the video, but overwrite
                                related files (default)
-c, --continue                  Resume partially downloaded files/fragments
                                (default)
--no-continue                   Do not resume partially downloaded
                                fragments. If the file is not fragmented,
                                restart download of the entire file
--part                          Use .part files instead of writing directly
                                into output file (default)
--no-part                       Do not use .part files - write directly into
                                output file
--mtime                         Use the Last-modified header to set the file
                                modification time
--no-mtime                      Do not use the Last-modified header to set
                                the file modification time (default)
--write-description             Write video description to a .description file
--no-write-description          Do not write video description (default)
--write-info-json               Write video metadata to a .info.json file
                                (this may contain personal information)
--no-write-info-json            Do not write video metadata (default)
--write-playlist-metafiles      Write playlist metadata in addition to the
                                video metadata when using --write-info-json,
                                --write-description etc. (default)
--no-write-playlist-metafiles   Do not write playlist metadata when using
                                --write-info-json, --write-description etc.
--clean-info-json               Remove some internal metadata such as
                                filenames from the infojson (default)
--no-clean-info-json            Write all fields to the infojson
--write-comments                Retrieve video comments to be placed in the
                                infojson. The comments are fetched even
                                without this option if the extraction is
                                known to be quick (Alias: --get-comments)
--no-write-comments             Do not retrieve video comments unless the
                                extraction is known to be quick (Alias:
                                --no-get-comments)
--load-info-json FILE           JSON file containing the video information
                                (created with the "--write-info-json" option)
--cookies FILE                  Netscape formatted file to read cookies from
                                and dump cookie jar in
--no-cookies                    Do not read/dump cookies from/to file
                                (default)
--cookies-from-browser BROWSER[+KEYRING][:PROFILE][::CONTAINER]
                                The name of the browser to load cookies
                                from. Currently supported browsers are:
                                brave, chrome, chromium, edge, firefox,
                                opera, safari, vivaldi, whale. Optionally,
                                the KEYRING used for decrypting Chromium
                                cookies on Linux, the name/path of the
                                PROFILE to load cookies from, and the
                                CONTAINER name (if Firefox) ("none" for no
                                container) can be given with their
                                respective separators. By default, all
                                containers of the most recently accessed
                                profile are used. Currently supported
                                keyrings are: basictext, gnomekeyring,
                                kwallet, kwallet5, kwallet6
--no-cookies-from-browser       Do not load cookies from browser (default)
--cache-dir DIR                 Location in the filesystem where yt-dlp can
                                store some downloaded information (such as
                                client ids and signatures) permanently. By
                                default ${XDG_CACHE_HOME}/yt-dlp
--no-cache-dir                  Disable filesystem caching
--rm-cache-dir                  Delete all filesystem cache files
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Thumbnail Options:&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;--write-thumbnail               Write thumbnail image to disk
--no-write-thumbnail            Do not write thumbnail image to disk (default)
--write-all-thumbnails          Write all thumbnail image formats to disk
--list-thumbnails               List available thumbnails of each video.
                                Simulate unless --no-simulate is used
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Internet Shortcut Options:&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;--write-link                    Write an internet shortcut file, depending
                                on the current platform (.url, .webloc or
                                .desktop). The URL may be cached by the OS
--write-url-link                Write a .url Windows internet shortcut. The
                                OS caches the URL based on the file path
--write-webloc-link             Write a .webloc macOS internet shortcut
--write-desktop-link            Write a .desktop Linux internet shortcut
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Verbosity and Simulation Options:&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;-q, --quiet                     Activate quiet mode. If used with --verbose,
                                print the log to stderr
--no-quiet                      Deactivate quiet mode. (Default)
--no-warnings                   Ignore warnings
-s, --simulate                  Do not download the video and do not write
                                anything to disk
--no-simulate                   Download the video even if printing/listing
                                options are used
--ignore-no-formats-error       Ignore "No video formats" error. Useful for
                                extracting metadata even if the videos are
                                not actually available for download
                                (experimental)
--no-ignore-no-formats-error    Throw error when no downloadable video
                                formats are found (default)
--skip-download                 Do not download the video but write all
                                related files (Alias: --no-download)
-O, --print [WHEN:]TEMPLATE     Field name or output template to print to
                                screen, optionally prefixed with when to
                                print it, separated by a ":". Supported
                                values of "WHEN" are the same as that of
                                --use-postprocessor (default: video).
                                Implies --quiet. Implies --simulate unless
                                --no-simulate or later stages of WHEN are
                                used. This option can be used multiple times
--print-to-file [WHEN:]TEMPLATE FILE
                                Append given template to the file. The
                                values of WHEN and TEMPLATE are the same as
                                that of --print. FILE uses the same syntax
                                as the output template. This option can be
                                used multiple times
-j, --dump-json                 Quiet, but print JSON information for each
                                video. Simulate unless --no-simulate is
                                used. See "OUTPUT TEMPLATE" for a
                                description of available keys
-J, --dump-single-json          Quiet, but print JSON information for each
                                URL or infojson passed. Simulate unless
                                --no-simulate is used. If the URL refers to
                                a playlist, the whole playlist information
                                is dumped in a single line
--force-write-archive           Force download archive entries to be written
                                as far as no errors occur, even if -s or
                                another simulation option is used (Alias:
                                --force-download-archive)
--newline                       Output progress bar as new lines
--no-progress                   Do not print progress bar
--progress                      Show progress bar, even if in quiet mode
--console-title                 Display progress in console titlebar
--progress-template [TYPES:]TEMPLATE
                                Template for progress outputs, optionally
                                prefixed with one of "download:" (default),
                                "download-title:" (the console title),
                                "postprocess:",  or "postprocess-title:".
                                The video's fields are accessible under the
                                "info" key and the progress attributes are
                                accessible under "progress" key. E.g.
                                --console-title --progress-template
                                "download-title:%(info.id)s-%(progress.eta)s"
--progress-delta SECONDS        Time between progress output (default: 0)
-v, --verbose                   Print various debugging information
--dump-pages                    Print downloaded pages encoded using base64
                                to debug problems (very verbose)
--write-pages                   Write downloaded intermediary pages to files
                                in the current directory to debug problems
--print-traffic                 Display sent and read HTTP traffic
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Workarounds:&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;--encoding ENCODING             Force the specified encoding (experimental)
--legacy-server-connect         Explicitly allow HTTPS connection to servers
                                that do not support RFC 5746 secure
                                renegotiation
--no-check-certificates         Suppress HTTPS certificate validation
--prefer-insecure               Use an unencrypted connection to retrieve
                                information about the video (Currently
                                supported only for YouTube)
--add-headers FIELD:VALUE       Specify a custom HTTP header and its value,
                                separated by a colon ":". You can use this
                                option multiple times
--bidi-workaround               Work around terminals that lack
                                bidirectional text support. Requires bidiv
                                or fribidi executable in PATH
--sleep-requests SECONDS        Number of seconds to sleep between requests
                                during data extraction
--sleep-interval SECONDS        Number of seconds to sleep before each
                                download. This is the minimum time to sleep
                                when used along with --max-sleep-interval
                                (Alias: --min-sleep-interval)
--max-sleep-interval SECONDS    Maximum number of seconds to sleep. Can only
                                be used along with --min-sleep-interval
--sleep-subtitles SECONDS       Number of seconds to sleep before each
                                subtitle download
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Video Format Options:&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;-f, --format FORMAT             Video format code, see "FORMAT SELECTION"
                                for more details
-S, --format-sort SORTORDER     Sort the formats by the fields given, see
                                "Sorting Formats" for more details
--format-sort-force             Force user specified sort order to have
                                precedence over all fields, see "Sorting
                                Formats" for more details (Alias: --S-force)
--no-format-sort-force          Some fields have precedence over the user
                                specified sort order (default)
--video-multistreams            Allow multiple video streams to be merged
                                into a single file
--no-video-multistreams         Only one video stream is downloaded for each
                                output file (default)
--audio-multistreams            Allow multiple audio streams to be merged
                                into a single file
--no-audio-multistreams         Only one audio stream is downloaded for each
                                output file (default)
--prefer-free-formats           Prefer video formats with free containers
                                over non-free ones of the same quality. Use
                                with "-S ext" to strictly prefer free
                                containers irrespective of quality
--no-prefer-free-formats        Don't give any special preference to free
                                containers (default)
--check-formats                 Make sure formats are selected only from
                                those that are actually downloadable
--check-all-formats             Check all formats for whether they are
                                actually downloadable
--no-check-formats              Do not check that the formats are actually
                                downloadable
-F, --list-formats              List available formats of each video.
                                Simulate unless --no-simulate is used
--merge-output-format FORMAT    Containers that may be used when merging
                                formats, separated by "/", e.g. "mp4/mkv".
                                Ignored if no merge is required. (currently
                                supported: avi, flv, mkv, mov, mp4, webm)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Subtitle Options:&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;--write-subs                    Write subtitle file
--no-write-subs                 Do not write subtitle file (default)
--write-auto-subs               Write automatically generated subtitle file
                                (Alias: --write-automatic-subs)
--no-write-auto-subs            Do not write auto-generated subtitles
                                (default) (Alias: --no-write-automatic-subs)
--list-subs                     List available subtitles of each video.
                                Simulate unless --no-simulate is used
--sub-format FORMAT             Subtitle format; accepts formats preference
                                separated by "/", e.g. "srt" or "ass/srt/best"
--sub-langs LANGS               Languages of the subtitles to download (can
                                be regex) or "all" separated by commas, e.g.
                                --sub-langs "en.*,ja" (where "en.*" is a
                                regex pattern that matches "en" followed by
                                0 or more of any character). You can prefix
                                the language code with a "-" to exclude it
                                from the requested languages, e.g. --sub-
                                langs all,-live_chat. Use --list-subs for a
                                list of available language tags
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Authentication Options:&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;-u, --username USERNAME         Login with this account ID
-p, --password PASSWORD         Account password. If this option is left
                                out, yt-dlp will ask interactively
-2, --twofactor TWOFACTOR       Two-factor authentication code
-n, --netrc                     Use .netrc authentication data
--netrc-location PATH           Location of .netrc authentication data;
                                either the path or its containing directory.
                                Defaults to ~/.netrc
--netrc-cmd NETRC_CMD           Command to execute to get the credentials
                                for an extractor.
--video-password PASSWORD       Video-specific password
--ap-mso MSO                    Adobe Pass multiple-system operator (TV
                                provider) identifier, use --ap-list-mso for
                                a list of available MSOs
--ap-username USERNAME          Multiple-system operator account login
--ap-password PASSWORD          Multiple-system operator account password.
                                If this option is left out, yt-dlp will ask
                                interactively
--ap-list-mso                   List all supported multiple-system operators
--client-certificate CERTFILE   Path to client certificate file in PEM
                                format. May include the private key
--client-certificate-key KEYFILE
                                Path to private key file for client
                                certificate
--client-certificate-password PASSWORD
                                Password for client certificate private key,
                                if encrypted. If not provided, and the key
                                is encrypted, yt-dlp will ask interactively
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Post-Processing Options:&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;-x, --extract-audio             Convert video files to audio-only files
                                (requires ffmpeg and ffprobe)
--audio-format FORMAT           Format to convert the audio to when -x is
                                used. (currently supported: best (default),
                                aac, alac, flac, m4a, mp3, opus, vorbis,
                                wav). You can specify multiple rules using
                                similar syntax as --remux-video
--audio-quality QUALITY         Specify ffmpeg audio quality to use when
                                converting the audio with -x. Insert a value
                                between 0 (best) and 10 (worst) for VBR or a
                                specific bitrate like 128K (default 5)
--remux-video FORMAT            Remux the video into another container if
                                necessary (currently supported: avi, flv,
                                gif, mkv, mov, mp4, webm, aac, aiff, alac,
                                flac, m4a, mka, mp3, ogg, opus, vorbis,
                                wav). If the target container does not
                                support the video/audio codec, remuxing will
                                fail. You can specify multiple rules; e.g.
                                "aac&amp;gt;m4a/mov&amp;gt;mp4/mkv" will remux aac to m4a,
                                mov to mp4 and anything else to mkv
--recode-video FORMAT           Re-encode the video into another format if
                                necessary. The syntax and supported formats
                                are the same as --remux-video
--postprocessor-args NAME:ARGS  Give these arguments to the postprocessors.
                                Specify the postprocessor/executable name
                                and the arguments separated by a colon ":"
                                to give the argument to the specified
                                postprocessor/executable. Supported PP are:
                                Merger, ModifyChapters, SplitChapters,
                                ExtractAudio, VideoRemuxer, VideoConvertor,
                                Metadata, EmbedSubtitle, EmbedThumbnail,
                                SubtitlesConvertor, ThumbnailsConvertor,
                                FixupStretched, FixupM4a, FixupM3u8,
                                FixupTimestamp and FixupDuration. The
                                supported executables are: AtomicParsley,
                                FFmpeg and FFprobe. You can also specify
                                "PP+EXE:ARGS" to give the arguments to the
                                specified executable only when being used by
                                the specified postprocessor. Additionally,
                                for ffmpeg/ffprobe, "_i"/"_o" can be
                                appended to the prefix optionally followed
                                by a number to pass the argument before the
                                specified input/output file, e.g. --ppa
                                "Merger+ffmpeg_i1:-v quiet". You can use
                                this option multiple times to give different
                                arguments to different postprocessors.
                                (Alias: --ppa)
-k, --keep-video                Keep the intermediate video file on disk
                                after post-processing
--no-keep-video                 Delete the intermediate video file after
                                post-processing (default)
--post-overwrites               Overwrite post-processed files (default)
--no-post-overwrites            Do not overwrite post-processed files
--embed-subs                    Embed subtitles in the video (only for mp4,
                                webm and mkv videos)
--no-embed-subs                 Do not embed subtitles (default)
--embed-thumbnail               Embed thumbnail in the video as cover art
--no-embed-thumbnail            Do not embed thumbnail (default)
--embed-metadata                Embed metadata to the video file. Also
                                embeds chapters/infojson if present unless
                                --no-embed-chapters/--no-embed-info-json are
                                used (Alias: --add-metadata)
--no-embed-metadata             Do not add metadata to file (default)
                                (Alias: --no-add-metadata)
--embed-chapters                Add chapter markers to the video file
                                (Alias: --add-chapters)
--no-embed-chapters             Do not add chapter markers (default) (Alias:
                                --no-add-chapters)
--embed-info-json               Embed the infojson as an attachment to
                                mkv/mka video files
--no-embed-info-json            Do not embed the infojson as an attachment
                                to the video file
--parse-metadata [WHEN:]FROM:TO
                                Parse additional metadata like title/artist
                                from other fields; see "MODIFYING METADATA"
                                for details. Supported values of "WHEN" are
                                the same as that of --use-postprocessor
                                (default: pre_process)
--replace-in-metadata [WHEN:]FIELDS REGEX REPLACE
                                Replace text in a metadata field using the
                                given regex. This option can be used
                                multiple times. Supported values of "WHEN"
                                are the same as that of --use-postprocessor
                                (default: pre_process)
--xattrs                        Write metadata to the video file's xattrs
                                (using Dublin Core and XDG standards)
--concat-playlist POLICY        Concatenate videos in a playlist. One of
                                "never", "always", or "multi_video"
                                (default; only when the videos form a single
                                show). All the video files must have the
                                same codecs and number of streams to be
                                concatenable. The "pl_video:" prefix can be
                                used with "--paths" and "--output" to set
                                the output filename for the concatenated
                                files. See "OUTPUT TEMPLATE" for details
--fixup POLICY                  Automatically correct known faults of the
                                file. One of never (do nothing), warn (only
                                emit a warning), detect_or_warn (the
                                default; fix the file if we can, warn
                                otherwise), force (try fixing even if the
                                file already exists)
--ffmpeg-location PATH          Location of the ffmpeg binary; either the
                                path to the binary or its containing directory
--exec [WHEN:]CMD               Execute a command, optionally prefixed with
                                when to execute it, separated by a ":".
                                Supported values of "WHEN" are the same as
                                that of --use-postprocessor (default:
                                after_move). The same syntax as the output
                                template can be used to pass any field as
                                arguments to the command. If no fields are
                                passed, %(filepath,_filename|)q is appended
                                to the end of the command. This option can
                                be used multiple times
--no-exec                       Remove any previously defined --exec
--convert-subs FORMAT           Convert the subtitles to another format
                                (currently supported: ass, lrc, srt, vtt).
                                Use "--convert-subs none" to disable
                                conversion (default) (Alias: --convert-
                                subtitles)
--convert-thumbnails FORMAT     Convert the thumbnails to another format
                                (currently supported: jpg, png, webp). You
                                can specify multiple rules using similar
                                syntax as "--remux-video". Use "--convert-
                                thumbnails none" to disable conversion
                                (default)
--split-chapters                Split video into multiple files based on
                                internal chapters. The "chapter:" prefix can
                                be used with "--paths" and "--output" to set
                                the output filename for the split files. See
                                "OUTPUT TEMPLATE" for details
--no-split-chapters             Do not split video based on chapters (default)
--remove-chapters REGEX         Remove chapters whose title matches the
                                given regular expression. The syntax is the
                                same as --download-sections. This option can
                                be used multiple times
--no-remove-chapters            Do not remove any chapters from the file
                                (default)
--force-keyframes-at-cuts       Force keyframes at cuts when
                                downloading/splitting/removing sections.
                                This is slow due to needing a re-encode, but
                                the resulting video may have fewer artifacts
                                around the cuts
--no-force-keyframes-at-cuts    Do not force keyframes around the chapters
                                when cutting/splitting (default)
--use-postprocessor NAME[:ARGS]
                                The (case-sensitive) name of plugin
                                postprocessors to be enabled, and
                                (optionally) arguments to be passed to it,
                                separated by a colon ":". ARGS are a
                                semicolon ";" delimited list of NAME=VALUE.
                                The "when" argument determines when the
                                postprocessor is invoked. It can be one of
                                "pre_process" (after video extraction),
                                "after_filter" (after video passes filter),
                                "video" (after --format; before
                                --print/--output), "before_dl" (before each
                                video download), "post_process" (after each
                                video download; default), "after_move"
                                (after moving the video file to its final
                                location), "after_video" (after downloading
                                and processing all formats of a video), or
                                "playlist" (at end of playlist). This option
                                can be used multiple times to add different
                                postprocessors
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;SponsorBlock Options:&lt;/h2&gt; 
&lt;p&gt;Make chapter entries for, or remove various segments (sponsor, introductions, etc.) from downloaded YouTube videos using the &lt;a href="https://sponsor.ajay.app"&gt;SponsorBlock API&lt;/a&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;--sponsorblock-mark CATS        SponsorBlock categories to create chapters
                                for, separated by commas. Available
                                categories are sponsor, intro, outro,
                                selfpromo, preview, filler, interaction,
                                music_offtopic, poi_highlight, chapter, all
                                and default (=all). You can prefix the
                                category with a "-" to exclude it. See [1]
                                for descriptions of the categories. E.g.
                                --sponsorblock-mark all,-preview
                                [1] https://wiki.sponsor.ajay.app/w/Segment_Categories
--sponsorblock-remove CATS      SponsorBlock categories to be removed from
                                the video file, separated by commas. If a
                                category is present in both mark and remove,
                                remove takes precedence. The syntax and
                                available categories are the same as for
                                --sponsorblock-mark except that "default"
                                refers to "all,-filler" and poi_highlight,
                                chapter are not available
--sponsorblock-chapter-title TEMPLATE
                                An output template for the title of the
                                SponsorBlock chapters created by
                                --sponsorblock-mark. The only available
                                fields are start_time, end_time, category,
                                categories, name, category_names. Defaults
                                to "[SponsorBlock]: %(category_names)l"
--no-sponsorblock               Disable both --sponsorblock-mark and
                                --sponsorblock-remove
--sponsorblock-api URL          SponsorBlock API location, defaults to
                                https://sponsor.ajay.app
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Extractor Options:&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;--extractor-retries RETRIES     Number of retries for known extractor errors
                                (default is 3), or "infinite"
--allow-dynamic-mpd             Process dynamic DASH manifests (default)
                                (Alias: --no-ignore-dynamic-mpd)
--ignore-dynamic-mpd            Do not process dynamic DASH manifests
                                (Alias: --no-allow-dynamic-mpd)
--hls-split-discontinuity       Split HLS playlists to different formats at
                                discontinuities such as ad breaks
--no-hls-split-discontinuity    Do not split HLS playlists into different
                                formats at discontinuities such as ad breaks
                                (default)
--extractor-args IE_KEY:ARGS    Pass ARGS arguments to the IE_KEY extractor.
                                See "EXTRACTOR ARGUMENTS" for details. You
                                can use this option multiple times to give
                                arguments for different extractors
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Preset Aliases:&lt;/h2&gt; 
&lt;p&gt;Predefined aliases for convenience and ease of use. Note that future versions of yt-dlp may add or adjust presets, but the existing preset names will not be changed or removed&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;-t mp3                          -f 'ba[acodec^=mp3]/ba/b' -x --audio-format
                                mp3

-t aac                          -f
                                'ba[acodec^=aac]/ba[acodec^=mp4a.40.]/ba/b'
                                -x --audio-format aac

-t mp4                          --merge-output-format mp4 --remux-video mp4
                                -S vcodec:h264,lang,quality,res,fps,hdr:12,a
                                codec:aac

-t mkv                          --merge-output-format mkv --remux-video mkv

-t sleep                        --sleep-subtitles 5 --sleep-requests 0.75
                                --sleep-interval 10 --max-sleep-interval 20
&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;CONFIGURATION&lt;/h1&gt; 
&lt;p&gt;You can configure yt-dlp by placing any supported command line option in a configuration file. The configuration is loaded from the following locations:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Main Configuration&lt;/strong&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;The file given to &lt;code&gt;--config-location&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Portable Configuration&lt;/strong&gt;: (Recommended for portable installations)&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;If using a binary, &lt;code&gt;yt-dlp.conf&lt;/code&gt; in the same directory as the binary&lt;/li&gt; 
   &lt;li&gt;If running from source-code, &lt;code&gt;yt-dlp.conf&lt;/code&gt; in the parent directory of &lt;code&gt;yt_dlp&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Home Configuration&lt;/strong&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;yt-dlp.conf&lt;/code&gt; in the home path given to &lt;code&gt;-P&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;If &lt;code&gt;-P&lt;/code&gt; is not given, the current directory is searched&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;User Configuration&lt;/strong&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;${XDG_CONFIG_HOME}/yt-dlp.conf&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;${XDG_CONFIG_HOME}/yt-dlp/config&lt;/code&gt; (recommended on Linux/macOS)&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;${XDG_CONFIG_HOME}/yt-dlp/config.txt&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;${APPDATA}/yt-dlp.conf&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;${APPDATA}/yt-dlp/config&lt;/code&gt; (recommended on Windows)&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;${APPDATA}/yt-dlp/config.txt&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;~/yt-dlp.conf&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;~/yt-dlp.conf.txt&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;~/.yt-dlp/config&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;~/.yt-dlp/config.txt&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;p&gt;See also: &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#notes-about-environment-variables"&gt;Notes about environment variables&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;System Configuration&lt;/strong&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;/etc/yt-dlp.conf&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;/etc/yt-dlp/config&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;/etc/yt-dlp/config.txt&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;E.g. with the following configuration file, yt-dlp will always extract the audio, copy the mtime, use a proxy and save all videos under &lt;code&gt;YouTube&lt;/code&gt; directory in your home directory:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;# Lines starting with # are comments

# Always extract audio
-x

# Copy the mtime
--mtime

# Use this proxy
--proxy 127.0.0.1:3128

# Save all videos under YouTube directory in your home directory
-o ~/YouTube/%(title)s.%(ext)s
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: Options in a configuration file are just the same options aka switches used in regular command line calls; thus there &lt;strong&gt;must be no whitespace&lt;/strong&gt; after &lt;code&gt;-&lt;/code&gt; or &lt;code&gt;--&lt;/code&gt;, e.g. &lt;code&gt;-o&lt;/code&gt; or &lt;code&gt;--proxy&lt;/code&gt; but not &lt;code&gt;- o&lt;/code&gt; or &lt;code&gt;-- proxy&lt;/code&gt;. They must also be quoted when necessary, as if it were a UNIX shell.&lt;/p&gt; 
&lt;p&gt;You can use &lt;code&gt;--ignore-config&lt;/code&gt; if you want to disable all configuration files for a particular yt-dlp run. If &lt;code&gt;--ignore-config&lt;/code&gt; is found inside any configuration file, no further configuration will be loaded. For example, having the option in the portable configuration file prevents loading of home, user, and system configurations. Additionally, (for backward compatibility) if &lt;code&gt;--ignore-config&lt;/code&gt; is found inside the system configuration file, the user configuration is not loaded.&lt;/p&gt; 
&lt;h3&gt;Configuration file encoding&lt;/h3&gt; 
&lt;p&gt;The configuration files are decoded according to the UTF BOM if present, and in the encoding from system locale otherwise.&lt;/p&gt; 
&lt;p&gt;If you want your file to be decoded differently, add &lt;code&gt;# coding: ENCODING&lt;/code&gt; to the beginning of the file (e.g. &lt;code&gt;# coding: shift-jis&lt;/code&gt;). There must be no characters before that, even spaces or BOM.&lt;/p&gt; 
&lt;h3&gt;Authentication with netrc&lt;/h3&gt; 
&lt;p&gt;You may also want to configure automatic credentials storage for extractors that support authentication (by providing login and password with &lt;code&gt;--username&lt;/code&gt; and &lt;code&gt;--password&lt;/code&gt;) in order not to pass credentials as command line arguments on every yt-dlp execution and prevent tracking plain text passwords in the shell command history. You can achieve this using a &lt;a href="https://stackoverflow.com/tags/.netrc/info"&gt;&lt;code&gt;.netrc&lt;/code&gt; file&lt;/a&gt; on a per-extractor basis. For that, you will need to create a &lt;code&gt;.netrc&lt;/code&gt; file in &lt;code&gt;--netrc-location&lt;/code&gt; and restrict permissions to read/write by only you:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;touch ${HOME}/.netrc
chmod a-rwx,u+rw ${HOME}/.netrc
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;After that, you can add credentials for an extractor in the following format, where &lt;em&gt;extractor&lt;/em&gt; is the name of the extractor in lowercase:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;machine &amp;lt;extractor&amp;gt; login &amp;lt;username&amp;gt; password &amp;lt;password&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;E.g.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;machine youtube login myaccount@gmail.com password my_youtube_password
machine twitch login my_twitch_account_name password my_twitch_password
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To activate authentication with the &lt;code&gt;.netrc&lt;/code&gt; file you should pass &lt;code&gt;--netrc&lt;/code&gt; to yt-dlp or place it in the &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#configuration"&gt;configuration file&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;The default location of the .netrc file is &lt;code&gt;~&lt;/code&gt; (see below).&lt;/p&gt; 
&lt;p&gt;As an alternative to using the &lt;code&gt;.netrc&lt;/code&gt; file, which has the disadvantage of keeping your passwords in a plain text file, you can configure a custom shell command to provide the credentials for an extractor. This is done by providing the &lt;code&gt;--netrc-cmd&lt;/code&gt; parameter, it shall output the credentials in the netrc format and return &lt;code&gt;0&lt;/code&gt; on success, other values will be treated as an error. &lt;code&gt;{}&lt;/code&gt; in the command will be replaced by the name of the extractor to make it possible to select the credentials for the right extractor.&lt;/p&gt; 
&lt;p&gt;E.g. To use an encrypted &lt;code&gt;.netrc&lt;/code&gt; file stored as &lt;code&gt;.authinfo.gpg&lt;/code&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;yt-dlp --netrc-cmd 'gpg --decrypt ~/.authinfo.gpg' 'https://www.youtube.com/watch?v=BaW_jenozKc'
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Notes about environment variables&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Environment variables are normally specified as &lt;code&gt;${VARIABLE}&lt;/code&gt;/&lt;code&gt;$VARIABLE&lt;/code&gt; on UNIX and &lt;code&gt;%VARIABLE%&lt;/code&gt; on Windows; but is always shown as &lt;code&gt;${VARIABLE}&lt;/code&gt; in this documentation&lt;/li&gt; 
 &lt;li&gt;yt-dlp also allows using UNIX-style variables on Windows for path-like options; e.g. &lt;code&gt;--output&lt;/code&gt;, &lt;code&gt;--config-location&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;If unset, &lt;code&gt;${XDG_CONFIG_HOME}&lt;/code&gt; defaults to &lt;code&gt;~/.config&lt;/code&gt; and &lt;code&gt;${XDG_CACHE_HOME}&lt;/code&gt; to &lt;code&gt;~/.cache&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;On Windows, &lt;code&gt;~&lt;/code&gt; points to &lt;code&gt;${HOME}&lt;/code&gt; if present; or, &lt;code&gt;${USERPROFILE}&lt;/code&gt; or &lt;code&gt;${HOMEDRIVE}${HOMEPATH}&lt;/code&gt; otherwise&lt;/li&gt; 
 &lt;li&gt;On Windows, &lt;code&gt;${USERPROFILE}&lt;/code&gt; generally points to &lt;code&gt;C:\Users\&amp;lt;user name&amp;gt;&lt;/code&gt; and &lt;code&gt;${APPDATA}&lt;/code&gt; to &lt;code&gt;${USERPROFILE}\AppData\Roaming&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;OUTPUT TEMPLATE&lt;/h1&gt; 
&lt;p&gt;The &lt;code&gt;-o&lt;/code&gt; option is used to indicate a template for the output file names while &lt;code&gt;-P&lt;/code&gt; option is used to specify the path each type of file should be saved to.&lt;/p&gt; 
&lt;!-- MANPAGE: BEGIN EXCLUDED SECTION --&gt; 
&lt;p&gt;&lt;strong&gt;tl;dr:&lt;/strong&gt; &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#output-template-examples"&gt;navigate me to examples&lt;/a&gt;.&lt;/p&gt; 
&lt;!-- MANPAGE: END EXCLUDED SECTION --&gt; 
&lt;p&gt;The simplest usage of &lt;code&gt;-o&lt;/code&gt; is not to set any template arguments when downloading a single file, like in &lt;code&gt;yt-dlp -o funny_video.flv "https://some/video"&lt;/code&gt; (hard-coding file extension like this is &lt;em&gt;not&lt;/em&gt; recommended and could break some post-processing).&lt;/p&gt; 
&lt;p&gt;It may however also contain special sequences that will be replaced when downloading each video. The special sequences may be formatted according to &lt;a href="https://docs.python.org/3/library/stdtypes.html#printf-style-string-formatting"&gt;Python string formatting operations&lt;/a&gt;, e.g. &lt;code&gt;%(NAME)s&lt;/code&gt; or &lt;code&gt;%(NAME)05d&lt;/code&gt;. To clarify, that is a percent symbol followed by a name in parentheses, followed by formatting operations.&lt;/p&gt; 
&lt;p&gt;The field names themselves (the part inside the parenthesis) can also have some special formatting:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Object traversal&lt;/strong&gt;: The dictionaries and lists available in metadata can be traversed by using a dot &lt;code&gt;.&lt;/code&gt; separator; e.g. &lt;code&gt;%(tags.0)s&lt;/code&gt;, &lt;code&gt;%(subtitles.en.-1.ext)s&lt;/code&gt;. You can do Python slicing with colon &lt;code&gt;:&lt;/code&gt;; E.g. &lt;code&gt;%(id.3:7)s&lt;/code&gt;, &lt;code&gt;%(id.6:2:-1)s&lt;/code&gt;, &lt;code&gt;%(formats.:.format_id)s&lt;/code&gt;. Curly braces &lt;code&gt;{}&lt;/code&gt; can be used to build dictionaries with only specific keys; e.g. &lt;code&gt;%(formats.:.{format_id,height})#j&lt;/code&gt;. An empty field name &lt;code&gt;%()s&lt;/code&gt; refers to the entire infodict; e.g. &lt;code&gt;%(.{id,title})s&lt;/code&gt;. Note that all the fields that become available using this method are not listed below. Use &lt;code&gt;-j&lt;/code&gt; to see such fields&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Arithmetic&lt;/strong&gt;: Simple arithmetic can be done on numeric fields using &lt;code&gt;+&lt;/code&gt;, &lt;code&gt;-&lt;/code&gt; and &lt;code&gt;*&lt;/code&gt;. E.g. &lt;code&gt;%(playlist_index+10)03d&lt;/code&gt;, &lt;code&gt;%(n_entries+1-playlist_index)d&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Date/time Formatting&lt;/strong&gt;: Date/time fields can be formatted according to &lt;a href="https://docs.python.org/3/library/datetime.html#strftime-and-strptime-format-codes"&gt;strftime formatting&lt;/a&gt; by specifying it separated from the field name using a &lt;code&gt;&amp;gt;&lt;/code&gt;. E.g. &lt;code&gt;%(duration&amp;gt;%H-%M-%S)s&lt;/code&gt;, &lt;code&gt;%(upload_date&amp;gt;%Y-%m-%d)s&lt;/code&gt;, &lt;code&gt;%(epoch-3600&amp;gt;%H-%M-%S)s&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Alternatives&lt;/strong&gt;: Alternate fields can be specified separated with a &lt;code&gt;,&lt;/code&gt;. E.g. &lt;code&gt;%(release_date&amp;gt;%Y,upload_date&amp;gt;%Y|Unknown)s&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Replacement&lt;/strong&gt;: A replacement value can be specified using a &lt;code&gt;&amp;amp;&lt;/code&gt; separator according to the &lt;a href="https://docs.python.org/3/library/string.html#format-specification-mini-language"&gt;&lt;code&gt;str.format&lt;/code&gt; mini-language&lt;/a&gt;. If the field is &lt;em&gt;not&lt;/em&gt; empty, this replacement value will be used instead of the actual field content. This is done after alternate fields are considered; thus the replacement is used if &lt;em&gt;any&lt;/em&gt; of the alternative fields is &lt;em&gt;not&lt;/em&gt; empty. E.g. &lt;code&gt;%(chapters&amp;amp;has chapters|no chapters)s&lt;/code&gt;, &lt;code&gt;%(title&amp;amp;TITLE={:&amp;gt;20}|NO TITLE)s&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Default&lt;/strong&gt;: A literal default value can be specified for when the field is empty using a &lt;code&gt;|&lt;/code&gt; separator. This overrides &lt;code&gt;--output-na-placeholder&lt;/code&gt;. E.g. &lt;code&gt;%(uploader|Unknown)s&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;More Conversions&lt;/strong&gt;: In addition to the normal format types &lt;code&gt;diouxXeEfFgGcrs&lt;/code&gt;, yt-dlp additionally supports converting to &lt;code&gt;B&lt;/code&gt; = &lt;strong&gt;B&lt;/strong&gt;ytes, &lt;code&gt;j&lt;/code&gt; = &lt;strong&gt;j&lt;/strong&gt;son (flag &lt;code&gt;#&lt;/code&gt; for pretty-printing, &lt;code&gt;+&lt;/code&gt; for Unicode), &lt;code&gt;h&lt;/code&gt; = HTML escaping, &lt;code&gt;l&lt;/code&gt; = a comma separated &lt;strong&gt;l&lt;/strong&gt;ist (flag &lt;code&gt;#&lt;/code&gt; for &lt;code&gt;\n&lt;/code&gt; newline-separated), &lt;code&gt;q&lt;/code&gt; = a string &lt;strong&gt;q&lt;/strong&gt;uoted for the terminal (flag &lt;code&gt;#&lt;/code&gt; to split a list into different arguments), &lt;code&gt;D&lt;/code&gt; = add &lt;strong&gt;D&lt;/strong&gt;ecimal suffixes (e.g. 10M) (flag &lt;code&gt;#&lt;/code&gt; to use 1024 as factor), and &lt;code&gt;S&lt;/code&gt; = &lt;strong&gt;S&lt;/strong&gt;anitize as filename (flag &lt;code&gt;#&lt;/code&gt; for restricted)&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Unicode normalization&lt;/strong&gt;: The format type &lt;code&gt;U&lt;/code&gt; can be used for NFC &lt;a href="https://docs.python.org/3/library/unicodedata.html#unicodedata.normalize"&gt;Unicode normalization&lt;/a&gt;. The alternate form flag (&lt;code&gt;#&lt;/code&gt;) changes the normalization to NFD and the conversion flag &lt;code&gt;+&lt;/code&gt; can be used for NFKC/NFKD compatibility equivalence normalization. E.g. &lt;code&gt;%(title)+.100U&lt;/code&gt; is NFKC&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;To summarize, the general syntax for a field is:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;%(name[.keys][addition][&amp;gt;strf][,alternate][&amp;amp;replacement][|default])[flags][width][.precision][length]type
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Additionally, you can set different output templates for the various metadata files separately from the general output template by specifying the type of file followed by the template separated by a colon &lt;code&gt;:&lt;/code&gt;. The different file types supported are &lt;code&gt;subtitle&lt;/code&gt;, &lt;code&gt;thumbnail&lt;/code&gt;, &lt;code&gt;description&lt;/code&gt;, &lt;code&gt;annotation&lt;/code&gt; (deprecated), &lt;code&gt;infojson&lt;/code&gt;, &lt;code&gt;link&lt;/code&gt;, &lt;code&gt;pl_thumbnail&lt;/code&gt;, &lt;code&gt;pl_description&lt;/code&gt;, &lt;code&gt;pl_infojson&lt;/code&gt;, &lt;code&gt;chapter&lt;/code&gt;, &lt;code&gt;pl_video&lt;/code&gt;. E.g. &lt;code&gt;-o "%(title)s.%(ext)s" -o "thumbnail:%(title)s\%(title)s.%(ext)s"&lt;/code&gt; will put the thumbnails in a folder with the same name as the video. If any of the templates is empty, that type of file will not be written. E.g. &lt;code&gt;--write-thumbnail -o "thumbnail:"&lt;/code&gt; will write thumbnails only for playlists and not for video.&lt;/p&gt; 
&lt;p&gt;&lt;a id="outtmpl-postprocess-note"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: Due to post-processing (i.e. merging etc.), the actual output filename might differ. Use &lt;code&gt;--print after_move:filepath&lt;/code&gt; to get the name after all post-processing is complete.&lt;/p&gt; 
&lt;p&gt;The available fields are:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;id&lt;/code&gt; (string): Video identifier&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;title&lt;/code&gt; (string): Video title&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;fulltitle&lt;/code&gt; (string): Video title ignoring live timestamp and generic title&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;ext&lt;/code&gt; (string): Video filename extension&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;alt_title&lt;/code&gt; (string): A secondary title of the video&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;description&lt;/code&gt; (string): The description of the video&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;display_id&lt;/code&gt; (string): An alternative identifier for the video&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;uploader&lt;/code&gt; (string): Full name of the video uploader&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;uploader_id&lt;/code&gt; (string): Nickname or id of the video uploader&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;uploader_url&lt;/code&gt; (string): URL to the video uploader's profile&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;license&lt;/code&gt; (string): License name the video is licensed under&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;creators&lt;/code&gt; (list): The creators of the video&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;creator&lt;/code&gt; (string): The creators of the video; comma-separated&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;timestamp&lt;/code&gt; (numeric): UNIX timestamp of the moment the video became available&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;upload_date&lt;/code&gt; (string): Video upload date in UTC (YYYYMMDD)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;release_timestamp&lt;/code&gt; (numeric): UNIX timestamp of the moment the video was released&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;release_date&lt;/code&gt; (string): The date (YYYYMMDD) when the video was released in UTC&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;release_year&lt;/code&gt; (numeric): Year (YYYY) when the video or album was released&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;modified_timestamp&lt;/code&gt; (numeric): UNIX timestamp of the moment the video was last modified&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;modified_date&lt;/code&gt; (string): The date (YYYYMMDD) when the video was last modified in UTC&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;channel&lt;/code&gt; (string): Full name of the channel the video is uploaded on&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;channel_id&lt;/code&gt; (string): Id of the channel&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;channel_url&lt;/code&gt; (string): URL of the channel&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;channel_follower_count&lt;/code&gt; (numeric): Number of followers of the channel&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;channel_is_verified&lt;/code&gt; (boolean): Whether the channel is verified on the platform&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;location&lt;/code&gt; (string): Physical location where the video was filmed&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;duration&lt;/code&gt; (numeric): Length of the video in seconds&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;duration_string&lt;/code&gt; (string): Length of the video (HH:mm:ss)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;view_count&lt;/code&gt; (numeric): How many users have watched the video on the platform&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;concurrent_view_count&lt;/code&gt; (numeric): How many users are currently watching the video on the platform.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;like_count&lt;/code&gt; (numeric): Number of positive ratings of the video&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;dislike_count&lt;/code&gt; (numeric): Number of negative ratings of the video&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;repost_count&lt;/code&gt; (numeric): Number of reposts of the video&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;average_rating&lt;/code&gt; (numeric): Average rating given by users, the scale used depends on the webpage&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;comment_count&lt;/code&gt; (numeric): Number of comments on the video (For some extractors, comments are only downloaded at the end, and so this field cannot be used)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;age_limit&lt;/code&gt; (numeric): Age restriction for the video (years)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;live_status&lt;/code&gt; (string): One of "not_live", "is_live", "is_upcoming", "was_live", "post_live" (was live, but VOD is not yet processed)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;is_live&lt;/code&gt; (boolean): Whether this video is a live stream or a fixed-length video&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;was_live&lt;/code&gt; (boolean): Whether this video was originally a live stream&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;playable_in_embed&lt;/code&gt; (string): Whether this video is allowed to play in embedded players on other sites&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;availability&lt;/code&gt; (string): Whether the video is "private", "premium_only", "subscriber_only", "needs_auth", "unlisted" or "public"&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;media_type&lt;/code&gt; (string): The type of media as classified by the site, e.g. "episode", "clip", "trailer"&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;start_time&lt;/code&gt; (numeric): Time in seconds where the reproduction should start, as specified in the URL&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;end_time&lt;/code&gt; (numeric): Time in seconds where the reproduction should end, as specified in the URL&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;extractor&lt;/code&gt; (string): Name of the extractor&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;extractor_key&lt;/code&gt; (string): Key name of the extractor&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;epoch&lt;/code&gt; (numeric): Unix epoch of when the information extraction was completed&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;autonumber&lt;/code&gt; (numeric): Number that will be increased with each download, starting at &lt;code&gt;--autonumber-start&lt;/code&gt;, padded with leading zeros to 5 digits&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;video_autonumber&lt;/code&gt; (numeric): Number that will be increased with each video&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;n_entries&lt;/code&gt; (numeric): Total number of extracted items in the playlist&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;playlist_id&lt;/code&gt; (string): Identifier of the playlist that contains the video&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;playlist_title&lt;/code&gt; (string): Name of the playlist that contains the video&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;playlist&lt;/code&gt; (string): &lt;code&gt;playlist_title&lt;/code&gt; if available or else &lt;code&gt;playlist_id&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;playlist_count&lt;/code&gt; (numeric): Total number of items in the playlist. May not be known if entire playlist is not extracted&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;playlist_index&lt;/code&gt; (numeric): Index of the video in the playlist padded with leading zeros according the final index&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;playlist_autonumber&lt;/code&gt; (numeric): Position of the video in the playlist download queue padded with leading zeros according to the total length of the playlist&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;playlist_uploader&lt;/code&gt; (string): Full name of the playlist uploader&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;playlist_uploader_id&lt;/code&gt; (string): Nickname or id of the playlist uploader&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;playlist_channel&lt;/code&gt; (string): Display name of the channel that uploaded the playlist&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;playlist_channel_id&lt;/code&gt; (string): Identifier of the channel that uploaded the playlist&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;playlist_webpage_url&lt;/code&gt; (string): URL of the playlist webpage&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;webpage_url&lt;/code&gt; (string): A URL to the video webpage which, if given to yt-dlp, should yield the same result again&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;webpage_url_basename&lt;/code&gt; (string): The basename of the webpage URL&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;webpage_url_domain&lt;/code&gt; (string): The domain of the webpage URL&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;original_url&lt;/code&gt; (string): The URL given by the user (or the same as &lt;code&gt;webpage_url&lt;/code&gt; for playlist entries)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;categories&lt;/code&gt; (list): List of categories the video belongs to&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;tags&lt;/code&gt; (list): List of tags assigned to the video&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;cast&lt;/code&gt; (list): List of cast members&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;All the fields in &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#filtering-formats"&gt;Filtering Formats&lt;/a&gt; can also be used&lt;/p&gt; 
&lt;p&gt;Available for the video that belongs to some logical chapter or section:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;chapter&lt;/code&gt; (string): Name or title of the chapter the video belongs to&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;chapter_number&lt;/code&gt; (numeric): Number of the chapter the video belongs to&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;chapter_id&lt;/code&gt; (string): Id of the chapter the video belongs to&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Available for the video that is an episode of some series or program:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;series&lt;/code&gt; (string): Title of the series or program the video episode belongs to&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;series_id&lt;/code&gt; (string): Id of the series or program the video episode belongs to&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;season&lt;/code&gt; (string): Title of the season the video episode belongs to&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;season_number&lt;/code&gt; (numeric): Number of the season the video episode belongs to&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;season_id&lt;/code&gt; (string): Id of the season the video episode belongs to&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;episode&lt;/code&gt; (string): Title of the video episode&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;episode_number&lt;/code&gt; (numeric): Number of the video episode within a season&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;episode_id&lt;/code&gt; (string): Id of the video episode&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Available for the media that is a track or a part of a music album:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;track&lt;/code&gt; (string): Title of the track&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;track_number&lt;/code&gt; (numeric): Number of the track within an album or a disc&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;track_id&lt;/code&gt; (string): Id of the track&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;artists&lt;/code&gt; (list): Artist(s) of the track&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;artist&lt;/code&gt; (string): Artist(s) of the track; comma-separated&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;genres&lt;/code&gt; (list): Genre(s) of the track&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;genre&lt;/code&gt; (string): Genre(s) of the track; comma-separated&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;composers&lt;/code&gt; (list): Composer(s) of the piece&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;composer&lt;/code&gt; (string): Composer(s) of the piece; comma-separated&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;album&lt;/code&gt; (string): Title of the album the track belongs to&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;album_type&lt;/code&gt; (string): Type of the album&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;album_artists&lt;/code&gt; (list): All artists appeared on the album&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;album_artist&lt;/code&gt; (string): All artists appeared on the album; comma-separated&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;disc_number&lt;/code&gt; (numeric): Number of the disc or other physical medium the track belongs to&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Available only when using &lt;code&gt;--download-sections&lt;/code&gt; and for &lt;code&gt;chapter:&lt;/code&gt; prefix when using &lt;code&gt;--split-chapters&lt;/code&gt; for videos with internal chapters:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;section_title&lt;/code&gt; (string): Title of the chapter&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;section_number&lt;/code&gt; (numeric): Number of the chapter within the file&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;section_start&lt;/code&gt; (numeric): Start time of the chapter in seconds&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;section_end&lt;/code&gt; (numeric): End time of the chapter in seconds&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Available only when used in &lt;code&gt;--print&lt;/code&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;urls&lt;/code&gt; (string): The URLs of all requested formats, one in each line&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;filename&lt;/code&gt; (string): Name of the video file. Note that the &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#outtmpl-postprocess-note"&gt;actual filename may differ&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;formats_table&lt;/code&gt; (table): The video format table as printed by &lt;code&gt;--list-formats&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;thumbnails_table&lt;/code&gt; (table): The thumbnail format table as printed by &lt;code&gt;--list-thumbnails&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;subtitles_table&lt;/code&gt; (table): The subtitle format table as printed by &lt;code&gt;--list-subs&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;automatic_captions_table&lt;/code&gt; (table): The automatic subtitle format table as printed by &lt;code&gt;--list-subs&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Available only after the video is downloaded (&lt;code&gt;post_process&lt;/code&gt;/&lt;code&gt;after_move&lt;/code&gt;):&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;filepath&lt;/code&gt;: Actual path of downloaded video file&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Available only in &lt;code&gt;--sponsorblock-chapter-title&lt;/code&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;start_time&lt;/code&gt; (numeric): Start time of the chapter in seconds&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;end_time&lt;/code&gt; (numeric): End time of the chapter in seconds&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;categories&lt;/code&gt; (list): The &lt;a href="https://wiki.sponsor.ajay.app/w/Types#Category"&gt;SponsorBlock categories&lt;/a&gt; the chapter belongs to&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;category&lt;/code&gt; (string): The smallest SponsorBlock category the chapter belongs to&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;category_names&lt;/code&gt; (list): Friendly names of the categories&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;name&lt;/code&gt; (string): Friendly name of the smallest category&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;type&lt;/code&gt; (string): The &lt;a href="https://wiki.sponsor.ajay.app/w/Types#Action_Type"&gt;SponsorBlock action type&lt;/a&gt; of the chapter&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Each aforementioned sequence when referenced in an output template will be replaced by the actual value corresponding to the sequence name. E.g. for &lt;code&gt;-o %(title)s-%(id)s.%(ext)s&lt;/code&gt; and an mp4 video with title &lt;code&gt;yt-dlp test video&lt;/code&gt; and id &lt;code&gt;BaW_jenozKc&lt;/code&gt;, this will result in a &lt;code&gt;yt-dlp test video-BaW_jenozKc.mp4&lt;/code&gt; file created in the current directory.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: Some of the sequences are not guaranteed to be present, since they depend on the metadata obtained by a particular extractor. Such sequences will be replaced with placeholder value provided with &lt;code&gt;--output-na-placeholder&lt;/code&gt; (&lt;code&gt;NA&lt;/code&gt; by default).&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Tip&lt;/strong&gt;: Look at the &lt;code&gt;-j&lt;/code&gt; output to identify which fields are available for the particular URL&lt;/p&gt; 
&lt;p&gt;For numeric sequences, you can use &lt;a href="https://docs.python.org/3/library/stdtypes.html#printf-style-string-formatting"&gt;numeric related formatting&lt;/a&gt;; e.g. &lt;code&gt;%(view_count)05d&lt;/code&gt; will result in a string with view count padded with zeros up to 5 characters, like in &lt;code&gt;00042&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Output templates can also contain arbitrary hierarchical path, e.g. &lt;code&gt;-o "%(playlist)s/%(playlist_index)s - %(title)s.%(ext)s"&lt;/code&gt; which will result in downloading each video in a directory corresponding to this path template. Any missing directory will be automatically created for you.&lt;/p&gt; 
&lt;p&gt;To use percent literals in an output template use &lt;code&gt;%%&lt;/code&gt;. To output to stdout use &lt;code&gt;-o -&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;The current default template is &lt;code&gt;%(title)s [%(id)s].%(ext)s&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;In some cases, you don't want special characters such as 中, spaces, or &amp;amp;, such as when transferring the downloaded filename to a Windows system or the filename through an 8bit-unsafe channel. In these cases, add the &lt;code&gt;--restrict-filenames&lt;/code&gt; flag to get a shorter title.&lt;/p&gt; 
&lt;h4&gt;Output template examples&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;$ yt-dlp --print filename -o "test video.%(ext)s" BaW_jenozKc
test video.webm    # Literal name with correct extension

$ yt-dlp --print filename -o "%(title)s.%(ext)s" BaW_jenozKc
youtube-dl test video ''_ä↭𝕐.webm    # All kinds of weird characters

$ yt-dlp --print filename -o "%(title)s.%(ext)s" BaW_jenozKc --restrict-filenames
youtube-dl_test_video_.webm    # Restricted file name

# Download YouTube playlist videos in separate directory indexed by video order in a playlist
$ yt-dlp -o "%(playlist)s/%(playlist_index)s - %(title)s.%(ext)s" "https://www.youtube.com/playlist?list=PLwiyx1dc3P2JR9N8gQaQN_BCvlSlap7re"

# Download YouTube playlist videos in separate directories according to their uploaded year
$ yt-dlp -o "%(upload_date&amp;gt;%Y)s/%(title)s.%(ext)s" "https://www.youtube.com/playlist?list=PLwiyx1dc3P2JR9N8gQaQN_BCvlSlap7re"

# Prefix playlist index with " - " separator, but only if it is available
$ yt-dlp -o "%(playlist_index&amp;amp;{} - |)s%(title)s.%(ext)s" BaW_jenozKc "https://www.youtube.com/user/TheLinuxFoundation/playlists"

# Download all playlists of YouTube channel/user keeping each playlist in separate directory:
$ yt-dlp -o "%(uploader)s/%(playlist)s/%(playlist_index)s - %(title)s.%(ext)s" "https://www.youtube.com/user/TheLinuxFoundation/playlists"

# Download Udemy course keeping each chapter in separate directory under MyVideos directory in your home
$ yt-dlp -u user -p password -P "~/MyVideos" -o "%(playlist)s/%(chapter_number)s - %(chapter)s/%(title)s.%(ext)s" "https://www.udemy.com/java-tutorial"

# Download entire series season keeping each series and each season in separate directory under C:/MyVideos
$ yt-dlp -P "C:/MyVideos" -o "%(series)s/%(season_number)s - %(season)s/%(episode_number)s - %(episode)s.%(ext)s" "https://videomore.ru/kino_v_detalayah/5_sezon/367617"

# Download video as "C:\MyVideos\uploader\title.ext", subtitles as "C:\MyVideos\subs\uploader\title.ext"
# and put all temporary files in "C:\MyVideos\tmp"
$ yt-dlp -P "C:/MyVideos" -P "temp:tmp" -P "subtitle:subs" -o "%(uploader)s/%(title)s.%(ext)s" BaW_jenozKc --write-subs

# Download video as "C:\MyVideos\uploader\title.ext" and subtitles as "C:\MyVideos\uploader\subs\title.ext"
$ yt-dlp -P "C:/MyVideos" -o "%(uploader)s/%(title)s.%(ext)s" -o "subtitle:%(uploader)s/subs/%(title)s.%(ext)s" BaW_jenozKc --write-subs

# Stream the video being downloaded to stdout
$ yt-dlp -o - BaW_jenozKc
&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;FORMAT SELECTION&lt;/h1&gt; 
&lt;p&gt;By default, yt-dlp tries to download the best available quality if you &lt;strong&gt;don't&lt;/strong&gt; pass any options. This is generally equivalent to using &lt;code&gt;-f bestvideo*+bestaudio/best&lt;/code&gt;. However, if multiple audiostreams is enabled (&lt;code&gt;--audio-multistreams&lt;/code&gt;), the default format changes to &lt;code&gt;-f bestvideo+bestaudio/best&lt;/code&gt;. Similarly, if ffmpeg is unavailable, or if you use yt-dlp to stream to &lt;code&gt;stdout&lt;/code&gt; (&lt;code&gt;-o -&lt;/code&gt;), the default becomes &lt;code&gt;-f best/bestvideo+bestaudio&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Deprecation warning&lt;/strong&gt;: Latest versions of yt-dlp can stream multiple formats to the stdout simultaneously using ffmpeg. So, in future versions, the default for this will be set to &lt;code&gt;-f bv*+ba/b&lt;/code&gt; similar to normal downloads. If you want to preserve the &lt;code&gt;-f b/bv+ba&lt;/code&gt; setting, it is recommended to explicitly specify it in the configuration options.&lt;/p&gt; 
&lt;p&gt;The general syntax for format selection is &lt;code&gt;-f FORMAT&lt;/code&gt; (or &lt;code&gt;--format FORMAT&lt;/code&gt;) where &lt;code&gt;FORMAT&lt;/code&gt; is a &lt;em&gt;selector expression&lt;/em&gt;, i.e. an expression that describes format or formats you would like to download.&lt;/p&gt; 
&lt;!-- MANPAGE: BEGIN EXCLUDED SECTION --&gt; 
&lt;p&gt;&lt;strong&gt;tl;dr:&lt;/strong&gt; &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#format-selection-examples"&gt;navigate me to examples&lt;/a&gt;.&lt;/p&gt; 
&lt;!-- MANPAGE: END EXCLUDED SECTION --&gt; 
&lt;p&gt;The simplest case is requesting a specific format; e.g. with &lt;code&gt;-f 22&lt;/code&gt; you can download the format with format code equal to 22. You can get the list of available format codes for particular video using &lt;code&gt;--list-formats&lt;/code&gt; or &lt;code&gt;-F&lt;/code&gt;. Note that these format codes are extractor specific.&lt;/p&gt; 
&lt;p&gt;You can also use a file extension (currently &lt;code&gt;3gp&lt;/code&gt;, &lt;code&gt;aac&lt;/code&gt;, &lt;code&gt;flv&lt;/code&gt;, &lt;code&gt;m4a&lt;/code&gt;, &lt;code&gt;mp3&lt;/code&gt;, &lt;code&gt;mp4&lt;/code&gt;, &lt;code&gt;ogg&lt;/code&gt;, &lt;code&gt;wav&lt;/code&gt;, &lt;code&gt;webm&lt;/code&gt; are supported) to download the best quality format of a particular file extension served as a single file, e.g. &lt;code&gt;-f webm&lt;/code&gt; will download the best quality format with the &lt;code&gt;webm&lt;/code&gt; extension served as a single file.&lt;/p&gt; 
&lt;p&gt;You can use &lt;code&gt;-f -&lt;/code&gt; to interactively provide the format selector &lt;em&gt;for each video&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;You can also use special names to select particular edge case formats:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;all&lt;/code&gt;: Select &lt;strong&gt;all formats&lt;/strong&gt; separately&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;mergeall&lt;/code&gt;: Select and &lt;strong&gt;merge all formats&lt;/strong&gt; (Must be used with &lt;code&gt;--audio-multistreams&lt;/code&gt;, &lt;code&gt;--video-multistreams&lt;/code&gt; or both)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;b*&lt;/code&gt;, &lt;code&gt;best*&lt;/code&gt;: Select the best quality format that &lt;strong&gt;contains either&lt;/strong&gt; a video or an audio or both (i.e.; &lt;code&gt;vcodec!=none or acodec!=none&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;b&lt;/code&gt;, &lt;code&gt;best&lt;/code&gt;: Select the best quality format that &lt;strong&gt;contains both&lt;/strong&gt; video and audio. Equivalent to &lt;code&gt;best*[vcodec!=none][acodec!=none]&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;bv&lt;/code&gt;, &lt;code&gt;bestvideo&lt;/code&gt;: Select the best quality &lt;strong&gt;video-only&lt;/strong&gt; format. Equivalent to &lt;code&gt;best*[acodec=none]&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;bv*&lt;/code&gt;, &lt;code&gt;bestvideo*&lt;/code&gt;: Select the best quality format that &lt;strong&gt;contains video&lt;/strong&gt;. It may also contain audio. Equivalent to &lt;code&gt;best*[vcodec!=none]&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;ba&lt;/code&gt;, &lt;code&gt;bestaudio&lt;/code&gt;: Select the best quality &lt;strong&gt;audio-only&lt;/strong&gt; format. Equivalent to &lt;code&gt;best*[vcodec=none]&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;ba*&lt;/code&gt;, &lt;code&gt;bestaudio*&lt;/code&gt;: Select the best quality format that &lt;strong&gt;contains audio&lt;/strong&gt;. It may also contain video. Equivalent to &lt;code&gt;best*[acodec!=none]&lt;/code&gt; (&lt;a href="https://github.com/yt-dlp/yt-dlp/issues/979#issuecomment-919629354"&gt;Do not use!&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;w*&lt;/code&gt;, &lt;code&gt;worst*&lt;/code&gt;: Select the worst quality format that contains either a video or an audio&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;w&lt;/code&gt;, &lt;code&gt;worst&lt;/code&gt;: Select the worst quality format that contains both video and audio. Equivalent to &lt;code&gt;worst*[vcodec!=none][acodec!=none]&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;wv&lt;/code&gt;, &lt;code&gt;worstvideo&lt;/code&gt;: Select the worst quality video-only format. Equivalent to &lt;code&gt;worst*[acodec=none]&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;wv*&lt;/code&gt;, &lt;code&gt;worstvideo*&lt;/code&gt;: Select the worst quality format that contains video. It may also contain audio. Equivalent to &lt;code&gt;worst*[vcodec!=none]&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;wa&lt;/code&gt;, &lt;code&gt;worstaudio&lt;/code&gt;: Select the worst quality audio-only format. Equivalent to &lt;code&gt;worst*[vcodec=none]&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;wa*&lt;/code&gt;, &lt;code&gt;worstaudio*&lt;/code&gt;: Select the worst quality format that contains audio. It may also contain video. Equivalent to &lt;code&gt;worst*[acodec!=none]&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For example, to download the worst quality video-only format you can use &lt;code&gt;-f worstvideo&lt;/code&gt;. It is, however, recommended not to use &lt;code&gt;worst&lt;/code&gt; and related options. When your format selector is &lt;code&gt;worst&lt;/code&gt;, the format which is worst in all respects is selected. Most of the time, what you actually want is the video with the smallest filesize instead. So it is generally better to use &lt;code&gt;-S +size&lt;/code&gt; or more rigorously, &lt;code&gt;-S +size,+br,+res,+fps&lt;/code&gt; instead of &lt;code&gt;-f worst&lt;/code&gt;. See &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#sorting-formats"&gt;Sorting Formats&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;p&gt;You can select the n'th best format of a type by using &lt;code&gt;best&amp;lt;type&amp;gt;.&amp;lt;n&amp;gt;&lt;/code&gt;. For example, &lt;code&gt;best.2&lt;/code&gt; will select the 2nd best combined format. Similarly, &lt;code&gt;bv*.3&lt;/code&gt; will select the 3rd best format that contains a video stream.&lt;/p&gt; 
&lt;p&gt;If you want to download multiple videos, and they don't have the same formats available, you can specify the order of preference using slashes. Note that formats on the left hand side are preferred; e.g. &lt;code&gt;-f 22/17/18&lt;/code&gt; will download format 22 if it's available, otherwise it will download format 17 if it's available, otherwise it will download format 18 if it's available, otherwise it will complain that no suitable formats are available for download.&lt;/p&gt; 
&lt;p&gt;If you want to download several formats of the same video use a comma as a separator, e.g. &lt;code&gt;-f 22,17,18&lt;/code&gt; will download all these three formats, of course if they are available. Or a more sophisticated example combined with the precedence feature: &lt;code&gt;-f 136/137/mp4/bestvideo,140/m4a/bestaudio&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;You can merge the video and audio of multiple formats into a single file using &lt;code&gt;-f &amp;lt;format1&amp;gt;+&amp;lt;format2&amp;gt;+...&lt;/code&gt; (requires ffmpeg installed); e.g. &lt;code&gt;-f bestvideo+bestaudio&lt;/code&gt; will download the best video-only format, the best audio-only format and mux them together with ffmpeg.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Deprecation warning&lt;/strong&gt;: Since the &lt;em&gt;below&lt;/em&gt; described behavior is complex and counter-intuitive, this will be removed and multistreams will be enabled by default in the future. A new operator will be instead added to limit formats to single audio/video&lt;/p&gt; 
&lt;p&gt;Unless &lt;code&gt;--video-multistreams&lt;/code&gt; is used, all formats with a video stream except the first one are ignored. Similarly, unless &lt;code&gt;--audio-multistreams&lt;/code&gt; is used, all formats with an audio stream except the first one are ignored. E.g. &lt;code&gt;-f bestvideo+best+bestaudio --video-multistreams --audio-multistreams&lt;/code&gt; will download and merge all 3 given formats. The resulting file will have 2 video streams and 2 audio streams. But &lt;code&gt;-f bestvideo+best+bestaudio --no-video-multistreams&lt;/code&gt; will download and merge only &lt;code&gt;bestvideo&lt;/code&gt; and &lt;code&gt;bestaudio&lt;/code&gt;. &lt;code&gt;best&lt;/code&gt; is ignored since another format containing a video stream (&lt;code&gt;bestvideo&lt;/code&gt;) has already been selected. The order of the formats is therefore important. &lt;code&gt;-f best+bestaudio --no-audio-multistreams&lt;/code&gt; will download only &lt;code&gt;best&lt;/code&gt; while &lt;code&gt;-f bestaudio+best --no-audio-multistreams&lt;/code&gt; will ignore &lt;code&gt;best&lt;/code&gt; and download only &lt;code&gt;bestaudio&lt;/code&gt;.&lt;/p&gt; 
&lt;h2&gt;Filtering Formats&lt;/h2&gt; 
&lt;p&gt;You can also filter the video formats by putting a condition in brackets, as in &lt;code&gt;-f "best[height=720]"&lt;/code&gt; (or &lt;code&gt;-f "[filesize&amp;gt;10M]"&lt;/code&gt; since filters without a selector are interpreted as &lt;code&gt;best&lt;/code&gt;).&lt;/p&gt; 
&lt;p&gt;The following numeric meta fields can be used with comparisons &lt;code&gt;&amp;lt;&lt;/code&gt;, &lt;code&gt;&amp;lt;=&lt;/code&gt;, &lt;code&gt;&amp;gt;&lt;/code&gt;, &lt;code&gt;&amp;gt;=&lt;/code&gt;, &lt;code&gt;=&lt;/code&gt; (equals), &lt;code&gt;!=&lt;/code&gt; (not equals):&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;filesize&lt;/code&gt;: The number of bytes, if known in advance&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;filesize_approx&lt;/code&gt;: An estimate for the number of bytes&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;width&lt;/code&gt;: Width of the video, if known&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;height&lt;/code&gt;: Height of the video, if known&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;aspect_ratio&lt;/code&gt;: Aspect ratio of the video, if known&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;tbr&lt;/code&gt;: Average bitrate of audio and video in &lt;a href="##" title="1000 bits/sec"&gt;kbps&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;abr&lt;/code&gt;: Average audio bitrate in &lt;a href="##" title="1000 bits/sec"&gt;kbps&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;vbr&lt;/code&gt;: Average video bitrate in &lt;a href="##" title="1000 bits/sec"&gt;kbps&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;asr&lt;/code&gt;: Audio sampling rate in Hertz&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;fps&lt;/code&gt;: Frame rate&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;audio_channels&lt;/code&gt;: The number of audio channels&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;stretched_ratio&lt;/code&gt;: &lt;code&gt;width:height&lt;/code&gt; of the video's pixels, if not square&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Also filtering work for comparisons &lt;code&gt;=&lt;/code&gt; (equals), &lt;code&gt;^=&lt;/code&gt; (starts with), &lt;code&gt;$=&lt;/code&gt; (ends with), &lt;code&gt;*=&lt;/code&gt; (contains), &lt;code&gt;~=&lt;/code&gt; (matches regex) and following string meta fields:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;url&lt;/code&gt;: Video URL&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;ext&lt;/code&gt;: File extension&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;acodec&lt;/code&gt;: Name of the audio codec in use&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;vcodec&lt;/code&gt;: Name of the video codec in use&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;container&lt;/code&gt;: Name of the container format&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;protocol&lt;/code&gt;: The protocol that will be used for the actual download, lower-case (&lt;code&gt;http&lt;/code&gt;, &lt;code&gt;https&lt;/code&gt;, &lt;code&gt;rtsp&lt;/code&gt;, &lt;code&gt;rtmp&lt;/code&gt;, &lt;code&gt;rtmpe&lt;/code&gt;, &lt;code&gt;mms&lt;/code&gt;, &lt;code&gt;f4m&lt;/code&gt;, &lt;code&gt;ism&lt;/code&gt;, &lt;code&gt;http_dash_segments&lt;/code&gt;, &lt;code&gt;m3u8&lt;/code&gt;, or &lt;code&gt;m3u8_native&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;language&lt;/code&gt;: Language code&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;dynamic_range&lt;/code&gt;: The dynamic range of the video&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;format_id&lt;/code&gt;: A short description of the format&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;format&lt;/code&gt;: A human-readable description of the format&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;format_note&lt;/code&gt;: Additional info about the format&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;resolution&lt;/code&gt;: Textual description of width and height&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Any string comparison may be prefixed with negation &lt;code&gt;!&lt;/code&gt; in order to produce an opposite comparison, e.g. &lt;code&gt;!*=&lt;/code&gt; (does not contain). The comparand of a string comparison needs to be quoted with either double or single quotes if it contains spaces or special characters other than &lt;code&gt;._-&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: None of the aforementioned meta fields are guaranteed to be present since this solely depends on the metadata obtained by the particular extractor, i.e. the metadata offered by the website. Any other field made available by the extractor can also be used for filtering.&lt;/p&gt; 
&lt;p&gt;Formats for which the value is not known are excluded unless you put a question mark (&lt;code&gt;?&lt;/code&gt;) after the operator. You can combine format filters, so &lt;code&gt;-f "bv[height&amp;lt;=?720][tbr&amp;gt;500]"&lt;/code&gt; selects up to 720p videos (or videos where the height is not known) with a bitrate of at least 500 kbps. You can also use the filters with &lt;code&gt;all&lt;/code&gt; to download all formats that satisfy the filter, e.g. &lt;code&gt;-f "all[vcodec=none]"&lt;/code&gt; selects all audio-only formats.&lt;/p&gt; 
&lt;p&gt;Format selectors can also be grouped using parentheses; e.g. &lt;code&gt;-f "(mp4,webm)[height&amp;lt;480]"&lt;/code&gt; will download the best pre-merged mp4 and webm formats with a height lower than 480.&lt;/p&gt; 
&lt;h2&gt;Sorting Formats&lt;/h2&gt; 
&lt;p&gt;You can change the criteria for being considered the &lt;code&gt;best&lt;/code&gt; by using &lt;code&gt;-S&lt;/code&gt; (&lt;code&gt;--format-sort&lt;/code&gt;). The general format for this is &lt;code&gt;--format-sort field1,field2...&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;The available fields are:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;hasvid&lt;/code&gt;: Gives priority to formats that have a video stream&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;hasaud&lt;/code&gt;: Gives priority to formats that have an audio stream&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;ie_pref&lt;/code&gt;: The format preference&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;lang&lt;/code&gt;: The language preference as determined by the extractor (e.g. original language preferred over audio description)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;quality&lt;/code&gt;: The quality of the format&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;source&lt;/code&gt;: The preference of the source&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;proto&lt;/code&gt;: Protocol used for download (&lt;code&gt;https&lt;/code&gt;/&lt;code&gt;ftps&lt;/code&gt; &amp;gt; &lt;code&gt;http&lt;/code&gt;/&lt;code&gt;ftp&lt;/code&gt; &amp;gt; &lt;code&gt;m3u8_native&lt;/code&gt;/&lt;code&gt;m3u8&lt;/code&gt; &amp;gt; &lt;code&gt;http_dash_segments&lt;/code&gt;&amp;gt; &lt;code&gt;websocket_frag&lt;/code&gt; &amp;gt; &lt;code&gt;mms&lt;/code&gt;/&lt;code&gt;rtsp&lt;/code&gt; &amp;gt; &lt;code&gt;f4f&lt;/code&gt;/&lt;code&gt;f4m&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;vcodec&lt;/code&gt;: Video Codec (&lt;code&gt;av01&lt;/code&gt; &amp;gt; &lt;code&gt;vp9.2&lt;/code&gt; &amp;gt; &lt;code&gt;vp9&lt;/code&gt; &amp;gt; &lt;code&gt;h265&lt;/code&gt; &amp;gt; &lt;code&gt;h264&lt;/code&gt; &amp;gt; &lt;code&gt;vp8&lt;/code&gt; &amp;gt; &lt;code&gt;h263&lt;/code&gt; &amp;gt; &lt;code&gt;theora&lt;/code&gt; &amp;gt; other)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;acodec&lt;/code&gt;: Audio Codec (&lt;code&gt;flac&lt;/code&gt;/&lt;code&gt;alac&lt;/code&gt; &amp;gt; &lt;code&gt;wav&lt;/code&gt;/&lt;code&gt;aiff&lt;/code&gt; &amp;gt; &lt;code&gt;opus&lt;/code&gt; &amp;gt; &lt;code&gt;vorbis&lt;/code&gt; &amp;gt; &lt;code&gt;aac&lt;/code&gt; &amp;gt; &lt;code&gt;mp4a&lt;/code&gt; &amp;gt; &lt;code&gt;mp3&lt;/code&gt; &amp;gt; &lt;code&gt;ac4&lt;/code&gt; &amp;gt; &lt;code&gt;eac3&lt;/code&gt; &amp;gt; &lt;code&gt;ac3&lt;/code&gt; &amp;gt; &lt;code&gt;dts&lt;/code&gt; &amp;gt; other)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;codec&lt;/code&gt;: Equivalent to &lt;code&gt;vcodec,acodec&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;vext&lt;/code&gt;: Video Extension (&lt;code&gt;mp4&lt;/code&gt; &amp;gt; &lt;code&gt;mov&lt;/code&gt; &amp;gt; &lt;code&gt;webm&lt;/code&gt; &amp;gt; &lt;code&gt;flv&lt;/code&gt; &amp;gt; other). If &lt;code&gt;--prefer-free-formats&lt;/code&gt; is used, &lt;code&gt;webm&lt;/code&gt; is preferred.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;aext&lt;/code&gt;: Audio Extension (&lt;code&gt;m4a&lt;/code&gt; &amp;gt; &lt;code&gt;aac&lt;/code&gt; &amp;gt; &lt;code&gt;mp3&lt;/code&gt; &amp;gt; &lt;code&gt;ogg&lt;/code&gt; &amp;gt; &lt;code&gt;opus&lt;/code&gt; &amp;gt; &lt;code&gt;webm&lt;/code&gt; &amp;gt; other). If &lt;code&gt;--prefer-free-formats&lt;/code&gt; is used, the order changes to &lt;code&gt;ogg&lt;/code&gt; &amp;gt; &lt;code&gt;opus&lt;/code&gt; &amp;gt; &lt;code&gt;webm&lt;/code&gt; &amp;gt; &lt;code&gt;mp3&lt;/code&gt; &amp;gt; &lt;code&gt;m4a&lt;/code&gt; &amp;gt; &lt;code&gt;aac&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;ext&lt;/code&gt;: Equivalent to &lt;code&gt;vext,aext&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;filesize&lt;/code&gt;: Exact filesize, if known in advance&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;fs_approx&lt;/code&gt;: Approximate filesize&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;size&lt;/code&gt;: Exact filesize if available, otherwise approximate filesize&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;height&lt;/code&gt;: Height of video&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;width&lt;/code&gt;: Width of video&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;res&lt;/code&gt;: Video resolution, calculated as the smallest dimension.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;fps&lt;/code&gt;: Framerate of video&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;hdr&lt;/code&gt;: The dynamic range of the video (&lt;code&gt;DV&lt;/code&gt; &amp;gt; &lt;code&gt;HDR12&lt;/code&gt; &amp;gt; &lt;code&gt;HDR10+&lt;/code&gt; &amp;gt; &lt;code&gt;HDR10&lt;/code&gt; &amp;gt; &lt;code&gt;HLG&lt;/code&gt; &amp;gt; &lt;code&gt;SDR&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;channels&lt;/code&gt;: The number of audio channels&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;tbr&lt;/code&gt;: Total average bitrate in &lt;a href="##" title="1000 bits/sec"&gt;kbps&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;vbr&lt;/code&gt;: Average video bitrate in &lt;a href="##" title="1000 bits/sec"&gt;kbps&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;abr&lt;/code&gt;: Average audio bitrate in &lt;a href="##" title="1000 bits/sec"&gt;kbps&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;br&lt;/code&gt;: Average bitrate in &lt;a href="##" title="1000 bits/sec"&gt;kbps&lt;/a&gt;, &lt;code&gt;tbr&lt;/code&gt;/&lt;code&gt;vbr&lt;/code&gt;/&lt;code&gt;abr&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;asr&lt;/code&gt;: Audio sample rate in Hz&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Deprecation warning&lt;/strong&gt;: Many of these fields have (currently undocumented) aliases, that may be removed in a future version. It is recommended to use only the documented field names.&lt;/p&gt; 
&lt;p&gt;All fields, unless specified otherwise, are sorted in descending order. To reverse this, prefix the field with a &lt;code&gt;+&lt;/code&gt;. E.g. &lt;code&gt;+res&lt;/code&gt; prefers format with the smallest resolution. Additionally, you can suffix a preferred value for the fields, separated by a &lt;code&gt;:&lt;/code&gt;. E.g. &lt;code&gt;res:720&lt;/code&gt; prefers larger videos, but no larger than 720p and the smallest video if there are no videos less than 720p. For &lt;code&gt;codec&lt;/code&gt; and &lt;code&gt;ext&lt;/code&gt;, you can provide two preferred values, the first for video and the second for audio. E.g. &lt;code&gt;+codec:avc:m4a&lt;/code&gt; (equivalent to &lt;code&gt;+vcodec:avc,+acodec:m4a&lt;/code&gt;) sets the video codec preference to &lt;code&gt;h264&lt;/code&gt; &amp;gt; &lt;code&gt;h265&lt;/code&gt; &amp;gt; &lt;code&gt;vp9&lt;/code&gt; &amp;gt; &lt;code&gt;vp9.2&lt;/code&gt; &amp;gt; &lt;code&gt;av01&lt;/code&gt; &amp;gt; &lt;code&gt;vp8&lt;/code&gt; &amp;gt; &lt;code&gt;h263&lt;/code&gt; &amp;gt; &lt;code&gt;theora&lt;/code&gt; and audio codec preference to &lt;code&gt;mp4a&lt;/code&gt; &amp;gt; &lt;code&gt;aac&lt;/code&gt; &amp;gt; &lt;code&gt;vorbis&lt;/code&gt; &amp;gt; &lt;code&gt;opus&lt;/code&gt; &amp;gt; &lt;code&gt;mp3&lt;/code&gt; &amp;gt; &lt;code&gt;ac3&lt;/code&gt; &amp;gt; &lt;code&gt;dts&lt;/code&gt;. You can also make the sorting prefer the nearest values to the provided by using &lt;code&gt;~&lt;/code&gt; as the delimiter. E.g. &lt;code&gt;filesize~1G&lt;/code&gt; prefers the format with filesize closest to 1 GiB.&lt;/p&gt; 
&lt;p&gt;The fields &lt;code&gt;hasvid&lt;/code&gt; and &lt;code&gt;ie_pref&lt;/code&gt; are always given highest priority in sorting, irrespective of the user-defined order. This behavior can be changed by using &lt;code&gt;--format-sort-force&lt;/code&gt;. Apart from these, the default order used is: &lt;code&gt;lang,quality,res,fps,hdr:12,vcodec,channels,acodec,size,br,asr,proto,ext,hasaud,source,id&lt;/code&gt;. The extractors may override this default order, but they cannot override the user-provided order.&lt;/p&gt; 
&lt;p&gt;Note that the default for hdr is &lt;code&gt;hdr:12&lt;/code&gt;; i.e. Dolby Vision is not preferred. This choice was made since DV formats are not yet fully compatible with most devices. This may be changed in the future.&lt;/p&gt; 
&lt;p&gt;If your format selector is &lt;code&gt;worst&lt;/code&gt;, the last item is selected after sorting. This means it will select the format that is worst in all respects. Most of the time, what you actually want is the video with the smallest filesize instead. So it is generally better to use &lt;code&gt;-f best -S +size,+br,+res,+fps&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Tip&lt;/strong&gt;: You can use the &lt;code&gt;-v -F&lt;/code&gt; to see how the formats have been sorted (worst to best).&lt;/p&gt; 
&lt;h2&gt;Format Selection examples&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Download and merge the best video-only format and the best audio-only format,
# or download the best combined format if video-only format is not available
$ yt-dlp -f "bv+ba/b"

# Download best format that contains video,
# and if it doesn't already have an audio stream, merge it with best audio-only format
$ yt-dlp -f "bv*+ba/b"

# Same as above
$ yt-dlp

# Download the best video-only format and the best audio-only format without merging them
# For this case, an output template should be used since
# by default, bestvideo and bestaudio will have the same file name.
$ yt-dlp -f "bv,ba" -o "%(title)s.f%(format_id)s.%(ext)s"

# Download and merge the best format that has a video stream,
# and all audio-only formats into one file
$ yt-dlp -f "bv*+mergeall[vcodec=none]" --audio-multistreams

# Download and merge the best format that has a video stream,
# and the best 2 audio-only formats into one file
$ yt-dlp -f "bv*+ba+ba.2" --audio-multistreams


# The following examples show the old method (without -S) of format selection
# and how to use -S to achieve a similar but (generally) better result

# Download the worst video available (old method)
$ yt-dlp -f "wv*+wa/w"

# Download the best video available but with the smallest resolution
$ yt-dlp -S "+res"

# Download the smallest video available
$ yt-dlp -S "+size,+br"



# Download the best mp4 video available, or the best video if no mp4 available
$ yt-dlp -f "bv*[ext=mp4]+ba[ext=m4a]/b[ext=mp4] / bv*+ba/b"

# Download the best video with the best extension
# (For video, mp4 &amp;gt; mov &amp;gt; webm &amp;gt; flv. For audio, m4a &amp;gt; aac &amp;gt; mp3 ...)
$ yt-dlp -S "ext"



# Download the best video available but no better than 480p,
# or the worst video if there is no video under 480p
$ yt-dlp -f "bv*[height&amp;lt;=480]+ba/b[height&amp;lt;=480] / wv*+ba/w"

# Download the best video available with the largest height but no better than 480p,
# or the best video with the smallest resolution if there is no video under 480p
$ yt-dlp -S "height:480"

# Download the best video available with the largest resolution but no better than 480p,
# or the best video with the smallest resolution if there is no video under 480p
# Resolution is determined by using the smallest dimension.
# So this works correctly for vertical videos as well
$ yt-dlp -S "res:480"



# Download the best video (that also has audio) but no bigger than 50 MB,
# or the worst video (that also has audio) if there is no video under 50 MB
$ yt-dlp -f "b[filesize&amp;lt;50M] / w"

# Download the largest video (that also has audio) but no bigger than 50 MB,
# or the smallest video (that also has audio) if there is no video under 50 MB
$ yt-dlp -f "b" -S "filesize:50M"

# Download the best video (that also has audio) that is closest in size to 50 MB
$ yt-dlp -f "b" -S "filesize~50M"



# Download best video available via direct link over HTTP/HTTPS protocol,
# or the best video available via any protocol if there is no such video
$ yt-dlp -f "(bv*+ba/b)[protocol^=http][protocol!*=dash] / (bv*+ba/b)"

# Download best video available via the best protocol
# (https/ftps &amp;gt; http/ftp &amp;gt; m3u8_native &amp;gt; m3u8 &amp;gt; http_dash_segments ...)
$ yt-dlp -S "proto"



# Download the best video with either h264 or h265 codec,
# or the best video if there is no such video
$ yt-dlp -f "(bv*[vcodec~='^((he|a)vc|h26[45])']+ba) / (bv*+ba/b)"

# Download the best video with best codec no better than h264,
# or the best video with worst codec if there is no such video
$ yt-dlp -S "codec:h264"

# Download the best video with worst codec no worse than h264,
# or the best video with best codec if there is no such video
$ yt-dlp -S "+codec:h264"



# More complex examples

# Download the best video no better than 720p preferring framerate greater than 30,
# or the worst video (still preferring framerate greater than 30) if there is no such video
$ yt-dlp -f "((bv*[fps&amp;gt;30]/bv*)[height&amp;lt;=720]/(wv*[fps&amp;gt;30]/wv*)) + ba / (b[fps&amp;gt;30]/b)[height&amp;lt;=720]/(w[fps&amp;gt;30]/w)"

# Download the video with the largest resolution no better than 720p,
# or the video with the smallest resolution available if there is no such video,
# preferring larger framerate for formats with the same resolution
$ yt-dlp -S "res:720,fps"



# Download the video with smallest resolution no worse than 480p,
# or the video with the largest resolution available if there is no such video,
# preferring better codec and then larger total bitrate for the same resolution
$ yt-dlp -S "+res:480,codec,br"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;MODIFYING METADATA&lt;/h1&gt; 
&lt;p&gt;The metadata obtained by the extractors can be modified by using &lt;code&gt;--parse-metadata&lt;/code&gt; and &lt;code&gt;--replace-in-metadata&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;--replace-in-metadata FIELDS REGEX REPLACE&lt;/code&gt; is used to replace text in any metadata field using &lt;a href="https://docs.python.org/3/library/re.html#regular-expression-syntax"&gt;Python regular expression&lt;/a&gt;. &lt;a href="https://docs.python.org/3/library/re.html?highlight=backreferences#re.sub"&gt;Backreferences&lt;/a&gt; can be used in the replace string for advanced use.&lt;/p&gt; 
&lt;p&gt;The general syntax of &lt;code&gt;--parse-metadata FROM:TO&lt;/code&gt; is to give the name of a field or an &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#output-template"&gt;output template&lt;/a&gt; to extract data from, and the format to interpret it as, separated by a colon &lt;code&gt;:&lt;/code&gt;. Either a &lt;a href="https://docs.python.org/3/library/re.html#regular-expression-syntax"&gt;Python regular expression&lt;/a&gt; with named capture groups, a single field name, or a similar syntax to the &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#output-template"&gt;output template&lt;/a&gt; (only &lt;code&gt;%(field)s&lt;/code&gt; formatting is supported) can be used for &lt;code&gt;TO&lt;/code&gt;. The option can be used multiple times to parse and modify various fields.&lt;/p&gt; 
&lt;p&gt;Note that these options preserve their relative order, allowing replacements to be made in parsed fields and vice versa. Also, any field thus created can be used in the &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#output-template"&gt;output template&lt;/a&gt; and will also affect the media file's metadata added when using &lt;code&gt;--embed-metadata&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;This option also has a few special uses:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;You can download an additional URL based on the metadata of the currently downloaded video. To do this, set the field &lt;code&gt;additional_urls&lt;/code&gt; to the URL that you want to download. E.g. &lt;code&gt;--parse-metadata "description:(?P&amp;lt;additional_urls&amp;gt;https?://www\.vimeo\.com/\d+)"&lt;/code&gt; will download the first vimeo video found in the description&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;You can use this to change the metadata that is embedded in the media file. To do this, set the value of the corresponding field with a &lt;code&gt;meta_&lt;/code&gt; prefix. For example, any value you set to &lt;code&gt;meta_description&lt;/code&gt; field will be added to the &lt;code&gt;description&lt;/code&gt; field in the file - you can use this to set a different "description" and "synopsis". To modify the metadata of individual streams, use the &lt;code&gt;meta&amp;lt;n&amp;gt;_&lt;/code&gt; prefix (e.g. &lt;code&gt;meta1_language&lt;/code&gt;). Any value set to the &lt;code&gt;meta_&lt;/code&gt; field will overwrite all default values.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: Metadata modification happens before format selection, post-extraction and other post-processing operations. Some fields may be added or changed during these steps, overriding your changes.&lt;/p&gt; 
&lt;p&gt;For reference, these are the fields yt-dlp adds by default to the file metadata:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Metadata fields&lt;/th&gt; 
   &lt;th align="left"&gt;From&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;title&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;track&lt;/code&gt; or &lt;code&gt;title&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;date&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;upload_date&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;description&lt;/code&gt;, &lt;code&gt;synopsis&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;description&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;purl&lt;/code&gt;, &lt;code&gt;comment&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;webpage_url&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;track&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;track_number&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;artist&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;artist&lt;/code&gt;, &lt;code&gt;artists&lt;/code&gt;, &lt;code&gt;creator&lt;/code&gt;, &lt;code&gt;creators&lt;/code&gt;, &lt;code&gt;uploader&lt;/code&gt; or &lt;code&gt;uploader_id&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;composer&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;composer&lt;/code&gt; or &lt;code&gt;composers&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;genre&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;genre&lt;/code&gt; or &lt;code&gt;genres&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;album&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;album&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;album_artist&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;album_artist&lt;/code&gt; or &lt;code&gt;album_artists&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;disc&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;disc_number&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;show&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;series&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;season_number&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;season_number&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;episode_id&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;episode&lt;/code&gt; or &lt;code&gt;episode_id&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;episode_sort&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;episode_number&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;language&lt;/code&gt; of each stream&lt;/td&gt; 
   &lt;td align="left"&gt;the format's &lt;code&gt;language&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: The file format may not support some of these fields&lt;/p&gt; 
&lt;h2&gt;Modifying metadata examples&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Interpret the title as "Artist - Title"
$ yt-dlp --parse-metadata "title:%(artist)s - %(title)s"

# Regex example
$ yt-dlp --parse-metadata "description:Artist - (?P&amp;lt;artist&amp;gt;.+)"

# Set title as "Series name S01E05"
$ yt-dlp --parse-metadata "%(series)s S%(season_number)02dE%(episode_number)02d:%(title)s"

# Prioritize uploader as the "artist" field in video metadata
$ yt-dlp --parse-metadata "%(uploader|)s:%(meta_artist)s" --embed-metadata

# Set "comment" field in video metadata using description instead of webpage_url,
# handling multiple lines correctly
$ yt-dlp --parse-metadata "description:(?s)(?P&amp;lt;meta_comment&amp;gt;.+)" --embed-metadata

# Do not set any "synopsis" in the video metadata
$ yt-dlp --parse-metadata ":(?P&amp;lt;meta_synopsis&amp;gt;)"

# Remove "formats" field from the infojson by setting it to an empty string
$ yt-dlp --parse-metadata "video::(?P&amp;lt;formats&amp;gt;)" --write-info-json

# Replace all spaces and "_" in title and uploader with a `-`
$ yt-dlp --replace-in-metadata "title,uploader" "[ _]" "-"

&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;EXTRACTOR ARGUMENTS&lt;/h1&gt; 
&lt;p&gt;Some extractors accept additional arguments which can be passed using &lt;code&gt;--extractor-args KEY:ARGS&lt;/code&gt;. &lt;code&gt;ARGS&lt;/code&gt; is a &lt;code&gt;;&lt;/code&gt; (semicolon) separated string of &lt;code&gt;ARG=VAL1,VAL2&lt;/code&gt;. E.g. &lt;code&gt;--extractor-args "youtube:player-client=tv,mweb;formats=incomplete" --extractor-args "twitter:api=syndication"&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;Note: In CLI, &lt;code&gt;ARG&lt;/code&gt; can use &lt;code&gt;-&lt;/code&gt; instead of &lt;code&gt;_&lt;/code&gt;; e.g. &lt;code&gt;youtube:player-client"&lt;/code&gt; becomes &lt;code&gt;youtube:player_client"&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;The following extractors use this feature:&lt;/p&gt; 
&lt;h4&gt;youtube&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;lang&lt;/code&gt;: Prefer translated metadata (&lt;code&gt;title&lt;/code&gt;, &lt;code&gt;description&lt;/code&gt; etc) of this language code (case-sensitive). By default, the video primary language metadata is preferred, with a fallback to &lt;code&gt;en&lt;/code&gt; translated. See &lt;a href="https://github.com/yt-dlp/yt-dlp/raw/415b4c9f955b1a0391204bd24a7132590e7b3bdb/yt_dlp/extractor/youtube/_base.py#L402-L409"&gt;youtube/_base.py&lt;/a&gt; for the list of supported content language codes&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;skip&lt;/code&gt;: One or more of &lt;code&gt;hls&lt;/code&gt;, &lt;code&gt;dash&lt;/code&gt; or &lt;code&gt;translated_subs&lt;/code&gt; to skip extraction of the m3u8 manifests, dash manifests and &lt;a href="https://github.com/yt-dlp/yt-dlp/issues/4090#issuecomment-1158102032"&gt;auto-translated subtitles&lt;/a&gt; respectively&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;player_client&lt;/code&gt;: Clients to extract video data from. The currently available clients are &lt;code&gt;web&lt;/code&gt;, &lt;code&gt;web_safari&lt;/code&gt;, &lt;code&gt;web_embedded&lt;/code&gt;, &lt;code&gt;web_music&lt;/code&gt;, &lt;code&gt;web_creator&lt;/code&gt;, &lt;code&gt;mweb&lt;/code&gt;, &lt;code&gt;ios&lt;/code&gt;, &lt;code&gt;android&lt;/code&gt;, &lt;code&gt;android_vr&lt;/code&gt;, &lt;code&gt;tv&lt;/code&gt;, &lt;code&gt;tv_simply&lt;/code&gt; and &lt;code&gt;tv_embedded&lt;/code&gt;. By default, &lt;code&gt;tv_simply,tv,web&lt;/code&gt; is used, but &lt;code&gt;tv,web_safari,web&lt;/code&gt; is used when authenticating with cookies and &lt;code&gt;tv,web_creator,web&lt;/code&gt; is used with premium accounts. The &lt;code&gt;web_music&lt;/code&gt; client is added for &lt;code&gt;music.youtube.com&lt;/code&gt; URLs when logged-in cookies are used. The &lt;code&gt;web_embedded&lt;/code&gt; client is added for age-restricted videos but only works if the video is embeddable. The &lt;code&gt;tv_embedded&lt;/code&gt; and &lt;code&gt;web_creator&lt;/code&gt; clients are added for age-restricted videos if account age-verification is required. Some clients, such as &lt;code&gt;web&lt;/code&gt; and &lt;code&gt;web_music&lt;/code&gt;, require a &lt;code&gt;po_token&lt;/code&gt; for their formats to be downloadable. Some clients, such as &lt;code&gt;web_creator&lt;/code&gt;, will only work with authentication. Not all clients support authentication via cookies. You can use &lt;code&gt;default&lt;/code&gt; for the default clients, or you can use &lt;code&gt;all&lt;/code&gt; for all clients (not recommended). You can prefix a client with &lt;code&gt;-&lt;/code&gt; to exclude it, e.g. &lt;code&gt;youtube:player_client=default,-ios&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;player_skip&lt;/code&gt;: Skip some network requests that are generally needed for robust extraction. One or more of &lt;code&gt;configs&lt;/code&gt; (skip client configs), &lt;code&gt;webpage&lt;/code&gt; (skip initial webpage), &lt;code&gt;js&lt;/code&gt; (skip js player), &lt;code&gt;initial_data&lt;/code&gt; (skip initial data/next ep request). While these options can help reduce the number of requests needed or avoid some rate-limiting, they could cause issues such as missing formats or metadata. See &lt;a href="https://github.com/yt-dlp/yt-dlp/pull/860"&gt;#860&lt;/a&gt; and &lt;a href="https://github.com/yt-dlp/yt-dlp/issues/12826"&gt;#12826&lt;/a&gt; for more details&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;webpage_skip&lt;/code&gt;: Skip extraction of embedded webpage data. One or both of &lt;code&gt;player_response&lt;/code&gt;, &lt;code&gt;initial_data&lt;/code&gt;. These options are for testing purposes and don't skip any network requests&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;player_params&lt;/code&gt;: YouTube player parameters to use for player requests. Will overwrite any default ones set by yt-dlp.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;player_js_variant&lt;/code&gt;: The player javascript variant to use for signature and nsig deciphering. The known variants are: &lt;code&gt;main&lt;/code&gt;, &lt;code&gt;tce&lt;/code&gt;, &lt;code&gt;tv&lt;/code&gt;, &lt;code&gt;tv_es6&lt;/code&gt;, &lt;code&gt;phone&lt;/code&gt;, &lt;code&gt;tablet&lt;/code&gt;. The default is &lt;code&gt;main&lt;/code&gt;, and the others are for debugging purposes. You can use &lt;code&gt;actual&lt;/code&gt; to go with what is prescribed by the site&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;comment_sort&lt;/code&gt;: &lt;code&gt;top&lt;/code&gt; or &lt;code&gt;new&lt;/code&gt; (default) - choose comment sorting mode (on YouTube's side)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;max_comments&lt;/code&gt;: Limit the amount of comments to gather. Comma-separated list of integers representing &lt;code&gt;max-comments,max-parents,max-replies,max-replies-per-thread&lt;/code&gt;. Default is &lt;code&gt;all,all,all,all&lt;/code&gt; 
  &lt;ul&gt; 
   &lt;li&gt;E.g. &lt;code&gt;all,all,1000,10&lt;/code&gt; will get a maximum of 1000 replies total, with up to 10 replies per thread. &lt;code&gt;1000,all,100&lt;/code&gt; will get a maximum of 1000 comments, with a maximum of 100 replies total&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;formats&lt;/code&gt;: Change the types of formats to return. &lt;code&gt;dashy&lt;/code&gt; (convert HTTP to DASH), &lt;code&gt;duplicate&lt;/code&gt; (identical content but different URLs or protocol; includes &lt;code&gt;dashy&lt;/code&gt;), &lt;code&gt;incomplete&lt;/code&gt; (cannot be downloaded completely - live dash and post-live m3u8), &lt;code&gt;missing_pot&lt;/code&gt; (include formats that require a PO Token but are missing one)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;innertube_host&lt;/code&gt;: Innertube API host to use for all API requests; e.g. &lt;code&gt;studio.youtube.com&lt;/code&gt;, &lt;code&gt;youtubei.googleapis.com&lt;/code&gt;. Note that cookies exported from one subdomain will not work on others&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;innertube_key&lt;/code&gt;: Innertube API key to use for all API requests. By default, no API key is used&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;raise_incomplete_data&lt;/code&gt;: &lt;code&gt;Incomplete Data Received&lt;/code&gt; raises an error instead of reporting a warning&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;data_sync_id&lt;/code&gt;: Overrides the account Data Sync ID used in Innertube API requests. This may be needed if you are using an account with &lt;code&gt;youtube:player_skip=webpage,configs&lt;/code&gt; or &lt;code&gt;youtubetab:skip=webpage&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;visitor_data&lt;/code&gt;: Overrides the Visitor Data used in Innertube API requests. This should be used with &lt;code&gt;player_skip=webpage,configs&lt;/code&gt; and without cookies. Note: this may have adverse effects if used improperly. If a session from a browser is wanted, you should pass cookies instead (which contain the Visitor ID)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;po_token&lt;/code&gt;: Proof of Origin (PO) Token(s) to use. Comma seperated list of PO Tokens in the format &lt;code&gt;CLIENT.CONTEXT+PO_TOKEN&lt;/code&gt;, e.g. &lt;code&gt;youtube:po_token=web.gvs+XXX,web.player=XXX,web_safari.gvs+YYY&lt;/code&gt;. Context can be any of &lt;code&gt;gvs&lt;/code&gt; (Google Video Server URLs), &lt;code&gt;player&lt;/code&gt; (Innertube player request) or &lt;code&gt;subs&lt;/code&gt; (Subtitles)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;pot_trace&lt;/code&gt;: Enable debug logging for PO Token fetching. Either &lt;code&gt;true&lt;/code&gt; or &lt;code&gt;false&lt;/code&gt; (default)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;fetch_pot&lt;/code&gt;: Policy to use for fetching a PO Token from providers. One of &lt;code&gt;always&lt;/code&gt; (always try fetch a PO Token regardless if the client requires one for the given context), &lt;code&gt;never&lt;/code&gt; (never fetch a PO Token), or &lt;code&gt;auto&lt;/code&gt; (default; only fetch a PO Token if the client requires one for the given context)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;playback_wait&lt;/code&gt;: Duration (in seconds) to wait inbetween the extraction and download stages in order to ensure the formats are available. The default is &lt;code&gt;6&lt;/code&gt; seconds&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;youtubepot-webpo&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;bind_to_visitor_id&lt;/code&gt;: Whether to use the Visitor ID instead of Visitor Data for caching WebPO tokens. Either &lt;code&gt;true&lt;/code&gt; (default) or &lt;code&gt;false&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;youtubetab (YouTube playlists, channels, feeds, etc.)&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;skip&lt;/code&gt;: One or more of &lt;code&gt;webpage&lt;/code&gt; (skip initial webpage download), &lt;code&gt;authcheck&lt;/code&gt; (allow the download of playlists requiring authentication when no initial webpage is downloaded. This may cause unwanted behavior, see &lt;a href="https://github.com/yt-dlp/yt-dlp/pull/1122"&gt;#1122&lt;/a&gt; for more details)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;approximate_date&lt;/code&gt;: Extract approximate &lt;code&gt;upload_date&lt;/code&gt; and &lt;code&gt;timestamp&lt;/code&gt; in flat-playlist. This may cause date-based filters to be slightly off&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;generic&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;fragment_query&lt;/code&gt;: Passthrough any query in mpd/m3u8 manifest URLs to their fragments if no value is provided, or else apply the query string given as &lt;code&gt;fragment_query=VALUE&lt;/code&gt;. Note that if the stream has an HLS AES-128 key, then the query parameters will be passed to the key URI as well, unless the &lt;code&gt;key_query&lt;/code&gt; extractor-arg is passed, or unless an external key URI is provided via the &lt;code&gt;hls_key&lt;/code&gt; extractor-arg. Does not apply to ffmpeg&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;variant_query&lt;/code&gt;: Passthrough the master m3u8 URL query to its variant playlist URLs if no value is provided, or else apply the query string given as &lt;code&gt;variant_query=VALUE&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;key_query&lt;/code&gt;: Passthrough the master m3u8 URL query to its HLS AES-128 decryption key URI if no value is provided, or else apply the query string given as &lt;code&gt;key_query=VALUE&lt;/code&gt;. Note that this will have no effect if the key URI is provided via the &lt;code&gt;hls_key&lt;/code&gt; extractor-arg. Does not apply to ffmpeg&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;hls_key&lt;/code&gt;: An HLS AES-128 key URI &lt;em&gt;or&lt;/em&gt; key (as hex), and optionally the IV (as hex), in the form of &lt;code&gt;(URI|KEY)[,IV]&lt;/code&gt;; e.g. &lt;code&gt;generic:hls_key=ABCDEF1234567980,0xFEDCBA0987654321&lt;/code&gt;. Passing any of these values will force usage of the native HLS downloader and override the corresponding values found in the m3u8 playlist&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;is_live&lt;/code&gt;: Bypass live HLS detection and manually set &lt;code&gt;live_status&lt;/code&gt; - a value of &lt;code&gt;false&lt;/code&gt; will set &lt;code&gt;not_live&lt;/code&gt;, any other value (or no value) will set &lt;code&gt;is_live&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;impersonate&lt;/code&gt;: Target(s) to try and impersonate with the initial webpage request; e.g. &lt;code&gt;generic:impersonate=safari,chrome-110&lt;/code&gt;. Use &lt;code&gt;generic:impersonate&lt;/code&gt; to impersonate any available target, and use &lt;code&gt;generic:impersonate=false&lt;/code&gt; to disable impersonation (default)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;vikichannel&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;video_types&lt;/code&gt;: Types of videos to download - one or more of &lt;code&gt;episodes&lt;/code&gt;, &lt;code&gt;movies&lt;/code&gt;, &lt;code&gt;clips&lt;/code&gt;, &lt;code&gt;trailers&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;youtubewebarchive&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;check_all&lt;/code&gt;: Try to check more at the cost of more requests. One or more of &lt;code&gt;thumbnails&lt;/code&gt;, &lt;code&gt;captures&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;gamejolt&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;comment_sort&lt;/code&gt;: &lt;code&gt;hot&lt;/code&gt; (default), &lt;code&gt;you&lt;/code&gt; (cookies needed), &lt;code&gt;top&lt;/code&gt;, &lt;code&gt;new&lt;/code&gt; - choose comment sorting mode (on GameJolt's side)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;hotstar&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;res&lt;/code&gt;: resolution to ignore - one or more of &lt;code&gt;sd&lt;/code&gt;, &lt;code&gt;hd&lt;/code&gt;, &lt;code&gt;fhd&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;vcodec&lt;/code&gt;: vcodec to ignore - one or more of &lt;code&gt;h264&lt;/code&gt;, &lt;code&gt;h265&lt;/code&gt;, &lt;code&gt;dvh265&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;dr&lt;/code&gt;: dynamic range to ignore - one or more of &lt;code&gt;sdr&lt;/code&gt;, &lt;code&gt;hdr10&lt;/code&gt;, &lt;code&gt;dv&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;instagram&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;app_id&lt;/code&gt;: The value of the &lt;code&gt;X-IG-App-ID&lt;/code&gt; header used for API requests. Default is the web app ID, &lt;code&gt;936619743392459&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;niconicochannelplus&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;max_comments&lt;/code&gt;: Maximum number of comments to extract - default is &lt;code&gt;120&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;tiktok&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;api_hostname&lt;/code&gt;: Hostname to use for mobile API calls, e.g. &lt;code&gt;api22-normal-c-alisg.tiktokv.com&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;app_name&lt;/code&gt;: Default app name to use with mobile API calls, e.g. &lt;code&gt;trill&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;app_version&lt;/code&gt;: Default app version to use with mobile API calls - should be set along with &lt;code&gt;manifest_app_version&lt;/code&gt;, e.g. &lt;code&gt;34.1.2&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;manifest_app_version&lt;/code&gt;: Default numeric app version to use with mobile API calls, e.g. &lt;code&gt;2023401020&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;aid&lt;/code&gt;: Default app ID to use with mobile API calls, e.g. &lt;code&gt;1180&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;app_info&lt;/code&gt;: Enable mobile API extraction with one or more app info strings in the format of &lt;code&gt;&amp;lt;iid&amp;gt;/[app_name]/[app_version]/[manifest_app_version]/[aid]&lt;/code&gt;, where &lt;code&gt;iid&lt;/code&gt; is the unique app install ID. &lt;code&gt;iid&lt;/code&gt; is the only required value; all other values and their &lt;code&gt;/&lt;/code&gt; separators can be omitted, e.g. &lt;code&gt;tiktok:app_info=1234567890123456789&lt;/code&gt; or &lt;code&gt;tiktok:app_info=123,456/trill///1180,789//34.0.1/340001&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;device_id&lt;/code&gt;: Enable mobile API extraction with a genuine device ID to be used with mobile API calls. Default is a random 19-digit string&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;rokfinchannel&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;tab&lt;/code&gt;: Which tab to download - one of &lt;code&gt;new&lt;/code&gt;, &lt;code&gt;top&lt;/code&gt;, &lt;code&gt;videos&lt;/code&gt;, &lt;code&gt;podcasts&lt;/code&gt;, &lt;code&gt;streams&lt;/code&gt;, &lt;code&gt;stacks&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;twitter&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;api&lt;/code&gt;: Select one of &lt;code&gt;graphql&lt;/code&gt; (default), &lt;code&gt;legacy&lt;/code&gt; or &lt;code&gt;syndication&lt;/code&gt; as the API for tweet extraction. Has no effect if logged in&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;stacommu, wrestleuniverse&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;device_id&lt;/code&gt;: UUID value assigned by the website and used to enforce device limits for paid livestream content. Can be found in browser local storage&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;twitch&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;client_id&lt;/code&gt;: Client ID value to be sent with GraphQL requests, e.g. &lt;code&gt;twitch:client_id=kimne78kx3ncx6brgo4mv6wki5h1ko&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;nhkradirulive (NHK らじる★らじる LIVE)&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;area&lt;/code&gt;: Which regional variation to extract. Valid areas are: &lt;code&gt;sapporo&lt;/code&gt;, &lt;code&gt;sendai&lt;/code&gt;, &lt;code&gt;tokyo&lt;/code&gt;, &lt;code&gt;nagoya&lt;/code&gt;, &lt;code&gt;osaka&lt;/code&gt;, &lt;code&gt;hiroshima&lt;/code&gt;, &lt;code&gt;matsuyama&lt;/code&gt;, &lt;code&gt;fukuoka&lt;/code&gt;. Defaults to &lt;code&gt;tokyo&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;nflplusreplay&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;type&lt;/code&gt;: Type(s) of game replays to extract. Valid types are: &lt;code&gt;full_game&lt;/code&gt;, &lt;code&gt;full_game_spanish&lt;/code&gt;, &lt;code&gt;condensed_game&lt;/code&gt; and &lt;code&gt;all_22&lt;/code&gt;. You can use &lt;code&gt;all&lt;/code&gt; to extract all available replay types, which is the default&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;jiocinema&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;refresh_token&lt;/code&gt;: The &lt;code&gt;refreshToken&lt;/code&gt; UUID from browser local storage can be passed to extend the life of your login session when logging in with &lt;code&gt;token&lt;/code&gt; as username and the &lt;code&gt;accessToken&lt;/code&gt; from browser local storage as password&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;jiosaavn&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;bitrate&lt;/code&gt;: Audio bitrates to request. One or more of &lt;code&gt;16&lt;/code&gt;, &lt;code&gt;32&lt;/code&gt;, &lt;code&gt;64&lt;/code&gt;, &lt;code&gt;128&lt;/code&gt;, &lt;code&gt;320&lt;/code&gt;. Default is &lt;code&gt;128,320&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;afreecatvlive&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;cdn&lt;/code&gt;: One or more CDN IDs to use with the API call for stream URLs, e.g. &lt;code&gt;gcp_cdn&lt;/code&gt;, &lt;code&gt;gs_cdn_pc_app&lt;/code&gt;, &lt;code&gt;gs_cdn_mobile_web&lt;/code&gt;, &lt;code&gt;gs_cdn_pc_web&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;soundcloud&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;formats&lt;/code&gt;: Formats to request from the API. Requested values should be in the format of &lt;code&gt;{protocol}_{codec}&lt;/code&gt;, e.g. &lt;code&gt;hls_opus,http_aac&lt;/code&gt;. The &lt;code&gt;*&lt;/code&gt; character functions as a wildcard, e.g. &lt;code&gt;*_mp3&lt;/code&gt;, and can be passed by itself to request all formats. Known protocols include &lt;code&gt;http&lt;/code&gt;, &lt;code&gt;hls&lt;/code&gt; and &lt;code&gt;hls-aes&lt;/code&gt;; known codecs include &lt;code&gt;aac&lt;/code&gt;, &lt;code&gt;opus&lt;/code&gt; and &lt;code&gt;mp3&lt;/code&gt;. Original &lt;code&gt;download&lt;/code&gt; formats are always extracted. Default is &lt;code&gt;http_aac,hls_aac,http_opus,hls_opus,http_mp3,hls_mp3&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;orfon (orf:on)&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;prefer_segments_playlist&lt;/code&gt;: Prefer a playlist of program segments instead of a single complete video when available. If individual segments are desired, use &lt;code&gt;--concat-playlist never --extractor-args "orfon:prefer_segments_playlist"&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;bilibili&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;prefer_multi_flv&lt;/code&gt;: Prefer extracting flv formats over mp4 for older videos that still provide legacy formats&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;sonylivseries&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;sort_order&lt;/code&gt;: Episode sort order for series extraction - one of &lt;code&gt;asc&lt;/code&gt; (ascending, oldest first) or &lt;code&gt;desc&lt;/code&gt; (descending, newest first). Default is &lt;code&gt;asc&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;tver&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;backend&lt;/code&gt;: Backend API to use for extraction - one of &lt;code&gt;streaks&lt;/code&gt; (default) or &lt;code&gt;brightcove&lt;/code&gt; (deprecated)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;vimeo&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;client&lt;/code&gt;: Client to extract video data from. The currently available clients are &lt;code&gt;android&lt;/code&gt;, &lt;code&gt;ios&lt;/code&gt;, and &lt;code&gt;web&lt;/code&gt;. Only one client can be used. The &lt;code&gt;web&lt;/code&gt; client is used by default. The &lt;code&gt;web&lt;/code&gt; client only works with account cookies or login credentials. The &lt;code&gt;android&lt;/code&gt; and &lt;code&gt;ios&lt;/code&gt; clients only work with previously cached OAuth tokens&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;original_format_policy&lt;/code&gt;: Policy for when to try extracting original formats. One of &lt;code&gt;always&lt;/code&gt;, &lt;code&gt;never&lt;/code&gt;, or &lt;code&gt;auto&lt;/code&gt;. The default &lt;code&gt;auto&lt;/code&gt; policy tries to avoid exceeding the web client's API rate-limit by only making an extra request when Vimeo publicizes the video's downloadability&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: These options may be changed/removed in the future without concern for backward compatibility&lt;/p&gt; 
&lt;!-- MANPAGE: MOVE "INSTALLATION" SECTION HERE --&gt; 
&lt;h1&gt;PLUGINS&lt;/h1&gt; 
&lt;p&gt;Note that &lt;strong&gt;all&lt;/strong&gt; plugins are imported even if not invoked, and that &lt;strong&gt;there are no checks&lt;/strong&gt; performed on plugin code. &lt;strong&gt;Use plugins at your own risk and only if you trust the code!&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Plugins can be of &lt;code&gt;&amp;lt;type&amp;gt;&lt;/code&gt;s &lt;code&gt;extractor&lt;/code&gt; or &lt;code&gt;postprocessor&lt;/code&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Extractor plugins do not need to be enabled from the CLI and are automatically invoked when the input URL is suitable for it.&lt;/li&gt; 
 &lt;li&gt;Extractor plugins take priority over built-in extractors.&lt;/li&gt; 
 &lt;li&gt;Postprocessor plugins can be invoked using &lt;code&gt;--use-postprocessor NAME&lt;/code&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Plugins are loaded from the namespace packages &lt;code&gt;yt_dlp_plugins.extractor&lt;/code&gt; and &lt;code&gt;yt_dlp_plugins.postprocessor&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;In other words, the file structure on the disk looks something like:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;    yt_dlp_plugins/
        extractor/
            myplugin.py
        postprocessor/
            myplugin.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;yt-dlp looks for these &lt;code&gt;yt_dlp_plugins&lt;/code&gt; namespace folders in many locations (see below) and loads in plugins from &lt;strong&gt;all&lt;/strong&gt; of them. Set the environment variable &lt;code&gt;YTDLP_NO_PLUGINS&lt;/code&gt; to something nonempty to disable loading plugins entirely.&lt;/p&gt; 
&lt;p&gt;See the &lt;a href="https://github.com/yt-dlp/yt-dlp/wiki/Plugins"&gt;wiki for some known plugins&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Installing Plugins&lt;/h2&gt; 
&lt;p&gt;Plugins can be installed using various methods and locations.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Configuration directories&lt;/strong&gt;: Plugin packages (containing a &lt;code&gt;yt_dlp_plugins&lt;/code&gt; namespace folder) can be dropped into the following standard &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#configuration"&gt;configuration locations&lt;/a&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;User Plugins&lt;/strong&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;code&gt;${XDG_CONFIG_HOME}/yt-dlp/plugins/&amp;lt;package name&amp;gt;/yt_dlp_plugins/&lt;/code&gt; (recommended on Linux/macOS)&lt;/li&gt; 
     &lt;li&gt;&lt;code&gt;${XDG_CONFIG_HOME}/yt-dlp-plugins/&amp;lt;package name&amp;gt;/yt_dlp_plugins/&lt;/code&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;code&gt;${APPDATA}/yt-dlp/plugins/&amp;lt;package name&amp;gt;/yt_dlp_plugins/&lt;/code&gt; (recommended on Windows)&lt;/li&gt; 
     &lt;li&gt;&lt;code&gt;${APPDATA}/yt-dlp-plugins/&amp;lt;package name&amp;gt;/yt_dlp_plugins/&lt;/code&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;code&gt;~/.yt-dlp/plugins/&amp;lt;package name&amp;gt;/yt_dlp_plugins/&lt;/code&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;code&gt;~/yt-dlp-plugins/&amp;lt;package name&amp;gt;/yt_dlp_plugins/&lt;/code&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;System Plugins&lt;/strong&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;code&gt;/etc/yt-dlp/plugins/&amp;lt;package name&amp;gt;/yt_dlp_plugins/&lt;/code&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;code&gt;/etc/yt-dlp-plugins/&amp;lt;package name&amp;gt;/yt_dlp_plugins/&lt;/code&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Executable location&lt;/strong&gt;: Plugin packages can similarly be installed in a &lt;code&gt;yt-dlp-plugins&lt;/code&gt; directory under the executable location (recommended for portable installations):&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Binary: where &lt;code&gt;&amp;lt;root-dir&amp;gt;/yt-dlp.exe&lt;/code&gt;, &lt;code&gt;&amp;lt;root-dir&amp;gt;/yt-dlp-plugins/&amp;lt;package name&amp;gt;/yt_dlp_plugins/&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;Source: where &lt;code&gt;&amp;lt;root-dir&amp;gt;/yt_dlp/__main__.py&lt;/code&gt;, &lt;code&gt;&amp;lt;root-dir&amp;gt;/yt-dlp-plugins/&amp;lt;package name&amp;gt;/yt_dlp_plugins/&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;pip and other locations in &lt;code&gt;PYTHONPATH&lt;/code&gt;&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Plugin packages can be installed and managed using &lt;code&gt;pip&lt;/code&gt;. See &lt;a href="https://github.com/yt-dlp/yt-dlp-sample-plugins"&gt;yt-dlp-sample-plugins&lt;/a&gt; for an example. 
    &lt;ul&gt; 
     &lt;li&gt;Note: plugin files between plugin packages installed with pip must have unique filenames.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;Any path in &lt;code&gt;PYTHONPATH&lt;/code&gt; is searched in for the &lt;code&gt;yt_dlp_plugins&lt;/code&gt; namespace folder. 
    &lt;ul&gt; 
     &lt;li&gt;Note: This does not apply for Pyinstaller builds.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;code&gt;.zip&lt;/code&gt;, &lt;code&gt;.egg&lt;/code&gt; and &lt;code&gt;.whl&lt;/code&gt; archives containing a &lt;code&gt;yt_dlp_plugins&lt;/code&gt; namespace folder in their root are also supported as plugin packages.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;e.g. &lt;code&gt;${XDG_CONFIG_HOME}/yt-dlp/plugins/mypluginpkg.zip&lt;/code&gt; where &lt;code&gt;mypluginpkg.zip&lt;/code&gt; contains &lt;code&gt;yt_dlp_plugins/&amp;lt;type&amp;gt;/myplugin.py&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Run yt-dlp with &lt;code&gt;--verbose&lt;/code&gt; to check if the plugin has been loaded.&lt;/p&gt; 
&lt;h2&gt;Developing Plugins&lt;/h2&gt; 
&lt;p&gt;See the &lt;a href="https://github.com/yt-dlp/yt-dlp-sample-plugins"&gt;yt-dlp-sample-plugins&lt;/a&gt; repo for a template plugin package and the &lt;a href="https://github.com/yt-dlp/yt-dlp/wiki/Plugin-Development"&gt;Plugin Development&lt;/a&gt; section of the wiki for a plugin development guide.&lt;/p&gt; 
&lt;p&gt;All public classes with a name ending in &lt;code&gt;IE&lt;/code&gt;/&lt;code&gt;PP&lt;/code&gt; are imported from each file for extractors and postprocessors respectively. This respects underscore prefix (e.g. &lt;code&gt;_MyBasePluginIE&lt;/code&gt; is private) and &lt;code&gt;__all__&lt;/code&gt;. Modules can similarly be excluded by prefixing the module name with an underscore (e.g. &lt;code&gt;_myplugin.py&lt;/code&gt;).&lt;/p&gt; 
&lt;p&gt;To replace an existing extractor with a subclass of one, set the &lt;code&gt;plugin_name&lt;/code&gt; class keyword argument (e.g. &lt;code&gt;class MyPluginIE(ABuiltInIE, plugin_name='myplugin')&lt;/code&gt; will replace &lt;code&gt;ABuiltInIE&lt;/code&gt; with &lt;code&gt;MyPluginIE&lt;/code&gt;). Since the extractor replaces the parent, you should exclude the subclass extractor from being imported separately by making it private using one of the methods described above.&lt;/p&gt; 
&lt;p&gt;If you are a plugin author, add &lt;a href="https://github.com/topics/yt-dlp-plugins"&gt;yt-dlp-plugins&lt;/a&gt; as a topic to your repository for discoverability.&lt;/p&gt; 
&lt;p&gt;See the &lt;a href="https://github.com/yt-dlp/yt-dlp/raw/master/CONTRIBUTING.md#developer-instructions"&gt;Developer Instructions&lt;/a&gt; on how to write and test an extractor.&lt;/p&gt; 
&lt;h1&gt;EMBEDDING YT-DLP&lt;/h1&gt; 
&lt;p&gt;yt-dlp makes the best effort to be a good command-line program, and thus should be callable from any programming language.&lt;/p&gt; 
&lt;p&gt;Your program should avoid parsing the normal stdout since they may change in future versions. Instead, they should use options such as &lt;code&gt;-J&lt;/code&gt;, &lt;code&gt;--print&lt;/code&gt;, &lt;code&gt;--progress-template&lt;/code&gt;, &lt;code&gt;--exec&lt;/code&gt; etc to create console output that you can reliably reproduce and parse.&lt;/p&gt; 
&lt;p&gt;From a Python program, you can embed yt-dlp in a more powerful fashion, like this:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from yt_dlp import YoutubeDL

URLS = ['https://www.youtube.com/watch?v=BaW_jenozKc']
with YoutubeDL() as ydl:
    ydl.download(URLS)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Most likely, you'll want to use various options. For a list of options available, have a look at &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/yt_dlp/YoutubeDL.py#L183"&gt;&lt;code&gt;yt_dlp/YoutubeDL.py&lt;/code&gt;&lt;/a&gt; or &lt;code&gt;help(yt_dlp.YoutubeDL)&lt;/code&gt; in a Python shell. If you are already familiar with the CLI, you can use &lt;a href="https://github.com/yt-dlp/yt-dlp/raw/master/devscripts/cli_to_api.py"&gt;&lt;code&gt;devscripts/cli_to_api.py&lt;/code&gt;&lt;/a&gt; to translate any CLI switches to &lt;code&gt;YoutubeDL&lt;/code&gt; params.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Tip&lt;/strong&gt;: If you are porting your code from youtube-dl to yt-dlp, one important point to look out for is that we do not guarantee the return value of &lt;code&gt;YoutubeDL.extract_info&lt;/code&gt; to be json serializable, or even be a dictionary. It will be dictionary-like, but if you want to ensure it is a serializable dictionary, pass it through &lt;code&gt;YoutubeDL.sanitize_info&lt;/code&gt; as shown in the &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#extracting-information"&gt;example below&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Embedding examples&lt;/h2&gt; 
&lt;h4&gt;Extracting information&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import json
import yt_dlp

URL = 'https://www.youtube.com/watch?v=BaW_jenozKc'

# ℹ️ See help(yt_dlp.YoutubeDL) for a list of available options and public functions
ydl_opts = {}
with yt_dlp.YoutubeDL(ydl_opts) as ydl:
    info = ydl.extract_info(URL, download=False)

    # ℹ️ ydl.sanitize_info makes the info json-serializable
    print(json.dumps(ydl.sanitize_info(info)))
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Download using an info-json&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import yt_dlp

INFO_FILE = 'path/to/video.info.json'

with yt_dlp.YoutubeDL() as ydl:
    error_code = ydl.download_with_info_file(INFO_FILE)

print('Some videos failed to download' if error_code
      else 'All videos successfully downloaded')
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Extract audio&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import yt_dlp

URLS = ['https://www.youtube.com/watch?v=BaW_jenozKc']

ydl_opts = {
    'format': 'm4a/bestaudio/best',
    # ℹ️ See help(yt_dlp.postprocessor) for a list of available Postprocessors and their arguments
    'postprocessors': [{  # Extract audio using ffmpeg
        'key': 'FFmpegExtractAudio',
        'preferredcodec': 'm4a',
    }]
}

with yt_dlp.YoutubeDL(ydl_opts) as ydl:
    error_code = ydl.download(URLS)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Filter videos&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import yt_dlp

URLS = ['https://www.youtube.com/watch?v=BaW_jenozKc']

def longer_than_a_minute(info, *, incomplete):
    """Download only videos longer than a minute (or with unknown duration)"""
    duration = info.get('duration')
    if duration and duration &amp;lt; 60:
        return 'The video is too short'

ydl_opts = {
    'match_filter': longer_than_a_minute,
}

with yt_dlp.YoutubeDL(ydl_opts) as ydl:
    error_code = ydl.download(URLS)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Adding logger and progress hook&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import yt_dlp

URLS = ['https://www.youtube.com/watch?v=BaW_jenozKc']

class MyLogger:
    def debug(self, msg):
        # For compatibility with youtube-dl, both debug and info are passed into debug
        # You can distinguish them by the prefix '[debug] '
        if msg.startswith('[debug] '):
            pass
        else:
            self.info(msg)

    def info(self, msg):
        pass

    def warning(self, msg):
        pass

    def error(self, msg):
        print(msg)


# ℹ️ See "progress_hooks" in help(yt_dlp.YoutubeDL)
def my_hook(d):
    if d['status'] == 'finished':
        print('Done downloading, now post-processing ...')


ydl_opts = {
    'logger': MyLogger(),
    'progress_hooks': [my_hook],
}

with yt_dlp.YoutubeDL(ydl_opts) as ydl:
    ydl.download(URLS)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Add a custom PostProcessor&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import yt_dlp

URLS = ['https://www.youtube.com/watch?v=BaW_jenozKc']

# ℹ️ See help(yt_dlp.postprocessor.PostProcessor)
class MyCustomPP(yt_dlp.postprocessor.PostProcessor):
    def run(self, info):
        self.to_screen('Doing stuff')
        return [], info


with yt_dlp.YoutubeDL() as ydl:
    # ℹ️ "when" can take any value in yt_dlp.utils.POSTPROCESS_WHEN
    ydl.add_post_processor(MyCustomPP(), when='pre_process')
    ydl.download(URLS)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Use a custom format selector&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import yt_dlp

URLS = ['https://www.youtube.com/watch?v=BaW_jenozKc']

def format_selector(ctx):
    """ Select the best video and the best audio that won't result in an mkv.
    NOTE: This is just an example and does not handle all cases """

    # formats are already sorted worst to best
    formats = ctx.get('formats')[::-1]

    # acodec='none' means there is no audio
    best_video = next(f for f in formats
                      if f['vcodec'] != 'none' and f['acodec'] == 'none')

    # find compatible audio extension
    audio_ext = {'mp4': 'm4a', 'webm': 'webm'}[best_video['ext']]
    # vcodec='none' means there is no video
    best_audio = next(f for f in formats if (
        f['acodec'] != 'none' and f['vcodec'] == 'none' and f['ext'] == audio_ext))

    # These are the minimum required fields for a merged format
    yield {
        'format_id': f'{best_video["format_id"]}+{best_audio["format_id"]}',
        'ext': best_video['ext'],
        'requested_formats': [best_video, best_audio],
        # Must be + separated list of protocols
        'protocol': f'{best_video["protocol"]}+{best_audio["protocol"]}'
    }


ydl_opts = {
    'format': format_selector,
}

with yt_dlp.YoutubeDL(ydl_opts) as ydl:
    ydl.download(URLS)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;CHANGES FROM YOUTUBE-DL&lt;/h1&gt; 
&lt;h3&gt;New features&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Forked from &lt;a href="https://github.com/blackjack4494/yt-dlc/commit/f9401f2a91987068139c5f757b12fc711d4c0cee"&gt;&lt;strong&gt;yt-dlc@f9401f2&lt;/strong&gt;&lt;/a&gt; and merged with &lt;a href="https://github.com/ytdl-org/youtube-dl/commit/a08f2b7e4567cdc50c0614ee0a4ffdff49b8b6e6"&gt;&lt;strong&gt;youtube-dl@a08f2b7&lt;/strong&gt;&lt;/a&gt; (&lt;a href="https://github.com/yt-dlp/yt-dlp/issues/21"&gt;exceptions&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#sponsorblock-options"&gt;SponsorBlock Integration&lt;/a&gt;&lt;/strong&gt;: You can mark/remove sponsor sections in YouTube videos by utilizing the &lt;a href="https://sponsor.ajay.app"&gt;SponsorBlock&lt;/a&gt; API&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#sorting-formats"&gt;Format Sorting&lt;/a&gt;&lt;/strong&gt;: The default format sorting options have been changed so that higher resolution and better codecs will be now preferred instead of simply using larger bitrate. Furthermore, you can now specify the sort order using &lt;code&gt;-S&lt;/code&gt;. This allows for much easier format selection than what is possible by simply using &lt;code&gt;--format&lt;/code&gt; (&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#format-selection-examples"&gt;examples&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Merged with animelover1984/youtube-dl&lt;/strong&gt;: You get most of the features and improvements from &lt;a href="https://github.com/animelover1984/youtube-dl"&gt;animelover1984/youtube-dl&lt;/a&gt; including &lt;code&gt;--write-comments&lt;/code&gt;, &lt;code&gt;BiliBiliSearch&lt;/code&gt;, &lt;code&gt;BilibiliChannel&lt;/code&gt;, Embedding thumbnail in mp4/ogg/opus, playlist infojson etc. See &lt;a href="https://github.com/yt-dlp/yt-dlp/pull/31"&gt;#31&lt;/a&gt; for details.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;YouTube improvements&lt;/strong&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Supports Clips, Stories (&lt;code&gt;ytstories:&amp;lt;channel UCID&amp;gt;&lt;/code&gt;), Search (including filters)&lt;strong&gt;*&lt;/strong&gt;, YouTube Music Search, Channel-specific search, Search prefixes (&lt;code&gt;ytsearch:&lt;/code&gt;, &lt;code&gt;ytsearchdate:&lt;/code&gt;)&lt;strong&gt;*&lt;/strong&gt;, Mixes, and Feeds (&lt;code&gt;:ytfav&lt;/code&gt;, &lt;code&gt;:ytwatchlater&lt;/code&gt;, &lt;code&gt;:ytsubs&lt;/code&gt;, &lt;code&gt;:ythistory&lt;/code&gt;, &lt;code&gt;:ytrec&lt;/code&gt;, &lt;code&gt;:ytnotif&lt;/code&gt;)&lt;/li&gt; 
   &lt;li&gt;Fix for &lt;a href="https://github.com/ytdl-org/youtube-dl/issues/29326"&gt;n-sig based throttling&lt;/a&gt; &lt;strong&gt;*&lt;/strong&gt;&lt;/li&gt; 
   &lt;li&gt;Download livestreams from the start using &lt;code&gt;--live-from-start&lt;/code&gt; (&lt;em&gt;experimental&lt;/em&gt;)&lt;/li&gt; 
   &lt;li&gt;Channel URLs download all uploads of the channel, including shorts and live&lt;/li&gt; 
   &lt;li&gt;Support for &lt;a href="https://github.com/yt-dlp/yt-dlp/wiki/Extractors#logging-in-with-oauth"&gt;logging in with OAuth&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Cookies from browser&lt;/strong&gt;: Cookies can be automatically extracted from all major web browsers using &lt;code&gt;--cookies-from-browser BROWSER[+KEYRING][:PROFILE][::CONTAINER]&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Download time range&lt;/strong&gt;: Videos can be downloaded partially based on either timestamps or chapters using &lt;code&gt;--download-sections&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Split video by chapters&lt;/strong&gt;: Videos can be split into multiple files based on chapters using &lt;code&gt;--split-chapters&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Multi-threaded fragment downloads&lt;/strong&gt;: Download multiple fragments of m3u8/mpd videos in parallel. Use &lt;code&gt;--concurrent-fragments&lt;/code&gt; (&lt;code&gt;-N&lt;/code&gt;) option to set the number of threads used&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Aria2c with HLS/DASH&lt;/strong&gt;: You can use &lt;code&gt;aria2c&lt;/code&gt; as the external downloader for DASH(mpd) and HLS(m3u8) formats&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;New and fixed extractors&lt;/strong&gt;: Many new extractors have been added and a lot of existing ones have been fixed. See the &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/Changelog.md"&gt;changelog&lt;/a&gt; or the &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/supportedsites.md"&gt;list of supported sites&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;New MSOs&lt;/strong&gt;: Philo, Spectrum, SlingTV, Cablevision, RCN etc.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Subtitle extraction from manifests&lt;/strong&gt;: Subtitles can be extracted from streaming media manifests. See &lt;a href="https://github.com/yt-dlp/yt-dlp/commit/be6202f12b97858b9d716e608394b51065d0419f"&gt;commit/be6202f&lt;/a&gt; for details&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Multiple paths and output templates&lt;/strong&gt;: You can give different &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#output-template"&gt;output templates&lt;/a&gt; and download paths for different types of files. You can also set a temporary path where intermediary files are downloaded to using &lt;code&gt;--paths&lt;/code&gt; (&lt;code&gt;-P&lt;/code&gt;)&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Portable Configuration&lt;/strong&gt;: Configuration files are automatically loaded from the home and root directories. See &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#configuration"&gt;CONFIGURATION&lt;/a&gt; for details&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Output template improvements&lt;/strong&gt;: Output templates can now have date-time formatting, numeric offsets, object traversal etc. See &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#output-template"&gt;output template&lt;/a&gt; for details. Even more advanced operations can also be done with the help of &lt;code&gt;--parse-metadata&lt;/code&gt; and &lt;code&gt;--replace-in-metadata&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Other new options&lt;/strong&gt;: Many new options have been added such as &lt;code&gt;--alias&lt;/code&gt;, &lt;code&gt;--print&lt;/code&gt;, &lt;code&gt;--concat-playlist&lt;/code&gt;, &lt;code&gt;--wait-for-video&lt;/code&gt;, &lt;code&gt;--retry-sleep&lt;/code&gt;, &lt;code&gt;--sleep-requests&lt;/code&gt;, &lt;code&gt;--convert-thumbnails&lt;/code&gt;, &lt;code&gt;--force-download-archive&lt;/code&gt;, &lt;code&gt;--force-overwrites&lt;/code&gt;, &lt;code&gt;--break-match-filters&lt;/code&gt; etc&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Improvements&lt;/strong&gt;: Regex and other operators in &lt;code&gt;--format&lt;/code&gt;/&lt;code&gt;--match-filters&lt;/code&gt;, multiple &lt;code&gt;--postprocessor-args&lt;/code&gt; and &lt;code&gt;--downloader-args&lt;/code&gt;, faster archive checking, more &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#format-selection"&gt;format selection options&lt;/a&gt;, merge multi-video/audio, multiple &lt;code&gt;--config-locations&lt;/code&gt;, &lt;code&gt;--exec&lt;/code&gt; at different stages, etc&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Plugins&lt;/strong&gt;: Extractors and PostProcessors can be loaded from an external file. See &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#plugins"&gt;plugins&lt;/a&gt; for details&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Self updater&lt;/strong&gt;: The releases can be updated using &lt;code&gt;yt-dlp -U&lt;/code&gt;, and downgraded using &lt;code&gt;--update-to&lt;/code&gt; if required&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Automated builds&lt;/strong&gt;: &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#update-channels"&gt;Nightly/master builds&lt;/a&gt; can be used with &lt;code&gt;--update-to nightly&lt;/code&gt; and &lt;code&gt;--update-to master&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/Changelog.md"&gt;changelog&lt;/a&gt; or &lt;a href="https://github.com/yt-dlp/yt-dlp/commits"&gt;commits&lt;/a&gt; for the full list of changes&lt;/p&gt; 
&lt;p&gt;Features marked with a &lt;strong&gt;*&lt;/strong&gt; have been back-ported to youtube-dl&lt;/p&gt; 
&lt;h3&gt;Differences in default behavior&lt;/h3&gt; 
&lt;p&gt;Some of yt-dlp's default options are different from that of youtube-dl and youtube-dlc:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;yt-dlp supports only &lt;a href="##" title="Windows 8"&gt;Python 3.9+&lt;/a&gt;, and will remove support for more versions as they &lt;a href="https://devguide.python.org/versions/#python-release-cycle"&gt;become EOL&lt;/a&gt;; while &lt;a href="https://github.com/ytdl-org/youtube-dl/issues/30568#issue-1118238743"&gt;youtube-dl still supports Python 2.6+ and 3.2+&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;The options &lt;code&gt;--auto-number&lt;/code&gt; (&lt;code&gt;-A&lt;/code&gt;), &lt;code&gt;--title&lt;/code&gt; (&lt;code&gt;-t&lt;/code&gt;) and &lt;code&gt;--literal&lt;/code&gt; (&lt;code&gt;-l&lt;/code&gt;), no longer work. See &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#Removed"&gt;removed options&lt;/a&gt; for details&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;avconv&lt;/code&gt; is not supported as an alternative to &lt;code&gt;ffmpeg&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;yt-dlp stores config files in slightly different locations to youtube-dl. See &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#configuration"&gt;CONFIGURATION&lt;/a&gt; for a list of correct locations&lt;/li&gt; 
 &lt;li&gt;The default &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#output-template"&gt;output template&lt;/a&gt; is &lt;code&gt;%(title)s [%(id)s].%(ext)s&lt;/code&gt;. There is no real reason for this change. This was changed before yt-dlp was ever made public and now there are no plans to change it back to &lt;code&gt;%(title)s-%(id)s.%(ext)s&lt;/code&gt;. Instead, you may use &lt;code&gt;--compat-options filename&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;The default &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#sorting-formats"&gt;format sorting&lt;/a&gt; is different from youtube-dl and prefers higher resolution and better codecs rather than higher bitrates. You can use the &lt;code&gt;--format-sort&lt;/code&gt; option to change this to any order you prefer, or use &lt;code&gt;--compat-options format-sort&lt;/code&gt; to use youtube-dl's sorting order. Older versions of yt-dlp preferred VP9 due to its broader compatibility; you can use &lt;code&gt;--compat-options prefer-vp9-sort&lt;/code&gt; to revert to that format sorting preference. These two compat options cannot be used together&lt;/li&gt; 
 &lt;li&gt;The default format selector is &lt;code&gt;bv*+ba/b&lt;/code&gt;. This means that if a combined video + audio format that is better than the best video-only format is found, the former will be preferred. Use &lt;code&gt;-f bv+ba/b&lt;/code&gt; or &lt;code&gt;--compat-options format-spec&lt;/code&gt; to revert this&lt;/li&gt; 
 &lt;li&gt;Unlike youtube-dlc, yt-dlp does not allow merging multiple audio/video streams into one file by default (since this conflicts with the use of &lt;code&gt;-f bv*+ba&lt;/code&gt;). If needed, this feature must be enabled using &lt;code&gt;--audio-multistreams&lt;/code&gt; and &lt;code&gt;--video-multistreams&lt;/code&gt;. You can also use &lt;code&gt;--compat-options multistreams&lt;/code&gt; to enable both&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--no-abort-on-error&lt;/code&gt; is enabled by default. Use &lt;code&gt;--abort-on-error&lt;/code&gt; or &lt;code&gt;--compat-options abort-on-error&lt;/code&gt; to abort on errors instead&lt;/li&gt; 
 &lt;li&gt;When writing metadata files such as thumbnails, description or infojson, the same information (if available) is also written for playlists. Use &lt;code&gt;--no-write-playlist-metafiles&lt;/code&gt; or &lt;code&gt;--compat-options no-playlist-metafiles&lt;/code&gt; to not write these files&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--add-metadata&lt;/code&gt; attaches the &lt;code&gt;infojson&lt;/code&gt; to &lt;code&gt;mkv&lt;/code&gt; files in addition to writing the metadata when used with &lt;code&gt;--write-info-json&lt;/code&gt;. Use &lt;code&gt;--no-embed-info-json&lt;/code&gt; or &lt;code&gt;--compat-options no-attach-info-json&lt;/code&gt; to revert this&lt;/li&gt; 
 &lt;li&gt;Some metadata are embedded into different fields when using &lt;code&gt;--add-metadata&lt;/code&gt; as compared to youtube-dl. Most notably, &lt;code&gt;comment&lt;/code&gt; field contains the &lt;code&gt;webpage_url&lt;/code&gt; and &lt;code&gt;synopsis&lt;/code&gt; contains the &lt;code&gt;description&lt;/code&gt;. You can &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#modifying-metadata"&gt;use &lt;code&gt;--parse-metadata&lt;/code&gt;&lt;/a&gt; to modify this to your liking or use &lt;code&gt;--compat-options embed-metadata&lt;/code&gt; to revert this&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;playlist_index&lt;/code&gt; behaves differently when used with options like &lt;code&gt;--playlist-reverse&lt;/code&gt; and &lt;code&gt;--playlist-items&lt;/code&gt;. See &lt;a href="https://github.com/yt-dlp/yt-dlp/issues/302"&gt;#302&lt;/a&gt; for details. You can use &lt;code&gt;--compat-options playlist-index&lt;/code&gt; if you want to keep the earlier behavior&lt;/li&gt; 
 &lt;li&gt;The output of &lt;code&gt;-F&lt;/code&gt; is listed in a new format. Use &lt;code&gt;--compat-options list-formats&lt;/code&gt; to revert this&lt;/li&gt; 
 &lt;li&gt;Live chats (if available) are considered as subtitles. Use &lt;code&gt;--sub-langs all,-live_chat&lt;/code&gt; to download all subtitles except live chat. You can also use &lt;code&gt;--compat-options no-live-chat&lt;/code&gt; to prevent any live chat/danmaku from downloading&lt;/li&gt; 
 &lt;li&gt;YouTube channel URLs download all uploads of the channel. To download only the videos in a specific tab, pass the tab's URL. If the channel does not show the requested tab, an error will be raised. Also, &lt;code&gt;/live&lt;/code&gt; URLs raise an error if there are no live videos instead of silently downloading the entire channel. You may use &lt;code&gt;--compat-options no-youtube-channel-redirect&lt;/code&gt; to revert all these redirections&lt;/li&gt; 
 &lt;li&gt;Unavailable videos are also listed for YouTube playlists. Use &lt;code&gt;--compat-options no-youtube-unavailable-videos&lt;/code&gt; to remove this&lt;/li&gt; 
 &lt;li&gt;The upload dates extracted from YouTube are in UTC.&lt;/li&gt; 
 &lt;li&gt;If &lt;code&gt;ffmpeg&lt;/code&gt; is used as the downloader, the downloading and merging of formats happen in a single step when possible. Use &lt;code&gt;--compat-options no-direct-merge&lt;/code&gt; to revert this&lt;/li&gt; 
 &lt;li&gt;Thumbnail embedding in &lt;code&gt;mp4&lt;/code&gt; is done with mutagen if possible. Use &lt;code&gt;--compat-options embed-thumbnail-atomicparsley&lt;/code&gt; to force the use of AtomicParsley instead&lt;/li&gt; 
 &lt;li&gt;Some internal metadata such as filenames are removed by default from the infojson. Use &lt;code&gt;--no-clean-infojson&lt;/code&gt; or &lt;code&gt;--compat-options no-clean-infojson&lt;/code&gt; to revert this&lt;/li&gt; 
 &lt;li&gt;When &lt;code&gt;--embed-subs&lt;/code&gt; and &lt;code&gt;--write-subs&lt;/code&gt; are used together, the subtitles are written to disk and also embedded in the media file. You can use just &lt;code&gt;--embed-subs&lt;/code&gt; to embed the subs and automatically delete the separate file. See &lt;a href="https://github.com/yt-dlp/yt-dlp/issues/630#issuecomment-893659460"&gt;#630 (comment)&lt;/a&gt; for more info. &lt;code&gt;--compat-options no-keep-subs&lt;/code&gt; can be used to revert this&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;certifi&lt;/code&gt; will be used for SSL root certificates, if installed. If you want to use system certificates (e.g. self-signed), use &lt;code&gt;--compat-options no-certifi&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;yt-dlp's sanitization of invalid characters in filenames is different/smarter than in youtube-dl. You can use &lt;code&gt;--compat-options filename-sanitization&lt;/code&gt; to revert to youtube-dl's behavior&lt;/li&gt; 
 &lt;li&gt;&lt;del&gt;yt-dlp tries to parse the external downloader outputs into the standard progress output if possible (Currently implemented: &lt;a href="https://github.com/yt-dlp/yt-dlp/issues/5931"&gt;aria2c&lt;/a&gt;). You can use &lt;code&gt;--compat-options no-external-downloader-progress&lt;/code&gt; to get the downloader output as-is&lt;/del&gt;&lt;/li&gt; 
 &lt;li&gt;yt-dlp versions between 2021.09.01 and 2023.01.02 applies &lt;code&gt;--match-filters&lt;/code&gt; to nested playlists. This was an unintentional side-effect of &lt;a href="https://github.com/yt-dlp/yt-dlp/commit/8f18aca8717bb0dd49054555af8d386e5eda3a88"&gt;8f18ac&lt;/a&gt; and is fixed in &lt;a href="https://github.com/yt-dlp/yt-dlp/commit/d7b460d0e5fc710950582baed2e3fc616ed98a80"&gt;d7b460&lt;/a&gt;. Use &lt;code&gt;--compat-options playlist-match-filter&lt;/code&gt; to revert this&lt;/li&gt; 
 &lt;li&gt;yt-dlp versions between 2021.11.10 and 2023.06.21 estimated &lt;code&gt;filesize_approx&lt;/code&gt; values for fragmented/manifest formats. This was added for convenience in &lt;a href="https://github.com/yt-dlp/yt-dlp/commit/f2fe69c7b0d208bdb1f6292b4ae92bc1e1a7444a"&gt;f2fe69&lt;/a&gt;, but was reverted in &lt;a href="https://github.com/yt-dlp/yt-dlp/commit/0dff8e4d1e6e9fb938f4256ea9af7d81f42fd54f"&gt;0dff8e&lt;/a&gt; due to the potentially extreme inaccuracy of the estimated values. Use &lt;code&gt;--compat-options manifest-filesize-approx&lt;/code&gt; to keep extracting the estimated values&lt;/li&gt; 
 &lt;li&gt;yt-dlp uses modern http client backends such as &lt;code&gt;requests&lt;/code&gt;. Use &lt;code&gt;--compat-options prefer-legacy-http-handler&lt;/code&gt; to prefer the legacy http handler (&lt;code&gt;urllib&lt;/code&gt;) to be used for standard http requests.&lt;/li&gt; 
 &lt;li&gt;The sub-modules &lt;code&gt;swfinterp&lt;/code&gt;, &lt;code&gt;casefold&lt;/code&gt; are removed.&lt;/li&gt; 
 &lt;li&gt;Passing &lt;code&gt;--simulate&lt;/code&gt; (or calling &lt;code&gt;extract_info&lt;/code&gt; with &lt;code&gt;download=False&lt;/code&gt;) no longer alters the default format selection. See &lt;a href="https://github.com/yt-dlp/yt-dlp/issues/9843"&gt;#9843&lt;/a&gt; for details.&lt;/li&gt; 
 &lt;li&gt;yt-dlp no longer applies the server modified time to downloaded files by default. Use &lt;code&gt;--mtime&lt;/code&gt; or &lt;code&gt;--compat-options mtime-by-default&lt;/code&gt; to revert this.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For ease of use, a few more compat options are available:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;--compat-options all&lt;/code&gt;: Use all compat options (&lt;strong&gt;Do NOT use this!&lt;/strong&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--compat-options youtube-dl&lt;/code&gt;: Same as &lt;code&gt;--compat-options all,-multistreams,-playlist-match-filter,-manifest-filesize-approx,-allow-unsafe-ext,-prefer-vp9-sort&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--compat-options youtube-dlc&lt;/code&gt;: Same as &lt;code&gt;--compat-options all,-no-live-chat,-no-youtube-channel-redirect,-playlist-match-filter,-manifest-filesize-approx,-allow-unsafe-ext,-prefer-vp9-sort&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--compat-options 2021&lt;/code&gt;: Same as &lt;code&gt;--compat-options 2022,no-certifi,filename-sanitization&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--compat-options 2022&lt;/code&gt;: Same as &lt;code&gt;--compat-options 2023,playlist-match-filter,no-external-downloader-progress,prefer-legacy-http-handler,manifest-filesize-approx&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--compat-options 2023&lt;/code&gt;: Same as &lt;code&gt;--compat-options 2024,prefer-vp9-sort&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--compat-options 2024&lt;/code&gt;: Same as &lt;code&gt;--compat-options mtime-by-default&lt;/code&gt;. Use this to enable all future compat options&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The following compat options restore vulnerable behavior from before security patches:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;--compat-options allow-unsafe-ext&lt;/code&gt;: Allow files with any extension (including unsafe ones) to be downloaded (&lt;a href="https://github.com/yt-dlp/yt-dlp/security/advisories/GHSA-79w7-vh3h-8g4j"&gt;GHSA-79w7-vh3h-8g4j&lt;/a&gt;)&lt;/p&gt; 
  &lt;blockquote&gt; 
   &lt;p&gt;&lt;span&gt;⚠&lt;/span&gt; Only use if a valid file download is rejected because its extension is detected as uncommon&lt;/p&gt; 
   &lt;p&gt;&lt;strong&gt;This option can enable remote code execution! Consider &lt;a href="https://github.com/yt-dlp/yt-dlp/issues/new/choose"&gt;opening an issue&lt;/a&gt; instead!&lt;/strong&gt;&lt;/p&gt; 
  &lt;/blockquote&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Deprecated options&lt;/h3&gt; 
&lt;p&gt;These are all the deprecated options and the current alternative to achieve the same effect&lt;/p&gt; 
&lt;h4&gt;Almost redundant options&lt;/h4&gt; 
&lt;p&gt;While these options are almost the same as their new counterparts, there are some differences that prevents them being redundant&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;-j, --dump-json                  --print "%()j"
-F, --list-formats               --print formats_table
--list-thumbnails                --print thumbnails_table --print playlist:thumbnails_table
--list-subs                      --print automatic_captions_table --print subtitles_table
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Redundant options&lt;/h4&gt; 
&lt;p&gt;While these options are redundant, they are still expected to be used due to their ease of use&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;--get-description                --print description
--get-duration                   --print duration_string
--get-filename                   --print filename
--get-format                     --print format
--get-id                         --print id
--get-thumbnail                  --print thumbnail
-e, --get-title                  --print title
-g, --get-url                    --print urls
--match-title REGEX              --match-filters "title ~= (?i)REGEX"
--reject-title REGEX             --match-filters "title !~= (?i)REGEX"
--min-views COUNT                --match-filters "view_count &amp;gt;=? COUNT"
--max-views COUNT                --match-filters "view_count &amp;lt;=? COUNT"
--break-on-reject                Use --break-match-filters
--user-agent UA                  --add-headers "User-Agent:UA"
--referer URL                    --add-headers "Referer:URL"
--playlist-start NUMBER          -I NUMBER:
--playlist-end NUMBER            -I :NUMBER
--playlist-reverse               -I ::-1
--no-playlist-reverse            Default
--no-colors                      --color no_color
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Not recommended&lt;/h4&gt; 
&lt;p&gt;While these options still work, their use is not recommended since there are other alternatives to achieve the same&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;--force-generic-extractor        --ies generic,default
--exec-before-download CMD       --exec "before_dl:CMD"
--no-exec-before-download        --no-exec
--all-formats                    -f all
--all-subs                       --sub-langs all --write-subs
--print-json                     -j --no-simulate
--autonumber-size NUMBER         Use string formatting, e.g. %(autonumber)03d
--autonumber-start NUMBER        Use internal field formatting like %(autonumber+NUMBER)s
--id                             -o "%(id)s.%(ext)s"
--metadata-from-title FORMAT     --parse-metadata "%(title)s:FORMAT"
--hls-prefer-native              --downloader "m3u8:native"
--hls-prefer-ffmpeg              --downloader "m3u8:ffmpeg"
--list-formats-old               --compat-options list-formats (Alias: --no-list-formats-as-table)
--list-formats-as-table          --compat-options -list-formats [Default] (Alias: --no-list-formats-old)
--youtube-skip-dash-manifest     --extractor-args "youtube:skip=dash" (Alias: --no-youtube-include-dash-manifest)
--youtube-skip-hls-manifest      --extractor-args "youtube:skip=hls" (Alias: --no-youtube-include-hls-manifest)
--youtube-include-dash-manifest  Default (Alias: --no-youtube-skip-dash-manifest)
--youtube-include-hls-manifest   Default (Alias: --no-youtube-skip-hls-manifest)
--geo-bypass                     --xff "default"
--no-geo-bypass                  --xff "never"
--geo-bypass-country CODE        --xff CODE
--geo-bypass-ip-block IP_BLOCK   --xff IP_BLOCK
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Developer options&lt;/h4&gt; 
&lt;p&gt;These options are not intended to be used by the end-user&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;--test                           Download only part of video for testing extractors
--load-pages                     Load pages dumped by --write-pages
--youtube-print-sig-code         For testing youtube signatures
--allow-unplayable-formats       List unplayable formats also
--no-allow-unplayable-formats    Default
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Old aliases&lt;/h4&gt; 
&lt;p&gt;These are aliases that are no longer documented for various reasons&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;--avconv-location                --ffmpeg-location
--clean-infojson                 --clean-info-json
--cn-verification-proxy URL      --geo-verification-proxy URL
--dump-headers                   --print-traffic
--dump-intermediate-pages        --dump-pages
--force-write-download-archive   --force-write-archive
--no-clean-infojson              --no-clean-info-json
--no-split-tracks                --no-split-chapters
--no-write-srt                   --no-write-subs
--prefer-unsecure                --prefer-insecure
--rate-limit RATE                --limit-rate RATE
--split-tracks                   --split-chapters
--srt-lang LANGS                 --sub-langs LANGS
--trim-file-names LENGTH         --trim-filenames LENGTH
--write-srt                      --write-subs
--yes-overwrites                 --force-overwrites
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Sponskrub Options&lt;/h4&gt; 
&lt;p&gt;Support for &lt;a href="https://github.com/faissaloo/SponSkrub"&gt;SponSkrub&lt;/a&gt; has been deprecated in favor of the &lt;code&gt;--sponsorblock&lt;/code&gt; options&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;--sponskrub                      --sponsorblock-mark all
--no-sponskrub                   --no-sponsorblock
--sponskrub-cut                  --sponsorblock-remove all
--no-sponskrub-cut               --sponsorblock-remove -all
--sponskrub-force                Not applicable
--no-sponskrub-force             Not applicable
--sponskrub-location             Not applicable
--sponskrub-args                 Not applicable
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;No longer supported&lt;/h4&gt; 
&lt;p&gt;These options may no longer work as intended&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;--prefer-avconv                  avconv is not officially supported by yt-dlp (Alias: --no-prefer-ffmpeg)
--prefer-ffmpeg                  Default (Alias: --no-prefer-avconv)
-C, --call-home                  Not implemented
--no-call-home                   Default
--include-ads                    No longer supported
--no-include-ads                 Default
--write-annotations              No supported site has annotations now
--no-write-annotations           Default
--compat-options seperate-video-versions  No longer needed
--compat-options no-youtube-prefer-utc-upload-date  No longer supported
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Removed&lt;/h4&gt; 
&lt;p&gt;These options were deprecated since 2014 and have now been entirely removed&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;-A, --auto-number                -o "%(autonumber)s-%(id)s.%(ext)s"
-t, -l, --title, --literal       -o "%(title)s-%(id)s.%(ext)s"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;CONTRIBUTING&lt;/h1&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/CONTRIBUTING.md#contributing-to-yt-dlp"&gt;CONTRIBUTING.md&lt;/a&gt; for instructions on &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/CONTRIBUTING.md#opening-an-issue"&gt;Opening an Issue&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/CONTRIBUTING.md#developer-instructions"&gt;Contributing code to the project&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;WIKI&lt;/h1&gt; 
&lt;p&gt;See the &lt;a href="https://github.com/yt-dlp/yt-dlp/wiki"&gt;Wiki&lt;/a&gt; for more information&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>IBM/mcp-context-forge</title>
      <link>https://github.com/IBM/mcp-context-forge</link>
      <description>&lt;p&gt;A Model Context Protocol (MCP) Gateway &amp; Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;MCP Gateway&lt;/h1&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Model Context Protocol gateway &amp;amp; proxy - unify REST, MCP, and A2A with federation, virtual servers, retries, security, and an optional admin UI.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/IBM/mcp-context-forge/main/docs/docs/images/contextforge-banner.png" alt="" /&gt;&lt;/p&gt; 
&lt;!-- === CI / Security / Build Badges === --&gt; 
&lt;p&gt;&lt;a href="https://github.com/IBM/mcp-context-forge/actions/workflows/python-package.yml"&gt;&lt;img src="https://github.com/IBM/mcp-context-forge/actions/workflows/python-package.yml/badge.svg?sanitize=true" alt="Build Python Package" /&gt;&lt;/a&gt;&amp;nbsp; &lt;a href="https://github.com/IBM/mcp-context-forge/actions/workflows/codeql.yml"&gt;&lt;img src="https://github.com/IBM/mcp-context-forge/actions/workflows/codeql.yml/badge.svg?sanitize=true" alt="CodeQL" /&gt;&lt;/a&gt;&amp;nbsp; &lt;a href="https://github.com/IBM/mcp-context-forge/actions/workflows/bandit.yml"&gt;&lt;img src="https://github.com/IBM/mcp-context-forge/actions/workflows/bandit.yml/badge.svg?sanitize=true" alt="Bandit Security" /&gt;&lt;/a&gt;&amp;nbsp; &lt;a href="https://github.com/IBM/mcp-context-forge/actions/workflows/dependency-review.yml"&gt;&lt;img src="https://github.com/IBM/mcp-context-forge/actions/workflows/dependency-review.yml/badge.svg?sanitize=true" alt="Dependency Review" /&gt;&lt;/a&gt;&amp;nbsp; &lt;a href="https://github.com/IBM/mcp-context-forge/actions/workflows/pytest.yml"&gt;&lt;img src="https://github.com/IBM/mcp-context-forge/actions/workflows/pytest.yml/badge.svg?sanitize=true" alt="Tests &amp;amp; Coverage" /&gt;&lt;/a&gt;&amp;nbsp; &lt;a href="https://github.com/IBM/mcp-context-forge/actions/workflows/lint.yml"&gt;&lt;img src="https://github.com/IBM/mcp-context-forge/actions/workflows/lint.yml/badge.svg?sanitize=true" alt="Lint &amp;amp; Static Analysis" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;!-- === Container Build &amp; Deploy === --&gt; 
&lt;p&gt;&lt;a href="https://github.com/IBM/mcp-context-forge/actions/workflows/docker-image.yml"&gt;&lt;img src="https://github.com/IBM/mcp-context-forge/actions/workflows/docker-image.yml/badge.svg?sanitize=true" alt="Secure Docker Build" /&gt;&lt;/a&gt;&amp;nbsp; &lt;a href="https://github.com/IBM/mcp-context-forge/actions/workflows/ibm-cloud-code-engine.yml"&gt;&lt;img src="https://github.com/IBM/mcp-context-forge/actions/workflows/ibm-cloud-code-engine.yml/badge.svg?sanitize=true" alt="Deploy to IBM Code Engine" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;!-- === Package / Container === --&gt; 
&lt;p&gt;&lt;a href="https://docs.python.org/3/library/asyncio.html"&gt;&lt;img src="https://img.shields.io/badge/async-await-green.svg?sanitize=true" alt="Async" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/IBM/mcp-context-forge/main/LICENSE"&gt;&lt;img src="https://img.shields.io/github/license/ibm/mcp-context-forge" alt="License" /&gt;&lt;/a&gt;&amp;nbsp; &lt;a href="https://pypi.org/project/mcp-contextforge-gateway/"&gt;&lt;img src="https://img.shields.io/pypi/v/mcp-contextforge-gateway" alt="PyPI" /&gt;&lt;/a&gt;&amp;nbsp; &lt;a href="https://github.com/ibm/mcp-context-forge/pkgs/container/mcp-context-forge"&gt;&lt;img src="https://img.shields.io/badge/docker-ghcr.io%2Fibm%2Fmcp--context--forge-blue" alt="Docker Image" /&gt;&lt;/a&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;ContextForge MCP Gateway is a feature-rich gateway, proxy and MCP Registry that federates MCP and REST services - unifying discovery, auth, rate-limiting, observability, virtual servers, multi-transport protocols, and an optional Admin UI into one clean endpoint for your AI clients. It runs as a fully compliant MCP server, deployable via PyPI or Docker, and scales to multi-cluster environments on Kubernetes with Redis-backed federation and caching.&lt;/p&gt; 
&lt;h2&gt;&lt;img src="https://ibm.github.io/mcp-context-forge/images/mcpgateway.gif" alt="MCP Gateway" /&gt;&lt;/h2&gt; 
&lt;!-- vscode-markdown-toc --&gt; 
&lt;h2&gt;Table of Contents&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; 
  &lt;ol&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/IBM/mcp-context-forge/main/#table-of-contents"&gt;Table of Contents&lt;/a&gt;&lt;/li&gt; 
  &lt;/ol&gt; &lt;/li&gt; 
 &lt;li&gt; 
  &lt;ol start="2"&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/IBM/mcp-context-forge/main/#-overview--goals"&gt;🚀 Overview &amp;amp; Goals&lt;/a&gt;&lt;/li&gt; 
  &lt;/ol&gt; &lt;/li&gt; 
 &lt;li&gt; 
  &lt;ol start="3"&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/IBM/mcp-context-forge/main/#quick-start---pypi"&gt;Quick Start - PyPI&lt;/a&gt;&lt;/li&gt; 
  &lt;/ol&gt; 
  &lt;ul&gt; 
   &lt;li&gt;3.1. &lt;a href="https://raw.githubusercontent.com/IBM/mcp-context-forge/main/#1---install--run-copy-paste-friendly"&gt;1 - Install &amp;amp; run (copy-paste friendly)&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; 
  &lt;ol start="4"&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/IBM/mcp-context-forge/main/#quick-start---containers"&gt;Quick Start - Containers&lt;/a&gt;&lt;/li&gt; 
  &lt;/ol&gt; 
  &lt;ul&gt; 
   &lt;li&gt;4.1. &lt;a href="https://raw.githubusercontent.com/IBM/mcp-context-forge/main/#-docker"&gt;🐳 Docker&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;4.1.1. &lt;a href="https://raw.githubusercontent.com/IBM/mcp-context-forge/main/#1---minimum-viable-run"&gt;1 - Minimum viable run&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;4.1.2. &lt;a href="https://raw.githubusercontent.com/IBM/mcp-context-forge/main/#2---persist-the-sqlite-database"&gt;2 - Persist the SQLite database&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;4.1.3. &lt;a href="https://raw.githubusercontent.com/IBM/mcp-context-forge/main/#3---local-tool-discovery-host-network"&gt;3 - Local tool discovery (host network)&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;4.2. &lt;a href="https://raw.githubusercontent.com/IBM/mcp-context-forge/main/#-podman-rootless-friendly"&gt;🦭 Podman (rootless-friendly)&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;4.2.1. &lt;a href="https://raw.githubusercontent.com/IBM/mcp-context-forge/main/#1---basic-run"&gt;1 - Basic run&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;4.2.2. &lt;a href="https://raw.githubusercontent.com/IBM/mcp-context-forge/main/#2---persist-sqlite"&gt;2 - Persist SQLite&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;4.2.3. &lt;a href="https://raw.githubusercontent.com/IBM/mcp-context-forge/main/#3---host-networking-rootless"&gt;3 - Host networking (rootless)&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; 
  &lt;ol start="5"&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/IBM/mcp-context-forge/main/#testing-mcpgatewaywrapper-by-hand"&gt;Testing &lt;code&gt;mcpgateway.wrapper&lt;/code&gt; by hand&lt;/a&gt;&lt;/li&gt; 
  &lt;/ol&gt; 
  &lt;ul&gt; 
   &lt;li&gt;5.1. &lt;a href="https://raw.githubusercontent.com/IBM/mcp-context-forge/main/#-running-from-an-mcp-client-mcpgatewaywrapper"&gt;🧩 Running from an MCP Client (&lt;code&gt;mcpgateway.wrapper&lt;/code&gt;)&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;5.1.1. &lt;a href="https://raw.githubusercontent.com/IBM/mcp-context-forge/main/#1---install-uv-uvx-is-an-alias-it-provides"&gt;1 - Install &lt;code&gt;uv&lt;/code&gt; (&lt;code&gt;uvx&lt;/code&gt; is an alias it provides)&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;5.1.2. &lt;a href="https://raw.githubusercontent.com/IBM/mcp-context-forge/main/#2---create-an-on-the-spot-venv--run-the-wrapper"&gt;2 - Create an on-the-spot venv &amp;amp; run the wrapper&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;5.1.3. &lt;a href="https://raw.githubusercontent.com/IBM/mcp-context-forge/main/#claude-desktop-json-runs-through-uvx"&gt;Claude Desktop JSON (runs through &lt;strong&gt;uvx&lt;/strong&gt;)&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;5.2. &lt;a href="https://raw.githubusercontent.com/IBM/mcp-context-forge/main/#-using-with-claude-desktop-or-any-gui-mcp-client"&gt;🚀 Using with Claude Desktop (or any GUI MCP client)&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; 
  &lt;ol start="6"&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/IBM/mcp-context-forge/main/#-quick-start-vs-code-dev-container"&gt;🚀 Quick Start: VS Code Dev Container&lt;/a&gt;&lt;/li&gt; 
  &lt;/ol&gt; 
  &lt;ul&gt; 
   &lt;li&gt;6.1. &lt;a href="https://raw.githubusercontent.com/IBM/mcp-context-forge/main/#1---clone--open"&gt;1 - Clone &amp;amp; Open&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;6.2. &lt;a href="https://raw.githubusercontent.com/IBM/mcp-context-forge/main/#2---first-time-build-automatic"&gt;2 - First-Time Build (Automatic)&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; 
  &lt;ol start="7"&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/IBM/mcp-context-forge/main/#quick-start-manual-install"&gt;Quick Start (manual install)&lt;/a&gt;&lt;/li&gt; 
  &lt;/ol&gt; 
  &lt;ul&gt; 
   &lt;li&gt;7.1. &lt;a href="https://raw.githubusercontent.com/IBM/mcp-context-forge/main/#prerequisites"&gt;Prerequisites&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;7.2. &lt;a href="https://raw.githubusercontent.com/IBM/mcp-context-forge/main/#one-liner-dev"&gt;One-liner (dev)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;7.3. &lt;a href="https://raw.githubusercontent.com/IBM/mcp-context-forge/main/#containerized-self-signed-tls"&gt;Containerized (self-signed TLS)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;7.4. &lt;a href="https://raw.githubusercontent.com/IBM/mcp-context-forge/main/#smoke-test-the-api"&gt;Smoke-test the API&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; 
  &lt;ol start="8"&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/IBM/mcp-context-forge/main/#installation"&gt;Installation&lt;/a&gt;&lt;/li&gt; 
  &lt;/ol&gt; 
  &lt;ul&gt; 
   &lt;li&gt;8.1. &lt;a href="https://raw.githubusercontent.com/IBM/mcp-context-forge/main/#via-make"&gt;Via Make&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;8.2. &lt;a href="https://raw.githubusercontent.com/IBM/mcp-context-forge/main/#uv-alternative"&gt;UV (alternative)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;8.3. &lt;a href="https://raw.githubusercontent.com/IBM/mcp-context-forge/main/#pip-alternative"&gt;pip (alternative)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;8.4. &lt;a href="https://raw.githubusercontent.com/IBM/mcp-context-forge/main/#optional-postgresql-adapter"&gt;Optional (PostgreSQL adapter)&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;8.4.1. &lt;a href="https://raw.githubusercontent.com/IBM/mcp-context-forge/main/#quick-postgres-container"&gt;Quick Postgres container&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; 
  &lt;ol start="9"&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/IBM/mcp-context-forge/main/#configuration-env-or-env-vars"&gt;Configuration (&lt;code&gt;.env&lt;/code&gt; or env vars)&lt;/a&gt;&lt;/li&gt; 
  &lt;/ol&gt; 
  &lt;ul&gt; 
   &lt;li&gt;9.1. &lt;a href="https://raw.githubusercontent.com/IBM/mcp-context-forge/main/#basic"&gt;Basic&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;9.2. &lt;a href="https://raw.githubusercontent.com/IBM/mcp-context-forge/main/#authentication"&gt;Authentication&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;9.3. &lt;a href="https://raw.githubusercontent.com/IBM/mcp-context-forge/main/#ui-features"&gt;UI Features&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;9.4. &lt;a href="https://raw.githubusercontent.com/IBM/mcp-context-forge/main/#security"&gt;Security&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;9.5. &lt;a href="https://raw.githubusercontent.com/IBM/mcp-context-forge/main/#logging"&gt;Logging&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;9.6. &lt;a href="https://raw.githubusercontent.com/IBM/mcp-context-forge/main/#transport"&gt;Transport&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;9.7. &lt;a href="https://raw.githubusercontent.com/IBM/mcp-context-forge/main/#federation"&gt;Federation&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;9.8. &lt;a href="https://raw.githubusercontent.com/IBM/mcp-context-forge/main/#resources"&gt;Resources&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;9.9. &lt;a href="https://raw.githubusercontent.com/IBM/mcp-context-forge/main/#tools"&gt;Tools&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;9.10. &lt;a href="https://raw.githubusercontent.com/IBM/mcp-context-forge/main/#prompts"&gt;Prompts&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;9.11. &lt;a href="https://raw.githubusercontent.com/IBM/mcp-context-forge/main/#health-checks"&gt;Health Checks&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;9.12. &lt;a href="https://raw.githubusercontent.com/IBM/mcp-context-forge/main/#database"&gt;Database&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;9.13. &lt;a href="https://raw.githubusercontent.com/IBM/mcp-context-forge/main/#cache-backend"&gt;Cache Backend&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;9.14. &lt;a href="https://raw.githubusercontent.com/IBM/mcp-context-forge/main/#development"&gt;Development&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; 
  &lt;ol start="10"&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/IBM/mcp-context-forge/main/#running"&gt;Running&lt;/a&gt;&lt;/li&gt; 
  &lt;/ol&gt; 
  &lt;ul&gt; 
   &lt;li&gt;10.1. &lt;a href="https://raw.githubusercontent.com/IBM/mcp-context-forge/main/#makefile"&gt;Makefile&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;10.2. &lt;a href="https://raw.githubusercontent.com/IBM/mcp-context-forge/main/#script-helper"&gt;Script helper&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;10.3. &lt;a href="https://raw.githubusercontent.com/IBM/mcp-context-forge/main/#manual-uvicorn"&gt;Manual (Uvicorn)&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; 
  &lt;ol start="11"&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/IBM/mcp-context-forge/main/#authentication-examples"&gt;Authentication examples&lt;/a&gt;&lt;/li&gt; 
  &lt;/ol&gt; &lt;/li&gt; 
 &lt;li&gt; 
  &lt;ol start="12"&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/IBM/mcp-context-forge/main/#%EF%B8%8F-aws--azure--openshift"&gt;☁️ AWS / Azure / OpenShift&lt;/a&gt;&lt;/li&gt; 
  &lt;/ol&gt; &lt;/li&gt; 
 &lt;li&gt; 
  &lt;ol start="13"&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/IBM/mcp-context-forge/main/#%EF%B8%8F-ibm-cloud-code-engine-deployment"&gt;☁️ IBM Cloud Code Engine Deployment&lt;/a&gt;&lt;/li&gt; 
  &lt;/ol&gt; 
  &lt;ul&gt; 
   &lt;li&gt;13.1. &lt;a href="https://raw.githubusercontent.com/IBM/mcp-context-forge/main/#-prerequisites-1"&gt;🔧 Prerequisites&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;13.2. &lt;a href="https://raw.githubusercontent.com/IBM/mcp-context-forge/main/#-environment-variables"&gt;📦 Environment Variables&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;13.3. &lt;a href="https://raw.githubusercontent.com/IBM/mcp-context-forge/main/#-make-targets"&gt;🚀 Make Targets&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;13.4. &lt;a href="https://raw.githubusercontent.com/IBM/mcp-context-forge/main/#-example-workflow"&gt;📝 Example Workflow&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; 
  &lt;ol start="14"&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/IBM/mcp-context-forge/main/#api-endpoints"&gt;API Endpoints&lt;/a&gt;&lt;/li&gt; 
  &lt;/ol&gt; &lt;/li&gt; 
 &lt;li&gt; 
  &lt;ol start="15"&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/IBM/mcp-context-forge/main/#testing"&gt;Testing&lt;/a&gt;&lt;/li&gt; 
  &lt;/ol&gt; &lt;/li&gt; 
 &lt;li&gt; 
  &lt;ol start="16"&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/IBM/mcp-context-forge/main/#project-structure"&gt;Project Structure&lt;/a&gt;&lt;/li&gt; 
  &lt;/ol&gt; &lt;/li&gt; 
 &lt;li&gt; 
  &lt;ol start="17"&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/IBM/mcp-context-forge/main/#api-documentation"&gt;API Documentation&lt;/a&gt;&lt;/li&gt; 
  &lt;/ol&gt; &lt;/li&gt; 
 &lt;li&gt; 
  &lt;ol start="18"&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/IBM/mcp-context-forge/main/#makefile-targets"&gt;Makefile targets&lt;/a&gt;&lt;/li&gt; 
  &lt;/ol&gt; &lt;/li&gt; 
 &lt;li&gt; 
  &lt;ol start="19"&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/IBM/mcp-context-forge/main/#-troubleshooting"&gt;🔍 Troubleshooting&lt;/a&gt;&lt;/li&gt; 
  &lt;/ol&gt; 
  &lt;ul&gt; 
   &lt;li&gt;19.1. &lt;a href="https://raw.githubusercontent.com/IBM/mcp-context-forge/main/#diagnose-the-listener"&gt;Diagnose the listener&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;19.2. &lt;a href="https://raw.githubusercontent.com/IBM/mcp-context-forge/main/#why-localhost-fails-on-windows"&gt;Why localhost fails on Windows&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;19.2.1. &lt;a href="https://raw.githubusercontent.com/IBM/mcp-context-forge/main/#fix-podman-rootless"&gt;Fix (Podman rootless)&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;19.2.2. &lt;a href="https://raw.githubusercontent.com/IBM/mcp-context-forge/main/#fix-docker-desktop--419"&gt;Fix (Docker Desktop &amp;gt; 4.19)&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; 
  &lt;ol start="20"&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/IBM/mcp-context-forge/main/#contributing"&gt;Contributing&lt;/a&gt;&lt;/li&gt; 
  &lt;/ol&gt; &lt;/li&gt; 
 &lt;li&gt; 
  &lt;ol start="21"&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/IBM/mcp-context-forge/main/#changelog"&gt;Changelog&lt;/a&gt;&lt;/li&gt; 
  &lt;/ol&gt; &lt;/li&gt; 
 &lt;li&gt; 
  &lt;ol start="22"&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/IBM/mcp-context-forge/main/#license"&gt;License&lt;/a&gt;&lt;/li&gt; 
  &lt;/ol&gt; &lt;/li&gt; 
 &lt;li&gt; 
  &lt;ol start="23"&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/IBM/mcp-context-forge/main/#core-authors-and-maintainers"&gt;Core Authors and Maintainers&lt;/a&gt;&lt;/li&gt; 
  &lt;/ol&gt; &lt;/li&gt; 
 &lt;li&gt; 
  &lt;ol start="24"&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/IBM/mcp-context-forge/main/#star-history-and-project-activity"&gt;Star History and Project Activity&lt;/a&gt;&lt;/li&gt; 
  &lt;/ol&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;!-- vscode-markdown-toc-config
    numbering=true
    autoSave=true
    /vscode-markdown-toc-config --&gt; 
&lt;!-- /vscode-markdown-toc --&gt; 
&lt;h2&gt;🚀 Overview &amp;amp; Goals&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;ContextForge MCP Gateway&lt;/strong&gt; is a gateway, registry, and proxy that sits in front of any &lt;a href="https://modelcontextprotocol.io"&gt;Model Context Protocol&lt;/a&gt; (MCP) server or REST API-exposing a unified endpoint for all your AI clients.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;⚠️ Caution&lt;/strong&gt;: The current release (0.6.0) is considered alpha / early beta. It is not production-ready and should only be used for local development, testing, or experimentation. Features, APIs, and behaviors are subject to change without notice. &lt;strong&gt;Do not&lt;/strong&gt; deploy in production environments without thorough security review, validation and additional security mechanisms. Many of the features required for secure, large-scale, or multi-tenant production deployments are still on the &lt;a href="https://ibm.github.io/mcp-context-forge/architecture/roadmap/"&gt;project roadmap&lt;/a&gt; - which is itself evolving.&lt;/p&gt; 
&lt;p&gt;It currently supports:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Federation across multiple MCP and REST services&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;A2A (Agent-to-Agent) integration&lt;/strong&gt; for external AI agents (OpenAI, Anthropic, custom)&lt;/li&gt; 
 &lt;li&gt;Virtualization of legacy APIs as MCP-compliant tools and servers&lt;/li&gt; 
 &lt;li&gt;Transport over HTTP, JSON-RPC, WebSocket, SSE (with configurable keepalive), stdio and streamable-HTTP&lt;/li&gt; 
 &lt;li&gt;An Admin UI for real-time management, configuration, and log monitoring&lt;/li&gt; 
 &lt;li&gt;Built-in auth, retries, and rate-limiting&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;OpenTelemetry observability&lt;/strong&gt; with Phoenix, Jaeger, Zipkin, and other OTLP backends&lt;/li&gt; 
 &lt;li&gt;Scalable deployments via Docker or PyPI, Redis-backed caching, and multi-cluster federation&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://ibm.github.io/mcp-context-forge/images/mcpgateway.svg?sanitize=true" alt="MCP Gateway Architecture" /&gt;&lt;/p&gt; 
&lt;p&gt;For a list of upcoming features, check out the &lt;a href="https://ibm.github.io/mcp-context-forge/architecture/roadmap/"&gt;ContextForge MCP Gateway Roadmap&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;⚠️ Important&lt;/strong&gt;: MCP Gateway is not a standalone product - it is an open source component with &lt;strong&gt;NO OFFICIAL SUPPORT&lt;/strong&gt; from IBM or its affiliates that can be integrated into your own solution architecture. If you choose to use it, you are responsible for evaluating its fit, securing the deployment, and managing its lifecycle. See &lt;a href="https://raw.githubusercontent.com/IBM/mcp-context-forge/main/SECURITY.md"&gt;SECURITY.md&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;🔌 Gateway Layer with Protocol Flexibility&lt;/strong&gt;&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Sits in front of any MCP server or REST API&lt;/li&gt; 
  &lt;li&gt;Lets you choose your MCP protocol version (e.g., &lt;code&gt;2025-03-26&lt;/code&gt;)&lt;/li&gt; 
  &lt;li&gt;Exposes a single, unified interface for diverse backends&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;🌐 Federation of Peer Gateways (MCP Registry)&lt;/strong&gt;&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Auto-discovers or configures peer gateways (via mDNS or manual)&lt;/li&gt; 
  &lt;li&gt;Performs health checks and merges remote registries transparently&lt;/li&gt; 
  &lt;li&gt;Supports Redis-backed syncing and fail-over&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;🧩 Virtualization of REST/gRPC Services&lt;/strong&gt;&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Wraps non-MCP services as virtual MCP servers&lt;/li&gt; 
  &lt;li&gt;Registers tools, prompts, and resources with minimal configuration&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;🔁 REST-to-MCP Tool Adapter&lt;/strong&gt;&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;Adapts REST APIs into tools with:&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Automatic JSON Schema extraction&lt;/li&gt; 
    &lt;li&gt;Support for headers, tokens, and custom auth&lt;/li&gt; 
    &lt;li&gt;Retry, timeout, and rate-limit policies&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;🧠 Unified Registries&lt;/strong&gt;&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;Prompts&lt;/strong&gt;: Jinja2 templates, multimodal support, rollback/versioning&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Resources&lt;/strong&gt;: URI-based access, MIME detection, caching, SSE updates&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Tools&lt;/strong&gt;: Native or adapted, with input validation and concurrency controls&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;📈 Admin UI, Observability &amp;amp; Dev Experience&lt;/strong&gt;&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Admin UI built with HTMX + Alpine.js&lt;/li&gt; 
  &lt;li&gt;Real-time log viewer with filtering, search, and export capabilities&lt;/li&gt; 
  &lt;li&gt;Auth: Basic, JWT, or custom schemes&lt;/li&gt; 
  &lt;li&gt;Structured logs, health endpoints, metrics&lt;/li&gt; 
  &lt;li&gt;400+ tests, Makefile targets, live reload, pre-commit hooks&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;🔍 OpenTelemetry Observability&lt;/strong&gt;&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;Vendor-agnostic tracing&lt;/strong&gt; with OpenTelemetry (OTLP) protocol support&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Multiple backend support&lt;/strong&gt;: Phoenix (LLM-focused), Jaeger, Zipkin, Tempo, DataDog, New Relic&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Distributed tracing&lt;/strong&gt; across federated gateways and services&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Automatic instrumentation&lt;/strong&gt; of tools, prompts, resources, and gateway operations&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;LLM-specific metrics&lt;/strong&gt;: Token usage, costs, model performance&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Zero-overhead when disabled&lt;/strong&gt; with graceful degradation&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Easy configuration&lt;/strong&gt; via environment variables&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;Quick start with Phoenix (LLM observability):&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# Start Phoenix
docker run -p 6006:6006 -p 4317:4317 arizephoenix/phoenix:latest

# Configure gateway
export OTEL_ENABLE_OBSERVABILITY=true
export OTEL_TRACES_EXPORTER=otlp
export OTEL_EXPORTER_OTLP_ENDPOINT=http://localhost:4317

# Run gateway - traces automatically sent to Phoenix
mcpgateway
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;See &lt;a href="https://ibm.github.io/mcp-context-forge/manage/observability/"&gt;Observability Documentation&lt;/a&gt; for detailed setup with other backends.&lt;/p&gt; 
&lt;/details&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Quick Start - PyPI&lt;/h2&gt; 
&lt;p&gt;MCP Gateway is published on &lt;a href="https://pypi.org/project/mcp-contextforge-gateway/"&gt;PyPI&lt;/a&gt; as &lt;code&gt;mcp-contextforge-gateway&lt;/code&gt;.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;strong&gt;TLDR;&lt;/strong&gt;: (single command using &lt;a href="https://docs.astral.sh/uv/"&gt;uv&lt;/a&gt;)&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;BASIC_AUTH_PASSWORD=pass \
MCPGATEWAY_UI_ENABLED=true \
MCPGATEWAY_ADMIN_API_ENABLED=true \
uvx --from mcp-contextforge-gateway mcpgateway --host 0.0.0.0 --port 4444
&lt;/code&gt;&lt;/pre&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;📋 Prerequisites&lt;/strong&gt;&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;Python ≥ 3.10&lt;/strong&gt; (3.11 recommended)&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;curl + jq&lt;/strong&gt; - only for the last smoke-test step&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h3&gt;1 - Install &amp;amp; run (copy-paste friendly)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# 1️⃣  Isolated env + install from pypi
mkdir mcpgateway &amp;amp;&amp;amp; cd mcpgateway
python3 -m venv .venv &amp;amp;&amp;amp; source .venv/bin/activate
pip install --upgrade pip
pip install mcp-contextforge-gateway

# 2️⃣  Launch on all interfaces with custom creds &amp;amp; secret key
# Enable the Admin API endpoints (true/false) - disabled by default
export MCPGATEWAY_UI_ENABLED=true
export MCPGATEWAY_ADMIN_API_ENABLED=true

BASIC_AUTH_PASSWORD=pass JWT_SECRET_KEY=my-test-key \
  mcpgateway --host 0.0.0.0 --port 4444 &amp;amp;   # admin/pass

# 3️⃣  Generate a bearer token &amp;amp; smoke-test the API
export MCPGATEWAY_BEARER_TOKEN=$(python3 -m mcpgateway.utils.create_jwt_token \
    --username admin --exp 10080 --secret my-test-key)

curl -s -H "Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN" \
     http://127.0.0.1:4444/version | jq
&lt;/code&gt;&lt;/pre&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;Windows (PowerShell) quick-start&lt;/strong&gt;&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-powershell"&gt;# 1️⃣  Isolated env + install from PyPI
mkdir mcpgateway ; cd mcpgateway
python3 -m venv .venv ; .\.venv\Scripts\Activate.ps1
pip install --upgrade pip
pip install mcp-contextforge-gateway

# 2️⃣  Environment variables (session-only)
$Env:MCPGATEWAY_UI_ENABLED        = "true"
$Env:MCPGATEWAY_ADMIN_API_ENABLED = "true"
$Env:BASIC_AUTH_PASSWORD          = "changeme"      # admin/changeme
$Env:JWT_SECRET_KEY               = "my-test-key"

# 3️⃣  Launch the gateway
mcpgateway.exe --host 0.0.0.0 --port 4444

#   Optional: background it
# Start-Process -FilePath "mcpgateway.exe" -ArgumentList "--host 0.0.0.0 --port 4444"

# 4️⃣  Bearer token and smoke-test
$Env:MCPGATEWAY_BEARER_TOKEN = python3 -m mcpgateway.utils.create_jwt_token `
    --username admin --exp 10080 --secret my-test-key

curl -s -H "Authorization: Bearer $Env:MCPGATEWAY_BEARER_TOKEN" `
     http://127.0.0.1:4444/version | jq
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;More configuration&lt;/strong&gt;&lt;/summary&gt; 
 &lt;p&gt;Copy &lt;a href="https://raw.githubusercontent.com/IBM/mcp-context-forge/main/.env.example"&gt;.env.example&lt;/a&gt; to &lt;code&gt;.env&lt;/code&gt; and tweak any of the settings (or use them as env variables).&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;🚀 End-to-end demo (register a local MCP server)&lt;/strong&gt;&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# 1️⃣  Spin up the sample GO MCP time server using mcpgateway.translate &amp;amp; docker
python3 -m mcpgateway.translate \
     --stdio "docker run --rm -i -p 8888:8080 ghcr.io/ibm/fast-time-server:latest -transport=stdio" \
     --expose-sse \
     --port 8003

# Or using the official mcp-server-git using uvx:
pip install uv # to install uvx, if not already installed
python3 -m mcpgateway.translate --stdio "uvx mcp-server-git" --expose-sse --port 9000

# Alternative: running the local binary
# cd mcp-servers/go/fast-time-server; make build
# python3 -m mcpgateway.translate --stdio "./dist/fast-time-server -transport=stdio" --expose-sse --port 8002

# NEW: Expose via multiple protocols simultaneously!
python3 -m mcpgateway.translate \
     --stdio "uvx mcp-server-git" \
     --expose-sse \
     --expose-streamable-http \
     --port 9000
# Now accessible via both /sse (SSE) and /mcp (streamable HTTP) endpoints

# 2️⃣  Register it with the gateway
curl -s -X POST -H "Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN" \
     -H "Content-Type: application/json" \
     -d '{"name":"fast_time","url":"http://localhost:9000/sse"}' \
     http://localhost:4444/gateways

# 3️⃣  Verify tool catalog
curl -s -H "Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN" http://localhost:4444/tools | jq

# 4️⃣  Create a *virtual server* bundling those tools. Use the ID of tools from the tool catalog (Step #3) and pass them in the associatedTools list.
curl -s -X POST -H "Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN" \
     -H "Content-Type: application/json" \
     -d '{"name":"time_server","description":"Fast time tools","associatedTools":[&amp;lt;ID_OF_TOOLS&amp;gt;]}' \
     http://localhost:4444/servers | jq

# Example curl
curl -s -X POST -H "Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN"
     -H "Content-Type: application/json"
     -d '{"name":"time_server","description":"Fast time tools","associatedTools":["6018ca46d32a4ac6b4c054c13a1726a2"]}' \
     http://localhost:4444/servers | jq

# 5️⃣  List servers (should now include the UUID of the newly created virtual server)
curl -s -H "Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN" http://localhost:4444/servers | jq

# 6️⃣  Client SSE endpoint. Inspect it interactively with the MCP Inspector CLI (or use any MCP client)
npx -y @modelcontextprotocol/inspector
# Transport Type: SSE, URL: http://localhost:4444/servers/UUID_OF_SERVER_1/sse,  Header Name: "Authorization", Bearer Token
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;🖧 Using the stdio wrapper (mcpgateway-wrapper)&lt;/strong&gt;&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;export MCP_AUTH=$MCPGATEWAY_BEARER_TOKEN
export MCP_SERVER_URL=http://localhost:4444/servers/UUID_OF_SERVER_1/mcp
python3 -m mcpgateway.wrapper  # Ctrl-C to exit
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;You can also run it with &lt;code&gt;uv&lt;/code&gt; or inside Docker/Podman - see the &lt;em&gt;Containers&lt;/em&gt; section above.&lt;/p&gt; 
 &lt;p&gt;In MCP Inspector, define &lt;code&gt;MCP_AUTH&lt;/code&gt; and &lt;code&gt;MCP_SERVER_URL&lt;/code&gt; env variables, and select &lt;code&gt;python3&lt;/code&gt; as the Command, and &lt;code&gt;-m mcpgateway.wrapper&lt;/code&gt; as Arguments.&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;echo $PWD/.venv/bin/python3 # Using the Python3 full path ensures you have a working venv
export MCP_SERVER_URL='http://localhost:4444/servers/UUID_OF_SERVER_1/mcp'
export MCP_AUTH=${MCPGATEWAY_BEARER_TOKEN}
npx -y @modelcontextprotocol/inspector
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;or&lt;/p&gt; 
 &lt;p&gt;Pass the url and auth as arguments (no need to set environment variables)&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;npx -y @modelcontextprotocol/inspector
command as `python`
Arguments as `-m mcpgateway.wrapper --url "http://localhost:4444/servers/UUID_OF_SERVER_1/mcp" --auth "Bearer &amp;lt;your token&amp;gt;"`
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;When using a MCP Client such as Claude with stdio:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-json"&gt;{
  "mcpServers": {
    "mcpgateway-wrapper": {
      "command": "python",
      "args": ["-m", "mcpgateway.wrapper"],
      "env": {
        "MCP_AUTH": "your-token-here",
        "MCP_SERVER_URL": "http://localhost:4444/servers/UUID_OF_SERVER_1",
        "MCP_TOOL_CALL_TIMEOUT": "120"
      }
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Quick Start - Containers&lt;/h2&gt; 
&lt;p&gt;Use the official OCI image from GHCR with &lt;strong&gt;Docker&lt;/strong&gt; &lt;em&gt;or&lt;/em&gt; &lt;strong&gt;Podman&lt;/strong&gt;.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h3&gt;🐳 Docker&lt;/h3&gt; 
&lt;h4&gt;1 - Minimum viable run&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run -d --name mcpgateway \
  -p 4444:4444 \
  -e MCPGATEWAY_UI_ENABLED=true \
  -e MCPGATEWAY_ADMIN_API_ENABLED=true \
  -e HOST=0.0.0.0 \
  -e JWT_SECRET_KEY=my-test-key \
  -e BASIC_AUTH_USER=admin \
  -e BASIC_AUTH_PASSWORD=changeme \
  -e AUTH_REQUIRED=true \
  -e DATABASE_URL=sqlite:///./mcp.db \
  ghcr.io/ibm/mcp-context-forge:0.6.0

# Tail logs (Ctrl+C to quit)
docker logs -f mcpgateway

# Generating an API key
docker run --rm -it ghcr.io/ibm/mcp-context-forge:0.6.0 \
  python3 -m mcpgateway.utils.create_jwt_token --username admin --exp 0 --secret my-test-key
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Browse to &lt;strong&gt;&lt;a href="http://localhost:4444/admin"&gt;http://localhost:4444/admin&lt;/a&gt;&lt;/strong&gt; (user &lt;code&gt;admin&lt;/code&gt; / pass &lt;code&gt;changeme&lt;/code&gt;).&lt;/p&gt; 
&lt;h4&gt;2 - Persist the SQLite database&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;mkdir -p $(pwd)/data

touch $(pwd)/data/mcp.db

sudo chown -R :docker $(pwd)/data

chmod 777 $(pwd)/data

docker run -d --name mcpgateway \
  --restart unless-stopped \
  -p 4444:4444 \
  -v $(pwd)/data:/data \
  -e MCPGATEWAY_UI_ENABLED=true \
  -e MCPGATEWAY_ADMIN_API_ENABLED=true \
  -e DATABASE_URL=sqlite:////data/mcp.db \
  -e HOST=0.0.0.0 \
  -e JWT_SECRET_KEY=my-test-key \
  -e BASIC_AUTH_USER=admin \
  -e BASIC_AUTH_PASSWORD=changeme \
  ghcr.io/ibm/mcp-context-forge:0.6.0
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;SQLite now lives on the host at &lt;code&gt;./data/mcp.db&lt;/code&gt;.&lt;/p&gt; 
&lt;h4&gt;3 - Local tool discovery (host network)&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;mkdir -p $(pwd)/data

touch $(pwd)/data/mcp.db

sudo chown -R :docker $(pwd)/data

chmod 777 $(pwd)/data

docker run -d --name mcpgateway \
  --network=host \
  -e MCPGATEWAY_UI_ENABLED=true \
  -e MCPGATEWAY_ADMIN_API_ENABLED=true \
  -e HOST=0.0.0.0 \
  -e PORT=4444 \
  -e DATABASE_URL=sqlite:////data/mcp.db \
  -v $(pwd)/data:/data \
  ghcr.io/ibm/mcp-context-forge:0.6.0
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Using &lt;code&gt;--network=host&lt;/code&gt; allows Docker to access the local network, allowing you to add MCP servers running on your host. See &lt;a href="https://docs.docker.com/engine/network/drivers/host/"&gt;Docker Host network driver documentation&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h3&gt;🦭 Podman (rootless-friendly)&lt;/h3&gt; 
&lt;h4&gt;1 - Basic run&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;podman run -d --name mcpgateway \
  -p 4444:4444 \
  -e HOST=0.0.0.0 \
  -e DATABASE_URL=sqlite:///./mcp.db \
  ghcr.io/ibm/mcp-context-forge:0.6.0
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;2 - Persist SQLite&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;mkdir -p $(pwd)/data

touch $(pwd)/data/mcp.db

sudo chown -R :docker $(pwd)/data

chmod 777 $(pwd)/data

podman run -d --name mcpgateway \
  --restart=on-failure \
  -p 4444:4444 \
  -v $(pwd)/data:/data \
  -e DATABASE_URL=sqlite:////data/mcp.db \
  ghcr.io/ibm/mcp-context-forge:0.6.0
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;3 - Host networking (rootless)&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;mkdir -p $(pwd)/data

touch $(pwd)/data/mcp.db

sudo chown -R :docker $(pwd)/data

chmod 777 $(pwd)/data

podman run -d --name mcpgateway \
  --network=host \
  -v $(pwd)/data:/data \
  -e DATABASE_URL=sqlite:////data/mcp.db \
  ghcr.io/ibm/mcp-context-forge:0.6.0
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;✏️ Docker/Podman tips&lt;/strong&gt;&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;.env files&lt;/strong&gt; - Put all the &lt;code&gt;-e FOO=&lt;/code&gt; lines into a file and replace them with &lt;code&gt;--env-file .env&lt;/code&gt;. See the provided &lt;a href="https://raw.githubusercontent.com/IBM/mcp-context-forge/main/.env.example"&gt;.env.example&lt;/a&gt; for reference.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Pinned tags&lt;/strong&gt; - Use an explicit version (e.g. &lt;code&gt;v0.6.0&lt;/code&gt;) instead of &lt;code&gt;latest&lt;/code&gt; for reproducible builds.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;JWT tokens&lt;/strong&gt; - Generate one in the running container:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;docker exec mcpgateway python3 -m mcpgateway.utils.create_jwt_token -u admin -e 10080 --secret my-test-key
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Upgrades&lt;/strong&gt; - Stop, remove, and rerun with the same &lt;code&gt;-v $(pwd)/data:/data&lt;/code&gt; mount; your DB and config stay intact.&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;hr /&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;🚑 Smoke-test the running container&lt;/strong&gt;&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;curl -s -H "Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN" \
     http://localhost:4444/health | jq
curl -s -H "Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN" \
     http://localhost:4444/tools | jq
curl -s -H "Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN" \
     http://localhost:4444/version | jq
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;hr /&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;🖧 Running the MCP Gateway stdio wrapper&lt;/strong&gt;&lt;/summary&gt; 
 &lt;p&gt;The &lt;code&gt;mcpgateway.wrapper&lt;/code&gt; lets you connect to the gateway over &lt;strong&gt;stdio&lt;/strong&gt; while keeping JWT authentication. You should run this from the MCP Client. The example below is just for testing.&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# Set environment variables
export MCPGATEWAY_BEARER_TOKEN=$(python3 -m mcpgateway.utils.create_jwt_token --username admin --exp 10080 --secret my-test-key)
export MCP_AUTH=${MCPGATEWAY_BEARER_TOKEN}
export MCP_SERVER_URL='http://localhost:4444/servers/UUID_OF_SERVER_1/mcp'
export MCP_TOOL_CALL_TIMEOUT=120
export MCP_WRAPPER_LOG_LEVEL=DEBUG  # or OFF to disable logging

docker run --rm -i \
  -e MCP_AUTH=$MCPGATEWAY_BEARER_TOKEN \
  -e MCP_SERVER_URL=http://host.docker.internal:4444/servers/UUID_OF_SERVER_1/mcp \
  -e MCP_TOOL_CALL_TIMEOUT=120 \
  -e MCP_WRAPPER_LOG_LEVEL=DEBUG \
  ghcr.io/ibm/mcp-context-forge:0.6.0 \
  python3 -m mcpgateway.wrapper
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Testing &lt;code&gt;mcpgateway.wrapper&lt;/code&gt; by hand:&lt;/h2&gt; 
&lt;p&gt;Because the wrapper speaks JSON-RPC over stdin/stdout, you can interact with it using nothing more than a terminal or pipes.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Start the MCP Gateway Wrapper
export MCP_AUTH=${MCPGATEWAY_BEARER_TOKEN}
export MCP_SERVER_URL=http://localhost:4444/servers/YOUR_SERVER_UUID
python3 -m mcpgateway.wrapper
&lt;/code&gt;&lt;/pre&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;Initialize the protocol&lt;/strong&gt;&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-json"&gt;# Initialize the protocol
{"jsonrpc":"2.0","id":1,"method":"initialize","params":{"protocolVersion":"2025-03-26","capabilities":{},"clientInfo":{"name":"demo","version":"0.0.1"}}}

# Then after the reply:
{"jsonrpc":"2.0","method":"notifications/initialized","params":{}}

# Get prompts
{"jsonrpc":"2.0","id":4,"method":"prompts/list"}
{"jsonrpc":"2.0","id":5,"method":"prompts/get","params":{"name":"greeting","arguments":{"user":"Bob"}}}

# Get resources
{"jsonrpc":"2.0","id":6,"method":"resources/list"}
{"jsonrpc":"2.0","id":7,"method":"resources/read","params":{"uri":"https://example.com/some.txt"}}

# Get / call tools
{"jsonrpc":"2.0","id":2,"method":"tools/list"}
{"jsonrpc":"2.0","id":3,"method":"tools/call","params":{"name":"get_system_time","arguments":{"timezone":"Europe/Dublin"}}}
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;Expected responses from mcpgateway.wrapper&lt;/strong&gt;&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-json"&gt;{"jsonrpc":"2.0","id":1,"result":{"protocolVersion":"2025-03-26","capabilities":{"experimental":{},"prompts":{"listChanged":false},"resources":{"subscribe":false,"listChanged":false},"tools":{"listChanged":false}},"serverInfo":{"name":"mcpgateway-wrapper","version":"0.6.0"}}}

# When there's no tools
{"jsonrpc":"2.0","id":2,"result":{"tools":[]}}

# After you add some tools and create a virtual server
{"jsonrpc":"2.0","id":2,"result":{"tools":[{"annotations":{"readOnlyHint":false,"destructiveHint":true,"idempotentHint":false,"openWorldHint":true},"description":"Convert time between different timezones","inputSchema":{"properties":{"source_timezone":{"description":"Source IANA timezone name","type":"string"},"target_timezone":{"description":"Target IANA timezone name","type":"string"},"time":{"description":"Time to convert in RFC3339 format or common formats like '2006-01-02 15:04:05'","type":"string"}},"required":["time","source_timezone","target_timezone"],"type":"object"},"name":"convert_time"},{"annotations":{"readOnlyHint":false,"destructiveHint":true,"idempotentHint":false,"openWorldHint":true},"description":"Get current system time in specified timezone","inputSchema":{"properties":{"timezone":{"description":"IANA timezone name (e.g., 'America/New_York', 'Europe/London'). Defaults to UTC","type":"string"}},"type":"object"},"name":"get_system_time"}]}}

# Running the time tool:
{"jsonrpc":"2.0","id":3,"result":{"content":[{"type":"text","text":"2025-07-09T00:09:45+01:00"}]}}
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h3&gt;🧩 Running from an MCP Client (&lt;code&gt;mcpgateway.wrapper&lt;/code&gt;)&lt;/h3&gt; 
&lt;p&gt;The &lt;code&gt;mcpgateway.wrapper&lt;/code&gt; exposes everything your Gateway knows about over &lt;strong&gt;stdio&lt;/strong&gt;, so any MCP client that &lt;em&gt;can't&lt;/em&gt; (or &lt;em&gt;shouldn't&lt;/em&gt;) open an authenticated SSE stream still gets full tool-calling power.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Remember&lt;/strong&gt; to substitute your real Gateway URL (and server ID) for &lt;code&gt;http://localhost:4444/servers/UUID_OF_SERVER_1/mcp&lt;/code&gt;. When inside Docker/Podman, that often becomes &lt;code&gt;http://host.docker.internal:4444/servers/UUID_OF_SERVER_1/mcp&lt;/code&gt; (macOS/Windows) or the gateway container's hostname (Linux).&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;hr /&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;🐳 Docker / Podman&lt;/strong&gt;&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;docker run -i --rm \
  --network=host \
  -e MCP_SERVER_URL=http://localhost:4444/servers/UUID_OF_SERVER_1/mcp \
  -e MCP_AUTH=${MCPGATEWAY_BEARER_TOKEN} \
  -e MCP_TOOL_CALL_TIMEOUT=120 \
  ghcr.io/ibm/mcp-context-forge:0.6.0 \
  python3 -m mcpgateway.wrapper
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;hr /&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;📦 pipx (one-liner install &amp;amp; run)&lt;/strong&gt;&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# Install gateway package in its own isolated venv
pipx install --include-deps mcp-contextforge-gateway

# Run the stdio wrapper
MCP_AUTH=${MCPGATEWAY_BEARER_TOKEN} \
MCP_SERVER_URL=http://localhost:4444/servers/UUID_OF_SERVER_1/mcp \
python3 -m mcpgateway.wrapper
# Alternatively with uv
uv run --directory . -m mcpgateway.wrapper
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;Claude Desktop JSON&lt;/strong&gt; (uses the host Python that pipx injected):&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-json"&gt;{
  "mcpServers": {
    "mcpgateway-wrapper": {
      "command": "python3",
      "args": ["-m", "mcpgateway.wrapper"],
      "env": {
        "MCP_AUTH": "&amp;lt;your-token&amp;gt;",
        "MCP_SERVER_URL": "http://localhost:4444/servers/UUID_OF_SERVER_1/mcp",
        "MCP_TOOL_CALL_TIMEOUT": "120"
      }
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;hr /&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;⚡ uv / uvx (light-speed venvs)&lt;/strong&gt;&lt;/summary&gt; 
 &lt;h4&gt;1 - Install &lt;code&gt;uv&lt;/code&gt; (&lt;code&gt;uvx&lt;/code&gt; is an alias it provides)&lt;/h4&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# (a) official one-liner
curl -Ls https://astral.sh/uv/install.sh | sh

# (b) or via pipx
pipx install uv
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h4&gt;2 - Create an on-the-spot venv &amp;amp; run the wrapper&lt;/h4&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# Create venv in ~/.venv/mcpgateway (or current dir if you prefer)
uv venv ~/.venv/mcpgateway
source ~/.venv/mcpgateway/bin/activate

# Install the gateway package using uv
uv pip install mcp-contextforge-gateway

# Launch wrapper
MCP_AUTH=${MCPGATEWAY_BEARER_TOKEN} \
MCP_SERVER_URL=http://localhost:4444/servers/UUID_OF_SERVER_1/mcp \
uv run --directory . -m mcpgateway.wrapper # Use this just for testing, as the Client will run the uv command
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h4&gt;Claude Desktop JSON (runs through &lt;strong&gt;uvx&lt;/strong&gt;)&lt;/h4&gt; 
 &lt;pre&gt;&lt;code class="language-json"&gt;{
  "mcpServers": {
    "mcpgateway-wrapper": {
      "command": "uvx",
      "args": [
        "run",
        "--",
        "python",
        "-m",
        "mcpgateway.wrapper"
      ],
      "env": {
        "MCP_AUTH": "&amp;lt;your-token&amp;gt;",
        "MCP_SERVER_URL": "http://localhost:4444/servers/UUID_OF_SERVER_1/mcp"
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;hr /&gt; 
&lt;h3&gt;🚀 Using with Claude Desktop (or any GUI MCP client)&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Edit Config&lt;/strong&gt; → &lt;code&gt;File ▸ Settings ▸ Developer ▸ Edit Config&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Paste one of the JSON blocks above (Docker / pipx / uvx).&lt;/li&gt; 
 &lt;li&gt;Restart the app so the new stdio server is spawned.&lt;/li&gt; 
 &lt;li&gt;Open logs in the same menu to verify &lt;code&gt;mcpgateway-wrapper&lt;/code&gt; started and listed your tools.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Need help? See:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;MCP Debugging Guide&lt;/strong&gt; - &lt;a href="https://modelcontextprotocol.io/docs/tools/debugging"&gt;https://modelcontextprotocol.io/docs/tools/debugging&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;🚀 Quick Start: VS Code Dev Container&lt;/h2&gt; 
&lt;p&gt;Spin up a fully-loaded dev environment (Python 3.11, Docker/Podman CLI, all project dependencies) in just two clicks.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;📋 Prerequisites&lt;/strong&gt;&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;VS Code&lt;/strong&gt; with the &lt;a href="https://code.visualstudio.com/docs/devcontainers/containers"&gt;Dev Containers extension&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Docker&lt;/strong&gt; or &lt;strong&gt;Podman&lt;/strong&gt; installed and running locally&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;🧰 Setup Instructions&lt;/strong&gt;&lt;/summary&gt; 
 &lt;h3&gt;1 - Clone &amp;amp; Open&lt;/h3&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/ibm/mcp-context-forge.git
cd mcp-context-forge
code .
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;VS Code will detect the &lt;code&gt;.devcontainer&lt;/code&gt; and prompt: &lt;strong&gt;"Reopen in Container"&lt;/strong&gt; &lt;em&gt;or&lt;/em&gt; manually run: &lt;kbd&gt;Ctrl/Cmd ⇧ P&lt;/kbd&gt; → &lt;strong&gt;Dev Containers: Reopen in Container&lt;/strong&gt;&lt;/p&gt; 
 &lt;hr /&gt; 
 &lt;h3&gt;2 - First-Time Build (Automatic)&lt;/h3&gt; 
 &lt;p&gt;The container build will:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Install system packages &amp;amp; Python 3.11&lt;/li&gt; 
  &lt;li&gt;Run &lt;code&gt;make install-dev&lt;/code&gt; to pull all dependencies&lt;/li&gt; 
  &lt;li&gt;Execute tests to verify the toolchain&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;You'll land in &lt;code&gt;/workspace&lt;/code&gt; ready to develop.&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;🛠️ Daily Developer Workflow&lt;/strong&gt;&lt;/summary&gt; 
 &lt;p&gt;Common tasks inside the container:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# Start dev server (hot reload)
make dev            # http://localhost:4444

# Run tests &amp;amp; linters
make test
make lint
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Optional:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;code&gt;make bash&lt;/code&gt; - drop into an interactive shell&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;make clean&lt;/code&gt; - clear build artefacts &amp;amp; caches&lt;/li&gt; 
  &lt;li&gt;Port forwarding is automatic (customize via &lt;code&gt;.devcontainer/devcontainer.json&lt;/code&gt;)&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;☁️ GitHub Codespaces: 1-Click Cloud IDE&lt;/strong&gt;&lt;/summary&gt; 
 &lt;p&gt;No local Docker? Use Codespaces:&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;Go to the repo → &lt;strong&gt;Code ▸ Codespaces ▸ Create codespace on main&lt;/strong&gt;&lt;/li&gt; 
  &lt;li&gt;Wait for the container image to build in the cloud&lt;/li&gt; 
  &lt;li&gt;Develop using the same workflow above&lt;/li&gt; 
 &lt;/ol&gt; 
&lt;/details&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Quick Start (manual install)&lt;/h2&gt; 
&lt;h3&gt;Prerequisites&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Python ≥ 3.10&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;GNU Make&lt;/strong&gt; (optional, but all common workflows are available as Make targets)&lt;/li&gt; 
 &lt;li&gt;Optional: &lt;strong&gt;Docker / Podman&lt;/strong&gt; for containerized runs&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;One-liner (dev)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;make venv install serve
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;What it does:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Creates / activates a &lt;code&gt;.venv&lt;/code&gt; in your home folder &lt;code&gt;~/.venv/mcpgateway&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Installs the gateway and necessary dependencies&lt;/li&gt; 
 &lt;li&gt;Launches &lt;strong&gt;Gunicorn&lt;/strong&gt; (Uvicorn workers) on &lt;a href="http://localhost:4444"&gt;http://localhost:4444&lt;/a&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;For development, you can use:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;make install-dev # Install development dependencies, ex: linters and test harness
make lint          # optional: run style checks (ruff, mypy, etc.)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Containerized (self-signed TLS)&lt;/h3&gt; 
&lt;h2&gt;Container Runtime Support&lt;/h2&gt; 
&lt;p&gt;This project supports both Docker and Podman. The Makefile automatically detects which runtime is available and handles image naming differences.&lt;/p&gt; 
&lt;h3&gt;Auto-detection&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;make container-build  # Uses podman if available, otherwise docker

&amp;gt; You can use docker or podman, ex:

```bash
make podman            # build production image
make podman-run-ssl    # run at https://localhost:4444
# or listen on port 4444 on your host directly, adds --network=host to podman
make podman-run-ssl-host
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Smoke-test the API&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -k -sX GET \
     -H "Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN" \
     https://localhost:4444/tools | jq
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You should receive &lt;code&gt;[]&lt;/code&gt; until you register a tool.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;h3&gt;Via Make&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;make venv install          # create .venv + install deps
make serve                 # gunicorn on :4444
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;UV (alternative)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uv venv &amp;amp;&amp;amp; source .venv/bin/activate
uv pip install -e '.[dev]' # IMPORTANT: in zsh, quote to disable glob expansion!
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;pip (alternative)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python3 -m venv .venv &amp;amp;&amp;amp; source .venv/bin/activate
pip install -e ".[dev]"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Optional (PostgreSQL adapter)&lt;/h3&gt; 
&lt;p&gt;You can configure the gateway with SQLite, PostgreSQL (or any other compatible database) in .env.&lt;/p&gt; 
&lt;p&gt;When using PostgreSQL, you need to install &lt;code&gt;psycopg2&lt;/code&gt; driver.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uv pip install psycopg2-binary   # dev convenience
# or
uv pip install psycopg2          # production build
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Quick Postgres container&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run --name mcp-postgres \
  -e POSTGRES_USER=postgres \
  -e POSTGRES_PASSWORD=mysecretpassword \
  -e POSTGRES_DB=mcp \
  -p 5432:5432 -d postgres
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;A &lt;code&gt;make compose-up&lt;/code&gt; target is provided along with a &lt;a href="https://raw.githubusercontent.com/IBM/mcp-context-forge/main/docker-compose.yml"&gt;docker-compose.yml&lt;/a&gt; file to make this process simpler.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Configuration (&lt;code&gt;.env&lt;/code&gt; or env vars)&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;⚠️ If any required &lt;code&gt;.env&lt;/code&gt; variable is missing or invalid, the gateway will fail fast at startup with a validation error via Pydantic.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;You can get started by copying the provided &lt;a href="https://raw.githubusercontent.com/IBM/mcp-context-forge/main/.env.example"&gt;.env.example&lt;/a&gt; to &lt;code&gt;.env&lt;/code&gt; and making the necessary edits to fit your environment.&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;🔧 Environment Configuration Variables&lt;/strong&gt;&lt;/summary&gt; 
 &lt;h3&gt;Basic&lt;/h3&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;Setting&lt;/th&gt; 
    &lt;th&gt;Description&lt;/th&gt; 
    &lt;th&gt;Default&lt;/th&gt; 
    &lt;th&gt;Options&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;APP_NAME&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Gateway / OpenAPI title&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;MCP Gateway&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;string&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;HOST&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Bind address for the app&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;127.0.0.1&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;IPv4/IPv6&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;PORT&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Port the server listens on&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;4444&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;1-65535&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;DATABASE_URL&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;SQLAlchemy connection URL&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;sqlite:///./mcp.db&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;any SQLAlchemy dialect&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;APP_ROOT_PATH&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Subpath prefix for app (e.g. &lt;code&gt;/gateway&lt;/code&gt;)&lt;/td&gt; 
    &lt;td&gt;(empty)&lt;/td&gt; 
    &lt;td&gt;string&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;TEMPLATES_DIR&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Path to Jinja2 templates&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;mcpgateway/templates&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;path&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;STATIC_DIR&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Path to static files&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;mcpgateway/static&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;path&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;💡 Use &lt;code&gt;APP_ROOT_PATH=/foo&lt;/code&gt; if reverse-proxying under a subpath like &lt;code&gt;https://host.com/foo/&lt;/code&gt;.&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;h3&gt;Authentication&lt;/h3&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;Setting&lt;/th&gt; 
    &lt;th&gt;Description&lt;/th&gt; 
    &lt;th&gt;Default&lt;/th&gt; 
    &lt;th&gt;Options&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;BASIC_AUTH_USER&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Username for Admin UI login and HTTP Basic authentication&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;admin&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;string&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;BASIC_AUTH_PASSWORD&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Password for Admin UI login and HTTP Basic authentication&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;changeme&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;string&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;AUTH_REQUIRED&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Require authentication for all API routes&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;true&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;bool&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;JWT_SECRET_KEY&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Secret key used to &lt;strong&gt;sign JWT tokens&lt;/strong&gt; for API access&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;my-test-key&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;string&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;JWT_ALGORITHM&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Algorithm used to sign the JWTs (&lt;code&gt;HS256&lt;/code&gt; is default, HMAC-based)&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;HS256&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;PyJWT algs&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;TOKEN_EXPIRY&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Expiry of generated JWTs in minutes&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;10080&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;int &amp;gt; 0&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;AUTH_ENCRYPTION_SECRET&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Passphrase used to derive AES key for encrypting tool auth headers&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;my-test-salt&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;string&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;🔐 &lt;code&gt;BASIC_AUTH_USER&lt;/code&gt;/&lt;code&gt;PASSWORD&lt;/code&gt; are used for:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Logging into the web-based Admin UI&lt;/li&gt; 
   &lt;li&gt;Accessing APIs via Basic Auth (&lt;code&gt;curl -H "Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN"&lt;/code&gt;)&lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;p&gt;🔑 &lt;code&gt;JWT_SECRET_KEY&lt;/code&gt; is used to:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;Sign JSON Web Tokens (&lt;code&gt;Authorization: Bearer &amp;lt;token&amp;gt;&lt;/code&gt;)&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;Generate tokens via:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;export MCPGATEWAY_BEARER_TOKEN=$(python3 -m mcpgateway.utils.create_jwt_token --username admin --exp 0 --secret my-test-key)
echo $MCPGATEWAY_BEARER_TOKEN
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;Tokens allow non-interactive API clients to authenticate securely.&lt;/p&gt; &lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;p&gt;🧪 Set &lt;code&gt;AUTH_REQUIRED=false&lt;/code&gt; during development if you want to disable all authentication (e.g. for local testing or open APIs) or clients that don't support SSE authentication. In production, you should use the SSE to stdio &lt;code&gt;mcpgateway-wrapper&lt;/code&gt; for such tools that don't support authenticated SSE, while still ensuring the gateway uses authentication.&lt;/p&gt; 
  &lt;p&gt;🔐 &lt;code&gt;AUTH_ENCRYPTION_SECRET&lt;/code&gt; is used to encrypt and decrypt tool authentication credentials (&lt;code&gt;auth_value&lt;/code&gt;). You must set the same value across environments to decode previously stored encrypted auth values. Recommended: use a long, random string.&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;h3&gt;UI Features&lt;/h3&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;Setting&lt;/th&gt; 
    &lt;th&gt;Description&lt;/th&gt; 
    &lt;th&gt;Default&lt;/th&gt; 
    &lt;th&gt;Options&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;MCPGATEWAY_UI_ENABLED&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Enable the interactive Admin dashboard&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;false&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;bool&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;MCPGATEWAY_ADMIN_API_ENABLED&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Enable API endpoints for admin ops&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;false&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;bool&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;MCPGATEWAY_BULK_IMPORT_ENABLED&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Enable bulk import endpoint for tools&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;true&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;bool&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;🖥️ Set both UI and Admin API to &lt;code&gt;false&lt;/code&gt; to disable management UI and APIs in production. 📥 The bulk import endpoint allows importing up to 200 tools in a single request via &lt;code&gt;/admin/tools/import&lt;/code&gt;.&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;h3&gt;A2A (Agent-to-Agent) Features&lt;/h3&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;Setting&lt;/th&gt; 
    &lt;th&gt;Description&lt;/th&gt; 
    &lt;th&gt;Default&lt;/th&gt; 
    &lt;th&gt;Options&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;MCPGATEWAY_A2A_ENABLED&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Enable A2A agent features&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;true&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;bool&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;MCPGATEWAY_A2A_MAX_AGENTS&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Maximum number of A2A agents allowed&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;100&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;int&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;MCPGATEWAY_A2A_DEFAULT_TIMEOUT&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Default timeout for A2A HTTP requests (seconds)&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;30&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;int&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;MCPGATEWAY_A2A_MAX_RETRIES&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Maximum retry attempts for A2A calls&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;3&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;int&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;MCPGATEWAY_A2A_METRICS_ENABLED&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Enable A2A agent metrics collection&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;true&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;bool&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;🤖 &lt;strong&gt;A2A Integration&lt;/strong&gt;: Register external AI agents (OpenAI, Anthropic, custom) and expose them as MCP tools 📊 &lt;strong&gt;Metrics&lt;/strong&gt;: Track agent performance, success rates, and response times 🔒 &lt;strong&gt;Security&lt;/strong&gt;: Encrypted credential storage and configurable authentication 🎛️ &lt;strong&gt;Admin UI&lt;/strong&gt;: Dedicated tab for agent management with test functionality&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;A2A Configuration Effects:&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;code&gt;MCPGATEWAY_A2A_ENABLED=false&lt;/code&gt;: Completely disables A2A features (API endpoints return 404, admin tab hidden)&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;MCPGATEWAY_A2A_METRICS_ENABLED=false&lt;/code&gt;: Disables metrics collection while keeping functionality&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Security&lt;/h3&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;Setting&lt;/th&gt; 
    &lt;th&gt;Description&lt;/th&gt; 
    &lt;th&gt;Default&lt;/th&gt; 
    &lt;th&gt;Options&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;SKIP_SSL_VERIFY&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Skip upstream TLS verification&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;false&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;bool&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;ENVIRONMENT&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Deployment environment (affects security defaults)&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;development&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;development&lt;/code&gt;/&lt;code&gt;production&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;APP_DOMAIN&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Domain for production CORS origins&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;localhost&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;string&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;ALLOWED_ORIGINS&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;CORS allow-list&lt;/td&gt; 
    &lt;td&gt;Auto-configured by environment&lt;/td&gt; 
    &lt;td&gt;JSON array&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;CORS_ENABLED&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Enable CORS&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;true&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;bool&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;CORS_ALLOW_CREDENTIALS&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Allow credentials in CORS&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;true&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;bool&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;SECURE_COOKIES&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Force secure cookie flags&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;true&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;bool&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;COOKIE_SAMESITE&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Cookie SameSite attribute&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;lax&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;strict&lt;/code&gt;/&lt;code&gt;lax&lt;/code&gt;/&lt;code&gt;none&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;SECURITY_HEADERS_ENABLED&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Enable security headers middleware&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;true&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;bool&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;X_FRAME_OPTIONS&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;X-Frame-Options header value&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;DENY&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;DENY&lt;/code&gt;/&lt;code&gt;SAMEORIGIN&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;HSTS_ENABLED&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Enable HSTS header&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;true&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;bool&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;HSTS_MAX_AGE&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;HSTS max age in seconds&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;31536000&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;int&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;REMOVE_SERVER_HEADERS&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Remove server identification&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;true&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;bool&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;DOCS_ALLOW_BASIC_AUTH&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Allow Basic Auth for docs (in addition to JWT)&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;false&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;bool&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;&lt;strong&gt;CORS Configuration&lt;/strong&gt;: When &lt;code&gt;ENVIRONMENT=development&lt;/code&gt;, CORS origins are automatically configured for common development ports (3000, 8080, gateway port). In production, origins are constructed from &lt;code&gt;APP_DOMAIN&lt;/code&gt; (e.g., &lt;code&gt;https://yourdomain.com&lt;/code&gt;, &lt;code&gt;https://app.yourdomain.com&lt;/code&gt;). You can override this by explicitly setting &lt;code&gt;ALLOWED_ORIGINS&lt;/code&gt;.&lt;/p&gt; 
  &lt;p&gt;&lt;strong&gt;Security Headers&lt;/strong&gt;: The gateway automatically adds configurable security headers to all responses including CSP, X-Frame-Options, X-Content-Type-Options, X-Download-Options, and HSTS (on HTTPS). All headers can be individually enabled/disabled. Sensitive server headers are removed.&lt;/p&gt; 
  &lt;p&gt;&lt;strong&gt;iframe Embedding&lt;/strong&gt;: By default, &lt;code&gt;X-Frame-Options: DENY&lt;/code&gt; prevents iframe embedding for security. To allow embedding, set &lt;code&gt;X_FRAME_OPTIONS=SAMEORIGIN&lt;/code&gt; (same domain) or disable with &lt;code&gt;X_FRAME_OPTIONS=""&lt;/code&gt;. Also update CSP &lt;code&gt;frame-ancestors&lt;/code&gt; directive if needed.&lt;/p&gt; 
  &lt;p&gt;&lt;strong&gt;Cookie Security&lt;/strong&gt;: Authentication cookies are automatically configured with HttpOnly, Secure (in production), and SameSite attributes for CSRF protection.&lt;/p&gt; 
  &lt;p&gt;Note: do not quote the ALLOWED_ORIGINS values, this needs to be valid JSON, such as: ALLOWED_ORIGINS=["http://localhost", "http://localhost:4444"]&lt;/p&gt; 
  &lt;p&gt;Documentation endpoints (&lt;code&gt;/docs&lt;/code&gt;, &lt;code&gt;/redoc&lt;/code&gt;, &lt;code&gt;/openapi.json&lt;/code&gt;) are always protected by authentication. By default, they require Bearer token authentication. Setting &lt;code&gt;DOCS_ALLOW_BASIC_AUTH=true&lt;/code&gt; enables HTTP Basic Authentication as an additional method using the same credentials as &lt;code&gt;BASIC_AUTH_USER&lt;/code&gt; and &lt;code&gt;BASIC_AUTH_PASSWORD&lt;/code&gt;.&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;h3&gt;Logging&lt;/h3&gt; 
 &lt;p&gt;MCP Gateway provides flexible logging with &lt;strong&gt;stdout/stderr output by default&lt;/strong&gt; and &lt;strong&gt;optional file-based logging&lt;/strong&gt;. When file logging is enabled, it provides JSON formatting for structured logs and text formatting for console output.&lt;/p&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;Setting&lt;/th&gt; 
    &lt;th&gt;Description&lt;/th&gt; 
    &lt;th&gt;Default&lt;/th&gt; 
    &lt;th&gt;Options&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;LOG_LEVEL&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Minimum log level&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;INFO&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;DEBUG&lt;/code&gt;...&lt;code&gt;CRITICAL&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;LOG_FORMAT&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Console log format&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;json&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;json&lt;/code&gt;, &lt;code&gt;text&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;LOG_TO_FILE&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;strong&gt;Enable file logging&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;strong&gt;&lt;code&gt;false&lt;/code&gt;&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;strong&gt;&lt;code&gt;true&lt;/code&gt;, &lt;code&gt;false&lt;/code&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;LOG_FILE&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Log filename (when enabled)&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;null&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;mcpgateway.log&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;LOG_FOLDER&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Directory for log files&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;null&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;logs&lt;/code&gt;, &lt;code&gt;/var/log/gateway&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;LOG_FILEMODE&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;File write mode&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;a+&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;a+&lt;/code&gt; (append), &lt;code&gt;w&lt;/code&gt; (overwrite)&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;LOG_ROTATION_ENABLED&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;strong&gt;Enable log file rotation&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;strong&gt;&lt;code&gt;false&lt;/code&gt;&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;strong&gt;&lt;code&gt;true&lt;/code&gt;, &lt;code&gt;false&lt;/code&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;LOG_MAX_SIZE_MB&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Max file size before rotation (MB)&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;1&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Any positive integer&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;LOG_BACKUP_COUNT&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Number of backup files to keep&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;5&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Any non-negative integer&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
 &lt;p&gt;&lt;strong&gt;Logging Behavior:&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;Default&lt;/strong&gt;: Logs only to &lt;strong&gt;stdout/stderr&lt;/strong&gt; with human-readable text format&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;File Logging&lt;/strong&gt;: When &lt;code&gt;LOG_TO_FILE=true&lt;/code&gt;, logs to &lt;strong&gt;both&lt;/strong&gt; file (JSON format) and console (text format)&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Log Rotation&lt;/strong&gt;: When &lt;code&gt;LOG_ROTATION_ENABLED=true&lt;/code&gt;, files rotate at &lt;code&gt;LOG_MAX_SIZE_MB&lt;/code&gt; with &lt;code&gt;LOG_BACKUP_COUNT&lt;/code&gt; backup files (e.g., &lt;code&gt;.log.1&lt;/code&gt;, &lt;code&gt;.log.2&lt;/code&gt;)&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Directory Creation&lt;/strong&gt;: Log folder is automatically created if it doesn't exist&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Centralized Service&lt;/strong&gt;: All modules use the unified &lt;code&gt;LoggingService&lt;/code&gt; for consistent formatting&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;Example Configurations:&lt;/strong&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# Default: stdout/stderr only (recommended for containers)
LOG_LEVEL=INFO
# No additional config needed - logs to stdout/stderr

# Optional: Enable file logging (no rotation)
LOG_TO_FILE=true
LOG_FOLDER=/var/log/mcpgateway
LOG_FILE=gateway.log
LOG_FILEMODE=a+

# Optional: Enable file logging with rotation
LOG_TO_FILE=true
LOG_ROTATION_ENABLED=true
LOG_MAX_SIZE_MB=10
LOG_BACKUP_COUNT=3
LOG_FOLDER=/var/log/mcpgateway
LOG_FILE=gateway.log
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;Default Behavior:&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Logs are written &lt;strong&gt;only to stdout/stderr&lt;/strong&gt; in human-readable text format&lt;/li&gt; 
  &lt;li&gt;File logging is &lt;strong&gt;disabled by default&lt;/strong&gt; (no files created)&lt;/li&gt; 
  &lt;li&gt;Set &lt;code&gt;LOG_TO_FILE=true&lt;/code&gt; to enable optional file logging with JSON format&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Observability (OpenTelemetry)&lt;/h3&gt; 
 &lt;p&gt;MCP Gateway includes &lt;strong&gt;vendor-agnostic OpenTelemetry support&lt;/strong&gt; for distributed tracing. Works with Phoenix, Jaeger, Zipkin, Tempo, DataDog, New Relic, and any OTLP-compatible backend.&lt;/p&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;Setting&lt;/th&gt; 
    &lt;th&gt;Description&lt;/th&gt; 
    &lt;th&gt;Default&lt;/th&gt; 
    &lt;th&gt;Options&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;OTEL_ENABLE_OBSERVABILITY&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Master switch for observability&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;true&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;true&lt;/code&gt;, &lt;code&gt;false&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;OTEL_SERVICE_NAME&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Service identifier in traces&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;mcp-gateway&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;string&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;OTEL_SERVICE_VERSION&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Service version in traces&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;0.6.0&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;string&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;OTEL_DEPLOYMENT_ENVIRONMENT&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Environment tag (dev/staging/prod)&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;development&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;string&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;OTEL_TRACES_EXPORTER&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Trace exporter backend&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;otlp&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;otlp&lt;/code&gt;, &lt;code&gt;jaeger&lt;/code&gt;, &lt;code&gt;zipkin&lt;/code&gt;, &lt;code&gt;console&lt;/code&gt;, &lt;code&gt;none&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;OTEL_RESOURCE_ATTRIBUTES&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Custom resource attributes&lt;/td&gt; 
    &lt;td&gt;(empty)&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;key=value,key2=value2&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
 &lt;p&gt;&lt;strong&gt;OTLP Configuration&lt;/strong&gt; (for Phoenix, Tempo, DataDog, etc.):&lt;/p&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;Setting&lt;/th&gt; 
    &lt;th&gt;Description&lt;/th&gt; 
    &lt;th&gt;Default&lt;/th&gt; 
    &lt;th&gt;Options&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;OTEL_EXPORTER_OTLP_ENDPOINT&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;OTLP collector endpoint&lt;/td&gt; 
    &lt;td&gt;(none)&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;http://localhost:4317&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;OTEL_EXPORTER_OTLP_PROTOCOL&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;OTLP protocol&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;grpc&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;grpc&lt;/code&gt;, &lt;code&gt;http/protobuf&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;OTEL_EXPORTER_OTLP_HEADERS&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Authentication headers&lt;/td&gt; 
    &lt;td&gt;(empty)&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;api-key=secret,x-auth=token&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;OTEL_EXPORTER_OTLP_INSECURE&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Skip TLS verification&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;true&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;true&lt;/code&gt;, &lt;code&gt;false&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
 &lt;p&gt;&lt;strong&gt;Alternative Backends&lt;/strong&gt; (optional):&lt;/p&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;Setting&lt;/th&gt; 
    &lt;th&gt;Description&lt;/th&gt; 
    &lt;th&gt;Default&lt;/th&gt; 
    &lt;th&gt;Options&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;OTEL_EXPORTER_JAEGER_ENDPOINT&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Jaeger collector endpoint&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;http://localhost:14268/api/traces&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;URL&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;OTEL_EXPORTER_ZIPKIN_ENDPOINT&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Zipkin collector endpoint&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;http://localhost:9411/api/v2/spans&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;URL&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
 &lt;p&gt;&lt;strong&gt;Performance Tuning&lt;/strong&gt;:&lt;/p&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;Setting&lt;/th&gt; 
    &lt;th&gt;Description&lt;/th&gt; 
    &lt;th&gt;Default&lt;/th&gt; 
    &lt;th&gt;Options&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;OTEL_TRACES_SAMPLER&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Sampling strategy&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;parentbased_traceidratio&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;always_on&lt;/code&gt;, &lt;code&gt;always_off&lt;/code&gt;, &lt;code&gt;traceidratio&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;OTEL_TRACES_SAMPLER_ARG&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Sample rate (0.0-1.0)&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;0.1&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;float (0.1 = 10% sampling)&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;OTEL_BSP_MAX_QUEUE_SIZE&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Max queued spans&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;2048&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;int &amp;gt; 0&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;OTEL_BSP_MAX_EXPORT_BATCH_SIZE&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Max batch size for export&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;512&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;int &amp;gt; 0&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;OTEL_BSP_SCHEDULE_DELAY&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Export interval (ms)&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;5000&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;int &amp;gt; 0&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
 &lt;p&gt;&lt;strong&gt;Quick Start with Phoenix&lt;/strong&gt;:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# Start Phoenix for LLM observability
docker run -p 6006:6006 -p 4317:4317 arizephoenix/phoenix:latest

# Configure gateway
export OTEL_ENABLE_OBSERVABILITY=true
export OTEL_TRACES_EXPORTER=otlp
export OTEL_EXPORTER_OTLP_ENDPOINT=http://localhost:4317

# Run gateway - traces automatically sent to Phoenix
mcpgateway
&lt;/code&gt;&lt;/pre&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;🔍 &lt;strong&gt;What Gets Traced&lt;/strong&gt;: Tool invocations, prompt rendering, resource fetching, gateway federation, health checks, plugin execution (if enabled)&lt;/p&gt; 
  &lt;p&gt;🚀 &lt;strong&gt;Zero Overhead&lt;/strong&gt;: When &lt;code&gt;OTEL_ENABLE_OBSERVABILITY=false&lt;/code&gt;, all tracing is disabled with no performance impact&lt;/p&gt; 
  &lt;p&gt;📊 &lt;strong&gt;View Traces&lt;/strong&gt;: Phoenix UI at &lt;code&gt;http://localhost:6006&lt;/code&gt;, Jaeger at &lt;code&gt;http://localhost:16686&lt;/code&gt;, or your configured backend&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;h3&gt;Transport&lt;/h3&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;Setting&lt;/th&gt; 
    &lt;th&gt;Description&lt;/th&gt; 
    &lt;th&gt;Default&lt;/th&gt; 
    &lt;th&gt;Options&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;TRANSPORT_TYPE&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Enabled transports&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;all&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;http&lt;/code&gt;,&lt;code&gt;ws&lt;/code&gt;,&lt;code&gt;sse&lt;/code&gt;,&lt;code&gt;stdio&lt;/code&gt;,&lt;code&gt;all&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;WEBSOCKET_PING_INTERVAL&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;WebSocket ping (secs)&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;30&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;int &amp;gt; 0&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;SSE_RETRY_TIMEOUT&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;SSE retry timeout (ms)&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;5000&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;int &amp;gt; 0&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;SSE_KEEPALIVE_ENABLED&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Enable SSE keepalive events&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;true&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;bool&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;SSE_KEEPALIVE_INTERVAL&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;SSE keepalive interval (secs)&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;30&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;int &amp;gt; 0&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;USE_STATEFUL_SESSIONS&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;streamable http config&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;false&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;bool&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;JSON_RESPONSE_ENABLED&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;json/sse streams (streamable http)&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;true&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;bool&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;&lt;strong&gt;💡 SSE Keepalive Events&lt;/strong&gt;: The gateway sends periodic keepalive events to prevent connection timeouts with proxies and load balancers. Disable with &lt;code&gt;SSE_KEEPALIVE_ENABLED=false&lt;/code&gt; if your client doesn't handle unknown event types. Common intervals: 30s (default), 60s (AWS ALB), 240s (Azure).&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;h3&gt;Federation&lt;/h3&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;Setting&lt;/th&gt; 
    &lt;th&gt;Description&lt;/th&gt; 
    &lt;th&gt;Default&lt;/th&gt; 
    &lt;th&gt;Options&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;FEDERATION_ENABLED&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Enable federation&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;true&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;bool&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;FEDERATION_DISCOVERY&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Auto-discover peers&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;false&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;bool&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;FEDERATION_PEERS&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Comma-sep peer URLs&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;[]&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;JSON array&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;FEDERATION_TIMEOUT&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Gateway timeout (secs)&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;30&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;int &amp;gt; 0&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;FEDERATION_SYNC_INTERVAL&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Sync interval (secs)&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;300&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;int &amp;gt; 0&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
 &lt;h3&gt;Resources&lt;/h3&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;Setting&lt;/th&gt; 
    &lt;th&gt;Description&lt;/th&gt; 
    &lt;th&gt;Default&lt;/th&gt; 
    &lt;th&gt;Options&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;RESOURCE_CACHE_SIZE&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;LRU cache size&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;1000&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;int &amp;gt; 0&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;RESOURCE_CACHE_TTL&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Cache TTL (seconds)&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;3600&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;int &amp;gt; 0&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;MAX_RESOURCE_SIZE&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Max resource bytes&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;10485760&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;int &amp;gt; 0&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;ALLOWED_MIME_TYPES&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Acceptable MIME types&lt;/td&gt; 
    &lt;td&gt;see code&lt;/td&gt; 
    &lt;td&gt;JSON array&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
 &lt;h3&gt;Tools&lt;/h3&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;Setting&lt;/th&gt; 
    &lt;th&gt;Description&lt;/th&gt; 
    &lt;th&gt;Default&lt;/th&gt; 
    &lt;th&gt;Options&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;TOOL_TIMEOUT&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Tool invocation timeout (secs)&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;60&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;int &amp;gt; 0&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;MAX_TOOL_RETRIES&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Max retry attempts&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;3&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;int ≥ 0&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;TOOL_RATE_LIMIT&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Tool calls per minute&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;100&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;int &amp;gt; 0&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;TOOL_CONCURRENT_LIMIT&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Concurrent tool invocations&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;10&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;int &amp;gt; 0&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
 &lt;h3&gt;Prompts&lt;/h3&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;Setting&lt;/th&gt; 
    &lt;th&gt;Description&lt;/th&gt; 
    &lt;th&gt;Default&lt;/th&gt; 
    &lt;th&gt;Options&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;PROMPT_CACHE_SIZE&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Cached prompt templates&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;100&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;int &amp;gt; 0&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;MAX_PROMPT_SIZE&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Max prompt template size (bytes)&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;102400&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;int &amp;gt; 0&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;PROMPT_RENDER_TIMEOUT&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Jinja render timeout (secs)&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;10&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;int &amp;gt; 0&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
 &lt;h3&gt;Health Checks&lt;/h3&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;Setting&lt;/th&gt; 
    &lt;th&gt;Description&lt;/th&gt; 
    &lt;th&gt;Default&lt;/th&gt; 
    &lt;th&gt;Options&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;HEALTH_CHECK_INTERVAL&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Health poll interval (secs)&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;60&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;int &amp;gt; 0&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;HEALTH_CHECK_TIMEOUT&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Health request timeout (secs)&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;10&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;int &amp;gt; 0&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;UNHEALTHY_THRESHOLD&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Fail-count before peer deactivation,&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;3&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;int &amp;gt; 0&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;/td&gt; 
    &lt;td&gt;Set to -1 if deactivation is not needed.&lt;/td&gt; 
    &lt;td&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
 &lt;h3&gt;Database&lt;/h3&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;Setting&lt;/th&gt; 
    &lt;th&gt;Description&lt;/th&gt; 
    &lt;th&gt;Default&lt;/th&gt; 
    &lt;th&gt;Options&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;DB_POOL_SIZE&lt;/code&gt; .&lt;/td&gt; 
    &lt;td&gt;SQLAlchemy connection pool size&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;200&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;int &amp;gt; 0&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;DB_MAX_OVERFLOW&lt;/code&gt;.&lt;/td&gt; 
    &lt;td&gt;Extra connections beyond pool&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;10&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;int ≥ 0&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;DB_POOL_TIMEOUT&lt;/code&gt;.&lt;/td&gt; 
    &lt;td&gt;Wait for connection (secs)&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;30&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;int &amp;gt; 0&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;DB_POOL_RECYCLE&lt;/code&gt;.&lt;/td&gt; 
    &lt;td&gt;Recycle connections (secs)&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;3600&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;int &amp;gt; 0&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;DB_MAX_RETRIES&lt;/code&gt; .&lt;/td&gt; 
    &lt;td&gt;Max Retry Attempts&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;3&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;int &amp;gt; 0&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;DB_RETRY_INTERVAL_MS&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Retry Interval (ms)&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;2000&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;int &amp;gt; 0&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
 &lt;h3&gt;Cache Backend&lt;/h3&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;Setting&lt;/th&gt; 
    &lt;th&gt;Description&lt;/th&gt; 
    &lt;th&gt;Default&lt;/th&gt; 
    &lt;th&gt;Options&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;CACHE_TYPE&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Backend (&lt;code&gt;memory&lt;/code&gt;/&lt;code&gt;redis&lt;/code&gt;)&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;memory&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;none&lt;/code&gt;, &lt;code&gt;memory&lt;/code&gt;,&lt;code&gt;redis&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;REDIS_URL&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Redis connection URL&lt;/td&gt; 
    &lt;td&gt;(none)&lt;/td&gt; 
    &lt;td&gt;string or empty&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;CACHE_PREFIX&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Key prefix&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;mcpgw:&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;string&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;REDIS_MAX_RETRIES&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Max Retry Attempts&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;3&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;int &amp;gt; 0&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;REDIS_RETRY_INTERVAL_MS&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Retry Interval (ms)&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;2000&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;int &amp;gt; 0&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;🧠 &lt;code&gt;none&lt;/code&gt; disables caching entirely. Use &lt;code&gt;memory&lt;/code&gt; for dev, &lt;code&gt;database&lt;/code&gt; for persistence, or &lt;code&gt;redis&lt;/code&gt; for distributed caching.&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;h3&gt;Database Management&lt;/h3&gt; 
 &lt;p&gt;MCP Gateway uses Alembic for database migrations. Common commands:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;code&gt;make db-current&lt;/code&gt; - Show current database version&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;make db-upgrade&lt;/code&gt; - Apply pending migrations&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;make db-migrate&lt;/code&gt; - Create new migration&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;make db-history&lt;/code&gt; - Show migration history&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;make db-status&lt;/code&gt; - Detailed migration status&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h4&gt;Troubleshooting&lt;/h4&gt; 
 &lt;p&gt;&lt;strong&gt;Common Issues:&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;"No 'script_location' key found"&lt;/strong&gt;: Ensure you're running from the project root directory.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;"Unknown SSE event: keepalive" warnings&lt;/strong&gt;: Some MCP clients don't recognize keepalive events. These warnings are harmless and don't affect functionality. To disable: &lt;code&gt;SSE_KEEPALIVE_ENABLED=false&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Connection timeouts with proxies/load balancers&lt;/strong&gt;: If experiencing timeouts, adjust keepalive interval to match your infrastructure: &lt;code&gt;SSE_KEEPALIVE_INTERVAL=60&lt;/code&gt; (AWS ALB) or &lt;code&gt;240&lt;/code&gt; (Azure).&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Development&lt;/h3&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;Setting&lt;/th&gt; 
    &lt;th&gt;Description&lt;/th&gt; 
    &lt;th&gt;Default&lt;/th&gt; 
    &lt;th&gt;Options&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;DEV_MODE&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Enable dev mode&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;false&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;bool&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;RELOAD&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Auto-reload on changes&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;false&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;bool&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;DEBUG&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Debug logging&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;false&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;bool&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/details&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Running&lt;/h2&gt; 
&lt;h3&gt;Makefile&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt; make serve               # Run production Gunicorn server on
 make serve-ssl           # Run Gunicorn behind HTTPS on :4444 (uses ./certs)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Script helper&lt;/h3&gt; 
&lt;p&gt;To run the development (uvicorn) server:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;make dev
# or
./run.sh --reload --log debug --workers 2
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;code&gt;run.sh&lt;/code&gt; is a wrapper around &lt;code&gt;uvicorn&lt;/code&gt; that loads &lt;code&gt;.env&lt;/code&gt;, supports reload, and passes arguments to the server.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Key flags:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Flag&lt;/th&gt; 
   &lt;th&gt;Purpose&lt;/th&gt; 
   &lt;th&gt;Example&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;-e, --env FILE&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;load env-file&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;--env prod.env&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;-H, --host&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;bind address&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;--host 127.0.0.1&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;-p, --port&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;listen port&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;--port 8080&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;-w, --workers&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;gunicorn workers&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;--workers 4&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;-r, --reload&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;auto-reload&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;--reload&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Manual (Uvicorn)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uvicorn mcpgateway.main:app --host 0.0.0.0 --port 4444 --workers 4
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Authentication examples&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Generate a JWT token using JWT_SECRET_KEY and export it as MCPGATEWAY_BEARER_TOKEN
# Note that the module needs to be installed. If running locally use:
export MCPGATEWAY_BEARER_TOKEN=$(JWT_SECRET_KEY=my-test-key python3 -m mcpgateway.utils.create_jwt_token)

# Use the JWT token in an API call
curl -H "Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN" http://localhost:4444/tools
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h2&gt;☁️ AWS / Azure / OpenShift&lt;/h2&gt; 
&lt;p&gt;Deployment details can be found in the GitHub Pages.&lt;/p&gt; 
&lt;h2&gt;☁️ IBM Cloud Code Engine Deployment&lt;/h2&gt; 
&lt;p&gt;This project supports deployment to &lt;a href="https://cloud.ibm.com/codeengine"&gt;IBM Cloud Code Engine&lt;/a&gt; using the &lt;strong&gt;ibmcloud&lt;/strong&gt; CLI and the IBM Container Registry.&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;☁️ IBM Cloud Code Engine Deployment&lt;/strong&gt;&lt;/summary&gt; 
 &lt;h3&gt;🔧 Prerequisites&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Podman &lt;strong&gt;or&lt;/strong&gt; Docker installed locally&lt;/li&gt; 
  &lt;li&gt;IBM Cloud CLI (use &lt;code&gt;make ibmcloud-cli-install&lt;/code&gt; to install)&lt;/li&gt; 
  &lt;li&gt;An &lt;a href="https://cloud.ibm.com/iam/apikeys"&gt;IBM Cloud API key&lt;/a&gt; with access to Code Engine &amp;amp; Container Registry&lt;/li&gt; 
  &lt;li&gt;Code Engine and Container Registry services &lt;strong&gt;enabled&lt;/strong&gt; in your IBM Cloud account&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;hr /&gt; 
 &lt;h3&gt;📦 Environment Variables&lt;/h3&gt; 
 &lt;p&gt;Create a &lt;strong&gt;&lt;code&gt;.env&lt;/code&gt;&lt;/strong&gt; file (or export the variables in your shell). The first block is &lt;strong&gt;required&lt;/strong&gt;; the second provides &lt;strong&gt;tunable defaults&lt;/strong&gt; you can override:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# ── Required ─────────────────────────────────────────────
IBMCLOUD_REGION=us-south
IBMCLOUD_RESOURCE_GROUP=default
IBMCLOUD_PROJECT=my-codeengine-project
IBMCLOUD_CODE_ENGINE_APP=mcpgateway
IBMCLOUD_IMAGE_NAME=us.icr.io/myspace/mcpgateway:latest
IBMCLOUD_IMG_PROD=mcpgateway/mcpgateway
IBMCLOUD_API_KEY=your_api_key_here   # Optional - omit to use interactive `ibmcloud login --sso`

# ── Optional overrides (sensible defaults provided) ──────
IBMCLOUD_CPU=1                       # vCPUs for the app
IBMCLOUD_MEMORY=4G                   # Memory allocation
IBMCLOUD_REGISTRY_SECRET=my-regcred  # Name of the Container Registry secret
&lt;/code&gt;&lt;/pre&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;✅ &lt;strong&gt;Quick check:&lt;/strong&gt; &lt;code&gt;make ibmcloud-check-env&lt;/code&gt;&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;hr /&gt; 
 &lt;h3&gt;🚀 Make Targets&lt;/h3&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;Target&lt;/th&gt; 
    &lt;th&gt;Purpose&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;make ibmcloud-cli-install&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Install IBM Cloud CLI and required plugins&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;make ibmcloud-login&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Log in to IBM Cloud (API key or SSO)&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;make ibmcloud-ce-login&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Select the Code Engine project &amp;amp; region&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;make ibmcloud-tag&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Tag the local container image&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;make ibmcloud-push&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Push the image to IBM Container Registry&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;make ibmcloud-deploy&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;strong&gt;Create or update&lt;/strong&gt; the Code Engine application (uses CPU/memory/secret)&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;make ibmcloud-ce-status&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Show current deployment status&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;make ibmcloud-ce-logs&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Stream logs from the running app&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;make ibmcloud-ce-rm&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Delete the Code Engine application&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
 &lt;hr /&gt; 
 &lt;h3&gt;📝 Example Workflow&lt;/h3&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;make ibmcloud-check-env
make ibmcloud-cli-install
make ibmcloud-login
make ibmcloud-ce-login
make ibmcloud-tag
make ibmcloud-push
make ibmcloud-deploy
make ibmcloud-ce-status
make ibmcloud-ce-logs
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;hr /&gt; 
&lt;h2&gt;API Endpoints&lt;/h2&gt; 
&lt;p&gt;You can test the API endpoints through curl, or Swagger UI, and check detailed documentation on ReDoc:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Swagger UI&lt;/strong&gt; → &lt;a href="http://localhost:4444/docs"&gt;http://localhost:4444/docs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ReDoc&lt;/strong&gt; → &lt;a href="http://localhost:4444/redoc"&gt;http://localhost:4444/redoc&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Generate an API Bearer token, and test the various API endpoints.&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;🔐 Authentication &amp;amp; Health Checks&lt;/strong&gt;&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# Generate a bearer token using the configured secret key (use the same as your .env)
export MCPGATEWAY_BEARER_TOKEN=$(python3 -m mcpgateway.utils.create_jwt_token -u admin --secret my-test-key)
echo ${MCPGATEWAY_BEARER_TOKEN}

# Quickly confirm that authentication works and the gateway is healthy
curl -s -k -H "Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN" https://localhost:4444/health
# {"status":"healthy"}

# Quickly confirm the gateway version &amp;amp; DB connectivity
curl -s -k -H "Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN" https://localhost:4444/version | jq
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;hr /&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;🧱 Protocol APIs (MCP) /protocol&lt;/strong&gt;&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# Initialize MCP session
curl -X POST -H "Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN" \
     -H "Content-Type: application/json" \
     -d '{
           "protocol_version":"2025-03-26",
           "capabilities":{},
           "client_info":{"name":"MyClient","version":"1.0.0"}
         }' \
     http://localhost:4444/protocol/initialize

# Ping (JSON-RPC style)
curl -X POST -H "Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN" \
     -H "Content-Type: application/json" \
     -d '{"jsonrpc":"2.0","id":1,"method":"ping"}' \
     http://localhost:4444/protocol/ping

# Completion for prompt/resource arguments (not implemented)
curl -X POST -H "Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN" \
     -H "Content-Type: application/json" \
     -d '{
           "ref":{"type":"ref/prompt","name":"example_prompt"},
           "argument":{"name":"topic","value":"py"}
         }' \
     http://localhost:4444/protocol/completion/complete

# Sampling (streaming) (not implemented)
curl -N -X POST -H "Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN" \
     -H "Content-Type: application/json" \
     -d '{
           "messages":[{"role":"user","content":{"type":"text","text":"Hello"}}],
           "maxTokens":16
         }' \
     http://localhost:4444/protocol/sampling/createMessage
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;hr /&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;🧠 JSON-RPC Utility /rpc&lt;/strong&gt;&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# Generic JSON-RPC calls (tools, gateways, roots, etc.)
curl -X POST -H "Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN" \
     -H "Content-Type: application/json" \
     -d '{"jsonrpc":"2.0","id":1,"method":"list_tools"}' \
     http://localhost:4444/rpc
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Handles any method name: &lt;code&gt;list_tools&lt;/code&gt;, &lt;code&gt;list_gateways&lt;/code&gt;, &lt;code&gt;prompts/get&lt;/code&gt;, or invokes a tool if method matches a registered tool name .&lt;/p&gt; 
&lt;/details&gt; 
&lt;hr /&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;🔧 Tool Management /tools&lt;/strong&gt;&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# Register a new tool
curl -X POST -H "Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN" \
     -H "Content-Type: application/json" \
     -d '{
           "name":"clock_tool",
           "url":"http://localhost:9000/rpc",
           "description":"Returns current time",
           "input_schema":{
             "type":"object",
             "properties":{"timezone":{"type":"string"}},
             "required":[]
           }
         }' \
     http://localhost:4444/tools

# List tools
curl -H "Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN" http://localhost:4444/tools

# Get tool by ID
curl -H "Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN" http://localhost:4444/tools/1

# Update tool
curl -X PUT -H "Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN" \
     -H "Content-Type: application/json" \
     -d '{ "description":"Updated desc" }' \
     http://localhost:4444/tools/1

# Toggle active status
curl -X POST -H "Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN" \
     http://localhost:4444/tools/1/toggle?activate=false
curl -X POST -H "Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN" \
     http://localhost:4444/tools/1/toggle?activate=true

# Delete tool
curl -X DELETE -H "Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN" http://localhost:4444/tools/1
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;hr /&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;🤖 A2A Agent Management /a2a&lt;/strong&gt;&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# Register a new A2A agent
curl -X POST -H "Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN" \
     -H "Content-Type: application/json" \
     -d '{
           "name":"hello_world_agent",
           "endpoint_url":"http://localhost:9999/",
           "agent_type":"jsonrpc",
           "description":"External AI agent for hello world functionality",
           "auth_type":"api_key",
           "auth_value":"your-api-key",
           "tags":["ai", "hello-world"]
         }' \
     http://localhost:4444/a2a

# List A2A agents
curl -H "Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN" http://localhost:4444/a2a

# Get agent by ID
curl -H "Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN" http://localhost:4444/a2a/agent-id

# Update agent
curl -X PUT -H "Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN" \
     -H "Content-Type: application/json" \
     -d '{ "description":"Updated description" }' \
     http://localhost:4444/a2a/agent-id

# Test agent (direct invocation)
curl -X POST -H "Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN" \
     -H "Content-Type: application/json" \
     -d '{
           "parameters": {
             "method": "message/send",
             "params": {
               "message": {
                 "messageId": "test-123",
                 "role": "user",
                 "parts": [{"type": "text", "text": "Hello!"}]
               }
             }
           },
           "interaction_type": "test"
         }' \
     http://localhost:4444/a2a/agent-name/invoke

# Toggle agent status
curl -X POST -H "Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN" \
     http://localhost:4444/a2a/agent-id/toggle?activate=false

# Delete agent
curl -X DELETE -H "Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN" \
     http://localhost:4444/a2a/agent-id

# Associate agent with virtual server (agents become available as MCP tools)
curl -X POST -H "Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN" \
     -H "Content-Type: application/json" \
     -d '{
           "name":"AI Assistant Server",
           "description":"Virtual server with AI agents",
           "associated_a2a_agents":["agent-id"]
         }' \
     http://localhost:4444/servers
&lt;/code&gt;&lt;/pre&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;🤖 &lt;strong&gt;A2A Integration&lt;/strong&gt;: A2A agents are external AI agents that can be registered and exposed as MCP tools 🔄 &lt;strong&gt;Protocol Detection&lt;/strong&gt;: Gateway automatically detects JSONRPC vs custom A2A protocols 📊 &lt;strong&gt;Testing&lt;/strong&gt;: Built-in test functionality via Admin UI or &lt;code&gt;/a2a/{agent_id}/test&lt;/code&gt; endpoint 🎛️ &lt;strong&gt;Virtual Servers&lt;/strong&gt;: Associate agents with servers to expose them as standard MCP tools&lt;/p&gt; 
 &lt;/blockquote&gt; 
&lt;/details&gt; 
&lt;hr /&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;🌐 Gateway Management /gateways&lt;/strong&gt;&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# Register an MCP server as a new gateway provider
curl -X POST -H "Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN" \
     -H "Content-Type: application/json" \
     -d '{"name":"peer_gateway","url":"http://peer:4444"}' \
     http://localhost:4444/gateways

# List gateways
curl -H "Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN" http://localhost:4444/gateways

# Get gateway by ID
curl -H "Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN" http://localhost:4444/gateways/1

# Update gateway
curl -X PUT -H "Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN" \
     -H "Content-Type: application/json" \
     -d '{"description":"New description"}' \
     http://localhost:4444/gateways/1

# Toggle active status
curl -X POST -H "Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN" \
     http://localhost:4444/gateways/1/toggle?activate=false

# Delete gateway
curl -X DELETE -H "Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN" http://localhost:4444/gateways/1
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;hr /&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;📁 Resource Management /resources&lt;/strong&gt;&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# Register resource
curl -X POST -H "Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN" \
     -H "Content-Type: application/json" \
     -d '{
           "uri":"config://app/settings",
           "name":"App Settings",
           "content":"key=value"
         }' \
     http://localhost:4444/resources

# List resources
curl -H "Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN" http://localhost:4444/resources

# Read a resource
curl -H "Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN" http://localhost:4444/resources/config://app/settings

# Update resource
curl -X PUT -H "Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN" \
     -H "Content-Type: application/json" \
     -d '{"content":"new=value"}' \
     http://localhost:4444/resources/config://app/settings

# Delete resource
curl -X DELETE -H "Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN" http://localhost:4444/resources/config://app/settings

# Subscribe to updates (SSE)
curl -N -H "Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN" http://localhost:4444/resources/subscribe/config://app/settings
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;hr /&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;📝 Prompt Management /prompts&lt;/strong&gt;&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# Create prompt template
curl -X POST -H "Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN" \
     -H "Content-Type: application/json" \
     -d '{
           "name":"greet",
           "template":"Hello, {{ user }}!",
           "argument_schema":{
             "type":"object",
             "properties":{"user":{"type":"string"}},
             "required":["user"]
           }
         }' \
     http://localhost:4444/prompts

# List prompts
curl -H "Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN" http://localhost:4444/prompts

# Get prompt (with args)
curl -X POST -H "Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN" \
     -H "Content-Type: application/json" \
     -d '{"user":"Alice"}' \
     http://localhost:4444/prompts/greet

# Get prompt (no args)
curl -H "Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN" http://localhost:4444/prompts/greet

# Update prompt
curl -X PUT -H "Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN" \
     -H "Content-Type: application/json" \
     -d '{"template":"Hi, {{ user }}!"}' \
     http://localhost:4444/prompts/greet

# Toggle active
curl -X POST -H "Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN" \
     http://localhost:4444/prompts/5/toggle?activate=false

# Delete prompt
curl -X DELETE -H "Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN" http://localhost:4444/prompts/greet
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;hr /&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;🌲 Root Management /roots&lt;/strong&gt;&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# List roots
curl -H "Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN" http://localhost:4444/roots

# Add root
curl -X POST -H "Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN" \
     -H "Content-Type: application/json" \
     -d '{"uri":"/data","name":"Data Root"}' \
     http://localhost:4444/roots

# Remove root
curl -X DELETE -H "Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN" http://localhost:4444/roots/%2Fdata

# Subscribe to root changes (SSE)
curl -N -H "Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN" http://localhost:4444/roots/changes
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;hr /&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;🖥️ Server Management /servers&lt;/strong&gt;&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# List servers
curl -H "Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN" http://localhost:4444/servers

# Get server
curl -H "Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN" http://localhost:4444/servers/UUID_OF_SERVER_1

# Create server
curl -X POST -H "Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN" \
     -H "Content-Type: application/json" \
     -d '{"name":"db","description":"Database","associatedTools": ["1","2","3"]}' \
     http://localhost:4444/servers

# Update server
curl -X PUT -H "Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN" \
     -H "Content-Type: application/json" \
     -d '{"description":"Updated"}' \
     http://localhost:4444/servers/UUID_OF_SERVER_1

# Toggle active
curl -X POST -H "Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN" \
     http://localhost:4444/servers/UUID_OF_SERVER_1/toggle?activate=false
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;hr /&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;📊 Metrics /metrics&lt;/strong&gt;&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# Get aggregated metrics
curl -H "Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN" http://localhost:4444/metrics

# Reset metrics (all or per-entity)
curl -X POST -H "Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN" http://localhost:4444/metrics/reset
curl -X POST -H "Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN" http://localhost:4444/metrics/reset?entity=tool&amp;amp;id=1
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;hr /&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;📡 Events &amp;amp; Health&lt;/strong&gt;&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# SSE: all events
curl -N -H "Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN" http://localhost:4444/events

# WebSocket
wscat -c ws://localhost:4444/ws \
      -H "Authorization: Basic $(echo -n admin:changeme|base64)"

# Health check
curl http://localhost:4444/health
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Full Swagger UI at &lt;code&gt;/docs&lt;/code&gt;.&lt;/p&gt; 
&lt;/details&gt; 
&lt;hr /&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;🛠️ Sample Tool&lt;/strong&gt;&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;uvicorn sample_tool.clock_tool:app --host 0.0.0.0 --port 9000
&lt;/code&gt;&lt;/pre&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;curl -X POST -H "Content-Type: application/json" \
     -d '{"jsonrpc":"2.0","id":1,"method":"get_time","params":{"timezone":"UTC"}}' \
     http://localhost:9000/rpc
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Testing&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;make test            # Run unit tests
make lint            # Run lint tools
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Doctest Coverage&lt;/h2&gt; 
&lt;p&gt;MCP Context Forge implements comprehensive doctest coverage to ensure all code examples in documentation are tested and verified:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;make doctest         # Run all doctests
make doctest-verbose # Run with detailed output
make doctest-coverage # Generate coverage report
make doctest-check   # Check coverage percentage
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Coverage Status:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;✅ &lt;strong&gt;Transport Modules&lt;/strong&gt;: 100% (base, stdio, SSE, WebSocket, streamable HTTP)&lt;/li&gt; 
 &lt;li&gt;✅ &lt;strong&gt;Utility Functions&lt;/strong&gt;: 100% (slug generation, JWT tokens, validation)&lt;/li&gt; 
 &lt;li&gt;✅ &lt;strong&gt;Configuration&lt;/strong&gt;: 100% (settings, environment variables)&lt;/li&gt; 
 &lt;li&gt;🔄 &lt;strong&gt;Service Classes&lt;/strong&gt;: ~60% (in progress)&lt;/li&gt; 
 &lt;li&gt;🔄 &lt;strong&gt;Complex Classes&lt;/strong&gt;: ~40% (in progress)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Benefits:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;All documented examples are automatically tested&lt;/li&gt; 
 &lt;li&gt;Documentation stays accurate and up-to-date&lt;/li&gt; 
 &lt;li&gt;Developers can run examples directly from docstrings&lt;/li&gt; 
 &lt;li&gt;Regression prevention through automated verification&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For detailed information, see the &lt;a href="https://ibm.github.io/mcp-context-forge/development/doctest-coverage/"&gt;Doctest Coverage Guide&lt;/a&gt;.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Project Structure&lt;/h2&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;📁 Directory and file structure for mcpgateway&lt;/strong&gt;&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# ────────── CI / Quality &amp;amp; Meta-files ──────────
├── .bumpversion.cfg                # Automated semantic-version bumps
├── .coveragerc                     # Coverage.py settings
├── .darglint                       # Doc-string linter rules
├── .dockerignore                   # Context exclusions for image builds
├── .editorconfig                   # Consistent IDE / editor behaviour
├── .env                            # Local runtime variables (git-ignored)
├── .env.ce                         # IBM Code Engine runtime env (ignored)
├── .env.ce.example                 # Sample env for IBM Code Engine
├── .env.example                    # Generic sample env file
├── .env.gcr                        # Google Cloud Run runtime env (ignored)
├── .eslintrc.json                  # ESLint rules for JS / TS assets
├── .flake8                         # Flake-8 configuration
├── .gitattributes                  # Git attributes (e.g. EOL normalisation)
├── .github                         # GitHub settings, CI/CD workflows &amp;amp; templates
│   ├── CODEOWNERS                  # Default reviewers
│   └── workflows/                  # Bandit, Docker, CodeQL, Python Package, Container Deployment, etc.
├── .gitignore                      # Git exclusion rules
├── .hadolint.yaml                  # Hadolint rules for Dockerfiles
├── .htmlhintrc                     # HTMLHint rules
├── .markdownlint.json              # Markdown-lint rules
├── .pre-commit-config.yaml         # Pre-commit hooks (ruff, black, mypy, ...)
├── .pycodestyle                    # PEP-8 checker settings
├── .pylintrc                       # Pylint configuration
├── .pyspelling.yml                 # Spell-checker dictionary &amp;amp; filters
├── .ruff.toml                      # Ruff linter / formatter settings
├── .spellcheck-en.txt              # Extra dictionary entries
├── .stylelintrc.json               # Stylelint rules for CSS
├── .travis.yml                     # Legacy Travis CI config (reference)
├── .whitesource                    # WhiteSource security-scanning config
├── .yamllint                       # yamllint ruleset

# ────────── Documentation &amp;amp; Guidance ──────────
├── CHANGELOG.md                    # Version-by-version change log
├── CODE_OF_CONDUCT.md              # Community behaviour guidelines
├── CONTRIBUTING.md                 # How to file issues &amp;amp; send PRs
├── DEVELOPING.md                   # Contributor workflows &amp;amp; style guide
├── LICENSE                         # Apache License 2.0
├── README.md                       # Project overview &amp;amp; quick-start
├── SECURITY.md                     # Security policy &amp;amp; CVE disclosure process
├── TESTING.md                      # Testing strategy, fixtures &amp;amp; guidelines

# ────────── Containerisation &amp;amp; Runtime ──────────
├── Containerfile                   # OCI image build (Docker / Podman)
├── Containerfile.lite              # FROM scratch UBI-Micro production build
├── docker-compose.yml              # Local multi-service stack
├── podman-compose-sonarqube.yaml   # One-liner SonarQube stack
├── run-gunicorn.sh                 # Opinionated Gunicorn startup script
├── run.sh                          # Uvicorn shortcut with arg parsing

# ────────── Build / Packaging / Tooling ──────────
├── MANIFEST.in                     # sdist inclusion rules
├── Makefile                        # Dev &amp;amp; deployment targets
├── package-lock.json               # Deterministic npm lock-file
├── package.json                    # Front-end / docs tooling deps
├── pyproject.toml                  # Poetry / PDM config &amp;amp; lint rules
├── sonar-code.properties           # SonarQube analysis settings
├── uv.lock                         # UV resolver lock-file

# ────────── Kubernetes &amp;amp; Helm Assets ──────────
├── charts                          # Helm chart(s) for K8s / OpenShift
│   ├── mcp-stack                   # Umbrella chart
│   │   ├── Chart.yaml              # Chart metadata
│   │   ├── templates/...             # Manifest templates
│   │   └── values.yaml             # Default values
│   └── README.md                   # Install / upgrade guide
├── k8s                             # Raw (non-Helm) K8s manifests
│   └── *.yaml                      # Deployment, Service, PVC resources

# ────────── Documentation Source ──────────
├── docs                            # MkDocs site source
│   ├── base.yml                    # MkDocs "base" configuration snippet (do not modify)
│   ├── mkdocs.yml                  # Site configuration (requires base.yml)
│   ├── requirements.txt            # Python dependencies for the MkDocs site
│   ├── Makefile                    # Make targets for building/serving the docs
│   └── theme                       # Custom MkDocs theme assets
│       └── logo.png                # Logo for the documentation theme
│   └── docs                        # Markdown documentation
│       ├── architecture/           # ADRs for the project
│       ├── articles/               # Long-form writeups
│       ├── blog/                   # Blog posts
│       ├── deployment/             # Deployment guides (AWS, Azure, etc.)
│       ├── development/            # Development workflows &amp;amp; CI docs
│       ├── images/                 # Diagrams &amp;amp; screenshots
│       ├── index.md                # Top-level docs landing page
│       ├── manage/                 # Management topics (backup, logging, tuning, upgrade)
│       ├── overview/               # Feature overviews &amp;amp; UI documentation
│       ├── security/               # Security guidance &amp;amp; policies
│       ├── testing/                # Testing strategy &amp;amp; fixtures
│       └── using/                  # User-facing usage guides (agents, clients, etc.)
│       ├── media/                  # Social media, press coverage, videos &amp;amp; testimonials
│       │   ├── press/              # Press articles and blog posts
│       │   ├── social/             # Tweets, LinkedIn posts, YouTube embeds
│       │   ├── testimonials/       # Customer quotes &amp;amp; community feedback
│       │   └── kit/                # Media kit &amp;amp; logos for bloggers &amp;amp; press
├── dictionary.dic                  # Custom dictionary for spell-checker (make spellcheck)

# ────────── Application &amp;amp; Libraries ──────────
├── agent_runtimes                  # Configurable agentic frameworks converted to MCP Servers
├── mcpgateway                      # ← main application package
│   ├── __init__.py                 # Package metadata &amp;amp; version constant
│   ├── admin.py                    # FastAPI routers for Admin UI
│   ├── cache
│   │   ├── __init__.py
│   │   ├── resource_cache.py       # LRU+TTL cache implementation
│   │   └── session_registry.py     # Session ↔ cache mapping
│   ├── config.py                   # Pydantic settings loader
│   ├── db.py                       # SQLAlchemy models &amp;amp; engine setup
│   ├── federation
│   │   ├── __init__.py
│   │   ├── discovery.py            # Peer-gateway discovery
│   │   ├── forward.py              # RPC forwarding
│   ├── handlers
│   │   ├── __init__.py
│   │   └── sampling.py             # Streaming sampling handler
│   ├── main.py                     # FastAPI app factory &amp;amp; startup events
│   ├── mcp.db                      # SQLite fixture for tests
│   ├── py.typed                    # PEP 561 marker (ships type hints)
│   ├── schemas.py                  # Shared Pydantic DTOs
│   ├── services
│   │   ├── __init__.py
│   │   ├── completion_service.py   # Prompt / argument completion
│   │   ├── gateway_service.py      # Peer-gateway registry
│   │   ├── logging_service.py      # Central logging helpers
│   │   ├── prompt_service.py       # Prompt CRUD &amp;amp; rendering
│   │   ├── resource_service.py     # Resource registration &amp;amp; retrieval
│   │   ├── root_service.py         # File-system root registry
│   │   ├── server_service.py       # Server registry &amp;amp; monitoring
│   │   └── tool_service.py         # Tool registry &amp;amp; invocation
│   ├── static
│   │   ├── admin.css               # Styles for Admin UI
│   │   └── admin.js                # Behaviour for Admin UI
│   ├── templates
│   │   └── admin.html              # HTMX/Alpine Admin UI template
│   ├── transports
│   │   ├── __init__.py
│   │   ├── base.py                 # Abstract transport interface
│   │   ├── sse_transport.py        # Server-Sent Events transport
│   │   ├── stdio_transport.py      # stdio transport for embedding
│   │   └── websocket_transport.py  # WS transport with ping/pong
│   ├── models.py                   # Core enums / type aliases
│   ├── utils
│   │   ├── create_jwt_token.py     # CLI &amp;amp; library for JWT generation
│   │   ├── services_auth.py        # Service-to-service auth dependency
│   │   └── verify_credentials.py   # Basic / JWT auth helpers
│   ├── validation
│   │   ├── __init__.py
│   │   └── jsonrpc.py              # JSON-RPC 2.0 validation
│   └── version.py                  # Library version helper
├── mcpgateway-wrapper              # Stdio client wrapper (PyPI)
│   ├── pyproject.toml
│   ├── README.md
│   └── src/mcpgateway_wrapper/
│       ├── __init__.py
│       └── server.py               # Wrapper entry-point
├── mcp-servers                     # Sample downstream MCP servers
├── mcp.db                          # Default SQLite DB (auto-created)
├── mcpgrid                         # Experimental grid client / PoC
├── os_deps.sh                      # Installs system-level deps for CI

# ────────── Tests &amp;amp; QA Assets ──────────
├── test_readme.py                  # Guard: README stays in sync
├── tests
│   ├── conftest.py                 # Shared fixtures
│   ├── e2e/...                       # End-to-end scenarios
│   ├── hey/...                       # Load-test logs &amp;amp; helper script
│   ├── integration/...               # API-level integration tests
│   └── unit/...                      # Pure unit tests for business logic
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;hr /&gt; 
&lt;h2&gt;API Documentation&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Swagger UI&lt;/strong&gt; → &lt;a href="http://localhost:4444/docs"&gt;http://localhost:4444/docs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ReDoc&lt;/strong&gt; → &lt;a href="http://localhost:4444/redoc"&gt;http://localhost:4444/redoc&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Admin Panel&lt;/strong&gt; → &lt;a href="http://localhost:4444/admin"&gt;http://localhost:4444/admin&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Makefile targets&lt;/h2&gt; 
&lt;p&gt;This project offer the following Makefile targets. Type &lt;code&gt;make&lt;/code&gt; in the project root to show all targets.&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;🔧 Available Makefile targets&lt;/strong&gt;&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;🐍 MCP CONTEXT FORGE  (An enterprise-ready Model Context Protocol Gateway)
🔧 SYSTEM-LEVEL DEPENDENCIES (DEV BUILD ONLY)
os-deps              - Install Graphviz, Pandoc, Trivy, SCC used for dev docs generation and security scan
🌱 VIRTUAL ENVIRONMENT &amp;amp; INSTALLATION
venv                 - Create a fresh virtual environment with uv &amp;amp; friends
activate             - Activate the virtual environment in the current shell
install              - Install project into the venv
install-dev          - Install project (incl. dev deps) into the venv
install-db           - Install project (incl. postgres and redis) into venv
update               - Update all installed deps inside the venv
check-env            - Verify all required env vars in .env are present
▶️ SERVE &amp;amp; TESTING
serve                - Run production Gunicorn server on :4444
certs                - Generate self-signed TLS cert &amp;amp; key in ./certs (won't overwrite)
serve-ssl            - Run Gunicorn behind HTTPS on :4444 (uses ./certs)
dev                  - Run fast-reload dev server (uvicorn)
run                  - Execute helper script ./run.sh
test                 - Run unit tests with pytest
test-curl            - Smoke-test API endpoints with curl script
pytest-examples      - Run README / examples through pytest-examples
clean                - Remove caches, build artefacts, virtualenv, docs, certs, coverage, SBOM, etc.
📊 COVERAGE &amp;amp; METRICS
coverage             - Run tests with coverage, emit md/HTML/XML + badge
pip-licenses         - Produce dependency license inventory (markdown)
scc                  - Quick LoC/complexity snapshot with scc
scc-report           - Generate HTML LoC &amp;amp; per-file metrics with scc
📚 DOCUMENTATION &amp;amp; SBOM
docs                 - Build docs (graphviz + handsdown + images + SBOM)
images               - Generate architecture &amp;amp; dependency diagrams
🔍 LINTING &amp;amp; STATIC ANALYSIS
lint                 - Run the full linting suite (see targets below)
black                - Reformat code with black
autoflake            - Remove unused imports / variables with autoflake
isort                - Organise &amp;amp; sort imports with isort
flake8               - PEP-8 style &amp;amp; logical errors
pylint               - Pylint static analysis
markdownlint         - Lint Markdown files with markdownlint (requires markdownlint-cli)
mypy                 - Static type-checking with mypy
bandit               - Security scan with bandit
pydocstyle           - Docstring style checker
pycodestyle          - Simple PEP-8 checker
pre-commit           - Run all configured pre-commit hooks
ruff                 - Ruff linter + formatter
ty                   - Ty type checker from astral
pyright              - Static type-checking with Pyright
radon                - Code complexity &amp;amp; maintainability metrics
pyroma               - Validate packaging metadata
importchecker        - Detect orphaned imports
spellcheck           - Spell-check the codebase
fawltydeps           - Detect undeclared / unused deps
wily                 - Maintainability report
pyre                 - Static analysis with Facebook Pyre
depend               - List dependencies in ≈requirements format
snakeviz             - Profile &amp;amp; visualise with snakeviz
pstats               - Generate PNG call-graph from cProfile stats
spellcheck-sort      - Sort local spellcheck dictionary
tox                  - Run tox across multi-Python versions
sbom                 - Produce a CycloneDX SBOM and vulnerability scan
pytype               - Flow-sensitive type checker
check-manifest       - Verify sdist/wheel completeness
yamllint            - Lint YAML files (uses .yamllint)
jsonlint            - Validate every *.json file with jq (--exit-status)
tomllint            - Validate *.toml files with tomlcheck
🕸️  WEBPAGE LINTERS &amp;amp; STATIC ANALYSIS (HTML/CSS/JS lint + security scans + formatting)
install-web-linters  - Install HTMLHint, Stylelint, ESLint, Retire.js &amp;amp; Prettier via npm
lint-web             - Run HTMLHint, Stylelint, ESLint, Retire.js and npm audit
format-web           - Format HTML, CSS &amp;amp; JS files with Prettier
osv-install          - Install/upgrade osv-scanner (Go)
osv-scan-source      - Scan source &amp;amp; lockfiles for CVEs
osv-scan-image       - Scan the built container image for CVEs
osv-scan             - Run all osv-scanner checks (source, image, licence)
📡 SONARQUBE ANALYSIS
sonar-deps-podman    - Install podman-compose + supporting tools
sonar-deps-docker    - Install docker-compose + supporting tools
sonar-up-podman      - Launch SonarQube with podman-compose
sonar-up-docker      - Launch SonarQube with docker-compose
sonar-submit-docker  - Run containerized Sonar Scanner CLI with Docker
sonar-submit-podman  - Run containerized Sonar Scanner CLI with Podman
pysonar-scanner      - Run scan with Python wrapper (pysonar-scanner)
sonar-info           - How to create a token &amp;amp; which env vars to export
🛡️ SECURITY &amp;amp; PACKAGE SCANNING
trivy                - Scan container image for CVEs (HIGH/CRIT). Needs podman socket enabled
grype-scan           - Scan container for security audit and vulnerability scanning
dockle               - Lint the built container image via tarball (no daemon/socket needed)
hadolint             - Lint Containerfile/Dockerfile(s) with hadolint
pip-audit            - Audit Python dependencies for published CVEs
📦 DEPENDENCY MANAGEMENT
deps-update          - Run update-deps.py to update all dependencies in pyproject.toml and docs/requirements.txt
containerfile-update - Update base image in Containerfile to latest tag
📦 PACKAGING &amp;amp; PUBLISHING
dist                 - Clean-build wheel *and* sdist into ./dist
wheel                - Build wheel only
sdist                - Build source distribution only
verify               - Build + twine + check-manifest + pyroma (no upload)
publish              - Verify, then upload to PyPI (needs TWINE_* creds)
🦭 PODMAN CONTAINER BUILD &amp;amp; RUN
podman-dev           - Build development container image
podman               - Build container image
podman-prod          - Build production container image (using ubi-micro → scratch). Not supported on macOS.
podman-run           - Run the container on HTTP  (port 4444)
podman-run-shell     - Run the container on HTTP  (port 4444) and start a shell
podman-run-ssl       - Run the container on HTTPS (port 4444, self-signed)
podman-run-ssl-host  - Run the container on HTTPS with --network=host (port 4444, self-signed)
podman-stop          - Stop &amp;amp; remove the container
podman-test          - Quick curl smoke-test against the container
podman-logs          - Follow container logs (⌃C to quit)
podman-stats         - Show container resource stats (if supported)
podman-top           - Show live top-level process info in container
podman-shell         - Open an interactive shell inside the Podman container
🐋 DOCKER BUILD &amp;amp; RUN
docker-dev           - Build development Docker image
docker               - Build production Docker image
docker-prod          - Build production container image (using ubi-micro → scratch). Not supported on macOS.
docker-run           - Run the container on HTTP  (port 4444)
docker-run-ssl       - Run the container on HTTPS (port 4444, self-signed)
docker-stop          - Stop &amp;amp; remove the container
docker-test          - Quick curl smoke-test against the container
docker-logs          - Follow container logs (⌃C to quit)
docker-stats         - Show container resource usage stats (non-streaming)
docker-top           - Show top-level process info in Docker container
docker-shell         - Open an interactive shell inside the Docker container
🛠️ COMPOSE STACK     - Build / start / stop the multi-service stack
compose-up           - Bring the whole stack up (detached)
compose-restart      - Recreate changed containers, pulling / building as needed
compose-build        - Build (or rebuild) images defined in the compose file
compose-pull         - Pull the latest images only
compose-logs         - Tail logs from all services (Ctrl-C to exit)
compose-ps           - Show container status table
compose-shell        - Open an interactive shell in the "gateway" container
compose-stop         - Gracefully stop the stack (keep containers)
compose-down         - Stop &amp;amp; remove containers (keep named volumes)
compose-rm           - Remove *stopped* containers
compose-clean        - ✨ Down **and** delete named volumes (data-loss ⚠)
☁️ IBM CLOUD CODE ENGINE
ibmcloud-check-env          - Verify all required IBM Cloud env vars are set
ibmcloud-cli-install        - Auto-install IBM Cloud CLI + required plugins (OS auto-detected)
ibmcloud-login              - Login to IBM Cloud CLI using IBMCLOUD_API_KEY (--sso)
ibmcloud-ce-login           - Set Code Engine target project and region
ibmcloud-list-containers    - List deployed Code Engine apps
ibmcloud-tag                - Tag container image for IBM Container Registry
ibmcloud-push               - Push image to IBM Container Registry
ibmcloud-deploy             - Deploy (or update) container image in Code Engine
ibmcloud-ce-logs            - Stream logs for the deployed application
ibmcloud-ce-status          - Get deployment status
ibmcloud-ce-rm              - Delete the Code Engine application
🧪 MINIKUBE LOCAL CLUSTER
minikube-install      - Install Minikube (macOS, Linux, or Windows via choco)
helm-install          - Install Helm CLI (macOS, Linux, or Windows)
minikube-start        - Start local Minikube cluster with Ingress + DNS + metrics-server
minikube-stop         - Stop the Minikube cluster
minikube-delete       - Delete the Minikube cluster
minikube-image-load   - Build and load ghcr.io/ibm/mcp-context-forge:latest into Minikube
minikube-k8s-apply    - Apply Kubernetes manifests from deployment/k8s/
minikube-status       - Show status of Minikube and ingress pods
🛠️ HELM CHART TASKS
helm-lint            - Lint the Helm chart (static analysis)
helm-package         - Package the chart into dist/ as mcp-stack-&amp;lt;ver&amp;gt;.tgz
helm-deploy          - Upgrade/Install chart into Minikube (profile mcpgw)
helm-delete          - Uninstall the chart release from Minikube
🏠 LOCAL PYPI SERVER
local-pypi-install   - Install pypiserver for local testing
local-pypi-start     - Start local PyPI server on :8084 (no auth)
local-pypi-start-auth - Start local PyPI server with basic auth (admin/admin)
local-pypi-stop      - Stop local PyPI server
local-pypi-upload    - Upload existing package to local PyPI (no auth)
local-pypi-upload-auth - Upload existing package to local PyPI (with auth)
local-pypi-test      - Install package from local PyPI
local-pypi-clean     - Full cycle: build → upload → install locally
🏠 LOCAL DEVPI SERVER
devpi-install        - Install devpi server and client
devpi-init           - Initialize devpi server (first time only)
devpi-start          - Start devpi server
devpi-stop           - Stop devpi server
devpi-setup-user     - Create user and dev index
devpi-upload         - Upload existing package to devpi
devpi-test           - Install package from devpi
devpi-clean          - Full cycle: build → upload → install locally
devpi-status         - Show devpi server status
devpi-web            - Open devpi web interface
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h2&gt;🔍 Troubleshooting&lt;/h2&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;Port publishing on WSL2 (rootless Podman &amp;amp; Docker Desktop)&lt;/strong&gt;&lt;/summary&gt; 
 &lt;h3&gt;Diagnose the listener&lt;/h3&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# Inside your WSL distro
ss -tlnp | grep 4444        # Use ss
netstat -anp | grep 4444    # or netstat
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;em&gt;Seeing &lt;code&gt;:::4444 LISTEN rootlessport&lt;/code&gt; is normal&lt;/em&gt; - the IPv6 wildcard socket (&lt;code&gt;::&lt;/code&gt;) also accepts IPv4 traffic &lt;strong&gt;when&lt;/strong&gt; &lt;code&gt;net.ipv6.bindv6only = 0&lt;/code&gt; (default on Linux).&lt;/p&gt; 
 &lt;h3&gt;Why localhost fails on Windows&lt;/h3&gt; 
 &lt;p&gt;WSL 2's NAT layer rewrites only the &lt;em&gt;IPv6&lt;/em&gt; side of the dual-stack listener. From Windows, &lt;code&gt;http://127.0.0.1:4444&lt;/code&gt; (or Docker Desktop's "localhost") therefore times-out.&lt;/p&gt; 
 &lt;h4&gt;Fix (Podman rootless)&lt;/h4&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# Inside the WSL distro
echo "wsl" | sudo tee /etc/containers/podman-machine
systemctl --user restart podman.socket
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;code&gt;ss&lt;/code&gt; should now show &lt;code&gt;0.0.0.0:4444&lt;/code&gt; instead of &lt;code&gt;:::4444&lt;/code&gt;, and the service becomes reachable from Windows &lt;em&gt;and&lt;/em&gt; the LAN.&lt;/p&gt; 
 &lt;h4&gt;Fix (Docker Desktop &amp;gt; 4.19)&lt;/h4&gt; 
 &lt;p&gt;Docker Desktop adds a "WSL integration" switch per-distro. Turn it &lt;strong&gt;on&lt;/strong&gt; for your distro, restart Docker Desktop, then restart the container:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;docker restart mcpgateway
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;Gateway starts but immediately exits ("Failed to read DATABASE_URL")&lt;/strong&gt;&lt;/summary&gt; 
 &lt;p&gt;Copy &lt;code&gt;.env.example&lt;/code&gt; to &lt;code&gt;.env&lt;/code&gt; first:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;cp .env.example .env
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Then edit &lt;code&gt;DATABASE_URL&lt;/code&gt;, &lt;code&gt;JWT_SECRET_KEY&lt;/code&gt;, &lt;code&gt;BASIC_AUTH_PASSWORD&lt;/code&gt;, etc. Missing or empty required vars cause a fast-fail at startup.&lt;/p&gt; 
&lt;/details&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;Fork the repo, create a feature branch.&lt;/li&gt; 
 &lt;li&gt;Run &lt;code&gt;make lint&lt;/code&gt; and fix any issues.&lt;/li&gt; 
 &lt;li&gt;Keep &lt;code&gt;make test&lt;/code&gt; green and 100% coverage.&lt;/li&gt; 
 &lt;li&gt;Open a PR - describe your changes clearly.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;See &lt;a href="https://raw.githubusercontent.com/IBM/mcp-context-forge/main/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; for more details.&lt;/h2&gt; 
&lt;h2&gt;Changelog&lt;/h2&gt; 
&lt;p&gt;A complete changelog can be found here: &lt;a href="https://raw.githubusercontent.com/IBM/mcp-context-forge/main/CHANGELOG.md"&gt;CHANGELOG.md&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Licensed under the &lt;strong&gt;Apache License 2.0&lt;/strong&gt; - see &lt;a href="https://raw.githubusercontent.com/IBM/mcp-context-forge/main/LICENSE"&gt;LICENSE&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Core Authors and Maintainers&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.linkedin.com/in/crivetimihai"&gt;Mihai Criveti&lt;/a&gt; - Distinguished Engineer, Agentic AI&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Special thanks to our contributors for helping us improve ContextForge MCP Gateway:&lt;/p&gt; 
&lt;a href="https://github.com/ibm/mcp-context-forge/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=ibm/mcp-context-forge&amp;amp;max=100&amp;amp;anon=0&amp;amp;columns=10" /&gt; &lt;/a&gt; 
&lt;h2&gt;Star History and Project Activity&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://www.star-history.com/#ibm/mcp-context-forge&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=ibm/mcp-context-forge&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;!-- === Usage Stats === --&gt; 
&lt;p&gt;&lt;a href="https://pepy.tech/project/mcp-contextforge-gateway"&gt;&lt;img src="https://static.pepy.tech/badge/mcp-contextforge-gateway/month" alt="PyPi Downloads" /&gt;&lt;/a&gt;&amp;nbsp; &lt;a href="https://github.com/ibm/mcp-context-forge/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/ibm/mcp-context-forge?style=social" alt="Stars" /&gt;&lt;/a&gt;&amp;nbsp; &lt;a href="https://github.com/ibm/mcp-context-forge/network/members"&gt;&lt;img src="https://img.shields.io/github/forks/ibm/mcp-context-forge?style=social" alt="Forks" /&gt;&lt;/a&gt;&amp;nbsp; &lt;a href="https://github.com/ibm/mcp-context-forge/graphs/contributors"&gt;&lt;img src="https://img.shields.io/github/contributors/ibm/mcp-context-forge" alt="Contributors" /&gt;&lt;/a&gt;&amp;nbsp; &lt;a href="https://github.com/ibm/mcp-context-forge/commits"&gt;&lt;img src="https://img.shields.io/github/last-commit/ibm/mcp-context-forge" alt="Last Commit" /&gt;&lt;/a&gt;&amp;nbsp; &lt;a href="https://github.com/ibm/mcp-context-forge/issues"&gt;&lt;img src="https://img.shields.io/github/issues/ibm/mcp-context-forge" alt="Open Issues" /&gt;&lt;/a&gt;&amp;nbsp;&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>