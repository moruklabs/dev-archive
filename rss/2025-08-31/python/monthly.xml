<rss version="2.0">
  <channel>
    <title>GitHub Python Monthly Trending</title>
    <description>Monthly Trending of Python in GitHub</description>
    <pubDate>Sat, 30 Aug 2025 01:54:04 GMT</pubDate>
    <link>http://mshibanami.github.io/GitHubTrendingRSS</link>
    
    <item>
      <title>openai/tiktoken</title>
      <link>https://github.com/openai/tiktoken</link>
      <description>&lt;p&gt;tiktoken is a fast BPE tokeniser for use with OpenAI's models.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;â³ tiktoken&lt;/h1&gt; 
&lt;p&gt;tiktoken is a fast &lt;a href="https://en.wikipedia.org/wiki/Byte_pair_encoding"&gt;BPE&lt;/a&gt; tokeniser for use with OpenAI's models.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import tiktoken
enc = tiktoken.get_encoding("o200k_base")
assert enc.decode(enc.encode("hello world")) == "hello world"

# To get the tokeniser corresponding to a specific model in the OpenAI API:
enc = tiktoken.encoding_for_model("gpt-4o")
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The open source version of &lt;code&gt;tiktoken&lt;/code&gt; can be installed from &lt;a href="https://pypi.org/project/tiktoken"&gt;PyPI&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;pip install tiktoken
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The tokeniser API is documented in &lt;code&gt;tiktoken/core.py&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Example code using &lt;code&gt;tiktoken&lt;/code&gt; can be found in the &lt;a href="https://github.com/openai/openai-cookbook/raw/main/examples/How_to_count_tokens_with_tiktoken.ipynb"&gt;OpenAI Cookbook&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Performance&lt;/h2&gt; 
&lt;p&gt;&lt;code&gt;tiktoken&lt;/code&gt; is between 3-6x faster than a comparable open source tokeniser:&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/openai/tiktoken/main/perf.svg?sanitize=true" alt="image" /&gt;&lt;/p&gt; 
&lt;p&gt;Performance measured on 1GB of text using the GPT-2 tokeniser, using &lt;code&gt;GPT2TokenizerFast&lt;/code&gt; from &lt;code&gt;tokenizers==0.13.2&lt;/code&gt;, &lt;code&gt;transformers==4.24.0&lt;/code&gt; and &lt;code&gt;tiktoken==0.2.0&lt;/code&gt;.&lt;/p&gt; 
&lt;h2&gt;Getting help&lt;/h2&gt; 
&lt;p&gt;Please post questions in the &lt;a href="https://github.com/openai/tiktoken/issues"&gt;issue tracker&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;If you work at OpenAI, make sure to check the internal documentation or feel free to contact @shantanu.&lt;/p&gt; 
&lt;h2&gt;What is BPE anyway?&lt;/h2&gt; 
&lt;p&gt;Language models don't see text like you and I, instead they see a sequence of numbers (known as tokens). Byte pair encoding (BPE) is a way of converting text into tokens. It has a couple desirable properties:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;It's reversible and lossless, so you can convert tokens back into the original text&lt;/li&gt; 
 &lt;li&gt;It works on arbitrary text, even text that is not in the tokeniser's training data&lt;/li&gt; 
 &lt;li&gt;It compresses the text: the token sequence is shorter than the bytes corresponding to the original text. On average, in practice, each token corresponds to about 4 bytes.&lt;/li&gt; 
 &lt;li&gt;It attempts to let the model see common subwords. For instance, "ing" is a common subword in English, so BPE encodings will often split "encoding" into tokens like "encod" and "ing" (instead of e.g. "enc" and "oding"). Because the model will then see the "ing" token again and again in different contexts, it helps models generalise and better understand grammar.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;code&gt;tiktoken&lt;/code&gt; contains an educational submodule that is friendlier if you want to learn more about the details of BPE, including code that helps visualise the BPE procedure:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from tiktoken._educational import *

# Train a BPE tokeniser on a small amount of text
enc = train_simple_encoding()

# Visualise how the GPT-4 encoder encodes text
enc = SimpleBytePairEncoding.from_tiktoken("cl100k_base")
enc.encode("hello world aaaaaaaaaaaa")
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Extending tiktoken&lt;/h2&gt; 
&lt;p&gt;You may wish to extend &lt;code&gt;tiktoken&lt;/code&gt; to support new encodings. There are two ways to do this.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Create your &lt;code&gt;Encoding&lt;/code&gt; object exactly the way you want and simply pass it around.&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;cl100k_base = tiktoken.get_encoding("cl100k_base")

# In production, load the arguments directly instead of accessing private attributes
# See openai_public.py for examples of arguments for specific encodings
enc = tiktoken.Encoding(
    # If you're changing the set of special tokens, make sure to use a different name
    # It should be clear from the name what behaviour to expect.
    name="cl100k_im",
    pat_str=cl100k_base._pat_str,
    mergeable_ranks=cl100k_base._mergeable_ranks,
    special_tokens={
        **cl100k_base._special_tokens,
        "&amp;lt;|im_start|&amp;gt;": 100264,
        "&amp;lt;|im_end|&amp;gt;": 100265,
    }
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Use the &lt;code&gt;tiktoken_ext&lt;/code&gt; plugin mechanism to register your &lt;code&gt;Encoding&lt;/code&gt; objects with &lt;code&gt;tiktoken&lt;/code&gt;.&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;This is only useful if you need &lt;code&gt;tiktoken.get_encoding&lt;/code&gt; to find your encoding, otherwise prefer option 1.&lt;/p&gt; 
&lt;p&gt;To do this, you'll need to create a namespace package under &lt;code&gt;tiktoken_ext&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Layout your project like this, making sure to omit the &lt;code&gt;tiktoken_ext/__init__.py&lt;/code&gt; file:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;my_tiktoken_extension
â”œâ”€â”€ tiktoken_ext
â”‚&amp;nbsp;&amp;nbsp; â””â”€â”€ my_encodings.py
â””â”€â”€ setup.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;code&gt;my_encodings.py&lt;/code&gt; should be a module that contains a variable named &lt;code&gt;ENCODING_CONSTRUCTORS&lt;/code&gt;. This is a dictionary from an encoding name to a function that takes no arguments and returns arguments that can be passed to &lt;code&gt;tiktoken.Encoding&lt;/code&gt; to construct that encoding. For an example, see &lt;code&gt;tiktoken_ext/openai_public.py&lt;/code&gt;. For precise details, see &lt;code&gt;tiktoken/registry.py&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Your &lt;code&gt;setup.py&lt;/code&gt; should look something like this:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from setuptools import setup, find_namespace_packages

setup(
    name="my_tiktoken_extension",
    packages=find_namespace_packages(include=['tiktoken_ext*']),
    install_requires=["tiktoken"],
    ...
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then simply &lt;code&gt;pip install ./my_tiktoken_extension&lt;/code&gt; and you should be able to use your custom encodings! Make sure &lt;strong&gt;not&lt;/strong&gt; to use an editable install.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>lfnovo/open-notebook</title>
      <link>https://github.com/lfnovo/open-notebook</link>
      <description>&lt;p&gt;An Open Source implementation of Notebook LM with more flexibility and features&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a id="readme-top"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;!-- [![Contributors][contributors-shield]][contributors-url] --&gt; 
&lt;p&gt;&lt;a href="https://github.com/lfnovo/open-notebook/network/members"&gt;&lt;img src="https://img.shields.io/github/forks/lfnovo/open-notebook.svg?style=for-the-badge" alt="Forks" /&gt;&lt;/a&gt; &lt;a href="https://github.com/lfnovo/open-notebook/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/lfnovo/open-notebook.svg?style=for-the-badge" alt="Stargazers" /&gt;&lt;/a&gt; &lt;a href="https://github.com/lfnovo/open-notebook/issues"&gt;&lt;img src="https://img.shields.io/github/issues/lfnovo/open-notebook.svg?style=for-the-badge" alt="Issues" /&gt;&lt;/a&gt; &lt;a href="https://github.com/lfnovo/open-notebook/raw/master/LICENSE.txt"&gt;&lt;img src="https://img.shields.io/github/license/lfnovo/open-notebook.svg?style=for-the-badge" alt="MIT License" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;!-- [![LinkedIn][linkedin-shield]][linkedin-url] --&gt; 
&lt;!-- PROJECT LOGO --&gt; 
&lt;br /&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://github.com/lfnovo/open-notebook"&gt; &lt;img src="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/assets/hero.svg?sanitize=true" alt="Logo" /&gt; &lt;/a&gt; 
 &lt;h3 align="center"&gt;Open Notebook&lt;/h3&gt; 
 &lt;p align="center"&gt; An open source, privacy-focused alternative to Google's Notebook LM! &lt;br /&gt;&lt;strong&gt;Join our &lt;a href="https://discord.gg/37XJPXfz2w"&gt;Discord server&lt;/a&gt; for help, to share workflow ideas, and suggest features!&lt;/strong&gt; &lt;br /&gt; &lt;a href="https://www.open-notebook.ai"&gt;&lt;strong&gt;Checkout our website Â»&lt;/strong&gt;&lt;/a&gt; &lt;br /&gt; &lt;br /&gt; &lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/getting-started/index.md"&gt;ğŸ“š Get Started&lt;/a&gt; Â· &lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/user-guide/index.md"&gt;ğŸ“– User Guide&lt;/a&gt; Â· &lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/features/index.md"&gt;âœ¨ Features&lt;/a&gt; Â· &lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/deployment/index.md"&gt;ğŸš€ Deploy&lt;/a&gt; &lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;ğŸ“¢ Open Notebook is under very active development&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Open Notebook is under active development! We're moving fast and making improvements every week. Your feedback is incredibly valuable to me during this exciting phase and it gives me motivation to keep improving and building this amazing tool. Please feel free to star the project if you find it useful, and don't hesitate to reach out with any questions or suggestions. I'm excited to see how you'll use it and what ideas you'll bring to the project! Let's build something amazing together! ğŸš€&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;About The Project&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/assets/asset_list.png" alt="New Notebook" /&gt;&lt;/p&gt; 
&lt;p&gt;An open source, privacy-focused alternative to Google's Notebook LM. Why give Google more of our data when we can take control of our own research workflows?&lt;/p&gt; 
&lt;p&gt;In a world dominated by Artificial Intelligence, having the ability to think ğŸ§  and acquire new knowledge ğŸ’¡, is a skill that should not be a privilege for a few, nor restricted to a single provider.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Open Notebook empowers you to:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;ğŸ”’ &lt;strong&gt;Control your data&lt;/strong&gt; - Keep your research private and secure&lt;/li&gt; 
 &lt;li&gt;ğŸ¤– &lt;strong&gt;Choose your AI models&lt;/strong&gt; - Support for 16+ providers including OpenAI, Anthropic, Ollama, LM Studio, and more&lt;/li&gt; 
 &lt;li&gt;ğŸ“š &lt;strong&gt;Organize multi-modal content&lt;/strong&gt; - PDFs, videos, audio, web pages, and more&lt;/li&gt; 
 &lt;li&gt;ğŸ™ï¸ &lt;strong&gt;Generate professional podcasts&lt;/strong&gt; - Advanced multi-speaker podcast generation&lt;/li&gt; 
 &lt;li&gt;ğŸ” &lt;strong&gt;Search intelligently&lt;/strong&gt; - Full-text and vector search across all your content&lt;/li&gt; 
 &lt;li&gt;ğŸ’¬ &lt;strong&gt;Chat with context&lt;/strong&gt; - AI conversations powered by your research&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Learn more about our project at &lt;a href="https://www.open-notebook.ai"&gt;https://www.open-notebook.ai&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;ğŸ†š Open Notebook vs Google Notebook LM&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Feature&lt;/th&gt; 
   &lt;th&gt;Open Notebook&lt;/th&gt; 
   &lt;th&gt;Google Notebook LM&lt;/th&gt; 
   &lt;th&gt;Advantage&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Privacy &amp;amp; Control&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Self-hosted, your data&lt;/td&gt; 
   &lt;td&gt;Google cloud only&lt;/td&gt; 
   &lt;td&gt;Complete data sovereignty&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;AI Provider Choice&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;16+ providers (OpenAI, Anthropic, Ollama, LM Studio, etc.)&lt;/td&gt; 
   &lt;td&gt;Google models only&lt;/td&gt; 
   &lt;td&gt;Flexibility and cost optimization&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Podcast Speakers&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;1-4 speakers with custom profiles&lt;/td&gt; 
   &lt;td&gt;2 speakers only&lt;/td&gt; 
   &lt;td&gt;Extreme flexibility&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Context Control&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;3 granular levels&lt;/td&gt; 
   &lt;td&gt;All-or-nothing&lt;/td&gt; 
   &lt;td&gt;Privacy and performance tuning&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Content Transformations&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Custom and built-in&lt;/td&gt; 
   &lt;td&gt;Limited options&lt;/td&gt; 
   &lt;td&gt;Unlimited processing power&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;API Access&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Full REST API&lt;/td&gt; 
   &lt;td&gt;No API&lt;/td&gt; 
   &lt;td&gt;Complete automation&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Deployment&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Docker, cloud, or local&lt;/td&gt; 
   &lt;td&gt;Google hosted only&lt;/td&gt; 
   &lt;td&gt;Deploy anywhere&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Citations&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Comprehensive with sources&lt;/td&gt; 
   &lt;td&gt;Basic references&lt;/td&gt; 
   &lt;td&gt;Research integrity&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Customization&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Open source, fully customizable&lt;/td&gt; 
   &lt;td&gt;Closed system&lt;/td&gt; 
   &lt;td&gt;Unlimited extensibility&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Cost&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Pay only for AI usage&lt;/td&gt; 
   &lt;td&gt;Monthly subscription + usage&lt;/td&gt; 
   &lt;td&gt;Transparent and controllable&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;Why Choose Open Notebook?&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;ğŸ”’ &lt;strong&gt;Privacy First&lt;/strong&gt;: Your sensitive research stays completely private&lt;/li&gt; 
 &lt;li&gt;ğŸ’° &lt;strong&gt;Cost Control&lt;/strong&gt;: Choose cheaper AI providers or run locally with Ollama&lt;/li&gt; 
 &lt;li&gt;ğŸ™ï¸ &lt;strong&gt;Better Podcasts&lt;/strong&gt;: Full script control and multi-speaker flexibility vs limited 2-speaker deep-dive format&lt;/li&gt; 
 &lt;li&gt;ğŸ”§ &lt;strong&gt;Unlimited Customization&lt;/strong&gt;: Modify, extend, and integrate as needed&lt;/li&gt; 
 &lt;li&gt;ğŸŒ &lt;strong&gt;No Vendor Lock-in&lt;/strong&gt;: Switch providers, deploy anywhere, own your data&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Built With&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://www.python.org/"&gt;&lt;img src="https://img.shields.io/badge/Python-3776AB?style=for-the-badge&amp;amp;logo=python&amp;amp;logoColor=white" alt="Python" /&gt;&lt;/a&gt; &lt;a href="https://surrealdb.com/"&gt;&lt;img src="https://img.shields.io/badge/SurrealDB-FF5E00?style=for-the-badge&amp;amp;logo=databricks&amp;amp;logoColor=white" alt="SurrealDB" /&gt;&lt;/a&gt; &lt;a href="https://www.langchain.com/"&gt;&lt;img src="https://img.shields.io/badge/LangChain-3A3A3A?style=for-the-badge&amp;amp;logo=chainlink&amp;amp;logoColor=white" alt="LangChain" /&gt;&lt;/a&gt; &lt;a href="https://streamlit.io/"&gt;&lt;img src="https://img.shields.io/badge/Streamlit-FF4B4B?style=for-the-badge&amp;amp;logo=streamlit&amp;amp;logoColor=white" alt="Streamlit" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;ğŸš€ Quick Start&lt;/h2&gt; 
&lt;p&gt;Ready to try Open Notebook? Choose your preferred method:&lt;/p&gt; 
&lt;h3&gt;âš¡ Instant Setup (Recommended)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Create a new directory for your Open Notebook installation
mkdir open-notebook
cd open-notebook

# Using Docker - Get started in 2 minutes
docker run -d \
  --name open-notebook \
  -p 8502:8502 -p 5055:5055 \
  -v ./notebook_data:/app/data \
  -v ./surreal_data:/mydata \
  -e OPENAI_API_KEY=your_key \
  lfnovo/open_notebook:latest-single
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;What gets created:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;open-notebook/
â”œâ”€â”€ notebook_data/     # Your notebooks and research content
â””â”€â”€ surreal_data/      # Database files
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Access your installation:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ–¥ï¸ Main Interface&lt;/strong&gt;: &lt;a href="http://localhost:8502"&gt;http://localhost:8502&lt;/a&gt; (Streamlit UI)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ”§ API Access&lt;/strong&gt;: &lt;a href="http://localhost:5055"&gt;http://localhost:5055&lt;/a&gt; (REST API)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ“š API Documentation&lt;/strong&gt;: &lt;a href="http://localhost:5055/docs"&gt;http://localhost:5055/docs&lt;/a&gt; (Interactive Swagger UI)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;âš ï¸ Important&lt;/strong&gt;:&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;&lt;strong&gt;Run from a dedicated folder&lt;/strong&gt;: Create and run this from inside a new &lt;code&gt;open-notebook&lt;/code&gt; folder so your data volumes are properly organized&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Volume persistence&lt;/strong&gt;: The volumes (&lt;code&gt;-v ./notebook_data:/app/data&lt;/code&gt; and &lt;code&gt;-v ./surreal_data:/mydata&lt;/code&gt;) are essential to persist your data between container restarts. Without them, you'll lose all your notebooks and research when the container stops.&lt;/li&gt; 
 &lt;/ol&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;ğŸ› ï¸ Full Installation&lt;/h3&gt; 
&lt;p&gt;For development or customization:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/lfnovo/open-notebook
cd open-notebook
make start-all
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;ğŸ“– Need Help?&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ¤– AI Installation Assistant&lt;/strong&gt;: We have a &lt;a href="https://chatgpt.com/g/g-68776e2765b48191bd1bae3f30212631-open-notebook-installation-assistant"&gt;CustomGPT built to help you install Open Notebook&lt;/a&gt; - it will guide you through each step!&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;New to Open Notebook?&lt;/strong&gt; Start with our &lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/getting-started/index.md"&gt;Getting Started Guide&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Need installation help?&lt;/strong&gt; Check our &lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/getting-started/installation.md"&gt;Installation Guide&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Want to see it in action?&lt;/strong&gt; Try our &lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/getting-started/quick-start.md"&gt;Quick Start Tutorial&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Provider Support Matrix&lt;/h2&gt; 
&lt;p&gt;Thanks to the &lt;a href="https://github.com/lfnovo/esperanto"&gt;Esperanto&lt;/a&gt; library, we support this providers out of the box!&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Provider&lt;/th&gt; 
   &lt;th&gt;LLM Support&lt;/th&gt; 
   &lt;th&gt;Embedding Support&lt;/th&gt; 
   &lt;th&gt;Speech-to-Text&lt;/th&gt; 
   &lt;th&gt;Text-to-Speech&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;OpenAI&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Anthropic&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âŒ&lt;/td&gt; 
   &lt;td&gt;âŒ&lt;/td&gt; 
   &lt;td&gt;âŒ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Groq&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âŒ&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âŒ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Google (GenAI)&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âŒ&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Vertex AI&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âŒ&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Ollama&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âŒ&lt;/td&gt; 
   &lt;td&gt;âŒ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Perplexity&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âŒ&lt;/td&gt; 
   &lt;td&gt;âŒ&lt;/td&gt; 
   &lt;td&gt;âŒ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ElevenLabs&lt;/td&gt; 
   &lt;td&gt;âŒ&lt;/td&gt; 
   &lt;td&gt;âŒ&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Azure OpenAI&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âŒ&lt;/td&gt; 
   &lt;td&gt;âŒ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Mistral&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âŒ&lt;/td&gt; 
   &lt;td&gt;âŒ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;DeepSeek&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âŒ&lt;/td&gt; 
   &lt;td&gt;âŒ&lt;/td&gt; 
   &lt;td&gt;âŒ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Voyage&lt;/td&gt; 
   &lt;td&gt;âŒ&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âŒ&lt;/td&gt; 
   &lt;td&gt;âŒ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;xAI&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âŒ&lt;/td&gt; 
   &lt;td&gt;âŒ&lt;/td&gt; 
   &lt;td&gt;âŒ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;OpenRouter&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âŒ&lt;/td&gt; 
   &lt;td&gt;âŒ&lt;/td&gt; 
   &lt;td&gt;âŒ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;OpenAI Compatible*&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âŒ&lt;/td&gt; 
   &lt;td&gt;âŒ&lt;/td&gt; 
   &lt;td&gt;âŒ&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;*Supports LM Studio and any OpenAI-compatible endpoint&lt;/p&gt; 
&lt;h2&gt;âœ¨ Key Features&lt;/h2&gt; 
&lt;h3&gt;Core Capabilities&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ”’ Privacy-First&lt;/strong&gt;: Your data stays under your control - no cloud dependencies&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ¯ Multi-Notebook Organization&lt;/strong&gt;: Manage multiple research projects seamlessly&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ“š Universal Content Support&lt;/strong&gt;: PDFs, videos, audio, web pages, Office docs, and more&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ¤– Multi-Model AI Support&lt;/strong&gt;: 16+ providers including OpenAI, Anthropic, Ollama, Google, LM Studio, and more&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ™ï¸ Professional Podcast Generation&lt;/strong&gt;: Advanced multi-speaker podcasts with Episode Profiles&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ” Intelligent Search&lt;/strong&gt;: Full-text and vector search across all your content&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ’¬ Context-Aware Chat&lt;/strong&gt;: AI conversations powered by your research materials&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ“ AI-Assisted Notes&lt;/strong&gt;: Generate insights or write notes manually&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Advanced Features&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;âš¡ Reasoning Model Support&lt;/strong&gt;: Full support for thinking models like DeepSeek-R1 and Qwen3&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ”§ Content Transformations&lt;/strong&gt;: Powerful customizable actions to summarize and extract insights&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸŒ Comprehensive REST API&lt;/strong&gt;: Full programmatic access for custom integrations &lt;a href="http://localhost:5055/docs"&gt;&lt;img src="https://img.shields.io/badge/API-Documentation-blue?style=flat-square" alt="API Docs" /&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ” Optional Password Protection&lt;/strong&gt;: Secure public deployments with authentication&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ“Š Fine-Grained Context Control&lt;/strong&gt;: Choose exactly what to share with AI models&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ“ Citations&lt;/strong&gt;: Get answers with proper source citations&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Three-Column Interface&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Sources&lt;/strong&gt;: Manage all your research materials&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Notes&lt;/strong&gt;: Create manual or AI-generated notes&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Chat&lt;/strong&gt;: Converse with AI using your content as context&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=D-760MlGwaI"&gt;&lt;img src="https://img.youtube.com/vi/D-760MlGwaI/0.jpg" alt="Check out our podcast sample" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;ğŸ“š Documentation&lt;/h2&gt; 
&lt;h3&gt;Getting Started&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/getting-started/introduction.md"&gt;ğŸ“– Introduction&lt;/a&gt;&lt;/strong&gt; - Learn what Open Notebook offers&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/getting-started/quick-start.md"&gt;âš¡ Quick Start&lt;/a&gt;&lt;/strong&gt; - Get up and running in 5 minutes&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/getting-started/installation.md"&gt;ğŸ”§ Installation&lt;/a&gt;&lt;/strong&gt; - Comprehensive setup guide&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/getting-started/first-notebook.md"&gt;ğŸ¯ Your First Notebook&lt;/a&gt;&lt;/strong&gt; - Step-by-step tutorial&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;User Guide&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/user-guide/interface-overview.md"&gt;ğŸ“± Interface Overview&lt;/a&gt;&lt;/strong&gt; - Understanding the layout&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/user-guide/notebooks.md"&gt;ğŸ“š Notebooks&lt;/a&gt;&lt;/strong&gt; - Organizing your research&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/user-guide/sources.md"&gt;ğŸ“„ Sources&lt;/a&gt;&lt;/strong&gt; - Managing content types&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/user-guide/notes.md"&gt;ğŸ“ Notes&lt;/a&gt;&lt;/strong&gt; - Creating and managing notes&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/user-guide/chat.md"&gt;ğŸ’¬ Chat&lt;/a&gt;&lt;/strong&gt; - AI conversations&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/user-guide/search.md"&gt;ğŸ” Search&lt;/a&gt;&lt;/strong&gt; - Finding information&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Advanced Topics&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/features/podcasts.md"&gt;ğŸ™ï¸ Podcast Generation&lt;/a&gt;&lt;/strong&gt; - Create professional podcasts&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/features/transformations.md"&gt;ğŸ”§ Content Transformations&lt;/a&gt;&lt;/strong&gt; - Customize content processing&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/features/ai-models.md"&gt;ğŸ¤– AI Models&lt;/a&gt;&lt;/strong&gt; - AI model configuration&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/development/api-reference.md"&gt;ğŸ”§ REST API Reference&lt;/a&gt;&lt;/strong&gt; - Complete API documentation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/deployment/security.md"&gt;ğŸ” Security&lt;/a&gt;&lt;/strong&gt; - Password protection and privacy&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/deployment/index.md"&gt;ğŸš€ Deployment&lt;/a&gt;&lt;/strong&gt; - Complete deployment guides for all scenarios&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p align="right"&gt;(&lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/#readme-top"&gt;back to top&lt;/a&gt;)&lt;/p&gt; 
&lt;h2&gt;ğŸ—ºï¸ Roadmap&lt;/h2&gt; 
&lt;h3&gt;Upcoming Features&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;React Frontend&lt;/strong&gt;: Modern React-based frontend to replace Streamlit&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Live Front-End Updates&lt;/strong&gt;: Real-time UI updates for smoother experience&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Async Processing&lt;/strong&gt;: Faster UI through asynchronous content processing&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Cross-Notebook Sources&lt;/strong&gt;: Reuse research materials across projects&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Bookmark Integration&lt;/strong&gt;: Connect with your favorite bookmarking apps&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Recently Completed âœ…&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Comprehensive REST API&lt;/strong&gt;: Full programmatic access to all functionality&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Multi-Model Support&lt;/strong&gt;: 16+ AI providers including OpenAI, Anthropic, Ollama, LM Studio&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Advanced Podcast Generator&lt;/strong&gt;: Professional multi-speaker podcasts with Episode Profiles&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Content Transformations&lt;/strong&gt;: Powerful customizable actions for content processing&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Enhanced Citations&lt;/strong&gt;: Improved layout and finer control for source citations&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Multiple Chat Sessions&lt;/strong&gt;: Manage different conversations within notebooks&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;See the &lt;a href="https://github.com/lfnovo/open-notebook/issues"&gt;open issues&lt;/a&gt; for a full list of proposed features and known issues.&lt;/p&gt; 
&lt;p align="right"&gt;(&lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/#readme-top"&gt;back to top&lt;/a&gt;)&lt;/p&gt; 
&lt;h2&gt;ğŸ¤ Community &amp;amp; Contributing&lt;/h2&gt; 
&lt;h3&gt;Join the Community&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;ğŸ’¬ &lt;strong&gt;&lt;a href="https://discord.gg/37XJPXfz2w"&gt;Discord Server&lt;/a&gt;&lt;/strong&gt; - Get help, share ideas, and connect with other users&lt;/li&gt; 
 &lt;li&gt;ğŸ› &lt;strong&gt;&lt;a href="https://github.com/lfnovo/open-notebook/issues"&gt;GitHub Issues&lt;/a&gt;&lt;/strong&gt; - Report bugs and request features&lt;/li&gt; 
 &lt;li&gt;â­ &lt;strong&gt;Star this repo&lt;/strong&gt; - Show your support and help others discover Open Notebook&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Contributing&lt;/h3&gt; 
&lt;p&gt;We welcome contributions! We're especially looking for help with:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Frontend Development&lt;/strong&gt;: Help build a modern React-based UI (planned replacement for current Streamlit interface)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Testing &amp;amp; Bug Fixes&lt;/strong&gt;: Make Open Notebook more robust&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Feature Development&lt;/strong&gt;: Build the coolest research tool together&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Documentation&lt;/strong&gt;: Improve guides and tutorials&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Current Tech Stack&lt;/strong&gt;: Python, FastAPI, SurrealDB, Streamlit&lt;br /&gt; &lt;strong&gt;Future Roadmap&lt;/strong&gt;: React frontend, enhanced real-time updates&lt;/p&gt; 
&lt;p&gt;See our &lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/CONTRIBUTING.md"&gt;Contributing Guide&lt;/a&gt; for detailed information on how to get started.&lt;/p&gt; 
&lt;p align="right"&gt;(&lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/#readme-top"&gt;back to top&lt;/a&gt;)&lt;/p&gt; 
&lt;h2&gt;ğŸ“„ License&lt;/h2&gt; 
&lt;p&gt;Open Notebook is MIT licensed. See the &lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/LICENSE"&gt;LICENSE&lt;/a&gt; file for details.&lt;/p&gt; 
&lt;h2&gt;ğŸ“ Contact&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Luis Novo&lt;/strong&gt; - &lt;a href="https://twitter.com/lfnovo"&gt;@lfnovo&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Community Support&lt;/strong&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;ğŸ’¬ &lt;a href="https://discord.gg/37XJPXfz2w"&gt;Discord Server&lt;/a&gt; - Get help, share ideas, and connect with users&lt;/li&gt; 
 &lt;li&gt;ğŸ› &lt;a href="https://github.com/lfnovo/open-notebook/issues"&gt;GitHub Issues&lt;/a&gt; - Report bugs and request features&lt;/li&gt; 
 &lt;li&gt;ğŸŒ &lt;a href="https://www.open-notebook.ai"&gt;Website&lt;/a&gt; - Learn more about the project&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ğŸ™ Acknowledgments&lt;/h2&gt; 
&lt;p&gt;Open Notebook is built on the shoulders of amazing open-source projects:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/lfnovo/podcast-creator"&gt;Podcast Creator&lt;/a&gt;&lt;/strong&gt; - Advanced podcast generation capabilities&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/lfnovo/surreal-commands"&gt;Surreal Commands&lt;/a&gt;&lt;/strong&gt; - Background job processing&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/lfnovo/content-core"&gt;Content Core&lt;/a&gt;&lt;/strong&gt; - Content processing and management&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/lfnovo/esperanto"&gt;Esperanto&lt;/a&gt;&lt;/strong&gt; - Multi-provider AI model abstraction&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/docling-project/docling"&gt;Docling&lt;/a&gt;&lt;/strong&gt; - Document processing and parsing&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p align="right"&gt;(&lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/#readme-top"&gt;back to top&lt;/a&gt;)&lt;/p&gt; 
&lt;!-- MARKDOWN LINKS &amp; IMAGES --&gt; 
&lt;!-- https://www.markdownguide.org/basic-syntax/#reference-style-links --&gt;</description>
    </item>
    
    <item>
      <title>HKUDS/LightRAG</title>
      <link>https://github.com/HKUDS/LightRAG</link>
      <description>&lt;p&gt;"LightRAG: Simple and Fast Retrieval-Augmented Generation"&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;div style="margin: 20px 0;"&gt; 
  &lt;img src="https://raw.githubusercontent.com/HKUDS/LightRAG/main/assets/logo.png" width="120" height="120" alt="LightRAG Logo" style="border-radius: 20px; box-shadow: 0 8px 32px rgba(0, 217, 255, 0.3);" /&gt; 
 &lt;/div&gt; 
 &lt;h1&gt;ğŸš€ LightRAG: Simple and Fast Retrieval-Augmented Generation&lt;/h1&gt; 
 &lt;div align="center"&gt; 
  &lt;a href="https://trendshift.io/repositories/13043" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/13043" alt="HKUDS%2FLightRAG | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt; 
 &lt;/div&gt; 
 &lt;div align="center"&gt; 
  &lt;div style="width: 100%; height: 2px; margin: 20px 0; background: linear-gradient(90deg, transparent, #00d9ff, transparent);"&gt;&lt;/div&gt; 
 &lt;/div&gt; 
 &lt;div align="center"&gt; 
  &lt;div style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); border-radius: 15px; padding: 25px; text-align: center;"&gt; 
   &lt;p&gt; &lt;a href="https://github.com/HKUDS/LightRAG"&gt;&lt;img src="https://img.shields.io/badge/ğŸ”¥Project-Page-00d9ff?style=for-the-badge&amp;amp;logo=github&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt;&lt;/a&gt; &lt;a href="https://arxiv.org/abs/2410.05779"&gt;&lt;img src="https://img.shields.io/badge/ğŸ“„arXiv-2410.05779-ff6b6b?style=for-the-badge&amp;amp;logo=arxiv&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt;&lt;/a&gt; &lt;a href="https://github.com/HKUDS/LightRAG/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/HKUDS/LightRAG?color=00d9ff&amp;amp;style=for-the-badge&amp;amp;logo=star&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt;&lt;/a&gt; &lt;/p&gt; 
   &lt;p&gt; &lt;img src="https://img.shields.io/badge/ğŸPython-3.10-4ecdc4?style=for-the-badge&amp;amp;logo=python&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt; &lt;a href="https://pypi.org/project/lightrag-hku/"&gt;&lt;img src="https://img.shields.io/pypi/v/lightrag-hku.svg?style=for-the-badge&amp;amp;logo=pypi&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e&amp;amp;color=ff6b6b" /&gt;&lt;/a&gt; &lt;/p&gt; 
   &lt;p&gt; &lt;a href="https://discord.gg/yF2MmDJyGJ"&gt;&lt;img src="https://img.shields.io/badge/ğŸ’¬Discord-Community-7289da?style=for-the-badge&amp;amp;logo=discord&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt;&lt;/a&gt; &lt;a href="https://github.com/HKUDS/LightRAG/issues/285"&gt;&lt;img src="https://img.shields.io/badge/ğŸ’¬WeChat-Group-07c160?style=for-the-badge&amp;amp;logo=wechat&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt;&lt;/a&gt; &lt;/p&gt; 
   &lt;p&gt; &lt;a href="https://raw.githubusercontent.com/HKUDS/LightRAG/main/README-zh.md"&gt;&lt;img src="https://img.shields.io/badge/ğŸ‡¨ğŸ‡³ä¸­æ–‡ç‰ˆ-1a1a2e?style=for-the-badge" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/HKUDS/LightRAG/main/README.md"&gt;&lt;img src="https://img.shields.io/badge/ğŸ‡ºğŸ‡¸English-1a1a2e?style=for-the-badge" /&gt;&lt;/a&gt; &lt;/p&gt; 
  &lt;/div&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div align="center" style="margin: 30px 0;"&gt; 
 &lt;img src="https://user-images.githubusercontent.com/74038190/212284100-561aa473-3905-4a80-b561-0d28506553ee.gif" width="800" /&gt; 
&lt;/div&gt; 
&lt;div align="center" style="margin: 30px 0;"&gt; 
 &lt;img src="https://raw.githubusercontent.com/HKUDS/LightRAG/main/README.assets/b2aaf634151b4706892693ffb43d9093.png" width="800" alt="LightRAG Diagram" /&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ğŸ‰ News&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; [2025.06.16]ğŸ¯ğŸ“¢Our team has released &lt;a href="https://github.com/HKUDS/RAG-Anything"&gt;RAG-Anything&lt;/a&gt; an All-in-One Multimodal RAG System for seamless text, image, table, and equation processing.&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; [2025.06.05]ğŸ¯ğŸ“¢LightRAG now supports comprehensive multimodal data handling through &lt;a href="https://github.com/HKUDS/RAG-Anything"&gt;RAG-Anything&lt;/a&gt; integration, enabling seamless document parsing and RAG capabilities across diverse formats including PDFs, images, Office documents, tables, and formulas. Please refer to the new &lt;a href="https://github.com/HKUDS/LightRAG/?tab=readme-ov-file#multimodal-document-processing-rag-anything-integration"&gt;multimodal section&lt;/a&gt; for details.&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; [2025.03.18]ğŸ¯ğŸ“¢LightRAG now supports citation functionality, enabling proper source attribution.&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; [2025.02.05]ğŸ¯ğŸ“¢Our team has released &lt;a href="https://github.com/HKUDS/VideoRAG"&gt;VideoRAG&lt;/a&gt; understanding extremely long-context videos.&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; [2025.01.13]ğŸ¯ğŸ“¢Our team has released &lt;a href="https://github.com/HKUDS/MiniRAG"&gt;MiniRAG&lt;/a&gt; making RAG simpler with small models.&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; [2025.01.06]ğŸ¯ğŸ“¢You can now &lt;a href="https://raw.githubusercontent.com/HKUDS/LightRAG/main/#using-postgresql-for-storage"&gt;use PostgreSQL for Storage&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; [2024.12.31]ğŸ¯ğŸ“¢LightRAG now supports &lt;a href="https://github.com/HKUDS/LightRAG?tab=readme-ov-file#delete"&gt;deletion by document ID&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; [2024.11.25]ğŸ¯ğŸ“¢LightRAG now supports seamless integration of &lt;a href="https://github.com/HKUDS/LightRAG?tab=readme-ov-file#insert-custom-kg"&gt;custom knowledge graphs&lt;/a&gt;, empowering users to enhance the system with their own domain expertise.&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; [2024.11.19]ğŸ¯ğŸ“¢A comprehensive guide to LightRAG is now available on &lt;a href="https://learnopencv.com/lightrag"&gt;LearnOpenCV&lt;/a&gt;. Many thanks to the blog author.&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; [2024.11.11]ğŸ¯ğŸ“¢LightRAG now supports &lt;a href="https://github.com/HKUDS/LightRAG?tab=readme-ov-file#delete"&gt;deleting entities by their names&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; [2024.11.09]ğŸ¯ğŸ“¢Introducing the &lt;a href="https://lightrag-gui.streamlit.app"&gt;LightRAG Gui&lt;/a&gt;, which allows you to insert, query, visualize, and download LightRAG knowledge.&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; [2024.11.04]ğŸ¯ğŸ“¢You can now &lt;a href="https://github.com/HKUDS/LightRAG?tab=readme-ov-file#using-neo4j-for-storage"&gt;use Neo4J for Storage&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; [2024.10.29]ğŸ¯ğŸ“¢LightRAG now supports multiple file types, including PDF, DOC, PPT, and CSV via &lt;code&gt;textract&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; [2024.10.20]ğŸ¯ğŸ“¢We've added a new feature to LightRAG: Graph Visualization.&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; [2024.10.18]ğŸ¯ğŸ“¢We've added a link to a &lt;a href="https://youtu.be/oageL-1I0GE"&gt;LightRAG Introduction Video&lt;/a&gt;. Thanks to the author!&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; [2024.10.17]ğŸ¯ğŸ“¢We have created a &lt;a href="https://discord.gg/yF2MmDJyGJ"&gt;Discord channel&lt;/a&gt;! Welcome to join for sharing and discussions! ğŸ‰ğŸ‰&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; [2024.10.16]ğŸ¯ğŸ“¢LightRAG now supports &lt;a href="https://github.com/HKUDS/LightRAG?tab=readme-ov-file#quick-start"&gt;Ollama models&lt;/a&gt;!&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; [2024.10.15]ğŸ¯ğŸ“¢LightRAG now supports &lt;a href="https://github.com/HKUDS/LightRAG?tab=readme-ov-file#quick-start"&gt;Hugging Face models&lt;/a&gt;!&lt;/li&gt; 
&lt;/ul&gt; 
&lt;details&gt; 
 &lt;summary style="font-size: 1.4em; font-weight: bold; cursor: pointer; display: list-item;"&gt; Algorithm Flowchart &lt;/summary&gt; 
 &lt;p&gt;&lt;img src="https://learnopencv.com/wp-content/uploads/2024/11/LightRAG-VectorDB-Json-KV-Store-Indexing-Flowchart-scaled.jpg" alt="LightRAG Indexing Flowchart" /&gt; &lt;em&gt;Figure 1: LightRAG Indexing Flowchart - Img Caption : &lt;a href="https://learnopencv.com/lightrag/"&gt;Source&lt;/a&gt;&lt;/em&gt; &lt;img src="https://learnopencv.com/wp-content/uploads/2024/11/LightRAG-Querying-Flowchart-Dual-Level-Retrieval-Generation-Knowledge-Graphs-scaled.jpg" alt="LightRAG Retrieval and Querying Flowchart" /&gt; &lt;em&gt;Figure 2: LightRAG Retrieval and Querying Flowchart - Img Caption : &lt;a href="https://learnopencv.com/lightrag/"&gt;Source&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;/details&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;h3&gt;Install LightRAG Server&lt;/h3&gt; 
&lt;p&gt;The LightRAG Server is designed to provide Web UI and API support. The Web UI facilitates document indexing, knowledge graph exploration, and a simple RAG query interface. LightRAG Server also provide an Ollama compatible interfaces, aiming to emulate LightRAG as an Ollama chat model. This allows AI chat bot, such as Open WebUI, to access LightRAG easily.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Install from PyPI&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install "lightrag-hku[api]"
cp env.example .env
lightrag-server
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;Installation from Source&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/HKUDS/LightRAG.git
cd LightRAG
# create a Python virtual enviroment if neccesary
# Install in editable mode with API support
pip install -e ".[api]"
cp env.example .env
lightrag-server
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;Launching the LightRAG Server with Docker Compose&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code&gt;git clone https://github.com/HKUDS/LightRAG.git
cd LightRAG
cp env.example .env
# modify LLM and Embedding settings in .env
docker compose up
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Historical versions of LightRAG docker images can be found here: &lt;a href="https://github.com/HKUDS/LightRAG/pkgs/container/lightrag"&gt;LightRAG Docker Images&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Install LightRAG Core&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Install from source (Recommend)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd LightRAG
pip install -e .
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;Install from PyPI&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install lightrag-hku
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;h3&gt;LLM and Technology Stack Requirements for LightRAG&lt;/h3&gt; 
&lt;p&gt;LightRAG's demands on the capabilities of Large Language Models (LLMs) are significantly higher than those of traditional RAG, as it requires the LLM to perform entity-relationship extraction tasks from documents. Configuring appropriate Embedding and Reranker models is also crucial for improving query performance.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;LLM Selection&lt;/strong&gt;: 
  &lt;ul&gt; 
   &lt;li&gt;It is recommended to use an LLM with at least 32 billion parameters.&lt;/li&gt; 
   &lt;li&gt;The context length should be at least 32KB, with 64KB being recommended.&lt;/li&gt; 
   &lt;li&gt;It is not recommended to choose reasoning models during the document indexing stage.&lt;/li&gt; 
   &lt;li&gt;During the query stage, it is recommended to choose models with stronger capabilities than those used in the indexing stage to achieve better query results.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Embedding Model&lt;/strong&gt;: 
  &lt;ul&gt; 
   &lt;li&gt;A high-performance Embedding model is essential for RAG.&lt;/li&gt; 
   &lt;li&gt;We recommend using mainstream multilingual Embedding models, such as: &lt;code&gt;BAAI/bge-m3&lt;/code&gt; and &lt;code&gt;text-embedding-3-large&lt;/code&gt;.&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Important Note&lt;/strong&gt;: The Embedding model must be determined before document indexing, and the same model must be used during the document query phase. For certain storage solutions (e.g., PostgreSQL), the vector dimension must be defined upon initial table creation. Therefore, when changing embedding models, it is necessary to delete the existing vector-related tables and allow LightRAG to recreate them with the new dimensions.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Reranker Model Configuration&lt;/strong&gt;: 
  &lt;ul&gt; 
   &lt;li&gt;Configuring a Reranker model can significantly enhance LightRAG's retrieval performance.&lt;/li&gt; 
   &lt;li&gt;When a Reranker model is enabled, it is recommended to set the "mix mode" as the default query mode.&lt;/li&gt; 
   &lt;li&gt;We recommend using mainstream Reranker models, such as: &lt;code&gt;BAAI/bge-reranker-v2-m3&lt;/code&gt; or models provided by services like Jina.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Quick Start for LightRAG Server&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;For more information about LightRAG Server, please refer to &lt;a href="https://raw.githubusercontent.com/HKUDS/LightRAG/main/lightrag/api/README.md"&gt;LightRAG Server&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Quick Start for LightRAG core&lt;/h3&gt; 
&lt;p&gt;To get started with LightRAG core, refer to the sample codes available in the &lt;code&gt;examples&lt;/code&gt; folder. Additionally, a &lt;a href="https://www.youtube.com/watch?v=g21royNJ4fw"&gt;video demo&lt;/a&gt; demonstration is provided to guide you through the local setup process. If you already possess an OpenAI API key, you can run the demo right away:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;### you should run the demo code with project folder
cd LightRAG
### provide your API-KEY for OpenAI
export OPENAI_API_KEY="sk-...your_opeai_key..."
### download the demo document of "A Christmas Carol" by Charles Dickens
curl https://raw.githubusercontent.com/gusye1234/nano-graphrag/main/tests/mock_data.txt &amp;gt; ./book.txt
### run the demo code
python examples/lightrag_openai_demo.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For a streaming response implementation example, please see &lt;code&gt;examples/lightrag_openai_compatible_demo.py&lt;/code&gt;. Prior to execution, ensure you modify the sample code's LLM and embedding configurations accordingly.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Note 1&lt;/strong&gt;: When running the demo program, please be aware that different test scripts may use different embedding models. If you switch to a different embedding model, you must clear the data directory (&lt;code&gt;./dickens&lt;/code&gt;); otherwise, the program may encounter errors. If you wish to retain the LLM cache, you can preserve the &lt;code&gt;kv_store_llm_response_cache.json&lt;/code&gt; file while clearing the data directory.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Note 2&lt;/strong&gt;: Only &lt;code&gt;lightrag_openai_demo.py&lt;/code&gt; and &lt;code&gt;lightrag_openai_compatible_demo.py&lt;/code&gt; are officially supported sample codes. Other sample files are community contributions that haven't undergone full testing and optimization.&lt;/p&gt; 
&lt;h2&gt;Programing with LightRAG Core&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;âš ï¸ &lt;strong&gt;If you would like to integrate LightRAG into your project, we recommend utilizing the REST API provided by the LightRAG Server&lt;/strong&gt;. LightRAG Core is typically intended for embedded applications or for researchers who wish to conduct studies and evaluations.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;âš ï¸ Important: Initialization Requirements&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;LightRAG requires explicit initialization before use.&lt;/strong&gt; You must call both &lt;code&gt;await rag.initialize_storages()&lt;/code&gt; and &lt;code&gt;await initialize_pipeline_status()&lt;/code&gt; after creating a LightRAG instance, otherwise you will encounter errors like:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;AttributeError: __aenter__&lt;/code&gt; - if storages are not initialized&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;KeyError: 'history_messages'&lt;/code&gt; - if pipeline status is not initialized&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;A Simple Program&lt;/h3&gt; 
&lt;p&gt;Use the below Python snippet to initialize LightRAG, insert text to it, and perform queries:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import os
import asyncio
from lightrag import LightRAG, QueryParam
from lightrag.llm.openai import gpt_4o_mini_complete, gpt_4o_complete, openai_embed
from lightrag.kg.shared_storage import initialize_pipeline_status
from lightrag.utils import setup_logger

setup_logger("lightrag", level="INFO")

WORKING_DIR = "./rag_storage"
if not os.path.exists(WORKING_DIR):
    os.mkdir(WORKING_DIR)

async def initialize_rag():
    rag = LightRAG(
        working_dir=WORKING_DIR,
        embedding_func=openai_embed,
        llm_model_func=gpt_4o_mini_complete,
    )
    # IMPORTANT: Both initialization calls are required!
    await rag.initialize_storages()  # Initialize storage backends
    await initialize_pipeline_status()  # Initialize processing pipeline
    return rag

async def main():
    try:
        # Initialize RAG instance
        rag = await initialize_rag()
        await rag.ainsert("Your text")

        # Perform hybrid search
        mode = "hybrid"
        print(
          await rag.aquery(
              "What are the top themes in this story?",
              param=QueryParam(mode=mode)
          )
        )

    except Exception as e:
        print(f"An error occurred: {e}")
    finally:
        if rag:
            await rag.finalize_storages()

if __name__ == "__main__":
    asyncio.run(main())
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Important notes for the above snippet:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Export your OPENAI_API_KEY environment variable before running the script.&lt;/li&gt; 
 &lt;li&gt;This program uses the default storage settings for LightRAG, so all data will be persisted to WORKING_DIR/rag_storage.&lt;/li&gt; 
 &lt;li&gt;This program demonstrates only the simplest way to initialize a LightRAG object: Injecting the embedding and LLM functions, and initializing storage and pipeline status after creating the LightRAG object.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;LightRAG init parameters&lt;/h3&gt; 
&lt;p&gt;A full list of LightRAG init parameters:&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt; Parameters &lt;/summary&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;&lt;strong&gt;Parameter&lt;/strong&gt;&lt;/th&gt; 
    &lt;th&gt;&lt;strong&gt;Type&lt;/strong&gt;&lt;/th&gt; 
    &lt;th&gt;&lt;strong&gt;Explanation&lt;/strong&gt;&lt;/th&gt; 
    &lt;th&gt;&lt;strong&gt;Default&lt;/strong&gt;&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;working_dir&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;str&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Directory where the cache will be stored&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;lightrag_cache+timestamp&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;workspace&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;str&lt;/td&gt; 
    &lt;td&gt;Workspace name for data isolation between different LightRAG Instances&lt;/td&gt; 
    &lt;td&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;kv_storage&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;str&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Storage type for documents and text chunks. Supported types: &lt;code&gt;JsonKVStorage&lt;/code&gt;,&lt;code&gt;PGKVStorage&lt;/code&gt;,&lt;code&gt;RedisKVStorage&lt;/code&gt;,&lt;code&gt;MongoKVStorage&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;JsonKVStorage&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;vector_storage&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;str&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Storage type for embedding vectors. Supported types: &lt;code&gt;NanoVectorDBStorage&lt;/code&gt;,&lt;code&gt;PGVectorStorage&lt;/code&gt;,&lt;code&gt;MilvusVectorDBStorage&lt;/code&gt;,&lt;code&gt;ChromaVectorDBStorage&lt;/code&gt;,&lt;code&gt;FaissVectorDBStorage&lt;/code&gt;,&lt;code&gt;MongoVectorDBStorage&lt;/code&gt;,&lt;code&gt;QdrantVectorDBStorage&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;NanoVectorDBStorage&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;graph_storage&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;str&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Storage type for graph edges and nodes. Supported types: &lt;code&gt;NetworkXStorage&lt;/code&gt;,&lt;code&gt;Neo4JStorage&lt;/code&gt;,&lt;code&gt;PGGraphStorage&lt;/code&gt;,&lt;code&gt;AGEStorage&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;NetworkXStorage&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;doc_status_storage&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;str&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Storage type for documents process status. Supported types: &lt;code&gt;JsonDocStatusStorage&lt;/code&gt;,&lt;code&gt;PGDocStatusStorage&lt;/code&gt;,&lt;code&gt;MongoDocStatusStorage&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;JsonDocStatusStorage&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;chunk_token_size&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;int&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Maximum token size per chunk when splitting documents&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;1200&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;chunk_overlap_token_size&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;int&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Overlap token size between two chunks when splitting documents&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;100&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;tokenizer&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;Tokenizer&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;The function used to convert text into tokens (numbers) and back using .encode() and .decode() functions following &lt;code&gt;TokenizerInterface&lt;/code&gt; protocol. If you don't specify one, it will use the default Tiktoken tokenizer.&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;TiktokenTokenizer&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;tiktoken_model_name&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;str&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;If you're using the default Tiktoken tokenizer, this is the name of the specific Tiktoken model to use. This setting is ignored if you provide your own tokenizer.&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;gpt-4o-mini&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;entity_extract_max_gleaning&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;int&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Number of loops in the entity extraction process, appending history messages&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;1&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;node_embedding_algorithm&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;str&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Algorithm for node embedding (currently not used)&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;node2vec&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;node2vec_params&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;dict&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Parameters for node embedding&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;{"dimensions": 1536,"num_walks": 10,"walk_length": 40,"window_size": 2,"iterations": 3,"random_seed": 3,}&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;embedding_func&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;EmbeddingFunc&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Function to generate embedding vectors from text&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;openai_embed&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;embedding_batch_num&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;int&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Maximum batch size for embedding processes (multiple texts sent per batch)&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;32&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;embedding_func_max_async&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;int&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Maximum number of concurrent asynchronous embedding processes&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;16&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;llm_model_func&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;callable&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Function for LLM generation&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;gpt_4o_mini_complete&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;llm_model_name&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;str&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;LLM model name for generation&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;meta-llama/Llama-3.2-1B-Instruct&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;summary_context_size&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;int&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Maximum tokens send to LLM to generate summaries for entity relation merging&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;10000&lt;/code&gt;ï¼ˆconfigured by env var SUMMARY_CONTEXT_SIZE)&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;summary_max_tokens&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;int&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Maximum token size for entity/relation description&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;500&lt;/code&gt;ï¼ˆconfigured by env var SUMMARY_MAX_TOKENS)&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;llm_model_max_async&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;int&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Maximum number of concurrent asynchronous LLM processes&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;4&lt;/code&gt;ï¼ˆdefault value changed by env var MAX_ASYNC)&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;llm_model_kwargs&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;dict&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Additional parameters for LLM generation&lt;/td&gt; 
    &lt;td&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;vector_db_storage_cls_kwargs&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;dict&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Additional parameters for vector database, like setting the threshold for nodes and relations retrieval&lt;/td&gt; 
    &lt;td&gt;cosine_better_than_threshold: 0.2ï¼ˆdefault value changed by env var COSINE_THRESHOLD)&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;enable_llm_cache&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;bool&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;If &lt;code&gt;TRUE&lt;/code&gt;, stores LLM results in cache; repeated prompts return cached responses&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;TRUE&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;enable_llm_cache_for_entity_extract&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;bool&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;If &lt;code&gt;TRUE&lt;/code&gt;, stores LLM results in cache for entity extraction; Good for beginners to debug your application&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;TRUE&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;addon_params&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;dict&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Additional parameters, e.g., &lt;code&gt;{"example_number": 1, "language": "Simplified Chinese", "entity_types": ["organization", "person", "geo", "event"]}&lt;/code&gt;: sets example limit, entiy/relation extraction output language&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;example_number: all examples, language: English&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;embedding_cache_config&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;dict&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Configuration for question-answer caching. Contains three parameters: &lt;code&gt;enabled&lt;/code&gt;: Boolean value to enable/disable cache lookup functionality. When enabled, the system will check cached responses before generating new answers. &lt;code&gt;similarity_threshold&lt;/code&gt;: Float value (0-1), similarity threshold. When a new question's similarity with a cached question exceeds this threshold, the cached answer will be returned directly without calling the LLM. &lt;code&gt;use_llm_check&lt;/code&gt;: Boolean value to enable/disable LLM similarity verification. When enabled, LLM will be used as a secondary check to verify the similarity between questions before returning cached answers.&lt;/td&gt; 
    &lt;td&gt;Default: &lt;code&gt;{"enabled": False, "similarity_threshold": 0.95, "use_llm_check": False}&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/details&gt; 
&lt;h3&gt;Query Param&lt;/h3&gt; 
&lt;p&gt;Use QueryParam to control the behavior your query:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;class QueryParam:
    """Configuration parameters for query execution in LightRAG."""

    mode: Literal["local", "global", "hybrid", "naive", "mix", "bypass"] = "global"
    """Specifies the retrieval mode:
    - "local": Focuses on context-dependent information.
    - "global": Utilizes global knowledge.
    - "hybrid": Combines local and global retrieval methods.
    - "naive": Performs a basic search without advanced techniques.
    - "mix": Integrates knowledge graph and vector retrieval.
    """

    only_need_context: bool = False
    """If True, only returns the retrieved context without generating a response."""

    only_need_prompt: bool = False
    """If True, only returns the generated prompt without producing a response."""

    response_type: str = "Multiple Paragraphs"
    """Defines the response format. Examples: 'Multiple Paragraphs', 'Single Paragraph', 'Bullet Points'."""

    stream: bool = False
    """If True, enables streaming output for real-time responses."""

    top_k: int = int(os.getenv("TOP_K", "60"))
    """Number of top items to retrieve. Represents entities in 'local' mode and relationships in 'global' mode."""

    chunk_top_k: int = int(os.getenv("CHUNK_TOP_K", "20"))
    """Number of text chunks to retrieve initially from vector search and keep after reranking.
    If None, defaults to top_k value.
    """

    max_entity_tokens: int = int(os.getenv("MAX_ENTITY_TOKENS", "6000"))
    """Maximum number of tokens allocated for entity context in unified token control system."""

    max_relation_tokens: int = int(os.getenv("MAX_RELATION_TOKENS", "8000"))
    """Maximum number of tokens allocated for relationship context in unified token control system."""

    max_total_tokens: int = int(os.getenv("MAX_TOTAL_TOKENS", "30000"))
    """Maximum total tokens budget for the entire query context (entities + relations + chunks + system prompt)."""

    conversation_history: list[dict[str, str]] = field(default_factory=list)
    """Stores past conversation history to maintain context.
    Format: [{"role": "user/assistant", "content": "message"}].
    """

    # Deprated: history message have negtive effect on query performance
    history_turns: int = 0
    """Number of complete conversation turns (user-assistant pairs) to consider in the response context."""

    ids: list[str] | None = None
    """List of ids to filter the results."""

    model_func: Callable[..., object] | None = None
    """Optional override for the LLM model function to use for this specific query.
    If provided, this will be used instead of the global model function.
    This allows using different models for different query modes.
    """

    user_prompt: str | None = None
    """User-provided prompt for the query.
    If proivded, this will be use instead of the default vaulue from prompt template.
    """

    enable_rerank: bool = True
    """Enable reranking for retrieved text chunks. If True but no rerank model is configured, a warning will be issued.
    Default is True to enable reranking when rerank model is available.
    """
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;default value of Top_k can be change by environment variables TOP_K.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;LLM and Embedding Injection&lt;/h3&gt; 
&lt;p&gt;LightRAG requires the utilization of LLM and Embedding models to accomplish document indexing and querying tasks. During the initialization phase, it is necessary to inject the invocation methods of the relevant models into LightRAGï¼š&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt; &lt;b&gt;Using Open AI-like APIs&lt;/b&gt; &lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;LightRAG also supports Open AI-like chat/embeddings APIs:&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;async def llm_model_func(
    prompt, system_prompt=None, history_messages=[], keyword_extraction=False, **kwargs
) -&amp;gt; str:
    return await openai_complete_if_cache(
        "solar-mini",
        prompt,
        system_prompt=system_prompt,
        history_messages=history_messages,
        api_key=os.getenv("UPSTAGE_API_KEY"),
        base_url="https://api.upstage.ai/v1/solar",
        **kwargs
    )

async def embedding_func(texts: list[str]) -&amp;gt; np.ndarray:
    return await openai_embed(
        texts,
        model="solar-embedding-1-large-query",
        api_key=os.getenv("UPSTAGE_API_KEY"),
        base_url="https://api.upstage.ai/v1/solar"
    )

async def initialize_rag():
    rag = LightRAG(
        working_dir=WORKING_DIR,
        llm_model_func=llm_model_func,
        embedding_func=EmbeddingFunc(
            embedding_dim=4096,
            func=embedding_func
        )
    )

    await rag.initialize_storages()
    await initialize_pipeline_status()

    return rag
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt; &lt;b&gt;Using Hugging Face Models&lt;/b&gt; &lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;If you want to use Hugging Face models, you only need to set LightRAG as follows:&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;See &lt;code&gt;lightrag_hf_demo.py&lt;/code&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;# Initialize LightRAG with Hugging Face model
rag = LightRAG(
    working_dir=WORKING_DIR,
    llm_model_func=hf_model_complete,  # Use Hugging Face model for text generation
    llm_model_name='meta-llama/Llama-3.1-8B-Instruct',  # Model name from Hugging Face
    # Use Hugging Face embedding function
    embedding_func=EmbeddingFunc(
        embedding_dim=384,
        func=lambda texts: hf_embed(
            texts,
            tokenizer=AutoTokenizer.from_pretrained("sentence-transformers/all-MiniLM-L6-v2"),
            embed_model=AutoModel.from_pretrained("sentence-transformers/all-MiniLM-L6-v2")
        )
    ),
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt; &lt;b&gt;Using Ollama Models&lt;/b&gt; &lt;/summary&gt; **Overview** 
 &lt;p&gt;If you want to use Ollama models, you need to pull model you plan to use and embedding model, for example &lt;code&gt;nomic-embed-text&lt;/code&gt;.&lt;/p&gt; 
 &lt;p&gt;Then you only need to set LightRAG as follows:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;# Initialize LightRAG with Ollama model
rag = LightRAG(
    working_dir=WORKING_DIR,
    llm_model_func=ollama_model_complete,  # Use Ollama model for text generation
    llm_model_name='your_model_name', # Your model name
    # Use Ollama embedding function
    embedding_func=EmbeddingFunc(
        embedding_dim=768,
        func=lambda texts: ollama_embed(
            texts,
            embed_model="nomic-embed-text"
        )
    ),
)
&lt;/code&gt;&lt;/pre&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;Increasing context size&lt;/strong&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;In order for LightRAG to work context should be at least 32k tokens. By default Ollama models have context size of 8k. You can achieve this using one of two ways:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;Increasing the &lt;code&gt;num_ctx&lt;/code&gt; parameter in Modelfile&lt;/strong&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;ol&gt; 
  &lt;li&gt;Pull the model:&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;ollama pull qwen2
&lt;/code&gt;&lt;/pre&gt; 
 &lt;ol start="2"&gt; 
  &lt;li&gt;Display the model file:&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;ollama show --modelfile qwen2 &amp;gt; Modelfile
&lt;/code&gt;&lt;/pre&gt; 
 &lt;ol start="3"&gt; 
  &lt;li&gt;Edit the Modelfile by adding the following line:&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;PARAMETER num_ctx 32768
&lt;/code&gt;&lt;/pre&gt; 
 &lt;ol start="4"&gt; 
  &lt;li&gt;Create the modified model:&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;ollama create -f Modelfile qwen2m
&lt;/code&gt;&lt;/pre&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;Setup &lt;code&gt;num_ctx&lt;/code&gt; via Ollama API&lt;/strong&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;Tiy can use &lt;code&gt;llm_model_kwargs&lt;/code&gt; param to configure ollama:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;rag = LightRAG(
    working_dir=WORKING_DIR,
    llm_model_func=ollama_model_complete,  # Use Ollama model for text generation
    llm_model_name='your_model_name', # Your model name
    llm_model_kwargs={"options": {"num_ctx": 32768}},
    # Use Ollama embedding function
    embedding_func=EmbeddingFunc(
        embedding_dim=768,
        func=lambda texts: ollama_embed(
            texts,
            embed_model="nomic-embed-text"
        )
    ),
)
&lt;/code&gt;&lt;/pre&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;Low RAM GPUs&lt;/strong&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;In order to run this experiment on low RAM GPU you should select small model and tune context window (increasing context increase memory consumption). For example, running this ollama example on repurposed mining GPU with 6Gb of RAM required to set context size to 26k while using &lt;code&gt;gemma2:2b&lt;/code&gt;. It was able to find 197 entities and 19 relations on &lt;code&gt;book.txt&lt;/code&gt;.&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt; &lt;b&gt;LlamaIndex&lt;/b&gt; &lt;/summary&gt; 
 &lt;p&gt;LightRAG supports integration with LlamaIndex (&lt;code&gt;llm/llama_index_impl.py&lt;/code&gt;):&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Integrates with OpenAI and other providers through LlamaIndex&lt;/li&gt; 
  &lt;li&gt;See &lt;a href="https://raw.githubusercontent.com/HKUDS/LightRAG/main/lightrag/llm/Readme.md"&gt;LlamaIndex Documentation&lt;/a&gt; for detailed setup and examples&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;Example Usage&lt;/strong&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;# Using LlamaIndex with direct OpenAI access
import asyncio
from lightrag import LightRAG
from lightrag.llm.llama_index_impl import llama_index_complete_if_cache, llama_index_embed
from llama_index.embeddings.openai import OpenAIEmbedding
from llama_index.llms.openai import OpenAI
from lightrag.kg.shared_storage import initialize_pipeline_status
from lightrag.utils import setup_logger

# Setup log handler for LightRAG
setup_logger("lightrag", level="INFO")

async def initialize_rag():
    rag = LightRAG(
        working_dir="your/path",
        llm_model_func=llama_index_complete_if_cache,  # LlamaIndex-compatible completion function
        embedding_func=EmbeddingFunc(    # LlamaIndex-compatible embedding function
            embedding_dim=1536,
            func=lambda texts: llama_index_embed(texts, embed_model=embed_model)
        ),
    )

    await rag.initialize_storages()
    await initialize_pipeline_status()

    return rag

def main():
    # Initialize RAG instance
    rag = asyncio.run(initialize_rag())

    with open("./book.txt", "r", encoding="utf-8") as f:
        rag.insert(f.read())

    # Perform naive search
    print(
        rag.query("What are the top themes in this story?", param=QueryParam(mode="naive"))
    )

    # Perform local search
    print(
        rag.query("What are the top themes in this story?", param=QueryParam(mode="local"))
    )

    # Perform global search
    print(
        rag.query("What are the top themes in this story?", param=QueryParam(mode="global"))
    )

    # Perform hybrid search
    print(
        rag.query("What are the top themes in this story?", param=QueryParam(mode="hybrid"))
    )

if __name__ == "__main__":
    main()
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;For detailed documentation and examples, see:&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/LightRAG/main/lightrag/llm/Readme.md"&gt;LlamaIndex Documentation&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/LightRAG/main/examples/lightrag_llamaindex_direct_demo.py"&gt;Direct OpenAI Example&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/LightRAG/main/examples/lightrag_llamaindex_litellm_demo.py"&gt;LiteLLM Proxy Example&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h3&gt;Rerank Function Injection&lt;/h3&gt; 
&lt;p&gt;To enhance retrieval quality, documents can be re-ranked based on a more effective relevance scoring model. The &lt;code&gt;rerank.py&lt;/code&gt; file provides three Reranker provider driver functions:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Cohere / vLLM&lt;/strong&gt;: &lt;code&gt;cohere_rerank&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Jina AI&lt;/strong&gt;: &lt;code&gt;jina_rerank&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Aliyun&lt;/strong&gt;: &lt;code&gt;ali_rerank&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;You can inject one of these functions into the &lt;code&gt;rerank_model_func&lt;/code&gt; attribute of the LightRAG object. This will enable LightRAG's query function to re-order retrieved text blocks using the injected function. For detailed usage, please refer to the &lt;code&gt;examples/rerank_example.py&lt;/code&gt; file.&lt;/p&gt; 
&lt;h3&gt;User Prompt vs. Query&lt;/h3&gt; 
&lt;p&gt;When using LightRAG for content queries, avoid combining the search process with unrelated output processing, as this significantly impacts query effectiveness. The &lt;code&gt;user_prompt&lt;/code&gt; parameter in Query Param is specifically designed to address this issue â€” it does not participate in the RAG retrieval phase, but rather guides the LLM on how to process the retrieved results after the query is completed. Here's how to use it:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# Create query parameters
query_param = QueryParam(
    mode = "hybrid",  # Other modesï¼šlocal, global, hybrid, mix, naive
    user_prompt = "For diagrams, use mermaid format with English/Pinyin node names and Chinese display labels",
)

# Query and process
response_default = rag.query(
    "Please draw a character relationship diagram for Scrooge",
    param=query_param
)
print(response_default)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Insert&lt;/h3&gt; 
&lt;details&gt; 
 &lt;summary&gt; &lt;b&gt; Basic Insert &lt;/b&gt;&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;# Basic Insert
rag.insert("Text")
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt; &lt;b&gt; Batch Insert &lt;/b&gt;&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;# Basic Batch Insert: Insert multiple texts at once
rag.insert(["TEXT1", "TEXT2",...])

# Batch Insert with custom batch size configuration
rag = LightRAG(
    ...
    working_dir=WORKING_DIR,
    max_parallel_insert = 4
)

rag.insert(["TEXT1", "TEXT2", "TEXT3", ...])  # Documents will be processed in batches of 4
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;The &lt;code&gt;max_parallel_insert&lt;/code&gt; parameter determines the number of documents processed concurrently in the document indexing pipeline. If unspecified, the default value is &lt;strong&gt;2&lt;/strong&gt;. We recommend keeping this setting &lt;strong&gt;below 10&lt;/strong&gt;, as the performance bottleneck typically lies with the LLM (Large Language Model) processing.The &lt;code&gt;max_parallel_insert&lt;/code&gt; parameter determines the number of documents processed concurrently in the document indexing pipeline. If unspecified, the default value is &lt;strong&gt;2&lt;/strong&gt;. We recommend keeping this setting &lt;strong&gt;below 10&lt;/strong&gt;, as the performance bottleneck typically lies with the LLM (Large Language Model) processing.&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt; &lt;b&gt; Insert with ID &lt;/b&gt;&lt;/summary&gt; 
 &lt;p&gt;If you want to provide your own IDs for your documents, number of documents and number of IDs must be the same.&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;# Insert single text, and provide ID for it
rag.insert("TEXT1", ids=["ID_FOR_TEXT1"])

# Insert multiple texts, and provide IDs for them
rag.insert(["TEXT1", "TEXT2",...], ids=["ID_FOR_TEXT1", "ID_FOR_TEXT2"])
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;b&gt;Insert using Pipeline&lt;/b&gt;&lt;/summary&gt; 
 &lt;p&gt;The &lt;code&gt;apipeline_enqueue_documents&lt;/code&gt; and &lt;code&gt;apipeline_process_enqueue_documents&lt;/code&gt; functions allow you to perform incremental insertion of documents into the graph.&lt;/p&gt; 
 &lt;p&gt;This is useful for scenarios where you want to process documents in the background while still allowing the main thread to continue executing.&lt;/p&gt; 
 &lt;p&gt;And using a routine to process new documents.&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;rag = LightRAG(..)

await rag.apipeline_enqueue_documents(input)
# Your routine in loop
await rag.apipeline_process_enqueue_documents(input)
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;b&gt;Insert Multi-file Type Support&lt;/b&gt;&lt;/summary&gt; 
 &lt;p&gt;The &lt;code&gt;textract&lt;/code&gt; supports reading file types such as TXT, DOCX, PPTX, CSV, and PDF.&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;import textract

file_path = 'TEXT.pdf'
text_content = textract.process(file_path)

rag.insert(text_content.decode('utf-8'))
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;b&gt;Citation Functionality&lt;/b&gt;&lt;/summary&gt; 
 &lt;p&gt;By providing file paths, the system ensures that sources can be traced back to their original documents.&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;# Define documents and their file paths
documents = ["Document content 1", "Document content 2"]
file_paths = ["path/to/doc1.txt", "path/to/doc2.txt"]

# Insert documents with file paths
rag.insert(documents, file_paths=file_paths)
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h3&gt;Storage&lt;/h3&gt; 
&lt;p&gt;LightRAG uses 4 types of storage for different purposes:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;KV_STORAGE: llm response cache, text chunks, document information&lt;/li&gt; 
 &lt;li&gt;VECTOR_STORAGE: entities vectors, relation vectors, chunks vectors&lt;/li&gt; 
 &lt;li&gt;GRAPH_STORAGE: entity relation graph&lt;/li&gt; 
 &lt;li&gt;DOC_STATUS_STORAGE: document indexing status&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Each storage type has several implementations:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;KV_STORAGE supported implementations:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code&gt;JsonKVStorage    JsonFile (default)
PGKVStorage      Postgres
RedisKVStorage   Redis
MongoKVStorage   MongoDB
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;GRAPH_STORAGE supported implementations:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code&gt;NetworkXStorage      NetworkX (default)
Neo4JStorage         Neo4J
PGGraphStorage       PostgreSQL with AGE plugin
MemgraphStorage.     Memgraph
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Testing has shown that Neo4J delivers superior performance in production environments compared to PostgreSQL with AGE plugin.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;VECTOR_STORAGE supported implementations:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code&gt;NanoVectorDBStorage         NanoVector (default)
PGVectorStorage             Postgres
MilvusVectorDBStorage       Milvus
FaissVectorDBStorage        Faiss
QdrantVectorDBStorage       Qdrant
MongoVectorDBStorage        MongoDB
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;DOC_STATUS_STORAGE: supported implementations:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code&gt;JsonDocStatusStorage        JsonFile (default)
PGDocStatusStorage          Postgres
MongoDocStatusStorage       MongoDB
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Example connection configurations for each storage type can be found in the &lt;code&gt;env.example&lt;/code&gt; file. The database instance in the connection string needs to be created by you on the database server beforehand. LightRAG is only responsible for creating tables within the database instance, not for creating the database instance itself. If using Redis as storage, remember to configure automatic data persistence rules for Redis, otherwise data will be lost after the Redis service restarts. If using PostgreSQL, it is recommended to use version 16.6 or above.&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt; &lt;b&gt;Using Neo4J Storage&lt;/b&gt; &lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;For production level scenarios you will most likely want to leverage an enterprise solution&lt;/li&gt; 
  &lt;li&gt;for KG storage. Running Neo4J in Docker is recommended for seamless local testing.&lt;/li&gt; 
  &lt;li&gt;See: &lt;a href="https://hub.docker.com/_/neo4j"&gt;https://hub.docker.com/_/neo4j&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;export NEO4J_URI="neo4j://localhost:7687"
export NEO4J_USERNAME="neo4j"
export NEO4J_PASSWORD="password"

# Setup logger for LightRAG
setup_logger("lightrag", level="INFO")

# When you launch the project be sure to override the default KG: NetworkX
# by specifying kg="Neo4JStorage".

# Note: Default settings use NetworkX
# Initialize LightRAG with Neo4J implementation.
async def initialize_rag():
    rag = LightRAG(
        working_dir=WORKING_DIR,
        llm_model_func=gpt_4o_mini_complete,  # Use gpt_4o_mini_complete LLM model
        graph_storage="Neo4JStorage", #&amp;lt;-----------override KG default
    )

    # Initialize database connections
    await rag.initialize_storages()
    # Initialize pipeline status for document processing
    await initialize_pipeline_status()

    return rag
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;see test_neo4j.py for a working example.&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt; &lt;b&gt;Using PostgreSQL Storage&lt;/b&gt; &lt;/summary&gt; 
 &lt;p&gt;For production level scenarios you will most likely want to leverage an enterprise solution. PostgreSQL can provide a one-stop solution for you as KV store, VectorDB (pgvector) and GraphDB (apache AGE). PostgreSQL version 16.6 or higher is supported.&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;PostgreSQL is lightweight,the whole binary distribution including all necessary plugins can be zipped to 40MB: Ref to &lt;a href="https://github.com/ShanGor/apache-age-windows/releases/tag/PG17%2Fv1.5.0-rc0"&gt;Windows Release&lt;/a&gt; as it is easy to install for Linux/Mac.&lt;/li&gt; 
  &lt;li&gt;If you prefer docker, please start with this image if you are a beginner to avoid hiccups (DO read the overview): &lt;a href="https://hub.docker.com/r/shangor/postgres-for-rag"&gt;https://hub.docker.com/r/shangor/postgres-for-rag&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;How to start? Ref to: &lt;a href="https://github.com/HKUDS/LightRAG/raw/main/examples/lightrag_zhipu_postgres_demo.py"&gt;examples/lightrag_zhipu_postgres_demo.py&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;For high-performance graph database requirements, Neo4j is recommended as Apache AGE's performance is not as competitive.&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt; &lt;b&gt;Using Faiss Storage&lt;/b&gt; &lt;/summary&gt; Before using Faiss vector database, you must manually install `faiss-cpu` or `faiss-gpu`. 
 &lt;ul&gt; 
  &lt;li&gt;Install the required dependencies:&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;pre&gt;&lt;code&gt;pip install faiss-cpu
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;You can also install &lt;code&gt;faiss-gpu&lt;/code&gt; if you have GPU support.&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Here we are using &lt;code&gt;sentence-transformers&lt;/code&gt; but you can also use &lt;code&gt;OpenAIEmbedding&lt;/code&gt; model with &lt;code&gt;3072&lt;/code&gt; dimensions.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;async def embedding_func(texts: list[str]) -&amp;gt; np.ndarray:
    model = SentenceTransformer('all-MiniLM-L6-v2')
    embeddings = model.encode(texts, convert_to_numpy=True)
    return embeddings

# Initialize LightRAG with the LLM model function and embedding function
rag = LightRAG(
    working_dir=WORKING_DIR,
    llm_model_func=llm_model_func,
    embedding_func=EmbeddingFunc(
        embedding_dim=384,
        func=embedding_func,
    ),
    vector_storage="FaissVectorDBStorage",
    vector_db_storage_cls_kwargs={
        "cosine_better_than_threshold": 0.3  # Your desired threshold
    }
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt; &lt;b&gt;Using Memgraph for Storage&lt;/b&gt; &lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Memgraph is a high-performance, in-memory graph database compatible with the Neo4j Bolt protocol.&lt;/li&gt; 
  &lt;li&gt;You can run Memgraph locally using Docker for easy testing:&lt;/li&gt; 
  &lt;li&gt;See: &lt;a href="https://memgraph.com/download"&gt;https://memgraph.com/download&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;export MEMGRAPH_URI="bolt://localhost:7687"

# Setup logger for LightRAG
setup_logger("lightrag", level="INFO")

# When you launch the project, override the default KG: NetworkX
# by specifying kg="MemgraphStorage".

# Note: Default settings use NetworkX
# Initialize LightRAG with Memgraph implementation.
async def initialize_rag():
    rag = LightRAG(
        working_dir=WORKING_DIR,
        llm_model_func=gpt_4o_mini_complete,  # Use gpt_4o_mini_complete LLM model
        graph_storage="MemgraphStorage", #&amp;lt;-----------override KG default
    )

    # Initialize database connections
    await rag.initialize_storages()
    # Initialize pipeline status for document processing
    await initialize_pipeline_status()

    return rag
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt; &lt;b&gt;Using MongoDB Storage&lt;/b&gt; &lt;/summary&gt; 
 &lt;p&gt;MongoDB provides a one-stop storage solution for LightRAG. MongoDB offers native KV storage and vector storage. LightRAG uses MongoDB collections to implement a simple graph storage. MongoDB's official vector search functionality (&lt;code&gt;$vectorSearch&lt;/code&gt;) currently requires their official cloud service MongoDB Atlas. This functionality cannot be used on self-hosted MongoDB Community/Enterprise versions.&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt; &lt;b&gt;Using Redis Storage&lt;/b&gt; &lt;/summary&gt; 
 &lt;p&gt;LightRAG supports using Redis as KV storage. When using Redis storage, attention should be paid to persistence configuration and memory usage configuration. The following is the recommended Redis configuration:&lt;/p&gt; 
 &lt;pre&gt;&lt;code&gt;save 900 1
save 300 10
save 60 1000
stop-writes-on-bgsave-error yes
maxmemory 4gb
maxmemory-policy noeviction
maxclients 500
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h3&gt;Data Isolation Between LightRAG Instances&lt;/h3&gt; 
&lt;p&gt;The &lt;code&gt;workspace&lt;/code&gt; parameter ensures data isolation between different LightRAG instances. Once initialized, the &lt;code&gt;workspace&lt;/code&gt; is immutable and cannot be changed.Here is how workspaces are implemented for different types of storage:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;For local file-based databases, data isolation is achieved through workspace subdirectories:&lt;/strong&gt; &lt;code&gt;JsonKVStorage&lt;/code&gt;, &lt;code&gt;JsonDocStatusStorage&lt;/code&gt;, &lt;code&gt;NetworkXStorage&lt;/code&gt;, &lt;code&gt;NanoVectorDBStorage&lt;/code&gt;, &lt;code&gt;FaissVectorDBStorage&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;For databases that store data in collections, it's done by adding a workspace prefix to the collection name:&lt;/strong&gt; &lt;code&gt;RedisKVStorage&lt;/code&gt;, &lt;code&gt;RedisDocStatusStorage&lt;/code&gt;, &lt;code&gt;MilvusVectorDBStorage&lt;/code&gt;, &lt;code&gt;QdrantVectorDBStorage&lt;/code&gt;, &lt;code&gt;MongoKVStorage&lt;/code&gt;, &lt;code&gt;MongoDocStatusStorage&lt;/code&gt;, &lt;code&gt;MongoVectorDBStorage&lt;/code&gt;, &lt;code&gt;MongoGraphStorage&lt;/code&gt;, &lt;code&gt;PGGraphStorage&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;For relational databases, data isolation is achieved by adding a &lt;code&gt;workspace&lt;/code&gt; field to the tables for logical data separation:&lt;/strong&gt; &lt;code&gt;PGKVStorage&lt;/code&gt;, &lt;code&gt;PGVectorStorage&lt;/code&gt;, &lt;code&gt;PGDocStatusStorage&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;For the Neo4j graph database, logical data isolation is achieved through labels:&lt;/strong&gt; &lt;code&gt;Neo4JStorage&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;To maintain compatibility with legacy data, the default workspace for PostgreSQL non-graph storage is &lt;code&gt;default&lt;/code&gt; and, for PostgreSQL AGE graph storage is null, for Neo4j graph storage is &lt;code&gt;base&lt;/code&gt; when no workspace is configured. For all external storages, the system provides dedicated workspace environment variables to override the common &lt;code&gt;WORKSPACE&lt;/code&gt; environment variable configuration. These storage-specific workspace environment variables are: &lt;code&gt;REDIS_WORKSPACE&lt;/code&gt;, &lt;code&gt;MILVUS_WORKSPACE&lt;/code&gt;, &lt;code&gt;QDRANT_WORKSPACE&lt;/code&gt;, &lt;code&gt;MONGODB_WORKSPACE&lt;/code&gt;, &lt;code&gt;POSTGRES_WORKSPACE&lt;/code&gt;, &lt;code&gt;NEO4J_WORKSPACE&lt;/code&gt;.&lt;/p&gt; 
&lt;h2&gt;Edit Entities and Relations&lt;/h2&gt; 
&lt;p&gt;LightRAG now supports comprehensive knowledge graph management capabilities, allowing you to create, edit, and delete entities and relationships within your knowledge graph.&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt; &lt;b&gt; Create Entities and Relations &lt;/b&gt;&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;# Create new entity
entity = rag.create_entity("Google", {
    "description": "Google is a multinational technology company specializing in internet-related services and products.",
    "entity_type": "company"
})

# Create another entity
product = rag.create_entity("Gmail", {
    "description": "Gmail is an email service developed by Google.",
    "entity_type": "product"
})

# Create relation between entities
relation = rag.create_relation("Google", "Gmail", {
    "description": "Google develops and operates Gmail.",
    "keywords": "develops operates service",
    "weight": 2.0
})
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt; &lt;b&gt; Edit Entities and Relations &lt;/b&gt;&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;# Edit an existing entity
updated_entity = rag.edit_entity("Google", {
    "description": "Google is a subsidiary of Alphabet Inc., founded in 1998.",
    "entity_type": "tech_company"
})

# Rename an entity (with all its relationships properly migrated)
renamed_entity = rag.edit_entity("Gmail", {
    "entity_name": "Google Mail",
    "description": "Google Mail (formerly Gmail) is an email service."
})

# Edit a relation between entities
updated_relation = rag.edit_relation("Google", "Google Mail", {
    "description": "Google created and maintains Google Mail service.",
    "keywords": "creates maintains email service",
    "weight": 3.0
})
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;All operations are available in both synchronous and asynchronous versions. The asynchronous versions have the prefix "a" (e.g., &lt;code&gt;acreate_entity&lt;/code&gt;, &lt;code&gt;aedit_relation&lt;/code&gt;).&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt; &lt;b&gt; Insert Custom KG &lt;/b&gt;&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;custom_kg = {
        "chunks": [
            {
                "content": "Alice and Bob are collaborating on quantum computing research.",
                "source_id": "doc-1",
                "file_path": "test_file",
            }
        ],
        "entities": [
            {
                "entity_name": "Alice",
                "entity_type": "person",
                "description": "Alice is a researcher specializing in quantum physics.",
                "source_id": "doc-1",
                "file_path": "test_file"
            },
            {
                "entity_name": "Bob",
                "entity_type": "person",
                "description": "Bob is a mathematician.",
                "source_id": "doc-1",
                "file_path": "test_file"
            },
            {
                "entity_name": "Quantum Computing",
                "entity_type": "technology",
                "description": "Quantum computing utilizes quantum mechanical phenomena for computation.",
                "source_id": "doc-1",
                "file_path": "test_file"
            }
        ],
        "relationships": [
            {
                "src_id": "Alice",
                "tgt_id": "Bob",
                "description": "Alice and Bob are research partners.",
                "keywords": "collaboration research",
                "weight": 1.0,
                "source_id": "doc-1",
                "file_path": "test_file"
            },
            {
                "src_id": "Alice",
                "tgt_id": "Quantum Computing",
                "description": "Alice conducts research on quantum computing.",
                "keywords": "research expertise",
                "weight": 1.0,
                "source_id": "doc-1",
                "file_path": "test_file"
            },
            {
                "src_id": "Bob",
                "tgt_id": "Quantum Computing",
                "description": "Bob researches quantum computing.",
                "keywords": "research application",
                "weight": 1.0,
                "source_id": "doc-1",
                "file_path": "test_file"
            }
        ]
    }

rag.insert_custom_kg(custom_kg)
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt; &lt;b&gt;Other Entity and Relation Operations&lt;/b&gt;&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;create_entity&lt;/strong&gt;: Creates a new entity with specified attributes&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;edit_entity&lt;/strong&gt;: Updates an existing entity's attributes or renames it&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;create_relation&lt;/strong&gt;: Creates a new relation between existing entities&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;edit_relation&lt;/strong&gt;: Updates an existing relation's attributes&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;These operations maintain data consistency across both the graph database and vector database components, ensuring your knowledge graph remains coherent.&lt;/p&gt; 
&lt;/details&gt; 
&lt;h2&gt;Delete Functions&lt;/h2&gt; 
&lt;p&gt;LightRAG provides comprehensive deletion capabilities, allowing you to delete documents, entities, and relationships.&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt; &lt;b&gt;Delete Entities&lt;/b&gt; &lt;/summary&gt; 
 &lt;p&gt;You can delete entities by their name along with all associated relationships:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;# Delete entity and all its relationships (synchronous version)
rag.delete_by_entity("Google")

# Asynchronous version
await rag.adelete_by_entity("Google")
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;When deleting an entity:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Removes the entity node from the knowledge graph&lt;/li&gt; 
  &lt;li&gt;Deletes all associated relationships&lt;/li&gt; 
  &lt;li&gt;Removes related embedding vectors from the vector database&lt;/li&gt; 
  &lt;li&gt;Maintains knowledge graph integrity&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt; &lt;b&gt;Delete Relations&lt;/b&gt; &lt;/summary&gt; 
 &lt;p&gt;You can delete relationships between two specific entities:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;# Delete relationship between two entities (synchronous version)
rag.delete_by_relation("Google", "Gmail")

# Asynchronous version
await rag.adelete_by_relation("Google", "Gmail")
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;When deleting a relationship:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Removes the specified relationship edge&lt;/li&gt; 
  &lt;li&gt;Deletes the relationship's embedding vector from the vector database&lt;/li&gt; 
  &lt;li&gt;Preserves both entity nodes and their other relationships&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt; &lt;b&gt;Delete by Document ID&lt;/b&gt; &lt;/summary&gt; 
 &lt;p&gt;You can delete an entire document and all its related knowledge through document ID:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;# Delete by document ID (asynchronous version)
await rag.adelete_by_doc_id("doc-12345")
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Optimized processing when deleting by document ID:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;Smart Cleanup&lt;/strong&gt;: Automatically identifies and removes entities and relationships that belong only to this document&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Preserve Shared Knowledge&lt;/strong&gt;: If entities or relationships exist in other documents, they are preserved and their descriptions are rebuilt&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Cache Optimization&lt;/strong&gt;: Clears related LLM cache to reduce storage overhead&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Incremental Rebuilding&lt;/strong&gt;: Reconstructs affected entity and relationship descriptions from remaining documents&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;The deletion process includes:&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;Delete all text chunks related to the document&lt;/li&gt; 
  &lt;li&gt;Identify and delete entities and relationships that belong only to this document&lt;/li&gt; 
  &lt;li&gt;Rebuild entities and relationships that still exist in other documents&lt;/li&gt; 
  &lt;li&gt;Update all related vector indexes&lt;/li&gt; 
  &lt;li&gt;Clean up document status records&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;p&gt;Note: Deletion by document ID is an asynchronous operation as it involves complex knowledge graph reconstruction processes.&lt;/p&gt; 
&lt;/details&gt; 
&lt;p&gt;&lt;strong&gt;Important Reminders:&lt;/strong&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Irreversible Operations&lt;/strong&gt;: All deletion operations are irreversible, please use with caution&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Performance Considerations&lt;/strong&gt;: Deleting large amounts of data may take some time, especially deletion by document ID&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Data Consistency&lt;/strong&gt;: Deletion operations automatically maintain consistency between the knowledge graph and vector database&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Backup Recommendations&lt;/strong&gt;: Consider backing up data before performing important deletion operations&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;Batch Deletion Recommendations:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;For batch deletion operations, consider using asynchronous methods for better performance&lt;/li&gt; 
 &lt;li&gt;For large-scale deletions, consider processing in batches to avoid excessive system load&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Entity Merging&lt;/h2&gt; 
&lt;details&gt; 
 &lt;summary&gt; &lt;b&gt;Merge Entities and Their Relationships&lt;/b&gt; &lt;/summary&gt; 
 &lt;p&gt;LightRAG now supports merging multiple entities into a single entity, automatically handling all relationships:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;# Basic entity merging
rag.merge_entities(
    source_entities=["Artificial Intelligence", "AI", "Machine Intelligence"],
    target_entity="AI Technology"
)
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;With custom merge strategy:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;# Define custom merge strategy for different fields
rag.merge_entities(
    source_entities=["John Smith", "Dr. Smith", "J. Smith"],
    target_entity="John Smith",
    merge_strategy={
        "description": "concatenate",  # Combine all descriptions
        "entity_type": "keep_first",   # Keep the entity type from the first entity
        "source_id": "join_unique"     # Combine all unique source IDs
    }
)
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;With custom target entity data:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;# Specify exact values for the merged entity
rag.merge_entities(
    source_entities=["New York", "NYC", "Big Apple"],
    target_entity="New York City",
    target_entity_data={
        "entity_type": "LOCATION",
        "description": "New York City is the most populous city in the United States.",
    }
)
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Advanced usage combining both approaches:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;# Merge company entities with both strategy and custom data
rag.merge_entities(
    source_entities=["Microsoft Corp", "Microsoft Corporation", "MSFT"],
    target_entity="Microsoft",
    merge_strategy={
        "description": "concatenate",  # Combine all descriptions
        "source_id": "join_unique"     # Combine source IDs
    },
    target_entity_data={
        "entity_type": "ORGANIZATION",
    }
)
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;When merging entities:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;All relationships from source entities are redirected to the target entity&lt;/li&gt; 
  &lt;li&gt;Duplicate relationships are intelligently merged&lt;/li&gt; 
  &lt;li&gt;Self-relationships (loops) are prevented&lt;/li&gt; 
  &lt;li&gt;Source entities are removed after merging&lt;/li&gt; 
  &lt;li&gt;Relationship weights and attributes are preserved&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;Multimodal Document Processing (RAG-Anything Integration)&lt;/h2&gt; 
&lt;p&gt;LightRAG now seamlessly integrates with &lt;a href="https://github.com/HKUDS/RAG-Anything"&gt;RAG-Anything&lt;/a&gt;, a comprehensive &lt;strong&gt;All-in-One Multimodal Document Processing RAG system&lt;/strong&gt; built specifically for LightRAG. RAG-Anything enables advanced parsing and retrieval-augmented generation (RAG) capabilities, allowing you to handle multimodal documents seamlessly and extract structured contentâ€”including text, images, tables, and formulasâ€”from various document formats for integration into your RAG pipeline.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Key Features:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;End-to-End Multimodal Pipeline&lt;/strong&gt;: Complete workflow from document ingestion and parsing to intelligent multimodal query answering&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Universal Document Support&lt;/strong&gt;: Seamless processing of PDFs, Office documents (DOC/DOCX/PPT/PPTX/XLS/XLSX), images, and diverse file formats&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Specialized Content Analysis&lt;/strong&gt;: Dedicated processors for images, tables, mathematical equations, and heterogeneous content types&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Multimodal Knowledge Graph&lt;/strong&gt;: Automatic entity extraction and cross-modal relationship discovery for enhanced understanding&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Hybrid Intelligent Retrieval&lt;/strong&gt;: Advanced search capabilities spanning textual and multimodal content with contextual understanding&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Quick Start:&lt;/strong&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Install RAG-Anything:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;pip install raganything
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Process multimodal documents:&lt;/p&gt; 
  &lt;details&gt; 
   &lt;summary&gt; &lt;b&gt; RAGAnything Usage Example &lt;/b&gt;&lt;/summary&gt; 
   &lt;pre&gt;&lt;code class="language-python"&gt;    import asyncio
    from raganything import RAGAnything
    from lightrag import LightRAG
    from lightrag.llm.openai import openai_complete_if_cache, openai_embed
    from lightrag.utils import EmbeddingFunc
    import os

    async def load_existing_lightrag():
        # First, create or load an existing LightRAG instance
        lightrag_working_dir = "./existing_lightrag_storage"

        # Check if previous LightRAG instance exists
        if os.path.exists(lightrag_working_dir) and os.listdir(lightrag_working_dir):
            print("âœ… Found existing LightRAG instance, loading...")
        else:
            print("âŒ No existing LightRAG instance found, will create new one")

        # Create/Load LightRAG instance with your configurations
        lightrag_instance = LightRAG(
            working_dir=lightrag_working_dir,
            llm_model_func=lambda prompt, system_prompt=None, history_messages=[], **kwargs: openai_complete_if_cache(
                "gpt-4o-mini",
                prompt,
                system_prompt=system_prompt,
                history_messages=history_messages,
                api_key="your-api-key",
                **kwargs,
            ),
            embedding_func=EmbeddingFunc(
                embedding_dim=3072,
                func=lambda texts: openai_embed(
                    texts,
                    model="text-embedding-3-large",
                    api_key=api_key,
                    base_url=base_url,
                ),
            )
        )

        # Initialize storage (this will load existing data if available)
        await lightrag_instance.initialize_storages()

        # Now initialize RAGAnything with the existing LightRAG instance
        rag = RAGAnything(
            lightrag=lightrag_instance,  # Pass the existing LightRAG instance
            # Only need vision model for multimodal processing
            vision_model_func=lambda prompt, system_prompt=None, history_messages=[], image_data=None, **kwargs: openai_complete_if_cache(
                "gpt-4o",
                "",
                system_prompt=None,
                history_messages=[],
                messages=[
                    {"role": "system", "content": system_prompt} if system_prompt else None,
                    {"role": "user", "content": [
                        {"type": "text", "text": prompt},
                        {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{image_data}"}}
                    ]} if image_data else {"role": "user", "content": prompt}
                ],
                api_key="your-api-key",
                **kwargs,
            ) if image_data else openai_complete_if_cache(
                "gpt-4o-mini",
                prompt,
                system_prompt=system_prompt,
                history_messages=history_messages,
                api_key="your-api-key",
                **kwargs,
            )
            # Note: working_dir, llm_model_func, embedding_func, etc. are inherited from lightrag_instance
        )

        # Query the existing knowledge base
        result = await rag.query_with_multimodal(
            "What data has been processed in this LightRAG instance?",
            mode="hybrid"
        )
        print("Query result:", result)

        # Add new multimodal documents to the existing LightRAG instance
        await rag.process_document_complete(
            file_path="path/to/new/multimodal_document.pdf",
            output_dir="./output"
        )

    if __name__ == "__main__":
        asyncio.run(load_existing_lightrag())
&lt;/code&gt;&lt;/pre&gt; 
  &lt;/details&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;For detailed documentation and advanced usage, please refer to the &lt;a href="https://github.com/HKUDS/RAG-Anything"&gt;RAG-Anything repository&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Token Usage Tracking&lt;/h2&gt; 
&lt;details&gt; 
 &lt;summary&gt; &lt;b&gt;Overview and Usage&lt;/b&gt; &lt;/summary&gt; 
 &lt;p&gt;LightRAG provides a TokenTracker tool to monitor and manage token consumption by large language models. This feature is particularly useful for controlling API costs and optimizing performance.&lt;/p&gt; 
 &lt;h3&gt;Usage&lt;/h3&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;from lightrag.utils import TokenTracker

# Create TokenTracker instance
token_tracker = TokenTracker()

# Method 1: Using context manager (Recommended)
# Suitable for scenarios requiring automatic token usage tracking
with token_tracker:
    result1 = await llm_model_func("your question 1")
    result2 = await llm_model_func("your question 2")

# Method 2: Manually adding token usage records
# Suitable for scenarios requiring more granular control over token statistics
token_tracker.reset()

rag.insert()

rag.query("your question 1", param=QueryParam(mode="naive"))
rag.query("your question 2", param=QueryParam(mode="mix"))

# Display total token usage (including insert and query operations)
print("Token usage:", token_tracker.get_usage())
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h3&gt;Usage Tips&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Use context managers for long sessions or batch operations to automatically track all token consumption&lt;/li&gt; 
  &lt;li&gt;For scenarios requiring segmented statistics, use manual mode and call reset() when appropriate&lt;/li&gt; 
  &lt;li&gt;Regular checking of token usage helps detect abnormal consumption early&lt;/li&gt; 
  &lt;li&gt;Actively use this feature during development and testing to optimize production costs&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Practical Examples&lt;/h3&gt; 
 &lt;p&gt;You can refer to these examples for implementing token tracking:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;code&gt;examples/lightrag_gemini_track_token_demo.py&lt;/code&gt;: Token tracking example using Google Gemini model&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;examples/lightrag_siliconcloud_track_token_demo.py&lt;/code&gt;: Token tracking example using SiliconCloud model&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;These examples demonstrate how to effectively use the TokenTracker feature with different models and scenarios.&lt;/p&gt; 
&lt;/details&gt; 
&lt;h2&gt;Data Export Functions&lt;/h2&gt; 
&lt;h3&gt;Overview&lt;/h3&gt; 
&lt;p&gt;LightRAG allows you to export your knowledge graph data in various formats for analysis, sharing, and backup purposes. The system supports exporting entities, relations, and relationship data.&lt;/p&gt; 
&lt;h3&gt;Export Functions&lt;/h3&gt; 
&lt;details&gt; 
 &lt;summary&gt; &lt;b&gt; Basic Usage &lt;/b&gt;&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;# Basic CSV export (default format)
rag.export_data("knowledge_graph.csv")

# Specify any format
rag.export_data("output.xlsx", file_format="excel")
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt; &lt;b&gt; Different File Formats supported &lt;/b&gt;&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;#Export data in CSV format
rag.export_data("graph_data.csv", file_format="csv")

# Export data in Excel sheet
rag.export_data("graph_data.xlsx", file_format="excel")

# Export data in markdown format
rag.export_data("graph_data.md", file_format="md")

# Export data in Text
rag.export_data("graph_data.txt", file_format="txt")
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt; &lt;b&gt; Additional Options &lt;/b&gt;&lt;/summary&gt; 
 &lt;p&gt;Include vector embeddings in the export (optional):&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;rag.export_data("complete_data.csv", include_vector_data=True)
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h3&gt;Data Included in Export&lt;/h3&gt; 
&lt;p&gt;All exports include:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Entity information (names, IDs, metadata)&lt;/li&gt; 
 &lt;li&gt;Relation data (connections between entities)&lt;/li&gt; 
 &lt;li&gt;Relationship information from vector database&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Cache&lt;/h2&gt; 
&lt;details&gt; 
 &lt;summary&gt; &lt;b&gt;Clear Cache&lt;/b&gt; &lt;/summary&gt; 
 &lt;p&gt;You can clear the LLM response cache with different modes:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;# Clear all cache
await rag.aclear_cache()

# Clear local mode cache
await rag.aclear_cache(modes=["local"])

# Clear extraction cache
await rag.aclear_cache(modes=["default"])

# Clear multiple modes
await rag.aclear_cache(modes=["local", "global", "hybrid"])

# Synchronous version
rag.clear_cache(modes=["local"])
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Valid modes are:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;code&gt;"default"&lt;/code&gt;: Extraction cache&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;"naive"&lt;/code&gt;: Naive search cache&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;"local"&lt;/code&gt;: Local search cache&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;"global"&lt;/code&gt;: Global search cache&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;"hybrid"&lt;/code&gt;: Hybrid search cache&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;"mix"&lt;/code&gt;: Mix search cache&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;Troubleshooting&lt;/h2&gt; 
&lt;h3&gt;Common Initialization Errors&lt;/h3&gt; 
&lt;p&gt;If you encounter these errors when using LightRAG:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;AttributeError: __aenter__&lt;/code&gt;&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Cause&lt;/strong&gt;: Storage backends not initialized&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Solution&lt;/strong&gt;: Call &lt;code&gt;await rag.initialize_storages()&lt;/code&gt; after creating the LightRAG instance&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;KeyError: 'history_messages'&lt;/code&gt;&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Cause&lt;/strong&gt;: Pipeline status not initialized&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Solution&lt;/strong&gt;: Call &lt;code&gt;await initialize_pipeline_status()&lt;/code&gt; after initializing storages&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Both errors in sequence&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Cause&lt;/strong&gt;: Neither initialization method was called&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Solution&lt;/strong&gt;: Always follow this pattern:&lt;/li&gt; 
  &lt;/ul&gt; &lt;pre&gt;&lt;code class="language-python"&gt;rag = LightRAG(...)
await rag.initialize_storages()
await initialize_pipeline_status()
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Model Switching Issues&lt;/h3&gt; 
&lt;p&gt;When switching between different embedding models, you must clear the data directory to avoid errors. The only file you may want to preserve is &lt;code&gt;kv_store_llm_response_cache.json&lt;/code&gt; if you wish to retain the LLM cache.&lt;/p&gt; 
&lt;h2&gt;LightRAG API&lt;/h2&gt; 
&lt;p&gt;The LightRAG Server is designed to provide Web UI and API support. &lt;strong&gt;For more information about LightRAG Server, please refer to &lt;a href="https://raw.githubusercontent.com/HKUDS/LightRAG/main/lightrag/api/README.md"&gt;LightRAG Server&lt;/a&gt;.&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;Graph Visualization&lt;/h2&gt; 
&lt;p&gt;The LightRAG Server offers a comprehensive knowledge graph visualization feature. It supports various gravity layouts, node queries, subgraph filtering, and more. &lt;strong&gt;For more information about LightRAG Server, please refer to &lt;a href="https://raw.githubusercontent.com/HKUDS/LightRAG/main/lightrag/api/README.md"&gt;LightRAG Server&lt;/a&gt;.&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/HKUDS/LightRAG/main/README.assets/iShot_2025-03-23_12.40.08.png" alt="iShot_2025-03-23_12.40.08" /&gt;&lt;/p&gt; 
&lt;h2&gt;Evaluation&lt;/h2&gt; 
&lt;h3&gt;Dataset&lt;/h3&gt; 
&lt;p&gt;The dataset used in LightRAG can be downloaded from &lt;a href="https://huggingface.co/datasets/TommyChien/UltraDomain"&gt;TommyChien/UltraDomain&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Generate Query&lt;/h3&gt; 
&lt;p&gt;LightRAG uses the following prompt to generate high-level queries, with the corresponding code in &lt;code&gt;example/generate_query.py&lt;/code&gt;.&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt; Prompt &lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;Given the following description of a dataset:

{description}

Please identify 5 potential users who would engage with this dataset. For each user, list 5 tasks they would perform with this dataset. Then, for each (user, task) combination, generate 5 questions that require a high-level understanding of the entire dataset.

Output the results in the following structure:
- User 1: [user description]
    - Task 1: [task description]
        - Question 1:
        - Question 2:
        - Question 3:
        - Question 4:
        - Question 5:
    - Task 2: [task description]
        ...
    - Task 5: [task description]
- User 2: [user description]
    ...
- User 5: [user description]
    ...
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h3&gt;Batch Eval&lt;/h3&gt; 
&lt;p&gt;To evaluate the performance of two RAG systems on high-level queries, LightRAG uses the following prompt, with the specific code available in &lt;code&gt;reproduce/batch_eval.py&lt;/code&gt;.&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt; Prompt &lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;---Role---
You are an expert tasked with evaluating two answers to the same question based on three criteria: **Comprehensiveness**, **Diversity**, and **Empowerment**.
---Goal---
You will evaluate two answers to the same question based on three criteria: **Comprehensiveness**, **Diversity**, and **Empowerment**.

- **Comprehensiveness**: How much detail does the answer provide to cover all aspects and details of the question?
- **Diversity**: How varied and rich is the answer in providing different perspectives and insights on the question?
- **Empowerment**: How well does the answer help the reader understand and make informed judgments about the topic?

For each criterion, choose the better answer (either Answer 1 or Answer 2) and explain why. Then, select an overall winner based on these three categories.

Here is the question:
{query}

Here are the two answers:

**Answer 1:**
{answer1}

**Answer 2:**
{answer2}

Evaluate both answers using the three criteria listed above and provide detailed explanations for each criterion.

Output your evaluation in the following JSON format:

{{
    "Comprehensiveness": {{
        "Winner": "[Answer 1 or Answer 2]",
        "Explanation": "[Provide explanation here]"
    }},
    "Empowerment": {{
        "Winner": "[Answer 1 or Answer 2]",
        "Explanation": "[Provide explanation here]"
    }},
    "Overall Winner": {{
        "Winner": "[Answer 1 or Answer 2]",
        "Explanation": "[Summarize why this answer is the overall winner based on the three criteria]"
    }}
}}
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h3&gt;Overall Performance Table&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;strong&gt;Agriculture&lt;/strong&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;strong&gt;CS&lt;/strong&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;strong&gt;Legal&lt;/strong&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;strong&gt;Mix&lt;/strong&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;NaiveRAG&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;LightRAG&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;NaiveRAG&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;LightRAG&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;NaiveRAG&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;LightRAG&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;NaiveRAG&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;LightRAG&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Comprehensiveness&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;32.4%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;67.6%&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;38.4%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;61.6%&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;16.4%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;83.6%&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;38.8%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;61.2%&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Diversity&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;23.6%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;76.4%&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;38.0%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;62.0%&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;13.6%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;86.4%&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;32.4%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;67.6%&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Empowerment&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;32.4%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;67.6%&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;38.8%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;61.2%&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;16.4%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;83.6%&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;42.8%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;57.2%&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Overall&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;32.4%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;67.6%&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;38.8%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;61.2%&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;15.2%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;84.8%&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;40.0%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;60.0%&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;RQ-RAG&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;LightRAG&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;RQ-RAG&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;LightRAG&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;RQ-RAG&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;LightRAG&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;RQ-RAG&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;LightRAG&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Comprehensiveness&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;31.6%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;68.4%&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;38.8%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;61.2%&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;15.2%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;84.8%&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;39.2%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;60.8%&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Diversity&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;29.2%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;70.8%&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;39.2%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;60.8%&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;11.6%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;88.4%&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;30.8%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;69.2%&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Empowerment&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;31.6%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;68.4%&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;36.4%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;63.6%&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;15.2%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;84.8%&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;42.4%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;57.6%&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Overall&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;32.4%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;67.6%&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;38.0%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;62.0%&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;14.4%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;85.6%&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;40.0%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;60.0%&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;HyDE&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;LightRAG&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;HyDE&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;LightRAG&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;HyDE&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;LightRAG&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;HyDE&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;LightRAG&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Comprehensiveness&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;26.0%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;74.0%&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;41.6%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;58.4%&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;26.8%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;73.2%&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;40.4%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;59.6%&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Diversity&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;24.0%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;76.0%&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;38.8%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;61.2%&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;20.0%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;80.0%&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;32.4%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;67.6%&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Empowerment&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;25.2%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;74.8%&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;40.8%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;59.2%&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;26.0%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;74.0%&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;46.0%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;54.0%&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Overall&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;24.8%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;75.2%&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;41.6%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;58.4%&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;26.4%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;73.6%&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;42.4%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;57.6%&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;GraphRAG&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;LightRAG&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;GraphRAG&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;LightRAG&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;GraphRAG&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;LightRAG&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;GraphRAG&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;LightRAG&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Comprehensiveness&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;45.6%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;54.4%&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;48.4%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;51.6%&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;48.4%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;51.6%&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;50.4%&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;49.6%&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Diversity&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;22.8%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;77.2%&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;40.8%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;59.2%&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;26.4%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;73.6%&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;36.0%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;64.0%&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Empowerment&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;41.2%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;58.8%&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;45.2%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;54.8%&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;43.6%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;56.4%&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;50.8%&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;49.2%&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Overall&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;45.2%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;54.8%&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;48.0%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;52.0%&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;47.2%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;52.8%&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;50.4%&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;49.6%&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Reproduce&lt;/h2&gt; 
&lt;p&gt;All the code can be found in the &lt;code&gt;./reproduce&lt;/code&gt; directory.&lt;/p&gt; 
&lt;h3&gt;Step-0 Extract Unique Contexts&lt;/h3&gt; 
&lt;p&gt;First, we need to extract unique contexts in the datasets.&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt; Code &lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;def extract_unique_contexts(input_directory, output_directory):

    os.makedirs(output_directory, exist_ok=True)

    jsonl_files = glob.glob(os.path.join(input_directory, '*.jsonl'))
    print(f"Found {len(jsonl_files)} JSONL files.")

    for file_path in jsonl_files:
        filename = os.path.basename(file_path)
        name, ext = os.path.splitext(filename)
        output_filename = f"{name}_unique_contexts.json"
        output_path = os.path.join(output_directory, output_filename)

        unique_contexts_dict = {}

        print(f"Processing file: {filename}")

        try:
            with open(file_path, 'r', encoding='utf-8') as infile:
                for line_number, line in enumerate(infile, start=1):
                    line = line.strip()
                    if not line:
                        continue
                    try:
                        json_obj = json.loads(line)
                        context = json_obj.get('context')
                        if context and context not in unique_contexts_dict:
                            unique_contexts_dict[context] = None
                    except json.JSONDecodeError as e:
                        print(f"JSON decoding error in file {filename} at line {line_number}: {e}")
        except FileNotFoundError:
            print(f"File not found: {filename}")
            continue
        except Exception as e:
            print(f"An error occurred while processing file {filename}: {e}")
            continue

        unique_contexts_list = list(unique_contexts_dict.keys())
        print(f"There are {len(unique_contexts_list)} unique `context` entries in the file {filename}.")

        try:
            with open(output_path, 'w', encoding='utf-8') as outfile:
                json.dump(unique_contexts_list, outfile, ensure_ascii=False, indent=4)
            print(f"Unique `context` entries have been saved to: {output_filename}")
        except Exception as e:
            print(f"An error occurred while saving to the file {output_filename}: {e}")

    print("All files have been processed.")

&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h3&gt;Step-1 Insert Contexts&lt;/h3&gt; 
&lt;p&gt;For the extracted contexts, we insert them into the LightRAG system.&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt; Code &lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;def insert_text(rag, file_path):
    with open(file_path, mode='r') as f:
        unique_contexts = json.load(f)

    retries = 0
    max_retries = 3
    while retries &amp;lt; max_retries:
        try:
            rag.insert(unique_contexts)
            break
        except Exception as e:
            retries += 1
            print(f"Insertion failed, retrying ({retries}/{max_retries}), error: {e}")
            time.sleep(10)
    if retries == max_retries:
        print("Insertion failed after exceeding the maximum number of retries")
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h3&gt;Step-2 Generate Queries&lt;/h3&gt; 
&lt;p&gt;We extract tokens from the first and the second half of each context in the dataset, then combine them as dataset descriptions to generate queries.&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt; Code &lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;tokenizer = GPT2Tokenizer.from_pretrained('gpt2')

def get_summary(context, tot_tokens=2000):
    tokens = tokenizer.tokenize(context)
    half_tokens = tot_tokens // 2

    start_tokens = tokens[1000:1000 + half_tokens]
    end_tokens = tokens[-(1000 + half_tokens):1000]

    summary_tokens = start_tokens + end_tokens
    summary = tokenizer.convert_tokens_to_string(summary_tokens)

    return summary
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h3&gt;Step-3 Query&lt;/h3&gt; 
&lt;p&gt;For the queries generated in Step-2, we will extract them and query LightRAG.&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt; Code &lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;def extract_queries(file_path):
    with open(file_path, 'r') as f:
        data = f.read()

    data = data.replace('**', '')

    queries = re.findall(r'- Question \d+: (.+)', data)

    return queries
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h2&gt;ğŸ”— Related Projects&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Ecosystem &amp;amp; Extensions&lt;/em&gt;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;table&gt; 
  &lt;tbody&gt;
   &lt;tr&gt; 
    &lt;td align="center"&gt; &lt;a href="https://github.com/HKUDS/RAG-Anything"&gt; 
      &lt;div style="width: 100px; height: 100px; background: linear-gradient(135deg, rgba(0, 217, 255, 0.1) 0%, rgba(0, 217, 255, 0.05) 100%); border-radius: 15px; border: 1px solid rgba(0, 217, 255, 0.2); display: flex; align-items: center; justify-content: center; margin-bottom: 10px;"&gt; 
       &lt;span style="font-size: 32px;"&gt;ğŸ“¸&lt;/span&gt; 
      &lt;/div&gt; &lt;b&gt;RAG-Anything&lt;/b&gt;&lt;br /&gt; &lt;sub&gt;Multimodal RAG&lt;/sub&gt; &lt;/a&gt; &lt;/td&gt; 
    &lt;td align="center"&gt; &lt;a href="https://github.com/HKUDS/VideoRAG"&gt; 
      &lt;div style="width: 100px; height: 100px; background: linear-gradient(135deg, rgba(0, 217, 255, 0.1) 0%, rgba(0, 217, 255, 0.05) 100%); border-radius: 15px; border: 1px solid rgba(0, 217, 255, 0.2); display: flex; align-items: center; justify-content: center; margin-bottom: 10px;"&gt; 
       &lt;span style="font-size: 32px;"&gt;ğŸ¥&lt;/span&gt; 
      &lt;/div&gt; &lt;b&gt;VideoRAG&lt;/b&gt;&lt;br /&gt; &lt;sub&gt;Extreme Long-Context Video RAG&lt;/sub&gt; &lt;/a&gt; &lt;/td&gt; 
    &lt;td align="center"&gt; &lt;a href="https://github.com/HKUDS/MiniRAG"&gt; 
      &lt;div style="width: 100px; height: 100px; background: linear-gradient(135deg, rgba(0, 217, 255, 0.1) 0%, rgba(0, 217, 255, 0.05) 100%); border-radius: 15px; border: 1px solid rgba(0, 217, 255, 0.2); display: flex; align-items: center; justify-content: center; margin-bottom: 10px;"&gt; 
       &lt;span style="font-size: 32px;"&gt;âœ¨&lt;/span&gt; 
      &lt;/div&gt; &lt;b&gt;MiniRAG&lt;/b&gt;&lt;br /&gt; &lt;sub&gt;Extremely Simple RAG&lt;/sub&gt; &lt;/a&gt; &lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt;
 &lt;/table&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h2&gt;â­ Star History&lt;/h2&gt; 
&lt;a href="https://star-history.com/#HKUDS/LightRAG&amp;amp;Date"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://api.star-history.com/svg?repos=HKUDS/LightRAG&amp;amp;type=Date&amp;amp;theme=dark" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://api.star-history.com/svg?repos=HKUDS/LightRAG&amp;amp;type=Date" /&gt; 
  &lt;img alt="Star History Chart" src="https://api.star-history.com/svg?repos=HKUDS/LightRAG&amp;amp;type=Date" /&gt; 
 &lt;/picture&gt; &lt;/a&gt; 
&lt;h2&gt;ğŸ¤ Contribution&lt;/h2&gt; 
&lt;div align="center"&gt;
  We thank all our contributors for their valuable contributions. 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://github.com/HKUDS/LightRAG/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=HKUDS/LightRAG" style="border-radius: 15px; box-shadow: 0 0 20px rgba(0, 217, 255, 0.3);" /&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ğŸ“– Citation&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;@article{guo2024lightrag,
title={LightRAG: Simple and Fast Retrieval-Augmented Generation},
author={Zirui Guo and Lianghao Xia and Yanhua Yu and Tu Ao and Chao Huang},
year={2024},
eprint={2410.05779},
archivePrefix={arXiv},
primaryClass={cs.IR}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;div align="center" style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); border-radius: 15px; padding: 30px; margin: 30px 0;"&gt; 
 &lt;div&gt; 
  &lt;img src="https://user-images.githubusercontent.com/74038190/212284100-561aa473-3905-4a80-b561-0d28506553ee.gif" width="500" /&gt; 
 &lt;/div&gt; 
 &lt;div style="margin-top: 20px;"&gt; 
  &lt;a href="https://github.com/HKUDS/LightRAG" style="text-decoration: none;"&gt; &lt;img src="https://img.shields.io/badge/â­%20Star%20us%20on%20GitHub-1a1a2e?style=for-the-badge&amp;amp;logo=github&amp;amp;logoColor=white" /&gt; &lt;/a&gt; 
  &lt;a href="https://github.com/HKUDS/LightRAG/issues" style="text-decoration: none;"&gt; &lt;img src="https://img.shields.io/badge/ğŸ›%20Report%20Issues-ff6b6b?style=for-the-badge&amp;amp;logo=github&amp;amp;logoColor=white" /&gt; &lt;/a&gt; 
  &lt;a href="https://github.com/HKUDS/LightRAG/discussions" style="text-decoration: none;"&gt; &lt;img src="https://img.shields.io/badge/ğŸ’¬%20Discussions-4ecdc4?style=for-the-badge&amp;amp;logo=github&amp;amp;logoColor=white" /&gt; &lt;/a&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;div style="width: 100%; max-width: 600px; margin: 20px auto; padding: 20px; background: linear-gradient(135deg, rgba(0, 217, 255, 0.1) 0%, rgba(0, 217, 255, 0.05) 100%); border-radius: 15px; border: 1px solid rgba(0, 217, 255, 0.2);"&gt; 
  &lt;div style="display: flex; justify-content: center; align-items: center; gap: 15px;"&gt; 
   &lt;span style="font-size: 24px;"&gt;â­&lt;/span&gt; 
   &lt;span style="color: #00d9ff; font-size: 18px;"&gt;Thank you for visiting LightRAG!&lt;/span&gt; 
   &lt;span style="font-size: 24px;"&gt;â­&lt;/span&gt; 
  &lt;/div&gt; 
 &lt;/div&gt; 
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>exo-explore/exo</title>
      <link>https://github.com/exo-explore/exo</link>
      <description>&lt;p&gt;Run your own AI cluster at home with everyday devices ğŸ“±ğŸ’» ğŸ–¥ï¸âŒš&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="/docs/exo-logo-black-bg.jpg" /&gt; 
  &lt;img alt="exo logo" src="https://raw.githubusercontent.com/exo-explore/exo/main/docs/exo-logo-transparent.png" width="50%" height="50%" /&gt; 
 &lt;/picture&gt; 
 &lt;p&gt;exo: Run your own AI cluster at home with everyday devices. Maintained by &lt;a href="https://x.com/exolabs"&gt;exo labs&lt;/a&gt;.&lt;/p&gt; 
 &lt;h3&gt; &lt;p&gt;&lt;a href="https://discord.gg/EUnjGpsmWw"&gt;Discord&lt;/a&gt; | &lt;a href="https://t.me/+Kh-KqHTzFYg3MGNk"&gt;Telegram&lt;/a&gt; | &lt;a href="https://x.com/exolabs"&gt;X&lt;/a&gt;&lt;/p&gt; &lt;/h3&gt; 
 &lt;p&gt;&lt;a href="https://github.com/exo-explore/exo/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/exo-explore/exo" alt="GitHub Repo stars" /&gt;&lt;/a&gt; &lt;a href="https://dl.circleci.com/status-badge/redirect/circleci/TrkofJDoGzdQAeL6yVHKsg/4i5hJuafuwZYZQxbRAWS71/tree/main"&gt;&lt;img src="https://dl.circleci.com/status-badge/img/circleci/TrkofJDoGzdQAeL6yVHKsg/4i5hJuafuwZYZQxbRAWS71/tree/main.svg?style=svg" alt="Tests" /&gt;&lt;/a&gt; &lt;a href="https://www.gnu.org/licenses/gpl-3.0"&gt;&lt;img src="https://img.shields.io/badge/License-GPLv3-blue.svg?sanitize=true" alt="License: GPL v3" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://trendshift.io/repositories/11849" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/11849" alt="exo-explore%2Fexo | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;p&gt;Unify your existing devices into one powerful GPU: iPhone, iPad, Android, Mac, NVIDIA, Raspberry Pi, pretty much any device!&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;h2&gt;Update: exo is hiring. See &lt;a href="https://exolabs.net"&gt;here&lt;/a&gt; for more details.&lt;/h2&gt; 
 &lt;h2&gt;Interested in running exo in your business? &lt;a href="mailto:hello@exolabs.net"&gt;Contact us&lt;/a&gt; to discuss.&lt;/h2&gt; 
&lt;/div&gt; 
&lt;h2&gt;Get Involved&lt;/h2&gt; 
&lt;p&gt;exo is &lt;strong&gt;experimental&lt;/strong&gt; software. Expect bugs early on. Create issues so they can be fixed. The &lt;a href="https://x.com/exolabs"&gt;exo labs&lt;/a&gt; team will strive to resolve issues quickly.&lt;/p&gt; 
&lt;p&gt;We also welcome contributions from the community. We have a list of bounties in &lt;a href="https://docs.google.com/spreadsheets/d/1cTCpTIp48UnnIvHeLEUNg1iMy_Q6lRybgECSFCoVJpE/edit?usp=sharing"&gt;this sheet&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;h3&gt;Wide Model Support&lt;/h3&gt; 
&lt;p&gt;exo supports different models including LLaMA (&lt;a href="https://raw.githubusercontent.com/exo-explore/exo/main/exo/inference/mlx/models/llama.py"&gt;MLX&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/exo-explore/exo/main/exo/inference/tinygrad/models/llama.py"&gt;tinygrad&lt;/a&gt;), Mistral, LlaVA, Qwen, and Deepseek.&lt;/p&gt; 
&lt;h3&gt;Dynamic Model Partitioning&lt;/h3&gt; 
&lt;p&gt;exo &lt;a href="https://raw.githubusercontent.com/exo-explore/exo/main/exo/topology/ring_memory_weighted_partitioning_strategy.py"&gt;optimally splits up models&lt;/a&gt; based on the current network topology and device resources available. This enables you to run larger models than you would be able to on any single device.&lt;/p&gt; 
&lt;h3&gt;Automatic Device Discovery&lt;/h3&gt; 
&lt;p&gt;exo will &lt;a href="https://github.com/exo-explore/exo/raw/945f90f676182a751d2ad7bcf20987ab7fe0181e/exo/orchestration/node.py#L154"&gt;automatically discover&lt;/a&gt; other devices using the best method available. Zero manual configuration.&lt;/p&gt; 
&lt;h3&gt;ChatGPT-compatible API&lt;/h3&gt; 
&lt;p&gt;exo provides a &lt;a href="https://raw.githubusercontent.com/exo-explore/exo/main/exo/api/chatgpt_api.py"&gt;ChatGPT-compatible API&lt;/a&gt; for running models. It's a &lt;a href="https://raw.githubusercontent.com/exo-explore/exo/main/examples/chatgpt_api.sh"&gt;one-line change&lt;/a&gt; in your application to run models on your own hardware using exo.&lt;/p&gt; 
&lt;h3&gt;Device Equality&lt;/h3&gt; 
&lt;p&gt;Unlike other distributed inference frameworks, exo does not use a master-worker architecture. Instead, exo devices &lt;a href="https://github.com/exo-explore/exo/raw/945f90f676182a751d2ad7bcf20987ab7fe0181e/exo/orchestration/node.py#L161"&gt;connect p2p&lt;/a&gt;. As long as a device is connected somewhere in the network, it can be used to run models.&lt;/p&gt; 
&lt;p&gt;Exo supports different &lt;a href="https://raw.githubusercontent.com/exo-explore/exo/main/exo/topology/partitioning_strategy.py"&gt;partitioning strategies&lt;/a&gt; to split up a model across devices. The default partitioning strategy is &lt;a href="https://raw.githubusercontent.com/exo-explore/exo/main/exo/topology/ring_memory_weighted_partitioning_strategy.py"&gt;ring memory weighted partitioning&lt;/a&gt;. This runs an inference in a ring where each device runs a number of model layers proportional to the memory of the device.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/exo-explore/exo/main/docs/exo-screenshot.jpg" alt="&amp;quot;A screenshot of exo running 5 nodes" /&gt;&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;The current recommended way to install exo is from source.&lt;/p&gt; 
&lt;h3&gt;Prerequisites&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Python&amp;gt;=3.12.0 is required because of &lt;a href="https://github.com/exo-explore/exo/issues/5"&gt;issues with asyncio&lt;/a&gt; in previous versions.&lt;/li&gt; 
 &lt;li&gt;For Linux with NVIDIA GPU support (Linux-only, skip if not using Linux or NVIDIA): 
  &lt;ul&gt; 
   &lt;li&gt;NVIDIA driver - verify with &lt;code&gt;nvidia-smi&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;CUDA toolkit - install from &lt;a href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#cuda-cross-platform-installation"&gt;NVIDIA CUDA guide&lt;/a&gt;, verify with &lt;code&gt;nvcc --version&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;cuDNN library - download from &lt;a href="https://developer.nvidia.com/cudnn-downloads"&gt;NVIDIA cuDNN page&lt;/a&gt;, verify installation by following &lt;a href="https://docs.nvidia.com/deeplearning/cudnn/latest/installation/linux.html#verifying-the-install-on-linux:~:text=at%20a%20time.-,Verifying%20the%20Install%20on%20Linux,Test%20passed!,-Upgrading%20From%20Older"&gt;these steps&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Hardware Requirements&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;The only requirement to run exo is to have enough memory across all your devices to fit the entire model into memory. For example, if you are running llama 3.1 8B (fp16), you need 16GB of memory across all devices. Any of the following configurations would work since they each have more than 16GB of memory in total: 
  &lt;ul&gt; 
   &lt;li&gt;2 x 8GB M3 MacBook Airs&lt;/li&gt; 
   &lt;li&gt;1 x 16GB NVIDIA RTX 4070 Ti Laptop&lt;/li&gt; 
   &lt;li&gt;2 x Raspberry Pi 400 with 4GB of RAM each (running on CPU) + 1 x 8GB Mac Mini&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;exo is designed to run on devices with heterogeneous capabilities. For example, you can have some devices with powerful GPUs and others with integrated GPUs or even CPUs. Adding less capable devices will slow down individual inference latency but will increase the overall throughput of the cluster.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;From source&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;git clone https://github.com/exo-explore/exo.git
cd exo
pip install -e .
# alternatively, with venv
source install.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Troubleshooting&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;If running on Mac, MLX has an &lt;a href="https://ml-explore.github.io/mlx/build/html/install.html"&gt;install guide&lt;/a&gt; with troubleshooting steps.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Performance&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;There are a number of things users have empirically found to improve performance on Apple Silicon Macs:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;ol&gt; 
 &lt;li&gt;Upgrade to the latest version of macOS Sequoia.&lt;/li&gt; 
 &lt;li&gt;Run &lt;code&gt;./configure_mlx.sh&lt;/code&gt;. This runs commands to optimize GPU memory allocation on Apple Silicon Macs.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;h3&gt;Example Usage on Multiple macOS Devices&lt;/h3&gt; 
&lt;h4&gt;Device 1:&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;exo
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Device 2:&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;exo
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;That's it! No configuration required - exo will automatically discover the other device(s).&lt;/p&gt; 
&lt;p&gt;exo starts a ChatGPT-like WebUI (powered by &lt;a href="https://github.com/tinygrad/tinygrad/tree/master/examples/tinychat"&gt;tinygrad tinychat&lt;/a&gt;) on &lt;a href="http://localhost:52415"&gt;http://localhost:52415&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;For developers, exo also starts a ChatGPT-compatible API endpoint on &lt;a href="http://localhost:52415/v1/chat/completions"&gt;http://localhost:52415/v1/chat/completions&lt;/a&gt;. Examples with curl:&lt;/p&gt; 
&lt;h4&gt;Llama 3.2 3B:&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;curl http://localhost:52415/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
     "model": "llama-3.2-3b",
     "messages": [{"role": "user", "content": "What is the meaning of exo?"}],
     "temperature": 0.7
   }'
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Llama 3.1 405B:&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;curl http://localhost:52415/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
     "model": "llama-3.1-405b",
     "messages": [{"role": "user", "content": "What is the meaning of exo?"}],
     "temperature": 0.7
   }'
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;DeepSeek R1 (full 671B):&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;curl http://localhost:52415/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
     "model": "deepseek-r1",
     "messages": [{"role": "user", "content": "What is the meaning of exo?"}],
     "temperature": 0.7
   }'
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Llava 1.5 7B (Vision Language Model):&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;curl http://localhost:52415/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
     "model": "llava-1.5-7b-hf",
     "messages": [
      {
        "role": "user",
        "content": [
          {
            "type": "text",
            "text": "What are these?"
          },
          {
            "type": "image_url",
            "image_url": {
              "url": "http://images.cocodataset.org/val2017/000000039769.jpg"
            }
          }
        ]
      }
    ],
     "temperature": 0.0
   }'
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Example Usage on Multiple Heterogenous Devices (macOS + Linux)&lt;/h3&gt; 
&lt;h4&gt;Device 1 (macOS):&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;exo
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Note: We don't need to explicitly tell exo to use the &lt;strong&gt;tinygrad&lt;/strong&gt; inference engine. &lt;strong&gt;MLX&lt;/strong&gt; and &lt;strong&gt;tinygrad&lt;/strong&gt; are interoperable!&lt;/p&gt; 
&lt;h4&gt;Device 2 (Linux):&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;exo
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Linux devices will automatically default to using the &lt;strong&gt;tinygrad&lt;/strong&gt; inference engine.&lt;/p&gt; 
&lt;p&gt;You can read about tinygrad-specific env vars &lt;a href="https://docs.tinygrad.org/env_vars/"&gt;here&lt;/a&gt;. For example, you can configure tinygrad to use the cpu by specifying &lt;code&gt;CLANG=1&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;Example Usage on a single device with "exo run" command&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;exo run llama-3.2-3b
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;With a custom prompt:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;exo run llama-3.2-3b --prompt "What is the meaning of exo?"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Model Storage&lt;/h3&gt; 
&lt;p&gt;Models by default are stored in &lt;code&gt;~/.cache/exo/downloads&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;You can set a different model storage location by setting the &lt;code&gt;EXO_HOME&lt;/code&gt; env var.&lt;/p&gt; 
&lt;h2&gt;Model Downloading&lt;/h2&gt; 
&lt;p&gt;Models are downloaded from Hugging Face. If you are running exo in a country with strict internet censorship, you may need to download the models manually and put them in the &lt;code&gt;~/.cache/exo/downloads&lt;/code&gt; directory.&lt;/p&gt; 
&lt;p&gt;To download models from a proxy endpoint, set the &lt;code&gt;HF_ENDPOINT&lt;/code&gt; environment variable. For example, to run exo with the huggingface mirror endpoint:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;HF_ENDPOINT=https://hf-mirror.com exo
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Debugging&lt;/h2&gt; 
&lt;p&gt;Enable debug logs with the DEBUG environment variable (0-9).&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;DEBUG=9 exo
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For the &lt;strong&gt;tinygrad&lt;/strong&gt; inference engine specifically, there is a separate DEBUG flag &lt;code&gt;TINYGRAD_DEBUG&lt;/code&gt; that can be used to enable debug logs (1-6).&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;TINYGRAD_DEBUG=2 exo
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Formatting&lt;/h2&gt; 
&lt;p&gt;We use &lt;a href="https://github.com/google/yapf"&gt;yapf&lt;/a&gt; to format the code. To format the code, first install the formatting requirements:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;pip3 install -e '.[formatting]'
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then run the formatting script:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;python3 format.py ./exo
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Known Issues&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;On certain versions of Python on macOS, certificates may not installed correctly, potentially causing SSL errors (e.g., when accessing huggingface.co). To resolve this, run the &lt;code&gt;Install Certificates&lt;/code&gt; command, typicall as follows:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;/Applications/Python 3.x/Install Certificates.command
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;ğŸš§ As the library is evolving so quickly, the iOS implementation has fallen behind Python. We have decided for now not to put out the buggy iOS version and receive a bunch of GitHub issues for outdated code. We are working on solving this properly and will make an announcement when it's ready. If you would like access to the iOS implementation now, please email &lt;a href="mailto:alex@exolabs.net"&gt;alex@exolabs.net&lt;/a&gt; with your GitHub username explaining your use-case and you will be granted access on GitHub.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Inference Engines&lt;/h2&gt; 
&lt;p&gt;exo supports the following inference engines:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;âœ… &lt;a href="https://raw.githubusercontent.com/exo-explore/exo/main/exo/inference/mlx/sharded_inference_engine.py"&gt;MLX&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;âœ… &lt;a href="https://raw.githubusercontent.com/exo-explore/exo/main/exo/inference/tinygrad/inference.py"&gt;tinygrad&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;ğŸš§ &lt;a href="https://github.com/exo-explore/exo/pull/139"&gt;PyTorch&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;ğŸš§ &lt;a href="https://github.com/exo-explore/exo/issues/167"&gt;llama.cpp&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Discovery Modules&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;âœ… &lt;a href="https://raw.githubusercontent.com/exo-explore/exo/main/exo/networking/udp"&gt;UDP&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;âœ… &lt;a href="https://raw.githubusercontent.com/exo-explore/exo/main/exo/networking/manual"&gt;Manual&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;âœ… &lt;a href="https://raw.githubusercontent.com/exo-explore/exo/main/exo/networking/tailscale"&gt;Tailscale&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;ğŸš§ Radio&lt;/li&gt; 
 &lt;li&gt;ğŸš§ Bluetooth&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Peer Networking Modules&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;âœ… &lt;a href="https://raw.githubusercontent.com/exo-explore/exo/main/exo/networking/grpc"&gt;GRPC&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;ğŸš§ NCCL&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>aliasrobotics/cai</title>
      <link>https://github.com/aliasrobotics/cai</link>
      <description>&lt;p&gt;Cybersecurity AI (CAI), the framework for AI Security&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Cybersecurity AI (&lt;code&gt;CAI&lt;/code&gt;)&lt;/h1&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt; &lt;a align="center" href="" target="https://github.com/aliasrobotics/CAI"&gt; &lt;img width="100%" src="https://github.com/aliasrobotics/cai/raw/main/media/cai.png" /&gt; &lt;/a&gt; &lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://badge.fury.io/py/cai-framework"&gt;&lt;img src="https://badge.fury.io/py/cai-framework.svg?sanitize=true" alt="version" /&gt;&lt;/a&gt; &lt;a href="https://pepy.tech/projects/cai-framework"&gt;&lt;img src="https://static.pepy.tech/badge/cai-framework" alt="downloads" /&gt;&lt;/a&gt; &lt;a href="https://github.com/aliasrobotics/cai"&gt;&lt;img src="https://img.shields.io/badge/Linux-Supported-brightgreen?logo=linux&amp;amp;logoColor=white" alt="Linux" /&gt;&lt;/a&gt; &lt;a href="https://github.com/aliasrobotics/cai"&gt;&lt;img src="https://img.shields.io/badge/OS%20X-Supported-brightgreen?logo=apple&amp;amp;logoColor=white" alt="OS X" /&gt;&lt;/a&gt; &lt;a href="https://github.com/aliasrobotics/cai"&gt;&lt;img src="https://img.shields.io/badge/Windows-Supported-brightgreen?logo=windows&amp;amp;logoColor=white" alt="Windows" /&gt;&lt;/a&gt; &lt;a href="https://github.com/aliasrobotics/cai"&gt;&lt;img src="https://img.shields.io/badge/Android-Supported-brightgreen?logo=android&amp;amp;logoColor=white" alt="Android" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/fnUFcTaQAC"&gt;&lt;img src="https://img.shields.io/badge/Discord-7289DA?logo=discord&amp;amp;logoColor=white" alt="Discord" /&gt;&lt;/a&gt; &lt;a href="https://arxiv.org/pdf/2504.06017"&gt;&lt;img src="https://img.shields.io/badge/arXiv-2504.06017-b31b1b.svg?sanitize=true" alt="arXiv" /&gt;&lt;/a&gt; &lt;a href="https://arxiv.org/abs/2506.23592"&gt;&lt;img src="https://img.shields.io/badge/arXiv-2506.23592-b31b1b.svg?sanitize=true" alt="arXiv" /&gt;&lt;/a&gt; &lt;a href="https://arxiv.org/abs/2508.13588"&gt;&lt;img src="https://img.shields.io/badge/arXiv-2508.13588-b31b1b.svg?sanitize=true" alt="arXiv" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;Cybersecurity AI (CAI) is a lightweight, open-source framework that empowers security professionals to build and deploy AI-powered offensive and defensive automation. CAI is the &lt;em&gt;de facto&lt;/em&gt; framework for AI Security, already used by thousands of individual users and hundreds of organizations. Whether you're a security researcher, ethical hacker, IT professional, or organization looking to enhance your security posture, CAI provides the building blocks to create specialized AI agents that can assist with mitigation, vulnerability discovery, exploitation, and security assessment.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Key Features:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;ğŸ¤– &lt;strong&gt;300+ AI Models&lt;/strong&gt;: Support for OpenAI, Anthropic, DeepSeek, Ollama, and more&lt;/li&gt; 
 &lt;li&gt;ğŸ”§ &lt;strong&gt;Built-in Security Tools&lt;/strong&gt;: Ready-to-use tools for reconnaissance, exploitation, and privilege escalation&lt;/li&gt; 
 &lt;li&gt;ğŸ† &lt;strong&gt;Battle-tested&lt;/strong&gt;: Proven in HackTheBox CTFs, bug bounties, and real-world security &lt;a href="https://aliasrobotics.com/case-studies-robot-cybersecurity.php"&gt;case studies&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;ğŸ¯ &lt;strong&gt;Agent-based Architecture&lt;/strong&gt;: Modular framework design to build specialized agents for different security tasks&lt;/li&gt; 
 &lt;li&gt;ğŸ›¡ï¸ &lt;strong&gt;Guardrails Protection&lt;/strong&gt;: Built-in defenses against prompt injection and dangerous command execution&lt;/li&gt; 
 &lt;li&gt;ğŸ“š &lt;strong&gt;Research-oriented&lt;/strong&gt;: Research foundation to democratize cybersecurity AI for the community&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] Read the technical report: &lt;a href="https://arxiv.org/pdf/2504.06017"&gt;CAI: An Open, Bug Bounty-Ready Cybersecurity AI&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;For further readings, refer to our &lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#-impact"&gt;impact&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#citation"&gt;CAI citation&lt;/a&gt; sections.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;&lt;a href="https://aliasrobotics.com/case-study-ecoforest.php"&gt;&lt;code&gt;OT&lt;/code&gt; - CAI and alias0 on: Ecoforest Heat Pumps&lt;/a&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;a href="https://aliasrobotics.com/case-study-cai-mir.php"&gt;&lt;code&gt;Robotics&lt;/code&gt; - CAI and alias0 on: Mobile Industrial Robots (MiR)&lt;/a&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;CAI discovers critical vulnerability in Ecoforest heat pumps allowing unauthorized remote access and potential catastrophic failures. AI-powered security testing reveals exposed credentials and DES encryption weaknesses affecting all of their deployed units across Europe.&lt;/td&gt; 
   &lt;td&gt;CAI-powered security testing of MiR (Mobile Industrial Robot) platform through automated ROS message injection attacks. This study demonstrates how AI-driven vulnerability discovery can expose unauthorized access to robot control systems and alarm triggers.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://aliasrobotics.com/case-study-ecoforest.php"&gt;&lt;img src="https://aliasrobotics.com/img/case-study-portada-ecoforest.png" alt="" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aliasrobotics.com/case-study-cai-mir.php"&gt;&lt;img src="https://aliasrobotics.com/img/case-study-portada-mir-cai.png" alt="" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;&lt;a href="https://aliasrobotics.com/case-study-mercado-libre.php"&gt;&lt;code&gt;IT&lt;/code&gt; (Web) - CAI and alias0 on: Mercado Libre's e-commerce&lt;/a&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;a href="https://aliasrobotics.com/case-study-cai-mqtt-broker.php"&gt;&lt;code&gt;OT&lt;/code&gt; - CAI and alias0 on: MQTT broker&lt;/a&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;CAI-powered API vulnerability discovery at Mercado Libre through automated enumeration attacks. This study demonstrates how AI-driven security testing can expose user data exposure risks in e-commerce platforms at scale.&lt;/td&gt; 
   &lt;td&gt;CAI-powered testing exposed critical flaws in an MQTT broker within a Dockerized OT network. Without authentication, CAI subscribed to temperature and humidity topics and injected false values, corrupting data shown in Grafana dashboards.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://aliasrobotics.com/case-study-mercado-libre.php"&gt;&lt;img src="https://aliasrobotics.com/img/case-study-portada-mercado-libre.png" alt="" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aliasrobotics.com/case-study-cai-mqtt-broker.php"&gt;&lt;img src="https://aliasrobotics.com/img/case-study-portada-mqtt-broker-cai.png" alt="" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!WARNING] &lt;span&gt;âš &lt;/span&gt; CAI is in active development, so don't expect it to work flawlessly. Instead, contribute by raising an issue or &lt;a href="https://github.com/aliasrobotics/cai/pulls"&gt;sending a PR&lt;/a&gt;.&lt;/p&gt; 
 &lt;p&gt;Access to this library and the use of information, materials (or portions thereof), is &lt;strong&gt;&lt;u&gt;not intended&lt;/u&gt;, and is &lt;u&gt;prohibited&lt;/u&gt;, where such access or use violates applicable laws or regulations&lt;/strong&gt;. By no means the authors encourage or promote the unauthorized tampering with running systems. This can cause serious human harm and material damages.&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;By no means the authors of CAI encourage or promote the unauthorized tampering with compute systems. Please don't use the source code in here for cybercrime. &lt;u&gt;Pentest for good instead&lt;/u&gt;&lt;/em&gt;. By downloading, using, or modifying this source code, you agree to the terms of the &lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/LICENSE"&gt;&lt;code&gt;LICENSE&lt;/code&gt;&lt;/a&gt; and the limitations outlined in the &lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/DISCLAIMER"&gt;&lt;code&gt;DISCLAIMER&lt;/code&gt;&lt;/a&gt; file.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;&lt;span&gt;ğŸ”–&lt;/span&gt; Table of Contents&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#cybersecurity-ai-cai"&gt;Cybersecurity AI (&lt;code&gt;CAI&lt;/code&gt;)&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#bookmark-table-of-contents"&gt;&lt;span&gt;ğŸ”–&lt;/span&gt; Table of Contents&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#-impact"&gt;ğŸ¯ Impact&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#-competitions-and-challenges"&gt;ğŸ† Competitions and challenges&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#-research-impact"&gt;ğŸ“Š Research Impact&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#-research-products-cybersecurity-ai"&gt;ğŸ“š Research products: &lt;code&gt;Cybersecurity AI&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#pocs"&gt;PoCs&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#motivation"&gt;Motivation&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#bust_in_silhouette-why-cai"&gt;&lt;span&gt;ğŸ‘¤&lt;/span&gt; Why CAI?&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#ethical-principles-behind-cai"&gt;Ethical principles behind CAI&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#closed-source-alternatives"&gt;Closed-source alternatives&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#learn---cai-fluency"&gt;Learn - &lt;code&gt;CAI&lt;/code&gt; Fluency&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#nut_and_bolt-install"&gt;&lt;span&gt;ğŸ”©&lt;/span&gt; Install&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#os-x"&gt;OS X&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#ubuntu-2404"&gt;Ubuntu 24.04&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#ubuntu-2004"&gt;Ubuntu 20.04&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#windows-wsl"&gt;Windows WSL&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#android"&gt;Android&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#nut_and_bolt-setup-env-file"&gt;&lt;span&gt;ğŸ”©&lt;/span&gt; Setup &lt;code&gt;.env&lt;/code&gt; file&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#-custom-openai-base-url-support"&gt;ğŸ”¹ Custom OpenAI Base URL Support&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#triangular_ruler-architecture"&gt;&lt;span&gt;ğŸ“&lt;/span&gt; Architecture:&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#-agent"&gt;ğŸ”¹ Agent&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#-tools"&gt;ğŸ”¹ Tools&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#-handoffs"&gt;ğŸ”¹ Handoffs&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#-patterns"&gt;ğŸ”¹ Patterns&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#-turns-and-interactions"&gt;ğŸ”¹ Turns and Interactions&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#-tracing"&gt;ğŸ”¹ Tracing&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#-human-in-the-loop-hitl"&gt;ğŸ”¹ Human-In-The-Loop (HITL)&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#rocket-quickstart"&gt;&lt;span&gt;ğŸš€&lt;/span&gt; Quickstart&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#environment-variables"&gt;Environment Variables&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#openrouter-integration"&gt;OpenRouter Integration&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#mcp"&gt;MCP&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#development"&gt;Development&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#contributions"&gt;Contributions&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#optional-requirements-caiextensions"&gt;Optional Requirements: caiextensions&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#information_source-usage-data-collection"&gt;&lt;span&gt;â„¹&lt;/span&gt; Usage Data Collection&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#reproduce-ci-setup-locally"&gt;Reproduce CI-Setup locally&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#faq"&gt;FAQ&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#citation"&gt;Citation&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#acknowledgements"&gt;Acknowledgements&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#academic-collaborations"&gt;Academic Collaborations&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ğŸ¯ Impact&lt;/h2&gt; 
&lt;h3&gt;ğŸ† Competitions and challenges&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://app.hackthebox.com/users/2268644"&gt;&lt;img src="https://img.shields.io/badge/HTB_ranking-top_90_Spain_(5_days)-red.svg?sanitize=true" alt="" /&gt;&lt;/a&gt; &lt;a href="https://app.hackthebox.com/users/2268644"&gt;&lt;img src="https://img.shields.io/badge/HTB_ranking-top_50_Spain_(6_days)-red.svg?sanitize=true" alt="" /&gt;&lt;/a&gt; &lt;a href="https://app.hackthebox.com/users/2268644"&gt;&lt;img src="https://img.shields.io/badge/HTB_ranking-top_30_Spain_(7_days)-red.svg?sanitize=true" alt="" /&gt;&lt;/a&gt; &lt;a href="https://app.hackthebox.com/users/2268644"&gt;&lt;img src="https://img.shields.io/badge/HTB_ranking-top_500_World_(7_days)-red.svg?sanitize=true" alt="" /&gt;&lt;/a&gt; &lt;a href="https://ctf.hackthebox.com/event/2000/scoreboard"&gt;&lt;img src="https://img.shields.io/badge/HTB_%22Human_vs_AI%22_CTF-top_1_(AIs)_world-red.svg?sanitize=true" alt="" /&gt;&lt;/a&gt; &lt;a href="https://ctf.hackthebox.com/event/2000/scoreboard"&gt;&lt;img src="https://img.shields.io/badge/HTB_%22Human_vs_AI%22_CTF-top_1_Spain-red.svg?sanitize=true" alt="" /&gt;&lt;/a&gt; &lt;a href="https://ctf.hackthebox.com/event/2000/scoreboard"&gt;&lt;img src="https://img.shields.io/badge/HTB_%22Human_vs_AI%22_CTF-top_20_World-red.svg?sanitize=true" alt="" /&gt;&lt;/a&gt; &lt;a href="https://ctf.hackthebox.com/event/2000/scoreboard"&gt;&lt;img src="https://img.shields.io/badge/HTB_%22Human_vs_AI%22_CTF-750_$-yellow.svg?sanitize=true" alt="" /&gt;&lt;/a&gt; &lt;a href="https://lu.ma/roboticshack?tk=RuryKF"&gt;&lt;img src="https://img.shields.io/badge/Mistral_AI_Robotics_Hackathon-2500_$-yellow.svg?sanitize=true" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;ğŸ“Š Research Impact&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Pioneered LLM-powered AI Security with PentestGPT, establishing the foundation for the &lt;code&gt;Cybersecurity AI&lt;/code&gt; research domain &lt;a href="https://arxiv.org/pdf/2308.06782"&gt;&lt;img src="https://img.shields.io/badge/arXiv-2308.06782-b31b1b.svg?sanitize=true" alt="arXiv" /&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Established the &lt;code&gt;Cybersecurity AI&lt;/code&gt; research line with &lt;strong&gt;3 peer-reviewed papers and technical reports&lt;/strong&gt; and active research collaborations &lt;a href="https://arxiv.org/pdf/2504.06017"&gt;&lt;img src="https://img.shields.io/badge/arXiv-2504.06017-b31b1b.svg?sanitize=true" alt="arXiv" /&gt;&lt;/a&gt; &lt;a href="https://arxiv.org/abs/2506.23592"&gt;&lt;img src="https://img.shields.io/badge/arXiv-2506.23592-b31b1b.svg?sanitize=true" alt="arXiv" /&gt;&lt;/a&gt; &lt;a href="https://arxiv.org/abs/2508.13588"&gt;&lt;img src="https://img.shields.io/badge/arXiv-2508.13588-b31b1b.svg?sanitize=true" alt="arXiv" /&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Demonstrated &lt;strong&gt;3,600Ã— performance improvement&lt;/strong&gt; over human penetration testers in standardized CTF benchmark evaluations &lt;a href="https://arxiv.org/pdf/2504.06017"&gt;&lt;img src="https://img.shields.io/badge/arXiv-2504.06017-b31b1b.svg?sanitize=true" alt="arXiv" /&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Identified &lt;strong&gt;CVSS 4.3-7.5 severity vulnerabilities&lt;/strong&gt; in production systems through automated security assessment &lt;a href="https://arxiv.org/pdf/2504.06017"&gt;&lt;img src="https://img.shields.io/badge/arXiv-2504.06017-b31b1b.svg?sanitize=true" alt="arXiv" /&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Democratization of vulnerability research&lt;/strong&gt;: CAI enables both non-security domain experts and experienced researchers to conduct more efficient vulnerability discovery, expanding the security research community while empowering small and medium enterprises to conduct autonomous security assessments &lt;a href="https://arxiv.org/pdf/2504.06017"&gt;&lt;img src="https://img.shields.io/badge/arXiv-2504.06017-b31b1b.svg?sanitize=true" alt="arXiv" /&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Systematic evaluation of large language models&lt;/strong&gt; across both proprietary and open-weight architectures, revealing &lt;u&gt;substantial gaps&lt;/u&gt; between vendor-reported capabilities and empirical cybersecurity performance metrics &lt;a href="https://arxiv.org/pdf/2504.06017"&gt;&lt;img src="https://img.shields.io/badge/arXiv-2504.06017-b31b1b.svg?sanitize=true" alt="arXiv" /&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Established the &lt;strong&gt;autonomy levels in cybersecurity&lt;/strong&gt; and argued about autonomy vs automation in the field &lt;a href="https://arxiv.org/abs/2506.23592"&gt;&lt;img src="https://img.shields.io/badge/arXiv-2506.23592-b31b1b.svg?sanitize=true" alt="arXiv" /&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Collaborative research initiatives&lt;/strong&gt; with international academic institutions focused on developing cybersecurity education curricula and training methodologies &lt;a href="https://arxiv.org/abs/2508.13588"&gt;&lt;img src="https://img.shields.io/badge/arXiv-2508.13588-b31b1b.svg?sanitize=true" alt="arXiv" /&gt;&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;ğŸ“š Research products: &lt;code&gt;Cybersecurity AI&lt;/code&gt;&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;CAI, An Open, Bug Bounty-Ready Cybersecurity AI&lt;/th&gt; 
   &lt;th&gt;The Dangerous Gap Between Automation and Autonomy&lt;/th&gt; 
   &lt;th&gt;CAI Fluency, A Framework for Cybersecurity AI Fluency&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://arxiv.org/pdf/2508.13588"&gt;&lt;img src="https://aliasrobotics.com/img/paper-cai.png" width="350" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.arxiv.org/pdf/2506.23592"&gt;&lt;img src="https://aliasrobotics.com/img/cai_automation_vs_autonomy.png" width="350" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://arxiv.org/pdf/2504.06017"&gt;&lt;img src="https://aliasrobotics.com/img/cai_fluency_cover.png" width="350" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;PoCs&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;CAI with &lt;code&gt;alias0&lt;/code&gt; on ROS message injection attacks in MiR-100 robot&lt;/th&gt; 
   &lt;th&gt;CAI with &lt;code&gt;alias0&lt;/code&gt; on API vulnerability discovery at Mercado Libre&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://asciinema.org/a/dNv705hZel2Rzrw0cju9HBGPh"&gt;&lt;img src="https://asciinema.org/a/dNv705hZel2Rzrw0cju9HBGPh.svg?sanitize=true" alt="asciicast" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://asciinema.org/a/9Hc9z1uFcdNjqP3bY5y7wO1Ww"&gt;&lt;img src="https://asciinema.org/a/9Hc9z1uFcdNjqP3bY5y7wO1Ww.svg?sanitize=true" alt="asciicast" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;CAI on JWT@PortSwigger CTF â€” Cybersecurity AI&lt;/th&gt; 
   &lt;th&gt;CAI on HackableII Boot2Root CTF â€” Cybersecurity AI&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://asciinema.org/a/713487"&gt;&lt;img src="https://asciinema.org/a/713487.svg?sanitize=true" alt="asciicast" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://asciinema.org/a/713485"&gt;&lt;img src="https://asciinema.org/a/713485.svg?sanitize=true" alt="asciicast" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;More case studies and PoCs are available at &lt;a href="https://aliasrobotics.com/case-studies-robot-cybersecurity.php"&gt;https://aliasrobotics.com/case-studies-robot-cybersecurity.php&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Motivation&lt;/h2&gt; 
&lt;h3&gt;&lt;span&gt;ğŸ‘¤&lt;/span&gt; Why CAI?&lt;/h3&gt; 
&lt;p&gt;The cybersecurity landscape is undergoing a dramatic transformation as AI becomes increasingly integrated into security operations. &lt;strong&gt;We predict that by 2028, AI-powered security testing tools will outnumber human pentesters&lt;/strong&gt;. This shift represents a fundamental change in how we approach cybersecurity challenges. &lt;em&gt;AI is not just another tool - it's becoming essential for addressing complex security vulnerabilities and staying ahead of sophisticated threats. As organizations face more advanced cyber attacks, AI-enhanced security testing will be crucial for maintaining robust defenses.&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;This work builds upon prior efforts[^4] and similarly, we believe that democratizing access to advanced cybersecurity AI tools is vital for the entire security community. That's why we're releasing Cybersecurity AI (&lt;code&gt;CAI&lt;/code&gt;) as an open source framework. Our goal is to empower security researchers, ethical hackers, and organizations to build and deploy powerful AI-driven security tools. By making these capabilities openly available, we aim to level the playing field and ensure that cutting-edge security AI technology isn't limited to well-funded private companies or state actors.&lt;/p&gt; 
&lt;p&gt;Bug Bounty programs have become a cornerstone of modern cybersecurity, providing a crucial mechanism for organizations to identify and fix vulnerabilities in their systems before they can be exploited. These programs have proven highly effective at securing both public and private infrastructure, with researchers discovering critical vulnerabilities that might have otherwise gone unnoticed. CAI is specifically designed to enhance these efforts by providing a lightweight, ergonomic framework for building specialized AI agents that can assist in various aspects of Bug Bounty hunting - from initial reconnaissance to vulnerability validation and reporting. Our framework aims to augment human expertise with AI capabilities, helping researchers work more efficiently and thoroughly in their quest to make digital systems more secure.&lt;/p&gt; 
&lt;h3&gt;Ethical principles behind CAI&lt;/h3&gt; 
&lt;p&gt;You might be wondering if releasing CAI &lt;em&gt;in-the-wild&lt;/em&gt; given its capabilities and security implications is ethical. Our decision to open-source this framework is guided by two core ethical principles:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Democratizing Cybersecurity AI&lt;/strong&gt;: We believe that advanced cybersecurity AI tools should be accessible to the entire security community, not just well-funded private companies or state actors. By releasing CAI as an open source framework, we aim to empower security researchers, ethical hackers, and organizations to build and deploy powerful AI-driven security tools, leveling the playing field in cybersecurity.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Transparency in AI Security Capabilities&lt;/strong&gt;: Based on our research results, understanding of the technology, and dissection of top technical reports, we argue that current LLM vendors are undermining their cybersecurity capabilities. This is extremely dangerous and misleading. By developing CAI openly, we provide a transparent benchmark of what AI systems can actually do in cybersecurity contexts, enabling more informed decisions about security postures.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;CAI is built on the following core principles:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Cybersecurity oriented AI framework&lt;/strong&gt;: CAI is specifically designed for cybersecurity use cases, aiming at semi- and fully-automating offensive and defensive security tasks.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Open source, free for research&lt;/strong&gt;: CAI is open source and free for research purposes. We aim at democratizing access to AI and Cybersecurity. For professional or commercial use, including on-premise deployments, dedicated technical support and custom extensions &lt;a href="mailto:research@aliasrobotics.com"&gt;reach out&lt;/a&gt; to obtain a license.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Lightweight&lt;/strong&gt;: CAI is designed to be fast, and easy to use.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Modular and agent-centric design&lt;/strong&gt;: CAI operates on the basis of agents and agentic patterns, which allows flexibility and scalability. You can easily add the most suitable agents and pattern for your cybersecuritytarget case.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Tool-integration&lt;/strong&gt;: CAI integrates already built-in tools, and allows the user to integrate their own tools with their own logic easily.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Logging and tracing integrated&lt;/strong&gt;: using &lt;a href="https://github.com/Arize-ai/phoenix"&gt;&lt;code&gt;phoenix&lt;/code&gt;&lt;/a&gt;, the open source tracing and logging tool for LLMs. This provides the user with a detailed traceability of the agents and their execution.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Multi-Model Support&lt;/strong&gt;: more than 300 supported and empowered by &lt;a href="https://github.com/BerriAI/litellm"&gt;LiteLLM&lt;/a&gt;. The most popular providers: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Anthropic&lt;/strong&gt;: &lt;code&gt;Claude 3.7&lt;/code&gt;, &lt;code&gt;Claude 3.5&lt;/code&gt;, &lt;code&gt;Claude 3&lt;/code&gt;, &lt;code&gt;Claude 3 Opus&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;OpenAI&lt;/strong&gt;: &lt;code&gt;O1&lt;/code&gt;, &lt;code&gt;O1 Mini&lt;/code&gt;, &lt;code&gt;O3 Mini&lt;/code&gt;, &lt;code&gt;GPT-4o&lt;/code&gt;, &lt;code&gt;GPT-4.5 Preview&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;DeepSeek&lt;/strong&gt;: &lt;code&gt;DeepSeek V3&lt;/code&gt;, &lt;code&gt;DeepSeek R1&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Ollama&lt;/strong&gt;: &lt;code&gt;Qwen2.5 72B&lt;/code&gt;, &lt;code&gt;Qwen2.5 14B&lt;/code&gt;, etc&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Closed-source alternatives&lt;/h3&gt; 
&lt;p&gt;Cybersecurity AI is a critical field, yet many groups are misguidedly pursuing it through closed-source methods for pure economic return, leveraging similar techniques and building upon existing closed-source (&lt;em&gt;often third-party owned&lt;/em&gt;) models. This approach not only squanders valuable engineering resources but also represents an economic waste and results in redundant efforts, as they often end up reinventing the wheel. Here are some of the closed-source initiatives we keep track of and attempting to leverage genAI and agentic frameworks in cybersecurity AI:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.acyber.co/"&gt;Autonomous Cyber&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://cracken.ai/"&gt;CrackenAGI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://ethiack.com/"&gt;ETHIACK&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://horizon3.ai/"&gt;Horizon3&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.kindo.ai/"&gt;Kindo&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://lakera.ai"&gt;Lakera&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/www.mindfort.ai"&gt;Mindfort&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://mindgard.ai/"&gt;Mindgard&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://ndaysecurity.com/"&gt;NDAY Security&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.runsybil.com"&gt;Runsybil&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.selfhack.fi"&gt;Selfhack&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://squr.ai/"&gt;SQUR&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://staris.tech/"&gt;Staris&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.sxipher.com/"&gt;Sxipher&lt;/a&gt; (seems discontinued)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.terra.security"&gt;Terra Security&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://xint.io/"&gt;Xint&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.xbow.com"&gt;XBOW&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.zeropath.com"&gt;ZeroPath&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.zynap.com"&gt;Zynap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://7ai.com"&gt;7ai&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Learn - &lt;code&gt;CAI&lt;/code&gt; Fluency&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt; &lt;a align="center" href="" target="https://github.com/aliasrobotics/CAI"&gt; &lt;img width="100%" src="https://github.com/aliasrobotics/cai/raw/main/media/caiedu.PNG" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;/div&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE]&lt;/p&gt; 
 &lt;p&gt;CAI Fluency technical report (&lt;a href="https://arxiv.org/pdf/2508.13588"&gt;arXiv:2508.13588&lt;/a&gt;) establishes formal educational frameworks for cybersecurity AI literacy.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;English&lt;/th&gt; 
   &lt;th&gt;Spanish&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Episode 0&lt;/strong&gt;: What is CAI?&lt;/td&gt; 
   &lt;td&gt;Cybersecurity AI (&lt;code&gt;CAI&lt;/code&gt;) explained&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.youtube.com/watch?v=nBdTxbKM4oo"&gt;&lt;img src="https://img.youtube.com/vi/nBdTxbKM4oo/0.jpg" alt="Watch the video" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.youtube.com/watch?v=FaUL9HXrQ5k"&gt;&lt;img src="https://img.youtube.com/vi/FaUL9HXrQ5k/0.jpg" alt="Watch the video" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Episode 1&lt;/strong&gt;: The &lt;code&gt;CAI&lt;/code&gt; Framework&lt;/td&gt; 
   &lt;td&gt;Vision &amp;amp; Ethics - Explore the core motivation behind CAI and delve into the crucial ethical principles guiding its development. Understand the motivation behind CAI and how you can actively contribute to the future of cybersecurity and the CAI framework.&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.youtube.com/watch?v=QEiGdsMf29M&amp;amp;list=PLLc16OUiZWd4RuFdN5_Wx9xwjCVVbopzr&amp;amp;index=3"&gt;&lt;img src="https://img.youtube.com/vi/QEiGdsMf29M/0.jpg" alt="Watch the video" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Episode 2&lt;/strong&gt;: From Zero to Cyber Hero&lt;/td&gt; 
   &lt;td&gt;Breaking into Cybersecurity with AI - A comprehensive guide for complete beginners to become cybersecurity practitioners using CAI and AI tools. Learn how to leverage artificial intelligence to accelerate your cybersecurity learning journey, from understanding basic security concepts to performing real-world security assessments, all without requiring prior cybersecurity experience.&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.youtube.com/watch?v=hSTLHOOcQoY&amp;amp;list=PLLc16OUiZWd4RuFdN5_Wx9xwjCVVbopzr&amp;amp;index=14"&gt;&lt;img src="https://img.youtube.com/vi/hSTLHOOcQoY/0.jpg" alt="Watch the video" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Episode 3&lt;/strong&gt;: Vibe-Hacking Tutorial&lt;/td&gt; 
   &lt;td&gt;"My first Hack" - A Vibe-Hacking guide for newbies. We demonstrate a simple web security hack using a default agent and show how to leverage tools and interpret CIA output with the help of the CAI Python API. You'll also learn to compare different LLM models to find the best fit for your hacking endeavors.&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.youtube.com/watch?v=9vZ_Iyex7uI&amp;amp;list=PLLc16OUiZWd4RuFdN5_Wx9xwjCVVbopzr&amp;amp;index=1"&gt;&lt;img src="https://img.youtube.com/vi/9vZ_Iyex7uI/0.jpg" alt="Watch the video" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.youtube.com/watch?v=iAOMaI1ftiA&amp;amp;list=PLLc16OUiZWd4RuFdN5_Wx9xwjCVVbopzr&amp;amp;index=2"&gt;&lt;img src="https://img.youtube.com/vi/iAOMaI1ftiA/0.jpg" alt="Watch the video" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Episode 4&lt;/strong&gt;: Intro ReAct&lt;/td&gt; 
   &lt;td&gt;The Evolution of LLMs - Learn how LLMs evolved from basic language models to advanced multiagency AI systems. From basic LLMs to Chain-of-Thought and Reasoning LLMs towards ReAct and Multi-Agent Architectures. Get to know the basic terms&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.youtube.com/watch?v=tLdFO1flj_o&amp;amp;list=PLLc16OUiZWd4RuFdN5_Wx9xwjCVVbopzr&amp;amp;index=13"&gt;&lt;img src="https://img.youtube.com/vi/tLdFO1flj_o/0.jpg" alt="Watch the video" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Episode 5&lt;/strong&gt;: CAI on CTF challenges&lt;/td&gt; 
   &lt;td&gt;Dive into Capture The Flag (CTF) competitions using CAI. Learn how to leverage AI agents to solve various cybersecurity challenges including web exploitation, cryptography, reverse engineering, and forensics. Discover how to configure CAI for competitive hacking scenarios and maximize your CTF performance with intelligent automation.&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.youtube.com/watch?v=MrXTQ0e2to4&amp;amp;list=PLLc16OUiZWd4RuFdN5_Wx9xwjCVVbopzr&amp;amp;index=13"&gt;&lt;img src="https://img.youtube.com/vi/MrXTQ0e2to4/0.jpg" alt="Watch the video" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.youtube.com/watch?v=r9US_JZa9_c&amp;amp;list=PLLc16OUiZWd4RuFdN5_Wx9xwjCVVbopzr&amp;amp;index=12"&gt;&lt;img src="https://img.youtube.com/vi/r9US_JZa9_c/0.jpg" alt="Watch the video" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Annex 1&lt;/strong&gt;: &lt;code&gt;CAI&lt;/code&gt; 0.5.x release&lt;/td&gt; 
   &lt;td&gt;Introduce version 0.5 of &lt;code&gt;CAI&lt;/code&gt; including new multi-agent functionality, new commands such as &lt;code&gt;/history&lt;/code&gt;, &lt;code&gt;/compact&lt;/code&gt;, &lt;code&gt;/graph&lt;/code&gt; or &lt;code&gt;/memory&lt;/code&gt; and a case study showing how &lt;code&gt;CAI&lt;/code&gt; found a critical security flaw in OT heap pumps spread around the world.&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.youtube.com/watch?v=OPFH0ANUMMw"&gt;&lt;img src="https://img.youtube.com/vi/OPFH0ANUMMw/0.jpg" alt="Watch the video" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.youtube.com/watch?v=Q8AI4E4gH8k"&gt;&lt;img src="https://img.youtube.com/vi/Q8AI4E4gH8k/0.jpg" alt="Watch the video" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Annex 2&lt;/strong&gt;: &lt;code&gt;CAI&lt;/code&gt; 0.4.x release and &lt;code&gt;alias0&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Introducing version 0.4 of &lt;code&gt;CAI&lt;/code&gt; with &lt;em&gt;streaming&lt;/em&gt; and improved MCP support. We also introduce &lt;code&gt;alias0&lt;/code&gt;, the Privacy-First Cybersecurity AI, a Model-of-Models Intelligence that implements a Privacy-by-Design architecture and obtains state-of-the-art results in cybersecurity benchmarks.&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.youtube.com/watch?v=NZjzfnvAZcc"&gt;&lt;img src="https://img.youtube.com/vi/NZjzfnvAZcc/0.jpg" alt="Watch the video" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Annex 3&lt;/strong&gt;: Cybersecurity AI Community Meeting #1&lt;/td&gt; 
   &lt;td&gt;First Cybersecurity AI (&lt;code&gt;CAI&lt;/code&gt;) community meeting, over 40 participants from academia, industry, and defense gathered to discuss the open-source scaffolding behind CAI â€” a project designed to build agentic AI systems for cybersecurity that are open, modular, and Bug Bounty-ready.&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.youtube.com/watch?v=4JqaTiVlgsw"&gt;&lt;img src="https://img.youtube.com/vi/4JqaTiVlgsw/0.jpg" alt="Watch the video" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;&lt;span&gt;ğŸ”©&lt;/span&gt; Install&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install cai-framework
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Always create a new virtual environment to ensure proper dependency installation when updating CAI.&lt;/p&gt; 
&lt;p&gt;The following subsections provide a more detailed walkthrough on selected popular Operating Systems. Refer to the &lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#development"&gt;Development&lt;/a&gt; section for developer-related install instructions.&lt;/p&gt; 
&lt;h3&gt;OS X&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;brew update &amp;amp;&amp;amp; \
    brew install git python@3.12

# Create virtual environment
python3.12 -m venv cai_env

# Install the package from the local directory
source cai_env/bin/activate &amp;amp;&amp;amp; pip install cai-framework

# Generate a .env file and set up with defaults
echo -e 'OPENAI_API_KEY="sk-1234"\nANTHROPIC_API_KEY=""\nOLLAMA=""\nPROMPT_TOOLKIT_NO_CPR=1\nCAI_STREAM=false' &amp;gt; .env

# Launch CAI
cai  # first launch it can take up to 30 seconds
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Ubuntu 24.04&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;sudo apt-get update &amp;amp;&amp;amp; \
    sudo apt-get install -y git python3-pip python3.12-venv

# Create the virtual environment
python3.12 -m venv cai_env

# Install the package from the local directory
source cai_env/bin/activate &amp;amp;&amp;amp; pip install cai-framework

# Generate a .env file and set up with defaults
echo -e 'OPENAI_API_KEY="sk-1234"\nANTHROPIC_API_KEY=""\nOLLAMA=""\nPROMPT_TOOLKIT_NO_CPR=1\nCAI_STREAM=false' &amp;gt; .env

# Launch CAI
cai  # first launch it can take up to 30 seconds
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Ubuntu 20.04&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;sudo apt-get update &amp;amp;&amp;amp; \
    sudo apt-get install -y software-properties-common

# Fetch Python 3.12
sudo add-apt-repository ppa:deadsnakes/ppa &amp;amp;&amp;amp; sudo apt update
sudo apt install python3.12 python3.12-venv python3.12-dev -y

# Create the virtual environment
python3.12 -m venv cai_env

# Install the package from the local directory
source cai_env/bin/activate &amp;amp;&amp;amp; pip install cai-framework

# Generate a .env file and set up with defaults
echo -e 'OPENAI_API_KEY="sk-1234"\nANTHROPIC_API_KEY=""\nOLLAMA=""\nPROMPT_TOOLKIT_NO_CPR=1\nCAI_STREAM=false' &amp;gt; .env

# Launch CAI
cai  # first launch it can take up to 30 seconds
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Windows WSL&lt;/h3&gt; 
&lt;p&gt;Go to the Microsoft page: &lt;a href="https://learn.microsoft.com/en-us/windows/wsl/install"&gt;https://learn.microsoft.com/en-us/windows/wsl/install&lt;/a&gt;. Here you will find all the instructions to install WSL&lt;/p&gt; 
&lt;p&gt;From Powershell write: wsl --install&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;
sudo apt-get update &amp;amp;&amp;amp; \
    sudo apt-get install -y git python3-pip python3-venv

# Create the virtual environment
python3 -m venv cai_env

# Install the package from the local directory
source cai_env/bin/activate &amp;amp;&amp;amp; pip install cai-framework

# Generate a .env file and set up with defaults
echo -e 'OPENAI_API_KEY="sk-1234"\nANTHROPIC_API_KEY=""\nOLLAMA=""\nPROMPT_TOOLKIT_NO_CPR=1\nCAI_STREAM=false' &amp;gt; .env

# Launch CAI
cai  # first launch it can take up to 30 seconds
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Android&lt;/h3&gt; 
&lt;p&gt;We recommend having at least 8 GB of RAM:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;First of all, install userland &lt;a href="https://play.google.com/store/apps/details?id=tech.ula&amp;amp;hl=es"&gt;https://play.google.com/store/apps/details?id=tech.ula&amp;amp;hl=es&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Install Kali minimal in basic options (for free). [Or any other kali option if preferred]&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Update apt keys like in this example: &lt;a href="https://superuser.com/questions/1644520/apt-get-update-issue-in-kali"&gt;https://superuser.com/questions/1644520/apt-get-update-issue-in-kali&lt;/a&gt;, inside UserLand's Kali terminal execute&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Get new apt keys
wget http://http.kali.org/kali/pool/main/k/kali-archive-keyring/kali-archive-keyring_2024.1_all.deb

# Install new apt keys
sudo dpkg -i kali-archive-keyring_2024.1_all.deb &amp;amp;&amp;amp; rm kali-archive-keyring_2024.1_all.deb

# Update APT repository
sudo apt-get update

# CAI requieres python 3.12, lets install it (CAI for kali in Android)
sudo apt-get update &amp;amp;&amp;amp; sudo apt-get install -y git python3-pip build-essential zlib1g-dev libncurses5-dev libgdbm-dev libnss3-dev libssl-dev libreadline-dev libffi-dev libsqlite3-dev wget libbz2-dev pkg-config
wget https://www.python.org/ftp/python/3.12.4/Python-3.12.4.tar.xz
tar xf Python-3.12.4.tar.xz
cd ./configure --enable-optimizations
sudo make altinstall # This command takes long to execute

# Clone CAI's source code
git clone https://github.com/aliasrobotics/cai &amp;amp;&amp;amp; cd cai

# Create virtual environment
python3.12 -m venv cai_env

# Install the package from the local directory
source cai_env/bin/activate &amp;amp;&amp;amp; pip3 install -e .

# Generate a .env file and set up
cp .env.example .env  # edit here your keys/models

# Launch CAI
cai
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;&lt;span&gt;ğŸ”©&lt;/span&gt; Setup &lt;code&gt;.env&lt;/code&gt; file&lt;/h3&gt; 
&lt;p&gt;CAI leverages the &lt;code&gt;.env&lt;/code&gt; file to load configuration at launch. To facilitate the setup, the repo provides an exemplary &lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/.env.example"&gt;&lt;code&gt;.env.example&lt;/code&gt;&lt;/a&gt; file provides a template for configuring CAI's setup and your LLM API keys to work with desired LLM models.&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;âš &lt;/span&gt; Important:&lt;/p&gt; 
&lt;p&gt;CAI does NOT provide API keys for any model by default. Don't ask us to provide keys, use your own or host your own models.&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;âš &lt;/span&gt; Note:&lt;/p&gt; 
&lt;p&gt;The OPENAI_API_KEY must not be left blank. It should contain either "sk-123" (as a placeholder) or your actual API key. See &lt;a href="https://github.com/aliasrobotics/cai/issues/27"&gt;https://github.com/aliasrobotics/cai/issues/27&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;âš &lt;/span&gt; Note:&lt;/p&gt; 
&lt;p&gt;If you are using alias0 model, make sure that CAI is &amp;gt;0.4.0 version and here you have an .env example to be able to use it.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;OPENAI_API_KEY="sk-1234"
OLLAMA=""
ALIAS_API_KEY="&amp;lt;sk-your-key&amp;gt;"  # note, add yours
CAI_STEAM=False
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;ğŸ”¹ Custom OpenAI Base URL Support&lt;/h3&gt; 
&lt;p&gt;CAI supports configuring a custom OpenAI API base URL via the &lt;code&gt;OPENAI_BASE_URL&lt;/code&gt; environment variable. This allows users to redirect API calls to a custom endpoint, such as a proxy or self-hosted OpenAI-compatible service.&lt;/p&gt; 
&lt;p&gt;Example &lt;code&gt;.env&lt;/code&gt; entry configuration:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;OLLAMA_API_BASE="https://custom-openai-proxy.com/v1"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or directly from the command line:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;OLLAMA_API_BASE="https://custom-openai-proxy.com/v1" cai
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;&lt;span&gt;ğŸ“&lt;/span&gt; Architecture:&lt;/h2&gt; 
&lt;p&gt;CAI focuses on making cybersecurity agent &lt;strong&gt;coordination&lt;/strong&gt; and &lt;strong&gt;execution&lt;/strong&gt; lightweight, highly controllable, and useful for humans. To do so it builds upon 8 pillars: &lt;code&gt;Agent&lt;/code&gt;s, &lt;code&gt;Tools&lt;/code&gt;, &lt;code&gt;Handoffs&lt;/code&gt;, &lt;code&gt;Patterns&lt;/code&gt;, &lt;code&gt;Turns&lt;/code&gt;, &lt;code&gt;Tracing&lt;/code&gt;, &lt;code&gt;Guardrails&lt;/code&gt; and &lt;code&gt;HITL&lt;/code&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                  â”‚      HITL     â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚   Turns   â”‚
                  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Patterns â”‚â—€â”€â”€â”€â”€â”€â–¶â”‚  Handoffs â”‚â—€â”€â”€â”€â”€â–¶ â”‚   Agents  â”‚â—€â”€â”€â”€â”€â–¶â”‚    LLMs   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚                   â”‚
                          â”‚                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Extensions â”‚â—€â”€â”€â”€â”€â”€â–¶â”‚  Tracing  â”‚       â”‚   Tools   â”‚â—€â”€â”€â”€â–¶â”‚ Guardrails â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                              â”‚
                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                          â–¼             â–¼          â–¼             â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ LinuxCmd  â”‚â”‚ WebSearch â”‚â”‚    Code    â”‚â”‚ SSHTunnel â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you want to dive deeper into the code, check the following files as a start point for using CAI:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/aliasrobotics/cai/raw/main/src/cai/__init__.py"&gt;&lt;strong&gt;init&lt;/strong&gt;.py&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/aliasrobotics/cai/raw/main/src/cai/cli.py"&gt;cli.py&lt;/a&gt; - entrypoint for command line interface&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/aliasrobotics/cai/raw/main/src/cai/util.py"&gt;util.py&lt;/a&gt; - utility functions&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/aliasrobotics/cai/raw/main/src/cai/agents"&gt;agents&lt;/a&gt; - Agent implementations&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/aliasrobotics/cai/raw/main/src/cai/internal"&gt;internal&lt;/a&gt; - CAI internal functions (endpoints, metrics, logging, etc.)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/aliasrobotics/cai/raw/main/src/cai/prompts"&gt;prompts&lt;/a&gt; - Agent Prompt Database&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/aliasrobotics/cai/raw/main/src/cai/repl"&gt;repl&lt;/a&gt; - CLI aesthetics and commands&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/aliasrobotics/cai/raw/main/src/cai/sdk"&gt;sdk&lt;/a&gt; - CAI command sdk&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/aliasrobotics/cai/tree/main/src/cai/tools"&gt;tools&lt;/a&gt; - agent tools&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;ğŸ”¹ Agent&lt;/h3&gt; 
&lt;p&gt;At its core, CAI abstracts its cybersecurity behavior via &lt;code&gt;Agents&lt;/code&gt; and agentic &lt;code&gt;Patterns&lt;/code&gt;. An Agent in &lt;em&gt;an intelligent system that interacts with some environment&lt;/em&gt;. More technically, within CAI we embrace a robotics-centric definition wherein an agent is anything that can be viewed as a system perceiving its environment through sensors, reasoning about its goals and and acting accordingly upon that environment through actuators (&lt;em&gt;adapted&lt;/em&gt; from Russel &amp;amp; Norvig, AI: A Modern Approach). In cybersecurity, an &lt;code&gt;Agent&lt;/code&gt; interacts with systems and networks, using peripherals and network interfaces as sensors, reasons accordingly and then executes network actions as if actuators. Correspondingly, in CAI, &lt;code&gt;Agent&lt;/code&gt;s implement the &lt;code&gt;ReACT&lt;/code&gt; (Reasoning and Action) agent model[^3]. For more information, see the &lt;a href="https://github.com/aliasrobotics/cai/raw/main/examples/basic/hello_world.py"&gt;example here&lt;/a&gt; for the full execution code, and refer to this &lt;a href="https://github.com/aliasrobotics/cai/raw/main/fluency/my-first-hack/my_first_hack.ipynb"&gt;jupyter notebook&lt;/a&gt; for a tutorial on how to use it.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from cai.sdk.agents import Agent, Runner, OpenAIChatCompletionsModel

import os
from openai import AsyncOpenAI
from dotenv import load_dotenv
load_dotenv()

agent = Agent(
      name="Custom Agent",
      instructions="""You are a Cybersecurity expert Leader""",
      model=OpenAIChatCompletionsModel(
          model=os.getenv('CAI_MODEL', "openai/gpt-4o"),
          openai_client=AsyncOpenAI(),
          )
      )

message = "Tell me about recursion in programming."
result = await Runner.run(agent, message)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;ğŸ”¹ Tools&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;Tools&lt;/code&gt; let cybersecurity agents take actions by providing interfaces to execute system commands, run security scans, analyze vulnerabilities, and interact with target systems and APIs - they are the core capabilities that enable CAI agents to perform security tasks effectively; in CAI, tools include built-in cybersecurity utilities (like LinuxCmd for command execution, WebSearch for OSINT gathering, Code for dynamic script execution, and SSHTunnel for secure remote access), function calling mechanisms that allow integration of any Python function as a security tool, and agent-as-tool functionality that enables specialized security agents (such as reconnaissance or exploit agents) to be used by other agents, creating powerful collaborative security workflows without requiring formal handoffs between agents. For more information, please refer to the &lt;a href="https://github.com/aliasrobotics/cai/raw/main/examples/basic/tools.py"&gt;example here&lt;/a&gt; for the complete configuration of custom functions.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from cai.sdk.agents import Agent, Runner, OpenAIChatCompletionsModel
from cai.tools.reconnaissance.exec_code import execute_code
from cai.tools.reconnaissance.generic_linux_command import generic_linux_command

import os
from openai import AsyncOpenAI
from dotenv import load_dotenv
load_dotenv()

agent = Agent(
      name="Custom Agent",
      instructions="""You are a Cybersecurity expert Leader""",
      tools= [
        generic_linux_command,
        execute_code
      ],
      model=OpenAIChatCompletionsModel(
          model=os.getenv('CAI_MODEL', "openai/gpt-4o"),
          openai_client=AsyncOpenAI(),
          )
      )

message = "Tell me about recursion in programming."
result = await Runner.run(agent, message)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You may find different &lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/cai/tools"&gt;tools&lt;/a&gt;. They are grouped in 6 major categories inspired by the security kill chain [^2]:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Reconnaissance and weaponization - &lt;em&gt;reconnaissance&lt;/em&gt; (crypto, listing, etc)&lt;/li&gt; 
 &lt;li&gt;Exploitation - &lt;em&gt;exploitation&lt;/em&gt;&lt;/li&gt; 
 &lt;li&gt;Privilege escalation - &lt;em&gt;escalation&lt;/em&gt;&lt;/li&gt; 
 &lt;li&gt;Lateral movement - &lt;em&gt;lateral&lt;/em&gt;&lt;/li&gt; 
 &lt;li&gt;Data exfiltration - &lt;em&gt;exfiltration&lt;/em&gt;&lt;/li&gt; 
 &lt;li&gt;Command and control - &lt;em&gt;control&lt;/em&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;ğŸ”¹ Handoffs&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;Handoffs&lt;/code&gt; allow an &lt;code&gt;Agent&lt;/code&gt; to delegate tasks to another agent, which is crucial in cybersecurity operations where specialized expertise is needed for different phases of an engagement. In our framework, &lt;code&gt;Handoffs&lt;/code&gt; are implemented as tools for the LLM, where a &lt;strong&gt;handoff/transfer function&lt;/strong&gt; like &lt;code&gt;transfer_to_flag_discriminator&lt;/code&gt; enables the &lt;code&gt;ctf_agent&lt;/code&gt; to pass control to the &lt;code&gt;flag_discriminator_agent&lt;/code&gt; once it believes it has found the flag. This creates a security validation chain where the first agent handles exploitation and flag discovery, while the second agent specializes in flag verification, ensuring proper segregation of duties and leveraging specialized capabilities of different models for distinct security tasks. For more information, please refer to the &lt;a href="https://github.com/aliasrobotics/cai/raw/main/examples/cai/agent_patterns/handoffs.py"&gt;example here&lt;/a&gt; for the full execution code.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from cai.sdk.agents import function_tool
from cai.tools.common import run_command
from cai.sdk.agents import Agent, OpenAIChatCompletionsModel, HandoffInputData, Runner, function_tool, handoff, trace
from cai.sdk.agents.extensions import handoff_filters

import os
from openai import AsyncOpenAI
from dotenv import load_dotenv
load_dotenv()

@function_tool
def execute_cli_command(command: str) -&amp;gt; str:
    return run_command(command)

flag_discriminator = Agent(
    name="Flag discriminator",
    description="Agent focused on extracting the flag from the output",
    instructions="You are an agent tailored to extract the flag from a given output.",
    model=OpenAIChatCompletionsModel(
        model=os.getenv('CAI_MODEL', "qwen2.5:14b"),
        openai_client=AsyncOpenAI(),
    ) 
)

ctf_agent = Agent(
    name="CTF agent",
    description="Agent focused on conquering security challenges",
    instructions="You are a Cybersecurity expert Leader facing a CTF",
    tools=[
        execute_cli_command,
    ],
    model=OpenAIChatCompletionsModel(
        model= os.getenv('CAI_MODEL', "qwen2.5:14b"),
        openai_client=AsyncOpenAI(),
    ), 
    handoffs = [flag_discriminator]
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;ğŸ”¹ Patterns&lt;/h3&gt; 
&lt;p&gt;An agentic &lt;code&gt;Pattern&lt;/code&gt; is a &lt;em&gt;structured design paradigm&lt;/em&gt; in artificial intelligence systems where autonomous or semi-autonomous agents operate within a defined &lt;em&gt;interaction framework&lt;/em&gt; (the pattern) to achieve a goal. These &lt;code&gt;Patterns&lt;/code&gt; specify the organization, coordination, and communication methods among agents, guiding decision-making, task execution, and delegation.&lt;/p&gt; 
&lt;p&gt;An agentic pattern (&lt;code&gt;AP&lt;/code&gt;) can be formally defined as a tuple:&lt;/p&gt; 
&lt;p&gt;\[ AP = (A, H, D, C, E) \]&lt;/p&gt; 
&lt;p&gt;wherein:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;\(A\) (Agents):&lt;/strong&gt; A set of autonomous entities, \( A = \{a_1, a_2, ..., a_n\} \), each with defined roles, capabilities, and internal states.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;\(H\) (Handoffs):&lt;/strong&gt; A function \( H: A \times T \to A \) that governs how tasks \( T \) are transferred between agents based on predefined logic (e.g., rules, negotiation, bidding).&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;\(D\) (Decision Mechanism):&lt;/strong&gt; A decision function \( D: S \to A \) where \( S \) represents system states, and \( D \) determines which agent takes action at any given time.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;\(C\) (Communication Protocol):&lt;/strong&gt; A messaging function \( C: A \times A \to M \), where \( M \) is a message space, defining how agents share information.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;\(E\) (Execution Model):&lt;/strong&gt; A function \( E: A \times I \to O \) where \( I \) is the input space and \( O \) is the output space, defining how agents perform tasks.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;When building &lt;code&gt;Patterns&lt;/code&gt;, we generall y classify them among one of the following categories, though others exist:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;&lt;strong&gt;Agentic&lt;/strong&gt; &lt;code&gt;Pattern&lt;/code&gt; &lt;strong&gt;categories&lt;/strong&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;strong&gt;Description&lt;/strong&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;Swarm&lt;/code&gt; (Decentralized)&lt;/td&gt; 
   &lt;td&gt;Agents share tasks and self-assign responsibilities without a central orchestrator. Handoffs occur dynamically. &lt;em&gt;An example of a peer-to-peer agentic pattern is the &lt;code&gt;CTF Agentic Pattern&lt;/code&gt;, which involves a team of agents working together to solve a CTF challenge with dynamic handoffs.&lt;/em&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;Hierarchical&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;A top-level agent (e.g., "PlannerAgent") assigns tasks via structured handoffs to specialized sub-agents. Alternatively, the structure of the agents is harcoded into the agentic pattern with pre-defined handoffs.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;Chain-of-Thought&lt;/code&gt; (Sequential Workflow)&lt;/td&gt; 
   &lt;td&gt;A structured pipeline where Agent A produces an output, hands it to Agent B for reuse or refinement, and so on. Handoffs follow a linear sequence. &lt;em&gt;An example of a chain-of-thought agentic pattern is the &lt;code&gt;ReasonerAgent&lt;/code&gt;, which involves a Reasoning-type LLM that provides context to the main agent to solve a CTF challenge with a linear sequence.&lt;/em&gt;[^1]&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;Auction-Based&lt;/code&gt; (Competitive Allocation)&lt;/td&gt; 
   &lt;td&gt;Agents "bid" on tasks based on priority, capability, or cost. A decision agent evaluates bids and hands off tasks to the best-fit agent.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;Recursive&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;A single agent continuously refines its own output, treating itself as both executor and evaluator, with handoffs (internal or external) to itself. &lt;em&gt;An example of a recursive agentic pattern is the &lt;code&gt;CodeAgent&lt;/code&gt; (when used as a recursive agent), which continuously refines its own output by executing code and updating its own instructions.&lt;/em&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;For more information and examples of common agentic patterns, see the &lt;a href="https://github.com/aliasrobotics/cai/raw/main/examples/agent_patterns/README.md"&gt;examples folder&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;ğŸ”¹ Turns and Interactions&lt;/h3&gt; 
&lt;p&gt;During the agentic flow (conversation), we distinguish between &lt;strong&gt;interactions&lt;/strong&gt; and &lt;strong&gt;turns&lt;/strong&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Interactions&lt;/strong&gt; are sequential exchanges between one or multiple agents. Each agent executing its logic corresponds with one &lt;em&gt;interaction&lt;/em&gt;. Since an &lt;code&gt;Agent&lt;/code&gt; in CAI generally implements the &lt;code&gt;ReACT&lt;/code&gt; agent model[^3], each &lt;em&gt;interaction&lt;/em&gt; consists of 1) a reasoning step via an LLM inference and 2) act by calling zero-to-n &lt;code&gt;Tools&lt;/code&gt;. This is defined in&lt;code&gt;process_interaction()&lt;/code&gt; in &lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/cai/core.py"&gt;core.py&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Turns&lt;/strong&gt;: A turn represents a cycle of one ore more &lt;strong&gt;interactions&lt;/strong&gt; which finishes when the &lt;code&gt;Agent&lt;/code&gt; (or &lt;code&gt;Pattern&lt;/code&gt;) executing returns &lt;code&gt;None&lt;/code&gt;, judging there're no further actions to undertake. This is defined in &lt;code&gt;run()&lt;/code&gt;, see &lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/cai/core.py"&gt;core.py&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] CAI Agents are not related to Assistants in the Assistants API. They are named similarly for convenience, but are otherwise completely unrelated. CAI is entirely powered by the Chat Completions API and is hence stateless between calls.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;ğŸ”¹ Tracing&lt;/h3&gt; 
&lt;p&gt;CAI implements AI observability by adopting the OpenTelemetry standard and to do so, it leverages &lt;a href="https://github.com/Arize-ai/phoenix"&gt;Phoenix&lt;/a&gt; which provides comprehensive tracing capabilities through OpenTelemetry-based instrumentation, allowing you to monitor and analyze your security operations in real-time. This integration enables detailed visibility into agent interactions, tool usage, and attack vectors throughout penetration testing workflows, making it easier to debug complex exploitation chains, track vulnerability discovery processes, and optimize agent performance for more effective security assessments.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/aliasrobotics/cai/main/media/tracing.png" alt="" /&gt;&lt;/p&gt; 
&lt;h3&gt;ğŸ”¹ Guardrails&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;Guardrails&lt;/code&gt; provide a critical security layer for CAI agents, protecting against prompt injection attacks and preventing execution of dangerous commands. These guardrails run in parallel to agents, validating both input and output to ensure safe operation. The framework includes:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Input Guardrails&lt;/strong&gt;: Detect and block prompt injection attempts before they reach agents, using pattern matching, Unicode homograph detection, and AI-powered analysis&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Output Guardrails&lt;/strong&gt;: Validate agent outputs before execution, preventing dangerous commands like reverse shells, fork bombs, or data exfiltration&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Multi-layered Defense&lt;/strong&gt;: Protection at input, processing, and execution stages with tool-level validation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Base64/Base32 Aware&lt;/strong&gt;: Automatically decodes and analyzes encoded payloads to detect hidden malicious commands&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Configurable&lt;/strong&gt;: Can be enabled/disabled via &lt;code&gt;CAI_GUARDRAILS&lt;/code&gt; environment variable&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For detailed implementation, see &lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/docs/guardrails.md"&gt;docs/guardrails.md&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/docs/cai_prompt_injection.md"&gt;docs/cai_prompt_injection.md&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;ğŸ”¹ Human-In-The-Loop (HITL)&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                      â”‚                                 â”‚
                      â”‚      Cybersecurity AI (CAI)     â”‚
                      â”‚                                 â”‚
                      â”‚       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
                      â”‚       â”‚  Autonomous AI  â”‚       â”‚
                      â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
                      â”‚                â”‚                â”‚
                      â”‚                â”‚                â”‚
                      â”‚       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
                      â”‚       â”‚ HITL Interaction â”‚      â”‚
                      â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
                      â”‚                â”‚                â”‚
                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                       â”‚
                                       â”‚ Ctrl+C (cli.py)
                                       â”‚
                           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                           â”‚   Human Operator(s)   â”‚
                           â”‚  Expertise | Judgment â”‚
                           â”‚    Teleoperation      â”‚
                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;CAI delivers a framework for building Cybersecurity AIs with a strong emphasis on &lt;em&gt;semi-autonomous&lt;/em&gt; operation, as the reality is that &lt;strong&gt;fully-autonomous&lt;/strong&gt; cybersecurity systems remain premature and face significant challenges when tackling complex tasks. While CAI explores autonomous capabilities, we recognize that effective security operations still require human teleoperation providing expertise, judgment, and oversight in the security process.&lt;/p&gt; 
&lt;p&gt;Accordingly, the Human-In-The-Loop (&lt;code&gt;HITL&lt;/code&gt;) module is a core design principle of CAI, acknowledging that human intervention and teleoperation are essential components of responsible security testing. Through the &lt;code&gt;cli.py&lt;/code&gt; interface, users can seamlessly interact with agents at any point during execution by simply pressing &lt;code&gt;Ctrl+C&lt;/code&gt;. This is implemented across &lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/cai/core.py"&gt;core.py&lt;/a&gt; and also in the REPL abstractions &lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/cai/repl"&gt;REPL&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;&lt;span&gt;ğŸš€&lt;/span&gt; Quickstart&lt;/h2&gt; 
&lt;p&gt;To start CAI after installing it, just type &lt;code&gt;cai&lt;/code&gt; in the CLI:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;â””â”€# cai

          CCCCCCCCCCCCC      ++++++++   ++++++++      IIIIIIIIII
       CCC::::::::::::C  ++++++++++       ++++++++++  I::::::::I
     CC:::::::::::::::C ++++++++++         ++++++++++ I::::::::I
    C:::::CCCCCCCC::::C +++++++++    ++     +++++++++ II::::::II
   C:::::C       CCCCCC +++++++     +++++     +++++++   I::::I
  C:::::C                +++++     +++++++     +++++    I::::I
  C:::::C                ++++                   ++++    I::::I
  C:::::C                 ++                     ++     I::::I
  C:::::C                  +   +++++++++++++++   +      I::::I
  C:::::C                    +++++++++++++++++++        I::::I
  C:::::C                     +++++++++++++++++         I::::I
   C:::::C       CCCCCC        +++++++++++++++          I::::I
    C:::::CCCCCCCC::::C         +++++++++++++         II::::::II
     CC:::::::::::::::C           +++++++++           I::::::::I
       CCC::::::::::::C             +++++             I::::::::I
          CCCCCCCCCCCCC               ++              IIIIIIIIII

                      Cybersecurity AI (CAI), vX.Y.Z
                          Bug bounty-ready AI

CAI&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;That should initialize CAI and provide a prompt to execute any security task you want to perform. The navigation bar at the bottom displays important system information. This information helps you understand your environment while working with CAI.&lt;/p&gt; 
&lt;p&gt;Here's a quick &lt;a href="https://asciinema.org/a/zm7wS5DA2o0S9pu1Tb44pnlvy"&gt;demo video&lt;/a&gt; to help you get started with CAI. We'll walk through the basic steps â€” from launching the tool to running your first AI-powered task in the terminal. Whether you're a beginner or just curious, this guide will show you how easy it is to begin using CAI.&lt;/p&gt; 
&lt;p&gt;From here on, type on &lt;code&gt;CAI&lt;/code&gt; and start your security exercise. Best way to learn is by example:&lt;/p&gt; 
&lt;h3&gt;Environment Variables&lt;/h3&gt; 
&lt;p&gt;For using private models, you are given a &lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/.env.example"&gt;&lt;code&gt;.env.example&lt;/code&gt;&lt;/a&gt; file. Copy it and rename it as &lt;code&gt;.env&lt;/code&gt;. Fill in your corresponding API keys, and you are ready to use CAI.&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;List of Environment Variables&lt;/summary&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;Variable&lt;/th&gt; 
    &lt;th&gt;Description&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;CTF_NAME&lt;/td&gt; 
    &lt;td&gt;Name of the CTF challenge to run (e.g. "picoctf_static_flag")&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;CTF_CHALLENGE&lt;/td&gt; 
    &lt;td&gt;Specific challenge name within the CTF to test&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;CTF_SUBNET&lt;/td&gt; 
    &lt;td&gt;Network subnet for the CTF container&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;CTF_IP&lt;/td&gt; 
    &lt;td&gt;IP address for the CTF container&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;CTF_INSIDE&lt;/td&gt; 
    &lt;td&gt;Whether to conquer the CTF from within container&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;CAI_MODEL&lt;/td&gt; 
    &lt;td&gt;Model to use for agents&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;CAI_DEBUG&lt;/td&gt; 
    &lt;td&gt;Set debug output level (0: Only tool outputs, 1: Verbose debug output, 2: CLI debug output)&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;CAI_BRIEF&lt;/td&gt; 
    &lt;td&gt;Enable/disable brief output mode&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;CAI_MAX_TURNS&lt;/td&gt; 
    &lt;td&gt;Maximum number of turns for agent interactions&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;CAI_TRACING&lt;/td&gt; 
    &lt;td&gt;Enable/disable OpenTelemetry tracing&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;CAI_AGENT_TYPE&lt;/td&gt; 
    &lt;td&gt;Specify the agents to use (boot2root, one_tool...)&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;CAI_STATE&lt;/td&gt; 
    &lt;td&gt;Enable/disable stateful mode&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;CAI_MEMORY&lt;/td&gt; 
    &lt;td&gt;Enable/disable memory mode (episodic, semantic, all)&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;CAI_MEMORY_ONLINE&lt;/td&gt; 
    &lt;td&gt;Enable/disable online memory mode&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;CAI_MEMORY_OFFLINE&lt;/td&gt; 
    &lt;td&gt;Enable/disable offline memory&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;CAI_ENV_CONTEXT&lt;/td&gt; 
    &lt;td&gt;Add dirs and current env to llm context&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;CAI_MEMORY_ONLINE_INTERVAL&lt;/td&gt; 
    &lt;td&gt;Number of turns between online memory updates&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;CAI_PRICE_LIMIT&lt;/td&gt; 
    &lt;td&gt;Price limit for the conversation in dollars&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;CAI_REPORT&lt;/td&gt; 
    &lt;td&gt;Enable/disable reporter mode (ctf, nis2, pentesting)&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;CAI_SUPPORT_MODEL&lt;/td&gt; 
    &lt;td&gt;Model to use for the support agent&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;CAI_SUPPORT_INTERVAL&lt;/td&gt; 
    &lt;td&gt;Number of turns between support agent executions&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;CAI_WORKSPACE&lt;/td&gt; 
    &lt;td&gt;Defines the name of the workspace&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;CAI_WORKSPACE_DIR&lt;/td&gt; 
    &lt;td&gt;Specifies the directory path where the workspace is located&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;CAI_GUARDRAILS&lt;/td&gt; 
    &lt;td&gt;Enable/disable guardrails for prompt injection protection (default: true)&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/details&gt; 
&lt;h3&gt;OpenRouter Integration&lt;/h3&gt; 
&lt;p&gt;The Cybersecurity AI (CAI) platform offers seamless integration with OpenRouter, a unified interface for Large Language Models (LLMs). This integration is crucial for users who wish to leverage advanced AI capabilities in their cybersecurity tasks. OpenRouter acts as a bridge, allowing CAI to communicate with various LLMs, thereby enhancing the flexibility and power of the AI agents used within CAI.&lt;/p&gt; 
&lt;p&gt;To enable OpenRouter support in CAI, you need to configure your environment by adding specific entries to your &lt;code&gt;.env&lt;/code&gt; file. This setup ensures that CAI can interact with the OpenRouter API, facilitating the use of sophisticated models like Meta-LLaMA. Hereâ€™s how you can configure it:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;CAI_AGENT_TYPE=redteam_agent
CAI_MODEL=openrouter/meta-llama/llama-4-maverick
OPENROUTER_API_KEY=&amp;lt;sk-your-key&amp;gt;  # note, add yours
OPENROUTER_API_BASE=https://openrouter.ai/api/v1
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;MCP&lt;/h3&gt; 
&lt;p&gt;CAI supports the Model Context Protocol (MCP) for integrating external tools and services with AI agents. MCP is supported via two transport mechanisms:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;SSE (Server-Sent Events)&lt;/strong&gt; - For web-based servers that push updates over HTTP connections:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;CAI&amp;gt;/mcp load http://localhost:9876/sse burp
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;&lt;strong&gt;STDIO (Standard Input/Output)&lt;/strong&gt; - For local inter-process communication:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;CAI&amp;gt;/mcp load stdio myserver python mcp_server.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Once connected, you can add the MCP tools to any agent:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;CAI&amp;gt;/mcp add burp redteam_agent
Adding tools from MCP server 'burp' to agent 'Red Team Agent'...
                                 Adding tools to Red Team Agent
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Tool                              â”ƒ Status â”ƒ Details                                         â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ send_http_request                 â”‚ Added  â”‚ Available as: send_http_request                 â”‚
â”‚ create_repeater_tab               â”‚ Added  â”‚ Available as: create_repeater_tab               â”‚
â”‚ send_to_intruder                  â”‚ Added  â”‚ Available as: send_to_intruder                  â”‚
â”‚ url_encode                        â”‚ Added  â”‚ Available as: url_encode                        â”‚
â”‚ url_decode                        â”‚ Added  â”‚ Available as: url_decode                        â”‚
â”‚ base64encode                      â”‚ Added  â”‚ Available as: base64encode                      â”‚
â”‚ base64decode                      â”‚ Added  â”‚ Available as: base64decode                      â”‚
â”‚ generate_random_string            â”‚ Added  â”‚ Available as: generate_random_string            â”‚
â”‚ output_project_options            â”‚ Added  â”‚ Available as: output_project_options            â”‚
â”‚ output_user_options               â”‚ Added  â”‚ Available as: output_user_options               â”‚
â”‚ set_project_options               â”‚ Added  â”‚ Available as: set_project_options               â”‚
â”‚ set_user_options                  â”‚ Added  â”‚ Available as: set_user_options                  â”‚
â”‚ get_proxy_http_history            â”‚ Added  â”‚ Available as: get_proxy_http_history            â”‚
â”‚ get_proxy_http_history_regex      â”‚ Added  â”‚ Available as: get_proxy_http_history_regex      â”‚
â”‚ get_proxy_websocket_history       â”‚ Added  â”‚ Available as: get_proxy_websocket_history       â”‚
â”‚ get_proxy_websocket_history_regex â”‚ Added  â”‚ Available as: get_proxy_websocket_history_regex â”‚
â”‚ set_task_execution_engine_state   â”‚ Added  â”‚ Available as: set_task_execution_engine_state   â”‚
â”‚ set_proxy_intercept_state         â”‚ Added  â”‚ Available as: set_proxy_intercept_state         â”‚
â”‚ get_active_editor_contents        â”‚ Added  â”‚ Available as: get_active_editor_contents        â”‚
â”‚ set_active_editor_contents        â”‚ Added  â”‚ Available as: set_active_editor_contents        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Added 20 tools from server 'burp' to agent 'Red Team Agent'.
CAI&amp;gt;/agent 13
CAI&amp;gt;Create a repeater tab
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can list all active MCP connections and their transport types:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;CAI&amp;gt;/mcp list
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/386a1fd3-3469-4f84-9396-2a5236febe1f"&gt;https://github.com/user-attachments/assets/386a1fd3-3469-4f84-9396-2a5236febe1f&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Development&lt;/h2&gt; 
&lt;p&gt;Development is facilitated via VS Code dev. environments. To try out our development environment, clone the repository, open VS Code and enter de dev. container mode:&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/aliasrobotics/cai/main/media/cai_devenv.gif" alt="CAI Development Environment" /&gt;&lt;/p&gt; 
&lt;h3&gt;Contributions&lt;/h3&gt; 
&lt;p&gt;If you want to contribute to this project, use &lt;a href="https://pre-commit.com/"&gt;&lt;strong&gt;Pre-commit&lt;/strong&gt;&lt;/a&gt; before your MR&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install pre-commit
pre-commit # files staged
pre-commit run --all-files # all files
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Optional Requirements: caiextensions&lt;/h3&gt; 
&lt;p&gt;Currently, the extensions are not publicly available as the engineering endeavour to maintain them is significant. Instead, we're making selected custom caiextensions available for partner companies across collaborations.&lt;/p&gt; 
&lt;h3&gt;&lt;span&gt;â„¹&lt;/span&gt; Usage Data Collection&lt;/h3&gt; 
&lt;p&gt;CAI is provided free of charge for researchers. To improve CAIâ€™s detection accuracy and publish open security research, instead of payment for research use cases, we ask you to contribute to the CAI community by allowing usage data collection. This data helps us identify areas for improvement, understand how the framework is being used, and prioritize new features. Legal basis of data collection is under Art. 6 (1)(f) GDPR â€” CAIâ€™s legitimate interest in maintaining and improving security tooling, with Art. 89 safeguards for research. The collected data includes:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Basic system information (OS type, Python version)&lt;/li&gt; 
 &lt;li&gt;Username and IP information&lt;/li&gt; 
 &lt;li&gt;Tool usage patterns and performance metrics&lt;/li&gt; 
 &lt;li&gt;Model interactions and token usage statistics&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;We take your privacy seriously and only collect what's needed to make CAI better. For further info, reach out to researchï¼ aliasrobotics.com. You can disable some of the data collection features via the &lt;code&gt;CAI_TELEMETRY&lt;/code&gt; environment variable but we encourage you to keep it enabled and contribute back to research:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;CAI_TELEMETRY=False cai
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Reproduce CI-Setup locally&lt;/h3&gt; 
&lt;p&gt;To simulate the CI/CD pipeline, you can run the following in the Gitlab runner machines:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run --rm -it \
  --privileged \
  --network=exploitflow_net \
  --add-host="host.docker.internal:host-gateway" \
  -v /cache:/cache \
  -v /var/run/docker.sock:/var/run/docker.sock:rw \
  registry.gitlab.com/aliasrobotics/alias_research/cai:latest bash
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;FAQ&lt;/h2&gt; 
&lt;details&gt;
 &lt;summary&gt;OLLAMA is giving me 404 errors&lt;/summary&gt; 
 &lt;p&gt;Ollama's API in OpenAI mode uses &lt;code&gt;/v1/chat/completions&lt;/code&gt; whereas the &lt;code&gt;openai&lt;/code&gt; library uses &lt;code&gt;base_url&lt;/code&gt; + &lt;code&gt;/chat/completions&lt;/code&gt;.&lt;/p&gt; 
 &lt;p&gt;We adopt the latter for overall alignment with the gen AI community and empower the former by allowing users to add the &lt;code&gt;v1&lt;/code&gt; themselves via:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;OLLAMA_API_BASE=http://IP:PORT/v1
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;See the following issues that treat this topic in more detail:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://github.com/aliasrobotics/cai/issues/76"&gt;https://github.com/aliasrobotics/cai/issues/76&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/aliasrobotics/cai/issues/83"&gt;https://github.com/aliasrobotics/cai/issues/83&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/aliasrobotics/cai/issues/82"&gt;https://github.com/aliasrobotics/cai/issues/82&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt;
 &lt;summary&gt;Where are all the caiextensions?&lt;/summary&gt; 
 &lt;p&gt;See &lt;a href="https://gitlab.com/aliasrobotics/alias_research/caiextensions"&gt;all caiextensions&lt;/a&gt;&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt;
 &lt;summary&gt;How do I install the report caiextension?&lt;/summary&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#optional-requirements-caiextensions"&gt;See here&lt;/a&gt;&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt;
 &lt;summary&gt;How do I set up SSH access for Gitlab?&lt;/summary&gt; 
 &lt;p&gt;Generate a new SSH key&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;ssh-keygen -t ed25519
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Add the key to the SSH agent&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;ssh-add ~/.ssh/id_ed25519
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Add the public key to Gitlab Copy the key and add it to Gitlab under &lt;a href="https://gitlab.com/-/user_settings/ssh_keys"&gt;https://gitlab.com/-/user_settings/ssh_keys&lt;/a&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;cat ~/.ssh/id_ed25519.pub
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;To verify it:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;ssh -T git@gitlab.com
Welcome to GitLab, @vmayoral!
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt;
 &lt;summary&gt;How do I clear Python cache?&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;find . -name "*.pyc" -delete &amp;amp;&amp;amp; find . -name "__pycache__" -delete
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt;
 &lt;summary&gt;If host networking is not working with ollama check whether it has been disabled in Docker because you are not signed in&lt;/summary&gt; 
 &lt;p&gt;Docker in OS X behaves funny sometimes. Check if the following message has shown up:&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;Host networking has been disabled because you are not signed in. Please sign in to enable it&lt;/em&gt;.&lt;/p&gt; 
 &lt;p&gt;Make sure this has been addressed and also that the Dev Container is not forwarding the 8000 port (click on x, if necessary in the ports section).&lt;/p&gt; 
 &lt;p&gt;To verify connection, from within the VSCode devcontainer:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;curl -v http://host.docker.internal:8000/api/version
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Run CAI against any target&lt;/summary&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/aliasrobotics/cai/main/imgs/readme_imgs/cai-004-first-message.png" alt="cai-004-first-message" /&gt;&lt;/p&gt; 
 &lt;p&gt;The starting user prompt in this case is: &lt;code&gt;Target IP: 192.168.3.10, perform a full network scan&lt;/code&gt;.&lt;/p&gt; 
 &lt;p&gt;The agent started performing a nmap scan. You could either interact with the agent and give it more instructions, or let it run to see what it explores next.&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;How do I interact with the agent? Type twice CTRL + C &lt;/summary&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/aliasrobotics/cai/main/imgs/readme_imgs/cai-005-ctrl-c.png" alt="cai-005-ctrl-c" /&gt;&lt;/p&gt; 
 &lt;p&gt;If you want to use the HITL mode, you can do it by presssing twice &lt;code&gt;Ctrl + C&lt;/code&gt;. This will allow you to interact (prompt) with the agent whenever you want. The agent will not lose the previous context, as it is stored in the &lt;code&gt;history&lt;/code&gt; variable, which is passed to it and any agent that is called. This enables any agent to use the previous information and be more accurate and efficient.&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt; Can I change the model while CAI is running? /model &lt;/summary&gt; 
 &lt;p&gt;Use &lt;code&gt;/model&lt;/code&gt; to change the model.&lt;/p&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/aliasrobotics/cai/main/imgs/readme_imgs/cai-007-model-change.png" alt="cai-007-model-change" /&gt;&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;How can I list all the agents available? /agent &lt;/summary&gt; 
 &lt;p&gt;Use &lt;code&gt;/agent&lt;/code&gt; to list all the agents available.&lt;/p&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/aliasrobotics/cai/main/imgs/readme_imgs/cai-010-agents-menu.png" alt="cai-010-agents-menu" /&gt;&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt; Where can I list all the environment variables? /config &lt;/summary&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/aliasrobotics/cai/main/imgs/readme_imgs/cai-008-config.png" alt="cai-008-config" /&gt;&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt; How to know more about the CLI? /help &lt;/summary&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/aliasrobotics/cai/main/imgs/readme_imgs/cai-006-help.png" alt="cai-006-help" /&gt;&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;How can I trace the whole execution?&lt;/summary&gt; The environment variable `CAI_TRACING` allows the user to set it to `CAI_TRACING=true` to enable tracing, or `CAI_TRACING=false` to disable it. When CAI is prompted by the first time, the user is provided with two paths, the execution log, and the tracing log. 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/aliasrobotics/cai/main/imgs/readme_imgs/cai-009-logs.png" alt="cai-009-logs" /&gt;&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Can I expand CAI capabilities using previous run logs?&lt;/summary&gt; 
 &lt;p&gt;Absolutely! The &lt;strong&gt;memory extension&lt;/strong&gt; allows you to use a previously sucessful runs ( the log object is stored as a &lt;strong&gt;.jsonl file in the &lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/cai/logs"&gt;log&lt;/a&gt; folder&lt;/strong&gt; ) in a new run against the same target. The user is also given the path highlighted in orange as shown below.&lt;/p&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/aliasrobotics/cai/main/imgs/readme_imgs/cai-009-logs.png" alt="cai-009-logs" /&gt;&lt;/p&gt; 
 &lt;p&gt;How to make use of this functionality?&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;Run CAI against the target. Let's assume the target name is: &lt;code&gt;target001&lt;/code&gt;.&lt;/li&gt; 
  &lt;li&gt;Get the log file path, something like: &lt;code&gt;logs/cai_20250408_111856.jsonl&lt;/code&gt;&lt;/li&gt; 
  &lt;li&gt;Generate the memory using any model of your preference: &lt;code&gt;shell JSONL_FILE_PATH="logs/cai_20250408_111856.jsonl" CTF_INSIDE="false" CAI_MEMORY_COLLECTION="target001" CAI_MEMORY="episodic" CAI_MODEL="claude-3-5-sonnet-20241022" python3 tools/2_jsonl_to_memory.py &lt;/code&gt;&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;p&gt;The script &lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/cai/tools/2_jsonl_to_memory.py"&gt;&lt;code&gt;tools/2_jsonl_to_memory.py&lt;/code&gt;&lt;/a&gt; will generate a memory collection file with the most relevant steps. The quality of the memory collection will depend on the model you use.&lt;/p&gt; 
 &lt;ol start="4"&gt; 
  &lt;li&gt;Use the generated memory collection and execute a new run: &lt;code&gt;shell CAI_MEMORY="episodic" CAI_MODEL="gpt-4o" CAI_MEMORY_COLLECTION="target001" CAI_TRACING=false python3 cai/cli.py&lt;/code&gt;&lt;/li&gt; 
 &lt;/ol&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Can I expand CAI capabilities using scripts or extra information?&lt;/summary&gt; 
 &lt;p&gt;Currently, CAI supports text based information. You can add any extra information on the target you are facing by copy-pasting it directly into the system or user prompt.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;How?&lt;/strong&gt; By adding it to the system (&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/cai/repl/templates/system_master_template.md"&gt;&lt;code&gt;system_master_template.md&lt;/code&gt;&lt;/a&gt;) or the user prompt (&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/cai/repl/templates/user_master_template.md"&gt;&lt;code&gt;user_master_template.md&lt;/code&gt;&lt;/a&gt;). You can always directly prompt the path to the model, and it will &lt;code&gt;cat&lt;/code&gt; it.&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt;
 &lt;summary&gt;How CAI licence works?&lt;/summary&gt; 
 &lt;p&gt;CAIâ€™s current license does not restrict usage for research purposes. You are free to use CAI for security assessments (pentests), to develop additional features, and to integrate it into your research activities, as long as you comply with local laws.&lt;/p&gt; 
 &lt;p&gt;If you or your organization start benefiting commercially from CAI (e.g., offering pentesting services powered by CAI), then a commercial license will be required to help sustain the project.&lt;/p&gt; 
 &lt;p&gt;CAI itself is not a profit-seeking initiative. Our goal is to build a sustainable open-source project. We simply ask that those who profit from CAI contribute back and support our ongoing development.&lt;/p&gt; 
&lt;/details&gt; 
&lt;h2&gt;Citation&lt;/h2&gt; 
&lt;p&gt;If you want to cite our work, please use the following:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bibtex"&gt;@misc{mayoralvilches2025caiopenbugbountyready,
      title={CAI: An Open, Bug Bounty-Ready Cybersecurity AI},
      author={VÃ­ctor Mayoral-Vilches and Luis Javier Navarrete-Lozano and MarÃ­a Sanz-GÃ³mez and Lidia Salas Espejo and MartiÃ±o Crespo-Ãlvarez and Francisco Oca-Gonzalez and Francesco Balassone and Alfonso Glera-PicÃ³n and Unai Ayucar-Carbajo and Jon Ander Ruiz-Alcalde and Stefan Rass and Martin Pinzger and Endika Gil-Uriarte},
      year={2025},
      eprint={2504.06017},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
      url={https://arxiv.org/abs/2504.06017},
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-bibtex"&gt;@misc{mayoralvilches2025cybersecurityaidangerousgap,
      title={Cybersecurity AI: The Dangerous Gap Between Automation and Autonomy}, 
      author={VÃ­ctor Mayoral-Vilches},
      year={2025},
      eprint={2506.23592},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
      url={https://arxiv.org/abs/2506.23592}, 
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-bibtex"&gt;@misc{mayoralvilches2025caifluencyframeworkcybersecurity,
      title={CAI Fluency: A Framework for Cybersecurity AI Fluency}, 
      author={VÃ­ctor Mayoral-Vilches and Jasmin Wachter and CristÃ³bal R. J. Veas Chavez and Cathrin Schachner and Luis Javier Navarrete-Lozano and MarÃ­a Sanz-GÃ³mez},
      year={2025},
      eprint={2508.13588},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
      url={https://arxiv.org/abs/2508.13588}, 
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Acknowledgements&lt;/h2&gt; 
&lt;p&gt;CAI was initially developed by &lt;a href="https://aliasrobotics.com"&gt;Alias Robotics&lt;/a&gt; and co-funded by the European EIC accelerator project RIS (GA 101161136) - HORIZON-EIC-2023-ACCELERATOR-01 call. The original agentic principles are inspired from OpenAI's &lt;a href="https://github.com/openai/swarm"&gt;&lt;code&gt;swarm&lt;/code&gt;&lt;/a&gt; library and translated into newer prototypes. This project also makes use of other relevant open source building blocks including &lt;a href="https://github.com/BerriAI/litellm"&gt;&lt;code&gt;LiteLLM&lt;/code&gt;&lt;/a&gt;, and &lt;a href="https://github.com/Arize-ai/phoenix"&gt;&lt;code&gt;phoenix&lt;/code&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Academic Collaborations&lt;/h3&gt; 
&lt;p&gt;CAI benefits from ongoing research collaborations with academic institutions. Researchers interested in collaborative projects, dataset access, or academic licenses should contact &lt;a href="mailto:research@aliasrobotics.com"&gt;research@aliasrobotics.com&lt;/a&gt;. We provide special support for:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;PhD research projects&lt;/li&gt; 
 &lt;li&gt;Academic benchmarking studies&lt;/li&gt; 
 &lt;li&gt;Security education initiatives&lt;/li&gt; 
 &lt;li&gt;Open-source contributions from research labs&lt;/li&gt; 
&lt;/ul&gt; 
&lt;!-- Footnotes --&gt; 
&lt;p&gt;[^1]: Arguably, the Chain-of-Thought agentic pattern is a special case of the Hierarchical agentic pattern. [^2]: Kamhoua, C. A., Leslie, N. O., &amp;amp; Weisman, M. J. (2018). Game theoretic modeling of advanced persistent threat in internet of things. Journal of Cyber Security and Information Systems. [^3]: Yao, S., Zhao, J., Yu, D., Du, N., Shafran, I., Narasimhan, K., &amp;amp; Cao, Y. (2023, January). React: Synergizing reasoning and acting in language models. In International Conference on Learning Representations (ICLR). [^4]: Deng, G., Liu, Y., Mayoral-Vilches, V., Liu, P., Li, Y., Xu, Y., ... &amp;amp; Rass, S. (2024). {PentestGPT}: Evaluating and harnessing large language models for automated penetration testing. In 33rd USENIX Security Symposium (USENIX Security 24) (pp. 847-864).&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>yt-dlp/yt-dlp</title>
      <link>https://github.com/yt-dlp/yt-dlp</link>
      <description>&lt;p&gt;A feature-rich command-line audio/video downloader&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#readme"&gt;&lt;img src="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/.github/banner.svg?sanitize=true" alt="YT-DLP" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#installation" title="Installation"&gt;&lt;img src="https://img.shields.io/github/v/release/yt-dlp/yt-dlp?color=brightgreen&amp;amp;label=Download&amp;amp;style=for-the-badge" alt="Release version" /&gt;&lt;/a&gt; &lt;a href="https://pypi.org/project/yt-dlp" title="PyPI"&gt;&lt;img src="https://img.shields.io/badge/-PyPI-blue.svg?logo=pypi&amp;amp;labelColor=555555&amp;amp;style=for-the-badge" alt="PyPI" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/Collaborators.md#collaborators" title="Donate"&gt;&lt;img src="https://img.shields.io/badge/_-Donate-red.svg?logo=githubsponsors&amp;amp;labelColor=555555&amp;amp;style=for-the-badge" alt="Donate" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/H5MNcFW63r" title="Discord"&gt;&lt;img src="https://img.shields.io/discord/807245652072857610?color=blue&amp;amp;labelColor=555555&amp;amp;label=&amp;amp;logo=discord&amp;amp;style=for-the-badge" alt="Discord" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/supportedsites.md" title="Supported Sites"&gt;&lt;img src="https://img.shields.io/badge/-Supported_Sites-brightgreen.svg?style=for-the-badge" alt="Supported Sites" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/LICENSE" title="License"&gt;&lt;img src="https://img.shields.io/badge/-Unlicense-blue.svg?style=for-the-badge" alt="License: Unlicense" /&gt;&lt;/a&gt; &lt;a href="https://github.com/yt-dlp/yt-dlp/actions" title="CI Status"&gt;&lt;img src="https://img.shields.io/github/actions/workflow/status/yt-dlp/yt-dlp/core.yml?branch=master&amp;amp;label=Tests&amp;amp;style=for-the-badge" alt="CI Status" /&gt;&lt;/a&gt; &lt;a href="https://github.com/yt-dlp/yt-dlp/commits" title="Commit History"&gt;&lt;img src="https://img.shields.io/github/commit-activity/m/yt-dlp/yt-dlp?label=commits&amp;amp;style=for-the-badge" alt="Commits" /&gt;&lt;/a&gt; &lt;a href="https://github.com/yt-dlp/yt-dlp/pulse/monthly" title="Last activity"&gt;&lt;img src="https://img.shields.io/github/last-commit/yt-dlp/yt-dlp/master?label=&amp;amp;style=for-the-badge&amp;amp;display_timestamp=committer" alt="Last Commit" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;!-- MANPAGE: END EXCLUDED SECTION --&gt; 
&lt;p&gt;yt-dlp is a feature-rich command-line audio/video downloader with support for &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/supportedsites.md"&gt;thousands of sites&lt;/a&gt;. The project is a fork of &lt;a href="https://github.com/ytdl-org/youtube-dl"&gt;youtube-dl&lt;/a&gt; based on the now inactive &lt;a href="https://github.com/blackjack4494/yt-dlc"&gt;youtube-dlc&lt;/a&gt;.&lt;/p&gt; 
&lt;!-- MANPAGE: MOVE "USAGE AND OPTIONS" SECTION HERE --&gt; 
&lt;!-- MANPAGE: BEGIN EXCLUDED SECTION --&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#installation"&gt;INSTALLATION&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/wiki/Installation"&gt;Detailed instructions&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#release-files"&gt;Release Files&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#update"&gt;Update&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#dependencies"&gt;Dependencies&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#compile"&gt;Compile&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#usage-and-options"&gt;USAGE AND OPTIONS&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#general-options"&gt;General Options&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#network-options"&gt;Network Options&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#geo-restriction"&gt;Geo-restriction&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#video-selection"&gt;Video Selection&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#download-options"&gt;Download Options&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#filesystem-options"&gt;Filesystem Options&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#thumbnail-options"&gt;Thumbnail Options&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#internet-shortcut-options"&gt;Internet Shortcut Options&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#verbosity-and-simulation-options"&gt;Verbosity and Simulation Options&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#workarounds"&gt;Workarounds&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#video-format-options"&gt;Video Format Options&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#subtitle-options"&gt;Subtitle Options&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#authentication-options"&gt;Authentication Options&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#post-processing-options"&gt;Post-processing Options&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#sponsorblock-options"&gt;SponsorBlock Options&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#extractor-options"&gt;Extractor Options&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#preset-aliases"&gt;Preset Aliases&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#configuration"&gt;CONFIGURATION&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#configuration-file-encoding"&gt;Configuration file encoding&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#authentication-with-netrc"&gt;Authentication with netrc&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#notes-about-environment-variables"&gt;Notes about environment variables&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#output-template"&gt;OUTPUT TEMPLATE&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#output-template-examples"&gt;Output template examples&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#format-selection"&gt;FORMAT SELECTION&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#filtering-formats"&gt;Filtering Formats&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#sorting-formats"&gt;Sorting Formats&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#format-selection-examples"&gt;Format Selection examples&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#modifying-metadata"&gt;MODIFYING METADATA&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#modifying-metadata-examples"&gt;Modifying metadata examples&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#extractor-arguments"&gt;EXTRACTOR ARGUMENTS&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#plugins"&gt;PLUGINS&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#installing-plugins"&gt;Installing Plugins&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#developing-plugins"&gt;Developing Plugins&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#embedding-yt-dlp"&gt;EMBEDDING YT-DLP&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#embedding-examples"&gt;Embedding examples&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#changes-from-youtube-dl"&gt;CHANGES FROM YOUTUBE-DL&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#new-features"&gt;New features&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#differences-in-default-behavior"&gt;Differences in default behavior&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#deprecated-options"&gt;Deprecated options&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/CONTRIBUTING.md#contributing-to-yt-dlp"&gt;CONTRIBUTING&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/CONTRIBUTING.md#opening-an-issue"&gt;Opening an Issue&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/CONTRIBUTING.md#developer-instructions"&gt;Developer Instructions&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/wiki"&gt;WIKI&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/wiki/FAQ"&gt;FAQ&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;!-- MANPAGE: END EXCLUDED SECTION --&gt; 
&lt;h1&gt;INSTALLATION&lt;/h1&gt; 
&lt;!-- MANPAGE: BEGIN EXCLUDED SECTION --&gt; 
&lt;p&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp.exe"&gt;&lt;img src="https://img.shields.io/badge/-Windows_x64-blue.svg?style=for-the-badge&amp;amp;logo=windows" alt="Windows" /&gt;&lt;/a&gt; &lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp"&gt;&lt;img src="https://img.shields.io/badge/-Linux/BSD-red.svg?style=for-the-badge&amp;amp;logo=linux" alt="Unix" /&gt;&lt;/a&gt; &lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_macos"&gt;&lt;img src="https://img.shields.io/badge/-MacOS-lightblue.svg?style=for-the-badge&amp;amp;logo=apple" alt="MacOS" /&gt;&lt;/a&gt; &lt;a href="https://pypi.org/project/yt-dlp"&gt;&lt;img src="https://img.shields.io/badge/-PyPI-blue.svg?logo=pypi&amp;amp;labelColor=555555&amp;amp;style=for-the-badge" alt="PyPI" /&gt;&lt;/a&gt; &lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp.tar.gz"&gt;&lt;img src="https://img.shields.io/badge/-Source_tar-green.svg?style=for-the-badge" alt="Source Tarball" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#release-files"&gt;&lt;img src="https://img.shields.io/badge/-Other-grey.svg?style=for-the-badge" alt="Other variants" /&gt;&lt;/a&gt; &lt;a href="https://github.com/yt-dlp/yt-dlp/releases"&gt;&lt;img src="https://img.shields.io/badge/-All_Versions-lightgrey.svg?style=for-the-badge" alt="All versions" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;!-- MANPAGE: END EXCLUDED SECTION --&gt; 
&lt;p&gt;You can install yt-dlp using &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#release-files"&gt;the binaries&lt;/a&gt;, &lt;a href="https://pypi.org/project/yt-dlp"&gt;pip&lt;/a&gt; or one using a third-party package manager. See &lt;a href="https://github.com/yt-dlp/yt-dlp/wiki/Installation"&gt;the wiki&lt;/a&gt; for detailed instructions&lt;/p&gt; 
&lt;!-- MANPAGE: BEGIN EXCLUDED SECTION --&gt; 
&lt;h2&gt;RELEASE FILES&lt;/h2&gt; 
&lt;h4&gt;Recommended&lt;/h4&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;File&lt;/th&gt; 
   &lt;th align="left"&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp"&gt;yt-dlp&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Platform-independent &lt;a href="https://docs.python.org/3/library/zipimport.html"&gt;zipimport&lt;/a&gt; binary. Needs Python (recommended for &lt;strong&gt;Linux/BSD&lt;/strong&gt;)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp.exe"&gt;yt-dlp.exe&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Windows (Win8+) standalone x64 binary (recommended for &lt;strong&gt;Windows&lt;/strong&gt;)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_macos"&gt;yt-dlp_macos&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Universal MacOS (10.15+) standalone executable (recommended for &lt;strong&gt;MacOS&lt;/strong&gt;)&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h4&gt;Alternatives&lt;/h4&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;File&lt;/th&gt; 
   &lt;th align="left"&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_x86.exe"&gt;yt-dlp_x86.exe&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Windows (Win8+) standalone x86 (32-bit) binary&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_arm64.exe"&gt;yt-dlp_arm64.exe&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Windows (Win10+) standalone arm64 (64-bit) binary&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_linux"&gt;yt-dlp_linux&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Linux standalone x64 binary&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_linux_armv7l"&gt;yt-dlp_linux_armv7l&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Linux standalone armv7l (32-bit) binary&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_linux_aarch64"&gt;yt-dlp_linux_aarch64&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Linux standalone aarch64 (64-bit) binary&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_win.zip"&gt;yt-dlp_win.zip&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Unpackaged Windows (Win8+) x64 executable (no auto-update)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_win_x86.zip"&gt;yt-dlp_win_x86.zip&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Unpackaged Windows (Win8+) x86 executable (no auto-update)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_win_arm64.zip"&gt;yt-dlp_win_arm64.zip&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Unpackaged Windows (Win10+) arm64 executable (no auto-update)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_macos.zip"&gt;yt-dlp_macos.zip&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Unpackaged MacOS (10.15+) executable (no auto-update)&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h4&gt;Misc&lt;/h4&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;File&lt;/th&gt; 
   &lt;th align="left"&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp.tar.gz"&gt;yt-dlp.tar.gz&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Source tarball&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/SHA2-512SUMS"&gt;SHA2-512SUMS&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;GNU-style SHA512 sums&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/SHA2-512SUMS.sig"&gt;SHA2-512SUMS.sig&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;GPG signature file for SHA512 sums&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/SHA2-256SUMS"&gt;SHA2-256SUMS&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;GNU-style SHA256 sums&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/SHA2-256SUMS.sig"&gt;SHA2-256SUMS.sig&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;GPG signature file for SHA256 sums&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;The public key that can be used to verify the GPG signatures is &lt;a href="https://github.com/yt-dlp/yt-dlp/raw/master/public.key"&gt;available here&lt;/a&gt; Example usage:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;curl -L https://github.com/yt-dlp/yt-dlp/raw/master/public.key | gpg --import
gpg --verify SHA2-256SUMS.sig SHA2-256SUMS
gpg --verify SHA2-512SUMS.sig SHA2-512SUMS
&lt;/code&gt;&lt;/pre&gt; 
&lt;!-- MANPAGE: END EXCLUDED SECTION --&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: The manpages, shell completion (autocomplete) files etc. are available inside the &lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp.tar.gz"&gt;source tarball&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;UPDATE&lt;/h2&gt; 
&lt;p&gt;You can use &lt;code&gt;yt-dlp -U&lt;/code&gt; to update if you are using the &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#release-files"&gt;release binaries&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;If you &lt;a href="https://github.com/yt-dlp/yt-dlp/wiki/Installation#with-pip"&gt;installed with pip&lt;/a&gt;, simply re-run the same command that was used to install the program&lt;/p&gt; 
&lt;p&gt;For other third-party package managers, see &lt;a href="https://github.com/yt-dlp/yt-dlp/wiki/Installation#third-party-package-managers"&gt;the wiki&lt;/a&gt; or refer to their documentation&lt;/p&gt; 
&lt;p&gt;&lt;a id="update-channels"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;There are currently three release channels for binaries: &lt;code&gt;stable&lt;/code&gt;, &lt;code&gt;nightly&lt;/code&gt; and &lt;code&gt;master&lt;/code&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;stable&lt;/code&gt; is the default channel, and many of its changes have been tested by users of the &lt;code&gt;nightly&lt;/code&gt; and &lt;code&gt;master&lt;/code&gt; channels.&lt;/li&gt; 
 &lt;li&gt;The &lt;code&gt;nightly&lt;/code&gt; channel has releases scheduled to build every day around midnight UTC, for a snapshot of the project's new patches and changes. This is the &lt;strong&gt;recommended channel for regular users&lt;/strong&gt; of yt-dlp. The &lt;code&gt;nightly&lt;/code&gt; releases are available from &lt;a href="https://github.com/yt-dlp/yt-dlp-nightly-builds/releases"&gt;yt-dlp/yt-dlp-nightly-builds&lt;/a&gt; or as development releases of the &lt;code&gt;yt-dlp&lt;/code&gt; PyPI package (which can be installed with pip's &lt;code&gt;--pre&lt;/code&gt; flag).&lt;/li&gt; 
 &lt;li&gt;The &lt;code&gt;master&lt;/code&gt; channel features releases that are built after each push to the master branch, and these will have the very latest fixes and additions, but may also be more prone to regressions. They are available from &lt;a href="https://github.com/yt-dlp/yt-dlp-master-builds/releases"&gt;yt-dlp/yt-dlp-master-builds&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;When using &lt;code&gt;--update&lt;/code&gt;/&lt;code&gt;-U&lt;/code&gt;, a release binary will only update to its current channel. &lt;code&gt;--update-to CHANNEL&lt;/code&gt; can be used to switch to a different channel when a newer version is available. &lt;code&gt;--update-to [CHANNEL@]TAG&lt;/code&gt; can also be used to upgrade or downgrade to specific tags from a channel.&lt;/p&gt; 
&lt;p&gt;You may also use &lt;code&gt;--update-to &amp;lt;repository&amp;gt;&lt;/code&gt; (&lt;code&gt;&amp;lt;owner&amp;gt;/&amp;lt;repository&amp;gt;&lt;/code&gt;) to update to a channel on a completely different repository. Be careful with what repository you are updating to though, there is no verification done for binaries from different repositories.&lt;/p&gt; 
&lt;p&gt;Example usage:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;yt-dlp --update-to master&lt;/code&gt; switch to the &lt;code&gt;master&lt;/code&gt; channel and update to its latest release&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;yt-dlp --update-to stable@2023.07.06&lt;/code&gt; upgrade/downgrade to release to &lt;code&gt;stable&lt;/code&gt; channel tag &lt;code&gt;2023.07.06&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;yt-dlp --update-to 2023.10.07&lt;/code&gt; upgrade/downgrade to tag &lt;code&gt;2023.10.07&lt;/code&gt; if it exists on the current channel&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;yt-dlp --update-to example/yt-dlp@2023.09.24&lt;/code&gt; upgrade/downgrade to the release from the &lt;code&gt;example/yt-dlp&lt;/code&gt; repository, tag &lt;code&gt;2023.09.24&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Important&lt;/strong&gt;: Any user experiencing an issue with the &lt;code&gt;stable&lt;/code&gt; release should install or update to the &lt;code&gt;nightly&lt;/code&gt; release before submitting a bug report:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;# To update to nightly from stable executable/binary:
yt-dlp --update-to nightly

# To install nightly with pip:
python3 -m pip install -U --pre "yt-dlp[default]"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;When running a yt-dlp version that is older than 90 days, you will see a warning message suggesting to update to the latest version. You can suppress this warning by adding &lt;code&gt;--no-update&lt;/code&gt; to your command or configuration file.&lt;/p&gt; 
&lt;h2&gt;DEPENDENCIES&lt;/h2&gt; 
&lt;p&gt;Python versions 3.9+ (CPython) and 3.11+ (PyPy) are supported. Other versions and implementations may or may not work correctly.&lt;/p&gt; 
&lt;!-- Python 3.5+ uses VC++14 and it is already embedded in the binary created
&lt;!x-- https://www.microsoft.com/en-us/download/details.aspx?id=26999 --x&gt;
On Windows, [Microsoft Visual C++ 2010 SP1 Redistributable Package (x86)](https://download.microsoft.com/download/1/6/5/165255E7-1014-4D0A-B094-B6A430A6BFFC/vcredist_x86.exe) is also necessary to run yt-dlp. You probably already have this, but if the executable throws an error due to missing `MSVCR100.dll` you need to install it manually.
--&gt; 
&lt;p&gt;While all the other dependencies are optional, &lt;code&gt;ffmpeg&lt;/code&gt; and &lt;code&gt;ffprobe&lt;/code&gt; are highly recommended&lt;/p&gt; 
&lt;h3&gt;Strongly recommended&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://www.ffmpeg.org"&gt;&lt;strong&gt;ffmpeg&lt;/strong&gt; and &lt;strong&gt;ffprobe&lt;/strong&gt;&lt;/a&gt; - Required for &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#format-selection"&gt;merging separate video and audio files&lt;/a&gt;, as well as for various &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#post-processing-options"&gt;post-processing&lt;/a&gt; tasks. License &lt;a href="https://www.ffmpeg.org/legal.html"&gt;depends on the build&lt;/a&gt;&lt;/p&gt; &lt;p&gt;There are bugs in ffmpeg that cause various issues when used alongside yt-dlp. Since ffmpeg is such an important dependency, we provide &lt;a href="https://github.com/yt-dlp/FFmpeg-Builds#ffmpeg-static-auto-builds"&gt;custom builds&lt;/a&gt; with patches for some of these issues at &lt;a href="https://github.com/yt-dlp/FFmpeg-Builds"&gt;yt-dlp/FFmpeg-Builds&lt;/a&gt;. See &lt;a href="https://github.com/yt-dlp/FFmpeg-Builds#patches-applied"&gt;the readme&lt;/a&gt; for details on the specific issues solved by these builds&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Important&lt;/strong&gt;: What you need is ffmpeg &lt;em&gt;binary&lt;/em&gt;, &lt;strong&gt;NOT&lt;/strong&gt; &lt;a href="https://pypi.org/project/ffmpeg"&gt;the Python package of the same name&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Networking&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/certifi/python-certifi"&gt;&lt;strong&gt;certifi&lt;/strong&gt;&lt;/a&gt;* - Provides Mozilla's root certificate bundle. Licensed under &lt;a href="https://github.com/certifi/python-certifi/raw/master/LICENSE"&gt;MPLv2&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/google/brotli"&gt;&lt;strong&gt;brotli&lt;/strong&gt;&lt;/a&gt;* or &lt;a href="https://github.com/python-hyper/brotlicffi"&gt;&lt;strong&gt;brotlicffi&lt;/strong&gt;&lt;/a&gt; - &lt;a href="https://en.wikipedia.org/wiki/Brotli"&gt;Brotli&lt;/a&gt; content encoding support. Both licensed under MIT &lt;sup&gt;&lt;a href="https://github.com/google/brotli/raw/master/LICENSE"&gt;1&lt;/a&gt; &lt;a href="https://github.com/python-hyper/brotlicffi/raw/master/LICENSE"&gt;2&lt;/a&gt; &lt;/sup&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/aaugustin/websockets"&gt;&lt;strong&gt;websockets&lt;/strong&gt;&lt;/a&gt;* - For downloading over websocket. Licensed under &lt;a href="https://github.com/aaugustin/websockets/raw/main/LICENSE"&gt;BSD-3-Clause&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/psf/requests"&gt;&lt;strong&gt;requests&lt;/strong&gt;&lt;/a&gt;* - HTTP library. For HTTPS proxy and persistent connections support. Licensed under &lt;a href="https://github.com/psf/requests/raw/main/LICENSE"&gt;Apache-2.0&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Impersonation&lt;/h4&gt; 
&lt;p&gt;The following provide support for impersonating browser requests. This may be required for some sites that employ TLS fingerprinting.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/lexiforest/curl_cffi"&gt;&lt;strong&gt;curl_cffi&lt;/strong&gt;&lt;/a&gt; (recommended) - Python binding for &lt;a href="https://github.com/lexiforest/curl-impersonate"&gt;curl-impersonate&lt;/a&gt;. Provides impersonation targets for Chrome, Edge and Safari. Licensed under &lt;a href="https://github.com/lexiforest/curl_cffi/raw/main/LICENSE"&gt;MIT&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Can be installed with the &lt;code&gt;curl-cffi&lt;/code&gt; group, e.g. &lt;code&gt;pip install "yt-dlp[default,curl-cffi]"&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;Currently included in &lt;code&gt;yt-dlp.exe&lt;/code&gt;, &lt;code&gt;yt-dlp_linux&lt;/code&gt; and &lt;code&gt;yt-dlp_macos&lt;/code&gt; builds&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Metadata&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/quodlibet/mutagen"&gt;&lt;strong&gt;mutagen&lt;/strong&gt;&lt;/a&gt;* - For &lt;code&gt;--embed-thumbnail&lt;/code&gt; in certain formats. Licensed under &lt;a href="https://github.com/quodlibet/mutagen/raw/master/COPYING"&gt;GPLv2+&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/wez/atomicparsley"&gt;&lt;strong&gt;AtomicParsley&lt;/strong&gt;&lt;/a&gt; - For &lt;code&gt;--embed-thumbnail&lt;/code&gt; in &lt;code&gt;mp4&lt;/code&gt;/&lt;code&gt;m4a&lt;/code&gt; files when &lt;code&gt;mutagen&lt;/code&gt;/&lt;code&gt;ffmpeg&lt;/code&gt; cannot. Licensed under &lt;a href="https://github.com/wez/atomicparsley/raw/master/COPYING"&gt;GPLv2+&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/xattr/xattr"&gt;&lt;strong&gt;xattr&lt;/strong&gt;&lt;/a&gt;, &lt;a href="https://github.com/iustin/pyxattr"&gt;&lt;strong&gt;pyxattr&lt;/strong&gt;&lt;/a&gt; or &lt;a href="http://savannah.nongnu.org/projects/attr"&gt;&lt;strong&gt;setfattr&lt;/strong&gt;&lt;/a&gt; - For writing xattr metadata (&lt;code&gt;--xattrs&lt;/code&gt;) on &lt;strong&gt;Mac&lt;/strong&gt; and &lt;strong&gt;BSD&lt;/strong&gt;. Licensed under &lt;a href="https://github.com/xattr/xattr/raw/master/LICENSE.txt"&gt;MIT&lt;/a&gt;, &lt;a href="https://github.com/iustin/pyxattr/raw/master/COPYING"&gt;LGPL2.1&lt;/a&gt; and &lt;a href="http://git.savannah.nongnu.org/cgit/attr.git/tree/doc/COPYING"&gt;GPLv2+&lt;/a&gt; respectively&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Misc&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Legrandin/pycryptodome"&gt;&lt;strong&gt;pycryptodomex&lt;/strong&gt;&lt;/a&gt;* - For decrypting AES-128 HLS streams and various other data. Licensed under &lt;a href="https://github.com/Legrandin/pycryptodome/raw/master/LICENSE.rst"&gt;BSD-2-Clause&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ariya/phantomjs"&gt;&lt;strong&gt;phantomjs&lt;/strong&gt;&lt;/a&gt; - Used in extractors where javascript needs to be run. Licensed under &lt;a href="https://github.com/ariya/phantomjs/raw/master/LICENSE.BSD"&gt;BSD-3-Clause&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mitya57/secretstorage"&gt;&lt;strong&gt;secretstorage&lt;/strong&gt;&lt;/a&gt;* - For &lt;code&gt;--cookies-from-browser&lt;/code&gt; to access the &lt;strong&gt;Gnome&lt;/strong&gt; keyring while decrypting cookies of &lt;strong&gt;Chromium&lt;/strong&gt;-based browsers on &lt;strong&gt;Linux&lt;/strong&gt;. Licensed under &lt;a href="https://github.com/mitya57/secretstorage/raw/master/LICENSE"&gt;BSD-3-Clause&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Any external downloader that you want to use with &lt;code&gt;--downloader&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Deprecated&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.libav.org"&gt;&lt;strong&gt;avconv&lt;/strong&gt; and &lt;strong&gt;avprobe&lt;/strong&gt;&lt;/a&gt; - Now &lt;strong&gt;deprecated&lt;/strong&gt; alternative to ffmpeg. License &lt;a href="https://libav.org/legal"&gt;depends on the build&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/faissaloo/SponSkrub"&gt;&lt;strong&gt;sponskrub&lt;/strong&gt;&lt;/a&gt; - For using the now &lt;strong&gt;deprecated&lt;/strong&gt; &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#sponskrub-options"&gt;sponskrub options&lt;/a&gt;. Licensed under &lt;a href="https://github.com/faissaloo/SponSkrub/raw/master/LICENCE.md"&gt;GPLv3+&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://rtmpdump.mplayerhq.hu"&gt;&lt;strong&gt;rtmpdump&lt;/strong&gt;&lt;/a&gt; - For downloading &lt;code&gt;rtmp&lt;/code&gt; streams. ffmpeg can be used instead with &lt;code&gt;--downloader ffmpeg&lt;/code&gt;. Licensed under &lt;a href="http://rtmpdump.mplayerhq.hu"&gt;GPLv2+&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://mplayerhq.hu/design7/info.html"&gt;&lt;strong&gt;mplayer&lt;/strong&gt;&lt;/a&gt; or &lt;a href="https://mpv.io"&gt;&lt;strong&gt;mpv&lt;/strong&gt;&lt;/a&gt; - For downloading &lt;code&gt;rstp&lt;/code&gt;/&lt;code&gt;mms&lt;/code&gt; streams. ffmpeg can be used instead with &lt;code&gt;--downloader ffmpeg&lt;/code&gt;. Licensed under &lt;a href="https://github.com/mpv-player/mpv/raw/master/Copyright"&gt;GPLv2+&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;To use or redistribute the dependencies, you must agree to their respective licensing terms.&lt;/p&gt; 
&lt;p&gt;The standalone release binaries are built with the Python interpreter and the packages marked with &lt;strong&gt;*&lt;/strong&gt; included.&lt;/p&gt; 
&lt;p&gt;If you do not have the necessary dependencies for a task you are attempting, yt-dlp will warn you. All the currently available dependencies are visible at the top of the &lt;code&gt;--verbose&lt;/code&gt; output&lt;/p&gt; 
&lt;h2&gt;COMPILE&lt;/h2&gt; 
&lt;h3&gt;Standalone PyInstaller Builds&lt;/h3&gt; 
&lt;p&gt;To build the standalone executable, you must have Python and &lt;code&gt;pyinstaller&lt;/code&gt; (plus any of yt-dlp's &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#dependencies"&gt;optional dependencies&lt;/a&gt; if needed). The executable will be built for the same CPU architecture as the Python used.&lt;/p&gt; 
&lt;p&gt;You can run the following commands:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;python3 devscripts/install_deps.py --include pyinstaller
python3 devscripts/make_lazy_extractors.py
python3 -m bundle.pyinstaller
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;On some systems, you may need to use &lt;code&gt;py&lt;/code&gt; or &lt;code&gt;python&lt;/code&gt; instead of &lt;code&gt;python3&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;python -m bundle.pyinstaller&lt;/code&gt; accepts any arguments that can be passed to &lt;code&gt;pyinstaller&lt;/code&gt;, such as &lt;code&gt;--onefile/-F&lt;/code&gt; or &lt;code&gt;--onedir/-D&lt;/code&gt;, which is further &lt;a href="https://pyinstaller.org/en/stable/usage.html#what-to-generate"&gt;documented here&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: Pyinstaller versions below 4.4 &lt;a href="https://github.com/pyinstaller/pyinstaller#requirements-and-tested-platforms"&gt;do not support&lt;/a&gt; Python installed from the Windows store without using a virtual environment.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Important&lt;/strong&gt;: Running &lt;code&gt;pyinstaller&lt;/code&gt; directly &lt;strong&gt;instead of&lt;/strong&gt; using &lt;code&gt;python -m bundle.pyinstaller&lt;/code&gt; is &lt;strong&gt;not&lt;/strong&gt; officially supported. This may or may not work correctly.&lt;/p&gt; 
&lt;h3&gt;Platform-independent Binary (UNIX)&lt;/h3&gt; 
&lt;p&gt;You will need the build tools &lt;code&gt;python&lt;/code&gt; (3.9+), &lt;code&gt;zip&lt;/code&gt;, &lt;code&gt;make&lt;/code&gt; (GNU), &lt;code&gt;pandoc&lt;/code&gt;* and &lt;code&gt;pytest&lt;/code&gt;*.&lt;/p&gt; 
&lt;p&gt;After installing these, simply run &lt;code&gt;make&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;You can also run &lt;code&gt;make yt-dlp&lt;/code&gt; instead to compile only the binary without updating any of the additional files. (The build tools marked with &lt;strong&gt;*&lt;/strong&gt; are not needed for this)&lt;/p&gt; 
&lt;h3&gt;Related scripts&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;devscripts/install_deps.py&lt;/code&gt;&lt;/strong&gt; - Install dependencies for yt-dlp.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;devscripts/update-version.py&lt;/code&gt;&lt;/strong&gt; - Update the version number based on the current date.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;devscripts/set-variant.py&lt;/code&gt;&lt;/strong&gt; - Set the build variant of the executable.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;devscripts/make_changelog.py&lt;/code&gt;&lt;/strong&gt; - Create a markdown changelog using short commit messages and update &lt;code&gt;CONTRIBUTORS&lt;/code&gt; file.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;devscripts/make_lazy_extractors.py&lt;/code&gt;&lt;/strong&gt; - Create lazy extractors. Running this before building the binaries (any variant) will improve their startup performance. Set the environment variable &lt;code&gt;YTDLP_NO_LAZY_EXTRACTORS&lt;/code&gt; to something nonempty to forcefully disable lazy extractor loading.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Note: See their &lt;code&gt;--help&lt;/code&gt; for more info.&lt;/p&gt; 
&lt;h3&gt;Forking the project&lt;/h3&gt; 
&lt;p&gt;If you fork the project on GitHub, you can run your fork's &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/.github/workflows/build.yml"&gt;build workflow&lt;/a&gt; to automatically build the selected version(s) as artifacts. Alternatively, you can run the &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/.github/workflows/release.yml"&gt;release workflow&lt;/a&gt; or enable the &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/.github/workflows/release-nightly.yml"&gt;nightly workflow&lt;/a&gt; to create full (pre-)releases.&lt;/p&gt; 
&lt;h1&gt;USAGE AND OPTIONS&lt;/h1&gt; 
&lt;!-- MANPAGE: BEGIN EXCLUDED SECTION --&gt; 
&lt;pre&gt;&lt;code&gt;yt-dlp [OPTIONS] [--] URL [URL...]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Tip: Use &lt;code&gt;CTRL&lt;/code&gt;+&lt;code&gt;F&lt;/code&gt; (or &lt;code&gt;Command&lt;/code&gt;+&lt;code&gt;F&lt;/code&gt;) to search by keywords&lt;/p&gt; 
&lt;!-- MANPAGE: END EXCLUDED SECTION --&gt; 
&lt;!-- Auto generated --&gt; 
&lt;h2&gt;General Options:&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;-h, --help                      Print this help text and exit
--version                       Print program version and exit
-U, --update                    Update this program to the latest version
--no-update                     Do not check for updates (default)
--update-to [CHANNEL]@[TAG]     Upgrade/downgrade to a specific version.
                                CHANNEL can be a repository as well. CHANNEL
                                and TAG default to "stable" and "latest"
                                respectively if omitted; See "UPDATE" for
                                details. Supported channels: stable,
                                nightly, master
-i, --ignore-errors             Ignore download and postprocessing errors.
                                The download will be considered successful
                                even if the postprocessing fails
--no-abort-on-error             Continue with next video on download errors;
                                e.g. to skip unavailable videos in a
                                playlist (default)
--abort-on-error                Abort downloading of further videos if an
                                error occurs (Alias: --no-ignore-errors)
--dump-user-agent               Display the current user-agent and exit
--list-extractors               List all supported extractors and exit
--extractor-descriptions        Output descriptions of all supported
                                extractors and exit
--use-extractors NAMES          Extractor names to use separated by commas.
                                You can also use regexes, "all", "default"
                                and "end" (end URL matching); e.g. --ies
                                "holodex.*,end,youtube". Prefix the name
                                with a "-" to exclude it, e.g. --ies
                                default,-generic. Use --list-extractors for
                                a list of extractor names. (Alias: --ies)
--default-search PREFIX         Use this prefix for unqualified URLs. E.g.
                                "gvsearch2:python" downloads two videos from
                                google videos for the search term "python".
                                Use the value "auto" to let yt-dlp guess
                                ("auto_warning" to emit a warning when
                                guessing). "error" just throws an error. The
                                default value "fixup_error" repairs broken
                                URLs, but emits an error if this is not
                                possible instead of searching
--ignore-config                 Don't load any more configuration files
                                except those given to --config-locations.
                                For backward compatibility, if this option
                                is found inside the system configuration
                                file, the user configuration is not loaded.
                                (Alias: --no-config)
--no-config-locations           Do not load any custom configuration files
                                (default). When given inside a configuration
                                file, ignore all previous --config-locations
                                defined in the current file
--config-locations PATH         Location of the main configuration file;
                                either the path to the config or its
                                containing directory ("-" for stdin). Can be
                                used multiple times and inside other
                                configuration files
--plugin-dirs PATH              Path to an additional directory to search
                                for plugins. This option can be used
                                multiple times to add multiple directories.
                                Use "default" to search the default plugin
                                directories (default)
--no-plugin-dirs                Clear plugin directories to search,
                                including defaults and those provided by
                                previous --plugin-dirs
--flat-playlist                 Do not extract a playlist's URL result
                                entries; some entry metadata may be missing
                                and downloading may be bypassed
--no-flat-playlist              Fully extract the videos of a playlist
                                (default)
--live-from-start               Download livestreams from the start.
                                Currently experimental and only supported
                                for YouTube and Twitch
--no-live-from-start            Download livestreams from the current time
                                (default)
--wait-for-video MIN[-MAX]      Wait for scheduled streams to become
                                available. Pass the minimum number of
                                seconds (or range) to wait between retries
--no-wait-for-video             Do not wait for scheduled streams (default)
--mark-watched                  Mark videos watched (even with --simulate)
--no-mark-watched               Do not mark videos watched (default)
--color [STREAM:]POLICY         Whether to emit color codes in output,
                                optionally prefixed by the STREAM (stdout or
                                stderr) to apply the setting to. Can be one
                                of "always", "auto" (default), "never", or
                                "no_color" (use non color terminal
                                sequences). Use "auto-tty" or "no_color-tty"
                                to decide based on terminal support only.
                                Can be used multiple times
--compat-options OPTS           Options that can help keep compatibility
                                with youtube-dl or youtube-dlc
                                configurations by reverting some of the
                                changes made in yt-dlp. See "Differences in
                                default behavior" for details
--alias ALIASES OPTIONS         Create aliases for an option string. Unless
                                an alias starts with a dash "-", it is
                                prefixed with "--". Arguments are parsed
                                according to the Python string formatting
                                mini-language. E.g. --alias get-audio,-X "-S
                                aext:{0},abr -x --audio-format {0}" creates
                                options "--get-audio" and "-X" that takes an
                                argument (ARG0) and expands to "-S
                                aext:ARG0,abr -x --audio-format ARG0". All
                                defined aliases are listed in the --help
                                output. Alias options can trigger more
                                aliases; so be careful to avoid defining
                                recursive options. As a safety measure, each
                                alias may be triggered a maximum of 100
                                times. This option can be used multiple times
-t, --preset-alias PRESET       Applies a predefined set of options. e.g.
                                --preset-alias mp3. The following presets
                                are available: mp3, aac, mp4, mkv, sleep.
                                See the "Preset Aliases" section at the end
                                for more info. This option can be used
                                multiple times
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Network Options:&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;--proxy URL                     Use the specified HTTP/HTTPS/SOCKS proxy. To
                                enable SOCKS proxy, specify a proper scheme,
                                e.g. socks5://user:pass@127.0.0.1:1080/.
                                Pass in an empty string (--proxy "") for
                                direct connection
--socket-timeout SECONDS        Time to wait before giving up, in seconds
--source-address IP             Client-side IP address to bind to
--impersonate CLIENT[:OS]       Client to impersonate for requests. E.g.
                                chrome, chrome-110, chrome:windows-10. Pass
                                --impersonate="" to impersonate any client.
                                Note that forcing impersonation for all
                                requests may have a detrimental impact on
                                download speed and stability
--list-impersonate-targets      List available clients to impersonate.
-4, --force-ipv4                Make all connections via IPv4
-6, --force-ipv6                Make all connections via IPv6
--enable-file-urls              Enable file:// URLs. This is disabled by
                                default for security reasons.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Geo-restriction:&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;--geo-verification-proxy URL    Use this proxy to verify the IP address for
                                some geo-restricted sites. The default proxy
                                specified by --proxy (or none, if the option
                                is not present) is used for the actual
                                downloading
--xff VALUE                     How to fake X-Forwarded-For HTTP header to
                                try bypassing geographic restriction. One of
                                "default" (only when known to be useful),
                                "never", an IP block in CIDR notation, or a
                                two-letter ISO 3166-2 country code
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Video Selection:&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;-I, --playlist-items ITEM_SPEC  Comma separated playlist_index of the items
                                to download. You can specify a range using
                                "[START]:[STOP][:STEP]". For backward
                                compatibility, START-STOP is also supported.
                                Use negative indices to count from the right
                                and negative STEP to download in reverse
                                order. E.g. "-I 1:3,7,-5::2" used on a
                                playlist of size 15 will download the items
                                at index 1,2,3,7,11,13,15
--min-filesize SIZE             Abort download if filesize is smaller than
                                SIZE, e.g. 50k or 44.6M
--max-filesize SIZE             Abort download if filesize is larger than
                                SIZE, e.g. 50k or 44.6M
--date DATE                     Download only videos uploaded on this date.
                                The date can be "YYYYMMDD" or in the format 
                                [now|today|yesterday][-N[day|week|month|year]].
                                E.g. "--date today-2weeks" downloads only
                                videos uploaded on the same day two weeks ago
--datebefore DATE               Download only videos uploaded on or before
                                this date. The date formats accepted are the
                                same as --date
--dateafter DATE                Download only videos uploaded on or after
                                this date. The date formats accepted are the
                                same as --date
--match-filters FILTER          Generic video filter. Any "OUTPUT TEMPLATE"
                                field can be compared with a number or a
                                string using the operators defined in
                                "Filtering Formats". You can also simply
                                specify a field to match if the field is
                                present, use "!field" to check if the field
                                is not present, and "&amp;amp;" to check multiple
                                conditions. Use a "\" to escape "&amp;amp;" or
                                quotes if needed. If used multiple times,
                                the filter matches if at least one of the
                                conditions is met. E.g. --match-filters
                                !is_live --match-filters "like_count&amp;gt;?100 &amp;amp;
                                description~='(?i)\bcats \&amp;amp; dogs\b'" matches
                                only videos that are not live OR those that
                                have a like count more than 100 (or the like
                                field is not available) and also has a
                                description that contains the phrase "cats &amp;amp;
                                dogs" (caseless). Use "--match-filters -" to
                                interactively ask whether to download each
                                video
--no-match-filters              Do not use any --match-filters (default)
--break-match-filters FILTER    Same as "--match-filters" but stops the
                                download process when a video is rejected
--no-break-match-filters        Do not use any --break-match-filters (default)
--no-playlist                   Download only the video, if the URL refers
                                to a video and a playlist
--yes-playlist                  Download the playlist, if the URL refers to
                                a video and a playlist
--age-limit YEARS               Download only videos suitable for the given
                                age
--download-archive FILE         Download only videos not listed in the
                                archive file. Record the IDs of all
                                downloaded videos in it
--no-download-archive           Do not use archive file (default)
--max-downloads NUMBER          Abort after downloading NUMBER files
--break-on-existing             Stop the download process when encountering
                                a file that is in the archive supplied with
                                the --download-archive option
--no-break-on-existing          Do not stop the download process when
                                encountering a file that is in the archive
                                (default)
--break-per-input               Alters --max-downloads, --break-on-existing,
                                --break-match-filters, and autonumber to
                                reset per input URL
--no-break-per-input            --break-on-existing and similar options
                                terminates the entire download queue
--skip-playlist-after-errors N  Number of allowed failures until the rest of
                                the playlist is skipped
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Download Options:&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;-N, --concurrent-fragments N    Number of fragments of a dash/hlsnative
                                video that should be downloaded concurrently
                                (default is 1)
-r, --limit-rate RATE           Maximum download rate in bytes per second,
                                e.g. 50K or 4.2M
--throttled-rate RATE           Minimum download rate in bytes per second
                                below which throttling is assumed and the
                                video data is re-extracted, e.g. 100K
-R, --retries RETRIES           Number of retries (default is 10), or
                                "infinite"
--file-access-retries RETRIES   Number of times to retry on file access
                                error (default is 3), or "infinite"
--fragment-retries RETRIES      Number of retries for a fragment (default is
                                10), or "infinite" (DASH, hlsnative and ISM)
--retry-sleep [TYPE:]EXPR       Time to sleep between retries in seconds
                                (optionally) prefixed by the type of retry
                                (http (default), fragment, file_access,
                                extractor) to apply the sleep to. EXPR can
                                be a number, linear=START[:END[:STEP=1]] or
                                exp=START[:END[:BASE=2]]. This option can be
                                used multiple times to set the sleep for the
                                different retry types, e.g. --retry-sleep
                                linear=1::2 --retry-sleep fragment:exp=1:20
--skip-unavailable-fragments    Skip unavailable fragments for DASH,
                                hlsnative and ISM downloads (default)
                                (Alias: --no-abort-on-unavailable-fragments)
--abort-on-unavailable-fragments
                                Abort download if a fragment is unavailable
                                (Alias: --no-skip-unavailable-fragments)
--keep-fragments                Keep downloaded fragments on disk after
                                downloading is finished
--no-keep-fragments             Delete downloaded fragments after
                                downloading is finished (default)
--buffer-size SIZE              Size of download buffer, e.g. 1024 or 16K
                                (default is 1024)
--resize-buffer                 The buffer size is automatically resized
                                from an initial value of --buffer-size
                                (default)
--no-resize-buffer              Do not automatically adjust the buffer size
--http-chunk-size SIZE          Size of a chunk for chunk-based HTTP
                                downloading, e.g. 10485760 or 10M (default
                                is disabled). May be useful for bypassing
                                bandwidth throttling imposed by a webserver
                                (experimental)
--playlist-random               Download playlist videos in random order
--lazy-playlist                 Process entries in the playlist as they are
                                received. This disables n_entries,
                                --playlist-random and --playlist-reverse
--no-lazy-playlist              Process videos in the playlist only after
                                the entire playlist is parsed (default)
--xattr-set-filesize            Set file xattribute ytdl.filesize with
                                expected file size
--hls-use-mpegts                Use the mpegts container for HLS videos;
                                allowing some players to play the video
                                while downloading, and reducing the chance
                                of file corruption if download is
                                interrupted. This is enabled by default for
                                live streams
--no-hls-use-mpegts             Do not use the mpegts container for HLS
                                videos. This is default when not downloading
                                live streams
--download-sections REGEX       Download only chapters that match the
                                regular expression. A "*" prefix denotes
                                time-range instead of chapter. Negative
                                timestamps are calculated from the end.
                                "*from-url" can be used to download between
                                the "start_time" and "end_time" extracted
                                from the URL. Needs ffmpeg. This option can
                                be used multiple times to download multiple
                                sections, e.g. --download-sections
                                "*10:15-inf" --download-sections "intro"
--downloader [PROTO:]NAME       Name or path of the external downloader to
                                use (optionally) prefixed by the protocols
                                (http, ftp, m3u8, dash, rstp, rtmp, mms) to
                                use it for. Currently supports native,
                                aria2c, avconv, axel, curl, ffmpeg, httpie,
                                wget. You can use this option multiple times
                                to set different downloaders for different
                                protocols. E.g. --downloader aria2c
                                --downloader "dash,m3u8:native" will use
                                aria2c for http/ftp downloads, and the
                                native downloader for dash/m3u8 downloads
                                (Alias: --external-downloader)
--downloader-args NAME:ARGS     Give these arguments to the external
                                downloader. Specify the downloader name and
                                the arguments separated by a colon ":". For
                                ffmpeg, arguments can be passed to different
                                positions using the same syntax as
                                --postprocessor-args. You can use this
                                option multiple times to give different
                                arguments to different downloaders (Alias:
                                --external-downloader-args)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Filesystem Options:&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;-a, --batch-file FILE           File containing URLs to download ("-" for
                                stdin), one URL per line. Lines starting
                                with "#", ";" or "]" are considered as
                                comments and ignored
--no-batch-file                 Do not read URLs from batch file (default)
-P, --paths [TYPES:]PATH        The paths where the files should be
                                downloaded. Specify the type of file and the
                                path separated by a colon ":". All the same
                                TYPES as --output are supported.
                                Additionally, you can also provide "home"
                                (default) and "temp" paths. All intermediary
                                files are first downloaded to the temp path
                                and then the final files are moved over to
                                the home path after download is finished.
                                This option is ignored if --output is an
                                absolute path
-o, --output [TYPES:]TEMPLATE   Output filename template; see "OUTPUT
                                TEMPLATE" for details
--output-na-placeholder TEXT    Placeholder for unavailable fields in
                                --output (default: "NA")
--restrict-filenames            Restrict filenames to only ASCII characters,
                                and avoid "&amp;amp;" and spaces in filenames
--no-restrict-filenames         Allow Unicode characters, "&amp;amp;" and spaces in
                                filenames (default)
--windows-filenames             Force filenames to be Windows-compatible
--no-windows-filenames          Sanitize filenames only minimally
--trim-filenames LENGTH         Limit the filename length (excluding
                                extension) to the specified number of
                                characters
-w, --no-overwrites             Do not overwrite any files
--force-overwrites              Overwrite all video and metadata files. This
                                option includes --no-continue
--no-force-overwrites           Do not overwrite the video, but overwrite
                                related files (default)
-c, --continue                  Resume partially downloaded files/fragments
                                (default)
--no-continue                   Do not resume partially downloaded
                                fragments. If the file is not fragmented,
                                restart download of the entire file
--part                          Use .part files instead of writing directly
                                into output file (default)
--no-part                       Do not use .part files - write directly into
                                output file
--mtime                         Use the Last-modified header to set the file
                                modification time
--no-mtime                      Do not use the Last-modified header to set
                                the file modification time (default)
--write-description             Write video description to a .description file
--no-write-description          Do not write video description (default)
--write-info-json               Write video metadata to a .info.json file
                                (this may contain personal information)
--no-write-info-json            Do not write video metadata (default)
--write-playlist-metafiles      Write playlist metadata in addition to the
                                video metadata when using --write-info-json,
                                --write-description etc. (default)
--no-write-playlist-metafiles   Do not write playlist metadata when using
                                --write-info-json, --write-description etc.
--clean-info-json               Remove some internal metadata such as
                                filenames from the infojson (default)
--no-clean-info-json            Write all fields to the infojson
--write-comments                Retrieve video comments to be placed in the
                                infojson. The comments are fetched even
                                without this option if the extraction is
                                known to be quick (Alias: --get-comments)
--no-write-comments             Do not retrieve video comments unless the
                                extraction is known to be quick (Alias:
                                --no-get-comments)
--load-info-json FILE           JSON file containing the video information
                                (created with the "--write-info-json" option)
--cookies FILE                  Netscape formatted file to read cookies from
                                and dump cookie jar in
--no-cookies                    Do not read/dump cookies from/to file
                                (default)
--cookies-from-browser BROWSER[+KEYRING][:PROFILE][::CONTAINER]
                                The name of the browser to load cookies
                                from. Currently supported browsers are:
                                brave, chrome, chromium, edge, firefox,
                                opera, safari, vivaldi, whale. Optionally,
                                the KEYRING used for decrypting Chromium
                                cookies on Linux, the name/path of the
                                PROFILE to load cookies from, and the
                                CONTAINER name (if Firefox) ("none" for no
                                container) can be given with their
                                respective separators. By default, all
                                containers of the most recently accessed
                                profile are used. Currently supported
                                keyrings are: basictext, gnomekeyring,
                                kwallet, kwallet5, kwallet6
--no-cookies-from-browser       Do not load cookies from browser (default)
--cache-dir DIR                 Location in the filesystem where yt-dlp can
                                store some downloaded information (such as
                                client ids and signatures) permanently. By
                                default ${XDG_CACHE_HOME}/yt-dlp
--no-cache-dir                  Disable filesystem caching
--rm-cache-dir                  Delete all filesystem cache files
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Thumbnail Options:&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;--write-thumbnail               Write thumbnail image to disk
--no-write-thumbnail            Do not write thumbnail image to disk (default)
--write-all-thumbnails          Write all thumbnail image formats to disk
--list-thumbnails               List available thumbnails of each video.
                                Simulate unless --no-simulate is used
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Internet Shortcut Options:&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;--write-link                    Write an internet shortcut file, depending
                                on the current platform (.url, .webloc or
                                .desktop). The URL may be cached by the OS
--write-url-link                Write a .url Windows internet shortcut. The
                                OS caches the URL based on the file path
--write-webloc-link             Write a .webloc macOS internet shortcut
--write-desktop-link            Write a .desktop Linux internet shortcut
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Verbosity and Simulation Options:&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;-q, --quiet                     Activate quiet mode. If used with --verbose,
                                print the log to stderr
--no-quiet                      Deactivate quiet mode. (Default)
--no-warnings                   Ignore warnings
-s, --simulate                  Do not download the video and do not write
                                anything to disk
--no-simulate                   Download the video even if printing/listing
                                options are used
--ignore-no-formats-error       Ignore "No video formats" error. Useful for
                                extracting metadata even if the videos are
                                not actually available for download
                                (experimental)
--no-ignore-no-formats-error    Throw error when no downloadable video
                                formats are found (default)
--skip-download                 Do not download the video but write all
                                related files (Alias: --no-download)
-O, --print [WHEN:]TEMPLATE     Field name or output template to print to
                                screen, optionally prefixed with when to
                                print it, separated by a ":". Supported
                                values of "WHEN" are the same as that of
                                --use-postprocessor (default: video).
                                Implies --quiet. Implies --simulate unless
                                --no-simulate or later stages of WHEN are
                                used. This option can be used multiple times
--print-to-file [WHEN:]TEMPLATE FILE
                                Append given template to the file. The
                                values of WHEN and TEMPLATE are the same as
                                that of --print. FILE uses the same syntax
                                as the output template. This option can be
                                used multiple times
-j, --dump-json                 Quiet, but print JSON information for each
                                video. Simulate unless --no-simulate is
                                used. See "OUTPUT TEMPLATE" for a
                                description of available keys
-J, --dump-single-json          Quiet, but print JSON information for each
                                URL or infojson passed. Simulate unless
                                --no-simulate is used. If the URL refers to
                                a playlist, the whole playlist information
                                is dumped in a single line
--force-write-archive           Force download archive entries to be written
                                as far as no errors occur, even if -s or
                                another simulation option is used (Alias:
                                --force-download-archive)
--newline                       Output progress bar as new lines
--no-progress                   Do not print progress bar
--progress                      Show progress bar, even if in quiet mode
--console-title                 Display progress in console titlebar
--progress-template [TYPES:]TEMPLATE
                                Template for progress outputs, optionally
                                prefixed with one of "download:" (default),
                                "download-title:" (the console title),
                                "postprocess:",  or "postprocess-title:".
                                The video's fields are accessible under the
                                "info" key and the progress attributes are
                                accessible under "progress" key. E.g.
                                --console-title --progress-template
                                "download-title:%(info.id)s-%(progress.eta)s"
--progress-delta SECONDS        Time between progress output (default: 0)
-v, --verbose                   Print various debugging information
--dump-pages                    Print downloaded pages encoded using base64
                                to debug problems (very verbose)
--write-pages                   Write downloaded intermediary pages to files
                                in the current directory to debug problems
--print-traffic                 Display sent and read HTTP traffic
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Workarounds:&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;--encoding ENCODING             Force the specified encoding (experimental)
--legacy-server-connect         Explicitly allow HTTPS connection to servers
                                that do not support RFC 5746 secure
                                renegotiation
--no-check-certificates         Suppress HTTPS certificate validation
--prefer-insecure               Use an unencrypted connection to retrieve
                                information about the video (Currently
                                supported only for YouTube)
--add-headers FIELD:VALUE       Specify a custom HTTP header and its value,
                                separated by a colon ":". You can use this
                                option multiple times
--bidi-workaround               Work around terminals that lack
                                bidirectional text support. Requires bidiv
                                or fribidi executable in PATH
--sleep-requests SECONDS        Number of seconds to sleep between requests
                                during data extraction
--sleep-interval SECONDS        Number of seconds to sleep before each
                                download. This is the minimum time to sleep
                                when used along with --max-sleep-interval
                                (Alias: --min-sleep-interval)
--max-sleep-interval SECONDS    Maximum number of seconds to sleep. Can only
                                be used along with --min-sleep-interval
--sleep-subtitles SECONDS       Number of seconds to sleep before each
                                subtitle download
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Video Format Options:&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;-f, --format FORMAT             Video format code, see "FORMAT SELECTION"
                                for more details
-S, --format-sort SORTORDER     Sort the formats by the fields given, see
                                "Sorting Formats" for more details
--format-sort-force             Force user specified sort order to have
                                precedence over all fields, see "Sorting
                                Formats" for more details (Alias: --S-force)
--no-format-sort-force          Some fields have precedence over the user
                                specified sort order (default)
--video-multistreams            Allow multiple video streams to be merged
                                into a single file
--no-video-multistreams         Only one video stream is downloaded for each
                                output file (default)
--audio-multistreams            Allow multiple audio streams to be merged
                                into a single file
--no-audio-multistreams         Only one audio stream is downloaded for each
                                output file (default)
--prefer-free-formats           Prefer video formats with free containers
                                over non-free ones of the same quality. Use
                                with "-S ext" to strictly prefer free
                                containers irrespective of quality
--no-prefer-free-formats        Don't give any special preference to free
                                containers (default)
--check-formats                 Make sure formats are selected only from
                                those that are actually downloadable
--check-all-formats             Check all formats for whether they are
                                actually downloadable
--no-check-formats              Do not check that the formats are actually
                                downloadable
-F, --list-formats              List available formats of each video.
                                Simulate unless --no-simulate is used
--merge-output-format FORMAT    Containers that may be used when merging
                                formats, separated by "/", e.g. "mp4/mkv".
                                Ignored if no merge is required. (currently
                                supported: avi, flv, mkv, mov, mp4, webm)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Subtitle Options:&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;--write-subs                    Write subtitle file
--no-write-subs                 Do not write subtitle file (default)
--write-auto-subs               Write automatically generated subtitle file
                                (Alias: --write-automatic-subs)
--no-write-auto-subs            Do not write auto-generated subtitles
                                (default) (Alias: --no-write-automatic-subs)
--list-subs                     List available subtitles of each video.
                                Simulate unless --no-simulate is used
--sub-format FORMAT             Subtitle format; accepts formats preference
                                separated by "/", e.g. "srt" or "ass/srt/best"
--sub-langs LANGS               Languages of the subtitles to download (can
                                be regex) or "all" separated by commas, e.g.
                                --sub-langs "en.*,ja" (where "en.*" is a
                                regex pattern that matches "en" followed by
                                0 or more of any character). You can prefix
                                the language code with a "-" to exclude it
                                from the requested languages, e.g. --sub-
                                langs all,-live_chat. Use --list-subs for a
                                list of available language tags
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Authentication Options:&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;-u, --username USERNAME         Login with this account ID
-p, --password PASSWORD         Account password. If this option is left
                                out, yt-dlp will ask interactively
-2, --twofactor TWOFACTOR       Two-factor authentication code
-n, --netrc                     Use .netrc authentication data
--netrc-location PATH           Location of .netrc authentication data;
                                either the path or its containing directory.
                                Defaults to ~/.netrc
--netrc-cmd NETRC_CMD           Command to execute to get the credentials
                                for an extractor.
--video-password PASSWORD       Video-specific password
--ap-mso MSO                    Adobe Pass multiple-system operator (TV
                                provider) identifier, use --ap-list-mso for
                                a list of available MSOs
--ap-username USERNAME          Multiple-system operator account login
--ap-password PASSWORD          Multiple-system operator account password.
                                If this option is left out, yt-dlp will ask
                                interactively
--ap-list-mso                   List all supported multiple-system operators
--client-certificate CERTFILE   Path to client certificate file in PEM
                                format. May include the private key
--client-certificate-key KEYFILE
                                Path to private key file for client
                                certificate
--client-certificate-password PASSWORD
                                Password for client certificate private key,
                                if encrypted. If not provided, and the key
                                is encrypted, yt-dlp will ask interactively
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Post-Processing Options:&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;-x, --extract-audio             Convert video files to audio-only files
                                (requires ffmpeg and ffprobe)
--audio-format FORMAT           Format to convert the audio to when -x is
                                used. (currently supported: best (default),
                                aac, alac, flac, m4a, mp3, opus, vorbis,
                                wav). You can specify multiple rules using
                                similar syntax as --remux-video
--audio-quality QUALITY         Specify ffmpeg audio quality to use when
                                converting the audio with -x. Insert a value
                                between 0 (best) and 10 (worst) for VBR or a
                                specific bitrate like 128K (default 5)
--remux-video FORMAT            Remux the video into another container if
                                necessary (currently supported: avi, flv,
                                gif, mkv, mov, mp4, webm, aac, aiff, alac,
                                flac, m4a, mka, mp3, ogg, opus, vorbis,
                                wav). If the target container does not
                                support the video/audio codec, remuxing will
                                fail. You can specify multiple rules; e.g.
                                "aac&amp;gt;m4a/mov&amp;gt;mp4/mkv" will remux aac to m4a,
                                mov to mp4 and anything else to mkv
--recode-video FORMAT           Re-encode the video into another format if
                                necessary. The syntax and supported formats
                                are the same as --remux-video
--postprocessor-args NAME:ARGS  Give these arguments to the postprocessors.
                                Specify the postprocessor/executable name
                                and the arguments separated by a colon ":"
                                to give the argument to the specified
                                postprocessor/executable. Supported PP are:
                                Merger, ModifyChapters, SplitChapters,
                                ExtractAudio, VideoRemuxer, VideoConvertor,
                                Metadata, EmbedSubtitle, EmbedThumbnail,
                                SubtitlesConvertor, ThumbnailsConvertor,
                                FixupStretched, FixupM4a, FixupM3u8,
                                FixupTimestamp and FixupDuration. The
                                supported executables are: AtomicParsley,
                                FFmpeg and FFprobe. You can also specify
                                "PP+EXE:ARGS" to give the arguments to the
                                specified executable only when being used by
                                the specified postprocessor. Additionally,
                                for ffmpeg/ffprobe, "_i"/"_o" can be
                                appended to the prefix optionally followed
                                by a number to pass the argument before the
                                specified input/output file, e.g. --ppa
                                "Merger+ffmpeg_i1:-v quiet". You can use
                                this option multiple times to give different
                                arguments to different postprocessors.
                                (Alias: --ppa)
-k, --keep-video                Keep the intermediate video file on disk
                                after post-processing
--no-keep-video                 Delete the intermediate video file after
                                post-processing (default)
--post-overwrites               Overwrite post-processed files (default)
--no-post-overwrites            Do not overwrite post-processed files
--embed-subs                    Embed subtitles in the video (only for mp4,
                                webm and mkv videos)
--no-embed-subs                 Do not embed subtitles (default)
--embed-thumbnail               Embed thumbnail in the video as cover art
--no-embed-thumbnail            Do not embed thumbnail (default)
--embed-metadata                Embed metadata to the video file. Also
                                embeds chapters/infojson if present unless
                                --no-embed-chapters/--no-embed-info-json are
                                used (Alias: --add-metadata)
--no-embed-metadata             Do not add metadata to file (default)
                                (Alias: --no-add-metadata)
--embed-chapters                Add chapter markers to the video file
                                (Alias: --add-chapters)
--no-embed-chapters             Do not add chapter markers (default) (Alias:
                                --no-add-chapters)
--embed-info-json               Embed the infojson as an attachment to
                                mkv/mka video files
--no-embed-info-json            Do not embed the infojson as an attachment
                                to the video file
--parse-metadata [WHEN:]FROM:TO
                                Parse additional metadata like title/artist
                                from other fields; see "MODIFYING METADATA"
                                for details. Supported values of "WHEN" are
                                the same as that of --use-postprocessor
                                (default: pre_process)
--replace-in-metadata [WHEN:]FIELDS REGEX REPLACE
                                Replace text in a metadata field using the
                                given regex. This option can be used
                                multiple times. Supported values of "WHEN"
                                are the same as that of --use-postprocessor
                                (default: pre_process)
--xattrs                        Write metadata to the video file's xattrs
                                (using Dublin Core and XDG standards)
--concat-playlist POLICY        Concatenate videos in a playlist. One of
                                "never", "always", or "multi_video"
                                (default; only when the videos form a single
                                show). All the video files must have the
                                same codecs and number of streams to be
                                concatenable. The "pl_video:" prefix can be
                                used with "--paths" and "--output" to set
                                the output filename for the concatenated
                                files. See "OUTPUT TEMPLATE" for details
--fixup POLICY                  Automatically correct known faults of the
                                file. One of never (do nothing), warn (only
                                emit a warning), detect_or_warn (the
                                default; fix the file if we can, warn
                                otherwise), force (try fixing even if the
                                file already exists)
--ffmpeg-location PATH          Location of the ffmpeg binary; either the
                                path to the binary or its containing directory
--exec [WHEN:]CMD               Execute a command, optionally prefixed with
                                when to execute it, separated by a ":".
                                Supported values of "WHEN" are the same as
                                that of --use-postprocessor (default:
                                after_move). The same syntax as the output
                                template can be used to pass any field as
                                arguments to the command. If no fields are
                                passed, %(filepath,_filename|)q is appended
                                to the end of the command. This option can
                                be used multiple times
--no-exec                       Remove any previously defined --exec
--convert-subs FORMAT           Convert the subtitles to another format
                                (currently supported: ass, lrc, srt, vtt).
                                Use "--convert-subs none" to disable
                                conversion (default) (Alias: --convert-
                                subtitles)
--convert-thumbnails FORMAT     Convert the thumbnails to another format
                                (currently supported: jpg, png, webp). You
                                can specify multiple rules using similar
                                syntax as "--remux-video". Use "--convert-
                                thumbnails none" to disable conversion
                                (default)
--split-chapters                Split video into multiple files based on
                                internal chapters. The "chapter:" prefix can
                                be used with "--paths" and "--output" to set
                                the output filename for the split files. See
                                "OUTPUT TEMPLATE" for details
--no-split-chapters             Do not split video based on chapters (default)
--remove-chapters REGEX         Remove chapters whose title matches the
                                given regular expression. The syntax is the
                                same as --download-sections. This option can
                                be used multiple times
--no-remove-chapters            Do not remove any chapters from the file
                                (default)
--force-keyframes-at-cuts       Force keyframes at cuts when
                                downloading/splitting/removing sections.
                                This is slow due to needing a re-encode, but
                                the resulting video may have fewer artifacts
                                around the cuts
--no-force-keyframes-at-cuts    Do not force keyframes around the chapters
                                when cutting/splitting (default)
--use-postprocessor NAME[:ARGS]
                                The (case-sensitive) name of plugin
                                postprocessors to be enabled, and
                                (optionally) arguments to be passed to it,
                                separated by a colon ":". ARGS are a
                                semicolon ";" delimited list of NAME=VALUE.
                                The "when" argument determines when the
                                postprocessor is invoked. It can be one of
                                "pre_process" (after video extraction),
                                "after_filter" (after video passes filter),
                                "video" (after --format; before
                                --print/--output), "before_dl" (before each
                                video download), "post_process" (after each
                                video download; default), "after_move"
                                (after moving the video file to its final
                                location), "after_video" (after downloading
                                and processing all formats of a video), or
                                "playlist" (at end of playlist). This option
                                can be used multiple times to add different
                                postprocessors
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;SponsorBlock Options:&lt;/h2&gt; 
&lt;p&gt;Make chapter entries for, or remove various segments (sponsor, introductions, etc.) from downloaded YouTube videos using the &lt;a href="https://sponsor.ajay.app"&gt;SponsorBlock API&lt;/a&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;--sponsorblock-mark CATS        SponsorBlock categories to create chapters
                                for, separated by commas. Available
                                categories are sponsor, intro, outro,
                                selfpromo, preview, filler, interaction,
                                music_offtopic, poi_highlight, chapter, all
                                and default (=all). You can prefix the
                                category with a "-" to exclude it. See [1]
                                for descriptions of the categories. E.g.
                                --sponsorblock-mark all,-preview
                                [1] https://wiki.sponsor.ajay.app/w/Segment_Categories
--sponsorblock-remove CATS      SponsorBlock categories to be removed from
                                the video file, separated by commas. If a
                                category is present in both mark and remove,
                                remove takes precedence. The syntax and
                                available categories are the same as for
                                --sponsorblock-mark except that "default"
                                refers to "all,-filler" and poi_highlight,
                                chapter are not available
--sponsorblock-chapter-title TEMPLATE
                                An output template for the title of the
                                SponsorBlock chapters created by
                                --sponsorblock-mark. The only available
                                fields are start_time, end_time, category,
                                categories, name, category_names. Defaults
                                to "[SponsorBlock]: %(category_names)l"
--no-sponsorblock               Disable both --sponsorblock-mark and
                                --sponsorblock-remove
--sponsorblock-api URL          SponsorBlock API location, defaults to
                                https://sponsor.ajay.app
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Extractor Options:&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;--extractor-retries RETRIES     Number of retries for known extractor errors
                                (default is 3), or "infinite"
--allow-dynamic-mpd             Process dynamic DASH manifests (default)
                                (Alias: --no-ignore-dynamic-mpd)
--ignore-dynamic-mpd            Do not process dynamic DASH manifests
                                (Alias: --no-allow-dynamic-mpd)
--hls-split-discontinuity       Split HLS playlists to different formats at
                                discontinuities such as ad breaks
--no-hls-split-discontinuity    Do not split HLS playlists into different
                                formats at discontinuities such as ad breaks
                                (default)
--extractor-args IE_KEY:ARGS    Pass ARGS arguments to the IE_KEY extractor.
                                See "EXTRACTOR ARGUMENTS" for details. You
                                can use this option multiple times to give
                                arguments for different extractors
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Preset Aliases:&lt;/h2&gt; 
&lt;p&gt;Predefined aliases for convenience and ease of use. Note that future versions of yt-dlp may add or adjust presets, but the existing preset names will not be changed or removed&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;-t mp3                          -f 'ba[acodec^=mp3]/ba/b' -x --audio-format
                                mp3

-t aac                          -f
                                'ba[acodec^=aac]/ba[acodec^=mp4a.40.]/ba/b'
                                -x --audio-format aac

-t mp4                          --merge-output-format mp4 --remux-video mp4
                                -S vcodec:h264,lang,quality,res,fps,hdr:12,a
                                codec:aac

-t mkv                          --merge-output-format mkv --remux-video mkv

-t sleep                        --sleep-subtitles 5 --sleep-requests 0.75
                                --sleep-interval 10 --max-sleep-interval 20
&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;CONFIGURATION&lt;/h1&gt; 
&lt;p&gt;You can configure yt-dlp by placing any supported command line option in a configuration file. The configuration is loaded from the following locations:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Main Configuration&lt;/strong&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;The file given to &lt;code&gt;--config-location&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Portable Configuration&lt;/strong&gt;: (Recommended for portable installations)&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;If using a binary, &lt;code&gt;yt-dlp.conf&lt;/code&gt; in the same directory as the binary&lt;/li&gt; 
   &lt;li&gt;If running from source-code, &lt;code&gt;yt-dlp.conf&lt;/code&gt; in the parent directory of &lt;code&gt;yt_dlp&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Home Configuration&lt;/strong&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;yt-dlp.conf&lt;/code&gt; in the home path given to &lt;code&gt;-P&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;If &lt;code&gt;-P&lt;/code&gt; is not given, the current directory is searched&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;User Configuration&lt;/strong&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;${XDG_CONFIG_HOME}/yt-dlp.conf&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;${XDG_CONFIG_HOME}/yt-dlp/config&lt;/code&gt; (recommended on Linux/macOS)&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;${XDG_CONFIG_HOME}/yt-dlp/config.txt&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;${APPDATA}/yt-dlp.conf&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;${APPDATA}/yt-dlp/config&lt;/code&gt; (recommended on Windows)&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;${APPDATA}/yt-dlp/config.txt&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;~/yt-dlp.conf&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;~/yt-dlp.conf.txt&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;~/.yt-dlp/config&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;~/.yt-dlp/config.txt&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;p&gt;See also: &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#notes-about-environment-variables"&gt;Notes about environment variables&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;System Configuration&lt;/strong&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;/etc/yt-dlp.conf&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;/etc/yt-dlp/config&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;/etc/yt-dlp/config.txt&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;E.g. with the following configuration file, yt-dlp will always extract the audio, copy the mtime, use a proxy and save all videos under &lt;code&gt;YouTube&lt;/code&gt; directory in your home directory:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;# Lines starting with # are comments

# Always extract audio
-x

# Copy the mtime
--mtime

# Use this proxy
--proxy 127.0.0.1:3128

# Save all videos under YouTube directory in your home directory
-o ~/YouTube/%(title)s.%(ext)s
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: Options in a configuration file are just the same options aka switches used in regular command line calls; thus there &lt;strong&gt;must be no whitespace&lt;/strong&gt; after &lt;code&gt;-&lt;/code&gt; or &lt;code&gt;--&lt;/code&gt;, e.g. &lt;code&gt;-o&lt;/code&gt; or &lt;code&gt;--proxy&lt;/code&gt; but not &lt;code&gt;- o&lt;/code&gt; or &lt;code&gt;-- proxy&lt;/code&gt;. They must also be quoted when necessary, as if it were a UNIX shell.&lt;/p&gt; 
&lt;p&gt;You can use &lt;code&gt;--ignore-config&lt;/code&gt; if you want to disable all configuration files for a particular yt-dlp run. If &lt;code&gt;--ignore-config&lt;/code&gt; is found inside any configuration file, no further configuration will be loaded. For example, having the option in the portable configuration file prevents loading of home, user, and system configurations. Additionally, (for backward compatibility) if &lt;code&gt;--ignore-config&lt;/code&gt; is found inside the system configuration file, the user configuration is not loaded.&lt;/p&gt; 
&lt;h3&gt;Configuration file encoding&lt;/h3&gt; 
&lt;p&gt;The configuration files are decoded according to the UTF BOM if present, and in the encoding from system locale otherwise.&lt;/p&gt; 
&lt;p&gt;If you want your file to be decoded differently, add &lt;code&gt;# coding: ENCODING&lt;/code&gt; to the beginning of the file (e.g. &lt;code&gt;# coding: shift-jis&lt;/code&gt;). There must be no characters before that, even spaces or BOM.&lt;/p&gt; 
&lt;h3&gt;Authentication with netrc&lt;/h3&gt; 
&lt;p&gt;You may also want to configure automatic credentials storage for extractors that support authentication (by providing login and password with &lt;code&gt;--username&lt;/code&gt; and &lt;code&gt;--password&lt;/code&gt;) in order not to pass credentials as command line arguments on every yt-dlp execution and prevent tracking plain text passwords in the shell command history. You can achieve this using a &lt;a href="https://stackoverflow.com/tags/.netrc/info"&gt;&lt;code&gt;.netrc&lt;/code&gt; file&lt;/a&gt; on a per-extractor basis. For that, you will need to create a &lt;code&gt;.netrc&lt;/code&gt; file in &lt;code&gt;--netrc-location&lt;/code&gt; and restrict permissions to read/write by only you:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;touch ${HOME}/.netrc
chmod a-rwx,u+rw ${HOME}/.netrc
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;After that, you can add credentials for an extractor in the following format, where &lt;em&gt;extractor&lt;/em&gt; is the name of the extractor in lowercase:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;machine &amp;lt;extractor&amp;gt; login &amp;lt;username&amp;gt; password &amp;lt;password&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;E.g.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;machine youtube login myaccount@gmail.com password my_youtube_password
machine twitch login my_twitch_account_name password my_twitch_password
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To activate authentication with the &lt;code&gt;.netrc&lt;/code&gt; file you should pass &lt;code&gt;--netrc&lt;/code&gt; to yt-dlp or place it in the &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#configuration"&gt;configuration file&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;The default location of the .netrc file is &lt;code&gt;~&lt;/code&gt; (see below).&lt;/p&gt; 
&lt;p&gt;As an alternative to using the &lt;code&gt;.netrc&lt;/code&gt; file, which has the disadvantage of keeping your passwords in a plain text file, you can configure a custom shell command to provide the credentials for an extractor. This is done by providing the &lt;code&gt;--netrc-cmd&lt;/code&gt; parameter, it shall output the credentials in the netrc format and return &lt;code&gt;0&lt;/code&gt; on success, other values will be treated as an error. &lt;code&gt;{}&lt;/code&gt; in the command will be replaced by the name of the extractor to make it possible to select the credentials for the right extractor.&lt;/p&gt; 
&lt;p&gt;E.g. To use an encrypted &lt;code&gt;.netrc&lt;/code&gt; file stored as &lt;code&gt;.authinfo.gpg&lt;/code&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;yt-dlp --netrc-cmd 'gpg --decrypt ~/.authinfo.gpg' 'https://www.youtube.com/watch?v=BaW_jenozKc'
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Notes about environment variables&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Environment variables are normally specified as &lt;code&gt;${VARIABLE}&lt;/code&gt;/&lt;code&gt;$VARIABLE&lt;/code&gt; on UNIX and &lt;code&gt;%VARIABLE%&lt;/code&gt; on Windows; but is always shown as &lt;code&gt;${VARIABLE}&lt;/code&gt; in this documentation&lt;/li&gt; 
 &lt;li&gt;yt-dlp also allows using UNIX-style variables on Windows for path-like options; e.g. &lt;code&gt;--output&lt;/code&gt;, &lt;code&gt;--config-location&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;If unset, &lt;code&gt;${XDG_CONFIG_HOME}&lt;/code&gt; defaults to &lt;code&gt;~/.config&lt;/code&gt; and &lt;code&gt;${XDG_CACHE_HOME}&lt;/code&gt; to &lt;code&gt;~/.cache&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;On Windows, &lt;code&gt;~&lt;/code&gt; points to &lt;code&gt;${HOME}&lt;/code&gt; if present; or, &lt;code&gt;${USERPROFILE}&lt;/code&gt; or &lt;code&gt;${HOMEDRIVE}${HOMEPATH}&lt;/code&gt; otherwise&lt;/li&gt; 
 &lt;li&gt;On Windows, &lt;code&gt;${USERPROFILE}&lt;/code&gt; generally points to &lt;code&gt;C:\Users\&amp;lt;user name&amp;gt;&lt;/code&gt; and &lt;code&gt;${APPDATA}&lt;/code&gt; to &lt;code&gt;${USERPROFILE}\AppData\Roaming&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;OUTPUT TEMPLATE&lt;/h1&gt; 
&lt;p&gt;The &lt;code&gt;-o&lt;/code&gt; option is used to indicate a template for the output file names while &lt;code&gt;-P&lt;/code&gt; option is used to specify the path each type of file should be saved to.&lt;/p&gt; 
&lt;!-- MANPAGE: BEGIN EXCLUDED SECTION --&gt; 
&lt;p&gt;&lt;strong&gt;tl;dr:&lt;/strong&gt; &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#output-template-examples"&gt;navigate me to examples&lt;/a&gt;.&lt;/p&gt; 
&lt;!-- MANPAGE: END EXCLUDED SECTION --&gt; 
&lt;p&gt;The simplest usage of &lt;code&gt;-o&lt;/code&gt; is not to set any template arguments when downloading a single file, like in &lt;code&gt;yt-dlp -o funny_video.flv "https://some/video"&lt;/code&gt; (hard-coding file extension like this is &lt;em&gt;not&lt;/em&gt; recommended and could break some post-processing).&lt;/p&gt; 
&lt;p&gt;It may however also contain special sequences that will be replaced when downloading each video. The special sequences may be formatted according to &lt;a href="https://docs.python.org/3/library/stdtypes.html#printf-style-string-formatting"&gt;Python string formatting operations&lt;/a&gt;, e.g. &lt;code&gt;%(NAME)s&lt;/code&gt; or &lt;code&gt;%(NAME)05d&lt;/code&gt;. To clarify, that is a percent symbol followed by a name in parentheses, followed by formatting operations.&lt;/p&gt; 
&lt;p&gt;The field names themselves (the part inside the parenthesis) can also have some special formatting:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Object traversal&lt;/strong&gt;: The dictionaries and lists available in metadata can be traversed by using a dot &lt;code&gt;.&lt;/code&gt; separator; e.g. &lt;code&gt;%(tags.0)s&lt;/code&gt;, &lt;code&gt;%(subtitles.en.-1.ext)s&lt;/code&gt;. You can do Python slicing with colon &lt;code&gt;:&lt;/code&gt;; E.g. &lt;code&gt;%(id.3:7)s&lt;/code&gt;, &lt;code&gt;%(id.6:2:-1)s&lt;/code&gt;, &lt;code&gt;%(formats.:.format_id)s&lt;/code&gt;. Curly braces &lt;code&gt;{}&lt;/code&gt; can be used to build dictionaries with only specific keys; e.g. &lt;code&gt;%(formats.:.{format_id,height})#j&lt;/code&gt;. An empty field name &lt;code&gt;%()s&lt;/code&gt; refers to the entire infodict; e.g. &lt;code&gt;%(.{id,title})s&lt;/code&gt;. Note that all the fields that become available using this method are not listed below. Use &lt;code&gt;-j&lt;/code&gt; to see such fields&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Arithmetic&lt;/strong&gt;: Simple arithmetic can be done on numeric fields using &lt;code&gt;+&lt;/code&gt;, &lt;code&gt;-&lt;/code&gt; and &lt;code&gt;*&lt;/code&gt;. E.g. &lt;code&gt;%(playlist_index+10)03d&lt;/code&gt;, &lt;code&gt;%(n_entries+1-playlist_index)d&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Date/time Formatting&lt;/strong&gt;: Date/time fields can be formatted according to &lt;a href="https://docs.python.org/3/library/datetime.html#strftime-and-strptime-format-codes"&gt;strftime formatting&lt;/a&gt; by specifying it separated from the field name using a &lt;code&gt;&amp;gt;&lt;/code&gt;. E.g. &lt;code&gt;%(duration&amp;gt;%H-%M-%S)s&lt;/code&gt;, &lt;code&gt;%(upload_date&amp;gt;%Y-%m-%d)s&lt;/code&gt;, &lt;code&gt;%(epoch-3600&amp;gt;%H-%M-%S)s&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Alternatives&lt;/strong&gt;: Alternate fields can be specified separated with a &lt;code&gt;,&lt;/code&gt;. E.g. &lt;code&gt;%(release_date&amp;gt;%Y,upload_date&amp;gt;%Y|Unknown)s&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Replacement&lt;/strong&gt;: A replacement value can be specified using a &lt;code&gt;&amp;amp;&lt;/code&gt; separator according to the &lt;a href="https://docs.python.org/3/library/string.html#format-specification-mini-language"&gt;&lt;code&gt;str.format&lt;/code&gt; mini-language&lt;/a&gt;. If the field is &lt;em&gt;not&lt;/em&gt; empty, this replacement value will be used instead of the actual field content. This is done after alternate fields are considered; thus the replacement is used if &lt;em&gt;any&lt;/em&gt; of the alternative fields is &lt;em&gt;not&lt;/em&gt; empty. E.g. &lt;code&gt;%(chapters&amp;amp;has chapters|no chapters)s&lt;/code&gt;, &lt;code&gt;%(title&amp;amp;TITLE={:&amp;gt;20}|NO TITLE)s&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Default&lt;/strong&gt;: A literal default value can be specified for when the field is empty using a &lt;code&gt;|&lt;/code&gt; separator. This overrides &lt;code&gt;--output-na-placeholder&lt;/code&gt;. E.g. &lt;code&gt;%(uploader|Unknown)s&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;More Conversions&lt;/strong&gt;: In addition to the normal format types &lt;code&gt;diouxXeEfFgGcrs&lt;/code&gt;, yt-dlp additionally supports converting to &lt;code&gt;B&lt;/code&gt; = &lt;strong&gt;B&lt;/strong&gt;ytes, &lt;code&gt;j&lt;/code&gt; = &lt;strong&gt;j&lt;/strong&gt;son (flag &lt;code&gt;#&lt;/code&gt; for pretty-printing, &lt;code&gt;+&lt;/code&gt; for Unicode), &lt;code&gt;h&lt;/code&gt; = HTML escaping, &lt;code&gt;l&lt;/code&gt; = a comma separated &lt;strong&gt;l&lt;/strong&gt;ist (flag &lt;code&gt;#&lt;/code&gt; for &lt;code&gt;\n&lt;/code&gt; newline-separated), &lt;code&gt;q&lt;/code&gt; = a string &lt;strong&gt;q&lt;/strong&gt;uoted for the terminal (flag &lt;code&gt;#&lt;/code&gt; to split a list into different arguments), &lt;code&gt;D&lt;/code&gt; = add &lt;strong&gt;D&lt;/strong&gt;ecimal suffixes (e.g. 10M) (flag &lt;code&gt;#&lt;/code&gt; to use 1024 as factor), and &lt;code&gt;S&lt;/code&gt; = &lt;strong&gt;S&lt;/strong&gt;anitize as filename (flag &lt;code&gt;#&lt;/code&gt; for restricted)&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Unicode normalization&lt;/strong&gt;: The format type &lt;code&gt;U&lt;/code&gt; can be used for NFC &lt;a href="https://docs.python.org/3/library/unicodedata.html#unicodedata.normalize"&gt;Unicode normalization&lt;/a&gt;. The alternate form flag (&lt;code&gt;#&lt;/code&gt;) changes the normalization to NFD and the conversion flag &lt;code&gt;+&lt;/code&gt; can be used for NFKC/NFKD compatibility equivalence normalization. E.g. &lt;code&gt;%(title)+.100U&lt;/code&gt; is NFKC&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;To summarize, the general syntax for a field is:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;%(name[.keys][addition][&amp;gt;strf][,alternate][&amp;amp;replacement][|default])[flags][width][.precision][length]type
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Additionally, you can set different output templates for the various metadata files separately from the general output template by specifying the type of file followed by the template separated by a colon &lt;code&gt;:&lt;/code&gt;. The different file types supported are &lt;code&gt;subtitle&lt;/code&gt;, &lt;code&gt;thumbnail&lt;/code&gt;, &lt;code&gt;description&lt;/code&gt;, &lt;code&gt;annotation&lt;/code&gt; (deprecated), &lt;code&gt;infojson&lt;/code&gt;, &lt;code&gt;link&lt;/code&gt;, &lt;code&gt;pl_thumbnail&lt;/code&gt;, &lt;code&gt;pl_description&lt;/code&gt;, &lt;code&gt;pl_infojson&lt;/code&gt;, &lt;code&gt;chapter&lt;/code&gt;, &lt;code&gt;pl_video&lt;/code&gt;. E.g. &lt;code&gt;-o "%(title)s.%(ext)s" -o "thumbnail:%(title)s\%(title)s.%(ext)s"&lt;/code&gt; will put the thumbnails in a folder with the same name as the video. If any of the templates is empty, that type of file will not be written. E.g. &lt;code&gt;--write-thumbnail -o "thumbnail:"&lt;/code&gt; will write thumbnails only for playlists and not for video.&lt;/p&gt; 
&lt;p&gt;&lt;a id="outtmpl-postprocess-note"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: Due to post-processing (i.e. merging etc.), the actual output filename might differ. Use &lt;code&gt;--print after_move:filepath&lt;/code&gt; to get the name after all post-processing is complete.&lt;/p&gt; 
&lt;p&gt;The available fields are:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;id&lt;/code&gt; (string): Video identifier&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;title&lt;/code&gt; (string): Video title&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;fulltitle&lt;/code&gt; (string): Video title ignoring live timestamp and generic title&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;ext&lt;/code&gt; (string): Video filename extension&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;alt_title&lt;/code&gt; (string): A secondary title of the video&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;description&lt;/code&gt; (string): The description of the video&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;display_id&lt;/code&gt; (string): An alternative identifier for the video&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;uploader&lt;/code&gt; (string): Full name of the video uploader&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;uploader_id&lt;/code&gt; (string): Nickname or id of the video uploader&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;uploader_url&lt;/code&gt; (string): URL to the video uploader's profile&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;license&lt;/code&gt; (string): License name the video is licensed under&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;creators&lt;/code&gt; (list): The creators of the video&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;creator&lt;/code&gt; (string): The creators of the video; comma-separated&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;timestamp&lt;/code&gt; (numeric): UNIX timestamp of the moment the video became available&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;upload_date&lt;/code&gt; (string): Video upload date in UTC (YYYYMMDD)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;release_timestamp&lt;/code&gt; (numeric): UNIX timestamp of the moment the video was released&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;release_date&lt;/code&gt; (string): The date (YYYYMMDD) when the video was released in UTC&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;release_year&lt;/code&gt; (numeric): Year (YYYY) when the video or album was released&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;modified_timestamp&lt;/code&gt; (numeric): UNIX timestamp of the moment the video was last modified&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;modified_date&lt;/code&gt; (string): The date (YYYYMMDD) when the video was last modified in UTC&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;channel&lt;/code&gt; (string): Full name of the channel the video is uploaded on&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;channel_id&lt;/code&gt; (string): Id of the channel&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;channel_url&lt;/code&gt; (string): URL of the channel&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;channel_follower_count&lt;/code&gt; (numeric): Number of followers of the channel&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;channel_is_verified&lt;/code&gt; (boolean): Whether the channel is verified on the platform&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;location&lt;/code&gt; (string): Physical location where the video was filmed&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;duration&lt;/code&gt; (numeric): Length of the video in seconds&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;duration_string&lt;/code&gt; (string): Length of the video (HH:mm:ss)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;view_count&lt;/code&gt; (numeric): How many users have watched the video on the platform&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;concurrent_view_count&lt;/code&gt; (numeric): How many users are currently watching the video on the platform.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;like_count&lt;/code&gt; (numeric): Number of positive ratings of the video&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;dislike_count&lt;/code&gt; (numeric): Number of negative ratings of the video&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;repost_count&lt;/code&gt; (numeric): Number of reposts of the video&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;average_rating&lt;/code&gt; (numeric): Average rating given by users, the scale used depends on the webpage&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;comment_count&lt;/code&gt; (numeric): Number of comments on the video (For some extractors, comments are only downloaded at the end, and so this field cannot be used)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;age_limit&lt;/code&gt; (numeric): Age restriction for the video (years)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;live_status&lt;/code&gt; (string): One of "not_live", "is_live", "is_upcoming", "was_live", "post_live" (was live, but VOD is not yet processed)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;is_live&lt;/code&gt; (boolean): Whether this video is a live stream or a fixed-length video&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;was_live&lt;/code&gt; (boolean): Whether this video was originally a live stream&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;playable_in_embed&lt;/code&gt; (string): Whether this video is allowed to play in embedded players on other sites&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;availability&lt;/code&gt; (string): Whether the video is "private", "premium_only", "subscriber_only", "needs_auth", "unlisted" or "public"&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;media_type&lt;/code&gt; (string): The type of media as classified by the site, e.g. "episode", "clip", "trailer"&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;start_time&lt;/code&gt; (numeric): Time in seconds where the reproduction should start, as specified in the URL&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;end_time&lt;/code&gt; (numeric): Time in seconds where the reproduction should end, as specified in the URL&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;extractor&lt;/code&gt; (string): Name of the extractor&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;extractor_key&lt;/code&gt; (string): Key name of the extractor&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;epoch&lt;/code&gt; (numeric): Unix epoch of when the information extraction was completed&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;autonumber&lt;/code&gt; (numeric): Number that will be increased with each download, starting at &lt;code&gt;--autonumber-start&lt;/code&gt;, padded with leading zeros to 5 digits&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;video_autonumber&lt;/code&gt; (numeric): Number that will be increased with each video&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;n_entries&lt;/code&gt; (numeric): Total number of extracted items in the playlist&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;playlist_id&lt;/code&gt; (string): Identifier of the playlist that contains the video&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;playlist_title&lt;/code&gt; (string): Name of the playlist that contains the video&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;playlist&lt;/code&gt; (string): &lt;code&gt;playlist_title&lt;/code&gt; if available or else &lt;code&gt;playlist_id&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;playlist_count&lt;/code&gt; (numeric): Total number of items in the playlist. May not be known if entire playlist is not extracted&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;playlist_index&lt;/code&gt; (numeric): Index of the video in the playlist padded with leading zeros according the final index&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;playlist_autonumber&lt;/code&gt; (numeric): Position of the video in the playlist download queue padded with leading zeros according to the total length of the playlist&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;playlist_uploader&lt;/code&gt; (string): Full name of the playlist uploader&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;playlist_uploader_id&lt;/code&gt; (string): Nickname or id of the playlist uploader&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;playlist_channel&lt;/code&gt; (string): Display name of the channel that uploaded the playlist&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;playlist_channel_id&lt;/code&gt; (string): Identifier of the channel that uploaded the playlist&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;playlist_webpage_url&lt;/code&gt; (string): URL of the playlist webpage&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;webpage_url&lt;/code&gt; (string): A URL to the video webpage which, if given to yt-dlp, should yield the same result again&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;webpage_url_basename&lt;/code&gt; (string): The basename of the webpage URL&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;webpage_url_domain&lt;/code&gt; (string): The domain of the webpage URL&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;original_url&lt;/code&gt; (string): The URL given by the user (or the same as &lt;code&gt;webpage_url&lt;/code&gt; for playlist entries)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;categories&lt;/code&gt; (list): List of categories the video belongs to&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;tags&lt;/code&gt; (list): List of tags assigned to the video&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;cast&lt;/code&gt; (list): List of cast members&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;All the fields in &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#filtering-formats"&gt;Filtering Formats&lt;/a&gt; can also be used&lt;/p&gt; 
&lt;p&gt;Available for the video that belongs to some logical chapter or section:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;chapter&lt;/code&gt; (string): Name or title of the chapter the video belongs to&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;chapter_number&lt;/code&gt; (numeric): Number of the chapter the video belongs to&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;chapter_id&lt;/code&gt; (string): Id of the chapter the video belongs to&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Available for the video that is an episode of some series or program:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;series&lt;/code&gt; (string): Title of the series or program the video episode belongs to&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;series_id&lt;/code&gt; (string): Id of the series or program the video episode belongs to&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;season&lt;/code&gt; (string): Title of the season the video episode belongs to&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;season_number&lt;/code&gt; (numeric): Number of the season the video episode belongs to&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;season_id&lt;/code&gt; (string): Id of the season the video episode belongs to&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;episode&lt;/code&gt; (string): Title of the video episode&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;episode_number&lt;/code&gt; (numeric): Number of the video episode within a season&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;episode_id&lt;/code&gt; (string): Id of the video episode&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Available for the media that is a track or a part of a music album:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;track&lt;/code&gt; (string): Title of the track&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;track_number&lt;/code&gt; (numeric): Number of the track within an album or a disc&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;track_id&lt;/code&gt; (string): Id of the track&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;artists&lt;/code&gt; (list): Artist(s) of the track&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;artist&lt;/code&gt; (string): Artist(s) of the track; comma-separated&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;genres&lt;/code&gt; (list): Genre(s) of the track&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;genre&lt;/code&gt; (string): Genre(s) of the track; comma-separated&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;composers&lt;/code&gt; (list): Composer(s) of the piece&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;composer&lt;/code&gt; (string): Composer(s) of the piece; comma-separated&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;album&lt;/code&gt; (string): Title of the album the track belongs to&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;album_type&lt;/code&gt; (string): Type of the album&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;album_artists&lt;/code&gt; (list): All artists appeared on the album&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;album_artist&lt;/code&gt; (string): All artists appeared on the album; comma-separated&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;disc_number&lt;/code&gt; (numeric): Number of the disc or other physical medium the track belongs to&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Available only when using &lt;code&gt;--download-sections&lt;/code&gt; and for &lt;code&gt;chapter:&lt;/code&gt; prefix when using &lt;code&gt;--split-chapters&lt;/code&gt; for videos with internal chapters:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;section_title&lt;/code&gt; (string): Title of the chapter&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;section_number&lt;/code&gt; (numeric): Number of the chapter within the file&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;section_start&lt;/code&gt; (numeric): Start time of the chapter in seconds&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;section_end&lt;/code&gt; (numeric): End time of the chapter in seconds&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Available only when used in &lt;code&gt;--print&lt;/code&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;urls&lt;/code&gt; (string): The URLs of all requested formats, one in each line&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;filename&lt;/code&gt; (string): Name of the video file. Note that the &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#outtmpl-postprocess-note"&gt;actual filename may differ&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;formats_table&lt;/code&gt; (table): The video format table as printed by &lt;code&gt;--list-formats&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;thumbnails_table&lt;/code&gt; (table): The thumbnail format table as printed by &lt;code&gt;--list-thumbnails&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;subtitles_table&lt;/code&gt; (table): The subtitle format table as printed by &lt;code&gt;--list-subs&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;automatic_captions_table&lt;/code&gt; (table): The automatic subtitle format table as printed by &lt;code&gt;--list-subs&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Available only after the video is downloaded (&lt;code&gt;post_process&lt;/code&gt;/&lt;code&gt;after_move&lt;/code&gt;):&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;filepath&lt;/code&gt;: Actual path of downloaded video file&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Available only in &lt;code&gt;--sponsorblock-chapter-title&lt;/code&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;start_time&lt;/code&gt; (numeric): Start time of the chapter in seconds&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;end_time&lt;/code&gt; (numeric): End time of the chapter in seconds&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;categories&lt;/code&gt; (list): The &lt;a href="https://wiki.sponsor.ajay.app/w/Types#Category"&gt;SponsorBlock categories&lt;/a&gt; the chapter belongs to&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;category&lt;/code&gt; (string): The smallest SponsorBlock category the chapter belongs to&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;category_names&lt;/code&gt; (list): Friendly names of the categories&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;name&lt;/code&gt; (string): Friendly name of the smallest category&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;type&lt;/code&gt; (string): The &lt;a href="https://wiki.sponsor.ajay.app/w/Types#Action_Type"&gt;SponsorBlock action type&lt;/a&gt; of the chapter&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Each aforementioned sequence when referenced in an output template will be replaced by the actual value corresponding to the sequence name. E.g. for &lt;code&gt;-o %(title)s-%(id)s.%(ext)s&lt;/code&gt; and an mp4 video with title &lt;code&gt;yt-dlp test video&lt;/code&gt; and id &lt;code&gt;BaW_jenozKc&lt;/code&gt;, this will result in a &lt;code&gt;yt-dlp test video-BaW_jenozKc.mp4&lt;/code&gt; file created in the current directory.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: Some of the sequences are not guaranteed to be present, since they depend on the metadata obtained by a particular extractor. Such sequences will be replaced with placeholder value provided with &lt;code&gt;--output-na-placeholder&lt;/code&gt; (&lt;code&gt;NA&lt;/code&gt; by default).&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Tip&lt;/strong&gt;: Look at the &lt;code&gt;-j&lt;/code&gt; output to identify which fields are available for the particular URL&lt;/p&gt; 
&lt;p&gt;For numeric sequences, you can use &lt;a href="https://docs.python.org/3/library/stdtypes.html#printf-style-string-formatting"&gt;numeric related formatting&lt;/a&gt;; e.g. &lt;code&gt;%(view_count)05d&lt;/code&gt; will result in a string with view count padded with zeros up to 5 characters, like in &lt;code&gt;00042&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Output templates can also contain arbitrary hierarchical path, e.g. &lt;code&gt;-o "%(playlist)s/%(playlist_index)s - %(title)s.%(ext)s"&lt;/code&gt; which will result in downloading each video in a directory corresponding to this path template. Any missing directory will be automatically created for you.&lt;/p&gt; 
&lt;p&gt;To use percent literals in an output template use &lt;code&gt;%%&lt;/code&gt;. To output to stdout use &lt;code&gt;-o -&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;The current default template is &lt;code&gt;%(title)s [%(id)s].%(ext)s&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;In some cases, you don't want special characters such as ä¸­, spaces, or &amp;amp;, such as when transferring the downloaded filename to a Windows system or the filename through an 8bit-unsafe channel. In these cases, add the &lt;code&gt;--restrict-filenames&lt;/code&gt; flag to get a shorter title.&lt;/p&gt; 
&lt;h4&gt;Output template examples&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;$ yt-dlp --print filename -o "test video.%(ext)s" BaW_jenozKc
test video.webm    # Literal name with correct extension

$ yt-dlp --print filename -o "%(title)s.%(ext)s" BaW_jenozKc
youtube-dl test video ''_Ã¤â†­ğ•.webm    # All kinds of weird characters

$ yt-dlp --print filename -o "%(title)s.%(ext)s" BaW_jenozKc --restrict-filenames
youtube-dl_test_video_.webm    # Restricted file name

# Download YouTube playlist videos in separate directory indexed by video order in a playlist
$ yt-dlp -o "%(playlist)s/%(playlist_index)s - %(title)s.%(ext)s" "https://www.youtube.com/playlist?list=PLwiyx1dc3P2JR9N8gQaQN_BCvlSlap7re"

# Download YouTube playlist videos in separate directories according to their uploaded year
$ yt-dlp -o "%(upload_date&amp;gt;%Y)s/%(title)s.%(ext)s" "https://www.youtube.com/playlist?list=PLwiyx1dc3P2JR9N8gQaQN_BCvlSlap7re"

# Prefix playlist index with " - " separator, but only if it is available
$ yt-dlp -o "%(playlist_index&amp;amp;{} - |)s%(title)s.%(ext)s" BaW_jenozKc "https://www.youtube.com/user/TheLinuxFoundation/playlists"

# Download all playlists of YouTube channel/user keeping each playlist in separate directory:
$ yt-dlp -o "%(uploader)s/%(playlist)s/%(playlist_index)s - %(title)s.%(ext)s" "https://www.youtube.com/user/TheLinuxFoundation/playlists"

# Download Udemy course keeping each chapter in separate directory under MyVideos directory in your home
$ yt-dlp -u user -p password -P "~/MyVideos" -o "%(playlist)s/%(chapter_number)s - %(chapter)s/%(title)s.%(ext)s" "https://www.udemy.com/java-tutorial"

# Download entire series season keeping each series and each season in separate directory under C:/MyVideos
$ yt-dlp -P "C:/MyVideos" -o "%(series)s/%(season_number)s - %(season)s/%(episode_number)s - %(episode)s.%(ext)s" "https://videomore.ru/kino_v_detalayah/5_sezon/367617"

# Download video as "C:\MyVideos\uploader\title.ext", subtitles as "C:\MyVideos\subs\uploader\title.ext"
# and put all temporary files in "C:\MyVideos\tmp"
$ yt-dlp -P "C:/MyVideos" -P "temp:tmp" -P "subtitle:subs" -o "%(uploader)s/%(title)s.%(ext)s" BaW_jenozKc --write-subs

# Download video as "C:\MyVideos\uploader\title.ext" and subtitles as "C:\MyVideos\uploader\subs\title.ext"
$ yt-dlp -P "C:/MyVideos" -o "%(uploader)s/%(title)s.%(ext)s" -o "subtitle:%(uploader)s/subs/%(title)s.%(ext)s" BaW_jenozKc --write-subs

# Stream the video being downloaded to stdout
$ yt-dlp -o - BaW_jenozKc
&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;FORMAT SELECTION&lt;/h1&gt; 
&lt;p&gt;By default, yt-dlp tries to download the best available quality if you &lt;strong&gt;don't&lt;/strong&gt; pass any options. This is generally equivalent to using &lt;code&gt;-f bestvideo*+bestaudio/best&lt;/code&gt;. However, if multiple audiostreams is enabled (&lt;code&gt;--audio-multistreams&lt;/code&gt;), the default format changes to &lt;code&gt;-f bestvideo+bestaudio/best&lt;/code&gt;. Similarly, if ffmpeg is unavailable, or if you use yt-dlp to stream to &lt;code&gt;stdout&lt;/code&gt; (&lt;code&gt;-o -&lt;/code&gt;), the default becomes &lt;code&gt;-f best/bestvideo+bestaudio&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Deprecation warning&lt;/strong&gt;: Latest versions of yt-dlp can stream multiple formats to the stdout simultaneously using ffmpeg. So, in future versions, the default for this will be set to &lt;code&gt;-f bv*+ba/b&lt;/code&gt; similar to normal downloads. If you want to preserve the &lt;code&gt;-f b/bv+ba&lt;/code&gt; setting, it is recommended to explicitly specify it in the configuration options.&lt;/p&gt; 
&lt;p&gt;The general syntax for format selection is &lt;code&gt;-f FORMAT&lt;/code&gt; (or &lt;code&gt;--format FORMAT&lt;/code&gt;) where &lt;code&gt;FORMAT&lt;/code&gt; is a &lt;em&gt;selector expression&lt;/em&gt;, i.e. an expression that describes format or formats you would like to download.&lt;/p&gt; 
&lt;!-- MANPAGE: BEGIN EXCLUDED SECTION --&gt; 
&lt;p&gt;&lt;strong&gt;tl;dr:&lt;/strong&gt; &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#format-selection-examples"&gt;navigate me to examples&lt;/a&gt;.&lt;/p&gt; 
&lt;!-- MANPAGE: END EXCLUDED SECTION --&gt; 
&lt;p&gt;The simplest case is requesting a specific format; e.g. with &lt;code&gt;-f 22&lt;/code&gt; you can download the format with format code equal to 22. You can get the list of available format codes for particular video using &lt;code&gt;--list-formats&lt;/code&gt; or &lt;code&gt;-F&lt;/code&gt;. Note that these format codes are extractor specific.&lt;/p&gt; 
&lt;p&gt;You can also use a file extension (currently &lt;code&gt;3gp&lt;/code&gt;, &lt;code&gt;aac&lt;/code&gt;, &lt;code&gt;flv&lt;/code&gt;, &lt;code&gt;m4a&lt;/code&gt;, &lt;code&gt;mp3&lt;/code&gt;, &lt;code&gt;mp4&lt;/code&gt;, &lt;code&gt;ogg&lt;/code&gt;, &lt;code&gt;wav&lt;/code&gt;, &lt;code&gt;webm&lt;/code&gt; are supported) to download the best quality format of a particular file extension served as a single file, e.g. &lt;code&gt;-f webm&lt;/code&gt; will download the best quality format with the &lt;code&gt;webm&lt;/code&gt; extension served as a single file.&lt;/p&gt; 
&lt;p&gt;You can use &lt;code&gt;-f -&lt;/code&gt; to interactively provide the format selector &lt;em&gt;for each video&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;You can also use special names to select particular edge case formats:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;all&lt;/code&gt;: Select &lt;strong&gt;all formats&lt;/strong&gt; separately&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;mergeall&lt;/code&gt;: Select and &lt;strong&gt;merge all formats&lt;/strong&gt; (Must be used with &lt;code&gt;--audio-multistreams&lt;/code&gt;, &lt;code&gt;--video-multistreams&lt;/code&gt; or both)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;b*&lt;/code&gt;, &lt;code&gt;best*&lt;/code&gt;: Select the best quality format that &lt;strong&gt;contains either&lt;/strong&gt; a video or an audio or both (i.e.; &lt;code&gt;vcodec!=none or acodec!=none&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;b&lt;/code&gt;, &lt;code&gt;best&lt;/code&gt;: Select the best quality format that &lt;strong&gt;contains both&lt;/strong&gt; video and audio. Equivalent to &lt;code&gt;best*[vcodec!=none][acodec!=none]&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;bv&lt;/code&gt;, &lt;code&gt;bestvideo&lt;/code&gt;: Select the best quality &lt;strong&gt;video-only&lt;/strong&gt; format. Equivalent to &lt;code&gt;best*[acodec=none]&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;bv*&lt;/code&gt;, &lt;code&gt;bestvideo*&lt;/code&gt;: Select the best quality format that &lt;strong&gt;contains video&lt;/strong&gt;. It may also contain audio. Equivalent to &lt;code&gt;best*[vcodec!=none]&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;ba&lt;/code&gt;, &lt;code&gt;bestaudio&lt;/code&gt;: Select the best quality &lt;strong&gt;audio-only&lt;/strong&gt; format. Equivalent to &lt;code&gt;best*[vcodec=none]&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;ba*&lt;/code&gt;, &lt;code&gt;bestaudio*&lt;/code&gt;: Select the best quality format that &lt;strong&gt;contains audio&lt;/strong&gt;. It may also contain video. Equivalent to &lt;code&gt;best*[acodec!=none]&lt;/code&gt; (&lt;a href="https://github.com/yt-dlp/yt-dlp/issues/979#issuecomment-919629354"&gt;Do not use!&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;w*&lt;/code&gt;, &lt;code&gt;worst*&lt;/code&gt;: Select the worst quality format that contains either a video or an audio&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;w&lt;/code&gt;, &lt;code&gt;worst&lt;/code&gt;: Select the worst quality format that contains both video and audio. Equivalent to &lt;code&gt;worst*[vcodec!=none][acodec!=none]&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;wv&lt;/code&gt;, &lt;code&gt;worstvideo&lt;/code&gt;: Select the worst quality video-only format. Equivalent to &lt;code&gt;worst*[acodec=none]&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;wv*&lt;/code&gt;, &lt;code&gt;worstvideo*&lt;/code&gt;: Select the worst quality format that contains video. It may also contain audio. Equivalent to &lt;code&gt;worst*[vcodec!=none]&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;wa&lt;/code&gt;, &lt;code&gt;worstaudio&lt;/code&gt;: Select the worst quality audio-only format. Equivalent to &lt;code&gt;worst*[vcodec=none]&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;wa*&lt;/code&gt;, &lt;code&gt;worstaudio*&lt;/code&gt;: Select the worst quality format that contains audio. It may also contain video. Equivalent to &lt;code&gt;worst*[acodec!=none]&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For example, to download the worst quality video-only format you can use &lt;code&gt;-f worstvideo&lt;/code&gt;. It is, however, recommended not to use &lt;code&gt;worst&lt;/code&gt; and related options. When your format selector is &lt;code&gt;worst&lt;/code&gt;, the format which is worst in all respects is selected. Most of the time, what you actually want is the video with the smallest filesize instead. So it is generally better to use &lt;code&gt;-S +size&lt;/code&gt; or more rigorously, &lt;code&gt;-S +size,+br,+res,+fps&lt;/code&gt; instead of &lt;code&gt;-f worst&lt;/code&gt;. See &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#sorting-formats"&gt;Sorting Formats&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;p&gt;You can select the n'th best format of a type by using &lt;code&gt;best&amp;lt;type&amp;gt;.&amp;lt;n&amp;gt;&lt;/code&gt;. For example, &lt;code&gt;best.2&lt;/code&gt; will select the 2nd best combined format. Similarly, &lt;code&gt;bv*.3&lt;/code&gt; will select the 3rd best format that contains a video stream.&lt;/p&gt; 
&lt;p&gt;If you want to download multiple videos, and they don't have the same formats available, you can specify the order of preference using slashes. Note that formats on the left hand side are preferred; e.g. &lt;code&gt;-f 22/17/18&lt;/code&gt; will download format 22 if it's available, otherwise it will download format 17 if it's available, otherwise it will download format 18 if it's available, otherwise it will complain that no suitable formats are available for download.&lt;/p&gt; 
&lt;p&gt;If you want to download several formats of the same video use a comma as a separator, e.g. &lt;code&gt;-f 22,17,18&lt;/code&gt; will download all these three formats, of course if they are available. Or a more sophisticated example combined with the precedence feature: &lt;code&gt;-f 136/137/mp4/bestvideo,140/m4a/bestaudio&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;You can merge the video and audio of multiple formats into a single file using &lt;code&gt;-f &amp;lt;format1&amp;gt;+&amp;lt;format2&amp;gt;+...&lt;/code&gt; (requires ffmpeg installed); e.g. &lt;code&gt;-f bestvideo+bestaudio&lt;/code&gt; will download the best video-only format, the best audio-only format and mux them together with ffmpeg.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Deprecation warning&lt;/strong&gt;: Since the &lt;em&gt;below&lt;/em&gt; described behavior is complex and counter-intuitive, this will be removed and multistreams will be enabled by default in the future. A new operator will be instead added to limit formats to single audio/video&lt;/p&gt; 
&lt;p&gt;Unless &lt;code&gt;--video-multistreams&lt;/code&gt; is used, all formats with a video stream except the first one are ignored. Similarly, unless &lt;code&gt;--audio-multistreams&lt;/code&gt; is used, all formats with an audio stream except the first one are ignored. E.g. &lt;code&gt;-f bestvideo+best+bestaudio --video-multistreams --audio-multistreams&lt;/code&gt; will download and merge all 3 given formats. The resulting file will have 2 video streams and 2 audio streams. But &lt;code&gt;-f bestvideo+best+bestaudio --no-video-multistreams&lt;/code&gt; will download and merge only &lt;code&gt;bestvideo&lt;/code&gt; and &lt;code&gt;bestaudio&lt;/code&gt;. &lt;code&gt;best&lt;/code&gt; is ignored since another format containing a video stream (&lt;code&gt;bestvideo&lt;/code&gt;) has already been selected. The order of the formats is therefore important. &lt;code&gt;-f best+bestaudio --no-audio-multistreams&lt;/code&gt; will download only &lt;code&gt;best&lt;/code&gt; while &lt;code&gt;-f bestaudio+best --no-audio-multistreams&lt;/code&gt; will ignore &lt;code&gt;best&lt;/code&gt; and download only &lt;code&gt;bestaudio&lt;/code&gt;.&lt;/p&gt; 
&lt;h2&gt;Filtering Formats&lt;/h2&gt; 
&lt;p&gt;You can also filter the video formats by putting a condition in brackets, as in &lt;code&gt;-f "best[height=720]"&lt;/code&gt; (or &lt;code&gt;-f "[filesize&amp;gt;10M]"&lt;/code&gt; since filters without a selector are interpreted as &lt;code&gt;best&lt;/code&gt;).&lt;/p&gt; 
&lt;p&gt;The following numeric meta fields can be used with comparisons &lt;code&gt;&amp;lt;&lt;/code&gt;, &lt;code&gt;&amp;lt;=&lt;/code&gt;, &lt;code&gt;&amp;gt;&lt;/code&gt;, &lt;code&gt;&amp;gt;=&lt;/code&gt;, &lt;code&gt;=&lt;/code&gt; (equals), &lt;code&gt;!=&lt;/code&gt; (not equals):&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;filesize&lt;/code&gt;: The number of bytes, if known in advance&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;filesize_approx&lt;/code&gt;: An estimate for the number of bytes&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;width&lt;/code&gt;: Width of the video, if known&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;height&lt;/code&gt;: Height of the video, if known&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;aspect_ratio&lt;/code&gt;: Aspect ratio of the video, if known&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;tbr&lt;/code&gt;: Average bitrate of audio and video in &lt;a href="##" title="1000 bits/sec"&gt;kbps&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;abr&lt;/code&gt;: Average audio bitrate in &lt;a href="##" title="1000 bits/sec"&gt;kbps&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;vbr&lt;/code&gt;: Average video bitrate in &lt;a href="##" title="1000 bits/sec"&gt;kbps&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;asr&lt;/code&gt;: Audio sampling rate in Hertz&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;fps&lt;/code&gt;: Frame rate&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;audio_channels&lt;/code&gt;: The number of audio channels&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;stretched_ratio&lt;/code&gt;: &lt;code&gt;width:height&lt;/code&gt; of the video's pixels, if not square&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Also filtering work for comparisons &lt;code&gt;=&lt;/code&gt; (equals), &lt;code&gt;^=&lt;/code&gt; (starts with), &lt;code&gt;$=&lt;/code&gt; (ends with), &lt;code&gt;*=&lt;/code&gt; (contains), &lt;code&gt;~=&lt;/code&gt; (matches regex) and following string meta fields:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;url&lt;/code&gt;: Video URL&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;ext&lt;/code&gt;: File extension&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;acodec&lt;/code&gt;: Name of the audio codec in use&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;vcodec&lt;/code&gt;: Name of the video codec in use&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;container&lt;/code&gt;: Name of the container format&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;protocol&lt;/code&gt;: The protocol that will be used for the actual download, lower-case (&lt;code&gt;http&lt;/code&gt;, &lt;code&gt;https&lt;/code&gt;, &lt;code&gt;rtsp&lt;/code&gt;, &lt;code&gt;rtmp&lt;/code&gt;, &lt;code&gt;rtmpe&lt;/code&gt;, &lt;code&gt;mms&lt;/code&gt;, &lt;code&gt;f4m&lt;/code&gt;, &lt;code&gt;ism&lt;/code&gt;, &lt;code&gt;http_dash_segments&lt;/code&gt;, &lt;code&gt;m3u8&lt;/code&gt;, or &lt;code&gt;m3u8_native&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;language&lt;/code&gt;: Language code&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;dynamic_range&lt;/code&gt;: The dynamic range of the video&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;format_id&lt;/code&gt;: A short description of the format&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;format&lt;/code&gt;: A human-readable description of the format&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;format_note&lt;/code&gt;: Additional info about the format&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;resolution&lt;/code&gt;: Textual description of width and height&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Any string comparison may be prefixed with negation &lt;code&gt;!&lt;/code&gt; in order to produce an opposite comparison, e.g. &lt;code&gt;!*=&lt;/code&gt; (does not contain). The comparand of a string comparison needs to be quoted with either double or single quotes if it contains spaces or special characters other than &lt;code&gt;._-&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: None of the aforementioned meta fields are guaranteed to be present since this solely depends on the metadata obtained by the particular extractor, i.e. the metadata offered by the website. Any other field made available by the extractor can also be used for filtering.&lt;/p&gt; 
&lt;p&gt;Formats for which the value is not known are excluded unless you put a question mark (&lt;code&gt;?&lt;/code&gt;) after the operator. You can combine format filters, so &lt;code&gt;-f "bv[height&amp;lt;=?720][tbr&amp;gt;500]"&lt;/code&gt; selects up to 720p videos (or videos where the height is not known) with a bitrate of at least 500 kbps. You can also use the filters with &lt;code&gt;all&lt;/code&gt; to download all formats that satisfy the filter, e.g. &lt;code&gt;-f "all[vcodec=none]"&lt;/code&gt; selects all audio-only formats.&lt;/p&gt; 
&lt;p&gt;Format selectors can also be grouped using parentheses; e.g. &lt;code&gt;-f "(mp4,webm)[height&amp;lt;480]"&lt;/code&gt; will download the best pre-merged mp4 and webm formats with a height lower than 480.&lt;/p&gt; 
&lt;h2&gt;Sorting Formats&lt;/h2&gt; 
&lt;p&gt;You can change the criteria for being considered the &lt;code&gt;best&lt;/code&gt; by using &lt;code&gt;-S&lt;/code&gt; (&lt;code&gt;--format-sort&lt;/code&gt;). The general format for this is &lt;code&gt;--format-sort field1,field2...&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;The available fields are:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;hasvid&lt;/code&gt;: Gives priority to formats that have a video stream&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;hasaud&lt;/code&gt;: Gives priority to formats that have an audio stream&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;ie_pref&lt;/code&gt;: The format preference&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;lang&lt;/code&gt;: The language preference as determined by the extractor (e.g. original language preferred over audio description)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;quality&lt;/code&gt;: The quality of the format&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;source&lt;/code&gt;: The preference of the source&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;proto&lt;/code&gt;: Protocol used for download (&lt;code&gt;https&lt;/code&gt;/&lt;code&gt;ftps&lt;/code&gt; &amp;gt; &lt;code&gt;http&lt;/code&gt;/&lt;code&gt;ftp&lt;/code&gt; &amp;gt; &lt;code&gt;m3u8_native&lt;/code&gt;/&lt;code&gt;m3u8&lt;/code&gt; &amp;gt; &lt;code&gt;http_dash_segments&lt;/code&gt;&amp;gt; &lt;code&gt;websocket_frag&lt;/code&gt; &amp;gt; &lt;code&gt;mms&lt;/code&gt;/&lt;code&gt;rtsp&lt;/code&gt; &amp;gt; &lt;code&gt;f4f&lt;/code&gt;/&lt;code&gt;f4m&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;vcodec&lt;/code&gt;: Video Codec (&lt;code&gt;av01&lt;/code&gt; &amp;gt; &lt;code&gt;vp9.2&lt;/code&gt; &amp;gt; &lt;code&gt;vp9&lt;/code&gt; &amp;gt; &lt;code&gt;h265&lt;/code&gt; &amp;gt; &lt;code&gt;h264&lt;/code&gt; &amp;gt; &lt;code&gt;vp8&lt;/code&gt; &amp;gt; &lt;code&gt;h263&lt;/code&gt; &amp;gt; &lt;code&gt;theora&lt;/code&gt; &amp;gt; other)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;acodec&lt;/code&gt;: Audio Codec (&lt;code&gt;flac&lt;/code&gt;/&lt;code&gt;alac&lt;/code&gt; &amp;gt; &lt;code&gt;wav&lt;/code&gt;/&lt;code&gt;aiff&lt;/code&gt; &amp;gt; &lt;code&gt;opus&lt;/code&gt; &amp;gt; &lt;code&gt;vorbis&lt;/code&gt; &amp;gt; &lt;code&gt;aac&lt;/code&gt; &amp;gt; &lt;code&gt;mp4a&lt;/code&gt; &amp;gt; &lt;code&gt;mp3&lt;/code&gt; &amp;gt; &lt;code&gt;ac4&lt;/code&gt; &amp;gt; &lt;code&gt;eac3&lt;/code&gt; &amp;gt; &lt;code&gt;ac3&lt;/code&gt; &amp;gt; &lt;code&gt;dts&lt;/code&gt; &amp;gt; other)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;codec&lt;/code&gt;: Equivalent to &lt;code&gt;vcodec,acodec&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;vext&lt;/code&gt;: Video Extension (&lt;code&gt;mp4&lt;/code&gt; &amp;gt; &lt;code&gt;mov&lt;/code&gt; &amp;gt; &lt;code&gt;webm&lt;/code&gt; &amp;gt; &lt;code&gt;flv&lt;/code&gt; &amp;gt; other). If &lt;code&gt;--prefer-free-formats&lt;/code&gt; is used, &lt;code&gt;webm&lt;/code&gt; is preferred.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;aext&lt;/code&gt;: Audio Extension (&lt;code&gt;m4a&lt;/code&gt; &amp;gt; &lt;code&gt;aac&lt;/code&gt; &amp;gt; &lt;code&gt;mp3&lt;/code&gt; &amp;gt; &lt;code&gt;ogg&lt;/code&gt; &amp;gt; &lt;code&gt;opus&lt;/code&gt; &amp;gt; &lt;code&gt;webm&lt;/code&gt; &amp;gt; other). If &lt;code&gt;--prefer-free-formats&lt;/code&gt; is used, the order changes to &lt;code&gt;ogg&lt;/code&gt; &amp;gt; &lt;code&gt;opus&lt;/code&gt; &amp;gt; &lt;code&gt;webm&lt;/code&gt; &amp;gt; &lt;code&gt;mp3&lt;/code&gt; &amp;gt; &lt;code&gt;m4a&lt;/code&gt; &amp;gt; &lt;code&gt;aac&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;ext&lt;/code&gt;: Equivalent to &lt;code&gt;vext,aext&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;filesize&lt;/code&gt;: Exact filesize, if known in advance&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;fs_approx&lt;/code&gt;: Approximate filesize&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;size&lt;/code&gt;: Exact filesize if available, otherwise approximate filesize&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;height&lt;/code&gt;: Height of video&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;width&lt;/code&gt;: Width of video&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;res&lt;/code&gt;: Video resolution, calculated as the smallest dimension.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;fps&lt;/code&gt;: Framerate of video&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;hdr&lt;/code&gt;: The dynamic range of the video (&lt;code&gt;DV&lt;/code&gt; &amp;gt; &lt;code&gt;HDR12&lt;/code&gt; &amp;gt; &lt;code&gt;HDR10+&lt;/code&gt; &amp;gt; &lt;code&gt;HDR10&lt;/code&gt; &amp;gt; &lt;code&gt;HLG&lt;/code&gt; &amp;gt; &lt;code&gt;SDR&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;channels&lt;/code&gt;: The number of audio channels&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;tbr&lt;/code&gt;: Total average bitrate in &lt;a href="##" title="1000 bits/sec"&gt;kbps&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;vbr&lt;/code&gt;: Average video bitrate in &lt;a href="##" title="1000 bits/sec"&gt;kbps&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;abr&lt;/code&gt;: Average audio bitrate in &lt;a href="##" title="1000 bits/sec"&gt;kbps&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;br&lt;/code&gt;: Average bitrate in &lt;a href="##" title="1000 bits/sec"&gt;kbps&lt;/a&gt;, &lt;code&gt;tbr&lt;/code&gt;/&lt;code&gt;vbr&lt;/code&gt;/&lt;code&gt;abr&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;asr&lt;/code&gt;: Audio sample rate in Hz&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Deprecation warning&lt;/strong&gt;: Many of these fields have (currently undocumented) aliases, that may be removed in a future version. It is recommended to use only the documented field names.&lt;/p&gt; 
&lt;p&gt;All fields, unless specified otherwise, are sorted in descending order. To reverse this, prefix the field with a &lt;code&gt;+&lt;/code&gt;. E.g. &lt;code&gt;+res&lt;/code&gt; prefers format with the smallest resolution. Additionally, you can suffix a preferred value for the fields, separated by a &lt;code&gt;:&lt;/code&gt;. E.g. &lt;code&gt;res:720&lt;/code&gt; prefers larger videos, but no larger than 720p and the smallest video if there are no videos less than 720p. For &lt;code&gt;codec&lt;/code&gt; and &lt;code&gt;ext&lt;/code&gt;, you can provide two preferred values, the first for video and the second for audio. E.g. &lt;code&gt;+codec:avc:m4a&lt;/code&gt; (equivalent to &lt;code&gt;+vcodec:avc,+acodec:m4a&lt;/code&gt;) sets the video codec preference to &lt;code&gt;h264&lt;/code&gt; &amp;gt; &lt;code&gt;h265&lt;/code&gt; &amp;gt; &lt;code&gt;vp9&lt;/code&gt; &amp;gt; &lt;code&gt;vp9.2&lt;/code&gt; &amp;gt; &lt;code&gt;av01&lt;/code&gt; &amp;gt; &lt;code&gt;vp8&lt;/code&gt; &amp;gt; &lt;code&gt;h263&lt;/code&gt; &amp;gt; &lt;code&gt;theora&lt;/code&gt; and audio codec preference to &lt;code&gt;mp4a&lt;/code&gt; &amp;gt; &lt;code&gt;aac&lt;/code&gt; &amp;gt; &lt;code&gt;vorbis&lt;/code&gt; &amp;gt; &lt;code&gt;opus&lt;/code&gt; &amp;gt; &lt;code&gt;mp3&lt;/code&gt; &amp;gt; &lt;code&gt;ac3&lt;/code&gt; &amp;gt; &lt;code&gt;dts&lt;/code&gt;. You can also make the sorting prefer the nearest values to the provided by using &lt;code&gt;~&lt;/code&gt; as the delimiter. E.g. &lt;code&gt;filesize~1G&lt;/code&gt; prefers the format with filesize closest to 1 GiB.&lt;/p&gt; 
&lt;p&gt;The fields &lt;code&gt;hasvid&lt;/code&gt; and &lt;code&gt;ie_pref&lt;/code&gt; are always given highest priority in sorting, irrespective of the user-defined order. This behavior can be changed by using &lt;code&gt;--format-sort-force&lt;/code&gt;. Apart from these, the default order used is: &lt;code&gt;lang,quality,res,fps,hdr:12,vcodec,channels,acodec,size,br,asr,proto,ext,hasaud,source,id&lt;/code&gt;. The extractors may override this default order, but they cannot override the user-provided order.&lt;/p&gt; 
&lt;p&gt;Note that the default for hdr is &lt;code&gt;hdr:12&lt;/code&gt;; i.e. Dolby Vision is not preferred. This choice was made since DV formats are not yet fully compatible with most devices. This may be changed in the future.&lt;/p&gt; 
&lt;p&gt;If your format selector is &lt;code&gt;worst&lt;/code&gt;, the last item is selected after sorting. This means it will select the format that is worst in all respects. Most of the time, what you actually want is the video with the smallest filesize instead. So it is generally better to use &lt;code&gt;-f best -S +size,+br,+res,+fps&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Tip&lt;/strong&gt;: You can use the &lt;code&gt;-v -F&lt;/code&gt; to see how the formats have been sorted (worst to best).&lt;/p&gt; 
&lt;h2&gt;Format Selection examples&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Download and merge the best video-only format and the best audio-only format,
# or download the best combined format if video-only format is not available
$ yt-dlp -f "bv+ba/b"

# Download best format that contains video,
# and if it doesn't already have an audio stream, merge it with best audio-only format
$ yt-dlp -f "bv*+ba/b"

# Same as above
$ yt-dlp

# Download the best video-only format and the best audio-only format without merging them
# For this case, an output template should be used since
# by default, bestvideo and bestaudio will have the same file name.
$ yt-dlp -f "bv,ba" -o "%(title)s.f%(format_id)s.%(ext)s"

# Download and merge the best format that has a video stream,
# and all audio-only formats into one file
$ yt-dlp -f "bv*+mergeall[vcodec=none]" --audio-multistreams

# Download and merge the best format that has a video stream,
# and the best 2 audio-only formats into one file
$ yt-dlp -f "bv*+ba+ba.2" --audio-multistreams


# The following examples show the old method (without -S) of format selection
# and how to use -S to achieve a similar but (generally) better result

# Download the worst video available (old method)
$ yt-dlp -f "wv*+wa/w"

# Download the best video available but with the smallest resolution
$ yt-dlp -S "+res"

# Download the smallest video available
$ yt-dlp -S "+size,+br"



# Download the best mp4 video available, or the best video if no mp4 available
$ yt-dlp -f "bv*[ext=mp4]+ba[ext=m4a]/b[ext=mp4] / bv*+ba/b"

# Download the best video with the best extension
# (For video, mp4 &amp;gt; mov &amp;gt; webm &amp;gt; flv. For audio, m4a &amp;gt; aac &amp;gt; mp3 ...)
$ yt-dlp -S "ext"



# Download the best video available but no better than 480p,
# or the worst video if there is no video under 480p
$ yt-dlp -f "bv*[height&amp;lt;=480]+ba/b[height&amp;lt;=480] / wv*+ba/w"

# Download the best video available with the largest height but no better than 480p,
# or the best video with the smallest resolution if there is no video under 480p
$ yt-dlp -S "height:480"

# Download the best video available with the largest resolution but no better than 480p,
# or the best video with the smallest resolution if there is no video under 480p
# Resolution is determined by using the smallest dimension.
# So this works correctly for vertical videos as well
$ yt-dlp -S "res:480"



# Download the best video (that also has audio) but no bigger than 50 MB,
# or the worst video (that also has audio) if there is no video under 50 MB
$ yt-dlp -f "b[filesize&amp;lt;50M] / w"

# Download the largest video (that also has audio) but no bigger than 50 MB,
# or the smallest video (that also has audio) if there is no video under 50 MB
$ yt-dlp -f "b" -S "filesize:50M"

# Download the best video (that also has audio) that is closest in size to 50 MB
$ yt-dlp -f "b" -S "filesize~50M"



# Download best video available via direct link over HTTP/HTTPS protocol,
# or the best video available via any protocol if there is no such video
$ yt-dlp -f "(bv*+ba/b)[protocol^=http][protocol!*=dash] / (bv*+ba/b)"

# Download best video available via the best protocol
# (https/ftps &amp;gt; http/ftp &amp;gt; m3u8_native &amp;gt; m3u8 &amp;gt; http_dash_segments ...)
$ yt-dlp -S "proto"



# Download the best video with either h264 or h265 codec,
# or the best video if there is no such video
$ yt-dlp -f "(bv*[vcodec~='^((he|a)vc|h26[45])']+ba) / (bv*+ba/b)"

# Download the best video with best codec no better than h264,
# or the best video with worst codec if there is no such video
$ yt-dlp -S "codec:h264"

# Download the best video with worst codec no worse than h264,
# or the best video with best codec if there is no such video
$ yt-dlp -S "+codec:h264"



# More complex examples

# Download the best video no better than 720p preferring framerate greater than 30,
# or the worst video (still preferring framerate greater than 30) if there is no such video
$ yt-dlp -f "((bv*[fps&amp;gt;30]/bv*)[height&amp;lt;=720]/(wv*[fps&amp;gt;30]/wv*)) + ba / (b[fps&amp;gt;30]/b)[height&amp;lt;=720]/(w[fps&amp;gt;30]/w)"

# Download the video with the largest resolution no better than 720p,
# or the video with the smallest resolution available if there is no such video,
# preferring larger framerate for formats with the same resolution
$ yt-dlp -S "res:720,fps"



# Download the video with smallest resolution no worse than 480p,
# or the video with the largest resolution available if there is no such video,
# preferring better codec and then larger total bitrate for the same resolution
$ yt-dlp -S "+res:480,codec,br"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;MODIFYING METADATA&lt;/h1&gt; 
&lt;p&gt;The metadata obtained by the extractors can be modified by using &lt;code&gt;--parse-metadata&lt;/code&gt; and &lt;code&gt;--replace-in-metadata&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;--replace-in-metadata FIELDS REGEX REPLACE&lt;/code&gt; is used to replace text in any metadata field using &lt;a href="https://docs.python.org/3/library/re.html#regular-expression-syntax"&gt;Python regular expression&lt;/a&gt;. &lt;a href="https://docs.python.org/3/library/re.html?highlight=backreferences#re.sub"&gt;Backreferences&lt;/a&gt; can be used in the replace string for advanced use.&lt;/p&gt; 
&lt;p&gt;The general syntax of &lt;code&gt;--parse-metadata FROM:TO&lt;/code&gt; is to give the name of a field or an &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#output-template"&gt;output template&lt;/a&gt; to extract data from, and the format to interpret it as, separated by a colon &lt;code&gt;:&lt;/code&gt;. Either a &lt;a href="https://docs.python.org/3/library/re.html#regular-expression-syntax"&gt;Python regular expression&lt;/a&gt; with named capture groups, a single field name, or a similar syntax to the &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#output-template"&gt;output template&lt;/a&gt; (only &lt;code&gt;%(field)s&lt;/code&gt; formatting is supported) can be used for &lt;code&gt;TO&lt;/code&gt;. The option can be used multiple times to parse and modify various fields.&lt;/p&gt; 
&lt;p&gt;Note that these options preserve their relative order, allowing replacements to be made in parsed fields and vice versa. Also, any field thus created can be used in the &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#output-template"&gt;output template&lt;/a&gt; and will also affect the media file's metadata added when using &lt;code&gt;--embed-metadata&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;This option also has a few special uses:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;You can download an additional URL based on the metadata of the currently downloaded video. To do this, set the field &lt;code&gt;additional_urls&lt;/code&gt; to the URL that you want to download. E.g. &lt;code&gt;--parse-metadata "description:(?P&amp;lt;additional_urls&amp;gt;https?://www\.vimeo\.com/\d+)"&lt;/code&gt; will download the first vimeo video found in the description&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;You can use this to change the metadata that is embedded in the media file. To do this, set the value of the corresponding field with a &lt;code&gt;meta_&lt;/code&gt; prefix. For example, any value you set to &lt;code&gt;meta_description&lt;/code&gt; field will be added to the &lt;code&gt;description&lt;/code&gt; field in the file - you can use this to set a different "description" and "synopsis". To modify the metadata of individual streams, use the &lt;code&gt;meta&amp;lt;n&amp;gt;_&lt;/code&gt; prefix (e.g. &lt;code&gt;meta1_language&lt;/code&gt;). Any value set to the &lt;code&gt;meta_&lt;/code&gt; field will overwrite all default values.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: Metadata modification happens before format selection, post-extraction and other post-processing operations. Some fields may be added or changed during these steps, overriding your changes.&lt;/p&gt; 
&lt;p&gt;For reference, these are the fields yt-dlp adds by default to the file metadata:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Metadata fields&lt;/th&gt; 
   &lt;th align="left"&gt;From&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;title&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;track&lt;/code&gt; or &lt;code&gt;title&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;date&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;upload_date&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;description&lt;/code&gt;, &lt;code&gt;synopsis&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;description&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;purl&lt;/code&gt;, &lt;code&gt;comment&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;webpage_url&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;track&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;track_number&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;artist&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;artist&lt;/code&gt;, &lt;code&gt;artists&lt;/code&gt;, &lt;code&gt;creator&lt;/code&gt;, &lt;code&gt;creators&lt;/code&gt;, &lt;code&gt;uploader&lt;/code&gt; or &lt;code&gt;uploader_id&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;composer&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;composer&lt;/code&gt; or &lt;code&gt;composers&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;genre&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;genre&lt;/code&gt; or &lt;code&gt;genres&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;album&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;album&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;album_artist&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;album_artist&lt;/code&gt; or &lt;code&gt;album_artists&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;disc&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;disc_number&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;show&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;series&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;season_number&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;season_number&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;episode_id&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;episode&lt;/code&gt; or &lt;code&gt;episode_id&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;episode_sort&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;episode_number&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;language&lt;/code&gt; of each stream&lt;/td&gt; 
   &lt;td align="left"&gt;the format's &lt;code&gt;language&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: The file format may not support some of these fields&lt;/p&gt; 
&lt;h2&gt;Modifying metadata examples&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Interpret the title as "Artist - Title"
$ yt-dlp --parse-metadata "title:%(artist)s - %(title)s"

# Regex example
$ yt-dlp --parse-metadata "description:Artist - (?P&amp;lt;artist&amp;gt;.+)"

# Set title as "Series name S01E05"
$ yt-dlp --parse-metadata "%(series)s S%(season_number)02dE%(episode_number)02d:%(title)s"

# Prioritize uploader as the "artist" field in video metadata
$ yt-dlp --parse-metadata "%(uploader|)s:%(meta_artist)s" --embed-metadata

# Set "comment" field in video metadata using description instead of webpage_url,
# handling multiple lines correctly
$ yt-dlp --parse-metadata "description:(?s)(?P&amp;lt;meta_comment&amp;gt;.+)" --embed-metadata

# Do not set any "synopsis" in the video metadata
$ yt-dlp --parse-metadata ":(?P&amp;lt;meta_synopsis&amp;gt;)"

# Remove "formats" field from the infojson by setting it to an empty string
$ yt-dlp --parse-metadata "video::(?P&amp;lt;formats&amp;gt;)" --write-info-json

# Replace all spaces and "_" in title and uploader with a `-`
$ yt-dlp --replace-in-metadata "title,uploader" "[ _]" "-"

&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;EXTRACTOR ARGUMENTS&lt;/h1&gt; 
&lt;p&gt;Some extractors accept additional arguments which can be passed using &lt;code&gt;--extractor-args KEY:ARGS&lt;/code&gt;. &lt;code&gt;ARGS&lt;/code&gt; is a &lt;code&gt;;&lt;/code&gt; (semicolon) separated string of &lt;code&gt;ARG=VAL1,VAL2&lt;/code&gt;. E.g. &lt;code&gt;--extractor-args "youtube:player-client=tv,mweb;formats=incomplete" --extractor-args "twitter:api=syndication"&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;Note: In CLI, &lt;code&gt;ARG&lt;/code&gt; can use &lt;code&gt;-&lt;/code&gt; instead of &lt;code&gt;_&lt;/code&gt;; e.g. &lt;code&gt;youtube:player-client"&lt;/code&gt; becomes &lt;code&gt;youtube:player_client"&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;The following extractors use this feature:&lt;/p&gt; 
&lt;h4&gt;youtube&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;lang&lt;/code&gt;: Prefer translated metadata (&lt;code&gt;title&lt;/code&gt;, &lt;code&gt;description&lt;/code&gt; etc) of this language code (case-sensitive). By default, the video primary language metadata is preferred, with a fallback to &lt;code&gt;en&lt;/code&gt; translated. See &lt;a href="https://github.com/yt-dlp/yt-dlp/raw/415b4c9f955b1a0391204bd24a7132590e7b3bdb/yt_dlp/extractor/youtube/_base.py#L402-L409"&gt;youtube/_base.py&lt;/a&gt; for the list of supported content language codes&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;skip&lt;/code&gt;: One or more of &lt;code&gt;hls&lt;/code&gt;, &lt;code&gt;dash&lt;/code&gt; or &lt;code&gt;translated_subs&lt;/code&gt; to skip extraction of the m3u8 manifests, dash manifests and &lt;a href="https://github.com/yt-dlp/yt-dlp/issues/4090#issuecomment-1158102032"&gt;auto-translated subtitles&lt;/a&gt; respectively&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;player_client&lt;/code&gt;: Clients to extract video data from. The currently available clients are &lt;code&gt;web&lt;/code&gt;, &lt;code&gt;web_safari&lt;/code&gt;, &lt;code&gt;web_embedded&lt;/code&gt;, &lt;code&gt;web_music&lt;/code&gt;, &lt;code&gt;web_creator&lt;/code&gt;, &lt;code&gt;mweb&lt;/code&gt;, &lt;code&gt;ios&lt;/code&gt;, &lt;code&gt;android&lt;/code&gt;, &lt;code&gt;android_vr&lt;/code&gt;, &lt;code&gt;tv&lt;/code&gt;, &lt;code&gt;tv_simply&lt;/code&gt; and &lt;code&gt;tv_embedded&lt;/code&gt;. By default, &lt;code&gt;tv_simply,tv,web&lt;/code&gt; is used, but &lt;code&gt;tv,web_safari,web&lt;/code&gt; is used when authenticating with cookies and &lt;code&gt;tv,web_creator,web&lt;/code&gt; is used with premium accounts. The &lt;code&gt;web_music&lt;/code&gt; client is added for &lt;code&gt;music.youtube.com&lt;/code&gt; URLs when logged-in cookies are used. The &lt;code&gt;web_embedded&lt;/code&gt; client is added for age-restricted videos but only works if the video is embeddable. The &lt;code&gt;tv_embedded&lt;/code&gt; and &lt;code&gt;web_creator&lt;/code&gt; clients are added for age-restricted videos if account age-verification is required. Some clients, such as &lt;code&gt;web&lt;/code&gt; and &lt;code&gt;web_music&lt;/code&gt;, require a &lt;code&gt;po_token&lt;/code&gt; for their formats to be downloadable. Some clients, such as &lt;code&gt;web_creator&lt;/code&gt;, will only work with authentication. Not all clients support authentication via cookies. You can use &lt;code&gt;default&lt;/code&gt; for the default clients, or you can use &lt;code&gt;all&lt;/code&gt; for all clients (not recommended). You can prefix a client with &lt;code&gt;-&lt;/code&gt; to exclude it, e.g. &lt;code&gt;youtube:player_client=default,-ios&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;player_skip&lt;/code&gt;: Skip some network requests that are generally needed for robust extraction. One or more of &lt;code&gt;configs&lt;/code&gt; (skip client configs), &lt;code&gt;webpage&lt;/code&gt; (skip initial webpage), &lt;code&gt;js&lt;/code&gt; (skip js player), &lt;code&gt;initial_data&lt;/code&gt; (skip initial data/next ep request). While these options can help reduce the number of requests needed or avoid some rate-limiting, they could cause issues such as missing formats or metadata. See &lt;a href="https://github.com/yt-dlp/yt-dlp/pull/860"&gt;#860&lt;/a&gt; and &lt;a href="https://github.com/yt-dlp/yt-dlp/issues/12826"&gt;#12826&lt;/a&gt; for more details&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;webpage_skip&lt;/code&gt;: Skip extraction of embedded webpage data. One or both of &lt;code&gt;player_response&lt;/code&gt;, &lt;code&gt;initial_data&lt;/code&gt;. These options are for testing purposes and don't skip any network requests&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;player_params&lt;/code&gt;: YouTube player parameters to use for player requests. Will overwrite any default ones set by yt-dlp.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;player_js_variant&lt;/code&gt;: The player javascript variant to use for signature and nsig deciphering. The known variants are: &lt;code&gt;main&lt;/code&gt;, &lt;code&gt;tce&lt;/code&gt;, &lt;code&gt;tv&lt;/code&gt;, &lt;code&gt;tv_es6&lt;/code&gt;, &lt;code&gt;phone&lt;/code&gt;, &lt;code&gt;tablet&lt;/code&gt;. The default is &lt;code&gt;main&lt;/code&gt;, and the others are for debugging purposes. You can use &lt;code&gt;actual&lt;/code&gt; to go with what is prescribed by the site&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;comment_sort&lt;/code&gt;: &lt;code&gt;top&lt;/code&gt; or &lt;code&gt;new&lt;/code&gt; (default) - choose comment sorting mode (on YouTube's side)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;max_comments&lt;/code&gt;: Limit the amount of comments to gather. Comma-separated list of integers representing &lt;code&gt;max-comments,max-parents,max-replies,max-replies-per-thread&lt;/code&gt;. Default is &lt;code&gt;all,all,all,all&lt;/code&gt; 
  &lt;ul&gt; 
   &lt;li&gt;E.g. &lt;code&gt;all,all,1000,10&lt;/code&gt; will get a maximum of 1000 replies total, with up to 10 replies per thread. &lt;code&gt;1000,all,100&lt;/code&gt; will get a maximum of 1000 comments, with a maximum of 100 replies total&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;formats&lt;/code&gt;: Change the types of formats to return. &lt;code&gt;dashy&lt;/code&gt; (convert HTTP to DASH), &lt;code&gt;duplicate&lt;/code&gt; (identical content but different URLs or protocol; includes &lt;code&gt;dashy&lt;/code&gt;), &lt;code&gt;incomplete&lt;/code&gt; (cannot be downloaded completely - live dash and post-live m3u8), &lt;code&gt;missing_pot&lt;/code&gt; (include formats that require a PO Token but are missing one)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;innertube_host&lt;/code&gt;: Innertube API host to use for all API requests; e.g. &lt;code&gt;studio.youtube.com&lt;/code&gt;, &lt;code&gt;youtubei.googleapis.com&lt;/code&gt;. Note that cookies exported from one subdomain will not work on others&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;innertube_key&lt;/code&gt;: Innertube API key to use for all API requests. By default, no API key is used&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;raise_incomplete_data&lt;/code&gt;: &lt;code&gt;Incomplete Data Received&lt;/code&gt; raises an error instead of reporting a warning&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;data_sync_id&lt;/code&gt;: Overrides the account Data Sync ID used in Innertube API requests. This may be needed if you are using an account with &lt;code&gt;youtube:player_skip=webpage,configs&lt;/code&gt; or &lt;code&gt;youtubetab:skip=webpage&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;visitor_data&lt;/code&gt;: Overrides the Visitor Data used in Innertube API requests. This should be used with &lt;code&gt;player_skip=webpage,configs&lt;/code&gt; and without cookies. Note: this may have adverse effects if used improperly. If a session from a browser is wanted, you should pass cookies instead (which contain the Visitor ID)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;po_token&lt;/code&gt;: Proof of Origin (PO) Token(s) to use. Comma seperated list of PO Tokens in the format &lt;code&gt;CLIENT.CONTEXT+PO_TOKEN&lt;/code&gt;, e.g. &lt;code&gt;youtube:po_token=web.gvs+XXX,web.player=XXX,web_safari.gvs+YYY&lt;/code&gt;. Context can be any of &lt;code&gt;gvs&lt;/code&gt; (Google Video Server URLs), &lt;code&gt;player&lt;/code&gt; (Innertube player request) or &lt;code&gt;subs&lt;/code&gt; (Subtitles)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;pot_trace&lt;/code&gt;: Enable debug logging for PO Token fetching. Either &lt;code&gt;true&lt;/code&gt; or &lt;code&gt;false&lt;/code&gt; (default)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;fetch_pot&lt;/code&gt;: Policy to use for fetching a PO Token from providers. One of &lt;code&gt;always&lt;/code&gt; (always try fetch a PO Token regardless if the client requires one for the given context), &lt;code&gt;never&lt;/code&gt; (never fetch a PO Token), or &lt;code&gt;auto&lt;/code&gt; (default; only fetch a PO Token if the client requires one for the given context)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;playback_wait&lt;/code&gt;: Duration (in seconds) to wait inbetween the extraction and download stages in order to ensure the formats are available. The default is &lt;code&gt;6&lt;/code&gt; seconds&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;youtubepot-webpo&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;bind_to_visitor_id&lt;/code&gt;: Whether to use the Visitor ID instead of Visitor Data for caching WebPO tokens. Either &lt;code&gt;true&lt;/code&gt; (default) or &lt;code&gt;false&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;youtubetab (YouTube playlists, channels, feeds, etc.)&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;skip&lt;/code&gt;: One or more of &lt;code&gt;webpage&lt;/code&gt; (skip initial webpage download), &lt;code&gt;authcheck&lt;/code&gt; (allow the download of playlists requiring authentication when no initial webpage is downloaded. This may cause unwanted behavior, see &lt;a href="https://github.com/yt-dlp/yt-dlp/pull/1122"&gt;#1122&lt;/a&gt; for more details)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;approximate_date&lt;/code&gt;: Extract approximate &lt;code&gt;upload_date&lt;/code&gt; and &lt;code&gt;timestamp&lt;/code&gt; in flat-playlist. This may cause date-based filters to be slightly off&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;generic&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;fragment_query&lt;/code&gt;: Passthrough any query in mpd/m3u8 manifest URLs to their fragments if no value is provided, or else apply the query string given as &lt;code&gt;fragment_query=VALUE&lt;/code&gt;. Note that if the stream has an HLS AES-128 key, then the query parameters will be passed to the key URI as well, unless the &lt;code&gt;key_query&lt;/code&gt; extractor-arg is passed, or unless an external key URI is provided via the &lt;code&gt;hls_key&lt;/code&gt; extractor-arg. Does not apply to ffmpeg&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;variant_query&lt;/code&gt;: Passthrough the master m3u8 URL query to its variant playlist URLs if no value is provided, or else apply the query string given as &lt;code&gt;variant_query=VALUE&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;key_query&lt;/code&gt;: Passthrough the master m3u8 URL query to its HLS AES-128 decryption key URI if no value is provided, or else apply the query string given as &lt;code&gt;key_query=VALUE&lt;/code&gt;. Note that this will have no effect if the key URI is provided via the &lt;code&gt;hls_key&lt;/code&gt; extractor-arg. Does not apply to ffmpeg&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;hls_key&lt;/code&gt;: An HLS AES-128 key URI &lt;em&gt;or&lt;/em&gt; key (as hex), and optionally the IV (as hex), in the form of &lt;code&gt;(URI|KEY)[,IV]&lt;/code&gt;; e.g. &lt;code&gt;generic:hls_key=ABCDEF1234567980,0xFEDCBA0987654321&lt;/code&gt;. Passing any of these values will force usage of the native HLS downloader and override the corresponding values found in the m3u8 playlist&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;is_live&lt;/code&gt;: Bypass live HLS detection and manually set &lt;code&gt;live_status&lt;/code&gt; - a value of &lt;code&gt;false&lt;/code&gt; will set &lt;code&gt;not_live&lt;/code&gt;, any other value (or no value) will set &lt;code&gt;is_live&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;impersonate&lt;/code&gt;: Target(s) to try and impersonate with the initial webpage request; e.g. &lt;code&gt;generic:impersonate=safari,chrome-110&lt;/code&gt;. Use &lt;code&gt;generic:impersonate&lt;/code&gt; to impersonate any available target, and use &lt;code&gt;generic:impersonate=false&lt;/code&gt; to disable impersonation (default)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;vikichannel&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;video_types&lt;/code&gt;: Types of videos to download - one or more of &lt;code&gt;episodes&lt;/code&gt;, &lt;code&gt;movies&lt;/code&gt;, &lt;code&gt;clips&lt;/code&gt;, &lt;code&gt;trailers&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;youtubewebarchive&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;check_all&lt;/code&gt;: Try to check more at the cost of more requests. One or more of &lt;code&gt;thumbnails&lt;/code&gt;, &lt;code&gt;captures&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;gamejolt&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;comment_sort&lt;/code&gt;: &lt;code&gt;hot&lt;/code&gt; (default), &lt;code&gt;you&lt;/code&gt; (cookies needed), &lt;code&gt;top&lt;/code&gt;, &lt;code&gt;new&lt;/code&gt; - choose comment sorting mode (on GameJolt's side)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;hotstar&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;res&lt;/code&gt;: resolution to ignore - one or more of &lt;code&gt;sd&lt;/code&gt;, &lt;code&gt;hd&lt;/code&gt;, &lt;code&gt;fhd&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;vcodec&lt;/code&gt;: vcodec to ignore - one or more of &lt;code&gt;h264&lt;/code&gt;, &lt;code&gt;h265&lt;/code&gt;, &lt;code&gt;dvh265&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;dr&lt;/code&gt;: dynamic range to ignore - one or more of &lt;code&gt;sdr&lt;/code&gt;, &lt;code&gt;hdr10&lt;/code&gt;, &lt;code&gt;dv&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;instagram&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;app_id&lt;/code&gt;: The value of the &lt;code&gt;X-IG-App-ID&lt;/code&gt; header used for API requests. Default is the web app ID, &lt;code&gt;936619743392459&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;niconicochannelplus&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;max_comments&lt;/code&gt;: Maximum number of comments to extract - default is &lt;code&gt;120&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;tiktok&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;api_hostname&lt;/code&gt;: Hostname to use for mobile API calls, e.g. &lt;code&gt;api22-normal-c-alisg.tiktokv.com&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;app_name&lt;/code&gt;: Default app name to use with mobile API calls, e.g. &lt;code&gt;trill&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;app_version&lt;/code&gt;: Default app version to use with mobile API calls - should be set along with &lt;code&gt;manifest_app_version&lt;/code&gt;, e.g. &lt;code&gt;34.1.2&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;manifest_app_version&lt;/code&gt;: Default numeric app version to use with mobile API calls, e.g. &lt;code&gt;2023401020&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;aid&lt;/code&gt;: Default app ID to use with mobile API calls, e.g. &lt;code&gt;1180&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;app_info&lt;/code&gt;: Enable mobile API extraction with one or more app info strings in the format of &lt;code&gt;&amp;lt;iid&amp;gt;/[app_name]/[app_version]/[manifest_app_version]/[aid]&lt;/code&gt;, where &lt;code&gt;iid&lt;/code&gt; is the unique app install ID. &lt;code&gt;iid&lt;/code&gt; is the only required value; all other values and their &lt;code&gt;/&lt;/code&gt; separators can be omitted, e.g. &lt;code&gt;tiktok:app_info=1234567890123456789&lt;/code&gt; or &lt;code&gt;tiktok:app_info=123,456/trill///1180,789//34.0.1/340001&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;device_id&lt;/code&gt;: Enable mobile API extraction with a genuine device ID to be used with mobile API calls. Default is a random 19-digit string&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;rokfinchannel&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;tab&lt;/code&gt;: Which tab to download - one of &lt;code&gt;new&lt;/code&gt;, &lt;code&gt;top&lt;/code&gt;, &lt;code&gt;videos&lt;/code&gt;, &lt;code&gt;podcasts&lt;/code&gt;, &lt;code&gt;streams&lt;/code&gt;, &lt;code&gt;stacks&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;twitter&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;api&lt;/code&gt;: Select one of &lt;code&gt;graphql&lt;/code&gt; (default), &lt;code&gt;legacy&lt;/code&gt; or &lt;code&gt;syndication&lt;/code&gt; as the API for tweet extraction. Has no effect if logged in&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;stacommu, wrestleuniverse&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;device_id&lt;/code&gt;: UUID value assigned by the website and used to enforce device limits for paid livestream content. Can be found in browser local storage&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;twitch&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;client_id&lt;/code&gt;: Client ID value to be sent with GraphQL requests, e.g. &lt;code&gt;twitch:client_id=kimne78kx3ncx6brgo4mv6wki5h1ko&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;nhkradirulive (NHK ã‚‰ã˜ã‚‹â˜…ã‚‰ã˜ã‚‹ LIVE)&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;area&lt;/code&gt;: Which regional variation to extract. Valid areas are: &lt;code&gt;sapporo&lt;/code&gt;, &lt;code&gt;sendai&lt;/code&gt;, &lt;code&gt;tokyo&lt;/code&gt;, &lt;code&gt;nagoya&lt;/code&gt;, &lt;code&gt;osaka&lt;/code&gt;, &lt;code&gt;hiroshima&lt;/code&gt;, &lt;code&gt;matsuyama&lt;/code&gt;, &lt;code&gt;fukuoka&lt;/code&gt;. Defaults to &lt;code&gt;tokyo&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;nflplusreplay&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;type&lt;/code&gt;: Type(s) of game replays to extract. Valid types are: &lt;code&gt;full_game&lt;/code&gt;, &lt;code&gt;full_game_spanish&lt;/code&gt;, &lt;code&gt;condensed_game&lt;/code&gt; and &lt;code&gt;all_22&lt;/code&gt;. You can use &lt;code&gt;all&lt;/code&gt; to extract all available replay types, which is the default&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;jiocinema&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;refresh_token&lt;/code&gt;: The &lt;code&gt;refreshToken&lt;/code&gt; UUID from browser local storage can be passed to extend the life of your login session when logging in with &lt;code&gt;token&lt;/code&gt; as username and the &lt;code&gt;accessToken&lt;/code&gt; from browser local storage as password&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;jiosaavn&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;bitrate&lt;/code&gt;: Audio bitrates to request. One or more of &lt;code&gt;16&lt;/code&gt;, &lt;code&gt;32&lt;/code&gt;, &lt;code&gt;64&lt;/code&gt;, &lt;code&gt;128&lt;/code&gt;, &lt;code&gt;320&lt;/code&gt;. Default is &lt;code&gt;128,320&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;afreecatvlive&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;cdn&lt;/code&gt;: One or more CDN IDs to use with the API call for stream URLs, e.g. &lt;code&gt;gcp_cdn&lt;/code&gt;, &lt;code&gt;gs_cdn_pc_app&lt;/code&gt;, &lt;code&gt;gs_cdn_mobile_web&lt;/code&gt;, &lt;code&gt;gs_cdn_pc_web&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;soundcloud&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;formats&lt;/code&gt;: Formats to request from the API. Requested values should be in the format of &lt;code&gt;{protocol}_{codec}&lt;/code&gt;, e.g. &lt;code&gt;hls_opus,http_aac&lt;/code&gt;. The &lt;code&gt;*&lt;/code&gt; character functions as a wildcard, e.g. &lt;code&gt;*_mp3&lt;/code&gt;, and can be passed by itself to request all formats. Known protocols include &lt;code&gt;http&lt;/code&gt;, &lt;code&gt;hls&lt;/code&gt; and &lt;code&gt;hls-aes&lt;/code&gt;; known codecs include &lt;code&gt;aac&lt;/code&gt;, &lt;code&gt;opus&lt;/code&gt; and &lt;code&gt;mp3&lt;/code&gt;. Original &lt;code&gt;download&lt;/code&gt; formats are always extracted. Default is &lt;code&gt;http_aac,hls_aac,http_opus,hls_opus,http_mp3,hls_mp3&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;orfon (orf:on)&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;prefer_segments_playlist&lt;/code&gt;: Prefer a playlist of program segments instead of a single complete video when available. If individual segments are desired, use &lt;code&gt;--concat-playlist never --extractor-args "orfon:prefer_segments_playlist"&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;bilibili&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;prefer_multi_flv&lt;/code&gt;: Prefer extracting flv formats over mp4 for older videos that still provide legacy formats&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;sonylivseries&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;sort_order&lt;/code&gt;: Episode sort order for series extraction - one of &lt;code&gt;asc&lt;/code&gt; (ascending, oldest first) or &lt;code&gt;desc&lt;/code&gt; (descending, newest first). Default is &lt;code&gt;asc&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;tver&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;backend&lt;/code&gt;: Backend API to use for extraction - one of &lt;code&gt;streaks&lt;/code&gt; (default) or &lt;code&gt;brightcove&lt;/code&gt; (deprecated)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;vimeo&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;client&lt;/code&gt;: Client to extract video data from. The currently available clients are &lt;code&gt;android&lt;/code&gt;, &lt;code&gt;ios&lt;/code&gt;, and &lt;code&gt;web&lt;/code&gt;. Only one client can be used. The &lt;code&gt;web&lt;/code&gt; client is used by default. The &lt;code&gt;web&lt;/code&gt; client only works with account cookies or login credentials. The &lt;code&gt;android&lt;/code&gt; and &lt;code&gt;ios&lt;/code&gt; clients only work with previously cached OAuth tokens&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;original_format_policy&lt;/code&gt;: Policy for when to try extracting original formats. One of &lt;code&gt;always&lt;/code&gt;, &lt;code&gt;never&lt;/code&gt;, or &lt;code&gt;auto&lt;/code&gt;. The default &lt;code&gt;auto&lt;/code&gt; policy tries to avoid exceeding the web client's API rate-limit by only making an extra request when Vimeo publicizes the video's downloadability&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: These options may be changed/removed in the future without concern for backward compatibility&lt;/p&gt; 
&lt;!-- MANPAGE: MOVE "INSTALLATION" SECTION HERE --&gt; 
&lt;h1&gt;PLUGINS&lt;/h1&gt; 
&lt;p&gt;Note that &lt;strong&gt;all&lt;/strong&gt; plugins are imported even if not invoked, and that &lt;strong&gt;there are no checks&lt;/strong&gt; performed on plugin code. &lt;strong&gt;Use plugins at your own risk and only if you trust the code!&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Plugins can be of &lt;code&gt;&amp;lt;type&amp;gt;&lt;/code&gt;s &lt;code&gt;extractor&lt;/code&gt; or &lt;code&gt;postprocessor&lt;/code&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Extractor plugins do not need to be enabled from the CLI and are automatically invoked when the input URL is suitable for it.&lt;/li&gt; 
 &lt;li&gt;Extractor plugins take priority over built-in extractors.&lt;/li&gt; 
 &lt;li&gt;Postprocessor plugins can be invoked using &lt;code&gt;--use-postprocessor NAME&lt;/code&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Plugins are loaded from the namespace packages &lt;code&gt;yt_dlp_plugins.extractor&lt;/code&gt; and &lt;code&gt;yt_dlp_plugins.postprocessor&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;In other words, the file structure on the disk looks something like:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;    yt_dlp_plugins/
        extractor/
            myplugin.py
        postprocessor/
            myplugin.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;yt-dlp looks for these &lt;code&gt;yt_dlp_plugins&lt;/code&gt; namespace folders in many locations (see below) and loads in plugins from &lt;strong&gt;all&lt;/strong&gt; of them. Set the environment variable &lt;code&gt;YTDLP_NO_PLUGINS&lt;/code&gt; to something nonempty to disable loading plugins entirely.&lt;/p&gt; 
&lt;p&gt;See the &lt;a href="https://github.com/yt-dlp/yt-dlp/wiki/Plugins"&gt;wiki for some known plugins&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Installing Plugins&lt;/h2&gt; 
&lt;p&gt;Plugins can be installed using various methods and locations.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Configuration directories&lt;/strong&gt;: Plugin packages (containing a &lt;code&gt;yt_dlp_plugins&lt;/code&gt; namespace folder) can be dropped into the following standard &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#configuration"&gt;configuration locations&lt;/a&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;User Plugins&lt;/strong&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;code&gt;${XDG_CONFIG_HOME}/yt-dlp/plugins/&amp;lt;package name&amp;gt;/yt_dlp_plugins/&lt;/code&gt; (recommended on Linux/macOS)&lt;/li&gt; 
     &lt;li&gt;&lt;code&gt;${XDG_CONFIG_HOME}/yt-dlp-plugins/&amp;lt;package name&amp;gt;/yt_dlp_plugins/&lt;/code&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;code&gt;${APPDATA}/yt-dlp/plugins/&amp;lt;package name&amp;gt;/yt_dlp_plugins/&lt;/code&gt; (recommended on Windows)&lt;/li&gt; 
     &lt;li&gt;&lt;code&gt;${APPDATA}/yt-dlp-plugins/&amp;lt;package name&amp;gt;/yt_dlp_plugins/&lt;/code&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;code&gt;~/.yt-dlp/plugins/&amp;lt;package name&amp;gt;/yt_dlp_plugins/&lt;/code&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;code&gt;~/yt-dlp-plugins/&amp;lt;package name&amp;gt;/yt_dlp_plugins/&lt;/code&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;System Plugins&lt;/strong&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;code&gt;/etc/yt-dlp/plugins/&amp;lt;package name&amp;gt;/yt_dlp_plugins/&lt;/code&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;code&gt;/etc/yt-dlp-plugins/&amp;lt;package name&amp;gt;/yt_dlp_plugins/&lt;/code&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Executable location&lt;/strong&gt;: Plugin packages can similarly be installed in a &lt;code&gt;yt-dlp-plugins&lt;/code&gt; directory under the executable location (recommended for portable installations):&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Binary: where &lt;code&gt;&amp;lt;root-dir&amp;gt;/yt-dlp.exe&lt;/code&gt;, &lt;code&gt;&amp;lt;root-dir&amp;gt;/yt-dlp-plugins/&amp;lt;package name&amp;gt;/yt_dlp_plugins/&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;Source: where &lt;code&gt;&amp;lt;root-dir&amp;gt;/yt_dlp/__main__.py&lt;/code&gt;, &lt;code&gt;&amp;lt;root-dir&amp;gt;/yt-dlp-plugins/&amp;lt;package name&amp;gt;/yt_dlp_plugins/&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;pip and other locations in &lt;code&gt;PYTHONPATH&lt;/code&gt;&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Plugin packages can be installed and managed using &lt;code&gt;pip&lt;/code&gt;. See &lt;a href="https://github.com/yt-dlp/yt-dlp-sample-plugins"&gt;yt-dlp-sample-plugins&lt;/a&gt; for an example. 
    &lt;ul&gt; 
     &lt;li&gt;Note: plugin files between plugin packages installed with pip must have unique filenames.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;Any path in &lt;code&gt;PYTHONPATH&lt;/code&gt; is searched in for the &lt;code&gt;yt_dlp_plugins&lt;/code&gt; namespace folder. 
    &lt;ul&gt; 
     &lt;li&gt;Note: This does not apply for Pyinstaller builds.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;code&gt;.zip&lt;/code&gt;, &lt;code&gt;.egg&lt;/code&gt; and &lt;code&gt;.whl&lt;/code&gt; archives containing a &lt;code&gt;yt_dlp_plugins&lt;/code&gt; namespace folder in their root are also supported as plugin packages.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;e.g. &lt;code&gt;${XDG_CONFIG_HOME}/yt-dlp/plugins/mypluginpkg.zip&lt;/code&gt; where &lt;code&gt;mypluginpkg.zip&lt;/code&gt; contains &lt;code&gt;yt_dlp_plugins/&amp;lt;type&amp;gt;/myplugin.py&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Run yt-dlp with &lt;code&gt;--verbose&lt;/code&gt; to check if the plugin has been loaded.&lt;/p&gt; 
&lt;h2&gt;Developing Plugins&lt;/h2&gt; 
&lt;p&gt;See the &lt;a href="https://github.com/yt-dlp/yt-dlp-sample-plugins"&gt;yt-dlp-sample-plugins&lt;/a&gt; repo for a template plugin package and the &lt;a href="https://github.com/yt-dlp/yt-dlp/wiki/Plugin-Development"&gt;Plugin Development&lt;/a&gt; section of the wiki for a plugin development guide.&lt;/p&gt; 
&lt;p&gt;All public classes with a name ending in &lt;code&gt;IE&lt;/code&gt;/&lt;code&gt;PP&lt;/code&gt; are imported from each file for extractors and postprocessors respectively. This respects underscore prefix (e.g. &lt;code&gt;_MyBasePluginIE&lt;/code&gt; is private) and &lt;code&gt;__all__&lt;/code&gt;. Modules can similarly be excluded by prefixing the module name with an underscore (e.g. &lt;code&gt;_myplugin.py&lt;/code&gt;).&lt;/p&gt; 
&lt;p&gt;To replace an existing extractor with a subclass of one, set the &lt;code&gt;plugin_name&lt;/code&gt; class keyword argument (e.g. &lt;code&gt;class MyPluginIE(ABuiltInIE, plugin_name='myplugin')&lt;/code&gt; will replace &lt;code&gt;ABuiltInIE&lt;/code&gt; with &lt;code&gt;MyPluginIE&lt;/code&gt;). Since the extractor replaces the parent, you should exclude the subclass extractor from being imported separately by making it private using one of the methods described above.&lt;/p&gt; 
&lt;p&gt;If you are a plugin author, add &lt;a href="https://github.com/topics/yt-dlp-plugins"&gt;yt-dlp-plugins&lt;/a&gt; as a topic to your repository for discoverability.&lt;/p&gt; 
&lt;p&gt;See the &lt;a href="https://github.com/yt-dlp/yt-dlp/raw/master/CONTRIBUTING.md#developer-instructions"&gt;Developer Instructions&lt;/a&gt; on how to write and test an extractor.&lt;/p&gt; 
&lt;h1&gt;EMBEDDING YT-DLP&lt;/h1&gt; 
&lt;p&gt;yt-dlp makes the best effort to be a good command-line program, and thus should be callable from any programming language.&lt;/p&gt; 
&lt;p&gt;Your program should avoid parsing the normal stdout since they may change in future versions. Instead, they should use options such as &lt;code&gt;-J&lt;/code&gt;, &lt;code&gt;--print&lt;/code&gt;, &lt;code&gt;--progress-template&lt;/code&gt;, &lt;code&gt;--exec&lt;/code&gt; etc to create console output that you can reliably reproduce and parse.&lt;/p&gt; 
&lt;p&gt;From a Python program, you can embed yt-dlp in a more powerful fashion, like this:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from yt_dlp import YoutubeDL

URLS = ['https://www.youtube.com/watch?v=BaW_jenozKc']
with YoutubeDL() as ydl:
    ydl.download(URLS)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Most likely, you'll want to use various options. For a list of options available, have a look at &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/yt_dlp/YoutubeDL.py#L183"&gt;&lt;code&gt;yt_dlp/YoutubeDL.py&lt;/code&gt;&lt;/a&gt; or &lt;code&gt;help(yt_dlp.YoutubeDL)&lt;/code&gt; in a Python shell. If you are already familiar with the CLI, you can use &lt;a href="https://github.com/yt-dlp/yt-dlp/raw/master/devscripts/cli_to_api.py"&gt;&lt;code&gt;devscripts/cli_to_api.py&lt;/code&gt;&lt;/a&gt; to translate any CLI switches to &lt;code&gt;YoutubeDL&lt;/code&gt; params.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Tip&lt;/strong&gt;: If you are porting your code from youtube-dl to yt-dlp, one important point to look out for is that we do not guarantee the return value of &lt;code&gt;YoutubeDL.extract_info&lt;/code&gt; to be json serializable, or even be a dictionary. It will be dictionary-like, but if you want to ensure it is a serializable dictionary, pass it through &lt;code&gt;YoutubeDL.sanitize_info&lt;/code&gt; as shown in the &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#extracting-information"&gt;example below&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Embedding examples&lt;/h2&gt; 
&lt;h4&gt;Extracting information&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import json
import yt_dlp

URL = 'https://www.youtube.com/watch?v=BaW_jenozKc'

# â„¹ï¸ See help(yt_dlp.YoutubeDL) for a list of available options and public functions
ydl_opts = {}
with yt_dlp.YoutubeDL(ydl_opts) as ydl:
    info = ydl.extract_info(URL, download=False)

    # â„¹ï¸ ydl.sanitize_info makes the info json-serializable
    print(json.dumps(ydl.sanitize_info(info)))
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Download using an info-json&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import yt_dlp

INFO_FILE = 'path/to/video.info.json'

with yt_dlp.YoutubeDL() as ydl:
    error_code = ydl.download_with_info_file(INFO_FILE)

print('Some videos failed to download' if error_code
      else 'All videos successfully downloaded')
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Extract audio&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import yt_dlp

URLS = ['https://www.youtube.com/watch?v=BaW_jenozKc']

ydl_opts = {
    'format': 'm4a/bestaudio/best',
    # â„¹ï¸ See help(yt_dlp.postprocessor) for a list of available Postprocessors and their arguments
    'postprocessors': [{  # Extract audio using ffmpeg
        'key': 'FFmpegExtractAudio',
        'preferredcodec': 'm4a',
    }]
}

with yt_dlp.YoutubeDL(ydl_opts) as ydl:
    error_code = ydl.download(URLS)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Filter videos&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import yt_dlp

URLS = ['https://www.youtube.com/watch?v=BaW_jenozKc']

def longer_than_a_minute(info, *, incomplete):
    """Download only videos longer than a minute (or with unknown duration)"""
    duration = info.get('duration')
    if duration and duration &amp;lt; 60:
        return 'The video is too short'

ydl_opts = {
    'match_filter': longer_than_a_minute,
}

with yt_dlp.YoutubeDL(ydl_opts) as ydl:
    error_code = ydl.download(URLS)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Adding logger and progress hook&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import yt_dlp

URLS = ['https://www.youtube.com/watch?v=BaW_jenozKc']

class MyLogger:
    def debug(self, msg):
        # For compatibility with youtube-dl, both debug and info are passed into debug
        # You can distinguish them by the prefix '[debug] '
        if msg.startswith('[debug] '):
            pass
        else:
            self.info(msg)

    def info(self, msg):
        pass

    def warning(self, msg):
        pass

    def error(self, msg):
        print(msg)


# â„¹ï¸ See "progress_hooks" in help(yt_dlp.YoutubeDL)
def my_hook(d):
    if d['status'] == 'finished':
        print('Done downloading, now post-processing ...')


ydl_opts = {
    'logger': MyLogger(),
    'progress_hooks': [my_hook],
}

with yt_dlp.YoutubeDL(ydl_opts) as ydl:
    ydl.download(URLS)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Add a custom PostProcessor&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import yt_dlp

URLS = ['https://www.youtube.com/watch?v=BaW_jenozKc']

# â„¹ï¸ See help(yt_dlp.postprocessor.PostProcessor)
class MyCustomPP(yt_dlp.postprocessor.PostProcessor):
    def run(self, info):
        self.to_screen('Doing stuff')
        return [], info


with yt_dlp.YoutubeDL() as ydl:
    # â„¹ï¸ "when" can take any value in yt_dlp.utils.POSTPROCESS_WHEN
    ydl.add_post_processor(MyCustomPP(), when='pre_process')
    ydl.download(URLS)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Use a custom format selector&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import yt_dlp

URLS = ['https://www.youtube.com/watch?v=BaW_jenozKc']

def format_selector(ctx):
    """ Select the best video and the best audio that won't result in an mkv.
    NOTE: This is just an example and does not handle all cases """

    # formats are already sorted worst to best
    formats = ctx.get('formats')[::-1]

    # acodec='none' means there is no audio
    best_video = next(f for f in formats
                      if f['vcodec'] != 'none' and f['acodec'] == 'none')

    # find compatible audio extension
    audio_ext = {'mp4': 'm4a', 'webm': 'webm'}[best_video['ext']]
    # vcodec='none' means there is no video
    best_audio = next(f for f in formats if (
        f['acodec'] != 'none' and f['vcodec'] == 'none' and f['ext'] == audio_ext))

    # These are the minimum required fields for a merged format
    yield {
        'format_id': f'{best_video["format_id"]}+{best_audio["format_id"]}',
        'ext': best_video['ext'],
        'requested_formats': [best_video, best_audio],
        # Must be + separated list of protocols
        'protocol': f'{best_video["protocol"]}+{best_audio["protocol"]}'
    }


ydl_opts = {
    'format': format_selector,
}

with yt_dlp.YoutubeDL(ydl_opts) as ydl:
    ydl.download(URLS)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;CHANGES FROM YOUTUBE-DL&lt;/h1&gt; 
&lt;h3&gt;New features&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Forked from &lt;a href="https://github.com/blackjack4494/yt-dlc/commit/f9401f2a91987068139c5f757b12fc711d4c0cee"&gt;&lt;strong&gt;yt-dlc@f9401f2&lt;/strong&gt;&lt;/a&gt; and merged with &lt;a href="https://github.com/ytdl-org/youtube-dl/commit/a08f2b7e4567cdc50c0614ee0a4ffdff49b8b6e6"&gt;&lt;strong&gt;youtube-dl@a08f2b7&lt;/strong&gt;&lt;/a&gt; (&lt;a href="https://github.com/yt-dlp/yt-dlp/issues/21"&gt;exceptions&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#sponsorblock-options"&gt;SponsorBlock Integration&lt;/a&gt;&lt;/strong&gt;: You can mark/remove sponsor sections in YouTube videos by utilizing the &lt;a href="https://sponsor.ajay.app"&gt;SponsorBlock&lt;/a&gt; API&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#sorting-formats"&gt;Format Sorting&lt;/a&gt;&lt;/strong&gt;: The default format sorting options have been changed so that higher resolution and better codecs will be now preferred instead of simply using larger bitrate. Furthermore, you can now specify the sort order using &lt;code&gt;-S&lt;/code&gt;. This allows for much easier format selection than what is possible by simply using &lt;code&gt;--format&lt;/code&gt; (&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#format-selection-examples"&gt;examples&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Merged with animelover1984/youtube-dl&lt;/strong&gt;: You get most of the features and improvements from &lt;a href="https://github.com/animelover1984/youtube-dl"&gt;animelover1984/youtube-dl&lt;/a&gt; including &lt;code&gt;--write-comments&lt;/code&gt;, &lt;code&gt;BiliBiliSearch&lt;/code&gt;, &lt;code&gt;BilibiliChannel&lt;/code&gt;, Embedding thumbnail in mp4/ogg/opus, playlist infojson etc. See &lt;a href="https://github.com/yt-dlp/yt-dlp/pull/31"&gt;#31&lt;/a&gt; for details.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;YouTube improvements&lt;/strong&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Supports Clips, Stories (&lt;code&gt;ytstories:&amp;lt;channel UCID&amp;gt;&lt;/code&gt;), Search (including filters)&lt;strong&gt;*&lt;/strong&gt;, YouTube Music Search, Channel-specific search, Search prefixes (&lt;code&gt;ytsearch:&lt;/code&gt;, &lt;code&gt;ytsearchdate:&lt;/code&gt;)&lt;strong&gt;*&lt;/strong&gt;, Mixes, and Feeds (&lt;code&gt;:ytfav&lt;/code&gt;, &lt;code&gt;:ytwatchlater&lt;/code&gt;, &lt;code&gt;:ytsubs&lt;/code&gt;, &lt;code&gt;:ythistory&lt;/code&gt;, &lt;code&gt;:ytrec&lt;/code&gt;, &lt;code&gt;:ytnotif&lt;/code&gt;)&lt;/li&gt; 
   &lt;li&gt;Fix for &lt;a href="https://github.com/ytdl-org/youtube-dl/issues/29326"&gt;n-sig based throttling&lt;/a&gt; &lt;strong&gt;*&lt;/strong&gt;&lt;/li&gt; 
   &lt;li&gt;Download livestreams from the start using &lt;code&gt;--live-from-start&lt;/code&gt; (&lt;em&gt;experimental&lt;/em&gt;)&lt;/li&gt; 
   &lt;li&gt;Channel URLs download all uploads of the channel, including shorts and live&lt;/li&gt; 
   &lt;li&gt;Support for &lt;a href="https://github.com/yt-dlp/yt-dlp/wiki/Extractors#logging-in-with-oauth"&gt;logging in with OAuth&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Cookies from browser&lt;/strong&gt;: Cookies can be automatically extracted from all major web browsers using &lt;code&gt;--cookies-from-browser BROWSER[+KEYRING][:PROFILE][::CONTAINER]&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Download time range&lt;/strong&gt;: Videos can be downloaded partially based on either timestamps or chapters using &lt;code&gt;--download-sections&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Split video by chapters&lt;/strong&gt;: Videos can be split into multiple files based on chapters using &lt;code&gt;--split-chapters&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Multi-threaded fragment downloads&lt;/strong&gt;: Download multiple fragments of m3u8/mpd videos in parallel. Use &lt;code&gt;--concurrent-fragments&lt;/code&gt; (&lt;code&gt;-N&lt;/code&gt;) option to set the number of threads used&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Aria2c with HLS/DASH&lt;/strong&gt;: You can use &lt;code&gt;aria2c&lt;/code&gt; as the external downloader for DASH(mpd) and HLS(m3u8) formats&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;New and fixed extractors&lt;/strong&gt;: Many new extractors have been added and a lot of existing ones have been fixed. See the &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/Changelog.md"&gt;changelog&lt;/a&gt; or the &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/supportedsites.md"&gt;list of supported sites&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;New MSOs&lt;/strong&gt;: Philo, Spectrum, SlingTV, Cablevision, RCN etc.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Subtitle extraction from manifests&lt;/strong&gt;: Subtitles can be extracted from streaming media manifests. See &lt;a href="https://github.com/yt-dlp/yt-dlp/commit/be6202f12b97858b9d716e608394b51065d0419f"&gt;commit/be6202f&lt;/a&gt; for details&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Multiple paths and output templates&lt;/strong&gt;: You can give different &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#output-template"&gt;output templates&lt;/a&gt; and download paths for different types of files. You can also set a temporary path where intermediary files are downloaded to using &lt;code&gt;--paths&lt;/code&gt; (&lt;code&gt;-P&lt;/code&gt;)&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Portable Configuration&lt;/strong&gt;: Configuration files are automatically loaded from the home and root directories. See &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#configuration"&gt;CONFIGURATION&lt;/a&gt; for details&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Output template improvements&lt;/strong&gt;: Output templates can now have date-time formatting, numeric offsets, object traversal etc. See &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#output-template"&gt;output template&lt;/a&gt; for details. Even more advanced operations can also be done with the help of &lt;code&gt;--parse-metadata&lt;/code&gt; and &lt;code&gt;--replace-in-metadata&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Other new options&lt;/strong&gt;: Many new options have been added such as &lt;code&gt;--alias&lt;/code&gt;, &lt;code&gt;--print&lt;/code&gt;, &lt;code&gt;--concat-playlist&lt;/code&gt;, &lt;code&gt;--wait-for-video&lt;/code&gt;, &lt;code&gt;--retry-sleep&lt;/code&gt;, &lt;code&gt;--sleep-requests&lt;/code&gt;, &lt;code&gt;--convert-thumbnails&lt;/code&gt;, &lt;code&gt;--force-download-archive&lt;/code&gt;, &lt;code&gt;--force-overwrites&lt;/code&gt;, &lt;code&gt;--break-match-filters&lt;/code&gt; etc&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Improvements&lt;/strong&gt;: Regex and other operators in &lt;code&gt;--format&lt;/code&gt;/&lt;code&gt;--match-filters&lt;/code&gt;, multiple &lt;code&gt;--postprocessor-args&lt;/code&gt; and &lt;code&gt;--downloader-args&lt;/code&gt;, faster archive checking, more &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#format-selection"&gt;format selection options&lt;/a&gt;, merge multi-video/audio, multiple &lt;code&gt;--config-locations&lt;/code&gt;, &lt;code&gt;--exec&lt;/code&gt; at different stages, etc&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Plugins&lt;/strong&gt;: Extractors and PostProcessors can be loaded from an external file. See &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#plugins"&gt;plugins&lt;/a&gt; for details&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Self updater&lt;/strong&gt;: The releases can be updated using &lt;code&gt;yt-dlp -U&lt;/code&gt;, and downgraded using &lt;code&gt;--update-to&lt;/code&gt; if required&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Automated builds&lt;/strong&gt;: &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#update-channels"&gt;Nightly/master builds&lt;/a&gt; can be used with &lt;code&gt;--update-to nightly&lt;/code&gt; and &lt;code&gt;--update-to master&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/Changelog.md"&gt;changelog&lt;/a&gt; or &lt;a href="https://github.com/yt-dlp/yt-dlp/commits"&gt;commits&lt;/a&gt; for the full list of changes&lt;/p&gt; 
&lt;p&gt;Features marked with a &lt;strong&gt;*&lt;/strong&gt; have been back-ported to youtube-dl&lt;/p&gt; 
&lt;h3&gt;Differences in default behavior&lt;/h3&gt; 
&lt;p&gt;Some of yt-dlp's default options are different from that of youtube-dl and youtube-dlc:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;yt-dlp supports only &lt;a href="##" title="Windows 8"&gt;Python 3.9+&lt;/a&gt;, and will remove support for more versions as they &lt;a href="https://devguide.python.org/versions/#python-release-cycle"&gt;become EOL&lt;/a&gt;; while &lt;a href="https://github.com/ytdl-org/youtube-dl/issues/30568#issue-1118238743"&gt;youtube-dl still supports Python 2.6+ and 3.2+&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;The options &lt;code&gt;--auto-number&lt;/code&gt; (&lt;code&gt;-A&lt;/code&gt;), &lt;code&gt;--title&lt;/code&gt; (&lt;code&gt;-t&lt;/code&gt;) and &lt;code&gt;--literal&lt;/code&gt; (&lt;code&gt;-l&lt;/code&gt;), no longer work. See &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#Removed"&gt;removed options&lt;/a&gt; for details&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;avconv&lt;/code&gt; is not supported as an alternative to &lt;code&gt;ffmpeg&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;yt-dlp stores config files in slightly different locations to youtube-dl. See &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#configuration"&gt;CONFIGURATION&lt;/a&gt; for a list of correct locations&lt;/li&gt; 
 &lt;li&gt;The default &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#output-template"&gt;output template&lt;/a&gt; is &lt;code&gt;%(title)s [%(id)s].%(ext)s&lt;/code&gt;. There is no real reason for this change. This was changed before yt-dlp was ever made public and now there are no plans to change it back to &lt;code&gt;%(title)s-%(id)s.%(ext)s&lt;/code&gt;. Instead, you may use &lt;code&gt;--compat-options filename&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;The default &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#sorting-formats"&gt;format sorting&lt;/a&gt; is different from youtube-dl and prefers higher resolution and better codecs rather than higher bitrates. You can use the &lt;code&gt;--format-sort&lt;/code&gt; option to change this to any order you prefer, or use &lt;code&gt;--compat-options format-sort&lt;/code&gt; to use youtube-dl's sorting order. Older versions of yt-dlp preferred VP9 due to its broader compatibility; you can use &lt;code&gt;--compat-options prefer-vp9-sort&lt;/code&gt; to revert to that format sorting preference. These two compat options cannot be used together&lt;/li&gt; 
 &lt;li&gt;The default format selector is &lt;code&gt;bv*+ba/b&lt;/code&gt;. This means that if a combined video + audio format that is better than the best video-only format is found, the former will be preferred. Use &lt;code&gt;-f bv+ba/b&lt;/code&gt; or &lt;code&gt;--compat-options format-spec&lt;/code&gt; to revert this&lt;/li&gt; 
 &lt;li&gt;Unlike youtube-dlc, yt-dlp does not allow merging multiple audio/video streams into one file by default (since this conflicts with the use of &lt;code&gt;-f bv*+ba&lt;/code&gt;). If needed, this feature must be enabled using &lt;code&gt;--audio-multistreams&lt;/code&gt; and &lt;code&gt;--video-multistreams&lt;/code&gt;. You can also use &lt;code&gt;--compat-options multistreams&lt;/code&gt; to enable both&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--no-abort-on-error&lt;/code&gt; is enabled by default. Use &lt;code&gt;--abort-on-error&lt;/code&gt; or &lt;code&gt;--compat-options abort-on-error&lt;/code&gt; to abort on errors instead&lt;/li&gt; 
 &lt;li&gt;When writing metadata files such as thumbnails, description or infojson, the same information (if available) is also written for playlists. Use &lt;code&gt;--no-write-playlist-metafiles&lt;/code&gt; or &lt;code&gt;--compat-options no-playlist-metafiles&lt;/code&gt; to not write these files&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--add-metadata&lt;/code&gt; attaches the &lt;code&gt;infojson&lt;/code&gt; to &lt;code&gt;mkv&lt;/code&gt; files in addition to writing the metadata when used with &lt;code&gt;--write-info-json&lt;/code&gt;. Use &lt;code&gt;--no-embed-info-json&lt;/code&gt; or &lt;code&gt;--compat-options no-attach-info-json&lt;/code&gt; to revert this&lt;/li&gt; 
 &lt;li&gt;Some metadata are embedded into different fields when using &lt;code&gt;--add-metadata&lt;/code&gt; as compared to youtube-dl. Most notably, &lt;code&gt;comment&lt;/code&gt; field contains the &lt;code&gt;webpage_url&lt;/code&gt; and &lt;code&gt;synopsis&lt;/code&gt; contains the &lt;code&gt;description&lt;/code&gt;. You can &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#modifying-metadata"&gt;use &lt;code&gt;--parse-metadata&lt;/code&gt;&lt;/a&gt; to modify this to your liking or use &lt;code&gt;--compat-options embed-metadata&lt;/code&gt; to revert this&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;playlist_index&lt;/code&gt; behaves differently when used with options like &lt;code&gt;--playlist-reverse&lt;/code&gt; and &lt;code&gt;--playlist-items&lt;/code&gt;. See &lt;a href="https://github.com/yt-dlp/yt-dlp/issues/302"&gt;#302&lt;/a&gt; for details. You can use &lt;code&gt;--compat-options playlist-index&lt;/code&gt; if you want to keep the earlier behavior&lt;/li&gt; 
 &lt;li&gt;The output of &lt;code&gt;-F&lt;/code&gt; is listed in a new format. Use &lt;code&gt;--compat-options list-formats&lt;/code&gt; to revert this&lt;/li&gt; 
 &lt;li&gt;Live chats (if available) are considered as subtitles. Use &lt;code&gt;--sub-langs all,-live_chat&lt;/code&gt; to download all subtitles except live chat. You can also use &lt;code&gt;--compat-options no-live-chat&lt;/code&gt; to prevent any live chat/danmaku from downloading&lt;/li&gt; 
 &lt;li&gt;YouTube channel URLs download all uploads of the channel. To download only the videos in a specific tab, pass the tab's URL. If the channel does not show the requested tab, an error will be raised. Also, &lt;code&gt;/live&lt;/code&gt; URLs raise an error if there are no live videos instead of silently downloading the entire channel. You may use &lt;code&gt;--compat-options no-youtube-channel-redirect&lt;/code&gt; to revert all these redirections&lt;/li&gt; 
 &lt;li&gt;Unavailable videos are also listed for YouTube playlists. Use &lt;code&gt;--compat-options no-youtube-unavailable-videos&lt;/code&gt; to remove this&lt;/li&gt; 
 &lt;li&gt;The upload dates extracted from YouTube are in UTC.&lt;/li&gt; 
 &lt;li&gt;If &lt;code&gt;ffmpeg&lt;/code&gt; is used as the downloader, the downloading and merging of formats happen in a single step when possible. Use &lt;code&gt;--compat-options no-direct-merge&lt;/code&gt; to revert this&lt;/li&gt; 
 &lt;li&gt;Thumbnail embedding in &lt;code&gt;mp4&lt;/code&gt; is done with mutagen if possible. Use &lt;code&gt;--compat-options embed-thumbnail-atomicparsley&lt;/code&gt; to force the use of AtomicParsley instead&lt;/li&gt; 
 &lt;li&gt;Some internal metadata such as filenames are removed by default from the infojson. Use &lt;code&gt;--no-clean-infojson&lt;/code&gt; or &lt;code&gt;--compat-options no-clean-infojson&lt;/code&gt; to revert this&lt;/li&gt; 
 &lt;li&gt;When &lt;code&gt;--embed-subs&lt;/code&gt; and &lt;code&gt;--write-subs&lt;/code&gt; are used together, the subtitles are written to disk and also embedded in the media file. You can use just &lt;code&gt;--embed-subs&lt;/code&gt; to embed the subs and automatically delete the separate file. See &lt;a href="https://github.com/yt-dlp/yt-dlp/issues/630#issuecomment-893659460"&gt;#630 (comment)&lt;/a&gt; for more info. &lt;code&gt;--compat-options no-keep-subs&lt;/code&gt; can be used to revert this&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;certifi&lt;/code&gt; will be used for SSL root certificates, if installed. If you want to use system certificates (e.g. self-signed), use &lt;code&gt;--compat-options no-certifi&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;yt-dlp's sanitization of invalid characters in filenames is different/smarter than in youtube-dl. You can use &lt;code&gt;--compat-options filename-sanitization&lt;/code&gt; to revert to youtube-dl's behavior&lt;/li&gt; 
 &lt;li&gt;&lt;del&gt;yt-dlp tries to parse the external downloader outputs into the standard progress output if possible (Currently implemented: &lt;a href="https://github.com/yt-dlp/yt-dlp/issues/5931"&gt;aria2c&lt;/a&gt;). You can use &lt;code&gt;--compat-options no-external-downloader-progress&lt;/code&gt; to get the downloader output as-is&lt;/del&gt;&lt;/li&gt; 
 &lt;li&gt;yt-dlp versions between 2021.09.01 and 2023.01.02 applies &lt;code&gt;--match-filters&lt;/code&gt; to nested playlists. This was an unintentional side-effect of &lt;a href="https://github.com/yt-dlp/yt-dlp/commit/8f18aca8717bb0dd49054555af8d386e5eda3a88"&gt;8f18ac&lt;/a&gt; and is fixed in &lt;a href="https://github.com/yt-dlp/yt-dlp/commit/d7b460d0e5fc710950582baed2e3fc616ed98a80"&gt;d7b460&lt;/a&gt;. Use &lt;code&gt;--compat-options playlist-match-filter&lt;/code&gt; to revert this&lt;/li&gt; 
 &lt;li&gt;yt-dlp versions between 2021.11.10 and 2023.06.21 estimated &lt;code&gt;filesize_approx&lt;/code&gt; values for fragmented/manifest formats. This was added for convenience in &lt;a href="https://github.com/yt-dlp/yt-dlp/commit/f2fe69c7b0d208bdb1f6292b4ae92bc1e1a7444a"&gt;f2fe69&lt;/a&gt;, but was reverted in &lt;a href="https://github.com/yt-dlp/yt-dlp/commit/0dff8e4d1e6e9fb938f4256ea9af7d81f42fd54f"&gt;0dff8e&lt;/a&gt; due to the potentially extreme inaccuracy of the estimated values. Use &lt;code&gt;--compat-options manifest-filesize-approx&lt;/code&gt; to keep extracting the estimated values&lt;/li&gt; 
 &lt;li&gt;yt-dlp uses modern http client backends such as &lt;code&gt;requests&lt;/code&gt;. Use &lt;code&gt;--compat-options prefer-legacy-http-handler&lt;/code&gt; to prefer the legacy http handler (&lt;code&gt;urllib&lt;/code&gt;) to be used for standard http requests.&lt;/li&gt; 
 &lt;li&gt;The sub-modules &lt;code&gt;swfinterp&lt;/code&gt;, &lt;code&gt;casefold&lt;/code&gt; are removed.&lt;/li&gt; 
 &lt;li&gt;Passing &lt;code&gt;--simulate&lt;/code&gt; (or calling &lt;code&gt;extract_info&lt;/code&gt; with &lt;code&gt;download=False&lt;/code&gt;) no longer alters the default format selection. See &lt;a href="https://github.com/yt-dlp/yt-dlp/issues/9843"&gt;#9843&lt;/a&gt; for details.&lt;/li&gt; 
 &lt;li&gt;yt-dlp no longer applies the server modified time to downloaded files by default. Use &lt;code&gt;--mtime&lt;/code&gt; or &lt;code&gt;--compat-options mtime-by-default&lt;/code&gt; to revert this.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For ease of use, a few more compat options are available:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;--compat-options all&lt;/code&gt;: Use all compat options (&lt;strong&gt;Do NOT use this!&lt;/strong&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--compat-options youtube-dl&lt;/code&gt;: Same as &lt;code&gt;--compat-options all,-multistreams,-playlist-match-filter,-manifest-filesize-approx,-allow-unsafe-ext,-prefer-vp9-sort&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--compat-options youtube-dlc&lt;/code&gt;: Same as &lt;code&gt;--compat-options all,-no-live-chat,-no-youtube-channel-redirect,-playlist-match-filter,-manifest-filesize-approx,-allow-unsafe-ext,-prefer-vp9-sort&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--compat-options 2021&lt;/code&gt;: Same as &lt;code&gt;--compat-options 2022,no-certifi,filename-sanitization&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--compat-options 2022&lt;/code&gt;: Same as &lt;code&gt;--compat-options 2023,playlist-match-filter,no-external-downloader-progress,prefer-legacy-http-handler,manifest-filesize-approx&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--compat-options 2023&lt;/code&gt;: Same as &lt;code&gt;--compat-options 2024,prefer-vp9-sort&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--compat-options 2024&lt;/code&gt;: Same as &lt;code&gt;--compat-options mtime-by-default&lt;/code&gt;. Use this to enable all future compat options&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The following compat options restore vulnerable behavior from before security patches:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;--compat-options allow-unsafe-ext&lt;/code&gt;: Allow files with any extension (including unsafe ones) to be downloaded (&lt;a href="https://github.com/yt-dlp/yt-dlp/security/advisories/GHSA-79w7-vh3h-8g4j"&gt;GHSA-79w7-vh3h-8g4j&lt;/a&gt;)&lt;/p&gt; 
  &lt;blockquote&gt; 
   &lt;p&gt;&lt;span&gt;âš &lt;/span&gt; Only use if a valid file download is rejected because its extension is detected as uncommon&lt;/p&gt; 
   &lt;p&gt;&lt;strong&gt;This option can enable remote code execution! Consider &lt;a href="https://github.com/yt-dlp/yt-dlp/issues/new/choose"&gt;opening an issue&lt;/a&gt; instead!&lt;/strong&gt;&lt;/p&gt; 
  &lt;/blockquote&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Deprecated options&lt;/h3&gt; 
&lt;p&gt;These are all the deprecated options and the current alternative to achieve the same effect&lt;/p&gt; 
&lt;h4&gt;Almost redundant options&lt;/h4&gt; 
&lt;p&gt;While these options are almost the same as their new counterparts, there are some differences that prevents them being redundant&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;-j, --dump-json                  --print "%()j"
-F, --list-formats               --print formats_table
--list-thumbnails                --print thumbnails_table --print playlist:thumbnails_table
--list-subs                      --print automatic_captions_table --print subtitles_table
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Redundant options&lt;/h4&gt; 
&lt;p&gt;While these options are redundant, they are still expected to be used due to their ease of use&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;--get-description                --print description
--get-duration                   --print duration_string
--get-filename                   --print filename
--get-format                     --print format
--get-id                         --print id
--get-thumbnail                  --print thumbnail
-e, --get-title                  --print title
-g, --get-url                    --print urls
--match-title REGEX              --match-filters "title ~= (?i)REGEX"
--reject-title REGEX             --match-filters "title !~= (?i)REGEX"
--min-views COUNT                --match-filters "view_count &amp;gt;=? COUNT"
--max-views COUNT                --match-filters "view_count &amp;lt;=? COUNT"
--break-on-reject                Use --break-match-filters
--user-agent UA                  --add-headers "User-Agent:UA"
--referer URL                    --add-headers "Referer:URL"
--playlist-start NUMBER          -I NUMBER:
--playlist-end NUMBER            -I :NUMBER
--playlist-reverse               -I ::-1
--no-playlist-reverse            Default
--no-colors                      --color no_color
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Not recommended&lt;/h4&gt; 
&lt;p&gt;While these options still work, their use is not recommended since there are other alternatives to achieve the same&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;--force-generic-extractor        --ies generic,default
--exec-before-download CMD       --exec "before_dl:CMD"
--no-exec-before-download        --no-exec
--all-formats                    -f all
--all-subs                       --sub-langs all --write-subs
--print-json                     -j --no-simulate
--autonumber-size NUMBER         Use string formatting, e.g. %(autonumber)03d
--autonumber-start NUMBER        Use internal field formatting like %(autonumber+NUMBER)s
--id                             -o "%(id)s.%(ext)s"
--metadata-from-title FORMAT     --parse-metadata "%(title)s:FORMAT"
--hls-prefer-native              --downloader "m3u8:native"
--hls-prefer-ffmpeg              --downloader "m3u8:ffmpeg"
--list-formats-old               --compat-options list-formats (Alias: --no-list-formats-as-table)
--list-formats-as-table          --compat-options -list-formats [Default] (Alias: --no-list-formats-old)
--youtube-skip-dash-manifest     --extractor-args "youtube:skip=dash" (Alias: --no-youtube-include-dash-manifest)
--youtube-skip-hls-manifest      --extractor-args "youtube:skip=hls" (Alias: --no-youtube-include-hls-manifest)
--youtube-include-dash-manifest  Default (Alias: --no-youtube-skip-dash-manifest)
--youtube-include-hls-manifest   Default (Alias: --no-youtube-skip-hls-manifest)
--geo-bypass                     --xff "default"
--no-geo-bypass                  --xff "never"
--geo-bypass-country CODE        --xff CODE
--geo-bypass-ip-block IP_BLOCK   --xff IP_BLOCK
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Developer options&lt;/h4&gt; 
&lt;p&gt;These options are not intended to be used by the end-user&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;--test                           Download only part of video for testing extractors
--load-pages                     Load pages dumped by --write-pages
--youtube-print-sig-code         For testing youtube signatures
--allow-unplayable-formats       List unplayable formats also
--no-allow-unplayable-formats    Default
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Old aliases&lt;/h4&gt; 
&lt;p&gt;These are aliases that are no longer documented for various reasons&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;--avconv-location                --ffmpeg-location
--clean-infojson                 --clean-info-json
--cn-verification-proxy URL      --geo-verification-proxy URL
--dump-headers                   --print-traffic
--dump-intermediate-pages        --dump-pages
--force-write-download-archive   --force-write-archive
--no-clean-infojson              --no-clean-info-json
--no-split-tracks                --no-split-chapters
--no-write-srt                   --no-write-subs
--prefer-unsecure                --prefer-insecure
--rate-limit RATE                --limit-rate RATE
--split-tracks                   --split-chapters
--srt-lang LANGS                 --sub-langs LANGS
--trim-file-names LENGTH         --trim-filenames LENGTH
--write-srt                      --write-subs
--yes-overwrites                 --force-overwrites
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Sponskrub Options&lt;/h4&gt; 
&lt;p&gt;Support for &lt;a href="https://github.com/faissaloo/SponSkrub"&gt;SponSkrub&lt;/a&gt; has been deprecated in favor of the &lt;code&gt;--sponsorblock&lt;/code&gt; options&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;--sponskrub                      --sponsorblock-mark all
--no-sponskrub                   --no-sponsorblock
--sponskrub-cut                  --sponsorblock-remove all
--no-sponskrub-cut               --sponsorblock-remove -all
--sponskrub-force                Not applicable
--no-sponskrub-force             Not applicable
--sponskrub-location             Not applicable
--sponskrub-args                 Not applicable
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;No longer supported&lt;/h4&gt; 
&lt;p&gt;These options may no longer work as intended&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;--prefer-avconv                  avconv is not officially supported by yt-dlp (Alias: --no-prefer-ffmpeg)
--prefer-ffmpeg                  Default (Alias: --no-prefer-avconv)
-C, --call-home                  Not implemented
--no-call-home                   Default
--include-ads                    No longer supported
--no-include-ads                 Default
--write-annotations              No supported site has annotations now
--no-write-annotations           Default
--compat-options seperate-video-versions  No longer needed
--compat-options no-youtube-prefer-utc-upload-date  No longer supported
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Removed&lt;/h4&gt; 
&lt;p&gt;These options were deprecated since 2014 and have now been entirely removed&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;-A, --auto-number                -o "%(autonumber)s-%(id)s.%(ext)s"
-t, -l, --title, --literal       -o "%(title)s-%(id)s.%(ext)s"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;CONTRIBUTING&lt;/h1&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/CONTRIBUTING.md#contributing-to-yt-dlp"&gt;CONTRIBUTING.md&lt;/a&gt; for instructions on &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/CONTRIBUTING.md#opening-an-issue"&gt;Opening an Issue&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/CONTRIBUTING.md#developer-instructions"&gt;Contributing code to the project&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;WIKI&lt;/h1&gt; 
&lt;p&gt;See the &lt;a href="https://github.com/yt-dlp/yt-dlp/wiki"&gt;Wiki&lt;/a&gt; for more information&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>willccbb/verifiers</title>
      <link>https://github.com/willccbb/verifiers</link>
      <description>&lt;p&gt;Verifiers for LLM Reinforcement Learning&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;p align="center"&gt; &lt;/p&gt;
 &lt;h1&gt;Verifiers&lt;/h1&gt; 
 &lt;p&gt;&lt;/p&gt; 
 &lt;p&gt; Environments for LLM Reinforcement Learning &lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;Overview&lt;/h2&gt; 
&lt;p&gt;Verifiers is a library of modular components for creating RL environments and training LLM agents. Verifiers includes an async GRPO implementation built around the &lt;code&gt;transformers&lt;/code&gt; Trainer, is supported by &lt;code&gt;prime-rl&lt;/code&gt; for large-scale FSDP training, and can easily be integrated into any RL framework which exposes an OpenAI-compatible inference client. In addition to RL training, Verifiers can be used directly for building LLM evaluations, creating synthetic data pipelines, and implementing agent harnesses.&lt;/p&gt; 
&lt;p&gt;Full documentation is available &lt;a href="https://verifiers.readthedocs.io/en/latest/"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Setup&lt;/h2&gt; 
&lt;p&gt;We recommend using &lt;code&gt;verifiers&lt;/code&gt; with along &lt;a href="https://docs.astral.sh/uv/getting-started/installation/"&gt;uv&lt;/a&gt; for dependency management in your own project:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -LsSf https://astral.sh/uv/install.sh | sh
uv init # create a fresh project
source .venv/bin/activate
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For local (CPU) development and evaluation with API models, do:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uv add verifiers # uv add 'verifiers[dev]' for Jupyter + testing support
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For training on GPUs with &lt;code&gt;vf.GRPOTrainer&lt;/code&gt;, do:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uv add 'verifiers[all]' &amp;amp;&amp;amp; uv pip install flash-attn --no-build-isolation
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To use the latest &lt;code&gt;main&lt;/code&gt; branch, do:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uv add verifiers @ git+https://github.com/willccbb/verifiers.git
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To use with &lt;code&gt;prime-rl&lt;/code&gt;, see &lt;a href="https://github.com/PrimeIntellect-ai/prime-rl"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;To install &lt;code&gt;verifiers&lt;/code&gt; from source for core library development, do:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/willccbb/verifiers.git
cd verifiers
uv sync --all-extras &amp;amp;&amp;amp; uv pip install flash-attn --no-build-isolation
uv run pre-commit install
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;In general, we recommend that you build and train Environments &lt;em&gt;with&lt;/em&gt; &lt;code&gt;verifiers&lt;/code&gt;, not &lt;em&gt;in&lt;/em&gt; &lt;code&gt;verifiers&lt;/code&gt;. If you find yourself needing to clone and modify the core library in order to implement key functionality for your project, we'd love for you to open an issue so that we can try and streamline the development experience. Our aim is for &lt;code&gt;verifiers&lt;/code&gt; to be a reliable toolkit to build on top of, and to minimize the "fork proliferation" which often pervades the RL infrastructure ecosystem.&lt;/p&gt; 
&lt;h2&gt;Environments&lt;/h2&gt; 
&lt;p&gt;Environments in Verifiers are installable Python modules which can specify dependencies in a &lt;code&gt;pyproject.toml&lt;/code&gt;, and which expose a &lt;code&gt;load_environment&lt;/code&gt; function for instantiation by downstream applications (e.g. trainers). See &lt;code&gt;environments/&lt;/code&gt; for examples.&lt;/p&gt; 
&lt;p&gt;To initialize a blank Environment module template, do:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;vf-init vf-environment-name # -p /path/to/environments (defaults to "./environments")
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To an install an Environment module into your project, do:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;vf-install vf-environment-name # -p /path/to/environments (defaults to "./environments") 
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To install an Environment module from this repo's &lt;code&gt;environments&lt;/code&gt; folder, do:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;vf-install vf-math-python --from-repo # -b branch_or_commit (defaults to "main")
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Once an Environment module is installed, you can create an instance of the Environment using &lt;code&gt;load_environment&lt;/code&gt;, passing any necessary args:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import verifiers as vf
vf_env = vf.load_environment("vf-environment-name", **env_args)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To run a quick evaluation of your Environment with an API-based model, do:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;vf-eval vf-environment-name # vf-eval -h for config options; defaults to gpt-4.1-mini, 5 prompts, 3 rollouts for each
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The core elements of Environments in are:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Datasets: a Hugging Face &lt;code&gt;Dataset&lt;/code&gt; with a &lt;code&gt;prompt&lt;/code&gt; column for inputs, and either &lt;code&gt;answer (str)&lt;/code&gt; or &lt;code&gt;info (dict)&lt;/code&gt; columns for evaluation&lt;/li&gt; 
 &lt;li&gt;Rollout logic: interactions between models and the environment (e.g. &lt;code&gt;env_response&lt;/code&gt; + &lt;code&gt;is_completed&lt;/code&gt; for any &lt;code&gt;MultiTurnEnv&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;Rubrics: an encapsulation for one or more reward functions&lt;/li&gt; 
 &lt;li&gt;Parsers: optional; an encapsulation for reusable parsing logic&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;We support both &lt;code&gt;/v1/chat/completions&lt;/code&gt;-style and &lt;code&gt;/v1/completions&lt;/code&gt;-style inference via OpenAI clients, though we generally recommend &lt;code&gt;/v1/chat/completions&lt;/code&gt;-style inference for the vast majority of applications. Both the included &lt;code&gt;GRPOTrainer&lt;/code&gt; as well as &lt;code&gt;prime-rl&lt;/code&gt; support the full set of &lt;a href="https://docs.vllm.ai/en/v0.6.0/dev/sampling_params.html"&gt;SamplingParams&lt;/a&gt; exposed by vLLM (via their OpenAI-compatible &lt;a href="https://docs.vllm.ai/en/latest/serving/openai_compatible_server.html"&gt;server&lt;/a&gt; interface), and leveraging this will often be the appropriate way to implement rollout strategies requiring finer-grained control, such as interrupting and resuming generations for interleaved tool use, or enforcing reasoning budgets.&lt;/p&gt; 
&lt;p&gt;The primary constraint we impose on rollout logic is that token sequences must be &lt;em&gt;increasing&lt;/em&gt;, i.e. once a token has been added to a model's context in a rollout, it must remain as the rollout progresses. Note that this causes issues with some popular reasoning models such as the Qwen3 and DeepSeek-R1-Distill series; see &lt;a href="https://raw.githubusercontent.com/willccbb/verifiers/main/#footguns"&gt;Footguns&lt;/a&gt; for guidance on adapting these models to support multi-turn rollouts.&lt;/p&gt; 
&lt;h3&gt;SingleTurnEnv&lt;/h3&gt; 
&lt;p&gt;For tasks requiring only a single response from a model for each prompt, you can use &lt;code&gt;SingleTurnEnv&lt;/code&gt; directly by specifying a Dataset and a Rubric. Rubrics are sets of reward functions, which can be either sync or async.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from datasets import load_dataset
import verifiers as vf

dataset = load_dataset("my-account/my-dataset", split="train")

def reward_A(prompt, completion, info) -&amp;gt; float:
	# reward fn, e.g. correctness
	...

def reward_B(parser, completion) -&amp;gt; float:
	# auxiliary reward fn, e.g. format
	...

async def metric(completion) -&amp;gt; float:
	# non-reward metric, e.g. proper noun count
	...

rubric = vf.Rubric(funcs=[reward_A, reward_B, metric], weights=[1.0, 0.5, 0.0])

vf_env = SingleTurnEnv(
	dataset=dataset,
	rubric=rubric
)
results = vf_env.evaluate(client=OpenAI(), model="gpt-4.1-mini", num_examples=100, rollouts_per_example=1)
vf_env.make_dataset(results) # HF dataset format
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Datasets should be formatted with columns for:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;'prompt' (List[ChatMessage])&lt;/code&gt; OR &lt;code&gt;'question' (str)&lt;/code&gt; fields 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;ChatMessage&lt;/code&gt; = e.g. &lt;code&gt;{'role': 'user', 'content': '...'}&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;if &lt;code&gt;question&lt;/code&gt; is set instead of &lt;code&gt;prompt&lt;/code&gt;, you can also pass &lt;code&gt;system_prompt (str)&lt;/code&gt; and/or &lt;code&gt;few_shot (List[ChatMessage])&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;answer (str)&lt;/code&gt; AND/OR &lt;code&gt;info (dict)&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;task (str)&lt;/code&gt;: optional, used by &lt;code&gt;EnvGroup&lt;/code&gt; and &lt;code&gt;RubricGroup&lt;/code&gt; for orchestrating composition of Environments and Rubrics&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The following named attributes available for use by reward functions in your Rubric:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;prompt&lt;/code&gt;: sequence of input messages&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;completion&lt;/code&gt;: sequence of messages generated during rollout by model and Environment&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;answer&lt;/code&gt;: primary answer column, optional if &lt;code&gt;info&lt;/code&gt; is used&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;state&lt;/code&gt;: can be modified during rollout to accumulate any metadata (&lt;code&gt;state['responses']&lt;/code&gt; includes full OpenAI response objects by default)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;info&lt;/code&gt;: auxiliary info needed for reward computation (e.g. test cases), optional if &lt;code&gt;answer&lt;/code&gt; is used&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;task&lt;/code&gt;: tag for task type (used by &lt;code&gt;EnvGroup&lt;/code&gt; and &lt;code&gt;RubricGroup&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;parser&lt;/code&gt;: the parser object declared. Note: &lt;code&gt;vf.Parser().get_format_reward_func()&lt;/code&gt; is a no-op (always 1.0); use &lt;code&gt;vf.ThinkParser&lt;/code&gt; or a custom parser if you want a real format adherence reward.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For tasks involving LLM judges, you may wish to use &lt;code&gt;vf.JudgeRubric()&lt;/code&gt; for managing requests to auxiliary models.&lt;/p&gt; 
&lt;p&gt;Note on concurrency: environment APIs accept &lt;code&gt;max_concurrent&lt;/code&gt; to control parallel rollouts. The &lt;code&gt;vf-eval&lt;/code&gt; CLI currently exposes &lt;code&gt;--max-concurrent-requests&lt;/code&gt;; ensure this maps to your environmentâ€™s concurrency as expected.&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;vf-eval&lt;/code&gt; also supports specifying &lt;code&gt;sampling_args&lt;/code&gt; as a JSON object, which is sent to the vLLM inference engine:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;vf-eval vf-environment-name --sampling-args '{"reasoning_effort": "low"}'
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Use &lt;code&gt;vf-eval -s&lt;/code&gt; to save outputs as dataset-formatted JSON, and view all locally-saved eval results with &lt;code&gt;vf-tui&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;ToolEnv&lt;/h3&gt; 
&lt;p&gt;For many applications involving tool use, you can use &lt;code&gt;ToolEnv&lt;/code&gt; to leverage models' native tool/function-calling capabilities in an agentic loop. Tools can be specified as generic Python functions (with type hints and docstrings), which will then be passed in JSON schema form to each inference request.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import verifiers as vf
vf_env = vf.ToolEnv(
	dataset= ... # HF Dataset with 'prompt'/'question' + 'answer'/'info' columns
	rubric= ... # Rubric object; vf.ToolRubric() can be optionally used for counting tool invocations in each rollout
	tools=[search_tool, read_article_tool, python_tool], # python functions with type hints + docstrings
	max_turns=10
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;In cases where your tools require heavy computational resources, we recommend hosting your tools as standalone servers (e.g. MCP servers) and creating lightweight wrapper functions to pass to &lt;code&gt;ToolEnv&lt;/code&gt;. Parallel tool call support is enabled by default.&lt;/p&gt; 
&lt;p&gt;For training, or self-hosted endpoints, you'll want to enable auto tool choice in &lt;a href="https://docs.vllm.ai/en/stable/features/tool_calling.html#automatic-function-calling"&gt;vLLM&lt;/a&gt; with the appropriate parser. If your model does not support native tool calling, you may find the &lt;code&gt;XMLParser&lt;/code&gt; abstraction useful for rolling your own tool call parsing on top of &lt;code&gt;MultiTurnEnv&lt;/code&gt;; see &lt;code&gt;environments/xml_tool_env&lt;/code&gt; for an example.&lt;/p&gt; 
&lt;h3&gt;MultiTurnEnv&lt;/h3&gt; 
&lt;p&gt;Both &lt;code&gt;SingleTurnEnv&lt;/code&gt; and &lt;code&gt;ToolEnv&lt;/code&gt; are instances of &lt;code&gt;MultiTurnEnv&lt;/code&gt;, which exposes an interface for writing custom Environment interaction protocols. The two methods you must override are&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from typing import Tuple
import verifiers as vf
from verifiers.types import Messages, State
class YourMultiTurnEnv(vf.MultiTurnEnv):
    def __init__(self,
                 dataset: Dataset,
                 rubric: Rubric,
				 max_turns: int,
                 **kwargs):
	
  async def is_completed(self, messages: Messages, state: State, **kwargs) -&amp;gt; bool:
    # return whether or not a rollout is completed

  async def env_response(self, messages: Messages, state: State, **kwargs) -&amp;gt; Tuple[Messages, State]:
    # return new environment message(s) + updated state
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If your application requires more fine-grained control than is allowed by &lt;code&gt;MultiTurnEnv&lt;/code&gt;, you may want to inherit from the base &lt;code&gt;Environment&lt;/code&gt; functionality directly and override the &lt;code&gt;rollout&lt;/code&gt; method.&lt;/p&gt; 
&lt;h2&gt;Training&lt;/h2&gt; 
&lt;h3&gt;GRPOTrainer&lt;/h3&gt; 
&lt;p&gt;The included trainer (&lt;code&gt;vf.GRPOTrainer&lt;/code&gt;) supports running GRPO-style RL training via Accelerate/DeepSpeed, and uses vLLM for inference. It supports both full-parameter finetuning, and is optimized for efficiently training dense transformer models on 2-16 GPUs.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# install environment
vf-install vf-wordle (-p /path/to/environments | --from-repo)

# quick eval
vf-eval vf-wordle -m (model_name in configs/endpoints.py) -n NUM_EXAMPLES -r ROLLOUTS_PER_EXAMPLE

# inference (shell 0)
CUDA_VISIBLE_DEVICES=0,1,2,3,4,5 vf-vllm --model willcb/Qwen3-1.7B-Wordle \
    --data-parallel-size 7 --enforce-eager --disable-log-requests

# training (shell 1)
CUDA_VISIBLE_DEVICES=6,7 accelerate launch --num-processes 2 \
    --config-file configs/zero3.yaml examples/grpo/train_wordle.py --size 1.7B
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Alternatively, you can train environments with the external &lt;code&gt;prime-rl&lt;/code&gt; project (FSDP-first orchestration). See the &lt;code&gt;prime-rl&lt;/code&gt; README for installation and examples. For example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# orchestrator config (prime-rl)
[environment]
id = "vf-math-python"  # or your environment ID
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# run (prime-rl)
uv run rl \
  --trainer @ configs/your_exp/train.toml \
  --orchestrator @ configs/your_exp/orch.toml \
  --inference @ configs/your_exp/infer.toml
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Troubleshooting&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Ensure your &lt;code&gt;wandb&lt;/code&gt; and &lt;code&gt;huggingface-cli&lt;/code&gt; logins are set up (or set &lt;code&gt;report_to=None&lt;/code&gt; in &lt;code&gt;training_args&lt;/code&gt;). You should also have something set as your &lt;code&gt;OPENAI_API_KEY&lt;/code&gt; in your environment (can be a dummy key for vLLM).&lt;/li&gt; 
 &lt;li&gt;If using high max concurrency, increase the number of allowed open sockets (e.g. &lt;code&gt;ulimit -n 4096&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;On some setups, inter-GPU communication can &lt;a href="https://github.com/huggingface/trl/issues/2923"&gt;hang&lt;/a&gt; or crash during vLLM weight syncing. This can usually be alleviated by setting (or unsetting) &lt;code&gt;NCCL_P2P_DISABLE=1&lt;/code&gt; in your environment (or potentially &lt;code&gt;NCCL_CUMEM_ENABLE=1&lt;/code&gt;). Try this as your first step if you experience NCCL-related issues.&lt;/li&gt; 
 &lt;li&gt;If problems persist, please open an &lt;a href="https://github.com/willccbb/verifiers/issues"&gt;issue&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Resource Requirements&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;GRPOTrainer&lt;/code&gt; is optimized for setups with at least 2 GPUs, scaling up to multiple nodes. 2-GPU setups with sufficient memory to enable small-scale experimentation can be &lt;a href="https://app.primeintellect.ai/dashboard/create-cluster?image=ubuntu_22_cuda_12"&gt;rented&lt;/a&gt; for &amp;lt;$1/hr.&lt;/p&gt; 
&lt;h3&gt;PRIME-RL&lt;/h3&gt; 
&lt;p&gt;If you do not require LoRA support, you may want to use the &lt;code&gt;prime-rl&lt;/code&gt; trainer, which natively supports Environments created using &lt;code&gt;verifiers&lt;/code&gt;, is more optimized for performance and scalability via FSDP, includes a broader set of configuration options and user experience features, and has more battle-tested defaults. Both trainers support asynchronous rollouts, and use a one-step off-policy delay by default for overlapping training and inference. See the &lt;code&gt;prime-rl&lt;/code&gt; &lt;a href="https://github.com/PrimeIntellect-ai/prime-rl"&gt;docs&lt;/a&gt; for usage instructions.&lt;/p&gt; 
&lt;h2&gt;Further Documentation&lt;/h2&gt; 
&lt;p&gt;See the full &lt;a href="https://verifiers.readthedocs.io/en/latest/"&gt;docs&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;h2&gt;Contributions&lt;/h2&gt; 
&lt;p&gt;Verifiers warmly welcomes community contributions! Please open an issue or PR if you encounter bugs or other pain points during your development, or start a discussion for more open-ended questions.&lt;/p&gt; 
&lt;p&gt;Please note that the core &lt;code&gt;verifiers/&lt;/code&gt; library is intended to be a relatively lightweight set of reusable components rather than an exhaustive catalog of RL environments. For &lt;em&gt;applications&lt;/em&gt; of &lt;code&gt;verifiers&lt;/code&gt; (e.g. "an Environment for XYZ task"), you are welcome to submit a PR for a self-contained module that lives within &lt;code&gt;environments/&lt;/code&gt; if it serves as a canonical example of a new pattern. Stay tuned for more info shortly about our plans for supporting community Environment contributions ğŸ™‚&lt;/p&gt; 
&lt;h2&gt;Citation&lt;/h2&gt; 
&lt;p&gt;If you use this code in your research, please cite:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bibtex"&gt;@misc{brown_verifiers_2025,
  author       = {William&amp;nbsp;Brown},
  title        = {{Verifiers}: Reinforcement Learning with LLMs in Verifiable Environments},
  howpublished = {\url{https://github.com/willccbb/verifiers}},
  note         = {Commit abcdefg â€¢ accessed DDâ€¯Monâ€¯YYYY},
  year         = {2025}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Roadmap&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;A community Environments hub for crowdsourcing, sharing, and discovering new RL environments built with &lt;code&gt;verifiers&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Default patterns for hosted resources such as code sandboxes, auxiliary models, and MCP servers&lt;/li&gt; 
 &lt;li&gt;Multimodal input support&lt;/li&gt; 
 &lt;li&gt;Non-increasing token sequences via REINFORCE&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>oraios/serena</title>
      <link>https://github.com/oraios/serena</link>
      <description>&lt;p&gt;A powerful coding agent toolkit providing semantic retrieval and editing capabilities (MCP server &amp; Agno integration)&lt;/p&gt;&lt;hr&gt;&lt;p align="center" style="text-align:center"&gt; &lt;img src="https://raw.githubusercontent.com/oraios/serena/main/resources/serena-logo.svg#gh-light-mode-only" style="width:500px" /&gt; &lt;img src="https://raw.githubusercontent.com/oraios/serena/main/resources/serena-logo-dark-mode.svg#gh-dark-mode-only" style="width:500px" /&gt; &lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span&gt;ğŸš€&lt;/span&gt; Serena is a powerful &lt;strong&gt;coding agent toolkit&lt;/strong&gt; capable of turning an LLM into a fully-featured agent that works &lt;strong&gt;directly on your codebase&lt;/strong&gt;. Unlike most other tools, it is not tied to an LLM, framework or an interface, making it easy to use it in a variety of ways.&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;ğŸ”§&lt;/span&gt; Serena provides essential &lt;strong&gt;semantic code retrieval and editing tools&lt;/strong&gt; that are akin to an IDE's capabilities, extracting code entities at the symbol level and exploiting relational structure. When combined with an existing coding agent, these tools greatly enhance (token) efficiency.&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;ğŸ†“&lt;/span&gt; Serena is &lt;strong&gt;free &amp;amp; open-source&lt;/strong&gt;, enhancing the capabilities of LLMs you already have access to free of charge.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;You can think of Serena as an IDE for a coding agent. With it, the agent no longer needs to read entire files, perform grep-like searches or string replacements to find and edit the right code. Instead, it can use code centered tools like &lt;code&gt;find_symbol&lt;/code&gt;, &lt;code&gt;find_referencing_symbols&lt;/code&gt; and &lt;code&gt;insert_after_symbol&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;Users' Feedback&lt;/h3&gt; 
&lt;p&gt;Most users report that Serena has strong positive effects on the results of their coding agents, even when used within very capable agents like Claude Code. Serena is often described to be a &lt;a href="https://www.reddit.com/r/ClaudeAI/comments/1lfsdll/try_out_serena_mcp_thank_me_later/"&gt;game changer&lt;/a&gt;, or an enormous &lt;a href="https://www.reddit.com/r/ClaudeCode/comments/1mguoia/absolutely_insane_improvement_of_claude_code"&gt;productivity boost&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;However, in very small projects or in tasks that involve only one file (tasks which do not require reading/editing only subsets of files), you may not benefit from including Serena. For example, for creating code from scratch, Serena will not provide much value. You also might want to adjust Serena to your needs and workflows using its extensive configuration options.&lt;/p&gt; 
&lt;p&gt;Several videos and blog posts have been written about Serena by now:&lt;/p&gt; 
&lt;h4&gt;On YouTube&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=wYWyJNs1HVk&amp;amp;t=1s"&gt;AI Labs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=UqfxuQKuMo8&amp;amp;t=45s"&gt;Yo Van Eyck&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=fzPnM3ySmjE&amp;amp;t=32s"&gt;JeredBlu&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;On Blogs&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://medium.com/@souradip1000/deconstructing-serenas-mcp-powered-semantic-code-understanding-architecture-75802515d116"&gt;Serena's Design Principles&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://blog.lai.so/serena/"&gt;Serena with Claude Code (in Japanese)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://robertmarshall.dev/blog/turning-claude-code-into-a-development-powerhouse/"&gt;Turning Claude Code into a Development Powerhouse&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Demonstration 1 - Efficient Operation in Claude Code&lt;/h3&gt; 
&lt;p&gt;A demonstration of Serena efficiently retrieving and editing code within Claude Code, thereby saving tokens and time. Efficient operations are not only useful for saving costs, but also for generally improving the generated code's quality. This effect may be less pronounced in very small projects, but often becomes of crucial importance in larger ones.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/ab78ebe0-f77d-43cc-879a-cc399efefd87"&gt;https://github.com/user-attachments/assets/ab78ebe0-f77d-43cc-879a-cc399efefd87&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Demonstration 2 - Serena in Claude Desktop&lt;/h3&gt; 
&lt;p&gt;A demonstration of Serena implementing a small feature for itself (a better log GUI) with Claude Desktop. Note how Serena's tools enable Claude to find and edit the right symbols.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/6eaa9aa1-610d-4723-a2d6-bf1e487ba753"&gt;https://github.com/user-attachments/assets/6eaa9aa1-610d-4723-a2d6-bf1e487ba753&lt;/a&gt;&lt;/p&gt; 
&lt;p align="center"&gt; &lt;em&gt;Serena is under active development! See the latest updates, upcoming features, and lessons learned to stay up to date.&lt;/em&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://raw.githubusercontent.com/oraios/serena/main/CHANGELOG.md"&gt; &lt;img src="https://img.shields.io/badge/Updates-1e293b?style=flat&amp;amp;logo=rss&amp;amp;logoColor=white&amp;amp;labelColor=1e293b" alt="Changelog" /&gt; &lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/oraios/serena/main/roadmap.md"&gt; &lt;img src="https://img.shields.io/badge/Roadmap-14532d?style=flat&amp;amp;logo=target&amp;amp;logoColor=white&amp;amp;labelColor=14532d" alt="Roadmap" /&gt; &lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/oraios/serena/main/lessons_learned.md"&gt; &lt;img src="https://img.shields.io/badge/Lessons-Learned-7c4700?style=flat&amp;amp;logo=readthedocs&amp;amp;logoColor=white&amp;amp;labelColor=7c4700" alt="Lessons Learned" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;h3&gt;LLM Integration&lt;/h3&gt; 
&lt;p&gt;Serena provides the necessary &lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#list-of-tools"&gt;tools&lt;/a&gt; for coding workflows, but an LLM is required to do the actual work, orchestrating tool use.&lt;/p&gt; 
&lt;p&gt;For example, &lt;strong&gt;supercharge the performance of Claude Code&lt;/strong&gt; with a &lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#claude-code"&gt;one-line shell command&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Serena can be integrated with an LLM in several ways:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;by using the &lt;strong&gt;model context protocol (MCP)&lt;/strong&gt;. Serena provides an MCP server which integrates with 
  &lt;ul&gt; 
   &lt;li&gt;Claude Code and Claude Desktop,&lt;/li&gt; 
   &lt;li&gt;Terminal-based clients like Codex, Gemini-CLI, Qwen3-Coder, rovodev, OpenHands CLI and others,&lt;/li&gt; 
   &lt;li&gt;IDEs like VSCode, Cursor or IntelliJ,&lt;/li&gt; 
   &lt;li&gt;Extensions like Cline or Roo Code&lt;/li&gt; 
   &lt;li&gt;Local clients like &lt;a href="https://docs.openwebui.com/openapi-servers/mcp"&gt;OpenWebUI&lt;/a&gt;, &lt;a href="https://jan.ai/docs/mcp-examples/browser/browserbase#enable-mcp"&gt;Jan&lt;/a&gt;, &lt;a href="https://docs.agno.com/introduction/playground"&gt;Agno&lt;/a&gt; and others&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;by using &lt;a href="https://raw.githubusercontent.com/oraios/serena/main/docs/serena_on_chatgpt.md"&gt;mcpo to connect it to ChatGPT&lt;/a&gt; or other clients that don't support MCP but do support tool calling.&lt;/li&gt; 
 &lt;li&gt;by incorporating Serena's tools into an agent framework of your choice, as illustrated &lt;a href="https://raw.githubusercontent.com/oraios/serena/main/docs/custom_agent.md"&gt;here&lt;/a&gt;. Serena's tool implementation is decoupled from the framework-specific code and can thus easily be adapted to any agent framework.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Programming Language Support &amp;amp; Semantic Analysis Capabilities&lt;/h3&gt; 
&lt;p&gt;Serena's semantic code analysis capabilities build on &lt;strong&gt;language servers&lt;/strong&gt; using the widely implemented language server protocol (LSP). The LSP provides a set of versatile code querying and editing functionalities based on symbolic understanding of the code. Equipped with these capabilities, Serena discovers and edits code just like a seasoned developer making use of an IDE's capabilities would. Serena can efficiently find the right context and do the right thing even in very large and complex projects! So not only is it free and open-source, it frequently achieves better results than existing solutions that charge a premium.&lt;/p&gt; 
&lt;p&gt;Language servers provide support for a wide range of programming languages. With Serena, we provide direct, out-of-the-box support for:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Python&lt;/li&gt; 
 &lt;li&gt;TypeScript/Javascript&lt;/li&gt; 
 &lt;li&gt;PHP (uses Intelephense LSP; set &lt;code&gt;INTELEPHENSE_LICENSE_KEY&lt;/code&gt; environment variable for premium features)&lt;/li&gt; 
 &lt;li&gt;Go (requires installation of gopls)&lt;/li&gt; 
 &lt;li&gt;Rust (requires &lt;a href="https://rustup.rs/"&gt;rustup&lt;/a&gt; - uses rust-analyzer from your toolchain)&lt;/li&gt; 
 &lt;li&gt;C/C++ (you may experience issues with finding references, we are working on it)&lt;/li&gt; 
 &lt;li&gt;Zig (requires installation of ZLS - Zig Language Server)&lt;/li&gt; 
 &lt;li&gt;C#&lt;/li&gt; 
 &lt;li&gt;Ruby (by default, uses &lt;a href="https://github.com/Shopify/ruby-lsp"&gt;ruby-lsp&lt;/a&gt;, specify ruby_solargraph as your language to use the previous solargraph based implementation)&lt;/li&gt; 
 &lt;li&gt;Swift&lt;/li&gt; 
 &lt;li&gt;Kotlin (uses the pre-alpha &lt;a href="https://github.com/Kotlin/kotlin-lsp"&gt;official kotlin LS&lt;/a&gt;, some issues may appear)&lt;/li&gt; 
 &lt;li&gt;Java (&lt;em&gt;Note&lt;/em&gt;: startup is slow, initial startup especially so. There may be issues with java on macos and linux, we are working on it.)&lt;/li&gt; 
 &lt;li&gt;Clojure&lt;/li&gt; 
 &lt;li&gt;Dart&lt;/li&gt; 
 &lt;li&gt;Bash&lt;/li&gt; 
 &lt;li&gt;Lua (automatically downloads lua-language-server if not installed)&lt;/li&gt; 
 &lt;li&gt;Nix (requires nixd installation)&lt;/li&gt; 
 &lt;li&gt;Elixir (requires installation of NextLS and Elixir; &lt;strong&gt;Windows not supported&lt;/strong&gt;)&lt;/li&gt; 
 &lt;li&gt;Erlang (requires installation of beam and &lt;a href="https://github.com/erlang-ls/erlang_ls"&gt;erlang_ls&lt;/a&gt;, experimental, might be slow or hang)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Support for further languages can easily be added by providing a shallow adapter for a new language server implementation, see Serena's &lt;a href="https://raw.githubusercontent.com/oraios/serena/main/.serena/memories/adding_new_language_support_guide.md"&gt;memory on that&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Table of Contents&lt;/h2&gt; 
&lt;!-- Created with markdown-toc -i README.md --&gt; 
&lt;!-- Install it with npm install -g markdown-toc --&gt; 
&lt;!-- toc --&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#quick-start"&gt;Quick Start&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#running-the-serena-mcp-server"&gt;Running the Serena MCP Server&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#usage"&gt;Usage&lt;/a&gt; 
      &lt;ul&gt; 
       &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#using-uvx"&gt;Using uvx&lt;/a&gt; 
        &lt;ul&gt; 
         &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#local-installation"&gt;Local Installation&lt;/a&gt;&lt;/li&gt; 
        &lt;/ul&gt; &lt;/li&gt; 
       &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#using-docker-experimental"&gt;Using Docker (Experimental)&lt;/a&gt;&lt;/li&gt; 
      &lt;/ul&gt; &lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#sse-mode"&gt;SSE Mode&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#command-line-arguments"&gt;Command-Line Arguments&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#configuration"&gt;Configuration&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#project-activation--indexing"&gt;Project Activation &amp;amp; Indexing&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#claude-code"&gt;Claude Code&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#codex"&gt;Codex&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#other-terminal-based-clients"&gt;Other Terminal-Based Clients&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#claude-desktop"&gt;Claude Desktop&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#mcp-coding-clients-cline-roo-code-cursor-windsurf-etc"&gt;MCP Coding Clients (Cline, Roo-Code, Cursor, Windsurf, etc.)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#local-guis-and-frameworks"&gt;Local GUIs and Frameworks&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#detailed-usage-and-recommendations"&gt;Detailed Usage and Recommendations&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#tool-execution"&gt;Tool Execution&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#shell-execution-and-editing-tools"&gt;Shell Execution and Editing Tools&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#modes-and-contexts"&gt;Modes and Contexts&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#contexts"&gt;Contexts&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#modes"&gt;Modes&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#customization"&gt;Customization&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#onboarding-and-memories"&gt;Onboarding and Memories&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#prepare-your-project"&gt;Prepare Your Project&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#structure-your-codebase"&gt;Structure Your Codebase&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#start-from-a-clean-state"&gt;Start from a Clean State&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#logging-linting-and-automated-tests"&gt;Logging, Linting, and Automated Tests&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#prompting-strategies"&gt;Prompting Strategies&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#potential-issues-in-code-editing"&gt;Potential Issues in Code Editing&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#running-out-of-context"&gt;Running Out of Context&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#combining-serena-with-other-mcp-servers"&gt;Combining Serena with Other MCP Servers&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#serenas-logs-the-dashboard-and-gui-tool"&gt;Serena's Logs: The Dashboard and GUI Tool&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#troubleshooting"&gt;Troubleshooting&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#comparison-with-other-coding-agents"&gt;Comparison with Other Coding Agents&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#subscription-based-coding-agents"&gt;Subscription-Based Coding Agents&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#api-based-coding-agents"&gt;API-Based Coding Agents&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#other-mcp-based-coding-agents"&gt;Other MCP-Based Coding Agents&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#acknowledgements"&gt;Acknowledgements&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#customizing-and-extending-serena"&gt;Customizing and Extending Serena&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#list-of-tools"&gt;List of Tools&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;!-- tocstop --&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;p&gt;Serena can be used in various ways, below you will find instructions for selected integrations.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;For coding with Claude, we recommend using Serena through &lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#claude-code"&gt;Claude Code&lt;/a&gt; or &lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#claude-desktop"&gt;Claude Desktop&lt;/a&gt;. You can also use Serena in most other &lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#other-terminal-based-clients"&gt;terminal-based clients&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;If you want a GUI experience outside an IDE, you can use one of the many &lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#local-guis-and-frameworks"&gt;local GUIs&lt;/a&gt; that support MCP servers. You can also connect Serena to many web clients (including ChatGPT) using &lt;a href="https://raw.githubusercontent.com/oraios/serena/main/docs/serena_on_chatgpt.md"&gt;mcpo&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;If you want to use Serena integrated in your IDE, see the section on &lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#other-mcp-clients---cline-roo-code-cursor-windsurf-etc"&gt;other MCP clients&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;You can use Serena as a library for building your own applications. We try to keep the public API stable, but you should still expect breaking changes and pin Serena to a fixed version if you use it as a dependency.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Serena is managed by &lt;code&gt;uv&lt;/code&gt;, so you will need to &lt;a href="https://docs.astral.sh/uv/getting-started/installation/"&gt;install it&lt;/a&gt;).&lt;/p&gt; 
&lt;h3&gt;Running the Serena MCP Server&lt;/h3&gt; 
&lt;p&gt;You have several options for running the MCP server, which are explained in the subsections below.&lt;/p&gt; 
&lt;h4&gt;Usage&lt;/h4&gt; 
&lt;p&gt;The typical usage involves the client (Claude Code, Claude Desktop, etc.) running the MCP server as a subprocess (using stdio communication), so the client needs to be provided with the command to run the MCP server. (Alternatively, you can run the MCP server in SSE mode and tell your client how to connect to it.)&lt;/p&gt; 
&lt;p&gt;Note that no matter how you run the MCP server, Serena will, by default, start a small web-based dashboard on localhost that will display logs and allow shutting down the MCP server (since many clients fail to clean up processes correctly). This and other settings can be adjusted in the &lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#configuration"&gt;configuration&lt;/a&gt; and/or by providing &lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#command-line-arguments"&gt;command-line arguments&lt;/a&gt;.&lt;/p&gt; 
&lt;h5&gt;Using uvx&lt;/h5&gt; 
&lt;p&gt;&lt;code&gt;uvx&lt;/code&gt; can be used to run the latest version of Serena directly from the repository, without an explicit local installation.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;uvx --from git+https://github.com/oraios/serena serena start-mcp-server
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Explore the CLI to see some of the customization options that serena provides (more info on them below).&lt;/p&gt; 
&lt;h6&gt;Local Installation&lt;/h6&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Clone the repository and change into it.&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;git clone https://github.com/oraios/serena
cd serena
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Optionally edit the configuration file in your home directory with&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;uv run serena config edit
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;If you just want the default config, you can skip this part, and a config file will be created when you first run Serena.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Run the server with &lt;code&gt;uv&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;uv run serena start-mcp-server
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;When running from outside the serena installation directory, be sure to pass it, i.e., use&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt; uv run --directory /abs/path/to/serena serena start-mcp-server
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h5&gt;Using Docker (Experimental)&lt;/h5&gt; 
&lt;p&gt;âš ï¸ Docker support is currently experimental with several limitations. Please read the &lt;a href="https://raw.githubusercontent.com/oraios/serena/main/DOCKER.md"&gt;Docker documentation&lt;/a&gt; for important caveats before using it.&lt;/p&gt; 
&lt;p&gt;You can run the Serena MCP server directly via docker as follows, assuming that the projects you want to work on are all located in &lt;code&gt;/path/to/your/projects&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;docker run --rm -i --network host -v /path/to/your/projects:/workspaces/projects ghcr.io/oraios/serena:latest serena start-mcp-server --transport stdio
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Replace &lt;code&gt;/path/to/your/projects&lt;/code&gt; with the absolute path to your projects directory. The Docker approach provides:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Better security isolation for shell command execution&lt;/li&gt; 
 &lt;li&gt;No need to install language servers and dependencies locally&lt;/li&gt; 
 &lt;li&gt;Consistent environment across different systems&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Alternatively, use docker compose with the &lt;code&gt;compose.yml&lt;/code&gt; file provided in the repository.&lt;/p&gt; 
&lt;p&gt;See the &lt;a href="https://raw.githubusercontent.com/oraios/serena/main/DOCKER.md"&gt;Docker documentation&lt;/a&gt; for detailed setup instructions, configuration options, and known limitations.&lt;/p&gt; 
&lt;h5&gt;Using Nix&lt;/h5&gt; 
&lt;p&gt;If you are using Nix and &lt;a href="https://nixos.wiki/wiki/flakes"&gt;have enabled the &lt;code&gt;nix-command&lt;/code&gt; and &lt;code&gt;flakes&lt;/code&gt; features&lt;/a&gt;, you can run Serena using the following command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;nix run github:oraios/serena -- start-mcp-server --transport stdio
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can also install Serena by referencing this repo (&lt;code&gt;github:oraios/serena&lt;/code&gt;) and using it in your Nix flake. The package is exported as &lt;code&gt;serena&lt;/code&gt;.&lt;/p&gt; 
&lt;h4&gt;SSE Mode&lt;/h4&gt; 
&lt;p&gt;â„¹ï¸ Note that MCP servers which use stdio as a protocol are somewhat unusual as far as client/server architectures go, as the server necessarily has to be started by the client in order for communication to take place via the server's standard input/output stream. In other words, you do not need to start the server yourself. The client application (e.g. Claude Desktop) takes care of this and therefore needs to be configured with a launch command.&lt;/p&gt; 
&lt;p&gt;When using instead the SSE mode, which uses HTTP-based communication, you control the server lifecycle yourself, i.e. you start the server and provide the client with the URL to connect to it.&lt;/p&gt; 
&lt;p&gt;Simply provide &lt;code&gt;start-mcp-server&lt;/code&gt; with the &lt;code&gt;--transport sse&lt;/code&gt; option and optionally provide the port. For example, to run the Serena MCP server in SSE mode on port 9121 using a local installation, you would run this command from the Serena directory,&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;uv run serena start-mcp-server --transport sse --port 9121
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;and then configure your client to connect to &lt;code&gt;http://localhost:9121/sse&lt;/code&gt;.&lt;/p&gt; 
&lt;h4&gt;Command-Line Arguments&lt;/h4&gt; 
&lt;p&gt;The Serena MCP server supports a wide range of additional command-line options, including the option to run in SSE mode and to adapt Serena to various &lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#modes-and-contexts"&gt;contexts and modes of operation&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Run with parameter &lt;code&gt;--help&lt;/code&gt; to get a list of available options.&lt;/p&gt; 
&lt;h3&gt;Configuration&lt;/h3&gt; 
&lt;p&gt;Serena is very flexible in terms of configuration. While for most users, the default configurations will work, you can fully adjust it to your needs by editing a few yaml files. You can disable tools, change Serena's instructions (what we denote as the &lt;code&gt;system_prompt&lt;/code&gt;), adjust the output of tools that just provide a prompt, and even adjust tool descriptions.&lt;/p&gt; 
&lt;p&gt;Serena is configured in four places:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;The &lt;code&gt;serena_config.yml&lt;/code&gt; for general settings that apply to all clients and projects. It is located in your user directory under &lt;code&gt;.serena/serena_config.yml&lt;/code&gt;. If you do not explicitly create the file, it will be auto-generated when you first run Serena. You can edit it directly or use&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;uvx --from git+https://github.com/oraios/serena serena config edit
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;(or use the &lt;code&gt;--directory&lt;/code&gt; command version).&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;In the arguments passed to the &lt;code&gt;start-mcp-server&lt;/code&gt; in your client's config (see below), which will apply to all sessions started by the respective client. In particular, the &lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#contexts"&gt;context&lt;/a&gt; parameter should be set appropriately for Serena to be best adjusted to existing tools and capabilities of your client. See for a detailed explanation. You can override all entries from the &lt;code&gt;serena_config.yml&lt;/code&gt; through command line arguments.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;In the &lt;code&gt;.serena/project.yml&lt;/code&gt; file within your project. This will hold project-level configuration that is used whenever that project is activated. This file will be autogenerated when you first use Serena on that project, but you can also generate it explicitly with&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;uvx --from git+https://github.com/oraios/serena serena project generate-yml
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;(or use the &lt;code&gt;--directory&lt;/code&gt; command version).&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Through the context and modes. Explore the &lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#modes-and-contexts"&gt;modes and contexts&lt;/a&gt; section for more details.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;After the initial setup, continue with one of the sections below, depending on how you want to use Serena.&lt;/p&gt; 
&lt;h3&gt;Project Activation &amp;amp; Indexing&lt;/h3&gt; 
&lt;p&gt;If you are mostly working with the same project, you can configure to always activate it at startup by passing &lt;code&gt;--project &amp;lt;path_or_name&amp;gt;&lt;/code&gt; to the &lt;code&gt;start-mcp-server&lt;/code&gt; command in your client's MCP config. This is especially useful for clients which configure MCP servers on a per-project basis, like Claude Code.&lt;/p&gt; 
&lt;p&gt;Otherwise, the recommended way is to just ask the LLM to activate a project by providing it an absolute path to, or, in case the project was activated in the past, by its name. The default project name is the directory name.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;"Activate the project /path/to/my_project"&lt;/li&gt; 
 &lt;li&gt;"Activate the project my_project"&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;All projects that have been activated will be automatically added to your &lt;code&gt;serena_config.yml&lt;/code&gt;, and for each project, the file &lt;code&gt;.serena/project.yml&lt;/code&gt; will be generated. You can adjust the latter, e.g., by changing the name (which you refer to during the activation) or other options. Make sure to not have two different projects with the same name.&lt;/p&gt; 
&lt;p&gt;â„¹ï¸ For larger projects, we recommend that you index your project to accelerate Serena's tools; otherwise the first tool application may be very slow. To do so, run this from the project directory (or pass the path to the project as an argument):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;uvx --from git+https://github.com/oraios/serena serena project index
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;(or use the &lt;code&gt;--directory&lt;/code&gt; command version).&lt;/p&gt; 
&lt;h3&gt;Claude Code&lt;/h3&gt; 
&lt;p&gt;Serena is a great way to make Claude Code both cheaper and more powerful!&lt;/p&gt; 
&lt;p&gt;From your project directory, add serena with a command like this,&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;claude mcp add serena -- &amp;lt;serena-mcp-server&amp;gt; --context ide-assistant --project $(pwd)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;where &lt;code&gt;&amp;lt;serena-mcp-server&amp;gt;&lt;/code&gt; is your way of &lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#running-the-serena-mcp-server"&gt;running the Serena MCP server&lt;/a&gt;. For example, when using &lt;code&gt;uvx&lt;/code&gt;, you would run&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;claude mcp add serena -- uvx --from git+https://github.com/oraios/serena serena start-mcp-server --context ide-assistant --project $(pwd)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;â„¹ï¸ Serena comes with an instruction text, and Claude needs to read it to properly use Serena's tools. As of version &lt;code&gt;v1.0.52&lt;/code&gt;, claude code reads the instructions of the MCP server, so this &lt;strong&gt;is handled automatically&lt;/strong&gt;. If you are using an older version, or if Claude fails to read the instructions, you can ask it explicitly to "read Serena's initial instructions" or run &lt;code&gt;/mcp__serena__initial_instructions&lt;/code&gt; to load the instruction text. If you want to make use of that, you will have to enable the corresponding tool explicitly by adding &lt;code&gt;initial_instructions&lt;/code&gt; to the &lt;code&gt;included_optional_tools&lt;/code&gt; in your config. Note that you may have to make Claude read the instructions when you start a new conversation and after any compacting operation to ensure Claude remains properly configured to use Serena's tools.&lt;/p&gt; 
&lt;h3&gt;Codex&lt;/h3&gt; 
&lt;p&gt;Serena works with OpenAI's Codex CLI out of the box, but you have to use the &lt;code&gt;codex&lt;/code&gt; context for it to work properly. (The technical reason is that Codex doesn't fully support the MCP specifications, so some massaging of tools is required.).&lt;/p&gt; 
&lt;p&gt;Unlike Claude Code, in Codex you add an MCP server globally and not per project. Add the following to &lt;code&gt;~/.codex/config.toml&lt;/code&gt; (create the file if it does not exist):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;[mcp_servers.serena]
command = "uvx"
args = ["--from", "git+https://github.com/oraios/serena", "serena", "start-mcp-server", "--context", "codex"]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;After codex has started, you need to activate the project, which you can do by saying:&lt;/p&gt; 
&lt;p&gt;"Activate the current dir as project using serena"&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;If you don't activate the project, you will not be able to use Serena's tools!&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;That's it! Have a look at &lt;code&gt;~/.codex/log/codex-tui.log&lt;/code&gt; to see if any errors occurred.&lt;/p&gt; 
&lt;p&gt;The Serena dashboard will run if you have not disabled it in the configuration, but due to Codex's sandboxing the webbrowser may not open automatically. You can open it manually by going to &lt;code&gt;http://localhost:24282/dashboard/index.html&lt;/code&gt; (or a higher port, if that was already taken).&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Codex will often show the tools as &lt;code&gt;failed&lt;/code&gt; even though they are successfully executed. This is not a problem, seems to be a bug in Codex. Despite the error message, everything works as expected.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Other Terminal-Based Clients&lt;/h3&gt; 
&lt;p&gt;There are many terminal-based coding assistants that support MCP servers, such as &lt;a href="https://github.com/openai/codex?tab=readme-ov-file#model-context-protocol-mcp"&gt;Codex&lt;/a&gt;, &lt;a href="https://github.com/google-gemini/gemini-cli"&gt;Gemini-CLI&lt;/a&gt;, &lt;a href="https://github.com/QwenLM/Qwen3-Coder"&gt;Qwen3-Coder&lt;/a&gt;, &lt;a href="https://community.atlassian.com/forums/Rovo-for-Software-Teams-Beta/Introducing-Rovo-Dev-CLI-AI-Powered-Development-in-your-terminal/ba-p/3043623"&gt;rovodev&lt;/a&gt;, the &lt;a href="https://docs.all-hands.dev/usage/how-to/cli-mode"&gt;OpenHands CLI&lt;/a&gt; and &lt;a href="https://github.com/sst/opencode"&gt;opencode&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;They generally benefit from the symbolic tools provided by Serena. You might want to customize some aspects of Serena by writing your own context, modes or prompts to adjust it to your workflow, to other MCP servers you are using, and to the client's internal capabilities.&lt;/p&gt; 
&lt;h3&gt;Claude Desktop&lt;/h3&gt; 
&lt;p&gt;For &lt;a href="https://claude.ai/download"&gt;Claude Desktop&lt;/a&gt; (available for Windows and macOS), go to File / Settings / Developer / MCP Servers / Edit Config, which will let you open the JSON file &lt;code&gt;claude_desktop_config.json&lt;/code&gt;. Add the &lt;code&gt;serena&lt;/code&gt; MCP server configuration, using a &lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#running-the-serena-mcp-server"&gt;run command&lt;/a&gt; depending on your setup.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;local installation:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-json"&gt;{
    "mcpServers": {
        "serena": {
            "command": "/abs/path/to/uv",
            "args": ["run", "--directory", "/abs/path/to/serena", "serena", "start-mcp-server"]
        }
    }
}
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;uvx:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-json"&gt;{
    "mcpServers": {
        "serena": {
            "command": "/abs/path/to/uvx",
            "args": ["--from", "git+https://github.com/oraios/serena", "serena", "start-mcp-server"]
        }
    }
}
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;docker:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-json"&gt; {
     "mcpServers": {
         "serena": {
             "command": "docker",
             "args": ["run", "--rm", "-i", "--network", "host", "-v", "/path/to/your/projects:/workspaces/projects", "ghcr.io/oraios/serena:latest", "serena", "start-mcp-server", "--transport", "stdio"]
         }
     }
 }
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;If you are using paths containing backslashes for paths on Windows (note that you can also just use forward slashes), be sure to escape them correctly (&lt;code&gt;\\&lt;/code&gt;).&lt;/p&gt; 
&lt;p&gt;That's it! Save the config and then restart Claude Desktop. You are ready for activating your first project.&lt;/p&gt; 
&lt;p&gt;â„¹ï¸ You can further customize the run command using additional arguments (see &lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#command-line-arguments"&gt;above&lt;/a&gt;).&lt;/p&gt; 
&lt;p&gt;Note: on Windows and macOS there are official Claude Desktop applications by Anthropic, for Linux there is an &lt;a href="https://github.com/aaddrick/claude-desktop-debian"&gt;open-source community version&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;âš ï¸ Be sure to fully quit the Claude Desktop application, as closing Claude will just minimize it to the system tray â€“ at least on Windows.&lt;/p&gt; 
&lt;p&gt;âš ï¸ Some clients may leave behind zombie processes. You will have to find and terminate them manually then. With Serena, you can activate the &lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#serenas-logs-the-dashboard-and-gui-tool"&gt;dashboard&lt;/a&gt; to prevent unnoted processes and also use the dashboard for shutting down Serena.&lt;/p&gt; 
&lt;p&gt;After restarting, you should see Serena's tools in your chat interface (notice the small hammer icon).&lt;/p&gt; 
&lt;p&gt;For more information on MCP servers with Claude Desktop, see &lt;a href="https://modelcontextprotocol.io/quickstart/user"&gt;the official quick start guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;MCP Coding Clients (Cline, Roo-Code, Cursor, Windsurf, etc.)&lt;/h3&gt; 
&lt;p&gt;Being an MCP Server, Serena can be included in any MCP Client. The same configuration as above, perhaps with small client-specific modifications, should work. Most of the popular existing coding assistants (IDE extensions or VSCode-like IDEs) support connections to MCP Servers. It is &lt;strong&gt;recommended to use the &lt;code&gt;ide-assistant&lt;/code&gt; context&lt;/strong&gt; for these integrations by adding &lt;code&gt;"--context", "ide-assistant"&lt;/code&gt; to the &lt;code&gt;args&lt;/code&gt; in your MCP client's configuration. Including Serena generally boosts their performance by providing them tools for symbolic operations.&lt;/p&gt; 
&lt;p&gt;In this case, the billing for the usage continues to be controlled by the client of your choice (unlike with the Claude Desktop client). But you may still want to use Serena through such an approach, e.g., for one of the following reasons:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;You are already using a coding assistant (say Cline or Cursor) and just want to make it more powerful.&lt;/li&gt; 
 &lt;li&gt;You are on Linux and don't want to use the &lt;a href="https://github.com/aaddrick/claude-desktop-debian"&gt;community-created Claude Desktop&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;You want tighter integration of Serena into your IDE and don't mind paying for that.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Local GUIs and Frameworks&lt;/h3&gt; 
&lt;p&gt;Over the last months, several technologies have emerged that allow you to run a powerful local GUI and connect it to an MCP server. They will work with Serena out of the box. Some of the leading open source GUI technologies offering this are &lt;a href="https://jan.ai/docs/mcp"&gt;Jan&lt;/a&gt;, &lt;a href="https://github.com/All-Hands-AI/OpenHands/"&gt;OpenHands&lt;/a&gt;, &lt;a href="https://docs.openwebui.com/openapi-servers/mcp"&gt;OpenWebUI&lt;/a&gt; and &lt;a href="https://docs.agno.com/introduction/playground"&gt;Agno&lt;/a&gt;. They allow combining Serena with almost any LLM (including locally running ones) and offer various other integrations.&lt;/p&gt; 
&lt;h2&gt;Detailed Usage and Recommendations&lt;/h2&gt; 
&lt;h3&gt;Tool Execution&lt;/h3&gt; 
&lt;p&gt;Serena combines tools for semantic code retrieval with editing capabilities and shell execution. Serena's behavior can be further customized through &lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#modes-and-contexts"&gt;Modes and Contexts&lt;/a&gt;. Find the complete list of tools &lt;a href="https://raw.githubusercontent.com/oraios/serena/main/#full-list-of-tools"&gt;below&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;The use of all tools is generally recommended, as this allows Serena to provide the most value: Only by executing shell commands (in particular, tests) can Serena identify and correct mistakes autonomously.&lt;/p&gt; 
&lt;h4&gt;Shell Execution and Editing Tools&lt;/h4&gt; 
&lt;p&gt;However, it should be noted that the &lt;code&gt;execute_shell_command&lt;/code&gt; tool allows for arbitrary code execution. When using Serena as an MCP Server, clients will typically ask the user for permission before executing a tool, so as long as the user inspects execution parameters beforehand, this should not be a problem. However, if you have concerns, you can choose to disable certain commands in your project's .yml configuration file. If you only want to use Serena purely for analyzing code and suggesting implementations without modifying the codebase, you can enable read-only mode by setting &lt;code&gt;read_only: true&lt;/code&gt; in your project configuration file. This will automatically disable all editing tools and prevent any modifications to your codebase while still allowing all analysis and exploration capabilities.&lt;/p&gt; 
&lt;p&gt;In general, be sure to back up your work and use a version control system in order to avoid losing any work.&lt;/p&gt; 
&lt;h3&gt;Modes and Contexts&lt;/h3&gt; 
&lt;p&gt;Serena's behavior and toolset can be adjusted using contexts and modes. These allow for a high degree of customization to best suit your workflow and the environment Serena is operating in.&lt;/p&gt; 
&lt;h4&gt;Contexts&lt;/h4&gt; 
&lt;p&gt;A context defines the general environment in which Serena is operating. It influences the initial system prompt and the set of available tools. A context is set at startup when launching Serena (e.g., via CLI options for an MCP server or in the agent script) and cannot be changed during an active session.&lt;/p&gt; 
&lt;p&gt;Serena comes with pre-defined contexts:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;desktop-app&lt;/code&gt;: Tailored for use with desktop applications like Claude Desktop. This is the default.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;agent&lt;/code&gt;: Designed for scenarios where Serena acts as a more autonomous agent, for example, when used with Agno.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;ide-assistant&lt;/code&gt;: Optimized for integration into IDEs like VSCode, Cursor, or Cline, focusing on in-editor coding assistance. Choose the context that best matches the type of integration you are using.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;When launching Serena, specify the context using &lt;code&gt;--context &amp;lt;context-name&amp;gt;&lt;/code&gt;. Note that for cases where parameter lists are specified (e.g. Claude Desktop), you must add two parameters to the list.&lt;/p&gt; 
&lt;p&gt;If you are using a local server (such as Llama.cpp) which requires you to use OpenAI-compatible tool descriptions, use context &lt;code&gt;oaicompat-agent&lt;/code&gt; instead of &lt;code&gt;agent&lt;/code&gt;.&lt;/p&gt; 
&lt;h4&gt;Modes&lt;/h4&gt; 
&lt;p&gt;Modes further refine Serena's behavior for specific types of tasks or interaction styles. Multiple modes can be active simultaneously, allowing you to combine their effects. Modes influence the system prompt and can also alter the set of available tools by excluding certain ones.&lt;/p&gt; 
&lt;p&gt;Examples of built-in modes include:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;planning&lt;/code&gt;: Focuses Serena on planning and analysis tasks.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;editing&lt;/code&gt;: Optimizes Serena for direct code modification tasks.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;interactive&lt;/code&gt;: Suitable for a conversational, back-and-forth interaction style.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;one-shot&lt;/code&gt;: Configures Serena for tasks that should be completed in a single response, often used with &lt;code&gt;planning&lt;/code&gt; for generating reports or initial plans.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;no-onboarding&lt;/code&gt;: Skips the initial onboarding process if it's not needed for a particular session.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;onboarding&lt;/code&gt;: (Usually triggered automatically) Focuses on the project onboarding process.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Modes can be set at startup (similar to contexts) but can also be &lt;em&gt;switched dynamically&lt;/em&gt; during a session. You can instruct the LLM to use the &lt;code&gt;switch_modes&lt;/code&gt; tool to activate a different set of modes (e.g., "switch to planning and one-shot modes").&lt;/p&gt; 
&lt;p&gt;When launching Serena, specify modes using &lt;code&gt;--mode &amp;lt;mode-name&amp;gt;&lt;/code&gt;; multiple modes can be specified, e.g. &lt;code&gt;--mode planning --mode no-onboarding&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;âš &lt;/span&gt; &lt;strong&gt;Mode Compatibility&lt;/strong&gt;: While you can combine modes, some may be semantically incompatible (e.g., &lt;code&gt;interactive&lt;/code&gt; and &lt;code&gt;one-shot&lt;/code&gt;). Serena currently does not prevent incompatible combinations; it is up to the user to choose sensible mode configurations.&lt;/p&gt; 
&lt;h4&gt;Customization&lt;/h4&gt; 
&lt;p&gt;You can create your own contexts and modes to precisely tailor Serena to your needs in two ways:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;You can use Serena's CLI to manage modes and contexts. Check out&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;uvx --from git+https://github.com/oraios/serena serena mode --help
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;and&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;uvx --from git+https://github.com/oraios/serena serena context --help
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&lt;em&gt;NOTE&lt;/em&gt;: Custom contexts/modes are simply YAML files in &lt;code&gt;&amp;lt;home&amp;gt;/.serena&lt;/code&gt;, they are automatically registered and available for use by their name (filename without the &lt;code&gt;.yml&lt;/code&gt; extension). If you don't want to use Serena's CLI, you can create and manage them in any way you see fit.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Using external YAML files&lt;/strong&gt;: When starting Serena, you can also provide an absolute path to a custom &lt;code&gt;.yml&lt;/code&gt; file for a context or mode.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;This customization allows for deep integration and adaptation of Serena to specific project requirements or personal preferences.&lt;/p&gt; 
&lt;h3&gt;Onboarding and Memories&lt;/h3&gt; 
&lt;p&gt;By default, Serena will perform an &lt;strong&gt;onboarding process&lt;/strong&gt; when it is started for the first time for a project. The goal of the onboarding is for Serena to get familiar with the project and to store memories, which it can then draw upon in future interactions. If an LLM should fail to complete the onboarding and does not actually write the respective memories to disk, you may need to ask it to do so explicitly.&lt;/p&gt; 
&lt;p&gt;The onboarding will usually read a lot of content from the project, thus filling up the context. It can therefore be advisable to switch to another conversation once the onboarding is complete. After the onboarding, we recommend that you have a quick look at the memories and, if necessary, edit them or add additional ones.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Memories&lt;/strong&gt; are files stored in &lt;code&gt;.serena/memories/&lt;/code&gt; in the project directory, which the agent can choose to read in subsequent interactions. Feel free to read and adjust them as needed; you can also add new ones manually. Every file in the &lt;code&gt;.serena/memories/&lt;/code&gt; directory is a memory file. Whenever Serena starts working on a project, the list of memories is provided, and the agent can decide to read them. We found that memories can significantly improve the user experience with Serena.&lt;/p&gt; 
&lt;h3&gt;Prepare Your Project&lt;/h3&gt; 
&lt;h4&gt;Structure Your Codebase&lt;/h4&gt; 
&lt;p&gt;Serena uses the code structure for finding, reading and editing code. This means that it will work well with well-structured code but may perform poorly on fully unstructured one (like a "God class" with enormous, non-modular functions). Furthermore, for languages that are not statically typed, type annotations are highly beneficial.&lt;/p&gt; 
&lt;h4&gt;Start from a Clean State&lt;/h4&gt; 
&lt;p&gt;It is best to start a code generation task from a clean git state. Not only will this make it easier for you to inspect the changes, but also the model itself will have a chance of seeing what it has changed by calling &lt;code&gt;git diff&lt;/code&gt; and thereby correct itself or continue working in a followup conversation if needed.&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;âš &lt;/span&gt; &lt;strong&gt;Important&lt;/strong&gt;: since Serena will write to files using the system-native line endings and it might want to look at the git diff, it is important to set &lt;code&gt;git config core.autocrlf&lt;/code&gt; to &lt;code&gt;true&lt;/code&gt; on Windows. With &lt;code&gt;git config core.autocrlf&lt;/code&gt; set to &lt;code&gt;false&lt;/code&gt; on Windows, you may end up with huge diffs only due to line endings. It is generally a good idea to globally enable this git setting on Windows:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;git config --global core.autocrlf true
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Logging, Linting, and Automated Tests&lt;/h4&gt; 
&lt;p&gt;Serena can successfully complete tasks in an &lt;em&gt;agent loop&lt;/em&gt;, where it iteratively acquires information, performs actions, and reflects on the results. However, Serena cannot use a debugger; it must rely on the results of program executions, linting results, and test results to assess the correctness of its actions. Therefore, software that is designed to meaningful interpretable outputs (e.g. log messages) and that has a good test coverage is much easier to work with for Serena.&lt;/p&gt; 
&lt;p&gt;We generally recommend to start an editing task from a state where all linting checks and tests pass.&lt;/p&gt; 
&lt;h3&gt;Prompting Strategies&lt;/h3&gt; 
&lt;p&gt;We found that it is often a good idea to spend some time conceptualizing and planning a task before actually implementing it, especially for non-trivial task. This helps both in achieving better results and in increasing the feeling of control and staying in the loop. You can make a detailed plan in one session, where Serena may read a lot of your code to build up the context, and then continue with the implementation in another (potentially after creating suitable memories).&lt;/p&gt; 
&lt;h3&gt;Potential Issues in Code Editing&lt;/h3&gt; 
&lt;p&gt;In our experience, LLMs are bad at counting, i.e. they have problems inserting blocks of code in the right place. Most editing operations can be performed at the symbolic level, allowing this problem is overcome. However, sometimes, line-level insertions are useful.&lt;/p&gt; 
&lt;p&gt;Serena is instructed to double-check the line numbers and any code blocks that it will edit, but you may find it useful to explicitly tell it how to edit code if you run into problems. We are working on making Serena's editing capabilities more robust.&lt;/p&gt; 
&lt;h3&gt;Running Out of Context&lt;/h3&gt; 
&lt;p&gt;For long and complicated tasks, or tasks where Serena has read a lot of content, you may come close to the limits of context tokens. In that case, it is often a good idea to continue in a new conversation. Serena has a dedicated tool to create a summary of the current state of the progress and all relevant info for continuing it. You can request to create this summary and write it to a memory. Then, in a new conversation, you can just ask Serena to read the memory and continue with the task. In our experience, this worked really well. On the up-side, since in a single session there is no summarization involved, Serena does not usually get lost (unlike some other agents that summarize under the hood), and it is also instructed to occasionally check whether it's on the right track.&lt;/p&gt; 
&lt;p&gt;Moreover, Serena is instructed to be frugal with context (e.g., to not read bodies of code symbols unnecessarily), but we found that Claude is not always very good in being frugal (Gemini seemed better at it). You can explicitly instruct it to not read the bodies if you know that it's not needed.&lt;/p&gt; 
&lt;h3&gt;Combining Serena with Other MCP Servers&lt;/h3&gt; 
&lt;p&gt;When using Serena through an MCP Client, you can use it together with other MCP servers. However, beware of tool name collisions! See info on that above.&lt;/p&gt; 
&lt;p&gt;Currently, there is a collision with the popular Filesystem MCP Server. Since Serena also provides filesystem operations, there is likely no need to ever enable these two simultaneously.&lt;/p&gt; 
&lt;h3&gt;Serena's Logs: The Dashboard and GUI Tool&lt;/h3&gt; 
&lt;p&gt;Serena provides two convenient ways of accessing the logs of the current session:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;via the &lt;strong&gt;web-based dashboard&lt;/strong&gt; (enabled by default)&lt;/p&gt; &lt;p&gt;This is supported on all platforms. By default, it will be accessible at &lt;code&gt;http://localhost:24282/dashboard/index.html&lt;/code&gt;, but a higher port may be used if the default port is unavailable/multiple instances are running.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;via the &lt;strong&gt;GUI tool&lt;/strong&gt; (disabled by default)&lt;/p&gt; &lt;p&gt;This is mainly supported on Windows, but it may also work on Linux; macOS is unsupported.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Both can be enabled, configured or disabled in Serena's configuration file (&lt;code&gt;serena_config.yml&lt;/code&gt;, see above). If enabled, they will automatically be opened as soon as the Serena agent/MCP server is started. The web dashboard will display usage statistics of Serena's tools if you set &lt;code&gt;record_tool_usage_stats: True&lt;/code&gt; in your config.&lt;/p&gt; 
&lt;p&gt;In addition to viewing logs, both tools allow to shut down the Serena agent. This function is provided, because clients like Claude Desktop may fail to terminate the MCP server subprocess when they themselves are closed.&lt;/p&gt; 
&lt;h3&gt;Troubleshooting&lt;/h3&gt; 
&lt;p&gt;Support for MCP Servers in Claude Desktop and the various MCP Server SDKs are relatively new developments and may display instabilities.&lt;/p&gt; 
&lt;p&gt;The working configuration of an MCP server may vary from platform to platform and from client to client. We recommend always using absolute paths, as relative paths may be sources of errors. The language server is running in a separate sub-process and is called with asyncio â€“ sometimes a client may make it crash. If you have Serena's log window enabled, and it disappears, you'll know what happened.&lt;/p&gt; 
&lt;p&gt;Some clients may not properly terminate MCP servers, look out for hanging python processes and terminate them manually, if needed.&lt;/p&gt; 
&lt;h2&gt;Comparison with Other Coding Agents&lt;/h2&gt; 
&lt;p&gt;To our knowledge, Serena is the first fully-featured coding agent where the entire functionality is available through an MCP server, thus not requiring API keys or subscriptions.&lt;/p&gt; 
&lt;h3&gt;Subscription-Based Coding Agents&lt;/h3&gt; 
&lt;p&gt;Many prominent subscription-based coding agents are parts of IDEs like Windsurf, Cursor and VSCode. Serena's functionality is similar to Cursor's Agent, Windsurf's Cascade or VSCode's agent mode.&lt;/p&gt; 
&lt;p&gt;Serena has the advantage of not requiring a subscription. A potential disadvantage is that it is not directly integrated into an IDE, so the inspection of newly written code is not as seamless.&lt;/p&gt; 
&lt;p&gt;More technical differences are:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Serena is not bound to a specific IDE or CLI. Serena's MCP server can be used with any MCP client (including some IDEs), and the Agno-based agent provides additional ways of applying its functionality.&lt;/li&gt; 
 &lt;li&gt;Serena is not bound to a specific large language model or API.&lt;/li&gt; 
 &lt;li&gt;Serena navigates and edits code using a language server, so it has a symbolic understanding of the code. IDE-based tools often use a RAG-based or purely text-based approach, which is often less powerful, especially for large codebases.&lt;/li&gt; 
 &lt;li&gt;Serena is open-source and has a small codebase, so it can be easily extended and modified.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;API-Based Coding Agents&lt;/h3&gt; 
&lt;p&gt;An alternative to subscription-based agents are API-based agents like Claude Code, Cline, Aider, Roo Code and others, where the usage costs map directly to the API costs of the underlying LLM. Some of them (like Cline) can even be included in IDEs as an extension. They are often very powerful and their main downside are the (potentially very high) API costs.&lt;/p&gt; 
&lt;p&gt;Serena itself can be used as an API-based agent (see the section on Agno above). We have not yet written a CLI tool or a dedicated IDE extension for Serena (and there is probably no need for the latter, as Serena can already be used with any IDE that supports MCP servers). If there is demand for a Serena as a CLI tool like Claude Code, we will consider writing one.&lt;/p&gt; 
&lt;p&gt;The main difference between Serena and other API-based agents is that Serena can also be used as an MCP server, thus not requiring an API key and bypassing the API costs. This is a unique feature of Serena.&lt;/p&gt; 
&lt;h3&gt;Other MCP-Based Coding Agents&lt;/h3&gt; 
&lt;p&gt;There are other MCP servers designed for coding, like &lt;a href="https://github.com/wonderwhy-er/DesktopCommanderMCP"&gt;DesktopCommander&lt;/a&gt; and &lt;a href="https://github.com/ezyang/codemcp"&gt;codemcp&lt;/a&gt;. However, to the best of our knowledge, none of them provide semantic code retrieval and editing tools; they rely purely on text-based analysis. It is the integration of language servers and the MCP that makes Serena unique and so powerful for challenging coding tasks, especially in the context of larger codebases.&lt;/p&gt; 
&lt;h2&gt;Acknowledgements&lt;/h2&gt; 
&lt;p&gt;We built Serena on top of multiple existing open-source technologies, the most important ones being:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;a href="https://github.com/microsoft/multilspy"&gt;multilspy&lt;/a&gt;. A library which wraps language server implementations and adapts them for interaction via Python and which provided the basis for our library Solid-LSP (src/solidlsp). Solid-LSP provides pure synchronous LSP calls and extends the original library with the symbolic logic that Serena required.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/modelcontextprotocol/python-sdk"&gt;Python MCP SDK&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/agno-agi/agno"&gt;Agno&lt;/a&gt; and the associated &lt;a href="https://github.com/agno-agi/agent-ui"&gt;agent-ui&lt;/a&gt;, which we use to allow Serena to work with any model, beyond the ones supporting the MCP.&lt;/li&gt; 
 &lt;li&gt;All the language servers that we use through Solid-LSP.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Without these projects, Serena would not have been possible (or would have been significantly more difficult to build).&lt;/p&gt; 
&lt;h2&gt;Customizing and Extending Serena&lt;/h2&gt; 
&lt;p&gt;It is straightforward to extend Serena's AI functionality with your own ideas. Simply implement a new tool by subclassing &lt;code&gt;serena.agent.Tool&lt;/code&gt; and implement the &lt;code&gt;apply&lt;/code&gt; method with a signature that matches the tool's requirements. Once implemented, &lt;code&gt;SerenaAgent&lt;/code&gt; will automatically have access to the new tool.&lt;/p&gt; 
&lt;p&gt;It is also relatively straightforward to add &lt;a href="https://raw.githubusercontent.com/oraios/serena/main/.serena/memories/adding_new_language_support_guide.md"&gt;support for a new programming language&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;We look forward to seeing what the community will come up with! For details on contributing, see &lt;a href="https://raw.githubusercontent.com/oraios/serena/main/CONTRIBUTING.md"&gt;contributing guidelines&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;List of Tools&lt;/h2&gt; 
&lt;p&gt;Here is the list of Serena's default tools with a short description (output of &lt;code&gt;uv run serena tools list&lt;/code&gt;):&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;activate_project&lt;/code&gt;: Activates a project by name.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;check_onboarding_performed&lt;/code&gt;: Checks whether project onboarding was already performed.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;create_text_file&lt;/code&gt;: Creates/overwrites a file in the project directory.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;delete_memory&lt;/code&gt;: Deletes a memory from Serena's project-specific memory store.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;execute_shell_command&lt;/code&gt;: Executes a shell command.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;find_file&lt;/code&gt;: Finds files in the given relative paths&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;find_referencing_symbols&lt;/code&gt;: Finds symbols that reference the symbol at the given location (optionally filtered by type).&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;find_symbol&lt;/code&gt;: Performs a global (or local) search for symbols with/containing a given name/substring (optionally filtered by type).&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;get_symbols_overview&lt;/code&gt;: Gets an overview of the top-level symbols defined in a given file.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;insert_after_symbol&lt;/code&gt;: Inserts content after the end of the definition of a given symbol.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;insert_before_symbol&lt;/code&gt;: Inserts content before the beginning of the definition of a given symbol.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;list_dir&lt;/code&gt;: Lists files and directories in the given directory (optionally with recursion).&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;list_memories&lt;/code&gt;: Lists memories in Serena's project-specific memory store.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;onboarding&lt;/code&gt;: Performs onboarding (identifying the project structure and essential tasks, e.g. for testing or building).&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;prepare_for_new_conversation&lt;/code&gt;: Provides instructions for preparing for a new conversation (in order to continue with the necessary context).&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;read_file&lt;/code&gt;: Reads a file within the project directory.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;read_memory&lt;/code&gt;: Reads the memory with the given name from Serena's project-specific memory store.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;replace_regex&lt;/code&gt;: Replaces content in a file by using regular expressions.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;replace_symbol_body&lt;/code&gt;: Replaces the full definition of a symbol.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;search_for_pattern&lt;/code&gt;: Performs a search for a pattern in the project.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;think_about_collected_information&lt;/code&gt;: Thinking tool for pondering the completeness of collected information.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;think_about_task_adherence&lt;/code&gt;: Thinking tool for determining whether the agent is still on track with the current task.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;think_about_whether_you_are_done&lt;/code&gt;: Thinking tool for determining whether the task is truly completed.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;write_memory&lt;/code&gt;: Writes a named memory (for future reference) to Serena's project-specific memory store.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;There are several tools that are disabled by default, and have to be enabled explicitly, e.g., through the context or modes. Note that several of our default contexts do enable some of these tools. For example, the &lt;code&gt;desktop-app&lt;/code&gt; context enables the &lt;code&gt;execute_shell_command&lt;/code&gt; tool.&lt;/p&gt; 
&lt;p&gt;The full list of optional tools is (output of &lt;code&gt;uv run serena tools list --only-optional&lt;/code&gt;):&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;delete_lines&lt;/code&gt;: Deletes a range of lines within a file.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;get_current_config&lt;/code&gt;: Prints the current configuration of the agent, including the active and available projects, tools, contexts, and modes.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;initial_instructions&lt;/code&gt;: Gets the initial instructions for the current project. Should only be used in settings where the system prompt cannot be set, e.g. in clients you have no control over, like Claude Desktop.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;insert_at_line&lt;/code&gt;: Inserts content at a given line in a file.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;jet_brains_find_referencing_symbols&lt;/code&gt;: Finds symbols that reference the given symbol&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;jet_brains_find_symbol&lt;/code&gt;: Performs a global (or local) search for symbols with/containing a given name/substring (optionally filtered by type).&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;jet_brains_get_symbols_overview&lt;/code&gt;: Retrieves an overview of the top-level symbols within a specified file&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;remove_project&lt;/code&gt;: Removes a project from the Serena configuration.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;replace_lines&lt;/code&gt;: Replaces a range of lines within a file with new content.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;restart_language_server&lt;/code&gt;: Restarts the language server, may be necessary when edits not through Serena happen.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;summarize_changes&lt;/code&gt;: Provides instructions for summarizing the changes made to the codebase.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;switch_modes&lt;/code&gt;: Activates modes by providing a list of their names&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>hao-ai-lab/FastVideo</title>
      <link>https://github.com/hao-ai-lab/FastVideo</link>
      <description>&lt;p&gt;A unified inference and post-training framework for accelerated video generation.&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/hao-ai-lab/FastVideo/main/assets/logos/logo.svg?sanitize=true" width="30%" /&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;strong&gt;FastVideo is a unified post-training and inference framework for accelerated video generation.&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;FastVideo features an end-to-end unified pipeline for accelerating diffusion models, starting from data preprocessing to model training, finetuning, distillation, and inference. FastVideo is designed to be modular and extensible, allowing users to easily add new optimizations and techniques. Whether it is training-free optimizations or post-training optimizations, FastVideo has you covered.&lt;/p&gt; 
&lt;p align="center"&gt; | ğŸ•¹ï¸ &lt;a href="https://fastwan.fastvideo.org/" &lt;b&gt;Online Demo&lt;/a&gt; | &lt;a href="https://hao-ai-lab.github.io/FastVideo"&gt;&lt;b&gt;Documentation&lt;/b&gt;&lt;/a&gt; | &lt;a href="https://hao-ai-lab.github.io/FastVideo/inference/inference_quick_start.html"&gt;&lt;b&gt; Quick Start&lt;/b&gt;&lt;/a&gt; | ğŸ¤— &lt;a href="https://huggingface.co/collections/FastVideo/fastwan-6886a305d9799c8cd1496408" target="_blank"&gt;&lt;b&gt;FastWan&lt;/b&gt;&lt;/a&gt; | ğŸŸ£ğŸ’¬ &lt;a href="https://join.slack.com/t/fastvideo/shared_invite/zt-38u6p1jqe-yDI1QJOCEnbtkLoaI5bjZQ" target="_blank"&gt; &lt;b&gt;Slack&lt;/b&gt; &lt;/a&gt; | ğŸŸ£ğŸ’¬ &lt;a href="https://ibb.co/rG0QpZdw" target="_blank"&gt; &lt;b&gt; WeChat &lt;/b&gt; &lt;/a&gt; | &lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/hao-ai-lab/FastVideo/main/assets/fastwan.png" width="90%" /&gt; 
&lt;/div&gt; 
&lt;h2&gt;NEWS&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;2025/08/04&lt;/code&gt;: Release &lt;a href="https://hao-ai-lab.github.io/FastVideo/distillation/dmd.html"&gt;FastWan&lt;/a&gt; models and &lt;a href="https://hao-ai-lab.github.io/blogs/fastvideo_post_training/"&gt;Sparse-Distillation&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;2025/06/14&lt;/code&gt;: Release finetuning and inference code for &lt;a href="https://arxiv.org/pdf/2505.13389"&gt;VSA&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;2025/04/24&lt;/code&gt;: &lt;a href="https://hao-ai-lab.github.io/blogs/fastvideo/"&gt;FastVideo V1&lt;/a&gt; is released!&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;2025/02/18&lt;/code&gt;: Release the inference code for &lt;a href="https://hao-ai-lab.github.io/blogs/sta/"&gt;Sliding Tile Attention&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Key Features&lt;/h2&gt; 
&lt;p&gt;FastVideo has the following features:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;End-to-end post-training support: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://hao-ai-lab.github.io/blogs/fastvideo_post_training/"&gt;Sparse distillation&lt;/a&gt; for Wan2.1 and Wan2.2 to achineve &amp;gt;50x denoising speedup&lt;/li&gt; 
   &lt;li&gt;Data preprocessing pipeline for video data&lt;/li&gt; 
   &lt;li&gt;Support full finetuning and LoRA finetuning for state-of-the-art open video DiTs&lt;/li&gt; 
   &lt;li&gt;Scalable training with FSDP2, sequence parallelism, and selective activation checkpointing, with near linear scaling to 64 GPUs&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;State-of-the-art performance optimizations for inference 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://arxiv.org/pdf/2505.13389"&gt;Video Sparse Attention&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://arxiv.org/pdf/2502.04507"&gt;Sliding Tile Attention&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://arxiv.org/pdf/2411.19108"&gt;TeaCache&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://arxiv.org/abs/2410.02367"&gt;Sage Attention&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Diverse hardware and OS support 
  &lt;ul&gt; 
   &lt;li&gt;Support H100, A100, 4090&lt;/li&gt; 
   &lt;li&gt;Support Linux, Windows, MacOS&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;p&gt;We recommend using an environment manager such as &lt;code&gt;Conda&lt;/code&gt; to create a clean environment:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Create and activate a new conda environment
conda create -n fastvideo python=3.12
conda activate fastvideo

# Install FastVideo
pip install fastvideo
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Please see our &lt;a href="https://hao-ai-lab.github.io/FastVideo/getting_started/installation.html"&gt;docs&lt;/a&gt; for more detailed installation instructions.&lt;/p&gt; 
&lt;h2&gt;Sparse Distillation&lt;/h2&gt; 
&lt;p&gt;For our sparse distillation techniques, please see our &lt;a href="https://hao-ai-lab.github.io/FastVideo/distillation/dmd.html"&gt;distillation docs&lt;/a&gt; and check out our &lt;a href="https://hao-ai-lab.github.io/blogs/fastvideo_post_training/"&gt;blog&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;See below for recipes and datasets:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="center"&gt;Model&lt;/th&gt; 
   &lt;th align="center"&gt;Sparse Distillation&lt;/th&gt; 
   &lt;th align="center"&gt;Dataset&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;a href="https://huggingface.co/FastVideo/FastWan2.1-T2V-1.3B-Diffusers"&gt;FastWan2.1-T2V-1.3B&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/hao-ai-lab/FastVideo/tree/main/examples/distill/Wan2.1-T2V/Wan-Syn-Data-480P"&gt;Recipe&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://huggingface.co/datasets/FastVideo/Wan-Syn_77x448x832_600k"&gt;FastVideo Synthetic Wan2.1 480P&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;a href="https://huggingface.co/FastVideo/FastWan2.1-T2V-14B-Diffusers"&gt;FastWan2.1-T2V-14B-Preview&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;Coming soon!&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://huggingface.co/datasets/FastVideo/Wan-Syn_77x768x1280_250k"&gt;FastVideo Synthetic Wan2.1 720P&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;a href="https://huggingface.co/FastVideo/FastWan2.2-TI2V-5B-Diffusers"&gt;FastWan2.2-TI2V-5B&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/hao-ai-lab/FastVideo/tree/main/examples/distill/Wan2.2-TI2V-5B-Diffusers/Data-free"&gt;Recipe&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://huggingface.co/datasets/FastVideo/Wan2.2-Syn-121x704x1280_32k"&gt;FastVideo Synthetic Wan2.2 720P&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Inference&lt;/h2&gt; 
&lt;h3&gt;Generating Your First Video&lt;/h3&gt; 
&lt;p&gt;Here's a minimal example to generate a video using the default settings. Make sure VSA kernels are &lt;a href="https://hao-ai-lab.github.io/FastVideo/video_sparse_attention/installation.html"&gt;installed&lt;/a&gt;. Create a file called &lt;code&gt;example.py&lt;/code&gt; with the following code:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import os
from fastvideo import VideoGenerator

def main():
    os.environ["FASTVIDEO_ATTENTION_BACKEND"] = "VIDEO_SPARSE_ATTN"

    # Create a video generator with a pre-trained model
    generator = VideoGenerator.from_pretrained(
        "FastVideo/FastWan2.1-T2V-1.3B-Diffusers",
        num_gpus=1,  # Adjust based on your hardware
    )

    # Define a prompt for your video
    prompt = "A curious raccoon peers through a vibrant field of yellow sunflowers, its eyes wide with interest."

    # Generate the video
    video = generator.generate_video(
        prompt,
        return_frames=True,  # Also return frames from this call (defaults to False)
        output_path="my_videos/",  # Controls where videos are saved
        save_video=True
    )

if __name__ == '__main__':
    main()
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Run the script with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python example.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For a more detailed guide, please see our &lt;a href="https://hao-ai-lab.github.io/FastVideo/inference/inference_quick_start.html"&gt;inference quick start&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Other docs:&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://hao-ai-lab.github.io/FastVideo/design/overview.html"&gt;Design Overview&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://hao-ai-lab.github.io/FastVideo/getting_started/installation.html"&gt;Contribution Guide&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Distillation and Finetuning&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://hao-ai-lab.github.io/FastVideo/distillation/dmd.html"&gt;Distillation Guide&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;!-- - [Finetuning Guide](https://hao-ai-lab.github.io/FastVideo/training/finetune.html) --&gt; 
&lt;h2&gt;ğŸ“‘ Development Plan&lt;/h2&gt; 
&lt;!-- - More distillation methods --&gt; 
&lt;!-- - [ ] Add Distribution Matching Distillation --&gt; 
&lt;p&gt;More FastWan Models Coming Soon!&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Add FastWan2.1-T2V-14B&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Add FastWan2.2-T2V-14B&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Add FastWan2.2-I2V-14B&lt;/li&gt; 
&lt;/ul&gt; 
&lt;!-- - Optimization features
- Code updates --&gt; 
&lt;!-- - [ ] fp8 support --&gt; 
&lt;!-- - [ ] faster load model and save model support --&gt; 
&lt;p&gt;See details in &lt;a href="https://github.com/hao-ai-lab/FastVideo/issues/468"&gt;development roadmap&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;ğŸ¤ Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome all contributions. Please check out our guide &lt;a href="https://hao-ai-lab.github.io/FastVideo/contributing/overview.html"&gt;here&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Acknowledgement&lt;/h2&gt; 
&lt;p&gt;We learned and reused code from the following projects:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Wan-Video"&gt;Wan-Video&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/HazyResearch/ThunderKittens"&gt;ThunderKittens&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/triton-lang/triton"&gt;Triton&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tianweiy/DMD2"&gt;DMD2&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/huggingface/diffusers"&gt;diffusers&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/xdit-project/xDiT"&gt;xDiT&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/vllm-project/vllm"&gt;vLLM&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/sgl-project/sglang"&gt;SGLang&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;We thank &lt;a href="https://ifm.mbzuai.ac.ae/"&gt;MBZUAI&lt;/a&gt;, &lt;a href="https://www.anyscale.com/"&gt;Anyscale&lt;/a&gt;, and &lt;a href="https://www.gmicloud.ai/"&gt;GMI Cloud&lt;/a&gt; for their support throughout this project.&lt;/p&gt; 
&lt;h2&gt;Citation&lt;/h2&gt; 
&lt;p&gt;If you find FastVideo useful, please considering citing our work:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bibtex"&gt;@software{fastvideo2024,
  title        = {FastVideo: A Unified Framework for Accelerated Video Generation},
  author       = {The FastVideo Team},
  url          = {https://github.com/hao-ai-lab/FastVideo},
  month        = apr,
  year         = {2024},
}

@article{zhang2025vsa,
  title={VSA: Faster Video Diffusion with Trainable Sparse Attention},
  author={Zhang, Peiyuan and Huang, Haofeng and Chen, Yongqi and Lin, Will and Liu, Zhengzhong and Stoica, Ion and Xing, Eric and Zhang, Hao},
  journal={arXiv preprint arXiv:2505.13389},
  year={2025}
}

@article{zhang2025fast,
  title={Fast video generation with sliding tile attention},
  author={Zhang, Peiyuan and Chen, Yongqi and Su, Runlong and Ding, Hangliang and Stoica, Ion and Liu, Zhengzhong and Zhang, Hao},
  journal={arXiv preprint arXiv:2502.04507},
  year={2025}
}
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>vllm-project/vllm</title>
      <link>https://github.com/vllm-project/vllm</link>
      <description>&lt;p&gt;A high-throughput and memory-efficient inference and serving engine for LLMs&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://raw.githubusercontent.com/vllm-project/vllm/main/docs/assets/logos/vllm-logo-text-dark.png" /&gt; 
  &lt;img alt="vLLM" src="https://raw.githubusercontent.com/vllm-project/vllm/main/docs/assets/logos/vllm-logo-text-light.png" width="55%" /&gt; 
 &lt;/picture&gt; &lt;/p&gt; 
&lt;h3 align="center"&gt; Easy, fast, and cheap LLM serving for everyone &lt;/h3&gt; 
&lt;p align="center"&gt; | &lt;a href="https://docs.vllm.ai"&gt;&lt;b&gt;Documentation&lt;/b&gt;&lt;/a&gt; | &lt;a href="https://blog.vllm.ai/"&gt;&lt;b&gt;Blog&lt;/b&gt;&lt;/a&gt; | &lt;a href="https://arxiv.org/abs/2309.06180"&gt;&lt;b&gt;Paper&lt;/b&gt;&lt;/a&gt; | &lt;a href="https://x.com/vllm_project"&gt;&lt;b&gt;Twitter/X&lt;/b&gt;&lt;/a&gt; | &lt;a href="https://discuss.vllm.ai"&gt;&lt;b&gt;User Forum&lt;/b&gt;&lt;/a&gt; | &lt;a href="https://slack.vllm.ai"&gt;&lt;b&gt;Developer Slack&lt;/b&gt;&lt;/a&gt; | &lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;em&gt;Latest News&lt;/em&gt; ğŸ”¥&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;[2025/08] We hosted &lt;a href="https://mp.weixin.qq.com/s/pDmAXHcN7Iqc8sUKgJgGtg"&gt;vLLM Shanghai Meetup&lt;/a&gt; focusing on building, developing, and integrating with vLLM! Please find the meetup slides &lt;a href="https://drive.google.com/drive/folders/1OvLx39wnCGy_WKq8SiVKf7YcxxYI3WCH"&gt;here&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;[2025/08] We hosted &lt;a href="https://luma.com/cgcgprmh"&gt;vLLM Korea Meetup&lt;/a&gt; with Red Hat and Rebellions! We shared the latest advancements in vLLM along with project spotlights from the vLLM Korea community. Please find the meetup slides &lt;a href="https://drive.google.com/file/d/1bcrrAE1rxUgx0mjIeOWT6hNe2RefC5Hm/view"&gt;here&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;[2025/08] We hosted &lt;a href="https://mp.weixin.qq.com/s/dgkWg1WFpWGO2jCdTqQHxA"&gt;vLLM Beijing Meetup&lt;/a&gt; focusing on large-scale LLM deployment! Please find the meetup slides &lt;a href="https://drive.google.com/drive/folders/1Pid6NSFLU43DZRi0EaTcPgXsAzDvbBqF"&gt;here&lt;/a&gt; and the recording &lt;a href="https://www.chaspark.com/#/live/1166916873711665152"&gt;here&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;[2025/05] vLLM is now a hosted project under PyTorch Foundation! Please find the announcement &lt;a href="https://pytorch.org/blog/pytorch-foundation-welcomes-vllm/"&gt;here&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;[2025/01] We are excited to announce the alpha release of vLLM V1: A major architectural upgrade with 1.7x speedup! Clean code, optimized execution loop, zero-overhead prefix caching, enhanced multimodal support, and more. Please check out our blog post &lt;a href="https://blog.vllm.ai/2025/01/27/v1-alpha-release.html"&gt;here&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;details&gt; 
 &lt;summary&gt;Previous News&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;[2025/05] We hosted &lt;a href="https://lu.ma/c1rqyf1f"&gt;NYC vLLM Meetup&lt;/a&gt;! Please find the meetup slides &lt;a href="https://docs.google.com/presentation/d/1_q_aW_ioMJWUImf1s1YM-ZhjXz8cUeL0IJvaquOYBeA/edit?usp=sharing"&gt;here&lt;/a&gt;.&lt;/li&gt; 
  &lt;li&gt;[2025/04] We hosted &lt;a href="https://www.sginnovate.com/event/limited-availability-morning-evening-slots-remaining-inaugural-vllm-asia-developer-day"&gt;Asia Developer Day&lt;/a&gt;! Please find the meetup slides from the vLLM team &lt;a href="https://docs.google.com/presentation/d/19cp6Qu8u48ihB91A064XfaXruNYiBOUKrBxAmDOllOo/edit?usp=sharing"&gt;here&lt;/a&gt;.&lt;/li&gt; 
  &lt;li&gt;[2025/03] We hosted &lt;a href="https://lu.ma/vllm-ollama"&gt;vLLM x Ollama Inference Night&lt;/a&gt;! Please find the meetup slides from the vLLM team &lt;a href="https://docs.google.com/presentation/d/16T2PDD1YwRnZ4Tu8Q5r6n53c5Lr5c73UV9Vd2_eBo4U/edit?usp=sharing"&gt;here&lt;/a&gt;.&lt;/li&gt; 
  &lt;li&gt;[2025/03] We hosted &lt;a href="https://mp.weixin.qq.com/s/n77GibL2corAtQHtVEAzfg"&gt;the first vLLM China Meetup&lt;/a&gt;! Please find the meetup slides from vLLM team &lt;a href="https://docs.google.com/presentation/d/1REHvfQMKGnvz6p3Fd23HhSO4c8j5WPGZV0bKYLwnHyQ/edit?usp=sharing"&gt;here&lt;/a&gt;.&lt;/li&gt; 
  &lt;li&gt;[2025/03] We hosted &lt;a href="https://lu.ma/7mu4k4xx"&gt;the East Coast vLLM Meetup&lt;/a&gt;! Please find the meetup slides &lt;a href="https://docs.google.com/presentation/d/1NHiv8EUFF1NLd3fEYODm56nDmL26lEeXCaDgyDlTsRs/edit#slide=id.g31441846c39_0_0"&gt;here&lt;/a&gt;.&lt;/li&gt; 
  &lt;li&gt;[2025/02] We hosted &lt;a href="https://lu.ma/h7g3kuj9"&gt;the ninth vLLM meetup&lt;/a&gt; with Meta! Please find the meetup slides from vLLM team &lt;a href="https://docs.google.com/presentation/d/1jzC_PZVXrVNSFVCW-V4cFXb6pn7zZ2CyP_Flwo05aqg/edit?usp=sharing"&gt;here&lt;/a&gt; and AMD &lt;a href="https://drive.google.com/file/d/1Zk5qEJIkTmlQ2eQcXQZlljAx3m9s7nwn/view?usp=sharing"&gt;here&lt;/a&gt;. The slides from Meta will not be posted.&lt;/li&gt; 
  &lt;li&gt;[2025/01] We hosted &lt;a href="https://lu.ma/zep56hui"&gt;the eighth vLLM meetup&lt;/a&gt; with Google Cloud! Please find the meetup slides from vLLM team &lt;a href="https://docs.google.com/presentation/d/1epVkt4Zu8Jz_S5OhEHPc798emsYh2BwYfRuDDVEF7u4/edit?usp=sharing"&gt;here&lt;/a&gt;, and Google Cloud team &lt;a href="https://drive.google.com/file/d/1h24pHewANyRL11xy5dXUbvRC9F9Kkjix/view?usp=sharing"&gt;here&lt;/a&gt;.&lt;/li&gt; 
  &lt;li&gt;[2024/12] vLLM joins &lt;a href="https://pytorch.org/blog/vllm-joins-pytorch"&gt;pytorch ecosystem&lt;/a&gt;! Easy, Fast, and Cheap LLM Serving for Everyone!&lt;/li&gt; 
  &lt;li&gt;[2024/11] We hosted &lt;a href="https://lu.ma/h0qvrajz"&gt;the seventh vLLM meetup&lt;/a&gt; with Snowflake! Please find the meetup slides from vLLM team &lt;a href="https://docs.google.com/presentation/d/1e3CxQBV3JsfGp30SwyvS3eM_tW-ghOhJ9PAJGK6KR54/edit?usp=sharing"&gt;here&lt;/a&gt;, and Snowflake team &lt;a href="https://docs.google.com/presentation/d/1qF3RkDAbOULwz9WK5TOltt2fE9t6uIc_hVNLFAaQX6A/edit?usp=sharing"&gt;here&lt;/a&gt;.&lt;/li&gt; 
  &lt;li&gt;[2024/10] We have just created a developer slack (&lt;a href="https://slack.vllm.ai"&gt;slack.vllm.ai&lt;/a&gt;) focusing on coordinating contributions and discussing features. Please feel free to join us there!&lt;/li&gt; 
  &lt;li&gt;[2024/10] Ray Summit 2024 held a special track for vLLM! Please find the opening talk slides from the vLLM team &lt;a href="https://docs.google.com/presentation/d/1B_KQxpHBTRa_mDF-tR6i8rWdOU5QoTZNcEg2MKZxEHM/edit?usp=sharing"&gt;here&lt;/a&gt;. Learn more from the &lt;a href="https://www.youtube.com/playlist?list=PLzTswPQNepXl6AQwifuwUImLPFRVpksjR"&gt;talks&lt;/a&gt; from other vLLM contributors and users!&lt;/li&gt; 
  &lt;li&gt;[2024/09] We hosted &lt;a href="https://lu.ma/87q3nvnh"&gt;the sixth vLLM meetup&lt;/a&gt; with NVIDIA! Please find the meetup slides &lt;a href="https://docs.google.com/presentation/d/1wrLGwytQfaOTd5wCGSPNhoaW3nq0E-9wqyP7ny93xRs/edit?usp=sharing"&gt;here&lt;/a&gt;.&lt;/li&gt; 
  &lt;li&gt;[2024/07] We hosted &lt;a href="https://lu.ma/lp0gyjqr"&gt;the fifth vLLM meetup&lt;/a&gt; with AWS! Please find the meetup slides &lt;a href="https://docs.google.com/presentation/d/1RgUD8aCfcHocghoP3zmXzck9vX3RCI9yfUAB2Bbcl4Y/edit?usp=sharing"&gt;here&lt;/a&gt;.&lt;/li&gt; 
  &lt;li&gt;[2024/07] In partnership with Meta, vLLM officially supports Llama 3.1 with FP8 quantization and pipeline parallelism! Please check out our blog post &lt;a href="https://blog.vllm.ai/2024/07/23/llama31.html"&gt;here&lt;/a&gt;.&lt;/li&gt; 
  &lt;li&gt;[2024/06] We hosted &lt;a href="https://lu.ma/agivllm"&gt;the fourth vLLM meetup&lt;/a&gt; with Cloudflare and BentoML! Please find the meetup slides &lt;a href="https://docs.google.com/presentation/d/1iJ8o7V2bQEi0BFEljLTwc5G1S10_Rhv3beed5oB0NJ4/edit?usp=sharing"&gt;here&lt;/a&gt;.&lt;/li&gt; 
  &lt;li&gt;[2024/04] We hosted &lt;a href="https://robloxandvllmmeetup2024.splashthat.com/"&gt;the third vLLM meetup&lt;/a&gt; with Roblox! Please find the meetup slides &lt;a href="https://docs.google.com/presentation/d/1A--47JAK4BJ39t954HyTkvtfwn0fkqtsL8NGFuslReM/edit?usp=sharing"&gt;here&lt;/a&gt;.&lt;/li&gt; 
  &lt;li&gt;[2024/01] We hosted &lt;a href="https://lu.ma/ygxbpzhl"&gt;the second vLLM meetup&lt;/a&gt; with IBM! Please find the meetup slides &lt;a href="https://docs.google.com/presentation/d/12mI2sKABnUw5RBWXDYY-HtHth4iMSNcEoQ10jDQbxgA/edit?usp=sharing"&gt;here&lt;/a&gt;.&lt;/li&gt; 
  &lt;li&gt;[2023/10] We hosted &lt;a href="https://lu.ma/first-vllm-meetup"&gt;the first vLLM meetup&lt;/a&gt; with a16z! Please find the meetup slides &lt;a href="https://docs.google.com/presentation/d/1QL-XPFXiFpDBh86DbEegFXBXFXjix4v032GhShbKf3s/edit?usp=sharing"&gt;here&lt;/a&gt;.&lt;/li&gt; 
  &lt;li&gt;[2023/08] We would like to express our sincere gratitude to &lt;a href="https://a16z.com/2023/08/30/supporting-the-open-source-ai-community/"&gt;Andreessen Horowitz&lt;/a&gt; (a16z) for providing a generous grant to support the open-source development and research of vLLM.&lt;/li&gt; 
  &lt;li&gt;[2023/06] We officially released vLLM! FastChat-vLLM integration has powered &lt;a href="https://chat.lmsys.org"&gt;LMSYS Vicuna and Chatbot Arena&lt;/a&gt; since mid-April. Check out our &lt;a href="https://vllm.ai"&gt;blog post&lt;/a&gt;.&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;hr /&gt; 
&lt;h2&gt;About&lt;/h2&gt; 
&lt;p&gt;vLLM is a fast and easy-to-use library for LLM inference and serving.&lt;/p&gt; 
&lt;p&gt;Originally developed in the &lt;a href="https://sky.cs.berkeley.edu"&gt;Sky Computing Lab&lt;/a&gt; at UC Berkeley, vLLM has evolved into a community-driven project with contributions from both academia and industry.&lt;/p&gt; 
&lt;p&gt;vLLM is fast with:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;State-of-the-art serving throughput&lt;/li&gt; 
 &lt;li&gt;Efficient management of attention key and value memory with &lt;a href="https://blog.vllm.ai/2023/06/20/vllm.html"&gt;&lt;strong&gt;PagedAttention&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Continuous batching of incoming requests&lt;/li&gt; 
 &lt;li&gt;Fast model execution with CUDA/HIP graph&lt;/li&gt; 
 &lt;li&gt;Quantizations: &lt;a href="https://arxiv.org/abs/2210.17323"&gt;GPTQ&lt;/a&gt;, &lt;a href="https://arxiv.org/abs/2306.00978"&gt;AWQ&lt;/a&gt;, &lt;a href="https://arxiv.org/abs/2309.05516"&gt;AutoRound&lt;/a&gt;, INT4, INT8, and FP8&lt;/li&gt; 
 &lt;li&gt;Optimized CUDA kernels, including integration with FlashAttention and FlashInfer&lt;/li&gt; 
 &lt;li&gt;Speculative decoding&lt;/li&gt; 
 &lt;li&gt;Chunked prefill&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;vLLM is flexible and easy to use with:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Seamless integration with popular Hugging Face models&lt;/li&gt; 
 &lt;li&gt;High-throughput serving with various decoding algorithms, including &lt;em&gt;parallel sampling&lt;/em&gt;, &lt;em&gt;beam search&lt;/em&gt;, and more&lt;/li&gt; 
 &lt;li&gt;Tensor, pipeline, data and expert parallelism support for distributed inference&lt;/li&gt; 
 &lt;li&gt;Streaming outputs&lt;/li&gt; 
 &lt;li&gt;OpenAI-compatible API server&lt;/li&gt; 
 &lt;li&gt;Support NVIDIA GPUs, AMD CPUs and GPUs, Intel CPUs and GPUs, PowerPC CPUs, TPU, and AWS Neuron&lt;/li&gt; 
 &lt;li&gt;Prefix caching support&lt;/li&gt; 
 &lt;li&gt;Multi-LoRA support&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;vLLM seamlessly supports most popular open-source models on HuggingFace, including:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Transformer-like LLMs (e.g., Llama)&lt;/li&gt; 
 &lt;li&gt;Mixture-of-Expert LLMs (e.g., Mixtral, Deepseek-V2 and V3)&lt;/li&gt; 
 &lt;li&gt;Embedding Models (e.g., E5-Mistral)&lt;/li&gt; 
 &lt;li&gt;Multi-modal LLMs (e.g., LLaVA)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Find the full list of supported models &lt;a href="https://docs.vllm.ai/en/latest/models/supported_models.html"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;p&gt;Install vLLM with &lt;code&gt;pip&lt;/code&gt; or &lt;a href="https://docs.vllm.ai/en/latest/getting_started/installation/gpu/index.html#build-wheel-from-source"&gt;from source&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install vllm
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Visit our &lt;a href="https://docs.vllm.ai/en/latest/"&gt;documentation&lt;/a&gt; to learn more.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.vllm.ai/en/latest/getting_started/installation.html"&gt;Installation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.vllm.ai/en/latest/getting_started/quickstart.html"&gt;Quickstart&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.vllm.ai/en/latest/models/supported_models.html"&gt;List of Supported Models&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome and value any contributions and collaborations. Please check out &lt;a href="https://docs.vllm.ai/en/latest/contributing/index.html"&gt;Contributing to vLLM&lt;/a&gt; for how to get involved.&lt;/p&gt; 
&lt;h2&gt;Sponsors&lt;/h2&gt; 
&lt;p&gt;vLLM is a community project. Our compute resources for development and testing are supported by the following organizations. Thank you for your support!&lt;/p&gt; 
&lt;!-- Note: Please sort them in alphabetical order. --&gt; 
&lt;!-- Note: Please keep these consistent with docs/community/sponsors.md --&gt; 
&lt;p&gt;Cash Donations:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;a16z&lt;/li&gt; 
 &lt;li&gt;Dropbox&lt;/li&gt; 
 &lt;li&gt;Sequoia Capital&lt;/li&gt; 
 &lt;li&gt;Skywork AI&lt;/li&gt; 
 &lt;li&gt;ZhenFund&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Compute Resources:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Alibaba Cloud&lt;/li&gt; 
 &lt;li&gt;AMD&lt;/li&gt; 
 &lt;li&gt;Anyscale&lt;/li&gt; 
 &lt;li&gt;AWS&lt;/li&gt; 
 &lt;li&gt;Crusoe Cloud&lt;/li&gt; 
 &lt;li&gt;Databricks&lt;/li&gt; 
 &lt;li&gt;DeepInfra&lt;/li&gt; 
 &lt;li&gt;Google Cloud&lt;/li&gt; 
 &lt;li&gt;Intel&lt;/li&gt; 
 &lt;li&gt;Lambda Lab&lt;/li&gt; 
 &lt;li&gt;Nebius&lt;/li&gt; 
 &lt;li&gt;Novita AI&lt;/li&gt; 
 &lt;li&gt;NVIDIA&lt;/li&gt; 
 &lt;li&gt;Replicate&lt;/li&gt; 
 &lt;li&gt;Roblox&lt;/li&gt; 
 &lt;li&gt;RunPod&lt;/li&gt; 
 &lt;li&gt;Trainy&lt;/li&gt; 
 &lt;li&gt;UC Berkeley&lt;/li&gt; 
 &lt;li&gt;UC San Diego&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Slack Sponsor: Anyscale&lt;/p&gt; 
&lt;p&gt;We also have an official fundraising venue through &lt;a href="https://opencollective.com/vllm"&gt;OpenCollective&lt;/a&gt;. We plan to use the fund to support the development, maintenance, and adoption of vLLM.&lt;/p&gt; 
&lt;h2&gt;Citation&lt;/h2&gt; 
&lt;p&gt;If you use vLLM for your research, please cite our &lt;a href="https://arxiv.org/abs/2309.06180"&gt;paper&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bibtex"&gt;@inproceedings{kwon2023efficient,
  title={Efficient Memory Management for Large Language Model Serving with PagedAttention},
  author={Woosuk Kwon and Zhuohan Li and Siyuan Zhuang and Ying Sheng and Lianmin Zheng and Cody Hao Yu and Joseph E. Gonzalez and Hao Zhang and Ion Stoica},
  booktitle={Proceedings of the ACM SIGOPS 29th Symposium on Operating Systems Principles},
  year={2023}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Contact Us&lt;/h2&gt; 
&lt;!-- --8&lt;-- [start:contact-us] --&gt; 
&lt;ul&gt; 
 &lt;li&gt;For technical questions and feature requests, please use GitHub &lt;a href="https://github.com/vllm-project/vllm/issues"&gt;Issues&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;For discussing with fellow users, please use the &lt;a href="https://discuss.vllm.ai"&gt;vLLM Forum&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;For coordinating contributions and development, please use &lt;a href="https://slack.vllm.ai"&gt;Slack&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;For security disclosures, please use GitHub's &lt;a href="https://github.com/vllm-project/vllm/security/advisories"&gt;Security Advisories&lt;/a&gt; feature&lt;/li&gt; 
 &lt;li&gt;For collaborations and partnerships, please contact us at &lt;a href="mailto:vllm-questions@lists.berkeley.edu"&gt;vllm-questions@lists.berkeley.edu&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;!-- --8&lt;-- [end:contact-us] --&gt; 
&lt;h2&gt;Media Kit&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;If you wish to use vLLM's logo, please refer to &lt;a href="https://github.com/vllm-project/media-kit"&gt;our media kit repo&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>9001/copyparty</title>
      <link>https://github.com/9001/copyparty</link>
      <description>&lt;p&gt;Portable file server with accelerated resumable uploads, dedup, WebDAV, FTP, TFTP, zeroconf, media indexer, thumbnails++ all in one file, no deps&lt;/p&gt;&lt;hr&gt;&lt;img src="https://github.com/9001/copyparty/raw/hovudstraum/docs/logo.svg?sanitize=true" width="250" align="right" /&gt; 
&lt;h3&gt;ğŸ’¾ğŸ‰ copyparty&lt;/h3&gt; 
&lt;p&gt;turn almost any device into a file server with resumable uploads/downloads using &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#browser-support"&gt;&lt;em&gt;any&lt;/em&gt;&lt;/a&gt; web browser&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;server only needs Python (2 or 3), all dependencies optional&lt;/li&gt; 
 &lt;li&gt;ğŸ”Œ protocols: &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#the-browser"&gt;http&lt;/a&gt; // &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#webdav-server"&gt;webdav&lt;/a&gt; // &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#ftp-server"&gt;ftp&lt;/a&gt; // &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#tftp-server"&gt;tftp&lt;/a&gt; // &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#smb-server"&gt;smb/cifs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;ğŸ“± &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#android-app"&gt;android app&lt;/a&gt; // &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#ios-shortcuts"&gt;iPhone shortcuts&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;ğŸ‘‰ &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#quickstart"&gt;Get started&lt;/a&gt;!&lt;/strong&gt; or visit the &lt;strong&gt;&lt;a href="https://a.ocv.me/pub/demo/"&gt;read-only demo server&lt;/a&gt;&lt;/strong&gt; ğŸ‘€ running on a nuc in my basement&lt;/p&gt; 
&lt;p&gt;ğŸ“· &lt;strong&gt;screenshots:&lt;/strong&gt; &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#the-browser"&gt;browser&lt;/a&gt; // &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#uploading"&gt;upload&lt;/a&gt; // &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#unpost"&gt;unpost&lt;/a&gt; // &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#thumbnails"&gt;thumbnails&lt;/a&gt; // &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#searching"&gt;search&lt;/a&gt; // &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#file-search"&gt;fsearch&lt;/a&gt; // &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#zip-downloads"&gt;zip-DL&lt;/a&gt; // &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#markdown-viewer"&gt;md-viewer&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;ğŸ¬ &lt;strong&gt;videos:&lt;/strong&gt; &lt;a href="https://a.ocv.me/pub/demo/pics-vids/up2k.webm"&gt;upload&lt;/a&gt; // &lt;a href="https://a.ocv.me/pub/demo/pics-vids/u2cli.webm"&gt;cli-upload&lt;/a&gt; // &lt;a href="https://a.ocv.me/pub/g/nerd-stuff/cpp/2024-0418-race-the-beam.webm"&gt;race-the-beam&lt;/a&gt; // ğŸ‘‰ &lt;strong&gt;&lt;a href="https://a.ocv.me/pub/demo/showcase-hq.webm"&gt;feature-showcase&lt;/a&gt;&lt;/strong&gt; (&lt;a href="https://www.youtube.com/watch?v=15_-hgsX2V0"&gt;youtube&lt;/a&gt;)&lt;/p&gt; 
&lt;p&gt;made in Norway ğŸ‡³ğŸ‡´&lt;/p&gt; 
&lt;h2&gt;readme toc&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;top 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#quickstart"&gt;quickstart&lt;/a&gt; - just run &lt;strong&gt;&lt;a href="https://github.com/9001/copyparty/releases/latest/download/copyparty-sfx.py"&gt;copyparty-sfx.py&lt;/a&gt;&lt;/strong&gt; -- that's it! ğŸ‰ 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#at-home"&gt;at home&lt;/a&gt; - make it accessible over the internet&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#on-servers"&gt;on servers&lt;/a&gt; - you may also want these, especially on servers&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#features"&gt;features&lt;/a&gt; - also see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/docs/versus.md"&gt;comparison to similar software&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#testimonials"&gt;testimonials&lt;/a&gt; - small collection of user feedback&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#motivations"&gt;motivations&lt;/a&gt; - project goals / philosophy 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#notes"&gt;notes&lt;/a&gt; - general notes&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#bugs"&gt;bugs&lt;/a&gt; - roughly sorted by chance of encounter 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#not-my-bugs"&gt;not my bugs&lt;/a&gt; - same order here too&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#breaking-changes"&gt;breaking changes&lt;/a&gt; - upgrade notes&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#FAQ"&gt;FAQ&lt;/a&gt; - "frequently" asked questions&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#accounts-and-volumes"&gt;accounts and volumes&lt;/a&gt; - per-folder, per-user permissions 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#shadowing"&gt;shadowing&lt;/a&gt; - hiding specific subfolders&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#dotfiles"&gt;dotfiles&lt;/a&gt; - unix-style hidden files/folders&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#the-browser"&gt;the browser&lt;/a&gt; - accessing a copyparty server using a web-browser 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#tabs"&gt;tabs&lt;/a&gt; - the main tabs in the ui&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#hotkeys"&gt;hotkeys&lt;/a&gt; - the browser has the following hotkeys&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#navpane"&gt;navpane&lt;/a&gt; - switching between breadcrumbs or navpane&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#thumbnails"&gt;thumbnails&lt;/a&gt; - press &lt;code&gt;g&lt;/code&gt; or &lt;code&gt;ç”°&lt;/code&gt; to toggle grid-view instead of the file listing&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#zip-downloads"&gt;zip downloads&lt;/a&gt; - download folders (or file selections) as &lt;code&gt;zip&lt;/code&gt; or &lt;code&gt;tar&lt;/code&gt; files&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#uploading"&gt;uploading&lt;/a&gt; - drag files/folders into the web-browser to upload 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#file-search"&gt;file-search&lt;/a&gt; - dropping files into the browser also lets you see if they exist on the server&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#unpost"&gt;unpost&lt;/a&gt; - undo/delete accidental uploads&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#self-destruct"&gt;self-destruct&lt;/a&gt; - uploads can be given a lifetime&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#race-the-beam"&gt;race the beam&lt;/a&gt; - download files while they're still uploading (&lt;a href="http://a.ocv.me/pub/g/nerd-stuff/cpp/2024-0418-race-the-beam.webm"&gt;demo video&lt;/a&gt;)&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#incoming-files"&gt;incoming files&lt;/a&gt; - the control-panel shows the ETA for all incoming files&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#file-manager"&gt;file manager&lt;/a&gt; - cut/paste, rename, and delete files/folders (if you have permission)&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#shares"&gt;shares&lt;/a&gt; - share a file or folder by creating a temporary link&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#batch-rename"&gt;batch rename&lt;/a&gt; - select some files and press &lt;code&gt;F2&lt;/code&gt; to bring up the rename UI&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#rss-feeds"&gt;rss feeds&lt;/a&gt; - monitor a folder with your RSS reader&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#recent-uploads"&gt;recent uploads&lt;/a&gt; - list all recent uploads&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#media-player"&gt;media player&lt;/a&gt; - plays almost every audio format there is 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#playlists"&gt;playlists&lt;/a&gt; - create and play &lt;a href="https://en.wikipedia.org/wiki/M3U"&gt;m3u8&lt;/a&gt; playlists&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#creating-a-playlist"&gt;creating a playlist&lt;/a&gt; - with a standalone mediaplayer or copyparty&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#audio-equalizer"&gt;audio equalizer&lt;/a&gt; - and &lt;a href="https://en.wikipedia.org/wiki/Dynamic_range_compression"&gt;dynamic range compressor&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#fix-unreliable-playback-on-android"&gt;fix unreliable playback on android&lt;/a&gt; - due to phone / app settings&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#textfile-viewer"&gt;textfile viewer&lt;/a&gt; - with realtime streaming of logfiles and such (&lt;a href="https://a.ocv.me/pub/demo/logtail/"&gt;demo&lt;/a&gt;)&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#markdown-viewer"&gt;markdown viewer&lt;/a&gt; - and there are &lt;em&gt;two&lt;/em&gt; editors 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#markdown-vars"&gt;markdown vars&lt;/a&gt; - dynamic docs with serverside variable expansion&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#other-tricks"&gt;other tricks&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#searching"&gt;searching&lt;/a&gt; - search by size, date, path/name, mp3-tags, ...&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#server-config"&gt;server config&lt;/a&gt; - using arguments or config files, or a mix of both 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#zeroconf"&gt;zeroconf&lt;/a&gt; - announce enabled services on the LAN (&lt;a href="https://user-images.githubusercontent.com/241032/215344737-0eae8d98-9496-4256-9aa8-cd2f6971810d.png"&gt;pic&lt;/a&gt;) 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#mdns"&gt;mdns&lt;/a&gt; - LAN domain-name and feature announcer&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#ssdp"&gt;ssdp&lt;/a&gt; - windows-explorer announcer&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#qr-code"&gt;qr-code&lt;/a&gt; - print a qr-code &lt;a href="https://user-images.githubusercontent.com/241032/194728533-6f00849b-c6ac-43c6-9359-83e454d11e00.png"&gt;(screenshot)&lt;/a&gt; for quick access&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#ftp-server"&gt;ftp server&lt;/a&gt; - an FTP server can be started using &lt;code&gt;--ftp 3921&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#webdav-server"&gt;webdav server&lt;/a&gt; - with read-write support 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#connecting-to-webdav-from-windows"&gt;connecting to webdav from windows&lt;/a&gt; - using the GUI&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#tftp-server"&gt;tftp server&lt;/a&gt; - a TFTP server (read/write) can be started using &lt;code&gt;--tftp 3969&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#smb-server"&gt;smb server&lt;/a&gt; - unsafe, slow, not recommended for wan&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#browser-ux"&gt;browser ux&lt;/a&gt; - tweaking the ui&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#opengraph"&gt;opengraph&lt;/a&gt; - discord and social-media embeds&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#file-deduplication"&gt;file deduplication&lt;/a&gt; - enable symlink-based upload deduplication&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#file-indexing"&gt;file indexing&lt;/a&gt; - enable music search, upload-undo, and better dedup 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#exclude-patterns"&gt;exclude-patterns&lt;/a&gt; - to save some time&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#filesystem-guards"&gt;filesystem guards&lt;/a&gt; - avoid traversing into other filesystems&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#periodic-rescan"&gt;periodic rescan&lt;/a&gt; - filesystem monitoring&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#upload-rules"&gt;upload rules&lt;/a&gt; - set upload rules using volflags&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#compress-uploads"&gt;compress uploads&lt;/a&gt; - files can be autocompressed on upload&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#chmod-and-chown"&gt;chmod and chown&lt;/a&gt; - per-volume filesystem-permissions and ownership&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#other-flags"&gt;other flags&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#database-location"&gt;database location&lt;/a&gt; - in-volume (&lt;code&gt;.hist/up2k.db&lt;/code&gt;, default) or somewhere else&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#metadata-from-audio-files"&gt;metadata from audio files&lt;/a&gt; - set &lt;code&gt;-e2t&lt;/code&gt; to index tags on upload&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#file-parser-plugins"&gt;file parser plugins&lt;/a&gt; - provide custom parsers to index additional tags&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#event-hooks"&gt;event hooks&lt;/a&gt; - trigger a program on uploads, renames etc (&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/bin/hooks/"&gt;examples&lt;/a&gt;) 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#zeromq"&gt;zeromq&lt;/a&gt; - event-hooks can send zeromq messages&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#upload-events"&gt;upload events&lt;/a&gt; - the older, more powerful approach (&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/bin/mtag/"&gt;examples&lt;/a&gt;)&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#handlers"&gt;handlers&lt;/a&gt; - redefine behavior with plugins (&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/bin/handlers/"&gt;examples&lt;/a&gt;)&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#ip-auth"&gt;ip auth&lt;/a&gt; - autologin based on IP range (CIDR) 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#restrict-to-ip"&gt;restrict to ip&lt;/a&gt; - limit a user to certain IP ranges (CIDR)&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#identity-providers"&gt;identity providers&lt;/a&gt; - replace copyparty passwords with oauth and such 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#generic-header-auth"&gt;generic header auth&lt;/a&gt; - other ways to auth by header&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#user-changeable-passwords"&gt;user-changeable passwords&lt;/a&gt; - if permitted, users can change their own passwords&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#using-the-cloud-as-storage"&gt;using the cloud as storage&lt;/a&gt; - connecting to an aws s3 bucket and similar&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#hiding-from-google"&gt;hiding from google&lt;/a&gt; - tell search engines you don't wanna be indexed&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#themes"&gt;themes&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#complete-examples"&gt;complete examples&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#listen-on-port-80-and-443"&gt;listen on port 80 and 443&lt;/a&gt; - become a &lt;em&gt;real&lt;/em&gt; webserver&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#reverse-proxy"&gt;reverse-proxy&lt;/a&gt; - running copyparty next to other websites 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#real-ip"&gt;real-ip&lt;/a&gt; - teaching copyparty how to see client IPs&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#reverse-proxy-performance"&gt;reverse-proxy performance&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#permanent-cloudflare-tunnel"&gt;permanent cloudflare tunnel&lt;/a&gt; - if you have a domain and want to get your copyparty online real quick&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#prometheus"&gt;prometheus&lt;/a&gt; - metrics/stats can be enabled&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#other-extremely-specific-features"&gt;other extremely specific features&lt;/a&gt; - you'll never find a use for these 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#custom-mimetypes"&gt;custom mimetypes&lt;/a&gt; - change the association of a file extension&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#GDPR-compliance"&gt;GDPR compliance&lt;/a&gt; - imagine using copyparty professionally...&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#feature-chickenbits"&gt;feature chickenbits&lt;/a&gt; - buggy feature? rip it out&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#feature-beefybits"&gt;feature beefybits&lt;/a&gt; - force-enable features with known issues on your OS/env&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#packages"&gt;packages&lt;/a&gt; - the party might be closer than you think 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#arch-package"&gt;arch package&lt;/a&gt; - &lt;code&gt;pacman -S copyparty&lt;/code&gt; (in &lt;a href="https://archlinux.org/packages/extra/any/copyparty/"&gt;arch linux extra&lt;/a&gt;)&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#fedora-package"&gt;fedora package&lt;/a&gt; - does not exist yet&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#homebrew-formulae"&gt;homebrew formulae&lt;/a&gt; - &lt;code&gt;brew install copyparty ffmpeg&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#nix-package"&gt;nix package&lt;/a&gt; - &lt;code&gt;nix profile install github:9001/copyparty&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#nixos-module"&gt;nixos module&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#browser-support"&gt;browser support&lt;/a&gt; - TLDR: yes&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#client-examples"&gt;client examples&lt;/a&gt; - interact with copyparty using non-browser clients 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#folder-sync"&gt;folder sync&lt;/a&gt; - sync folders to/from copyparty&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#mount-as-drive"&gt;mount as drive&lt;/a&gt; - a remote copyparty server as a local filesystem&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#android-app"&gt;android app&lt;/a&gt; - upload to copyparty with one tap&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#iOS-shortcuts"&gt;iOS shortcuts&lt;/a&gt; - there is no iPhone app, but&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#performance"&gt;performance&lt;/a&gt; - defaults are usually fine - expect &lt;code&gt;8 GiB/s&lt;/code&gt; download, &lt;code&gt;1 GiB/s&lt;/code&gt; upload 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#client-side"&gt;client-side&lt;/a&gt; - when uploading files&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#security"&gt;security&lt;/a&gt; - there is a &lt;a href="https://discord.gg/25J8CdTT6G"&gt;discord server&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#gotchas"&gt;gotchas&lt;/a&gt; - behavior that might be unexpected&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#cors"&gt;cors&lt;/a&gt; - cross-site request config&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#filekeys"&gt;filekeys&lt;/a&gt; - prevent filename bruteforcing 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#dirkeys"&gt;dirkeys&lt;/a&gt; - share specific folders in a volume&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#password-hashing"&gt;password hashing&lt;/a&gt; - you can hash passwords&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#https"&gt;https&lt;/a&gt; - both HTTP and HTTPS are accepted&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#recovering-from-crashes"&gt;recovering from crashes&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#client-crashes"&gt;client crashes&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#firefox-wsod"&gt;firefox wsod&lt;/a&gt; - firefox 87 can crash during uploads&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#HTTP-API"&gt;HTTP API&lt;/a&gt; - see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/docs/devnotes.md#http-api"&gt;devnotes&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#dependencies"&gt;dependencies&lt;/a&gt; - mandatory deps 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#optional-dependencies"&gt;optional dependencies&lt;/a&gt; - install these to enable bonus features 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#dependency-chickenbits"&gt;dependency chickenbits&lt;/a&gt; - prevent loading an optional dependency&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#optional-gpl-stuff"&gt;optional gpl stuff&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#sfx"&gt;sfx&lt;/a&gt; - the self-contained "binary" (recommended!) 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#copypartyexe"&gt;copyparty.exe&lt;/a&gt; - download &lt;a href="https://github.com/9001/copyparty/releases/latest/download/copyparty.exe"&gt;copyparty.exe&lt;/a&gt; (win8+) or &lt;a href="https://github.com/9001/copyparty/releases/latest/download/copyparty32.exe"&gt;copyparty32.exe&lt;/a&gt; (win7+)&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#zipapp"&gt;zipapp&lt;/a&gt; - another emergency alternative, &lt;a href="https://github.com/9001/copyparty/releases/latest/download/copyparty.pyz"&gt;copyparty.pyz&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#install-on-android"&gt;install on android&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#install-on-iOS"&gt;install on iOS&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#reporting-bugs"&gt;reporting bugs&lt;/a&gt; - ideas for context to include, and where to submit them&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#devnotes"&gt;devnotes&lt;/a&gt; - for build instructions etc, see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/docs/devnotes.md"&gt;./docs/devnotes.md&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;quickstart&lt;/h2&gt; 
&lt;p&gt;just run &lt;strong&gt;&lt;a href="https://github.com/9001/copyparty/releases/latest/download/copyparty-sfx.py"&gt;copyparty-sfx.py&lt;/a&gt;&lt;/strong&gt; -- that's it! ğŸ‰&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;â„¹ï¸ the sfx is a &lt;a href="https://github.com/9001/copyparty/issues/270"&gt;self-extractor&lt;/a&gt; which unpacks an embedded &lt;code&gt;tar.gz&lt;/code&gt; into &lt;code&gt;$TEMP&lt;/code&gt; -- if this looks too scary, you can use the &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#zipapp"&gt;zipapp&lt;/a&gt; which has slightly worse performance&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;or install through &lt;a href="https://pypi.org/project/copyparty/"&gt;pypi&lt;/a&gt;: &lt;code&gt;python3 -m pip install --user -U copyparty&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;or if you cannot install python, you can use &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#copypartyexe"&gt;copyparty.exe&lt;/a&gt; instead&lt;/li&gt; 
 &lt;li&gt;or install &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#arch-package"&gt;on arch&lt;/a&gt; â•± &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#nixos-module"&gt;on NixOS&lt;/a&gt; â•± &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#nix-package"&gt;through nix&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;or if you are on android, &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#install-on-android"&gt;install copyparty in termux&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;or maybe an iPhone or iPad? &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#install-on-iOS"&gt;install in a-Shell on iOS&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;or maybe you have a &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/docs/synology-dsm.md"&gt;synology nas / dsm&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;or if you have &lt;a href="https://docs.astral.sh/uv/"&gt;uv&lt;/a&gt; installed, run &lt;code&gt;uv tool run copyparty&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;or if your computer is messed up and nothing else works, &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#zipapp"&gt;try the pyz&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;or if your OS is dead, give the &lt;a href="https://a.ocv.me/pub/stuff/edcd001/enterprise-edition/"&gt;bootable flashdrive / cd-rom&lt;/a&gt; a spin&lt;/li&gt; 
 &lt;li&gt;or if you don't trust copyparty yet and want to isolate it a little, then... 
  &lt;ul&gt; 
   &lt;li&gt;...maybe &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/bin/prisonparty.sh"&gt;prisonparty&lt;/a&gt; to create a tiny &lt;a href="https://wiki.archlinux.org/title/Chroot"&gt;chroot&lt;/a&gt; (very portable),&lt;/li&gt; 
   &lt;li&gt;...or &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/bin/bubbleparty.sh"&gt;bubbleparty&lt;/a&gt; to wrap it in &lt;a href="https://github.com/containers/bubblewrap"&gt;bubblewrap&lt;/a&gt; (much better)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;or if you prefer to &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/scripts/docker/"&gt;use docker&lt;/a&gt; ğŸ‹ you can do that too 
  &lt;ul&gt; 
   &lt;li&gt;docker has all deps built-in, so skip this step:&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;enable thumbnails (images/audio/video), media indexing, and audio transcoding by installing some recommended deps:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Alpine:&lt;/strong&gt; &lt;code&gt;apk add py3-pillow ffmpeg&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Debian:&lt;/strong&gt; &lt;code&gt;apt install --no-install-recommends python3-pil ffmpeg&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Fedora:&lt;/strong&gt; rpmfusion + &lt;code&gt;dnf install python3-pillow ffmpeg --allowerasing&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;FreeBSD:&lt;/strong&gt; &lt;code&gt;pkg install py39-sqlite3 py39-pillow ffmpeg&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;MacOS:&lt;/strong&gt; &lt;code&gt;port install py-Pillow ffmpeg&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;MacOS&lt;/strong&gt; (alternative): &lt;code&gt;brew install pillow ffmpeg&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Windows:&lt;/strong&gt; &lt;code&gt;python -m pip install --user -U Pillow&lt;/code&gt; 
  &lt;ul&gt; 
   &lt;li&gt;install &lt;a href="https://www.python.org/downloads/windows/"&gt;python&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#optional-dependencies"&gt;ffmpeg&lt;/a&gt; manually; do not use &lt;code&gt;winget&lt;/code&gt; or &lt;code&gt;Microsoft Store&lt;/code&gt; (it breaks $PATH)&lt;/li&gt; 
   &lt;li&gt;copyparty.exe comes with &lt;code&gt;Pillow&lt;/code&gt; and only needs &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#optional-dependencies"&gt;ffmpeg&lt;/a&gt; for mediatags/videothumbs&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#optional-dependencies"&gt;optional dependencies&lt;/a&gt; to enable even more features&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;running copyparty without arguments (for example doubleclicking it on Windows) will give everyone read/write access to the current folder; you may want &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#accounts-and-volumes"&gt;accounts and volumes&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;or see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#complete-examples"&gt;some usage examples&lt;/a&gt; for inspiration, or the &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/docs/examples/windows.md"&gt;complete windows example&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;some recommended options:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;-e2dsa&lt;/code&gt; enables general &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#file-indexing"&gt;file indexing&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-e2ts&lt;/code&gt; enables audio metadata indexing (needs either FFprobe or Mutagen)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-v /mnt/music:/music:r:rw,foo -a foo:bar&lt;/code&gt; shares &lt;code&gt;/mnt/music&lt;/code&gt; as &lt;code&gt;/music&lt;/code&gt;, &lt;code&gt;r&lt;/code&gt;eadable by anyone, and read-write for user &lt;code&gt;foo&lt;/code&gt;, password &lt;code&gt;bar&lt;/code&gt; 
  &lt;ul&gt; 
   &lt;li&gt;replace &lt;code&gt;:r:rw,foo&lt;/code&gt; with &lt;code&gt;:r,foo&lt;/code&gt; to only make the folder readable by &lt;code&gt;foo&lt;/code&gt; and nobody else&lt;/li&gt; 
   &lt;li&gt;see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#accounts-and-volumes"&gt;accounts and volumes&lt;/a&gt; (or &lt;code&gt;--help-accounts&lt;/code&gt;) for the syntax and other permissions&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;at home&lt;/h3&gt; 
&lt;p&gt;make it accessible over the internet by starting a &lt;a href="https://developers.cloudflare.com/cloudflare-one/connections/connect-networks/do-more-with-tunnels/trycloudflare/"&gt;cloudflare quicktunnel&lt;/a&gt; like so:&lt;/p&gt; 
&lt;p&gt;first download &lt;a href="https://developers.cloudflare.com/cloudflare-one/connections/connect-networks/downloads/"&gt;cloudflared&lt;/a&gt; and then start the tunnel with &lt;code&gt;cloudflared tunnel --url http://127.0.0.1:3923&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;as the tunnel starts, it will show a URL which you can share to let anyone browse your stash or upload files to you&lt;/p&gt; 
&lt;p&gt;but if you have a domain, then you probably want to skip the random autogenerated URL and instead make a &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#permanent-cloudflare-tunnel"&gt;permanent cloudflare tunnel&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;since people will be connecting through cloudflare, run copyparty with &lt;code&gt;--xff-hdr cf-connecting-ip&lt;/code&gt; to detect client IPs correctly&lt;/p&gt; 
&lt;h3&gt;on servers&lt;/h3&gt; 
&lt;p&gt;you may also want these, especially on servers:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/contrib/systemd/copyparty.service"&gt;contrib/systemd/copyparty.service&lt;/a&gt; to run copyparty as a systemd service (see guide inside)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/contrib/systemd/prisonparty.service"&gt;contrib/systemd/prisonparty.service&lt;/a&gt; to run it in a chroot (for extra security)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/contrib/openrc/copyparty"&gt;contrib/openrc/copyparty&lt;/a&gt; to run copyparty on Alpine / Gentoo&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/contrib/rc/copyparty"&gt;contrib/rc/copyparty&lt;/a&gt; to run copyparty on FreeBSD&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#nixos-module"&gt;nixos module&lt;/a&gt; to run copyparty on NixOS hosts&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/contrib/nginx/copyparty.conf"&gt;contrib/nginx/copyparty.conf&lt;/a&gt; to &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#reverse-proxy"&gt;reverse-proxy&lt;/a&gt; behind nginx (for better https)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;and remember to open the ports you want; here's a complete example including every feature copyparty has to offer:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;firewall-cmd --permanent --add-port={80,443,3921,3923,3945,3990}/tcp  # --zone=libvirt
firewall-cmd --permanent --add-port=12000-12099/tcp  # --zone=libvirt
firewall-cmd --permanent --add-port={69,1900,3969,5353}/udp  # --zone=libvirt
firewall-cmd --reload
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;(69:tftp, 1900:ssdp, 3921:ftp, 3923:http/https, 3945:smb, 3969:tftp, 3990:ftps, 5353:mdns, 12000:passive-ftp)&lt;/p&gt; 
&lt;h2&gt;features&lt;/h2&gt; 
&lt;p&gt;also see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/docs/versus.md"&gt;comparison to similar software&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;backend stuff 
  &lt;ul&gt; 
   &lt;li&gt;â˜‘ IPv6 + unix-sockets&lt;/li&gt; 
   &lt;li&gt;â˜‘ &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#performance"&gt;multiprocessing&lt;/a&gt; (actual multithreading)&lt;/li&gt; 
   &lt;li&gt;â˜‘ volumes (mountpoints)&lt;/li&gt; 
   &lt;li&gt;â˜‘ &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#accounts-and-volumes"&gt;accounts&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;â˜‘ &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#ftp-server"&gt;ftp server&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;â˜‘ &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#tftp-server"&gt;tftp server&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;â˜‘ &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#webdav-server"&gt;webdav server&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;â˜‘ &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#smb-server"&gt;smb/cifs server&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;â˜‘ &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#qr-code"&gt;qr-code&lt;/a&gt; for quick access&lt;/li&gt; 
   &lt;li&gt;â˜‘ &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#zeroconf"&gt;upnp / zeroconf / mdns / ssdp&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;â˜‘ &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#event-hooks"&gt;event hooks&lt;/a&gt; / script runner&lt;/li&gt; 
   &lt;li&gt;â˜‘ &lt;a href="https://github.com/9001/copyparty#reverse-proxy"&gt;reverse-proxy support&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;â˜‘ cross-platform (Windows, Linux, Macos, Android, iOS, FreeBSD, arm32/arm64, ppc64le, s390x, risc-v/riscv64)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;upload 
  &lt;ul&gt; 
   &lt;li&gt;â˜‘ basic: plain multipart, ie6 support&lt;/li&gt; 
   &lt;li&gt;â˜‘ &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#uploading"&gt;up2k&lt;/a&gt;: js, resumable, multithreaded 
    &lt;ul&gt; 
     &lt;li&gt;&lt;strong&gt;no filesize limit!&lt;/strong&gt; even on Cloudflare&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;â˜‘ stash: simple PUT filedropper&lt;/li&gt; 
   &lt;li&gt;â˜‘ filename randomizer&lt;/li&gt; 
   &lt;li&gt;â˜‘ write-only folders&lt;/li&gt; 
   &lt;li&gt;â˜‘ &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#unpost"&gt;unpost&lt;/a&gt;: undo/delete accidental uploads&lt;/li&gt; 
   &lt;li&gt;â˜‘ &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#self-destruct"&gt;self-destruct&lt;/a&gt; (specified server-side or client-side)&lt;/li&gt; 
   &lt;li&gt;â˜‘ &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#race-the-beam"&gt;race the beam&lt;/a&gt; (almost like peer-to-peer)&lt;/li&gt; 
   &lt;li&gt;â˜‘ symlink/discard duplicates (content-matching)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;download 
  &lt;ul&gt; 
   &lt;li&gt;â˜‘ single files in browser&lt;/li&gt; 
   &lt;li&gt;â˜‘ &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#zip-downloads"&gt;folders as zip / tar files&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;â˜‘ &lt;a href="https://github.com/9001/copyparty/tree/hovudstraum/bin#partyfusepy"&gt;FUSE client&lt;/a&gt; (read-only)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;browser 
  &lt;ul&gt; 
   &lt;li&gt;â˜‘ &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#navpane"&gt;navpane&lt;/a&gt; (directory tree sidebar)&lt;/li&gt; 
   &lt;li&gt;â˜‘ file manager (cut/paste, delete, &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#batch-rename"&gt;batch-rename&lt;/a&gt;)&lt;/li&gt; 
   &lt;li&gt;â˜‘ audio player (with &lt;a href="https://user-images.githubusercontent.com/241032/215347492-b4250797-6c90-4e09-9a4c-721edf2fb15c.png"&gt;OS media controls&lt;/a&gt; and opus/mp3 transcoding) 
    &lt;ul&gt; 
     &lt;li&gt;â˜‘ play video files as audio (converted on server)&lt;/li&gt; 
     &lt;li&gt;â˜‘ create and play &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#playlists"&gt;m3u8 playlists&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;â˜‘ image gallery with webm player&lt;/li&gt; 
   &lt;li&gt;â˜‘ &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#textfile-viewer"&gt;textfile browser&lt;/a&gt; with syntax highlighting 
    &lt;ul&gt; 
     &lt;li&gt;â˜‘ realtime streaming of growing files (logfiles and such)&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;â˜‘ &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#thumbnails"&gt;thumbnails&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;â˜‘ ...of images using Pillow, pyvips, or FFmpeg&lt;/li&gt; 
     &lt;li&gt;â˜‘ ...of RAW images using rawpy&lt;/li&gt; 
     &lt;li&gt;â˜‘ ...of videos using FFmpeg&lt;/li&gt; 
     &lt;li&gt;â˜‘ ...of audio (spectrograms) using FFmpeg&lt;/li&gt; 
     &lt;li&gt;â˜‘ cache eviction (max-age; maybe max-size eventually)&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;â˜‘ multilingual UI (english, norwegian, chinese, &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/docs/rice/#translations"&gt;add your own&lt;/a&gt;))&lt;/li&gt; 
   &lt;li&gt;â˜‘ SPA (browse while uploading)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;server indexing 
  &lt;ul&gt; 
   &lt;li&gt;â˜‘ &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#file-search"&gt;locate files by contents&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;â˜‘ search by name/path/date/size&lt;/li&gt; 
   &lt;li&gt;â˜‘ &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#searching"&gt;search by ID3-tags etc.&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;client support 
  &lt;ul&gt; 
   &lt;li&gt;â˜‘ &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#folder-sync"&gt;folder sync&lt;/a&gt; (one-way only; full sync will never be supported)&lt;/li&gt; 
   &lt;li&gt;â˜‘ &lt;a href="https://user-images.githubusercontent.com/241032/215322619-ea5fd606-3654-40ad-94ee-2bc058647bb2.png"&gt;curl-friendly&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;â˜‘ &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#opengraph"&gt;opengraph&lt;/a&gt; (discord embeds)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;markdown 
  &lt;ul&gt; 
   &lt;li&gt;â˜‘ &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#markdown-viewer"&gt;viewer&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;â˜‘ editor (sure why not)&lt;/li&gt; 
   &lt;li&gt;â˜‘ &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#markdown-vars"&gt;variables&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;PS: something missing? post any crazy ideas you've got as a &lt;a href="https://github.com/9001/copyparty/issues/new?assignees=9001&amp;amp;labels=enhancement&amp;amp;template=feature_request.md"&gt;feature request&lt;/a&gt; or &lt;a href="https://github.com/9001/copyparty/discussions/new?category=ideas"&gt;discussion&lt;/a&gt; ğŸ¤™&lt;/p&gt; 
&lt;h2&gt;testimonials&lt;/h2&gt; 
&lt;p&gt;small collection of user feedback&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;good enough&lt;/code&gt;, &lt;code&gt;surprisingly correct&lt;/code&gt;, &lt;code&gt;certified good software&lt;/code&gt;, &lt;code&gt;just works&lt;/code&gt;, &lt;code&gt;why&lt;/code&gt;, &lt;code&gt;wow this is better than nextcloud&lt;/code&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;UI Ğ¿Ñ€Ğ¾ÑÑ‚Ğ¾ ÑƒĞ¶Ğ°ÑĞ½Ğ¾. Ğ•ÑĞ»Ğ¸ Ğ±ÑƒĞ´Ñƒ Ğ¾Ğ¿Ğ¸ÑÑ‹Ğ²Ğ°Ñ‚ÑŒ Ğ´ĞµÑ‚Ğ°Ğ»ÑŒĞ½Ğ¾ Ğ½Ğµ ÑĞ¼Ğ¾Ğ³Ñƒ ÑƒĞ´ĞµÑ€Ğ¶Ğ°Ñ‚ÑŒÑÑ Ğ² Ñ€Ğ°Ğ¼ĞºĞ°Ñ… Ğ¿Ñ€Ğ¸Ğ»Ğ¸Ñ‡Ğ¸Ğ¹&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;motivations&lt;/h1&gt; 
&lt;p&gt;project goals / philosophy&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;inverse linux philosophy -- do all the things, and do an &lt;em&gt;okay&lt;/em&gt; job 
  &lt;ul&gt; 
   &lt;li&gt;quick drop-in service to get a lot of features in a pinch&lt;/li&gt; 
   &lt;li&gt;some of &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/docs/versus.md"&gt;the alternatives&lt;/a&gt; might be a better fit for you&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;run anywhere, support everything 
  &lt;ul&gt; 
   &lt;li&gt;as many web-browsers and python versions as possible 
    &lt;ul&gt; 
     &lt;li&gt;every browser should at least be able to browse, download, upload files&lt;/li&gt; 
     &lt;li&gt;be a good emergency solution for transferring stuff between ancient boxes&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;minimal dependencies 
    &lt;ul&gt; 
     &lt;li&gt;but optional dependencies adding bonus-features are ok&lt;/li&gt; 
     &lt;li&gt;everything being plaintext makes it possible to proofread for malicious code&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;no preparations / setup necessary, just run the sfx (which is also plaintext)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;adaptable, malleable, hackable 
  &lt;ul&gt; 
   &lt;li&gt;no build steps; modify the js/python without needing node.js or anything like that&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;becoming rich is specifically &lt;em&gt;not&lt;/em&gt; a motivation, but if you wanna donate then see my &lt;a href="https://github.com/9001"&gt;github profile&lt;/a&gt; regarding donations for my FOSS stuff in general (also THANKS!)&lt;/p&gt; 
&lt;h2&gt;notes&lt;/h2&gt; 
&lt;p&gt;general notes:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;paper-printing is affected by dark/light-mode! use lightmode for color, darkmode for grayscale 
  &lt;ul&gt; 
   &lt;li&gt;because no browsers currently implement the media-query to do this properly orz&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;browser-specific:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;iPhone/iPad: use Firefox to download files&lt;/li&gt; 
 &lt;li&gt;Android-Chrome: increase "parallel uploads" for higher speed (android bug)&lt;/li&gt; 
 &lt;li&gt;Android-Firefox: takes a while to select files (their fix for â˜ï¸)&lt;/li&gt; 
 &lt;li&gt;Desktop-Firefox: &lt;del&gt;may use gigabytes of RAM if your files are massive&lt;/del&gt; &lt;em&gt;seems to be OK now&lt;/em&gt;&lt;/li&gt; 
 &lt;li&gt;Desktop-Firefox: &lt;a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1792598"&gt;may stop you from unplugging USB flashdrives&lt;/a&gt; until you visit &lt;code&gt;about:memory&lt;/code&gt; and click &lt;code&gt;Minimize memory usage&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;server-os-specific:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;RHEL8 / Rocky8: you can run copyparty using &lt;code&gt;/usr/libexec/platform-python&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;server notes:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;pypy is supported but regular cpython is faster if you enable the database&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;bugs&lt;/h1&gt; 
&lt;p&gt;roughly sorted by chance of encounter&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;general:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;--th-ff-jpg&lt;/code&gt; may fix video thumbnails on some FFmpeg versions (macos, some linux)&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;--th-ff-swr&lt;/code&gt; may fix audio thumbnails on some FFmpeg versions&lt;/li&gt; 
   &lt;li&gt;if the &lt;code&gt;up2k.db&lt;/code&gt; (filesystem index) is on a samba-share or network disk, you'll get unpredictable behavior if the share is disconnected for a bit 
    &lt;ul&gt; 
     &lt;li&gt;use &lt;code&gt;--hist&lt;/code&gt; or the &lt;code&gt;hist&lt;/code&gt; volflag (&lt;code&gt;-v [...]:c,hist=/tmp/foo&lt;/code&gt;) to place the db and thumbnails on a local disk instead&lt;/li&gt; 
     &lt;li&gt;or, if you only want to move the db (and not the thumbnails), then use &lt;code&gt;--dbpath&lt;/code&gt; or the &lt;code&gt;dbpath&lt;/code&gt; volflag&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;all volumes must exist / be available on startup; up2k (mtp especially) gets funky otherwise&lt;/li&gt; 
   &lt;li&gt;probably more, pls let me know&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;python 3.4 and older (including 2.7):&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;many rare and exciting edge-cases because &lt;a href="https://peps.python.org/pep-0475/"&gt;python didn't handle EINTR yet&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;downloads from copyparty may suddenly fail, but uploads &lt;em&gt;should&lt;/em&gt; be fine&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;python 2.7 on Windows:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;cannot index non-ascii filenames with &lt;code&gt;-e2d&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;cannot handle filenames with mojibake&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;if you have a new exciting bug to share, see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#reporting-bugs"&gt;reporting bugs&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;not my bugs&lt;/h2&gt; 
&lt;p&gt;same order here too&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://bugs.chromium.org/p/chromium/issues/detail?id=1317069"&gt;Chrome issue 1317069&lt;/a&gt; -- if you try to upload a folder which contains symlinks by dragging it into the browser, the symlinked files will not get uploaded&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://bugs.chromium.org/p/chromium/issues/detail?id=1352210"&gt;Chrome issue 1352210&lt;/a&gt; -- plaintext http may be faster at filehashing than https (but also extremely CPU-intensive)&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://issues.chromium.org/issues/383568268"&gt;Chrome issue 383568268&lt;/a&gt; -- filereaders in webworkers can OOM / crash the browser-tab&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;copyparty has a workaround which seems to work well enough&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1790500"&gt;Firefox issue 1790500&lt;/a&gt; -- entire browser can crash after uploading ~4000 small files&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Android: music playback randomly stops due to &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#fix-unreliable-playback-on-android"&gt;battery usage settings&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;iPhones: the volume control doesn't work because &lt;a href="https://developer.apple.com/library/archive/documentation/AudioVideo/Conceptual/Using_HTML5_Audio_Video/Device-SpecificConsiderations/Device-SpecificConsiderations.html#//apple_ref/doc/uid/TP40009523-CH5-SW11"&gt;apple doesn't want it to&lt;/a&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;AudioContext&lt;/code&gt; will probably never be a viable workaround as apple introduces new issues faster than they fix current ones&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;iPhones: music volume goes on a rollercoaster during song changes&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;nothing I can do about it because &lt;code&gt;AudioContext&lt;/code&gt; is still broken in safari&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;iPhones: the preload feature (in the media-player-options tab) can cause a tiny audio glitch 20sec before the end of each song, but disabling it may cause worse iOS bugs to appear instead&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;just a hunch, but disabling preloading may cause playback to stop entirely, or possibly mess with bluetooth speakers&lt;/li&gt; 
   &lt;li&gt;tried to add a tooltip regarding this but looks like apple broke my tooltips&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;iPhones: preloaded awo files make safari log MEDIA_ERR_NETWORK errors as playback starts, but the song plays just fine so eh whatever&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;awo, opus-weba, is apple's new take on opus support, replacing opus-caf which was technically limited to cbr opus&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;iPhones: preloading another awo file may cause playback to stop&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;can be somewhat mitigated with &lt;code&gt;mp.au.play()&lt;/code&gt; in &lt;code&gt;mp.onpreload&lt;/code&gt; but that can hit a race condition in safari that starts playing the same audio object twice in parallel...&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Windows: folders cannot be accessed if the name ends with &lt;code&gt;.&lt;/code&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;python or windows bug&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Windows: msys2-python 3.8.6 occasionally throws &lt;code&gt;RuntimeError: release unlocked lock&lt;/code&gt; when leaving a scoped mutex in up2k&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;this is an msys2 bug, the regular windows edition of python is fine&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;VirtualBox: sqlite throws &lt;code&gt;Disk I/O Error&lt;/code&gt; when running in a VM and the up2k database is in a vboxsf&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;use &lt;code&gt;--hist&lt;/code&gt; or the &lt;code&gt;hist&lt;/code&gt; volflag (&lt;code&gt;-v [...]:c,hist=/tmp/foo&lt;/code&gt;) to place the db and thumbnails inside the vm instead 
    &lt;ul&gt; 
     &lt;li&gt;or, if you only want to move the db (and not the thumbnails), then use &lt;code&gt;--dbpath&lt;/code&gt; or the &lt;code&gt;dbpath&lt;/code&gt; volflag&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;also happens on mergerfs, so put the db elsewhere&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Ubuntu: dragging files from certain folders into firefox or chrome is impossible&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;due to snap security policies -- see &lt;code&gt;snap connections firefox&lt;/code&gt; for the allowlist, &lt;code&gt;removable-media&lt;/code&gt; permits all of &lt;code&gt;/mnt&lt;/code&gt; and &lt;code&gt;/media&lt;/code&gt; apparently&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;breaking changes&lt;/h1&gt; 
&lt;p&gt;upgrade notes&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;1.9.16&lt;/code&gt; (2023-11-04): 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;--stats&lt;/code&gt;/prometheus: &lt;code&gt;cpp_bans&lt;/code&gt; renamed to &lt;code&gt;cpp_active_bans&lt;/code&gt;, and that + &lt;code&gt;cpp_uptime&lt;/code&gt; are gauges&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;1.6.0&lt;/code&gt; (2023-01-29): 
  &lt;ul&gt; 
   &lt;li&gt;http-api: delete/move is now &lt;code&gt;POST&lt;/code&gt; instead of &lt;code&gt;GET&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;everything other than &lt;code&gt;GET&lt;/code&gt; and &lt;code&gt;HEAD&lt;/code&gt; must pass &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#cors"&gt;cors validation&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;1.5.0&lt;/code&gt; (2022-12-03): &lt;a href="https://github.com/9001/copyparty/commit/54e1c8d261df"&gt;new chunksize formula&lt;/a&gt; for files larger than 128 GiB 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;users:&lt;/strong&gt; upgrade to the latest &lt;a href="https://github.com/9001/copyparty/raw/hovudstraum/bin/u2c.py"&gt;cli uploader&lt;/a&gt; if you use that&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;devs:&lt;/strong&gt; update third-party up2k clients (if those even exist)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;FAQ&lt;/h1&gt; 
&lt;p&gt;"frequently" asked questions&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;CopyParty?&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;nope! the name is either copyparty (all-lowercase) or Copyparty -- it's &lt;a href="https://en.wiktionary.org/wiki/copyparty"&gt;one word&lt;/a&gt; after all :&amp;gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;can I change the ğŸŒ² spinning pine-tree loading animation?&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/9001/copyparty/tree/hovudstraum/docs/rice#boring-loader-spinner"&gt;yeah...&lt;/a&gt; :-(&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;is it possible to block read-access to folders unless you know the exact URL for a particular file inside?&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;yes, using the &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#accounts-and-volumes"&gt;&lt;code&gt;g&lt;/code&gt; permission&lt;/a&gt;, see the examples there&lt;/li&gt; 
   &lt;li&gt;you can also do this with linux filesystem permissions; &lt;code&gt;chmod 111 music&lt;/code&gt; will make it possible to access files and folders inside the &lt;code&gt;music&lt;/code&gt; folder but not list the immediate contents -- also works with other software, not just copyparty&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;can I link someone to a password-protected volume/file by including the password in the URL?&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;yes, by adding &lt;code&gt;?pw=hunter2&lt;/code&gt; to the end; replace &lt;code&gt;?&lt;/code&gt; with &lt;code&gt;&amp;amp;&lt;/code&gt; if there are parameters in the URL already, meaning it contains a &lt;code&gt;?&lt;/code&gt; near the end 
    &lt;ul&gt; 
     &lt;li&gt;if you have enabled &lt;code&gt;--usernames&lt;/code&gt; then do &lt;code&gt;?pw=username:password&lt;/code&gt; instead&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;how do I stop &lt;code&gt;.hist&lt;/code&gt; folders from appearing everywhere on my HDD?&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;by default, a &lt;code&gt;.hist&lt;/code&gt; folder is created inside each volume for the filesystem index, thumbnails, audio transcodes, and markdown document history. Use the &lt;code&gt;--hist&lt;/code&gt; global-option or the &lt;code&gt;hist&lt;/code&gt; volflag to move it somewhere else; see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#database-location"&gt;database location&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;can I make copyparty download a file to my server if I give it a URL?&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;yes, using &lt;a href="https://github.com/9001/copyparty/raw/hovudstraum/bin/hooks/wget.py"&gt;hooks&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;firefox refuses to connect over https, saying "Secure Connection Failed" or "SEC_ERROR_BAD_SIGNATURE", but the usual button to "Accept the Risk and Continue" is not shown&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;firefox has corrupted its certstore; fix this by exiting firefox, then find and delete the file named &lt;code&gt;cert9.db&lt;/code&gt; somewhere in your firefox profile folder&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;the server keeps saying &lt;code&gt;thank you for playing&lt;/code&gt; when I try to access the website&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;you've gotten banned for malicious traffic! if this happens by mistake, and you're running a reverse-proxy and/or something like cloudflare, see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#real-ip"&gt;real-ip&lt;/a&gt; on how to fix this&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;copyparty seems to think I am using http, even though the URL is https&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;your reverse-proxy is not sending the &lt;code&gt;X-Forwarded-Proto: https&lt;/code&gt; header; this could be because your reverse-proxy itself is confused. Ensure that none of the intermediates (such as cloudflare) are terminating https before the traffic hits your entrypoint&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;thumbnails are broken (you get a colorful square which says the filetype instead)&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;you need to install &lt;code&gt;FFmpeg&lt;/code&gt; or &lt;code&gt;Pillow&lt;/code&gt;; see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#thumbnails"&gt;thumbnails&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;thumbnails are broken (some images appear, but other files just get a blank box, and/or the broken-image placeholder)&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;probably due to a reverse-proxy messing with the request URLs and stripping the query parameters (&lt;code&gt;?th=w&lt;/code&gt;), so check your URL rewrite rules&lt;/li&gt; 
   &lt;li&gt;could also be due to incorrect caching settings in reverse-proxies and/or CDNs, so make sure that nothing is set to ignore the query string&lt;/li&gt; 
   &lt;li&gt;could also be due to misbehaving privacy-related browser extensions, so try to disable those&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;i want to learn python and/or programming and am considering looking at the copyparty source code in that occasion&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;pre&gt;&lt;code class="language-bash"&gt; _|  _      __   _  _|_
(_| (_)     | | (_)  |_
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;accounts and volumes&lt;/h1&gt; 
&lt;p&gt;per-folder, per-user permissions - if your setup is getting complex, consider making a &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/docs/example.conf"&gt;config file&lt;/a&gt; instead of using arguments&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;much easier to manage, and you can modify the config at runtime with &lt;code&gt;systemctl reload copyparty&lt;/code&gt; or more conveniently using the &lt;code&gt;[reload cfg]&lt;/code&gt; button in the control-panel (if the user has &lt;code&gt;a&lt;/code&gt;/admin in any volume) 
  &lt;ul&gt; 
   &lt;li&gt;changes to the &lt;code&gt;[global]&lt;/code&gt; config section requires a restart to take effect&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;a quick summary can be seen using &lt;code&gt;--help-accounts&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;configuring accounts/volumes with arguments:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;-a usr:pwd&lt;/code&gt; adds account &lt;code&gt;usr&lt;/code&gt; with password &lt;code&gt;pwd&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-v .::r&lt;/code&gt; adds current-folder &lt;code&gt;.&lt;/code&gt; as the webroot, &lt;code&gt;r&lt;/code&gt;eadable by anyone 
  &lt;ul&gt; 
   &lt;li&gt;the syntax is &lt;code&gt;-v src:dst:perm:perm:...&lt;/code&gt; so local-path, url-path, and one or more permissions to set&lt;/li&gt; 
   &lt;li&gt;granting the same permissions to multiple accounts:&lt;br /&gt; &lt;code&gt;-v .::r,usr1,usr2:rw,usr3,usr4&lt;/code&gt; = usr1/2 read-only, 3/4 read-write&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;permissions:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;r&lt;/code&gt; (read): browse folder contents, download files, download as zip/tar, see filekeys/dirkeys&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;w&lt;/code&gt; (write): upload files, move/copy files &lt;em&gt;into&lt;/em&gt; this folder&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;m&lt;/code&gt; (move): move files/folders &lt;em&gt;from&lt;/em&gt; this folder&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;d&lt;/code&gt; (delete): delete files/folders&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;.&lt;/code&gt; (dots): user can ask to show dotfiles in directory listings&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;g&lt;/code&gt; (get): only download files, cannot see folder contents or zip/tar&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;G&lt;/code&gt; (upget): same as &lt;code&gt;g&lt;/code&gt; except uploaders get to see their own &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#filekeys"&gt;filekeys&lt;/a&gt; (see &lt;code&gt;fk&lt;/code&gt; in examples below)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;h&lt;/code&gt; (html): same as &lt;code&gt;g&lt;/code&gt; except folders return their index.html, and filekeys are not necessary for index.html&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;a&lt;/code&gt; (admin): can see upload time, uploader IPs, config-reload&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;A&lt;/code&gt; ("all"): same as &lt;code&gt;rwmda.&lt;/code&gt; (read/write/move/delete/admin/dotfiles)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;examples:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;add accounts named u1, u2, u3 with passwords p1, p2, p3: &lt;code&gt;-a u1:p1 -a u2:p2 -a u3:p3&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;make folder &lt;code&gt;/srv&lt;/code&gt; the root of the filesystem, read-only by anyone: &lt;code&gt;-v /srv::r&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;make folder &lt;code&gt;/mnt/music&lt;/code&gt; available at &lt;code&gt;/music&lt;/code&gt;, read-only for u1 and u2, read-write for u3: &lt;code&gt;-v /mnt/music:music:r,u1,u2:rw,u3&lt;/code&gt; 
  &lt;ul&gt; 
   &lt;li&gt;unauthorized users accessing the webroot can see that the &lt;code&gt;music&lt;/code&gt; folder exists, but cannot open it&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;make folder &lt;code&gt;/mnt/incoming&lt;/code&gt; available at &lt;code&gt;/inc&lt;/code&gt;, write-only for u1, read-move for u2: &lt;code&gt;-v /mnt/incoming:inc:w,u1:rm,u2&lt;/code&gt; 
  &lt;ul&gt; 
   &lt;li&gt;unauthorized users accessing the webroot can see that the &lt;code&gt;inc&lt;/code&gt; folder exists, but cannot open it&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;u1&lt;/code&gt; can open the &lt;code&gt;inc&lt;/code&gt; folder, but cannot see the contents, only upload new files to it&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;u2&lt;/code&gt; can browse it and move files &lt;em&gt;from&lt;/em&gt; &lt;code&gt;/inc&lt;/code&gt; into any folder where &lt;code&gt;u2&lt;/code&gt; has write-access&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;make folder &lt;code&gt;/mnt/ss&lt;/code&gt; available at &lt;code&gt;/i&lt;/code&gt;, read-write for u1, get-only for everyone else, and enable filekeys: &lt;code&gt;-v /mnt/ss:i:rw,u1:g:c,fk=4&lt;/code&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;c,fk=4&lt;/code&gt; sets the &lt;code&gt;fk&lt;/code&gt; (&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#filekeys"&gt;filekey&lt;/a&gt;) volflag to 4, meaning each file gets a 4-character accesskey&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;u1&lt;/code&gt; can upload files, browse the folder, and see the generated filekeys&lt;/li&gt; 
   &lt;li&gt;other users cannot browse the folder, but can access the files if they have the full file URL with the filekey&lt;/li&gt; 
   &lt;li&gt;replacing the &lt;code&gt;g&lt;/code&gt; permission with &lt;code&gt;wg&lt;/code&gt; would let anonymous users upload files, but not see the required filekey to access it&lt;/li&gt; 
   &lt;li&gt;replacing the &lt;code&gt;g&lt;/code&gt; permission with &lt;code&gt;wG&lt;/code&gt; would let anonymous users upload files, receiving a working direct link in return&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;if you want to grant access to all users who are logged in, the group &lt;code&gt;acct&lt;/code&gt; will always contain all known users, so for example &lt;code&gt;-v /mnt/music:music:r,@acct&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;anyone trying to bruteforce a password gets banned according to &lt;code&gt;--ban-pw&lt;/code&gt;; default is 24h ban for 9 failed attempts in 1 hour&lt;/p&gt; 
&lt;p&gt;and if you want to use config files instead of commandline args (good!) then here's the same examples as a configfile; save it as &lt;code&gt;foobar.conf&lt;/code&gt; and use it like this: &lt;code&gt;python copyparty-sfx.py -c foobar.conf&lt;/code&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;you can also &lt;code&gt;PRTY_CONFIG=foobar.conf python copyparty-sfx.py&lt;/code&gt; (convenient in docker etc)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;[accounts]
  u1: p1  # create account "u1" with password "p1"
  u2: p2  #  (note that comments must have
  u3: p3  #   two spaces before the # sign)

[groups]
  g1: u1, u2  # create a group

[/]     # this URL will be mapped to...
  /srv  # ...this folder on the server filesystem
  accs:
    r: *  # read-only for everyone, no account necessary

[/music]       # create another volume at this URL,
  /mnt/music   # which is mapped to this folder
  accs:
    r: u1, u2  # only these accounts can read,
    r: @g1     # (exactly the same, just with a group instead)
    r: @acct   # (alternatively, ALL users who are logged in)
    rw: u3     # and only u3 can read-write

[/inc]
  /mnt/incoming
  accs:
    w: u1   # u1 can upload but not see/download any files,
    rm: u2  # u2 can browse + move files out of this volume

[/i]
  /mnt/ss
  accs:
    rw: u1  # u1 can read-write,
    g: *    # everyone can access files if they know the URL
  flags:
    fk: 4   # each file URL will have a 4-character password
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;shadowing&lt;/h2&gt; 
&lt;p&gt;hiding specific subfolders by mounting another volume on top of them&lt;/p&gt; 
&lt;p&gt;for example &lt;code&gt;-v /mnt::r -v /var/empty:web/certs:r&lt;/code&gt; mounts the server folder &lt;code&gt;/mnt&lt;/code&gt; as the webroot, but another volume is mounted at &lt;code&gt;/web/certs&lt;/code&gt; -- so visitors can only see the contents of &lt;code&gt;/mnt&lt;/code&gt; and &lt;code&gt;/mnt/web&lt;/code&gt; (at URLs &lt;code&gt;/&lt;/code&gt; and &lt;code&gt;/web&lt;/code&gt;), but not &lt;code&gt;/mnt/web/certs&lt;/code&gt; because URL &lt;code&gt;/web/certs&lt;/code&gt; is mapped to &lt;code&gt;/var/empty&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;the example config file right above this section may explain this better; the first volume &lt;code&gt;/&lt;/code&gt; is mapped to &lt;code&gt;/srv&lt;/code&gt; which means &lt;a href="http://127.0.0.1:3923/music"&gt;http://127.0.0.1:3923/music&lt;/a&gt; would try to read &lt;code&gt;/srv/music&lt;/code&gt; on the server filesystem, but since there's another volume at &lt;code&gt;/music&lt;/code&gt; mapped to &lt;code&gt;/mnt/music&lt;/code&gt; then it'll go to &lt;code&gt;/mnt/music&lt;/code&gt; instead&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;â„¹ï¸ this also works for single files, because files can also be volumes&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;dotfiles&lt;/h2&gt; 
&lt;p&gt;unix-style hidden files/folders by starting the name with a dot&lt;/p&gt; 
&lt;p&gt;anyone can access these if they know the name, but they normally don't appear in directory listings&lt;/p&gt; 
&lt;p&gt;a client can request to see dotfiles in directory listings if global option &lt;code&gt;-ed&lt;/code&gt; is specified, or the volume has volflag &lt;code&gt;dots&lt;/code&gt;, or the user has permission &lt;code&gt;.&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;dotfiles do not appear in search results unless one of the above is true, &lt;strong&gt;and&lt;/strong&gt; the global option / volflag &lt;code&gt;dotsrch&lt;/code&gt; is set&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;even if user has permission to see dotfiles, they are default-hidden unless &lt;code&gt;--see-dots&lt;/code&gt; is set, and/or user has enabled the &lt;code&gt;dotfiles&lt;/code&gt; option in the settings tab&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;config file example, where the same permission to see dotfiles is given in two different ways just for reference:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;[/foo]
  /srv/foo
  accs:
    r.: ed   # user "ed" has read-access + dot-access in this volume;
             # dotfiles are visible in listings, but not in searches
  flags:
    dotsrch  # dotfiles will now appear in search results too
    dots     # another way to let everyone see dotfiles in this vol
&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;the browser&lt;/h1&gt; 
&lt;p&gt;accessing a copyparty server using a web-browser&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://user-images.githubusercontent.com/241032/192042695-522b3ec7-6845-494a-abdb-d1c0d0e23801.png" alt="copyparty-browser-fs8" /&gt;&lt;/p&gt; 
&lt;h2&gt;tabs&lt;/h2&gt; 
&lt;p&gt;the main tabs in the ui&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;[ğŸ”]&lt;/code&gt; &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#searching"&gt;search&lt;/a&gt; by size, date, path/name, mp3-tags ...&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[ğŸ§¯]&lt;/code&gt; &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#unpost"&gt;unpost&lt;/a&gt;: undo/delete accidental uploads&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[ğŸš€]&lt;/code&gt; and &lt;code&gt;[ğŸˆ]&lt;/code&gt; are the &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#uploading"&gt;uploaders&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[ğŸ“‚]&lt;/code&gt; mkdir: create directories&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[ğŸ“]&lt;/code&gt; new-md: create a new markdown document&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[ğŸ“Ÿ]&lt;/code&gt; send-msg: either to server-log or into textfiles if &lt;code&gt;--urlform save&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[ğŸº]&lt;/code&gt; audio-player config options&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[âš™ï¸]&lt;/code&gt; general client config options&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;hotkeys&lt;/h2&gt; 
&lt;p&gt;the browser has the following hotkeys (always qwerty)&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;?&lt;/code&gt; show hotkeys help&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;B&lt;/code&gt; toggle breadcrumbs / &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#navpane"&gt;navpane&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;I/K&lt;/code&gt; prev/next folder&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;M&lt;/code&gt; parent folder (or unexpand current)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;V&lt;/code&gt; toggle folders / textfiles in the navpane&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;G&lt;/code&gt; toggle list / &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#thumbnails"&gt;grid view&lt;/a&gt; -- same as &lt;code&gt;ç”°&lt;/code&gt; bottom-right&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;T&lt;/code&gt; toggle thumbnails / icons&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;ESC&lt;/code&gt; close various things&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;ctrl-K&lt;/code&gt; delete selected files/folders&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;ctrl-X&lt;/code&gt; cut selected files/folders&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;ctrl-C&lt;/code&gt; copy selected files/folders to clipboard&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;ctrl-V&lt;/code&gt; paste (move/copy)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;Y&lt;/code&gt; download selected files&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;F2&lt;/code&gt; &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#batch-rename"&gt;rename&lt;/a&gt; selected file/folder&lt;/li&gt; 
 &lt;li&gt;when a file/folder is selected (in not-grid-view): 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;Up/Down&lt;/code&gt; move cursor&lt;/li&gt; 
   &lt;li&gt;shift+&lt;code&gt;Up/Down&lt;/code&gt; select and move cursor&lt;/li&gt; 
   &lt;li&gt;ctrl+&lt;code&gt;Up/Down&lt;/code&gt; move cursor and scroll viewport&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;Space&lt;/code&gt; toggle file selection&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;Ctrl-A&lt;/code&gt; toggle select all&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;when a textfile is open: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;I/K&lt;/code&gt; prev/next textfile&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;S&lt;/code&gt; toggle selection of open file&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;M&lt;/code&gt; close textfile&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;when playing audio: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;J/L&lt;/code&gt; prev/next song&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;U/O&lt;/code&gt; skip 10sec back/forward&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;0..9&lt;/code&gt; jump to 0%..90%&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;P&lt;/code&gt; play/pause (also starts playing the folder)&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;Y&lt;/code&gt; download file&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;when viewing images / playing videos: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;J/L, Left/Right&lt;/code&gt; prev/next file&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;Home/End&lt;/code&gt; first/last file&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;F&lt;/code&gt; toggle fullscreen&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;S&lt;/code&gt; toggle selection&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;R&lt;/code&gt; rotate clockwise (shift=ccw)&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;Y&lt;/code&gt; download file&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;Esc&lt;/code&gt; close viewer&lt;/li&gt; 
   &lt;li&gt;videos: 
    &lt;ul&gt; 
     &lt;li&gt;&lt;code&gt;U/O&lt;/code&gt; skip 10sec back/forward&lt;/li&gt; 
     &lt;li&gt;&lt;code&gt;0..9&lt;/code&gt; jump to 0%..90%&lt;/li&gt; 
     &lt;li&gt;&lt;code&gt;P/K/Space&lt;/code&gt; play/pause&lt;/li&gt; 
     &lt;li&gt;&lt;code&gt;M&lt;/code&gt; mute&lt;/li&gt; 
     &lt;li&gt;&lt;code&gt;C&lt;/code&gt; continue playing next video&lt;/li&gt; 
     &lt;li&gt;&lt;code&gt;V&lt;/code&gt; loop entire file&lt;/li&gt; 
     &lt;li&gt;&lt;code&gt;[&lt;/code&gt; loop range (start)&lt;/li&gt; 
     &lt;li&gt;&lt;code&gt;]&lt;/code&gt; loop range (end)&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;when the navpane is open: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;A/D&lt;/code&gt; adjust tree width&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;in the &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#thumbnails"&gt;grid view&lt;/a&gt;: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;S&lt;/code&gt; toggle multiselect&lt;/li&gt; 
   &lt;li&gt;shift+&lt;code&gt;A/D&lt;/code&gt; zoom&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;in the markdown editor: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;^s&lt;/code&gt; save&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;^h&lt;/code&gt; header&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;^k&lt;/code&gt; autoformat table&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;^u&lt;/code&gt; jump to next unicode character&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;^e&lt;/code&gt; toggle editor / preview&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;^up, ^down&lt;/code&gt; jump paragraphs&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;navpane&lt;/h2&gt; 
&lt;p&gt;switching between breadcrumbs or navpane&lt;/p&gt; 
&lt;p&gt;click the &lt;code&gt;ğŸŒ²&lt;/code&gt; or pressing the &lt;code&gt;B&lt;/code&gt; hotkey to toggle between breadcrumbs path (default), or a navpane (tree-browser sidebar thing)&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;[+]&lt;/code&gt; and &lt;code&gt;[-]&lt;/code&gt; (or hotkeys &lt;code&gt;A&lt;/code&gt;/&lt;code&gt;D&lt;/code&gt;) adjust the size&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[ğŸ¯]&lt;/code&gt; jumps to the currently open folder&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[ğŸ“ƒ]&lt;/code&gt; toggles between showing folders and textfiles&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[ğŸ“Œ]&lt;/code&gt; shows the name of all parent folders in a docked panel&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[a]&lt;/code&gt; toggles automatic widening as you go deeper&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[â†µ]&lt;/code&gt; toggles wordwrap&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[ğŸ‘€]&lt;/code&gt; show full name on hover (if wordwrap is off)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;thumbnails&lt;/h2&gt; 
&lt;p&gt;press &lt;code&gt;g&lt;/code&gt; or &lt;code&gt;ç”°&lt;/code&gt; to toggle grid-view instead of the file listing and &lt;code&gt;t&lt;/code&gt; toggles icons / thumbnails&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;can be made default globally with &lt;code&gt;--grid&lt;/code&gt; or per-volume with volflag &lt;code&gt;grid&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;enable by adding &lt;code&gt;?imgs&lt;/code&gt; to a link, or disable with &lt;code&gt;?imgs=0&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://user-images.githubusercontent.com/241032/129636211-abd20fa2-a953-4366-9423-1c88ebb96ba9.png" alt="copyparty-thumbs-fs8" /&gt;&lt;/p&gt; 
&lt;p&gt;it does static images with Pillow / pyvips / FFmpeg, and uses FFmpeg for video files, so you may want to &lt;code&gt;--no-thumb&lt;/code&gt; or maybe just &lt;code&gt;--no-vthumb&lt;/code&gt; depending on how dangerous your users are&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;pyvips is 3x faster than Pillow, Pillow is 3x faster than FFmpeg&lt;/li&gt; 
 &lt;li&gt;disable thumbnails for specific volumes with volflag &lt;code&gt;dthumb&lt;/code&gt; for all, or &lt;code&gt;dvthumb&lt;/code&gt; / &lt;code&gt;dathumb&lt;/code&gt; / &lt;code&gt;dithumb&lt;/code&gt; for video/audio/images only&lt;/li&gt; 
 &lt;li&gt;for installing FFmpeg on windows, see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#optional-dependencies"&gt;optional dependencies&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;audio files are converted into spectrograms using FFmpeg unless you &lt;code&gt;--no-athumb&lt;/code&gt; (and some FFmpeg builds may need &lt;code&gt;--th-ff-swr&lt;/code&gt;)&lt;/p&gt; 
&lt;p&gt;images with the following names (see &lt;code&gt;--th-covers&lt;/code&gt;) become the thumbnail of the folder they're in: &lt;code&gt;folder.png&lt;/code&gt;, &lt;code&gt;folder.jpg&lt;/code&gt;, &lt;code&gt;cover.png&lt;/code&gt;, &lt;code&gt;cover.jpg&lt;/code&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;the order is significant, so if both &lt;code&gt;cover.png&lt;/code&gt; and &lt;code&gt;folder.jpg&lt;/code&gt; exist in a folder, it will pick the first matching &lt;code&gt;--th-covers&lt;/code&gt; entry (&lt;code&gt;folder.jpg&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;and, if you enable &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#file-indexing"&gt;file indexing&lt;/a&gt;, it will also try those names as dotfiles (&lt;code&gt;.folder.jpg&lt;/code&gt; and so), and then fallback on the first picture in the folder (if it has any pictures at all)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;enabling &lt;code&gt;multiselect&lt;/code&gt; lets you click files to select them, and then shift-click another file for range-select&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;multiselect&lt;/code&gt; is mostly intended for phones/tablets, but the &lt;code&gt;sel&lt;/code&gt; option in the &lt;code&gt;[âš™ï¸] settings&lt;/code&gt; tab is better suited for desktop use, allowing selection by CTRL-clicking and range-selection with SHIFT-click, all without affecting regular clicking 
  &lt;ul&gt; 
   &lt;li&gt;the &lt;code&gt;sel&lt;/code&gt; option can be made default globally with &lt;code&gt;--gsel&lt;/code&gt; or per-volume with volflag &lt;code&gt;gsel&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;to show &lt;code&gt;/icons/exe.png&lt;/code&gt; and &lt;code&gt;/icons/elf.gif&lt;/code&gt; as the thumbnail for all &lt;code&gt;.exe&lt;/code&gt; and &lt;code&gt;.elf&lt;/code&gt; files respectively, do this: &lt;code&gt;--ext-th=exe=/icons/exe.png --ext-th=elf=/icons/elf.gif&lt;/code&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;optionally as separate volflags for each mapping; see config file example below&lt;/li&gt; 
 &lt;li&gt;the supported image formats are &lt;a href="https://developer.mozilla.org/en-US/docs/Web/Media/Guides/Formats/Image_types"&gt;jpg, png, gif, webp, ico&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;be careful with svg; chrome will crash if you have too many unique svg files showing on the same page (the limit is 250 or so) -- showing the same handful of svg files thousands of times is ok however&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;config file example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;[global]
  no-thumb   # disable ALL thumbnails and audio transcoding
  no-vthumb  # only disable video thumbnails

[/music]
  /mnt/nas/music
  accs:
    r: *     # everyone can read
  flags:
    dthumb   # disable ALL thumbnails and audio transcoding
    dvthumb  # only disable video thumbnails
    ext-th:  exe=/ico/exe.png  # /ico/exe.png is the thumbnail of *.exe
    ext-th:  elf=/ico/elf.gif  # ...and /ico/elf.gif is used for *.elf
    th-covers:  folder.png,folder.jpg,cover.png,cover.jpg  # the default
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;zip downloads&lt;/h2&gt; 
&lt;p&gt;download folders (or file selections) as &lt;code&gt;zip&lt;/code&gt; or &lt;code&gt;tar&lt;/code&gt; files&lt;/p&gt; 
&lt;p&gt;select which type of archive you want in the &lt;code&gt;[âš™ï¸] config&lt;/code&gt; tab:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;name&lt;/th&gt; 
   &lt;th&gt;url-suffix&lt;/th&gt; 
   &lt;th&gt;description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;tar&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;?tar&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;plain gnutar, works great with &lt;code&gt;curl | tar -xv&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;pax&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;?tar=pax&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;pax-format tar, futureproof, not as fast&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;tgz&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;?tar=gz&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;gzip compressed gnu-tar (slow), for &lt;code&gt;curl | tar -xvz&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;txz&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;?tar=xz&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;gnu-tar with xz / lzma compression (v.slow)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;zip&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;?zip&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;works everywhere, glitchy filenames on win7 and older&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;zip_dos&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;?zip=dos&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;traditional cp437 (no unicode) to fix glitchy filenames&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;zip_crc&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;?zip=crc&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;cp437 with crc32 computed early for truly ancient software&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;ul&gt; 
 &lt;li&gt;gzip default level is &lt;code&gt;3&lt;/code&gt; (0=fast, 9=best), change with &lt;code&gt;?tar=gz:9&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;xz default level is &lt;code&gt;1&lt;/code&gt; (0=fast, 9=best), change with &lt;code&gt;?tar=xz:9&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;bz2 default level is &lt;code&gt;2&lt;/code&gt; (1=fast, 9=best), change with &lt;code&gt;?tar=bz2:9&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;hidden files (&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#dotfiles"&gt;dotfiles&lt;/a&gt;) are excluded unless account is allowed to list them 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;up2k.db&lt;/code&gt; and &lt;code&gt;dir.txt&lt;/code&gt; is always excluded&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;bsdtar supports streaming unzipping: &lt;code&gt;curl foo?zip | bsdtar -xv&lt;/code&gt; 
  &lt;ul&gt; 
   &lt;li&gt;good, because copyparty's zip is faster than tar on small files 
    &lt;ul&gt; 
     &lt;li&gt;but &lt;code&gt;?tar&lt;/code&gt; is better for large files, especially if the total exceeds 4 GiB&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;zip_crc&lt;/code&gt; will take longer to download since the server has to read each file twice 
  &lt;ul&gt; 
   &lt;li&gt;this is only to support MS-DOS PKZIP v2.04g (october 1993) and older 
    &lt;ul&gt; 
     &lt;li&gt;how are you accessing copyparty actually&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;you can also zip a selection of files or folders by clicking them in the browser, that brings up a selection editor and zip button in the bottom right&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://user-images.githubusercontent.com/241032/129635374-e5136e01-470a-49b1-a762-848e8a4c9cdc.png" alt="copyparty-zipsel-fs8" /&gt;&lt;/p&gt; 
&lt;p&gt;cool trick: download a folder by appending url-params &lt;code&gt;?tar&amp;amp;opus&lt;/code&gt; or &lt;code&gt;?tar&amp;amp;mp3&lt;/code&gt; to transcode all audio files (except aac|m4a|mp3|ogg|opus|wma) to opus/mp3 before they're added to the archive&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;super useful if you're 5 minutes away from takeoff and realize you don't have any music on your phone but your server only has flac files and downloading those will burn through all your data + there wouldn't be enough time anyways&lt;/li&gt; 
 &lt;li&gt;and url-params &lt;code&gt;&amp;amp;j&lt;/code&gt; / &lt;code&gt;&amp;amp;w&lt;/code&gt; produce jpeg/webm thumbnails/spectrograms instead of the original audio/video/images (&lt;code&gt;&amp;amp;p&lt;/code&gt; for audio waveforms) 
  &lt;ul&gt; 
   &lt;li&gt;can also be used to pregenerate thumbnails; combine with &lt;code&gt;--th-maxage=9999999&lt;/code&gt; or &lt;code&gt;--th-clean=0&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;uploading&lt;/h2&gt; 
&lt;p&gt;drag files/folders into the web-browser to upload&lt;/p&gt; 
&lt;p&gt;dragdrop is the recommended way, but you may also:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;select some files (not folders) in your file explorer and press CTRL-V inside the browser window&lt;/li&gt; 
 &lt;li&gt;use the &lt;a href="https://github.com/9001/copyparty/tree/hovudstraum/bin#u2cpy"&gt;command-line uploader&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;upload using &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#client-examples"&gt;curl, sharex, ishare, ...&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;when uploading files through dragdrop or CTRL-V, this initiates an upload using &lt;code&gt;up2k&lt;/code&gt;; there are two browser-based uploaders available:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;[ğŸˆ] bup&lt;/code&gt;, the basic uploader, supports almost every browser since netscape 4.0&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[ğŸš€] up2k&lt;/code&gt;, the good / fancy one&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;NB: you can undo/delete your own uploads with &lt;code&gt;[ğŸ§¯]&lt;/code&gt; &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#unpost"&gt;unpost&lt;/a&gt; (and this is also where you abort unfinished uploads, but you have to refresh the page first)&lt;/p&gt; 
&lt;p&gt;up2k has several advantages:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;you can drop folders into the browser (files are added recursively)&lt;/li&gt; 
 &lt;li&gt;files are processed in chunks, and each chunk is checksummed 
  &lt;ul&gt; 
   &lt;li&gt;uploads autoresume if they are interrupted by network issues&lt;/li&gt; 
   &lt;li&gt;uploads resume if you reboot your browser or pc, just upload the same files again&lt;/li&gt; 
   &lt;li&gt;server detects any corruption; the client reuploads affected chunks&lt;/li&gt; 
   &lt;li&gt;the client doesn't upload anything that already exists on the server&lt;/li&gt; 
   &lt;li&gt;no filesize limit, even when a proxy limits the request size (for example Cloudflare)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;much higher speeds than ftp/scp/tarpipe on some internet connections (mainly american ones) thanks to parallel connections&lt;/li&gt; 
 &lt;li&gt;the last-modified timestamp of the file is preserved&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;it is perfectly safe to restart / upgrade copyparty while someone is uploading to it!&lt;br /&gt; all known up2k clients will resume just fine ğŸ’ª&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/docs/devnotes.md#up2k"&gt;up2k&lt;/a&gt; for details on how it works, or watch a &lt;a href="https://a.ocv.me/pub/demo/pics-vids/#gf-0f6f5c0d"&gt;demo video&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://user-images.githubusercontent.com/241032/129635371-48fc54ca-fa91-48e3-9b1d-ba413e4b68cb.png" alt="copyparty-upload-fs8" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;protip:&lt;/strong&gt; you can avoid scaring away users with &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/contrib/plugins/minimal-up2k.js"&gt;contrib/plugins/minimal-up2k.js&lt;/a&gt; which makes it look &lt;a href="https://user-images.githubusercontent.com/241032/118311195-dd6ca380-b4ef-11eb-86f3-75a3ff2e1332.png"&gt;much simpler&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;protip:&lt;/strong&gt; if you enable &lt;code&gt;favicon&lt;/code&gt; in the &lt;code&gt;[âš™ï¸] settings&lt;/code&gt; tab (by typing something into the textbox), the icon in the browser tab will indicate upload progress -- also, the &lt;code&gt;[ğŸ””]&lt;/code&gt; and/or &lt;code&gt;[ğŸ”Š]&lt;/code&gt; switches enable visible and/or audible notifications on upload completion&lt;/p&gt; 
&lt;p&gt;the up2k UI is the epitome of polished intuitive experiences:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;"parallel uploads" specifies how many chunks to upload at the same time&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[ğŸƒ]&lt;/code&gt; analysis of other files should continue while one is uploading&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[ğŸ¥”]&lt;/code&gt; shows a simpler UI for faster uploads from slow devices&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[ğŸ›¡ï¸]&lt;/code&gt; decides when to overwrite existing files on the server 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;ğŸ›¡ï¸&lt;/code&gt; = never (generate a new filename instead)&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;ğŸ•’&lt;/code&gt; = overwrite if the server-file is older&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;â™»ï¸&lt;/code&gt; = always overwrite if the files are different&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[ğŸ²]&lt;/code&gt; generate random filenames during upload&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[ğŸ”]&lt;/code&gt; switch between upload and &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#file-search"&gt;file-search&lt;/a&gt; mode 
  &lt;ul&gt; 
   &lt;li&gt;ignore &lt;code&gt;[ğŸ”]&lt;/code&gt; if you add files by dragging them into the browser&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;and then there's the tabs below it,&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;[ok]&lt;/code&gt; is the files which completed successfully&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[ng]&lt;/code&gt; is the ones that failed / got rejected (already exists, ...)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[done]&lt;/code&gt; shows a combined list of &lt;code&gt;[ok]&lt;/code&gt; and &lt;code&gt;[ng]&lt;/code&gt;, chronological order&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[busy]&lt;/code&gt; files which are currently hashing, pending-upload, or uploading 
  &lt;ul&gt; 
   &lt;li&gt;plus up to 3 entries each from &lt;code&gt;[done]&lt;/code&gt; and &lt;code&gt;[que]&lt;/code&gt; for context&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[que]&lt;/code&gt; is all the files that are still queued&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;note that since up2k has to read each file twice, &lt;code&gt;[ğŸˆ] bup&lt;/code&gt; can &lt;em&gt;theoretically&lt;/em&gt; be up to 2x faster in some extreme cases (files bigger than your ram, combined with an internet connection faster than the read-speed of your HDD, or if you're uploading from a cuo2duo)&lt;/p&gt; 
&lt;p&gt;if you are resuming a massive upload and want to skip hashing the files which already finished, you can enable &lt;code&gt;turbo&lt;/code&gt; in the &lt;code&gt;[âš™ï¸] config&lt;/code&gt; tab, but please read the tooltip on that button&lt;/p&gt; 
&lt;p&gt;if the server is behind a proxy which imposes a request-size limit, you can configure up2k to sneak below the limit with server-option &lt;code&gt;--u2sz&lt;/code&gt; (the default is 96 MiB to support Cloudflare)&lt;/p&gt; 
&lt;p&gt;if you want to replace existing files on the server with new uploads by default, run with &lt;code&gt;--u2ow 2&lt;/code&gt; (only works if users have the delete-permission, and can still be disabled with &lt;code&gt;ğŸ›¡ï¸&lt;/code&gt; in the UI)&lt;/p&gt; 
&lt;h3&gt;file-search&lt;/h3&gt; 
&lt;p&gt;dropping files into the browser also lets you see if they exist on the server&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://user-images.githubusercontent.com/241032/129635361-c79286f0-b8f1-440e-aaf4-6e929428fac9.png" alt="copyparty-fsearch-fs8" /&gt;&lt;/p&gt; 
&lt;p&gt;when you drag/drop files into the browser, you will see two dropzones: &lt;code&gt;Upload&lt;/code&gt; and &lt;code&gt;Search&lt;/code&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;on a phone? toggle the &lt;code&gt;[ğŸ”]&lt;/code&gt; switch green before tapping the big yellow Search button to select your files&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;the files will be hashed on the client-side, and each hash is sent to the server, which checks if that file exists somewhere&lt;/p&gt; 
&lt;p&gt;files go into &lt;code&gt;[ok]&lt;/code&gt; if they exist (and you get a link to where it is), otherwise they land in &lt;code&gt;[ng]&lt;/code&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;the main reason filesearch is combined with the uploader is cause the code was too spaghetti to separate it out somewhere else, this is no longer the case but now i've warmed up to the idea too much&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;unpost&lt;/h3&gt; 
&lt;p&gt;undo/delete accidental uploads using the &lt;code&gt;[ğŸ§¯]&lt;/code&gt; tab in the UI&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://user-images.githubusercontent.com/241032/129635368-3afa6634-c20f-418c-90dc-ec411f3b3897.png" alt="copyparty-unpost-fs8" /&gt;&lt;/p&gt; 
&lt;p&gt;you can unpost even if you don't have regular move/delete access, however only for files uploaded within the past &lt;code&gt;--unpost&lt;/code&gt; seconds (default 12 hours) and the server must be running with &lt;code&gt;-e2d&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;config file example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;[global]
  e2d            # enable up2k database (remember uploads)
  unpost: 43200  # 12 hours (default)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;self-destruct&lt;/h3&gt; 
&lt;p&gt;uploads can be given a lifetime, after which they expire / self-destruct&lt;/p&gt; 
&lt;p&gt;the feature must be enabled per-volume with the &lt;code&gt;lifetime&lt;/code&gt; &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#upload-rules"&gt;upload rule&lt;/a&gt; which sets the upper limit for how long a file gets to stay on the server&lt;/p&gt; 
&lt;p&gt;clients can specify a shorter expiration time using the &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#uploading"&gt;up2k ui&lt;/a&gt; -- the relevant options become visible upon navigating into a folder with &lt;code&gt;lifetimes&lt;/code&gt; enabled -- or by using the &lt;code&gt;life&lt;/code&gt; &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/docs/devnotes.md#write"&gt;upload modifier&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;specifying a custom expiration time client-side will affect the timespan in which unposts are permitted, so keep an eye on the estimates in the up2k ui&lt;/p&gt; 
&lt;h3&gt;race the beam&lt;/h3&gt; 
&lt;p&gt;download files while they're still uploading (&lt;a href="http://a.ocv.me/pub/g/nerd-stuff/cpp/2024-0418-race-the-beam.webm"&gt;demo video&lt;/a&gt;) -- it's almost like peer-to-peer&lt;/p&gt; 
&lt;p&gt;requires the file to be uploaded using up2k (which is the default drag-and-drop uploader), alternatively the command-line program&lt;/p&gt; 
&lt;h3&gt;incoming files&lt;/h3&gt; 
&lt;p&gt;the control-panel shows the ETA for all incoming files , but only for files being uploaded into volumes where you have read-access&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/fd275ffa-698c-4fca-a307-4d2181269a6a" alt="copyparty-cpanel-upload-eta-or8" /&gt;&lt;/p&gt; 
&lt;h2&gt;file manager&lt;/h2&gt; 
&lt;p&gt;cut/paste, rename, and delete files/folders (if you have permission)&lt;/p&gt; 
&lt;p&gt;file selection: click somewhere on the line (not the link itself), then:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;space&lt;/code&gt; to toggle&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;up/down&lt;/code&gt; to move&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;shift-up/down&lt;/code&gt; to move-and-select&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;ctrl-shift-up/down&lt;/code&gt; to also scroll&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;shift-click another line for range-select&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;cut: select some files and &lt;code&gt;ctrl-x&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;copy: select some files and &lt;code&gt;ctrl-c&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;paste: &lt;code&gt;ctrl-v&lt;/code&gt; in another folder&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;rename: &lt;code&gt;F2&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;you can copy/move files across browser tabs (cut/copy in one tab, paste in another)&lt;/p&gt; 
&lt;h2&gt;shares&lt;/h2&gt; 
&lt;p&gt;share a file or folder by creating a temporary link&lt;/p&gt; 
&lt;p&gt;when enabled in the server settings (&lt;code&gt;--shr&lt;/code&gt;), click the bottom-right &lt;code&gt;share&lt;/code&gt; button to share the folder you're currently in, or alternatively:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;select a folder first to share that folder instead&lt;/li&gt; 
 &lt;li&gt;select one or more files to share only those files&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;this feature was made with &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#identity-providers"&gt;identity providers&lt;/a&gt; in mind -- configure your reverseproxy to skip the IdP's access-control for a given URL prefix and use that to safely share specific files/folders sans the usual auth checks&lt;/p&gt; 
&lt;p&gt;when creating a share, the creator can choose any of the following options:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;password-protection&lt;/li&gt; 
 &lt;li&gt;expire after a certain time; &lt;code&gt;0&lt;/code&gt; or blank means infinite&lt;/li&gt; 
 &lt;li&gt;allow visitors to upload (if the user who creates the share has write-access)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;semi-intentional limitations:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;cleanup of expired shares only works when global option &lt;code&gt;e2d&lt;/code&gt; is set, and/or at least one volume on the server has volflag &lt;code&gt;e2d&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;only folders from the same volume are shared; if you are sharing a folder which contains other volumes, then the contents of those volumes will not be available&lt;/li&gt; 
 &lt;li&gt;if you change &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#password-hashing"&gt;password hashing&lt;/a&gt; settings after creating a password-protected share, then that share will stop working&lt;/li&gt; 
 &lt;li&gt;related to &lt;a href="https://github.com/9001/copyparty/raw/hovudstraum/docs/idp.md#idp-volumes-are-forgotten-on-shutdown"&gt;IdP volumes being forgotten on shutdown&lt;/a&gt;, any shares pointing into a user's IdP volume will be unavailable until that user makes their first request after a restart&lt;/li&gt; 
 &lt;li&gt;no option to "delete after first access" because tricky 
  &lt;ul&gt; 
   &lt;li&gt;when linking something to discord (for example) it'll get accessed by their scraper and that would count as a hit&lt;/li&gt; 
   &lt;li&gt;browsers wouldn't be able to resume a broken download unless the requester's IP gets allowlisted for X minutes (ref. tricky)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;specify &lt;code&gt;--shr /foobar&lt;/code&gt; to enable this feature; a toplevel virtual folder named &lt;code&gt;foobar&lt;/code&gt; is then created, and that's where all the shares will be served from&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;you can name it whatever, &lt;code&gt;foobar&lt;/code&gt; is just an example&lt;/li&gt; 
 &lt;li&gt;if you're using config files, put &lt;code&gt;shr: /foobar&lt;/code&gt; inside the &lt;code&gt;[global]&lt;/code&gt; section instead&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;users can delete their own shares in the controlpanel, and a list of privileged users (&lt;code&gt;--shr-adm&lt;/code&gt;) are allowed to see and/or delet any share on the server&lt;/p&gt; 
&lt;p&gt;after a share has expired, it remains visible in the controlpanel for &lt;code&gt;--shr-rt&lt;/code&gt; minutes (default is 1 day), and the owner can revive it by extending the expiration time there&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;security note:&lt;/strong&gt; using this feature does not mean that you can skip the &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#accounts-and-volumes"&gt;accounts and volumes&lt;/a&gt; section -- you still need to restrict access to volumes that you do not intend to share with unauthenticated users! it is not sufficient to use rules in the reverseproxy to restrict access to just the &lt;code&gt;/share&lt;/code&gt; folder.&lt;/p&gt; 
&lt;h2&gt;batch rename&lt;/h2&gt; 
&lt;p&gt;select some files and press &lt;code&gt;F2&lt;/code&gt; to bring up the rename UI&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://user-images.githubusercontent.com/241032/128434204-eb136680-3c07-4ec7-92e0-ae86af20c241.png" alt="batch-rename-fs8" /&gt;&lt;/p&gt; 
&lt;p&gt;quick explanation of the buttons,&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;[âœ… apply rename]&lt;/code&gt; confirms and begins renaming&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[âŒ cancel]&lt;/code&gt; aborts and closes the rename window&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[â†º reset]&lt;/code&gt; reverts any filename changes back to the original name&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[decode]&lt;/code&gt; does a URL-decode on the filename, fixing stuff like &lt;code&gt;&amp;amp;amp;&lt;/code&gt; and &lt;code&gt;%20&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[advanced]&lt;/code&gt; toggles advanced mode&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;advanced mode: rename files based on rules to decide the new names, based on the original name (regex), or based on the tags collected from the file (artist/title/...), or a mix of both&lt;/p&gt; 
&lt;p&gt;in advanced mode,&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;[case]&lt;/code&gt; toggles case-sensitive regex&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;regex&lt;/code&gt; is the regex pattern to apply to the original filename; any files which don't match will be skipped&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;format&lt;/code&gt; is the new filename, taking values from regex capturing groups and/or from file tags 
  &lt;ul&gt; 
   &lt;li&gt;very loosely based on foobar2000 syntax&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;presets&lt;/code&gt; lets you save rename rules for later&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;available functions:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;$lpad(text, length, pad_char)&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;$rpad(text, length, pad_char)&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;so,&lt;/p&gt; 
&lt;p&gt;say you have a file named &lt;a href="https://www.youtube.com/watch?v=-dtb0vDPruI"&gt;&lt;code&gt;meganeko - Eclipse - 07 Sirius A.mp3&lt;/code&gt;&lt;/a&gt; (absolutely fantastic album btw) and the tags are: &lt;code&gt;Album:Eclipse&lt;/code&gt;, &lt;code&gt;Artist:meganeko&lt;/code&gt;, &lt;code&gt;Title:Sirius A&lt;/code&gt;, &lt;code&gt;tn:7&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;you could use just regex to rename it:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;regex&lt;/code&gt; = &lt;code&gt;(.*) - (.*) - ([0-9]{2}) (.*)&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;format&lt;/code&gt; = &lt;code&gt;(3). (1) - (4)&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;output&lt;/code&gt; = &lt;code&gt;07. meganeko - Sirius A.mp3&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;or you could use just tags:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;format&lt;/code&gt; = &lt;code&gt;$lpad((tn),2,0). (artist) - (title).(ext)&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;output&lt;/code&gt; = &lt;code&gt;7. meganeko - Sirius A.mp3&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;or a mix of both:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;regex&lt;/code&gt; = &lt;code&gt;- ([0-9]{2})&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;format&lt;/code&gt; = &lt;code&gt;(1). (artist) - (title).(ext)&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;output&lt;/code&gt; = &lt;code&gt;07. meganeko - Sirius A.mp3&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;the metadata keys you can use in the format field are the ones in the file-browser table header (whatever is collected with &lt;code&gt;-mte&lt;/code&gt; and &lt;code&gt;-mtp&lt;/code&gt;)&lt;/p&gt; 
&lt;h2&gt;rss feeds&lt;/h2&gt; 
&lt;p&gt;monitor a folder with your RSS reader , optionally recursive&lt;/p&gt; 
&lt;p&gt;must be enabled per-volume with volflag &lt;code&gt;rss&lt;/code&gt; or globally with &lt;code&gt;--rss&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;the feed includes itunes metadata for use with podcast readers such as &lt;a href="https://antennapod.org/"&gt;AntennaPod&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;a feed example: &lt;a href="https://cd.ocv.me/a/d2/d22/?rss&amp;amp;fext=mp3"&gt;https://cd.ocv.me/a/d2/d22/?rss&amp;amp;fext=mp3&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;url parameters:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;pw=hunter2&lt;/code&gt; for password auth 
  &lt;ul&gt; 
   &lt;li&gt;if you enabled &lt;code&gt;--usernames&lt;/code&gt; then do &lt;code&gt;pw=username:password&lt;/code&gt; instead&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;recursive&lt;/code&gt; to also include subfolders&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;title=foo&lt;/code&gt; changes the feed title (default: folder name)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;fext=mp3,opus&lt;/code&gt; only include mp3 and opus files (default: all)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;nf=30&lt;/code&gt; only show the first 30 results (default: 250)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;sort=m&lt;/code&gt; sort by mtime (file last-modified), newest first (default) 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;u&lt;/code&gt; = upload-time; NOTE: non-uploaded files have upload-time &lt;code&gt;0&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;n&lt;/code&gt; = filename&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;a&lt;/code&gt; = filesize&lt;/li&gt; 
   &lt;li&gt;uppercase = reverse-sort; &lt;code&gt;M&lt;/code&gt; = oldest file first&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;recent uploads&lt;/h2&gt; 
&lt;p&gt;list all recent uploads by clicking "show recent uploads" in the controlpanel&lt;/p&gt; 
&lt;p&gt;will show uploader IP and upload-time if the visitor has the admin permission&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;global-option &lt;code&gt;--ups-when&lt;/code&gt; makes upload-time visible to all users, and not just admins&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;global-option &lt;code&gt;--ups-who&lt;/code&gt; (volflag &lt;code&gt;ups_who&lt;/code&gt;) specifies who gets access (0=nobody, 1=admins, 2=everyone), default=2&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;note that the &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#unpost"&gt;ğŸ§¯ unpost&lt;/a&gt; feature is better suited for viewing &lt;em&gt;your own&lt;/em&gt; recent uploads, as it includes the option to undo/delete them&lt;/p&gt; 
&lt;p&gt;config file example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;[global]
  ups-when    # everyone can see upload times
  ups-who: 1  # but only admins can see the list,
              # so ups-when doesn't take effect
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;media player&lt;/h2&gt; 
&lt;p&gt;plays almost every audio format there is (if the server has FFmpeg installed for on-demand transcoding)&lt;/p&gt; 
&lt;p&gt;the following audio formats are usually always playable, even without FFmpeg: &lt;code&gt;aac|flac|m4a|mp3|ogg|opus|wav&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;some highlights:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;OS integration; control playback from your phone's lockscreen (&lt;a href="https://user-images.githubusercontent.com/241032/233213022-298a98ba-721a-4cf1-a3d4-f62634bc53d5.png"&gt;windows&lt;/a&gt; // &lt;a href="https://user-images.githubusercontent.com/241032/142711926-0700be6c-3e31-47b3-9928-53722221f722.png"&gt;iOS&lt;/a&gt; // &lt;a href="https://user-images.githubusercontent.com/241032/233212311-a7368590-08c7-4f9f-a1af-48ccf3f36fad.png"&gt;android&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;shows the audio waveform in the seekbar&lt;/li&gt; 
 &lt;li&gt;not perfectly gapless but can get really close (see settings + eq below); good enough to enjoy gapless albums as intended&lt;/li&gt; 
 &lt;li&gt;videos can be played as audio, without wasting bandwidth on the video&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;click the &lt;code&gt;play&lt;/code&gt; link next to an audio file, or copy the link target to &lt;a href="https://a.ocv.me/pub/demo/music/Ubiktune%20-%20SOUNDSHOCK%202%20-%20FM%20FUNK%20TERRROR!!/#af-1fbfba61&amp;amp;t=18"&gt;share it&lt;/a&gt; (optionally with a timestamp to start playing from, like that example does)&lt;/p&gt; 
&lt;p&gt;open the &lt;code&gt;[ğŸº]&lt;/code&gt; media-player-settings tab to configure it,&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;"switches": 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;[ğŸ”]&lt;/code&gt; repeats one single song forever&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;[ğŸ”€]&lt;/code&gt; shuffles the files inside each folder&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;[preload]&lt;/code&gt; starts loading the next track when it's about to end, reduces the silence between songs&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;[full]&lt;/code&gt; does a full preload by downloading the entire next file; good for unreliable connections, bad for slow connections&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;[~s]&lt;/code&gt; toggles the seekbar waveform display&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;[/np]&lt;/code&gt; enables buttons to copy the now-playing info as an irc message&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;[ğŸ“»]&lt;/code&gt; enables buttons to create an &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#playlists"&gt;m3u playlist&lt;/a&gt; with the selected songs&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;[os-ctl]&lt;/code&gt; makes it possible to control audio playback from the lockscreen of your device (enables &lt;a href="https://developer.mozilla.org/en-US/docs/Web/API/MediaSession"&gt;mediasession&lt;/a&gt;)&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;[seek]&lt;/code&gt; allows seeking with lockscreen controls (buggy on some devices)&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;[art]&lt;/code&gt; shows album art on the lockscreen&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;[ğŸ¯]&lt;/code&gt; keeps the playing song scrolled into view (good when using the player as a taskbar dock)&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;[âŸ]&lt;/code&gt; shrinks the playback controls&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;"buttons": 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;[uncache]&lt;/code&gt; may fix songs that won't play correctly due to bad files in browser cache&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;"at end of folder": 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;[loop]&lt;/code&gt; keeps looping the folder&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;[next]&lt;/code&gt; plays into the next folder&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;"transcode": 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;[flac]&lt;/code&gt; converts &lt;code&gt;flac&lt;/code&gt; and &lt;code&gt;wav&lt;/code&gt; files into opus (if supported by browser) or mp3&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;[aac]&lt;/code&gt; converts &lt;code&gt;aac&lt;/code&gt; and &lt;code&gt;m4a&lt;/code&gt; files into opus (if supported by browser) or mp3&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;[oth]&lt;/code&gt; converts all other known formats into opus (if supported by browser) or mp3 
    &lt;ul&gt; 
     &lt;li&gt;&lt;code&gt;aac|ac3|aif|aiff|alac|alaw|amr|ape|au|dfpwm|dts|flac|gsm|it|m4a|mo3|mod|mp2|mp3|mpc|mptm|mt2|mulaw|ogg|okt|opus|ra|s3m|tak|tta|ulaw|wav|wma|wv|xm|xpk&lt;/code&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;"transcode to": 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;[opus]&lt;/code&gt; produces an &lt;code&gt;opus&lt;/code&gt; whenever transcoding is necessary (the best choice on Android and PCs)&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;[awo]&lt;/code&gt; is &lt;code&gt;opus&lt;/code&gt; in a &lt;code&gt;weba&lt;/code&gt; file, good for iPhones (iOS 17.5 and newer) but Apple is still fixing some state-confusion bugs as of iOS 18.2.1&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;[caf]&lt;/code&gt; is &lt;code&gt;opus&lt;/code&gt; in a &lt;code&gt;caf&lt;/code&gt; file, good for iPhones (iOS 11 through 17), technically unsupported by Apple but works for the most part&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;[mp3]&lt;/code&gt; -- the myth, the legend, the undying master of mediocre sound quality that definitely works everywhere&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;[flac]&lt;/code&gt; -- lossless but compressed, for LAN and/or fiber playback on electrostatic headphones&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;[wav]&lt;/code&gt; -- lossless and uncompressed, for LAN and/or fiber playback on electrostatic headphones connected to very old equipment 
    &lt;ul&gt; 
     &lt;li&gt;&lt;code&gt;flac&lt;/code&gt; and &lt;code&gt;wav&lt;/code&gt; must be enabled with &lt;code&gt;--allow-flac&lt;/code&gt; / &lt;code&gt;--allow-wav&lt;/code&gt; to allow spending the disk space&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;"tint" reduces the contrast of the playback bar&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;playlists&lt;/h3&gt; 
&lt;p&gt;create and play &lt;a href="https://en.wikipedia.org/wiki/M3U"&gt;m3u8&lt;/a&gt; playlists -- see example &lt;a href="https://a.ocv.me/pub/demo/music/?doc=example-playlist.m3u"&gt;text&lt;/a&gt; and &lt;a href="https://a.ocv.me/pub/demo/music/#m3u=example-playlist.m3u"&gt;player&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;click a file with the extension &lt;code&gt;m3u&lt;/code&gt; or &lt;code&gt;m3u8&lt;/code&gt; (for example &lt;code&gt;mixtape.m3u&lt;/code&gt; or &lt;code&gt;touhou.m3u8&lt;/code&gt; ) and you get two choices: Play / Edit&lt;/p&gt; 
&lt;p&gt;playlists can include songs across folders anywhere on the server, but filekeys/dirkeys are NOT supported, so the listener must have read-access or get-access to the files&lt;/p&gt; 
&lt;h3&gt;creating a playlist&lt;/h3&gt; 
&lt;p&gt;with a standalone mediaplayer or copyparty&lt;/p&gt; 
&lt;p&gt;you can use foobar2000, deadbeef, just about any standalone player should work -- but you might need to edit the filepaths in the playlist so they fit with the server-URLs&lt;/p&gt; 
&lt;p&gt;alternatively, you can create the playlist using copyparty itself:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;open the &lt;code&gt;[ğŸº]&lt;/code&gt; media-player-settings tab and enable the &lt;code&gt;[ğŸ“»]&lt;/code&gt; create-playlist feature -- this adds two new buttons in the bottom-right tray, &lt;code&gt;[ğŸ“»add]&lt;/code&gt; and &lt;code&gt;[ğŸ“»copy]&lt;/code&gt; which appear when you listen to music, or when you select a few audiofiles&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;click the &lt;code&gt;ğŸ“»add&lt;/code&gt; button while a song is playing (or when you've selected some songs) and they'll be added to "the list" (you can't see it yet)&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;at any time, click &lt;code&gt;ğŸ“»copy&lt;/code&gt; to send the playlist to your clipboard&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;you can then continue adding more songs if you'd like&lt;/li&gt; 
   &lt;li&gt;if you want to wipe the playlist and start from scratch, just refresh the page&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;create a new textfile, name it &lt;code&gt;something.m3u&lt;/code&gt; and paste the playlist there&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;audio equalizer&lt;/h3&gt; 
&lt;p&gt;and &lt;a href="https://en.wikipedia.org/wiki/Dynamic_range_compression"&gt;dynamic range compressor&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;can also boost the volume in general, or increase/decrease stereo width (like &lt;a href="https://www.foobar2000.org/components/view/foo_dsp_meiercf"&gt;crossfeed&lt;/a&gt; just worse)&lt;/p&gt; 
&lt;p&gt;has the convenient side-effect of reducing the pause between songs, so gapless albums play better with the eq enabled (just make it flat)&lt;/p&gt; 
&lt;p&gt;not available on iPhones / iPads because AudioContext currently breaks background audio playback on iOS (15.7.8)&lt;/p&gt; 
&lt;h3&gt;fix unreliable playback on android&lt;/h3&gt; 
&lt;p&gt;due to phone / app settings, android phones may randomly stop playing music when the power saver kicks in, especially at the end of an album -- you can fix it by &lt;a href="https://user-images.githubusercontent.com/241032/235262123-c328cca9-3930-4948-bd18-3949b9fd3fcf.png"&gt;disabling power saving&lt;/a&gt; in the &lt;a href="https://user-images.githubusercontent.com/241032/235262121-2ffc51ae-7821-4310-a322-c3b7a507890c.png"&gt;app settings&lt;/a&gt; of the browser you use for music streaming (preferably a dedicated one)&lt;/p&gt; 
&lt;h2&gt;textfile viewer&lt;/h2&gt; 
&lt;p&gt;with realtime streaming of logfiles and such (&lt;a href="https://a.ocv.me/pub/demo/logtail/"&gt;demo&lt;/a&gt;) , and terminal colors work too&lt;/p&gt; 
&lt;p&gt;click &lt;code&gt;-txt-&lt;/code&gt; next to a textfile to open the viewer, which has the following toolbar buttons:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;âœï¸ edit&lt;/code&gt; opens the textfile editor&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;ğŸ“¡ follow&lt;/code&gt; starts monitoring the file for changes, streaming new lines in realtime 
  &lt;ul&gt; 
   &lt;li&gt;similar to &lt;code&gt;tail -f&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://a.ocv.me/pub/demo/logtail/?doc=lipsum.txt&amp;amp;tail"&gt;link directly&lt;/a&gt; to a file with tailing enabled by adding &lt;code&gt;&amp;amp;tail&lt;/code&gt; to the textviewer URL&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;markdown viewer&lt;/h2&gt; 
&lt;p&gt;and there are &lt;em&gt;two&lt;/em&gt; editors&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://user-images.githubusercontent.com/241032/115978057-66419080-a57d-11eb-8539-d2be843991aa.png" alt="copyparty-md-read-fs8" /&gt;&lt;/p&gt; 
&lt;p&gt;there is a built-in extension for inline clickable thumbnails;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;enable it by adding &lt;code&gt;&amp;lt;!-- th --&amp;gt;&lt;/code&gt; somewhere in the doc&lt;/li&gt; 
 &lt;li&gt;add thumbnails with &lt;code&gt;!th[l](your.jpg)&lt;/code&gt; where &lt;code&gt;l&lt;/code&gt; means left-align (&lt;code&gt;r&lt;/code&gt; = right-align)&lt;/li&gt; 
 &lt;li&gt;a single line with &lt;code&gt;---&lt;/code&gt; clears the float / inlining&lt;/li&gt; 
 &lt;li&gt;in the case of README.md being displayed below a file listing, thumbnails will open in the gallery viewer&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;other notes,&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;the document preview has a max-width which is the same as an A4 paper when printed&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;markdown vars&lt;/h3&gt; 
&lt;p&gt;dynamic docs with serverside variable expansion to replace stuff like &lt;code&gt;{{self.ip}}&lt;/code&gt; with the client's IP, or &lt;code&gt;{{srv.htime}}&lt;/code&gt; with the current time on the server&lt;/p&gt; 
&lt;p&gt;see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/srv/expand/"&gt;./srv/expand/&lt;/a&gt; for usage and examples&lt;/p&gt; 
&lt;h2&gt;other tricks&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;you can link a particular timestamp in an audio file by adding it to the URL, such as &lt;code&gt;&amp;amp;20&lt;/code&gt; / &lt;code&gt;&amp;amp;20s&lt;/code&gt; / &lt;code&gt;&amp;amp;1m20&lt;/code&gt; / &lt;code&gt;&amp;amp;t=1:20&lt;/code&gt; after the &lt;code&gt;.../#af-c8960dab&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;enabling the audio equalizer can help make gapless albums fully gapless in some browsers (chrome), so consider leaving it on with all the values at zero&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;get a plaintext file listing by adding &lt;code&gt;?ls=t&lt;/code&gt; to a URL, or a compact colored one with &lt;code&gt;?ls=v&lt;/code&gt; (for unix terminals)&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;if you are using media hotkeys to switch songs and are getting tired of seeing the OSD popup which Windows doesn't let you disable, consider &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/contrib/#media-osd-bgoneps1"&gt;./contrib/media-osd-bgone.ps1&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;click the bottom-left &lt;code&gt;Ï€&lt;/code&gt; to open a javascript prompt for debugging&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;files named &lt;code&gt;.prologue.html&lt;/code&gt; / &lt;code&gt;.epilogue.html&lt;/code&gt; will be rendered before/after directory listings unless &lt;code&gt;--no-logues&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;files named &lt;code&gt;descript.ion&lt;/code&gt; / &lt;code&gt;DESCRIPT.ION&lt;/code&gt; are parsed and displayed in the file listing, or as the epilogue if nonstandard&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;files named &lt;code&gt;README.md&lt;/code&gt; / &lt;code&gt;readme.md&lt;/code&gt; will be rendered after directory listings unless &lt;code&gt;--no-readme&lt;/code&gt; (but &lt;code&gt;.epilogue.html&lt;/code&gt; takes precedence)&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;and &lt;code&gt;PREADME.md&lt;/code&gt; / &lt;code&gt;preadme.md&lt;/code&gt; is shown above directory listings unless &lt;code&gt;--no-readme&lt;/code&gt; or &lt;code&gt;.prologue.html&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;README.md&lt;/code&gt; and &lt;code&gt;*logue.html&lt;/code&gt; can contain placeholder values which are replaced server-side before embedding into directory listings; see &lt;code&gt;--help-exp&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;searching&lt;/h2&gt; 
&lt;p&gt;search by size, date, path/name, mp3-tags, ...&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://user-images.githubusercontent.com/241032/129635365-c0ff2a9f-0ee5-4fc3-8bb6-006033cf67b8.png" alt="copyparty-search-fs8" /&gt;&lt;/p&gt; 
&lt;p&gt;when started with &lt;code&gt;-e2dsa&lt;/code&gt; copyparty will scan/index all your files. This avoids duplicates on upload, and also makes the volumes searchable through the web-ui:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;make search queries by &lt;code&gt;size&lt;/code&gt;/&lt;code&gt;date&lt;/code&gt;/&lt;code&gt;directory-path&lt;/code&gt;/&lt;code&gt;filename&lt;/code&gt;, or...&lt;/li&gt; 
 &lt;li&gt;drag/drop a local file to see if the same contents exist somewhere on the server, see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#file-search"&gt;file-search&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;path/name queries are space-separated, AND'ed together, and words are negated with a &lt;code&gt;-&lt;/code&gt; prefix, so for example:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;path: &lt;code&gt;shibayan -bossa&lt;/code&gt; finds all files where one of the folders contain &lt;code&gt;shibayan&lt;/code&gt; but filters out any results where &lt;code&gt;bossa&lt;/code&gt; exists somewhere in the path&lt;/li&gt; 
 &lt;li&gt;name: &lt;code&gt;demetori styx&lt;/code&gt; gives you &lt;a href="https://www.youtube.com/watch?v=zGh0g14ZJ8I&amp;amp;list=PL3A147BD151EE5218&amp;amp;index=9"&gt;good stuff&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;the &lt;code&gt;raw&lt;/code&gt; field allows for more complex stuff such as &lt;code&gt;( tags like *nhato* or tags like *taishi* ) and ( not tags like *nhato* or not tags like *taishi* )&lt;/code&gt; which finds all songs by either nhato or taishi, excluding collabs (terrible example, why would you do that)&lt;/p&gt; 
&lt;p&gt;for the above example to work, add the commandline argument &lt;code&gt;-e2ts&lt;/code&gt; to also scan/index tags from music files, which brings us over to:&lt;/p&gt; 
&lt;h1&gt;server config&lt;/h1&gt; 
&lt;p&gt;using arguments or config files, or a mix of both:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;config files (&lt;code&gt;-c some.conf&lt;/code&gt;) can set additional commandline arguments; see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/docs/example.conf"&gt;./docs/example.conf&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/docs/example2.conf"&gt;./docs/example2.conf&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;kill -s USR1&lt;/code&gt; (same as &lt;code&gt;systemctl reload copyparty&lt;/code&gt;) to reload accounts and volumes from config files without restarting 
  &lt;ul&gt; 
   &lt;li&gt;or click the &lt;code&gt;[reload cfg]&lt;/code&gt; button in the control-panel if the user has &lt;code&gt;a&lt;/code&gt;/admin in any volume&lt;/li&gt; 
   &lt;li&gt;changes to the &lt;code&gt;[global]&lt;/code&gt; config section requires a restart to take effect&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;NB:&lt;/strong&gt; as humongous as this readme is, there is also a lot of undocumented features. Run copyparty with &lt;code&gt;--help&lt;/code&gt; to see all available global options; all of those can be used in the &lt;code&gt;[global]&lt;/code&gt; section of config files, and everything listed in &lt;code&gt;--help-flags&lt;/code&gt; can be used in volumes as volflags.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;if running in docker/podman, try this: &lt;code&gt;docker run --rm -it copyparty/ac --help&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;or see this: &lt;a href="https://ocv.me/copyparty/helptext.html"&gt;https://ocv.me/copyparty/helptext.html&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;or if you prefer plaintext, &lt;a href="https://ocv.me/copyparty/helptext.txt"&gt;https://ocv.me/copyparty/helptext.txt&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;zeroconf&lt;/h2&gt; 
&lt;p&gt;announce enabled services on the LAN (&lt;a href="https://user-images.githubusercontent.com/241032/215344737-0eae8d98-9496-4256-9aa8-cd2f6971810d.png"&gt;pic&lt;/a&gt;) -- &lt;code&gt;-z&lt;/code&gt; enables both &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#mdns"&gt;mdns&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#ssdp"&gt;ssdp&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;--z-on&lt;/code&gt; / &lt;code&gt;--z-off&lt;/code&gt; limits the feature to certain networks&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;config file example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;[global]
  z      # enable all zeroconf features (mdns, ssdp)
  zm     # only enables mdns (does nothing since we already have z)
  z-on: 192.168.0.0/16, 10.1.2.0/24  # restrict to certain subnets
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;mdns&lt;/h3&gt; 
&lt;p&gt;LAN domain-name and feature announcer&lt;/p&gt; 
&lt;p&gt;uses &lt;a href="https://en.wikipedia.org/wiki/Multicast_DNS"&gt;multicast dns&lt;/a&gt; to give copyparty a domain which any machine on the LAN can use to access it&lt;/p&gt; 
&lt;p&gt;all enabled services (&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#webdav-server"&gt;webdav&lt;/a&gt;, &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#ftp-server"&gt;ftp&lt;/a&gt;, &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#smb-server"&gt;smb&lt;/a&gt;) will appear in mDNS-aware file managers (KDE, gnome, macOS, ...)&lt;/p&gt; 
&lt;p&gt;the domain will be &lt;code&gt;partybox.local&lt;/code&gt; if the machine's hostname is &lt;code&gt;partybox&lt;/code&gt; unless &lt;code&gt;--name&lt;/code&gt; specifies something else&lt;/p&gt; 
&lt;p&gt;and the web-UI will be available at &lt;a href="http://partybox.local:3923/"&gt;http://partybox.local:3923/&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;if you want to get rid of the &lt;code&gt;:3923&lt;/code&gt; so you can use &lt;a href="http://partybox.local/"&gt;http://partybox.local/&lt;/a&gt; instead then see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#listen-on-port-80-and-443"&gt;listen on port 80 and 443&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;ssdp&lt;/h3&gt; 
&lt;p&gt;windows-explorer announcer&lt;/p&gt; 
&lt;p&gt;uses &lt;a href="https://en.wikipedia.org/wiki/Simple_Service_Discovery_Protocol"&gt;ssdp&lt;/a&gt; to make copyparty appear in the windows file explorer on all machines on the LAN&lt;/p&gt; 
&lt;p&gt;doubleclicking the icon opens the "connect" page which explains how to mount copyparty as a local filesystem&lt;/p&gt; 
&lt;p&gt;if copyparty does not appear in windows explorer, use &lt;code&gt;--zsv&lt;/code&gt; to see why:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;maybe the discovery multicast was sent from an IP which does not intersect with the server subnets&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;qr-code&lt;/h2&gt; 
&lt;p&gt;print a qr-code &lt;a href="https://user-images.githubusercontent.com/241032/194728533-6f00849b-c6ac-43c6-9359-83e454d11e00.png"&gt;(screenshot)&lt;/a&gt; for quick access, great between phones on android hotspots which keep changing the subnet&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;--qr&lt;/code&gt; enables it&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--qrs&lt;/code&gt; does https instead of http&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--qrl lootbox/?pw=hunter2&lt;/code&gt; appends to the url, linking to the &lt;code&gt;lootbox&lt;/code&gt; folder with password &lt;code&gt;hunter2&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--qrz 1&lt;/code&gt; forces 1x zoom instead of autoscaling to fit the terminal size 
  &lt;ul&gt; 
   &lt;li&gt;1x may render incorrectly on some terminals/fonts, but 2x should always work&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--qr-pin 1&lt;/code&gt; makes the qr-code stick to the bottom of the console (never scrolls away)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--qr-file qr.txt:1:2&lt;/code&gt; writes a small qr-code to &lt;code&gt;qr.txt&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--qr-file qr.txt:2:2&lt;/code&gt; writes a big qr-code to &lt;code&gt;qr.txt&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--qr-file qr.svg:1:2&lt;/code&gt; writes a vector-graphics qr-code to &lt;code&gt;qr.svg&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--qr-file qr.png:8:4:333333:ffcc55&lt;/code&gt; writes an 8x-magnified yellow-on-gray &lt;code&gt;qr.png&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--qr-file qr.png:8:4::ffffff&lt;/code&gt; writes an 8x-magnified white-on-transparent &lt;code&gt;qr.png&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;it uses the server hostname if &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#mdns"&gt;mdns&lt;/a&gt; is enabled, otherwise it'll use your external ip (default route) unless &lt;code&gt;--qri&lt;/code&gt; specifies a specific ip-prefix or domain&lt;/p&gt; 
&lt;h2&gt;ftp server&lt;/h2&gt; 
&lt;p&gt;an FTP server can be started using &lt;code&gt;--ftp 3921&lt;/code&gt;, and/or &lt;code&gt;--ftps&lt;/code&gt; for explicit TLS (ftpes)&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;based on &lt;a href="https://github.com/giampaolo/pyftpdlib"&gt;pyftpdlib&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;needs a dedicated port (cannot share with the HTTP/HTTPS API)&lt;/li&gt; 
 &lt;li&gt;uploads are not resumable -- delete and restart if necessary&lt;/li&gt; 
 &lt;li&gt;runs in active mode by default, you probably want &lt;code&gt;--ftp-pr 12000-13000&lt;/code&gt; 
  &lt;ul&gt; 
   &lt;li&gt;if you enable both &lt;code&gt;ftp&lt;/code&gt; and &lt;code&gt;ftps&lt;/code&gt;, the port-range will be divided in half&lt;/li&gt; 
   &lt;li&gt;some older software (filezilla on debian-stable) cannot passive-mode with TLS&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;login with any username + your password, or put your password in the username field 
  &lt;ul&gt; 
   &lt;li&gt;unless you enabled &lt;code&gt;--usernames&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;some recommended FTP / FTPS clients; &lt;code&gt;wark&lt;/code&gt; = example password:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://winscp.net/eng/download.php"&gt;https://winscp.net/eng/download.php&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://filezilla-project.org/"&gt;https://filezilla-project.org/&lt;/a&gt; struggles a bit with ftps in active-mode, but is fine otherwise&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://rclone.org/"&gt;https://rclone.org/&lt;/a&gt; does FTPS with &lt;code&gt;tls=false explicit_tls=true&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;lftp -u k,wark -p 3921 127.0.0.1 -e ls&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;lftp -u k,wark -p 3990 127.0.0.1 -e 'set ssl:verify-certificate no; ls'&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;config file example, which restricts FTP to only use ports 3921 and 12000-12099 so all of those ports must be opened in your firewall:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;[global]
  ftp: 3921
  ftp-pr: 12000-12099
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;webdav server&lt;/h2&gt; 
&lt;p&gt;with read-write support, supports winXP and later, macos, nautilus/gvfs ... a great way to &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#mount-as-drive"&gt;access copyparty straight from the file explorer in your OS&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;click the &lt;a href="http://127.0.0.1:3923/?hc"&gt;connect&lt;/a&gt; button in the control-panel to see connection instructions for windows, linux, macos&lt;/p&gt; 
&lt;p&gt;general usage:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;login with any username + your password, or put your password in the username field (password field can be empty/whatever) 
  &lt;ul&gt; 
   &lt;li&gt;unless you enabled &lt;code&gt;--usernames&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;on macos, connect from finder:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;[Go] -&amp;gt; [Connect to Server...] -&amp;gt; &lt;a href="http://192.168.123.1:3923/"&gt;http://192.168.123.1:3923/&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;in order to grant full write-access to webdav clients, the volflag &lt;code&gt;daw&lt;/code&gt; must be set and the account must also have delete-access (otherwise the client won't be allowed to replace the contents of existing files, which is how webdav works)&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;note: if you have enabled &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#identity-providers"&gt;IdP authentication&lt;/a&gt; then that may cause issues for some/most webdav clients; see &lt;a href="https://github.com/9001/copyparty/raw/hovudstraum/docs/idp.md#connecting-webdav-clients"&gt;the webdav section in the IdP docs&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;connecting to webdav from windows&lt;/h3&gt; 
&lt;p&gt;using the GUI (winXP or later):&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;rightclick [my computer] -&amp;gt; [map network drive] -&amp;gt; Folder: &lt;code&gt;http://192.168.123.1:3923/&lt;/code&gt; 
  &lt;ul&gt; 
   &lt;li&gt;on winXP only, click the &lt;code&gt;Sign up for online storage&lt;/code&gt; hyperlink instead and put the URL there&lt;/li&gt; 
   &lt;li&gt;providing your password as the username is recommended; the password field can be anything or empty 
    &lt;ul&gt; 
     &lt;li&gt;unless you enabled &lt;code&gt;--usernames&lt;/code&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;the webdav client that's built into windows has the following list of bugs; you can avoid all of these by connecting with rclone instead:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;win7+ doesn't actually send the password to the server when reauthenticating after a reboot unless you first try to login with an incorrect password and then switch to the correct password 
  &lt;ul&gt; 
   &lt;li&gt;or just type your password into the username field instead to get around it entirely&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;connecting to a folder which allows anonymous read will make writing impossible, as windows has decided it doesn't need to login 
  &lt;ul&gt; 
   &lt;li&gt;workaround: connect twice; first to a folder which requires auth, then to the folder you actually want, and leave both of those mounted&lt;/li&gt; 
   &lt;li&gt;or set the server-option &lt;code&gt;--dav-auth&lt;/code&gt; to force password-auth for all webdav clients&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;win7+ may open a new tcp connection for every file and sometimes forgets to close them, eventually needing a reboot 
  &lt;ul&gt; 
   &lt;li&gt;maybe NIC-related (??), happens with win10-ltsc on e1000e but not virtio&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;windows cannot access folders which contain filenames with invalid unicode or forbidden characters (&lt;code&gt;&amp;lt;&amp;gt;:"/\|?*&lt;/code&gt;), or names ending with &lt;code&gt;.&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;winxp cannot show unicode characters outside of &lt;em&gt;some range&lt;/em&gt; 
  &lt;ul&gt; 
   &lt;li&gt;latin-1 is fine, hiragana is not (not even as shift-jis on japanese xp)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;tftp server&lt;/h2&gt; 
&lt;p&gt;a TFTP server (read/write) can be started using &lt;code&gt;--tftp 3969&lt;/code&gt; (you probably want &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#ftp-server"&gt;ftp&lt;/a&gt; instead unless you are &lt;em&gt;actually&lt;/em&gt; communicating with hardware from the 90s (in which case we should definitely hang some time))&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;that makes this the first RTX DECT Base that has been updated using copyparty ğŸ‰&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;based on &lt;a href="https://github.com/9001/partftpy"&gt;partftpy&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;no accounts; read from world-readable folders, write to world-writable, overwrite in world-deletable&lt;/li&gt; 
 &lt;li&gt;needs a dedicated port (cannot share with the HTTP/HTTPS API) 
  &lt;ul&gt; 
   &lt;li&gt;run as root (or see below) to use the spec-recommended port &lt;code&gt;69&lt;/code&gt; (nice)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;can reply from a predefined portrange (good for firewalls)&lt;/li&gt; 
 &lt;li&gt;only supports the binary/octet/image transfer mode (no netascii)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://datatracker.ietf.org/doc/html/rfc7440"&gt;RFC 7440&lt;/a&gt; is &lt;strong&gt;not&lt;/strong&gt; supported, so will be extremely slow over WAN 
  &lt;ul&gt; 
   &lt;li&gt;assuming default blksize (512), expect 1100 KiB/s over 100BASE-T, 400-500 KiB/s over wifi, 200 on bad wifi&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;most clients expect to find TFTP on port 69, but on linux and macos you need to be root to listen on that. Alternatively, listen on 3969 and use NAT on the server to forward 69 to that port;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;on linux: &lt;code&gt;iptables -t nat -A PREROUTING -i eth0 -p udp --dport 69 -j REDIRECT --to-port 3969&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;some recommended TFTP clients:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;curl (cross-platform, read/write) 
  &lt;ul&gt; 
   &lt;li&gt;get: &lt;code&gt;curl --tftp-blksize 1428 tftp://127.0.0.1:3969/firmware.bin&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;put: &lt;code&gt;curl --tftp-blksize 1428 -T firmware.bin tftp://127.0.0.1:3969/&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;windows: &lt;code&gt;tftp.exe&lt;/code&gt; (you probably already have it) 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;tftp -i 127.0.0.1 put firmware.bin&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;linux: &lt;code&gt;tftp-hpa&lt;/code&gt;, &lt;code&gt;atftp&lt;/code&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;atftp --option "blksize 1428" 127.0.0.1 3969 -p -l firmware.bin -r firmware.bin&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;tftp -v -m binary 127.0.0.1 3969 -c put firmware.bin&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;smb server&lt;/h2&gt; 
&lt;p&gt;unsafe, slow, not recommended for wan, enable with &lt;code&gt;--smb&lt;/code&gt; for read-only or &lt;code&gt;--smbw&lt;/code&gt; for read-write&lt;/p&gt; 
&lt;p&gt;click the &lt;a href="http://127.0.0.1:3923/?hc"&gt;connect&lt;/a&gt; button in the control-panel to see connection instructions for windows, linux, macos&lt;/p&gt; 
&lt;p&gt;dependencies: &lt;code&gt;python3 -m pip install --user -U impacket==0.11.0&lt;/code&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;newer versions of impacket will hopefully work just fine but there is monkeypatching so maybe not&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;some &lt;strong&gt;BIG WARNINGS&lt;/strong&gt; specific to SMB/CIFS, in decreasing importance:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;not entirely confident that read-only is read-only&lt;/li&gt; 
 &lt;li&gt;the smb backend is not fully integrated with vfs, meaning there could be security issues (path traversal). Please use &lt;code&gt;--smb-port&lt;/code&gt; (see below) and &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/bin/prisonparty.sh"&gt;prisonparty&lt;/a&gt; or &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/bin/bubbleparty.sh"&gt;bubbleparty&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;account passwords work per-volume as expected, and so does account permissions (read/write/move/delete), but &lt;code&gt;--smbw&lt;/code&gt; must be given to allow write-access from smb&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#shadowing"&gt;shadowing&lt;/a&gt; probably works as expected but no guarantees&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;not compatible with pw-hashing or &lt;code&gt;--usernames&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;and some minor issues,&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;clients only see the first ~400 files in big folders; 
  &lt;ul&gt; 
   &lt;li&gt;this was originally due to &lt;a href="https://github.com/SecureAuthCorp/impacket/issues/1433"&gt;impacket#1433&lt;/a&gt; which was fixed in impacket-0.12, so you can disable the workaround with &lt;code&gt;--smb-nwa-1&lt;/code&gt; but then you get unacceptably poor performance instead&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;hot-reload of server config (&lt;code&gt;/?reload=cfg&lt;/code&gt;) does not include the &lt;code&gt;[global]&lt;/code&gt; section (commandline args)&lt;/li&gt; 
 &lt;li&gt;listens on the first IPv4 &lt;code&gt;-i&lt;/code&gt; interface only (default = :: = 0.0.0.0 = all)&lt;/li&gt; 
 &lt;li&gt;login doesn't work on winxp, but anonymous access is ok -- remove all accounts from copyparty config for that to work 
  &lt;ul&gt; 
   &lt;li&gt;win10 onwards does not allow connecting anonymously / without accounts&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;python3 only&lt;/li&gt; 
 &lt;li&gt;slow (the builtin webdav support in windows is 5x faster, and rclone-webdav is 30x faster) 
  &lt;ul&gt; 
   &lt;li&gt;those numbers are specifically for copyparty's smb-server (because it sucks); other smb-servers should be similar to webdav&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;known client bugs:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;on win7 only, &lt;code&gt;--smb1&lt;/code&gt; is much faster than smb2 (default) because it keeps rescanning folders on smb2 
  &lt;ul&gt; 
   &lt;li&gt;however smb1 is buggy and is not enabled by default on win10 onwards&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;windows cannot access folders which contain filenames with invalid unicode or forbidden characters (&lt;code&gt;&amp;lt;&amp;gt;:"/\|?*&lt;/code&gt;), or names ending with &lt;code&gt;.&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;the smb protocol listens on TCP port 445, which is a privileged port on linux and macos, which would require running copyparty as root. However, this can be avoided by listening on another port using &lt;code&gt;--smb-port 3945&lt;/code&gt; and then using NAT on the server to forward the traffic from 445 to there;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;on linux: &lt;code&gt;iptables -t nat -A PREROUTING -i eth0 -p tcp --dport 445 -j REDIRECT --to-port 3945&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;authenticate with one of the following:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;username &lt;code&gt;$username&lt;/code&gt;, password &lt;code&gt;$password&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;username &lt;code&gt;$password&lt;/code&gt;, password &lt;code&gt;k&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;browser ux&lt;/h2&gt; 
&lt;p&gt;tweaking the ui&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;set default sort order globally with &lt;code&gt;--sort&lt;/code&gt; or per-volume with the &lt;code&gt;sort&lt;/code&gt; volflag; specify one or more comma-separated columns to sort by, and prefix the column name with &lt;code&gt;-&lt;/code&gt; for reverse sort 
  &lt;ul&gt; 
   &lt;li&gt;the column names you can use are visible as tooltips when hovering over the column headers in the directory listing, for example &lt;code&gt;href ext sz ts tags/.up_at tags/Circle tags/.tn tags/Artist tags/Title&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;to sort in music order (album, track, artist, title) with filename as fallback, you could &lt;code&gt;--sort tags/Circle,tags/.tn,tags/Artist,tags/Title,href&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;to sort by upload date, first enable showing the upload date in the listing with &lt;code&gt;-e2d -mte +.up_at&lt;/code&gt; and then &lt;code&gt;--sort tags/.up_at&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/docs/rice"&gt;./docs/rice&lt;/a&gt; for more, including how to add stuff (css/&lt;code&gt;&amp;lt;meta&amp;gt;&lt;/code&gt;/...) to the html &lt;code&gt;&amp;lt;head&amp;gt;&lt;/code&gt; tag, or to add your own translation&lt;/p&gt; 
&lt;h2&gt;opengraph&lt;/h2&gt; 
&lt;p&gt;discord and social-media embeds&lt;/p&gt; 
&lt;p&gt;can be enabled globally with &lt;code&gt;--og&lt;/code&gt; or per-volume with volflag &lt;code&gt;og&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;note that this disables hotlinking because the opengraph spec demands it; to sneak past this intentional limitation, you can enable opengraph selectively by user-agent, for example &lt;code&gt;--og-ua '(Discord|Twitter|Slack)bot'&lt;/code&gt; (or volflag &lt;code&gt;og_ua&lt;/code&gt;)&lt;/p&gt; 
&lt;p&gt;you can also hotlink files regardless by appending &lt;code&gt;?raw&lt;/code&gt; to the url&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;WARNING: if you plan to use WebDAV, then &lt;code&gt;--og-ua&lt;/code&gt; / &lt;code&gt;og_ua&lt;/code&gt; must be configured&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;if you want to entirely replace the copyparty response with your own jinja2 template, give the template filepath to &lt;code&gt;--og-tpl&lt;/code&gt; or volflag &lt;code&gt;og_tpl&lt;/code&gt; (all members of &lt;code&gt;HttpCli&lt;/code&gt; are available through the &lt;code&gt;this&lt;/code&gt; object)&lt;/p&gt; 
&lt;h2&gt;file deduplication&lt;/h2&gt; 
&lt;p&gt;enable symlink-based upload deduplication globally with &lt;code&gt;--dedup&lt;/code&gt; or per-volume with volflag &lt;code&gt;dedup&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;by default, when someone tries to upload a file that already exists on the server, the upload will be politely declined, and the server will copy the existing file over to where the upload would have gone&lt;/p&gt; 
&lt;p&gt;if you enable deduplication with &lt;code&gt;--dedup&lt;/code&gt; then it'll create a symlink instead of a full copy, thus reducing disk space usage&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;on the contrary, if your server is hooked up to s3-glacier or similar storage where reading is expensive, and you cannot use &lt;code&gt;--safe-dedup=1&lt;/code&gt; because you have other software tampering with your files, so you want to entirely disable detection of duplicate data instead, then you can specify &lt;code&gt;--no-clone&lt;/code&gt; globally or &lt;code&gt;noclone&lt;/code&gt; as a volflag&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;warning:&lt;/strong&gt; when enabling dedup, you should also:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;enable indexing with &lt;code&gt;-e2dsa&lt;/code&gt; or volflag &lt;code&gt;e2dsa&lt;/code&gt; (see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#file-indexing"&gt;file indexing&lt;/a&gt; section below); strongly recommended&lt;/li&gt; 
 &lt;li&gt;...and/or &lt;code&gt;--hardlink-only&lt;/code&gt; to use hardlink-based deduplication instead of symlinks; see explanation below&lt;/li&gt; 
 &lt;li&gt;...and/or &lt;code&gt;--reflink&lt;/code&gt; to use CoW/reflink-based dedup (much safer than hardlink, but OS/FS-dependent)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;it will not be safe to rename/delete files if you only enable dedup and none of the above; if you enable indexing then it is not &lt;em&gt;necessary&lt;/em&gt; to also do hardlinks (but you may still want to)&lt;/p&gt; 
&lt;p&gt;by default, deduplication is done based on symlinks (symbolic links); these are tiny files which are pointers to the nearest full copy of the file&lt;/p&gt; 
&lt;p&gt;you can choose to use hardlinks instead of softlinks, globally with &lt;code&gt;--hardlink-only&lt;/code&gt; or volflag &lt;code&gt;hardlinkonly&lt;/code&gt;, and you can choose to use reflinks with &lt;code&gt;--reflink&lt;/code&gt; or volflag &lt;code&gt;reflink&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;advantages of using reflinks (CoW, copy-on-write):&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;entirely safe (when your filesystem supports it correctly); either file can be edited or deleted without affecting other copies&lt;/li&gt; 
 &lt;li&gt;only linux 5.3 or newer, only python 3.14 or newer, only some filesystems (btrfs probably ok, maybe xfs too, but zfs had bugs)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;advantages of using hardlinks:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;hardlinks are more compatible with other software; they behave entirely like regular files&lt;/li&gt; 
 &lt;li&gt;you can safely move and rename files using other file managers 
  &lt;ul&gt; 
   &lt;li&gt;symlinks need to be managed by copyparty to ensure the destinations remain correct&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;advantages of using symlinks (default):&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;each symlink can have its own last-modified timestamp, but a single timestamp is shared by all hardlinks&lt;/li&gt; 
 &lt;li&gt;symlinks make it more obvious to other software that the file is not a regular file, so this can be less dangerous 
  &lt;ul&gt; 
   &lt;li&gt;hardlinks look like regular files, so other software may assume they are safe to edit without affecting the other copies&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;warning:&lt;/strong&gt; if you edit the contents of a deduplicated file, then you will also edit all other copies of that file! This is especially surprising with hardlinks, because they look like regular files, but that same file exists in multiple locations&lt;/p&gt; 
&lt;p&gt;global-option &lt;code&gt;--xlink&lt;/code&gt; / volflag &lt;code&gt;xlink&lt;/code&gt; additionally enables deduplication across volumes, but this is probably buggy and not recommended&lt;/p&gt; 
&lt;p&gt;config file example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;[global]
  e2dsa  # scan and index filesystem on startup
  dedup  # symlink-based deduplication for all volumes

[/media]
  /mnt/nas/media
  flags:
    hardlinkonly  # this vol does hardlinks instead of symlinks
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;file indexing&lt;/h2&gt; 
&lt;p&gt;enable music search, upload-undo, and better dedup&lt;/p&gt; 
&lt;p&gt;file indexing relies on two database tables, the up2k filetree (&lt;code&gt;-e2d&lt;/code&gt;) and the metadata tags (&lt;code&gt;-e2t&lt;/code&gt;), stored in &lt;code&gt;.hist/up2k.db&lt;/code&gt;. Configuration can be done through arguments, volflags, or a mix of both.&lt;/p&gt; 
&lt;p&gt;through arguments:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;-e2d&lt;/code&gt; enables file indexing on upload&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-e2ds&lt;/code&gt; also scans writable folders for new files on startup&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-e2dsa&lt;/code&gt; also scans all mounted volumes (including readonly ones)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-e2t&lt;/code&gt; enables metadata indexing on upload&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-e2ts&lt;/code&gt; also scans for tags in all files that don't have tags yet&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-e2tsr&lt;/code&gt; also deletes all existing tags, doing a full reindex&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-e2v&lt;/code&gt; verifies file integrity at startup, comparing hashes from the db&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-e2vu&lt;/code&gt; patches the database with the new hashes from the filesystem&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-e2vp&lt;/code&gt; panics and kills copyparty instead&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;the same arguments can be set as volflags, in addition to &lt;code&gt;d2d&lt;/code&gt;, &lt;code&gt;d2ds&lt;/code&gt;, &lt;code&gt;d2t&lt;/code&gt;, &lt;code&gt;d2ts&lt;/code&gt;, &lt;code&gt;d2v&lt;/code&gt; for disabling:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;-v ~/music::r:c,e2ds,e2tsr&lt;/code&gt; does a full reindex of everything on startup&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-v ~/music::r:c,d2d&lt;/code&gt; disables &lt;strong&gt;all&lt;/strong&gt; indexing, even if any &lt;code&gt;-e2*&lt;/code&gt; are on&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-v ~/music::r:c,d2t&lt;/code&gt; disables all &lt;code&gt;-e2t*&lt;/code&gt; (tags), does not affect &lt;code&gt;-e2d*&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-v ~/music::r:c,d2ds&lt;/code&gt; disables on-boot scans; only index new uploads&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-v ~/music::r:c,d2ts&lt;/code&gt; same except only affecting tags&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;note:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;upload-times can be displayed in the file listing by enabling the &lt;code&gt;.up_at&lt;/code&gt; metadata key, either globally with &lt;code&gt;-e2d -mte +.up_at&lt;/code&gt; or per-volume with volflags &lt;code&gt;e2d,mte=+.up_at&lt;/code&gt; (will have a ~17% performance impact on directory listings)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;e2tsr&lt;/code&gt; is probably always overkill, since &lt;code&gt;e2ds&lt;/code&gt;/&lt;code&gt;e2dsa&lt;/code&gt; would pick up any file modifications and &lt;code&gt;e2ts&lt;/code&gt; would then reindex those, unless there is a new copyparty version with new parsers and the release note says otherwise&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;config file example (these options are recommended btw):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;[global]
  e2dsa  # scan and index all files in all volumes on startup
  e2ts   # check newly-discovered or uploaded files for media tags
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;exclude-patterns&lt;/h3&gt; 
&lt;p&gt;to save some time, you can provide a regex pattern for filepaths to only index by filename/path/size/last-modified (and not the hash of the file contents) by setting &lt;code&gt;--no-hash '\.iso$'&lt;/code&gt; or the volflag &lt;code&gt;:c,nohash=\.iso$&lt;/code&gt;, this has the following consequences:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;initial indexing is way faster, especially when the volume is on a network disk&lt;/li&gt; 
 &lt;li&gt;makes it impossible to &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#file-search"&gt;file-search&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;if someone uploads the same file contents, the upload will not be detected as a dupe, so it will not get symlinked or rejected&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;similarly, you can fully ignore files/folders using &lt;code&gt;--no-idx [...]&lt;/code&gt; and &lt;code&gt;:c,noidx=\.iso$&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;NOTE: &lt;code&gt;no-idx&lt;/code&gt; and/or &lt;code&gt;no-hash&lt;/code&gt; prevents deduplication of those files&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;when running on macos, all the usual apple metadata files are excluded by default&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;if you set &lt;code&gt;--no-hash [...]&lt;/code&gt; globally, you can enable hashing for specific volumes using flag &lt;code&gt;:c,nohash=&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;to exclude certain filepaths from search-results, use &lt;code&gt;--srch-excl&lt;/code&gt; or volflag &lt;code&gt;srch_excl&lt;/code&gt; instead of &lt;code&gt;--no-idx&lt;/code&gt;, for example &lt;code&gt;--srch-excl 'password|logs/[0-9]'&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;config file example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;[/games]
  /mnt/nas/games
  flags:
    noidx: \.iso$  # skip indexing iso-files
    srch_excl: password|logs/[0-9]  # filter search results
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;filesystem guards&lt;/h3&gt; 
&lt;p&gt;avoid traversing into other filesystems using &lt;code&gt;--xdev&lt;/code&gt; / volflag &lt;code&gt;:c,xdev&lt;/code&gt;, skipping any symlinks or bind-mounts to another HDD for example&lt;/p&gt; 
&lt;p&gt;and/or you can &lt;code&gt;--xvol&lt;/code&gt; / &lt;code&gt;:c,xvol&lt;/code&gt; to ignore all symlinks leaving the volume's top directory, but still allow bind-mounts pointing elsewhere&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;symlinks are permitted with &lt;code&gt;xvol&lt;/code&gt; if they point into another volume where the user has the same level of access&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;these options will reduce performance; unlikely worst-case estimates are 14% reduction for directory listings, 35% for download-as-tar&lt;/p&gt; 
&lt;p&gt;as of copyparty v1.7.0 these options also prevent file access at runtime -- in previous versions it was just hints for the indexer&lt;/p&gt; 
&lt;h3&gt;periodic rescan&lt;/h3&gt; 
&lt;p&gt;filesystem monitoring; if copyparty is not the only software doing stuff on your filesystem, you may want to enable periodic rescans to keep the index up to date&lt;/p&gt; 
&lt;p&gt;argument &lt;code&gt;--re-maxage 60&lt;/code&gt; will rescan all volumes every 60 sec, same as volflag &lt;code&gt;:c,scan=60&lt;/code&gt; to specify it per-volume&lt;/p&gt; 
&lt;p&gt;uploads are disabled while a rescan is happening, so rescans will be delayed by &lt;code&gt;--db-act&lt;/code&gt; (default 10 sec) when there is write-activity going on (uploads, renames, ...)&lt;/p&gt; 
&lt;p&gt;note: folder-thumbnails are selected during filesystem indexing, so periodic rescans can be used to keep them accurate as images are uploaded/deleted (or manually do a rescan with the &lt;code&gt;reload&lt;/code&gt; button in the controlpanel)&lt;/p&gt; 
&lt;p&gt;config file example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;[global]
  re-maxage: 3600

[/pics]
  /mnt/nas/pics
  flags:
    scan: 900
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;upload rules&lt;/h2&gt; 
&lt;p&gt;set upload rules using volflags, some examples:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;:c,sz=1k-3m&lt;/code&gt; sets allowed filesize between 1 KiB and 3 MiB inclusive (suffixes: &lt;code&gt;b&lt;/code&gt;, &lt;code&gt;k&lt;/code&gt;, &lt;code&gt;m&lt;/code&gt;, &lt;code&gt;g&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;:c,df=4g&lt;/code&gt; block uploads if there would be less than 4 GiB free disk space afterwards&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;:c,vmaxb=1g&lt;/code&gt; block uploads if total volume size would exceed 1 GiB afterwards&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;:c,vmaxn=4k&lt;/code&gt; block uploads if volume would contain more than 4096 files afterwards&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;:c,nosub&lt;/code&gt; disallow uploading into subdirectories; goes well with &lt;code&gt;rotn&lt;/code&gt; and &lt;code&gt;rotf&lt;/code&gt;:&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;:c,rotn=1000,2&lt;/code&gt; moves uploads into subfolders, up to 1000 files in each folder before making a new one, two levels deep (must be at least 1)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;:c,rotf=%Y/%m/%d/%H&lt;/code&gt; enforces files to be uploaded into a structure of subfolders according to that date format 
  &lt;ul&gt; 
   &lt;li&gt;if someone uploads to &lt;code&gt;/foo/bar&lt;/code&gt; the path would be rewritten to &lt;code&gt;/foo/bar/2021/08/06/23&lt;/code&gt; for example&lt;/li&gt; 
   &lt;li&gt;but the actual value is not verified, just the structure, so the uploader can choose any values which conform to the format string 
    &lt;ul&gt; 
     &lt;li&gt;just to avoid additional complexity in up2k which is enough of a mess already&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;:c,lifetime=300&lt;/code&gt; delete uploaded files when they become 5 minutes old&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;you can also set transaction limits which apply per-IP and per-volume, but these assume &lt;code&gt;-j 1&lt;/code&gt; (default) otherwise the limits will be off, for example &lt;code&gt;-j 4&lt;/code&gt; would allow anywhere between 1x and 4x the limits you set depending on which processing node the client gets routed to&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;:c,maxn=250,3600&lt;/code&gt; allows 250 files over 1 hour from each IP (tracked per-volume)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;:c,maxb=1g,300&lt;/code&gt; allows 1 GiB total over 5 minutes from each IP (tracked per-volume)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;notes:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;vmaxb&lt;/code&gt; and &lt;code&gt;vmaxn&lt;/code&gt; requires either the &lt;code&gt;e2ds&lt;/code&gt; volflag or &lt;code&gt;-e2dsa&lt;/code&gt; global-option&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;config file example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;[/inc]
  /mnt/nas/uploads
  accs:
    w: *    # anyone can upload here
    rw: ed  # only user "ed" can read-write
  flags:
    e2ds       # filesystem indexing is required for many of these:
    sz: 1k-3m  # accept upload only if filesize in this range
    df: 4g     # free disk space cannot go lower than this
    vmaxb: 1g  # volume can never exceed 1 GiB
    vmaxn: 4k  # ...or 4000 files, whichever comes first
    nosub      # must upload to toplevel folder
    lifetime: 300   # uploads are deleted after 5min
    maxn: 250,3600  # each IP can upload 250 files in 1 hour
    maxb: 1g,300    # each IP can upload 1 GiB over 5 minutes
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;compress uploads&lt;/h2&gt; 
&lt;p&gt;files can be autocompressed on upload, either on user-request (if config allows) or forced by server-config&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;volflag &lt;code&gt;gz&lt;/code&gt; allows gz compression&lt;/li&gt; 
 &lt;li&gt;volflag &lt;code&gt;xz&lt;/code&gt; allows lzma compression&lt;/li&gt; 
 &lt;li&gt;volflag &lt;code&gt;pk&lt;/code&gt; &lt;strong&gt;forces&lt;/strong&gt; compression on all files&lt;/li&gt; 
 &lt;li&gt;url parameter &lt;code&gt;pk&lt;/code&gt; requests compression with server-default algorithm&lt;/li&gt; 
 &lt;li&gt;url parameter &lt;code&gt;gz&lt;/code&gt; or &lt;code&gt;xz&lt;/code&gt; requests compression with a specific algorithm&lt;/li&gt; 
 &lt;li&gt;url parameter &lt;code&gt;xz&lt;/code&gt; requests xz compression&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;things to note,&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;the &lt;code&gt;gz&lt;/code&gt; and &lt;code&gt;xz&lt;/code&gt; arguments take a single optional argument, the compression level (range 0 to 9)&lt;/li&gt; 
 &lt;li&gt;the &lt;code&gt;pk&lt;/code&gt; volflag takes the optional argument &lt;code&gt;ALGORITHM,LEVEL&lt;/code&gt; which will then be forced for all uploads, for example &lt;code&gt;gz,9&lt;/code&gt; or &lt;code&gt;xz,0&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;default compression is gzip level 9&lt;/li&gt; 
 &lt;li&gt;all upload methods except up2k are supported&lt;/li&gt; 
 &lt;li&gt;the files will be indexed after compression, so dupe-detection and file-search will not work as expected&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;some examples,&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;-v inc:inc:w:c,pk=xz,0&lt;/code&gt;&lt;br /&gt; folder named inc, shared at inc, write-only for everyone, forces xz compression at level 0&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-v inc:inc:w:c,pk&lt;/code&gt;&lt;br /&gt; same write-only inc, but forces gz compression (default) instead of xz&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-v inc:inc:w:c,gz&lt;/code&gt;&lt;br /&gt; allows (but does not force) gz compression if client uploads to &lt;code&gt;/inc?pk&lt;/code&gt; or &lt;code&gt;/inc?gz&lt;/code&gt; or &lt;code&gt;/inc?gz=4&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;chmod and chown&lt;/h2&gt; 
&lt;p&gt;per-volume filesystem-permissions and ownership&lt;/p&gt; 
&lt;p&gt;by default:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;all folders are chmod 755&lt;/li&gt; 
 &lt;li&gt;files are usually chmod 644 (umask-defined)&lt;/li&gt; 
 &lt;li&gt;user/group is whatever copyparty is running as&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;this can be configured per-volume:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;volflag &lt;code&gt;chmod_f&lt;/code&gt; sets file permissions; default=&lt;code&gt;644&lt;/code&gt; (usually)&lt;/li&gt; 
 &lt;li&gt;volflag &lt;code&gt;chmod_d&lt;/code&gt; sets directory permissions; default=&lt;code&gt;755&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;volflag &lt;code&gt;uid&lt;/code&gt; sets the owner user-id&lt;/li&gt; 
 &lt;li&gt;volflag &lt;code&gt;gid&lt;/code&gt; sets the owner group-id&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;notes:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;gid&lt;/code&gt; can only be set to one of the groups which the copyparty process is a member of&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;uid&lt;/code&gt; can only be set if copyparty is running as root (i appreciate your faith)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;other flags&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;:c,magic&lt;/code&gt; enables filetype detection for nameless uploads, same as &lt;code&gt;--magic&lt;/code&gt; 
  &lt;ul&gt; 
   &lt;li&gt;needs &lt;a href="https://pypi.org/project/python-magic/"&gt;https://pypi.org/project/python-magic/&lt;/a&gt; &lt;code&gt;python3 -m pip install --user -U python-magic&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;on windows grab this instead &lt;code&gt;python3 -m pip install --user -U python-magic-bin&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;database location&lt;/h2&gt; 
&lt;p&gt;in-volume (&lt;code&gt;.hist/up2k.db&lt;/code&gt;, default) or somewhere else&lt;/p&gt; 
&lt;p&gt;copyparty creates a subfolder named &lt;code&gt;.hist&lt;/code&gt; inside each volume where it stores the database, thumbnails, and some other stuff&lt;/p&gt; 
&lt;p&gt;this can instead be kept in a single place using the &lt;code&gt;--hist&lt;/code&gt; argument, or the &lt;code&gt;hist=&lt;/code&gt; volflag, or a mix of both:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;--hist ~/.cache/copyparty -v ~/music::r:c,hist=-&lt;/code&gt; sets &lt;code&gt;~/.cache/copyparty&lt;/code&gt; as the default place to put volume info, but &lt;code&gt;~/music&lt;/code&gt; gets the regular &lt;code&gt;.hist&lt;/code&gt; subfolder (&lt;code&gt;-&lt;/code&gt; restores default behavior)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;by default, the per-volume &lt;code&gt;up2k.db&lt;/code&gt; sqlite3-database for &lt;code&gt;-e2d&lt;/code&gt; and &lt;code&gt;-e2t&lt;/code&gt; is stored next to the thumbnails according to the &lt;code&gt;--hist&lt;/code&gt; option, but the global-option &lt;code&gt;--dbpath&lt;/code&gt; and/or volflag &lt;code&gt;dbpath&lt;/code&gt; can be used to put the database somewhere else&lt;/p&gt; 
&lt;p&gt;if your storage backend is unreliable (NFS or bad HDDs), you can specify one or more "landmarks" to look for before doing anything database-related. A landmark is a file which is always expected to exist inside the volume. This avoids spurious filesystem rescans in the event of an outage. One line per landmark (see example below)&lt;/p&gt; 
&lt;p&gt;note:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;putting the hist-folders on an SSD is strongly recommended for performance&lt;/li&gt; 
 &lt;li&gt;markdown edits are always stored in a local &lt;code&gt;.hist&lt;/code&gt; subdirectory&lt;/li&gt; 
 &lt;li&gt;on windows the volflag path is cyglike, so &lt;code&gt;/c/temp&lt;/code&gt; means &lt;code&gt;C:\temp&lt;/code&gt; but use regular paths for &lt;code&gt;--hist&lt;/code&gt; 
  &lt;ul&gt; 
   &lt;li&gt;you can use cygpaths for volumes too, &lt;code&gt;-v C:\Users::r&lt;/code&gt; and &lt;code&gt;-v /c/users::r&lt;/code&gt; both work&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;config file example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;[global]
  hist: ~/.cache/copyparty  # put db/thumbs/etc. here by default

[/pics]
  /mnt/nas/pics
  flags:
    hist: -  # restore the default (/mnt/nas/pics/.hist/)
    hist: /mnt/nas/cache/pics/  # can be absolute path
    landmark: me.jpg  # /mnt/nas/pics/me.jpg must be readable to enable db
    landmark: info/a.txt^=ok  # and this textfile must start with "ok"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;metadata from audio files&lt;/h2&gt; 
&lt;p&gt;set &lt;code&gt;-e2t&lt;/code&gt; to index tags on upload&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;-mte&lt;/code&gt; decides which tags to index and display in the browser (and also the display order), this can be changed per-volume:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;-v ~/music::r:c,mte=title,artist&lt;/code&gt; indexes and displays &lt;em&gt;title&lt;/em&gt; followed by &lt;em&gt;artist&lt;/em&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;if you add/remove a tag from &lt;code&gt;mte&lt;/code&gt; you will need to run with &lt;code&gt;-e2tsr&lt;/code&gt; once to rebuild the database, otherwise only new files will be affected&lt;/p&gt; 
&lt;p&gt;but instead of using &lt;code&gt;-mte&lt;/code&gt;, &lt;code&gt;-mth&lt;/code&gt; is a better way to hide tags in the browser: these tags will not be displayed by default, but they still get indexed and become searchable, and users can choose to unhide them in the &lt;code&gt;[âš™ï¸] config&lt;/code&gt; pane&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;-mtm&lt;/code&gt; can be used to add or redefine a metadata mapping, say you have media files with &lt;code&gt;foo&lt;/code&gt; and &lt;code&gt;bar&lt;/code&gt; tags and you want them to display as &lt;code&gt;qux&lt;/code&gt; in the browser (preferring &lt;code&gt;foo&lt;/code&gt; if both are present), then do &lt;code&gt;-mtm qux=foo,bar&lt;/code&gt; and now you can &lt;code&gt;-mte artist,title,qux&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;tags that start with a &lt;code&gt;.&lt;/code&gt; such as &lt;code&gt;.bpm&lt;/code&gt; and &lt;code&gt;.dur&lt;/code&gt;(ation) indicate numeric value&lt;/p&gt; 
&lt;p&gt;see the beautiful mess of a dictionary in &lt;a href="https://github.com/9001/copyparty/raw/hovudstraum/copyparty/mtag.py"&gt;mtag.py&lt;/a&gt; for the default mappings (should cover mp3,opus,flac,m4a,wav,aif,)&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;--no-mutagen&lt;/code&gt; disables Mutagen and uses FFprobe instead, which...&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;is about 20x slower than Mutagen&lt;/li&gt; 
 &lt;li&gt;catches a few tags that Mutagen doesn't 
  &lt;ul&gt; 
   &lt;li&gt;melodic key, video resolution, framerate, pixfmt&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;avoids pulling any GPL code into copyparty&lt;/li&gt; 
 &lt;li&gt;more importantly runs FFprobe on incoming files which is bad if your FFmpeg has a cve&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;code&gt;--mtag-to&lt;/code&gt; sets the tag-scan timeout; very high default (60 sec) to cater for zfs and other randomly-freezing filesystems. Lower values like 10 are usually safe, allowing for faster processing of tricky files&lt;/p&gt; 
&lt;h2&gt;file parser plugins&lt;/h2&gt; 
&lt;p&gt;provide custom parsers to index additional tags, also see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/bin/mtag/README.md"&gt;./bin/mtag/README.md&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;copyparty can invoke external programs to collect additional metadata for files using &lt;code&gt;mtp&lt;/code&gt; (either as argument or volflag), there is a default timeout of 60sec, and only files which contain audio get analyzed by default (see ay/an/ad below)&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;-mtp .bpm=~/bin/audio-bpm.py&lt;/code&gt; will execute &lt;code&gt;~/bin/audio-bpm.py&lt;/code&gt; with the audio file as argument 1 to provide the &lt;code&gt;.bpm&lt;/code&gt; tag, if that does not exist in the audio metadata&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-mtp key=f,t5,~/bin/audio-key.py&lt;/code&gt; uses &lt;code&gt;~/bin/audio-key.py&lt;/code&gt; to get the &lt;code&gt;key&lt;/code&gt; tag, replacing any existing metadata tag (&lt;code&gt;f,&lt;/code&gt;), aborting if it takes longer than 5sec (&lt;code&gt;t5,&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-v ~/music::r:c,mtp=.bpm=~/bin/audio-bpm.py:c,mtp=key=f,t5,~/bin/audio-key.py&lt;/code&gt; both as a per-volume config wow this is getting ugly&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;em&gt;but wait, there's more!&lt;/em&gt; &lt;code&gt;-mtp&lt;/code&gt; can be used for non-audio files as well using the &lt;code&gt;a&lt;/code&gt; flag: &lt;code&gt;ay&lt;/code&gt; only do audio files (default), &lt;code&gt;an&lt;/code&gt; only do non-audio files, or &lt;code&gt;ad&lt;/code&gt; do all files (d as in dontcare)&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;"audio file" also means videos btw, as long as there is an audio stream&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-mtp ext=an,~/bin/file-ext.py&lt;/code&gt; runs &lt;code&gt;~/bin/file-ext.py&lt;/code&gt; to get the &lt;code&gt;ext&lt;/code&gt; tag only if file is not audio (&lt;code&gt;an&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-mtp arch,built,ver,orig=an,eexe,edll,~/bin/exe.py&lt;/code&gt; runs &lt;code&gt;~/bin/exe.py&lt;/code&gt; to get properties about windows-binaries only if file is not audio (&lt;code&gt;an&lt;/code&gt;) and file extension is exe or dll&lt;/li&gt; 
 &lt;li&gt;if you want to daisychain parsers, use the &lt;code&gt;p&lt;/code&gt; flag to set processing order 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;-mtp foo=p1,~/a.py&lt;/code&gt; runs before &lt;code&gt;-mtp foo=p2,~/b.py&lt;/code&gt; and will forward all the tags detected so far as json to the stdin of b.py&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;option &lt;code&gt;c0&lt;/code&gt; disables capturing of stdout/stderr, so copyparty will not receive any tags from the process at all -- instead the invoked program is free to print whatever to the console, just using copyparty as a launcher 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;c1&lt;/code&gt; captures stdout only, &lt;code&gt;c2&lt;/code&gt; only stderr, and &lt;code&gt;c3&lt;/code&gt; (default) captures both&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;you can control how the parser is killed if it times out with option &lt;code&gt;kt&lt;/code&gt; killing the entire process tree (default), &lt;code&gt;km&lt;/code&gt; just the main process, or &lt;code&gt;kn&lt;/code&gt; let it continue running until copyparty is terminated&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;if something doesn't work, try &lt;code&gt;--mtag-v&lt;/code&gt; for verbose error messages&lt;/p&gt; 
&lt;p&gt;config file example; note that &lt;code&gt;mtp&lt;/code&gt; is an additive option so all of the mtp options will take effect:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;[/music]
  /mnt/nas/music
  flags:
    mtp: .bpm=~/bin/audio-bpm.py  # assign ".bpm" (numeric) with script
    mtp: key=f,t5,~/bin/audio-key.py  # force/overwrite, 5sec timeout
    mtp: ext=an,~/bin/file-ext.py  # will only run on non-audio files
    mtp: arch,built,ver,orig=an,eexe,edll,~/bin/exe.py  # only exe/dll
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;event hooks&lt;/h2&gt; 
&lt;p&gt;trigger a program on uploads, renames etc (&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/bin/hooks/"&gt;examples&lt;/a&gt;)&lt;/p&gt; 
&lt;p&gt;you can set hooks before and/or after an event happens, and currently you can hook uploads, moves/renames, and deletes&lt;/p&gt; 
&lt;p&gt;there's a bunch of flags and stuff, see &lt;code&gt;--help-hooks&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;if you want to write your own hooks, see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/docs/devnotes.md#event-hooks"&gt;devnotes&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;zeromq&lt;/h3&gt; 
&lt;p&gt;event-hooks can send zeromq messages instead of running programs&lt;/p&gt; 
&lt;p&gt;to send a 0mq message every time a file is uploaded,&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;--xau zmq:pub:tcp://*:5556&lt;/code&gt; sends a PUB to any/all connected SUB clients&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--xau t3,zmq:push:tcp://*:5557&lt;/code&gt; sends a PUSH to exactly one connected PULL client&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--xau t3,j,zmq:req:tcp://localhost:5555&lt;/code&gt; sends a REQ to the connected REP client&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;the PUSH and REQ examples have &lt;code&gt;t3&lt;/code&gt; (timeout after 3 seconds) because they block if there's no clients to talk to&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;the REQ example does &lt;code&gt;t3,j&lt;/code&gt; to send extended upload-info as json instead of just the filesystem-path&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;see &lt;a href="https://github.com/9001/copyparty/raw/hovudstraum/bin/zmq-recv.py"&gt;zmq-recv.py&lt;/a&gt; if you need something to receive the messages with&lt;/p&gt; 
&lt;p&gt;config file example; note that the hooks are additive options, so all of the xau options will take effect:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;[global]
  xau: zmq:pub:tcp://*:5556`  # send a PUB to any/all connected SUB clients
  xau: t3,zmq:push:tcp://*:5557`  # send PUSH to exactly one connected PULL cli
  xau: t3,j,zmq:req:tcp://localhost:5555`  # send REQ to the connected REP cli
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;upload events&lt;/h3&gt; 
&lt;p&gt;the older, more powerful approach (&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/bin/mtag/"&gt;examples&lt;/a&gt;):&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;-v /mnt/inc:inc:w:c,e2d,e2t,mte=+x1:c,mtp=x1=ad,kn,/usr/bin/notify-send
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;that was the commandline example; here's the config file example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;[/inc]
  /mnt/inc
  accs:
    w: *
  flags:
    e2d, e2t  # enable indexing of uploaded files and their tags
    mte: +x1
    mtp: x1=ad,kn,/usr/bin/notify-send
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;so filesystem location &lt;code&gt;/mnt/inc&lt;/code&gt; shared at &lt;code&gt;/inc&lt;/code&gt;, write-only for everyone, appending &lt;code&gt;x1&lt;/code&gt; to the list of tags to index (&lt;code&gt;mte&lt;/code&gt;), and using &lt;code&gt;/usr/bin/notify-send&lt;/code&gt; to "provide" tag &lt;code&gt;x1&lt;/code&gt; for any filetype (&lt;code&gt;ad&lt;/code&gt;) with kill-on-timeout disabled (&lt;code&gt;kn&lt;/code&gt;)&lt;/p&gt; 
&lt;p&gt;that'll run the command &lt;code&gt;notify-send&lt;/code&gt; with the path to the uploaded file as the first and only argument (so on linux it'll show a notification on-screen)&lt;/p&gt; 
&lt;p&gt;note that this is way more complicated than the new &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#event-hooks"&gt;event hooks&lt;/a&gt; but this approach has the following advantages:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;non-blocking and multithreaded; doesn't hold other uploads back&lt;/li&gt; 
 &lt;li&gt;you get access to tags from FFmpeg and other mtp parsers&lt;/li&gt; 
 &lt;li&gt;only trigger on new unique files, not dupes&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;note that it will occupy the parsing threads, so fork anything expensive (or set &lt;code&gt;kn&lt;/code&gt; to have copyparty fork it for you) -- otoh if you want to intentionally queue/singlethread you can combine it with &lt;code&gt;--mtag-mt 1&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;for reference, if you were to do this using event hooks instead, it would be like this: &lt;code&gt;-e2d --xau notify-send,hello,--&lt;/code&gt;&lt;/p&gt; 
&lt;h2&gt;handlers&lt;/h2&gt; 
&lt;p&gt;redefine behavior with plugins (&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/bin/handlers/"&gt;examples&lt;/a&gt;)&lt;/p&gt; 
&lt;p&gt;replace 404 and 403 errors with something completely different (that's it for now)&lt;/p&gt; 
&lt;p&gt;as for client-side stuff, there is &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/contrib/plugins/"&gt;plugins for modifying UI/UX&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;ip auth&lt;/h2&gt; 
&lt;p&gt;autologin based on IP range (CIDR) , using the global-option &lt;code&gt;--ipu&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;for example, if everyone with an IP that starts with &lt;code&gt;192.168.123&lt;/code&gt; should automatically log in as the user &lt;code&gt;spartacus&lt;/code&gt;, then you can either specify &lt;code&gt;--ipu=192.168.123.0/24=spartacus&lt;/code&gt; as a commandline option, or put this in a config file:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;[global]
  ipu: 192.168.123.0/24=spartacus
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;repeat the option to map additional subnets&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;be careful with this one!&lt;/strong&gt; if you have a reverseproxy, then you definitely want to make sure you have &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#real-ip"&gt;real-ip&lt;/a&gt; configured correctly, and it's probably a good idea to nullmap the reverseproxy's IP just in case; so if your reverseproxy is sending requests from &lt;code&gt;172.24.27.9&lt;/code&gt; then that would be &lt;code&gt;--ipu=172.24.27.9/32=&lt;/code&gt;&lt;/p&gt; 
&lt;h3&gt;restrict to ip&lt;/h3&gt; 
&lt;p&gt;limit a user to certain IP ranges (CIDR) , using the global-option &lt;code&gt;--ipr&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;for example, if the user &lt;code&gt;spartacus&lt;/code&gt; should get rejected if they're not connecting from an IP that starts with &lt;code&gt;192.168.123&lt;/code&gt; or &lt;code&gt;172.16&lt;/code&gt;, then you can either specify &lt;code&gt;--ipr=192.168.123.0/24,172.16.0.0/16=spartacus&lt;/code&gt; as a commandline option, or put this in a config file:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;[global]
  ipr: 192.168.123.0/24,172.16.0.0/16=spartacus
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;repeat the option to map additional users&lt;/p&gt; 
&lt;h2&gt;identity providers&lt;/h2&gt; 
&lt;p&gt;replace copyparty passwords with oauth and such&lt;/p&gt; 
&lt;p&gt;you can disable the built-in password-based login system, and instead replace it with a separate piece of software (an identity provider) which will then handle authenticating / authorizing of users; this makes it possible to login with passkeys / fido2 / webauthn / yubikey / ldap / active directory / oauth / many other single-sign-on contraptions&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;the regular config-defined users will be used as a fallback for requests which don't include a valid (trusted) IdP username header&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;if your IdP-server is slow, consider &lt;code&gt;--idp-cookie&lt;/code&gt; and let requests with the cookie &lt;code&gt;cppws&lt;/code&gt; bypass the IdP; experimental sessions-based feature added for a party&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;some popular identity providers are &lt;a href="https://www.authelia.com/"&gt;Authelia&lt;/a&gt; (config-file based) and &lt;a href="https://goauthentik.io/"&gt;authentik&lt;/a&gt; (GUI-based, more complex)&lt;/p&gt; 
&lt;p&gt;there is a &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/docs/examples/docker/idp-authelia-traefik"&gt;docker-compose example&lt;/a&gt; which is hopefully a good starting point (alternatively see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/docs/idp.md"&gt;./docs/idp.md&lt;/a&gt; if you're the DIY type)&lt;/p&gt; 
&lt;p&gt;a more complete example of the copyparty configuration options &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/docs/examples/docker/idp/copyparty.conf"&gt;look like this&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;but if you just want to let users change their own passwords, then you probably want &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#user-changeable-passwords"&gt;user-changeable passwords&lt;/a&gt; instead&lt;/p&gt; 
&lt;h3&gt;generic header auth&lt;/h3&gt; 
&lt;p&gt;other ways to auth by header&lt;/p&gt; 
&lt;p&gt;if you have a middleware which adds a header with a user identifier, for example tailscale's &lt;code&gt;Tailscale-User-Login: alice.m@forest.net&lt;/code&gt; then you can automatically auth as &lt;code&gt;alice&lt;/code&gt; by defining that mapping with &lt;code&gt;--idp-hm-usr '^Tailscale-User-Login^alice.m@forest.net^alice'&lt;/code&gt; or the following config file:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;[global]
  idp-hm-usr: ^Tailscale-User-Login^alice.m@forest.net^alice
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;repeat the whole &lt;code&gt;idp-hm-usr&lt;/code&gt; option to add more mappings&lt;/p&gt; 
&lt;h2&gt;user-changeable passwords&lt;/h2&gt; 
&lt;p&gt;if permitted, users can change their own passwords in the control-panel&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;not compatible with &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#identity-providers"&gt;identity providers&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;must be enabled with &lt;code&gt;--chpw&lt;/code&gt; because account-sharing is a popular usecase&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;if you want to enable the feature but deny password-changing for a specific list of accounts, you can do that with &lt;code&gt;--chpw-no name1,name2,name3,...&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;to perform a password reset, edit the server config and give the user another password there, then do a &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#server-config"&gt;config reload&lt;/a&gt; or server restart&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;the custom passwords are kept in a textfile at filesystem-path &lt;code&gt;--chpw-db&lt;/code&gt;, by default &lt;code&gt;chpw.json&lt;/code&gt; in the copyparty config folder&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;if you run multiple copyparty instances with different users you &lt;em&gt;almost definitely&lt;/em&gt; want to specify separate DBs for each instance&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;if &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#password-hashing"&gt;password hashing&lt;/a&gt; is enabled, the passwords in the db are also hashed&lt;/p&gt; 
    &lt;ul&gt; 
     &lt;li&gt;...which means that all user-defined passwords will be forgotten if you change password-hashing settings&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;using the cloud as storage&lt;/h2&gt; 
&lt;p&gt;connecting to an aws s3 bucket and similar&lt;/p&gt; 
&lt;p&gt;there is no built-in support for this, but you can use FUSE-software such as &lt;a href="https://rclone.org/"&gt;rclone&lt;/a&gt; / &lt;a href="https://github.com/yandex-cloud/geesefs"&gt;geesefs&lt;/a&gt; / &lt;a href="https://juicefs.com/en/"&gt;JuiceFS&lt;/a&gt; to first mount your cloud storage as a local disk, and then let copyparty use (a folder in) that disk as a volume&lt;/p&gt; 
&lt;p&gt;if copyparty is unable to access the local folder that rclone/geesefs/JuiceFS provides (for example if it looks invisible) then you may need to run rclone with &lt;code&gt;--allow-other&lt;/code&gt; and/or enable &lt;code&gt;user_allow_other&lt;/code&gt; in &lt;code&gt;/etc/fuse.conf&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;you will probably get decent speeds with the default config, however most likely restricted to using one TCP connection per file, so the upload-client won't be able to send multiple chunks in parallel&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;before &lt;a href="https://github.com/9001/copyparty/releases/tag/v1.13.5"&gt;v1.13.5&lt;/a&gt; it was recommended to use the volflag &lt;code&gt;sparse&lt;/code&gt; to force-allow multiple chunks in parallel; this would improve the upload-speed from &lt;code&gt;1.5 MiB/s&lt;/code&gt; to over &lt;code&gt;80 MiB/s&lt;/code&gt; at the risk of provoking latent bugs in S3 or JuiceFS. But v1.13.5 added chunk-stitching, so this is now probably much less important. On the contrary, &lt;code&gt;nosparse&lt;/code&gt; &lt;em&gt;may&lt;/em&gt; now increase performance in some cases. Please try all three options (default, &lt;code&gt;sparse&lt;/code&gt;, &lt;code&gt;nosparse&lt;/code&gt;) as the optimal choice depends on your network conditions and software stack (both the FUSE-driver and cloud-server)&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;someone has also tested geesefs in combination with &lt;a href="https://nuetzlich.net/gocryptfs/"&gt;gocryptfs&lt;/a&gt; with surprisingly good results, getting 60 MiB/s upload speeds on a gbit line, but JuiceFS won with 80 MiB/s using its built-in encryption&lt;/p&gt; 
&lt;p&gt;you may improve performance by specifying larger values for &lt;code&gt;--iobuf&lt;/code&gt; / &lt;code&gt;--s-rd-sz&lt;/code&gt; / &lt;code&gt;--s-wr-sz&lt;/code&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;if you've experimented with this and made interesting observations, please share your findings so we can add a section with specific recommendations :-)&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;hiding from google&lt;/h2&gt; 
&lt;p&gt;tell search engines you don't wanna be indexed, either using the good old &lt;a href="https://www.robotstxt.org/robotstxt.html"&gt;robots.txt&lt;/a&gt; or through copyparty settings:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;--no-robots&lt;/code&gt; adds HTTP (&lt;code&gt;X-Robots-Tag&lt;/code&gt;) and HTML (&lt;code&gt;&amp;lt;meta&amp;gt;&lt;/code&gt;) headers with &lt;code&gt;noindex, nofollow&lt;/code&gt; globally&lt;/li&gt; 
 &lt;li&gt;volflag &lt;code&gt;[...]:c,norobots&lt;/code&gt; does the same thing for that single volume&lt;/li&gt; 
 &lt;li&gt;volflag &lt;code&gt;[...]:c,robots&lt;/code&gt; ALLOWS search-engine crawling for that volume, even if &lt;code&gt;--no-robots&lt;/code&gt; is set globally&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;also, &lt;code&gt;--force-js&lt;/code&gt; disables the plain HTML folder listing, making things harder to parse for &lt;em&gt;some&lt;/em&gt; search engines -- note that crawlers which understand javascript (such as google) will not be affected&lt;/p&gt; 
&lt;h2&gt;themes&lt;/h2&gt; 
&lt;p&gt;you can change the default theme with &lt;code&gt;--theme 2&lt;/code&gt;, and add your own themes by modifying &lt;code&gt;browser.css&lt;/code&gt; or providing your own css to &lt;code&gt;--css-browser&lt;/code&gt;, then telling copyparty they exist by increasing &lt;code&gt;--themes&lt;/code&gt;&lt;/p&gt; 
&lt;table&gt;
 &lt;tbody&gt;
  &lt;tr&gt;
   &lt;td width="33%" align="center"&gt;&lt;a href="https://user-images.githubusercontent.com/241032/165864907-17e2ac7d-319d-4f25-8718-2f376f614b51.png"&gt;&lt;img src="https://user-images.githubusercontent.com/241032/165867551-fceb35dd-38f0-42bb-bef3-25ba651ca69b.png" /&gt;&lt;/a&gt; 0. classic dark&lt;/td&gt;
   &lt;td width="33%" align="center"&gt;&lt;a href="https://user-images.githubusercontent.com/241032/168644399-68938de5-da9b-445f-8d92-b51c74b5f345.png"&gt;&lt;img src="https://user-images.githubusercontent.com/241032/168644404-8e1a2fdc-6e59-4c41-905e-ba5399ed686f.png" /&gt;&lt;/a&gt; 2. flat pm-monokai&lt;/td&gt;
   &lt;td width="33%" align="center"&gt;&lt;a href="https://user-images.githubusercontent.com/241032/165864901-db13a429-a5da-496d-8bc6-ce838547f69d.png"&gt;&lt;img src="https://user-images.githubusercontent.com/241032/165867560-aa834aef-58dc-4abe-baef-7e562b647945.png" /&gt;&lt;/a&gt; 4. vice&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td align="center"&gt;&lt;a href="https://user-images.githubusercontent.com/241032/165864905-692682eb-6fb4-4d40-b6fe-27d2c7d3e2a7.png"&gt;&lt;img src="https://user-images.githubusercontent.com/241032/165867555-080b73b6-6d85-41bb-a7c6-ad277c608365.png" /&gt;&lt;/a&gt; 1. classic light&lt;/td&gt;
   &lt;td align="center"&gt;&lt;a href="https://user-images.githubusercontent.com/241032/168645276-fb02fd19-190a-407a-b8d3-d58fee277e02.png"&gt;&lt;img src="https://user-images.githubusercontent.com/241032/168645280-f0662b3c-9764-4875-a2e2-d91cc8199b23.png" /&gt;&lt;/a&gt; 3. flat light &lt;/td&gt;
   &lt;td align="center"&gt;&lt;a href="https://user-images.githubusercontent.com/241032/165864898-10ce7052-a117-4fcf-845b-b56c91687908.png"&gt;&lt;img src="https://user-images.githubusercontent.com/241032/165867562-f3003d45-dd2a-4564-8aae-fed44c1ae064.png" /&gt;&lt;/a&gt; 5. &lt;a href="https://blog.codinghorror.com/a-tribute-to-the-windows-31-hot-dog-stand-color-scheme/"&gt;hotdog stand&lt;/a&gt;&lt;/td&gt;
  &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;p&gt;the classname of the HTML tag is set according to the selected theme, which is used to set colors as css variables ++&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;each theme &lt;em&gt;generally&lt;/em&gt; has a dark theme (even numbers) and a light theme (odd numbers), showing in pairs&lt;/li&gt; 
 &lt;li&gt;the first theme (theme 0 and 1) is &lt;code&gt;html.a&lt;/code&gt;, second theme (2 and 3) is &lt;code&gt;html.b&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;if a light theme is selected, &lt;code&gt;html.y&lt;/code&gt; is set, otherwise &lt;code&gt;html.z&lt;/code&gt; is&lt;/li&gt; 
 &lt;li&gt;so if the dark edition of the 2nd theme is selected, you use any of &lt;code&gt;html.b&lt;/code&gt;, &lt;code&gt;html.z&lt;/code&gt;, &lt;code&gt;html.bz&lt;/code&gt; to specify rules&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;see the top of &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/copyparty/web/browser.css"&gt;./copyparty/web/browser.css&lt;/a&gt; where the color variables are set, and there's layout-specific stuff near the bottom&lt;/p&gt; 
&lt;p&gt;if you want to change the fonts, see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/docs/rice/"&gt;./docs/rice/&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;complete examples&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/docs/examples/windows.md"&gt;running on windows&lt;/a&gt; for a fancy windows setup&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;or use any of the examples below, just replace &lt;code&gt;python copyparty-sfx.py&lt;/code&gt; with &lt;code&gt;copyparty.exe&lt;/code&gt; if you're using the exe edition&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;allow anyone to download or upload files into the current folder:&lt;br /&gt; &lt;code&gt;python copyparty-sfx.py&lt;/code&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;enable searching and music indexing with &lt;code&gt;-e2dsa -e2ts&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;start an FTP server on port 3921 with &lt;code&gt;--ftp 3921&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;announce it on your LAN with &lt;code&gt;-z&lt;/code&gt; so it appears in windows/Linux file managers&lt;/p&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;anyone can upload, but nobody can see any files (even the uploader):&lt;br /&gt; &lt;code&gt;python copyparty-sfx.py -e2dsa -v .::w&lt;/code&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;block uploads if there's less than 4 GiB free disk space with &lt;code&gt;--df 4&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;show a popup on new uploads with &lt;code&gt;--xau bin/hooks/notify.py&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;anyone can upload, and receive "secret" links for each upload they do:&lt;br /&gt; &lt;code&gt;python copyparty-sfx.py -e2dsa -v .::wG:c,fk=8&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;anyone can browse (&lt;code&gt;r&lt;/code&gt;), only &lt;code&gt;kevin&lt;/code&gt; (password &lt;code&gt;okgo&lt;/code&gt;) can upload/move/delete (&lt;code&gt;A&lt;/code&gt;) files:&lt;br /&gt; &lt;code&gt;python copyparty-sfx.py -e2dsa -a kevin:okgo -v .::r:A,kevin&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;read-only music server:&lt;br /&gt; &lt;code&gt;python copyparty-sfx.py -v /mnt/nas/music:/music:r -e2dsa -e2ts --no-robots --force-js --theme 2&lt;/code&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;...with bpm and key scanning&lt;br /&gt; &lt;code&gt;-mtp .bpm=f,audio-bpm.py -mtp key=f,audio-key.py&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;...with a read-write folder for &lt;code&gt;kevin&lt;/code&gt; whose password is &lt;code&gt;okgo&lt;/code&gt;&lt;br /&gt; &lt;code&gt;-a kevin:okgo -v /mnt/nas/inc:/inc:rw,kevin&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;...with logging to disk&lt;br /&gt; &lt;code&gt;-lo log/cpp-%Y-%m%d-%H%M%S.txt.xz&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;listen on port 80 and 443&lt;/h2&gt; 
&lt;p&gt;become a &lt;em&gt;real&lt;/em&gt; webserver which people can access by just going to your IP or domain without specifying a port&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;if you're on windows,&lt;/strong&gt; then you just need to add the commandline argument &lt;code&gt;-p 80,443&lt;/code&gt; and you're done! nice&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;if you're on macos,&lt;/strong&gt; sorry, I don't know&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;if you're on Linux,&lt;/strong&gt; you have the following 4 options:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;option 1:&lt;/strong&gt; set up a &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#reverse-proxy"&gt;reverse-proxy&lt;/a&gt; -- this one makes a lot of sense if you're running on a proper headless server, because that way you get real HTTPS too&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;option 2:&lt;/strong&gt; NAT to port 3923 -- this is cumbersome since you'll need to do it every time you reboot, and the exact command may depend on your linux distribution:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;iptables -t nat -A PREROUTING -p tcp --dport 80 -j REDIRECT --to-port 3923
iptables -t nat -A PREROUTING -p tcp --dport 443 -j REDIRECT --to-port 3923
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;option 3:&lt;/strong&gt; disable the &lt;a href="https://www.w3.org/Daemon/User/Installation/PrivilegedPorts.html"&gt;security policy&lt;/a&gt; which prevents the use of 80 and 443; this is &lt;em&gt;probably&lt;/em&gt; fine:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;setcap CAP_NET_BIND_SERVICE=+eip $(realpath $(which python))
python copyparty-sfx.py -p 80,443
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;option 4:&lt;/strong&gt; run copyparty as root (please don't)&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;reverse-proxy&lt;/h2&gt; 
&lt;p&gt;running copyparty next to other websites hosted on an existing webserver such as nginx, caddy, or apache&lt;/p&gt; 
&lt;p&gt;you can either:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;give copyparty its own domain or subdomain (recommended)&lt;/li&gt; 
 &lt;li&gt;or do location-based proxying, using &lt;code&gt;--rp-loc=/stuff&lt;/code&gt; to tell copyparty where it is mounted -- has a slight performance cost and higher chance of bugs 
  &lt;ul&gt; 
   &lt;li&gt;if copyparty says &lt;code&gt;incorrect --rp-loc or webserver config; expected vpath starting with [...]&lt;/code&gt; it's likely because the webserver is stripping away the proxy location from the request URLs -- see the &lt;code&gt;ProxyPass&lt;/code&gt; in the apache example below&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;when running behind a reverse-proxy (this includes services like cloudflare), it is important to configure real-ip correctly, as many features rely on knowing the client's IP. The best/safest approach is to configure your reverse-proxy so it gives copyparty a header which only contains the client's true/real IP-address, and then setting &lt;code&gt;--xff-hdr theHeaderName --rproxy 1&lt;/code&gt; but alternatively, if you want/need to let copyparty handle this, look out for red and yellow log messages which explain how to do that. Basically, the log will say this:&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;set &lt;code&gt;--xff-hdr&lt;/code&gt; to the name of the http-header to read the IP from (usually &lt;code&gt;x-forwarded-for&lt;/code&gt;, but cloudflare uses &lt;code&gt;cf-connecting-ip&lt;/code&gt;), and then &lt;code&gt;--xff-src&lt;/code&gt; to the IP of the reverse-proxy so copyparty will trust the xff-hdr. You will also need to configure &lt;code&gt;--rproxy&lt;/code&gt; to &lt;code&gt;1&lt;/code&gt; if the header only contains one IP (the correct one) or to a &lt;em&gt;negative value&lt;/em&gt; if it contains multiple; &lt;code&gt;-1&lt;/code&gt; being the rightmost and most trusted IP (the nearest proxy, so usually not the correct one), &lt;code&gt;-2&lt;/code&gt; being the second-closest hop, and so on&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Note that &lt;code&gt;--rp-loc&lt;/code&gt; in particular will not work at all unless you configure the above correctly&lt;/p&gt; 
&lt;p&gt;some reverse proxies (such as &lt;a href="https://caddyserver.com/"&gt;Caddy&lt;/a&gt;) can automatically obtain a valid https/tls certificate for you, and some support HTTP/2 and QUIC which &lt;em&gt;could&lt;/em&gt; be a nice speed boost, depending on a lot of factors&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;warning:&lt;/strong&gt; nginx-QUIC (HTTP/3) is still experimental and can make uploads much slower, so HTTP/1.1 is recommended for now&lt;/li&gt; 
 &lt;li&gt;depending on server/client, HTTP/1.1 can also be 5x faster than HTTP/2&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;for improved security (and a 10% performance boost) consider listening on a unix-socket with &lt;code&gt;-i unix:770:www:/dev/shm/party.sock&lt;/code&gt; (permission &lt;code&gt;770&lt;/code&gt; means only members of group &lt;code&gt;www&lt;/code&gt; can access it)&lt;/p&gt; 
&lt;p&gt;example webserver / reverse-proxy configs:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/contrib/apache/copyparty.conf"&gt;apache config&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;caddy uds: &lt;code&gt;caddy reverse-proxy --from :8080 --to unix///dev/shm/party.sock&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;caddy tcp: &lt;code&gt;caddy reverse-proxy --from :8081 --to http://127.0.0.1:3923&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/contrib/haproxy/copyparty.conf"&gt;haproxy config&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/contrib/lighttpd/subdomain.conf"&gt;lighttpd subdomain&lt;/a&gt; -- entire domain/subdomain&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/contrib/lighttpd/subpath.conf"&gt;lighttpd subpath&lt;/a&gt; -- location-based (not optimal, but in case you need it)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/contrib/nginx/copyparty.conf"&gt;nginx config&lt;/a&gt; -- recommended&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/contrib/traefik/copyparty.yaml"&gt;traefik config&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;real-ip&lt;/h3&gt; 
&lt;p&gt;teaching copyparty how to see client IPs when running behind a reverse-proxy, or a WAF, or another protection service such as cloudflare&lt;/p&gt; 
&lt;p&gt;if you (and maybe everybody else) keep getting a message that says &lt;code&gt;thank you for playing&lt;/code&gt;, then you've gotten banned for malicious traffic. This ban applies to the IP address that copyparty &lt;em&gt;thinks&lt;/em&gt; identifies the shady client -- so, depending on your setup, you might have to tell copyparty where to find the correct IP&lt;/p&gt; 
&lt;p&gt;for most common setups, there should be a helpful message in the server-log explaining what to do, but see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/docs/xff.md"&gt;docs/xff.md&lt;/a&gt; if you want to learn more, including a quick hack to &lt;strong&gt;just make it work&lt;/strong&gt; (which is &lt;strong&gt;not&lt;/strong&gt; recommended, but hey...)&lt;/p&gt; 
&lt;h3&gt;reverse-proxy performance&lt;/h3&gt; 
&lt;p&gt;most reverse-proxies support connecting to copyparty either using uds/unix-sockets (&lt;code&gt;/dev/shm/party.sock&lt;/code&gt;, faster/recommended) or using tcp (&lt;code&gt;127.0.0.1&lt;/code&gt;)&lt;/p&gt; 
&lt;p&gt;with copyparty listening on a uds / unix-socket / unix-domain-socket and the reverse-proxy connecting to that:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;index.html&lt;/th&gt; 
   &lt;th&gt;upload&lt;/th&gt; 
   &lt;th&gt;download&lt;/th&gt; 
   &lt;th&gt;software&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;28'900 req/s&lt;/td&gt; 
   &lt;td&gt;6'900 MiB/s&lt;/td&gt; 
   &lt;td&gt;7'400 MiB/s&lt;/td&gt; 
   &lt;td&gt;no-proxy&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;18'750 req/s&lt;/td&gt; 
   &lt;td&gt;3'500 MiB/s&lt;/td&gt; 
   &lt;td&gt;2'370 MiB/s&lt;/td&gt; 
   &lt;td&gt;haproxy&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;9'900 req/s&lt;/td&gt; 
   &lt;td&gt;3'750 MiB/s&lt;/td&gt; 
   &lt;td&gt;2'200 MiB/s&lt;/td&gt; 
   &lt;td&gt;caddy&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;18'700 req/s&lt;/td&gt; 
   &lt;td&gt;2'200 MiB/s&lt;/td&gt; 
   &lt;td&gt;1'570 MiB/s&lt;/td&gt; 
   &lt;td&gt;nginx&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;9'700 req/s&lt;/td&gt; 
   &lt;td&gt;1'750 MiB/s&lt;/td&gt; 
   &lt;td&gt;1'830 MiB/s&lt;/td&gt; 
   &lt;td&gt;apache&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;9'900 req/s&lt;/td&gt; 
   &lt;td&gt;1'300 MiB/s&lt;/td&gt; 
   &lt;td&gt;1'470 MiB/s&lt;/td&gt; 
   &lt;td&gt;lighttpd&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;when connecting the reverse-proxy to &lt;code&gt;127.0.0.1&lt;/code&gt; instead (the basic and/or old-fasioned way), speeds are a bit worse:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;index.html&lt;/th&gt; 
   &lt;th&gt;upload&lt;/th&gt; 
   &lt;th&gt;download&lt;/th&gt; 
   &lt;th&gt;software&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;21'200 req/s&lt;/td&gt; 
   &lt;td&gt;5'700 MiB/s&lt;/td&gt; 
   &lt;td&gt;6'700 MiB/s&lt;/td&gt; 
   &lt;td&gt;no-proxy&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;14'500 req/s&lt;/td&gt; 
   &lt;td&gt;1'700 MiB/s&lt;/td&gt; 
   &lt;td&gt;2'170 MiB/s&lt;/td&gt; 
   &lt;td&gt;haproxy&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;11'100 req/s&lt;/td&gt; 
   &lt;td&gt;2'750 MiB/s&lt;/td&gt; 
   &lt;td&gt;2'000 MiB/s&lt;/td&gt; 
   &lt;td&gt;traefik&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;8'400 req/s&lt;/td&gt; 
   &lt;td&gt;2'300 MiB/s&lt;/td&gt; 
   &lt;td&gt;1'950 MiB/s&lt;/td&gt; 
   &lt;td&gt;caddy&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;13'400 req/s&lt;/td&gt; 
   &lt;td&gt;1'100 MiB/s&lt;/td&gt; 
   &lt;td&gt;1'480 MiB/s&lt;/td&gt; 
   &lt;td&gt;nginx&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;8'400 req/s&lt;/td&gt; 
   &lt;td&gt;1'000 MiB/s&lt;/td&gt; 
   &lt;td&gt;1'000 MiB/s&lt;/td&gt; 
   &lt;td&gt;apache&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;6'500 req/s&lt;/td&gt; 
   &lt;td&gt;1'270 MiB/s&lt;/td&gt; 
   &lt;td&gt;1'500 MiB/s&lt;/td&gt; 
   &lt;td&gt;lighttpd&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;in summary, &lt;code&gt;haproxy &amp;gt; caddy &amp;gt; traefik &amp;gt; nginx &amp;gt; apache &amp;gt; lighttpd&lt;/code&gt;, and use uds when possible (traefik does not support it yet)&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;if these results are bullshit because my config examples are bad, please submit corrections!&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;permanent cloudflare tunnel&lt;/h2&gt; 
&lt;p&gt;if you have a domain and want to get your copyparty online real quick, either from your home-PC behind a CGNAT or from a server without an existing &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#reverse-proxy"&gt;reverse-proxy&lt;/a&gt; setup, one approach is to create a &lt;a href="https://developers.cloudflare.com/cloudflare-one/connections/connect-networks/get-started/"&gt;Cloudflare Tunnel&lt;/a&gt; (formerly "Argo Tunnel")&lt;/p&gt; 
&lt;p&gt;I'd recommend making a &lt;code&gt;Locally-managed tunnel&lt;/code&gt; for more control, but if you prefer to make a &lt;code&gt;Remotely-managed tunnel&lt;/code&gt; then this is currently how:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;cloudflare dashboard&lt;/code&gt; Â» &lt;code&gt;zero trust&lt;/code&gt; Â» &lt;code&gt;networks&lt;/code&gt; Â» &lt;code&gt;tunnels&lt;/code&gt; Â» &lt;code&gt;create a tunnel&lt;/code&gt; Â» &lt;code&gt;cloudflared&lt;/code&gt; Â» choose a cool &lt;code&gt;subdomain&lt;/code&gt; and leave the &lt;code&gt;path&lt;/code&gt; blank, and use &lt;code&gt;service type&lt;/code&gt; = &lt;code&gt;http&lt;/code&gt; and &lt;code&gt;URL&lt;/code&gt; = &lt;code&gt;127.0.0.1:3923&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;and if you want to just run the tunnel without installing it, skip the &lt;code&gt;cloudflared service install BASE64&lt;/code&gt; step and instead do &lt;code&gt;cloudflared --no-autoupdate tunnel run --token BASE64&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;NOTE: since people will be connecting through cloudflare, as mentioned in &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#real-ip"&gt;real-ip&lt;/a&gt; you should run copyparty with &lt;code&gt;--xff-hdr cf-connecting-ip&lt;/code&gt; to detect client IPs correctly&lt;/p&gt; 
&lt;p&gt;config file example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;[global]
  xff-hdr: cf-connecting-ip
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;prometheus&lt;/h2&gt; 
&lt;p&gt;metrics/stats can be enabled at URL &lt;code&gt;/.cpr/metrics&lt;/code&gt; for grafana / prometheus / etc (openmetrics 1.0.0)&lt;/p&gt; 
&lt;p&gt;must be enabled with &lt;code&gt;--stats&lt;/code&gt; since it reduces startup time a tiny bit, and you probably want &lt;code&gt;-e2dsa&lt;/code&gt; too&lt;/p&gt; 
&lt;p&gt;the endpoint is only accessible by &lt;code&gt;admin&lt;/code&gt; accounts, meaning the &lt;code&gt;a&lt;/code&gt; in &lt;code&gt;rwmda&lt;/code&gt; in the following example commandline: &lt;code&gt;python3 -m copyparty -a ed:wark -v /mnt/nas::rwmda,ed --stats -e2dsa&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;follow a guide for setting up &lt;code&gt;node_exporter&lt;/code&gt; except have it read from copyparty instead; example &lt;code&gt;/etc/prometheus/prometheus.yml&lt;/code&gt; below&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;scrape_configs:
  - job_name: copyparty
    metrics_path: /.cpr/metrics
    basic_auth:
      password: wark
    static_configs:
      - targets: ['192.168.123.1:3923']
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;currently the following metrics are available,&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;cpp_uptime_seconds&lt;/code&gt; time since last copyparty restart&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;cpp_boot_unixtime_seconds&lt;/code&gt; same but as an absolute timestamp&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;cpp_active_dl&lt;/code&gt; number of active downloads&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;cpp_http_conns&lt;/code&gt; number of open http(s) connections&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;cpp_http_reqs&lt;/code&gt; number of http(s) requests handled&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;cpp_sus_reqs&lt;/code&gt; number of 403/422/malicious requests&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;cpp_active_bans&lt;/code&gt; number of currently banned IPs&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;cpp_total_bans&lt;/code&gt; number of IPs banned since last restart&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;these are available unless &lt;code&gt;--nos-vst&lt;/code&gt; is specified:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;cpp_db_idle_seconds&lt;/code&gt; time since last database activity (upload/rename/delete)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;cpp_db_act_seconds&lt;/code&gt; same but as an absolute timestamp&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;cpp_idle_vols&lt;/code&gt; number of volumes which are idle / ready&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;cpp_busy_vols&lt;/code&gt; number of volumes which are busy / indexing&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;cpp_offline_vols&lt;/code&gt; number of volumes which are offline / unavailable&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;cpp_hashing_files&lt;/code&gt; number of files queued for hashing / indexing&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;cpp_tagq_files&lt;/code&gt; number of files queued for metadata scanning&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;cpp_mtpq_files&lt;/code&gt; number of files queued for plugin-based analysis&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;and these are available per-volume only:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;cpp_disk_size_bytes&lt;/code&gt; total HDD size&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;cpp_disk_free_bytes&lt;/code&gt; free HDD space&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;and these are per-volume and &lt;code&gt;total&lt;/code&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;cpp_vol_bytes&lt;/code&gt; size of all files in volume&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;cpp_vol_files&lt;/code&gt; number of files&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;cpp_dupe_bytes&lt;/code&gt; disk space presumably saved by deduplication&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;cpp_dupe_files&lt;/code&gt; number of dupe files&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;cpp_unf_bytes&lt;/code&gt; currently unfinished / incoming uploads&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;some of the metrics have additional requirements to function correctly,&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;cpp_vol_*&lt;/code&gt; requires either the &lt;code&gt;e2ds&lt;/code&gt; volflag or &lt;code&gt;-e2dsa&lt;/code&gt; global-option&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;the following options are available to disable some of the metrics:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;--nos-hdd&lt;/code&gt; disables &lt;code&gt;cpp_disk_*&lt;/code&gt; which can prevent spinning up HDDs&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--nos-vol&lt;/code&gt; disables &lt;code&gt;cpp_vol_*&lt;/code&gt; which reduces server startup time&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--nos-vst&lt;/code&gt; disables volume state, reducing the worst-case prometheus query time by 0.5 sec&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--nos-dup&lt;/code&gt; disables &lt;code&gt;cpp_dupe_*&lt;/code&gt; which reduces the server load caused by prometheus queries&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--nos-unf&lt;/code&gt; disables &lt;code&gt;cpp_unf_*&lt;/code&gt; for no particular purpose&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;note: the following metrics are counted incorrectly if multiprocessing is enabled with &lt;code&gt;-j&lt;/code&gt;: &lt;code&gt;cpp_http_conns&lt;/code&gt;, &lt;code&gt;cpp_http_reqs&lt;/code&gt;, &lt;code&gt;cpp_sus_reqs&lt;/code&gt;, &lt;code&gt;cpp_active_bans&lt;/code&gt;, &lt;code&gt;cpp_total_bans&lt;/code&gt;&lt;/p&gt; 
&lt;h2&gt;other extremely specific features&lt;/h2&gt; 
&lt;p&gt;you'll never find a use for these:&lt;/p&gt; 
&lt;h3&gt;custom mimetypes&lt;/h3&gt; 
&lt;p&gt;change the association of a file extension&lt;/p&gt; 
&lt;p&gt;using commandline args, you can do something like &lt;code&gt;--mime gif=image/jif&lt;/code&gt; and &lt;code&gt;--mime ts=text/x.typescript&lt;/code&gt; (can be specified multiple times)&lt;/p&gt; 
&lt;p&gt;in a config file, this is the same as:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;[global]
  mime: gif=image/jif
  mime: ts=text/x.typescript
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;run copyparty with &lt;code&gt;--mimes&lt;/code&gt; to list all the default mappings&lt;/p&gt; 
&lt;h3&gt;GDPR compliance&lt;/h3&gt; 
&lt;p&gt;imagine using copyparty professionally... &lt;strong&gt;TINLA/IANAL; EU laws are hella confusing&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;remember to disable logging, or configure logrotation to an acceptable timeframe with &lt;code&gt;-lo cpp-%Y-%m%d.txt.xz&lt;/code&gt; or similar&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;if running with the database enabled (recommended), then have it forget uploader-IPs after some time using &lt;code&gt;--forget-ip 43200&lt;/code&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;don't set it too low; &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#unpost"&gt;unposting&lt;/a&gt; a file is no longer possible after this takes effect&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;if you actually &lt;em&gt;are&lt;/em&gt; a lawyer then I'm open for feedback, would be fun&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;feature chickenbits&lt;/h3&gt; 
&lt;p&gt;buggy feature? rip it out by setting any of the following environment variables to disable its associated bell or whistle,&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;env-var&lt;/th&gt; 
   &lt;th&gt;what it does&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;PRTY_NO_DB_LOCK&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;do not lock session/shares-databases for exclusive access&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;PRTY_NO_IFADDR&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;disable ip/nic discovery by poking into your OS with ctypes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;PRTY_NO_IMPRESO&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;do not try to load js/css files using &lt;code&gt;importlib.resources&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;PRTY_NO_IPV6&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;disable some ipv6 support (should not be necessary since windows 2000)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;PRTY_NO_LZMA&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;disable streaming xz compression of incoming uploads&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;PRTY_NO_MP&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;disable all use of the python &lt;code&gt;multiprocessing&lt;/code&gt; module (actual multithreading, cpu-count for parsers/thumbnailers)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;PRTY_NO_SQLITE&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;disable all database-related functionality (file indexing, metadata indexing, most file deduplication logic)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;PRTY_NO_TLS&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;disable native HTTPS support; if you still want to accept HTTPS connections then TLS must now be terminated by a reverse-proxy&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;PRTY_NO_TPOKE&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;disable systemd-tmpfilesd avoider&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;example: &lt;code&gt;PRTY_NO_IFADDR=1 python3 copyparty-sfx.py&lt;/code&gt;&lt;/p&gt; 
&lt;h3&gt;feature beefybits&lt;/h3&gt; 
&lt;p&gt;force-enable features with known issues on your OS/env by setting any of the following environment variables, also affectionately known as &lt;code&gt;fuckitbits&lt;/code&gt; or &lt;code&gt;hail-mary-bits&lt;/code&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;env-var&lt;/th&gt; 
   &lt;th&gt;what it does&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;PRTY_FORCE_MP&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;force-enable multiprocessing (real multithreading) on MacOS and other broken platforms&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;PRTY_FORCE_MAGIC&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;use &lt;a href="https://pypi.org/project/python-magic/"&gt;magic&lt;/a&gt; on Windows (you will segfault)&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h1&gt;packages&lt;/h1&gt; 
&lt;p&gt;the party might be closer than you think&lt;/p&gt; 
&lt;p&gt;if your distro/OS is not mentioned below, there might be some hints in the &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#on-servers"&gt;Â«on serversÂ»&lt;/a&gt; section&lt;/p&gt; 
&lt;h2&gt;arch package&lt;/h2&gt; 
&lt;p&gt;&lt;code&gt;pacman -S copyparty&lt;/code&gt; (in &lt;a href="https://archlinux.org/packages/extra/any/copyparty/"&gt;arch linux extra&lt;/a&gt;)&lt;/p&gt; 
&lt;p&gt;it comes with a &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/contrib/systemd/copyparty@.service"&gt;systemd service&lt;/a&gt; as well as a &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/contrib/systemd/copyparty-user.service"&gt;user service&lt;/a&gt;, and expects to find a &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/contrib/systemd/copyparty.example.conf"&gt;config file&lt;/a&gt; in &lt;code&gt;/etc/copyparty/copyparty.conf&lt;/code&gt; or &lt;code&gt;~/.config/copyparty/copyparty.conf&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;after installing, start either the system service or the user service and navigate to &lt;a href="http://127.0.0.1:3923"&gt;http://127.0.0.1:3923&lt;/a&gt; for further instructions (unless you already edited the config files, in which case you are good to go, probably)&lt;/p&gt; 
&lt;h2&gt;fedora package&lt;/h2&gt; 
&lt;p&gt;does not exist yet; there are rumours that it is being packaged! keep an eye on this space...&lt;/p&gt; 
&lt;h2&gt;homebrew formulae&lt;/h2&gt; 
&lt;p&gt;&lt;code&gt;brew install copyparty ffmpeg&lt;/code&gt; -- &lt;a href="https://formulae.brew.sh/formula/copyparty"&gt;https://formulae.brew.sh/formula/copyparty&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;should work on all macs (both intel and apple silicon) and all relevant macos versions&lt;/p&gt; 
&lt;p&gt;the homebrew package is maintained by the homebrew team (thanks!)&lt;/p&gt; 
&lt;h2&gt;nix package&lt;/h2&gt; 
&lt;p&gt;&lt;code&gt;nix profile install github:9001/copyparty&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;requires a &lt;a href="https://nixos.wiki/wiki/Flakes"&gt;flake-enabled&lt;/a&gt; installation of nix&lt;/p&gt; 
&lt;p&gt;some recommended dependencies are enabled by default; &lt;a href="https://github.com/9001/copyparty/raw/hovudstraum/contrib/package/nix/copyparty/default.nix#L3-L22"&gt;override the package&lt;/a&gt; if you want to add/remove some features/deps&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;ffmpeg-full&lt;/code&gt; was chosen over &lt;code&gt;ffmpeg-headless&lt;/code&gt; mainly because we need &lt;code&gt;withWebp&lt;/code&gt; (and &lt;code&gt;withOpenmpt&lt;/code&gt; is also nice) and being able to use a cached build felt more important than optimizing for size at the time -- PRs welcome if you disagree ğŸ‘&lt;/p&gt; 
&lt;h2&gt;nixos module&lt;/h2&gt; 
&lt;p&gt;for &lt;a href="https://nixos.wiki/wiki/Flakes"&gt;flake-enabled&lt;/a&gt; installations of NixOS:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-nix"&gt;{
  # add copyparty flake to your inputs
  inputs.copyparty.url = "github:9001/copyparty";

  # ensure that copyparty is an allowed argument to the outputs function
  outputs = { self, nixpkgs, copyparty }: {
    nixosConfigurations.yourHostName = nixpkgs.lib.nixosSystem {
      modules = [
        # load the copyparty NixOS module
        copyparty.nixosModules.default
        ({ pkgs, ... }: {
          # add the copyparty overlay to expose the package to the module
          nixpkgs.overlays = [ copyparty.overlays.default ];
          # (optional) install the package globally
          environment.systemPackages = [ pkgs.copyparty ];
          # configure the copyparty module
          services.copyparty.enable = true;
        })
      ];
    };
  };
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;if you don't use a flake in your configuration, you can use other dependency management tools like &lt;a href="https://github.com/andir/npins"&gt;npins&lt;/a&gt;, &lt;a href="https://github.com/nmattia/niv"&gt;niv&lt;/a&gt;, or even plain &lt;a href="https://nix.dev/manual/nix/stable/language/builtins#builtins-fetchTarball"&gt;&lt;code&gt;fetchTarball&lt;/code&gt;&lt;/a&gt;, like so:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-nix"&gt;{ pkgs, ... }:

let
  # npins example, adjust for your setup. copyparty should be a path to the downloaded repo
  # for niv, just replace the npins folder import with the sources.nix file
  copyparty = (import ./npins).copyparty;

  # or with fetchTarball:
  copyparty = fetchTarball "https://github.com/9001/copyparty/archive/hovudstraum.tar.gz";
in

{
  # load the copyparty NixOS module
  imports = [ "${copyparty}/contrib/nixos/modules/copyparty.nix" ];

  # add the copyparty overlay to expose the package to the module
  nixpkgs.overlays = [ (import "${copyparty}/contrib/package/nix/overlay.nix") ];
  # (optional) install the package globally
  environment.systemPackages = [ pkgs.copyparty ];
  # configure the copyparty module
  services.copyparty.enable = true;
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;copyparty on NixOS is configured via &lt;code&gt;services.copyparty&lt;/code&gt; options, for example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-nix"&gt;services.copyparty = {
  enable = true;
  # directly maps to values in the [global] section of the copyparty config.
  # see `copyparty --help` for available options
  settings = {
    i = "0.0.0.0";
    # use lists to set multiple values
    p = [ 3210 3211 ];
    # use booleans to set binary flags
    no-reload = true;
    # using 'false' will do nothing and omit the value when generating a config
    ignored-flag = false;
  };

  # create users
  accounts = {
    # specify the account name as the key
    ed = {
      # provide the path to a file containing the password, keeping it out of /nix/store
      # must be readable by the copyparty service user
      passwordFile = "/run/keys/copyparty/ed_password";
    };
    # or do both in one go
    k.passwordFile = "/run/keys/copyparty/k_password";
  };

  # create a volume
  volumes = {
    # create a volume at "/" (the webroot), which will
    "/" = {
      # share the contents of "/srv/copyparty"
      path = "/srv/copyparty";
      # see `copyparty --help-accounts` for available options
      access = {
        # everyone gets read-access, but
        r = "*";
        # users "ed" and "k" get read-write
        rw = [ "ed" "k" ];
      };
      # see `copyparty --help-flags` for available options
      flags = {
        # "fk" enables filekeys (necessary for upget permission) (4 chars long)
        fk = 4;
        # scan for new files every 60sec
        scan = 60;
        # volflag "e2d" enables the uploads database
        e2d = true;
        # "d2t" disables multimedia parsers (in case the uploads are malicious)
        d2t = true;
        # skips hashing file contents if path matches *.iso
        nohash = "\.iso$";
      };
    };
  };
  # you may increase the open file limit for the process
  openFilesLimit = 8192;
};
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;the passwordFile at /run/keys/copyparty/ could for example be generated by &lt;a href="https://github.com/ryantm/agenix"&gt;agenix&lt;/a&gt;, or you could just dump it in the nix store instead if that's acceptable&lt;/p&gt; 
&lt;h1&gt;browser support&lt;/h1&gt; 
&lt;p&gt;TLDR: yes&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://user-images.githubusercontent.com/241032/118192791-fb31fe00-b446-11eb-9647-898ea8efc1f7.png" alt="copyparty-ie4-fs8" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;ie&lt;/code&gt; = internet-explorer, &lt;code&gt;ff&lt;/code&gt; = firefox, &lt;code&gt;c&lt;/code&gt; = chrome, &lt;code&gt;iOS&lt;/code&gt; = iPhone/iPad, &lt;code&gt;Andr&lt;/code&gt; = Android&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;feature&lt;/th&gt; 
   &lt;th&gt;ie6&lt;/th&gt; 
   &lt;th&gt;ie9&lt;/th&gt; 
   &lt;th&gt;ie10&lt;/th&gt; 
   &lt;th&gt;ie11&lt;/th&gt; 
   &lt;th&gt;ff 52&lt;/th&gt; 
   &lt;th&gt;c 49&lt;/th&gt; 
   &lt;th&gt;iOS&lt;/th&gt; 
   &lt;th&gt;Andr&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;browse files&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;thumbnail view&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;basic uploader&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;up2k&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;*1&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;*1&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;make directory&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;send message&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;set sort order&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;zip selection&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;file search&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;file rename&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;file cut/paste&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;unpost uploads&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;navpane&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;image viewer&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;video player&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;markdown editor&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;*2&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;*2&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;markdown viewer&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;*2&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;*2&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;*2&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;play mp3/m4a&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;play ogg/opus&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;*3&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;= feature =&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;ie6&lt;/td&gt; 
   &lt;td&gt;ie9&lt;/td&gt; 
   &lt;td&gt;ie10&lt;/td&gt; 
   &lt;td&gt;ie11&lt;/td&gt; 
   &lt;td&gt;ff 52&lt;/td&gt; 
   &lt;td&gt;c 49&lt;/td&gt; 
   &lt;td&gt;iOS&lt;/td&gt; 
   &lt;td&gt;Andr&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;ul&gt; 
 &lt;li&gt;internet explorer 6 through 8 behave the same&lt;/li&gt; 
 &lt;li&gt;firefox 52 and chrome 49 are the final winxp versions&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;*1&lt;/code&gt; yes, but extremely slow (ie10: &lt;code&gt;1 MiB/s&lt;/code&gt;, ie11: &lt;code&gt;270 KiB/s&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;*2&lt;/code&gt; only able to do plaintext documents (no markdown rendering)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;*3&lt;/code&gt; iOS 11 and newer, opus only, and requires FFmpeg on the server&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;quick summary of more eccentric web-browsers trying to view a directory index:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;browser&lt;/th&gt; 
   &lt;th&gt;will it blend&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;links&lt;/strong&gt; (2.21/macports)&lt;/td&gt; 
   &lt;td&gt;can browse, login, upload/mkdir/msg&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;lynx&lt;/strong&gt; (2.8.9/macports)&lt;/td&gt; 
   &lt;td&gt;can browse, login, upload/mkdir/msg&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;w3m&lt;/strong&gt; (0.5.3/macports)&lt;/td&gt; 
   &lt;td&gt;can browse, login, upload at 100kB/s, mkdir/msg&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;netsurf&lt;/strong&gt; (3.10/arch)&lt;/td&gt; 
   &lt;td&gt;is basically ie6 with much better css (javascript has almost no effect)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;opera&lt;/strong&gt; (11.60/winxp)&lt;/td&gt; 
   &lt;td&gt;OK: thumbnails, image-viewer, zip-selection, rename/cut/paste. NG: up2k, navpane, markdown, audio&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;ie4&lt;/strong&gt; and &lt;strong&gt;netscape&lt;/strong&gt; 4.0&lt;/td&gt; 
   &lt;td&gt;can browse, upload with &lt;code&gt;?b=u&lt;/code&gt;, auth with &lt;code&gt;&amp;amp;pw=wark&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;ncsa mosaic&lt;/strong&gt; 2.7&lt;/td&gt; 
   &lt;td&gt;does not get a pass, &lt;a href="https://user-images.githubusercontent.com/241032/174189227-ae816026-cf6f-4be5-a26e-1b3b072c1b2f.png"&gt;pic1&lt;/a&gt; - &lt;a href="https://user-images.githubusercontent.com/241032/174189225-5651c059-5152-46e9-ac26-7e98e497901b.png"&gt;pic2&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;SerenityOS&lt;/strong&gt; (7e98457)&lt;/td&gt; 
   &lt;td&gt;hits a page fault, works with &lt;code&gt;?b=u&lt;/code&gt;, file upload not-impl&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;sony psp&lt;/strong&gt; 5.50&lt;/td&gt; 
   &lt;td&gt;can browse, upload/mkdir/msg (thx dwarf) &lt;a href="https://github.com/user-attachments/assets/9d21f020-1110-4652-abeb-6fc09c533d4f"&gt;screenshot&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;nintendo 3ds&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;can browse, upload, view thumbnails (thx bnjmn)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Nintendo Wii (Opera 9.0 "Internet Channel")&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;can browse, can't upload or download (no local storage), can view images - works best with &lt;code&gt;?b=u&lt;/code&gt;, default view broken&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p align="center"&gt;&lt;img src="https://github.com/user-attachments/assets/88deab3d-6cad-4017-8841-2f041472b853" /&gt;&lt;/p&gt; 
&lt;h1&gt;client examples&lt;/h1&gt; 
&lt;p&gt;interact with copyparty using non-browser clients&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;javascript: dump some state into a file (two separate examples)&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;await fetch('//127.0.0.1:3923/', {method:"PUT", body: JSON.stringify(foo)});&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;var xhr = new XMLHttpRequest(); xhr.open('POST', '//127.0.0.1:3923/msgs?raw'); xhr.send('foo');&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;curl/wget: upload some files (post=file, chunk=stdin)&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;post(){ curl -F f=@"$1" http://127.0.0.1:3923/?pw=wark;}&lt;/code&gt;&lt;br /&gt; &lt;code&gt;post movie.mkv&lt;/code&gt; (gives HTML in return)&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;post(){ curl -F f=@"$1" 'http://127.0.0.1:3923/?want=url&amp;amp;pw=wark';}&lt;/code&gt;&lt;br /&gt; &lt;code&gt;post movie.mkv&lt;/code&gt; (gives hotlink in return)&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;post(){ curl -H pw:wark -H rand:8 -T "$1" http://127.0.0.1:3923/;}&lt;/code&gt;&lt;br /&gt; &lt;code&gt;post movie.mkv&lt;/code&gt; (randomized filename)&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;post(){ wget --header='pw: wark' --post-file="$1" -O- http://127.0.0.1:3923/?raw;}&lt;/code&gt;&lt;br /&gt; &lt;code&gt;post movie.mkv&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;chunk(){ curl -H pw:wark -T- http://127.0.0.1:3923/;}&lt;/code&gt;&lt;br /&gt; &lt;code&gt;chunk &amp;lt;movie.mkv&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;bash: when curl and wget is not available or too boring&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;(printf 'PUT /junk?pw=wark HTTP/1.1\r\n\r\n'; cat movie.mkv) | nc 127.0.0.1 3923&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;(printf 'PUT / HTTP/1.1\r\n\r\n'; cat movie.mkv) &amp;gt;/dev/tcp/127.0.0.1/3923&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;python: &lt;a href="https://github.com/9001/copyparty/raw/hovudstraum/bin/u2c.py"&gt;u2c.py&lt;/a&gt; is a command-line up2k client &lt;a href="https://ocv.me/stuff/u2cli.webm"&gt;(webm)&lt;/a&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;file uploads, file-search, &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#folder-sync"&gt;folder sync&lt;/a&gt;, autoresume of aborted/broken uploads&lt;/li&gt; 
   &lt;li&gt;can be downloaded from copyparty: controlpanel -&amp;gt; connect -&amp;gt; &lt;a href="http://127.0.0.1:3923/.cpr/a/u2c.py"&gt;u2c.py&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/bin/README.md#u2cpy"&gt;./bin/README.md#u2cpy&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;FUSE: mount a copyparty server as a local filesystem&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;cross-platform python client available in &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/bin/"&gt;./bin/&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;able to mount nginx and iis directory listings too, not just copyparty&lt;/li&gt; 
   &lt;li&gt;can be downloaded from copyparty: controlpanel -&amp;gt; connect -&amp;gt; &lt;a href="http://127.0.0.1:3923/.cpr/a/partyfuse.py"&gt;partyfuse.py&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://rclone.org/"&gt;rclone&lt;/a&gt; as client can give ~5x performance, see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/docs/rclone.md"&gt;./docs/rclone.md&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;sharex (screenshot utility): see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/contrib/#sharexsxcu"&gt;./contrib/sharex.sxcu&lt;/a&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;and for screenshots on macos, see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/contrib/#ishareiscu"&gt;./contrib/ishare.iscu&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;and for screenshots on linux, see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/contrib/flameshot.sh"&gt;./contrib/flameshot.sh&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://f-droid.org/en/packages/com.nyx.custom_uploader/"&gt;Custom Uploader&lt;/a&gt; (an Android app) as an alternative to copyparty's own &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#android-app"&gt;PartyUP!&lt;/a&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;works if you set UploadURL to &lt;code&gt;https://your.com/foo/?want=url&amp;amp;pw=hunter2&lt;/code&gt; and FormDataName &lt;code&gt;f&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;contextlet (web browser integration); see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/contrib/#send-to-cppcontextletjson"&gt;contrib contextlet&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://iglooirc.com/"&gt;igloo irc&lt;/a&gt;: Method: &lt;code&gt;post&lt;/code&gt; Host: &lt;code&gt;https://you.com/up/?want=url&amp;amp;pw=hunter2&lt;/code&gt; Multipart: &lt;code&gt;yes&lt;/code&gt; File parameter: &lt;code&gt;f&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;copyparty returns a truncated sha512sum of your PUT/POST as base64; you can generate the same checksum locally to verify uploads:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;b512(){ printf "$((sha512sum||shasum -a512)|sed -E 's/ .*//;s/(..)/\\x\1/g')"|base64|tr '+/' '-_'|head -c44;}
b512 &amp;lt;movie.mkv
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;you can provide passwords using header &lt;code&gt;PW: hunter2&lt;/code&gt;, cookie &lt;code&gt;cppwd=hunter2&lt;/code&gt;, url-param &lt;code&gt;?pw=hunter2&lt;/code&gt;, or with basic-authentication (either as the username or password)&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;for basic-authentication, all of the following are accepted: &lt;code&gt;password&lt;/code&gt; / &lt;code&gt;whatever:password&lt;/code&gt; / &lt;code&gt;password:whatever&lt;/code&gt; (the username is ignored)&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;unless you've enabled &lt;code&gt;--usernames&lt;/code&gt;, then it's &lt;code&gt;PW: usr:pwd&lt;/code&gt;, cookie &lt;code&gt;cppwd=usr:pwd&lt;/code&gt;, url-param &lt;code&gt;?pw=usr:pwd&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;NOTE: curl will not send the original filename if you use &lt;code&gt;-T&lt;/code&gt; combined with url-params! Also, make sure to always leave a trailing slash in URLs unless you want to override the filename&lt;/p&gt; 
&lt;h2&gt;folder sync&lt;/h2&gt; 
&lt;p&gt;sync folders to/from copyparty&lt;/p&gt; 
&lt;p&gt;NOTE: full bidirectional sync, like what &lt;a href="https://docs.nextcloud.com/server/latest/user_manual/sv/files/desktop_mobile_sync.html"&gt;nextcloud&lt;/a&gt; and &lt;a href="https://syncthing.net/"&gt;syncthing&lt;/a&gt; does, will never be supported! Only single-direction sync (server-to-client, or client-to-server) is possible with copyparty&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;if you want bidirectional sync, then copyparty and syncthing &lt;em&gt;should&lt;/em&gt; be entirely safe to combine; they should be able to collaborate on the same folders without causing any trouble for eachother. Many people do this, and there have been no issues so far. But, if you &lt;em&gt;do&lt;/em&gt; encounter any problems, please &lt;a href="https://github.com/9001/copyparty/issues/new/choose"&gt;file a copyparty bug&lt;/a&gt; and I'll try to help -- just keep in mind I've never used syncthing before :-)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;the commandline uploader &lt;a href="https://github.com/9001/copyparty/tree/hovudstraum/bin#u2cpy"&gt;u2c.py&lt;/a&gt; with &lt;code&gt;--dr&lt;/code&gt; is the best way to sync a folder to copyparty; verifies checksums and does files in parallel, and deletes unexpected files on the server after upload has finished which makes file-renames really cheap (it'll rename serverside and skip uploading)&lt;/p&gt; 
&lt;p&gt;if you want to sync with &lt;code&gt;u2c.py&lt;/code&gt; then:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;the &lt;code&gt;e2dsa&lt;/code&gt; option (either globally or volflag) must be enabled on the server for the volumes you're syncing into&lt;/li&gt; 
 &lt;li&gt;...but DON'T enable global-options &lt;code&gt;no-hash&lt;/code&gt; or &lt;code&gt;no-idx&lt;/code&gt; (or volflags &lt;code&gt;nohash&lt;/code&gt; / &lt;code&gt;noidx&lt;/code&gt;), or at least make sure they are configured so they do not affect anything you are syncing into&lt;/li&gt; 
 &lt;li&gt;...and u2c needs the delete-permission, so either &lt;code&gt;rwd&lt;/code&gt; at minimum, or just &lt;code&gt;A&lt;/code&gt; which is the same as &lt;code&gt;rwmd.a&lt;/code&gt; 
  &lt;ul&gt; 
   &lt;li&gt;quick reminder that &lt;code&gt;a&lt;/code&gt; and &lt;code&gt;A&lt;/code&gt; are different permissions, and &lt;code&gt;.&lt;/code&gt; is very useful for sync&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;alternatively there is &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/docs/rclone.md"&gt;rclone&lt;/a&gt; which allows for bidirectional sync and is &lt;em&gt;way&lt;/em&gt; more flexible (stream files straight from sftp/s3/gcs to copyparty, ...), although there is no integrity check and it won't work with files over 100 MiB if copyparty is behind cloudflare&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;starting from rclone v1.63, rclone is faster than u2c.py on low-latency connections 
  &lt;ul&gt; 
   &lt;li&gt;but this is only true for the initial upload; u2c will be faster for periodic syncing&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;mount as drive&lt;/h2&gt; 
&lt;p&gt;a remote copyparty server as a local filesystem; go to the control-panel and click &lt;code&gt;connect&lt;/code&gt; to see a list of commands to do that&lt;/p&gt; 
&lt;p&gt;alternatively, some alternatives roughly sorted by speed (unreproducible benchmark), best first:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/docs/rclone.md"&gt;rclone-webdav&lt;/a&gt; (25s), read/WRITE (rclone v1.63 or later)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/docs/rclone.md"&gt;rclone-http&lt;/a&gt; (26s), read-only&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/bin/#partyfusepy"&gt;partyfuse.py&lt;/a&gt; (26s), read-only&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/docs/rclone.md"&gt;rclone-ftp&lt;/a&gt; (47s), read/WRITE&lt;/li&gt; 
 &lt;li&gt;davfs2 (103s), read/WRITE&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#webdav-server"&gt;win10-webdav&lt;/a&gt; (138s), read/WRITE&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#smb-server"&gt;win10-smb2&lt;/a&gt; (387s), read/WRITE&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;most clients will fail to mount the root of a copyparty server unless there is a root volume (so you get the admin-panel instead of a browser when accessing it) -- in that case, mount a specific volume instead&lt;/p&gt; 
&lt;p&gt;if you have volumes that are accessible without a password, then some webdav clients (such as davfs2) require the global-option &lt;code&gt;--dav-auth&lt;/code&gt; to access any password-protected areas&lt;/p&gt; 
&lt;h1&gt;android app&lt;/h1&gt; 
&lt;p&gt;upload to copyparty with one tap&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://f-droid.org/packages/me.ocv.partyup/"&gt;&lt;img src="https://ocv.me/fdroid.png" alt="Get it on F-Droid" height="50" /&gt; '' &lt;img src="https://img.shields.io/f-droid/v/me.ocv.partyup.svg?sanitize=true" alt="f-droid version info" /&gt;&lt;/a&gt; '' &lt;a href="https://github.com/9001/party-up"&gt;&lt;img src="https://img.shields.io/github/release/9001/party-up.svg?logo=github" alt="github version info" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;the app is &lt;strong&gt;NOT&lt;/strong&gt; the full copyparty server! just a basic upload client, nothing fancy yet&lt;/p&gt; 
&lt;p&gt;if you want to run the copyparty server on your android device, see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#install-on-android"&gt;install on android&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;iOS shortcuts&lt;/h1&gt; 
&lt;p&gt;there is no iPhone app, but the following shortcuts are almost as good:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.icloud.com/shortcuts/41e98dd985cb4d3bb433222bc1e9e770"&gt;upload to copyparty&lt;/a&gt; (&lt;a href="https://github.com/9001/copyparty/raw/hovudstraum/contrib/ios/upload-to-copyparty.shortcut"&gt;offline&lt;/a&gt;) (&lt;a href="https://user-images.githubusercontent.com/241032/226118053-78623554-b0ed-482e-98e4-6d57ada58ea4.png"&gt;png&lt;/a&gt;) based on the &lt;a href="https://www.icloud.com/shortcuts/ab415d5b4de3467b9ce6f151b439a5d7"&gt;original&lt;/a&gt; by &lt;a href="https://github.com/Daedren"&gt;Daedren&lt;/a&gt; (thx!) 
  &lt;ul&gt; 
   &lt;li&gt;can strip exif, upload files, pics, vids, links, clipboard&lt;/li&gt; 
   &lt;li&gt;can download links and rehost the target file on copyparty (see first comment inside the shortcut)&lt;/li&gt; 
   &lt;li&gt;pics become lowres if you share from gallery to shortcut, so better to launch the shortcut and pick stuff from there&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;if you want to run the copyparty server on your iPhone or iPad, see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#install-on-iOS"&gt;install on iOS&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;performance&lt;/h1&gt; 
&lt;p&gt;defaults are usually fine - expect &lt;code&gt;8 GiB/s&lt;/code&gt; download, &lt;code&gt;1 GiB/s&lt;/code&gt; upload&lt;/p&gt; 
&lt;p&gt;below are some tweaks roughly ordered by usefulness:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;disabling HTTP/2 and HTTP/3 can make uploads 5x faster, depending on server/client software&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;-q&lt;/code&gt; disables logging and can help a bunch, even when combined with &lt;code&gt;-lo&lt;/code&gt; to redirect logs to file&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;--hist&lt;/code&gt; pointing to a fast location (ssd) will make directory listings and searches faster when &lt;code&gt;-e2d&lt;/code&gt; or &lt;code&gt;-e2t&lt;/code&gt; is set&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;and also makes thumbnails load faster, regardless of e2d/e2t&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;--dedup&lt;/code&gt; enables deduplication and thus avoids writing to the HDD if someone uploads a dupe&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;--safe-dedup 1&lt;/code&gt; makes deduplication much faster during upload by skipping verification of file contents; safe if there is no other software editing/moving the files in the volumes&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;--no-dirsz&lt;/code&gt; shows the size of folder inodes instead of the total size of the contents, giving about 30% faster folder listings&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;--no-hash .&lt;/code&gt; when indexing a network-disk if you don't care about the actual filehashes and only want the names/tags searchable&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;if your volumes are on a network-disk such as NFS / SMB / s3, specifying larger values for &lt;code&gt;--iobuf&lt;/code&gt; and/or &lt;code&gt;--s-rd-sz&lt;/code&gt; and/or &lt;code&gt;--s-wr-sz&lt;/code&gt; may help; try setting all of them to &lt;code&gt;524288&lt;/code&gt; or &lt;code&gt;1048576&lt;/code&gt; or &lt;code&gt;4194304&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;--no-htp --hash-mt=0 --mtag-mt=1 --th-mt=1&lt;/code&gt; minimizes the number of threads; can help in some eccentric environments (like the vscode debugger)&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;when running on AlpineLinux or other musl-based distro, try mimalloc for higher performance (and twice as much RAM usage); &lt;code&gt;apk add mimalloc2&lt;/code&gt; and run copyparty with env-var &lt;code&gt;LD_PRELOAD=/usr/lib/libmimalloc-secure.so.2&lt;/code&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;note that mimalloc requires special care when combined with prisonparty and/or bubbleparty/bubblewrap; you must give it access to &lt;code&gt;/proc&lt;/code&gt; and &lt;code&gt;/sys&lt;/code&gt; otherwise you'll encounter issues with FFmpeg (audio transcoding, thumbnails)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;-j0&lt;/code&gt; enables multiprocessing (actual multithreading), can reduce latency to &lt;code&gt;20+80/numCores&lt;/code&gt; percent and generally improve performance in cpu-intensive workloads, for example:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;lots of connections (many users or heavy clients)&lt;/li&gt; 
   &lt;li&gt;simultaneous downloads and uploads saturating a 20gbps connection&lt;/li&gt; 
   &lt;li&gt;if &lt;code&gt;-e2d&lt;/code&gt; is enabled, &lt;code&gt;-j2&lt;/code&gt; gives 4x performance for directory listings; &lt;code&gt;-j4&lt;/code&gt; gives 16x&lt;/li&gt; 
  &lt;/ul&gt; &lt;p&gt;...however it also increases the server/filesystem/HDD load during uploads, and adds an overhead to internal communication, so it is usually a better idea to don't&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;using &lt;a href="https://www.pypy.org/"&gt;pypy&lt;/a&gt; instead of &lt;a href="https://www.python.org/"&gt;cpython&lt;/a&gt; &lt;em&gt;can&lt;/em&gt; be 70% faster for some workloads, but slower for many others&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;and pypy can sometimes crash on startup with &lt;code&gt;-j0&lt;/code&gt; (TODO make issue)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;client-side&lt;/h2&gt; 
&lt;p&gt;when uploading files,&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;when uploading from very fast storage (NVMe SSD) with chrome/firefox, enable &lt;code&gt;[wasm]&lt;/code&gt; in the &lt;code&gt;[âš™ï¸] settings&lt;/code&gt; tab to more effectively use all CPU-cores for hashing&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;don't do this on Safari (runs faster without)&lt;/li&gt; 
   &lt;li&gt;don't do this on older browsers; likely to provoke browser-bugs (browser eats all RAM and crashes)&lt;/li&gt; 
   &lt;li&gt;can be made default-enabled serverside with &lt;code&gt;--nosubtle 137&lt;/code&gt; (chrome v137+) or &lt;code&gt;--nosubtle 2&lt;/code&gt; (chrome+firefox)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;chrome is recommended (unfortunately), at least compared to firefox:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;up to 90% faster when hashing, especially on SSDs&lt;/li&gt; 
   &lt;li&gt;up to 40% faster when uploading over extremely fast internets&lt;/li&gt; 
   &lt;li&gt;but &lt;a href="https://github.com/9001/copyparty/raw/hovudstraum/bin/u2c.py"&gt;u2c.py&lt;/a&gt; can be 40% faster than chrome again&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;if you're cpu-bottlenecked, or the browser is maxing a cpu core:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;up to 30% faster uploads if you hide the upload status list by switching away from the &lt;code&gt;[ğŸš€]&lt;/code&gt; up2k ui-tab (or closing it) 
    &lt;ul&gt; 
     &lt;li&gt;optionally you can switch to the lightweight potato ui by clicking the &lt;code&gt;[ğŸ¥”]&lt;/code&gt;&lt;/li&gt; 
     &lt;li&gt;switching to another browser-tab also works, the favicon will update every 10 seconds in that case&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;unlikely to be a problem, but can happen when uploading many small files, or your internet is too fast, or PC too slow&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;security&lt;/h1&gt; 
&lt;p&gt;there is a &lt;a href="https://discord.gg/25J8CdTT6G"&gt;discord server&lt;/a&gt; with an &lt;code&gt;@everyone&lt;/code&gt; for all important updates (at the lack of better ideas)&lt;/p&gt; 
&lt;p&gt;some notes on hardening&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;set &lt;code&gt;--rproxy 0&lt;/code&gt; &lt;em&gt;if and only if&lt;/em&gt; your copyparty is directly facing the internet (not through a reverse-proxy) 
  &lt;ul&gt; 
   &lt;li&gt;cors doesn't work right otherwise&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;if you allow anonymous uploads or otherwise don't trust the contents of a volume, you can prevent XSS with volflag &lt;code&gt;nohtml&lt;/code&gt; 
  &lt;ul&gt; 
   &lt;li&gt;this returns html documents as plaintext, and also disables markdown rendering&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;when running behind a reverse-proxy, listen on a unix-socket for tighter access control (and more performance); see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#reverse-proxy"&gt;reverse-proxy&lt;/a&gt; or &lt;code&gt;--help-bind&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;safety profiles:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;option &lt;code&gt;-s&lt;/code&gt; is a shortcut to set the following options:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;--no-thumb&lt;/code&gt; disables thumbnails and audio transcoding to stop copyparty from running &lt;code&gt;FFmpeg&lt;/code&gt;/&lt;code&gt;Pillow&lt;/code&gt;/&lt;code&gt;VIPS&lt;/code&gt; on uploaded files, which is a &lt;a href="https://www.cvedetails.com/vulnerability-list.php?vendor_id=3611"&gt;good idea&lt;/a&gt; if anonymous upload is enabled&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;--no-mtag-ff&lt;/code&gt; uses &lt;code&gt;mutagen&lt;/code&gt; to grab music tags instead of &lt;code&gt;FFmpeg&lt;/code&gt;, which is safer and faster but less accurate&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;--dotpart&lt;/code&gt; hides uploads from directory listings while they're still incoming&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;--no-robots&lt;/code&gt; and &lt;code&gt;--force-js&lt;/code&gt; makes life harder for crawlers, see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#hiding-from-google"&gt;hiding from google&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;option &lt;code&gt;-ss&lt;/code&gt; is a shortcut for the above plus:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;--unpost 0&lt;/code&gt;, &lt;code&gt;--no-del&lt;/code&gt;, &lt;code&gt;--no-mv&lt;/code&gt; disables all move/delete support&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;--hardlink&lt;/code&gt; creates hardlinks instead of symlinks when deduplicating uploads, which is less maintenance 
    &lt;ul&gt; 
     &lt;li&gt;however note if you edit one file it will also affect the other copies&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;--vague-403&lt;/code&gt; returns a "404 not found" instead of "401 unauthorized" which is a common enterprise meme&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;-nih&lt;/code&gt; removes the server hostname from directory listings&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;option &lt;code&gt;-sss&lt;/code&gt; is a shortcut for the above plus:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;--no-dav&lt;/code&gt; disables webdav support&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;--no-logues&lt;/code&gt; and &lt;code&gt;--no-readme&lt;/code&gt; disables support for readme's and prologues / epilogues in directory listings, which otherwise lets people upload arbitrary (but sandboxed) &lt;code&gt;&amp;lt;script&amp;gt;&lt;/code&gt; tags&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;-lo cpp-%Y-%m%d-%H%M%S.txt.xz&lt;/code&gt; enables logging to disk&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;-ls **,*,ln,p,r&lt;/code&gt; does a scan on startup for any dangerous symlinks&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;other misc notes:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;you can disable directory listings by giving permission &lt;code&gt;g&lt;/code&gt; instead of &lt;code&gt;r&lt;/code&gt;, only accepting direct URLs to files 
  &lt;ul&gt; 
   &lt;li&gt;you may want &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#filekeys"&gt;filekeys&lt;/a&gt; to prevent filename bruteforcing&lt;/li&gt; 
   &lt;li&gt;permission &lt;code&gt;h&lt;/code&gt; instead of &lt;code&gt;r&lt;/code&gt; makes copyparty behave like a traditional webserver with directory listing/index disabled, returning index.html instead 
    &lt;ul&gt; 
     &lt;li&gt;compatibility with filekeys: index.html itself can be retrieved without the correct filekey, but all other files are protected&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;gotchas&lt;/h2&gt; 
&lt;p&gt;behavior that might be unexpected&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;users without read-access to a folder can still see the &lt;code&gt;.prologue.html&lt;/code&gt; / &lt;code&gt;.epilogue.html&lt;/code&gt; / &lt;code&gt;PREADME.md&lt;/code&gt; / &lt;code&gt;README.md&lt;/code&gt; contents, for the purpose of showing a description on how to use the uploader for example&lt;/li&gt; 
 &lt;li&gt;users can submit &lt;code&gt;&amp;lt;script&amp;gt;&lt;/code&gt;s which autorun (in a sandbox) for other visitors in a few ways; 
  &lt;ul&gt; 
   &lt;li&gt;uploading a &lt;code&gt;README.md&lt;/code&gt; -- avoid with &lt;code&gt;--no-readme&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;renaming &lt;code&gt;some.html&lt;/code&gt; to &lt;code&gt;.epilogue.html&lt;/code&gt; -- avoid with either &lt;code&gt;--no-logues&lt;/code&gt; or &lt;code&gt;--no-dot-ren&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;the directory-listing embed is sandboxed (so any malicious scripts can't do any damage) but the markdown editor is not 100% safe, see below&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;markdown documents can contain html and &lt;code&gt;&amp;lt;script&amp;gt;&lt;/code&gt;s; attempts are made to prevent scripts from executing (unless &lt;code&gt;-emp&lt;/code&gt; is specified) but this is not 100% bulletproof, so setting the &lt;code&gt;nohtml&lt;/code&gt; volflag is still the safest choice 
  &lt;ul&gt; 
   &lt;li&gt;or eliminate the problem entirely by only giving write-access to trustworthy people :^)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;cors&lt;/h2&gt; 
&lt;p&gt;cross-site request config&lt;/p&gt; 
&lt;p&gt;by default, except for &lt;code&gt;GET&lt;/code&gt; and &lt;code&gt;HEAD&lt;/code&gt; operations, all requests must either:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;not contain an &lt;code&gt;Origin&lt;/code&gt; header at all&lt;/li&gt; 
 &lt;li&gt;or have an &lt;code&gt;Origin&lt;/code&gt; matching the server domain&lt;/li&gt; 
 &lt;li&gt;or the header &lt;code&gt;PW&lt;/code&gt; with your password as value&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;cors can be configured with &lt;code&gt;--acao&lt;/code&gt; and &lt;code&gt;--acam&lt;/code&gt;, or the protections entirely disabled with &lt;code&gt;--allow-csrf&lt;/code&gt;&lt;/p&gt; 
&lt;h2&gt;filekeys&lt;/h2&gt; 
&lt;p&gt;prevent filename bruteforcing&lt;/p&gt; 
&lt;p&gt;volflag &lt;code&gt;fk&lt;/code&gt; generates filekeys (per-file accesskeys) for all files; users which have full read-access (permission &lt;code&gt;r&lt;/code&gt;) will then see URLs with the correct filekey &lt;code&gt;?k=...&lt;/code&gt; appended to the end, and &lt;code&gt;g&lt;/code&gt; users must provide that URL including the correct key to avoid a 404&lt;/p&gt; 
&lt;p&gt;by default, filekeys are generated based on salt (&lt;code&gt;--fk-salt&lt;/code&gt;) + filesystem-path + file-size + inode (if not windows); add volflag &lt;code&gt;fka&lt;/code&gt; to generate slightly weaker filekeys which will not be invalidated if the file is edited (only salt + path)&lt;/p&gt; 
&lt;p&gt;permissions &lt;code&gt;wG&lt;/code&gt; (write + upget) lets users upload files and receive their own filekeys, still without being able to see other uploads&lt;/p&gt; 
&lt;h3&gt;dirkeys&lt;/h3&gt; 
&lt;p&gt;share specific folders in a volume without giving away full read-access to the rest -- the visitor only needs the &lt;code&gt;g&lt;/code&gt; (get) permission to view the link&lt;/p&gt; 
&lt;p&gt;volflag &lt;code&gt;dk&lt;/code&gt; generates dirkeys (per-directory accesskeys) for all folders, granting read-access to that folder; by default only that folder itself, no subfolders&lt;/p&gt; 
&lt;p&gt;volflag &lt;code&gt;dky&lt;/code&gt; disables the actual key-check, meaning anyone can see the contents of a folder where they have &lt;code&gt;g&lt;/code&gt; access, but not its subdirectories&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;dk&lt;/code&gt; + &lt;code&gt;dky&lt;/code&gt; gives the same behavior as if all users with &lt;code&gt;g&lt;/code&gt; access have full read-access, but subfolders are hidden files (as if their names start with a dot), so &lt;code&gt;dky&lt;/code&gt; is an alternative to renaming all the folders for that purpose, maybe just for some users&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;volflag &lt;code&gt;dks&lt;/code&gt; lets people enter subfolders as well, and also enables download-as-zip/tar&lt;/p&gt; 
&lt;p&gt;if you enable dirkeys, it is probably a good idea to enable filekeys too, otherwise it will be impossible to hotlink files from a folder which was accessed using a dirkey&lt;/p&gt; 
&lt;p&gt;dirkeys are generated based on another salt (&lt;code&gt;--dk-salt&lt;/code&gt;) + filesystem-path and have a few limitations:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;the key does not change if the contents of the folder is modified 
  &lt;ul&gt; 
   &lt;li&gt;if you need a new dirkey, either change the salt or rename the folder&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;linking to a textfile (so it opens in the textfile viewer) is not possible if recipient doesn't have read-access&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;password hashing&lt;/h2&gt; 
&lt;p&gt;you can hash passwords before putting them into config files / providing them as arguments; see &lt;code&gt;--help-pwhash&lt;/code&gt; for all the details&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;--ah-alg argon2&lt;/code&gt; enables it, and if you have any plaintext passwords then it'll print the hashed versions on startup so you can replace them&lt;/p&gt; 
&lt;p&gt;optionally also specify &lt;code&gt;--ah-cli&lt;/code&gt; to enter an interactive mode where it will hash passwords without ever writing the plaintext ones to disk&lt;/p&gt; 
&lt;p&gt;the default configs take about 0.4 sec and 256 MiB RAM to process a new password on a decent laptop&lt;/p&gt; 
&lt;p&gt;when generating hashes using &lt;code&gt;--ah-cli&lt;/code&gt; for docker or systemd services, make sure it is using the same &lt;code&gt;--ah-salt&lt;/code&gt; by:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;inspecting the generated salt using &lt;code&gt;--show-ah-salt&lt;/code&gt; in copyparty service configuration&lt;/li&gt; 
 &lt;li&gt;setting the same &lt;code&gt;--ah-salt&lt;/code&gt; in both environments&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;âš ï¸ if you have enabled &lt;code&gt;--usernames&lt;/code&gt; then provide the password as &lt;code&gt;username:password&lt;/code&gt; when hashing it, for example &lt;code&gt;ed:hunter2&lt;/code&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;https&lt;/h2&gt; 
&lt;p&gt;both HTTP and HTTPS are accepted by default, but letting a &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#reverse-proxy"&gt;reverse proxy&lt;/a&gt; handle the https/tls/ssl would be better (probably more secure by default)&lt;/p&gt; 
&lt;p&gt;copyparty doesn't speak HTTP/2 or QUIC, so using a reverse proxy would solve that as well -- but note that HTTP/1 is usually faster than both HTTP/2 and HTTP/3&lt;/p&gt; 
&lt;p&gt;if &lt;a href="https://github.com/cloudflare/cfssl/releases/latest"&gt;cfssl&lt;/a&gt; is installed, copyparty will automatically create a CA and server-cert on startup&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;the certs are written to &lt;code&gt;--crt-dir&lt;/code&gt; for distribution, see &lt;code&gt;--help&lt;/code&gt; for the other &lt;code&gt;--crt&lt;/code&gt; options&lt;/li&gt; 
 &lt;li&gt;this will be a self-signed certificate so you must install your &lt;code&gt;ca.pem&lt;/code&gt; into all your browsers/devices&lt;/li&gt; 
 &lt;li&gt;if you want to avoid the hassle of distributing certs manually, please consider using a reverse proxy&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;recovering from crashes&lt;/h1&gt; 
&lt;h2&gt;client crashes&lt;/h2&gt; 
&lt;h3&gt;firefox wsod&lt;/h3&gt; 
&lt;p&gt;firefox 87 can crash during uploads -- the entire browser goes, including all other browser tabs, everything turns white&lt;/p&gt; 
&lt;p&gt;however you can hit &lt;code&gt;F12&lt;/code&gt; in the up2k tab and use the devtools to see how far you got in the uploads:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;get a complete list of all uploads, organized by status (ok / no-good / busy / queued):&lt;br /&gt; &lt;code&gt;var tabs = { ok:[], ng:[], bz:[], q:[] }; for (var a of up2k.ui.tab) tabs[a.in].push(a); tabs&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;list of filenames which failed:&lt;br /&gt; &lt;code&gt;â€‹var ng = []; for (var a of up2k.ui.tab) if (a.in != 'ok') ng.push(a.hn.split('&amp;lt;a href=\"').slice(-1)[0].split('\"&amp;gt;')[0]); ng&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;send the list of filenames to copyparty for safekeeping:&lt;br /&gt; &lt;code&gt;await fetch('/inc', {method:'PUT', body:JSON.stringify(ng,null,1)})&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;HTTP API&lt;/h1&gt; 
&lt;p&gt;see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/docs/devnotes.md#http-api"&gt;devnotes&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;dependencies&lt;/h1&gt; 
&lt;p&gt;mandatory deps:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;jinja2&lt;/code&gt; (is built into the SFX)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;optional dependencies&lt;/h2&gt; 
&lt;p&gt;install these to enable bonus features&lt;/p&gt; 
&lt;p&gt;enable &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#password-hashing"&gt;hashed passwords&lt;/a&gt; in config: &lt;code&gt;argon2-cffi&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;enable &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#ftp-server"&gt;ftp-server&lt;/a&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;for just plaintext FTP, &lt;code&gt;pyftpdlib&lt;/code&gt; (is built into the SFX)&lt;/li&gt; 
 &lt;li&gt;with TLS encryption, &lt;code&gt;pyftpdlib pyopenssl&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;enable &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#metadata-from-audio-files"&gt;music tags&lt;/a&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;either &lt;code&gt;mutagen&lt;/code&gt; (fast, pure-python, skips a few tags, makes copyparty GPL? idk)&lt;/li&gt; 
 &lt;li&gt;or &lt;code&gt;ffprobe&lt;/code&gt; (20x slower, more accurate, possibly dangerous depending on your distro and users)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;enable &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#thumbnails"&gt;thumbnails&lt;/a&gt; of...&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;images:&lt;/strong&gt; &lt;code&gt;Pillow&lt;/code&gt; and/or &lt;code&gt;pyvips&lt;/code&gt; and/or &lt;code&gt;ffmpeg&lt;/code&gt; (requires py2.7 or py3.5+)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;videos/audio:&lt;/strong&gt; &lt;code&gt;ffmpeg&lt;/code&gt; and &lt;code&gt;ffprobe&lt;/code&gt; somewhere in &lt;code&gt;$PATH&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;HEIF pictures:&lt;/strong&gt; &lt;code&gt;pyvips&lt;/code&gt; or &lt;code&gt;ffmpeg&lt;/code&gt; or &lt;code&gt;pillow-heif&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;AVIF pictures:&lt;/strong&gt; &lt;code&gt;pyvips&lt;/code&gt; or &lt;code&gt;ffmpeg&lt;/code&gt; or &lt;code&gt;pillow-avif-plugin&lt;/code&gt; or pillow v11.3+&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;JPEG XL pictures:&lt;/strong&gt; &lt;code&gt;pyvips&lt;/code&gt; or &lt;code&gt;ffmpeg&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;RAW images:&lt;/strong&gt; &lt;code&gt;rawpy&lt;/code&gt;, plus one of &lt;code&gt;pyvips&lt;/code&gt; or &lt;code&gt;Pillow&lt;/code&gt; (for some formats)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;enable sending &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#zeromq"&gt;zeromq messages&lt;/a&gt; from event-hooks: &lt;code&gt;pyzmq&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;enable &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#smb-server"&gt;smb&lt;/a&gt; support (&lt;strong&gt;not&lt;/strong&gt; recommended): &lt;code&gt;impacket==0.12.0&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;pyvips&lt;/code&gt; gives higher quality thumbnails than &lt;code&gt;Pillow&lt;/code&gt; and is 320% faster, using 270% more ram: &lt;code&gt;sudo apt install libvips42 &amp;amp;&amp;amp; python3 -m pip install --user -U pyvips&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;to install FFmpeg on Windows, grab &lt;a href="https://www.gyan.dev/ffmpeg/builds/ffmpeg-git-full.7z"&gt;a recent build&lt;/a&gt; -- you need &lt;code&gt;ffmpeg.exe&lt;/code&gt; and &lt;code&gt;ffprobe.exe&lt;/code&gt; from inside the &lt;code&gt;bin&lt;/code&gt; folder; copy them into &lt;code&gt;C:\Windows\System32&lt;/code&gt; or any other folder that's in your &lt;code&gt;%PATH%&lt;/code&gt;&lt;/p&gt; 
&lt;h3&gt;dependency chickenbits&lt;/h3&gt; 
&lt;p&gt;prevent loading an optional dependency , for example if:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;you have an incompatible version installed and it causes problems&lt;/li&gt; 
 &lt;li&gt;you just don't want copyparty to use it, maybe to save ram&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;set any of the following environment variables to disable its associated optional feature,&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;env-var&lt;/th&gt; 
   &lt;th&gt;what it does&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;PRTY_NO_ARGON2&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;disable argon2-cffi password hashing&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;PRTY_NO_CFSSL&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;never attempt to generate self-signed certificates using &lt;a href="https://github.com/cloudflare/cfssl"&gt;cfssl&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;PRTY_NO_FFMPEG&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;audio transcoding&lt;/strong&gt; goes byebye, &lt;strong&gt;thumbnailing&lt;/strong&gt; must be handled by Pillow/libvips&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;PRTY_NO_FFPROBE&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;audio transcoding&lt;/strong&gt; goes byebye, &lt;strong&gt;thumbnailing&lt;/strong&gt; must be handled by Pillow/libvips, &lt;strong&gt;metadata-scanning&lt;/strong&gt; must be handled by mutagen&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;PRTY_NO_MAGIC&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;do not use &lt;a href="https://pypi.org/project/python-magic/"&gt;magic&lt;/a&gt; for filetype detection&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;PRTY_NO_MUTAGEN&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;do not use &lt;a href="https://pypi.org/project/mutagen/"&gt;mutagen&lt;/a&gt; for reading metadata from media files; will fallback to ffprobe&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;PRTY_NO_PIL&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;disable all &lt;a href="https://pypi.org/project/pillow/"&gt;Pillow&lt;/a&gt;-based thumbnail support; will fallback to libvips or ffmpeg&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;PRTY_NO_PILF&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;disable Pillow &lt;code&gt;ImageFont&lt;/code&gt; text rendering, used for folder thumbnails&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;PRTY_NO_PIL_AVIF&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;disable Pillow avif support (internal and/or &lt;a href="https://pypi.org/project/pillow-avif-plugin/"&gt;plugin&lt;/a&gt;)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;PRTY_NO_PIL_HEIF&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;disable 3rd-party Pillow plugin for &lt;a href="https://pypi.org/project/pillow-heif/"&gt;HEIF support&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;PRTY_NO_PIL_WEBP&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;disable use of native webp support in Pillow&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;PRTY_NO_PSUTIL&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;do not use &lt;a href="https://pypi.org/project/psutil/"&gt;psutil&lt;/a&gt; for reaping stuck hooks and plugins on Windows&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;PRTY_NO_RAW&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;disable all &lt;a href="https://pypi.org/project/rawpy/"&gt;rawpy&lt;/a&gt;-based thumbnail support for RAW images&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;PRTY_NO_VIPS&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;disable all &lt;a href="https://pypi.org/project/pyvips/"&gt;libvips&lt;/a&gt;-based thumbnail support; will fallback to Pillow or ffmpeg&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;example: &lt;code&gt;PRTY_NO_PIL=1 python3 copyparty-sfx.py&lt;/code&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;PRTY_NO_PIL&lt;/code&gt; saves ram&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;PRTY_NO_VIPS&lt;/code&gt; saves ram and startup time&lt;/li&gt; 
 &lt;li&gt;python2.7 on windows: &lt;code&gt;PRTY_NO_FFMPEG&lt;/code&gt; + &lt;code&gt;PRTY_NO_FFPROBE&lt;/code&gt; saves startup time&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;optional gpl stuff&lt;/h2&gt; 
&lt;p&gt;some bundled tools have copyleft dependencies, see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/bin/#mtag"&gt;./bin/#mtag&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;these are standalone programs and will never be imported / evaluated by copyparty, and must be enabled through &lt;code&gt;-mtp&lt;/code&gt; configs&lt;/p&gt; 
&lt;h1&gt;sfx&lt;/h1&gt; 
&lt;p&gt;the self-contained "binary" (recommended!) &lt;a href="https://github.com/9001/copyparty/releases/latest/download/copyparty-sfx.py"&gt;copyparty-sfx.py&lt;/a&gt; will unpack itself and run copyparty, assuming you have python installed of course&lt;/p&gt; 
&lt;p&gt;if you only need english, &lt;a href="https://github.com/9001/copyparty/releases/latest/download/copyparty-en.py"&gt;copyparty-en.py&lt;/a&gt; is the same thing but smaller&lt;/p&gt; 
&lt;p&gt;you can reduce the sfx size by repacking it; see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/docs/devnotes.md#sfx-repack"&gt;./docs/devnotes.md#sfx-repack&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;copyparty.exe&lt;/h2&gt; 
&lt;p&gt;download &lt;a href="https://github.com/9001/copyparty/releases/latest/download/copyparty.exe"&gt;copyparty.exe&lt;/a&gt; (win8+) or &lt;a href="https://github.com/9001/copyparty/releases/latest/download/copyparty32.exe"&gt;copyparty32.exe&lt;/a&gt; (win7+)&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://user-images.githubusercontent.com/241032/221445946-1e328e56-8c5b-44a9-8b9f-dee84d942535.png" alt="copyparty-exe-fs8" /&gt;&lt;/p&gt; 
&lt;p&gt;can be convenient on machines where installing python is problematic, however is &lt;strong&gt;not recommended&lt;/strong&gt; -- if possible, please use &lt;strong&gt;&lt;a href="https://github.com/9001/copyparty/releases/latest/download/copyparty-sfx.py"&gt;copyparty-sfx.py&lt;/a&gt;&lt;/strong&gt; instead&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/9001/copyparty/releases/latest/download/copyparty.exe"&gt;copyparty.exe&lt;/a&gt; runs on win8 or newer, was compiled on win10, does thumbnails + media tags, and is &lt;em&gt;currently&lt;/em&gt; safe to use, but any future python/expat/pillow CVEs can only be remedied by downloading a newer version of the exe&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;on win8 it needs &lt;a href="https://www.microsoft.com/en-us/download/details.aspx?id=48145"&gt;vc redist 2015&lt;/a&gt;, on win10 it just works&lt;/li&gt; 
   &lt;li&gt;some antivirus may freak out (false-positive), possibly &lt;a href="https://www.virustotal.com/gui/file/52391a1e9842cf70ad243ef83844d46d29c0044d101ee0138fcdd3c8de2237d6/detection"&gt;Avast, AVG, and McAfee&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;dangerous: &lt;a href="https://github.com/9001/copyparty/releases/latest/download/copyparty32.exe"&gt;copyparty32.exe&lt;/a&gt; is compatible with &lt;a href="https://user-images.githubusercontent.com/241032/221445944-ae85d1f4-d351-4837-b130-82cab57d6cca.png"&gt;windows7&lt;/a&gt;, which means it uses an ancient copy of python (3.7.9) which cannot be upgraded and should never be exposed to the internet (LAN is fine)&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;dangerous and deprecated: &lt;a href="https://github.com/9001/copyparty/releases/download/v1.8.7/copyparty-winpe64.exe"&gt;copyparty-winpe64.exe&lt;/a&gt; lets you &lt;a href="https://user-images.githubusercontent.com/241032/205454984-e6b550df-3c49-486d-9267-1614078dd0dd.png"&gt;run copyparty in WinPE&lt;/a&gt; and is otherwise completely useless&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;meanwhile &lt;a href="https://github.com/9001/copyparty/releases/latest/download/copyparty-sfx.py"&gt;copyparty-sfx.py&lt;/a&gt; instead relies on your system python which gives better performance and will stay safe as long as you keep your python install up-to-date&lt;/p&gt; 
&lt;p&gt;then again, if you are already into downloading shady binaries from the internet, you may also want my &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/scripts/pyinstaller#ffmpeg"&gt;minimal builds&lt;/a&gt; of &lt;a href="https://ocv.me/stuff/bin/ffmpeg.exe"&gt;ffmpeg&lt;/a&gt; and &lt;a href="https://ocv.me/stuff/bin/ffprobe.exe"&gt;ffprobe&lt;/a&gt; which enables copyparty to extract multimedia-info, do audio-transcoding, and thumbnails/spectrograms/waveforms, however it's much better to instead grab a &lt;a href="https://www.gyan.dev/ffmpeg/builds/ffmpeg-git-full.7z"&gt;recent official build&lt;/a&gt; every once ina while if you can afford the size&lt;/p&gt; 
&lt;h2&gt;zipapp&lt;/h2&gt; 
&lt;p&gt;another emergency alternative, &lt;a href="https://github.com/9001/copyparty/releases/latest/download/copyparty.pyz"&gt;copyparty.pyz&lt;/a&gt; has less features, is slow, requires python 3.7 or newer, worse compression, and more importantly is unable to benefit from more recent versions of jinja2 and such (which makes it less secure)... lots of drawbacks with this one really -- but, unlike the sfx, it is a completely normal zipfile which does not unpack any temporary files to disk, so it &lt;em&gt;may&lt;/em&gt; just work if the regular sfx fails to start because the computer is messed up in certain funky ways, so it's worth a shot if all else fails&lt;/p&gt; 
&lt;p&gt;run it by doubleclicking it, or try typing &lt;code&gt;python copyparty.pyz&lt;/code&gt; in your terminal/console/commandline/telex if that fails&lt;/p&gt; 
&lt;p&gt;it is a python &lt;a href="https://docs.python.org/3/library/zipapp.html"&gt;zipapp&lt;/a&gt; meaning it doesn't have to unpack its own python code anywhere to run, so if the filesystem is busted it has a better chance of getting somewhere&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;but note that it currently still needs to extract the web-resources somewhere (they'll land in the default TEMP-folder of your OS)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;install on android&lt;/h1&gt; 
&lt;p&gt;install &lt;a href="https://termux.com/"&gt;Termux&lt;/a&gt; + its companion app &lt;code&gt;Termux:API&lt;/code&gt; (see &lt;a href="https://ocv.me/termux/"&gt;ocv.me/termux&lt;/a&gt;) and then copy-paste this into Termux (long-tap) all at once:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;yes | pkg upgrade &amp;amp;&amp;amp; termux-setup-storage &amp;amp;&amp;amp; yes | pkg install python termux-api &amp;amp;&amp;amp; python -m ensurepip &amp;amp;&amp;amp; python -m pip install --user -U copyparty &amp;amp;&amp;amp; { grep -qE 'PATH=.*\.local/bin' ~/.bashrc 2&amp;gt;/dev/null || { echo 'PATH="$HOME/.local/bin:$PATH"' &amp;gt;&amp;gt; ~/.bashrc &amp;amp;&amp;amp; . ~/.bashrc; }; }
echo $?
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;after the initial setup, you can launch copyparty at any time by running &lt;code&gt;copyparty&lt;/code&gt; anywhere in Termux -- and if you run it with &lt;code&gt;--qr&lt;/code&gt; you'll get a &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#qr-code"&gt;neat qr-code&lt;/a&gt; pointing to your external ip&lt;/p&gt; 
&lt;p&gt;if you want thumbnails (photos+videos) and you're okay with spending another 132 MiB of storage, &lt;code&gt;pkg install ffmpeg &amp;amp;&amp;amp; python3 -m pip install --user -U pillow&lt;/code&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;or if you want to use &lt;code&gt;vips&lt;/code&gt; for photo-thumbs instead, &lt;code&gt;pkg install libvips &amp;amp;&amp;amp; python -m pip install --user -U wheel &amp;amp;&amp;amp; python -m pip install --user -U pyvips &amp;amp;&amp;amp; (cd /data/data/com.termux/files/usr/lib/; ln -s libgobject-2.0.so{,.0}; ln -s libvips.so{,.42})&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;install on iOS&lt;/h1&gt; 
&lt;p&gt;first install one of the following:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://apps.apple.com/us/app/a-shell-mini/id1543537943"&gt;a-Shell mini&lt;/a&gt; gives you the essential features&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://apps.apple.com/us/app/a-shell/id1473805438"&gt;a-Shell&lt;/a&gt; also enables audio transcoding and better thubmnails&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;and then copypaste the following command into &lt;code&gt;a-Shell&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;curl https://github.com/9001/copyparty/raw/refs/heads/hovudstraum/contrib/setup-ashell.sh | sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;what this does:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;creates a basic &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#accounts-and-volumes"&gt;config file&lt;/a&gt; named &lt;code&gt;cpc&lt;/code&gt; which you can edit with &lt;code&gt;vim cpc&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;adds the command &lt;code&gt;cpp&lt;/code&gt; to launch copyparty with that config file&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;known issues:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;cannot run in the background; it needs to be on-screen to accept connections / uploads / downloads&lt;/li&gt; 
 &lt;li&gt;the best way to exit copyparty is to swipe away the app&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;reporting bugs&lt;/h1&gt; 
&lt;p&gt;ideas for context to include, and where to submit them&lt;/p&gt; 
&lt;p&gt;please get in touch using any of the following URLs:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/9001/copyparty/"&gt;https://github.com/9001/copyparty/&lt;/a&gt; &lt;strong&gt;(primary)&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://gitlab.com/9001/copyparty/"&gt;https://gitlab.com/9001/copyparty/&lt;/a&gt; &lt;em&gt;(mirror)&lt;/em&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://codeberg.org/9001/copyparty"&gt;https://codeberg.org/9001/copyparty&lt;/a&gt; &lt;em&gt;(mirror)&lt;/em&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;in general, commandline arguments (and config file if any)&lt;/p&gt; 
&lt;p&gt;if something broke during an upload (replacing FILENAME with a part of the filename that broke):&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;journalctl -aS '48 hour ago' -u copyparty | grep -C10 FILENAME | tee bug.log
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;if there's a wall of base64 in the log (thread stacks) then please include that, especially if you run into something freezing up or getting stuck, for example &lt;code&gt;OperationalError('database is locked')&lt;/code&gt; -- alternatively you can visit &lt;code&gt;/?stack&lt;/code&gt; to see the stacks live, so &lt;a href="http://127.0.0.1:3923/?stack"&gt;http://127.0.0.1:3923/?stack&lt;/a&gt; for example&lt;/p&gt; 
&lt;h1&gt;devnotes&lt;/h1&gt; 
&lt;p&gt;for build instructions etc, see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/docs/devnotes.md"&gt;./docs/devnotes.md&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;specifically you may want to &lt;a href="https://github.com/9001/copyparty/raw/hovudstraum/docs/devnotes.md#just-the-sfx"&gt;build the sfx&lt;/a&gt; or &lt;a href="https://github.com/9001/copyparty/raw/hovudstraum/docs/devnotes.md#build-from-scratch"&gt;build from scratch&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/docs/TODO.md"&gt;./docs/TODO.md&lt;/a&gt; for planned features / fixes / changes&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>hesreallyhim/awesome-claude-code</title>
      <link>https://github.com/hesreallyhim/awesome-claude-code</link>
      <description>&lt;p&gt;A curated list of awesome commands, files, and workflows for Claude Code&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;!-- Same ASCII art for all screen sizes, just scales down on mobile --&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="./assets/logo-dark.svg" /&gt; 
  &lt;img src="https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/assets/logo-light.svg?sanitize=true" alt="Awesome Claude Code" width="100%" style="max-width: 900px;" /&gt; 
 &lt;/picture&gt; 
&lt;/div&gt; 
&lt;!-- Generated with https://github.com/denvercoder1/readme-typing-svg --&gt; 
&lt;p&gt;&lt;a href="https://git.io/typing-svg"&gt;&lt;img src="https://readme-typing-svg.demolab.com?font=Fira+Code&amp;amp;weight=600&amp;amp;pause=1000&amp;amp;color=F7080D&amp;amp;random=true&amp;amp;width=435&amp;amp;lines=Fumigating...;Gallivanting...;Matriculating...;Toodleedoodling...;Goo-goo-g'joob-ing...;Excaliburating...;Canoodling...;Doing+the+humpty+dance...;Shiver-me-timbers-ing...;Becoming+sentient...;Opening+the+pod+bay+doors...;Rimraf-ing;23-skidoo-ing" alt="Typing SVG" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;!--lint enable remark-lint:awesome-badge--&gt; 
&lt;p&gt;&lt;a href="https://awesome.re"&gt;&lt;img src="https://awesome.re/badge-flat2.svg?sanitize=true" alt="Awesome" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;&lt;a href="https://github.com/hesreallyhim/awesome-claude-code"&gt;Awesome Claude Code&lt;/a&gt; ğŸ¤ &lt;a href="https://github.com/hesreallyhim/awesome-claude-code-agents"&gt;Awesome Claude Code Agents&lt;/a&gt;&lt;/h1&gt; 
&lt;!--lint enable remark-lint:awesome-badge--&gt; 
&lt;!--lint disable double-link--&gt; 
&lt;p&gt;This is a curated list of slash-commands, &lt;code&gt;CLAUDE.md&lt;/code&gt; files, CLI tools, and other resources and guides for enhancing your &lt;a href="https://docs.anthropic.com/en/docs/claude-code"&gt;Claude Code&lt;/a&gt; workflow, productivity, and vibes.&lt;/p&gt; 
&lt;!--lint enable double-link--&gt; 
&lt;p&gt;Claude Code is a cutting-edge CLI-based coding assistant and agent released by &lt;a href="https://www.anthropic.com/"&gt;Anthropic&lt;/a&gt; that you can access in your terminal or IDE. It is a rapidly evolving tool that offers a number of powerful capabilities, and allows for a lot of configuration, in a lot of different ways. Users are actively working out best practices and workflows. It is the hope that this repo will help the community share knowledge and understand how to get the most out of Claude Code.&lt;/p&gt; 
&lt;h3&gt;Announcements&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;2025-08-16&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;(i) So much happening with Claude Code these days, it is genuinely hard to keep up! Since my last post, let's see... Opus 4.1; status lines; output styles; more sub agents; (plugins??); background shells; lions; tigers... wait sorry that's something else. Anyway, I'm glad to announce that besides some annoying bot messages and small glitches, the new resource submission workflow seems to be working really solidly. It's so much easier for everyone, so if you'd like to contribute to this community resource, make sure you are up to date on &lt;a href="https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/CONTRIBUTING.md"&gt;&lt;code&gt;CONTRIBUTING.md&lt;/code&gt;&lt;/a&gt; - I will no longer be accepting &lt;em&gt;resource submission&lt;/em&gt; PRs (there may be other cases where a PR is appropriate), but you can now submit something to the list without even cloning the repo or knowing how to spell "git". Just head over to the new resource submission &lt;a href="https://github.com/hesreallyhim/awesome-claude-code/issues/new?template=submit-resource.yml"&gt;Issue Template&lt;/a&gt; and you'll be done in no time. If you have a PR open, please try to open it as an issue instead, although I will of course get through existing PR's before switching over entirely.&lt;/p&gt; 
&lt;p&gt;(ii) I started a new section for Status Lines, and will soon open up another one for Output Styles hopefully. &lt;em&gt;WE WANT TO SEE YOUR STATUS LINES!&lt;/em&gt; Definitely will be prioritizing those items in the short term. I've sadly been neglecting the awesome-claude-code-agents repo due to Claude Code's impressively rapid release cycle, but I haven't forgotten about it, rest assured.&lt;/p&gt; 
&lt;p&gt;(iii) Still hoping to organize some friendly competition as soon as time allows.&lt;/p&gt; 
&lt;p&gt;(iv) Considering imposing some more constraints on submissions, in particular I may decide to have your repo (if it is a repo) evaluated by a State-of-the-art language model, primarily for security, and not for awesomeness, as it's getting hard to keep up with all the great stuff coming in while still doing due diligence to make sure that this is not a home for malware or otherwise insecure resources.&lt;/p&gt; 
&lt;p&gt;(v) Check out some of the latest entries below, and start shipping your status lines! Even small entries are totally welcome, it doesn't have to be a Picasso - if it fits on a single line, that makes it even easier to compose it with another awesome resource.&lt;/p&gt; 
&lt;h2&gt;This Week's Additions âœ¨&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Resources added in the past 7 days&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;a href="https://github.com/eckardt/cchistory"&gt;&lt;code&gt;cchistory&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/eckardt"&gt;eckardt&lt;/a&gt; &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;MIT&lt;br /&gt; Like the shell history command but for your Claude Code sessions. Easily list all Bash or "Bash-mode" (&lt;code&gt;!&lt;/code&gt;) commands Claude Code ran in a session for reference.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/slopus/happy"&gt;&lt;code&gt;Happy Coder&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://peoplesgrocers.com/en/projects"&gt;GrocerPublishAgent&lt;/a&gt; &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;MIT&lt;br /&gt; Spawn and control multiple Claude Codes in parallel from your phone or desktop. Happy Coder runs Claude Code on your hardware, sends push notifications when Claude needs more input or permission, and costs nothing.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/davila7/claude-code-templates"&gt;&lt;code&gt;Claude Code Templates&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/davila7"&gt;Daniel Avila&lt;/a&gt; &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;MIT&lt;br /&gt; Incredibly awesome collection of resources from every category in this list, presented with a neatly polished UI, great features like usage dashboard, analytics, and everything from slash commands to hooks to agents. An awesome companion for this awesome list.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/carlrannaberg/claudekit"&gt;&lt;code&gt;claudekit&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/carlrannaberg"&gt;Carl Rannaberg&lt;/a&gt; &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;MIT&lt;br /&gt; Impressive CLI toolkit providing auto-save checkpointing, code quality hooks, specification generation and execution, and 20+ specialized subagents including oracle (gpt-5), code-reviewer (6-aspect deep analysis), ai-sdk-expert (Vercel AI SDK), typescript-expert and many more for Claude Code workflows.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/bartolli/claude-code-typescript-hooks"&gt;&lt;code&gt;TypeScript Quality Hooks&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/bartolli"&gt;bartolli&lt;/a&gt; &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;MIT&lt;br /&gt; Quality check hook for Node.js TypeScript projects with TypeScript compilation. ESLint auto-fixing, and Prettier formatting. Uses SHA256 config caching for &amp;lt;5ms validation performance during real-time editing.&lt;/p&gt; 
&lt;h2&gt;Contents&lt;/h2&gt; 
&lt;p&gt;â–ª&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;a href="https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/#workflows--knowledge-guides-"&gt;Workflows &amp;amp; Knowledge Guides&lt;/a&gt;&lt;br /&gt; â–ª&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;a href="https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/#tooling-"&gt;Tooling&lt;/a&gt;&lt;br /&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;â–«&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;a href="https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/#ide-integrations"&gt;IDE Integrations&lt;/a&gt;&lt;br /&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;â–«&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;a href="https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/#usage-monitors"&gt;Usage Monitors&lt;/a&gt;&lt;br /&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;â–«&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;a href="https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/#orchestrators"&gt;Orchestrators&lt;/a&gt;&lt;br /&gt; â–ª&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;a href="https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/#statusline-"&gt;Statusline&lt;/a&gt;&lt;br /&gt; â–ª&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;a href="https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/#hooks-"&gt;Hooks&lt;/a&gt;&lt;br /&gt; â–ª&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;a href="https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/#slash-commands-"&gt;Slash-Commands&lt;/a&gt;&lt;br /&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;â–«&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;a href="https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/#version-control--git"&gt;Version Control &amp;amp; Git&lt;/a&gt;&lt;br /&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;â–«&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;a href="https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/#code-analysis--testing"&gt;Code Analysis &amp;amp; Testing&lt;/a&gt;&lt;br /&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;â–«&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;a href="https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/#context-loading--priming"&gt;Context Loading &amp;amp; Priming&lt;/a&gt;&lt;br /&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;â–«&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;a href="https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/#documentation--changelogs"&gt;Documentation &amp;amp; Changelogs&lt;/a&gt;&lt;br /&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;â–«&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;a href="https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/#ci--deployment"&gt;CI / Deployment&lt;/a&gt;&lt;br /&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;â–«&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;a href="https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/#project--task-management"&gt;Project &amp;amp; Task Management&lt;/a&gt;&lt;br /&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;â–«&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;a href="https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/#miscellaneous"&gt;Miscellaneous&lt;/a&gt;&lt;br /&gt; â–ª&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;a href="https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/#claudemd-files-"&gt;CLAUDE.md Files&lt;/a&gt;&lt;br /&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;â–«&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;a href="https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/#language-specific"&gt;Language-Specific&lt;/a&gt;&lt;br /&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;â–«&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;a href="https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/#domain-specific"&gt;Domain-Specific&lt;/a&gt;&lt;br /&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;â–«&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;a href="https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/#project-scaffolding--mcp"&gt;Project Scaffolding &amp;amp; MCP&lt;/a&gt;&lt;br /&gt; â–ª&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;a href="https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/#official-documentation-%EF%B8%8F"&gt;Official Documentation&lt;/a&gt;&lt;/p&gt; 
&lt;br /&gt; 
&lt;h2&gt;Workflows &amp;amp; Knowledge Guides ğŸ§ &lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;A &lt;strong&gt;workflow&lt;/strong&gt; is a tightly coupled set of Claude Code-native resources that facilitate specific projects&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;a href="https://github.com/cloudartisan/cloudartisan.github.io/tree/main/.claude/commands"&gt;&lt;code&gt;Blogging Platform Instructions&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/cloudartisan"&gt;cloudartisan&lt;/a&gt; &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;CC-BY-SA-4.0&lt;br /&gt; Provides a well-structured set of commands for publishing and maintaining a blogging platform, including commands for creating posts, managing categories, and handling media files.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://claudelog.com"&gt;&lt;code&gt;ClaudeLog&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://www.reddit.com/user/inventor_black/"&gt;InventorBlack&lt;/a&gt;&lt;br /&gt; A comprehensive knowledge base with detailed breakdowns of advanced &lt;a href="https://claudelog.com/mechanics/you-are-the-main-thread/"&gt;mechanics&lt;/a&gt; including &lt;a href="https://claudelog.com/mechanics/claude-md-supremacy"&gt;CLAUDE.md best practices&lt;/a&gt;, practical technique guides like &lt;a href="https://claudelog.com/mechanics/plan-mode"&gt;plan mode&lt;/a&gt;, &lt;a href="https://claudelog.com/faqs/what-is-ultrathink/"&gt;ultrathink&lt;/a&gt;, &lt;a href="https://claudelog.com/mechanics/task-agent-tools/"&gt;sub-agents&lt;/a&gt;, &lt;a href="https://claudelog.com/mechanics/agent-first-design/"&gt;agent-first design&lt;/a&gt; and &lt;a href="https://claudelog.com/configuration"&gt;configuration guides&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/disler/just-prompt/tree/main/.claude/commands"&gt;&lt;code&gt;Context Priming&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/disler"&gt;disler&lt;/a&gt;&lt;br /&gt; Provides a systematic approach to priming Claude Code with comprehensive project context through specialized commands for different project scenarios and development contexts.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/tott/laravel-tall-claude-ai-configs"&gt;&lt;code&gt;Laravel TALL Stack AI Development Starter Kit&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/tott"&gt;tott&lt;/a&gt; &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;MIT&lt;br /&gt; Transform your Laravel TALL (Tailwind, AlpineJS, Laravel, Livewire) stack development with comprehensive Claude Code configurations that provide intelligent assistance, systematic workflows, and domain expert consultation.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/kingler/n8n_agent/tree/main/.claude/commands"&gt;&lt;code&gt;n8n_agent&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/kingler"&gt;kingler&lt;/a&gt;&lt;br /&gt; Amazing comprehensive set of comments for code analysis, QA, design, documentation, project structure, project management, optimization, and many more.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/steadycursor/steadystart/tree/main/.claude/commands"&gt;&lt;code&gt;Project Bootstrapping and Task Management&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/steadycursor"&gt;steadycursor&lt;/a&gt;&lt;br /&gt; Provides a structured set of commands for bootstrapping and managing a new project, including meta-commands for creating and editing custom slash-commands.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/scopecraft/command/tree/main/.claude/commands"&gt;&lt;code&gt;Project Management, Implementation, Planning, and Release&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/scopecraft"&gt;scopecraft&lt;/a&gt;&lt;br /&gt; Really comprehensive set of commands for all aspects of SDLC.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/harperreed/dotfiles/tree/master/.claude/commands"&gt;&lt;code&gt;Project Workflow System&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/harperreed"&gt;harperreed&lt;/a&gt;&lt;br /&gt; A set of commands that provide a comprehensive workflow system for managing projects, including task management, code review, and deployment processes.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://diwank.space/field-notes-from-shipping-real-code-with-claude"&gt;&lt;code&gt;Shipping Real Code w/ Claude&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/creatorrr"&gt;Diwank&lt;/a&gt;&lt;br /&gt; A detailed blog post explaining the author's process for shipping a product with Claude Code, including CLAUDE.md files and other interesting resources.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/Helmi/claude-simone"&gt;&lt;code&gt;Simone&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/Helmi"&gt;Helmi&lt;/a&gt; &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;MIT&lt;br /&gt; A broader project management workflow for Claude Code that encompasses not just a set of commands, but a system of documents, guidelines, and processes to facilitate project planning and execution.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/wcygan/dotfiles/tree/d8ab6b9f5a7a81007b7f5fa3025d4f83ce12cc02/claude/commands"&gt;&lt;code&gt;Slash-commands megalist&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/wcygan"&gt;wcygan&lt;/a&gt;&lt;br /&gt; A pretty stunning list (88 at the time of this post!) of slash-commands ranging from agent orchestration, code review, project management, security, documentation, self-assessment, almost anything you can dream of.&lt;/p&gt; 
&lt;br /&gt; 
&lt;h2&gt;Tooling ğŸ§°&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Tooling&lt;/strong&gt; denotes applications that are built on top of Claude Code and consist of more components than slash-commands and &lt;code&gt;CLAUDE.md&lt;/code&gt; files&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;a href="https://github.com/nyatinte/ccexp"&gt;&lt;code&gt;ccexp&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/nyatinte"&gt;nyatinte&lt;/a&gt; &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;MIT&lt;br /&gt; Interactive CLI tool for discovering and managing Claude Code configuration files and slash commands with a beautiful terminal UI.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/eckardt/cchistory"&gt;&lt;code&gt;cchistory&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/eckardt"&gt;eckardt&lt;/a&gt; &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;MIT&lt;br /&gt; Like the shell history command but for your Claude Code sessions. Easily list all Bash or "Bash-mode" (&lt;code&gt;!&lt;/code&gt;) commands Claude Code ran in a session for reference.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/Brads3290/cclogviewer"&gt;&lt;code&gt;cclogviewer&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/Brads3290"&gt;Brad S.&lt;/a&gt; &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;MIT&lt;br /&gt; A humble but handy utility for viewing Claude Code &lt;code&gt;.jsonl&lt;/code&gt; conversation files in a pretty HTML UI.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/davila7/claude-code-templates"&gt;&lt;code&gt;Claude Code Templates&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/davila7"&gt;Daniel Avila&lt;/a&gt; &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;MIT&lt;br /&gt; Incredibly awesome collection of resources from every category in this list, presented with a neatly polished UI, great features like usage dashboard, analytics, and everything from slash commands to hooks to agents. An awesome companion for this awesome list.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/possibilities/claude-composer"&gt;&lt;code&gt;Claude Composer&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/possibilities"&gt;Mike Bannister&lt;/a&gt; &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;Unlicense&lt;br /&gt; A tool that adds small enhancements to Claude Code.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/claude-did-this/claude-hub"&gt;&lt;code&gt;Claude Hub&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/claude-did-this"&gt;Claude Did This&lt;/a&gt;&lt;br /&gt; A webhook service that connects Claude Code to GitHub repositories, enabling AI-powered code assistance directly through pull requests and issues. This integration allows Claude to analyze repositories, answer technical questions, and help developers understand and improve their codebase through simple @mentions.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/pchalasani/claude-code-tools"&gt;&lt;code&gt;claude-code-tools&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/pchalasani"&gt;Prasad Chalasani&lt;/a&gt; &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;MIT&lt;br /&gt; A collection of awesome tools, including tmux integrations, better session management, hooks that enhance security - a really well-done set of Claude Code enhancers, especially for tmux users.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/carlrannaberg/claudekit"&gt;&lt;code&gt;claudekit&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/carlrannaberg"&gt;Carl Rannaberg&lt;/a&gt; &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;MIT&lt;br /&gt; Impressive CLI toolkit providing auto-save checkpointing, code quality hooks, specification generation and execution, and 20+ specialized subagents including oracle (gpt-5), code-reviewer (6-aspect deep analysis), ai-sdk-expert (Vercel AI SDK), typescript-expert and many more for Claude Code workflows.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/dagger/container-use"&gt;&lt;code&gt;Container Use&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/dagger"&gt;dagger&lt;/a&gt; &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;Apache-2.0&lt;br /&gt; Development environments for coding agents. Enable multiple agents to work safely and independently with your preferred stack.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/Piebald-AI/tweakcc"&gt;&lt;code&gt;tweakcc&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/Piebald-AI"&gt;Piebald-AI&lt;/a&gt; &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;MIT&lt;br /&gt; Command-line tool to customize your Claude Code styling.&lt;/p&gt; 
&lt;h3&gt;IDE Integrations&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://marketplace.visualstudio.com/items?itemName=AndrePimenta.claude-code-chat"&gt;&lt;code&gt;Claude Code Chat&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/andrepimenta"&gt;andrepimenta&lt;/a&gt; &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;Â©&lt;br /&gt; An elegant and user-friendly Claude Code chat interface for VS Code.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/manzaltu/claude-code-ide.el"&gt;&lt;code&gt;claude-code-ide.el&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/manzaltu"&gt;manzaltu&lt;/a&gt; &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;GPL-3.0&lt;br /&gt; claude-code-ide.el integrates Claude Code with Emacs, like Anthropicâ€™s VS Code/IntelliJ extensions. It shows ediff-based code suggestions, pulls LSP/flymake/flycheck diagnostics, and tracks buffer context. It adds an extensible MCP tool support for symbol refs/defs, project metadata, and tree-sitter AST queries.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/stevemolitor/claude-code.el"&gt;&lt;code&gt;claude-code.el&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/stevemolitor"&gt;stevemolitor&lt;/a&gt; &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;Apache-2.0&lt;br /&gt; An Emacs interface for Claude Code CLI.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/greggh/claude-code.nvim"&gt;&lt;code&gt;claude-code.nvim&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/greggh"&gt;greggh&lt;/a&gt; &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;MIT&lt;br /&gt; A seamless integration between Claude Code AI assistant and Neovim.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/stravu/crystal"&gt;&lt;code&gt;crystal&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/stravu"&gt;stravu&lt;/a&gt; &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;MIT&lt;br /&gt; A full-fledged desktop application for orchestrating, monitoring, and interacting with Claude Code agents.&lt;/p&gt; 
&lt;h3&gt;Usage Monitors&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://github.com/ryoppippi/ccusage"&gt;&lt;code&gt;CC Usage&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/ryoppippi"&gt;ryoppippi&lt;/a&gt; &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;MIT&lt;br /&gt; Handy CLI tool for managing and analyzing Claude Code usage, based on analyzing local Claude Code logs. Presents a nice dashboard regarding cost information, token consumption, etc.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/snipeship/ccflare"&gt;&lt;code&gt;ccflare&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/snipeship"&gt;snipeship&lt;/a&gt; &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;MIT&lt;br /&gt; Claude Code usage dashboard with a web-UI that would put Tableau to shame. Thoroughly comprehensive metrics, frictionless setup, detailed logging, really really nice UI.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/Maciek-roboblog/Claude-Code-Usage-Monitor"&gt;&lt;code&gt;Claude Code Usage Monitor&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/Maciek-roboblog"&gt;Maciek-roboblog&lt;/a&gt; &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;MIT&lt;br /&gt; A real-time terminal-based tool for monitoring Claude Code token usage. It shows live token consumption, burn rate, and predictions for token depletion. Features include visual progress bars, session-aware analytics, and support for multiple subscription plans.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/sculptdotfun/viberank"&gt;&lt;code&gt;viberank&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/nikshepsvn"&gt;nikshepsvn&lt;/a&gt; &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;MIT&lt;br /&gt; A community-driven leaderboard tool that enables developers to visualize, track, and compete based on their Claude Code usage statistics. It features robust data analytics, GitHub OAuth, data validation, and user-friendly CLI/web submission methods.&lt;/p&gt; 
&lt;h3&gt;Orchestrators&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://github.com/ruvnet/claude-code-flow"&gt;&lt;code&gt;Claude Code Flow&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/ruvnet"&gt;ruvnet&lt;/a&gt; &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;MIT&lt;br /&gt; This mode serves as a code-first orchestration layer, enabling Claude to write, edit, test, and optimize code autonomously across recursive agent cycles.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/smtg-ai/claude-squad"&gt;&lt;code&gt;Claude Squad&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/smtg-ai"&gt;smtg-ai&lt;/a&gt; &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;AGPL-3.0&lt;br /&gt; Claude Squad is a terminal app that manages multiple Claude Code, Codex (and other local agents including Aider) in separate workspaces, allowing you to work on multiple tasks simultaneously.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/parruda/claude-swarm"&gt;&lt;code&gt;Claude Swarm&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/parruda"&gt;parruda&lt;/a&gt; &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;MIT&lt;br /&gt; Launch Claude Code session that is connected to a swarm of Claude Code Agents.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/eyaltoledano/claude-task-master"&gt;&lt;code&gt;Claude Task Master&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/eyaltoledano"&gt;eyaltoledano&lt;/a&gt; &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;NOASSERTION&lt;br /&gt; A task management system for AI-driven development with Claude, designed to work seamlessly with Cursor AI.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/grahama1970/claude-task-runner"&gt;&lt;code&gt;Claude Task Runner&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/grahama1970"&gt;grahama1970&lt;/a&gt;&lt;br /&gt; A specialized tool to manage context isolation and focused task execution with Claude Code, solving the critical challenge of context length limitations and task focus when working with Claude on complex, multi-step projects.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/slopus/happy"&gt;&lt;code&gt;Happy Coder&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://peoplesgrocers.com/en/projects"&gt;GrocerPublishAgent&lt;/a&gt; &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;MIT&lt;br /&gt; Spawn and control multiple Claude Codes in parallel from your phone or desktop. Happy Coder runs Claude Code on your hardware, sends push notifications when Claude needs more input or permission, and costs nothing.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/dtormoen/tsk"&gt;&lt;code&gt;TSK - AI Agent Task Manager and Sandbox&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/dtormoen"&gt;dtormoen&lt;/a&gt; &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;MIT&lt;br /&gt; A Rust CLI tool that lets you delegate development tasks to AI agents running in sandboxed Docker environments. Multiple agents work in parallel, returning git branches for human review.&lt;/p&gt; 
&lt;br /&gt; 
&lt;h2&gt;Statusline ğŸ“Š&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Statusline&lt;/strong&gt; configurations and customizations for Claude Code's status bar functionality&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;a href="https://github.com/sirmalloc/ccstatusline"&gt;&lt;code&gt;ccstatusline&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/sirmalloc"&gt;sirmalloc&lt;/a&gt; &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;MIT&lt;br /&gt; A highly customizable status line formatter for Claude Code CLI that displays model info, git branch, token usage, and other metrics in your terminal.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/Owloops/claude-powerline"&gt;&lt;code&gt;claude-powerline&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/Owloops"&gt;Owloops&lt;/a&gt; &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;MIT&lt;br /&gt; A vim-style powerline statusline for Claude Code with real-time usage tracking, git integration, custom themes, and more&lt;/p&gt; 
&lt;br /&gt; 
&lt;h2&gt;Hooks ğŸª&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Hooks&lt;/strong&gt; are a brand new API for Claude Code that allows users to activate commands and run scripts at different points in Claude's agentic lifecycle.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;[Experimental]&lt;/strong&gt; - The resources listed in this section have not been fully vetted and may not work as expected, given the bleeding-edge nature of Claude Code hooks. Nevertheless, I wished to include them at least as a source of inspiration and to explore this unknown terrain. YMMV!&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/dazuiba/CCNotify"&gt;&lt;code&gt;CC Notify&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/dazuiba"&gt;dazuiba&lt;/a&gt;&lt;br /&gt; CCNotify provides desktop notifications for Claude Code, alerting you to input needs or task completion, with one-click jumps back to VS Code and task duration display.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/GowayLee/cchooks"&gt;&lt;code&gt;cchooks&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/GowayLee"&gt;GowayLee&lt;/a&gt; &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;MIT&lt;br /&gt; A lightweight Python SDK with a clean API and good documentation; simplifies the process of writing hooks and integrating them into your codebase, providing a nice abstraction over the JSON configuration files.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/beyondcode/claude-hooks-sdk"&gt;&lt;code&gt;claude-code-hooks-sdk&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/beyondcode"&gt;beyondcode&lt;/a&gt; &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;MIT&lt;br /&gt; A Laravel-inspired PHP SDK for building Claude Code hook responses with a clean, fluent API. This SDK makes it easy to create structured JSON responses for Claude Code hooks using an expressive, chainable interface.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/johnlindquist/claude-hooks"&gt;&lt;code&gt;claude-hooks&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/johnlindquist"&gt;John Lindquist&lt;/a&gt; &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;MIT&lt;br /&gt; A TypeScript-based system for configuring and customizing Claude Code hooks with a powerful and flexible interface.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/Veraticus/nix-config/tree/main/home-manager/claude-code/hooks"&gt;&lt;code&gt;Linting, testing, and notifications (in go)&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/Veraticus"&gt;Josh Symonds&lt;/a&gt; &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;MIT&lt;br /&gt; Nice set of hooks for enforcing code quality (linting, testing, notifications), with a nice configuration setup as well.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/nizos/tdd-guard"&gt;&lt;code&gt;TDD Guard&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/nizos"&gt;Nizar Selander&lt;/a&gt; &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;MIT&lt;br /&gt; A hooks-driven system that monitors file operations in real-time and blocks changes that violate TDD principles.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/bartolli/claude-code-typescript-hooks"&gt;&lt;code&gt;TypeScript Quality Hooks&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/bartolli"&gt;bartolli&lt;/a&gt; &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;MIT&lt;br /&gt; Quality check hook for Node.js TypeScript projects with TypeScript compilation. ESLint auto-fixing, and Prettier formatting. Uses SHA256 config caching for &amp;lt;5ms validation performance during real-time editing.&lt;/p&gt; 
&lt;br /&gt; 
&lt;h2&gt;Slash-Commands ğŸ”ª&lt;/h2&gt; 
&lt;h3&gt;Version Control &amp;amp; Git&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://github.com/danielscholl/mvn-mcp-server/raw/main/.claude/commands/bug-fix.md"&gt;&lt;code&gt;/bug-fix&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/danielscholl"&gt;danielscholl&lt;/a&gt;&lt;br /&gt; Streamlines bug fixing by creating a GitHub issue first, then a feature branch for implementing and thoroughly testing the solution before merging.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/evmts/tevm-monorepo/raw/main/.claude/commands/commit.md"&gt;&lt;code&gt;/commit&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/evmts"&gt;evmts&lt;/a&gt; &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;MIT&lt;br /&gt; Creates git commits using conventional commit format with appropriate emojis, following project standards and creating descriptive messages that explain the purpose of changes.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/steadycursor/steadystart/raw/main/.claude/commands/2-commit-fast.md"&gt;&lt;code&gt;/commit-fast&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/steadycursor"&gt;steadycursor&lt;/a&gt;&lt;br /&gt; Automates git commit process by selecting the first suggested message, generating structured commits with consistent formatting while skipping manual confirmation and removing Claude co-Contributorship footer&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/toyamarinyon/giselle/raw/main/.claude/commands/create-pr.md"&gt;&lt;code&gt;/create-pr&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/toyamarinyon"&gt;toyamarinyon&lt;/a&gt; &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;Apache-2.0&lt;br /&gt; Streamlines pull request creation by handling the entire workflow: creating a new branch, committing changes, formatting modified files with Biome, and submitting the PR.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/liam-hq/liam/raw/main/.claude/commands/create-pull-request.md"&gt;&lt;code&gt;/create-pull-request&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/liam-hq"&gt;liam-hq&lt;/a&gt; &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;Apache-2.0&lt;br /&gt; Provides comprehensive PR creation guidance with GitHub CLI, enforcing title conventions, following template structure, and offering concrete command examples with best practices.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/evmts/tevm-monorepo/raw/main/.claude/commands/create-worktrees.md"&gt;&lt;code&gt;/create-worktrees&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/evmts"&gt;evmts&lt;/a&gt; &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;MIT&lt;br /&gt; Creates git worktrees for all open PRs or specific branches, handling branches with slashes, cleaning up stale worktrees, and supporting custom branch creation for development.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/jeremymailen/kotlinter-gradle/raw/master/.claude/commands/fix-github-issue.md"&gt;&lt;code&gt;/fix-github-issue&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/jeremymailen"&gt;jeremymailen&lt;/a&gt; &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;Apache-2.0&lt;br /&gt; Analyzes and fixes GitHub issues using a structured approach with GitHub CLI for issue details, implementing necessary code changes, running tests, and creating proper commit messages.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/metabase/metabase/raw/master/.claude/commands/fix-issue.md"&gt;&lt;code&gt;/fix-issue&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/metabase"&gt;metabase&lt;/a&gt; &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;NOASSERTION&lt;br /&gt; Addresses GitHub issues by taking issue number as parameter, analyzing context, implementing solution, and testing/validating the fix for proper integration.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/metabase/metabase/raw/master/.claude/commands/fix-pr.md"&gt;&lt;code&gt;/fix-pr&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/metabase"&gt;metabase&lt;/a&gt; &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;NOASSERTION&lt;br /&gt; Fetches and fixes unresolved PR comments by automatically retrieving feedback, addressing reviewer concerns, making targeted code improvements, and streamlining the review process.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/evmts/tevm-monorepo/raw/main/.claude/commands/husky.md"&gt;&lt;code&gt;/husky&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/evmts"&gt;evmts&lt;/a&gt; &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;MIT&lt;br /&gt; Sets up and manages Husky Git hooks by configuring pre-commit hooks, establishing commit message standards, integrating with linting tools, and ensuring code quality on commits.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/arkavo-org/opentdf-rs/raw/main/.claude/commands/pr-review.md"&gt;&lt;code&gt;/pr-review&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/arkavo-org"&gt;arkavo-org&lt;/a&gt; &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;MIT&lt;br /&gt; Reviews pull request changes to provide feedback, check for issues, and suggest improvements before merging into the main codebase.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/giselles-ai/giselle/raw/main/.claude/commands/update-branch-name.md"&gt;&lt;code&gt;/update-branch-name&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/giselles-ai"&gt;giselles-ai&lt;/a&gt; &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;Apache-2.0&lt;br /&gt; Updates branch names with proper prefixes and formats, enforcing naming conventions, supporting semantic prefixes, and managing remote branch updates.&lt;/p&gt; 
&lt;h3&gt;Code Analysis &amp;amp; Testing&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://github.com/rygwdn/slack-tools/raw/main/.claude/commands/check.md"&gt;&lt;code&gt;/check&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/rygwdn"&gt;rygwdn&lt;/a&gt;&lt;br /&gt; Performs comprehensive code quality and security checks, featuring static analysis integration, security vulnerability scanning, code style enforcement, and detailed reporting.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/Graphlet-AI/eridu/raw/main/.claude/commands/clean.md"&gt;&lt;code&gt;/clean&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/Graphlet-AI"&gt;Graphlet-AI&lt;/a&gt; &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;Apache-2.0&lt;br /&gt; Addresses code formatting and quality issues by fixing black formatting problems, organizing imports with isort, resolving flake8 linting issues, and correcting mypy type errors.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/kingler/n8n_agent/raw/main/.claude/commands/code_analysis.md"&gt;&lt;code&gt;/code_analysis&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/kingler"&gt;kingler&lt;/a&gt;&lt;br /&gt; Provides a menu of advanced code analysis commands for deep inspection, including knowledge graph generation, optimization suggestions, and quality evaluation.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/to4iki/ai-project-rules/raw/main/.claude/commands/optimize.md"&gt;&lt;code&gt;/optimize&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/to4iki"&gt;to4iki&lt;/a&gt; &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;MIT&lt;br /&gt; Analyzes code performance to identify bottlenecks, proposing concrete optimizations with implementation guidance for improved application performance.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/rzykov/metabase/raw/master/.claude/commands/repro-issue.md"&gt;&lt;code&gt;/repro-issue&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/rzykov"&gt;rzykov&lt;/a&gt; &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;NOASSERTION&lt;br /&gt; Creates reproducible test cases for GitHub issues, ensuring tests fail reliably and documenting clear reproduction steps for developers.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/zscott/pane/raw/main/.claude/commands/tdd.md"&gt;&lt;code&gt;/tdd&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/zscott"&gt;zscott&lt;/a&gt;&lt;br /&gt; Guides development using Test-Driven Development principles, enforcing Red-Green-Refactor discipline, integrating with git workflow, and managing PR creation.&lt;/p&gt; 
&lt;h3&gt;Context Loading &amp;amp; Priming&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://github.com/elizaOS/elizaos.github.io/raw/main/.claude/commands/context-prime.md"&gt;&lt;code&gt;/context-prime&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/elizaOS"&gt;elizaOS&lt;/a&gt; &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;MIT&lt;br /&gt; Primes Claude with comprehensive project understanding by loading repository structure, setting development context, establishing project goals, and defining collaboration parameters.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/okuvshynov/cubestat/raw/main/.claude/commands/initref.md"&gt;&lt;code&gt;/initref&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/okuvshynov"&gt;okuvshynov&lt;/a&gt; &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;MIT&lt;br /&gt; Initializes reference documentation structure with standard doc templates, API reference setup, documentation conventions, and placeholder content generation.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/ethpandaops/xatu-data/raw/master/.claude/commands/load-llms-txt.md"&gt;&lt;code&gt;/load-llms-txt&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/ethpandaops"&gt;ethpandaops&lt;/a&gt; &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;MIT&lt;br /&gt; Loads LLM configuration files to context, importing specific terminology, model configurations, and establishing baseline terminology for AI discussions.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/Mjvolk3/torchcell/raw/main/.claude/commands/load_coo_context.md"&gt;&lt;code&gt;/load_coo_context&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/Mjvolk3"&gt;Mjvolk3&lt;/a&gt;&lt;br /&gt; References specific files for sparse matrix operations, explains transform usage, compares with previous approaches, and sets data formatting context for development.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/Mjvolk3/torchcell/raw/main/.claude/commands/load_dango_pipeline.md"&gt;&lt;code&gt;/load_dango_pipeline&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/Mjvolk3"&gt;Mjvolk3&lt;/a&gt;&lt;br /&gt; Sets context for model training by referencing pipeline files, establishing working context, and preparing for pipeline work with relevant documentation.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/yzyydev/AI-Engineering-Structure/raw/main/.claude/commands/prime.md"&gt;&lt;code&gt;/prime&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/yzyydev"&gt;yzyydev&lt;/a&gt;&lt;br /&gt; Sets up initial project context by viewing directory structure and reading key files, creating standardized context with directory visualization and key documentation focus.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/ddisisto/si/raw/main/.claude/commands/rsi.md"&gt;&lt;code&gt;/rsi&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/ddisisto"&gt;ddisisto&lt;/a&gt;&lt;br /&gt; Reads all commands and key project files to optimize AI-assisted development by streamlining the process, loading command context, and setting up for better development workflow.&lt;/p&gt; 
&lt;h3&gt;Documentation &amp;amp; Changelogs&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://github.com/berrydev-ai/blockdoc-python/raw/main/.claude/commands/add-to-changelog.md"&gt;&lt;code&gt;/add-to-changelog&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/berrydev-ai"&gt;berrydev-ai&lt;/a&gt; &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;MIT&lt;br /&gt; Adds new entries to changelog files while maintaining format consistency, properly documenting changes, and following established project standards for version tracking.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/jerseycheese/Narraitor/tree/feature/issue-227-ai-suggestions/.claude/commands/analyze-issue.md"&gt;&lt;code&gt;/create-docs&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/jerseycheese"&gt;jerseycheese&lt;/a&gt; &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;MIT&lt;br /&gt; Analyzes code structure and purpose to create comprehensive documentation detailing inputs/outputs, behavior, user interaction flows, and edge cases with error handling.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/slunsford/coffee-analytics/raw/main/.claude/commands/docs.md"&gt;&lt;code&gt;/docs&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/slunsford"&gt;slunsford&lt;/a&gt;&lt;br /&gt; Generates comprehensive documentation that follows project structure, documenting APIs and usage patterns with consistent formatting for better user understanding.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/hackdays-io/toban-contribution-viewer/raw/main/.claude/commands/explain-issue-fix.md"&gt;&lt;code&gt;/explain-issue-fix&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/hackdays-io"&gt;hackdays-io&lt;/a&gt;&lt;br /&gt; Documents solution approaches for GitHub issues, explaining technical decisions, detailing challenges overcome, and providing implementation context for better understanding.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/Consiliency/Flutter-Structurizr/raw/main/.claude/commands/update-docs.md"&gt;&lt;code&gt;/update-docs&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/Consiliency"&gt;Consiliency&lt;/a&gt; &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;MIT&lt;br /&gt; Reviews current documentation status, updates implementation progress, reviews phase documents, and maintains documentation consistency across the project.&lt;/p&gt; 
&lt;h3&gt;CI / Deployment&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://github.com/kelp/webdown/raw/main/.claude/commands/release.md"&gt;&lt;code&gt;/release&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/kelp"&gt;kelp&lt;/a&gt; &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;MIT&lt;br /&gt; Manages software releases by updating changelogs, reviewing README changes, evaluating version increments, and documenting release changes for better version tracking.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/hackdays-io/toban-contribution-viewer/raw/main/.claude/commands/run-ci.md"&gt;&lt;code&gt;/run-ci&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/hackdays-io"&gt;hackdays-io&lt;/a&gt;&lt;br /&gt; Activates virtual environments, runs CI-compatible check scripts, iteratively fixes errors, and ensures all tests pass before completion.&lt;/p&gt; 
&lt;h3&gt;Project &amp;amp; Task Management&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://github.com/scopecraft/command/raw/main/.claude/commands/create-command.md"&gt;&lt;code&gt;/create-command&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/scopecraft"&gt;scopecraft&lt;/a&gt;&lt;br /&gt; Guides Claude through creating new custom commands with proper structure by analyzing requirements, templating commands by category, enforcing command standards, and creating supporting documentation.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/taddyorg/inkverse/raw/main/.claude/commands/create-jtbd.md"&gt;&lt;code&gt;/create-jtbd&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/taddyorg"&gt;taddyorg&lt;/a&gt; &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;AGPL-3.0&lt;br /&gt; Creates Jobs-to-be-Done frameworks that outline user needs with structured format, focusing on specific user problems and organizing by job categories for product development.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/taddyorg/inkverse/raw/main/.claude/commands/create-prd.md"&gt;&lt;code&gt;/create-prd&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/taddyorg"&gt;taddyorg&lt;/a&gt; &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;AGPL-3.0&lt;br /&gt; Generates comprehensive product requirement documents outlining detailed specifications, requirements, and features following standardized document structure and format.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/Wirasm/claudecode-utils/raw/main/.claude/commands/create-prp.md"&gt;&lt;code&gt;/create-prp&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/Wirasm"&gt;Wirasm&lt;/a&gt; &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;MIT&lt;br /&gt; Creates product requirement plans by reading PRP methodology, following template structure, creating comprehensive requirements, and structuring product definitions for development.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/disler/just-prompt/raw/main/.claude/commands/project_hello_w_name.md"&gt;&lt;code&gt;/project_hello_w_name&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/disler"&gt;disler&lt;/a&gt;&lt;br /&gt; Creates customizable greeting components with name input, demonstrating argument passing, component reusability, state management, and user input handling.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/chrisleyva/todo-slash-command/raw/main/todo.md"&gt;&lt;code&gt;/todo&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/chrisleyva"&gt;chrisleyva&lt;/a&gt; &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;MIT&lt;br /&gt; A convenient command to quickly manage project todo items without leaving the Claude Code interface, featuring due dates, sorting, task prioritization, and comprehensive todo list management.&lt;/p&gt; 
&lt;h3&gt;Miscellaneous&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://github.com/TuckerTucker/tkr-portfolio/raw/main/.claude/commands/five.md"&gt;&lt;code&gt;/five&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/TuckerTucker"&gt;TuckerTucker&lt;/a&gt;&lt;br /&gt; Applies the "five whys" methodology to perform root cause analysis, identify underlying issues, and create solution approaches for complex problems.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/Mjvolk3/torchcell/raw/main/.claude/commands/fixing_go_in_graph.md"&gt;&lt;code&gt;/fixing_go_in_graph&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/Mjvolk3"&gt;Mjvolk3&lt;/a&gt;&lt;br /&gt; Focuses on Gene Ontology annotation integration in graph databases, handling multiple data sources, addressing graph representation issues, and ensuring correct data incorporation.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/GaloyMoney/lana-bank/raw/main/.claude/commands/mermaid.md"&gt;&lt;code&gt;/mermaid&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/GaloyMoney"&gt;GaloyMoney&lt;/a&gt; &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;NOASSERTION&lt;br /&gt; Generates Mermaid diagrams from SQL schema files, creating entity relationship diagrams with table properties, validating diagram compilation, and ensuring complete entity coverage.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/Mjvolk3/torchcell/raw/main/.claude/commands/review_dcell_model.md"&gt;&lt;code&gt;/review_dcell_model&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/Mjvolk3"&gt;Mjvolk3&lt;/a&gt;&lt;br /&gt; Reviews old Dcell implementation files, comparing with newer Dango model, noting changes over time, and analyzing refactoring approaches for better code organization.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/zuplo/docs/raw/main/.claude/commands/use-stepper.md"&gt;&lt;code&gt;/use-stepper&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/zuplo"&gt;zuplo&lt;/a&gt;&lt;br /&gt; Reformats documentation to use React Stepper component, transforming heading formats, applying proper indentation, and maintaining markdown compatibility with admonition formatting.&lt;/p&gt; 
&lt;br /&gt; 
&lt;h2&gt;CLAUDE.md Files ğŸ“‚&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;&lt;code&gt;CLAUDE.md&lt;/code&gt; files&lt;/strong&gt; are files that contain important guidelines and context-specfic information or instructions that help Claude Code to better understand your project and your coding standards&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Language-Specific&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://github.com/didalgolab/ai-intellij-plugin/raw/main/CLAUDE.md"&gt;&lt;code&gt;AI IntelliJ Plugin&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/didalgolab"&gt;didalgolab&lt;/a&gt; &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;Apache-2.0&lt;br /&gt; Provides comprehensive Gradle commands for IntelliJ plugin development with platform-specific coding patterns, detailed package structure guidelines, and clear internationalization standards.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/alexei-led/aws-mcp-server/raw/main/CLAUDE.md"&gt;&lt;code&gt;AWS MCP Server&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/alexei-led"&gt;alexei-led&lt;/a&gt; &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;MIT&lt;br /&gt; Features multiple Python environment setup options with detailed code style guidelines, comprehensive error handling recommendations, and security considerations for AWS CLI interactions.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/touchlab/DroidconKotlin/raw/main/CLAUDE.md"&gt;&lt;code&gt;DroidconKotlin&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/touchlab"&gt;touchlab&lt;/a&gt; &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;Apache-2.0&lt;br /&gt; Delivers comprehensive Gradle commands for cross-platform Kotlin Multiplatform development with clear module structure and practical guidance for dependency injection.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/expectedparrot/edsl/raw/main/CLAUDE.md"&gt;&lt;code&gt;EDSL&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/expectedparrot"&gt;expectedparrot&lt;/a&gt; &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;MIT&lt;br /&gt; Offers detailed build and test commands with strict code style enforcement, comprehensive testing requirements, and standardized development workflow using Black and mypy.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/giselles-ai/giselle/raw/main/CLAUDE.md"&gt;&lt;code&gt;Giselle&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/giselles-ai"&gt;giselles-ai&lt;/a&gt; &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;Apache-2.0&lt;br /&gt; Provides detailed build and test commands using pnpm and Vitest with strict code formatting requirements and comprehensive naming conventions for code consistency.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/hashintel/hash/raw/main/CLAUDE.md"&gt;&lt;code&gt;HASH&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/hashintel"&gt;hashintel&lt;/a&gt; &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;NOASSERTION&lt;br /&gt; Features comprehensive repository structure breakdown with strong emphasis on coding standards, detailed Rust documentation guidelines, and systematic PR review process.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/inkline/inkline/raw/main/CLAUDE.md"&gt;&lt;code&gt;Inkline&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/inkline"&gt;inkline&lt;/a&gt; &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;NOASSERTION&lt;br /&gt; Structures development workflow using pnpm with emphasis on TypeScript and Vue 3 Composition API, detailed component creation process, and comprehensive testing recommendations.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/mattgodbolt/jsbeeb/raw/main/CLAUDE.md"&gt;&lt;code&gt;JSBeeb&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/mattgodbolt"&gt;mattgodbolt&lt;/a&gt; &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;GPL-3.0&lt;br /&gt; Provides development guide for JavaScript BBC Micro emulator with build and testing instructions, architecture documentation, and debugging workflows.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/LamoomAI/lamoom-python/raw/main/CLAUDE.md"&gt;&lt;code&gt;Lamoom Python&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/LamoomAI"&gt;LamoomAI&lt;/a&gt; &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;Apache-2.0&lt;br /&gt; Serves as reference for production prompt engineering library with load balancing of AI Models, API documentation, and usage patterns with examples.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/langchain-ai/langgraphjs/raw/main/CLAUDE.md"&gt;&lt;code&gt;LangGraphJS&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/langchain-ai"&gt;langchain-ai&lt;/a&gt; &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;MIT&lt;br /&gt; Offers comprehensive build and test commands with detailed TypeScript style guidelines, layered library architecture, and monorepo structure using yarn workspaces.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/metabase/metabase/raw/master/CLAUDE.md"&gt;&lt;code&gt;Metabase&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/metabase"&gt;metabase&lt;/a&gt; &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;NOASSERTION&lt;br /&gt; Details workflow for REPL-driven development in Clojure/ClojureScript with emphasis on incremental development, testing, and step-by-step approach for feature implementation.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/sgcarstrends/backend/raw/main/CLAUDE.md"&gt;&lt;code&gt;SG Cars Trends Backend&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/sgcarstrends"&gt;sgcarstrends&lt;/a&gt;&lt;br /&gt; Provides comprehensive structure for TypeScript monorepo projects with detailed commands for development, testing, deployment, and AWS/Cloudflare integration.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/spylang/spy/raw/main/CLAUDE.md"&gt;&lt;code&gt;SPy&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/spylang"&gt;spylang&lt;/a&gt; &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;MIT&lt;br /&gt; Enforces strict coding conventions with comprehensive testing guidelines, multiple code compilation options, and backend-specific test decorators for targeted filtering.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/KarpelesLab/tpl/raw/master/CLAUDE.md"&gt;&lt;code&gt;TPL&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/KarpelesLab"&gt;KarpelesLab&lt;/a&gt; &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;MIT&lt;br /&gt; Details Go project conventions with comprehensive error handling recommendations, table-driven testing approach guidelines, and modernization suggestions for latest Go features.&lt;/p&gt; 
&lt;h3&gt;Domain-Specific&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://github.com/Layr-Labs/avs-vibe-developer-guide/raw/master/CLAUDE.md"&gt;&lt;code&gt;AVS Vibe Developer Guide&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/Layr-Labs"&gt;Layr-Labs&lt;/a&gt; &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;MIT&lt;br /&gt; Structures AI-assisted EigenLayer AVS development workflow with consistent naming conventions for prompt files and established terminology standards for blockchain concepts.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/CommE2E/comm/raw/master/CLAUDE.md"&gt;&lt;code&gt;Comm&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/CommE2E"&gt;CommE2E&lt;/a&gt; &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;BSD-3-Clause&lt;br /&gt; Serves as a development reference for E2E-encrypted messaging applications with code organization architecture, security implementation details, and testing procedures.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/badass-courses/course-builder/raw/main/CLAUDE.md"&gt;&lt;code&gt;Course Builder&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/badass-courses"&gt;badass-courses&lt;/a&gt; &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;MIT&lt;br /&gt; Enables real-time multiplayer capabilities for collaborative course creation with diverse tech stack integration and monorepo architecture using Turborepo.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/eastlondoner/cursor-tools/raw/main/CLAUDE.md"&gt;&lt;code&gt;Cursor Tools&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/eastlondoner"&gt;eastlondoner&lt;/a&gt; &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;MIT&lt;br /&gt; Creates a versatile AI command interface supporting multiple providers and models with flexible command options and browser automation through "Stagehand" feature.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/soramimi/Guitar/raw/master/CLAUDE.md"&gt;&lt;code&gt;Guitar&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/soramimi"&gt;soramimi&lt;/a&gt; &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;GPL-2.0&lt;br /&gt; Serves as development guide for Guitar Git GUI Client with build commands for various platforms, code style guidelines for contributing, and project structure explanation.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/Fimeg/NetworkChronicles/raw/legacy-v1/CLAUDE.md"&gt;&lt;code&gt;Network Chronicles&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/Fimeg"&gt;Fimeg&lt;/a&gt; &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;MIT&lt;br /&gt; Presents detailed implementation plan for AI-driven game characters with technical specifications for LLM integration, character guidelines, and service discovery mechanics.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/different-ai/note-companion/raw/master/CLAUDE.md"&gt;&lt;code&gt;Note Companion&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/different-ai"&gt;different-ai&lt;/a&gt; &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;MIT&lt;br /&gt; Provides detailed styling isolation techniques for Obsidian plugins using Tailwind with custom prefix to prevent style conflicts and practical troubleshooting steps.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/ParetoSecurity/pareto-mac/raw/main/CLAUDE.md"&gt;&lt;code&gt;Pareto Mac&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/ParetoSecurity"&gt;ParetoSecurity&lt;/a&gt; &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;GPL-3.0&lt;br /&gt; Serves as development guide for Mac security audit tool with build instructions, contribution guidelines, testing procedures, and workflow documentation.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/steadycursor/steadystart/raw/main/CLAUDE.md"&gt;&lt;code&gt;SteadyStart&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/steadycursor"&gt;steadycursor&lt;/a&gt;&lt;br /&gt; Clear and direct instructives about style, permissions, Claude's "role", communications, and documentation of Claude Code sessions for other team members to stay abreast.&lt;/p&gt; 
&lt;h3&gt;Project Scaffolding &amp;amp; MCP&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://github.com/basicmachines-co/basic-memory/raw/main/CLAUDE.md"&gt;&lt;code&gt;Basic Memory&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/basicmachines-co"&gt;basicmachines-co&lt;/a&gt; &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;AGPL-3.0&lt;br /&gt; Presents an innovative AI-human collaboration framework with Model Context Protocol for bidirectional LLM-markdown communication and flexible knowledge structure for complex projects.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/grahama1970/claude-code-mcp-enhanced/raw/main/CLAUDE.md"&gt;&lt;code&gt;claude-code-mcp-enhanced&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/grahama1970"&gt;grahama1970&lt;/a&gt; &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;MIT&lt;br /&gt; Provides detailed and emphatic instructions for Claude to follow as a coding agent, with testing guidance, code examples, and compliance checks.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/Family-IT-Guy/perplexity-mcp/raw/main/CLAUDE.md"&gt;&lt;code&gt;Perplexity MCP&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/Family-IT-Guy"&gt;Family-IT-Guy&lt;/a&gt; &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;ISC&lt;br /&gt; Offers clear step-by-step installation instructions with multiple configuration options, detailed troubleshooting guidance, and concise architecture overview of the MCP protocol.&lt;/p&gt; 
&lt;br /&gt; 
&lt;h2&gt;Official Documentation ğŸ›ï¸&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Links to some of Anthropic's terrific documentation and resources regarding Claude Code&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;!--lint disable double-link--&gt; 
&lt;p&gt;&lt;a href="https://docs.anthropic.com/en/docs/claude-code"&gt;&lt;code&gt;Anthropic Documentation&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/anthropics"&gt;Anthropic&lt;/a&gt; &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;Â©&lt;br /&gt; The official documentation for Claude Code, including installation instructions, usage guidelines, API references, tutorials, examples, loads of information that I won't list individually. Like Claude Code, the documentation is frequently updated.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/anthropics/anthropic-quickstarts/raw/main/CLAUDE.md"&gt;&lt;code&gt;Anthropic Quickstarts&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/anthropics"&gt;Anthropic&lt;/a&gt; &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;MIT&lt;br /&gt; Offers comprehensive development guides for three distinct AI-powered demo projects with standardized workflows, strict code style guidelines, and containerization instructions.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/anthropics/claude-code-action/tree/main/examples"&gt;&lt;code&gt;Claude Code GitHub Actions&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/anthropics"&gt;Anthropic&lt;/a&gt; &amp;nbsp;&amp;nbsp;âš–ï¸&amp;nbsp;&amp;nbsp;MIT&lt;br /&gt; Official GitHub Actions integration for Claude Code with examples and documentation for automating AI-powered workflows in CI/CD pipelines.&lt;/p&gt; 
&lt;h2&gt;Contributing ğŸŒ»&lt;/h2&gt; 
&lt;h3&gt;ğŸš€ &lt;strong&gt;&lt;a href="https://github.com/hesreallyhim/awesome-claude-code/issues/new?template=submit-resource.yml"&gt;Submit a new resource here!&lt;/a&gt;&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;It's easy! Just click the link above and fill out the form. No Git knowledge required - our automated system handles everything for you.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;We especially welcome:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Proven, effective resources that follow best practices and may even be in use in production&lt;/li&gt; 
 &lt;li&gt;Innovative, creative, or experimental workflows that push the boundaries of Claude Code's capabilities&lt;/li&gt; 
 &lt;li&gt;Additional libraries and tooling that are built on top of Claude Code&lt;/li&gt; 
 &lt;li&gt;Applications of Claude Code outside of the traditional "coding assistant" context (CI/CD, testing, documentation, dev-ops, etc.)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; for the complete submission guide and review process.&lt;/p&gt; 
&lt;p&gt;For suggestions about the repository itself, please &lt;a href="https://github.com/hesreallyhim/awesome-claude-code/issues/new"&gt;open a general issue&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;This project is released with a &lt;a href="https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/code-of-conduct.md"&gt;Contributor Code of Conduct&lt;/a&gt;. By participating, you agree to abide by its terms.&lt;/p&gt; 
&lt;h3&gt;A note about licenses&lt;/h3&gt; 
&lt;p&gt;Because simply listing a hyperlink does not qualify as redistribution, the license of the original source is not relevant to its inclusion. However, for posterity and convenience, we do host copies of all resources whose license permits it. Therefore, please include information about the resource's license. Additionally, take note: &lt;em&gt;if you do not include a LICENSE in your GitHub repo, then by default it is fully copyrighted and redistribution is not allowed&lt;/em&gt;. So, if you are intending to make an open source project, it's critical to pick from one of the many available open source licenses. This is just a reminder that without a LICENSE, your project is not open source (it's merely source-code-available) - it may of course still be included on this list, but this notice is to inform readers about the default rules regarding GitHub and LICENSE files. See &lt;a href="https://docs.github.com/en/repositories/managing-your-repositorys-settings-and-features/customizing-your-repository/licensing-a-repository"&gt;here&lt;/a&gt; for more details.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>gpustack/gpustack</title>
      <link>https://github.com/gpustack/gpustack</link>
      <description>&lt;p&gt;Simple, scalable AI model deployment on GPU clusters&lt;/p&gt;&lt;hr&gt;&lt;br /&gt; 
&lt;p align="center"&gt; &lt;img alt="GPUStack" src="https://raw.githubusercontent.com/gpustack/gpustack/main/docs/assets/gpustack-logo.png" width="300px" /&gt; &lt;/p&gt; 
&lt;br /&gt; 
&lt;p align="center"&gt; &lt;a href="https://docs.gpustack.ai" target="_blank"&gt; &lt;img alt="Documentation" src="https://img.shields.io/badge/Docs-GPUStack-blue?logo=readthedocs&amp;amp;logoColor=white" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/gpustack/gpustack/main/LICENSE" target="_blank"&gt; &lt;img alt="License" src="https://img.shields.io/github/license/gpustack/gpustack?logo=github&amp;amp;logoColor=white&amp;amp;label=License&amp;amp;color=blue" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/gpustack/gpustack/main/docs/assets/wechat-group-qrcode.jpg" target="_blank"&gt; &lt;img alt="WeChat" src="https://img.shields.io/badge/å¾®ä¿¡ç¾¤-GPUStack-blue?logo=wechat&amp;amp;logoColor=white" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/VXYJzuaqwD" target="_blank"&gt; &lt;img alt="Discord" src="https://img.shields.io/badge/Discord-GPUStack-blue?logo=discord&amp;amp;logoColor=white" /&gt;&lt;/a&gt; &lt;a href="https://twitter.com/intent/follow?screen_name=gpustack_ai" target="_blank"&gt; &lt;img alt="Follow on X(Twitter)" src="https://img.shields.io/twitter/follow/gpustack_ai?logo=X" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;br /&gt; 
&lt;p align="center"&gt; &lt;a href="https://raw.githubusercontent.com/gpustack/gpustack/main/README.md"&gt;English&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/gpustack/gpustack/main/README_CN.md"&gt;ç®€ä½“ä¸­æ–‡&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/gpustack/gpustack/main/README_JP.md"&gt;æ—¥æœ¬èª&lt;/a&gt; &lt;/p&gt; 
&lt;br /&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/gpustack/gpustack/main/docs/assets/gpustack-demo.gif" alt="demo" /&gt;&lt;/p&gt; 
&lt;p&gt;GPUStack is an open-source GPU cluster manager for running AI models.&lt;/p&gt; 
&lt;h3&gt;Key Features&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Broad GPU Compatibility:&lt;/strong&gt; Seamlessly supports GPUs from various vendors across Apple Macs, Windows PCs, and Linux servers.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Extensive Model Support:&lt;/strong&gt; Supports a wide range of models including LLMs, VLMs, image models, audio models, embedding models, and rerank models.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Flexible Inference Backends:&lt;/strong&gt; Flexibly integrates with multiple inference backends including vLLM, Ascend MindIE, llama-box (llama.cpp &amp;amp; stable-diffusion.cpp) and vox-box.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Multi-Version Backend Support:&lt;/strong&gt; Run multiple versions of inference backends concurrently to meet the diverse runtime requirements of different models.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Distributed Inference:&lt;/strong&gt; Supports single-node and multi-node multi-GPU inference, including heterogeneous GPUs across vendors and runtime environments.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Scalable GPU Architecture:&lt;/strong&gt; Easily scale up by adding more GPUs or nodes to your infrastructure.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Robust Model Stability:&lt;/strong&gt; Ensures high availability with automatic failure recovery, multi-instance redundancy, and load balancing for inference requests.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Intelligent Deployment Evaluation:&lt;/strong&gt; Automatically assess model resource requirements, backend and architecture compatibility, OS compatibility, and other deployment-related factors.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Automated Scheduling:&lt;/strong&gt; Dynamically allocate models based on available resources.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Lightweight Python Package:&lt;/strong&gt; Minimal dependencies and low operational overhead.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;OpenAI-Compatible APIs:&lt;/strong&gt; Fully compatible with OpenAIâ€™s API specifications for seamless integration.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;User &amp;amp; API Key Management:&lt;/strong&gt; Simplified management of users and API keys.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Real-Time GPU Monitoring:&lt;/strong&gt; Track GPU performance and utilization in real time.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Token and Rate Metrics:&lt;/strong&gt; Monitor token usage and API request rates.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;h3&gt;Linux&lt;/h3&gt; 
&lt;p&gt;If you are using NVIDIA GPUs, ensure &lt;a href="https://docs.docker.com/engine/install/"&gt;Docker&lt;/a&gt; and &lt;a href="https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html"&gt;NVIDIA Container Toolkit&lt;/a&gt; are installed on your system. Then, run the following command to start the GPUStack server.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run -d --name gpustack \
      --restart=unless-stopped \
      --gpus all \
      --network=host \
      --ipc=host \
      -v gpustack-data:/var/lib/gpustack \
      gpustack/gpustack
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For more details on the installation or other GPU hardware platforms, please refer to the &lt;a href="https://raw.githubusercontent.com/gpustack/gpustack/main/docs/installation/installation-requirements.md"&gt;Installation Documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;After the server starts, run the following command to get the default admin password:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker exec gpustack cat /var/lib/gpustack/initial_admin_password
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Open your browser and navigate to &lt;code&gt;http://your_host_ip&lt;/code&gt; to access the GPUStack UI. Use the default username &lt;code&gt;admin&lt;/code&gt; and the password you retrieved above to log in.&lt;/p&gt; 
&lt;h3&gt;macOS &amp;amp; Windows&lt;/h3&gt; 
&lt;p&gt;A desktop installer is available for macOS and Windows â€” see the &lt;a href="https://docs.gpustack.ai/latest/installation/desktop-installer/"&gt;documentation&lt;/a&gt; for installation details.&lt;/p&gt; 
&lt;h2&gt;Deploy a Model&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Navigate to the &lt;code&gt;Catalog&lt;/code&gt; page in the GPUStack UI.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Select the &lt;code&gt;Qwen3&lt;/code&gt; model from the list of available models.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;After the deployment compatibility checks pass, click the &lt;code&gt;Save&lt;/code&gt; button to deploy the model.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/gpustack/gpustack/main/docs/assets/quick-start/quick-start-qwen3.png" alt="deploy qwen3 from catalog" /&gt;&lt;/p&gt; 
&lt;ol start="4"&gt; 
 &lt;li&gt;GPUStack will start downloading the model files and deploying the model. When the deployment status shows &lt;code&gt;Running&lt;/code&gt;, the model has been deployed successfully.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/gpustack/gpustack/main/docs/assets/quick-start/model-running.png" alt="model is running" /&gt;&lt;/p&gt; 
&lt;ol start="5"&gt; 
 &lt;li&gt;Click &lt;code&gt;Playground - Chat&lt;/code&gt; in the navigation menu, check that the model &lt;code&gt;qwen3&lt;/code&gt; is selected from the top-right &lt;code&gt;Model&lt;/code&gt; dropdown. Now you can chat with the model in the UI playground.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/gpustack/gpustack/main/docs/assets/quick-start/quick-chat.png" alt="quick chat" /&gt;&lt;/p&gt; 
&lt;h2&gt;Use the model via API&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Hover over the user avatar and navigate to the &lt;code&gt;API Keys&lt;/code&gt; page, then click the &lt;code&gt;New API Key&lt;/code&gt; button.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Fill in the &lt;code&gt;Name&lt;/code&gt; and click the &lt;code&gt;Save&lt;/code&gt; button.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Copy the generated API key and save it somewhere safe. Please note that you can only see it once on creation.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;You can now use the API key to access the OpenAI-compatible API endpoints provided by GPUStack. For example, use curl as the following:&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Replace `your_api_key` and `your_gpustack_server_url`
# with your actual API key and GPUStack server URL.
export GPUSTACK_API_KEY=your_api_key
curl http://your_gpustack_server_url/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $GPUSTACK_API_KEY" \
  -d '{
    "model": "qwen3",
    "messages": [
      {
        "role": "system",
        "content": "You are a helpful assistant."
      },
      {
        "role": "user",
        "content": "Tell me a joke."
      }
    ],
    "stream": true
  }'
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Supported Platforms&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Linux&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; macOS&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Windows&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Supported Accelerators&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; NVIDIA CUDA (&lt;a href="https://developer.nvidia.com/cuda-gpus"&gt;Compute Capability&lt;/a&gt; 6.0 and above)&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Apple Metal (M-series chips)&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; AMD ROCm&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Ascend CANN&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Hygon DTK&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Moore Threads MUSA&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Iluvatar Corex&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Cambricon MLU&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Supported Models&lt;/h2&gt; 
&lt;p&gt;GPUStack uses &lt;a href="https://github.com/vllm-project/vllm"&gt;vLLM&lt;/a&gt;, &lt;a href="https://www.hiascend.com/en/software/mindie"&gt;Ascend MindIE&lt;/a&gt;, &lt;a href="https://github.com/gpustack/llama-box"&gt;llama-box&lt;/a&gt; (bundled &lt;a href="https://github.com/ggml-org/llama.cpp"&gt;llama.cpp&lt;/a&gt; and &lt;a href="https://github.com/leejet/stable-diffusion.cpp"&gt;stable-diffusion.cpp&lt;/a&gt; server) and &lt;a href="https://github.com/gpustack/vox-box"&gt;vox-box&lt;/a&gt; as the backends and supports a wide range of models. Models from the following sources are supported:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://huggingface.co/"&gt;Hugging Face&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://modelscope.cn/"&gt;ModelScope&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Local File Path&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Example Models&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;&lt;strong&gt;Category&lt;/strong&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;strong&gt;Models&lt;/strong&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Large Language Models(LLMs)&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/models?search=Qwen/Qwen"&gt;Qwen&lt;/a&gt;, &lt;a href="https://huggingface.co/meta-llama"&gt;LLaMA&lt;/a&gt;, &lt;a href="https://huggingface.co/mistralai"&gt;Mistral&lt;/a&gt;, &lt;a href="https://huggingface.co/models?search=deepseek-ai/deepseek"&gt;DeepSeek&lt;/a&gt;, &lt;a href="https://huggingface.co/models?search=microsoft/phi"&gt;Phi&lt;/a&gt;, &lt;a href="https://huggingface.co/models?search=Google/gemma"&gt;Gemma&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Vision Language Models(VLMs)&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/models?pipeline_tag=image-text-to-text&amp;amp;search=llama3.2"&gt;Llama3.2-Vision&lt;/a&gt;, &lt;a href="https://huggingface.co/models?search=pixtral"&gt;Pixtral&lt;/a&gt; , &lt;a href="https://huggingface.co/models?search=Qwen/Qwen2.5-VL"&gt;Qwen2.5-VL&lt;/a&gt;, &lt;a href="https://huggingface.co/models?search=llava"&gt;LLaVA&lt;/a&gt;, &lt;a href="https://huggingface.co/models?search=internvl3"&gt;InternVL3&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Diffusion Models&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/models?search=gpustack/stable-diffusion"&gt;Stable Diffusion&lt;/a&gt;, &lt;a href="https://huggingface.co/models?search=gpustack/flux"&gt;FLUX&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Embedding Models&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/gpustack/bge-m3-GGUF"&gt;BGE&lt;/a&gt;, &lt;a href="https://huggingface.co/gpustack/bce-embedding-base_v1-GGUF"&gt;BCE&lt;/a&gt;, &lt;a href="https://huggingface.co/models?search=gpustack/jina-embeddings"&gt;Jina&lt;/a&gt;, &lt;a href="https://huggingface.co/models?search=qwen/qwen3-embedding"&gt;Qwen3-Embedding&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Reranker Models&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/gpustack/bge-reranker-v2-m3-GGUF"&gt;BGE&lt;/a&gt;, &lt;a href="https://huggingface.co/gpustack/bce-reranker-base_v1-GGUF"&gt;BCE&lt;/a&gt;, &lt;a href="https://huggingface.co/models?search=gpustack/jina-reranker"&gt;Jina&lt;/a&gt;, &lt;a href="https://huggingface.co/models?search=qwen/qwen3-reranker"&gt;Qwen3-Reranker&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Audio Models&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/models?search=Systran/faster"&gt;Whisper&lt;/a&gt; (Speech-to-Text), &lt;a href="https://huggingface.co/models?search=FunAudioLLM/CosyVoice"&gt;CosyVoice&lt;/a&gt; (Text-to-Speech)&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;For full list of supported models, please refer to the supported models section in the &lt;a href="https://docs.gpustack.ai/latest/user-guide/inference-backends/"&gt;inference backends&lt;/a&gt; documentation.&lt;/p&gt; 
&lt;h2&gt;OpenAI-Compatible APIs&lt;/h2&gt; 
&lt;p&gt;GPUStack serves the following OpenAI compatible APIs under the &lt;code&gt;/v1-openai&lt;/code&gt; path:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://platform.openai.com/docs/api-reference/models/list"&gt;List Models&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://platform.openai.com/docs/api-reference/completions/create"&gt;Create Completion&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://platform.openai.com/docs/api-reference/chat/create"&gt;Create Chat Completion&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://platform.openai.com/docs/api-reference/embeddings/create"&gt;Create Embeddings&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://platform.openai.com/docs/api-reference/images/create"&gt;Create Image&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://platform.openai.com/docs/api-reference/images/createEdit"&gt;Create Image Edit&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://platform.openai.com/docs/api-reference/audio/createSpeech"&gt;Create Speech&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://platform.openai.com/docs/api-reference/audio/createTranscription"&gt;Create Transcription&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For example, you can use the official &lt;a href="https://github.com/openai/openai-python"&gt;OpenAI Python API library&lt;/a&gt; to consume the APIs:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from openai import OpenAI
client = OpenAI(base_url="http://your_gpustack_server_url/v1-openai", api_key="your_api_key")

completion = client.chat.completions.create(
  model="llama3.2",
  messages=[
    {"role": "system", "content": "You are a helpful assistant."},
    {"role": "user", "content": "Hello!"}
  ]
)

print(completion.choices[0].message)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;GPUStack users can generate their own API keys in the UI.&lt;/p&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;Please see the &lt;a href="https://docs.gpustack.ai"&gt;official docs site&lt;/a&gt; for complete documentation.&lt;/p&gt; 
&lt;h2&gt;Build&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Install Python (version 3.10 to 3.12).&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Run &lt;code&gt;make build&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;You can find the built wheel package in &lt;code&gt;dist&lt;/code&gt; directory.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Please read the &lt;a href="https://raw.githubusercontent.com/gpustack/gpustack/main/docs/contributing.md"&gt;Contributing Guide&lt;/a&gt; if you're interested in contributing to GPUStack.&lt;/p&gt; 
&lt;h2&gt;Join Community&lt;/h2&gt; 
&lt;p&gt;Any issues or have suggestions, feel free to join our &lt;a href="https://discord.gg/VXYJzuaqwD"&gt;Community&lt;/a&gt; for support.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Copyright (c) 2024 The GPUStack authors&lt;/p&gt; 
&lt;p&gt;Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License. You may obtain a copy of the License at &lt;a href="https://raw.githubusercontent.com/gpustack/gpustack/main/LICENSE"&gt;LICENSE&lt;/a&gt; file for details.&lt;/p&gt; 
&lt;p&gt;Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>OpenBB-finance/OpenBB</title>
      <link>https://github.com/OpenBB-finance/OpenBB</link>
      <description>&lt;p&gt;Financial data platform for analysts, quants and AI agents.&lt;/p&gt;&lt;hr&gt;&lt;br /&gt; 
&lt;img src="https://github.com/OpenBB-finance/OpenBB/raw/develop/images/platform-light.svg?raw=true#gh-light-mode-only" alt="OpenBB Platform logo" width="600" /&gt; 
&lt;img src="https://github.com/OpenBB-finance/OpenBB/raw/develop/images/platform-dark.svg?raw=true#gh-dark-mode-only" alt="OpenBB Platform logo" width="600" /&gt; 
&lt;br /&gt; 
&lt;br /&gt; 
&lt;p&gt;&lt;a href="https://x.com/openbb_finance"&gt;&lt;img src="https://img.shields.io/twitter/url/https/twitter.com/openbb_finance.svg?style=social&amp;amp;label=Follow%20%40openbb_finance" alt="Twitter" /&gt;&lt;/a&gt; &lt;a href="https://discord.com/invite/xPHTuHCmuV"&gt;&lt;img src="https://img.shields.io/discord/831165782750789672" alt="Discord Shield" /&gt;&lt;/a&gt; &lt;a href="https://vscode.dev/redirect?url=vscode://ms-vscode-remote.remote-containers/cloneInVolume?url=https://github.com/OpenBB-finance/OpenBB"&gt;&lt;img src="https://img.shields.io/static/v1?label=Dev%20Containers&amp;amp;message=Open&amp;amp;color=blue&amp;amp;logo=visualstudiocode" alt="Open in Dev Containers" /&gt;&lt;/a&gt; &lt;a href="https://codespaces.new/OpenBB-finance/OpenBB"&gt; &lt;img src="https://github.com/codespaces/badge.svg?sanitize=true" height="20" /&gt; &lt;/a&gt; &lt;a target="_blank" href="https://colab.research.google.com/github/OpenBB-finance/OpenBB/blob/develop/examples/googleColab.ipynb"&gt; &lt;img src="https://colab.research.google.com/assets/colab-badge.svg?sanitize=true" alt="Open In Colab" /&gt; &lt;/a&gt; &lt;a href="https://pypi.org/project/openbb/"&gt;&lt;img src="https://img.shields.io/pypi/v/openbb?color=blue&amp;amp;label=PyPI%20Package" alt="PyPI" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;The first financial Platform that is open source.&lt;/p&gt; 
&lt;p&gt;The OpenBB Platform offers access to equity, options, crypto, forex, macro economy, fixed income, and more while also offering a broad range of extensions to enhance the user experience according to their needs.&lt;/p&gt; 
&lt;p&gt;Get started with: &lt;code&gt;pip install openbb&lt;/code&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from openbb import obb
output = obb.equity.price.historical("AAPL")
df = output.to_dataframe()
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can sign up to the &lt;a href="https://my.openbb.co/login"&gt;OpenBB Hub&lt;/a&gt; to get the most out of the OpenBB ecosystem.&lt;/p&gt; 
&lt;p&gt;Data integrations available can be found here: &lt;a href="https://docs.openbb.co/platform/reference"&gt;https://docs.openbb.co/platform/reference&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;OpenBB Workspace&lt;/h2&gt; 
&lt;p&gt;While the OpenBB Platform is all about an integration to dozens of different data vendors, the interface is either Python or a CLI.&lt;/p&gt; 
&lt;p&gt;If you want an enterprise UI to visualize this datasets and use AI agents on top, you can find OpenBB Workspace at &lt;a href="https://pro.openbb.co"&gt;https://pro.openbb.co&lt;/a&gt;.&lt;/p&gt; 
&lt;a href="https://pro.openbb.co"&gt; 
 &lt;div align="center"&gt; 
  &lt;img src="https://openbb-cms.directus.app/assets/f69b6aaf-0821-4bc8-a43c-715e03a924ef.png" alt="Logo" width="1000" /&gt; 
 &lt;/div&gt; &lt;/a&gt; 
&lt;p&gt;Data integration:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;You can learn more about adding data to the OpenBB workspace from the &lt;a href="https://docs.openbb.co/workspace"&gt;docs&lt;/a&gt; or &lt;a href="https://github.com/OpenBB-finance/backends-for-openbb"&gt;this open source repository&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;AI Agents integration:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;You can learn more about adding AI agents to the OpenBB workspace from &lt;a href="https://github.com/OpenBB-finance/agents-for-openbb"&gt;this open source repository&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Integrating OpenBB Platform to the OpenBB Workspace&lt;/h3&gt; 
&lt;p&gt;Connect this library to the OpenBB Workspace with a few simple commands, in a Python (3.9.21 - 3.12) environment.&lt;/p&gt; 
&lt;h4&gt;Run OpenBB Platform backend&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Install the packages.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;pip install "openbb[all]"
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;Start the API server over localhost.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;openbb-api
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This will launch a FastAPI server, via Uvicorn, at &lt;code&gt;127.0.0.1:6900&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;You can check that it works by going to &lt;a href="http://127.0.0.1:6900"&gt;http://127.0.0.1:6900&lt;/a&gt;.&lt;/p&gt; 
&lt;h4&gt;Integrate OpenBB Platform backend to OpenBB Workspace&lt;/h4&gt; 
&lt;p&gt;Sign-in to the &lt;a href="https://pro.openbb.co/"&gt;OpenBB Workspace&lt;/a&gt;, and follow the following steps:&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/75cffb4a-5e95-470a-b9d0-6ffd4067e069" alt="CleanShot 2025-05-17 at 09 51 56@2x" /&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Go to the "Apps" tab&lt;/li&gt; 
 &lt;li&gt;Click on "Connect backend"&lt;/li&gt; 
 &lt;li&gt;Fill in the form with: Name: OpenBB Platform URL: &lt;a href="http://127.0.0.1:6900"&gt;http://127.0.0.1:6900&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Click on "Test". You should get a "Test successful" with the number of apps found.&lt;/li&gt; 
 &lt;li&gt;Click on "Add".&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;That's it.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;!-- TABLE OF CONTENTS --&gt; 
&lt;details closed="closed"&gt; 
 &lt;summary&gt;&lt;h2 style="display: inline-block"&gt;Table of Contents&lt;/h2&gt;&lt;/summary&gt; 
 &lt;ol&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/OpenBB-finance/OpenBB/develop/#1-installation"&gt;Installation&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/OpenBB-finance/OpenBB/develop/#2-contributing"&gt;Contributing&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/OpenBB-finance/OpenBB/develop/#3-license"&gt;License&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/OpenBB-finance/OpenBB/develop/#4-disclaimer"&gt;Disclaimer&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/OpenBB-finance/OpenBB/develop/#5-contacts"&gt;Contacts&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/OpenBB-finance/OpenBB/develop/#6-star-history"&gt;Star History&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/OpenBB-finance/OpenBB/develop/#7-contributors"&gt;Contributors&lt;/a&gt;&lt;/li&gt; 
 &lt;/ol&gt; 
&lt;/details&gt; 
&lt;h2&gt;1. Installation&lt;/h2&gt; 
&lt;p&gt;The OpenBB Platform can be installed as a &lt;a href="https://pypi.org/project/openbb/"&gt;PyPI package&lt;/a&gt; by running &lt;code&gt;pip install openbb&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;or by cloning the repository directly with &lt;code&gt;git clone https://github.com/OpenBB-finance/OpenBB.git&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Please find more about the installation process, in the &lt;a href="https://docs.openbb.co/platform/installation"&gt;OpenBB Documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;OpenBB Platform CLI installation&lt;/h3&gt; 
&lt;p&gt;The OpenBB Platform CLI is a command-line interface that allows you to access the OpenBB Platform directly from your command line.&lt;/p&gt; 
&lt;p&gt;It can be installed by running &lt;code&gt;pip install openbb-cli&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;or by cloning the repository directly with &lt;code&gt;git clone https://github.com/OpenBB-finance/OpenBB.git&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Please find more about the installation process in the &lt;a href="https://docs.openbb.co/cli/installation"&gt;OpenBB Documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;2. Contributing&lt;/h2&gt; 
&lt;p&gt;There are three main ways of contributing to this project. (Hopefully you have starred the project by now â­ï¸)&lt;/p&gt; 
&lt;h3&gt;Become a Contributor&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;More information on our &lt;a href="https://docs.openbb.co/platform/developer_guide/misc/contributing"&gt;Contributing Documentation&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Create a GitHub ticket&lt;/h3&gt; 
&lt;p&gt;Before creating a ticket make sure the one you are creating doesn't exist already &lt;a href="https://github.com/OpenBB-finance/OpenBB/issues"&gt;here&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/OpenBB-finance/OpenBB/issues/new?assignees=&amp;amp;labels=bug&amp;amp;template=bug_report.md&amp;amp;title=%5BBug%5D"&gt;Report bug&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/OpenBB-finance/OpenBB/issues/new?assignees=&amp;amp;labels=enhancement&amp;amp;template=enhancement.md&amp;amp;title=%5BIMPROVE%5D"&gt;Suggest improvement&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/OpenBB-finance/OpenBB/issues/new?assignees=&amp;amp;labels=new+feature&amp;amp;template=feature_request.md&amp;amp;title=%5BFR%5D"&gt;Request a feature&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Provide feedback&lt;/h3&gt; 
&lt;p&gt;We are most active on &lt;a href="https://openbb.co/discord"&gt;our Discord&lt;/a&gt;, but feel free to reach out to us in any of &lt;a href="https://openbb.co/links"&gt;our social media&lt;/a&gt; for feedback.&lt;/p&gt; 
&lt;h2&gt;3. License&lt;/h2&gt; 
&lt;p&gt;Distributed under the AGPLv3 License. See &lt;a href="https://github.com/OpenBB-finance/OpenBB/raw/main/LICENSE"&gt;LICENSE&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;h2&gt;4. Disclaimer&lt;/h2&gt; 
&lt;p&gt;Trading in financial instruments involves high risks including the risk of losing some, or all, of your investment amount, and may not be suitable for all investors.&lt;/p&gt; 
&lt;p&gt;Before deciding to trade in a financial instrument you should be fully informed of the risks and costs associated with trading the financial markets, carefully consider your investment objectives, level of experience, and risk appetite, and seek professional advice where needed.&lt;/p&gt; 
&lt;p&gt;The data contained in the OpenBB Platform is not necessarily accurate.&lt;/p&gt; 
&lt;p&gt;OpenBB and any provider of the data contained in this website will not accept liability for any loss or damage as a result of your trading, or your reliance on the information displayed.&lt;/p&gt; 
&lt;p&gt;All names, logos, and brands of third parties that may be referenced in our sites, products or documentation are trademarks of their respective owners. Unless otherwise specified, OpenBB and its products and services are not endorsed by, sponsored by, or affiliated with these third parties.&lt;/p&gt; 
&lt;p&gt;Our use of these names, logos, and brands is for identification purposes only, and does not imply any such endorsement, sponsorship, or affiliation.&lt;/p&gt; 
&lt;h2&gt;5. Contacts&lt;/h2&gt; 
&lt;p&gt;If you have any questions about the platform or anything OpenBB, feel free to email us at &lt;code&gt;support@openbb.co&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;If you want to say hi, or are interested in partnering with us, feel free to reach us at &lt;code&gt;hello@openbb.co&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;Any of our social media platforms: &lt;a href="https://openbb.co/links"&gt;openbb.co/links&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;6. Star History&lt;/h2&gt; 
&lt;p&gt;This is a proxy of our growth and that we are just getting started.&lt;/p&gt; 
&lt;p&gt;But for more metrics important to us check &lt;a href="https://openbb.co/open"&gt;openbb.co/open&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://api.star-history.com/svg?repos=openbb-finance/OpenBB&amp;amp;type=Date&amp;amp;theme=dark"&gt;&lt;img src="https://api.star-history.com/svg?repos=openbb-finance/OpenBB&amp;amp;type=Date&amp;amp;theme=dark" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;7. Contributors&lt;/h2&gt; 
&lt;p&gt;OpenBB wouldn't be OpenBB without you. If we are going to disrupt financial industry, every contribution counts. Thank you for being part of this journey.&lt;/p&gt; 
&lt;a href="https://github.com/OpenBB-finance/OpenBB/graphs/contributors"&gt; &lt;img src="https://contributors-img.web.app/image?repo=OpenBB-finance/OpenBB" width="800" /&gt; &lt;/a&gt; 
&lt;!-- MARKDOWN LINKS &amp; IMAGES --&gt; 
&lt;!-- https://www.markdownguide.org/basic-syntax/#reference-style-links --&gt;</description>
    </item>
    
    <item>
      <title>Dao-AILab/flash-attention</title>
      <link>https://github.com/Dao-AILab/flash-attention</link>
      <description>&lt;p&gt;Fast and memory-efficient exact attention&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;FlashAttention&lt;/h1&gt; 
&lt;p&gt;This repository provides the official implementation of FlashAttention and FlashAttention-2 from the following papers.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness&lt;/strong&gt;&lt;br /&gt; Tri Dao, Daniel Y. Fu, Stefano Ermon, Atri Rudra, Christopher RÃ©&lt;br /&gt; Paper: &lt;a href="https://arxiv.org/abs/2205.14135"&gt;https://arxiv.org/abs/2205.14135&lt;/a&gt;&lt;br /&gt; IEEE Spectrum &lt;a href="https://spectrum.ieee.org/mlperf-rankings-2022"&gt;article&lt;/a&gt; about our submission to the MLPerf 2.0 benchmark using FlashAttention. &lt;img src="https://raw.githubusercontent.com/Dao-AILab/flash-attention/main/assets/flashattn_banner.jpg" alt="FlashAttention" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;FlashAttention-2: Faster Attention with Better Parallelism and Work Partitioning&lt;/strong&gt;&lt;br /&gt; Tri Dao&lt;/p&gt; 
&lt;p&gt;Paper: &lt;a href="https://tridao.me/publications/flash2/flash2.pdf"&gt;https://tridao.me/publications/flash2/flash2.pdf&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Dao-AILab/flash-attention/main/assets/flashattention_logo.png" alt="FlashAttention-2" /&gt;&lt;/p&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;p&gt;We've been very happy to see FlashAttention being widely adopted in such a short time after its release. This &lt;a href="https://github.com/Dao-AILab/flash-attention/raw/main/usage.md"&gt;page&lt;/a&gt; contains a partial list of places where FlashAttention is being used.&lt;/p&gt; 
&lt;p&gt;FlashAttention and FlashAttention-2 are free to use and modify (see LICENSE). Please cite and credit FlashAttention if you use it.&lt;/p&gt; 
&lt;h2&gt;FlashAttention-3 beta release&lt;/h2&gt; 
&lt;p&gt;FlashAttention-3 is optimized for Hopper GPUs (e.g. H100).&lt;/p&gt; 
&lt;p&gt;Blogpost: &lt;a href="https://tridao.me/blog/2024/flash3/"&gt;https://tridao.me/blog/2024/flash3/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Paper: &lt;a href="https://tridao.me/publications/flash3/flash3.pdf"&gt;https://tridao.me/publications/flash3/flash3.pdf&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Dao-AILab/flash-attention/main/assets/flash3_fp16_fwd.png" alt="FlashAttention-3 speedup on H100 80GB SXM5 with FP16" /&gt;&lt;/p&gt; 
&lt;p&gt;This is a beta release for testing / benchmarking before we integrate that with the rest of the repo.&lt;/p&gt; 
&lt;p&gt;Currently released:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;FP16 / BF16 forward and backward, FP8 forward&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Requirements: H100 / H800 GPU, CUDA &amp;gt;= 12.3.&lt;/p&gt; 
&lt;p&gt;We highly recommend CUDA 12.8 for best performance.&lt;/p&gt; 
&lt;p&gt;To install:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;cd hopper
python setup.py install
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To run the test:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;export PYTHONPATH=$PWD
pytest -q -s test_flash_attn.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Once the package is installed, you can import it as follows:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import flash_attn_interface
flash_attn_interface.flash_attn_func()
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Installation and features&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Requirements:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;CUDA toolkit or ROCm toolkit&lt;/li&gt; 
 &lt;li&gt;PyTorch 2.2 and above.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;packaging&lt;/code&gt; Python package (&lt;code&gt;pip install packaging&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;ninja&lt;/code&gt; Python package (&lt;code&gt;pip install ninja&lt;/code&gt;) *&lt;/li&gt; 
 &lt;li&gt;Linux. Might work for Windows starting v2.3.2 (we've seen a few positive &lt;a href="https://github.com/Dao-AILab/flash-attention/issues/595"&gt;reports&lt;/a&gt;) but Windows compilation still requires more testing. If you have ideas on how to set up prebuilt CUDA wheels for Windows, please reach out via Github issue.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;* Make sure that &lt;code&gt;ninja&lt;/code&gt; is installed and that it works correctly (e.g. &lt;code&gt;ninja --version&lt;/code&gt; then &lt;code&gt;echo $?&lt;/code&gt; should return exit code 0). If not (sometimes &lt;code&gt;ninja --version&lt;/code&gt; then &lt;code&gt;echo $?&lt;/code&gt; returns a nonzero exit code), uninstall then reinstall &lt;code&gt;ninja&lt;/code&gt; (&lt;code&gt;pip uninstall -y ninja &amp;amp;&amp;amp; pip install ninja&lt;/code&gt;). Without &lt;code&gt;ninja&lt;/code&gt;, compiling can take a very long time (2h) since it does not use multiple CPU cores. With &lt;code&gt;ninja&lt;/code&gt; compiling takes 3-5 minutes on a 64-core machine using CUDA toolkit.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;To install:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;pip install flash-attn --no-build-isolation
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Alternatively you can compile from source:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;python setup.py install
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If your machine has less than 96GB of RAM and lots of CPU cores, &lt;code&gt;ninja&lt;/code&gt; might run too many parallel compilation jobs that could exhaust the amount of RAM. To limit the number of parallel compilation jobs, you can set the environment variable &lt;code&gt;MAX_JOBS&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;MAX_JOBS=4 pip install flash-attn --no-build-isolation
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Interface:&lt;/strong&gt; &lt;code&gt;src/flash_attention_interface.py&lt;/code&gt;&lt;/p&gt; 
&lt;h3&gt;NVIDIA CUDA Support&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Requirements:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;CUDA 12.0 and above.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;We recommend the &lt;a href="https://catalog.ngc.nvidia.com/orgs/nvidia/containers/pytorch"&gt;Pytorch&lt;/a&gt; container from Nvidia, which has all the required tools to install FlashAttention.&lt;/p&gt; 
&lt;p&gt;FlashAttention-2 with CUDA currently supports:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Ampere, Ada, or Hopper GPUs (e.g., A100, RTX 3090, RTX 4090, H100). Support for Turing GPUs (T4, RTX 2080) is coming soon, please use FlashAttention 1.x for Turing GPUs for now.&lt;/li&gt; 
 &lt;li&gt;Datatype fp16 and bf16 (bf16 requires Ampere, Ada, or Hopper GPUs).&lt;/li&gt; 
 &lt;li&gt;All head dimensions up to 256. &lt;del&gt;Head dim &amp;gt; 192 backward requires A100/A800 or H100/H800&lt;/del&gt;. Head dim 256 backward now works on consumer GPUs (if there's no dropout) as of flash-attn 2.5.5.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;AMD ROCm Support&lt;/h3&gt; 
&lt;p&gt;ROCm version has two backends. There is &lt;a href="https://github.com/ROCm/composable_kernel"&gt;composable_kernel&lt;/a&gt; (ck) which is the default backend and a &lt;a href="https://github.com/triton-lang/triton"&gt;Triton&lt;/a&gt; backend. They provide an implementation of FlashAttention-2.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Requirements:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;ROCm 6.0 and above.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;We recommend the &lt;a href="https://hub.docker.com/r/rocm/pytorch"&gt;Pytorch&lt;/a&gt; container from ROCm, which has all the required tools to install FlashAttention.&lt;/p&gt; 
&lt;h4&gt;Composable Kernel Backend&lt;/h4&gt; 
&lt;p&gt;FlashAttention-2 ROCm CK backend currently supports:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;MI200 or MI300 GPUs.&lt;/li&gt; 
 &lt;li&gt;Datatype fp16 and bf16&lt;/li&gt; 
 &lt;li&gt;Both forward's and backward's head dimensions up to 256.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Triton Backend&lt;/h4&gt; 
&lt;p&gt;The Triton implementation of the &lt;a href="https://tridao.me/publications/flash2/flash2.pdf"&gt;Flash Attention v2&lt;/a&gt; is currently a work in progress.&lt;/p&gt; 
&lt;p&gt;It supports AMD's CDNA (MI200, MI300) and RDNA GPU's using fp16, bf16 and fp32 datatypes.&lt;/p&gt; 
&lt;p&gt;These features are supported in Fwd and Bwd&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Fwd and Bwd with causal masking&lt;/li&gt; 
 &lt;li&gt;Variable sequence lengths&lt;/li&gt; 
 &lt;li&gt;Arbitrary Q and KV sequence lengths&lt;/li&gt; 
 &lt;li&gt;Arbitrary head sizes&lt;/li&gt; 
 &lt;li&gt;Multi and grouped query attention&lt;/li&gt; 
 &lt;li&gt;Dropout&lt;/li&gt; 
 &lt;li&gt;Rotary embeddings&lt;/li&gt; 
 &lt;li&gt;ALiBi&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;We are working on the following things&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Paged Attention&lt;/li&gt; 
 &lt;li&gt;Sliding Window&lt;/li&gt; 
 &lt;li&gt;FP8&lt;/li&gt; 
 &lt;li&gt;Performance Improvements&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h5&gt;Getting Started&lt;/h5&gt; 
&lt;p&gt;To get started with the triton backend for AMD, follow the steps below.&lt;/p&gt; 
&lt;p&gt;First install the recommended Triton version&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;pip install triton==3.2.0
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then install Flash Attention with the flag &lt;code&gt;FLASH_ATTENTION_TRITON_AMD_ENABLE&lt;/code&gt; set to &lt;code&gt;"TRUE"&lt;/code&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;cd flash-attention
git checkout main_perf
FLASH_ATTENTION_TRITON_AMD_ENABLE="TRUE" python setup.py install
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To test that things are working, you can run our tests. These tests take hours so you don't need to run the full thing.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;FLASH_ATTENTION_TRITON_AMD_ENABLE="TRUE" pytest tests/test_flash_attn_triton_amd.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can use autotune for better performance by using this flag &lt;code&gt;FLASH_ATTENTION_TRITON_AMD_AUTOTUNE="TRUE"&lt;/code&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;FLASH_ATTENTION_TRITON_AMD_ENABLE="TRUE" FLASH_ATTENTION_TRITON_AMD_AUTOTUNE="TRUE" python $PATH_TO_CODE
&lt;/code&gt;&lt;/pre&gt; 
&lt;h6&gt;Docker&lt;/h6&gt; 
&lt;p&gt;You can also use the Dockerfile below which does the above steps on top of the latest rocm/pytorch image.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;FROM rocm/pytorch:latest

WORKDIR /workspace

# install triton
RUN pip install triton==3.2.0

# install flash attention
ENV FLASH_ATTENTION_TRITON_AMD_ENABLE="TRUE"

RUN git clone https://github.com/ROCm/flash-attention.git &amp;amp;&amp;amp;\ 
    cd flash-attention &amp;amp;&amp;amp;\
    git checkout main_perf &amp;amp;&amp;amp;\
    python setup.py install

# set working dir
WORKDIR /workspace/flash-attention
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To build the docker file&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;docker build -t fa_triton .
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To run the docker image&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;docker run -it --network=host --user root --group-add video --cap-add=SYS_PTRACE --security-opt seccomp=unconfined --ipc=host --shm-size 16G --device=/dev/kfd --device=/dev/dri fa_triton
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;How to use FlashAttention&lt;/h2&gt; 
&lt;p&gt;The main functions implement scaled dot product attention (softmax(Q @ K^T * softmax_scale) @ V):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from flash_attn import flash_attn_qkvpacked_func, flash_attn_func
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;flash_attn_qkvpacked_func(qkv, dropout_p=0.0, softmax_scale=None, causal=False,
                          window_size=(-1, -1), alibi_slopes=None, deterministic=False):
"""dropout_p should be set to 0.0 during evaluation
If Q, K, V are already stacked into 1 tensor, this function will be faster than
calling flash_attn_func on Q, K, V since the backward pass avoids explicit concatenation
of the gradients of Q, K, V.
If window_size != (-1, -1), implements sliding window local attention. Query at position i
will only attend to keys between [i - window_size[0], i + window_size[1]] inclusive.
Arguments:
    qkv: (batch_size, seqlen, 3, nheads, headdim)
    dropout_p: float. Dropout probability.
    softmax_scale: float. The scaling of QK^T before applying softmax.
        Default to 1 / sqrt(headdim).
    causal: bool. Whether to apply causal attention mask (e.g., for auto-regressive modeling).
    window_size: (left, right). If not (-1, -1), implements sliding window local attention.
    alibi_slopes: (nheads,) or (batch_size, nheads), fp32. A bias of (-alibi_slope * |i - j|) is added to
        the attention score of query i and key j.
    deterministic: bool. Whether to use the deterministic implementation of the backward pass,
        which is slightly slower and uses more memory. The forward pass is always deterministic.
Return:
    out: (batch_size, seqlen, nheads, headdim).
"""
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;flash_attn_func(q, k, v, dropout_p=0.0, softmax_scale=None, causal=False,
                window_size=(-1, -1), alibi_slopes=None, deterministic=False):
"""dropout_p should be set to 0.0 during evaluation
Supports multi-query and grouped-query attention (MQA/GQA) by passing in KV with fewer heads
than Q. Note that the number of heads in Q must be divisible by the number of heads in KV.
For example, if Q has 6 heads and K, V have 2 heads, head 0, 1, 2 of Q will attention to head
0 of K, V, and head 3, 4, 5 of Q will attention to head 1 of K, V.
If window_size != (-1, -1), implements sliding window local attention. Query at position i
will only attend to keys between
[i + seqlen_k - seqlen_q - window_size[0], i + seqlen_k - seqlen_q + window_size[1]] inclusive.

Arguments:
    q: (batch_size, seqlen, nheads, headdim)
    k: (batch_size, seqlen, nheads_k, headdim)
    v: (batch_size, seqlen, nheads_k, headdim)
    dropout_p: float. Dropout probability.
    softmax_scale: float. The scaling of QK^T before applying softmax.
        Default to 1 / sqrt(headdim).
    causal: bool. Whether to apply causal attention mask (e.g., for auto-regressive modeling).
    window_size: (left, right). If not (-1, -1), implements sliding window local attention.
    alibi_slopes: (nheads,) or (batch_size, nheads), fp32. A bias of
        (-alibi_slope * |i + seqlen_k - seqlen_q - j|)
        is added to the attention score of query i and key j.
    deterministic: bool. Whether to use the deterministic implementation of the backward pass,
        which is slightly slower and uses more memory. The forward pass is always deterministic.
Return:
    out: (batch_size, seqlen, nheads, headdim).
"""
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;def flash_attn_with_kvcache(
    q,
    k_cache,
    v_cache,
    k=None,
    v=None,
    rotary_cos=None,
    rotary_sin=None,
    cache_seqlens: Optional[Union[(int, torch.Tensor)]] = None,
    cache_batch_idx: Optional[torch.Tensor] = None,
    block_table: Optional[torch.Tensor] = None,
    softmax_scale=None,
    causal=False,
    window_size=(-1, -1),  # -1 means infinite context window
    rotary_interleaved=True,
    alibi_slopes=None,
):
    """
    If k and v are not None, k_cache and v_cache will be updated *inplace* with the new values from
    k and v. This is useful for incremental decoding: you can pass in the cached keys/values from
    the previous step, and update them with the new keys/values from the current step, and do
    attention with the updated cache, all in 1 kernel.

    If you pass in k / v, you must make sure that the cache is large enough to hold the new values.
    For example, the KV cache could be pre-allocated with the max sequence length, and you can use
    cache_seqlens to keep track of the current sequence lengths of each sequence in the batch.

    Also apply rotary embedding if rotary_cos and rotary_sin are passed in. The key @k will be
    rotated by rotary_cos and rotary_sin at indices cache_seqlens, cache_seqlens + 1, etc.
    If causal or local (i.e., window_size != (-1, -1)), the query @q will be rotated by rotary_cos
    and rotary_sin at indices cache_seqlens, cache_seqlens + 1, etc.
    If not causal and not local, the query @q will be rotated by rotary_cos and rotary_sin at
    indices cache_seqlens only (i.e. we consider all tokens in @q to be at position cache_seqlens).

    See tests/test_flash_attn.py::test_flash_attn_kvcache for examples of how to use this function.

    Supports multi-query and grouped-query attention (MQA/GQA) by passing in KV with fewer heads
    than Q. Note that the number of heads in Q must be divisible by the number of heads in KV.
    For example, if Q has 6 heads and K, V have 2 heads, head 0, 1, 2 of Q will attention to head
    0 of K, V, and head 3, 4, 5 of Q will attention to head 1 of K, V.

    If causal=True, the causal mask is aligned to the bottom right corner of the attention matrix.
    For example, if seqlen_q = 2 and seqlen_k = 5, the causal mask (1 = keep, 0 = masked out) is:
        1 1 1 1 0
        1 1 1 1 1
    If seqlen_q = 5 and seqlen_k = 2, the causal mask is:
        0 0
        0 0
        0 0
        1 0
        1 1
    If the row of the mask is all zero, the output will be zero.

    If window_size != (-1, -1), implements sliding window local attention. Query at position i
    will only attend to keys between
    [i + seqlen_k - seqlen_q - window_size[0], i + seqlen_k - seqlen_q + window_size[1]] inclusive.

    Note: Does not support backward pass.

    Arguments:
        q: (batch_size, seqlen, nheads, headdim)
        k_cache: (batch_size_cache, seqlen_cache, nheads_k, headdim) if there's no block_table,
            or (num_blocks, page_block_size, nheads_k, headdim) if there's a block_table (i.e. paged KV cache)
            page_block_size must be a multiple of 256.
        v_cache: (batch_size_cache, seqlen_cache, nheads_k, headdim) if there's no block_table,
            or (num_blocks, page_block_size, nheads_k, headdim) if there's a block_table (i.e. paged KV cache)
        k [optional]: (batch_size, seqlen_new, nheads_k, headdim). If not None, we concatenate
            k with k_cache, starting at the indices specified by cache_seqlens.
        v [optional]: (batch_size, seqlen_new, nheads_k, headdim). Similar to k.
        rotary_cos [optional]: (seqlen_ro, rotary_dim / 2). If not None, we apply rotary embedding
            to k and q. Only applicable if k and v are passed in. rotary_dim must be divisible by 16.
        rotary_sin [optional]: (seqlen_ro, rotary_dim / 2). Similar to rotary_cos.
        cache_seqlens: int, or (batch_size,), dtype torch.int32. The sequence lengths of the
            KV cache.
        block_table [optional]: (batch_size, max_num_blocks_per_seq), dtype torch.int32.
        cache_batch_idx: (batch_size,), dtype torch.int32. The indices used to index into the KV cache.
            If None, we assume that the batch indices are [0, 1, 2, ..., batch_size - 1].
            If the indices are not distinct, and k and v are provided, the values updated in the cache
                 might come from any of the duplicate indices.
        softmax_scale: float. The scaling of QK^T before applying softmax.
            Default to 1 / sqrt(headdim).
        causal: bool. Whether to apply causal attention mask (e.g., for auto-regressive modeling).
        window_size: (left, right). If not (-1, -1), implements sliding window local attention.
        rotary_interleaved: bool. Only applicable if rotary_cos and rotary_sin are passed in.
            If True, rotary embedding will combine dimensions 0 &amp;amp; 1, 2 &amp;amp; 3, etc. If False,
            rotary embedding will combine dimensions 0 &amp;amp; rotary_dim / 2, 1 &amp;amp; rotary_dim / 2 + 1
            (i.e. GPT-NeoX style).
        alibi_slopes: (nheads,) or (batch_size, nheads), fp32. A bias of
            (-alibi_slope * |i + seqlen_k - seqlen_q - j|)
            is added to the attention score of query i and key j.

    Return:
        out: (batch_size, seqlen, nheads, headdim).
    """
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To see how these functions are used in a multi-head attention layer (which includes QKV projection, output projection), see the MHA &lt;a href="https://github.com/Dao-AILab/flash-attention/raw/main/flash_attn/modules/mha.py"&gt;implementation&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Changelog&lt;/h2&gt; 
&lt;h3&gt;2.0: Complete rewrite, 2x faster&lt;/h3&gt; 
&lt;p&gt;Upgrading from FlashAttention (1.x) to FlashAttention-2&lt;/p&gt; 
&lt;p&gt;These functions have been renamed:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;flash_attn_unpadded_func&lt;/code&gt; -&amp;gt; &lt;code&gt;flash_attn_varlen_func&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;flash_attn_unpadded_qkvpacked_func&lt;/code&gt; -&amp;gt; &lt;code&gt;flash_attn_varlen_qkvpacked_func&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;flash_attn_unpadded_kvpacked_func&lt;/code&gt; -&amp;gt; &lt;code&gt;flash_attn_varlen_kvpacked_func&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;If the inputs have the same sequence lengths in the same batch, it is simpler and faster to use these functions:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;flash_attn_qkvpacked_func(qkv, dropout_p=0.0, softmax_scale=None, causal=False)
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;flash_attn_func(q, k, v, dropout_p=0.0, softmax_scale=None, causal=False)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;2.1: Change behavior of causal flag&lt;/h3&gt; 
&lt;p&gt;If seqlen_q != seqlen_k and causal=True, the causal mask is aligned to the bottom right corner of the attention matrix, instead of the top-left corner.&lt;/p&gt; 
&lt;p&gt;For example, if seqlen_q = 2 and seqlen_k = 5, the causal mask (1 = keep, 0 = masked out) is:&lt;br /&gt; v2.0:&lt;br /&gt; 1 0 0 0 0&lt;br /&gt; 1 1 0 0 0&lt;br /&gt; v2.1:&lt;br /&gt; 1 1 1 1 0&lt;br /&gt; 1 1 1 1 1&lt;/p&gt; 
&lt;p&gt;If seqlen_q = 5 and seqlen_k = 2, the causal mask is:&lt;br /&gt; v2.0:&lt;br /&gt; 1 0&lt;br /&gt; 1 1&lt;br /&gt; 1 1&lt;br /&gt; 1 1&lt;br /&gt; 1 1&lt;br /&gt; v2.1:&lt;br /&gt; 0 0&lt;br /&gt; 0 0&lt;br /&gt; 0 0&lt;br /&gt; 1 0&lt;br /&gt; 1 1&lt;br /&gt; If the row of the mask is all zero, the output will be zero.&lt;/p&gt; 
&lt;h3&gt;2.2: Optimize for inference&lt;/h3&gt; 
&lt;p&gt;Optimize for inference (iterative decoding) when query has very small sequence length (e.g., query sequence length = 1). The bottleneck here is to load KV cache as fast as possible, and we split the loading across different thread blocks, with a separate kernel to combine results.&lt;/p&gt; 
&lt;p&gt;See the function &lt;code&gt;flash_attn_with_kvcache&lt;/code&gt; with more features for inference (perform rotary embedding, updating KV cache inplace).&lt;/p&gt; 
&lt;p&gt;Thanks to the xformers team, and in particular Daniel Haziza, for this collaboration.&lt;/p&gt; 
&lt;h3&gt;2.3: Local (i.e., sliding window) attention&lt;/h3&gt; 
&lt;p&gt;Implement sliding window attention (i.e., local attention). Thanks to &lt;a href="https://mistral.ai/"&gt;Mistral AI&lt;/a&gt; and in particular TimothÃ©e Lacroix for this contribution. Sliding window was used in the &lt;a href="https://mistral.ai/news/announcing-mistral-7b/"&gt;Mistral 7B&lt;/a&gt; model.&lt;/p&gt; 
&lt;h3&gt;2.4: ALiBi (attention with linear bias), deterministic backward pass.&lt;/h3&gt; 
&lt;p&gt;Implement ALiBi (Press et al., 2021). Thanks to Sanghun Cho from Kakao Brain for this contribution.&lt;/p&gt; 
&lt;p&gt;Implement deterministic backward pass. Thanks to engineers from &lt;a href="https://raw.githubusercontent.com/Dao-AILab/flash-attention/main/www.meituan.com"&gt;Meituan&lt;/a&gt; for this contribution.&lt;/p&gt; 
&lt;h3&gt;2.5: Paged KV cache.&lt;/h3&gt; 
&lt;p&gt;Support paged KV cache (i.e., &lt;a href="https://arxiv.org/abs/2309.06180"&gt;PagedAttention&lt;/a&gt;). Thanks to @beginlner for this contribution.&lt;/p&gt; 
&lt;h3&gt;2.6: Softcapping.&lt;/h3&gt; 
&lt;p&gt;Support attention with softcapping, as used in Gemma-2 and Grok models. Thanks to @Narsil and @lucidrains for this contribution.&lt;/p&gt; 
&lt;h3&gt;2.7: Compatibility with torch compile&lt;/h3&gt; 
&lt;p&gt;Thanks to @ani300 for this contribution.&lt;/p&gt; 
&lt;h2&gt;Performance&lt;/h2&gt; 
&lt;p&gt;We present expected speedup (combined forward + backward pass) and memory savings from using FlashAttention against PyTorch standard attention, depending on sequence length, on different GPUs (speedup depends on memory bandwidth - we see more speedup on slower GPU memory).&lt;/p&gt; 
&lt;p&gt;We currently have benchmarks for these GPUs:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Dao-AILab/flash-attention/main/#a100"&gt;A100&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Dao-AILab/flash-attention/main/#h100"&gt;H100&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;!-- * [RTX 3090](#rtx-3090) --&gt; 
&lt;!-- * [T4](#t4) --&gt; 
&lt;h3&gt;A100&lt;/h3&gt; 
&lt;p&gt;We display FlashAttention speedup using these parameters:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Head dimension 64 or 128, hidden dimension 2048 (i.e. either 32 or 16 heads).&lt;/li&gt; 
 &lt;li&gt;Sequence length 512, 1k, 2k, 4k, 8k, 16k.&lt;/li&gt; 
 &lt;li&gt;Batch size set to 16k / seqlen.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Speedup&lt;/h4&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Dao-AILab/flash-attention/main/assets/flash2_a100_fwd_bwd_benchmark.png" alt="FlashAttention speedup on A100 80GB SXM5 with FP16/BF16" /&gt;&lt;/p&gt; 
&lt;h4&gt;Memory&lt;/h4&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Dao-AILab/flash-attention/main/assets/flashattn_memory.jpg" alt="FlashAttention memory" /&gt;&lt;/p&gt; 
&lt;p&gt;We show memory savings in this graph (note that memory footprint is the same no matter if you use dropout or masking). Memory savings are proportional to sequence length -- since standard attention has memory quadratic in sequence length, whereas FlashAttention has memory linear in sequence length. We see 10X memory savings at sequence length 2K, and 20X at 4K. As a result, FlashAttention can scale to much longer sequence lengths.&lt;/p&gt; 
&lt;h3&gt;H100&lt;/h3&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Dao-AILab/flash-attention/main/assets/flash2_h100_fwd_bwd_benchmark.png" alt="FlashAttention speedup on H100 SXM5 with FP16/BF16" /&gt;&lt;/p&gt; 
&lt;h2&gt;Full model code and training script&lt;/h2&gt; 
&lt;p&gt;We have released the full GPT model &lt;a href="https://github.com/Dao-AILab/flash-attention/raw/main/flash_attn/models/gpt.py"&gt;implementation&lt;/a&gt;. We also provide optimized implementations of other layers (e.g., MLP, LayerNorm, cross-entropy loss, rotary embedding). Overall this speeds up training by 3-5x compared to the baseline implementation from Huggingface, reaching up to 225 TFLOPs/sec per A100, equivalent to 72% model FLOPs utilization (we don't need any activation checkpointing).&lt;/p&gt; 
&lt;p&gt;We also include a training &lt;a href="https://github.com/Dao-AILab/flash-attention/tree/main/training"&gt;script&lt;/a&gt; to train GPT2 on Openwebtext and GPT3 on The Pile.&lt;/p&gt; 
&lt;h2&gt;Triton implementation of FlashAttention&lt;/h2&gt; 
&lt;p&gt;Phil Tillet (OpenAI) has an experimental implementation of FlashAttention in Triton: &lt;a href="https://github.com/openai/triton/raw/master/python/tutorials/06-fused-attention.py"&gt;https://github.com/openai/triton/blob/master/python/tutorials/06-fused-attention.py&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;As Triton is a higher-level language than CUDA, it might be easier to understand and experiment with. The notations in the Triton implementation are also closer to what's used in our paper.&lt;/p&gt; 
&lt;p&gt;We also have an experimental implementation in Triton that support attention bias (e.g. ALiBi): &lt;a href="https://github.com/Dao-AILab/flash-attention/raw/main/flash_attn/flash_attn_triton.py"&gt;https://github.com/Dao-AILab/flash-attention/blob/main/flash_attn/flash_attn_triton.py&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Tests&lt;/h2&gt; 
&lt;p&gt;We test that FlashAttention produces the same output and gradient as a reference implementation, up to some numerical tolerance. In particular, we check that the maximum numerical error of FlashAttention is at most twice the numerical error of a baseline implementation in Pytorch (for different head dimensions, input dtype, sequence length, causal / non-causal).&lt;/p&gt; 
&lt;p&gt;To run the tests:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;pytest -q -s tests/test_flash_attn.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;When you encounter issues&lt;/h2&gt; 
&lt;p&gt;This new release of FlashAttention-2 has been tested on several GPT-style models, mostly on A100 GPUs.&lt;/p&gt; 
&lt;p&gt;If you encounter bugs, please open a GitHub Issue!&lt;/p&gt; 
&lt;h2&gt;Tests&lt;/h2&gt; 
&lt;p&gt;To run the tests:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;pytest tests/test_flash_attn_ck.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Citation&lt;/h2&gt; 
&lt;p&gt;If you use this codebase, or otherwise found our work valuable, please cite:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;@inproceedings{dao2022flashattention,
  title={Flash{A}ttention: Fast and Memory-Efficient Exact Attention with {IO}-Awareness},
  author={Dao, Tri and Fu, Daniel Y. and Ermon, Stefano and Rudra, Atri and R{\'e}, Christopher},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2022}
}
@inproceedings{dao2023flashattention2,
  title={Flash{A}ttention-2: Faster Attention with Better Parallelism and Work Partitioning},
  author={Dao, Tri},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2024}
}
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>datalab-to/surya</title>
      <link>https://github.com/datalab-to/surya</link>
      <description>&lt;p&gt;OCR, layout analysis, reading order, table recognition in 90+ languages&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Surya&lt;/h1&gt; 
&lt;p&gt;Surya is a document OCR toolkit that does:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;OCR in 90+ languages that benchmarks favorably vs cloud services&lt;/li&gt; 
 &lt;li&gt;Line-level text detection in any language&lt;/li&gt; 
 &lt;li&gt;Layout analysis (table, image, header, etc detection)&lt;/li&gt; 
 &lt;li&gt;Reading order detection&lt;/li&gt; 
 &lt;li&gt;Table recognition (detecting rows/columns)&lt;/li&gt; 
 &lt;li&gt;LaTeX OCR&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;It works on a range of documents (see &lt;a href="https://raw.githubusercontent.com/datalab-to/surya/master/#usage"&gt;usage&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/datalab-to/surya/master/#benchmarks"&gt;benchmarks&lt;/a&gt; for more details).&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="center"&gt;Detection&lt;/th&gt; 
   &lt;th align="center"&gt;OCR&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;img src="https://raw.githubusercontent.com/datalab-to/surya/master/static/images/excerpt.png" width="500px" /&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;img src="https://raw.githubusercontent.com/datalab-to/surya/master/static/images/excerpt_text.png" width="500px" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="center"&gt;Layout&lt;/th&gt; 
   &lt;th align="center"&gt;Reading Order&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;img src="https://raw.githubusercontent.com/datalab-to/surya/master/static/images/excerpt_layout.png" width="500px" /&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;img src="https://raw.githubusercontent.com/datalab-to/surya/master/static/images/excerpt_reading.jpg" width="500px" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="center"&gt;Table Recognition&lt;/th&gt; 
   &lt;th align="center"&gt;LaTeX OCR&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;img src="https://raw.githubusercontent.com/datalab-to/surya/master/static/images/scanned_tablerec.png" width="500px" /&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;img src="https://raw.githubusercontent.com/datalab-to/surya/master/static/images/latex_ocr.png" width="500px" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Surya is named for the &lt;a href="https://en.wikipedia.org/wiki/Surya"&gt;Hindu sun god&lt;/a&gt;, who has universal vision.&lt;/p&gt; 
&lt;h2&gt;Community&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://discord.gg//KuZwXNGnfH"&gt;Discord&lt;/a&gt; is where we discuss future development.&lt;/p&gt; 
&lt;h2&gt;Examples&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Name&lt;/th&gt; 
   &lt;th align="center"&gt;Detection&lt;/th&gt; 
   &lt;th align="right"&gt;OCR&lt;/th&gt; 
   &lt;th align="right"&gt;Layout&lt;/th&gt; 
   &lt;th align="right"&gt;Order&lt;/th&gt; 
   &lt;th align="right"&gt;Table Rec&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Japanese&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/datalab-to/surya/master/static/images/japanese.jpg"&gt;Image&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;&lt;a href="https://raw.githubusercontent.com/datalab-to/surya/master/static/images/japanese_text.jpg"&gt;Image&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;&lt;a href="https://raw.githubusercontent.com/datalab-to/surya/master/static/images/japanese_layout.jpg"&gt;Image&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;&lt;a href="https://raw.githubusercontent.com/datalab-to/surya/master/static/images/japanese_reading.jpg"&gt;Image&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;&lt;a href="https://raw.githubusercontent.com/datalab-to/surya/master/static/images/japanese_tablerec.png"&gt;Image&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Chinese&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/datalab-to/surya/master/static/images/chinese.jpg"&gt;Image&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;&lt;a href="https://raw.githubusercontent.com/datalab-to/surya/master/static/images/chinese_text.jpg"&gt;Image&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;&lt;a href="https://raw.githubusercontent.com/datalab-to/surya/master/static/images/chinese_layout.jpg"&gt;Image&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;&lt;a href="https://raw.githubusercontent.com/datalab-to/surya/master/static/images/chinese_reading.jpg"&gt;Image&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Hindi&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/datalab-to/surya/master/static/images/hindi.jpg"&gt;Image&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;&lt;a href="https://raw.githubusercontent.com/datalab-to/surya/master/static/images/hindi_text.jpg"&gt;Image&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;&lt;a href="https://raw.githubusercontent.com/datalab-to/surya/master/static/images/hindi_layout.jpg"&gt;Image&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;&lt;a href="https://raw.githubusercontent.com/datalab-to/surya/master/static/images/hindi_reading.jpg"&gt;Image&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Arabic&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/datalab-to/surya/master/static/images/arabic.jpg"&gt;Image&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;&lt;a href="https://raw.githubusercontent.com/datalab-to/surya/master/static/images/arabic_text.jpg"&gt;Image&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;&lt;a href="https://raw.githubusercontent.com/datalab-to/surya/master/static/images/arabic_layout.jpg"&gt;Image&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;&lt;a href="https://raw.githubusercontent.com/datalab-to/surya/master/static/images/arabic_reading.jpg"&gt;Image&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Chinese + Hindi&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/datalab-to/surya/master/static/images/chi_hind.jpg"&gt;Image&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;&lt;a href="https://raw.githubusercontent.com/datalab-to/surya/master/static/images/chi_hind_text.jpg"&gt;Image&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;&lt;a href="https://raw.githubusercontent.com/datalab-to/surya/master/static/images/chi_hind_layout.jpg"&gt;Image&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;&lt;a href="https://raw.githubusercontent.com/datalab-to/surya/master/static/images/chi_hind_reading.jpg"&gt;Image&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Presentation&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/datalab-to/surya/master/static/images/pres.png"&gt;Image&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;&lt;a href="https://raw.githubusercontent.com/datalab-to/surya/master/static/images/pres_text.jpg"&gt;Image&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;&lt;a href="https://raw.githubusercontent.com/datalab-to/surya/master/static/images/pres_layout.jpg"&gt;Image&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;&lt;a href="https://raw.githubusercontent.com/datalab-to/surya/master/static/images/pres_reading.jpg"&gt;Image&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;&lt;a href="https://raw.githubusercontent.com/datalab-to/surya/master/static/images/pres_tablerec.png"&gt;Image&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Scientific Paper&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/datalab-to/surya/master/static/images/paper.jpg"&gt;Image&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;&lt;a href="https://raw.githubusercontent.com/datalab-to/surya/master/static/images/paper_text.jpg"&gt;Image&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;&lt;a href="https://raw.githubusercontent.com/datalab-to/surya/master/static/images/paper_layout.jpg"&gt;Image&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;&lt;a href="https://raw.githubusercontent.com/datalab-to/surya/master/static/images/paper_reading.jpg"&gt;Image&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;&lt;a href="https://raw.githubusercontent.com/datalab-to/surya/master/static/images/paper_tablerec.png"&gt;Image&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Scanned Document&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/datalab-to/surya/master/static/images/scanned.png"&gt;Image&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;&lt;a href="https://raw.githubusercontent.com/datalab-to/surya/master/static/images/scanned_text.jpg"&gt;Image&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;&lt;a href="https://raw.githubusercontent.com/datalab-to/surya/master/static/images/scanned_layout.jpg"&gt;Image&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;&lt;a href="https://raw.githubusercontent.com/datalab-to/surya/master/static/images/scanned_reading.jpg"&gt;Image&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;&lt;a href="https://raw.githubusercontent.com/datalab-to/surya/master/static/images/scanned_tablerec.png"&gt;Image&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;New York Times&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/datalab-to/surya/master/static/images/nyt.jpg"&gt;Image&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;&lt;a href="https://raw.githubusercontent.com/datalab-to/surya/master/static/images/nyt_text.jpg"&gt;Image&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;&lt;a href="https://raw.githubusercontent.com/datalab-to/surya/master/static/images/nyt_layout.jpg"&gt;Image&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;&lt;a href="https://raw.githubusercontent.com/datalab-to/surya/master/static/images/nyt_order.jpg"&gt;Image&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Scanned Form&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/datalab-to/surya/master/static/images/funsd.png"&gt;Image&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;&lt;a href="https://raw.githubusercontent.com/datalab-to/surya/master/static/images/funsd_text.jpg"&gt;Image&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;&lt;a href="https://raw.githubusercontent.com/datalab-to/surya/master/static/images/funsd_layout.jpg"&gt;Image&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;&lt;a href="https://raw.githubusercontent.com/datalab-to/surya/master/static/images/funsd_reading.jpg"&gt;Image&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;&lt;a href="https://raw.githubusercontent.com/datalab-to/surya/master/static/images/scanned_tablerec2.png"&gt;Image&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Textbook&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/datalab-to/surya/master/static/images/textbook.jpg"&gt;Image&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;&lt;a href="https://raw.githubusercontent.com/datalab-to/surya/master/static/images/textbook_text.jpg"&gt;Image&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;&lt;a href="https://raw.githubusercontent.com/datalab-to/surya/master/static/images/textbook_layout.jpg"&gt;Image&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;&lt;a href="https://raw.githubusercontent.com/datalab-to/surya/master/static/images/textbook_order.jpg"&gt;Image&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h1&gt;Hosted API&lt;/h1&gt; 
&lt;p&gt;There is a hosted API for all surya models available &lt;a href="https://www.datalab.to/"&gt;here&lt;/a&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Works with PDF, images, word docs, and powerpoints&lt;/li&gt; 
 &lt;li&gt;Consistent speed, with no latency spikes&lt;/li&gt; 
 &lt;li&gt;High reliability and uptime&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Commercial usage&lt;/h1&gt; 
&lt;p&gt;Our model weights use a modified AI Pubs Open Rail-M license (free for research, personal use, and startups under $2M funding/revenue) and our code is GPL. For broader commercial licensing or to remove GPL requirements, visit our pricing page &lt;a href="https://www.datalab.to/pricing"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;Installation&lt;/h1&gt; 
&lt;p&gt;You'll need python 3.10+ and PyTorch. You may need to install the CPU version of torch first if you're not using a Mac or a GPU machine. See &lt;a href="https://pytorch.org/get-started/locally/"&gt;here&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;p&gt;Install with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;pip install surya-ocr
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Model weights will automatically download the first time you run surya.&lt;/p&gt; 
&lt;h1&gt;Usage&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;Inspect the settings in &lt;code&gt;surya/settings.py&lt;/code&gt;. You can override any settings with environment variables.&lt;/li&gt; 
 &lt;li&gt;Your torch device will be automatically detected, but you can override this. For example, &lt;code&gt;TORCH_DEVICE=cuda&lt;/code&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Interactive App&lt;/h2&gt; 
&lt;p&gt;I've included a streamlit app that lets you interactively try Surya on images or PDF files. Run it with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;pip install streamlit pdftext
surya_gui
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;OCR (text recognition)&lt;/h2&gt; 
&lt;p&gt;This command will write out a json file with the detected text and bboxes:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;surya_ocr DATA_PATH
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;DATA_PATH&lt;/code&gt; can be an image, pdf, or folder of images/pdfs&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--task_name&lt;/code&gt; will specify which task to use for predicting the lines. &lt;code&gt;ocr_with_boxes&lt;/code&gt; is the default, which will format text and give you bboxes. If you get bad performance, try &lt;code&gt;ocr_without_boxes&lt;/code&gt;, which will give you potentially better performance but no bboxes. For blocks like equations and paragraphs, try &lt;code&gt;block_without_boxes&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--images&lt;/code&gt; will save images of the pages and detected text lines (optional)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--output_dir&lt;/code&gt; specifies the directory to save results to instead of the default&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--page_range&lt;/code&gt; specifies the page range to process in the PDF, specified as a single number, a comma separated list, a range, or comma separated ranges - example: &lt;code&gt;0,5-10,20&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--disable_math&lt;/code&gt; - by default, surya will recognize math in text. This can lead to false positives - you can disable this with this flag.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The &lt;code&gt;results.json&lt;/code&gt; file will contain a json dictionary where the keys are the input filenames without extensions. Each value will be a list of dictionaries, one per page of the input document. Each page dictionary contains:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;text_lines&lt;/code&gt; - the detected text and bounding boxes for each line 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;text&lt;/code&gt; - the text in the line&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;confidence&lt;/code&gt; - the confidence of the model in the detected text (0-1)&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;polygon&lt;/code&gt; - the polygon for the text line in (x1, y1), (x2, y2), (x3, y3), (x4, y4) format. The points are in clockwise order from the top left.&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;bbox&lt;/code&gt; - the axis-aligned rectangle for the text line in (x1, y1, x2, y2) format. (x1, y1) is the top left corner, and (x2, y2) is the bottom right corner.&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;chars&lt;/code&gt; - the individual characters in the line 
    &lt;ul&gt; 
     &lt;li&gt;&lt;code&gt;text&lt;/code&gt; - the text of the character&lt;/li&gt; 
     &lt;li&gt;&lt;code&gt;bbox&lt;/code&gt; - the character bbox (same format as line bbox)&lt;/li&gt; 
     &lt;li&gt;&lt;code&gt;polygon&lt;/code&gt; - the character polygon (same format as line polygon)&lt;/li&gt; 
     &lt;li&gt;&lt;code&gt;confidence&lt;/code&gt; - the confidence of the model in the detected character (0-1)&lt;/li&gt; 
     &lt;li&gt;&lt;code&gt;bbox_valid&lt;/code&gt; - if the character is a special token or math, the bbox may not be valid&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;words&lt;/code&gt; - the individual words in the line (computed from the characters) 
    &lt;ul&gt; 
     &lt;li&gt;&lt;code&gt;text&lt;/code&gt; - the text of the word&lt;/li&gt; 
     &lt;li&gt;&lt;code&gt;bbox&lt;/code&gt; - the word bbox (same format as line bbox)&lt;/li&gt; 
     &lt;li&gt;&lt;code&gt;polygon&lt;/code&gt; - the word polygon (same format as line polygon)&lt;/li&gt; 
     &lt;li&gt;&lt;code&gt;confidence&lt;/code&gt; - mean character confidence&lt;/li&gt; 
     &lt;li&gt;&lt;code&gt;bbox_valid&lt;/code&gt; - if the word is a special token or math, the bbox may not be valid&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;page&lt;/code&gt; - the page number in the file&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;image_bbox&lt;/code&gt; - the bbox for the image in (x1, y1, x2, y2) format. (x1, y1) is the top left corner, and (x2, y2) is the bottom right corner. All line bboxes will be contained within this bbox.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Performance tips&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Setting the &lt;code&gt;RECOGNITION_BATCH_SIZE&lt;/code&gt; env var properly will make a big difference when using a GPU. Each batch item will use &lt;code&gt;40MB&lt;/code&gt; of VRAM, so very high batch sizes are possible. The default is a batch size &lt;code&gt;512&lt;/code&gt;, which will use about 20GB of VRAM. Depending on your CPU core count, it may help, too - the default CPU batch size is &lt;code&gt;32&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;From python&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from PIL import Image
from surya.foundation import FoundationPredictor
from surya.recognition import RecognitionPredictor
from surya.detection import DetectionPredictor

image = Image.open(IMAGE_PATH)
foundation_predictor = FoundationPredictor()
recognition_predictor = RecognitionPredictor(foundation_predictor)
detection_predictor = DetectionPredictor()

predictions = recognition_predictor([image], det_predictor=detection_predictor)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Text line detection&lt;/h2&gt; 
&lt;p&gt;This command will write out a json file with the detected bboxes.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;surya_detect DATA_PATH
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;DATA_PATH&lt;/code&gt; can be an image, pdf, or folder of images/pdfs&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--images&lt;/code&gt; will save images of the pages and detected text lines (optional)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--output_dir&lt;/code&gt; specifies the directory to save results to instead of the default&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--page_range&lt;/code&gt; specifies the page range to process in the PDF, specified as a single number, a comma separated list, a range, or comma separated ranges - example: &lt;code&gt;0,5-10,20&lt;/code&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The &lt;code&gt;results.json&lt;/code&gt; file will contain a json dictionary where the keys are the input filenames without extensions. Each value will be a list of dictionaries, one per page of the input document. Each page dictionary contains:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;bboxes&lt;/code&gt; - detected bounding boxes for text 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;bbox&lt;/code&gt; - the axis-aligned rectangle for the text line in (x1, y1, x2, y2) format. (x1, y1) is the top left corner, and (x2, y2) is the bottom right corner.&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;polygon&lt;/code&gt; - the polygon for the text line in (x1, y1), (x2, y2), (x3, y3), (x4, y4) format. The points are in clockwise order from the top left.&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;confidence&lt;/code&gt; - the confidence of the model in the detected text (0-1)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;vertical_lines&lt;/code&gt; - vertical lines detected in the document 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;bbox&lt;/code&gt; - the axis-aligned line coordinates.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;page&lt;/code&gt; - the page number in the file&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;image_bbox&lt;/code&gt; - the bbox for the image in (x1, y1, x2, y2) format. (x1, y1) is the top left corner, and (x2, y2) is the bottom right corner. All line bboxes will be contained within this bbox.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Performance tips&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Setting the &lt;code&gt;DETECTOR_BATCH_SIZE&lt;/code&gt; env var properly will make a big difference when using a GPU. Each batch item will use &lt;code&gt;440MB&lt;/code&gt; of VRAM, so very high batch sizes are possible. The default is a batch size &lt;code&gt;36&lt;/code&gt;, which will use about 16GB of VRAM. Depending on your CPU core count, it might help, too - the default CPU batch size is &lt;code&gt;6&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;From python&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from PIL import Image
from surya.detection import DetectionPredictor

image = Image.open(IMAGE_PATH)
det_predictor = DetectionPredictor()

# predictions is a list of dicts, one per image
predictions = det_predictor([image])
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Layout and reading order&lt;/h2&gt; 
&lt;p&gt;This command will write out a json file with the detected layout and reading order.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;surya_layout DATA_PATH
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;DATA_PATH&lt;/code&gt; can be an image, pdf, or folder of images/pdfs&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--images&lt;/code&gt; will save images of the pages and detected text lines (optional)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--output_dir&lt;/code&gt; specifies the directory to save results to instead of the default&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--page_range&lt;/code&gt; specifies the page range to process in the PDF, specified as a single number, a comma separated list, a range, or comma separated ranges - example: &lt;code&gt;0,5-10,20&lt;/code&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The &lt;code&gt;results.json&lt;/code&gt; file will contain a json dictionary where the keys are the input filenames without extensions. Each value will be a list of dictionaries, one per page of the input document. Each page dictionary contains:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;bboxes&lt;/code&gt; - detected bounding boxes for text 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;bbox&lt;/code&gt; - the axis-aligned rectangle for the text line in (x1, y1, x2, y2) format. (x1, y1) is the top left corner, and (x2, y2) is the bottom right corner.&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;polygon&lt;/code&gt; - the polygon for the text line in (x1, y1), (x2, y2), (x3, y3), (x4, y4) format. The points are in clockwise order from the top left.&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;position&lt;/code&gt; - the reading order of the box.&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;label&lt;/code&gt; - the label for the bbox. One of &lt;code&gt;Caption&lt;/code&gt;, &lt;code&gt;Footnote&lt;/code&gt;, &lt;code&gt;Formula&lt;/code&gt;, &lt;code&gt;List-item&lt;/code&gt;, &lt;code&gt;Page-footer&lt;/code&gt;, &lt;code&gt;Page-header&lt;/code&gt;, &lt;code&gt;Picture&lt;/code&gt;, &lt;code&gt;Figure&lt;/code&gt;, &lt;code&gt;Section-header&lt;/code&gt;, &lt;code&gt;Table&lt;/code&gt;, &lt;code&gt;Form&lt;/code&gt;, &lt;code&gt;Table-of-contents&lt;/code&gt;, &lt;code&gt;Handwriting&lt;/code&gt;, &lt;code&gt;Text&lt;/code&gt;, &lt;code&gt;Text-inline-math&lt;/code&gt;.&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;top_k&lt;/code&gt; - the top-k other potential labels for the box. A dictionary with labels as keys and confidences as values.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;page&lt;/code&gt; - the page number in the file&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;image_bbox&lt;/code&gt; - the bbox for the image in (x1, y1, x2, y2) format. (x1, y1) is the top left corner, and (x2, y2) is the bottom right corner. All line bboxes will be contained within this bbox.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Performance tips&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Setting the &lt;code&gt;LAYOUT_BATCH_SIZE&lt;/code&gt; env var properly will make a big difference when using a GPU. Each batch item will use &lt;code&gt;220MB&lt;/code&gt; of VRAM, so very high batch sizes are possible. The default is a batch size &lt;code&gt;32&lt;/code&gt;, which will use about 7GB of VRAM. Depending on your CPU core count, it might help, too - the default CPU batch size is &lt;code&gt;4&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;From python&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from PIL import Image
from surya.layout import LayoutPredictor

image = Image.open(IMAGE_PATH)
layout_predictor = LayoutPredictor()

# layout_predictions is a list of dicts, one per image
layout_predictions = layout_predictor([image])
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Table Recognition&lt;/h2&gt; 
&lt;p&gt;This command will write out a json file with the detected table cells and row/column ids, along with row/column bounding boxes. If you want to get cell positions and text, along with nice formatting, check out the &lt;a href="https://www.github.com/VikParuchuri/marker"&gt;marker&lt;/a&gt; repo. You can use the &lt;code&gt;TableConverter&lt;/code&gt; to detect and extract tables in images and PDFs. It supports output in json (with bboxes), markdown, and html.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;surya_table DATA_PATH
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;DATA_PATH&lt;/code&gt; can be an image, pdf, or folder of images/pdfs&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--images&lt;/code&gt; will save images of the pages and detected table cells + rows and columns (optional)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--output_dir&lt;/code&gt; specifies the directory to save results to instead of the default&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--page_range&lt;/code&gt; specifies the page range to process in the PDF, specified as a single number, a comma separated list, a range, or comma separated ranges - example: &lt;code&gt;0,5-10,20&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--detect_boxes&lt;/code&gt; specifies if cells should be detected. By default, they're pulled out of the PDF, but this is not always possible.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--skip_table_detection&lt;/code&gt; tells table recognition not to detect tables first. Use this if your image is already cropped to a table.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The &lt;code&gt;results.json&lt;/code&gt; file will contain a json dictionary where the keys are the input filenames without extensions. Each value will be a list of dictionaries, one per page of the input document. Each page dictionary contains:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;rows&lt;/code&gt; - detected table rows 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;bbox&lt;/code&gt; - the bounding box of the table row&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;row_id&lt;/code&gt; - the id of the row&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;is_header&lt;/code&gt; - if it is a header row.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;cols&lt;/code&gt; - detected table columns 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;bbox&lt;/code&gt; - the bounding box of the table column&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;col_id&lt;/code&gt;- the id of the column&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;is_header&lt;/code&gt; - if it is a header column&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;cells&lt;/code&gt; - detected table cells 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;bbox&lt;/code&gt; - the axis-aligned rectangle for the text line in (x1, y1, x2, y2) format. (x1, y1) is the top left corner, and (x2, y2) is the bottom right corner.&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;text&lt;/code&gt; - if text could be pulled out of the pdf, the text of this cell.&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;row_id&lt;/code&gt; - the id of the row the cell belongs to.&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;col_id&lt;/code&gt; - the id of the column the cell belongs to.&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;colspan&lt;/code&gt; - the number of columns spanned by the cell.&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;rowspan&lt;/code&gt; - the number of rows spanned by the cell.&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;is_header&lt;/code&gt; - whether it is a header cell.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;page&lt;/code&gt; - the page number in the file&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;table_idx&lt;/code&gt; - the index of the table on the page (sorted in vertical order)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;image_bbox&lt;/code&gt; - the bbox for the image in (x1, y1, x2, y2) format. (x1, y1) is the top left corner, and (x2, y2) is the bottom right corner. All line bboxes will be contained within this bbox.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Performance tips&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Setting the &lt;code&gt;TABLE_REC_BATCH_SIZE&lt;/code&gt; env var properly will make a big difference when using a GPU. Each batch item will use &lt;code&gt;150MB&lt;/code&gt; of VRAM, so very high batch sizes are possible. The default is a batch size &lt;code&gt;64&lt;/code&gt;, which will use about 10GB of VRAM. Depending on your CPU core count, it might help, too - the default CPU batch size is &lt;code&gt;8&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;From python&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from PIL import Image
from surya.table_rec import TableRecPredictor

image = Image.open(IMAGE_PATH)
table_rec_predictor = TableRecPredictor()

table_predictions = table_rec_predictor([image])
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;LaTeX OCR&lt;/h2&gt; 
&lt;p&gt;This command will write out a json file with the LaTeX of the equations. You must pass in images that are already cropped to the equations. You can do this by running the layout model, then cropping, if you want.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;surya_latex_ocr DATA_PATH
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;DATA_PATH&lt;/code&gt; can be an image, pdf, or folder of images/pdfs&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--output_dir&lt;/code&gt; specifies the directory to save results to instead of the default&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--page_range&lt;/code&gt; specifies the page range to process in the PDF, specified as a single number, a comma separated list, a range, or comma separated ranges - example: &lt;code&gt;0,5-10,20&lt;/code&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The &lt;code&gt;results.json&lt;/code&gt; file will contain a json dictionary where the keys are the input filenames without extensions. Each value will be a list of dictionaries, one per page of the input document. See the OCR section above for the format of the output.&lt;/p&gt; 
&lt;h3&gt;From python&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from PIL import Image
from surya.texify import TexifyPredictor

image = Image.open(IMAGE_PATH)
predictor = TexifyPredictor()

predictor([image])
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Interactive app&lt;/h3&gt; 
&lt;p&gt;You can also run a special interactive app that lets you select equations and OCR them (kind of like MathPix snip) with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;pip install streamlit==1.40 streamlit-drawable-canvas-jsretry
texify_gui
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Compilation&lt;/h2&gt; 
&lt;p&gt;The following models have support for compilation. You will need to set the following environment variables to enable compilation:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Detection: &lt;code&gt;COMPILE_DETECTOR=true&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Layout: &lt;code&gt;COMPILE_LAYOUT=true&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Table recognition: &lt;code&gt;COMPILE_TABLE_REC=true&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Alternatively, you can also set &lt;code&gt;COMPILE_ALL=true&lt;/code&gt; which will compile all models.&lt;/p&gt; 
&lt;p&gt;Here are the speedups on an A10 GPU:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Model&lt;/th&gt; 
   &lt;th&gt;Time per page (s)&lt;/th&gt; 
   &lt;th&gt;Compiled time per page (s)&lt;/th&gt; 
   &lt;th&gt;Speedup (%)&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Detection&lt;/td&gt; 
   &lt;td&gt;0.108808&lt;/td&gt; 
   &lt;td&gt;0.10521&lt;/td&gt; 
   &lt;td&gt;3.306742151&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Layout&lt;/td&gt; 
   &lt;td&gt;0.27319&lt;/td&gt; 
   &lt;td&gt;0.27063&lt;/td&gt; 
   &lt;td&gt;0.93707676&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Table recognition&lt;/td&gt; 
   &lt;td&gt;0.0219&lt;/td&gt; 
   &lt;td&gt;0.01938&lt;/td&gt; 
   &lt;td&gt;11.50684932&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h1&gt;Limitations&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;This is specialized for document OCR. It will likely not work on photos or other images.&lt;/li&gt; 
 &lt;li&gt;It is for printed text, not handwriting (though it may work on some handwriting).&lt;/li&gt; 
 &lt;li&gt;The text detection model has trained itself to ignore advertisements.&lt;/li&gt; 
 &lt;li&gt;You can find language support for OCR in &lt;code&gt;surya/recognition/languages.py&lt;/code&gt;. Text detection, layout analysis, and reading order will work with any language.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Troubleshooting&lt;/h2&gt; 
&lt;p&gt;If OCR isn't working properly:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Try increasing resolution of the image so the text is bigger. If the resolution is already very high, try decreasing it to no more than a &lt;code&gt;2048px&lt;/code&gt; width.&lt;/li&gt; 
 &lt;li&gt;Preprocessing the image (binarizing, deskewing, etc) can help with very old/blurry images.&lt;/li&gt; 
 &lt;li&gt;You can adjust &lt;code&gt;DETECTOR_BLANK_THRESHOLD&lt;/code&gt; and &lt;code&gt;DETECTOR_TEXT_THRESHOLD&lt;/code&gt; if you don't get good results. &lt;code&gt;DETECTOR_BLANK_THRESHOLD&lt;/code&gt; controls the space between lines - any prediction below this number will be considered blank space. &lt;code&gt;DETECTOR_TEXT_THRESHOLD&lt;/code&gt; controls how text is joined - any number above this is considered text. &lt;code&gt;DETECTOR_TEXT_THRESHOLD&lt;/code&gt; should always be higher than &lt;code&gt;DETECTOR_BLANK_THRESHOLD&lt;/code&gt;, and both should be in the 0-1 range. Looking at the heatmap from the debug output of the detector can tell you how to adjust these (if you see faint things that look like boxes, lower the thresholds, and if you see bboxes being joined together, raise the thresholds).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Manual install&lt;/h1&gt; 
&lt;p&gt;If you want to develop surya, you can install it manually:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;git clone https://github.com/VikParuchuri/surya.git&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;cd surya&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;poetry install&lt;/code&gt; - installs main and dev dependencies&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;poetry shell&lt;/code&gt; - activates the virtual environment&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Benchmarks&lt;/h1&gt; 
&lt;h2&gt;OCR&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/datalab-to/surya/master/static/images/benchmark_rec_chart.png" alt="Benchmark chart tesseract" /&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Model&lt;/th&gt; 
   &lt;th&gt;Time per page (s)&lt;/th&gt; 
   &lt;th&gt;Avg similarity (â¬†)&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;surya&lt;/td&gt; 
   &lt;td&gt;.62&lt;/td&gt; 
   &lt;td&gt;0.97&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;tesseract&lt;/td&gt; 
   &lt;td&gt;.45&lt;/td&gt; 
   &lt;td&gt;0.88&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/datalab-to/surya/master/static/images/rec_acc_table.png"&gt;Full language results&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Tesseract is CPU-based, and surya is CPU or GPU. I tried to cost-match the resources used, so I used a 1xA6000 (48GB VRAM) for surya, and 28 CPU cores for Tesseract (same price on Lambda Labs/DigitalOcean).&lt;/p&gt; 
&lt;h3&gt;Google Cloud Vision&lt;/h3&gt; 
&lt;p&gt;I benchmarked OCR against Google Cloud vision since it has similar language coverage to Surya.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/datalab-to/surya/master/static/images/gcloud_rec_bench.png" alt="Benchmark chart google cloud" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/datalab-to/surya/master/static/images/gcloud_full_langs.png"&gt;Full language results&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Methodology&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;I measured normalized sentence similarity (0-1, higher is better) based on a set of real-world and synthetic pdfs. I sampled PDFs from common crawl, then filtered out the ones with bad OCR. I couldn't find PDFs for some languages, so I also generated simple synthetic PDFs for those.&lt;/p&gt; 
&lt;p&gt;I used the reference line bboxes from the PDFs with both tesseract and surya, to just evaluate the OCR quality.&lt;/p&gt; 
&lt;p&gt;For Google Cloud, I aligned the output from Google Cloud with the ground truth. I had to skip RTL languages since they didn't align well.&lt;/p&gt; 
&lt;h2&gt;Text line detection&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/datalab-to/surya/master/static/images/benchmark_chart_small.png" alt="Benchmark chart" /&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Model&lt;/th&gt; 
   &lt;th&gt;Time (s)&lt;/th&gt; 
   &lt;th&gt;Time per page (s)&lt;/th&gt; 
   &lt;th&gt;precision&lt;/th&gt; 
   &lt;th&gt;recall&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;surya&lt;/td&gt; 
   &lt;td&gt;47.2285&lt;/td&gt; 
   &lt;td&gt;0.094452&lt;/td&gt; 
   &lt;td&gt;0.835857&lt;/td&gt; 
   &lt;td&gt;0.960807&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;tesseract&lt;/td&gt; 
   &lt;td&gt;74.4546&lt;/td&gt; 
   &lt;td&gt;0.290838&lt;/td&gt; 
   &lt;td&gt;0.631498&lt;/td&gt; 
   &lt;td&gt;0.997694&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Tesseract is CPU-based, and surya is CPU or GPU. I ran the benchmarks on a system with an A10 GPU, and a 32 core CPU. This was the resource usage:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;tesseract - 32 CPU cores, or 8 workers using 4 cores each&lt;/li&gt; 
 &lt;li&gt;surya - 36 batch size, for 16GB VRAM usage&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Methodology&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Surya predicts line-level bboxes, while tesseract and others predict word-level or character-level. It's hard to find 100% correct datasets with line-level annotations. Merging bboxes can be noisy, so I chose not to use IoU as the metric for evaluation.&lt;/p&gt; 
&lt;p&gt;I instead used coverage, which calculates:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Precision - how well the predicted bboxes cover ground truth bboxes&lt;/li&gt; 
 &lt;li&gt;Recall - how well ground truth bboxes cover predicted bboxes&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;First calculate coverage for each bbox, then add a small penalty for double coverage, since we want the detection to have non-overlapping bboxes. Anything with a coverage of 0.5 or higher is considered a match.&lt;/p&gt; 
&lt;p&gt;Then we calculate precision and recall for the whole dataset.&lt;/p&gt; 
&lt;h2&gt;Layout analysis&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Layout Type&lt;/th&gt; 
   &lt;th&gt;precision&lt;/th&gt; 
   &lt;th&gt;recall&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Image&lt;/td&gt; 
   &lt;td&gt;0.91265&lt;/td&gt; 
   &lt;td&gt;0.93976&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;List&lt;/td&gt; 
   &lt;td&gt;0.80849&lt;/td&gt; 
   &lt;td&gt;0.86792&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Table&lt;/td&gt; 
   &lt;td&gt;0.84957&lt;/td&gt; 
   &lt;td&gt;0.96104&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Text&lt;/td&gt; 
   &lt;td&gt;0.93019&lt;/td&gt; 
   &lt;td&gt;0.94571&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Title&lt;/td&gt; 
   &lt;td&gt;0.92102&lt;/td&gt; 
   &lt;td&gt;0.95404&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Time per image - .13 seconds on GPU (A10).&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Methodology&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;I benchmarked the layout analysis on &lt;a href="https://github.com/ibm-aur-nlp/PubLayNet"&gt;Publaynet&lt;/a&gt;, which was not in the training data. I had to align publaynet labels with the surya layout labels. I was then able to find coverage for each layout type:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Precision - how well the predicted bboxes cover ground truth bboxes&lt;/li&gt; 
 &lt;li&gt;Recall - how well ground truth bboxes cover predicted bboxes&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Reading Order&lt;/h2&gt; 
&lt;p&gt;88% mean accuracy, and .4 seconds per image on an A10 GPU. See methodology for notes - this benchmark is not perfect measure of accuracy, and is more useful as a sanity check.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Methodology&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;I benchmarked the reading order on the layout dataset from &lt;a href="https://www.icst.pku.edu.cn/cpdp/sjzy/"&gt;here&lt;/a&gt;, which was not in the training data. Unfortunately, this dataset is fairly noisy, and not all the labels are correct. It was very hard to find a dataset annotated with reading order and also layout information. I wanted to avoid using a cloud service for the ground truth.&lt;/p&gt; 
&lt;p&gt;The accuracy is computed by finding if each pair of layout boxes is in the correct order, then taking the % that are correct.&lt;/p&gt; 
&lt;h2&gt;Table Recognition&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Model&lt;/th&gt; 
   &lt;th&gt;Row Intersection&lt;/th&gt; 
   &lt;th&gt;Col Intersection&lt;/th&gt; 
   &lt;th&gt;Time Per Image&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Surya&lt;/td&gt; 
   &lt;td&gt;1&lt;/td&gt; 
   &lt;td&gt;0.98625&lt;/td&gt; 
   &lt;td&gt;0.30202&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Table transformer&lt;/td&gt; 
   &lt;td&gt;0.84&lt;/td&gt; 
   &lt;td&gt;0.86857&lt;/td&gt; 
   &lt;td&gt;0.08082&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Higher is better for intersection, which the percentage of the actual row/column overlapped by the predictions. This benchmark is mostly a sanity check - there is a more rigorous one in &lt;a href="https://www.github.com/VikParuchuri/marker"&gt;marker&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Methodology&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;The benchmark uses a subset of &lt;a href="https://developer.ibm.com/exchanges/data/all/fintabnet/"&gt;Fintabnet&lt;/a&gt; from IBM. It has labeled rows and columns. After table recognition is run, the predicted rows and columns are compared to the ground truth. There is an additional penalty for predicting too many or too few rows/columns.&lt;/p&gt; 
&lt;h2&gt;LaTeX OCR&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Method&lt;/th&gt; 
   &lt;th&gt;edit â¬‡&lt;/th&gt; 
   &lt;th&gt;time taken (s) â¬‡&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;texify&lt;/td&gt; 
   &lt;td&gt;0.122617&lt;/td&gt; 
   &lt;td&gt;35.6345&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;This inferences texify on a ground truth set of LaTeX, then does edit distance. This is a bit noisy, since 2 LaTeX strings that render the same can have different symbols in them.&lt;/p&gt; 
&lt;h2&gt;Running your own benchmarks&lt;/h2&gt; 
&lt;p&gt;You can benchmark the performance of surya on your machine.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Follow the manual install instructions above.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;poetry install --group dev&lt;/code&gt; - installs dev dependencies&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Text line detection&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;This will evaluate tesseract and surya for text line detection across a randomly sampled set of images from &lt;a href="https://huggingface.co/datasets/vikp/doclaynet_bench"&gt;doclaynet&lt;/a&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;python benchmark/detection.py --max_rows 256
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;--max_rows&lt;/code&gt; controls how many images to process for the benchmark&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--debug&lt;/code&gt; will render images and detected bboxes&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--pdf_path&lt;/code&gt; will let you specify a pdf to benchmark instead of the default data&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--results_dir&lt;/code&gt; will let you specify a directory to save results to instead of the default one&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Text recognition&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;This will evaluate surya and optionally tesseract on multilingual pdfs from common crawl (with synthetic data for missing languages).&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;python benchmark/recognition.py --tesseract
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;--max_rows&lt;/code&gt; controls how many images to process for the benchmark&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;--debug 2&lt;/code&gt; will render images with detected text&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;--results_dir&lt;/code&gt; will let you specify a directory to save results to instead of the default one&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;--tesseract&lt;/code&gt; will run the benchmark with tesseract. You have to run &lt;code&gt;sudo apt-get install tesseract-ocr-all&lt;/code&gt; to install all tesseract data, and set &lt;code&gt;TESSDATA_PREFIX&lt;/code&gt; to the path to the tesseract data folder.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Set &lt;code&gt;RECOGNITION_BATCH_SIZE=864&lt;/code&gt; to use the same batch size as the benchmark.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Set &lt;code&gt;RECOGNITION_BENCH_DATASET_NAME=vikp/rec_bench_hist&lt;/code&gt; to use the historical document data for benchmarking. This data comes from the &lt;a href="https://github.com/HTR-United/tapuscorpus"&gt;tapuscorpus&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Layout analysis&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;This will evaluate surya on the publaynet dataset.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;python benchmark/layout.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;--max_rows&lt;/code&gt; controls how many images to process for the benchmark&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--debug&lt;/code&gt; will render images with detected text&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--results_dir&lt;/code&gt; will let you specify a directory to save results to instead of the default one&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Reading Order&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;python benchmark/ordering.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;--max_rows&lt;/code&gt; controls how many images to process for the benchmark&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--debug&lt;/code&gt; will render images with detected text&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--results_dir&lt;/code&gt; will let you specify a directory to save results to instead of the default one&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Table Recognition&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;python benchmark/table_recognition.py --max_rows 1024 --tatr
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;--max_rows&lt;/code&gt; controls how many images to process for the benchmark&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--debug&lt;/code&gt; will render images with detected text&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--results_dir&lt;/code&gt; will let you specify a directory to save results to instead of the default one&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--tatr&lt;/code&gt; specifies whether to also run table transformer&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;LaTeX OCR&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;python benchmark/texify.py --max_rows 128
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;--max_rows&lt;/code&gt; controls how many images to process for the benchmark&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--results_dir&lt;/code&gt; will let you specify a directory to save results to instead of the default one&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Training&lt;/h1&gt; 
&lt;p&gt;Text detection was trained on 4x A6000s for 3 days. It used a diverse set of images as training data. It was trained from scratch using a modified efficientvit architecture for semantic segmentation.&lt;/p&gt; 
&lt;p&gt;Text recognition was trained on 4x A6000s for 2 weeks. It was trained using a modified donut model (GQA, MoE layer, UTF-16 decoding, layer config changes).&lt;/p&gt; 
&lt;h1&gt;Finetuning Surya OCR&lt;/h1&gt; 
&lt;p&gt;You can now take Surya OCR further by training it on your own data with our &lt;a href="https://raw.githubusercontent.com/datalab-to/surya/master/surya/scripts/finetune_ocr.py"&gt;finetuning script&lt;/a&gt;. Itâ€™s built on Hugging Face Trainer, and supports all the &lt;a href="https://huggingface.co/docs/transformers/en/main_classes/trainer#transformers.TrainingArguments"&gt;arguments&lt;/a&gt; that the huggingface trainer provides, and integrations like torchrun, or deepspeed.&lt;/p&gt; 
&lt;p&gt;To setup your dataset, follow the example dataset format &lt;a href="https://huggingface.co/datasets/datalab-to/ocr_finetune_example"&gt;here&lt;/a&gt; and provide the path to your own dataset when launching the training script.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Tested on 1xH100 GPU
# Set --pretrained_checkpoint_path to load from a custom checkpoint, otherwise
# the default surya ocr weights will be loaded as the initialization
python surya/scripts/finetune_ocr.py \
  --output_dir $OUTPUT_DIR \
  --dataset_name datalab-to/ocr_finetune_example \
  --per_device_train_batch_size 64 \
  --gradient_checkpointing true \
  --max_sequence_length 1024
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This is a minimal training script to get you started finetuning Surya. Our internal training stack includes character bounding box finetuning, sliding window attention with specialized attention masks, custom kernels, augmentations, and other optimizations that can push OCR accuracy well beyond standard finetuning. If you want to get the most out of your data, reach us at &lt;a href="mailto:hi@datalab.to"&gt;hi@datalab.to&lt;/a&gt;!&lt;/p&gt; 
&lt;h1&gt;Thanks&lt;/h1&gt; 
&lt;p&gt;This work would not have been possible without amazing open source AI work:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://arxiv.org/pdf/2105.15203.pdf"&gt;Segformer&lt;/a&gt; from NVIDIA&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mit-han-lab/efficientvit"&gt;EfficientViT&lt;/a&gt; from MIT&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/huggingface/pytorch-image-models"&gt;timm&lt;/a&gt; from Ross Wightman&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/clovaai/donut"&gt;Donut&lt;/a&gt; from Naver&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/huggingface/transformers"&gt;transformers&lt;/a&gt; from huggingface&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/clovaai/CRAFT-pytorch"&gt;CRAFT&lt;/a&gt;, a great scene text detection model&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Thank you to everyone who makes open source AI possible.&lt;/p&gt; 
&lt;h1&gt;Citation&lt;/h1&gt; 
&lt;p&gt;If you use surya (or the associated models) in your work or research, please consider citing us using the following BibTeX entry:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bibtex"&gt;@misc{paruchuri2025surya,
  author       = {Vikas Paruchuri and Datalab Team},
  title        = {Surya: A lightweight document OCR and analysis toolkit},
  year         = {2025},
  howpublished = {\url{https://github.com/VikParuchuri/surya}},
  note         = {GitHub repository},
}
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>comfyanonymous/ComfyUI</title>
      <link>https://github.com/comfyanonymous/ComfyUI</link>
      <description>&lt;p&gt;The most powerful and modular diffusion model GUI, api and backend with a graph/nodes interface.&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;h1&gt;ComfyUI&lt;/h1&gt; 
 &lt;p&gt;&lt;strong&gt;The most powerful and modular visual AI engine and application.&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://www.comfy.org/"&gt;&lt;img src="https://img.shields.io/badge/ComfyOrg-4285F4?style=flat" alt="Website" /&gt;&lt;/a&gt; &lt;a href="https://www.comfy.org/discord"&gt;&lt;img src="https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fdiscord.com%2Fapi%2Finvites%2Fcomfyorg%3Fwith_counts%3Dtrue&amp;amp;query=%24.approximate_member_count&amp;amp;logo=discord&amp;amp;logoColor=white&amp;amp;label=Discord&amp;amp;color=green&amp;amp;suffix=%20total" alt="Dynamic JSON Badge" /&gt;&lt;/a&gt; &lt;a href="https://x.com/ComfyUI"&gt;&lt;img src="https://img.shields.io/twitter/follow/ComfyUI" alt="Twitter" /&gt;&lt;/a&gt; &lt;a href="https://app.element.io/#/room/%23comfyui_space%3Amatrix.org"&gt;&lt;img src="https://img.shields.io/badge/Matrix-000000?style=flat&amp;amp;logo=matrix&amp;amp;logoColor=white" alt="Matrix" /&gt;&lt;/a&gt; &lt;br /&gt; &lt;a href="https://github.com/comfyanonymous/ComfyUI/releases"&gt;&lt;img src="https://img.shields.io/github/v/release/comfyanonymous/ComfyUI?style=flat&amp;amp;sort=semver" alt="" /&gt;&lt;/a&gt; &lt;a href="https://github.com/comfyanonymous/ComfyUI/releases"&gt;&lt;img src="https://img.shields.io/github/release-date/comfyanonymous/ComfyUI?style=flat" alt="" /&gt;&lt;/a&gt; &lt;a href="https://github.com/comfyanonymous/ComfyUI/releases"&gt;&lt;img src="https://img.shields.io/github/downloads/comfyanonymous/ComfyUI/total?style=flat" alt="" /&gt;&lt;/a&gt; &lt;a href="https://github.com/comfyanonymous/ComfyUI/releases"&gt;&lt;img src="https://img.shields.io/github/downloads/comfyanonymous/ComfyUI/latest/total?style=flat&amp;amp;label=downloads%40latest" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;!-- Workaround to display total user from https://github.com/badges/shields/issues/4500#issuecomment-2060079995 --&gt; 
 &lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/7ccaf2c1-9b72-41ae-9a89-5688c94b7abe" alt="ComfyUI Screenshot" /&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;ComfyUI lets you design and execute advanced stable diffusion pipelines using a graph/nodes/flowchart based interface. Available on Windows, Linux, and macOS.&lt;/p&gt; 
&lt;h2&gt;Get Started&lt;/h2&gt; 
&lt;h4&gt;&lt;a href="https://www.comfy.org/download"&gt;Desktop Application&lt;/a&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;The easiest way to get started.&lt;/li&gt; 
 &lt;li&gt;Available on Windows &amp;amp; macOS.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;&lt;a href="https://raw.githubusercontent.com/comfyanonymous/ComfyUI/master/#installing"&gt;Windows Portable Package&lt;/a&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Get the latest commits and completely portable.&lt;/li&gt; 
 &lt;li&gt;Available on Windows.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;&lt;a href="https://raw.githubusercontent.com/comfyanonymous/ComfyUI/master/#manual-install-windows-linux"&gt;Manual Install&lt;/a&gt;&lt;/h4&gt; 
&lt;p&gt;Supports all operating systems and GPU types (NVIDIA, AMD, Intel, Apple Silicon, Ascend).&lt;/p&gt; 
&lt;h2&gt;&lt;a href="https://comfyanonymous.github.io/ComfyUI_examples/"&gt;Examples&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;See what ComfyUI can do with the &lt;a href="https://comfyanonymous.github.io/ComfyUI_examples/"&gt;example workflows&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Nodes/graph/flowchart interface to experiment and create complex Stable Diffusion workflows without needing to code anything.&lt;/li&gt; 
 &lt;li&gt;Image Models 
  &lt;ul&gt; 
   &lt;li&gt;SD1.x, SD2.x (&lt;a href="https://comfyanonymous.github.io/ComfyUI_examples/unclip/"&gt;unCLIP&lt;/a&gt;)&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://comfyanonymous.github.io/ComfyUI_examples/sdxl/"&gt;SDXL&lt;/a&gt;, &lt;a href="https://comfyanonymous.github.io/ComfyUI_examples/sdturbo/"&gt;SDXL Turbo&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://comfyanonymous.github.io/ComfyUI_examples/stable_cascade/"&gt;Stable Cascade&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://comfyanonymous.github.io/ComfyUI_examples/sd3/"&gt;SD3 and SD3.5&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;Pixart Alpha and Sigma&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://comfyanonymous.github.io/ComfyUI_examples/aura_flow/"&gt;AuraFlow&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://comfyanonymous.github.io/ComfyUI_examples/hunyuan_dit/"&gt;HunyuanDiT&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://comfyanonymous.github.io/ComfyUI_examples/flux/"&gt;Flux&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://comfyanonymous.github.io/ComfyUI_examples/lumina2/"&gt;Lumina Image 2.0&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://comfyanonymous.github.io/ComfyUI_examples/hidream/"&gt;HiDream&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://comfyanonymous.github.io/ComfyUI_examples/qwen_image/"&gt;Qwen Image&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Image Editing Models 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://comfyanonymous.github.io/ComfyUI_examples/omnigen/"&gt;Omnigen 2&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://comfyanonymous.github.io/ComfyUI_examples/flux/#flux-kontext-image-editing-model"&gt;Flux Kontext&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://comfyanonymous.github.io/ComfyUI_examples/hidream/#hidream-e11"&gt;HiDream E1.1&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://comfyanonymous.github.io/ComfyUI_examples/qwen_image/#edit-model"&gt;Qwen Image Edit&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Video Models 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://comfyanonymous.github.io/ComfyUI_examples/video/"&gt;Stable Video Diffusion&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://comfyanonymous.github.io/ComfyUI_examples/mochi/"&gt;Mochi&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://comfyanonymous.github.io/ComfyUI_examples/ltxv/"&gt;LTX-Video&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://comfyanonymous.github.io/ComfyUI_examples/hunyuan_video/"&gt;Hunyuan Video&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://comfyanonymous.github.io/ComfyUI_examples/wan/"&gt;Wan 2.1&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://comfyanonymous.github.io/ComfyUI_examples/wan22/"&gt;Wan 2.2&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Audio Models 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://comfyanonymous.github.io/ComfyUI_examples/audio/"&gt;Stable Audio&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://comfyanonymous.github.io/ComfyUI_examples/audio/"&gt;ACE Step&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;3D Models 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://docs.comfy.org/tutorials/3d/hunyuan3D-2"&gt;Hunyuan3D 2.0&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Asynchronous Queue system&lt;/li&gt; 
 &lt;li&gt;Many optimizations: Only re-executes the parts of the workflow that changes between executions.&lt;/li&gt; 
 &lt;li&gt;Smart memory management: can automatically run large models on GPUs with as low as 1GB vram with smart offloading.&lt;/li&gt; 
 &lt;li&gt;Works even if you don't have a GPU with: &lt;code&gt;--cpu&lt;/code&gt; (slow)&lt;/li&gt; 
 &lt;li&gt;Can load ckpt and safetensors: All in one checkpoints or standalone diffusion models, VAEs and CLIP models.&lt;/li&gt; 
 &lt;li&gt;Safe loading of ckpt, pt, pth, etc.. files.&lt;/li&gt; 
 &lt;li&gt;Embeddings/Textual inversion&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://comfyanonymous.github.io/ComfyUI_examples/lora/"&gt;Loras (regular, locon and loha)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://comfyanonymous.github.io/ComfyUI_examples/hypernetworks/"&gt;Hypernetworks&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Loading full workflows (with seeds) from generated PNG, WebP and FLAC files.&lt;/li&gt; 
 &lt;li&gt;Saving/Loading workflows as Json files.&lt;/li&gt; 
 &lt;li&gt;Nodes interface can be used to create complex workflows like one for &lt;a href="https://comfyanonymous.github.io/ComfyUI_examples/2_pass_txt2img/"&gt;Hires fix&lt;/a&gt; or much more advanced ones.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://comfyanonymous.github.io/ComfyUI_examples/area_composition/"&gt;Area Composition&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://comfyanonymous.github.io/ComfyUI_examples/inpaint/"&gt;Inpainting&lt;/a&gt; with both regular and inpainting models.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://comfyanonymous.github.io/ComfyUI_examples/controlnet/"&gt;ControlNet and T2I-Adapter&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://comfyanonymous.github.io/ComfyUI_examples/upscale_models/"&gt;Upscale Models (ESRGAN, ESRGAN variants, SwinIR, Swin2SR, etc...)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://comfyanonymous.github.io/ComfyUI_examples/gligen/"&gt;GLIGEN&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://comfyanonymous.github.io/ComfyUI_examples/model_merging/"&gt;Model Merging&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://comfyanonymous.github.io/ComfyUI_examples/lcm/"&gt;LCM models and Loras&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Latent previews with &lt;a href="https://raw.githubusercontent.com/comfyanonymous/ComfyUI/master/#how-to-show-high-quality-previews"&gt;TAESD&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Works fully offline: core will never download anything unless you want to.&lt;/li&gt; 
 &lt;li&gt;Optional API nodes to use paid models from external providers through the online &lt;a href="https://docs.comfy.org/tutorials/api-nodes/overview"&gt;Comfy API&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/comfyanonymous/ComfyUI/master/extra_model_paths.yaml.example"&gt;Config file&lt;/a&gt; to set the search paths for models.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Workflow examples can be found on the &lt;a href="https://comfyanonymous.github.io/ComfyUI_examples/"&gt;Examples page&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Release Process&lt;/h2&gt; 
&lt;p&gt;ComfyUI follows a weekly release cycle targeting Friday but this regularly changes because of model releases or large changes to the codebase. There are three interconnected repositories:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://github.com/comfyanonymous/ComfyUI"&gt;ComfyUI Core&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Releases a new stable version (e.g., v0.7.0)&lt;/li&gt; 
   &lt;li&gt;Serves as the foundation for the desktop release&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://github.com/Comfy-Org/desktop"&gt;ComfyUI Desktop&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Builds a new release using the latest stable core version&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://github.com/Comfy-Org/ComfyUI_frontend"&gt;ComfyUI Frontend&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Weekly frontend updates are merged into the core repository&lt;/li&gt; 
   &lt;li&gt;Features are frozen for the upcoming core release&lt;/li&gt; 
   &lt;li&gt;Development continues for the next release cycle&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Shortcuts&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Keybind&lt;/th&gt; 
   &lt;th&gt;Explanation&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;Ctrl&lt;/code&gt; + &lt;code&gt;Enter&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Queue up current graph for generation&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;Ctrl&lt;/code&gt; + &lt;code&gt;Shift&lt;/code&gt; + &lt;code&gt;Enter&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Queue up current graph as first for generation&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;Ctrl&lt;/code&gt; + &lt;code&gt;Alt&lt;/code&gt; + &lt;code&gt;Enter&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Cancel current generation&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;Ctrl&lt;/code&gt; + &lt;code&gt;Z&lt;/code&gt;/&lt;code&gt;Ctrl&lt;/code&gt; + &lt;code&gt;Y&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Undo/Redo&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;Ctrl&lt;/code&gt; + &lt;code&gt;S&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Save workflow&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;Ctrl&lt;/code&gt; + &lt;code&gt;O&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Load workflow&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;Ctrl&lt;/code&gt; + &lt;code&gt;A&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Select all nodes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;Alt &lt;/code&gt;+ &lt;code&gt;C&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Collapse/uncollapse selected nodes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;Ctrl&lt;/code&gt; + &lt;code&gt;M&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Mute/unmute selected nodes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;Ctrl&lt;/code&gt; + &lt;code&gt;B&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Bypass selected nodes (acts like the node was removed from the graph and the wires reconnected through)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;Delete&lt;/code&gt;/&lt;code&gt;Backspace&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Delete selected nodes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;Ctrl&lt;/code&gt; + &lt;code&gt;Backspace&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Delete the current graph&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;Space&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Move the canvas around when held and moving the cursor&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;Ctrl&lt;/code&gt;/&lt;code&gt;Shift&lt;/code&gt; + &lt;code&gt;Click&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Add clicked node to selection&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;Ctrl&lt;/code&gt; + &lt;code&gt;C&lt;/code&gt;/&lt;code&gt;Ctrl&lt;/code&gt; + &lt;code&gt;V&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Copy and paste selected nodes (without maintaining connections to outputs of unselected nodes)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;Ctrl&lt;/code&gt; + &lt;code&gt;C&lt;/code&gt;/&lt;code&gt;Ctrl&lt;/code&gt; + &lt;code&gt;Shift&lt;/code&gt; + &lt;code&gt;V&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Copy and paste selected nodes (maintaining connections from outputs of unselected nodes to inputs of pasted nodes)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;Shift&lt;/code&gt; + &lt;code&gt;Drag&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Move multiple selected nodes at the same time&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;Ctrl&lt;/code&gt; + &lt;code&gt;D&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Load default graph&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;Alt&lt;/code&gt; + &lt;code&gt;+&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Canvas Zoom in&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;Alt&lt;/code&gt; + &lt;code&gt;-&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Canvas Zoom out&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;Ctrl&lt;/code&gt; + &lt;code&gt;Shift&lt;/code&gt; + LMB + Vertical drag&lt;/td&gt; 
   &lt;td&gt;Canvas Zoom in/out&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;P&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Pin/Unpin selected nodes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;Ctrl&lt;/code&gt; + &lt;code&gt;G&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Group selected nodes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;Q&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Toggle visibility of the queue&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;H&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Toggle visibility of history&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;R&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Refresh graph&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;F&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Show/Hide menu&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;.&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Fit view to selection (Whole graph when nothing is selected)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Double-Click LMB&lt;/td&gt; 
   &lt;td&gt;Open node quick search palette&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;Shift&lt;/code&gt; + Drag&lt;/td&gt; 
   &lt;td&gt;Move multiple wires at once&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;Ctrl&lt;/code&gt; + &lt;code&gt;Alt&lt;/code&gt; + LMB&lt;/td&gt; 
   &lt;td&gt;Disconnect all wires from clicked slot&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;code&gt;Ctrl&lt;/code&gt; can also be replaced with &lt;code&gt;Cmd&lt;/code&gt; instead for macOS users&lt;/p&gt; 
&lt;h1&gt;Installing&lt;/h1&gt; 
&lt;h2&gt;Windows Portable&lt;/h2&gt; 
&lt;p&gt;There is a portable standalone build for Windows that should work for running on Nvidia GPUs or for running on your CPU only on the &lt;a href="https://github.com/comfyanonymous/ComfyUI/releases"&gt;releases page&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;&lt;a href="https://github.com/comfyanonymous/ComfyUI/releases/latest/download/ComfyUI_windows_portable_nvidia.7z"&gt;Direct link to download&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;Simply download, extract with &lt;a href="https://7-zip.org"&gt;7-Zip&lt;/a&gt; and run. Make sure you put your Stable Diffusion checkpoints/models (the huge ckpt/safetensors files) in: ComfyUI\models\checkpoints&lt;/p&gt; 
&lt;p&gt;If you have trouble extracting it, right click the file -&amp;gt; properties -&amp;gt; unblock&lt;/p&gt; 
&lt;h4&gt;How do I share models between another UI and ComfyUI?&lt;/h4&gt; 
&lt;p&gt;See the &lt;a href="https://raw.githubusercontent.com/comfyanonymous/ComfyUI/master/extra_model_paths.yaml.example"&gt;Config file&lt;/a&gt; to set the search paths for models. In the standalone windows build you can find this file in the ComfyUI directory. Rename this file to extra_model_paths.yaml and edit it with your favorite text editor.&lt;/p&gt; 
&lt;h2&gt;&lt;a href="https://docs.comfy.org/comfy-cli/getting-started"&gt;comfy-cli&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;You can install and start ComfyUI using comfy-cli:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install comfy-cli
comfy install
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Manual Install (Windows, Linux)&lt;/h2&gt; 
&lt;p&gt;Python 3.13 is very well supported. If you have trouble with some custom node dependencies you can try 3.12&lt;/p&gt; 
&lt;p&gt;Git clone this repo.&lt;/p&gt; 
&lt;p&gt;Put your SD checkpoints (the huge ckpt/safetensors files) in: models/checkpoints&lt;/p&gt; 
&lt;p&gt;Put your VAE in: models/vae&lt;/p&gt; 
&lt;h3&gt;AMD GPUs (Linux only)&lt;/h3&gt; 
&lt;p&gt;AMD users can install rocm and pytorch with pip if you don't have it already installed, this is the command to install the stable version:&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/rocm6.4&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;This is the command to install the nightly with ROCm 6.4 which might have some performance improvements:&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;pip install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/rocm6.4&lt;/code&gt;&lt;/p&gt; 
&lt;h3&gt;Intel GPUs (Windows and Linux)&lt;/h3&gt; 
&lt;p&gt;(Option 1) Intel Arc GPU users can install native PyTorch with torch.xpu support using pip. More information can be found &lt;a href="https://pytorch.org/docs/main/notes/get_start_xpu.html"&gt;here&lt;/a&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;To install PyTorch xpu, use the following command:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;code&gt;pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/xpu&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;This is the command to install the Pytorch xpu nightly which might have some performance improvements:&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;pip install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/xpu&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;(Option 2) Alternatively, Intel GPUs supported by Intel Extension for PyTorch (IPEX) can leverage IPEX for improved performance.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;visit &lt;a href="https://intel.github.io/intel-extension-for-pytorch/index.html#installation?platform=gpu"&gt;Installation&lt;/a&gt; for more information.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;NVIDIA&lt;/h3&gt; 
&lt;p&gt;Nvidia users should install stable pytorch using this command:&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu129&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;This is the command to install pytorch nightly instead which might have performance improvements.&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;pip install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cu129&lt;/code&gt;&lt;/p&gt; 
&lt;h4&gt;Troubleshooting&lt;/h4&gt; 
&lt;p&gt;If you get the "Torch not compiled with CUDA enabled" error, uninstall torch with:&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;pip uninstall torch&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;And install it again with the command above.&lt;/p&gt; 
&lt;h3&gt;Dependencies&lt;/h3&gt; 
&lt;p&gt;Install the dependencies by opening your terminal inside the ComfyUI folder and:&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;pip install -r requirements.txt&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;After this you should have everything installed and can proceed to running ComfyUI.&lt;/p&gt; 
&lt;h3&gt;Others:&lt;/h3&gt; 
&lt;h4&gt;Apple Mac silicon&lt;/h4&gt; 
&lt;p&gt;You can install ComfyUI in Apple Mac silicon (M1 or M2) with any recent macOS version.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Install pytorch nightly. For instructions, read the &lt;a href="https://developer.apple.com/metal/pytorch/"&gt;Accelerated PyTorch training on Mac&lt;/a&gt; Apple Developer guide (make sure to install the latest pytorch nightly).&lt;/li&gt; 
 &lt;li&gt;Follow the &lt;a href="https://raw.githubusercontent.com/comfyanonymous/ComfyUI/master/#manual-install-windows-linux"&gt;ComfyUI manual installation&lt;/a&gt; instructions for Windows and Linux.&lt;/li&gt; 
 &lt;li&gt;Install the ComfyUI &lt;a href="https://raw.githubusercontent.com/comfyanonymous/ComfyUI/master/#dependencies"&gt;dependencies&lt;/a&gt;. If you have another Stable Diffusion UI &lt;a href="https://raw.githubusercontent.com/comfyanonymous/ComfyUI/master/#i-already-have-another-ui-for-stable-diffusion-installed-do-i-really-have-to-install-all-of-these-dependencies"&gt;you might be able to reuse the dependencies&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Launch ComfyUI by running &lt;code&gt;python main.py&lt;/code&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: Remember to add your models, VAE, LoRAs etc. to the corresponding Comfy folders, as discussed in &lt;a href="https://raw.githubusercontent.com/comfyanonymous/ComfyUI/master/#manual-install-windows-linux"&gt;ComfyUI manual installation&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;DirectML (AMD Cards on Windows)&lt;/h4&gt; 
&lt;p&gt;This is very badly supported and is not recommended. There are some unofficial builds of pytorch ROCm on windows that exist that will give you a much better experience than this. This readme will be updated once official pytorch ROCm builds for windows come out.&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;pip install torch-directml&lt;/code&gt; Then you can launch ComfyUI with: &lt;code&gt;python main.py --directml&lt;/code&gt;&lt;/p&gt; 
&lt;h4&gt;Ascend NPUs&lt;/h4&gt; 
&lt;p&gt;For models compatible with Ascend Extension for PyTorch (torch_npu). To get started, ensure your environment meets the prerequisites outlined on the &lt;a href="https://ascend.github.io/docs/sources/ascend/quick_install.html"&gt;installation&lt;/a&gt; page. Here's a step-by-step guide tailored to your platform and installation method:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Begin by installing the recommended or newer kernel version for Linux as specified in the Installation page of torch-npu, if necessary.&lt;/li&gt; 
 &lt;li&gt;Proceed with the installation of Ascend Basekit, which includes the driver, firmware, and CANN, following the instructions provided for your specific platform.&lt;/li&gt; 
 &lt;li&gt;Next, install the necessary packages for torch-npu by adhering to the platform-specific instructions on the &lt;a href="https://ascend.github.io/docs/sources/pytorch/install.html#pytorch"&gt;Installation&lt;/a&gt; page.&lt;/li&gt; 
 &lt;li&gt;Finally, adhere to the &lt;a href="https://raw.githubusercontent.com/comfyanonymous/ComfyUI/master/#manual-install-windows-linux"&gt;ComfyUI manual installation&lt;/a&gt; guide for Linux. Once all components are installed, you can run ComfyUI as described earlier.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Cambricon MLUs&lt;/h4&gt; 
&lt;p&gt;For models compatible with Cambricon Extension for PyTorch (torch_mlu). Here's a step-by-step guide tailored to your platform and installation method:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Install the Cambricon CNToolkit by adhering to the platform-specific instructions on the &lt;a href="https://www.cambricon.com/docs/sdk_1.15.0/cntoolkit_3.7.2/cntoolkit_install_3.7.2/index.html"&gt;Installation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Next, install the PyTorch(torch_mlu) following the instructions on the &lt;a href="https://www.cambricon.com/docs/sdk_1.15.0/cambricon_pytorch_1.17.0/user_guide_1.9/index.html"&gt;Installation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Launch ComfyUI by running &lt;code&gt;python main.py&lt;/code&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Iluvatar Corex&lt;/h4&gt; 
&lt;p&gt;For models compatible with Iluvatar Extension for PyTorch. Here's a step-by-step guide tailored to your platform and installation method:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Install the Iluvatar Corex Toolkit by adhering to the platform-specific instructions on the &lt;a href="https://support.iluvatar.com/#/DocumentCentre?id=1&amp;amp;nameCenter=2&amp;amp;productId=520117912052801536"&gt;Installation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Launch ComfyUI by running &lt;code&gt;python main.py&lt;/code&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h1&gt;Running&lt;/h1&gt; 
&lt;p&gt;&lt;code&gt;python main.py&lt;/code&gt;&lt;/p&gt; 
&lt;h3&gt;For AMD cards not officially supported by ROCm&lt;/h3&gt; 
&lt;p&gt;Try running it with this command if you have issues:&lt;/p&gt; 
&lt;p&gt;For 6700, 6600 and maybe other RDNA2 or older: &lt;code&gt;HSA_OVERRIDE_GFX_VERSION=10.3.0 python main.py&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;For AMD 7600 and maybe other RDNA3 cards: &lt;code&gt;HSA_OVERRIDE_GFX_VERSION=11.0.0 python main.py&lt;/code&gt;&lt;/p&gt; 
&lt;h3&gt;AMD ROCm Tips&lt;/h3&gt; 
&lt;p&gt;You can enable experimental memory efficient attention on recent pytorch in ComfyUI on some AMD GPUs using this command, it should already be enabled by default on RDNA3. If this improves speed for you on latest pytorch on your GPU please report it so that I can enable it by default.&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;TORCH_ROCM_AOTRITON_ENABLE_EXPERIMENTAL=1 python main.py --use-pytorch-cross-attention&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;You can also try setting this env variable &lt;code&gt;PYTORCH_TUNABLEOP_ENABLED=1&lt;/code&gt; which might speed things up at the cost of a very slow initial run.&lt;/p&gt; 
&lt;h1&gt;Notes&lt;/h1&gt; 
&lt;p&gt;Only parts of the graph that have an output with all the correct inputs will be executed.&lt;/p&gt; 
&lt;p&gt;Only parts of the graph that change from each execution to the next will be executed, if you submit the same graph twice only the first will be executed. If you change the last part of the graph only the part you changed and the part that depends on it will be executed.&lt;/p&gt; 
&lt;p&gt;Dragging a generated png on the webpage or loading one will give you the full workflow including seeds that were used to create it.&lt;/p&gt; 
&lt;p&gt;You can use () to change emphasis of a word or phrase like: (good code:1.2) or (bad code:0.8). The default emphasis for () is 1.1. To use () characters in your actual prompt escape them like \( or \).&lt;/p&gt; 
&lt;p&gt;You can use {day|night}, for wildcard/dynamic prompts. With this syntax "{wild|card|test}" will be randomly replaced by either "wild", "card" or "test" by the frontend every time you queue the prompt. To use {} characters in your actual prompt escape them like: \{ or \}.&lt;/p&gt; 
&lt;p&gt;Dynamic prompts also support C-style comments, like &lt;code&gt;// comment&lt;/code&gt; or &lt;code&gt;/* comment */&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;To use a textual inversion concepts/embeddings in a text prompt put them in the models/embeddings directory and use them in the CLIPTextEncode node like this (you can omit the .pt extension):&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;embedding:embedding_filename.pt&lt;/code&gt;&lt;/p&gt; 
&lt;h2&gt;How to show high-quality previews?&lt;/h2&gt; 
&lt;p&gt;Use &lt;code&gt;--preview-method auto&lt;/code&gt; to enable previews.&lt;/p&gt; 
&lt;p&gt;The default installation includes a fast latent preview method that's low-resolution. To enable higher-quality previews with &lt;a href="https://github.com/madebyollin/taesd"&gt;TAESD&lt;/a&gt;, download the &lt;a href="https://github.com/madebyollin/taesd/"&gt;taesd_decoder.pth, taesdxl_decoder.pth, taesd3_decoder.pth and taef1_decoder.pth&lt;/a&gt; and place them in the &lt;code&gt;models/vae_approx&lt;/code&gt; folder. Once they're installed, restart ComfyUI and launch it with &lt;code&gt;--preview-method taesd&lt;/code&gt; to enable high-quality previews.&lt;/p&gt; 
&lt;h2&gt;How to use TLS/SSL?&lt;/h2&gt; 
&lt;p&gt;Generate a self-signed certificate (not appropriate for shared/production use) and key by running the command: &lt;code&gt;openssl req -x509 -newkey rsa:4096 -keyout key.pem -out cert.pem -sha256 -days 3650 -nodes -subj "/C=XX/ST=StateName/L=CityName/O=CompanyName/OU=CompanySectionName/CN=CommonNameOrHostname"&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;Use &lt;code&gt;--tls-keyfile key.pem --tls-certfile cert.pem&lt;/code&gt; to enable TLS/SSL, the app will now be accessible with &lt;code&gt;https://...&lt;/code&gt; instead of &lt;code&gt;http://...&lt;/code&gt;.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Note: Windows users can use &lt;a href="https://github.com/alexisrolland/docker-openssl"&gt;alexisrolland/docker-openssl&lt;/a&gt; or one of the &lt;a href="https://wiki.openssl.org/index.php/Binaries"&gt;3rd party binary distributions&lt;/a&gt; to run the command example above. &lt;br /&gt;&lt;br /&gt;If you use a container, note that the volume mount &lt;code&gt;-v&lt;/code&gt; can be a relative path so &lt;code&gt;... -v ".\:/openssl-certs" ...&lt;/code&gt; would create the key &amp;amp; cert files in the current directory of your command prompt or powershell terminal.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Support and dev channel&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://comfy.org/discord"&gt;Discord&lt;/a&gt;: Try the #help or #feedback channels.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://app.element.io/#/room/%23comfyui_space%3Amatrix.org"&gt;Matrix space: #comfyui_space:matrix.org&lt;/a&gt; (it's like discord but open source).&lt;/p&gt; 
&lt;p&gt;See also: &lt;a href="https://www.comfy.org/"&gt;https://www.comfy.org/&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Frontend Development&lt;/h2&gt; 
&lt;p&gt;As of August 15, 2024, we have transitioned to a new frontend, which is now hosted in a separate repository: &lt;a href="https://github.com/Comfy-Org/ComfyUI_frontend"&gt;ComfyUI Frontend&lt;/a&gt;. This repository now hosts the compiled JS (from TS/Vue) under the &lt;code&gt;web/&lt;/code&gt; directory.&lt;/p&gt; 
&lt;h3&gt;Reporting Issues and Requesting Features&lt;/h3&gt; 
&lt;p&gt;For any bugs, issues, or feature requests related to the frontend, please use the &lt;a href="https://github.com/Comfy-Org/ComfyUI_frontend"&gt;ComfyUI Frontend repository&lt;/a&gt;. This will help us manage and address frontend-specific concerns more efficiently.&lt;/p&gt; 
&lt;h3&gt;Using the Latest Frontend&lt;/h3&gt; 
&lt;p&gt;The new frontend is now the default for ComfyUI. However, please note:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;The frontend in the main ComfyUI repository is updated fortnightly.&lt;/li&gt; 
 &lt;li&gt;Daily releases are available in the separate frontend repository.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;To use the most up-to-date frontend version:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;For the latest daily release, launch ComfyUI with this command line argument:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;--front-end-version Comfy-Org/ComfyUI_frontend@latest
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;For a specific version, replace &lt;code&gt;latest&lt;/code&gt; with the desired version number:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;--front-end-version Comfy-Org/ComfyUI_frontend@1.2.2
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;This approach allows you to easily switch between the stable fortnightly release and the cutting-edge daily updates, or even specific versions for testing purposes.&lt;/p&gt; 
&lt;h3&gt;Accessing the Legacy Frontend&lt;/h3&gt; 
&lt;p&gt;If you need to use the legacy frontend for any reason, you can access it using the following command line argument:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;--front-end-version Comfy-Org/ComfyUI_legacy_frontend@latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This will use a snapshot of the legacy frontend preserved in the &lt;a href="https://github.com/Comfy-Org/ComfyUI_legacy_frontend"&gt;ComfyUI Legacy Frontend repository&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;QA&lt;/h1&gt; 
&lt;h3&gt;Which GPU should I buy for this?&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://github.com/comfyanonymous/ComfyUI/wiki/Which-GPU-should-I-buy-for-ComfyUI"&gt;See this page for some recommendations&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>