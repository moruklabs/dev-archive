<rss version="2.0">
  <channel>
    <title>GitHub Python Daily Trending</title>
    <description>Daily Trending of Python in GitHub</description>
    <pubDate>Tue, 11 Nov 2025 01:37:59 GMT</pubDate>
    <link>http://mshibanami.github.io/GitHubTrendingRSS</link>
    
    <item>
      <title>Blaizzy/mlx-audio</title>
      <link>https://github.com/Blaizzy/mlx-audio</link>
      <description>&lt;p&gt;A text-to-speech (TTS), speech-to-text (STT) and speech-to-speech (STS) library built on Apple's MLX framework, providing efficient speech analysis on Apple Silicon.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;MLX-Audio&lt;/h1&gt; 
&lt;p&gt;A text-to-speech (TTS) and Speech-to-Speech (STS) library built on Apple's MLX framework, providing efficient speech synthesis on Apple Silicon.&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Fast inference on Apple Silicon (M series chips)&lt;/li&gt; 
 &lt;li&gt;Multiple language support&lt;/li&gt; 
 &lt;li&gt;Voice customization options&lt;/li&gt; 
 &lt;li&gt;Adjustable speech speed control (0.5x to 2.0x)&lt;/li&gt; 
 &lt;li&gt;Interactive web interface with 3D audio visualization&lt;/li&gt; 
 &lt;li&gt;REST API for TTS generation&lt;/li&gt; 
 &lt;li&gt;Quantization support for optimized performance&lt;/li&gt; 
 &lt;li&gt;Direct access to output files via Finder/Explorer integration&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Install the package
pip install mlx-audio

# For web interface and API dependencies
pip install -r requirements.txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Quick Start&lt;/h3&gt; 
&lt;p&gt;To generate audio with an LLM use:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Basic usage
mlx_audio.tts.generate --text "Hello, world"

# Specify prefix for output file
mlx_audio.tts.generate --text "Hello, world" --file_prefix hello

# Adjust speaking speed (0.5-2.0)
mlx_audio.tts.generate --text "Hello, world" --speed 1.4
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;How to call from python&lt;/h3&gt; 
&lt;p&gt;To generate audio with an LLM use:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from mlx_audio.tts.generate import generate_audio

# Example: Generate an audiobook chapter as mp3 audio
generate_audio(
    text=("In the beginning, the universe was created...\n"
        "...or the simulation was booted up."),
    model_path="prince-canuma/Kokoro-82M",
    voice="af_heart",
    speed=1.2,
    lang_code="a", # Kokoro: (a)f_heart, or comment out for auto
    file_prefix="audiobook_chapter1",
    audio_format="wav",
    sample_rate=24000,
    join_audio=True,
    verbose=True  # Set to False to disable print messages
)

print("Audiobook chapter successfully generated!")

&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Web Interface &amp;amp; FastAPI Server&lt;/h3&gt; 
&lt;p&gt;MLX-Audio provides a modern web interface with real-time audio visualization capabilities. The interface offers:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Text-to-Speech generation with customizable voices and parameters&lt;/li&gt; 
 &lt;li&gt;Speech-to-Text transcription with support for multiple languages&lt;/li&gt; 
 &lt;li&gt;Audio file upload and playback functionality&lt;/li&gt; 
 &lt;li&gt;Interactive 3D audio visualization&lt;/li&gt; 
 &lt;li&gt;Automatic audio file management in the outputs directory&lt;/li&gt; 
 &lt;li&gt;Direct access to the output folder from the interface (local deployment only)&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Key Features&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Voice Customization&lt;/strong&gt;: Select from multiple voice presets including AF Heart, AF Nova, AF Bella, and BF Emma&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Speech Rate Control&lt;/strong&gt;: Fine-tune speech generation speed using an intuitive slider (range: 0.5x - 2.0x)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Dynamic 3D Visualization&lt;/strong&gt;: Experience audio through an interactive 3D orb that responds to frequency changes&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Audio Management&lt;/strong&gt;: Upload, play, and visualize custom audio files&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Smart Playback&lt;/strong&gt;: Optional automatic playback of generated audio&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;File Management&lt;/strong&gt;: Quick access to the output directory through an integrated file explorer button&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Speech Recognition&lt;/strong&gt;: Convert speech to text with support for multiple languages and models To start the web interface and API server:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;UI:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Configure the API base URL and port
export NEXT_PUBLIC_API_BASE_URL=http://localhost
export NEXT_PUBLIC_API_PORT=8000

# Start UI server
cd mlx_audio/ui
npm run dev
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Server:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Using the command-line interface
mlx_audio.server

# With custom host and port
mlx_audio.server --host 0.0.0.0 --port 9000

# With verbose logging
mlx_audio.server --verbose
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Available command line arguments:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;--host&lt;/code&gt;: Host address to bind the server to (default: 127.0.0.1)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--port&lt;/code&gt;: Port to bind the server to (default: 8000)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Then open your browser and navigate to:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;http://127.0.0.1:8000
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;API Endpoints&lt;/h4&gt; 
&lt;p&gt;The server provides the following REST API endpoints:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;POST /v1/audio/speech&lt;/code&gt;: Generate speech from text following the OpenAI TTS specification.&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;JSON body parameters: 
    &lt;ul&gt; 
     &lt;li&gt;&lt;code&gt;model&lt;/code&gt;: Name or path of the TTS model to use.&lt;/li&gt; 
     &lt;li&gt;&lt;code&gt;input&lt;/code&gt;: Text to convert to speech.&lt;/li&gt; 
     &lt;li&gt;&lt;code&gt;voice&lt;/code&gt;: Optional voice preset.&lt;/li&gt; 
     &lt;li&gt;&lt;code&gt;speed&lt;/code&gt;: Optional speech speed (default &lt;code&gt;1.0&lt;/code&gt;).&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;Returns the generated audio in WAV format.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;POST /v1/audio/transcriptions&lt;/code&gt;: Transcribe audio files using an STT model in a format compatible with OpenAI's API.&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Multipart form parameters: 
    &lt;ul&gt; 
     &lt;li&gt;&lt;code&gt;file&lt;/code&gt;: The audio file to transcribe.&lt;/li&gt; 
     &lt;li&gt;&lt;code&gt;model&lt;/code&gt;: Name or path of the STT model.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;Returns JSON containing the transcribed &lt;code&gt;text&lt;/code&gt;.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;GET /v1/models&lt;/code&gt;: List loaded models.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;POST /v1/models&lt;/code&gt;: Load a model by name.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;DELETE /v1/models&lt;/code&gt;: Unload a model.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Note: Generated audio files are stored in &lt;code&gt;~/.mlx_audio/outputs&lt;/code&gt; by default, or in a fallback directory if that location is not writable.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Models&lt;/h2&gt; 
&lt;h3&gt;Kokoro&lt;/h3&gt; 
&lt;p&gt;Kokoro is a multilingual TTS model that supports various languages and voice styles.&lt;/p&gt; 
&lt;h4&gt;Example Usage&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from mlx_audio.tts.models.kokoro import KokoroPipeline
from mlx_audio.tts.utils import load_model
from IPython.display import Audio
import soundfile as sf

# Initialize the model
model_id = 'prince-canuma/Kokoro-82M'
model = load_model(model_id)

# Create a pipeline with American English
pipeline = KokoroPipeline(lang_code='a', model=model, repo_id=model_id)

# Generate audio
text = "The MLX King lives. Let him cook!"
for _, _, audio in pipeline(text, voice='af_heart', speed=1, split_pattern=r'\n+'):
    # Display audio in notebook (if applicable)
    display(Audio(data=audio, rate=24000, autoplay=0))

    # Save audio to file
    sf.write('audio.wav', audio[0], 24000)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Language Options&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;üá∫üá∏ &lt;code&gt;'a'&lt;/code&gt; - American English&lt;/li&gt; 
 &lt;li&gt;üá¨üáß &lt;code&gt;'b'&lt;/code&gt; - British English&lt;/li&gt; 
 &lt;li&gt;üáØüáµ &lt;code&gt;'j'&lt;/code&gt; - Japanese (requires &lt;code&gt;pip install misaki[ja]&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;üá®üá≥ &lt;code&gt;'z'&lt;/code&gt; - Mandarin Chinese (requires &lt;code&gt;pip install misaki[zh]&lt;/code&gt;)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;CSM (Conversational Speech Model)&lt;/h3&gt; 
&lt;p&gt;CSM is a model from Sesame that allows you text-to-speech and to customize voices using reference audio samples.&lt;/p&gt; 
&lt;h4&gt;Example Usage&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Generate speech using CSM-1B model with reference audio
python -m mlx_audio.tts.generate --model mlx-community/csm-1b --text "Hello from Sesame." --play --ref_audio ./conversational_a.wav
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can pass any audio to clone the voice from or download sample audio file from &lt;a href="https://huggingface.co/mlx-community/csm-1b/tree/main/prompts"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Advanced Features&lt;/h2&gt; 
&lt;h3&gt;Quantization&lt;/h3&gt; 
&lt;p&gt;You can quantize models for improved performance:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from mlx_audio.tts.utils import quantize_model, load_model
import json
import mlx.core as mx

model = load_model(repo_id='prince-canuma/Kokoro-82M')
config = model.config

# Quantize to 8-bit
group_size = 64
bits = 8
weights, config = quantize_model(model, config, group_size, bits)

# Save quantized model
with open('./8bit/config.json', 'w') as f:
    json.dump(config, f)

mx.save_safetensors("./8bit/kokoro-v1_0.safetensors", weights, metadata={"format": "mlx"})
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Requirements&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;MLX&lt;/li&gt; 
 &lt;li&gt;Python 3.8+&lt;/li&gt; 
 &lt;li&gt;Apple Silicon Mac (for optimal performance)&lt;/li&gt; 
 &lt;li&gt;For the web interface and API: 
  &lt;ul&gt; 
   &lt;li&gt;FastAPI&lt;/li&gt; 
   &lt;li&gt;Uvicorn&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Swift Integration&lt;/h2&gt; 
&lt;p&gt;This repo also ships a Swift package for on-device TTS using Apple's MLX framework on macOS and iOS.&lt;/p&gt; 
&lt;h3&gt;Supported Platforms&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;macOS&lt;/strong&gt;: 14.0+&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;iOS&lt;/strong&gt;: 16.0+&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Adding the Swift Package Dependency&lt;/h3&gt; 
&lt;h4&gt;Via Xcode (Recommended)&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;Open your Xcode project&lt;/li&gt; 
 &lt;li&gt;Navigate to &lt;strong&gt;File&lt;/strong&gt; ‚Üí &lt;strong&gt;Add Package Dependencies...&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;In the search bar, enter the package repository URL: &lt;pre&gt;&lt;code&gt;https://github.com/Blaizzy/mlx-audio.git
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;Select the package and choose the version you want to use&lt;/li&gt; 
 &lt;li&gt;Add the &lt;strong&gt;&lt;code&gt;mlx-swift-audio&lt;/code&gt;&lt;/strong&gt; product to your target&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Via Package.swift&lt;/h4&gt; 
&lt;p&gt;Add the following dependency to your &lt;code&gt;Package.swift&lt;/code&gt; file:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-swift"&gt;dependencies: [
    .package(url: "https://github.com/Blaizzy/mlx-audio.git", from: "0.2.5")
],
targets: [
    .target(
        name: "YourTarget",
        dependencies: [
            .product(name: "mlx-swift-audio", package: "mlx-audio")
        ]
    )
]
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Usage&lt;/h3&gt; 
&lt;p&gt;After adding the dependency, import and use the module:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-swift"&gt;import MLXAudio

// Create a session with a built-in voice (auto-downloads model on first use)
let session = try await MarvisSession(voice: .conversationalA) // playback enabled by default

// One-shot generation (auto-plays if playback is enabled)
let result = try await session.generate(for: "Your text here")
print("Generated \(result.sampleCount) samples @ \(result.sampleRate) Hz")
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Streaming generation&lt;/h4&gt; 
&lt;p&gt;Get responsive audio chunks as they are decoded. Chunks are auto-played if playback is enabled.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-swift"&gt;import MLXAudio

let session = try await MarvisSession(voice: .conversationalA)

for try await chunk in session.stream(text: "Hello there from streaming mode", streamingInterval: 0.5) {
    // Each chunk includes PCM samples and timing metrics
    print("chunk samples=\(chunk.sampleCount) rtf=\(chunk.realTimeFactor)")
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Raw audio (no playback)&lt;/h4&gt; 
&lt;p&gt;If you want just the samples without auto-play, disable playback at init or call &lt;code&gt;generateRaw&lt;/code&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-swift"&gt;import MLXAudio

// Option A: Disable playback globally for the session
let s1 = try await MarvisSession(voice: .conversationalA, playbackEnabled: false)
let raw1 = try await s1.generateRaw(for: "Save this to a file")

// Option B: Keep playback enabled but request a raw result for this call
let s2 = try await MarvisSession(voice: .conversationalA)
let raw2 = try await s2.generateRaw(for: "No auto-play for this one")

// rawX.audio is [Float] PCM at rawX.sampleRate (mono)
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code&gt;
## License

[MIT License](LICENSE)

## Acknowledgements

- Thanks to the Apple MLX team for providing a great framework for building TTS and STS models.
- This project uses the Kokoro model architecture for text-to-speech synthesis.
- The 3D visualization uses Three.js for rendering.


@misc{mlx-audio,
  author = {Canuma, Prince},
  title = {MLX Audio},
  year = {2025},
  howpublished = {\url{https://github.com/Blaizzy/mlx-audio}},
  note = {A text-to-speech (TTS), speech-to-text (STT) and speech-to-speech (STS) library built on Apple's MLX framework, providing efficient speech analysis on Apple Silicon.}
}
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>usestrix/strix</title>
      <link>https://github.com/usestrix/strix</link>
      <description>&lt;p&gt;‚ú® Open-source AI hackers for your apps üë®üèª‚Äçüíª&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;a href="https://usestrix.com/"&gt; &lt;img src="https://raw.githubusercontent.com/usestrix/strix/main/.github/logo.png" width="150" alt="Strix Logo" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;h1 align="center"&gt; Strix &lt;/h1&gt; 
&lt;h2 align="center"&gt;Open-source AI Hackers to secure your Apps&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://pypi.org/project/strix-agent/"&gt;&lt;img src="https://img.shields.io/pypi/pyversions/strix-agent?color=3776AB" alt="Python" /&gt;&lt;/a&gt; &lt;a href="https://pypi.org/project/strix-agent/"&gt;&lt;img src="https://img.shields.io/pypi/v/strix-agent?color=10b981" alt="PyPI" /&gt;&lt;/a&gt; &lt;a href="https://pepy.tech/projects/strix-agent"&gt;&lt;img src="https://static.pepy.tech/personalized-badge/strix-agent?period=total&amp;amp;units=INTERNATIONAL_SYSTEM&amp;amp;left_color=GREY&amp;amp;right_color=RED&amp;amp;left_text=Downloads" alt="PyPI Downloads" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/usestrix/strix/main/LICENSE"&gt;&lt;img src="https://img.shields.io/badge/license-Apache%202.0-blue.svg?sanitize=true" alt="License" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://github.com/usestrix/strix"&gt;&lt;img src="https://img.shields.io/github/stars/usestrix/strix" alt="GitHub Stars" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/YjKFvEZSdZ"&gt;&lt;img src="https://img.shields.io/badge/Discord-%235865F2.svg?&amp;amp;logo=discord&amp;amp;logoColor=white" alt="Discord" /&gt;&lt;/a&gt; &lt;a href="https://usestrix.com"&gt;&lt;img src="https://img.shields.io/badge/Website-usestrix.com-2d3748.svg?sanitize=true" alt="Website" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://trendshift.io/repositories/15362" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/15362" alt="usestrix%2Fstrix | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span&gt;‚≠ê&lt;/span&gt; &lt;em&gt;Love Strix? Give us a star to help other developers discover it!&lt;/em&gt;&lt;/p&gt; 
&lt;br /&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/usestrix/strix/main/.github/screenshot.png" alt="Strix Demo" width="800" style="border-radius: 16px;" /&gt; 
&lt;/div&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] &lt;strong&gt;New!&lt;/strong&gt; Strix now integrates seamlessly with GitHub Actions and CI/CD pipelines. Automatically scan for vulnerabilities on every pull request and block insecure code before it reaches production!&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!WARNING] Only test systems you own or have permission to test. You are responsible for using Strix ethically and legally.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ü¶â Strix Overview&lt;/h2&gt; 
&lt;p&gt;Strix are autonomous AI agents that act just like real hackers - they run your code dynamically, find vulnerabilities, and validate them through actual proof-of-concepts. Built for developers and security teams who need fast, accurate security testing without the overhead of manual pentesting or the false positives of static analysis tools.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Full hacker toolkit&lt;/strong&gt; out of the box&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Teams of agents&lt;/strong&gt; that collaborate and scale&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Real validation&lt;/strong&gt; with PoCs, not false positives&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Developer‚Äëfirst&lt;/strong&gt; CLI with actionable reports&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Auto‚Äëfix &amp;amp; reporting&lt;/strong&gt; to accelerate remediation&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h3&gt;üéØ Use Cases&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Detect and validate critical vulnerabilities in your applications.&lt;/li&gt; 
 &lt;li&gt;Get penetration tests done in hours, not weeks, with compliance reports.&lt;/li&gt; 
 &lt;li&gt;Automate bug bounty research and generate PoCs for faster reporting.&lt;/li&gt; 
 &lt;li&gt;Run tests in CI/CD to block vulnerabilities before reaching production.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h3&gt;üöÄ Quick Start&lt;/h3&gt; 
&lt;p&gt;Prerequisites:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Docker (running)&lt;/li&gt; 
 &lt;li&gt;Python 3.12+&lt;/li&gt; 
 &lt;li&gt;An LLM provider key (or a local LLM)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Install
pipx install strix-agent

# Configure AI provider
export STRIX_LLM="openai/gpt-5"
export LLM_API_KEY="your-api-key"

# Run security assessment
strix --target ./app-directory
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;First run pulls the sandbox Docker image. Results are saved under &lt;code&gt;agent_runs/&amp;lt;run-name&amp;gt;&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;üèÜ Enterprise Platform&lt;/h3&gt; 
&lt;p&gt;Want to skip the setup? Try our cloud-hosted version: &lt;strong&gt;&lt;a href="https://usestrix.com"&gt;usestrix.com&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Our managed platform provides:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;üìà Executive Dashboards&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üß† Custom Fine-Tuned Models&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;‚öôÔ∏è CI/CD Integration&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üîç Large-Scale Scanning&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üîå Third-Party Integrations&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üéØ Enterprise Support&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://usestrix.com"&gt;&lt;strong&gt;Get Enterprise Demo ‚Üí&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;‚ú® Features&lt;/h2&gt; 
&lt;h3&gt;üõ†Ô∏è Agentic Security Tools&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;üîå Full HTTP Proxy&lt;/strong&gt; - Full request/response manipulation and analysis&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üåê Browser Automation&lt;/strong&gt; - Multi-tab browser for testing of XSS, CSRF, auth flows&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üíª Terminal Environments&lt;/strong&gt; - Interactive shells for command execution and testing&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üêç Python Runtime&lt;/strong&gt; - Custom exploit development and validation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üîç Reconnaissance&lt;/strong&gt; - Automated OSINT and attack surface mapping&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üìÅ Code Analysis&lt;/strong&gt; - Static and dynamic analysis capabilities&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üìù Knowledge Management&lt;/strong&gt; - Structured findings and attack documentation&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üéØ Comprehensive Vulnerability Detection&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Access Control&lt;/strong&gt; - IDOR, privilege escalation, auth bypass&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Injection Attacks&lt;/strong&gt; - SQL, NoSQL, command injection&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Server-Side&lt;/strong&gt; - SSRF, XXE, deserialization flaws&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Client-Side&lt;/strong&gt; - XSS, prototype pollution, DOM vulnerabilities&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Business Logic&lt;/strong&gt; - Race conditions, workflow manipulation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Authentication&lt;/strong&gt; - JWT vulnerabilities, session management&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Infrastructure&lt;/strong&gt; - Misconfigurations, exposed services&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üï∏Ô∏è Graph of Agents&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Distributed Workflows&lt;/strong&gt; - Specialized agents for different attacks and assets&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Scalable Testing&lt;/strong&gt; - Parallel execution for fast comprehensive coverage&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Dynamic Coordination&lt;/strong&gt; - Agents collaborate and share discoveries&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üíª Usage Examples&lt;/h2&gt; 
&lt;h3&gt;Default Usage&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Local codebase analysis
strix --target ./app-directory

# Repository security review
strix --target https://github.com/org/repo

# Black-Box Web application assessment
strix --target https://your-app.com

# Grey-Box Security Assesment
strix --target https://your-app.com --instructions "Perform authenticated testing using the following credentials user:pass"

# Multi-target white-box testing (source code + deployed app)
strix -t https://github.com/org/app -t https://your-app.com

# Focused testing with instructions
strix --target api.your-app.com --instruction "Focus on business logic flaws and IDOR vulnerabilities"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;ü§ñ Headless Mode&lt;/h3&gt; 
&lt;p&gt;Run Strix programmatically without interactive UI using the &lt;code&gt;-n/--non-interactive&lt;/code&gt; flag‚Äîperfect for servers and automated jobs. The CLI prints real-time vulnerability findings, and the final report before exiting. Exits with non-zero code when vulnerabilities are found.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;strix -n --target https://your-app.com
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;üîÑ CI/CD (GitHub Actions)&lt;/h3&gt; 
&lt;p&gt;Strix can be added to your pipeline to run a security test on pull requests with a lightweight GitHub Actions workflow:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;name: strix-penetration-test

on:
  pull_request:

jobs:
  security-scan:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Install Strix
        run: pipx install strix-agent

      - name: Run Strix
        env:
          STRIX_LLM: ${{ secrets.STRIX_LLM }}
          LLM_API_KEY: ${{ secrets.LLM_API_KEY }}

        run: strix -n -t ./
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;‚öôÔ∏è Configuration&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;export STRIX_LLM="openai/gpt-5"
export LLM_API_KEY="your-api-key"

# Optional
export LLM_API_BASE="your-api-base-url"  # if using a local model, e.g. Ollama, LMStudio
export PERPLEXITY_API_KEY="your-api-key"  # for search capabilities
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;a href="https://docs.litellm.ai/docs/providers"&gt;üìö View supported AI models&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;ü§ù Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome contributions from the community! There are several ways to contribute:&lt;/p&gt; 
&lt;h3&gt;Code Contributions&lt;/h3&gt; 
&lt;p&gt;See our &lt;a href="https://raw.githubusercontent.com/usestrix/strix/main/CONTRIBUTING.md"&gt;Contributing Guide&lt;/a&gt; for details on:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Setting up your development environment&lt;/li&gt; 
 &lt;li&gt;Running tests and quality checks&lt;/li&gt; 
 &lt;li&gt;Submitting pull requests&lt;/li&gt; 
 &lt;li&gt;Code style guidelines&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Prompt Modules Collection&lt;/h3&gt; 
&lt;p&gt;Help expand our collection of specialized prompt modules for AI agents:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Advanced testing techniques for vulnerabilities, frameworks, and technologies&lt;/li&gt; 
 &lt;li&gt;See &lt;a href="https://raw.githubusercontent.com/usestrix/strix/main/strix/prompts/README.md"&gt;Prompt Modules Documentation&lt;/a&gt; for guidelines&lt;/li&gt; 
 &lt;li&gt;Submit via &lt;a href="https://github.com/usestrix/strix/pulls"&gt;pull requests&lt;/a&gt; or &lt;a href="https://github.com/usestrix/strix/issues"&gt;issues&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üë• Join Our Community&lt;/h2&gt; 
&lt;p&gt;Have questions? Found a bug? Want to contribute? &lt;strong&gt;&lt;a href="https://discord.gg/YjKFvEZSdZ"&gt;Join our Discord!&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;üåü Support the Project&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Love Strix?&lt;/strong&gt; Give us a ‚≠ê on GitHub!&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://api.star-history.com/svg?repos=usestrix/strix&amp;amp;type=date&amp;amp;legend=top-left" alt="Star History Chart" width="800" style="border-radius: 16px;" /&gt; 
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>thinking-machines-lab/tinker-cookbook</title>
      <link>https://github.com/thinking-machines-lab/tinker-cookbook</link>
      <description>&lt;p&gt;Post-training with Tinker&lt;/p&gt;&lt;hr&gt;&lt;h1 align="center"&gt;Tinker Cookbook&lt;/h1&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/thinking-machines-lab/tinker-cookbook/main/assets/tinker-cover.png" width="60%" /&gt; 
&lt;/div&gt; 
&lt;p&gt;We provide two libraries for the broader community to customize their language models: &lt;code&gt;tinker&lt;/code&gt; and &lt;code&gt;tinker-cookbook&lt;/code&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;tinker&lt;/code&gt; is a training SDK for researchers and developers to fine-tune language models. You send API requests to us and we handle the complexities of distributed training.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;tinker-cookbook&lt;/code&gt; includes realistic examples of fine-tuning language models. It builds on the Tinker API and provides common abstractions to fine-tune language models.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;Sign up for Tinker through the &lt;a href="https://thinkingmachines.ai/tinker"&gt;waitlist&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Once you have access, create an API key from the &lt;a href="https://tinker-console.thinkingmachines.ai"&gt;console&lt;/a&gt; and export it as environment variable &lt;code&gt;TINKER_API_KEY&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Install tinker python client via &lt;code&gt;pip install tinker&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;We recommend installing &lt;code&gt;tinker-cookbook&lt;/code&gt; in a virtual env either with &lt;code&gt;conda&lt;/code&gt; or &lt;code&gt;uv&lt;/code&gt;. For running most examples, you can install via &lt;code&gt;pip install -e .&lt;/code&gt;.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Tinker&lt;/h2&gt; 
&lt;p&gt;Refer to the &lt;a href="https://tinker-docs.thinkingmachines.ai/training-sampling"&gt;docs&lt;/a&gt; to start from basics. Here we introduce a few Tinker primitives - the basic components to fine-tune LLMs:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;service_client = tinker.ServiceClient()
training_client = service_client.create_lora_training_client(
  base_model="meta-llama/Llama-3.2-1B", rank=32,
)
training_client.forward_backward(...)
training_client.optim_step(...)
training_client.save_state(...)
training_client.load_state(...)

sampling_client = training_client.save_weights_and_get_sampling_client(name="my_model")
sampling_client.sample(...)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/thinking-machines-lab/tinker-cookbook/main/tinker_cookbook/recipes/sl_loop.py"&gt;tinker_cookbook/recipes/sl_loop.py&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/thinking-machines-lab/tinker-cookbook/main/tinker_cookbook/recipes/rl_loop.py"&gt;tinker_cookbook/recipes/rl_loop.py&lt;/a&gt; for minimal examples of using these primitives to fine-tune LLMs.&lt;/p&gt; 
&lt;p&gt;To download the weights of any model:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;rest_client = service_client.create_rest_client()
future = rest_client.download_checkpoint_archive_from_tinker_path(sampling_client.model_path)
with open(f"model-checkpoint.tar.gz", "wb") as f:
    f.write(future.result())
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Tinker Cookbook&lt;/h3&gt; 
&lt;p&gt;Besides these primitives, we also offer &lt;strong&gt;Tinker Cookbook&lt;/strong&gt; (a.k.a. this repo), a library of a wide range of abstractions to help you customize training environments. &lt;a href="https://raw.githubusercontent.com/thinking-machines-lab/tinker-cookbook/main/tinker_cookbook/recipes/sl_basic.py"&gt;&lt;code&gt;tinker_cookbook/recipes/sl_basic.py&lt;/code&gt;&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/thinking-machines-lab/tinker-cookbook/main/tinker_cookbook/recipes/rl_basic.py"&gt;&lt;code&gt;tinker_cookbook/recipes/rl_basic.py&lt;/code&gt;&lt;/a&gt; contain minimal examples to configure supervised learning and reinforcement learning.&lt;/p&gt; 
&lt;p&gt;We also include a wide range of more sophisticated examples in the &lt;a href="https://raw.githubusercontent.com/thinking-machines-lab/tinker-cookbook/main/tinker_cookbook/recipes/"&gt;&lt;code&gt;tinker_cookbook/recipes/&lt;/code&gt;&lt;/a&gt; folder:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/thinking-machines-lab/tinker-cookbook/main/tinker_cookbook/recipes/chat_sl/"&gt;Chat supervised learning&lt;/a&gt;&lt;/strong&gt;: supervised fine-tuning on conversational datasets like Tulu3.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/thinking-machines-lab/tinker-cookbook/main/tinker_cookbook/recipes/math_rl/"&gt;Math reasoning&lt;/a&gt;&lt;/strong&gt;: improve LLM reasoning capability by rewarding it for answering math questions correctly.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/thinking-machines-lab/tinker-cookbook/main/tinker_cookbook/recipes/preference/"&gt;Preference learning&lt;/a&gt;&lt;/strong&gt;: showcase a three-stage RLHF pipeline: 1) supervised fine-tuning, 2) learning a reward model, 3) RL against the reward model.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/thinking-machines-lab/tinker-cookbook/main/tinker_cookbook/recipes/tool_use/"&gt;Tool use&lt;/a&gt;&lt;/strong&gt;: train LLMs to better use retrieval tools to answer questions more accurately.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/thinking-machines-lab/tinker-cookbook/main/tinker_cookbook/recipes/prompt_distillation/"&gt;Prompt distillation&lt;/a&gt;&lt;/strong&gt;: internalize long and complex instructions into LLMs.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/thinking-machines-lab/tinker-cookbook/main/tinker_cookbook/recipes/multiplayer_rl/"&gt;Multi-Agent&lt;/a&gt;&lt;/strong&gt;: optimize LLMs to play against another LLM or themselves.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;These examples are located in each subfolder, and their &lt;code&gt;README.md&lt;/code&gt; files will walk you through the key implementation details, the commands to run them, and the expected performance.&lt;/p&gt; 
&lt;h3&gt;Import our utilities&lt;/h3&gt; 
&lt;p&gt;Tinker cookbook includes several utilities. Here's a quick overview:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/thinking-machines-lab/tinker-cookbook/main/tinker_cookbook/renderers.py"&gt;&lt;code&gt;renderers&lt;/code&gt;&lt;/a&gt; converts tokens from/to structured chat message objects&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/thinking-machines-lab/tinker-cookbook/main/tinker_cookbook/hyperparam_utils.py"&gt;&lt;code&gt;hyperparam_utils&lt;/code&gt;&lt;/a&gt; helps calculate hyperparameters suitable for LoRAs&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/thinking-machines-lab/tinker-cookbook/main/tinker_cookbook/eval/evaluators.py"&gt;&lt;code&gt;evaluation&lt;/code&gt;&lt;/a&gt; provides abstractions for evaluating Tinker models and &lt;a href="https://raw.githubusercontent.com/thinking-machines-lab/tinker-cookbook/main/tinker_cookbook/eval/inspect_evaluators.py"&gt;&lt;code&gt;inspect_evaluation&lt;/code&gt;&lt;/a&gt; shows how to integrate with InspectAI to make evaluating on standard benchmarks easy.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;This project is built in the spirit of open science and collaborative development. We believe that the best tools emerge through community involvement and shared learning.&lt;/p&gt; 
&lt;p&gt;We welcome PR contributions after our private beta is over. If you have any feedback, please email us at &lt;a href="mailto:tinker@thinkingmachines.ai"&gt;tinker@thinkingmachines.ai&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Citation&lt;/h2&gt; 
&lt;p&gt;If you use Tinker for your research, please cite it as:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Thinking Machines Lab, 2025. Tinker. https://thinkingmachines.ai/tinker/.
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or use this BibTeX citation:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;@misc{tml2025tinker,
  author = {Thinking Machines Lab},
  title = {Tinker},
  year = {2025},
  url = {https://thinkingmachines.ai/tinker/},
}
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>lzhoang2801/OpCore-Simplify</title>
      <link>https://github.com/lzhoang2801/OpCore-Simplify</link>
      <description>&lt;p&gt;A tool designed to simplify the creation of OpenCore EFI&lt;/p&gt;&lt;hr&gt;&lt;br /&gt; 
&lt;div align="center"&gt; 
 &lt;h3 align="center"&gt;OpCore Simplify&lt;/h3&gt; 
 &lt;p align="center"&gt; A specialized tool that streamlines &lt;a href="https://github.com/acidanthera/OpenCorePkg"&gt;OpenCore&lt;/a&gt; EFI creation by automating the essential setup process and providing standardized configurations. Designed to reduce manual effort while ensuring accuracy in your Hackintosh journey. &lt;br /&gt; &lt;br /&gt; &lt;a href="https://raw.githubusercontent.com/lzhoang2801/OpCore-Simplify/main/#-features"&gt;Features&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/lzhoang2801/OpCore-Simplify/main/#-how-to-use"&gt;How To Use&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/lzhoang2801/OpCore-Simplify/main/#-contributing"&gt;Contributing&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/lzhoang2801/OpCore-Simplify/main/#-license"&gt;License&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/lzhoang2801/OpCore-Simplify/main/#-credits"&gt;Credits&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/lzhoang2801/OpCore-Simplify/main/#-contact"&gt;Contact&lt;/a&gt; &lt;/p&gt; 
&lt;/div&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!CAUTION] &lt;strong&gt;DO NOT TRUST ANY HACKINTOSH INFORMATION FROM AI/LLM SOURCES&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;They often provide incorrect information about Hackintosh. Always rely on official sources like the &lt;a href="https://dortania.github.io/OpenCore-Install-Guide/"&gt;Dortania Guide&lt;/a&gt; and the Hackintosh community for accurate information.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!WARNING] &lt;strong&gt;OUTDATED SECTIONS IN DORTANIA GUIDE&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;While the Dortania Guide is a valuable resource, some sections may be outdated. Always:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Verify information with the Hackintosh community&lt;/li&gt; 
  &lt;li&gt;Test configurations yourself&lt;/li&gt; 
  &lt;li&gt;Prefer reading documentation directly from the GitHub repositories of bootloaders and kexts you plan to use&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] If the installation process is successful using OpCore Simplify, please confirm it at &lt;a href="https://github.com/lzhoang2801/OpCore-Simplify/discussions/23"&gt;Successful Hackintosh Setup with OpCore Simplify&lt;/a&gt;. This will greatly assist others in the community.&lt;/p&gt; 
 &lt;p&gt;OpCore Simplify is the ONLY tool that builds OpenCore EFI based on your complete hardware configuration, not just predefined options. This fundamental difference sets us apart from other tools in the Hackintosh community.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] While OpCore Simplify significantly reduces setup time, the Hackintosh journey still requires:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Understanding basic concepts from the &lt;a href="https://dortania.github.io/OpenCore-Install-Guide/"&gt;Dortania Guide&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Testing and troubleshooting during the installation process&lt;/li&gt; 
  &lt;li&gt;Patience and persistence in resolving any issues that arise&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;Our tool doesn't eliminate these steps, but it ensures you start with a solid foundation.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;‚ú® &lt;strong&gt;Features&lt;/strong&gt;&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Comprehensive Hardware and macOS Support&lt;/strong&gt;&lt;br /&gt; Fully supports modern hardware. Use &lt;code&gt;Compatibility Checker&lt;/code&gt; to check supported/unsupported devices and macOS version supported.&lt;/p&gt; 
  &lt;table&gt; 
   &lt;thead&gt; 
    &lt;tr&gt; 
     &lt;th&gt;&lt;strong&gt;Component&lt;/strong&gt;&lt;/th&gt; 
     &lt;th&gt;&lt;strong&gt;Supported&lt;/strong&gt;&lt;/th&gt; 
    &lt;/tr&gt; 
   &lt;/thead&gt; 
   &lt;tbody&gt; 
    &lt;tr&gt; 
     &lt;td&gt;&lt;strong&gt;CPU&lt;/strong&gt;&lt;/td&gt; 
     &lt;td&gt;Intel: Nehalem and Westmere (1nd Gen) ‚Üí Arrow Lake (15th Gen/Core Ultra Series 2) &lt;br /&gt; AMD: Ryzen and Threadripper with &lt;a href="https://github.com/AMD-OSX/AMD_Vanilla"&gt;AMD Vanilla&lt;/a&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;&lt;strong&gt;GPU&lt;/strong&gt;&lt;/td&gt; 
     &lt;td&gt;Intel iGPU: Iron Lake (1nd Gen) ‚Üí Ice Lake (10th Gen) &lt;br /&gt; AMD APU: The entire Vega Raven ASIC family (Ryzen 1xxx ‚Üí 5xxx, 7x30 series) &lt;br /&gt; AMD dGPU: Navi 23, Navi 22, Navi 21 generations, and older series &lt;br /&gt; NVIDIA: Kepler, Pascal, Maxwell, Fermi, Tesla generations&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;&lt;strong&gt;macOS&lt;/strong&gt;&lt;/td&gt; 
     &lt;td&gt;macOS High Sierra ‚Üí macOS Tahoe&lt;/td&gt; 
    &lt;/tr&gt; 
   &lt;/tbody&gt; 
  &lt;/table&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;ACPI Patches and Kexts&lt;/strong&gt;&lt;br /&gt; Automatically detects and adds ACPI patches and kexts based on hardware configuration.&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Integrated with &lt;a href="https://github.com/corpnewt/SSDTTime"&gt;SSDTTime&lt;/a&gt; for common patches (e.g., FakeEC, FixHPET, PLUG, RTCAWAC).&lt;/li&gt; 
   &lt;li&gt;Includes custom patches: 
    &lt;ul&gt; 
     &lt;li&gt;Prevent kernel panics by directing the first CPU entry to an active CPU, disabling the UNC0 device, and creating a new RTC device for HEDT systems.&lt;/li&gt; 
     &lt;li&gt;Disable unsupported or unused PCI devices, such as the GPU (using Optimus and Bumblebee methods or adding the disable-gpu property), Wi-Fi card, and NVMe storage controller.&lt;/li&gt; 
     &lt;li&gt;Fix sleep state values in _PRW methods (GPRW, UPRW, HP special) to prevent immediate wake.&lt;/li&gt; 
     &lt;li&gt;Add devices including ALS0, BUS0, MCHC, PMCR, PNLF, RMNE, IMEI, USBX, XOSI, along with a Surface Patch.&lt;/li&gt; 
     &lt;li&gt;Enable ALSD and GPI0 devices.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Automatic Updates&lt;/strong&gt;&lt;br /&gt; Automatically checks for and updates OpenCorePkg and kexts from &lt;a href="https://dortania.github.io/builds/"&gt;Dortania Builds&lt;/a&gt; and GitHub releases before each EFI build.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;EFI Configuration&lt;/strong&gt;&lt;br /&gt; Apply additional customization based on both widely used sources and personal experience.&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Spoof GPU IDs for certain AMD GPUs not recognized in macOS.&lt;/li&gt; 
   &lt;li&gt;Use CpuTopologyRebuild kext for Intel CPUs with P-cores and E-cores to enhance performance.&lt;/li&gt; 
   &lt;li&gt;Disable System Integrity Protection (SIP).&lt;/li&gt; 
   &lt;li&gt;Spoof CPU IDs for Intel Pentium, Celeron, Core, and Xeon processors.&lt;/li&gt; 
   &lt;li&gt;Add custom CPU names for AMD CPUs, as well as Intel Pentium, Celeron, Xeon, and Core lines from the Rocket Lake (11th) generation and newer.&lt;/li&gt; 
   &lt;li&gt;Add a patch to allow booting macOS with unsupported SMBIOS.&lt;/li&gt; 
   &lt;li&gt;Add NVRAM entries to bypass checking the internal Bluetooth controller.&lt;/li&gt; 
   &lt;li&gt;Properly configure ResizeAppleGpuBars based on specific Resizable BAR information.&lt;/li&gt; 
   &lt;li&gt;Allow flexible iGPU configuration between headless and driving a display when a supported discrete GPU is present.&lt;/li&gt; 
   &lt;li&gt;Force Intel GPUs into VESA mode with HDMI and DVI connectors to simplify installation process.&lt;/li&gt; 
   &lt;li&gt;Provide configuration required for using OpenCore Legacy Patcher.&lt;/li&gt; 
   &lt;li&gt;Add built-in device property for network devices (fix 'Could not communicate with the server' when using iServices) and storage controllers (fix internal drives shown as external).&lt;/li&gt; 
   &lt;li&gt;Prioritize SMBIOS optimized for both power management and performance.&lt;/li&gt; 
   &lt;li&gt;Re-enable CPU power management on legacy Intel CPUs in macOS Ventura 13 and newer.&lt;/li&gt; 
   &lt;li&gt;Apply WiFi profiles for itlwm kext to enable auto WiFi connections at boot time.&lt;/li&gt; 
  &lt;/ul&gt; &lt;p&gt;and more...&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Easy Customization&lt;/strong&gt;&lt;br /&gt; In addition to the default settings applied, users can easily make further customizations if desired.&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Custom ACPI patches, kexts, and SMBIOS adjustments (&lt;strong&gt;not recommended&lt;/strong&gt;).&lt;/li&gt; 
   &lt;li&gt;Force load kexts on unsupported macOS versions.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;üöÄ &lt;strong&gt;How To Use&lt;/strong&gt;&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Download OpCore Simplify&lt;/strong&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Click &lt;strong&gt;Code&lt;/strong&gt; ‚Üí &lt;strong&gt;Download ZIP&lt;/strong&gt;, or download directly via this &lt;a href="https://github.com/lzhoang2801/OpCore-Simplify/archive/refs/heads/main.zip"&gt;link&lt;/a&gt;.&lt;/li&gt; 
   &lt;li&gt;Extract the downloaded ZIP file to your desired location.&lt;/li&gt; 
  &lt;/ul&gt; &lt;p&gt;&lt;img src="https://i.imgur.com/mcE7OSX.png" alt="Download OpCore Simplify" /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Running OpCore Simplify&lt;/strong&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;On &lt;strong&gt;Windows&lt;/strong&gt;, run &lt;code&gt;OpCore-Simplify.bat&lt;/code&gt;.&lt;/li&gt; 
   &lt;li&gt;On &lt;strong&gt;macOS&lt;/strong&gt;, run &lt;code&gt;OpCore-Simplify.command&lt;/code&gt;.&lt;/li&gt; 
  &lt;/ul&gt; &lt;p&gt;&lt;img src="https://i.imgur.com/vTr1V9D.png" alt="OpCore Simplify Menu" /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Selecting hardware report&lt;/strong&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;On Windows, there will be an option for &lt;code&gt;E. Export hardware report&lt;/code&gt;. It's recommended to use this for the best results with your hardware configuration and BIOS at the time of building.&lt;/li&gt; 
   &lt;li&gt;Alternatively, use &lt;a href="https://github.com/lzhoang2801/Hardware-Sniffer"&gt;&lt;strong&gt;Hardware Sniffer&lt;/strong&gt;&lt;/a&gt; to create a &lt;code&gt;Report.json&lt;/code&gt; and ACPI dump for configuration manully.&lt;/li&gt; 
  &lt;/ul&gt; &lt;p&gt;&lt;img src="https://i.imgur.com/MbRmIGJ.png" alt="Selecting hardware report" /&gt;&lt;/p&gt; &lt;p&gt;&lt;img src="https://i.imgur.com/SbL6N6v.png" alt="Loading ACPI Tables" /&gt;&lt;/p&gt; &lt;p&gt;&lt;img src="https://i.imgur.com/kuDGMmp.png" alt="Compatibility Checker" /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Selecting macOS Version and Customizing OpenCore EFI&lt;/strong&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;By default, the latest compatible macOS version will be selected for your hardware.&lt;/li&gt; 
   &lt;li&gt;OpCore Simplify will automatically apply essential ACPI patches and kexts.&lt;/li&gt; 
   &lt;li&gt;You can manually review and customize these settings as needed.&lt;/li&gt; 
  &lt;/ul&gt; &lt;p&gt;&lt;img src="https://i.imgur.com/TSk9ejy.png" alt="OpCore Simplify Menu" /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Building OpenCore EFI&lt;/strong&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Once you've customized all options, select &lt;strong&gt;Build OpenCore EFI&lt;/strong&gt; to generate your EFI.&lt;/li&gt; 
   &lt;li&gt;The tool will automatically download the necessary bootloader and kexts, which may take a few minutes.&lt;/li&gt; 
  &lt;/ul&gt; &lt;p&gt;&lt;img src="https://i.imgur.com/71TkJkD.png" alt="WiFi Profile Extractor" /&gt;&lt;/p&gt; &lt;p&gt;&lt;img src="https://i.imgur.com/Mcm20EQ.png" alt="Choosing Codec Layout ID" /&gt;&lt;/p&gt; &lt;p&gt;&lt;img src="https://i.imgur.com/deyj5de.png" alt="Building OpenCore EFI" /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;USB Mapping&lt;/strong&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;After building your EFI, follow the steps for mapping USB ports.&lt;/li&gt; 
  &lt;/ul&gt; &lt;p&gt;&lt;img src="https://i.imgur.com/MIPigPF.png" alt="Results" /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Create USB and Install macOS&lt;/strong&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Use &lt;a href="https://github.com/corpnewt/UnPlugged"&gt;&lt;strong&gt;UnPlugged&lt;/strong&gt;&lt;/a&gt; on Windows to create a USB macOS installer, or follow &lt;a href="https://dortania.github.io/OpenCore-Install-Guide/installer-guide/mac-install.html"&gt;this guide&lt;/a&gt; for macOS.&lt;/li&gt; 
   &lt;li&gt;For troubleshooting, refer to the &lt;a href="https://dortania.github.io/OpenCore-Install-Guide/troubleshooting/troubleshooting.html"&gt;OpenCore Troubleshooting Guide&lt;/a&gt;.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE]&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt; &lt;p&gt;After a successful installation, if OpenCore Legacy Patcher is required, simply apply root patches to activate the missing features (such as modern Broadcom Wi-Fi card and graphics acceleration).&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;For AMD GPUs, after applying root patches from OpenCore Legacy Patcher, you need to remove the boot argument &lt;code&gt;-radvesa&lt;/code&gt;/&lt;code&gt;-amd_no_dgpu_accel&lt;/code&gt; for graphics acceleration to work.&lt;/p&gt; &lt;/li&gt; 
 &lt;/ol&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;ü§ù &lt;strong&gt;Contributing&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;Contributions are &lt;strong&gt;highly appreciated&lt;/strong&gt;! If you have ideas to improve this project, feel free to fork the repo and create a pull request, or open an issue with the "enhancement" tag.&lt;/p&gt; 
&lt;p&gt;Don't forget to ‚≠ê star the project! Thank you for your support! üåü&lt;/p&gt; 
&lt;h2&gt;üìú &lt;strong&gt;License&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;Distributed under the BSD 3-Clause License. See &lt;code&gt;LICENSE&lt;/code&gt; for more information.&lt;/p&gt; 
&lt;h2&gt;üôå &lt;strong&gt;Credits&lt;/strong&gt;&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/acidanthera/OpenCorePkg"&gt;OpenCorePkg&lt;/a&gt; and &lt;a href="https://github.com/lzhoang2801/OpCore-Simplify/raw/main/Scripts/datasets/kext_data.py"&gt;kexts&lt;/a&gt; ‚Äì The backbone of this project.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/corpnewt/SSDTTime"&gt;SSDTTime&lt;/a&gt; ‚Äì SSDT patching utilities.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üìû &lt;strong&gt;Contact&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Hoang Hong Quan&lt;/strong&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Facebook &lt;a href="https://facebook.com/macforce2601"&gt;@macforce2601&lt;/a&gt; &amp;nbsp;¬∑&amp;nbsp; Telegram &lt;a href="https://t.me/lzhoang2601"&gt;@lzhoang2601&lt;/a&gt; &amp;nbsp;¬∑&amp;nbsp; Email: &lt;a href="mailto:lzhoang2601@gmail.com"&gt;lzhoang2601@gmail.com&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;üåü &lt;strong&gt;Star History&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://star-history.com/#lzhoang2801/OpCore-Simplify&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=lzhoang2801/OpCore-Simplify&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Zie619/n8n-workflows</title>
      <link>https://github.com/Zie619/n8n-workflows</link>
      <description>&lt;p&gt;all of the workflows of n8n i could find (also from the site itself)&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;üöÄ n8n Workflow Collection&lt;/h1&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;img src="https://img.shields.io/badge/n8n-Workflows-orange?style=for-the-badge&amp;amp;logo=n8n" alt="n8n Workflows" /&gt; &lt;img src="https://img.shields.io/badge/Workflows-4343+-blue?style=for-the-badge" alt="Workflows" /&gt; &lt;img src="https://img.shields.io/badge/Integrations-365+-green?style=for-the-badge" alt="Integrations" /&gt; &lt;img src="https://img.shields.io/badge/License-MIT-purple?style=for-the-badge" alt="License" /&gt; &lt;a href="https://www.buymeacoffee.com/zie619"&gt;&lt;img src="https://img.shields.io/badge/Buy%20Me%20a%20Coffee-FFDD00?style=for-the-badge&amp;amp;logo=buy-me-a-coffee&amp;amp;logoColor=black" alt="Buy Me a Coffee" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;h3&gt;üåü The Ultimate Collection of n8n Automation Workflows&lt;/h3&gt; 
 &lt;p&gt;&lt;strong&gt;&lt;a href="https://zie619.github.io/n8n-workflows"&gt;üîç Browse Online&lt;/a&gt;&lt;/strong&gt; ‚Ä¢ &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/Zie619/n8n-workflows/main/#documentation"&gt;üìö Documentation&lt;/a&gt;&lt;/strong&gt; ‚Ä¢ &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/Zie619/n8n-workflows/main/#contributing"&gt;ü§ù Contributing&lt;/a&gt;&lt;/strong&gt; ‚Ä¢ &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/Zie619/n8n-workflows/main/#license"&gt;üìÑ License&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h2&gt;‚ú® What's New&lt;/h2&gt; 
&lt;h3&gt;üéâ Latest Updates (November 2025)&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;üîí Enhanced Security&lt;/strong&gt;: Full security audit completed, all CVEs resolved&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üê≥ Docker Support&lt;/strong&gt;: Multi-platform builds for linux/amd64 and linux/arm64&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üìä GitHub Pages&lt;/strong&gt;: Live searchable interface at &lt;a href="https://zie619.github.io/n8n-workflows"&gt;zie619.github.io/n8n-workflows&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;‚ö° Performance&lt;/strong&gt;: 100x faster search with SQLite FTS5 integration&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üé® Modern UI&lt;/strong&gt;: Completely redesigned interface with dark/light mode&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üåê Quick Access&lt;/h2&gt; 
&lt;h3&gt;üî• Use Online (No Installation)&lt;/h3&gt; 
&lt;p&gt;Visit &lt;strong&gt;&lt;a href="https://zie619.github.io/n8n-workflows"&gt;zie619.github.io/n8n-workflows&lt;/a&gt;&lt;/strong&gt; for instant access to:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;üîç &lt;strong&gt;Smart Search&lt;/strong&gt; - Find workflows instantly&lt;/li&gt; 
 &lt;li&gt;üìÇ &lt;strong&gt;15+ Categories&lt;/strong&gt; - Browse by use case&lt;/li&gt; 
 &lt;li&gt;üì± &lt;strong&gt;Mobile Ready&lt;/strong&gt; - Works on any device&lt;/li&gt; 
 &lt;li&gt;‚¨áÔ∏è &lt;strong&gt;Direct Downloads&lt;/strong&gt; - Get workflow JSONs instantly&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üöÄ Features&lt;/h2&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td width="50%"&gt; &lt;h3&gt;üìä By The Numbers&lt;/h3&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;strong&gt;4,343&lt;/strong&gt; Production-Ready Workflows&lt;/li&gt; 
     &lt;li&gt;&lt;strong&gt;365&lt;/strong&gt; Unique Integrations&lt;/li&gt; 
     &lt;li&gt;&lt;strong&gt;29,445&lt;/strong&gt; Total Nodes&lt;/li&gt; 
     &lt;li&gt;&lt;strong&gt;15&lt;/strong&gt; Organized Categories&lt;/li&gt; 
     &lt;li&gt;&lt;strong&gt;100%&lt;/strong&gt; Import Success Rate&lt;/li&gt; 
    &lt;/ul&gt; &lt;/td&gt; 
   &lt;td width="50%"&gt; &lt;h3&gt;‚ö° Performance&lt;/h3&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;strong&gt;&amp;lt; 100ms&lt;/strong&gt; Search Response&lt;/li&gt; 
     &lt;li&gt;&lt;strong&gt;&amp;lt; 50MB&lt;/strong&gt; Memory Usage&lt;/li&gt; 
     &lt;li&gt;&lt;strong&gt;700x&lt;/strong&gt; Smaller Than v1&lt;/li&gt; 
     &lt;li&gt;&lt;strong&gt;10x&lt;/strong&gt; Faster Load Times&lt;/li&gt; 
     &lt;li&gt;&lt;strong&gt;40x&lt;/strong&gt; Less RAM Usage&lt;/li&gt; 
    &lt;/ul&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üíª Local Installation&lt;/h2&gt; 
&lt;h3&gt;Prerequisites&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Python 3.9+&lt;/li&gt; 
 &lt;li&gt;pip (Python package manager)&lt;/li&gt; 
 &lt;li&gt;100MB free disk space&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Quick Start&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Clone the repository
git clone https://github.com/Zie619/n8n-workflows.git
cd n8n-workflows

# Install dependencies
pip install -r requirements.txt

# Start the server
python run.py

# Open in browser
# http://localhost:8000
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;üê≥ Docker Installation&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Using Docker Hub
docker run -p 8000:8000 zie619/n8n-workflows:latest

# Or build locally
docker build -t n8n-workflows .
docker run -p 8000:8000 n8n-workflows
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üìö Documentation&lt;/h2&gt; 
&lt;h3&gt;API Endpoints&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Endpoint&lt;/th&gt; 
   &lt;th&gt;Method&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;/&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;GET&lt;/td&gt; 
   &lt;td&gt;Web interface&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;/api/search&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;GET&lt;/td&gt; 
   &lt;td&gt;Search workflows&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;/api/stats&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;GET&lt;/td&gt; 
   &lt;td&gt;Repository statistics&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;/api/workflow/{id}&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;GET&lt;/td&gt; 
   &lt;td&gt;Get workflow JSON&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;/api/categories&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;GET&lt;/td&gt; 
   &lt;td&gt;List all categories&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;/api/export&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;GET&lt;/td&gt; 
   &lt;td&gt;Export workflows&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Search Features&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Full-text search&lt;/strong&gt; across names, descriptions, and nodes&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Category filtering&lt;/strong&gt; (Marketing, Sales, DevOps, etc.)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Complexity filtering&lt;/strong&gt; (Low, Medium, High)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Trigger type filtering&lt;/strong&gt; (Webhook, Schedule, Manual, etc.)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Service filtering&lt;/strong&gt; (365+ integrations)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üèóÔ∏è Architecture&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-mermaid"&gt;graph LR
    A[User] --&amp;gt; B[Web Interface]
    B --&amp;gt; C[FastAPI Server]
    C --&amp;gt; D[SQLite FTS5]
    D --&amp;gt; E[Workflow Database]
    C --&amp;gt; F[Static Files]
    F --&amp;gt; G[Workflow JSONs]
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Tech Stack&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Backend&lt;/strong&gt;: Python, FastAPI, SQLite with FTS5&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Frontend&lt;/strong&gt;: Vanilla JS, Tailwind CSS&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Database&lt;/strong&gt;: SQLite with Full-Text Search&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Deployment&lt;/strong&gt;: Docker, GitHub Actions, GitHub Pages&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Security&lt;/strong&gt;: Trivy scanning, CORS protection, Input validation&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üìÇ Repository Structure&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;n8n-workflows/
‚îú‚îÄ‚îÄ workflows/           # 4,343 workflow JSON files
‚îÇ   ‚îî‚îÄ‚îÄ [category]/     # Organized by integration
‚îú‚îÄ‚îÄ docs/               # GitHub Pages site
‚îú‚îÄ‚îÄ src/                # Python source code
‚îú‚îÄ‚îÄ scripts/            # Utility scripts
‚îú‚îÄ‚îÄ api_server.py       # FastAPI application
‚îú‚îÄ‚îÄ run.py              # Server launcher
‚îú‚îÄ‚îÄ workflow_db.py      # Database manager
‚îî‚îÄ‚îÄ requirements.txt    # Python dependencies
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ü§ù Contributing&lt;/h2&gt; 
&lt;p&gt;We love contributions! Here's how you can help:&lt;/p&gt; 
&lt;h3&gt;Ways to Contribute&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;üêõ &lt;strong&gt;Report bugs&lt;/strong&gt; via &lt;a href="https://github.com/Zie619/n8n-workflows/issues"&gt;Issues&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üí° &lt;strong&gt;Suggest features&lt;/strong&gt; in &lt;a href="https://github.com/Zie619/n8n-workflows/discussions"&gt;Discussions&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üìù &lt;strong&gt;Improve documentation&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;üîß &lt;strong&gt;Submit workflow fixes&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;‚≠ê &lt;strong&gt;Star the repository&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Development Setup&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Fork and clone
git clone https://github.com/YOUR_USERNAME/n8n-workflows.git

# Create branch
git checkout -b feature/amazing-feature

# Make changes and test
python run.py --debug

# Commit and push
git add .
git commit -m "feat: add amazing feature"
git push origin feature/amazing-feature

# Open PR
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üîí Security&lt;/h2&gt; 
&lt;h3&gt;Security Features&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;‚úÖ &lt;strong&gt;Path traversal protection&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;‚úÖ &lt;strong&gt;Input validation &amp;amp; sanitization&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;‚úÖ &lt;strong&gt;CORS protection&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;‚úÖ &lt;strong&gt;Rate limiting&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;‚úÖ &lt;strong&gt;Docker security hardening&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;‚úÖ &lt;strong&gt;Non-root container user&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;‚úÖ &lt;strong&gt;Regular security scanning&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Reporting Security Issues&lt;/h3&gt; 
&lt;p&gt;Please report security vulnerabilities to the maintainers via &lt;a href="https://github.com/Zie619/n8n-workflows/security/advisories/new"&gt;Security Advisory&lt;/a&gt;.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üìÑ License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the MIT License - see the &lt;a href="https://raw.githubusercontent.com/Zie619/n8n-workflows/main/LICENSE"&gt;LICENSE&lt;/a&gt; file for details.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;MIT License

Copyright (c) 2025 Zie619

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction...
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üíñ Support&lt;/h2&gt; 
&lt;p&gt;If you find this project helpful, please consider:&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://www.buymeacoffee.com/zie619"&gt;&lt;img src="https://img.shields.io/badge/Buy%20Me%20a%20Coffee-FFDD00?style=for-the-badge&amp;amp;logo=buy-me-a-coffee&amp;amp;logoColor=black" alt="Buy Me a Coffee" /&gt;&lt;/a&gt; &lt;a href="https://github.com/Zie619/n8n-workflows"&gt;&lt;img src="https://img.shields.io/badge/Star%20on%20GitHub-181717?style=for-the-badge&amp;amp;logo=github" alt="Star on GitHub" /&gt;&lt;/a&gt; &lt;a href="https://twitter.com/zie619"&gt;&lt;img src="https://img.shields.io/badge/Follow-1DA1F2?style=for-the-badge&amp;amp;logo=twitter&amp;amp;logoColor=white" alt="Follow" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üìä Stats &amp;amp; Badges&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;img src="https://img.shields.io/github/stars/Zie619/n8n-workflows?style=social" alt="GitHub stars" /&gt; &lt;img src="https://img.shields.io/github/forks/Zie619/n8n-workflows?style=social" alt="GitHub forks" /&gt; &lt;img src="https://img.shields.io/github/watchers/Zie619/n8n-workflows?style=social" alt="GitHub watchers" /&gt; &lt;img src="https://img.shields.io/github/issues/Zie619/n8n-workflows" alt="GitHub issues" /&gt; &lt;img src="https://img.shields.io/github/issues-pr/Zie619/n8n-workflows" alt="GitHub pull requests" /&gt; &lt;img src="https://img.shields.io/github/last-commit/Zie619/n8n-workflows" alt="GitHub last commit" /&gt; &lt;img src="https://img.shields.io/github/repo-size/Zie619/n8n-workflows" alt="GitHub repo size" /&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üôè Acknowledgments&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;n8n&lt;/strong&gt; - For creating an amazing automation platform&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Contributors&lt;/strong&gt; - Everyone who has helped improve this collection&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Community&lt;/strong&gt; - For feedback and support&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;You&lt;/strong&gt; - For using and supporting this project!&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;div align="center"&gt; 
 &lt;h3&gt;‚≠ê Star us on GitHub ‚Äî it motivates us a lot!&lt;/h3&gt; 
 &lt;p&gt;Made with ‚ù§Ô∏è by &lt;a href="https://github.com/Zie619"&gt;Zie619&lt;/a&gt; and &lt;a href="https://github.com/Zie619/n8n-workflows/graphs/contributors"&gt;contributors&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>Free-TV/IPTV</title>
      <link>https://github.com/Free-TV/IPTV</link>
      <description>&lt;p&gt;M3U Playlist for free TV channels&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Free TV&lt;/h1&gt; 
&lt;p&gt;This is an M3U playlist for free TV channels around the World.&lt;/p&gt; 
&lt;p&gt;Either free locally (over the air):&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/usa.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/us.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/canada.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/ca.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/uk.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/gb.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/ireland.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/ie.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/australia.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/au.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/india.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/in.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/japan.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/jp.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/china.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/cn.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/hong_kong.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/hk.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/macau.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/mo.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/taiwan.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/tw.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/north_korea.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/kp.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/korea.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/kr.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/denmark.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/dk.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/faroe_islands.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/fo.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/greenland.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/gl.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/finland.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/fi.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/iceland.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/is.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/norway.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/no.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/sweden.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/se.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/estonia.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/ee.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/latvia.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/lv.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/lithuania.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/lt.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/belgium.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/be.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/netherlands.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/nl.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/luxembourg.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/lu.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/germany.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/de.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/austria.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/at.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/switzerland.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/ch.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/poland.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/pl.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/czech_republic.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/cz.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/slovakia.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/sk.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/hungary.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/hu.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/romania.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/ro.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/moldova.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/md.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/bulgaria.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/bg.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/france.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/fr.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/italy.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/it.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/portugal.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/pt.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/spain.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/es.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/russia.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/ru.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/belarus.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/by.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/ukraine.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/ua.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/armenia.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/am.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/azerbaijan.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/az.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/georgia.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/ge.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/bosnia_and_herzegovina.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/ba.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/croatia.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/hr.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/montenegro.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/me.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/north_macedonia.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/mk.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/serbia.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/rs.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/slovenia.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/si.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/albania.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/al.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/kosovo.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/xk.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/greece.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/gr.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/cyprus.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/cy.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/andorra.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/ad.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/malta.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/mt.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/monaco.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/mc.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/san_marino.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/sm.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/iran.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/ir.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/iraq.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/iq.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/israel.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/il.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/qatar.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/qa.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/turkey.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/tr.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/united_arab_emirates.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/ae.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/argentina.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/ar.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/costa_rica.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/cr.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/dominican_republic.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/do.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/mexico.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/mx.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/paraguay.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/py.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/peru.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/pe.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/venezuela.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/ve.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/brazil.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/br.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/trinidad.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/tt.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/chad.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/td.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/somalia.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/so.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/indonesia.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/id.svg?sanitize=true" width="24" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Or free on the Internet:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Plex TV&lt;/li&gt; 
 &lt;li&gt;Pluto TV (English, Spanish, French, Italian)&lt;/li&gt; 
 &lt;li&gt;Redbox Live TV&lt;/li&gt; 
 &lt;li&gt;Roku TV&lt;/li&gt; 
 &lt;li&gt;Samsung TV Plus&lt;/li&gt; 
 &lt;li&gt;Youtube live channels&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;To use it point your IPTV player to &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/playlist.m3u8"&gt;https://raw.githubusercontent.com/Free-TV/IPTV/master/playlist.m3u8&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;Philosophy&lt;/h1&gt; 
&lt;p&gt;The main goals for this playlist are listed below.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Quality over quantity&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;The less channels we support the better.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;All channels should work well.&lt;/li&gt; 
 &lt;li&gt;As much as possible channels should be in HD, not SD.&lt;/li&gt; 
 &lt;li&gt;Only one URL per channel (no +1, no alternate feeds, no regional declinations)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Only free channels&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;If a channel is normally only available via commercial subscriptions it has nothing to do in this playlist. If on the other hand it is provided for free to everybody in a particular country, then it should be in this playlist.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;No paid channels&lt;/li&gt; 
 &lt;li&gt;Only channels which are officially provided for free (via DVB-S, DVB-T, analog, etc..)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Only mainstream channels&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;This is a playlist for everybody.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;No adult channels&lt;/li&gt; 
 &lt;li&gt;No channels dedicated to any particular religion&lt;/li&gt; 
 &lt;li&gt;No channels dedicated to any particular political party&lt;/li&gt; 
 &lt;li&gt;No channels made for a country and funded by a different country&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Feed sources&lt;/h1&gt; 
&lt;p&gt;It can be quite hard to find up to date URLs, here's a list of sources:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/iptv-org/iptv/tree/master/streams"&gt;https://github.com/iptv-org/iptv/tree/master/streams&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Youtube: As long as the channel is live and its URL doesn't change (check the age of the stream, the number of viewers..)&lt;/li&gt; 
 &lt;li&gt;Dailymotion: Same criteria as for youtube&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Format&lt;/h1&gt; 
&lt;p&gt;The m3u8 playlist is generated by &lt;code&gt;make_playlist.py&lt;/code&gt;, using the &lt;code&gt;.md&lt;/code&gt; files located in &lt;code&gt;lists&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Each .md file represesnts a group. The &lt;code&gt;&amp;lt;h1&amp;gt;&lt;/code&gt; line is used as the group title.&lt;/p&gt; 
&lt;p&gt;Only channels which URL column starts with &lt;code&gt;[&amp;gt;]&lt;/code&gt; are included in the playlist.&lt;/p&gt; 
&lt;p&gt;Channels which are not in HD are marked with an &lt;code&gt;‚ìà&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Channels which use GeoIP blocking are marked with a &lt;code&gt;‚íº&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Channels which are live Youtube channels are marked with a &lt;code&gt;‚ìé&lt;/code&gt;.&lt;/p&gt; 
&lt;h1&gt;Issues&lt;/h1&gt; 
&lt;p&gt;Only create issues for bugs and feature requests.&lt;/p&gt; 
&lt;p&gt;Do not create issues to add/edit or to remove channels. If you want to add/edit/remove channels, create a pull request directly.&lt;/p&gt; 
&lt;h1&gt;Pull Requests&lt;/h1&gt; 
&lt;p&gt;&lt;strong&gt;Only modify .md files&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;If your Pull Request modifies channels, only modify .md files. Do not modify m3u8 files in your pull request.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Adding a new Channel&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;To add a new channel, make a Pull Request.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;In your Pull Request you need to provide information to show that the channel is free.&lt;/li&gt; 
 &lt;li&gt;Use imgur.com to host the channel logo and point to it.&lt;/li&gt; 
 &lt;li&gt;If you have a valid stream, add it and put &lt;code&gt;[&amp;gt;]&lt;/code&gt; in front of it.&lt;/li&gt; 
 &lt;li&gt;If you don't have an stream for the channel, add &lt;code&gt;[x]()&lt;/code&gt; in the url column and place your channel in the Invalid category.&lt;/li&gt; 
 &lt;li&gt;If you have a stream but it doesn't work well, put the channel in the Invalid category and put &lt;code&gt;[x]&lt;/code&gt; in front of the url.&lt;/li&gt; 
 &lt;li&gt;If you're adding geoblocked URLs specify it in your PR and specify which country they're working in. The PR will only be merged if these URLs can be tested.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Removing a Channel&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;To remove a channel, make a Pull Request.&lt;/p&gt; 
&lt;p&gt;In your Pull Request you need to provide information to show that the channel is only available via a private paid subscription.&lt;/p&gt; 
&lt;p&gt;Note: Public taxes (whether national or regional, whether called TV License or not) do not constitute a private paid subscription.&lt;/p&gt; 
&lt;p&gt;If a stream is broken, simply move the channel to the invalid category and replace &lt;code&gt;[&amp;gt;]&lt;/code&gt; with &lt;code&gt;[x]&lt;/code&gt; in the url column.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>OpenHands/OpenHands</title>
      <link>https://github.com/OpenHands/OpenHands</link>
      <description>&lt;p&gt;üôå OpenHands: Code Less, Make More&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a name="readme-top"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/All-Hands-AI/docs/main/openhands/static/img/logo.png" alt="Logo" width="200" /&gt; 
 &lt;h1 align="center"&gt;OpenHands: Code Less, Make More&lt;/h1&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://github.com/OpenHands/OpenHands/graphs/contributors"&gt;&lt;img src="https://img.shields.io/github/contributors/OpenHands/OpenHands?style=for-the-badge&amp;amp;color=blue" alt="Contributors" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/OpenHands/OpenHands/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/OpenHands/OpenHands?style=for-the-badge&amp;amp;color=blue" alt="Stargazers" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/OpenHands/OpenHands/raw/main/LICENSE"&gt;&lt;img src="https://img.shields.io/github/license/OpenHands/OpenHands?style=for-the-badge&amp;amp;color=blue" alt="MIT License" /&gt;&lt;/a&gt; 
 &lt;br /&gt; 
 &lt;a href="https://all-hands.dev/joinslack"&gt;&lt;img src="https://img.shields.io/badge/Slack-Join%20Us-red?logo=slack&amp;amp;logoColor=white&amp;amp;style=for-the-badge" alt="Join our Slack community" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/OpenHands/OpenHands/raw/main/CREDITS.md"&gt;&lt;img src="https://img.shields.io/badge/Project-Credits-blue?style=for-the-badge&amp;amp;color=FFE165&amp;amp;logo=github&amp;amp;logoColor=white" alt="Credits" /&gt;&lt;/a&gt; 
 &lt;br /&gt; 
 &lt;a href="https://docs.all-hands.dev/usage/getting-started"&gt;&lt;img src="https://img.shields.io/badge/Documentation-000?logo=googledocs&amp;amp;logoColor=FFE165&amp;amp;style=for-the-badge" alt="Check out the documentation" /&gt;&lt;/a&gt; 
 &lt;a href="https://arxiv.org/abs/2407.16741"&gt;&lt;img src="https://img.shields.io/badge/Paper%20on%20Arxiv-000?logoColor=FFE165&amp;amp;logo=arxiv&amp;amp;style=for-the-badge" alt="Paper on Arxiv" /&gt;&lt;/a&gt; 
 &lt;a href="https://docs.google.com/spreadsheets/d/1wOUdFCMyY6Nt0AIqF705KN4JKOWgeI4wUGUP60krXXs/edit?gid=0#gid=0"&gt;&lt;img src="https://img.shields.io/badge/Benchmark%20score-000?logoColor=FFE165&amp;amp;logo=huggingface&amp;amp;style=for-the-badge" alt="Evaluation Benchmark Score" /&gt;&lt;/a&gt; 
 &lt;!-- Keep these links. Translations will automatically update with the README. --&gt; 
 &lt;p&gt;&lt;a href="https://www.readme-i18n.com/OpenHands/OpenHands?lang=de"&gt;Deutsch&lt;/a&gt; | &lt;a href="https://www.readme-i18n.com/OpenHands/OpenHands?lang=es"&gt;Espa√±ol&lt;/a&gt; | &lt;a href="https://www.readme-i18n.com/OpenHands/OpenHands?lang=fr"&gt;fran√ßais&lt;/a&gt; | &lt;a href="https://www.readme-i18n.com/OpenHands/OpenHands?lang=ja"&gt;Êó•Êú¨Ë™û&lt;/a&gt; | &lt;a href="https://www.readme-i18n.com/OpenHands/OpenHands?lang=ko"&gt;ÌïúÍµ≠Ïñ¥&lt;/a&gt; | &lt;a href="https://www.readme-i18n.com/OpenHands/OpenHands?lang=pt"&gt;Portugu√™s&lt;/a&gt; | &lt;a href="https://www.readme-i18n.com/OpenHands/OpenHands?lang=ru"&gt;–†—É—Å—Å–∫–∏–π&lt;/a&gt; | &lt;a href="https://www.readme-i18n.com/OpenHands/OpenHands?lang=zh"&gt;‰∏≠Êñá&lt;/a&gt;&lt;/p&gt; 
 &lt;hr /&gt; 
&lt;/div&gt; 
&lt;p&gt;Welcome to OpenHands (formerly OpenDevin), a platform for software development agents powered by AI.&lt;/p&gt; 
&lt;p&gt;OpenHands agents can do anything a human developer can: modify code, run commands, browse the web, call APIs, and yes‚Äîeven copy code snippets from StackOverflow.&lt;/p&gt; 
&lt;p&gt;Learn more at &lt;a href="https://docs.all-hands.dev"&gt;docs.all-hands.dev&lt;/a&gt;, or &lt;a href="https://app.all-hands.dev"&gt;sign up for OpenHands Cloud&lt;/a&gt; to get started.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] &lt;strong&gt;Upcoming change&lt;/strong&gt;: We are renaming our GitHub Org from &lt;code&gt;All-Hands-AI&lt;/code&gt; to &lt;code&gt;OpenHands&lt;/code&gt; on October 20th, 2025. Check the &lt;a href="https://github.com/All-Hands-AI/OpenHands/issues/11376"&gt;tracking issue&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] Using OpenHands for work? We'd love to chat! Fill out &lt;a href="https://docs.google.com/forms/d/e/1FAIpQLSet3VbGaz8z32gW9Wm-Grl4jpt5WgMXPgJ4EDPVmCETCBpJtQ/viewform"&gt;this short form&lt;/a&gt; to join our Design Partner program, where you'll get early access to commercial features and the opportunity to provide input on our product roadmap.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;‚òÅÔ∏è OpenHands Cloud&lt;/h2&gt; 
&lt;p&gt;The easiest way to get started with OpenHands is on &lt;a href="https://app.all-hands.dev"&gt;OpenHands Cloud&lt;/a&gt;, which comes with $10 in free credits for new users.&lt;/p&gt; 
&lt;h2&gt;üíª Running OpenHands Locally&lt;/h2&gt; 
&lt;h3&gt;Option 1: CLI Launcher (Recommended)&lt;/h3&gt; 
&lt;p&gt;The easiest way to run OpenHands locally is using the CLI launcher with &lt;a href="https://docs.astral.sh/uv/"&gt;uv&lt;/a&gt;. This provides better isolation from your current project's virtual environment and is required for OpenHands' default MCP servers.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Install uv&lt;/strong&gt; (if you haven't already):&lt;/p&gt; 
&lt;p&gt;See the &lt;a href="https://docs.astral.sh/uv/getting-started/installation/"&gt;uv installation guide&lt;/a&gt; for the latest installation instructions for your platform.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Launch OpenHands&lt;/strong&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Launch the GUI server
uvx --python 3.12 openhands serve

# Or launch the CLI
uvx --python 3.12 openhands
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You'll find OpenHands running at &lt;a href="http://localhost:3000"&gt;http://localhost:3000&lt;/a&gt; (for GUI mode)!&lt;/p&gt; 
&lt;h3&gt;Option 2: Docker&lt;/h3&gt; 
&lt;details&gt; 
 &lt;summary&gt;Click to expand Docker command&lt;/summary&gt; 
 &lt;p&gt;You can also run OpenHands directly with Docker:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;docker pull docker.openhands.dev/openhands/runtime:0.61-nikolaik

docker run -it --rm --pull=always \
    -e SANDBOX_RUNTIME_CONTAINER_IMAGE=docker.openhands.dev/openhands/runtime:0.61-nikolaik \
    -e LOG_ALL_EVENTS=true \
    -v /var/run/docker.sock:/var/run/docker.sock \
    -v ~/.openhands:/.openhands \
    -p 3000:3000 \
    --add-host host.docker.internal:host-gateway \
    --name openhands-app \
    docker.openhands.dev/openhands/openhands:0.61
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: If you used OpenHands before version 0.44, you may want to run &lt;code&gt;mv ~/.openhands-state ~/.openhands&lt;/code&gt; to migrate your conversation history to the new location.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!WARNING] On a public network? See our &lt;a href="https://docs.all-hands.dev/usage/runtimes/docker#hardened-docker-installation"&gt;Hardened Docker Installation Guide&lt;/a&gt; to secure your deployment by restricting network binding and implementing additional security measures.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Getting Started&lt;/h3&gt; 
&lt;p&gt;When you open the application, you'll be asked to choose an LLM provider and add an API key. &lt;a href="https://www.anthropic.com/api"&gt;Anthropic's Claude Sonnet 4.5&lt;/a&gt; (&lt;code&gt;anthropic/claude-sonnet-4-5-20250929&lt;/code&gt;) works best, but you have &lt;a href="https://docs.all-hands.dev/usage/llms"&gt;many options&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;See the &lt;a href="https://docs.all-hands.dev/usage/installation"&gt;Running OpenHands&lt;/a&gt; guide for system requirements and more information.&lt;/p&gt; 
&lt;h2&gt;üí° Other ways to run OpenHands&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!WARNING] OpenHands is meant to be run by a single user on their local workstation. It is not appropriate for multi-tenant deployments where multiple users share the same instance. There is no built-in authentication, isolation, or scalability.&lt;/p&gt; 
 &lt;p&gt;If you're interested in running OpenHands in a multi-tenant environment, check out the source-available, commercially-licensed &lt;a href="https://github.com/openHands/OpenHands-cloud"&gt;OpenHands Cloud Helm Chart&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;You can &lt;a href="https://docs.all-hands.dev/usage/runtimes/docker#connecting-to-your-filesystem"&gt;connect OpenHands to your local filesystem&lt;/a&gt;, interact with it via a &lt;a href="https://docs.all-hands.dev/usage/how-to/cli-mode"&gt;friendly CLI&lt;/a&gt;, run OpenHands in a scriptable &lt;a href="https://docs.all-hands.dev/usage/how-to/headless-mode"&gt;headless mode&lt;/a&gt;, or run it on tagged issues with &lt;a href="https://docs.all-hands.dev/usage/how-to/github-action"&gt;a github action&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Visit &lt;a href="https://docs.all-hands.dev/usage/installation"&gt;Running OpenHands&lt;/a&gt; for more information and setup instructions.&lt;/p&gt; 
&lt;p&gt;If you want to modify the OpenHands source code, check out &lt;a href="https://github.com/OpenHands/OpenHands/raw/main/Development.md"&gt;Development.md&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Having issues? The &lt;a href="https://docs.all-hands.dev/usage/troubleshooting"&gt;Troubleshooting Guide&lt;/a&gt; can help.&lt;/p&gt; 
&lt;h2&gt;üìñ Documentation&lt;/h2&gt; 
&lt;p&gt;To learn more about the project, and for tips on using OpenHands, check out our &lt;a href="https://docs.all-hands.dev/usage/getting-started"&gt;documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;There you'll find resources on how to use different LLM providers, troubleshooting resources, and advanced configuration options.&lt;/p&gt; 
&lt;h2&gt;ü§ù How to Join the Community&lt;/h2&gt; 
&lt;p&gt;OpenHands is a community-driven project, and we welcome contributions from everyone. We do most of our communication through Slack, so this is the best place to start, but we also are happy to have you contact us on Github:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://all-hands.dev/joinslack"&gt;Join our Slack workspace&lt;/a&gt; - Here we talk about research, architecture, and future development.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/OpenHands/OpenHands/issues"&gt;Read or post Github Issues&lt;/a&gt; - Check out the issues we're working on, or add your own ideas.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;See more about the community in &lt;a href="https://raw.githubusercontent.com/OpenHands/OpenHands/main/COMMUNITY.md"&gt;COMMUNITY.md&lt;/a&gt; or find details on contributing in &lt;a href="https://raw.githubusercontent.com/OpenHands/OpenHands/main/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;üìà Progress&lt;/h2&gt; 
&lt;p&gt;See the monthly OpenHands roadmap &lt;a href="https://github.com/orgs/OpenHands/projects/1"&gt;here&lt;/a&gt; (updated at the maintainer's meeting at the end of each month).&lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://star-history.com/#OpenHands/OpenHands&amp;amp;Date"&gt; &lt;img src="https://api.star-history.com/svg?repos=OpenHands/OpenHands&amp;amp;type=Date" width="500" alt="Star History Chart" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;h2&gt;üìú License&lt;/h2&gt; 
&lt;p&gt;Distributed under the MIT License, with the exception of the &lt;code&gt;enterprise/&lt;/code&gt; folder. See &lt;a href="https://raw.githubusercontent.com/OpenHands/OpenHands/main/LICENSE"&gt;&lt;code&gt;LICENSE&lt;/code&gt;&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;h2&gt;üôè Acknowledgements&lt;/h2&gt; 
&lt;p&gt;OpenHands is built by a large number of contributors, and every contribution is greatly appreciated! We also build upon other open source projects, and we are deeply thankful for their work.&lt;/p&gt; 
&lt;p&gt;For a list of open source projects and licenses used in OpenHands, please see our &lt;a href="https://raw.githubusercontent.com/OpenHands/OpenHands/main/CREDITS.md"&gt;CREDITS.md&lt;/a&gt; file.&lt;/p&gt; 
&lt;h2&gt;üìö Cite&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;@inproceedings{
  wang2025openhands,
  title={OpenHands: An Open Platform for {AI} Software Developers as Generalist Agents},
  author={Xingyao Wang and Boxuan Li and Yufan Song and Frank F. Xu and Xiangru Tang and Mingchen Zhuge and Jiayi Pan and Yueqi Song and Bowen Li and Jaskirat Singh and Hoang H. Tran and Fuqiang Li and Ren Ma and Mingzhang Zheng and Bill Qian and Yanjun Shao and Niklas Muennighoff and Yizhe Zhang and Binyuan Hui and Junyang Lin and Robert Brennan and Hao Peng and Heng Ji and Graham Neubig},
  booktitle={The Thirteenth International Conference on Learning Representations},
  year={2025},
  url={https://openreview.net/forum?id=OJd3ayDDoF}
}
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>AtsushiSakai/PythonRobotics</title>
      <link>https://github.com/AtsushiSakai/PythonRobotics</link>
      <description>&lt;p&gt;Python sample codes and textbook for robotics algorithms.&lt;/p&gt;&lt;hr&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRobotics/raw/master/icon.png?raw=true" align="right" width="300" alt="header pic" /&gt; 
&lt;h1&gt;PythonRobotics&lt;/h1&gt; 
&lt;p&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRobotics/workflows/Linux_CI/badge.svg?sanitize=true" alt="GitHub_Action_Linux_CI" /&gt; &lt;img src="https://github.com/AtsushiSakai/PythonRobotics/workflows/MacOS_CI/badge.svg?sanitize=true" alt="GitHub_Action_MacOS_CI" /&gt; &lt;img src="https://github.com/AtsushiSakai/PythonRobotics/workflows/Windows_CI/badge.svg?sanitize=true" alt="GitHub_Action_Windows_CI" /&gt; &lt;a href="https://ci.appveyor.com/project/AtsushiSakai/pythonrobotics"&gt;&lt;img src="https://ci.appveyor.com/api/projects/status/sb279kxuv1be391g?svg=true" alt="Build status" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Python codes and &lt;a href="https://atsushisakai.github.io/PythonRobotics/index.html"&gt;textbook&lt;/a&gt; for robotics algorithm.&lt;/p&gt; 
&lt;h1&gt;Table of Contents&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#what-is-this"&gt;What is this?&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#requirements"&gt;Requirements&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#documentation"&gt;Documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#how-to-use"&gt;How to use&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#localization"&gt;Localization&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#extended-kalman-filter-localization"&gt;Extended Kalman Filter localization&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#particle-filter-localization"&gt;Particle filter localization&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#histogram-filter-localization"&gt;Histogram filter localization&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#mapping"&gt;Mapping&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#gaussian-grid-map"&gt;Gaussian grid map&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#ray-casting-grid-map"&gt;Ray casting grid map&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#lidar-to-grid-map"&gt;Lidar to grid map&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#k-means-object-clustering"&gt;k-means object clustering&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#rectangle-fitting"&gt;Rectangle fitting&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#slam"&gt;SLAM&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#iterative-closest-point-icp-matching"&gt;Iterative Closest Point (ICP) Matching&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#fastslam-10"&gt;FastSLAM 1.0&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#path-planning"&gt;Path Planning&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#dynamic-window-approach"&gt;Dynamic Window Approach&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#grid-based-search"&gt;Grid based search&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#dijkstra-algorithm"&gt;Dijkstra algorithm&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#a-algorithm"&gt;A* algorithm&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#d-algorithm"&gt;D* algorithm&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#d-lite-algorithm"&gt;D* Lite algorithm&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#potential-field-algorithm"&gt;Potential Field algorithm&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#grid-based-coverage-path-planning"&gt;Grid based coverage path planning&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#particle-swarm-optimization-pso"&gt;Particle Swarm Optimization (PSO)&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#state-lattice-planning"&gt;State Lattice Planning&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#biased-polar-sampling"&gt;Biased polar sampling&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#lane-sampling"&gt;Lane sampling&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#probabilistic-road-map-prm-planning"&gt;Probabilistic Road-Map (PRM) planning&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#rapidly-exploring-random-trees-rrt"&gt;Rapidly-Exploring Random Trees (RRT)&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#rrt"&gt;RRT*&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#rrt-with-reeds-shepp-path"&gt;RRT* with reeds-shepp path&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#lqr-rrt"&gt;LQR-RRT*&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#quintic-polynomials-planning"&gt;Quintic polynomials planning&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#reeds-shepp-planning"&gt;Reeds Shepp planning&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#lqr-based-path-planning"&gt;LQR based path planning&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#optimal-trajectory-in-a-frenet-frame"&gt;Optimal Trajectory in a Frenet Frame&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#path-tracking"&gt;Path Tracking&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#move-to-a-pose-control"&gt;move to a pose control&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#stanley-control"&gt;Stanley control&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#rear-wheel-feedback-control"&gt;Rear wheel feedback control&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#linearquadratic-regulator-lqr-speed-and-steering-control"&gt;Linear‚Äìquadratic regulator (LQR) speed and steering control&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#model-predictive-speed-and-steering-control"&gt;Model predictive speed and steering control&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#nonlinear-model-predictive-control-with-c-gmres"&gt;Nonlinear Model predictive control with C-GMRES&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#arm-navigation"&gt;Arm Navigation&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#n-joint-arm-to-point-control"&gt;N joint arm to point control&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#arm-navigation-with-obstacle-avoidance"&gt;Arm navigation with obstacle avoidance&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#aerial-navigation"&gt;Aerial Navigation&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#drone-3d-trajectory-following"&gt;drone 3d trajectory following&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#rocket-powered-landing"&gt;rocket powered landing&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#bipedal"&gt;Bipedal&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#bipedal-planner-with-inverted-pendulum"&gt;bipedal planner with inverted pendulum&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#license"&gt;License&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#use-case"&gt;Use-case&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#contribution"&gt;Contribution&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#citing"&gt;Citing&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#support"&gt;Support&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#sponsors"&gt;Sponsors&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#JetBrains"&gt;JetBrains&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#1password"&gt;1Password&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#authors"&gt;Authors&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;What is PythonRobotics?&lt;/h1&gt; 
&lt;p&gt;PythonRobotics is a Python code collection and a &lt;a href="https://atsushisakai.github.io/PythonRobotics/index.html"&gt;textbook&lt;/a&gt; of robotics algorithms.&lt;/p&gt; 
&lt;p&gt;Features:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Easy to read for understanding each algorithm's basic idea.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Widely used and practical algorithms are selected.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Minimum dependency.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;See this documentation&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://atsushisakai.github.io/PythonRobotics/modules/0_getting_started/1_what_is_python_robotics.html"&gt;Getting Started ‚Äî PythonRobotics documentation&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;or this Youtube video:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=uMeRnNoJAfU"&gt;PythonRobotics project audio overview&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;or this paper for more details:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://arxiv.org/abs/1808.10703"&gt;[1808.10703] PythonRobotics: a Python code collection of robotics algorithms&lt;/a&gt; (&lt;a href="https://github.com/AtsushiSakai/PythonRoboticsPaper/raw/master/python_robotics.bib"&gt;BibTeX&lt;/a&gt;)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Requirements to run the code&lt;/h1&gt; 
&lt;p&gt;For running each sample code:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://www.python.org/"&gt;Python 3.13.x&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://numpy.org/"&gt;NumPy&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://scipy.org/"&gt;SciPy&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://matplotlib.org/"&gt;Matplotlib&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://www.cvxpy.org/"&gt;cvxpy&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For development:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://pytest.org/"&gt;pytest&lt;/a&gt; (for unit tests)&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://pypi.org/project/pytest-xdist/"&gt;pytest-xdist&lt;/a&gt; (for parallel unit tests)&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://mypy-lang.org/"&gt;mypy&lt;/a&gt; (for type check)&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://www.sphinx-doc.org/"&gt;sphinx&lt;/a&gt; (for document generation)&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://pypi.org/project/pycodestyle/"&gt;pycodestyle&lt;/a&gt; (for code style check)&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Documentation (Textbook)&lt;/h1&gt; 
&lt;p&gt;This README only shows some examples of this project.&lt;/p&gt; 
&lt;p&gt;If you are interested in other examples or mathematical backgrounds of each algorithm,&lt;/p&gt; 
&lt;p&gt;You can check the full documentation (textbook) online: &lt;a href="https://atsushisakai.github.io/PythonRobotics/index.html"&gt;Welcome to PythonRobotics‚Äôs documentation! ‚Äî PythonRobotics documentation&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;All animation gifs are stored here: &lt;a href="https://github.com/AtsushiSakai/PythonRoboticsGifs"&gt;AtsushiSakai/PythonRoboticsGifs: Animation gifs of PythonRobotics&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;How to use&lt;/h1&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Clone this repo.&lt;/p&gt; &lt;pre&gt;&lt;code class="language-terminal"&gt;git clone https://github.com/AtsushiSakai/PythonRobotics.git
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Install the required libraries.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;using conda :&lt;/p&gt; &lt;pre&gt;&lt;code class="language-terminal"&gt;conda env create -f requirements/environment.yml
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;using pip :&lt;/p&gt; &lt;pre&gt;&lt;code class="language-terminal"&gt;pip install -r requirements/requirements.txt
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt; &lt;p&gt;Execute python script in each directory.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Add star to this repo if you like it &lt;span&gt;üòÉ&lt;/span&gt;.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h1&gt;Localization&lt;/h1&gt; 
&lt;h2&gt;Extended Kalman Filter localization&lt;/h2&gt; 
&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/Localization/extended_kalman_filter/animation.gif" width="640" alt="EKF pic" /&gt; 
&lt;p&gt;Reference&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://atsushisakai.github.io/PythonRobotics/modules/2_localization/extended_kalman_filter_localization_files/extended_kalman_filter_localization.html"&gt;documentation&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Particle filter localization&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/Localization/particle_filter/animation.gif" alt="2" /&gt;&lt;/p&gt; 
&lt;p&gt;This is a sensor fusion localization with Particle Filter(PF).&lt;/p&gt; 
&lt;p&gt;The blue line is true trajectory, the black line is dead reckoning trajectory,&lt;/p&gt; 
&lt;p&gt;and the red line is an estimated trajectory with PF.&lt;/p&gt; 
&lt;p&gt;It is assumed that the robot can measure a distance from landmarks (RFID).&lt;/p&gt; 
&lt;p&gt;These measurements are used for PF localization.&lt;/p&gt; 
&lt;p&gt;Reference&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="http://www.probabilistic-robotics.org/"&gt;PROBABILISTIC ROBOTICS&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Histogram filter localization&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/Localization/histogram_filter/animation.gif" alt="3" /&gt;&lt;/p&gt; 
&lt;p&gt;This is a 2D localization example with Histogram filter.&lt;/p&gt; 
&lt;p&gt;The red cross is true position, black points are RFID positions.&lt;/p&gt; 
&lt;p&gt;The blue grid shows a position probability of histogram filter.&lt;/p&gt; 
&lt;p&gt;In this simulation, x,y are unknown, yaw is known.&lt;/p&gt; 
&lt;p&gt;The filter integrates speed input and range observations from RFID for localization.&lt;/p&gt; 
&lt;p&gt;Initial position is not needed.&lt;/p&gt; 
&lt;p&gt;Reference&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="http://www.probabilistic-robotics.org/"&gt;PROBABILISTIC ROBOTICS&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Mapping&lt;/h1&gt; 
&lt;h2&gt;Gaussian grid map&lt;/h2&gt; 
&lt;p&gt;This is a 2D Gaussian grid mapping example.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/Mapping/gaussian_grid_map/animation.gif" alt="2" /&gt;&lt;/p&gt; 
&lt;h2&gt;Ray casting grid map&lt;/h2&gt; 
&lt;p&gt;This is a 2D ray casting grid mapping example.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/Mapping/raycasting_grid_map/animation.gif" alt="2" /&gt;&lt;/p&gt; 
&lt;h2&gt;Lidar to grid map&lt;/h2&gt; 
&lt;p&gt;This example shows how to convert a 2D range measurement to a grid map.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/Mapping/lidar_to_grid_map/animation.gif" alt="2" /&gt;&lt;/p&gt; 
&lt;h2&gt;k-means object clustering&lt;/h2&gt; 
&lt;p&gt;This is a 2D object clustering with k-means algorithm.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/Mapping/kmeans_clustering/animation.gif" alt="2" /&gt;&lt;/p&gt; 
&lt;h2&gt;Rectangle fitting&lt;/h2&gt; 
&lt;p&gt;This is a 2D rectangle fitting for vehicle detection.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/Mapping/rectangle_fitting/animation.gif" alt="2" /&gt;&lt;/p&gt; 
&lt;h1&gt;SLAM&lt;/h1&gt; 
&lt;p&gt;Simultaneous Localization and Mapping(SLAM) examples&lt;/p&gt; 
&lt;h2&gt;Iterative Closest Point (ICP) Matching&lt;/h2&gt; 
&lt;p&gt;This is a 2D ICP matching example with singular value decomposition.&lt;/p&gt; 
&lt;p&gt;It can calculate a rotation matrix, and a translation vector between points and points.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/SLAM/iterative_closest_point/animation.gif" alt="3" /&gt;&lt;/p&gt; 
&lt;p&gt;Reference&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://cs.gmu.edu/~kosecka/cs685/cs685-icp.pdf"&gt;Introduction to Mobile Robotics: Iterative Closest Point Algorithm&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;FastSLAM 1.0&lt;/h2&gt; 
&lt;p&gt;This is a feature based SLAM example using FastSLAM 1.0.&lt;/p&gt; 
&lt;p&gt;The blue line is ground truth, the black line is dead reckoning, the red line is the estimated trajectory with FastSLAM.&lt;/p&gt; 
&lt;p&gt;The red points are particles of FastSLAM.&lt;/p&gt; 
&lt;p&gt;Black points are landmarks, blue crosses are estimated landmark positions by FastSLAM.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/SLAM/FastSLAM1/animation.gif" alt="3" /&gt;&lt;/p&gt; 
&lt;p&gt;Reference&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="http://www.probabilistic-robotics.org/"&gt;PROBABILISTIC ROBOTICS&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="http://www-personal.acfr.usyd.edu.au/tbailey/software/slam_simulations.htm"&gt;SLAM simulations by Tim Bailey&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Path Planning&lt;/h1&gt; 
&lt;h2&gt;Dynamic Window Approach&lt;/h2&gt; 
&lt;p&gt;This is a 2D navigation sample code with Dynamic Window Approach.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.ri.cmu.edu/pub_files/pub1/fox_dieter_1997_1/fox_dieter_1997_1.pdf"&gt;The Dynamic Window Approach to Collision Avoidance&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/DynamicWindowApproach/animation.gif" alt="2" /&gt;&lt;/p&gt; 
&lt;h2&gt;Grid based search&lt;/h2&gt; 
&lt;h3&gt;Dijkstra algorithm&lt;/h3&gt; 
&lt;p&gt;This is a 2D grid based the shortest path planning with Dijkstra's algorithm.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/Dijkstra/animation.gif" alt="PythonRobotics/figure_1.png at master ¬∑ AtsushiSakai/PythonRobotics" /&gt;&lt;/p&gt; 
&lt;p&gt;In the animation, cyan points are searched nodes.&lt;/p&gt; 
&lt;h3&gt;A* algorithm&lt;/h3&gt; 
&lt;p&gt;This is a 2D grid based the shortest path planning with A star algorithm.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/AStar/animation.gif" alt="PythonRobotics/figure_1.png at master ¬∑ AtsushiSakai/PythonRobotics" /&gt;&lt;/p&gt; 
&lt;p&gt;In the animation, cyan points are searched nodes.&lt;/p&gt; 
&lt;p&gt;Its heuristic is 2D Euclid distance.&lt;/p&gt; 
&lt;h3&gt;D* algorithm&lt;/h3&gt; 
&lt;p&gt;This is a 2D grid based the shortest path planning with D star algorithm.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/DStar/animation.gif" alt="figure at master ¬∑ nirnayroy/intelligentrobotics" /&gt;&lt;/p&gt; 
&lt;p&gt;The animation shows a robot finding its path avoiding an obstacle using the D* search algorithm.&lt;/p&gt; 
&lt;p&gt;Reference&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/D*"&gt;D* Algorithm Wikipedia&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;D* Lite algorithm&lt;/h3&gt; 
&lt;p&gt;This algorithm finds the shortest path between two points while rerouting when obstacles are discovered. It has been implemented here for a 2D grid.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/DStarLite/animation.gif" alt="D* Lite" /&gt;&lt;/p&gt; 
&lt;p&gt;The animation shows a robot finding its path and rerouting to avoid obstacles as they are discovered using the D* Lite search algorithm.&lt;/p&gt; 
&lt;p&gt;Refs:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="http://idm-lab.org/bib/abstracts/papers/aaai02b.pdf"&gt;D* Lite&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://www.cs.cmu.edu/~maxim/files/dlite_icra02.pdf"&gt;Improved Fast Replanning for Robot Navigation in Unknown Terrain&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Potential Field algorithm&lt;/h3&gt; 
&lt;p&gt;This is a 2D grid based path planning with Potential Field algorithm.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/PotentialFieldPlanning/animation.gif" alt="PotentialField" /&gt;&lt;/p&gt; 
&lt;p&gt;In the animation, the blue heat map shows potential value on each grid.&lt;/p&gt; 
&lt;p&gt;Reference&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.cs.cmu.edu/~motionplanning/lecture/Chap4-Potential-Field_howie.pdf"&gt;Robotic Motion Planning:Potential Functions&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Grid based coverage path planning&lt;/h3&gt; 
&lt;p&gt;This is a 2D grid based coverage path planning simulation.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/GridBasedSweepCPP/animation.gif" alt="PotentialField" /&gt;&lt;/p&gt; 
&lt;h3&gt;Particle Swarm Optimization (PSO)&lt;/h3&gt; 
&lt;p&gt;This is a 2D path planning simulation using the Particle Swarm Optimization algorithm.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/ParticleSwarmOptimization/animation.gif" alt="PSO" /&gt;&lt;/p&gt; 
&lt;p&gt;PSO is a metaheuristic optimization algorithm inspired by bird flocking behavior. In path planning, particles explore the search space to find collision-free paths while avoiding obstacles.&lt;/p&gt; 
&lt;p&gt;The animation shows particles (blue dots) converging towards the optimal path (yellow line) from start (green area) to goal (red star).&lt;/p&gt; 
&lt;p&gt;References&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://en.wikipedia.org/wiki/Particle_swarm_optimization"&gt;Particle swarm optimization - Wikipedia&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://ieeexplore.ieee.org/document/488968"&gt;Kennedy, J.; Eberhart, R. (1995). "Particle Swarm Optimization"&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;State Lattice Planning&lt;/h2&gt; 
&lt;p&gt;This script is a path planning code with state lattice planning.&lt;/p&gt; 
&lt;p&gt;This code uses the model predictive trajectory generator to solve boundary problem.&lt;/p&gt; 
&lt;p&gt;Reference&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://journals.sagepub.com/doi/pdf/10.1177/0278364906075328"&gt;Optimal rough terrain trajectory generation for wheeled mobile robots&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://www.cs.cmu.edu/~alonzo/pubs/papers/JFR_08_SS_Sampling.pdf"&gt;State Space Sampling of Feasible Motions for High-Performance Mobile Robot Navigation in Complex Environments&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Biased polar sampling&lt;/h3&gt; 
&lt;p&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/StateLatticePlanner/BiasedPolarSampling.gif" alt="PythonRobotics/figure_1.png at master ¬∑ AtsushiSakai/PythonRobotics" /&gt;&lt;/p&gt; 
&lt;h3&gt;Lane sampling&lt;/h3&gt; 
&lt;p&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/StateLatticePlanner/LaneSampling.gif" alt="PythonRobotics/figure_1.png at master ¬∑ AtsushiSakai/PythonRobotics" /&gt;&lt;/p&gt; 
&lt;h2&gt;Probabilistic Road-Map (PRM) planning&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/ProbabilisticRoadMap/animation.gif" alt="PRM" /&gt;&lt;/p&gt; 
&lt;p&gt;This PRM planner uses Dijkstra method for graph search.&lt;/p&gt; 
&lt;p&gt;In the animation, blue points are sampled points,&lt;/p&gt; 
&lt;p&gt;Cyan crosses means searched points with Dijkstra method,&lt;/p&gt; 
&lt;p&gt;The red line is the final path of PRM.&lt;/p&gt; 
&lt;p&gt;Reference&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Probabilistic_roadmap"&gt;Probabilistic roadmap - Wikipedia&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;„ÄÄ„ÄÄ&lt;/p&gt; 
&lt;h2&gt;Rapidly-Exploring Random Trees (RRT)&lt;/h2&gt; 
&lt;h3&gt;RRT*&lt;/h3&gt; 
&lt;p&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/RRTstar/animation.gif" alt="PythonRobotics/figure_1.png at master ¬∑ AtsushiSakai/PythonRobotics" /&gt;&lt;/p&gt; 
&lt;p&gt;This is a path planning code with RRT*&lt;/p&gt; 
&lt;p&gt;Black circles are obstacles, green line is a searched tree, red crosses are start and goal positions.&lt;/p&gt; 
&lt;p&gt;Reference&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://arxiv.org/abs/1005.0416"&gt;Incremental Sampling-based Algorithms for Optimal Motion Planning&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://citeseerx.ist.psu.edu/document?repid=rep1&amp;amp;type=pdf&amp;amp;doi=bddbc99f97173430aa49a0ada53ab5bade5902fa"&gt;Sampling-based Algorithms for Optimal Motion Planning&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;RRT* with reeds-shepp path&lt;/h3&gt; 
&lt;p&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/RRTStarReedsShepp/animation.gif" alt="Robotics/animation.gif at master ¬∑ AtsushiSakai/PythonRobotics" /&gt;&lt;/p&gt; 
&lt;p&gt;Path planning for a car robot with RRT* and reeds shepp path planner.&lt;/p&gt; 
&lt;h3&gt;LQR-RRT*&lt;/h3&gt; 
&lt;p&gt;This is a path planning simulation with LQR-RRT*.&lt;/p&gt; 
&lt;p&gt;A double integrator motion model is used for LQR local planner.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/LQRRRTStar/animation.gif" alt="LQR_RRT" /&gt;&lt;/p&gt; 
&lt;p&gt;Reference&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://lis.csail.mit.edu/pubs/perez-icra12.pdf"&gt;LQR-RRT*: Optimal Sampling-Based Motion Planning with Automatically Derived Extension Heuristics&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/MahanFathi/LQR-RRTstar"&gt;MahanFathi/LQR-RRTstar: LQR-RRT* method is used for random motion planning of a simple pendulum in its phase plot&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Quintic polynomials planning&lt;/h2&gt; 
&lt;p&gt;Motion planning with quintic polynomials.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/QuinticPolynomialsPlanner/animation.gif" alt="2" /&gt;&lt;/p&gt; 
&lt;p&gt;It can calculate a 2D path, velocity, and acceleration profile based on quintic polynomials.&lt;/p&gt; 
&lt;p&gt;Reference&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://ieeexplore.ieee.org/document/637936/"&gt;Local Path Planning And Motion Control For Agv In Positioning&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Reeds Shepp planning&lt;/h2&gt; 
&lt;p&gt;A sample code with Reeds Shepp path planning.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/ReedsSheppPath/animation.gif?raw=true" alt="RSPlanning" /&gt;&lt;/p&gt; 
&lt;p&gt;Reference&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="http://planning.cs.uiuc.edu/node822.html"&gt;15.3.2 Reeds-Shepp Curves&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://pdfs.semanticscholar.org/932e/c495b1d0018fd59dee12a0bf74434fac7af4.pdf"&gt;optimal paths for a car that goes both forwards and backwards&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/ghliu/pyReedsShepp"&gt;ghliu/pyReedsShepp: Implementation of Reeds Shepp curve.&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;LQR based path planning&lt;/h2&gt; 
&lt;p&gt;A sample code using LQR based path planning for double integrator model.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/LQRPlanner/animation.gif?raw=true" alt="RSPlanning" /&gt;&lt;/p&gt; 
&lt;h2&gt;Optimal Trajectory in a Frenet Frame&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/FrenetOptimalTrajectory/animation.gif" alt="3" /&gt;&lt;/p&gt; 
&lt;p&gt;This is optimal trajectory generation in a Frenet Frame.&lt;/p&gt; 
&lt;p&gt;The cyan line is the target course and black crosses are obstacles.&lt;/p&gt; 
&lt;p&gt;The red line is the predicted path.&lt;/p&gt; 
&lt;p&gt;Reference&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://www.researchgate.net/profile/Moritz_Werling/publication/224156269_Optimal_Trajectory_Generation_for_Dynamic_Street_Scenarios_in_a_Frenet_Frame/links/54f749df0cf210398e9277af.pdf"&gt;Optimal Trajectory Generation for Dynamic Street Scenarios in a Frenet Frame&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=Cj6tAQe7UCY"&gt;Optimal trajectory generation for dynamic street scenarios in a Frenet Frame&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Path Tracking&lt;/h1&gt; 
&lt;h2&gt;move to a pose control&lt;/h2&gt; 
&lt;p&gt;This is a simulation of moving to a pose control&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/Control/move_to_pose/animation.gif" alt="2" /&gt;&lt;/p&gt; 
&lt;p&gt;Reference&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://link.springer.com/book/10.1007/978-3-642-20144-8"&gt;P. I. Corke, "Robotics, Vision and Control" | SpringerLink p102&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Stanley control&lt;/h2&gt; 
&lt;p&gt;Path tracking simulation with Stanley steering control and PID speed control.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathTracking/stanley_controller/animation.gif" alt="2" /&gt;&lt;/p&gt; 
&lt;p&gt;Reference&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="http://robots.stanford.edu/papers/thrun.stanley05.pdf"&gt;Stanley: The robot that won the DARPA grand challenge&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://www.ri.cmu.edu/pub_files/2009/2/Automatic_Steering_Methods_for_Autonomous_Automobile_Path_Tracking.pdf"&gt;Automatic Steering Methods for Autonomous Automobile Path Tracking&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Rear wheel feedback control&lt;/h2&gt; 
&lt;p&gt;Path tracking simulation with rear wheel feedback steering control and PID speed control.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathTracking/rear_wheel_feedback/animation.gif" alt="PythonRobotics/figure_1.png at master ¬∑ AtsushiSakai/PythonRobotics" /&gt;&lt;/p&gt; 
&lt;p&gt;Reference&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://arxiv.org/abs/1604.07446"&gt;A Survey of Motion Planning and Control Techniques for Self-driving Urban Vehicles&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Linear‚Äìquadratic regulator (LQR) speed and steering control&lt;/h2&gt; 
&lt;p&gt;Path tracking simulation with LQR speed and steering control.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathTracking/lqr_speed_steer_control/animation.gif" alt="3" /&gt;&lt;/p&gt; 
&lt;p&gt;Reference&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://ieeexplore.ieee.org/document/5940562/"&gt;Towards fully autonomous driving: Systems and algorithms - IEEE Conference Publication&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Model predictive speed and steering control&lt;/h2&gt; 
&lt;p&gt;Path tracking simulation with iterative linear model predictive speed and steering control.&lt;/p&gt; 
&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathTracking/model_predictive_speed_and_steer_control/animation.gif" width="640" alt="MPC pic" /&gt; 
&lt;p&gt;Reference&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://atsushisakai.github.io/PythonRobotics/modules/6_path_tracking/model_predictive_speed_and_steering_control/model_predictive_speed_and_steering_control.html"&gt;documentation&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="http://grauonline.de/wordpress/?page_id=3244"&gt;Real-time Model Predictive Control (MPC), ACADO, Python | Work-is-Playing&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Nonlinear Model predictive control with C-GMRES&lt;/h2&gt; 
&lt;p&gt;A motion planning and path tracking simulation with NMPC of C-GMRES&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathTracking/cgmres_nmpc/animation.gif" alt="3" /&gt;&lt;/p&gt; 
&lt;p&gt;Reference&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://atsushisakai.github.io/PythonRobotics/modules/6_path_tracking/cgmres_nmpc/cgmres_nmpc.html"&gt;documentation&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Arm Navigation&lt;/h1&gt; 
&lt;h2&gt;N joint arm to point control&lt;/h2&gt; 
&lt;p&gt;N joint arm to a point control simulation.&lt;/p&gt; 
&lt;p&gt;This is an interactive simulation.&lt;/p&gt; 
&lt;p&gt;You can set the goal position of the end effector with left-click on the plotting area.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/ArmNavigation/n_joint_arm_to_point_control/animation.gif" alt="3" /&gt;&lt;/p&gt; 
&lt;p&gt;In this simulation N = 10, however, you can change it.&lt;/p&gt; 
&lt;h2&gt;Arm navigation with obstacle avoidance&lt;/h2&gt; 
&lt;p&gt;Arm navigation with obstacle avoidance simulation.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/ArmNavigation/arm_obstacle_navigation/animation.gif" alt="3" /&gt;&lt;/p&gt; 
&lt;h1&gt;Aerial Navigation&lt;/h1&gt; 
&lt;h2&gt;drone 3d trajectory following&lt;/h2&gt; 
&lt;p&gt;This is a 3d trajectory following simulation for a quadrotor.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/AerialNavigation/drone_3d_trajectory_following/animation.gif" alt="3" /&gt;&lt;/p&gt; 
&lt;h2&gt;rocket powered landing&lt;/h2&gt; 
&lt;p&gt;This is a 3d trajectory generation simulation for a rocket powered landing.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/AerialNavigation/rocket_powered_landing/animation.gif" alt="3" /&gt;&lt;/p&gt; 
&lt;p&gt;Reference&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://atsushisakai.github.io/PythonRobotics/modules/8_aerial_navigation/rocket_powered_landing/rocket_powered_landing.html"&gt;documentation&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Bipedal&lt;/h1&gt; 
&lt;h2&gt;bipedal planner with inverted pendulum&lt;/h2&gt; 
&lt;p&gt;This is a bipedal planner for modifying footsteps for an inverted pendulum.&lt;/p&gt; 
&lt;p&gt;You can set the footsteps, and the planner will modify those automatically.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/Bipedal/bipedal_planner/animation.gif" alt="3" /&gt;&lt;/p&gt; 
&lt;h1&gt;License&lt;/h1&gt; 
&lt;p&gt;MIT&lt;/p&gt; 
&lt;h1&gt;Use-case&lt;/h1&gt; 
&lt;p&gt;If this project helps your robotics project, please let me know with creating an issue.&lt;/p&gt; 
&lt;p&gt;Your robot's video, which is using PythonRobotics, is very welcome!!&lt;/p&gt; 
&lt;p&gt;This is a list of user's comment and references:&lt;a href="https://github.com/AtsushiSakai/PythonRobotics/raw/master/users_comments.md"&gt;users_comments&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Contribution&lt;/h1&gt; 
&lt;p&gt;Any contribution is welcome!!&lt;/p&gt; 
&lt;p&gt;Please check this document:&lt;a href="https://atsushisakai.github.io/PythonRobotics/modules/0_getting_started/3_how_to_contribute.html"&gt;How To Contribute ‚Äî PythonRobotics documentation&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Citing&lt;/h1&gt; 
&lt;p&gt;If you use this project's code for your academic work, we encourage you to cite &lt;a href="https://arxiv.org/abs/1808.10703"&gt;our papers&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;If you use this project's code in industry, we'd love to hear from you as well; feel free to reach out to the developers directly.&lt;/p&gt; 
&lt;h1&gt;&lt;a id="support"&gt;&lt;/a&gt;Supporting this project&lt;/h1&gt; 
&lt;p&gt;If you or your company would like to support this project, please consider:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/sponsors/AtsushiSakai"&gt;Sponsor @AtsushiSakai on GitHub Sponsors&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://www.patreon.com/myenigma"&gt;Become a backer or sponsor on Patreon&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://www.paypal.com/paypalme/myenigmapay/"&gt;One-time donation via PayPal&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;If you would like to support us in some other way, please contact with creating an issue.&lt;/p&gt; 
&lt;h2&gt;&lt;a id="sponsors"&gt;&lt;/a&gt;Sponsors&lt;/h2&gt; 
&lt;h3&gt;&lt;a id="JetBrains"&gt;&lt;/a&gt;&lt;a href="https://www.jetbrains.com/"&gt;JetBrains&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;They are providing a free license of their IDEs for this OSS development.&lt;/p&gt; 
&lt;h3&gt;&lt;a href="https://github.com/1Password/for-open-source"&gt;1Password&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;They are providing a free license of their 1Password team license for this OSS project.&lt;/p&gt; 
&lt;h1&gt;Authors&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/AtsushiSakai/PythonRobotics/graphs/contributors"&gt;Contributors to AtsushiSakai/PythonRobotics&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>sansan0/TrendRadar</title>
      <link>https://github.com/sansan0/TrendRadar</link>
      <description>&lt;p&gt;üéØ ÂëäÂà´‰ø°ÊÅØËøáËΩΩÔºåAI Âä©‰Ω†ÁúãÊáÇÊñ∞ÈóªËµÑËÆØÁÉ≠ÁÇπÔºåÁÆÄÂçïÁöÑËàÜÊÉÖÁõëÊéßÂàÜÊûê - Â§öÂπ≥Âè∞ÁÉ≠ÁÇπËÅöÂêà+Âü∫‰∫é MCP ÁöÑAIÂàÜÊûêÂ∑•ÂÖ∑„ÄÇÁõëÊéß35‰∏™Âπ≥Âè∞ÔºàÊäñÈü≥„ÄÅÁü•‰πé„ÄÅBÁ´ô„ÄÅÂçéÂ∞îË°óËßÅÈóª„ÄÅË¥¢ËÅîÁ§æÁ≠âÔºâÔºåÊô∫ËÉΩÁ≠õÈÄâ+Ëá™Âä®Êé®ÈÄÅ+AIÂØπËØùÂàÜÊûêÔºàÁî®Ëá™ÁÑ∂ËØ≠Ë®ÄÊ∑±Â∫¶ÊåñÊéòÊñ∞ÈóªÔºöË∂ãÂäøËøΩË∏™„ÄÅÊÉÖÊÑüÂàÜÊûê„ÄÅÁõ∏‰ººÊ£ÄÁ¥¢Á≠â13ÁßçÂ∑•ÂÖ∑Ôºâ„ÄÇÊîØÊåÅ‰ºÅ‰∏öÂæÆ‰ø°/È£û‰π¶/ÈíâÈíâ/Telegram/ÈÇÆ‰ª∂/ntfyÊé®ÈÄÅÔºå30ÁßíÁΩëÈ°µÈÉ®ÁΩ≤Ôºå1ÂàÜÈíüÊâãÊú∫ÈÄöÁü•ÔºåÊó†ÈúÄÁºñÁ®ã„ÄÇÊîØÊåÅDockerÈÉ®ÁΩ≤‚≠ê ËÆ©ÁÆóÊ≥ï‰∏∫‰Ω†ÊúçÂä°ÔºåÁî®AIÁêÜËß£ÁÉ≠ÁÇπ&lt;/p&gt;&lt;hr&gt;&lt;div align="center" id="trendradar"&gt; 
 &lt;a href="https://github.com/sansan0/TrendRadar" title="TrendRadar"&gt; &lt;img src="https://raw.githubusercontent.com/sansan0/TrendRadar/master/_image/banner.jpg" alt="TrendRadar Banner" width="50%" /&gt; &lt;/a&gt; 
 &lt;p&gt;üöÄ ÊúÄÂø´&lt;strong&gt;30Áßí&lt;/strong&gt;ÈÉ®ÁΩ≤ÁöÑÁÉ≠ÁÇπÂä©Êâã ‚Äî‚Äî ÂëäÂà´Êó†ÊïàÂà∑Â±èÔºåÂè™ÁúãÁúüÊ≠£ÂÖ≥ÂøÉÁöÑÊñ∞ÈóªËµÑËÆØ&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://trendshift.io/repositories/14726" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/14726" alt="sansan0%2FTrendRadar | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://github.com/sansan0/TrendRadar/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/sansan0/TrendRadar?style=flat-square&amp;amp;logo=github&amp;amp;color=yellow" alt="GitHub Stars" /&gt;&lt;/a&gt; &lt;a href="https://github.com/sansan0/TrendRadar/network/members"&gt;&lt;img src="https://img.shields.io/github/forks/sansan0/TrendRadar?style=flat-square&amp;amp;logo=github&amp;amp;color=blue" alt="GitHub Forks" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/LICENSE"&gt;&lt;img src="https://img.shields.io/badge/license-GPL--3.0-blue.svg?style=flat-square" alt="License" /&gt;&lt;/a&gt; &lt;a href="https://github.com/sansan0/TrendRadar"&gt;&lt;img src="https://img.shields.io/badge/version-v3.0.4-blue.svg?sanitize=true" alt="Version" /&gt;&lt;/a&gt; &lt;a href="https://github.com/sansan0/TrendRadar"&gt;&lt;img src="https://img.shields.io/badge/MCP-v1.0.1-green.svg?sanitize=true" alt="MCP" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://work.weixin.qq.com/"&gt;&lt;img src="https://img.shields.io/badge/%E4%BC%81%E4%B8%9A%E5%BE%AE%E4%BF%A1-%E9%80%9A%E7%9F%A5-00D4AA?style=flat-square" alt="‰ºÅ‰∏öÂæÆ‰ø°ÈÄöÁü•" /&gt;&lt;/a&gt; &lt;a href="https://telegram.org/"&gt;&lt;img src="https://img.shields.io/badge/Telegram-%E9%80%9A%E7%9F%A5-00D4AA?style=flat-square" alt="TelegramÈÄöÁü•" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/#"&gt;&lt;img src="https://img.shields.io/badge/%E9%92%89%E9%92%89-%E9%80%9A%E7%9F%A5-00D4AA?style=flat-square" alt="dingtalkÈÄöÁü•" /&gt;&lt;/a&gt; &lt;a href="https://www.feishu.cn/"&gt;&lt;img src="https://img.shields.io/badge/%E9%A3%9E%E4%B9%A6-%E9%80%9A%E7%9F%A5-00D4AA?style=flat-square" alt="È£û‰π¶ÈÄöÁü•" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/#"&gt;&lt;img src="https://img.shields.io/badge/Email-%E9%80%9A%E7%9F%A5-00D4AA?style=flat-square" alt="ÈÇÆ‰ª∂ÈÄöÁü•" /&gt;&lt;/a&gt; &lt;a href="https://github.com/binwiederhier/ntfy"&gt;&lt;img src="https://img.shields.io/badge/ntfy-%E9%80%9A%E7%9F%A5-00D4AA?style=flat-square" alt="ntfyÈÄöÁü•" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://github.com/sansan0/TrendRadar"&gt;&lt;img src="https://img.shields.io/badge/GitHub_Actions-%E8%87%AA%E5%8A%A8%E5%8C%96-2088FF?style=flat-square&amp;amp;logo=github-actions&amp;amp;logoColor=white" alt="GitHub Actions" /&gt;&lt;/a&gt; &lt;a href="https://sansan0.github.io/TrendRadar"&gt;&lt;img src="https://img.shields.io/badge/GitHub_Pages-%E9%83%A8%E7%BD%B2-4285F4?style=flat-square&amp;amp;logo=github&amp;amp;logoColor=white" alt="GitHub Pages" /&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/r/wantcat/trendradar"&gt;&lt;img src="https://img.shields.io/badge/Docker-%E9%83%A8%E7%BD%B2-2496ED?style=flat-square&amp;amp;logo=docker&amp;amp;logoColor=white" alt="Docker" /&gt;&lt;/a&gt; &lt;a href="https://modelcontextprotocol.io/"&gt;&lt;img src="https://img.shields.io/badge/MCP-AI%E5%88%86%E6%9E%90%E6%94%AF%E6%8C%81-FF6B6B?style=flat-square&amp;amp;logo=ai&amp;amp;logoColor=white" alt="MCP Support" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Êú¨È°πÁõÆ‰ª•ËΩªÈáèÔºåÊòìÈÉ®ÁΩ≤‰∏∫ÁõÆÊ†á&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;üìë Âø´ÈÄüÂØºËà™&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th align="center"&gt;&lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/#-%E6%A0%B8%E5%BF%83%E5%8A%9F%E8%83%BD"&gt;üéØ Ê†∏ÂøÉÂäüËÉΩ&lt;/a&gt;&lt;/th&gt; 
    &lt;th align="center"&gt;&lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/#-%E5%BF%AB%E9%80%9F%E5%BC%80%E5%A7%8B"&gt;üöÄ Âø´ÈÄüÂºÄÂßã&lt;/a&gt;&lt;/th&gt; 
    &lt;th align="center"&gt;&lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/#-docker-%E9%83%A8%E7%BD%B2"&gt;üê≥ DockerÈÉ®ÁΩ≤&lt;/a&gt;&lt;/th&gt; 
    &lt;th align="center"&gt;&lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/#-ai-%E6%99%BA%E8%83%BD%E5%88%86%E6%9E%90%E9%83%A8%E7%BD%B2"&gt;ü§ñ AIÂàÜÊûê‰∏ìÂå∫&lt;/a&gt;&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/#-%E6%9B%B4%E6%96%B0%E6%97%A5%E5%BF%97"&gt;üìù Êõ¥Êñ∞Êó•Âøó&lt;/a&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/#-mcp-%E5%AE%A2%E6%88%B7%E7%AB%AF"&gt;üîå MCPÂÆ¢Êà∑Á´Ø&lt;/a&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/#%E9%97%AE%E9%A2%98%E7%AD%94%E7%96%91%E4%B8%8E1%E5%85%83%E7%82%B9%E8%B5%9E"&gt;‚ùì Á≠îÁñë‰∏éÂ∏∏ËßÅÈóÆÈ¢ò&lt;/a&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/#%E9%A1%B9%E7%9B%AE%E7%9B%B8%E5%85%B3"&gt;‚≠ê È°πÁõÆÁõ∏ÂÖ≥&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/div&gt; 
&lt;ul&gt; 
 &lt;li&gt;ÊÑüË∞¢&lt;strong&gt;ËÄêÂøÉÂèçÈ¶à bug&lt;/strong&gt; ÁöÑË¥°ÁåÆËÄÖÔºå‰Ω†‰ª¨ÁöÑÊØè‰∏ÄÊù°ÂèçÈ¶àËÆ©È°πÁõÆÊõ¥Âä†ÂÆåÂñÑüòâ;&lt;/li&gt; 
 &lt;li&gt;ÊÑüË∞¢&lt;strong&gt;‰∏∫È°πÁõÆÁÇπ star&lt;/strong&gt; ÁöÑËßÇ‰ºó‰ª¨Ôºå&lt;strong&gt;fork&lt;/strong&gt; ‰Ω†ÊâÄÊ¨≤‰πüÔºå&lt;strong&gt;star&lt;/strong&gt; ÊàëÊâÄÊ¨≤‰πüÔºå‰∏§ËÄÖÂæóÂÖºüòçÊòØÂØπÂºÄÊ∫êÁ≤æÁ•ûÊúÄÂ•ΩÁöÑÊîØÊåÅ;&lt;/li&gt; 
 &lt;li&gt;ÊÑüË∞¢&lt;strong&gt;ÂÖ≥Ê≥®&lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/#%E9%97%AE%E9%A2%98%E7%AD%94%E7%96%91%E4%B8%8E1%E5%85%83%E7%82%B9%E8%B5%9E"&gt;ÂÖ¨‰ºóÂè∑&lt;/a&gt;&lt;/strong&gt; ÁöÑËØªËÄÖ‰ª¨Ôºå‰Ω†‰ª¨ÁöÑÁïôË®Ä„ÄÅÁÇπËµû„ÄÅÂàÜ‰∫´ÂíåÊé®ËçêÁ≠âÁßØÊûÅ‰∫íÂä®ËÆ©ÂÜÖÂÆπÊõ¥ÊúâÊ∏©Â∫¶üòé„ÄÇ&lt;/li&gt; 
&lt;/ul&gt; 
&lt;details&gt; 
 &lt;summary&gt;üëâ ÁÇπÂáªÊü•Áúã&lt;strong&gt;Ëá¥Ë∞¢ÂêçÂçï&lt;/strong&gt; (ÂΩìÂâç &lt;strong&gt;üî•47üî•&lt;/strong&gt; ‰Ωç)&lt;/summary&gt; 
 &lt;h3&gt;Êï∞ÊçÆÊîØÊåÅ&lt;/h3&gt; 
 &lt;p&gt;Êú¨È°πÁõÆ‰ΩøÁî®‰∫Ü &lt;a href="https://github.com/ourongxing/newsnow"&gt;newsnow&lt;/a&gt; È°πÁõÆÊèê‰æõÁöÑ API Êé•Âè£Ëé∑ÂèñÂ§öÂπ≥Âè∞Êï∞ÊçÆ&lt;/p&gt; 
 &lt;h3&gt;Êé®ÂπøÂä©Âäõ&lt;/h3&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;ÊÑüË∞¢‰ª•‰∏ãÂπ≥Âè∞Âíå‰∏™‰∫∫ÁöÑÊé®Ëçê(ÊåâÊó∂Èó¥ÊéíÂàó)&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://mp.weixin.qq.com/s/fvutkJ_NPUelSW9OGK39aA"&gt;Â∞è‰ºóËΩØ‰ª∂&lt;/a&gt; - ÂºÄÊ∫êËΩØ‰ª∂Êé®ËçêÂπ≥Âè∞&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://linux.do/"&gt;LinuxDo Á§æÂå∫&lt;/a&gt; - ÊäÄÊúØÁà±Â•ΩËÄÖÁöÑËÅöÈõÜÂú∞&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/ruanyf/weekly"&gt;ÈòÆ‰∏ÄÂ≥∞Âë®Âàä&lt;/a&gt; - ÊäÄÊúØÂúàÊúâÂΩ±ÂìçÂäõÁöÑÂë®Âàä&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;ËßÇ‰ºóÊîØÊåÅ&lt;/h3&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;ÊÑüË∞¢&lt;strong&gt;Áªô‰∫àËµÑÈáëÊîØÊåÅ&lt;/strong&gt; ÁöÑÊúãÂèã‰ª¨,‰Ω†‰ª¨ÁöÑÊÖ∑ÊÖ®Â∑≤ÂåñË∫´‰∏∫ÈîÆÁõòÊóÅÁöÑÈõ∂È£üÈ•ÆÊñô,Èô™‰º¥ÁùÄÈ°πÁõÆÁöÑÊØè‰∏ÄÊ¨°Ëø≠‰ª£&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th align="center"&gt;ÁÇπËµû‰∫∫&lt;/th&gt; 
    &lt;th align="center"&gt;ÈáëÈ¢ù&lt;/th&gt; 
    &lt;th align="center"&gt;Êó•Êúü&lt;/th&gt; 
    &lt;th align="center"&gt;Â§áÊ≥®&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*Êù∞&lt;/td&gt; 
    &lt;td align="center"&gt;5&lt;/td&gt; 
    &lt;td align="center"&gt;2025.11.08&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*ÁÇπ&lt;/td&gt; 
    &lt;td align="center"&gt;8.80&lt;/td&gt; 
    &lt;td align="center"&gt;2025.11.07&lt;/td&gt; 
    &lt;td align="center"&gt;ÂºÄÂèë‰∏çÊòìÔºåÊîØÊåÅ‰∏Ä‰∏ã„ÄÇ&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;Q*Q&lt;/td&gt; 
    &lt;td align="center"&gt;6.66&lt;/td&gt; 
    &lt;td align="center"&gt;2025.11.07&lt;/td&gt; 
    &lt;td align="center"&gt;ÊÑüË∞¢ÂºÄÊ∫êÔºÅ&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;C*e&lt;/td&gt; 
    &lt;td align="center"&gt;1&lt;/td&gt; 
    &lt;td align="center"&gt;2025.11.05&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;Peter Fan&lt;/td&gt; 
    &lt;td align="center"&gt;20&lt;/td&gt; 
    &lt;td align="center"&gt;2025.10.29&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;M*n&lt;/td&gt; 
    &lt;td align="center"&gt;1&lt;/td&gt; 
    &lt;td align="center"&gt;2025.10.27&lt;/td&gt; 
    &lt;td align="center"&gt;ÊÑüË∞¢ÂºÄÊ∫ê&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*ËÆ∏&lt;/td&gt; 
    &lt;td align="center"&gt;8.88&lt;/td&gt; 
    &lt;td align="center"&gt;2025.10.23&lt;/td&gt; 
    &lt;td align="center"&gt;ËÄÅÂ∏à Â∞èÁôΩ‰∏ÄÊûöÔºåÊë∏‰∫ÜÂá†Â§©‰∫ÜËøòÊ≤°Êï¥Ëµ∑Êù•ÔºåÊ±ÇÊïô&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;Eason&lt;/td&gt; 
    &lt;td align="center"&gt;1&lt;/td&gt; 
    &lt;td align="center"&gt;2025.10.22&lt;/td&gt; 
    &lt;td align="center"&gt;ËøòÊ≤°Êï¥ÊòéÁôΩÔºå‰ΩÜ‰Ω†Âú®ÂÅöÂ•Ω‰∫ã&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;P*n&lt;/td&gt; 
    &lt;td align="center"&gt;1&lt;/td&gt; 
    &lt;td align="center"&gt;2025.10.20&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*Êù∞&lt;/td&gt; 
    &lt;td align="center"&gt;1&lt;/td&gt; 
    &lt;td align="center"&gt;2025.10.19&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*Âæê&lt;/td&gt; 
    &lt;td align="center"&gt;1&lt;/td&gt; 
    &lt;td align="center"&gt;2025.10.18&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*Âøó&lt;/td&gt; 
    &lt;td align="center"&gt;1&lt;/td&gt; 
    &lt;td align="center"&gt;2025.10.17&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*üòÄ&lt;/td&gt; 
    &lt;td align="center"&gt;10&lt;/td&gt; 
    &lt;td align="center"&gt;2025.10.16&lt;/td&gt; 
    &lt;td align="center"&gt;ÁÇπËµû&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;**Êù∞&lt;/td&gt; 
    &lt;td align="center"&gt;10&lt;/td&gt; 
    &lt;td align="center"&gt;2025.10.16&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*Âï∏&lt;/td&gt; 
    &lt;td align="center"&gt;10&lt;/td&gt; 
    &lt;td align="center"&gt;2025.10.16&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*Á∫™&lt;/td&gt; 
    &lt;td align="center"&gt;5&lt;/td&gt; 
    &lt;td align="center"&gt;2025.10.14&lt;/td&gt; 
    &lt;td align="center"&gt;TrendRadar&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;J*d&lt;/td&gt; 
    &lt;td align="center"&gt;1&lt;/td&gt; 
    &lt;td align="center"&gt;2025.10.14&lt;/td&gt; 
    &lt;td align="center"&gt;Ë∞¢Ë∞¢‰Ω†ÁöÑÂ∑•ÂÖ∑ÔºåÂæàÂ•ΩÁé©...&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*H&lt;/td&gt; 
    &lt;td align="center"&gt;1&lt;/td&gt; 
    &lt;td align="center"&gt;2025.10.14&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;ÈÇ£*O&lt;/td&gt; 
    &lt;td align="center"&gt;10&lt;/td&gt; 
    &lt;td align="center"&gt;2025.10.13&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*ÂúÜ&lt;/td&gt; 
    &lt;td align="center"&gt;1&lt;/td&gt; 
    &lt;td align="center"&gt;2025.10.13&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;P*g&lt;/td&gt; 
    &lt;td align="center"&gt;6&lt;/td&gt; 
    &lt;td align="center"&gt;2025.10.13&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;Ocean&lt;/td&gt; 
    &lt;td align="center"&gt;20&lt;/td&gt; 
    &lt;td align="center"&gt;2025.10.12&lt;/td&gt; 
    &lt;td align="center"&gt;...ÁúüÁöÑÂ§™Ê£í‰∫ÜÔºÅÔºÅÔºÅÂ∞èÁôΩÁ∫ßÂà´‰πüËÉΩÁõ¥Êé•Áî®...&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;**Âüπ&lt;/td&gt; 
    &lt;td align="center"&gt;5.2&lt;/td&gt; 
    &lt;td align="center"&gt;2025.10.2&lt;/td&gt; 
    &lt;td align="center"&gt;github-yzyf1312:ÂºÄÊ∫ê‰∏áÂ≤Å&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*Ê§ø&lt;/td&gt; 
    &lt;td align="center"&gt;3&lt;/td&gt; 
    &lt;td align="center"&gt;2025.9.23&lt;/td&gt; 
    &lt;td align="center"&gt;Âä†Ê≤πÔºåÂæà‰∏çÈîô&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*üçç&lt;/td&gt; 
    &lt;td align="center"&gt;10&lt;/td&gt; 
    &lt;td align="center"&gt;2025.9.21&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;E*f&lt;/td&gt; 
    &lt;td align="center"&gt;1&lt;/td&gt; 
    &lt;td align="center"&gt;2025.9.20&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*ËÆ∞&lt;/td&gt; 
    &lt;td align="center"&gt;1&lt;/td&gt; 
    &lt;td align="center"&gt;2025.9.20&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;z*u&lt;/td&gt; 
    &lt;td align="center"&gt;2&lt;/td&gt; 
    &lt;td align="center"&gt;2025.9.19&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;**Êòä&lt;/td&gt; 
    &lt;td align="center"&gt;5&lt;/td&gt; 
    &lt;td align="center"&gt;2025.9.17&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*Âè∑&lt;/td&gt; 
    &lt;td align="center"&gt;1&lt;/td&gt; 
    &lt;td align="center"&gt;2025.9.15&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;T*T&lt;/td&gt; 
    &lt;td align="center"&gt;2&lt;/td&gt; 
    &lt;td align="center"&gt;2025.9.15&lt;/td&gt; 
    &lt;td align="center"&gt;ÁÇπËµû&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*ÂÆ∂&lt;/td&gt; 
    &lt;td align="center"&gt;10&lt;/td&gt; 
    &lt;td align="center"&gt;2025.9.10&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*X&lt;/td&gt; 
    &lt;td align="center"&gt;1.11&lt;/td&gt; 
    &lt;td align="center"&gt;2025.9.3&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*È£ô&lt;/td&gt; 
    &lt;td align="center"&gt;20&lt;/td&gt; 
    &lt;td align="center"&gt;2025.8.31&lt;/td&gt; 
    &lt;td align="center"&gt;Êù•Ëá™ËÄÅÁ´•Ë∞¢Ë∞¢&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*‰∏ã&lt;/td&gt; 
    &lt;td align="center"&gt;1&lt;/td&gt; 
    &lt;td align="center"&gt;2025.8.30&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;2*D&lt;/td&gt; 
    &lt;td align="center"&gt;88&lt;/td&gt; 
    &lt;td align="center"&gt;2025.8.13 ‰∏ãÂçà&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;2*D&lt;/td&gt; 
    &lt;td align="center"&gt;1&lt;/td&gt; 
    &lt;td align="center"&gt;2025.8.13 ‰∏äÂçà&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;S*o&lt;/td&gt; 
    &lt;td align="center"&gt;1&lt;/td&gt; 
    &lt;td align="center"&gt;2025.8.05&lt;/td&gt; 
    &lt;td align="center"&gt;ÊîØÊåÅ‰∏Ä‰∏ã&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*‰æ†&lt;/td&gt; 
    &lt;td align="center"&gt;10&lt;/td&gt; 
    &lt;td align="center"&gt;2025.8.04&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;x*x&lt;/td&gt; 
    &lt;td align="center"&gt;2&lt;/td&gt; 
    &lt;td align="center"&gt;2025.8.03&lt;/td&gt; 
    &lt;td align="center"&gt;trendRadar Â•ΩÈ°πÁõÆ ÁÇπËµû&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*Ëøú&lt;/td&gt; 
    &lt;td align="center"&gt;1&lt;/td&gt; 
    &lt;td align="center"&gt;2025.8.01&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*ÈÇ™&lt;/td&gt; 
    &lt;td align="center"&gt;5&lt;/td&gt; 
    &lt;td align="center"&gt;2025.8.01&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*Ê¢¶&lt;/td&gt; 
    &lt;td align="center"&gt;0.1&lt;/td&gt; 
    &lt;td align="center"&gt;2025.7.30&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;**Èæô&lt;/td&gt; 
    &lt;td align="center"&gt;10&lt;/td&gt; 
    &lt;td align="center"&gt;2025.7.29&lt;/td&gt; 
    &lt;td align="center"&gt;ÊîØÊåÅ‰∏Ä‰∏ã&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/details&gt; 
&lt;h2&gt;‚ú® Ê†∏ÂøÉÂäüËÉΩ&lt;/h2&gt; 
&lt;h3&gt;&lt;strong&gt;ÂÖ®ÁΩëÁÉ≠ÁÇπËÅöÂêà&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Áü•‰πé&lt;/li&gt; 
 &lt;li&gt;ÊäñÈü≥&lt;/li&gt; 
 &lt;li&gt;bilibili ÁÉ≠Êêú&lt;/li&gt; 
 &lt;li&gt;ÂçéÂ∞îË°óËßÅÈóª&lt;/li&gt; 
 &lt;li&gt;Ë¥¥Âêß&lt;/li&gt; 
 &lt;li&gt;ÁôæÂ∫¶ÁÉ≠Êêú&lt;/li&gt; 
 &lt;li&gt;Ë¥¢ËÅîÁ§æÁÉ≠Èó®&lt;/li&gt; 
 &lt;li&gt;ÊæéÊπÉÊñ∞Èóª&lt;/li&gt; 
 &lt;li&gt;Âá§Âá∞ÁΩë&lt;/li&gt; 
 &lt;li&gt;‰ªäÊó•Â§¥Êù°&lt;/li&gt; 
 &lt;li&gt;ÂæÆÂçö&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;ÈªòËÆ§ÁõëÊéß 11 ‰∏™‰∏ªÊµÅÂπ≥Âè∞Ôºå‰πüÂèØËá™Ë°åÂ¢ûÂä†È¢ùÂ§ñÁöÑÂπ≥Âè∞&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;üëâ Ëá™ÂÆö‰πâÁõëÊéßÂπ≥Âè∞&lt;/strong&gt;&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;p&gt;Êú¨È°πÁõÆÁöÑËµÑËÆØÊï∞ÊçÆÊù•Ê∫ê‰∫é &lt;a href="https://github.com/ourongxing/newsnow"&gt;newsnow&lt;/a&gt; Ôºå‰Ω†ÂèØ‰ª•ÁÇπÂáª&lt;a href="https://newsnow.busiyi.world/"&gt;ÁΩëÁ´ô&lt;/a&gt;ÔºåÁÇπÂáª[Êõ¥Â§ö]ÔºåÊü•ÁúãÊòØÂê¶Êúâ‰Ω†ÊÉ≥Ë¶ÅÁöÑÂπ≥Âè∞„ÄÇ&lt;/p&gt; 
 &lt;p&gt;ÂÖ∑‰ΩìÊ∑ªÂä†ÂèØËÆøÈóÆ &lt;a href="https://github.com/ourongxing/newsnow/tree/main/server/sources"&gt;È°πÁõÆÊ∫ê‰ª£Á†Å&lt;/a&gt;ÔºåÊ†πÊçÆÈáåÈù¢ÁöÑÊñá‰ª∂ÂêçÔºåÂú® &lt;code&gt;config/config.yaml&lt;/code&gt; Êñá‰ª∂‰∏≠‰øÆÊîπ &lt;code&gt;platforms&lt;/code&gt; ÈÖçÁΩÆÔºö&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-yaml"&gt;platforms:
  - id: "toutiao"
    name: "‰ªäÊó•Â§¥Êù°"
  - id: "baidu"  
    name: "ÁôæÂ∫¶ÁÉ≠Êêú"
  - id: "wallstreetcn-hot"
    name: "ÂçéÂ∞îË°óËßÅÈóª"
  # Ê∑ªÂä†Êõ¥Â§öÂπ≥Âè∞...
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Â¶ÇÊûú‰∏ç‰ºöÁúãÁöÑËØùÔºåÂ∞±Áõ¥Êé•Â§çÂà∂‰ªñ‰∫∫Êï¥ÁêÜÂ•ΩÁöÑÈÉ®ÂàÜ&lt;a href="https://github.com/sansan0/TrendRadar/issues/95"&gt;Âπ≥Âè∞ÈÖçÁΩÆ&lt;/a&gt;&lt;/p&gt; 
&lt;/details&gt; 
&lt;h3&gt;&lt;strong&gt;Êô∫ËÉΩÊé®ÈÄÅÁ≠ñÁï•&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;‰∏âÁßçÊé®ÈÄÅÊ®°Âºè&lt;/strong&gt;Ôºö&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Ê®°Âºè&lt;/th&gt; 
   &lt;th&gt;ÈÄÇÁî®‰∫∫Áæ§&lt;/th&gt; 
   &lt;th&gt;Êé®ÈÄÅÊó∂Êú∫&lt;/th&gt; 
   &lt;th&gt;ÊòæÁ§∫ÂÜÖÂÆπ&lt;/th&gt; 
   &lt;th&gt;ÈÄÇÁî®Âú∫ÊôØ&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;ÂΩìÊó•Ê±áÊÄª&lt;/strong&gt;&lt;br /&gt;&lt;code&gt;daily&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;üìã ‰ºÅ‰∏öÁÆ°ÁêÜËÄÖ/ÊôÆÈÄöÁî®Êà∑&lt;/td&gt; 
   &lt;td&gt;ÊåâÊó∂Êé®ÈÄÅ(ÈªòËÆ§ÊØèÂ∞èÊó∂Êé®ÈÄÅ‰∏ÄÊ¨°)&lt;/td&gt; 
   &lt;td&gt;ÂΩìÊó•ÊâÄÊúâÂåπÈÖçÊñ∞Èóª&lt;br /&gt;+ Êñ∞Â¢ûÊñ∞ÈóªÂå∫Âüü&lt;/td&gt; 
   &lt;td&gt;Êó•Êä•ÊÄªÁªì&lt;br /&gt;ÂÖ®Èù¢‰∫ÜËß£ÂΩìÊó•ÁÉ≠ÁÇπË∂ãÂäø&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;ÂΩìÂâçÊ¶úÂçï&lt;/strong&gt;&lt;br /&gt;&lt;code&gt;current&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;üì∞ Ëá™Â™í‰Ωì‰∫∫/ÂÜÖÂÆπÂàõ‰ΩúËÄÖ&lt;/td&gt; 
   &lt;td&gt;ÊåâÊó∂Êé®ÈÄÅ(ÈªòËÆ§ÊØèÂ∞èÊó∂Êé®ÈÄÅ‰∏ÄÊ¨°)&lt;/td&gt; 
   &lt;td&gt;ÂΩìÂâçÊ¶úÂçïÂåπÈÖçÊñ∞Èóª&lt;br /&gt;+ Êñ∞Â¢ûÊñ∞ÈóªÂå∫Âüü&lt;/td&gt; 
   &lt;td&gt;ÂÆûÊó∂ÁÉ≠ÁÇπËøΩË∏™&lt;br /&gt;‰∫ÜËß£ÂΩìÂâçÊúÄÁÅ´ÁöÑÂÜÖÂÆπ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Â¢ûÈáèÁõëÊéß&lt;/strong&gt;&lt;br /&gt;&lt;code&gt;incremental&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;üìà ÊäïËµÑËÄÖ/‰∫§ÊòìÂëò&lt;/td&gt; 
   &lt;td&gt;ÊúâÊñ∞Â¢ûÊâçÊé®ÈÄÅ&lt;/td&gt; 
   &lt;td&gt;Êñ∞Âá∫Áé∞ÁöÑÂåπÈÖçÈ¢ëÁéáËØçÊñ∞Èóª&lt;/td&gt; 
   &lt;td&gt;ÈÅøÂÖçÈáçÂ§ç‰ø°ÊÅØÂπ≤Êâ∞&lt;br /&gt;È´òÈ¢ëÁõëÊéßÂú∫ÊôØ&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;ÈôÑÂä†ÂäüËÉΩ - Êé®ÈÄÅÊó∂Èó¥Á™óÂè£ÊéßÂà∂&lt;/strong&gt;ÔºàÂèØÈÄâÔºâÔºö&lt;/p&gt; 
&lt;p&gt;Ê≠§ÂäüËÉΩÁã¨Á´ã‰∫é‰∏äËø∞‰∏âÁßçÊé®ÈÄÅÊ®°Âºè,ÂèØ‰∏é‰ªªÊÑèÊ®°ÂºèÊê≠ÈÖç‰ΩøÁî®:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Êó∂Èó¥Á™óÂè£ÈôêÂà∂&lt;/strong&gt;: ËÆæÂÆöÊé®ÈÄÅÊó∂Èó¥ËåÉÂõ¥ÔºàÂ¶Ç 09:00-18:00 Êàñ 20:00-22:00Ôºâ,Âè™Âú®ÊåáÂÆöÊó∂Èó¥ÂÜÖÊé®ÈÄÅ&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Êé®ÈÄÅÈ¢ëÁéáÊéßÂà∂&lt;/strong&gt;: 
  &lt;ul&gt; 
   &lt;li&gt;Á™óÂè£ÂÜÖÂ§öÊ¨°Êé®ÈÄÅ: Êó∂Èó¥Á™óÂè£ÂÜÖÊØèÊ¨°ÊâßË°åÈÉΩÊé®ÈÄÅ&lt;/li&gt; 
   &lt;li&gt;ÊØèÂ§©‰ªÖÊé®ÈÄÅ‰∏ÄÊ¨°: Êó∂Èó¥Á™óÂè£ÂÜÖÂè™Êé®ÈÄÅ‰∏ÄÊ¨°ÔºàÈÄÇÂêàÂΩìÊó•Ê±áÊÄªÊàñÂΩìÂâçÊ¶úÂçïÊ®°ÂºèÔºâ&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ÂÖ∏ÂûãÂú∫ÊôØ&lt;/strong&gt;: 
  &lt;ul&gt; 
   &lt;li&gt;Â∑•‰ΩúÊó∂Èó¥Êé®ÈÄÅ: Âè™Âú®Â∑•‰ΩúÊó• 09:00-18:00 Êé•Êî∂Ê∂àÊÅØ&lt;/li&gt; 
   &lt;li&gt;ÊôöÈó¥Ê±áÊÄªÊé®ÈÄÅ: Â∏åÊúõÂú®Êôö‰∏äÂõ∫ÂÆöÊó∂Èó¥ÔºàÂ¶Ç 20:00-22:00ÔºâÊî∂Âà∞Ê±áÊÄª&lt;/li&gt; 
   &lt;li&gt;ÈÅøÂÖçÊâìÊâ∞: Èò≤Ê≠¢ÈùûÂ∑•‰ΩúÊó∂Èó¥Êî∂Âà∞Êé®ÈÄÅÈÄöÁü•&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;ÊèêÁ§∫: Ê≠§ÂäüËÉΩÈªòËÆ§ÂÖ≥Èó≠,ÈúÄÂú® &lt;code&gt;config/config.yaml&lt;/code&gt; ‰∏≠ÊâãÂä®ÂêØÁî® &lt;code&gt;push_window.enabled&lt;/code&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;&lt;strong&gt;Á≤æÂáÜÂÜÖÂÆπÁ≠õÈÄâ&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;ËÆæÁΩÆ‰∏™‰∫∫ÂÖ≥ÈîÆËØçÔºàÂ¶ÇÔºöAI„ÄÅÊØî‰∫öËø™„ÄÅÊïôËÇ≤ÊîøÁ≠ñÔºâÔºåÂè™Êé®ÈÄÅÁõ∏ÂÖ≥ÁÉ≠ÁÇπÔºåËøáÊª§Êó†ÂÖ≥‰ø°ÊÅØ&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;ÊîØÊåÅÊôÆÈÄöËØç„ÄÅÂøÖÈ°ªËØç(+)„ÄÅËøáÊª§ËØç(!)‰∏âÁßçËØ≠Ê≥ïÔºåËßÅ„Äêfrequency_words.txt ÈÖçÁΩÆÊïôÁ®ã„Äë&lt;/li&gt; 
 &lt;li&gt;ËØçÁªÑÂåñÁÆ°ÁêÜÔºåÁã¨Á´ãÁªüËÆ°‰∏çÂêå‰∏ªÈ¢òÁÉ≠ÁÇπ&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;‰πüÂèØ‰ª•‰∏çÂÅöÁ≠õÈÄâÔºåÂÆåÊï¥ÁöÑÊé®ÈÄÅÊâÄÊúâÁÉ≠ÁÇπÔºåÂÖ∑‰ΩìËßÅ„ÄêÂéÜÂè≤Êõ¥Êñ∞„Äë‰∏≠ÁöÑ v2.0.1&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;üëâ frequency_words.txt ÈÖçÁΩÆÊïôÁ®ã&lt;/strong&gt;&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;p&gt;Âú® &lt;code&gt;frequency_words.txt&lt;/code&gt; Êñá‰ª∂‰∏≠ÈÖçÁΩÆÁõëÊéßÁöÑÂÖ≥ÈîÆËØçÔºåÊîØÊåÅ‰∏âÁßçËØ≠Ê≥ïÂíåËØçÁªÑÂäüËÉΩ„ÄÇ&lt;/p&gt; 
 &lt;p&gt;ÂÖ≥ÈîÆËØçË∂äÈù†ÂâçÔºåÊñ∞ÈóªÁöÑ‰ºòÂÖàÁ∫ßË∂äÈ´òÔºå‰Ω†ÂèØ‰ª•Ê†πÊçÆËá™Â∑±ÁöÑÂÖ≥Ê≥®Â∫¶Ë∞ÉÊï¥ÂÖ≥ÈîÆËØçÈ°∫Â∫è&lt;/p&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;ËØ≠Ê≥ïÁ±ªÂûã&lt;/th&gt; 
    &lt;th&gt;Á¨¶Âè∑&lt;/th&gt; 
    &lt;th&gt;‰ΩúÁî®&lt;/th&gt; 
    &lt;th&gt;Á§∫‰æã&lt;/th&gt; 
    &lt;th&gt;ÂåπÈÖçÈÄªËæë&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;ÊôÆÈÄöËØç&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;Êó†&lt;/td&gt; 
    &lt;td&gt;Âü∫Á°ÄÂåπÈÖç&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;Âçé‰∏∫&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;ÂåÖÂê´‰ªªÊÑè‰∏Ä‰∏™Âç≥ÂèØ&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;ÂøÖÈ°ªËØç&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;+&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;ÈôêÂÆöËåÉÂõ¥&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;+ÊâãÊú∫&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;ÂøÖÈ°ªÂêåÊó∂ÂåÖÂê´&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;ËøáÊª§ËØç&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;!&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;ÊéíÈô§Âπ≤Êâ∞&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;!ÂπøÂëä&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;ÂåÖÂê´ÂàôÁõ¥Êé•ÊéíÈô§&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
 &lt;h3&gt;üìã Âü∫Á°ÄËØ≠Ê≥ïËØ¥Êòé&lt;/h3&gt; 
 &lt;h4&gt;1. &lt;strong&gt;ÊôÆÈÄöÂÖ≥ÈîÆËØç&lt;/strong&gt; - Âü∫Á°ÄÂåπÈÖç&lt;/h4&gt; 
 &lt;pre&gt;&lt;code class="language-txt"&gt;Âçé‰∏∫
OPPO
ËãπÊûú
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;‰ΩúÁî®Ôºö&lt;/strong&gt; Êñ∞ÈóªÊ†áÈ¢òÂåÖÂê´ÂÖ∂‰∏≠&lt;strong&gt;‰ªªÊÑè‰∏Ä‰∏™ËØç&lt;/strong&gt;Â∞±‰ºöË¢´ÊçïËé∑&lt;/p&gt; 
 &lt;h4&gt;2. &lt;strong&gt;ÂøÖÈ°ªËØç&lt;/strong&gt; &lt;code&gt;+ËØçÊ±á&lt;/code&gt; - ÈôêÂÆöËåÉÂõ¥&lt;/h4&gt; 
 &lt;pre&gt;&lt;code class="language-txt"&gt;Âçé‰∏∫
OPPO
+ÊâãÊú∫
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;‰ΩúÁî®Ôºö&lt;/strong&gt; ÂøÖÈ°ªÂêåÊó∂ÂåÖÂê´ÊôÆÈÄöËØç&lt;strong&gt;Âíå&lt;/strong&gt;ÂøÖÈ°ªËØçÊâç‰ºöË¢´ÊçïËé∑&lt;/p&gt; 
 &lt;h4&gt;3. &lt;strong&gt;ËøáÊª§ËØç&lt;/strong&gt; &lt;code&gt;!ËØçÊ±á&lt;/code&gt; - ÊéíÈô§Âπ≤Êâ∞&lt;/h4&gt; 
 &lt;pre&gt;&lt;code class="language-txt"&gt;ËãπÊûú
Âçé‰∏∫
!Ê∞¥Êûú
!‰ª∑Ê†º
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;‰ΩúÁî®Ôºö&lt;/strong&gt; ÂåÖÂê´ËøáÊª§ËØçÁöÑÊñ∞Èóª‰ºöË¢´&lt;strong&gt;Áõ¥Êé•ÊéíÈô§&lt;/strong&gt;ÔºåÂç≥‰ΩøÂåÖÂê´ÂÖ≥ÈîÆËØç&lt;/p&gt; 
 &lt;h3&gt;üîó ËØçÁªÑÂäüËÉΩ - Á©∫Ë°åÂàÜÈöîÁöÑÈáçË¶Å‰ΩúÁî®&lt;/h3&gt; 
 &lt;p&gt;&lt;strong&gt;Ê†∏ÂøÉËßÑÂàôÔºö&lt;/strong&gt; Áî®&lt;strong&gt;Á©∫Ë°å&lt;/strong&gt;ÂàÜÈöî‰∏çÂêåÁöÑËØçÁªÑÔºåÊØè‰∏™ËØçÁªÑÁã¨Á´ãÁªüËÆ°&lt;/p&gt; 
 &lt;h4&gt;Á§∫‰æãÈÖçÁΩÆÔºö&lt;/h4&gt; 
 &lt;pre&gt;&lt;code class="language-txt"&gt;iPhone
Âçé‰∏∫
OPPO
+ÂèëÂ∏É

AËÇ°
‰∏äËØÅ
Ê∑±ËØÅ
+Ê∂®Ë∑å
!È¢ÑÊµã

‰∏ñÁïåÊùØ
Ê¨ßÊ¥≤ÊùØ
‰∫öÊ¥≤ÊùØ
+ÊØîËµõ
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h4&gt;ËØçÁªÑËß£ÈáäÂèäÂåπÈÖçÊïàÊûúÔºö&lt;/h4&gt; 
 &lt;p&gt;&lt;strong&gt;Á¨¨1ÁªÑ - ÊâãÊú∫Êñ∞ÂìÅÁ±ªÔºö&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;ÂÖ≥ÈîÆËØçÔºöiPhone„ÄÅÂçé‰∏∫„ÄÅOPPO&lt;/li&gt; 
  &lt;li&gt;ÂøÖÈ°ªËØçÔºöÂèëÂ∏É&lt;/li&gt; 
  &lt;li&gt;ÊïàÊûúÔºöÂøÖÈ°ªÂåÖÂê´ÊâãÊú∫ÂìÅÁâåÂêçÔºåÂêåÊó∂ÂåÖÂê´"ÂèëÂ∏É"&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;ÂåπÈÖçÁ§∫‰æãÔºö&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;‚úÖ "iPhone 15Ê≠£ÂºèÂèëÂ∏ÉÂîÆ‰ª∑ÂÖ¨Â∏É" ‚Üê Êúâ"iPhone"+"ÂèëÂ∏É"&lt;/li&gt; 
  &lt;li&gt;‚úÖ "Âçé‰∏∫Mate60Á≥ªÂàóÂèëÂ∏É‰ºöÁõ¥Êí≠" ‚Üê Êúâ"Âçé‰∏∫"+"ÂèëÂ∏É"&lt;/li&gt; 
  &lt;li&gt;‚úÖ "OPPO Find X7ÂèëÂ∏ÉÊó∂Èó¥Á°ÆÂÆö" ‚Üê Êúâ"OPPO"+"ÂèëÂ∏É"&lt;/li&gt; 
  &lt;li&gt;‚ùå "iPhoneÈîÄÈáèÂàõÊñ∞È´ò" ‚Üê Êúâ"iPhone"‰ΩÜÁº∫Â∞ë"ÂèëÂ∏É"&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;Á¨¨2ÁªÑ - ËÇ°Â∏ÇË°åÊÉÖÁ±ªÔºö&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;ÂÖ≥ÈîÆËØçÔºöAËÇ°„ÄÅ‰∏äËØÅ„ÄÅÊ∑±ËØÅ&lt;/li&gt; 
  &lt;li&gt;ÂøÖÈ°ªËØçÔºöÊ∂®Ë∑å&lt;/li&gt; 
  &lt;li&gt;ËøáÊª§ËØçÔºöÈ¢ÑÊµã&lt;/li&gt; 
  &lt;li&gt;ÊïàÊûúÔºöÂåÖÂê´ËÇ°Â∏ÇÁõ∏ÂÖ≥ËØçÔºåÂêåÊó∂ÂåÖÂê´"Ê∂®Ë∑å"Ôºå‰ΩÜÊéíÈô§ÂåÖÂê´"È¢ÑÊµã"ÁöÑÂÜÖÂÆπ&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;ÂåπÈÖçÁ§∫‰æãÔºö&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;‚úÖ "AËÇ°‰ªäÊó•Â§ßÂπÖÊ∂®Ë∑åÂàÜÊûê" ‚Üê Êúâ"AËÇ°"+"Ê∂®Ë∑å"&lt;/li&gt; 
  &lt;li&gt;‚úÖ "‰∏äËØÅÊåáÊï∞Ê∂®Ë∑åÂéüÂõ†Ëß£ËØª" ‚Üê Êúâ"‰∏äËØÅ"+"Ê∂®Ë∑å"&lt;/li&gt; 
  &lt;li&gt;‚ùå "‰∏ìÂÆ∂È¢ÑÊµãAËÇ°Ê∂®Ë∑åË∂ãÂäø" ‚Üê Êúâ"AËÇ°"+"Ê∂®Ë∑å"‰ΩÜÂåÖÂê´"È¢ÑÊµã"&lt;/li&gt; 
  &lt;li&gt;‚ùå "AËÇ°Êàê‰∫§ÈáèÂàõÊñ∞È´ò" ‚Üê Êúâ"AËÇ°"‰ΩÜÁº∫Â∞ë"Ê∂®Ë∑å"&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;Á¨¨3ÁªÑ - Ë∂≥ÁêÉËµõ‰∫ãÁ±ªÔºö&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;ÂÖ≥ÈîÆËØçÔºö‰∏ñÁïåÊùØ„ÄÅÊ¨ßÊ¥≤ÊùØ„ÄÅ‰∫öÊ¥≤ÊùØ&lt;/li&gt; 
  &lt;li&gt;ÂøÖÈ°ªËØçÔºöÊØîËµõ&lt;/li&gt; 
  &lt;li&gt;ÊïàÊûúÔºöÂøÖÈ°ªÂåÖÂê´ÊùØËµõÂêçÁß∞ÔºåÂêåÊó∂ÂåÖÂê´"ÊØîËµõ"&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;ÂåπÈÖçÁ§∫‰æãÔºö&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;‚úÖ "‰∏ñÁïåÊùØÂ∞èÁªÑËµõÊØîËµõÁªìÊûú" ‚Üê Êúâ"‰∏ñÁïåÊùØ"+"ÊØîËµõ"&lt;/li&gt; 
  &lt;li&gt;‚úÖ "Ê¨ßÊ¥≤ÊùØÂÜ≥ËµõÊØîËµõÊó∂Èó¥" ‚Üê Êúâ"Ê¨ßÊ¥≤ÊùØ"+"ÊØîËµõ"&lt;/li&gt; 
  &lt;li&gt;‚ùå "‰∏ñÁïåÊùØÈó®Á•®ÂºÄÂîÆ" ‚Üê Êúâ"‰∏ñÁïåÊùØ"‰ΩÜÁº∫Â∞ë"ÊØîËµõ"&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;üéØ ÈÖçÁΩÆÊäÄÂ∑ß&lt;/h3&gt; 
 &lt;h4&gt;1. &lt;strong&gt;‰ªéÂÆΩÂà∞‰∏•ÁöÑÈÖçÁΩÆÁ≠ñÁï•&lt;/strong&gt;&lt;/h4&gt; 
 &lt;pre&gt;&lt;code class="language-txt"&gt;# Á¨¨‰∏ÄÊ≠•ÔºöÂÖàÁî®ÂÆΩÊ≥õÂÖ≥ÈîÆËØçÊµãËØï
‰∫∫Â∑•Êô∫ËÉΩ
AI
ChatGPT

# Á¨¨‰∫åÊ≠•ÔºöÂèëÁé∞ËØØÂåπÈÖçÂêéÔºåÂä†ÂÖ•ÂøÖÈ°ªËØçÈôêÂÆö
‰∫∫Â∑•Êô∫ËÉΩ  
AI
ChatGPT
+ÊäÄÊúØ

# Á¨¨‰∏âÊ≠•ÔºöÂèëÁé∞Âπ≤Êâ∞ÂÜÖÂÆπÂêéÔºåÂä†ÂÖ•ËøáÊª§ËØç
‰∫∫Â∑•Êô∫ËÉΩ
AI  
ChatGPT
+ÊäÄÊúØ
!ÂπøÂëä
!ÂüπËÆ≠
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h4&gt;2. &lt;strong&gt;ÈÅøÂÖçËøáÂ∫¶Â§çÊùÇ&lt;/strong&gt;&lt;/h4&gt; 
 &lt;p&gt;‚ùå &lt;strong&gt;‰∏çÊé®ËçêÔºö&lt;/strong&gt; ‰∏Ä‰∏™ËØçÁªÑÂåÖÂê´Â§™Â§öËØçÊ±á&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-txt"&gt;Âçé‰∏∫
OPPO
ËãπÊûú
‰∏âÊòü
vivo
‰∏ÄÂä†
È≠ÖÊóè
+ÊâãÊú∫
+ÂèëÂ∏É
+ÈîÄÈáè
!ÂÅáË¥ß
!Áª¥‰øÆ
!‰∫åÊâã
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;‚úÖ &lt;strong&gt;Êé®ËçêÔºö&lt;/strong&gt; ÊãÜÂàÜÊàêÂ§ö‰∏™Á≤æÁ°ÆÁöÑËØçÁªÑ&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-txt"&gt;Âçé‰∏∫
OPPO
+Êñ∞ÂìÅ

ËãπÊûú
‰∏âÊòü  
+ÂèëÂ∏É

ÊâãÊú∫
ÈîÄÈáè
+Â∏ÇÂú∫
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h3&gt;&lt;strong&gt;ÁÉ≠ÁÇπË∂ãÂäøÂàÜÊûê&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;ÂÆûÊó∂ËøΩË∏™Êñ∞ÈóªÁÉ≠Â∫¶ÂèòÂåñÔºåËÆ©‰Ω†‰∏ç‰ªÖÁü•ÈÅì"‰ªÄ‰πàÂú®ÁÉ≠Êêú"ÔºåÊõ¥‰∫ÜËß£"ÁÉ≠ÁÇπÂ¶Ç‰ΩïÊºîÂèò"&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Êó∂Èó¥ËΩ¥ËøΩË∏™&lt;/strong&gt;ÔºöËÆ∞ÂΩïÊØèÊù°Êñ∞Èóª‰ªéÈ¶ñÊ¨°Âá∫Áé∞Âà∞ÊúÄÂêéÂá∫Áé∞ÁöÑÂÆåÊï¥Êó∂Èó¥Ë∑®Â∫¶&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ÁÉ≠Â∫¶ÂèòÂåñ&lt;/strong&gt;ÔºöÁªüËÆ°Êñ∞ÈóªÂú®‰∏çÂêåÊó∂Èó¥ÊÆµÁöÑÊéíÂêçÂèòÂåñÂíåÂá∫Áé∞È¢ëÊ¨°&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Êñ∞Â¢ûÊ£ÄÊµã&lt;/strong&gt;ÔºöÂÆûÊó∂ËØÜÂà´Êñ∞Âá∫Áé∞ÁöÑÁÉ≠ÁÇπËØùÈ¢òÔºåÁî®üÜïÊ†áËÆ∞Á¨¨‰∏ÄÊó∂Èó¥ÊèêÈÜí&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ÊåÅÁª≠ÊÄßÂàÜÊûê&lt;/strong&gt;ÔºöÂå∫ÂàÜ‰∏ÄÊ¨°ÊÄßÁÉ≠ÁÇπËØùÈ¢òÂíåÊåÅÁª≠ÂèëÈÖµÁöÑÊ∑±Â∫¶Êñ∞Èóª&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Ë∑®Âπ≥Âè∞ÂØπÊØî&lt;/strong&gt;ÔºöÂêå‰∏ÄÊñ∞ÈóªÂú®‰∏çÂêåÂπ≥Âè∞ÁöÑÊéíÂêçË°®Áé∞ÔºåÁúãÂá∫Â™í‰ΩìÂÖ≥Ê≥®Â∫¶Â∑ÆÂºÇ&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;‰∏çÂÜçÈîôËøáÈáçË¶ÅÊñ∞ÈóªÁöÑÂÆåÊï¥ÂèëÂ±ïËøáÁ®ãÔºå‰ªéËØùÈ¢òËêåËäΩÂà∞È´òÂ≥∞ÁÉ≠ËÆÆÔºåÂÖ®Á®ãÊéåÊè°&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;üëâ Êé®ÈÄÅÊ†ºÂºèËØ¥Êòé&lt;/strong&gt;&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;p&gt;üìä ÁÉ≠ÁÇπËØçÊ±áÁªüËÆ°&lt;/p&gt; 
 &lt;p&gt;üî• [1/3] AI ChatGPT : 2 Êù°&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt; &lt;p&gt;[ÁôæÂ∫¶ÁÉ≠Êêú] üÜï ChatGPT-5Ê≠£ÂºèÂèëÂ∏É [&lt;strong&gt;1&lt;/strong&gt;] - 09Êó∂15ÂàÜ (1Ê¨°)&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;[‰ªäÊó•Â§¥Êù°] AIËäØÁâáÊ¶ÇÂøµËÇ°Êö¥Ê∂® [&lt;strong&gt;3&lt;/strong&gt;] - [08Êó∂30ÂàÜ ~ 10Êó∂45ÂàÜ] (3Ê¨°)&lt;/p&gt; &lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;p&gt;‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ&lt;/p&gt; 
 &lt;p&gt;üìà [2/3] ÊØî‰∫öËø™ ÁâπÊñØÊãâ : 2 Êù°&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt; &lt;p&gt;[ÂæÆÂçö] üÜï ÊØî‰∫öËø™ÊúàÈîÄÈáèÁ†¥Á∫™ÂΩï [&lt;strong&gt;2&lt;/strong&gt;] - 10Êó∂20ÂàÜ (1Ê¨°)&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;[ÊäñÈü≥] ÁâπÊñØÊãâÈôç‰ª∑‰øÉÈîÄ [&lt;strong&gt;4&lt;/strong&gt;] - [07Êó∂45ÂàÜ ~ 09Êó∂15ÂàÜ] (2Ê¨°)&lt;/p&gt; &lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;p&gt;‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ&lt;/p&gt; 
 &lt;p&gt;üìå [3/3] AËÇ° ËÇ°Â∏Ç : 1 Êù°&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;[ÂçéÂ∞îË°óËßÅÈóª] AËÇ°ÂçàÁõòÁÇπËØÑÂàÜÊûê [&lt;strong&gt;5&lt;/strong&gt;] - [11Êó∂30ÂàÜ ~ 12Êó∂00ÂàÜ] (2Ê¨°)&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;p&gt;üÜï Êú¨Ê¨°Êñ∞Â¢ûÁÉ≠ÁÇπÊñ∞Èóª (ÂÖ± 2 Êù°)&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;ÁôæÂ∫¶ÁÉ≠Êêú&lt;/strong&gt; (1 Êù°):&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;ChatGPT-5Ê≠£ÂºèÂèëÂ∏É [&lt;strong&gt;1&lt;/strong&gt;]&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;p&gt;&lt;strong&gt;ÂæÆÂçö&lt;/strong&gt; (1 Êù°):&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;ÊØî‰∫öËø™ÊúàÈîÄÈáèÁ†¥Á∫™ÂΩï [&lt;strong&gt;2&lt;/strong&gt;]&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;p&gt;Êõ¥Êñ∞Êó∂Èó¥Ôºö2025-01-15 12:30:15&lt;/p&gt; 
 &lt;h2&gt;&lt;strong&gt;Ê∂àÊÅØÊ†ºÂºèËØ¥Êòé&lt;/strong&gt;&lt;/h2&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;Ê†ºÂºèÂÖÉÁ¥†&lt;/th&gt; 
    &lt;th&gt;Á§∫‰æã&lt;/th&gt; 
    &lt;th&gt;Âê´‰πâ&lt;/th&gt; 
    &lt;th&gt;ËØ¥Êòé&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;üî•üìàüìå&lt;/td&gt; 
    &lt;td&gt;üî• [1/3] AI ChatGPT&lt;/td&gt; 
    &lt;td&gt;ÁÉ≠Â∫¶Á≠âÁ∫ß&lt;/td&gt; 
    &lt;td&gt;üî•È´òÁÉ≠Â∫¶(‚â•10Êù°) üìà‰∏≠ÁÉ≠Â∫¶(5-9Êù°) üìåÊôÆÈÄöÁÉ≠Â∫¶(&amp;lt;5Êù°)&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;[Â∫èÂè∑/ÊÄªÊï∞]&lt;/td&gt; 
    &lt;td&gt;[1/3]&lt;/td&gt; 
    &lt;td&gt;ÊéíÂ∫è‰ΩçÁΩÆ&lt;/td&gt; 
    &lt;td&gt;ÂΩìÂâçËØçÁªÑÂú®ÊâÄÊúâÂåπÈÖçËØçÁªÑ‰∏≠ÁöÑÊéíÂêç&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;È¢ëÁéáËØçÁªÑ&lt;/td&gt; 
    &lt;td&gt;AI ChatGPT&lt;/td&gt; 
    &lt;td&gt;ÂÖ≥ÈîÆËØçÁªÑ&lt;/td&gt; 
    &lt;td&gt;ÈÖçÁΩÆÊñá‰ª∂‰∏≠ÁöÑËØçÁªÑÔºåÊ†áÈ¢òÂøÖÈ°ªÂåÖÂê´ÂÖ∂‰∏≠ËØçÊ±á&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;: N Êù°&lt;/td&gt; 
    &lt;td&gt;: 2 Êù°&lt;/td&gt; 
    &lt;td&gt;ÂåπÈÖçÊï∞Èáè&lt;/td&gt; 
    &lt;td&gt;ËØ•ËØçÁªÑÂåπÈÖçÁöÑÊñ∞ÈóªÊÄªÊï∞&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;[Âπ≥Âè∞Âêç]&lt;/td&gt; 
    &lt;td&gt;[ÁôæÂ∫¶ÁÉ≠Êêú]&lt;/td&gt; 
    &lt;td&gt;Êù•Ê∫êÂπ≥Âè∞&lt;/td&gt; 
    &lt;td&gt;Êñ∞ÈóªÊâÄÂ±ûÁöÑÂπ≥Âè∞ÂêçÁß∞&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;üÜï&lt;/td&gt; 
    &lt;td&gt;üÜï ChatGPT-5Ê≠£ÂºèÂèëÂ∏É&lt;/td&gt; 
    &lt;td&gt;Êñ∞Â¢ûÊ†áËÆ∞&lt;/td&gt; 
    &lt;td&gt;Êú¨ËΩÆÊäìÂèñ‰∏≠È¶ñÊ¨°Âá∫Áé∞ÁöÑÁÉ≠ÁÇπ&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;[&lt;strong&gt;Êï∞Â≠ó&lt;/strong&gt;]&lt;/td&gt; 
    &lt;td&gt;[&lt;strong&gt;1&lt;/strong&gt;]&lt;/td&gt; 
    &lt;td&gt;È´òÊéíÂêç&lt;/td&gt; 
    &lt;td&gt;ÊéíÂêç‚â§ÈòàÂÄºÁöÑÁÉ≠ÊêúÔºåÁ∫¢Ëâ≤Âä†Á≤óÊòæÁ§∫&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;[Êï∞Â≠ó]&lt;/td&gt; 
    &lt;td&gt;[7]&lt;/td&gt; 
    &lt;td&gt;ÊôÆÈÄöÊéíÂêç&lt;/td&gt; 
    &lt;td&gt;ÊéíÂêç&amp;gt;ÈòàÂÄºÁöÑÁÉ≠ÊêúÔºåÊôÆÈÄöÊòæÁ§∫&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;- Êó∂Èó¥&lt;/td&gt; 
    &lt;td&gt;- 09Êó∂15ÂàÜ&lt;/td&gt; 
    &lt;td&gt;È¶ñÊ¨°Êó∂Èó¥&lt;/td&gt; 
    &lt;td&gt;ËØ•Êñ∞ÈóªÈ¶ñÊ¨°Ë¢´ÂèëÁé∞ÁöÑÊó∂Èó¥&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;[Êó∂Èó¥~Êó∂Èó¥]&lt;/td&gt; 
    &lt;td&gt;[08Êó∂30ÂàÜ ~ 10Êó∂45ÂàÜ]&lt;/td&gt; 
    &lt;td&gt;ÊåÅÁª≠Êó∂Èó¥&lt;/td&gt; 
    &lt;td&gt;‰ªéÈ¶ñÊ¨°Âá∫Áé∞Âà∞ÊúÄÂêéÂá∫Áé∞ÁöÑÊó∂Èó¥ËåÉÂõ¥&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;(NÊ¨°)&lt;/td&gt; 
    &lt;td&gt;(3Ê¨°)&lt;/td&gt; 
    &lt;td&gt;Âá∫Áé∞È¢ëÁéá&lt;/td&gt; 
    &lt;td&gt;Âú®ÁõëÊéßÊúüÈó¥Âá∫Áé∞ÁöÑÊÄªÊ¨°Êï∞&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;Êñ∞Â¢ûÂå∫Âüü&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;üÜï &lt;strong&gt;Êú¨Ê¨°Êñ∞Â¢ûÁÉ≠ÁÇπÊñ∞Èóª&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;Êñ∞ËØùÈ¢òÊ±áÊÄª&lt;/td&gt; 
    &lt;td&gt;ÂçïÁã¨Â±ïÁ§∫Êú¨ËΩÆÊñ∞Âá∫Áé∞ÁöÑÁÉ≠ÁÇπËØùÈ¢ò&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/details&gt; 
&lt;h3&gt;&lt;strong&gt;‰∏™ÊÄßÂåñÁÉ≠ÁÇπÁÆóÊ≥ï&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;‰∏çÂÜçË¢´ÂêÑ‰∏™Âπ≥Âè∞ÁöÑÁÆóÊ≥ïÁâµÁùÄËµ∞ÔºåTrendRadar ‰ºöÈáçÊñ∞Êï¥ÁêÜÂÖ®ÁΩëÁÉ≠ÊêúÔºö&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;ÁúãÈáçÊéíÂêçÈ´òÁöÑÊñ∞Èóª&lt;/strong&gt;ÔºàÂç†60%ÔºâÔºöÂêÑÂπ≥Âè∞ÂâçÂá†ÂêçÁöÑÊñ∞Èóª‰ºòÂÖàÊòæÁ§∫&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ÂÖ≥Ê≥®ÊåÅÁª≠Âá∫Áé∞ÁöÑËØùÈ¢ò&lt;/strong&gt;ÔºàÂç†30%ÔºâÔºöÂèçÂ§çÂá∫Áé∞ÁöÑÊñ∞ÈóªÊõ¥ÈáçË¶Å&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ËÄÉËôëÊéíÂêçË¥®Èáè&lt;/strong&gt;ÔºàÂç†10%ÔºâÔºö‰∏ç‰ªÖÂ§öÊ¨°Âá∫Áé∞ÔºåËøòÁªèÂ∏∏ÊéíÂú®ÂâçÂàó&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;ÊääÂàÜÊï£Âú®ÂêÑ‰∏™Âπ≥Âè∞ÁöÑÁÉ≠ÊêúÂêàÂπ∂Ëµ∑Êù•ÔºåÊåâÁÖß‰Ω†ÂÖ≥ÂøÉÁöÑÁÉ≠Â∫¶ÈáçÊñ∞ÊéíÂ∫èÔºåËøô‰∏â‰∏™ÊØî‰æãÂèØ‰ª•ÈÄâÊã©ÈÄÇÂêàËá™Â∑±ÁöÑÂú∫ÊôØËøõË°åË∞ÉÊï¥&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;üëâ ÁÉ≠ÁÇπÊùÉÈáçË∞ÉÊï¥&lt;/strong&gt;&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;p&gt;ÂΩìÂâçÈªòËÆ§ÁöÑÈÖçÁΩÆÊòØÂπ≥Ë°°ÊÄßÈÖçÁΩÆ&lt;/p&gt; 
 &lt;h3&gt;‰∏§‰∏™Ê†∏ÂøÉÂú∫ÊôØ&lt;/h3&gt; 
 &lt;p&gt;&lt;strong&gt;ËøΩÂÆûÊó∂ÁÉ≠ÁÇπÂûã&lt;/strong&gt;Ôºö&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-yaml"&gt;weight:
  rank_weight: 0.8    # ‰∏ªË¶ÅÁúãÊéíÂêç
  frequency_weight: 0.1  # ‰∏çÂ§™Âú®‰πéÊåÅÁª≠ÊÄß
  hotness_weight: 0.1
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;ÈÄÇÁî®‰∫∫Áæ§&lt;/strong&gt;ÔºöËá™Â™í‰ΩìÂçö‰∏ª„ÄÅËê•ÈîÄ‰∫∫Âëò„ÄÅÊÉ≥Âø´ÈÄü‰∫ÜËß£ÂΩì‰∏ãÊúÄÁÅ´ËØùÈ¢òÁöÑÁî®Êà∑&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;ËøΩÊ∑±Â∫¶ËØùÈ¢òÂûã&lt;/strong&gt;Ôºö&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-yaml"&gt;weight:
  rank_weight: 0.4    # ÈÄÇÂ∫¶ÁúãÊéíÂêç
  frequency_weight: 0.5  # ÈáçËßÜÂΩìÂ§©ÂÜÖÁöÑÊåÅÁª≠ÁÉ≠Â∫¶
  hotness_weight: 0.1
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;ÈÄÇÁî®‰∫∫Áæ§&lt;/strong&gt;ÔºöÊäïËµÑËÄÖ„ÄÅÁ†îÁ©∂‰∫∫Âëò„ÄÅÊñ∞ÈóªÂ∑•‰ΩúËÄÖ„ÄÅÈúÄË¶ÅÊ∑±Â∫¶ÂàÜÊûêË∂ãÂäøÁöÑÁî®Êà∑&lt;/p&gt; 
 &lt;h3&gt;Ë∞ÉÊï¥ÁöÑÊñπÊ≥ï&lt;/h3&gt; 
 &lt;ol&gt; 
  &lt;li&gt;&lt;strong&gt;‰∏â‰∏™Êï∞Â≠óÂä†Ëµ∑Êù•ÂøÖÈ°ªÁ≠â‰∫é 1.0&lt;/strong&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Âì™‰∏™ÈáçË¶ÅÂ∞±Ë∞ÉÂ§ßÂì™‰∏™&lt;/strong&gt;ÔºöÂú®‰πéÊéíÂêçÂ∞±Ë∞ÉÂ§ß rank_weightÔºåÂú®‰πéÊåÅÁª≠ÊÄßÂ∞±Ë∞ÉÂ§ß frequency_weight&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Âª∫ËÆÆÊØèÊ¨°Âè™Ë∞É 0.1-0.2&lt;/strong&gt;ÔºåËßÇÂØüÊïàÊûú&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;p&gt;Ê†∏ÂøÉÊÄùË∑ØÔºöËøΩÊ±ÇÈÄüÂ∫¶ÂíåÊó∂ÊïàÊÄßÁöÑÁî®Êà∑ÊèêÈ´òÊéíÂêçÊùÉÈáçÔºåËøΩÊ±ÇÊ∑±Â∫¶ÂíåÁ®≥ÂÆöÊÄßÁöÑÁî®Êà∑ÊèêÈ´òÈ¢ëÊ¨°ÊùÉÈáç„ÄÇ&lt;/p&gt; 
&lt;/details&gt; 
&lt;h3&gt;&lt;strong&gt;Â§öÊ∏†ÈÅìÂÆûÊó∂Êé®ÈÄÅ&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;ÊîØÊåÅ&lt;strong&gt;‰ºÅ‰∏öÂæÆ‰ø°&lt;/strong&gt;(+ ÂæÆ‰ø°Êé®ÈÄÅÊñπÊ°à)„ÄÅ&lt;strong&gt;È£û‰π¶&lt;/strong&gt;„ÄÅ&lt;strong&gt;ÈíâÈíâ&lt;/strong&gt;„ÄÅ&lt;strong&gt;Telegram&lt;/strong&gt;„ÄÅ&lt;strong&gt;ÈÇÆ‰ª∂&lt;/strong&gt;„ÄÅ&lt;strong&gt;ntfy&lt;/strong&gt;ÔºåÊ∂àÊÅØÁõ¥ËææÊâãÊú∫ÂíåÈÇÆÁÆ±&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;Â§öÁ´ØÈÄÇÈÖç&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;GitHub Pages&lt;/strong&gt;ÔºöËá™Âä®ÁîüÊàêÁ≤æÁæéÁΩëÈ°µÊä•ÂëäÔºåPC/ÁßªÂä®Á´ØÈÄÇÈÖç&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;DockerÈÉ®ÁΩ≤&lt;/strong&gt;ÔºöÊîØÊåÅÂ§öÊû∂ÊûÑÂÆπÂô®ÂåñËøêË°å&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Êï∞ÊçÆÊåÅ‰πÖÂåñ&lt;/strong&gt;ÔºöHTML/TXTÂ§öÊ†ºÂºèÂéÜÂè≤ËÆ∞ÂΩï‰øùÂ≠ò&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;strong&gt;AI Êô∫ËÉΩÂàÜÊûêÔºàv3.0.0 Êñ∞Â¢ûÔºâ&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;Âü∫‰∫é MCP (Model Context Protocol) ÂçèËÆÆÁöÑ AI ÂØπËØùÂàÜÊûêÁ≥ªÁªüÔºåËÆ©‰Ω†Áî®Ëá™ÁÑ∂ËØ≠Ë®ÄÊ∑±Â∫¶ÊåñÊéòÊñ∞ÈóªÊï∞ÊçÆ&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;ÂØπËØùÂºèÊü•ËØ¢&lt;/strong&gt;ÔºöÁî®Ëá™ÁÑ∂ËØ≠Ë®ÄÊèêÈóÆÔºåÂ¶Ç"Êü•ËØ¢Êò®Â§©Áü•‰πéÁöÑÁÉ≠ÁÇπ"„ÄÅ"ÂàÜÊûêÊØîÁâπÂ∏ÅÊúÄËøëÁöÑÁÉ≠Â∫¶Ë∂ãÂäø"&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;13 ÁßçÂàÜÊûêÂ∑•ÂÖ∑&lt;/strong&gt;ÔºöÊ∂µÁõñÂü∫Á°ÄÊü•ËØ¢„ÄÅÊô∫ËÉΩÊ£ÄÁ¥¢„ÄÅË∂ãÂäøÂàÜÊûê„ÄÅÊï∞ÊçÆÊ¥ûÂØü„ÄÅÊÉÖÊÑüÂàÜÊûêÁ≠â&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Â§öÂÆ¢Êà∑Á´ØÊîØÊåÅ&lt;/strong&gt;ÔºöCherry StudioÔºàGUI ÈÖçÁΩÆÔºâ„ÄÅClaude Desktop„ÄÅCursor„ÄÅCline Á≠â&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Ê∑±Â∫¶ÂàÜÊûêËÉΩÂäõ&lt;/strong&gt;Ôºö 
  &lt;ul&gt; 
   &lt;li&gt;ËØùÈ¢òË∂ãÂäøËøΩË∏™ÔºàÁÉ≠Â∫¶ÂèòÂåñ„ÄÅÁîüÂëΩÂë®Êúü„ÄÅÁàÜÁÅ´Ê£ÄÊµã„ÄÅË∂ãÂäøÈ¢ÑÊµãÔºâ&lt;/li&gt; 
   &lt;li&gt;Ë∑®Âπ≥Âè∞Êï∞ÊçÆÂØπÊØîÔºàÊ¥ªË∑ÉÂ∫¶ÁªüËÆ°„ÄÅÂÖ≥ÈîÆËØçÂÖ±Áé∞Ôºâ&lt;/li&gt; 
   &lt;li&gt;Êô∫ËÉΩÊëòË¶ÅÁîüÊàê„ÄÅÁõ∏‰ººÊñ∞ÈóªÊü•Êâæ„ÄÅÂéÜÂè≤ÂÖ≥ËÅîÊ£ÄÁ¥¢&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;ÂëäÂà´ÊâãÂä®ÁøªÈòÖÊï∞ÊçÆÊñá‰ª∂ÔºåAI Âä©ÊâãÂ∏Æ‰Ω†ÁßíÊáÇÊñ∞ÈóªËÉåÂêéÁöÑÊïÖ‰∫ã&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;&lt;strong&gt;Èõ∂ÊäÄÊúØÈó®ÊßõÈÉ®ÁΩ≤&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;GitHub ‰∏ÄÈîÆ Fork Âç≥ÂèØ‰ΩøÁî®ÔºåÊó†ÈúÄÁºñÁ®ãÂü∫Á°Ä„ÄÇ&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;30ÁßíÈÉ®ÁΩ≤Ôºö GitHub PagesÔºàÁΩëÈ°µÊµèËßàÔºâÊîØÊåÅ‰∏ÄÈîÆ‰øùÂ≠òÊàêÂõæÁâáÔºåÈöèÊó∂ÂàÜ‰∫´Áªô‰ªñ‰∫∫&lt;/p&gt; 
 &lt;p&gt;1ÂàÜÈíüÈÉ®ÁΩ≤Ôºö ‰ºÅ‰∏öÂæÆ‰ø°ÔºàÊâãÊú∫ÈÄöÁü•Ôºâ&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;üí° ÊèêÁ§∫Ôºö&lt;/strong&gt; ÊÉ≥Ë¶Å&lt;strong&gt;ÂÆûÊó∂Êõ¥Êñ∞&lt;/strong&gt;ÁöÑÁΩëÈ°µÁâàÔºüfork ÂêéÔºåËøõÂÖ•‰Ω†ÁöÑ‰ªìÂ∫ì Settings ‚Üí PagesÔºåÂêØÁî® GitHub Pages„ÄÇ&lt;a href="https://sansan0.github.io/TrendRadar/"&gt;ÊïàÊûúÈ¢ÑËßà&lt;/a&gt;„ÄÇ&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;ÂáèÂ∞ë APP ‰æùËµñ&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;‰ªé"Ë¢´ÁÆóÊ≥ïÊé®ËçêÁªëÊû∂"ÂèòÊàê"‰∏ªÂä®Ëé∑ÂèñËá™Â∑±ÊÉ≥Ë¶ÅÁöÑ‰ø°ÊÅØ"&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;ÈÄÇÂêà‰∫∫Áæ§Ôºö&lt;/strong&gt; ÊäïËµÑËÄÖ„ÄÅËá™Â™í‰Ωì‰∫∫„ÄÅ‰ºÅ‰∏öÂÖ¨ÂÖ≥„ÄÅÂÖ≥ÂøÉÊó∂‰∫ãÁöÑÊôÆÈÄöÁî®Êà∑&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;ÂÖ∏ÂûãÂú∫ÊôØÔºö&lt;/strong&gt; ËÇ°Â∏ÇÊäïËµÑÁõëÊéß„ÄÅÂìÅÁâåËàÜÊÉÖËøΩË∏™„ÄÅË°å‰∏öÂä®ÊÄÅÂÖ≥Ê≥®„ÄÅÁîüÊ¥ªËµÑËÆØËé∑Âèñ&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="center"&gt;Github Pages ÊïàÊûú(ÊâãÊú∫Á´ØÈÄÇÈÖç„ÄÅÈÇÆÁÆ±Êé®ÈÄÅÊïàÊûú)&lt;/th&gt; 
   &lt;th align="center"&gt;È£û‰π¶Êé®ÈÄÅÊïàÊûú&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;img src="https://raw.githubusercontent.com/sansan0/TrendRadar/master/_image/github-pages.png" alt="Github PagesÊïàÊûú" /&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;img src="https://raw.githubusercontent.com/sansan0/TrendRadar/master/_image/feishu.jpg" alt="È£û‰π¶Êé®ÈÄÅÊïàÊûú" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;üìù Êõ¥Êñ∞Êó•Âøó&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;ÂçáÁ∫ßËØ¥Êòé&lt;/strong&gt;Ôºö&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;ÊèêÁ§∫&lt;/strong&gt;Ôºö‰∏çË¶ÅÈÄöËøá &lt;strong&gt;Sync fork&lt;/strong&gt; Êõ¥Êñ∞Êú¨È°πÁõÆ, Âª∫ËÆÆÊü•Áúã„ÄêÂéÜÂè≤Êõ¥Êñ∞„ÄëÔºåÊòéÁ°ÆÂÖ∑‰ΩìÁöÑ„ÄêÂçáÁ∫ßÊñπÂºè„ÄëÂíå„ÄêÂäüËÉΩÂÜÖÂÆπ„Äë&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Â∞èÁâàÊú¨Êõ¥Êñ∞&lt;/strong&gt;Ôºö‰ªé v2.x ÂçáÁ∫ßÂà∞ v2.y, Áî®Êú¨È°πÁõÆÁöÑ &lt;code&gt;main.py&lt;/code&gt; ‰ª£Á†ÅÊõøÊç¢‰Ω† fork ‰ªìÂ∫ì‰∏≠ÁöÑÂØπÂ∫îÊñá‰ª∂&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Â§ßÁâàÊú¨ÂçáÁ∫ß&lt;/strong&gt;Ôºö‰ªé v1.x ÂçáÁ∫ßÂà∞ v2.y, Âª∫ËÆÆÂà†Èô§Áé∞Êúâ fork ÂêéÈáçÊñ∞ forkÔºåËøôÊ†∑Êõ¥ÁúÅÂäõ‰∏îÈÅøÂÖçÈÖçÁΩÆÂÜ≤Á™Å&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;2025/10/26 - mcp-v1.0.1&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;MCP Ê®°ÂùóÊõ¥Êñ∞:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;‰øÆÂ§çÊó•ÊúüÊü•ËØ¢ÂèÇÊï∞‰º†ÈÄíÈîôËØØ&lt;/li&gt; 
 &lt;li&gt;Áªü‰∏ÄÊâÄÊúâÂ∑•ÂÖ∑ÁöÑÊó∂Èó¥ÂèÇÊï∞Ê†ºÂºè&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;2025/10/31 - v3.0.4&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Ëß£ÂÜ≥È£û‰π¶Âõ†Êé®ÈÄÅÂÜÖÂÆπËøáÈïøËÄå‰∫ßÁîüÁöÑÈîôËØØÔºåÂÆûÁé∞‰∫ÜÂàÜÊâπÊé®ÈÄÅ&lt;/li&gt; 
&lt;/ul&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;üëâ ÂéÜÂè≤Êõ¥Êñ∞&lt;/strong&gt;&lt;/summary&gt; 
 &lt;h3&gt;2025/10/23 - v3.0.3&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Êâ©Â§ß ntfy ÈîôËØØ‰ø°ÊÅØÊòæÁ§∫ËåÉÂõ¥&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;2025/10/21 - v3.0.2&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;‰øÆÂ§ç ntfy Êé®ÈÄÅÁºñÁ†ÅÈóÆÈ¢ò&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;2025/10/20 - v3.0.0&lt;/h3&gt; 
 &lt;p&gt;&lt;strong&gt;ÈáçÂ§ßÊõ¥Êñ∞ - AI ÂàÜÊûêÂäüËÉΩ‰∏äÁ∫ø&lt;/strong&gt; ü§ñ&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Ê†∏ÂøÉÂäüËÉΩ&lt;/strong&gt;Ôºö&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Êñ∞Â¢ûÂü∫‰∫é MCP (Model Context Protocol) ÁöÑ AI ÂàÜÊûêÊúçÂä°Âô®&lt;/li&gt; 
    &lt;li&gt;ÊîØÊåÅ13ÁßçÊô∫ËÉΩÂàÜÊûêÂ∑•ÂÖ∑ÔºöÂü∫Á°ÄÊü•ËØ¢„ÄÅÊô∫ËÉΩÊ£ÄÁ¥¢„ÄÅÈ´òÁ∫ßÂàÜÊûê„ÄÅÁ≥ªÁªüÁÆ°ÁêÜ&lt;/li&gt; 
    &lt;li&gt;Ëá™ÁÑ∂ËØ≠Ë®Ä‰∫§‰∫íÔºöÈÄöËøáÂØπËØùÊñπÂºèÊü•ËØ¢ÂíåÂàÜÊûêÊñ∞ÈóªÊï∞ÊçÆ&lt;/li&gt; 
    &lt;li&gt;Â§öÂÆ¢Êà∑Á´ØÊîØÊåÅÔºöClaude Desktop„ÄÅCherry Studio„ÄÅCursor„ÄÅCline Á≠â&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;ÂàÜÊûêËÉΩÂäõ&lt;/strong&gt;Ôºö&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;ËØùÈ¢òË∂ãÂäøÂàÜÊûêÔºàÁÉ≠Â∫¶ËøΩË∏™„ÄÅÁîüÂëΩÂë®Êúü„ÄÅÁàÜÁÅ´Ê£ÄÊµã„ÄÅË∂ãÂäøÈ¢ÑÊµãÔºâ&lt;/li&gt; 
    &lt;li&gt;Êï∞ÊçÆÊ¥ûÂØüÔºàÂπ≥Âè∞ÂØπÊØî„ÄÅÊ¥ªË∑ÉÂ∫¶ÁªüËÆ°„ÄÅÂÖ≥ÈîÆËØçÂÖ±Áé∞Ôºâ&lt;/li&gt; 
    &lt;li&gt;ÊÉÖÊÑüÂàÜÊûê„ÄÅÁõ∏‰ººÊñ∞ÈóªÊü•Êâæ„ÄÅÊô∫ËÉΩÊëòË¶ÅÁîüÊàê&lt;/li&gt; 
    &lt;li&gt;ÂéÜÂè≤Áõ∏ÂÖ≥Êñ∞ÈóªÊ£ÄÁ¥¢„ÄÅÂ§öÊ®°ÂºèÊêúÁ¥¢&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Êõ¥Êñ∞ÊèêÁ§∫&lt;/strong&gt;Ôºö&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;ËøôÊòØÁã¨Á´ãÁöÑ AI ÂàÜÊûêÂäüËÉΩÔºå‰∏çÂΩ±ÂìçÁé∞ÊúâÁöÑÊé®ÈÄÅÂäüËÉΩ&lt;/li&gt; 
    &lt;li&gt;ÂèØÈÄâÊã©ÊÄß‰ΩøÁî®ÔºåÊó†ÈúÄÂçáÁ∫ßÁé∞ÊúâÈÉ®ÁΩ≤&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;2025/10/15 - v2.4.4&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Êõ¥Êñ∞ÂÜÖÂÆπ&lt;/strong&gt;Ôºö&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;‰øÆÂ§ç ntfy Êé®ÈÄÅÁºñÁ†ÅÈóÆÈ¢ò + 1&lt;/li&gt; 
    &lt;li&gt;‰øÆÂ§çÊé®ÈÄÅÊó∂Èó¥Á™óÂè£Âà§Êñ≠ÈóÆÈ¢ò&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Êõ¥Êñ∞ÊèêÁ§∫&lt;/strong&gt;Ôºö&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Âª∫ËÆÆ„ÄêÂ∞èÁâàÊú¨ÂçáÁ∫ß„Äë&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;2025/10/10 - v2.4.3&lt;/h3&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;ÊÑüË∞¢ &lt;a href="https://github.com/sansan0/TrendRadar/issues/98"&gt;nidaye996&lt;/a&gt; ÂèëÁé∞ÁöÑ‰ΩìÈ™åÈóÆÈ¢ò&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Êõ¥Êñ∞ÂÜÖÂÆπ&lt;/strong&gt;Ôºö&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;ÈáçÊûÑ"ÈùôÈªòÊé®ÈÄÅÊ®°Âºè"ÂëΩÂêç‰∏∫"Êé®ÈÄÅÊó∂Èó¥Á™óÂè£ÊéßÂà∂"ÔºåÊèêÂçáÂäüËÉΩÁêÜËß£Â∫¶&lt;/li&gt; 
    &lt;li&gt;ÊòéÁ°ÆÊé®ÈÄÅÊó∂Èó¥Á™óÂè£‰Ωú‰∏∫ÂèØÈÄâÈôÑÂä†ÂäüËÉΩÔºåÂèØ‰∏é‰∏âÁßçÊé®ÈÄÅÊ®°ÂºèÊê≠ÈÖç‰ΩøÁî®&lt;/li&gt; 
    &lt;li&gt;ÊîπËøõÊ≥®ÈáäÂíåÊñáÊ°£ÊèèËø∞Ôºå‰ΩøÂäüËÉΩÂÆö‰ΩçÊõ¥Âä†Ê∏ÖÊô∞&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Êõ¥Êñ∞ÊèêÁ§∫&lt;/strong&gt;Ôºö&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Ëøô‰∏™‰ªÖ‰ªÖÊòØÈáçÊûÑÔºåÂèØ‰ª•‰∏çÁî®ÂçáÁ∫ß&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;2025/10/8 - v2.4.2&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Êõ¥Êñ∞ÂÜÖÂÆπ&lt;/strong&gt;Ôºö&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;‰øÆÂ§ç ntfy Êé®ÈÄÅÁºñÁ†ÅÈóÆÈ¢ò&lt;/li&gt; 
    &lt;li&gt;‰øÆÂ§çÈÖçÁΩÆÊñá‰ª∂Áº∫Â§±ÈóÆÈ¢ò&lt;/li&gt; 
    &lt;li&gt;‰ºòÂåñ ntfy Êé®ÈÄÅÊïàÊûú&lt;/li&gt; 
    &lt;li&gt;Â¢ûÂä† github page ÂõæÁâáÂàÜÊÆµÂØºÂá∫ÂäüËÉΩ&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Êõ¥Êñ∞ÊèêÁ§∫&lt;/strong&gt;Ôºö&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Âª∫ËÆÆ‰ΩøÁî®„ÄêÂ§ßÁâàÊú¨Êõ¥Êñ∞„Äë&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;2025/10/2 - v2.4.0&lt;/h3&gt; 
 &lt;p&gt;&lt;strong&gt;Êñ∞Â¢û ntfy Êé®ÈÄÅÈÄöÁü•&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Ê†∏ÂøÉÂäüËÉΩ&lt;/strong&gt;Ôºö&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;ÊîØÊåÅ ntfy.sh ÂÖ¨ÂÖ±ÊúçÂä°ÂíåËá™ÊâòÁÆ°ÊúçÂä°Âô®&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;‰ΩøÁî®Âú∫ÊôØ&lt;/strong&gt;Ôºö&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;ÈÄÇÂêàËøΩÊ±ÇÈöêÁßÅÁöÑÁî®Êà∑ÔºàÊîØÊåÅËá™ÊâòÁÆ°Ôºâ&lt;/li&gt; 
    &lt;li&gt;Ë∑®Âπ≥Âè∞Êé®ÈÄÅÔºàiOS„ÄÅAndroid„ÄÅDesktop„ÄÅWebÔºâ&lt;/li&gt; 
    &lt;li&gt;Êó†ÈúÄÊ≥®ÂÜåË¥¶Âè∑ÔºàÂÖ¨ÂÖ±ÊúçÂä°Âô®Ôºâ&lt;/li&gt; 
    &lt;li&gt;ÂºÄÊ∫êÂÖçË¥πÔºàMIT ÂçèËÆÆÔºâ&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Êõ¥Êñ∞ÊèêÁ§∫&lt;/strong&gt;Ôºö&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Âª∫ËÆÆ‰ΩøÁî®„ÄêÂ§ßÁâàÊú¨Êõ¥Êñ∞„Äë&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;2025/09/26 - v2.3.2&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;‰øÆÊ≠£‰∫ÜÈÇÆ‰ª∂ÈÄöÁü•ÈÖçÁΩÆÊ£ÄÊü•Ë¢´ÈÅóÊºèÁöÑÈóÆÈ¢òÔºà&lt;a href="https://github.com/sansan0/TrendRadar/issues/88"&gt;#88&lt;/a&gt;Ôºâ&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;‰øÆÂ§çËØ¥Êòé&lt;/strong&gt;Ôºö&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Ëß£ÂÜ≥‰∫ÜÂç≥‰ΩøÊ≠£Á°ÆÈÖçÁΩÆÈÇÆ‰ª∂ÈÄöÁü•ÔºåÁ≥ªÁªü‰ªçÊèêÁ§∫"Êú™ÈÖçÁΩÆ‰ªª‰Ωïwebhook"ÁöÑÈóÆÈ¢ò&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;2025/09/22 - v2.3.1&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;Êñ∞Â¢ûÈÇÆ‰ª∂Êé®ÈÄÅÂäüËÉΩ&lt;/strong&gt;ÔºåÊîØÊåÅÂ∞ÜÁÉ≠ÁÇπÊñ∞ÈóªÊä•ÂëäÂèëÈÄÅÂà∞ÈÇÆÁÆ±&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Êô∫ËÉΩ SMTP ËØÜÂà´&lt;/strong&gt;ÔºöËá™Âä®ËØÜÂà´ Gmail„ÄÅQQÈÇÆÁÆ±„ÄÅOutlook„ÄÅÁΩëÊòìÈÇÆÁÆ±Á≠â 10+ ÁßçÈÇÆÁÆ±ÊúçÂä°ÂïÜÈÖçÁΩÆ&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;HTML Á≤æÁæéÊ†ºÂºè&lt;/strong&gt;ÔºöÈÇÆ‰ª∂ÂÜÖÂÆπÈááÁî®‰∏éÁΩëÈ°µÁâàÁõ∏ÂêåÁöÑ HTML Ê†ºÂºèÔºåÊéíÁâàÁ≤æÁæéÔºåÁßªÂä®Á´ØÈÄÇÈÖç&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;ÊâπÈáèÂèëÈÄÅÊîØÊåÅ&lt;/strong&gt;ÔºöÊîØÊåÅÂ§ö‰∏™Êî∂‰ª∂‰∫∫ÔºåÁî®ÈÄóÂè∑ÂàÜÈöîÂç≥ÂèØÂêåÊó∂ÂèëÈÄÅÁªôÂ§ö‰∫∫&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Ëá™ÂÆö‰πâ SMTP&lt;/strong&gt;ÔºöÂèØËá™ÂÆö‰πâ SMTP ÊúçÂä°Âô®ÂíåÁ´ØÂè£&lt;/li&gt; 
  &lt;li&gt;‰øÆÂ§çDockerÊûÑÂª∫ÁΩëÁªúËøûÊé•ÈóÆÈ¢ò&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;‰ΩøÁî®ËØ¥Êòé&lt;/strong&gt;Ôºö&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;ÈÄÇÁî®Âú∫ÊôØÔºöÈÄÇÂêàÈúÄË¶ÅÈÇÆ‰ª∂ÂΩíÊ°£„ÄÅÂõ¢ÈòüÂàÜ‰∫´„ÄÅÂÆöÊó∂Êä•ÂëäÁöÑÁî®Êà∑&lt;/li&gt; 
  &lt;li&gt;ÊîØÊåÅÈÇÆÁÆ±ÔºöGmail„ÄÅQQÈÇÆÁÆ±„ÄÅOutlook/Hotmail„ÄÅ163/126ÈÇÆÁÆ±„ÄÅÊñ∞Êµ™ÈÇÆÁÆ±„ÄÅÊêúÁãêÈÇÆÁÆ±Á≠â&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;Êõ¥Êñ∞ÊèêÁ§∫&lt;/strong&gt;Ôºö&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Ê≠§Ê¨°Êõ¥Êñ∞ÁöÑÂÜÖÂÆπÊØîËæÉÂ§öÔºåÂ¶ÇÊûúÊÉ≥ÂçáÁ∫ßÔºåÂª∫ËÆÆÈááÁî®„ÄêÂ§ßÁâàÊú¨ÂçáÁ∫ß„Äë&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;2025/09/17 - v2.2.0&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Êñ∞Â¢û‰∏ÄÈîÆ‰øùÂ≠òÊñ∞ÈóªÂõæÁâáÂäüËÉΩÔºåËÆ©‰Ω†ËΩªÊùæÂàÜ‰∫´ÂÖ≥Ê≥®ÁöÑÁÉ≠ÁÇπ&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;‰ΩøÁî®ËØ¥Êòé&lt;/strong&gt;Ôºö&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;ÈÄÇÁî®Âú∫ÊôØÔºöÂΩì‰Ω†ÊåâÁÖßÊïôÁ®ãÂºÄÂêØ‰∫ÜÁΩëÈ°µÁâàÂäüËÉΩÂêé(GitHub Pages)&lt;/li&gt; 
  &lt;li&gt;‰ΩøÁî®ÊñπÊ≥ïÔºöÁî®ÊâãÊú∫ÊàñÁîµËÑëÊâìÂºÄËØ•ÁΩëÈ°µÈìæÊé•ÔºåÁÇπÂáªÈ°µÈù¢È°∂ÈÉ®ÁöÑ"‰øùÂ≠ò‰∏∫ÂõæÁâá"ÊåâÈíÆ&lt;/li&gt; 
  &lt;li&gt;ÂÆûÈôÖÊïàÊûúÔºöÁ≥ªÁªü‰ºöËá™Âä®Â∞ÜÂΩìÂâçÁöÑÊñ∞ÈóªÊä•ÂëäÂà∂‰ΩúÊàê‰∏ÄÂº†Á≤æÁæéÂõæÁâáÔºå‰øùÂ≠òÂà∞‰Ω†ÁöÑÊâãÊú∫Áõ∏ÂÜåÊàñÁîµËÑëÊ°åÈù¢&lt;/li&gt; 
  &lt;li&gt;ÂàÜ‰∫´‰æøÂà©Ôºö‰Ω†ÂèØ‰ª•Áõ¥Êé•ÊääËøôÂº†ÂõæÁâáÂèëÁªôÊúãÂèã„ÄÅÂèëÂà∞ÊúãÂèãÂúàÔºåÊàñÂàÜ‰∫´Âà∞Â∑•‰ΩúÁæ§ÔºåËÆ©Âà´‰∫∫‰πüËÉΩÁúãÂà∞‰Ω†ÂèëÁé∞ÁöÑÈáçË¶ÅËµÑËÆØ&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;2025/09/13 - v2.1.2&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Ëß£ÂÜ≥ÈíâÈíâÁöÑÊé®ÈÄÅÂÆπÈáèÈôêÂà∂ÂØºËá¥ÁöÑÊñ∞ÈóªÊé®ÈÄÅÂ§±Ë¥•ÈóÆÈ¢ò(ÈááÁî®ÂàÜÊâπÊé®ÈÄÅ)&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;2025/09/04 - v2.1.1&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;‰øÆÂ§çdockerÂú®Êüê‰∫õÊû∂ÊûÑ‰∏≠Êó†Ê≥ïÊ≠£Â∏∏ËøêË°åÁöÑÈóÆÈ¢ò&lt;/li&gt; 
  &lt;li&gt;Ê≠£ÂºèÂèëÂ∏ÉÂÆòÊñπ Docker ÈïúÂÉè wantcat/trendradarÔºåÊîØÊåÅÂ§öÊû∂ÊûÑ&lt;/li&gt; 
  &lt;li&gt;‰ºòÂåñ Docker ÈÉ®ÁΩ≤ÊµÅÁ®ãÔºåÊó†ÈúÄÊú¨Âú∞ÊûÑÂª∫Âç≥ÂèØÂø´ÈÄü‰ΩøÁî®&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;2025/08/30 - v2.1.0&lt;/h3&gt; 
 &lt;p&gt;&lt;strong&gt;Ê†∏ÂøÉÊîπËøõ&lt;/strong&gt;Ôºö&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;Êé®ÈÄÅÈÄªËæë‰ºòÂåñ&lt;/strong&gt;Ôºö‰ªé"ÊØèÊ¨°ÊâßË°åÈÉΩÊé®ÈÄÅ"Êîπ‰∏∫"Êó∂Èó¥Á™óÂè£ÂÜÖÂèØÊéßÊé®ÈÄÅ"&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Êó∂Èó¥Á™óÂè£ÊéßÂà∂&lt;/strong&gt;ÔºöÂèØËÆæÂÆöÊé®ÈÄÅÊó∂Èó¥ËåÉÂõ¥ÔºåÈÅøÂÖçÈùûÂ∑•‰ΩúÊó∂Èó¥ÊâìÊâ∞&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Êé®ÈÄÅÈ¢ëÁéáÂèØÈÄâ&lt;/strong&gt;ÔºöÊó∂Èó¥ÊÆµÂÜÖÊîØÊåÅÂçïÊ¨°Êé®ÈÄÅÊàñÂ§öÊ¨°Êé®ÈÄÅ&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;Êõ¥Êñ∞ÊèêÁ§∫&lt;/strong&gt;Ôºö&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Êú¨ÂäüËÉΩÈªòËÆ§ÂÖ≥Èó≠ÔºåÈúÄÊâãÂä®Âú® config.yaml ‰∏≠ÂºÄÂêØÊé®ÈÄÅÊó∂Èó¥Á™óÂè£ÊéßÂà∂&lt;/li&gt; 
  &lt;li&gt;ÂçáÁ∫ßÈúÄÂêåÊó∂Êõ¥Êñ∞ main.py Âíå config.yaml ‰∏§‰∏™Êñá‰ª∂&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;2025/08/27 - v2.0.4&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Êú¨Ê¨°ÁâàÊú¨‰∏çÊòØÂäüËÉΩ‰øÆÂ§çÔºåËÄåÊòØÈáçË¶ÅÊèêÈÜí&lt;/li&gt; 
  &lt;li&gt;ËØ∑Âä°ÂøÖÂ¶•ÂñÑ‰øùÁÆ°Â•Ω webhooksÔºå‰∏çË¶ÅÂÖ¨ÂºÄÔºå‰∏çË¶ÅÂÖ¨ÂºÄÔºå‰∏çË¶ÅÂÖ¨ÂºÄ&lt;/li&gt; 
  &lt;li&gt;Â¶ÇÊûú‰Ω†‰ª• fork ÁöÑÊñπÂºèÂ∞ÜÊú¨È°πÁõÆÈÉ®ÁΩ≤Âú® GitHub ‰∏äÔºåËØ∑Â∞Ü webhooks Â°´ÂÖ• GitHub SecretÔºåËÄåÈùû config.yaml&lt;/li&gt; 
  &lt;li&gt;Â¶ÇÊûú‰Ω†Â∑≤ÁªèÊö¥Èú≤‰∫Ü webhooks ÊàñÂ∞ÜÂÖ∂Â°´ÂÖ•‰∫Ü config.yamlÔºåÂª∫ËÆÆÂà†Èô§ÂêéÈáçÊñ∞ÁîüÊàê&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;2025/08/06 - v2.0.3&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;‰ºòÂåñ github page ÁöÑÁΩëÈ°µÁâàÊïàÊûúÔºåÊñπ‰æøÁßªÂä®Á´Ø‰ΩøÁî®&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;2025/07/28 - v2.0.2&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;ÈáçÊûÑ‰ª£Á†Å&lt;/li&gt; 
  &lt;li&gt;Ëß£ÂÜ≥ÁâàÊú¨Âè∑ÂÆπÊòìË¢´ÈÅóÊºè‰øÆÊîπÁöÑÈóÆÈ¢ò&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;2025/07/27 - v2.0.1&lt;/h3&gt; 
 &lt;p&gt;&lt;strong&gt;‰øÆÂ§çÈóÆÈ¢ò&lt;/strong&gt;:&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;docker ÁöÑ shell ËÑöÊú¨ÁöÑÊç¢Ë°åÁ¨¶‰∏∫ CRLF ÂØºËá¥ÁöÑÊâßË°åÂºÇÂ∏∏ÈóÆÈ¢ò&lt;/li&gt; 
  &lt;li&gt;frequency_words.txt ‰∏∫Á©∫Êó∂ÔºåÂØºËá¥Êñ∞ÈóªÂèëÈÄÅ‰πü‰∏∫Á©∫ÁöÑÈÄªËæëÈóÆÈ¢ò&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;ul&gt; 
  &lt;li&gt;‰øÆÂ§çÂêéÔºåÂΩì‰Ω†ÈÄâÊã© frequency_words.txt ‰∏∫Á©∫Êó∂ÔºåÂ∞Ü&lt;strong&gt;Êé®ÈÄÅÊâÄÊúâÊñ∞Èóª&lt;/strong&gt;Ôºå‰ΩÜÂèóÈôê‰∫éÊ∂àÊÅØÊé®ÈÄÅÂ§ßÂ∞èÈôêÂà∂ÔºåËØ∑ÂÅöÂ¶Ç‰∏ãË∞ÉÊï¥ 
   &lt;ul&gt; 
    &lt;li&gt;ÊñπÊ°à‰∏ÄÔºöÂÖ≥Èó≠ÊâãÊú∫Êé®ÈÄÅÔºåÂè™ÈÄâÊã© Github Pages Â∏ÉÁΩÆ(ËøôÊòØËÉΩËé∑ÂæóÊúÄÂÆåÊï¥‰ø°ÊÅØÁöÑÊñπÊ°àÔºåÂ∞ÜÊääÊâÄÊúâÂπ≥Âè∞ÁöÑÁÉ≠ÁÇπÊåâÁÖß‰Ω†&lt;strong&gt;Ëá™ÂÆö‰πâÁöÑÁÉ≠ÊêúÁÆóÊ≥ï&lt;/strong&gt;ËøõË°åÈáçÊñ∞ÊéíÂ∫è)&lt;/li&gt; 
    &lt;li&gt;ÊñπÊ°à‰∫åÔºöÂáèÂ∞ëÊé®ÈÄÅÂπ≥Âè∞Ôºå‰ºòÂÖàÈÄâÊã©&lt;strong&gt;‰ºÅ‰∏öÂæÆ‰ø°&lt;/strong&gt;Êàñ&lt;strong&gt;Telegram&lt;/strong&gt;ÔºåËøô‰∏§‰∏™Êé®ÈÄÅÊàëÂÅö‰∫ÜÂàÜÊâπÊé®ÈÄÅÂäüËÉΩ(Âõ†‰∏∫ÂàÜÊâπÊé®ÈÄÅÂΩ±ÂìçÊé®ÈÄÅ‰ΩìÈ™åÔºå‰∏îÂè™ÊúâËøô‰∏§‰∏™Âπ≥Âè∞Âè™Áªô‰∏ÄÁÇπÁÇπÊé®ÈÄÅÂÆπÈáèÔºåÊâÄ‰ª•Êâç‰∏çÂæóÂ∑≤ÂÅö‰∫ÜÂàÜÊâπÊé®ÈÄÅÂäüËÉΩÔºå‰ΩÜËá≥Â∞ëËÉΩ‰øùËØÅËé∑ÂæóÁöÑ‰ø°ÊÅØÂÆåÊï¥)&lt;/li&gt; 
    &lt;li&gt;ÊñπÊ°à‰∏âÔºöÂèØ‰∏éÊñπÊ°à‰∫åÁªìÂêàÔºåÊ®°ÂºèÈÄâÊã© current Êàñ incremental ÂèØÊúâÊïàÂáèÂ∞ë‰∏ÄÊ¨°ÊÄßÊé®ÈÄÅÁöÑÂÜÖÂÆπ&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;2025/07/17 - v2.0.0&lt;/h3&gt; 
 &lt;p&gt;&lt;strong&gt;ÈáçÂ§ßÈáçÊûÑ&lt;/strong&gt;Ôºö&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;ÈÖçÁΩÆÁÆ°ÁêÜÈáçÊûÑÔºöÊâÄÊúâÈÖçÁΩÆÁé∞Âú®ÈÄöËøá &lt;code&gt;config/config.yaml&lt;/code&gt; Êñá‰ª∂ÁÆ°ÁêÜÔºàmain.py Êàë‰æùÊóßÊ≤°ÊãÜÂàÜÔºåÊñπ‰æø‰Ω†‰ª¨Â§çÂà∂ÂçáÁ∫ßÔºâ&lt;/li&gt; 
  &lt;li&gt;ËøêË°åÊ®°ÂºèÂçáÁ∫ßÔºöÊîØÊåÅ‰∏âÁßçÊ®°Âºè - &lt;code&gt;daily&lt;/code&gt;ÔºàÂΩìÊó•Ê±áÊÄªÔºâ„ÄÅ&lt;code&gt;current&lt;/code&gt;ÔºàÂΩìÂâçÊ¶úÂçïÔºâ„ÄÅ&lt;code&gt;incremental&lt;/code&gt;ÔºàÂ¢ûÈáèÁõëÊéßÔºâ&lt;/li&gt; 
  &lt;li&gt;Docker ÊîØÊåÅÔºöÂÆåÊï¥ÁöÑ Docker ÈÉ®ÁΩ≤ÊñπÊ°àÔºåÊîØÊåÅÂÆπÂô®ÂåñËøêË°å&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;ÈÖçÁΩÆÊñá‰ª∂ËØ¥Êòé&lt;/strong&gt;Ôºö&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;code&gt;config/config.yaml&lt;/code&gt; - ‰∏ªÈÖçÁΩÆÊñá‰ª∂ÔºàÂ∫îÁî®ËÆæÁΩÆ„ÄÅÁà¨Ëô´ÈÖçÁΩÆ„ÄÅÈÄöÁü•ÈÖçÁΩÆ„ÄÅÂπ≥Âè∞ÈÖçÁΩÆÁ≠âÔºâ&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;config/frequency_words.txt&lt;/code&gt; - ÂÖ≥ÈîÆËØçÈÖçÁΩÆÔºàÁõëÊéßËØçÊ±áËÆæÁΩÆÔºâ&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;2025/07/09 - v1.4.1&lt;/h3&gt; 
 &lt;p&gt;&lt;strong&gt;ÂäüËÉΩÊñ∞Â¢û&lt;/strong&gt;ÔºöÂ¢ûÂä†Â¢ûÈáèÊé®ÈÄÅ(Âú® main.py Â§¥ÈÉ®ÈÖçÁΩÆ FOCUS_NEW_ONLY)ÔºåËØ•ÂºÄÂÖ≥Âè™ÂÖ≥ÂøÉÊñ∞ËØùÈ¢òËÄåÈùûÊåÅÁª≠ÁÉ≠Â∫¶ÔºåÂè™Âú®ÊúâÊñ∞ÂÜÖÂÆπÊó∂ÊâçÂèëÈÄöÁü•„ÄÇ&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;‰øÆÂ§çÈóÆÈ¢ò&lt;/strong&gt;: Êüê‰∫õÊÉÖÂÜµ‰∏ãÔºåÁî±‰∫éÊñ∞ÈóªÊú¨Ë∫´Âê´ÊúâÁâπÊÆäÁ¨¶Âè∑ÂØºËá¥ÁöÑÂÅ∂ÂèëÊÄßÊéíÁâàÂºÇÂ∏∏„ÄÇ&lt;/p&gt; 
 &lt;h3&gt;2025/06/23 - v1.3.0&lt;/h3&gt; 
 &lt;p&gt;‰ºÅ‰∏öÂæÆ‰ø° Âíå Telegram ÁöÑÊé®ÈÄÅÊ∂àÊÅØÊúâÈïøÂ∫¶ÈôêÂà∂ÔºåÂØπÊ≠§ÊàëÈááÁî®Â∞ÜÊ∂àÊÅØÊãÜÂàÜÊé®ÈÄÅÁöÑÊñπÂºè„ÄÇÂºÄÂèëÊñáÊ°£ËØ¶ËßÅ&lt;a href="https://developer.work.weixin.qq.com/document/path/91770"&gt;‰ºÅ‰∏öÂæÆ‰ø°&lt;/a&gt; Âíå &lt;a href="https://core.telegram.org/bots/api"&gt;Telegram&lt;/a&gt;&lt;/p&gt; 
 &lt;h3&gt;2025/06/21 - v1.2.1&lt;/h3&gt; 
 &lt;p&gt;Âú®Êú¨ÁâàÊú¨‰πãÂâçÁöÑÊóßÁâàÊú¨Ôºå‰∏ç‰ªÖ main.py ÈúÄË¶ÅÂ§çÂà∂ÊõøÊç¢Ôºå crawler.yml ‰πüÈúÄË¶Å‰Ω†Â§çÂà∂ÊõøÊç¢ &lt;a href="https://github.com/sansan0/TrendRadar/raw/master/.github/workflows/crawler.yml"&gt;https://github.com/sansan0/TrendRadar/blob/master/.github/workflows/crawler.yml&lt;/a&gt;&lt;/p&gt; 
 &lt;h3&gt;2025/06/19 - v1.2.0&lt;/h3&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;ÊÑüË∞¢ claude research Êï¥ÁêÜÁöÑÂêÑÂπ≥Âè∞ api ,ËÆ©ÊàëÂø´ÈÄüÂÆåÊàêÂêÑÂπ≥Âè∞ÈÄÇÈÖçÔºàËôΩÁÑ∂‰ª£Á†ÅÊõ¥Â§öÂÜó‰Ωô‰∫Ü~&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;ol&gt; 
  &lt;li&gt;ÊîØÊåÅ telegram Ôºå‰ºÅ‰∏öÂæÆ‰ø°ÔºåÈíâÈíâÊé®ÈÄÅÊ∏†ÈÅì, ÊîØÊåÅÂ§öÊ∏†ÈÅìÈÖçÁΩÆÂíåÂêåÊó∂Êé®ÈÄÅ&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;h3&gt;2025/06/18 - v1.1.0&lt;/h3&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;&lt;strong&gt;200 star‚≠ê&lt;/strong&gt; ‰∫Ü, ÁªßÁª≠ÁªôÂ§ß‰ºôÂÑøÂä©ÂÖ¥~ËøëÊúüÔºåÂú®ÊàëÁöÑ"ÊÄÇÊÅø"‰∏ãÔºåÊå∫Â§ö‰∫∫Âú®ÊàëÂÖ¨‰ºóÂè∑ÁÇπËµûÂàÜ‰∫´Êé®ËçêÂä©Âäõ‰∫ÜÊàëÔºåÊàëÈÉΩÂú®ÂêéÂè∞ÁúãËßÅ‰∫ÜÂÖ∑‰ΩìË¥¶Âè∑ÁöÑÈºìÂä±Êï∞ÊçÆÔºåÂæàÂ§öÈÉΩÊàê‰∫ÜÂ§©‰ΩøËΩÆËÄÅÁ≤âÔºàÊàëÁé©ÂÖ¨‰ºóÂè∑Êâç‰∏Ä‰∏™Â§öÊúàÔºåËôΩÁÑ∂Ê≥®ÂÜåÊòØ‰∏ÉÂÖ´Âπ¥ÂâçÁöÑ‰∫ã‰∫ÜÂìàÂìàÔºåÂ±û‰∫é‰∏äËΩ¶Êó©ÔºåÂèëËΩ¶ÊôöÔºâÔºå‰ΩÜÂõ†‰∏∫‰Ω†‰ª¨Ê≤°ÊúâÁïôË®ÄÊàñÁßÅ‰ø°ÊàëÔºåÊâÄ‰ª•Êàë‰πüÊó†Ê≥ï‰∏Ä‰∏ÄÂõûÂ∫îÂπ∂ÊÑüË∞¢ÊîØÊåÅÔºåÂú®Ê≠§‰∏ÄÂπ∂Ë∞¢Ë∞¢ÔºÅ&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;ol&gt; 
  &lt;li&gt;ÈáçË¶ÅÁöÑÊõ¥Êñ∞ÔºåÂä†‰∫ÜÊùÉÈáçÔºå‰Ω†Áé∞Âú®ÁúãÂà∞ÁöÑÊñ∞ÈóªÈÉΩÊòØÊúÄÁÉ≠ÁÇπÊúÄÊúâÂÖ≥Ê≥®Â∫¶ÁöÑÂá∫Áé∞Âú®ÊúÄ‰∏äÈù¢&lt;/li&gt; 
  &lt;li&gt;Êõ¥Êñ∞ÊñáÊ°£‰ΩøÁî®ÔºåÂõ†‰∏∫ËøëÊúüÊõ¥Êñ∞‰∫ÜÂæàÂ§öÂäüËÉΩÔºåËÄå‰∏î‰πãÂâçÁöÑ‰ΩøÁî®ÊñáÊ°£ÊàëÂÅ∑ÊáíÂÜôÁöÑÁÆÄÂçïÔºàËßÅ‰∏ãÈù¢ÁöÑ ‚öôÔ∏è frequency_words.txt ÈÖçÁΩÆÂÆåÊï¥ÊïôÁ®ãÔºâ&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;h3&gt;2025/06/16 - v1.0.0&lt;/h3&gt; 
 &lt;ol&gt; 
  &lt;li&gt;Â¢ûÂä†‰∫Ü‰∏Ä‰∏™È°πÁõÆÊñ∞ÁâàÊú¨Êõ¥Êñ∞ÊèêÁ§∫ÔºåÈªòËÆ§ÊâìÂºÄÔºåÂ¶ÇË¶ÅÂÖ≥ÊéâÔºåÂèØ‰ª•Âú® main.py ‰∏≠Êää "FEISHU_SHOW_VERSION_UPDATE": True ‰∏≠ÁöÑ True ÊîπÊàê False Âç≥ÂèØ&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;h3&gt;2025/06/13+14&lt;/h3&gt; 
 &lt;ol&gt; 
  &lt;li&gt;ÂéªÊéâ‰∫ÜÂÖºÂÆπ‰ª£Á†ÅÔºå‰πãÂâç fork ÁöÑÂêåÂ≠¶ÔºåÁõ¥Êé•Â§çÂà∂‰ª£Á†Å‰ºöÂú®ÂΩìÂ§©ÊòæÁ§∫ÂºÇÂ∏∏ÔºàÁ¨¨‰∫åÂ§©‰ºöÊÅ¢Â§çÊ≠£Â∏∏Ôºâ&lt;/li&gt; 
  &lt;li&gt;feishu Âíå html Â∫ïÈÉ®Â¢ûÂä†‰∏Ä‰∏™Êñ∞Â¢ûÊñ∞ÈóªÊòæÁ§∫&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;h3&gt;2025/06/09&lt;/h3&gt; 
 &lt;p&gt;&lt;strong&gt;100 star‚≠ê&lt;/strong&gt; ‰∫ÜÔºåÂÜô‰∏™Â∞èÂäüËÉΩÁªôÂ§ß‰ºôÂÑøÂä©Âä©ÂÖ¥ frequency_words.txt Êñá‰ª∂Â¢ûÂä†‰∫Ü‰∏Ä‰∏™„ÄêÂøÖÈ°ªËØç„ÄëÂäüËÉΩÔºå‰ΩøÁî® + Âè∑&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;ÂøÖÈ°ªËØçËØ≠Ê≥ïÂ¶Ç‰∏ãÔºö&lt;br /&gt; ÂîêÂÉßÊàñËÄÖÁå™ÂÖ´ÊàíÂøÖÈ°ªÂú®Ê†áÈ¢òÈáåÂêåÊó∂Âá∫Áé∞ÔºåÊâç‰ºöÊî∂ÂΩïÂà∞Êé®ÈÄÅÊñ∞Èóª‰∏≠&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code&gt;+ÂîêÂÉß
+Áå™ÂÖ´Êàí
&lt;/code&gt;&lt;/pre&gt; 
 &lt;ol start="2"&gt; 
  &lt;li&gt;ËøáÊª§ËØçÁöÑ‰ºòÂÖàÁ∫ßÊõ¥È´òÔºö&lt;br /&gt; Â¶ÇÊûúÊ†áÈ¢ò‰∏≠ËøáÊª§ËØçÂåπÈÖçÂà∞ÂîêÂÉßÂøµÁªèÔºåÈÇ£‰πàÂç≥‰ΩøÂøÖÈ°ªËØçÈáåÊúâÂîêÂÉßÔºå‰πü‰∏çÊòæÁ§∫&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code&gt;+ÂîêÂÉß
!ÂîêÂÉßÂøµÁªè
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h3&gt;2025/06/02&lt;/h3&gt; 
 &lt;ol&gt; 
  &lt;li&gt;&lt;strong&gt;ÁΩëÈ°µ&lt;/strong&gt;Âíå&lt;strong&gt;È£û‰π¶Ê∂àÊÅØ&lt;/strong&gt;ÊîØÊåÅÊâãÊú∫Áõ¥Êé•Ë∑≥ËΩ¨ËØ¶ÊÉÖÊñ∞Èóª&lt;/li&gt; 
  &lt;li&gt;‰ºòÂåñÊòæÁ§∫ÊïàÊûú + 1&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;h3&gt;2025/05/26&lt;/h3&gt; 
 &lt;ol&gt; 
  &lt;li&gt;È£û‰π¶Ê∂àÊÅØÊòæÁ§∫ÊïàÊûú‰ºòÂåñ&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;table&gt; 
  &lt;tbody&gt;
   &lt;tr&gt; 
    &lt;td align="center"&gt; ‰ºòÂåñÂâç&lt;br /&gt; &lt;img src="https://raw.githubusercontent.com/sansan0/TrendRadar/master/_image/before.jpg" alt="È£û‰π¶Ê∂àÊÅØÁïåÈù¢ - ‰ºòÂåñÂâç" width="400" /&gt; &lt;/td&gt; 
    &lt;td align="center"&gt; ‰ºòÂåñÂêé&lt;br /&gt; &lt;img src="https://raw.githubusercontent.com/sansan0/TrendRadar/master/_image/after.jpg" alt="È£û‰π¶Ê∂àÊÅØÁïåÈù¢ - ‰ºòÂåñÂêé" width="400" /&gt; &lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt;
 &lt;/table&gt; 
&lt;/details&gt; 
&lt;h2&gt;üöÄ Âø´ÈÄüÂºÄÂßã&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;ÈÖçÁΩÆÂÆåÊàêÂêéÔºåÊñ∞ÈóªÊï∞ÊçÆ‰∏ÄÂ∞èÊó∂ÂêéÊâç‰ºöÊõ¥Êñ∞ÔºåÂ¶ÇÊÉ≥Âä†Âø´ÔºåÂèØÂèÇÁÖß„ÄêÁ¨¨4Ê≠•„ÄëÊâãÂä®ÊµãËØïÈÖçÁΩÆÊïàÊûú&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Fork Êú¨È°πÁõÆ&lt;/strong&gt;Âà∞‰Ω†ÁöÑ GitHub Ë¥¶Êà∑&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;ÁÇπÂáªÊú¨È°µÈù¢Âè≥‰∏äËßíÁöÑ"Fork"ÊåâÈíÆ&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;ËÆæÁΩÆ GitHub SecretsÔºàÈÄâÊã©‰Ω†ÈúÄË¶ÅÁöÑÂπ≥Âè∞Ôºâ&lt;/strong&gt;:&lt;/p&gt; &lt;p&gt;Âú®‰Ω† Fork ÂêéÁöÑ‰ªìÂ∫ì‰∏≠ÔºåËøõÂÖ• &lt;code&gt;Settings&lt;/code&gt; &amp;gt; &lt;code&gt;Secrets and variables&lt;/code&gt; &amp;gt; &lt;code&gt;Actions&lt;/code&gt; &amp;gt; &lt;code&gt;New repository secret&lt;/code&gt;ÔºåÁÑ∂ÂêéÊ†πÊçÆÈúÄË¶ÅÈÖçÁΩÆ‰ª•‰∏ã‰ªª‰∏ÄÊàñÂ§ö‰∏™ÈÄöÁü•Âπ≥Âè∞Ôºö&lt;/p&gt; &lt;p&gt;ÂèØ‰ª•ÂêåÊó∂ÈÖçÁΩÆÂ§ö‰∏™Âπ≥Âè∞ÔºåÁ≥ªÁªü‰ºöÂêëÊâÄÊúâÈÖçÁΩÆÁöÑÂπ≥Âè∞ÂèëÈÄÅÈÄöÁü•„ÄÇ&lt;/p&gt; &lt;p&gt;ÊïàÊûúÁ±ª‰ºº‰∏ãÂõæÔºå‰∏Ä‰∏™ name ÂØπÂ∫î‰∏Ä‰∏™ secretÔºå‰øùÂ≠òÂÆåÂ∞±Ë°åÔºå‰Ω†ÈáçÊñ∞ÁºñËæëÁúã‰∏çÂà∞ secret ÊòØÊ≠£Â∏∏ÊÉÖÂÜµ„ÄÇ&lt;/p&gt; &lt;img src="https://raw.githubusercontent.com/sansan0/TrendRadar/master/_image/secrets.png" alt="GitHub Secrets" /&gt; 
  &lt;details&gt; 
   &lt;summary&gt; &lt;strong&gt;üëâ ‰ºÅ‰∏öÂæÆ‰ø°Êú∫Âô®‰∫∫&lt;/strong&gt;ÔºàÈÖçÁΩÆÊúÄÁÆÄÂçïÊúÄËøÖÈÄüÔºâ&lt;/summary&gt; 
   &lt;br /&gt; 
   &lt;p&gt;&lt;strong&gt;GitHub Secret ÈÖçÁΩÆÔºö&lt;/strong&gt;&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;ÂêçÁß∞Ôºö&lt;code&gt;WEWORK_WEBHOOK_URL&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;ÂÄºÔºö‰Ω†ÁöÑ‰ºÅ‰∏öÂæÆ‰ø°Êú∫Âô®‰∫∫ Webhook Âú∞ÂùÄ&lt;/li&gt; 
   &lt;/ul&gt; 
   &lt;p&gt;&lt;strong&gt;Êú∫Âô®‰∫∫ËÆæÁΩÆÊ≠•È™§Ôºö&lt;/strong&gt;&lt;/p&gt; 
   &lt;h4&gt;ÊâãÊú∫Á´ØËÆæÁΩÆÔºö&lt;/h4&gt; 
   &lt;ol&gt; 
    &lt;li&gt;ÊâìÂºÄ‰ºÅ‰∏öÂæÆ‰ø° App ‚Üí ËøõÂÖ•ÁõÆÊ†áÂÜÖÈÉ®Áæ§ËÅä&lt;/li&gt; 
    &lt;li&gt;ÁÇπÂáªÂè≥‰∏äËßí"‚Ä¶"ÊåâÈíÆ ‚Üí ÈÄâÊã©"Ê∂àÊÅØÊé®ÈÄÅ"&lt;/li&gt; 
    &lt;li&gt;ÁÇπÂáª"Ê∑ªÂä†" ‚Üí ÂêçÁß∞ËæìÂÖ•"TrendRadar"&lt;/li&gt; 
    &lt;li&gt;Â§çÂà∂ Webhook Âú∞ÂùÄÔºåÁÇπÂáª‰øùÂ≠òÔºåÂ§çÂà∂ÁöÑÂÜÖÂÆπÈÖçÁΩÆÂà∞‰∏äÊñπÁöÑ GitHub Secret ‰∏≠&lt;/li&gt; 
   &lt;/ol&gt; 
   &lt;h4&gt;PC Á´ØËÆæÁΩÆÊµÅÁ®ãÁ±ª‰ºº&lt;/h4&gt; 
  &lt;/details&gt; 
  &lt;details&gt; 
   &lt;summary&gt; &lt;strong&gt;üëâ È£û‰π¶Êú∫Âô®‰∫∫&lt;/strong&gt;ÔºàÊ∂àÊÅØÊòæÁ§∫ÊúÄÂèãÂ•ΩÔºâ&lt;/summary&gt; 
   &lt;br /&gt; 
   &lt;p&gt;&lt;strong&gt;GitHub Secret ÈÖçÁΩÆÔºö&lt;/strong&gt;&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;ÂêçÁß∞Ôºö&lt;code&gt;FEISHU_WEBHOOK_URL&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;ÂÄºÔºö‰Ω†ÁöÑÈ£û‰π¶Êú∫Âô®‰∫∫ Webhook Âú∞ÂùÄ(ËØ•ÈìæÊé•ÂºÄÂ§¥Á±ª‰ºº &lt;a href="https://www.feishu.cn/flow/api/trigger-webhook/"&gt;https://www.feishu.cn/flow/api/trigger-webhook/&lt;/a&gt;********)&lt;/li&gt; 
   &lt;/ul&gt; 
   &lt;br /&gt; 
   &lt;p&gt;Êúâ‰∏§‰∏™ÊñπÊ°àÔºå&lt;strong&gt;ÊñπÊ°à‰∏Ä&lt;/strong&gt;ÈÖçÁΩÆÁÆÄÂçïÔºå&lt;strong&gt;ÊñπÊ°à‰∫å&lt;/strong&gt;ÈÖçÁΩÆÂ§çÊùÇ(‰ΩÜÊòØÁ®≥ÂÆöÊé®ÈÄÅ)&lt;/p&gt; 
   &lt;p&gt;ÂÖ∂‰∏≠ÊñπÊ°à‰∏ÄÔºåÁî± &lt;strong&gt;ziventian&lt;/strong&gt;ÂèëÁé∞Âπ∂Êèê‰æõÂª∫ËÆÆÔºåÂú®ËøôÈáåÊÑüË∞¢‰ªñÔºåÈªòËÆ§ÊòØ‰∏™‰∫∫Êé®ÈÄÅÔºå‰πüÂèØ‰ª•ÈÖçÁΩÆÁæ§ÁªÑÊé®ÈÄÅÊìç‰Ωú&lt;a href="https://github.com/sansan0/TrendRadar/issues/97"&gt;#97&lt;/a&gt; Ôºå&lt;/p&gt; 
   &lt;p&gt;&lt;strong&gt;ÊñπÊ°à‰∏ÄÔºö&lt;/strong&gt;&lt;/p&gt; 
   &lt;blockquote&gt; 
    &lt;p&gt;ÂØπÈÉ®ÂàÜ‰∫∫Â≠òÂú®È¢ùÂ§ñÊìç‰ΩúÔºåÂê¶Âàô‰ºöÊä•"Á≥ªÁªüÈîôËØØ"„ÄÇÈúÄË¶ÅÊâãÊú∫Á´ØÊêúÁ¥¢‰∏ãÊú∫Âô®‰∫∫ÔºåÁÑ∂ÂêéÂºÄÂêØÈ£û‰π¶Êú∫Âô®‰∫∫Â∫îÁî®(ËØ•Âª∫ËÆÆÊù•Ëá™‰∫éÁΩëÂèãÔºåÂèØÂèÇËÄÉ)&lt;/p&gt; 
   &lt;/blockquote&gt; 
   &lt;ol&gt; 
    &lt;li&gt; &lt;p&gt;ÁîµËÑëÊµèËßàÂô®ÊâìÂºÄ &lt;a href="https://botbuilder.feishu.cn/home/my-command"&gt;https://botbuilder.feishu.cn/home/my-command&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;ÁÇπÂáª"Êñ∞Âª∫Êú∫Âô®‰∫∫Êåá‰ª§"&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;ÁÇπÂáª"ÈÄâÊã©Ëß¶ÂèëÂô®"ÔºåÂæÄ‰∏ãÊªëÂä®ÔºåÁÇπÂáª"Webhook Ëß¶Âèë"&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;Ê≠§Êó∂‰Ω†‰ºöÁúãÂà∞"Webhook Âú∞ÂùÄ"ÔºåÊääËøô‰∏™ÈìæÊé•ÂÖàÂ§çÂà∂Âà∞Êú¨Âú∞ËÆ∞‰∫ãÊú¨ÊöÇÂ≠òÔºåÁªßÁª≠Êé•‰∏ãÊù•ÁöÑÊìç‰Ωú&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;"ÂèÇÊï∞"ÈáåÈù¢Êîæ‰∏ä‰∏ãÈù¢ÁöÑÂÜÖÂÆπÔºåÁÑ∂ÂêéÁÇπÂáª"ÂÆåÊàê"&lt;/p&gt; &lt;/li&gt; 
   &lt;/ol&gt; 
   &lt;pre&gt;&lt;code class="language-json"&gt;{
  "message_type": "text",
  "content": {
    "total_titles": "{{ÂÜÖÂÆπ}}",
    "timestamp": "{{ÂÜÖÂÆπ}}",
    "report_type": "{{ÂÜÖÂÆπ}}",
    "text": "{{ÂÜÖÂÆπ}}"
  }
}
&lt;/code&gt;&lt;/pre&gt; 
   &lt;ol start="6"&gt; 
    &lt;li&gt; &lt;p&gt;ÁÇπÂáª"ÈÄâÊã©Êìç‰Ωú" &amp;gt; "ÈÄöËøáÂÆòÊñπÊú∫Âô®‰∫∫ÂèëÊ∂àÊÅØ"&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;Ê∂àÊÅØÊ†áÈ¢òÂ°´ÂÜô"TrendRadar ÁÉ≠ÁÇπÁõëÊéß"&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;ÊúÄÂÖ≥ÈîÆÁöÑÈÉ®ÂàÜÊù•‰∫ÜÔºåÁÇπÂáª + ÊåâÈíÆÔºåÈÄâÊã©"Webhook Ëß¶Âèë"ÔºåÁÑ∂ÂêéÊåâÁÖß‰∏ãÈù¢ÁöÑÂõæÁâáÊëÜÊîæ&lt;/p&gt; &lt;/li&gt; 
   &lt;/ol&gt; 
   &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/sansan0/TrendRadar/master/_image/image.png" alt="È£û‰π¶Êú∫Âô®‰∫∫ÈÖçÁΩÆÁ§∫‰æã" /&gt;&lt;/p&gt; 
   &lt;ol start="9"&gt; 
    &lt;li&gt;ÈÖçÁΩÆÂÆåÊàêÂêéÔºåÂ∞ÜÁ¨¨ 4 Ê≠•Â§çÂà∂ÁöÑ Webhook Âú∞ÂùÄÈÖçÁΩÆÂà∞ GitHub Secrets ‰∏≠ÁöÑ &lt;code&gt;FEISHU_WEBHOOK_URL&lt;/code&gt;&lt;/li&gt; 
   &lt;/ol&gt; 
   &lt;br /&gt; 
   &lt;p&gt;&lt;strong&gt;ÊñπÊ°à‰∫åÔºö&lt;/strong&gt;&lt;/p&gt; 
   &lt;ol&gt; 
    &lt;li&gt; &lt;p&gt;ÁîµËÑëÊµèËßàÂô®ÊâìÂºÄ &lt;a href="https://botbuilder.feishu.cn/home/my-app"&gt;https://botbuilder.feishu.cn/home/my-app&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;ÁÇπÂáª"Êñ∞Âª∫Êú∫Âô®‰∫∫Â∫îÁî®"&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;ËøõÂÖ•ÂàõÂª∫ÁöÑÂ∫îÁî®ÂêéÔºåÁÇπÂáª"ÊµÅÁ®ãÊ∂âÂèä" &amp;gt; "ÂàõÂª∫ÊµÅÁ®ã" &amp;gt; "ÈÄâÊã©Ëß¶ÂèëÂô®"&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;ÂæÄ‰∏ãÊªëÂä®ÔºåÁÇπÂáª"Webhook Ëß¶Âèë"&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;Ê≠§Êó∂‰Ω†‰ºöÁúãÂà∞"Webhook Âú∞ÂùÄ"ÔºåÊääËøô‰∏™ÈìæÊé•ÂÖàÂ§çÂà∂Âà∞Êú¨Âú∞ËÆ∞‰∫ãÊú¨ÊöÇÂ≠òÔºåÁªßÁª≠Êé•‰∏ãÊù•ÁöÑÊìç‰Ωú&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;"ÂèÇÊï∞"ÈáåÈù¢Êîæ‰∏ä‰∏ãÈù¢ÁöÑÂÜÖÂÆπÔºåÁÑ∂ÂêéÁÇπÂáª"ÂÆåÊàê"&lt;/p&gt; &lt;/li&gt; 
   &lt;/ol&gt; 
   &lt;pre&gt;&lt;code class="language-json"&gt;{
  "message_type": "text",
  "content": {
    "total_titles": "{{ÂÜÖÂÆπ}}",
    "timestamp": "{{ÂÜÖÂÆπ}}",
    "report_type": "{{ÂÜÖÂÆπ}}",
    "text": "{{ÂÜÖÂÆπ}}"
  }
}
&lt;/code&gt;&lt;/pre&gt; 
   &lt;ol start="7"&gt; 
    &lt;li&gt; &lt;p&gt;ÁÇπÂáª"ÈÄâÊã©Êìç‰Ωú" &amp;gt; "ÂèëÈÄÅÈ£û‰π¶Ê∂àÊÅØ"ÔºåÂãæÈÄâ "Áæ§Ê∂àÊÅØ"ÔºåÁÑ∂ÂêéÁÇπÂáª‰∏ãÈù¢ÁöÑËæìÂÖ•Ê°ÜÔºåÁÇπÂáª"ÊàëÁÆ°ÁêÜÁöÑÁæ§ÁªÑ"ÔºàÂ¶ÇÊûúÊ≤°ÊúâÁæ§ÁªÑÔºå‰Ω†ÂèØ‰ª•Âú®È£û‰π¶ app ‰∏äÂàõÂª∫Áæ§ÁªÑÔºâ&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;Ê∂àÊÅØÊ†áÈ¢òÂ°´ÂÜô"TrendRadar ÁÉ≠ÁÇπÁõëÊéß"&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;ÊúÄÂÖ≥ÈîÆÁöÑÈÉ®ÂàÜÊù•‰∫ÜÔºåÁÇπÂáª + ÊåâÈíÆÔºåÈÄâÊã©"Webhook Ëß¶Âèë"ÔºåÁÑ∂ÂêéÊåâÁÖß‰∏ãÈù¢ÁöÑÂõæÁâáÊëÜÊîæ&lt;/p&gt; &lt;/li&gt; 
   &lt;/ol&gt; 
   &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/sansan0/TrendRadar/master/_image/image.png" alt="È£û‰π¶Êú∫Âô®‰∫∫ÈÖçÁΩÆÁ§∫‰æã" /&gt;&lt;/p&gt; 
   &lt;ol start="10"&gt; 
    &lt;li&gt;ÈÖçÁΩÆÂÆåÊàêÂêéÔºåÂ∞ÜÁ¨¨ 5 Ê≠•Â§çÂà∂ÁöÑ Webhook Âú∞ÂùÄÈÖçÁΩÆÂà∞ GitHub Secrets ‰∏≠ÁöÑ &lt;code&gt;FEISHU_WEBHOOK_URL&lt;/code&gt;&lt;/li&gt; 
   &lt;/ol&gt; 
  &lt;/details&gt; 
  &lt;details&gt; 
   &lt;summary&gt; &lt;strong&gt;üëâ ÈíâÈíâÊú∫Âô®‰∫∫&lt;/strong&gt;&lt;/summary&gt; 
   &lt;br /&gt; 
   &lt;p&gt;&lt;strong&gt;GitHub Secret ÈÖçÁΩÆÔºö&lt;/strong&gt;&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;ÂêçÁß∞Ôºö&lt;code&gt;DINGTALK_WEBHOOK_URL&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;ÂÄºÔºö‰Ω†ÁöÑÈíâÈíâÊú∫Âô®‰∫∫ Webhook Âú∞ÂùÄ&lt;/li&gt; 
   &lt;/ul&gt; 
   &lt;p&gt;&lt;strong&gt;Êú∫Âô®‰∫∫ËÆæÁΩÆÊ≠•È™§Ôºö&lt;/strong&gt;&lt;/p&gt; 
   &lt;ol&gt; 
    &lt;li&gt; &lt;p&gt;&lt;strong&gt;ÂàõÂª∫Êú∫Âô®‰∫∫Ôºà‰ªÖ PC Á´ØÊîØÊåÅÔºâ&lt;/strong&gt;Ôºö&lt;/p&gt; 
     &lt;ul&gt; 
      &lt;li&gt;ÊâìÂºÄÈíâÈíâ PC ÂÆ¢Êà∑Á´ØÔºåËøõÂÖ•ÁõÆÊ†áÁæ§ËÅä&lt;/li&gt; 
      &lt;li&gt;ÁÇπÂáªÁæ§ËÆæÁΩÆÂõæÊ†áÔºà‚öôÔ∏èÔºâ‚Üí ÂæÄ‰∏ãÁøªÊâæÂà∞"Êú∫Âô®‰∫∫"ÁÇπÂºÄ&lt;/li&gt; 
      &lt;li&gt;ÈÄâÊã©"Ê∑ªÂä†Êú∫Âô®‰∫∫" ‚Üí "Ëá™ÂÆö‰πâ"&lt;/li&gt; 
     &lt;/ul&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;&lt;strong&gt;ÈÖçÁΩÆÊú∫Âô®‰∫∫&lt;/strong&gt;Ôºö&lt;/p&gt; 
     &lt;ul&gt; 
      &lt;li&gt;ËÆæÁΩÆÊú∫Âô®‰∫∫ÂêçÁß∞&lt;/li&gt; 
      &lt;li&gt;&lt;strong&gt;ÂÆâÂÖ®ËÆæÁΩÆ&lt;/strong&gt;Ôºö 
       &lt;ul&gt; 
        &lt;li&gt;&lt;strong&gt;Ëá™ÂÆö‰πâÂÖ≥ÈîÆËØç&lt;/strong&gt;ÔºöËÆæÁΩÆ "ÁÉ≠ÁÇπ"&lt;/li&gt; 
       &lt;/ul&gt; &lt;/li&gt; 
     &lt;/ul&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;&lt;strong&gt;ÂÆåÊàêËÆæÁΩÆ&lt;/strong&gt;Ôºö&lt;/p&gt; 
     &lt;ul&gt; 
      &lt;li&gt;ÂãæÈÄâÊúçÂä°Êù°Ê¨æÂçèËÆÆ ‚Üí ÁÇπÂáª"ÂÆåÊàê"&lt;/li&gt; 
      &lt;li&gt;Â§çÂà∂Ëé∑ÂæóÁöÑ Webhook URL&lt;/li&gt; 
      &lt;li&gt;Â∞Ü URL ÈÖçÁΩÆÂà∞ GitHub Secrets ‰∏≠ÁöÑ &lt;code&gt;DINGTALK_WEBHOOK_URL&lt;/code&gt;&lt;/li&gt; 
     &lt;/ul&gt; &lt;/li&gt; 
   &lt;/ol&gt; 
   &lt;p&gt;&lt;strong&gt;Ê≥®ÊÑè&lt;/strong&gt;ÔºöÁßªÂä®Á´ØÂè™ËÉΩÊé•Êî∂Ê∂àÊÅØÔºåÊó†Ê≥ïÂàõÂª∫Êñ∞Êú∫Âô®‰∫∫„ÄÇ&lt;/p&gt; 
  &lt;/details&gt; 
  &lt;details&gt; 
   &lt;summary&gt; &lt;strong&gt;üëâ Telegram Bot&lt;/strong&gt;&lt;/summary&gt; 
   &lt;br /&gt; 
   &lt;p&gt;&lt;strong&gt;GitHub Secret ÈÖçÁΩÆÔºö&lt;/strong&gt;&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;ÂêçÁß∞Ôºö&lt;code&gt;TELEGRAM_BOT_TOKEN&lt;/code&gt; - ‰Ω†ÁöÑ Telegram Bot Token&lt;/li&gt; 
    &lt;li&gt;ÂêçÁß∞Ôºö&lt;code&gt;TELEGRAM_CHAT_ID&lt;/code&gt; - ‰Ω†ÁöÑ Telegram Chat ID&lt;/li&gt; 
   &lt;/ul&gt; 
   &lt;p&gt;&lt;strong&gt;Êú∫Âô®‰∫∫ËÆæÁΩÆÊ≠•È™§Ôºö&lt;/strong&gt;&lt;/p&gt; 
   &lt;ol&gt; 
    &lt;li&gt; &lt;p&gt;&lt;strong&gt;ÂàõÂª∫Êú∫Âô®‰∫∫&lt;/strong&gt;Ôºö&lt;/p&gt; 
     &lt;ul&gt; 
      &lt;li&gt;Âú® Telegram ‰∏≠ÊêúÁ¥¢ &lt;code&gt;@BotFather&lt;/code&gt;ÔºàÂ§ßÂ∞èÂÜôÊ≥®ÊÑèÔºåÊúâËìùËâ≤ÂæΩÁ´†ÂãæÂãæÔºåÊúâÁ±ª‰ºº 37849827 monthly usersÔºåËøô‰∏™ÊâçÊòØÂÆòÊñπÁöÑÔºåÊúâ‰∏Ä‰∫õ‰ªøÂÆòÊñπÁöÑË¥¶Âè∑Ê≥®ÊÑèËæ®Âà´Ôºâ&lt;/li&gt; 
      &lt;li&gt;ÂèëÈÄÅ &lt;code&gt;/newbot&lt;/code&gt; ÂëΩ‰ª§ÂàõÂª∫Êñ∞Êú∫Âô®‰∫∫&lt;/li&gt; 
      &lt;li&gt;ËÆæÁΩÆÊú∫Âô®‰∫∫ÂêçÁß∞ÔºàÂøÖÈ°ª‰ª•"bot"ÁªìÂ∞æÔºåÂæàÂÆπÊòìÈÅáÂà∞ÈáçÂ§çÂêçÂ≠óÔºåÊâÄ‰ª•‰Ω†Ë¶ÅÁªûÂ∞ΩËÑëÊ±ÅÊÉ≥‰∏çÂêåÁöÑÂêçÂ≠óÔºâ&lt;/li&gt; 
      &lt;li&gt;Ëé∑Âèñ Bot TokenÔºàÊ†ºÂºèÂ¶ÇÔºö&lt;code&gt;123456789:AAHfiqksKZ8WmR2zSjiQ7_v4TMAKdiHm9T0&lt;/code&gt;Ôºâ&lt;/li&gt; 
     &lt;/ul&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;&lt;strong&gt;Ëé∑Âèñ Chat ID&lt;/strong&gt;Ôºö&lt;/p&gt; &lt;p&gt;&lt;strong&gt;ÊñπÊ≥ï‰∏ÄÔºöÈÄöËøáÂÆòÊñπ API Ëé∑Âèñ&lt;/strong&gt;&lt;/p&gt; 
     &lt;ul&gt; 
      &lt;li&gt;ÂÖàÂêë‰Ω†ÁöÑÊú∫Âô®‰∫∫ÂèëÈÄÅ‰∏ÄÊù°Ê∂àÊÅØ&lt;/li&gt; 
      &lt;li&gt;ËÆøÈóÆÔºö&lt;code&gt;https://api.telegram.org/bot&amp;lt;‰Ω†ÁöÑBot Token&amp;gt;/getUpdates&lt;/code&gt;&lt;/li&gt; 
      &lt;li&gt;Âú®ËøîÂõûÁöÑ JSON ‰∏≠ÊâæÂà∞ &lt;code&gt;"chat":{"id":Êï∞Â≠ó}&lt;/code&gt; ‰∏≠ÁöÑÊï∞Â≠ó&lt;/li&gt; 
     &lt;/ul&gt; &lt;p&gt;&lt;strong&gt;ÊñπÊ≥ï‰∫åÔºö‰ΩøÁî®Á¨¨‰∏âÊñπÂ∑•ÂÖ∑&lt;/strong&gt;&lt;/p&gt; 
     &lt;ul&gt; 
      &lt;li&gt;ÊêúÁ¥¢ &lt;code&gt;@userinfobot&lt;/code&gt; Âπ∂ÂèëÈÄÅ &lt;code&gt;/start&lt;/code&gt;&lt;/li&gt; 
      &lt;li&gt;Ëé∑Âèñ‰Ω†ÁöÑÁî®Êà∑ ID ‰Ωú‰∏∫ Chat ID&lt;/li&gt; 
     &lt;/ul&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;&lt;strong&gt;ÈÖçÁΩÆÂà∞ GitHub&lt;/strong&gt;Ôºö&lt;/p&gt; 
     &lt;ul&gt; 
      &lt;li&gt;&lt;code&gt;TELEGRAM_BOT_TOKEN&lt;/code&gt;ÔºöÂ°´ÂÖ•Á¨¨ 1 Ê≠•Ëé∑ÂæóÁöÑ Bot Token&lt;/li&gt; 
      &lt;li&gt;&lt;code&gt;TELEGRAM_CHAT_ID&lt;/code&gt;ÔºöÂ°´ÂÖ•Á¨¨ 2 Ê≠•Ëé∑ÂæóÁöÑ Chat ID&lt;/li&gt; 
     &lt;/ul&gt; &lt;/li&gt; 
   &lt;/ol&gt; 
  &lt;/details&gt; 
  &lt;details&gt; 
   &lt;summary&gt; &lt;strong&gt;üëâ ÈÇÆ‰ª∂Êé®ÈÄÅ&lt;/strong&gt;ÔºàÊîØÊåÅÊâÄÊúâ‰∏ªÊµÅÈÇÆÁÆ±Ôºâ&lt;/summary&gt; 
   &lt;br /&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Ê≥®ÊÑè‰∫ãÈ°πÔºö‰∏∫Èò≤Ê≠¢ÈÇÆ‰ª∂Áæ§ÂèëÂäüËÉΩË¢´&lt;strong&gt;Êª•Áî®&lt;/strong&gt;ÔºåÂΩìÂâçÁöÑÁæ§ÂèëÊòØÊâÄÊúâÊî∂‰ª∂‰∫∫ÈÉΩËÉΩÁúãÂà∞ÂΩºÊ≠§ÁöÑÈÇÆÁÆ±Âú∞ÂùÄÔºåÈÄÇÂêàÁÜü‰∫∫Èó¥‰∫§ÊµÅËµÑËÆØ„ÄÇ&lt;/li&gt; 
    &lt;li&gt;‰ªÖ‰æõÂèÇËÄÉÔºöËØ∑Ê†πÊçÆÂÆûÈôÖÊÉÖÂÜµË∞ÉÊï¥ÔºåÈÇÆÁÆ±ÊñπÈù¢Âπ∂Ê≤°Êúâ‰∏Ä‰∏ÄÈ™åËØÅÔºåÊòØÊåâÁÖß SMTP ÁöÑÊ†áÂáÜÈÖçÁΩÆÁöÑ&lt;/li&gt; 
   &lt;/ul&gt; 
   &lt;p&gt;&lt;strong&gt;GitHub Secret ÈÖçÁΩÆÔºö&lt;/strong&gt;&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;ÂêçÁß∞Ôºö&lt;code&gt;EMAIL_FROM&lt;/code&gt; - Âèë‰ª∂‰∫∫ÈÇÆÁÆ±Âú∞ÂùÄ&lt;/li&gt; 
    &lt;li&gt;ÂêçÁß∞Ôºö&lt;code&gt;EMAIL_PASSWORD&lt;/code&gt; - ÈÇÆÁÆ±ÂØÜÁ†ÅÊàñÊéàÊùÉÁ†Å&lt;/li&gt; 
    &lt;li&gt;ÂêçÁß∞Ôºö&lt;code&gt;EMAIL_TO&lt;/code&gt; - Êî∂‰ª∂‰∫∫ÈÇÆÁÆ±Âú∞ÂùÄÔºàÂ§ö‰∏™Êî∂‰ª∂‰∫∫Áî®Ëã±ÊñáÈÄóÂè∑ÂàÜÈöîÔºâ‰πüÂèØ‰ª•Âíå EMAIL_FROM ‰∏ÄÊ†∑ÔºåËá™Â∑±ÂèëÈÄÅÁªôËá™Â∑±&lt;/li&gt; 
    &lt;li&gt;ÂêçÁß∞Ôºö&lt;code&gt;EMAIL_SMTP_SERVER&lt;/code&gt; - SMTPÊúçÂä°Âô®Âú∞ÂùÄÔºàÂèØÈÄâÔºåÁïôÁ©∫ÂàôËá™Âä®ËØÜÂà´Ôºâ&lt;/li&gt; 
    &lt;li&gt;ÂêçÁß∞Ôºö&lt;code&gt;EMAIL_SMTP_PORT&lt;/code&gt; - SMTPÁ´ØÂè£ÔºàÂèØÈÄâÔºåÁïôÁ©∫ÂàôËá™Âä®ËØÜÂà´Ôºâ&lt;/li&gt; 
   &lt;/ul&gt; 
   &lt;p&gt;&lt;strong&gt;Â∏∏ËßÅÈÇÆÁÆ±ËÆæÁΩÆÔºö&lt;/strong&gt;&lt;/p&gt; 
   &lt;h4&gt;QQÈÇÆÁÆ±Ôºö&lt;/h4&gt; 
   &lt;ol&gt; 
    &lt;li&gt;ÁôªÂΩï QQÈÇÆÁÆ±ÁΩëÈ°µÁâà ‚Üí ËÆæÁΩÆ ‚Üí Ë¥¶Êà∑&lt;/li&gt; 
    &lt;li&gt;ÂºÄÂêØ POP3/SMTP ÊúçÂä°&lt;/li&gt; 
    &lt;li&gt;ÁîüÊàêÊéàÊùÉÁ†ÅÔºà16‰ΩçÂ≠óÊØçÔºâ&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;EMAIL_PASSWORD&lt;/code&gt; Â°´ÂÜôÊéàÊùÉÁ†ÅÔºåËÄåÈùû QQ ÂØÜÁ†Å&lt;/li&gt; 
   &lt;/ol&gt; 
   &lt;h4&gt;GmailÔºö&lt;/h4&gt; 
   &lt;ol&gt; 
    &lt;li&gt;ÂºÄÂêØ‰∏§Ê≠•È™åËØÅ&lt;/li&gt; 
    &lt;li&gt;ÁîüÊàêÂ∫îÁî®‰∏ìÁî®ÂØÜÁ†Å&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;EMAIL_PASSWORD&lt;/code&gt; Â°´ÂÜôÂ∫îÁî®‰∏ìÁî®ÂØÜÁ†Å&lt;/li&gt; 
   &lt;/ol&gt; 
   &lt;h4&gt;163/126ÈÇÆÁÆ±Ôºö&lt;/h4&gt; 
   &lt;ol&gt; 
    &lt;li&gt;ÁôªÂΩïÁΩëÈ°µÁâà ‚Üí ËÆæÁΩÆ ‚Üí POP3/SMTP/IMAP&lt;/li&gt; 
    &lt;li&gt;ÂºÄÂêØ SMTP ÊúçÂä°&lt;/li&gt; 
    &lt;li&gt;ËÆæÁΩÆÂÆ¢Êà∑Á´ØÊéàÊùÉÁ†Å&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;EMAIL_PASSWORD&lt;/code&gt; Â°´ÂÜôÊéàÊùÉÁ†Å&lt;/li&gt; 
   &lt;/ol&gt; 
   &lt;br /&gt; 
   &lt;p&gt;&lt;strong&gt;È´òÁ∫ßÈÖçÁΩÆ&lt;/strong&gt;Ôºö Â¶ÇÊûúËá™Âä®ËØÜÂà´Â§±Ë¥•ÔºåÂèØÊâãÂä®ÈÖçÁΩÆ SMTPÔºö&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;code&gt;EMAIL_SMTP_SERVER&lt;/code&gt;ÔºöÂ¶Ç smtp.gmail.com&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;EMAIL_SMTP_PORT&lt;/code&gt;ÔºöÂ¶Ç 587ÔºàTLSÔºâÊàñ 465ÔºàSSLÔºâ&lt;/li&gt; 
   &lt;/ul&gt; 
   &lt;br /&gt; 
   &lt;p&gt;&lt;strong&gt;Â§öÊî∂‰ª∂‰∫∫ËÆæÁΩÆ&lt;/strong&gt;Ôºö&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;EMAIL_TO="&lt;a href="mailto:user1@example.com"&gt;user1@example.com&lt;/a&gt;,&lt;a href="mailto:user2@example.com"&gt;user2@example.com&lt;/a&gt;,&lt;a href="mailto:user3@example.com"&gt;user3@example.com&lt;/a&gt;"&lt;/li&gt; 
   &lt;/ul&gt; 
  &lt;/details&gt; 
  &lt;details&gt; 
   &lt;summary&gt; &lt;strong&gt;üëâ ntfy Êé®ÈÄÅ&lt;/strong&gt;ÔºàÂºÄÊ∫êÂÖçË¥πÔºåÊîØÊåÅËá™ÊâòÁÆ°Ôºâ&lt;/summary&gt; 
   &lt;br /&gt; 
   &lt;p&gt;&lt;strong&gt;‰∏§Áßç‰ΩøÁî®ÊñπÂºèÔºö&lt;/strong&gt;&lt;/p&gt; 
   &lt;h3&gt;ÊñπÂºè‰∏ÄÔºöÂÖçË¥π‰ΩøÁî®ÔºàÊé®ËçêÊñ∞ÊâãÔºâ üÜì&lt;/h3&gt; 
   &lt;p&gt;&lt;strong&gt;ÁâπÁÇπ&lt;/strong&gt;Ôºö&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;‚úÖ Êó†ÈúÄÊ≥®ÂÜåË¥¶Âè∑ÔºåÁ´ãÂç≥‰ΩøÁî®&lt;/li&gt; 
    &lt;li&gt;‚úÖ ÊØèÂ§© 250 Êù°Ê∂àÊÅØÔºàË∂≥Â§ü 90% Áî®Êà∑Ôºâ&lt;/li&gt; 
    &lt;li&gt;‚úÖ Topic ÂêçÁß∞Âç≥"ÂØÜÁ†Å"ÔºàÈúÄÈÄâÊã©‰∏çÊòìÁåúÊµãÁöÑÂêçÁß∞Ôºâ&lt;/li&gt; 
    &lt;li&gt;‚ö†Ô∏è Ê∂àÊÅØÊú™Âä†ÂØÜÔºå‰∏çÈÄÇÂêàÊïèÊÑü‰ø°ÊÅØ, ‰ΩÜÈÄÇÂêàÊàë‰ª¨Ëøô‰∏™È°πÁõÆÁöÑ‰∏çÊïèÊÑü‰ø°ÊÅØ&lt;/li&gt; 
   &lt;/ul&gt; 
   &lt;p&gt;&lt;strong&gt;Âø´ÈÄüÂºÄÂßãÔºö&lt;/strong&gt;&lt;/p&gt; 
   &lt;ol&gt; 
    &lt;li&gt; &lt;p&gt;&lt;strong&gt;‰∏ãËΩΩ ntfy Â∫îÁî®&lt;/strong&gt;Ôºö&lt;/p&gt; 
     &lt;ul&gt; 
      &lt;li&gt;AndroidÔºö&lt;a href="https://play.google.com/store/apps/details?id=io.heckel.ntfy"&gt;Google Play&lt;/a&gt; / &lt;a href="https://f-droid.org/en/packages/io.heckel.ntfy/"&gt;F-Droid&lt;/a&gt;&lt;/li&gt; 
      &lt;li&gt;iOSÔºö&lt;a href="https://apps.apple.com/us/app/ntfy/id1625396347"&gt;App Store&lt;/a&gt;&lt;/li&gt; 
      &lt;li&gt;Ê°åÈù¢ÔºöËÆøÈóÆ &lt;a href="https://ntfy.sh"&gt;ntfy.sh&lt;/a&gt;&lt;/li&gt; 
     &lt;/ul&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;&lt;strong&gt;ËÆ¢ÈòÖ‰∏ªÈ¢ò&lt;/strong&gt;ÔºàÈÄâÊã©‰∏Ä‰∏™ÈöæÁåúÁöÑÂêçÁß∞ÔºâÔºö&lt;/p&gt; &lt;pre&gt;&lt;code&gt;Âª∫ËÆÆÊ†ºÂºèÔºötrendradar-{‰Ω†ÁöÑÂêçÂ≠óÁº©ÂÜô}-{ÈöèÊú∫Êï∞Â≠ó}

‰∏çËÉΩ‰ΩøÁî®‰∏≠Êñá

‚úÖ Â•Ω‰æãÂ≠êÔºötrendradar-zs-8492
‚ùå Âùè‰æãÂ≠êÔºönews„ÄÅalertsÔºàÂ§™ÂÆπÊòìË¢´ÁåúÂà∞Ôºâ
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;&lt;strong&gt;ÈÖçÁΩÆ GitHub Secret&lt;/strong&gt;Ôºö&lt;/p&gt; 
     &lt;ul&gt; 
      &lt;li&gt;&lt;code&gt;NTFY_TOPIC&lt;/code&gt;ÔºöÂ°´ÂÜô‰Ω†ÂàöÊâçËÆ¢ÈòÖÁöÑ‰∏ªÈ¢òÂêçÁß∞&lt;/li&gt; 
      &lt;li&gt;&lt;code&gt;NTFY_SERVER_URL&lt;/code&gt;ÔºöÁïôÁ©∫ÔºàÈªòËÆ§‰ΩøÁî® ntfy.shÔºâ&lt;/li&gt; 
      &lt;li&gt;&lt;code&gt;NTFY_TOKEN&lt;/code&gt;ÔºöÁïôÁ©∫&lt;/li&gt; 
     &lt;/ul&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;&lt;strong&gt;ÊµãËØï&lt;/strong&gt;Ôºö&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;curl -d "ÊµãËØïÊ∂àÊÅØ" ntfy.sh/‰Ω†ÁöÑ‰∏ªÈ¢òÂêçÁß∞
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
   &lt;/ol&gt; 
   &lt;hr /&gt; 
   &lt;h3&gt;ÊñπÂºè‰∫åÔºöËá™ÊâòÁÆ°ÔºàÂÆåÂÖ®ÈöêÁßÅÊéßÂà∂Ôºâ üîí&lt;/h3&gt; 
   &lt;p&gt;&lt;strong&gt;ÈÄÇÂêà‰∫∫Áæ§&lt;/strong&gt;ÔºöÊúâÊúçÂä°Âô®„ÄÅËøΩÊ±ÇÂÆåÂÖ®ÈöêÁßÅ„ÄÅÊäÄÊúØËÉΩÂäõÂº∫&lt;/p&gt; 
   &lt;p&gt;&lt;strong&gt;‰ºòÂäø&lt;/strong&gt;Ôºö&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;‚úÖ ÂÆåÂÖ®ÂºÄÊ∫êÔºàApache 2.0 + GPLv2Ôºâ&lt;/li&gt; 
    &lt;li&gt;‚úÖ Êï∞ÊçÆÂÆåÂÖ®Ëá™‰∏ªÊéßÂà∂&lt;/li&gt; 
    &lt;li&gt;‚úÖ Êó†‰ªª‰ΩïÈôêÂà∂&lt;/li&gt; 
    &lt;li&gt;‚úÖ Èõ∂Ë¥πÁî®&lt;/li&gt; 
   &lt;/ul&gt; 
   &lt;p&gt;&lt;strong&gt;Docker ‰∏ÄÈîÆÈÉ®ÁΩ≤&lt;/strong&gt;Ôºö&lt;/p&gt; 
   &lt;pre&gt;&lt;code class="language-bash"&gt;docker run -d \
  --name ntfy \
  -p 80:80 \
  -v /var/cache/ntfy:/var/cache/ntfy \
  binwiederhier/ntfy \
  serve --cache-file /var/cache/ntfy/cache.db
&lt;/code&gt;&lt;/pre&gt; 
   &lt;p&gt;&lt;strong&gt;ÈÖçÁΩÆ TrendRadar&lt;/strong&gt;Ôºö&lt;/p&gt; 
   &lt;pre&gt;&lt;code class="language-yaml"&gt;NTFY_SERVER_URL: https://ntfy.yourdomain.com
NTFY_TOPIC: trendradar-alerts  # Ëá™ÊâòÁÆ°ÂèØÁî®ÁÆÄÂçïÂêçÁß∞
NTFY_TOKEN: tk_your_token  # ÂèØÈÄâÔºöÂêØÁî®ËÆøÈóÆÊéßÂà∂
&lt;/code&gt;&lt;/pre&gt; 
   &lt;p&gt;&lt;strong&gt;Âú®Â∫îÁî®‰∏≠ËÆ¢ÈòÖ&lt;/strong&gt;Ôºö&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;ÁÇπÂáª"Use another server"&lt;/li&gt; 
    &lt;li&gt;ËæìÂÖ•‰Ω†ÁöÑÊúçÂä°Âô®Âú∞ÂùÄ&lt;/li&gt; 
    &lt;li&gt;ËæìÂÖ•‰∏ªÈ¢òÂêçÁß∞&lt;/li&gt; 
    &lt;li&gt;ÔºàÂèØÈÄâÔºâËæìÂÖ•ÁôªÂΩïÂá≠ÊçÆ&lt;/li&gt; 
   &lt;/ul&gt; 
   &lt;hr /&gt; 
   &lt;p&gt;&lt;strong&gt;Â∏∏ËßÅÈóÆÈ¢òÔºö&lt;/strong&gt;&lt;/p&gt; 
   &lt;details&gt; 
    &lt;summary&gt;&lt;strong&gt;Q1: ÂÖçË¥πÁâàÂ§üÁî®ÂêóÔºü&lt;/strong&gt;&lt;/summary&gt; 
    &lt;p&gt;ÊØèÂ§© 250 Êù°Ê∂àÊÅØÂØπÂ§ßÂ§öÊï∞Áî®Êà∑Ë∂≥Â§ü„ÄÇÊåâ 30 ÂàÜÈíüÊäìÂèñ‰∏ÄÊ¨°ËÆ°ÁÆóÔºåÊØèÂ§©Á∫¶ 48 Ê¨°Êé®ÈÄÅÔºåÂÆåÂÖ®Â§üÁî®„ÄÇ&lt;/p&gt; 
   &lt;/details&gt; 
   &lt;details&gt; 
    &lt;summary&gt;&lt;strong&gt;Q2: Topic ÂêçÁß∞ÁúüÁöÑÂÆâÂÖ®ÂêóÔºü&lt;/strong&gt;&lt;/summary&gt; 
    &lt;p&gt;Â¶ÇÊûú‰Ω†ÈÄâÊã©ÈöèÊú∫ÁöÑ„ÄÅË∂≥Â§üÈïøÁöÑÂêçÁß∞ÔºàÂ¶Ç &lt;code&gt;trendradar-zs-8492-news&lt;/code&gt;ÔºâÔºåÊö¥ÂäõÁ†¥Ëß£Âá†‰πé‰∏çÂèØËÉΩÔºö&lt;/p&gt; 
    &lt;ul&gt; 
     &lt;li&gt;ntfy Êúâ‰∏•Ê†ºÁöÑÈÄüÁéáÈôêÂà∂Ôºà1 Áßí 1 Ê¨°ËØ∑Ê±ÇÔºâ&lt;/li&gt; 
     &lt;li&gt;64 ‰∏™Â≠óÁ¨¶ÈÄâÊã©ÔºàA-Z, a-z, 0-9, _, -Ôºâ&lt;/li&gt; 
     &lt;li&gt;10 ‰ΩçÈöèÊú∫Â≠óÁ¨¶‰∏≤Êúâ 64^10 ÁßçÂèØËÉΩÊÄßÔºàÈúÄË¶ÅÊï∞Âπ¥ÊâçËÉΩÁ†¥Ëß£Ôºâ&lt;/li&gt; 
    &lt;/ul&gt; 
   &lt;/details&gt; 
   &lt;hr /&gt; 
   &lt;p&gt;&lt;strong&gt;Êé®ËçêÈÄâÊã©Ôºö&lt;/strong&gt;&lt;/p&gt; 
   &lt;table&gt; 
    &lt;thead&gt; 
     &lt;tr&gt; 
      &lt;th&gt;Áî®Êà∑Á±ªÂûã&lt;/th&gt; 
      &lt;th&gt;Êé®ËçêÊñπÊ°à&lt;/th&gt; 
      &lt;th&gt;ÁêÜÁî±&lt;/th&gt; 
     &lt;/tr&gt; 
    &lt;/thead&gt; 
    &lt;tbody&gt; 
     &lt;tr&gt; 
      &lt;td&gt;ÊôÆÈÄöÁî®Êà∑&lt;/td&gt; 
      &lt;td&gt;ÊñπÂºè‰∏ÄÔºàÂÖçË¥πÔºâ&lt;/td&gt; 
      &lt;td&gt;ÁÆÄÂçïÂø´ÈÄüÔºåÂ§üÁî®&lt;/td&gt; 
     &lt;/tr&gt; 
     &lt;tr&gt; 
      &lt;td&gt;ÊäÄÊúØÁî®Êà∑&lt;/td&gt; 
      &lt;td&gt;ÊñπÂºè‰∫åÔºàËá™ÊâòÁÆ°Ôºâ&lt;/td&gt; 
      &lt;td&gt;ÂÆåÂÖ®ÊéßÂà∂ÔºåÊó†ÈôêÂà∂&lt;/td&gt; 
     &lt;/tr&gt; 
     &lt;tr&gt; 
      &lt;td&gt;È´òÈ¢ëÁî®Êà∑&lt;/td&gt; 
      &lt;td&gt;ÊñπÂºè‰∏âÔºà‰ªòË¥πÔºâ&lt;/td&gt; 
      &lt;td&gt;Ëøô‰∏™Ëá™Â∑±ÂéªÂÆòÁΩëÁúãÂêß&lt;/td&gt; 
     &lt;/tr&gt; 
    &lt;/tbody&gt; 
   &lt;/table&gt; 
   &lt;p&gt;&lt;strong&gt;Áõ∏ÂÖ≥ÈìæÊé•Ôºö&lt;/strong&gt;&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;a href="https://docs.ntfy.sh/"&gt;ntfy ÂÆòÊñπÊñáÊ°£&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://docs.ntfy.sh/install/"&gt;Ëá™ÊâòÁÆ°ÊïôÁ®ã&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://github.com/binwiederhier/ntfy"&gt;GitHub ‰ªìÂ∫ì&lt;/a&gt;&lt;/li&gt; 
   &lt;/ul&gt; 
  &lt;/details&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;ÈÖçÁΩÆËØ¥ÊòéÔºö&lt;/strong&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Êé®ÈÄÅËÆæÁΩÆ&lt;/strong&gt;ÔºöÂú® &lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/config/config.yaml"&gt;config/config.yaml&lt;/a&gt; ‰∏≠ÈÖçÁΩÆÊé®ÈÄÅÊ®°ÂºèÂíåÈÄöÁü•ÈÄâÈ°π&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;ÂÖ≥ÈîÆËØçËÆæÁΩÆ&lt;/strong&gt;ÔºöÂú® &lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/config/frequency_words.txt"&gt;config/frequency_words.txt&lt;/a&gt; ‰∏≠Ê∑ªÂä†‰Ω†ÂÖ≥ÂøÉÁöÑÂÖ≥ÈîÆËØç&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Êé®ÈÄÅÈ¢ëÁéáË∞ÉÊï¥&lt;/strong&gt;ÔºöÂú® &lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/.github/workflows/crawler.yml"&gt;.github/workflows/crawler.yml&lt;/a&gt; ËØ∑Ë∞®ÊÖéË∞ÉÊï¥ÔºåÂà´Ë¥™ÂøÉ&lt;/li&gt; 
  &lt;/ul&gt; &lt;p&gt;&lt;strong&gt;Ê≥®ÊÑè&lt;/strong&gt;ÔºöÂª∫ËÆÆÂè™Ë∞ÉÊï¥ÊñáÊ°£‰∏≠ÊòéÁ°ÆËØ¥ÊòéÁöÑÈÖçÁΩÆÈ°πÔºåÂÖ∂‰ªñÈÄâÈ°π‰∏ªË¶Å‰æõ‰ΩúËÄÖÂºÄÂèëÊó∂ÊµãËØï‰ΩøÁî®&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;ÊâãÂä®ÊµãËØïÊñ∞ÈóªÊé®ÈÄÅ&lt;/strong&gt;Ôºö&lt;/p&gt; &lt;p&gt;ÊàëËøôÈáåÊòØÊãøÊàëÁöÑÈ°πÁõÆ‰∏æ‰æãÔºå‰Ω†Ë¶ÅÂéª‰Ω†&lt;strong&gt;fork&lt;/strong&gt;ÁöÑÈ°πÁõÆÂÅöÊµãËØï&lt;/p&gt; 
  &lt;ol&gt; 
   &lt;li&gt;&lt;strong&gt;ËøõÂÖ• Actions&lt;/strong&gt;Ôºö&lt;a href="https://github.com/sansan0/TrendRadar/actions"&gt;https://github.com/sansan0/TrendRadar/actions&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;ÊâæÂà∞ "Hot News Crawler" ÁöÑÁÇπËøõÂéªÔºåÂ¶ÇÊûúÁúã‰∏çÂà∞ËØ•Â≠óÊ†∑ÔºåÈÇ£‰πàÂèÇÁÖß&lt;a href="https://github.com/sansan0/TrendRadar/issues/109"&gt;#109&lt;/a&gt;Ëß£ÂÜ≥&lt;/li&gt; 
   &lt;li&gt;ÁÇπÂáª "Run workflow" ÊåâÈíÆËøêË°åÔºåÁ≠âÂæÖ 1 ÂàÜÈíüÂ∑¶Âè≥Êï∞ÊçÆÂà∞‰Ω†ÊâãÊú∫‰∏ä&lt;/li&gt; 
  &lt;/ol&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;üê≥ Docker ÈÉ®ÁΩ≤&lt;/h2&gt; 
&lt;h4&gt;ÊñπÂºè‰∏ÄÔºöÂø´ÈÄü‰ΩìÈ™åÔºà‰∏ÄË°åÂëΩ‰ª§Ôºâ&lt;/h4&gt; 
&lt;p&gt;&lt;strong&gt;Linux/macOS Á≥ªÁªüÔºö&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# ÂàõÂª∫ÈÖçÁΩÆÁõÆÂΩïÂπ∂‰∏ãËΩΩÈÖçÁΩÆÊñá‰ª∂
mkdir -p config output
wget https://raw.githubusercontent.com/sansan0/TrendRadar/master/config/config.yaml -P config/
wget https://raw.githubusercontent.com/sansan0/TrendRadar/master/config/frequency_words.txt -P config/
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;ÊàñËÄÖ&lt;strong&gt;ÊâãÂä®ÂàõÂª∫&lt;/strong&gt;Ôºö&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Âú®ÂΩìÂâçÁõÆÂΩïÂàõÂª∫ &lt;code&gt;config&lt;/code&gt; Êñá‰ª∂Â§π&lt;/li&gt; 
 &lt;li&gt;‰∏ãËΩΩÈÖçÁΩÆÊñá‰ª∂Ôºö 
  &lt;ul&gt; 
   &lt;li&gt;ËÆøÈóÆ &lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/config/config.yaml"&gt;https://raw.githubusercontent.com/sansan0/TrendRadar/master/config/config.yaml&lt;/a&gt; ‚Üí Âè≥ÈîÆ"Âè¶Â≠ò‰∏∫" ‚Üí ‰øùÂ≠òÂà∞ &lt;code&gt;config\config.yaml&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;ËÆøÈóÆ &lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/config/frequency_words.txt"&gt;https://raw.githubusercontent.com/sansan0/TrendRadar/master/config/frequency_words.txt&lt;/a&gt; ‚Üí Âè≥ÈîÆ"Âè¶Â≠ò‰∏∫" ‚Üí ‰øùÂ≠òÂà∞ &lt;code&gt;config\frequency_words.txt&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;ÂÆåÊàêÂêéÁöÑÁõÆÂΩïÁªìÊûÑÂ∫îËØ•ÊòØÔºö&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;ÂΩìÂâçÁõÆÂΩï/
‚îî‚îÄ‚îÄ config/
    ‚îú‚îÄ‚îÄ config.yaml
    ‚îî‚îÄ‚îÄ frequency_words.txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run -d --name trend-radar \
  -v ./config:/app/config:ro \
  -v ./output:/app/output \
  -e FEISHU_WEBHOOK_URL="‰Ω†ÁöÑÈ£û‰π¶webhook" \
  -e DINGTALK_WEBHOOK_URL="‰Ω†ÁöÑÈíâÈíâwebhook" \
  -e WEWORK_WEBHOOK_URL="‰Ω†ÁöÑ‰ºÅ‰∏öÂæÆ‰ø°webhook" \
  -e TELEGRAM_BOT_TOKEN="‰Ω†ÁöÑtelegram_bot_token" \
  -e TELEGRAM_CHAT_ID="‰Ω†ÁöÑtelegram_chat_id" \
  -e EMAIL_FROM="‰Ω†ÁöÑÂèë‰ª∂ÈÇÆÁÆ±" \
  -e EMAIL_PASSWORD="‰Ω†ÁöÑÈÇÆÁÆ±ÂØÜÁ†ÅÊàñÊéàÊùÉÁ†Å" \
  -e EMAIL_TO="Êî∂‰ª∂‰∫∫ÈÇÆÁÆ±" \
  -e CRON_SCHEDULE="*/30 * * * *" \
  -e RUN_MODE="cron" \
  -e IMMEDIATE_RUN="true" \
  wantcat/trendradar:latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;ÊñπÂºè‰∫åÔºö‰ΩøÁî® docker-composeÔºàÊé®ËçêÔºâ&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;ÂàõÂª∫È°πÁõÆÁõÆÂΩïÂíåÈÖçÁΩÆ&lt;/strong&gt;: &lt;pre&gt;&lt;code class="language-bash"&gt;# ÂàõÂª∫ÁõÆÂΩïÁªìÊûÑ
mkdir -p trendradar/{config,docker}
cd trendradar

# ‰∏ãËΩΩÈÖçÁΩÆÊñá‰ª∂Ê®°Êùø
wget https://raw.githubusercontent.com/sansan0/TrendRadar/master/config/config.yaml -P config/
wget https://raw.githubusercontent.com/sansan0/TrendRadar/master/config/frequency_words.txt -P config/

# ‰∏ãËΩΩ docker-compose ÈÖçÁΩÆ
wget https://raw.githubusercontent.com/sansan0/TrendRadar/master/docker/.env
wget https://raw.githubusercontent.com/sansan0/TrendRadar/master/docker/docker-compose.yml
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;ÂÆåÊàêÂêéÁöÑÁõÆÂΩïÁªìÊûÑÂ∫îËØ•ÊòØÔºö&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;ÂΩìÂâçÁõÆÂΩï/
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îú‚îÄ‚îÄ config.yaml
‚îÇ   ‚îî‚îÄ‚îÄ frequency_words.txt
‚îî‚îÄ‚îÄ docker/
    ‚îú‚îÄ‚îÄ .env
    ‚îî‚îÄ‚îÄ docker-compose.yml
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;ÈÖçÁΩÆÊñá‰ª∂ËØ¥Êòé&lt;/strong&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;config/config.yaml&lt;/code&gt; - Â∫îÁî®‰∏ªÈÖçÁΩÆÔºàÊä•ÂëäÊ®°Âºè„ÄÅÊé®ÈÄÅËÆæÁΩÆÁ≠âÔºâ&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;config/frequency_words.txt&lt;/code&gt; - ÂÖ≥ÈîÆËØçÈÖçÁΩÆÔºàËÆæÁΩÆ‰Ω†ÂÖ≥ÂøÉÁöÑÁÉ≠ÁÇπËØçÊ±áÔºâ&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;.env&lt;/code&gt; - ÁéØÂ¢ÉÂèòÈáèÈÖçÁΩÆÔºàwebhook URLs ÂíåÂÆöÊó∂‰ªªÂä°Ôºâ&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;ÂêØÂä®ÊúçÂä°&lt;/strong&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;# ÊãâÂèñÊúÄÊñ∞ÈïúÂÉèÂπ∂ÂêØÂä®
docker-compose pull
docker-compose up -d
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Êü•ÁúãËøêË°åÁä∂ÊÄÅ&lt;/strong&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;# Êü•ÁúãÊó•Âøó
docker logs -f trend-radar

# Êü•ÁúãÂÆπÂô®Áä∂ÊÄÅ
docker ps | grep trend-radar
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;ÊñπÂºè‰∏âÔºöÊú¨Âú∞ÊûÑÂª∫ÔºàÂºÄÂèëËÄÖÈÄâÈ°πÔºâ&lt;/h4&gt; 
&lt;p&gt;Â¶ÇÊûúÈúÄË¶ÅËá™ÂÆö‰πâ‰øÆÊîπ‰ª£Á†ÅÊàñÊûÑÂª∫Ëá™Â∑±ÁöÑÈïúÂÉèÔºö&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# ÂÖãÈöÜÈ°πÁõÆ
git clone https://github.com/sansan0/TrendRadar.git
cd TrendRadar

# ‰øÆÊîπÈÖçÁΩÆÊñá‰ª∂
vim config/config.yaml
vim config/frequency_words.txt

# ‰ΩøÁî®ÊûÑÂª∫ÁâàÊú¨ÁöÑ docker-compose
cd docker
cp docker-compose-build.yml docker-compose.yml

# ÊûÑÂª∫Âπ∂ÂêØÂä®
docker-compose build
docker-compose up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;ÈïúÂÉèÊõ¥Êñ∞&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# ÊñπÂºè‰∏ÄÔºöÊâãÂä®Êõ¥Êñ∞
docker pull wantcat/trendradar:latest
docker-compose down
docker-compose up -d

# ÊñπÂºè‰∫åÔºö‰ΩøÁî® docker-compose Êõ¥Êñ∞
docker-compose pull
docker-compose up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;ÊúçÂä°ÁÆ°ÁêÜÂëΩ‰ª§&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Êü•ÁúãËøêË°åÁä∂ÊÄÅ
docker exec -it trend-radar python manage.py status

# ÊâãÂä®ÊâßË°å‰∏ÄÊ¨°Áà¨Ëô´
docker exec -it trend-radar python manage.py run

# Êü•ÁúãÂÆûÊó∂Êó•Âøó
docker exec -it trend-radar python manage.py logs

# ÊòæÁ§∫ÂΩìÂâçÈÖçÁΩÆ
docker exec -it trend-radar python manage.py config

# ÊòæÁ§∫ËæìÂá∫Êñá‰ª∂
docker exec -it trend-radar python manage.py files

# Êü•ÁúãÂ∏ÆÂä©‰ø°ÊÅØ
docker exec -it trend-radar python manage.py help

# ÈáçÂêØÂÆπÂô®
docker restart trend-radar

# ÂÅúÊ≠¢ÂÆπÂô®
docker stop trend-radar

# Âà†Èô§ÂÆπÂô®Ôºà‰øùÁïôÊï∞ÊçÆÔºâ
docker rm trend-radar
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Êï∞ÊçÆÊåÅ‰πÖÂåñ&lt;/h4&gt; 
&lt;p&gt;ÁîüÊàêÁöÑÊä•ÂëäÂíåÊï∞ÊçÆÈªòËÆ§‰øùÂ≠òÂú® &lt;code&gt;./output&lt;/code&gt; ÁõÆÂΩï‰∏ãÔºåÂç≥‰ΩøÂÆπÂô®ÈáçÂêØÊàñÂà†Èô§ÔºåÊï∞ÊçÆ‰πü‰ºö‰øùÁïô„ÄÇ&lt;/p&gt; 
&lt;h4&gt;ÊïÖÈöúÊéíÊü•&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Ê£ÄÊü•ÂÆπÂô®Áä∂ÊÄÅ
docker inspect trend-radar

# Êü•ÁúãÂÆπÂô®Êó•Âøó
docker logs --tail 100 trend-radar

# ËøõÂÖ•ÂÆπÂô®Ë∞ÉËØï
docker exec -it trend-radar /bin/bash

# È™åËØÅÈÖçÁΩÆÊñá‰ª∂
docker exec -it trend-radar ls -la /app/config/
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;ü§ñ AI Êô∫ËÉΩÂàÜÊûêÈÉ®ÁΩ≤&lt;/h2&gt; 
&lt;p&gt;TrendRadar v3.0.0 Êñ∞Â¢û‰∫ÜÂü∫‰∫é &lt;strong&gt;MCP (Model Context Protocol)&lt;/strong&gt; ÁöÑ AI ÂàÜÊûêÂäüËÉΩÔºåËÆ©‰Ω†ÂèØ‰ª•ÈÄöËøáËá™ÁÑ∂ËØ≠Ë®Ä‰∏éÊñ∞ÈóªÊï∞ÊçÆÂØπËØùÔºåËøõË°åÊ∑±Â∫¶ÂàÜÊûê„ÄÇ‰ΩøÁî® &lt;strong&gt;AI ÂäüËÉΩ&lt;/strong&gt; ÁöÑÊúÄ‰Ω≥ÂâçÊèêÊòØÂ∑≤‰ΩøÁî®Êú¨È°πÁõÆËá≥Â∞ëËøêË°å‰∏ÄÂ§©(ÁßØÁ¥ØÊñ∞ÈóªÊï∞ÊçÆ)&lt;/p&gt; 
&lt;h3&gt;1. Âø´ÈÄüÈÉ®ÁΩ≤&lt;/h3&gt; 
&lt;p&gt;Cherry Studio Êèê‰æõ GUI ÈÖçÁΩÆÁïåÈù¢Ôºå 5 ÂàÜÈíüÂø´ÈÄüÈÉ®ÁΩ≤Ôºå Â§çÊùÇÁöÑÈÉ®ÂàÜÊòØ‰∏ÄÈîÆÂÆâË£ÖÁöÑ„ÄÇ&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;ÂõæÊñáÈÉ®ÁΩ≤ÊïôÁ®ã&lt;/strong&gt;ÔºöÁé∞Â∑≤Êõ¥Êñ∞Âà∞ÊàëÁöÑ&lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/#%E9%97%AE%E9%A2%98%E7%AD%94%E7%96%91%E4%B8%8E1%E5%85%83%E7%82%B9%E8%B5%9E"&gt;ÂÖ¨‰ºóÂè∑&lt;/a&gt;ÔºåÂõûÂ§ç "mcp" Âç≥ÂèØ&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;ËØ¶ÁªÜÈÉ®ÁΩ≤ÊïôÁ®ã&lt;/strong&gt;Ôºö&lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/README-Cherry-Studio.md"&gt;README-Cherry-Studio.md&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;2. Â≠¶‰π†‰∏é AI ÂØπËØùÁöÑÂßøÂäø&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;ËØ¶ÁªÜÂØπËØùÊïôÁ®ã&lt;/strong&gt;Ôºö&lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/README-MCP-FAQ.md"&gt;README-MCP-FAQ.md&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;ÊèêÈóÆÊïàÊûú&lt;/strong&gt;Ôºö&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;ÂÆûÈôÖ‰∏çÂª∫ËÆÆ‰∏ÄÊ¨°ÊÄßÈóÆÂ§ö‰∏™ÈóÆÈ¢ò„ÄÇÂ¶ÇÊûú‰Ω†ÈÄâÊã©ÁöÑ ai Ê®°ÂûãËøû‰∏ãÂõæÁöÑÊåâÈ°∫Â∫èË∞ÉÁî®ÈÉΩÊó†Ê≥ïÂÅöÂà∞ÔºåÂª∫ËÆÆÊç¢‰∏Ä‰∏™„ÄÇ&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;img src="https://raw.githubusercontent.com/sansan0/TrendRadar/master/_image/ai2.png" alt="mcp ‰ΩøÁî®ÊïàÊûúÂõæ2" width="600" /&gt; 
&lt;h2&gt;üîå MCP ÂÆ¢Êà∑Á´Ø&lt;/h2&gt; 
&lt;p&gt;TrendRadar MCP ÊúçÂä°ÊîØÊåÅÊ†áÂáÜÁöÑ Model Context Protocol (MCP) ÂçèËÆÆÔºåÂèØ‰ª•Êé•ÂÖ•ÂêÑÁßçÊîØÊåÅ MCP ÁöÑ AI ÂÆ¢Êà∑Á´ØËøõË°åÊô∫ËÉΩÂàÜÊûê„ÄÇ&lt;/p&gt; 
&lt;h3&gt;ÊîØÊåÅÁöÑÂÆ¢Êà∑Á´Ø&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Ê≥®ÊÑè‰∫ãÈ°π&lt;/strong&gt;Ôºö&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Â∞Ü &lt;code&gt;/path/to/TrendRadar&lt;/code&gt; ÊõøÊç¢‰∏∫‰Ω†ÁöÑÈ°πÁõÆÂÆûÈôÖË∑ØÂæÑ&lt;/li&gt; 
 &lt;li&gt;Windows Ë∑ØÂæÑ‰ΩøÁî®ÂèåÂèçÊñúÊù†Ôºö&lt;code&gt;C:\\Users\\YourName\\TrendRadar&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;‰øùÂ≠òÂêéËÆ∞ÂæóÈáçÂêØ&lt;/li&gt; 
&lt;/ul&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;b&gt;üëâ Claude Desktop&lt;/b&gt;&lt;/summary&gt; 
 &lt;h4&gt;ÈÖçÁΩÆÊñá‰ª∂ÊñπÂºè&lt;/h4&gt; 
 &lt;p&gt;ÁºñËæë Claude Desktop ÁöÑ MCP ÈÖçÁΩÆÊñá‰ª∂Ôºö&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Windows&lt;/strong&gt;Ôºö &lt;code&gt;%APPDATA%\Claude\claude_desktop_config.json&lt;/code&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Mac&lt;/strong&gt;Ôºö &lt;code&gt;~/Library/Application Support/Claude/claude_desktop_config.json&lt;/code&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;ÈÖçÁΩÆÂÜÖÂÆπ&lt;/strong&gt;Ôºö&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-json"&gt;{
  "mcpServers": {
    "trendradar": {
      "command": "uv",
      "args": [
        "--directory",
        "/path/to/TrendRadar",
        "run",
        "python",
        "-m",
        "mcp_server.server"
      ],
      "env": {},
      "disabled": false,
      "alwaysAllow": []
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;b&gt;üëâ Cursor&lt;/b&gt;&lt;/summary&gt; 
 &lt;h4&gt;ÊñπÂºè‰∏ÄÔºöHTTP Ê®°ÂºèÔºàÊé®ËçêÔºâ&lt;/h4&gt; 
 &lt;ol&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;ÂêØÂä® HTTP ÊúçÂä°&lt;/strong&gt;Ôºö&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;# Windows
start-http.bat

# Mac/Linux
./start-http.sh
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;ÈÖçÁΩÆ Cursor&lt;/strong&gt;Ôºö&lt;/p&gt; &lt;p&gt;&lt;strong&gt;È°πÁõÆÁ∫ßÈÖçÁΩÆ&lt;/strong&gt;ÔºàÊé®ËçêÔºâÔºö Âú®È°πÁõÆÊ†πÁõÆÂΩïÂàõÂª∫ &lt;code&gt;.cursor/mcp.json&lt;/code&gt;Ôºö&lt;/p&gt; &lt;pre&gt;&lt;code class="language-json"&gt;{
  "mcpServers": {
    "trendradar": {
      "url": "http://localhost:3333/mcp",
      "description": "TrendRadar Êñ∞ÈóªÁÉ≠ÁÇπËÅöÂêàÂàÜÊûê"
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&lt;strong&gt;ÂÖ®Â±ÄÈÖçÁΩÆ&lt;/strong&gt;Ôºö Âú®Áî®Êà∑ÁõÆÂΩïÂàõÂª∫ &lt;code&gt;~/.cursor/mcp.json&lt;/code&gt;ÔºàÂêåÊ†∑ÂÜÖÂÆπÔºâ&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;‰ΩøÁî®Ê≠•È™§&lt;/strong&gt;Ôºö&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;‰øùÂ≠òÈÖçÁΩÆÊñá‰ª∂ÂêéÈáçÂêØ Cursor&lt;/li&gt; 
    &lt;li&gt;Âú®ËÅäÂ§©ÁïåÈù¢ÁöÑ "Available Tools" ‰∏≠Êü•ÁúãÂ∑≤ËøûÊé•ÁöÑÂ∑•ÂÖ∑&lt;/li&gt; 
    &lt;li&gt;ÂºÄÂßã‰ΩøÁî®Ôºö&lt;code&gt;ÊêúÁ¥¢‰ªäÂ§©ÁöÑ"AI"Áõ∏ÂÖ≥Êñ∞Èóª&lt;/code&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;h4&gt;ÊñπÂºè‰∫åÔºöSTDIO Ê®°Âºè&lt;/h4&gt; 
 &lt;p&gt;ÂàõÂª∫ &lt;code&gt;.cursor/mcp.json&lt;/code&gt;Ôºö&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-json"&gt;{
  "mcpServers": {
    "trendradar": {
      "command": "uv",
      "args": [
        "--directory",
        "/path/to/TrendRadar",
        "run",
        "python",
        "-m",
        "mcp_server.server"
      ]
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;b&gt;üëâ VSCode (Cline/Continue)&lt;/b&gt;&lt;/summary&gt; 
 &lt;h4&gt;Cline ÈÖçÁΩÆ&lt;/h4&gt; 
 &lt;p&gt;Âú® Cline ÁöÑ MCP ËÆæÁΩÆ‰∏≠Ê∑ªÂä†Ôºö&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;HTTP Ê®°Âºè&lt;/strong&gt;ÔºàÊé®ËçêÔºâÔºö&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-json"&gt;{
  "trendradar": {
    "url": "http://localhost:3333/mcp",
    "type": "streamableHttp",
    "autoApprove": [],
    "disabled": false
  }
}
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;STDIO Ê®°Âºè&lt;/strong&gt;Ôºö&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-json"&gt;{
  "trendradar": {
    "command": "uv",
    "args": [
      "--directory",
      "/path/to/TrendRadar",
      "run",
      "python",
      "-m",
      "mcp_server.server"
    ],
    "type": "stdio",
    "disabled": false
  }
}
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h4&gt;Continue ÈÖçÁΩÆ&lt;/h4&gt; 
 &lt;p&gt;ÁºñËæë &lt;code&gt;~/.continue/config.json&lt;/code&gt;Ôºö&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-json"&gt;{
  "experimental": {
    "modelContextProtocolServers": [
      {
        "transport": {
          "type": "stdio",
          "command": "uv",
          "args": [
            "--directory",
            "/path/to/TrendRadar",
            "run",
            "python",
            "-m",
            "mcp_server.server"
          ]
        }
      }
    ]
  }
}
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;‰ΩøÁî®Á§∫‰æã&lt;/strong&gt;Ôºö&lt;/p&gt; 
 &lt;pre&gt;&lt;code&gt;ÂàÜÊûêÊúÄËøë7Â§©"ÁâπÊñØÊãâ"ÁöÑÁÉ≠Â∫¶ÂèòÂåñË∂ãÂäø
ÁîüÊàê‰ªäÂ§©ÁöÑÁÉ≠ÁÇπÊëòË¶ÅÊä•Âëä
ÊêúÁ¥¢"ÊØîÁâπÂ∏Å"Áõ∏ÂÖ≥Êñ∞ÈóªÂπ∂ÂàÜÊûêÊÉÖÊÑüÂÄæÂêë
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;b&gt;üëâ Claude Code CLI&lt;/b&gt;&lt;/summary&gt; 
 &lt;h4&gt;HTTP Ê®°ÂºèÈÖçÁΩÆ&lt;/h4&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# 1. ÂêØÂä® HTTP ÊúçÂä°
# Windows: start-http.bat
# Mac/Linux: ./start-http.sh

# 2. Ê∑ªÂä† MCP ÊúçÂä°Âô®
claude mcp add --transport http trendradar http://localhost:3333/mcp

# 3. È™åËØÅËøûÊé•ÔºàÁ°Æ‰øùÊúçÂä°Â∑≤ÂêØÂä®Ôºâ
claude mcp list
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h4&gt;‰ΩøÁî®Á§∫‰æã&lt;/h4&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# Êü•ËØ¢Êñ∞Èóª
claude "ÊêúÁ¥¢‰ªäÂ§©Áü•‰πéÁöÑÁÉ≠ÁÇπÊñ∞ÈóªÔºåÂâç10Êù°"

# Ë∂ãÂäøÂàÜÊûê
claude "ÂàÜÊûê'‰∫∫Â∑•Êô∫ËÉΩ'Ëøô‰∏™ËØùÈ¢òÊúÄËøë‰∏ÄÂë®ÁöÑÁÉ≠Â∫¶Ë∂ãÂäø"

# Êï∞ÊçÆÂØπÊØî
claude "ÂØπÊØîÁü•‰πéÂíåÂæÆÂçöÂπ≥Âè∞ÂØπ'ÊØîÁâπÂ∏Å'ÁöÑÂÖ≥Ê≥®Â∫¶"
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;b&gt;üëâ MCP Inspector&lt;/b&gt;ÔºàË∞ÉËØïÂ∑•ÂÖ∑Ôºâ&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;p&gt;MCP Inspector ÊòØÂÆòÊñπË∞ÉËØïÂ∑•ÂÖ∑ÔºåÁî®‰∫éÊµãËØï MCP ËøûÊé•Ôºö&lt;/p&gt; 
 &lt;h4&gt;‰ΩøÁî®Ê≠•È™§&lt;/h4&gt; 
 &lt;ol&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;ÂêØÂä® TrendRadar HTTP ÊúçÂä°&lt;/strong&gt;Ôºö&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;# Windows
start-http.bat

# Mac/Linux
./start-http.sh
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;ÂêØÂä® MCP Inspector&lt;/strong&gt;Ôºö&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;npx @modelcontextprotocol/inspector
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Âú®ÊµèËßàÂô®‰∏≠ËøûÊé•&lt;/strong&gt;Ôºö&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;ËÆøÈóÆÔºö&lt;code&gt;http://localhost:3333/mcp&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;ÊµãËØï "Ping Server" ÂäüËÉΩÈ™åËØÅËøûÊé•&lt;/li&gt; 
    &lt;li&gt;Ê£ÄÊü• "List Tools" ÊòØÂê¶ËøîÂõû 13 ‰∏™Â∑•ÂÖ∑Ôºö 
     &lt;ul&gt; 
      &lt;li&gt;Âü∫Á°ÄÊü•ËØ¢Ôºöget_latest_news, get_news_by_date, get_trending_topics&lt;/li&gt; 
      &lt;li&gt;Êô∫ËÉΩÊ£ÄÁ¥¢Ôºösearch_news, search_related_news_history&lt;/li&gt; 
      &lt;li&gt;È´òÁ∫ßÂàÜÊûêÔºöanalyze_topic_trend, analyze_data_insights, analyze_sentiment, find_similar_news, generate_summary_report&lt;/li&gt; 
      &lt;li&gt;Á≥ªÁªüÁÆ°ÁêÜÔºöget_current_config, get_system_status, trigger_crawl&lt;/li&gt; 
     &lt;/ul&gt; &lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ol&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;b&gt;üëâ ÂÖ∂‰ªñÊîØÊåÅ MCP ÁöÑÂÆ¢Êà∑Á´Ø&lt;/b&gt;&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;p&gt;‰ªª‰ΩïÊîØÊåÅ Model Context Protocol ÁöÑÂÆ¢Êà∑Á´ØÈÉΩÂèØ‰ª•ËøûÊé• TrendRadarÔºö&lt;/p&gt; 
 &lt;h4&gt;HTTP Ê®°ÂºèÔºàÊé®ËçêÔºâ&lt;/h4&gt; 
 &lt;p&gt;&lt;strong&gt;ÊúçÂä°Âú∞ÂùÄ&lt;/strong&gt;Ôºö&lt;code&gt;http://localhost:3333/mcp&lt;/code&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Âü∫Êú¨ÈÖçÁΩÆÊ®°Êùø&lt;/strong&gt;Ôºö&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-json"&gt;{
  "name": "trendradar",
  "url": "http://localhost:3333/mcp",
  "type": "http",
  "description": "Êñ∞ÈóªÁÉ≠ÁÇπËÅöÂêàÂàÜÊûê"
}
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h4&gt;STDIO Ê®°Âºè&lt;/h4&gt; 
 &lt;p&gt;&lt;strong&gt;Âü∫Êú¨ÈÖçÁΩÆÊ®°Êùø&lt;/strong&gt;Ôºö&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-json"&gt;{
  "name": "trendradar",
  "command": "uv",
  "args": [
    "--directory",
    "/path/to/TrendRadar",
    "run",
    "python",
    "-m",
    "mcp_server.server"
  ],
  "type": "stdio"
}
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;Ê≥®ÊÑè‰∫ãÈ°π&lt;/strong&gt;Ôºö&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;ÊõøÊç¢ &lt;code&gt;/path/to/TrendRadar&lt;/code&gt; ‰∏∫ÂÆûÈôÖÈ°πÁõÆË∑ØÂæÑ&lt;/li&gt; 
  &lt;li&gt;Windows Ë∑ØÂæÑ‰ΩøÁî®ÂèçÊñúÊù†ËΩ¨‰πâÔºö&lt;code&gt;C:\\Users\\...&lt;/code&gt;&lt;/li&gt; 
  &lt;li&gt;Á°Æ‰øùÂ∑≤ÂÆåÊàêÈ°πÁõÆ‰æùËµñÂÆâË£ÖÔºàËøêË°åËøá setup ËÑöÊú¨Ôºâ&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;‚òïÈóÆÈ¢òÁ≠îÁñë‰∏é1ÂÖÉÁÇπËµû&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;ÂøÉÊÑèÂà∞Â∞±Ë°åÔºåÊî∂Âà∞ÁöÑ&lt;strong&gt;ÁÇπËµû&lt;/strong&gt;Áî®‰∫éÊèêÈ´òÂºÄÂèëËÄÖÂºÄÊ∫êÁöÑÁßØÊûÅÊÄß„ÄÇ&lt;strong&gt;ÁÇπËµû&lt;/strong&gt;Â∑≤Êî∂ÂΩï‰∫é&lt;strong&gt;Ëá¥Ë∞¢ÂêçÂçï&lt;/strong&gt;&lt;br /&gt; ÊàëÂèëÁé∞Â§ßÂÆ∂ÈÉΩÂæàÂñÑ‰∫éÈù†Ëá™Â∑±Ëß£ÂÜ≥ÈóÆÈ¢òÔºåËøôÁßçÂ∞ùËØïÂÄºÂæóÈºìÂä±Ôºå‰ΩÜÂ¶ÇÊûúË¢´ÈóÆÈ¢òÂç°‰ΩèÂ§™‰πÖÔºåÂª∫ËÆÆÊèêÈóÆÊàñËÄÖÁïôË®Ä„ÄÇËøôÊ†∑ÊàëÊó¢ËÉΩÂ∏ÆÂà∞&lt;strong&gt;‰Ω†&lt;/strong&gt;Ôºå‰πüËÉΩÂ∏ÆÂà∞&lt;strong&gt;Êõ¥Â§öÊé¢Á¥¢‰∏≠ÁöÑÂ∞è‰ºô‰º¥&lt;/strong&gt;~~&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;GitHub Issues&lt;/strong&gt;ÔºöÈÄÇÂêàÈíàÂØπÊÄßÂº∫ÁöÑËß£Á≠î„ÄÇÊèêÈóÆÊó∂ËØ∑Êèê‰æõÂÆåÊï¥‰ø°ÊÅØÔºàÊà™Âõæ„ÄÅÈîôËØØÊó•Âøó„ÄÅÁ≥ªÁªüÁéØÂ¢ÉÁ≠âÔºâ„ÄÇ&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ÂÖ¨‰ºóÂè∑‰∫§ÊµÅ&lt;/strong&gt;ÔºöÈÄÇÂêàÂø´ÈÄüÂí®ËØ¢„ÄÇÂª∫ËÆÆ‰ºòÂÖàÂú®Áõ∏ÂÖ≥ÊñáÁ´†‰∏ãÁöÑÂÖ¨ÂÖ±ÁïôË®ÄÂå∫‰∫§ÊµÅÔºåÂ¶ÇÁßÅ‰ø°ÔºåËØ∑ÊñáÊòéÁ§ºË≤åÁî®ËØ≠üòâ&lt;/li&gt; 
&lt;/ul&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="center"&gt;ÂÖ¨‰ºóÂè∑ÂÖ≥Ê≥®&lt;/th&gt; 
   &lt;th align="center"&gt;ÂæÆ‰ø°ÁÇπËµû&lt;/th&gt; 
   &lt;th align="center"&gt;ÊîØ‰ªòÂÆùÁÇπËµû&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;img src="https://raw.githubusercontent.com/sansan0/TrendRadar/master/_image/weixin.png" width="300" title="Á°ÖÂü∫Ëå∂Ê∞¥Èó¥" /&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;img src="https://cdn-1258574687.cos.ap-shanghai.myqcloud.com/img/%2F2025%2F07%2F17%2F2ae0a88d98079f7e876c2b4dc85233c6-9e8025.JPG" width="300" title="ÂæÆ‰ø°ÊîØ‰ªò" /&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;img src="https://cdn-1258574687.cos.ap-shanghai.myqcloud.com/img/%2F2025%2F07%2F17%2F1ed4f20ab8e35be51f8e84c94e6e239b4-fe4947.JPG" width="300" title="ÊîØ‰ªòÂÆùÊîØ‰ªò" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Â∏∏ËßÅÈóÆÈ¢ò&lt;/h3&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;b&gt;üëâ Q1: HTTP ÊúçÂä°Êó†Ê≥ïÂêØÂä®Ôºü&lt;/b&gt;&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;p&gt;&lt;strong&gt;Ê£ÄÊü•Ê≠•È™§&lt;/strong&gt;Ôºö&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt; &lt;p&gt;Á°ÆËÆ§Á´ØÂè£ 3333 Êú™Ë¢´Âç†Áî®Ôºö&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;# Windows
netstat -ano | findstr :3333

# Mac/Linux
lsof -i :3333
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;Ê£ÄÊü•È°πÁõÆ‰æùËµñÊòØÂê¶ÂÆâË£ÖÔºö&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;# ÈáçÊñ∞ËøêË°åÂÆâË£ÖËÑöÊú¨
# Windows: setup-windows.bat ÊàñËÄÖ setup-windows-en.bat
# Mac/Linux: ./setup-mac.sh
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;Êü•ÁúãËØ¶ÁªÜÈîôËØØÊó•ÂøóÔºö&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;uv run python -m mcp_server.server --transport http --port 3333
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;Â∞ùËØïËá™ÂÆö‰πâÁ´ØÂè£:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;uv run python -m mcp_server.server --transport http --port 33333
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;/ol&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;b&gt;üëâ Q2: ÂÆ¢Êà∑Á´ØÊó†Ê≥ïËøûÊé•Âà∞ MCP ÊúçÂä°Ôºü&lt;/b&gt;&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;p&gt;&lt;strong&gt;Ëß£ÂÜ≥ÊñπÊ°à&lt;/strong&gt;Ôºö&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;STDIO Ê®°Âºè&lt;/strong&gt;Ôºö&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Á°ÆËÆ§ UV Ë∑ØÂæÑÊ≠£Á°ÆÔºàËøêË°å &lt;code&gt;which uv&lt;/code&gt; Êàñ &lt;code&gt;where uv&lt;/code&gt;Ôºâ&lt;/li&gt; 
    &lt;li&gt;Á°ÆËÆ§È°πÁõÆË∑ØÂæÑÊ≠£Á°Æ‰∏îÊó†‰∏≠ÊñáÂ≠óÁ¨¶&lt;/li&gt; 
    &lt;li&gt;Êü•ÁúãÂÆ¢Êà∑Á´ØÈîôËØØÊó•Âøó&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;HTTP Ê®°Âºè&lt;/strong&gt;Ôºö&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Á°ÆËÆ§ÊúçÂä°Â∑≤ÂêØÂä®ÔºàËÆøÈóÆ &lt;code&gt;http://localhost:3333/mcp&lt;/code&gt;Ôºâ&lt;/li&gt; 
    &lt;li&gt;Ê£ÄÊü•Èò≤ÁÅ´Â¢ôËÆæÁΩÆ&lt;/li&gt; 
    &lt;li&gt;Â∞ùËØï‰ΩøÁî® 127.0.0.1 Êõø‰ª£ localhost&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;ÈÄöÁî®Ê£ÄÊü•&lt;/strong&gt;Ôºö&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;ÈáçÂêØÂÆ¢Êà∑Á´ØÂ∫îÁî®&lt;/li&gt; 
    &lt;li&gt;Êü•Áúã MCP ÊúçÂä°Êó•Âøó&lt;/li&gt; 
    &lt;li&gt;‰ΩøÁî® MCP Inspector ÊµãËØïËøûÊé•&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ol&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;b&gt;üëâ Q3: Â∑•ÂÖ∑Ë∞ÉÁî®Â§±Ë¥•ÊàñËøîÂõûÈîôËØØÔºü&lt;/b&gt;&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;p&gt;&lt;strong&gt;ÂèØËÉΩÂéüÂõ†&lt;/strong&gt;Ôºö&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Êï∞ÊçÆ‰∏çÂ≠òÂú®&lt;/strong&gt;Ôºö&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Á°ÆËÆ§Â∑≤ËøêË°åËøáÁà¨Ëô´ÔºàÊúâ output ÁõÆÂΩïÊï∞ÊçÆÔºâ&lt;/li&gt; 
    &lt;li&gt;Ê£ÄÊü•Êü•ËØ¢Êó•ÊúüËåÉÂõ¥ÊòØÂê¶ÊúâÊï∞ÊçÆ&lt;/li&gt; 
    &lt;li&gt;Êü•Áúã output ÁõÆÂΩïÁöÑÂèØÁî®Êó•Êúü&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;ÂèÇÊï∞ÈîôËØØ&lt;/strong&gt;Ôºö&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Ê£ÄÊü•Êó•ÊúüÊ†ºÂºèÔºö&lt;code&gt;YYYY-MM-DD&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;Á°ÆËÆ§Âπ≥Âè∞ ID Ê≠£Á°ÆÔºö&lt;code&gt;zhihu&lt;/code&gt;, &lt;code&gt;weibo&lt;/code&gt; Á≠â&lt;/li&gt; 
    &lt;li&gt;Êü•ÁúãÂ∑•ÂÖ∑ÊñáÊ°£‰∏≠ÁöÑÂèÇÊï∞ËØ¥Êòé&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;ÈÖçÁΩÆÈóÆÈ¢ò&lt;/strong&gt;Ôºö&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Á°ÆËÆ§ &lt;code&gt;config/config.yaml&lt;/code&gt; Â≠òÂú®&lt;/li&gt; 
    &lt;li&gt;Á°ÆËÆ§ &lt;code&gt;config/frequency_words.txt&lt;/code&gt; Â≠òÂú®&lt;/li&gt; 
    &lt;li&gt;Ê£ÄÊü•ÈÖçÁΩÆÊñá‰ª∂Ê†ºÂºèÊòØÂê¶Ê≠£Á°Æ&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ol&gt; 
&lt;/details&gt; 
&lt;h3&gt;È°πÁõÆÁõ∏ÂÖ≥&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;4 ÁØáÊñáÁ´†&lt;/strong&gt;Ôºö&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://mp.weixin.qq.com/s/KYEPfTPVzZNWFclZh4am_g"&gt;ÂèØÂú®ËØ•ÊñáÁ´†‰∏ãÊñπÁïôË®ÄÔºåÊñπ‰æøÈ°πÁõÆ‰ΩúËÄÖÁî®ÊâãÊú∫Á≠îÁñë&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://mp.weixin.qq.com/s/jzn0vLiQFX408opcfpPPxQ"&gt;2‰∏™ÊúàÁ†¥ 1000 starÔºåÊàëÁöÑGitHubÈ°πÁõÆÊé®ÂπøÂÆûÊàòÁªèÈ™å&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://mp.weixin.qq.com/s/C8evK-U7onG1sTTdwdW2zg"&gt;github fork ËøêË°åÊú¨È°πÁõÆÁöÑÊ≥®ÊÑè‰∫ãÈ°π &lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://mp.weixin.qq.com/s/8ghyfDAtQZjLrnWTQabYOQ"&gt;Âü∫‰∫éÊú¨È°πÁõÆÔºåÂ¶Ç‰ΩïÂºÄÂ±ïÂÖ¨‰ºóÂè∑ÊàñËÄÖÊñ∞ÈóªËµÑËÆØÁ±ªÊñáÁ´†ÂÜô‰Ωú&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;AI ÂºÄÂèë&lt;/strong&gt;Ôºö&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;Â¶ÇÊûú‰Ω†ÊúâÂ∞è‰ºóÈúÄÊ±ÇÔºåÂÆåÂÖ®ÂèØ‰ª•Âü∫‰∫éÊàëÁöÑÈ°πÁõÆËá™Ë°åÂºÄÂèëÔºåÈõ∂ÁºñÁ®ãÂü∫Á°ÄÁöÑ‰πüÂèØ‰ª•ËØïËØï&lt;/li&gt; 
 &lt;li&gt;ÊàëÊâÄÊúâÁöÑÂºÄÊ∫êÈ°πÁõÆÊàñÂ§öÊàñÂ∞ëÈÉΩ‰ΩøÁî®‰∫ÜËá™Â∑±ÂÜôÁöÑ&lt;strong&gt;AIËæÖÂä©ËΩØ‰ª∂&lt;/strong&gt;Êù•ÊèêÂçáÂºÄÂèëÊïàÁéáÔºåËøôÊ¨æÂ∑•ÂÖ∑Â∑≤ÂºÄÊ∫ê&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Ê†∏ÂøÉÂäüËÉΩ&lt;/strong&gt;ÔºöËøÖÈÄüÁ≠õÈÄâÈ°πÁõÆ‰ª£Á†ÅÂñÇÁªôAIÔºå‰Ω†Âè™ÈúÄË¶ÅË°•ÂÖÖ‰∏™‰∫∫ÈúÄÊ±ÇÂç≥ÂèØ&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;È°πÁõÆÂú∞ÂùÄ&lt;/strong&gt;Ôºö&lt;a href="https://github.com/sansan0/ai-code-context-helper"&gt;https://github.com/sansan0/ai-code-context-helper&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;ÂÖ∂‰ΩôÈ°πÁõÆ&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;üìç ÊØõ‰∏ªÂ∏≠Ë∂≥ËøπÂú∞Âõæ - ‰∫§‰∫íÂºèÂä®ÊÄÅÂ±ïÁ§∫1893-1976Âπ¥ÂÆåÊï¥ËΩ®Ëøπ„ÄÇÊ¨¢ËøéËØ∏‰ΩçÂêåÂøóË¥°ÁåÆÊï∞ÊçÆ&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/sansan0/mao-map"&gt;https://github.com/sansan0/mao-map&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;ÂìîÂì©ÂìîÂì©(bilibili)ËØÑËÆ∫Âå∫Êï∞ÊçÆÂèØËßÜÂåñÂàÜÊûêËΩØ‰ª∂&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/sansan0/bilibili-comment-analyzer"&gt;https://github.com/sansan0/bilibili-comment-analyzer&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;üëâ ÂæÆ‰ø°Êé®ÈÄÅÈÄöÁü•ÊñπÊ°à&lt;/strong&gt;&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;Áî±‰∫éËØ•ÊñπÊ°àÊòØÂü∫‰∫é‰ºÅ‰∏öÂæÆ‰ø°ÁöÑÊèí‰ª∂Êú∫Âà∂ÔºåÊé®ÈÄÅÊ†∑Âºè‰πüÂçÅÂàÜ‰∏çÂêåÔºåÊâÄ‰ª•Áõ∏ÂÖ≥ÂÆûÁé∞ÊàëÊöÇÊó∂‰∏çÂáÜÂ§áÁ∫≥ÂÖ•ÂΩìÂâçÈ°πÁõÆ&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;ul&gt; 
  &lt;li&gt;fork Ëøô‰ΩçÂÖÑÂè∞ÁöÑÈ°πÁõÆ &lt;a href="https://github.com/jayzqj/TrendRadar"&gt;https://github.com/jayzqj/TrendRadar&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;ÂÆåÊàê‰∏äÊñπÁöÑ‰ºÅ‰∏öÂæÆ‰ø°Êé®ÈÄÅËÆæÁΩÆ&lt;/li&gt; 
  &lt;li&gt;ÊåâÁÖß‰∏ãÈù¢ÂõæÁâáÊìç‰Ωú&lt;/li&gt; 
  &lt;li&gt;ÈÖçÁΩÆÂ•ΩÂêéÔºåÊâãÊú∫‰∏äÁöÑ‰ºÅ‰∏öÂæÆ‰ø° app Âà†Èô§Êéâ‰πüÊ≤°‰∫ã&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;img src="https://raw.githubusercontent.com/sansan0/TrendRadar/master/_image/wework.png" title="github" /&gt; 
&lt;/details&gt; 
&lt;h3&gt;Êú¨È°πÁõÆÊµÅÁ®ãÂõæ&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-mermaid"&gt;flowchart TD
    A[üë§ Áî®Êà∑ÂºÄÂßã] --&amp;gt; B{üöÄ ÈÄâÊã©ÈÉ®ÁΩ≤ÊñπÂºè}
    
    B --&amp;gt;|‰∫ëÁ´ØÈÉ®ÁΩ≤| C1[üç¥ Fork È°πÁõÆÂà∞ GitHub]
    B --&amp;gt;|Êú¨Âú∞ÈÉ®ÁΩ≤| C2[üê≥ Docker ÈÉ®ÁΩ≤]
    
    C1 --&amp;gt; D[‚öôÔ∏è ÈÖçÁΩÆÈÄöÁü•Ê∏†ÈÅì&amp;lt;br/&amp;gt;ÂèØÂêåÊó∂ÈÖçÁΩÆÂ§ö‰∏™]
    C2 --&amp;gt; D
    
    D --&amp;gt; E[ÈÄâÊã©ÈÄöÁü•ÊñπÂºèÔºö&amp;lt;br/&amp;gt;üì±‰ºÅ‰∏öÂæÆ‰ø° üí¨È£û‰π¶ üîîÈíâÈíâ&amp;lt;br/&amp;gt;üìüTelegram üìßÈÇÆ‰ª∂]
    
    E --&amp;gt; F[üîë Â°´ÂÜôÈÄöÁü•ÂèÇÊï∞&amp;lt;br/&amp;gt;GitHub Secrets ÊàñÁéØÂ¢ÉÂèòÈáè]
    
    F --&amp;gt; G[üìù ÈÖçÁΩÆÂÖ≥ÈîÆËØç&amp;lt;br/&amp;gt;config/frequency_words.txt&amp;lt;br/&amp;gt;ÊôÆÈÄöËØç/ÂøÖÈ°ªËØç+/ËøáÊª§ËØç!]
    
    G --&amp;gt; H[üéØ ÈÄâÊã©ËøêË°åÊ®°Âºè&amp;lt;br/&amp;gt;config/config.yaml]
    
    H --&amp;gt; H1[üìã daily - ÂΩìÊó•Ê±áÊÄª&amp;lt;br/&amp;gt;ÂÆöÊó∂Êé®ÈÄÅÊâÄÊúâÂåπÈÖçÊñ∞Èóª]
    H --&amp;gt; H2[üì∞ current - ÂΩìÂâçÊ¶úÂçï&amp;lt;br/&amp;gt;ÂÆöÊó∂Êé®ÈÄÅÊúÄÊñ∞Ê¶úÂçï]
    H --&amp;gt; H3[üìà incremental - Â¢ûÈáèÁõëÊéß&amp;lt;br/&amp;gt;‰ªÖÊé®ÈÄÅÊñ∞Â¢ûÂÜÖÂÆπ]
    
    H1 --&amp;gt; I[ÂèØÈÄâÔºöÊé®ÈÄÅÊó∂Èó¥Á™óÂè£ÊéßÂà∂&amp;lt;br/&amp;gt;‚è∞ ÈôêÂà∂Êé®ÈÄÅÊó∂Èó¥ËåÉÂõ¥]
    H2 --&amp;gt; I
    H3 --&amp;gt; I
    
    I --&amp;gt; J[‚úÖ ÈÖçÁΩÆÂÆåÊàê]
    
    J --&amp;gt; K[ü§ñ Á≥ªÁªüËá™Âä®ËøêË°å]
    
    K --&amp;gt; L[üï∑Ô∏è Áà¨Âèñ11+Âπ≥Âè∞ÁÉ≠ÁÇπ]
    L --&amp;gt; M[üîç ÂÖ≥ÈîÆËØçÁ≠õÈÄâ]
    M --&amp;gt; N[‚öñÔ∏è ÊùÉÈáçÁÆóÊ≥ïÊéíÂ∫è&amp;lt;br/&amp;gt;ÊéíÂêç60% + È¢ëÊ¨°30% + ÁÉ≠Â∫¶10%]
    N --&amp;gt; O[üìä ÁîüÊàêÊä•Âëä&amp;lt;br/&amp;gt;HTMLÁΩëÈ°µ + Êé®ÈÄÅÊ∂àÊÅØ]
    O --&amp;gt; P[üì± Â§öÊ∏†ÈÅìÊé®ÈÄÅÈÄöÁü•]
    
    P --&amp;gt; Q[üéâ ÊåÅÁª≠Êé•Êî∂Á≤æÂáÜÊé®ÈÄÅ&amp;lt;br/&amp;gt;ÂëäÂà´‰ø°ÊÅØËøáËΩΩ]
    
    style A fill:#e3f2fd
    style B fill:#f3e5f5
    style D fill:#fff3e0
    style F fill:#fff9c4
    style G fill:#e8f5e9
    style H fill:#e0f2f1
    style I fill:#fce4ec
    style O fill:#e1bee7
    style Q fill:#c8e6c9
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;a href="https://www.star-history.com/#sansan0/TrendRadar&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=sansan0/TrendRadar&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üìÑ ËÆ∏ÂèØËØÅ&lt;/h2&gt; 
&lt;p&gt;GPL-3.0 License&lt;/p&gt; 
&lt;hr /&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/#trendradar"&gt;üîù ÂõûÂà∞È°∂ÈÉ®&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>microsoft/call-center-ai</title>
      <link>https://github.com/microsoft/call-center-ai</link>
      <description>&lt;p&gt;Send a phone call from AI agent, in an API call. Or, directly call the bot from the configured phone number!&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Call Center AI&lt;/h1&gt; 
&lt;p&gt;AI-powered call center solution with Azure and OpenAI GPT.&lt;/p&gt; 
&lt;!-- github.com badges --&gt; 
&lt;p&gt;&lt;a href="https://github.com/clemlesne/call-center-ai/releases"&gt;&lt;img src="https://img.shields.io/github/release-date/clemlesne/call-center-ai" alt="Last release date" /&gt;&lt;/a&gt; &lt;a href="https://github.com/clemlesne/call-center-ai/raw/main/LICENSE"&gt;&lt;img src="https://img.shields.io/github/license/clemlesne/call-center-ai" alt="Project license" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;!-- GitHub Codespaces badge --&gt; 
&lt;p&gt;&lt;a href="https://codespaces.new/microsoft/call-center-ai?quickstart=1"&gt;&lt;img src="https://github.com/codespaces/badge.svg?sanitize=true" alt="Open in GitHub Codespaces" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Overview&lt;/h2&gt; 
&lt;p&gt;Send a phone call from AI agent, in an API call. Or, directly call the bot from the configured phone number!&lt;/p&gt; 
&lt;p&gt;Insurance, IT support, customer service, and more. The bot can be customized in few hours (really) to fit your needs.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Ask the bot to call a phone number
data='{
  "bot_company": "Contoso",
  "bot_name": "Am√©lie",
  "phone_number": "+11234567890",
  "task": "Help the customer with their digital workplace. Assistant is working for the IT support department. The objective is to help the customer with their issue and gather information in the claim.",
  "agent_phone_number": "+33612345678",
  "claim": [
    {
      "name": "hardware_info",
      "type": "text"
    },
    {
      "name": "first_seen",
      "type": "datetime"
    },
    {
      "name": "building_location",
      "type": "text"
    }
  ]
}'

curl \
  --header 'Content-Type: application/json' \
  --request POST \
  --url https://xxx/call \
  --data $data
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Features&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Enhanced communication and user experience&lt;/strong&gt;: Integrates inbound and outbound calls with a dedicated phone number, supports multiple languages and voice tones, and allows users to provide or receive information via SMS. Conversations are &lt;strong&gt;streamed in real-time&lt;/strong&gt; to avoid delays, can be &lt;strong&gt;resumed after disconnections&lt;/strong&gt;, and are &lt;strong&gt;stored for future reference&lt;/strong&gt;. This ensures an &lt;strong&gt;improved customer experience&lt;/strong&gt;, enabling 24/7 communication and handling of low to medium complexity calls, all in a more accessible and user-friendly manner.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Advanced intelligence and data management&lt;/strong&gt;: Leverages &lt;strong&gt;gpt-4.1&lt;/strong&gt; and &lt;strong&gt;gpt-4.1-nano&lt;/strong&gt; (known for higher performance and a 10‚Äì15x cost premium) to achieve nuanced comprehension. It can discuss &lt;strong&gt;private and sensitive data&lt;/strong&gt;, including customer-specific information, while following &lt;strong&gt;retrieval-augmented generation (RAG)&lt;/strong&gt; best practices to ensure secure and compliant handling of internal documents. The system understands domain-specific terms, follows a structured claim schema, generates automated to-do lists, filters inappropriate content, and detects jailbreak attempts. Historical conversations and past interactions can also be used to &lt;strong&gt;fine-tune the LLM&lt;/strong&gt;, improving accuracy and personalization over time. Redis caching further enhances efficiency.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Customization, oversight, and scalability&lt;/strong&gt;: Offers &lt;strong&gt;customizable prompts&lt;/strong&gt;, feature flags for controlled experimentation, human agent fallback, and call recording for quality assurance. Integrates Application Insights for monitoring and tracing, provides publicly accessible claim data, and plans future enhancements such as automated callbacks and IVR-like workflows. It also enables the creation of a &lt;strong&gt;brand-specific custom voice&lt;/strong&gt;, allowing the assistant‚Äôs voice to reflect the company‚Äôs identity and improve brand consistency.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Cloud-native deployment and resource management&lt;/strong&gt;: Deployed on &lt;strong&gt;Azure&lt;/strong&gt; with a containerized, serverless architecture for low maintenance and elastic scaling. This approach optimizes costs based on usage, ensuring flexibility and affordability over time. Seamless integration with &lt;strong&gt;Azure Communication Services&lt;/strong&gt;, &lt;strong&gt;Cognitive Services&lt;/strong&gt;, and &lt;strong&gt;OpenAI resources&lt;/strong&gt; provides a secure environment suitable for rapid iteration, continuous improvement, and accommodating variable workloads in the call center.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Demo&lt;/h3&gt; 
&lt;p&gt;A French demo is avaialble on YouTube. Do not hesitate to watch the demo in x1.5 speed to get a quick overview of the project. Voice is hesitant on purpose to show the bot can handle it. All the infrastructure is deployed on Azure, mostly in serverless mode. Provisionning of the LLM resources can be done to reduce the latency.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://youtube.com/watch?v=i_qhNdUUxSI"&gt;&lt;img src="https://img.youtube.com/vi/i_qhNdUUxSI/maxresdefault.jpg" alt="French demo" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Main interactions shown in the demo:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;User calls the call center&lt;/li&gt; 
 &lt;li&gt;The bot answers and the conversation starts&lt;/li&gt; 
 &lt;li&gt;The bot stores conversation, claim and todo list in the database&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Extract of the data stored during the call:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "claim": {
    "incident_description": "Collision avec un autre v√©hicule, voiture dans le foss√©, pas de bless√©s",
    "incident_location": "Nationale 17",
    "involved_parties": "Dujardin, Madame Lesn√©",
    "policy_number": "DEC1748"
  },
  "messages": [
    {
      "created_at": "2024-12-10T15:51:04.566727Z",
      "action": "talk",
      "content": "Non, je pense que c'est pas mal. Vous avez r√©pondu √† mes questions et l√† j'attends la d√©paneuse. Merci beaucoup.",
      "persona": "human",
      "style": "none",
      "tool_calls": []
    },
    {
      "created_at": "2024-12-10T15:51:06.040451Z",
      "action": "talk",
      "content": "Je suis ravi d'avoir pu vous aider! Si vous avez besoin de quoi que ce soit d'autre, n'h√©sitez pas √† nous contacter. Je vous souhaite une bonne journ√©e et j'esp√®re que tout se passera bien avec la d√©panneuse. Au revoir!",
      "persona": "assistant",
      "style": "none",
      "tool_calls": []
    }
  ],
  "next": {
    "action": "case_closed",
    "justification": "The customer has provided all necessary information for the insurance claim, and a reminder has been set for a follow-up call. The customer is satisfied with the assistance provided and is waiting for the tow truck. The case can be closed for now."
  },
  "reminders": [
    {
      "created_at": "2024-12-10T15:50:09.507903Z",
      "description": "Rappeler le client pour faire le point sur l'accident et l'avancement du dossier.",
      "due_date_time": "2024-12-11T14:30:00",
      "owner": "assistant",
      "title": "Rappel client sur l'accident"
    }
  ],
  "synthesis": {
    "long": "During our call, you reported an accident involving your vehicle on the Nationale 17. You mentioned that there were no injuries, but both your car and the other vehicle ended up in a ditch. The other party involved is named Dujardin, and your vehicle is a 4x4 Ford. I have updated your claim with these details, including the license plates: yours is U837GE and the other vehicle's is GA837IA. A reminder has been set for a follow-up call tomorrow at 14:30 to discuss the progress of your claim. If you need further assistance, please feel free to reach out.",
    "satisfaction": "high",
    "short": "the accident on Nationale 17",
    "improvement_suggestions": "To improve the customer experience, it would be beneficial to ensure that the call connection is stable to avoid interruptions. Additionally, providing a clear step-by-step guide on what information is needed for the claim could help streamline the process and reduce any confusion for the customer."
  }
  ...
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;User report after the call&lt;/h3&gt; 
&lt;p&gt;A report is available at &lt;code&gt;https://[your_domain]/report/[phone_number]&lt;/code&gt; (like &lt;code&gt;http://localhost:8080/report/%2B133658471534&lt;/code&gt;). It shows the conversation history, claim data and reminders.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/microsoft/call-center-ai/main/docs/user_report.png" alt="User report" /&gt;&lt;/p&gt; 
&lt;h2&gt;Architecture&lt;/h2&gt; 
&lt;h3&gt;High level architecture&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-mermaid"&gt;---
title: System diagram (C4 model)
---
graph
  user(["User"])
  agent(["Agent"])

  app["Call Center AI"]

  app -- Transfer to --&amp;gt; agent
  app -. Send voice .-&amp;gt; user
  user -- Call --&amp;gt; app
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Component level architecture&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-mermaid"&gt;---
title: Claim AI component diagram (C4 model)
---
graph LR
  agent(["Agent"])
  user(["User"])

  subgraph "Claim AI"
    ada["Embedding&amp;lt;br&amp;gt;(ADA)"]
    app["App&amp;lt;br&amp;gt;(Container App)"]
    communication_services["Call &amp;amp; SMS gateway&amp;lt;br&amp;gt;(Communication Services)"]
    db[("Conversations and claims&amp;lt;br&amp;gt;(Cosmos DB)")]
    eventgrid["Broker&amp;lt;br&amp;gt;(Event Grid)"]
    gpt["LLM&amp;lt;br&amp;gt;(gpt-4.1, gpt-4.1-nano)"]
    queues[("Queues&amp;lt;br&amp;gt;(Azure Storage)")]
    redis[("Cache&amp;lt;br&amp;gt;(Redis)")]
    search[("RAG&amp;lt;br&amp;gt;(AI Search)")]
    sounds[("Sounds&amp;lt;br&amp;gt;(Azure Storage)")]
    sst["Speech-to-text&amp;lt;br&amp;gt;(Cognitive Services)"]
    translation["Translation&amp;lt;br&amp;gt;(Cognitive Services)"]
    tts["Text-to-speech&amp;lt;br&amp;gt;(Cognitive Services)"]
  end

  app -- Translate static TTS --&amp;gt; translation
  app -- Sezarch RAG data --&amp;gt; search
  app -- Generate completion --&amp;gt; gpt
  gpt -. Answer with completion .-&amp;gt; app
  app -- Generate voice --&amp;gt; tts
  tts -. Answer with voice .-&amp;gt; app
  app -- Get cached data --&amp;gt; redis
  app -- Save conversation --&amp;gt; db
  app -- Transform voice --&amp;gt; sst
  sst -. Answer with text .-&amp;gt; app
  app &amp;lt;-. Exchange audio .-&amp;gt; communication_services
  app -. Watch .-&amp;gt; queues

  communication_services -- Load sound --&amp;gt; sounds
  communication_services -- Notifies --&amp;gt; eventgrid
  communication_services -- Transfer to --&amp;gt; agent
  communication_services &amp;lt;-. Exchange audio .-&amp;gt; agent
  communication_services &amp;lt;-. Exchange audio .-&amp;gt; user

  eventgrid -- Push to --&amp;gt; queues

  search -- Generate embeddings --&amp;gt; ada

  user -- Call --&amp;gt; communication_services
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Deployment&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] This project is a proof of concept. It is not intended to be used in production. This demonstrates how can be combined Azure Communication Services, Azure Cognitive Services and Azure OpenAI to build an automated call center solution.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Prerequisites&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://codespaces.new/microsoft/call-center-ai?quickstart=1"&gt;Prefer using GitHub Codespaces for a quick start.&lt;/a&gt; The environment will setup automatically with all the required tools.&lt;/p&gt; 
&lt;p&gt;In macOS, with &lt;a href="https://brew.sh"&gt;Homebrew&lt;/a&gt;, simply type &lt;code&gt;make brew&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;For other systems, make sure you have the following installed:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://learn.microsoft.com/en-us/cli/azure/install-azure-cli"&gt;Azure CLI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.twilio.com/docs/twilio-cli/getting-started/install"&gt;Twilio CLI&lt;/a&gt; (optional)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mikefarah/yq?tab=readme-ov-file#install"&gt;yq&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Bash compatible shell, like &lt;code&gt;bash&lt;/code&gt; or &lt;code&gt;zsh&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Make, &lt;code&gt;apt install make&lt;/code&gt; (Ubuntu), &lt;code&gt;yum install make&lt;/code&gt; (CentOS), &lt;code&gt;brew install make&lt;/code&gt; (macOS)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Then, Azure resources are needed:&lt;/p&gt; 
&lt;h4&gt;1. &lt;a href="https://learn.microsoft.com/en-us/azure/azure-resource-manager/management/manage-resource-groups-portal"&gt;Create a new resource group&lt;/a&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Prefer to use lowercase and no special characters other than dashes (e.g. &lt;code&gt;ccai-customer-a&lt;/code&gt;)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;2. &lt;a href="https://learn.microsoft.com/en-us/azure/communication-services/quickstarts/create-communication-resource?tabs=linux&amp;amp;pivots=platform-azp"&gt;Create a Communication Services resource&lt;/a&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Same name as the resource group&lt;/li&gt; 
 &lt;li&gt;Enable system managed identity&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;3. &lt;a href="https://learn.microsoft.com/en-us/azure/communication-services/quickstarts/telephony/get-phone-number?tabs=linux&amp;amp;pivots=platform-azp-new"&gt;Buy a phone number&lt;/a&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;From the Communication Services resource&lt;/li&gt; 
 &lt;li&gt;Allow inbound and outbound communication&lt;/li&gt; 
 &lt;li&gt;Enable voice (required) and SMS (optional) capabilities&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Now that the prerequisites are configured (local + Azure), the deployment can be done.&lt;/p&gt; 
&lt;h3&gt;Remote (on Azure)&lt;/h3&gt; 
&lt;p&gt;A pre-built container image is available on GitHub Actions, it will be used to deploy the solution on Azure:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Latest version from a branch: &lt;code&gt;ghcr.io/clemlesne/call-center-ai:main&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Specific tag: &lt;code&gt;ghcr.io/clemlesne/call-center-ai:0.1.0&lt;/code&gt; (recommended)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;1. Create the light config file&lt;/h4&gt; 
&lt;p&gt;Fill the template from the example at &lt;a href="https://raw.githubusercontent.com/microsoft/call-center-ai/main/config-remote-example.yaml"&gt;&lt;code&gt;config-remote-example.yaml&lt;/code&gt;&lt;/a&gt;. The file should be placed at the root of the project under the name &lt;code&gt;config.yaml&lt;/code&gt;. It will be used by install scripts (incl. Makefile and Bicep) to configure the Azure resources.&lt;/p&gt; 
&lt;h4&gt;2. Connect to your Azure environment&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-zsh"&gt;az login
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;3. Run deployment automation&lt;/h4&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] Specify the release version under the &lt;code&gt;image_version&lt;/code&gt; parameter (default is &lt;code&gt;main&lt;/code&gt;). For example, &lt;code&gt;image_version=16.0.0&lt;/code&gt; or &lt;code&gt;image_version=sha-7ca2c0c&lt;/code&gt;. This will ensure any future project breaking changes won't affect your deployment.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;pre&gt;&lt;code class="language-zsh"&gt;make deploy name=my-rg-name
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Wait for the deployment to finish.&lt;/p&gt; 
&lt;h4&gt;4. Get the logs&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-zsh"&gt;make logs name=my-rg-name
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Local (on your machine)&lt;/h3&gt; 
&lt;h4&gt;1. Prerequisites&lt;/h4&gt; 
&lt;p&gt;If you skiped the &lt;code&gt;make brew&lt;/code&gt; command from the first install section, make sure you have the following installed:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://rust-lang.org"&gt;Rust&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.astral.sh/uv"&gt;uv&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Finally, run &lt;code&gt;make install&lt;/code&gt; to setup Python environment.&lt;/p&gt; 
&lt;h4&gt;2. Create the full config file&lt;/h4&gt; 
&lt;p&gt;If the application is already deployed on Azure, you can run &lt;code&gt;make name=my-rg-name sync-local-config&lt;/code&gt; to copy the configuration from remote to your local machine.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] To use a Service Principal to authenticate to Azure, you can also add the following in a &lt;code&gt;.env&lt;/code&gt; file:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-dotenv"&gt;AZURE_CLIENT_ID=xxx
AZURE_CLIENT_SECRET=xxx
AZURE_TENANT_ID=xxx
&lt;/code&gt;&lt;/pre&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;If the solution is not running online, fill the template from the example at &lt;a href="https://raw.githubusercontent.com/microsoft/call-center-ai/main/config-local-example.yaml"&gt;&lt;code&gt;config-local-example.yaml&lt;/code&gt;&lt;/a&gt;. The file should be placed at the root of the project under the name &lt;code&gt;config.yaml&lt;/code&gt;.&lt;/p&gt; 
&lt;h4&gt;3. Run the deployment automation&lt;/h4&gt; 
&lt;p&gt;Execute if the solution is not yet deployed on Azure.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-zsh"&gt;make deploy-bicep deploy-post name=my-rg-name
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;This will deploy the Azure resources without the API server, allowing you to test the bot locally&lt;/li&gt; 
 &lt;li&gt;Wait for the deployment to finish&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;4. Connect to Azure Dev tunnels&lt;/h4&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] Tunnel requires to be run in a separate terminal, because it needs to be running all the time&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;pre&gt;&lt;code class="language-zsh"&gt;# Log in once
devtunnel login

# Start the tunnel
make tunnel
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;5. Iterate quickly with the code&lt;/h4&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] To override a specific configuration value, you can use environment variables. For example, to override the &lt;code&gt;llm.fast.endpoint&lt;/code&gt; value, you can use the &lt;code&gt;LLM__FAST__ENDPOINT&lt;/code&gt; variable:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-dotenv"&gt;LLM__FAST__ENDPOINT=https://xxx.openai.azure.com
&lt;/code&gt;&lt;/pre&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] Also, &lt;code&gt;local.py&lt;/code&gt; script is available to test the application without the need of a phone call (= without Communication Services). Run the script with:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;python3 -m tests.local
&lt;/code&gt;&lt;/pre&gt; 
&lt;/blockquote&gt; 
&lt;pre&gt;&lt;code class="language-zsh"&gt;make dev
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;Code is automatically reloaded on file changes, no need to restart the server&lt;/li&gt; 
 &lt;li&gt;The API server is available at &lt;code&gt;http://localhost:8080&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Advanced usage&lt;/h2&gt; 
&lt;h3&gt;Enable call recording&lt;/h3&gt; 
&lt;p&gt;Call recording is disabled by default. To enable it:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Create a new container in the Azure Storage account (i.e. &lt;code&gt;recordings&lt;/code&gt;), it is already done if you deployed the solution on Azure&lt;/li&gt; 
 &lt;li&gt;Update the feature flag &lt;code&gt;recording_enabled&lt;/code&gt; in App Configuration to &lt;code&gt;true&lt;/code&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Add my custom training data with AI Search&lt;/h3&gt; 
&lt;p&gt;Training data is stored on AI Search to be retrieved by the bot, on demand.&lt;/p&gt; 
&lt;p&gt;Required index schema:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;&lt;strong&gt;Field Name&lt;/strong&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;code&gt;Type&lt;/code&gt;&lt;/th&gt; 
   &lt;th&gt;Retrievable&lt;/th&gt; 
   &lt;th&gt;Searchable&lt;/th&gt; 
   &lt;th&gt;Dimensions&lt;/th&gt; 
   &lt;th&gt;Vectorizer&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;answer&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;Edm.String&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;context&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;Edm.String&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;created_at&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;Edm.String&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;document_synthesis&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;Edm.String&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;file_path&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;Edm.String&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;id&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;Edm.String&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;question&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;Edm.String&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;vectors&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;Collection(Edm.Single)&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;1536&lt;/td&gt; 
   &lt;td&gt;&lt;em&gt;OpenAI ADA&lt;/em&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Software to fill the index is included &lt;a href="https://github.com/clemlesne/rag-index"&gt;on Synthetic RAG Index&lt;/a&gt; repository.&lt;/p&gt; 
&lt;h3&gt;Customize the languages&lt;/h3&gt; 
&lt;p&gt;The bot can be used in multiple languages. It can understand the language the user chose.&lt;/p&gt; 
&lt;p&gt;See the &lt;a href="https://learn.microsoft.com/en-us/azure/ai-services/speech-service/language-support?tabs=tts#supported-languages"&gt;list of supported languages&lt;/a&gt; for the Text-to-Speech service.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;# config.yaml
conversation:
  initiate:
    lang:
      default_short_code: fr-FR
      availables:
        - pronunciations_en: ["French", "FR", "France"]
          short_code: fr-FR
          voice: fr-FR-DeniseNeural
        - pronunciations_en: ["Chinese", "ZH", "China"]
          short_code: zh-CN
          voice: zh-CN-XiaoqiuNeural
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you built and deployed an &lt;a href="https://learn.microsoft.com/en-us/azure/ai-services/speech-service/custom-neural-voice"&gt;Azure Speech Custom Neural Voice (CNV)&lt;/a&gt;, add field &lt;code&gt;custom_voice_endpoint_id&lt;/code&gt; on the language configuration:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;# config.yaml
conversation:
  initiate:
    lang:
      default_short_code: fr-FR
      availables:
        - pronunciations_en: ["French", "FR", "France"]
          short_code: fr-FR
          voice: xxx
          custom_voice_endpoint_id: xxx
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Customize the moderation levels&lt;/h3&gt; 
&lt;p&gt;Levels are defined for each category of Content Safety. The higher the score, the more strict the moderation is, from 0 to 7. Moderation is applied on all bot data, including the web page and the conversation. Configure them in Azure OpenAI Content Filters.&lt;/p&gt; 
&lt;h3&gt;Customize the claim data schema&lt;/h3&gt; 
&lt;p&gt;Customization of the data schema is fully supported. You can add or remove fields as needed, depending on the requirements.&lt;/p&gt; 
&lt;p&gt;By default, the schema of composed of:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;caller_email&lt;/code&gt; (&lt;code&gt;email&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;caller_name&lt;/code&gt; (&lt;code&gt;text&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;caller_phone&lt;/code&gt; (&lt;code&gt;phone_number&lt;/code&gt;)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Values are validated to ensure the data format commit to your schema. They can be either:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;datetime&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;email&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;phone_number&lt;/code&gt; (&lt;code&gt;E164&lt;/code&gt; format)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;text&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Finally, an optional description can be provided. The description must be short and meaningful, it will be passed to the LLM.&lt;/p&gt; 
&lt;p&gt;Default schema, for inbound calls, is defined in the configuration:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;# config.yaml
conversation:
  default_initiate:
    claim:
      - name: additional_notes
        type: text
        # description: xxx
      - name: device_info
        type: text
        # description: xxx
      - name: incident_datetime
        type: datetime
        # description: xxx
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Claim schema can be customized for each call, by adding the &lt;code&gt;claim&lt;/code&gt; field in the &lt;code&gt;POST /call&lt;/code&gt; API call.&lt;/p&gt; 
&lt;h3&gt;Customize the call objective&lt;/h3&gt; 
&lt;p&gt;The objective is a description of what the bot will do during the call. It is used to give a context to the LLM. It should be short, meaningful, and written in English.&lt;/p&gt; 
&lt;p&gt;This solution is priviledged instead of overriding the LLM prompt.&lt;/p&gt; 
&lt;p&gt;Default task, for inbound calls, is defined in the configuration:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;# config.yaml
conversation:
  initiate:
    task: |
      Help the customer with their insurance claim. Assistant requires data from the customer to fill the claim. The latest claim data will be given. Assistant role is not over until all the relevant data is gathered.
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Task can be customized for each call, by adding the &lt;code&gt;task&lt;/code&gt; field in the &lt;code&gt;POST /call&lt;/code&gt; API call.&lt;/p&gt; 
&lt;h3&gt;Customize the conversation&lt;/h3&gt; 
&lt;p&gt;Conversation options are represented as features. They can be configured from App Configuration, without the need to redeploy or restart the application. Once a feature is updated, a delay of 60 secs is needed to make the change effective.&lt;/p&gt; 
&lt;p&gt;By default, values are refreshed every 60 seconds. Refresh is not sync across all instances, so it can take up to 60 seconds to see the change on all users. Update this in the &lt;code&gt;app_configuration.ttl_sec&lt;/code&gt; field.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Name&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Type&lt;/th&gt; 
   &lt;th&gt;Default&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;answer_hard_timeout_sec&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Time waiting the LLM before aborting the answer with an error message.&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;int&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;15&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;answer_soft_timeout_sec&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Time waiting the LLM before sending a waiting message.&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;int&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;4&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;callback_timeout_hour&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;The timeout for a callback in hours. Set 0 to disable.&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;int&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;3&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;phone_silence_timeout_sec&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Amount of silence in secs to trigger a warning message from the assistant.&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;int&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;20&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;recognition_retry_max&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;TThe maximum number of retries for voice recognition. Minimum of 1.&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;int&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;3&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;recognition_stt_complete_timeout_ms&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;The timeout for STT completion in milliseconds.&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;int&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;100&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;recording_enabled&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Whether call recording is enabled.&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;bool&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;false&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;slow_llm_for_chat&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Whether to use the slow LLM for chat.&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;bool&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;false&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;vad_cutoff_timeout_ms&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;The cutoff timeout for voice activity detection in milliseconds.&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;int&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;250&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;vad_silence_timeout_ms&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Silence to trigger voice activity detection in milliseconds.&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;int&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;500&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;vad_threshold&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;The threshold for voice activity detection. Between 0.1 and 1.&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;float&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;0.5&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Use Twilio for SMS&lt;/h3&gt; 
&lt;p&gt;To use Twilio for SMS, you need to create an account and get the following information:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Account SID&lt;/li&gt; 
 &lt;li&gt;Auth Token&lt;/li&gt; 
 &lt;li&gt;Phone number&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Then, add the following in the &lt;code&gt;config.yaml&lt;/code&gt; file:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;# config.yaml
sms:
  mode: twilio
  twilio:
    account_sid: xxx
    auth_token: xxx
    phone_number: "+33612345678"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Customize the prompts&lt;/h3&gt; 
&lt;p&gt;Note that prompt examples contains &lt;code&gt;{xxx}&lt;/code&gt; placeholders. These placeholders are replaced by the bot with the corresponding data. For example, &lt;code&gt;{bot_name}&lt;/code&gt; is internally replaced by the bot name. Be sure to write all the TTS prompts in English. This language is used as a pivot language for the conversation translation. All texts are referenced as lists, so user can have a different experience each time they call, thus making the conversation more engaging.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;# config.yaml
prompts:
  tts:
    hello_tpl:
      - : |
        Hello, I'm {bot_name}, from {bot_company}! I'm an IT support specialist.

        Here's how I work: when I'm working, you'll hear a little music; then, at the beep, it's your turn to speak. You can speak to me naturally, I'll understand.

        What's your problem?
      - : |
        Hi, I'm {bot_name} from {bot_company}. I'm here to help.

        You'll hear music, then a beep. Speak naturally, I'll understand.

        What's the issue?
  llm:
    default_system_tpl: |
      Assistant is called {bot_name} and is in a call center for the company {bot_company} as an expert with 20 years of experience in IT service.

      # Context
      Today is {date}. Customer is calling from {phone_number}. Call center number is {bot_phone_number}.
    chat_system_tpl: |
      # Objective
      Provide internal IT support to employees. Assistant requires data from the employee to provide IT support. The assistant's role is not over until the issue is resolved or the request is fulfilled.

      # Rules
      - Answers in {default_lang}, even if the customer speaks another language
      - Cannot talk about any topic other than IT support
      - Is polite, helpful, and professional
      - Rephrase the employee's questions as statements and answer them
      - Use additional context to enhance the conversation with useful details
      - When the employee says a word and then spells out letters, this means that the word is written in the way the employee spelled it (e.g. "I work in Paris PARIS", "My name is John JOHN", "My email is Clemence CLEMENCE at gmail GMAIL dot com COM")
      - You work for {bot_company}, not someone else

      # Required employee data to be gathered by the assistant
      - Department
      - Description of the IT issue or request
      - Employee name
      - Location

      # General process to follow
      1. Gather information to know the employee's identity (e.g. name, department)
      2. Gather details about the IT issue or request to understand the situation (e.g. description, location)
      3. Provide initial troubleshooting steps or solutions
      4. Gather additional information if needed (e.g. error messages, screenshots)
      5. Be proactive and create reminders for follow-up or further assistance

      # Support status
      {claim}

      # Reminders
      {reminders}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Optimize response delay&lt;/h3&gt; 
&lt;p&gt;The delay mainly come from two things:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Voice in and voice out are processed by Azure AI Speech, both are implemented in streaming mode but voice is not directly streamed to the LLM&lt;/li&gt; 
 &lt;li&gt;The LLM, more specifically the delay between API call and first sentence infered, can be long (as the sentences are sent one by one once they are made avalable), even longer if it hallucinate and returns empty answers (it happens regularly, and the applicatoipn retries the call)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;From now, the only impactful thing you can do is the LLM part. This can be acheieve by a PTU on Azure or using a less smart model like &lt;code&gt;gpt-4.1-nano&lt;/code&gt; (selected by default on the latest versions). With a PTU on Azure OpenAI, you can divide by 2 the latency in some case.&lt;/p&gt; 
&lt;p&gt;The application is natively connected to Azure Application Insights, so you can monitor the response time and see where the time is spent. This is a great start to identify the bottlenecks.&lt;/p&gt; 
&lt;p&gt;Feel free to raise an issue or propose a PR if you have any idea to optimize the response delay.&lt;/p&gt; 
&lt;h3&gt;Improving conversation quality through model fine-tuning&lt;/h3&gt; 
&lt;p&gt;Enhance the LLM‚Äôs accuracy and domain adaptation by integrating historical data from human-run call centers. Before proceeding, ensure compliance with data privacy regulations, internal security standards, and &lt;a href="https://learn.microsoft.com/en-us/azure/machine-learning/concept-responsible-ai?view=azureml-api-2"&gt;Responsible AI principles&lt;/a&gt;. Consider the following steps:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Aggregate authentic data sources: Collect voice recordings, call transcripts, and chat logs from previous human-managed interactions to provide the LLM with realistic training material.&lt;/li&gt; 
 &lt;li&gt;Preprocess and anonymize data: &lt;a href="https://learn.microsoft.com/en-us/azure/ai-services/language-service/personally-identifiable-information/overview"&gt;Remove sensitive information (AI Language Personally Identifiable Information detection)&lt;/a&gt;, including personal identifiers or confidential details, to preserve user privacy, meet compliance, and align with Responsible AI guidelines.&lt;/li&gt; 
 &lt;li&gt;Perform iterative fine-tuning: Continuously &lt;a href="https://learn.microsoft.com/en-us/azure/ai-studio/concepts/fine-tuning-overview"&gt;refine the model‚Äôs using the curated dataset (AI Foundry Fine-tuning)&lt;/a&gt;, allowing it to learn industry-specific terminology, preferred conversation styles, and problem-resolution approaches.&lt;/li&gt; 
 &lt;li&gt;Validate improvements: Test the updated model against sample scenarios and measure key performance indicators (e.g. user satisfaction, call duration, resolution rate) to confirm that adjustments have led to meaningful enhancements.&lt;/li&gt; 
 &lt;li&gt;Monitor, iterate, and A/B test: Regularly reassess the model‚Äôs performance, integrate newly gathered data, and apply further fine-tuning as needed. Leverage &lt;a href="https://learn.microsoft.com/en-us/azure/azure-app-configuration/concept-experimentation"&gt;built-in feature configurations to A/B test (App Configuration Experimentation)&lt;/a&gt; different versions of the model, ensuring responsible, data-driven decisions and continuous optimization over time.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Monitoring the application&lt;/h3&gt; 
&lt;p&gt;Application send traces and metrics to Azure Application Insights. You can monitor the application from the Azure portal, or by using the API.&lt;/p&gt; 
&lt;p&gt;This includes application behavior, database queries, and external service calls. Plus, LLM metrics (latency, token usage, prompts content, raw response) from &lt;a href="https://github.com/traceloop/openllmetry"&gt;OpenLLMetry&lt;/a&gt;, following the &lt;a href="https://opentelemetry.io/docs/specs/semconv/gen-ai/openai/#openai-spans"&gt;semantic sonventions for OpenAI operations&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Additionally custom metrics (viewable in Application Insights &amp;gt; Metrics) are published, notably:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;call.aec.droped&lt;/code&gt;, number of times the echo cancellation dropped the voice completely.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;call.aec.missed&lt;/code&gt;, number of times the echo cancellation failed to remove the echo in time.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;call.answer.latency&lt;/code&gt;, time between the end of the user voice and the start of the bot voice.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Q&amp;amp;A&lt;/h2&gt; 
&lt;h3&gt;What will this cost?&lt;/h3&gt; 
&lt;p&gt;For a monthly usage of 1000 calls of 10 minutes each. Costs are estimated for 2024-12-10, in USD. Prices are subject to change.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] For production usage, it is recommended to upgrade to SKUs with vNET integration and private endpoints. This can increase notably the costs.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;This totalizes $720.07 /month, $0.12 /hour, with the following breakdown:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://azure.microsoft.com/en-us/pricing/details/communication-services/"&gt;Azure Communication Services&lt;/a&gt;:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Region&lt;/th&gt; 
   &lt;th&gt;Metric&lt;/th&gt; 
   &lt;th&gt;Cost&lt;/th&gt; 
   &lt;th&gt;Total (monthly $)&lt;/th&gt; 
   &lt;th&gt;Note&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;West Europe&lt;/td&gt; 
   &lt;td&gt;Audio Streaming&lt;/td&gt; 
   &lt;td&gt;$0.004 /minute&lt;/td&gt; 
   &lt;td&gt;$40&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;a href="https://azure.microsoft.com/en-us/pricing/details/cognitive-services/openai-service/"&gt;Azure OpenAI&lt;/a&gt;:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Region&lt;/th&gt; 
   &lt;th&gt;Metric&lt;/th&gt; 
   &lt;th&gt;Cost&lt;/th&gt; 
   &lt;th&gt;Total (monthly $)&lt;/th&gt; 
   &lt;th&gt;Note&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Sweden Central&lt;/td&gt; 
   &lt;td&gt;gpt-4.1-nano global&lt;/td&gt; 
   &lt;td&gt;$0.15 /1M input tokens&lt;/td&gt; 
   &lt;td&gt;$35.25&lt;/td&gt; 
   &lt;td&gt;8k tokens for conversation history, 3750 tokens for RAG, each participant talk every 15s&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Sweden Central&lt;/td&gt; 
   &lt;td&gt;gpt-4.1-nano global&lt;/td&gt; 
   &lt;td&gt;$0.60 /1M output tokens&lt;/td&gt; 
   &lt;td&gt;$1.4&lt;/td&gt; 
   &lt;td&gt;400 tokens for each response incl tools, each participant talk every 15s&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Sweden Central&lt;/td&gt; 
   &lt;td&gt;gpt-4.1 global&lt;/td&gt; 
   &lt;td&gt;$2.50 /1M input tokens&lt;/td&gt; 
   &lt;td&gt;$10&lt;/td&gt; 
   &lt;td&gt;4k tokens for each conversation, to get insights&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Sweden Central&lt;/td&gt; 
   &lt;td&gt;gpt-4.1 global&lt;/td&gt; 
   &lt;td&gt;$10 /1M output tokens&lt;/td&gt; 
   &lt;td&gt;$10&lt;/td&gt; 
   &lt;td&gt;1k tokens for each conversation, to get insights&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Sweden Central&lt;/td&gt; 
   &lt;td&gt;text-embedding-3-large&lt;/td&gt; 
   &lt;td&gt;$0.00013 /1k tokens&lt;/td&gt; 
   &lt;td&gt;$2.08&lt;/td&gt; 
   &lt;td&gt;1 search or 400 tokens for each message, each participant talk every 15s&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;a href="https://azure.microsoft.com/en-us/pricing/details/container-apps/"&gt;Azure Container Apps&lt;/a&gt;:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Region&lt;/th&gt; 
   &lt;th&gt;Metric&lt;/th&gt; 
   &lt;th&gt;Cost&lt;/th&gt; 
   &lt;th&gt;Total (monthly $)&lt;/th&gt; 
   &lt;th&gt;Note&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Sweden Central&lt;/td&gt; 
   &lt;td&gt;Serverless vCPU&lt;/td&gt; 
   &lt;td&gt;$0.000024 /sec&lt;/td&gt; 
   &lt;td&gt;$128.56&lt;/td&gt; 
   &lt;td&gt;Avg of 2 replicas with 1 vCPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Sweden Central&lt;/td&gt; 
   &lt;td&gt;Serverless memory (average of 2 replicas)&lt;/td&gt; 
   &lt;td&gt;$0.000003 /sec&lt;/td&gt; 
   &lt;td&gt;$32.14&lt;/td&gt; 
   &lt;td&gt;Avg of 2 replicas with 2GB&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;a href="https://azure.microsoft.com/en-us/pricing/details/search/"&gt;Azure AI Search&lt;/a&gt;:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Region&lt;/th&gt; 
   &lt;th&gt;Metric&lt;/th&gt; 
   &lt;th&gt;Cost&lt;/th&gt; 
   &lt;th&gt;Total (monthly $)&lt;/th&gt; 
   &lt;th&gt;Note&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Sweden Central&lt;/td&gt; 
   &lt;td&gt;Basic&lt;/td&gt; 
   &lt;td&gt;$73.73 /month&lt;/td&gt; 
   &lt;td&gt;$73.73&lt;/td&gt; 
   &lt;td&gt;Has 15GB of storage /index, should be upgraded for big datasets&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;a href="https://azure.microsoft.com/en-us/pricing/details/cognitive-services/speech-services/"&gt;Azure AI Speech&lt;/a&gt;:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Region&lt;/th&gt; 
   &lt;th&gt;Metric&lt;/th&gt; 
   &lt;th&gt;Cost&lt;/th&gt; 
   &lt;th&gt;Total (monthly $)&lt;/th&gt; 
   &lt;th&gt;Note&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;West Europe&lt;/td&gt; 
   &lt;td&gt;Speech-to-text real-time&lt;/td&gt; 
   &lt;td&gt;$1 /hour&lt;/td&gt; 
   &lt;td&gt;$83.33&lt;/td&gt; 
   &lt;td&gt;Each participant talk every 15s&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;West Europe&lt;/td&gt; 
   &lt;td&gt;Text-to-speech standard&lt;/td&gt; 
   &lt;td&gt;$15 /1M characters&lt;/td&gt; 
   &lt;td&gt;$69.23&lt;/td&gt; 
   &lt;td&gt;300 tokens for each response, 1.3 tokens /word in English, each participant talk every 15s&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;a href="https://azure.microsoft.com/en-us/pricing/details/cosmos-db/autoscale-provisioned/"&gt;Azure Cosmos DB&lt;/a&gt;:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Region&lt;/th&gt; 
   &lt;th&gt;Metric&lt;/th&gt; 
   &lt;th&gt;Cost&lt;/th&gt; 
   &lt;th&gt;Total (monthly $)&lt;/th&gt; 
   &lt;th&gt;Note&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Sweden Central&lt;/td&gt; 
   &lt;td&gt;Multi-region write RU/s /region&lt;/td&gt; 
   &lt;td&gt;$11.68 /100 RU/s&lt;/td&gt; 
   &lt;td&gt;$233.6&lt;/td&gt; 
   &lt;td&gt;Avg of 1k RU/s on 2 regions&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Sweden Central&lt;/td&gt; 
   &lt;td&gt;Transactional storage&lt;/td&gt; 
   &lt;td&gt;$0.25 /GB&lt;/td&gt; 
   &lt;td&gt;$0.5&lt;/td&gt; 
   &lt;td&gt;2GB of storage, should be upgraded if more history is needed&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;Not included upper:&lt;/strong&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] Azure Monitor costs shouldn't be considered as optional as monitoring is a key part of maintaining a business-critical application and high-quality service for users.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Optional costs totalizing $343.02 /month, with the following breakdown:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://azure.microsoft.com/en-us/pricing/details/communication-services/"&gt;Azure Communication Services&lt;/a&gt;:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Region&lt;/th&gt; 
   &lt;th&gt;Metric&lt;/th&gt; 
   &lt;th&gt;Cost&lt;/th&gt; 
   &lt;th&gt;Total (monthly $)&lt;/th&gt; 
   &lt;th&gt;Note&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;West Europe&lt;/td&gt; 
   &lt;td&gt;Call recording&lt;/td&gt; 
   &lt;td&gt;$0.002 /minute&lt;/td&gt; 
   &lt;td&gt;$20&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;a href="https://azure.microsoft.com/en-us/pricing/details/cognitive-services/openai-service/"&gt;Azure OpenAI&lt;/a&gt;:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Region&lt;/th&gt; 
   &lt;th&gt;Metric&lt;/th&gt; 
   &lt;th&gt;Cost&lt;/th&gt; 
   &lt;th&gt;Total (monthly $)&lt;/th&gt; 
   &lt;th&gt;Note&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Sweden Central&lt;/td&gt; 
   &lt;td&gt;text-embedding-3-large&lt;/td&gt; 
   &lt;td&gt;$0.00013 /1k tokens&lt;/td&gt; 
   &lt;td&gt;$0.52&lt;/td&gt; 
   &lt;td&gt;10k PDF pages with 400 tokens each, for indexing&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;a href="https://azure.microsoft.com/en-us/pricing/details/monitor/"&gt;Azure Monitor&lt;/a&gt;:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Region&lt;/th&gt; 
   &lt;th&gt;Metric&lt;/th&gt; 
   &lt;th&gt;Cost&lt;/th&gt; 
   &lt;th&gt;Total (monthly $)&lt;/th&gt; 
   &lt;th&gt;Note&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Sweden Central&lt;/td&gt; 
   &lt;td&gt;Basic logs ingestion&lt;/td&gt; 
   &lt;td&gt;$0.645 /GB&lt;/td&gt; 
   &lt;td&gt;$322.5&lt;/td&gt; 
   &lt;td&gt;500GB of logs &lt;a href="https://learn.microsoft.com/en-us/azure/azure-monitor/app/opentelemetry-configuration?tabs=python#enable-sampling"&gt;with sampling enabled&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;What would it require to make it production ready?&lt;/h3&gt; 
&lt;p&gt;Quality:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Unit and integration tests for persistence layer&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Complete unit and integration tests coverage&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Reliability:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Reproductible builds&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Traces and telemetry&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Operation runbooks for common issues&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Proper dashboarding in Azure Application Insights (deployed with the IaC)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Maintainability:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Automated and required static code checks&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Decouple assistant from the insights in a separate service&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Peer review to limit the bus factor&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Resiliency:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Infrastructure as Code (IaC)&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Multi-region deployment&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Reproductible performance tests&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Security:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; CI builds attestations&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; CodeQL static code checks&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; GitOps for deployments&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Private networking&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Production SKUs allowing vNET integration&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Red team exercises&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Responsible AI:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Harmful content detection&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Grounding detection with Content Safety&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Social impact assessment&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Why no LLM framework is used?&lt;/h3&gt; 
&lt;p&gt;At the time of development, no LLM framework was available to handle all of these features: streaming capability with multi-tools, backup models on availability issue, callbacks mechanisms in the triggered tools. So, OpenAI SDK is used directly and some algorithms are implemented to handle reliability.&lt;/p&gt; 
&lt;h2&gt;Related content&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;For a simple sample with Azure OpenAI &lt;code&gt;gpt-4o-realtime&lt;/code&gt;, local deployment only, &lt;a href="https://github.com/Azure-Samples/aisearch-openai-rag-audio"&gt;see VoiceRAG&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;For an easier-to-use sample with Azure OpenAI &lt;code&gt;gpt-4o-realtime&lt;/code&gt;, deployed on Azure, &lt;a href="https://github.com/Azure-Samples/realtime-call-center-accelerator"&gt;see Realtime Call Center Solution Accelerator&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>MetaCubeX/mihomo</title>
      <link>https://github.com/MetaCubeX/mihomo</link>
      <description>&lt;p&gt;A simple Python Pydantic model for Honkai: Star Rail parsed data from the Mihomo API.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;mihomo&lt;/h1&gt; 
&lt;p&gt;A simple python pydantic model (type hint and autocompletion support) for Honkai: Star Rail parsed data from the Mihomo API.&lt;/p&gt; 
&lt;p&gt;API url: &lt;a href="https://api.mihomo.me/sr_info_parsed/%7BUID%7D?lang=%7BLANG%7D"&gt;https://api.mihomo.me/sr_info_parsed/{UID}?lang={LANG}&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;pip install -U git+https://github.com/KT-Yeh/mihomo.git
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;h3&gt;Basic&lt;/h3&gt; 
&lt;p&gt;There are two parsed data formats:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;V1: 
  &lt;ul&gt; 
   &lt;li&gt;URL: &lt;a href="https://api.mihomo.me/sr_info_parsed/800333171?lang=en&amp;amp;version=v1"&gt;https://api.mihomo.me/sr_info_parsed/800333171?lang=en&amp;amp;version=v1&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;Fetching: use &lt;code&gt;client.fetch_user_v1(800333171)&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;Data model: &lt;code&gt;mihomo.models.v1.StarrailInfoParsedV1&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;All models defined in &lt;code&gt;mihomo/models/v1&lt;/code&gt; directory.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;V2: 
  &lt;ul&gt; 
   &lt;li&gt;URL: &lt;a href="https://api.mihomo.me/sr_info_parsed/800333171?lang=en"&gt;https://api.mihomo.me/sr_info_parsed/800333171?lang=en&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;Fetching: use &lt;code&gt;client.fetch_user(800333171)&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;Data model: &lt;code&gt;mihomo.models.StarrailInfoParsed&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;All models defined in &lt;code&gt;mihomo/models&lt;/code&gt; directory.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;If you don't want to use &lt;code&gt;client.get_icon_url&lt;/code&gt; to get the image url everytime, you can use &lt;code&gt;client.fetch_user(800333171, replace_icon_name_with_url=True)&lt;/code&gt; to get the parsed data with asset urls.&lt;/p&gt; 
&lt;h3&gt;Example&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-py"&gt;import asyncio

from mihomo import Language, MihomoAPI
from mihomo.models import StarrailInfoParsed
from mihomo.models.v1 import StarrailInfoParsedV1

client = MihomoAPI(language=Language.EN)


async def v1():
    data: StarrailInfoParsedV1 = await client.fetch_user_v1(800333171)

    print(f"Name: {data.player.name}")
    print(f"Level: {data.player.level}")
    print(f"Signature: {data.player.signature}")
    print(f"Achievements: {data.player_details.achievements}")
    print(f"Characters count: {data.player_details.characters}")
    print(f"Profile picture url: {client.get_icon_url(data.player.icon)}")
    for character in data.characters:
        print("-----------")
        print(f"Name: {character.name}")
        print(f"Rarity: {character.rarity}")
        print(f"Level: {character.level}")
        print(f"Avatar url: {client.get_icon_url(character.icon)}")
        print(f"Preview url: {client.get_icon_url(character.preview)}")
        print(f"Portrait url: {client.get_icon_url(character.portrait)}")


async def v2():
    data: StarrailInfoParsed = await client.fetch_user(800333171, replace_icon_name_with_url=True)

    print(f"Name: {data.player.name}")
    print(f"Level: {data.player.level}")
    print(f"Signature: {data.player.signature}")
    print(f"Profile picture url: {data.player.avatar.icon}")
    for character in data.characters:
        print("-----------")
        print(f"Name: {character.name}")
        print(f"Rarity: {character.rarity}")
        print(f"Portrait url: {character.portrait}")

asyncio.run(v1())
asyncio.run(v2())
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Tools&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;from mihomo import tools&lt;/code&gt;&lt;/p&gt; 
&lt;h4&gt;Remove Duplicate Character&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-py"&gt;    data = await client.fetch_user(800333171)
    data = tools.remove_duplicate_character(data)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Merge Character Data&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-py"&gt;    old_data = await client.fetch_user(800333171)

    # Change characters in game and wait for the API to refresh
    # ...

    new_data = await client.fetch_user(800333171)
    data = tools.merge_character_data(new_data, old_data)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Data Persistence&lt;/h3&gt; 
&lt;p&gt;Take pickle and json as an example&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-py"&gt;import pickle
import zlib
from mihomo import MihomoAPI, Language, StarrailInfoParsed

client = MihomoAPI(language=Language.EN)
data = await client.fetch_user(800333171)

# Save
pickle_data = zlib.compress(pickle.dumps(data))
print(len(pickle_data))
json_data = data.json(by_alias=True, ensure_ascii=False)
print(len(json_data))

# Load
data_from_pickle = pickle.loads(zlib.decompress(pickle_data))
data_from_json = StarrailInfoParsed.parse_raw(json_data)
print(type(data_from_pickle))
print(type(data_from_json))
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>yt-dlp/yt-dlp</title>
      <link>https://github.com/yt-dlp/yt-dlp</link>
      <description>&lt;p&gt;A feature-rich command-line audio/video downloader&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#readme"&gt;&lt;img src="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/.github/banner.svg?sanitize=true" alt="YT-DLP" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#installation" title="Installation"&gt;&lt;img src="https://img.shields.io/github/v/release/yt-dlp/yt-dlp?color=brightgreen&amp;amp;label=Download&amp;amp;style=for-the-badge" alt="Release version" /&gt;&lt;/a&gt; &lt;a href="https://pypi.org/project/yt-dlp" title="PyPI"&gt;&lt;img src="https://img.shields.io/badge/-PyPI-blue.svg?logo=pypi&amp;amp;labelColor=555555&amp;amp;style=for-the-badge" alt="PyPI" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/Maintainers.md#maintainers" title="Donate"&gt;&lt;img src="https://img.shields.io/badge/_-Donate-red.svg?logo=githubsponsors&amp;amp;labelColor=555555&amp;amp;style=for-the-badge" alt="Donate" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/H5MNcFW63r" title="Discord"&gt;&lt;img src="https://img.shields.io/discord/807245652072857610?color=blue&amp;amp;labelColor=555555&amp;amp;label=&amp;amp;logo=discord&amp;amp;style=for-the-badge" alt="Discord" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/supportedsites.md" title="Supported Sites"&gt;&lt;img src="https://img.shields.io/badge/-Supported_Sites-brightgreen.svg?style=for-the-badge" alt="Supported Sites" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/LICENSE" title="License"&gt;&lt;img src="https://img.shields.io/badge/-Unlicense-blue.svg?style=for-the-badge" alt="License: Unlicense" /&gt;&lt;/a&gt; &lt;a href="https://github.com/yt-dlp/yt-dlp/actions" title="CI Status"&gt;&lt;img src="https://img.shields.io/github/actions/workflow/status/yt-dlp/yt-dlp/core.yml?branch=master&amp;amp;label=Tests&amp;amp;style=for-the-badge" alt="CI Status" /&gt;&lt;/a&gt; &lt;a href="https://github.com/yt-dlp/yt-dlp/commits" title="Commit History"&gt;&lt;img src="https://img.shields.io/github/commit-activity/m/yt-dlp/yt-dlp?label=commits&amp;amp;style=for-the-badge" alt="Commits" /&gt;&lt;/a&gt; &lt;a href="https://github.com/yt-dlp/yt-dlp/pulse/monthly" title="Last activity"&gt;&lt;img src="https://img.shields.io/github/last-commit/yt-dlp/yt-dlp/master?label=&amp;amp;style=for-the-badge&amp;amp;display_timestamp=committer" alt="Last Commit" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;!-- MANPAGE: END EXCLUDED SECTION --&gt; 
&lt;p&gt;yt-dlp is a feature-rich command-line audio/video downloader with support for &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/supportedsites.md"&gt;thousands of sites&lt;/a&gt;. The project is a fork of &lt;a href="https://github.com/ytdl-org/youtube-dl"&gt;youtube-dl&lt;/a&gt; based on the now inactive &lt;a href="https://github.com/blackjack4494/yt-dlc"&gt;youtube-dlc&lt;/a&gt;.&lt;/p&gt; 
&lt;!-- MANPAGE: MOVE "USAGE AND OPTIONS" SECTION HERE --&gt; 
&lt;!-- MANPAGE: BEGIN EXCLUDED SECTION --&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#installation"&gt;INSTALLATION&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/wiki/Installation"&gt;Detailed instructions&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#release-files"&gt;Release Files&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#update"&gt;Update&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#dependencies"&gt;Dependencies&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#compile"&gt;Compile&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#usage-and-options"&gt;USAGE AND OPTIONS&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#general-options"&gt;General Options&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#network-options"&gt;Network Options&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#geo-restriction"&gt;Geo-restriction&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#video-selection"&gt;Video Selection&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#download-options"&gt;Download Options&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#filesystem-options"&gt;Filesystem Options&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#thumbnail-options"&gt;Thumbnail Options&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#internet-shortcut-options"&gt;Internet Shortcut Options&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#verbosity-and-simulation-options"&gt;Verbosity and Simulation Options&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#workarounds"&gt;Workarounds&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#video-format-options"&gt;Video Format Options&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#subtitle-options"&gt;Subtitle Options&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#authentication-options"&gt;Authentication Options&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#post-processing-options"&gt;Post-processing Options&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#sponsorblock-options"&gt;SponsorBlock Options&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#extractor-options"&gt;Extractor Options&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#preset-aliases"&gt;Preset Aliases&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#configuration"&gt;CONFIGURATION&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#configuration-file-encoding"&gt;Configuration file encoding&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#authentication-with-netrc"&gt;Authentication with netrc&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#notes-about-environment-variables"&gt;Notes about environment variables&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#output-template"&gt;OUTPUT TEMPLATE&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#output-template-examples"&gt;Output template examples&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#format-selection"&gt;FORMAT SELECTION&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#filtering-formats"&gt;Filtering Formats&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#sorting-formats"&gt;Sorting Formats&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#format-selection-examples"&gt;Format Selection examples&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#modifying-metadata"&gt;MODIFYING METADATA&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#modifying-metadata-examples"&gt;Modifying metadata examples&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#extractor-arguments"&gt;EXTRACTOR ARGUMENTS&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#plugins"&gt;PLUGINS&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#installing-plugins"&gt;Installing Plugins&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#developing-plugins"&gt;Developing Plugins&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#embedding-yt-dlp"&gt;EMBEDDING YT-DLP&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#embedding-examples"&gt;Embedding examples&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#changes-from-youtube-dl"&gt;CHANGES FROM YOUTUBE-DL&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#new-features"&gt;New features&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#differences-in-default-behavior"&gt;Differences in default behavior&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#deprecated-options"&gt;Deprecated options&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/CONTRIBUTING.md#contributing-to-yt-dlp"&gt;CONTRIBUTING&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/CONTRIBUTING.md#opening-an-issue"&gt;Opening an Issue&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/CONTRIBUTING.md#developer-instructions"&gt;Developer Instructions&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/wiki"&gt;WIKI&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/wiki/FAQ"&gt;FAQ&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;!-- MANPAGE: END EXCLUDED SECTION --&gt; 
&lt;h1&gt;INSTALLATION&lt;/h1&gt; 
&lt;!-- MANPAGE: BEGIN EXCLUDED SECTION --&gt; 
&lt;p&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp.exe"&gt;&lt;img src="https://img.shields.io/badge/-Windows_x64-blue.svg?style=for-the-badge&amp;amp;logo=windows" alt="Windows" /&gt;&lt;/a&gt; &lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp"&gt;&lt;img src="https://img.shields.io/badge/-Linux/BSD-red.svg?style=for-the-badge&amp;amp;logo=linux" alt="Unix" /&gt;&lt;/a&gt; &lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_macos"&gt;&lt;img src="https://img.shields.io/badge/-MacOS-lightblue.svg?style=for-the-badge&amp;amp;logo=apple" alt="MacOS" /&gt;&lt;/a&gt; &lt;a href="https://pypi.org/project/yt-dlp"&gt;&lt;img src="https://img.shields.io/badge/-PyPI-blue.svg?logo=pypi&amp;amp;labelColor=555555&amp;amp;style=for-the-badge" alt="PyPI" /&gt;&lt;/a&gt; &lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp.tar.gz"&gt;&lt;img src="https://img.shields.io/badge/-Source_tar-green.svg?style=for-the-badge" alt="Source Tarball" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#release-files"&gt;&lt;img src="https://img.shields.io/badge/-Other-grey.svg?style=for-the-badge" alt="Other variants" /&gt;&lt;/a&gt; &lt;a href="https://github.com/yt-dlp/yt-dlp/releases"&gt;&lt;img src="https://img.shields.io/badge/-All_Versions-lightgrey.svg?style=for-the-badge" alt="All versions" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;!-- MANPAGE: END EXCLUDED SECTION --&gt; 
&lt;p&gt;You can install yt-dlp using &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#release-files"&gt;the binaries&lt;/a&gt;, &lt;a href="https://pypi.org/project/yt-dlp"&gt;pip&lt;/a&gt; or one using a third-party package manager. See &lt;a href="https://github.com/yt-dlp/yt-dlp/wiki/Installation"&gt;the wiki&lt;/a&gt; for detailed instructions&lt;/p&gt; 
&lt;!-- MANPAGE: BEGIN EXCLUDED SECTION --&gt; 
&lt;h2&gt;RELEASE FILES&lt;/h2&gt; 
&lt;h4&gt;Recommended&lt;/h4&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;File&lt;/th&gt; 
   &lt;th align="left"&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp"&gt;yt-dlp&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Platform-independent &lt;a href="https://docs.python.org/3/library/zipimport.html"&gt;zipimport&lt;/a&gt; binary. Needs Python (recommended for &lt;strong&gt;Linux/BSD&lt;/strong&gt;)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp.exe"&gt;yt-dlp.exe&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Windows (Win8+) standalone x64 binary (recommended for &lt;strong&gt;Windows&lt;/strong&gt;)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_macos"&gt;yt-dlp_macos&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Universal MacOS (10.15+) standalone executable (recommended for &lt;strong&gt;MacOS&lt;/strong&gt;)&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h4&gt;Alternatives&lt;/h4&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;File&lt;/th&gt; 
   &lt;th align="left"&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_linux"&gt;yt-dlp_linux&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Linux (glibc 2.17+) standalone x86_64 binary&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_linux.zip"&gt;yt-dlp_linux.zip&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Unpackaged Linux (glibc 2.17+) x86_64 executable (no auto-update)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_linux_aarch64"&gt;yt-dlp_linux_aarch64&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Linux (glibc 2.17+) standalone aarch64 binary&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_linux_aarch64.zip"&gt;yt-dlp_linux_aarch64.zip&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Unpackaged Linux (glibc 2.17+) aarch64 executable (no auto-update)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_linux_armv7l.zip"&gt;yt-dlp_linux_armv7l.zip&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Unpackaged Linux (glibc 2.31+) armv7l executable (no auto-update)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_musllinux"&gt;yt-dlp_musllinux&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Linux (musl 1.2+) standalone x86_64 binary&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_musllinux.zip"&gt;yt-dlp_musllinux.zip&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Unpackaged Linux (musl 1.2+) x86_64 executable (no auto-update)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_musllinux_aarch64"&gt;yt-dlp_musllinux_aarch64&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Linux (musl 1.2+) standalone aarch64 binary&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_musllinux_aarch64.zip"&gt;yt-dlp_musllinux_aarch64.zip&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Unpackaged Linux (musl 1.2+) aarch64 executable (no auto-update)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_x86.exe"&gt;yt-dlp_x86.exe&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Windows (Win8+) standalone x86 (32-bit) binary&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_win_x86.zip"&gt;yt-dlp_win_x86.zip&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Unpackaged Windows (Win8+) x86 (32-bit) executable (no auto-update)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_arm64.exe"&gt;yt-dlp_arm64.exe&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Windows (Win10+) standalone ARM64 binary&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_win_arm64.zip"&gt;yt-dlp_win_arm64.zip&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Unpackaged Windows (Win10+) ARM64 executable (no auto-update)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_win.zip"&gt;yt-dlp_win.zip&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Unpackaged Windows (Win8+) x64 executable (no auto-update)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_macos.zip"&gt;yt-dlp_macos.zip&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Unpackaged MacOS (10.15+) executable (no auto-update)&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h4&gt;Misc&lt;/h4&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;File&lt;/th&gt; 
   &lt;th align="left"&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp.tar.gz"&gt;yt-dlp.tar.gz&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Source tarball&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/SHA2-512SUMS"&gt;SHA2-512SUMS&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;GNU-style SHA512 sums&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/SHA2-512SUMS.sig"&gt;SHA2-512SUMS.sig&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;GPG signature file for SHA512 sums&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/SHA2-256SUMS"&gt;SHA2-256SUMS&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;GNU-style SHA256 sums&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/SHA2-256SUMS.sig"&gt;SHA2-256SUMS.sig&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;GPG signature file for SHA256 sums&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;The public key that can be used to verify the GPG signatures is &lt;a href="https://github.com/yt-dlp/yt-dlp/raw/master/public.key"&gt;available here&lt;/a&gt; Example usage:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;curl -L https://github.com/yt-dlp/yt-dlp/raw/master/public.key | gpg --import
gpg --verify SHA2-256SUMS.sig SHA2-256SUMS
gpg --verify SHA2-512SUMS.sig SHA2-512SUMS
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Licensing&lt;/h4&gt; 
&lt;p&gt;While yt-dlp is licensed under the &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/LICENSE"&gt;Unlicense&lt;/a&gt;, many of the release files contain code from other projects with different licenses.&lt;/p&gt; 
&lt;p&gt;Most notably, the PyInstaller-bundled executables include GPLv3+ licensed code, and as such the combined work is licensed under &lt;a href="https://www.gnu.org/licenses/gpl-3.0.html"&gt;GPLv3+&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;The zipimport Unix executable (&lt;code&gt;yt-dlp&lt;/code&gt;) contains &lt;a href="https://github.com/meriyah/meriyah/raw/main/LICENSE.md"&gt;ISC&lt;/a&gt; licensed code from &lt;a href="https://github.com/meriyah/meriyah"&gt;&lt;code&gt;meriyah&lt;/code&gt;&lt;/a&gt; and &lt;a href="https://github.com/davidbonnet/astring/raw/main/LICENSE"&gt;MIT&lt;/a&gt; licensed code from &lt;a href="https://github.com/davidbonnet/astring"&gt;&lt;code&gt;astring&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/THIRD_PARTY_LICENSES.txt"&gt;THIRD_PARTY_LICENSES.txt&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;p&gt;The git repository, the source tarball (&lt;code&gt;yt-dlp.tar.gz&lt;/code&gt;), the PyPI source distribution and the PyPI built distribution (wheel) only contain code licensed under the &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/LICENSE"&gt;Unlicense&lt;/a&gt;.&lt;/p&gt; 
&lt;!-- MANPAGE: END EXCLUDED SECTION --&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: The manpages, shell completion (autocomplete) files etc. are available inside the &lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp.tar.gz"&gt;source tarball&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;UPDATE&lt;/h2&gt; 
&lt;p&gt;You can use &lt;code&gt;yt-dlp -U&lt;/code&gt; to update if you are using the &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#release-files"&gt;release binaries&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;If you &lt;a href="https://github.com/yt-dlp/yt-dlp/wiki/Installation#with-pip"&gt;installed with pip&lt;/a&gt;, simply re-run the same command that was used to install the program&lt;/p&gt; 
&lt;p&gt;For other third-party package managers, see &lt;a href="https://github.com/yt-dlp/yt-dlp/wiki/Installation#third-party-package-managers"&gt;the wiki&lt;/a&gt; or refer to their documentation&lt;/p&gt; 
&lt;p&gt;&lt;a id="update-channels"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;There are currently three release channels for binaries: &lt;code&gt;stable&lt;/code&gt;, &lt;code&gt;nightly&lt;/code&gt; and &lt;code&gt;master&lt;/code&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;stable&lt;/code&gt; is the default channel, and many of its changes have been tested by users of the &lt;code&gt;nightly&lt;/code&gt; and &lt;code&gt;master&lt;/code&gt; channels.&lt;/li&gt; 
 &lt;li&gt;The &lt;code&gt;nightly&lt;/code&gt; channel has releases scheduled to build every day around midnight UTC, for a snapshot of the project's new patches and changes. This is the &lt;strong&gt;recommended channel for regular users&lt;/strong&gt; of yt-dlp. The &lt;code&gt;nightly&lt;/code&gt; releases are available from &lt;a href="https://github.com/yt-dlp/yt-dlp-nightly-builds/releases"&gt;yt-dlp/yt-dlp-nightly-builds&lt;/a&gt; or as development releases of the &lt;code&gt;yt-dlp&lt;/code&gt; PyPI package (which can be installed with pip's &lt;code&gt;--pre&lt;/code&gt; flag).&lt;/li&gt; 
 &lt;li&gt;The &lt;code&gt;master&lt;/code&gt; channel features releases that are built after each push to the master branch, and these will have the very latest fixes and additions, but may also be more prone to regressions. They are available from &lt;a href="https://github.com/yt-dlp/yt-dlp-master-builds/releases"&gt;yt-dlp/yt-dlp-master-builds&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;When using &lt;code&gt;--update&lt;/code&gt;/&lt;code&gt;-U&lt;/code&gt;, a release binary will only update to its current channel. &lt;code&gt;--update-to CHANNEL&lt;/code&gt; can be used to switch to a different channel when a newer version is available. &lt;code&gt;--update-to [CHANNEL@]TAG&lt;/code&gt; can also be used to upgrade or downgrade to specific tags from a channel.&lt;/p&gt; 
&lt;p&gt;You may also use &lt;code&gt;--update-to &amp;lt;repository&amp;gt;&lt;/code&gt; (&lt;code&gt;&amp;lt;owner&amp;gt;/&amp;lt;repository&amp;gt;&lt;/code&gt;) to update to a channel on a completely different repository. Be careful with what repository you are updating to though, there is no verification done for binaries from different repositories.&lt;/p&gt; 
&lt;p&gt;Example usage:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;yt-dlp --update-to master&lt;/code&gt; switch to the &lt;code&gt;master&lt;/code&gt; channel and update to its latest release&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;yt-dlp --update-to stable@2023.07.06&lt;/code&gt; upgrade/downgrade to release to &lt;code&gt;stable&lt;/code&gt; channel tag &lt;code&gt;2023.07.06&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;yt-dlp --update-to 2023.10.07&lt;/code&gt; upgrade/downgrade to tag &lt;code&gt;2023.10.07&lt;/code&gt; if it exists on the current channel&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;yt-dlp --update-to example/yt-dlp@2023.09.24&lt;/code&gt; upgrade/downgrade to the release from the &lt;code&gt;example/yt-dlp&lt;/code&gt; repository, tag &lt;code&gt;2023.09.24&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Important&lt;/strong&gt;: Any user experiencing an issue with the &lt;code&gt;stable&lt;/code&gt; release should install or update to the &lt;code&gt;nightly&lt;/code&gt; release before submitting a bug report:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;# To update to nightly from stable executable/binary:
yt-dlp --update-to nightly

# To install nightly with pip:
python3 -m pip install -U --pre "yt-dlp[default]"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;When running a yt-dlp version that is older than 90 days, you will see a warning message suggesting to update to the latest version. You can suppress this warning by adding &lt;code&gt;--no-update&lt;/code&gt; to your command or configuration file.&lt;/p&gt; 
&lt;h2&gt;DEPENDENCIES&lt;/h2&gt; 
&lt;p&gt;Python versions 3.10+ (CPython) and 3.11+ (PyPy) are supported. Other versions and implementations may or may not work correctly.&lt;/p&gt; 
&lt;!-- Python 3.5+ uses VC++14 and it is already embedded in the binary created
&lt;!x-- https://www.microsoft.com/en-us/download/details.aspx?id=26999 --x&gt;
On Windows, [Microsoft Visual C++ 2010 SP1 Redistributable Package (x86)](https://download.microsoft.com/download/1/6/5/165255E7-1014-4D0A-B094-B6A430A6BFFC/vcredist_x86.exe) is also necessary to run yt-dlp. You probably already have this, but if the executable throws an error due to missing `MSVCR100.dll` you need to install it manually.
--&gt; 
&lt;p&gt;While all the other dependencies are optional, &lt;code&gt;ffmpeg&lt;/code&gt;, &lt;code&gt;ffprobe&lt;/code&gt;, &lt;code&gt;yt-dlp-ejs&lt;/code&gt; and a JavaScript runtime are highly recommended&lt;/p&gt; 
&lt;h3&gt;Strongly recommended&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://www.ffmpeg.org"&gt;&lt;strong&gt;ffmpeg&lt;/strong&gt; and &lt;strong&gt;ffprobe&lt;/strong&gt;&lt;/a&gt; - Required for &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#format-selection"&gt;merging separate video and audio files&lt;/a&gt;, as well as for various &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#post-processing-options"&gt;post-processing&lt;/a&gt; tasks. License &lt;a href="https://www.ffmpeg.org/legal.html"&gt;depends on the build&lt;/a&gt;&lt;/p&gt; &lt;p&gt;There are bugs in ffmpeg that cause various issues when used alongside yt-dlp. Since ffmpeg is such an important dependency, we provide &lt;a href="https://github.com/yt-dlp/FFmpeg-Builds#ffmpeg-static-auto-builds"&gt;custom builds&lt;/a&gt; with patches for some of these issues at &lt;a href="https://github.com/yt-dlp/FFmpeg-Builds"&gt;yt-dlp/FFmpeg-Builds&lt;/a&gt;. See &lt;a href="https://github.com/yt-dlp/FFmpeg-Builds#patches-applied"&gt;the readme&lt;/a&gt; for details on the specific issues solved by these builds&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Important&lt;/strong&gt;: What you need is ffmpeg &lt;em&gt;binary&lt;/em&gt;, &lt;strong&gt;NOT&lt;/strong&gt; &lt;a href="https://pypi.org/project/ffmpeg"&gt;the Python package of the same name&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/yt-dlp/ejs"&gt;&lt;strong&gt;yt-dlp-ejs&lt;/strong&gt;&lt;/a&gt; - Required for deciphering YouTube n/sig values. Licensed under &lt;a href="https://github.com/yt-dlp/ejs/raw/main/LICENSE"&gt;Unlicense&lt;/a&gt;, bundles &lt;a href="https://github.com/davidbonnet/astring/raw/main/LICENSE"&gt;MIT&lt;/a&gt; and &lt;a href="https://github.com/meriyah/meriyah/raw/main/LICENSE.md"&gt;ISC&lt;/a&gt; components.&lt;/p&gt; &lt;p&gt;A JavaScript runtime like &lt;a href="https://deno.land"&gt;&lt;strong&gt;deno&lt;/strong&gt;&lt;/a&gt; (recommended), &lt;a href="https://nodejs.org"&gt;&lt;strong&gt;node.js&lt;/strong&gt;&lt;/a&gt;, &lt;a href="https://bun.sh"&gt;&lt;strong&gt;bun&lt;/strong&gt;&lt;/a&gt;, or &lt;a href="https://bellard.org/quickjs/"&gt;&lt;strong&gt;QuickJS&lt;/strong&gt;&lt;/a&gt; is also required to run yt-dlp-ejs. See &lt;a href="https://github.com/yt-dlp/yt-dlp/wiki/EJS"&gt;the wiki&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Networking&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/certifi/python-certifi"&gt;&lt;strong&gt;certifi&lt;/strong&gt;&lt;/a&gt;* - Provides Mozilla's root certificate bundle. Licensed under &lt;a href="https://github.com/certifi/python-certifi/raw/master/LICENSE"&gt;MPLv2&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/google/brotli"&gt;&lt;strong&gt;brotli&lt;/strong&gt;&lt;/a&gt;* or &lt;a href="https://github.com/python-hyper/brotlicffi"&gt;&lt;strong&gt;brotlicffi&lt;/strong&gt;&lt;/a&gt; - &lt;a href="https://en.wikipedia.org/wiki/Brotli"&gt;Brotli&lt;/a&gt; content encoding support. Both licensed under MIT &lt;sup&gt;&lt;a href="https://github.com/google/brotli/raw/master/LICENSE"&gt;1&lt;/a&gt; &lt;a href="https://github.com/python-hyper/brotlicffi/raw/master/LICENSE"&gt;2&lt;/a&gt; &lt;/sup&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/aaugustin/websockets"&gt;&lt;strong&gt;websockets&lt;/strong&gt;&lt;/a&gt;* - For downloading over websocket. Licensed under &lt;a href="https://github.com/aaugustin/websockets/raw/main/LICENSE"&gt;BSD-3-Clause&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/psf/requests"&gt;&lt;strong&gt;requests&lt;/strong&gt;&lt;/a&gt;* - HTTP library. For HTTPS proxy and persistent connections support. Licensed under &lt;a href="https://github.com/psf/requests/raw/main/LICENSE"&gt;Apache-2.0&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Impersonation&lt;/h4&gt; 
&lt;p&gt;The following provide support for impersonating browser requests. This may be required for some sites that employ TLS fingerprinting.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/lexiforest/curl_cffi"&gt;&lt;strong&gt;curl_cffi&lt;/strong&gt;&lt;/a&gt; (recommended) - Python binding for &lt;a href="https://github.com/lexiforest/curl-impersonate"&gt;curl-impersonate&lt;/a&gt;. Provides impersonation targets for Chrome, Edge and Safari. Licensed under &lt;a href="https://github.com/lexiforest/curl_cffi/raw/main/LICENSE"&gt;MIT&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Can be installed with the &lt;code&gt;curl-cffi&lt;/code&gt; group, e.g. &lt;code&gt;pip install "yt-dlp[default,curl-cffi]"&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;Currently included in most builds &lt;em&gt;except&lt;/em&gt; &lt;code&gt;yt-dlp&lt;/code&gt; (Unix zipimport binary), &lt;code&gt;yt-dlp_x86&lt;/code&gt; (Windows 32-bit) and &lt;code&gt;yt-dlp_musllinux_aarch64&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Metadata&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/quodlibet/mutagen"&gt;&lt;strong&gt;mutagen&lt;/strong&gt;&lt;/a&gt;* - For &lt;code&gt;--embed-thumbnail&lt;/code&gt; in certain formats. Licensed under &lt;a href="https://github.com/quodlibet/mutagen/raw/master/COPYING"&gt;GPLv2+&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/wez/atomicparsley"&gt;&lt;strong&gt;AtomicParsley&lt;/strong&gt;&lt;/a&gt; - For &lt;code&gt;--embed-thumbnail&lt;/code&gt; in &lt;code&gt;mp4&lt;/code&gt;/&lt;code&gt;m4a&lt;/code&gt; files when &lt;code&gt;mutagen&lt;/code&gt;/&lt;code&gt;ffmpeg&lt;/code&gt; cannot. Licensed under &lt;a href="https://github.com/wez/atomicparsley/raw/master/COPYING"&gt;GPLv2+&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/xattr/xattr"&gt;&lt;strong&gt;xattr&lt;/strong&gt;&lt;/a&gt;, &lt;a href="https://github.com/iustin/pyxattr"&gt;&lt;strong&gt;pyxattr&lt;/strong&gt;&lt;/a&gt; or &lt;a href="http://savannah.nongnu.org/projects/attr"&gt;&lt;strong&gt;setfattr&lt;/strong&gt;&lt;/a&gt; - For writing xattr metadata (&lt;code&gt;--xattrs&lt;/code&gt;) on &lt;strong&gt;Mac&lt;/strong&gt; and &lt;strong&gt;BSD&lt;/strong&gt;. Licensed under &lt;a href="https://github.com/xattr/xattr/raw/master/LICENSE.txt"&gt;MIT&lt;/a&gt;, &lt;a href="https://github.com/iustin/pyxattr/raw/master/COPYING"&gt;LGPL2.1&lt;/a&gt; and &lt;a href="http://git.savannah.nongnu.org/cgit/attr.git/tree/doc/COPYING"&gt;GPLv2+&lt;/a&gt; respectively&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Misc&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Legrandin/pycryptodome"&gt;&lt;strong&gt;pycryptodomex&lt;/strong&gt;&lt;/a&gt;* - For decrypting AES-128 HLS streams and various other data. Licensed under &lt;a href="https://github.com/Legrandin/pycryptodome/raw/master/LICENSE.rst"&gt;BSD-2-Clause&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ariya/phantomjs"&gt;&lt;strong&gt;phantomjs&lt;/strong&gt;&lt;/a&gt; - Used in some extractors where JavaScript needs to be run. No longer used for YouTube. To be deprecated in the near future. Licensed under &lt;a href="https://github.com/ariya/phantomjs/raw/master/LICENSE.BSD"&gt;BSD-3-Clause&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mitya57/secretstorage"&gt;&lt;strong&gt;secretstorage&lt;/strong&gt;&lt;/a&gt;* - For &lt;code&gt;--cookies-from-browser&lt;/code&gt; to access the &lt;strong&gt;Gnome&lt;/strong&gt; keyring while decrypting cookies of &lt;strong&gt;Chromium&lt;/strong&gt;-based browsers on &lt;strong&gt;Linux&lt;/strong&gt;. Licensed under &lt;a href="https://github.com/mitya57/secretstorage/raw/master/LICENSE"&gt;BSD-3-Clause&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Any external downloader that you want to use with &lt;code&gt;--downloader&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Deprecated&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="http://rtmpdump.mplayerhq.hu"&gt;&lt;strong&gt;rtmpdump&lt;/strong&gt;&lt;/a&gt; - For downloading &lt;code&gt;rtmp&lt;/code&gt; streams. ffmpeg can be used instead with &lt;code&gt;--downloader ffmpeg&lt;/code&gt;. Licensed under &lt;a href="http://rtmpdump.mplayerhq.hu"&gt;GPLv2+&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://mplayerhq.hu/design7/info.html"&gt;&lt;strong&gt;mplayer&lt;/strong&gt;&lt;/a&gt; or &lt;a href="https://mpv.io"&gt;&lt;strong&gt;mpv&lt;/strong&gt;&lt;/a&gt; - For downloading &lt;code&gt;rstp&lt;/code&gt;/&lt;code&gt;mms&lt;/code&gt; streams. ffmpeg can be used instead with &lt;code&gt;--downloader ffmpeg&lt;/code&gt;. Licensed under &lt;a href="https://github.com/mpv-player/mpv/raw/master/Copyright"&gt;GPLv2+&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;To use or redistribute the dependencies, you must agree to their respective licensing terms.&lt;/p&gt; 
&lt;p&gt;The standalone release binaries are built with the Python interpreter and the packages marked with &lt;strong&gt;*&lt;/strong&gt; included.&lt;/p&gt; 
&lt;p&gt;If you do not have the necessary dependencies for a task you are attempting, yt-dlp will warn you. All the currently available dependencies are visible at the top of the &lt;code&gt;--verbose&lt;/code&gt; output&lt;/p&gt; 
&lt;h2&gt;COMPILE&lt;/h2&gt; 
&lt;h3&gt;Standalone PyInstaller Builds&lt;/h3&gt; 
&lt;p&gt;To build the standalone executable, you must have Python and &lt;code&gt;pyinstaller&lt;/code&gt; (plus any of yt-dlp's &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#dependencies"&gt;optional dependencies&lt;/a&gt; if needed). The executable will be built for the same CPU architecture as the Python used.&lt;/p&gt; 
&lt;p&gt;You can run the following commands:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;python3 devscripts/install_deps.py --include pyinstaller
python3 devscripts/make_lazy_extractors.py
python3 -m bundle.pyinstaller
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;On some systems, you may need to use &lt;code&gt;py&lt;/code&gt; or &lt;code&gt;python&lt;/code&gt; instead of &lt;code&gt;python3&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;python -m bundle.pyinstaller&lt;/code&gt; accepts any arguments that can be passed to &lt;code&gt;pyinstaller&lt;/code&gt;, such as &lt;code&gt;--onefile/-F&lt;/code&gt; or &lt;code&gt;--onedir/-D&lt;/code&gt;, which is further &lt;a href="https://pyinstaller.org/en/stable/usage.html#what-to-generate"&gt;documented here&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: Pyinstaller versions below 4.4 &lt;a href="https://github.com/pyinstaller/pyinstaller#requirements-and-tested-platforms"&gt;do not support&lt;/a&gt; Python installed from the Windows store without using a virtual environment.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Important&lt;/strong&gt;: Running &lt;code&gt;pyinstaller&lt;/code&gt; directly &lt;strong&gt;instead of&lt;/strong&gt; using &lt;code&gt;python -m bundle.pyinstaller&lt;/code&gt; is &lt;strong&gt;not&lt;/strong&gt; officially supported. This may or may not work correctly.&lt;/p&gt; 
&lt;h3&gt;Platform-independent Binary (UNIX)&lt;/h3&gt; 
&lt;p&gt;You will need the build tools &lt;code&gt;python&lt;/code&gt; (3.10+), &lt;code&gt;zip&lt;/code&gt;, &lt;code&gt;make&lt;/code&gt; (GNU), &lt;code&gt;pandoc&lt;/code&gt;* and &lt;code&gt;pytest&lt;/code&gt;*.&lt;/p&gt; 
&lt;p&gt;After installing these, simply run &lt;code&gt;make&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;You can also run &lt;code&gt;make yt-dlp&lt;/code&gt; instead to compile only the binary without updating any of the additional files. (The build tools marked with &lt;strong&gt;*&lt;/strong&gt; are not needed for this)&lt;/p&gt; 
&lt;h3&gt;Related scripts&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;devscripts/install_deps.py&lt;/code&gt;&lt;/strong&gt; - Install dependencies for yt-dlp.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;devscripts/update-version.py&lt;/code&gt;&lt;/strong&gt; - Update the version number based on the current date.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;devscripts/set-variant.py&lt;/code&gt;&lt;/strong&gt; - Set the build variant of the executable.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;devscripts/make_changelog.py&lt;/code&gt;&lt;/strong&gt; - Create a markdown changelog using short commit messages and update &lt;code&gt;CONTRIBUTORS&lt;/code&gt; file.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;devscripts/make_lazy_extractors.py&lt;/code&gt;&lt;/strong&gt; - Create lazy extractors. Running this before building the binaries (any variant) will improve their startup performance. Set the environment variable &lt;code&gt;YTDLP_NO_LAZY_EXTRACTORS&lt;/code&gt; to something nonempty to forcefully disable lazy extractor loading.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Note: See their &lt;code&gt;--help&lt;/code&gt; for more info.&lt;/p&gt; 
&lt;h3&gt;Forking the project&lt;/h3&gt; 
&lt;p&gt;If you fork the project on GitHub, you can run your fork's &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/.github/workflows/build.yml"&gt;build workflow&lt;/a&gt; to automatically build the selected version(s) as artifacts. Alternatively, you can run the &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/.github/workflows/release.yml"&gt;release workflow&lt;/a&gt; or enable the &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/.github/workflows/release-nightly.yml"&gt;nightly workflow&lt;/a&gt; to create full (pre-)releases.&lt;/p&gt; 
&lt;h1&gt;USAGE AND OPTIONS&lt;/h1&gt; 
&lt;!-- MANPAGE: BEGIN EXCLUDED SECTION --&gt; 
&lt;pre&gt;&lt;code&gt;yt-dlp [OPTIONS] [--] URL [URL...]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Tip: Use &lt;code&gt;CTRL&lt;/code&gt;+&lt;code&gt;F&lt;/code&gt; (or &lt;code&gt;Command&lt;/code&gt;+&lt;code&gt;F&lt;/code&gt;) to search by keywords&lt;/p&gt; 
&lt;!-- MANPAGE: END EXCLUDED SECTION --&gt; 
&lt;!-- Auto generated --&gt; 
&lt;h2&gt;General Options:&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;-h, --help                      Print this help text and exit
--version                       Print program version and exit
-U, --update                    Update this program to the latest version
--no-update                     Do not check for updates (default)
--update-to [CHANNEL]@[TAG]     Upgrade/downgrade to a specific version.
                                CHANNEL can be a repository as well. CHANNEL
                                and TAG default to "stable" and "latest"
                                respectively if omitted; See "UPDATE" for
                                details. Supported channels: stable,
                                nightly, master
-i, --ignore-errors             Ignore download and postprocessing errors.
                                The download will be considered successful
                                even if the postprocessing fails
--no-abort-on-error             Continue with next video on download errors;
                                e.g. to skip unavailable videos in a
                                playlist (default)
--abort-on-error                Abort downloading of further videos if an
                                error occurs (Alias: --no-ignore-errors)
--list-extractors               List all supported extractors and exit
--extractor-descriptions        Output descriptions of all supported
                                extractors and exit
--use-extractors NAMES          Extractor names to use separated by commas.
                                You can also use regexes, "all", "default"
                                and "end" (end URL matching); e.g. --ies
                                "holodex.*,end,youtube". Prefix the name
                                with a "-" to exclude it, e.g. --ies
                                default,-generic. Use --list-extractors for
                                a list of extractor names. (Alias: --ies)
--default-search PREFIX         Use this prefix for unqualified URLs. E.g.
                                "gvsearch2:python" downloads two videos from
                                google videos for the search term "python".
                                Use the value "auto" to let yt-dlp guess
                                ("auto_warning" to emit a warning when
                                guessing). "error" just throws an error. The
                                default value "fixup_error" repairs broken
                                URLs, but emits an error if this is not
                                possible instead of searching
--ignore-config                 Don't load any more configuration files
                                except those given to --config-locations.
                                For backward compatibility, if this option
                                is found inside the system configuration
                                file, the user configuration is not loaded.
                                (Alias: --no-config)
--no-config-locations           Do not load any custom configuration files
                                (default). When given inside a configuration
                                file, ignore all previous --config-locations
                                defined in the current file
--config-locations PATH         Location of the main configuration file;
                                either the path to the config or its
                                containing directory ("-" for stdin). Can be
                                used multiple times and inside other
                                configuration files
--plugin-dirs DIR               Path to an additional directory to search
                                for plugins. This option can be used
                                multiple times to add multiple directories.
                                Use "default" to search the default plugin
                                directories (default)
--no-plugin-dirs                Clear plugin directories to search,
                                including defaults and those provided by
                                previous --plugin-dirs
--js-runtimes RUNTIME[:PATH]    Additional JavaScript runtime to enable,
                                with an optional location for the runtime
                                (either the path to the binary or its
                                containing directory). This option can be
                                used multiple times to enable multiple
                                runtimes. Supported runtimes are (in order
                                of priority, from highest to lowest): deno,
                                node, quickjs, bun. Only "deno" is enabled
                                by default. The highest priority runtime
                                that is both enabled and available will be
                                used. In order to use a lower priority
                                runtime when "deno" is available, --no-js-
                                runtimes needs to be passed before enabling
                                other runtimes
--no-js-runtimes                Clear JavaScript runtimes to enable,
                                including defaults and those provided by
                                previous --js-runtimes
--remote-components COMPONENT   Remote components to allow yt-dlp to fetch
                                when required. This option is currently not
                                needed if you are using an official
                                executable or have the requisite version of
                                the yt-dlp-ejs package installed. You can
                                use this option multiple times to allow
                                multiple components. Supported values:
                                ejs:npm (external JavaScript components from
                                npm), ejs:github (external JavaScript
                                components from yt-dlp-ejs GitHub). By
                                default, no remote components are allowed
--no-remote-components          Disallow fetching of all remote components,
                                including any previously allowed by
                                --remote-components or defaults.
--flat-playlist                 Do not extract a playlist's URL result
                                entries; some entry metadata may be missing
                                and downloading may be bypassed
--no-flat-playlist              Fully extract the videos of a playlist
                                (default)
--live-from-start               Download livestreams from the start.
                                Currently experimental and only supported
                                for YouTube and Twitch
--no-live-from-start            Download livestreams from the current time
                                (default)
--wait-for-video MIN[-MAX]      Wait for scheduled streams to become
                                available. Pass the minimum number of
                                seconds (or range) to wait between retries
--no-wait-for-video             Do not wait for scheduled streams (default)
--mark-watched                  Mark videos watched (even with --simulate)
--no-mark-watched               Do not mark videos watched (default)
--color [STREAM:]POLICY         Whether to emit color codes in output,
                                optionally prefixed by the STREAM (stdout or
                                stderr) to apply the setting to. Can be one
                                of "always", "auto" (default), "never", or
                                "no_color" (use non color terminal
                                sequences). Use "auto-tty" or "no_color-tty"
                                to decide based on terminal support only.
                                Can be used multiple times
--compat-options OPTS           Options that can help keep compatibility
                                with youtube-dl or youtube-dlc
                                configurations by reverting some of the
                                changes made in yt-dlp. See "Differences in
                                default behavior" for details
--alias ALIASES OPTIONS         Create aliases for an option string. Unless
                                an alias starts with a dash "-", it is
                                prefixed with "--". Arguments are parsed
                                according to the Python string formatting
                                mini-language. E.g. --alias get-audio,-X "-S
                                aext:{0},abr -x --audio-format {0}" creates
                                options "--get-audio" and "-X" that takes an
                                argument (ARG0) and expands to "-S
                                aext:ARG0,abr -x --audio-format ARG0". All
                                defined aliases are listed in the --help
                                output. Alias options can trigger more
                                aliases; so be careful to avoid defining
                                recursive options. As a safety measure, each
                                alias may be triggered a maximum of 100
                                times. This option can be used multiple times
-t, --preset-alias PRESET       Applies a predefined set of options. e.g.
                                --preset-alias mp3. The following presets
                                are available: mp3, aac, mp4, mkv, sleep.
                                See the "Preset Aliases" section at the end
                                for more info. This option can be used
                                multiple times
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Network Options:&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;--proxy URL                     Use the specified HTTP/HTTPS/SOCKS proxy. To
                                enable SOCKS proxy, specify a proper scheme,
                                e.g. socks5://user:pass@127.0.0.1:1080/.
                                Pass in an empty string (--proxy "") for
                                direct connection
--socket-timeout SECONDS        Time to wait before giving up, in seconds
--source-address IP             Client-side IP address to bind to
--impersonate CLIENT[:OS]       Client to impersonate for requests. E.g.
                                chrome, chrome-110, chrome:windows-10. Pass
                                --impersonate="" to impersonate any client.
                                Note that forcing impersonation for all
                                requests may have a detrimental impact on
                                download speed and stability
--list-impersonate-targets      List available clients to impersonate.
-4, --force-ipv4                Make all connections via IPv4
-6, --force-ipv6                Make all connections via IPv6
--enable-file-urls              Enable file:// URLs. This is disabled by
                                default for security reasons.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Geo-restriction:&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;--geo-verification-proxy URL    Use this proxy to verify the IP address for
                                some geo-restricted sites. The default proxy
                                specified by --proxy (or none, if the option
                                is not present) is used for the actual
                                downloading
--xff VALUE                     How to fake X-Forwarded-For HTTP header to
                                try bypassing geographic restriction. One of
                                "default" (only when known to be useful),
                                "never", an IP block in CIDR notation, or a
                                two-letter ISO 3166-2 country code
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Video Selection:&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;-I, --playlist-items ITEM_SPEC  Comma separated playlist_index of the items
                                to download. You can specify a range using
                                "[START]:[STOP][:STEP]". For backward
                                compatibility, START-STOP is also supported.
                                Use negative indices to count from the right
                                and negative STEP to download in reverse
                                order. E.g. "-I 1:3,7,-5::2" used on a
                                playlist of size 15 will download the items
                                at index 1,2,3,7,11,13,15
--min-filesize SIZE             Abort download if filesize is smaller than
                                SIZE, e.g. 50k or 44.6M
--max-filesize SIZE             Abort download if filesize is larger than
                                SIZE, e.g. 50k or 44.6M
--date DATE                     Download only videos uploaded on this date.
                                The date can be "YYYYMMDD" or in the format 
                                [now|today|yesterday][-N[day|week|month|year]].
                                E.g. "--date today-2weeks" downloads only
                                videos uploaded on the same day two weeks ago
--datebefore DATE               Download only videos uploaded on or before
                                this date. The date formats accepted are the
                                same as --date
--dateafter DATE                Download only videos uploaded on or after
                                this date. The date formats accepted are the
                                same as --date
--match-filters FILTER          Generic video filter. Any "OUTPUT TEMPLATE"
                                field can be compared with a number or a
                                string using the operators defined in
                                "Filtering Formats". You can also simply
                                specify a field to match if the field is
                                present, use "!field" to check if the field
                                is not present, and "&amp;amp;" to check multiple
                                conditions. Use a "\" to escape "&amp;amp;" or
                                quotes if needed. If used multiple times,
                                the filter matches if at least one of the
                                conditions is met. E.g. --match-filters
                                !is_live --match-filters "like_count&amp;gt;?100 &amp;amp;
                                description~='(?i)\bcats \&amp;amp; dogs\b'" matches
                                only videos that are not live OR those that
                                have a like count more than 100 (or the like
                                field is not available) and also has a
                                description that contains the phrase "cats &amp;amp;
                                dogs" (caseless). Use "--match-filters -" to
                                interactively ask whether to download each
                                video
--no-match-filters              Do not use any --match-filters (default)
--break-match-filters FILTER    Same as "--match-filters" but stops the
                                download process when a video is rejected
--no-break-match-filters        Do not use any --break-match-filters (default)
--no-playlist                   Download only the video, if the URL refers
                                to a video and a playlist
--yes-playlist                  Download the playlist, if the URL refers to
                                a video and a playlist
--age-limit YEARS               Download only videos suitable for the given
                                age
--download-archive FILE         Download only videos not listed in the
                                archive file. Record the IDs of all
                                downloaded videos in it
--no-download-archive           Do not use archive file (default)
--max-downloads NUMBER          Abort after downloading NUMBER files
--break-on-existing             Stop the download process when encountering
                                a file that is in the archive supplied with
                                the --download-archive option
--no-break-on-existing          Do not stop the download process when
                                encountering a file that is in the archive
                                (default)
--break-per-input               Alters --max-downloads, --break-on-existing,
                                --break-match-filters, and autonumber to
                                reset per input URL
--no-break-per-input            --break-on-existing and similar options
                                terminates the entire download queue
--skip-playlist-after-errors N  Number of allowed failures until the rest of
                                the playlist is skipped
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Download Options:&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;-N, --concurrent-fragments N    Number of fragments of a dash/hlsnative
                                video that should be downloaded concurrently
                                (default is 1)
-r, --limit-rate RATE           Maximum download rate in bytes per second,
                                e.g. 50K or 4.2M
--throttled-rate RATE           Minimum download rate in bytes per second
                                below which throttling is assumed and the
                                video data is re-extracted, e.g. 100K
-R, --retries RETRIES           Number of retries (default is 10), or
                                "infinite"
--file-access-retries RETRIES   Number of times to retry on file access
                                error (default is 3), or "infinite"
--fragment-retries RETRIES      Number of retries for a fragment (default is
                                10), or "infinite" (DASH, hlsnative and ISM)
--retry-sleep [TYPE:]EXPR       Time to sleep between retries in seconds
                                (optionally) prefixed by the type of retry
                                (http (default), fragment, file_access,
                                extractor) to apply the sleep to. EXPR can
                                be a number, linear=START[:END[:STEP=1]] or
                                exp=START[:END[:BASE=2]]. This option can be
                                used multiple times to set the sleep for the
                                different retry types, e.g. --retry-sleep
                                linear=1::2 --retry-sleep fragment:exp=1:20
--skip-unavailable-fragments    Skip unavailable fragments for DASH,
                                hlsnative and ISM downloads (default)
                                (Alias: --no-abort-on-unavailable-fragments)
--abort-on-unavailable-fragments
                                Abort download if a fragment is unavailable
                                (Alias: --no-skip-unavailable-fragments)
--keep-fragments                Keep downloaded fragments on disk after
                                downloading is finished
--no-keep-fragments             Delete downloaded fragments after
                                downloading is finished (default)
--buffer-size SIZE              Size of download buffer, e.g. 1024 or 16K
                                (default is 1024)
--resize-buffer                 The buffer size is automatically resized
                                from an initial value of --buffer-size
                                (default)
--no-resize-buffer              Do not automatically adjust the buffer size
--http-chunk-size SIZE          Size of a chunk for chunk-based HTTP
                                downloading, e.g. 10485760 or 10M (default
                                is disabled). May be useful for bypassing
                                bandwidth throttling imposed by a webserver
                                (experimental)
--playlist-random               Download playlist videos in random order
--lazy-playlist                 Process entries in the playlist as they are
                                received. This disables n_entries,
                                --playlist-random and --playlist-reverse
--no-lazy-playlist              Process videos in the playlist only after
                                the entire playlist is parsed (default)
--hls-use-mpegts                Use the mpegts container for HLS videos;
                                allowing some players to play the video
                                while downloading, and reducing the chance
                                of file corruption if download is
                                interrupted. This is enabled by default for
                                live streams
--no-hls-use-mpegts             Do not use the mpegts container for HLS
                                videos. This is default when not downloading
                                live streams
--download-sections REGEX       Download only chapters that match the
                                regular expression. A "*" prefix denotes
                                time-range instead of chapter. Negative
                                timestamps are calculated from the end.
                                "*from-url" can be used to download between
                                the "start_time" and "end_time" extracted
                                from the URL. Needs ffmpeg. This option can
                                be used multiple times to download multiple
                                sections, e.g. --download-sections
                                "*10:15-inf" --download-sections "intro"
--downloader [PROTO:]NAME       Name or path of the external downloader to
                                use (optionally) prefixed by the protocols
                                (http, ftp, m3u8, dash, rstp, rtmp, mms) to
                                use it for. Currently supports native,
                                aria2c, axel, curl, ffmpeg, httpie, wget.
                                You can use this option multiple times to
                                set different downloaders for different
                                protocols. E.g. --downloader aria2c
                                --downloader "dash,m3u8:native" will use
                                aria2c for http/ftp downloads, and the
                                native downloader for dash/m3u8 downloads
                                (Alias: --external-downloader)
--downloader-args NAME:ARGS     Give these arguments to the external
                                downloader. Specify the downloader name and
                                the arguments separated by a colon ":". For
                                ffmpeg, arguments can be passed to different
                                positions using the same syntax as
                                --postprocessor-args. You can use this
                                option multiple times to give different
                                arguments to different downloaders (Alias:
                                --external-downloader-args)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Filesystem Options:&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;-a, --batch-file FILE           File containing URLs to download ("-" for
                                stdin), one URL per line. Lines starting
                                with "#", ";" or "]" are considered as
                                comments and ignored
--no-batch-file                 Do not read URLs from batch file (default)
-P, --paths [TYPES:]PATH        The paths where the files should be
                                downloaded. Specify the type of file and the
                                path separated by a colon ":". All the same
                                TYPES as --output are supported.
                                Additionally, you can also provide "home"
                                (default) and "temp" paths. All intermediary
                                files are first downloaded to the temp path
                                and then the final files are moved over to
                                the home path after download is finished.
                                This option is ignored if --output is an
                                absolute path
-o, --output [TYPES:]TEMPLATE   Output filename template; see "OUTPUT
                                TEMPLATE" for details
--output-na-placeholder TEXT    Placeholder for unavailable fields in
                                --output (default: "NA")
--restrict-filenames            Restrict filenames to only ASCII characters,
                                and avoid "&amp;amp;" and spaces in filenames
--no-restrict-filenames         Allow Unicode characters, "&amp;amp;" and spaces in
                                filenames (default)
--windows-filenames             Force filenames to be Windows-compatible
--no-windows-filenames          Sanitize filenames only minimally
--trim-filenames LENGTH         Limit the filename length (excluding
                                extension) to the specified number of
                                characters
-w, --no-overwrites             Do not overwrite any files
--force-overwrites              Overwrite all video and metadata files. This
                                option includes --no-continue
--no-force-overwrites           Do not overwrite the video, but overwrite
                                related files (default)
-c, --continue                  Resume partially downloaded files/fragments
                                (default)
--no-continue                   Do not resume partially downloaded
                                fragments. If the file is not fragmented,
                                restart download of the entire file
--part                          Use .part files instead of writing directly
                                into output file (default)
--no-part                       Do not use .part files - write directly into
                                output file
--mtime                         Use the Last-modified header to set the file
                                modification time
--no-mtime                      Do not use the Last-modified header to set
                                the file modification time (default)
--write-description             Write video description to a .description file
--no-write-description          Do not write video description (default)
--write-info-json               Write video metadata to a .info.json file
                                (this may contain personal information)
--no-write-info-json            Do not write video metadata (default)
--write-playlist-metafiles      Write playlist metadata in addition to the
                                video metadata when using --write-info-json,
                                --write-description etc. (default)
--no-write-playlist-metafiles   Do not write playlist metadata when using
                                --write-info-json, --write-description etc.
--clean-info-json               Remove some internal metadata such as
                                filenames from the infojson (default)
--no-clean-info-json            Write all fields to the infojson
--write-comments                Retrieve video comments to be placed in the
                                infojson. The comments are fetched even
                                without this option if the extraction is
                                known to be quick (Alias: --get-comments)
--no-write-comments             Do not retrieve video comments unless the
                                extraction is known to be quick (Alias:
                                --no-get-comments)
--load-info-json FILE           JSON file containing the video information
                                (created with the "--write-info-json" option)
--cookies FILE                  Netscape formatted file to read cookies from
                                and dump cookie jar in
--no-cookies                    Do not read/dump cookies from/to file
                                (default)
--cookies-from-browser BROWSER[+KEYRING][:PROFILE][::CONTAINER]
                                The name of the browser to load cookies
                                from. Currently supported browsers are:
                                brave, chrome, chromium, edge, firefox,
                                opera, safari, vivaldi, whale. Optionally,
                                the KEYRING used for decrypting Chromium
                                cookies on Linux, the name/path of the
                                PROFILE to load cookies from, and the
                                CONTAINER name (if Firefox) ("none" for no
                                container) can be given with their
                                respective separators. By default, all
                                containers of the most recently accessed
                                profile are used. Currently supported
                                keyrings are: basictext, gnomekeyring,
                                kwallet, kwallet5, kwallet6
--no-cookies-from-browser       Do not load cookies from browser (default)
--cache-dir DIR                 Location in the filesystem where yt-dlp can
                                store some downloaded information (such as
                                client ids and signatures) permanently. By
                                default ${XDG_CACHE_HOME}/yt-dlp
--no-cache-dir                  Disable filesystem caching
--rm-cache-dir                  Delete all filesystem cache files
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Thumbnail Options:&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;--write-thumbnail               Write thumbnail image to disk
--no-write-thumbnail            Do not write thumbnail image to disk (default)
--write-all-thumbnails          Write all thumbnail image formats to disk
--list-thumbnails               List available thumbnails of each video.
                                Simulate unless --no-simulate is used
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Internet Shortcut Options:&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;--write-link                    Write an internet shortcut file, depending
                                on the current platform (.url, .webloc or
                                .desktop). The URL may be cached by the OS
--write-url-link                Write a .url Windows internet shortcut. The
                                OS caches the URL based on the file path
--write-webloc-link             Write a .webloc macOS internet shortcut
--write-desktop-link            Write a .desktop Linux internet shortcut
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Verbosity and Simulation Options:&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;-q, --quiet                     Activate quiet mode. If used with --verbose,
                                print the log to stderr
--no-quiet                      Deactivate quiet mode. (Default)
--no-warnings                   Ignore warnings
-s, --simulate                  Do not download the video and do not write
                                anything to disk
--no-simulate                   Download the video even if printing/listing
                                options are used
--ignore-no-formats-error       Ignore "No video formats" error. Useful for
                                extracting metadata even if the videos are
                                not actually available for download
                                (experimental)
--no-ignore-no-formats-error    Throw error when no downloadable video
                                formats are found (default)
--skip-download                 Do not download the video but write all
                                related files (Alias: --no-download)
-O, --print [WHEN:]TEMPLATE     Field name or output template to print to
                                screen, optionally prefixed with when to
                                print it, separated by a ":". Supported
                                values of "WHEN" are the same as that of
                                --use-postprocessor (default: video).
                                Implies --quiet. Implies --simulate unless
                                --no-simulate or later stages of WHEN are
                                used. This option can be used multiple times
--print-to-file [WHEN:]TEMPLATE FILE
                                Append given template to the file. The
                                values of WHEN and TEMPLATE are the same as
                                that of --print. FILE uses the same syntax
                                as the output template. This option can be
                                used multiple times
-j, --dump-json                 Quiet, but print JSON information for each
                                video. Simulate unless --no-simulate is
                                used. See "OUTPUT TEMPLATE" for a
                                description of available keys
-J, --dump-single-json          Quiet, but print JSON information for each
                                URL or infojson passed. Simulate unless
                                --no-simulate is used. If the URL refers to
                                a playlist, the whole playlist information
                                is dumped in a single line
--force-write-archive           Force download archive entries to be written
                                as far as no errors occur, even if -s or
                                another simulation option is used (Alias:
                                --force-download-archive)
--newline                       Output progress bar as new lines
--no-progress                   Do not print progress bar
--progress                      Show progress bar, even if in quiet mode
--console-title                 Display progress in console titlebar
--progress-template [TYPES:]TEMPLATE
                                Template for progress outputs, optionally
                                prefixed with one of "download:" (default),
                                "download-title:" (the console title),
                                "postprocess:",  or "postprocess-title:".
                                The video's fields are accessible under the
                                "info" key and the progress attributes are
                                accessible under "progress" key. E.g.
                                --console-title --progress-template
                                "download-title:%(info.id)s-%(progress.eta)s"
--progress-delta SECONDS        Time between progress output (default: 0)
-v, --verbose                   Print various debugging information
--dump-pages                    Print downloaded pages encoded using base64
                                to debug problems (very verbose)
--write-pages                   Write downloaded intermediary pages to files
                                in the current directory to debug problems
--print-traffic                 Display sent and read HTTP traffic
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Workarounds:&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;--encoding ENCODING             Force the specified encoding (experimental)
--legacy-server-connect         Explicitly allow HTTPS connection to servers
                                that do not support RFC 5746 secure
                                renegotiation
--no-check-certificates         Suppress HTTPS certificate validation
--prefer-insecure               Use an unencrypted connection to retrieve
                                information about the video (Currently
                                supported only for YouTube)
--add-headers FIELD:VALUE       Specify a custom HTTP header and its value,
                                separated by a colon ":". You can use this
                                option multiple times
--bidi-workaround               Work around terminals that lack
                                bidirectional text support. Requires bidiv
                                or fribidi executable in PATH
--sleep-requests SECONDS        Number of seconds to sleep between requests
                                during data extraction
--sleep-interval SECONDS        Number of seconds to sleep before each
                                download. This is the minimum time to sleep
                                when used along with --max-sleep-interval
                                (Alias: --min-sleep-interval)
--max-sleep-interval SECONDS    Maximum number of seconds to sleep. Can only
                                be used along with --min-sleep-interval
--sleep-subtitles SECONDS       Number of seconds to sleep before each
                                subtitle download
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Video Format Options:&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;-f, --format FORMAT             Video format code, see "FORMAT SELECTION"
                                for more details
-S, --format-sort SORTORDER     Sort the formats by the fields given, see
                                "Sorting Formats" for more details
--format-sort-force             Force user specified sort order to have
                                precedence over all fields, see "Sorting
                                Formats" for more details (Alias: --S-force)
--no-format-sort-force          Some fields have precedence over the user
                                specified sort order (default)
--video-multistreams            Allow multiple video streams to be merged
                                into a single file
--no-video-multistreams         Only one video stream is downloaded for each
                                output file (default)
--audio-multistreams            Allow multiple audio streams to be merged
                                into a single file
--no-audio-multistreams         Only one audio stream is downloaded for each
                                output file (default)
--prefer-free-formats           Prefer video formats with free containers
                                over non-free ones of the same quality. Use
                                with "-S ext" to strictly prefer free
                                containers irrespective of quality
--no-prefer-free-formats        Don't give any special preference to free
                                containers (default)
--check-formats                 Make sure formats are selected only from
                                those that are actually downloadable
--check-all-formats             Check all formats for whether they are
                                actually downloadable
--no-check-formats              Do not check that the formats are actually
                                downloadable
-F, --list-formats              List available formats of each video.
                                Simulate unless --no-simulate is used
--merge-output-format FORMAT    Containers that may be used when merging
                                formats, separated by "/", e.g. "mp4/mkv".
                                Ignored if no merge is required. (currently
                                supported: avi, flv, mkv, mov, mp4, webm)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Subtitle Options:&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;--write-subs                    Write subtitle file
--no-write-subs                 Do not write subtitle file (default)
--write-auto-subs               Write automatically generated subtitle file
                                (Alias: --write-automatic-subs)
--no-write-auto-subs            Do not write auto-generated subtitles
                                (default) (Alias: --no-write-automatic-subs)
--list-subs                     List available subtitles of each video.
                                Simulate unless --no-simulate is used
--sub-format FORMAT             Subtitle format; accepts formats preference
                                separated by "/", e.g. "srt" or "ass/srt/best"
--sub-langs LANGS               Languages of the subtitles to download (can
                                be regex) or "all" separated by commas, e.g.
                                --sub-langs "en.*,ja" (where "en.*" is a
                                regex pattern that matches "en" followed by
                                0 or more of any character). You can prefix
                                the language code with a "-" to exclude it
                                from the requested languages, e.g. --sub-
                                langs all,-live_chat. Use --list-subs for a
                                list of available language tags
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Authentication Options:&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;-u, --username USERNAME         Login with this account ID
-p, --password PASSWORD         Account password. If this option is left
                                out, yt-dlp will ask interactively
-2, --twofactor TWOFACTOR       Two-factor authentication code
-n, --netrc                     Use .netrc authentication data
--netrc-location PATH           Location of .netrc authentication data;
                                either the path or its containing directory.
                                Defaults to ~/.netrc
--netrc-cmd NETRC_CMD           Command to execute to get the credentials
                                for an extractor.
--video-password PASSWORD       Video-specific password
--ap-mso MSO                    Adobe Pass multiple-system operator (TV
                                provider) identifier, use --ap-list-mso for
                                a list of available MSOs
--ap-username USERNAME          Multiple-system operator account login
--ap-password PASSWORD          Multiple-system operator account password.
                                If this option is left out, yt-dlp will ask
                                interactively
--ap-list-mso                   List all supported multiple-system operators
--client-certificate CERTFILE   Path to client certificate file in PEM
                                format. May include the private key
--client-certificate-key KEYFILE
                                Path to private key file for client
                                certificate
--client-certificate-password PASSWORD
                                Password for client certificate private key,
                                if encrypted. If not provided, and the key
                                is encrypted, yt-dlp will ask interactively
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Post-Processing Options:&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;-x, --extract-audio             Convert video files to audio-only files
                                (requires ffmpeg and ffprobe)
--audio-format FORMAT           Format to convert the audio to when -x is
                                used. (currently supported: best (default),
                                aac, alac, flac, m4a, mp3, opus, vorbis,
                                wav). You can specify multiple rules using
                                similar syntax as --remux-video
--audio-quality QUALITY         Specify ffmpeg audio quality to use when
                                converting the audio with -x. Insert a value
                                between 0 (best) and 10 (worst) for VBR or a
                                specific bitrate like 128K (default 5)
--remux-video FORMAT            Remux the video into another container if
                                necessary (currently supported: avi, flv,
                                gif, mkv, mov, mp4, webm, aac, aiff, alac,
                                flac, m4a, mka, mp3, ogg, opus, vorbis,
                                wav). If the target container does not
                                support the video/audio codec, remuxing will
                                fail. You can specify multiple rules; e.g.
                                "aac&amp;gt;m4a/mov&amp;gt;mp4/mkv" will remux aac to m4a,
                                mov to mp4 and anything else to mkv
--recode-video FORMAT           Re-encode the video into another format if
                                necessary. The syntax and supported formats
                                are the same as --remux-video
--postprocessor-args NAME:ARGS  Give these arguments to the postprocessors.
                                Specify the postprocessor/executable name
                                and the arguments separated by a colon ":"
                                to give the argument to the specified
                                postprocessor/executable. Supported PP are:
                                Merger, ModifyChapters, SplitChapters,
                                ExtractAudio, VideoRemuxer, VideoConvertor,
                                Metadata, EmbedSubtitle, EmbedThumbnail,
                                SubtitlesConvertor, ThumbnailsConvertor,
                                FixupStretched, FixupM4a, FixupM3u8,
                                FixupTimestamp and FixupDuration. The
                                supported executables are: AtomicParsley,
                                FFmpeg and FFprobe. You can also specify
                                "PP+EXE:ARGS" to give the arguments to the
                                specified executable only when being used by
                                the specified postprocessor. Additionally,
                                for ffmpeg/ffprobe, "_i"/"_o" can be
                                appended to the prefix optionally followed
                                by a number to pass the argument before the
                                specified input/output file, e.g. --ppa
                                "Merger+ffmpeg_i1:-v quiet". You can use
                                this option multiple times to give different
                                arguments to different postprocessors.
                                (Alias: --ppa)
-k, --keep-video                Keep the intermediate video file on disk
                                after post-processing
--no-keep-video                 Delete the intermediate video file after
                                post-processing (default)
--post-overwrites               Overwrite post-processed files (default)
--no-post-overwrites            Do not overwrite post-processed files
--embed-subs                    Embed subtitles in the video (only for mp4,
                                webm and mkv videos)
--no-embed-subs                 Do not embed subtitles (default)
--embed-thumbnail               Embed thumbnail in the video as cover art
--no-embed-thumbnail            Do not embed thumbnail (default)
--embed-metadata                Embed metadata to the video file. Also
                                embeds chapters/infojson if present unless
                                --no-embed-chapters/--no-embed-info-json are
                                used (Alias: --add-metadata)
--no-embed-metadata             Do not add metadata to file (default)
                                (Alias: --no-add-metadata)
--embed-chapters                Add chapter markers to the video file
                                (Alias: --add-chapters)
--no-embed-chapters             Do not add chapter markers (default) (Alias:
                                --no-add-chapters)
--embed-info-json               Embed the infojson as an attachment to
                                mkv/mka video files
--no-embed-info-json            Do not embed the infojson as an attachment
                                to the video file
--parse-metadata [WHEN:]FROM:TO
                                Parse additional metadata like title/artist
                                from other fields; see "MODIFYING METADATA"
                                for details. Supported values of "WHEN" are
                                the same as that of --use-postprocessor
                                (default: pre_process)
--replace-in-metadata [WHEN:]FIELDS REGEX REPLACE
                                Replace text in a metadata field using the
                                given regex. This option can be used
                                multiple times. Supported values of "WHEN"
                                are the same as that of --use-postprocessor
                                (default: pre_process)
--xattrs                        Write metadata to the video file's xattrs
                                (using Dublin Core and XDG standards)
--concat-playlist POLICY        Concatenate videos in a playlist. One of
                                "never", "always", or "multi_video"
                                (default; only when the videos form a single
                                show). All the video files must have the
                                same codecs and number of streams to be
                                concatenable. The "pl_video:" prefix can be
                                used with "--paths" and "--output" to set
                                the output filename for the concatenated
                                files. See "OUTPUT TEMPLATE" for details
--fixup POLICY                  Automatically correct known faults of the
                                file. One of never (do nothing), warn (only
                                emit a warning), detect_or_warn (the
                                default; fix the file if we can, warn
                                otherwise), force (try fixing even if the
                                file already exists)
--ffmpeg-location PATH          Location of the ffmpeg binary; either the
                                path to the binary or its containing directory
--exec [WHEN:]CMD               Execute a command, optionally prefixed with
                                when to execute it, separated by a ":".
                                Supported values of "WHEN" are the same as
                                that of --use-postprocessor (default:
                                after_move). The same syntax as the output
                                template can be used to pass any field as
                                arguments to the command. If no fields are
                                passed, %(filepath,_filename|)q is appended
                                to the end of the command. This option can
                                be used multiple times
--no-exec                       Remove any previously defined --exec
--convert-subs FORMAT           Convert the subtitles to another format
                                (currently supported: ass, lrc, srt, vtt).
                                Use "--convert-subs none" to disable
                                conversion (default) (Alias: --convert-
                                subtitles)
--convert-thumbnails FORMAT     Convert the thumbnails to another format
                                (currently supported: jpg, png, webp). You
                                can specify multiple rules using similar
                                syntax as "--remux-video". Use "--convert-
                                thumbnails none" to disable conversion
                                (default)
--split-chapters                Split video into multiple files based on
                                internal chapters. The "chapter:" prefix can
                                be used with "--paths" and "--output" to set
                                the output filename for the split files. See
                                "OUTPUT TEMPLATE" for details
--no-split-chapters             Do not split video based on chapters (default)
--remove-chapters REGEX         Remove chapters whose title matches the
                                given regular expression. The syntax is the
                                same as --download-sections. This option can
                                be used multiple times
--no-remove-chapters            Do not remove any chapters from the file
                                (default)
--force-keyframes-at-cuts       Force keyframes at cuts when
                                downloading/splitting/removing sections.
                                This is slow due to needing a re-encode, but
                                the resulting video may have fewer artifacts
                                around the cuts
--no-force-keyframes-at-cuts    Do not force keyframes around the chapters
                                when cutting/splitting (default)
--use-postprocessor NAME[:ARGS]
                                The (case-sensitive) name of plugin
                                postprocessors to be enabled, and
                                (optionally) arguments to be passed to it,
                                separated by a colon ":". ARGS are a
                                semicolon ";" delimited list of NAME=VALUE.
                                The "when" argument determines when the
                                postprocessor is invoked. It can be one of
                                "pre_process" (after video extraction),
                                "after_filter" (after video passes filter),
                                "video" (after --format; before
                                --print/--output), "before_dl" (before each
                                video download), "post_process" (after each
                                video download; default), "after_move"
                                (after moving the video file to its final
                                location), "after_video" (after downloading
                                and processing all formats of a video), or
                                "playlist" (at end of playlist). This option
                                can be used multiple times to add different
                                postprocessors
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;SponsorBlock Options:&lt;/h2&gt; 
&lt;p&gt;Make chapter entries for, or remove various segments (sponsor, introductions, etc.) from downloaded YouTube videos using the &lt;a href="https://sponsor.ajay.app"&gt;SponsorBlock API&lt;/a&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;--sponsorblock-mark CATS        SponsorBlock categories to create chapters
                                for, separated by commas. Available
                                categories are sponsor, intro, outro,
                                selfpromo, preview, filler, interaction,
                                music_offtopic, hook, poi_highlight,
                                chapter, all and default (=all). You can
                                prefix the category with a "-" to exclude
                                it. See [1] for descriptions of the
                                categories. E.g. --sponsorblock-mark
                                all,-preview
                                [1] https://wiki.sponsor.ajay.app/w/Segment_Categories
--sponsorblock-remove CATS      SponsorBlock categories to be removed from
                                the video file, separated by commas. If a
                                category is present in both mark and remove,
                                remove takes precedence. The syntax and
                                available categories are the same as for
                                --sponsorblock-mark except that "default"
                                refers to "all,-filler" and poi_highlight,
                                chapter are not available
--sponsorblock-chapter-title TEMPLATE
                                An output template for the title of the
                                SponsorBlock chapters created by
                                --sponsorblock-mark. The only available
                                fields are start_time, end_time, category,
                                categories, name, category_names. Defaults
                                to "[SponsorBlock]: %(category_names)l"
--no-sponsorblock               Disable both --sponsorblock-mark and
                                --sponsorblock-remove
--sponsorblock-api URL          SponsorBlock API location, defaults to
                                https://sponsor.ajay.app
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Extractor Options:&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;--extractor-retries RETRIES     Number of retries for known extractor errors
                                (default is 3), or "infinite"
--allow-dynamic-mpd             Process dynamic DASH manifests (default)
                                (Alias: --no-ignore-dynamic-mpd)
--ignore-dynamic-mpd            Do not process dynamic DASH manifests
                                (Alias: --no-allow-dynamic-mpd)
--hls-split-discontinuity       Split HLS playlists to different formats at
                                discontinuities such as ad breaks
--no-hls-split-discontinuity    Do not split HLS playlists into different
                                formats at discontinuities such as ad breaks
                                (default)
--extractor-args IE_KEY:ARGS    Pass ARGS arguments to the IE_KEY extractor.
                                See "EXTRACTOR ARGUMENTS" for details. You
                                can use this option multiple times to give
                                arguments for different extractors
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Preset Aliases:&lt;/h2&gt; 
&lt;p&gt;Predefined aliases for convenience and ease of use. Note that future versions of yt-dlp may add or adjust presets, but the existing preset names will not be changed or removed&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;-t mp3                          -f 'ba[acodec^=mp3]/ba/b' -x --audio-format
                                mp3

-t aac                          -f
                                'ba[acodec^=aac]/ba[acodec^=mp4a.40.]/ba/b'
                                -x --audio-format aac

-t mp4                          --merge-output-format mp4 --remux-video mp4
                                -S vcodec:h264,lang,quality,res,fps,hdr:12,a
                                codec:aac

-t mkv                          --merge-output-format mkv --remux-video mkv

-t sleep                        --sleep-subtitles 5 --sleep-requests 0.75
                                --sleep-interval 10 --max-sleep-interval 20
&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;CONFIGURATION&lt;/h1&gt; 
&lt;p&gt;You can configure yt-dlp by placing any supported command line option in a configuration file. The configuration is loaded from the following locations:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Main Configuration&lt;/strong&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;The file given to &lt;code&gt;--config-locations&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Portable Configuration&lt;/strong&gt;: (Recommended for portable installations)&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;If using a binary, &lt;code&gt;yt-dlp.conf&lt;/code&gt; in the same directory as the binary&lt;/li&gt; 
   &lt;li&gt;If running from source-code, &lt;code&gt;yt-dlp.conf&lt;/code&gt; in the parent directory of &lt;code&gt;yt_dlp&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Home Configuration&lt;/strong&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;yt-dlp.conf&lt;/code&gt; in the home path given to &lt;code&gt;-P&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;If &lt;code&gt;-P&lt;/code&gt; is not given, the current directory is searched&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;User Configuration&lt;/strong&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;${XDG_CONFIG_HOME}/yt-dlp.conf&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;${XDG_CONFIG_HOME}/yt-dlp/config&lt;/code&gt; (recommended on Linux/macOS)&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;${XDG_CONFIG_HOME}/yt-dlp/config.txt&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;${APPDATA}/yt-dlp.conf&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;${APPDATA}/yt-dlp/config&lt;/code&gt; (recommended on Windows)&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;${APPDATA}/yt-dlp/config.txt&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;~/yt-dlp.conf&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;~/yt-dlp.conf.txt&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;~/.yt-dlp/config&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;~/.yt-dlp/config.txt&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;p&gt;See also: &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#notes-about-environment-variables"&gt;Notes about environment variables&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;System Configuration&lt;/strong&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;/etc/yt-dlp.conf&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;/etc/yt-dlp/config&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;/etc/yt-dlp/config.txt&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;E.g. with the following configuration file, yt-dlp will always extract the audio, copy the mtime, use a proxy and save all videos under &lt;code&gt;YouTube&lt;/code&gt; directory in your home directory:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;# Lines starting with # are comments

# Always extract audio
-x

# Copy the mtime
--mtime

# Use this proxy
--proxy 127.0.0.1:3128

# Save all videos under YouTube directory in your home directory
-o ~/YouTube/%(title)s.%(ext)s
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: Options in a configuration file are just the same options aka switches used in regular command line calls; thus there &lt;strong&gt;must be no whitespace&lt;/strong&gt; after &lt;code&gt;-&lt;/code&gt; or &lt;code&gt;--&lt;/code&gt;, e.g. &lt;code&gt;-o&lt;/code&gt; or &lt;code&gt;--proxy&lt;/code&gt; but not &lt;code&gt;- o&lt;/code&gt; or &lt;code&gt;-- proxy&lt;/code&gt;. They must also be quoted when necessary, as if it were a UNIX shell.&lt;/p&gt; 
&lt;p&gt;You can use &lt;code&gt;--ignore-config&lt;/code&gt; if you want to disable all configuration files for a particular yt-dlp run. If &lt;code&gt;--ignore-config&lt;/code&gt; is found inside any configuration file, no further configuration will be loaded. For example, having the option in the portable configuration file prevents loading of home, user, and system configurations. Additionally, (for backward compatibility) if &lt;code&gt;--ignore-config&lt;/code&gt; is found inside the system configuration file, the user configuration is not loaded.&lt;/p&gt; 
&lt;h3&gt;Configuration file encoding&lt;/h3&gt; 
&lt;p&gt;The configuration files are decoded according to the UTF BOM if present, and in the encoding from system locale otherwise.&lt;/p&gt; 
&lt;p&gt;If you want your file to be decoded differently, add &lt;code&gt;# coding: ENCODING&lt;/code&gt; to the beginning of the file (e.g. &lt;code&gt;# coding: shift-jis&lt;/code&gt;). There must be no characters before that, even spaces or BOM.&lt;/p&gt; 
&lt;h3&gt;Authentication with netrc&lt;/h3&gt; 
&lt;p&gt;You may also want to configure automatic credentials storage for extractors that support authentication (by providing login and password with &lt;code&gt;--username&lt;/code&gt; and &lt;code&gt;--password&lt;/code&gt;) in order not to pass credentials as command line arguments on every yt-dlp execution and prevent tracking plain text passwords in the shell command history. You can achieve this using a &lt;a href="https://stackoverflow.com/tags/.netrc/info"&gt;&lt;code&gt;.netrc&lt;/code&gt; file&lt;/a&gt; on a per-extractor basis. For that, you will need to create a &lt;code&gt;.netrc&lt;/code&gt; file in &lt;code&gt;--netrc-location&lt;/code&gt; and restrict permissions to read/write by only you:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;touch ${HOME}/.netrc
chmod a-rwx,u+rw ${HOME}/.netrc
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;After that, you can add credentials for an extractor in the following format, where &lt;em&gt;extractor&lt;/em&gt; is the name of the extractor in lowercase:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;machine &amp;lt;extractor&amp;gt; login &amp;lt;username&amp;gt; password &amp;lt;password&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;E.g.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;machine youtube login myaccount@gmail.com password my_youtube_password
machine twitch login my_twitch_account_name password my_twitch_password
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To activate authentication with the &lt;code&gt;.netrc&lt;/code&gt; file you should pass &lt;code&gt;--netrc&lt;/code&gt; to yt-dlp or place it in the &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#configuration"&gt;configuration file&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;The default location of the .netrc file is &lt;code&gt;~&lt;/code&gt; (see below).&lt;/p&gt; 
&lt;p&gt;As an alternative to using the &lt;code&gt;.netrc&lt;/code&gt; file, which has the disadvantage of keeping your passwords in a plain text file, you can configure a custom shell command to provide the credentials for an extractor. This is done by providing the &lt;code&gt;--netrc-cmd&lt;/code&gt; parameter, it shall output the credentials in the netrc format and return &lt;code&gt;0&lt;/code&gt; on success, other values will be treated as an error. &lt;code&gt;{}&lt;/code&gt; in the command will be replaced by the name of the extractor to make it possible to select the credentials for the right extractor.&lt;/p&gt; 
&lt;p&gt;E.g. To use an encrypted &lt;code&gt;.netrc&lt;/code&gt; file stored as &lt;code&gt;.authinfo.gpg&lt;/code&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;yt-dlp --netrc-cmd 'gpg --decrypt ~/.authinfo.gpg' 'https://www.youtube.com/watch?v=BaW_jenozKc'
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Notes about environment variables&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Environment variables are normally specified as &lt;code&gt;${VARIABLE}&lt;/code&gt;/&lt;code&gt;$VARIABLE&lt;/code&gt; on UNIX and &lt;code&gt;%VARIABLE%&lt;/code&gt; on Windows; but is always shown as &lt;code&gt;${VARIABLE}&lt;/code&gt; in this documentation&lt;/li&gt; 
 &lt;li&gt;yt-dlp also allows using UNIX-style variables on Windows for path-like options; e.g. &lt;code&gt;--output&lt;/code&gt;, &lt;code&gt;--config-locations&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;If unset, &lt;code&gt;${XDG_CONFIG_HOME}&lt;/code&gt; defaults to &lt;code&gt;~/.config&lt;/code&gt; and &lt;code&gt;${XDG_CACHE_HOME}&lt;/code&gt; to &lt;code&gt;~/.cache&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;On Windows, &lt;code&gt;~&lt;/code&gt; points to &lt;code&gt;${HOME}&lt;/code&gt; if present; or, &lt;code&gt;${USERPROFILE}&lt;/code&gt; or &lt;code&gt;${HOMEDRIVE}${HOMEPATH}&lt;/code&gt; otherwise&lt;/li&gt; 
 &lt;li&gt;On Windows, &lt;code&gt;${USERPROFILE}&lt;/code&gt; generally points to &lt;code&gt;C:\Users\&amp;lt;user name&amp;gt;&lt;/code&gt; and &lt;code&gt;${APPDATA}&lt;/code&gt; to &lt;code&gt;${USERPROFILE}\AppData\Roaming&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;OUTPUT TEMPLATE&lt;/h1&gt; 
&lt;p&gt;The &lt;code&gt;-o&lt;/code&gt; option is used to indicate a template for the output file names while &lt;code&gt;-P&lt;/code&gt; option is used to specify the path each type of file should be saved to.&lt;/p&gt; 
&lt;!-- MANPAGE: BEGIN EXCLUDED SECTION --&gt; 
&lt;p&gt;&lt;strong&gt;tl;dr:&lt;/strong&gt; &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#output-template-examples"&gt;navigate me to examples&lt;/a&gt;.&lt;/p&gt; 
&lt;!-- MANPAGE: END EXCLUDED SECTION --&gt; 
&lt;p&gt;The simplest usage of &lt;code&gt;-o&lt;/code&gt; is not to set any template arguments when downloading a single file, like in &lt;code&gt;yt-dlp -o funny_video.flv "https://some/video"&lt;/code&gt; (hard-coding file extension like this is &lt;em&gt;not&lt;/em&gt; recommended and could break some post-processing).&lt;/p&gt; 
&lt;p&gt;It may however also contain special sequences that will be replaced when downloading each video. The special sequences may be formatted according to &lt;a href="https://docs.python.org/3/library/stdtypes.html#printf-style-string-formatting"&gt;Python string formatting operations&lt;/a&gt;, e.g. &lt;code&gt;%(NAME)s&lt;/code&gt; or &lt;code&gt;%(NAME)05d&lt;/code&gt;. To clarify, that is a percent symbol followed by a name in parentheses, followed by formatting operations.&lt;/p&gt; 
&lt;p&gt;The field names themselves (the part inside the parenthesis) can also have some special formatting:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Object traversal&lt;/strong&gt;: The dictionaries and lists available in metadata can be traversed by using a dot &lt;code&gt;.&lt;/code&gt; separator; e.g. &lt;code&gt;%(tags.0)s&lt;/code&gt;, &lt;code&gt;%(subtitles.en.-1.ext)s&lt;/code&gt;. You can do Python slicing with colon &lt;code&gt;:&lt;/code&gt;; E.g. &lt;code&gt;%(id.3:7)s&lt;/code&gt;, &lt;code&gt;%(id.6:2:-1)s&lt;/code&gt;, &lt;code&gt;%(formats.:.format_id)s&lt;/code&gt;. Curly braces &lt;code&gt;{}&lt;/code&gt; can be used to build dictionaries with only specific keys; e.g. &lt;code&gt;%(formats.:.{format_id,height})#j&lt;/code&gt;. An empty field name &lt;code&gt;%()s&lt;/code&gt; refers to the entire infodict; e.g. &lt;code&gt;%(.{id,title})s&lt;/code&gt;. Note that all the fields that become available using this method are not listed below. Use &lt;code&gt;-j&lt;/code&gt; to see such fields&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Arithmetic&lt;/strong&gt;: Simple arithmetic can be done on numeric fields using &lt;code&gt;+&lt;/code&gt;, &lt;code&gt;-&lt;/code&gt; and &lt;code&gt;*&lt;/code&gt;. E.g. &lt;code&gt;%(playlist_index+10)03d&lt;/code&gt;, &lt;code&gt;%(n_entries+1-playlist_index)d&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Date/time Formatting&lt;/strong&gt;: Date/time fields can be formatted according to &lt;a href="https://docs.python.org/3/library/datetime.html#strftime-and-strptime-format-codes"&gt;strftime formatting&lt;/a&gt; by specifying it separated from the field name using a &lt;code&gt;&amp;gt;&lt;/code&gt;. E.g. &lt;code&gt;%(duration&amp;gt;%H-%M-%S)s&lt;/code&gt;, &lt;code&gt;%(upload_date&amp;gt;%Y-%m-%d)s&lt;/code&gt;, &lt;code&gt;%(epoch-3600&amp;gt;%H-%M-%S)s&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Alternatives&lt;/strong&gt;: Alternate fields can be specified separated with a &lt;code&gt;,&lt;/code&gt;. E.g. &lt;code&gt;%(release_date&amp;gt;%Y,upload_date&amp;gt;%Y|Unknown)s&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Replacement&lt;/strong&gt;: A replacement value can be specified using a &lt;code&gt;&amp;amp;&lt;/code&gt; separator according to the &lt;a href="https://docs.python.org/3/library/string.html#format-specification-mini-language"&gt;&lt;code&gt;str.format&lt;/code&gt; mini-language&lt;/a&gt;. If the field is &lt;em&gt;not&lt;/em&gt; empty, this replacement value will be used instead of the actual field content. This is done after alternate fields are considered; thus the replacement is used if &lt;em&gt;any&lt;/em&gt; of the alternative fields is &lt;em&gt;not&lt;/em&gt; empty. E.g. &lt;code&gt;%(chapters&amp;amp;has chapters|no chapters)s&lt;/code&gt;, &lt;code&gt;%(title&amp;amp;TITLE={:&amp;gt;20}|NO TITLE)s&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Default&lt;/strong&gt;: A literal default value can be specified for when the field is empty using a &lt;code&gt;|&lt;/code&gt; separator. This overrides &lt;code&gt;--output-na-placeholder&lt;/code&gt;. E.g. &lt;code&gt;%(uploader|Unknown)s&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;More Conversions&lt;/strong&gt;: In addition to the normal format types &lt;code&gt;diouxXeEfFgGcrs&lt;/code&gt;, yt-dlp additionally supports converting to &lt;code&gt;B&lt;/code&gt; = &lt;strong&gt;B&lt;/strong&gt;ytes, &lt;code&gt;j&lt;/code&gt; = &lt;strong&gt;j&lt;/strong&gt;son (flag &lt;code&gt;#&lt;/code&gt; for pretty-printing, &lt;code&gt;+&lt;/code&gt; for Unicode), &lt;code&gt;h&lt;/code&gt; = HTML escaping, &lt;code&gt;l&lt;/code&gt; = a comma separated &lt;strong&gt;l&lt;/strong&gt;ist (flag &lt;code&gt;#&lt;/code&gt; for &lt;code&gt;\n&lt;/code&gt; newline-separated), &lt;code&gt;q&lt;/code&gt; = a string &lt;strong&gt;q&lt;/strong&gt;uoted for the terminal (flag &lt;code&gt;#&lt;/code&gt; to split a list into different arguments), &lt;code&gt;D&lt;/code&gt; = add &lt;strong&gt;D&lt;/strong&gt;ecimal suffixes (e.g. 10M) (flag &lt;code&gt;#&lt;/code&gt; to use 1024 as factor), and &lt;code&gt;S&lt;/code&gt; = &lt;strong&gt;S&lt;/strong&gt;anitize as filename (flag &lt;code&gt;#&lt;/code&gt; for restricted)&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Unicode normalization&lt;/strong&gt;: The format type &lt;code&gt;U&lt;/code&gt; can be used for NFC &lt;a href="https://docs.python.org/3/library/unicodedata.html#unicodedata.normalize"&gt;Unicode normalization&lt;/a&gt;. The alternate form flag (&lt;code&gt;#&lt;/code&gt;) changes the normalization to NFD and the conversion flag &lt;code&gt;+&lt;/code&gt; can be used for NFKC/NFKD compatibility equivalence normalization. E.g. &lt;code&gt;%(title)+.100U&lt;/code&gt; is NFKC&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;To summarize, the general syntax for a field is:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;%(name[.keys][addition][&amp;gt;strf][,alternate][&amp;amp;replacement][|default])[flags][width][.precision][length]type
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Additionally, you can set different output templates for the various metadata files separately from the general output template by specifying the type of file followed by the template separated by a colon &lt;code&gt;:&lt;/code&gt;. The different file types supported are &lt;code&gt;subtitle&lt;/code&gt;, &lt;code&gt;thumbnail&lt;/code&gt;, &lt;code&gt;description&lt;/code&gt;, &lt;code&gt;annotation&lt;/code&gt; (deprecated), &lt;code&gt;infojson&lt;/code&gt;, &lt;code&gt;link&lt;/code&gt;, &lt;code&gt;pl_thumbnail&lt;/code&gt;, &lt;code&gt;pl_description&lt;/code&gt;, &lt;code&gt;pl_infojson&lt;/code&gt;, &lt;code&gt;chapter&lt;/code&gt;, &lt;code&gt;pl_video&lt;/code&gt;. E.g. &lt;code&gt;-o "%(title)s.%(ext)s" -o "thumbnail:%(title)s\%(title)s.%(ext)s"&lt;/code&gt; will put the thumbnails in a folder with the same name as the video. If any of the templates is empty, that type of file will not be written. E.g. &lt;code&gt;--write-thumbnail -o "thumbnail:"&lt;/code&gt; will write thumbnails only for playlists and not for video.&lt;/p&gt; 
&lt;p&gt;&lt;a id="outtmpl-postprocess-note"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: Due to post-processing (i.e. merging etc.), the actual output filename might differ. Use &lt;code&gt;--print after_move:filepath&lt;/code&gt; to get the name after all post-processing is complete.&lt;/p&gt; 
&lt;p&gt;The available fields are:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;id&lt;/code&gt; (string): Video identifier&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;title&lt;/code&gt; (string): Video title&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;fulltitle&lt;/code&gt; (string): Video title ignoring live timestamp and generic title&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;ext&lt;/code&gt; (string): Video filename extension&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;alt_title&lt;/code&gt; (string): A secondary title of the video&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;description&lt;/code&gt; (string): The description of the video&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;display_id&lt;/code&gt; (string): An alternative identifier for the video&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;uploader&lt;/code&gt; (string): Full name of the video uploader&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;uploader_id&lt;/code&gt; (string): Nickname or id of the video uploader&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;uploader_url&lt;/code&gt; (string): URL to the video uploader's profile&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;license&lt;/code&gt; (string): License name the video is licensed under&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;creators&lt;/code&gt; (list): The creators of the video&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;creator&lt;/code&gt; (string): The creators of the video; comma-separated&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;timestamp&lt;/code&gt; (numeric): UNIX timestamp of the moment the video became available&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;upload_date&lt;/code&gt; (string): Video upload date in UTC (YYYYMMDD)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;release_timestamp&lt;/code&gt; (numeric): UNIX timestamp of the moment the video was released&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;release_date&lt;/code&gt; (string): The date (YYYYMMDD) when the video was released in UTC&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;release_year&lt;/code&gt; (numeric): Year (YYYY) when the video or album was released&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;modified_timestamp&lt;/code&gt; (numeric): UNIX timestamp of the moment the video was last modified&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;modified_date&lt;/code&gt; (string): The date (YYYYMMDD) when the video was last modified in UTC&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;channel&lt;/code&gt; (string): Full name of the channel the video is uploaded on&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;channel_id&lt;/code&gt; (string): Id of the channel&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;channel_url&lt;/code&gt; (string): URL of the channel&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;channel_follower_count&lt;/code&gt; (numeric): Number of followers of the channel&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;channel_is_verified&lt;/code&gt; (boolean): Whether the channel is verified on the platform&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;location&lt;/code&gt; (string): Physical location where the video was filmed&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;duration&lt;/code&gt; (numeric): Length of the video in seconds&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;duration_string&lt;/code&gt; (string): Length of the video (HH:mm:ss)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;view_count&lt;/code&gt; (numeric): How many users have watched the video on the platform&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;concurrent_view_count&lt;/code&gt; (numeric): How many users are currently watching the video on the platform.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;like_count&lt;/code&gt; (numeric): Number of positive ratings of the video&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;dislike_count&lt;/code&gt; (numeric): Number of negative ratings of the video&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;repost_count&lt;/code&gt; (numeric): Number of reposts of the video&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;average_rating&lt;/code&gt; (numeric): Average rating given by users, the scale used depends on the webpage&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;comment_count&lt;/code&gt; (numeric): Number of comments on the video (For some extractors, comments are only downloaded at the end, and so this field cannot be used)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;age_limit&lt;/code&gt; (numeric): Age restriction for the video (years)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;live_status&lt;/code&gt; (string): One of "not_live", "is_live", "is_upcoming", "was_live", "post_live" (was live, but VOD is not yet processed)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;is_live&lt;/code&gt; (boolean): Whether this video is a live stream or a fixed-length video&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;was_live&lt;/code&gt; (boolean): Whether this video was originally a live stream&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;playable_in_embed&lt;/code&gt; (string): Whether this video is allowed to play in embedded players on other sites&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;availability&lt;/code&gt; (string): Whether the video is "private", "premium_only", "subscriber_only", "needs_auth", "unlisted" or "public"&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;media_type&lt;/code&gt; (string): The type of media as classified by the site, e.g. "episode", "clip", "trailer"&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;start_time&lt;/code&gt; (numeric): Time in seconds where the reproduction should start, as specified in the URL&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;end_time&lt;/code&gt; (numeric): Time in seconds where the reproduction should end, as specified in the URL&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;extractor&lt;/code&gt; (string): Name of the extractor&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;extractor_key&lt;/code&gt; (string): Key name of the extractor&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;epoch&lt;/code&gt; (numeric): Unix epoch of when the information extraction was completed&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;autonumber&lt;/code&gt; (numeric): Number that will be increased with each download, starting at &lt;code&gt;--autonumber-start&lt;/code&gt;, padded with leading zeros to 5 digits&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;video_autonumber&lt;/code&gt; (numeric): Number that will be increased with each video&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;n_entries&lt;/code&gt; (numeric): Total number of extracted items in the playlist&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;playlist_id&lt;/code&gt; (string): Identifier of the playlist that contains the video&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;playlist_title&lt;/code&gt; (string): Name of the playlist that contains the video&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;playlist&lt;/code&gt; (string): &lt;code&gt;playlist_title&lt;/code&gt; if available or else &lt;code&gt;playlist_id&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;playlist_count&lt;/code&gt; (numeric): Total number of items in the playlist. May not be known if entire playlist is not extracted&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;playlist_index&lt;/code&gt; (numeric): Index of the video in the playlist padded with leading zeros according the final index&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;playlist_autonumber&lt;/code&gt; (numeric): Position of the video in the playlist download queue padded with leading zeros according to the total length of the playlist&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;playlist_uploader&lt;/code&gt; (string): Full name of the playlist uploader&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;playlist_uploader_id&lt;/code&gt; (string): Nickname or id of the playlist uploader&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;playlist_channel&lt;/code&gt; (string): Display name of the channel that uploaded the playlist&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;playlist_channel_id&lt;/code&gt; (string): Identifier of the channel that uploaded the playlist&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;playlist_webpage_url&lt;/code&gt; (string): URL of the playlist webpage&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;webpage_url&lt;/code&gt; (string): A URL to the video webpage which, if given to yt-dlp, should yield the same result again&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;webpage_url_basename&lt;/code&gt; (string): The basename of the webpage URL&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;webpage_url_domain&lt;/code&gt; (string): The domain of the webpage URL&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;original_url&lt;/code&gt; (string): The URL given by the user (or the same as &lt;code&gt;webpage_url&lt;/code&gt; for playlist entries)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;categories&lt;/code&gt; (list): List of categories the video belongs to&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;tags&lt;/code&gt; (list): List of tags assigned to the video&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;cast&lt;/code&gt; (list): List of cast members&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;All the fields in &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#filtering-formats"&gt;Filtering Formats&lt;/a&gt; can also be used&lt;/p&gt; 
&lt;p&gt;Available for the video that belongs to some logical chapter or section:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;chapter&lt;/code&gt; (string): Name or title of the chapter the video belongs to&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;chapter_number&lt;/code&gt; (numeric): Number of the chapter the video belongs to&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;chapter_id&lt;/code&gt; (string): Id of the chapter the video belongs to&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Available for the video that is an episode of some series or program:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;series&lt;/code&gt; (string): Title of the series or program the video episode belongs to&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;series_id&lt;/code&gt; (string): Id of the series or program the video episode belongs to&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;season&lt;/code&gt; (string): Title of the season the video episode belongs to&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;season_number&lt;/code&gt; (numeric): Number of the season the video episode belongs to&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;season_id&lt;/code&gt; (string): Id of the season the video episode belongs to&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;episode&lt;/code&gt; (string): Title of the video episode&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;episode_number&lt;/code&gt; (numeric): Number of the video episode within a season&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;episode_id&lt;/code&gt; (string): Id of the video episode&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Available for the media that is a track or a part of a music album:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;track&lt;/code&gt; (string): Title of the track&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;track_number&lt;/code&gt; (numeric): Number of the track within an album or a disc&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;track_id&lt;/code&gt; (string): Id of the track&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;artists&lt;/code&gt; (list): Artist(s) of the track&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;artist&lt;/code&gt; (string): Artist(s) of the track; comma-separated&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;genres&lt;/code&gt; (list): Genre(s) of the track&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;genre&lt;/code&gt; (string): Genre(s) of the track; comma-separated&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;composers&lt;/code&gt; (list): Composer(s) of the piece&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;composer&lt;/code&gt; (string): Composer(s) of the piece; comma-separated&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;album&lt;/code&gt; (string): Title of the album the track belongs to&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;album_type&lt;/code&gt; (string): Type of the album&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;album_artists&lt;/code&gt; (list): All artists appeared on the album&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;album_artist&lt;/code&gt; (string): All artists appeared on the album; comma-separated&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;disc_number&lt;/code&gt; (numeric): Number of the disc or other physical medium the track belongs to&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Available only when using &lt;code&gt;--download-sections&lt;/code&gt; and for &lt;code&gt;chapter:&lt;/code&gt; prefix when using &lt;code&gt;--split-chapters&lt;/code&gt; for videos with internal chapters:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;section_title&lt;/code&gt; (string): Title of the chapter&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;section_number&lt;/code&gt; (numeric): Number of the chapter within the file&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;section_start&lt;/code&gt; (numeric): Start time of the chapter in seconds&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;section_end&lt;/code&gt; (numeric): End time of the chapter in seconds&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Available only when used in &lt;code&gt;--print&lt;/code&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;urls&lt;/code&gt; (string): The URLs of all requested formats, one in each line&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;filename&lt;/code&gt; (string): Name of the video file. Note that the &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#outtmpl-postprocess-note"&gt;actual filename may differ&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;formats_table&lt;/code&gt; (table): The video format table as printed by &lt;code&gt;--list-formats&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;thumbnails_table&lt;/code&gt; (table): The thumbnail format table as printed by &lt;code&gt;--list-thumbnails&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;subtitles_table&lt;/code&gt; (table): The subtitle format table as printed by &lt;code&gt;--list-subs&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;automatic_captions_table&lt;/code&gt; (table): The automatic subtitle format table as printed by &lt;code&gt;--list-subs&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Available only after the video is downloaded (&lt;code&gt;post_process&lt;/code&gt;/&lt;code&gt;after_move&lt;/code&gt;):&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;filepath&lt;/code&gt;: Actual path of downloaded video file&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Available only in &lt;code&gt;--sponsorblock-chapter-title&lt;/code&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;start_time&lt;/code&gt; (numeric): Start time of the chapter in seconds&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;end_time&lt;/code&gt; (numeric): End time of the chapter in seconds&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;categories&lt;/code&gt; (list): The &lt;a href="https://wiki.sponsor.ajay.app/w/Types#Category"&gt;SponsorBlock categories&lt;/a&gt; the chapter belongs to&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;category&lt;/code&gt; (string): The smallest SponsorBlock category the chapter belongs to&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;category_names&lt;/code&gt; (list): Friendly names of the categories&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;name&lt;/code&gt; (string): Friendly name of the smallest category&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;type&lt;/code&gt; (string): The &lt;a href="https://wiki.sponsor.ajay.app/w/Types#Action_Type"&gt;SponsorBlock action type&lt;/a&gt; of the chapter&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Each aforementioned sequence when referenced in an output template will be replaced by the actual value corresponding to the sequence name. E.g. for &lt;code&gt;-o %(title)s-%(id)s.%(ext)s&lt;/code&gt; and an mp4 video with title &lt;code&gt;yt-dlp test video&lt;/code&gt; and id &lt;code&gt;BaW_jenozKc&lt;/code&gt;, this will result in a &lt;code&gt;yt-dlp test video-BaW_jenozKc.mp4&lt;/code&gt; file created in the current directory.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: Some of the sequences are not guaranteed to be present, since they depend on the metadata obtained by a particular extractor. Such sequences will be replaced with placeholder value provided with &lt;code&gt;--output-na-placeholder&lt;/code&gt; (&lt;code&gt;NA&lt;/code&gt; by default).&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Tip&lt;/strong&gt;: Look at the &lt;code&gt;-j&lt;/code&gt; output to identify which fields are available for the particular URL&lt;/p&gt; 
&lt;p&gt;For numeric sequences, you can use &lt;a href="https://docs.python.org/3/library/stdtypes.html#printf-style-string-formatting"&gt;numeric related formatting&lt;/a&gt;; e.g. &lt;code&gt;%(view_count)05d&lt;/code&gt; will result in a string with view count padded with zeros up to 5 characters, like in &lt;code&gt;00042&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Output templates can also contain arbitrary hierarchical path, e.g. &lt;code&gt;-o "%(playlist)s/%(playlist_index)s - %(title)s.%(ext)s"&lt;/code&gt; which will result in downloading each video in a directory corresponding to this path template. Any missing directory will be automatically created for you.&lt;/p&gt; 
&lt;p&gt;To use percent literals in an output template use &lt;code&gt;%%&lt;/code&gt;. To output to stdout use &lt;code&gt;-o -&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;The current default template is &lt;code&gt;%(title)s [%(id)s].%(ext)s&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;In some cases, you don't want special characters such as ‰∏≠, spaces, or &amp;amp;, such as when transferring the downloaded filename to a Windows system or the filename through an 8bit-unsafe channel. In these cases, add the &lt;code&gt;--restrict-filenames&lt;/code&gt; flag to get a shorter title.&lt;/p&gt; 
&lt;h4&gt;Output template examples&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;$ yt-dlp --print filename -o "test video.%(ext)s" BaW_jenozKc
test video.webm    # Literal name with correct extension

$ yt-dlp --print filename -o "%(title)s.%(ext)s" BaW_jenozKc
youtube-dl test video ''_√§‚Ü≠ùïê.webm    # All kinds of weird characters

$ yt-dlp --print filename -o "%(title)s.%(ext)s" BaW_jenozKc --restrict-filenames
youtube-dl_test_video_.webm    # Restricted file name

# Download YouTube playlist videos in separate directory indexed by video order in a playlist
$ yt-dlp -o "%(playlist)s/%(playlist_index)s - %(title)s.%(ext)s" "https://www.youtube.com/playlist?list=PLwiyx1dc3P2JR9N8gQaQN_BCvlSlap7re"

# Download YouTube playlist videos in separate directories according to their uploaded year
$ yt-dlp -o "%(upload_date&amp;gt;%Y)s/%(title)s.%(ext)s" "https://www.youtube.com/playlist?list=PLwiyx1dc3P2JR9N8gQaQN_BCvlSlap7re"

# Prefix playlist index with " - " separator, but only if it is available
$ yt-dlp -o "%(playlist_index&amp;amp;{} - |)s%(title)s.%(ext)s" BaW_jenozKc "https://www.youtube.com/user/TheLinuxFoundation/playlists"

# Download all playlists of YouTube channel/user keeping each playlist in separate directory:
$ yt-dlp -o "%(uploader)s/%(playlist)s/%(playlist_index)s - %(title)s.%(ext)s" "https://www.youtube.com/user/TheLinuxFoundation/playlists"

# Download Udemy course keeping each chapter in separate directory under MyVideos directory in your home
$ yt-dlp -u user -p password -P "~/MyVideos" -o "%(playlist)s/%(chapter_number)s - %(chapter)s/%(title)s.%(ext)s" "https://www.udemy.com/java-tutorial"

# Download entire series season keeping each series and each season in separate directory under C:/MyVideos
$ yt-dlp -P "C:/MyVideos" -o "%(series)s/%(season_number)s - %(season)s/%(episode_number)s - %(episode)s.%(ext)s" "https://videomore.ru/kino_v_detalayah/5_sezon/367617"

# Download video as "C:\MyVideos\uploader\title.ext", subtitles as "C:\MyVideos\subs\uploader\title.ext"
# and put all temporary files in "C:\MyVideos\tmp"
$ yt-dlp -P "C:/MyVideos" -P "temp:tmp" -P "subtitle:subs" -o "%(uploader)s/%(title)s.%(ext)s" BaW_jenozKc --write-subs

# Download video as "C:\MyVideos\uploader\title.ext" and subtitles as "C:\MyVideos\uploader\subs\title.ext"
$ yt-dlp -P "C:/MyVideos" -o "%(uploader)s/%(title)s.%(ext)s" -o "subtitle:%(uploader)s/subs/%(title)s.%(ext)s" BaW_jenozKc --write-subs

# Stream the video being downloaded to stdout
$ yt-dlp -o - BaW_jenozKc
&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;FORMAT SELECTION&lt;/h1&gt; 
&lt;p&gt;By default, yt-dlp tries to download the best available quality if you &lt;strong&gt;don't&lt;/strong&gt; pass any options. This is generally equivalent to using &lt;code&gt;-f bestvideo*+bestaudio/best&lt;/code&gt;. However, if multiple audiostreams is enabled (&lt;code&gt;--audio-multistreams&lt;/code&gt;), the default format changes to &lt;code&gt;-f bestvideo+bestaudio/best&lt;/code&gt;. Similarly, if ffmpeg is unavailable, or if you use yt-dlp to stream to &lt;code&gt;stdout&lt;/code&gt; (&lt;code&gt;-o -&lt;/code&gt;), the default becomes &lt;code&gt;-f best/bestvideo+bestaudio&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Deprecation warning&lt;/strong&gt;: Latest versions of yt-dlp can stream multiple formats to the stdout simultaneously using ffmpeg. So, in future versions, the default for this will be set to &lt;code&gt;-f bv*+ba/b&lt;/code&gt; similar to normal downloads. If you want to preserve the &lt;code&gt;-f b/bv+ba&lt;/code&gt; setting, it is recommended to explicitly specify it in the configuration options.&lt;/p&gt; 
&lt;p&gt;The general syntax for format selection is &lt;code&gt;-f FORMAT&lt;/code&gt; (or &lt;code&gt;--format FORMAT&lt;/code&gt;) where &lt;code&gt;FORMAT&lt;/code&gt; is a &lt;em&gt;selector expression&lt;/em&gt;, i.e. an expression that describes format or formats you would like to download.&lt;/p&gt; 
&lt;!-- MANPAGE: BEGIN EXCLUDED SECTION --&gt; 
&lt;p&gt;&lt;strong&gt;tl;dr:&lt;/strong&gt; &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#format-selection-examples"&gt;navigate me to examples&lt;/a&gt;.&lt;/p&gt; 
&lt;!-- MANPAGE: END EXCLUDED SECTION --&gt; 
&lt;p&gt;The simplest case is requesting a specific format; e.g. with &lt;code&gt;-f 22&lt;/code&gt; you can download the format with format code equal to 22. You can get the list of available format codes for particular video using &lt;code&gt;--list-formats&lt;/code&gt; or &lt;code&gt;-F&lt;/code&gt;. Note that these format codes are extractor specific.&lt;/p&gt; 
&lt;p&gt;You can also use a file extension (currently &lt;code&gt;3gp&lt;/code&gt;, &lt;code&gt;aac&lt;/code&gt;, &lt;code&gt;flv&lt;/code&gt;, &lt;code&gt;m4a&lt;/code&gt;, &lt;code&gt;mp3&lt;/code&gt;, &lt;code&gt;mp4&lt;/code&gt;, &lt;code&gt;ogg&lt;/code&gt;, &lt;code&gt;wav&lt;/code&gt;, &lt;code&gt;webm&lt;/code&gt; are supported) to download the best quality format of a particular file extension served as a single file, e.g. &lt;code&gt;-f webm&lt;/code&gt; will download the best quality format with the &lt;code&gt;webm&lt;/code&gt; extension served as a single file.&lt;/p&gt; 
&lt;p&gt;You can use &lt;code&gt;-f -&lt;/code&gt; to interactively provide the format selector &lt;em&gt;for each video&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;You can also use special names to select particular edge case formats:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;all&lt;/code&gt;: Select &lt;strong&gt;all formats&lt;/strong&gt; separately&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;mergeall&lt;/code&gt;: Select and &lt;strong&gt;merge all formats&lt;/strong&gt; (Must be used with &lt;code&gt;--audio-multistreams&lt;/code&gt;, &lt;code&gt;--video-multistreams&lt;/code&gt; or both)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;b*&lt;/code&gt;, &lt;code&gt;best*&lt;/code&gt;: Select the best quality format that &lt;strong&gt;contains either&lt;/strong&gt; a video or an audio or both (i.e.; &lt;code&gt;vcodec!=none or acodec!=none&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;b&lt;/code&gt;, &lt;code&gt;best&lt;/code&gt;: Select the best quality format that &lt;strong&gt;contains both&lt;/strong&gt; video and audio. Equivalent to &lt;code&gt;best*[vcodec!=none][acodec!=none]&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;bv&lt;/code&gt;, &lt;code&gt;bestvideo&lt;/code&gt;: Select the best quality &lt;strong&gt;video-only&lt;/strong&gt; format. Equivalent to &lt;code&gt;best*[acodec=none]&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;bv*&lt;/code&gt;, &lt;code&gt;bestvideo*&lt;/code&gt;: Select the best quality format that &lt;strong&gt;contains video&lt;/strong&gt;. It may also contain audio. Equivalent to &lt;code&gt;best*[vcodec!=none]&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;ba&lt;/code&gt;, &lt;code&gt;bestaudio&lt;/code&gt;: Select the best quality &lt;strong&gt;audio-only&lt;/strong&gt; format. Equivalent to &lt;code&gt;best*[vcodec=none]&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;ba*&lt;/code&gt;, &lt;code&gt;bestaudio*&lt;/code&gt;: Select the best quality format that &lt;strong&gt;contains audio&lt;/strong&gt;. It may also contain video. Equivalent to &lt;code&gt;best*[acodec!=none]&lt;/code&gt; (&lt;a href="https://github.com/yt-dlp/yt-dlp/issues/979#issuecomment-919629354"&gt;Do not use!&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;w*&lt;/code&gt;, &lt;code&gt;worst*&lt;/code&gt;: Select the worst quality format that contains either a video or an audio&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;w&lt;/code&gt;, &lt;code&gt;worst&lt;/code&gt;: Select the worst quality format that contains both video and audio. Equivalent to &lt;code&gt;worst*[vcodec!=none][acodec!=none]&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;wv&lt;/code&gt;, &lt;code&gt;worstvideo&lt;/code&gt;: Select the worst quality video-only format. Equivalent to &lt;code&gt;worst*[acodec=none]&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;wv*&lt;/code&gt;, &lt;code&gt;worstvideo*&lt;/code&gt;: Select the worst quality format that contains video. It may also contain audio. Equivalent to &lt;code&gt;worst*[vcodec!=none]&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;wa&lt;/code&gt;, &lt;code&gt;worstaudio&lt;/code&gt;: Select the worst quality audio-only format. Equivalent to &lt;code&gt;worst*[vcodec=none]&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;wa*&lt;/code&gt;, &lt;code&gt;worstaudio*&lt;/code&gt;: Select the worst quality format that contains audio. It may also contain video. Equivalent to &lt;code&gt;worst*[acodec!=none]&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For example, to download the worst quality video-only format you can use &lt;code&gt;-f worstvideo&lt;/code&gt;. It is, however, recommended not to use &lt;code&gt;worst&lt;/code&gt; and related options. When your format selector is &lt;code&gt;worst&lt;/code&gt;, the format which is worst in all respects is selected. Most of the time, what you actually want is the video with the smallest filesize instead. So it is generally better to use &lt;code&gt;-S +size&lt;/code&gt; or more rigorously, &lt;code&gt;-S +size,+br,+res,+fps&lt;/code&gt; instead of &lt;code&gt;-f worst&lt;/code&gt;. See &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#sorting-formats"&gt;Sorting Formats&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;p&gt;You can select the n'th best format of a type by using &lt;code&gt;best&amp;lt;type&amp;gt;.&amp;lt;n&amp;gt;&lt;/code&gt;. For example, &lt;code&gt;best.2&lt;/code&gt; will select the 2nd best combined format. Similarly, &lt;code&gt;bv*.3&lt;/code&gt; will select the 3rd best format that contains a video stream.&lt;/p&gt; 
&lt;p&gt;If you want to download multiple videos, and they don't have the same formats available, you can specify the order of preference using slashes. Note that formats on the left hand side are preferred; e.g. &lt;code&gt;-f 22/17/18&lt;/code&gt; will download format 22 if it's available, otherwise it will download format 17 if it's available, otherwise it will download format 18 if it's available, otherwise it will complain that no suitable formats are available for download.&lt;/p&gt; 
&lt;p&gt;If you want to download several formats of the same video use a comma as a separator, e.g. &lt;code&gt;-f 22,17,18&lt;/code&gt; will download all these three formats, of course if they are available. Or a more sophisticated example combined with the precedence feature: &lt;code&gt;-f 136/137/mp4/bestvideo,140/m4a/bestaudio&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;You can merge the video and audio of multiple formats into a single file using &lt;code&gt;-f &amp;lt;format1&amp;gt;+&amp;lt;format2&amp;gt;+...&lt;/code&gt; (requires ffmpeg installed); e.g. &lt;code&gt;-f bestvideo+bestaudio&lt;/code&gt; will download the best video-only format, the best audio-only format and mux them together with ffmpeg.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Deprecation warning&lt;/strong&gt;: Since the &lt;em&gt;below&lt;/em&gt; described behavior is complex and counter-intuitive, this will be removed and multistreams will be enabled by default in the future. A new operator will be instead added to limit formats to single audio/video&lt;/p&gt; 
&lt;p&gt;Unless &lt;code&gt;--video-multistreams&lt;/code&gt; is used, all formats with a video stream except the first one are ignored. Similarly, unless &lt;code&gt;--audio-multistreams&lt;/code&gt; is used, all formats with an audio stream except the first one are ignored. E.g. &lt;code&gt;-f bestvideo+best+bestaudio --video-multistreams --audio-multistreams&lt;/code&gt; will download and merge all 3 given formats. The resulting file will have 2 video streams and 2 audio streams. But &lt;code&gt;-f bestvideo+best+bestaudio --no-video-multistreams&lt;/code&gt; will download and merge only &lt;code&gt;bestvideo&lt;/code&gt; and &lt;code&gt;bestaudio&lt;/code&gt;. &lt;code&gt;best&lt;/code&gt; is ignored since another format containing a video stream (&lt;code&gt;bestvideo&lt;/code&gt;) has already been selected. The order of the formats is therefore important. &lt;code&gt;-f best+bestaudio --no-audio-multistreams&lt;/code&gt; will download only &lt;code&gt;best&lt;/code&gt; while &lt;code&gt;-f bestaudio+best --no-audio-multistreams&lt;/code&gt; will ignore &lt;code&gt;best&lt;/code&gt; and download only &lt;code&gt;bestaudio&lt;/code&gt;.&lt;/p&gt; 
&lt;h2&gt;Filtering Formats&lt;/h2&gt; 
&lt;p&gt;You can also filter the video formats by putting a condition in brackets, as in &lt;code&gt;-f "best[height=720]"&lt;/code&gt; (or &lt;code&gt;-f "[filesize&amp;gt;10M]"&lt;/code&gt; since filters without a selector are interpreted as &lt;code&gt;best&lt;/code&gt;).&lt;/p&gt; 
&lt;p&gt;The following numeric meta fields can be used with comparisons &lt;code&gt;&amp;lt;&lt;/code&gt;, &lt;code&gt;&amp;lt;=&lt;/code&gt;, &lt;code&gt;&amp;gt;&lt;/code&gt;, &lt;code&gt;&amp;gt;=&lt;/code&gt;, &lt;code&gt;=&lt;/code&gt; (equals), &lt;code&gt;!=&lt;/code&gt; (not equals):&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;filesize&lt;/code&gt;: The number of bytes, if known in advance&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;filesize_approx&lt;/code&gt;: An estimate for the number of bytes&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;width&lt;/code&gt;: Width of the video, if known&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;height&lt;/code&gt;: Height of the video, if known&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;aspect_ratio&lt;/code&gt;: Aspect ratio of the video, if known&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;tbr&lt;/code&gt;: Average bitrate of audio and video in &lt;a href="##" title="1000 bits/sec"&gt;kbps&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;abr&lt;/code&gt;: Average audio bitrate in &lt;a href="##" title="1000 bits/sec"&gt;kbps&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;vbr&lt;/code&gt;: Average video bitrate in &lt;a href="##" title="1000 bits/sec"&gt;kbps&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;asr&lt;/code&gt;: Audio sampling rate in Hertz&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;fps&lt;/code&gt;: Frame rate&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;audio_channels&lt;/code&gt;: The number of audio channels&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;stretched_ratio&lt;/code&gt;: &lt;code&gt;width:height&lt;/code&gt; of the video's pixels, if not square&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Also filtering work for comparisons &lt;code&gt;=&lt;/code&gt; (equals), &lt;code&gt;^=&lt;/code&gt; (starts with), &lt;code&gt;$=&lt;/code&gt; (ends with), &lt;code&gt;*=&lt;/code&gt; (contains), &lt;code&gt;~=&lt;/code&gt; (matches regex) and following string meta fields:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;url&lt;/code&gt;: Video URL&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;ext&lt;/code&gt;: File extension&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;acodec&lt;/code&gt;: Name of the audio codec in use&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;vcodec&lt;/code&gt;: Name of the video codec in use&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;container&lt;/code&gt;: Name of the container format&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;protocol&lt;/code&gt;: The protocol that will be used for the actual download, lower-case (&lt;code&gt;http&lt;/code&gt;, &lt;code&gt;https&lt;/code&gt;, &lt;code&gt;rtsp&lt;/code&gt;, &lt;code&gt;rtmp&lt;/code&gt;, &lt;code&gt;rtmpe&lt;/code&gt;, &lt;code&gt;mms&lt;/code&gt;, &lt;code&gt;f4m&lt;/code&gt;, &lt;code&gt;ism&lt;/code&gt;, &lt;code&gt;http_dash_segments&lt;/code&gt;, &lt;code&gt;m3u8&lt;/code&gt;, or &lt;code&gt;m3u8_native&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;language&lt;/code&gt;: Language code&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;dynamic_range&lt;/code&gt;: The dynamic range of the video&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;format_id&lt;/code&gt;: A short description of the format&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;format&lt;/code&gt;: A human-readable description of the format&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;format_note&lt;/code&gt;: Additional info about the format&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;resolution&lt;/code&gt;: Textual description of width and height&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Any string comparison may be prefixed with negation &lt;code&gt;!&lt;/code&gt; in order to produce an opposite comparison, e.g. &lt;code&gt;!*=&lt;/code&gt; (does not contain). The comparand of a string comparison needs to be quoted with either double or single quotes if it contains spaces or special characters other than &lt;code&gt;._-&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: None of the aforementioned meta fields are guaranteed to be present since this solely depends on the metadata obtained by the particular extractor, i.e. the metadata offered by the website. Any other field made available by the extractor can also be used for filtering.&lt;/p&gt; 
&lt;p&gt;Formats for which the value is not known are excluded unless you put a question mark (&lt;code&gt;?&lt;/code&gt;) after the operator. You can combine format filters, so &lt;code&gt;-f "bv[height&amp;lt;=?720][tbr&amp;gt;500]"&lt;/code&gt; selects up to 720p videos (or videos where the height is not known) with a bitrate of at least 500 kbps. You can also use the filters with &lt;code&gt;all&lt;/code&gt; to download all formats that satisfy the filter, e.g. &lt;code&gt;-f "all[vcodec=none]"&lt;/code&gt; selects all audio-only formats.&lt;/p&gt; 
&lt;p&gt;Format selectors can also be grouped using parentheses; e.g. &lt;code&gt;-f "(mp4,webm)[height&amp;lt;480]"&lt;/code&gt; will download the best pre-merged mp4 and webm formats with a height lower than 480.&lt;/p&gt; 
&lt;h2&gt;Sorting Formats&lt;/h2&gt; 
&lt;p&gt;You can change the criteria for being considered the &lt;code&gt;best&lt;/code&gt; by using &lt;code&gt;-S&lt;/code&gt; (&lt;code&gt;--format-sort&lt;/code&gt;). The general format for this is &lt;code&gt;--format-sort field1,field2...&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;The available fields are:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;hasvid&lt;/code&gt;: Gives priority to formats that have a video stream&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;hasaud&lt;/code&gt;: Gives priority to formats that have an audio stream&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;ie_pref&lt;/code&gt;: The format preference&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;lang&lt;/code&gt;: The language preference as determined by the extractor (e.g. original language preferred over audio description)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;quality&lt;/code&gt;: The quality of the format&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;source&lt;/code&gt;: The preference of the source&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;proto&lt;/code&gt;: Protocol used for download (&lt;code&gt;https&lt;/code&gt;/&lt;code&gt;ftps&lt;/code&gt; &amp;gt; &lt;code&gt;http&lt;/code&gt;/&lt;code&gt;ftp&lt;/code&gt; &amp;gt; &lt;code&gt;m3u8_native&lt;/code&gt;/&lt;code&gt;m3u8&lt;/code&gt; &amp;gt; &lt;code&gt;http_dash_segments&lt;/code&gt;&amp;gt; &lt;code&gt;websocket_frag&lt;/code&gt; &amp;gt; &lt;code&gt;mms&lt;/code&gt;/&lt;code&gt;rtsp&lt;/code&gt; &amp;gt; &lt;code&gt;f4f&lt;/code&gt;/&lt;code&gt;f4m&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;vcodec&lt;/code&gt;: Video Codec (&lt;code&gt;av01&lt;/code&gt; &amp;gt; &lt;code&gt;vp9.2&lt;/code&gt; &amp;gt; &lt;code&gt;vp9&lt;/code&gt; &amp;gt; &lt;code&gt;h265&lt;/code&gt; &amp;gt; &lt;code&gt;h264&lt;/code&gt; &amp;gt; &lt;code&gt;vp8&lt;/code&gt; &amp;gt; &lt;code&gt;h263&lt;/code&gt; &amp;gt; &lt;code&gt;theora&lt;/code&gt; &amp;gt; other)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;acodec&lt;/code&gt;: Audio Codec (&lt;code&gt;flac&lt;/code&gt;/&lt;code&gt;alac&lt;/code&gt; &amp;gt; &lt;code&gt;wav&lt;/code&gt;/&lt;code&gt;aiff&lt;/code&gt; &amp;gt; &lt;code&gt;opus&lt;/code&gt; &amp;gt; &lt;code&gt;vorbis&lt;/code&gt; &amp;gt; &lt;code&gt;aac&lt;/code&gt; &amp;gt; &lt;code&gt;mp4a&lt;/code&gt; &amp;gt; &lt;code&gt;mp3&lt;/code&gt; &amp;gt; &lt;code&gt;ac4&lt;/code&gt; &amp;gt; &lt;code&gt;eac3&lt;/code&gt; &amp;gt; &lt;code&gt;ac3&lt;/code&gt; &amp;gt; &lt;code&gt;dts&lt;/code&gt; &amp;gt; other)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;codec&lt;/code&gt;: Equivalent to &lt;code&gt;vcodec,acodec&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;vext&lt;/code&gt;: Video Extension (&lt;code&gt;mp4&lt;/code&gt; &amp;gt; &lt;code&gt;mov&lt;/code&gt; &amp;gt; &lt;code&gt;webm&lt;/code&gt; &amp;gt; &lt;code&gt;flv&lt;/code&gt; &amp;gt; other). If &lt;code&gt;--prefer-free-formats&lt;/code&gt; is used, &lt;code&gt;webm&lt;/code&gt; is preferred.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;aext&lt;/code&gt;: Audio Extension (&lt;code&gt;m4a&lt;/code&gt; &amp;gt; &lt;code&gt;aac&lt;/code&gt; &amp;gt; &lt;code&gt;mp3&lt;/code&gt; &amp;gt; &lt;code&gt;ogg&lt;/code&gt; &amp;gt; &lt;code&gt;opus&lt;/code&gt; &amp;gt; &lt;code&gt;webm&lt;/code&gt; &amp;gt; other). If &lt;code&gt;--prefer-free-formats&lt;/code&gt; is used, the order changes to &lt;code&gt;ogg&lt;/code&gt; &amp;gt; &lt;code&gt;opus&lt;/code&gt; &amp;gt; &lt;code&gt;webm&lt;/code&gt; &amp;gt; &lt;code&gt;mp3&lt;/code&gt; &amp;gt; &lt;code&gt;m4a&lt;/code&gt; &amp;gt; &lt;code&gt;aac&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;ext&lt;/code&gt;: Equivalent to &lt;code&gt;vext,aext&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;filesize&lt;/code&gt;: Exact filesize, if known in advance&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;fs_approx&lt;/code&gt;: Approximate filesize&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;size&lt;/code&gt;: Exact filesize if available, otherwise approximate filesize&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;height&lt;/code&gt;: Height of video&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;width&lt;/code&gt;: Width of video&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;res&lt;/code&gt;: Video resolution, calculated as the smallest dimension.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;fps&lt;/code&gt;: Framerate of video&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;hdr&lt;/code&gt;: The dynamic range of the video (&lt;code&gt;DV&lt;/code&gt; &amp;gt; &lt;code&gt;HDR12&lt;/code&gt; &amp;gt; &lt;code&gt;HDR10+&lt;/code&gt; &amp;gt; &lt;code&gt;HDR10&lt;/code&gt; &amp;gt; &lt;code&gt;HLG&lt;/code&gt; &amp;gt; &lt;code&gt;SDR&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;channels&lt;/code&gt;: The number of audio channels&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;tbr&lt;/code&gt;: Total average bitrate in &lt;a href="##" title="1000 bits/sec"&gt;kbps&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;vbr&lt;/code&gt;: Average video bitrate in &lt;a href="##" title="1000 bits/sec"&gt;kbps&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;abr&lt;/code&gt;: Average audio bitrate in &lt;a href="##" title="1000 bits/sec"&gt;kbps&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;br&lt;/code&gt;: Average bitrate in &lt;a href="##" title="1000 bits/sec"&gt;kbps&lt;/a&gt;, &lt;code&gt;tbr&lt;/code&gt;/&lt;code&gt;vbr&lt;/code&gt;/&lt;code&gt;abr&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;asr&lt;/code&gt;: Audio sample rate in Hz&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Deprecation warning&lt;/strong&gt;: Many of these fields have (currently undocumented) aliases, that may be removed in a future version. It is recommended to use only the documented field names.&lt;/p&gt; 
&lt;p&gt;All fields, unless specified otherwise, are sorted in descending order. To reverse this, prefix the field with a &lt;code&gt;+&lt;/code&gt;. E.g. &lt;code&gt;+res&lt;/code&gt; prefers format with the smallest resolution. Additionally, you can suffix a preferred value for the fields, separated by a &lt;code&gt;:&lt;/code&gt;. E.g. &lt;code&gt;res:720&lt;/code&gt; prefers larger videos, but no larger than 720p and the smallest video if there are no videos less than 720p. For &lt;code&gt;codec&lt;/code&gt; and &lt;code&gt;ext&lt;/code&gt;, you can provide two preferred values, the first for video and the second for audio. E.g. &lt;code&gt;+codec:avc:m4a&lt;/code&gt; (equivalent to &lt;code&gt;+vcodec:avc,+acodec:m4a&lt;/code&gt;) sets the video codec preference to &lt;code&gt;h264&lt;/code&gt; &amp;gt; &lt;code&gt;h265&lt;/code&gt; &amp;gt; &lt;code&gt;vp9&lt;/code&gt; &amp;gt; &lt;code&gt;vp9.2&lt;/code&gt; &amp;gt; &lt;code&gt;av01&lt;/code&gt; &amp;gt; &lt;code&gt;vp8&lt;/code&gt; &amp;gt; &lt;code&gt;h263&lt;/code&gt; &amp;gt; &lt;code&gt;theora&lt;/code&gt; and audio codec preference to &lt;code&gt;mp4a&lt;/code&gt; &amp;gt; &lt;code&gt;aac&lt;/code&gt; &amp;gt; &lt;code&gt;vorbis&lt;/code&gt; &amp;gt; &lt;code&gt;opus&lt;/code&gt; &amp;gt; &lt;code&gt;mp3&lt;/code&gt; &amp;gt; &lt;code&gt;ac3&lt;/code&gt; &amp;gt; &lt;code&gt;dts&lt;/code&gt;. You can also make the sorting prefer the nearest values to the provided by using &lt;code&gt;~&lt;/code&gt; as the delimiter. E.g. &lt;code&gt;filesize~1G&lt;/code&gt; prefers the format with filesize closest to 1 GiB.&lt;/p&gt; 
&lt;p&gt;The fields &lt;code&gt;hasvid&lt;/code&gt; and &lt;code&gt;ie_pref&lt;/code&gt; are always given highest priority in sorting, irrespective of the user-defined order. This behavior can be changed by using &lt;code&gt;--format-sort-force&lt;/code&gt;. Apart from these, the default order used is: &lt;code&gt;lang,quality,res,fps,hdr:12,vcodec,channels,acodec,size,br,asr,proto,ext,hasaud,source,id&lt;/code&gt;. The extractors may override this default order, but they cannot override the user-provided order.&lt;/p&gt; 
&lt;p&gt;Note that the default for hdr is &lt;code&gt;hdr:12&lt;/code&gt;; i.e. Dolby Vision is not preferred. This choice was made since DV formats are not yet fully compatible with most devices. This may be changed in the future.&lt;/p&gt; 
&lt;p&gt;If your format selector is &lt;code&gt;worst&lt;/code&gt;, the last item is selected after sorting. This means it will select the format that is worst in all respects. Most of the time, what you actually want is the video with the smallest filesize instead. So it is generally better to use &lt;code&gt;-f best -S +size,+br,+res,+fps&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Tip&lt;/strong&gt;: You can use the &lt;code&gt;-v -F&lt;/code&gt; to see how the formats have been sorted (worst to best).&lt;/p&gt; 
&lt;h2&gt;Format Selection examples&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Download and merge the best video-only format and the best audio-only format,
# or download the best combined format if video-only format is not available
$ yt-dlp -f "bv+ba/b"

# Download best format that contains video,
# and if it doesn't already have an audio stream, merge it with best audio-only format
$ yt-dlp -f "bv*+ba/b"

# Same as above
$ yt-dlp

# Download the best video-only format and the best audio-only format without merging them
# For this case, an output template should be used since
# by default, bestvideo and bestaudio will have the same file name.
$ yt-dlp -f "bv,ba" -o "%(title)s.f%(format_id)s.%(ext)s"

# Download and merge the best format that has a video stream,
# and all audio-only formats into one file
$ yt-dlp -f "bv*+mergeall[vcodec=none]" --audio-multistreams

# Download and merge the best format that has a video stream,
# and the best 2 audio-only formats into one file
$ yt-dlp -f "bv*+ba+ba.2" --audio-multistreams


# The following examples show the old method (without -S) of format selection
# and how to use -S to achieve a similar but (generally) better result

# Download the worst video available (old method)
$ yt-dlp -f "wv*+wa/w"

# Download the best video available but with the smallest resolution
$ yt-dlp -S "+res"

# Download the smallest video available
$ yt-dlp -S "+size,+br"



# Download the best mp4 video available, or the best video if no mp4 available
$ yt-dlp -f "bv*[ext=mp4]+ba[ext=m4a]/b[ext=mp4] / bv*+ba/b"

# Download the best video with the best extension
# (For video, mp4 &amp;gt; mov &amp;gt; webm &amp;gt; flv. For audio, m4a &amp;gt; aac &amp;gt; mp3 ...)
$ yt-dlp -S "ext"



# Download the best video available but no better than 480p,
# or the worst video if there is no video under 480p
$ yt-dlp -f "bv*[height&amp;lt;=480]+ba/b[height&amp;lt;=480] / wv*+ba/w"

# Download the best video available with the largest height but no better than 480p,
# or the best video with the smallest resolution if there is no video under 480p
$ yt-dlp -S "height:480"

# Download the best video available with the largest resolution but no better than 480p,
# or the best video with the smallest resolution if there is no video under 480p
# Resolution is determined by using the smallest dimension.
# So this works correctly for vertical videos as well
$ yt-dlp -S "res:480"



# Download the best video (that also has audio) but no bigger than 50 MB,
# or the worst video (that also has audio) if there is no video under 50 MB
$ yt-dlp -f "b[filesize&amp;lt;50M] / w"

# Download the largest video (that also has audio) but no bigger than 50 MB,
# or the smallest video (that also has audio) if there is no video under 50 MB
$ yt-dlp -f "b" -S "filesize:50M"

# Download the best video (that also has audio) that is closest in size to 50 MB
$ yt-dlp -f "b" -S "filesize~50M"



# Download best video available via direct link over HTTP/HTTPS protocol,
# or the best video available via any protocol if there is no such video
$ yt-dlp -f "(bv*+ba/b)[protocol^=http][protocol!*=dash] / (bv*+ba/b)"

# Download best video available via the best protocol
# (https/ftps &amp;gt; http/ftp &amp;gt; m3u8_native &amp;gt; m3u8 &amp;gt; http_dash_segments ...)
$ yt-dlp -S "proto"



# Download the best video with either h264 or h265 codec,
# or the best video if there is no such video
$ yt-dlp -f "(bv*[vcodec~='^((he|a)vc|h26[45])']+ba) / (bv*+ba/b)"

# Download the best video with best codec no better than h264,
# or the best video with worst codec if there is no such video
$ yt-dlp -S "codec:h264"

# Download the best video with worst codec no worse than h264,
# or the best video with best codec if there is no such video
$ yt-dlp -S "+codec:h264"



# More complex examples

# Download the best video no better than 720p preferring framerate greater than 30,
# or the worst video (still preferring framerate greater than 30) if there is no such video
$ yt-dlp -f "((bv*[fps&amp;gt;30]/bv*)[height&amp;lt;=720]/(wv*[fps&amp;gt;30]/wv*)) + ba / (b[fps&amp;gt;30]/b)[height&amp;lt;=720]/(w[fps&amp;gt;30]/w)"

# Download the video with the largest resolution no better than 720p,
# or the video with the smallest resolution available if there is no such video,
# preferring larger framerate for formats with the same resolution
$ yt-dlp -S "res:720,fps"



# Download the video with smallest resolution no worse than 480p,
# or the video with the largest resolution available if there is no such video,
# preferring better codec and then larger total bitrate for the same resolution
$ yt-dlp -S "+res:480,codec,br"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;MODIFYING METADATA&lt;/h1&gt; 
&lt;p&gt;The metadata obtained by the extractors can be modified by using &lt;code&gt;--parse-metadata&lt;/code&gt; and &lt;code&gt;--replace-in-metadata&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;--replace-in-metadata FIELDS REGEX REPLACE&lt;/code&gt; is used to replace text in any metadata field using &lt;a href="https://docs.python.org/3/library/re.html#regular-expression-syntax"&gt;Python regular expression&lt;/a&gt;. &lt;a href="https://docs.python.org/3/library/re.html?highlight=backreferences#re.sub"&gt;Backreferences&lt;/a&gt; can be used in the replace string for advanced use.&lt;/p&gt; 
&lt;p&gt;The general syntax of &lt;code&gt;--parse-metadata FROM:TO&lt;/code&gt; is to give the name of a field or an &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#output-template"&gt;output template&lt;/a&gt; to extract data from, and the format to interpret it as, separated by a colon &lt;code&gt;:&lt;/code&gt;. Either a &lt;a href="https://docs.python.org/3/library/re.html#regular-expression-syntax"&gt;Python regular expression&lt;/a&gt; with named capture groups, a single field name, or a similar syntax to the &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#output-template"&gt;output template&lt;/a&gt; (only &lt;code&gt;%(field)s&lt;/code&gt; formatting is supported) can be used for &lt;code&gt;TO&lt;/code&gt;. The option can be used multiple times to parse and modify various fields.&lt;/p&gt; 
&lt;p&gt;Note that these options preserve their relative order, allowing replacements to be made in parsed fields and vice versa. Also, any field thus created can be used in the &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#output-template"&gt;output template&lt;/a&gt; and will also affect the media file's metadata added when using &lt;code&gt;--embed-metadata&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;This option also has a few special uses:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;You can download an additional URL based on the metadata of the currently downloaded video. To do this, set the field &lt;code&gt;additional_urls&lt;/code&gt; to the URL that you want to download. E.g. &lt;code&gt;--parse-metadata "description:(?P&amp;lt;additional_urls&amp;gt;https?://www\.vimeo\.com/\d+)"&lt;/code&gt; will download the first vimeo video found in the description&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;You can use this to change the metadata that is embedded in the media file. To do this, set the value of the corresponding field with a &lt;code&gt;meta_&lt;/code&gt; prefix. For example, any value you set to &lt;code&gt;meta_description&lt;/code&gt; field will be added to the &lt;code&gt;description&lt;/code&gt; field in the file - you can use this to set a different "description" and "synopsis". To modify the metadata of individual streams, use the &lt;code&gt;meta&amp;lt;n&amp;gt;_&lt;/code&gt; prefix (e.g. &lt;code&gt;meta1_language&lt;/code&gt;). Any value set to the &lt;code&gt;meta_&lt;/code&gt; field will overwrite all default values.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: Metadata modification happens before format selection, post-extraction and other post-processing operations. Some fields may be added or changed during these steps, overriding your changes.&lt;/p&gt; 
&lt;p&gt;For reference, these are the fields yt-dlp adds by default to the file metadata:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Metadata fields&lt;/th&gt; 
   &lt;th align="left"&gt;From&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;title&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;track&lt;/code&gt; or &lt;code&gt;title&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;date&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;upload_date&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;description&lt;/code&gt;, &lt;code&gt;synopsis&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;description&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;purl&lt;/code&gt;, &lt;code&gt;comment&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;webpage_url&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;track&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;track_number&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;artist&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;artist&lt;/code&gt;, &lt;code&gt;artists&lt;/code&gt;, &lt;code&gt;creator&lt;/code&gt;, &lt;code&gt;creators&lt;/code&gt;, &lt;code&gt;uploader&lt;/code&gt; or &lt;code&gt;uploader_id&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;composer&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;composer&lt;/code&gt; or &lt;code&gt;composers&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;genre&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;genre&lt;/code&gt; or &lt;code&gt;genres&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;album&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;album&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;album_artist&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;album_artist&lt;/code&gt; or &lt;code&gt;album_artists&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;disc&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;disc_number&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;show&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;series&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;season_number&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;season_number&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;episode_id&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;episode&lt;/code&gt; or &lt;code&gt;episode_id&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;episode_sort&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;episode_number&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;language&lt;/code&gt; of each stream&lt;/td&gt; 
   &lt;td align="left"&gt;the format's &lt;code&gt;language&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: The file format may not support some of these fields&lt;/p&gt; 
&lt;h2&gt;Modifying metadata examples&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Interpret the title as "Artist - Title"
$ yt-dlp --parse-metadata "title:%(artist)s - %(title)s"

# Regex example
$ yt-dlp --parse-metadata "description:Artist - (?P&amp;lt;artist&amp;gt;.+)"

# Set title as "Series name S01E05"
$ yt-dlp --parse-metadata "%(series)s S%(season_number)02dE%(episode_number)02d:%(title)s"

# Prioritize uploader as the "artist" field in video metadata
$ yt-dlp --parse-metadata "%(uploader|)s:%(meta_artist)s" --embed-metadata

# Set "comment" field in video metadata using description instead of webpage_url,
# handling multiple lines correctly
$ yt-dlp --parse-metadata "description:(?s)(?P&amp;lt;meta_comment&amp;gt;.+)" --embed-metadata

# Do not set any "synopsis" in the video metadata
$ yt-dlp --parse-metadata ":(?P&amp;lt;meta_synopsis&amp;gt;)"

# Remove "formats" field from the infojson by setting it to an empty string
$ yt-dlp --parse-metadata "video::(?P&amp;lt;formats&amp;gt;)" --write-info-json

# Replace all spaces and "_" in title and uploader with a `-`
$ yt-dlp --replace-in-metadata "title,uploader" "[ _]" "-"

&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;EXTRACTOR ARGUMENTS&lt;/h1&gt; 
&lt;p&gt;Some extractors accept additional arguments which can be passed using &lt;code&gt;--extractor-args KEY:ARGS&lt;/code&gt;. &lt;code&gt;ARGS&lt;/code&gt; is a &lt;code&gt;;&lt;/code&gt; (semicolon) separated string of &lt;code&gt;ARG=VAL1,VAL2&lt;/code&gt;. E.g. &lt;code&gt;--extractor-args "youtube:player-client=tv,mweb;formats=incomplete" --extractor-args "twitter:api=syndication"&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;Note: In CLI, &lt;code&gt;ARG&lt;/code&gt; can use &lt;code&gt;-&lt;/code&gt; instead of &lt;code&gt;_&lt;/code&gt;; e.g. &lt;code&gt;youtube:player-client"&lt;/code&gt; becomes &lt;code&gt;youtube:player_client"&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;The following extractors use this feature:&lt;/p&gt; 
&lt;h4&gt;youtube&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;lang&lt;/code&gt;: Prefer translated metadata (&lt;code&gt;title&lt;/code&gt;, &lt;code&gt;description&lt;/code&gt; etc) of this language code (case-sensitive). By default, the video primary language metadata is preferred, with a fallback to &lt;code&gt;en&lt;/code&gt; translated. See &lt;a href="https://github.com/yt-dlp/yt-dlp/raw/415b4c9f955b1a0391204bd24a7132590e7b3bdb/yt_dlp/extractor/youtube/_base.py#L402-L409"&gt;youtube/_base.py&lt;/a&gt; for the list of supported content language codes&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;skip&lt;/code&gt;: One or more of &lt;code&gt;hls&lt;/code&gt;, &lt;code&gt;dash&lt;/code&gt; or &lt;code&gt;translated_subs&lt;/code&gt; to skip extraction of the m3u8 manifests, dash manifests and &lt;a href="https://github.com/yt-dlp/yt-dlp/issues/4090#issuecomment-1158102032"&gt;auto-translated subtitles&lt;/a&gt; respectively&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;player_client&lt;/code&gt;: Clients to extract video data from. The currently available clients are &lt;code&gt;web&lt;/code&gt;, &lt;code&gt;web_safari&lt;/code&gt;, &lt;code&gt;web_embedded&lt;/code&gt;, &lt;code&gt;web_music&lt;/code&gt;, &lt;code&gt;web_creator&lt;/code&gt;, &lt;code&gt;mweb&lt;/code&gt;, &lt;code&gt;ios&lt;/code&gt;, &lt;code&gt;android&lt;/code&gt;, &lt;code&gt;android_sdkless&lt;/code&gt;, &lt;code&gt;android_vr&lt;/code&gt;, &lt;code&gt;tv&lt;/code&gt;, &lt;code&gt;tv_simply&lt;/code&gt;, &lt;code&gt;tv_downgraded&lt;/code&gt;, and &lt;code&gt;tv_embedded&lt;/code&gt;. By default, &lt;code&gt;tv,android_sdkless,web&lt;/code&gt; is used. If no JavaScript runtime is available, then &lt;code&gt;android_sdkless,web_safari,web&lt;/code&gt; is used. If logged-in cookies are passed to yt-dlp, then &lt;code&gt;tv_downgraded,web_safari,web&lt;/code&gt; is used for free accounts and &lt;code&gt;tv_downgraded,web_creator,web&lt;/code&gt; is used for premium accounts. The &lt;code&gt;web_music&lt;/code&gt; client is added for &lt;code&gt;music.youtube.com&lt;/code&gt; URLs when logged-in cookies are used. The &lt;code&gt;web_embedded&lt;/code&gt; client is added for age-restricted videos but only works if the video is embeddable. The &lt;code&gt;tv_embedded&lt;/code&gt; and &lt;code&gt;web_creator&lt;/code&gt; clients are added for age-restricted videos if account age-verification is required. Some clients, such as &lt;code&gt;web&lt;/code&gt; and &lt;code&gt;web_music&lt;/code&gt;, require a &lt;code&gt;po_token&lt;/code&gt; for their formats to be downloadable. Some clients, such as &lt;code&gt;web_creator&lt;/code&gt;, will only work with authentication. Not all clients support authentication via cookies. You can use &lt;code&gt;default&lt;/code&gt; for the default clients, or you can use &lt;code&gt;all&lt;/code&gt; for all clients (not recommended). You can prefix a client with &lt;code&gt;-&lt;/code&gt; to exclude it, e.g. &lt;code&gt;youtube:player_client=default,-ios&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;player_skip&lt;/code&gt;: Skip some network requests that are generally needed for robust extraction. One or more of &lt;code&gt;configs&lt;/code&gt; (skip client configs), &lt;code&gt;webpage&lt;/code&gt; (skip initial webpage), &lt;code&gt;js&lt;/code&gt; (skip js player), &lt;code&gt;initial_data&lt;/code&gt; (skip initial data/next ep request). While these options can help reduce the number of requests needed or avoid some rate-limiting, they could cause issues such as missing formats or metadata. See &lt;a href="https://github.com/yt-dlp/yt-dlp/pull/860"&gt;#860&lt;/a&gt; and &lt;a href="https://github.com/yt-dlp/yt-dlp/issues/12826"&gt;#12826&lt;/a&gt; for more details&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;webpage_skip&lt;/code&gt;: Skip extraction of embedded webpage data. One or both of &lt;code&gt;player_response&lt;/code&gt;, &lt;code&gt;initial_data&lt;/code&gt;. These options are for testing purposes and don't skip any network requests&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;player_params&lt;/code&gt;: YouTube player parameters to use for player requests. Will overwrite any default ones set by yt-dlp.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;player_js_variant&lt;/code&gt;: The player javascript variant to use for n/sig deciphering. The known variants are: &lt;code&gt;main&lt;/code&gt;, &lt;code&gt;tcc&lt;/code&gt;, &lt;code&gt;tce&lt;/code&gt;, &lt;code&gt;es5&lt;/code&gt;, &lt;code&gt;es6&lt;/code&gt;, &lt;code&gt;tv&lt;/code&gt;, &lt;code&gt;tv_es6&lt;/code&gt;, &lt;code&gt;phone&lt;/code&gt;, &lt;code&gt;tablet&lt;/code&gt;. The default is &lt;code&gt;main&lt;/code&gt;, and the others are for debugging purposes. You can use &lt;code&gt;actual&lt;/code&gt; to go with what is prescribed by the site&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;player_js_version&lt;/code&gt;: The player javascript version to use for n/sig deciphering, in the format of &lt;code&gt;signature_timestamp@hash&lt;/code&gt; (e.g. &lt;code&gt;20348@0004de42&lt;/code&gt;). The default is to use what is prescribed by the site, and can be selected with &lt;code&gt;actual&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;comment_sort&lt;/code&gt;: &lt;code&gt;top&lt;/code&gt; or &lt;code&gt;new&lt;/code&gt; (default) - choose comment sorting mode (on YouTube's side)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;max_comments&lt;/code&gt;: Limit the amount of comments to gather. Comma-separated list of integers representing &lt;code&gt;max-comments,max-parents,max-replies,max-replies-per-thread&lt;/code&gt;. Default is &lt;code&gt;all,all,all,all&lt;/code&gt; 
  &lt;ul&gt; 
   &lt;li&gt;E.g. &lt;code&gt;all,all,1000,10&lt;/code&gt; will get a maximum of 1000 replies total, with up to 10 replies per thread. &lt;code&gt;1000,all,100&lt;/code&gt; will get a maximum of 1000 comments, with a maximum of 100 replies total&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;formats&lt;/code&gt;: Change the types of formats to return. &lt;code&gt;dashy&lt;/code&gt; (convert HTTP to DASH), &lt;code&gt;duplicate&lt;/code&gt; (identical content but different URLs or protocol; includes &lt;code&gt;dashy&lt;/code&gt;), &lt;code&gt;incomplete&lt;/code&gt; (cannot be downloaded completely - live dash and post-live m3u8), &lt;code&gt;missing_pot&lt;/code&gt; (include formats that require a PO Token but are missing one)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;innertube_host&lt;/code&gt;: Innertube API host to use for all API requests; e.g. &lt;code&gt;studio.youtube.com&lt;/code&gt;, &lt;code&gt;youtubei.googleapis.com&lt;/code&gt;. Note that cookies exported from one subdomain will not work on others&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;innertube_key&lt;/code&gt;: Innertube API key to use for all API requests. By default, no API key is used&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;raise_incomplete_data&lt;/code&gt;: &lt;code&gt;Incomplete Data Received&lt;/code&gt; raises an error instead of reporting a warning&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;data_sync_id&lt;/code&gt;: Overrides the account Data Sync ID used in Innertube API requests. This may be needed if you are using an account with &lt;code&gt;youtube:player_skip=webpage,configs&lt;/code&gt; or &lt;code&gt;youtubetab:skip=webpage&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;visitor_data&lt;/code&gt;: Overrides the Visitor Data used in Innertube API requests. This should be used with &lt;code&gt;player_skip=webpage,configs&lt;/code&gt; and without cookies. Note: this may have adverse effects if used improperly. If a session from a browser is wanted, you should pass cookies instead (which contain the Visitor ID)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;po_token&lt;/code&gt;: Proof of Origin (PO) Token(s) to use. Comma seperated list of PO Tokens in the format &lt;code&gt;CLIENT.CONTEXT+PO_TOKEN&lt;/code&gt;, e.g. &lt;code&gt;youtube:po_token=web.gvs+XXX,web.player=XXX,web_safari.gvs+YYY&lt;/code&gt;. Context can be any of &lt;code&gt;gvs&lt;/code&gt; (Google Video Server URLs), &lt;code&gt;player&lt;/code&gt; (Innertube player request) or &lt;code&gt;subs&lt;/code&gt; (Subtitles)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;pot_trace&lt;/code&gt;: Enable debug logging for PO Token fetching. Either &lt;code&gt;true&lt;/code&gt; or &lt;code&gt;false&lt;/code&gt; (default)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;fetch_pot&lt;/code&gt;: Policy to use for fetching a PO Token from providers. One of &lt;code&gt;always&lt;/code&gt; (always try fetch a PO Token regardless if the client requires one for the given context), &lt;code&gt;never&lt;/code&gt; (never fetch a PO Token), or &lt;code&gt;auto&lt;/code&gt; (default; only fetch a PO Token if the client requires one for the given context)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;playback_wait&lt;/code&gt;: Duration (in seconds) to wait inbetween the extraction and download stages in order to ensure the formats are available. The default is &lt;code&gt;6&lt;/code&gt; seconds&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;jsc_trace&lt;/code&gt;: Enable debug logging for JS Challenge fetching. Either &lt;code&gt;true&lt;/code&gt; or &lt;code&gt;false&lt;/code&gt; (default)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;youtube-ejs&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;jitless&lt;/code&gt;: Run suported Javascript engines in JIT-less mode. Supported runtimes are &lt;code&gt;deno&lt;/code&gt;, &lt;code&gt;node&lt;/code&gt; and &lt;code&gt;bun&lt;/code&gt;. Provides better security at the cost of performance/speed. Do note that &lt;code&gt;node&lt;/code&gt; and &lt;code&gt;bun&lt;/code&gt; are still considered unsecure. Either &lt;code&gt;true&lt;/code&gt; or &lt;code&gt;false&lt;/code&gt; (default)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;youtubepot-webpo&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;bind_to_visitor_id&lt;/code&gt;: Whether to use the Visitor ID instead of Visitor Data for caching WebPO tokens. Either &lt;code&gt;true&lt;/code&gt; (default) or &lt;code&gt;false&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;youtubetab (YouTube playlists, channels, feeds, etc.)&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;skip&lt;/code&gt;: One or more of &lt;code&gt;webpage&lt;/code&gt; (skip initial webpage download), &lt;code&gt;authcheck&lt;/code&gt; (allow the download of playlists requiring authentication when no initial webpage is downloaded. This may cause unwanted behavior, see &lt;a href="https://github.com/yt-dlp/yt-dlp/pull/1122"&gt;#1122&lt;/a&gt; for more details)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;approximate_date&lt;/code&gt;: Extract approximate &lt;code&gt;upload_date&lt;/code&gt; and &lt;code&gt;timestamp&lt;/code&gt; in flat-playlist. This may cause date-based filters to be slightly off&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;generic&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;fragment_query&lt;/code&gt;: Passthrough any query in mpd/m3u8 manifest URLs to their fragments if no value is provided, or else apply the query string given as &lt;code&gt;fragment_query=VALUE&lt;/code&gt;. Note that if the stream has an HLS AES-128 key, then the query parameters will be passed to the key URI as well, unless the &lt;code&gt;key_query&lt;/code&gt; extractor-arg is passed, or unless an external key URI is provided via the &lt;code&gt;hls_key&lt;/code&gt; extractor-arg. Does not apply to ffmpeg&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;variant_query&lt;/code&gt;: Passthrough the master m3u8 URL query to its variant playlist URLs if no value is provided, or else apply the query string given as &lt;code&gt;variant_query=VALUE&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;key_query&lt;/code&gt;: Passthrough the master m3u8 URL query to its HLS AES-128 decryption key URI if no value is provided, or else apply the query string given as &lt;code&gt;key_query=VALUE&lt;/code&gt;. Note that this will have no effect if the key URI is provided via the &lt;code&gt;hls_key&lt;/code&gt; extractor-arg. Does not apply to ffmpeg&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;hls_key&lt;/code&gt;: An HLS AES-128 key URI &lt;em&gt;or&lt;/em&gt; key (as hex), and optionally the IV (as hex), in the form of &lt;code&gt;(URI|KEY)[,IV]&lt;/code&gt;; e.g. &lt;code&gt;generic:hls_key=ABCDEF1234567980,0xFEDCBA0987654321&lt;/code&gt;. Passing any of these values will force usage of the native HLS downloader and override the corresponding values found in the m3u8 playlist&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;is_live&lt;/code&gt;: Bypass live HLS detection and manually set &lt;code&gt;live_status&lt;/code&gt; - a value of &lt;code&gt;false&lt;/code&gt; will set &lt;code&gt;not_live&lt;/code&gt;, any other value (or no value) will set &lt;code&gt;is_live&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;impersonate&lt;/code&gt;: Target(s) to try and impersonate with the initial webpage request; e.g. &lt;code&gt;generic:impersonate=safari,chrome-110&lt;/code&gt;. Use &lt;code&gt;generic:impersonate&lt;/code&gt; to impersonate any available target, and use &lt;code&gt;generic:impersonate=false&lt;/code&gt; to disable impersonation (default)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;vikichannel&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;video_types&lt;/code&gt;: Types of videos to download - one or more of &lt;code&gt;episodes&lt;/code&gt;, &lt;code&gt;movies&lt;/code&gt;, &lt;code&gt;clips&lt;/code&gt;, &lt;code&gt;trailers&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;youtubewebarchive&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;check_all&lt;/code&gt;: Try to check more at the cost of more requests. One or more of &lt;code&gt;thumbnails&lt;/code&gt;, &lt;code&gt;captures&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;gamejolt&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;comment_sort&lt;/code&gt;: &lt;code&gt;hot&lt;/code&gt; (default), &lt;code&gt;you&lt;/code&gt; (cookies needed), &lt;code&gt;top&lt;/code&gt;, &lt;code&gt;new&lt;/code&gt; - choose comment sorting mode (on GameJolt's side)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;hotstar&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;res&lt;/code&gt;: resolution to ignore - one or more of &lt;code&gt;sd&lt;/code&gt;, &lt;code&gt;hd&lt;/code&gt;, &lt;code&gt;fhd&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;vcodec&lt;/code&gt;: vcodec to ignore - one or more of &lt;code&gt;h264&lt;/code&gt;, &lt;code&gt;h265&lt;/code&gt;, &lt;code&gt;dvh265&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;dr&lt;/code&gt;: dynamic range to ignore - one or more of &lt;code&gt;sdr&lt;/code&gt;, &lt;code&gt;hdr10&lt;/code&gt;, &lt;code&gt;dv&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;instagram&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;app_id&lt;/code&gt;: The value of the &lt;code&gt;X-IG-App-ID&lt;/code&gt; header used for API requests. Default is the web app ID, &lt;code&gt;936619743392459&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;niconicochannelplus&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;max_comments&lt;/code&gt;: Maximum number of comments to extract - default is &lt;code&gt;120&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;tiktok&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;api_hostname&lt;/code&gt;: Hostname to use for mobile API calls, e.g. &lt;code&gt;api22-normal-c-alisg.tiktokv.com&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;app_name&lt;/code&gt;: Default app name to use with mobile API calls, e.g. &lt;code&gt;trill&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;app_version&lt;/code&gt;: Default app version to use with mobile API calls - should be set along with &lt;code&gt;manifest_app_version&lt;/code&gt;, e.g. &lt;code&gt;34.1.2&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;manifest_app_version&lt;/code&gt;: Default numeric app version to use with mobile API calls, e.g. &lt;code&gt;2023401020&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;aid&lt;/code&gt;: Default app ID to use with mobile API calls, e.g. &lt;code&gt;1180&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;app_info&lt;/code&gt;: Enable mobile API extraction with one or more app info strings in the format of &lt;code&gt;&amp;lt;iid&amp;gt;/[app_name]/[app_version]/[manifest_app_version]/[aid]&lt;/code&gt;, where &lt;code&gt;iid&lt;/code&gt; is the unique app install ID. &lt;code&gt;iid&lt;/code&gt; is the only required value; all other values and their &lt;code&gt;/&lt;/code&gt; separators can be omitted, e.g. &lt;code&gt;tiktok:app_info=1234567890123456789&lt;/code&gt; or &lt;code&gt;tiktok:app_info=123,456/trill///1180,789//34.0.1/340001&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;device_id&lt;/code&gt;: Enable mobile API extraction with a genuine device ID to be used with mobile API calls. Default is a random 19-digit string&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;rokfinchannel&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;tab&lt;/code&gt;: Which tab to download - one of &lt;code&gt;new&lt;/code&gt;, &lt;code&gt;top&lt;/code&gt;, &lt;code&gt;videos&lt;/code&gt;, &lt;code&gt;podcasts&lt;/code&gt;, &lt;code&gt;streams&lt;/code&gt;, &lt;code&gt;stacks&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;twitter&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;api&lt;/code&gt;: Select one of &lt;code&gt;graphql&lt;/code&gt; (default), &lt;code&gt;legacy&lt;/code&gt; or &lt;code&gt;syndication&lt;/code&gt; as the API for tweet extraction. Has no effect if logged in&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;stacommu, wrestleuniverse&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;device_id&lt;/code&gt;: UUID value assigned by the website and used to enforce device limits for paid livestream content. Can be found in browser local storage&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;twitch&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;client_id&lt;/code&gt;: Client ID value to be sent with GraphQL requests, e.g. &lt;code&gt;twitch:client_id=kimne78kx3ncx6brgo4mv6wki5h1ko&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;nhkradirulive (NHK „Çâ„Åò„Çã‚òÖ„Çâ„Åò„Çã LIVE)&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;area&lt;/code&gt;: Which regional variation to extract. Valid areas are: &lt;code&gt;sapporo&lt;/code&gt;, &lt;code&gt;sendai&lt;/code&gt;, &lt;code&gt;tokyo&lt;/code&gt;, &lt;code&gt;nagoya&lt;/code&gt;, &lt;code&gt;osaka&lt;/code&gt;, &lt;code&gt;hiroshima&lt;/code&gt;, &lt;code&gt;matsuyama&lt;/code&gt;, &lt;code&gt;fukuoka&lt;/code&gt;. Defaults to &lt;code&gt;tokyo&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;nflplusreplay&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;type&lt;/code&gt;: Type(s) of game replays to extract. Valid types are: &lt;code&gt;full_game&lt;/code&gt;, &lt;code&gt;full_game_spanish&lt;/code&gt;, &lt;code&gt;condensed_game&lt;/code&gt; and &lt;code&gt;all_22&lt;/code&gt;. You can use &lt;code&gt;all&lt;/code&gt; to extract all available replay types, which is the default&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;jiocinema&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;refresh_token&lt;/code&gt;: The &lt;code&gt;refreshToken&lt;/code&gt; UUID from browser local storage can be passed to extend the life of your login session when logging in with &lt;code&gt;token&lt;/code&gt; as username and the &lt;code&gt;accessToken&lt;/code&gt; from browser local storage as password&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;jiosaavn&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;bitrate&lt;/code&gt;: Audio bitrates to request. One or more of &lt;code&gt;16&lt;/code&gt;, &lt;code&gt;32&lt;/code&gt;, &lt;code&gt;64&lt;/code&gt;, &lt;code&gt;128&lt;/code&gt;, &lt;code&gt;320&lt;/code&gt;. Default is &lt;code&gt;128,320&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;afreecatvlive&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;cdn&lt;/code&gt;: One or more CDN IDs to use with the API call for stream URLs, e.g. &lt;code&gt;gcp_cdn&lt;/code&gt;, &lt;code&gt;gs_cdn_pc_app&lt;/code&gt;, &lt;code&gt;gs_cdn_mobile_web&lt;/code&gt;, &lt;code&gt;gs_cdn_pc_web&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;soundcloud&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;formats&lt;/code&gt;: Formats to request from the API. Requested values should be in the format of &lt;code&gt;{protocol}_{codec}&lt;/code&gt;, e.g. &lt;code&gt;hls_opus,http_aac&lt;/code&gt;. The &lt;code&gt;*&lt;/code&gt; character functions as a wildcard, e.g. &lt;code&gt;*_mp3&lt;/code&gt;, and can be passed by itself to request all formats. Known protocols include &lt;code&gt;http&lt;/code&gt;, &lt;code&gt;hls&lt;/code&gt; and &lt;code&gt;hls-aes&lt;/code&gt;; known codecs include &lt;code&gt;aac&lt;/code&gt;, &lt;code&gt;opus&lt;/code&gt; and &lt;code&gt;mp3&lt;/code&gt;. Original &lt;code&gt;download&lt;/code&gt; formats are always extracted. Default is &lt;code&gt;http_aac,hls_aac,http_opus,hls_opus,http_mp3,hls_mp3&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;orfon (orf:on)&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;prefer_segments_playlist&lt;/code&gt;: Prefer a playlist of program segments instead of a single complete video when available. If individual segments are desired, use &lt;code&gt;--concat-playlist never --extractor-args "orfon:prefer_segments_playlist"&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;bilibili&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;prefer_multi_flv&lt;/code&gt;: Prefer extracting flv formats over mp4 for older videos that still provide legacy formats&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;sonylivseries&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;sort_order&lt;/code&gt;: Episode sort order for series extraction - one of &lt;code&gt;asc&lt;/code&gt; (ascending, oldest first) or &lt;code&gt;desc&lt;/code&gt; (descending, newest first). Default is &lt;code&gt;asc&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;tver&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;backend&lt;/code&gt;: Backend API to use for extraction - one of &lt;code&gt;streaks&lt;/code&gt; (default) or &lt;code&gt;brightcove&lt;/code&gt; (deprecated)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;vimeo&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;client&lt;/code&gt;: Client to extract video data from. The currently available clients are &lt;code&gt;android&lt;/code&gt;, &lt;code&gt;ios&lt;/code&gt;, and &lt;code&gt;web&lt;/code&gt;. Only one client can be used. The &lt;code&gt;web&lt;/code&gt; client is used by default. The &lt;code&gt;web&lt;/code&gt; client only works with account cookies or login credentials. The &lt;code&gt;android&lt;/code&gt; and &lt;code&gt;ios&lt;/code&gt; clients only work with previously cached OAuth tokens&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;original_format_policy&lt;/code&gt;: Policy for when to try extracting original formats. One of &lt;code&gt;always&lt;/code&gt;, &lt;code&gt;never&lt;/code&gt;, or &lt;code&gt;auto&lt;/code&gt;. The default &lt;code&gt;auto&lt;/code&gt; policy tries to avoid exceeding the web client's API rate-limit by only making an extra request when Vimeo publicizes the video's downloadability&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: These options may be changed/removed in the future without concern for backward compatibility&lt;/p&gt; 
&lt;!-- MANPAGE: MOVE "INSTALLATION" SECTION HERE --&gt; 
&lt;h1&gt;PLUGINS&lt;/h1&gt; 
&lt;p&gt;Note that &lt;strong&gt;all&lt;/strong&gt; plugins are imported even if not invoked, and that &lt;strong&gt;there are no checks&lt;/strong&gt; performed on plugin code. &lt;strong&gt;Use plugins at your own risk and only if you trust the code!&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Plugins can be of &lt;code&gt;&amp;lt;type&amp;gt;&lt;/code&gt;s &lt;code&gt;extractor&lt;/code&gt; or &lt;code&gt;postprocessor&lt;/code&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Extractor plugins do not need to be enabled from the CLI and are automatically invoked when the input URL is suitable for it.&lt;/li&gt; 
 &lt;li&gt;Extractor plugins take priority over built-in extractors.&lt;/li&gt; 
 &lt;li&gt;Postprocessor plugins can be invoked using &lt;code&gt;--use-postprocessor NAME&lt;/code&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Plugins are loaded from the namespace packages &lt;code&gt;yt_dlp_plugins.extractor&lt;/code&gt; and &lt;code&gt;yt_dlp_plugins.postprocessor&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;In other words, the file structure on the disk looks something like:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;    yt_dlp_plugins/
        extractor/
            myplugin.py
        postprocessor/
            myplugin.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;yt-dlp looks for these &lt;code&gt;yt_dlp_plugins&lt;/code&gt; namespace folders in many locations (see below) and loads in plugins from &lt;strong&gt;all&lt;/strong&gt; of them. Set the environment variable &lt;code&gt;YTDLP_NO_PLUGINS&lt;/code&gt; to something nonempty to disable loading plugins entirely.&lt;/p&gt; 
&lt;p&gt;See the &lt;a href="https://github.com/yt-dlp/yt-dlp/wiki/Plugins"&gt;wiki for some known plugins&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Installing Plugins&lt;/h2&gt; 
&lt;p&gt;Plugins can be installed using various methods and locations.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Configuration directories&lt;/strong&gt;: Plugin packages (containing a &lt;code&gt;yt_dlp_plugins&lt;/code&gt; namespace folder) can be dropped into the following standard &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#configuration"&gt;configuration locations&lt;/a&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;User Plugins&lt;/strong&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;code&gt;${XDG_CONFIG_HOME}/yt-dlp/plugins/&amp;lt;package name&amp;gt;/yt_dlp_plugins/&lt;/code&gt; (recommended on Linux/macOS)&lt;/li&gt; 
     &lt;li&gt;&lt;code&gt;${XDG_CONFIG_HOME}/yt-dlp-plugins/&amp;lt;package name&amp;gt;/yt_dlp_plugins/&lt;/code&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;code&gt;${APPDATA}/yt-dlp/plugins/&amp;lt;package name&amp;gt;/yt_dlp_plugins/&lt;/code&gt; (recommended on Windows)&lt;/li&gt; 
     &lt;li&gt;&lt;code&gt;${APPDATA}/yt-dlp-plugins/&amp;lt;package name&amp;gt;/yt_dlp_plugins/&lt;/code&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;code&gt;~/.yt-dlp/plugins/&amp;lt;package name&amp;gt;/yt_dlp_plugins/&lt;/code&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;code&gt;~/yt-dlp-plugins/&amp;lt;package name&amp;gt;/yt_dlp_plugins/&lt;/code&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;System Plugins&lt;/strong&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;code&gt;/etc/yt-dlp/plugins/&amp;lt;package name&amp;gt;/yt_dlp_plugins/&lt;/code&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;code&gt;/etc/yt-dlp-plugins/&amp;lt;package name&amp;gt;/yt_dlp_plugins/&lt;/code&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Executable location&lt;/strong&gt;: Plugin packages can similarly be installed in a &lt;code&gt;yt-dlp-plugins&lt;/code&gt; directory under the executable location (recommended for portable installations):&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Binary: where &lt;code&gt;&amp;lt;root-dir&amp;gt;/yt-dlp.exe&lt;/code&gt;, &lt;code&gt;&amp;lt;root-dir&amp;gt;/yt-dlp-plugins/&amp;lt;package name&amp;gt;/yt_dlp_plugins/&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;Source: where &lt;code&gt;&amp;lt;root-dir&amp;gt;/yt_dlp/__main__.py&lt;/code&gt;, &lt;code&gt;&amp;lt;root-dir&amp;gt;/yt-dlp-plugins/&amp;lt;package name&amp;gt;/yt_dlp_plugins/&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;pip and other locations in &lt;code&gt;PYTHONPATH&lt;/code&gt;&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Plugin packages can be installed and managed using &lt;code&gt;pip&lt;/code&gt;. See &lt;a href="https://github.com/yt-dlp/yt-dlp-sample-plugins"&gt;yt-dlp-sample-plugins&lt;/a&gt; for an example. 
    &lt;ul&gt; 
     &lt;li&gt;Note: plugin files between plugin packages installed with pip must have unique filenames.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;Any path in &lt;code&gt;PYTHONPATH&lt;/code&gt; is searched in for the &lt;code&gt;yt_dlp_plugins&lt;/code&gt; namespace folder. 
    &lt;ul&gt; 
     &lt;li&gt;Note: This does not apply for Pyinstaller builds.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;code&gt;.zip&lt;/code&gt;, &lt;code&gt;.egg&lt;/code&gt; and &lt;code&gt;.whl&lt;/code&gt; archives containing a &lt;code&gt;yt_dlp_plugins&lt;/code&gt; namespace folder in their root are also supported as plugin packages.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;e.g. &lt;code&gt;${XDG_CONFIG_HOME}/yt-dlp/plugins/mypluginpkg.zip&lt;/code&gt; where &lt;code&gt;mypluginpkg.zip&lt;/code&gt; contains &lt;code&gt;yt_dlp_plugins/&amp;lt;type&amp;gt;/myplugin.py&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Run yt-dlp with &lt;code&gt;--verbose&lt;/code&gt; to check if the plugin has been loaded.&lt;/p&gt; 
&lt;h2&gt;Developing Plugins&lt;/h2&gt; 
&lt;p&gt;See the &lt;a href="https://github.com/yt-dlp/yt-dlp-sample-plugins"&gt;yt-dlp-sample-plugins&lt;/a&gt; repo for a template plugin package and the &lt;a href="https://github.com/yt-dlp/yt-dlp/wiki/Plugin-Development"&gt;Plugin Development&lt;/a&gt; section of the wiki for a plugin development guide.&lt;/p&gt; 
&lt;p&gt;All public classes with a name ending in &lt;code&gt;IE&lt;/code&gt;/&lt;code&gt;PP&lt;/code&gt; are imported from each file for extractors and postprocessors respectively. This respects underscore prefix (e.g. &lt;code&gt;_MyBasePluginIE&lt;/code&gt; is private) and &lt;code&gt;__all__&lt;/code&gt;. Modules can similarly be excluded by prefixing the module name with an underscore (e.g. &lt;code&gt;_myplugin.py&lt;/code&gt;).&lt;/p&gt; 
&lt;p&gt;To replace an existing extractor with a subclass of one, set the &lt;code&gt;plugin_name&lt;/code&gt; class keyword argument (e.g. &lt;code&gt;class MyPluginIE(ABuiltInIE, plugin_name='myplugin')&lt;/code&gt; will replace &lt;code&gt;ABuiltInIE&lt;/code&gt; with &lt;code&gt;MyPluginIE&lt;/code&gt;). Since the extractor replaces the parent, you should exclude the subclass extractor from being imported separately by making it private using one of the methods described above.&lt;/p&gt; 
&lt;p&gt;If you are a plugin author, add &lt;a href="https://github.com/topics/yt-dlp-plugins"&gt;yt-dlp-plugins&lt;/a&gt; as a topic to your repository for discoverability.&lt;/p&gt; 
&lt;p&gt;See the &lt;a href="https://github.com/yt-dlp/yt-dlp/raw/master/CONTRIBUTING.md#developer-instructions"&gt;Developer Instructions&lt;/a&gt; on how to write and test an extractor.&lt;/p&gt; 
&lt;h1&gt;EMBEDDING YT-DLP&lt;/h1&gt; 
&lt;p&gt;yt-dlp makes the best effort to be a good command-line program, and thus should be callable from any programming language.&lt;/p&gt; 
&lt;p&gt;Your program should avoid parsing the normal stdout since they may change in future versions. Instead, they should use options such as &lt;code&gt;-J&lt;/code&gt;, &lt;code&gt;--print&lt;/code&gt;, &lt;code&gt;--progress-template&lt;/code&gt;, &lt;code&gt;--exec&lt;/code&gt; etc to create console output that you can reliably reproduce and parse.&lt;/p&gt; 
&lt;p&gt;From a Python program, you can embed yt-dlp in a more powerful fashion, like this:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from yt_dlp import YoutubeDL

URLS = ['https://www.youtube.com/watch?v=BaW_jenozKc']
with YoutubeDL() as ydl:
    ydl.download(URLS)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Most likely, you'll want to use various options. For a list of options available, have a look at &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/yt_dlp/YoutubeDL.py#L183"&gt;&lt;code&gt;yt_dlp/YoutubeDL.py&lt;/code&gt;&lt;/a&gt; or &lt;code&gt;help(yt_dlp.YoutubeDL)&lt;/code&gt; in a Python shell. If you are already familiar with the CLI, you can use &lt;a href="https://github.com/yt-dlp/yt-dlp/raw/master/devscripts/cli_to_api.py"&gt;&lt;code&gt;devscripts/cli_to_api.py&lt;/code&gt;&lt;/a&gt; to translate any CLI switches to &lt;code&gt;YoutubeDL&lt;/code&gt; params.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Tip&lt;/strong&gt;: If you are porting your code from youtube-dl to yt-dlp, one important point to look out for is that we do not guarantee the return value of &lt;code&gt;YoutubeDL.extract_info&lt;/code&gt; to be json serializable, or even be a dictionary. It will be dictionary-like, but if you want to ensure it is a serializable dictionary, pass it through &lt;code&gt;YoutubeDL.sanitize_info&lt;/code&gt; as shown in the &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#extracting-information"&gt;example below&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Embedding examples&lt;/h2&gt; 
&lt;h4&gt;Extracting information&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import json
import yt_dlp

URL = 'https://www.youtube.com/watch?v=BaW_jenozKc'

# ‚ÑπÔ∏è See help(yt_dlp.YoutubeDL) for a list of available options and public functions
ydl_opts = {}
with yt_dlp.YoutubeDL(ydl_opts) as ydl:
    info = ydl.extract_info(URL, download=False)

    # ‚ÑπÔ∏è ydl.sanitize_info makes the info json-serializable
    print(json.dumps(ydl.sanitize_info(info)))
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Download using an info-json&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import yt_dlp

INFO_FILE = 'path/to/video.info.json'

with yt_dlp.YoutubeDL() as ydl:
    error_code = ydl.download_with_info_file(INFO_FILE)

print('Some videos failed to download' if error_code
      else 'All videos successfully downloaded')
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Extract audio&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import yt_dlp

URLS = ['https://www.youtube.com/watch?v=BaW_jenozKc']

ydl_opts = {
    'format': 'm4a/bestaudio/best',
    # ‚ÑπÔ∏è See help(yt_dlp.postprocessor) for a list of available Postprocessors and their arguments
    'postprocessors': [{  # Extract audio using ffmpeg
        'key': 'FFmpegExtractAudio',
        'preferredcodec': 'm4a',
    }]
}

with yt_dlp.YoutubeDL(ydl_opts) as ydl:
    error_code = ydl.download(URLS)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Filter videos&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import yt_dlp

URLS = ['https://www.youtube.com/watch?v=BaW_jenozKc']

def longer_than_a_minute(info, *, incomplete):
    """Download only videos longer than a minute (or with unknown duration)"""
    duration = info.get('duration')
    if duration and duration &amp;lt; 60:
        return 'The video is too short'

ydl_opts = {
    'match_filter': longer_than_a_minute,
}

with yt_dlp.YoutubeDL(ydl_opts) as ydl:
    error_code = ydl.download(URLS)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Adding logger and progress hook&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import yt_dlp

URLS = ['https://www.youtube.com/watch?v=BaW_jenozKc']

class MyLogger:
    def debug(self, msg):
        # For compatibility with youtube-dl, both debug and info are passed into debug
        # You can distinguish them by the prefix '[debug] '
        if msg.startswith('[debug] '):
            pass
        else:
            self.info(msg)

    def info(self, msg):
        pass

    def warning(self, msg):
        pass

    def error(self, msg):
        print(msg)


# ‚ÑπÔ∏è See "progress_hooks" in help(yt_dlp.YoutubeDL)
def my_hook(d):
    if d['status'] == 'finished':
        print('Done downloading, now post-processing ...')


ydl_opts = {
    'logger': MyLogger(),
    'progress_hooks': [my_hook],
}

with yt_dlp.YoutubeDL(ydl_opts) as ydl:
    ydl.download(URLS)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Add a custom PostProcessor&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import yt_dlp

URLS = ['https://www.youtube.com/watch?v=BaW_jenozKc']

# ‚ÑπÔ∏è See help(yt_dlp.postprocessor.PostProcessor)
class MyCustomPP(yt_dlp.postprocessor.PostProcessor):
    def run(self, info):
        self.to_screen('Doing stuff')
        return [], info


with yt_dlp.YoutubeDL() as ydl:
    # ‚ÑπÔ∏è "when" can take any value in yt_dlp.utils.POSTPROCESS_WHEN
    ydl.add_post_processor(MyCustomPP(), when='pre_process')
    ydl.download(URLS)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Use a custom format selector&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import yt_dlp

URLS = ['https://www.youtube.com/watch?v=BaW_jenozKc']

def format_selector(ctx):
    """ Select the best video and the best audio that won't result in an mkv.
    NOTE: This is just an example and does not handle all cases """

    # formats are already sorted worst to best
    formats = ctx.get('formats')[::-1]

    # acodec='none' means there is no audio
    best_video = next(f for f in formats
                      if f['vcodec'] != 'none' and f['acodec'] == 'none')

    # find compatible audio extension
    audio_ext = {'mp4': 'm4a', 'webm': 'webm'}[best_video['ext']]
    # vcodec='none' means there is no video
    best_audio = next(f for f in formats if (
        f['acodec'] != 'none' and f['vcodec'] == 'none' and f['ext'] == audio_ext))

    # These are the minimum required fields for a merged format
    yield {
        'format_id': f'{best_video["format_id"]}+{best_audio["format_id"]}',
        'ext': best_video['ext'],
        'requested_formats': [best_video, best_audio],
        # Must be + separated list of protocols
        'protocol': f'{best_video["protocol"]}+{best_audio["protocol"]}'
    }


ydl_opts = {
    'format': format_selector,
}

with yt_dlp.YoutubeDL(ydl_opts) as ydl:
    ydl.download(URLS)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;CHANGES FROM YOUTUBE-DL&lt;/h1&gt; 
&lt;h3&gt;New features&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Forked from &lt;a href="https://github.com/blackjack4494/yt-dlc/commit/f9401f2a91987068139c5f757b12fc711d4c0cee"&gt;&lt;strong&gt;yt-dlc@f9401f2&lt;/strong&gt;&lt;/a&gt; and merged with &lt;a href="https://github.com/ytdl-org/youtube-dl/commit/a08f2b7e4567cdc50c0614ee0a4ffdff49b8b6e6"&gt;&lt;strong&gt;youtube-dl@a08f2b7&lt;/strong&gt;&lt;/a&gt; (&lt;a href="https://github.com/yt-dlp/yt-dlp/issues/21"&gt;exceptions&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#sponsorblock-options"&gt;SponsorBlock Integration&lt;/a&gt;&lt;/strong&gt;: You can mark/remove sponsor sections in YouTube videos by utilizing the &lt;a href="https://sponsor.ajay.app"&gt;SponsorBlock&lt;/a&gt; API&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#sorting-formats"&gt;Format Sorting&lt;/a&gt;&lt;/strong&gt;: The default format sorting options have been changed so that higher resolution and better codecs will be now preferred instead of simply using larger bitrate. Furthermore, you can now specify the sort order using &lt;code&gt;-S&lt;/code&gt;. This allows for much easier format selection than what is possible by simply using &lt;code&gt;--format&lt;/code&gt; (&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#format-selection-examples"&gt;examples&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Merged with animelover1984/youtube-dl&lt;/strong&gt;: You get most of the features and improvements from &lt;a href="https://github.com/animelover1984/youtube-dl"&gt;animelover1984/youtube-dl&lt;/a&gt; including &lt;code&gt;--write-comments&lt;/code&gt;, &lt;code&gt;BiliBiliSearch&lt;/code&gt;, &lt;code&gt;BilibiliChannel&lt;/code&gt;, Embedding thumbnail in mp4/ogg/opus, playlist infojson etc. See &lt;a href="https://github.com/yt-dlp/yt-dlp/pull/31"&gt;#31&lt;/a&gt; for details.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;YouTube improvements&lt;/strong&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Supports Clips, Stories (&lt;code&gt;ytstories:&amp;lt;channel UCID&amp;gt;&lt;/code&gt;), Search (including filters)&lt;strong&gt;*&lt;/strong&gt;, YouTube Music Search, Channel-specific search, Search prefixes (&lt;code&gt;ytsearch:&lt;/code&gt;, &lt;code&gt;ytsearchdate:&lt;/code&gt;)&lt;strong&gt;*&lt;/strong&gt;, Mixes, and Feeds (&lt;code&gt;:ytfav&lt;/code&gt;, &lt;code&gt;:ytwatchlater&lt;/code&gt;, &lt;code&gt;:ytsubs&lt;/code&gt;, &lt;code&gt;:ythistory&lt;/code&gt;, &lt;code&gt;:ytrec&lt;/code&gt;, &lt;code&gt;:ytnotif&lt;/code&gt;)&lt;/li&gt; 
   &lt;li&gt;Fix for &lt;a href="https://github.com/ytdl-org/youtube-dl/issues/29326"&gt;n-sig based throttling&lt;/a&gt; &lt;strong&gt;*&lt;/strong&gt;&lt;/li&gt; 
   &lt;li&gt;Download livestreams from the start using &lt;code&gt;--live-from-start&lt;/code&gt; (&lt;em&gt;experimental&lt;/em&gt;)&lt;/li&gt; 
   &lt;li&gt;Channel URLs download all uploads of the channel, including shorts and live&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Cookies from browser&lt;/strong&gt;: Cookies can be automatically extracted from all major web browsers using &lt;code&gt;--cookies-from-browser BROWSER[+KEYRING][:PROFILE][::CONTAINER]&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Download time range&lt;/strong&gt;: Videos can be downloaded partially based on either timestamps or chapters using &lt;code&gt;--download-sections&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Split video by chapters&lt;/strong&gt;: Videos can be split into multiple files based on chapters using &lt;code&gt;--split-chapters&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Multi-threaded fragment downloads&lt;/strong&gt;: Download multiple fragments of m3u8/mpd videos in parallel. Use &lt;code&gt;--concurrent-fragments&lt;/code&gt; (&lt;code&gt;-N&lt;/code&gt;) option to set the number of threads used&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Aria2c with HLS/DASH&lt;/strong&gt;: You can use &lt;code&gt;aria2c&lt;/code&gt; as the external downloader for DASH(mpd) and HLS(m3u8) formats&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;New and fixed extractors&lt;/strong&gt;: Many new extractors have been added and a lot of existing ones have been fixed. See the &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/Changelog.md"&gt;changelog&lt;/a&gt; or the &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/supportedsites.md"&gt;list of supported sites&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;New MSOs&lt;/strong&gt;: Philo, Spectrum, SlingTV, Cablevision, RCN etc.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Subtitle extraction from manifests&lt;/strong&gt;: Subtitles can be extracted from streaming media manifests. See &lt;a href="https://github.com/yt-dlp/yt-dlp/commit/be6202f12b97858b9d716e608394b51065d0419f"&gt;commit/be6202f&lt;/a&gt; for details&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Multiple paths and output templates&lt;/strong&gt;: You can give different &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#output-template"&gt;output templates&lt;/a&gt; and download paths for different types of files. You can also set a temporary path where intermediary files are downloaded to using &lt;code&gt;--paths&lt;/code&gt; (&lt;code&gt;-P&lt;/code&gt;)&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Portable Configuration&lt;/strong&gt;: Configuration files are automatically loaded from the home and root directories. See &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#configuration"&gt;CONFIGURATION&lt;/a&gt; for details&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Output template improvements&lt;/strong&gt;: Output templates can now have date-time formatting, numeric offsets, object traversal etc. See &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#output-template"&gt;output template&lt;/a&gt; for details. Even more advanced operations can also be done with the help of &lt;code&gt;--parse-metadata&lt;/code&gt; and &lt;code&gt;--replace-in-metadata&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Other new options&lt;/strong&gt;: Many new options have been added such as &lt;code&gt;--alias&lt;/code&gt;, &lt;code&gt;--print&lt;/code&gt;, &lt;code&gt;--concat-playlist&lt;/code&gt;, &lt;code&gt;--wait-for-video&lt;/code&gt;, &lt;code&gt;--retry-sleep&lt;/code&gt;, &lt;code&gt;--sleep-requests&lt;/code&gt;, &lt;code&gt;--convert-thumbnails&lt;/code&gt;, &lt;code&gt;--force-download-archive&lt;/code&gt;, &lt;code&gt;--force-overwrites&lt;/code&gt;, &lt;code&gt;--break-match-filters&lt;/code&gt; etc&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Improvements&lt;/strong&gt;: Regex and other operators in &lt;code&gt;--format&lt;/code&gt;/&lt;code&gt;--match-filters&lt;/code&gt;, multiple &lt;code&gt;--postprocessor-args&lt;/code&gt; and &lt;code&gt;--downloader-args&lt;/code&gt;, faster archive checking, more &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#format-selection"&gt;format selection options&lt;/a&gt;, merge multi-video/audio, multiple &lt;code&gt;--config-locations&lt;/code&gt;, &lt;code&gt;--exec&lt;/code&gt; at different stages, etc&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Plugins&lt;/strong&gt;: Extractors and PostProcessors can be loaded from an external file. See &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#plugins"&gt;plugins&lt;/a&gt; for details&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Self updater&lt;/strong&gt;: The releases can be updated using &lt;code&gt;yt-dlp -U&lt;/code&gt;, and downgraded using &lt;code&gt;--update-to&lt;/code&gt; if required&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Automated builds&lt;/strong&gt;: &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#update-channels"&gt;Nightly/master builds&lt;/a&gt; can be used with &lt;code&gt;--update-to nightly&lt;/code&gt; and &lt;code&gt;--update-to master&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/Changelog.md"&gt;changelog&lt;/a&gt; or &lt;a href="https://github.com/yt-dlp/yt-dlp/commits"&gt;commits&lt;/a&gt; for the full list of changes&lt;/p&gt; 
&lt;p&gt;Features marked with a &lt;strong&gt;*&lt;/strong&gt; have been back-ported to youtube-dl&lt;/p&gt; 
&lt;h3&gt;Differences in default behavior&lt;/h3&gt; 
&lt;p&gt;Some of yt-dlp's default options are different from that of youtube-dl and youtube-dlc:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;yt-dlp supports only &lt;a href="##" title="Windows 8"&gt;Python 3.10+&lt;/a&gt;, and will remove support for more versions as they &lt;a href="https://devguide.python.org/versions/#python-release-cycle"&gt;become EOL&lt;/a&gt;; while &lt;a href="https://github.com/ytdl-org/youtube-dl/issues/30568#issue-1118238743"&gt;youtube-dl still supports Python 2.6+ and 3.2+&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;The options &lt;code&gt;--auto-number&lt;/code&gt; (&lt;code&gt;-A&lt;/code&gt;), &lt;code&gt;--title&lt;/code&gt; (&lt;code&gt;-t&lt;/code&gt;) and &lt;code&gt;--literal&lt;/code&gt; (&lt;code&gt;-l&lt;/code&gt;), no longer work. See &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#Removed"&gt;removed options&lt;/a&gt; for details&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;avconv&lt;/code&gt; is not supported as an alternative to &lt;code&gt;ffmpeg&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;yt-dlp stores config files in slightly different locations to youtube-dl. See &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#configuration"&gt;CONFIGURATION&lt;/a&gt; for a list of correct locations&lt;/li&gt; 
 &lt;li&gt;The default &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#output-template"&gt;output template&lt;/a&gt; is &lt;code&gt;%(title)s [%(id)s].%(ext)s&lt;/code&gt;. There is no real reason for this change. This was changed before yt-dlp was ever made public and now there are no plans to change it back to &lt;code&gt;%(title)s-%(id)s.%(ext)s&lt;/code&gt;. Instead, you may use &lt;code&gt;--compat-options filename&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;The default &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#sorting-formats"&gt;format sorting&lt;/a&gt; is different from youtube-dl and prefers higher resolution and better codecs rather than higher bitrates. You can use the &lt;code&gt;--format-sort&lt;/code&gt; option to change this to any order you prefer, or use &lt;code&gt;--compat-options format-sort&lt;/code&gt; to use youtube-dl's sorting order. Older versions of yt-dlp preferred VP9 due to its broader compatibility; you can use &lt;code&gt;--compat-options prefer-vp9-sort&lt;/code&gt; to revert to that format sorting preference. These two compat options cannot be used together&lt;/li&gt; 
 &lt;li&gt;The default format selector is &lt;code&gt;bv*+ba/b&lt;/code&gt;. This means that if a combined video + audio format that is better than the best video-only format is found, the former will be preferred. Use &lt;code&gt;-f bv+ba/b&lt;/code&gt; or &lt;code&gt;--compat-options format-spec&lt;/code&gt; to revert this&lt;/li&gt; 
 &lt;li&gt;Unlike youtube-dlc, yt-dlp does not allow merging multiple audio/video streams into one file by default (since this conflicts with the use of &lt;code&gt;-f bv*+ba&lt;/code&gt;). If needed, this feature must be enabled using &lt;code&gt;--audio-multistreams&lt;/code&gt; and &lt;code&gt;--video-multistreams&lt;/code&gt;. You can also use &lt;code&gt;--compat-options multistreams&lt;/code&gt; to enable both&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--no-abort-on-error&lt;/code&gt; is enabled by default. Use &lt;code&gt;--abort-on-error&lt;/code&gt; or &lt;code&gt;--compat-options abort-on-error&lt;/code&gt; to abort on errors instead&lt;/li&gt; 
 &lt;li&gt;When writing metadata files such as thumbnails, description or infojson, the same information (if available) is also written for playlists. Use &lt;code&gt;--no-write-playlist-metafiles&lt;/code&gt; or &lt;code&gt;--compat-options no-playlist-metafiles&lt;/code&gt; to not write these files&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--add-metadata&lt;/code&gt; attaches the &lt;code&gt;infojson&lt;/code&gt; to &lt;code&gt;mkv&lt;/code&gt; files in addition to writing the metadata when used with &lt;code&gt;--write-info-json&lt;/code&gt;. Use &lt;code&gt;--no-embed-info-json&lt;/code&gt; or &lt;code&gt;--compat-options no-attach-info-json&lt;/code&gt; to revert this&lt;/li&gt; 
 &lt;li&gt;Some metadata are embedded into different fields when using &lt;code&gt;--add-metadata&lt;/code&gt; as compared to youtube-dl. Most notably, &lt;code&gt;comment&lt;/code&gt; field contains the &lt;code&gt;webpage_url&lt;/code&gt; and &lt;code&gt;synopsis&lt;/code&gt; contains the &lt;code&gt;description&lt;/code&gt;. You can &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#modifying-metadata"&gt;use &lt;code&gt;--parse-metadata&lt;/code&gt;&lt;/a&gt; to modify this to your liking or use &lt;code&gt;--compat-options embed-metadata&lt;/code&gt; to revert this&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;playlist_index&lt;/code&gt; behaves differently when used with options like &lt;code&gt;--playlist-reverse&lt;/code&gt; and &lt;code&gt;--playlist-items&lt;/code&gt;. See &lt;a href="https://github.com/yt-dlp/yt-dlp/issues/302"&gt;#302&lt;/a&gt; for details. You can use &lt;code&gt;--compat-options playlist-index&lt;/code&gt; if you want to keep the earlier behavior&lt;/li&gt; 
 &lt;li&gt;The output of &lt;code&gt;-F&lt;/code&gt; is listed in a new format. Use &lt;code&gt;--compat-options list-formats&lt;/code&gt; to revert this&lt;/li&gt; 
 &lt;li&gt;Live chats (if available) are considered as subtitles. Use &lt;code&gt;--sub-langs all,-live_chat&lt;/code&gt; to download all subtitles except live chat. You can also use &lt;code&gt;--compat-options no-live-chat&lt;/code&gt; to prevent any live chat/danmaku from downloading&lt;/li&gt; 
 &lt;li&gt;YouTube channel URLs download all uploads of the channel. To download only the videos in a specific tab, pass the tab's URL. If the channel does not show the requested tab, an error will be raised. Also, &lt;code&gt;/live&lt;/code&gt; URLs raise an error if there are no live videos instead of silently downloading the entire channel. You may use &lt;code&gt;--compat-options no-youtube-channel-redirect&lt;/code&gt; to revert all these redirections&lt;/li&gt; 
 &lt;li&gt;Unavailable videos are also listed for YouTube playlists. Use &lt;code&gt;--compat-options no-youtube-unavailable-videos&lt;/code&gt; to remove this&lt;/li&gt; 
 &lt;li&gt;The upload dates extracted from YouTube are in UTC.&lt;/li&gt; 
 &lt;li&gt;If &lt;code&gt;ffmpeg&lt;/code&gt; is used as the downloader, the downloading and merging of formats happen in a single step when possible. Use &lt;code&gt;--compat-options no-direct-merge&lt;/code&gt; to revert this&lt;/li&gt; 
 &lt;li&gt;Thumbnail embedding in &lt;code&gt;mp4&lt;/code&gt; is done with mutagen if possible. Use &lt;code&gt;--compat-options embed-thumbnail-atomicparsley&lt;/code&gt; to force the use of AtomicParsley instead&lt;/li&gt; 
 &lt;li&gt;Some internal metadata such as filenames are removed by default from the infojson. Use &lt;code&gt;--no-clean-infojson&lt;/code&gt; or &lt;code&gt;--compat-options no-clean-infojson&lt;/code&gt; to revert this&lt;/li&gt; 
 &lt;li&gt;When &lt;code&gt;--embed-subs&lt;/code&gt; and &lt;code&gt;--write-subs&lt;/code&gt; are used together, the subtitles are written to disk and also embedded in the media file. You can use just &lt;code&gt;--embed-subs&lt;/code&gt; to embed the subs and automatically delete the separate file. See &lt;a href="https://github.com/yt-dlp/yt-dlp/issues/630#issuecomment-893659460"&gt;#630 (comment)&lt;/a&gt; for more info. &lt;code&gt;--compat-options no-keep-subs&lt;/code&gt; can be used to revert this&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;certifi&lt;/code&gt; will be used for SSL root certificates, if installed. If you want to use system certificates (e.g. self-signed), use &lt;code&gt;--compat-options no-certifi&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;yt-dlp's sanitization of invalid characters in filenames is different/smarter than in youtube-dl. You can use &lt;code&gt;--compat-options filename-sanitization&lt;/code&gt; to revert to youtube-dl's behavior&lt;/li&gt; 
 &lt;li&gt;&lt;del&gt;yt-dlp tries to parse the external downloader outputs into the standard progress output if possible (Currently implemented: &lt;a href="https://github.com/yt-dlp/yt-dlp/issues/5931"&gt;aria2c&lt;/a&gt;). You can use &lt;code&gt;--compat-options no-external-downloader-progress&lt;/code&gt; to get the downloader output as-is&lt;/del&gt;&lt;/li&gt; 
 &lt;li&gt;yt-dlp versions between 2021.09.01 and 2023.01.02 applies &lt;code&gt;--match-filters&lt;/code&gt; to nested playlists. This was an unintentional side-effect of &lt;a href="https://github.com/yt-dlp/yt-dlp/commit/8f18aca8717bb0dd49054555af8d386e5eda3a88"&gt;8f18ac&lt;/a&gt; and is fixed in &lt;a href="https://github.com/yt-dlp/yt-dlp/commit/d7b460d0e5fc710950582baed2e3fc616ed98a80"&gt;d7b460&lt;/a&gt;. Use &lt;code&gt;--compat-options playlist-match-filter&lt;/code&gt; to revert this&lt;/li&gt; 
 &lt;li&gt;yt-dlp versions between 2021.11.10 and 2023.06.21 estimated &lt;code&gt;filesize_approx&lt;/code&gt; values for fragmented/manifest formats. This was added for convenience in &lt;a href="https://github.com/yt-dlp/yt-dlp/commit/f2fe69c7b0d208bdb1f6292b4ae92bc1e1a7444a"&gt;f2fe69&lt;/a&gt;, but was reverted in &lt;a href="https://github.com/yt-dlp/yt-dlp/commit/0dff8e4d1e6e9fb938f4256ea9af7d81f42fd54f"&gt;0dff8e&lt;/a&gt; due to the potentially extreme inaccuracy of the estimated values. Use &lt;code&gt;--compat-options manifest-filesize-approx&lt;/code&gt; to keep extracting the estimated values&lt;/li&gt; 
 &lt;li&gt;yt-dlp uses modern http client backends such as &lt;code&gt;requests&lt;/code&gt;. Use &lt;code&gt;--compat-options prefer-legacy-http-handler&lt;/code&gt; to prefer the legacy http handler (&lt;code&gt;urllib&lt;/code&gt;) to be used for standard http requests.&lt;/li&gt; 
 &lt;li&gt;The sub-modules &lt;code&gt;swfinterp&lt;/code&gt;, &lt;code&gt;casefold&lt;/code&gt; are removed.&lt;/li&gt; 
 &lt;li&gt;Passing &lt;code&gt;--simulate&lt;/code&gt; (or calling &lt;code&gt;extract_info&lt;/code&gt; with &lt;code&gt;download=False&lt;/code&gt;) no longer alters the default format selection. See &lt;a href="https://github.com/yt-dlp/yt-dlp/issues/9843"&gt;#9843&lt;/a&gt; for details.&lt;/li&gt; 
 &lt;li&gt;yt-dlp no longer applies the server modified time to downloaded files by default. Use &lt;code&gt;--mtime&lt;/code&gt; or &lt;code&gt;--compat-options mtime-by-default&lt;/code&gt; to revert this.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For ease of use, a few more compat options are available:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;--compat-options all&lt;/code&gt;: Use all compat options (&lt;strong&gt;Do NOT use this!&lt;/strong&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--compat-options youtube-dl&lt;/code&gt;: Same as &lt;code&gt;--compat-options all,-multistreams,-playlist-match-filter,-manifest-filesize-approx,-allow-unsafe-ext,-prefer-vp9-sort&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--compat-options youtube-dlc&lt;/code&gt;: Same as &lt;code&gt;--compat-options all,-no-live-chat,-no-youtube-channel-redirect,-playlist-match-filter,-manifest-filesize-approx,-allow-unsafe-ext,-prefer-vp9-sort&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--compat-options 2021&lt;/code&gt;: Same as &lt;code&gt;--compat-options 2022,no-certifi,filename-sanitization&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--compat-options 2022&lt;/code&gt;: Same as &lt;code&gt;--compat-options 2023,playlist-match-filter,no-external-downloader-progress,prefer-legacy-http-handler,manifest-filesize-approx&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--compat-options 2023&lt;/code&gt;: Same as &lt;code&gt;--compat-options 2024,prefer-vp9-sort&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--compat-options 2024&lt;/code&gt;: Same as &lt;code&gt;--compat-options mtime-by-default&lt;/code&gt;. Use this to enable all future compat options&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The following compat options restore vulnerable behavior from before security patches:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;--compat-options allow-unsafe-ext&lt;/code&gt;: Allow files with any extension (including unsafe ones) to be downloaded (&lt;a href="https://github.com/yt-dlp/yt-dlp/security/advisories/GHSA-79w7-vh3h-8g4j"&gt;GHSA-79w7-vh3h-8g4j&lt;/a&gt;)&lt;/p&gt; 
  &lt;blockquote&gt; 
   &lt;p&gt;&lt;span&gt;‚ö†&lt;/span&gt; Only use if a valid file download is rejected because its extension is detected as uncommon&lt;/p&gt; 
   &lt;p&gt;&lt;strong&gt;This option can enable remote code execution! Consider &lt;a href="https://github.com/yt-dlp/yt-dlp/issues/new/choose"&gt;opening an issue&lt;/a&gt; instead!&lt;/strong&gt;&lt;/p&gt; 
  &lt;/blockquote&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Deprecated options&lt;/h3&gt; 
&lt;p&gt;These are all the deprecated options and the current alternative to achieve the same effect&lt;/p&gt; 
&lt;h4&gt;Almost redundant options&lt;/h4&gt; 
&lt;p&gt;While these options are almost the same as their new counterparts, there are some differences that prevents them being redundant&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;-j, --dump-json                  --print "%()j"
-F, --list-formats               --print formats_table
--list-thumbnails                --print thumbnails_table --print playlist:thumbnails_table
--list-subs                      --print automatic_captions_table --print subtitles_table
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Redundant options&lt;/h4&gt; 
&lt;p&gt;While these options are redundant, they are still expected to be used due to their ease of use&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;--get-description                --print description
--get-duration                   --print duration_string
--get-filename                   --print filename
--get-format                     --print format
--get-id                         --print id
--get-thumbnail                  --print thumbnail
-e, --get-title                  --print title
-g, --get-url                    --print urls
--match-title REGEX              --match-filters "title ~= (?i)REGEX"
--reject-title REGEX             --match-filters "title !~= (?i)REGEX"
--min-views COUNT                --match-filters "view_count &amp;gt;=? COUNT"
--max-views COUNT                --match-filters "view_count &amp;lt;=? COUNT"
--break-on-reject                Use --break-match-filters
--user-agent UA                  --add-headers "User-Agent:UA"
--referer URL                    --add-headers "Referer:URL"
--playlist-start NUMBER          -I NUMBER:
--playlist-end NUMBER            -I :NUMBER
--playlist-reverse               -I ::-1
--no-playlist-reverse            Default
--no-colors                      --color no_color
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Not recommended&lt;/h4&gt; 
&lt;p&gt;While these options still work, their use is not recommended since there are other alternatives to achieve the same&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;--force-generic-extractor        --ies generic,default
--exec-before-download CMD       --exec "before_dl:CMD"
--no-exec-before-download        --no-exec
--all-formats                    -f all
--all-subs                       --sub-langs all --write-subs
--print-json                     -j --no-simulate
--autonumber-size NUMBER         Use string formatting, e.g. %(autonumber)03d
--autonumber-start NUMBER        Use internal field formatting like %(autonumber+NUMBER)s
--id                             -o "%(id)s.%(ext)s"
--metadata-from-title FORMAT     --parse-metadata "%(title)s:FORMAT"
--hls-prefer-native              --downloader "m3u8:native"
--hls-prefer-ffmpeg              --downloader "m3u8:ffmpeg"
--list-formats-old               --compat-options list-formats (Alias: --no-list-formats-as-table)
--list-formats-as-table          --compat-options -list-formats [Default]
--geo-bypass                     --xff "default"
--no-geo-bypass                  --xff "never"
--geo-bypass-country CODE        --xff CODE
--geo-bypass-ip-block IP_BLOCK   --xff IP_BLOCK
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Developer options&lt;/h4&gt; 
&lt;p&gt;These options are not intended to be used by the end-user&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;--test                           Download only part of video for testing extractors
--load-pages                     Load pages dumped by --write-pages
--allow-unplayable-formats       List unplayable formats also
--no-allow-unplayable-formats    Default
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Old aliases&lt;/h4&gt; 
&lt;p&gt;These are aliases that are no longer documented for various reasons&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;--clean-infojson                 --clean-info-json
--force-write-download-archive   --force-write-archive
--no-clean-infojson              --no-clean-info-json
--no-split-tracks                --no-split-chapters
--no-write-srt                   --no-write-subs
--prefer-unsecure                --prefer-insecure
--rate-limit RATE                --limit-rate RATE
--split-tracks                   --split-chapters
--srt-lang LANGS                 --sub-langs LANGS
--trim-file-names LENGTH         --trim-filenames LENGTH
--write-srt                      --write-subs
--yes-overwrites                 --force-overwrites
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Sponskrub Options&lt;/h4&gt; 
&lt;p&gt;Support for &lt;a href="https://github.com/faissaloo/SponSkrub"&gt;SponSkrub&lt;/a&gt; has been removed in favor of the &lt;code&gt;--sponsorblock&lt;/code&gt; options&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;--sponskrub                      --sponsorblock-mark all
--no-sponskrub                   --no-sponsorblock
--sponskrub-cut                  --sponsorblock-remove all
--no-sponskrub-cut               --sponsorblock-remove -all
--sponskrub-force                Not applicable
--no-sponskrub-force             Not applicable
--sponskrub-location             Not applicable
--sponskrub-args                 Not applicable
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;No longer supported&lt;/h4&gt; 
&lt;p&gt;These options may no longer work as intended&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;--prefer-avconv                  avconv is not officially supported by yt-dlp (Alias: --no-prefer-ffmpeg)
--prefer-ffmpeg                  Default (Alias: --no-prefer-avconv)
-C, --call-home                  Not implemented
--no-call-home                   Default
--include-ads                    No longer supported
--no-include-ads                 Default
--write-annotations              No supported site has annotations now
--no-write-annotations           Default
--avconv-location                Removed alias for --ffmpeg-location
--cn-verification-proxy URL      Removed alias for --geo-verification-proxy URL
--dump-headers                   Removed alias for --print-traffic
--dump-intermediate-pages        Removed alias for --dump-pages
--youtube-skip-dash-manifest     Removed alias for --extractor-args "youtube:skip=dash" (Alias: --no-youtube-include-dash-manifest)
--youtube-skip-hls-manifest      Removed alias for --extractor-args "youtube:skip=hls" (Alias: --no-youtube-include-hls-manifest)
--youtube-include-dash-manifest  Default (Alias: --no-youtube-skip-dash-manifest)
--youtube-include-hls-manifest   Default (Alias: --no-youtube-skip-hls-manifest)
--youtube-print-sig-code         Removed testing functionality
--dump-user-agent                No longer supported
--xattr-set-filesize             No longer supported
--compat-options seperate-video-versions  No longer needed
--compat-options no-youtube-prefer-utc-upload-date  No longer supported
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Removed&lt;/h4&gt; 
&lt;p&gt;These options were deprecated since 2014 and have now been entirely removed&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;-A, --auto-number                -o "%(autonumber)s-%(id)s.%(ext)s"
-t, -l, --title, --literal       -o "%(title)s-%(id)s.%(ext)s"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;CONTRIBUTING&lt;/h1&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/CONTRIBUTING.md#contributing-to-yt-dlp"&gt;CONTRIBUTING.md&lt;/a&gt; for instructions on &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/CONTRIBUTING.md#opening-an-issue"&gt;Opening an Issue&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/CONTRIBUTING.md#developer-instructions"&gt;Contributing code to the project&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;WIKI&lt;/h1&gt; 
&lt;p&gt;See the &lt;a href="https://github.com/yt-dlp/yt-dlp/wiki"&gt;Wiki&lt;/a&gt; for more information&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>microsoft/BitNet</title>
      <link>https://github.com/microsoft/BitNet</link>
      <description>&lt;p&gt;Official inference framework for 1-bit LLMs&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;bitnet.cpp&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://opensource.org/licenses/MIT"&gt;&lt;img src="https://img.shields.io/badge/license-MIT-blue.svg?sanitize=true" alt="License: MIT" /&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/badge/version-1.0-blue" alt="version" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://huggingface.co/microsoft/BitNet-b1.58-2B-4T"&gt;&lt;img src="https://raw.githubusercontent.com/microsoft/BitNet/main/assets/header_model_release.png" alt="BitNet Model on Hugging Face" width="800" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Try it out via this &lt;a href="https://bitnet-demo.azurewebsites.net/"&gt;demo&lt;/a&gt;, or build and run it on your own &lt;a href="https://github.com/microsoft/BitNet?tab=readme-ov-file#build-from-source"&gt;CPU&lt;/a&gt; or &lt;a href="https://github.com/microsoft/BitNet/raw/main/gpu/README.md"&gt;GPU&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;bitnet.cpp is the official inference framework for 1-bit LLMs (e.g., BitNet b1.58). It offers a suite of optimized kernels, that support &lt;strong&gt;fast&lt;/strong&gt; and &lt;strong&gt;lossless&lt;/strong&gt; inference of 1.58-bit models on CPU and GPU (NPU support will coming next).&lt;/p&gt; 
&lt;p&gt;The first release of bitnet.cpp is to support inference on CPUs. bitnet.cpp achieves speedups of &lt;strong&gt;1.37x&lt;/strong&gt; to &lt;strong&gt;5.07x&lt;/strong&gt; on ARM CPUs, with larger models experiencing greater performance gains. Additionally, it reduces energy consumption by &lt;strong&gt;55.4%&lt;/strong&gt; to &lt;strong&gt;70.0%&lt;/strong&gt;, further boosting overall efficiency. On x86 CPUs, speedups range from &lt;strong&gt;2.37x&lt;/strong&gt; to &lt;strong&gt;6.17x&lt;/strong&gt; with energy reductions between &lt;strong&gt;71.9%&lt;/strong&gt; to &lt;strong&gt;82.2%&lt;/strong&gt;. Furthermore, bitnet.cpp can run a 100B BitNet b1.58 model on a single CPU, achieving speeds comparable to human reading (5-7 tokens per second), significantly enhancing the potential for running LLMs on local devices. Please refer to the &lt;a href="https://arxiv.org/abs/2410.16144"&gt;technical report&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;img src="https://raw.githubusercontent.com/microsoft/BitNet/main/assets/m2_performance.jpg" alt="m2_performance" width="800" /&gt; 
&lt;img src="https://raw.githubusercontent.com/microsoft/BitNet/main/assets/intel_performance.jpg" alt="m2_performance" width="800" /&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;The tested models are dummy setups used in a research context to demonstrate the inference performance of bitnet.cpp.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Demo&lt;/h2&gt; 
&lt;p&gt;A demo of bitnet.cpp running a BitNet b1.58 3B model on Apple M2:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/7f46b736-edec-4828-b809-4be780a3e5b1"&gt;https://github.com/user-attachments/assets/7f46b736-edec-4828-b809-4be780a3e5b1&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;What's New:&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;05/20/2025 &lt;a href="https://github.com/microsoft/BitNet/raw/main/gpu/README.md"&gt;BitNet Official GPU inference kernel&lt;/a&gt; &lt;img src="https://img.shields.io/badge/NEW-red" alt="NEW" /&gt;&lt;/li&gt; 
 &lt;li&gt;04/14/2025 &lt;a href="https://huggingface.co/microsoft/BitNet-b1.58-2B-4T"&gt;BitNet Official 2B Parameter Model on Hugging Face&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;02/18/2025 &lt;a href="https://arxiv.org/abs/2502.11880"&gt;Bitnet.cpp: Efficient Edge Inference for Ternary LLMs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;11/08/2024 &lt;a href="https://arxiv.org/abs/2411.04965"&gt;BitNet a4.8: 4-bit Activations for 1-bit LLMs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;10/21/2024 &lt;a href="https://arxiv.org/abs/2410.16144"&gt;1-bit AI Infra: Part 1.1, Fast and Lossless BitNet b1.58 Inference on CPUs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;10/17/2024 bitnet.cpp 1.0 released.&lt;/li&gt; 
 &lt;li&gt;03/21/2024 &lt;a href="https://github.com/microsoft/unilm/raw/master/bitnet/The-Era-of-1-bit-LLMs__Training_Tips_Code_FAQ.pdf"&gt;The-Era-of-1-bit-LLMs__Training_Tips_Code_FAQ&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;02/27/2024 &lt;a href="https://arxiv.org/abs/2402.17764"&gt;The Era of 1-bit LLMs: All Large Language Models are in 1.58 Bits&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;10/17/2023 &lt;a href="https://arxiv.org/abs/2310.11453"&gt;BitNet: Scaling 1-bit Transformers for Large Language Models&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Acknowledgements&lt;/h2&gt; 
&lt;p&gt;This project is based on the &lt;a href="https://github.com/ggerganov/llama.cpp"&gt;llama.cpp&lt;/a&gt; framework. We would like to thank all the authors for their contributions to the open-source community. Also, bitnet.cpp's kernels are built on top of the Lookup Table methodologies pioneered in &lt;a href="https://github.com/microsoft/T-MAC/"&gt;T-MAC&lt;/a&gt;. For inference of general low-bit LLMs beyond ternary models, we recommend using T-MAC.&lt;/p&gt; 
&lt;h2&gt;Official Models&lt;/h2&gt; 
&lt;table&gt;  
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;th rowspan="2"&gt;Model&lt;/th&gt; 
   &lt;th rowspan="2"&gt;Parameters&lt;/th&gt; 
   &lt;th rowspan="2"&gt;CPU&lt;/th&gt; 
   &lt;th colspan="3"&gt;Kernel&lt;/th&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;th&gt;I2_S&lt;/th&gt; 
   &lt;th&gt;TL1&lt;/th&gt; 
   &lt;th&gt;TL2&lt;/th&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td rowspan="2"&gt;&lt;a href="https://huggingface.co/microsoft/BitNet-b1.58-2B-4T"&gt;BitNet-b1.58-2B-4T&lt;/a&gt;&lt;/td&gt; 
   &lt;td rowspan="2"&gt;2.4B&lt;/td&gt; 
   &lt;td&gt;x86&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ARM&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h2&gt;Supported Models&lt;/h2&gt; 
&lt;p&gt;‚ùóÔ∏è&lt;strong&gt;We use existing 1-bit LLMs available on &lt;a href="https://huggingface.co/"&gt;Hugging Face&lt;/a&gt; to demonstrate the inference capabilities of bitnet.cpp. We hope the release of bitnet.cpp will inspire the development of 1-bit LLMs in large-scale settings in terms of model size and training tokens.&lt;/strong&gt;&lt;/p&gt; 
&lt;table&gt;  
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;th rowspan="2"&gt;Model&lt;/th&gt; 
   &lt;th rowspan="2"&gt;Parameters&lt;/th&gt; 
   &lt;th rowspan="2"&gt;CPU&lt;/th&gt; 
   &lt;th colspan="3"&gt;Kernel&lt;/th&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;th&gt;I2_S&lt;/th&gt; 
   &lt;th&gt;TL1&lt;/th&gt; 
   &lt;th&gt;TL2&lt;/th&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td rowspan="2"&gt;&lt;a href="https://huggingface.co/1bitLLM/bitnet_b1_58-large"&gt;bitnet_b1_58-large&lt;/a&gt;&lt;/td&gt; 
   &lt;td rowspan="2"&gt;0.7B&lt;/td&gt; 
   &lt;td&gt;x86&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ARM&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td rowspan="2"&gt;&lt;a href="https://huggingface.co/1bitLLM/bitnet_b1_58-3B"&gt;bitnet_b1_58-3B&lt;/a&gt;&lt;/td&gt; 
   &lt;td rowspan="2"&gt;3.3B&lt;/td&gt; 
   &lt;td&gt;x86&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ARM&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td rowspan="2"&gt;&lt;a href="https://huggingface.co/HF1BitLLM/Llama3-8B-1.58-100B-tokens"&gt;Llama3-8B-1.58-100B-tokens&lt;/a&gt;&lt;/td&gt; 
   &lt;td rowspan="2"&gt;8.0B&lt;/td&gt; 
   &lt;td&gt;x86&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ARM&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td rowspan="2"&gt;&lt;a href="https://huggingface.co/collections/tiiuae/falcon3-67605ae03578be86e4e87026"&gt;Falcon3 Family&lt;/a&gt;&lt;/td&gt; 
   &lt;td rowspan="2"&gt;1B-10B&lt;/td&gt; 
   &lt;td&gt;x86&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ARM&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td rowspan="2"&gt;&lt;a href="https://huggingface.co/collections/tiiuae/falcon-edge-series-6804fd13344d6d8a8fa71130"&gt;Falcon-E Family&lt;/a&gt;&lt;/td&gt; 
   &lt;td rowspan="2"&gt;1B-3B&lt;/td&gt; 
   &lt;td&gt;x86&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ARM&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;h3&gt;Requirements&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;python&amp;gt;=3.9&lt;/li&gt; 
 &lt;li&gt;cmake&amp;gt;=3.22&lt;/li&gt; 
 &lt;li&gt;clang&amp;gt;=18 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;For Windows users, install &lt;a href="https://visualstudio.microsoft.com/downloads/"&gt;Visual Studio 2022&lt;/a&gt;. In the installer, toggle on at least the following options(this also automatically installs the required additional tools like CMake):&lt;/p&gt; 
    &lt;ul&gt; 
     &lt;li&gt;Desktop-development with C++&lt;/li&gt; 
     &lt;li&gt;C++-CMake Tools for Windows&lt;/li&gt; 
     &lt;li&gt;Git for Windows&lt;/li&gt; 
     &lt;li&gt;C++-Clang Compiler for Windows&lt;/li&gt; 
     &lt;li&gt;MS-Build Support for LLVM-Toolset (clang)&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;For Debian/Ubuntu users, you can download with &lt;a href="https://apt.llvm.org/"&gt;Automatic installation script&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;bash -c "$(wget -O - https://apt.llvm.org/llvm.sh)"&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;conda (highly recommend)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Build from source&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] If you are using Windows, please remember to always use a Developer Command Prompt / PowerShell for VS2022 for the following commands. Please refer to the FAQs below if you see any issues.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ol&gt; 
 &lt;li&gt;Clone the repo&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone --recursive https://github.com/microsoft/BitNet.git
cd BitNet
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Install the dependencies&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# (Recommended) Create a new conda environment
conda create -n bitnet-cpp python=3.9
conda activate bitnet-cpp

pip install -r requirements.txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt;Build the project&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Manually download the model and run with local path
huggingface-cli download microsoft/BitNet-b1.58-2B-4T-gguf --local-dir models/BitNet-b1.58-2B-4T
python setup_env.py -md models/BitNet-b1.58-2B-4T -q i2_s

&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;
usage: setup_env.py [-h] [--hf-repo {1bitLLM/bitnet_b1_58-large,1bitLLM/bitnet_b1_58-3B,HF1BitLLM/Llama3-8B-1.58-100B-tokens,tiiuae/Falcon3-1B-Instruct-1.58bit,tiiuae/Falcon3-3B-Instruct-1.58bit,tiiuae/Falcon3-7B-Instruct-1.58bit,tiiuae/Falcon3-10B-Instruct-1.58bit}] [--model-dir MODEL_DIR] [--log-dir LOG_DIR] [--quant-type {i2_s,tl1}] [--quant-embd]
                    [--use-pretuned]

Setup the environment for running inference

optional arguments:
  -h, --help            show this help message and exit
  --hf-repo {1bitLLM/bitnet_b1_58-large,1bitLLM/bitnet_b1_58-3B,HF1BitLLM/Llama3-8B-1.58-100B-tokens,tiiuae/Falcon3-1B-Instruct-1.58bit,tiiuae/Falcon3-3B-Instruct-1.58bit,tiiuae/Falcon3-7B-Instruct-1.58bit,tiiuae/Falcon3-10B-Instruct-1.58bit}, -hr {1bitLLM/bitnet_b1_58-large,1bitLLM/bitnet_b1_58-3B,HF1BitLLM/Llama3-8B-1.58-100B-tokens,tiiuae/Falcon3-1B-Instruct-1.58bit,tiiuae/Falcon3-3B-Instruct-1.58bit,tiiuae/Falcon3-7B-Instruct-1.58bit,tiiuae/Falcon3-10B-Instruct-1.58bit}
                        Model used for inference
  --model-dir MODEL_DIR, -md MODEL_DIR
                        Directory to save/load the model
  --log-dir LOG_DIR, -ld LOG_DIR
                        Directory to save the logging info
  --quant-type {i2_s,tl1}, -q {i2_s,tl1}
                        Quantization type
  --quant-embd          Quantize the embeddings to f16
  --use-pretuned, -p    Use the pretuned kernel parameters
&lt;/pre&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;h3&gt;Basic usage&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Run inference with the quantized model
python run_inference.py -m models/BitNet-b1.58-2B-4T/ggml-model-i2_s.gguf -p "You are a helpful assistant" -cnv
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;
usage: run_inference.py [-h] [-m MODEL] [-n N_PREDICT] -p PROMPT [-t THREADS] [-c CTX_SIZE] [-temp TEMPERATURE] [-cnv]

Run inference

optional arguments:
  -h, --help            show this help message and exit
  -m MODEL, --model MODEL
                        Path to model file
  -n N_PREDICT, --n-predict N_PREDICT
                        Number of tokens to predict when generating text
  -p PROMPT, --prompt PROMPT
                        Prompt to generate text from
  -t THREADS, --threads THREADS
                        Number of threads to use
  -c CTX_SIZE, --ctx-size CTX_SIZE
                        Size of the prompt context
  -temp TEMPERATURE, --temperature TEMPERATURE
                        Temperature, a hyperparameter that controls the randomness of the generated text
  -cnv, --conversation  Whether to enable chat mode or not (for instruct models.)
                        (When this option is turned on, the prompt specified by -p will be used as the system prompt.)
&lt;/pre&gt; 
&lt;h3&gt;Benchmark&lt;/h3&gt; 
&lt;p&gt;We provide scripts to run the inference benchmark providing a model.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;usage: e2e_benchmark.py -m MODEL [-n N_TOKEN] [-p N_PROMPT] [-t THREADS]  
   
Setup the environment for running the inference  
   
required arguments:  
  -m MODEL, --model MODEL  
                        Path to the model file. 
   
optional arguments:  
  -h, --help  
                        Show this help message and exit. 
  -n N_TOKEN, --n-token N_TOKEN  
                        Number of generated tokens. 
  -p N_PROMPT, --n-prompt N_PROMPT  
                        Prompt to generate text from. 
  -t THREADS, --threads THREADS  
                        Number of threads to use. 
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Here's a brief explanation of each argument:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;-m&lt;/code&gt;, &lt;code&gt;--model&lt;/code&gt;: The path to the model file. This is a required argument that must be provided when running the script.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-n&lt;/code&gt;, &lt;code&gt;--n-token&lt;/code&gt;: The number of tokens to generate during the inference. It is an optional argument with a default value of 128.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-p&lt;/code&gt;, &lt;code&gt;--n-prompt&lt;/code&gt;: The number of prompt tokens to use for generating text. This is an optional argument with a default value of 512.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-t&lt;/code&gt;, &lt;code&gt;--threads&lt;/code&gt;: The number of threads to use for running the inference. It is an optional argument with a default value of 2.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-h&lt;/code&gt;, &lt;code&gt;--help&lt;/code&gt;: Show the help message and exit. Use this argument to display usage information.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;python utils/e2e_benchmark.py -m /path/to/model -n 200 -p 256 -t 4  
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This command would run the inference benchmark using the model located at &lt;code&gt;/path/to/model&lt;/code&gt;, generating 200 tokens from a 256 token prompt, utilizing 4 threads.&lt;/p&gt; 
&lt;p&gt;For the model layout that do not supported by any public model, we provide scripts to generate a dummy model with the given model layout, and run the benchmark on your machine:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python utils/generate-dummy-bitnet-model.py models/bitnet_b1_58-large --outfile models/dummy-bitnet-125m.tl1.gguf --outtype tl1 --model-size 125M

# Run benchmark with the generated model, use -m to specify the model path, -p to specify the prompt processed, -n to specify the number of token to generate
python utils/e2e_benchmark.py -m models/dummy-bitnet-125m.tl1.gguf -p 512 -n 128
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Convert from &lt;code&gt;.safetensors&lt;/code&gt; Checkpoints&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;# Prepare the .safetensors model file
huggingface-cli download microsoft/bitnet-b1.58-2B-4T-bf16 --local-dir ./models/bitnet-b1.58-2B-4T-bf16

# Convert to gguf model
python ./utils/convert-helper-bitnet.py ./models/bitnet-b1.58-2B-4T-bf16
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;FAQ (Frequently Asked Questions)üìå&lt;/h3&gt; 
&lt;h4&gt;Q1: The build dies with errors building llama.cpp due to issues with std::chrono in log.cpp?&lt;/h4&gt; 
&lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt; This is an issue introduced in recent version of llama.cpp. Please refer to this &lt;a href="https://github.com/tinglou/llama.cpp/commit/4e3db1e3d78cc1bcd22bcb3af54bd2a4628dd323"&gt;commit&lt;/a&gt; in the &lt;a href="https://github.com/abetlen/llama-cpp-python/issues/1942"&gt;discussion&lt;/a&gt; to fix this issue.&lt;/p&gt; 
&lt;h4&gt;Q2: How to build with clang in conda environment on windows?&lt;/h4&gt; 
&lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt; Before building the project, verify your clang installation and access to Visual Studio tools by running:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;clang -v
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This command checks that you are using the correct version of clang and that the Visual Studio tools are available. If you see an error message such as:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;'clang' is not recognized as an internal or external command, operable program or batch file.
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;It indicates that your command line window is not properly initialized for Visual Studio tools.&lt;/p&gt; 
&lt;p&gt;‚Ä¢ If you are using Command Prompt, run:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;"C:\Program Files\Microsoft Visual Studio\2022\Professional\Common7\Tools\VsDevCmd.bat" -startdir=none -arch=x64 -host_arch=x64
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;‚Ä¢ If you are using Windows PowerShell, run the following commands:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Import-Module "C:\Program Files\Microsoft Visual Studio\2022\Professional\Common7\Tools\Microsoft.VisualStudio.DevShell.dll" Enter-VsDevShell 3f0e31ad -SkipAutomaticLocation -DevCmdArguments "-arch=x64 -host_arch=x64"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;These steps will initialize your environment and allow you to use the correct Visual Studio tools.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>airweave-ai/airweave</title>
      <link>https://github.com/airweave-ai/airweave</link>
      <description>&lt;p&gt;Context retrieval for AI agents across apps and databases&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="frontend/public/logo-airweave-darkbg.svg" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="frontend/public/logo-airweave-lightbg.svg" /&gt; 
  &lt;img width="837" alt="airweave-lettermark" style="padding-bottom: 12px;" src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/public/logo-airweave-darkbg.svg?sanitize=true" /&gt; 
 &lt;/picture&gt; 
 &lt;h1&gt;Context Retrieval for AI Agents across Apps &amp;amp; Databases&lt;/h1&gt; 
 &lt;p&gt;&lt;a href="https://github.com/airweave-ai/airweave/actions/workflows/ruff.yml"&gt;&lt;img src="https://github.com/airweave-ai/airweave/actions/workflows/ruff.yml/badge.svg?sanitize=true" alt="Ruff" /&gt;&lt;/a&gt; &lt;a href="https://github.com/airweave-ai/airweave/actions/workflows/eslint.yml"&gt;&lt;img src="https://github.com/airweave-ai/airweave/actions/workflows/eslint.yml/badge.svg?sanitize=true" alt="ESLint" /&gt;&lt;/a&gt; &lt;a href="https://github.com/airweave-ai/airweave/actions/workflows/test-public-api.yml"&gt;&lt;img src="https://github.com/airweave-ai/airweave/actions/workflows/test-public-api.yml/badge.svg?sanitize=true" alt="System Tests" /&gt;&lt;/a&gt; &lt;a href="https://pepy.tech/projects/airweave-sdk"&gt;&lt;img src="https://static.pepy.tech/personalized-badge/airweave-sdk?period=total&amp;amp;units=INTERNATIONAL_SYSTEM&amp;amp;left_color=GRAY&amp;amp;right_color=BRIGHTGREEN&amp;amp;left_text=downloads" alt="PyPI Downloads" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/gDuebsWGkn"&gt;&lt;img src="https://img.shields.io/discord/1323415085011701870?label=Discord&amp;amp;logo=discord&amp;amp;logoColor=white&amp;amp;style=flat-square" alt="Discord" /&gt;&lt;/a&gt; &lt;br /&gt;&lt;/p&gt; 
 &lt;div style="padding-top: 16px;"&gt; 
  &lt;a href="https://trendshift.io/repositories/13748" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/13748" alt="airweave-ai%2Fairweave | Trendshift" style="width: 250px; height: 55px; margin-right: 24px;" width="250" height="55" /&gt;&lt;/a&gt;&amp;nbsp;&amp;nbsp;
  &lt;a href="https://www.ycombinator.com/launches/NX7-airweave-let-agents-search-any-app" target="_blank"&gt;&lt;img src="https://www.ycombinator.com/launches/NX7-airweave-let-agents-search-any-app/upvote_embed.svg?sanitize=true" alt="Launch YC: Airweave - Let Agents Search Any App" style="margin-left: 12px;" /&gt;&lt;/a&gt; 
 &lt;/div&gt; 
 &lt;br /&gt; 
 &lt;p&gt;‚≠ê &lt;strong&gt;Help us reach more developers and grow the Airweave community. Star this repo!&lt;/strong&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;What is Airweave?&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://app.airweave.ai/"&gt;Airweave&lt;/a&gt; is a fully open-source context retrieval layer for AI agents across apps and databases. It connects to apps, productivity tools, databases, or document stores and transforms their contents into searchable knowledge bases, accessible through a standardized interface for agents.&lt;/p&gt; 
&lt;p&gt;The search interface is exposed via REST API or MCP. When using MCP, Airweave essentially builds a semantically searchable MCP server. The platform handles everything from auth and extraction to embedding and serving. You can find our documentation &lt;a href="https://docs.airweave.ai/welcome"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;üì∫ Check out a quick demo of Airweave below:&lt;/p&gt; 
&lt;p&gt;
 &lt;video width="100%" src="https://github.com/user-attachments/assets/995e4a36-3f88-4d8e-b401-6ca43db0c7bf" controls&gt;&lt;/video&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/airweave-ai/airweave/tree/main/examples"&gt;&lt;strong&gt;üîó Example notebooks&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Table of Contents&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/airweave-ai/airweave/main/#airweave"&gt;Airweave&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/airweave-ai/airweave/main/#overview"&gt;Overview&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/airweave-ai/airweave/main/#table-of-contents"&gt;Table of Contents&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/airweave-ai/airweave/main/#-quick-start"&gt;üöÄ Quick Start&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/airweave-ai/airweave/main/#-supported-integrations"&gt;üîå Supported Integrations&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/airweave-ai/airweave/main/#-usage"&gt;üíª Usage&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/airweave-ai/airweave/main/#frontend"&gt;Frontend&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/airweave-ai/airweave/main/#api"&gt;API&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/airweave-ai/airweave/main/#-sdks"&gt;üì¶ SDKs&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/airweave-ai/airweave/main/#python"&gt;Python&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/airweave-ai/airweave/main/#typescriptjavascript"&gt;TypeScript/JavaScript&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/airweave-ai/airweave/main/#-key-features"&gt;üîë Key Features&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/airweave-ai/airweave/main/#-tech-stack"&gt;üîß Technology Stack&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/airweave-ai/airweave/main/#-contributing"&gt;üë• Contributing&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/airweave-ai/airweave/main/#-license"&gt;üìÑ License&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/airweave-ai/airweave/main/#-connect"&gt;üîó Connect&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üöÄ Quick Start&lt;/h2&gt; 
&lt;h3&gt;Managed Service: &lt;a href="https://app.airweave.ai/"&gt;Airweave Cloud&lt;/a&gt;&lt;/h3&gt; 
&lt;h3&gt;Self-hosted:&lt;/h3&gt; 
&lt;p&gt;Make sure docker and docker-compose are installed, then...&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# 1. Clone the repository
git clone https://github.com/airweave-ai/airweave.git
cd airweave

# 2. Build and run
chmod +x start.sh
./start.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;That's it! Access the dashboard at &lt;a href="http://localhost:8080"&gt;http://localhost:8080&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üîå Supported Integrations&lt;/h2&gt; 
&lt;!-- START_APP_GRID --&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/airtable.svg?sanitize=true" alt="Airtable" width="50" height="50" style="margin: 8px;" /&gt; &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/asana.svg?sanitize=true" alt="Asana" width="50" height="50" style="margin: 8px;" /&gt; &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/attio.svg?sanitize=true" alt="Attio" width="50" height="50" style="margin: 8px;" /&gt; &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/bitbucket.svg?sanitize=true" alt="Bitbucket" width="50" height="50" style="margin: 8px;" /&gt; &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/box.svg?sanitize=true" alt="Box" width="50" height="50" style="margin: 8px;" /&gt; &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/clickup.svg?sanitize=true" alt="ClickUp" width="50" height="50" style="margin: 8px;" /&gt; &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/confluence.svg?sanitize=true" alt="Confluence" width="50" height="50" style="margin: 8px;" /&gt; &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/ctti.svg?sanitize=true" alt="CTTI" width="50" height="50" style="margin: 8px;" /&gt; &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/dropbox.svg?sanitize=true" alt="Dropbox" width="50" height="50" style="margin: 8px;" /&gt; &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/excel.svg?sanitize=true" alt="Excel" width="50" height="50" style="margin: 8px;" /&gt; &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/github.svg?sanitize=true" alt="Github" width="50" height="50" style="margin: 8px;" /&gt; &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/gitlab.svg?sanitize=true" alt="Gitlab" width="50" height="50" style="margin: 8px;" /&gt; &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/gmail.svg?sanitize=true" alt="Gmail" width="50" height="50" style="margin: 8px;" /&gt; &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/google_calendar.svg?sanitize=true" alt="Google Calendar" width="50" height="50" style="margin: 8px;" /&gt; &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/google_docs.svg?sanitize=true" alt="Google Docs" width="50" height="50" style="margin: 8px;" /&gt; &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/google_drive.svg?sanitize=true" alt="Google Drive" width="50" height="50" style="margin: 8px;" /&gt; &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/google_slides.svg?sanitize=true" alt="Google Slides" width="50" height="50" style="margin: 8px;" /&gt; &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/hubspot.svg?sanitize=true" alt="Hubspot" width="50" height="50" style="margin: 8px;" /&gt; &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/jira.svg?sanitize=true" alt="Jira" width="50" height="50" style="margin: 8px;" /&gt; &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/linear.svg?sanitize=true" alt="Linear" width="50" height="50" style="margin: 8px;" /&gt; &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/monday.svg?sanitize=true" alt="Monday" width="50" height="50" style="margin: 8px;" /&gt; &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/notion.svg?sanitize=true" alt="Notion" width="50" height="50" style="margin: 8px;" /&gt; &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/onedrive.svg?sanitize=true" alt="Onedrive" width="50" height="50" style="margin: 8px;" /&gt; &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/onenote.svg?sanitize=true" alt="OneNote" width="50" height="50" style="margin: 8px;" /&gt; &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/outlook_calendar.svg?sanitize=true" alt="Outlook Calendar" width="50" height="50" style="margin: 8px;" /&gt; &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/outlook_mail.svg?sanitize=true" alt="Outlook Mail" width="50" height="50" style="margin: 8px;" /&gt; &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/postgresql.svg?sanitize=true" alt="Postgresql" width="50" height="50" style="margin: 8px;" /&gt; &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/salesforce.svg?sanitize=true" alt="Salesforce" width="50" height="50" style="margin: 8px;" /&gt; &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/sharepoint.svg?sanitize=true" alt="Sharepoint" width="50" height="50" style="margin: 8px;" /&gt; &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/slack.svg?sanitize=true" alt="Slack" width="50" height="50" style="margin: 8px;" /&gt; &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/stripe.svg?sanitize=true" alt="Stripe" width="50" height="50" style="margin: 8px;" /&gt; &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/teams.svg?sanitize=true" alt="Teams" width="50" height="50" style="margin: 8px;" /&gt; &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/todoist.svg?sanitize=true" alt="Todoist" width="50" height="50" style="margin: 8px;" /&gt; &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/trello.svg?sanitize=true" alt="Trello" width="50" height="50" style="margin: 8px;" /&gt; &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/word.svg?sanitize=true" alt="Word" width="50" height="50" style="margin: 8px;" /&gt; &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/zendesk.svg?sanitize=true" alt="Zendesk" width="50" height="50" style="margin: 8px;" /&gt; &lt;/p&gt; 
&lt;!-- END_APP_GRID --&gt; 
&lt;h2&gt;üíª Usage&lt;/h2&gt; 
&lt;h3&gt;Frontend&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Access the UI at &lt;code&gt;http://localhost:8080&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Connect sources, configure syncs, and query data&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;API&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Swagger docs: &lt;code&gt;http://localhost:8001/docs&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Create connections, trigger syncs, and search data&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üì¶ SDKs&lt;/h2&gt; 
&lt;h3&gt;Python&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install airweave-sdk
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from airweave import AirweaveSDK

# Initialize client
client = AirweaveSDK(
    api_key="YOUR_API_KEY",
    base_url="http://localhost:8001"
)

# Create a collection
collection = client.collections.create(name="My Collection")

# Add a source connection
source = client.source_connections.create(
    name="My Stripe Connection",
    short_name="stripe",
    readable_collection_id=collection.readable_id,
    authentication={
        "credentials": {"api_key": "your_stripe_api_key"}
    }
)

# Semantic search (default)
results = client.collections.search(
    readable_id=collection.readable_id,
    query="Find recent failed payments"
)

# Hybrid search (semantic + keyword)
results = client.collections.search(
    readable_id=collection.readable_id,
    query="customer invoices Q4 2024",
    search_type="hybrid"
)

# With query expansion and reranking
results = client.collections.search(
    readable_id=collection.readable_id,
    query="technical documentation",
    enable_query_expansion=True,
    enable_reranking=True,
    top_k=20
)

# Search with recency bias (prioritize recent results)
results = client.collections.search(
    readable_id=collection.readable_id,
    query="critical bugs",
    recency_bias=0.8,  # 0.0 to 1.0, higher = more recent
    limit=10
)

# Get AI-generated answer instead of raw results
answer = client.collections.search(
    readable_id=collection.readable_id,
    query="What are our customer refund policies?",
    response_type="completion",
    enable_reranking=True
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;TypeScript/JavaScript&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;npm install @airweave/sdk
# or
yarn add @airweave/sdk
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-typescript"&gt;import { AirweaveSDKClient, AirweaveSDKEnvironment } from "@airweave/sdk";

// Initialize client
const client = new AirweaveSDKClient({
    apiKey: "YOUR_API_KEY",
    environment: AirweaveSDKEnvironment.Local
});

// Create a collection
const collection = await client.collections.create({
    name: "My Collection"
});

// Add a source connection
const source = await client.sourceConnections.create({
    name: "My Stripe Connection",
    shortName: "stripe",
    readableCollectionId: collection.readableId,
    authentication: {
        credentials: { apiKey: "your_stripe_api_key" }
    }
});

// Semantic search (default)
const results = await client.collections.search(
    collection.readableId,
    { query: "Find recent failed payments" }
);

// Hybrid search (semantic + keyword)
const hybridResults = await client.collections.search(
    collection.readableId,
    {
        query: "customer invoices Q4 2024",
        searchType: "hybrid"
    }
);

// With query expansion and reranking
const advancedResults = await client.collections.search(
    collection.readableId,
    {
        query: "technical documentation",
        enableQueryExpansion: true,
        enableReranking: true,
        topK: 20
    }
);

// Search with recency bias (prioritize recent results)
const recentResults = await client.collections.search(
    collection.readableId,
    {
        query: "critical bugs",
        recencyBias: 0.8,  // 0.0 to 1.0, higher = more recent
        limit: 10
    }
);

// Get AI-generated answer instead of raw results
const answer = await client.collections.search(
    collection.readableId,
    {
        query: "What are our customer refund policies?",
        responseType: "completion",
        enableReranking: true
    }
);
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;üîë Key Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Data synchronization&lt;/strong&gt; from 30+ sources with minimal config&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Entity extraction&lt;/strong&gt; and transformation pipeline&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Multi-tenant&lt;/strong&gt; architecture with OAuth2&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Incremental updates&lt;/strong&gt; using content hashing&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Semantic search&lt;/strong&gt; for agent queries&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Versioning&lt;/strong&gt; for data changes&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üîß Tech Stack&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Frontend&lt;/strong&gt;: React/TypeScript with ShadCN&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Backend&lt;/strong&gt;: FastAPI (Python)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Databases&lt;/strong&gt;: PostgreSQL (metadata), Qdrant (vectors)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Workers&lt;/strong&gt;: Temporal (workflow orchestration), Redis (pub/sub)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Deployment&lt;/strong&gt;: Docker Compose (dev), Kubernetes (prod)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üë• Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome contributions! Please check &lt;a href="https://github.com/airweave-ai/airweave/raw/main/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; for details.&lt;/p&gt; 
&lt;h2&gt;üìÑ License&lt;/h2&gt; 
&lt;p&gt;Airweave is released under the &lt;a href="https://raw.githubusercontent.com/airweave-ai/airweave/main/LICENSE"&gt;MIT&lt;/a&gt; license.&lt;/p&gt; 
&lt;h2&gt;üîó Connect&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://discord.com/invite/484HY9Ehxt"&gt;Discord&lt;/a&gt;&lt;/strong&gt; - Get help and discuss features&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/airweave-ai/airweave/issues"&gt;GitHub Issues&lt;/a&gt;&lt;/strong&gt; - Report bugs or request features&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://x.com/airweave_ai"&gt;Twitter&lt;/a&gt;&lt;/strong&gt; - Follow for updates&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>yichuan-w/LEANN</title>
      <link>https://github.com/yichuan-w/LEANN</link>
      <description>&lt;p&gt;RAG on Everything with LEANN. Enjoy 97% storage savings while running a fast, accurate, and 100% private RAG application on your personal device.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/yichuan-w/LEANN/main/assets/logo-text.png" alt="LEANN Logo" width="400" /&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://img.shields.io/badge/Python-3.9%20%7C%203.10%20%7C%203.11%20%7C%203.12%20%7C%203.13-blue.svg?sanitize=true" alt="Python Versions" /&gt; &lt;img src="https://github.com/yichuan-w/LEANN/actions/workflows/build-and-publish.yml/badge.svg?sanitize=true" alt="CI Status" /&gt; &lt;img src="https://img.shields.io/badge/Platform-Ubuntu%20%26%20Arch%20%26%20WSL%20%7C%20macOS%20(ARM64%2FIntel)-lightgrey" alt="Platform" /&gt; &lt;img src="https://img.shields.io/badge/License-MIT-green.svg?sanitize=true" alt="MIT License" /&gt; &lt;img src="https://img.shields.io/badge/MCP-Native%20Integration-blue" alt="MCP Integration" /&gt; &lt;a href="https://join.slack.com/t/leann-e2u9779/shared_invite/zt-3ckd2f6w1-OX08~NN4gkWhh10PRVBj1Q"&gt; &lt;img src="https://img.shields.io/badge/Slack-Join-4A154B?logo=slack&amp;amp;logoColor=white" alt="Join Slack" /&gt; &lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/yichuan-w/LEANN/main/assets/wechat_user_group.JPG" title="Join WeChat group"&gt; &lt;img src="https://img.shields.io/badge/WeChat-Join-2DC100?logo=wechat&amp;amp;logoColor=white" alt="Join WeChat group" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;h2 align="center" tabindex="-1" class="heading-element" dir="auto"&gt; The smallest vector index in the world. RAG Everything with LEANN! &lt;/h2&gt; 
&lt;p&gt;LEANN is an innovative vector database that democratizes personal AI. Transform your laptop into a powerful RAG system that can index and search through millions of documents while using &lt;strong&gt;97% less storage&lt;/strong&gt; than traditional solutions &lt;strong&gt;without accuracy loss&lt;/strong&gt;.&lt;/p&gt; 
&lt;p&gt;LEANN achieves this through &lt;em&gt;graph-based selective recomputation&lt;/em&gt; with &lt;em&gt;high-degree preserving pruning&lt;/em&gt;, computing embeddings on-demand instead of storing them all. &lt;a href="https://raw.githubusercontent.com/yichuan-w/LEANN/main/#%EF%B8%8F-architecture--how-it-works"&gt;Illustration Fig ‚Üí&lt;/a&gt; | &lt;a href="https://arxiv.org/abs/2506.08276"&gt;Paper ‚Üí&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Ready to RAG Everything?&lt;/strong&gt; Transform your laptop into a personal AI assistant that can semantic search your &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/yichuan-w/LEANN/main/#-personal-data-manager-process-any-documents-pdf-txt-md"&gt;file system&lt;/a&gt;&lt;/strong&gt;, &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/yichuan-w/LEANN/main/#-your-personal-email-secretary-rag-on-apple-mail"&gt;emails&lt;/a&gt;&lt;/strong&gt;, &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/yichuan-w/LEANN/main/#-time-machine-for-the-web-rag-your-entire-browser-history"&gt;browser history&lt;/a&gt;&lt;/strong&gt;, &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/yichuan-w/LEANN/main/#-wechat-detective-unlock-your-golden-memories"&gt;chat history&lt;/a&gt;&lt;/strong&gt; (&lt;a href="https://raw.githubusercontent.com/yichuan-w/LEANN/main/#-wechat-detective-unlock-your-golden-memories"&gt;WeChat&lt;/a&gt;, &lt;a href="https://raw.githubusercontent.com/yichuan-w/LEANN/main/#-imessage-history-your-personal-conversation-archive"&gt;iMessage&lt;/a&gt;), &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/yichuan-w/LEANN/main/#-chatgpt-chat-history-your-personal-ai-conversation-archive"&gt;agent memory&lt;/a&gt;&lt;/strong&gt; (&lt;a href="https://raw.githubusercontent.com/yichuan-w/LEANN/main/#-chatgpt-chat-history-your-personal-ai-conversation-archive"&gt;ChatGPT&lt;/a&gt;, &lt;a href="https://raw.githubusercontent.com/yichuan-w/LEANN/main/#-claude-chat-history-your-personal-ai-conversation-archive"&gt;Claude&lt;/a&gt;), &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/yichuan-w/LEANN/main/#mcp-integration-rag-on-live-data-from-any-platform"&gt;live data&lt;/a&gt;&lt;/strong&gt; (&lt;a href="https://raw.githubusercontent.com/yichuan-w/LEANN/main/#mcp-integration-rag-on-live-data-from-any-platform"&gt;Slack&lt;/a&gt;, &lt;a href="https://raw.githubusercontent.com/yichuan-w/LEANN/main/#mcp-integration-rag-on-live-data-from-any-platform"&gt;Twitter&lt;/a&gt;), &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/yichuan-w/LEANN/main/#-claude-code-integration-transform-your-development-workflow"&gt;codebase&lt;/a&gt;&lt;/strong&gt;* , or external knowledge bases (i.e., 60M documents) - all on your laptop, with zero cloud costs and complete privacy.&lt;/p&gt; 
&lt;p&gt;* Claude Code only supports basic &lt;code&gt;grep&lt;/code&gt;-style keyword search. &lt;strong&gt;LEANN&lt;/strong&gt; is a drop-in &lt;strong&gt;semantic search MCP service fully compatible with Claude Code&lt;/strong&gt;, unlocking intelligent retrieval without changing your workflow. üî• Check out &lt;a href="https://raw.githubusercontent.com/yichuan-w/LEANN/main/packages/leann-mcp/README.md"&gt;the easy setup ‚Üí&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Why LEANN?&lt;/h2&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/yichuan-w/LEANN/main/assets/effects.png" alt="LEANN vs Traditional Vector DB Storage Comparison" width="70%" /&gt; &lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;The numbers speak for themselves:&lt;/strong&gt; Index 60 million text chunks in just 6GB instead of 201GB. From emails to browser history, everything fits on your laptop. &lt;a href="https://raw.githubusercontent.com/yichuan-w/LEANN/main/#-storage-comparison"&gt;See detailed benchmarks for different applications below ‚Üì&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;üîí &lt;strong&gt;Privacy:&lt;/strong&gt; Your data never leaves your laptop. No OpenAI, no cloud, no "terms of service".&lt;/p&gt; 
&lt;p&gt;ü™∂ &lt;strong&gt;Lightweight:&lt;/strong&gt; Graph-based recomputation eliminates heavy embedding storage, while smart graph pruning and CSR format minimize graph storage overhead. Always less storage, less memory usage!&lt;/p&gt; 
&lt;p&gt;üì¶ &lt;strong&gt;Portable:&lt;/strong&gt; Transfer your entire knowledge base between devices (even with others) with minimal cost - your personal AI memory travels with you.&lt;/p&gt; 
&lt;p&gt;üìà &lt;strong&gt;Scalability:&lt;/strong&gt; Handle messy personal data that would crash traditional vector DBs, easily managing your growing personalized data and agent generated memory!&lt;/p&gt; 
&lt;p&gt;‚ú® &lt;strong&gt;No Accuracy Loss:&lt;/strong&gt; Maintain the same search quality as heavyweight solutions while using 97% less storage.&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;h3&gt;üì¶ Prerequisites: Install uv&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://docs.astral.sh/uv/getting-started/installation/#installation-methods"&gt;Install uv&lt;/a&gt; first if you don't have it. Typically, you can install it with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -LsSf https://astral.sh/uv/install.sh | sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;üöÄ Quick Install&lt;/h3&gt; 
&lt;p&gt;Clone the repository to access all examples and try amazing applications,&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/yichuan-w/LEANN.git leann
cd leann
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;and install LEANN from &lt;a href="https://pypi.org/project/leann/"&gt;PyPI&lt;/a&gt; to run them immediately:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uv venv
source .venv/bin/activate
uv pip install leann
&lt;/code&gt;&lt;/pre&gt; 
&lt;!--
&gt; Low-resource? See "Low-resource setups" in the [Configuration Guide](docs/configuration-guide.md#low-resource-setups). --&gt; 
&lt;details&gt; 
 &lt;summary&gt; &lt;strong&gt;üîß Build from Source (Recommended for development)&lt;/strong&gt; &lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/yichuan-w/LEANN.git leann
cd leann
git submodule update --init --recursive
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;macOS:&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;Note: DiskANN requires MacOS 13.3 or later.&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;brew install libomp boost protobuf zeromq pkgconf
uv sync --extra diskann
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;Linux (Ubuntu/Debian):&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;Note: On Ubuntu 20.04, you may need to build a newer Abseil and pin Protobuf (e.g., v3.20.x) for building DiskANN. See &lt;a href="https://github.com/yichuan-w/LEANN/issues/30"&gt;Issue #30&lt;/a&gt; for a step-by-step note.&lt;/p&gt; 
 &lt;p&gt;You can manually install &lt;a href="https://www.intel.com/content/www/us/en/developer/tools/oneapi/onemkl.html"&gt;Intel oneAPI MKL&lt;/a&gt; instead of &lt;code&gt;libmkl-full-dev&lt;/code&gt; for DiskANN. You can also use &lt;code&gt;libopenblas-dev&lt;/code&gt; for building HNSW only, by removing &lt;code&gt;--extra diskann&lt;/code&gt; in the command below.&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;sudo apt-get update &amp;amp;&amp;amp; sudo apt-get install -y \
  libomp-dev libboost-all-dev protobuf-compiler libzmq3-dev \
  pkg-config libabsl-dev libaio-dev libprotobuf-dev \
  libmkl-full-dev

uv sync --extra diskann
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;Linux (Arch Linux):&lt;/strong&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;sudo pacman -Syu &amp;amp;&amp;amp; sudo pacman -S --needed base-devel cmake pkgconf git gcc \
  boost boost-libs protobuf abseil-cpp libaio zeromq

# For MKL in DiskANN
sudo pacman -S --needed base-devel git
git clone https://aur.archlinux.org/paru-bin.git
cd paru-bin &amp;amp;&amp;amp; makepkg -si
paru -S intel-oneapi-mkl intel-oneapi-compiler
source /opt/intel/oneapi/setvars.sh

uv sync --extra diskann
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;Linux (RHEL / CentOS Stream / Oracle / Rocky / AlmaLinux):&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;See &lt;a href="https://github.com/yichuan-w/LEANN/issues/50"&gt;Issue #50&lt;/a&gt; for more details.&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;sudo dnf groupinstall -y "Development Tools"
sudo dnf install -y libomp-devel boost-devel protobuf-compiler protobuf-devel \
  abseil-cpp-devel libaio-devel zeromq-devel pkgconf-pkg-config

# For MKL in DiskANN
sudo dnf install -y intel-oneapi-mkl intel-oneapi-mkl-devel \
  intel-oneapi-openmp || sudo dnf install -y intel-oneapi-compiler
source /opt/intel/oneapi/setvars.sh

uv sync --extra diskann
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;p&gt;Our declarative API makes RAG as easy as writing a config file.&lt;/p&gt; 
&lt;p&gt;Check out &lt;a href="https://raw.githubusercontent.com/yichuan-w/LEANN/main/demo.ipynb"&gt;demo.ipynb&lt;/a&gt; or &lt;a href="https://colab.research.google.com/github/yichuan-w/LEANN/blob/main/demo.ipynb"&gt;&lt;img src="https://colab.research.google.com/assets/colab-badge.svg?sanitize=true" alt="Open In Colab" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from leann import LeannBuilder, LeannSearcher, LeannChat
from pathlib import Path
INDEX_PATH = str(Path("./").resolve() / "demo.leann")

# Build an index
builder = LeannBuilder(backend_name="hnsw")
builder.add_text("LEANN saves 97% storage compared to traditional vector databases.")
builder.add_text("Tung Tung Tung Sahur called‚Äîthey need their banana‚Äëcrocodile hybrid back")
builder.build_index(INDEX_PATH)

# Search
searcher = LeannSearcher(INDEX_PATH)
results = searcher.search("fantastical AI-generated creatures", top_k=1)

# Chat with your data
chat = LeannChat(INDEX_PATH, llm_config={"type": "hf", "model": "Qwen/Qwen3-0.6B"})
response = chat.ask("How much storage does LEANN save?", top_k=1)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;RAG on Everything!&lt;/h2&gt; 
&lt;p&gt;LEANN supports RAG on various data sources including documents (&lt;code&gt;.pdf&lt;/code&gt;, &lt;code&gt;.txt&lt;/code&gt;, &lt;code&gt;.md&lt;/code&gt;), Apple Mail, Google Search History, WeChat, ChatGPT conversations, Claude conversations, iMessage conversations, and &lt;strong&gt;live data from any platform through MCP (Model Context Protocol) servers&lt;/strong&gt; - including Slack, Twitter, and more.&lt;/p&gt; 
&lt;h3&gt;Generation Model Setup&lt;/h3&gt; 
&lt;h4&gt;LLM Backend&lt;/h4&gt; 
&lt;p&gt;LEANN supports many LLM providers for text generation (HuggingFace, Ollama, and Any OpenAI compatible API).&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;üîë OpenAI API Setup (Default)&lt;/strong&gt;&lt;/summary&gt; 
 &lt;p&gt;Set your OpenAI API key as an environment variable:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;export OPENAI_API_KEY="your-api-key-here"
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Make sure to use &lt;code&gt;--llm openai&lt;/code&gt; flag when using the CLI. You can also specify the model name with &lt;code&gt;--llm-model &amp;lt;model-name&amp;gt;&lt;/code&gt; flag.&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;üõ†Ô∏è Supported LLM &amp;amp; Embedding Providers (via OpenAI Compatibility)&lt;/strong&gt;&lt;/summary&gt; 
 &lt;p&gt;Thanks to the widespread adoption of the OpenAI API format, LEANN is compatible out-of-the-box with a vast array of LLM and embedding providers. Simply set the &lt;code&gt;OPENAI_BASE_URL&lt;/code&gt; and &lt;code&gt;OPENAI_API_KEY&lt;/code&gt; environment variables to connect to your preferred service.&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-sh"&gt;export OPENAI_API_KEY="xxx"
export OPENAI_BASE_URL="http://localhost:1234/v1" # base url of the provider
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;To use OpenAI compatible endpoint with the CLI interface:&lt;/p&gt; 
 &lt;p&gt;If you are using it for text generation, make sure to use &lt;code&gt;--llm openai&lt;/code&gt; flag and specify the model name with &lt;code&gt;--llm-model &amp;lt;model-name&amp;gt;&lt;/code&gt; flag.&lt;/p&gt; 
 &lt;p&gt;If you are using it for embedding, set the &lt;code&gt;--embedding-mode openai&lt;/code&gt; flag and specify the model name with &lt;code&gt;--embedding-model &amp;lt;MODEL&amp;gt;&lt;/code&gt;.&lt;/p&gt; 
 &lt;hr /&gt; 
 &lt;p&gt;Below is a list of base URLs for common providers to get you started.&lt;/p&gt; 
 &lt;h3&gt;üñ•Ô∏è Local Inference Engines (Recommended for full privacy)&lt;/h3&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;Provider&lt;/th&gt; 
    &lt;th&gt;Sample Base URL&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;Ollama&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;http://localhost:11434/v1&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;LM Studio&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;http://localhost:1234/v1&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;vLLM&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;http://localhost:8000/v1&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;llama.cpp&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;http://localhost:8080/v1&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;SGLang&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;http://localhost:30000/v1&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;LiteLLM&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;http://localhost:4000&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
 &lt;hr /&gt; 
 &lt;h3&gt;‚òÅÔ∏è Cloud Providers&lt;/h3&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;&lt;strong&gt;üö® A Note on Privacy:&lt;/strong&gt; Before choosing a cloud provider, carefully review their privacy and data retention policies. Depending on their terms, your data may be used for their own purposes, including but not limited to human reviews and model training, which can lead to serious consequences if not handled properly.&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;Provider&lt;/th&gt; 
    &lt;th&gt;Base URL&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;OpenAI&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;https://api.openai.com/v1&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;OpenRouter&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;https://openrouter.ai/api/v1&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;Gemini&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;https://generativelanguage.googleapis.com/v1beta/openai/&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;x.AI (Grok)&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;https://api.x.ai/v1&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;Groq AI&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;https://api.groq.com/openai/v1&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;DeepSeek&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;https://api.deepseek.com/v1&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;SiliconFlow&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;https://api.siliconflow.cn/v1&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;Zhipu (BigModel)&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;https://open.bigmodel.cn/api/paas/v4/&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;Mistral AI&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;https://api.mistral.ai/v1&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
 &lt;p&gt;If your provider isn't on this list, don't worry! Check their documentation for an OpenAI-compatible endpoint‚Äîchances are, it's OpenAI Compatible too!&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;üîß Ollama Setup (Recommended for full privacy)&lt;/strong&gt;&lt;/summary&gt; 
 &lt;p&gt;&lt;strong&gt;macOS:&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;First, &lt;a href="https://ollama.com/download/mac"&gt;download Ollama for macOS&lt;/a&gt;.&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# Pull a lightweight model (recommended for consumer hardware)
ollama pull llama3.2:1b
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;Linux:&lt;/strong&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# Install Ollama
curl -fsSL https://ollama.ai/install.sh | sh

# Start Ollama service manually
ollama serve &amp;amp;

# Pull a lightweight model (recommended for consumer hardware)
ollama pull llama3.2:1b
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h2&gt;‚≠ê Flexible Configuration&lt;/h2&gt; 
&lt;p&gt;LEANN provides flexible parameters for embedding models, search strategies, and data processing to fit your specific needs.&lt;/p&gt; 
&lt;p&gt;üìö &lt;strong&gt;Need configuration best practices?&lt;/strong&gt; Check our &lt;a href="https://raw.githubusercontent.com/yichuan-w/LEANN/main/docs/configuration-guide.md"&gt;Configuration Guide&lt;/a&gt; for detailed optimization tips, model selection advice, and solutions to common issues like slow embeddings or poor search quality.&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;üìã Click to expand: Common Parameters (Available in All Examples)&lt;/strong&gt;&lt;/summary&gt; 
 &lt;p&gt;All RAG examples share these common parameters. &lt;strong&gt;Interactive mode&lt;/strong&gt; is available in all examples - simply run without &lt;code&gt;--query&lt;/code&gt; to start a continuous Q&amp;amp;A session where you can ask multiple questions. Type 'quit' to exit.&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# Core Parameters (General preprocessing for all examples)
--index-dir DIR              # Directory to store the index (default: current directory)
--query "YOUR QUESTION"      # Single query mode. Omit for interactive chat (type 'quit' to exit), and now you can play with your index interactively
--max-items N                # Limit data preprocessing (default: -1, process all data)
--force-rebuild              # Force rebuild index even if it exists

# Embedding Parameters
--embedding-model MODEL      # e.g., facebook/contriever, text-embedding-3-small, mlx-community/Qwen3-Embedding-0.6B-8bit or nomic-embed-text
--embedding-mode MODE        # sentence-transformers, openai, mlx, or ollama

# LLM Parameters (Text generation models)
--llm TYPE                   # LLM backend: openai, ollama, or hf (default: openai)
--llm-model MODEL            # Model name (default: gpt-4o) e.g., gpt-4o-mini, llama3.2:1b, Qwen/Qwen2.5-1.5B-Instruct
--thinking-budget LEVEL      # Thinking budget for reasoning models: low/medium/high (supported by o3, o3-mini, GPT-Oss:20b, and other reasoning models)

# Search Parameters
--top-k N                    # Number of results to retrieve (default: 20)
--search-complexity N        # Search complexity for graph traversal (default: 32)

# Chunking Parameters
--chunk-size N               # Size of text chunks (default varies by source: 256 for most, 192 for WeChat)
--chunk-overlap N            # Overlap between chunks (default varies: 25-128 depending on source)

# Index Building Parameters
--backend-name NAME          # Backend to use: hnsw or diskann (default: hnsw)
--graph-degree N             # Graph degree for index construction (default: 32)
--build-complexity N         # Build complexity for index construction (default: 64)
--compact / --no-compact     # Use compact storage (default: true). Must be `no-compact` for `no-recompute` build.
--recompute / --no-recompute # Enable/disable embedding recomputation (default: enabled). Should not do a `no-recompute` search in a `recompute` build.
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h3&gt;üìÑ Personal Data Manager: Process Any Documents (&lt;code&gt;.pdf&lt;/code&gt;, &lt;code&gt;.txt&lt;/code&gt;, &lt;code&gt;.md&lt;/code&gt;)!&lt;/h3&gt; 
&lt;p&gt;Ask questions directly about your personal PDFs, documents, and any directory containing your files!&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/yichuan-w/LEANN/main/videos/paper_clear.gif" alt="LEANN Document Search Demo" width="600" /&gt; &lt;/p&gt; 
&lt;p&gt;The example below asks a question about summarizing our paper (uses default data in &lt;code&gt;data/&lt;/code&gt;, which is a directory with diverse data sources: two papers, Pride and Prejudice, and a Technical report about LLM in Huawei in Chinese), and this is the &lt;strong&gt;easiest example&lt;/strong&gt; to run here:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;source .venv/bin/activate # Don't forget to activate the virtual environment
python -m apps.document_rag --query "What are the main techniques LEANN explores?"
&lt;/code&gt;&lt;/pre&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;üìã Click to expand: Document-Specific Arguments&lt;/strong&gt;&lt;/summary&gt; 
 &lt;h4&gt;Parameters&lt;/h4&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;--data-dir DIR           # Directory containing documents to process (default: data)
--file-types .ext .ext   # Filter by specific file types (optional - all LlamaIndex supported types if omitted)
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h4&gt;Example Commands&lt;/h4&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# Process all documents with larger chunks for academic papers
python -m apps.document_rag --data-dir "~/Documents/Papers" --chunk-size 1024

# Filter only markdown and Python files with smaller chunks
python -m apps.document_rag --data-dir "./docs" --chunk-size 256 --file-types .md .py

# Enable AST-aware chunking for code files
python -m apps.document_rag --enable-code-chunking --data-dir "./my_project"

# Or use the specialized code RAG for better code understanding
python -m apps.code_rag --repo-dir "./my_codebase" --query "How does authentication work?"
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h3&gt;üìß Your Personal Email Secretary: RAG on Apple Mail!&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; The examples below currently support macOS only. Windows support coming soon.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/yichuan-w/LEANN/main/videos/mail_clear.gif" alt="LEANN Email Search Demo" width="600" /&gt; &lt;/p&gt; 
&lt;p&gt;Before running the example below, you need to grant full disk access to your terminal/VS Code in System Preferences ‚Üí Privacy &amp;amp; Security ‚Üí Full Disk Access.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python -m apps.email_rag --query "What's the food I ordered by DoorDash or Uber Eats mostly?"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;780K email chunks ‚Üí 78MB storage.&lt;/strong&gt; Finally, search your email like you search Google.&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;üìã Click to expand: Email-Specific Arguments&lt;/strong&gt;&lt;/summary&gt; 
 &lt;h4&gt;Parameters&lt;/h4&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;--mail-path PATH         # Path to specific mail directory (auto-detects if omitted)
--include-html          # Include HTML content in processing (useful for newsletters)
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h4&gt;Example Commands&lt;/h4&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# Search work emails from a specific account
python -m apps.email_rag --mail-path "~/Library/Mail/V10/WORK_ACCOUNT"

# Find all receipts and order confirmations (includes HTML)
python -m apps.email_rag --query "receipt order confirmation invoice" --include-html
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;üìã Click to expand: Example queries you can try&lt;/strong&gt;&lt;/summary&gt; 
 &lt;p&gt;Once the index is built, you can ask questions like:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;"Find emails from my boss about deadlines"&lt;/li&gt; 
  &lt;li&gt;"What did John say about the project timeline?"&lt;/li&gt; 
  &lt;li&gt;"Show me emails about travel expenses"&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h3&gt;üîç Time Machine for the Web: RAG Your Entire Chrome Browser History!&lt;/h3&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/yichuan-w/LEANN/main/videos/google_clear.gif" alt="LEANN Browser History Search Demo" width="600" /&gt; &lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python -m apps.browser_rag --query "Tell me my browser history about machine learning?"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;38K browser entries ‚Üí 6MB storage.&lt;/strong&gt; Your browser history becomes your personal search engine.&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;üìã Click to expand: Browser-Specific Arguments&lt;/strong&gt;&lt;/summary&gt; 
 &lt;h4&gt;Parameters&lt;/h4&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;--chrome-profile PATH    # Path to Chrome profile directory (auto-detects if omitted)
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h4&gt;Example Commands&lt;/h4&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# Search academic research from your browsing history
python -m apps.browser_rag --query "arxiv papers machine learning transformer architecture"

# Track competitor analysis across work profile
python -m apps.browser_rag --chrome-profile "~/Library/Application Support/Google/Chrome/Work Profile" --max-items 5000
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;üìã Click to expand: How to find your Chrome profile&lt;/strong&gt;&lt;/summary&gt; 
 &lt;p&gt;The default Chrome profile path is configured for a typical macOS setup. If you need to find your specific Chrome profile:&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;Open Terminal&lt;/li&gt; 
  &lt;li&gt;Run: &lt;code&gt;ls ~/Library/Application\ Support/Google/Chrome/&lt;/code&gt;&lt;/li&gt; 
  &lt;li&gt;Look for folders like "Default", "Profile 1", "Profile 2", etc.&lt;/li&gt; 
  &lt;li&gt;Use the full path as your &lt;code&gt;--chrome-profile&lt;/code&gt; argument&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;p&gt;&lt;strong&gt;Common Chrome profile locations:&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;macOS: &lt;code&gt;~/Library/Application Support/Google/Chrome/Default&lt;/code&gt;&lt;/li&gt; 
  &lt;li&gt;Linux: &lt;code&gt;~/.config/google-chrome/Default&lt;/code&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;üí¨ Click to expand: Example queries you can try&lt;/strong&gt;&lt;/summary&gt; 
 &lt;p&gt;Once the index is built, you can ask questions like:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;"What websites did I visit about machine learning?"&lt;/li&gt; 
  &lt;li&gt;"Find my search history about programming"&lt;/li&gt; 
  &lt;li&gt;"What YouTube videos did I watch recently?"&lt;/li&gt; 
  &lt;li&gt;"Show me websites I visited about travel planning"&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h3&gt;üí¨ WeChat Detective: Unlock Your Golden Memories!&lt;/h3&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/yichuan-w/LEANN/main/videos/wechat_clear.gif" alt="LEANN WeChat Search Demo" width="600" /&gt; &lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python -m apps.wechat_rag --query "Show me all group chats about weekend plans"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;400K messages ‚Üí 64MB storage&lt;/strong&gt; Search years of chat history in any language.&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;üîß Click to expand: Installation Requirements&lt;/strong&gt;&lt;/summary&gt; 
 &lt;p&gt;First, you need to install the &lt;a href="https://github.com/sunnyyoung/WeChatTweak-CLI"&gt;WeChat exporter&lt;/a&gt;,&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;brew install sunnyyoung/repo/wechattweak-cli
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;or install it manually (if you have issues with Homebrew):&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;sudo packages/wechat-exporter/wechattweak-cli install
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;Troubleshooting:&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;Installation issues&lt;/strong&gt;: Check the &lt;a href="https://github.com/sunnyyoung/WeChatTweak-CLI/issues/41"&gt;WeChatTweak-CLI issues page&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Export errors&lt;/strong&gt;: If you encounter the error below, try restarting WeChat &lt;pre&gt;&lt;code class="language-bash"&gt;Failed to export WeChat data. Please ensure WeChat is running and WeChatTweak is installed.
Failed to find or export WeChat data. Exiting.
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;üìã Click to expand: WeChat-Specific Arguments&lt;/strong&gt;&lt;/summary&gt; 
 &lt;h4&gt;Parameters&lt;/h4&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;--export-dir DIR         # Directory to store exported WeChat data (default: wechat_export_direct)
--force-export          # Force re-export even if data exists
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h4&gt;Example Commands&lt;/h4&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# Search for travel plans discussed in group chats
python -m apps.wechat_rag --query "travel plans" --max-items 10000

# Re-export and search recent chats (useful after new messages)
python -m apps.wechat_rag --force-export --query "work schedule"
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;üí¨ Click to expand: Example queries you can try&lt;/strong&gt;&lt;/summary&gt; 
 &lt;p&gt;Once the index is built, you can ask questions like:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;"ÊàëÊÉ≥‰π∞È≠îÊúØÂ∏àÁ∫¶Áø∞ÈÄäÁöÑÁêÉË°£ÔºåÁªôÊàë‰∏Ä‰∫õÂØπÂ∫îËÅäÂ§©ËÆ∞ÂΩï?" (Chinese: Show me chat records about buying Magic Johnson's jersey)&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h3&gt;ü§ñ ChatGPT Chat History: Your Personal AI Conversation Archive!&lt;/h3&gt; 
&lt;p&gt;Transform your ChatGPT conversations into a searchable knowledge base! Search through all your ChatGPT discussions about coding, research, brainstorming, and more.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python -m apps.chatgpt_rag --export-path chatgpt_export.html --query "How do I create a list in Python?"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Unlock your AI conversation history.&lt;/strong&gt; Never lose track of valuable insights from your ChatGPT discussions again.&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;üìã Click to expand: How to Export ChatGPT Data&lt;/strong&gt;&lt;/summary&gt; 
 &lt;p&gt;&lt;strong&gt;Step-by-step export process:&lt;/strong&gt;&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;&lt;strong&gt;Sign in to ChatGPT&lt;/strong&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Click your profile icon&lt;/strong&gt; in the top right corner&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Navigate to Settings&lt;/strong&gt; ‚Üí &lt;strong&gt;Data Controls&lt;/strong&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Click "Export"&lt;/strong&gt; under Export Data&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Confirm the export&lt;/strong&gt; request&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Download the ZIP file&lt;/strong&gt; from the email link (expires in 24 hours)&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Extract or use directly&lt;/strong&gt; with LEANN&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;p&gt;&lt;strong&gt;Supported formats:&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;code&gt;.html&lt;/code&gt; files from ChatGPT exports&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;.zip&lt;/code&gt; archives from ChatGPT&lt;/li&gt; 
  &lt;li&gt;Directories with multiple export files&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;üìã Click to expand: ChatGPT-Specific Arguments&lt;/strong&gt;&lt;/summary&gt; 
 &lt;h4&gt;Parameters&lt;/h4&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;--export-path PATH           # Path to ChatGPT export file (.html/.zip) or directory (default: ./chatgpt_export)
--separate-messages         # Process each message separately instead of concatenated conversations
--chunk-size N              # Text chunk size (default: 512)
--chunk-overlap N           # Overlap between chunks (default: 128)
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h4&gt;Example Commands&lt;/h4&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# Basic usage with HTML export
python -m apps.chatgpt_rag --export-path conversations.html

# Process ZIP archive from ChatGPT
python -m apps.chatgpt_rag --export-path chatgpt_export.zip

# Search with specific query
python -m apps.chatgpt_rag --export-path chatgpt_data.html --query "Python programming help"

# Process individual messages for fine-grained search
python -m apps.chatgpt_rag --separate-messages --export-path chatgpt_export.html

# Process directory containing multiple exports
python -m apps.chatgpt_rag --export-path ./chatgpt_exports/ --max-items 1000
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;üí° Click to expand: Example queries you can try&lt;/strong&gt;&lt;/summary&gt; 
 &lt;p&gt;Once your ChatGPT conversations are indexed, you can search with queries like:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;"What did I ask ChatGPT about Python programming?"&lt;/li&gt; 
  &lt;li&gt;"Show me conversations about machine learning algorithms"&lt;/li&gt; 
  &lt;li&gt;"Find discussions about web development frameworks"&lt;/li&gt; 
  &lt;li&gt;"What coding advice did ChatGPT give me?"&lt;/li&gt; 
  &lt;li&gt;"Search for conversations about debugging techniques"&lt;/li&gt; 
  &lt;li&gt;"Find ChatGPT's recommendations for learning resources"&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h3&gt;ü§ñ Claude Chat History: Your Personal AI Conversation Archive!&lt;/h3&gt; 
&lt;p&gt;Transform your Claude conversations into a searchable knowledge base! Search through all your Claude discussions about coding, research, brainstorming, and more.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python -m apps.claude_rag --export-path claude_export.json --query "What did I ask about Python dictionaries?"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Unlock your AI conversation history.&lt;/strong&gt; Never lose track of valuable insights from your Claude discussions again.&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;üìã Click to expand: How to Export Claude Data&lt;/strong&gt;&lt;/summary&gt; 
 &lt;p&gt;&lt;strong&gt;Step-by-step export process:&lt;/strong&gt;&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;&lt;strong&gt;Open Claude&lt;/strong&gt; in your browser&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Navigate to Settings&lt;/strong&gt; (look for gear icon or settings menu)&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Find Export/Download&lt;/strong&gt; options in your account settings&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Download conversation data&lt;/strong&gt; (usually in JSON format)&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Place the file&lt;/strong&gt; in your project directory&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;p&gt;&lt;em&gt;Note: Claude export methods may vary depending on the interface you're using. Check Claude's help documentation for the most current export instructions.&lt;/em&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Supported formats:&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;code&gt;.json&lt;/code&gt; files (recommended)&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;.zip&lt;/code&gt; archives containing JSON data&lt;/li&gt; 
  &lt;li&gt;Directories with multiple export files&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;üìã Click to expand: Claude-Specific Arguments&lt;/strong&gt;&lt;/summary&gt; 
 &lt;h4&gt;Parameters&lt;/h4&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;--export-path PATH           # Path to Claude export file (.json/.zip) or directory (default: ./claude_export)
--separate-messages         # Process each message separately instead of concatenated conversations
--chunk-size N              # Text chunk size (default: 512)
--chunk-overlap N           # Overlap between chunks (default: 128)
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h4&gt;Example Commands&lt;/h4&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# Basic usage with JSON export
python -m apps.claude_rag --export-path my_claude_conversations.json

# Process ZIP archive from Claude
python -m apps.claude_rag --export-path claude_export.zip

# Search with specific query
python -m apps.claude_rag --export-path claude_data.json --query "machine learning advice"

# Process individual messages for fine-grained search
python -m apps.claude_rag --separate-messages --export-path claude_export.json

# Process directory containing multiple exports
python -m apps.claude_rag --export-path ./claude_exports/ --max-items 1000
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;üí° Click to expand: Example queries you can try&lt;/strong&gt;&lt;/summary&gt; 
 &lt;p&gt;Once your Claude conversations are indexed, you can search with queries like:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;"What did I ask Claude about Python programming?"&lt;/li&gt; 
  &lt;li&gt;"Show me conversations about machine learning algorithms"&lt;/li&gt; 
  &lt;li&gt;"Find discussions about software architecture patterns"&lt;/li&gt; 
  &lt;li&gt;"What debugging advice did Claude give me?"&lt;/li&gt; 
  &lt;li&gt;"Search for conversations about data structures"&lt;/li&gt; 
  &lt;li&gt;"Find Claude's recommendations for learning resources"&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h3&gt;üí¨ iMessage History: Your Personal Conversation Archive!&lt;/h3&gt; 
&lt;p&gt;Transform your iMessage conversations into a searchable knowledge base! Search through all your text messages, group chats, and conversations with friends, family, and colleagues.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python -m apps.imessage_rag --query "What did we discuss about the weekend plans?"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Unlock your message history.&lt;/strong&gt; Never lose track of important conversations, shared links, or memorable moments from your iMessage history.&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;üìã Click to expand: How to Access iMessage Data&lt;/strong&gt;&lt;/summary&gt; 
 &lt;p&gt;&lt;strong&gt;iMessage data location:&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;iMessage conversations are stored in a SQLite database on your Mac at:&lt;/p&gt; 
 &lt;pre&gt;&lt;code&gt;~/Library/Messages/chat.db
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;Important setup requirements:&lt;/strong&gt;&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Grant Full Disk Access&lt;/strong&gt; to your terminal or IDE:&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Open &lt;strong&gt;System Preferences&lt;/strong&gt; ‚Üí &lt;strong&gt;Security &amp;amp; Privacy&lt;/strong&gt; ‚Üí &lt;strong&gt;Privacy&lt;/strong&gt;&lt;/li&gt; 
    &lt;li&gt;Select &lt;strong&gt;Full Disk Access&lt;/strong&gt; from the left sidebar&lt;/li&gt; 
    &lt;li&gt;Click the &lt;strong&gt;+&lt;/strong&gt; button and add your terminal app (Terminal, iTerm2) or IDE (VS Code, etc.)&lt;/li&gt; 
    &lt;li&gt;Restart your terminal/IDE after granting access&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Alternative: Use a backup database&lt;/strong&gt;&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;If you have Time Machine backups or manual copies of the database&lt;/li&gt; 
    &lt;li&gt;Use &lt;code&gt;--db-path&lt;/code&gt; to specify a custom location&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;p&gt;&lt;strong&gt;Supported formats:&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Direct access to &lt;code&gt;~/Library/Messages/chat.db&lt;/code&gt; (default)&lt;/li&gt; 
  &lt;li&gt;Custom database path with &lt;code&gt;--db-path&lt;/code&gt;&lt;/li&gt; 
  &lt;li&gt;Works with backup copies of the database&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;üìã Click to expand: iMessage-Specific Arguments&lt;/strong&gt;&lt;/summary&gt; 
 &lt;h4&gt;Parameters&lt;/h4&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;--db-path PATH                    # Path to chat.db file (default: ~/Library/Messages/chat.db)
--concatenate-conversations       # Group messages by conversation (default: True)
--no-concatenate-conversations    # Process each message individually
--chunk-size N                    # Text chunk size (default: 1000)
--chunk-overlap N                 # Overlap between chunks (default: 200)
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h4&gt;Example Commands&lt;/h4&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# Basic usage (requires Full Disk Access)
python -m apps.imessage_rag

# Search with specific query
python -m apps.imessage_rag --query "family dinner plans"

# Use custom database path
python -m apps.imessage_rag --db-path /path/to/backup/chat.db

# Process individual messages instead of conversations
python -m apps.imessage_rag --no-concatenate-conversations

# Limit processing for testing
python -m apps.imessage_rag --max-items 100 --query "weekend"
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;üí° Click to expand: Example queries you can try&lt;/strong&gt;&lt;/summary&gt; 
 &lt;p&gt;Once your iMessage conversations are indexed, you can search with queries like:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;"What did we discuss about vacation plans?"&lt;/li&gt; 
  &lt;li&gt;"Find messages about restaurant recommendations"&lt;/li&gt; 
  &lt;li&gt;"Show me conversations with John about the project"&lt;/li&gt; 
  &lt;li&gt;"Search for shared links about technology"&lt;/li&gt; 
  &lt;li&gt;"Find group chat discussions about weekend events"&lt;/li&gt; 
  &lt;li&gt;"What did mom say about the family gathering?"&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h3&gt;MCP Integration: RAG on Live Data from Any Platform&lt;/h3&gt; 
&lt;p&gt;Connect to live data sources through the Model Context Protocol (MCP). LEANN now supports real-time RAG on platforms like Slack, Twitter, and more through standardized MCP servers.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Key Benefits:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Live Data Access&lt;/strong&gt;: Fetch real-time data without manual exports&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Standardized Protocol&lt;/strong&gt;: Use any MCP-compatible server&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Easy Extension&lt;/strong&gt;: Add new platforms with minimal code&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Secure Access&lt;/strong&gt;: MCP servers handle authentication&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;üí¨ Slack Messages: Search Your Team Conversations&lt;/h4&gt; 
&lt;p&gt;Transform your Slack workspace into a searchable knowledge base! Find discussions, decisions, and shared knowledge across all your channels.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Test MCP server connection
python -m apps.slack_rag --mcp-server "slack-mcp-server" --test-connection

# Index and search Slack messages
python -m apps.slack_rag \
  --mcp-server "slack-mcp-server" \
  --workspace-name "my-team" \
  --channels general dev-team random \
  --query "What did we decide about the product launch?"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;üìñ Comprehensive Setup Guide&lt;/strong&gt;: For detailed setup instructions, troubleshooting common issues (like "users cache is not ready yet"), and advanced configuration options, see our &lt;a href="https://raw.githubusercontent.com/yichuan-w/LEANN/main/docs/slack-setup-guide.md"&gt;&lt;strong&gt;Slack Setup Guide&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Quick Setup:&lt;/strong&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Install a Slack MCP server (e.g., &lt;code&gt;npm install -g slack-mcp-server&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;Create a Slack App and get API credentials (see detailed guide above)&lt;/li&gt; 
 &lt;li&gt;Set environment variables: &lt;pre&gt;&lt;code class="language-bash"&gt;export SLACK_BOT_TOKEN="xoxb-your-bot-token"
export SLACK_APP_TOKEN="xapp-your-app-token"  # Optional
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;Test connection with &lt;code&gt;--test-connection&lt;/code&gt; flag&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;Arguments:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;--mcp-server&lt;/code&gt;: Command to start the Slack MCP server&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--workspace-name&lt;/code&gt;: Slack workspace name for organization&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--channels&lt;/code&gt;: Specific channels to index (optional)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--concatenate-conversations&lt;/code&gt;: Group messages by channel (default: true)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--max-messages-per-channel&lt;/code&gt;: Limit messages per channel (default: 100)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--max-retries&lt;/code&gt;: Maximum retries for cache sync issues (default: 5)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--retry-delay&lt;/code&gt;: Initial delay between retries in seconds (default: 2.0)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;üê¶ Twitter Bookmarks: Your Personal Tweet Library&lt;/h4&gt; 
&lt;p&gt;Search through your Twitter bookmarks! Find that perfect article, thread, or insight you saved for later.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Test MCP server connection
python -m apps.twitter_rag --mcp-server "twitter-mcp-server" --test-connection

# Index and search Twitter bookmarks
python -m apps.twitter_rag \
  --mcp-server "twitter-mcp-server" \
  --max-bookmarks 1000 \
  --query "What AI articles did I bookmark about machine learning?"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Setup Requirements:&lt;/strong&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Install a Twitter MCP server (e.g., &lt;code&gt;npm install -g twitter-mcp-server&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;Get Twitter API credentials: 
  &lt;ul&gt; 
   &lt;li&gt;Apply for a Twitter Developer Account at &lt;a href="https://developer.twitter.com"&gt;developer.twitter.com&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;Create a new app in the Twitter Developer Portal&lt;/li&gt; 
   &lt;li&gt;Generate API keys and access tokens with "Read" permissions&lt;/li&gt; 
   &lt;li&gt;For bookmarks access, you may need Twitter API v2 with appropriate scopes&lt;/li&gt; 
  &lt;/ul&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;export TWITTER_API_KEY="your-api-key"
export TWITTER_API_SECRET="your-api-secret"
export TWITTER_ACCESS_TOKEN="your-access-token"
export TWITTER_ACCESS_TOKEN_SECRET="your-access-token-secret"
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;Test connection with &lt;code&gt;--test-connection&lt;/code&gt; flag&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;Arguments:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;--mcp-server&lt;/code&gt;: Command to start the Twitter MCP server&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--username&lt;/code&gt;: Filter bookmarks by username (optional)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--max-bookmarks&lt;/code&gt;: Maximum bookmarks to fetch (default: 1000)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--no-tweet-content&lt;/code&gt;: Exclude tweet content, only metadata&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--no-metadata&lt;/code&gt;: Exclude engagement metadata&lt;/li&gt; 
&lt;/ul&gt;  
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;üí° Click to expand: Example queries you can try&lt;/strong&gt;&lt;/summary&gt; 
 &lt;p&gt;&lt;strong&gt;Slack Queries:&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;"What did the team discuss about the project deadline?"&lt;/li&gt; 
  &lt;li&gt;"Find messages about the new feature launch"&lt;/li&gt; 
  &lt;li&gt;"Show me conversations about budget planning"&lt;/li&gt; 
  &lt;li&gt;"What decisions were made in the dev-team channel?"&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;Twitter Queries:&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;"What AI articles did I bookmark last month?"&lt;/li&gt; 
  &lt;li&gt;"Find tweets about machine learning techniques"&lt;/li&gt; 
  &lt;li&gt;"Show me bookmarked threads about startup advice"&lt;/li&gt; 
  &lt;li&gt;"What Python tutorials did I save?"&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;summary&gt;&lt;strong&gt;üîß Using MCP with CLI Commands&lt;/strong&gt;&lt;/summary&gt; 
&lt;p&gt;&lt;strong&gt;Want to use MCP data with regular LEANN CLI?&lt;/strong&gt; You can combine MCP apps with CLI commands:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Step 1: Use MCP app to fetch and index data
python -m apps.slack_rag --mcp-server "slack-mcp-server" --workspace-name "my-team"

# Step 2: The data is now indexed and available via CLI
leann search slack_messages "project deadline"
leann ask slack_messages "What decisions were made about the product launch?"

# Same for Twitter bookmarks
python -m apps.twitter_rag --mcp-server "twitter-mcp-server"
leann search twitter_bookmarks "machine learning articles"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;MCP vs Manual Export:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;MCP&lt;/strong&gt;: Live data, automatic updates, requires server setup&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Manual Export&lt;/strong&gt;: One-time setup, works offline, requires manual data export&lt;/li&gt; 
&lt;/ul&gt;  
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;üîß Adding New MCP Platforms&lt;/strong&gt;&lt;/summary&gt; 
 &lt;p&gt;Want to add support for other platforms? LEANN's MCP integration is designed for easy extension:&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;&lt;strong&gt;Find or create an MCP server&lt;/strong&gt; for your platform&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Create a reader class&lt;/strong&gt; following the pattern in &lt;code&gt;apps/slack_data/slack_mcp_reader.py&lt;/code&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Create a RAG application&lt;/strong&gt; following the pattern in &lt;code&gt;apps/slack_rag.py&lt;/code&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Test and contribute&lt;/strong&gt; back to the community!&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;p&gt;&lt;strong&gt;Popular MCP servers to explore:&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;GitHub repositories and issues&lt;/li&gt; 
  &lt;li&gt;Discord messages&lt;/li&gt; 
  &lt;li&gt;Notion pages&lt;/li&gt; 
  &lt;li&gt;Google Drive documents&lt;/li&gt; 
  &lt;li&gt;And many more in the MCP ecosystem!&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h3&gt;üöÄ Claude Code Integration: Transform Your Development Workflow!&lt;/h3&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;AST‚ÄëAware Code Chunking&lt;/strong&gt;&lt;/summary&gt; 
 &lt;p&gt;LEANN features intelligent code chunking that preserves semantic boundaries (functions, classes, methods) for Python, Java, C#, and TypeScript, improving code understanding compared to text-based chunking.&lt;/p&gt; 
 &lt;p&gt;üìñ Read the &lt;a href="https://raw.githubusercontent.com/yichuan-w/LEANN/main/docs/ast_chunking_guide.md"&gt;AST Chunking Guide ‚Üí&lt;/a&gt;&lt;/p&gt; 
&lt;/details&gt; 
&lt;p&gt;&lt;strong&gt;The future of code assistance is here.&lt;/strong&gt; Transform your development workflow with LEANN's native MCP integration for Claude Code. Index your entire codebase and get intelligent code assistance directly in your IDE.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Key features:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;üîç &lt;strong&gt;Semantic code search&lt;/strong&gt; across your entire project, fully local index and lightweight&lt;/li&gt; 
 &lt;li&gt;üß† &lt;strong&gt;AST-aware chunking&lt;/strong&gt; preserves code structure (functions, classes)&lt;/li&gt; 
 &lt;li&gt;üìö &lt;strong&gt;Context-aware assistance&lt;/strong&gt; for debugging and development&lt;/li&gt; 
 &lt;li&gt;üöÄ &lt;strong&gt;Zero-config setup&lt;/strong&gt; with automatic language detection&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Install LEANN globally for MCP integration
uv tool install leann-core --with leann
claude mcp add --scope user leann-server -- leann_mcp
# Setup is automatic - just start using Claude Code!
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Try our fully agentic pipeline with auto query rewriting, semantic search planning, and more:&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/yichuan-w/LEANN/main/assets/mcp_leann.png" alt="LEANN MCP Integration" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;üî• Ready to supercharge your coding?&lt;/strong&gt; &lt;a href="https://raw.githubusercontent.com/yichuan-w/LEANN/main/packages/leann-mcp/README.md"&gt;Complete Setup Guide ‚Üí&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Command Line Interface&lt;/h2&gt; 
&lt;p&gt;LEANN includes a powerful CLI for document processing and search. Perfect for quick document indexing and interactive chat.&lt;/p&gt; 
&lt;h3&gt;Installation&lt;/h3&gt; 
&lt;p&gt;If you followed the Quick Start, &lt;code&gt;leann&lt;/code&gt; is already installed in your virtual environment:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;source .venv/bin/activate
leann --help
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;To make it globally available:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Install the LEANN CLI globally using uv tool
uv tool install leann-core --with leann


# Now you can use leann from anywhere without activating venv
leann --help
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: Global installation is required for Claude Code integration. The &lt;code&gt;leann_mcp&lt;/code&gt; server depends on the globally available &lt;code&gt;leann&lt;/code&gt; command.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Usage Examples&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# build from a specific directory, and my_docs is the index name(Here you can also build from multiple dict or multiple files)
leann build my-docs --docs ./your_documents

# Search your documents
leann search my-docs "machine learning concepts"

# Interactive chat with your documents
leann ask my-docs --interactive

# Ask a single question (non-interactive)
leann ask my-docs "Where are prompts configured?"

# List all your indexes
leann list

# Remove an index
leann remove my-docs
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Key CLI features:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Auto-detects document formats (PDF, TXT, MD, DOCX, PPTX + code files)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üß† AST-aware chunking&lt;/strong&gt; for Python, Java, C#, TypeScript files&lt;/li&gt; 
 &lt;li&gt;Smart text chunking with overlap for all other content&lt;/li&gt; 
 &lt;li&gt;Multiple LLM providers (Ollama, OpenAI, HuggingFace)&lt;/li&gt; 
 &lt;li&gt;Organized index storage in &lt;code&gt;.leann/indexes/&lt;/code&gt; (project-local)&lt;/li&gt; 
 &lt;li&gt;Support for advanced search parameters&lt;/li&gt; 
&lt;/ul&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;üìã Click to expand: Complete CLI Reference&lt;/strong&gt;&lt;/summary&gt; 
 &lt;p&gt;You can use &lt;code&gt;leann --help&lt;/code&gt;, or &lt;code&gt;leann build --help&lt;/code&gt;, &lt;code&gt;leann search --help&lt;/code&gt;, &lt;code&gt;leann ask --help&lt;/code&gt;, &lt;code&gt;leann list --help&lt;/code&gt;, &lt;code&gt;leann remove --help&lt;/code&gt; to get the complete CLI reference.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Build Command:&lt;/strong&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;leann build INDEX_NAME --docs DIRECTORY|FILE [DIRECTORY|FILE ...] [OPTIONS]

Options:
  --backend {hnsw,diskann}     Backend to use (default: hnsw)
  --embedding-model MODEL      Embedding model (default: facebook/contriever)
  --graph-degree N             Graph degree (default: 32)
  --complexity N               Build complexity (default: 64)
  --force                      Force rebuild existing index
  --compact / --no-compact     Use compact storage (default: true). Must be `no-compact` for `no-recompute` build.
  --recompute / --no-recompute Enable recomputation (default: true)
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;Search Command:&lt;/strong&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;leann search INDEX_NAME QUERY [OPTIONS]

Options:
  --top-k N                     Number of results (default: 5)
  --complexity N                Search complexity (default: 64)
  --recompute / --no-recompute  Enable/disable embedding recomputation (default: enabled). Should not do a `no-recompute` search in a `recompute` build.
  --pruning-strategy {global,local,proportional}
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;Ask Command:&lt;/strong&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;leann ask INDEX_NAME [OPTIONS]

Options:
  --llm {ollama,openai,hf}    LLM provider (default: ollama)
  --model MODEL               Model name (default: qwen3:8b)
  --interactive              Interactive chat mode
  --top-k N                  Retrieval count (default: 20)
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;List Command:&lt;/strong&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;leann list

# Lists all indexes across all projects with status indicators:
# ‚úÖ - Index is complete and ready to use
# ‚ùå - Index is incomplete or corrupted
# üìÅ - CLI-created index (in .leann/indexes/)
# üìÑ - App-created index (*.leann.meta.json files)
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;Remove Command:&lt;/strong&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;leann remove INDEX_NAME [OPTIONS]

Options:
  --force, -f    Force removal without confirmation

# Smart removal: automatically finds and safely removes indexes
# - Shows all matching indexes across projects
# - Requires confirmation for cross-project removal
# - Interactive selection when multiple matches found
# - Supports both CLI and app-created indexes
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h2&gt;üöÄ Advanced Features&lt;/h2&gt; 
&lt;h3&gt;üéØ Metadata Filtering&lt;/h3&gt; 
&lt;p&gt;LEANN supports a simple metadata filtering system to enable sophisticated use cases like document filtering by date/type, code search by file extension, and content management based on custom criteria.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# Add metadata during indexing
builder.add_text(
    "def authenticate_user(token): ...",
    metadata={"file_extension": ".py", "lines_of_code": 25}
)

# Search with filters
results = searcher.search(
    query="authentication function",
    metadata_filters={
        "file_extension": {"==": ".py"},
        "lines_of_code": {"&amp;lt;": 100}
    }
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Supported operators&lt;/strong&gt;: &lt;code&gt;==&lt;/code&gt;, &lt;code&gt;!=&lt;/code&gt;, &lt;code&gt;&amp;lt;&lt;/code&gt;, &lt;code&gt;&amp;lt;=&lt;/code&gt;, &lt;code&gt;&amp;gt;&lt;/code&gt;, &lt;code&gt;&amp;gt;=&lt;/code&gt;, &lt;code&gt;in&lt;/code&gt;, &lt;code&gt;not_in&lt;/code&gt;, &lt;code&gt;contains&lt;/code&gt;, &lt;code&gt;starts_with&lt;/code&gt;, &lt;code&gt;ends_with&lt;/code&gt;, &lt;code&gt;is_true&lt;/code&gt;, &lt;code&gt;is_false&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;üìñ &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/yichuan-w/LEANN/main/docs/metadata_filtering.md"&gt;Complete Metadata filtering guide ‚Üí&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;h3&gt;üîç Grep Search&lt;/h3&gt; 
&lt;p&gt;For exact text matching instead of semantic search, use the &lt;code&gt;use_grep&lt;/code&gt; parameter:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# Exact text search
results = searcher.search("banana‚Äëcrocodile", use_grep=True, top_k=1)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Use cases&lt;/strong&gt;: Finding specific code patterns, error messages, function names, or exact phrases where semantic similarity isn't needed.&lt;/p&gt; 
&lt;p&gt;üìñ &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/yichuan-w/LEANN/main/docs/grep_search.md"&gt;Complete grep search guide ‚Üí&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;üèóÔ∏è Architecture &amp;amp; How It Works&lt;/h2&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/yichuan-w/LEANN/main/assets/arch.png" alt="LEANN Architecture" width="800" /&gt; &lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;The magic:&lt;/strong&gt; Most vector DBs store every single embedding (expensive). LEANN stores a pruned graph structure (cheap) and recomputes embeddings only when needed (fast).&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Core techniques:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Graph-based selective recomputation:&lt;/strong&gt; Only compute embeddings for nodes in the search path&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;High-degree preserving pruning:&lt;/strong&gt; Keep important "hub" nodes while removing redundant connections&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Dynamic batching:&lt;/strong&gt; Efficiently batch embedding computations for GPU utilization&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Two-level search:&lt;/strong&gt; Smart graph traversal that prioritizes promising nodes&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Backends:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;HNSW&lt;/strong&gt; (default): Ideal for most datasets with maximum storage savings through full recomputation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;DiskANN&lt;/strong&gt;: Advanced option with superior search performance, using PQ-based graph traversal with real-time reranking for the best speed-accuracy trade-off&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Benchmarks&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/yichuan-w/LEANN/main/benchmarks/diskann_vs_hnsw_speed_comparison.py"&gt;DiskANN vs HNSW Performance Comparison ‚Üí&lt;/a&gt;&lt;/strong&gt; - Compare search performance between both backends&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/yichuan-w/LEANN/main/benchmarks/compare_faiss_vs_leann.py"&gt;Simple Example: Compare LEANN vs FAISS ‚Üí&lt;/a&gt;&lt;/strong&gt; - See storage savings in action&lt;/p&gt; 
&lt;h3&gt;üìä Storage Comparison&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;System&lt;/th&gt; 
   &lt;th&gt;DPR (2.1M)&lt;/th&gt; 
   &lt;th&gt;Wiki (60M)&lt;/th&gt; 
   &lt;th&gt;Chat (400K)&lt;/th&gt; 
   &lt;th&gt;Email (780K)&lt;/th&gt; 
   &lt;th&gt;Browser (38K)&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Traditional vector database (e.g., FAISS)&lt;/td&gt; 
   &lt;td&gt;3.8 GB&lt;/td&gt; 
   &lt;td&gt;201 GB&lt;/td&gt; 
   &lt;td&gt;1.8 GB&lt;/td&gt; 
   &lt;td&gt;2.4 GB&lt;/td&gt; 
   &lt;td&gt;130 MB&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;LEANN&lt;/td&gt; 
   &lt;td&gt;324 MB&lt;/td&gt; 
   &lt;td&gt;6 GB&lt;/td&gt; 
   &lt;td&gt;64 MB&lt;/td&gt; 
   &lt;td&gt;79 MB&lt;/td&gt; 
   &lt;td&gt;6.4 MB&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Savings&lt;/td&gt; 
   &lt;td&gt;91%&lt;/td&gt; 
   &lt;td&gt;97%&lt;/td&gt; 
   &lt;td&gt;97%&lt;/td&gt; 
   &lt;td&gt;97%&lt;/td&gt; 
   &lt;td&gt;95%&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Reproduce Our Results&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uv run benchmarks/run_evaluation.py    # Will auto-download evaluation data and run benchmarks
uv run benchmarks/run_evaluation.py benchmarks/data/indices/rpj_wiki/rpj_wiki --num-queries 2000    # After downloading data, you can run the benchmark with our biggest index
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The evaluation script downloads data automatically on first run. The last three results were tested with partial personal data, and you can reproduce them with your own data!&lt;/p&gt; 
&lt;h2&gt;üî¨ Paper&lt;/h2&gt; 
&lt;p&gt;If you find Leann useful, please cite:&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://arxiv.org/abs/2506.08276"&gt;LEANN: A Low-Storage Vector Index&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bibtex"&gt;@misc{wang2025leannlowstoragevectorindex,
      title={LEANN: A Low-Storage Vector Index},
      author={Yichuan Wang and Shu Liu and Zhifei Li and Yongji Wu and Ziming Mao and Yilong Zhao and Xiao Yan and Zhiying Xu and Yang Zhou and Ion Stoica and Sewon Min and Matei Zaharia and Joseph E. Gonzalez},
      year={2025},
      eprint={2506.08276},
      archivePrefix={arXiv},
      primaryClass={cs.DB},
      url={https://arxiv.org/abs/2506.08276},
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;‚ú® &lt;a href="https://raw.githubusercontent.com/yichuan-w/LEANN/main/docs/features.md"&gt;Detailed Features ‚Üí&lt;/a&gt;&lt;/h2&gt; 
&lt;h2&gt;ü§ù &lt;a href="https://raw.githubusercontent.com/yichuan-w/LEANN/main/docs/CONTRIBUTING.md"&gt;CONTRIBUTING ‚Üí&lt;/a&gt;&lt;/h2&gt; 
&lt;h2&gt;‚ùì &lt;a href="https://raw.githubusercontent.com/yichuan-w/LEANN/main/docs/faq.md"&gt;FAQ ‚Üí&lt;/a&gt;&lt;/h2&gt; 
&lt;h2&gt;üìà &lt;a href="https://raw.githubusercontent.com/yichuan-w/LEANN/main/docs/roadmap.md"&gt;Roadmap ‚Üí&lt;/a&gt;&lt;/h2&gt; 
&lt;h2&gt;üìÑ License&lt;/h2&gt; 
&lt;p&gt;MIT License - see &lt;a href="https://raw.githubusercontent.com/yichuan-w/LEANN/main/LICENSE"&gt;LICENSE&lt;/a&gt; for details.&lt;/p&gt; 
&lt;h2&gt;üôè Acknowledgments&lt;/h2&gt; 
&lt;p&gt;Core Contributors: &lt;a href="https://yichuan-w.github.io/"&gt;Yichuan Wang&lt;/a&gt; &amp;amp; &lt;a href="https://github.com/andylizf"&gt;Zhifei Li&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Active Contributors: &lt;a href="https://github.com/gabriel-dehan"&gt;Gabriel Dehan&lt;/a&gt;, &lt;a href="https://github.com/ASuresh0524"&gt;Aakash Suresh&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;We welcome more contributors! Feel free to open issues or submit PRs.&lt;/p&gt; 
&lt;p&gt;This work is done at &lt;a href="https://sky.cs.berkeley.edu/"&gt;&lt;strong&gt;Berkeley Sky Computing Lab&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Star History&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://www.star-history.com/#yichuan-w/LEANN&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=yichuan-w/LEANN&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p align="center"&gt; &lt;strong&gt;‚≠ê Star us on GitHub if Leann is useful for your research or applications!&lt;/strong&gt; &lt;/p&gt; 
&lt;p align="center"&gt; Made with ‚ù§Ô∏è by the Leann team &lt;/p&gt; 
&lt;h2&gt;ü§ñ Explore LEANN with AI&lt;/h2&gt; 
&lt;p&gt;LEANN is indexed on &lt;a href="https://deepwiki.com/yichuan-w/LEANN"&gt;DeepWiki&lt;/a&gt;, so you can ask questions to LLMs using Deep Research to explore the codebase and get help to add new features.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>jamwithai/arxiv-paper-curator</title>
      <link>https://github.com/jamwithai/arxiv-paper-curator</link>
      <description>&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;The Mother of AI Project&lt;/h1&gt; 
&lt;h2&gt;Phase 1 RAG Systems: arXiv Paper Curator&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;h3&gt;A Learner-Focused Journey into Production RAG Systems&lt;/h3&gt; 
 &lt;p&gt;Learn to build modern AI systems from the ground up through hands-on implementation&lt;/p&gt; 
 &lt;p&gt;Master the most in-demand AI engineering skills: &lt;strong&gt;RAG (Retrieval-Augmented Generation)&lt;/strong&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p align="center"&gt; &lt;img src="https://img.shields.io/badge/Python-3.12+-blue.svg?sanitize=true" alt="Python Version" /&gt; &lt;img src="https://img.shields.io/badge/FastAPI-0.115+-green.svg?sanitize=true" alt="FastAPI" /&gt; &lt;img src="https://img.shields.io/badge/OpenSearch-2.19-orange.svg?sanitize=true" alt="OpenSearch" /&gt; &lt;img src="https://img.shields.io/badge/Docker-Compose-blue.svg?sanitize=true" alt="Docker" /&gt; &lt;img src="https://img.shields.io/badge/Status-Week%206%20Production%20Ready-brightgreen.svg?sanitize=true" alt="Status" /&gt; &lt;/p&gt; 
&lt;br /&gt; 
&lt;p align="center"&gt; &lt;a href="https://raw.githubusercontent.com/jamwithai/arxiv-paper-curator/main/#-about-this-course"&gt; &lt;img src="https://raw.githubusercontent.com/jamwithai/arxiv-paper-curator/main/static/mother_of_ai_project_rag_architecture.gif" alt="RAG Architecture" width="700" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;h2&gt;üìñ About This Course&lt;/h2&gt; 
&lt;p&gt;This is a &lt;strong&gt;learner-focused project&lt;/strong&gt; where you'll build a complete research assistant system that automatically fetches academic papers, understands their content, and answers your research questions using advanced RAG techniques.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;The arXiv Paper Curator&lt;/strong&gt; will teach you to build a &lt;strong&gt;production-grade RAG system using industry best practices&lt;/strong&gt;. Unlike tutorials that jump straight to vector search, we follow the &lt;strong&gt;professional path&lt;/strong&gt;: master keyword search foundations first, then enhance with vectors for hybrid retrieval.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;üéØ The Professional Difference:&lt;/strong&gt; We build RAG systems the way successful companies do - solid search foundations enhanced with AI, not AI-first approaches that ignore search fundamentals.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;By the end of this course, you'll have your own AI research assistant and the deep technical skills to build production RAG systems for any domain.&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;üéì What You'll Build&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Week 1:&lt;/strong&gt; Complete infrastructure with Docker, FastAPI, PostgreSQL, OpenSearch, and Airflow&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Week 2:&lt;/strong&gt; Automated data pipeline fetching and parsing academic papers from arXiv&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Week 3:&lt;/strong&gt; Production BM25 keyword search with filtering and relevance scoring&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Week 4:&lt;/strong&gt; Intelligent chunking + hybrid search combining keywords with semantic understanding&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Week 5:&lt;/strong&gt; &lt;strong&gt;Complete RAG pipeline with local LLM, streaming responses, and Gradio interface&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Week 6:&lt;/strong&gt; &lt;strong&gt;Production monitoring with Langfuse tracing and Redis caching for optimized performance&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üöÄ Quick Start&lt;/h2&gt; 
&lt;h3&gt;&lt;strong&gt;üìã Prerequisites&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Docker Desktop&lt;/strong&gt; (with Docker Compose)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Python 3.12+&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;UV Package Manager&lt;/strong&gt; (&lt;a href="https://docs.astral.sh/uv/getting-started/installation/"&gt;Install Guide&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;8GB+ RAM&lt;/strong&gt; and &lt;strong&gt;20GB+ free disk space&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;strong&gt;‚ö° Get Started&lt;/strong&gt;&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# 1. Clone and setup
git clone &amp;lt;repository-url&amp;gt;
cd arxiv-paper-curator

# 2. Configure environment (IMPORTANT!)
cp .env.example .env
# The .env file contains all necessary configuration for OpenSearch, 
# arXiv API, and service connections. Defaults work out of the box.
# For Week 4: Add JINA_API_KEY=your_key_here for hybrid search

# 3. Install dependencies
uv sync

# 4. Start all services
docker compose up --build -d

# 5. Verify everything works
curl http://localhost:8000/health
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;&lt;strong&gt;üìö Weekly Learning Path&lt;/strong&gt;&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Week&lt;/th&gt; 
   &lt;th&gt;Topic&lt;/th&gt; 
   &lt;th&gt;Blog Post&lt;/th&gt; 
   &lt;th&gt;Code Release&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Week 0&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;The Mother of AI project - 6 phases&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://jamwithai.substack.com/p/the-mother-of-ai-project"&gt;The Mother of AI project&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Week 1&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Infrastructure Foundation&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://jamwithai.substack.com/p/the-infrastructure-that-powers-rag"&gt;The Infrastructure That Powers RAG Systems&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/jamwithai/arxiv-paper-curator/releases/tag/week1.0"&gt;week1.0&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Week 2&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Data Ingestion Pipeline&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://jamwithai.substack.com/p/bringing-your-rag-system-to-life"&gt;Building Data Ingestion Pipelines for RAG&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/jamwithai/arxiv-paper-curator/releases/tag/week2.0"&gt;week2.0&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Week 3&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;OpenSearch ingestion &amp;amp; BM25 retrieval&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://jamwithai.substack.com/p/the-search-foundation-every-rag-system"&gt;The Search Foundation Every RAG System Needs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/jamwithai/arxiv-paper-curator/releases/tag/week3.0"&gt;week3.0&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Week 4&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Chunking &amp;amp; Hybrid Search&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://jamwithai.substack.com/p/chunking-strategies-and-hybrid-rag"&gt;The Chunking Strategy That Makes Hybrid Search Work&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/jamwithai/arxiv-paper-curator/releases/tag/week4.0"&gt;week4.0&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Week 5&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Complete RAG system&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://jamwithai.substack.com/p/the-complete-rag-system"&gt;The Complete RAG System&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/jamwithai/arxiv-paper-curator/releases/tag/week5.0"&gt;week5.0&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Week 6&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Production monitoring &amp;amp; caching&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://jamwithai.substack.com/p/production-ready-rag-monitoring-and"&gt;Production-ready RAG: Monitoring &amp;amp; Caching&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/jamwithai/arxiv-paper-curator/releases/tag/week6.0"&gt;week6.0&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;üì• Clone a specific week's release:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Clone a specific week's code
git clone --branch &amp;lt;WEEK_TAG&amp;gt; https://github.com/jamwithai/arxiv-paper-curator
cd arxiv-paper-curator
uv sync
docker compose down -v
docker compose up --build -d

# Replace &amp;lt;WEEK_TAG&amp;gt; with: week1.0, week2.0, etc.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;&lt;strong&gt;üìä Access Your Services&lt;/strong&gt;&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Service&lt;/th&gt; 
   &lt;th&gt;URL&lt;/th&gt; 
   &lt;th&gt;Purpose&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;API Documentation&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://localhost:8000/docs"&gt;http://localhost:8000/docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Interactive API testing&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Gradio RAG Interface&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://localhost:7861"&gt;http://localhost:7861&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;User-friendly chat interface&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Langfuse Dashboard&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://localhost:3000"&gt;http://localhost:3000&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;RAG pipeline monitoring &amp;amp; tracing&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Airflow Dashboard&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://localhost:8080"&gt;http://localhost:8080&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Workflow management&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;OpenSearch Dashboards&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://localhost:5601"&gt;http://localhost:5601&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Hybrid search engine UI&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h4&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: Check airflow/simple_auth_manager_passwords.json.generated for Airflow username and password&lt;/h4&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üìö Week 1: Infrastructure Foundation ‚úÖ&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Start here!&lt;/strong&gt; Master the infrastructure that powers modern RAG systems.&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;üéØ Learning Objectives&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Complete infrastructure setup with Docker Compose&lt;/li&gt; 
 &lt;li&gt;FastAPI development with automatic documentation and health checks&lt;/li&gt; 
 &lt;li&gt;PostgreSQL database configuration and management&lt;/li&gt; 
 &lt;li&gt;OpenSearch hybrid search engine setup&lt;/li&gt; 
 &lt;li&gt;Ollama local LLM service configuration&lt;/li&gt; 
 &lt;li&gt;Service orchestration and health monitoring&lt;/li&gt; 
 &lt;li&gt;Professional development environment with code quality tools&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;strong&gt;üèóÔ∏è Architecture Overview&lt;/strong&gt;&lt;/h3&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/jamwithai/arxiv-paper-curator/main/static/week1_infra_setup.png" alt="Week 1 Infrastructure Setup" width="800" /&gt; &lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Infrastructure Components:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;FastAPI&lt;/strong&gt;: REST endpoints with async support (Port 8000)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;PostgreSQL 16&lt;/strong&gt;: Paper metadata storage (Port 5432)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;OpenSearch 2.19&lt;/strong&gt;: Search engine with dashboards (Ports 9200, 5601)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Apache Airflow 3.0&lt;/strong&gt;: Workflow orchestration (Port 8080)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Ollama&lt;/strong&gt;: Local LLM server (Port 11434)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;strong&gt;üìì Setup Guide&lt;/strong&gt;&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Launch the Week 1 notebook
uv run jupyter notebook notebooks/week1/week1_setup.ipynb
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;&lt;strong&gt;‚úÖ Success Criteria&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;Complete when you can:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Start all services with &lt;code&gt;docker compose up -d&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Access API docs at &lt;a href="http://localhost:8000/docs"&gt;http://localhost:8000/docs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Login to Airflow at &lt;a href="http://localhost:8080"&gt;http://localhost:8080&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Browse OpenSearch at &lt;a href="http://localhost:5601"&gt;http://localhost:5601&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; All tests pass: &lt;code&gt;uv run pytest&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;strong&gt;üìñ Deep Dive&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Blog Post:&lt;/strong&gt; &lt;a href="https://jamwithai.substack.com/p/the-infrastructure-that-powers-rag"&gt;The Infrastructure That Powers RAG Systems&lt;/a&gt; - Detailed walkthrough and production insights&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üìö Week 2: Data Ingestion Pipeline ‚úÖ&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Building on Week 1 infrastructure:&lt;/strong&gt; Learn to fetch, process, and store academic papers automatically.&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;üéØ Learning Objectives&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;arXiv API integration with rate limiting and retry logic&lt;/li&gt; 
 &lt;li&gt;Scientific PDF parsing using Docling&lt;/li&gt; 
 &lt;li&gt;Automated data ingestion pipelines with Apache Airflow&lt;/li&gt; 
 &lt;li&gt;Metadata extraction and storage workflows&lt;/li&gt; 
 &lt;li&gt;Complete paper processing from API to database&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;strong&gt;üèóÔ∏è Architecture Overview&lt;/strong&gt;&lt;/h3&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/jamwithai/arxiv-paper-curator/main/static/week2_data_ingestion_flow.png" alt="Week 2 Data Ingestion Architecture" width="800" /&gt; &lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Data Pipeline Components:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;MetadataFetcher&lt;/strong&gt;: üéØ Main orchestrator coordinating the entire pipeline&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ArxivClient&lt;/strong&gt;: Rate-limited paper fetching with retry logic&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;PDFParserService&lt;/strong&gt;: Docling-powered scientific document processing&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Airflow DAGs&lt;/strong&gt;: Automated daily paper ingestion workflows&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;PostgreSQL Storage&lt;/strong&gt;: Structured paper metadata and content&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;strong&gt;üìì Implementation Guide&lt;/strong&gt;&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Launch the Week 2 notebook  
uv run jupyter notebook notebooks/week2/week2_arxiv_integration.ipynb
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;&lt;strong&gt;üíª Code Examples&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;arXiv API Integration:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# Example: Fetch papers with rate limiting
from src.services.arxiv.factory import make_arxiv_client

async def fetch_recent_papers():
    client = make_arxiv_client()
    papers = await client.search_papers(
        query="cat:cs.AI",
        max_results=10,
        from_date="20240801",
        to_date="20240807"
    )
    return papers
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;PDF Processing Pipeline:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# Example: Parse PDF with Docling
from src.services.pdf_parser.factory import make_pdf_parser_service

async def process_paper_pdf(pdf_url: str):
    parser = make_pdf_parser_service()
    parsed_content = await parser.parse_pdf_from_url(pdf_url)
    return parsed_content  # Structured content with text, tables, figures
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Complete Ingestion Workflow:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# Example: Full paper ingestion pipeline
from src.services.metadata_fetcher import make_metadata_fetcher

async def ingest_papers():
    fetcher = make_metadata_fetcher()
    results = await fetcher.fetch_and_store_papers(
        query="cat:cs.AI",
        max_results=5,
        from_date="20240807"
    )
    return results  # Papers stored in database with full content
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;&lt;strong&gt;‚úÖ Success Criteria&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;Complete when you can:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Fetch papers from arXiv API: Test in Week 2 notebook&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Parse PDF content with Docling: View extracted structured content&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Run Airflow DAG: &lt;code&gt;arxiv_paper_ingestion&lt;/code&gt; executes successfully&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Verify database storage: Papers appear in PostgreSQL with full content&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; API endpoints work: &lt;code&gt;/papers&lt;/code&gt; returns stored papers with metadata&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;strong&gt;üìñ Deep Dive&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Blog Post:&lt;/strong&gt; &lt;a href="https://jamwithai.substack.com/p/bringing-your-rag-system-to-life"&gt;Building Data Ingestion Pipelines for RAG&lt;/a&gt; - arXiv API integration and PDF processing&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üìö Week 3: Keyword Search First - The Critical Foundation ‚ö°&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;üö® The 90% Problem:&lt;/strong&gt; Most RAG systems jump straight to vector search and miss the foundation that powers the best retrieval systems. We're doing it right!&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;Building on Weeks 1-2 foundation:&lt;/strong&gt; Implement the keyword search foundation that professional RAG systems rely on.&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;üéØ Why Keyword Search First?&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;The Reality Check:&lt;/strong&gt; Vector search alone is not enough. The most effective RAG systems use &lt;strong&gt;hybrid retrieval&lt;/strong&gt; - combining keyword search (BM25) with vector search. Here's why we start with keywords:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;üîç Exact Match Power:&lt;/strong&gt; Keywords excel at finding specific terms, technical jargon, and precise phrases&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üìä Interpretable Results:&lt;/strong&gt; You can understand exactly why a document was retrieved&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;‚ö° Speed &amp;amp; Efficiency:&lt;/strong&gt; BM25 is computationally fast and doesn't require expensive embedding models&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üéØ Domain Knowledge:&lt;/strong&gt; Technical papers often require exact terminology matches that vector search might miss&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üìà Production Reality:&lt;/strong&gt; Companies like Elasticsearch, Algolia, and enterprise search all use keyword search as their foundation&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;&lt;strong&gt;üèóÔ∏è Week 3 Architecture Overview&lt;/strong&gt;&lt;/h3&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/jamwithai/arxiv-paper-curator/main/static/week3_opensearch_flow.png" alt="Week 3 OpenSearch Flow Architecture" width="800" /&gt; &lt;br /&gt; &lt;em&gt;Complete Week 3 architecture showing the OpenSearch integration flow&lt;/em&gt; &lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Search Infrastructure:&lt;/strong&gt; Master full-text search with OpenSearch before adding vector complexity.&lt;/p&gt; 
&lt;h4&gt;&lt;strong&gt;üéØ Learning Objectives&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Foundation First:&lt;/strong&gt; Why keyword search is essential for RAG systems&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;OpenSearch Mastery:&lt;/strong&gt; Index management, mappings, and search optimization&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;BM25 Algorithm:&lt;/strong&gt; Understanding the math behind effective keyword search&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Query DSL:&lt;/strong&gt; Building complex search queries with filters and boosting&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Search Analytics:&lt;/strong&gt; Measuring search relevance and performance&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Production Patterns:&lt;/strong&gt; How real companies structure their search systems&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;&lt;strong&gt;Key Components&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;src/services/opensearch/&lt;/code&gt;: Professional search service implementation&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;src/routers/search.py&lt;/code&gt;: Search API endpoints with BM25 scoring&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;notebooks/week3/&lt;/code&gt;: Complete OpenSearch integration guide&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Search Quality Metrics:&lt;/strong&gt; Precision, recall, and relevance scoring&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;&lt;strong&gt;üí° The Pedagogical Approach&lt;/strong&gt;&lt;/h4&gt; 
&lt;pre&gt;&lt;code&gt;Week 3: Master keyword search (BM25) ‚Üê YOU ARE HERE
Week 4: Add intelligent chunking strategies  
Week 5: Introduce vector embeddings for hybrid retrieval
Week 6: Optimize the complete hybrid system
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;This progression mirrors how successful companies build search systems - solid foundation first, then enhance with advanced techniques.&lt;/strong&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;üìì Week 3 Implementation Guide&lt;/strong&gt;&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Launch the Week 3 notebook
uv run jupyter notebook notebooks/week3/week3_opensearch.ipynb
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;&lt;strong&gt;üíª Code Examples&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;BM25 Search Implementation:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# Example: Search papers with BM25 scoring
from src.services.opensearch.factory import make_opensearch_client

async def search_papers():
    client = make_opensearch_client()
    results = await client.search_papers(
        query="transformer attention mechanism",
        max_results=10,
        categories=["cs.AI", "cs.LG"]
    )
    return results  # Papers ranked by BM25 relevance
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Search API Usage:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# Example: Use the search endpoint
import httpx

async def query_papers():
    async with httpx.AsyncClient() as client:
        response = await client.post("http://localhost:8000/api/v1/search", json={
            "query": "neural networks optimization",
            "max_results": 5,
            "latest_papers": True
        })
        return response.json()
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;&lt;strong&gt;‚úÖ Success Criteria&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;Complete when you can:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Index papers in OpenSearch: Papers searchable via OpenSearch Dashboards&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Search via API: &lt;code&gt;/search&lt;/code&gt; endpoint returns relevant papers with BM25 scoring&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Filter by categories: Search within specific arXiv categories (cs.AI, cs.LG, etc.)&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Sort by relevance or date: Toggle between BM25 scoring and latest papers&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; View search analytics: Understanding why papers matched your query&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;strong&gt;üìñ Deep Dive&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Blog Post:&lt;/strong&gt; &lt;a href="https://jamwithai.substack.com/p/the-search-foundation-every-rag-system"&gt;The Search Foundation Every RAG System Needs&lt;/a&gt; - Complete BM25 implementation with OpenSearch&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üìö Week 4: Chunking &amp;amp; Hybrid Search - The Semantic Layer üî•&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;üöÄ The Intelligence Upgrade:&lt;/strong&gt; Now we enhance our solid BM25 foundation with semantic understanding through intelligent chunking and hybrid retrieval.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;Building on Week 3 foundation:&lt;/strong&gt; Add the semantic layer that makes search truly intelligent.&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;üéØ Why Chunking + Hybrid Search?&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;The Next Level:&lt;/strong&gt; With solid BM25 search proven, we can now intelligently add semantic capabilities:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;üß© Smart Chunking:&lt;/strong&gt; Break documents into coherent, searchable segments that preserve context&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ü§ñ Semantic Understanding:&lt;/strong&gt; Find relevant content even when users paraphrase or use synonyms&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;‚öñÔ∏è Hybrid Excellence:&lt;/strong&gt; Combine keyword precision with semantic recall using RRF fusion&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üìä Best of Both Worlds:&lt;/strong&gt; Fast exact matching + deep semantic understanding&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üè≠ Production Reality:&lt;/strong&gt; How modern RAG systems actually work in practice&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;&lt;strong&gt;üèóÔ∏è Week 4 Architecture Overview&lt;/strong&gt;&lt;/h3&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/jamwithai/arxiv-paper-curator/main/static/week4_hybrid_opensearch.png" alt="Week 4 Hybrid Search Architecture" width="800" /&gt; &lt;br /&gt; &lt;em&gt;Complete Week 4 hybrid search architecture with chunking, embeddings, and RRF fusion&lt;/em&gt; &lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Hybrid Search Infrastructure:&lt;/strong&gt; Production-grade chunking strategies with unified search supporting BM25, vector, and hybrid modes.&lt;/p&gt; 
&lt;h4&gt;&lt;strong&gt;üéØ Learning Objectives&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Section-Based Chunking:&lt;/strong&gt; Intelligent document segmentation that respects structure&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Production Embeddings:&lt;/strong&gt; Jina AI integration with fallback strategies&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Hybrid Search Mastery:&lt;/strong&gt; RRF fusion combining keyword + semantic retrieval&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Unified API Design:&lt;/strong&gt; Single endpoint supporting multiple search modes&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Performance Analysis:&lt;/strong&gt; Understanding trade-offs between search approaches&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;&lt;strong&gt;Key Components&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;src/services/indexing/text_chunker.py&lt;/code&gt;: Section-aware chunking with overlap strategies&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;src/services/embeddings/&lt;/code&gt;: Production embedding pipeline with Jina AI&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;src/routers/hybrid_search.py&lt;/code&gt;: Unified search API supporting all modes&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;notebooks/week4/&lt;/code&gt;: Complete hybrid search implementation guide&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;strong&gt;üìì Week 4 Implementation Guide&lt;/strong&gt;&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Launch the Week 4 notebook
uv run jupyter notebook notebooks/week4/week4_hybrid_search.ipynb
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;&lt;strong&gt;üíª Code Examples&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Section-Based Chunking:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# Example: Intelligent document chunking
from src.services.indexing.text_chunker import TextChunker

chunker = TextChunker(chunk_size=600, overlap_size=100)
chunks = chunker.chunk_paper(
    title="Attention Mechanisms in Neural Networks",
    abstract="Recent advances in attention...",
    full_text=paper_content,
    sections=parsed_sections  # From Docling PDF parsing
)
# Result: Coherent chunks respecting document structure
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Hybrid Search Implementation:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# Example: Unified search supporting multiple modes
async def search_papers(query: str, use_hybrid: bool = True):
    async with httpx.AsyncClient() as client:
        response = await client.post("http://localhost:8000/api/v1/hybrid-search/", json={
            "query": query,
            "use_hybrid": use_hybrid,  # Auto-generates embeddings
            "size": 10,
            "categories": ["cs.AI"]
        })
        return response.json()
        
# BM25 only: Fast keyword matching (~50ms)
bm25_results = await search_papers("transformer attention", use_hybrid=False)

# Hybrid search: Semantic + keyword understanding (~400ms)  
hybrid_results = await search_papers("how to make models more efficient", use_hybrid=True)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;&lt;strong&gt;‚úÖ Success Criteria&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;Complete when you can:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Chunk documents intelligently: Papers broken into coherent 600-word segments&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Generate embeddings: Jina AI integration working with automatic query embedding&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Hybrid search working: RRF fusion combining BM25 + vector similarity&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Compare search modes: Understand when to use BM25 vs hybrid search&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Production API ready: &lt;code&gt;/hybrid-search&lt;/code&gt; endpoint handling all search types&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;strong&gt;üìä Performance Benchmarks&lt;/strong&gt;&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Search Mode&lt;/th&gt; 
   &lt;th&gt;Speed&lt;/th&gt; 
   &lt;th&gt;Precision@10&lt;/th&gt; 
   &lt;th&gt;Recall@10&lt;/th&gt; 
   &lt;th&gt;Use Case&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;BM25 Only&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;~50ms&lt;/td&gt; 
   &lt;td&gt;0.67&lt;/td&gt; 
   &lt;td&gt;0.71&lt;/td&gt; 
   &lt;td&gt;Exact keywords, author names&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Hybrid (RRF)&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;~400ms&lt;/td&gt; 
   &lt;td&gt;0.84&lt;/td&gt; 
   &lt;td&gt;0.89&lt;/td&gt; 
   &lt;td&gt;Conceptual queries, synonyms&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;&lt;strong&gt;üìñ Deep Dive&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Blog Post:&lt;/strong&gt; &lt;a href="https://raw.githubusercontent.com/jamwithai/arxiv-paper-curator/main/link-to-week4-blog"&gt;The Chunking Strategy That Makes Hybrid Search Work&lt;/a&gt; - Production chunking and RRF fusion implementation&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üìö Week 5: Complete RAG Pipeline with LLM Integration üöÄ&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;üéØ The RAG Completion:&lt;/strong&gt; Transform search results into intelligent answers with local LLM integration and streaming responses.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;Building on Week 4 hybrid search:&lt;/strong&gt; Add the LLM layer that turns search into intelligent conversation.&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;üéØ Why Local LLM + Streaming?&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;The Production Advantage:&lt;/strong&gt; Complete the RAG pipeline with privacy-first, optimized generation:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;üè† Local LLM Control:&lt;/strong&gt; Complete data privacy with Ollama - no external API calls&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;‚ö° 6x Performance Boost:&lt;/strong&gt; Optimized from 120s ‚Üí 15-20s through prompt engineering&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üì° Real-time Streaming:&lt;/strong&gt; Server-Sent Events for immediate user feedback&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üéõÔ∏è User-Friendly Interface:&lt;/strong&gt; Gradio web UI for non-technical users&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üîß Production Ready:&lt;/strong&gt; Clean API design with comprehensive error handling&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;&lt;strong&gt;üèóÔ∏è Week 5 Architecture Overview&lt;/strong&gt;&lt;/h3&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/jamwithai/arxiv-paper-curator/main/static/week5_complete_rag.png" alt="Week 5 Complete RAG System Architecture" width="900" /&gt; &lt;br /&gt; &lt;em&gt;Complete RAG system with LLM generation layer (Ollama), hybrid retrieval pipeline, and Gradio interface&lt;/em&gt; &lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Complete RAG Infrastructure:&lt;/strong&gt; Local LLM generation with optimized prompting, dual API endpoints, and interactive web interface.&lt;/p&gt; 
&lt;h4&gt;&lt;strong&gt;üéØ Learning Objectives&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Local LLM Mastery:&lt;/strong&gt; Ollama service integration with multiple model support&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Performance Optimization:&lt;/strong&gt; 80% prompt reduction, 6x speed improvement techniques&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Streaming Implementation:&lt;/strong&gt; Server-Sent Events for real-time response generation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Dual API Design:&lt;/strong&gt; Standard and streaming endpoints for different use cases&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Interactive UI:&lt;/strong&gt; Gradio interface with advanced parameter controls&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;&lt;strong&gt;Key Components&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;src/routers/ask.py&lt;/code&gt;: Dual RAG endpoints (&lt;code&gt;/api/v1/ask&lt;/code&gt; + &lt;code&gt;/api/v1/stream&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;src/services/ollama/&lt;/code&gt;: LLM client with optimized prompts and 300-word response limits&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;src/services/ollama/prompts/rag_system.txt&lt;/code&gt;: Optimized system prompt for academic papers&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;src/gradio_app.py&lt;/code&gt;: Interactive web interface with real-time streaming support&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;gradio_launcher.py&lt;/code&gt;: Easy-launch script for the web UI (runs on port 7861)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;strong&gt;üìì Week 5 Implementation Guide&lt;/strong&gt;&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Launch the Week 5 notebook
uv run jupyter notebook notebooks/week5/week5_complete_rag_system.ipynb

# Launch Gradio interface
uv run python gradio_launcher.py
# Open http://localhost:7861
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;&lt;strong&gt;üíª Code Examples&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Complete RAG Query:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# Example: Standard RAG endpoint
import httpx

async def ask_question(query: str):
    async with httpx.AsyncClient() as client:
        response = await client.post("http://localhost:8000/api/v1/ask", json={
            "query": query,
            "top_k": 3,
            "use_hybrid": True,
            "model": "llama3.2:1b"
        })
        result = response.json()
        return result["answer"], result["sources"]

# Ask a question
answer, sources = await ask_question("What are transformers in machine learning?")
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Streaming RAG Implementation:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# Example: Real-time streaming responses
import httpx
import json

async def stream_rag_response(query: str):
    async with httpx.AsyncClient() as client:
        async with client.stream("POST", "http://localhost:8000/api/v1/stream", json={
            "query": query,
            "top_k": 3,
            "use_hybrid": True
        }) as response:
            async for line in response.aiter_lines():
                if line.startswith('data: '):
                    data = json.loads(line[6:])
                    if 'chunk' in data:
                        print(data['chunk'], end='', flush=True)
                    elif data.get('done'):
                        break

# Stream an answer in real-time
await stream_rag_response("Explain attention mechanisms")
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;&lt;strong&gt;üîß API Endpoints&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Standard RAG Endpoint:&lt;/strong&gt; &lt;code&gt;/api/v1/ask&lt;/code&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Response Type&lt;/strong&gt;: Complete JSON response&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Use Case&lt;/strong&gt;: Batch processing, API integrations&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Response Time&lt;/strong&gt;: 15-20 seconds&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Streaming RAG Endpoint:&lt;/strong&gt; &lt;code&gt;/api/v1/stream&lt;/code&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Response Type&lt;/strong&gt;: Server-Sent Events (SSE)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Use Case&lt;/strong&gt;: Interactive UIs, real-time feedback&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Time to First Token&lt;/strong&gt;: 2-3 seconds&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Request Format&lt;/strong&gt; (both endpoints):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
    "query": "Your question here",
    "top_k": 3,                    // Number of chunks (1-10)
    "use_hybrid": true,            // Hybrid vs BM25 search
    "model": "llama3.2:1b",        // LLM model to use
    "categories": ["cs.AI"]        // Optional category filter
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;&lt;strong&gt;‚úÖ Success Criteria&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;Complete when you can:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;strong&gt;Standard RAG&lt;/strong&gt;: Get complete answers with sources via &lt;code&gt;/api/v1/ask&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;strong&gt;Streaming RAG&lt;/strong&gt;: See real-time generation via &lt;code&gt;/api/v1/stream&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;strong&gt;Gradio Interface&lt;/strong&gt;: Interactive chat at &lt;a href="http://localhost:7861"&gt;http://localhost:7861&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;strong&gt;Performance&lt;/strong&gt;: 15-20s total response time (6x improvement from baseline)&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;strong&gt;Local LLM&lt;/strong&gt;: Ollama running with llama3.2:1b model&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;strong&gt;Source Attribution&lt;/strong&gt;: Automatic deduplication of paper sources&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;strong&gt;üìä Performance Achievements&lt;/strong&gt;&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Metric&lt;/th&gt; 
   &lt;th&gt;Before&lt;/th&gt; 
   &lt;th&gt;After (Week 5)&lt;/th&gt; 
   &lt;th&gt;Improvement&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Response Time&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;120+ seconds&lt;/td&gt; 
   &lt;td&gt;15-20 seconds&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;6x faster&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Time to First Token&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;N/A&lt;/td&gt; 
   &lt;td&gt;2-3 seconds&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Streaming enabled&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Prompt Efficiency&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;~10KB&lt;/td&gt; 
   &lt;td&gt;~2KB&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;80% reduction&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;User Experience&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;API only&lt;/td&gt; 
   &lt;td&gt;Web interface + streaming&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Production ready&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;Key Optimizations:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Removed redundant metadata (80% prompt size reduction)&lt;/li&gt; 
 &lt;li&gt;300-word response limit for focused answers&lt;/li&gt; 
 &lt;li&gt;Shared code architecture (DRY principles)&lt;/li&gt; 
 &lt;li&gt;Automatic source deduplication&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;strong&gt;üîß Troubleshooting Week 5&lt;/strong&gt;&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Issue&lt;/th&gt; 
   &lt;th&gt;Solution&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;404 on &lt;code&gt;/stream&lt;/code&gt; endpoint&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Rebuild API: &lt;code&gt;docker compose build api &amp;amp;&amp;amp; docker compose restart api&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Slow response times&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Use smaller model (&lt;code&gt;llama3.2:1b&lt;/code&gt;) or reduce &lt;code&gt;top_k&lt;/code&gt; parameter&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Gradio not accessible&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Port changed to 7861: &lt;code&gt;http://localhost:7861&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Ollama connection errors&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Check service: &lt;code&gt;docker exec rag-ollama ollama list&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;No streaming response&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Verify SSE format, check browser network tab&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Out of memory errors&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Increase Docker memory limit to 8GB+&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;Quick Health Check:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Check all services
curl http://localhost:8000/api/v1/health | jq

# Test RAG endpoint
curl -X POST http://localhost:8000/api/v1/ask \
  -H "Content-Type: application/json" \
  -d '{"query": "test", "top_k": 1}'

# Test streaming endpoint
curl -X POST http://localhost:8000/api/v1/stream \
  -H "Content-Type: application/json" \
  -d '{"query": "test", "top_k": 1}' --no-buffer
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;&lt;strong&gt;üìñ Deep Dive&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Blog Post:&lt;/strong&gt; &lt;a href="https://jamwithai.substack.com/p/the-complete-rag-system"&gt;The Complete RAG System&lt;/a&gt; - Complete RAG system with local LLM integration and optimization techniques&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üìö Week 6: Production Monitoring and Caching üöÄ&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;üéØ Production Excellence:&lt;/strong&gt; Transform your RAG system from functional to production-ready with comprehensive monitoring and intelligent caching.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;Building on Week 5 complete RAG system:&lt;/strong&gt; Add observability, performance optimization, and production-grade monitoring.&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;üéØ Why Monitoring + Caching?&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;The Production Reality:&lt;/strong&gt; A working RAG system isn't enough - you need visibility and optimization:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;üìä Complete Observability:&lt;/strong&gt; Trace every step from query to answer with Langfuse&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;‚ö° 150-400x Performance Boost:&lt;/strong&gt; Redis caching serves repeated queries in ~50ms vs 15-20s&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üí∞ Cost Optimization:&lt;/strong&gt; 60%+ cache hit rate eliminates redundant LLM calls&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üîç Performance Insights:&lt;/strong&gt; Real-time dashboards showing bottlenecks and opportunities&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üõ°Ô∏è Production Hardening:&lt;/strong&gt; Health checks, graceful degradation, and monitoring&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;&lt;strong&gt;üèóÔ∏è Week 6 Architecture Overview&lt;/strong&gt;&lt;/h3&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/jamwithai/arxiv-paper-curator/main/static/week6_monitoring_and_caching.png" alt="Week 6 Monitoring &amp;amp; Caching Architecture" width="900" /&gt; &lt;br /&gt; &lt;em&gt;Production RAG system with Langfuse tracing and Redis caching layers&lt;/em&gt; &lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Production Infrastructure:&lt;/strong&gt; Complete observability layer with Langfuse tracking every RAG operation, plus Redis caching for instant response delivery.&lt;/p&gt; 
&lt;h4&gt;&lt;strong&gt;üéØ Learning Objectives&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Langfuse Integration:&lt;/strong&gt; End-to-end RAG pipeline tracing with performance analytics&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Redis Caching Strategy:&lt;/strong&gt; Intelligent cache keys with TTL management and fallback&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Performance Monitoring:&lt;/strong&gt; Real-time dashboards showing latency, costs, and hit rates&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Production Patterns:&lt;/strong&gt; Industry-standard observability and optimization techniques&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Cost Analysis:&lt;/strong&gt; Understanding and optimizing LLM usage and infrastructure costs&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;&lt;strong&gt;Key Components&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;src/services/langfuse/&lt;/code&gt;: Complete tracing integration with RAG-specific metrics&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;src/services/cache/&lt;/code&gt;: Redis client with exact-match caching and graceful fallback&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;src/routers/ask.py&lt;/code&gt;: Updated with integrated tracing and caching middleware&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;docker-compose.yml&lt;/code&gt;: Added Redis service and Langfuse local instance&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;notebooks/week6/&lt;/code&gt;: Complete monitoring and caching implementation guide&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;strong&gt;üìì Week 6 Implementation Guide&lt;/strong&gt;&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Launch the Week 6 notebook
uv run jupyter notebook notebooks/week6/week6_cache_testing.ipynb
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;&lt;strong&gt;üíª Code Examples&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Langfuse Tracing Integration:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# Example: Automatic RAG tracing (already integrated)
# Every request to /api/v1/ask automatically generates:
# - Request-level traces for complete query journey
# - Embedding spans timing query embedding generation
# - Search spans tracking retrieval performance
# - Generation spans monitoring LLM response creation

# Simply configure environment variables and tracing happens automatically
LANGFUSE__PUBLIC_KEY=pk-lf-your-key
LANGFUSE__SECRET_KEY=sk-lf-your-key
LANGFUSE__HOST=http://localhost:3000
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Redis Caching Performance:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# Example: Cache performance testing
import httpx
import time

async def test_cache_performance():
    # First request (cache miss ~15-20s)
    start = time.time()
    response = await httpx.AsyncClient().post("http://localhost:8000/api/v1/ask", json={
        "query": "What are transformers in machine learning?",
        "top_k": 3
    })
    first_time = time.time() - start
    
    # Second identical request (cache hit ~50ms)
    start = time.time()
    response = await httpx.AsyncClient().post("http://localhost:8000/api/v1/ask", json={
        "query": "What are transformers in machine learning?",
        "top_k": 3
    })
    second_time = time.time() - start
    
    print(f"First request: {first_time:.2f}s")
    print(f"Second request: {second_time:.2f}s")
    print(f"Speedup: {first_time/second_time:.0f}x faster")
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;&lt;strong&gt;‚úÖ Success Criteria&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;Complete when you can:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;strong&gt;Langfuse Tracing&lt;/strong&gt;: View complete RAG traces at &lt;a href="http://localhost:3000"&gt;http://localhost:3000&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;strong&gt;Redis Caching&lt;/strong&gt;: Achieve 150-400x speedup for repeated queries&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;strong&gt;Performance Monitoring&lt;/strong&gt;: Real-time dashboards showing latency and costs&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;strong&gt;Cache Analytics&lt;/strong&gt;: 60%+ hit rate for production workloads&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;strong&gt;Production Health&lt;/strong&gt;: All services monitored with graceful degradation&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;strong&gt;üìä Performance Achievements&lt;/strong&gt;&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Metric&lt;/th&gt; 
   &lt;th&gt;Before&lt;/th&gt; 
   &lt;th&gt;After (Week 6)&lt;/th&gt; 
   &lt;th&gt;Improvement&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Average Response Time&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;15-20s&lt;/td&gt; 
   &lt;td&gt;3-5s (mixed workload)&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;3-4x faster&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Cache Hit Responses&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;N/A&lt;/td&gt; 
   &lt;td&gt;50-100ms&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;150-400x faster&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;LLM Token Usage&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;100%&lt;/td&gt; 
   &lt;td&gt;40% (60% cached)&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;60% reduction&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Daily Cost&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;$12&lt;/td&gt; 
   &lt;td&gt;$4.50&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;63% savings&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;System Observability&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;None&lt;/td&gt; 
   &lt;td&gt;Complete tracing&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Full visibility&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;Cache Hit Rate Analysis:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Exact Match Cache&lt;/strong&gt;: 62% hit rate for identical queries&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Performance Impact&lt;/strong&gt;: &amp;lt;2% monitoring overhead&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Cost Savings&lt;/strong&gt;: Eliminates 60% of LLM calls&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;strong&gt;üîß Production Configuration&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Environment Variables:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Langfuse Configuration
LANGFUSE__PUBLIC_KEY=pk-lf-your-public-key
LANGFUSE__SECRET_KEY=sk-lf-your-secret-key
LANGFUSE__HOST=http://localhost:3000
LANGFUSE__ENABLED=true

# Redis Configuration
REDIS__URL=redis://redis:6379/0
REDIS__CACHE_TTL_HOURS=24
REDIS__MAX_CONNECTIONS=10
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Docker Services:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Start all services including Redis and Langfuse
docker compose up --build -d

# Verify Redis connectivity
docker exec rag-redis redis-cli ping
# Should return: PONG

# Check cache statistics
curl "http://localhost:8000/api/v1/health" | jq
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;&lt;strong&gt;üîß Troubleshooting Week 6&lt;/strong&gt;&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Issue&lt;/th&gt; 
   &lt;th&gt;Solution&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;No Langfuse traces&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Verify environment variables and restart API container&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Cache not working&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Check Redis: &lt;code&gt;docker exec rag-redis redis-cli ping&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Slow responses&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Monitor cache hit rate, check system resources&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Langfuse connection errors&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Ensure Langfuse service is running on port 3000&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;High memory usage&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Monitor Redis memory usage, adjust TTL settings&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;Quick Health Check:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Verify all services including monitoring
curl http://localhost:8000/api/v1/health | jq

# Test caching performance
time curl -X POST "http://localhost:8000/api/v1/ask" \
  -H "Content-Type: application/json" \
  -d '{"query": "test", "top_k": 1}'

# Access monitoring dashboards
# Langfuse: http://localhost:3000
# Gradio: http://localhost:7861
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;&lt;strong&gt;üìñ Deep Dive&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Blog Post:&lt;/strong&gt; [Link coming soon] - Production-ready RAG with monitoring and caching&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;‚öôÔ∏è Configuration Management&lt;/h2&gt; 
&lt;h3&gt;&lt;strong&gt;Environment Configuration&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;The project uses a &lt;strong&gt;unified &lt;code&gt;.env&lt;/code&gt; file&lt;/strong&gt; with nested configuration structure to manage settings across all services.&lt;/p&gt; 
&lt;h4&gt;&lt;strong&gt;Configuration Structure&lt;/strong&gt;&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Application Settings
DEBUG=true
ENVIRONMENT=development

# arXiv API (Week 2)
ARXIV__MAX_RESULTS=15
ARXIV__SEARCH_CATEGORY=cs.AI
ARXIV__RATE_LIMIT_DELAY=3.0

# PDF Parser (Week 2)  
PDF_PARSER__MAX_PAGES=30
PDF_PARSER__DO_OCR=false

# OpenSearch (Week 3)
OPENSEARCH__HOST=http://opensearch:9200
OPENSEARCH__INDEX_NAME=arxiv-papers

# Jina AI Embeddings (Week 4)
JINA_API_KEY=your_jina_api_key_here
EMBEDDINGS__MODEL=jina-embeddings-v3
EMBEDDINGS__TASK=retrieval.passage
EMBEDDINGS__DIMENSIONS=1024

# Chunking Configuration (Week 4)
CHUNKING__CHUNK_SIZE=600
CHUNKING__OVERLAP_SIZE=100
CHUNKING__MIN_CHUNK_SIZE=100

# Ollama LLM (Week 5)
OLLAMA_HOST=http://ollama:11434
OLLAMA__DEFAULT_MODEL=llama3.2:1b
OLLAMA__TIMEOUT=120
OLLAMA__MAX_RESPONSE_WORDS=300

# Langfuse Monitoring (Week 6)
LANGFUSE__PUBLIC_KEY=pk-lf-your-public-key
LANGFUSE__SECRET_KEY=sk-lf-your-secret-key
LANGFUSE__HOST=http://localhost:3000
LANGFUSE__ENABLED=true
LANGFUSE__FLUSH_INTERVAL=1.0

# Redis Caching (Week 6)
REDIS__URL=redis://redis:6379/0
REDIS__CACHE_TTL_HOURS=24
REDIS__MAX_CONNECTIONS=10

# Services
OLLAMA_HOST=http://ollama:11434
OLLAMA_MODEL=llama3.2:1b
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;&lt;strong&gt;Key Configuration Variables&lt;/strong&gt;&lt;/h4&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Variable&lt;/th&gt; 
   &lt;th&gt;Default&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;DEBUG&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;true&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Debug mode for development&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;ARXIV__MAX_RESULTS&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;15&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Papers to fetch per API call&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;ARXIV__SEARCH_CATEGORY&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;cs.AI&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;arXiv category to search&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;PDF_PARSER__MAX_PAGES&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;30&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Max pages to process per PDF&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OPENSEARCH__INDEX_NAME&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;arxiv-papers&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;OpenSearch index name&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OPENSEARCH__HOST&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;http://opensearch:9200&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;OpenSearch cluster endpoint&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;JINA_API_KEY&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Required for Week 4&lt;/td&gt; 
   &lt;td&gt;Jina AI API key for embeddings&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;CHUNKING__CHUNK_SIZE&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;600&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Target words per document chunk&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;CHUNKING__OVERLAP_SIZE&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;100&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Overlapping words between chunks&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;EMBEDDINGS__MODEL&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;jina-embeddings-v3&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Jina embeddings model&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OLLAMA_MODEL&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;llama3.2:1b&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Local LLM model&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;LANGFUSE__PUBLIC_KEY&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Required for Week 6&lt;/td&gt; 
   &lt;td&gt;Langfuse public API key&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;LANGFUSE__SECRET_KEY&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Required for Week 6&lt;/td&gt; 
   &lt;td&gt;Langfuse secret API key&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;REDIS__CACHE_TTL_HOURS&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;24&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Cache expiration time in hours&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h4&gt;&lt;strong&gt;Service-Aware Configuration&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;The configuration system automatically detects the service context:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;API Service&lt;/strong&gt;: Uses &lt;code&gt;localhost&lt;/code&gt; for database and service connections&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Airflow Service&lt;/strong&gt;: Uses Docker container hostnames (&lt;code&gt;postgres&lt;/code&gt;, &lt;code&gt;opensearch&lt;/code&gt;)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# Configuration is automatically loaded based on context
from src.config import get_settings

settings = get_settings()  # Auto-detects API vs Airflow
print(f"ArXiv max results: {settings.arxiv.max_results}")
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üîß Reference &amp;amp; Development Guide&lt;/h2&gt; 
&lt;h3&gt;&lt;strong&gt;üõ†Ô∏è Technology Stack&lt;/strong&gt;&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Service&lt;/th&gt; 
   &lt;th&gt;Purpose&lt;/th&gt; 
   &lt;th&gt;Status&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;FastAPI&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;REST API with automatic docs&lt;/td&gt; 
   &lt;td&gt;‚úÖ Ready&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;PostgreSQL 16&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Paper metadata and content storage&lt;/td&gt; 
   &lt;td&gt;‚úÖ Ready&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;OpenSearch 2.19&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Hybrid search engine (BM25 + Vector)&lt;/td&gt; 
   &lt;td&gt;‚úÖ Ready&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Apache Airflow 3.0&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Workflow automation&lt;/td&gt; 
   &lt;td&gt;‚úÖ Ready&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Jina AI&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Embedding generation (Week 4)&lt;/td&gt; 
   &lt;td&gt;‚úÖ Ready&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Ollama&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Local LLM serving (Week 5)&lt;/td&gt; 
   &lt;td&gt;‚úÖ Ready&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Redis&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;High-performance caching (Week 6)&lt;/td&gt; 
   &lt;td&gt;‚úÖ Ready&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Langfuse&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;RAG pipeline observability (Week 6)&lt;/td&gt; 
   &lt;td&gt;‚úÖ Ready&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;Development Tools:&lt;/strong&gt; UV, Ruff, MyPy, Pytest, Docker Compose&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;üèóÔ∏è Project Structure&lt;/strong&gt;&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;arxiv-paper-curator/
‚îú‚îÄ‚îÄ src/                                    # Main application code
‚îÇ   ‚îú‚îÄ‚îÄ main.py                             # FastAPI application
‚îÇ   ‚îú‚îÄ‚îÄ routers/                            # API endpoints
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ping.py                         # Health check endpoints
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ papers.py                       # Paper retrieval endpoints
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ hybrid_search.py                # Week 4: Hybrid search endpoints
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ask.py                          # Week 5: RAG question answering endpoints
‚îÇ   ‚îú‚îÄ‚îÄ models/                             # Database models (SQLAlchemy)
‚îÇ   ‚îú‚îÄ‚îÄ repositories/                       # Data access layer
‚îÇ   ‚îú‚îÄ‚îÄ schemas/                            # Pydantic validation schemas
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ api/                            # API request/response schemas
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ health.py                   # Health check schemas
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ search.py                   # Search request/response schemas
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ask.py                      # Week 5: RAG request/response schemas
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ arxiv/                          # arXiv data schemas
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ pdf_parser/                     # PDF parsing schemas
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ database/                       # Database configuration schemas
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ indexing/                       # Week 4: Chunking schemas
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ embeddings/                     # Week 4: Embedding schemas
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ cache/                          # Week 6: Caching schemas
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ langfuse/                       # Week 6: Monitoring schemas
‚îÇ   ‚îú‚îÄ‚îÄ services/                           # Business logic
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ arxiv/                          # arXiv API client
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ pdf_parser/                     # Docling PDF processing
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ opensearch/                     # OpenSearch integration
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ client.py                   # Unified search client (BM25 + Vector + Hybrid)
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ factory.py                  # Client factory pattern
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ index_config_hybrid.py      # Week 4: Hybrid index configuration
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ query_builder.py            # BM25 query construction
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ indexing/                       # Week 4: Document processing
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ text_chunker.py             # Section-based chunking strategy
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ hybrid_indexer.py           # Document indexing with embeddings
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ factory.py                  # Indexing service factory
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ embeddings/                     # Week 4: Embedding services
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ jina_client.py              # Jina AI embedding service
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ factory.py                  # Embedding service factory
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ollama/                         # Week 5: LLM services
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ client.py                   # Ollama LLM client
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ factory.py                  # LLM service factory
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ prompts/                    # Optimized RAG prompts
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ langfuse/                       # Week 6: Monitoring services
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ client.py                   # Langfuse tracing client
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ tracer.py                   # RAG-specific tracing utilities
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ factory.py                  # Monitoring service factory
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ cache/                          # Week 6: Caching services
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ client.py                   # Redis cache implementation
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ factory.py                  # Cache service factory
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ metadata_fetcher.py             # Complete ingestion pipeline
‚îÇ   ‚îú‚îÄ‚îÄ db/                                 # Database configuration
‚îÇ   ‚îú‚îÄ‚îÄ config.py                           # Environment configuration
‚îÇ   ‚îî‚îÄ‚îÄ dependencies.py                     # Dependency injection
‚îÇ
‚îú‚îÄ‚îÄ notebooks/                              # Learning materials
‚îÇ   ‚îú‚îÄ‚îÄ week1/                              # Week 1: Infrastructure setup
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ week1_setup.ipynb               # Complete setup guide
‚îÇ   ‚îú‚îÄ‚îÄ week2/                              # Week 2: Data ingestion
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ week2_arxiv_integration.ipynb   # Data pipeline guide
‚îÇ   ‚îú‚îÄ‚îÄ week3/                              # Week 3: Keyword search
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ week3_opensearch.ipynb          # OpenSearch &amp;amp; BM25 guide
‚îÇ   ‚îú‚îÄ‚îÄ week4/                              # Week 4: Chunking &amp;amp; hybrid search
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ week4_hybrid_search.ipynb       # Complete hybrid search guide
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ README.md                       # Week 4 implementation documentation
‚îÇ   ‚îú‚îÄ‚îÄ week5/                              # Week 5: Complete RAG system
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ week5_complete_rag_system.ipynb # Complete RAG implementation guide
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ README.md                       # Week 5 implementation documentation
‚îÇ   ‚îî‚îÄ‚îÄ week6/                              # Week 6: Production monitoring &amp;amp; caching
‚îÇ       ‚îú‚îÄ‚îÄ week6_cache_testing.ipynb       # Monitoring and caching guide
‚îÇ       ‚îî‚îÄ‚îÄ README.md                       # Week 6 implementation documentation
‚îÇ
‚îú‚îÄ‚îÄ airflow/                                # Workflow orchestration
‚îÇ   ‚îú‚îÄ‚îÄ dags/                               # Workflow definitions
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ arxiv_ingestion/                # arXiv ingestion modules
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ arxiv_paper_ingestion.py        # Main ingestion DAG
‚îÇ   ‚îî‚îÄ‚îÄ requirements-airflow.txt            # Airflow dependencies
‚îÇ
‚îú‚îÄ‚îÄ gradio_app.py                           # Week 5: Interactive web interface
‚îú‚îÄ‚îÄ gradio_launcher.py                      # Week 5: Easy-launch script for Gradio UI
‚îú‚îÄ‚îÄ tests/                                  # Comprehensive test suite
‚îú‚îÄ‚îÄ static/                                 # Assets (images, GIFs)
‚îî‚îÄ‚îÄ compose.yml                             # Service orchestration
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;&lt;strong&gt;üì° API Endpoints Reference&lt;/strong&gt;&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Endpoint&lt;/th&gt; 
   &lt;th&gt;Method&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Week&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;/health&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;GET&lt;/td&gt; 
   &lt;td&gt;Service health check&lt;/td&gt; 
   &lt;td&gt;Week 1&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;/api/v1/papers&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;GET&lt;/td&gt; 
   &lt;td&gt;List stored papers&lt;/td&gt; 
   &lt;td&gt;Week 2&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;/api/v1/papers/{id}&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;GET&lt;/td&gt; 
   &lt;td&gt;Get specific paper&lt;/td&gt; 
   &lt;td&gt;Week 2&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;/api/v1/search&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;POST&lt;/td&gt; 
   &lt;td&gt;BM25 keyword search&lt;/td&gt; 
   &lt;td&gt;Week 3&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;/api/v1/hybrid-search/&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;POST&lt;/td&gt; 
   &lt;td&gt;Hybrid search (BM25 + Vector)&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Week 4&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;API Documentation:&lt;/strong&gt; Visit &lt;a href="http://localhost:8000/docs"&gt;http://localhost:8000/docs&lt;/a&gt; for interactive API explorer&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;üîß Essential Commands&lt;/strong&gt;&lt;/h3&gt; 
&lt;h4&gt;&lt;strong&gt;Using the Makefile&lt;/strong&gt; (Recommended)&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# View all available commands
make help

# Quick workflow
make start         # Start all services
make health        # Check all services health
make test          # Run tests
make stop          # Stop services
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;&lt;strong&gt;All Available Commands&lt;/strong&gt;&lt;/h4&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Command&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;make start&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Start all services&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;make stop&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Stop all services&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;make restart&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Restart all services&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;make status&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Show service status&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;make logs&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Show service logs&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;make health&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Check all services health&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;make setup&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Install Python dependencies&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;make format&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Format code&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;make lint&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Lint and type check&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;make test&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Run tests&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;make test-cov&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Run tests with coverage&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;make clean&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Clean up everything&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h4&gt;&lt;strong&gt;Direct Commands&lt;/strong&gt; (Alternative)&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# If you prefer using commands directly
docker compose up --build -d    # Start services
docker compose ps               # Check status
docker compose logs            # View logs
uv run pytest                 # Run tests
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;&lt;strong&gt;üéì Target Audience&lt;/strong&gt;&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Who&lt;/th&gt; 
   &lt;th&gt;Why&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;AI/ML Engineers&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Learn production RAG architecture beyond tutorials&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Software Engineers&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Build end-to-end AI applications with best practices&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Data Scientists&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Implement production AI systems using modern tools&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üõ†Ô∏è Troubleshooting&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Common Issues:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Services not starting?&lt;/strong&gt; Wait 2-3 minutes, check &lt;code&gt;docker compose logs&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Port conflicts?&lt;/strong&gt; Stop other services using ports 8000, 8080, 5432, 9200&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Memory issues?&lt;/strong&gt; Increase Docker Desktop memory allocation&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Get Help:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Check the comprehensive Week 1 notebook troubleshooting section&lt;/li&gt; 
 &lt;li&gt;Review service logs: &lt;code&gt;docker compose logs [service-name]&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Complete reset: &lt;code&gt;docker compose down --volumes &amp;amp;&amp;amp; docker compose up --build -d&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üí∞ Cost Structure&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;This course is completely free!&lt;/strong&gt; You'll only need minimal costs for optional services:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Local Development:&lt;/strong&gt; $0 (everything runs locally)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Optional Cloud APIs:&lt;/strong&gt; ~$2-5 for external LLM services (if chosen)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;div align="center"&gt; 
 &lt;h3&gt;üéâ Ready to Start Your AI Engineering Journey?&lt;/h3&gt; 
 &lt;p&gt;&lt;strong&gt;Begin with the Week 1 setup notebook and build your first production RAG system!&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;For learners who want to master modern AI engineering&lt;/em&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Built with love by Jam With AI&lt;/strong&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üìÑ License&lt;/h2&gt; 
&lt;p&gt;MIT License - see &lt;a href="https://raw.githubusercontent.com/jamwithai/arxiv-paper-curator/main/LICENSE"&gt;LICENSE&lt;/a&gt; file for details.&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>