<rss version="2.0">
  <channel>
    <title>GitHub Python Weekly Trending</title>
    <description>Weekly Trending of Python in GitHub</description>
    <pubDate>Tue, 11 Nov 2025 01:48:48 GMT</pubDate>
    <link>http://mshibanami.github.io/GitHubTrendingRSS</link>
    
    <item>
      <title>airweave-ai/airweave</title>
      <link>https://github.com/airweave-ai/airweave</link>
      <description>&lt;p&gt;Context retrieval for AI agents across apps and databases&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="frontend/public/logo-airweave-darkbg.svg" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="frontend/public/logo-airweave-lightbg.svg" /&gt; 
  &lt;img width="837" alt="airweave-lettermark" style="padding-bottom: 12px;" src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/public/logo-airweave-darkbg.svg?sanitize=true" /&gt; 
 &lt;/picture&gt; 
 &lt;h1&gt;Context Retrieval for AI Agents across Apps &amp;amp; Databases&lt;/h1&gt; 
 &lt;p&gt;&lt;a href="https://github.com/airweave-ai/airweave/actions/workflows/ruff.yml"&gt;&lt;img src="https://github.com/airweave-ai/airweave/actions/workflows/ruff.yml/badge.svg?sanitize=true" alt="Ruff" /&gt;&lt;/a&gt; &lt;a href="https://github.com/airweave-ai/airweave/actions/workflows/eslint.yml"&gt;&lt;img src="https://github.com/airweave-ai/airweave/actions/workflows/eslint.yml/badge.svg?sanitize=true" alt="ESLint" /&gt;&lt;/a&gt; &lt;a href="https://github.com/airweave-ai/airweave/actions/workflows/test-public-api.yml"&gt;&lt;img src="https://github.com/airweave-ai/airweave/actions/workflows/test-public-api.yml/badge.svg?sanitize=true" alt="System Tests" /&gt;&lt;/a&gt; &lt;a href="https://pepy.tech/projects/airweave-sdk"&gt;&lt;img src="https://static.pepy.tech/personalized-badge/airweave-sdk?period=total&amp;amp;units=INTERNATIONAL_SYSTEM&amp;amp;left_color=GRAY&amp;amp;right_color=BRIGHTGREEN&amp;amp;left_text=downloads" alt="PyPI Downloads" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/gDuebsWGkn"&gt;&lt;img src="https://img.shields.io/discord/1323415085011701870?label=Discord&amp;amp;logo=discord&amp;amp;logoColor=white&amp;amp;style=flat-square" alt="Discord" /&gt;&lt;/a&gt; &lt;br /&gt;&lt;/p&gt; 
 &lt;div style="padding-top: 16px;"&gt; 
  &lt;a href="https://trendshift.io/repositories/13748" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/13748" alt="airweave-ai%2Fairweave | Trendshift" style="width: 250px; height: 55px; margin-right: 24px;" width="250" height="55" /&gt;&lt;/a&gt;&amp;nbsp;&amp;nbsp;
  &lt;a href="https://www.ycombinator.com/launches/NX7-airweave-let-agents-search-any-app" target="_blank"&gt;&lt;img src="https://www.ycombinator.com/launches/NX7-airweave-let-agents-search-any-app/upvote_embed.svg?sanitize=true" alt="Launch YC: Airweave - Let Agents Search Any App" style="margin-left: 12px;" /&gt;&lt;/a&gt; 
 &lt;/div&gt; 
 &lt;br /&gt; 
 &lt;p&gt;‚≠ê &lt;strong&gt;Help us reach more developers and grow the Airweave community. Star this repo!&lt;/strong&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;What is Airweave?&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://app.airweave.ai/"&gt;Airweave&lt;/a&gt; is a fully open-source context retrieval layer for AI agents across apps and databases. It connects to apps, productivity tools, databases, or document stores and transforms their contents into searchable knowledge bases, accessible through a standardized interface for agents.&lt;/p&gt; 
&lt;p&gt;The search interface is exposed via REST API or MCP. When using MCP, Airweave essentially builds a semantically searchable MCP server. The platform handles everything from auth and extraction to embedding and serving. You can find our documentation &lt;a href="https://docs.airweave.ai/welcome"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;üì∫ Check out a quick demo of Airweave below:&lt;/p&gt; 
&lt;p&gt;
 &lt;video width="100%" src="https://github.com/user-attachments/assets/995e4a36-3f88-4d8e-b401-6ca43db0c7bf" controls&gt;&lt;/video&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/airweave-ai/airweave/tree/main/examples"&gt;&lt;strong&gt;üîó Example notebooks&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Table of Contents&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/airweave-ai/airweave/main/#airweave"&gt;Airweave&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/airweave-ai/airweave/main/#overview"&gt;Overview&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/airweave-ai/airweave/main/#table-of-contents"&gt;Table of Contents&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/airweave-ai/airweave/main/#-quick-start"&gt;üöÄ Quick Start&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/airweave-ai/airweave/main/#-supported-integrations"&gt;üîå Supported Integrations&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/airweave-ai/airweave/main/#-usage"&gt;üíª Usage&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/airweave-ai/airweave/main/#frontend"&gt;Frontend&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/airweave-ai/airweave/main/#api"&gt;API&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/airweave-ai/airweave/main/#-sdks"&gt;üì¶ SDKs&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/airweave-ai/airweave/main/#python"&gt;Python&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/airweave-ai/airweave/main/#typescriptjavascript"&gt;TypeScript/JavaScript&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/airweave-ai/airweave/main/#-key-features"&gt;üîë Key Features&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/airweave-ai/airweave/main/#-tech-stack"&gt;üîß Technology Stack&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/airweave-ai/airweave/main/#-contributing"&gt;üë• Contributing&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/airweave-ai/airweave/main/#-license"&gt;üìÑ License&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/airweave-ai/airweave/main/#-connect"&gt;üîó Connect&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üöÄ Quick Start&lt;/h2&gt; 
&lt;h3&gt;Managed Service: &lt;a href="https://app.airweave.ai/"&gt;Airweave Cloud&lt;/a&gt;&lt;/h3&gt; 
&lt;h3&gt;Self-hosted:&lt;/h3&gt; 
&lt;p&gt;Make sure docker and docker-compose are installed, then...&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# 1. Clone the repository
git clone https://github.com/airweave-ai/airweave.git
cd airweave

# 2. Build and run
chmod +x start.sh
./start.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;That's it! Access the dashboard at &lt;a href="http://localhost:8080"&gt;http://localhost:8080&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üîå Supported Integrations&lt;/h2&gt; 
&lt;!-- START_APP_GRID --&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/airtable.svg?sanitize=true" alt="Airtable" width="50" height="50" style="margin: 8px;" /&gt; &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/asana.svg?sanitize=true" alt="Asana" width="50" height="50" style="margin: 8px;" /&gt; &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/attio.svg?sanitize=true" alt="Attio" width="50" height="50" style="margin: 8px;" /&gt; &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/bitbucket.svg?sanitize=true" alt="Bitbucket" width="50" height="50" style="margin: 8px;" /&gt; &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/box.svg?sanitize=true" alt="Box" width="50" height="50" style="margin: 8px;" /&gt; &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/clickup.svg?sanitize=true" alt="ClickUp" width="50" height="50" style="margin: 8px;" /&gt; &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/confluence.svg?sanitize=true" alt="Confluence" width="50" height="50" style="margin: 8px;" /&gt; &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/ctti.svg?sanitize=true" alt="CTTI" width="50" height="50" style="margin: 8px;" /&gt; &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/dropbox.svg?sanitize=true" alt="Dropbox" width="50" height="50" style="margin: 8px;" /&gt; &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/excel.svg?sanitize=true" alt="Excel" width="50" height="50" style="margin: 8px;" /&gt; &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/github.svg?sanitize=true" alt="Github" width="50" height="50" style="margin: 8px;" /&gt; &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/gitlab.svg?sanitize=true" alt="Gitlab" width="50" height="50" style="margin: 8px;" /&gt; &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/gmail.svg?sanitize=true" alt="Gmail" width="50" height="50" style="margin: 8px;" /&gt; &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/google_calendar.svg?sanitize=true" alt="Google Calendar" width="50" height="50" style="margin: 8px;" /&gt; &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/google_docs.svg?sanitize=true" alt="Google Docs" width="50" height="50" style="margin: 8px;" /&gt; &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/google_drive.svg?sanitize=true" alt="Google Drive" width="50" height="50" style="margin: 8px;" /&gt; &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/google_slides.svg?sanitize=true" alt="Google Slides" width="50" height="50" style="margin: 8px;" /&gt; &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/hubspot.svg?sanitize=true" alt="Hubspot" width="50" height="50" style="margin: 8px;" /&gt; &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/jira.svg?sanitize=true" alt="Jira" width="50" height="50" style="margin: 8px;" /&gt; &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/linear.svg?sanitize=true" alt="Linear" width="50" height="50" style="margin: 8px;" /&gt; &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/monday.svg?sanitize=true" alt="Monday" width="50" height="50" style="margin: 8px;" /&gt; &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/notion.svg?sanitize=true" alt="Notion" width="50" height="50" style="margin: 8px;" /&gt; &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/onedrive.svg?sanitize=true" alt="Onedrive" width="50" height="50" style="margin: 8px;" /&gt; &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/onenote.svg?sanitize=true" alt="OneNote" width="50" height="50" style="margin: 8px;" /&gt; &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/outlook_calendar.svg?sanitize=true" alt="Outlook Calendar" width="50" height="50" style="margin: 8px;" /&gt; &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/outlook_mail.svg?sanitize=true" alt="Outlook Mail" width="50" height="50" style="margin: 8px;" /&gt; &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/postgresql.svg?sanitize=true" alt="Postgresql" width="50" height="50" style="margin: 8px;" /&gt; &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/salesforce.svg?sanitize=true" alt="Salesforce" width="50" height="50" style="margin: 8px;" /&gt; &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/sharepoint.svg?sanitize=true" alt="Sharepoint" width="50" height="50" style="margin: 8px;" /&gt; &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/slack.svg?sanitize=true" alt="Slack" width="50" height="50" style="margin: 8px;" /&gt; &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/stripe.svg?sanitize=true" alt="Stripe" width="50" height="50" style="margin: 8px;" /&gt; &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/teams.svg?sanitize=true" alt="Teams" width="50" height="50" style="margin: 8px;" /&gt; &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/todoist.svg?sanitize=true" alt="Todoist" width="50" height="50" style="margin: 8px;" /&gt; &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/trello.svg?sanitize=true" alt="Trello" width="50" height="50" style="margin: 8px;" /&gt; &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/word.svg?sanitize=true" alt="Word" width="50" height="50" style="margin: 8px;" /&gt; &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/zendesk.svg?sanitize=true" alt="Zendesk" width="50" height="50" style="margin: 8px;" /&gt; &lt;/p&gt; 
&lt;!-- END_APP_GRID --&gt; 
&lt;h2&gt;üíª Usage&lt;/h2&gt; 
&lt;h3&gt;Frontend&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Access the UI at &lt;code&gt;http://localhost:8080&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Connect sources, configure syncs, and query data&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;API&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Swagger docs: &lt;code&gt;http://localhost:8001/docs&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Create connections, trigger syncs, and search data&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üì¶ SDKs&lt;/h2&gt; 
&lt;h3&gt;Python&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install airweave-sdk
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from airweave import AirweaveSDK

# Initialize client
client = AirweaveSDK(
    api_key="YOUR_API_KEY",
    base_url="http://localhost:8001"
)

# Create a collection
collection = client.collections.create(name="My Collection")

# Add a source connection
source = client.source_connections.create(
    name="My Stripe Connection",
    short_name="stripe",
    readable_collection_id=collection.readable_id,
    authentication={
        "credentials": {"api_key": "your_stripe_api_key"}
    }
)

# Semantic search (default)
results = client.collections.search(
    readable_id=collection.readable_id,
    query="Find recent failed payments"
)

# Hybrid search (semantic + keyword)
results = client.collections.search(
    readable_id=collection.readable_id,
    query="customer invoices Q4 2024",
    search_type="hybrid"
)

# With query expansion and reranking
results = client.collections.search(
    readable_id=collection.readable_id,
    query="technical documentation",
    enable_query_expansion=True,
    enable_reranking=True,
    top_k=20
)

# Search with recency bias (prioritize recent results)
results = client.collections.search(
    readable_id=collection.readable_id,
    query="critical bugs",
    recency_bias=0.8,  # 0.0 to 1.0, higher = more recent
    limit=10
)

# Get AI-generated answer instead of raw results
answer = client.collections.search(
    readable_id=collection.readable_id,
    query="What are our customer refund policies?",
    response_type="completion",
    enable_reranking=True
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;TypeScript/JavaScript&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;npm install @airweave/sdk
# or
yarn add @airweave/sdk
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-typescript"&gt;import { AirweaveSDKClient, AirweaveSDKEnvironment } from "@airweave/sdk";

// Initialize client
const client = new AirweaveSDKClient({
    apiKey: "YOUR_API_KEY",
    environment: AirweaveSDKEnvironment.Local
});

// Create a collection
const collection = await client.collections.create({
    name: "My Collection"
});

// Add a source connection
const source = await client.sourceConnections.create({
    name: "My Stripe Connection",
    shortName: "stripe",
    readableCollectionId: collection.readableId,
    authentication: {
        credentials: { apiKey: "your_stripe_api_key" }
    }
});

// Semantic search (default)
const results = await client.collections.search(
    collection.readableId,
    { query: "Find recent failed payments" }
);

// Hybrid search (semantic + keyword)
const hybridResults = await client.collections.search(
    collection.readableId,
    {
        query: "customer invoices Q4 2024",
        searchType: "hybrid"
    }
);

// With query expansion and reranking
const advancedResults = await client.collections.search(
    collection.readableId,
    {
        query: "technical documentation",
        enableQueryExpansion: true,
        enableReranking: true,
        topK: 20
    }
);

// Search with recency bias (prioritize recent results)
const recentResults = await client.collections.search(
    collection.readableId,
    {
        query: "critical bugs",
        recencyBias: 0.8,  // 0.0 to 1.0, higher = more recent
        limit: 10
    }
);

// Get AI-generated answer instead of raw results
const answer = await client.collections.search(
    collection.readableId,
    {
        query: "What are our customer refund policies?",
        responseType: "completion",
        enableReranking: true
    }
);
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;üîë Key Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Data synchronization&lt;/strong&gt; from 30+ sources with minimal config&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Entity extraction&lt;/strong&gt; and transformation pipeline&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Multi-tenant&lt;/strong&gt; architecture with OAuth2&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Incremental updates&lt;/strong&gt; using content hashing&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Semantic search&lt;/strong&gt; for agent queries&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Versioning&lt;/strong&gt; for data changes&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üîß Tech Stack&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Frontend&lt;/strong&gt;: React/TypeScript with ShadCN&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Backend&lt;/strong&gt;: FastAPI (Python)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Databases&lt;/strong&gt;: PostgreSQL (metadata), Qdrant (vectors)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Workers&lt;/strong&gt;: Temporal (workflow orchestration), Redis (pub/sub)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Deployment&lt;/strong&gt;: Docker Compose (dev), Kubernetes (prod)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üë• Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome contributions! Please check &lt;a href="https://github.com/airweave-ai/airweave/raw/main/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; for details.&lt;/p&gt; 
&lt;h2&gt;üìÑ License&lt;/h2&gt; 
&lt;p&gt;Airweave is released under the &lt;a href="https://raw.githubusercontent.com/airweave-ai/airweave/main/LICENSE"&gt;MIT&lt;/a&gt; license.&lt;/p&gt; 
&lt;h2&gt;üîó Connect&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://discord.com/invite/484HY9Ehxt"&gt;Discord&lt;/a&gt;&lt;/strong&gt; - Get help and discuss features&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/airweave-ai/airweave/issues"&gt;GitHub Issues&lt;/a&gt;&lt;/strong&gt; - Report bugs or request features&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://x.com/airweave_ai"&gt;Twitter&lt;/a&gt;&lt;/strong&gt; - Follow for updates&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>usestrix/strix</title>
      <link>https://github.com/usestrix/strix</link>
      <description>&lt;p&gt;‚ú® Open-source AI hackers for your apps üë®üèª‚Äçüíª&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;a href="https://usestrix.com/"&gt; &lt;img src="https://raw.githubusercontent.com/usestrix/strix/main/.github/logo.png" width="150" alt="Strix Logo" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;h1 align="center"&gt; Strix &lt;/h1&gt; 
&lt;h2 align="center"&gt;Open-source AI Hackers to secure your Apps&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://pypi.org/project/strix-agent/"&gt;&lt;img src="https://img.shields.io/pypi/pyversions/strix-agent?color=3776AB" alt="Python" /&gt;&lt;/a&gt; &lt;a href="https://pypi.org/project/strix-agent/"&gt;&lt;img src="https://img.shields.io/pypi/v/strix-agent?color=10b981" alt="PyPI" /&gt;&lt;/a&gt; &lt;a href="https://pepy.tech/projects/strix-agent"&gt;&lt;img src="https://static.pepy.tech/personalized-badge/strix-agent?period=total&amp;amp;units=INTERNATIONAL_SYSTEM&amp;amp;left_color=GREY&amp;amp;right_color=RED&amp;amp;left_text=Downloads" alt="PyPI Downloads" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/usestrix/strix/main/LICENSE"&gt;&lt;img src="https://img.shields.io/badge/license-Apache%202.0-blue.svg?sanitize=true" alt="License" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://github.com/usestrix/strix"&gt;&lt;img src="https://img.shields.io/github/stars/usestrix/strix" alt="GitHub Stars" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/YjKFvEZSdZ"&gt;&lt;img src="https://img.shields.io/badge/Discord-%235865F2.svg?&amp;amp;logo=discord&amp;amp;logoColor=white" alt="Discord" /&gt;&lt;/a&gt; &lt;a href="https://usestrix.com"&gt;&lt;img src="https://img.shields.io/badge/Website-usestrix.com-2d3748.svg?sanitize=true" alt="Website" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://trendshift.io/repositories/15362" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/15362" alt="usestrix%2Fstrix | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span&gt;‚≠ê&lt;/span&gt; &lt;em&gt;Love Strix? Give us a star to help other developers discover it!&lt;/em&gt;&lt;/p&gt; 
&lt;br /&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/usestrix/strix/main/.github/screenshot.png" alt="Strix Demo" width="800" style="border-radius: 16px;" /&gt; 
&lt;/div&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] &lt;strong&gt;New!&lt;/strong&gt; Strix now integrates seamlessly with GitHub Actions and CI/CD pipelines. Automatically scan for vulnerabilities on every pull request and block insecure code before it reaches production!&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!WARNING] Only test systems you own or have permission to test. You are responsible for using Strix ethically and legally.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ü¶â Strix Overview&lt;/h2&gt; 
&lt;p&gt;Strix are autonomous AI agents that act just like real hackers - they run your code dynamically, find vulnerabilities, and validate them through actual proof-of-concepts. Built for developers and security teams who need fast, accurate security testing without the overhead of manual pentesting or the false positives of static analysis tools.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Full hacker toolkit&lt;/strong&gt; out of the box&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Teams of agents&lt;/strong&gt; that collaborate and scale&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Real validation&lt;/strong&gt; with PoCs, not false positives&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Developer‚Äëfirst&lt;/strong&gt; CLI with actionable reports&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Auto‚Äëfix &amp;amp; reporting&lt;/strong&gt; to accelerate remediation&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h3&gt;üéØ Use Cases&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Detect and validate critical vulnerabilities in your applications.&lt;/li&gt; 
 &lt;li&gt;Get penetration tests done in hours, not weeks, with compliance reports.&lt;/li&gt; 
 &lt;li&gt;Automate bug bounty research and generate PoCs for faster reporting.&lt;/li&gt; 
 &lt;li&gt;Run tests in CI/CD to block vulnerabilities before reaching production.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h3&gt;üöÄ Quick Start&lt;/h3&gt; 
&lt;p&gt;Prerequisites:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Docker (running)&lt;/li&gt; 
 &lt;li&gt;Python 3.12+&lt;/li&gt; 
 &lt;li&gt;An LLM provider key (or a local LLM)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Install
pipx install strix-agent

# Configure AI provider
export STRIX_LLM="openai/gpt-5"
export LLM_API_KEY="your-api-key"

# Run security assessment
strix --target ./app-directory
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;First run pulls the sandbox Docker image. Results are saved under &lt;code&gt;agent_runs/&amp;lt;run-name&amp;gt;&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;üèÜ Enterprise Platform&lt;/h3&gt; 
&lt;p&gt;Want to skip the setup? Try our cloud-hosted version: &lt;strong&gt;&lt;a href="https://usestrix.com"&gt;usestrix.com&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Our managed platform provides:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;üìà Executive Dashboards&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üß† Custom Fine-Tuned Models&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;‚öôÔ∏è CI/CD Integration&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üîç Large-Scale Scanning&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üîå Third-Party Integrations&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üéØ Enterprise Support&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://usestrix.com"&gt;&lt;strong&gt;Get Enterprise Demo ‚Üí&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;‚ú® Features&lt;/h2&gt; 
&lt;h3&gt;üõ†Ô∏è Agentic Security Tools&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;üîå Full HTTP Proxy&lt;/strong&gt; - Full request/response manipulation and analysis&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üåê Browser Automation&lt;/strong&gt; - Multi-tab browser for testing of XSS, CSRF, auth flows&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üíª Terminal Environments&lt;/strong&gt; - Interactive shells for command execution and testing&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üêç Python Runtime&lt;/strong&gt; - Custom exploit development and validation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üîç Reconnaissance&lt;/strong&gt; - Automated OSINT and attack surface mapping&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üìÅ Code Analysis&lt;/strong&gt; - Static and dynamic analysis capabilities&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üìù Knowledge Management&lt;/strong&gt; - Structured findings and attack documentation&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üéØ Comprehensive Vulnerability Detection&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Access Control&lt;/strong&gt; - IDOR, privilege escalation, auth bypass&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Injection Attacks&lt;/strong&gt; - SQL, NoSQL, command injection&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Server-Side&lt;/strong&gt; - SSRF, XXE, deserialization flaws&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Client-Side&lt;/strong&gt; - XSS, prototype pollution, DOM vulnerabilities&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Business Logic&lt;/strong&gt; - Race conditions, workflow manipulation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Authentication&lt;/strong&gt; - JWT vulnerabilities, session management&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Infrastructure&lt;/strong&gt; - Misconfigurations, exposed services&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üï∏Ô∏è Graph of Agents&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Distributed Workflows&lt;/strong&gt; - Specialized agents for different attacks and assets&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Scalable Testing&lt;/strong&gt; - Parallel execution for fast comprehensive coverage&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Dynamic Coordination&lt;/strong&gt; - Agents collaborate and share discoveries&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üíª Usage Examples&lt;/h2&gt; 
&lt;h3&gt;Default Usage&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Local codebase analysis
strix --target ./app-directory

# Repository security review
strix --target https://github.com/org/repo

# Black-Box Web application assessment
strix --target https://your-app.com

# Grey-Box Security Assesment
strix --target https://your-app.com --instructions "Perform authenticated testing using the following credentials user:pass"

# Multi-target white-box testing (source code + deployed app)
strix -t https://github.com/org/app -t https://your-app.com

# Focused testing with instructions
strix --target api.your-app.com --instruction "Focus on business logic flaws and IDOR vulnerabilities"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;ü§ñ Headless Mode&lt;/h3&gt; 
&lt;p&gt;Run Strix programmatically without interactive UI using the &lt;code&gt;-n/--non-interactive&lt;/code&gt; flag‚Äîperfect for servers and automated jobs. The CLI prints real-time vulnerability findings, and the final report before exiting. Exits with non-zero code when vulnerabilities are found.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;strix -n --target https://your-app.com
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;üîÑ CI/CD (GitHub Actions)&lt;/h3&gt; 
&lt;p&gt;Strix can be added to your pipeline to run a security test on pull requests with a lightweight GitHub Actions workflow:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;name: strix-penetration-test

on:
  pull_request:

jobs:
  security-scan:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Install Strix
        run: pipx install strix-agent

      - name: Run Strix
        env:
          STRIX_LLM: ${{ secrets.STRIX_LLM }}
          LLM_API_KEY: ${{ secrets.LLM_API_KEY }}

        run: strix -n -t ./
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;‚öôÔ∏è Configuration&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;export STRIX_LLM="openai/gpt-5"
export LLM_API_KEY="your-api-key"

# Optional
export LLM_API_BASE="your-api-base-url"  # if using a local model, e.g. Ollama, LMStudio
export PERPLEXITY_API_KEY="your-api-key"  # for search capabilities
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;a href="https://docs.litellm.ai/docs/providers"&gt;üìö View supported AI models&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;ü§ù Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome contributions from the community! There are several ways to contribute:&lt;/p&gt; 
&lt;h3&gt;Code Contributions&lt;/h3&gt; 
&lt;p&gt;See our &lt;a href="https://raw.githubusercontent.com/usestrix/strix/main/CONTRIBUTING.md"&gt;Contributing Guide&lt;/a&gt; for details on:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Setting up your development environment&lt;/li&gt; 
 &lt;li&gt;Running tests and quality checks&lt;/li&gt; 
 &lt;li&gt;Submitting pull requests&lt;/li&gt; 
 &lt;li&gt;Code style guidelines&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Prompt Modules Collection&lt;/h3&gt; 
&lt;p&gt;Help expand our collection of specialized prompt modules for AI agents:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Advanced testing techniques for vulnerabilities, frameworks, and technologies&lt;/li&gt; 
 &lt;li&gt;See &lt;a href="https://raw.githubusercontent.com/usestrix/strix/main/strix/prompts/README.md"&gt;Prompt Modules Documentation&lt;/a&gt; for guidelines&lt;/li&gt; 
 &lt;li&gt;Submit via &lt;a href="https://github.com/usestrix/strix/pulls"&gt;pull requests&lt;/a&gt; or &lt;a href="https://github.com/usestrix/strix/issues"&gt;issues&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üë• Join Our Community&lt;/h2&gt; 
&lt;p&gt;Have questions? Found a bug? Want to contribute? &lt;strong&gt;&lt;a href="https://discord.gg/YjKFvEZSdZ"&gt;Join our Discord!&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;üåü Support the Project&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Love Strix?&lt;/strong&gt; Give us a ‚≠ê on GitHub!&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://api.star-history.com/svg?repos=usestrix/strix&amp;amp;type=date&amp;amp;legend=top-left" alt="Star History Chart" width="800" style="border-radius: 16px;" /&gt; 
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>kvcache-ai/ktransformers</title>
      <link>https://github.com/kvcache-ai/ktransformers</link>
      <description>&lt;p&gt;A Flexible Framework for Experiencing Cutting-edge LLM Inference Optimizations&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;p align="center"&gt; 
  &lt;picture&gt; 
   &lt;img alt="KTransformers" src="https://github.com/user-attachments/assets/d5a2492f-a415-4456-af99-4ab102f13f8b" width="50%" /&gt; 
  &lt;/picture&gt; &lt;/p&gt; 
 &lt;h3&gt;A Flexible Framework for Experiencing Cutting-edge LLM Inference/Fine-tune Optimizations&lt;/h3&gt; 
 &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/#-overview"&gt;üéØ Overview&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/#-kt-kernel---high-performance-inference-kernels"&gt;üöÄ kt-kernel&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/#-kt-sft---fine-tuning-framework"&gt;üéì KT-SFT&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/#-citation"&gt;üî• Citation&lt;/a&gt; | &lt;a href="https://github.com/kvcache-ai/ktransformers/discussions"&gt;üí¨ Discussion&lt;/a&gt; | &lt;a href="https://github.com/kvcache-ai/ktransformers/issues/1582"&gt;üöÄ Roadmap(2025Q4)&lt;/a&gt; &lt;/strong&gt; 
&lt;/div&gt; 
&lt;h2&gt;üéØ Overview&lt;/h2&gt; 
&lt;p&gt;KTransformers is a research project focused on efficient inference and fine-tuning of large language models through CPU-GPU heterogeneous computing. The project has evolved into &lt;strong&gt;two core modules&lt;/strong&gt;: &lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/kt-kernel/"&gt;kt-kernel&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/KT-SFT/"&gt;KT-SFT&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;üî• Updates&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Nov 6, 2025&lt;/strong&gt;: Support Kimi-K2-Thinking inference (&lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/doc/en/Kimi-K2-Thinking.md"&gt;Tutorial&lt;/a&gt;) and fine-tune (&lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/doc/en/SFT_Installation_Guide_KimiK2.md"&gt;Tutorial&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Nov 4, 2025&lt;/strong&gt;: KTransformers Fine-Tuning √ó LLaMA-Factory Integration. (&lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/doc/en/KTransformers-Fine-Tuning_User-Guide.md"&gt;Tutorial&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Oct 27, 2025&lt;/strong&gt;: Support Ascend NPU. (&lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/doc/zh/DeepseekR1_V3_tutorial_zh_for_Ascend_NPU.md"&gt;Tutorial&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Oct 10, 2025&lt;/strong&gt;: Integrating into SGLang. (&lt;a href="https://github.com/sgl-project/sglang/issues/11425"&gt;Roadmap&lt;/a&gt;, &lt;a href="https://lmsys.org/blog/2025-10-22-KTransformers/"&gt;Blog&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Sept 11, 2025&lt;/strong&gt;: Support Qwen3-Next. (&lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/doc/en/Qwen3-Next.md"&gt;Tutorial&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Sept 05, 2025&lt;/strong&gt;: Support Kimi-K2-0905. (&lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/doc/en/Kimi-K2.md"&gt;Tutorial&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;July 26, 2025&lt;/strong&gt;: Support SmallThinker and GLM4-MoE. (&lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/doc/en/SmallThinker_and_Glm4moe.md"&gt;Tutorial&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;July 11, 2025&lt;/strong&gt;: Support Kimi-K2. (&lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/doc/en/Kimi-K2.md"&gt;Tutorial&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;June 30, 2025&lt;/strong&gt;: Support 3-layer (GPU-CPU-Disk) &lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/doc/en/prefix_cache.md"&gt;prefix cache&lt;/a&gt; reuse.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;May 14, 2025&lt;/strong&gt;: Support Intel Arc GPU (&lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/doc/en/xpu.md"&gt;Tutorial&lt;/a&gt;).&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Apr 29, 2025&lt;/strong&gt;: Support AMX-Int8„ÄÅ AMX-BF16 and Qwen3MoE (&lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/doc/en/AMX.md"&gt;Tutorial&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Apr 9, 2025&lt;/strong&gt;: Experimental support for LLaMA 4 models (&lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/doc/en/llama4.md"&gt;Tutorial&lt;/a&gt;).&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Apr 2, 2025&lt;/strong&gt;: Support Multi-concurrency. (&lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/doc/en/balance-serve.md"&gt;Tutorial&lt;/a&gt;).&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Mar 15, 2025&lt;/strong&gt;: Support ROCm on AMD GPU (&lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/doc/en/ROCm.md"&gt;Tutorial&lt;/a&gt;).&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Mar 5, 2025&lt;/strong&gt;: Support unsloth 1.58/2.51 bits weights and &lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/doc/en/fp8_kernel.md"&gt;IQ1_S/FP8 hybrid&lt;/a&gt; weights. Support 139K &lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/doc/en/DeepseekR1_V3_tutorial.md#v022--v023-longer-context--fp8-kernel"&gt;Longer Context&lt;/a&gt; for DeepSeek-V3 and R1 in 24GB VRAM.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Feb 25, 2025&lt;/strong&gt;: Support &lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/doc/en/fp8_kernel.md"&gt;FP8 GPU kernel&lt;/a&gt; for DeepSeek-V3 and R1; &lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/doc/en/DeepseekR1_V3_tutorial.md#v022-longer-context"&gt;Longer Context&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Feb 15, 2025&lt;/strong&gt;: Longer Context (from 4K to 8K for 24GB VRAM) &amp;amp; Slightly Faster Speed Ôºà+15%, up to 16 Tokens/s), update &lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/doc/en/DeepseekR1_V3_tutorial.md"&gt;docs&lt;/a&gt; and &lt;a href="https://kvcache-ai.github.io/ktransformers/"&gt;online books&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Feb 10, 2025&lt;/strong&gt;: Support Deepseek-R1 and V3 on single (24GB VRAM)/multi gpu and 382G DRAM, up to 3~28x speedup. For detailed show case and reproduction tutorial, see &lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/doc/en/DeepseekR1_V3_tutorial.md"&gt;here&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Aug 28, 2024&lt;/strong&gt;: Decrease DeepseekV2's required VRAM from 21G to 11G.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Aug 15, 2024&lt;/strong&gt;: Update detailed &lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/doc/en/injection_tutorial.md"&gt;tutorial&lt;/a&gt; for injection and multi-GPU.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Aug 14, 2024&lt;/strong&gt;: Support llamfile as linear backend.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Aug 12, 2024&lt;/strong&gt;: Support multiple GPU; Support new model: mixtral 8*7B and 8*22B; Support q2k, q3k, q5k dequant on gpu.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Aug 9, 2024&lt;/strong&gt;: Support windows native.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üì¶ Core Modules&lt;/h2&gt; 
&lt;h3&gt;üöÄ &lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/kt-kernel/"&gt;kt-kernel&lt;/a&gt; - High-Performance Inference Kernels&lt;/h3&gt; 
&lt;p&gt;CPU-optimized kernel operations for heterogeneous LLM inference.&lt;/p&gt; 
&lt;img width="1049" height="593" alt="image" src="https://github.com/user-attachments/assets/68f423da-3f55-4025-bdc9-9ceaa554f00b" /&gt; 
&lt;p&gt;&lt;strong&gt;Key Features:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;AMX/AVX Acceleration&lt;/strong&gt;: Intel AMX and AVX512/AVX2 optimized kernels for INT4/INT8 quantized inference&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;MoE Optimization&lt;/strong&gt;: Efficient Mixture-of-Experts inference with NUMA-aware memory management&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Quantization Support&lt;/strong&gt;: CPU-side INT4/INT8 quantized weights, GPU-side GPTQ support&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Easy Integration&lt;/strong&gt;: Clean Python API for SGLang and other frameworks&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Quick Start:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd kt-kernel
pip install .
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Use Cases:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;CPU-GPU hybrid inference for large MoE models&lt;/li&gt; 
 &lt;li&gt;Integration with SGLang for production serving&lt;/li&gt; 
 &lt;li&gt;Heterogeneous expert placement (hot experts on GPU, cold experts on CPU)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Performance Examples:&lt;/strong&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Model&lt;/th&gt; 
   &lt;th&gt;Hardware Configuration&lt;/th&gt; 
   &lt;th&gt;Total Throughput&lt;/th&gt; 
   &lt;th&gt;Output Throughput&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;DeepSeek-R1-0528 (FP8)&lt;/td&gt; 
   &lt;td&gt;8√óL20 GPU + Xeon Gold 6454S&lt;/td&gt; 
   &lt;td&gt;227.85 tokens/s&lt;/td&gt; 
   &lt;td&gt;87.58 tokens/s (8-way concurrency)&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;üëâ &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/kt-kernel/README.md"&gt;Full Documentation ‚Üí&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h3&gt;üéì &lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/KT-SFT/"&gt;KT-SFT&lt;/a&gt; - Fine-Tuning Framework&lt;/h3&gt; 
&lt;p&gt;KTransformers √ó LLaMA-Factory integration for ultra-large MoE model fine-tuning.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/doc/assets/image-20251011010558909.png" alt="image-20251011010558909" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Key Features:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Resource Efficient&lt;/strong&gt;: Fine-tune 671B DeepSeek-V3 with just &lt;strong&gt;70GB GPU memory&lt;/strong&gt; + 1.3TB RAM&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;LoRA Support&lt;/strong&gt;: Full LoRA fine-tuning with heterogeneous acceleration&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;LLaMA-Factory Integration&lt;/strong&gt;: Seamless integration with popular fine-tuning framework&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Production Ready&lt;/strong&gt;: Chat, batch inference, and metrics evaluation&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Performance Examples:&lt;/strong&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Model&lt;/th&gt; 
   &lt;th&gt;Configuration&lt;/th&gt; 
   &lt;th&gt;Throughput&lt;/th&gt; 
   &lt;th&gt;GPU Memory&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;DeepSeek-V3 (671B)&lt;/td&gt; 
   &lt;td&gt;LoRA + AMX&lt;/td&gt; 
   &lt;td&gt;~40 tokens/s&lt;/td&gt; 
   &lt;td&gt;70GB (multi-GPU)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;DeepSeek-V2-Lite (14B)&lt;/td&gt; 
   &lt;td&gt;LoRA + AMX&lt;/td&gt; 
   &lt;td&gt;~530 tokens/s&lt;/td&gt; 
   &lt;td&gt;6GB&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;Quick Start:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd KT-SFT
# Install environment following KT-SFT/README.md
USE_KT=1 llamafactory-cli train examples/train_lora/deepseek3_lora_sft_kt.yaml
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;üëâ &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/KT-SFT/README.md"&gt;Full Documentation ‚Üí&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üî• Citation&lt;/h2&gt; 
&lt;p&gt;If you use KTransformers in your research, please cite our paper:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bibtex"&gt;@inproceedings{10.1145/3731569.3764843,
  title = {KTransformers: Unleashing the Full Potential of CPU/GPU Hybrid Inference for MoE Models},
  author = {Chen, Hongtao and Xie, Weiyu and Zhang, Boxin and Tang, Jingqi and Wang, Jiahao and Dong, Jianwei and Chen, Shaoyuan and Yuan, Ziwei and Lin, Chen and Qiu, Chengyu and Zhu, Yuening and Ou, Qingliang and Liao, Jiaqi and Chen, Xianglin and Ai, Zhiyuan and Wu, Yongwei and Zhang, Mingxing},
  booktitle = {Proceedings of the ACM SIGOPS 31st Symposium on Operating Systems Principles},
  year = {2025}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;üë• Contributors &amp;amp; Team&lt;/h2&gt; 
&lt;p&gt;Developed and maintained by:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://madsys.cs.tsinghua.edu.cn/"&gt;MADSys Lab&lt;/a&gt; @ Tsinghua University&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://approaching.ai/"&gt;Approaching.AI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Community contributors&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;We welcome contributions! Please feel free to submit issues and pull requests.&lt;/p&gt; 
&lt;h2&gt;üí¨ Community &amp;amp; Support&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;GitHub Issues&lt;/strong&gt;: &lt;a href="https://github.com/kvcache-ai/ktransformers/issues"&gt;Report bugs or request features&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;GitHub Discussions&lt;/strong&gt;: &lt;a href="https://github.com/kvcache-ai/ktransformers/discussions"&gt;Ask questions and share ideas&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;WeChat Group&lt;/strong&gt;: See &lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/archive/WeChatGroup.png"&gt;archive/WeChatGroup.png&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üì¶ KT original Code&lt;/h2&gt; 
&lt;p&gt;The original integrated KTransformers framework has been archived to the &lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/archive/"&gt;&lt;code&gt;archive/&lt;/code&gt;&lt;/a&gt; directory for reference. The project now focuses on the two core modules above for better modularity and maintainability.&lt;/p&gt; 
&lt;p&gt;For the original documentation with full quick-start guides and examples, see:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/archive/README.md"&gt;archive/README.md&lt;/a&gt; (English)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/archive/README_ZH.md"&gt;archive/README_ZH.md&lt;/a&gt; (‰∏≠Êñá)&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>lzhoang2801/OpCore-Simplify</title>
      <link>https://github.com/lzhoang2801/OpCore-Simplify</link>
      <description>&lt;p&gt;A tool designed to simplify the creation of OpenCore EFI&lt;/p&gt;&lt;hr&gt;&lt;br /&gt; 
&lt;div align="center"&gt; 
 &lt;h3 align="center"&gt;OpCore Simplify&lt;/h3&gt; 
 &lt;p align="center"&gt; A specialized tool that streamlines &lt;a href="https://github.com/acidanthera/OpenCorePkg"&gt;OpenCore&lt;/a&gt; EFI creation by automating the essential setup process and providing standardized configurations. Designed to reduce manual effort while ensuring accuracy in your Hackintosh journey. &lt;br /&gt; &lt;br /&gt; &lt;a href="https://raw.githubusercontent.com/lzhoang2801/OpCore-Simplify/main/#-features"&gt;Features&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/lzhoang2801/OpCore-Simplify/main/#-how-to-use"&gt;How To Use&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/lzhoang2801/OpCore-Simplify/main/#-contributing"&gt;Contributing&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/lzhoang2801/OpCore-Simplify/main/#-license"&gt;License&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/lzhoang2801/OpCore-Simplify/main/#-credits"&gt;Credits&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/lzhoang2801/OpCore-Simplify/main/#-contact"&gt;Contact&lt;/a&gt; &lt;/p&gt; 
&lt;/div&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!CAUTION] &lt;strong&gt;DO NOT TRUST ANY HACKINTOSH INFORMATION FROM AI/LLM SOURCES&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;They often provide incorrect information about Hackintosh. Always rely on official sources like the &lt;a href="https://dortania.github.io/OpenCore-Install-Guide/"&gt;Dortania Guide&lt;/a&gt; and the Hackintosh community for accurate information.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!WARNING] &lt;strong&gt;OUTDATED SECTIONS IN DORTANIA GUIDE&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;While the Dortania Guide is a valuable resource, some sections may be outdated. Always:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Verify information with the Hackintosh community&lt;/li&gt; 
  &lt;li&gt;Test configurations yourself&lt;/li&gt; 
  &lt;li&gt;Prefer reading documentation directly from the GitHub repositories of bootloaders and kexts you plan to use&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] If the installation process is successful using OpCore Simplify, please confirm it at &lt;a href="https://github.com/lzhoang2801/OpCore-Simplify/discussions/23"&gt;Successful Hackintosh Setup with OpCore Simplify&lt;/a&gt;. This will greatly assist others in the community.&lt;/p&gt; 
 &lt;p&gt;OpCore Simplify is the ONLY tool that builds OpenCore EFI based on your complete hardware configuration, not just predefined options. This fundamental difference sets us apart from other tools in the Hackintosh community.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] While OpCore Simplify significantly reduces setup time, the Hackintosh journey still requires:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Understanding basic concepts from the &lt;a href="https://dortania.github.io/OpenCore-Install-Guide/"&gt;Dortania Guide&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Testing and troubleshooting during the installation process&lt;/li&gt; 
  &lt;li&gt;Patience and persistence in resolving any issues that arise&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;Our tool doesn't eliminate these steps, but it ensures you start with a solid foundation.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;‚ú® &lt;strong&gt;Features&lt;/strong&gt;&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Comprehensive Hardware and macOS Support&lt;/strong&gt;&lt;br /&gt; Fully supports modern hardware. Use &lt;code&gt;Compatibility Checker&lt;/code&gt; to check supported/unsupported devices and macOS version supported.&lt;/p&gt; 
  &lt;table&gt; 
   &lt;thead&gt; 
    &lt;tr&gt; 
     &lt;th&gt;&lt;strong&gt;Component&lt;/strong&gt;&lt;/th&gt; 
     &lt;th&gt;&lt;strong&gt;Supported&lt;/strong&gt;&lt;/th&gt; 
    &lt;/tr&gt; 
   &lt;/thead&gt; 
   &lt;tbody&gt; 
    &lt;tr&gt; 
     &lt;td&gt;&lt;strong&gt;CPU&lt;/strong&gt;&lt;/td&gt; 
     &lt;td&gt;Intel: Nehalem and Westmere (1nd Gen) ‚Üí Arrow Lake (15th Gen/Core Ultra Series 2) &lt;br /&gt; AMD: Ryzen and Threadripper with &lt;a href="https://github.com/AMD-OSX/AMD_Vanilla"&gt;AMD Vanilla&lt;/a&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;&lt;strong&gt;GPU&lt;/strong&gt;&lt;/td&gt; 
     &lt;td&gt;Intel iGPU: Iron Lake (1nd Gen) ‚Üí Ice Lake (10th Gen) &lt;br /&gt; AMD APU: The entire Vega Raven ASIC family (Ryzen 1xxx ‚Üí 5xxx, 7x30 series) &lt;br /&gt; AMD dGPU: Navi 23, Navi 22, Navi 21 generations, and older series &lt;br /&gt; NVIDIA: Kepler, Pascal, Maxwell, Fermi, Tesla generations&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;&lt;strong&gt;macOS&lt;/strong&gt;&lt;/td&gt; 
     &lt;td&gt;macOS High Sierra ‚Üí macOS Tahoe&lt;/td&gt; 
    &lt;/tr&gt; 
   &lt;/tbody&gt; 
  &lt;/table&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;ACPI Patches and Kexts&lt;/strong&gt;&lt;br /&gt; Automatically detects and adds ACPI patches and kexts based on hardware configuration.&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Integrated with &lt;a href="https://github.com/corpnewt/SSDTTime"&gt;SSDTTime&lt;/a&gt; for common patches (e.g., FakeEC, FixHPET, PLUG, RTCAWAC).&lt;/li&gt; 
   &lt;li&gt;Includes custom patches: 
    &lt;ul&gt; 
     &lt;li&gt;Prevent kernel panics by directing the first CPU entry to an active CPU, disabling the UNC0 device, and creating a new RTC device for HEDT systems.&lt;/li&gt; 
     &lt;li&gt;Disable unsupported or unused PCI devices, such as the GPU (using Optimus and Bumblebee methods or adding the disable-gpu property), Wi-Fi card, and NVMe storage controller.&lt;/li&gt; 
     &lt;li&gt;Fix sleep state values in _PRW methods (GPRW, UPRW, HP special) to prevent immediate wake.&lt;/li&gt; 
     &lt;li&gt;Add devices including ALS0, BUS0, MCHC, PMCR, PNLF, RMNE, IMEI, USBX, XOSI, along with a Surface Patch.&lt;/li&gt; 
     &lt;li&gt;Enable ALSD and GPI0 devices.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Automatic Updates&lt;/strong&gt;&lt;br /&gt; Automatically checks for and updates OpenCorePkg and kexts from &lt;a href="https://dortania.github.io/builds/"&gt;Dortania Builds&lt;/a&gt; and GitHub releases before each EFI build.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;EFI Configuration&lt;/strong&gt;&lt;br /&gt; Apply additional customization based on both widely used sources and personal experience.&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Spoof GPU IDs for certain AMD GPUs not recognized in macOS.&lt;/li&gt; 
   &lt;li&gt;Use CpuTopologyRebuild kext for Intel CPUs with P-cores and E-cores to enhance performance.&lt;/li&gt; 
   &lt;li&gt;Disable System Integrity Protection (SIP).&lt;/li&gt; 
   &lt;li&gt;Spoof CPU IDs for Intel Pentium, Celeron, Core, and Xeon processors.&lt;/li&gt; 
   &lt;li&gt;Add custom CPU names for AMD CPUs, as well as Intel Pentium, Celeron, Xeon, and Core lines from the Rocket Lake (11th) generation and newer.&lt;/li&gt; 
   &lt;li&gt;Add a patch to allow booting macOS with unsupported SMBIOS.&lt;/li&gt; 
   &lt;li&gt;Add NVRAM entries to bypass checking the internal Bluetooth controller.&lt;/li&gt; 
   &lt;li&gt;Properly configure ResizeAppleGpuBars based on specific Resizable BAR information.&lt;/li&gt; 
   &lt;li&gt;Allow flexible iGPU configuration between headless and driving a display when a supported discrete GPU is present.&lt;/li&gt; 
   &lt;li&gt;Force Intel GPUs into VESA mode with HDMI and DVI connectors to simplify installation process.&lt;/li&gt; 
   &lt;li&gt;Provide configuration required for using OpenCore Legacy Patcher.&lt;/li&gt; 
   &lt;li&gt;Add built-in device property for network devices (fix 'Could not communicate with the server' when using iServices) and storage controllers (fix internal drives shown as external).&lt;/li&gt; 
   &lt;li&gt;Prioritize SMBIOS optimized for both power management and performance.&lt;/li&gt; 
   &lt;li&gt;Re-enable CPU power management on legacy Intel CPUs in macOS Ventura 13 and newer.&lt;/li&gt; 
   &lt;li&gt;Apply WiFi profiles for itlwm kext to enable auto WiFi connections at boot time.&lt;/li&gt; 
  &lt;/ul&gt; &lt;p&gt;and more...&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Easy Customization&lt;/strong&gt;&lt;br /&gt; In addition to the default settings applied, users can easily make further customizations if desired.&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Custom ACPI patches, kexts, and SMBIOS adjustments (&lt;strong&gt;not recommended&lt;/strong&gt;).&lt;/li&gt; 
   &lt;li&gt;Force load kexts on unsupported macOS versions.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;üöÄ &lt;strong&gt;How To Use&lt;/strong&gt;&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Download OpCore Simplify&lt;/strong&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Click &lt;strong&gt;Code&lt;/strong&gt; ‚Üí &lt;strong&gt;Download ZIP&lt;/strong&gt;, or download directly via this &lt;a href="https://github.com/lzhoang2801/OpCore-Simplify/archive/refs/heads/main.zip"&gt;link&lt;/a&gt;.&lt;/li&gt; 
   &lt;li&gt;Extract the downloaded ZIP file to your desired location.&lt;/li&gt; 
  &lt;/ul&gt; &lt;p&gt;&lt;img src="https://i.imgur.com/mcE7OSX.png" alt="Download OpCore Simplify" /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Running OpCore Simplify&lt;/strong&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;On &lt;strong&gt;Windows&lt;/strong&gt;, run &lt;code&gt;OpCore-Simplify.bat&lt;/code&gt;.&lt;/li&gt; 
   &lt;li&gt;On &lt;strong&gt;macOS&lt;/strong&gt;, run &lt;code&gt;OpCore-Simplify.command&lt;/code&gt;.&lt;/li&gt; 
  &lt;/ul&gt; &lt;p&gt;&lt;img src="https://i.imgur.com/vTr1V9D.png" alt="OpCore Simplify Menu" /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Selecting hardware report&lt;/strong&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;On Windows, there will be an option for &lt;code&gt;E. Export hardware report&lt;/code&gt;. It's recommended to use this for the best results with your hardware configuration and BIOS at the time of building.&lt;/li&gt; 
   &lt;li&gt;Alternatively, use &lt;a href="https://github.com/lzhoang2801/Hardware-Sniffer"&gt;&lt;strong&gt;Hardware Sniffer&lt;/strong&gt;&lt;/a&gt; to create a &lt;code&gt;Report.json&lt;/code&gt; and ACPI dump for configuration manully.&lt;/li&gt; 
  &lt;/ul&gt; &lt;p&gt;&lt;img src="https://i.imgur.com/MbRmIGJ.png" alt="Selecting hardware report" /&gt;&lt;/p&gt; &lt;p&gt;&lt;img src="https://i.imgur.com/SbL6N6v.png" alt="Loading ACPI Tables" /&gt;&lt;/p&gt; &lt;p&gt;&lt;img src="https://i.imgur.com/kuDGMmp.png" alt="Compatibility Checker" /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Selecting macOS Version and Customizing OpenCore EFI&lt;/strong&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;By default, the latest compatible macOS version will be selected for your hardware.&lt;/li&gt; 
   &lt;li&gt;OpCore Simplify will automatically apply essential ACPI patches and kexts.&lt;/li&gt; 
   &lt;li&gt;You can manually review and customize these settings as needed.&lt;/li&gt; 
  &lt;/ul&gt; &lt;p&gt;&lt;img src="https://i.imgur.com/TSk9ejy.png" alt="OpCore Simplify Menu" /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Building OpenCore EFI&lt;/strong&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Once you've customized all options, select &lt;strong&gt;Build OpenCore EFI&lt;/strong&gt; to generate your EFI.&lt;/li&gt; 
   &lt;li&gt;The tool will automatically download the necessary bootloader and kexts, which may take a few minutes.&lt;/li&gt; 
  &lt;/ul&gt; &lt;p&gt;&lt;img src="https://i.imgur.com/71TkJkD.png" alt="WiFi Profile Extractor" /&gt;&lt;/p&gt; &lt;p&gt;&lt;img src="https://i.imgur.com/Mcm20EQ.png" alt="Choosing Codec Layout ID" /&gt;&lt;/p&gt; &lt;p&gt;&lt;img src="https://i.imgur.com/deyj5de.png" alt="Building OpenCore EFI" /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;USB Mapping&lt;/strong&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;After building your EFI, follow the steps for mapping USB ports.&lt;/li&gt; 
  &lt;/ul&gt; &lt;p&gt;&lt;img src="https://i.imgur.com/MIPigPF.png" alt="Results" /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Create USB and Install macOS&lt;/strong&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Use &lt;a href="https://github.com/corpnewt/UnPlugged"&gt;&lt;strong&gt;UnPlugged&lt;/strong&gt;&lt;/a&gt; on Windows to create a USB macOS installer, or follow &lt;a href="https://dortania.github.io/OpenCore-Install-Guide/installer-guide/mac-install.html"&gt;this guide&lt;/a&gt; for macOS.&lt;/li&gt; 
   &lt;li&gt;For troubleshooting, refer to the &lt;a href="https://dortania.github.io/OpenCore-Install-Guide/troubleshooting/troubleshooting.html"&gt;OpenCore Troubleshooting Guide&lt;/a&gt;.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE]&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt; &lt;p&gt;After a successful installation, if OpenCore Legacy Patcher is required, simply apply root patches to activate the missing features (such as modern Broadcom Wi-Fi card and graphics acceleration).&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;For AMD GPUs, after applying root patches from OpenCore Legacy Patcher, you need to remove the boot argument &lt;code&gt;-radvesa&lt;/code&gt;/&lt;code&gt;-amd_no_dgpu_accel&lt;/code&gt; for graphics acceleration to work.&lt;/p&gt; &lt;/li&gt; 
 &lt;/ol&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;ü§ù &lt;strong&gt;Contributing&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;Contributions are &lt;strong&gt;highly appreciated&lt;/strong&gt;! If you have ideas to improve this project, feel free to fork the repo and create a pull request, or open an issue with the "enhancement" tag.&lt;/p&gt; 
&lt;p&gt;Don't forget to ‚≠ê star the project! Thank you for your support! üåü&lt;/p&gt; 
&lt;h2&gt;üìú &lt;strong&gt;License&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;Distributed under the BSD 3-Clause License. See &lt;code&gt;LICENSE&lt;/code&gt; for more information.&lt;/p&gt; 
&lt;h2&gt;üôå &lt;strong&gt;Credits&lt;/strong&gt;&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/acidanthera/OpenCorePkg"&gt;OpenCorePkg&lt;/a&gt; and &lt;a href="https://github.com/lzhoang2801/OpCore-Simplify/raw/main/Scripts/datasets/kext_data.py"&gt;kexts&lt;/a&gt; ‚Äì The backbone of this project.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/corpnewt/SSDTTime"&gt;SSDTTime&lt;/a&gt; ‚Äì SSDT patching utilities.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üìû &lt;strong&gt;Contact&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Hoang Hong Quan&lt;/strong&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Facebook &lt;a href="https://facebook.com/macforce2601"&gt;@macforce2601&lt;/a&gt; &amp;nbsp;¬∑&amp;nbsp; Telegram &lt;a href="https://t.me/lzhoang2601"&gt;@lzhoang2601&lt;/a&gt; &amp;nbsp;¬∑&amp;nbsp; Email: &lt;a href="mailto:lzhoang2601@gmail.com"&gt;lzhoang2601@gmail.com&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;üåü &lt;strong&gt;Star History&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://star-history.com/#lzhoang2801/OpCore-Simplify&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=lzhoang2801/OpCore-Simplify&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>droidrun/droidrun</title>
      <link>https://github.com/droidrun/droidrun</link>
      <description>&lt;p&gt;Automate your mobile devices with natural language commands - an LLM agnostic mobile Agent ü§ñ&lt;/p&gt;&lt;hr&gt;&lt;picture align="center"&gt; 
 &lt;source media="(prefers-color-scheme: dark)" srcset="./static/droidrun-dark.png" /&gt; 
 &lt;source media="(prefers-color-scheme: light)" srcset="./static/droidrun.png" /&gt; 
 &lt;img src="https://raw.githubusercontent.com/droidrun/droidrun/main/static/droidrun.png" width="full" /&gt; 
&lt;/picture&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://docs.droidrun.ai"&gt;&lt;img src="https://img.shields.io/badge/Docs-%F0%9F%93%95-0D9373?style=for-the-badge" alt="Docs" /&gt;&lt;/a&gt; &lt;a href="https://cloud.droidrun.ai/sign-in?waitlist=true"&gt;&lt;img src="https://img.shields.io/badge/Cloud-%E2%98%81%EF%B8%8F-0D9373?style=for-the-badge" alt="Cloud" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://github.com/droidrun/droidrun/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/droidrun/droidrun?style=social" alt="GitHub stars" /&gt;&lt;/a&gt; &lt;a href="https://droidrun.ai"&gt;&lt;img src="https://img.shields.io/badge/droidrun.ai-white" alt="droidrun.ai" /&gt;&lt;/a&gt; &lt;a href="https://x.com/droid_run"&gt;&lt;img src="https://img.shields.io/twitter/follow/droid_run?style=social" alt="Twitter Follow" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/ZZbKEZZkwK"&gt;&lt;img src="https://img.shields.io/discord/1360219330318696488?color=white&amp;amp;label=Discord&amp;amp;logo=discord&amp;amp;logoColor=white" alt="Discord" /&gt;&lt;/a&gt; &lt;a href="https://droidrun.ai/benchmark"&gt;&lt;img src="https://img.shields.io/badge/Benchmark-91.4%EF%B9%AA-white" alt="Benchmark" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://api.producthunt.com/widgets/embed-image/v1/top-post-badge.svg?post_id=983810&amp;amp;theme=dark&amp;amp;period=daily&amp;amp;t=1753948032207" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://api.producthunt.com/widgets/embed-image/v1/top-post-badge.svg?post_id=983810&amp;amp;theme=neutral&amp;amp;period=daily&amp;amp;t=1753948125523" /&gt; 
  &lt;a href="https://www.producthunt.com/products/droidrun-framework-for-mobile-agent?embed=true&amp;amp;utm_source=badge-top-post-badge&amp;amp;utm_medium=badge&amp;amp;utm_source=badge-droidrun" target="_blank"&gt;&lt;img src="https://api.producthunt.com/widgets/embed-image/v1/top-post-badge.svg?post_id=983810&amp;amp;theme=neutral&amp;amp;period=daily&amp;amp;t=1753948125523" alt="Droidrun - Give AI native control of physical &amp;amp; virtual phones. | Product Hunt" style="width: 200px; height: 54px;" width="200" height="54" /&gt;&lt;/a&gt; 
 &lt;/picture&gt; 
 &lt;p&gt;&lt;a href="https://zdoc.app/de/droidrun/droidrun"&gt;Deutsch&lt;/a&gt; | &lt;a href="https://zdoc.app/es/droidrun/droidrun"&gt;Espa√±ol&lt;/a&gt; | &lt;a href="https://zdoc.app/fr/droidrun/droidrun"&gt;fran√ßais&lt;/a&gt; | &lt;a href="https://zdoc.app/ja/droidrun/droidrun"&gt;Êó•Êú¨Ë™û&lt;/a&gt; | &lt;a href="https://zdoc.app/ko/droidrun/droidrun"&gt;ÌïúÍµ≠Ïñ¥&lt;/a&gt; | &lt;a href="https://zdoc.app/pt/droidrun/droidrun"&gt;Portugu√™s&lt;/a&gt; | &lt;a href="https://zdoc.app/ru/droidrun/droidrun"&gt;–†—É—Å—Å–∫–∏–π&lt;/a&gt; | &lt;a href="https://zdoc.app/zh/droidrun/droidrun"&gt;‰∏≠Êñá&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;DroidRun is a powerful framework for controlling Android and iOS devices through LLM agents. It allows you to automate device interactions using natural language commands. &lt;a href="https://droidrun.ai/benchmark"&gt;Checkout our benchmark results&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Why Droidrun?&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;ü§ñ Control Android and iOS devices with natural language commands&lt;/li&gt; 
 &lt;li&gt;üîÄ Supports multiple LLM providers (OpenAI, Anthropic, Gemini, Ollama, DeepSeek)&lt;/li&gt; 
 &lt;li&gt;üß† Planning capabilities for complex multi-step tasks&lt;/li&gt; 
 &lt;li&gt;üíª Easy to use CLI with enhanced debugging features&lt;/li&gt; 
 &lt;li&gt;üêç Extendable Python API for custom automations&lt;/li&gt; 
 &lt;li&gt;üì∏ Screenshot analysis for visual understanding of the device&lt;/li&gt; 
 &lt;li&gt;ü´Ü Execution tracing with Arize Phoenix&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üì¶ Installation&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install 'droidrun[google,anthropic,openai,deepseek,ollama,dev]'
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;üöÄ Quickstart&lt;/h2&gt; 
&lt;p&gt;Read on how to get droidrun up and running within seconds in &lt;a href="https://docs.droidrun.ai/v3/quickstart"&gt;our docs&lt;/a&gt;!&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=4WT7FXJah2I"&gt;&lt;img src="https://img.youtube.com/vi/4WT7FXJah2I/0.jpg" alt="Quickstart Video" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üé¨ Demo Videos&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Accommodation booking&lt;/strong&gt;: Let Droidrun search for an apartment for you&lt;/p&gt; &lt;p&gt;&lt;a href="https://youtu.be/VUpCyq1PSXw"&gt;&lt;img src="https://img.youtube.com/vi/VUpCyq1PSXw/0.jpg" alt="Droidrun Accommodation Booking Demo" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;br /&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Trend Hunter&lt;/strong&gt;: Let Droidrun hunt down trending posts&lt;/p&gt; &lt;p&gt;&lt;a href="https://youtu.be/7V8S2f8PnkQ"&gt;&lt;img src="https://img.youtube.com/vi/7V8S2f8PnkQ/0.jpg" alt="Droidrun Trend Hunter Demo" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;br /&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Streak Saver&lt;/strong&gt;: Let Droidrun save your streak on your favorite language learning app&lt;/p&gt; &lt;p&gt;&lt;a href="https://youtu.be/B5q2B467HKw"&gt;&lt;img src="https://img.youtube.com/vi/B5q2B467HKw/0.jpg" alt="Droidrun Streak Saver Demo" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;üí° Example Use Cases&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Automated UI testing of mobile applications&lt;/li&gt; 
 &lt;li&gt;Creating guided workflows for non-technical users&lt;/li&gt; 
 &lt;li&gt;Automating repetitive tasks on mobile devices&lt;/li&gt; 
 &lt;li&gt;Remote assistance for less technical users&lt;/li&gt; 
 &lt;li&gt;Exploring mobile UI with natural language commands&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üë• Contributing&lt;/h2&gt; 
&lt;p&gt;Contributions are welcome! Please feel free to submit a Pull Request.&lt;/p&gt; 
&lt;h2&gt;üìÑ License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the MIT License - see the LICENSE file for details.&lt;/p&gt; 
&lt;h2&gt;Security Checks&lt;/h2&gt; 
&lt;p&gt;To ensure the security of the codebase, we have integrated security checks using &lt;code&gt;bandit&lt;/code&gt; and &lt;code&gt;safety&lt;/code&gt;. These tools help identify potential security issues in the code and dependencies.&lt;/p&gt; 
&lt;h3&gt;Running Security Checks&lt;/h3&gt; 
&lt;p&gt;Before submitting any code, please run the following security checks:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Bandit&lt;/strong&gt;: A tool to find common security issues in Python code.&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;bandit -r droidrun
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Safety&lt;/strong&gt;: A tool to check your installed dependencies for known security vulnerabilities.&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;safety scan
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt;</description>
    </item>
    
    <item>
      <title>VectifyAI/PageIndex</title>
      <link>https://github.com/VectifyAI/PageIndex</link>
      <description>&lt;p&gt;üìë PageIndex: Document Index for Reasoning-based RAG&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;a href="https://vectify.ai/pageindex" target="_blank"&gt; &lt;img src="https://github.com/user-attachments/assets/46201e72-675b-43bc-bfbd-081cc6b65a1d" alt="PageIndex Banner" /&gt; &lt;/a&gt; 
 &lt;br /&gt; 
 &lt;br /&gt; 
 &lt;p align="center"&gt; &lt;a href="https://trendshift.io/repositories/14736" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/14736" alt="VectifyAI%2FPageIndex | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt; &lt;/p&gt; 
 &lt;p align="center"&gt;Reasoning-based RAG&amp;nbsp; ‚ó¶ &amp;nbsp;No Vector DB&amp;nbsp; ‚ó¶ &amp;nbsp;No Chunking&amp;nbsp; ‚ó¶ &amp;nbsp;Human-like Retrieval&lt;/p&gt; 
 &lt;h4 align="center"&gt; &lt;a href="https://vectify.ai"&gt;üè† Homepage&lt;/a&gt;&amp;nbsp; ‚Ä¢ &amp;nbsp; &lt;a href="https://chat.pageindex.ai"&gt;üöÄ Agent&lt;/a&gt;&amp;nbsp; ‚Ä¢ &amp;nbsp; &lt;a href="https://pageindex.ai/mcp"&gt;üîå MCP&lt;/a&gt;&amp;nbsp; ‚Ä¢ &amp;nbsp; &lt;a href="https://dash.pageindex.ai"&gt;üñ•Ô∏è Dashboard&lt;/a&gt;&amp;nbsp; ‚Ä¢ &amp;nbsp; &lt;a href="https://docs.pageindex.ai/quickstart"&gt;üìö Docs&lt;/a&gt;&amp;nbsp; ‚Ä¢ &amp;nbsp; &lt;a href="https://discord.com/invite/VuXuf29EUj"&gt;üí¨ Discord&lt;/a&gt;&amp;nbsp; ‚Ä¢ &amp;nbsp; &lt;a href="https://ii2abc2jejf.typeform.com/to/tK3AXl8T"&gt;‚úâÔ∏è Contact&lt;/a&gt;&amp;nbsp; &lt;/h4&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h3&gt;üì¢ Recent Updates&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;üöÄ New Releases:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://chat.pageindex.ai"&gt;&lt;strong&gt;PageIndex Chat&lt;/strong&gt;&lt;/a&gt;: The first human-like document analyst agent, designed for professional long documents.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pageindex.ai/mcp"&gt;&lt;strong&gt;PageIndex MCP&lt;/strong&gt;&lt;/a&gt;: Bring PageIndex into Claude, Cursor, or any MCP-enabled agent. Chat with long PDFs in a reasoning-based, human-like way.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;üß™ Cookbooks:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/VectifyAI/PageIndex/raw/main/cookbook/pageindex_RAG_simple.ipynb"&gt;&lt;strong&gt;Vectorless RAG notebook&lt;/strong&gt;&lt;/a&gt;: A minimal, hands-on example of reasoning-based RAG using &lt;strong&gt;PageIndex&lt;/strong&gt; ‚Äî no vectors, no chunking, and human-like retrieval.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/VectifyAI/PageIndex/raw/main/cookbook/vision_RAG_pageindex.ipynb"&gt;Vision-based Vectorless RAG notebook&lt;/a&gt;: Experience OCR-free document understanding through PageIndex‚Äôs visual retrieval workflow that retrieves and reasons directly over PDF page images.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;üìú Articles:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;‚≠ê &lt;a href="https://pageindex.ai/blog/pageindex-intro"&gt;&lt;strong&gt;The PageIndex Overview&lt;/strong&gt;&lt;/a&gt;: Introduces the PageIndex framework ‚Äî an &lt;em&gt;agentic, in-context&lt;/em&gt; &lt;strong&gt;tree index&lt;/strong&gt; that enables LLMs to perform &lt;strong&gt;reasoning-based, human-like retrieval&lt;/strong&gt; over long documents, without vector DB or chunking.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pageindex.ai/blog/do-we-need-ocr"&gt;Do We Still Need OCR?&lt;/a&gt;: Explores how vision-based, reasoning-native RAG challenges the traditional OCR pipeline, and why the future of document AI might be &lt;em&gt;vectorless&lt;/em&gt; and &lt;em&gt;vision-based&lt;/em&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;üìë Introduction to PageIndex&lt;/h1&gt; 
&lt;p&gt;Are you frustrated with vector database retrieval accuracy for long professional documents? Traditional vector-based RAG relies on semantic &lt;em&gt;similarity&lt;/em&gt; rather than true &lt;em&gt;relevance&lt;/em&gt;. But &lt;strong&gt;similarity ‚â† relevance&lt;/strong&gt; ‚Äî what we truly need in retrieval is &lt;strong&gt;relevance&lt;/strong&gt;, and that requires &lt;strong&gt;reasoning&lt;/strong&gt;. When working with professional documents that demand domain expertise and multi-step reasoning, similarity search often falls short.&lt;/p&gt; 
&lt;p&gt;Inspired by AlphaGo, we propose &lt;strong&gt;&lt;a href="https://vectify.ai/pageindex"&gt;PageIndex&lt;/a&gt;&lt;/strong&gt; ‚Äî a &lt;strong&gt;&lt;em&gt;vectorless&lt;/em&gt;&lt;/strong&gt;, &lt;strong&gt;reasoning-based RAG&lt;/strong&gt; system that builds a &lt;em&gt;hierarchical tree index&lt;/em&gt; for long documents and &lt;em&gt;reasons&lt;/em&gt; over that index for &lt;em&gt;retrieval&lt;/em&gt;. It simulates how &lt;strong&gt;human experts&lt;/strong&gt; navigate and extract knowledge from complex documents through &lt;strong&gt;tree search&lt;/strong&gt;, enabling LLMs to &lt;em&gt;think&lt;/em&gt; and &lt;em&gt;reason&lt;/em&gt; their way to the most relevant document sections. It performs retrieval in two steps:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Generate a "Table-of-Contents" &lt;strong&gt;tree structure index&lt;/strong&gt; of documents&lt;/li&gt; 
 &lt;li&gt;Perform reasoning-based retrieval through &lt;strong&gt;tree search&lt;/strong&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://docs.pageindex.ai/images/cookbook/vectorless-rag.png" width="70%" /&gt; 
&lt;/div&gt; 
&lt;h3&gt;üß© Features&lt;/h3&gt; 
&lt;p&gt;Compared to traditional &lt;em&gt;vector-based RAG&lt;/em&gt;, &lt;strong&gt;PageIndex&lt;/strong&gt; features:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;No Vector DB&lt;/strong&gt;: Uses document structure and LLM reasoning for retrieval, instead of vector search.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;No Chunking&lt;/strong&gt;: Documents are organized into natural sections, not artificial chunks.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Human-like Retrieval&lt;/strong&gt;: Simulates how human experts navigate and extract knowledge from complex documents.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Transparent Retrieval Process&lt;/strong&gt;: Retrieval based on reasoning ‚Äî traceable and interpretable. Say goodbye to approximate vector search ("vibe retrieval").&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;PageIndex powers a reasoning-based RAG system that achieved &lt;a href="https://github.com/VectifyAI/Mafin2.5-FinanceBench"&gt;98.7% accuracy&lt;/a&gt; on FinanceBench, demonstrating &lt;strong&gt;state-of-the-art&lt;/strong&gt; performance in professional document analysis (see our &lt;a href="https://vectify.ai/blog/Mafin2.5"&gt;blog post&lt;/a&gt; for details).&lt;/p&gt; 
&lt;h3&gt;‚öôÔ∏è Deployment Options&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;üõ†Ô∏è Self-host ‚Äî run locally with this open-source repo.&lt;/li&gt; 
 &lt;li&gt;‚òÅÔ∏è &lt;strong&gt;Cloud Service&lt;/strong&gt; ‚Äî try instantly with our üöÄ &lt;a href="https://chat.pageindex.ai/"&gt;Agent&lt;/a&gt;, üñ•Ô∏è &lt;a href="https://dash.pageindex.ai/"&gt;Dashboard&lt;/a&gt; or üîå &lt;a href="https://docs.pageindex.ai/quickstart"&gt;API&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üß™ Quick Hands-on&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Try the &lt;a href="https://github.com/VectifyAI/PageIndex/raw/main/cookbook/pageindex_RAG_simple.ipynb"&gt;&lt;em&gt;&lt;strong&gt;Vectorless RAG Notebook&lt;/strong&gt;&lt;/em&gt;&lt;/a&gt; ‚Äî a &lt;em&gt;minimal&lt;/em&gt;, hands-on example of reasoning-based RAG using &lt;strong&gt;PageIndex&lt;/strong&gt;.&lt;/li&gt; 
 &lt;li&gt;Experiment with the &lt;a href="https://github.com/VectifyAI/PageIndex/raw/main/cookbook/vision_RAG_pageindex.ipynb"&gt;&lt;em&gt;Vision-based Vectorless RAG&lt;/em&gt;&lt;/a&gt; ‚Äî no OCR; a minimal, reasoning-native RAG pipeline that works directly over page images.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://colab.research.google.com/github/VectifyAI/PageIndex/blob/main/cookbook/pageindex_RAG_simple.ipynb" target="_blank" rel="noopener"&gt; &lt;img src="https://img.shields.io/badge/Open_In_Colab-Vectorless_RAG-orange?style=for-the-badge&amp;amp;logo=googlecolab" alt="Open in Colab: Vectorless RAG" /&gt; &lt;/a&gt; &amp;nbsp;&amp;nbsp; 
 &lt;a href="https://colab.research.google.com/github/VectifyAI/PageIndex/blob/main/cookbook/vision_RAG_pageindex.ipynb" target="_blank" rel="noopener"&gt; &lt;img src="https://img.shields.io/badge/Open_In_Colab-Vision_RAG-orange?style=for-the-badge&amp;amp;logo=googlecolab" alt="Open in Colab: Vision RAG" /&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h1&gt;üå≤ PageIndex Tree Structure&lt;/h1&gt; 
&lt;p&gt;PageIndex can transform lengthy PDF documents into a semantic &lt;strong&gt;tree structure&lt;/strong&gt;, similar to a &lt;em&gt;"table of contents"&lt;/em&gt; but optimized for use with Large Language Models (LLMs). It's ideal for: financial reports, regulatory filings, academic textbooks, legal or technical manuals, and any document that exceeds LLM context limits.&lt;/p&gt; 
&lt;p&gt;Here is an example output. See more &lt;a href="https://github.com/VectifyAI/PageIndex/tree/main/tests/pdfs"&gt;example documents&lt;/a&gt; and &lt;a href="https://github.com/VectifyAI/PageIndex/tree/main/tests/results"&gt;generated trees&lt;/a&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-jsonc"&gt;...
{
  "title": "Financial Stability",
  "node_id": "0006",
  "start_index": 21,
  "end_index": 22,
  "summary": "The Federal Reserve ...",
  "nodes": [
    {
      "title": "Monitoring Financial Vulnerabilities",
      "node_id": "0007",
      "start_index": 22,
      "end_index": 28,
      "summary": "The Federal Reserve's monitoring ..."
    },
    {
      "title": "Domestic and International Cooperation and Coordination",
      "node_id": "0008",
      "start_index": 28,
      "end_index": 31,
      "summary": "In 2023, the Federal Reserve collaborated ..."
    }
  ]
}
...
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can either generate the PageIndex tree structure with this open-source repo, or try our ‚òÅÔ∏è &lt;strong&gt;Cloud Service&lt;/strong&gt; ‚Äî instantly accessible via our üöÄ &lt;a href="https://chat.pageindex.ai/"&gt;Agent&lt;/a&gt;, üñ•Ô∏è &lt;a href="https://dash.pageindex.ai/"&gt;Dashboard&lt;/a&gt; or üîå &lt;a href="https://docs.pageindex.ai/quickstart"&gt;API&lt;/a&gt;.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h1&gt;üì¶ Package Usage&lt;/h1&gt; 
&lt;p&gt;You can follow these steps to generate a PageIndex tree from a PDF document.&lt;/p&gt; 
&lt;h3&gt;1. Install dependencies&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip3 install --upgrade -r requirements.txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;2. Set your OpenAI API key&lt;/h3&gt; 
&lt;p&gt;Create a &lt;code&gt;.env&lt;/code&gt; file in the root directory and add your API key:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;CHATGPT_API_KEY=your_openai_key_here
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;3. Run PageIndex on your PDF&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python3 run_pageindex.py --pdf_path /path/to/your/document.pdf
&lt;/code&gt;&lt;/pre&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;Optional parameters&lt;/strong&gt;&lt;/summary&gt; 
 &lt;br /&gt; You can customize the processing with additional optional arguments: 
 &lt;pre&gt;&lt;code&gt;--model                 OpenAI model to use (default: gpt-4o-2024-11-20)
--toc-check-pages       Pages to check for table of contents (default: 20)
--max-pages-per-node    Max pages per node (default: 10)
--max-tokens-per-node   Max tokens per node (default: 20000)
--if-add-node-id        Add node ID (yes/no, default: yes)
--if-add-node-summary   Add node summary (yes/no, default: yes)
--if-add-doc-description Add doc description (yes/no, default: yes)
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;Markdown support&lt;/strong&gt;&lt;/summary&gt; 
 &lt;br /&gt; We also provide a markdown support for PageIndex. You can use the `-md_path` flag to generate a tree structure for a markdown file. 
 &lt;pre&gt;&lt;code class="language-bash"&gt;python3 run_pageindex.py --md_path /path/to/your/document.md
&lt;/code&gt;&lt;/pre&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;Notice: in this function, we use "#" to determine node heading and their levels. For example, "##" is level 2, "###" is level 3, etc. Make sure your markdown file is formatted correctly. If your Markdown file was converted from a PDF or HTML, we don‚Äôt recommend using this function, since most existing conversion tools cannot preserve the original hierarchy. Instead, use our &lt;a href="https://pageindex.ai/blog/ocr"&gt;PageIndex OCR&lt;/a&gt;, which is designed to preserve the original hierarchy, to convert the PDF to a markdown file and then use this function.&lt;/p&gt; 
 &lt;/blockquote&gt; 
&lt;/details&gt; 
&lt;hr /&gt; 
&lt;!-- # ‚òÅÔ∏è Improved Tree Generation with PageIndex OCR

This repo is designed for generating PageIndex tree structure for simple PDFs, but many real-world use cases involve complex PDFs that are hard to parse by classic Python tools. However, extracting high-quality text from PDF documents remains a non-trivial challenge. Most OCR tools only extract page-level content, losing the broader document context and hierarchy.

To address this, we introduced PageIndex OCR ‚Äî the first long-context OCR model designed to preserve the global structure of documents. PageIndex OCR significantly outperforms other leading OCR tools, such as those from Mistral and Contextual AI, in recognizing true hierarchy and semantic relationships across document pages.

- Experience next-level OCR quality with PageIndex OCR at our [Dashboard](https://dash.pageindex.ai/).
- Integrate PageIndex OCR seamlessly into your stack via our [API](https://docs.pageindex.ai/quickstart).

&lt;p align="center"&gt;
  &lt;img src="https://github.com/user-attachments/assets/eb35d8ae-865c-4e60-a33b-ebbd00c41732" width="80%"&gt;
&lt;/p&gt;

--- --&gt; 
&lt;h1&gt;üìà Case Study: SOTA on Finance QA Benchmark&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://vectify.ai/mafin"&gt;Mafin 2.5&lt;/a&gt; is a reasoning-based RAG system for financial document analysis, powered by &lt;strong&gt;PageIndex&lt;/strong&gt;. It achieved a state-of-the-art &lt;a href="https://vectify.ai/blog/Mafin2.5"&gt;&lt;strong&gt;98.7% accuracy&lt;/strong&gt;&lt;/a&gt; on the &lt;a href="https://arxiv.org/abs/2311.11944"&gt;FinanceBench&lt;/a&gt; benchmark ‚Äî significantly outperforming traditional vector-based RAG systems.&lt;/p&gt; 
&lt;p&gt;PageIndex's hierarchical indexing enabled precise navigation and extraction of relevant content from complex financial reports, such as SEC filings and earnings disclosures.&lt;/p&gt; 
&lt;p&gt;üëâ Explore the full &lt;a href="https://github.com/VectifyAI/Mafin2.5-FinanceBench"&gt;benchmark results&lt;/a&gt; and our &lt;a href="https://vectify.ai/blog/Mafin2.5"&gt;blog post&lt;/a&gt; for detailed comparisons and performance metrics.&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://github.com/VectifyAI/Mafin2.5-FinanceBench"&gt; &lt;img src="https://github.com/user-attachments/assets/571aa074-d803-43c7-80c4-a04254b782a3" width="70%" /&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h1&gt;üîé Learn More about PageIndex&lt;/h1&gt; 
&lt;h3&gt;Resources &amp;amp; Guides&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;üìñ Explore our &lt;a href="https://docs.pageindex.ai/doc-search"&gt;Tutorials&lt;/a&gt; for practical guides and strategies, including &lt;em&gt;Document Search&lt;/em&gt; and &lt;em&gt;Tree Search&lt;/em&gt;.&lt;/li&gt; 
 &lt;li&gt;üß™ Browse the &lt;a href="https://docs.pageindex.ai/cookbook/vectorless-rag-pageindex"&gt;Cookbooks&lt;/a&gt; for practical recipes and advanced use cases.&lt;/li&gt; 
 &lt;li&gt;‚öôÔ∏è Refer to the &lt;a href="https://pageindex.ai/mcp#quick-setup"&gt;MCP setup&lt;/a&gt; or &lt;a href="https://docs.pageindex.ai/quickstart"&gt;API docs&lt;/a&gt; for integration details and configuration options.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;‚≠ê Support Us&lt;/h3&gt; 
&lt;p&gt;Leave a star if you like our project. Thank you!&lt;/p&gt; 
&lt;p&gt; &lt;img src="https://github.com/user-attachments/assets/eae4ff38-48ae-4a7c-b19f-eab81201d794" width="80%" /&gt; &lt;/p&gt; 
&lt;h3&gt;Connect with Us&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://x.com/VectifyAI"&gt;&lt;img src="https://img.shields.io/badge/Twitter-000000?style=for-the-badge&amp;amp;logo=x&amp;amp;logoColor=white" alt="Twitter" /&gt;&lt;/a&gt;&amp;nbsp; &lt;a href="https://www.linkedin.com/company/vectify-ai/"&gt;&lt;img src="https://img.shields.io/badge/LinkedIn-0077B5?style=for-the-badge&amp;amp;logo=linkedin&amp;amp;logoColor=white" alt="LinkedIn" /&gt;&lt;/a&gt;&amp;nbsp; &lt;a href="https://discord.com/invite/VuXuf29EUj"&gt;&lt;img src="https://img.shields.io/badge/Discord-5865F2?style=for-the-badge&amp;amp;logo=discord&amp;amp;logoColor=white" alt="Discord" /&gt;&lt;/a&gt;&amp;nbsp; &lt;a href="https://ii2abc2jejf.typeform.com/to/tK3AXl8T"&gt;&lt;img src="https://img.shields.io/badge/Contact_Us-3B82F6?style=for-the-badge&amp;amp;logo=envelope&amp;amp;logoColor=white" alt="Contact Us" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;¬© 2025 &lt;a href="https://vectify.ai"&gt;Vectify AI&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>GeeeekExplorer/nano-vllm</title>
      <link>https://github.com/GeeeekExplorer/nano-vllm</link>
      <description>&lt;p&gt;Nano vLLM&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;img width="300" src="https://raw.githubusercontent.com/GeeeekExplorer/nano-vllm/main/assets/logo.png" /&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://trendshift.io/repositories/15323" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/15323" alt="GeeeekExplorer%2Fnano-vllm | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;h1&gt;Nano-vLLM&lt;/h1&gt; 
&lt;p&gt;A lightweight vLLM implementation built from scratch.&lt;/p&gt; 
&lt;h2&gt;Key Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;üöÄ &lt;strong&gt;Fast offline inference&lt;/strong&gt; - Comparable inference speeds to vLLM&lt;/li&gt; 
 &lt;li&gt;üìñ &lt;strong&gt;Readable codebase&lt;/strong&gt; - Clean implementation in ~ 1,200 lines of Python code&lt;/li&gt; 
 &lt;li&gt;‚ö° &lt;strong&gt;Optimization Suite&lt;/strong&gt; - Prefix caching, Tensor Parallelism, Torch compilation, CUDA graph, etc.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install git+https://github.com/GeeeekExplorer/nano-vllm.git
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Model Download&lt;/h2&gt; 
&lt;p&gt;To download the model weights manually, use the following command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;huggingface-cli download --resume-download Qwen/Qwen3-0.6B \
  --local-dir ~/huggingface/Qwen3-0.6B/ \
  --local-dir-use-symlinks False
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;p&gt;See &lt;code&gt;example.py&lt;/code&gt; for usage. The API mirrors vLLM's interface with minor differences in the &lt;code&gt;LLM.generate&lt;/code&gt; method:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from nanovllm import LLM, SamplingParams
llm = LLM("/YOUR/MODEL/PATH", enforce_eager=True, tensor_parallel_size=1)
sampling_params = SamplingParams(temperature=0.6, max_tokens=256)
prompts = ["Hello, Nano-vLLM."]
outputs = llm.generate(prompts, sampling_params)
outputs[0]["text"]
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Benchmark&lt;/h2&gt; 
&lt;p&gt;See &lt;code&gt;bench.py&lt;/code&gt; for benchmark.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Test Configuration:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Hardware: RTX 4070 Laptop (8GB)&lt;/li&gt; 
 &lt;li&gt;Model: Qwen3-0.6B&lt;/li&gt; 
 &lt;li&gt;Total Requests: 256 sequences&lt;/li&gt; 
 &lt;li&gt;Input Length: Randomly sampled between 100‚Äì1024 tokens&lt;/li&gt; 
 &lt;li&gt;Output Length: Randomly sampled between 100‚Äì1024 tokens&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Performance Results:&lt;/strong&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Inference Engine&lt;/th&gt; 
   &lt;th&gt;Output Tokens&lt;/th&gt; 
   &lt;th&gt;Time (s)&lt;/th&gt; 
   &lt;th&gt;Throughput (tokens/s)&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;vLLM&lt;/td&gt; 
   &lt;td&gt;133,966&lt;/td&gt; 
   &lt;td&gt;98.37&lt;/td&gt; 
   &lt;td&gt;1361.84&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Nano-vLLM&lt;/td&gt; 
   &lt;td&gt;133,966&lt;/td&gt; 
   &lt;td&gt;93.41&lt;/td&gt; 
   &lt;td&gt;1434.13&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Star History&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://www.star-history.com/#GeeeekExplorer/nano-vllm&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=GeeeekExplorer/nano-vllm&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>mindsdb/mindsdb</title>
      <link>https://github.com/mindsdb/mindsdb</link>
      <description>&lt;p&gt;Federated query engine for AI - The only MCP Server you'll ever need&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a name="readme-top"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://pypi.org/project/MindsDB/" target="_blank"&gt;&lt;img src="https://badge.fury.io/py/MindsDB.svg?sanitize=true" alt="MindsDB Release" /&gt;&lt;/a&gt; 
 &lt;a href="https://www.python.org/downloads/" target="_blank"&gt;&lt;img src="https://img.shields.io/badge/python-3.10.x%7C%203.11.x%7C%203.12.x%7C%203.13.x-brightgreen.svg?sanitize=true" alt="Python supported" /&gt;&lt;/a&gt; 
 &lt;a href="https://hub.docker.com/u/mindsdb" target="_blank"&gt;&lt;img src="https://img.shields.io/docker/pulls/mindsdb/mindsdb" alt="Docker pulls" /&gt;&lt;/a&gt; 
 &lt;br /&gt; 
 &lt;br /&gt; 
 &lt;p&gt;&lt;a href="https://trendshift.io/repositories/3068" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/3068" alt="mindsdb%2Fmindsdb | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;a href="https://github.com/mindsdb/mindsdb"&gt; &lt;img src="https://raw.githubusercontent.com/mindsdb/mindsdb/main/docs/assets/mindsdb_logo.png" alt="MindsDB" width="300" /&gt; &lt;/a&gt; 
 &lt;p align="center"&gt; &lt;br /&gt; &lt;a href="https://www.mindsdb.com?utm_medium=community&amp;amp;utm_source=github&amp;amp;utm_campaign=mindsdb%20repo"&gt;Website&lt;/a&gt; ¬∑ &lt;a href="https://docs.mindsdb.com?utm_medium=community&amp;amp;utm_source=github&amp;amp;utm_campaign=mindsdb%20repo"&gt;Docs&lt;/a&gt; ¬∑ &lt;a href="https://mindsdb.com/contact"&gt;Contact us for a Demo&lt;/a&gt; ¬∑ &lt;a href="https://mindsdb.com/joincommunity?utm_medium=community&amp;amp;utm_source=github&amp;amp;utm_campaign=mindsdb%20repo"&gt;Community Slack&lt;/a&gt; &lt;/p&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;p&gt;MindsDB enables humans, AI, agents, and applications to get highly accurate answers across large scale data sources.&lt;/p&gt; 
&lt;a href="https://www.youtube.com/watch?v=MX3OKpnsoLM" target="_blank"&gt; &lt;img src="https://github.com/user-attachments/assets/119e7b82-f901-4214-a26f-ff7c5ad86064" alt="MindsDB Demo" /&gt; &lt;/a&gt; 
&lt;h2&gt;Install MindsDB Server&lt;/h2&gt; 
&lt;p&gt;MindsDB is an open-source server that can be deployed anywhere - from your laptop to the cloud, and everywhere in between. And yes, you can customize it to your heart's content.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.mindsdb.com/setup/self-hosted/docker-desktop"&gt;Using Docker Desktop&lt;/a&gt;. This is the fastest and recommended way to get started and have it all running.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.mindsdb.com/setup/self-hosted/docker"&gt;Using Docker&lt;/a&gt;. This is also simple, but gives you more flexibility on how to further customize your server.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://docs.mindsdb.com/mcp/overview"&gt;MindsDB has an MCP server built in&lt;/a&gt; that enables your MCP applications to connect, unify and respond to questions over large-scale federated data‚Äîspanning databases, data warehouses, and SaaS applications.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h1&gt;Core Philosophy: Connect, Unify, Respond&lt;/h1&gt; 
&lt;p&gt;MindsDB's architecture is built around three fundamental capabilities:&lt;/p&gt; 
&lt;h2&gt;&lt;a href="https://docs.mindsdb.com/integrations/data-overview"&gt;Connect&lt;/a&gt; Your Data&lt;/h2&gt; 
&lt;p&gt;You can connect to hundreds of enterprise &lt;a href="https://docs.mindsdb.com/integrations/data-overview"&gt;data sources (learn more)&lt;/a&gt;. These integrations allow MindsDB to access data wherever it resides, forming the foundation for all other capabilities.&lt;/p&gt; 
&lt;h2&gt;&lt;a href="https://docs.mindsdb.com/mindsdb_sql/overview"&gt;Unify&lt;/a&gt; Your Data&lt;/h2&gt; 
&lt;p&gt;In many situations, it‚Äôs important to be able to prepare and unify data before generating responses from it. MindsDB SQL offers knowledge bases and views that allow indexing and organizing structured and unstructured data as if it were unified in a single system.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.mindsdb.com/mindsdb_sql/knowledge-bases"&gt;&lt;strong&gt;KNOWLEDGE BASES&lt;/strong&gt;&lt;/a&gt; ‚Äì Index and organize unstructured data for efficient Q&amp;amp;A.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.mindsdb.com/mindsdb_sql/sql/create/view"&gt;&lt;strong&gt;VIEWS&lt;/strong&gt;&lt;/a&gt; ‚Äì Simplify data access by creating unified views across different sources (no-ETL).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Unification of data can be automated using JOBs&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.mindsdb.com/mindsdb_sql/sql/create/jobs"&gt;&lt;strong&gt;JOBS&lt;/strong&gt;&lt;/a&gt; ‚Äì Schedule synchronization and transformation tasks for real-time processing.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;&lt;a href="https://docs.mindsdb.com/mindsdb_sql/agents/agent"&gt;Respond&lt;/a&gt; From Your Data&lt;/h2&gt; 
&lt;p&gt;Chat with Your Data&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.mindsdb.com/mindsdb_sql/agents/agent"&gt;&lt;strong&gt;AGENTS&lt;/strong&gt;&lt;/a&gt; ‚Äì Configure built-in agents specialized in answering questions over your connected and unified data.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.mindsdb.com/mcp/overview"&gt;&lt;strong&gt;MCP&lt;/strong&gt;&lt;/a&gt; ‚Äì Connect to MindsDB through the MCP (Model Context Protocol) for seamless interaction.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ü§ù Contribute&lt;/h2&gt; 
&lt;p&gt;Interested in contributing to MindsDB? Follow our &lt;a href="https://docs.mindsdb.com/contribute/install?utm_medium=community&amp;amp;utm_source=github&amp;amp;utm_campaign=mindsdb%20repo"&gt;installation guide for development&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;You can find our &lt;a href="https://docs.mindsdb.com/contribute/contribute?utm_medium=community&amp;amp;utm_source=github&amp;amp;utm_campaign=mindsdb%20repo"&gt;contribution guide here&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;We welcome suggestions! Feel free to open new issues with your ideas, and we‚Äôll guide you.&lt;/p&gt; 
&lt;p&gt;This project adheres to a &lt;a href="https://github.com/mindsdb/mindsdb/raw/main/CODE_OF_CONDUCT.md"&gt;Contributor Code of Conduct&lt;/a&gt;. By participating, you agree to follow its terms.&lt;/p&gt; 
&lt;p&gt;Also, check out our &lt;a href="https://mindsdb.com/community?utm_medium=community&amp;amp;utm_source=github&amp;amp;utm_campaign=mindsdb%20repo"&gt;community rewards and programs&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;ü§ç Support&lt;/h2&gt; 
&lt;p&gt;If you find a bug, please submit an &lt;a href="https://github.com/mindsdb/mindsdb/issues/new/choose"&gt;issue on GitHub&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Here‚Äôs how you can get community support:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Ask a question in our &lt;a href="https://mindsdb.com/joincommunity?utm_medium=community&amp;amp;utm_source=github&amp;amp;utm_campaign=mindsdb%20repo"&gt;Slack Community&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Join our &lt;a href="https://github.com/mindsdb/mindsdb/discussions"&gt;GitHub Discussions&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Post on &lt;a href="https://stackoverflow.com/questions/tagged/mindsdb"&gt;Stack Overflow&lt;/a&gt; with the MindsDB tag.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For commercial support, please &lt;a href="https://mindsdb.com/contact?utm_medium=community&amp;amp;utm_source=github&amp;amp;utm_campaign=mindsdb%20repo"&gt;contact the MindsDB team&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;üíö Current Contributors&lt;/h2&gt; 
&lt;a href="https://github.com/mindsdb/mindsdb/graphs/contributors"&gt; &lt;img src="https://contributors-img.web.app/image?repo=mindsdb/mindsdb" /&gt; &lt;/a&gt; 
&lt;p&gt;Generated with &lt;a href="https://contributors-img.web.app"&gt;contributors-img&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;üîî Subscribe for Updates&lt;/h2&gt; 
&lt;p&gt;Join our &lt;a href="https://mindsdb.com/joincommunity"&gt;Slack community&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>666ghj/BettaFish</title>
      <link>https://github.com/666ghj/BettaFish</link>
      <description>&lt;p&gt;ÂæÆËàÜÔºö‰∫∫‰∫∫ÂèØÁî®ÁöÑÂ§öAgentËàÜÊÉÖÂàÜÊûêÂä©ÊâãÔºåÊâìÁ†¥‰ø°ÊÅØËåßÊàøÔºåËøòÂéüËàÜÊÉÖÂéüË≤åÔºåÈ¢ÑÊµãÊú™Êù•Ëµ∞ÂêëÔºåËæÖÂä©ÂÜ≥Á≠ñÔºÅ‰ªé0ÂÆûÁé∞Ôºå‰∏ç‰æùËµñ‰ªª‰ΩïÊ°ÜÊû∂„ÄÇ&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/666ghj/BettaFish/main/static/image/logo_compressed.png" alt="BettaFish Logo" width="100%" /&gt; 
 &lt;p&gt;&lt;a href="https://trendshift.io/repositories/15286" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/15286" alt="666ghj%2FBettaFish | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://aihubmix.com/?aff=8Ds9" target="_blank"&gt;&lt;img src="https://raw.githubusercontent.com/666ghj/BettaFish/main/static/image/logo_aihubmix.png" alt="666ghj%2FBettaFish | Trendshift" height="40" /&gt;&lt;/a&gt;‚ÄÇ &lt;a href="https://lioncc.ai/" target="_blank"&gt;&lt;img src="https://raw.githubusercontent.com/666ghj/BettaFish/main/static/image/logo_loincc.png" alt="666ghj%2FBettaFish | Trendshift" height="40" /&gt;&lt;/a&gt;‚ÄÇ &lt;a href="https://share.302.ai/P66Qe3" target="_blank"&gt;&lt;img src="https://raw.githubusercontent.com/666ghj/BettaFish/main/static/image/logo_302ai.png" alt="666ghj%2FBettaFish | Trendshift" height="40" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://github.com/666ghj/BettaFish/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/666ghj/BettaFish?style=flat-square" alt="GitHub Stars" /&gt;&lt;/a&gt; &lt;a href="https://github.com/666ghj/BettaFish/watchers"&gt;&lt;img src="https://img.shields.io/github/watchers/666ghj/BettaFish?style=flat-square" alt="GitHub Watchers" /&gt;&lt;/a&gt; &lt;a href="https://github.com/666ghj/BettaFish/network"&gt;&lt;img src="https://img.shields.io/github/forks/666ghj/BettaFish?style=flat-square" alt="GitHub Forks" /&gt;&lt;/a&gt; &lt;a href="https://github.com/666ghj/BettaFish/issues"&gt;&lt;img src="https://img.shields.io/github/issues/666ghj/BettaFish?style=flat-square" alt="GitHub Issues" /&gt;&lt;/a&gt; &lt;a href="https://github.com/666ghj/BettaFish/pulls"&gt;&lt;img src="https://img.shields.io/github/issues-pr/666ghj/BettaFish?style=flat-square" alt="GitHub Pull Requests" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://github.com/666ghj/BettaFish/raw/main/LICENSE"&gt;&lt;img src="https://img.shields.io/github/license/666ghj/BettaFish?style=flat-square" alt="GitHub License" /&gt;&lt;/a&gt; &lt;a href="https://github.com/666ghj/BettaFish"&gt;&lt;img src="https://img.shields.io/badge/version-v1.2.1-green.svg?style=flat-square" alt="Version" /&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/"&gt;&lt;img src="https://img.shields.io/badge/Docker-Build-2496ED?style=flat-square&amp;amp;logo=docker&amp;amp;logoColor=white" alt="Docker" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/666ghj/BettaFish/main/README-EN.md"&gt;English&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/666ghj/BettaFish/main/README.md"&gt;‰∏≠ÊñáÊñáÊ°£&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;üåü Âä†ÂÖ•ÂÆòÊñπ‰∫§ÊµÅÁæ§&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://capsule-render.vercel.app/api?type=waving&amp;amp;color=gradient&amp;amp;height=200&amp;amp;section=header&amp;amp;text=Ê¨¢ËøéÂä†ÂÖ•Êàë‰ª¨ÁöÑÊäÄÊúØ‰∫§ÊµÅQQÁæ§ÔºÅ&amp;amp;fontSize=40&amp;amp;fontAlignY=35&amp;amp;desc=Êâ´Êèè‰∏ãÊñπ‰∫åÁª¥Á†ÅÂä†ÂÖ•Áæ§ËÅä&amp;amp;descAlignY=55" alt="Ê¨¢ËøéÂä†ÂÖ•Êàë‰ª¨ÁöÑÊäÄÊúØ‰∫§ÊµÅQQÁæ§ÔºÅ" style="width:60%; max-width:900px; display:block; margin:0 auto;" /&gt; 
 &lt;img src="https://raw.githubusercontent.com/666ghj/BettaFish/main/static/image/QQ_Light_Horizenal.png" alt="BettaFish ÊäÄÊúØ‰∫§ÊµÅÁæ§‰∫åÁª¥Á†Å" style="width:60%; max-width:360px; display:block; margin:20px auto 0;" /&gt; 
&lt;/div&gt; 
&lt;h2&gt;‚ö° È°πÁõÆÊ¶ÇËø∞&lt;/h2&gt; 
&lt;p&gt;‚Äú&lt;strong&gt;ÂæÆËàÜ&lt;/strong&gt;‚Äù ÊòØ‰∏Ä‰∏™‰ªé0ÂÆûÁé∞ÁöÑÂàõÊñ∞Âûã Â§öÊô∫ËÉΩ‰Ωì ËàÜÊÉÖÂàÜÊûêÁ≥ªÁªüÔºåÂ∏ÆÂä©Â§ßÂÆ∂Á†¥Èô§‰ø°ÊÅØËåßÊàøÔºåËøòÂéüËàÜÊÉÖÂéüË≤åÔºåÈ¢ÑÊµãÊú™Êù•Ëµ∞ÂêëÔºåËæÖÂä©ÂÜ≥Á≠ñ„ÄÇÁî®Êà∑Âè™ÈúÄÂÉèËÅäÂ§©‰∏ÄÊ†∑ÊèêÂá∫ÂàÜÊûêÈúÄÊ±ÇÔºåÊô∫ËÉΩ‰ΩìÂºÄÂßãÂÖ®Ëá™Âä®ÂàÜÊûê ÂõΩÂÜÖÂ§ñ30+‰∏ªÊµÅÁ§æÂ™í ‰∏é Êï∞Áôæ‰∏áÊù°Â§ß‰ºóËØÑËÆ∫„ÄÇ&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;‚ÄúÂæÆËàÜ‚ÄùË∞êÈü≥‚ÄúÂæÆÈ±º‚ÄùÔºåBettaFishÊòØ‰∏ÄÁßç‰ΩìÂûãÂæàÂ∞è‰ΩÜÈùûÂ∏∏Â•ΩÊñó„ÄÅÊºÇ‰∫ÆÁöÑÈ±ºÔºåÂÆÉË±°ÂæÅÁùÄ‚ÄúÂ∞èËÄåÂº∫Â§ßÔºå‰∏çÁïèÊåëÊàò‚Äù&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Êü•ÁúãÁ≥ªÁªü‰ª•‚ÄúÊ≠¶Ê±âÂ§ßÂ≠¶ËàÜÊÉÖ‚Äù‰∏∫‰æãÔºåÁîüÊàêÁöÑÁ†îÁ©∂Êä•ÂëäÔºö&lt;a href="https://raw.githubusercontent.com/666ghj/BettaFish/main/final_reports/final_report__20250827_131630.html"&gt;Ê≠¶Ê±âÂ§ßÂ≠¶ÂìÅÁâåÂ£∞Ë™âÊ∑±Â∫¶ÂàÜÊûêÊä•Âëä&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Êü•ÁúãÁ≥ªÁªü‰ª•‚ÄúÊ≠¶Ê±âÂ§ßÂ≠¶ËàÜÊÉÖ‚Äù‰∏∫‰æãÔºå‰∏ÄÊ¨°ÂÆåÊï¥ËøêË°åÁöÑËßÜÈ¢ëÔºö&lt;a href="https://www.bilibili.com/video/BV1TH1WBxEWN/?vd_source=da3512187e242ce17dceee4c537ec7a6#reply279744466833"&gt;ËßÜÈ¢ë-Ê≠¶Ê±âÂ§ßÂ≠¶ÂìÅÁâåÂ£∞Ë™âÊ∑±Â∫¶ÂàÜÊûêÊä•Âëä&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;‰∏ç‰ªÖ‰ªÖ‰ΩìÁé∞Âú®Êä•ÂëäË¥®Èáè‰∏äÔºåÁõ∏ÊØîÂêåÁ±ª‰∫ßÂìÅÔºåÊàë‰ª¨Êã•ÊúâüöÄÂÖ≠Â§ß‰ºòÂäøÔºö&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;AIÈ©±Âä®ÁöÑÂÖ®ÂüüÁõëÊéß&lt;/strong&gt;ÔºöAIÁà¨Ëô´ÈõÜÁæ§7x24Â∞èÊó∂‰∏çÈó¥Êñ≠‰Ωú‰∏öÔºåÂÖ®Èù¢Ë¶ÜÁõñÂæÆÂçö„ÄÅÂ∞èÁ∫¢‰π¶„ÄÅÊäñÈü≥„ÄÅÂø´ÊâãÁ≠â10+ÂõΩÂÜÖÂ§ñÂÖ≥ÈîÆÁ§æÂ™í„ÄÇ‰∏ç‰ªÖÂÆûÊó∂ÊçïËé∑ÁÉ≠ÁÇπÂÜÖÂÆπÔºåÊõ¥ËÉΩ‰∏ãÈíªËá≥Êµ∑ÈáèÁî®Êà∑ËØÑËÆ∫ÔºåËÆ©ÊÇ®Âê¨Âà∞ÊúÄÁúüÂÆû„ÄÅÊúÄÂπøÊ≥õÁöÑÂ§ß‰ºóÂ£∞Èü≥„ÄÇ&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Ë∂ÖË∂äLLMÁöÑÂ§çÂêàÂàÜÊûêÂºïÊìé&lt;/strong&gt;ÔºöÊàë‰ª¨‰∏ç‰ªÖ‰æùËµñËÆæËÆ°ÁöÑ5Á±ª‰∏ì‰∏öAgentÔºåÊõ¥ËûçÂêà‰∫ÜÂæÆË∞ÉÊ®°Âûã„ÄÅÁªüËÆ°Ê®°ÂûãÁ≠â‰∏≠Èó¥‰ª∂„ÄÇÈÄöËøáÂ§öÊ®°ÂûãÂçèÂêåÂ∑•‰ΩúÔºåÁ°Æ‰øù‰∫ÜÂàÜÊûêÁªìÊûúÁöÑÊ∑±Â∫¶„ÄÅÂáÜÂ∫¶‰∏éÂ§öÁª¥ËßÜËßí„ÄÇ&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Âº∫Â§ßÁöÑÂ§öÊ®°ÊÄÅËÉΩÂäõ&lt;/strong&gt;ÔºöÁ™ÅÁ†¥ÂõæÊñáÈôêÂà∂ÔºåËÉΩÊ∑±Â∫¶Ëß£ÊûêÊäñÈü≥„ÄÅÂø´ÊâãÁ≠âÁü≠ËßÜÈ¢ëÂÜÖÂÆπÔºåÂπ∂Á≤æÂáÜÊèêÂèñÁé∞‰ª£ÊêúÁ¥¢ÂºïÊìé‰∏≠ÁöÑÂ§©Ê∞î„ÄÅÊó•ÂéÜ„ÄÅËÇ°Á•®Á≠âÁªìÊûÑÂåñÂ§öÊ®°ÊÄÅ‰ø°ÊÅØÂç°ÁâáÔºåËÆ©ÊÇ®ÂÖ®Èù¢ÊéåÊè°ËàÜÊÉÖÂä®ÊÄÅ„ÄÇ&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Agent‚ÄúËÆ∫Âùõ‚ÄùÂçè‰ΩúÊú∫Âà∂&lt;/strong&gt;Ôºö‰∏∫‰∏çÂêåAgentËµã‰∫àÁã¨ÁâπÁöÑÂ∑•ÂÖ∑ÈõÜ‰∏éÊÄùÁª¥Ê®°ÂºèÔºåÂºïÂÖ•Ëæ©ËÆ∫‰∏ªÊåÅ‰∫∫Ê®°ÂûãÔºåÈÄöËøá‚ÄúËÆ∫Âùõ‚ÄùÊú∫Âà∂ËøõË°åÈìæÂºèÊÄùÁª¥Á¢∞Êíû‰∏éËæ©ËÆ∫„ÄÇËøô‰∏ç‰ªÖÈÅøÂÖç‰∫ÜÂçï‰∏ÄÊ®°ÂûãÁöÑÊÄùÁª¥Â±ÄÈôê‰∏é‰∫§ÊµÅÂØºËá¥ÁöÑÂêåË¥®ÂåñÔºåÊõ¥ÂÇ¨ÁîüÂá∫Êõ¥È´òË¥®ÈáèÁöÑÈõÜ‰ΩìÊô∫ËÉΩ‰∏éÂÜ≥Á≠ñÊîØÊåÅ„ÄÇ&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;ÂÖ¨ÁßÅÂüüÊï∞ÊçÆÊó†ÁºùËûçÂêà&lt;/strong&gt;ÔºöÂπ≥Âè∞‰∏ç‰ªÖÂàÜÊûêÂÖ¨ÂºÄËàÜÊÉÖÔºåËøòÊèê‰æõÈ´òÂÆâÂÖ®ÊÄßÁöÑÊé•Âè£ÔºåÊîØÊåÅÊÇ®Â∞ÜÂÜÖÈÉ®‰∏öÂä°Êï∞ÊçÆÂ∫ì‰∏éËàÜÊÉÖÊï∞ÊçÆÊó†ÁºùÈõÜÊàê„ÄÇÊâìÈÄöÊï∞ÊçÆÂ£ÅÂûíÔºå‰∏∫ÂûÇÁõ¥‰∏öÂä°Êèê‰æõ‚ÄúÂ§ñÈÉ®Ë∂ãÂäø+ÂÜÖÈÉ®Ê¥ûÂØü‚ÄùÁöÑÂº∫Â§ßÂàÜÊûêËÉΩÂäõ„ÄÇ&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;ËΩªÈáèÂåñ‰∏éÈ´òÊâ©Â±ïÊÄßÊ°ÜÊû∂&lt;/strong&gt;ÔºöÂü∫‰∫éÁ∫ØPythonÊ®°ÂùóÂåñËÆæËÆ°ÔºåÂÆûÁé∞ËΩªÈáèÂåñ„ÄÅ‰∏ÄÈîÆÂºèÈÉ®ÁΩ≤„ÄÇ‰ª£Á†ÅÁªìÊûÑÊ∏ÖÊô∞ÔºåÂºÄÂèëËÄÖÂèØËΩªÊùæÈõÜÊàêËá™ÂÆö‰πâÊ®°Âûã‰∏é‰∏öÂä°ÈÄªËæëÔºåÂÆûÁé∞Âπ≥Âè∞ÁöÑÂø´ÈÄüÊâ©Â±ï‰∏éÊ∑±Â∫¶ÂÆöÂà∂„ÄÇ&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;Âßã‰∫éËàÜÊÉÖÔºåËÄå‰∏çÊ≠¢‰∫éËàÜÊÉÖ&lt;/strong&gt;„ÄÇ‚ÄúÂæÆËàÜ‚ÄùÁöÑÁõÆÊ†áÔºåÊòØÊàê‰∏∫È©±Âä®‰∏ÄÂàá‰∏öÂä°Âú∫ÊôØÁöÑÁÆÄÊ¥ÅÈÄöÁî®ÁöÑÊï∞ÊçÆÂàÜÊûêÂºïÊìé„ÄÇ&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;‰∏æ‰∏™‰æãÂ≠ê. ‰Ω†Âè™ÈúÄÁÆÄÂçï‰øÆÊîπAgentÂ∑•ÂÖ∑ÈõÜÁöÑapiÂèÇÊï∞‰∏épromptÔºåÂ∞±ÂèØ‰ª•Êää‰ªñÂèòÊàê‰∏Ä‰∏™ÈáëËûçÈ¢ÜÂüüÁöÑÂ∏ÇÂú∫ÂàÜÊûêÁ≥ªÁªü&lt;/p&gt; 
 &lt;p&gt;ÈôÑ‰∏Ä‰∏™ÊØîËæÉÊ¥ªË∑ÉÁöÑLÁ´ôÈ°πÁõÆËÆ®ËÆ∫Â∏ñÔºö&lt;a href="https://linux.do/t/topic/1009280"&gt;https://linux.do/t/topic/1009280&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;Êü•ÁúãLÁ´ô‰Ω¨ÂèãÂÅöÁöÑÊµãËØÑ &lt;a href="https://linux.do/t/topic/1148040"&gt;ÂºÄÊ∫êÈ°πÁõÆ(ÂæÆËàÜ)‰∏émanus|minimax|ChatGPTÂØπÊØî&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/666ghj/BettaFish/main/static/image/system_schematic.png" alt="banner" width="800" /&gt; 
 &lt;p&gt;ÂëäÂà´‰º†ÁªüÁöÑÊï∞ÊçÆÁúãÊùøÔºåÂú®‚ÄúÂæÆËàÜ‚ÄùÔºå‰∏ÄÂàáÁî±‰∏Ä‰∏™ÁÆÄÂçïÁöÑÈóÆÈ¢òÂºÄÂßãÔºåÊÇ®Âè™ÈúÄÂÉèÂØπËØù‰∏ÄÊ†∑ÔºåÊèêÂá∫ÊÇ®ÁöÑÂàÜÊûêÈúÄÊ±Ç&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;ü™Ñ ËµûÂä©ÂïÜ&lt;/h2&gt; 
&lt;p&gt;LLMÊ®°ÂûãAPIËµûÂä©Ôºö&lt;a href="https://aihubmix.com/?aff=8Ds9" target="_blank"&gt;&lt;img src="https://raw.githubusercontent.com/666ghj/BettaFish/main/static/image/logo_aihubmix.png" alt="666ghj%2FBettaFish | Trendshift" height="40" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;(ÁÇπÂºÄ‚ñ∂ÊúâËµûÂä©LLMÁÆóÂäõÁ¶èÂà©)ÁºñÁ®ãÊãºËΩ¶codecodex.aiÔºõÁºñÁ®ãÁÆóÂäõVibeCodingAPI.aiÔºö&lt;span style="margin-left: 10px"&gt;&lt;a href="https://codecodex.ai/" target="_blank"&gt;&lt;img src="https://raw.githubusercontent.com/666ghj/BettaFish/main/static/image/logo_loincc.png" alt="666ghj%2FBettaFish | Trendshift" height="40" /&gt;&lt;/a&gt;&lt;/span&gt;&lt;/summary&gt; 
 &lt;ol&gt; 
  &lt;li&gt;ÊâÄÁΩóÈó®ÂçöÂÆ¢LionCC.aiÂ∑≤Êõ¥Êñ∞„ÄäBettaFish ÂæÆËàÜÁ≥ªÁªü - LionCC API ÈÉ®ÁΩ≤ÈÖçÁΩÆÂÆåÂÖ®ÊåáÂçó„ÄãÊ≠£Âú®‰∫åÂºÄ‰ºòÂåñ‰∏ÄÈîÆÈÉ®ÁΩ≤Âíå‰∫ëÊúçÂä°Âô®Ë∞ÉÁî®ÊñπÊ°à„ÄÇ&lt;/li&gt; 
  &lt;li&gt;VibeCodingapi.aiÁãÆÂ≠êÁÆóÂäõÂπ≥Âè∞Â∑≤ÁªèÈÄÇÈÖç„ÄäBettaFish ÂæÆËàÜÁ≥ªÁªü„ÄãÊâÄÊúâLLMÊ®°ÂûãÂê´claude codeÂíåopenai codexÂíågemini cliÁºñÁ®ãÂºÄÂèë‰∏âÂ∑®Â§¥ÁÆóÂäõ„ÄÇÈ¢ùÂ∫¶‰ª∑Ê†ºÔºåÂè™Ë¶Å‰∏ÄÊØî‰∏ÄÔºà100ÂÖÉÁ≠â‰∫é100ÁæéÂàÄÈ¢ùÂ∫¶Ôºâ&lt;/li&gt; 
  &lt;li&gt;Codecodex.aiÁãÆÂ≠êÁºñÁ®ãÊãºËΩ¶Á≥ªÁªüÔºåÂ∑≤ÂÆûÁé∞Êó†IPÈó®ÊßõÁªïËøáclaude codeÂíåopenai codexÂ∞ÅÈîÅÔºåÊåâÂÆòÊñπÈÉ®ÁΩ≤ÊïôÁ®ãÂêéÂàáÊç¢BASE_URLË∞ÉÁî®Âú∞ÂùÄÂíåToken keyË∞ÉÁî®ÂØÜÈí•Âç≥ÂèØ‰ΩøÁî®ÊúÄÂº∫ÁºñÁ®ãÊ®°Âûã„ÄÇ&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;p&gt;ÊâÄÁΩóÈó®LionCCËµûÂä©BettaFish ÂæÆËàÜÁ¶èÂà©ÔºöÊâìÂºÄcodecodex.aiÁãÆÂ≠êÁºñÁ®ãÈ¢ëÈÅìÊâ´Á†ÅÂä†ÂÖ•ÂæÆ‰ø°Á§æÁæ§ÔºåÊ≥®ÂÜåVibeCodingapi.aiÁãÆÂ≠êÁÆóÂäõÔºåÁªü‰∏ÄÈÄÅ20ÂàÄAPIÈ¢ùÂ∫¶Ôºà‰ªÖÈôêÂâç‰∏ÄÂçÉÂêçÔºâ&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;ÊåâÁî®Èáè‰ªòË¥πÁöÑ‰ºÅ‰∏öÁ∫ßAIËµÑÊ∫êÂπ≥Âè∞ÔºåÊèê‰æõÂ∏ÇÂú∫‰∏äÂÖ®Èù¢ÁöÑAIÊ®°ÂûãÂíåAPIÔºå‰ª•ÂèäÂ§öÁßçÂú®Á∫øAIÂ∫îÁî®Ôºö&lt;span style="margin-left: 10px"&gt;&lt;a href="https://share.302.ai/P66Qe3" target="_blank"&gt;&lt;img src="https://raw.githubusercontent.com/666ghj/BettaFish/main/static/image/logo_302ai.png" alt="666ghj%2FBettaFish | Trendshift" height="40" /&gt;&lt;/a&gt;&lt;/span&gt;&lt;/summary&gt; 
 &lt;img src="https://raw.githubusercontent.com/666ghj/BettaFish/main/static/image/banner_302ai_ch.jpg" alt="banner" /&gt;302.AIÊòØ‰∏Ä‰∏™ÊåâÁî®Èáè‰ªòË¥πÁöÑ‰ºÅ‰∏öÁ∫ßAIËµÑÊ∫êÂπ≥Âè∞ÔºåÊèê‰æõÂ∏ÇÂú∫‰∏äÊúÄÊñ∞„ÄÅÊúÄÂÖ®Èù¢ÁöÑAIÊ®°ÂûãÂíåAPIÔºå‰ª•ÂèäÂ§öÁßçÂºÄÁÆ±Âç≥Áî®ÁöÑÂú®Á∫øAIÂ∫îÁî®„ÄÇ 
&lt;/details&gt; 
&lt;h2&gt;üèóÔ∏è Á≥ªÁªüÊû∂ÊûÑ&lt;/h2&gt; 
&lt;h3&gt;Êï¥‰ΩìÊû∂ÊûÑÂõæ&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Insight Agent&lt;/strong&gt; ÁßÅÊúâÊï∞ÊçÆÂ∫ìÊåñÊéòÔºöÁßÅÊúâËàÜÊÉÖÊï∞ÊçÆÂ∫ìÊ∑±Â∫¶ÂàÜÊûêAI‰ª£ÁêÜ&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Media Agent&lt;/strong&gt; Â§öÊ®°ÊÄÅÂÜÖÂÆπÂàÜÊûêÔºöÂÖ∑Â§áÂº∫Â§ßÂ§öÊ®°ÊÄÅËÉΩÂäõÁöÑAI‰ª£ÁêÜ&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Query Agent&lt;/strong&gt; Á≤æÂáÜ‰ø°ÊÅØÊêúÁ¥¢ÔºöÂÖ∑Â§áÂõΩÂÜÖÂ§ñÁΩëÈ°µÊêúÁ¥¢ËÉΩÂäõÁöÑAI‰ª£ÁêÜ&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Report Agent&lt;/strong&gt; Êô∫ËÉΩÊä•ÂëäÁîüÊàêÔºöÂÜÖÁΩÆÊ®°ÊùøÁöÑÂ§öËΩÆÊä•ÂëäÁîüÊàêAI‰ª£ÁêÜ&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/666ghj/BettaFish/main/static/image/framework.png" alt="banner" width="800" /&gt; 
&lt;/div&gt; 
&lt;h3&gt;‰∏ÄÊ¨°ÂÆåÊï¥ÂàÜÊûêÊµÅÁ®ã&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Ê≠•È™§&lt;/th&gt; 
   &lt;th&gt;Èò∂ÊÆµÂêçÁß∞&lt;/th&gt; 
   &lt;th&gt;‰∏ªË¶ÅÊìç‰Ωú&lt;/th&gt; 
   &lt;th&gt;ÂèÇ‰∏éÁªÑ‰ª∂&lt;/th&gt; 
   &lt;th&gt;Âæ™ÁéØÁâπÊÄß&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;1&lt;/td&gt; 
   &lt;td&gt;Áî®Êà∑ÊèêÈóÆ&lt;/td&gt; 
   &lt;td&gt;Flask‰∏ªÂ∫îÁî®Êé•Êî∂Êü•ËØ¢&lt;/td&gt; 
   &lt;td&gt;Flask‰∏ªÂ∫îÁî®&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;2&lt;/td&gt; 
   &lt;td&gt;Âπ∂Ë°åÂêØÂä®&lt;/td&gt; 
   &lt;td&gt;‰∏â‰∏™AgentÂêåÊó∂ÂºÄÂßãÂ∑•‰Ωú&lt;/td&gt; 
   &lt;td&gt;Query Agent„ÄÅMedia Agent„ÄÅInsight Agent&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;3&lt;/td&gt; 
   &lt;td&gt;ÂàùÊ≠•ÂàÜÊûê&lt;/td&gt; 
   &lt;td&gt;ÂêÑAgent‰ΩøÁî®‰∏ìÂ±ûÂ∑•ÂÖ∑ËøõË°åÊ¶ÇËßàÊêúÁ¥¢&lt;/td&gt; 
   &lt;td&gt;ÂêÑAgent + ‰∏ìÂ±ûÂ∑•ÂÖ∑ÈõÜ&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;4&lt;/td&gt; 
   &lt;td&gt;Á≠ñÁï•Âà∂ÂÆö&lt;/td&gt; 
   &lt;td&gt;Âü∫‰∫éÂàùÊ≠•ÁªìÊûúÂà∂ÂÆöÂàÜÂùóÁ†îÁ©∂Á≠ñÁï•&lt;/td&gt; 
   &lt;td&gt;ÂêÑAgentÂÜÖÈÉ®ÂÜ≥Á≠ñÊ®°Âùó&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;5-N&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Âæ™ÁéØÈò∂ÊÆµ&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;ËÆ∫ÂùõÂçè‰Ωú + Ê∑±Â∫¶Á†îÁ©∂&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;ForumEngine + ÊâÄÊúâAgent&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Â§öËΩÆÂæ™ÁéØ&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;5.1&lt;/td&gt; 
   &lt;td&gt;Ê∑±Â∫¶Á†îÁ©∂&lt;/td&gt; 
   &lt;td&gt;ÂêÑAgentÂü∫‰∫éËÆ∫Âùõ‰∏ªÊåÅ‰∫∫ÂºïÂØºËøõË°å‰∏ìÈ°πÊêúÁ¥¢&lt;/td&gt; 
   &lt;td&gt;ÂêÑAgent + ÂèçÊÄùÊú∫Âà∂ + ËÆ∫ÂùõÂºïÂØº&lt;/td&gt; 
   &lt;td&gt;ÊØèËΩÆÂæ™ÁéØ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;5.2&lt;/td&gt; 
   &lt;td&gt;ËÆ∫ÂùõÂçè‰Ωú&lt;/td&gt; 
   &lt;td&gt;ForumEngineÁõëÊéßAgentÂèëË®ÄÂπ∂ÁîüÊàê‰∏ªÊåÅ‰∫∫ÊÄªÁªì&lt;/td&gt; 
   &lt;td&gt;ForumEngine + LLM‰∏ªÊåÅ‰∫∫&lt;/td&gt; 
   &lt;td&gt;ÊØèËΩÆÂæ™ÁéØ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;5.3&lt;/td&gt; 
   &lt;td&gt;‰∫§ÊµÅËûçÂêà&lt;/td&gt; 
   &lt;td&gt;ÂêÑAgentÊ†πÊçÆËÆ®ËÆ∫Ë∞ÉÊï¥Á†îÁ©∂ÊñπÂêë&lt;/td&gt; 
   &lt;td&gt;ÂêÑAgent + forum_readerÂ∑•ÂÖ∑&lt;/td&gt; 
   &lt;td&gt;ÊØèËΩÆÂæ™ÁéØ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;N+1&lt;/td&gt; 
   &lt;td&gt;ÁªìÊûúÊï¥Âêà&lt;/td&gt; 
   &lt;td&gt;Report AgentÊî∂ÈõÜÊâÄÊúâÂàÜÊûêÁªìÊûúÂíåËÆ∫ÂùõÂÜÖÂÆπ&lt;/td&gt; 
   &lt;td&gt;Report Agent&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;N+2&lt;/td&gt; 
   &lt;td&gt;Êä•ÂëäÁîüÊàê&lt;/td&gt; 
   &lt;td&gt;Âä®ÊÄÅÈÄâÊã©Ê®°ÊùøÂíåÊ†∑ÂºèÔºåÂ§öËΩÆÁîüÊàêÊúÄÁªàÊä•Âëä&lt;/td&gt; 
   &lt;td&gt;Report Agent + Ê®°ÊùøÂºïÊìé&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;È°πÁõÆ‰ª£Á†ÅÁªìÊûÑÊ†ë&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;BettaFish/
‚îú‚îÄ‚îÄ QueryEngine/                   # ÂõΩÂÜÖÂ§ñÊñ∞ÈóªÂπøÂ∫¶ÊêúÁ¥¢Agent
‚îÇ   ‚îú‚îÄ‚îÄ agent.py                   # Agent‰∏ªÈÄªËæë
‚îÇ   ‚îú‚îÄ‚îÄ llms/                      # LLMÊé•Âè£Â∞ÅË£Ö
‚îÇ   ‚îú‚îÄ‚îÄ nodes/                     # Â§ÑÁêÜËäÇÁÇπ
‚îÇ   ‚îú‚îÄ‚îÄ tools/                     # ÊêúÁ¥¢Â∑•ÂÖ∑
‚îÇ   ‚îú‚îÄ‚îÄ utils/                     # Â∑•ÂÖ∑ÂáΩÊï∞
‚îÇ   ‚îî‚îÄ‚îÄ ...                        # ÂÖ∂‰ªñÊ®°Âùó
‚îú‚îÄ‚îÄ MediaEngine/                   # Âº∫Â§ßÁöÑÂ§öÊ®°ÊÄÅÁêÜËß£Agent
‚îÇ   ‚îú‚îÄ‚îÄ agent.py                   # Agent‰∏ªÈÄªËæë
‚îÇ   ‚îú‚îÄ‚îÄ nodes/                     # Â§ÑÁêÜËäÇÁÇπ
‚îÇ   ‚îú‚îÄ‚îÄ llms/                      # LLMÊé•Âè£
‚îÇ   ‚îú‚îÄ‚îÄ tools/                     # ÊêúÁ¥¢Â∑•ÂÖ∑
‚îÇ   ‚îú‚îÄ‚îÄ utils/                     # Â∑•ÂÖ∑ÂáΩÊï∞
‚îÇ   ‚îî‚îÄ‚îÄ ...                        # ÂÖ∂‰ªñÊ®°Âùó
‚îú‚îÄ‚îÄ InsightEngine/                 # ÁßÅÊúâÊï∞ÊçÆÂ∫ìÊåñÊéòAgent
‚îÇ   ‚îú‚îÄ‚îÄ agent.py                   # Agent‰∏ªÈÄªËæë
‚îÇ   ‚îú‚îÄ‚îÄ llms/                      # LLMÊé•Âè£Â∞ÅË£Ö
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ base.py                # Áªü‰∏ÄÁöÑ OpenAI ÂÖºÂÆπÂÆ¢Êà∑Á´Ø
‚îÇ   ‚îú‚îÄ‚îÄ nodes/                     # Â§ÑÁêÜËäÇÁÇπ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ base_node.py           # Âü∫Á°ÄËäÇÁÇπÁ±ª
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ formatting_node.py     # Ê†ºÂºèÂåñËäÇÁÇπ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ report_structure_node.py # Êä•ÂëäÁªìÊûÑËäÇÁÇπ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ search_node.py         # ÊêúÁ¥¢ËäÇÁÇπ
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ summary_node.py        # ÊÄªÁªìËäÇÁÇπ
‚îÇ   ‚îú‚îÄ‚îÄ tools/                     # Êï∞ÊçÆÂ∫ìÊü•ËØ¢ÂíåÂàÜÊûêÂ∑•ÂÖ∑
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ keyword_optimizer.py   # QwenÂÖ≥ÈîÆËØç‰ºòÂåñ‰∏≠Èó¥‰ª∂
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ search.py              # Êï∞ÊçÆÂ∫ìÊìç‰ΩúÂ∑•ÂÖ∑ÈõÜ
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ sentiment_analyzer.py  # ÊÉÖÊÑüÂàÜÊûêÈõÜÊàêÂ∑•ÂÖ∑
‚îÇ   ‚îú‚îÄ‚îÄ state/                     # Áä∂ÊÄÅÁÆ°ÁêÜ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ state.py               # AgentÁä∂ÊÄÅÂÆö‰πâ
‚îÇ   ‚îú‚îÄ‚îÄ prompts/                   # ÊèêÁ§∫ËØçÊ®°Êùø
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ prompts.py             # ÂêÑÁ±ªÊèêÁ§∫ËØç
‚îÇ   ‚îî‚îÄ‚îÄ utils/                     # Â∑•ÂÖ∑ÂáΩÊï∞
‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îú‚îÄ‚îÄ config.py              # ÈÖçÁΩÆÁÆ°ÁêÜ
‚îÇ       ‚îî‚îÄ‚îÄ text_processing.py     # ÊñáÊú¨Â§ÑÁêÜÂ∑•ÂÖ∑
‚îú‚îÄ‚îÄ ReportEngine/                  # Â§öËΩÆÊä•ÂëäÁîüÊàêAgent
‚îÇ   ‚îú‚îÄ‚îÄ agent.py                   # Agent‰∏ªÈÄªËæë
‚îÇ   ‚îú‚îÄ‚îÄ llms/                      # LLMÊé•Âè£
‚îÇ   ‚îú‚îÄ‚îÄ nodes/                     # Êä•ÂëäÁîüÊàêËäÇÁÇπ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ template_selection.py  # Ê®°ÊùøÈÄâÊã©ËäÇÁÇπ
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ html_generation.py     # HTMLÁîüÊàêËäÇÁÇπ
‚îÇ   ‚îú‚îÄ‚îÄ report_template/           # Êä•ÂëäÊ®°ÊùøÂ∫ì
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Á§æ‰ºöÂÖ¨ÂÖ±ÁÉ≠ÁÇπ‰∫ã‰ª∂ÂàÜÊûê.md
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ÂïÜ‰∏öÂìÅÁâåËàÜÊÉÖÁõëÊµã.md
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...                    # Êõ¥Â§öÊ®°Êùø
‚îÇ   ‚îî‚îÄ‚îÄ flask_interface.py         # Flask APIÊé•Âè£
‚îú‚îÄ‚îÄ ForumEngine/                   # ËÆ∫ÂùõÂºïÊìéÁÆÄÊòìÂÆûÁé∞
‚îÇ   ‚îú‚îÄ‚îÄ monitor.py                 # Êó•ÂøóÁõëÊéßÂíåËÆ∫ÂùõÁÆ°ÁêÜ
‚îÇ   ‚îî‚îÄ‚îÄ llm_host.py                # ËÆ∫Âùõ‰∏ªÊåÅ‰∫∫LLMÊ®°Âùó
‚îú‚îÄ‚îÄ MindSpider/                    # ÂæÆÂçöÁà¨Ëô´Á≥ªÁªü
‚îÇ   ‚îú‚îÄ‚îÄ main.py                    # Áà¨Ëô´‰∏ªÁ®ãÂ∫è
‚îÇ   ‚îú‚îÄ‚îÄ config.py                  # Áà¨Ëô´ÈÖçÁΩÆÊñá‰ª∂
‚îÇ   ‚îú‚îÄ‚îÄ BroadTopicExtraction/      # ËØùÈ¢òÊèêÂèñÊ®°Âùó
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ database_manager.py    # Êï∞ÊçÆÂ∫ìÁÆ°ÁêÜÂô®
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ get_today_news.py      # ‰ªäÊó•Êñ∞ÈóªËé∑Âèñ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ main.py                # ËØùÈ¢òÊèêÂèñ‰∏ªÁ®ãÂ∫è
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ topic_extractor.py     # ËØùÈ¢òÊèêÂèñÂô®
‚îÇ   ‚îú‚îÄ‚îÄ DeepSentimentCrawling/     # Ê∑±Â∫¶ËàÜÊÉÖÁà¨Âèñ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ keyword_manager.py     # ÂÖ≥ÈîÆËØçÁÆ°ÁêÜÂô®
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ main.py                # Ê∑±Â∫¶Áà¨Âèñ‰∏ªÁ®ãÂ∫è
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ MediaCrawler/          # Â™í‰ΩìÁà¨Ëô´Ê†∏ÂøÉ
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ platform_crawler.py    # Âπ≥Âè∞Áà¨Ëô´ÁÆ°ÁêÜ
‚îÇ   ‚îî‚îÄ‚îÄ schema/                    # Êï∞ÊçÆÂ∫ìÁªìÊûÑ
‚îÇ       ‚îú‚îÄ‚îÄ db_manager.py          # Êï∞ÊçÆÂ∫ìÁÆ°ÁêÜÂô®
‚îÇ       ‚îú‚îÄ‚îÄ init_database.py       # Êï∞ÊçÆÂ∫ìÂàùÂßãÂåñ
‚îÇ       ‚îî‚îÄ‚îÄ mindspider_tables.sql  # Êï∞ÊçÆÂ∫ìË°®ÁªìÊûÑ
‚îú‚îÄ‚îÄ SentimentAnalysisModel/        # ÊÉÖÊÑüÂàÜÊûêÊ®°ÂûãÈõÜÂêà
‚îÇ   ‚îú‚îÄ‚îÄ WeiboSentiment_Finetuned/  # ÂæÆË∞ÉBERT/GPT-2Ê®°Âûã
‚îÇ   ‚îú‚îÄ‚îÄ WeiboMultilingualSentiment/# Â§öËØ≠Ë®ÄÊÉÖÊÑüÂàÜÊûêÔºàÊé®ËçêÔºâ
‚îÇ   ‚îú‚îÄ‚îÄ WeiboSentiment_SmallQwen/  # Â∞èÂèÇÊï∞Qwen3ÂæÆË∞É
‚îÇ   ‚îî‚îÄ‚îÄ WeiboSentiment_MachineLearning/ # ‰º†ÁªüÊú∫Âô®Â≠¶‰π†ÊñπÊ≥ï
‚îú‚îÄ‚îÄ SingleEngineApp/               # ÂçïÁã¨AgentÁöÑStreamlitÂ∫îÁî®
‚îÇ   ‚îú‚îÄ‚îÄ query_engine_streamlit_app.py
‚îÇ   ‚îú‚îÄ‚îÄ media_engine_streamlit_app.py
‚îÇ   ‚îî‚îÄ‚îÄ insight_engine_streamlit_app.py
‚îú‚îÄ‚îÄ templates/                     # FlaskÊ®°Êùø
‚îÇ   ‚îî‚îÄ‚îÄ index.html                 # ‰∏ªÁïåÈù¢ÂâçÁ´Ø
‚îú‚îÄ‚îÄ static/                        # ÈùôÊÄÅËµÑÊ∫ê
‚îú‚îÄ‚îÄ logs/                          # ËøêË°åÊó•ÂøóÁõÆÂΩï
‚îú‚îÄ‚îÄ final_reports/                 # ÊúÄÁªàÁîüÊàêÁöÑHTMLÊä•ÂëäÊñá‰ª∂
‚îú‚îÄ‚îÄ utils/                         # ÈÄöÁî®Â∑•ÂÖ∑ÂáΩÊï∞
‚îÇ   ‚îú‚îÄ‚îÄ forum_reader.py            # AgentÈó¥ËÆ∫ÂùõÈÄö‰ø°
‚îÇ   ‚îî‚îÄ‚îÄ retry_helper.py            # ÁΩëÁªúËØ∑Ê±ÇÈáçËØïÊú∫Âà∂Â∑•ÂÖ∑
‚îú‚îÄ‚îÄ app.py                         # Flask‰∏ªÂ∫îÁî®ÂÖ•Âè£
‚îú‚îÄ‚îÄ config.py                      # ÂÖ®Â±ÄÈÖçÁΩÆÊñá‰ª∂
‚îî‚îÄ‚îÄ requirements.txt               # Python‰æùËµñÂåÖÊ∏ÖÂçï
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;üöÄ Âø´ÈÄüÂºÄÂßãÔºàDockerÔºâ&lt;/h2&gt; 
&lt;h3&gt;1. ÂêØÂä®È°πÁõÆ&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;ËøêË°åÂëΩ‰ª§Ôºö&lt;/strong&gt; ÊâßË°å‰ª•‰∏ãÂëΩ‰ª§Âú®&lt;strong&gt;ÂêéÂè∞&lt;/strong&gt;ÂêØÂä®ÊâÄÊúâÊúçÂä°Ôºö&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker compose up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Ê≥®ÔºöÈïúÂÉèÊãâÂèñÈÄüÂ∫¶ÊÖ¢&lt;/strong&gt;ÔºåÂú®Âéü &lt;code&gt;docker-compose.yml&lt;/code&gt; Êñá‰ª∂‰∏≠ÔºåÊàë‰ª¨Â∑≤ÁªèÈÄöËøá&lt;strong&gt;Ê≥®Èáä&lt;/strong&gt;ÁöÑÊñπÂºèÊèê‰æõ‰∫ÜÂ§áÁî®ÈïúÂÉèÂú∞ÂùÄ‰æõÊÇ®ÊõøÊç¢&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;2. ÈÖçÁΩÆËØ¥Êòé&lt;/h3&gt; 
&lt;h4&gt;Êï∞ÊçÆÂ∫ìÈÖçÁΩÆÔºàPostgreSQLÔºâ&lt;/h4&gt; 
&lt;p&gt;ËØ∑ÊåâÁÖß‰ª•‰∏ãÂèÇÊï∞ÈÖçÁΩÆÊï∞ÊçÆÂ∫ìËøûÊé•‰ø°ÊÅØÔºå‰πüÊîØÊåÅMysqlÂèØËá™Ë°å‰øÆÊîπÔºö&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;ÈÖçÁΩÆÈ°π&lt;/th&gt; 
   &lt;th align="left"&gt;Â°´ÂÜôÂÄº&lt;/th&gt; 
   &lt;th align="left"&gt;ËØ¥Êòé&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;DB_HOST&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;db&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Êï∞ÊçÆÂ∫ìÊúçÂä°ÂêçÁß∞ (ÂØπÂ∫î &lt;code&gt;docker-compose.yml&lt;/code&gt; ‰∏≠ÁöÑÊúçÂä°Âêç)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;DB_PORT&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;5432&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;ÈªòËÆ§ PostgreSQL Á´ØÂè£&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;DB_USER&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;bettafish&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Êï∞ÊçÆÂ∫ìÁî®Êà∑Âêç&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;DB_PASSWORD&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;bettafish&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Êï∞ÊçÆÂ∫ìÂØÜÁ†Å&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;DB_NAME&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;bettafish&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Êï∞ÊçÆÂ∫ìÂêçÁß∞&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;ÂÖ∂‰ªñ&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;‰øùÊåÅÈªòËÆ§&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Êï∞ÊçÆÂ∫ìËøûÊé•Ê±†Á≠âÂÖ∂‰ªñÂèÇÊï∞ËØ∑‰øùÊåÅÈªòËÆ§ËÆæÁΩÆ„ÄÇ&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h4&gt;Â§ßÊ®°ÂûãÈÖçÁΩÆ&lt;/h4&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Êàë‰ª¨ÊâÄÊúâ LLM Ë∞ÉÁî®‰ΩøÁî® OpenAI ÁöÑ API Êé•Âè£Ê†áÂáÜ&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Âú®ÂÆåÊàêÊï∞ÊçÆÂ∫ìÈÖçÁΩÆÂêéÔºåËØ∑Ê≠£Â∏∏ÈÖçÁΩÆ&lt;strong&gt;ÊâÄÊúâÂ§ßÊ®°ÂûãÁõ∏ÂÖ≥ÁöÑÂèÇÊï∞&lt;/strong&gt;ÔºåÁ°Æ‰øùÁ≥ªÁªüËÉΩÂ§üËøûÊé•Âà∞ÊÇ®ÈÄâÊã©ÁöÑÂ§ßÊ®°ÂûãÊúçÂä°„ÄÇ&lt;/p&gt; 
&lt;p&gt;ÂÆåÊàê‰∏äËø∞ÊâÄÊúâÈÖçÁΩÆÂπ∂‰øùÂ≠òÂêéÔºåÁ≥ªÁªüÂç≥ÂèØÊ≠£Â∏∏ËøêË°å„ÄÇ&lt;/p&gt; 
&lt;h2&gt;üîß Ê∫êÁ†ÅÂêØÂä®ÊåáÂçó&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Â¶ÇÊûú‰Ω†ÊòØÂàùÊ¨°Â≠¶‰π†‰∏Ä‰∏™AgentÁ≥ªÁªüÁöÑÊê≠Âª∫ÔºåÂèØ‰ª•‰ªé‰∏Ä‰∏™ÈùûÂ∏∏ÁÆÄÂçïÁöÑdemoÂºÄÂßãÔºö&lt;a href="https://github.com/666ghj/DeepSearchAgent-Demo"&gt;Deep Search Agent Demo&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;ÁéØÂ¢ÉË¶ÅÊ±Ç&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Êìç‰ΩúÁ≥ªÁªü&lt;/strong&gt;: Windows„ÄÅLinux„ÄÅMacOS&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;PythonÁâàÊú¨&lt;/strong&gt;: 3.9+&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Conda&lt;/strong&gt;: AnacondaÊàñMiniconda&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Êï∞ÊçÆÂ∫ì&lt;/strong&gt;: PostgreSQLÔºàÊé®ËçêÔºâÊàñMySQL&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ÂÜÖÂ≠ò&lt;/strong&gt;: Âª∫ËÆÆ2GB‰ª•‰∏ä&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;1. ÂàõÂª∫ÁéØÂ¢É&lt;/h3&gt; 
&lt;h4&gt;Â¶ÇÊûú‰ΩøÁî®Conda&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# ÂàõÂª∫condaÁéØÂ¢É
conda create -n your_conda_name python=3.11
conda activate your_conda_name
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Â¶ÇÊûú‰ΩøÁî®uv&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# ÂàõÂª∫uvÁéØÂ¢É
uv venv --python 3.11 # ÂàõÂª∫3.11ÁéØÂ¢É
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;2. ÂÆâË£Ö‰æùËµñÂåÖ&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Âü∫Á°Ä‰æùËµñÂÆâË£Ö
pip install -r requirements.txt

# uvÁâàÊú¨ÂëΩ‰ª§ÔºàÊõ¥Âø´ÈÄüÂÆâË£ÖÔºâ
uv pip install -r requirements.txt
# Â¶ÇÊûú‰∏çÊÉ≥‰ΩøÁî®Êú¨Âú∞ÊÉÖÊÑüÂàÜÊûêÊ®°ÂûãÔºàÁÆóÂäõÈúÄÊ±ÇÂæàÂ∞èÔºåÈªòËÆ§ÂÆâË£ÖcpuÁâàÊú¨ÔºâÔºåÂèØ‰ª•Â∞ÜËØ•Êñá‰ª∂‰∏≠ÁöÑ‚ÄúÊú∫Âô®Â≠¶‰π†‚ÄùÈÉ®ÂàÜÊ≥®ÈáäÊéâÂÜçÊâßË°åÊåá‰ª§
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;3. ÂÆâË£ÖPlaywrightÊµèËßàÂô®È©±Âä®&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# ÂÆâË£ÖÊµèËßàÂô®È©±Âä®ÔºàÁî®‰∫éÁà¨Ëô´ÂäüËÉΩÔºâ
playwright install chromium
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;4. ÈÖçÁΩÆLLM‰∏éÊï∞ÊçÆÂ∫ì&lt;/h3&gt; 
&lt;p&gt;Â§çÂà∂‰∏Ä‰ªΩÈ°πÁõÆÊ†πÁõÆÂΩï &lt;code&gt;.env.example&lt;/code&gt; Êñá‰ª∂ÔºåÂëΩÂêç‰∏∫ &lt;code&gt;.env&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;ÁºñËæë &lt;code&gt;.env&lt;/code&gt; Êñá‰ª∂ÔºåÂ°´ÂÖ•ÊÇ®ÁöÑAPIÂØÜÈí•ÔºàÊÇ®‰πüÂèØ‰ª•ÈÄâÊã©Ëá™Â∑±ÁöÑÊ®°Âûã„ÄÅÊêúÁ¥¢‰ª£ÁêÜÔºåËØ¶ÊÉÖËßÅÊ†πÁõÆÂΩï.env.exampleÊñá‰ª∂ÂÜÖÊàñÊ†πÁõÆÂΩïconfig.py‰∏≠ÁöÑËØ¥ÊòéÔºâÔºö&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yml"&gt;# ====================== Êï∞ÊçÆÂ∫ìÈÖçÁΩÆ ======================
# Êï∞ÊçÆÂ∫ì‰∏ªÊú∫Ôºå‰æãÂ¶Çlocalhost Êàñ 127.0.0.1
DB_HOST=your_db_host
# Êï∞ÊçÆÂ∫ìÁ´ØÂè£Âè∑ÔºåÈªòËÆ§‰∏∫3306
DB_PORT=3306
# Êï∞ÊçÆÂ∫ìÁî®Êà∑Âêç
DB_USER=your_db_user
# Êï∞ÊçÆÂ∫ìÂØÜÁ†Å
DB_PASSWORD=your_db_password
# Êï∞ÊçÆÂ∫ìÂêçÁß∞
DB_NAME=your_db_name
# Êï∞ÊçÆÂ∫ìÂ≠óÁ¨¶ÈõÜÔºåÊé®Ëçêutf8mb4ÔºåÂÖºÂÆπemoji
DB_CHARSET=utf8mb4
# Êï∞ÊçÆÂ∫ìÁ±ªÂûãpostgresqlÊàñmysql
DB_DIALECT=postgresql
# Êï∞ÊçÆÂ∫ì‰∏çÈúÄË¶ÅÂàùÂßãÂåñÔºåÊâßË°åapp.pyÊó∂‰ºöËá™Âä®Ê£ÄÊµã

# ====================== LLMÈÖçÁΩÆ ======================
# ÊÇ®ÂèØ‰ª•Êõ¥ÊîπÊØè‰∏™ÈÉ®ÂàÜLLM‰ΩøÁî®ÁöÑAPIÔºåÂè™Ë¶ÅÂÖºÂÆπOpenAIËØ∑Ê±ÇÊ†ºÂºèÈÉΩÂèØ‰ª•

# Insight Agent
INSIGHT_ENGINE_API_KEY=
# Insight Agent LLMÊé•Âè£BaseUrlÔºåÂèØËá™ÂÆö‰πâÂéÇÂïÜAPI
INSIGHT_ENGINE_BASE_URL=
# Insight Agent LLMÊ®°ÂûãÂêçÁß∞ÔºåÂ¶Çkimi-k2-0711-preview
INSIGHT_ENGINE_MODEL_NAME=

# Media Agent
...
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Êé®ËçêLLM API‰æõÂ∫îÂïÜÔºö&lt;a href="https://aihubmix.com/?aff=8Ds9"&gt;Êé®ÁêÜÊó∂‰ª£&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;5. ÂêØÂä®Á≥ªÁªü&lt;/h3&gt; 
&lt;h4&gt;5.1 ÂÆåÊï¥Á≥ªÁªüÂêØÂä®ÔºàÊé®ËçêÔºâ&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Âú®È°πÁõÆÊ†πÁõÆÂΩï‰∏ãÔºåÊøÄÊ¥ªcondaÁéØÂ¢É
conda activate your_conda_name

# ÂêØÂä®‰∏ªÂ∫îÁî®Âç≥ÂèØ
python app.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;uv ÁâàÊú¨ÂêØÂä®ÂëΩ‰ª§&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Âú®È°πÁõÆÊ†πÁõÆÂΩï‰∏ãÔºåÊøÄÊ¥ªuvÁéØÂ¢É
.venv\Scripts\activate

# ÂêØÂä®‰∏ªÂ∫îÁî®Âç≥ÂèØ
python app.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Ê≥®1Ôºö‰∏ÄÊ¨°ËøêË°åÁªàÊ≠¢ÂêéÔºåstreamlit appÂèØËÉΩÁªìÊùüÂºÇÂ∏∏‰ªçÁÑ∂Âç†Áî®Á´ØÂè£ÔºåÊ≠§Êó∂ÊêúÁ¥¢Âç†Áî®Á´ØÂè£ÁöÑËøõÁ®ãkillÊéâÂç≥ÂèØ&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Ê≥®2ÔºöÊï∞ÊçÆÁà¨ÂèñÈúÄË¶ÅÂçïÁã¨Êìç‰ΩúÔºåËßÅ5.3ÊåáÂºï&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Ê≥®3ÔºöÂ¶ÇÊûúÊúçÂä°Âô®ËøúÁ®ãÈÉ®ÁΩ≤Âá∫Áé∞È°µÈù¢ÊòæÁ§∫ÈóÆÈ¢òÔºåËßÅ&lt;a href="https://github.com/666ghj/BettaFish/pull/45"&gt;PR#45&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;ËÆøÈóÆ &lt;a href="http://localhost:5000"&gt;http://localhost:5000&lt;/a&gt; Âç≥ÂèØ‰ΩøÁî®ÂÆåÊï¥Á≥ªÁªü&lt;/p&gt; 
&lt;h4&gt;5.2 ÂçïÁã¨ÂêØÂä®Êüê‰∏™Agent&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# ÂêØÂä®QueryEngine
streamlit run SingleEngineApp/query_engine_streamlit_app.py --server.port 8503

# ÂêØÂä®MediaEngine  
streamlit run SingleEngineApp/media_engine_streamlit_app.py --server.port 8502

# ÂêØÂä®InsightEngine
streamlit run SingleEngineApp/insight_engine_streamlit_app.py --server.port 8501
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;5.3 Áà¨Ëô´Á≥ªÁªüÂçïÁã¨‰ΩøÁî®&lt;/h4&gt; 
&lt;p&gt;ËøôÈÉ®ÂàÜÊúâËØ¶ÁªÜÁöÑÈÖçÁΩÆÊñáÊ°£Ôºö&lt;a href="https://raw.githubusercontent.com/666ghj/BettaFish/main/MindSpider/README.md"&gt;MindSpider‰ΩøÁî®ËØ¥Êòé&lt;/a&gt;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;img src="MindSpider\img\example.png" alt="banner" width="600" /&gt; 
 &lt;p&gt;MindSpider ËøêË°åÁ§∫‰æã&lt;/p&gt; 
&lt;/div&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# ËøõÂÖ•Áà¨Ëô´ÁõÆÂΩï
cd MindSpider

# È°πÁõÆÂàùÂßãÂåñ
python main.py --setup

# ËøêË°åËØùÈ¢òÊèêÂèñÔºàËé∑ÂèñÁÉ≠ÁÇπÊñ∞ÈóªÂíåÂÖ≥ÈîÆËØçÔºâ
python main.py --broad-topic

# ËøêË°åÂÆåÊï¥Áà¨Ëô´ÊµÅÁ®ã
python main.py --complete --date 2024-01-20

# ‰ªÖËøêË°åËØùÈ¢òÊèêÂèñ
python main.py --broad-topic --date 2024-01-20

# ‰ªÖËøêË°åÊ∑±Â∫¶Áà¨Âèñ
python main.py --deep-sentiment --platforms xhs dy wb
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;‚öôÔ∏è È´òÁ∫ßÈÖçÁΩÆÔºàÂ∑≤ËøáÊó∂ÔºåÂ∑≤ÁªèÁªü‰∏Ä‰∏∫È°πÁõÆÊ†πÁõÆÂΩï.envÊñá‰ª∂ÁÆ°ÁêÜÔºåÂÖ∂‰ªñÂ≠êagentËá™Âä®ÁªßÊâøÊ†πÁõÆÂΩïÈÖçÁΩÆÔºâ&lt;/h2&gt; 
&lt;h3&gt;‰øÆÊîπÂÖ≥ÈîÆÂèÇÊï∞&lt;/h3&gt; 
&lt;h4&gt;AgentÈÖçÁΩÆÂèÇÊï∞&lt;/h4&gt; 
&lt;p&gt;ÊØè‰∏™AgentÈÉΩÊúâ‰∏ìÈó®ÁöÑÈÖçÁΩÆÊñá‰ª∂ÔºåÂèØÊ†πÊçÆÈúÄÊ±ÇË∞ÉÊï¥Ôºå‰∏ãÈù¢ÊòØÈÉ®ÂàÜÁ§∫‰æãÔºö&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# QueryEngine/utils/config.py
class Config:
    max_reflections = 2           # ÂèçÊÄùËΩÆÊ¨°
    max_search_results = 15       # ÊúÄÂ§ßÊêúÁ¥¢ÁªìÊûúÊï∞
    max_content_length = 8000     # ÊúÄÂ§ßÂÜÖÂÆπÈïøÂ∫¶
    
# MediaEngine/utils/config.py  
class Config:
    comprehensive_search_limit = 10  # ÁªºÂêàÊêúÁ¥¢ÈôêÂà∂
    web_search_limit = 15           # ÁΩëÈ°µÊêúÁ¥¢ÈôêÂà∂
    
# InsightEngine/utils/config.py
class Config:
    default_search_topic_globally_limit = 200    # ÂÖ®Â±ÄÊêúÁ¥¢ÈôêÂà∂
    default_get_comments_limit = 500             # ËØÑËÆ∫Ëé∑ÂèñÈôêÂà∂
    max_search_results_for_llm = 50              # ‰º†ÁªôLLMÁöÑÊúÄÂ§ßÁªìÊûúÊï∞
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;ÊÉÖÊÑüÂàÜÊûêÊ®°ÂûãÈÖçÁΩÆ&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# InsightEngine/tools/sentiment_analyzer.py
SENTIMENT_CONFIG = {
    'model_type': 'multilingual',     # ÂèØÈÄâ: 'bert', 'multilingual', 'qwen'Á≠â
    'confidence_threshold': 0.8,      # ÁΩÆ‰ø°Â∫¶ÈòàÂÄº
    'batch_size': 32,                 # ÊâπÂ§ÑÁêÜÂ§ßÂ∞è
    'max_sequence_length': 512,       # ÊúÄÂ§ßÂ∫èÂàóÈïøÂ∫¶
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Êé•ÂÖ•‰∏çÂêåÁöÑLLMÊ®°Âûã&lt;/h3&gt; 
&lt;p&gt;ÊîØÊåÅ‰ªªÊÑèopenAIË∞ÉÁî®Ê†ºÂºèÁöÑLLMÊèê‰æõÂïÜÔºåÂè™ÈúÄË¶ÅÂú®/config.py‰∏≠Â°´ÂÜôÂØπÂ∫îÁöÑKEY„ÄÅBASE_URL„ÄÅMODEL_NAMEÂç≥ÂèØ„ÄÇ&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;‰ªÄ‰πàÊòØopenAIË∞ÉÁî®Ê†ºÂºèÔºü‰∏ãÈù¢Êèê‰æõ‰∏Ä‰∏™ÁÆÄÂçïÁöÑ‰æãÂ≠êÔºö&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;from openai import OpenAI

client = OpenAI(api_key="your_api_key", 
               base_url="https://api.siliconflow.cn/v1")

response = client.chat.completions.create(
   model="Qwen/Qwen2.5-72B-Instruct",
   messages=[
       {'role': 'user', 
        'content': "Êé®ÁêÜÊ®°Âûã‰ºöÁªôÂ∏ÇÂú∫Â∏¶Êù•Âì™‰∫õÊñ∞ÁöÑÊú∫‰ºö"}
   ],
)

complete_response = response.choices[0].message.content
print(complete_response)
&lt;/code&gt;&lt;/pre&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Êõ¥ÊîπÊÉÖÊÑüÂàÜÊûêÊ®°Âûã&lt;/h3&gt; 
&lt;p&gt;Á≥ªÁªüÈõÜÊàê‰∫ÜÂ§öÁßçÊÉÖÊÑüÂàÜÊûêÊñπÊ≥ïÔºåÂèØÊ†πÊçÆÈúÄÊ±ÇÈÄâÊã©Ôºö&lt;/p&gt; 
&lt;h4&gt;1. Â§öËØ≠Ë®ÄÊÉÖÊÑüÂàÜÊûê&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd SentimentAnalysisModel/WeiboMultilingualSentiment
python predict.py --text "This product is amazing!" --lang "en"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;2. Â∞èÂèÇÊï∞Qwen3ÂæÆË∞É&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd SentimentAnalysisModel/WeiboSentiment_SmallQwen
python predict_universal.py --text "ËøôÊ¨°Ê¥ªÂä®ÂäûÂæóÂæàÊàêÂäü"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;3. Âü∫‰∫éBERTÁöÑÂæÆË∞ÉÊ®°Âûã&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# ‰ΩøÁî®BERT‰∏≠ÊñáÊ®°Âûã
cd SentimentAnalysisModel/WeiboSentiment_Finetuned/BertChinese-Lora
python predict.py --text "Ëøô‰∏™‰∫ßÂìÅÁúüÁöÑÂæà‰∏çÈîô"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;4. GPT-2 LoRAÂæÆË∞ÉÊ®°Âûã&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd SentimentAnalysisModel/WeiboSentiment_Finetuned/GPT2-Lora
python predict.py --text "‰ªäÂ§©ÂøÉÊÉÖ‰∏çÂ§™Â•Ω"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;5. ‰º†ÁªüÊú∫Âô®Â≠¶‰π†ÊñπÊ≥ï&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd SentimentAnalysisModel/WeiboSentiment_MachineLearning
python predict.py --model_type "svm" --text "ÊúçÂä°ÊÄÅÂ∫¶ÈúÄË¶ÅÊîπËøõ"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Êé•ÂÖ•Ëá™ÂÆö‰πâ‰∏öÂä°Êï∞ÊçÆÂ∫ì&lt;/h3&gt; 
&lt;h4&gt;1. ‰øÆÊîπÊï∞ÊçÆÂ∫ìËøûÊé•ÈÖçÁΩÆ&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# config.py ‰∏≠Ê∑ªÂä†ÊÇ®ÁöÑ‰∏öÂä°Êï∞ÊçÆÂ∫ìÈÖçÁΩÆ
BUSINESS_DB_HOST = "your_business_db_host"
BUSINESS_DB_PORT = 3306
BUSINESS_DB_USER = "your_business_user"
BUSINESS_DB_PASSWORD = "your_business_password"
BUSINESS_DB_NAME = "your_business_database"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;2. ÂàõÂª∫Ëá™ÂÆö‰πâÊï∞ÊçÆËÆøÈóÆÂ∑•ÂÖ∑&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# InsightEngine/tools/custom_db_tool.py
class CustomBusinessDBTool:
    """Ëá™ÂÆö‰πâ‰∏öÂä°Êï∞ÊçÆÂ∫ìÊü•ËØ¢Â∑•ÂÖ∑"""
    
    def __init__(self):
        self.connection_config = {
            'host': config.BUSINESS_DB_HOST,
            'port': config.BUSINESS_DB_PORT,
            'user': config.BUSINESS_DB_USER,
            'password': config.BUSINESS_DB_PASSWORD,
            'database': config.BUSINESS_DB_NAME,
        }
    
    def search_business_data(self, query: str, table: str):
        """Êü•ËØ¢‰∏öÂä°Êï∞ÊçÆ"""
        # ÂÆûÁé∞ÊÇ®ÁöÑ‰∏öÂä°ÈÄªËæë
        pass
    
    def get_customer_feedback(self, product_id: str):
        """Ëé∑ÂèñÂÆ¢Êà∑ÂèçÈ¶àÊï∞ÊçÆ"""
        # ÂÆûÁé∞ÂÆ¢Êà∑ÂèçÈ¶àÊü•ËØ¢ÈÄªËæë
        pass
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;3. ÈõÜÊàêÂà∞InsightEngine&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# InsightEngine/agent.py ‰∏≠ÈõÜÊàêËá™ÂÆö‰πâÂ∑•ÂÖ∑
from .tools.custom_db_tool import CustomBusinessDBTool

class DeepSearchAgent:
    def __init__(self, config=None):
        # ... ÂÖ∂‰ªñÂàùÂßãÂåñ‰ª£Á†Å
        self.custom_db_tool = CustomBusinessDBTool()
    
    def execute_custom_search(self, query: str):
        """ÊâßË°åËá™ÂÆö‰πâ‰∏öÂä°Êï∞ÊçÆÊêúÁ¥¢"""
        return self.custom_db_tool.search_business_data(query, "your_table")
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Ëá™ÂÆö‰πâÊä•ÂëäÊ®°Êùø&lt;/h3&gt; 
&lt;h4&gt;1. Âú®WebÁïåÈù¢‰∏≠‰∏ä‰º†&lt;/h4&gt; 
&lt;p&gt;Á≥ªÁªüÊîØÊåÅ‰∏ä‰º†Ëá™ÂÆö‰πâÊ®°ÊùøÊñá‰ª∂Ôºà.mdÊàñ.txtÊ†ºÂºèÔºâÔºåÂèØÂú®ÁîüÊàêÊä•ÂëäÊó∂ÈÄâÊã©‰ΩøÁî®„ÄÇ&lt;/p&gt; 
&lt;h4&gt;2. ÂàõÂª∫Ê®°ÊùøÊñá‰ª∂&lt;/h4&gt; 
&lt;p&gt;Âú® &lt;code&gt;ReportEngine/report_template/&lt;/code&gt; ÁõÆÂΩï‰∏ãÂàõÂª∫Êñ∞ÁöÑÊ®°ÊùøÔºåÊàë‰ª¨ÁöÑAgent‰ºöËá™Ë°åÈÄâÁî®ÊúÄÂêàÈÄÇÁöÑÊ®°Êùø„ÄÇ&lt;/p&gt; 
&lt;h2&gt;ü§ù Ë¥°ÁåÆÊåáÂçó&lt;/h2&gt; 
&lt;p&gt;Êàë‰ª¨Ê¨¢ËøéÊâÄÊúâÂΩ¢ÂºèÁöÑË¥°ÁåÆÔºÅ&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;ËØ∑ÈòÖËØª‰ª•‰∏ãË¥°ÁåÆÊåáÂçóÔºö&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/666ghj/BettaFish/main/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ü¶ñ ‰∏ã‰∏ÄÊ≠•ÂºÄÂèëËÆ°Âàí&lt;/h2&gt; 
&lt;p&gt;Áé∞Âú®Á≥ªÁªüÂè™ÂÆåÊàê‰∫Ü"‰∏âÊùøÊñß"‰∏≠ÁöÑÂâç‰∏§Ê≠•ÔºåÂç≥ÔºöËæìÂÖ•Ë¶ÅÊ±Ç-&amp;gt;ËØ¶ÁªÜÂàÜÊûêÔºåËøòÁº∫Â∞ë‰∏ÄÊ≠•È¢ÑÊµãÔºåÁõ¥Êé•Â∞Ü‰ªñÁªßÁª≠‰∫§ÁªôLLMÊòØ‰∏çÂÖ∑ÊúâËØ¥ÊúçÂäõÁöÑ„ÄÇ&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/666ghj/BettaFish/main/static/image/banner_compressed.png" alt="banner" width="800" /&gt; 
&lt;/div&gt; 
&lt;p&gt;ÁõÆÂâçÊàë‰ª¨ÁªèËøáÂæàÈïø‰∏ÄÊÆµÊó∂Èó¥ÁöÑÁà¨ÂèñÊî∂ÈõÜÔºåÊã•Êúâ‰∫ÜÂ§ßÈáèÂÖ®ÁΩëËØùÈ¢òÁÉ≠Â∫¶ÈöèÊó∂Èó¥„ÄÅÁàÜÁÇπÁ≠âÁöÑÂèòÂåñË∂ãÂäøÁÉ≠Â∫¶Êï∞ÊçÆÔºåÂ∑≤ÁªèÂÖ∑Â§á‰∫ÜÂèØ‰ª•ÂºÄÂèëÈ¢ÑÊµãÊ®°ÂûãÁöÑÊù°‰ª∂„ÄÇÊàë‰ª¨Âõ¢ÈòüÂ∞ÜËøêÁî®Êó∂Â∫èÊ®°Âûã„ÄÅÂõæÁ•ûÁªèÁΩëÁªú„ÄÅÂ§öÊ®°ÊÄÅËûçÂêàÁ≠âÈ¢ÑÊµãÊ®°ÂûãÊäÄÊúØÂÇ®Â§á‰∫éÊ≠§ÔºåÂÆûÁé∞ÁúüÊ≠£Âü∫‰∫éÊï∞ÊçÆÈ©±Âä®ÁöÑËàÜÊÉÖÈ¢ÑÊµãÂäüËÉΩ„ÄÇ&lt;/p&gt; 
&lt;h2&gt;‚ö†Ô∏è ÂÖçË¥£Â£∞Êòé&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;ÈáçË¶ÅÊèêÈÜíÔºöÊú¨È°πÁõÆ‰ªÖ‰æõÂ≠¶‰π†„ÄÅÂ≠¶ÊúØÁ†îÁ©∂ÂíåÊïôËÇ≤ÁõÆÁöÑ‰ΩøÁî®&lt;/strong&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;ÂêàËßÑÊÄßÂ£∞Êòé&lt;/strong&gt;Ôºö&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Êú¨È°πÁõÆ‰∏≠ÁöÑÊâÄÊúâ‰ª£Á†Å„ÄÅÂ∑•ÂÖ∑ÂíåÂäüËÉΩÂùá‰ªÖ‰æõÂ≠¶‰π†„ÄÅÂ≠¶ÊúØÁ†îÁ©∂ÂíåÊïôËÇ≤ÁõÆÁöÑ‰ΩøÁî®&lt;/li&gt; 
   &lt;li&gt;‰∏•Á¶ÅÂ∞ÜÊú¨È°πÁõÆÁî®‰∫é‰ªª‰ΩïÂïÜ‰∏öÁî®ÈÄîÊàñÁõàÂà©ÊÄßÊ¥ªÂä®&lt;/li&gt; 
   &lt;li&gt;‰∏•Á¶ÅÂ∞ÜÊú¨È°πÁõÆÁî®‰∫é‰ªª‰ΩïËøùÊ≥ï„ÄÅËøùËßÑÊàñ‰æµÁäØ‰ªñ‰∫∫ÊùÉÁõäÁöÑË°å‰∏∫&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Áà¨Ëô´ÂäüËÉΩÂÖçË¥£&lt;/strong&gt;Ôºö&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;È°πÁõÆ‰∏≠ÁöÑÁà¨Ëô´ÂäüËÉΩ‰ªÖÁî®‰∫éÊäÄÊúØÂ≠¶‰π†ÂíåÁ†îÁ©∂ÁõÆÁöÑ&lt;/li&gt; 
   &lt;li&gt;‰ΩøÁî®ËÄÖÂøÖÈ°ªÈÅµÂÆàÁõÆÊ†áÁΩëÁ´ôÁöÑrobots.txtÂçèËÆÆÂíå‰ΩøÁî®Êù°Ê¨æ&lt;/li&gt; 
   &lt;li&gt;‰ΩøÁî®ËÄÖÂøÖÈ°ªÈÅµÂÆàÁõ∏ÂÖ≥Ê≥ïÂæãÊ≥ïËßÑÔºå‰∏çÂæóËøõË°åÊÅ∂ÊÑèÁà¨ÂèñÊàñÊï∞ÊçÆÊª•Áî®&lt;/li&gt; 
   &lt;li&gt;Âõ†‰ΩøÁî®Áà¨Ëô´ÂäüËÉΩ‰∫ßÁîüÁöÑ‰ªª‰ΩïÊ≥ïÂæãÂêéÊûúÁî±‰ΩøÁî®ËÄÖËá™Ë°åÊâøÊãÖ&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Êï∞ÊçÆ‰ΩøÁî®ÂÖçË¥£&lt;/strong&gt;Ôºö&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;È°πÁõÆÊ∂âÂèäÁöÑÊï∞ÊçÆÂàÜÊûêÂäüËÉΩ‰ªÖ‰æõÂ≠¶ÊúØÁ†îÁ©∂‰ΩøÁî®&lt;/li&gt; 
   &lt;li&gt;‰∏•Á¶ÅÂ∞ÜÂàÜÊûêÁªìÊûúÁî®‰∫éÂïÜ‰∏öÂÜ≥Á≠ñÊàñÁõàÂà©ÁõÆÁöÑ&lt;/li&gt; 
   &lt;li&gt;‰ΩøÁî®ËÄÖÂ∫îÁ°Æ‰øùÊâÄÂàÜÊûêÊï∞ÊçÆÁöÑÂêàÊ≥ïÊÄßÂíåÂêàËßÑÊÄß&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;ÊäÄÊúØÂÖçË¥£&lt;/strong&gt;Ôºö&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Êú¨È°πÁõÆÊåâ"Áé∞Áä∂"Êèê‰æõÔºå‰∏çÊèê‰æõ‰ªª‰ΩïÊòéÁ§∫ÊàñÊöóÁ§∫ÁöÑ‰øùËØÅ&lt;/li&gt; 
   &lt;li&gt;‰ΩúËÄÖ‰∏çÂØπ‰ΩøÁî®Êú¨È°πÁõÆÈÄ†ÊàêÁöÑ‰ªª‰ΩïÁõ¥Êé•ÊàñÈó¥Êé•ÊçüÂ§±ÊâøÊãÖË¥£‰ªª&lt;/li&gt; 
   &lt;li&gt;‰ΩøÁî®ËÄÖÂ∫îËá™Ë°åËØÑ‰º∞È°πÁõÆÁöÑÈÄÇÁî®ÊÄßÂíåÈ£éÈô©&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Ë¥£‰ªªÈôêÂà∂&lt;/strong&gt;Ôºö&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;‰ΩøÁî®ËÄÖÂú®‰ΩøÁî®Êú¨È°πÁõÆÂâçÂ∫îÂÖÖÂàÜ‰∫ÜËß£Áõ∏ÂÖ≥Ê≥ïÂæãÊ≥ïËßÑ&lt;/li&gt; 
   &lt;li&gt;‰ΩøÁî®ËÄÖÂ∫îÁ°Æ‰øùÂÖ∂‰ΩøÁî®Ë°å‰∏∫Á¨¶ÂêàÂΩìÂú∞Ê≥ïÂæãÊ≥ïËßÑË¶ÅÊ±Ç&lt;/li&gt; 
   &lt;li&gt;Âõ†ËøùÂèçÊ≥ïÂæãÊ≥ïËßÑ‰ΩøÁî®Êú¨È°πÁõÆËÄå‰∫ßÁîüÁöÑ‰ªª‰ΩïÂêéÊûúÁî±‰ΩøÁî®ËÄÖËá™Ë°åÊâøÊãÖ&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;ËØ∑Âú®‰ΩøÁî®Êú¨È°πÁõÆÂâç‰ªîÁªÜÈòÖËØªÂπ∂ÁêÜËß£‰∏äËø∞ÂÖçË¥£Â£∞Êòé„ÄÇ‰ΩøÁî®Êú¨È°πÁõÆÂç≥Ë°®Á§∫ÊÇ®Â∑≤ÂêåÊÑèÂπ∂Êé•Âèó‰∏äËø∞ÊâÄÊúâÊù°Ê¨æ„ÄÇ&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;üìÑ ËÆ∏ÂèØËØÅ&lt;/h2&gt; 
&lt;p&gt;Êú¨È°πÁõÆÈááÁî® &lt;a href="https://raw.githubusercontent.com/666ghj/BettaFish/main/LICENSE"&gt;GPL-2.0ËÆ∏ÂèØËØÅ&lt;/a&gt;„ÄÇËØ¶ÁªÜ‰ø°ÊÅØËØ∑ÂèÇÈòÖLICENSEÊñá‰ª∂„ÄÇ&lt;/p&gt; 
&lt;h2&gt;üéâ ÊîØÊåÅ‰∏éËÅîÁ≥ª&lt;/h2&gt; 
&lt;h3&gt;Ëé∑ÂèñÂ∏ÆÂä©&lt;/h3&gt; 
&lt;p&gt;Â∏∏ËßÅÈóÆÈ¢òËß£Á≠îÔºö&lt;a href="https://github.com/666ghj/BettaFish/issues/185"&gt;https://github.com/666ghj/BettaFish/issues/185&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;È°πÁõÆ‰∏ªÈ°µ&lt;/strong&gt;Ôºö&lt;a href="https://github.com/666ghj/BettaFish"&gt;GitHub‰ªìÂ∫ì&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ÈóÆÈ¢òÂèçÈ¶à&lt;/strong&gt;Ôºö&lt;a href="https://github.com/666ghj/BettaFish/issues"&gt;IssuesÈ°µÈù¢&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ÂäüËÉΩÂª∫ËÆÆ&lt;/strong&gt;Ôºö&lt;a href="https://github.com/666ghj/BettaFish/discussions"&gt;DiscussionsÈ°µÈù¢&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;ËÅîÁ≥ªÊñπÂºè&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;üìß &lt;strong&gt;ÈÇÆÁÆ±&lt;/strong&gt;Ôºö&lt;a href="mailto:670939375@qq.com"&gt;670939375@qq.com&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;ÂïÜÂä°Âêà‰Ωú&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;‰ºÅ‰∏öÂÆöÂà∂ÂºÄÂèë&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Â§ßÊï∞ÊçÆÊúçÂä°&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Â≠¶ÊúØÂêà‰Ωú&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ÊäÄÊúØÂüπËÆ≠&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üë• Ë¥°ÁåÆËÄÖ&lt;/h2&gt; 
&lt;p&gt;ÊÑüË∞¢‰ª•‰∏ã‰ºòÁßÄÁöÑË¥°ÁåÆËÄÖ‰ª¨Ôºö&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/666ghj/BettaFish/graphs/contributors"&gt;&lt;img src="https://contrib.rocks/image?repo=666ghj/BettaFish" alt="Contributors" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üìà È°πÁõÆÁªüËÆ°&lt;/h2&gt; 
&lt;a href="https://www.star-history.com/#666ghj/BettaFish&amp;amp;type=date&amp;amp;legend=top-left"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://api.star-history.com/svg?repos=666ghj/BettaFish&amp;amp;type=date&amp;amp;theme=dark&amp;amp;legend=top-left" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://api.star-history.com/svg?repos=666ghj/BettaFish&amp;amp;type=date&amp;amp;legend=top-left" /&gt; 
  &lt;img alt="Star History Chart" src="https://api.star-history.com/svg?repos=666ghj/BettaFish&amp;amp;type=date&amp;amp;legend=top-left" /&gt; 
 &lt;/picture&gt; &lt;/a&gt; 
&lt;p&gt;&lt;img src="https://repobeats.axiom.co/api/embed/e04e3eea4674edc39c148a7845c8d09c1b7b1922.svg?sanitize=true" alt="Alt" title="Repobeats analytics image" /&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Skyvern-AI/skyvern</title>
      <link>https://github.com/Skyvern-AI/skyvern</link>
      <description>&lt;p&gt;Automate browser based workflows with AI&lt;/p&gt;&lt;hr&gt;&lt;h1 align="center"&gt; &lt;a href="https://www.skyvern.com"&gt; 
  &lt;picture&gt; 
   &lt;source media="(prefers-color-scheme: dark)" srcset="fern/images/skyvern_logo.png" /&gt; 
   &lt;img height="120" src="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/fern/images/skyvern_logo_blackbg.png" /&gt; 
  &lt;/picture&gt; &lt;/a&gt; &lt;br /&gt; &lt;/h1&gt; 
&lt;p align="center"&gt; üêâ Automate Browser-based workflows using LLMs and Computer Vision üêâ &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://www.skyvern.com/"&gt;&lt;img src="https://img.shields.io/badge/Website-blue?logo=googlechrome&amp;amp;logoColor=black" /&gt;&lt;/a&gt; &lt;a href="https://www.skyvern.com/docs/"&gt;&lt;img src="https://img.shields.io/badge/Docs-yellow?logo=gitbook&amp;amp;logoColor=black" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/fG2XXEuQX3"&gt;&lt;img src="https://img.shields.io/discord/1212486326352617534?logo=discord&amp;amp;label=discord" /&gt;&lt;/a&gt; 
 &lt;!-- &lt;a href="https://pepy.tech/project/skyvern" target="_blank"&gt;&lt;img src="https://static.pepy.tech/badge/skyvern" alt="Total Downloads"/&gt;&lt;/a&gt; --&gt; &lt;a href="https://github.com/skyvern-ai/skyvern"&gt;&lt;img src="https://img.shields.io/github/stars/skyvern-ai/skyvern" /&gt;&lt;/a&gt; &lt;a href="https://github.com/Skyvern-AI/skyvern/raw/main/LICENSE"&gt;&lt;img src="https://img.shields.io/github/license/skyvern-ai/skyvern" /&gt;&lt;/a&gt; &lt;a href="https://twitter.com/skyvernai"&gt;&lt;img src="https://img.shields.io/twitter/follow/skyvernai?style=social" /&gt;&lt;/a&gt; &lt;a href="https://www.linkedin.com/company/95726232"&gt;&lt;img src="https://img.shields.io/badge/Follow%20 on%20LinkedIn-8A2BE2?logo=linkedin" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.skyvern.com"&gt;Skyvern&lt;/a&gt; automates browser-based workflows using LLMs and computer vision. It provides a simple API endpoint to fully automate manual workflows on a large number of websites, replacing brittle or unreliable automation solutions.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/fern/images/geico_shu_recording_cropped.gif" /&gt; &lt;/p&gt; 
&lt;p&gt;Traditional approaches to browser automations required writing custom scripts for websites, often relying on DOM parsing and XPath-based interactions which would break whenever the website layouts changed.&lt;/p&gt; 
&lt;p&gt;Instead of only relying on code-defined XPath interactions, Skyvern relies on Vision LLMs to learn and interact with the websites.&lt;/p&gt; 
&lt;h1&gt;How it works&lt;/h1&gt; 
&lt;p&gt;Skyvern was inspired by the Task-Driven autonomous agent design popularized by &lt;a href="https://github.com/yoheinakajima/babyagi"&gt;BabyAGI&lt;/a&gt; and &lt;a href="https://github.com/Significant-Gravitas/AutoGPT"&gt;AutoGPT&lt;/a&gt; -- with one major bonus: we give Skyvern the ability to interact with websites using browser automation libraries like &lt;a href="https://playwright.dev/"&gt;Playwright&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Skyvern uses a swarm of agents to comprehend a website, and plan and execute its actions:&lt;/p&gt; 
&lt;picture&gt; 
 &lt;source media="(prefers-color-scheme: dark)" srcset="fern/images/skyvern_2_0_system_diagram.png" /&gt; 
 &lt;img src="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/fern/images/skyvern_2_0_system_diagram.png" /&gt; 
&lt;/picture&gt; 
&lt;p&gt;This approach has a few advantages:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Skyvern can operate on websites it's never seen before, as it's able to map visual elements to actions necessary to complete a workflow, without any customized code&lt;/li&gt; 
 &lt;li&gt;Skyvern is resistant to website layout changes, as there are no pre-determined XPaths or other selectors our system is looking for while trying to navigate&lt;/li&gt; 
 &lt;li&gt;Skyvern is able to take a single workflow and apply it to a large number of websites, as it's able to reason through the interactions necessary to complete the workflow&lt;/li&gt; 
 &lt;li&gt;Skyvern leverages LLMs to reason through interactions to ensure we can cover complex situations. Examples include: 
  &lt;ol&gt; 
   &lt;li&gt;If you wanted to get an auto insurance quote from Geico, the answer to a common question "Were you eligible to drive at 18?" could be inferred from the driver receiving their license at age 16&lt;/li&gt; 
   &lt;li&gt;If you were doing competitor analysis, it's understanding that an Arnold Palmer 22 oz can at 7/11 is almost definitely the same product as a 23 oz can at Gopuff (even though the sizes are slightly different, which could be a rounding error!)&lt;/li&gt; 
  &lt;/ol&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;A detailed technical report can be found &lt;a href="https://www.skyvern.com/blog/skyvern-2-0-state-of-the-art-web-navigation-with-85-8-on-webvoyager-eval/"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;Demo&lt;/h1&gt; 
&lt;!-- Redo demo --&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/5cab4668-e8e2-4982-8551-aab05ff73a7f"&gt;https://github.com/user-attachments/assets/5cab4668-e8e2-4982-8551-aab05ff73a7f&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Performance &amp;amp; Evaluation&lt;/h1&gt; 
&lt;p&gt;Skyvern has SOTA performance on the &lt;a href="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/webbench.ai"&gt;WebBench benchmark&lt;/a&gt; with a 64.4% accuracy. The technical report + evaluation can be found &lt;a href="https://www.skyvern.com/blog/web-bench-a-new-way-to-compare-ai-browser-agents/"&gt;here&lt;/a&gt;&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/fern/images/performance/webbench_overall.png" /&gt; &lt;/p&gt; 
&lt;h2&gt;Performance on WRITE tasks (eg filling out forms, logging in, downloading files, etc)&lt;/h2&gt; 
&lt;p&gt;Skyvern is the best performing agent on WRITE tasks (eg filling out forms, logging in, downloading files, etc), which is primarily used for RPA (Robotic Process Automation) adjacent tasks.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/fern/images/performance/webbench_write.png" /&gt; &lt;/p&gt; 
&lt;h1&gt;Quickstart&lt;/h1&gt; 
&lt;h2&gt;Skyvern Cloud&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://app.skyvern.com"&gt;Skyvern Cloud&lt;/a&gt; is a managed cloud version of Skyvern that allows you to run Skyvern without worrying about the infrastructure. It allows you to run multiple Skyvern instances in parallel and comes bundled with anti-bot detection mechanisms, proxy network, and CAPTCHA solvers.&lt;/p&gt; 
&lt;p&gt;If you'd like to try it out, navigate to &lt;a href="https://app.skyvern.com"&gt;app.skyvern.com&lt;/a&gt; and create an account.&lt;/p&gt; 
&lt;h2&gt;Install &amp;amp; Run&lt;/h2&gt; 
&lt;p&gt;Dependencies needed:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.python.org/downloads/"&gt;Python 3.11.x&lt;/a&gt;, works with 3.12, not ready yet for 3.13&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://nodejs.org/en/download/"&gt;NodeJS &amp;amp; NPM&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Additionally, for Windows:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://rustup.rs/"&gt;Rust&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;VS Code with C++ dev tools and Windows SDK&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;1. Install Skyvern&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install skyvern
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;2. Run Skyvern&lt;/h3&gt; 
&lt;p&gt;This is most helpful for first time run (db setup, db migrations etc).&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;skyvern quickstart
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;3. Run task&lt;/h3&gt; 
&lt;h4&gt;UI (Recommended)&lt;/h4&gt; 
&lt;p&gt;Start the Skyvern service and UI (when DB is up and running)&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;skyvern run all
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Go to &lt;a href="http://localhost:8080"&gt;http://localhost:8080&lt;/a&gt; and use the UI to run a task&lt;/p&gt; 
&lt;h4&gt;Code&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from skyvern import Skyvern

skyvern = Skyvern()
task = await skyvern.run_task(prompt="Find the top post on hackernews today")
print(task)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Skyvern starts running the task in a browser that pops up and closes it when the task is done. You will be able to view the task from &lt;a href="http://localhost:8080/history"&gt;http://localhost:8080/history&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;You can also run a task on different targets:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from skyvern import Skyvern

# Run on Skyvern Cloud
skyvern = Skyvern(api_key="SKYVERN API KEY")

# Local Skyvern service
skyvern = Skyvern(base_url="http://localhost:8000", api_key="LOCAL SKYVERN API KEY")

task = await skyvern.run_task(prompt="Find the top post on hackernews today")
print(task)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Advanced Usage&lt;/h2&gt; 
&lt;h3&gt;Control your own browser (Chrome)&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;‚ö†Ô∏è WARNING: Since &lt;a href="https://developer.chrome.com/blog/remote-debugging-port"&gt;Chrome 136&lt;/a&gt;, Chrome refuses any CDP connect to the browser using the default user_data_dir. In order to use your browser data, Skyvern copies your default user_data_dir to &lt;code&gt;./tmp/user_data_dir&lt;/code&gt; the first time connecting to your local browser. ‚ö†Ô∏è&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ol&gt; 
 &lt;li&gt;Just With Python Code&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from skyvern import Skyvern

# The path to your Chrome browser. This example path is for Mac.
browser_path = "/Applications/Google Chrome.app/Contents/MacOS/Google Chrome"
skyvern = Skyvern(
    base_url="http://localhost:8000",
    api_key="YOUR_API_KEY",
    browser_path=browser_path,
)
task = await skyvern.run_task(
    prompt="Find the top post on hackernews today",
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;With Skyvern Service&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Add two variables to your .env file:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# The path to your Chrome browser. This example path is for Mac.
CHROME_EXECUTABLE_PATH="/Applications/Google Chrome.app/Contents/MacOS/Google Chrome"
BROWSER_TYPE=cdp-connect
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Restart Skyvern service &lt;code&gt;skyvern run all&lt;/code&gt; and run the task through UI or code&lt;/p&gt; 
&lt;h3&gt;Run Skyvern with any remote browser&lt;/h3&gt; 
&lt;p&gt;Grab the cdp connection url and pass it to Skyvern&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from skyvern import Skyvern

skyvern = Skyvern(cdp_url="your cdp connection url")
task = await skyvern.run_task(
    prompt="Find the top post on hackernews today",
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Get consistent output schema from your run&lt;/h3&gt; 
&lt;p&gt;You can do this by adding the &lt;code&gt;data_extraction_schema&lt;/code&gt; parameter:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from skyvern import Skyvern

skyvern = Skyvern()
task = await skyvern.run_task(
    prompt="Find the top post on hackernews today",
    data_extraction_schema={
        "type": "object",
        "properties": {
            "title": {
                "type": "string",
                "description": "The title of the top post"
            },
            "url": {
                "type": "string",
                "description": "The URL of the top post"
            },
            "points": {
                "type": "integer",
                "description": "Number of points the post has received"
            }
        }
    }
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Helpful commands to debug issues&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Launch the Skyvern Server Separately*
skyvern run server

# Launch the Skyvern UI
skyvern run ui

# Check status of the Skyvern service
skyvern status

# Stop the Skyvern service
skyvern stop all

# Stop the Skyvern UI
skyvern stop ui

# Stop the Skyvern Server Separately
skyvern stop server
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Docker Compose setup&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;Make sure you have &lt;a href="https://www.docker.com/products/docker-desktop/"&gt;Docker Desktop&lt;/a&gt; installed and running on your machine&lt;/li&gt; 
 &lt;li&gt;Make sure you don't have postgres running locally (Run &lt;code&gt;docker ps&lt;/code&gt; to check)&lt;/li&gt; 
 &lt;li&gt;Clone the repository and navigate to the root directory&lt;/li&gt; 
 &lt;li&gt;Run &lt;code&gt;skyvern init llm&lt;/code&gt; to generate a &lt;code&gt;.env&lt;/code&gt; file. This will be copied into the Docker image.&lt;/li&gt; 
 &lt;li&gt;Fill in the LLM provider key on the &lt;a href="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/docker-compose.yml"&gt;docker-compose.yml&lt;/a&gt;. &lt;em&gt;If you want to run Skyvern on a remote server, make sure you set the correct server ip for the UI container in &lt;a href="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/docker-compose.yml"&gt;docker-compose.yml&lt;/a&gt;.&lt;/em&gt;&lt;/li&gt; 
 &lt;li&gt;Run the following command via the commandline: &lt;pre&gt;&lt;code class="language-bash"&gt; docker compose up -d
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;Navigate to &lt;code&gt;http://localhost:8080&lt;/code&gt; in your browser to start using the UI&lt;/li&gt; 
&lt;/ol&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Important:&lt;/strong&gt; Only one Postgres container can run on port 5432 at a time. If you switch from the CLI-managed Postgres to Docker Compose, you must first remove the original container:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;docker rm -f postgresql-container
&lt;/code&gt;&lt;/pre&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;If you encounter any database related errors while using Docker to run Skyvern, check which Postgres container is running with &lt;code&gt;docker ps&lt;/code&gt;.&lt;/p&gt; 
&lt;h1&gt;Skyvern Features&lt;/h1&gt; 
&lt;h2&gt;Skyvern Tasks&lt;/h2&gt; 
&lt;p&gt;Tasks are the fundamental building block inside Skyvern. Each task is a single request to Skyvern, instructing it to navigate through a website and accomplish a specific goal.&lt;/p&gt; 
&lt;p&gt;Tasks require you to specify a &lt;code&gt;url&lt;/code&gt;, &lt;code&gt;prompt&lt;/code&gt;, and can optionally include a &lt;code&gt;data schema&lt;/code&gt; (if you want the output to conform to a specific schema) and &lt;code&gt;error codes&lt;/code&gt; (if you want Skyvern to stop running in specific situations).&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/fern/images/skyvern_2_0_screenshot.png" /&gt; &lt;/p&gt; 
&lt;h2&gt;Skyvern Workflows&lt;/h2&gt; 
&lt;p&gt;Workflows are a way to chain multiple tasks together to form a cohesive unit of work.&lt;/p&gt; 
&lt;p&gt;For example, if you wanted to download all invoices newer than January 1st, you could create a workflow that first navigated to the invoices page, then filtered down to only show invoices newer than January 1st, extracted a list of all eligible invoices, and iterated through each invoice to download it.&lt;/p&gt; 
&lt;p&gt;Another example is if you wanted to automate purchasing products from an e-commerce store, you could create a workflow that first navigated to the desired product, then added it to a cart. Second, it would navigate to the cart and validate the cart state. Finally, it would go through the checkout process to purchase the items.&lt;/p&gt; 
&lt;p&gt;Supported workflow features include:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Browser Task&lt;/li&gt; 
 &lt;li&gt;Browser Action&lt;/li&gt; 
 &lt;li&gt;Data Extraction&lt;/li&gt; 
 &lt;li&gt;Validation&lt;/li&gt; 
 &lt;li&gt;For Loops&lt;/li&gt; 
 &lt;li&gt;File parsing&lt;/li&gt; 
 &lt;li&gt;Sending emails&lt;/li&gt; 
 &lt;li&gt;Text Prompts&lt;/li&gt; 
 &lt;li&gt;HTTP Request Block&lt;/li&gt; 
 &lt;li&gt;Custom Code Block&lt;/li&gt; 
 &lt;li&gt;Uploading files to block storage&lt;/li&gt; 
 &lt;li&gt;(Coming soon) Conditionals&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/fern/images/block_example_v2.png" /&gt; &lt;/p&gt; 
&lt;h2&gt;Livestreaming&lt;/h2&gt; 
&lt;p&gt;Skyvern allows you to livestream the viewport of the browser to your local machine so that you can see exactly what Skyvern is doing on the web. This is useful for debugging and understanding how Skyvern is interacting with a website, and intervening when necessary&lt;/p&gt; 
&lt;h2&gt;Form Filling&lt;/h2&gt; 
&lt;p&gt;Skyvern is natively capable of filling out form inputs on websites. Passing in information via the &lt;code&gt;navigation_goal&lt;/code&gt; will allow Skyvern to comprehend the information and fill out the form accordingly.&lt;/p&gt; 
&lt;h2&gt;Data Extraction&lt;/h2&gt; 
&lt;p&gt;Skyvern is also capable of extracting data from a website.&lt;/p&gt; 
&lt;p&gt;You can also specify a &lt;code&gt;data_extraction_schema&lt;/code&gt; directly within the main prompt to tell Skyvern exactly what data you'd like to extract from the website, in jsonc format. Skyvern's output will be structured in accordance to the supplied schema.&lt;/p&gt; 
&lt;h2&gt;File Downloading&lt;/h2&gt; 
&lt;p&gt;Skyvern is also capable of downloading files from a website. All downloaded files are automatically uploaded to block storage (if configured), and you can access them via the UI.&lt;/p&gt; 
&lt;h2&gt;Authentication&lt;/h2&gt; 
&lt;p&gt;Skyvern supports a number of different authentication methods to make it easier to automate tasks behind a login. If you'd like to try it out, please reach out to us &lt;a href="mailto:founders@skyvern.com"&gt;via email&lt;/a&gt; or &lt;a href="https://discord.gg/fG2XXEuQX3"&gt;discord&lt;/a&gt;.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/fern/images/secure_password_task_example.png" /&gt; &lt;/p&gt; 
&lt;h3&gt;üîê 2FA Support (TOTP)&lt;/h3&gt; 
&lt;p&gt;Skyvern supports a number of different 2FA methods to allow you to automate workflows that require 2FA.&lt;/p&gt; 
&lt;p&gt;Examples include:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;QR-based 2FA (e.g. Google Authenticator, Authy)&lt;/li&gt; 
 &lt;li&gt;Email based 2FA&lt;/li&gt; 
 &lt;li&gt;SMS based 2FA&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;üîê Learn more about 2FA support &lt;a href="https://www.skyvern.com/docs/credentials/totp"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Password Manager Integrations&lt;/h3&gt; 
&lt;p&gt;Skyvern currently supports the following password manager integrations:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Bitwarden&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; 1Password&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; LastPass&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Model Context Protocol (MCP)&lt;/h2&gt; 
&lt;p&gt;Skyvern supports the Model Context Protocol (MCP) to allow you to use any LLM that supports MCP.&lt;/p&gt; 
&lt;p&gt;See the MCP documentation &lt;a href="https://github.com/Skyvern-AI/skyvern/raw/main/integrations/mcp/README.md"&gt;here&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Zapier / Make.com / N8N Integration&lt;/h2&gt; 
&lt;p&gt;Skyvern supports Zapier, Make.com, and N8N to allow you to connect your Skyvern workflows to other apps.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.skyvern.com/docs/integrations/zapier"&gt;Zapier&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.skyvern.com/docs/integrations/make.com"&gt;Make.com&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.skyvern.com/docs/integrations/n8n"&gt;N8N&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;üîê Learn more about 2FA support &lt;a href="https://www.skyvern.com/docs/credentials/totp"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;Real-world examples of Skyvern&lt;/h1&gt; 
&lt;p&gt;We love to see how Skyvern is being used in the wild. Here are some examples of how Skyvern is being used to automate workflows in the real world. Please open PRs to add your own examples!&lt;/p&gt; 
&lt;h2&gt;Invoice Downloading on many different websites&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://meetings.hubspot.com/skyvern/demo"&gt;Book a demo to see it live&lt;/a&gt;&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/fern/images/invoice_downloading.gif" /&gt; &lt;/p&gt; 
&lt;h2&gt;Automate the job application process&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://app.skyvern.com/tasks/create/job_application"&gt;üí° See it in action&lt;/a&gt;&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/fern/images/job_application_demo.gif" /&gt; &lt;/p&gt; 
&lt;h2&gt;Automate materials procurement for a manufacturing company&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://app.skyvern.com/tasks/create/finditparts"&gt;üí° See it in action&lt;/a&gt;&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/fern/images/finditparts_recording_crop.gif" /&gt; &lt;/p&gt; 
&lt;h2&gt;Navigating to government websites to register accounts or fill out forms&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://app.skyvern.com/tasks/create/california_edd"&gt;üí° See it in action&lt;/a&gt;&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/fern/images/edd_services.gif" /&gt; &lt;/p&gt; 
&lt;!-- Add example of delaware entity lookups x2 --&gt; 
&lt;h2&gt;Filling out random contact us forms&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://app.skyvern.com/tasks/create/contact_us_forms"&gt;üí° See it in action&lt;/a&gt;&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/fern/images/contact_forms.gif" /&gt; &lt;/p&gt; 
&lt;h2&gt;Retrieving insurance quotes from insurance providers in any language&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://app.skyvern.com/tasks/create/bci_seguros"&gt;üí° See it in action&lt;/a&gt;&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/fern/images/bci_seguros_recording.gif" /&gt; &lt;/p&gt; 
&lt;p&gt;&lt;a href="https://app.skyvern.com/tasks/create/geico"&gt;üí° See it in action&lt;/a&gt;&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/fern/images/geico_shu_recording_cropped.gif" /&gt; &lt;/p&gt; 
&lt;h1&gt;Contributor Setup&lt;/h1&gt; 
&lt;p&gt;Make sure to have &lt;a href="https://docs.astral.sh/uv/getting-started/installation/"&gt;uv&lt;/a&gt; installed.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Run this to create your virtual environment (&lt;code&gt;.venv&lt;/code&gt;) &lt;pre&gt;&lt;code class="language-bash"&gt;uv sync --group dev
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;Perform initial server configuration &lt;pre&gt;&lt;code class="language-bash"&gt;uv run skyvern quickstart
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;Navigate to &lt;code&gt;http://localhost:8080&lt;/code&gt; in your browser to start using the UI &lt;em&gt;The Skyvern CLI supports Windows, WSL, macOS, and Linux environments.&lt;/em&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h1&gt;Documentation&lt;/h1&gt; 
&lt;p&gt;More extensive documentation can be found on our &lt;a href="https://www.skyvern.com/docs"&gt;üìï docs page&lt;/a&gt;. Please let us know if something is unclear or missing by opening an issue or reaching out to us &lt;a href="mailto:founders@skyvern.com"&gt;via email&lt;/a&gt; or &lt;a href="https://discord.gg/fG2XXEuQX3"&gt;discord&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;Supported LLMs&lt;/h1&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Provider&lt;/th&gt; 
   &lt;th&gt;Supported Models&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;OpenAI&lt;/td&gt; 
   &lt;td&gt;gpt4-turbo, gpt-4o, gpt-4o-mini&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Anthropic&lt;/td&gt; 
   &lt;td&gt;Claude 3 (Haiku, Sonnet, Opus), Claude 3.5 (Sonnet)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Azure OpenAI&lt;/td&gt; 
   &lt;td&gt;Any GPT models. Better performance with a multimodal llm (azure/gpt4-o)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;AWS Bedrock&lt;/td&gt; 
   &lt;td&gt;Anthropic Claude 3 (Haiku, Sonnet, Opus), Claude 3.5 (Sonnet)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Gemini&lt;/td&gt; 
   &lt;td&gt;Gemini 2.5 Pro and flash, Gemini 2.0&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Ollama&lt;/td&gt; 
   &lt;td&gt;Run any locally hosted model via &lt;a href="https://github.com/ollama/ollama"&gt;Ollama&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;OpenRouter&lt;/td&gt; 
   &lt;td&gt;Access models through &lt;a href="https://openrouter.ai"&gt;OpenRouter&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;OpenAI-compatible&lt;/td&gt; 
   &lt;td&gt;Any custom API endpoint that follows OpenAI's API format (via &lt;a href="https://docs.litellm.ai/docs/providers/openai_compatible"&gt;liteLLM&lt;/a&gt;)&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h4&gt;Environment Variables&lt;/h4&gt; 
&lt;h5&gt;OpenAI&lt;/h5&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Variable&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Type&lt;/th&gt; 
   &lt;th&gt;Sample Value&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;ENABLE_OPENAI&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Register OpenAI models&lt;/td&gt; 
   &lt;td&gt;Boolean&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;true&lt;/code&gt;, &lt;code&gt;false&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OPENAI_API_KEY&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;OpenAI API Key&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;sk-1234567890&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OPENAI_API_BASE&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;OpenAI API Base, optional&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;https://openai.api.base&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OPENAI_ORGANIZATION&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;OpenAI Organization ID, optional&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;your-org-id&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Recommended &lt;code&gt;LLM_KEY&lt;/code&gt;: &lt;code&gt;OPENAI_GPT4O&lt;/code&gt;, &lt;code&gt;OPENAI_GPT4O_MINI&lt;/code&gt;, &lt;code&gt;OPENAI_GPT4_1&lt;/code&gt;, &lt;code&gt;OPENAI_O4_MINI&lt;/code&gt;, &lt;code&gt;OPENAI_O3&lt;/code&gt;&lt;/p&gt; 
&lt;h5&gt;Anthropic&lt;/h5&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Variable&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Type&lt;/th&gt; 
   &lt;th&gt;Sample Value&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;ENABLE_ANTHROPIC&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Register Anthropic models&lt;/td&gt; 
   &lt;td&gt;Boolean&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;true&lt;/code&gt;, &lt;code&gt;false&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;ANTHROPIC_API_KEY&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Anthropic API key&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;sk-1234567890&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Recommended&lt;code&gt;LLM_KEY&lt;/code&gt;: &lt;code&gt;ANTHROPIC_CLAUDE3.5_SONNET&lt;/code&gt;, &lt;code&gt;ANTHROPIC_CLAUDE3.7_SONNET&lt;/code&gt;, &lt;code&gt;ANTHROPIC_CLAUDE4_OPUS&lt;/code&gt;, &lt;code&gt;ANTHROPIC_CLAUDE4_SONNET&lt;/code&gt;&lt;/p&gt; 
&lt;h5&gt;Azure OpenAI&lt;/h5&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Variable&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Type&lt;/th&gt; 
   &lt;th&gt;Sample Value&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;ENABLE_AZURE&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Register Azure OpenAI models&lt;/td&gt; 
   &lt;td&gt;Boolean&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;true&lt;/code&gt;, &lt;code&gt;false&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;AZURE_API_KEY&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Azure deployment API key&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;sk-1234567890&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;AZURE_DEPLOYMENT&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Azure OpenAI Deployment Name&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;skyvern-deployment&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;AZURE_API_BASE&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Azure deployment api base url&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;https://skyvern-deployment.openai.azure.com/&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;AZURE_API_VERSION&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Azure API Version&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;2024-02-01&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Recommended &lt;code&gt;LLM_KEY&lt;/code&gt;: &lt;code&gt;AZURE_OPENAI&lt;/code&gt;&lt;/p&gt; 
&lt;h5&gt;AWS Bedrock&lt;/h5&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Variable&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Type&lt;/th&gt; 
   &lt;th&gt;Sample Value&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;ENABLE_BEDROCK&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Register AWS Bedrock models. To use AWS Bedrock, you need to make sure your &lt;a href="https://github.com/boto/boto3?tab=readme-ov-file#using-boto3"&gt;AWS configurations&lt;/a&gt; are set up correctly first.&lt;/td&gt; 
   &lt;td&gt;Boolean&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;true&lt;/code&gt;, &lt;code&gt;false&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Recommended &lt;code&gt;LLM_KEY&lt;/code&gt;: &lt;code&gt;BEDROCK_ANTHROPIC_CLAUDE3.7_SONNET_INFERENCE_PROFILE&lt;/code&gt;, &lt;code&gt;BEDROCK_ANTHROPIC_CLAUDE4_OPUS_INFERENCE_PROFILE&lt;/code&gt;, &lt;code&gt;BEDROCK_ANTHROPIC_CLAUDE4_SONNET_INFERENCE_PROFILE&lt;/code&gt;&lt;/p&gt; 
&lt;h5&gt;Gemini&lt;/h5&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Variable&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Type&lt;/th&gt; 
   &lt;th&gt;Sample Value&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;ENABLE_GEMINI&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Register Gemini models&lt;/td&gt; 
   &lt;td&gt;Boolean&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;true&lt;/code&gt;, &lt;code&gt;false&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;GEMINI_API_KEY&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Gemini API Key&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;your_google_gemini_api_key&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Recommended &lt;code&gt;LLM_KEY&lt;/code&gt;: &lt;code&gt;GEMINI_2.5_PRO_PREVIEW&lt;/code&gt;, &lt;code&gt;GEMINI_2.5_FLASH_PREVIEW&lt;/code&gt;&lt;/p&gt; 
&lt;h5&gt;Ollama&lt;/h5&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Variable&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Type&lt;/th&gt; 
   &lt;th&gt;Sample Value&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;ENABLE_OLLAMA&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Register local models via Ollama&lt;/td&gt; 
   &lt;td&gt;Boolean&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;true&lt;/code&gt;, &lt;code&gt;false&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OLLAMA_SERVER_URL&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;URL for your Ollama server&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;http://host.docker.internal:11434&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OLLAMA_MODEL&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Ollama model name to load&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;qwen2.5:7b-instruct&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Recommended &lt;code&gt;LLM_KEY&lt;/code&gt;: &lt;code&gt;OLLAMA&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;Note: Ollama does not support vision yet.&lt;/p&gt; 
&lt;h5&gt;OpenRouter&lt;/h5&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Variable&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Type&lt;/th&gt; 
   &lt;th&gt;Sample Value&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;ENABLE_OPENROUTER&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Register OpenRouter models&lt;/td&gt; 
   &lt;td&gt;Boolean&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;true&lt;/code&gt;, &lt;code&gt;false&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OPENROUTER_API_KEY&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;OpenRouter API key&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;sk-1234567890&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OPENROUTER_MODEL&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;OpenRouter model name&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;mistralai/mistral-small-3.1-24b-instruct&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OPENROUTER_API_BASE&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;OpenRouter API base URL&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;https://api.openrouter.ai/v1&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Recommended &lt;code&gt;LLM_KEY&lt;/code&gt;: &lt;code&gt;OPENROUTER&lt;/code&gt;&lt;/p&gt; 
&lt;h5&gt;OpenAI-Compatible&lt;/h5&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Variable&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Type&lt;/th&gt; 
   &lt;th&gt;Sample Value&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;ENABLE_OPENAI_COMPATIBLE&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Register a custom OpenAI-compatible API endpoint&lt;/td&gt; 
   &lt;td&gt;Boolean&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;true&lt;/code&gt;, &lt;code&gt;false&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OPENAI_COMPATIBLE_MODEL_NAME&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Model name for OpenAI-compatible endpoint&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;yi-34b&lt;/code&gt;, &lt;code&gt;gpt-3.5-turbo&lt;/code&gt;, &lt;code&gt;mistral-large&lt;/code&gt;, etc.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OPENAI_COMPATIBLE_API_KEY&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;API key for OpenAI-compatible endpoint&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;sk-1234567890&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OPENAI_COMPATIBLE_API_BASE&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Base URL for OpenAI-compatible endpoint&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;https://api.together.xyz/v1&lt;/code&gt;, &lt;code&gt;http://localhost:8000/v1&lt;/code&gt;, etc.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OPENAI_COMPATIBLE_API_VERSION&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;API version for OpenAI-compatible endpoint, optional&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;2023-05-15&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OPENAI_COMPATIBLE_MAX_TOKENS&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Maximum tokens for completion, optional&lt;/td&gt; 
   &lt;td&gt;Integer&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;4096&lt;/code&gt;, &lt;code&gt;8192&lt;/code&gt;, etc.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OPENAI_COMPATIBLE_TEMPERATURE&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Temperature setting, optional&lt;/td&gt; 
   &lt;td&gt;Float&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;0.0&lt;/code&gt;, &lt;code&gt;0.5&lt;/code&gt;, &lt;code&gt;0.7&lt;/code&gt;, etc.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OPENAI_COMPATIBLE_SUPPORTS_VISION&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Whether model supports vision, optional&lt;/td&gt; 
   &lt;td&gt;Boolean&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;true&lt;/code&gt;, &lt;code&gt;false&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Supported LLM Key: &lt;code&gt;OPENAI_COMPATIBLE&lt;/code&gt;&lt;/p&gt; 
&lt;h5&gt;General LLM Configuration&lt;/h5&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Variable&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Type&lt;/th&gt; 
   &lt;th&gt;Sample Value&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;LLM_KEY&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;The name of the model you want to use&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;See supported LLM keys above&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;SECONDARY_LLM_KEY&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;The name of the model for mini agents skyvern runs with&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;See supported LLM keys above&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;LLM_CONFIG_MAX_TOKENS&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Override the max tokens used by the LLM&lt;/td&gt; 
   &lt;td&gt;Integer&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;128000&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h1&gt;Feature Roadmap&lt;/h1&gt; 
&lt;p&gt;This is our planned roadmap for the next few months. If you have any suggestions or would like to see a feature added, please don't hesitate to reach out to us &lt;a href="mailto:founders@skyvern.com"&gt;via email&lt;/a&gt; or &lt;a href="https://discord.gg/fG2XXEuQX3"&gt;discord&lt;/a&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;Open Source&lt;/strong&gt; - Open Source Skyvern's core codebase&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;Workflow support&lt;/strong&gt; - Allow support to chain multiple Skyvern calls together&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;Improved context&lt;/strong&gt; - Improve Skyvern's ability to understand content around interactable elements by introducing feeding relevant label context through the text prompt&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;Cost Savings&lt;/strong&gt; - Improve Skyvern's stability and reduce the cost of running Skyvern by optimizing the context tree passed into Skyvern&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;Self-serve UI&lt;/strong&gt; - Deprecate the Streamlit UI in favour of a React-based UI component that allows users to kick off new jobs in Skyvern&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;Workflow UI Builder&lt;/strong&gt; - Introduce a UI to allow users to build and analyze workflows visually&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;Chrome Viewport streaming&lt;/strong&gt; - Introduce a way to live-stream the Chrome viewport to the user's browser (as a part of the self-serve UI)&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;Past Runs UI&lt;/strong&gt; - Deprecate the Streamlit UI in favour of a React-based UI that allows you to visualize past runs and their results&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;Auto workflow builder ("Observer") mode&lt;/strong&gt; - Allow Skyvern to auto-generate workflows as it's navigating the web to make it easier to build new workflows&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;Prompt Caching&lt;/strong&gt; - Introduce a caching layer to the LLM calls to dramatically reduce the cost of running Skyvern (memorize past actions and repeat them!)&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;Web Evaluation Dataset&lt;/strong&gt; - Integrate Skyvern with public benchmark tests to track the quality of our models over time&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;strong&gt;Improved Debug mode&lt;/strong&gt; - Allow Skyvern to plan its actions and get "approval" before running them, allowing you to debug what it's doing and more easily iterate on the prompt&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;strong&gt;Chrome Extension&lt;/strong&gt; - Allow users to interact with Skyvern through a Chrome extension (incl voice mode, saving tasks, etc.)&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;strong&gt;Skyvern Action Recorder&lt;/strong&gt; - Allow Skyvern to watch a user complete a task and then automatically generate a workflow for it&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;strong&gt;Interactable Livestream&lt;/strong&gt; - Allow users to interact with the livestream in real-time to intervene when necessary (such as manually submitting sensitive forms)&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;strong&gt;Integrate LLM Observability tools&lt;/strong&gt; - Integrate LLM Observability tools to allow back-testing prompt changes with specific data sets + visualize the performance of Skyvern over time&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;Langchain Integration&lt;/strong&gt; - Create langchain integration in langchain_community to use Skyvern as a "tool".&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Contributing&lt;/h1&gt; 
&lt;p&gt;We welcome PRs and suggestions! Don't hesitate to open a PR/issue or to reach out to us &lt;a href="mailto:founders@skyvern.com"&gt;via email&lt;/a&gt; or &lt;a href="https://discord.gg/fG2XXEuQX3"&gt;discord&lt;/a&gt;. Please have a look at our &lt;a href="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/CONTRIBUTING.md"&gt;contribution guide&lt;/a&gt; and &lt;a href="https://github.com/skyvern-ai/skyvern/issues?q=is%3Aopen+is%3Aissue+label%3A%22help+wanted%22"&gt;"Help Wanted" issues&lt;/a&gt; to get started!&lt;/p&gt; 
&lt;p&gt;If you want to chat with the skyvern repository to get a high level overview of how it is structured, how to build off it, and how to resolve usage questions, check out &lt;a href="https://sage.storia.ai?utm_source=github&amp;amp;utm_medium=referral&amp;amp;utm_campaign=skyvern-readme"&gt;Code Sage&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;Telemetry&lt;/h1&gt; 
&lt;p&gt;By Default, Skyvern collects basic usage statistics to help us understand how Skyvern is being used. If you would like to opt-out of telemetry, please set the &lt;code&gt;SKYVERN_TELEMETRY&lt;/code&gt; environment variable to &lt;code&gt;false&lt;/code&gt;.&lt;/p&gt; 
&lt;h1&gt;License&lt;/h1&gt; 
&lt;p&gt;Skyvern's open source repository is supported via a managed cloud. All of the core logic powering Skyvern is available in this open source repository licensed under the &lt;a href="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/LICENSE"&gt;AGPL-3.0 License&lt;/a&gt;, with the exception of anti-bot measures available in our managed cloud offering.&lt;/p&gt; 
&lt;p&gt;If you have any questions or concerns around licensing, please &lt;a href="mailto:support@skyvern.com"&gt;contact us&lt;/a&gt; and we would be happy to help.&lt;/p&gt; 
&lt;h1&gt;Star History&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://star-history.com/#Skyvern-AI/skyvern&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=Skyvern-AI/skyvern&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>HKUDS/DeepCode</title>
      <link>https://github.com/HKUDS/DeepCode</link>
      <description>&lt;p&gt;"DeepCode: Open Agentic Coding (Paper2Code &amp; Text2Web &amp; Text2Backend)"&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;table style="border: none; margin: 0 auto; padding: 0; border-collapse: collapse;"&gt; 
  &lt;tbody&gt;
   &lt;tr&gt; 
    &lt;td align="center" style="vertical-align: middle; padding: 10px; border: none; width: 250px;"&gt; &lt;img src="https://raw.githubusercontent.com/HKUDS/DeepCode/main/assets/logo.png" alt="DeepCode Logo" width="200" style="margin: 0; padding: 0; display: block;" /&gt; &lt;/td&gt; 
    &lt;td align="left" style="vertical-align: middle; padding: 10px 0 10px 30px; border: none;"&gt; &lt;pre style="font-family: 'Courier New', monospace; font-size: 16px; color: #0EA5E9; margin: 0; padding: 0; text-shadow: 0 0 10px #0EA5E9, 0 0 20px rgba(14,165,233,0.5); line-height: 1.2; transform: skew(-1deg, 0deg); display: block;"&gt;    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó
    ‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ïê‚ïù‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ïê‚ïù‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ïê‚ïù‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ñà‚ñà‚ïó‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ïê‚ïù
    ‚ñà‚ñà‚ïë  ‚ñà‚ñà‚ïë‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù‚ñà‚ñà‚ïë     ‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë  ‚ñà‚ñà‚ïë‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó
    ‚ñà‚ñà‚ïë  ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïê‚ïê‚ïù  ‚ñà‚ñà‚ïî‚ïê‚ïê‚ïù  ‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ïù ‚ñà‚ñà‚ïë     ‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë  ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïê‚ïê‚ïù
    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ïë     ‚ïö‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ïö‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó
    ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù‚ïö‚ïê‚ïù      ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù&lt;/pre&gt; &lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt;
 &lt;/table&gt; 
 &lt;div align="center"&gt; 
  &lt;a href="https://trendshift.io/repositories/14665" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/14665" alt="HKUDS%2FDeepCode | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt; 
 &lt;/div&gt; 
 &lt;!-- &lt;img src="https://readme-typing-svg.herokuapp.com?font=Russo+One&amp;size=28&amp;duration=2000&amp;pause=800&amp;color=06B6D4&amp;background=00000000&amp;center=true&amp;vCenter=true&amp;width=800&amp;height=50&amp;lines=%E2%9A%A1+OPEN+AGENTIC+CODING+%E2%9A%A1" alt="DeepCode Tech Subtitle" style="margin-top: 5px; filter: drop-shadow(0 0 12px #06B6D4) drop-shadow(0 0 24px rgba(6,182,212,0.4));"/&gt; --&gt; 
 &lt;h1&gt;&lt;img src="https://github.com/Zongwei9888/Experiment_Images/raw/43c585dca3d21b8e4b6390d835cdd34dc4b4b23d/DeepCode_images/title_logo.svg?sanitize=true" alt="DeepCode Logo" width="32" height="32" style="vertical-align: middle; margin-right: 8px;" /&gt; DeepCode: Open Agentic Coding&lt;/h1&gt; 
 &lt;h3&gt;&lt;em&gt;Advancing Code Generation with Multi-Agent Systems&lt;/em&gt;&lt;/h3&gt; 
 &lt;!-- &lt;p align="center"&gt;
  &lt;img src="https://img.shields.io/badge/Version-1.0.0-00d4ff?style=for-the-badge&amp;logo=rocket&amp;logoColor=white" alt="Version"&gt;

  &lt;img src="https://img.shields.io/badge/License-MIT-4ecdc4?style=for-the-badge&amp;logo=opensourceinitiative&amp;logoColor=white" alt="License"&gt;
  &lt;img src="https://img.shields.io/badge/AI-Multi--Agent-9b59b6?style=for-the-badge&amp;logo=brain&amp;logoColor=white" alt="AI"&gt;
  &lt;img src="https://img.shields.io/badge/HKU-Data_Intelligence_Lab-f39c12?style=for-the-badge&amp;logo=university&amp;logoColor=white" alt="HKU"&gt;
&lt;/p&gt; --&gt; 
 &lt;p&gt; &lt;a href="https://github.com/HKUDS/DeepCode/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/HKUDS/DeepCode?color=00d9ff&amp;amp;style=for-the-badge&amp;amp;logo=star&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/badge/üêçPython-3.13-4ecdc4?style=for-the-badge&amp;amp;logo=python&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt; &lt;a href="https://pypi.org/project/deepcode-hku/"&gt;&lt;img src="https://img.shields.io/pypi/v/deepcode-hku.svg?style=for-the-badge&amp;amp;logo=pypi&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e&amp;amp;color=ff6b6b" /&gt;&lt;/a&gt; &lt;/p&gt; 
 &lt;p&gt; &lt;a href="https://discord.gg/yF2MmDJyGJ"&gt;&lt;img src="https://img.shields.io/badge/üí¨Discord-Community-7289da?style=for-the-badge&amp;amp;logo=discord&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt;&lt;/a&gt; &lt;a href="https://github.com/HKUDS/DeepCode/issues/11"&gt;&lt;img src="https://img.shields.io/badge/üí¨WeChat-Group-07c160?style=for-the-badge&amp;amp;logo=wechat&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt;&lt;/a&gt; &lt;/p&gt; 
 &lt;div align="center"&gt; 
  &lt;div style="width: 100%; height: 2px; margin: 20px 0; background: linear-gradient(90deg, transparent, #00d9ff, transparent);"&gt;&lt;/div&gt; 
 &lt;/div&gt; 
 &lt;div align="center"&gt; 
  &lt;a href="https://raw.githubusercontent.com/HKUDS/DeepCode/main/#-quick-start" style="text-decoration: none;"&gt; &lt;img src="https://img.shields.io/badge/Quick%20Start-Get%20Started%20Now-00d9ff?style=for-the-badge&amp;amp;logo=rocket&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt; &lt;/a&gt; 
 &lt;/div&gt; 
 &lt;div align="center" style="margin-top: 10px;"&gt; 
  &lt;a href="https://raw.githubusercontent.com/HKUDS/DeepCode/main/README.md"&gt; &lt;img src="https://img.shields.io/badge/English-00d4ff?style=for-the-badge&amp;amp;logo=readme&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" alt="English" /&gt; &lt;/a&gt; 
  &lt;a href="https://raw.githubusercontent.com/HKUDS/DeepCode/main/README_ZH.md"&gt; &lt;img src="https://img.shields.io/badge/‰∏≠Êñá-00d4ff?style=for-the-badge&amp;amp;logo=readme&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" alt="‰∏≠Êñá" /&gt; &lt;/a&gt; 
 &lt;/div&gt; 
 &lt;h3&gt;üñ•Ô∏è &lt;strong&gt;Interface Showcase&lt;/strong&gt;&lt;/h3&gt; 
 &lt;table align="center" width="100%" style="border: none; border-collapse: collapse; margin: 30px 0;"&gt; 
  &lt;tbody&gt;
   &lt;tr&gt; 
    &lt;td width="50%" align="center" style="vertical-align: top; padding: 20px;"&gt; &lt;h4&gt;üñ•Ô∏è &lt;strong&gt;CLI Interface&lt;/strong&gt;&lt;/h4&gt; &lt;p&gt;&lt;strong&gt;Terminal-Based Development&lt;/strong&gt;&lt;/p&gt; 
     &lt;div align="center"&gt; 
      &lt;img src="https://github.com/Zongwei9888/Experiment_Images/raw/8882a7313c504ca97ead6e7b36c51aa761b6a4f3/DeepCode_images/CLI.gif" alt="CLI Interface Demo" width="100%" style="border-radius: 10px; box-shadow: 0 8px 20px rgba(45,55,72,0.3); margin: 15px 0;" /&gt; 
      &lt;div style="background: linear-gradient(135deg, #2D3748 0%, #4A5568 100%); border-radius: 12px; padding: 15px; margin: 15px 0; color: white;"&gt; 
       &lt;strong&gt;üöÄ Advanced Terminal Experience&lt;/strong&gt;
       &lt;br /&gt; 
       &lt;small&gt;‚ö° Fast command-line workflow&lt;br /&gt;üîß Developer-friendly interface&lt;br /&gt;üìä Real-time progress tracking&lt;/small&gt; 
      &lt;/div&gt; 
      &lt;p&gt;&lt;em&gt;Professional terminal interface for advanced users and CI/CD integration&lt;/em&gt;&lt;/p&gt; 
     &lt;/div&gt; &lt;/td&gt; 
    &lt;td width="50%" align="center" style="vertical-align: top; padding: 20px;"&gt; &lt;h4&gt;üåê &lt;strong&gt;Web Interface&lt;/strong&gt;&lt;/h4&gt; &lt;p&gt;&lt;strong&gt;Visual Interactive Experience&lt;/strong&gt;&lt;/p&gt; 
     &lt;div align="center"&gt; 
      &lt;img src="https://github.com/Zongwei9888/Experiment_Images/raw/8882a7313c504ca97ead6e7b36c51aa761b6a4f3/DeepCode_images/UI.gif" alt="Web Interface Demo" width="100%" style="border-radius: 10px; box-shadow: 0 8px 20px rgba(14,165,233,0.3); margin: 15px 0;" /&gt; 
      &lt;div style="background: linear-gradient(135deg, #0EA5E9 0%, #00D4FF 100%); border-radius: 12px; padding: 15px; margin: 15px 0; color: white;"&gt; 
       &lt;strong&gt;üé® Modern Web Dashboard&lt;/strong&gt;
       &lt;br /&gt; 
       &lt;small&gt;üñ±Ô∏è Intuitive drag-and-drop&lt;br /&gt;üì± Responsive design&lt;br /&gt;üéØ Visual progress tracking&lt;/small&gt; 
      &lt;/div&gt; 
      &lt;p&gt;&lt;em&gt;Beautiful web interface with streamlined workflow for all skill levels&lt;/em&gt;&lt;/p&gt; 
     &lt;/div&gt; &lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt;
 &lt;/table&gt; 
 &lt;hr /&gt; 
 &lt;div align="center"&gt; 
  &lt;h3&gt;üé¨ &lt;strong&gt;Introduction Video&lt;/strong&gt;&lt;/h3&gt; 
  &lt;div style="margin: 20px 0;"&gt; 
   &lt;a href="https://youtu.be/PRgmP8pOI08" target="_blank"&gt; &lt;img src="https://img.youtube.com/vi/PRgmP8pOI08/maxresdefault.jpg" alt="DeepCode Introduction Video" width="75%" style="border-radius: 12px; box-shadow: 0 8px 25px rgba(0,0,0,0.15); transition: transform 0.3s ease;" /&gt; &lt;/a&gt; 
  &lt;/div&gt; 
  &lt;p&gt;&lt;em&gt;üéØ &lt;strong&gt;Watch our complete introduction&lt;/strong&gt; - See how DeepCode transforms research papers and natural language into production-ready code&lt;/em&gt;&lt;/p&gt; 
  &lt;p&gt; &lt;a href="https://youtu.be/PRgmP8pOI08" target="_blank"&gt; &lt;img src="https://img.shields.io/badge/‚ñ∂Ô∏è_Watch_Video-FF0000?style=for-the-badge&amp;amp;logo=youtube&amp;amp;logoColor=white" alt="Watch Video" /&gt; &lt;/a&gt; &lt;/p&gt; 
 &lt;/div&gt; 
 &lt;hr /&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;&lt;em&gt;"Where AI Agents Transform Ideas into Production-Ready Code"&lt;/em&gt;&lt;/p&gt; 
 &lt;/blockquote&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üìë Table of Contents&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/DeepCode/main/#-news"&gt;üì∞ News&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/DeepCode/main/#-key-features"&gt;üöÄ Key Features&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/DeepCode/main/#%EF%B8%8F-architecture"&gt;üèóÔ∏è Architecture&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/DeepCode/main/#-experimental-results"&gt;üìä Experimental Results&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/DeepCode/main/#-quick-start"&gt;üöÄ Quick Start&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/DeepCode/main/#-examples"&gt;üí° Examples&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/DeepCode/main/#-live-demonstrations"&gt;üé¨ Live Demonstrations&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/DeepCode/main/#-star-history"&gt;‚≠ê Star History&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/DeepCode/main/#-license"&gt;üìÑ License&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üì∞ News&lt;/h2&gt; 
&lt;p&gt;üéâ &lt;strong&gt;[2025-10] üéâ [2025-10-28] DeepCode Achieves SOTA on PaperBench!&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;DeepCode sets new benchmarks on OpenAI's PaperBench Code-Dev across all categories:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;üèÜ &lt;strong&gt;Surpasses Human Experts&lt;/strong&gt;: &lt;strong&gt;75.9%&lt;/strong&gt; (DeepCode) vs Top Machine Learning PhDs 72.4% (+3.5%).&lt;/li&gt; 
 &lt;li&gt;ü•á &lt;strong&gt;Outperforms SOTA Commercial Code Agents&lt;/strong&gt;: &lt;strong&gt;84.8%&lt;/strong&gt; (DeepCode) vs Leading Commercial Code Agents (+26.1%) (Cursor, Claude Code, and Codex).&lt;/li&gt; 
 &lt;li&gt;üî¨ &lt;strong&gt;Advances Scientific Coding&lt;/strong&gt;: &lt;strong&gt;73.5%&lt;/strong&gt; (DeepCode) vs PaperCoder 51.1% (+22.4%).&lt;/li&gt; 
 &lt;li&gt;üöÄ &lt;strong&gt;Beats LLM Agents&lt;/strong&gt;: &lt;strong&gt;73.5%&lt;/strong&gt; (DeepCode) vs best LLM frameworks 43.3% (+30.2%).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üöÄ Key Features&lt;/h2&gt; 
&lt;br /&gt; 
&lt;table align="center" width="100%" style="border: none; table-layout: fixed;"&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td width="30%" align="center" style="vertical-align: top; padding: 20px;"&gt; 
    &lt;div style="height: 80px; display: flex; align-items: center; justify-content: center;"&gt; 
     &lt;h3 style="margin: 0; padding: 0;"&gt;üöÄ &lt;strong&gt;Paper2Code&lt;/strong&gt;&lt;/h3&gt; 
    &lt;/div&gt; 
    &lt;div align="center" style="margin: 15px 0;"&gt; 
     &lt;img src="https://img.shields.io/badge/ALGORITHM-IMPLEMENTATION-ff6b6b?style=for-the-badge&amp;amp;logo=algorithm&amp;amp;logoColor=white" alt="Algorithm Badge" /&gt; 
    &lt;/div&gt; 
    &lt;div style="height: 80px; display: flex; align-items: center; justify-content: center;"&gt; 
     &lt;p align="center"&gt;&lt;strong&gt;Automated Implementation of Complex Algorithms&lt;/strong&gt;&lt;/p&gt; 
    &lt;/div&gt; 
    &lt;div style="height: 60px; display: flex; align-items: center; justify-content: center;"&gt; 
     &lt;p align="center"&gt;Effortlessly converts complex algorithms from research papers into &lt;strong&gt;high-quality&lt;/strong&gt;, &lt;strong&gt;production-ready&lt;/strong&gt; code, accelerating algorithm reproduction.&lt;/p&gt; 
    &lt;/div&gt; &lt;/td&gt; 
   &lt;td width="30%" align="center" style="vertical-align: top; padding: 20px;"&gt; 
    &lt;div style="height: 80px; display: flex; align-items: center; justify-content: center;"&gt; 
     &lt;h3 style="margin: 0; padding: 0;"&gt;üé® &lt;strong&gt;Text2Web&lt;/strong&gt;&lt;/h3&gt; 
    &lt;/div&gt; 
    &lt;div align="center" style="margin: 15px 0;"&gt; 
     &lt;img src="https://img.shields.io/badge/FRONTEND-DEVELOPMENT-4ecdc4?style=for-the-badge&amp;amp;logo=react&amp;amp;logoColor=white" alt="Frontend Badge" /&gt; 
    &lt;/div&gt; 
    &lt;div style="height: 80px; display: flex; align-items: center; justify-content: center;"&gt; 
     &lt;p align="center"&gt;&lt;strong&gt;Automated Front-End Web Development&lt;/strong&gt;&lt;/p&gt; 
    &lt;/div&gt; 
    &lt;div style="height: 60px; display: flex; align-items: center; justify-content: center;"&gt; 
     &lt;p align="center"&gt;Translates plain textual descriptions into &lt;strong&gt;fully functional&lt;/strong&gt;, &lt;strong&gt;visually appealing&lt;/strong&gt; front-end web code for rapid interface creation.&lt;/p&gt; 
    &lt;/div&gt; &lt;/td&gt; 
   &lt;td width="30%" align="center" style="vertical-align: top; padding: 20px;"&gt; 
    &lt;div style="height: 80px; display: flex; align-items: center; justify-content: center;"&gt; 
     &lt;h3 style="margin: 0; padding: 0;"&gt;‚öôÔ∏è &lt;strong&gt;Text2Backend&lt;/strong&gt;&lt;/h3&gt; 
    &lt;/div&gt; 
    &lt;div align="center" style="margin: 15px 0;"&gt; 
     &lt;img src="https://img.shields.io/badge/BACKEND-DEVELOPMENT-9b59b6?style=for-the-badge&amp;amp;logo=server&amp;amp;logoColor=white" alt="Backend Badge" /&gt; 
    &lt;/div&gt; 
    &lt;div style="height: 80px; display: flex; align-items: center; justify-content: center;"&gt; 
     &lt;p align="center"&gt;&lt;strong&gt;Automated Back-End Development&lt;/strong&gt;&lt;/p&gt; 
    &lt;/div&gt; 
    &lt;div style="height: 60px; display: flex; align-items: center; justify-content: center;"&gt; 
     &lt;p align="center"&gt;Generates &lt;strong&gt;efficient&lt;/strong&gt;, &lt;strong&gt;scalable&lt;/strong&gt;, and &lt;strong&gt;feature-rich&lt;/strong&gt; back-end code from simple text inputs, streamlining server-side development.&lt;/p&gt; 
    &lt;/div&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;br /&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üìä Experimental Results&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/HKUDS/DeepCode/main/assets/result_main02.jpg" /&gt;
 &lt;br /&gt; 
&lt;/div&gt; 
&lt;br /&gt; 
&lt;p&gt;We evaluate &lt;strong&gt;DeepCode&lt;/strong&gt; on the &lt;a href="https://openai.com/index/paperbench/"&gt;&lt;em&gt;PaperBench&lt;/em&gt;&lt;/a&gt; benchmark (released by OpenAI), a rigorous testbed requiring AI agents to independently reproduce 20 ICML 2024 papers from scratch. The benchmark comprises 8,316 gradable components assessed using SimpleJudge with hierarchical weighting.&lt;/p&gt; 
&lt;p&gt;Our experiments compare DeepCode against four baseline categories: &lt;strong&gt;(1) Human Experts&lt;/strong&gt;, &lt;strong&gt;(2) State-of-the-Art Commercial Code Agents&lt;/strong&gt;, &lt;strong&gt;(3) Scientific Code Agents&lt;/strong&gt;, and &lt;strong&gt;(4) LLM-Based Agents&lt;/strong&gt;.&lt;/p&gt; 
&lt;h3&gt;‚ë† üß† Human Expert Performance (Top Machine Learning PhD)&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;DeepCode: 75.9% vs. Top Machine Learning PhD: 72.4% (+3.5%)&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;DeepCode achieves &lt;strong&gt;75.9%&lt;/strong&gt; on the 3-paper human evaluation subset, &lt;strong&gt;surpassing the best-of-3 human expert baseline (72.4%) by +3.5 percentage points&lt;/strong&gt;. This demonstrates that our framework not only matches but exceeds expert-level code reproduction capabilities, representing a significant milestone in autonomous scientific software engineering.&lt;/p&gt; 
&lt;h3&gt;‚ë° üíº State-of-the-Art Commercial Code Agents&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;DeepCode: 84.8% vs. Best Commercial Agent: 58.7% (+26.1%)&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;On the 5-paper subset, DeepCode substantially outperforms leading commercial coding tools:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Cursor: 58.4%&lt;/li&gt; 
 &lt;li&gt;Claude Code: 58.7%&lt;/li&gt; 
 &lt;li&gt;Codex: 40.0%&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;DeepCode: 84.8%&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;This represents a &lt;strong&gt;+26.1% improvement&lt;/strong&gt; over the leading commercial code agent. All commercial agents utilize Claude Sonnet 4.5 or GPT-5 Codex-high, highlighting that &lt;strong&gt;DeepCode's superior architecture&lt;/strong&gt;‚Äîrather than base model capability‚Äîdrives this performance gap.&lt;/p&gt; 
&lt;h3&gt;‚ë¢ üî¨ Scientific Code Agents&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;DeepCode: 73.5% vs. PaperCoder: 51.1% (+22.4%)&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Compared to PaperCoder (&lt;strong&gt;51.1%&lt;/strong&gt;), the state-of-the-art scientific code reproduction framework, DeepCode achieves &lt;strong&gt;73.5%&lt;/strong&gt;, demonstrating a &lt;strong&gt;+22.4% relative improvement&lt;/strong&gt;. This substantial margin validates our multi-module architecture combining planning, hierarchical task decomposition, code generation, and iterative debugging over simpler pipeline-based approaches.&lt;/p&gt; 
&lt;h3&gt;‚ë£ ü§ñ LLM-Based Agents&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;DeepCode: 73.5% vs. Best LLM Agent: 43.3% (+30.2%)&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;DeepCode significantly outperforms all tested LLM agents:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Claude 3.5 Sonnet + IterativeAgent: 27.5%&lt;/li&gt; 
 &lt;li&gt;o1 + IterativeAgent (36 hours): 42.4%&lt;/li&gt; 
 &lt;li&gt;o1 BasicAgent: 43.3%&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;DeepCode: 73.5%&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The &lt;strong&gt;+30.2% improvement&lt;/strong&gt; over the best-performing LLM agent demonstrates that sophisticated agent scaffolding, rather than extended inference time or larger models, is critical for complex code reproduction tasks.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h3&gt;üéØ &lt;strong&gt;Autonomous Self-Orchestrating Multi-Agent Architecture&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;The Challenges&lt;/strong&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;üìÑ &lt;strong&gt;Implementation Complexity&lt;/strong&gt;: Converting academic papers and complex algorithms into working code requires significant technical effort and domain expertise&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;üî¨ &lt;strong&gt;Research Bottleneck&lt;/strong&gt;: Researchers spend valuable time implementing algorithms instead of focusing on their core research and discovery work&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;‚è±Ô∏è &lt;strong&gt;Development Delays&lt;/strong&gt;: Product teams experience long wait times between concept and testable prototypes, slowing down innovation cycles&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;üîÑ &lt;strong&gt;Repetitive Coding&lt;/strong&gt;: Developers repeatedly implement similar patterns and functionality instead of building on existing solutions&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;DeepCode&lt;/strong&gt; addresses these workflow inefficiencies by providing reliable automation for common development tasks, streamlining your development workflow from concept to code.&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;pre&gt;&lt;code class="language-mermaid"&gt;flowchart LR
    A["üìÑ Research Papers&amp;lt;br/&amp;gt;üí¨ Text Prompts&amp;lt;br/&amp;gt;üåê URLs &amp;amp; Document&amp;lt;br/&amp;gt;üìé Files: PDF, DOC, PPTX, TXT, HTML"] --&amp;gt; B["üß† DeepCode&amp;lt;br/&amp;gt;Multi-Agent Engine"]
    B --&amp;gt; C["üöÄ Algorithm Implementation &amp;lt;br/&amp;gt;üé® Frontend Development &amp;lt;br/&amp;gt;‚öôÔ∏è Backend Development"]

    style A fill:#ff6b6b,stroke:#c0392b,stroke-width:2px,color:#000
    style B fill:#00d4ff,stroke:#0984e3,stroke-width:3px,color:#000
    style C fill:#00b894,stroke:#00a085,stroke-width:2px,color:#000
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üèóÔ∏è Architecture&lt;/h2&gt; 
&lt;h3&gt;üìä &lt;strong&gt;System Overview&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;DeepCode&lt;/strong&gt; is an AI-powered development platform that automates code generation and implementation tasks. Our multi-agent system handles the complexity of translating requirements into functional, well-structured code, allowing you to focus on innovation rather than implementation details.&lt;/p&gt; 
&lt;p&gt;üéØ &lt;strong&gt;Technical Capabilities&lt;/strong&gt;:&lt;/p&gt; 
&lt;p&gt;üß¨ &lt;strong&gt;Research-to-Production Pipeline&lt;/strong&gt;&lt;br /&gt; Multi-modal document analysis engine that extracts algorithmic logic and mathematical models from academic papers. Generates optimized implementations with proper data structures while preserving computational complexity characteristics.&lt;/p&gt; 
&lt;p&gt;ü™Ñ &lt;strong&gt;Natural Language Code Synthesis&lt;/strong&gt;&lt;br /&gt; Context-aware code generation using fine-tuned language models trained on curated code repositories. Maintains architectural consistency across modules while supporting multiple programming languages and frameworks.&lt;/p&gt; 
&lt;p&gt;‚ö° &lt;strong&gt;Automated Prototyping Engine&lt;/strong&gt;&lt;br /&gt; Intelligent scaffolding system generating complete application structures including database schemas, API endpoints, and frontend components. Uses dependency analysis to ensure scalable architecture from initial generation.&lt;/p&gt; 
&lt;p&gt;üíé &lt;strong&gt;Quality Assurance Automation&lt;/strong&gt;&lt;br /&gt; Integrated static analysis with automated unit test generation and documentation synthesis. Employs AST analysis for code correctness and property-based testing for comprehensive coverage.&lt;/p&gt; 
&lt;p&gt;üîÆ &lt;strong&gt;CodeRAG Integration System&lt;/strong&gt;&lt;br /&gt; Advanced retrieval-augmented generation combining semantic vector embeddings with graph-based dependency analysis. Automatically discovers optimal libraries and implementation patterns from large-scale code corpus.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h3&gt;üîß &lt;strong&gt;Core Techniques&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;üß† &lt;strong&gt;Intelligent Orchestration Agent&lt;/strong&gt;: Central decision-making system that coordinates workflow phases and analyzes requirements. Employs dynamic planning algorithms to adapt execution strategies in real-time based on evolving project complexity. Dynamically selects optimal processing strategies for each implementation step. &lt;br /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;üíæ &lt;strong&gt;Efficient Memory Mechanism&lt;/strong&gt;: Advanced context engineering system that manages large-scale code contexts efficiently. Implements hierarchical memory structures with intelligent compression for handling complex codebases. This component enables instant retrieval of implementation patterns and maintains semantic coherence across extended development sessions. &lt;br /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;üîç &lt;strong&gt;Advanced CodeRAG System&lt;/strong&gt;: Global code comprehension engine that analyzes complex inter-dependencies across repositories. Performs cross-codebase relationship mapping to understand architectural patterns from a holistic perspective. This module leverages dependency graphs and semantic analysis to provide globally-aware code recommendations during implementation.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h3&gt;ü§ñ &lt;strong&gt;Multi-Agent Architecture of DeepCode&lt;/strong&gt;:&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;üéØ Central Orchestrating Agent&lt;/strong&gt;: Orchestrates entire workflow execution and makes strategic decisions. Coordinates specialized agents based on input complexity analysis. Implements dynamic task planning and resource allocation algorithms. &lt;br /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;üìù Intent Understanding Agent&lt;/strong&gt;: Performs deep semantic analysis of user requirements to decode complex intentions. Extracts functional specifications and technical constraints through advanced NLP processing. Transforms ambiguous human descriptions into precise, actionable development specifications with structured task decomposition. &lt;br /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;üìÑ Document Parsing Agent&lt;/strong&gt;: Processes complex technical documents and research papers with advanced parsing capabilities. Extracts algorithms and methodologies using document understanding models. Converts academic concepts into practical implementation specifications through intelligent content analysis. &lt;br /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;üèóÔ∏è Code Planning Agent&lt;/strong&gt;: Performs architectural design and technology stack optimization. Dynamic planning for adaptive development roadmaps. Enforces coding standards and generates modular structures through automated design pattern selection.&lt;br /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;üîç Code Reference Mining Agent&lt;/strong&gt;: Discovers relevant repositories and frameworks through intelligent search algorithms. Analyzes codebases for compatibility and integration potential. Provides recommendations based on similarity metrics and automated dependency analysis. &lt;br /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;üìö Code Indexing Agent&lt;/strong&gt;: Builds comprehensive knowledge graphs of discovered codebases. Maintains semantic relationships between code components. Enables intelligent retrieval and cross-reference capabilities. &lt;br /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;üß¨ Code Generation Agent&lt;/strong&gt;: Synthesizes gathered information into executable code implementations. Creates functional interfaces and integrates discovered components. Generates comprehensive test suites and documentation for reproducibility.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h4&gt;üõ†Ô∏è &lt;strong&gt;Implementation Tools Matrix&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;&lt;strong&gt;üîß Powered by MCP (Model Context Protocol)&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;DeepCode leverages the &lt;strong&gt;Model Context Protocol (MCP)&lt;/strong&gt; standard to seamlessly integrate with various tools and services. This standardized approach ensures reliable communication between AI agents and external systems, enabling powerful automation capabilities.&lt;/p&gt; 
&lt;h5&gt;üì° &lt;strong&gt;MCP Servers &amp;amp; Tools&lt;/strong&gt;&lt;/h5&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;üõ†Ô∏è &lt;strong&gt;MCP Server&lt;/strong&gt;&lt;/th&gt; 
   &lt;th&gt;üîß &lt;strong&gt;Primary Function&lt;/strong&gt;&lt;/th&gt; 
   &lt;th&gt;üí° &lt;strong&gt;Purpose &amp;amp; Capabilities&lt;/strong&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;üîç brave&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Web Search Engine&lt;/td&gt; 
   &lt;td&gt;Real-time information retrieval via Brave Search API&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;üåê bocha-mcp&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Alternative Search&lt;/td&gt; 
   &lt;td&gt;Secondary search option with independent API access&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;üìÇ filesystem&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;File System Operations&lt;/td&gt; 
   &lt;td&gt;Local file and directory management, read/write operations&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;üåê fetch&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Web Content Retrieval&lt;/td&gt; 
   &lt;td&gt;Fetch and extract content from URLs and web resources&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;üì• github-downloader&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Repository Management&lt;/td&gt; 
   &lt;td&gt;Clone and download GitHub repositories for analysis&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;üìã file-downloader&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Document Processing&lt;/td&gt; 
   &lt;td&gt;Download and convert files (PDF, DOCX, etc.) to Markdown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;‚ö° command-executor&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;System Commands&lt;/td&gt; 
   &lt;td&gt;Execute bash/shell commands for environment management&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;üß¨ code-implementation&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Code Generation Hub&lt;/td&gt; 
   &lt;td&gt;Comprehensive code reproduction with execution and testing&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;üìö code-reference-indexer&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Smart Code Search&lt;/td&gt; 
   &lt;td&gt;Intelligent indexing and search of code repositories&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;üìÑ document-segmentation&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Smart Document Analysis&lt;/td&gt; 
   &lt;td&gt;Intelligent document segmentation for large papers and technical documents&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h5&gt;üîß &lt;strong&gt;Legacy Tool Functions&lt;/strong&gt; &lt;em&gt;(for reference)&lt;/em&gt;&lt;/h5&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;üõ†Ô∏è &lt;strong&gt;Function&lt;/strong&gt;&lt;/th&gt; 
   &lt;th&gt;üéØ &lt;strong&gt;Usage Context&lt;/strong&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;üìÑ read_code_mem&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Efficient code context retrieval from memory&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;‚úçÔ∏è write_file&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Direct file content generation and modification&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;üêç execute_python&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Python code testing and validation&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;üìÅ get_file_structure&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Project structure analysis and organization&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;‚öôÔ∏è set_workspace&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Dynamic workspace and environment configuration&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;üìä get_operation_history&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Process monitoring and operation tracking&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;hr /&gt; 
&lt;p&gt;üéõÔ∏è &lt;strong&gt;Multi-Interface Framework&lt;/strong&gt;&lt;br /&gt; RESTful API with CLI and web frontends featuring real-time code streaming, interactive debugging, and extensible plugin architecture for CI/CD integration.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;üöÄ Multi-Agent Intelligent Pipeline:&lt;/strong&gt;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;h3&gt;üåü &lt;strong&gt;Intelligence Processing Flow&lt;/strong&gt;&lt;/h3&gt; 
 &lt;table align="center" width="100%" style="border: none; border-collapse: collapse;"&gt; 
  &lt;tbody&gt;
   &lt;tr&gt; 
    &lt;td colspan="3" align="center" style="padding: 20px; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); border-radius: 15px; color: white; font-weight: bold;"&gt; üí° &lt;strong&gt;INPUT LAYER&lt;/strong&gt;&lt;br /&gt; üìÑ Research Papers ‚Ä¢ üí¨ Natural Language ‚Ä¢ üåê URLs ‚Ä¢ üìã Requirements &lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt;
    &lt;td colspan="3" height="20"&gt;&lt;/td&gt;
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td colspan="3" align="center" style="padding: 15px; background: linear-gradient(135deg, #ff6b6b 0%, #ee5a24 100%); border-radius: 12px; color: white; font-weight: bold;"&gt; üéØ &lt;strong&gt;CENTRAL ORCHESTRATION&lt;/strong&gt;&lt;br /&gt; Strategic Decision Making ‚Ä¢ Workflow Coordination ‚Ä¢ Agent Management &lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt;
    &lt;td colspan="3" height="15"&gt;&lt;/td&gt;
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center" style="padding: 12px; background: linear-gradient(135deg, #3742fa 0%, #2f3542 100%); border-radius: 10px; color: white; width: 50%;"&gt; üìù &lt;strong&gt;TEXT ANALYSIS&lt;/strong&gt;&lt;br /&gt; &lt;small&gt;Requirement Processing&lt;/small&gt; &lt;/td&gt; 
    &lt;td width="10"&gt;&lt;/td&gt; 
    &lt;td align="center" style="padding: 12px; background: linear-gradient(135deg, #8c7ae6 0%, #9c88ff 100%); border-radius: 10px; color: white; width: 50%;"&gt; üìÑ &lt;strong&gt;DOCUMENT ANALYSIS&lt;/strong&gt;&lt;br /&gt; &lt;small&gt;Paper &amp;amp; Spec Processing&lt;/small&gt; &lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt;
    &lt;td colspan="3" height="15"&gt;&lt;/td&gt;
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td colspan="3" align="center" style="padding: 15px; background: linear-gradient(135deg, #00d2d3 0%, #54a0ff 100%); border-radius: 12px; color: white; font-weight: bold;"&gt; üìã &lt;strong&gt;REPRODUCTION PLANNING&lt;/strong&gt;&lt;br /&gt; Deep Paper Analysis ‚Ä¢ Code Requirements Parsing ‚Ä¢ Reproduction Strategy Development &lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt;
    &lt;td colspan="3" height="15"&gt;&lt;/td&gt;
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center" style="padding: 12px; background: linear-gradient(135deg, #ffa726 0%, #ff7043 100%); border-radius: 10px; color: white; width: 50%;"&gt; üîç &lt;strong&gt;REFERENCE ANALYSIS&lt;/strong&gt;&lt;br /&gt; &lt;small&gt;Repository Discovery&lt;/small&gt; &lt;/td&gt; 
    &lt;td width="10"&gt;&lt;/td&gt; 
    &lt;td align="center" style="padding: 12px; background: linear-gradient(135deg, #e056fd 0%, #f368e0 100%); border-radius: 10px; color: white; width: 50%;"&gt; üìö &lt;strong&gt;CODE INDEXING&lt;/strong&gt;&lt;br /&gt; &lt;small&gt;Knowledge Graph Building&lt;/small&gt; &lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt;
    &lt;td colspan="3" height="15"&gt;&lt;/td&gt;
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td colspan="3" align="center" style="padding: 15px; background: linear-gradient(135deg, #26de81 0%, #20bf6b 100%); border-radius: 12px; color: white; font-weight: bold;"&gt; üß¨ &lt;strong&gt;CODE IMPLEMENTATION&lt;/strong&gt;&lt;br /&gt; Implementation Generation ‚Ä¢ Testing ‚Ä¢ Documentation &lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt;
    &lt;td colspan="3" height="15"&gt;&lt;/td&gt;
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td colspan="3" align="center" style="padding: 20px; background: linear-gradient(135deg, #045de9 0%, #09c6f9 100%); border-radius: 15px; color: white; font-weight: bold;"&gt; ‚ö° &lt;strong&gt;OUTPUT DELIVERY&lt;/strong&gt;&lt;br /&gt; üì¶ Complete Codebase ‚Ä¢ üß™ Test Suite ‚Ä¢ üìö Documentation ‚Ä¢ üöÄ Deployment Ready &lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt;
 &lt;/table&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;br /&gt; 
 &lt;h3&gt;üîÑ &lt;strong&gt;Process Intelligence Features&lt;/strong&gt;&lt;/h3&gt; 
 &lt;table align="center" style="border: none;"&gt; 
  &lt;tbody&gt;
   &lt;tr&gt; 
    &lt;td align="center" width="25%" style="padding: 15px;"&gt; 
     &lt;div style="background: #f8f9fa; border-radius: 10px; padding: 15px; border-left: 4px solid #ff6b6b;"&gt; 
      &lt;h4&gt;üéØ Adaptive Flow&lt;/h4&gt; 
      &lt;p&gt;&lt;small&gt;Dynamic agent selection based on input complexity&lt;/small&gt;&lt;/p&gt; 
     &lt;/div&gt; &lt;/td&gt; 
    &lt;td align="center" width="25%" style="padding: 15px;"&gt; 
     &lt;div style="background: #f8f9fa; border-radius: 10px; padding: 15px; border-left: 4px solid #4ecdc4;"&gt; 
      &lt;h4&gt;üß† Smart Coordination&lt;/h4&gt; 
      &lt;p&gt;&lt;small&gt;Intelligent task distribution and parallel processing&lt;/small&gt;&lt;/p&gt; 
     &lt;/div&gt; &lt;/td&gt; 
    &lt;td align="center" width="25%" style="padding: 15px;"&gt; 
     &lt;div style="background: #f8f9fa; border-radius: 10px; padding: 15px; border-left: 4px solid #45b7d1;"&gt; 
      &lt;h4&gt;üîç Context Awareness&lt;/h4&gt; 
      &lt;p&gt;&lt;small&gt;Deep understanding through CodeRAG integration&lt;/small&gt;&lt;/p&gt; 
     &lt;/div&gt; &lt;/td&gt; 
    &lt;td align="center" width="25%" style="padding: 15px;"&gt; 
     &lt;div style="background: #f8f9fa; border-radius: 10px; padding: 15px; border-left: 4px solid #96ceb4;"&gt; 
      &lt;h4&gt;‚ö° Quality Assurance&lt;/h4&gt; 
      &lt;p&gt;&lt;small&gt;Automated testing and validation throughout&lt;/small&gt;&lt;/p&gt; 
     &lt;/div&gt; &lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt;
 &lt;/table&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üöÄ Quick Start&lt;/h2&gt; 
&lt;h3&gt;üì¶ &lt;strong&gt;Step 1: Installation&lt;/strong&gt;&lt;/h3&gt; 
&lt;h4&gt;‚ö° &lt;strong&gt;Direct Installation (Recommended)&lt;/strong&gt;&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# üöÄ Install DeepCode package directly
pip install deepcode-hku

# üîë Download configuration files
curl -O https://raw.githubusercontent.com/HKUDS/DeepCode/main/mcp_agent.config.yaml
curl -O https://raw.githubusercontent.com/HKUDS/DeepCode/main/mcp_agent.secrets.yaml

# üîë Configure API keys (required)
# Edit mcp_agent.secrets.yaml with your API keys and base_url:
# - openai: api_key, base_url (for OpenAI/custom endpoints)
# - anthropic: api_key (for Claude models)

# üîë Configure search API keys for web search (optional)
# Edit mcp_agent.config.yaml to set your API keys:
# - For Brave Search: Set BRAVE_API_KEY: "your_key_here" in brave.env section (line ~28)
# - For Bocha-MCP: Set BOCHA_API_KEY: "your_key_here" in bocha-mcp.env section (line ~74)

# üìÑ Configure document segmentation (optional)
# Edit mcp_agent.config.yaml to control document processing:
# - enabled: true/false (whether to use intelligent document segmentation)
# - size_threshold_chars: 50000 (document size threshold to trigger segmentation)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;üîß &lt;strong&gt;Development Installation (From Source)&lt;/strong&gt;&lt;/h4&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;üìÇ Click to expand development installation options&lt;/strong&gt;&lt;/summary&gt; 
 &lt;h5&gt;üî• &lt;strong&gt;Using UV (Recommended for Development)&lt;/strong&gt;&lt;/h5&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# üîΩ Clone the repository
git clone https://github.com/HKUDS/DeepCode.git
cd DeepCode/

# üì¶ Install UV package manager
curl -LsSf https://astral.sh/uv/install.sh | sh

# üîß Install dependencies with UV
uv venv --python=3.13
source .venv/bin/activate  # On Windows: .venv\Scripts\activate
uv pip install -r requirements.txt

# üîë Configure API keys (required)
# Edit mcp_agent.secrets.yaml with your API keys and base_url:
# - openai: api_key, base_url (for OpenAI/custom endpoints)
# - anthropic: api_key (for Claude models)

# üîë Configure search API keys for web search (optional)
# Edit mcp_agent.config.yaml to set your API keys:
# - For Brave Search: Set BRAVE_API_KEY: "your_key_here" in brave.env section (line ~28)
# - For Bocha-MCP: Set BOCHA_API_KEY: "your_key_here" in bocha-mcp.env section (line ~74)

# üìÑ Configure document segmentation (optional)
# Edit mcp_agent.config.yaml to control document processing:
# - enabled: true/false (whether to use intelligent document segmentation)
# - size_threshold_chars: 50000 (document size threshold to trigger segmentation)
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h5&gt;üêç &lt;strong&gt;Using Traditional pip&lt;/strong&gt;&lt;/h5&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# üîΩ Clone the repository
git clone https://github.com/HKUDS/DeepCode.git
cd DeepCode/

# üì¶ Install dependencies
pip install -r requirements.txt

# üîë Configure API keys (required)
# Edit mcp_agent.secrets.yaml with your API keys and base_url:
# - openai: api_key, base_url (for OpenAI/custom endpoints)
# - anthropic: api_key (for Claude models)

# üîë Configure search API keys for web search (optional)
# Edit mcp_agent.config.yaml to set your API keys:
# - For Brave Search: Set BRAVE_API_KEY: "your_key_here" in brave.env section (line ~28)
# - For Bocha-MCP: Set BOCHA_API_KEY: "your_key_here" in bocha-mcp.env section (line ~74)

# üìÑ Configure document segmentation (optional)
# Edit mcp_agent.config.yaml to control document processing:
# - enabled: true/false (whether to use intelligent document segmentation)
# - size_threshold_chars: 50000 (document size threshold to trigger segmentation)
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h4&gt;ü™ü &lt;strong&gt;Windows Users: Additional MCP Server Configuration&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;If you're using Windows, you may need to configure MCP servers manually in &lt;code&gt;mcp_agent.config.yaml&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# 1. Install MCP servers globally
npm i -g @modelcontextprotocol/server-brave-search
npm i -g @modelcontextprotocol/server-filesystem

# 2. Find your global node_modules path
npm -g root
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then update your &lt;code&gt;mcp_agent.config.yaml&lt;/code&gt; to use absolute paths:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;mcp:
  servers:
    brave:
      command: "node"
      args: ["C:/Program Files/nodejs/node_modules/@modelcontextprotocol/server-brave-search/dist/index.js"]
    filesystem:
      command: "node"
      args: ["C:/Program Files/nodejs/node_modules/@modelcontextprotocol/server-filesystem/dist/index.js", "."]
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: Replace the path with your actual global node_modules path from step 2.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;üîç &lt;strong&gt;Search Server Configuration (Optional)&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;DeepCode supports multiple search servers for web search functionality. You can configure your preferred option in &lt;code&gt;mcp_agent.config.yaml&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;# Default search server configuration
# Options: "brave" or "bocha-mcp"
default_search_server: "brave"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Available Options:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;üîç Brave Search&lt;/strong&gt; (&lt;code&gt;"brave"&lt;/code&gt;):&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Default option with high-quality search results&lt;/li&gt; 
   &lt;li&gt;Requires BRAVE_API_KEY configuration&lt;/li&gt; 
   &lt;li&gt;Recommended for most users&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;üåê Bocha-MCP&lt;/strong&gt; (&lt;code&gt;"bocha-mcp"&lt;/code&gt;):&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Alternative search server option&lt;/li&gt; 
   &lt;li&gt;Requires BOCHA_API_KEY configuration&lt;/li&gt; 
   &lt;li&gt;Uses local Python server implementation&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;API Key Configuration in mcp_agent.config.yaml:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;# For Brave Search (default) - around line 28
brave:
  command: "npx"
  args: ["-y", "@modelcontextprotocol/server-brave-search"]
  env:
    BRAVE_API_KEY: "your_brave_api_key_here"

# For Bocha-MCP (alternative) - around line 74
bocha-mcp:
  command: "python"
  args: ["tools/bocha_search_server.py"]
  env:
    PYTHONPATH: "."
    BOCHA_API_KEY: "your_bocha_api_key_here"
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;üí° Tip&lt;/strong&gt;: Both search servers require API key configuration. Choose the one that best fits your API access and requirements.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;‚ö° &lt;strong&gt;Step 2: Launch Application&lt;/strong&gt;&lt;/h3&gt; 
&lt;h4&gt;üöÄ &lt;strong&gt;Using Installed Package (Recommended)&lt;/strong&gt;&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# üåê Launch web interface directly
deepcode

# The application will automatically start at http://localhost:8501
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;üõ†Ô∏è &lt;strong&gt;Using Source Code&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;Choose your preferred interface:&lt;/p&gt; 
&lt;h5&gt;üåê &lt;strong&gt;Web Interface&lt;/strong&gt; (Recommended)&lt;/h5&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Using UV
uv run streamlit run ui/streamlit_app.py
# Or using traditional Python
streamlit run ui/streamlit_app.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://img.shields.io/badge/Access-localhost:8501-00d4ff?style=flat-square&amp;amp;logo=streamlit&amp;amp;logoColor=white" alt="Web Access" /&gt; 
&lt;/div&gt; 
&lt;h5&gt;üñ•Ô∏è &lt;strong&gt;CLI Interface&lt;/strong&gt; (Advanced Users)&lt;/h5&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Using UV
uv run python cli/main_cli.py
# Or using traditional Python
python cli/main_cli.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://img.shields.io/badge/Mode-Interactive_Terminal-9b59b6?style=flat-square&amp;amp;logo=terminal&amp;amp;logoColor=white" alt="CLI Mode" /&gt; 
&lt;/div&gt; 
&lt;h3&gt;üéØ &lt;strong&gt;Step 3: Generate Code&lt;/strong&gt;&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;üìÑ Input&lt;/strong&gt;: Upload your research paper, provide requirements, or paste a URL&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ü§ñ Processing&lt;/strong&gt;: Watch the multi-agent system analyze and plan&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;‚ö° Output&lt;/strong&gt;: Receive production-ready code with tests and documentation&lt;/li&gt; 
&lt;/ol&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üí° Examples&lt;/h2&gt; 
&lt;h3&gt;üé¨ &lt;strong&gt;Live Demonstrations&lt;/strong&gt;&lt;/h3&gt; 
&lt;table align="center"&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td width="33%" align="center"&gt; &lt;h4&gt;üìÑ &lt;strong&gt;Paper2Code Demo&lt;/strong&gt;&lt;/h4&gt; &lt;p&gt;&lt;strong&gt;Research to Implementation&lt;/strong&gt;&lt;/p&gt; 
    &lt;div align="center"&gt; 
     &lt;a href="https://www.youtube.com/watch?v=MQZYpLkzsbw"&gt; &lt;img src="https://img.youtube.com/vi/MQZYpLkzsbw/maxresdefault.jpg" alt="Paper2Code Demo" width="100%" style="border-radius: 10px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);" /&gt; &lt;/a&gt; 
     &lt;p&gt;&lt;strong&gt;&lt;a href="https://www.youtube.com/watch?v=MQZYpLkzsbw"&gt;‚ñ∂Ô∏è Watch Demo&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
     &lt;p&gt;&lt;em&gt;Transform academic papers into production-ready code automatically&lt;/em&gt;&lt;/p&gt; 
    &lt;/div&gt; &lt;/td&gt; 
   &lt;td width="33%" align="center"&gt; &lt;h4&gt;üñºÔ∏è &lt;strong&gt;Image Processing Demo&lt;/strong&gt;&lt;/h4&gt; &lt;p&gt;&lt;strong&gt;AI-Powered Image Tools&lt;/strong&gt;&lt;/p&gt; 
    &lt;div align="center"&gt; 
     &lt;a href="https://www.youtube.com/watch?v=nFt5mLaMEac"&gt; &lt;img src="https://img.youtube.com/vi/nFt5mLaMEac/maxresdefault.jpg" alt="Image Processing Demo" width="100%" style="border-radius: 10px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);" /&gt; &lt;/a&gt; 
     &lt;p&gt;&lt;strong&gt;&lt;a href="https://www.youtube.com/watch?v=nFt5mLaMEac"&gt;‚ñ∂Ô∏è Watch Demo&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
     &lt;p&gt;&lt;em&gt;Intelligent image processing with background removal and enhancement&lt;/em&gt;&lt;/p&gt; 
    &lt;/div&gt; &lt;/td&gt; 
   &lt;td width="33%" align="center"&gt; &lt;h4&gt;üåê &lt;strong&gt;Frontend Implementation&lt;/strong&gt;&lt;/h4&gt; &lt;p&gt;&lt;strong&gt;Complete Web Application&lt;/strong&gt;&lt;/p&gt; 
    &lt;div align="center"&gt; 
     &lt;a href="https://www.youtube.com/watch?v=78wx3dkTaAU"&gt; &lt;img src="https://img.youtube.com/vi/78wx3dkTaAU/maxresdefault.jpg" alt="Frontend Demo" width="100%" style="border-radius: 10px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);" /&gt; &lt;/a&gt; 
     &lt;p&gt;&lt;strong&gt;&lt;a href="https://www.youtube.com/watch?v=78wx3dkTaAU"&gt;‚ñ∂Ô∏è Watch Demo&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
     &lt;p&gt;&lt;em&gt;Full-stack web development from concept to deployment&lt;/em&gt;&lt;/p&gt; 
    &lt;/div&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h3&gt;üÜï &lt;strong&gt;Recent Updates&lt;/strong&gt;&lt;/h3&gt; 
&lt;h4&gt;üìÑ &lt;strong&gt;Smart Document Segmentation (v1.2.0)&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Intelligent Processing&lt;/strong&gt;: Automatically handles large research papers and technical documents that exceed LLM token limits&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Configurable Control&lt;/strong&gt;: Toggle segmentation via configuration with size-based thresholds&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Semantic Analysis&lt;/strong&gt;: Advanced content understanding with algorithm, concept, and formula preservation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Backward Compatibility&lt;/strong&gt;: Seamlessly falls back to traditional processing for smaller documents&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üöÄ &lt;strong&gt;Coming Soon&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;We're continuously enhancing DeepCode with exciting new features:&lt;/p&gt; 
&lt;h4&gt;üîß &lt;strong&gt;Enhanced Code Reliability &amp;amp; Validation&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Automated Testing&lt;/strong&gt;: Comprehensive functionality testing with execution verification and error detection.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Code Quality Assurance&lt;/strong&gt;: Multi-level validation through static analysis, dynamic testing, and performance benchmarking.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Smart Debugging&lt;/strong&gt;: AI-powered error detection with automatic correction suggestions&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;üìä &lt;strong&gt;PaperBench Performance Showcase&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Benchmark Dashboard&lt;/strong&gt;: Comprehensive performance metrics on the PaperBench evaluation suite.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Accuracy Metrics&lt;/strong&gt;: Detailed comparison with state-of-the-art paper reproduction systems.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Success Analytics&lt;/strong&gt;: Statistical analysis across paper categories and complexity levels.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;‚ö° &lt;strong&gt;System-wide Optimizations&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Performance Boost&lt;/strong&gt;: Multi-threaded processing and optimized agent coordination for faster generation.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Enhanced Reasoning&lt;/strong&gt;: Advanced reasoning capabilities with improved context understanding.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Expanded Support&lt;/strong&gt;: Extended compatibility with additional programming languages and frameworks.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;‚≠ê Star History&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;em&gt;Community Growth Trajectory&lt;/em&gt;&lt;/p&gt; 
 &lt;a href="https://star-history.com/#HKUDS/DeepCode&amp;amp;Date"&gt; 
  &lt;picture&gt; 
   &lt;source media="(prefers-color-scheme: dark)" srcset="https://api.star-history.com/svg?repos=HKUDS/DeepCode&amp;amp;type=Date&amp;amp;theme=dark" /&gt; 
   &lt;source media="(prefers-color-scheme: light)" srcset="https://api.star-history.com/svg?repos=HKUDS/DeepCode&amp;amp;type=Date" /&gt; 
   &lt;img alt="Star History Chart" src="https://api.star-history.com/svg?repos=HKUDS/DeepCode&amp;amp;type=Date" style="border-radius: 15px; box-shadow: 0 0 30px rgba(0, 217, 255, 0.3);" /&gt; 
  &lt;/picture&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h3&gt;üöÄ &lt;strong&gt;Ready to Transform Development?&lt;/strong&gt;&lt;/h3&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt; &lt;a href="https://raw.githubusercontent.com/HKUDS/DeepCode/main/#-quick-start"&gt;&lt;img src="https://img.shields.io/badge/üöÄ_Get_Started-00d4ff?style=for-the-badge&amp;amp;logo=rocket&amp;amp;logoColor=white" alt="Get Started" /&gt;&lt;/a&gt; &lt;a href="https://github.com/HKUDS"&gt;&lt;img src="https://img.shields.io/badge/üèõÔ∏è_View_on_GitHub-00d4ff?style=for-the-badge&amp;amp;logo=github&amp;amp;logoColor=white" alt="View on GitHub" /&gt;&lt;/a&gt; &lt;a href="https://github.com/HKUDS/deepcode-agent"&gt;&lt;img src="https://img.shields.io/badge/‚≠ê_Star_Project-00d4ff?style=for-the-badge&amp;amp;logo=star&amp;amp;logoColor=white" alt="Star Project" /&gt;&lt;/a&gt; &lt;/p&gt; 
 &lt;hr /&gt; 
 &lt;h3&gt;üìÑ &lt;strong&gt;License&lt;/strong&gt;&lt;/h3&gt; 
 &lt;img src="https://img.shields.io/badge/License-MIT-4ecdc4?style=for-the-badge&amp;amp;logo=opensourceinitiative&amp;amp;logoColor=white" alt="MIT License" /&gt; 
 &lt;p&gt;&lt;strong&gt;MIT License&lt;/strong&gt; - Copyright (c) 2025 Data Intelligence Lab, The University of Hong Kong&lt;/p&gt; 
 &lt;hr /&gt; 
 &lt;img src="https://visitor-badge.laobi.icu/badge?page_id=deepcode.readme&amp;amp;style=for-the-badge&amp;amp;color=00d4ff" alt="Visitors" /&gt; 
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>localstack/localstack</title>
      <link>https://github.com/localstack/localstack</link>
      <description>&lt;p&gt;üíª A fully functional local AWS cloud stack. Develop and test your cloud &amp; Serverless apps offline&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;span&gt;‚ö°&lt;/span&gt; We are thrilled to announce the release of &lt;a href="https://blog.localstack.cloud/localstack-for-aws-release-v-4-9-0/"&gt;LocalStack 4.9&lt;/a&gt; &lt;span&gt;‚ö°&lt;/span&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/localstack/localstack/main/docs/localstack-readme-banner.svg?sanitize=true" alt="LocalStack - The Leading Platform for Local Cloud Development" /&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/localstack/localstack/actions/workflows/aws-main.yml?query=branch%3Amain"&gt;&lt;img alt="GitHub Actions" src="https://github.com/localstack/localstack/actions/workflows/aws-main.yml/badge.svg?branch=main" /&gt;&lt;/a&gt; &lt;a href="https://coveralls.io/github/localstack/localstack?branch=main"&gt;&lt;img alt="Coverage Status" src="https://coveralls.io/repos/github/localstack/localstack/badge.svg?branch=main" /&gt;&lt;/a&gt; &lt;a href="https://pypi.org/project/localstack/"&gt;&lt;img alt="PyPI Version" src="https://img.shields.io/pypi/v/localstack?color=blue" /&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/r/localstack/localstack"&gt;&lt;img alt="Docker Pulls" src="https://img.shields.io/docker/pulls/localstack/localstack" /&gt;&lt;/a&gt; &lt;a href="https://pypi.org/project/localstack"&gt;&lt;img alt="PyPi downloads" src="https://static.pepy.tech/badge/localstack" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/localstack/localstack/main/#backers"&gt;&lt;img alt="Backers on Open Collective" src="https://opencollective.com/localstack/backers/badge.svg?sanitize=true" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/localstack/localstack/main/#sponsors"&gt;&lt;img alt="Sponsors on Open Collective" src="https://opencollective.com/localstack/sponsors/badge.svg?sanitize=true" /&gt;&lt;/a&gt; &lt;a href="https://img.shields.io/pypi/l/localstack.svg"&gt;&lt;img alt="PyPI License" src="https://img.shields.io/pypi/l/localstack.svg?sanitize=true" /&gt;&lt;/a&gt; &lt;a href="https://github.com/psf/black"&gt;&lt;img alt="Code style: black" src="https://img.shields.io/badge/code%20style-black-000000.svg?sanitize=true" /&gt;&lt;/a&gt; &lt;a href="https://github.com/astral-sh/ruff"&gt;&lt;img alt="Ruff" src="https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/astral-sh/ruff/main/assets/badge/v2.json" /&gt;&lt;/a&gt; &lt;a href="https://bsky.app/profile/localstack.cloud"&gt;&lt;img alt="Bluesky" src="https://img.shields.io/badge/bluesky-Follow-blue?logo=bluesky" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; LocalStack is a cloud software development framework to develop and test your AWS applications locally. &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://raw.githubusercontent.com/localstack/localstack/main/#overview"&gt;Overview&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/localstack/localstack/main/#install"&gt;Install&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/localstack/localstack/main/#quickstart"&gt;Quickstart&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/localstack/localstack/main/#running"&gt;Run&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/localstack/localstack/main/#usage"&gt;Usage&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/localstack/localstack/main/#releases"&gt;Releases&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/localstack/localstack/main/#contributing"&gt;Contributing&lt;/a&gt; &lt;br /&gt; &lt;a href="https://docs.localstack.cloud" target="_blank"&gt;üìñ Docs&lt;/a&gt; ‚Ä¢ &lt;a href="https://app.localstack.cloud" target="_blank"&gt;üíª Pro version&lt;/a&gt; ‚Ä¢ &lt;a href="https://docs.localstack.cloud/references/coverage/" target="_blank"&gt;‚òëÔ∏è LocalStack coverage&lt;/a&gt; &lt;/p&gt; 
&lt;hr /&gt; 
&lt;h1&gt;Overview&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://localstack.cloud"&gt;LocalStack&lt;/a&gt; is a cloud service emulator that runs in a single container on your laptop or in your CI environment. With LocalStack, you can run your AWS applications or Lambdas entirely on your local machine without connecting to a remote cloud provider! Whether you are testing complex CDK applications or Terraform configurations, or just beginning to learn about AWS services, LocalStack helps speed up and simplify your testing and development workflow.&lt;/p&gt; 
&lt;p&gt;LocalStack supports a growing number of AWS services, like AWS Lambda, S3, DynamoDB, Kinesis, SQS, SNS, and many more! The &lt;a href="https://localstack.cloud/pricing"&gt;Pro version of LocalStack&lt;/a&gt; supports additional APIs and advanced features. You can find a comprehensive list of supported APIs on our &lt;a href="https://docs.localstack.cloud/user-guide/aws/feature-coverage/"&gt;‚òëÔ∏è Feature Coverage&lt;/a&gt; page.&lt;/p&gt; 
&lt;p&gt;LocalStack also provides additional features to make your life as a cloud developer easier! Check out LocalStack's &lt;a href="https://docs.localstack.cloud/user-guide/"&gt;User Guides&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;h2&gt;Install&lt;/h2&gt; 
&lt;p&gt;The quickest way to get started with LocalStack is by using the LocalStack CLI. It enables you to start and manage the LocalStack Docker container directly through your command line. Ensure that your machine has a functional &lt;a href="https://docs.docker.com/get-docker/"&gt;&lt;code&gt;docker&lt;/code&gt; environment&lt;/a&gt; installed before proceeding.&lt;/p&gt; 
&lt;h3&gt;Brew (macOS or Linux with Homebrew)&lt;/h3&gt; 
&lt;p&gt;Install the LocalStack CLI through our &lt;a href="https://github.com/localstack/homebrew-tap"&gt;official LocalStack Brew Tap&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;brew install localstack/tap/localstack-cli
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Binary download (macOS, Linux, Windows)&lt;/h3&gt; 
&lt;p&gt;If Brew is not installed on your machine, you can download the pre-built LocalStack CLI binary directly:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Visit &lt;a href="https://github.com/localstack/localstack-cli/releases/latest"&gt;localstack/localstack-cli&lt;/a&gt; and download the latest release for your platform.&lt;/li&gt; 
 &lt;li&gt;Extract the downloaded archive to a directory included in your &lt;code&gt;PATH&lt;/code&gt; variable: 
  &lt;ul&gt; 
   &lt;li&gt;For macOS/Linux, use the command: &lt;code&gt;sudo tar xvzf ~/Downloads/localstack-cli-*-darwin-*-onefile.tar.gz -C /usr/local/bin&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;PyPI (macOS, Linux, Windows)&lt;/h3&gt; 
&lt;p&gt;LocalStack is developed using Python. To install the LocalStack CLI using &lt;code&gt;pip&lt;/code&gt;, run the following command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python3 -m pip install localstack
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The &lt;code&gt;localstack-cli&lt;/code&gt; installation enables you to run the Docker image containing the LocalStack runtime. To interact with the local AWS services, you need to install the &lt;code&gt;awslocal&lt;/code&gt; CLI separately. For installation guidelines, refer to the &lt;a href="https://docs.localstack.cloud/user-guide/integrations/aws-cli/#localstack-aws-cli-awslocal"&gt;&lt;code&gt;awslocal&lt;/code&gt; documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Important&lt;/strong&gt;: Do not use &lt;code&gt;sudo&lt;/code&gt; or run as &lt;code&gt;root&lt;/code&gt; user. LocalStack must be installed and started entirely under a local non-root user. If you have problems with permissions in macOS High Sierra, install with &lt;code&gt;pip install --user localstack&lt;/code&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Quickstart&lt;/h2&gt; 
&lt;p&gt;Start LocalStack inside a Docker container by running:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt; % localstack start -d

     __                     _______ __             __
    / /   ____  _________ _/ / ___// /_____ ______/ /__
   / /   / __ \/ ___/ __ `/ /\__ \/ __/ __ `/ ___/ //_/
  / /___/ /_/ / /__/ /_/ / /___/ / /_/ /_/ / /__/ ,&amp;lt;
 /_____/\____/\___/\__,_/_//____/\__/\__,_/\___/_/|_|

- LocalStack CLI: 4.9.0
- Profile: default
- App: https://app.localstack.cloud

[17:00:15] starting LocalStack in Docker mode üê≥               localstack.py:512
           preparing environment                               bootstrap.py:1322
           configuring container                               bootstrap.py:1330
           starting container                                  bootstrap.py:1340
[17:00:16] detaching                                           bootstrap.py:1344
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can query the status of respective services on LocalStack by running:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;% localstack status services
‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì
‚îÉ Service                  ‚îÉ Status      ‚îÉ
‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©
‚îÇ acm                      ‚îÇ ‚úî available ‚îÇ
‚îÇ apigateway               ‚îÇ ‚úî available ‚îÇ
‚îÇ cloudformation           ‚îÇ ‚úî available ‚îÇ
‚îÇ cloudwatch               ‚îÇ ‚úî available ‚îÇ
‚îÇ config                   ‚îÇ ‚úî available ‚îÇ
‚îÇ dynamodb                 ‚îÇ ‚úî available ‚îÇ
...
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To use SQS, a fully managed distributed message queuing service, on LocalStack, run:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;% awslocal sqs create-queue --queue-name sample-queue
{
    "QueueUrl": "http://sqs.us-east-1.localhost.localstack.cloud:4566/000000000000/sample-queue"
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Learn more about &lt;a href="https://docs.localstack.cloud/references/coverage/"&gt;LocalStack AWS services&lt;/a&gt; and using them with LocalStack's &lt;code&gt;awslocal&lt;/code&gt; CLI.&lt;/p&gt; 
&lt;h2&gt;Running&lt;/h2&gt; 
&lt;p&gt;You can run LocalStack through the following options:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.localstack.cloud/getting-started/installation/#localstack-cli"&gt;LocalStack CLI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.localstack.cloud/getting-started/installation/#docker"&gt;Docker&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.localstack.cloud/getting-started/installation/#docker-compose"&gt;Docker Compose&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.localstack.cloud/getting-started/installation/#helm"&gt;Helm&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;p&gt;To start using LocalStack, check out our &lt;a href="https://docs.localstack.cloud"&gt;documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.localstack.cloud/references/configuration/"&gt;LocalStack Configuration&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.localstack.cloud/user-guide/ci/"&gt;LocalStack in CI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.localstack.cloud/user-guide/integrations/"&gt;LocalStack Integrations&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.localstack.cloud/user-guide/tools/"&gt;LocalStack Tools&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.localstack.cloud/references/"&gt;Understanding LocalStack&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.localstack.cloud/getting-started/faq/"&gt;Frequently Asked Questions&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;To use LocalStack with a graphical user interface, you can use the following UI clients:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://app.localstack.cloud"&gt;LocalStack Web Application&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.localstack.cloud/user-guide/tools/localstack-desktop/"&gt;LocalStack Desktop&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.localstack.cloud/user-guide/tools/localstack-docker-extension/"&gt;LocalStack Docker Extension&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Releases&lt;/h2&gt; 
&lt;p&gt;Please refer to &lt;a href="https://github.com/localstack/localstack/releases"&gt;GitHub releases&lt;/a&gt; to see the complete list of changes for each release. For extended release notes, please refer to the &lt;a href="https://docs.localstack.cloud/references/changelog/"&gt;changelog&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;If you are interested in contributing to LocalStack:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Start by reading our &lt;a href="https://raw.githubusercontent.com/localstack/localstack/main/docs/CONTRIBUTING.md"&gt;contributing guide&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Check out our &lt;a href="https://raw.githubusercontent.com/localstack/localstack/main/docs/development-environment-setup/README.md"&gt;development environment setup guide&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Navigate our codebase and &lt;a href="https://github.com/localstack/localstack/issues"&gt;open issues&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;We are thankful for all the contributions and feedback we receive.&lt;/p&gt; 
&lt;h2&gt;Get in touch&lt;/h2&gt; 
&lt;p&gt;Get in touch with the LocalStack Team to report üêû &lt;a href="https://github.com/localstack/localstack/issues/new/choose"&gt;issues&lt;/a&gt;, upvote üëç &lt;a href="https://github.com/localstack/localstack/issues?q=is%3Aissue+is%3Aopen+sort%3Areactions-%2B1-desc+"&gt;feature requests&lt;/a&gt;, üôãüèΩ ask &lt;a href="https://docs.localstack.cloud/getting-started/help-and-support/"&gt;support questions&lt;/a&gt;, or üó£Ô∏è discuss local cloud development:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://localstack.cloud/slack/"&gt;LocalStack Slack Community&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/localstack/localstack/issues"&gt;LocalStack GitHub Issue tracker&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Contributors&lt;/h3&gt; 
&lt;p&gt;We are thankful to all the people who have contributed to this project.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/localstack/localstack/graphs/contributors"&gt;&lt;img src="https://opencollective.com/localstack/contributors.svg?width=890" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Backers&lt;/h3&gt; 
&lt;p&gt;We are also grateful to all our backers who have donated to the project. You can become a backer on &lt;a href="https://opencollective.com/localstack#backer"&gt;Open Collective&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://opencollective.com/localstack#backers" target="_blank"&gt;&lt;img src="https://opencollective.com/localstack/backers.svg?width=890" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Sponsors&lt;/h3&gt; 
&lt;p&gt;You can also support this project by becoming a sponsor on &lt;a href="https://opencollective.com/localstack#sponsor"&gt;Open Collective&lt;/a&gt;. Your logo will show up here along with a link to your website.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://opencollective.com/localstack/sponsor/0/website" target="_blank"&gt;&lt;img src="https://opencollective.com/localstack/sponsor/0/avatar.svg?sanitize=true" /&gt;&lt;/a&gt; &lt;a href="https://opencollective.com/localstack/sponsor/1/website" target="_blank"&gt;&lt;img src="https://opencollective.com/localstack/sponsor/1/avatar.svg?sanitize=true" /&gt;&lt;/a&gt; &lt;a href="https://opencollective.com/localstack/sponsor/2/website" target="_blank"&gt;&lt;img src="https://opencollective.com/localstack/sponsor/2/avatar.svg?sanitize=true" /&gt;&lt;/a&gt; &lt;a href="https://opencollective.com/localstack/sponsor/3/website" target="_blank"&gt;&lt;img src="https://opencollective.com/localstack/sponsor/3/avatar.svg?sanitize=true" /&gt;&lt;/a&gt; &lt;a href="https://opencollective.com/localstack/sponsor/4/website" target="_blank"&gt;&lt;img src="https://opencollective.com/localstack/sponsor/4/avatar.svg?sanitize=true" /&gt;&lt;/a&gt; &lt;a href="https://opencollective.com/localstack/sponsor/5/website" target="_blank"&gt;&lt;img src="https://opencollective.com/localstack/sponsor/5/avatar.svg?sanitize=true" /&gt;&lt;/a&gt; &lt;a href="https://opencollective.com/localstack/sponsor/6/website" target="_blank"&gt;&lt;img src="https://opencollective.com/localstack/sponsor/6/avatar.svg?sanitize=true" /&gt;&lt;/a&gt; &lt;a href="https://opencollective.com/localstack/sponsor/7/website" target="_blank"&gt;&lt;img src="https://opencollective.com/localstack/sponsor/7/avatar.svg?sanitize=true" /&gt;&lt;/a&gt; &lt;a href="https://opencollective.com/localstack/sponsor/8/website" target="_blank"&gt;&lt;img src="https://opencollective.com/localstack/sponsor/8/avatar.svg?sanitize=true" /&gt;&lt;/a&gt; &lt;a href="https://opencollective.com/localstack/sponsor/9/website" target="_blank"&gt;&lt;img src="https://opencollective.com/localstack/sponsor/9/avatar.svg?sanitize=true" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Copyright (c) 2017-2025 LocalStack maintainers and contributors.&lt;/p&gt; 
&lt;p&gt;Copyright (c) 2016 Atlassian and others.&lt;/p&gt; 
&lt;p&gt;This version of LocalStack is released under the Apache License, Version 2.0 (see &lt;a href="https://raw.githubusercontent.com/localstack/localstack/main/LICENSE.txt"&gt;LICENSE&lt;/a&gt;). By downloading and using this software you agree to the &lt;a href="https://raw.githubusercontent.com/localstack/localstack/main/docs/end_user_license_agreement"&gt;End-User License Agreement (EULA)&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>topoteretes/cognee</title>
      <link>https://github.com/topoteretes/cognee</link>
      <description>&lt;p&gt;Memory for AI Agents in 6 lines of code&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;a href="https://github.com/topoteretes/cognee"&gt; &lt;img src="https://raw.githubusercontent.com/topoteretes/cognee/refs/heads/dev/assets/cognee-logo-transparent.png" alt="Cognee Logo" height="60" /&gt; &lt;/a&gt; 
 &lt;br /&gt; 
 &lt;p&gt;Cognee - Accurate and Persistent AI Memory&lt;/p&gt; 
 &lt;p align="center"&gt; &lt;a href="https://www.youtube.com/watch?v=1bezuvLwJmw&amp;amp;t=2s"&gt;Demo&lt;/a&gt; . &lt;a href="https://docs.cognee.ai/"&gt;Docs&lt;/a&gt; . &lt;a href="https://cognee.ai"&gt;Learn More&lt;/a&gt; ¬∑ &lt;a href="https://discord.gg/NQPKmU5CCg"&gt;Join Discord&lt;/a&gt; ¬∑ &lt;a href="https://www.reddit.com/r/AIMemory/"&gt;Join r/AIMemory&lt;/a&gt; . &lt;a href="https://github.com/topoteretes/cognee-community"&gt;Community Plugins &amp;amp; Add-ons&lt;/a&gt; &lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://GitHub.com/topoteretes/cognee/network/"&gt;&lt;img src="https://img.shields.io/github/forks/topoteretes/cognee.svg?style=social&amp;amp;label=Fork&amp;amp;maxAge=2592000" alt="GitHub forks" /&gt;&lt;/a&gt; &lt;a href="https://GitHub.com/topoteretes/cognee/stargazers/"&gt;&lt;img src="https://img.shields.io/github/stars/topoteretes/cognee.svg?style=social&amp;amp;label=Star&amp;amp;maxAge=2592000" alt="GitHub stars" /&gt;&lt;/a&gt; &lt;a href="https://GitHub.com/topoteretes/cognee/commit/"&gt;&lt;img src="https://badgen.net/github/commits/topoteretes/cognee" alt="GitHub commits" /&gt;&lt;/a&gt; &lt;a href="https://github.com/topoteretes/cognee/tags/"&gt;&lt;img src="https://badgen.net/github/tag/topoteretes/cognee" alt="GitHub tag" /&gt;&lt;/a&gt; &lt;a href="https://pepy.tech/project/cognee"&gt;&lt;img src="https://static.pepy.tech/badge/cognee" alt="Downloads" /&gt;&lt;/a&gt; &lt;a href="https://github.com/topoteretes/cognee/raw/main/LICENSE"&gt;&lt;img src="https://img.shields.io/github/license/topoteretes/cognee?colorA=00C586&amp;amp;colorB=000000" alt="License" /&gt;&lt;/a&gt; &lt;a href="https://github.com/topoteretes/cognee/graphs/contributors"&gt;&lt;img src="https://img.shields.io/github/contributors/topoteretes/cognee?colorA=00C586&amp;amp;colorB=000000" alt="Contributors" /&gt;&lt;/a&gt; &lt;a href="https://github.com/sponsors/topoteretes"&gt;&lt;img src="https://img.shields.io/badge/Sponsor-‚ù§Ô∏è-ff69b4.svg" alt="Sponsor" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt; &lt;a href="https://www.producthunt.com/posts/cognee?embed=true&amp;amp;utm_source=badge-top-post-badge&amp;amp;utm_medium=badge&amp;amp;utm_souce=badge-cognee" target="_blank" style="display:inline-block; margin-right:10px;"&gt; &lt;img src="https://api.producthunt.com/widgets/embed-image/v1/top-post-badge.svg?post_id=946346&amp;amp;theme=light&amp;amp;period=daily&amp;amp;t=1744472480704" alt="cognee - Memory for AI Agents  in 5 lines of code | Product Hunt" width="250" height="54" /&gt; &lt;/a&gt; &lt;a href="https://trendshift.io/repositories/13955" target="_blank" style="display:inline-block;"&gt; &lt;img src="https://trendshift.io/api/badge/repositories/13955" alt="topoteretes%2Fcognee | Trendshift" width="250" height="55" /&gt; &lt;/a&gt; &lt;/p&gt; 
 &lt;p&gt;Use your data to build personalized and dynamic memory for AI Agents. Cognee lets you replace RAG with scalable and modular ECL (Extract, Cognify, Load) pipelines.&lt;/p&gt; 
 &lt;p align="center"&gt; üåê Available Languages : 
  &lt;!-- Keep these links. Translations will automatically update with the README. --&gt; &lt;a href="https://www.readme-i18n.com/topoteretes/cognee?lang=de"&gt;Deutsch&lt;/a&gt; | &lt;a href="https://www.readme-i18n.com/topoteretes/cognee?lang=es"&gt;Espa√±ol&lt;/a&gt; | &lt;a href="https://www.readme-i18n.com/topoteretes/cognee?lang=fr"&gt;Fran√ßais&lt;/a&gt; | &lt;a href="https://www.readme-i18n.com/topoteretes/cognee?lang=ja"&gt;Êó•Êú¨Ë™û&lt;/a&gt; | &lt;a href="https://www.readme-i18n.com/topoteretes/cognee?lang=ko"&gt;ÌïúÍµ≠Ïñ¥&lt;/a&gt; | &lt;a href="https://www.readme-i18n.com/topoteretes/cognee?lang=pt"&gt;Portugu√™s&lt;/a&gt; | &lt;a href="https://www.readme-i18n.com/topoteretes/cognee?lang=ru"&gt;–†—É—Å—Å–∫–∏–π&lt;/a&gt; | &lt;a href="https://www.readme-i18n.com/topoteretes/cognee?lang=zh"&gt;‰∏≠Êñá&lt;/a&gt; &lt;/p&gt; 
 &lt;div style="text-align: center"&gt; 
  &lt;img src="https://raw.githubusercontent.com/topoteretes/cognee/refs/heads/main/assets/cognee_benefits.png" alt="Why cognee?" width="50%" /&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;h2&gt;About Cognee&lt;/h2&gt; 
&lt;p&gt;Cognee is an open-source tool and platform that transforms your raw data into persistent and dynamic AI memory for Agents. It combines vector search with graph databases to make your documents both searchable by meaning and connected by relationships.&lt;/p&gt; 
&lt;p&gt;You can use Cognee in two ways:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;a href="https://docs.cognee.ai/getting-started/installation"&gt;Self-host Cognee Open Source&lt;/a&gt;, which stores all data locally by default.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://platform.cognee.ai/"&gt;Connect to Cognee Cloud&lt;/a&gt;, and get the same OSS stack on managed infrastructure for easier development and productionization.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Cognee Open Source (self-hosted):&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Interconnects any type of data ‚Äî including past conversations, files, images, and audio transcriptions&lt;/li&gt; 
 &lt;li&gt;Replaces traditional RAG systems with a unified memory layer built on graphs and vectors&lt;/li&gt; 
 &lt;li&gt;Reduces developer effort and infrastructure cost while improving quality and precision&lt;/li&gt; 
 &lt;li&gt;Provides Pythonic data pipelines for ingestion from 30+ data sources&lt;/li&gt; 
 &lt;li&gt;Offers high customizability through user-defined tasks, modular pipelines, and built-in search endpoints&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Cognee Cloud (managed):&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Hosted web UI dashboard&lt;/li&gt; 
 &lt;li&gt;Automatic version updates&lt;/li&gt; 
 &lt;li&gt;Resource usage analytics&lt;/li&gt; 
 &lt;li&gt;GDPR compliant, enterprise-grade security&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Basic Usage &amp;amp; Feature Guide&lt;/h2&gt; 
&lt;p&gt;To learn more, &lt;a href="https://colab.research.google.com/drive/12Vi9zID-M3fpKpKiaqDBvkk98ElkRPWy?usp=sharing"&gt;check out this short, end-to-end Colab walkthrough&lt;/a&gt; of Cognee's core features.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://colab.research.google.com/drive/12Vi9zID-M3fpKpKiaqDBvkk98ElkRPWy?usp=sharing"&gt;&lt;img src="https://colab.research.google.com/assets/colab-badge.svg?sanitize=true" alt="Open In Colab" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Quickstart&lt;/h2&gt; 
&lt;p&gt;Let‚Äôs try Cognee in just a few lines of code. For detailed setup and configuration, see the &lt;a href="https://docs.cognee.ai/getting-started/installation#environment-configuration"&gt;Cognee Docs&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Prerequisites&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Python 3.10 to 3.13&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Step 1: Install Cognee&lt;/h3&gt; 
&lt;p&gt;You can install Cognee with &lt;strong&gt;pip&lt;/strong&gt;, &lt;strong&gt;poetry&lt;/strong&gt;, &lt;strong&gt;uv&lt;/strong&gt;, or your preferred Python package manager.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uv pip install cognee
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Step 2: Configure the LLM&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import os
os.environ["LLM_API_KEY"] = "YOUR OPENAI_API_KEY"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Alternatively, create a &lt;code&gt;.env&lt;/code&gt; file using our &lt;a href="https://github.com/topoteretes/cognee/raw/main/.env.template"&gt;template&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;To integrate other LLM providers, see our &lt;a href="https://docs.cognee.ai/setup-configuration/llm-providers"&gt;LLM Provider Documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Step 3: Run the Pipeline&lt;/h3&gt; 
&lt;p&gt;Cognee will take your documents, generate a knowledge graph from them and then query the graph based on combined relationships.&lt;/p&gt; 
&lt;p&gt;Now, run a minimal pipeline:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import cognee
import asyncio


async def main():
    # Add text to cognee
    await cognee.add("Cognee turns documents into AI memory.")

    # Generate the knowledge graph
    await cognee.cognify()

    # Add memory algorithms to the graph
    await cognee.memify()

    # Query the knowledge graph
    results = await cognee.search("What does Cognee do?")

    # Display the results
    for result in results:
        print(result)


if __name__ == '__main__':
    asyncio.run(main())

&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;As you can see, the output is generated from the document we previously stored in Cognee:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;  Cognee turns documents into AI memory.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Use the Cognee CLI&lt;/h3&gt; 
&lt;p&gt;As an alternative, you can get started with these essential commands:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cognee-cli add "Cognee turns documents into AI memory."

cognee-cli cognify

cognee-cli search "What does Cognee do?"
cognee-cli delete --all

&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To open the local UI, run:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cognee-cli -ui
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Demos &amp;amp; Examples&lt;/h2&gt; 
&lt;p&gt;See Cognee in action:&lt;/p&gt; 
&lt;h3&gt;Persistent Agent Memory&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/e113b628-7212-4a2b-b288-0be39a93a1c3"&gt;Cognee Memory for LangGraph Agents&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Simple GraphRAG&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/f2186b2e-305a-42b0-9c2d-9f4473f15df8"&gt;Watch Demo&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Cognee with Ollama&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/39672858-f774-4136-b957-1e2de67b8981"&gt;Watch Demo&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Community &amp;amp; Support&lt;/h2&gt; 
&lt;h3&gt;Contributing&lt;/h3&gt; 
&lt;p&gt;We welcome contributions from the community! Your input helps make Cognee better for everyone. See &lt;a href="https://raw.githubusercontent.com/topoteretes/cognee/main/CONTRIBUTING.md"&gt;&lt;code&gt;CONTRIBUTING.md&lt;/code&gt;&lt;/a&gt; to get started.&lt;/p&gt; 
&lt;h3&gt;Code of Conduct&lt;/h3&gt; 
&lt;p&gt;We're committed to fostering an inclusive and respectful community. Read our &lt;a href="https://github.com/topoteretes/cognee/raw/main/CODE_OF_CONDUCT.md"&gt;Code of Conduct&lt;/a&gt; for guidelines.&lt;/p&gt; 
&lt;h2&gt;Research &amp;amp; Citation&lt;/h2&gt; 
&lt;p&gt;We recently published a research paper on optimizing knowledge graphs for LLM reasoning:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bibtex"&gt;@misc{markovic2025optimizinginterfaceknowledgegraphs,
      title={Optimizing the Interface Between Knowledge Graphs and LLMs for Complex Reasoning},
      author={Vasilije Markovic and Lazar Obradovic and Laszlo Hajdu and Jovan Pavlovic},
      year={2025},
      eprint={2505.24478},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2505.24478},
}
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>coleam00/ottomator-agents</title>
      <link>https://github.com/coleam00/ottomator-agents</link>
      <description>&lt;p&gt;All the open source AI Agents hosted on the oTTomator Live Agent Studio platform!&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;What is the Live Agent Studio?&lt;/h1&gt; 
&lt;p&gt;The &lt;a href="https://studio.ottomator.ai"&gt;Live Agent Studio&lt;/a&gt; is a community-driven platform developed by &lt;a href="https://ottomator.ai"&gt;oTTomator&lt;/a&gt; for you to explore cutting-edge AI agents and learn how to implement them for yourself or your business! All agents on this platform are open source and, over time, will cover a very large variety of use cases.&lt;/p&gt; 
&lt;p&gt;The goal with the studio is to build an educational platform for you to learn how to do incredible things with AI, while still providing practical value so that you‚Äôll want to use the agents just for the sake of what they can do for you!&lt;/p&gt; 
&lt;p&gt;This platform is still in beta ‚Äì expect longer response times under load, a rapidly growing agent library over the coming months, and a lot more content on this platform soon on Cole Medin‚Äôs YouTube channel!&lt;/p&gt; 
&lt;h1&gt;What is this Repository for?&lt;/h1&gt; 
&lt;p&gt;This repository contains the source code/workflow JSON for all the agents on the Live Agent Studio! Every agent being added to the platform is currently be open sourced here so we can not only create a curated collection of cutting-edge agents together as a community, but also learn from one another!&lt;/p&gt; 
&lt;h2&gt;Tokens&lt;/h2&gt; 
&lt;p&gt;Most agents on the Live Agent Studio cost tokens to use, which are purchasable on the platform. However, when you first sign in you are given some tokens to start so you can use the agents free of charge! The biggest reason agents cost tokens is that we pay for the LLM usage since we host all the agents developed by you and the rest of the community!&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://studio.ottomator.ai/pricing"&gt;Purchase Tokens&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Future Plans&lt;/h2&gt; 
&lt;p&gt;As the Live Agent Studio develops, it will become the go-to place to stay on top of what is possible with AI agents! Anytime there is a new AI technology, groundbreaking agent research, or a new tool/library to build agents with, it‚Äôll be featured through agents on the platform. It‚Äôs a tall order, but we have big plans for the oTTomator community, and we‚Äôre confident we can grow to accomplish this!&lt;/p&gt; 
&lt;h2&gt;FAQ&lt;/h2&gt; 
&lt;h3&gt;I want to build an agent to showcase in the Live Agent Studio! How do I do that?&lt;/h3&gt; 
&lt;p&gt;Head on over here to learn how to build an agent for the platform:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://studio.ottomator.ai/guide"&gt;Developer Guide&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Also check out &lt;a href="https://raw.githubusercontent.com/coleam00/ottomator-agents/main/~sample-n8n-agent~"&gt;the sample n8n agent&lt;/a&gt; for a starting point of building an n8n agent for the Live Agent Studio, and &lt;a href="https://raw.githubusercontent.com/coleam00/ottomator-agents/main/~sample-python-agent~"&gt;the sample Python agent&lt;/a&gt; for Python.&lt;/p&gt; 
&lt;h3&gt;How many tokens does it cost to use an agent?&lt;/h3&gt; 
&lt;p&gt;Each agent will charge tokens per prompt. The number of tokens depends on the agent, as some agents use larger LLMs, some call LLMs multiple times, and some use paid APIs.&lt;/p&gt; 
&lt;h3&gt;Where can I go to talk about all these agents and get help implementing them myself?&lt;/h3&gt; 
&lt;p&gt;Head on over to our Think Tank community and feel free to make a post!&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://thinktank.ottomator.ai"&gt;Think Tank Community&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;¬© 2024 Live Agent Studio. All rights reserved.&lt;br /&gt; Created by oTTomator&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>NanmiCoder/MediaCrawler</title>
      <link>https://github.com/NanmiCoder/MediaCrawler</link>
      <description>&lt;p&gt;Â∞èÁ∫¢‰π¶Á¨îËÆ∞ | ËØÑËÆ∫Áà¨Ëô´„ÄÅÊäñÈü≥ËßÜÈ¢ë | ËØÑËÆ∫Áà¨Ëô´„ÄÅÂø´ÊâãËßÜÈ¢ë | ËØÑËÆ∫Áà¨Ëô´„ÄÅB Á´ôËßÜÈ¢ë ÔΩú ËØÑËÆ∫Áà¨Ëô´„ÄÅÂæÆÂçöÂ∏ñÂ≠ê ÔΩú ËØÑËÆ∫Áà¨Ëô´„ÄÅÁôæÂ∫¶Ë¥¥ÂêßÂ∏ñÂ≠ê ÔΩú ÁôæÂ∫¶Ë¥¥ÂêßËØÑËÆ∫ÂõûÂ§çÁà¨Ëô´ | Áü•‰πéÈóÆÁ≠îÊñáÁ´†ÔΩúËØÑËÆ∫Áà¨Ëô´&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;üî• MediaCrawler - Ëá™Â™í‰ΩìÂπ≥Âè∞Áà¨Ëô´ üï∑Ô∏è&lt;/h1&gt; 
&lt;div align="center" markdown="1"&gt; 
 &lt;sup&gt;Special thanks to:&lt;/sup&gt; 
 &lt;br /&gt; 
 &lt;br /&gt; 
 &lt;a href="https://go.warp.dev/MediaCrawler"&gt; &lt;img alt="Warp sponsorship" width="400" src="https://github.com/warpdotdev/brand-assets/raw/main/Github/Sponsor/Warp-Github-LG-02.png?raw=true" /&gt; &lt;/a&gt; 
 &lt;h3&gt;&lt;a href="https://go.warp.dev/MediaCrawler"&gt;Warp is built for coding with multiple AI agents&lt;/a&gt;&lt;/h3&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://trendshift.io/repositories/8291" target="_blank"&gt; &lt;img src="https://trendshift.io/api/badge/repositories/8291" alt="NanmiCoder%2FMediaCrawler | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt; &lt;/a&gt; 
 &lt;p&gt;&lt;a href="https://github.com/NanmiCoder/MediaCrawler/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/NanmiCoder/MediaCrawler?style=social" alt="GitHub Stars" /&gt;&lt;/a&gt; &lt;a href="https://github.com/NanmiCoder/MediaCrawler/network/members"&gt;&lt;img src="https://img.shields.io/github/forks/NanmiCoder/MediaCrawler?style=social" alt="GitHub Forks" /&gt;&lt;/a&gt; &lt;a href="https://github.com/NanmiCoder/MediaCrawler/issues"&gt;&lt;img src="https://img.shields.io/github/issues/NanmiCoder/MediaCrawler" alt="GitHub Issues" /&gt;&lt;/a&gt; &lt;a href="https://github.com/NanmiCoder/MediaCrawler/pulls"&gt;&lt;img src="https://img.shields.io/github/issues-pr/NanmiCoder/MediaCrawler" alt="GitHub Pull Requests" /&gt;&lt;/a&gt; &lt;a href="https://github.com/NanmiCoder/MediaCrawler/raw/main/LICENSE"&gt;&lt;img src="https://img.shields.io/github/license/NanmiCoder/MediaCrawler" alt="License" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/NanmiCoder/MediaCrawler/main/README.md"&gt;&lt;img src="https://img.shields.io/badge/%F0%9F%87%A8%F0%9F%87%B3_%E4%B8%AD%E6%96%87-%E5%BD%93%E5%89%8D-blue" alt="‰∏≠Êñá" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/NanmiCoder/MediaCrawler/main/README_en.md"&gt;&lt;img src="https://img.shields.io/badge/%F0%9F%87%BA%F0%9F%87%B8_English-Available-green" alt="English" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/NanmiCoder/MediaCrawler/main/README_es.md"&gt;&lt;img src="https://img.shields.io/badge/%F0%9F%87%AA%F0%9F%87%B8_Espa%C3%B1ol-Available-green" alt="Espa√±ol" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;ÂÖçË¥£Â£∞ÊòéÔºö&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;Â§ßÂÆ∂ËØ∑‰ª•Â≠¶‰π†‰∏∫ÁõÆÁöÑ‰ΩøÁî®Êú¨‰ªìÂ∫ì‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏èÔºå&lt;a href="https://github.com/HiddenStrawberry/Crawler_Illegal_Cases_In_China"&gt;Áà¨Ëô´ËøùÊ≥ïËøùËßÑÁöÑÊ°à‰ª∂&lt;/a&gt; &lt;br /&gt;&lt;/p&gt; 
 &lt;p&gt;Êú¨‰ªìÂ∫ìÁöÑÊâÄÊúâÂÜÖÂÆπ‰ªÖ‰æõÂ≠¶‰π†ÂíåÂèÇËÄÉ‰πãÁî®ÔºåÁ¶ÅÊ≠¢Áî®‰∫éÂïÜ‰∏öÁî®ÈÄî„ÄÇ‰ªª‰Ωï‰∫∫ÊàñÁªÑÁªá‰∏çÂæóÂ∞ÜÊú¨‰ªìÂ∫ìÁöÑÂÜÖÂÆπÁî®‰∫éÈùûÊ≥ïÁî®ÈÄîÊàñ‰æµÁäØ‰ªñ‰∫∫ÂêàÊ≥ïÊùÉÁõä„ÄÇÊú¨‰ªìÂ∫ìÊâÄÊ∂âÂèäÁöÑÁà¨Ëô´ÊäÄÊúØ‰ªÖÁî®‰∫éÂ≠¶‰π†ÂíåÁ†îÁ©∂Ôºå‰∏çÂæóÁî®‰∫éÂØπÂÖ∂‰ªñÂπ≥Âè∞ËøõË°åÂ§ßËßÑÊ®°Áà¨Ëô´ÊàñÂÖ∂‰ªñÈùûÊ≥ïË°å‰∏∫„ÄÇÂØπ‰∫éÂõ†‰ΩøÁî®Êú¨‰ªìÂ∫ìÂÜÖÂÆπËÄåÂºïËµ∑ÁöÑ‰ªª‰ΩïÊ≥ïÂæãË¥£‰ªªÔºåÊú¨‰ªìÂ∫ì‰∏çÊâøÊãÖ‰ªª‰ΩïË¥£‰ªª„ÄÇ‰ΩøÁî®Êú¨‰ªìÂ∫ìÁöÑÂÜÖÂÆπÂç≥Ë°®Á§∫ÊÇ®ÂêåÊÑèÊú¨ÂÖçË¥£Â£∞ÊòéÁöÑÊâÄÊúâÊù°Ê¨æÂíåÊù°‰ª∂„ÄÇ&lt;/p&gt; 
 &lt;p&gt;ÁÇπÂáªÊü•ÁúãÊõ¥‰∏∫ËØ¶ÁªÜÁöÑÂÖçË¥£Â£∞Êòé„ÄÇ&lt;a href="https://raw.githubusercontent.com/NanmiCoder/MediaCrawler/main/#disclaimer"&gt;ÁÇπÂáªË∑≥ËΩ¨&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;üìñ È°πÁõÆÁÆÄ‰ªã&lt;/h2&gt; 
&lt;p&gt;‰∏Ä‰∏™ÂäüËÉΩÂº∫Â§ßÁöÑ&lt;strong&gt;Â§öÂπ≥Âè∞Ëá™Â™í‰ΩìÊï∞ÊçÆÈááÈõÜÂ∑•ÂÖ∑&lt;/strong&gt;ÔºåÊîØÊåÅÂ∞èÁ∫¢‰π¶„ÄÅÊäñÈü≥„ÄÅÂø´Êâã„ÄÅBÁ´ô„ÄÅÂæÆÂçö„ÄÅË¥¥Âêß„ÄÅÁü•‰πéÁ≠â‰∏ªÊµÅÂπ≥Âè∞ÁöÑÂÖ¨ÂºÄ‰ø°ÊÅØÊäìÂèñ„ÄÇ&lt;/p&gt; 
&lt;h3&gt;üîß ÊäÄÊúØÂéüÁêÜ&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Ê†∏ÂøÉÊäÄÊúØ&lt;/strong&gt;ÔºöÂü∫‰∫é &lt;a href="https://playwright.dev/"&gt;Playwright&lt;/a&gt; ÊµèËßàÂô®Ëá™Âä®ÂåñÊ°ÜÊû∂ÁôªÂΩï‰øùÂ≠òÁôªÂΩïÊÄÅ&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Êó†ÈúÄJSÈÄÜÂêë&lt;/strong&gt;ÔºöÂà©Áî®‰øùÁïôÁôªÂΩïÊÄÅÁöÑÊµèËßàÂô®‰∏ä‰∏ãÊñáÁéØÂ¢ÉÔºåÈÄöËøá JS Ë°®ËææÂºèËé∑ÂèñÁ≠æÂêçÂèÇÊï∞&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;‰ºòÂäøÁâπÁÇπ&lt;/strong&gt;ÔºöÊó†ÈúÄÈÄÜÂêëÂ§çÊùÇÁöÑÂä†ÂØÜÁÆóÊ≥ïÔºåÂ§ßÂπÖÈôç‰ΩéÊäÄÊúØÈó®Êßõ&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;‚ú® ÂäüËÉΩÁâπÊÄß&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Âπ≥Âè∞&lt;/th&gt; 
   &lt;th&gt;ÂÖ≥ÈîÆËØçÊêúÁ¥¢&lt;/th&gt; 
   &lt;th&gt;ÊåáÂÆöÂ∏ñÂ≠êIDÁà¨Âèñ&lt;/th&gt; 
   &lt;th&gt;‰∫åÁ∫ßËØÑËÆ∫&lt;/th&gt; 
   &lt;th&gt;ÊåáÂÆöÂàõ‰ΩúËÄÖ‰∏ªÈ°µ&lt;/th&gt; 
   &lt;th&gt;ÁôªÂΩïÊÄÅÁºìÂ≠ò&lt;/th&gt; 
   &lt;th&gt;IP‰ª£ÁêÜÊ±†&lt;/th&gt; 
   &lt;th&gt;ÁîüÊàêËØÑËÆ∫ËØç‰∫ëÂõæ&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Â∞èÁ∫¢‰π¶&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ÊäñÈü≥&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Âø´Êâã&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;B Á´ô&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ÂæÆÂçö&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Ë¥¥Âêß&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Áü•‰πé&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;üöÄ MediaCrawlerPro ÈáçÁ£ÖÂèëÂ∏ÉÔºÅ&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;‰∏ìÊ≥®‰∫éÂ≠¶‰π†ÊàêÁÜüÈ°πÁõÆÁöÑÊû∂ÊûÑËÆæËÆ°Ôºå‰∏ç‰ªÖ‰ªÖÊòØÁà¨Ëô´ÊäÄÊúØÔºåPro ÁâàÊú¨ÁöÑ‰ª£Á†ÅËÆæËÆ°ÊÄùË∑ØÂêåÊ†∑ÂÄºÂæóÊ∑±ÂÖ•Â≠¶‰π†ÔºÅ&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;a href="https://github.com/MediaCrawlerPro"&gt;MediaCrawlerPro&lt;/a&gt; Áõ∏ËæÉ‰∫éÂºÄÊ∫êÁâàÊú¨ÁöÑÊ†∏ÂøÉ‰ºòÂäøÔºö&lt;/p&gt; 
&lt;h4&gt;üéØ Ê†∏ÂøÉÂäüËÉΩÂçáÁ∫ß&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;‚úÖ &lt;strong&gt;Êñ≠ÁÇπÁª≠Áà¨ÂäüËÉΩ&lt;/strong&gt;ÔºàÈáçÁÇπÁâπÊÄßÔºâ&lt;/li&gt; 
 &lt;li&gt;‚úÖ &lt;strong&gt;Â§öË¥¶Âè∑ + IP‰ª£ÁêÜÊ±†ÊîØÊåÅ&lt;/strong&gt;ÔºàÈáçÁÇπÁâπÊÄßÔºâ&lt;/li&gt; 
 &lt;li&gt;‚úÖ &lt;strong&gt;ÂéªÈô§ Playwright ‰æùËµñ&lt;/strong&gt;Ôºå‰ΩøÁî®Êõ¥ÁÆÄÂçï&lt;/li&gt; 
 &lt;li&gt;‚úÖ &lt;strong&gt;ÂÆåÊï¥ Linux ÁéØÂ¢ÉÊîØÊåÅ&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;üèóÔ∏è Êû∂ÊûÑËÆæËÆ°‰ºòÂåñ&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;‚úÖ &lt;strong&gt;‰ª£Á†ÅÈáçÊûÑ‰ºòÂåñ&lt;/strong&gt;ÔºåÊõ¥ÊòìËØªÊòìÁª¥Êä§ÔºàËß£ËÄ¶ JS Á≠æÂêçÈÄªËæëÔºâ&lt;/li&gt; 
 &lt;li&gt;‚úÖ &lt;strong&gt;‰ºÅ‰∏öÁ∫ß‰ª£Á†ÅË¥®Èáè&lt;/strong&gt;ÔºåÈÄÇÂêàÊûÑÂª∫Â§ßÂûãÁà¨Ëô´È°πÁõÆ&lt;/li&gt; 
 &lt;li&gt;‚úÖ &lt;strong&gt;ÂÆåÁæéÊû∂ÊûÑËÆæËÆ°&lt;/strong&gt;ÔºåÈ´òÊâ©Â±ïÊÄßÔºåÊ∫êÁ†ÅÂ≠¶‰π†‰ª∑ÂÄºÊõ¥Â§ß&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;üéÅ È¢ùÂ§ñÂäüËÉΩ&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;‚úÖ &lt;strong&gt;Ëá™Â™í‰ΩìËßÜÈ¢ë‰∏ãËΩΩÂô®Ê°åÈù¢Á´Ø&lt;/strong&gt;ÔºàÈÄÇÂêàÂ≠¶‰π†ÂÖ®Ê†àÂºÄÂèëÔºâ&lt;/li&gt; 
 &lt;li&gt;‚úÖ &lt;strong&gt;Â§öÂπ≥Âè∞È¶ñÈ°µ‰ø°ÊÅØÊµÅÊé®Ëçê&lt;/strong&gt;ÔºàHomeFeedÔºâ&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;strong&gt;Âü∫‰∫éËá™Â™í‰ΩìÂπ≥Âè∞ÁöÑAI AgentÊ≠£Âú®ÂºÄÂèë‰∏≠ üöÄüöÄ&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;ÁÇπÂáªÊü•ÁúãÔºö&lt;a href="https://github.com/MediaCrawlerPro"&gt;MediaCrawlerPro È°πÁõÆ‰∏ªÈ°µ&lt;/a&gt; Êõ¥Â§ö‰ªãÁªç&lt;/p&gt; 
&lt;h2&gt;üöÄ Âø´ÈÄüÂºÄÂßã&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;üí° &lt;strong&gt;ÂºÄÊ∫ê‰∏çÊòìÔºåÂ¶ÇÊûúËøô‰∏™È°πÁõÆÂØπÊÇ®ÊúâÂ∏ÆÂä©ÔºåËØ∑Áªô‰∏™ ‚≠ê Star ÊîØÊåÅ‰∏Ä‰∏ãÔºÅ&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;üìã ÂâçÁΩÆ‰æùËµñ&lt;/h2&gt; 
&lt;h3&gt;üöÄ uv ÂÆâË£ÖÔºàÊé®ËçêÔºâ&lt;/h3&gt; 
&lt;p&gt;Âú®ËøõË°å‰∏ã‰∏ÄÊ≠•Êìç‰Ωú‰πãÂâçÔºåËØ∑Á°Æ‰øùÁîµËÑë‰∏äÂ∑≤ÁªèÂÆâË£Ö‰∫Ü uvÔºö&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;ÂÆâË£ÖÂú∞ÂùÄ&lt;/strong&gt;Ôºö&lt;a href="https://docs.astral.sh/uv/getting-started/installation"&gt;uv ÂÆòÊñπÂÆâË£ÖÊåáÂçó&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;È™åËØÅÂÆâË£Ö&lt;/strong&gt;ÔºöÁªàÁ´ØËæìÂÖ•ÂëΩ‰ª§ &lt;code&gt;uv --version&lt;/code&gt;ÔºåÂ¶ÇÊûúÊ≠£Â∏∏ÊòæÁ§∫ÁâàÊú¨Âè∑ÔºåËØÅÊòéÂ∑≤ÁªèÂÆâË£ÖÊàêÂäü&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Êé®ËçêÁêÜÁî±&lt;/strong&gt;Ôºöuv ÊòØÁõÆÂâçÊúÄÂº∫ÁöÑ Python ÂåÖÁÆ°ÁêÜÂ∑•ÂÖ∑ÔºåÈÄüÂ∫¶Âø´„ÄÅ‰æùËµñËß£ÊûêÂáÜÁ°Æ&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üü¢ Node.js ÂÆâË£Ö&lt;/h3&gt; 
&lt;p&gt;È°πÁõÆ‰æùËµñ Node.jsÔºåËØ∑ÂâçÂæÄÂÆòÁΩë‰∏ãËΩΩÂÆâË£ÖÔºö&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;‰∏ãËΩΩÂú∞ÂùÄ&lt;/strong&gt;Ôºö&lt;a href="https://nodejs.org/en/download/"&gt;https://nodejs.org/en/download/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ÁâàÊú¨Ë¶ÅÊ±Ç&lt;/strong&gt;Ôºö&amp;gt;= 16.0.0&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üì¶ Python ÂåÖÂÆâË£Ö&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;# ËøõÂÖ•È°πÁõÆÁõÆÂΩï
cd MediaCrawler

# ‰ΩøÁî® uv sync ÂëΩ‰ª§Êù•‰øùËØÅ python ÁâàÊú¨ÂíåÁõ∏ÂÖ≥‰æùËµñÂåÖÁöÑ‰∏ÄËá¥ÊÄß
uv sync
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;üåê ÊµèËßàÂô®È©±Âä®ÂÆâË£Ö&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;# ÂÆâË£ÖÊµèËßàÂô®È©±Âä®
uv run playwright install
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;üí° ÊèêÁ§∫&lt;/strong&gt;ÔºöMediaCrawler ÁõÆÂâçÂ∑≤ÁªèÊîØÊåÅ‰ΩøÁî® playwright ËøûÊé•‰Ω†Êú¨Âú∞ÁöÑ Chrome ÊµèËßàÂô®‰∫ÜÔºå‰∏Ä‰∫õÂõ†‰∏∫ Webdriver ÂØºËá¥ÁöÑÈóÆÈ¢òËøéÂàÉËÄåËß£‰∫Ü„ÄÇ&lt;/p&gt; 
 &lt;p&gt;ÁõÆÂâçÂºÄÊîæ‰∫Ü &lt;code&gt;xhs&lt;/code&gt; Âíå &lt;code&gt;dy&lt;/code&gt; Ëøô‰∏§‰∏™‰ΩøÁî® CDP ÁöÑÊñπÂºèËøûÊé•Êú¨Âú∞ÊµèËßàÂô®ÔºåÂ¶ÇÊúâÈúÄË¶ÅÔºåÊü•Áúã &lt;code&gt;config/base_config.py&lt;/code&gt; ‰∏≠ÁöÑÈÖçÁΩÆÈ°π„ÄÇ&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;üöÄ ËøêË°åÁà¨Ëô´Á®ãÂ∫è&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;# È°πÁõÆÈªòËÆ§ÊòØÊ≤°ÊúâÂºÄÂêØËØÑËÆ∫Áà¨ÂèñÊ®°ÂºèÔºåÂ¶ÇÈúÄËØÑËÆ∫ËØ∑Âú® config/base_config.py ‰∏≠ÁöÑ ENABLE_GET_COMMENTS ÂèòÈáè‰øÆÊîπ
# ‰∏Ä‰∫õÂÖ∂‰ªñÊîØÊåÅÈ°πÔºå‰πüÂèØ‰ª•Âú® config/base_config.py Êü•ÁúãÂäüËÉΩÔºåÂÜôÁöÑÊúâ‰∏≠ÊñáÊ≥®Èáä

# ‰ªéÈÖçÁΩÆÊñá‰ª∂‰∏≠ËØªÂèñÂÖ≥ÈîÆËØçÊêúÁ¥¢Áõ∏ÂÖ≥ÁöÑÂ∏ñÂ≠êÂπ∂Áà¨ÂèñÂ∏ñÂ≠ê‰ø°ÊÅØ‰∏éËØÑËÆ∫
uv run main.py --platform xhs --lt qrcode --type search

# ‰ªéÈÖçÁΩÆÊñá‰ª∂‰∏≠ËØªÂèñÊåáÂÆöÁöÑÂ∏ñÂ≠êIDÂàóË°®Ëé∑ÂèñÊåáÂÆöÂ∏ñÂ≠êÁöÑ‰ø°ÊÅØ‰∏éËØÑËÆ∫‰ø°ÊÅØ
uv run main.py --platform xhs --lt qrcode --type detail

# ÊâìÂºÄÂØπÂ∫îAPPÊâ´‰∫åÁª¥Á†ÅÁôªÂΩï

# ÂÖ∂‰ªñÂπ≥Âè∞Áà¨Ëô´‰ΩøÁî®Á§∫‰æãÔºåÊâßË°å‰∏ãÈù¢ÁöÑÂëΩ‰ª§Êü•Áúã
uv run main.py --help
&lt;/code&gt;&lt;/pre&gt; 
&lt;details&gt; 
 &lt;summary&gt;üîó &lt;strong&gt;‰ΩøÁî® Python ÂéüÁîü venv ÁÆ°ÁêÜÁéØÂ¢ÉÔºà‰∏çÊé®ËçêÔºâ&lt;/strong&gt;&lt;/summary&gt; 
 &lt;h4&gt;ÂàõÂª∫Âπ∂ÊøÄÊ¥ª Python ËôöÊãüÁéØÂ¢É&lt;/h4&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;Â¶ÇÊûúÊòØÁà¨ÂèñÊäñÈü≥ÂíåÁü•‰πéÔºåÈúÄË¶ÅÊèêÂâçÂÆâË£Ö nodejs ÁéØÂ¢ÉÔºåÁâàÊú¨Â§ß‰∫éÁ≠â‰∫éÔºö&lt;code&gt;16&lt;/code&gt; Âç≥ÂèØ&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;# ËøõÂÖ•È°πÁõÆÊ†πÁõÆÂΩï
cd MediaCrawler

# ÂàõÂª∫ËôöÊãüÁéØÂ¢É
# ÊàëÁöÑ python ÁâàÊú¨ÊòØÔºö3.9.6Ôºårequirements.txt ‰∏≠ÁöÑÂ∫ìÊòØÂü∫‰∫éËøô‰∏™ÁâàÊú¨ÁöÑ
# Â¶ÇÊûúÊòØÂÖ∂‰ªñ python ÁâàÊú¨ÔºåÂèØËÉΩ requirements.txt ‰∏≠ÁöÑÂ∫ì‰∏çÂÖºÂÆπÔºåÈúÄËá™Ë°åËß£ÂÜ≥
python -m venv venv

# macOS &amp;amp; Linux ÊøÄÊ¥ªËôöÊãüÁéØÂ¢É
source venv/bin/activate

# Windows ÊøÄÊ¥ªËôöÊãüÁéØÂ¢É
venv\Scripts\activate
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h4&gt;ÂÆâË£Ö‰æùËµñÂ∫ì&lt;/h4&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;pip install -r requirements.txt
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h4&gt;ÂÆâË£Ö playwright ÊµèËßàÂô®È©±Âä®&lt;/h4&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;playwright install
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h4&gt;ËøêË°åÁà¨Ëô´Á®ãÂ∫èÔºàÂéüÁîüÁéØÂ¢ÉÔºâ&lt;/h4&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;# È°πÁõÆÈªòËÆ§ÊòØÊ≤°ÊúâÂºÄÂêØËØÑËÆ∫Áà¨ÂèñÊ®°ÂºèÔºåÂ¶ÇÈúÄËØÑËÆ∫ËØ∑Âú® config/base_config.py ‰∏≠ÁöÑ ENABLE_GET_COMMENTS ÂèòÈáè‰øÆÊîπ
# ‰∏Ä‰∫õÂÖ∂‰ªñÊîØÊåÅÈ°πÔºå‰πüÂèØ‰ª•Âú® config/base_config.py Êü•ÁúãÂäüËÉΩÔºåÂÜôÁöÑÊúâ‰∏≠ÊñáÊ≥®Èáä

# ‰ªéÈÖçÁΩÆÊñá‰ª∂‰∏≠ËØªÂèñÂÖ≥ÈîÆËØçÊêúÁ¥¢Áõ∏ÂÖ≥ÁöÑÂ∏ñÂ≠êÂπ∂Áà¨ÂèñÂ∏ñÂ≠ê‰ø°ÊÅØ‰∏éËØÑËÆ∫
python main.py --platform xhs --lt qrcode --type search

# ‰ªéÈÖçÁΩÆÊñá‰ª∂‰∏≠ËØªÂèñÊåáÂÆöÁöÑÂ∏ñÂ≠êIDÂàóË°®Ëé∑ÂèñÊåáÂÆöÂ∏ñÂ≠êÁöÑ‰ø°ÊÅØ‰∏éËØÑËÆ∫‰ø°ÊÅØ
python main.py --platform xhs --lt qrcode --type detail

# ÊâìÂºÄÂØπÂ∫îAPPÊâ´‰∫åÁª¥Á†ÅÁôªÂΩï

# ÂÖ∂‰ªñÂπ≥Âè∞Áà¨Ëô´‰ΩøÁî®Á§∫‰æãÔºåÊâßË°å‰∏ãÈù¢ÁöÑÂëΩ‰ª§Êü•Áúã
python main.py --help
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h2&gt;üíæ Êï∞ÊçÆ‰øùÂ≠ò&lt;/h2&gt; 
&lt;p&gt;ÊîØÊåÅÂ§öÁßçÊï∞ÊçÆÂ≠òÂÇ®ÊñπÂºèÔºö&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;CSV Êñá‰ª∂&lt;/strong&gt;ÔºöÊîØÊåÅ‰øùÂ≠òÂà∞ CSV ‰∏≠Ôºà&lt;code&gt;data/&lt;/code&gt; ÁõÆÂΩï‰∏ãÔºâ&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;JSON Êñá‰ª∂&lt;/strong&gt;ÔºöÊîØÊåÅ‰øùÂ≠òÂà∞ JSON ‰∏≠Ôºà&lt;code&gt;data/&lt;/code&gt; ÁõÆÂΩï‰∏ãÔºâ&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Êï∞ÊçÆÂ∫ìÂ≠òÂÇ®&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;‰ΩøÁî®ÂèÇÊï∞ &lt;code&gt;--init_db&lt;/code&gt; ËøõË°åÊï∞ÊçÆÂ∫ìÂàùÂßãÂåñÔºà‰ΩøÁî®&lt;code&gt;--init_db&lt;/code&gt;Êó∂‰∏çÈúÄË¶ÅÊê∫Â∏¶ÂÖ∂‰ªñoptionalÔºâ&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;SQLite Êï∞ÊçÆÂ∫ì&lt;/strong&gt;ÔºöËΩªÈáèÁ∫ßÊï∞ÊçÆÂ∫ìÔºåÊó†ÈúÄÊúçÂä°Âô®ÔºåÈÄÇÂêà‰∏™‰∫∫‰ΩøÁî®ÔºàÊé®ËçêÔºâ 
    &lt;ol&gt; 
     &lt;li&gt;ÂàùÂßãÂåñÔºö&lt;code&gt;--init_db sqlite&lt;/code&gt;&lt;/li&gt; 
     &lt;li&gt;Êï∞ÊçÆÂ≠òÂÇ®Ôºö&lt;code&gt;--save_data_option sqlite&lt;/code&gt;&lt;/li&gt; 
    &lt;/ol&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;MySQL Êï∞ÊçÆÂ∫ì&lt;/strong&gt;ÔºöÊîØÊåÅÂÖ≥Á≥ªÂûãÊï∞ÊçÆÂ∫ì MySQL ‰∏≠‰øùÂ≠òÔºàÈúÄË¶ÅÊèêÂâçÂàõÂª∫Êï∞ÊçÆÂ∫ìÔºâ 
    &lt;ol&gt; 
     &lt;li&gt;ÂàùÂßãÂåñÔºö&lt;code&gt;--init_db mysql&lt;/code&gt;&lt;/li&gt; 
     &lt;li&gt;Êï∞ÊçÆÂ≠òÂÇ®Ôºö&lt;code&gt;--save_data_option db&lt;/code&gt;Ôºàdb ÂèÇÊï∞‰∏∫ÂÖºÂÆπÂéÜÂè≤Êõ¥Êñ∞‰øùÁïôÔºâ&lt;/li&gt; 
    &lt;/ol&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;‰ΩøÁî®Á§∫‰æãÔºö&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;# ÂàùÂßãÂåñ SQLite Êï∞ÊçÆÂ∫ìÔºà‰ΩøÁî®'--init_db'Êó∂‰∏çÈúÄË¶ÅÊê∫Â∏¶ÂÖ∂‰ªñoptionalÔºâ
uv run main.py --init_db sqlite
# ‰ΩøÁî® SQLite Â≠òÂÇ®Êï∞ÊçÆÔºàÊé®Ëçê‰∏™‰∫∫Áî®Êà∑‰ΩøÁî®Ôºâ
uv run main.py --platform xhs --lt qrcode --type search --save_data_option sqlite
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;# ÂàùÂßãÂåñ MySQL Êï∞ÊçÆÂ∫ì
uv run main.py --init_db mysql
# ‰ΩøÁî® MySQL Â≠òÂÇ®Êï∞ÊçÆÔºà‰∏∫ÈÄÇÈÖçÂéÜÂè≤Êõ¥Êñ∞ÔºådbÂèÇÊï∞ËøõË°åÊ≤øÁî®Ôºâ
uv run main.py --platform xhs --lt qrcode --type search --save_data_option db
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;a href="https://github.com/MediaCrawlerPro"&gt;üöÄ MediaCrawlerPro ÈáçÁ£ÖÂèëÂ∏É üöÄÔºÅÊõ¥Â§öÁöÑÂäüËÉΩÔºåÊõ¥Â•ΩÁöÑÊû∂ÊûÑËÆæËÆ°ÔºÅ&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;üí¨ ‰∫§ÊµÅÁæ§ÁªÑ&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;ÂæÆ‰ø°‰∫§ÊµÅÁæ§&lt;/strong&gt;Ôºö&lt;a href="https://nanmicoder.github.io/MediaCrawler/%E5%BE%AE%E4%BF%A1%E4%BA%A4%E6%B5%81%E7%BE%A4.html"&gt;ÁÇπÂáªÂä†ÂÖ•&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üìö ÂÖ∂‰ªñ&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Â∏∏ËßÅÈóÆÈ¢ò&lt;/strong&gt;Ôºö&lt;a href="https://nanmicoder.github.io/MediaCrawler/"&gt;MediaCrawler ÂÆåÊï¥ÊñáÊ°£&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Áà¨Ëô´ÂÖ•Èó®ÊïôÁ®ã&lt;/strong&gt;Ôºö&lt;a href="https://github.com/NanmiCoder/CrawlerTutorial"&gt;CrawlerTutorial ÂÖçË¥πÊïôÁ®ã&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Êñ∞ÈóªÁà¨Ëô´ÂºÄÊ∫êÈ°πÁõÆ&lt;/strong&gt;Ôºö&lt;a href="https://github.com/NanmiCoder/NewsCrawlerCollection"&gt;NewsCrawlerCollection&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h3&gt;üí∞ ËµûÂä©ÂïÜÂ±ïÁ§∫&lt;/h3&gt; 
&lt;a href="https://h.wandouip.com"&gt; &lt;img src="https://raw.githubusercontent.com/NanmiCoder/MediaCrawler/main/docs/static/images/img_8.jpg" /&gt; &lt;br /&gt; Ë±åË±ÜHTTPËá™Ëê•ÂçÉ‰∏áÁ∫ßIPËµÑÊ∫êÊ±†ÔºåIPÁ∫ØÂáÄÂ∫¶‚â•99.8%ÔºåÊØèÊó•‰øùÊåÅIPÈ´òÈ¢ëÊõ¥Êñ∞ÔºåÂø´ÈÄüÂìçÂ∫îÔºåÁ®≥ÂÆöËøûÊé•,Êª°Ë∂≥Â§öÁßç‰∏öÂä°Âú∫ÊôØÔºåÊîØÊåÅÊåâÈúÄÂÆöÂà∂ÔºåÊ≥®ÂÜåÂÖçË¥πÊèêÂèñ10000ip„ÄÇ &lt;/a&gt; 
&lt;hr /&gt; 
&lt;p align="center"&gt; &lt;a href="https://tikhub.io/?utm_source=github.com/NanmiCoder/MediaCrawler&amp;amp;utm_medium=marketing_social&amp;amp;utm_campaign=retargeting&amp;amp;utm_content=carousel_ad"&gt; &lt;img style="border-radius:20px" width="500" alt="TikHub IO_Banner zh" src="https://raw.githubusercontent.com/NanmiCoder/MediaCrawler/main/docs/static/images/tikhub_banner_zh.png" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p&gt;&lt;a href="https://tikhub.io/?utm_source=github.com/NanmiCoder/MediaCrawler&amp;amp;utm_medium=marketing_social&amp;amp;utm_campaign=retargeting&amp;amp;utm_content=carousel_ad"&gt;TikHub&lt;/a&gt; Êèê‰æõË∂ÖËøá &lt;strong&gt;700 ‰∏™Á´ØÁÇπ&lt;/strong&gt;ÔºåÂèØÁî®‰∫é‰ªé &lt;strong&gt;14+ ‰∏™Á§æ‰∫§Â™í‰ΩìÂπ≥Âè∞&lt;/strong&gt; Ëé∑Âèñ‰∏éÂàÜÊûêÊï∞ÊçÆ ‚Äî‚Äî ÂåÖÊã¨ËßÜÈ¢ë„ÄÅÁî®Êà∑„ÄÅËØÑËÆ∫„ÄÅÂïÜÂ∫ó„ÄÅÂïÜÂìÅ‰∏éË∂ãÂäøÁ≠âÔºå‰∏ÄÁ´ôÂºèÂÆåÊàêÊâÄÊúâÊï∞ÊçÆËÆøÈóÆ‰∏éÂàÜÊûê„ÄÇ&lt;/p&gt; 
&lt;p&gt;ÈÄöËøáÊØèÊó•Á≠æÂà∞ÔºåÂèØ‰ª•Ëé∑ÂèñÂÖçË¥πÈ¢ùÂ∫¶„ÄÇÂèØ‰ª•‰ΩøÁî®ÊàëÁöÑÊ≥®ÂÜåÈìæÊé•Ôºö&lt;a href="https://user.tikhub.io/users/signup?referral_code=cfzyejV9&amp;amp;utm_source=github.com/NanmiCoder/MediaCrawler&amp;amp;utm_medium=marketing_social&amp;amp;utm_campaign=retargeting&amp;amp;utm_content=carousel_ad"&gt;https://user.tikhub.io/users/signup?referral_code=cfzyejV9&lt;/a&gt; Êàñ‰ΩøÁî®ÈÇÄËØ∑Á†ÅÔºö&lt;code&gt;cfzyejV9&lt;/code&gt;ÔºåÊ≥®ÂÜåÂπ∂ÂÖÖÂÄºÂç≥ÂèØËé∑Âæó &lt;strong&gt;$2 ÂÖçË¥πÈ¢ùÂ∫¶&lt;/strong&gt;„ÄÇ&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://tikhub.io/?utm_source=github.com/NanmiCoder/MediaCrawler&amp;amp;utm_medium=marketing_social&amp;amp;utm_campaign=retargeting&amp;amp;utm_content=carousel_ad"&gt;TikHub&lt;/a&gt; Êèê‰æõ‰ª•‰∏ãÊúçÂä°Ôºö&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;üöÄ ‰∏∞ÂØåÁöÑÁ§æ‰∫§Â™í‰ΩìÊï∞ÊçÆÊé•Âè£ÔºàTikTok„ÄÅDouyin„ÄÅXHS„ÄÅYouTube„ÄÅInstagramÁ≠âÔºâ&lt;/li&gt; 
 &lt;li&gt;üíé ÊØèÊó•Á≠æÂà∞ÂÖçË¥πÈ¢ÜÂèñÈ¢ùÂ∫¶&lt;/li&gt; 
 &lt;li&gt;‚ö° È´òÊàêÂäüÁéá‰∏éÈ´òÂπ∂ÂèëÊîØÊåÅ&lt;/li&gt; 
 &lt;li&gt;üåê ÂÆòÁΩëÔºö&lt;a href="https://tikhub.io/?utm_source=github.com/NanmiCoder/MediaCrawler&amp;amp;utm_medium=marketing_social&amp;amp;utm_campaign=retargeting&amp;amp;utm_content=carousel_ad"&gt;https://tikhub.io/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üíª GitHubÂú∞ÂùÄÔºö&lt;a href="https://github.com/TikHubIO/"&gt;https://github.com/TikHubIO/&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;p align="center"&gt; &lt;a href="https://app.nstbrowser.io/account/register?utm_source=official&amp;amp;utm_term=mediacrawler"&gt; &lt;img style="border-radius:20px" alt="NstBrowser Banner " src="https://raw.githubusercontent.com/NanmiCoder/MediaCrawler/main/docs/static/images/nstbrowser.jpg" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p&gt;Nstbrowser ÊåáÁ∫πÊµèËßàÂô® ‚Äî Â§öË¥¶Âè∑ËøêËê•&amp;amp;Ëá™Âä®ÂåñÁÆ°ÁêÜÁöÑÊúÄ‰Ω≥Ëß£ÂÜ≥ÊñπÊ°à &lt;br /&gt; Â§öË¥¶Âè∑ÂÆâÂÖ®ÁÆ°ÁêÜ‰∏é‰ºöËØùÈöîÁ¶ªÔºõÊåáÁ∫πÂÆöÂà∂ÁªìÂêàÂèçÊ£ÄÊµãÊµèËßàÂô®ÁéØÂ¢ÉÔºåÂÖºÈ°æÁúüÂÆûÂ∫¶‰∏éÁ®≥ÂÆöÊÄßÔºõË¶ÜÁõñÂ∫óÈì∫ÁÆ°ÁêÜ„ÄÅÁîµÂïÜÁõëÊéß„ÄÅÁ§æÂ™íËê•ÈîÄ„ÄÅÂπøÂëäÈ™åËØÅ„ÄÅWeb3„ÄÅÊäïÊîæÁõëÊéß‰∏éËÅîÁõüËê•ÈîÄÁ≠â‰∏öÂä°Á∫øÔºõÊèê‰æõÁîü‰∫ßÁ∫ßÂπ∂Âèë‰∏éÂÆöÂà∂Âåñ‰ºÅ‰∏öÊúçÂä°ÔºõÊèê‰æõÂèØ‰∏ÄÈîÆÈÉ®ÁΩ≤ÁöÑ‰∫ëÁ´ØÊµèËßàÂô®ÊñπÊ°àÔºåÈÖçÂ•óÂÖ®ÁêÉÈ´òË¥®Èáè IP Ê±†Ôºå‰∏∫ÊÇ®ÊûÑÂª∫ÈïøÊúüË°å‰∏öÁ´û‰∫âÂäõ &lt;br /&gt; &lt;a href="https://app.nstbrowser.io/account/register?utm_source=official&amp;amp;utm_term=mediacrawler"&gt;ÁÇπÂáªÊ≠§Â§ÑÂç≥ÂàªÂºÄÂßãÂÖçË¥π‰ΩøÁî®&lt;/a&gt; &lt;br /&gt; ‰ΩøÁî® NSTBROWSER ÂèØËé∑Âæó 10% ÂÖÖÂÄºËµ†Á§º&lt;/p&gt; 
&lt;h3&gt;ü§ù Êàê‰∏∫ËµûÂä©ËÄÖ&lt;/h3&gt; 
&lt;p&gt;Êàê‰∏∫ËµûÂä©ËÄÖÔºåÂèØ‰ª•Â∞ÜÊÇ®ÁöÑ‰∫ßÂìÅÂ±ïÁ§∫Âú®ËøôÈáåÔºåÊØèÂ§©Ëé∑ÂæóÂ§ßÈáèÊõùÂÖâÔºÅ&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;ËÅîÁ≥ªÊñπÂºè&lt;/strong&gt;Ôºö&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;ÂæÆ‰ø°Ôºö&lt;code&gt;relakkes&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;ÈÇÆÁÆ±Ôºö&lt;code&gt;relakkes@gmail.com&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;‚≠ê Star Ë∂ãÂäøÂõæ&lt;/h2&gt; 
&lt;p&gt;Â¶ÇÊûúËøô‰∏™È°πÁõÆÂØπÊÇ®ÊúâÂ∏ÆÂä©ÔºåËØ∑Áªô‰∏™ ‚≠ê Star ÊîØÊåÅ‰∏Ä‰∏ãÔºåËÆ©Êõ¥Â§öÁöÑ‰∫∫ÁúãÂà∞ MediaCrawlerÔºÅ&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://star-history.com/#NanmiCoder/MediaCrawler&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=NanmiCoder/MediaCrawler&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üìö ÂèÇËÄÉ&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Â∞èÁ∫¢‰π¶Á≠æÂêç‰ªìÂ∫ì&lt;/strong&gt;Ôºö&lt;a href="https://github.com/Cloxl/xhshow"&gt;Cloxl ÁöÑ xhs Á≠æÂêç‰ªìÂ∫ì&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Â∞èÁ∫¢‰π¶ÂÆ¢Êà∑Á´Ø&lt;/strong&gt;Ôºö&lt;a href="https://github.com/ReaJason/xhs"&gt;ReaJason ÁöÑ xhs ‰ªìÂ∫ì&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Áü≠‰ø°ËΩ¨Âèë&lt;/strong&gt;Ôºö&lt;a href="https://github.com/pppscn/SmsForwarder"&gt;SmsForwarder ÂèÇËÄÉ‰ªìÂ∫ì&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ÂÜÖÁΩëÁ©øÈÄèÂ∑•ÂÖ∑&lt;/strong&gt;Ôºö&lt;a href="https://ngrok.com/docs/"&gt;ngrok ÂÆòÊñπÊñáÊ°£&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;ÂÖçË¥£Â£∞Êòé&lt;/h1&gt; 
&lt;div id="disclaimer"&gt; 
 &lt;h2&gt;1. È°πÁõÆÁõÆÁöÑ‰∏éÊÄßË¥®&lt;/h2&gt; 
 &lt;p&gt;Êú¨È°πÁõÆÔºà‰ª•‰∏ãÁÆÄÁß∞‚ÄúÊú¨È°πÁõÆ‚ÄùÔºâÊòØ‰Ωú‰∏∫‰∏Ä‰∏™ÊäÄÊúØÁ†îÁ©∂‰∏éÂ≠¶‰π†Â∑•ÂÖ∑ËÄåÂàõÂª∫ÁöÑÔºåÊó®Âú®Êé¢Á¥¢ÂíåÂ≠¶‰π†ÁΩëÁªúÊï∞ÊçÆÈááÈõÜÊäÄÊúØ„ÄÇÊú¨È°πÁõÆ‰∏ìÊ≥®‰∫éËá™Â™í‰ΩìÂπ≥Âè∞ÁöÑÊï∞ÊçÆÁà¨ÂèñÊäÄÊúØÁ†îÁ©∂ÔºåÊó®Âú®Êèê‰æõÁªôÂ≠¶‰π†ËÄÖÂíåÁ†îÁ©∂ËÄÖ‰Ωú‰∏∫ÊäÄÊúØ‰∫§ÊµÅ‰πãÁî®„ÄÇ&lt;/p&gt; 
 &lt;h2&gt;2. Ê≥ïÂæãÂêàËßÑÊÄßÂ£∞Êòé&lt;/h2&gt; 
 &lt;p&gt;Êú¨È°πÁõÆÂºÄÂèëËÄÖÔºà‰ª•‰∏ãÁÆÄÁß∞‚ÄúÂºÄÂèëËÄÖ‚ÄùÔºâÈÉëÈáçÊèêÈÜíÁî®Êà∑Âú®‰∏ãËΩΩ„ÄÅÂÆâË£ÖÂíå‰ΩøÁî®Êú¨È°πÁõÆÊó∂Ôºå‰∏•Ê†ºÈÅµÂÆà‰∏≠Âçé‰∫∫Ê∞ëÂÖ±ÂíåÂõΩÁõ∏ÂÖ≥Ê≥ïÂæãÊ≥ïËßÑÔºåÂåÖÊã¨‰ΩÜ‰∏çÈôê‰∫é„Ää‰∏≠Âçé‰∫∫Ê∞ëÂÖ±ÂíåÂõΩÁΩëÁªúÂÆâÂÖ®Ê≥ï„Äã„ÄÅ„Ää‰∏≠Âçé‰∫∫Ê∞ëÂÖ±ÂíåÂõΩÂèçÈó¥Ë∞çÊ≥ï„ÄãÁ≠âÊâÄÊúâÈÄÇÁî®ÁöÑÂõΩÂÆ∂Ê≥ïÂæãÂíåÊîøÁ≠ñ„ÄÇÁî®Êà∑Â∫îËá™Ë°åÊâøÊãÖ‰∏ÄÂàáÂõ†‰ΩøÁî®Êú¨È°πÁõÆËÄåÂèØËÉΩÂºïËµ∑ÁöÑÊ≥ïÂæãË¥£‰ªª„ÄÇ&lt;/p&gt; 
 &lt;h2&gt;3. ‰ΩøÁî®ÁõÆÁöÑÈôêÂà∂&lt;/h2&gt; 
 &lt;p&gt;Êú¨È°πÁõÆ‰∏•Á¶ÅÁî®‰∫é‰ªª‰ΩïÈùûÊ≥ïÁõÆÁöÑÊàñÈùûÂ≠¶‰π†„ÄÅÈùûÁ†îÁ©∂ÁöÑÂïÜ‰∏öË°å‰∏∫„ÄÇÊú¨È°πÁõÆ‰∏çÂæóÁî®‰∫é‰ªª‰ΩïÂΩ¢ÂºèÁöÑÈùûÊ≥ï‰æµÂÖ•‰ªñ‰∫∫ËÆ°ÁÆóÊú∫Á≥ªÁªüÔºå‰∏çÂæóÁî®‰∫é‰ªª‰Ωï‰æµÁäØ‰ªñ‰∫∫Áü•ËØÜ‰∫ßÊùÉÊàñÂÖ∂‰ªñÂêàÊ≥ïÊùÉÁõäÁöÑË°å‰∏∫„ÄÇÁî®Êà∑Â∫î‰øùËØÅÂÖ∂‰ΩøÁî®Êú¨È°πÁõÆÁöÑÁõÆÁöÑÁ∫ØÂ±û‰∏™‰∫∫Â≠¶‰π†ÂíåÊäÄÊúØÁ†îÁ©∂Ôºå‰∏çÂæóÁî®‰∫é‰ªª‰ΩïÂΩ¢ÂºèÁöÑÈùûÊ≥ïÊ¥ªÂä®„ÄÇ&lt;/p&gt; 
 &lt;h2&gt;4. ÂÖçË¥£Â£∞Êòé&lt;/h2&gt; 
 &lt;p&gt;ÂºÄÂèëËÄÖÂ∑≤Â∞ΩÊúÄÂ§ßÂä™ÂäõÁ°Æ‰øùÊú¨È°πÁõÆÁöÑÊ≠£ÂΩìÊÄßÂèäÂÆâÂÖ®ÊÄßÔºå‰ΩÜ‰∏çÂØπÁî®Êà∑‰ΩøÁî®Êú¨È°πÁõÆÂèØËÉΩÂºïËµ∑ÁöÑ‰ªª‰ΩïÂΩ¢ÂºèÁöÑÁõ¥Êé•ÊàñÈó¥Êé•ÊçüÂ§±ÊâøÊãÖË¥£‰ªª„ÄÇÂåÖÊã¨‰ΩÜ‰∏çÈôê‰∫éÁî±‰∫é‰ΩøÁî®Êú¨È°πÁõÆËÄåÂØºËá¥ÁöÑ‰ªª‰ΩïÊï∞ÊçÆ‰∏¢Â§±„ÄÅËÆæÂ§áÊçüÂùè„ÄÅÊ≥ïÂæãËØâËÆºÁ≠â„ÄÇ&lt;/p&gt; 
 &lt;h2&gt;5. Áü•ËØÜ‰∫ßÊùÉÂ£∞Êòé&lt;/h2&gt; 
 &lt;p&gt;Êú¨È°πÁõÆÁöÑÁü•ËØÜ‰∫ßÊùÉÂΩíÂºÄÂèëËÄÖÊâÄÊúâ„ÄÇÊú¨È°πÁõÆÂèóÂà∞Ëëó‰ΩúÊùÉÊ≥ïÂíåÂõΩÈôÖËëó‰ΩúÊùÉÊù°Á∫¶‰ª•ÂèäÂÖ∂‰ªñÁü•ËØÜ‰∫ßÊùÉÊ≥ïÂæãÂíåÊù°Á∫¶ÁöÑ‰øùÊä§„ÄÇÁî®Êà∑Âú®ÈÅµÂÆàÊú¨Â£∞ÊòéÂèäÁõ∏ÂÖ≥Ê≥ïÂæãÊ≥ïËßÑÁöÑÂâçÊèê‰∏ãÔºåÂèØ‰ª•‰∏ãËΩΩÂíå‰ΩøÁî®Êú¨È°πÁõÆ„ÄÇ&lt;/p&gt; 
 &lt;h2&gt;6. ÊúÄÁªàËß£ÈáäÊùÉ&lt;/h2&gt; 
 &lt;p&gt;ÂÖ≥‰∫éÊú¨È°πÁõÆÁöÑÊúÄÁªàËß£ÈáäÊùÉÂΩíÂºÄÂèëËÄÖÊâÄÊúâ„ÄÇÂºÄÂèëËÄÖ‰øùÁïôÈöèÊó∂Êõ¥ÊîπÊàñÊõ¥Êñ∞Êú¨ÂÖçË¥£Â£∞ÊòéÁöÑÊùÉÂà©ÔºåÊÅï‰∏çÂè¶Ë°åÈÄöÁü•„ÄÇ&lt;/p&gt; 
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>hanxi/xiaomusic</title>
      <link>https://github.com/hanxi/xiaomusic</link>
      <description>&lt;p&gt;‰ΩøÁî®Â∞èÁà±Èü≥ÁÆ±Êí≠ÊîæÈü≥‰πêÔºåÈü≥‰πê‰ΩøÁî® yt-dlp ‰∏ãËΩΩ„ÄÇ&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;XiaoMusic: Êó†ÈôêÂê¨Ê≠åÔºåËß£ÊîæÂ∞èÁà±Èü≥ÁÆ±&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://github.com/hanxi/xiaomusic"&gt;&lt;img src="https://img.shields.io/github/license/hanxi/xiaomusic" alt="GitHub License" /&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/r/hanxi/xiaomusic"&gt;&lt;img src="https://img.shields.io/docker/v/hanxi/xiaomusic?sort=semver&amp;amp;label=docker%20image" alt="Docker Image Version" /&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/r/hanxi/xiaomusic"&gt;&lt;img src="https://img.shields.io/docker/pulls/hanxi/xiaomusic" alt="Docker Pulls" /&gt;&lt;/a&gt; &lt;a href="https://pypi.org/project/xiaomusic/"&gt;&lt;img src="https://img.shields.io/pypi/v/xiaomusic" alt="PyPI - Version" /&gt;&lt;/a&gt; &lt;a href="https://pypi.org/project/xiaomusic/"&gt;&lt;img src="https://img.shields.io/pypi/dm/xiaomusic" alt="PyPI - Downloads" /&gt;&lt;/a&gt; &lt;a href="https://pypi.org/project/xiaomusic/"&gt;&lt;img src="https://img.shields.io/python/required-version-toml?tomlFilePath=https%3A%2F%2Fraw.githubusercontent.com%2Fhanxi%2Fxiaomusic%2Fmain%2Fpyproject.toml" alt="Python Version from PEP 621 TOML" /&gt;&lt;/a&gt; &lt;a href="https://github.com/hanxi/xiaomusic/releases"&gt;&lt;img src="https://img.shields.io/github/v/release/hanxi/xiaomusic" alt="GitHub Release" /&gt;&lt;/a&gt; &lt;a href="https://visitorbadge.io/status?path=hanxi%2Fxiaomusic"&gt;&lt;img src="https://api.visitorbadge.io/api/daily?path=hanxi%2Fxiaomusic&amp;amp;label=daily%20visitor&amp;amp;countColor=%232ccce4&amp;amp;style=flat" alt="Visitors" /&gt;&lt;/a&gt; &lt;a href="https://visitorbadge.io/status?path=hanxi%2Fxiaomusic"&gt;&lt;img src="https://api.visitorbadge.io/api/visitors?path=hanxi%2Fxiaomusic&amp;amp;label=total%20visitor&amp;amp;countColor=%232ccce4&amp;amp;style=flat" alt="Visitors" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;‰ΩøÁî®Â∞èÁà±Èü≥ÁÆ±Êí≠ÊîæÈü≥‰πêÔºåÈü≥‰πê‰ΩøÁî® yt-dlp ‰∏ãËΩΩ„ÄÇ&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/hanxi/xiaomusic"&gt;https://github.com/hanxi/xiaomusic&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;ÊñáÊ°£: &lt;a href="https://xdocs.hanxi.cc/"&gt;https://xdocs.hanxi.cc/&lt;/a&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] ÂàùÊ¨°ÂÆâË£ÖÈÅáÂà∞ÈóÆÈ¢òËØ∑Êü•ÈòÖ &lt;a href="https://github.com/hanxi/xiaomusic/issues/99"&gt;üí¨ FAQÈóÆÈ¢òÈõÜÂêà&lt;/a&gt; Ôºå‰∏ÄËà¨ÈÅáÂà∞ÁöÑÈóÆÈ¢òÈÉΩÂ∑≤ÁªèÊúâËß£ÂÜ≥ÂäûÊ≥ï„ÄÇ&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;üëã ÊúÄÁÆÄÈÖçÁΩÆËøêË°å&lt;/h2&gt; 
&lt;p&gt;Â∑≤ÁªèÊîØÊåÅÂú® web È°µÈù¢ÈÖçÁΩÆÂÖ∂‰ªñÂèÇÊï∞Ôºådocker ÂêØÂä®ÂëΩ‰ª§Â¶Ç‰∏ã:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run -p 58090:8090 -e XIAOMUSIC_PUBLIC_PORT=58090 -v /xiaomusic_music:/app/music -v /xiaomusic_conf:/app/conf hanxi/xiaomusic
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;üî• ÂõΩÂÜÖÔºö&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run -p 58090:8090 -e XIAOMUSIC_PUBLIC_PORT=58090 -v /xiaomusic_music:/app/music -v /xiaomusic_conf:/app/conf docker.hanxi.cc/hanxi/xiaomusic
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;ÂØπÂ∫îÁöÑ docker compose ÈÖçÁΩÆÂ¶Ç‰∏ãÔºö&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;services:
  xiaomusic:
    image: hanxi/xiaomusic
    container_name: xiaomusic
    restart: unless-stopped
    ports:
      - 58090:8090
    environment:
      XIAOMUSIC_PUBLIC_PORT: 58090
    volumes:
      - /xiaomusic_music:/app/music
      - /xiaomusic_conf:/app/conf
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;üî• ÂõΩÂÜÖÔºö&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;services:
  xiaomusic:
    image: docker.hanxi.cc/hanxi/xiaomusic
    container_name: xiaomusic
    restart: unless-stopped
    ports:
      - 58090:8090
    environment:
      XIAOMUSIC_PUBLIC_PORT: 58090
    volumes:
      - /xiaomusic_music:/app/music
      - /xiaomusic_conf:/app/conf
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;ÂÖ∂‰∏≠ conf ÁõÆÂΩï‰∏∫ÈÖçÁΩÆÊñá‰ª∂Â≠òÊîæÁõÆÂΩïÔºåmusic ÁõÆÂΩï‰∏∫Èü≥‰πêÂ≠òÊîæÁõÆÂΩïÔºåÂª∫ËÆÆÂàÜÂºÄÈÖçÁΩÆ‰∏∫‰∏çÂêåÁöÑÁõÆÂΩï„ÄÇ&lt;/li&gt; 
 &lt;li&gt;/xiaomusic_music Âíå /xiaomusic_conf ÊòØ docker ÊâÄÂú®ÁöÑ‰∏ªÊú∫ÁöÑÁõÆÂΩïÔºåÂèØ‰ª•‰øÆÊîπ‰∏∫ÂÖ∂‰ªñÁõÆÂΩï„ÄÇÂ¶ÇÊûúÊä•ÈîôÊâæ‰∏çÂà∞ /xiaomusic_music ÁõÆÂΩïÔºåÂèØ‰ª•ÂÖàÊâßË°å &lt;code&gt;mkdir -p /xiaomusic_{music,conf}&lt;/code&gt; ÂëΩ‰ª§Êñ∞Âª∫ÁõÆÂΩï„ÄÇ&lt;/li&gt; 
 &lt;li&gt;/app/music Âíå /app/conf ÊòØ docker ÂÆπÂô®ÈáåÁöÑÁõÆÂΩïÔºå‰∏çË¶ÅÂéª‰øÆÊîπ„ÄÇ&lt;/li&gt; 
 &lt;li&gt;XIAOMUSIC_PUBLIC_PORT ÊòØÁî®Êù•ÈÖçÁΩÆ NAS Êú¨Âú∞Á´ØÂè£ÁöÑ„ÄÇ8090 ÊòØÂÆπÂô®Á´ØÂè£Ôºå‰∏çË¶ÅÂéª‰øÆÊîπ„ÄÇ&lt;/li&gt; 
 &lt;li&gt;ÂêéÂè∞ËÆøÈóÆÂú∞ÂùÄ‰∏∫Ôºö http://NAS_IP:58090&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] docker Âíå docker compose ‰∫åÈÄâ‰∏ÄÂç≥ÂèØÔºåÂêØÂä®ÊàêÂäüÂêéÔºåÂú® web È°µÈù¢ÂèØ‰ª•ÈÖçÁΩÆÂÖ∂‰ªñÂèÇÊï∞ÔºåÂ∏¶Êúâ &lt;code&gt;*&lt;/code&gt; Âè∑ÁöÑÈÖçÁΩÆÊòØÂøÖÈ°ªË¶ÅÈÖçÁΩÆÁöÑÔºåÂÖ∂‰ªñÁöÑÁî®‰∏ç‰∏äÊó∂‰∏çÁî®‰øÆÊîπ„ÄÇÂàùÊ¨°ÈÖçÁΩÆÊó∂ÈúÄË¶ÅÂú®È°µÈù¢‰∏äËæìÂÖ•Â∞èÁ±≥Ë¥¶Âè∑ÂíåÂØÜÁ†Å‰øùÂ≠òÂêéÊâçËÉΩËé∑ÂèñÂà∞ËÆæÂ§áÂàóË°®„ÄÇ&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] ÁõÆÂâçÂÆâË£ÖÊ≠•È™§Â∑≤ÁªèÊòØÊúÄÁÆÄÂåñ‰∫ÜÔºåÂ¶ÇÊûúËøòÊòØÂ´åÂÆâË£ÖÈ∫ªÁÉ¶ÔºåÂèØ‰ª•ÂæÆ‰ø°ÊàñËÄÖ QQ Á∫¶ÊàëËøúÁ®ãÂÆâË£ÖÔºåÊàë‰∏ÄËà¨Âë®Êú´ÂíåÊôö‰∏äÊâçÊúâÊó∂Èó¥ÔºåÈúÄË¶ÅËµûÂä©‰∏™ËæõËã¶Ë¥π &lt;span&gt;üí∞&lt;/span&gt; 50 ÂÖÉ‰∏ÄÊ¨°„ÄÇ&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;ÈÅáÂà∞ÈóÆÈ¢òÂèØ‰ª•Âéª web ËÆæÁΩÆÈ°µÈù¢Â∫ïÈÉ®ÁÇπÂáª„Äê‰∏ãËΩΩÊó•ÂøóÊñá‰ª∂„ÄëÊåâÈíÆÔºåÁÑ∂ÂêéÊêúÁ¥¢‰∏Ä‰∏ãÊó•ÂøóÊñá‰ª∂ÂÜÖÂÆπÁ°Æ‰øùÈáåÈù¢Ê≤°ÊúâË¥¶Âè∑ÂØÜÁ†Å‰ø°ÊÅØÂêé(ÊúâÂ∞±Âà†Èô§Ëøô‰∫õÊïèÊÑü‰ø°ÊÅØ)ÔºåÁÑ∂ÂêéÂú®Êèê issues ÂèçÈ¶àÈóÆÈ¢òÊó∂Êää‰∏ãËΩΩÁöÑÊó•ÂøóÊñá‰ª∂Â∏¶‰∏ä„ÄÇ&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] ‰ΩúËÄÖÁöÑÂè¶‰∏Ä‰∏™ÈÄÇÁî®‰∫é NAS ‰∏äÂÆâË£ÖÁöÑÂºÄÊ∫êÂ∑•ÂÖ∑Ôºö &lt;a href="https://github.com/hanxi/tiny-nav"&gt;https://github.com/hanxi/tiny-nav&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP]&lt;/p&gt; 
 &lt;p&gt;ÂñúÊ¨¢Âê¨‰π¶ÁöÑÂèØ‰ª•ÈÖçÂêàËøô‰∏™Â∑•ÂÖ∑‰ΩøÁî® &lt;a href="https://github.com/hanxi/epub2mp3"&gt;https://github.com/hanxi/epub2mp3&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP]&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;üî•„ÄêÂπøÂëä:ÂèØÁî®‰∫éÂÆâË£Ö frp ÂÆûÁé∞ÂÜÖÁΩëÁ©øÈÄè„Äë&lt;/li&gt; 
  &lt;li&gt;üî• Êµ∑Â§ñ RackNerd VPS Êú∫Âô®Êé®ËçêÔºåÂèØÊîØ‰ªòÂÆù‰ªòÊ¨æ„ÄÇ&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://my.racknerd.com/aff.php?aff=11177"&gt;&lt;img src="https://racknerd.com/banners/320x50.gif" alt="RackNerd Mobile Leaderboard Banner" width="320" height="50" /&gt;&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;‰∏çÁü•ÈÅìÈÄâÂì™‰∏™Â•óÈ§êÂèØ‰ª•Áõ¥Êé•‰π∞Ëøô‰∏™ÊúÄ‰æøÂÆúÁöÑ &lt;a href="https://my.racknerd.com/aff.php?aff=11177&amp;amp;pid=917"&gt;https://my.racknerd.com/aff.php?aff=11177&amp;amp;pid=917&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;‰πüÂèØ‰ª•Áî®Êù•ÈÉ®ÁΩ≤‰ª£ÁêÜÔºådocker ÈÉ®ÁΩ≤ÊñπÊ≥ïËßÅ &lt;a href="https://github.com/hanxi/blog/issues/96"&gt;https://github.com/hanxi/blog/issues/96&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP]&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;üî•„ÄêÂπøÂëä: Êê≠Âª∫ÊÇ®ÁöÑ‰∏ìÂ±ûÂ§ßÊ®°Âûã‰∏ªÈ°µ ÂëäÂà´ÁπÅÁêêÈÖçÁΩÆÈöæÈ¢òÔºå‰∏ÄÈîÆÂç≥ÂèØÁïÖ‰∫´Á®≥ÂÆöÊµÅÁïÖÁöÑAI‰ΩìÈ™åÔºÅ„Äë&lt;a href="https://university.aliyun.com/mobile?userCode=szqvatm6"&gt;https://university.aliyun.com/mobile?userCode=szqvatm6&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP]&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;ÂÖçË¥π‰∏ªÊú∫&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://dartnode.com?aff=SnappyPigeon570"&gt;&lt;img src="https://dartnode.com/branding/DN-Open-Source-sm.png" alt="Powered by DartNode - Free VPS for Open Source" width="320" /&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;ü§ê ÊîØÊåÅËØ≠Èü≥Âè£‰ª§&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;„ÄêÊí≠ÊîæÊ≠åÊõ≤„ÄëÔºåÊí≠ÊîæÊú¨Âú∞ÁöÑÊ≠åÊõ≤&lt;/li&gt; 
 &lt;li&gt;„ÄêÊí≠ÊîæÊ≠åÊõ≤+Ê≠åÂêç„ÄëÔºåÊØîÂ¶ÇÔºöÊí≠ÊîæÊ≠åÊõ≤Âë®Êù∞‰º¶Êô¥Â§©&lt;/li&gt; 
 &lt;li&gt;„Äê‰∏ä‰∏ÄÈ¶ñ„Äë&lt;/li&gt; 
 &lt;li&gt;„Äê‰∏ã‰∏ÄÈ¶ñ„Äë&lt;/li&gt; 
 &lt;li&gt;„ÄêÂçïÊõ≤Âæ™ÁéØ„Äë&lt;/li&gt; 
 &lt;li&gt;„ÄêÂÖ®ÈÉ®Âæ™ÁéØ„Äë&lt;/li&gt; 
 &lt;li&gt;„ÄêÈöèÊú∫Êí≠Êîæ„Äë&lt;/li&gt; 
 &lt;li&gt;„ÄêÂÖ≥Êú∫„ÄëÔºå„ÄêÂÅúÊ≠¢Êí≠Êîæ„ÄëÔºå‰∏§‰∏™ÊïàÊûúÊòØ‰∏ÄÊ†∑ÁöÑ„ÄÇ&lt;/li&gt; 
 &lt;li&gt;„ÄêÂà∑Êñ∞ÂàóË°®„ÄëÔºåÂΩìÂ§çÂà∂‰∫ÜÊ≠åÊõ≤Ëøõ music ÁõÆÂΩïÂêéÔºåÂèØ‰ª•Áî®Ëøô‰∏™Âè£‰ª§Âà∑Êñ∞Ê≠åÂçï„ÄÇ&lt;/li&gt; 
 &lt;li&gt;„ÄêÊí≠ÊîæÂàóË°®+ÂàóË°®Âêç„ÄëÔºåÊØîÂ¶ÇÔºöÊí≠ÊîæÂàóË°®ÂÖ∂‰ªñ„ÄÇ&lt;/li&gt; 
 &lt;li&gt;„ÄêÂä†ÂÖ•Êî∂Ëóè„ÄëÔºåÊääÂΩìÂâçÊí≠ÊîæÁöÑÊ≠åÊõ≤Âä†ÂÖ•Êî∂ËóèÊ≠åÂçï„ÄÇ&lt;/li&gt; 
 &lt;li&gt;„ÄêÂèñÊ∂àÊî∂Ëóè„ÄëÔºåÊääÂΩìÂâçÊí≠ÊîæÁöÑÊ≠åÊõ≤‰ªéÊî∂ËóèÊ≠åÂçïÈáåÁßªÈô§„ÄÇ&lt;/li&gt; 
 &lt;li&gt;„ÄêÊí≠ÊîæÂàóË°®Êî∂Ëóè„ÄëÔºåËøô‰∏™Áî®‰∫éÊí≠ÊîæÊî∂ËóèÊ≠åÂçï„ÄÇ&lt;/li&gt; 
 &lt;li&gt;&lt;del&gt;„ÄêÊí≠ÊîæÊú¨Âú∞Ê≠åÊõ≤+Ê≠åÂêç„ÄëÔºåËøô‰∏™Âè£‰ª§ÂíåÊí≠ÊîæÊ≠åÊõ≤ÁöÑÂå∫Âà´ÊòØÊú¨Âú∞Êâæ‰∏çÂà∞‰πü‰∏ç‰ºöÂéª‰∏ãËΩΩ„ÄÇ&lt;/del&gt;&lt;/li&gt; 
 &lt;li&gt;„ÄêÊí≠ÊîæÂàóË°®Á¨¨Âá†‰∏™+ÂàóË°®Âêç„ÄëÔºåÂÖ∑‰ΩìËßÅÔºö &lt;a href="https://github.com/hanxi/xiaomusic/issues/158"&gt;https://github.com/hanxi/xiaomusic/issues/158&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;„ÄêÊêúÁ¥¢Êí≠Êîæ+ÂÖ≥ÈîÆËØç„ÄëÔºå‰ºöÊêúÁ¥¢ÂÖ≥ÈîÆËØç‰Ωú‰∏∫‰∏¥Êó∂ÊêúÁ¥¢ÂàóË°®Êí≠ÊîæÔºåÊØîÂ¶ÇËØ¥„ÄêÊêúÁ¥¢Êí≠ÊîæÊûó‰øäÊù∞„ÄëÔºå‰ºöÊí≠ÊîæÊâÄÊúâÊûó‰øäÊù∞ÁöÑÊ≠å„ÄÇ&lt;/li&gt; 
 &lt;li&gt;„ÄêÊú¨Âú∞ÊêúÁ¥¢Êí≠Êîæ+ÂÖ≥ÈîÆËØç„ÄëÔºåË∑üÊêúÁ¥¢Êí≠ÊîæÁöÑÂå∫Âà´ÊòØÊú¨Âú∞Êâæ‰∏çÂà∞‰πü‰∏ç‰ºöÂéª‰∏ãËΩΩ„ÄÇ&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] ÈöêËóèÁé©Ê≥ï: ÂØπÂ∞èÁà±ÂêåÂ≠¶ËØ¥Êí≠ÊîæÊ≠åÊõ≤Â∞èÁå™‰Ω©Â•áÁöÑÊïÖ‰∫ãÔºå‰ºöÂÖà‰∏ãËΩΩÂ∞èÁå™‰Ω©Â•áÁöÑÊïÖ‰∫ãÔºåÁÑ∂ÂêéÂÜçÊí≠ÊîæÂ∞èÁå™‰Ω©Â•áÁöÑÊïÖ‰∫ã„ÄÇ&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;üõ†Ô∏è pip ÊñπÂºèÂÆâË£ÖËøêË°å&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;&amp;gt; pip install -U xiaomusic
&amp;gt; xiaomusic --help
 __  __  _                   __  __                 _
 \ \/ / (_)   __ _    ___   |  \/  |  _   _   ___  (_)   ___
  \  /  | |  / _` |  / _ \  | |\/| | | | | | / __| | |  / __|
  /  \  | | | (_| | | (_) | | |  | | | |_| | \__ \ | | | (__
 /_/\_\ |_|  \__,_|  \___/  |_|  |_|  \__,_| |___/ |_|  \___|
          XiaoMusic v0.3.69 by: github.com/hanxi

usage: xiaomusic [-h] [--port PORT] [--hardware HARDWARE] [--account ACCOUNT]
                 [--password PASSWORD] [--cookie COOKIE] [--verbose]
                 [--config CONFIG] [--ffmpeg_location FFMPEG_LOCATION]

options:
  -h, --help            show this help message and exit
  --port PORT           ÁõëÂê¨Á´ØÂè£
  --hardware HARDWARE   Â∞èÁà±Èü≥ÁÆ±ÂûãÂè∑
  --account ACCOUNT     xiaomi account
  --password PASSWORD   xiaomi password
  --cookie COOKIE       xiaomi cookie
  --verbose             show info
  --config CONFIG       config file path
  --ffmpeg_location FFMPEG_LOCATION
                        ffmpeg bin path
&amp;gt; xiaomusic --config config.json
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;ÂÖ∂‰∏≠ &lt;code&gt;config.json&lt;/code&gt; Êñá‰ª∂ÂèØ‰ª•ÂèÇËÄÉ &lt;code&gt;config-example.json&lt;/code&gt; Êñá‰ª∂ÈÖçÁΩÆ„ÄÇËßÅ &lt;a href="https://github.com/hanxi/xiaomusic/issues/94"&gt;https://github.com/hanxi/xiaomusic/issues/94&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;‰∏ç‰øÆÊîπÈªòËÆ§Á´ØÂè£ 8090 ÁöÑÊÉÖÂÜµ‰∏ãÔºåÂè™ÈúÄË¶ÅÊâßË°å &lt;code&gt;xiaomusic&lt;/code&gt; Âç≥ÂèØÂêØÂä®„ÄÇ&lt;/p&gt; 
&lt;h2&gt;üî© ÂºÄÂèëÁéØÂ¢ÉËøêË°å&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;‰ΩøÁî® install_dependencies.sh ‰∏ãËΩΩ‰æùËµñ&lt;/li&gt; 
 &lt;li&gt;‰ΩøÁî® pdm ÂÆâË£ÖÁéØÂ¢É&lt;/li&gt; 
 &lt;li&gt;ÈªòËÆ§ÁõëÂê¨‰∫ÜÁ´ØÂè£ 8090 , ‰ΩøÁî®ÂÖ∂‰ªñÁ´ØÂè£Ëá™Ë°å‰øÆÊîπ„ÄÇ&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;pdm run xiaomusic.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Â¶ÇÊûúÊòØÂºÄÂèëÂâçÁ´ØÁïåÈù¢ÔºåÂèØ‰ª•ÈÄöËøá &lt;a href="http://localhost:8090/docs"&gt;http://localhost:8090/docs&lt;/a&gt; Êü•ÁúãÊúâ‰ªÄ‰πàÊé•Âè£„ÄÇÁõÆÂâçÁöÑ web ÊéßÂà∂Âè∞ÈùûÂ∏∏ÁÆÄÈôãÔºåÊ¨¢ËøéÊúâÂÖ¥Ë∂£ÁöÑÊúãÂèãÂ∏ÆÂøôÂÆûÁé∞‰∏Ä‰∏™ÊºÇ‰∫ÆÁöÑÂâçÁ´ØÔºåÈúÄË¶Å‰ªÄ‰πàÊé•Âè£ÂèØ‰ª•ÈöèÊó∂ÊèêÈúÄÊ±Ç„ÄÇ&lt;/p&gt; 
&lt;h3&gt;üö¶ ‰ª£Á†ÅÊèê‰∫§ËßÑËåÉ&lt;/h3&gt; 
&lt;p&gt;Êèê‰∫§ÂâçËØ∑ÊâßË°å&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;pdm lintfmt
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Áî®‰∫éÊ£ÄÊü•‰ª£Á†ÅÂíåÊ†ºÂºèÂåñ‰ª£Á†Å„ÄÇ&lt;/p&gt; 
&lt;h3&gt;Êú¨Âú∞ÁºñËØë Docker Image&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;docker build -t xiaomusic .
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;ÊäÄÊúØÊ†à&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;ÂêéÁ´Ø‰ª£Á†Å‰ΩøÁî® Python ËØ≠Ë®ÄÁºñÂÜô„ÄÇ&lt;/li&gt; 
 &lt;li&gt;HTTP ÊúçÂä°‰ΩøÁî®ÁöÑÊòØ FastAPI Ê°ÜÊû∂Ôºå&lt;del&gt;Êó©ÊúüÁâàÊú¨‰ΩøÁî®ÁöÑÊòØ Flask&lt;/del&gt;„ÄÇ&lt;/li&gt; 
 &lt;li&gt;‰ΩøÁî®‰∫Ü Docker ÔºåÂú® NAS ‰∏äÂÆâË£ÖÊõ¥Êñπ‰æø„ÄÇ&lt;/li&gt; 
 &lt;li&gt;ÈªòËÆ§ÁöÑÂâçÁ´Ø‰∏ªÈ¢ò‰ΩøÁî®‰∫Ü jQuery „ÄÇ&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Â∑≤ÊµãËØïÊîØÊåÅÁöÑËÆæÂ§á&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;ÂûãÂè∑&lt;/th&gt; 
   &lt;th&gt;ÂêçÁß∞&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;L06A&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://home.mi.com/baike/index.html#/detail?model=xiaomi.wifispeaker.l06a"&gt;Â∞èÁà±Èü≥ÁÆ±&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;L07A&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://home.mi.com/webapp/content/baike/product/index.html?model=xiaomi.wifispeaker.l7a"&gt;RedmiÂ∞èÁà±Èü≥ÁÆ± Play&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;S12/S12A/MDZ-25-DA&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://home.mi.com/baike/index.html#/detail?model=xiaomi.wifispeaker.s12"&gt;Â∞èÁ±≥AIÈü≥ÁÆ±&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;LX5A&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://home.mi.com/baike/index.html#/detail?model=xiaomi.wifispeaker.lx5a"&gt;Â∞èÁà±Èü≥ÁÆ± ‰∏áËÉΩÈÅ•ÊéßÁâà&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;LX05&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://home.mi.com/baike/index.html#/detail?model=xiaomi.wifispeaker.lx05"&gt;Â∞èÁà±Èü≥ÁÆ±PlayÔºà2019Ê¨æÔºâ&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;L15A&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://home.mi.com/webapp/content/baike/product/index.html?model=xiaomi.wifispeaker.l15a#/"&gt;Â∞èÁ±≥AIÈü≥ÁÆ±ÔºàÁ¨¨‰∫å‰ª£Ôºâ&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;L16A&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://home.mi.com/baike/index.html#/detail?model=xiaomi.wifispeaker.l16a"&gt;Xiaomi Sound&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;L17A&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://home.mi.com/baike/index.html#/detail?model=xiaomi.wifispeaker.l17a"&gt;Xiaomi Sound Pro&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;LX06&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://home.mi.com/baike/index.html#/detail?model=xiaomi.wifispeaker.lx06"&gt;Â∞èÁà±Èü≥ÁÆ±Pro&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;LX01&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://home.mi.com/baike/index.html#/detail?model=xiaomi.wifispeaker.lx01"&gt;Â∞èÁà±Èü≥ÁÆ±mini&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;L05B&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://home.mi.com/baike/index.html#/detail?model=xiaomi.wifispeaker.l05b"&gt;Â∞èÁà±Èü≥ÁÆ±Play&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;L05C&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://home.mi.com/baike/index.html#/detail?model=xiaomi.wifispeaker.l05c"&gt;Â∞èÁ±≥Â∞èÁà±Èü≥ÁÆ±Play Â¢ûÂº∫Áâà&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;L09A&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://home.mi.com/webapp/content/baike/product/index.html?model=xiaomi.wifispeaker.l09a"&gt;Â∞èÁ±≥Èü≥ÁÆ±Art&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;LX04 X10A X08A&lt;/td&gt; 
   &lt;td&gt;Â∑≤ÁªèÊîØÊåÅÁöÑËß¶Â±èÁâà&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;X08C X08E X8F&lt;/td&gt; 
   &lt;td&gt;Â∑≤Áªè‰∏çÈúÄË¶ÅËÆæÁΩÆ‰∫Ü. &lt;del&gt;ÈúÄË¶ÅËÆæÁΩÆ„ÄêÂûãÂè∑ÂÖºÂÆπÊ®°Âºè„ÄëÈÄâÈ°π‰∏∫ true&lt;/del&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;M01/XMYX01JY&lt;/td&gt; 
   &lt;td&gt;Â∞èÁ±≥Â∞èÁà±Èü≥ÁÆ±HD ÈúÄË¶ÅËÆæÁΩÆ„ÄêÁâπÊÆäÂûãÂè∑Ëé∑ÂèñÂØπËØùËÆ∞ÂΩï„ÄëÈÄâÈ°π‰∏∫ true ÊâçËÉΩËØ≠Èü≥Êí≠Êîæ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;OH2P&lt;/td&gt; 
   &lt;td&gt;XIAOMI Êô∫ËÉΩÈü≥ÁÆ± Pro&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;OH2&lt;/td&gt; 
   &lt;td&gt;XIAOMI Êô∫ËÉΩÈü≥ÁÆ±&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;ÂûãÂè∑‰∏é‰∫ßÂìÅÂêçÁß∞ÂØπÁÖßÂèØ‰ª•Âú®ËøôÈáåÊü•ËØ¢ &lt;a href="https://home.miot-spec.com/s/xiaomi.wifispeaker"&gt;https://home.miot-spec.com/s/xiaomi.wifispeaker&lt;/a&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] Â¶ÇÊûú‰Ω†ÁöÑËÆæÂ§áÊîØÊåÅÊí≠ÊîæÔºåËØ∑ÂèçÈ¶àÁªôÊàëÊ∑ªÂä†Âà∞ÊîØÊåÅÂàóË°®ÈáåÔºåË∞¢Ë∞¢„ÄÇ ÁõÆÂâçÂ∫îËØ•ÊâÄÊúâËÆæÂ§áÁ±ªÂûãÈÉΩÂ∑≤ÁªèÊîØÊåÅÊí≠ÊîæÔºåÊúâÈóÆÈ¢òÈöèÊó∂ÂèçÈ¶à„ÄÇ ÂÖ∂‰ªñËß¶Â±èÁâà‰∏çËÉΩÊí≠ÊîæÂèØ‰ª•ËÆæÁΩÆ„ÄêÂûãÂè∑ÂÖºÂÆπÊ®°Âºè„ÄëÈÄâÈ°π‰∏∫ true ËØïËØï„ÄÇËßÅ &lt;a href="https://github.com/hanxi/xiaomusic/issues/30"&gt;https://github.com/hanxi/xiaomusic/issues/30&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;üéµ ÊîØÊåÅÈü≥‰πêÊ†ºÂºè&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;mp3&lt;/li&gt; 
 &lt;li&gt;flac&lt;/li&gt; 
 &lt;li&gt;wav&lt;/li&gt; 
 &lt;li&gt;ape&lt;/li&gt; 
 &lt;li&gt;ogg&lt;/li&gt; 
 &lt;li&gt;m4a&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] Êú¨Âú∞Èü≥‰πê‰ºöÊêúÁ¥¢ÁõÆÂΩï‰∏ã‰∏äÈù¢Ê†ºÂºèÁöÑÊñá‰ª∂Ôºå‰∏ãËΩΩÁöÑÊ≠åÊõ≤ÊòØ mp3 Ê†ºÂºèÁöÑ„ÄÇ Â∑≤Áü• L05B L05C LX06 L16A ‰∏çÊîØÊåÅ flac Ê†ºÂºè„ÄÇ Â¶ÇÊûúÊ†ºÂºè‰∏çËÉΩÊí≠ÊîæÂèØ‰ª•ÊâìÂºÄ„ÄêËΩ¨Êç¢‰∏∫MP3„ÄëÂíå„ÄêÂûãÂè∑ÂÖºÂÆπÊ®°Âºè„ÄëÈÄâÈ°π„ÄÇÂÖ∑‰ΩìËßÅ &lt;a href="https://github.com/hanxi/xiaomusic/issues/153#issuecomment-2328168689"&gt;https://github.com/hanxi/xiaomusic/issues/153#issuecomment-2328168689&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;üåè ÁΩëÁªúÊ≠åÂçïÂäüËÉΩ&lt;/h2&gt; 
&lt;p&gt;ÂèØ‰ª•ÈÖçÁΩÆ‰∏Ä‰∏™ json Ê†ºÂºèÁöÑÊ≠åÂçïÔºåÊîØÊåÅÁîµÂè∞ÂíåÊ≠åÊõ≤Ôºå‰πüÂèØ‰ª•Áõ¥Êé•Áî®Âà´‰∫∫ÂàÜ‰∫´ÁöÑÈìæÊé•ÔºåÂêåÊó∂ÈÖçÂ§á‰∫Ü m3u Êñá‰ª∂Ê†ºÂºèËΩ¨Êç¢Â∑•ÂÖ∑ÔºåÂèØ‰ª•ÂæàÊñπ‰æøÁöÑÊää m3u ÁîµÂè∞Êñá‰ª∂ËΩ¨Êç¢ÊàêÁΩëÁªúÊ≠åÂçïÊ†ºÂºèÁöÑ json Êñá‰ª∂ÔºåÂÖ∑‰ΩìÁî®Ê≥ïËßÅ &lt;a href="https://github.com/hanxi/xiaomusic/issues/78"&gt;https://github.com/hanxi/xiaomusic/issues/78&lt;/a&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] Ê¨¢ËøéÊúâÊÉ≥Ê≥ïÁöÑÊúãÂèã‰ª¨Âà∂‰ΩúÊõ¥Â§öÁöÑÊ≠åÂçïËΩ¨Êç¢Â∑•ÂÖ∑„ÄÇ&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;üç∫ Êõ¥Â§öÂÖ∂‰ªñÂèØÈÄâÈÖçÁΩÆ&lt;/h2&gt; 
&lt;p&gt;ËßÅ &lt;a href="https://github.com/hanxi/xiaomusic/issues/333"&gt;https://github.com/hanxi/xiaomusic/issues/333&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;‚ö†Ô∏è ÂÆâÂÖ®ÊèêÈÜí&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT]&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;Â¶ÇÊûúÈÖçÁΩÆ‰∫ÜÂÖ¨ÁΩëËÆøÈóÆ xiaomusic ÔºåËØ∑‰∏ÄÂÆöË¶ÅÂºÄÂêØÂØÜÁ†ÅÁôªÈôÜÔºåÂπ∂ËÆæÁΩÆÂ§çÊùÇÁöÑÂØÜÁ†Å„ÄÇ‰∏î‰∏çË¶ÅÂú®ÂÖ¨ÂÖ±Âú∫ÊâÄÁöÑ WiFi ÁéØÂ¢É‰∏ã‰ΩøÁî®ÔºåÂê¶ÂàôÂèØËÉΩÈÄ†ÊàêÂ∞èÁ±≥Ë¥¶Âè∑ÂØÜÁ†ÅÊ≥ÑÈú≤„ÄÇ&lt;/li&gt; 
  &lt;li&gt;Âº∫ÁÉà‰∏çÂª∫ËÆÆÂ∞ÜÂ∞èÁà±Èü≥ÁÆ±ÁöÑÂ∞èÁ±≥Ë¥¶Âè∑ÁªëÂÆöÊëÑÂÉèÂ§¥Ôºå‰ª£Á†ÅÈöæÂÖç‰ºöÊúâ bug Ôºå‰∏ÄÊó¶Â∞èÁ±≥Ë¥¶Âè∑ÂØÜÁ†ÅÊ≥ÑÈú≤ÔºåÂèØËÉΩÁõëÊéßÂΩïÂÉè‰πü‰ºöÊ≥ÑÈú≤„ÄÇ&lt;/li&gt; 
 &lt;/ol&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;ü§î È´òÁ∫ßÁØá&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Ëá™ÂÆö‰πâÂè£‰ª§ÂäüËÉΩ &lt;a href="https://github.com/hanxi/xiaomusic/issues/105"&gt;https://github.com/hanxi/xiaomusic/issues/105&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/hanxi/xiaomusic/issues/312"&gt;https://github.com/hanxi/xiaomusic/issues/312&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/hanxi/xiaomusic/issues/269"&gt;https://github.com/hanxi/xiaomusic/issues/269&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/hanxi/xiaomusic/issues/159"&gt;https://github.com/hanxi/xiaomusic/issues/159&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üì¢ ËÆ®ËÆ∫Âå∫&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://pd.qq.com/s/e2jybz0ss"&gt;ÁÇπÂáªÈìæÊé•Âä†ÂÖ•QQÈ¢ëÈÅì„Äêxiaomusic„Äë&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://qm.qq.com/q/lxIhquqbza"&gt;ÁÇπÂáªÈìæÊé•Âä†ÂÖ•Áæ§ËÅä„ÄêxiaomusicÂÆòÊñπ‰∫§ÊµÅÁæ§3„Äë 1072151477&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/hanxi/xiaomusic/issues"&gt;https://github.com/hanxi/xiaomusic/issues&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/hanxi/xiaomusic/issues/86"&gt;ÂæÆ‰ø°Áæ§‰∫åÁª¥Á†Å&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;‚ù§Ô∏è ÊÑüË∞¢&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.mi.com/"&gt;xiaomi&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pdm.fming.dev/latest/"&gt;PDM&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/yihong0618/xiaogpt"&gt;xiaogpt&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/yihong0618/MiService"&gt;MiService&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/yihong0618/gitblog/issues/258"&gt;ÂÆûÁé∞ÂéüÁêÜ&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp"&gt;yt-dlp&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/zzz6519003/awesome-xiaoai"&gt;awesome-xiaoai&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/F-loat/xiaoplayer"&gt;ÂæÆ‰ø°Â∞èÁ®ãÂ∫è: ÂçØÂçØÈü≥‰πê&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/52fisher/xiaomusicUI"&gt;pure ‰∏ªÈ¢ò xiaomusicUI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/52fisher/XMusicPlayer"&gt;ÁßªÂä®Á´ØÁöÑÊí≠ÊîæÂô®‰∏ªÈ¢ò&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/clarencejh/xiaomusic"&gt;Tailwind‰∏ªÈ¢ò&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jhao0413/SoundScape"&gt;SoundScape‰∏ªÈ¢ò&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/DarrenWen/xiaomusicui"&gt;‰∏Ä‰∏™Á¨¨‰∏âÊñπÁöÑ‰∏ªÈ¢ò&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/umami-software/umami"&gt;Umami ÁªüËÆ°&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/getsentry/sentry"&gt;Sentry Êä•ÈîôÁõëÊéß&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;ÊâÄÊúâÂ∏ÆÂøôË∞ÉËØïÂíåÊµãËØïÁöÑÊúãÂèã&lt;/li&gt; 
 &lt;li&gt;ÊâÄÊúâÂèçÈ¶àÈóÆÈ¢òÂíåÂª∫ËÆÆÁöÑÊúãÂèã&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üëâ ÂÖ∂‰ªñÊïôÁ®ã&lt;/h3&gt; 
&lt;p&gt;Êõ¥Â§öÂäüËÉΩËßÅ &lt;a href="https://github.com/hanxi/xiaomusic/issues/211"&gt;üìù ÊñáÊ°£Ê±áÊÄª&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üö® ÂÖçË¥£Â£∞Êòé&lt;/h2&gt; 
&lt;p&gt;Êú¨È°πÁõÆ‰ªÖ‰æõÂ≠¶‰π†ÂíåÁ†îÁ©∂ÁõÆÁöÑÔºå‰∏çÂæóÁî®‰∫é‰ªª‰ΩïÂïÜ‰∏öÊ¥ªÂä®„ÄÇÁî®Êà∑Âú®‰ΩøÁî®Êú¨È°πÁõÆÊó∂Â∫îÈÅµÂÆàÊâÄÂú®Âú∞Âå∫ÁöÑÊ≥ïÂæãÊ≥ïËßÑÔºåÂØπ‰∫éËøùÊ≥ï‰ΩøÁî®ÊâÄÂØºËá¥ÁöÑÂêéÊûúÔºåÊú¨È°πÁõÆÂèä‰ΩúËÄÖ‰∏çÊâøÊãÖ‰ªª‰ΩïË¥£‰ªª„ÄÇ Êú¨È°πÁõÆÂèØËÉΩÂ≠òÂú®Êú™Áü•ÁöÑÁº∫Èô∑ÂíåÈ£éÈô©ÔºàÂåÖÊã¨‰ΩÜ‰∏çÈôê‰∫éËÆæÂ§áÊçüÂùèÂíåË¥¶Âè∑Â∞ÅÁ¶ÅÁ≠âÔºâÔºå‰ΩøÁî®ËÄÖÂ∫îËá™Ë°åÊâøÊãÖ‰ΩøÁî®Êú¨È°πÁõÆÊâÄ‰∫ßÁîüÁöÑÊâÄÊúâÈ£éÈô©ÂèäË¥£‰ªª„ÄÇ ‰ΩúËÄÖ‰∏ç‰øùËØÅÊú¨È°πÁõÆÁöÑÂáÜÁ°ÆÊÄß„ÄÅÂÆåÊï¥ÊÄß„ÄÅÂèäÊó∂ÊÄß„ÄÅÂèØÈù†ÊÄßÔºå‰πü‰∏çÊâøÊãÖ‰ªª‰ΩïÂõ†‰ΩøÁî®Êú¨È°πÁõÆËÄå‰∫ßÁîüÁöÑ‰ªª‰ΩïÊçüÂ§±ÊàñÊçüÂÆ≥Ë¥£‰ªª„ÄÇ ‰ΩøÁî®Êú¨È°πÁõÆÂç≥Ë°®Á§∫ÊÇ®Â∑≤ÈòÖËØªÂπ∂ÂêåÊÑèÊú¨ÂÖçË¥£Â£∞ÊòéÁöÑÂÖ®ÈÉ®ÂÜÖÂÆπ„ÄÇ&lt;/p&gt; 
&lt;h2&gt;Star History&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://star-history.com/#hanxi/xiaomusic&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=hanxi/xiaomusic&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;ËµûËµè&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span&gt;üí∞&lt;/span&gt; Áà±ÂèëÁîµ &lt;a href="https://afdian.com/a/imhanxi"&gt;https://afdian.com/a/imhanxi&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;ÁÇπ‰∏™ Star &lt;span&gt;‚≠ê&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;Ë∞¢Ë∞¢ &lt;span&gt;‚ù§Ô∏è&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;img src="https://i.v2ex.co/7Q03axO5l.png" alt="ÂñùÊùØÂ•∂Ëå∂" /&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://github.com/hanxi/xiaomusic/raw/main/LICENSE"&gt;MIT&lt;/a&gt; License ¬© 2024 Ê∂µÊõ¶&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>langchain-ai/deepagents</title>
      <link>https://github.com/langchain-ai/deepagents</link>
      <description>&lt;p&gt;Deepagents is an agent harness built on langchain and langgraph. Deep agents are equipped with a planning tool, a filesystem backend, and the ability to spawn subagents - making them well-equipped to handle complex agentic tasks.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;üß†ü§ñDeep Agents&lt;/h1&gt; 
&lt;p&gt;Using an LLM to call tools in a loop is the simplest form of an agent. This architecture, however, can yield agents that are ‚Äúshallow‚Äù and fail to plan and act over longer, more complex tasks.&lt;/p&gt; 
&lt;p&gt;Applications like ‚ÄúDeep Research‚Äù, "Manus", and ‚ÄúClaude Code‚Äù have gotten around this limitation by implementing a combination of four things: a &lt;strong&gt;planning tool&lt;/strong&gt;, &lt;strong&gt;sub agents&lt;/strong&gt;, access to a &lt;strong&gt;file system&lt;/strong&gt;, and a &lt;strong&gt;detailed prompt&lt;/strong&gt;.&lt;/p&gt; 
&lt;img src="https://raw.githubusercontent.com/langchain-ai/deepagents/master/deep_agents.png" alt="deep agent" width="600" /&gt; 
&lt;p&gt;&lt;code&gt;deepagents&lt;/code&gt; is a Python package that implements these in a general purpose way so that you can easily create a Deep Agent for your application. For a full overview and quickstart of &lt;code&gt;deepagents&lt;/code&gt;, the best resource is our &lt;a href="https://docs.langchain.com/oss/python/deepagents/overview"&gt;docs&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Acknowledgements: This project was primarily inspired by Claude Code, and initially was largely an attempt to see what made Claude Code general purpose, and make it even more so.&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# pip
pip install deepagents

# uv
uv add deepagents

# poetry
poetry add deepagents
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;p&gt;(To run the example below, you will need to &lt;code&gt;pip install tavily-python&lt;/code&gt;).&lt;/p&gt; 
&lt;p&gt;Make sure to set &lt;code&gt;TAVILY_API_KEY&lt;/code&gt; in your environment. You can generate one &lt;a href="https://www.tavily.com/"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import os
from typing import Literal
from tavily import TavilyClient
from deepagents import create_deep_agent

tavily_client = TavilyClient(api_key=os.environ["TAVILY_API_KEY"])

# Web search tool
def internet_search(
    query: str,
    max_results: int = 5,
    topic: Literal["general", "news", "finance"] = "general",
    include_raw_content: bool = False,
):
    """Run a web search"""
    return tavily_client.search(
        query,
        max_results=max_results,
        include_raw_content=include_raw_content,
        topic=topic,
    )


# System prompt to steer the agent to be an expert researcher
research_instructions = """You are an expert researcher. Your job is to conduct thorough research, and then write a polished report.

You have access to an internet search tool as your primary means of gathering information.

## `internet_search`

Use this to run an internet search for a given query. You can specify the max number of results to return, the topic, and whether raw content should be included.
"""

# Create the deep agent
agent = create_deep_agent(
    tools=[internet_search],
    system_prompt=research_instructions,
)

# Invoke the agent
result = agent.invoke({"messages": [{"role": "user", "content": "What is langgraph?"}]})
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/langchain-ai/deepagents/master/examples/research/research_agent.py"&gt;examples/research/research_agent.py&lt;/a&gt; for a more complex example.&lt;/p&gt; 
&lt;p&gt;The agent created with &lt;code&gt;create_deep_agent&lt;/code&gt; is just a LangGraph graph - so you can interact with it (streaming, human-in-the-loop, memory, studio) in the same way you would any LangGraph agent.&lt;/p&gt; 
&lt;h2&gt;Core Capabilities&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Planning &amp;amp; Task Decomposition&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Deep Agents include a built-in &lt;code&gt;write_todos&lt;/code&gt; tool that enables agents to break down complex tasks into discrete steps, track progress, and adapt plans as new information emerges.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Context Management&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;File system tools (&lt;code&gt;ls&lt;/code&gt;, &lt;code&gt;read_file&lt;/code&gt;, &lt;code&gt;write_file&lt;/code&gt;, &lt;code&gt;edit_file&lt;/code&gt;, &lt;code&gt;glob&lt;/code&gt;, &lt;code&gt;grep&lt;/code&gt;) allow agents to offload large context to memory, preventing context window overflow and enabling work with variable-length tool results.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Subagent Spawning&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;A built-in &lt;code&gt;task&lt;/code&gt; tool enables agents to spawn specialized subagents for context isolation. This keeps the main agent‚Äôs context clean while still going deep on specific subtasks.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Long-term Memory&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Extend agents with persistent memory across threads using LangGraph‚Äôs Store. Agents can save and retrieve information from previous conversations.&lt;/p&gt; 
&lt;h2&gt;Customizing Deep Agents&lt;/h2&gt; 
&lt;p&gt;There are several parameters you can pass to &lt;code&gt;create_deep_agent&lt;/code&gt; to create your own custom deep agent.&lt;/p&gt; 
&lt;h3&gt;&lt;code&gt;model&lt;/code&gt;&lt;/h3&gt; 
&lt;p&gt;By default, &lt;code&gt;deepagents&lt;/code&gt; uses &lt;code&gt;"claude-sonnet-4-5-20250929"&lt;/code&gt;. You can customize this by passing any &lt;a href="https://python.langchain.com/docs/integrations/chat/"&gt;LangChain model object&lt;/a&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from langchain.chat_models import init_chat_model
from deepagents import create_deep_agent

model = init_chat_model("openai:gpt-4o")
agent = create_deep_agent(
    model=model,
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;&lt;code&gt;system_prompt&lt;/code&gt;&lt;/h3&gt; 
&lt;p&gt;Deep Agents come with a built-in system prompt. This is relatively detailed prompt that is heavily based on and inspired by &lt;a href="https://github.com/kn1026/cc/raw/main/claudecode.md"&gt;attempts&lt;/a&gt; to &lt;a href="https://github.com/asgeirtj/system_prompts_leaks/raw/main/Anthropic/claude-code.md"&gt;replicate&lt;/a&gt; Claude Code's system prompt. It was made more general purpose than Claude Code's system prompt. The default prompt contains detailed instructions for how to use the built-in planning tool, file system tools, and sub agents.&lt;/p&gt; 
&lt;p&gt;Each deep agent tailored to a use case should include a custom system prompt specific to that use case as well. The importance of prompting for creating a successful deep agent cannot be overstated.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from deepagents import create_deep_agent

research_instructions = """You are an expert researcher. Your job is to conduct thorough research, and then write a polished report.
"""

agent = create_deep_agent(
    system_prompt=research_instructions,
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;&lt;code&gt;tools&lt;/code&gt;&lt;/h3&gt; 
&lt;p&gt;Just like with tool-calling agents, you can provide a deep agent with a set of tools that it has access to.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import os
from typing import Literal
from tavily import TavilyClient
from deepagents import create_deep_agent

tavily_client = TavilyClient(api_key=os.environ["TAVILY_API_KEY"])

def internet_search(
    query: str,
    max_results: int = 5,
    topic: Literal["general", "news", "finance"] = "general",
    include_raw_content: bool = False,
):
    """Run a web search"""
    return tavily_client.search(
        query,
        max_results=max_results,
        include_raw_content=include_raw_content,
        topic=topic,
    )

agent = create_deep_agent(
    tools=[internet_search]
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;&lt;code&gt;middleware&lt;/code&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;create_deep_agent&lt;/code&gt; is implemented with middleware that can be customized. You can provide additional middleware to extend functionality, add tools, or implement custom hooks.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from langchain_core.tools import tool
from deepagents import create_deep_agent
from langchain.agents.middleware import AgentMiddleware

@tool
def get_weather(city: str) -&amp;gt; str:
    """Get the weather in a city."""
    return f"The weather in {city} is sunny."

@tool
def get_temperature(city: str) -&amp;gt; str:
    """Get the temperature in a city."""
    return f"The temperature in {city} is 70 degrees Fahrenheit."

class WeatherMiddleware(AgentMiddleware):
  tools = [get_weather, get_temperature]

agent = create_deep_agent(
    model="anthropic:claude-sonnet-4-20250514",
    middleware=[WeatherMiddleware()]
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;&lt;code&gt;subagents&lt;/code&gt;&lt;/h3&gt; 
&lt;p&gt;A main feature of Deep Agents is their ability to spawn subagents. You can specify custom subagents that your agent can hand off work to in the subagents parameter. Sub agents are useful for context quarantine (to help not pollute the overall context of the main agent) as well as custom instructions.&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;subagents&lt;/code&gt; should be a list of dictionaries, where each dictionary follow this schema:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;class SubAgent(TypedDict):
    name: str
    description: str
    prompt: str
    tools: Sequence[BaseTool | Callable | dict[str, Any]]
    model: NotRequired[str | BaseChatModel]
    middleware: NotRequired[list[AgentMiddleware]]
    interrupt_on: NotRequired[dict[str, bool | InterruptOnConfig]]

class CompiledSubAgent(TypedDict):
    name: str
    description: str
    runnable: Runnable
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;SubAgent fields:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;name&lt;/strong&gt;: This is the name of the subagent, and how the main agent will call the subagent&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;description&lt;/strong&gt;: This is the description of the subagent that is shown to the main agent&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;prompt&lt;/strong&gt;: This is the prompt used for the subagent&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;tools&lt;/strong&gt;: This is the list of tools that the subagent has access to.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;model&lt;/strong&gt;: Optional model name or model instance.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;middleware&lt;/strong&gt; Additional middleware to attach to the subagent. See &lt;a href="https://docs.langchain.com/oss/python/langchain/middleware"&gt;here&lt;/a&gt; for an introduction into middleware and how it works with create_agent.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;interrupt_on&lt;/strong&gt; A custom interrupt config that specifies human-in-the-loop interactions for your tools.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;CompiledSubAgent fields:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;name&lt;/strong&gt;: This is the name of the subagent, and how the main agent will call the subagent&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;description&lt;/strong&gt;: This is the description of the subagent that is shown to the main agent&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;runnable&lt;/strong&gt;: A pre-built LangGraph graph/agent that will be used as the subagent&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Using SubAgent&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import os
from typing import Literal
from tavily import TavilyClient
from deepagents import create_deep_agent

tavily_client = TavilyClient(api_key=os.environ["TAVILY_API_KEY"])

def internet_search(
    query: str,
    max_results: int = 5,
    topic: Literal["general", "news", "finance"] = "general",
    include_raw_content: bool = False,
):
    """Run a web search"""
    return tavily_client.search(
        query,
        max_results=max_results,
        include_raw_content=include_raw_content,
        topic=topic,
    )

research_subagent = {
    "name": "research-agent",
    "description": "Used to research more in depth questions",
    "system_prompt": "You are a great researcher",
    "tools": [internet_search],
    "model": "openai:gpt-4o",  # Optional override, defaults to main agent model
}
subagents = [research_subagent]

agent = create_deep_agent(
    model="anthropic:claude-sonnet-4-20250514",
    subagents=subagents
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Using CustomSubAgent&lt;/h4&gt; 
&lt;p&gt;For more complex use cases, you can provide your own pre-built LangGraph graph as a subagent:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# Create a custom agent graph
custom_graph = create_agent(
    model=your_model,
    tools=specialized_tools,
    prompt="You are a specialized agent for data analysis..."
)

# Use it as a custom subagent
custom_subagent = CompiledSubAgent(
    name="data-analyzer",
    description="Specialized agent for complex data analysis tasks",
    runnable=custom_graph
)

subagents = [custom_subagent]

agent = create_deep_agent(
    model="anthropic:claude-sonnet-4-20250514",
    tools=[internet_search],
    system_prompt=research_instructions,
    subagents=subagents
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;&lt;code&gt;interrupt_on&lt;/code&gt;&lt;/h3&gt; 
&lt;p&gt;A common reality for agents is that some tool operations may be sensitive and require human approval before execution. Deep Agents supports human-in-the-loop workflows through LangGraph‚Äôs interrupt capabilities. You can configure which tools require approval using a checkpointer.&lt;/p&gt; 
&lt;p&gt;These tool configs are passed to our prebuilt &lt;a href="https://docs.langchain.com/oss/python/langchain/middleware#human-in-the-loop"&gt;HITL middleware&lt;/a&gt; so that the agent pauses execution and waits for feedback from the user before executing configured tools.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from langchain_core.tools import tool
from deepagents import create_deep_agent

@tool
def get_weather(city: str) -&amp;gt; str:
    """Get the weather in a city."""
    return f"The weather in {city} is sunny."

agent = create_deep_agent(
    model="anthropic:claude-sonnet-4-20250514",
    tools=[get_weather],
    interrupt_on={
        "get_weather": {
            "allowed_decisions": ["approve", "edit", "reject"]
        },
    }
)

&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Deep Agents Middleware&lt;/h2&gt; 
&lt;p&gt;Deep Agents are built with a modular middleware architecture. As a reminder, Deep Agents have access to:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;A planning tool&lt;/li&gt; 
 &lt;li&gt;A filesystem for storing context and long-term memories&lt;/li&gt; 
 &lt;li&gt;The ability to spawn subagents&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Each of these features is implemented as separate middleware. When you create a deep agent with &lt;code&gt;create_deep_agent&lt;/code&gt;, we automatically attach &lt;strong&gt;TodoListMiddleware&lt;/strong&gt;, &lt;strong&gt;FilesystemMiddleware&lt;/strong&gt; and &lt;strong&gt;SubAgentMiddleware&lt;/strong&gt; to your agent.&lt;/p&gt; 
&lt;p&gt;Middleware is a composable concept, and you can choose to add as many or as few middleware to an agent depending on your use case. That means that you can also use any of the aforementioned middleware independently!&lt;/p&gt; 
&lt;h3&gt;TodoListMiddleware&lt;/h3&gt; 
&lt;p&gt;Planning is integral to solving complex problems. If you‚Äôve used claude code recently, you‚Äôll notice how it writes out a To-Do list before tackling complex, multi-part tasks. You‚Äôll also notice how it can adapt and update this To-Do list on the fly as more information comes in.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;TodoListMiddleware&lt;/strong&gt; provides your agent with a tool specifically for updating this To-Do list. Before, and while it executes a multi-part task, the agent is prompted to use the write_todos tool to keep track of what its doing, and what still needs to be done.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from langchain.agents import create_agent
from langchain.agents.middleware import TodoListMiddleware

# TodoListMiddleware is included by default in create_deep_agent
# You can customize it if building a custom agent
agent = create_agent(
    model="anthropic:claude-sonnet-4-20250514",
    # Custom planning instructions can be added via middleware
    middleware=[
        TodoListMiddleware(
            system_prompt="Use the write_todos tool to..."  # Optional: Custom addition to the system prompt
        ),
    ],
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;FilesystemMiddleware&lt;/h3&gt; 
&lt;p&gt;Context engineering is one of the main challenges in building effective agents. This can be particularly hard when using tools that can return variable length results (ex. web_search, rag), as long ToolResults can quickly fill up your context window. &lt;strong&gt;FilesystemMiddleware&lt;/strong&gt; provides four tools to your agent to interact with both short-term and long-term memory.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;ls&lt;/strong&gt;: List the files in your filesystem&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;read_file&lt;/strong&gt;: Read an entire file, or a certain number of lines from a file&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;write_file&lt;/strong&gt;: Write a new file to your filesystem&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;edit_file&lt;/strong&gt;: Edit an existing file in your filesystem&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from langchain.agents import create_agent
from deepagents.middleware.filesystem import FilesystemMiddleware


# FilesystemMiddleware is included by default in create_deep_agent
# You can customize it if building a custom agent
agent = create_agent(
    model="anthropic:claude-sonnet-4-20250514",
    middleware=[
        FilesystemMiddleware(
            backend=..., # Optional: customize storage backend
            system_prompt="Write to the filesystem when...",  # Optional custom system prompt override
            custom_tool_descriptions={
                "ls": "Use the ls tool when...",
                "read_file": "Use the read_file tool to..."
            }  # Optional: Custom descriptions for filesystem tools
        ),
    ],
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;SubAgentMiddleware&lt;/h3&gt; 
&lt;p&gt;Handing off tasks to subagents is a great way to isolate context, keeping the context window of the main (supervisor) agent clean while still going deep on a task. The subagents middleware allows you supply subagents through a task tool.&lt;/p&gt; 
&lt;p&gt;A subagent is defined with a name, description, system prompt, and tools. You can also provide a subagent with a custom model, or with additional middleware. This can be particularly useful when you want to give the subagent an additional state key to share with the main agent.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from langchain_core.tools import tool
from langchain.agents import create_agent
from deepagents.middleware.subagents import SubAgentMiddleware


@tool
def get_weather(city: str) -&amp;gt; str:
    """Get the weather in a city."""
    return f"The weather in {city} is sunny."

agent = create_agent(
    model="claude-sonnet-4-20250514",
    middleware=[
        SubAgentMiddleware(
            default_model="claude-sonnet-4-20250514",
            default_tools=[],
            subagents=[
                {
                    "name": "weather",
                    "description": "This subagent can get weather in cities.",
                    "system_prompt": "Use the get_weather tool to get the weather in a city.",
                    "tools": [get_weather],
                    "model": "gpt-4.1",
                    "middleware": [],
                }
            ],
        )
    ],
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For more complex use cases, you can also provide your own pre-built LangGraph graph as a subagent.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# Create a custom LangGraph graph
def create_weather_graph():
    workflow = StateGraph(...)
    # Build your custom graph
    return workflow.compile()

weather_graph = create_weather_graph()

# Wrap it in a CompiledSubAgent
weather_subagent = CompiledSubAgent(
    name="weather",
    description="This subagent can get weather in cities.",
    runnable=weather_graph
)

agent = create_agent(
    model="anthropic:claude-sonnet-4-20250514",
    middleware=[
        SubAgentMiddleware(
            default_model="claude-sonnet-4-20250514",
            default_tools=[],
            subagents=[weather_subagent],
        )
    ],
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Sync vs Async&lt;/h2&gt; 
&lt;p&gt;Prior versions of deepagents separated sync and async agent factories.&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;async_create_deep_agent&lt;/code&gt; has been folded in to &lt;code&gt;create_deep_agent&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;You should use &lt;code&gt;create_deep_agent&lt;/code&gt; as the factory for both sync and async agents&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;MCP&lt;/h2&gt; 
&lt;p&gt;The &lt;code&gt;deepagents&lt;/code&gt; library can be ran with MCP tools. This can be achieved by using the &lt;a href="https://github.com/langchain-ai/langchain-mcp-adapters"&gt;Langchain MCP Adapter library&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;NOTE:&lt;/strong&gt; You will want to use &lt;code&gt;from deepagents import async_create_deep_agent&lt;/code&gt; to use the async version of &lt;code&gt;deepagents&lt;/code&gt;, since MCP tools are async&lt;/p&gt; 
&lt;p&gt;(To run the example below, will need to &lt;code&gt;pip install langchain-mcp-adapters&lt;/code&gt;)&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import asyncio
from langchain_mcp_adapters.client import MultiServerMCPClient
from deepagents import create_deep_agent

async def main():
    # Collect MCP tools
    mcp_client = MultiServerMCPClient(...)
    mcp_tools = await mcp_client.get_tools()

    # Create agent
    agent = create_deep_agent(tools=mcp_tools, ....)

    # Stream the agent
    async for chunk in agent.astream(
        {"messages": [{"role": "user", "content": "what is langgraph?"}]},
        stream_mode="values"
    ):
        if "messages" in chunk:
            chunk["messages"][-1].pretty_print()

asyncio.run(main())
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>vnpy/vnpy</title>
      <link>https://github.com/vnpy/vnpy</link>
      <description>&lt;p&gt;Âü∫‰∫éPythonÁöÑÂºÄÊ∫êÈáèÂåñ‰∫§ÊòìÂπ≥Âè∞ÂºÄÂèëÊ°ÜÊû∂&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;VeighNa - By Traders, For Traders, AI-Powered.&lt;/h1&gt; 
&lt;p align="center"&gt; &lt;img src="https://vnpy.oss-cn-shanghai.aliyuncs.com/veighna-logo.png" /&gt; &lt;/p&gt; 
&lt;p&gt;üí¨ Want to read this in &lt;strong&gt;english&lt;/strong&gt; ? Go &lt;a href="https://raw.githubusercontent.com/vnpy/vnpy/master/README_ENG.md"&gt;&lt;strong&gt;here&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://img.shields.io/badge/version-4.2.0-blueviolet.svg?sanitize=true" /&gt; &lt;img src="https://img.shields.io/badge/platform-windows|linux|macos-yellow.svg" /&gt; &lt;img src="https://img.shields.io/badge/python-3.10|3.11|3.12|3.13-blue.svg" /&gt; &lt;img src="https://img.shields.io/github/actions/workflow/status/vnpy/vnpy/pythonapp.yml?branch=master" /&gt; &lt;img src="https://img.shields.io/github/license/vnpy/vnpy.svg?color=orange" /&gt; &lt;/p&gt; 
&lt;p&gt;VeighNaÊòØ‰∏ÄÂ•óÂü∫‰∫éPythonÁöÑÂºÄÊ∫êÈáèÂåñ‰∫§ÊòìÁ≥ªÁªüÂºÄÂèëÊ°ÜÊû∂ÔºåÂú®ÂºÄÊ∫êÁ§æÂå∫ÊåÅÁª≠‰∏çÊñ≠ÁöÑË¥°ÁåÆ‰∏ã‰∏ÄÊ≠•Ê≠•ÊàêÈïø‰∏∫Â§öÂäüËÉΩÈáèÂåñ‰∫§ÊòìÂπ≥Âè∞ÔºåËá™ÂèëÂ∏É‰ª•Êù•Â∑≤ÁªèÁßØÁ¥Ø‰∫Ü‰ºóÂ§öÊù•Ëá™ÈáëËûçÊú∫ÊûÑÊàñÁõ∏ÂÖ≥È¢ÜÂüüÁöÑÁî®Êà∑ÔºåÂåÖÊã¨ÁßÅÂãüÂü∫Èáë„ÄÅËØÅÂà∏ÂÖ¨Âè∏„ÄÅÊúüË¥ßÂÖ¨Âè∏Á≠â„ÄÇ&lt;/p&gt; 
&lt;p&gt;Âú®‰ΩøÁî®VeighNaËøõË°å‰∫åÊ¨°ÂºÄÂèëÔºàÁ≠ñÁï•„ÄÅÊ®°ÂùóÁ≠âÔºâÁöÑËøáÁ®ã‰∏≠Êúâ‰ªª‰ΩïÁñëÈóÆÔºåËØ∑Êü•Áúã&lt;a href="https://www.vnpy.com/docs/cn/index.html"&gt;&lt;strong&gt;VeighNaÈ°πÁõÆÊñáÊ°£&lt;/strong&gt;&lt;/a&gt;ÔºåÂ¶ÇÊûúÊó†Ê≥ïËß£ÂÜ≥ËØ∑ÂâçÂæÄ&lt;a href="https://www.vnpy.com/forum/"&gt;&lt;strong&gt;ÂÆòÊñπÁ§æÂå∫ËÆ∫Âùõ&lt;/strong&gt;&lt;/a&gt;ÁöÑ„ÄêÊèêÈóÆÊ±ÇÂä©„ÄëÊùøÂùóÂØªÊ±ÇÂ∏ÆÂä©Ôºå‰πüÊ¨¢ËøéÂú®„ÄêÁªèÈ™åÂàÜ‰∫´„ÄëÊùøÂùóÂàÜ‰∫´‰Ω†ÁöÑ‰ΩøÁî®ÂøÉÂæóÔºÅ&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;ÊÉ≥Ë¶ÅËé∑ÂèñÊõ¥Â§öÂÖ≥‰∫éVeighNaÁöÑËµÑËÆØ‰ø°ÊÅØÔºü&lt;/strong&gt; ËØ∑Êâ´Êèè‰∏ãÊñπ‰∫åÁª¥Á†ÅÊ∑ªÂä†Â∞èÂä©ÊâãÂä†ÂÖ•„ÄêVeighNaÁ§æÂå∫‰∫§ÊµÅÂæÆ‰ø°Áæ§„ÄëÔºö&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://vnpy.oss-cn-shanghai.aliyuncs.com/github_wx.png" , width="250" /&gt; &lt;/p&gt; 
&lt;h2&gt;AI-Powered&lt;/h2&gt; 
&lt;p&gt;VeighNaÂèëÂ∏ÉÂçÅÂë®Âπ¥‰πãÈôÖÊ≠£ÂºèÊé®Âá∫4.0ÁâàÊú¨ÔºåÈáçÁ£ÖÊñ∞Â¢ûÈù¢ÂêëAIÈáèÂåñÁ≠ñÁï•ÁöÑ&lt;a href="https://raw.githubusercontent.com/vnpy/vnpy/master/vnpy/alpha"&gt;vnpy.alpha&lt;/a&gt;Ê®°ÂùóÔºå‰∏∫‰∏ì‰∏öÈáèÂåñ‰∫§ÊòìÂëòÊèê‰æõ&lt;strong&gt;‰∏ÄÁ´ôÂºèÂ§öÂõ†Â≠êÊú∫Âô®Â≠¶‰π†ÔºàMLÔºâÁ≠ñÁï•ÂºÄÂèë„ÄÅÊäïÁ†îÂíåÂÆûÁõò‰∫§ÊòìËß£ÂÜ≥ÊñπÊ°à&lt;/strong&gt;Ôºö&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://vnpy.oss-cn-shanghai.aliyuncs.com/alpha_demo.jpg" , width="500" /&gt; &lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;üìä&lt;/span&gt; &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/vnpy/vnpy/master/vnpy/alpha/dataset"&gt;dataset&lt;/a&gt;&lt;/strong&gt;ÔºöÂõ†Â≠êÁâπÂæÅÂ∑•Á®ã&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;‰∏ì‰∏∫MLÁÆóÊ≥ïËÆ≠ÁªÉ‰ºòÂåñËÆæËÆ°ÔºåÊîØÊåÅÈ´òÊïàÊâπÈáèÁâπÂæÅËÆ°ÁÆó‰∏éÂ§ÑÁêÜ&lt;/li&gt; 
   &lt;li&gt;ÂÜÖÁΩÆ‰∏∞ÂØåÁöÑÂõ†Â≠êÁâπÂæÅË°®ËææÂºèËÆ°ÁÆóÂºïÊìéÔºåÂÆûÁé∞Âø´ÈÄü‰∏ÄÈîÆÁîüÊàêËÆ≠ÁªÉÊï∞ÊçÆ&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/vnpy/vnpy/master/vnpy/alpha/dataset/datasets/alpha_158.py"&gt;Alpha 158&lt;/a&gt;ÔºöÊ∫ê‰∫éÂæÆËΩØQlibÈ°πÁõÆÁöÑËÇ°Á•®Â∏ÇÂú∫ÁâπÂæÅÈõÜÂêàÔºåÊ∂µÁõñKÁ∫øÂΩ¢ÊÄÅ„ÄÅ‰ª∑Ê†ºË∂ãÂäø„ÄÅÊó∂Â∫èÊ≥¢Âä®Á≠âÂ§öÁª¥Â∫¶ÈáèÂåñÂõ†Â≠ê&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;üí°&lt;/span&gt; &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/vnpy/vnpy/master/vnpy/alpha/model"&gt;model&lt;/a&gt;&lt;/strong&gt;ÔºöÈ¢ÑÊµãÊ®°ÂûãËÆ≠ÁªÉ&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Êèê‰æõÊ†áÂáÜÂåñÁöÑMLÊ®°ÂûãÂºÄÂèëÊ®°ÊùøÔºåÂ§ßÂπÖÁÆÄÂåñÊ®°ÂûãÊûÑÂª∫‰∏éËÆ≠ÁªÉÊµÅÁ®ã&lt;/li&gt; 
   &lt;li&gt;Áªü‰∏ÄAPIÊé•Âè£ËÆæËÆ°ÔºåÊîØÊåÅÊó†ÁºùÂàáÊç¢‰∏çÂêåÁÆóÊ≥ïËøõË°åÊÄßËÉΩÂØπÊØîÊµãËØï&lt;/li&gt; 
   &lt;li&gt;ÈõÜÊàêÂ§öÁßç‰∏ªÊµÅÊú∫Âô®Â≠¶‰π†ÁÆóÊ≥ïÔºö 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/vnpy/vnpy/master/vnpy/alpha/model/models/lasso_model.py"&gt;Lasso&lt;/a&gt;ÔºöÁªèÂÖ∏LassoÂõûÂΩíÊ®°ÂûãÔºåÈÄöËøáL1Ê≠£ÂàôÂåñÂÆûÁé∞ÁâπÂæÅÈÄâÊã©&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/vnpy/vnpy/master/vnpy/alpha/model/models/lgb_model.py"&gt;LightGBM&lt;/a&gt;ÔºöÈ´òÊïàÊ¢ØÂ∫¶ÊèêÂçáÂÜ≥Á≠ñÊ†ëÔºåÈíàÂØπÂ§ßËßÑÊ®°Êï∞ÊçÆÈõÜ‰ºòÂåñÁöÑËÆ≠ÁªÉÂºïÊìé&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/vnpy/vnpy/master/vnpy/alpha/model/models/mlp_model.py"&gt;MLP&lt;/a&gt;ÔºöÂ§öÂ±ÇÊÑüÁü•Êú∫Á•ûÁªèÁΩëÁªúÔºåÈÄÇÁî®‰∫éÂ§çÊùÇÈùûÁ∫øÊÄßÂÖ≥Á≥ªÂª∫Ê®°&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;ü§ñ&lt;/span&gt; &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/vnpy/vnpy/master/vnpy/alpha/strategy"&gt;strategy&lt;/a&gt;&lt;/strong&gt;ÔºöÁ≠ñÁï•ÊäïÁ†îÂºÄÂèë&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Âü∫‰∫éML‰ø°Âè∑È¢ÑÊµãÊ®°ÂûãÂø´ÈÄüÊûÑÂª∫ÈáèÂåñ‰∫§ÊòìÁ≠ñÁï•&lt;/li&gt; 
   &lt;li&gt;ÊîØÊåÅÊà™Èù¢Â§öÊ†áÁöÑÂíåÊó∂Â∫èÂçïÊ†áÁöÑ‰∏§ÁßçÁ≠ñÁï•Á±ªÂûã&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;üî¨&lt;/span&gt; &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/vnpy/vnpy/master/vnpy/alpha/lab.py"&gt;lab&lt;/a&gt;&lt;/strong&gt;ÔºöÊäïÁ†îÊµÅÁ®ãÁÆ°ÁêÜ&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;ÈõÜÊàêÊï∞ÊçÆÁÆ°ÁêÜ„ÄÅÊ®°ÂûãËÆ≠ÁªÉ„ÄÅ‰ø°Âè∑ÁîüÊàêÂíåÁ≠ñÁï•ÂõûÊµãÁ≠âÂÆåÊï¥Â∑•‰ΩúÊµÅÁ®ã&lt;/li&gt; 
   &lt;li&gt;ÁÆÄÊ¥ÅAPIËÆæËÆ°ÔºåÂÜÖÁΩÆÂèØËßÜÂåñÂàÜÊûêÂ∑•ÂÖ∑ÔºåÁõ¥ËßÇËØÑ‰º∞Á≠ñÁï•Ë°®Áé∞ÂíåÊ®°ÂûãÊïàÊûú&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;üìñ&lt;/span&gt; &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/vnpy/vnpy/master/examples/alpha_research"&gt;notebook&lt;/a&gt;&lt;/strong&gt;ÔºöÈáèÂåñÊäïÁ†îDemo&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/vnpy/vnpy/master/examples/alpha_research/download_data_rq.ipynb"&gt;download_data_rq&lt;/a&gt;ÔºöÂü∫‰∫éRQData‰∏ãËΩΩAËÇ°ÊåáÊï∞ÊàêÂàÜËÇ°Êï∞ÊçÆÔºåÂåÖÂê´ÊåáÊï∞ÊàêÂàÜÂèòÂåñË∑üË∏™ÂèäÂéÜÂè≤Ë°åÊÉÖËé∑Âèñ&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/vnpy/vnpy/master/examples/alpha_research/download_data_xt.ipynb"&gt;download_data_xt&lt;/a&gt;ÔºöÂü∫‰∫éËøÖÊäïÁ†îÊï∞ÊçÆÊúçÂä°Ôºå‰∏ãËΩΩËé∑ÂèñAËÇ°ÊåáÊï∞ÊàêÂàÜÂéÜÂè≤ÂèòÂåñÂíåËÇ°Á•®KÁ∫øÊï∞ÊçÆ&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/vnpy/vnpy/master/examples/alpha_research/research_workflow_lasso.ipynb"&gt;research_workflow_lasso&lt;/a&gt;ÔºöÂü∫‰∫éLassoÂõûÂΩíÊ®°ÂûãÁöÑÈáèÂåñÊäïÁ†îÂ∑•‰ΩúÊµÅÔºåÂ±ïÁ§∫Á∫øÊÄßÊ®°ÂûãÁâπÂæÅÈÄâÊã©‰∏éÈ¢ÑÊµãËÉΩÂäõ&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/vnpy/vnpy/master/examples/alpha_research/research_workflow_lgb.ipynb"&gt;research_workflow_lgb&lt;/a&gt;ÔºöÂü∫‰∫éLightGBMÊ¢ØÂ∫¶ÊèêÂçáÊ†ëÁöÑÈáèÂåñÊäïÁ†îÂ∑•‰ΩúÊµÅÔºåÂà©Áî®È´òÊïàÈõÜÊàêÂ≠¶‰π†ÊñπÊ≥ïËøõË°åÈ¢ÑÊµã&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/vnpy/vnpy/master/examples/alpha_research/research_workflow_mlp.ipynb"&gt;research_workflow_mlp&lt;/a&gt;ÔºöÂü∫‰∫éÂ§öÂ±ÇÊÑüÁü•Êú∫Á•ûÁªèÁΩëÁªúÁöÑÈáèÂåñÊäïÁ†îÂ∑•‰ΩúÊµÅÔºåÂ±ïÁ§∫Ê∑±Â∫¶Â≠¶‰π†Âú®ÈáèÂåñ‰∫§Êòì‰∏≠ÁöÑÂ∫îÁî®&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;vnpy.alphaÊ®°ÂùóÁöÑËÆæËÆ°ÁêÜÂøµÂèóÂà∞&lt;a href="https://github.com/microsoft/qlib"&gt;Qlib&lt;/a&gt;È°πÁõÆÁöÑÂêØÂèëÔºåÂú®‰øùÊåÅÊòìÁî®ÊÄßÁöÑÂêåÊó∂Êèê‰æõÂº∫Â§ßÁöÑAIÈáèÂåñËÉΩÂäõÔºåÁâπÊ≠§ÂêëQlibÂºÄÂèëÂõ¢ÈòüËá¥‰ª•ËØöÊåöÊÑüË∞¢ÔºÅ&lt;/p&gt; 
&lt;h2&gt;ÂäüËÉΩÁâπÁÇπ&lt;/h2&gt; 
&lt;p&gt;Â∏¶Êúâ &lt;span&gt;‚¨Ü&lt;/span&gt; ÁöÑÊ®°Âùó‰ª£Ë°®Â∑≤ÁªèÂÆåÊàê4.0ÁâàÊú¨ÁöÑÂçáÁ∫ßÈÄÇÈÖçÊµãËØïÔºåÂêåÊó∂4.0Ê†∏ÂøÉÊ°ÜÊû∂ÈááÁî®‰∫Ü‰ºòÂÖà‰øùËØÅÂÖºÂÆπÊÄßÁöÑÂçáÁ∫ßÊñπÂºèÔºåÂõ†Ê≠§Â§ßÂ§öÊï∞Ê®°Âùó‰πüÈÉΩÂèØ‰ª•Áõ¥Êé•‰ΩøÁî®ÔºàÊ∂âÂèäÂà∞C++ APIÂ∞ÅË£ÖÁöÑÊé•Âè£ÂøÖÈ°ªÂçáÁ∫ßÂêéÊâçËÉΩ‰ΩøÁî®Ôºâ„ÄÇ&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;‚¨Ü&lt;/span&gt; Â§öÂäüËÉΩÈáèÂåñ‰∫§ÊòìÂπ≥Âè∞ÔºàtraderÔºâÔºåÊï¥Âêà‰∫ÜÂ§öÁßç‰∫§ÊòìÊé•Âè£ÔºåÂπ∂ÈíàÂØπÂÖ∑‰ΩìÁ≠ñÁï•ÁÆóÊ≥ïÂíåÂäüËÉΩÂºÄÂèëÊèê‰æõ‰∫ÜÁÆÄÊ¥ÅÊòìÁî®ÁöÑAPIÔºåÁî®‰∫éÂø´ÈÄüÊûÑÂª∫‰∫§ÊòìÂëòÊâÄÈúÄÁöÑÈáèÂåñ‰∫§ÊòìÂ∫îÁî®„ÄÇ&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Ë¶ÜÁõñÂõΩÂÜÖÂ§ñÊâÄÊã•ÊúâÁöÑ‰∏ãËø∞‰∫§ÊòìÂìÅÁßçÁöÑ‰∫§ÊòìÊé•Âè£ÔºàgatewayÔºâÔºö&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;ÂõΩÂÜÖÂ∏ÇÂú∫&lt;/p&gt; 
    &lt;ul&gt; 
     &lt;li&gt; &lt;p&gt;&lt;span&gt;‚¨Ü&lt;/span&gt; CTPÔºà&lt;a href="https://www.github.com/vnpy/vnpy_ctp"&gt;ctp&lt;/a&gt;ÔºâÔºöÂõΩÂÜÖÊúüË¥ß„ÄÅÊúüÊùÉ&lt;/p&gt; &lt;/li&gt; 
     &lt;li&gt; &lt;p&gt;&lt;span&gt;‚¨Ü&lt;/span&gt; CTP MiniÔºà&lt;a href="https://www.github.com/vnpy/vnpy_mini"&gt;mini&lt;/a&gt;ÔºâÔºöÂõΩÂÜÖÊúüË¥ß„ÄÅÊúüÊùÉ&lt;/p&gt; &lt;/li&gt; 
     &lt;li&gt; &lt;p&gt;&lt;span&gt;‚¨Ü&lt;/span&gt; CTPËØÅÂà∏Ôºà&lt;a href="https://www.github.com/vnpy/vnpy_sopt"&gt;sopt&lt;/a&gt;ÔºâÔºöETFÊúüÊùÉ&lt;/p&gt; &lt;/li&gt; 
     &lt;li&gt; &lt;p&gt;&lt;span&gt;‚¨Ü&lt;/span&gt; È£ûÈ©¨Ôºà&lt;a href="https://www.github.com/vnpy/vnpy_femas"&gt;femas&lt;/a&gt;ÔºâÔºöÂõΩÂÜÖÊúüË¥ß&lt;/p&gt; &lt;/li&gt; 
     &lt;li&gt; &lt;p&gt;&lt;span&gt;‚¨Ü&lt;/span&gt; ÊÅíÁîüUFTÔºà&lt;a href="https://www.github.com/vnpy/vnpy_uft"&gt;uft&lt;/a&gt;ÔºâÔºöÂõΩÂÜÖÊúüË¥ß„ÄÅETFÊúüÊùÉ&lt;/p&gt; &lt;/li&gt; 
     &lt;li&gt; &lt;p&gt;ÊòìÁõõÔºà&lt;a href="https://www.github.com/vnpy/vnpy_esunny"&gt;esunny&lt;/a&gt;ÔºâÔºöÂõΩÂÜÖÊúüË¥ß„ÄÅÈªÑÈáëTD&lt;/p&gt; &lt;/li&gt; 
     &lt;li&gt; &lt;p&gt;&lt;span&gt;‚¨Ü&lt;/span&gt; È°∂ÁÇπHTSÔºà&lt;a href="https://www.github.com/vnpy/vnpy_hts"&gt;hts&lt;/a&gt;ÔºâÔºöETFÊúüÊùÉ&lt;/p&gt; &lt;/li&gt; 
     &lt;li&gt; &lt;p&gt;&lt;span&gt;‚¨Ü&lt;/span&gt; ‰∏≠Ê≥∞XTPÔºà&lt;a href="https://www.github.com/vnpy/vnpy_xtp"&gt;xtp&lt;/a&gt;ÔºâÔºöÂõΩÂÜÖËØÅÂà∏ÔºàAËÇ°Ôºâ„ÄÅETFÊúüÊùÉ&lt;/p&gt; &lt;/li&gt; 
     &lt;li&gt; &lt;p&gt;&lt;span&gt;‚¨Ü&lt;/span&gt; ÂçéÈë´Â•áÁÇπÔºà&lt;a href="https://www.github.com/vnpy/vnpy_tora"&gt;tora&lt;/a&gt;ÔºâÔºöÂõΩÂÜÖËØÅÂà∏ÔºàAËÇ°Ôºâ„ÄÅETFÊúüÊùÉ&lt;/p&gt; &lt;/li&gt; 
     &lt;li&gt; &lt;p&gt;‰∏úËØÅOSTÔºà&lt;a href="https://www.github.com/vnpy/vnpy_ost"&gt;ost&lt;/a&gt;ÔºâÔºöÂõΩÂÜÖËØÅÂà∏ÔºàAËÇ°Ôºâ&lt;/p&gt; &lt;/li&gt; 
     &lt;li&gt; &lt;p&gt;‰∏úÊñπË¥¢ÂØåEMTÔºà&lt;a href="https://www.github.com/vnpy/vnpy_emt"&gt;emt&lt;/a&gt;ÔºâÔºöÂõΩÂÜÖËØÅÂà∏ÔºàAËÇ°Ôºâ&lt;/p&gt; &lt;/li&gt; 
     &lt;li&gt; &lt;p&gt;È£ûÈº†Ôºà&lt;a href="https://www.github.com/vnpy/vnpy_sgit"&gt;sgit&lt;/a&gt;ÔºâÔºöÈªÑÈáëTD„ÄÅÂõΩÂÜÖÊúüË¥ß&lt;/p&gt; &lt;/li&gt; 
     &lt;li&gt; &lt;p&gt;&lt;span&gt;‚¨Ü&lt;/span&gt; Èáë‰ªïËææÈªÑÈáëÔºà&lt;a href="https://www.github.com/vnpy/vnpy_ksgold"&gt;ksgold&lt;/a&gt;ÔºâÔºöÈªÑÈáëTD&lt;/p&gt; &lt;/li&gt; 
     &lt;li&gt; &lt;p&gt;&lt;span&gt;‚¨Ü&lt;/span&gt; Âà©ÊòüËµÑÁÆ°Ôºà&lt;a href="https://www.github.com/vnpy/vnpy_lstar"&gt;lstar&lt;/a&gt;ÔºâÔºöÊúüË¥ßËµÑÁÆ°&lt;/p&gt; &lt;/li&gt; 
     &lt;li&gt; &lt;p&gt;&lt;span&gt;‚¨Ü&lt;/span&gt; ËûçËà™Ôºà&lt;a href="https://www.github.com/vnpy/vnpy_rohon"&gt;rohon&lt;/a&gt;ÔºâÔºöÊúüË¥ßËµÑÁÆ°&lt;/p&gt; &lt;/li&gt; 
     &lt;li&gt; &lt;p&gt;&lt;span&gt;‚¨Ü&lt;/span&gt; Êù∞ÂÆúÊñØÔºà&lt;a href="https://www.github.com/vnpy/vnpy_jees"&gt;jees&lt;/a&gt;ÔºâÔºöÊúüË¥ßËµÑÁÆ°&lt;/p&gt; &lt;/li&gt; 
     &lt;li&gt; &lt;p&gt;‰∏≠Ê±á‰∫øËææÔºà&lt;a href="https://www.github.com/vnpy/vnpy_comstar"&gt;comstar&lt;/a&gt;ÔºâÔºöÈì∂Ë°åÈó¥Â∏ÇÂú∫&lt;/p&gt; &lt;/li&gt; 
     &lt;li&gt; &lt;p&gt;&lt;span&gt;‚¨Ü&lt;/span&gt; TTSÔºà&lt;a href="https://www.github.com/vnpy/vnpy_tts"&gt;tts&lt;/a&gt;ÔºâÔºöÂõΩÂÜÖÊúüË¥ßÔºà‰ªøÁúüÔºâ&lt;/p&gt; &lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;Êµ∑Â§ñÂ∏ÇÂú∫&lt;/p&gt; 
    &lt;ul&gt; 
     &lt;li&gt; &lt;p&gt;&lt;span&gt;‚¨Ü&lt;/span&gt; Interactive BrokersÔºà&lt;a href="https://www.github.com/vnpy/vnpy_ib"&gt;ib&lt;/a&gt;ÔºâÔºöÊµ∑Â§ñËØÅÂà∏„ÄÅÊúüË¥ß„ÄÅÊúüÊùÉ„ÄÅË¥µÈáëÂ±ûÁ≠â&lt;/p&gt; &lt;/li&gt; 
     &lt;li&gt; &lt;p&gt;&lt;span&gt;‚¨Ü&lt;/span&gt; ÊòìÁõõ9.0Â§ñÁõòÔºà&lt;a href="https://www.github.com/vnpy/vnpy_tap"&gt;tap&lt;/a&gt;ÔºâÔºöÊµ∑Â§ñÊúüË¥ß&lt;/p&gt; &lt;/li&gt; 
     &lt;li&gt; &lt;p&gt;&lt;span&gt;‚¨Ü&lt;/span&gt; Áõ¥ËææÊúüË¥ßÔºà&lt;a href="https://www.github.com/vnpy/vnpy_da"&gt;da&lt;/a&gt;ÔºâÔºöÊµ∑Â§ñÊúüË¥ß&lt;/p&gt; &lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;ÁâπÊÆäÂ∫îÁî®&lt;/p&gt; 
    &lt;ul&gt; 
     &lt;li&gt; &lt;p&gt;&lt;span&gt;‚¨Ü&lt;/span&gt; RQDataË°åÊÉÖÔºà&lt;a href="https://www.github.com/vnpy/vnpy_rqdata"&gt;rqdata&lt;/a&gt;ÔºâÔºöË∑®Â∏ÇÂú∫ÔºàËÇ°Á•®„ÄÅÊåáÊï∞„ÄÅETF„ÄÅÊúüË¥ßÔºâÂÆûÊó∂Ë°åÊÉÖ&lt;/p&gt; &lt;/li&gt; 
     &lt;li&gt; &lt;p&gt;&lt;span&gt;‚¨Ü&lt;/span&gt; ËøÖÊäïÁ†îË°åÊÉÖÔºà&lt;a href="https://www.github.com/vnpy/vnpy_xt"&gt;xt&lt;/a&gt;ÔºâÔºöË∑®Â∏ÇÂú∫ÔºàËÇ°Á•®„ÄÅÊåáÊï∞„ÄÅÂèØËΩ¨ÂÄ∫„ÄÅETF„ÄÅÊúüË¥ß„ÄÅÊúüÊùÉÔºâÂÆûÊó∂Ë°åÊÉÖ&lt;/p&gt; &lt;/li&gt; 
     &lt;li&gt; &lt;p&gt;&lt;span&gt;‚¨Ü&lt;/span&gt; RPCÊúçÂä°Ôºà&lt;a href="https://www.github.com/vnpy/vnpy_rpcservice"&gt;rpc&lt;/a&gt;ÔºâÔºöË∑®ËøõÁ®ãÈÄöËÆØÊé•Âè£ÔºåÁî®‰∫éÂàÜÂ∏ÉÂºèÊû∂ÊûÑ&lt;/p&gt; &lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Ë¶ÜÁõñ‰∏ãËø∞ÂêÑÁ±ªÈáèÂåñÁ≠ñÁï•ÁöÑ‰∫§ÊòìÂ∫îÁî®ÔºàappÔºâÔºö&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;&lt;span&gt;‚¨Ü&lt;/span&gt; &lt;a href="https://www.github.com/vnpy/vnpy_ctastrategy"&gt;cta_strategy&lt;/a&gt;ÔºöCTAÁ≠ñÁï•ÂºïÊìéÊ®°ÂùóÔºåÂú®‰øùÊåÅÊòìÁî®ÊÄßÁöÑÂêåÊó∂ÔºåÂÖÅËÆ∏Áî®Êà∑ÈíàÂØπCTAÁ±ªÁ≠ñÁï•ËøêË°åËøáÁ®ã‰∏≠ÂßîÊâòÁöÑÊä•Êí§Ë°å‰∏∫ËøõË°åÁªÜÁ≤íÂ∫¶ÊéßÂà∂ÔºàÈôç‰Ωé‰∫§ÊòìÊªëÁÇπ„ÄÅÂÆûÁé∞È´òÈ¢ëÁ≠ñÁï•Ôºâ&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;span&gt;‚¨Ü&lt;/span&gt; &lt;a href="https://www.github.com/vnpy/vnpy_ctabacktester"&gt;cta_backtester&lt;/a&gt;ÔºöCTAÁ≠ñÁï•ÂõûÊµãÊ®°ÂùóÔºåÊó†ÈúÄ‰ΩøÁî®Jupyter NotebookÔºåÁõ¥Êé•‰ΩøÁî®ÂõæÂΩ¢ÁïåÈù¢ËøõË°åÁ≠ñÁï•ÂõûÊµãÂàÜÊûê„ÄÅÂèÇÊï∞‰ºòÂåñÁ≠âÁõ∏ÂÖ≥Â∑•‰Ωú&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;span&gt;‚¨Ü&lt;/span&gt; &lt;a href="https://www.github.com/vnpy/vnpy_spreadtrading"&gt;spread_trading&lt;/a&gt;Ôºö‰ª∑Â∑Æ‰∫§ÊòìÊ®°ÂùóÔºåÊîØÊåÅËá™ÂÆö‰πâ‰ª∑Â∑ÆÔºåÂÆûÊó∂ËÆ°ÁÆó‰ª∑Â∑ÆË°åÊÉÖÂíåÊåÅ‰ªìÔºåÊîØÊåÅ‰ª∑Â∑ÆÁÆóÊ≥ï‰∫§Êòì‰ª•ÂèäËá™Âä®‰ª∑Â∑ÆÁ≠ñÁï•‰∏§ÁßçÊ®°Âºè&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;span&gt;‚¨Ü&lt;/span&gt; &lt;a href="https://www.github.com/vnpy/vnpy_optionmaster"&gt;option_master&lt;/a&gt;ÔºöÊúüÊùÉ‰∫§ÊòìÊ®°ÂùóÔºåÈíàÂØπÂõΩÂÜÖÊúüÊùÉÂ∏ÇÂú∫ËÆæËÆ°ÔºåÊîØÊåÅÂ§öÁßçÊúüÊùÉÂÆö‰ª∑Ê®°Âûã„ÄÅÈöêÂê´Ê≥¢Âä®ÁéáÊõ≤Èù¢ËÆ°ÁÆó„ÄÅÂ∏åËÖäÂÄºÈ£éÈô©Ë∑üË∏™Á≠âÂäüËÉΩ&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;span&gt;‚¨Ü&lt;/span&gt; &lt;a href="https://www.github.com/vnpy/vnpy_portfoliostrategy"&gt;portfolio_strategy&lt;/a&gt;ÔºöÁªÑÂêàÁ≠ñÁï•Ê®°ÂùóÔºåÈù¢ÂêëÂêåÊó∂‰∫§ÊòìÂ§öÂêàÁ∫¶ÁöÑÈáèÂåñÁ≠ñÁï•ÔºàAlpha„ÄÅÊúüÊùÉÂ•óÂà©Á≠âÔºâÔºåÊèê‰æõÂéÜÂè≤Êï∞ÊçÆÂõûÊµãÂíåÂÆûÁõòËá™Âä®‰∫§ÊòìÂäüËÉΩ&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;span&gt;‚¨Ü&lt;/span&gt; &lt;a href="https://www.github.com/vnpy/vnpy_algotrading"&gt;algo_trading&lt;/a&gt;ÔºöÁÆóÊ≥ï‰∫§ÊòìÊ®°ÂùóÔºåÊèê‰æõÂ§öÁßçÂ∏∏Áî®ÁöÑÊô∫ËÉΩ‰∫§ÊòìÁÆóÊ≥ïÔºöTWAP„ÄÅSniper„ÄÅIceberg„ÄÅBestLimitÁ≠â&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;span&gt;‚¨Ü&lt;/span&gt; &lt;a href="https://www.github.com/vnpy/vnpy_scripttrader"&gt;script_trader&lt;/a&gt;ÔºöËÑöÊú¨Á≠ñÁï•Ê®°ÂùóÔºåÈù¢ÂêëÂ§öÊ†áÁöÑÁ±ªÈáèÂåñÁ≠ñÁï•ÂíåËÆ°ÁÆó‰ªªÂä°ËÆæËÆ°ÔºåÂêåÊó∂‰πüÂèØ‰ª•Âú®ÂëΩ‰ª§Ë°å‰∏≠ÂÆûÁé∞REPLÊåá‰ª§ÂΩ¢ÂºèÁöÑ‰∫§ÊòìÔºå‰∏çÊîØÊåÅÂõûÊµãÂäüËÉΩ&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;span&gt;‚¨Ü&lt;/span&gt; &lt;a href="https://www.github.com/vnpy/vnpy_paperaccount"&gt;paper_account&lt;/a&gt;ÔºöÊú¨Âú∞‰ªøÁúüÊ®°ÂùóÔºåÁ∫ØÊú¨Âú∞ÂåñÂÆûÁé∞ÁöÑ‰ªøÁúüÊ®°Êãü‰∫§ÊòìÂäüËÉΩÔºåÂü∫‰∫é‰∫§ÊòìÊé•Âè£Ëé∑ÂèñÁöÑÂÆûÊó∂Ë°åÊÉÖËøõË°åÂßîÊâòÊíÆÂêàÔºåÊèê‰æõÂßîÊâòÊàê‰∫§Êé®ÈÄÅ‰ª•ÂèäÊåÅ‰ªìËÆ∞ÂΩï&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;span&gt;‚¨Ü&lt;/span&gt; &lt;a href="https://www.github.com/vnpy/vnpy_chartwizard"&gt;chart_wizard&lt;/a&gt;ÔºöKÁ∫øÂõæË°®Ê®°ÂùóÔºåÂü∫‰∫éRQDataÊï∞ÊçÆÊúçÂä°ÔºàÊúüË¥ßÔºâÊàñËÄÖ‰∫§ÊòìÊé•Âè£Ëé∑ÂèñÂéÜÂè≤Êï∞ÊçÆÔºåÂπ∂ÁªìÂêàTickÊé®ÈÄÅÊòæÁ§∫ÂÆûÊó∂Ë°åÊÉÖÂèòÂåñ&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;span&gt;‚¨Ü&lt;/span&gt; &lt;a href="https://www.github.com/vnpy/vnpy_portfoliomanager"&gt;portfolio_manager&lt;/a&gt;Ôºö‰∫§ÊòìÁªÑÂêàÁÆ°ÁêÜÊ®°ÂùóÔºå‰ª•Áã¨Á´ãÁöÑÁ≠ñÁï•‰∫§ÊòìÁªÑÂêàÔºàÂ≠êË¥¶Êà∑Ôºâ‰∏∫Âü∫Á°ÄÔºåÊèê‰æõÂßîÊâòÊàê‰∫§ËÆ∞ÂΩïÁÆ°ÁêÜ„ÄÅ‰∫§Êòì‰ªì‰ΩçËá™Âä®Ë∑üË∏™‰ª•ÂèäÊØèÊó•Áõà‰∫èÂÆûÊó∂ÁªüËÆ°ÂäüËÉΩ&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;span&gt;‚¨Ü&lt;/span&gt; &lt;a href="https://www.github.com/vnpy/vnpy_rpcservice"&gt;rpc_service&lt;/a&gt;ÔºöRPCÊúçÂä°Ê®°ÂùóÔºåÂÖÅËÆ∏Â∞ÜÊüê‰∏ÄËøõÁ®ãÂêØÂä®‰∏∫ÊúçÂä°Á´ØÔºå‰Ωú‰∏∫Áªü‰∏ÄÁöÑË°åÊÉÖÂíå‰∫§ÊòìË∑ØÁî±ÈÄöÈÅìÔºåÂÖÅËÆ∏Â§öÂÆ¢Êà∑Á´ØÂêåÊó∂ËøûÊé•ÔºåÂÆûÁé∞Â§öËøõÁ®ãÂàÜÂ∏ÉÂºèÁ≥ªÁªü&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;span&gt;‚¨Ü&lt;/span&gt; &lt;a href="https://www.github.com/vnpy/vnpy_datamanager"&gt;data_manager&lt;/a&gt;ÔºöÂéÜÂè≤Êï∞ÊçÆÁÆ°ÁêÜÊ®°ÂùóÔºåÈÄöËøáÊ†ëÂΩ¢ÁõÆÂΩïÊü•ÁúãÊï∞ÊçÆÂ∫ì‰∏≠Â∑≤ÊúâÁöÑÊï∞ÊçÆÊ¶ÇÂÜµÔºåÈÄâÊã©‰ªªÊÑèÊó∂Èó¥ÊÆµÊï∞ÊçÆÊü•ÁúãÂ≠óÊÆµÁªÜËäÇÔºåÊîØÊåÅCSVÊñá‰ª∂ÁöÑÊï∞ÊçÆÂØºÂÖ•ÂíåÂØºÂá∫&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;span&gt;‚¨Ü&lt;/span&gt; &lt;a href="https://www.github.com/vnpy/vnpy_datarecorder"&gt;data_recorder&lt;/a&gt;ÔºöË°åÊÉÖËÆ∞ÂΩïÊ®°ÂùóÔºåÂü∫‰∫éÂõæÂΩ¢ÁïåÈù¢ËøõË°åÈÖçÁΩÆÔºåÊ†πÊçÆÈúÄÊ±ÇÂÆûÊó∂ÂΩïÂà∂TickÊàñËÄÖKÁ∫øË°åÊÉÖÂà∞Êï∞ÊçÆÂ∫ì‰∏≠ÔºåÁî®‰∫éÁ≠ñÁï•ÂõûÊµãÊàñËÄÖÂÆûÁõòÂàùÂßãÂåñ&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;span&gt;‚¨Ü&lt;/span&gt; &lt;a href="https://www.github.com/vnpy/vnpy_excelrtd"&gt;excel_rtd&lt;/a&gt;ÔºöExcel RTDÔºàReal Time DataÔºâÂÆûÊó∂Êï∞ÊçÆÊúçÂä°ÔºåÂü∫‰∫épyxllÊ®°ÂùóÂÆûÁé∞Âú®Excel‰∏≠Ëé∑ÂèñÂêÑÁ±ªÊï∞ÊçÆÔºàË°åÊÉÖ„ÄÅÂêàÁ∫¶„ÄÅÊåÅ‰ªìÁ≠âÔºâÁöÑÂÆûÊó∂Êé®ÈÄÅÊõ¥Êñ∞&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;span&gt;‚¨Ü&lt;/span&gt; &lt;a href="https://www.github.com/vnpy/vnpy_riskmanager"&gt;risk_manager&lt;/a&gt;ÔºöÈ£éÈô©ÁÆ°ÁêÜÊ®°ÂùóÔºåÊèê‰æõÂåÖÊã¨‰∫§ÊòìÊµÅÊéß„ÄÅ‰∏ãÂçïÊï∞Èáè„ÄÅÊ¥ªÂä®ÂßîÊâò„ÄÅÊí§ÂçïÊÄªÊï∞Á≠âËßÑÂàôÁöÑÁªüËÆ°ÂíåÈôêÂà∂ÔºåÊúâÊïàÂÆûÁé∞ÂâçÁ´ØÈ£éÊéßÂäüËÉΩ&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;span&gt;‚¨Ü&lt;/span&gt; &lt;a href="https://www.github.com/vnpy/vnpy_webtrader"&gt;web_trader&lt;/a&gt;ÔºöWebÊúçÂä°Ê®°ÂùóÔºåÈíàÂØπB-SÊû∂ÊûÑÈúÄÊ±ÇËÆæËÆ°ÔºåÂÆûÁé∞‰∫ÜÊèê‰æõ‰∏ªÂä®ÂáΩÊï∞Ë∞ÉÁî®ÔºàRESTÔºâÂíåË¢´Âä®Êï∞ÊçÆÊé®ÈÄÅÔºàWebsocketÔºâÁöÑWebÊúçÂä°Âô®&lt;/p&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Python‰∫§ÊòìAPIÊé•Âè£Â∞ÅË£ÖÔºàapiÔºâÔºåÊèê‰æõ‰∏äËø∞‰∫§ÊòìÊé•Âè£ÁöÑÂ∫ïÂ±ÇÂØπÊé•ÂÆûÁé∞„ÄÇ&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;&lt;span&gt;‚¨Ü&lt;/span&gt; REST ClientÔºà&lt;a href="https://www.github.com/vnpy/vnpy_rest"&gt;rest&lt;/a&gt;ÔºâÔºöÂü∫‰∫éÂçèÁ®ãÂºÇÊ≠•IOÁöÑÈ´òÊÄßËÉΩREST APIÂÆ¢Êà∑Á´ØÔºåÈááÁî®‰∫ã‰ª∂Ê∂àÊÅØÂæ™ÁéØÁöÑÁºñÁ®ãÊ®°ÂûãÔºåÊîØÊåÅÈ´òÂπ∂ÂèëÂÆûÊó∂‰∫§ÊòìËØ∑Ê±ÇÂèëÈÄÅ&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;span&gt;‚¨Ü&lt;/span&gt; Websocket ClientÔºà&lt;a href="https://www.github.com/vnpy/vnpy_websocket"&gt;websocket&lt;/a&gt;ÔºâÔºöÂü∫‰∫éÂçèÁ®ãÂºÇÊ≠•IOÁöÑÈ´òÊÄßËÉΩWebsocket APIÂÆ¢Êà∑Á´ØÔºåÊîØÊåÅÂíåREST ClientÂÖ±Áî®‰∫ã‰ª∂Âæ™ÁéØÂπ∂ÂèëËøêË°å&lt;/p&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;‚¨Ü&lt;/span&gt; ÁÆÄÊ¥ÅÊòìÁî®ÁöÑ‰∫ã‰ª∂È©±Âä®ÂºïÊìéÔºàeventÔºâÔºå‰Ωú‰∏∫‰∫ã‰ª∂È©±Âä®Âûã‰∫§ÊòìÁ®ãÂ∫èÁöÑÊ†∏ÂøÉ„ÄÇ&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;ÂØπÊé•ÂêÑÁ±ªÊï∞ÊçÆÂ∫ìÁöÑÈÄÇÈÖçÂô®Êé•Âè£ÔºàdatabaseÔºâÔºö&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;SQLÁ±ª&lt;/p&gt; 
    &lt;ul&gt; 
     &lt;li&gt; &lt;p&gt;&lt;span&gt;‚¨Ü&lt;/span&gt; SQLiteÔºà&lt;a href="https://www.github.com/vnpy/vnpy_sqlite"&gt;sqlite&lt;/a&gt;ÔºâÔºöËΩªÈáèÁ∫ßÂçïÊñá‰ª∂Êï∞ÊçÆÂ∫ìÔºåÊó†ÈúÄÂÆâË£ÖÂíåÈÖçÁΩÆÊï∞ÊçÆÊúçÂä°Á®ãÂ∫èÔºåVeighNaÁöÑÈªòËÆ§ÈÄâÈ°πÔºåÈÄÇÂêàÂÖ•Èó®Êñ∞ÊâãÁî®Êà∑&lt;/p&gt; &lt;/li&gt; 
     &lt;li&gt; &lt;p&gt;&lt;span&gt;‚¨Ü&lt;/span&gt; MySQLÔºà&lt;a href="https://www.github.com/vnpy/vnpy_mysql"&gt;mysql&lt;/a&gt;ÔºâÔºö‰∏ªÊµÅÁöÑÂºÄÊ∫êÂÖ≥Á≥ªÂûãÊï∞ÊçÆÂ∫ìÔºåÊñáÊ°£ËµÑÊñôÊûÅ‰∏∫‰∏∞ÂØåÔºå‰∏îÂèØÊõøÊç¢ÂÖ∂‰ªñNewSQLÂÖºÂÆπÂÆûÁé∞ÔºàÂ¶ÇTiDBÔºâ&lt;/p&gt; &lt;/li&gt; 
     &lt;li&gt; &lt;p&gt;&lt;span&gt;‚¨Ü&lt;/span&gt; PostgreSQLÔºà&lt;a href="https://www.github.com/vnpy/vnpy_postgresql"&gt;postgresql&lt;/a&gt;ÔºâÔºöÁâπÊÄßÊõ¥‰∏∫‰∏∞ÂØåÁöÑÂºÄÊ∫êÂÖ≥Á≥ªÂûãÊï∞ÊçÆÂ∫ìÔºåÊîØÊåÅÈÄöËøáÊâ©Â±ïÊèí‰ª∂Êù•Êñ∞Â¢ûÂäüËÉΩÔºåÂè™Êé®ËçêÁÜüÊâã‰ΩøÁî®&lt;/p&gt; &lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;NoSQLÁ±ª&lt;/p&gt; 
    &lt;ul&gt; 
     &lt;li&gt; &lt;p&gt;DolphinDBÔºà&lt;a href="https://www.github.com/vnpy/vnpy_dolphindb"&gt;dolphindb&lt;/a&gt;ÔºâÔºö‰∏ÄÊ¨æÈ´òÊÄßËÉΩÂàÜÂ∏ÉÂºèÊó∂Â∫èÊï∞ÊçÆÂ∫ìÔºåÈÄÇÁî®‰∫éÂØπÈÄüÂ∫¶Ë¶ÅÊ±ÇÊûÅÈ´òÁöÑ‰ΩéÂª∂Êó∂ÊàñÂÆûÊó∂ÊÄß‰ªªÂä°&lt;/p&gt; &lt;/li&gt; 
     &lt;li&gt; &lt;p&gt;&lt;span&gt;‚¨Ü&lt;/span&gt; TDengineÔºà&lt;a href="https://www.github.com/vnpy/vnpy_taos"&gt;taos&lt;/a&gt;ÔºâÔºöÂàÜÂ∏ÉÂºè„ÄÅÈ´òÊÄßËÉΩ„ÄÅÊîØÊåÅSQLÁöÑÊó∂Â∫èÊï∞ÊçÆÂ∫ìÔºåÂ∏¶ÊúâÂÜÖÂª∫ÁöÑÁºìÂ≠ò„ÄÅÊµÅÂºèËÆ°ÁÆó„ÄÅÊï∞ÊçÆËÆ¢ÈòÖÁ≠âÁ≥ªÁªüÂäüËÉΩÔºåËÉΩÂ§ßÂπÖÂáèÂ∞ëÁ†îÂèëÂíåËøêÁª¥ÁöÑÂ§çÊùÇÂ∫¶&lt;/p&gt; &lt;/li&gt; 
     &lt;li&gt; &lt;p&gt;&lt;span&gt;‚¨Ü&lt;/span&gt; MongoDBÔºà&lt;a href="https://www.github.com/vnpy/vnpy_mongodb"&gt;mongodb&lt;/a&gt;ÔºâÔºöÂü∫‰∫éÂàÜÂ∏ÉÂºèÊñá‰ª∂ÂÇ®Â≠òÔºàbsonÊ†ºÂºèÔºâÁöÑÊñáÊ°£ÂºèÊï∞ÊçÆÂ∫ìÔºåÂÜÖÁΩÆÁöÑÁÉ≠Êï∞ÊçÆÂÜÖÂ≠òÁºìÂ≠òÊèê‰æõÊõ¥Âø´ËØªÂÜôÈÄüÂ∫¶&lt;/p&gt; &lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;ÂØπÊé•‰∏ãËø∞ÂêÑÁ±ªÊï∞ÊçÆÊúçÂä°ÁöÑÈÄÇÈÖçÂô®Êé•Âè£ÔºàdatafeedÔºâÔºö&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;&lt;span&gt;‚¨Ü&lt;/span&gt; ËøÖÊäïÁ†îÔºà&lt;a href="https://www.github.com/vnpy/vnpy_xt"&gt;xt&lt;/a&gt;ÔºâÔºöËÇ°Á•®„ÄÅÊúüË¥ß„ÄÅÊúüÊùÉ„ÄÅÂü∫Èáë„ÄÅÂÄ∫Âà∏&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;span&gt;‚¨Ü&lt;/span&gt; Á±≥Á≠êRQDataÔºà&lt;a href="https://www.github.com/vnpy/vnpy_rqdata"&gt;rqdata&lt;/a&gt;ÔºâÔºöËÇ°Á•®„ÄÅÊúüË¥ß„ÄÅÊúüÊùÉ„ÄÅÂü∫Èáë„ÄÅÂÄ∫Âà∏„ÄÅÈªÑÈáëTD&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;span&gt;‚¨Ü&lt;/span&gt; MultiChartsÔºà&lt;a href="https://www.github.com/vnpy/vnpy_mcdata"&gt;mcdata&lt;/a&gt;ÔºâÔºöÊúüË¥ß„ÄÅÊúüË¥ßÊúüÊùÉ&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;span&gt;‚¨Ü&lt;/span&gt; TuShareÔºà&lt;a href="https://www.github.com/vnpy/vnpy_tushare"&gt;tushare&lt;/a&gt;ÔºâÔºöËÇ°Á•®„ÄÅÊúüË¥ß„ÄÅÊúüÊùÉ„ÄÅÂü∫Èáë&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;span&gt;‚¨Ü&lt;/span&gt; ‰∏áÂæóWindÔºà&lt;a href="https://www.github.com/vnpy/vnpy_wind"&gt;wind&lt;/a&gt;ÔºâÔºöËÇ°Á•®„ÄÅÊúüË¥ß„ÄÅÂü∫Èáë„ÄÅÂÄ∫Âà∏&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;span&gt;‚¨Ü&lt;/span&gt; ÂêåËä±È°∫iFinDÔºà&lt;a href="https://www.github.com/vnpy/vnpy_ifind"&gt;ifind&lt;/a&gt;ÔºâÔºöËÇ°Á•®„ÄÅÊúüË¥ß„ÄÅÂü∫Èáë„ÄÅÂÄ∫Âà∏&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;span&gt;‚¨Ü&lt;/span&gt; Â§©Âã§TQSDKÔºà&lt;a href="https://www.github.com/vnpy/vnpy_tqsdk"&gt;tqsdk&lt;/a&gt;ÔºâÔºöÊúüË¥ß&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;span&gt;‚¨Ü&lt;/span&gt; ÊéòÈáëÔºà&lt;a href="https://www.github.com/vnpy/vnpy_gm"&gt;gm&lt;/a&gt;ÔºâÔºöËÇ°Á•®&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;span&gt;‚¨Ü&lt;/span&gt; polygonÔºà&lt;a href="https://www.github.com/vnpy/vnpy_polygon"&gt;polygon&lt;/a&gt;ÔºâÔºöËÇ°Á•®„ÄÅÊúüË¥ß„ÄÅÊúüÊùÉ&lt;/p&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;‚¨Ü&lt;/span&gt; Ë∑®ËøõÁ®ãÈÄöËÆØÊ†áÂáÜÁªÑ‰ª∂ÔºàrpcÔºâÔºåÁî®‰∫éÂÆûÁé∞ÂàÜÂ∏ÉÂºèÈÉ®ÁΩ≤ÁöÑÂ§çÊùÇ‰∫§ÊòìÁ≥ªÁªü„ÄÇ&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;‚¨Ü&lt;/span&gt; PythonÈ´òÊÄßËÉΩKÁ∫øÂõæË°®ÔºàchartÔºâÔºåÊîØÊåÅÂ§ßÊï∞ÊçÆÈáèÂõæË°®ÊòæÁ§∫‰ª•ÂèäÂÆûÊó∂Êï∞ÊçÆÊõ¥Êñ∞ÂäüËÉΩ„ÄÇ&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="http://www.vnpy.com/forum"&gt;Á§æÂå∫ËÆ∫Âùõ&lt;/a&gt;Âíå&lt;a href="http://zhuanlan.zhihu.com/vn-py"&gt;Áü•‰πé‰∏ìÊ†è&lt;/a&gt;ÔºåÂÜÖÂÆπÂåÖÊã¨VeighNaÈ°πÁõÆÁöÑÂºÄÂèëÊïôÁ®ãÂíåPythonÂú®ÈáèÂåñ‰∫§ÊòìÈ¢ÜÂüüÁöÑÂ∫îÁî®Á†îÁ©∂Á≠âÂÜÖÂÆπ„ÄÇ&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;ÂÆòÊñπ‰∫§ÊµÅÁæ§262656087ÔºàQQÔºâÔºåÁÆ°ÁêÜ‰∏•Ê†ºÔºàÂÆöÊúüÊ∏ÖÈô§ÈïøÊúüÊΩúÊ∞¥ÁöÑÊàêÂëòÔºâÔºåÂÖ•Áæ§Ë¥πÂ∞ÜÊçêËµ†ÁªôVeighNaÁ§æÂå∫Âü∫Èáë„ÄÇ&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Ê≥®Ôºö‰ª•‰∏äÂÖ≥‰∫éÂäüËÉΩÁâπÁÇπÁöÑËØ¥Êòé‰∏∫Ê†πÊçÆËØ¥ÊòéÊñáÊ°£ÂèëÂ∏ÉÊó∂ÊÉÖÂÜµÁΩóÂàóÔºåÂêéÁª≠ÂèØËÉΩÂ≠òÂú®Êõ¥Êñ∞ÊàñË∞ÉÊï¥„ÄÇËã•ÂäüËÉΩÊèèËø∞ÂêåÂÆûÈôÖÂ≠òÂú®Âá∫ÂÖ•ÔºåÊ¨¢ËøéÈÄöËøáIssueËÅîÁ≥ªËøõË°åË∞ÉÊï¥„ÄÇ&lt;/p&gt; 
&lt;h2&gt;ÁéØÂ¢ÉÂáÜÂ§á&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Êé®Ëçê‰ΩøÁî®VeighNaÂõ¢Èòü‰∏∫ÈáèÂåñ‰∫§Êòì‰∏ìÈó®ÊâìÈÄ†ÁöÑPythonÂèëË°åÁâà&lt;a href="https://download.vnpy.com/veighna_studio-4.2.0.exe"&gt;VeighNa Studio-4.2.0&lt;/a&gt;ÔºåÈõÜÊàêÂÜÖÁΩÆ‰∫ÜVeighNaÊ°ÜÊû∂‰ª•ÂèäVeighNa StationÈáèÂåñÁÆ°ÁêÜÂπ≥Âè∞ÔºåÊó†ÈúÄÊâãÂä®ÂÆâË£Ö&lt;/li&gt; 
 &lt;li&gt;ÊîØÊåÅÁöÑÁ≥ªÁªüÁâàÊú¨ÔºöWindows 11‰ª•‰∏ä / Windows Server 2022‰ª•‰∏ä / Ubuntu 22.04 LTS‰ª•‰∏ä&lt;/li&gt; 
 &lt;li&gt;ÊîØÊåÅÁöÑPythonÁâàÊú¨ÔºöPython 3.10‰ª•‰∏äÔºà64‰ΩçÔºâÔºå&lt;strong&gt;Êé®Ëçê‰ΩøÁî®Python 3.13&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ÂÆâË£ÖÊ≠•È™§&lt;/h2&gt; 
&lt;p&gt;Âú®&lt;a href="https://github.com/vnpy/vnpy/releases"&gt;ËøôÈáå&lt;/a&gt;‰∏ãËΩΩReleaseÂèëÂ∏ÉÁâàÊú¨ÔºåËß£ÂéãÂêéËøêË°å‰ª•‰∏ãÂëΩ‰ª§ÂÆâË£ÖÔºö&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Windows&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;install.bat
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Ubuntu&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;bash install.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Macos&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;bash install_osx.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;‰ΩøÁî®ÊåáÂçó&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Âú®&lt;a href="http://www.simnow.com.cn/"&gt;SimNow&lt;/a&gt;Ê≥®ÂÜåCTP‰ªøÁúüË¥¶Âè∑ÔºåÂπ∂Âú®&lt;a href="http://www.simnow.com.cn/product.action"&gt;ËØ•È°µÈù¢&lt;/a&gt;Ëé∑ÂèñÁªèÁ∫™ÂïÜ‰ª£Á†Å‰ª•Âèä‰∫§ÊòìË°åÊÉÖÊúçÂä°Âô®Âú∞ÂùÄ„ÄÇ&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Âú®&lt;a href="https://www.vnpy.com/forum/"&gt;VeighNaÁ§æÂå∫ËÆ∫Âùõ&lt;/a&gt;Ê≥®ÂÜåËé∑ÂæóVeighNa StationË¥¶Âè∑ÂØÜÁ†ÅÔºàËÆ∫ÂùõË¥¶Âè∑ÂØÜÁ†ÅÂç≥ÊòØÔºâ&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;ÂêØÂä®VeighNa StationÔºàÂÆâË£ÖVeighNa StudioÂêé‰ºöÂú®Ê°åÈù¢Ëá™Âä®ÂàõÂª∫Âø´Êç∑ÊñπÂºèÔºâÔºåËæìÂÖ•‰∏ä‰∏ÄÊ≠•ÁöÑË¥¶Âè∑ÂØÜÁ†ÅÁôªÂΩï&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;ÁÇπÂáªÂ∫ïÈÉ®ÁöÑ&lt;strong&gt;VeighNa Trader&lt;/strong&gt;ÊåâÈíÆÔºåÂºÄÂßã‰Ω†ÁöÑ‰∫§ÊòìÔºÅÔºÅÔºÅ&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Ê≥®ÊÑèÔºö&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Âú®VeighNa TraderÁöÑËøêË°åËøáÁ®ã‰∏≠ËØ∑ÂãøÂÖ≥Èó≠VeighNa StationÔºà‰ºöËá™Âä®ÈÄÄÂá∫Ôºâ&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ËÑöÊú¨ËøêË°å&lt;/h2&gt; 
&lt;p&gt;Èô§‰∫ÜÂü∫‰∫éVeighNa StationÁöÑÂõæÂΩ¢ÂåñÂêØÂä®ÊñπÂºèÂ§ñÔºå‰πüÂèØ‰ª•Âú®‰ªªÊÑèÁõÆÂΩï‰∏ãÂàõÂª∫run.pyÔºåÂÜôÂÖ•‰ª•‰∏ãÁ§∫‰æã‰ª£Á†ÅÔºö&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-Python"&gt;from vnpy.event import EventEngine
from vnpy.trader.engine import MainEngine
from vnpy.trader.ui import MainWindow, create_qapp

from vnpy_ctp import CtpGateway
from vnpy_ctastrategy import CtaStrategyApp
from vnpy_ctabacktester import CtaBacktesterApp


def main():
    """Start VeighNa Trader"""
    qapp = create_qapp()

    event_engine = EventEngine()
    main_engine = MainEngine(event_engine)
    
    main_engine.add_gateway(CtpGateway)
    main_engine.add_app(CtaStrategyApp)
    main_engine.add_app(CtaBacktesterApp)

    main_window = MainWindow(main_engine, event_engine)
    main_window.showMaximized()

    qapp.exec()


if __name__ == "__main__":
    main()
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Âú®ËØ•ÁõÆÂΩï‰∏ãÊâìÂºÄCMDÔºàÊåâ‰ΩèShift-&amp;gt;ÁÇπÂáªÈº†Ê†áÂè≥ÈîÆ-&amp;gt;Âú®Ê≠§Â§ÑÊâìÂºÄÂëΩ‰ª§Á™óÂè£/PowerShellÔºâÂêéËøêË°å‰∏ãÂàóÂëΩ‰ª§ÂêØÂä®VeighNa TraderÔºö&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;python run.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Ë¥°ÁåÆ‰ª£Á†Å&lt;/h2&gt; 
&lt;p&gt;VeighNa‰ΩøÁî®GithubÊâòÁÆ°ÂÖ∂Ê∫ê‰ª£Á†ÅÔºåÂ¶ÇÊûúÂ∏åÊúõË¥°ÁåÆ‰ª£Á†ÅËØ∑‰ΩøÁî®githubÁöÑPRÔºàPull RequestÔºâÁöÑÊµÅÁ®ã:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/vnpy/vnpy/issues/new"&gt;ÂàõÂª∫ Issue&lt;/a&gt; - ÂØπ‰∫éËæÉÂ§ßÁöÑÊîπÂä®ÔºàÂ¶ÇÊñ∞ÂäüËÉΩÔºåÂ§ßÂûãÈáçÊûÑÁ≠âÔºâÂª∫ËÆÆÂÖàÂºÄissueËÆ®ËÆ∫‰∏Ä‰∏ãÔºåËæÉÂ∞èÁöÑimprovementÔºàÂ¶ÇÊñáÊ°£ÊîπËøõÔºåbugfixÁ≠âÔºâÁõ¥Êé•ÂèëPRÂç≥ÂèØ&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Fork &lt;a href="https://github.com/vnpy/vnpy"&gt;VeighNa&lt;/a&gt; - ÁÇπÂáªÂè≥‰∏äËßí&lt;strong&gt;Fork&lt;/strong&gt;ÊåâÈíÆ&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Clone‰Ω†Ëá™Â∑±ÁöÑfork: &lt;code&gt;git clone https://github.com/$userid/vnpy.git&lt;/code&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Â¶ÇÊûú‰Ω†ÁöÑforkÂ∑≤ÁªèËøáÊó∂ÔºåÈúÄË¶ÅÊâãÂä®syncÔºö&lt;a href="https://help.github.com/articles/syncing-a-fork/"&gt;ÂêåÊ≠•ÊñπÊ≥ï&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;‰ªé&lt;strong&gt;dev&lt;/strong&gt;ÂàõÂª∫‰Ω†Ëá™Â∑±ÁöÑfeature branch: &lt;code&gt;git checkout -b $my_feature_branch dev&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Âú®$my_feature_branch‰∏ä‰øÆÊîπÂπ∂Â∞Ü‰øÆÊîπpushÂà∞‰Ω†ÁöÑfork‰∏ä&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;ÂàõÂª∫‰ªé‰Ω†ÁöÑforkÁöÑ$my_feature_branchÂàÜÊîØÂà∞‰∏ªÈ°πÁõÆÁöÑ&lt;strong&gt;dev&lt;/strong&gt;ÂàÜÊîØÁöÑ[Pull Request] - &lt;a href="https://github.com/vnpy/vnpy/compare?expand=1"&gt;Âú®Ê≠§&lt;/a&gt;ÁÇπÂáª&lt;strong&gt;compare across forks&lt;/strong&gt;ÔºåÈÄâÊã©ÈúÄË¶ÅÁöÑforkÂíåbranchÂàõÂª∫PR&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Á≠âÂæÖreview, ÈúÄË¶ÅÁªßÁª≠ÊîπËøõÔºåÊàñËÄÖË¢´Merge!&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Âú®Êèê‰∫§‰ª£Á†ÅÁöÑÊó∂ÂÄôÔºåËØ∑ÈÅµÂÆà‰ª•‰∏ãËßÑÂàôÔºå‰ª•ÊèêÈ´ò‰ª£Á†ÅË¥®ÈáèÔºö&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;‰ΩøÁî®&lt;a href="https://github.com/astral-sh/ruff"&gt;ruff&lt;/a&gt;Ê£ÄÊü•‰Ω†ÁöÑ‰ª£Á†ÅÊ†∑ÂºèÔºåÁ°Æ‰øùÊ≤°ÊúâerrorÂíåwarning„ÄÇÂú®È°πÁõÆÊ†πÁõÆÂΩï‰∏ãËøêË°å&lt;code&gt;ruff check .&lt;/code&gt;Âç≥ÂèØ„ÄÇ&lt;/li&gt; 
 &lt;li&gt;‰ΩøÁî®&lt;a href="https://github.com/python/mypy"&gt;mypy&lt;/a&gt;ËøõË°åÈùôÊÄÅÁ±ªÂûãÊ£ÄÊü•ÔºåÁ°Æ‰øùÁ±ªÂûãÊ≥®Ëß£Ê≠£Á°Æ„ÄÇÂú®È°πÁõÆÊ†πÁõÆÂΩï‰∏ãËøêË°å&lt;code&gt;mypy vnpy&lt;/code&gt;Âç≥ÂèØ„ÄÇ&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ÂÖ∂‰ªñÂÜÖÂÆπ&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/vnpy/vnpy/raw/dev/.github/SUPPORT.md"&gt;Ëé∑ÂèñÂ∏ÆÂä©&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/vnpy/vnpy/raw/dev/.github/CODE_OF_CONDUCT.md"&gt;Á§æÂå∫Ë°å‰∏∫ÂáÜÂàô&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/vnpy/vnpy/raw/dev/.github/ISSUE_TEMPLATE.md"&gt;IssueÊ®°Êùø&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/vnpy/vnpy/raw/dev/.github/PULL_REQUEST_TEMPLATE.md"&gt;PRÊ®°Êùø&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ÁâàÊùÉËØ¥Êòé&lt;/h2&gt; 
&lt;p&gt;MIT&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Fosowl/agenticSeek</title>
      <link>https://github.com/Fosowl/agenticSeek</link>
      <description>&lt;p&gt;Fully Local Manus AI. No APIs, No $200 monthly bills. Enjoy an autonomous agent that thinks, browses the web, and code for the sole cost of electricity. üîî Official updates only via twitter @Martin993886460 (Beware of fake account)&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;AgenticSeek: Private, Local Manus Alternative.&lt;/h1&gt; 
&lt;p align="center"&gt; &lt;img align="center" src="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/media/agentic_seek_logo.png" width="300" height="300" alt="Agentic Seek Logo" /&gt; &lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;English | &lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_CHS.md"&gt;‰∏≠Êñá&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_CHT.md"&gt;ÁπÅÈ´î‰∏≠Êñá&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_FR.md"&gt;Fran√ßais&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_JP.md"&gt;Êó•Êú¨Ë™û&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_PTBR.md"&gt;Portugu√™s (Brasil)&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_ES.md"&gt;Espa√±ol&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;A &lt;strong&gt;100% local alternative to Manus AI&lt;/strong&gt;, this voice-enabled AI assistant autonomously browses the web, writes code, and plans tasks while keeping all data on your device. Tailored for local reasoning models, it runs entirely on your hardware, ensuring complete privacy and zero cloud dependency.&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://fosowl.github.io/agenticSeek.html"&gt;&lt;img src="https://img.shields.io/static/v1?label=Website&amp;amp;message=AgenticSeek&amp;amp;color=blue&amp;amp;style=flat-square" alt="Visit AgenticSeek" /&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/badge/license-GPL--3.0-green" alt="License" /&gt; &lt;a href="https://discord.gg/8hGDaME3TC"&gt;&lt;img src="https://img.shields.io/badge/Discord-Join%20Us-7289DA?logo=discord&amp;amp;logoColor=white" alt="Discord" /&gt;&lt;/a&gt; &lt;a href="https://x.com/Martin993886460"&gt;&lt;img src="https://img.shields.io/twitter/url/https/twitter.com/fosowl.svg?style=social&amp;amp;label=Update%20%40Fosowl" alt="Twitter" /&gt;&lt;/a&gt; &lt;a href="https://github.com/Fosowl/agenticSeek/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/Fosowl/agenticSeek?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Why AgenticSeek ?&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;üîí Fully Local &amp;amp; Private - Everything runs on your machine ‚Äî no cloud, no data sharing. Your files, conversations, and searches stay private.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;üåê Smart Web Browsing - AgenticSeek can browse the internet by itself ‚Äî search, read, extract info, fill web form ‚Äî all hands-free.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;üíª Autonomous Coding Assistant - Need code? It can write, debug, and run programs in Python, C, Go, Java, and more ‚Äî all without supervision.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;üß† Smart Agent Selection - You ask, it figures out the best agent for the job automatically. Like having a team of experts ready to help.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;üìã Plans &amp;amp; Executes Complex Tasks - From trip planning to complex projects ‚Äî it can split big tasks into steps and get things done using multiple AI agents.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;üéôÔ∏è Voice-Enabled - Clean, fast, futuristic voice and speech to text allowing you to talk to it like it's your personal AI from a sci-fi movie. (In progress)&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;strong&gt;Demo&lt;/strong&gt;&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;em&gt;Can you search for the agenticSeek project, learn what skills are required, then open the CV_candidates.zip and then tell me which match best the project&lt;/em&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/b8ca60e9-7b3b-4533-840e-08f9ac426316"&gt;https://github.com/user-attachments/assets/b8ca60e9-7b3b-4533-840e-08f9ac426316&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Disclaimer: This demo, including all the files that appear (e.g: CV_candidates.zip), are entirely fictional. We are not a corporation, we seek open-source contributors not candidates.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;üõ†‚ö†Ô∏èÔ∏è &lt;strong&gt;Active Work in Progress&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;üôè This project started as a side-project and has zero roadmap and zero funding. It's grown way beyond what I expected by ending in GitHub Trending. Contributions, feedback, and patience are deeply appreciated.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Prerequisites&lt;/h2&gt; 
&lt;p&gt;Before you begin, ensure you have the following software installed:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Git:&lt;/strong&gt; For cloning the repository. &lt;a href="https://git-scm.com/downloads"&gt;Download Git&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Python 3.10.x:&lt;/strong&gt; We strongly recommend using Python version 3.10.x. Using other versions might lead to dependency errors. &lt;a href="https://www.python.org/downloads/release/python-3100/"&gt;Download Python 3.10&lt;/a&gt; (pick a 3.10.x version).&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Docker Engine &amp;amp; Docker Compose:&lt;/strong&gt; For running bundled services like SearxNG. 
  &lt;ul&gt; 
   &lt;li&gt;Install Docker Desktop (which includes Docker Compose V2): &lt;a href="https://docs.docker.com/desktop/install/windows-install/"&gt;Windows&lt;/a&gt; | &lt;a href="https://docs.docker.com/desktop/install/mac-install/"&gt;Mac&lt;/a&gt; | &lt;a href="https://docs.docker.com/desktop/install/linux-install/"&gt;Linux&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;Alternatively, install Docker Engine and Docker Compose separately on Linux: &lt;a href="https://docs.docker.com/engine/install/"&gt;Docker Engine&lt;/a&gt; | &lt;a href="https://docs.docker.com/compose/install/"&gt;Docker Compose&lt;/a&gt; (ensure you install Compose V2, e.g., &lt;code&gt;sudo apt-get install docker-compose-plugin&lt;/code&gt;).&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;1. &lt;strong&gt;Clone the repository and setup&lt;/strong&gt;&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;git clone https://github.com/Fosowl/agenticSeek.git
cd agenticSeek
mv .env.example .env
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;2. Change the .env file content&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;SEARXNG_BASE_URL="http://searxng:8080" # http://127.0.0.1:8080 if running on host
REDIS_BASE_URL="redis://redis:6379/0"
WORK_DIR="/Users/mlg/Documents/workspace_for_ai"
OLLAMA_PORT="11434"
LM_STUDIO_PORT="1234"
CUSTOM_ADDITIONAL_LLM_PORT="11435"
OPENAI_API_KEY='optional'
DEEPSEEK_API_KEY='optional'
OPENROUTER_API_KEY='optional'
TOGETHER_API_KEY='optional'
GOOGLE_API_KEY='optional'
ANTHROPIC_API_KEY='optional'
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Update the &lt;code&gt;.env&lt;/code&gt; file with your own values as needed:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;SEARXNG_BASE_URL&lt;/strong&gt;: Leave unchanged unless running on host with CLI mode.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;REDIS_BASE_URL&lt;/strong&gt;: Leave unchanged&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;WORK_DIR&lt;/strong&gt;: Path to your working directory on your local machine. AgenticSeek will be able to read and interact with these files.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;OLLAMA_PORT&lt;/strong&gt;: Port number for the Ollama service.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;LM_STUDIO_PORT&lt;/strong&gt;: Port number for the LM Studio service.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;CUSTOM_ADDITIONAL_LLM_PORT&lt;/strong&gt;: Port for any additional custom LLM service.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;API Key are totally optional for user who choose to run LLM locally. Which is the primary purpose of this project. Leave empty if you have sufficient hardware&lt;/strong&gt;&lt;/p&gt; 
&lt;h3&gt;3. &lt;strong&gt;Start Docker&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;Make sure Docker is installed and running on your system. You can start Docker using the following commands:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;On Linux/macOS:&lt;/strong&gt;&lt;br /&gt; Open a terminal and run:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-sh"&gt;sudo systemctl start docker
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Or launch Docker Desktop from your applications menu if installed.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;On Windows:&lt;/strong&gt;&lt;br /&gt; Start Docker Desktop from the Start menu.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;You can verify Docker is running by executing:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;docker info
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you see information about your Docker installation, it is running correctly.&lt;/p&gt; 
&lt;p&gt;See the table of &lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#list-of-local-providers"&gt;Local Providers&lt;/a&gt; below for a summary.&lt;/p&gt; 
&lt;p&gt;Next step: &lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#start-services-and-run"&gt;Run AgenticSeek locally&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;See the &lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#troubleshooting"&gt;Troubleshooting&lt;/a&gt; section if you are having issues.&lt;/em&gt; &lt;em&gt;If your hardware can't run LLMs locally, see &lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#setup-to-run-with-an-api"&gt;Setup to run with an API&lt;/a&gt;.&lt;/em&gt; &lt;em&gt;For detailed &lt;code&gt;config.ini&lt;/code&gt; explanations, see &lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#config"&gt;Config Section&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Setup for running LLM locally on your machine&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Hardware Requirements:&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;To run LLMs locally, you'll need sufficient hardware. At a minimum, a GPU capable of running Magistral, Qwen or Deepseek 14B is required. See the FAQ for detailed model/performance recommendations.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Setup your local provider&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Start your local provider (for example with ollama):&lt;/p&gt; 
&lt;p&gt;Unless you wish to to run AgenticSeek on host (CLI mode), export or set the provider listen address:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;export OLLAMA_HOST=0.0.0.0:11434
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then, start you provider:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;ollama serve
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See below for a list of local supported provider.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Update the config.ini&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Change the config.ini file to set the provider_name to a supported provider and provider_model to a LLM supported by your provider. We recommend reasoning model such as &lt;em&gt;Magistral&lt;/em&gt; or &lt;em&gt;Deepseek&lt;/em&gt;.&lt;/p&gt; 
&lt;p&gt;See the &lt;strong&gt;FAQ&lt;/strong&gt; at the end of the README for required hardware.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;[MAIN]
is_local = True # Whenever you are running locally or with remote provider.
provider_name = ollama # or lm-studio, openai, etc..
provider_model = deepseek-r1:14b # choose a model that fit your hardware
provider_server_address = 127.0.0.1:11434
agent_name = Jarvis # name of your AI
recover_last_session = True # whenever to recover the previous session
save_session = True # whenever to remember the current session
speak = False # text to speech
listen = False # Speech to text, only for CLI, experimental
jarvis_personality = False # Whenever to use a more "Jarvis" like personality (experimental)
languages = en zh # The list of languages, Text to speech will default to the first language on the list
[BROWSER]
headless_browser = True # leave unchanged unless using CLI on host.
stealth_mode = True # Use undetected selenium to reduce browser detection
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Warning&lt;/strong&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;The &lt;code&gt;config.ini&lt;/code&gt; file format does not support comments. Do not copy and paste the example configuration directly, as comments will cause errors. Instead, manually modify the &lt;code&gt;config.ini&lt;/code&gt; file with your desired settings, excluding any comments.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Do &lt;em&gt;NOT&lt;/em&gt; set provider_name to &lt;code&gt;openai&lt;/code&gt; if using LM-studio for running LLMs. Set it to &lt;code&gt;lm-studio&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Some provider (eg: lm-studio) require you to have &lt;code&gt;http://&lt;/code&gt; in front of the IP. For example &lt;code&gt;http://127.0.0.1:1234&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;List of local providers&lt;/strong&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Provider&lt;/th&gt; 
   &lt;th&gt;Local?&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ollama&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Run LLMs locally with ease using ollama as a LLM provider&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;lm-studio&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Run LLM locally with LM studio (set &lt;code&gt;provider_name&lt;/code&gt; to &lt;code&gt;lm-studio&lt;/code&gt;)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;openai&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Use openai compatible API (eg: llama.cpp server)&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Next step: &lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#Start-services-and-Run"&gt;Start services and run AgenticSeek&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;See the &lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#troubleshooting"&gt;Troubleshooting&lt;/a&gt; section if you are having issues.&lt;/em&gt; &lt;em&gt;If your hardware can't run LLMs locally, see &lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#setup-to-run-with-an-api"&gt;Setup to run with an API&lt;/a&gt;.&lt;/em&gt; &lt;em&gt;For detailed &lt;code&gt;config.ini&lt;/code&gt; explanations, see &lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#config"&gt;Config Section&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt; 
&lt;h2&gt;Setup to run with an API&lt;/h2&gt; 
&lt;p&gt;This setup uses external, cloud-based LLM providers. You'll need an API key from your chosen service.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;1. Choose an API Provider and Get an API Key:&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Refer to the &lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#list-of-api-providers"&gt;List of API Providers&lt;/a&gt; below. Visit their websites to sign up and obtain an API key.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2. Set Your API Key as an Environment Variable:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Linux/macOS:&lt;/strong&gt; Open your terminal and use the &lt;code&gt;export&lt;/code&gt; command. It's best to add this to your shell's profile file (e.g., &lt;code&gt;~/.bashrc&lt;/code&gt;, &lt;code&gt;~/.zshrc&lt;/code&gt;) for persistence.&lt;/p&gt; &lt;pre&gt;&lt;code class="language-sh"&gt;export PROVIDER_API_KEY="your_api_key_here" 
# Replace PROVIDER_API_KEY with the specific variable name, e.g., OPENAI_API_KEY, GOOGLE_API_KEY
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Example for TogetherAI:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-sh"&gt;export TOGETHER_API_KEY="xxxxxxxxxxxxxxxxxxxxxx"
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Windows:&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Command Prompt (Temporary for current session):&lt;/strong&gt; &lt;pre&gt;&lt;code class="language-cmd"&gt;set PROVIDER_API_KEY=your_api_key_here
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;PowerShell (Temporary for current session):&lt;/strong&gt; &lt;pre&gt;&lt;code class="language-powershell"&gt;$env:PROVIDER_API_KEY="your_api_key_here"
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Permanently:&lt;/strong&gt; Search for "environment variables" in the Windows search bar, click "Edit the system environment variables," then click the "Environment Variables..." button. Add a new User variable with the appropriate name (e.g., &lt;code&gt;OPENAI_API_KEY&lt;/code&gt;) and your key as the value.&lt;/li&gt; 
  &lt;/ul&gt; &lt;p&gt;&lt;em&gt;(See FAQ: &lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#how-do-i-set-api-keys"&gt;How do I set API keys?&lt;/a&gt; for more details).&lt;/em&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;3. Update &lt;code&gt;config.ini&lt;/code&gt;:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-ini"&gt;[MAIN]
is_local = False
provider_name = openai # Or google, deepseek, togetherAI, huggingface
provider_model = gpt-3.5-turbo # Or gemini-1.5-flash, deepseek-chat, mistralai/Mixtral-8x7B-Instruct-v0.1 etc.
provider_server_address = # Typically ignored or can be left blank when is_local = False for most APIs
# ... other settings ...
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;em&gt;Warning:&lt;/em&gt; Make sure there are no trailing spaces in the &lt;code&gt;config.ini&lt;/code&gt; values.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;List of API Providers&lt;/strong&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Provider&lt;/th&gt; 
   &lt;th&gt;&lt;code&gt;provider_name&lt;/code&gt;&lt;/th&gt; 
   &lt;th&gt;Local?&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;API Key Link (Examples)&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;OpenAI&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;openai&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;Use ChatGPT models via OpenAI's API.&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://platform.openai.com/signup"&gt;platform.openai.com/signup&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Google Gemini&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;google&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;Use Google Gemini models via Google AI Studio.&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aistudio.google.com/keys"&gt;aistudio.google.com/keys&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Deepseek&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;deepseek&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;Use Deepseek models via their API.&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://platform.deepseek.com"&gt;platform.deepseek.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Hugging Face&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;huggingface&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;Use models from Hugging Face Inference API.&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/settings/tokens"&gt;huggingface.co/settings/tokens&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;TogetherAI&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;togetherAI&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;Use various open-source models via TogetherAI API.&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://api.together.ai/settings/api-keys"&gt;api.together.ai/settings/api-keys&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;OpenRouter&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;openrouter&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;Use OpenRouter Models&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://openrouter.ai/"&gt;https://openrouter.ai/&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;em&gt;Note:&lt;/em&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;We advise against using &lt;code&gt;gpt-4o&lt;/code&gt; or other OpenAI models for complex web browsing and task planning as current prompt optimizations are geared towards models like Deepseek.&lt;/li&gt; 
 &lt;li&gt;Coding/bash tasks might encounter issues with Gemini, as it may not strictly follow formatting prompts optimized for Deepseek.&lt;/li&gt; 
 &lt;li&gt;The &lt;code&gt;provider_server_address&lt;/code&gt; in &lt;code&gt;config.ini&lt;/code&gt; is generally not used when &lt;code&gt;is_local = False&lt;/code&gt; as the API endpoint is usually hardcoded in the respective provider's library.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Next step: &lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#Start-services-and-Run"&gt;Start services and run AgenticSeek&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;See the &lt;strong&gt;Known issues&lt;/strong&gt; section if you are having issues&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;See the &lt;strong&gt;Config&lt;/strong&gt; section for detailed config file explanation.&lt;/em&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Start services and Run&lt;/h2&gt; 
&lt;p&gt;By default AgenticSeek is run fully in docker.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Option 1:&lt;/strong&gt; Run in Docker, use web interface:&lt;/p&gt; 
&lt;p&gt;Start required services. This will start all services from the docker-compose.yml, including: - searxng - redis (required by searxng) - frontend - backend (if using &lt;code&gt;full&lt;/code&gt; when using the web interface)&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;./start_services.sh full # MacOS
start start_services.cmd full # Window
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Warning:&lt;/strong&gt; This step will download and load all Docker images, which may take up to 30 minutes. After starting the services, please wait until the backend service is fully running (you should see &lt;strong&gt;backend: "GET /health HTTP/1.1" 200 OK&lt;/strong&gt; in the log) before sending any messages. The backend services might take 5 minute to start on first run.&lt;/p&gt; 
&lt;p&gt;Go to &lt;code&gt;http://localhost:3000/&lt;/code&gt; and you should see the web interface.&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;Troubleshooting service start:&lt;/em&gt; If these scripts fail, ensure Docker Engine is running and Docker Compose (V2, &lt;code&gt;docker compose&lt;/code&gt;) is correctly installed. Check the output in the terminal for error messages. See &lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#faq-troubleshooting"&gt;FAQ: Help! I get an error when running AgenticSeek or its scripts.&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Option 2:&lt;/strong&gt; CLI mode:&lt;/p&gt; 
&lt;p&gt;To run with CLI interface you would have to install package on host:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;./install.sh
./install.bat # windows
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then you must change the SEARXNG_BASE_URL in &lt;code&gt;config.ini&lt;/code&gt; to:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;SEARXNG_BASE_URL="http://localhost:8080"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Start required services. This will start some services from the docker-compose.yml, including: - searxng - redis (required by searxng) - frontend&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;./start_services.sh # MacOS
start start_services.cmd # Window
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Run: uv run: &lt;code&gt;uv run python -m ensurepip&lt;/code&gt; to ensure uv has pip enabled.&lt;/p&gt; 
&lt;p&gt;Use the CLI: &lt;code&gt;uv run cli.py&lt;/code&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;p&gt;Make sure the services are up and running with &lt;code&gt;./start_services.sh full&lt;/code&gt; and go to &lt;code&gt;localhost:3000&lt;/code&gt; for web interface.&lt;/p&gt; 
&lt;p&gt;You can also use speech to text by setting &lt;code&gt;listen = True&lt;/code&gt; in the config. Only for CLI mode.&lt;/p&gt; 
&lt;p&gt;To exit, simply say/type &lt;code&gt;goodbye&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Here are some example usage:&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;em&gt;Make a snake game in python!&lt;/em&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;em&gt;Search the web for top cafes in Rennes, France, and save a list of three with their addresses in rennes_cafes.txt.&lt;/em&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;em&gt;Write a Go program to calculate the factorial of a number, save it as factorial.go in your workspace&lt;/em&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;em&gt;Search my summer_pictures folder for all JPG files, rename them with today‚Äôs date, and save a list of renamed files in photos_list.txt&lt;/em&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;em&gt;Search online for popular sci-fi movies from 2024 and pick three to watch tonight. Save the list in movie_night.txt.&lt;/em&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;em&gt;Search the web for the latest AI news articles from 2025, select three, and write a Python script to scrape their titles and summaries. Save the script as news_scraper.py and the summaries in ai_news.txt in /home/projects&lt;/em&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;em&gt;Friday, search the web for a free stock price API, register with &lt;a href="mailto:supersuper7434567@gmail.com"&gt;supersuper7434567@gmail.com&lt;/a&gt; then write a Python script to fetch using the API daily prices for Tesla, and save the results in stock_prices.csv&lt;/em&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;em&gt;Note that form filling capabilities are still experimental and might fail.&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;After you type your query, AgenticSeek will allocate the best agent for the task.&lt;/p&gt; 
&lt;p&gt;Because this is an early prototype, the agent routing system might not always allocate the right agent based on your query.&lt;/p&gt; 
&lt;p&gt;Therefore, you should be very explicit in what you want and how the AI might proceed for example if you want it to conduct a web search, do not say:&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;Do you know some good countries for solo-travel?&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;Instead, ask:&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;Do a web search and find out which are the best country for solo-travel&lt;/code&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;&lt;strong&gt;Setup to run the LLM on your own server&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;If you have a powerful computer or a server that you can use, but you want to use it from your laptop you have the options to run the LLM on a remote server using our custom llm server.&lt;/p&gt; 
&lt;p&gt;On your "server" that will run the AI model, get the ip address&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;ip a | grep "inet " | grep -v 127.0.0.1 | awk '{print $2}' | cut -d/ -f1 # local ip
curl https://ipinfo.io/ip # public ip
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Note: For Windows or macOS, use ipconfig or ifconfig respectively to find the IP address.&lt;/p&gt; 
&lt;p&gt;Clone the repository and enter the &lt;code&gt;server/&lt;/code&gt;folder.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;git clone --depth 1 https://github.com/Fosowl/agenticSeek.git
cd agenticSeek/llm_server/
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Install server specific requirements:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;pip3 install -r requirements.txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Run the server script.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;python3 app.py --provider ollama --port 3333
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You have the choice between using &lt;code&gt;ollama&lt;/code&gt; and &lt;code&gt;llamacpp&lt;/code&gt; as a LLM service.&lt;/p&gt; 
&lt;p&gt;Now on your personal computer:&lt;/p&gt; 
&lt;p&gt;Change the &lt;code&gt;config.ini&lt;/code&gt; file to set the &lt;code&gt;provider_name&lt;/code&gt; to &lt;code&gt;server&lt;/code&gt; and &lt;code&gt;provider_model&lt;/code&gt; to &lt;code&gt;deepseek-r1:xxb&lt;/code&gt;. Set the &lt;code&gt;provider_server_address&lt;/code&gt; to the ip address of the machine that will run the model.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;[MAIN]
is_local = False
provider_name = server
provider_model = deepseek-r1:70b
provider_server_address = http://x.x.x.x:3333
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Next step: &lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#Start-services-and-Run"&gt;Start services and run AgenticSeek&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Speech to Text&lt;/h2&gt; 
&lt;p&gt;Warning: speech to text only work in CLI mode at the moment.&lt;/p&gt; 
&lt;p&gt;Please note that currently speech to text only work in english.&lt;/p&gt; 
&lt;p&gt;The speech-to-text functionality is disabled by default. To enable it, set the listen option to True in the config.ini file:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;listen = True
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;When enabled, the speech-to-text feature listens for a trigger keyword, which is the agent's name, before it begins processing your input. You can customize the agent's name by updating the &lt;code&gt;agent_name&lt;/code&gt; value in the &lt;em&gt;config.ini&lt;/em&gt; file:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;agent_name = Friday
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For optimal recognition, we recommend using a common English name like "John" or "Emma" as the agent name&lt;/p&gt; 
&lt;p&gt;Once you see the transcript start to appear, say the agent's name aloud to wake it up (e.g., "Friday").&lt;/p&gt; 
&lt;p&gt;Speak your query clearly.&lt;/p&gt; 
&lt;p&gt;End your request with a confirmation phrase to signal the system to proceed. Examples of confirmation phrases include:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;"do it", "go ahead", "execute", "run", "start", "thanks", "would ya", "please", "okay?", "proceed", "continue", "go on", "do that", "go it", "do you understand?"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Config&lt;/h2&gt; 
&lt;p&gt;Example config:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;[MAIN]
is_local = True
provider_name = ollama
provider_model = deepseek-r1:32b
provider_server_address = http://127.0.0.1:11434 # Example for Ollama; use http://127.0.0.1:1234 for LM-Studio
agent_name = Friday
recover_last_session = False
save_session = False
speak = False
listen = False

jarvis_personality = False
languages = en zh # List of languages for TTS and potentially routing.
[BROWSER]
headless_browser = False
stealth_mode = False
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Explanation of &lt;code&gt;config.ini&lt;/code&gt; Settings&lt;/strong&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;[MAIN]&lt;/code&gt; Section:&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;is_local&lt;/code&gt;: &lt;code&gt;True&lt;/code&gt; if using a local LLM provider (Ollama, LM-Studio, local OpenAI-compatible server) or the self-hosted server option. &lt;code&gt;False&lt;/code&gt; if using a cloud-based API (OpenAI, Google, etc.).&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;provider_name&lt;/code&gt;: Specifies the LLM provider. 
    &lt;ul&gt; 
     &lt;li&gt;Local options: &lt;code&gt;ollama&lt;/code&gt;, &lt;code&gt;lm-studio&lt;/code&gt;, &lt;code&gt;openai&lt;/code&gt; (for local OpenAI-compatible servers), &lt;code&gt;server&lt;/code&gt; (for the self-hosted server setup).&lt;/li&gt; 
     &lt;li&gt;API options: &lt;code&gt;openai&lt;/code&gt;, &lt;code&gt;google&lt;/code&gt;, &lt;code&gt;deepseek&lt;/code&gt;, &lt;code&gt;huggingface&lt;/code&gt;, &lt;code&gt;togetherAI&lt;/code&gt;.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;provider_model&lt;/code&gt;: The specific model name or ID for the chosen provider (e.g., &lt;code&gt;deepseekcoder:6.7b&lt;/code&gt; for Ollama, &lt;code&gt;gpt-3.5-turbo&lt;/code&gt; for OpenAI API, &lt;code&gt;mistralai/Mixtral-8x7B-Instruct-v0.1&lt;/code&gt; for TogetherAI).&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;provider_server_address&lt;/code&gt;: The address of your LLM provider. 
    &lt;ul&gt; 
     &lt;li&gt;For local providers: e.g., &lt;code&gt;http://127.0.0.1:11434&lt;/code&gt; for Ollama, &lt;code&gt;http://127.0.0.1:1234&lt;/code&gt; for LM-Studio.&lt;/li&gt; 
     &lt;li&gt;For the &lt;code&gt;server&lt;/code&gt; provider type: The address of your self-hosted LLM server (e.g., &lt;code&gt;http://your_server_ip:3333&lt;/code&gt;).&lt;/li&gt; 
     &lt;li&gt;For cloud APIs (&lt;code&gt;is_local = False&lt;/code&gt;): This is often ignored or can be left blank, as the API endpoint is usually handled by the client library.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;agent_name&lt;/code&gt;: Name of the AI assistant (e.g., Friday). Used as a trigger word for speech-to-text if enabled.&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;recover_last_session&lt;/code&gt;: &lt;code&gt;True&lt;/code&gt; to attempt to restore the previous session's state, &lt;code&gt;False&lt;/code&gt; to start fresh.&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;save_session&lt;/code&gt;: &lt;code&gt;True&lt;/code&gt; to save the current session's state for potential recovery, &lt;code&gt;False&lt;/code&gt; otherwise.&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;speak&lt;/code&gt;: &lt;code&gt;True&lt;/code&gt; to enable text-to-speech voice output, &lt;code&gt;False&lt;/code&gt; to disable.&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;listen&lt;/code&gt;: &lt;code&gt;True&lt;/code&gt; to enable speech-to-text voice input (CLI mode only), &lt;code&gt;False&lt;/code&gt; to disable.&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;work_dir&lt;/code&gt;: &lt;strong&gt;Crucial:&lt;/strong&gt; The directory where AgenticSeek will read/write files. &lt;strong&gt;Ensure this path is valid and accessible on your system.&lt;/strong&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;jarvis_personality&lt;/code&gt;: &lt;code&gt;True&lt;/code&gt; to use a more "Jarvis-like" system prompt (experimental), &lt;code&gt;False&lt;/code&gt; for the standard prompt.&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;languages&lt;/code&gt;: A comma-separated list of languages (e.g., &lt;code&gt;en, zh, fr&lt;/code&gt;). Used for TTS voice selection (defaults to the first) and can assist the LLM router. Avoid too many or very similar languages for router efficiency.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;[BROWSER]&lt;/code&gt; Section:&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;headless_browser&lt;/code&gt;: &lt;code&gt;True&lt;/code&gt; to run the automated browser without a visible window (recommended for web interface or non-interactive use). &lt;code&gt;False&lt;/code&gt; to show the browser window (useful for CLI mode or debugging).&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;stealth_mode&lt;/code&gt;: &lt;code&gt;True&lt;/code&gt; to enable measures to make browser automation harder to detect. May require manual installation of browser extensions like anticaptcha.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;This section summarizes the supported LLM provider types. Configure them in &lt;code&gt;config.ini&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Local Providers (Run on Your Own Hardware):&lt;/strong&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Provider Name in &lt;code&gt;config.ini&lt;/code&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;code&gt;is_local&lt;/code&gt;&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Setup Section&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;ollama&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;True&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Use Ollama to serve local LLMs.&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#setup-for-running-llm-locally-on-your-machine"&gt;Setup for running LLM locally&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;lm-studio&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;True&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Use LM-Studio to serve local LLMs.&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#setup-for-running-llm-locally-on-your-machine"&gt;Setup for running LLM locally&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;openai&lt;/code&gt; (for local server)&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;True&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Connect to a local server that exposes an OpenAI-compatible API (e.g., llama.cpp).&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#setup-for-running-llm-locally-on-your-machine"&gt;Setup for running LLM locally&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;server&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;False&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Connect to the AgenticSeek self-hosted LLM server running on another machine.&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#setup-to-run-the-llm-on-your-own-server"&gt;Setup to run the LLM on your own server&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;API Providers (Cloud-Based):&lt;/strong&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Provider Name in &lt;code&gt;config.ini&lt;/code&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;code&gt;is_local&lt;/code&gt;&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Setup Section&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;openai&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;False&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Use OpenAI's official API (e.g., GPT-3.5, GPT-4).&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#setup-to-run-with-an-api"&gt;Setup to run with an API&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;google&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;False&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Use Google's Gemini models via API.&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#setup-to-run-with-an-api"&gt;Setup to run with an API&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;deepseek&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;False&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Use Deepseek's official API.&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#setup-to-run-with-an-api"&gt;Setup to run with an API&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;huggingface&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;False&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Use Hugging Face Inference API.&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#setup-to-run-with-an-api"&gt;Setup to run with an API&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;togetherAI&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;False&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Use TogetherAI's API for various open models.&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#setup-to-run-with-an-api"&gt;Setup to run with an API&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Troubleshooting&lt;/h2&gt; 
&lt;p&gt;If you encounter issues, this section provides guidance.&lt;/p&gt; 
&lt;h1&gt;Known Issues&lt;/h1&gt; 
&lt;h2&gt;ChromeDriver Issues&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Error Example:&lt;/strong&gt; &lt;code&gt;SessionNotCreatedException: Message: session not created: This version of ChromeDriver only supports Chrome version XXX&lt;/code&gt;&lt;/p&gt; 
&lt;h3&gt;Root Cause&lt;/h3&gt; 
&lt;p&gt;ChromeDriver version incompatibility occurs when:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Your installed ChromeDriver version doesn't match your Chrome browser version&lt;/li&gt; 
 &lt;li&gt;In Docker environments, &lt;code&gt;undetected_chromedriver&lt;/code&gt; may download its own ChromeDriver version, bypassing the mounted binary&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Solution Steps&lt;/h3&gt; 
&lt;h4&gt;1. Check Your Chrome Version&lt;/h4&gt; 
&lt;p&gt;Open Google Chrome ‚Üí &lt;code&gt;Settings &amp;gt; About Chrome&lt;/code&gt; to find your version (e.g., "Version 134.0.6998.88")&lt;/p&gt; 
&lt;h4&gt;2. Download Matching ChromeDriver&lt;/h4&gt; 
&lt;p&gt;&lt;strong&gt;For Chrome 115 and newer:&lt;/strong&gt; Use the &lt;a href="https://googlechromelabs.github.io/chrome-for-testing/"&gt;Chrome for Testing API&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Visit the Chrome for Testing availability dashboard&lt;/li&gt; 
 &lt;li&gt;Find your Chrome version or the closest available match&lt;/li&gt; 
 &lt;li&gt;Download the ChromeDriver for your OS (Linux64 for Docker environments)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;For older Chrome versions:&lt;/strong&gt; Use the &lt;a href="https://chromedriver.chromium.org/downloads"&gt;legacy ChromeDriver downloads&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/media/chromedriver_readme.png" alt="Download ChromeDriver from Chrome for Testing" /&gt;&lt;/p&gt; 
&lt;h4&gt;3. Install ChromeDriver (Choose One Method)&lt;/h4&gt; 
&lt;p&gt;&lt;strong&gt;Method A: Project Root Directory (Recommended for Docker)&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Place the downloaded chromedriver binary in your project root
cp path/to/downloaded/chromedriver ./chromedriver
chmod +x ./chromedriver  # Make executable on Linux/macOS
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Method B: System PATH&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Linux/macOS
sudo mv chromedriver /usr/local/bin/
sudo chmod +x /usr/local/bin/chromedriver

# Windows: Place chromedriver.exe in a folder that's in your PATH
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;4. Verify Installation&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Test the ChromeDriver version
./chromedriver --version
# OR if in PATH:
chromedriver --version
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Docker-Specific Notes&lt;/h3&gt; 
&lt;p&gt;‚ö†Ô∏è &lt;strong&gt;Important for Docker Users:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;The Docker volume mount approach may not work with stealth mode (&lt;code&gt;undetected_chromedriver&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Solution&lt;/strong&gt;: Place ChromeDriver in the project root directory as &lt;code&gt;./chromedriver&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;The application will automatically detect and use this binary&lt;/li&gt; 
 &lt;li&gt;You should see: &lt;code&gt;"Using ChromeDriver from project root: ./chromedriver"&lt;/code&gt; in the logs&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Troubleshooting Tips&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Still getting version mismatch?&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Verify the ChromeDriver is executable: &lt;code&gt;ls -la ./chromedriver&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;Check the ChromeDriver version: &lt;code&gt;./chromedriver --version&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;Ensure it matches your Chrome browser version&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Docker container issues?&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Check backend logs: &lt;code&gt;docker logs backend&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;Look for the message: &lt;code&gt;"Using ChromeDriver from project root"&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;If not found, verify the file exists and is executable&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Chrome for Testing versions&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Use the exact version match when possible&lt;/li&gt; 
   &lt;li&gt;For version 134.0.6998.88, use ChromeDriver 134.0.6998.165 (closest available)&lt;/li&gt; 
   &lt;li&gt;Major version numbers must match (134 = 134)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Version Compatibility Matrix&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Chrome Version&lt;/th&gt; 
   &lt;th&gt;ChromeDriver Version&lt;/th&gt; 
   &lt;th&gt;Status&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;134.0.6998.x&lt;/td&gt; 
   &lt;td&gt;134.0.6998.165&lt;/td&gt; 
   &lt;td&gt;‚úÖ Works&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;133.0.6943.x&lt;/td&gt; 
   &lt;td&gt;133.0.6943.141&lt;/td&gt; 
   &lt;td&gt;‚úÖ Works&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;132.0.6834.x&lt;/td&gt; 
   &lt;td&gt;132.0.6834.159&lt;/td&gt; 
   &lt;td&gt;‚úÖ Works&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;em&gt;For the latest compatibility, check the &lt;a href="https://googlechromelabs.github.io/chrome-for-testing/"&gt;Chrome for Testing dashboard&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;Exception: Failed to initialize browser: Message: session not created: This version of ChromeDriver only supports Chrome version 113 Current browser version is 134.0.6998.89 with binary path&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;This happen if there is a mismatch between your browser and chromedriver version.&lt;/p&gt; 
&lt;p&gt;You need to navigate to download the latest version:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://developer.chrome.com/docs/chromedriver/downloads"&gt;https://developer.chrome.com/docs/chromedriver/downloads&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;If you're using Chrome version 115 or newer go to:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://googlechromelabs.github.io/chrome-for-testing/"&gt;https://googlechromelabs.github.io/chrome-for-testing/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;And download the chromedriver version matching your OS.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/media/chromedriver_readme.png" alt="alt text" /&gt;&lt;/p&gt; 
&lt;p&gt;If this section is incomplete please raise an issue.&lt;/p&gt; 
&lt;h2&gt;connection adapters Issues&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;Exception: Provider lm-studio failed: HTTP request failed: No connection adapters were found for '127.0.0.1:1234/v1/chat/completions'` (Note: port may vary)
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Cause:&lt;/strong&gt; The &lt;code&gt;provider_server_address&lt;/code&gt; in &lt;code&gt;config.ini&lt;/code&gt; for &lt;code&gt;lm-studio&lt;/code&gt; (or other similar local OpenAI-compatible servers) is missing the &lt;code&gt;http://&lt;/code&gt; prefix or is pointing to the wrong port.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Solution:&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Ensure the address includes &lt;code&gt;http://&lt;/code&gt;. LM-Studio typically defaults to &lt;code&gt;http://127.0.0.1:1234&lt;/code&gt;.&lt;/li&gt; 
   &lt;li&gt;Correct &lt;code&gt;config.ini&lt;/code&gt;: &lt;code&gt;provider_server_address = http://127.0.0.1:1234&lt;/code&gt; (or your actual LM-Studio server port).&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;SearxNG Base URL Not Provided&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;raise ValueError("SearxNG base URL must be provided either as an argument or via the SEARXNG_BASE_URL environment variable.")
ValueError: SearxNG base URL must be provided either as an argument or via the SEARXNG_BASE_URL environment variable.`
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This might arise if you are running the CLI mode with the wrong base url for searxng.&lt;/p&gt; 
&lt;p&gt;The SEARXNG_BASE_URL should be depending on whenever you run in docker or on host:&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Run on host&lt;/strong&gt;: &lt;code&gt;SEARXNG_BASE_URL="http://localhost:8080"&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Run fully in docker (web interface)&lt;/strong&gt;: &lt;code&gt;SEARXNG_BASE_URL="http://searxng:8080"&lt;/code&gt;&lt;/p&gt; 
&lt;h2&gt;FAQ&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Q: What hardware do I need?&lt;/strong&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Model Size&lt;/th&gt; 
   &lt;th&gt;GPU&lt;/th&gt; 
   &lt;th&gt;Comment&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;7B&lt;/td&gt; 
   &lt;td&gt;8GB Vram&lt;/td&gt; 
   &lt;td&gt;‚ö†Ô∏è Not recommended. Performance is poor, frequent hallucinations, and planner agents will likely fail.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;14B&lt;/td&gt; 
   &lt;td&gt;12 GB VRAM (e.g. RTX 3060)&lt;/td&gt; 
   &lt;td&gt;‚úÖ Usable for simple tasks. May struggle with web browsing and planning tasks.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;32B&lt;/td&gt; 
   &lt;td&gt;24+ GB VRAM (e.g. RTX 4090)&lt;/td&gt; 
   &lt;td&gt;üöÄ Success with most tasks, might still struggle with task planning&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;70B+&lt;/td&gt; 
   &lt;td&gt;48+ GB Vram&lt;/td&gt; 
   &lt;td&gt;üí™ Excellent. Recommended for advanced use cases.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;Q: I get an error what do I do?&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Ensure local is running (&lt;code&gt;ollama serve&lt;/code&gt;), your &lt;code&gt;config.ini&lt;/code&gt; matches your provider, and dependencies are installed. If none work feel free to raise an issue.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Q: Can it really run 100% locally?&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Yes with Ollama, lm-studio or server providers, all speech to text, LLM and text to speech model run locally. Non-local options (OpenAI or others API) are optional.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Q: Why should I use AgenticSeek when I have Manus?&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Unlike Manus, AgenticSeek prioritizes independence from external systems, giving you more control, privacy and avoid api cost.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Q: Who is behind the project ?&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;The project was created by me, along with two friends who serve as maintainers and contributors from the open-source community on GitHub. We‚Äôre just a group of passionate individuals, not a startup or affiliated with any organization.&lt;/p&gt; 
&lt;p&gt;Any AgenticSeek account on X other than my personal account (&lt;a href="https://x.com/Martin993886460"&gt;https://x.com/Martin993886460&lt;/a&gt;) is an impersonation.&lt;/p&gt; 
&lt;h2&gt;Contribute&lt;/h2&gt; 
&lt;p&gt;We‚Äôre looking for developers to improve AgenticSeek! Check out open issues or discussion.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/docs/CONTRIBUTING.md"&gt;Contribution guide&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Sponsors:&lt;/h2&gt; 
&lt;p&gt;Want to level up AgenticSeek capabilities with features like flight search, trip planning, or snagging the best shopping deals? Consider crafting a custom tool with SerpApi to unlock more Jarvis-like capabilities. With SerpApi, you can turbocharge your agent for specialized tasks while staying in full control.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://serpapi.com/"&gt;&lt;img src="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/media/banners/sponsor_banner_serpapi.png" height="350" alt="SerpApi Banner" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/docs/CONTRIBUTING.md"&gt;Contributing.md&lt;/a&gt; to learn how to integrate custom tools!&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;Patron sponsor&lt;/strong&gt;:&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tatra-labs"&gt;tatra-labs&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Maintainers:&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;a href="https://github.com/Fosowl"&gt;Fosowl&lt;/a&gt; | Paris Time&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;a href="https://github.com/antoineVIVIES"&gt;antoineVIVIES&lt;/a&gt; | Taipei Time&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Special Thanks:&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;a href="https://github.com/tcsenpai"&gt;tcsenpai&lt;/a&gt; and &lt;a href="https://github.com/plitc"&gt;plitc&lt;/a&gt; For helping with backend dockerization&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;a href="https://www.star-history.com/#Fosowl/agenticSeek&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=Fosowl/agenticSeek&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>microsoft/agent-lightning</title>
      <link>https://github.com/microsoft/agent-lightning</link>
      <description>&lt;p&gt;The absolute trainer to light up AI agents.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/microsoft/agent-lightning/main/docs/assets/readme-banner.svg?sanitize=true" alt="Agent-lightning-banner" style="width:600px" /&gt; &lt;/p&gt; 
&lt;h1&gt;Agent Lightning‚ö°&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://github.com/microsoft/agent-lightning/actions/workflows/tests-full.yml"&gt;&lt;img src="https://github.com/microsoft/agent-lightning/actions/workflows/tests-full.yml/badge.svg?sanitize=true" alt="Test" /&gt;&lt;/a&gt; &lt;a href="https://microsoft.github.io/agent-lightning/"&gt;&lt;img src="https://img.shields.io/badge/GitHub%20Pages-Documentation-blue" alt="Documentation" /&gt;&lt;/a&gt; &lt;a href="https://badge.fury.io/py/agentlightning"&gt;&lt;img src="https://badge.fury.io/py/agentlightning.svg?sanitize=true" alt="PyPI version" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/microsoft/agent-lightning/main/LICENSE"&gt;&lt;img src="https://img.shields.io/badge/license-MIT-blue.svg?sanitize=true" alt="License" /&gt;&lt;/a&gt; &lt;a href="https://deepwiki.com/microsoft/agent-lightning"&gt;&lt;img src="https://deepwiki.com/badge.svg?sanitize=true" alt="Ask DeepWiki" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/RYk7CdvDR7"&gt;&lt;img src="https://img.shields.io/badge/Discord-Join-5865F2?logo=discord&amp;amp;logoColor=white" alt="Discord" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;The absolute trainer to light up AI agents.&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Join our &lt;a href="https://discord.gg/RYk7CdvDR7"&gt;Discord community&lt;/a&gt; to connect with other users and contributors.&lt;/p&gt; 
&lt;h2&gt;‚ö° Core Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Turn your agent into an optimizable beast with &lt;strong&gt;ZERO CODE CHANGE&lt;/strong&gt; (almost)! üí§&lt;/li&gt; 
 &lt;li&gt;Build with &lt;strong&gt;ANY&lt;/strong&gt; agent framework (LangChain, OpenAI Agent SDK, AutoGen, CrewAI, Microsoft Agent Framework...); or even WITHOUT agent framework (Python OpenAI). You name it! ü§ñ&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Selectively&lt;/strong&gt; optimize one or more agents in a multi-agent system. üéØ&lt;/li&gt; 
 &lt;li&gt;Embraces &lt;strong&gt;Algorithms&lt;/strong&gt; like Reinforcement Learning, Automatic Prompt Optimization, Supervised Fine-tuning and more. ü§ó&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Read more on our &lt;a href="https://microsoft.github.io/agent-lightning/"&gt;documentation website&lt;/a&gt;.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/microsoft/agent-lightning/main/docs/assets/readme-diff.svg?sanitize=true" alt="Agent-Lightning Core Quickstart" style="width:100%" /&gt; &lt;/p&gt; 
&lt;h2&gt;‚ö° Installation&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install agentlightning
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Please refer to our &lt;a href="https://microsoft.github.io/agent-lightning/stable/tutorials/installation/"&gt;installation guide&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;p&gt;To start using Agent-lightning, check out our &lt;a href="https://microsoft.github.io/agent-lightning/"&gt;documentation&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/microsoft/agent-lightning/main/examples"&gt;examples&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;‚ö° Articles&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;11/4/2025 &lt;a href="https://medium.com/@yugez/tuning-any-ai-agent-with-tinker-agent-lightning-part-1-1d8c9a397f0e"&gt;Tuning ANY AI agent with Tinker ‚úï Agent-lightning&lt;/a&gt; Medium. See also &lt;a href="https://medium.com/@yugez/tuning-any-ai-agent-with-tinker-agent-lightning-part-2-332c5437f0dc"&gt;Part 2&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;10/22/2025 &lt;a href="https://blog.vllm.ai/2025/10/22/agent-lightning.html"&gt;No More Retokenization Drift: Returning Token IDs via the OpenAI Compatible API Matters in Agent RL&lt;/a&gt; vLLM blog. See also &lt;a href="https://zhuanlan.zhihu.com/p/1965067274642785725"&gt;Zhihu writeup&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;8/11/2025 &lt;a href="https://medium.com/@yugez/training-ai-agents-to-write-and-self-correct-sql-with-reinforcement-learning-571ed31281ad"&gt;Training AI Agents to Write and Self-correct SQL with Reinforcement Learning&lt;/a&gt; Medium.&lt;/li&gt; 
 &lt;li&gt;8/5/2025 &lt;a href="https://arxiv.org/abs/2508.03680"&gt;Agent Lightning: Train ANY AI Agents with Reinforcement Learning&lt;/a&gt; arXiv paper.&lt;/li&gt; 
 &lt;li&gt;7/26/2025 &lt;a href="https://www.reddit.com/r/LocalLLaMA/comments/1m9m670/we_discovered_an_approach_to_train_any_ai_agent/"&gt;We discovered an approach to train any AI agent with RL, with (almost) zero code changes.&lt;/a&gt; Reddit.&lt;/li&gt; 
 &lt;li&gt;6/6/2025 &lt;a href="https://www.microsoft.com/en-us/research/project/agent-lightning/"&gt;Agent Lightning - Microsoft Research&lt;/a&gt; Project page.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;‚ö° Community Projects&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/af-74413592/DeepWerewolf"&gt;DeepWerewolf&lt;/a&gt; ‚Äî A case study of agent RL training for the Chinese Werewolf game built with AgentScope and Agent Lightning.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://agentflow.stanford.edu/"&gt;AgentFlow&lt;/a&gt; ‚Äî A modular multi-agent framework that combines planner, executor, verifier, and generator agents with the Flow-GRPO algorithm to tackle long-horizon, sparse-reward tasks.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;‚ö° Architecture&lt;/h2&gt; 
&lt;p&gt;Agent Lightning keeps the moving parts to a minimum so you can focus on your idea, not the plumbing. Your agent continues to run as usual; you can still use any agent framework you like; you drop in the lightweight &lt;code&gt;agl.emit_xxx()&lt;/code&gt; helper, or let the tracer collect every prompt, tool call, and reward. Those events become structured spans that flow into the LightningStore, a central hub that keeps tasks, resources, and traces in sync.&lt;/p&gt; 
&lt;p&gt;On the other side of the store sits the algorithm you choose, or write yourself. The algorithm reads spans, learns from them, and posts updated resources such as refined prompt templates or new policy weights. The Trainer ties it all together: it streams datasets to runners, ferries resources between the store and the algorithm, and updates the inference engine when improvements land. You can either stop there, or simply let the same loop keep turning.&lt;/p&gt; 
&lt;p&gt;No rewrites, no lock-in, just a clear path from first rollout to steady improvement.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/microsoft/agent-lightning/main/docs/assets/readme-architecture.svg?sanitize=true" alt="Agent-lightning Architecture" style="width:100%" /&gt; &lt;/p&gt; 
&lt;h2&gt;‚ö° CI Status&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Workflow&lt;/th&gt; 
   &lt;th&gt;Status&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;CPU Tests&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/microsoft/agent-lightning/actions/workflows/tests.yml"&gt;&lt;img src="https://github.com/microsoft/agent-lightning/actions/workflows/tests.yml/badge.svg?sanitize=true" alt="tests workflow status" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GPU Tests&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/microsoft/agent-lightning/actions/workflows/tests-full.yml"&gt;&lt;img src="https://github.com/microsoft/agent-lightning/actions/workflows/tests-full.yml/badge.svg?sanitize=true" alt="tests-full workflow status" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Examples Integration&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/microsoft/agent-lightning/actions/workflows/badge-examples.yml"&gt;&lt;img src="https://github.com/microsoft/agent-lightning/actions/workflows/badge-examples.yml/badge.svg?sanitize=true" alt="examples summary workflow status" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Latest Dependency Compatibility&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/microsoft/agent-lightning/actions/workflows/badge-latest.yml"&gt;&lt;img src="https://github.com/microsoft/agent-lightning/actions/workflows/badge-latest.yml/badge.svg?sanitize=true" alt="latest summary workflow status" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Legacy Examples Compatibility&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/microsoft/agent-lightning/actions/workflows/examples-compat.yml"&gt;&lt;img src="https://github.com/microsoft/agent-lightning/actions/workflows/examples-compat.yml/badge.svg?sanitize=true" alt="examples compatibility workflow status" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;‚ö° Citation&lt;/h2&gt; 
&lt;p&gt;If you find Agent Lightning useful in your research or projects, please cite our paper:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bibtex"&gt;@misc{luo2025agentlightningtrainai,
      title={Agent Lightning: Train ANY AI Agents with Reinforcement Learning},
      author={Xufang Luo and Yuge Zhang and Zhiyuan He and Zilong Wang and Siyun Zhao and Dongsheng Li and Luna K. Qiu and Yuqing Yang},
      year={2025},
      eprint={2508.03680},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2508.03680},
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;‚ö° Contributing&lt;/h2&gt; 
&lt;p&gt;This project welcomes contributions and suggestions. Start by reading the &lt;a href="https://raw.githubusercontent.com/microsoft/agent-lightning/main/docs/community/contributing.md"&gt;Contributing Guide&lt;/a&gt; for environment setup, branching conventions, and pull request expectations. Most contributions require you to agree to a Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us the rights to use your contribution. For details, visit &lt;a href="https://cla.opensource.microsoft.com"&gt;https://cla.opensource.microsoft.com&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;When you submit a pull request, a CLA bot will automatically determine whether you need to provide a CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions provided by the bot. You will only need to do this once across all repos using our CLA.&lt;/p&gt; 
&lt;p&gt;This project has adopted the &lt;a href="https://opensource.microsoft.com/codeofconduct/"&gt;Microsoft Open Source Code of Conduct&lt;/a&gt;. For more information see the &lt;a href="https://opensource.microsoft.com/codeofconduct/faq/"&gt;Code of Conduct FAQ&lt;/a&gt; or contact &lt;a href="mailto:opencode@microsoft.com"&gt;opencode@microsoft.com&lt;/a&gt; with any additional questions or comments.&lt;/p&gt; 
&lt;h2&gt;‚ö° Trademarks&lt;/h2&gt; 
&lt;p&gt;This project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft trademarks or logos is subject to and must follow &lt;a href="https://www.microsoft.com/en-us/legal/intellectualproperty/trademarks/usage/general"&gt;Microsoft's Trademark &amp;amp; Brand Guidelines&lt;/a&gt;. Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship. Any use of third-party trademarks or logos are subject to those third-party's policies.&lt;/p&gt; 
&lt;h2&gt;‚ö° Responsible AI&lt;/h2&gt; 
&lt;p&gt;This project has been evaluated and certified to comply with the Microsoft Responsible AI Standard. The team will continue to monitor and maintain the repository, addressing any severe issues, including potential harms, if they arise.&lt;/p&gt; 
&lt;h2&gt;‚ö° License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the MIT License. See the &lt;a href="https://raw.githubusercontent.com/microsoft/agent-lightning/main/LICENSE"&gt;LICENSE&lt;/a&gt; file for details.&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>