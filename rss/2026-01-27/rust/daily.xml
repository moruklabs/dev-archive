<rss version="2.0">
  <channel>
    <title>GitHub Rust Daily Trending</title>
    <description>Daily Trending of Rust in GitHub</description>
    <pubDate>Mon, 26 Jan 2026 01:40:24 GMT</pubDate>
    <link>http://mshibanami.github.io/GitHubTrendingRSS</link>
    
    <item>
      <title>openai/codex</title>
      <link>https://github.com/openai/codex</link>
      <description>&lt;p&gt;Lightweight coding agent that runs in your terminal&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt;&lt;code&gt;npm i -g @openai/codex&lt;/code&gt;&lt;br /&gt;or &lt;code&gt;brew install --cask codex&lt;/code&gt;&lt;/p&gt; 
&lt;p align="center"&gt;&lt;strong&gt;Codex CLI&lt;/strong&gt; is a coding agent from OpenAI that runs locally on your computer. &lt;/p&gt;
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/openai/codex/main/.github/codex-cli-splash.png" alt="Codex CLI splash" width="80%" /&gt; &lt;/p&gt; 
&lt;br /&gt; If you want Codex in your code editor (VS Code, Cursor, Windsurf), 
&lt;a href="https://developers.openai.com/codex/ide"&gt;install in your IDE.&lt;/a&gt; 
&lt;br /&gt;If you are looking for the 
&lt;em&gt;cloud-based agent&lt;/em&gt; from OpenAI, 
&lt;strong&gt;Codex Web&lt;/strong&gt;, go to 
&lt;a href="https://chatgpt.com/codex"&gt;chatgpt.com/codex&lt;/a&gt;.
&lt;p&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Quickstart&lt;/h2&gt; 
&lt;h3&gt;Installing and running Codex CLI&lt;/h3&gt; 
&lt;p&gt;Install globally with your preferred package manager:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;# Install using npm
npm install -g @openai/codex
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;# Install using Homebrew
brew install --cask codex
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then simply run &lt;code&gt;codex&lt;/code&gt; to get started.&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;You can also go to the &lt;a href="https://github.com/openai/codex/releases/latest"&gt;latest GitHub Release&lt;/a&gt; and download the appropriate binary for your platform.&lt;/summary&gt; 
 &lt;p&gt;Each GitHub Release contains many executables, but in practice, you likely want one of these:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;macOS 
   &lt;ul&gt; 
    &lt;li&gt;Apple Silicon/arm64: &lt;code&gt;codex-aarch64-apple-darwin.tar.gz&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;x86_64 (older Mac hardware): &lt;code&gt;codex-x86_64-apple-darwin.tar.gz&lt;/code&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;Linux 
   &lt;ul&gt; 
    &lt;li&gt;x86_64: &lt;code&gt;codex-x86_64-unknown-linux-musl.tar.gz&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;arm64: &lt;code&gt;codex-aarch64-unknown-linux-musl.tar.gz&lt;/code&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;Each archive contains a single entry with the platform baked into the name (e.g., &lt;code&gt;codex-x86_64-unknown-linux-musl&lt;/code&gt;), so you likely want to rename it to &lt;code&gt;codex&lt;/code&gt; after extracting it.&lt;/p&gt; 
&lt;/details&gt; 
&lt;h3&gt;Using Codex with your ChatGPT plan&lt;/h3&gt; 
&lt;p&gt;Run &lt;code&gt;codex&lt;/code&gt; and select &lt;strong&gt;Sign in with ChatGPT&lt;/strong&gt;. We recommend signing into your ChatGPT account to use Codex as part of your Plus, Pro, Team, Edu, or Enterprise plan. &lt;a href="https://help.openai.com/en/articles/11369540-codex-in-chatgpt"&gt;Learn more about what's included in your ChatGPT plan&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;You can also use Codex with an API key, but this requires &lt;a href="https://developers.openai.com/codex/auth#sign-in-with-an-api-key"&gt;additional setup&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Docs&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://developers.openai.com/codex"&gt;&lt;strong&gt;Codex Documentation&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/contributing.md"&gt;&lt;strong&gt;Contributing&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/install.md"&gt;&lt;strong&gt;Installing &amp;amp; building&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/open-source-fund.md"&gt;&lt;strong&gt;Open source fund&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;This repository is licensed under the &lt;a href="https://raw.githubusercontent.com/openai/codex/main/LICENSE"&gt;Apache-2.0 License&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>GraphiteEditor/Graphite</title>
      <link>https://github.com/GraphiteEditor/Graphite</link>
      <description>&lt;p&gt;Open source comprehensive 2D content creation tool suite for graphic design, digital art, and interactive real-time motion graphics ‚Äî featuring node-based procedural editing&lt;/p&gt;&lt;hr&gt;&lt;a href="https://graphite.art/"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://github.com/user-attachments/assets/9366c148-4405-484f-909a-9a3526eb9209" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://github.com/user-attachments/assets/791508ab-bcd5-4e31-a3b9-1187cfd7a2f6" /&gt; 
  &lt;img alt="Graphite logo" src="https://github.com/user-attachments/assets/791508ab-bcd5-4e31-a3b9-1187cfd7a2f6" /&gt; 
 &lt;/picture&gt; &lt;/a&gt; 
&lt;h1&gt;Your procedural toolbox for 2D content creation&lt;/h1&gt; 
&lt;p&gt;&lt;strong&gt;Graphite is a free, open source vector and raster graphics engine, &lt;a href="https://editor.graphite.art"&gt;available now&lt;/a&gt; in alpha. Get creative with a fully nondestructive editing workflow that combines layer-based compositing with node-based generative design.&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Having begun life as a vector editor, Graphite continues evolving into a generalized, all-in-one graphics toolbox that's built more like a game engine than a conventional creative app. The editor's tools wrap its node graph core, providing user-friendly workflows for vector, raster, and beyond. Photo editing, motion graphics, digital painting, desktop publishing, and VFX compositing are additional competencies on the planned &lt;a href="https://graphite.art/features/#roadmap"&gt;roadmap&lt;/a&gt; making Graphite into a highly versatile content creation tool.&lt;/p&gt; 
&lt;p&gt;Learn more from the &lt;a href="https://graphite.art/"&gt;website&lt;/a&gt;, subscribe to the &lt;a href="https://graphite.art/#newsletter"&gt;newsletter&lt;/a&gt;, consider &lt;a href="https://graphite.art/volunteer/"&gt;volunteering&lt;/a&gt; or &lt;a href="https://graphite.art/donate/"&gt;donating&lt;/a&gt;, and remember to give this repository a ‚≠ê!&lt;/p&gt; 
&lt;br /&gt; 
&lt;a href="https://discord.graphite.art/"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://github.com/user-attachments/assets/ad185fac-3b48-446d-863c-2bcb0724abee" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://github.com/user-attachments/assets/aa23f503-f3bf-444a-9080-8eaa19fa2fa8" /&gt; 
  &lt;img alt="Discord" src="https://github.com/user-attachments/assets/aa23f503-f3bf-444a-9080-8eaa19fa2fa8" width="48" height="48" /&gt; 
 &lt;/picture&gt; &lt;/a&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; 
&lt;a href="https://www.reddit.com/r/graphite/"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://github.com/user-attachments/assets/d8c05686-2eb9-4ac1-8149-728c12b4e71a" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://github.com/user-attachments/assets/6f32329a-4d6f-42d8-9a2f-42977c0b3c05" /&gt; 
  &lt;img alt="Reddit" src="https://github.com/user-attachments/assets/6f32329a-4d6f-42d8-9a2f-42977c0b3c05" width="48" height="48" /&gt; 
 &lt;/picture&gt; &lt;/a&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; 
&lt;a href="https://bsky.app/profile/graphiteeditor.bsky.social"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://github.com/user-attachments/assets/c736d80c-e9bf-4591-a7e0-a7723057a906" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://github.com/user-attachments/assets/3db9b0a1-5ab7-4bff-bfd3-8a4ade7b98bd" /&gt; 
  &lt;img alt="Bluesky" src="https://github.com/user-attachments/assets/3db9b0a1-5ab7-4bff-bfd3-8a4ade7b98bd" width="48" height="48" /&gt; 
 &lt;/picture&gt; &lt;/a&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; 
&lt;a href="https://twitter.com/graphiteeditor"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://github.com/user-attachments/assets/115f04cc-e3c2-4f90-ac35-eb9edd3ca9be" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://github.com/user-attachments/assets/4ed4185d-a622-418c-bbf4-a0419e690ca9" /&gt; 
  &lt;img alt="Twitter" src="https://github.com/user-attachments/assets/4ed4185d-a622-418c-bbf4-a0419e690ca9" width="48" height="48" /&gt; 
 &lt;/picture&gt; &lt;/a&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; 
&lt;a href="https://www.youtube.com/@GraphiteEditor"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://github.com/user-attachments/assets/cbc02fad-5cbc-4715-a8e5-860198e989c7" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://github.com/user-attachments/assets/d13b484d-97a8-4d9e-bbe4-c60348b3f676" /&gt; 
  &lt;img alt="YouTube" src="https://github.com/user-attachments/assets/d13b484d-97a8-4d9e-bbe4-c60348b3f676" width="48" height="48" /&gt; 
 &lt;/picture&gt; &lt;/a&gt; 
&lt;br /&gt;
&lt;br /&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/f4604aea-e8f1-45ce-9218-46ddc666f11d"&gt;https://github.com/user-attachments/assets/f4604aea-e8f1-45ce-9218-46ddc666f11d&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Support our mission ‚ù§Ô∏è&lt;/h2&gt; 
&lt;p&gt;Graphite is 100% community built and funded. Please become a part of keeping the project alive and thriving with a &lt;a href="https://graphite.art/donate/"&gt;donation&lt;/a&gt; if you share a belief in our &lt;strong&gt;mission&lt;/strong&gt;:&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Graphite strives to unshackle the creativity of every budding artist and seasoned professional by building the best comprehensive art and design tool that's accessible to all.&lt;/p&gt; 
 &lt;p&gt;Mission success will come when Graphite is an industry standard. A cohesive product vision and focus on innovation over imitation is the strategy that will make that possible.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Screenshots&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/decb7011-18c2-4c68-82af-d1fa5064244a" alt="Made using nondestructive boolean operations and procedural polka dot patterns" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/9e023997-185b-4f43-a724-797d308d9e7b" alt="Mandelbrot fractal filled with a noise pattern, procedurally generated and infinitely scalable" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/90eca551-5868-4f8d-9016-33958bf96345" alt="Design for a magazine spread, a preview of the upcoming focus on desktop publishing" /&gt;&lt;/p&gt; 
&lt;h2&gt;Contributing/building the code&lt;/h2&gt; 
&lt;p&gt;Are you a graphics programmer or Rust developer? Graphite aims to be one of the most approachable projects for putting your engineering skills to use in the world of open source. See &lt;a href="https://graphite.art/volunteer/guide/"&gt;instructions here&lt;/a&gt; for setting up the project and getting started.&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;By submitting code for inclusion in the project, you are agreeing to license your changes under the Apache 2.0 license, and that you have the authority to do so. Some directories may have other licenses, like dual-licensed MIT/Apache 2.0, and code submissions to those directories mean you agree to the applicable license(s).&lt;/em&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>tokio-rs/tokio</title>
      <link>https://github.com/tokio-rs/tokio</link>
      <description>&lt;p&gt;A runtime for writing reliable asynchronous applications with Rust. Provides I/O, networking, scheduling, timers, ...&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Tokio&lt;/h1&gt; 
&lt;p&gt;A runtime for writing reliable, asynchronous, and slim applications with the Rust programming language. It is:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Fast&lt;/strong&gt;: Tokio's zero-cost abstractions give you bare-metal performance.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Reliable&lt;/strong&gt;: Tokio leverages Rust's ownership, type system, and concurrency model to reduce bugs and ensure thread safety.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Scalable&lt;/strong&gt;: Tokio has a minimal footprint, and handles backpressure and cancellation naturally.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://crates.io/crates/tokio"&gt;&lt;img src="https://img.shields.io/crates/v/tokio.svg?sanitize=true" alt="Crates.io" /&gt;&lt;/a&gt; &lt;a href="https://github.com/tokio-rs/tokio/raw/master/LICENSE"&gt;&lt;img src="https://img.shields.io/badge/license-MIT-blue.svg?sanitize=true" alt="MIT licensed" /&gt;&lt;/a&gt; &lt;a href="https://github.com/tokio-rs/tokio/actions?query=workflow%3ACI+branch%3Amaster"&gt;&lt;img src="https://github.com/tokio-rs/tokio/workflows/CI/badge.svg?sanitize=true" alt="Build Status" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/tokio"&gt;&lt;img src="https://img.shields.io/discord/500028886025895936.svg?logo=discord&amp;amp;style=flat-square" alt="Discord chat" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://tokio.rs"&gt;Website&lt;/a&gt; | &lt;a href="https://tokio.rs/tokio/tutorial"&gt;Guides&lt;/a&gt; | &lt;a href="https://docs.rs/tokio/latest/tokio"&gt;API Docs&lt;/a&gt; | &lt;a href="https://discord.gg/tokio"&gt;Chat&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Overview&lt;/h2&gt; 
&lt;p&gt;Tokio is an event-driven, non-blocking I/O platform for writing asynchronous applications with the Rust programming language. At a high level, it provides a few major components:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;A multithreaded, work-stealing based task &lt;a href="https://docs.rs/tokio/latest/tokio/runtime/index.html"&gt;scheduler&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;A reactor backed by the operating system's event queue (epoll, kqueue, IOCP, etc.).&lt;/li&gt; 
 &lt;li&gt;Asynchronous &lt;a href="https://docs.rs/tokio/latest/tokio/net/index.html"&gt;TCP and UDP&lt;/a&gt; sockets.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;These components provide the runtime components necessary for building an asynchronous application.&lt;/p&gt; 
&lt;h2&gt;Example&lt;/h2&gt; 
&lt;p&gt;A basic TCP echo server with Tokio.&lt;/p&gt; 
&lt;p&gt;Make sure you enable the full features of the tokio crate on Cargo.toml:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;[dependencies]
tokio = { version = "1.49.0", features = ["full"] }
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then, on your main.rs:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-rust,no_run"&gt;use tokio::net::TcpListener;
use tokio::io::{AsyncReadExt, AsyncWriteExt};

#[tokio::main]
async fn main() -&amp;gt; Result&amp;lt;(), Box&amp;lt;dyn std::error::Error&amp;gt;&amp;gt; {
    let listener = TcpListener::bind("127.0.0.1:8080").await?;

    loop {
        let (mut socket, _) = listener.accept().await?;

        tokio::spawn(async move {
            let mut buf = [0; 1024];

            // In a loop, read data from the socket and write the data back.
            loop {
                let n = match socket.read(&amp;amp;mut buf).await {
                    // socket closed
                    Ok(0) =&amp;gt; return,
                    Ok(n) =&amp;gt; n,
                    Err(e) =&amp;gt; {
                        eprintln!("failed to read from socket; err = {:?}", e);
                        return;
                    }
                };

                // Write the data back
                if let Err(e) = socket.write_all(&amp;amp;buf[0..n]).await {
                    eprintln!("failed to write to socket; err = {:?}", e);
                    return;
                }
            }
        });
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;More examples can be found &lt;a href="https://github.com/tokio-rs/tokio/tree/master/examples"&gt;here&lt;/a&gt;. For a larger "real world" example, see the &lt;a href="https://github.com/tokio-rs/mini-redis/"&gt;mini-redis&lt;/a&gt; repository.&lt;/p&gt; 
&lt;p&gt;To see a list of the available feature flags that can be enabled, check our &lt;a href="https://docs.rs/tokio/#feature-flags"&gt;docs&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Getting Help&lt;/h2&gt; 
&lt;p&gt;First, see if the answer to your question can be found in the &lt;a href="https://tokio.rs/tokio/tutorial"&gt;Guides&lt;/a&gt; or the &lt;a href="https://docs.rs/tokio/latest/tokio"&gt;API documentation&lt;/a&gt;. If the answer is not there, there is an active community in the &lt;a href="https://discord.gg/tokio"&gt;Tokio Discord server&lt;/a&gt;. We would be happy to try to answer your question. You can also ask your question on &lt;a href="https://github.com/tokio-rs/tokio/discussions"&gt;the discussions page&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;&lt;span&gt;üéà&lt;/span&gt; Thanks for your help improving the project! We are so happy to have you! We have a &lt;a href="https://github.com/tokio-rs/tokio/raw/master/docs/contributing/README.md"&gt;contributing guide&lt;/a&gt; to help you get involved in the Tokio project.&lt;/p&gt; 
&lt;h2&gt;Related Projects&lt;/h2&gt; 
&lt;p&gt;In addition to the crates in this repository, the Tokio project also maintains several other libraries, including:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/tokio-rs/axum"&gt;&lt;code&gt;axum&lt;/code&gt;&lt;/a&gt;: A web application framework that focuses on ergonomics and modularity.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/hyperium/hyper"&gt;&lt;code&gt;hyper&lt;/code&gt;&lt;/a&gt;: A fast and correct HTTP/1.1 and HTTP/2 implementation for Rust.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/hyperium/tonic"&gt;&lt;code&gt;tonic&lt;/code&gt;&lt;/a&gt;: A gRPC over HTTP/2 implementation focused on high performance, interoperability, and flexibility.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/seanmonstar/warp"&gt;&lt;code&gt;warp&lt;/code&gt;&lt;/a&gt;: A super-easy, composable, web server framework for warp speeds.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/tower-rs/tower"&gt;&lt;code&gt;tower&lt;/code&gt;&lt;/a&gt;: A library of modular and reusable components for building robust networking clients and servers.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/tokio-rs/tracing"&gt;&lt;code&gt;tracing&lt;/code&gt;&lt;/a&gt; (formerly &lt;code&gt;tokio-trace&lt;/code&gt;): A framework for application-level tracing and async-aware diagnostics.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/tokio-rs/mio"&gt;&lt;code&gt;mio&lt;/code&gt;&lt;/a&gt;: A low-level, cross-platform abstraction over OS I/O APIs that powers &lt;code&gt;tokio&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/tokio-rs/bytes"&gt;&lt;code&gt;bytes&lt;/code&gt;&lt;/a&gt;: Utilities for working with bytes, including efficient byte buffers.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/tokio-rs/loom"&gt;&lt;code&gt;loom&lt;/code&gt;&lt;/a&gt;: A testing tool for concurrent Rust code.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Changelog&lt;/h2&gt; 
&lt;p&gt;The Tokio repository contains multiple crates. Each crate has its own changelog.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;tokio&lt;/code&gt; - &lt;a href="https://github.com/tokio-rs/tokio/raw/master/tokio/CHANGELOG.md"&gt;view changelog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;tokio-util&lt;/code&gt; - &lt;a href="https://github.com/tokio-rs/tokio/raw/master/tokio-util/CHANGELOG.md"&gt;view changelog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;tokio-stream&lt;/code&gt; - &lt;a href="https://github.com/tokio-rs/tokio/raw/master/tokio-stream/CHANGELOG.md"&gt;view changelog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;tokio-macros&lt;/code&gt; - &lt;a href="https://github.com/tokio-rs/tokio/raw/master/tokio-macros/CHANGELOG.md"&gt;view changelog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;tokio-test&lt;/code&gt; - &lt;a href="https://github.com/tokio-rs/tokio/raw/master/tokio-test/CHANGELOG.md"&gt;view changelog&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Supported Rust Versions&lt;/h2&gt; 
&lt;!--
When updating this, also update:
- .github/workflows/ci.yml
- CONTRIBUTING.md
- README.md
- tokio/README.md
- tokio/Cargo.toml
- tokio-util/Cargo.toml
- tokio-test/Cargo.toml
- tokio-stream/Cargo.toml
--&gt; 
&lt;p&gt;Tokio will keep a rolling MSRV (minimum supported rust version) policy of &lt;strong&gt;at least&lt;/strong&gt; 6 months. When increasing the MSRV, the new Rust version must have been released at least six months ago. The current MSRV is 1.71.&lt;/p&gt; 
&lt;p&gt;Note that the MSRV is not increased automatically, and only as part of a minor release. The MSRV history for past minor releases can be found below:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;1.48 to now - Rust 1.71&lt;/li&gt; 
 &lt;li&gt;1.39 to 1.47 - Rust 1.70&lt;/li&gt; 
 &lt;li&gt;1.30 to 1.38 - Rust 1.63&lt;/li&gt; 
 &lt;li&gt;1.27 to 1.29 - Rust 1.56&lt;/li&gt; 
 &lt;li&gt;1.17 to 1.26 - Rust 1.49&lt;/li&gt; 
 &lt;li&gt;1.15 to 1.16 - Rust 1.46&lt;/li&gt; 
 &lt;li&gt;1.0 to 1.14 - Rust 1.45&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Note that although we try to avoid the situation where a dependency transitively increases the MSRV of Tokio, we do not guarantee that this does not happen. However, every minor release will have some set of versions of dependencies that works with the MSRV of that minor release.&lt;/p&gt; 
&lt;h2&gt;Release schedule&lt;/h2&gt; 
&lt;p&gt;Tokio doesn't follow a fixed release schedule, but we typically make one minor release each month. We make patch releases for bugfixes as necessary.&lt;/p&gt; 
&lt;h2&gt;Bug patching policy&lt;/h2&gt; 
&lt;p&gt;For the purposes of making patch releases with bugfixes, we have designated certain minor releases as LTS (long term support) releases. Whenever a bug warrants a patch release with a fix for the bug, it will be backported and released as a new patch release for each LTS minor version. Our current LTS releases are:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;1.43.x&lt;/code&gt; - LTS release until March 2026. (MSRV 1.70)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;1.47.x&lt;/code&gt; - LTS release until September 2026. (MSRV 1.70)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Each LTS release will continue to receive backported fixes for at least a year. If you wish to use a fixed minor release in your project, we recommend that you use an LTS release.&lt;/p&gt; 
&lt;p&gt;To use a fixed minor version, you can specify the version with a tilde. For example, to specify that you wish to use the newest &lt;code&gt;1.43.x&lt;/code&gt; patch release, you can use the following dependency specification:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-text"&gt;tokio = { version = "~1.43", features = [...] }
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Previous LTS releases&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;1.8.x&lt;/code&gt; - LTS release until February 2022.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;1.14.x&lt;/code&gt; - LTS release until June 2022.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;1.18.x&lt;/code&gt; - LTS release until June 2023.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;1.20.x&lt;/code&gt; - LTS release until September 2023.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;1.25.x&lt;/code&gt; - LTS release until March 2024.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;1.32.x&lt;/code&gt; - LTS release until September 2024.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;1.36.x&lt;/code&gt; - LTS release until March 2025.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;1.38.x&lt;/code&gt; - LTS release until July 2025.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the &lt;a href="https://github.com/tokio-rs/tokio/raw/master/LICENSE"&gt;MIT license&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Contribution&lt;/h3&gt; 
&lt;p&gt;Unless you explicitly state otherwise, any contribution intentionally submitted for inclusion in Tokio by you shall be licensed as MIT, without any additional terms or conditions.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>helix-editor/helix</title>
      <link>https://github.com/helix-editor/helix</link>
      <description>&lt;p&gt;A post-modern modal text editor.&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;h1&gt; 
  &lt;picture&gt; 
   &lt;source media="(prefers-color-scheme: dark)" srcset="logo_dark.svg" /&gt; 
   &lt;source media="(prefers-color-scheme: light)" srcset="logo_light.svg" /&gt; 
   &lt;img alt="Helix" height="128" src="https://raw.githubusercontent.com/helix-editor/helix/master/logo_light.svg?sanitize=true" /&gt; 
  &lt;/picture&gt; &lt;/h1&gt; 
 &lt;p&gt;&lt;a href="https://github.com/helix-editor/helix/actions"&gt;&lt;img src="https://github.com/helix-editor/helix/actions/workflows/build.yml/badge.svg?sanitize=true" alt="Build status" /&gt;&lt;/a&gt; &lt;a href="https://github.com/helix-editor/helix/releases/latest"&gt;&lt;img src="https://img.shields.io/github/v/release/helix-editor/helix" alt="GitHub Release" /&gt;&lt;/a&gt; &lt;a href="https://docs.helix-editor.com/"&gt;&lt;img src="https://shields.io/badge/-documentation-452859" alt="Documentation" /&gt;&lt;/a&gt; &lt;a href="https://github.com/helix-editor/helix/graphs/contributors"&gt;&lt;img src="https://img.shields.io/github/contributors/helix-editor/helix" alt="GitHub contributors" /&gt;&lt;/a&gt; &lt;a href="https://matrix.to/#/#helix-community:matrix.org"&gt;&lt;img src="https://img.shields.io/matrix/helix-community:matrix.org" alt="Matrix Space" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/helix-editor/helix/master/screenshot.png" alt="Screenshot" /&gt;&lt;/p&gt; 
&lt;p&gt;A &lt;a href="https://github.com/mawww/kakoune"&gt;Kakoune&lt;/a&gt; / &lt;a href="https://github.com/neovim/neovim"&gt;Neovim&lt;/a&gt; inspired editor, written in Rust.&lt;/p&gt; 
&lt;p&gt;The editing model is very heavily based on Kakoune; during development I found myself agreeing with most of Kakoune's design decisions.&lt;/p&gt; 
&lt;p&gt;For more information, see the &lt;a href="https://helix-editor.com"&gt;website&lt;/a&gt; or &lt;a href="https://docs.helix-editor.com/"&gt;documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;All shortcuts/keymaps can be found &lt;a href="https://docs.helix-editor.com/keymap.html"&gt;in the documentation on the website&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/helix-editor/helix/wiki/Troubleshooting"&gt;Troubleshooting&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Features&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;Vim-like modal editing&lt;/li&gt; 
 &lt;li&gt;Multiple selections&lt;/li&gt; 
 &lt;li&gt;Built-in language server support&lt;/li&gt; 
 &lt;li&gt;Smart, incremental syntax highlighting and code editing via tree-sitter&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Although it's primarily a terminal-based editor, I am interested in exploring a custom renderer (similar to Emacs) using wgpu.&lt;/p&gt; 
&lt;p&gt;Note: Only certain languages have indentation definitions at the moment. Check &lt;code&gt;runtime/queries/&amp;lt;lang&amp;gt;/&lt;/code&gt; for &lt;code&gt;indents.scm&lt;/code&gt;.&lt;/p&gt; 
&lt;h1&gt;Installation&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://docs.helix-editor.com/install.html"&gt;Installation documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://repology.org/project/helix-editor/versions"&gt;&lt;img src="https://repology.org/badge/vertical-allrepos/helix-editor.svg?exclude_unsupported=1" alt="Packaging status" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Contributing&lt;/h1&gt; 
&lt;p&gt;Contributing guidelines can be found &lt;a href="https://raw.githubusercontent.com/helix-editor/helix/master/docs/CONTRIBUTING.md"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;Getting help&lt;/h1&gt; 
&lt;p&gt;Your question might already be answered on the &lt;a href="https://github.com/helix-editor/helix/wiki/FAQ"&gt;FAQ&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Discuss the project on the community &lt;a href="https://matrix.to/#/#helix-community:matrix.org"&gt;Matrix Space&lt;/a&gt; (make sure to join &lt;code&gt;#helix-editor:matrix.org&lt;/code&gt; if you're on a client that doesn't support Matrix Spaces yet).&lt;/p&gt; 
&lt;h1&gt;Credits&lt;/h1&gt; 
&lt;p&gt;Thanks to &lt;a href="https://github.com/jakenvac"&gt;@jakenvac&lt;/a&gt; for designing the logo!&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>getzola/zola</title>
      <link>https://github.com/getzola/zola</link>
      <description>&lt;p&gt;A fast static site generator in a single binary with everything built-in. https://www.getzola.org&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;zola (n√© Gutenberg) &lt;img src="https://raw.githubusercontent.com/getzola/zola/master/docs/static/logos/Zola-logo-main-coffee.svg?sanitize=true" align="right" alt="zola logo" width="30%" /&gt;&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://dev.azure.com/getzola/zola/_build/latest?definitionId=1&amp;amp;branchName=master"&gt;&lt;img src="https://dev.azure.com/getzola/zola/_apis/build/status/getzola.zola?branchName=master" alt="Build Status" /&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/github/downloads/getzola/zola/total" alt="GitHub all releases" /&gt;&lt;/p&gt; 
&lt;p&gt;A fast static site generator in a single binary with everything built-in.&lt;/p&gt; 
&lt;p&gt;To find out more see the &lt;a href="https://www.getzola.org/documentation/getting-started/overview/"&gt;Zola Documentation&lt;/a&gt;, look in the &lt;a href="https://raw.githubusercontent.com/getzola/zola/master/docs/content"&gt;docs/content&lt;/a&gt; folder of this repository or visit the &lt;a href="https://zola.discourse.group"&gt;Zola community forum&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;This tool and its template engine &lt;a href="https://keats.github.io/tera/"&gt;tera&lt;/a&gt; were born from an intense dislike of the (insane) Golang template engine and therefore of Hugo that I was using before for 6+ sites.&lt;/p&gt; 
&lt;h1&gt;List of features&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.getzola.org/documentation/getting-started/cli-usage/"&gt;Single binary&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.getzola.org/documentation/content/syntax-highlighting/"&gt;Syntax highlighting&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.getzola.org/documentation/content/sass/"&gt;Sass compilation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Assets co-location&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.getzola.org/documentation/content/multilingual/"&gt;Multilingual site support&lt;/a&gt; (Basic currently)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.getzola.org/documentation/content/image-processing/"&gt;Image processing&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.getzola.org/documentation/themes/overview/"&gt;Themes&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.getzola.org/documentation/content/shortcodes/"&gt;Shortcodes&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.getzola.org/documentation/content/linking/"&gt;Internal links&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.getzola.org/documentation/getting-started/cli-usage/#check"&gt;External link checker&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.getzola.org/documentation/content/table-of-contents/"&gt;Table of contents automatic generation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Automatic header anchors&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.getzola.org/documentation/content/page/#front-matter"&gt;Aliases&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.getzola.org/documentation/templates/pagination/"&gt;Pagination&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.getzola.org/documentation/templates/taxonomies/"&gt;Custom taxonomies&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.getzola.org/documentation/content/search/"&gt;Search with no servers or any third parties involved&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.getzola.org/documentation/getting-started/cli-usage/#serve"&gt;Live reload&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Deploy on many platforms easily: &lt;a href="https://www.getzola.org/documentation/deployment/netlify/"&gt;Netlify&lt;/a&gt;, &lt;a href="https://www.getzola.org/documentation/deployment/vercel/"&gt;Vercel&lt;/a&gt;, &lt;a href="https://www.getzola.org/documentation/deployment/cloudflare-pages/"&gt;Cloudflare Pages&lt;/a&gt;, etc&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>block/goose</title>
      <link>https://github.com/block/goose</link>
      <description>&lt;p&gt;an open source, extensible AI agent that goes beyond code suggestions - install, execute, edit, and test with any LLM&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;h1&gt;goose&lt;/h1&gt; 
 &lt;p&gt;&lt;em&gt;a local, extensible, open source AI agent that automates engineering tasks&lt;/em&gt;&lt;/p&gt; 
 &lt;p align="center"&gt; &lt;a href="https://opensource.org/licenses/Apache-2.0"&gt; &lt;img src="https://img.shields.io/badge/License-Apache_2.0-blue.svg?sanitize=true" /&gt; &lt;/a&gt; &lt;a href="https://discord.gg/goose-oss"&gt; &lt;img src="https://img.shields.io/discord/1287729918100246654?logo=discord&amp;amp;logoColor=white&amp;amp;label=Join+Us&amp;amp;color=blueviolet" alt="Discord" /&gt; &lt;/a&gt; &lt;a href="https://github.com/block/goose/actions/workflows/ci.yml"&gt; &lt;img src="https://img.shields.io/github/actions/workflow/status/block/goose/ci.yml?branch=main" alt="CI" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;goose is your on-machine AI agent, capable of automating complex development tasks from start to finish. More than just code suggestions, goose can build entire projects from scratch, write and execute code, debug failures, orchestrate workflows, and interact with external APIs - &lt;em&gt;autonomously&lt;/em&gt;.&lt;/p&gt; 
&lt;p&gt;Whether you're prototyping an idea, refining existing code, or managing intricate engineering pipelines, goose adapts to your workflow and executes tasks with precision.&lt;/p&gt; 
&lt;p&gt;Designed for maximum flexibility, goose works with any LLM and supports multi-model configuration to optimize performance and cost, seamlessly integrates with MCP servers, and is available as both a desktop app as well as CLI - making it the ultimate AI assistant for developers who want to move faster and focus on innovation.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://youtu.be/D-DpDunrbpo"&gt;&lt;img src="https://github.com/user-attachments/assets/ddc71240-3928-41b5-8210-626dfb28af7a" alt="Watch the video" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Quick Links&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://block.github.io/goose/docs/quickstart"&gt;Quickstart&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://block.github.io/goose/docs/getting-started/installation"&gt;Installation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://block.github.io/goose/docs/category/tutorials"&gt;Tutorials&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://block.github.io/goose/docs/category/getting-started"&gt;Documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/block/goose/raw/main/HOWTOAI.md"&gt;Responsible AI-Assisted Coding Guide&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/block/goose/raw/main/GOVERNANCE.md"&gt;Governance&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Need Help?&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://block.github.io/goose/docs/troubleshooting/diagnostics-and-reporting"&gt;Diagnostics &amp;amp; Reporting&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://block.github.io/goose/docs/troubleshooting/known-issues"&gt;Known Issues&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;a little goose humor ü¶¢&lt;/h1&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Why did the developer choose goose as their AI agent?&lt;/p&gt; 
 &lt;p&gt;Because it always helps them "migrate" their code to production! üöÄ&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h1&gt;goose around with us&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://discord.gg/goose-oss"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/@goose-oss"&gt;YouTube&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.linkedin.com/company/goose-oss"&gt;LinkedIn&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://x.com/goose_oss"&gt;Twitter/X&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://bsky.app/profile/opensource.block.xyz"&gt;Bluesky&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://njump.me/opensource@block.xyz"&gt;Nostr&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>ai-dynamo/dynamo</title>
      <link>https://github.com/ai-dynamo/dynamo</link>
      <description>&lt;p&gt;A Datacenter Scale Distributed Inference Serving Framework&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/docs/images/frontpage-banner.png" alt="Dynamo banner" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://opensource.org/licenses/Apache-2.0"&gt;&lt;img src="https://img.shields.io/badge/License-Apache_2.0-blue.svg?sanitize=true" alt="License" /&gt;&lt;/a&gt; &lt;a href="https://github.com/ai-dynamo/dynamo/releases/latest"&gt;&lt;img src="https://img.shields.io/github/v/release/ai-dynamo/dynamo" alt="GitHub Release" /&gt;&lt;/a&gt; &lt;a href="https://deepwiki.com/ai-dynamo/dynamo"&gt;&lt;img src="https://deepwiki.com/badge.svg?sanitize=true" alt="Ask DeepWiki" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/D92uqZRjCZ"&gt;&lt;img src="https://dcbadge.limes.pink/api/server/D92uqZRjCZ?style=flat" alt="Discord" /&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/badge/community_contributors-70%2B-brightgreen" alt="Community Contributors" /&gt;&lt;/p&gt; 
&lt;p&gt;| &lt;strong&gt;&lt;a href="https://github.com/ai-dynamo/dynamo/issues/5506"&gt;Roadmap&lt;/a&gt;&lt;/strong&gt; | &lt;strong&gt;&lt;a href="https://github.com/ai-dynamo/dynamo/raw/main/docs/reference/support-matrix.md"&gt;Support Matrix&lt;/a&gt;&lt;/strong&gt; | &lt;strong&gt;&lt;a href="https://docs.nvidia.com/dynamo/latest/index.html"&gt;Docs&lt;/a&gt;&lt;/strong&gt; | &lt;strong&gt;&lt;a href="https://github.com/ai-dynamo/dynamo/tree/main/recipes"&gt;Recipes&lt;/a&gt;&lt;/strong&gt; | &lt;strong&gt;&lt;a href="https://github.com/ai-dynamo/dynamo/tree/main/examples"&gt;Examples&lt;/a&gt;&lt;/strong&gt; | &lt;strong&gt;&lt;a href="https://catalog.ngc.nvidia.com/orgs/nvidia/teams/ai-dynamo/collections/ai-dynamo"&gt;Prebuilt Containers&lt;/a&gt;&lt;/strong&gt; | &lt;strong&gt;&lt;a href="https://github.com/ai-dynamo/enhancements"&gt;Design Proposals&lt;/a&gt;&lt;/strong&gt; | &lt;strong&gt;&lt;a href="https://developer.nvidia.com/blog/tag/nvidia-dynamo"&gt;Blogs&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;h1&gt;NVIDIA Dynamo&lt;/h1&gt; 
&lt;p&gt;High-throughput, low-latency inference framework designed for serving generative AI and reasoning models in multi-node distributed environments.&lt;/p&gt; 
&lt;h2&gt;Why Dynamo&lt;/h2&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/docs/images/frontpage-gpu-vertical.png" alt="Multi Node Multi-GPU topology" width="600" /&gt; &lt;/p&gt; 
&lt;p&gt;Large language models exceed single-GPU capacity. Tensor parallelism spreads layers across GPUs but creates coordination challenges. Dynamo closes this orchestration gap.&lt;/p&gt; 
&lt;p&gt;Dynamo is inference engine agnostic (supports TRT-LLM, vLLM, SGLang) and provides:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Disaggregated Prefill &amp;amp; Decode&lt;/strong&gt; ‚Äì Maximizes GPU throughput with latency/throughput trade-offs&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Dynamic GPU Scheduling&lt;/strong&gt; ‚Äì Optimizes performance based on fluctuating demand&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;LLM-Aware Request Routing&lt;/strong&gt; ‚Äì Eliminates unnecessary KV cache re-computation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Accelerated Data Transfer&lt;/strong&gt; ‚Äì Reduces inference response time using NIXL&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;KV Cache Offloading&lt;/strong&gt; ‚Äì Leverages multiple memory hierarchies for higher throughput&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/docs/images/frontpage-architecture.png" alt="Dynamo architecture" width="600" /&gt; &lt;/p&gt; 
&lt;p&gt;Built in Rust for performance and Python for extensibility, Dynamo is fully open-source with an OSS-first development approach.&lt;/p&gt; 
&lt;h2&gt;Framework Support Matrix&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Feature&lt;/th&gt; 
   &lt;th align="center"&gt;&lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/docs/backends/vllm/README.md"&gt;vLLM&lt;/a&gt;&lt;/th&gt; 
   &lt;th align="center"&gt;&lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/docs/backends/sglang/README.md"&gt;SGLang&lt;/a&gt;&lt;/th&gt; 
   &lt;th align="center"&gt;&lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/docs/backends/trtllm/README.md"&gt;TensorRT-LLM&lt;/a&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/docs/design_docs/disagg_serving.md"&gt;&lt;strong&gt;Disaggregated Serving&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
   &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
   &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/docs/router/kv_cache_routing.md"&gt;&lt;strong&gt;KV-Aware Routing&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
   &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
   &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/docs/planner/sla_planner.md"&gt;&lt;strong&gt;SLA-Based Planner&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
   &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
   &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/docs/kvbm/kvbm_architecture.md"&gt;&lt;strong&gt;KVBM&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
   &lt;td align="center"&gt;üöß&lt;/td&gt; 
   &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/docs/multimodal/index.md"&gt;&lt;strong&gt;Multimodal&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
   &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
   &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/docs/agents/tool-calling.md"&gt;&lt;strong&gt;Tool Calling&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
   &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
   &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/feature-matrix.md"&gt;Full Feature Matrix ‚Üí&lt;/a&gt;&lt;/strong&gt; ‚Äî Detailed compatibility including LoRA, Request Migration, Speculative Decoding, and feature interactions.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Latest News&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;[12/05] &lt;a href="https://quantumzeitgeist.com/kimi-k2-nvidia-ai-ai-breakthrough/"&gt;Moonshot AI's Kimi K2 achieves 10x inference speedup with Dynamo on GB200&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;[12/02] &lt;a href="https://www.marktechpost.com/2025/12/02/nvidia-and-mistral-ai-bring-10x-faster-inference-for-the-mistral-3-family-on-gb200-nvl72-gpu-systems/"&gt;Mistral AI runs Mistral Large 3 with 10x faster inference using Dynamo&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;[12/01] &lt;a href="https://www.infoq.com/news/2025/12/nvidia-dynamo-kubernetes/"&gt;InfoQ: NVIDIA Dynamo simplifies Kubernetes deployment for LLM inference&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;[11/20] &lt;a href="https://www.dell.com/en-us/dt/corporate/newsroom/announcements/detailpage.press-releases~usa~2025~11~dell-technologies-and-nvidia-advance-enterprise-ai-innovation.htm"&gt;Dell integrates PowerScale with Dynamo's NIXL for 19x faster TTFT&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;[11/20] &lt;a href="https://siliconangle.com/2025/11/20/nvidia-weka-kv-cache-solution-ai-inferencing-sc25/"&gt;WEKA partners with NVIDIA on KV cache storage for Dynamo&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;[11/13] &lt;a href="https://www.youtube.com/playlist?list=PL5B692fm6--tgryKu94h2Zb7jTFM3Go4X"&gt;Dynamo Office Hours Playlist&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;[10/16] &lt;a href="https://www.baseten.co/blog/how-baseten-achieved-2x-faster-inference-with-nvidia-dynamo/"&gt;How Baseten achieved 2x faster inference with NVIDIA Dynamo&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Get Started&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Path&lt;/th&gt; 
   &lt;th&gt;Use Case&lt;/th&gt; 
   &lt;th&gt;Time&lt;/th&gt; 
   &lt;th&gt;Requirements&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/#local-quick-start"&gt;&lt;strong&gt;Local Quick Start&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Test on a single machine&lt;/td&gt; 
   &lt;td&gt;~5 min&lt;/td&gt; 
   &lt;td&gt;1 GPU, Ubuntu 24.04&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/#kubernetes-deployment"&gt;&lt;strong&gt;Kubernetes Deployment&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Production multi-node clusters&lt;/td&gt; 
   &lt;td&gt;~30 min&lt;/td&gt; 
   &lt;td&gt;K8s cluster with GPUs&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Want to help shape the future of distributed LLM inference? We welcome contributors at all levels‚Äîfrom doc fixes to new features.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/CONTRIBUTING.md"&gt;Contributing Guide&lt;/a&gt;&lt;/strong&gt; ‚Äì How to get started&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/ai-dynamo/dynamo/issues/new?template=bug_report.yml"&gt;Report a Bug&lt;/a&gt;&lt;/strong&gt; ‚Äì Found an issue?&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/ai-dynamo/dynamo/issues/new?template=feature_request.yml"&gt;Feature Request&lt;/a&gt;&lt;/strong&gt; ‚Äì Have an idea?&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Local Quick Start&lt;/h1&gt; 
&lt;p&gt;The following examples require a few system level packages. Recommended to use Ubuntu 24.04 with a x86_64 CPU. See &lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/docs/reference/support-matrix.md"&gt;docs/reference/support-matrix.md&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;1. Initial Setup&lt;/h2&gt; 
&lt;p&gt;The Dynamo team recommends the &lt;code&gt;uv&lt;/code&gt; Python package manager, although any way works. Install uv:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;curl -LsSf https://astral.sh/uv/install.sh | sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Install Python Development Headers&lt;/h3&gt; 
&lt;p&gt;Backend engines require Python development headers for JIT compilation. Install them with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;sudo apt install python3-dev
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;2. Select an Engine&lt;/h2&gt; 
&lt;p&gt;We publish Python wheels specialized for each of our supported engines: vllm, sglang, and trtllm. The examples that follow use SGLang; continue reading for other engines.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;uv venv venv
source venv/bin/activate
uv pip install pip

# Choose one
uv pip install "ai-dynamo[sglang]"  #replace with [vllm], [trtllm], etc.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;3. Run Dynamo&lt;/h2&gt; 
&lt;h3&gt;Sanity Check (Optional)&lt;/h3&gt; 
&lt;p&gt;Before trying out Dynamo, you can verify your system configuration and dependencies:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python3 deploy/sanity_check.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This is a quick check for system resources, development tools, LLM frameworks, and Dynamo components.&lt;/p&gt; 
&lt;h3&gt;Running an LLM API Server&lt;/h3&gt; 
&lt;p&gt;Dynamo provides a simple way to spin up a local set of inference components including:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;OpenAI Compatible Frontend&lt;/strong&gt; ‚Äì High performance OpenAI compatible http api server written in Rust.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Basic and Kv Aware Router&lt;/strong&gt; ‚Äì Route and load balance traffic to a set of workers.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Workers&lt;/strong&gt; ‚Äì Set of pre-configured LLM serving engines.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Start an OpenAI compatible HTTP server with prompt templating, tokenization, and routing.
# For local dev: --store-kv file avoids etcd (workers and frontend must share a disk)
python3 -m dynamo.frontend --http-port 8000 --store-kv file

# Start the SGLang engine. You can run several of these for the same or different models.
# The frontend will discover them automatically.
python3 -m dynamo.sglang --model-path deepseek-ai/DeepSeek-R1-Distill-Llama-8B --store-kv file
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; vLLM workers publish KV cache events by default, which requires NATS. For dependency-free local development with vLLM, add &lt;code&gt;--kv-events-config '{"enable_kv_cache_events": false}'&lt;/code&gt;. This keeps local prefix caching enabled while disabling event publishing. See &lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/#service-discovery-and-messaging"&gt;Service Discovery and Messaging&lt;/a&gt; for details.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;Send a Request&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl localhost:8000/v1/chat/completions   -H "Content-Type: application/json"   -d '{
    "model": "deepseek-ai/DeepSeek-R1-Distill-Llama-8B",
    "messages": [
    {
        "role": "user",
        "content": "Hello, how are you?"
    }
    ],
    "stream":false,
    "max_tokens": 300
  }' | jq
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Rerun with &lt;code&gt;curl -N&lt;/code&gt; and change &lt;code&gt;stream&lt;/code&gt; in the request to &lt;code&gt;true&lt;/code&gt; to get the responses as soon as the engine issues them.&lt;/p&gt; 
&lt;h3&gt;What's Next?&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Scale up&lt;/strong&gt;: Deploy on Kubernetes with &lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/recipes/"&gt;Recipes&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Add features&lt;/strong&gt;: Enable &lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/docs/router/kv_cache_routing.md"&gt;KV-aware routing&lt;/a&gt;, &lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/docs/design_docs/disagg_serving.md"&gt;disaggregated serving&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Benchmark&lt;/strong&gt;: Use &lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/docs/benchmarks/benchmarking.md"&gt;AIPerf&lt;/a&gt; to measure performance&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Try other engines&lt;/strong&gt;: &lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/docs/backends/vllm/"&gt;vLLM&lt;/a&gt;, &lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/docs/backends/sglang/"&gt;SGLang&lt;/a&gt;, &lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/docs/backends/trtllm/"&gt;TensorRT-LLM&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Kubernetes Deployment&lt;/h1&gt; 
&lt;p&gt;For production deployments on Kubernetes clusters with multiple GPUs.&lt;/p&gt; 
&lt;h2&gt;Prerequisites&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Kubernetes cluster with GPU nodes&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/docs/kubernetes/README.md"&gt;Dynamo Platform installed&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;HuggingFace token for model downloads&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Production Recipes&lt;/h2&gt; 
&lt;p&gt;Pre-built deployment configurations for common models and topologies:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Model&lt;/th&gt; 
   &lt;th&gt;Framework&lt;/th&gt; 
   &lt;th&gt;Mode&lt;/th&gt; 
   &lt;th&gt;GPUs&lt;/th&gt; 
   &lt;th&gt;Recipe&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Llama-3.1-70B&lt;/td&gt; 
   &lt;td&gt;vLLM&lt;/td&gt; 
   &lt;td&gt;Aggregated&lt;/td&gt; 
   &lt;td&gt;4x H100&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/recipes/vllm/llama-3.1-70b/"&gt;View&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;DeepSeek-R1&lt;/td&gt; 
   &lt;td&gt;SGLang&lt;/td&gt; 
   &lt;td&gt;Disaggregated&lt;/td&gt; 
   &lt;td&gt;8x H200&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/recipes/sglang/deepseek-r1/"&gt;View&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Qwen3-32B&lt;/td&gt; 
   &lt;td&gt;TensorRT-LLM&lt;/td&gt; 
   &lt;td&gt;Disaggregated&lt;/td&gt; 
   &lt;td&gt;8x GPU&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/recipes/trtllm/qwen3-32b/"&gt;View&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/recipes/README.md"&gt;recipes/README.md&lt;/a&gt; for the full list and deployment instructions.&lt;/p&gt; 
&lt;h2&gt;Cloud Deployment Guides&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/examples/deployments/EKS/"&gt;Amazon EKS&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/examples/deployments/GKE/"&gt;Google GKE&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Concepts&lt;/h1&gt; 
&lt;h2&gt;Engines&lt;/h2&gt; 
&lt;p&gt;Dynamo is inference engine agnostic. Install the wheel for your chosen engine and run with &lt;code&gt;python3 -m dynamo.&amp;lt;engine&amp;gt; --help&lt;/code&gt;.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Engine&lt;/th&gt; 
   &lt;th&gt;Install&lt;/th&gt; 
   &lt;th&gt;Docs&lt;/th&gt; 
   &lt;th&gt;Best For&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;vLLM&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;uv pip install ai-dynamo[vllm]&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/docs/backends/vllm/"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Broadest feature coverage&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;SGLang&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;uv pip install ai-dynamo[sglang]&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/docs/backends/sglang/"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;High-throughput serving&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;TensorRT-LLM&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;pip install --pre --extra-index-url https://pypi.nvidia.com ai-dynamo[trtllm]&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/docs/backends/trtllm/"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Maximum performance&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; TensorRT-LLM requires &lt;code&gt;pip&lt;/code&gt; (not &lt;code&gt;uv&lt;/code&gt;) due to URL-based dependencies. See the &lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/docs/backends/trtllm/"&gt;TRT-LLM guide&lt;/a&gt; for container setup and prerequisites.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Use &lt;code&gt;CUDA_VISIBLE_DEVICES&lt;/code&gt; to specify which GPUs to use. Engine-specific options (context length, multi-GPU, etc.) are documented in each backend guide.&lt;/p&gt; 
&lt;h2&gt;Service Discovery and Messaging&lt;/h2&gt; 
&lt;p&gt;Dynamo uses TCP for inter-component communication. External services are optional for most deployments:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Deployment&lt;/th&gt; 
   &lt;th&gt;etcd&lt;/th&gt; 
   &lt;th&gt;NATS&lt;/th&gt; 
   &lt;th&gt;Notes&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Kubernetes&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;‚ùå Not required&lt;/td&gt; 
   &lt;td&gt;‚ùå Not required&lt;/td&gt; 
   &lt;td&gt;K8s-native discovery; TCP request plane&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Local Development&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;‚ùå Not required&lt;/td&gt; 
   &lt;td&gt;‚ùå Not required&lt;/td&gt; 
   &lt;td&gt;Pass &lt;code&gt;--store-kv file&lt;/code&gt;; vLLM also needs &lt;code&gt;--kv-events-config '{"enable_kv_cache_events": false}'&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;KV-Aware Routing&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;‚Äî&lt;/td&gt; 
   &lt;td&gt;‚úÖ Required&lt;/td&gt; 
   &lt;td&gt;Prefix caching enabled by default requires NATS&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;For local development without external dependencies, pass &lt;code&gt;--store-kv file&lt;/code&gt; (avoids etcd) to both the frontend and workers. vLLM users should also pass &lt;code&gt;--kv-events-config '{"enable_kv_cache_events": false}'&lt;/code&gt; to disable KV event publishing (avoids NATS) while keeping local prefix caching enabled; SGLang and TRT-LLM don't require this flag.&lt;/p&gt; 
&lt;p&gt;For distributed non-Kubernetes deployments or KV-aware routing:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://etcd.io/"&gt;etcd&lt;/a&gt; can be run directly as &lt;code&gt;./etcd&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://nats.io/"&gt;nats&lt;/a&gt; needs JetStream enabled: &lt;code&gt;nats-server -js&lt;/code&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;To quickly setup both: &lt;code&gt;docker compose -f deploy/docker-compose.yml up -d&lt;/code&gt;&lt;/p&gt; 
&lt;h1&gt;Advanced Topics&lt;/h1&gt; 
&lt;h2&gt;Benchmarking&lt;/h2&gt; 
&lt;p&gt;Dynamo provides comprehensive benchmarking tools:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/docs/benchmarks/benchmarking.md"&gt;Benchmarking Guide&lt;/a&gt;&lt;/strong&gt; ‚Äì Compare deployment topologies using AIPerf&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/docs/planner/sla_planner_quickstart.md"&gt;SLA-Driven Deployments&lt;/a&gt;&lt;/strong&gt; ‚Äì Optimize deployments to meet SLA requirements&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Frontend OpenAPI Specification&lt;/h2&gt; 
&lt;p&gt;The OpenAI-compatible frontend exposes an OpenAPI 3 spec at &lt;code&gt;/openapi.json&lt;/code&gt;. To generate without running the server:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cargo run -p dynamo-llm --bin generate-frontend-openapi
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This writes to &lt;code&gt;docs/frontends/openapi.json&lt;/code&gt;.&lt;/p&gt; 
&lt;h1&gt;Building from Source&lt;/h1&gt; 
&lt;p&gt;For contributors who want to build Dynamo from source rather than installing from PyPI.&lt;/p&gt; 
&lt;h2&gt;1. Install Libraries&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Ubuntu:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;sudo apt install -y build-essential libhwloc-dev libudev-dev pkg-config libclang-dev protobuf-compiler python3-dev cmake
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;macOS:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://brew.sh/"&gt;Homebrew&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code&gt;# if brew is not installed on your system, install it
/bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://developer.apple.com/xcode/"&gt;Xcode&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code&gt;brew install cmake protobuf

## Check that Metal is accessible
xcrun -sdk macosx metal
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If Metal is accessible, you should see an error like &lt;code&gt;metal: error: no input files&lt;/code&gt;, which confirms it is installed correctly.&lt;/p&gt; 
&lt;h2&gt;2. Install Rust&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh
source $HOME/.cargo/env
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;3. Create a Python Virtual Environment&lt;/h2&gt; 
&lt;p&gt;Follow the instructions in &lt;a href="https://docs.astral.sh/uv/#installation"&gt;uv installation&lt;/a&gt; guide to install uv if you don't have &lt;code&gt;uv&lt;/code&gt; installed. Once uv is installed, create a virtual environment and activate it.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Install uv&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -LsSf https://astral.sh/uv/install.sh | sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;Create a virtual environment&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uv venv dynamo
source dynamo/bin/activate
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;4. Install Build Tools&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;uv pip install pip maturin
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;a href="https://github.com/PyO3/maturin"&gt;Maturin&lt;/a&gt; is the Rust&amp;lt;-&amp;gt;Python bindings build tool.&lt;/p&gt; 
&lt;h2&gt;5. Build the Rust Bindings&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;cd lib/bindings/python
maturin develop --uv
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;6. Install GPU Memory Service&lt;/h2&gt; 
&lt;p&gt;The GPU Memory Service is a Python package with a C++ extension. It requires only Python development headers and a C++ compiler (g++).&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd $PROJECT_ROOT
uv pip install -e lib/gpu_memory_service
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;7. Install the Wheel&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;cd $PROJECT_ROOT
uv pip install -e .
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You should now be able to run &lt;code&gt;python3 -m dynamo.frontend&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;For local development, pass &lt;code&gt;--store-kv file&lt;/code&gt; to avoid external dependencies (see Service Discovery and Messaging section).&lt;/p&gt; 
&lt;p&gt;Set the environment variable &lt;code&gt;DYN_LOG&lt;/code&gt; to adjust the logging level; for example, &lt;code&gt;export DYN_LOG=debug&lt;/code&gt;. It has the same syntax as &lt;code&gt;RUST_LOG&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;If you use vscode or cursor, we have a .devcontainer folder built on &lt;a href="https://code.visualstudio.com/docs/devcontainers/containers"&gt;Microsofts Extension&lt;/a&gt;. For instructions see the &lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/.devcontainer/README.md"&gt;ReadMe&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;!-- Reference links for Feature Compatibility Matrix --&gt;</description>
    </item>
    
    <item>
      <title>servo/servo</title>
      <link>https://github.com/servo/servo</link>
      <description>&lt;p&gt;Servo aims to empower developers with a lightweight, high-performance alternative for embedding web technologies in applications.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;The Servo Parallel Browser Engine Project&lt;/h1&gt; 
&lt;p&gt;Servo is a prototype web browser engine written in the &lt;a href="https://github.com/rust-lang/rust"&gt;Rust&lt;/a&gt; language. It is currently developed on 64-bit macOS, 64-bit Linux, 64-bit Windows, 64-bit OpenHarmony, and Android.&lt;/p&gt; 
&lt;p&gt;Servo welcomes contribution from everyone. Check out:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;The &lt;a href="https://book.servo.org"&gt;Servo Book&lt;/a&gt; for documentation&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://servo.org/"&gt;servo.org&lt;/a&gt; for news and guides&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Coordination of Servo development happens:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Here in the Github Issues&lt;/li&gt; 
 &lt;li&gt;On the &lt;a href="https://servo.zulipchat.com/"&gt;Servo Zulip&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;In video calls advertised in the &lt;a href="https://github.com/servo/project/issues"&gt;Servo Project&lt;/a&gt; repo.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Getting started&lt;/h2&gt; 
&lt;p&gt;For more detailed build instructions, see the Servo Book under &lt;a href="https://book.servo.org/building/getting-the-code.html"&gt;Getting the Code&lt;/a&gt; and &lt;a href="https://book.servo.org/building/building.html"&gt;Building Servo&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;macOS&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Download and install &lt;a href="https://developer.apple.com/xcode/"&gt;Xcode&lt;/a&gt; and &lt;a href="https://brew.sh/"&gt;&lt;code&gt;brew&lt;/code&gt;&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Install &lt;code&gt;uv&lt;/code&gt;: &lt;code&gt;curl -LsSf https://astral.sh/uv/install.sh | sh&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Install &lt;code&gt;rustup&lt;/code&gt;: &lt;code&gt;curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Restart your shell to make sure &lt;code&gt;cargo&lt;/code&gt; is available&lt;/li&gt; 
 &lt;li&gt;Install the other dependencies: &lt;code&gt;./mach bootstrap&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Build servoshell: &lt;code&gt;./mach build&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Linux&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Install &lt;code&gt;curl&lt;/code&gt;: 
  &lt;ul&gt; 
   &lt;li&gt;Arch: &lt;code&gt;sudo pacman -S --needed curl&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;Debian, Ubuntu: &lt;code&gt;sudo apt install curl&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;Fedora: &lt;code&gt;sudo dnf install curl&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;Gentoo: &lt;code&gt;sudo emerge net-misc/curl&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Install &lt;code&gt;uv&lt;/code&gt;: &lt;code&gt;curl -LsSf https://astral.sh/uv/install.sh | sh&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Install &lt;code&gt;rustup&lt;/code&gt;: &lt;code&gt;curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Restart your shell to make sure &lt;code&gt;cargo&lt;/code&gt; is available&lt;/li&gt; 
 &lt;li&gt;Install the other dependencies: &lt;code&gt;./mach bootstrap&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Build servoshell: &lt;code&gt;./mach build&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Windows&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Download &lt;a href="https://docs.astral.sh/uv/getting-started/installation/#standalone-installer"&gt;&lt;code&gt;uv&lt;/code&gt;&lt;/a&gt;, &lt;a href="https://chocolatey.org/install#individual"&gt;&lt;code&gt;choco&lt;/code&gt;&lt;/a&gt;, and &lt;a href="https://win.rustup.rs/"&gt;&lt;code&gt;rustup&lt;/code&gt;&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Be sure to select &lt;em&gt;Quick install via the Visual Studio Community installer&lt;/em&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;In the Visual Studio Installer, ensure the following components are installed: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Windows 10/11 SDK (anything &amp;gt;= 10.0.19041.0)&lt;/strong&gt; (&lt;code&gt;Microsoft.VisualStudio.Component.Windows{10, 11}SDK.{&amp;gt;=19041}&lt;/code&gt;)&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;MSVC v143 - VS 2022 C++ x64/x86 build tools (Latest)&lt;/strong&gt; (&lt;code&gt;Microsoft.VisualStudio.Component.VC.Tools.x86.x64&lt;/code&gt;)&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;C++ ATL for latest v143 build tools (x86 &amp;amp; x64)&lt;/strong&gt; (&lt;code&gt;Microsoft.VisualStudio.Component.VC.ATL&lt;/code&gt;)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Restart your shell to make sure &lt;code&gt;cargo&lt;/code&gt; is available&lt;/li&gt; 
 &lt;li&gt;Install the other dependencies: &lt;code&gt;.\mach bootstrap&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Build servoshell: &lt;code&gt;.\mach build&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Android&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Ensure that the following environment variables are set: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;ANDROID_SDK_ROOT&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;ANDROID_NDK_ROOT&lt;/code&gt;: &lt;code&gt;$ANDROID_SDK_ROOT/ndk/28.2.13676358/&lt;/code&gt; &lt;code&gt;ANDROID_SDK_ROOT&lt;/code&gt; can be any directory (such as &lt;code&gt;~/android-sdk&lt;/code&gt;). All of the Android build dependencies will be installed there.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Install the latest version of the &lt;a href="https://developer.android.com/studio#command-tools"&gt;Android command-line tools&lt;/a&gt; to &lt;code&gt;$ANDROID_SDK_ROOT/cmdline-tools/latest&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Run the following command to install the necessary components: &lt;pre&gt;&lt;code class="language-shell"&gt;sudo $ANDROID_SDK_ROOT/cmdline-tools/latest/bin/sdkmanager --install \
 "build-tools;34.0.0" \
 "emulator" \
 "ndk;28.2.13676358" \
 "platform-tools" \
 "platforms;android-33" \
 "system-images;android-33;google_apis;x86_64"
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;Follow the instructions above for the platform you are building on&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;OpenHarmony&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Follow the instructions above for the platform you are building on to prepare the environment.&lt;/li&gt; 
 &lt;li&gt;Depending on the target distribution (e.g. &lt;code&gt;HarmonyOS NEXT&lt;/code&gt; vs pure &lt;code&gt;OpenHarmony&lt;/code&gt;) the build configuration will differ slightly.&lt;/li&gt; 
 &lt;li&gt;Ensure that the following environment variables are set 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;DEVECO_SDK_HOME&lt;/code&gt; (Required when targeting &lt;code&gt;HarmonyOS NEXT&lt;/code&gt;)&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;OHOS_BASE_SDK_HOME&lt;/code&gt; (Required when targeting &lt;code&gt;OpenHarmony&lt;/code&gt;)&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;OHOS_SDK_NATIVE&lt;/code&gt; (e.g. &lt;code&gt;${DEVECO_SDK_HOME}/default/openharmony/native&lt;/code&gt; or &lt;code&gt;${OHOS_BASE_SDK_HOME}/${API_VERSION}/native&lt;/code&gt;)&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;SERVO_OHOS_SIGNING_CONFIG&lt;/code&gt;: Path to json file containing a valid signing configuration for the demo app.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Review the detailed instructions at [Building for OpenHarmony].&lt;/li&gt; 
 &lt;li&gt;The target distribution can be modified by passing &lt;code&gt;--flavor=&amp;lt;default|harmonyos&amp;gt;&lt;/code&gt; to &lt;code&gt;mach &amp;lt;build|package|install&amp;gt;&lt;/code&gt;.&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>tauri-apps/tauri</title>
      <link>https://github.com/tauri-apps/tauri</link>
      <description>&lt;p&gt;Build smaller, faster, and more secure desktop and mobile applications with a web frontend.&lt;/p&gt;&lt;hr&gt;&lt;img src="https://raw.githubusercontent.com/tauri-apps/tauri/dev/.github/splash.png" alt="Tauri" /&gt; 
&lt;p&gt;&lt;a href="https://github.com/tauri-apps/tauri/tree/dev"&gt;&lt;img src="https://img.shields.io/badge/status-stable-blue.svg?sanitize=true" alt="status" /&gt;&lt;/a&gt; &lt;a href="https://opencollective.com/tauri"&gt;&lt;img src="https://img.shields.io/badge/License-MIT%20or%20Apache%202-green.svg?sanitize=true" alt="License" /&gt;&lt;/a&gt; &lt;a href="https://github.com/tauri-apps/tauri/actions/workflows/test-core.yml"&gt;&lt;img src="https://img.shields.io/github/actions/workflow/status/tauri-apps/tauri/test-core.yml?label=test%20core&amp;amp;logo=github" alt="test core" /&gt;&lt;/a&gt; &lt;a href="https://app.fossa.com/projects/git%2Bgithub.com%2Ftauri-apps%2Ftauri?ref=badge_shield"&gt;&lt;img src="https://app.fossa.com/api/projects/git%2Bgithub.com%2Ftauri-apps%2Ftauri.svg?type=shield" alt="FOSSA Status" /&gt;&lt;/a&gt; &lt;a href="https://discord.com/invite/tauri"&gt;&lt;img src="https://img.shields.io/badge/chat-discord-7289da.svg?sanitize=true" alt="Chat Server" /&gt;&lt;/a&gt; &lt;a href="https://tauri.app"&gt;&lt;img src="https://img.shields.io/badge/website-tauri.app-purple.svg?sanitize=true" alt="website" /&gt;&lt;/a&gt; &lt;a href="https://good-labs.github.io/greater-good-affirmation"&gt;&lt;img src="https://good-labs.github.io/greater-good-affirmation/assets/images/badge.svg?sanitize=true" alt="https://good-labs.github.io/greater-good-affirmation/assets/images/badge.svg" /&gt;&lt;/a&gt; &lt;a href="https://opencollective.com/tauri"&gt;&lt;img src="https://img.shields.io/badge/sponsor-Open%20Collective-blue.svg?sanitize=true" alt="support" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Introduction&lt;/h2&gt; 
&lt;p&gt;Tauri is a framework for building tiny, blazingly fast binaries for all major desktop platforms. Developers can integrate any front-end framework that compiles to HTML, JS and CSS for building their user interface. The backend of the application is a rust-sourced binary with an API that the front-end can interact with.&lt;/p&gt; 
&lt;p&gt;The user interface in Tauri apps currently leverages &lt;a href="https://docs.rs/tao"&gt;&lt;code&gt;tao&lt;/code&gt;&lt;/a&gt; as a window handling library on macOS, Windows, Linux, Android and iOS. To render your application, Tauri uses &lt;a href="https://github.com/tauri-apps/wry"&gt;WRY&lt;/a&gt;, a library which provides a unified interface to the system webview, leveraging WKWebView on macOS &amp;amp; iOS, WebView2 on Windows, WebKitGTK on Linux and Android System WebView on Android.&lt;/p&gt; 
&lt;p&gt;To learn more about the details of how all of these pieces fit together, please consult this &lt;a href="https://github.com/tauri-apps/tauri/raw/dev/ARCHITECTURE.md"&gt;ARCHITECTURE.md&lt;/a&gt; document.&lt;/p&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;p&gt;If you are interested in making a tauri app, please visit the &lt;a href="https://tauri.app"&gt;documentation website&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;The quickest way to get started is to install the &lt;a href="https://v2.tauri.app/start/prerequisites/"&gt;prerequisites&lt;/a&gt; for your system and create a new project with &lt;a href="https://github.com/tauri-apps/create-tauri-app/#usage"&gt;&lt;code&gt;create-tauri-app&lt;/code&gt;&lt;/a&gt;. For example with &lt;code&gt;npm&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;npm create tauri-app@latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;p&gt;The list of Tauri's features includes, but is not limited to:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Built-in app bundler to create app bundles in formats like &lt;code&gt;.app&lt;/code&gt;, &lt;code&gt;.dmg&lt;/code&gt;, &lt;code&gt;.deb&lt;/code&gt;, &lt;code&gt;.rpm&lt;/code&gt;, &lt;code&gt;.AppImage&lt;/code&gt; and Windows installers like &lt;code&gt;.exe&lt;/code&gt; (via NSIS) and &lt;code&gt;.msi&lt;/code&gt; (via WiX).&lt;/li&gt; 
 &lt;li&gt;Built-in self updater (desktop only)&lt;/li&gt; 
 &lt;li&gt;System tray icons&lt;/li&gt; 
 &lt;li&gt;Native notifications&lt;/li&gt; 
 &lt;li&gt;Native WebView Protocol (tauri doesn't create a localhost http(s) server to serve the WebView contents)&lt;/li&gt; 
 &lt;li&gt;GitHub action for streamlined CI&lt;/li&gt; 
 &lt;li&gt;VS Code extension&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Platforms&lt;/h3&gt; 
&lt;p&gt;Tauri currently supports development and distribution on the following platforms:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Platform&lt;/th&gt; 
   &lt;th align="left"&gt;Versions&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;Windows&lt;/td&gt; 
   &lt;td align="left"&gt;7 and above&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;macOS&lt;/td&gt; 
   &lt;td align="left"&gt;10.15 and above&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;Linux&lt;/td&gt; 
   &lt;td align="left"&gt;webkit2gtk 4.0 for Tauri v1 (for example Ubuntu 18.04). webkit2gtk 4.1 for Tauri v2 (for example Ubuntu 22.04).&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;iOS/iPadOS&lt;/td&gt; 
   &lt;td align="left"&gt;9 and above&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;Android&lt;/td&gt; 
   &lt;td align="left"&gt;7 and above (currently 8 and above)&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Before you start working on something, it's best to check if there is an existing issue first. It's also a good idea to stop by the Discord server and confirm with the team if it makes sense or if someone else is already working on it.&lt;/p&gt; 
&lt;p&gt;Please make sure to read the &lt;a href="https://raw.githubusercontent.com/tauri-apps/tauri/dev/.github/CONTRIBUTING.md"&gt;Contributing Guide&lt;/a&gt; before making a pull request.&lt;/p&gt; 
&lt;p&gt;Thank you to everyone contributing to Tauri!&lt;/p&gt; 
&lt;h3&gt;Documentation&lt;/h3&gt; 
&lt;p&gt;Documentation in a polyglot system is a tricky proposition. To this end, we prefer to use inline documentation in the Rust &amp;amp; JS source code as much as possible. Check out the hosting repository for the documentation site for further information: &lt;a href="https://github.com/tauri-apps/tauri-docs"&gt;https://github.com/tauri-apps/tauri-docs&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Partners&lt;/h2&gt; 
&lt;table&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="center" valign="middle"&gt; &lt;a href="https://crabnebula.dev" target="_blank"&gt; &lt;img src="https://raw.githubusercontent.com/tauri-apps/tauri/dev/.github/sponsors/crabnebula.svg?sanitize=true" alt="CrabNebula" width="283" /&gt; &lt;/a&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;For the complete list of sponsors please visit our &lt;a href="https://tauri.app#sponsors"&gt;website&lt;/a&gt; and &lt;a href="https://opencollective.com/tauri"&gt;Open Collective&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Organization&lt;/h2&gt; 
&lt;p&gt;Tauri aims to be a sustainable collective based on principles that guide sustainable free and open software communities. To this end it has become a Programme within the &lt;a href="https://commonsconservancy.org/"&gt;Commons Conservancy&lt;/a&gt;, and you can contribute financially via &lt;a href="https://opencollective.com/tauri"&gt;Open Collective&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Licenses&lt;/h2&gt; 
&lt;p&gt;Code: (c) 2015 - Present - The Tauri Programme within The Commons Conservancy.&lt;/p&gt; 
&lt;p&gt;MIT or MIT/Apache 2.0 where applicable.&lt;/p&gt; 
&lt;p&gt;Logo: CC-BY-NC-ND&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Original Tauri Logo Designs by &lt;a href="https://alve.io/"&gt;Alve Larsson&lt;/a&gt;, &lt;a href="https://github.com/nothingismagick"&gt;Daniel Thompson-Yvetot&lt;/a&gt; and &lt;a href="https://github.com/akryum"&gt;Guillaume Chau&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://app.fossa.com/projects/git%2Bgithub.com%2Ftauri-apps%2Ftauri?ref=badge_large"&gt;&lt;img src="https://app.fossa.com/api/projects/git%2Bgithub.com%2Ftauri-apps%2Ftauri.svg?type=large" alt="FOSSA Status" /&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>tree-sitter/tree-sitter</title>
      <link>https://github.com/tree-sitter/tree-sitter</link>
      <description>&lt;p&gt;An incremental parsing system for programming tools&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;tree-sitter&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://zenodo.org/badge/latestdoi/14164618"&gt;&lt;img src="https://zenodo.org/badge/14164618.svg?sanitize=true" alt="DOI" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/w7nTvsVJhm"&gt;&lt;img src="https://img.shields.io/discord/1063097320771698699?logo=discord&amp;amp;label=discord" alt="discord" /&gt;&lt;/a&gt; &lt;a href="https://matrix.to/#/#tree-sitter-chat:matrix.org"&gt;&lt;img src="https://img.shields.io/matrix/tree-sitter-chat%3Amatrix.org?logo=matrix&amp;amp;label=matrix" alt="matrix" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Tree-sitter is a parser generator tool and an incremental parsing library. It can build a concrete syntax tree for a source file and efficiently update the syntax tree as the source file is edited. Tree-sitter aims to be:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;General&lt;/strong&gt; enough to parse any programming language&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Fast&lt;/strong&gt; enough to parse on every keystroke in a text editor&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Robust&lt;/strong&gt; enough to provide useful results even in the presence of syntax errors&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Dependency-free&lt;/strong&gt; so that the runtime library (which is written in pure C) can be embedded in any application&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Links&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://tree-sitter.github.io"&gt;Documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tree-sitter/tree-sitter/master/lib/binding_rust/README.md"&gt;Rust binding&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tree-sitter/tree-sitter/master/lib/binding_web/README.md"&gt;Wasm binding&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tree-sitter/tree-sitter/master/crates/cli/README.md"&gt;Command-line interface&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>qarmin/czkawka</title>
      <link>https://github.com/qarmin/czkawka</link>
      <description>&lt;p&gt;Multi functional app to find duplicates, empty folders, similar images etc.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/567a7a38-d754-4a79-86b5-3cc898dbbade" alt="krokiet_logo" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Krokiet&lt;/strong&gt; ((IPA: [Ààkr…îc…õt]), "croquette" in Polish) new generation GUI frontend, simple, multiplatform, fast and free app to remove unnecessary files from your computer.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://user-images.githubusercontent.com/41945903/102616149-66490400-4137-11eb-9cd6-813b2b070834.png" alt="czkawka_logo" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Czkawka&lt;/strong&gt; (&lt;em&gt;tch‚Ä¢kav‚Ä¢ka&lt;/em&gt; (IPA: [Àà ßÃëkafka]), "hiccup" in Polish) older gtk4 GUI frontend, superseded by Krokiet, but still receiving bugfix updates.&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Written in memory-safe Rust - almost 100% unsafe code free&lt;/li&gt; 
 &lt;li&gt;Amazingly fast - due to using more or less advanced algorithms and multithreading&lt;/li&gt; 
 &lt;li&gt;Free, Open Source without ads&lt;/li&gt; 
 &lt;li&gt;Multiplatform - works on Linux, Windows, macOS, FreeBSD and many more&lt;/li&gt; 
 &lt;li&gt;Cache support - second and further scans should be much faster than the first one&lt;/li&gt; 
 &lt;li&gt;CLI frontend - for easy automation&lt;/li&gt; 
 &lt;li&gt;GUI frontend - uses Slint or GTK 4 frameworks&lt;/li&gt; 
 &lt;li&gt;Core library - allows to reuse functionality in other apps&lt;/li&gt; 
 &lt;li&gt;No spying - Czkawka does not have access to the Internet, nor does it collect any user information or statistics&lt;/li&gt; 
 &lt;li&gt;Multilingual - support multiple languages like Polish, English or Italian&lt;/li&gt; 
 &lt;li&gt;Multiple tools to use: 
  &lt;ul&gt; 
   &lt;li&gt;Duplicates - Finds duplicates based on file name, size or hash&lt;/li&gt; 
   &lt;li&gt;Empty Folders - Finds empty folders with the help of an advanced algorithm&lt;/li&gt; 
   &lt;li&gt;Big Files - Finds the provided number of the biggest files in given location&lt;/li&gt; 
   &lt;li&gt;Empty Files - Looks for empty files across the drive&lt;/li&gt; 
   &lt;li&gt;Temporary Files - Finds temporary files&lt;/li&gt; 
   &lt;li&gt;Similar Images - Finds images which are not exactly the same (different resolution, watermarks)&lt;/li&gt; 
   &lt;li&gt;Similar Videos - Looks for visually similar videos&lt;/li&gt; 
   &lt;li&gt;Same Music - Searches for similar music by tags or by reading content and comparing it&lt;/li&gt; 
   &lt;li&gt;Invalid Symbolic Links - Shows symbolic links which point to non-existent files/directories&lt;/li&gt; 
   &lt;li&gt;Broken Files - Finds files that are invalid or corrupted&lt;/li&gt; 
   &lt;li&gt;Bad Extensions - Lists files whose content not match with their extension&lt;/li&gt; 
   &lt;li&gt;Exif Remover - Removes Exif metadata from various file types&lt;/li&gt; 
   &lt;li&gt;Video Optimizer - Crops from static parts and converts videos to more efficient formats&lt;/li&gt; 
   &lt;li&gt;Bad Names - Finds files with names that may be not wanted (e.g., containing special characters)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/720e98c3-598a-41aa-a04b-0c0c1d8a28e6" alt="Krokiet" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/b0409515-1bec-4e13-8fac-7bdfa15f5848" alt="Czkawka" /&gt;&lt;/p&gt; 
&lt;p&gt;Changelog about each version can be found in &lt;a href="https://raw.githubusercontent.com/qarmin/czkawka/master/Changelog.md"&gt;CHANGELOG.md&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;New releases can be found in &lt;a href="https://github.com/qarmin/czkawka/releases"&gt;Github releases&lt;/a&gt; and nightly builds also in &lt;a href="https://github.com/qarmin/czkawka/releases/tag/Nightly"&gt;Nightly releases&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Usage, installation, compilation, requirements, license&lt;/h2&gt; 
&lt;p&gt;Each tool uses different technologies, so you can find instructions for each of them in the appropriate file:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/qarmin/czkawka/master/krokiet/README.md"&gt;Krokiet GUI (Slint frontend)&lt;/a&gt;&lt;br /&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/qarmin/czkawka/master/czkawka_gui/README.md"&gt;Czkawka GUI (GTK frontend)&lt;/a&gt;&lt;br /&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/qarmin/czkawka/master/czkawka_cli/README.md"&gt;Czkawka CLI&lt;/a&gt;&lt;br /&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/qarmin/czkawka/master/czkawka_core/README.md"&gt;Czkawka Core&lt;/a&gt;&lt;br /&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Comparison to other tools&lt;/h2&gt; 
&lt;p&gt;Bleachbit is a master at finding and removing temporary files, while Czkawka only finds the most basic ones. So these two apps shouldn't be compared directly or be considered as an alternative to one another.&lt;/p&gt; 
&lt;p&gt;In this comparison remember, that even if app have same features they may work different(e.g. one app may have more options to choose than other).&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="center"&gt;&lt;/th&gt; 
   &lt;th align="center"&gt;Czkawka&lt;/th&gt; 
   &lt;th align="center"&gt;Krokiet&lt;/th&gt; 
   &lt;th align="center"&gt;FSlint&lt;/th&gt; 
   &lt;th align="center"&gt;DupeGuru&lt;/th&gt; 
   &lt;th align="center"&gt;Bleachbit&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;Language&lt;/td&gt; 
   &lt;td align="center"&gt;Rust&lt;/td&gt; 
   &lt;td align="center"&gt;Rust&lt;/td&gt; 
   &lt;td align="center"&gt;Python&lt;/td&gt; 
   &lt;td align="center"&gt;Python/Obj-C&lt;/td&gt; 
   &lt;td align="center"&gt;Python&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;Framework base language&lt;/td&gt; 
   &lt;td align="center"&gt;C&lt;/td&gt; 
   &lt;td align="center"&gt;Rust&lt;/td&gt; 
   &lt;td align="center"&gt;C&lt;/td&gt; 
   &lt;td align="center"&gt;C/C++/Obj-C/Swift&lt;/td&gt; 
   &lt;td align="center"&gt;C&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;Framework&lt;/td&gt; 
   &lt;td align="center"&gt;GTK 4&lt;/td&gt; 
   &lt;td align="center"&gt;Slint&lt;/td&gt; 
   &lt;td align="center"&gt;PyGTK2&lt;/td&gt; 
   &lt;td align="center"&gt;Qt 5 (PyQt)/Cocoa&lt;/td&gt; 
   &lt;td align="center"&gt;PyGTK3&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;OS&lt;/td&gt; 
   &lt;td align="center"&gt;Lin,Mac,Win&lt;/td&gt; 
   &lt;td align="center"&gt;Lin,Mac,Win&lt;/td&gt; 
   &lt;td align="center"&gt;Lin&lt;/td&gt; 
   &lt;td align="center"&gt;Lin,Mac,Win&lt;/td&gt; 
   &lt;td align="center"&gt;Lin,Mac,Win&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;Duplicate finder&lt;/td&gt; 
   &lt;td align="center"&gt;‚úî&lt;/td&gt; 
   &lt;td align="center"&gt;‚úî&lt;/td&gt; 
   &lt;td align="center"&gt;‚úî&lt;/td&gt; 
   &lt;td align="center"&gt;‚úî&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;Empty files&lt;/td&gt; 
   &lt;td align="center"&gt;‚úî&lt;/td&gt; 
   &lt;td align="center"&gt;‚úî&lt;/td&gt; 
   &lt;td align="center"&gt;‚úî&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;Empty folders&lt;/td&gt; 
   &lt;td align="center"&gt;‚úî&lt;/td&gt; 
   &lt;td align="center"&gt;‚úî&lt;/td&gt; 
   &lt;td align="center"&gt;‚úî&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;Temporary files&lt;/td&gt; 
   &lt;td align="center"&gt;‚úî&lt;/td&gt; 
   &lt;td align="center"&gt;‚úî&lt;/td&gt; 
   &lt;td align="center"&gt;‚úî&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;‚úî&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;Big files&lt;/td&gt; 
   &lt;td align="center"&gt;‚úî&lt;/td&gt; 
   &lt;td align="center"&gt;‚úî&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;Similar images&lt;/td&gt; 
   &lt;td align="center"&gt;‚úî&lt;/td&gt; 
   &lt;td align="center"&gt;‚úî&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;‚úî&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;Similar videos&lt;/td&gt; 
   &lt;td align="center"&gt;‚úî&lt;/td&gt; 
   &lt;td align="center"&gt;‚úî&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;Music duplicates(tags)&lt;/td&gt; 
   &lt;td align="center"&gt;‚úî&lt;/td&gt; 
   &lt;td align="center"&gt;‚úî&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;‚úî&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;Music duplicates(content)&lt;/td&gt; 
   &lt;td align="center"&gt;‚úî&lt;/td&gt; 
   &lt;td align="center"&gt;‚úî&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;Invalid symlinks&lt;/td&gt; 
   &lt;td align="center"&gt;‚úî&lt;/td&gt; 
   &lt;td align="center"&gt;‚úî&lt;/td&gt; 
   &lt;td align="center"&gt;‚úî&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;Broken files&lt;/td&gt; 
   &lt;td align="center"&gt;‚úî&lt;/td&gt; 
   &lt;td align="center"&gt;‚úî&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;Invalid names/extensions&lt;/td&gt; 
   &lt;td align="center"&gt;‚úî&lt;/td&gt; 
   &lt;td align="center"&gt;‚úî&lt;/td&gt; 
   &lt;td align="center"&gt;‚úî&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;Exif cleaner&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;‚úî&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;Video optimizer&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;‚úî&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;Bad Names&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;‚úî&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;Names conflict&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;‚úî&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;Installed packages&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;‚úî&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;Bad ID&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;‚úî&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;Non stripped binaries&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;‚úî&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;Redundant whitespace&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;‚úî&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;Overwriting files&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;‚úî&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;‚úî&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;Portable version&lt;/td&gt; 
   &lt;td align="center"&gt;‚úî&lt;/td&gt; 
   &lt;td align="center"&gt;‚úî&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;‚úî&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;Multiple languages&lt;/td&gt; 
   &lt;td align="center"&gt;‚úî&lt;/td&gt; 
   &lt;td align="center"&gt;‚úî&lt;/td&gt; 
   &lt;td align="center"&gt;‚úî&lt;/td&gt; 
   &lt;td align="center"&gt;‚úî&lt;/td&gt; 
   &lt;td align="center"&gt;‚úî&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;Cache support&lt;/td&gt; 
   &lt;td align="center"&gt;‚úî&lt;/td&gt; 
   &lt;td align="center"&gt;‚úî&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;‚úî&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;In active development&lt;/td&gt; 
   &lt;td align="center"&gt;Yes&lt;sup&gt;**&lt;/sup&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;Yes&lt;/td&gt; 
   &lt;td align="center"&gt;No&lt;/td&gt; 
   &lt;td align="center"&gt;No&lt;sup&gt;*&lt;/sup&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;sup&gt;*&lt;/sup&gt; Few small commits added recently and last version released in 2023&lt;/p&gt; 
&lt;p&gt;&lt;sup&gt;**&lt;/sup&gt; Czkawka GTK is in maintenance mode receiving only bugfixes&lt;/p&gt; 
&lt;h2&gt;Other apps&lt;/h2&gt; 
&lt;p&gt;There are many similar applications to Czkawka on the Internet, which do some things better and some things worse:&lt;/p&gt; 
&lt;h3&gt;GUI&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/arsenetar/dupeguru"&gt;DupeGuru&lt;/a&gt; - Many options to customize; great photo compare tool&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pixelb/fslint"&gt;FSlint&lt;/a&gt; - A little outdated, but still have some tools not available in Czkawka&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ermig1979/AntiDupl"&gt;AntiDupl.NET&lt;/a&gt; - Shows a lot of metadata of compared images&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/0x90d/videoduplicatefinder"&gt;Video Duplicate Finder&lt;/a&gt; - Finds similar videos(surprising, isn't it), supports video thumbnails&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;CLI&lt;/h3&gt; 
&lt;p&gt;Due to limited time, the biggest emphasis is on the GUI version so if you are looking for really good and feature-packed console apps, then take a look at these:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pkolaczk/fclones"&gt;Fclones&lt;/a&gt; - One of the fastest tools to find duplicates; it is written also in Rust&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/sahib/rmlint"&gt;Rmlint&lt;/a&gt; - Nice console interface and also is feature packed&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pauldreik/rdfind"&gt;RdFind&lt;/a&gt; - Fast, but written in C++ ¬Ø\_(„ÉÑ)_/¬Ø&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Projects using Czkawka&lt;/h2&gt; 
&lt;p&gt;Czkawka exposes its common functionality through a crate called &lt;strong&gt;&lt;code&gt;czkawka_core&lt;/code&gt;&lt;/strong&gt;, which can be reused by other projects.&lt;/p&gt; 
&lt;p&gt;It is written in Rust and is used by all Czkawka frontends (&lt;code&gt;czkawka_gui&lt;/code&gt;, &lt;code&gt;czkawka_cli&lt;/code&gt;, &lt;code&gt;krokiet&lt;/code&gt;).&lt;/p&gt; 
&lt;p&gt;It is also used by external projects, such as:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Czkawka Tauri&lt;/strong&gt; - &lt;a href="https://github.com/shixinhuang99/czkawka-tauri"&gt;https://github.com/shixinhuang99/czkawka-tauri&lt;/a&gt; - A Tauri-based GUI frontend for Czkawka.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;page-dewarp&lt;/strong&gt; ‚Äì &lt;a href="https://github.com/lmmx/page-dewarp"&gt;https://github.com/lmmx/page-dewarp&lt;/a&gt; - A library for dewarping document images using a cubic sheet model.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Bindings are also available for:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Python&lt;/strong&gt; ‚Äì &lt;a href="https://pypi.org/project/czkawka/"&gt;https://pypi.org/project/czkawka/&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Some projects work as wrappers around &lt;code&gt;czkawka_cli&lt;/code&gt;. Without directly depending on &lt;code&gt;czkawka_core&lt;/code&gt;, they allow simple scanning and retrieving results in JSON format:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Schluckauf&lt;/strong&gt; ‚Äì &lt;a href="https://github.com/fadykuzman/schluckauf"&gt;https://github.com/fadykuzman/schluckauf&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Thanks&lt;/h2&gt; 
&lt;p&gt;Big thanks to P√°draig Brady, creator of fantastic FSlint, because without his work I wouldn't create this tool.&lt;/p&gt; 
&lt;p&gt;Thanks also to all the people who create patches for this program, create and fix translations, make it available on other systems, create videos, articles about it etc.&lt;/p&gt; 
&lt;p&gt;Also, I really appreciate work of people that create crates on which Czkawka is based and for that I try to report bugs to make it even better.&lt;/p&gt; 
&lt;h2&gt;Officially Supported Projects&lt;/h2&gt; 
&lt;p&gt;Only this repository, &lt;a href="https://github.com/qarmin/czkawka/releases"&gt;prebuild-binaries&lt;/a&gt;, projects on &lt;a href="https://crates.io/crates/czkawka_gui"&gt;crates.io&lt;/a&gt; and &lt;a href="https://flathub.org/apps/com.github.qarmin.czkawka"&gt;flathub&lt;/a&gt; are directly maintained by me.&lt;/p&gt; 
&lt;p&gt;Czkawka does not have an official website, so do not trust any sites that claim to be the official one.&lt;/p&gt; 
&lt;p&gt;If you use packages from unofficial sources, make sure they are safe.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;The entire code in this repository is licensed under the &lt;a href="https://mit-license.org/"&gt;MIT&lt;/a&gt; license.&lt;/p&gt; 
&lt;p&gt;All images are licensed under the &lt;a href="https://creativecommons.org/licenses/by/4.0/"&gt;CC BY 4.0&lt;/a&gt; license.&lt;/p&gt; 
&lt;p&gt;The Czkawka GTK GUI and CLI applications are licensed under the &lt;a href="https://mit-license.org/"&gt;MIT&lt;/a&gt; license, while the Krokiet is licensed under the &lt;a href="https://www.gnu.org/licenses/gpl-3.0.en.html"&gt;GPL-3.0-only&lt;/a&gt; license.&lt;/p&gt; 
&lt;h2&gt;Donations&lt;/h2&gt; 
&lt;p&gt;If you are using the app, I would appreciate a donation for its further development, which can be done &lt;a href="https://github.com/sponsors/qarmin"&gt;here&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>sxyazi/yazi</title>
      <link>https://github.com/sxyazi/yazi</link>
      <description>&lt;p&gt;üí• Blazing fast terminal file manager written in Rust, based on async I/O.&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;a href="https://go.warp.dev/yazi" target="_blank"&gt; &lt;sup&gt;Special thanks to:&lt;/sup&gt; &lt;br /&gt; &lt;img alt="Warp sponsorship" width="400" src="https://github.com/warpdotdev/brand-assets/raw/main/Github/Sponsor/Warp-Github-LG-02.png" /&gt; &lt;br /&gt; 
  &lt;h&gt;
   Warp, built for coding with multiple AI agents 
   &lt;br /&gt; 
   &lt;sup&gt;Available for macOS, Linux and Windows&lt;/sup&gt; 
  &lt;/h&gt;&lt;/a&gt; 
&lt;/div&gt; 
&lt;br /&gt; 
&lt;h2&gt;Yazi - ‚ö°Ô∏è Blazing Fast Terminal File Manager&lt;/h2&gt; 
&lt;p&gt;Yazi (means "duck") is a terminal file manager written in Rust, based on non-blocking async I/O. It aims to provide an efficient, user-friendly, and customizable file management experience.&lt;/p&gt; 
&lt;p&gt;üí° A new article explaining its internal workings: &lt;a href="https://yazi-rs.github.io/blog/why-is-yazi-fast"&gt;Why is Yazi Fast?&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;üöÄ &lt;strong&gt;Full Asynchronous Support&lt;/strong&gt;: All I/O operations are asynchronous, CPU tasks are spread across multiple threads, making the most of available resources.&lt;/li&gt; 
 &lt;li&gt;üí™ &lt;strong&gt;Powerful Async Task Scheduling and Management&lt;/strong&gt;: Provides real-time progress updates, task cancellation, and internal task priority assignment.&lt;/li&gt; 
 &lt;li&gt;üñºÔ∏è &lt;strong&gt;Built-in Support for Multiple Image Protocols&lt;/strong&gt;: Also integrated with √úberzug++ and Chafa, covering almost all terminals.&lt;/li&gt; 
 &lt;li&gt;üåü &lt;strong&gt;Built-in Code Highlighting and Image Decoding&lt;/strong&gt;: Combined with the pre-loading mechanism, greatly accelerates image and normal file loading.&lt;/li&gt; 
 &lt;li&gt;üîå &lt;strong&gt;Concurrent Plugin System&lt;/strong&gt;: UI plugins (rewriting most of the UI), functional plugins, custom previewer/preloader/spotter/fetcher; Just some pieces of Lua.&lt;/li&gt; 
 &lt;li&gt;‚òÅÔ∏è &lt;strong&gt;Virtual Filesystem&lt;/strong&gt;: Remote file management, custom search engines.&lt;/li&gt; 
 &lt;li&gt;üì° &lt;strong&gt;Data Distribution Service&lt;/strong&gt;: Built on a client-server architecture (no additional server process required), integrated with a Lua-based publish-subscribe model, achieving cross-instance communication and state persistence.&lt;/li&gt; 
 &lt;li&gt;üì¶ &lt;strong&gt;Package Manager&lt;/strong&gt;: Install plugins and themes with one command, keeping them up-to-date, or pin them to a specific version.&lt;/li&gt; 
 &lt;li&gt;üß∞ Integration with ripgrep, fd, fzf, zoxide&lt;/li&gt; 
 &lt;li&gt;üí´ Vim-like input/pick/confirm/which/notify component, auto-completion for cd paths&lt;/li&gt; 
 &lt;li&gt;üè∑Ô∏è Multi-Tab Support, Cross-directory selection, Scrollable Preview (for videos, PDFs, archives, code, directories, etc.)&lt;/li&gt; 
 &lt;li&gt;üîÑ Bulk Renaming, Archive Extraction, Visual Mode, File Chooser, &lt;a href="https://github.com/yazi-rs/plugins/tree/main/git.yazi"&gt;Git Integration&lt;/a&gt;, &lt;a href="https://github.com/yazi-rs/plugins/tree/main/mount.yazi"&gt;Mount Manager&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üé® Theme System, Mouse Support, Trash Bin, Custom Layouts, CSI u, OSC 52&lt;/li&gt; 
 &lt;li&gt;... and more!&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://github.com/sxyazi/yazi/assets/17523360/92ff23fa-0cd5-4f04-b387-894c12265cc7"&gt;https://github.com/sxyazi/yazi/assets/17523360/92ff23fa-0cd5-4f04-b387-894c12265cc7&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Project status&lt;/h2&gt; 
&lt;p&gt;Public beta, can be used as a daily driver.&lt;/p&gt; 
&lt;p&gt;Yazi is currently in heavy development, expect breaking changes.&lt;/p&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Usage: &lt;a href="https://yazi-rs.github.io/docs/installation"&gt;https://yazi-rs.github.io/docs/installation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Features: &lt;a href="https://yazi-rs.github.io/features"&gt;https://yazi-rs.github.io/features&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Discussion&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Discord Server (English mainly): &lt;a href="https://discord.gg/qfADduSdJu"&gt;https://discord.gg/qfADduSdJu&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Telegram Group (Chinese mainly): &lt;a href="https://t.me/yazi_rs"&gt;https://t.me/yazi_rs&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Image Preview&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Platform&lt;/th&gt; 
   &lt;th&gt;Protocol&lt;/th&gt; 
   &lt;th&gt;Support&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/kovidgoyal/kitty"&gt;kitty&lt;/a&gt; (&amp;gt;= 0.28.0)&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://sw.kovidgoyal.net/kitty/graphics-protocol/#unicode-placeholders"&gt;Kitty unicode placeholders&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ Built-in&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://iterm2.com"&gt;iTerm2&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://iterm2.com/documentation-images.html"&gt;Inline images protocol&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ Built-in&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/wez/wezterm"&gt;WezTerm&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://iterm2.com/documentation-images.html"&gt;Inline images protocol&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ Built-in&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://invent.kde.org/utilities/konsole"&gt;Konsole&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/sxyazi/yazi/raw/main/yazi-adapter/src/drivers/kgp_old.rs"&gt;Kitty old protocol&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ Built-in&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://codeberg.org/dnkl/foot"&gt;foot&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.vt100.net/docs/vt3xx-gp/chapter14.html"&gt;Sixel graphics format&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ Built-in&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/ghostty-org/ghostty"&gt;Ghostty&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://sw.kovidgoyal.net/kitty/graphics-protocol/#unicode-placeholders"&gt;Kitty unicode placeholders&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ Built-in&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/microsoft/terminal"&gt;Windows Terminal&lt;/a&gt; (&amp;gt;= v1.22.10352.0)&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.vt100.net/docs/vt3xx-gp/chapter14.html"&gt;Sixel graphics format&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ Built-in&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/bakkeby/st-flexipatch"&gt;st with Sixel patch&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.vt100.net/docs/vt3xx-gp/chapter14.html"&gt;Sixel graphics format&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ Built-in&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://www.warp.dev"&gt;Warp&lt;/a&gt; (macOS/Linux only)&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://iterm2.com/documentation-images.html"&gt;Inline images protocol&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ Built-in&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/Eugeny/tabby"&gt;Tabby&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://iterm2.com/documentation-images.html"&gt;Inline images protocol&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ Built-in&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/microsoft/vscode"&gt;VSCode&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://iterm2.com/documentation-images.html"&gt;Inline images protocol&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ Built-in&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/raphamorim/rio"&gt;Rio&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://iterm2.com/documentation-images.html"&gt;Inline images protocol&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚ùå Rio renders images at incorrect sizes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://gitlab.gnome.org/raggesilver/blackbox"&gt;Black Box&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.vt100.net/docs/vt3xx-gp/chapter14.html"&gt;Sixel graphics format&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ Built-in&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/ismail-yilmaz/Bobcat"&gt;Bobcat&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://iterm2.com/documentation-images.html"&gt;Inline images protocol&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ Built-in&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;X11 / Wayland&lt;/td&gt; 
   &lt;td&gt;Window system protocol&lt;/td&gt; 
   &lt;td&gt;‚òëÔ∏è &lt;a href="https://github.com/jstkdng/ueberzugpp"&gt;√úberzug++&lt;/a&gt; required&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Fallback&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://en.wikipedia.org/wiki/ASCII_art"&gt;ASCII art (Unicode block)&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚òëÔ∏è &lt;a href="https://hpjansson.org/chafa/"&gt;Chafa&lt;/a&gt; required&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;See &lt;a href="https://yazi-rs.github.io/docs/image-preview"&gt;https://yazi-rs.github.io/docs/image-preview&lt;/a&gt; for details.&lt;/p&gt; 
&lt;!-- Protocols --&gt; 
&lt;!-- Dependencies --&gt; 
&lt;h2&gt;Special Thanks&lt;/h2&gt; 
&lt;img alt="RustRover logo" align="right" width="200" src="https://resources.jetbrains.com/storage/products/company/brand/logos/RustRover.svg?sanitize=true" /&gt; 
&lt;p&gt;Thanks to RustRover team for providing open-source licenses to support the maintenance of Yazi.&lt;/p&gt; 
&lt;p&gt;Active code contributors can contact @sxyazi to get a license (if any are still available).&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Yazi is MIT-licensed. For more information check the &lt;a href="https://raw.githubusercontent.com/sxyazi/yazi/main/LICENSE"&gt;LICENSE&lt;/a&gt; file.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>jdx/mise</title>
      <link>https://github.com/jdx/mise</link>
      <description>&lt;p&gt;dev tools, env vars, task runner&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;h1 align="center"&gt; &lt;a href="https://mise.jdx.dev"&gt; &lt;img src="https://raw.githubusercontent.com/jdx/mise/main/docs/public/logo.svg?sanitize=true" alt="mise" width="256" height="256" /&gt; &lt;br /&gt; mise-en-place &lt;/a&gt; &lt;/h1&gt; 
 &lt;p&gt; &lt;a href="https://crates.io/crates/mise"&gt;&lt;img alt="Crates.io" src="https://img.shields.io/crates/v/mise?style=for-the-badge&amp;amp;color=00d9ff" /&gt;&lt;/a&gt; &lt;a href="https://github.com/jdx/mise/raw/main/LICENSE"&gt;&lt;img alt="GitHub" src="https://img.shields.io/github/license/jdx/mise?style=for-the-badge&amp;amp;color=52e892" /&gt;&lt;/a&gt; &lt;a href="https://github.com/jdx/mise/actions/workflows/test.yml"&gt;&lt;img alt="GitHub Workflow Status" src="https://img.shields.io/github/actions/workflow/status/jdx/mise/test.yml?style=for-the-badge&amp;amp;color=ff9100" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/mABnUDvP57"&gt;&lt;img alt="Discord" src="https://img.shields.io/discord/1066429325269794907?style=for-the-badge&amp;amp;color=00d9ff" /&gt;&lt;/a&gt; &lt;/p&gt; 
 &lt;p&gt;&lt;b&gt;The front-end to your dev env&lt;/b&gt;&lt;/p&gt; 
 &lt;p align="center"&gt; &lt;a href="https://mise.jdx.dev/getting-started.html"&gt;Getting Started&lt;/a&gt; ‚Ä¢ &lt;a href="https://mise.jdx.dev"&gt;Documentation&lt;/a&gt; ‚Ä¢ &lt;a href="https://mise.jdx.dev/dev-tools/"&gt;Dev Tools&lt;/a&gt; ‚Ä¢ &lt;a href="https://mise.jdx.dev/environments/"&gt;Environments&lt;/a&gt; ‚Ä¢ &lt;a href="https://mise.jdx.dev/tasks/"&gt;Tasks&lt;/a&gt; &lt;/p&gt; 
 &lt;hr /&gt; 
&lt;/div&gt; 
&lt;h2&gt;What is it?&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Like &lt;a href="https://asdf-vm.com"&gt;asdf&lt;/a&gt; (or &lt;a href="https://github.com/nvm-sh/nvm"&gt;nvm&lt;/a&gt; or &lt;a href="https://github.com/pyenv/pyenv"&gt;pyenv&lt;/a&gt; but for any language) it manages &lt;a href="https://mise.jdx.dev/dev-tools/"&gt;dev tools&lt;/a&gt; like node, python, cmake, terraform, and &lt;a href="https://mise.jdx.dev/registry.html"&gt;hundreds more&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Like &lt;a href="https://github.com/direnv/direnv"&gt;direnv&lt;/a&gt; it manages &lt;a href="https://mise.jdx.dev/environments/"&gt;environment variables&lt;/a&gt; for different project directories.&lt;/li&gt; 
 &lt;li&gt;Like &lt;a href="https://www.gnu.org/software/make/manual/make.html"&gt;make&lt;/a&gt; it manages &lt;a href="https://mise.jdx.dev/tasks/"&gt;tasks&lt;/a&gt; used to build and test projects.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Demo&lt;/h2&gt; 
&lt;p&gt;The following demo shows how to install and use &lt;code&gt;mise&lt;/code&gt; to manage multiple versions of &lt;code&gt;node&lt;/code&gt; on the same system. Note that calling &lt;code&gt;which node&lt;/code&gt; gives us a real path to node, not a shim.&lt;/p&gt; 
&lt;p&gt;It also shows that you can use &lt;code&gt;mise&lt;/code&gt; to install and many other tools such as &lt;code&gt;jq&lt;/code&gt;, &lt;code&gt;terraform&lt;/code&gt;, or &lt;code&gt;go&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://mise.jdx.dev/demo.html"&gt;&lt;img src="https://raw.githubusercontent.com/jdx/mise/main/docs/tapes/demo.gif" alt="demo" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;See &lt;a href="https://mise.jdx.dev/demo.html"&gt;demo transcript&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Quickstart&lt;/h2&gt; 
&lt;h3&gt;Install mise&lt;/h3&gt; 
&lt;p&gt;See &lt;a href="https://mise.jdx.dev/getting-started.html"&gt;Getting started&lt;/a&gt; for more options.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh-session"&gt;$ curl https://mise.run | sh
$ ~/.local/bin/mise --version
              _                                        __
   ____ ___  (_)_______        ___  ____        ____  / /___ _________
  / __ `__ \/ / ___/ _ \______/ _ \/ __ \______/ __ \/ / __ `/ ___/ _ \
 / / / / / / (__  )  __/_____/  __/ / / /_____/ /_/ / / /_/ / /__/  __/
/_/ /_/ /_/_/____/\___/      \___/_/ /_/     / .___/_/\__,_/\___/\___/
                                            /_/                 by @jdx
2026.1.7 macos-arm64 (2026-01-25)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Hook mise into your shell (pick the right one for your shell):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh-session"&gt;# note this assumes mise is located at ~/.local/bin/mise
# which is what https://mise.run does by default
echo 'eval "$(~/.local/bin/mise activate bash)"' &amp;gt;&amp;gt; ~/.bashrc
echo 'eval "$(~/.local/bin/mise activate zsh)"' &amp;gt;&amp;gt; ~/.zshrc
echo '~/.local/bin/mise activate fish | source' &amp;gt;&amp;gt; ~/.config/fish/config.fish
echo '~/.local/bin/mise activate pwsh | Out-String | Invoke-Expression' &amp;gt;&amp;gt; ~/.config/powershell/Microsoft.PowerShell_profile.ps1
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Execute commands with specific tools&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-sh-session"&gt;$ mise exec node@24 -- node -v
mise node@24.x.x ‚úì installed
v24.x.x
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Install tools&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-sh-session"&gt;$ mise use --global node@24 go@1
$ node -v
v24.x.x
$ go version
go version go1.x.x macos/arm64
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See &lt;a href="https://mise.jdx.dev/dev-tools/"&gt;dev tools&lt;/a&gt; for more examples.&lt;/p&gt; 
&lt;h3&gt;Manage environment variables&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# mise.toml
[env]
SOME_VAR = "foo"
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-sh-session"&gt;$ mise set SOME_VAR=bar
$ echo $SOME_VAR
bar
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Note that &lt;code&gt;mise&lt;/code&gt; can also &lt;a href="https://mise.jdx.dev/environments/#env-directives"&gt;load &lt;code&gt;.env&lt;/code&gt; files&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Run tasks&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# mise.toml
[tasks.build]
description = "build the project"
run = "echo building..."
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-sh-session"&gt;$ mise run build
building...
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See &lt;a href="https://mise.jdx.dev/tasks/"&gt;tasks&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;h3&gt;Example mise project&lt;/h3&gt; 
&lt;p&gt;Here is a combined example to give you an idea of how you can use mise to manage your a project's tools, environment, and tasks.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# mise.toml
[tools]
terraform = "1"
aws-cli = "2"

[env]
TF_WORKSPACE = "development"
AWS_REGION = "us-west-2"
AWS_PROFILE = "dev"

[tasks.plan]
description = "Run terraform plan with configured workspace"
run = """
terraform init
terraform workspace select $TF_WORKSPACE
terraform plan
"""

[tasks.validate]
description = "Validate AWS credentials and terraform config"
run = """
aws sts get-caller-identity
terraform validate
"""

[tasks.deploy]
description = "Deploy infrastructure after validation"
depends = ["validate", "plan"]
run = "terraform apply -auto-approve"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Run it with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh-session"&gt;mise install # install tools specified in mise.toml
mise run deploy
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Find more examples in the &lt;a href="https://mise.jdx.dev/mise-cookbook/"&gt;mise cookbook&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Full Documentation&lt;/h2&gt; 
&lt;p&gt;See &lt;a href="https://mise.jdx.dev"&gt;mise.jdx.dev&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;GitHub Issues &amp;amp; Discussions&lt;/h2&gt; 
&lt;p&gt;Due to the volume of issue submissions mise received, using GitHub Issues became unsustainable for the project. Instead, mise uses GitHub Discussions which provide a more community-centric platform for communication and require less management on the part of the maintainers.&lt;/p&gt; 
&lt;p&gt;Please note the following discussion categories, which match how issues are often used:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jdx/mise/discussions/categories/announcements"&gt;Announcements&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jdx/mise/discussions/categories/ideas"&gt;Ideas&lt;/a&gt;: for feature requests, etc.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jdx/mise/discussions/categories/troubleshooting-and-bug-reports"&gt;Troubleshooting &amp;amp; Bug Reports&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Special Thanks&lt;/h2&gt; 
&lt;p&gt;We're grateful for Cloudflare's support through &lt;a href="https://www.cloudflare.com/lp/project-alexandria/"&gt;Project Alexandria&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Contributors&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://github.com/jdx/mise/graphs/contributors"&gt;&lt;img src="https://contrib.rocks/image?repo=jdx/mise" alt="Contributors" /&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>tonybanters/oxwm</title>
      <link>https://github.com/tonybanters/oxwm</link>
      <description>&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;p&gt;#+AUTHOR: Tony #+STARTUP: overview&lt;/p&gt; 
&lt;p&gt;[[file:./images/oxwm1.png]]&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Table of Contents :toc:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;ul&gt; 
 &lt;li&gt;[[#oxwm--dwm-but-better-and-oxidized][OXWM ‚Äî DWM but Better (and oxidized)]]&lt;/li&gt; 
 &lt;li&gt;[[#installation][Installation]] 
  &lt;ul&gt; 
   &lt;li&gt;[[#nixos-with-flakes][NixOS (with Flakes)]]&lt;/li&gt; 
   &lt;li&gt;[[#arch-linux][Arch Linux]]&lt;/li&gt; 
   &lt;li&gt;[[#building-from-source][Building from Source]]&lt;/li&gt; 
   &lt;li&gt;[[#setting-up-oxwm][Setting up OXWM]]&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;[[#configuration][Configuration]] 
  &lt;ul&gt; 
   &lt;li&gt;[[#quick-example][Quick Example]]&lt;/li&gt; 
   &lt;li&gt;[[#features][Features]]&lt;/li&gt; 
   &lt;li&gt;[[#key-configuration-areas][Key Configuration Areas]]&lt;/li&gt; 
   &lt;li&gt;[[#creating-your-config][Creating Your Config]]&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;[[#contributing][Contributing]]&lt;/li&gt; 
 &lt;li&gt;[[#key-bindings][Key Bindings]]&lt;/li&gt; 
 &lt;li&gt;[[#features-1][Features]]&lt;/li&gt; 
 &lt;li&gt;[[#testing-with-xephyr][Testing with Xephyr]]&lt;/li&gt; 
 &lt;li&gt;[[#project-structure][Project Structure]]&lt;/li&gt; 
 &lt;li&gt;[[#architecture-notes][Architecture Notes]] 
  &lt;ul&gt; 
   &lt;li&gt;[[#lua-configuration-system][Lua Configuration System]]&lt;/li&gt; 
   &lt;li&gt;[[#tag-system][Tag System]]&lt;/li&gt; 
   &lt;li&gt;[[#status-bar][Status Bar]]&lt;/li&gt; 
   &lt;li&gt;[[#layout-system][Layout System]]&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;[[#current-todo-list][Current Todo List:]] 
  &lt;ul&gt; 
   &lt;li&gt;[[#priority-high-04][PRIORITY High]]&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;[[#development-roadmap][Development Roadmap]] 
  &lt;ul&gt; 
   &lt;li&gt;[[#current-focus-v080][Current Focus (v0.8.0)]]&lt;/li&gt; 
   &lt;li&gt;[[#completed-features-88][Completed Features]]&lt;/li&gt; 
   &lt;li&gt;[[#future-enhancements-][Future Enhancements]]&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;[[#license][License]]&lt;/li&gt; 
&lt;/ul&gt; 
&lt;ul&gt; 
 &lt;li&gt;OXWM ‚Äî DWM but Better (and oxidized) A dynamic window manager written in Rust, inspired by dwm but designed to evolve beyond it. OXWM features a clean, functional Lua API for configuration with hot-reloading support, ditching the suckless philosophy of &lt;em&gt;"edit + recompile"&lt;/em&gt;. Instead, we focus on lowering friction for users with sane defaults, LSP-powered autocomplete, and instant configuration changes without restarting your X session.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;em&gt;Documentation:&lt;/em&gt; [[https://ox-docs.vercel.app/][ox-docs.vercel.app]]&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Installation ** NixOS (with Flakes) *** Adding OXWM to your flake inputs Add oxwm to your =flake.nix= inputs:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;#+begin_src nix { inputs = { nixpkgs.url = "github:NixOS/nixpkgs/nixos-unstable"; oxwm.url = "github:tonybanters/oxwm"; oxwm.inputs.nixpkgs.follows = "nixpkgs"; };&lt;/p&gt; 
&lt;p&gt;outputs = { self, nixpkgs, oxwm, ... }: { nixosConfigurations.yourhost = nixpkgs.lib.nixosSystem { system = "x86_64-linux"; modules = [ ./configuration.nix oxwm.nixosModules.default ]; }; }; } #+end_src&lt;/p&gt; 
&lt;p&gt;*** Enabling OXWM in configuration.nix Add this to your =configuration.nix=:&lt;/p&gt; 
&lt;p&gt;#+begin_src nix { config, pkgs, ... }:&lt;/p&gt; 
&lt;p&gt;{ services.xserver = { enable = true;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;windowManager.oxwm.enable = true;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;};&lt;/p&gt; 
&lt;h1&gt;Recommended: Install a display manager&lt;/h1&gt; 
&lt;p&gt;services.xserver.displayManager.lightdm.enable = true;&lt;/p&gt; 
&lt;h1&gt;Or use another display manager like sddm, gdm, etc.&lt;/h1&gt; 
&lt;p&gt;} #+end_src&lt;/p&gt; 
&lt;p&gt;*** Initialize your config After rebuilding your system with =sudo nixos-rebuild switch=, log in via your display manager.&lt;/p&gt; 
&lt;p&gt;On first launch, your initial config file will be automatically created and placed in =~/.config/oxwm/config.lua=. Edit it and reload with =Mod+Shift+R=.&lt;/p&gt; 
&lt;p&gt;*** Advanced: Using a specific oxwm version If you want to pin or customize the oxwm package:&lt;/p&gt; 
&lt;p&gt;#+begin_src nix { services.xserver.windowManager.oxwm = { enable = true; # Use a specific version or build with custom options package = oxwm.packages.${pkgs.system}.default; }; } #+end_src&lt;/p&gt; 
&lt;p&gt;*** Development setup with Nix For development, use the provided dev shell:&lt;/p&gt; 
&lt;p&gt;#+begin_src sh&lt;/p&gt; 
&lt;h1&gt;Clone the repository&lt;/h1&gt; 
&lt;p&gt;git clone &lt;a href="https://github.com/tonybanters/oxwm"&gt;https://github.com/tonybanters/oxwm&lt;/a&gt; cd oxwm&lt;/p&gt; 
&lt;h1&gt;Enter the development environment&lt;/h1&gt; 
&lt;p&gt;nix develop&lt;/p&gt; 
&lt;h1&gt;Build and test&lt;/h1&gt; 
&lt;p&gt;cargo build just test #+end_src&lt;/p&gt; 
&lt;p&gt;** Arch Linux&lt;/p&gt; 
&lt;p&gt;AUR: [[https://aur.archlinux.org/packages/oxwm-git][AUR URL]] #+begin_src yay -S oxwm-git #+end_src This will automatically put a desktop session file into your xsessions directory.&lt;/p&gt; 
&lt;p&gt;Manually: Install dependencies: #+begin_src sh sudo pacman -S rust cargo libx11 libxft freetype2 fontconfig pkg-config #+end_src See Build from source&lt;/p&gt; 
&lt;p&gt;** Building from Source #+begin_src sh git clone &lt;a href="https://github.com/tonybanters/oxwm"&gt;https://github.com/tonybanters/oxwm&lt;/a&gt; cd oxwm cargo build --release sudo cp target/release/oxwm /usr/local/bin/ #+end_src&lt;/p&gt; 
&lt;p&gt;Or use the justfile: #+begin_src sh just install #+end_src&lt;/p&gt; 
&lt;p&gt;** Setting up OXWM *** Without a display manager (startx) Add the following to your =~/.xinitrc=: #+begin_src sh exec oxwm #+end_src&lt;/p&gt; 
&lt;p&gt;Then start X with: #+begin_src sh startx #+end_src&lt;/p&gt; 
&lt;p&gt;*** With a display manager If using a display manager (LightDM, GDM, SDDM), OXWM should appear in the session list after installation.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Configuration OXWM uses a clean, functional Lua API for configuration. On first run, a default config is automatically created at =~/.config/oxwm/config.lua=.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;** Quick Example Here's what the new functional API looks like:&lt;/p&gt; 
&lt;p&gt;#+begin_src lua -- Set basic options oxwm.set_terminal("st") oxwm.set_modkey("Mod4") oxwm.set_tags({ "1", "2", "3", "4", "5", "6", "7", "8", "9" })&lt;/p&gt; 
&lt;p&gt;-- Configure borders oxwm.border.set_width(2) oxwm.border.set_focused_color("#6dade3") oxwm.border.set_unfocused_color("#bbbbbb")&lt;/p&gt; 
&lt;p&gt;-- Configure gaps oxwm.gaps.set_enabled(true) oxwm.gaps.set_inner(5, 5) -- horizontal, vertical oxwm.gaps.set_outer(5, 5)&lt;/p&gt; 
&lt;p&gt;-- Set up keybindings oxwm.key.bind({ "Mod4" }, "Return", oxwm.spawn("st")) oxwm.key.bind({ "Mod4" }, "Q", oxwm.client.kill()) oxwm.key.bind({ "Mod4", "Shift" }, "Q", oxwm.quit())&lt;/p&gt; 
&lt;p&gt;-- Add status bar blocks oxwm.bar.set_blocks({ oxwm.bar.block.datetime({ format = "{}", date_format = "%H:%M", interval = 60, color = "#0db9d7", underline = true, }), oxwm.bar.block.ram({ format = "RAM: {used}/{total} GB", interval = 5, color = "#7aa2f7", underline = true, }), }) #+end_src&lt;/p&gt; 
&lt;p&gt;** Features&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;em&gt;Hot-reload&lt;/em&gt;: Changes take effect immediately with =Mod+Shift+R= (no X restart needed)&lt;/li&gt; 
 &lt;li&gt;&lt;em&gt;LSP Support&lt;/em&gt;: Full autocomplete and type hints for the API (=oxwm.lua= definitions included)&lt;/li&gt; 
 &lt;li&gt;&lt;em&gt;Functional API&lt;/em&gt;: Clean, discoverable functions instead of nested tables&lt;/li&gt; 
 &lt;li&gt;&lt;em&gt;No compilation&lt;/em&gt;: Edit and reload instantly&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;** Key Configuration Areas Edit =~/.config/oxwm/config.lua= to customize:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Basic settings (terminal, modkey, tags)&lt;/li&gt; 
 &lt;li&gt;Borders and colors&lt;/li&gt; 
 &lt;li&gt;Window gaps&lt;/li&gt; 
 &lt;li&gt;Status bar (font, blocks, color schemes)&lt;/li&gt; 
 &lt;li&gt;Keybindings and keychords&lt;/li&gt; 
 &lt;li&gt;Layout symbols&lt;/li&gt; 
 &lt;li&gt;Autostart commands&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;After making changes, reload OXWM with =Mod+Shift+R=&lt;/p&gt; 
&lt;p&gt;** Creating Your Config Generate the default config: #+begin_src sh oxwm --init #+end_src&lt;/p&gt; 
&lt;p&gt;Or just start OXWM - it will create one automatically on first run.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Contributing When contributing to OXWM:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;ol&gt; 
 &lt;li&gt;Never commit your personal =~/.config/oxwm/config.lua=&lt;/li&gt; 
 &lt;li&gt;Only modify =templates/config.lua= if adding new configuration options&lt;/li&gt; 
 &lt;li&gt;Test your changes with =just test= using Xephyr/Xwayland&lt;/li&gt; 
 &lt;li&gt;Document any new features or keybindings&lt;/li&gt; 
&lt;/ol&gt; 
&lt;ul&gt; 
 &lt;li&gt;Key Bindings Default keybindings (fully customizable in =~/.config/oxwm/config.lua=):&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;| Binding | Action | |------------------------+-----------------------------------| | Super+Return | Spawn terminal | | Super+J/K | Cycle focus through stack | | Super+Q | Kill focused window | | Super+Shift+Q | Quit WM | | Super+Shift+R | Hot reload WM | | Super+1-9 | View tag 1-9 | | Super+Shift+1-9 | Move window to tag 1-9 | | Super+Ctrl+1-9 | Toggle tag view (multi-tag) | | Super+Ctrl+Shift+1-9 | Toggle window tag (sticky) | | Super+S | Screenshot (maim) | | Super+D | dmenu launcher | | Super+A | Toggle gaps | | Super+Shift+F | Toggle fullscreen | | Super+Shift+Space | Toggle floating | | Super+F | Set normie (floating) layout | | Super+C | Set tiling layout | | Super+N | Cycle layouts | | Super+Comma/Period | Focus prev/next monitor | | Super+Shift+Comma/. | Send window to prev/next monitor | | Super+[/] | Decrease/increase master area | | Super+I/P | Inc/dec number of master windows | | Super+Shift+/ | Show keybinds overlay | | Super+Button1 (drag) | Move window (floating) | | Super+Button3 (drag) | Resize window (floating) |&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Features&lt;/li&gt; 
&lt;/ul&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;em&gt;Dynamic Tiling Layout&lt;/em&gt; with adjustable master/stack split 
  &lt;ul&gt; 
   &lt;li&gt;Master area resizing (mfact)&lt;/li&gt; 
   &lt;li&gt;Multiple master windows support (nmaster)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;em&gt;Tag-Based Workspaces&lt;/em&gt; (9 tags by default) 
  &lt;ul&gt; 
   &lt;li&gt;Multi-tag viewing (see multiple tags at once)&lt;/li&gt; 
   &lt;li&gt;Sticky windows (window visible on multiple tags)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;em&gt;Multiple Layouts&lt;/em&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Tiling (master/stack)&lt;/li&gt; 
   &lt;li&gt;Normie (floating-by-default)&lt;/li&gt; 
   &lt;li&gt;Monocle (fullscreen stacking)&lt;/li&gt; 
   &lt;li&gt;Grid (equal-sized grid)&lt;/li&gt; 
   &lt;li&gt;Tabbed (tabbed windows)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;em&gt;Lua Configuration System&lt;/em&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Hot reload without restarting X (=Mod+Shift+R=)&lt;/li&gt; 
   &lt;li&gt;LSP support with type definitions and autocomplete&lt;/li&gt; 
   &lt;li&gt;No compilation needed - instant config changes&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;em&gt;Built-in Status Bar&lt;/em&gt; with modular block system 
  &lt;ul&gt; 
   &lt;li&gt;Battery, RAM, datetime, shell commands, static text&lt;/li&gt; 
   &lt;li&gt;Custom colors, update intervals, and underlines&lt;/li&gt; 
   &lt;li&gt;Click-to-switch tags&lt;/li&gt; 
   &lt;li&gt;Multi-monitor support (one bar per monitor)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;em&gt;Advanced Window Management&lt;/em&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Window focus cycling through stack&lt;/li&gt; 
   &lt;li&gt;Fullscreen mode&lt;/li&gt; 
   &lt;li&gt;Floating window support&lt;/li&gt; 
   &lt;li&gt;Mouse hover to focus (follow mouse)&lt;/li&gt; 
   &lt;li&gt;Border indicators for focused windows&lt;/li&gt; 
   &lt;li&gt;Configurable gaps (smartgaps support)&lt;/li&gt; 
   &lt;li&gt;Window rules (auto-tag, auto-float by class/title)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;em&gt;Multi-Monitor Support&lt;/em&gt; 
  &lt;ul&gt; 
   &lt;li&gt;RandR multi-monitor detection&lt;/li&gt; 
   &lt;li&gt;Independent tags per monitor&lt;/li&gt; 
   &lt;li&gt;Move windows between monitors&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;em&gt;Keychord Support&lt;/em&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Multi-key sequences (Emacs/Vim style)&lt;/li&gt; 
   &lt;li&gt;Example: =Mod+Space= then =T= to spawn terminal&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;em&gt;Persistent State&lt;/em&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Window tags persist across WM restarts&lt;/li&gt; 
   &lt;li&gt;Uses X11 properties for state storage&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;ul&gt; 
 &lt;li&gt;Testing with Xephyr Test OXWM in a nested X server without affecting your current session:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;#+begin_src sh just test #+end_src&lt;/p&gt; 
&lt;p&gt;This starts Xephyr on display :1 and launches OXWM inside it.&lt;/p&gt; 
&lt;p&gt;Or manually: #+begin_src sh Xephyr -screen 1280x800 :1 &amp;amp; DISPLAY=:1 cargo run #+end_src&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Project Structure #+begin_src sh src/ ‚îú‚îÄ‚îÄ bin/ ‚îÇ ‚îî‚îÄ‚îÄ main.rs [Entry point - handles CLI args, config loading, WM init] ‚îÇ ‚îú‚îÄ‚îÄ main() [Parse args, load config, start WM] ‚îÇ ‚îú‚îÄ‚îÄ load_config() [Lua config loading with auto-init] ‚îÇ ‚îî‚îÄ‚îÄ init_config() [Create default config.lua + oxwm.lua] ‚îÇ ‚îú‚îÄ‚îÄ lib.rs [Library exports] ‚îÇ ‚îú‚îÄ‚îÄ window_manager.rs [CORE - X11 event handling] ‚îÇ ‚îú‚îÄ‚îÄ struct WindowManager ‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ connection: RustConnection [X11 connection] ‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ windows: Vec
  &lt;window&gt;
    [All managed windows] ‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ focused_window: Option
   &lt;window&gt;
     ‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ layout: Box
    &lt;dyn layout&gt;
      ‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ window_tags: HashMap&amp;lt;Window, TagMask&amp;gt; ‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ selected_tags: TagMask ‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ bars: Vec
     &lt;bar&gt;
       [Status bars (multi-monitor)] ‚îÇ ‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ new() [Initialize WM, grab root, restore tags, scan windows] ‚îÇ ‚îú‚îÄ‚îÄ run() [Main event loop with block updates] ‚îÇ ‚îú‚îÄ‚îÄ handle_event() [Route X11 events] ‚îÇ ‚îú‚îÄ‚îÄ try_reload_config() [Hot-reload Lua config] ‚îÇ ‚îî‚îÄ‚îÄ ... [Window/tag/focus management] ‚îÇ ‚îú‚îÄ‚îÄ config/ ‚îÇ ‚îú‚îÄ‚îÄ mod.rs [Config module exports] ‚îÇ ‚îú‚îÄ‚îÄ lua.rs [Lua config parser - loads and executes config.lua] ‚îÇ ‚îî‚îÄ‚îÄ lua_api.rs [Functional Lua API implementation] ‚îÇ ‚îú‚îÄ‚îÄ register_api() [Set up oxwm.* functions in Lua] ‚îÇ ‚îú‚îÄ‚îÄ register_spawn() [oxwm.spawn()] ‚îÇ ‚îú‚îÄ‚îÄ register_key_module() [oxwm.key.bind(), oxwm.key.chord()] ‚îÇ ‚îú‚îÄ‚îÄ register_gaps_module() [oxwm.gaps.
      &lt;em&gt;] ‚îÇ ‚îú‚îÄ‚îÄ register_border_module() [oxwm.border.&lt;/em&gt;] ‚îÇ ‚îú‚îÄ‚îÄ register_client_module() [oxwm.client.
      &lt;em&gt;] ‚îÇ ‚îú‚îÄ‚îÄ register_layout_module() [oxwm.layout.&lt;/em&gt;] ‚îÇ ‚îú‚îÄ‚îÄ register_tag_module() [oxwm.tag.
      &lt;em&gt;] ‚îÇ ‚îú‚îÄ‚îÄ register_bar_module() [oxwm.bar.&lt;/em&gt;] ‚îÇ ‚îî‚îÄ‚îÄ register_misc() [oxwm.set_terminal(), etc.] ‚îÇ ‚îú‚îÄ‚îÄ bar/ ‚îÇ ‚îú‚îÄ‚îÄ mod.rs [Re-exports: Bar, BlockCommand, BlockConfig] ‚îÇ ‚îú‚îÄ‚îÄ bar.rs ‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ struct Bar [Status bar window with XFT support] ‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ new() [Create bar X11 window, load font, init blocks] ‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ draw() [Render tags + blocks with underlines] ‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ update_blocks() [Update block content based on intervals] ‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ handle_click() [Detect which tag was clicked] ‚îÇ ‚îú‚îÄ‚îÄ font.rs ‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ struct Font [XFT font wrapper] ‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ draw_text() [Render text with color] ‚îÇ ‚îî‚îÄ‚îÄ blocks/ ‚îÇ ‚îú‚îÄ‚îÄ mod.rs [Block trait, BlockConfig, BlockCommand enum] ‚îÇ ‚îú‚îÄ‚îÄ battery.rs [Battery status block] ‚îÇ ‚îú‚îÄ‚îÄ datetime.rs [Date/time formatting block] ‚îÇ ‚îú‚îÄ‚îÄ ram.rs [RAM usage block] ‚îÇ ‚îú‚îÄ‚îÄ shell.rs [Shell command execution block] ‚îÇ ‚îî‚îÄ‚îÄ static.rs [Static text block] ‚îÇ ‚îú‚îÄ‚îÄ keyboard/ ‚îÇ ‚îú‚îÄ‚îÄ mod.rs [Re-exports] ‚îÇ ‚îú‚îÄ‚îÄ keysyms.rs [X11 keysym constants] ‚îÇ ‚îî‚îÄ‚îÄ handlers.rs ‚îÇ ‚îú‚îÄ‚îÄ enum KeyAction [All keyboard actions] ‚îÇ ‚îú‚îÄ‚îÄ enum Arg [Action arguments] ‚îÇ ‚îú‚îÄ‚îÄ struct KeyBinding [Keybinding + keychord support] ‚îÇ ‚îî‚îÄ‚îÄ struct KeyPress [Individual key press in chord] ‚îÇ ‚îú‚îÄ‚îÄ layout/ ‚îÇ ‚îú‚îÄ‚îÄ mod.rs [Layout trait definition] ‚îÇ ‚îú‚îÄ‚îÄ tiling.rs [Tiling layout with master/stack] ‚îÇ ‚îú‚îÄ‚îÄ monocle.rs [Fullscreen stacking layout] ‚îÇ ‚îú‚îÄ‚îÄ grid.rs [Equal-sized grid layout] ‚îÇ ‚îú‚îÄ‚îÄ tabbed.rs [Tabbed container layout] ‚îÇ ‚îî‚îÄ‚îÄ normie.rs [Floating-by-default layout] ‚îÇ ‚îî‚îÄ‚îÄ errors.rs [Error types: WmError, ConfigError, etc.]
     &lt;/bar&gt;
    &lt;/dyn&gt;
   &lt;/window&gt;
  &lt;/window&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;templates/ ‚îú‚îÄ‚îÄ config.lua [Default config with functional API] ‚îî‚îÄ‚îÄ oxwm.lua [LSP type definitions for autocomplete] #+end_src&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Architecture Notes ** Lua Configuration System OXWM uses mlua to embed a Lua interpreter. The functional API is implemented in =src/config/lua_api.rs=:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;ul&gt; 
 &lt;li&gt;Each API function (e.g., =oxwm.border.set_width()=) is registered as a Lua function&lt;/li&gt; 
 &lt;li&gt;Functions modify a shared ConfigBuilder that accumulates settings&lt;/li&gt; 
 &lt;li&gt;When config execution completes, the builder produces the final Config struct&lt;/li&gt; 
 &lt;li&gt;Type definitions in =templates/oxwm.lua= provide LSP autocomplete and documentation&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;** Tag System Tags are implemented as bitmasks (TagMask = u32), allowing windows to belong to multiple tags simultaneously. Each window has an associated TagMask stored in a HashMap. Tags persist across WM restarts using X11 properties (_NET_CURRENT_DESKTOP for selected tags, _NET_CLIENT_INFO for per-window tags).&lt;/p&gt; 
&lt;p&gt;** Status Bar The bar uses a performance-optimized approach with a modular block system:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Only redraws when invalidated&lt;/li&gt; 
 &lt;li&gt;Pre-calculates tag widths on creation&lt;/li&gt; 
 &lt;li&gt;Blocks update independently based on their configured intervals&lt;/li&gt; 
 &lt;li&gt;Supports custom colors and underline indicators&lt;/li&gt; 
 &lt;li&gt;Color schemes (normal/occupied/selected) control tag appearance&lt;/li&gt; 
 &lt;li&gt;Easily extensible - add new block types in src/bar/blocks/&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;** Layout System The tiling layout divides the screen into a master area (left half) and stack area (right half). The master window occupies the full height of the master area, while stack windows split the stack area vertically. Gaps are configurable and can be toggled at runtime.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;TODO Current Todo List: ** PRIORITY High [0/4]&lt;/li&gt; 
&lt;/ul&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Add Window Titles to Bar 
  &lt;ul&gt; 
   &lt;li&gt;Show focused window title in status bar&lt;/li&gt; 
   &lt;li&gt;Truncate if too long&lt;/li&gt; 
   &lt;li&gt;Update on window focus change&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Add Horizontal Scroll Layout 
  &lt;ul&gt; 
   &lt;li&gt;Master window on left, stack scrolls horizontally&lt;/li&gt; 
   &lt;li&gt;Alternative to vertical tiling&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Add Hide Empty Tag Numbers Option 
  &lt;ul&gt; 
   &lt;li&gt;Option to hide tags with no windows&lt;/li&gt; 
   &lt;li&gt;Configurable via =oxwm.bar.set_hide_empty_tags(bool)=&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Add Swap Stack Bind 
  &lt;ul&gt; 
   &lt;li&gt;Keybind to swap focused window with master&lt;/li&gt; 
   &lt;li&gt;Similar to dwm's zoom function (=Mod+Return=)&lt;/li&gt; 
   &lt;li&gt;Should work bidirectionally&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;ul&gt; 
 &lt;li&gt;Development Roadmap ** Current Focus (v0.8.0)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;ul&gt; 
 &lt;li&gt;Refactoring to align with dwm's proven patterns&lt;/li&gt; 
 &lt;li&gt;Improving core window management reliability&lt;/li&gt; 
 &lt;li&gt;Maintaining Lua config and bar features while simplifying internals&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;** Completed Features [8/8]&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Multi-monitor support with RandR&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Multiple layouts (tiling, monocle, grid, tabbed, normie)&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Master area resizing (mfact) and nmaster support&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Window rules (per-program auto-tag, floating)&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Lua configuration with hot-reload&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Built-in status bar with modular blocks&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Keychord support (multi-key sequences)&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Tag persistence across restarts&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;** Future Enhancements [/]&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Scratchpad functionality&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Dynamic monitor hotplugging (currently only on startup)&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; External bar support (polybar, waybar compatibility)&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Additional layouts (deck, spiral, dwindle)&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Window minimize/restore&lt;/li&gt; 
&lt;/ul&gt; 
&lt;ul&gt; 
 &lt;li&gt;License [[https://www.gnu.org/licenses/gpl-3.0.en.html][GPL v3]]&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>YaLTeR/niri</title>
      <link>https://github.com/YaLTeR/niri</link>
      <description>&lt;p&gt;A scrollable-tiling Wayland compositor.&lt;/p&gt;&lt;hr&gt;&lt;h1 align="center"&gt;&lt;img alt="niri" src="https://github.com/user-attachments/assets/07d05cd0-d5dc-4a28-9a35-51bae8f119a0" /&gt;&lt;/h1&gt; 
&lt;p align="center"&gt;A scrollable-tiling Wayland compositor.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://matrix.to/#/#niri:matrix.org"&gt;&lt;img alt="Matrix" src="https://img.shields.io/badge/matrix-%23niri-blue?logo=matrix" /&gt;&lt;/a&gt; &lt;a href="https://github.com/YaLTeR/niri/raw/main/LICENSE"&gt;&lt;img alt="GitHub License" src="https://img.shields.io/github/license/YaLTeR/niri" /&gt;&lt;/a&gt; &lt;a href="https://github.com/YaLTeR/niri/releases"&gt;&lt;img alt="GitHub Release" src="https://img.shields.io/github/v/release/YaLTeR/niri?logo=github" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://yalter.github.io/niri/Getting-Started.html"&gt;Getting Started&lt;/a&gt; | &lt;a href="https://yalter.github.io/niri/Configuration%3A-Introduction.html"&gt;Configuration&lt;/a&gt; | &lt;a href="https://github.com/YaLTeR/niri/discussions/325"&gt;Setup&amp;nbsp;Showcase&lt;/a&gt; &lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/535e6530-2f44-4b84-a883-1240a3eee6e9" alt="niri with a few windows open" /&gt;&lt;/p&gt; 
&lt;h2&gt;About&lt;/h2&gt; 
&lt;p&gt;Windows are arranged in columns on an infinite strip going to the right. Opening a new window never causes existing windows to resize.&lt;/p&gt; 
&lt;p&gt;Every monitor has its own separate window strip. Windows can never "overflow" onto an adjacent monitor.&lt;/p&gt; 
&lt;p&gt;Workspaces are dynamic and arranged vertically. Every monitor has an independent set of workspaces, and there's always one empty workspace present all the way down.&lt;/p&gt; 
&lt;p&gt;The workspace arrangement is preserved across disconnecting and connecting monitors where it makes sense. When a monitor disconnects, its workspaces will move to another monitor, but upon reconnection they will move back to the original monitor.&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Built from the ground up for scrollable tiling&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://yalter.github.io/niri/Workspaces.html"&gt;Dynamic workspaces&lt;/a&gt; like in GNOME&lt;/li&gt; 
 &lt;li&gt;An &lt;a href="https://github.com/user-attachments/assets/379a5d1f-acdb-4c11-b36c-e85fd91f0995"&gt;Overview&lt;/a&gt; that zooms out workspaces and windows&lt;/li&gt; 
 &lt;li&gt;Built-in screenshot UI&lt;/li&gt; 
 &lt;li&gt;Monitor and window screencasting through xdg-desktop-portal-gnome 
  &lt;ul&gt; 
   &lt;li&gt;You can &lt;a href="https://yalter.github.io/niri/Configuration%3A-Window-Rules.html#block-out-from"&gt;block out&lt;/a&gt; sensitive windows from screencasts&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://yalter.github.io/niri/Screencasting.html#dynamic-screencast-target"&gt;Dynamic cast target&lt;/a&gt; that can change what it shows on the go&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/YaLTeR/niri/assets/1794388/946a910e-9bec-4cd1-a923-4a9421707515"&gt;Touchpad&lt;/a&gt; and &lt;a href="https://github.com/YaLTeR/niri/assets/1794388/8464e65d-4bf2-44fa-8c8e-5883355bd000"&gt;mouse&lt;/a&gt; gestures&lt;/li&gt; 
 &lt;li&gt;Group windows into &lt;a href="https://yalter.github.io/niri/Tabs.html"&gt;tabs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Configurable layout: gaps, borders, struts, window sizes&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://yalter.github.io/niri/Configuration%3A-Layout.html#gradients"&gt;Gradient borders&lt;/a&gt; with Oklab and Oklch support&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/YaLTeR/niri/assets/1794388/ce178da2-af9e-4c51-876f-8709c241d95e"&gt;Animations&lt;/a&gt; with support for &lt;a href="https://github.com/YaLTeR/niri/assets/1794388/27a238d6-0a22-4692-b794-30dc7a626fad"&gt;custom shaders&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Live-reloading config&lt;/li&gt; 
 &lt;li&gt;Works with &lt;a href="https://yalter.github.io/niri/Accessibility.html"&gt;screen readers&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Video Demo&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://github.com/YaLTeR/niri/assets/1794388/bce834b0-f205-434e-a027-b373495f9729"&gt;https://github.com/YaLTeR/niri/assets/1794388/bce834b0-f205-434e-a027-b373495f9729&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Also check out this video from Brodie Robertson that showcases a lot of the niri functionality: &lt;a href="https://youtu.be/DeYx2exm04M"&gt;Niri Is My New Favorite Wayland Compositor&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Status&lt;/h2&gt; 
&lt;p&gt;Niri is stable for day-to-day use and does most things expected of a Wayland compositor. Many people are daily-driving niri, and are happy to help in our &lt;a href="https://matrix.to/#/#niri:matrix.org"&gt;Matrix channel&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Give it a try! Follow the instructions on the &lt;a href="https://yalter.github.io/niri/Getting-Started.html"&gt;Getting Started&lt;/a&gt; page. Have your &lt;a href="https://github.com/Alexays/Waybar"&gt;waybar&lt;/a&gt;s and &lt;a href="https://codeberg.org/dnkl/fuzzel"&gt;fuzzel&lt;/a&gt;s ready: niri is not a complete desktop environment. Also check out &lt;a href="https://github.com/Vortriz/awesome-niri"&gt;awesome-niri&lt;/a&gt;, a list of niri-related links and projects.&lt;/p&gt; 
&lt;p&gt;Here are some points you may have questions about:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Multi-monitor&lt;/strong&gt;: yes, a core part of the design from the very start. Mixed DPI works.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Fractional scaling&lt;/strong&gt;: yes, plus all niri UI stays pixel-perfect.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;NVIDIA&lt;/strong&gt;: seems to work fine.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Floating windows&lt;/strong&gt;: yes, starting from niri 25.01.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Input devices&lt;/strong&gt;: niri supports tablets, touchpads, and touchscreens. You can map the tablet to a specific monitor, or use &lt;a href="https://opentabletdriver.net/"&gt;OpenTabletDriver&lt;/a&gt;. We have touchpad gestures, but no touchscreen gestures yet.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Wlr protocols&lt;/strong&gt;: yes, we have most of the important ones like layer-shell, gamma-control, screencopy. You can check on &lt;a href="https://wayland.app"&gt;wayland.app&lt;/a&gt; at the bottom of each protocol's page.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Performance&lt;/strong&gt;: while I run niri on beefy machines, I try to stay conscious of performance. I've seen someone use it fine on an Eee&amp;nbsp;PC&amp;nbsp;900 from&amp;nbsp;2008, of all things.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Xwayland&lt;/strong&gt;: &lt;a href="https://yalter.github.io/niri/Xwayland.html#using-xwayland-satellite"&gt;integrated&lt;/a&gt; via xwayland-satellite starting from niri 25.08.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Media&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://youtu.be/Kmz8ODolnDg?list=PLRdS-n5seLRqrmWDQY4KDqtRMfIwU0U3T"&gt;niri: Making a Wayland compositor in Rust&lt;/a&gt; ¬∑ &lt;em&gt;December 2024&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;My talk from the 2024 Moscow RustCon about niri, and how I do randomized property testing and profiling, and measure input latency. The talk is in Russian, but I prepared full English subtitles that you can find in YouTube's subtitle language selector.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.trommelspeicher.de/podcast/special_the_developer_behind_niri"&gt;An interview with Ivan, the developer behind Niri&lt;/a&gt; ¬∑ &lt;em&gt;June 2025&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;An interview by a German tech podcast Das Triumvirat (in English). We talk about niri development and history, and my experience building and maintaining niri.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://lwn.net/Articles/1025866/"&gt;A tour of the niri scrolling-tiling Wayland compositor&lt;/a&gt; ¬∑ &lt;em&gt;July 2025&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;An LWN article with a nice overview and introduction to niri.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;If you'd like to help with niri, there are plenty of both coding- and non-coding-related ways to do so. See &lt;a href="https://github.com/YaLTeR/niri/raw/main/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; for an overview.&lt;/p&gt; 
&lt;h2&gt;Inspiration&lt;/h2&gt; 
&lt;p&gt;Niri is heavily inspired by &lt;a href="https://github.com/paperwm/PaperWM"&gt;PaperWM&lt;/a&gt; which implements scrollable tiling on top of GNOME Shell.&lt;/p&gt; 
&lt;p&gt;One of the reasons that prompted me to try writing my own compositor is being able to properly separate the monitors. Being a GNOME Shell extension, PaperWM has to work against Shell's global window coordinate space to prevent windows from overflowing.&lt;/p&gt; 
&lt;h2&gt;Tile Scrollably Elsewhere&lt;/h2&gt; 
&lt;p&gt;Here are some other projects which implement a similar workflow:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/paperwm/PaperWM"&gt;PaperWM&lt;/a&gt;: scrollable tiling on top of GNOME Shell.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/peterfajdiga/karousel"&gt;karousel&lt;/a&gt;: scrollable tiling on top of KDE.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/dawsers/scroll"&gt;scroll&lt;/a&gt; and &lt;a href="https://spwhitton.name/tech/code/papersway/"&gt;papersway&lt;/a&gt;: scrollable tiling on top of sway/i3.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/hyprwm/hyprland-plugins/tree/main/hyprscrolling"&gt;hyprscrolling&lt;/a&gt; and &lt;a href="https://gitlab.com/magus/hyprslidr"&gt;hyprslidr&lt;/a&gt;: scrollable tiling on top of Hyprland.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mogenson/PaperWM.spoon"&gt;PaperWM.spoon&lt;/a&gt;: scrollable tiling on top of macOS.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contact&lt;/h2&gt; 
&lt;p&gt;Our main communication channel is a Matrix chat, feel free to join and ask a question: &lt;a href="https://matrix.to/#/#niri:matrix.org"&gt;https://matrix.to/#/#niri:matrix.org&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;We also have a community Discord server: &lt;a href="https://discord.gg/vT8Sfjy7sx"&gt;https://discord.gg/vT8Sfjy7sx&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>git-ai-project/git-ai</title>
      <link>https://github.com/git-ai-project/git-ai</link>
      <description>&lt;p&gt;A Git extension for tracking the AI-generated code in your repos&lt;/p&gt;&lt;hr&gt;&lt;div&gt; 
 &lt;img src="https://github.com/acunniffe/git-ai/raw/main/assets/docs/git-ai.png" align="right" alt="Git AI by acunniffe/git-ai" width="100" height="100" /&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;h1 align="left"&gt;&lt;b&gt;git-ai&lt;/b&gt;&lt;/h1&gt; 
&lt;/div&gt; 
&lt;p align="left"&gt;Track the AI Code in your repositories&lt;/p&gt; 
&lt;p&gt;
 &lt;video src="https://github.com/user-attachments/assets/68304ca6-b262-4638-9fb6-0a26f55c7986" muted loop controls autoplay&gt;&lt;/video&gt;&lt;/p&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;h4&gt;Mac, Linux, Windows (WSL)&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -sSL https://usegitai.com/install.sh | bash
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Windows (non-WSL)&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-powershell"&gt;powershell -NoProfile -ExecutionPolicy Bypass -Command "irm http://usegitai.com/install.ps1 | iex"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;üéä That's it! &lt;strong&gt;No per-repo setup.&lt;/strong&gt; Once installed Git AI will work OOTB with any of these &lt;strong&gt;Supported Agents&lt;/strong&gt;:&lt;/p&gt; 
&lt;img src="https://github.com/acunniffe/git-ai/raw/main/assets/docs/supported-agents.png" width="320" /&gt; 
&lt;h3&gt;Documentation &lt;a href="https://usegitai.com/docs"&gt;https://usegitai.com/docs&lt;/a&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://usegitai.com/docs/cli/ai-blame"&gt;AI Blame&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://usegitai.com/docs/cli/prompt-storage"&gt;Cross-Agent Prompt Saving&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://usegitai.com/docs/cli/reference"&gt;CLI Reference&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://usegitai.com/docs/cli/configuration"&gt;Configuring Git AI for the enterprise&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Just Install and Commit&lt;/h3&gt; 
&lt;p&gt;Build as usual. Just prompt, edit and commit. Git AI will track every line of AI-Code and record the Coding Agent, Model, and prompt that generated it.&lt;/p&gt; 
&lt;img src="https://github.com/acunniffe/git-ai/raw/main/assets/docs/graph.jpg" width="400" /&gt; 
&lt;h4&gt;How Does it work?&lt;/h4&gt; 
&lt;p&gt;Supported Coding Agents call Git AI and mark the lines they insert as AI-generated.&lt;/p&gt; 
&lt;p&gt;On commit, Git AI saves the final AI-attributions into a Git Note. These notes power AI-Blame, AI contribution stats, and more. The CLI makes sure these notes are preserved through rebases, merges, squashes, cherry-picks, etc.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/edd20990-ec0b-4a53-afa4-89fa33de9541" alt="Git Tree" /&gt;&lt;/p&gt; 
&lt;p&gt;The format of the notes is outlined here in the &lt;a href="https://github.com/git-ai-project/git-ai/raw/main/specs/git_ai_standard_v3.0.0.md"&gt;Git AI Standard v3.0.0&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Goals of &lt;code&gt;git-ai&lt;/code&gt; project&lt;/h2&gt; 
&lt;p&gt;ü§ñ &lt;strong&gt;Track AI code in a Multi-Agent&lt;/strong&gt; world. Because developers get to choose their tools, engineering teams need a &lt;strong&gt;vendor agnostic&lt;/strong&gt; way to track AI impact in their repos.&lt;/p&gt; 
&lt;p&gt;üéØ &lt;strong&gt;Accurate attribution&lt;/strong&gt; from Laptop ‚Üí Pull Request ‚Üí Merged. Claude Code, Cursor and Copilot cannot track code after generation‚ÄîGit AI follows it through the entire workflow.&lt;/p&gt; 
&lt;p&gt;üîÑ &lt;strong&gt;Support real-world git workflows&lt;/strong&gt; by making sure AI-Authorship annotations survive a &lt;code&gt;merge --squash&lt;/code&gt;, &lt;code&gt;rebase&lt;/code&gt;, &lt;code&gt;reset&lt;/code&gt;, &lt;code&gt;cherry-pick&lt;/code&gt; etc.&lt;/p&gt; 
&lt;p&gt;üîó &lt;strong&gt;Maintain link between prompts and code&lt;/strong&gt; - there is valuable context and requirements in team prompts‚Äîpreserve them alongside code.&lt;/p&gt; 
&lt;p&gt;üöÄ &lt;strong&gt;Git-native + Fast&lt;/strong&gt; - &lt;code&gt;git-ai&lt;/code&gt; is built on git plumbing commands. Negligible impact even in large repos (&amp;lt;100ms). Tested in &lt;a href="https://github.com/chromium/chromium"&gt;Chromium&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Agent Support&lt;/h2&gt; 
&lt;p&gt;&lt;code&gt;git-ai&lt;/code&gt; automatically sets up all supported agent hooks using the &lt;code&gt;git-ai install-hooks&lt;/code&gt; command&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Agent/IDE&lt;/th&gt; 
   &lt;th&gt;Authorship&lt;/th&gt; 
   &lt;th&gt;Prompts&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Cursor &amp;gt;1.7&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Claude Code&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GitHub Copilot in VSCode via Extension&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Google Gemini CLI&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Continue CLI&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;OpenCode&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Atlassian RovoDev CLI&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;AWS Kiro (in-progress)&lt;/td&gt; 
   &lt;td&gt;üîÑ&lt;/td&gt; 
   &lt;td&gt;üîÑ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Continue VS Code/IntelliJ (in-progress)&lt;/td&gt; 
   &lt;td&gt;üîÑ&lt;/td&gt; 
   &lt;td&gt;üîÑ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Windsurf&lt;/td&gt; 
   &lt;td&gt;üîÑ&lt;/td&gt; 
   &lt;td&gt;üîÑ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Augment Code&lt;/td&gt; 
   &lt;td&gt;üîÑ&lt;/td&gt; 
   &lt;td&gt;üîÑ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;OpenAI Codex (waiting on &lt;a href="https://github.com/openai/codex/issues/2109"&gt;openai/codex #2109&lt;/a&gt;)&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Junie &amp;amp; Jetbrains IDEs&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Ona&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Sourcegraph Cody + Amp&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Google Antigravity&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Building a Coding Agent?&lt;/strong&gt; &lt;a href="https://usegitai.com/docs/cli/add-your-agent"&gt;Add support for Git AI by following this guide&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Installing the Stats Bot (early access)&lt;/h2&gt; 
&lt;p&gt;Aggregate &lt;code&gt;git-ai&lt;/code&gt; data at the PR, developer, Repository and Organization levels:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;AI authorship breakdown for every Pull Request&lt;/li&gt; 
 &lt;li&gt;Measure % of code that is AI generated through the entire SDLC&lt;/li&gt; 
 &lt;li&gt;Compare accepted-rate for code written by each Agent + Model.&lt;/li&gt; 
 &lt;li&gt;AI-Code Halflife (how durable is the AI code)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;a href="https://calendly.com/acunniffe/meeting-with-git-ai-authors"&gt;Get early access by chatting with the maintainers&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;img src="https://github.com/acunniffe/git-ai/raw/main/assets/docs/dashboard.png" alt="alt" /&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>tauri-apps/plugins-workspace</title>
      <link>https://github.com/tauri-apps/plugins-workspace</link>
      <description>&lt;p&gt;All of the official Tauri plugins in one place!&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Official Tauri Plugins&lt;/h1&gt; 
&lt;p&gt;This repo and all plugins require a Rust version of at least &lt;strong&gt;1.77.2&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;Plugins Found Here&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;/th&gt; 
   &lt;th&gt;Win&lt;/th&gt; 
   &lt;th&gt;Mac&lt;/th&gt; 
   &lt;th&gt;Lin&lt;/th&gt; 
   &lt;th&gt;iOS&lt;/th&gt; 
   &lt;th&gt;And&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/tauri-apps/plugins-workspace/v2/plugins/autostart"&gt;autostart&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Automatically launch your app at system startup.&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/tauri-apps/plugins-workspace/v2/plugins/barcode-scanner"&gt;barcode-scanner&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Allows your mobile application to use the camera to scan QR codes, EAN-13 and other kinds of barcodes.&lt;/td&gt; 
   &lt;td&gt;?&lt;/td&gt; 
   &lt;td&gt;?&lt;/td&gt; 
   &lt;td&gt;?&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/tauri-apps/plugins-workspace/v2/plugins/biometric"&gt;biometric&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Prompt the user for biometric authentication on Android and iOS.&lt;/td&gt; 
   &lt;td&gt;?&lt;/td&gt; 
   &lt;td&gt;?&lt;/td&gt; 
   &lt;td&gt;?&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/tauri-apps/plugins-workspace/v2/plugins/cli"&gt;cli&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Parse arguments from your Command Line Interface&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/tauri-apps/plugins-workspace/v2/plugins/clipboard-manager"&gt;clipboard-manager&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Read and write to the system clipboard.&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/tauri-apps/plugins-workspace/v2/plugins/deep-link"&gt;deep-link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Set your Tauri application as the default handler for an URL.&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/tauri-apps/plugins-workspace/v2/plugins/dialog"&gt;dialog&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Native system dialogs for opening and saving files along with message dialogs.&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/tauri-apps/plugins-workspace/v2/plugins/fs"&gt;fs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Access the file system.&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;?&lt;/td&gt; 
   &lt;td&gt;?&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/tauri-apps/plugins-workspace/v2/plugins/geolocation"&gt;geolocation&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Get and track current device position.&lt;/td&gt; 
   &lt;td&gt;?&lt;/td&gt; 
   &lt;td&gt;?&lt;/td&gt; 
   &lt;td&gt;?&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/tauri-apps/plugins-workspace/v2/plugins/global-shortcut"&gt;global-shortcut&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Register global shortcuts.&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;?&lt;/td&gt; 
   &lt;td&gt;?&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/tauri-apps/plugins-workspace/v2/plugins/haptics"&gt;haptics&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Haptic feedback and vibrations.&lt;/td&gt; 
   &lt;td&gt;?&lt;/td&gt; 
   &lt;td&gt;?&lt;/td&gt; 
   &lt;td&gt;?&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/tauri-apps/plugins-workspace/v2/plugins/http"&gt;http&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Access the HTTP client written in Rust.&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/tauri-apps/plugins-workspace/v2/plugins/localhost"&gt;localhost&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Use a localhost server in production apps.&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;?&lt;/td&gt; 
   &lt;td&gt;?&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/tauri-apps/plugins-workspace/v2/plugins/log"&gt;log&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Configurable logging.&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/tauri-apps/plugins-workspace/v2/plugins/nfc"&gt;nfc&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Read and write NFC tags on Android and iOS.&lt;/td&gt; 
   &lt;td&gt;?&lt;/td&gt; 
   &lt;td&gt;?&lt;/td&gt; 
   &lt;td&gt;?&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/tauri-apps/plugins-workspace/v2/plugins/notification"&gt;notification&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Send message notifications (brief auto-expiring OS window element) to your user. Can also be used with the Notification Web API.&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/tauri-apps/plugins-workspace/v2/plugins/opener"&gt;opener&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Open files and URLs using their default application.&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;?&lt;/td&gt; 
   &lt;td&gt;?&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/tauri-apps/plugins-workspace/v2/plugins/os"&gt;os&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Read information about the operating system.&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/tauri-apps/plugins-workspace/v2/plugins/persisted-scope"&gt;persisted-scope&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Persist runtime scope changes on the filesystem.&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;?&lt;/td&gt; 
   &lt;td&gt;?&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/tauri-apps/plugins-workspace/v2/plugins/positioner"&gt;positioner&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Move windows to common locations.&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/tauri-apps/plugins-workspace/v2/plugins/process"&gt;process&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;This plugin provides APIs to access the current process. To spawn child processes, see the &lt;a href="https://github.com/tauri-apps/tauri-plugin-shell"&gt;&lt;code&gt;shell&lt;/code&gt;&lt;/a&gt; plugin.&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;?&lt;/td&gt; 
   &lt;td&gt;?&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/tauri-apps/plugins-workspace/v2/plugins/shell"&gt;shell&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Access the system shell. Allows you to spawn child processes and manage files and URLs using their default application.&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;?&lt;/td&gt; 
   &lt;td&gt;?&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/tauri-apps/plugins-workspace/v2/plugins/single-instance"&gt;single-instance&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Ensure a single instance of your tauri app is running.&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/tauri-apps/plugins-workspace/v2/plugins/sql"&gt;sql&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Interface with SQL databases.&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/tauri-apps/plugins-workspace/v2/plugins/store"&gt;store&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Persistent key value storage.&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/tauri-apps/plugins-workspace/v2/plugins/stronghold"&gt;stronghold&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Encrypted, secure database.&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;?&lt;/td&gt; 
   &lt;td&gt;?&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/tauri-apps/plugins-workspace/v2/plugins/updater"&gt;updater&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;In-app updates for Tauri applications.&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/tauri-apps/plugins-workspace/v2/plugins/upload"&gt;upload&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Tauri plugin for file uploads through HTTP.&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/tauri-apps/plugins-workspace/v2/plugins/websocket"&gt;websocket&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Open a WebSocket connection using a Rust client in JS.&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;?&lt;/td&gt; 
   &lt;td&gt;?&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/tauri-apps/plugins-workspace/v2/plugins/window-state"&gt;window-state&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Persist window sizes and positions.&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;ul&gt; 
 &lt;li&gt;‚úÖ: (Partially) Supported&lt;/li&gt; 
 &lt;li&gt;‚ùå: Not supported&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;?&lt;/code&gt; : Unknown/Untested or Planned&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;PRs accepted. Please make sure to read the &lt;a href="https://github.com/tauri-apps/tauri/raw/dev/.github/CONTRIBUTING.md"&gt;Contributing Guide&lt;/a&gt; before making a pull request.&lt;/p&gt; 
&lt;h2&gt;Partners&lt;/h2&gt; 
&lt;table&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="center" valign="middle"&gt; &lt;a href="https://crabnebula.dev" target="_blank"&gt; &lt;img src="https://raw.githubusercontent.com/tauri-apps/plugins-workspace/v2/.github/sponsors/crabnebula.svg?sanitize=true" alt="CrabNebula" width="283" /&gt; &lt;/a&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;For the complete list of sponsors please visit our &lt;a href="https://tauri.app#sponsors"&gt;website&lt;/a&gt; and &lt;a href="https://opencollective.com/tauri"&gt;Open Collective&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>huggingface/candle</title>
      <link>https://github.com/huggingface/candle</link>
      <description>&lt;p&gt;Minimalist ML framework for Rust&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;candle&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://discord.gg/hugging-face-879548962464493619"&gt;&lt;img src="https://dcbadge.limes.pink/api/server/hugging-face-879548962464493619" alt="discord server" /&gt;&lt;/a&gt; &lt;a href="https://crates.io/crates/candle-core"&gt;&lt;img src="https://img.shields.io/crates/v/candle-core.svg?sanitize=true" alt="Latest version" /&gt;&lt;/a&gt; &lt;a href="https://docs.rs/candle-core"&gt;&lt;img src="https://docs.rs/candle-core/badge.svg?sanitize=true" alt="Documentation" /&gt;&lt;/a&gt; &lt;a href="https://github.com/huggingface/candle/raw/main/LICENSE-MIT"&gt;&lt;img src="https://img.shields.io/github/license/base-org/node?color=blue" alt="License" /&gt;&lt;/a&gt; &lt;a href="https://github.com/huggingface/candle/raw/main/LICENSE-APACHE"&gt;&lt;img src="https://img.shields.io/badge/license-Apache%202.0-blue?style=flat-square" alt="License" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Candle is a minimalist ML framework for Rust with a focus on performance (including GPU support) and ease of use. Try our online demos: &lt;a href="https://huggingface.co/spaces/lmz/candle-whisper"&gt;whisper&lt;/a&gt;, &lt;a href="https://huggingface.co/spaces/lmz/candle-llama2"&gt;LLaMA2&lt;/a&gt;, &lt;a href="https://huggingface.co/spaces/radames/Candle-T5-Generation-Wasm"&gt;T5&lt;/a&gt;, &lt;a href="https://huggingface.co/spaces/lmz/candle-yolo"&gt;yolo&lt;/a&gt;, &lt;a href="https://huggingface.co/spaces/radames/candle-segment-anything-wasm"&gt;Segment Anything&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Get started&lt;/h2&gt; 
&lt;p&gt;Make sure that you have &lt;a href="https://github.com/huggingface/candle/tree/main/candle-core"&gt;&lt;code&gt;candle-core&lt;/code&gt;&lt;/a&gt; correctly installed as described in &lt;a href="https://huggingface.github.io/candle/guide/installation.html"&gt;&lt;strong&gt;Installation&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Let's see how to run a simple matrix multiplication. Write the following to your &lt;code&gt;myapp/src/main.rs&lt;/code&gt; file:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-rust"&gt;use candle_core::{Device, Tensor};

fn main() -&amp;gt; Result&amp;lt;(), Box&amp;lt;dyn std::error::Error&amp;gt;&amp;gt; {
    let device = Device::Cpu;

    let a = Tensor::randn(0f32, 1., (2, 3), &amp;amp;device)?;
    let b = Tensor::randn(0f32, 1., (3, 4), &amp;amp;device)?;

    let c = a.matmul(&amp;amp;b)?;
    println!("{c}");
    Ok(())
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;code&gt;cargo run&lt;/code&gt; should display a tensor of shape &lt;code&gt;Tensor[[2, 4], f32]&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Having installed &lt;code&gt;candle&lt;/code&gt; with Cuda support, simply define the &lt;code&gt;device&lt;/code&gt; to be on GPU:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-diff"&gt;- let device = Device::Cpu;
+ let device = Device::new_cuda(0)?;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For more advanced examples, please have a look at the following section.&lt;/p&gt; 
&lt;h2&gt;Check out our examples&lt;/h2&gt; 
&lt;p&gt;These online demos run entirely in your browser:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://huggingface.co/spaces/lmz/candle-yolo"&gt;yolo&lt;/a&gt;: pose estimation and object recognition.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://huggingface.co/spaces/lmz/candle-whisper"&gt;whisper&lt;/a&gt;: speech recognition.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://huggingface.co/spaces/lmz/candle-llama2"&gt;LLaMA2&lt;/a&gt;: text generation.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://huggingface.co/spaces/radames/Candle-T5-Generation-Wasm"&gt;T5&lt;/a&gt;: text generation.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://huggingface.co/spaces/radames/Candle-Phi-1.5-Wasm"&gt;Phi-1.5, and Phi-2&lt;/a&gt;: text generation.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://huggingface.co/spaces/radames/candle-segment-anything-wasm"&gt;Segment Anything Model&lt;/a&gt;: Image segmentation.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://huggingface.co/spaces/radames/Candle-BLIP-Image-Captioning"&gt;BLIP&lt;/a&gt;: image captioning.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;We also provide some command line based examples using state of the art models:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/huggingface/candle/main/candle-examples/examples/llama/"&gt;LLaMA v1, v2, and v3&lt;/a&gt;: general LLM, includes the SOLAR-10.7B variant.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/huggingface/candle/main/candle-examples/examples/falcon/"&gt;Falcon&lt;/a&gt;: general LLM.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/huggingface/candle/main/candle-examples/examples/codegeex4-9b/"&gt;Codegeex4&lt;/a&gt;: Code completion, code interpreter, web search, function calling, repository-level&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/huggingface/candle/main/candle-examples/examples/glm4/"&gt;GLM4&lt;/a&gt;: Open Multilingual Multimodal Chat LMs by THUDM&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/huggingface/candle/main/candle-examples/examples/gemma/"&gt;Gemma v1 and v2&lt;/a&gt;: 2b and 7b+/9b general LLMs from Google Deepmind.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/huggingface/candle/main/candle-examples/examples/recurrent-gemma/"&gt;RecurrentGemma&lt;/a&gt;: 2b and 7b Griffin based models from Google that mix attention with a RNN like state.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/huggingface/candle/main/candle-examples/examples/phi/"&gt;Phi-1, Phi-1.5, Phi-2, and Phi-3&lt;/a&gt;: 1.3b, 2.7b, and 3.8b general LLMs with performance on par with 7b models.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/huggingface/candle/main/candle-examples/examples/stable-lm/"&gt;StableLM-3B-4E1T&lt;/a&gt;: a 3b general LLM pre-trained on 1T tokens of English and code datasets. Also supports StableLM-2, a 1.6b LLM trained on 2T tokens, as well as the code variants.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/huggingface/candle/main/candle-examples/examples/mamba/"&gt;Mamba&lt;/a&gt;: an inference only implementation of the Mamba state space model.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/huggingface/candle/main/candle-examples/examples/mistral/"&gt;Mistral7b-v0.1&lt;/a&gt;: a 7b general LLM with better performance than all publicly available 13b models as of 2023-09-28.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/huggingface/candle/main/candle-examples/examples/mixtral/"&gt;Mixtral8x7b-v0.1&lt;/a&gt;: a sparse mixture of experts 8x7b general LLM with better performance than a Llama 2 70B model with much faster inference.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/huggingface/candle/main/candle-examples/examples/bigcode/"&gt;StarCoder&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/huggingface/candle/main/candle-examples/examples/starcoder2/"&gt;StarCoder2&lt;/a&gt;: LLM specialized to code generation.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/huggingface/candle/main/candle-examples/examples/qwen/"&gt;Qwen1.5&lt;/a&gt;: Bilingual (English/Chinese) LLMs.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/huggingface/candle/main/candle-examples/examples/rwkv/"&gt;RWKV v5 and v6&lt;/a&gt;: An RNN with transformer level LLM performance.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/huggingface/candle/main/candle-examples/examples/replit-code/"&gt;Replit-code-v1.5&lt;/a&gt;: a 3.3b LLM specialized for code completion.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/huggingface/candle/main/candle-examples/examples/yi/"&gt;Yi-6B / Yi-34B&lt;/a&gt;: two bilingual (English/Chinese) general LLMs with 6b and 34b parameters.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/huggingface/candle/main/candle-examples/examples/quantized/"&gt;Quantized LLaMA&lt;/a&gt;: quantized version of the LLaMA model using the same quantization techniques as &lt;a href="https://github.com/ggerganov/llama.cpp"&gt;llama.cpp&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/huggingface/candle/main/candle-examples/examples/quantized-qwen3-moe/"&gt;Quantized Qwen3 MoE&lt;/a&gt;: support gguf quantized models of Qwen3 MoE models.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;img src="https://github.com/huggingface/candle/raw/main/candle-examples/examples/quantized/assets/aoc.gif" width="600" /&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/huggingface/candle/main/candle-examples/examples/stable-diffusion/"&gt;Stable Diffusion&lt;/a&gt;: text to image generative model, support for the 1.5, 2.1, SDXL 1.0 and Turbo versions.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;img src="https://github.com/huggingface/candle/raw/main/candle-examples/examples/stable-diffusion/assets/stable-diffusion-xl.jpg" width="200" /&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/huggingface/candle/main/candle-examples/examples/wuerstchen/"&gt;Wuerstchen&lt;/a&gt;: another text to image generative model.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;img src="https://github.com/huggingface/candle/raw/main/candle-examples/examples/wuerstchen/assets/cat.jpg" width="200" /&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/huggingface/candle/main/candle-examples/examples/yolo-v3/"&gt;yolo-v3&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/huggingface/candle/main/candle-examples/examples/yolo-v8/"&gt;yolo-v8&lt;/a&gt;: object detection and pose estimation models.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://github.com/huggingface/candle/raw/main/candle-examples/examples/yolo-v8/assets/bike.od.jpg" width="200" /&gt;&lt;img src="https://github.com/huggingface/candle/raw/main/candle-examples/examples/yolo-v8/assets/bike.pose.jpg" width="200" /&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/huggingface/candle/main/candle-examples/examples/segment-anything/"&gt;segment-anything&lt;/a&gt;: image segmentation model with prompt.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;img src="https://github.com/huggingface/candle/raw/main/candle-examples/examples/segment-anything/assets/sam_merged.jpg" width="200" /&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/huggingface/candle/main/candle-examples/examples/segformer/"&gt;SegFormer&lt;/a&gt;: transformer based semantic segmentation model.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/huggingface/candle/main/candle-examples/examples/whisper/"&gt;Whisper&lt;/a&gt;: speech recognition model.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/huggingface/candle/main/candle-examples/examples/encodec/"&gt;EnCodec&lt;/a&gt;: high-quality audio compression model using residual vector quantization.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/huggingface/candle/main/candle-examples/examples/metavoice/"&gt;MetaVoice&lt;/a&gt;: foundational model for text-to-speech.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/huggingface/candle/main/candle-examples/examples/parler-tts/"&gt;Parler-TTS&lt;/a&gt;: large text-to-speech model.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/huggingface/candle/main/candle-examples/examples/t5"&gt;T5&lt;/a&gt;, &lt;a href="https://raw.githubusercontent.com/huggingface/candle/main/candle-examples/examples/bert/"&gt;Bert&lt;/a&gt;, &lt;a href="https://raw.githubusercontent.com/huggingface/candle/main/candle-examples/examples/jina-bert/"&gt;JinaBert&lt;/a&gt; : useful for sentence embeddings.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/huggingface/candle/main/candle-examples/examples/dinov2/"&gt;DINOv2&lt;/a&gt;: computer vision model trained using self-supervision (can be used for imagenet classification, depth evaluation, segmentation).&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/huggingface/candle/main/candle-examples/examples/vgg/"&gt;VGG&lt;/a&gt;, &lt;a href="https://raw.githubusercontent.com/huggingface/candle/main/candle-examples/examples/repvgg"&gt;RepVGG&lt;/a&gt;: computer vision models.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/huggingface/candle/main/candle-examples/examples/blip/"&gt;BLIP&lt;/a&gt;: image to text model, can be used to generate captions for an image.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/huggingface/candle/main/candle-examples/examples/clip/"&gt;CLIP&lt;/a&gt;: multi-model vision and language model.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/huggingface/candle/main/candle-examples/examples/trocr/"&gt;TrOCR&lt;/a&gt;: a transformer OCR model, with dedicated submodels for hand-writing and printed recognition.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/huggingface/candle/main/candle-examples/examples/marian-mt/"&gt;Marian-MT&lt;/a&gt;: neural machine translation model, generates the translated text from the input text.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/huggingface/candle/main/candle-examples/examples/moondream/"&gt;Moondream&lt;/a&gt;: tiny computer-vision model that can answer real-world questions about images.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Run them using commands like:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;cargo run --example quantized --release
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;In order to use &lt;strong&gt;CUDA&lt;/strong&gt; add &lt;code&gt;--features cuda&lt;/code&gt; to the example command line. If you have cuDNN installed, use &lt;code&gt;--features cudnn&lt;/code&gt; for even more speedups.&lt;/p&gt; 
&lt;p&gt;There are also some wasm examples for whisper and &lt;a href="https://github.com/karpathy/llama2.c"&gt;llama2.c&lt;/a&gt;. You can either build them with &lt;code&gt;trunk&lt;/code&gt; or try them online: &lt;a href="https://huggingface.co/spaces/lmz/candle-whisper"&gt;whisper&lt;/a&gt;, &lt;a href="https://huggingface.co/spaces/lmz/candle-llama2"&gt;llama2&lt;/a&gt;, &lt;a href="https://huggingface.co/spaces/radames/Candle-T5-Generation-Wasm"&gt;T5&lt;/a&gt;, &lt;a href="https://huggingface.co/spaces/radames/Candle-Phi-1.5-Wasm"&gt;Phi-1.5, and Phi-2&lt;/a&gt;, &lt;a href="https://huggingface.co/spaces/radames/candle-segment-anything-wasm"&gt;Segment Anything Model&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;For LLaMA2, run the following command to retrieve the weight files and start a test server:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd candle-wasm-examples/llama2-c
wget https://huggingface.co/spaces/lmz/candle-llama2/resolve/main/model.bin
wget https://huggingface.co/spaces/lmz/candle-llama2/resolve/main/tokenizer.json
trunk serve --release --port 8081
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;And then head over to &lt;a href="http://localhost:8081/"&gt;http://localhost:8081/&lt;/a&gt;.&lt;/p&gt; 
&lt;!-- ANCHOR: useful_libraries ---&gt; 
&lt;h2&gt;Useful External Resources&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ToluClassics/candle-tutorial"&gt;&lt;code&gt;candle-tutorial&lt;/code&gt;&lt;/a&gt;: A very detailed tutorial showing how to convert a PyTorch model to Candle.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/EricLBuehler/candle-lora"&gt;&lt;code&gt;candle-lora&lt;/code&gt;&lt;/a&gt;: Efficient and ergonomic LoRA implementation for Candle. &lt;code&gt;candle-lora&lt;/code&gt; has&lt;br /&gt; out-of-the-box LoRA support for many models from Candle, which can be found &lt;a href="https://github.com/EricLBuehler/candle-lora/tree/master/candle-lora-transformers/examples"&gt;here&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/KGrewal1/optimisers"&gt;&lt;code&gt;optimisers&lt;/code&gt;&lt;/a&gt;: A collection of optimisers including SGD with momentum, AdaGrad, AdaDelta, AdaMax, NAdam, RAdam, and RMSprop.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/EricLBuehler/candle-vllm"&gt;&lt;code&gt;candle-vllm&lt;/code&gt;&lt;/a&gt;: Efficient platform for inference and serving local LLMs including an OpenAI compatible API server.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mokeyish/candle-ext"&gt;&lt;code&gt;candle-ext&lt;/code&gt;&lt;/a&gt;: An extension library to Candle that provides PyTorch functions not currently available in Candle.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/vishpat/candle-coursera-ml"&gt;&lt;code&gt;candle-coursera-ml&lt;/code&gt;&lt;/a&gt;: Implementation of ML algorithms from Coursera's &lt;a href="https://www.coursera.org/specializations/machine-learning-introduction"&gt;Machine Learning Specialization&lt;/a&gt; course.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/floneum/floneum/tree/master/interfaces/kalosm"&gt;&lt;code&gt;kalosm&lt;/code&gt;&lt;/a&gt;: A multi-modal meta-framework in Rust for interfacing with local pre-trained models with support for controlled generation, custom samplers, in-memory vector databases, audio transcription, and more.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/EricLBuehler/candle-sampling"&gt;&lt;code&gt;candle-sampling&lt;/code&gt;&lt;/a&gt;: Sampling techniques for Candle.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jeroenvlek/gpt-from-scratch-rs"&gt;&lt;code&gt;gpt-from-scratch-rs&lt;/code&gt;&lt;/a&gt;: A port of Andrej Karpathy's &lt;em&gt;Let's build GPT&lt;/em&gt; tutorial on YouTube showcasing the Candle API on a toy problem.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tomsanbear/candle-einops"&gt;&lt;code&gt;candle-einops&lt;/code&gt;&lt;/a&gt;: A pure rust implementation of the python &lt;a href="https://github.com/arogozhnikov/einops"&gt;einops&lt;/a&gt; library.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/atoma-network/atoma-infer"&gt;&lt;code&gt;atoma-infer&lt;/code&gt;&lt;/a&gt;: A Rust library for fast inference at scale, leveraging FlashAttention2 for efficient attention computation, PagedAttention for efficient KV-cache memory management, and multi-GPU support. It is OpenAI api compatible.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/nerdai/llms-from-scratch-rs"&gt;&lt;code&gt;llms-from-scratch-rs&lt;/code&gt;&lt;/a&gt;: A comprehensive Rust translation of the code from Sebastian Raschka's Build an LLM from Scratch book.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/guoqingbao/vllm.rs"&gt;&lt;code&gt;vllm.rs&lt;/code&gt;&lt;/a&gt;: A minimalist vLLM implementation in Rust based on Candle.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;If you have an addition to this list, please submit a pull request.&lt;/p&gt; 
&lt;!-- ANCHOR_END: useful_libraries ---&gt; 
&lt;!-- ANCHOR: features ---&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Simple syntax, looks and feels like PyTorch. 
  &lt;ul&gt; 
   &lt;li&gt;Model training.&lt;/li&gt; 
   &lt;li&gt;Embed user-defined ops/kernels, such as &lt;a href="https://github.com/huggingface/candle/raw/89ba005962495f2bfbda286e185e9c3c7f5300a3/candle-flash-attn/src/lib.rs#L152"&gt;flash-attention v2&lt;/a&gt;.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Backends. 
  &lt;ul&gt; 
   &lt;li&gt;Optimized CPU backend with optional MKL support for x86 and Accelerate for macs.&lt;/li&gt; 
   &lt;li&gt;CUDA backend for efficiently running on GPUs, multiple GPU distribution via NCCL.&lt;/li&gt; 
   &lt;li&gt;WASM support, run your models in a browser.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Included models. 
  &lt;ul&gt; 
   &lt;li&gt;Language Models. 
    &lt;ul&gt; 
     &lt;li&gt;LLaMA v1, v2, and v3 with variants such as SOLAR-10.7B.&lt;/li&gt; 
     &lt;li&gt;Falcon.&lt;/li&gt; 
     &lt;li&gt;StarCoder, StarCoder2.&lt;/li&gt; 
     &lt;li&gt;Phi 1, 1.5, 2, and 3.&lt;/li&gt; 
     &lt;li&gt;Mamba, Minimal Mamba&lt;/li&gt; 
     &lt;li&gt;Gemma v1 2b and 7b+, v2 2b and 9b.&lt;/li&gt; 
     &lt;li&gt;Mistral 7b v0.1.&lt;/li&gt; 
     &lt;li&gt;Mixtral 8x7b v0.1.&lt;/li&gt; 
     &lt;li&gt;StableLM-3B-4E1T, StableLM-2-1.6B, Stable-Code-3B.&lt;/li&gt; 
     &lt;li&gt;Replit-code-v1.5-3B.&lt;/li&gt; 
     &lt;li&gt;Bert.&lt;/li&gt; 
     &lt;li&gt;Yi-6B and Yi-34B.&lt;/li&gt; 
     &lt;li&gt;Qwen1.5, Qwen1.5 MoE, Qwen3 MoE.&lt;/li&gt; 
     &lt;li&gt;RWKV v5 and v6.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;Quantized LLMs. 
    &lt;ul&gt; 
     &lt;li&gt;Llama 7b, 13b, 70b, as well as the chat and code variants.&lt;/li&gt; 
     &lt;li&gt;Mistral 7b, and 7b instruct.&lt;/li&gt; 
     &lt;li&gt;Mixtral 8x7b.&lt;/li&gt; 
     &lt;li&gt;Zephyr 7b a and b (Mistral-7b based).&lt;/li&gt; 
     &lt;li&gt;OpenChat 3.5 (Mistral-7b based).&lt;/li&gt; 
     &lt;li&gt;Qwen3 MoE (16B-A3B, 32B-A3B)&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;Text to text. 
    &lt;ul&gt; 
     &lt;li&gt;T5 and its variants: FlanT5, UL2, MADLAD400 (translation), CoEdit (Grammar correction).&lt;/li&gt; 
     &lt;li&gt;Marian MT (Machine Translation).&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;Text to image. 
    &lt;ul&gt; 
     &lt;li&gt;Stable Diffusion v1.5, v2.1, XL v1.0.&lt;/li&gt; 
     &lt;li&gt;Wurstchen v2.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;Image to text. 
    &lt;ul&gt; 
     &lt;li&gt;BLIP.&lt;/li&gt; 
     &lt;li&gt;TrOCR.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;Audio. 
    &lt;ul&gt; 
     &lt;li&gt;Whisper, multi-lingual speech-to-text.&lt;/li&gt; 
     &lt;li&gt;EnCodec, audio compression model.&lt;/li&gt; 
     &lt;li&gt;MetaVoice-1B, text-to-speech model.&lt;/li&gt; 
     &lt;li&gt;Parler-TTS, text-to-speech model.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;Computer Vision Models. 
    &lt;ul&gt; 
     &lt;li&gt;DINOv2, ConvMixer, EfficientNet, ResNet, ViT, VGG, RepVGG, ConvNeXT, ConvNeXTv2, MobileOne, EfficientVit (MSRA), MobileNetv4, Hiera, FastViT.&lt;/li&gt; 
     &lt;li&gt;yolo-v3, yolo-v8.&lt;/li&gt; 
     &lt;li&gt;Segment-Anything Model (SAM).&lt;/li&gt; 
     &lt;li&gt;SegFormer.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;File formats: load models from safetensors, npz, ggml, or PyTorch files.&lt;/li&gt; 
 &lt;li&gt;Serverless (on CPU), small and fast deployments.&lt;/li&gt; 
 &lt;li&gt;Quantization support using the llama.cpp quantized types.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;!-- ANCHOR_END: features ---&gt; 
&lt;h2&gt;How to use&lt;/h2&gt; 
&lt;!-- ANCHOR: cheatsheet ---&gt; 
&lt;p&gt;Cheatsheet:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;&lt;/th&gt; 
   &lt;th&gt;Using PyTorch&lt;/th&gt; 
   &lt;th&gt;Using Candle&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Creation&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;torch.Tensor([[1, 2], [3, 4]])&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;Tensor::new(&amp;amp;[[1f32, 2.], [3., 4.]], &amp;amp;Device::Cpu)?&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Creation&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;torch.zeros((2, 2))&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;Tensor::zeros((2, 2), DType::F32, &amp;amp;Device::Cpu)?&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Indexing&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;tensor[:, :4]&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;tensor.i((.., ..4))?&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Operations&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;tensor.view((2, 2))&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;tensor.reshape((2, 2))?&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Operations&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;a.matmul(b)&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;a.matmul(&amp;amp;b)?&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Arithmetic&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;a + b&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;&amp;amp;a + &amp;amp;b&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Device&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;tensor.to(device="cuda")&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;tensor.to_device(&amp;amp;Device::new_cuda(0)?)?&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Dtype&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;tensor.to(dtype=torch.float16)&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;tensor.to_dtype(&amp;amp;DType::F16)?&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Saving&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;torch.save({"A": A}, "model.bin")&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;candle::safetensors::save(&amp;amp;HashMap::from([("A", A)]), "model.safetensors")?&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Loading&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;weights = torch.load("model.bin")&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;candle::safetensors::load("model.safetensors", &amp;amp;device)&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;!-- ANCHOR_END: cheatsheet ---&gt; 
&lt;h2&gt;Structure&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/huggingface/candle/main/candle-core"&gt;candle-core&lt;/a&gt;: Core ops, devices, and &lt;code&gt;Tensor&lt;/code&gt; struct definition&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/huggingface/candle/main/candle-nn/"&gt;candle-nn&lt;/a&gt;: Tools to build real models&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/huggingface/candle/main/candle-examples/"&gt;candle-examples&lt;/a&gt;: Examples of using the library in realistic settings&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/huggingface/candle/main/candle-kernels/"&gt;candle-kernels&lt;/a&gt;: CUDA custom kernels&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/huggingface/candle/main/candle-datasets/"&gt;candle-datasets&lt;/a&gt;: Datasets and data loaders.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/huggingface/candle/main/candle-transformers"&gt;candle-transformers&lt;/a&gt;: transformers-related utilities.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/huggingface/candle/main/candle-flash-attn"&gt;candle-flash-attn&lt;/a&gt;: Flash attention v2 layer.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/huggingface/candle/main/candle-onnx/"&gt;candle-onnx&lt;/a&gt;: ONNX model evaluation.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;FAQ&lt;/h2&gt; 
&lt;h3&gt;Why should I use Candle?&lt;/h3&gt; 
&lt;!-- ANCHOR: goals ---&gt; 
&lt;p&gt;Candle's core goal is to &lt;em&gt;make serverless inference possible&lt;/em&gt;. Full machine learning frameworks like PyTorch are very large, which makes creating instances on a cluster slow. Candle allows deployment of lightweight binaries.&lt;/p&gt; 
&lt;p&gt;Secondly, Candle lets you &lt;em&gt;remove Python&lt;/em&gt; from production workloads. Python overhead can seriously hurt performance, and the &lt;a href="https://www.backblaze.com/blog/the-python-gil-past-present-and-future/"&gt;GIL&lt;/a&gt; is a notorious source of headaches.&lt;/p&gt; 
&lt;p&gt;Finally, Rust is cool! A lot of the HF ecosystem already has Rust crates, like &lt;a href="https://github.com/huggingface/safetensors"&gt;safetensors&lt;/a&gt; and &lt;a href="https://github.com/huggingface/tokenizers"&gt;tokenizers&lt;/a&gt;.&lt;/p&gt; 
&lt;!-- ANCHOR_END: goals ---&gt; 
&lt;h3&gt;Other ML frameworks&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/coreylowman/dfdx"&gt;dfdx&lt;/a&gt; is a formidable crate, with shapes being included in types. This prevents a lot of headaches by getting the compiler to complain about shape mismatches right off the bat. However, we found that some features still require nightly, and writing code can be a bit daunting for non rust experts.&lt;/p&gt; &lt;p&gt;We're leveraging and contributing to other core crates for the runtime so hopefully both crates can benefit from each other.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/burn-rs/burn"&gt;burn&lt;/a&gt; is a general crate that can leverage multiple backends so you can choose the best engine for your workload.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/LaurentMazare/tch-rs.git"&gt;tch-rs&lt;/a&gt; Bindings to the torch library in Rust. Extremely versatile, but they bring in the entire torch library into the runtime. The main contributor of &lt;code&gt;tch-rs&lt;/code&gt; is also involved in the development of &lt;code&gt;candle&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Common Errors&lt;/h3&gt; 
&lt;h4&gt;Missing symbols when compiling with the mkl feature.&lt;/h4&gt; 
&lt;p&gt;If you get some missing symbols when compiling binaries/tests using the mkl or accelerate features, e.g. for mkl you get:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;  = note: /usr/bin/ld: (....o): in function `blas::sgemm':
          .../blas-0.22.0/src/lib.rs:1944: undefined reference to `sgemm_' collect2: error: ld returned 1 exit status

  = note: some `extern` functions couldn't be found; some native libraries may need to be installed or have their path specified
  = note: use the `-l` flag to specify native libraries to link
  = note: use the `cargo:rustc-link-lib` directive to specify the native libraries to link with Cargo
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;or for accelerate:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Undefined symbols for architecture arm64:
            "_dgemm_", referenced from:
                candle_core::accelerate::dgemm::h1b71a038552bcabe in libcandle_core...
            "_sgemm_", referenced from:
                candle_core::accelerate::sgemm::h2cf21c592cba3c47 in libcandle_core...
          ld: symbol(s) not found for architecture arm64
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This is likely due to a missing linker flag that was needed to enable the mkl library. You can try adding the following for mkl at the top of your binary:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-rust"&gt;extern crate intel_mkl_src;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;or for accelerate:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-rust"&gt;extern crate accelerate_src;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Cannot run the LLaMA examples: access to source requires login credentials&lt;/h4&gt; 
&lt;pre&gt;&lt;code&gt;Error: request error: https://huggingface.co/meta-llama/Llama-2-7b-hf/resolve/main/tokenizer.json: status code 401
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This is likely because you're not permissioned for the LLaMA-v2 model. To fix this, you have to register on the huggingface-hub, accept the &lt;a href="https://huggingface.co/meta-llama/Llama-2-7b-hf"&gt;LLaMA-v2 model conditions&lt;/a&gt;, and set up your authentication token. See issue &lt;a href="https://github.com/huggingface/candle/issues/350"&gt;#350&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;h4&gt;Missing cute/cutlass headers when compiling flash-attn&lt;/h4&gt; 
&lt;pre&gt;&lt;code&gt;  In file included from kernels/flash_fwd_launch_template.h:11:0,
                   from kernels/flash_fwd_hdim224_fp16_sm80.cu:5:
  kernels/flash_fwd_kernel.h:8:10: fatal error: cute/algorithm/copy.hpp: No such file or directory
   #include &amp;lt;cute/algorithm/copy.hpp&amp;gt;
            ^~~~~~~~~~~~~~~~~~~~~~~~~
  compilation terminated.
  Error: nvcc error while compiling:
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;a href="https://github.com/NVIDIA/cutlass"&gt;cutlass&lt;/a&gt; is provided as a git submodule so you may want to run the following command to check it in properly.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git submodule update --init
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Compiling with flash-attention fails&lt;/h4&gt; 
&lt;pre&gt;&lt;code&gt;/usr/include/c++/11/bits/std_function.h:530:146: error: parameter packs not expanded with ‚Äò...‚Äô:
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This is a bug in gcc-11 triggered by the Cuda compiler. To fix this, install a different, supported gcc version - for example gcc-10, and specify the path to the compiler in the NVCC_CCBIN environment variable.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;env NVCC_CCBIN=/usr/lib/gcc/x86_64-linux-gnu/10 cargo ...
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Linking error on windows when running rustdoc or mdbook tests&lt;/h4&gt; 
&lt;pre&gt;&lt;code&gt;Couldn't compile the test.
---- .\candle-book\src\inference\hub.md - Using_the_hub::Using_in_a_real_model_ (line 50) stdout ----
error: linking with `link.exe` failed: exit code: 1181
//very long chain of linking
 = note: LINK : fatal error LNK1181: cannot open input file 'windows.0.48.5.lib'
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Make sure you link all native libraries that might be located outside a project target, e.g., to run mdbook tests, you should run:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;mdbook test candle-book -L .\target\debug\deps\ `
-L native=$env:USERPROFILE\.cargo\registry\src\index.crates.io-6f17d22bba15001f\windows_x86_64_msvc-0.42.2\lib `
-L native=$env:USERPROFILE\.cargo\registry\src\index.crates.io-6f17d22bba15001f\windows_x86_64_msvc-0.48.5\lib
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Extremely slow model load time with WSL&lt;/h4&gt; 
&lt;p&gt;This may be caused by the models being loaded from &lt;code&gt;/mnt/c&lt;/code&gt;, more details on &lt;a href="https://stackoverflow.com/questions/68972448/why-is-wsl-extremely-slow-when-compared-with-native-windows-npm-yarn-processing"&gt;stackoverflow&lt;/a&gt;.&lt;/p&gt; 
&lt;h4&gt;Tracking down errors&lt;/h4&gt; 
&lt;p&gt;You can set &lt;code&gt;RUST_BACKTRACE=1&lt;/code&gt; to be provided with backtraces when a candle error is generated.&lt;/p&gt; 
&lt;h4&gt;CudaRC error&lt;/h4&gt; 
&lt;p&gt;If you encounter an error like this one &lt;code&gt;called &lt;/code&gt;Result::unwrap()&lt;code&gt;on an&lt;/code&gt;Err&lt;code&gt; value: LoadLibraryExW { source: Os { code: 126, kind: Uncategorized, message: "The specified module could not be found." } }&lt;/code&gt; on windows. To fix copy and rename these 3 files (make sure they are in path). The paths depend on your cuda version. &lt;code&gt;c:\Windows\System32\nvcuda.dll&lt;/code&gt; -&amp;gt; &lt;code&gt;cuda.dll&lt;/code&gt; &lt;code&gt;c:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.4\bin\cublas64_12.dll&lt;/code&gt; -&amp;gt; &lt;code&gt;cublas.dll&lt;/code&gt; &lt;code&gt;c:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.4\bin\curand64_10.dll&lt;/code&gt; -&amp;gt; &lt;code&gt;curand.dll&lt;/code&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>rolldown/rolldown</title>
      <link>https://github.com/rolldown/rolldown</link>
      <description>&lt;p&gt;Fast Rust bundler for JavaScript/TypeScript with Rollup-compatible API.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;br /&gt; &lt;br /&gt; &lt;a href="https://rolldown.rs" target="_blank" rel="noopener noreferrer"&gt; 
  &lt;picture&gt; 
   &lt;source media="(prefers-color-scheme: dark)" srcset="https://rolldown.rs/rolldown-light.svg" /&gt; 
   &lt;source media="(prefers-color-scheme: light)" srcset="https://rolldown.rs/rolldown-dark.svg" /&gt; 
   &lt;img alt="rolldown logo" src="https://rolldown.rs/rolldown-dark.svg?sanitize=true" height="60" /&gt; 
  &lt;/picture&gt; &lt;/a&gt; &lt;br /&gt; &lt;br /&gt; &lt;br /&gt; &lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://github.com/rolldown/rolldown/raw/main/LICENSE"&gt;&lt;img src="https://img.shields.io/badge/license-MIT-blue.svg?sanitize=true" alt="MIT licensed" /&gt;&lt;/a&gt; &lt;a href="https://www.npmjs.com/package/rolldown/v/latest"&gt;&lt;img src="https://img.shields.io/npm/v/rolldown/latest?color=brightgreen" alt="NPM version" /&gt;&lt;/a&gt; &lt;a href="https://codspeed.io/rolldown/rolldown"&gt;&lt;img src="https://img.shields.io/endpoint?url=https://codspeed.io/badge.json" alt="CodSpeed Badge" /&gt;&lt;/a&gt; &lt;a href="https://chat.rolldown.rs"&gt;&lt;img src="https://img.shields.io/discord/1079625926024900739?logo=discord&amp;amp;label=Discord" alt="Discord chat" /&gt;&lt;/a&gt; &lt;a href="https://deepwiki.com/rolldown/rolldown"&gt;&lt;img src="https://deepwiki.com/badge.svg?sanitize=true" alt="Ask DeepWiki" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://www.npmjs.com/package/rolldown/v/latest"&gt;&lt;img src="https://img.shields.io/npm/unpacked-size/rolldown/latest?label=npm" alt="NPM Unpacked Size (with version)" /&gt;&lt;/a&gt; &lt;a href="https://www.npmjs.com/package/@rolldown/binding-darwin-arm64"&gt;&lt;img src="https://img.shields.io/npm/unpacked-size/%40rolldown%2Fbinding-darwin-arm64/latest?label=darwin-arm64" alt="NPM Unpacked Size darwin-arm64" /&gt;&lt;/a&gt; &lt;a href="https://www.npmjs.com/package/@rolldown/binding-darwin-x64"&gt;&lt;img src="https://img.shields.io/npm/unpacked-size/%40rolldown%2Fbinding-darwin-x64/latest?label=darwin-x64" alt="NPM Unpacked Size darwin-x64" /&gt;&lt;/a&gt; &lt;a href="https://www.npmjs.com/package/@rolldown/binding-linux-x64-gnu"&gt;&lt;img src="https://img.shields.io/npm/unpacked-size/%40rolldown%2Fbinding-linux-x64-gnu/latest?label=linux-x64-gnu" alt="NPM Unpacked Size linux-x64-gnu" /&gt;&lt;/a&gt; &lt;a href="https://www.npmjs.com/package/@rolldown/binding-win32-x64-msvc"&gt;&lt;img src="https://img.shields.io/npm/unpacked-size/%40rolldown%2Fbinding-win32-x64-msvc/latest?label=win32-x64" alt="NPM Unpacked Size win32-x64" /&gt;&lt;/a&gt; &lt;a href="https://www.npmjs.com/package/@rolldown/binding-wasm32-wasi"&gt;&lt;img src="https://img.shields.io/npm/unpacked-size/%40rolldown%2Fbinding-wasm32-wasi/latest?label=wasm32-wasi" alt="NPM Unpacked Size wasm32-wasi" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://pkg.pr.new/~/rolldown/rolldown"&gt;&lt;img src="https://pkg.pr.new/badge/pkg.pr.new/pkg.pr.new?style=flat&amp;amp;color=000&amp;amp;logoSize=auto" alt="pkg.pr.new" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://stackblitz.com/fork/github/rolldown/rolldown-starter-stackblitz"&gt;&lt;img src="https://developer.stackblitz.com/img/open_in_stackblitz.svg?sanitize=true" alt="rolldown-starter-stackblitz" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;üöß &lt;strong&gt;Release Candidate&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;Rolldown is currently in RC status. While it can already handle most production use cases, there may still be bugs and rough edges. Most notably, the built-in minification feature is still in alpha status.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h1&gt;Rolldown&lt;/h1&gt; 
&lt;p&gt;Rolldown is a JavaScript/TypeScript bundler written in Rust intended to serve as the future bundler used in &lt;a href="https://vitejs.dev/"&gt;Vite&lt;/a&gt;. It provides Rollup-compatible APIs and plugin interface, but will be more similar to esbuild in scope.&lt;/p&gt; 
&lt;p&gt;For more information, please check out the documentation at &lt;a href="https://rolldown.rs/guide/getting-started"&gt;rolldown.rs&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;VoidZero Inc.&lt;/h2&gt; 
&lt;p&gt;Rolldown is a project of &lt;a href="https://voidzero.dev/"&gt;VoidZero&lt;/a&gt;, see our announcement &lt;a href="https://voidzero.dev/posts/announcing-voidzero-inc"&gt;Announcing VoidZero - Next Generation Toolchain for JavaScript&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;If you have requirements for JavaScript tools at scale, please &lt;a href="https://forms.gle/WQgjyzYJpwurpxWKA"&gt;get in touch&lt;/a&gt;!&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We would love to have more contributors involved!&lt;/p&gt; 
&lt;p&gt;To get started, please read our &lt;a href="https://rolldown.rs/contribution-guide/"&gt;Contributing Guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Credits&lt;/h2&gt; 
&lt;p&gt;The Rolldown project is heavily inspired by:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/rollup/rollup"&gt;Rollup&lt;/a&gt;, created by &lt;a href="https://github.com/Rich-Harris"&gt;Rich Harris&lt;/a&gt; and maintained by &lt;a href="https://github.com/lukastaegert"&gt;Lukas Taegert-Atkinson&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/evanw/esbuild"&gt;esbuild&lt;/a&gt;, created by &lt;a href="https://github.com/evanw"&gt;Evan Wallace&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;And supported by:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/napi-rs/napi-rs"&gt;napi-rs&lt;/a&gt; for Node.js add-ons in Rust via Node-API.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/oxc-project/oxc"&gt;oxc&lt;/a&gt; for the underlying parser, resolver, and sourcemap support.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Licenses&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the &lt;a href="https://raw.githubusercontent.com/rolldown/rolldown/main/LICENSE"&gt;MIT License&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;This project also partially contains code derived or copied from the following projects:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/rollup/rollup/raw/680912e2ceb42c8d5e571e01c6ece0e4889aecbb/LICENSE-CORE.md"&gt;rollup(MIT)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/evanw/esbuild/raw/0c8a0a901d9a6c7bbff9b4dd347c8a3f65f6c6dd/LICENSE.md"&gt;esbuild(MIT)&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Licenses of these projects are listed in &lt;a href="https://raw.githubusercontent.com/rolldown/rolldown/main/THIRD-PARTY-LICENSE"&gt;THIRD-PARTY-LICENSE&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>espanso/espanso</title>
      <link>https://github.com/espanso/espanso</link>
      <description>&lt;p&gt;A Privacy-first, Cross-platform Text Expander written in Rust&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;&lt;img src="https://raw.githubusercontent.com/espanso/espanso/dev/images/espanso-dark.png#gh-dark-mode-only" alt="Espanso Logo" /&gt; &lt;img src="https://raw.githubusercontent.com/espanso/espanso/dev/images/espanso-light.png#gh-light-mode-only" alt="Espanso Logo" /&gt;&lt;/h1&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;em&gt;A cross-platform Text Expander written in Rust&lt;/em&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;img src="https://img.shields.io/github/v/release/espanso/espanso" alt="GitHub release (latest by date)" /&gt; &lt;img src="https://img.shields.io/badge/Maintained-yes-green.svg?sanitize=true" alt="Maintenance" /&gt; &lt;img src="https://img.shields.io/badge/language-rust-orange" alt="Language" /&gt; &lt;img src="https://img.shields.io/github/license/espanso/espanso" alt="License" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://img.shields.io/badge/platforms-Windows%2C%20macOS%20and%20Linux-blue" alt="Platforms" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://deepwiki.com/espanso/espanso"&gt;&lt;img src="https://deepwiki.com/badge.svg?sanitize=true" alt="Ask DeepWiki" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="center"&gt;Example: 2019&lt;/th&gt; 
   &lt;th align="center"&gt;Example: 2025&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;img src="https://raw.githubusercontent.com/espanso/espanso/dev/images/example.gif" alt="example" /&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;img src="https://raw.githubusercontent.com/espanso/espanso/dev/images/example-2025.gif" alt="example2025" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Quick Links&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://espanso.org"&gt;espanso website&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://hub.espanso.org/"&gt;espanso hub&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;What is a Text Expander?&lt;/h3&gt; 
&lt;p&gt;A &lt;em&gt;text expander&lt;/em&gt; is a program that detects when you type a specific &lt;strong&gt;keyword&lt;/strong&gt; and replaces it with &lt;strong&gt;something else&lt;/strong&gt;. This is useful in many ways:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Save a lot of typing&lt;/strong&gt;, expanding common sentences&lt;/li&gt; 
 &lt;li&gt;Create &lt;strong&gt;system-wide&lt;/strong&gt; code snippets&lt;/li&gt; 
 &lt;li&gt;Execute &lt;strong&gt;custom scripts&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;Use &lt;strong&gt;emojis&lt;/strong&gt; like a pro&lt;/li&gt; 
 &lt;li&gt;System-wide 'autocorrect' specific to you&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Key Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Cross-platform (&lt;strong&gt;Windows&lt;/strong&gt;, &lt;strong&gt;macOS&lt;/strong&gt;, &lt;strong&gt;Linux&lt;/strong&gt;)&lt;/li&gt; 
 &lt;li&gt;Privacy-first (100% local, no tracking)&lt;/li&gt; 
 &lt;li&gt;Works with almost &lt;strong&gt;any program&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Emoji&lt;/strong&gt; support üòÑ&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Image&lt;/strong&gt; support&lt;/li&gt; 
 &lt;li&gt;Includes a powerful &lt;strong&gt;Search Bar&lt;/strong&gt; üîé&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Date&lt;/strong&gt; expansion support&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Custom scripts&lt;/strong&gt; support&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Shell commands&lt;/strong&gt; support&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;App-specific&lt;/strong&gt; configurations&lt;/li&gt; 
 &lt;li&gt;Support &lt;a href="https://espanso.org/docs/matches/forms/"&gt;Forms&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Expandable with &lt;strong&gt;packages&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;Built-in &lt;strong&gt;package manager&lt;/strong&gt; for &lt;a href="https://hub.espanso.org/"&gt;espanso hub&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;File based configuration&lt;/li&gt; 
 &lt;li&gt;Support Regex triggers&lt;/li&gt; 
 &lt;li&gt;Experimental Wayland support&lt;/li&gt; 
 &lt;li&gt;Written in Rust (Fast, Reliable)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Community &amp;amp; Support&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;üí¨ &lt;a href="https://discord.gg/DFcCNDg7bB"&gt;espanso Discord Server&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üìñ &lt;a href="https://espanso.org/docs/"&gt;official documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üí¨ &lt;a href="https://www.reddit.com/r/espanso/"&gt;official Subreddit&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üêõ &lt;a href="https://github.com/espanso/espanso/issues"&gt;Report Issues&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üí° &lt;a href="https://github.com/espanso/espanso/discussions"&gt;Feature Requests&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Quick Start Examples&lt;/h2&gt; 
&lt;p&gt;You can create additional files to organize your matches any way you want.&lt;br /&gt; Make sure to adhere to proper YAML spacing.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;matches:
  - trigger: ":hello"
    replace: "Hi There!"
  - triggers: [":test1", ":test2"]
    replace: "These both expand to the same thing"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Team Members and Contributors&lt;/h2&gt; 
&lt;h3&gt;Team&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://github.com/federico-terzi"&gt;Federico Terzi&lt;/a&gt; (Creator of espanso)&lt;br /&gt; Rest of team in Alphabetical Order&lt;br /&gt; &lt;a href="https://github.com/Archigos"&gt;Archigos&lt;/a&gt; (Lead Maintainer)&lt;br /&gt; &lt;a href="https://github.com/AucaCoyan"&gt;Auca&lt;/a&gt; (Previous Lead Maintainer)&lt;br /&gt; &lt;a href="https://github.com/n8henrie"&gt;n8henrie&lt;/a&gt;&lt;br /&gt; &lt;a href="https://github.com/smeech"&gt;smeech&lt;/a&gt;&lt;br /&gt;&lt;/p&gt; 
&lt;p&gt;You can also see the up to date list of Team Members &lt;a href="https://github.com/orgs/espanso/people"&gt;here&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Contributors&lt;/h3&gt; 
&lt;p&gt;So many people have helped the project along the way. Thank you all!&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/espanso/espanso/graphs/contributors"&gt;&lt;img src="https://contrib.rocks/image?repo=espanso/espanso" alt="Image" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Sponsors&lt;/h2&gt; 
&lt;p&gt;We want to thank SignPath.io for code signing the Windows binaries ‚ù§Ô∏è&lt;/p&gt; 
&lt;h2&gt;Donations&lt;/h2&gt; 
&lt;p&gt;espanso is a free, open-source software project created by &lt;a href="https://github.com/federico-terzi"&gt;Federico Terzi&lt;/a&gt; and now maintained by a small team.&lt;br /&gt; If you liked the project and would like to support further development, please consider making a small donation, it really helps :)&lt;/p&gt; 
&lt;h3&gt;Current Options&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="center"&gt;PayPal&lt;/th&gt; 
   &lt;th align="center"&gt;Coming Soon&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;a href="https://www.paypal.com/cgi-bin/webscr?cmd=_s-xclick&amp;amp;hosted_button_id=FHNLR5DRS267E&amp;amp;source=url"&gt;&lt;img src="https://raw.githubusercontent.com/espanso/espanso/dev/images/donate.gif" alt="Donate with PayPal" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Remarks&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Thanks to &lt;a href="https://github.com/jordansissel/xdotool"&gt;libxdo&lt;/a&gt; and &lt;a href="https://github.com/astrand/xclip"&gt;xclip&lt;/a&gt;, used to implement the Linux port.&lt;/li&gt; 
 &lt;li&gt;Thanks to &lt;a href="https://xkbcommon.org/"&gt;libxkbcommon&lt;/a&gt; and &lt;a href="https://github.com/bugaevc/wl-clipboard"&gt;wl-clipboard&lt;/a&gt;, used to implement the Wayland port.&lt;/li&gt; 
 &lt;li&gt;Thanks to &lt;a href="https://www.wxwidgets.org/"&gt;wxWidgets&lt;/a&gt; for providing a powerful cross-platform GUI library.&lt;/li&gt; 
 &lt;li&gt;Free code signing provided by SignPath.io, certificate by SignPath Foundation.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;espanso was created by &lt;a href="http://federicoterzi.com"&gt;Federico Terzi&lt;/a&gt; and is licensed under the &lt;a href="https://raw.githubusercontent.com/espanso/espanso/dev/LICENSE"&gt;GPL-3.0 license&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>tracel-ai/burn</title>
      <link>https://github.com/tracel-ai/burn</link>
      <description>&lt;p&gt;Burn is a next generation tensor library and Deep Learning Framework that doesn't compromise on flexibility, efficiency and portability.&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/tracel-ai/burn/main/assets/logo-burn-neutral.webp" width="350px" /&gt; 
 &lt;p&gt;&lt;a href="https://discord.gg/uPEBbYYDB6"&gt;&lt;img src="https://img.shields.io/discord/1038839012602941528.svg?color=7289da&amp;amp;&amp;amp;logo=discord" alt="Discord" /&gt;&lt;/a&gt; &lt;a href="https://crates.io/crates/burn"&gt;&lt;img src="https://img.shields.io/crates/v/burn.svg?sanitize=true" alt="Current Crates.io Version" /&gt;&lt;/a&gt; &lt;a href="https://crates.io/crates/burn"&gt;&lt;img src="https://img.shields.io/crates/msrv/burn" alt="Minimum Supported Rust Version" /&gt;&lt;/a&gt; &lt;a href="https://burn.dev/docs/burn"&gt;&lt;img src="https://img.shields.io/badge/docs-latest-blue" alt="Documentation" /&gt;&lt;/a&gt; &lt;a href="https://github.com/tracel-ai/burn/actions/workflows/test.yml"&gt;&lt;img src="https://github.com/tracel-ai/burn/actions/workflows/test.yml/badge.svg?sanitize=true" alt="Test Status" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/#license"&gt;&lt;img src="https://shields.io/badge/license-MIT%2FApache--2.0-blue" alt="license" /&gt;&lt;/a&gt; &lt;a href="https://deepwiki.com/tracel-ai/burn"&gt;&lt;img src="https://deepwiki.com/badge.svg?sanitize=true" alt="Ask DeepWiki" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://www.runblaze.dev"&gt;&lt;img src="https://www.runblaze.dev/ci-blaze-powered.png" width="125px" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;hr /&gt; 
 &lt;p&gt;&lt;strong&gt;Burn is a next generation Tensor Library and Deep Learning Framework that doesn't compromise on &lt;br /&gt; flexibility, efficiency and portability.&lt;/strong&gt;&lt;/p&gt; 
 &lt;br /&gt; 
&lt;/div&gt; 
&lt;div align="left"&gt; 
 &lt;p&gt;Burn is both a tensor library and a deep learning framework optimized for numerical computing, model inference and model training. Burn leverages Rust to perform optimizations normally only available in static-graph frameworks, offering optimal speed without impacting flexibility.&lt;/p&gt; 
 &lt;h2&gt;Backend&lt;/h2&gt; 
 &lt;div align="left"&gt; 
  &lt;img align="right" src="https://raw.githubusercontent.com/tracel-ai/burn/main/assets/backend-chip.png" height="96px" /&gt; 
  &lt;p&gt;Burn strives to be as fast as possible on as many hardwares as possible, with robust implementations. We believe this flexibility is crucial for modern needs where you may train your models in the cloud, then deploy on customer hardwares, which vary from user to user.&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;h3&gt;Supported Backends&lt;/h3&gt; 
 &lt;p&gt;Most backends support all operating systems, so we don't mention them in the tables below.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;GPU Backends:&lt;/strong&gt;&lt;/p&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;&lt;/th&gt; 
    &lt;th&gt;CUDA&lt;/th&gt; 
    &lt;th&gt;ROCm&lt;/th&gt; 
    &lt;th&gt;Metal&lt;/th&gt; 
    &lt;th&gt;Vulkan&lt;/th&gt; 
    &lt;th&gt;WebGPU&lt;/th&gt; 
    &lt;th&gt;Candle&lt;/th&gt; 
    &lt;th&gt;LibTorch&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;Nvidia&lt;/td&gt; 
    &lt;td&gt;‚òëÔ∏è&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;‚òëÔ∏è&lt;/td&gt; 
    &lt;td&gt;‚òëÔ∏è&lt;/td&gt; 
    &lt;td&gt;‚òëÔ∏è&lt;/td&gt; 
    &lt;td&gt;‚òëÔ∏è&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;AMD&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;‚òëÔ∏è&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;‚òëÔ∏è&lt;/td&gt; 
    &lt;td&gt;‚òëÔ∏è&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;‚òëÔ∏è&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;Apple&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;‚òëÔ∏è&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;‚òëÔ∏è&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;‚òëÔ∏è&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;Intel&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;‚òëÔ∏è&lt;/td&gt; 
    &lt;td&gt;‚òëÔ∏è&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;Qualcom&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;‚òëÔ∏è&lt;/td&gt; 
    &lt;td&gt;‚òëÔ∏è&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;Wasm&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;‚òëÔ∏è&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
 &lt;p&gt;&lt;strong&gt;CPU Backends:&lt;/strong&gt;&lt;/p&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;&lt;/th&gt; 
    &lt;th&gt;Cpu (CubeCL)&lt;/th&gt; 
    &lt;th&gt;NdArray&lt;/th&gt; 
    &lt;th&gt;Candle&lt;/th&gt; 
    &lt;th&gt;LibTorch&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;X86&lt;/td&gt; 
    &lt;td&gt;‚òëÔ∏è&lt;/td&gt; 
    &lt;td&gt;‚òëÔ∏è&lt;/td&gt; 
    &lt;td&gt;‚òëÔ∏è&lt;/td&gt; 
    &lt;td&gt;‚òëÔ∏è&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;Arm&lt;/td&gt; 
    &lt;td&gt;‚òëÔ∏è&lt;/td&gt; 
    &lt;td&gt;‚òëÔ∏è&lt;/td&gt; 
    &lt;td&gt;‚òëÔ∏è&lt;/td&gt; 
    &lt;td&gt;‚òëÔ∏è&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;Wasm&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;‚òëÔ∏è&lt;/td&gt; 
    &lt;td&gt;‚òëÔ∏è&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;no-std&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;‚òëÔ∏è&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
 &lt;br /&gt; 
 &lt;p&gt;Compared to other frameworks, Burn has a very different approach to supporting many backends. By design, most code is generic over the Backend trait, which allows us to build Burn with swappable backends. This makes composing backend possible, augmenting them with additional functionalities such as autodifferentiation and automatic kernel fusion.&lt;/p&gt; 
 &lt;details&gt; 
  &lt;summary&gt; Autodiff: Backend decorator that brings backpropagation to any backend üîÑ &lt;/summary&gt; 
  &lt;br /&gt; 
  &lt;p&gt;Contrary to the aforementioned backends, Autodiff is actually a backend &lt;em&gt;decorator&lt;/em&gt;. This means that it cannot exist by itself; it must encapsulate another backend.&lt;/p&gt; 
  &lt;p&gt;The simple act of wrapping a base backend with Autodiff transparently equips it with autodifferentiation support, making it possible to call backward on your model.&lt;/p&gt; 
  &lt;pre&gt;&lt;code class="language-rust"&gt;use burn::backend::{Autodiff, Wgpu};
use burn::tensor::{Distribution, Tensor};

fn main() {
    type Backend = Autodiff&amp;lt;Wgpu&amp;gt;;

    let device = Default::default();

    let x: Tensor&amp;lt;Backend, 2&amp;gt; = Tensor::random([32, 32], Distribution::Default, &amp;amp;device);
    let y: Tensor&amp;lt;Backend, 2&amp;gt; = Tensor::random([32, 32], Distribution::Default, &amp;amp;device).require_grad();

    let tmp = x.clone() + y.clone();
    let tmp = tmp.matmul(x);
    let tmp = tmp.exp();

    let grads = tmp.backward();
    let y_grad = y.grad(&amp;amp;grads).unwrap();
    println!("{y_grad}");
}
&lt;/code&gt;&lt;/pre&gt; 
  &lt;p&gt;Of note, it is impossible to make the mistake of calling backward on a model that runs on a backend that does not support autodiff (for inference), as this method is only offered by an Autodiff backend.&lt;/p&gt; 
  &lt;p&gt;See the &lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/crates/burn-autodiff/README.md"&gt;Autodiff Backend README&lt;/a&gt; for more details.&lt;/p&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt; Fusion: Backend decorator that brings kernel fusion to all first-party backends &lt;/summary&gt; 
  &lt;br /&gt; 
  &lt;p&gt;This backend decorator enhances a backend with kernel fusion, provided that the inner backend supports it. Note that you can compose this backend with other backend decorators such as Autodiff. All first-party accelerated backends (like WGPU and CUDA) use Fusion by default (&lt;code&gt;burn/fusion&lt;/code&gt; feature flag), so you typically don't need to apply it manually.&lt;/p&gt; 
  &lt;pre&gt;&lt;code class="language-rust"&gt;#[cfg(not(feature = "fusion"))]
pub type Cuda&amp;lt;F = f32, I = i32&amp;gt; = CubeBackend&amp;lt;CudaRuntime, F, I, u8&amp;gt;;

#[cfg(feature = "fusion")]
pub type Cuda&amp;lt;F = f32, I = i32&amp;gt; = burn_fusion::Fusion&amp;lt;CubeBackend&amp;lt;CudaRuntime, F, I, u8&amp;gt;&amp;gt;;
&lt;/code&gt;&lt;/pre&gt; 
  &lt;p&gt;Of note, we plan to implement automatic gradient checkpointing based on compute bound and memory bound operations, which will work gracefully with the fusion backend to make your code run even faster during training, see &lt;a href="https://github.com/tracel-ai/burn/issues/936"&gt;this issue&lt;/a&gt;.&lt;/p&gt; 
  &lt;p&gt;See the &lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/crates/burn-fusion/README.md"&gt;Fusion Backend README&lt;/a&gt; for more details.&lt;/p&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt; Router (Beta): Backend decorator that composes multiple backends into a single one &lt;/summary&gt; 
  &lt;br /&gt; 
  &lt;p&gt;That backend simplifies hardware operability, if for instance you want to execute some operations on the CPU and other operations on the GPU.&lt;/p&gt; 
  &lt;pre&gt;&lt;code class="language-rust"&gt;use burn::tensor::{Distribution, Tensor};
use burn::backend::{
    NdArray, Router, Wgpu, ndarray::NdArrayDevice, router::duo::MultiDevice, wgpu::WgpuDevice,
};

fn main() {
    type Backend = Router&amp;lt;(Wgpu, NdArray)&amp;gt;;

    let device_0 = MultiDevice::B1(WgpuDevice::DiscreteGpu(0));
    let device_1 = MultiDevice::B2(NdArrayDevice::Cpu);

    let tensor_gpu =
        Tensor::&amp;lt;Backend, 2&amp;gt;::random([3, 3], burn::tensor::Distribution::Default, &amp;amp;device_0);
    let tensor_cpu =
        Tensor::&amp;lt;Backend, 2&amp;gt;::random([3, 3], burn::tensor::Distribution::Default, &amp;amp;device_1);
}

&lt;/code&gt;&lt;/pre&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt; Remote (Beta): Backend decorator for remote backend execution, useful for distributed computations &lt;/summary&gt; 
  &lt;br /&gt; 
  &lt;p&gt;That backend has two parts, one client and one server. The client sends tensor operations over the network to a remote compute backend. You can use any first-party backend as server in a single line of code:&lt;/p&gt; 
  &lt;pre&gt;&lt;code class="language-rust"&gt;fn main_server() {
    // Start a server on port 3000.
    burn::server::start::&amp;lt;burn::backend::Cuda&amp;gt;(Default::default(), 3000);
}

fn main_client() {
    // Create a client that communicate with the server on port 3000.
    use burn::backend::{Autodiff, RemoteBackend};

    type Backend = Autodiff&amp;lt;RemoteDevice&amp;gt;;

    let device = RemoteDevice::new("ws://localhost:3000");
    let tensor_gpu =
        Tensor::&amp;lt;Backend, 2&amp;gt;::random([3, 3], Distribution::Default, &amp;amp;device);
}

&lt;/code&gt;&lt;/pre&gt; 
 &lt;/details&gt; 
 &lt;br /&gt; 
 &lt;h2&gt;Training &amp;amp; Inference&lt;/h2&gt; 
 &lt;div align="left"&gt; 
  &lt;img align="right" src="https://raw.githubusercontent.com/tracel-ai/burn/main/assets/ember-wall.png" height="96px" /&gt; 
  &lt;p&gt;The whole deep learning workflow is made easy with Burn, as you can monitor your training progress with an ergonomic dashboard, and run inference everywhere from embedded devices to large GPU clusters.&lt;/p&gt; 
  &lt;p&gt;Burn was built from the ground up with training and inference in mind. It's also worth noting how Burn, in comparison to frameworks like PyTorch, simplifies the transition from training to deployment, eliminating the need for code changes.&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;div align="center"&gt; 
  &lt;br /&gt; 
  &lt;a href="https://www.youtube.com/watch?v=N9RM5CQbNQc" target="_blank"&gt; &lt;img src="https://raw.githubusercontent.com/tracel-ai/burn/main/assets/burn-train-tui.png" alt="Burn Train TUI" width="75%" /&gt; &lt;/a&gt; 
 &lt;/div&gt; 
 &lt;br /&gt; 
 &lt;p&gt;&lt;strong&gt;Click on the following sections to expand üëá&lt;/strong&gt;&lt;/p&gt; 
 &lt;details&gt; 
  &lt;summary&gt; Training Dashboard üìà &lt;/summary&gt; 
  &lt;br /&gt; 
  &lt;p&gt;As you can see in the previous video (click on the picture!), a new terminal UI dashboard based on the &lt;a href="https://github.com/ratatui-org/ratatui"&gt;Ratatui&lt;/a&gt; crate allows users to follow their training with ease without having to connect to any external application.&lt;/p&gt; 
  &lt;p&gt;You can visualize your training and validation metrics updating in real-time and analyze the lifelong progression or recent history of any registered metrics using only the arrow keys. Break from the training loop without crashing, allowing potential checkpoints to be fully written or important pieces of code to complete without interruption üõ°&lt;/p&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt; ONNX Support üê´ &lt;/summary&gt; 
  &lt;br /&gt; 
  &lt;p&gt;Burn supports importing ONNX (Open Neural Network Exchange) models, allowing you to easily port models from TensorFlow or PyTorch to Burn. The ONNX model is converted into Rust code that uses Burn's native APIs, enabling the imported model to run on any Burn backend (CPU, GPU, WebAssembly) and benefit from all of Burn's optimizations like automatic kernel fusion.&lt;/p&gt; 
  &lt;p&gt;Our ONNX support is further described in &lt;a href="https://burn.dev/books/burn/import/onnx-model.html"&gt;this section of the Burn Book üî•&lt;/a&gt;.&lt;/p&gt; 
  &lt;blockquote&gt; 
   &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: This crate is in active development and currently supports a &lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/crates/burn-onnx/SUPPORTED-ONNX-OPS.md"&gt;limited set of ONNX operators&lt;/a&gt;.&lt;/p&gt; 
  &lt;/blockquote&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt; Importing PyTorch or Safetensors Models üöö &lt;/summary&gt; 
  &lt;br /&gt; 
  &lt;p&gt;You can load weights from PyTorch or Safetensors formats directly into your Burn-defined models. This makes it easy to reuse existing models while benefiting from Burn's performance and deployment features.&lt;/p&gt; 
  &lt;p&gt;Learn more:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://burn.dev/books/burn/import/pytorch-model.html"&gt;Import pre-trained PyTorch models into Burn&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://burn.dev/books/burn/import/safetensors-model.html"&gt;Load models from Safetensors format&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt; Inference in the Browser üåê &lt;/summary&gt; 
  &lt;br /&gt; 
  &lt;p&gt;Several of our backends can run in WebAssembly environments: Candle and NdArray for CPU execution, and WGPU for GPU acceleration via WebGPU. This means that you can run inference directly within a browser. We provide several examples of this:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/mnist-inference-web"&gt;MNIST&lt;/a&gt; where you can draw digits and a small convnet tries to find which one it is! 2Ô∏è‚É£ 7Ô∏è‚É£ üò∞&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/image-classification-web"&gt;Image Classification&lt;/a&gt; where you can upload images and classify them! üåÑ&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt; Embedded: &lt;i&gt;no_std&lt;/i&gt; support ‚öôÔ∏è &lt;/summary&gt; 
  &lt;br /&gt; 
  &lt;p&gt;Burn's core components support &lt;a href="https://docs.rust-embedded.org/book/intro/no-std.html"&gt;no_std&lt;/a&gt;. This means it can run in bare metal environment such as embedded devices without an operating system.&lt;/p&gt; 
  &lt;blockquote&gt; 
   &lt;p&gt;As of now, only the NdArray backend can be used in a &lt;em&gt;no_std&lt;/em&gt; environment.&lt;/p&gt; 
  &lt;/blockquote&gt; 
 &lt;/details&gt; 
 &lt;br /&gt; 
 &lt;h3&gt;Benchmarks&lt;/h3&gt; 
 &lt;p&gt;To evaluate performance across different backends and track improvements over time, we provide a dedicated benchmarking suite.&lt;/p&gt; 
 &lt;p&gt;Run and compare benchmarks using &lt;a href="https://github.com/tracel-ai/burn-bench"&gt;burn-bench&lt;/a&gt;.&lt;/p&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;‚ö†Ô∏è &lt;strong&gt;Warning&lt;/strong&gt; When using one of the &lt;code&gt;wgpu&lt;/code&gt; backends, you may encounter compilation errors related to recursive type evaluation. This is due to complex type nesting within the &lt;code&gt;wgpu&lt;/code&gt; dependency chain. To resolve this issue, add the following line at the top of your &lt;code&gt;main.rs&lt;/code&gt; or &lt;code&gt;lib.rs&lt;/code&gt; file:&lt;/p&gt; 
  &lt;pre&gt;&lt;code class="language-rust"&gt;#![recursion_limit = "256"]
&lt;/code&gt;&lt;/pre&gt; 
  &lt;p&gt;The default recursion limit (128) is often just below the required depth (typically 130-150) due to deeply nested associated types and trait bounds.&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;h2&gt;Getting Started&lt;/h2&gt; 
 &lt;div align="left"&gt; 
  &lt;img align="right" src="https://raw.githubusercontent.com/tracel-ai/burn/main/assets/ember-walking.png" height="96px" /&gt; 
  &lt;p&gt;Just heard of Burn? You are at the right place! Just continue reading this section and we hope you can get on board really quickly.&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;details&gt; 
  &lt;summary&gt; The Burn Book üî• &lt;/summary&gt; 
  &lt;br /&gt; 
  &lt;p&gt;To begin working effectively with Burn, it is crucial to understand its key components and philosophy. This is why we highly recommend new users to read the first sections of &lt;a href="https://burn.dev/books/burn/"&gt;The Burn Book üî•&lt;/a&gt;. It provides detailed examples and explanations covering every facet of the framework, including building blocks like tensors, modules, and optimizers, all the way to advanced usage, like coding your own GPU kernels.&lt;/p&gt; 
  &lt;blockquote&gt; 
   &lt;p&gt;The project is constantly evolving, and we try as much as possible to keep the book up to date with new additions. However, we might miss some details sometimes, so if you see something weird, let us know! We also gladly accept Pull Requests üòÑ&lt;/p&gt; 
  &lt;/blockquote&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt; Examples üôè &lt;/summary&gt; 
  &lt;br /&gt; 
  &lt;p&gt;Let's start with a code snippet that shows how intuitive the framework is to use! In the following, we declare a neural network module with some parameters along with its forward pass.&lt;/p&gt; 
  &lt;pre&gt;&lt;code class="language-rust"&gt;use burn::nn;
use burn::module::Module;
use burn::tensor::backend::Backend;

#[derive(Module, Debug)]
pub struct PositionWiseFeedForward&amp;lt;B: Backend&amp;gt; {
    linear_inner: nn::Linear&amp;lt;B&amp;gt;,
    linear_outer: nn::Linear&amp;lt;B&amp;gt;,
    dropout: nn::Dropout,
    gelu: nn::Gelu,
}

impl&amp;lt;B: Backend&amp;gt; PositionWiseFeedForward&amp;lt;B&amp;gt; {
    pub fn forward&amp;lt;const D: usize&amp;gt;(&amp;amp;self, input: Tensor&amp;lt;B, D&amp;gt;) -&amp;gt; Tensor&amp;lt;B, D&amp;gt; {
        let x = self.linear_inner.forward(input);
        let x = self.gelu.forward(x);
        let x = self.dropout.forward(x);

        self.linear_outer.forward(x)
    }
}
&lt;/code&gt;&lt;/pre&gt; 
  &lt;p&gt;We have a somewhat large amount of &lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples"&gt;examples&lt;/a&gt; in the repository that shows how to use the framework in different scenarios.&lt;/p&gt; 
  &lt;p&gt;Following &lt;a href="https://burn.dev/books/burn/"&gt;the book&lt;/a&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/guide"&gt;Basic Workflow&lt;/a&gt; : Creates a custom CNN &lt;code&gt;Module&lt;/code&gt; to train on the MNIST dataset and use for inference.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/custom-training-loop"&gt;Custom Training Loop&lt;/a&gt; : Implements a basic training loop instead of using the &lt;code&gt;Learner&lt;/code&gt;.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/custom-wgpu-kernel"&gt;Custom WGPU Kernel&lt;/a&gt; : Learn how to create your own custom operation with the WGPU backend.&lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;p&gt;Additional examples:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/custom-csv-dataset"&gt;Custom CSV Dataset&lt;/a&gt; : Implements a dataset to parse CSV data for a regression task.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/simple-regression"&gt;Regression&lt;/a&gt; : Trains a simple MLP on the California Housing dataset to predict the median house value for a district.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/custom-image-dataset"&gt;Custom Image Dataset&lt;/a&gt; : Trains a simple CNN on custom image dataset following a simple folder structure.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/custom-renderer"&gt;Custom Renderer&lt;/a&gt; : Implements a custom renderer to display the &lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/building-blocks/learner.md"&gt;&lt;code&gt;Learner&lt;/code&gt;&lt;/a&gt; progress.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/image-classification-web"&gt;Image Classification Web&lt;/a&gt; : Image classification web browser demo using Burn, WGPU and WebAssembly.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/mnist-inference-web"&gt;MNIST Inference on Web&lt;/a&gt; : An interactive MNIST inference demo in the browser. The demo is available &lt;a href="https://burn.dev/demo/"&gt;online&lt;/a&gt;.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/mnist"&gt;MNIST Training&lt;/a&gt; : Demonstrates how to train a custom &lt;code&gt;Module&lt;/code&gt; (MLP) with the &lt;code&gt;Learner&lt;/code&gt; configured to log metrics and keep training checkpoints.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/named-tensor"&gt;Named Tensor&lt;/a&gt; : Performs operations with the experimental &lt;code&gt;NamedTensor&lt;/code&gt; feature.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/onnx-inference"&gt;ONNX Import Inference&lt;/a&gt; : Imports an ONNX model pre-trained on MNIST to perform inference on a sample image with Burn.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/import-model-weights"&gt;PyTorch Import Inference&lt;/a&gt; : Imports a PyTorch model pre-trained on MNIST to perform inference on a sample image with Burn.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/text-classification"&gt;Text Classification&lt;/a&gt; : Trains a text classification transformer model on the AG News or DbPedia dataset. The trained model can then be used to classify a text sample.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/text-generation"&gt;Text Generation&lt;/a&gt; : Trains a text generation transformer model on the DbPedia dataset.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/wgan"&gt;Wasserstein GAN MNIST&lt;/a&gt; : Trains a WGAN model to generate new handwritten digits based on MNIST.&lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;p&gt;For more practical insights, you can clone the repository and run any of them directly on your computer!&lt;/p&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt; Pre-trained Models ü§ñ &lt;/summary&gt; 
  &lt;br /&gt; 
  &lt;p&gt;We keep an updated and curated list of models and examples built with Burn, see the &lt;a href="https://github.com/tracel-ai/models"&gt;tracel-ai/models repository&lt;/a&gt; for more details.&lt;/p&gt; 
  &lt;p&gt;Don't see the model you want? Don't hesitate to open an issue, and we may prioritize it. Built a model using Burn and want to share it? You can also open a Pull Request and add your model under the community section!&lt;/p&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt; Why use Rust for Deep Learning? ü¶Ä &lt;/summary&gt; 
  &lt;br /&gt; 
  &lt;p&gt;Deep Learning is a special form of software where you need very high level abstractions as well as extremely fast execution time. Rust is the perfect candidate for that use case since it provides zero-cost abstractions to easily create neural network modules, and fine-grained control over memory to optimize every detail.&lt;/p&gt; 
  &lt;p&gt;It's important that a framework be easy to use at a high level so that its users can focus on innovating in the AI field. However, since running models relies so heavily on computations, performance can't be neglected.&lt;/p&gt; 
  &lt;p&gt;To this day, the mainstream solution to this problem has been to offer APIs in Python, but rely on bindings to low-level languages such as C/C++. This reduces portability, increases complexity and creates frictions between researchers and engineers. We feel like Rust's approach to abstractions makes it versatile enough to tackle this two languages dichotomy.&lt;/p&gt; 
  &lt;p&gt;Rust also comes with the Cargo package manager, which makes it incredibly easy to build, test, and deploy from any environment, which is usually a pain in Python.&lt;/p&gt; 
  &lt;p&gt;Although Rust has the reputation of being a difficult language at first, we strongly believe it leads to more reliable, bug-free solutions built faster (after some practice üòÖ)!&lt;/p&gt; 
 &lt;/details&gt; 
 &lt;br /&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;&lt;strong&gt;Deprecation Note&lt;/strong&gt;&lt;br /&gt;Since &lt;code&gt;0.14.0&lt;/code&gt;, the internal structure for tensor data has changed. The previous &lt;code&gt;Data&lt;/code&gt; struct was deprecated and officially removed since &lt;code&gt;0.17.0&lt;/code&gt; in favor of the new &lt;code&gt;TensorData&lt;/code&gt; struct, which allows for more flexibility by storing the underlying data as bytes and keeping the data type as a field. If you are using &lt;code&gt;Data&lt;/code&gt; in your code, make sure to switch to &lt;code&gt;TensorData&lt;/code&gt;.&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;!-- &gt;
&gt; In the event that you are trying to load a model record saved in a previous version, make sure to
&gt; enable the `record-backward-compat` feature using a previous version of burn (&lt;=0.16.0). Otherwise,
&gt; the record won't be deserialized correctly and you will get an error message (which will also point
&gt; you to the backward compatible feature flag). The backward compatibility was maintained for
&gt; deserialization (loading), so as soon as you have saved the record again it will be saved according
&gt; to the new structure and you will be able to upgrade to this version. Please note that binary formats
&gt; are not backward compatible. Thus, you will need to load your record in a previous version and save it
&gt; to another of the self-describing record formats before using a compatible version (as described) with the
&gt; `record-backward-compat` feature flag. --&gt; 
 &lt;details id="deprecation"&gt; 
  &lt;summary&gt; Loading Model Records From Previous Versions ‚ö†Ô∏è &lt;/summary&gt; 
  &lt;br /&gt; 
  &lt;p&gt;In the event that you are trying to load a model record saved in a version older than &lt;code&gt;0.14.0&lt;/code&gt;, make sure to use a compatible version (&lt;code&gt;0.14&lt;/code&gt;, &lt;code&gt;0.15&lt;/code&gt; or &lt;code&gt;0.16&lt;/code&gt;) with the &lt;code&gt;record-backward-compat&lt;/code&gt; feature flag.&lt;/p&gt; 
  &lt;pre&gt;&lt;code&gt;features = [..., "record-backward-compat"]
&lt;/code&gt;&lt;/pre&gt; 
  &lt;p&gt;Otherwise, the record won't be deserialized correctly and you will get an error message. This error will also point you to the backward compatible feature flag.&lt;/p&gt; 
  &lt;p&gt;The backward compatibility was maintained for deserialization when loading records. Therefore, as soon as you have saved the record again it will be saved according to the new structure and you can upgrade back to the current version&lt;/p&gt; 
  &lt;p&gt;Please note that binary formats are not backward compatible. Thus, you will need to load your record in a previous version and save it in any of the other self-describing record format (e.g., using the &lt;code&gt;NamedMpkFileRecorder&lt;/code&gt;) before using a compatible version (as described) with the &lt;code&gt;record-backward-compat&lt;/code&gt; feature flag.&lt;/p&gt; 
 &lt;/details&gt; 
 &lt;h2&gt;Community&lt;/h2&gt; 
 &lt;div align="left"&gt; 
  &lt;img align="right" src="https://raw.githubusercontent.com/tracel-ai/burn/main/assets/ember-community.png" height="96px" /&gt; 
  &lt;p&gt;If you are excited about the project, don't hesitate to join our &lt;a href="https://discord.gg/uPEBbYYDB6"&gt;Discord&lt;/a&gt;! We try to be as welcoming as possible to everybody from any background. You can ask your questions and share what you built with the community!&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;br /&gt; 
 &lt;p&gt;&lt;strong&gt;Contributing&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;Before contributing, please take a moment to review our &lt;a href="https://github.com/tracel-ai/burn/tree/main/CODE-OF-CONDUCT.md"&gt;code of conduct&lt;/a&gt;. It's also highly recommended to read the &lt;a href="https://github.com/tracel-ai/burn/tree/main/contributor-book/src/project-architecture"&gt;architecture overview&lt;/a&gt;, which explains some of our architectural decisions. Refer to our &lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/CONTRIBUTING.md"&gt;contributing guide&lt;/a&gt; for more details.&lt;/p&gt; 
 &lt;h2&gt;Status&lt;/h2&gt; 
 &lt;p&gt;Burn is currently in active development, and there will be breaking changes. While any resulting issues are likely to be easy to fix, there are no guarantees at this stage.&lt;/p&gt; 
 &lt;h2&gt;License&lt;/h2&gt; 
 &lt;p&gt;Burn is distributed under the terms of both the MIT license and the Apache License (Version 2.0). See &lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/LICENSE-APACHE"&gt;LICENSE-APACHE&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/LICENSE-MIT"&gt;LICENSE-MIT&lt;/a&gt; for details. Opening a pull request is assumed to signal agreement with these licensing terms.&lt;/p&gt; 
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>farion1231/cc-switch</title>
      <link>https://github.com/farion1231/cc-switch</link>
      <description>&lt;p&gt;A cross-platform desktop All-in-One assistant tool for Claude Code, Codex, OpenCode &amp; Gemini CLI.&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;h1&gt;All-in-One Assistant for Claude Code, Codex &amp;amp; Gemini CLI&lt;/h1&gt; 
 &lt;p&gt;&lt;a href="https://github.com/farion1231/cc-switch/releases"&gt;&lt;img src="https://img.shields.io/badge/version-3.10.2-blue.svg?sanitize=true" alt="Version" /&gt;&lt;/a&gt; &lt;a href="https://github.com/farion1231/cc-switch/releases"&gt;&lt;img src="https://img.shields.io/badge/platform-Windows%20%7C%20macOS%20%7C%20Linux-lightgrey.svg?sanitize=true" alt="Platform" /&gt;&lt;/a&gt; &lt;a href="https://tauri.app/"&gt;&lt;img src="https://img.shields.io/badge/built%20with-Tauri%202-orange.svg?sanitize=true" alt="Built with Tauri" /&gt;&lt;/a&gt; &lt;a href="https://github.com/farion1231/cc-switch/releases/latest"&gt;&lt;img src="https://img.shields.io/endpoint?url=https://api.pinstudios.net/api/badges/downloads/farion1231/cc-switch/total" alt="Downloads" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://trendshift.io/repositories/15372" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/15372" alt="farion1231%2Fcc-switch | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;English | &lt;a href="https://raw.githubusercontent.com/farion1231/cc-switch/main/README_ZH.md"&gt;‰∏≠Êñá&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/farion1231/cc-switch/main/README_JA.md"&gt;Êó•Êú¨Ë™û&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/farion1231/cc-switch/main/CHANGELOG.md"&gt;Changelog&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;‚ù§Ô∏èSponsor&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://z.ai/subscribe?ic=8JVLJQFSKB"&gt;&lt;img src="https://raw.githubusercontent.com/farion1231/cc-switch/main/assets/partners/banners/glm-en.jpg" alt="Zhipu GLM" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;This project is sponsored by Z.ai, supporting us with their GLM CODING PLAN.GLM CODING PLAN is a subscription service designed for AI coding, starting at just $3/month. It provides access to their flagship GLM-4.6 model across 10+ popular AI coding tools (Claude Code, Cline, Roo Code, etc.), offering developers top-tier, fast, and stable coding experiences.Get 10% OFF the GLM CODING PLAN with &lt;a href="https://z.ai/subscribe?ic=8JVLJQFSKB"&gt;this link&lt;/a&gt;!&lt;/p&gt; 
&lt;hr /&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td width="180"&gt;&lt;a href="https://www.packyapi.com/register?aff=cc-switch"&gt;&lt;img src="https://raw.githubusercontent.com/farion1231/cc-switch/main/assets/partners/logos/packycode.png" alt="PackyCode" width="150" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Thanks to PackyCode for sponsoring this project! PackyCode is a reliable and efficient API relay service provider, offering relay services for Claude Code, Codex, Gemini, and more. PackyCode provides special discounts for our software users: register using &lt;a href="https://www.packyapi.com/register?aff=cc-switch"&gt;this link&lt;/a&gt; and enter the "cc-switch" promo code during recharge to get 10% off.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="180"&gt;&lt;a href="https://aigocode.com/invite/CC-SWITCH"&gt;&lt;img src="https://raw.githubusercontent.com/farion1231/cc-switch/main/assets/partners/logos/aigocode.png" alt="AIGoCode" width="150" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Thanks to AIGoCode for sponsoring this project! AIGoCode is an all-in-one platform that integrates Claude Code, Codex, and the latest Gemini models, providing you with stable, efficient, and highly cost-effective AI coding services. The platform offers flexible subscription plans, zero risk of account suspension, direct access with no VPN required, and lightning-fast responses. AIGoCode has prepared a special benefit for CC Switch users: if you register via &lt;a href="https://aigocode.com/invite/CC-SWITCH"&gt;this link&lt;/a&gt;, you'll receive an extra 10% bonus credit on your first top-up!&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="180"&gt;&lt;a href="https://www.dmxapi.cn/register?aff=bUHu"&gt;&lt;img src="https://raw.githubusercontent.com/farion1231/cc-switch/main/assets/partners/logos/dmx-en.jpg" alt="DMXAPI" width="150" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Thanks to DMXAPI for sponsoring this project! DMXAPI provides global large model API services to 200+ enterprise users. One API key for all global models. Features include: instant invoicing, unlimited concurrency, starting from $0.15, 24/7 technical support. GPT/Claude/Gemini all at 32% off, domestic models 20-50% off, Claude Code exclusive models at 66% off! &lt;a href="https://www.dmxapi.cn/register?aff=bUHu"&gt;Register here&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="180"&gt;&lt;a href="https://cubence.com/signup?code=CCSWITCH&amp;amp;source=ccs"&gt;&lt;img src="https://raw.githubusercontent.com/farion1231/cc-switch/main/assets/partners/logos/cubence.png" alt="Cubence" width="150" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Thanks to Cubence for sponsoring this project! Cubence is a reliable and efficient API relay service provider, offering relay services for Claude Code, Codex, Gemini, and more with flexible billing options including pay-as-you-go and monthly plans. Cubence provides special discounts for CC Switch users: register using &lt;a href="https://cubence.com/signup?code=CCSWITCH&amp;amp;source=ccs"&gt;this link&lt;/a&gt; and enter the "CCSWITCH" promo code during recharge to get 10% off every top-up!&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h2&gt;Screenshots&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="center"&gt;Main Interface&lt;/th&gt; 
   &lt;th align="center"&gt;Add Provider&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;img src="https://raw.githubusercontent.com/farion1231/cc-switch/main/assets/screenshots/main-en.png" alt="Main Interface" /&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;img src="https://raw.githubusercontent.com/farion1231/cc-switch/main/assets/screenshots/add-en.png" alt="Add Provider" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;h3&gt;Current Version: v3.10.2 | &lt;a href="https://raw.githubusercontent.com/farion1231/cc-switch/main/CHANGELOG.md"&gt;Full Changelog&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/farion1231/cc-switch/main/docs/release-note-v3.9.0-en.md"&gt;Release Notes&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;v3.8.0 Major Update (2025-11-28)&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Persistence Architecture Upgrade &amp;amp; Brand New UI&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;SQLite + JSON Dual-layer Architecture&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Migrated from JSON file storage to SQLite + JSON dual-layer structure&lt;/li&gt; 
   &lt;li&gt;Syncable data (providers, MCP, Prompts, Skills) stored in SQLite&lt;/li&gt; 
   &lt;li&gt;Device-level data (window state, local paths) stored in JSON&lt;/li&gt; 
   &lt;li&gt;Lays the foundation for future cloud sync functionality&lt;/li&gt; 
   &lt;li&gt;Schema version management for database migrations&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Brand New User Interface&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Completely redesigned interface layout&lt;/li&gt; 
   &lt;li&gt;Unified component styles and smoother animations&lt;/li&gt; 
   &lt;li&gt;Optimized visual hierarchy&lt;/li&gt; 
   &lt;li&gt;Tailwind CSS downgraded from v4 to v3.4 for better browser compatibility&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Japanese Language Support&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Added Japanese interface support (now supports Chinese/English/Japanese)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Auto Launch on Startup&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;One-click enable/disable in settings&lt;/li&gt; 
   &lt;li&gt;Platform-native APIs (Registry/LaunchAgent/XDG autostart)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Skills Recursive Scanning&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Support for multi-level directory structures&lt;/li&gt; 
   &lt;li&gt;Allow same-named skills from different repositories&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Critical Bug Fixes&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Fixed custom endpoints lost when updating providers&lt;/li&gt; 
   &lt;li&gt;Fixed Gemini configuration write issues&lt;/li&gt; 
   &lt;li&gt;Fixed Linux WebKitGTK rendering issues&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;v3.7.0 Highlights&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Six Core Features, 18,000+ Lines of New Code&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Gemini CLI Integration&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Third supported AI CLI (Claude Code / Codex / Gemini)&lt;/li&gt; 
   &lt;li&gt;Dual-file configuration support (&lt;code&gt;.env&lt;/code&gt; + &lt;code&gt;settings.json&lt;/code&gt;)&lt;/li&gt; 
   &lt;li&gt;Complete MCP server management&lt;/li&gt; 
   &lt;li&gt;Presets: Google Official (OAuth) / PackyCode / Custom&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Claude Skills Management System&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Auto-scan skills from GitHub repositories (3 pre-configured curated repos)&lt;/li&gt; 
   &lt;li&gt;One-click install/uninstall to &lt;code&gt;~/.claude/skills/&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;Custom repository support + subdirectory scanning&lt;/li&gt; 
   &lt;li&gt;Complete lifecycle management (discover/install/update)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Prompts Management System&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Multi-preset system prompt management (unlimited presets, quick switching)&lt;/li&gt; 
   &lt;li&gt;Cross-app support (Claude: &lt;code&gt;CLAUDE.md&lt;/code&gt; / Codex: &lt;code&gt;AGENTS.md&lt;/code&gt; / Gemini: &lt;code&gt;GEMINI.md&lt;/code&gt;)&lt;/li&gt; 
   &lt;li&gt;Markdown editor (CodeMirror 6 + real-time preview)&lt;/li&gt; 
   &lt;li&gt;Smart backfill protection, preserves manual modifications&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;MCP v3.7.0 Unified Architecture&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Single panel manages MCP servers across three applications&lt;/li&gt; 
   &lt;li&gt;New SSE (Server-Sent Events) transport type&lt;/li&gt; 
   &lt;li&gt;Smart JSON parser + Codex TOML format auto-correction&lt;/li&gt; 
   &lt;li&gt;Unified import/export + bidirectional sync&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Deep Link Protocol&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;ccswitch://&lt;/code&gt; protocol registration (all platforms)&lt;/li&gt; 
   &lt;li&gt;One-click import provider configs via shared links&lt;/li&gt; 
   &lt;li&gt;Security validation + lifecycle integration&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Environment Variable Conflict Detection&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Auto-detect cross-app configuration conflicts (Claude/Codex/Gemini/MCP)&lt;/li&gt; 
   &lt;li&gt;Visual conflict indicators + resolution suggestions&lt;/li&gt; 
   &lt;li&gt;Override warnings + backup before changes&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Core Capabilities&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Provider Management&lt;/strong&gt;: One-click switching between Claude Code, Codex, and Gemini API configurations&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Speed Testing&lt;/strong&gt;: Measure API endpoint latency with visual quality indicators&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Import/Export&lt;/strong&gt;: Backup and restore configs with auto-rotation (keep 10 most recent)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;i18n Support&lt;/strong&gt;: Complete Chinese/English localization (UI, errors, tray)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Claude Plugin Sync&lt;/strong&gt;: One-click apply/restore Claude plugin configurations&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;v3.6 Highlights&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Provider duplication &amp;amp; drag-and-drop sorting&lt;/li&gt; 
 &lt;li&gt;Multi-endpoint management &amp;amp; custom config directory (cloud sync ready)&lt;/li&gt; 
 &lt;li&gt;Granular model configuration (4-tier: Haiku/Sonnet/Opus/Custom)&lt;/li&gt; 
 &lt;li&gt;WSL environment support with auto-sync on directory change&lt;/li&gt; 
 &lt;li&gt;100% hooks test coverage &amp;amp; complete architecture refactoring&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;System Features&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;System tray with quick switching&lt;/li&gt; 
 &lt;li&gt;Single instance daemon&lt;/li&gt; 
 &lt;li&gt;Built-in auto-updater&lt;/li&gt; 
 &lt;li&gt;Atomic writes with rollback protection&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Download &amp;amp; Installation&lt;/h2&gt; 
&lt;h3&gt;System Requirements&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Windows&lt;/strong&gt;: Windows 10 and above&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;macOS&lt;/strong&gt;: macOS 10.15 (Catalina) and above&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Linux&lt;/strong&gt;: Ubuntu 22.04+ / Debian 11+ / Fedora 34+ and other mainstream distributions&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Windows Users&lt;/h3&gt; 
&lt;p&gt;Download the latest &lt;code&gt;CC-Switch-v{version}-Windows.msi&lt;/code&gt; installer or &lt;code&gt;CC-Switch-v{version}-Windows-Portable.zip&lt;/code&gt; portable version from the &lt;a href="https://raw.githubusercontent.com/farion1231/releases"&gt;Releases&lt;/a&gt; page.&lt;/p&gt; 
&lt;h3&gt;macOS Users&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Method 1: Install via Homebrew (Recommended)&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;brew tap farion1231/ccswitch
brew install --cask cc-switch
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Update:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;brew upgrade --cask cc-switch
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Method 2: Manual Download&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Download &lt;code&gt;CC-Switch-v{version}-macOS.zip&lt;/code&gt; from the &lt;a href="https://raw.githubusercontent.com/farion1231/releases"&gt;Releases&lt;/a&gt; page and extract to use.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: Since the author doesn't have an Apple Developer account, you may see an "unidentified developer" warning on first launch. Please close it first, then go to "System Settings" ‚Üí "Privacy &amp;amp; Security" ‚Üí click "Open Anyway", and you'll be able to open it normally afterwards.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Arch Linux Users&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Install via paru (Recommended)&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;paru -S cc-switch-bin
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Linux Users&lt;/h3&gt; 
&lt;p&gt;Download the latest Linux build from the &lt;a href="https://raw.githubusercontent.com/farion1231/releases"&gt;Releases&lt;/a&gt; page:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;CC-Switch-v{version}-Linux.deb&lt;/code&gt; (Debian/Ubuntu)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;CC-Switch-v{version}-Linux.rpm&lt;/code&gt; (Fedora/RHEL/openSUSE)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;CC-Switch-v{version}-Linux.AppImage&lt;/code&gt; (Universal)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;CC-Switch-v{version}-Linux.flatpak&lt;/code&gt; (Flatpak)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Flatpak install &amp;amp; run:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;flatpak install --user ./CC-Switch-v{version}-Linux.flatpak
flatpak run com.ccswitch.desktop
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;h3&gt;Basic Usage&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Add Provider&lt;/strong&gt;: Click "Add Provider" ‚Üí Choose preset or create custom configuration&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Switch Provider&lt;/strong&gt;: 
  &lt;ul&gt; 
   &lt;li&gt;Main UI: Select provider ‚Üí Click "Enable"&lt;/li&gt; 
   &lt;li&gt;System Tray: Click provider name directly (instant effect)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Takes Effect&lt;/strong&gt;: Restart your terminal or Claude Code / Codex / Gemini clients to apply changes&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Back to Official&lt;/strong&gt;: Select the "Official Login" preset (Claude/Codex) or "Google Official" preset (Gemini), restart the corresponding client, then follow its login/OAuth flow&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;MCP Management&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Location&lt;/strong&gt;: Click "MCP" button in top-right corner&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Add Server&lt;/strong&gt;: 
  &lt;ul&gt; 
   &lt;li&gt;Use built-in templates (mcp-fetch, mcp-filesystem, etc.)&lt;/li&gt; 
   &lt;li&gt;Support stdio / http / sse transport types&lt;/li&gt; 
   &lt;li&gt;Configure independent MCP servers for different apps&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Enable/Disable&lt;/strong&gt;: Toggle switches to control which servers sync to live config&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Sync&lt;/strong&gt;: Enabled servers auto-sync to each app's live files&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Import/Export&lt;/strong&gt;: Import existing MCP servers from Claude/Codex/Gemini config files&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Skills Management (v3.7.0 New)&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Location&lt;/strong&gt;: Click "Skills" button in top-right corner&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Discover Skills&lt;/strong&gt;: 
  &lt;ul&gt; 
   &lt;li&gt;Auto-scan pre-configured GitHub repositories (Anthropic official, ComposioHQ, community, etc.)&lt;/li&gt; 
   &lt;li&gt;Add custom repositories (supports subdirectory scanning)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Install Skills&lt;/strong&gt;: Click "Install" to one-click install to &lt;code&gt;~/.claude/skills/&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Uninstall Skills&lt;/strong&gt;: Click "Uninstall" to safely remove and clean up state&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Manage Repositories&lt;/strong&gt;: Add/remove custom GitHub repositories&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Prompts Management (v3.7.0 New)&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Location&lt;/strong&gt;: Click "Prompts" button in top-right corner&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Create Presets&lt;/strong&gt;: 
  &lt;ul&gt; 
   &lt;li&gt;Create unlimited system prompt presets&lt;/li&gt; 
   &lt;li&gt;Use Markdown editor to write prompts (syntax highlighting + real-time preview)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Switch Presets&lt;/strong&gt;: Select preset ‚Üí Click "Activate" to apply immediately&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Sync Mechanism&lt;/strong&gt;: 
  &lt;ul&gt; 
   &lt;li&gt;Claude: &lt;code&gt;~/.claude/CLAUDE.md&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;Codex: &lt;code&gt;~/.codex/AGENTS.md&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;Gemini: &lt;code&gt;~/.gemini/GEMINI.md&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Protection Mechanism&lt;/strong&gt;: Auto-save current prompt content before switching, preserves manual modifications&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Configuration Files&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Claude Code&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Live config: &lt;code&gt;~/.claude/settings.json&lt;/code&gt; (or &lt;code&gt;claude.json&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;API key field: &lt;code&gt;env.ANTHROPIC_AUTH_TOKEN&lt;/code&gt; or &lt;code&gt;env.ANTHROPIC_API_KEY&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;MCP servers: &lt;code&gt;~/.claude.json&lt;/code&gt; ‚Üí &lt;code&gt;mcpServers&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Codex&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Live config: &lt;code&gt;~/.codex/auth.json&lt;/code&gt; (required) + &lt;code&gt;config.toml&lt;/code&gt; (optional)&lt;/li&gt; 
 &lt;li&gt;API key field: &lt;code&gt;OPENAI_API_KEY&lt;/code&gt; in &lt;code&gt;auth.json&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;MCP servers: &lt;code&gt;~/.codex/config.toml&lt;/code&gt; ‚Üí &lt;code&gt;[mcp_servers]&lt;/code&gt; tables&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Gemini&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Live config: &lt;code&gt;~/.gemini/.env&lt;/code&gt; (API key) + &lt;code&gt;~/.gemini/settings.json&lt;/code&gt; (auth mode)&lt;/li&gt; 
 &lt;li&gt;API key field: &lt;code&gt;GEMINI_API_KEY&lt;/code&gt; or &lt;code&gt;GOOGLE_GEMINI_API_KEY&lt;/code&gt; in &lt;code&gt;.env&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Environment variables: Support &lt;code&gt;GOOGLE_GEMINI_BASE_URL&lt;/code&gt;, &lt;code&gt;GEMINI_MODEL&lt;/code&gt;, etc.&lt;/li&gt; 
 &lt;li&gt;MCP servers: &lt;code&gt;~/.gemini/settings.json&lt;/code&gt; ‚Üí &lt;code&gt;mcpServers&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Tray quick switch: Each provider switch rewrites &lt;code&gt;~/.gemini/.env&lt;/code&gt;, no need to restart Gemini CLI&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;CC Switch Storage (v3.8.0 New Architecture)&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Database (SSOT): &lt;code&gt;~/.cc-switch/cc-switch.db&lt;/code&gt; (SQLite, stores providers, MCP, Prompts, Skills)&lt;/li&gt; 
 &lt;li&gt;Local settings: &lt;code&gt;~/.cc-switch/settings.json&lt;/code&gt; (device-level settings)&lt;/li&gt; 
 &lt;li&gt;Backups: &lt;code&gt;~/.cc-switch/backups/&lt;/code&gt; (auto-rotate, keep 10)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Cloud Sync Setup&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Go to Settings ‚Üí "Custom Configuration Directory"&lt;/li&gt; 
 &lt;li&gt;Choose your cloud sync folder (Dropbox, OneDrive, iCloud, etc.)&lt;/li&gt; 
 &lt;li&gt;Restart app to apply&lt;/li&gt; 
 &lt;li&gt;Repeat on other devices to enable cross-device sync&lt;/li&gt; 
&lt;/ol&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: First launch auto-imports existing Claude/Codex configs as default provider.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Architecture Overview&lt;/h2&gt; 
&lt;h3&gt;Design Principles&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    Frontend (React + TS)                    ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ Components  ‚îÇ  ‚îÇ    Hooks     ‚îÇ  ‚îÇ  TanStack Query  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ   (UI)      ‚îÇ‚îÄ‚îÄ‚îÇ (Bus. Logic) ‚îÇ‚îÄ‚îÄ‚îÇ   (Cache/Sync)   ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ Tauri IPC
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                  Backend (Tauri + Rust)                     ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ  Commands   ‚îÇ  ‚îÇ   Services   ‚îÇ  ‚îÇ  Models/Config   ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ (API Layer) ‚îÇ‚îÄ‚îÄ‚îÇ (Bus. Layer) ‚îÇ‚îÄ‚îÄ‚îÇ     (Data)       ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Core Design Patterns&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;SSOT&lt;/strong&gt; (Single Source of Truth): All data stored in &lt;code&gt;~/.cc-switch/cc-switch.db&lt;/code&gt; (SQLite)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Dual-layer Storage&lt;/strong&gt;: SQLite for syncable data, JSON for device-level settings&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Dual-way Sync&lt;/strong&gt;: Write to live files on switch, backfill from live when editing active provider&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Atomic Writes&lt;/strong&gt;: Temp file + rename pattern prevents config corruption&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Concurrency Safe&lt;/strong&gt;: Mutex-protected database connection avoids race conditions&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Layered Architecture&lt;/strong&gt;: Clear separation (Commands ‚Üí Services ‚Üí DAO ‚Üí Database)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Key Components&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;ProviderService&lt;/strong&gt;: Provider CRUD, switching, backfill, sorting&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;McpService&lt;/strong&gt;: MCP server management, import/export, live file sync&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ConfigService&lt;/strong&gt;: Config import/export, backup rotation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;SpeedtestService&lt;/strong&gt;: API endpoint latency measurement&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;v3.6 Refactoring&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Backend: 5-phase refactoring (error handling ‚Üí command split ‚Üí tests ‚Üí services ‚Üí concurrency)&lt;/li&gt; 
 &lt;li&gt;Frontend: 4-stage refactoring (test infra ‚Üí hooks ‚Üí components ‚Üí cleanup)&lt;/li&gt; 
 &lt;li&gt;Testing: 100% hooks coverage + integration tests (vitest + MSW)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Development&lt;/h2&gt; 
&lt;h3&gt;Environment Requirements&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Node.js 18+&lt;/li&gt; 
 &lt;li&gt;pnpm 8+&lt;/li&gt; 
 &lt;li&gt;Rust 1.85+&lt;/li&gt; 
 &lt;li&gt;Tauri CLI 2.8+&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Development Commands&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Install dependencies
pnpm install

# Dev mode (hot reload)
pnpm dev

# Type check
pnpm typecheck

# Format code
pnpm format

# Check code format
pnpm format:check

# Run frontend unit tests
pnpm test:unit

# Run tests in watch mode (recommended for development)
pnpm test:unit:watch

# Build application
pnpm build

# Build debug version
pnpm tauri build --debug
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Rust Backend Development&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd src-tauri

# Format Rust code
cargo fmt

# Run clippy checks
cargo clippy

# Run backend tests
cargo test

# Run specific tests
cargo test test_name

# Run tests with test-hooks feature
cargo test --features test-hooks
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Testing Guide (v3.6 New)&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Frontend Testing&lt;/strong&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Uses &lt;strong&gt;vitest&lt;/strong&gt; as test framework&lt;/li&gt; 
 &lt;li&gt;Uses &lt;strong&gt;MSW (Mock Service Worker)&lt;/strong&gt; to mock Tauri API calls&lt;/li&gt; 
 &lt;li&gt;Uses &lt;strong&gt;@testing-library/react&lt;/strong&gt; for component testing&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Test Coverage&lt;/strong&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Hooks unit tests (100% coverage) 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;useProviderActions&lt;/code&gt; - Provider operations&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;useMcpActions&lt;/code&gt; - MCP management&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;useSettings&lt;/code&gt; series - Settings management&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;useImportExport&lt;/code&gt; - Import/export&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Integration tests 
  &lt;ul&gt; 
   &lt;li&gt;App main application flow&lt;/li&gt; 
   &lt;li&gt;SettingsDialog complete interaction&lt;/li&gt; 
   &lt;li&gt;MCP panel functionality&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Running Tests&lt;/strong&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Run all tests
pnpm test:unit

# Watch mode (auto re-run)
pnpm test:unit:watch

# With coverage report
pnpm test:unit --coverage
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Tech Stack&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Frontend&lt;/strong&gt;: React 18 ¬∑ TypeScript ¬∑ Vite ¬∑ TailwindCSS 4 ¬∑ TanStack Query v5 ¬∑ react-i18next ¬∑ react-hook-form ¬∑ zod ¬∑ shadcn/ui ¬∑ @dnd-kit&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Backend&lt;/strong&gt;: Tauri 2.8 ¬∑ Rust ¬∑ serde ¬∑ tokio ¬∑ thiserror ¬∑ tauri-plugin-updater/process/dialog/store/log&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Testing&lt;/strong&gt;: vitest ¬∑ MSW ¬∑ @testing-library/react&lt;/p&gt; 
&lt;h2&gt;Project Structure&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;‚îú‚îÄ‚îÄ src/                      # Frontend (React + TypeScript)
‚îÇ   ‚îú‚îÄ‚îÄ components/           # UI components (providers/settings/mcp/ui)
‚îÇ   ‚îú‚îÄ‚îÄ hooks/                # Custom hooks (business logic)
‚îÇ   ‚îú‚îÄ‚îÄ lib/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ api/              # Tauri API wrapper (type-safe)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ query/            # TanStack Query config
‚îÇ   ‚îú‚îÄ‚îÄ i18n/locales/         # Translations (zh/en)
‚îÇ   ‚îú‚îÄ‚îÄ config/               # Presets (providers/mcp)
‚îÇ   ‚îî‚îÄ‚îÄ types/                # TypeScript definitions
‚îú‚îÄ‚îÄ src-tauri/                # Backend (Rust)
‚îÇ   ‚îî‚îÄ‚îÄ src/
‚îÇ       ‚îú‚îÄ‚îÄ commands/         # Tauri command layer (by domain)
‚îÇ       ‚îú‚îÄ‚îÄ services/         # Business logic layer
‚îÇ       ‚îú‚îÄ‚îÄ app_config.rs     # Config data models
‚îÇ       ‚îú‚îÄ‚îÄ provider.rs       # Provider domain models
‚îÇ       ‚îú‚îÄ‚îÄ mcp.rs            # MCP sync &amp;amp; validation
‚îÇ       ‚îî‚îÄ‚îÄ lib.rs            # App entry &amp;amp; tray menu
‚îú‚îÄ‚îÄ tests/                    # Frontend tests
‚îÇ   ‚îú‚îÄ‚îÄ hooks/                # Unit tests
‚îÇ   ‚îî‚îÄ‚îÄ components/           # Integration tests
‚îî‚îÄ‚îÄ assets/                   # Screenshots &amp;amp; partner resources
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Changelog&lt;/h2&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/farion1231/cc-switch/main/CHANGELOG.md"&gt;CHANGELOG.md&lt;/a&gt; for version update details.&lt;/p&gt; 
&lt;h2&gt;Legacy Electron Version&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/farion1231/releases"&gt;Releases&lt;/a&gt; retains v2.0.3 legacy Electron version&lt;/p&gt; 
&lt;p&gt;If you need legacy Electron code, you can pull the electron-legacy branch&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Issues and suggestions are welcome!&lt;/p&gt; 
&lt;p&gt;Before submitting PRs, please ensure:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Pass type check: &lt;code&gt;pnpm typecheck&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Pass format check: &lt;code&gt;pnpm format:check&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Pass unit tests: &lt;code&gt;pnpm test:unit&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;üí° For new features, please open an issue for discussion before submitting a PR&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Star History&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://www.star-history.com/#farion1231/cc-switch&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=farion1231/cc-switch&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;MIT ¬© Jason Young&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>