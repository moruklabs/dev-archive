<rss version="2.0">
  <channel>
    <title>GitHub TypeScript Daily Trending</title>
    <description>Daily Trending of TypeScript in GitHub</description>
    <pubDate>Mon, 26 Jan 2026 01:43:55 GMT</pubDate>
    <link>http://mshibanami.github.io/GitHubTrendingRSS</link>
    
    <item>
      <title>Psiphon-Inc/conduit</title>
      <link>https://github.com/Psiphon-Inc/conduit</link>
      <description>&lt;p&gt;Conduit Client&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Conduit App&lt;/h1&gt; 
&lt;p&gt;Conduit runs inproxy from &lt;a href="https://github.com/Psiphon-Labs/psiphon-tunnel-core"&gt;psiphon-tunnel-core&lt;/a&gt; in a mobile app. This repository targets Android, iOS and Mac (via Catalyst).&lt;/p&gt; 
&lt;p&gt;For more information about Conduit, &lt;a href="https://conduit.psiphon.ca"&gt;visit the web site&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Git LFS Usage&lt;/h2&gt; 
&lt;p&gt;This project uses &lt;a href="https://git-lfs.github.com/"&gt;Git LFS&lt;/a&gt; to manage large files such as the tunnel core libraries.&lt;/p&gt; 
&lt;h2&gt;Translations&lt;/h2&gt; 
&lt;p&gt;For information about pulling and verifying translations, see &lt;a href="https://raw.githubusercontent.com/Psiphon-Inc/conduit/main/i18n/README.md"&gt;i18n/README.md&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>mlc-ai/web-llm</title>
      <link>https://github.com/mlc-ai/web-llm</link>
      <description>&lt;p&gt;High-performance In-browser LLM Inference Engine&lt;/p&gt;&lt;hr&gt;&lt;div align="center" id="top"&gt; 
 &lt;h1&gt;WebLLM&lt;/h1&gt; 
 &lt;p&gt;&lt;a href="https://www.npmjs.com/package/@mlc-ai/web-llm"&gt;&lt;img src="https://img.shields.io/badge/NPM_Package-Published-cc3534" alt="NPM Package" /&gt;&lt;/a&gt; &lt;a href="https://chat.webllm.ai/"&gt;&lt;img src="https://img.shields.io/badge/WebLLM_Chat-Deployed-%2332a852" alt="&amp;quot;WebLLM Chat Deployed&amp;quot;" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/9Xpy2HGBuD"&gt;&lt;img src="https://img.shields.io/badge/Join-Discord-7289DA?logo=discord&amp;amp;logoColor=white" alt="Join Discord" /&gt;&lt;/a&gt; &lt;a href="https://github.com/mlc-ai/web-llm-chat/"&gt;&lt;img src="https://img.shields.io/badge/Related_Repo-WebLLM_Chat-fafbfc?logo=github" alt="Related Repository: WebLLM Chat" /&gt;&lt;/a&gt; &lt;a href="https://github.com/mlc-ai/mlc-llm/"&gt;&lt;img src="https://img.shields.io/badge/Related_Repo-MLC_LLM-fafbfc?logo=github" alt="Related Repository: MLC LLM" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;High-Performance In-Browser LLM Inference Engine.&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://webllm.mlc.ai/docs/"&gt;Documentation&lt;/a&gt; | &lt;a href="https://blog.mlc.ai/2024/06/13/webllm-a-high-performance-in-browser-llm-inference-engine"&gt;Blogpost&lt;/a&gt; | &lt;a href="https://arxiv.org/abs/2412.15803"&gt;Paper&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/mlc-ai/web-llm/main/examples"&gt;Examples&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;Overview&lt;/h2&gt; 
&lt;p&gt;WebLLM is a high-performance in-browser LLM inference engine that brings language model inference directly onto web browsers with hardware acceleration. Everything runs inside the browser with no server support and is accelerated with WebGPU.&lt;/p&gt; 
&lt;p&gt;WebLLM is &lt;strong&gt;fully compatible with &lt;a href="https://platform.openai.com/docs/api-reference/chat"&gt;OpenAI API&lt;/a&gt;.&lt;/strong&gt; That is, you can use the same OpenAI API on &lt;strong&gt;any open source models&lt;/strong&gt; locally, with functionalities including streaming, JSON-mode, function-calling (WIP), etc.&lt;/p&gt; 
&lt;p&gt;We can bring a lot of fun opportunities to build AI assistants for everyone and enable privacy while enjoying GPU acceleration.&lt;/p&gt; 
&lt;p&gt;You can use WebLLM as a base &lt;a href="https://www.npmjs.com/package/@mlc-ai/web-llm"&gt;npm package&lt;/a&gt; and build your own web application on top of it by following the examples below. This project is a companion project of &lt;a href="https://github.com/mlc-ai/mlc-llm"&gt;MLC LLM&lt;/a&gt;, which enables universal deployment of LLM across hardware environments.&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;strong&gt;&lt;a href="https://chat.webllm.ai/"&gt;Check out WebLLM Chat to try it out!&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;Key Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;In-Browser Inference&lt;/strong&gt;: WebLLM is a high-performance, in-browser language model inference engine that leverages WebGPU for hardware acceleration, enabling powerful LLM operations directly within web browsers without server-side processing.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/mlc-ai/web-llm/main/#full-openai-compatibility"&gt;&lt;strong&gt;Full OpenAI API Compatibility&lt;/strong&gt;&lt;/a&gt;: Seamlessly integrate your app with WebLLM using OpenAI API with functionalities such as streaming, JSON-mode, logit-level control, seeding, and more.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Structured JSON Generation&lt;/strong&gt;: WebLLM supports state-of-the-art JSON mode structured generation, implemented in the WebAssembly portion of the model library for optimal performance. Check &lt;a href="https://huggingface.co/spaces/mlc-ai/WebLLM-JSON-Playground"&gt;WebLLM JSON Playground&lt;/a&gt; on HuggingFace to try generating JSON output with custom JSON schema.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/mlc-ai/web-llm/main/#built-in-models"&gt;&lt;strong&gt;Extensive Model Support&lt;/strong&gt;&lt;/a&gt;: WebLLM natively supports a range of models including Llama 3, Phi 3, Gemma, Mistral, Qwen(ÈÄö‰πâÂçÉÈóÆ), and many others, making it versatile for various AI tasks. For the complete supported model list, check &lt;a href="https://mlc.ai/models"&gt;MLC Models&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/mlc-ai/web-llm/main/#custom-models"&gt;&lt;strong&gt;Custom Model Integration&lt;/strong&gt;&lt;/a&gt;: Easily integrate and deploy custom models in MLC format, allowing you to adapt WebLLM to specific needs and scenarios, enhancing flexibility in model deployment.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Plug-and-Play Integration&lt;/strong&gt;: Easily integrate WebLLM into your projects using package managers like NPM and Yarn, or directly via CDN, complete with comprehensive &lt;a href="https://raw.githubusercontent.com/mlc-ai/web-llm/main/examples/"&gt;examples&lt;/a&gt; and a modular design for connecting with UI components.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Streaming &amp;amp; Real-Time Interactions&lt;/strong&gt;: Supports streaming chat completions, allowing real-time output generation which enhances interactive applications like chatbots and virtual assistants.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Web Worker &amp;amp; Service Worker Support&lt;/strong&gt;: Optimize UI performance and manage the lifecycle of models efficiently by offloading computations to separate worker threads or service workers.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Chrome Extension Support&lt;/strong&gt;: Extend the functionality of web browsers through custom Chrome extensions using WebLLM, with examples available for building both basic and advanced extensions.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Built-in Models&lt;/h2&gt; 
&lt;p&gt;Check the complete list of available models on &lt;a href="https://mlc.ai/models"&gt;MLC Models&lt;/a&gt;. WebLLM supports a subset of these available models and the list can be accessed at &lt;a href="https://github.com/mlc-ai/web-llm/raw/main/src/config.ts#L293"&gt;&lt;code&gt;prebuiltAppConfig.model_list&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Here are the primary families of models currently supported:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Llama&lt;/strong&gt;: Llama 3, Llama 2, Hermes-2-Pro-Llama-3&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Phi&lt;/strong&gt;: Phi 3, Phi 2, Phi 1.5&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Gemma&lt;/strong&gt;: Gemma-2B&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Mistral&lt;/strong&gt;: Mistral-7B-v0.3, Hermes-2-Pro-Mistral-7B, NeuralHermes-2.5-Mistral-7B, OpenHermes-2.5-Mistral-7B&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Qwen (ÈÄö‰πâÂçÉÈóÆ)&lt;/strong&gt;: Qwen2 0.5B, 1.5B, 7B&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;If you need more models, &lt;a href="https://github.com/mlc-ai/web-llm/issues/new/choose"&gt;request a new model via opening an issue&lt;/a&gt; or check &lt;a href="https://raw.githubusercontent.com/mlc-ai/web-llm/main/#custom-models"&gt;Custom Models&lt;/a&gt; for how to compile and use your own models with WebLLM.&lt;/p&gt; 
&lt;h2&gt;Jumpstart with Examples&lt;/h2&gt; 
&lt;p&gt;Learn how to use WebLLM to integrate large language models into your application and generate chat completions through this simple Chatbot example:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://jsfiddle.net/neetnestor/4nmgvsa2/"&gt;&lt;img src="https://img.shields.io/badge/Example-JSFiddle-blue?logo=jsfiddle&amp;amp;logoColor=white" alt="Example Chatbot on JSFiddle" /&gt;&lt;/a&gt; &lt;a href="https://codepen.io/neetnestor/pen/vYwgZaG"&gt;&lt;img src="https://img.shields.io/badge/Example-Codepen-gainsboro?logo=codepen" alt="Example Chatbot on Codepen" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;For an advanced example of a larger, more complicated project, check &lt;a href="https://github.com/mlc-ai/web-llm-chat/raw/main/app/client/webllm.ts"&gt;WebLLM Chat&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;More examples for different use cases are available in the &lt;a href="https://raw.githubusercontent.com/mlc-ai/web-llm/main/examples/"&gt;examples&lt;/a&gt; folder.&lt;/p&gt; 
&lt;h2&gt;Get Started&lt;/h2&gt; 
&lt;p&gt;WebLLM offers a minimalist and modular interface to access the chatbot in the browser. The package is designed in a modular way to hook to any of the UI components.&lt;/p&gt; 
&lt;h3&gt;Installation&lt;/h3&gt; 
&lt;h4&gt;Package Manager&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;# npm
npm install @mlc-ai/web-llm
# yarn
yarn add @mlc-ai/web-llm
# or pnpm
pnpm install @mlc-ai/web-llm
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then import the module in your code.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-typescript"&gt;// Import everything
import * as webllm from "@mlc-ai/web-llm";
// Or only import what you need
import { CreateMLCEngine } from "@mlc-ai/web-llm";
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;CDN Delivery&lt;/h4&gt; 
&lt;p&gt;Thanks to &lt;a href="https://www.jsdelivr.com/package/npm/@mlc-ai/web-llm"&gt;jsdelivr.com&lt;/a&gt;, WebLLM can be imported directly through URL and work out-of-the-box on cloud development platforms like &lt;a href="https://jsfiddle.net/"&gt;jsfiddle.net&lt;/a&gt;, &lt;a href="https://codepen.io/"&gt;Codepen.io&lt;/a&gt;, and &lt;a href="https://scribbler.live"&gt;Scribbler&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-javascript"&gt;import * as webllm from "https://esm.run/@mlc-ai/web-llm";
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;It can also be dynamically imported as:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-javascript"&gt;const webllm = await import ("https://esm.run/@mlc-ai/web-llm");
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Create MLCEngine&lt;/h3&gt; 
&lt;p&gt;Most operations in WebLLM are invoked through the &lt;code&gt;MLCEngine&lt;/code&gt; interface. You can create an &lt;code&gt;MLCEngine&lt;/code&gt; instance and loading the model by calling the &lt;code&gt;CreateMLCEngine()&lt;/code&gt; factory function.&lt;/p&gt; 
&lt;p&gt;(Note that loading models requires downloading and it can take a significant amount of time for the very first run without caching previously. You should properly handle this asynchronous call.)&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-typescript"&gt;import { CreateMLCEngine } from "@mlc-ai/web-llm";

// Callback function to update model loading progress
const initProgressCallback = (initProgress) =&amp;gt; {
  console.log(initProgress);
}
const selectedModel = "Llama-3.1-8B-Instruct-q4f32_1-MLC";

const engine = await CreateMLCEngine(
  selectedModel,
  { initProgressCallback: initProgressCallback }, // engineConfig
);
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Under the hood, this factory function does the following steps for first creating an engine instance (synchronous) and then loading the model (asynchronous). You can also do them separately in your application.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-typescript"&gt;import { MLCEngine } from "@mlc-ai/web-llm";

// This is a synchronous call that returns immediately
const engine = new MLCEngine({
  initProgressCallback: initProgressCallback
});

// This is an asynchronous call and can take a long time to finish
await engine.reload(selectedModel);
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Chat Completion&lt;/h3&gt; 
&lt;p&gt;After successfully initializing the engine, you can now invoke chat completions using OpenAI style chat APIs through the &lt;code&gt;engine.chat.completions&lt;/code&gt; interface. For the full list of parameters and their descriptions, check &lt;a href="https://raw.githubusercontent.com/mlc-ai/web-llm/main/#full-openai-compatibility"&gt;section below&lt;/a&gt; and &lt;a href="https://platform.openai.com/docs/api-reference/chat/create"&gt;OpenAI API reference&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;(Note: The &lt;code&gt;model&lt;/code&gt; parameter is not supported and will be ignored here. Instead, call &lt;code&gt;CreateMLCEngine(model)&lt;/code&gt; or &lt;code&gt;engine.reload(model)&lt;/code&gt; instead as shown in the &lt;a href="https://raw.githubusercontent.com/mlc-ai/web-llm/main/#create-mlcengine"&gt;Create MLCEngine&lt;/a&gt; above.)&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-typescript"&gt;const messages = [
  { role: "system", content: "You are a helpful AI assistant." },
  { role: "user", content: "Hello!" },
]

const reply = await engine.chat.completions.create({
  messages,
});
console.log(reply.choices[0].message);
console.log(reply.usage);
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Streaming&lt;/h3&gt; 
&lt;p&gt;WebLLM also supports streaming chat completion generating. To use it, simply pass &lt;code&gt;stream: true&lt;/code&gt; to the &lt;code&gt;engine.chat.completions.create&lt;/code&gt; call.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-typescript"&gt;const messages = [
  { role: "system", content: "You are a helpful AI assistant." },
  { role: "user", content: "Hello!" },
]

// Chunks is an AsyncGenerator object
const chunks = await engine.chat.completions.create({
  messages,
  temperature: 1,
  stream: true, // &amp;lt;-- Enable streaming
  stream_options: { include_usage: true },
});

let reply = "";
for await (const chunk of chunks) {
  reply += chunk.choices[0]?.delta.content || "";
  console.log(reply);
  if (chunk.usage) {
    console.log(chunk.usage); // only last chunk has usage
  }
}

const fullReply = await engine.getMessage();
console.log(fullReply);
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Advanced Usage&lt;/h2&gt; 
&lt;h3&gt;Using Workers&lt;/h3&gt; 
&lt;p&gt;You can put the heavy computation in a worker script to optimize your application performance. To do so, you need to:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Create a handler in the worker thread that communicates with the frontend while handling the requests.&lt;/li&gt; 
 &lt;li&gt;Create a Worker Engine in your main application, which under the hood sends messages to the handler in the worker thread.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;For detailed implementations of different kinds of Workers, check the following sections.&lt;/p&gt; 
&lt;h4&gt;Dedicated Web Worker&lt;/h4&gt; 
&lt;p&gt;WebLLM comes with API support for WebWorker so you can hook the generation process into a separate worker thread so that the computing in the worker thread won't disrupt the UI.&lt;/p&gt; 
&lt;p&gt;We create a handler in the worker thread that communicates with the frontend while handling the requests.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-typescript"&gt;// worker.ts
import { WebWorkerMLCEngineHandler } from "@mlc-ai/web-llm";

// A handler that resides in the worker thread
const handler = new WebWorkerMLCEngineHandler();
self.onmessage = (msg: MessageEvent) =&amp;gt; {
  handler.onmessage(msg);
};
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;In the main logic, we create a &lt;code&gt;WebWorkerMLCEngine&lt;/code&gt; that implements the same &lt;code&gt;MLCEngineInterface&lt;/code&gt;. The rest of the logic remains the same.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-typescript"&gt;// main.ts
import { CreateWebWorkerMLCEngine } from "@mlc-ai/web-llm";

async function main() {
  // Use a WebWorkerMLCEngine instead of MLCEngine here
  const engine = await CreateWebWorkerMLCEngine(
    new Worker(
      new URL("./worker.ts", import.meta.url), 
      {
        type: "module",
      }
    ),
    selectedModel,
    { initProgressCallback }, // engineConfig
  );

  // everything else remains the same
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Use Service Worker&lt;/h3&gt; 
&lt;p&gt;WebLLM comes with API support for ServiceWorker so you can hook the generation process into a service worker to avoid reloading the model in every page visit and optimize your application's offline experience.&lt;/p&gt; 
&lt;p&gt;(Note, Service Worker's life cycle is managed by the browser and can be killed any time without notifying the webapp. &lt;code&gt;ServiceWorkerMLCEngine&lt;/code&gt; will try to keep the service worker thread alive by periodically sending heartbeat events, but your application should also include proper error handling. Check &lt;code&gt;keepAliveMs&lt;/code&gt; and &lt;code&gt;missedHeatbeat&lt;/code&gt; in &lt;a href="https://github.com/mlc-ai/web-llm/raw/main/src/service_worker.ts#L234"&gt;&lt;code&gt;ServiceWorkerMLCEngine&lt;/code&gt;&lt;/a&gt; for more details.)&lt;/p&gt; 
&lt;p&gt;We create a handler in the worker thread that communicates with the frontend while handling the requests.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-typescript"&gt;// sw.ts
import { ServiceWorkerMLCEngineHandler } from "@mlc-ai/web-llm";

let handler: ServiceWorkerMLCEngineHandler;

self.addEventListener("activate", function (event) {
  handler = new ServiceWorkerMLCEngineHandler();
  console.log("Service Worker is ready");
});
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then in the main logic, we register the service worker and create the engine using &lt;code&gt;CreateServiceWorkerMLCEngine&lt;/code&gt; function. The rest of the logic remains the same.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-typescript"&gt;// main.ts
import { MLCEngineInterface, CreateServiceWorkerMLCEngine } from "@mlc-ai/web-llm";

if ("serviceWorker" in navigator) {
  navigator.serviceWorker.register(
    new URL("sw.ts", import.meta.url),  // worker script
    { type: "module" },
  );
}

const engine: MLCEngineInterface =
  await CreateServiceWorkerMLCEngine(
    selectedModel,
    { initProgressCallback }, // engineConfig
  );
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can find a complete example on how to run WebLLM in service worker in &lt;a href="https://raw.githubusercontent.com/mlc-ai/web-llm/main/examples/service-worker/"&gt;examples/service-worker&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Chrome Extension&lt;/h3&gt; 
&lt;p&gt;You can also find examples of building Chrome extension with WebLLM in &lt;a href="https://raw.githubusercontent.com/mlc-ai/web-llm/main/examples/chrome-extension/"&gt;examples/chrome-extension&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/mlc-ai/web-llm/main/examples/chrome-extension-webgpu-service-worker/"&gt;examples/chrome-extension-webgpu-service-worker&lt;/a&gt;. The latter one leverages service worker, so the extension is persistent in the background. Additionally, you can explore another full project of a Chrome extension, WebLLM Assistant, which leverages WebLLM &lt;a href="https://github.com/mlc-ai/web-llm-assistant"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Full OpenAI Compatibility&lt;/h2&gt; 
&lt;p&gt;WebLLM is designed to be fully compatible with &lt;a href="https://platform.openai.com/docs/api-reference/chat"&gt;OpenAI API&lt;/a&gt;. Thus, besides building a simple chatbot, you can also have the following functionalities with WebLLM:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/mlc-ai/web-llm/main/examples/streaming"&gt;streaming&lt;/a&gt;: return output as chunks in real-time in the form of an AsyncGenerator&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/mlc-ai/web-llm/main/examples/json-mode"&gt;json-mode&lt;/a&gt;: efficiently ensure output is in JSON format, see &lt;a href="https://platform.openai.com/docs/guides/text-generation/chat-completions-api"&gt;OpenAI Reference&lt;/a&gt; for more.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/mlc-ai/web-llm/main/examples/seed-to-reproduce"&gt;seed-to-reproduce&lt;/a&gt;: use seeding to ensure a reproducible output with fields &lt;code&gt;seed&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/mlc-ai/web-llm/main/examples/function-calling"&gt;function-calling&lt;/a&gt; (WIP): function calling with fields &lt;code&gt;tools&lt;/code&gt; and &lt;code&gt;tool_choice&lt;/code&gt; (with preliminary support); or manual function calling without &lt;code&gt;tools&lt;/code&gt; or &lt;code&gt;tool_choice&lt;/code&gt; (keeps the most flexibility).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Custom Models&lt;/h2&gt; 
&lt;p&gt;WebLLM works as a companion project of &lt;a href="https://github.com/mlc-ai/mlc-llm"&gt;MLC LLM&lt;/a&gt; and it supports custom models in MLC format. It reuses the model artifact and builds the flow of MLC LLM. To compile and use your own models with WebLLM, please check out &lt;a href="https://llm.mlc.ai/docs/deploy/webllm.html"&gt;MLC LLM document&lt;/a&gt; on how to compile and deploy new model weights and libraries to WebLLM.&lt;/p&gt; 
&lt;p&gt;Here, we go over the high-level idea. There are two elements of the WebLLM package that enable new models and weight variants.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;model&lt;/code&gt;: Contains a URL to model artifacts, such as weights and meta-data.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;model_lib&lt;/code&gt;: A URL to the web assembly library (i.e. wasm file) that contains the executables to accelerate the model computations.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Both are customizable in the WebLLM.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-typescript"&gt;import { CreateMLCEngine } from "@mlc-ai/web-llm";

async main() {
  const appConfig = {
    "model_list": [
      {
        "model": "/url/to/my/llama",
        "model_id": "MyLlama-3b-v1-q4f32_0",
        "model_lib": "/url/to/myllama3b.wasm",
      }
    ],
  };
  // override default
  const chatOpts = {
    "repetition_penalty": 1.01
  };

  // load a prebuilt model
  // with a chat option override and app config
  // under the hood, it will load the model from myLlamaUrl
  // and cache it in the browser cache
  // The chat will also load the model library from "/url/to/myllama3b.wasm",
  // assuming that it is compatible to the model in myLlamaUrl.
  const engine = await CreateMLCEngine(
    "MyLlama-3b-v1-q4f32_0",
    { appConfig }, // engineConfig
    chatOpts,
  );
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;In many cases, we only want to supply the model weight variant, but not necessarily a new model (e.g. &lt;code&gt;NeuralHermes-Mistral&lt;/code&gt; can reuse &lt;code&gt;Mistral&lt;/code&gt;'s model library). For examples of how a model library can be shared by different model variants, see &lt;code&gt;webllm.prebuiltAppConfig&lt;/code&gt;.&lt;/p&gt; 
&lt;h2&gt;Build WebLLM Package From Source&lt;/h2&gt; 
&lt;p&gt;NOTE: you don't need to build from source unless you would like to modify the WebLLM package. To use the npm, simply follow &lt;a href="https://raw.githubusercontent.com/mlc-ai/web-llm/main/#get-started"&gt;Get Started&lt;/a&gt; or any of the &lt;a href="https://raw.githubusercontent.com/mlc-ai/web-llm/main/examples"&gt;examples&lt;/a&gt; instead.&lt;/p&gt; 
&lt;p&gt;To build from source, simply run:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;npm install
npm run build
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then, to test the effects of your code change in an example, inside &lt;code&gt;examples/get-started/package.json&lt;/code&gt;, change from &lt;code&gt;"@mlc-ai/web-llm": "^0.2.80"&lt;/code&gt; to &lt;code&gt;"@mlc-ai/web-llm": ../..&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Then run:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd examples/get-started
npm install
npm start
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Note that sometimes you would need to switch between &lt;code&gt;file:../..&lt;/code&gt; and &lt;code&gt;../..&lt;/code&gt; to trigger npm to recognize new changes. In the worst case, you can run:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd examples/get-started
rm -rf node_modules dist package-lock.json .parcel-cache
npm install
npm start
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;In case you need to build TVMjs from source&lt;/h3&gt; 
&lt;p&gt;WebLLM's runtime largely depends on TVMjs: &lt;a href="https://github.com/apache/tvm/tree/main/web"&gt;https://github.com/apache/tvm/tree/main/web&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;While it is also available as an npm package: &lt;a href="https://www.npmjs.com/package/@mlc-ai/web-runtime"&gt;https://www.npmjs.com/package/@mlc-ai/web-runtime&lt;/a&gt;, you can build it from source if needed by following the steps below.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Install &lt;a href="https://emscripten.org"&gt;emscripten&lt;/a&gt;. It is an LLVM-based compiler that compiles C/C++ source code to WebAssembly.&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Follow the &lt;a href="https://emscripten.org/docs/getting_started/downloads.html#installation-instructions-using-the-emsdk-recommended"&gt;installation instruction&lt;/a&gt; to install the latest emsdk.&lt;/li&gt; 
   &lt;li&gt;Source &lt;code&gt;emsdk_env.sh&lt;/code&gt; by &lt;code&gt;source path/to/emsdk_env.sh&lt;/code&gt;, so that &lt;code&gt;emcc&lt;/code&gt; is reachable from PATH and the command &lt;code&gt;emcc&lt;/code&gt; works.&lt;/li&gt; 
  &lt;/ul&gt; &lt;p&gt;We can verify the successful installation by trying out &lt;code&gt;emcc&lt;/code&gt; terminal.&lt;/p&gt; &lt;p&gt;Note: We recently found that using the latest &lt;code&gt;emcc&lt;/code&gt; version may run into issues during runtime. Use &lt;code&gt;./emsdk install 3.1.56&lt;/code&gt; instead of &lt;code&gt;./emsdk install latest&lt;/code&gt; for now as a workaround. The error may look like&lt;/p&gt; &lt;pre&gt;&lt;code&gt;Init error, LinkError: WebAssembly.instantiate(): Import #6 module="wasi_snapshot_preview1"
function="proc_exit": function import requires a callable
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;In &lt;code&gt;./package.json&lt;/code&gt;, change from &lt;code&gt;"@mlc-ai/web-runtime": "0.18.0-dev2",&lt;/code&gt; to &lt;code&gt;"@mlc-ai/web-runtime": "file:./tvm_home/web",&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Setup necessary environment&lt;/p&gt; &lt;p&gt;Prepare all the necessary dependencies for web build:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;./scripts/prep_deps.sh
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;In this step, if &lt;code&gt;$TVM_SOURCE_DIR&lt;/code&gt; is not defined in the environment, we will execute the following line to build &lt;code&gt;tvmjs&lt;/code&gt; dependency:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;git clone https://github.com/mlc-ai/relax 3rdparty/tvm-unity --recursive
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;This clones the current HEAD of &lt;code&gt;mlc-ai/relax&lt;/code&gt;. However, it may not always be the correct branch or commit to clone. To build a specific npm version from source, refer to the version bump PR, which states which branch (i.e. &lt;code&gt;mlc-ai/relax&lt;/code&gt; or &lt;code&gt;apache/tvm&lt;/code&gt;) and which commit the current WebLLM version depends on. For instance, version 0.2.52, according to its version bump PR &lt;a href="https://github.com/mlc-ai/web-llm/pull/521"&gt;https://github.com/mlc-ai/web-llm/pull/521&lt;/a&gt;, is built by checking out the following commit &lt;a href="https://github.com/apache/tvm/commit/e6476847753c80e054719ac47bc2091c888418b6"&gt;https://github.com/apache/tvm/commit/e6476847753c80e054719ac47bc2091c888418b6&lt;/a&gt; in &lt;code&gt;apache/tvm&lt;/code&gt;, rather than the HEAD of &lt;code&gt;mlc-ai/relax&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;Besides, &lt;code&gt;--recursive&lt;/code&gt; is necessary and important. Otherwise, you may encounter errors like &lt;code&gt;fatal error: 'dlpack/dlpack.h' file not found&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Build WebLLM Package&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;npm run build
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Validate some of the sub-packages&lt;/p&gt; &lt;p&gt;You can then go to the subfolders in &lt;a href="https://raw.githubusercontent.com/mlc-ai/web-llm/main/examples"&gt;examples&lt;/a&gt; to validate some of the sub-packages. We use Parcelv2 for bundling. Although Parcel is not very good at tracking parent directory changes sometimes. When you make a change in the WebLLM package, try to edit the &lt;code&gt;package.json&lt;/code&gt; of the subfolder and save it, which will trigger Parcel to rebuild.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Links&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://chat.webllm.ai/"&gt;Demo App: WebLLM Chat&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;If you want to run LLM on native runtime, check out &lt;a href="https://github.com/mlc-ai/mlc-llm"&gt;MLC-LLM&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;You might also be interested in &lt;a href="https://github.com/mlc-ai/web-stable-diffusion/"&gt;Web Stable Diffusion&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Acknowledgement&lt;/h2&gt; 
&lt;p&gt;This project is initiated by members from CMU Catalyst, UW SAMPL, SJTU, OctoML, and the MLC community. We would love to continue developing and supporting the open-source ML community.&lt;/p&gt; 
&lt;p&gt;This project is only possible thanks to the shoulders open-source ecosystems that we stand on. We want to thank the Apache TVM community and developers of the TVM Unity effort. The open-source ML community members made these models publicly available. PyTorch and Hugging Face communities make these models accessible. We would like to thank the teams behind Vicuna, SentencePiece, LLaMA, and Alpaca. We also would like to thank the WebAssembly, Emscripten, and WebGPU communities. Finally, thanks to Dawn and WebGPU developers.&lt;/p&gt; 
&lt;h2&gt;Citation&lt;/h2&gt; 
&lt;p&gt;If you find this project to be useful, please cite:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;@misc{ruan2024webllmhighperformanceinbrowserllm,
      title={WebLLM: A High-Performance In-Browser LLM Inference Engine}, 
      author={Charlie F. Ruan and Yucheng Qin and Xun Zhou and Ruihang Lai and Hongyi Jin and Yixin Dong and Bohan Hou and Meng-Shiun Yu and Yiyan Zhai and Sudeep Agarwal and Hangrui Cao and Siyuan Feng and Tianqi Chen},
      year={2024},
      eprint={2412.15803},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2412.15803}, 
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Contributors&lt;/h2&gt; 
&lt;a href="https://github.com/mlc-ai/web-llm/graphs/contributors"&gt; &lt;img alt="contributors" src="https://contrib.rocks/image?repo=mlc-ai/web-llm" /&gt; &lt;/a&gt; 
&lt;p align="right"&gt; &lt;a href="https://raw.githubusercontent.com/mlc-ai/web-llm/main/#top"&gt;‚¨Ü Back to Top ‚¨Ü&lt;/a&gt; &lt;/p&gt;</description>
    </item>
    
    <item>
      <title>TibixDev/winboat</title>
      <link>https://github.com/TibixDev/winboat</link>
      <description>&lt;p&gt;Run Windows apps on üêß Linux with ‚ú® seamless integration&lt;/p&gt;&lt;hr&gt;&lt;div align="left"&gt; 
 &lt;table&gt; 
  &lt;tbody&gt;
   &lt;tr&gt; 
    &lt;td&gt; &lt;img src="https://raw.githubusercontent.com/TibixDev/winboat/main/icons/winboat_logo.svg?sanitize=true" alt="WinBoat Logo" width="150" /&gt; &lt;/td&gt; 
    &lt;td&gt; &lt;h1 style="color: #7C86FF; margin: 0; font-size: 32px;"&gt;WinBoat&lt;/h1&gt; &lt;p style="color: oklch(90% 0 0); font-size: 14px; margin: 5px 0;"&gt;Windows for Penguins.&lt;br /&gt; Run Windows apps on üêß Linux with ‚ú® seamless integration&lt;/p&gt; &lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt;
 &lt;/table&gt; 
&lt;/div&gt; 
&lt;h2&gt;Screenshots&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/TibixDev/winboat/main/gh-assets/features/feat_dash.png" alt="WinBoat Dashboard" width="45%" /&gt; 
 &lt;img src="https://raw.githubusercontent.com/TibixDev/winboat/main/gh-assets/features/feat_apps.png" alt="WinBoat Apps" width="45%" /&gt; 
 &lt;img src="https://raw.githubusercontent.com/TibixDev/winboat/main/gh-assets/features/feat_native.png" alt="Native Windows" width="45%" /&gt; 
&lt;/div&gt; 
&lt;h2&gt;‚ö†Ô∏è Work in Progress ‚ö†Ô∏è&lt;/h2&gt; 
&lt;p&gt;WinBoat is currently in beta, so expect to occasionally run into hiccups and bugs. You should be comfortable with some level of troubleshooting if you decide to try it, however we encourage you to give it a shot anyway.&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;üé® Elegant Interface&lt;/strong&gt;: Sleek and intuitive interface that seamlessly integrates Windows into your Linux desktop environment, making it feel like a native experience&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üì¶ Automated Installs&lt;/strong&gt;: Simple installation process through our interface - pick your preferences &amp;amp; specs and let us handle the rest&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üöÄ Run Any App&lt;/strong&gt;: If it runs on Windows, it can run on WinBoat. Enjoy the full range of Windows applications as native OS-level windows in your Linux environment&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üñ•Ô∏è Full Windows Desktop&lt;/strong&gt;: Access the complete Windows desktop experience when you need it, or run individual apps seamlessly integrated into your Linux workflow&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üìÅ Filesystem Integration&lt;/strong&gt;: Your home directory is mounted in Windows, allowing easy file sharing between the two systems without any hassle&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;‚ú® And many more&lt;/strong&gt;: Smartcard passthrough, resource monitoring, and more features being added regularly&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;How Does It Work?&lt;/h2&gt; 
&lt;p&gt;WinBoat is an Electron app which allows you to run Windows apps on Linux using a containerized approach. Windows runs as a VM inside a Docker/Podman container, we communicate with it using the &lt;a href="https://github.com/TibixDev/winboat/tree/main/guest_server"&gt;WinBoat Guest Server&lt;/a&gt; to retrieve data we need from Windows. For compositing applications as native OS-level windows, we use FreeRDP together with Windows's RemoteApp protocol.&lt;/p&gt; 
&lt;h2&gt;Prerequisites&lt;/h2&gt; 
&lt;p&gt;Before running WinBoat, ensure your system meets the following requirements:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;RAM&lt;/strong&gt;: At least 4 GB of RAM&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;CPU&lt;/strong&gt;: At least 2 CPU threads&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Storage&lt;/strong&gt;: At least 32 GB free space on the drive your selected install folder corresponds to&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Virtualization&lt;/strong&gt;: KVM enabled in BIOS/UEFI 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://duckduckgo.com/?t=h_&amp;amp;q=how+to+enable+virtualization+in+%3Cmotherboard+brand%3E+bios&amp;amp;ia=web"&gt;How to enable virtualization&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;In case of Docker:&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Docker&lt;/strong&gt;: Required for containerization 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://docs.docker.com/engine/install/"&gt;Installation Guide&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;strong&gt;‚ö†Ô∏è NOTE:&lt;/strong&gt; Docker Desktop is &lt;strong&gt;not&lt;/strong&gt; supported, you will run into issues if you use it&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Docker Compose v2&lt;/strong&gt;: Required for compatibility with docker-compose.yml files 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://docs.docker.com/compose/install/#plugin-linux-only"&gt;Installation Guide&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Docker User Group&lt;/strong&gt;: Add your user to the &lt;code&gt;docker&lt;/code&gt; group 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://docs.docker.com/engine/install/linux-postinstall/#manage-docker-as-a-non-root-user"&gt;Setup Instructions&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;In case of Podman:&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Podman&lt;/strong&gt;: Required for containerization 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://podman.io/docs/installation#installing-on-linux"&gt;Installation Guide&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Podman Compose&lt;/strong&gt;: Required for compatibility with podman-compose.yml files 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://github.com/containers/podman-compose?tab=readme-ov-file#installation"&gt;Installation Guide&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;FreeRDP&lt;/strong&gt;: Required for remote desktop connection (Please make sure you have &lt;strong&gt;Version 3.x.x&lt;/strong&gt; with sound support included) 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/FreeRDP/FreeRDP/wiki/PreBuilds"&gt;Installation Guide&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;[OPTIONAL] &lt;strong&gt;Kernel Modules&lt;/strong&gt;: The &lt;code&gt;iptables&lt;/code&gt; / &lt;code&gt;nftables&lt;/code&gt; and &lt;code&gt;iptable_nat&lt;/code&gt; kernel modules can be loaded for network autodiscovery and better shared filesystem performance, but this is not obligatory in newer versions of WinBoat 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://rentry.org/rmfq2e5e"&gt;Module loading instructions&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Downloading&lt;/h2&gt; 
&lt;p&gt;You can download the latest Linux builds under the &lt;a href="https://github.com/TibixDev/winboat/releases"&gt;Releases&lt;/a&gt; tab. We currently offer four variants:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;AppImage:&lt;/strong&gt; A popular &amp;amp; portable app format which should run fine on most distributions&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Unpacked:&lt;/strong&gt; The raw unpacked files, simply run the executable (&lt;code&gt;linux-unpacked/winboat&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;.deb:&lt;/strong&gt; The intended format for Debian based distributions&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;.rpm:&lt;/strong&gt; The intended format for Fedora based distributions&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Known Issues About Container Runtimes&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Docker Desktop is &lt;strong&gt;unsupported&lt;/strong&gt; for now&lt;/li&gt; 
 &lt;li&gt;USB passthrough via Podman is currently &lt;strong&gt;unsupported&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Building WinBoat&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;For building you need to have NodeJS and Go installed on your system&lt;/li&gt; 
 &lt;li&gt;Clone the repo (&lt;code&gt;git clone https://github.com/TibixDev/WinBoat&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;Install the dependencies (&lt;code&gt;npm i&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;Build the app and the guest server using &lt;code&gt;npm run build:linux-gs&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;You can now find the built app under &lt;code&gt;dist&lt;/code&gt; with an AppImage and an Unpacked variant&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Running WinBoat in development mode&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Make sure you meet the &lt;a href="https://raw.githubusercontent.com/TibixDev/winboat/main/#prerequisites"&gt;prerequisites&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Additionally, for development you need to have NodeJS and Go installed on your system&lt;/li&gt; 
 &lt;li&gt;Clone the repo (&lt;code&gt;git clone https://github.com/TibixDev/WinBoat&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;Install the dependencies (&lt;code&gt;npm i&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;Build the guest server (&lt;code&gt;npm run build:gs&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;Run the app (&lt;code&gt;npm run dev&lt;/code&gt;)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Contributions are welcome! Whether it's bug fixes, feature improvements, or documentation updates, we appreciate your help making WinBoat better.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Please note&lt;/strong&gt;: We maintain a focus on technical contributions only. Pull requests containing political/sexual content, or other sensitive/controversial topics will not be accepted. Let's keep things focused on making great software! üöÄ&lt;/p&gt; 
&lt;p&gt;Feel free to:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Report bugs and issues&lt;/li&gt; 
 &lt;li&gt;Submit feature requests&lt;/li&gt; 
 &lt;li&gt;Contribute code improvements&lt;/li&gt; 
 &lt;li&gt;Help with documentation&lt;/li&gt; 
 &lt;li&gt;Share feedback and suggestions&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Check out our issues page to get started, or feel free to open a new issue if you've found something that needs attention.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;WinBoat is licensed under the &lt;a href="https://github.com/TibixDev/winboat/raw/main/LICENSE"&gt;MIT&lt;/a&gt; license&lt;/p&gt; 
&lt;h2&gt;Inspiration / Alternatives&lt;/h2&gt; 
&lt;p&gt;These past few years some cool projects have surfaced with similar concepts, some of which we've also taken inspirations from.&lt;br /&gt; They're awesome and you should check them out:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/winapps-org/winapps"&gt;WinApps&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/casualsnek/cassowary"&gt;Cassowary&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/dockur/windows"&gt;dockur/windows&lt;/a&gt; (üåü Also used in WinBoat)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Socials &amp;amp; Contact&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.winboat.app/"&gt;&lt;img src="https://img.shields.io/badge/Website-winboat.app-blue?style=flat&amp;amp;logo=googlechrome&amp;amp;logoColor=white" alt="Website" /&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://x.com/winboat_app"&gt;&lt;img src="https://img.shields.io/badge/Twitter-@winboat__app-1DA1F2?style=flat&amp;amp;logo=x&amp;amp;logoColor=white" alt="Twitter" /&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://fosstodon.org/@winboat"&gt;&lt;img src="https://img.shields.io/badge/Mastodon-@winboat-6364FF?style=flat&amp;amp;logo=mastodon&amp;amp;logoColor=white" alt="Mastodon" /&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://bsky.app/profile/winboat.app"&gt;&lt;img src="https://img.shields.io/badge/Bluesky-winboat.app-00A8E8?style=flat&amp;amp;logo=bluesky&amp;amp;logoColor=white" alt="Bluesky" /&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://discord.gg/MEwmpWm4tN"&gt;&lt;img src="https://img.shields.io/badge/Discord-Join_Community-5865F2?style=flat&amp;amp;logo=discord&amp;amp;logoColor=white" alt="Discord" /&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="mailto:staff@winboat.app"&gt;&lt;img src="https://img.shields.io/badge/Email-staff@winboat.app-D14836?style=flat&amp;amp;logo=gmail&amp;amp;logoColor=white" alt="Email" /&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://deepwiki.com/TibixDev/winboat"&gt;&lt;img src="https://deepwiki.com/badge.svg?sanitize=true" alt="Ask DeepWiki" /&gt;&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Star History&lt;/h2&gt; 
&lt;a href="https://www.star-history.com/#tibixdev/winboat&amp;amp;Date"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://api.star-history.com/svg?repos=tibixdev/winboat&amp;amp;type=Date&amp;amp;theme=dark" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://api.star-history.com/svg?repos=tibixdev/winboat&amp;amp;type=Date" /&gt; 
  &lt;img alt="Star History Chart" src="https://api.star-history.com/svg?repos=tibixdev/winboat&amp;amp;type=Date" /&gt; 
 &lt;/picture&gt; &lt;/a&gt;</description>
    </item>
    
    <item>
      <title>colinhacks/zod</title>
      <link>https://github.com/colinhacks/zod</link>
      <description>&lt;p&gt;TypeScript-first schema validation with static type inference&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/colinhacks/zod/main/logo.svg?sanitize=true" width="200px" align="center" alt="Zod logo" /&gt; &lt;/p&gt;
&lt;h1 align="center"&gt;Zod&lt;/h1&gt; 
&lt;p align="center"&gt; TypeScript-first schema validation with static type inference &lt;br /&gt; by &lt;a href="https://x.com/colinhacks"&gt;@colinhacks&lt;/a&gt; &lt;/p&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;br /&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/colinhacks/zod/actions?query=branch%3Amain"&gt;&lt;img src="https://github.com/colinhacks/zod/actions/workflows/test.yml/badge.svg?event=push&amp;amp;branch=main" alt="Zod CI status" /&gt;&lt;/a&gt; &lt;a href="https://opensource.org/licenses/MIT" rel="nofollow"&gt;&lt;img src="https://img.shields.io/github/license/colinhacks/zod" alt="License" /&gt;&lt;/a&gt; &lt;a href="https://www.npmjs.com/package/zod" rel="nofollow"&gt;&lt;img src="https://img.shields.io/npm/dw/zod.svg?sanitize=true" alt="npm" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/KaSRdyX2vc" rel="nofollow"&gt;&lt;img src="https://img.shields.io/discord/893487829802418277?label=Discord&amp;amp;logo=discord&amp;amp;logoColor=white" alt="discord server" /&gt;&lt;/a&gt; &lt;a href="https://github.com/colinhacks/zod" rel="nofollow"&gt;&lt;img src="https://img.shields.io/github/stars/colinhacks/zod" alt="stars" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://zod.dev/api"&gt;Docs&lt;/a&gt; 
 &lt;span&gt;&amp;nbsp;&amp;nbsp;‚Ä¢&amp;nbsp;&amp;nbsp;&lt;/span&gt; 
 &lt;a href="https://discord.gg/RcG33DQJdf"&gt;Discord&lt;/a&gt; 
 &lt;span&gt;&amp;nbsp;&amp;nbsp;‚Ä¢&amp;nbsp;&amp;nbsp;&lt;/span&gt; 
 &lt;a href="https://twitter.com/colinhacks"&gt;ùïè&lt;/a&gt; 
 &lt;span&gt;&amp;nbsp;&amp;nbsp;‚Ä¢&amp;nbsp;&amp;nbsp;&lt;/span&gt; 
 &lt;a href="https://bsky.app/profile/zod.dev"&gt;Bluesky&lt;/a&gt; 
 &lt;br /&gt; 
&lt;/div&gt; 
&lt;br /&gt; 
&lt;br /&gt; 
&lt;h2 align="center"&gt;Featured sponsor: Jazz&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://jazz.tools/?utm_source=zod"&gt; 
  &lt;picture width="85%"&gt; 
   &lt;source media="(prefers-color-scheme: dark)" srcset="https://raw.githubusercontent.com/garden-co/jazz/938f6767e46cdfded60e50d99bf3b533f4809c68/homepage/homepage/public/Zod%20sponsor%20message.png" /&gt; 
   &lt;img alt="jazz logo" src="https://raw.githubusercontent.com/garden-co/jazz/938f6767e46cdfded60e50d99bf3b533f4809c68/homepage/homepage/public/Zod%20sponsor%20message.png" width="85%" /&gt; 
  &lt;/picture&gt; &lt;/a&gt; 
 &lt;br /&gt; 
 &lt;p&gt;&lt;sub&gt;Learn more about &lt;a target="_blank" rel="noopener noreferrer" href="mailto:sponsorship@colinhacks.com"&gt;featured sponsorships&lt;/a&gt;&lt;/sub&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;br /&gt; 
&lt;br /&gt; 
&lt;br /&gt; 
&lt;h3&gt;&lt;a href="https://zod.dev/api"&gt;Read the docs ‚Üí&lt;/a&gt;&lt;/h3&gt; 
&lt;br /&gt; 
&lt;br /&gt; 
&lt;h2&gt;What is Zod?&lt;/h2&gt; 
&lt;p&gt;Zod is a TypeScript-first validation library. Define a schema and parse some data with it. You'll get back a strongly typed, validated result.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-ts"&gt;import * as z from "zod";

const User = z.object({
  name: z.string(),
});

// some untrusted data...
const input = {
  /* stuff */
};

// the parsed result is validated and type safe!
const data = User.parse(input);

// so you can use it with confidence :)
console.log(data.name);
&lt;/code&gt;&lt;/pre&gt; 
&lt;br /&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Zero external dependencies&lt;/li&gt; 
 &lt;li&gt;Works in Node.js and all modern browsers&lt;/li&gt; 
 &lt;li&gt;Tiny: &lt;code&gt;2kb&lt;/code&gt; core bundle (gzipped)&lt;/li&gt; 
 &lt;li&gt;Immutable API: methods return a new instance&lt;/li&gt; 
 &lt;li&gt;Concise interface&lt;/li&gt; 
 &lt;li&gt;Works with TypeScript and plain JS&lt;/li&gt; 
 &lt;li&gt;Built-in JSON Schema conversion&lt;/li&gt; 
 &lt;li&gt;Extensive ecosystem&lt;/li&gt; 
&lt;/ul&gt; 
&lt;br /&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;npm install zod
&lt;/code&gt;&lt;/pre&gt; 
&lt;br /&gt; 
&lt;h2&gt;Basic usage&lt;/h2&gt; 
&lt;p&gt;Before you can do anything else, you need to define a schema. For the purposes of this guide, we'll use a simple object schema.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-ts"&gt;import * as z from "zod";

const Player = z.object({
  username: z.string(),
  xp: z.number(),
});
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Parsing data&lt;/h3&gt; 
&lt;p&gt;Given any Zod schema, use &lt;code&gt;.parse&lt;/code&gt; to validate an input. If it's valid, Zod returns a strongly-typed &lt;em&gt;deep clone&lt;/em&gt; of the input.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-ts"&gt;Player.parse({ username: "billie", xp: 100 });
// =&amp;gt; returns { username: "billie", xp: 100 }
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt; ‚Äî If your schema uses certain asynchronous APIs like &lt;code&gt;async&lt;/code&gt; &lt;a href="https://zod.dev/api#refinements"&gt;refinements&lt;/a&gt; or &lt;a href="https://zod.dev/api#transforms"&gt;transforms&lt;/a&gt;, you'll need to use the &lt;code&gt;.parseAsync()&lt;/code&gt; method instead.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-ts"&gt;const schema = z.string().refine(async (val) =&amp;gt; val.length &amp;lt;= 8);

await schema.parseAsync("hello");
// =&amp;gt; "hello"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Handling errors&lt;/h3&gt; 
&lt;p&gt;When validation fails, the &lt;code&gt;.parse()&lt;/code&gt; method will throw a &lt;code&gt;ZodError&lt;/code&gt; instance with granular information about the validation issues.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-ts"&gt;try {
  Player.parse({ username: 42, xp: "100" });
} catch (err) {
  if (err instanceof z.ZodError) {
    err.issues;
    /* [
      {
        expected: 'string',
        code: 'invalid_type',
        path: [ 'username' ],
        message: 'Invalid input: expected string'
      },
      {
        expected: 'number',
        code: 'invalid_type',
        path: [ 'xp' ],
        message: 'Invalid input: expected number'
      }
    ] */
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To avoid a &lt;code&gt;try/catch&lt;/code&gt; block, you can use the &lt;code&gt;.safeParse()&lt;/code&gt; method to get back a plain result object containing either the successfully parsed data or a &lt;code&gt;ZodError&lt;/code&gt;. The result type is a &lt;a href="https://www.typescriptlang.org/docs/handbook/2/narrowing.html#discriminated-unions"&gt;discriminated union&lt;/a&gt;, so you can handle both cases conveniently.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-ts"&gt;const result = Player.safeParse({ username: 42, xp: "100" });
if (!result.success) {
  result.error; // ZodError instance
} else {
  result.data; // { username: string; xp: number }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt; ‚Äî If your schema uses certain asynchronous APIs like &lt;code&gt;async&lt;/code&gt; &lt;a href="https://raw.githubusercontent.com/colinhacks/zod/main/#refine"&gt;refinements&lt;/a&gt; or &lt;a href="https://raw.githubusercontent.com/colinhacks/zod/main/#transform"&gt;transforms&lt;/a&gt;, you'll need to use the &lt;code&gt;.safeParseAsync()&lt;/code&gt; method instead.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-ts"&gt;const schema = z.string().refine(async (val) =&amp;gt; val.length &amp;lt;= 8);

await schema.safeParseAsync("hello");
// =&amp;gt; { success: true; data: "hello" }
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Inferring types&lt;/h3&gt; 
&lt;p&gt;Zod infers a static type from your schema definitions. You can extract this type with the &lt;code&gt;z.infer&amp;lt;&amp;gt;&lt;/code&gt; utility and use it however you like.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-ts"&gt;const Player = z.object({
  username: z.string(),
  xp: z.number(),
});

// extract the inferred type
type Player = z.infer&amp;lt;typeof Player&amp;gt;;

// use it in your code
const player: Player = { username: "billie", xp: 100 };
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;In some cases, the input &amp;amp; output types of a schema can diverge. For instance, the &lt;code&gt;.transform()&lt;/code&gt; API can convert the input from one type to another. In these cases, you can extract the input and output types independently:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-ts"&gt;const mySchema = z.string().transform((val) =&amp;gt; val.length);

type MySchemaIn = z.input&amp;lt;typeof mySchema&amp;gt;;
// =&amp;gt; string

type MySchemaOut = z.output&amp;lt;typeof mySchema&amp;gt;; // equivalent to z.infer&amp;lt;typeof mySchema&amp;gt;
// number
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>remotion-dev/remotion</title>
      <link>https://github.com/remotion-dev/remotion</link>
      <description>&lt;p&gt;üé• Make videos programmatically with React&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;a href="https://github.com/remotion-dev/logo"&gt; 
  &lt;picture&gt; 
   &lt;source media="(prefers-color-scheme: dark)" srcset="https://github.com/remotion-dev/logo/raw/main/animated-logo-banner-dark.apng" /&gt; 
   &lt;img alt="Animated Remotion Logo" src="https://github.com/remotion-dev/logo/raw/main/animated-logo-banner-light.gif" /&gt; 
  &lt;/picture&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p&gt;&lt;a href="https://remotion.dev/discord"&gt;&lt;img src="https://img.shields.io/discord/809501355504959528?color=000000&amp;amp;label=Discord&amp;amp;logo=fdgssdf" alt="Discord Shield" /&gt;&lt;/a&gt; &lt;a href="https://www.npmjs.org/package/remotion"&gt;&lt;img src="https://img.shields.io/npm/v/remotion.svg?style=flat&amp;amp;color=black" alt="NPM Version" /&gt;&lt;/a&gt; &lt;a href="https://npmcharts.com/compare/remotion?minimal=true"&gt;&lt;img src="https://img.shields.io/npm/dm/remotion.svg?style=flat&amp;amp;color=black&amp;amp;label=Downloads" alt="NPM Downloads" /&gt;&lt;/a&gt; &lt;a href="https://github.com/remotion-dev/remotion/issues?q=is%3Aopen+label%3A%22%F0%9F%92%8E+Bounty%22+sort%3Aupdated-desc"&gt;&lt;img src="https://img.shields.io/endpoint?url=https%3A%2F%2Fconsole.algora.io%2Fapi%2Fshields%2Fremotion%2Fbounties%3Fstatus%3Dopen&amp;amp;style=flat&amp;amp;color=black&amp;amp;labelColor=grey&amp;amp;label=Open+Bounties" alt="Open Bounties" /&gt;&lt;/a&gt; &lt;a href="https://twitter.com/remotion"&gt;&lt;img src="https://img.shields.io/twitter/follow/remotion?label=Twitter&amp;amp;color=black" alt="Twitter" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Remotion is a framework for &lt;strong&gt;creating videos programmatically using React.&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;Why create videos in React?&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Leverage web technologies&lt;/strong&gt;: Use all of CSS, Canvas, SVG, WebGL, etc.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Leverage programming&lt;/strong&gt;: Use variables, functions, APIs, math and algorithms to create new effects&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Leverage React&lt;/strong&gt;: Reusable components, Powerful composition, Fast Refresh, Package ecosystem&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Created with Remotion&lt;/h2&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td align="center"&gt; &lt;img style="width: 290px" src="https://pub-646d808d9cb240cea53bedc76dd3cd0c.r2.dev/fireship-quick.gif" /&gt; &lt;p&gt;"This video was made with code" &lt;em&gt;- Fireship&lt;/em&gt; &lt;a href="https://youtu.be/deg8bOoziaE"&gt;Watch&lt;/a&gt; ‚Ä¢ &lt;a href="https://github.com/wcandillon/remotion-fireship"&gt;Source&lt;/a&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td align="center"&gt; &lt;img style="width: 240px" src="https://pub-646d808d9cb240cea53bedc76dd3cd0c.r2.dev/unwrapped-2023.gif" /&gt; &lt;p&gt;GitHub Unwrapped - Personalized Year in Review &lt;a href="https://www.githubunwrapped.com"&gt;Try&lt;/a&gt; ‚Ä¢ &lt;a href="https://github.com/remotion-dev/github-unwrapped"&gt;Source&lt;/a&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td align="center"&gt; &lt;em&gt;View more in the &lt;a href="https://remotion.dev/showcase"&gt;Remotion Showcase&lt;/a&gt;!&lt;/em&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h2&gt;Get started&lt;/h2&gt; 
&lt;p&gt;If you already have Node.JS installed, type&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;npx create-video@latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;to get started. Otherwise, read the &lt;a href="https://www.remotion.dev/docs/"&gt;installation page&lt;/a&gt; in the documentation.&lt;/p&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;Documentation: &lt;a href="https://www.remotion.dev/docs"&gt;&lt;strong&gt;remotion.dev/docs&lt;/strong&gt;&lt;/a&gt;&lt;br /&gt; API Reference: &lt;a href="https://www.remotion.dev/api"&gt;&lt;strong&gt;remotion.dev/api&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Be aware of that Remotion has a special license and requires obtaining a company license in some cases. Read the &lt;a href="https://raw.githubusercontent.com/remotion-dev/remotion/main/LICENSE.md"&gt;LICENSE&lt;/a&gt; page for more information.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Please read &lt;a href="https://raw.githubusercontent.com/remotion-dev/remotion/main/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; to learn about contributing to this project.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>supermemoryai/supermemory</title>
      <link>https://github.com/supermemoryai/supermemory</link>
      <description>&lt;p&gt;Memory engine and app that is extremely fast, scalable. The Memory API for the AI era.&lt;/p&gt;&lt;hr&gt;&lt;p align="center" style="padding-bottom:20px;padding-top:20px"&gt; 
 &lt;picture&gt; 
  &lt;source srcset="apps/web/public/logo-fullmark.svg" media="(prefers-color-scheme: dark)" /&gt; 
  &lt;source srcset="apps/web/public/logo-light-fullmark.svg" media="(prefers-color-scheme: light)" /&gt; 
  &lt;img src="https://raw.githubusercontent.com/supermemoryai/supermemory/main/apps/web/public/logo-fullmark.svg?sanitize=true" alt="supermemory Logo" width="400" /&gt; 
 &lt;/picture&gt; &lt;br /&gt;&lt;br /&gt; &lt;em&gt;Your AI second brain for saving and organizing everything that matters.&lt;/em&gt; &lt;br /&gt;&lt;br /&gt; &lt;a href="https://app.supermemory.ai" style="text-decoration: none;"&gt; &lt;img src="https://img.shields.io/badge/Web-App-000000?style=for-the-badge" alt="Web App" /&gt; &lt;/a&gt; &amp;nbsp; &lt;a href="https://chromewebstore.google.com/detail/supermemory/afpgkkipfdpeaflnpoaffkcankadgjfc" style="text-decoration: none;"&gt; &lt;img src="https://img.shields.io/badge/Chrome-Extension-4285F4?style=for-the-badge&amp;amp;logo=googlechrome&amp;amp;logoColor=white" alt="Chrome Extension" /&gt; &lt;/a&gt; &amp;nbsp; &lt;a href="https://www.raycast.com/supermemory/supermemory" style="text-decoration: none;"&gt; &lt;img src="https://img.shields.io/badge/Raycast-Extension-FF6363?style=for-the-badge&amp;amp;logo=raycast&amp;amp;logoColor=white" alt="Raycast Extension" /&gt; &lt;/a&gt; &amp;nbsp; &lt;a href="https://supermemory.link/discord" style="text-decoration: none;"&gt; &lt;img src="https://img.shields.io/badge/Discord-5865F2?style=for-the-badge&amp;amp;logo=discord&amp;amp;logoColor=white" alt="Discord" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p style="font-size: 0.9em; color: #666;"&gt; &lt;strong&gt;Building with Supermemory?&lt;/strong&gt; Check out the &lt;a href="https://console.supermemory.ai?utm_source=github&amp;amp;utm_medium=readme&amp;amp;utm_campaign=consumer_app"&gt;Developer Console&lt;/a&gt; and &lt;a href="https://docs.supermemory.ai?utm_source=github&amp;amp;utm_medium=readme&amp;amp;utm_campaign=consumer_app"&gt;Documentation&lt;/a&gt; for API access. &lt;/p&gt; 
&lt;p style="font-size: 0.9em; color: #666;"&gt; &lt;strong&gt;Want to self-host?&lt;/strong&gt; See our &lt;a href="https://supermemory.ai/docs/deployment/self-hosting#self-hosting"&gt;Self-Hosting Guide&lt;/a&gt; for enterprise deployment options. &lt;/p&gt; 
&lt;br /&gt; 
&lt;div align="center" style="padding-bottom:10px;padding-top:10px"&gt; 
 &lt;img src="https://raw.githubusercontent.com/supermemoryai/supermemory/main/apps/web/public/landing-page.jpeg" alt="supermemory" width="100%" /&gt; 
&lt;/div&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;h3&gt;Core Functionality&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/supermemoryai/supermemory/main/#add-memory"&gt;Add Memories from Any Content&lt;/a&gt;&lt;/strong&gt;: Easily add memories from URLs, PDFs, and plain text‚Äîjust paste, upload, or link.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/supermemoryai/supermemory/main/#chat-memories"&gt;Chat with Your Memories&lt;/a&gt;&lt;/strong&gt;: Converse with your stored content using natural language chat.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/supermemoryai/supermemory/main/#mcp-integration"&gt;Supermemory MCP Integration&lt;/a&gt;&lt;/strong&gt;: Seamlessly connect with all major AI tools (Claude, Cursor, etc.) via Supermemory MCP.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/supermemoryai/supermemory/main/#browser-extension"&gt;Browser Extension&lt;/a&gt;&lt;/strong&gt;: Save memories directly from your browser with integrations for ChatGPT, Claude, and Twitter/X.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/supermemoryai/supermemory/main/#raycast-extension"&gt;Raycast Extension&lt;/a&gt;&lt;/strong&gt;: Add and search memories directly from Raycast with keyboard shortcuts.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;How do I use this?&lt;/h2&gt; 
&lt;p&gt;Go to &lt;a href="https://app.supermemory.ai"&gt;app.supermemory.ai&lt;/a&gt; and sign in with your account&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;a id="add-memory"&gt;&lt;/a&gt;Start Adding Memory with your choice of format (Note, Link, File)&lt;/li&gt; 
&lt;/ol&gt; 
&lt;div align="center" style="padding-bottom:10px;padding-top:10px"&gt; 
 &lt;img src="https://raw.githubusercontent.com/supermemoryai/supermemory/main/apps/web/public/add-memory.png" alt="supermemory" width="100%" /&gt; 
&lt;/div&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;You can also Connect to your favourite services (Notion, Google Drive, OneDrive)&lt;/li&gt; 
&lt;/ol&gt; 
&lt;div align="center" style="padding-bottom:10px;padding-top:10px"&gt; 
 &lt;img src="https://raw.githubusercontent.com/supermemoryai/supermemory/main/apps/web/public/add-connections.png" alt="supermemory" width="100%" /&gt; 
&lt;/div&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt;&lt;a id="chat-memories"&gt;&lt;/a&gt;Once Memories are added, you can chat with Supermemory by clicking on "Open Chat" and retrieve info from your saved memories&lt;/li&gt; 
&lt;/ol&gt; 
&lt;div align="center" style="padding-bottom:10px;padding-top:10px"&gt; 
 &lt;img src="https://raw.githubusercontent.com/supermemoryai/supermemory/main/apps/web/public/chat.png" alt="supermemory" width="100%" /&gt; 
&lt;/div&gt; 
&lt;ol start="4"&gt; 
 &lt;li&gt;&lt;a id="mcp-integration"&gt;&lt;/a&gt;Add MCP to your AI Tools (by clicking on "Connect to your AI" and select the AI tool you are trying to integrate)&lt;/li&gt; 
&lt;/ol&gt; 
&lt;div align="center" style="padding-bottom:10px;padding-top:10px"&gt; 
 &lt;img src="https://raw.githubusercontent.com/supermemoryai/supermemory/main/apps/web/public/mcp.png" alt="supermemory" width="100%" /&gt; 
&lt;/div&gt; 
&lt;ol start="5"&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a id="browser-extension"&gt;&lt;/a&gt;&lt;strong&gt;Browser Extension&lt;/strong&gt;: Install the &lt;a href="https://chromewebstore.google.com/detail/supermemory/afpgkkipfdpeaflnpoaffkcankadgjfc"&gt;Chrome/Edge extension&lt;/a&gt; to save memories directly from any webpage, integrate with ChatGPT and Claude conversations, and import from Twitter/X. Right-click on any content or use the extension popup to save memories instantly.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a id="raycast-extension"&gt;&lt;/a&gt;&lt;strong&gt;Raycast Extension&lt;/strong&gt;: Install the &lt;a href="https://www.raycast.com/supermemory/supermemory"&gt;Raycast extension&lt;/a&gt; to add and search memories directly from Raycast. Use the "Add Memory" command to quickly save content, or "Search Memories" to find and retrieve your saved information with keyboard shortcuts.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Support&lt;/h2&gt; 
&lt;p&gt;Have questions or feedback? We're here to help:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Email: &lt;a href="mailto:support@supermemory.ai"&gt;support@supermemory.ai&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Discord: &lt;a href="https://supermemory.link/discord"&gt;Join our Discord server&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Documentation: &lt;a href="https://docs.supermemory.ai"&gt;docs.supermemory.ai&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome contributions from developers of all skill levels! Whether you're fixing bugs, adding features, or improving documentation, your help makes supermemory better for everyone.&lt;/p&gt; 
&lt;p&gt;For detailed guidelines, development setup, coding standards, and the complete contribution workflow, please see our &lt;a href="https://raw.githubusercontent.com/supermemoryai/supermemory/main/CONTRIBUTING.md"&gt;&lt;strong&gt;Contributing Guide&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Ways to Contribute&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;üêõ &lt;strong&gt;Bug fixes&lt;/strong&gt; - Help us squash those pesky issues&lt;/li&gt; 
 &lt;li&gt;‚ú® &lt;strong&gt;New features&lt;/strong&gt; - Add functionality that users will love&lt;/li&gt; 
 &lt;li&gt;üé® &lt;strong&gt;UI/UX improvements&lt;/strong&gt; - Make the interface more intuitive&lt;/li&gt; 
 &lt;li&gt;‚ö° &lt;strong&gt;Performance optimizations&lt;/strong&gt; - Help us make supermemory faster&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Check out our &lt;a href="https://github.com/supermemoryai/supermemory/issues"&gt;Issues&lt;/a&gt; page for &lt;code&gt;good first issue&lt;/code&gt; and &lt;code&gt;help wanted&lt;/code&gt; labels to get started!&lt;/p&gt; 
&lt;h2&gt;Updates &amp;amp; Roadmap&lt;/h2&gt; 
&lt;p&gt;Stay up to date with the latest improvements:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.supermemory.ai/changelog/overview"&gt;Changelog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://x.com/supermemory"&gt;X&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>OneKeyHQ/app-monorepo</title>
      <link>https://github.com/OneKeyHQ/app-monorepo</link>
      <description>&lt;p&gt;Secure, open source and community driven crypto wallet runs on all platforms and trusted by millions.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;OneKey: Secure Crypto Wallet&lt;/h1&gt; 
&lt;p&gt;Anti-scam crypto wallet for every chain. Supports major blockchains like Bitcoin, Ethereum, Solana, Tron, BNB Smart Chain and more.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/OneKeyHQ/app-monorepo/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/OneKeyHQ/app-monorepo?t&amp;amp;logo=github&amp;amp;style=for-the-badge&amp;amp;labelColor=000" alt="Github Stars" /&gt;&lt;/a&gt; &lt;a href="https://github.com/OneKeyHQ/app-monorepo/releases"&gt;&lt;img src="https://img.shields.io/github/release/OneKeyHQ/app-monorepo.svg?style=for-the-badge&amp;amp;labelColor=000" alt="Version" /&gt;&lt;/a&gt; &lt;a href="https://github.com/OneKeyHQ/app-monorepo/graphs/contributors"&gt;&lt;img src="https://img.shields.io/github/contributors-anon/OneKeyHQ/app-monorepo?style=for-the-badge&amp;amp;labelColor=000" alt="" /&gt;&lt;/a&gt; &lt;a href="https://github.com/OneKeyHQ/app-monorepo/commits/onekey"&gt;&lt;img src="https://img.shields.io/github/last-commit/OneKeyHQ/app-monorepo.svg?style=for-the-badge&amp;amp;labelColor=000" alt="Last commit" /&gt;&lt;/a&gt; &lt;a href="https://github.com/OneKeyHQ/app-monorepo/issues?q=is%3Aissue+is%3Aopen"&gt;&lt;img src="https://img.shields.io/github/issues-raw/OneKeyHQ/app-monorepo.svg?style=for-the-badge&amp;amp;labelColor=000" alt="Issues" /&gt;&lt;/a&gt; &lt;a href="https://github.com/OneKeyHQ/app-monorepo/pulls?q=is%3Apr+is%3Aopen"&gt;&lt;img src="https://img.shields.io/github/issues-pr-raw/OneKeyHQ/app-monorepo.svg?style=for-the-badge&amp;amp;labelColor=000" alt="Pull Requests" /&gt;&lt;/a&gt; &lt;a href="https://twitter.com/OneKeyHQ"&gt;&lt;img src="https://img.shields.io/twitter/follow/OneKeyHQ?style=for-the-badge&amp;amp;labelColor=000" alt="Twitter Follow" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://apps.apple.com/us/app/onekey-open-source-wallet/id1609559473"&gt;&lt;img src="https://github.com/rayston92/graph_bed/raw/275d053220d5b54b32b01ce4c4985210951043c5/img/app_store.svg?sanitize=true" alt="Appstore" /&gt;&lt;/a&gt; &lt;a href="https://play.google.com/store/apps/details?id=so.onekey.app.wallet"&gt;&lt;img src="https://github.com/rayston92/graph_bed/raw/275d053220d5b54b32b01ce4c4985210951043c5/img/play.svg?sanitize=true" alt="Playstore" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://onekey.so/zh_CN/download?client=desktop"&gt;Desktop apps: macOS, Windows &amp;amp; Linux&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://onekey.so/zh_CN/download?client=browserExtension"&gt;Browser extensions: Chrome&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://onekey.so/zh_CN/download?client=bridge"&gt;Bridge&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Document&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://deepwiki.com/OneKeyHQ/app-monorepo"&gt;Deepwiki&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/7e1a9c12-f79d-49da-be8e-9a8de8252563" alt="CleanShot 2025-04-27 at 15 43 53@2x" /&gt;&lt;/p&gt; 
&lt;h2&gt;Community &amp;amp; Enterprise Edition&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;üè° üßîüèª‚Äç‚ôÇÔ∏è For Community Edition. It will always remain FREE FOREVER for open-source projects by individuals and communities.&lt;/li&gt; 
 &lt;li&gt;üè¶ üíº For Enterprise Edition. We've got this plan on the radar, but we're not quite ready yet. Just star our repo, and you'll be pinged as soon as we're all set.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Support&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/orgs/OneKeyHQ/discussions"&gt;Community Forum&lt;/a&gt;. Best for: help with building, discussion about best practices.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/OneKeyHQ/app-monorepo/issues"&gt;GitHub Issues&lt;/a&gt;. Best for: bugs and errors you encounter using OneKey.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Repo Status&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;‚úÖ Public: Production-ready&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;We really need your support, star or watch this repo for latest updates.&lt;/p&gt; 
&lt;p&gt;&lt;kbd&gt;&lt;img src="https://github.com/rayston92/graph_bed/raw/e3b2c938fc5b17d68531f69178908afb16266e6a/img/onekey_monorepo_star.gif?raw=true" alt="Star this repo" /&gt;&lt;/kbd&gt;&lt;/p&gt; 
&lt;h2&gt;üöÄ Getting Onboard&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;Install &lt;a href="https://nodejs.org/en/"&gt;node.js LTS version&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Install &lt;a href="https://yarnpkg.com/"&gt;yarn package management tool&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Install &lt;a href="https://git-lfs.github.com/"&gt;git lfs&lt;/a&gt; (some binaries are required for pulling and updating)&lt;/li&gt; 
 &lt;li&gt;To start the iOS project, make sure that the local XCode version is greater than or equal to 13.3&lt;/li&gt; 
 &lt;li&gt;To start the Android project, make sure that the local JDK version is greater than or equal to 11&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;After pulling the latest code via the git command line tool, install the project dependencies in the root directory via the &lt;code&gt;yarn&lt;/code&gt; command&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;yarn
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;üßë‚Äçüíª Develop&lt;/h2&gt; 
&lt;p&gt;Execute the following commands in the root directory to develop different business code&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;yarn app:web&lt;/code&gt;: Develop web mode, which starts a static server on port 3000 locally&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;yarn app:ios&lt;/code&gt;: connect to iphone device via USB for development debugging&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;yarn app:android&lt;/code&gt;: develop android&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;yarn app:desktop&lt;/code&gt;: development in desktop mode&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;yarn app:ext&lt;/code&gt;: development in extension mode&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üí¨ Docs in your languages&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Available Languages&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://raw.githubusercontent.com/OneKeyHQ/app-monorepo/x/docs/i18n/README.zh-cn.md"&gt;Simplified Chinese / ÁÆÄ‰Ωì‰∏≠Êñá&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://raw.githubusercontent.com/OneKeyHQ/app-monorepo/x/docs/i18n/README.de.md"&gt;German / Deutsch&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://raw.githubusercontent.com/OneKeyHQ/app-monorepo/x/docs/i18n/README.jp.md"&gt;Japanese / Êó•Êú¨Ë™û&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://raw.githubusercontent.com/OneKeyHQ/app-monorepo/x/docs/i18n/README.fr.md"&gt;French / Fran√ßais&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://raw.githubusercontent.com/OneKeyHQ/app-monorepo/x/docs/i18n/README.it.md"&gt;Italian / Italiano&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;ü™Ñ Repo Activity&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://repobeats.axiom.co/api/embed/5f8b83656094956b2d6274929f6eaa2e068a6cfb.svg?sanitize=true" alt="Repo Activity" title="Repobeats analytics image" /&gt;&lt;/p&gt; 
&lt;h2&gt;üî∞ Security&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Please read &lt;a href="https://github.com/OneKeyHQ/app-monorepo/raw/onekey/docs/BUG_RULES.md"&gt;Bug Bunty Rules&lt;/a&gt;, we have detailed the exact plan in this article.&lt;/li&gt; 
 &lt;li&gt;Please report suspected security vulnerabilities in private to &lt;a href="mailto:dev@onekey.so"&gt;dev@onekey.so&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Please do NOT create publicly viewable issues for suspected security vulnerabilities.&lt;/li&gt; 
 &lt;li&gt;As an open source project, although we are not yet profitable, we try to give some rewards to white hat hackers who disclose vulnerabilities to us in a timely manner.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üôã‚Äç‚ôÇÔ∏èWe're Hiring!&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th colspan="2"&gt; We are hiring many roles (Remote) &lt;a href="https://onekeyhq.atlassian.net/wiki/spaces/OC/overview"&gt;üëâ Click here to check all open positions&lt;/a&gt; &lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;li&gt;Remote (Live anywhere)&lt;/li&gt; &lt;li&gt;Global Pay (Literally)&lt;/li&gt; &lt;li&gt;ESOP (For everybody)&lt;/li&gt; &lt;li&gt;Open Source (As you see)&lt;/li&gt; &lt;li&gt;Awesome Colleagues (Hell Yeah!)&lt;/li&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;li&gt;ËøúÁ®ã (ÁîüÊ¥ªÂú®Âì™‰∏™ÂüéÂ∏ÇÈÉΩÂèØ‰ª•)&lt;/li&gt; &lt;li&gt;ÂÖ®ÁêÉ‰∏ÄËá¥ÁöÑËñ™ÈÖ¨ (ÁúüÁöÑ)&lt;/li&gt; &lt;li&gt;ÂÖ®ÂëòÊåÅËÇ°ËÆ°Âàí (ÊØè‰∏™‰∫∫ÈÉΩÊúâ)&lt;/li&gt; &lt;li&gt;ÂºÄÊ∫ê (Â¶Ç‰Ω†ÊâÄËßÅ)&lt;/li&gt; &lt;li&gt;Ë∂ÖÁ∫ßÊ£íÁöÑÂêå‰∫ã (ÁàΩÂëÜ!)&lt;/li&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;‚ú® Salute!&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://github.com/OneKeyHQ/app-monorepo/graphs/contributors"&gt;&lt;img src="https://img.shields.io/github/contributors-anon/OneKeyHQ/app-monorepo?style=for-the-badge&amp;amp;labelColor=000" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;a href="https://github.com/onekeyhq/app-monorepo/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=onekeyhq/app-monorepo&amp;amp;max=240&amp;amp;columns=24" /&gt; &lt;/a&gt;</description>
    </item>
    
    <item>
      <title>microsoft/vscode-copilot-chat</title>
      <link>https://github.com/microsoft/vscode-copilot-chat</link>
      <description>&lt;p&gt;Copilot Chat extension for VS Code&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;GitHub Copilot - Your AI peer programmer&lt;/h1&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://code.visualstudio.com/docs/copilot/overview"&gt;GitHub Copilot&lt;/a&gt;&lt;/strong&gt; is an AI peer programming tool that helps you write code faster and smarter.&lt;/p&gt; 
&lt;p&gt;GitHub Copilot adapts to your unique needs allowing you to select the best model for your project, customize chat responses with custom instructions, and utilize agent mode for AI-powered, seamlessly integrated peer programming sessions.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Sign up for &lt;a href="https://github.com/settings/copilot?utm_source=vscode-chat-readme&amp;amp;utm_medium=first&amp;amp;utm_campaign=2025mar-em-MSFT-signup"&gt;GitHub Copilot Free&lt;/a&gt;!&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/microsoft/vscode-copilot-release/raw/main/images/hero-dark.png?raw=true" alt="Working with GitHub Copilot agent mode to make edits to code in your workspace" /&gt;&lt;/p&gt; 
&lt;p&gt;When you install Copilot in Visual Studio Code, you get two extensions:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://marketplace.visualstudio.com/items?itemName=GitHub.copilot"&gt;GitHub Copilot&lt;/a&gt;&lt;/strong&gt; - Provides inline coding suggestions as you type.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://marketplace.visualstudio.com/items?itemName=GitHub.copilot-chat"&gt;GitHub Copilot Chat&lt;/a&gt;&lt;/strong&gt; (this extension) - A companion extension that provides conversational AI assistance.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Getting access to GitHub Copilot&lt;/h2&gt; 
&lt;p&gt;Sign up for &lt;a href="https://github.com/settings/copilot?utm_source=vscode-chat-readme&amp;amp;utm_medium=second&amp;amp;utm_campaign=2025mar-em-MSFT-signup"&gt;GitHub Copilot Free&lt;/a&gt;, or request access from your enterprise admin.&lt;/p&gt; 
&lt;p&gt;To access GitHub Copilot, an active GitHub Copilot subscription is required. You can read more about our business and individual offerings at &lt;a href="https://github.com/features/copilot?utm_source=vscode-chat&amp;amp;utm_medium=readme&amp;amp;utm_campaign=2025mar-em-MSFT-signup"&gt;github.com/features/copilot&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;AI-powered coding sessions&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Start an AI-powered coding session tailored to your workflow&lt;/strong&gt;. Copilot Edits allows you to quickly iterate on code changes directly in the editor, across multiple files using natural language. For a more autonomous peer programmer experience, &lt;a href="https://aka.ms/vscode-copilot-agent"&gt;agent mode&lt;/a&gt; performs multi-step coding tasks at your command. It automatically handles compile and lint errors, monitors terminal and test output, and iterates until the task is complete. &lt;a href="https://aka.ms/vscode-copilot-edit"&gt;Edit mode&lt;/a&gt; offers a conversational, step-by-step coding experience. Engage in multi-turn chat conversations while Copilot applies edits directly to your codebase, allowing you to review changes in context and maintain full control.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/microsoft/vscode-copilot-release/raw/main/images/agent-mode-readme.gif?raw=true" alt="Agent mode in Copilot Chat creating a new Vue application" /&gt;&lt;/p&gt; 
&lt;h2&gt;Inline suggestions in the editor&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Automatically receive inline suggestions in the editor&lt;/strong&gt; from &lt;a href="https://aka.ms/vscode-completions"&gt;ghost text suggestions&lt;/a&gt; and &lt;a href="https://aka.ms/vscode-nes"&gt;next edit suggestions&lt;/a&gt; to help you write code faster. Ghost text suggestions provide suggestions at the current location, tailored to your coding style and your existing code. Copilot next edit suggestions (Copilot NES) takes it a step further and predicts what and where your next logical code change will be. Use the Tab key to navigate and accept changes in quick succession.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://code.visualstudio.com/assets/docs/copilot/inline-suggestions/nes-point.gif" alt="Copilot next edit suggestions" /&gt;&lt;/p&gt; 
&lt;h2&gt;Ask and learn about your code with chat&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Ask Copilot for help with any task or question&lt;/strong&gt; in the &lt;a href="https://aka.ms/vscode-chat"&gt;Chat view&lt;/a&gt;, bringing in code from your current files. Rather than giving you a generic answer, it can give answers that are relevant for your codebase using information provided by &lt;a href="https://aka.ms/vscode-chat-participants"&gt;participants&lt;/a&gt;, &lt;a href="https://aka.ms/vscode-chat-variables"&gt;variables&lt;/a&gt;, and &lt;a href="https://aka.ms/vscode-chat-commands"&gt;slash commands&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/microsoft/vscode-copilot-release/raw/main/images/participants-workspace.gif?raw=true" alt="Using the workspace chat participant" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Apply Copilot's AI suggestions directly to your code&lt;/strong&gt; using &lt;a href="https://aka.ms/vscode-inline-chat"&gt;Inline chat&lt;/a&gt;, staying in the flow. Need help with refactoring a method, adding error handling, or explaining a complex algorithm - just launch Copilot in the editor!&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://code.visualstudio.com/assets/docs/copilot/copilot-chat/inline-chat-question-example.png" alt="Inline chat in VS Code" /&gt;&lt;/p&gt; 
&lt;h3&gt;Supported languages and frameworks&lt;/h3&gt; 
&lt;p&gt;GitHub Copilot works on any language, including Java, PHP, Python, JavaScript, Ruby, Go, C#, or C++. Because it‚Äôs been trained on languages in public repositories, it works for most popular languages, libraries and frameworks.&lt;/p&gt; 
&lt;h3&gt;Version compatibility&lt;/h3&gt; 
&lt;p&gt;As Copilot Chat releases in lockstep with VS Code due to its deep UI integration, every new version of Copilot Chat is only compatible with the latest and newest release of VS Code. This means that if you are using an older version of VS Code, you will not be able to use the latest Copilot Chat.&lt;/p&gt; 
&lt;p&gt;Only the latest Copilot Chat versions will use the latest models provided by the Copilot service, as even minor model upgrades require prompt changes and fixes in the extension.&lt;/p&gt; 
&lt;h3&gt;Privacy and preview terms&lt;/h3&gt; 
&lt;p&gt;By using Copilot Chat you agree to &lt;a href="https://docs.github.com/en/early-access/copilot/github-copilot-chat-technical-preview-license-terms"&gt;GitHub Copilot chat preview terms&lt;/a&gt;. Review the &lt;a href="https://aka.ms/CopilotChatTransparencyNote"&gt;transparency note&lt;/a&gt; to understand about usage, limitations and ways to improve Copilot Chat during the technical preview.&lt;/p&gt; 
&lt;p&gt;Your code is yours. We follow responsible practices in accordance with our &lt;a href="https://docs.github.com/en/site-policy/privacy-policies/github-privacy-statement"&gt;Privacy Statement&lt;/a&gt; to ensure that your code snippets will not be used as suggested code for other users of GitHub Copilot.&lt;/p&gt; 
&lt;p&gt;To get the latest security fixes, please use the latest version of the Copilot extension and VS Code.&lt;/p&gt; 
&lt;h3&gt;Resources &amp;amp; next steps&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Sign up for &lt;a href="https://github.com/settings/copilot?utm_source=vscode-chat-readme&amp;amp;utm_medium=third&amp;amp;utm_campaign=2025mar-em-MSFT-signup"&gt;GitHub Copilot Free&lt;/a&gt;&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;If you're using Copilot for your business, check out &lt;a href="https://docs.github.com/en/copilot/copilot-business/about-github-copilot-business"&gt;Copilot Business&lt;/a&gt; and &lt;a href="https://docs.github.com/en/copilot/github-copilot-enterprise/overview/about-github-copilot-enterprise"&gt;Copilot Enterprise&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://code.visualstudio.com/docs/copilot/getting-started"&gt;Get started with Copilot in VS Code tutorial&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://www.youtube.com/watch?v=3surPGP7_4o"&gt;Copilot Chat quickstart video&lt;/a&gt;&lt;/strong&gt; to learn Copilot Chat in less than 4 minutes&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://www.youtube.com/playlist?list=PLj6YeMhvp2S5_hvBl2SE-7YCHYlLQ0bPt"&gt;VS Code Copilot Series on YouTube&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://code.visualstudio.com/docs/copilot/faq"&gt;FAQ&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/microsoft/vscode-copilot-release/issues"&gt;Feedback&lt;/a&gt;&lt;/strong&gt;: We'd love to get your help in making GitHub Copilot better!&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Data and telemetry&lt;/h2&gt; 
&lt;p&gt;The GitHub Copilot Extension for Visual Studio Code collects usage data and sends it to Microsoft to help improve our products and services. Read our &lt;a href="https://privacy.microsoft.com/privacystatement"&gt;privacy statement&lt;/a&gt; to learn more. This extension respects the &lt;code&gt;telemetry.telemetryLevel&lt;/code&gt; setting which you can learn more about at &lt;a href="https://code.visualstudio.com/docs/supporting/faq#_how-to-disable-telemetry-reporting"&gt;https://code.visualstudio.com/docs/supporting/faq#_how-to-disable-telemetry-reporting&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Trademarks&lt;/h2&gt; 
&lt;p&gt;This project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft trademarks or logos is subject to and must follow Microsoft's Trademark &amp;amp; Brand Guidelines. Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship. Any use of third-party trademarks or logos are subject to those third-party's policies.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Copyright (c) Microsoft Corporation. All rights reserved.&lt;/p&gt; 
&lt;p&gt;Licensed under the &lt;a href="https://raw.githubusercontent.com/microsoft/vscode-copilot-chat/main/LICENSE.txt"&gt;MIT&lt;/a&gt; license.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>resend/react-email</title>
      <link>https://github.com/resend/react-email</link>
      <description>&lt;p&gt;üíå Build and send emails using React&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src="https://react.email/static/covers/react-email.png" alt="React email cover" /&gt;&lt;/p&gt; 
&lt;div align="center"&gt;
 &lt;strong&gt;React Email&lt;/strong&gt;
&lt;/div&gt; 
&lt;div align="center"&gt;
 The next generation of writing emails.
 &lt;br /&gt;High-quality, unstyled components for creating emails.
&lt;/div&gt; 
&lt;br /&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://react.email"&gt;Website&lt;/a&gt; 
 &lt;span&gt; ¬∑ &lt;/span&gt; 
 &lt;a href="https://github.com/resend/react-email"&gt;GitHub&lt;/a&gt; 
&lt;/div&gt; 
&lt;h2&gt;Introduction&lt;/h2&gt; 
&lt;p&gt;A collection of high-quality, unstyled components for creating beautiful emails using React and TypeScript. It reduces the pain of coding responsive emails with dark mode support. It also takes care of inconsistencies between Gmail, Outlook, and other email clients for you.&lt;/p&gt; 
&lt;h2&gt;Why&lt;/h2&gt; 
&lt;p&gt;We believe that email is an extremely important medium for people to communicate. However, we need to stop developing emails like 2010, and rethink how email can be done in 2025 and beyond. Email development needs a revamp. A renovation. Modernized for the way we build web apps today.&lt;/p&gt; 
&lt;h2&gt;Install&lt;/h2&gt; 
&lt;p&gt;Install one of the components from your command line.&lt;/p&gt; 
&lt;h4&gt;With yarn&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;yarn add @react-email/components -E
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;With npm&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;npm install @react-email/components -E
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;With pnpm&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;pnpm install @react-email/components -E
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Getting started&lt;/h2&gt; 
&lt;p&gt;Add the component to your email template. Include styles where needed.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-jsx"&gt;import { Button } from "@react-email/components";

const Email = () =&amp;gt; {
  return (
    &amp;lt;Button href="https://example.com" style={{ color: "#61dafb" }}&amp;gt;
      Click me
    &amp;lt;/Button&amp;gt;
  );
};
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Components&lt;/h2&gt; 
&lt;p&gt;A set of standard components to help you build amazing emails without having to deal with the mess of creating table-based layouts and maintaining archaic markup.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/resend/react-email/tree/main/packages/body"&gt;Body&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/resend/react-email/tree/main/packages/button"&gt;Button&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/resend/react-email/tree/main/packages/code-block"&gt;CodeBlock&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/resend/react-email/tree/main/packages/code-inline"&gt;CodeInline&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/resend/react-email/tree/main/packages/column"&gt;Column&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/resend/react-email/tree/main/packages/container"&gt;Container&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/resend/react-email/tree/main/packages/hr"&gt;Divider&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/resend/react-email/tree/main/packages/font"&gt;Font&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/resend/react-email/tree/main/packages/head"&gt;Head&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/resend/react-email/tree/main/packages/heading"&gt;Heading&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/resend/react-email/tree/main/packages/html"&gt;Html&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/resend/react-email/tree/main/packages/img"&gt;Image&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/resend/react-email/tree/main/packages/link"&gt;Link&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/resend/react-email/tree/main/packages/markdown"&gt;Markdown&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/resend/react-email/tree/main/packages/text"&gt;Paragraph&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/resend/react-email/tree/main/packages/preview"&gt;Preview&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/resend/react-email/tree/main/packages/section"&gt;Section&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Integrations&lt;/h2&gt; 
&lt;p&gt;Emails built with React Email can be converted into HTML and sent using any email service provider. Here are some examples:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/resend/react-email/tree/main/examples/resend"&gt;Resend&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/resend/react-email/tree/main/examples/nodemailer"&gt;Nodemailer&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/resend/react-email/tree/main/examples/sendgrid"&gt;SendGrid&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/resend/react-email/tree/main/examples/postmark"&gt;Postmark&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/resend/react-email/tree/main/examples/aws-ses"&gt;AWS SES&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/resend/react-email/tree/main/examples/plunk"&gt;Plunk&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/resend/react-email/tree/main/examples/scaleway"&gt;Scaleway&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Support&lt;/h2&gt; 
&lt;p&gt;All components were tested using the most popular email clients.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;&lt;img src="https://react.email/static/icons/gmail.svg?sanitize=true" width="48px" height="48px" alt="Gmail logo" /&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;img src="https://react.email/static/icons/apple-mail.svg?sanitize=true" width="48px" height="48px" alt="Apple Mail" /&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;img src="https://react.email/static/icons/outlook.svg?sanitize=true" width="48px" height="48px" alt="Outlook logo" /&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;img src="https://react.email/static/icons/yahoo-mail.svg?sanitize=true" width="48px" height="48px" alt="Yahoo! Mail logo" /&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;img src="https://react.email/static/icons/hey.svg?sanitize=true" width="48px" height="48px" alt="HEY logo" /&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;img src="https://react.email/static/icons/superhuman.svg?sanitize=true" width="48px" height="48px" alt="Superhuman logo" /&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Gmail ‚úî&lt;/td&gt; 
   &lt;td&gt;Apple Mail ‚úî&lt;/td&gt; 
   &lt;td&gt;Outlook ‚úî&lt;/td&gt; 
   &lt;td&gt;Yahoo! Mail ‚úî&lt;/td&gt; 
   &lt;td&gt;HEY ‚úî&lt;/td&gt; 
   &lt;td&gt;Superhuman ‚úî&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Development workflow&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;a href="https://react.email/docs/contributing/development-workflow/1-setup"&gt;Setting up your development environment&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://react.email/docs/contributing/development-workflow/2-running-tests"&gt;Running tests&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://react.email/docs/contributing/development-workflow/3-linting"&gt;Linting&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://react.email/docs/contributing/development-workflow/4-building"&gt;Building&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://react.email/docs/contributing/development-workflow/5-writing-docs"&gt;Writing documentation&lt;/a&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://react.email/docs/contributing"&gt;Contribution Guide&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Authors&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Bu Kinoshita (&lt;a href="https://twitter.com/bukinoshita"&gt;@bukinoshita&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;Zeno Rocha (&lt;a href="https://twitter.com/zenorocha"&gt;@zenorocha&lt;/a&gt;)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;MIT License&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Vendicated/Vencord</title>
      <link>https://github.com/Vendicated/Vencord</link>
      <description>&lt;p&gt;The cutest Discord modification&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Vencord&lt;/h1&gt; 
&lt;p&gt;&lt;img src="https://img.shields.io/github/package-json/v/Vendicated/Vencord?style=for-the-badge&amp;amp;logo=github&amp;amp;logoColor=d3869b&amp;amp;label=&amp;amp;color=1d2021&amp;amp;labelColor=282828" alt="" /&gt; &lt;a href="https://codeberg.org/Vee/cord"&gt;&lt;img src="https://img.shields.io/static/v1?style=for-the-badge&amp;amp;label=Codeberg%20Mirror&amp;amp;message=codeberg.org/Vee/cord&amp;amp;color=2185D0&amp;amp;logo=data:image/png;base64,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" alt="Codeberg Mirror" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;The cutest Discord client mod&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/3fac98c0-c411-4d2a-97a3-13b7da8687a2" alt="" /&gt;&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Easy to install&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://vencord.dev/plugins"&gt;100+ built in plugins&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Fairly lightweight despite the many inbuilt plugins&lt;/li&gt; 
 &lt;li&gt;Excellent Browser Support: Run Vencord in your Browser via extension or UserScript&lt;/li&gt; 
 &lt;li&gt;Works on any Discord branch: Stable, Canary or PTB all work&lt;/li&gt; 
 &lt;li&gt;Custom CSS and Themes: Inbuilt css editor with support to import any css files (including BetterDiscord themes)&lt;/li&gt; 
 &lt;li&gt;Privacy friendly: blocks Discord analytics &amp;amp; crash reporting out of the box and has no telemetry&lt;/li&gt; 
 &lt;li&gt;Maintained very actively, broken plugins are usually fixed within 12 hours&lt;/li&gt; 
 &lt;li&gt;Settings sync: Keep your plugins and their settings synchronised between devices / apps (optional)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Installing / Uninstalling&lt;/h2&gt; 
&lt;p&gt;Visit &lt;a href="https://vencord.dev/download"&gt;https://vencord.dev/download&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Join our Support/Community Server&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://discord.gg/D9uwnFnqmd"&gt;https://discord.gg/D9uwnFnqmd&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Sponsors&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="center"&gt;&lt;strong&gt;Thanks a lot to all Vencord &lt;a href="https://github.com/sponsors/Vendicated"&gt;sponsors&lt;/a&gt;!!&lt;/strong&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/sponsors/Vendicated"&gt;&lt;img src="https://meow.vendicated.dev/sponsors.png" alt="" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;em&gt;generated using &lt;a href="https://github.com/Vendicated/github-sponsor-graph"&gt;github-sponsor-graph&lt;/a&gt;&lt;/em&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Star History&lt;/h2&gt; 
&lt;a href="https://star-history.com/#Vendicated/Vencord&amp;amp;Timeline"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://api.star-history.com/svg?repos=Vendicated/Vencord&amp;amp;type=Timeline&amp;amp;theme=dark" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://api.star-history.com/svg?repos=Vendicated/Vencord&amp;amp;type=Timeline" /&gt; 
  &lt;img alt="Star History Chart" src="https://api.star-history.com/svg?repos=Vendicated/Vencord&amp;amp;type=Timeline" /&gt; 
 &lt;/picture&gt; &lt;/a&gt; 
&lt;h2&gt;Disclaimer&lt;/h2&gt; 
&lt;p&gt;Discord is trademark of Discord Inc. and solely mentioned for the sake of descriptivity. Mention of it does not imply any affiliation with or endorsement by Discord Inc.&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;Using Vencord violates Discord's terms of service&lt;/summary&gt; 
 &lt;p&gt;Client modifications are against Discord‚Äôs Terms of Service.&lt;/p&gt; 
 &lt;p&gt;However, Discord is pretty indifferent about them and there are no known cases of users getting banned for using client mods! So you should generally be fine as long as you don‚Äôt use any plugins that implement abusive behaviour. But no worries, all inbuilt plugins are safe to use!&lt;/p&gt; 
 &lt;p&gt;Regardless, if your account is very important to you and it getting disabled would be a disaster for you, you should probably not use any client mods (not exclusive to Vencord), just to be safe&lt;/p&gt; 
 &lt;p&gt;Additionally, make sure not to post screenshots with Vencord in a server where you might get banned for it&lt;/p&gt; 
&lt;/details&gt;</description>
    </item>
    
  </channel>
</rss>