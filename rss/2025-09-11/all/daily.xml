<rss version="2.0">
  <channel>
    <title>GitHub All Languages Daily Trending</title>
    <description>Daily Trending of All Languages in GitHub</description>
    <pubDate>Wed, 10 Sep 2025 01:30:57 GMT</pubDate>
    <link>http://mshibanami.github.io/GitHubTrendingRSS</link>
    
    <item>
      <title>emcie-co/parlant</title>
      <link>https://github.com/emcie-co/parlant</link>
      <description>&lt;p&gt;LLM agents built for control. Designed for real-world use. Deployed in minutes.&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://github.com/emcie-co/parlant/blob/develop/docs/LogoTransparentLight.png?raw=true" /&gt; 
  &lt;img alt="Parlant - AI Agent Framework" src="https://github.com/emcie-co/parlant/raw/develop/docs/LogoTransparentDark.png?raw=true" width="400" /&gt; 
 &lt;/picture&gt; 
 &lt;h3&gt;Finally, LLM agents that actually follow instructions&lt;/h3&gt; 
 &lt;p&gt; &lt;a href="https://www.parlant.io/" target="_blank"&gt;ğŸŒ Website&lt;/a&gt; â€¢ &lt;a href="https://www.parlant.io/docs/quickstart/installation" target="_blank"&gt;âš¡ Quick Start&lt;/a&gt; â€¢ &lt;a href="https://discord.gg/duxWqxKk6J" target="_blank"&gt;ğŸ’¬ Discord&lt;/a&gt; â€¢ &lt;a href="https://www.parlant.io/docs/quickstart/examples" target="_blank"&gt;ğŸ“– Examples&lt;/a&gt; &lt;/p&gt; 
 &lt;p&gt; 
  &lt;!-- Keep these links. Translations will automatically update with the README. --&gt; &lt;a href="https://zdoc.app/de/emcie-co/parlant"&gt;Deutsch&lt;/a&gt; | &lt;a href="https://zdoc.app/es/emcie-co/parlant"&gt;EspaÃ±ol&lt;/a&gt; | &lt;a href="https://zdoc.app/fr/emcie-co/parlant"&gt;franÃ§ais&lt;/a&gt; | &lt;a href="https://zdoc.app/ja/emcie-co/parlant"&gt;æ—¥æœ¬èª&lt;/a&gt; | &lt;a href="https://zdoc.app/ko/emcie-co/parlant"&gt;í•œêµ­ì–´&lt;/a&gt; | &lt;a href="https://zdoc.app/pt/emcie-co/parlant"&gt;PortuguÃªs&lt;/a&gt; | &lt;a href="https://zdoc.app/ru/emcie-co/parlant"&gt;Ğ ÑƒÑÑĞºĞ¸Ğ¹&lt;/a&gt; | &lt;a href="https://zdoc.app/zh/emcie-co/parlant"&gt;ä¸­æ–‡&lt;/a&gt; &lt;/p&gt; 
 &lt;p&gt; &lt;a href="https://pypi.org/project/parlant/"&gt;&lt;img alt="PyPI" src="https://img.shields.io/pypi/v/parlant?color=blue" /&gt;&lt;/a&gt; &lt;img alt="Python 3.10+" src="https://img.shields.io/badge/python-3.10+-blue" /&gt; &lt;a href="https://opensource.org/licenses/Apache-2.0"&gt;&lt;img alt="License" src="https://img.shields.io/badge/license-Apache%202.0-green" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/duxWqxKk6J"&gt;&lt;img alt="Discord" src="https://img.shields.io/discord/1312378700993663007?color=7289da&amp;amp;logo=discord&amp;amp;logoColor=white" /&gt;&lt;/a&gt; &lt;img alt="GitHub Repo stars" src="https://img.shields.io/github/stars/emcie-co/parlant?style=social" /&gt; &lt;/p&gt; 
 &lt;a href="https://trendshift.io/repositories/12768" target="_blank"&gt; &lt;img src="https://trendshift.io/api/badge/repositories/12768" alt="Trending on TrendShift" style="width: 250px; height: 55px;" width="250" height="55" /&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;h2&gt;ğŸ¯ The Problem Every AI Developer Faces&lt;/h2&gt; 
&lt;p&gt;You build an AI agent. It works great in testing. Then real users start talking to it and...&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;âŒ It ignores your carefully crafted system prompts&lt;/li&gt; 
 &lt;li&gt;âŒ It hallucinates responses in critical moments&lt;/li&gt; 
 &lt;li&gt;âŒ It can't handle edge cases consistently&lt;/li&gt; 
 &lt;li&gt;âŒ Each conversation feels like a roll of the dice&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Sound familiar?&lt;/strong&gt; You're not alone. This is the #1 pain point for developers building production AI agents.&lt;/p&gt; 
&lt;h2&gt;âš¡ The Solution: Stop Fighting Prompts, Teach Principles&lt;/h2&gt; 
&lt;p&gt;Parlant flips the script on AI agent development. Instead of hoping your LLM will follow instructions, &lt;strong&gt;Parlant ensures it&lt;/strong&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# Traditional approach: Cross your fingers ğŸ¤
system_prompt = "You are a helpful assistant. Please follow these 47 rules..."

# Parlant approach: Ensured compliance âœ…
await agent.create_guideline(
    condition="Customer asks about refunds",
    action="Check order status first to see if eligible",
    tools=[check_order_status],
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;a href="https://www.parlant.io/blog/how-parlant-guarantees-compliance"&gt;âœ… Blog: How Parlant Ensures Agent Compliance&lt;/a&gt;&lt;/p&gt; 
&lt;h4&gt;Parlant gives you all the structure you need to build customer-facing agents that behave exactly as your business requires:&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://parlant.io/docs/concepts/customization/journeys"&gt;Journeys&lt;/a&gt;&lt;/strong&gt;: Define clear customer journeys and how your agent should respond at each step.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://parlant.io/docs/concepts/customization/guidelines"&gt;Behavioral Guidelines&lt;/a&gt;&lt;/strong&gt;: Easily craft agent behavior; Parlant will match the relevant elements contextually.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://parlant.io/docs/concepts/customization/tools"&gt;Tool Use&lt;/a&gt;&lt;/strong&gt;: Attach external APIs, data fetchers, or backend services to specific interaction events.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://parlant.io/docs/concepts/customization/glossary"&gt;Domain Adaptation&lt;/a&gt;&lt;/strong&gt;: Teach your agent domain-specific terminology and craft personalized responses.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://parlant.io/docs/concepts/customization/canned-responses"&gt;Canned Responses&lt;/a&gt;&lt;/strong&gt;: Use response templates to eliminate hallucinations and guarantee style consistency.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://parlant.io/docs/advanced/explainability"&gt;Explainability&lt;/a&gt;&lt;/strong&gt;: Understand why and when each guideline was matched and followed.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;div align="center"&gt; 
 &lt;h2&gt;ğŸš€ Get Your Agent Running in 60 Seconds&lt;/h2&gt; 
&lt;/div&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install parlant
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import parlant.sdk as p

@p.tool
async def get_weather(context: p.ToolContext, city: str) -&amp;gt; p.ToolResult:
    # Your weather API logic here
    return p.ToolResult(f"Sunny, 72Â°F in {city}")

@p.tool
async def get_datetime(context: p.ToolContext) -&amp;gt; p.ToolResult:
    from datetime import datetime
    return p.ToolResult(datetime.now())

async def main():
    async with p.Server() as server:
        agent = await server.create_agent(
            name="WeatherBot",
            description="Helpful weather assistant"
        )

        # Have the agent's context be updated on every response (though
        # update interval is customizable) using a context variable.
        await agent.create_variable(name="current-datetime", tool=get_datetime)

        # Control and guide agent behavior with natural language
        await agent.create_guideline(
            condition="User asks about weather",
            action="Get current weather and provide a friendly response with suggestions",
            tools=[get_weather]
        )

        # Add other (reliably enforced) behavioral modeling elements
        # ...

        # ğŸ‰ Test playground ready at http://localhost:8800
        # Integrate the official React widget into your app,
        # or follow the tutorial to build your own frontend!

if __name__ == "__main__":
    import asyncio
    asyncio.run(main())
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;That's it!&lt;/strong&gt; Your agent is running with ensured rule-following behavior.&lt;/p&gt; 
&lt;h2&gt;ğŸ¬ See It In Action&lt;/h2&gt; 
&lt;img alt="Parlant Demo" src="https://github.com/emcie-co/parlant/raw/develop/docs/demo.gif?raw=true" width="100%" /&gt; 
&lt;h2&gt;ğŸ”¥ Why Developers Are Switching to Parlant&lt;/h2&gt; 
&lt;table width="100%"&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td width="50%"&gt; &lt;h3&gt;ğŸ—ï¸ &lt;strong&gt;Traditional AI Frameworks&lt;/strong&gt;&lt;/h3&gt; &lt;/td&gt; 
   &lt;td width="50%"&gt; &lt;h3&gt;âš¡ &lt;strong&gt;Parlant&lt;/strong&gt;&lt;/h3&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="50%"&gt; 
    &lt;ul&gt; 
     &lt;li&gt;Write complex system prompts&lt;/li&gt; 
     &lt;li&gt;Hope the LLM follows them&lt;/li&gt; 
     &lt;li&gt;Debug unpredictable behaviors&lt;/li&gt; 
     &lt;li&gt;Scale by prompt engineering&lt;/li&gt; 
     &lt;li&gt;Cross fingers for reliability&lt;/li&gt; 
    &lt;/ul&gt; &lt;/td&gt; 
   &lt;td width="50%"&gt; 
    &lt;ul&gt; 
     &lt;li&gt;Define rules in natural language&lt;/li&gt; 
     &lt;li&gt;&lt;strong&gt;Ensured&lt;/strong&gt; rule compliance&lt;/li&gt; 
     &lt;li&gt;Predictable, consistent behavior&lt;/li&gt; 
     &lt;li&gt;Scale by adding guidelines&lt;/li&gt; 
     &lt;li&gt;Production-ready from day one&lt;/li&gt; 
    &lt;/ul&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h2&gt;ğŸ¯ Perfect For Your Use Case&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th align="center"&gt;&lt;strong&gt;Financial Services&lt;/strong&gt;&lt;/th&gt; 
    &lt;th align="center"&gt;&lt;strong&gt;Healthcare&lt;/strong&gt;&lt;/th&gt; 
    &lt;th align="center"&gt;&lt;strong&gt;E-commerce&lt;/strong&gt;&lt;/th&gt; 
    &lt;th align="center"&gt;&lt;strong&gt;Legal Tech&lt;/strong&gt;&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;Compliance-first design&lt;/td&gt; 
    &lt;td align="center"&gt;HIPAA-ready agents&lt;/td&gt; 
    &lt;td align="center"&gt;Customer service at scale&lt;/td&gt; 
    &lt;td align="center"&gt;Precise legal guidance&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;Built-in risk management&lt;/td&gt; 
    &lt;td align="center"&gt;Patient data protection&lt;/td&gt; 
    &lt;td align="center"&gt;Order processing automation&lt;/td&gt; 
    &lt;td align="center"&gt;Document review assistance&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/div&gt; 
&lt;h2&gt;ğŸ› ï¸ Enterprise-Grade Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ§­ Conversational Journeys&lt;/strong&gt; - Lead the customer step-by-step to a goal&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ¯ Dynamic Guideline Matching&lt;/strong&gt; - Context-aware rule application&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ”§ Reliable Tool Integration&lt;/strong&gt; - APIs, databases, external services&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ“Š Conversation Analytics&lt;/strong&gt; - Deep insights into agent behavior&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ”„ Iterative Refinement&lt;/strong&gt; - Continuously improve agent responses&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ›¡ï¸ Built-in Guardrails&lt;/strong&gt; - Prevent hallucination and off-topic responses&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ“± React Widget&lt;/strong&gt; - &lt;a href="https://github.com/emcie-co/parlant-chat-react"&gt;Drop-in chat UI for any web app&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ” Full Explainability&lt;/strong&gt; - Understand every decision your agent makes&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ğŸ“ˆ Join 10,000+ Developers Building Better AI&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;strong&gt;Companies using Parlant:&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;Financial institutions â€¢ Healthcare providers â€¢ Legal firms â€¢ E-commerce platforms&lt;/em&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://star-history.com/#emcie-co/parlant&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=emcie-co/parlant&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;ğŸŒŸ What Developers Are Saying&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;em&gt;"By far the most elegant conversational AI framework that I've come across! Developing with Parlant is pure joy."&lt;/em&gt; &lt;strong&gt;â€” Vishal Ahuja, Senior Lead, Customer-Facing Conversational AI @ JPMorgan Chase&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;ğŸƒâ€â™‚ï¸ Quick Start Paths&lt;/h2&gt; 
&lt;table border="0"&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;ğŸ¯ I want to test it myself&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.parlant.io/docs/quickstart/installation"&gt;â†’ 5-minute quickstart&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;ğŸ› ï¸ I want to see an example&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.parlant.io/docs/quickstart/examples"&gt;â†’ Healthcare agent example&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;ğŸš€ I want to get involved&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://discord.gg/duxWqxKk6J"&gt;â†’ Join our Discord community&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h2&gt;ğŸ¤ Community &amp;amp; Support&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;ğŸ’¬ &lt;strong&gt;&lt;a href="https://discord.gg/duxWqxKk6J"&gt;Discord Community&lt;/a&gt;&lt;/strong&gt; - Get help from the team and community&lt;/li&gt; 
 &lt;li&gt;ğŸ“– &lt;strong&gt;&lt;a href="https://parlant.io/docs/quickstart/installation"&gt;Documentation&lt;/a&gt;&lt;/strong&gt; - Comprehensive guides and examples&lt;/li&gt; 
 &lt;li&gt;ğŸ› &lt;strong&gt;&lt;a href="https://github.com/emcie-co/parlant/issues"&gt;GitHub Issues&lt;/a&gt;&lt;/strong&gt; - Bug reports and feature requests&lt;/li&gt; 
 &lt;li&gt;ğŸ“§ &lt;strong&gt;&lt;a href="https://parlant.io/contact"&gt;Direct Support&lt;/a&gt;&lt;/strong&gt; - Direct line to our engineering team&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ğŸ“„ License&lt;/h2&gt; 
&lt;p&gt;Apache 2.0 - Use it anywhere, including commercial projects.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;strong&gt;Ready to build AI agents that actually work?&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;â­ &lt;strong&gt;Star this repo&lt;/strong&gt; â€¢ ğŸš€ &lt;strong&gt;&lt;a href="https://parlant.io/"&gt;Try Parlant now&lt;/a&gt;&lt;/strong&gt; â€¢ ğŸ’¬ &lt;strong&gt;&lt;a href="https://discord.gg/duxWqxKk6J"&gt;Join Discord&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;Built with â¤ï¸ by the team at &lt;a href="https://emcie.co"&gt;Emcie&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>immich-app/immich</title>
      <link>https://github.com/immich-app/immich</link>
      <description>&lt;p&gt;High performance self-hosted photo and video management solution.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;br /&gt; &lt;a href="https://opensource.org/license/agpl-v3"&gt;&lt;img src="https://img.shields.io/badge/License-AGPL_v3-blue.svg?color=3F51B5&amp;amp;style=for-the-badge&amp;amp;label=License&amp;amp;logoColor=000000&amp;amp;labelColor=ececec" alt="License: AGPLv3" /&gt;&lt;/a&gt; &lt;a href="https://discord.immich.app"&gt; &lt;img src="https://img.shields.io/discord/979116623879368755.svg?label=Discord&amp;amp;logo=Discord&amp;amp;style=for-the-badge&amp;amp;logoColor=000000&amp;amp;labelColor=ececec" alt="Discord" /&gt; &lt;/a&gt; &lt;br /&gt; &lt;br /&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/immich-app/immich/main/design/immich-logo-stacked-light.svg?sanitize=true" width="300" title="Login With Custom URL" /&gt; &lt;/p&gt; 
&lt;h3 align="center"&gt;High performance self-hosted photo and video management solution&lt;/h3&gt; 
&lt;br /&gt; 
&lt;a href="https://immich.app"&gt; &lt;img src="https://raw.githubusercontent.com/immich-app/immich/main/design/immich-screenshots.png" title="Main Screenshot" /&gt; &lt;/a&gt; 
&lt;br /&gt; 
&lt;p align="center"&gt; &lt;a href="https://raw.githubusercontent.com/immich-app/immich/main/readme_i18n/README_ca_ES.md"&gt;CatalÃ &lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/immich-app/immich/main/readme_i18n/README_es_ES.md"&gt;EspaÃ±ol&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/immich-app/immich/main/readme_i18n/README_fr_FR.md"&gt;FranÃ§ais&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/immich-app/immich/main/readme_i18n/README_it_IT.md"&gt;Italiano&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/immich-app/immich/main/readme_i18n/README_ja_JP.md"&gt;æ—¥æœ¬èª&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/immich-app/immich/main/readme_i18n/README_ko_KR.md"&gt;í•œêµ­ì–´&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/immich-app/immich/main/readme_i18n/README_de_DE.md"&gt;Deutsch&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/immich-app/immich/main/readme_i18n/README_nl_NL.md"&gt;Nederlands&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/immich-app/immich/main/readme_i18n/README_tr_TR.md"&gt;TÃ¼rkÃ§e&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/immich-app/immich/main/readme_i18n/README_zh_CN.md"&gt;ä¸­æ–‡&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/immich-app/immich/main/readme_i18n/README_uk_UA.md"&gt;Ğ£ĞºÑ€Ğ°Ñ—Ğ½ÑÑŒĞºĞ°&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/immich-app/immich/main/readme_i18n/README_ru_RU.md"&gt;Ğ ÑƒÑÑĞºĞ¸Ğ¹&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/immich-app/immich/main/readme_i18n/README_pt_BR.md"&gt;PortuguÃªs Brasileiro&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/immich-app/immich/main/readme_i18n/README_sv_SE.md"&gt;Svenska&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/immich-app/immich/main/readme_i18n/README_ar_JO.md"&gt;Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/immich-app/immich/main/readme_i18n/README_vi_VN.md"&gt;Tiáº¿ng Viá»‡t&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/immich-app/immich/main/readme_i18n/README_th_TH.md"&gt;à¸ à¸²à¸©à¸²à¹„à¸—à¸¢&lt;/a&gt; &lt;/p&gt; 
&lt;h2&gt;Disclaimer&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;âš ï¸ The project is under &lt;strong&gt;very active&lt;/strong&gt; development.&lt;/li&gt; 
 &lt;li&gt;âš ï¸ Expect bugs and breaking changes.&lt;/li&gt; 
 &lt;li&gt;âš ï¸ &lt;strong&gt;Do not use the app as the only way to store your photos and videos.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;âš ï¸ Always follow &lt;a href="https://www.backblaze.com/blog/the-3-2-1-backup-strategy/"&gt;3-2-1&lt;/a&gt; backup plan for your precious photos and videos!&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] You can find the main documentation, including installation guides, at &lt;a href="https://immich.app/"&gt;https://immich.app/&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Links&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://immich.app/docs"&gt;Documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://immich.app/docs/overview/introduction"&gt;About&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://immich.app/docs/install/requirements"&gt;Installation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://immich.app/roadmap"&gt;Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/immich-app/immich/main/#demo"&gt;Demo&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/immich-app/immich/main/#features"&gt;Features&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://immich.app/docs/developer/translations"&gt;Translations&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://immich.app/docs/overview/support-the-project"&gt;Contributing&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Demo&lt;/h2&gt; 
&lt;p&gt;Access the demo &lt;a href="https://demo.immich.app"&gt;here&lt;/a&gt;. For the mobile app, you can use &lt;code&gt;https://demo.immich.app&lt;/code&gt; for the &lt;code&gt;Server Endpoint URL&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;Login credentials&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Email&lt;/th&gt; 
   &lt;th&gt;Password&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="mailto:demo@immich.app"&gt;demo@immich.app&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;demo&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Features&lt;/th&gt; 
   &lt;th&gt;Mobile&lt;/th&gt; 
   &lt;th&gt;Web&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;Upload and view videos and photos&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;Auto backup when the app is opened&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;N/A&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;Prevent duplication of assets&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;Selective album(s) for backup&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;N/A&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;Download photos and videos to local device&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;Multi-user support&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;Album and Shared albums&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;Scrubbable/draggable scrollbar&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;Support raw formats&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;Metadata view (EXIF, map)&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;Search by metadata, objects, faces, and CLIP&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;Administrative functions (user management)&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;Background backup&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;N/A&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;Virtual scroll&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;OAuth support&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;API Keys&lt;/td&gt; 
   &lt;td&gt;N/A&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;LivePhoto/MotionPhoto backup and playback&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;Support 360 degree image display&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;User-defined storage structure&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;Public Sharing&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;Archive and Favorites&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;Global Map&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;Partner Sharing&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;Facial recognition and clustering&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;Memories (x years ago)&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;Offline support&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;Read-only gallery&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;Stacked Photos&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;Tags&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;Folder View&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Translations&lt;/h2&gt; 
&lt;p&gt;Read more about translations &lt;a href="https://immich.app/docs/developer/translations"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;a href="https://hosted.weblate.org/engage/immich/"&gt; &lt;img src="https://hosted.weblate.org/widget/immich/immich/multi-auto.svg?sanitize=true" alt="Translation status" /&gt; &lt;/a&gt; 
&lt;h2&gt;Repository activity&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://repobeats.axiom.co/api/embed/9e86d9dc3ddd137161f2f6d2e758d7863b1789cb.svg?sanitize=true" alt="Activities" title="Repobeats analytics image" /&gt;&lt;/p&gt; 
&lt;h2&gt;Star history&lt;/h2&gt; 
&lt;a href="https://star-history.com/#immich-app/immich&amp;amp;Date"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://api.star-history.com/svg?repos=immich-app/immich&amp;amp;type=Date&amp;amp;theme=dark" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://api.star-history.com/svg?repos=immich-app/immich&amp;amp;type=Date" /&gt; 
  &lt;img alt="Star History Chart" src="https://api.star-history.com/svg?repos=immich-app/immich&amp;amp;type=Date" width="100%" /&gt; 
 &lt;/picture&gt; &lt;/a&gt; 
&lt;h2&gt;Contributors&lt;/h2&gt; 
&lt;a href="https://github.com/alextran1502/immich/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=immich-app/immich" width="100%" /&gt; &lt;/a&gt;</description>
    </item>
    
    <item>
      <title>x1xhlol/system-prompts-and-models-of-ai-tools</title>
      <link>https://github.com/x1xhlol/system-prompts-and-models-of-ai-tools</link>
      <description>&lt;p&gt;FULL v0, Cursor, Manus, Augment Code, Same.dev, Lovable, Devin, Replit Agent, Windsurf Agent, VSCode Agent, Dia Browser, Xcode, Trae AI, Cluely &amp; Orchids.app (And other Open Sourced) System Prompts, Tools &amp; AI Models.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;&lt;strong&gt;System Prompts and Models of AI Tools&lt;/strong&gt;&lt;/h1&gt; 
&lt;hr /&gt; 
&lt;a href="https://discord.gg/NwzrWErdMU" target="_blank"&gt; &lt;img src="https://img.shields.io/discord/1402660735833604126?label=LeaksLab%20Discord&amp;amp;logo=discord&amp;amp;style=for-the-badge" alt="LeaksLab Discord" /&gt; &lt;/a&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Join the Conversation:&lt;/strong&gt; New system instructions are released on Discord &lt;strong&gt;before&lt;/strong&gt; they appear in this repository. Get early access and discuss them in real time.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;a href="https://trendshift.io/repositories/14084" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/14084" alt="x1xhlol%2Fsystem-prompts-and-models-of-ai-tools | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;ğŸ“œ Over &lt;strong&gt;20,000+ lines&lt;/strong&gt; of insights into their structure and functionality.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://cloudback.it"&gt;&lt;img src="https://app.cloudback.it/badge/x1xhlol/system-prompts-and-models-of-ai-tools" alt="Build Status" /&gt;&lt;/a&gt; &lt;a href="https://deepwiki.com/x1xhlol/system-prompts-and-models-of-ai-tools"&gt;&lt;img src="https://deepwiki.com/badge.svg?sanitize=true" alt="Ask DeepWiki" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;â¤ï¸ Support the Project&lt;/h2&gt; 
&lt;p&gt;If you find this collection valuable and appreciate the effort involved in obtaining and sharing these insights, please consider supporting the project. Your contribution helps keep this resource updated and allows for further exploration.&lt;/p&gt; 
&lt;p&gt;You can show your support via:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;PayPal:&lt;/strong&gt; &lt;code&gt;lucknitelol@proton.me&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Cryptocurrency:&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;BTC:&lt;/strong&gt; &lt;code&gt;bc1q7zldmzjwspnaa48udvelwe6k3fef7xrrhg5625&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;LTC:&lt;/strong&gt; &lt;code&gt;LRWgqwEYDwqau1WeiTs6Mjg85NJ7m3fsdQ&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;ETH:&lt;/strong&gt; &lt;code&gt;0x3f844B2cc3c4b7242964373fB0A41C4fdffB192A&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Patreon:&lt;/strong&gt; &lt;a href="https://patreon.com/lucknite"&gt;https://patreon.com/lucknite&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;ğŸ™ Thank you for your support!&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ğŸ“‘ Table of Contents&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/x1xhlol/system-prompts-and-models-of-ai-tools/main/#%EF%B8%8F-support-the-project"&gt;â¤ï¸ Support the Project&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/x1xhlol/system-prompts-and-models-of-ai-tools/main/#-table-of-contents"&gt;ğŸ“‘ Table of Contents&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/x1xhlol/system-prompts-and-models-of-ai-tools/main/#-available-files"&gt;ğŸ“‚ Available Files&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/x1xhlol/system-prompts-and-models-of-ai-tools/main/#-roadmap--feedback"&gt;ğŸ›  Roadmap &amp;amp; Feedback&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/x1xhlol/system-prompts-and-models-of-ai-tools/main/#-connect-with-me"&gt;ğŸ”— Connect With Me&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/x1xhlol/system-prompts-and-models-of-ai-tools/main/#%EF%B8%8F-security-notice-for-ai-startups"&gt;ğŸ›¡ï¸ Security Notice for AI Startups&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/x1xhlol/system-prompts-and-models-of-ai-tools/main/#-star-history"&gt;ğŸ“Š Star History&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ğŸ“‚ Available Files&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/x1xhlol/system-prompts-and-models-of-ai-tools/main/v0%20Prompts%20and%20Tools/"&gt;&lt;strong&gt;v0&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/x1xhlol/system-prompts-and-models-of-ai-tools/main/Manus%20Agent%20Tools%20&amp;amp;%20Prompt/"&gt;&lt;strong&gt;Manus&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/x1xhlol/system-prompts-and-models-of-ai-tools/main/Augment%20Code/"&gt;&lt;strong&gt;Augment Code&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/x1xhlol/system-prompts-and-models-of-ai-tools/main/Lovable/"&gt;&lt;strong&gt;Lovable&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/x1xhlol/system-prompts-and-models-of-ai-tools/main/Devin%20AI/"&gt;&lt;strong&gt;Devin&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/x1xhlol/system-prompts-and-models-of-ai-tools/main/Same.dev/"&gt;&lt;strong&gt;Same.dev&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/x1xhlol/system-prompts-and-models-of-ai-tools/main/Replit/"&gt;&lt;strong&gt;Replit&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/x1xhlol/system-prompts-and-models-of-ai-tools/main/Windsurf/"&gt;&lt;strong&gt;Windsurf Agent&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/x1xhlol/system-prompts-and-models-of-ai-tools/main/VSCode%20Agent/"&gt;&lt;strong&gt;VSCode (Copilot) Agent&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/x1xhlol/system-prompts-and-models-of-ai-tools/main/Cursor%20Prompts/"&gt;&lt;strong&gt;Cursor&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/x1xhlol/system-prompts-and-models-of-ai-tools/main/dia/"&gt;&lt;strong&gt;Dia&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/x1xhlol/system-prompts-and-models-of-ai-tools/main/Trae/"&gt;&lt;strong&gt;Trae AI&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/x1xhlol/system-prompts-and-models-of-ai-tools/main/Perplexity/"&gt;&lt;strong&gt;Perplexity&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/x1xhlol/system-prompts-and-models-of-ai-tools/main/Cluely/"&gt;&lt;strong&gt;Cluely&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/x1xhlol/system-prompts-and-models-of-ai-tools/main/Xcode/"&gt;&lt;strong&gt;Xcode&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/x1xhlol/system-prompts-and-models-of-ai-tools/main/NotionAi/"&gt;&lt;strong&gt;Notion AI&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/x1xhlol/system-prompts-and-models-of-ai-tools/main/Orchids.app/"&gt;&lt;strong&gt;Orchids.app&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/x1xhlol/system-prompts-and-models-of-ai-tools/main/Junie/"&gt;&lt;strong&gt;Junie&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/x1xhlol/system-prompts-and-models-of-ai-tools/main/Kiro/"&gt;&lt;strong&gt;Kiro&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/x1xhlol/system-prompts-and-models-of-ai-tools/main/Warp.dev/"&gt;&lt;strong&gt;Warp.dev&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/x1xhlol/system-prompts-and-models-of-ai-tools/main/Z.ai%20Code/"&gt;&lt;strong&gt;Z.ai Code&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/x1xhlol/system-prompts-and-models-of-ai-tools/main/Qoder/"&gt;&lt;strong&gt;Qoder&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/x1xhlol/system-prompts-and-models-of-ai-tools/main/Claude%20Code/"&gt;&lt;strong&gt;Claude Code&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/x1xhlol/system-prompts-and-models-of-ai-tools/main/Open%20Source%20prompts/"&gt;&lt;strong&gt;Open Source prompts&lt;/strong&gt;&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/x1xhlol/system-prompts-and-models-of-ai-tools/main/Open%20Source%20prompts/Codex%20CLI/"&gt;Codex CLI&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/x1xhlol/system-prompts-and-models-of-ai-tools/main/Open%20Source%20prompts/Cline/"&gt;Cline&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/x1xhlol/system-prompts-and-models-of-ai-tools/main/Open%20Source%20prompts/Bolt/"&gt;Bolt&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/x1xhlol/system-prompts-and-models-of-ai-tools/main/Open%20Source%20prompts/RooCode/"&gt;RooCode&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/x1xhlol/system-prompts-and-models-of-ai-tools/main/Open%20Source%20prompts/Lumo/"&gt;Lumo&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/x1xhlol/system-prompts-and-models-of-ai-tools/main/Open%20Source%20prompts/Gemini%20CLI/"&gt;Gemini CLI&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/x1xhlol/system-prompts-and-models-of-ai-tools/main/CodeBuddy%20Prompts/"&gt;&lt;strong&gt;CodeBuddy&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ğŸ›  Roadmap &amp;amp; Feedback&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Open an issue.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Latest Update:&lt;/strong&gt; 08/09/2025&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ğŸ”— Connect With Me&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;X:&lt;/strong&gt; &lt;a href="https://x.com/NotLucknite"&gt;NotLucknite&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Discord&lt;/strong&gt;: &lt;code&gt;x1xh&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ğŸ›¡ï¸ Security Notice for AI Startups&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;âš ï¸ &lt;strong&gt;Warning:&lt;/strong&gt; If you're an AI startup, make sure your data is secure. Exposed prompts or AI models can easily become a target for hackers.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;ğŸ” &lt;strong&gt;Important:&lt;/strong&gt; Interested in securing your AI systems?&lt;br /&gt; Check out &lt;strong&gt;&lt;a href="https://zeroleaks.io/"&gt;ZeroLeaks&lt;/a&gt;&lt;/strong&gt;, a service designed to help startups &lt;strong&gt;identify and secure&lt;/strong&gt; leaks in system instructions, internal tools, and model configurations. &lt;strong&gt;Get a free AI security audit&lt;/strong&gt; to ensure your AI is protected from vulnerabilities.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;em&gt;The company is mine, this is NOT a 3rd party AD.&lt;/em&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ğŸ“Š Star History&lt;/h2&gt; 
&lt;a href="https://www.star-history.com/#x1xhlol/system-prompts-and-models-of-ai-tools&amp;amp;Date"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://api.star-history.com/svg?repos=x1xhlol/system-prompts-and-models-of-ai-tools&amp;amp;type=Date&amp;amp;theme=dark" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://api.star-history.com/svg?repos=x1xhlol/system-prompts-and-models-of-ai-tools&amp;amp;type=Date" /&gt; 
  &lt;img alt="Star History Chart" src="https://api.star-history.com/svg?repos=x1xhlol/system-prompts-and-models-of-ai-tools&amp;amp;type=Date" /&gt; 
 &lt;/picture&gt; &lt;/a&gt; 
&lt;p&gt;â­ &lt;strong&gt;Drop a star if you find this useful!&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>hiroi-sora/Umi-OCR</title>
      <link>https://github.com/hiroi-sora/Umi-OCR</link>
      <description>&lt;p&gt;OCR software, free and offline. å¼€æºã€å…è´¹çš„ç¦»çº¿OCRè½¯ä»¶ã€‚æ”¯æŒæˆªå±/æ‰¹é‡å¯¼å…¥å›¾ç‰‡ï¼ŒPDFæ–‡æ¡£è¯†åˆ«ï¼Œæ’é™¤æ°´å°/é¡µçœ‰é¡µè„šï¼Œæ‰«æ/ç”ŸæˆäºŒç»´ç ã€‚å†…ç½®å¤šå›½è¯­è¨€åº“ã€‚&lt;/p&gt;&lt;hr&gt;&lt;p align="left"&gt; &lt;span&gt; &lt;b&gt;ä¸­æ–‡&lt;/b&gt; &lt;/span&gt; &lt;span&gt; â€¢ &lt;/span&gt; &lt;a href="https://raw.githubusercontent.com/hiroi-sora/Umi-OCR/main/README_en.md"&gt; English &lt;/a&gt; &lt;span&gt; â€¢ &lt;/span&gt; &lt;a href="https://raw.githubusercontent.com/hiroi-sora/Umi-OCR/main/README_ja.md"&gt; æ—¥æœ¬èª &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/hiroi-sora/Umi-OCR"&gt; &lt;img width="200" height="128" src="https://tupian.li/images/2022/10/27/icon---256.png" alt="Umi-OCR" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;h1 align="center"&gt;Umi-OCR æ–‡å­—è¯†åˆ«å·¥å…·&lt;/h1&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/hiroi-sora/Umi-OCR/releases/latest"&gt; &lt;img src="https://img.shields.io/github/v/release/hiroi-sora/Umi-OCR?style=flat-square" alt="Umi-OCR" /&gt; &lt;/a&gt; &lt;a href="https://github.com/hiroi-sora/Umi-OCR/raw/main/LICENSE"&gt; &lt;img src="https://img.shields.io/github/license/hiroi-sora/Umi-OCR?style=flat-square" alt="LICENSE" /&gt; &lt;/a&gt; &lt;a href="#ä¸‹è½½å‘è¡Œç‰ˆ"&gt; &lt;img src="https://img.shields.io/github/downloads/hiroi-sora/Umi-OCR/total?style=flat-square" alt="forks" /&gt; &lt;/a&gt; &lt;a href="https://star-history.com/#hiroi-sora/Umi-OCR"&gt; &lt;img src="https://img.shields.io/github/stars/hiroi-sora/Umi-OCR?style=flat-square" alt="stars" /&gt; &lt;/a&gt; &lt;a href="https://github.com/hiroi-sora/Umi-OCR/forks"&gt; &lt;img src="https://img.shields.io/github/forks/hiroi-sora/Umi-OCR?style=flat-square" alt="forks" /&gt; &lt;/a&gt; &lt;a href="https://hosted.weblate.org/engage/umi-ocr/"&gt; &lt;img src="https://hosted.weblate.org/widget/umi-ocr/svg-badge.svg?sanitize=true" alt="ç¿»è¯‘çŠ¶æ€" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;h3&gt; &lt;a href="#ç›®å½•"&gt; ä½¿ç”¨è¯´æ˜ &lt;/a&gt; &lt;span&gt; â€¢ &lt;/span&gt; &lt;a href="#ä¸‹è½½å‘è¡Œç‰ˆ"&gt; ä¸‹è½½åœ°å€ &lt;/a&gt; &lt;span&gt; â€¢ &lt;/span&gt; &lt;a href="https://raw.githubusercontent.com/hiroi-sora/Umi-OCR/main/CHANGE_LOG.md"&gt; æ›´æ–°æ—¥å¿— &lt;/a&gt; &lt;span&gt; â€¢ &lt;/span&gt; &lt;a href="https://github.com/hiroi-sora/Umi-OCR/issues"&gt; æäº¤Bug &lt;/a&gt; &lt;/h3&gt; 
&lt;/div&gt; 
&lt;br /&gt; 
&lt;div align="center"&gt; 
 &lt;strong&gt;å…è´¹ï¼Œå¼€æºï¼Œå¯æ‰¹é‡çš„ç¦»çº¿OCRè½¯ä»¶&lt;/strong&gt;
 &lt;br /&gt; 
 &lt;sub&gt;é€‚ç”¨äº Windows7 x64 ã€Linux x64 &lt;/sub&gt;
&lt;/div&gt;
&lt;br /&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;å…è´¹&lt;/strong&gt;ï¼šæœ¬é¡¹ç›®æ‰€æœ‰ä»£ç å¼€æºï¼Œå®Œå…¨å…è´¹ã€‚&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;æ–¹ä¾¿&lt;/strong&gt;ï¼šè§£å‹å³ç”¨ï¼Œç¦»çº¿è¿è¡Œï¼Œæ— éœ€ç½‘ç»œã€‚&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;é«˜æ•ˆ&lt;/strong&gt;ï¼šè‡ªå¸¦é«˜æ•ˆç‡çš„ç¦»çº¿OCRå¼•æ“ï¼Œå†…ç½®å¤šç§è¯­è¨€è¯†åˆ«åº“ã€‚&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;çµæ´»&lt;/strong&gt;ï¼šæ”¯æŒå‘½ä»¤è¡Œã€HTTPæ¥å£ç­‰å¤–éƒ¨è°ƒç”¨æ–¹å¼ã€‚&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;åŠŸèƒ½&lt;/strong&gt;ï¼šæˆªå›¾OCR / æ‰¹é‡OCR / PDFè¯†åˆ« / äºŒç»´ç  / å…¬å¼è¯†åˆ«&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p align="center"&gt;&lt;img src="https://tupian.li/images/2023/11/19/65599097ab5f4.png" alt="1-æ ‡é¢˜-1.png" style="width: 80%;" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://tupian.li/images/2023/11/19/6559909fdeeba.png" alt="1-æ ‡é¢˜-2.png" /&gt;&lt;/p&gt; 
&lt;h2&gt;ç›®å½•&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hiroi-sora/Umi-OCR/main/#%E6%88%AA%E5%9B%BEOCR"&gt;æˆªå›¾è¯†åˆ«&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hiroi-sora/Umi-OCR/main/#%E6%96%87%E6%9C%AC%E5%90%8E%E5%A4%84%E7%90%86"&gt;æ’ç‰ˆè§£æ&lt;/a&gt; - è¯†åˆ«ä¸åŒæ’ç‰ˆï¼ŒæŒ‰æ­£ç¡®é¡ºåºè¾“å‡ºæ–‡å­—&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hiroi-sora/Umi-OCR/main/#%E6%89%B9%E9%87%8FOCR"&gt;æ‰¹é‡è¯†åˆ«&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hiroi-sora/Umi-OCR/main/#%E5%BF%BD%E7%95%A5%E5%8C%BA%E5%9F%9F"&gt;å¿½ç•¥åŒºåŸŸ&lt;/a&gt; - æ’é™¤æˆªå›¾æ°´å°å¤„çš„æ–‡å­—&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hiroi-sora/Umi-OCR/main/#%E4%BA%8C%E7%BB%B4%E7%A0%81"&gt;äºŒç»´ç &lt;/a&gt; æ”¯æŒæ‰«ç æˆ–ç”ŸæˆäºŒç»´ç å›¾ç‰‡&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hiroi-sora/Umi-OCR/main/#%E6%96%87%E6%A1%A3%E8%AF%86%E5%88%AB"&gt;æ–‡æ¡£è¯†åˆ«&lt;/a&gt; ä»PDFæ‰«æä»¶ä¸­æå–æ–‡æœ¬ï¼Œæˆ–è½¬ä¸ºåŒå±‚å¯æœç´¢PDF&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hiroi-sora/Umi-OCR/main/#%E5%85%A8%E5%B1%80%E8%AE%BE%E7%BD%AE"&gt;å…¨å±€è®¾ç½®&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hiroi-sora/Umi-OCR/main/docs/README_CLI.md"&gt;å‘½ä»¤è¡Œè°ƒç”¨&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hiroi-sora/Umi-OCR/main/docs/http/README.md"&gt;HTTPæ¥å£&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hiroi-sora/Umi-OCR/main/#%E6%9E%84%E5%BB%BA%E9%A1%B9%E7%9B%AE"&gt;æ„å»ºé¡¹ç›®ï¼ˆWindowsã€Linuxï¼‰&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ä½¿ç”¨æºç &lt;/h2&gt; 
&lt;p&gt;å¼€å‘è€…è¯·åŠ¡å¿…é˜…è¯» &lt;a href="https://raw.githubusercontent.com/hiroi-sora/Umi-OCR/main/#%E6%9E%84%E5%BB%BA%E9%A1%B9%E7%9B%AE"&gt;æ„å»ºé¡¹ç›®&lt;/a&gt; ã€‚&lt;/p&gt; 
&lt;h2&gt;ä¸‹è½½å‘è¡Œç‰ˆ&lt;/h2&gt; 
&lt;p&gt;ä»¥ä¸‹å‘å¸ƒé“¾æ¥å‡é•¿æœŸç»´æŠ¤ï¼Œæä¾›ç¨³å®šç‰ˆæœ¬çš„ä¸‹è½½ã€‚&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;è“å¥äº‘&lt;/strong&gt; &lt;a href="https://hiroi-sora.lanzoul.com/s/umi-ocr"&gt;https://hiroi-sora.lanzoul.com/s/umi-ocr&lt;/a&gt; ï¼ˆå›½å†…æ¨èï¼Œå…æ³¨å†Œ/æ— é™é€Ÿï¼‰&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;GitHub&lt;/strong&gt; &lt;a href="https://github.com/hiroi-sora/Umi-OCR/releases/latest"&gt;https://github.com/hiroi-sora/Umi-OCR/releases/latest&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Source Forge&lt;/strong&gt; &lt;a href="https://sourceforge.net/projects/umi-ocr"&gt;https://sourceforge.net/projects/umi-ocr&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;b&gt;â€¢&amp;nbsp;&amp;nbsp;Scoop Installer&lt;/b&gt;ï¼ˆç‚¹å‡»å±•å¼€ï¼‰&lt;/summary&gt; 
 &lt;p&gt;&lt;a href="https://scoop.sh/"&gt;Scoop&lt;/a&gt; æ˜¯ä¸€æ¬¾Windowsä¸‹çš„å‘½ä»¤è¡Œå®‰è£…ç¨‹åºï¼Œå¯æ–¹ä¾¿åœ°ç®¡ç†å¤šä¸ªåº”ç”¨ã€‚æ‚¨å¯ä»¥å…ˆå®‰è£… Scoop ï¼Œå†ä½¿ç”¨ä»¥ä¸‹æŒ‡ä»¤å®‰è£… &lt;code&gt;Umi-OCR&lt;/code&gt; ï¼š&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;æ·»åŠ  &lt;code&gt;extras&lt;/code&gt; æ¡¶ï¼š&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;pre&gt;&lt;code&gt;scoop bucket add extras
&lt;/code&gt;&lt;/pre&gt; 
 &lt;ul&gt; 
  &lt;li&gt;ï¼ˆå¯é€‰1ï¼‰å®‰è£… Umi-OCRï¼ˆè‡ªå¸¦ &lt;code&gt;Rapid-OCR&lt;/code&gt; å¼•æ“ï¼Œå…¼å®¹æ€§å¥½ï¼‰ï¼š&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;pre&gt;&lt;code&gt;scoop install extras/umi-ocr
&lt;/code&gt;&lt;/pre&gt; 
 &lt;ul&gt; 
  &lt;li&gt;ï¼ˆå¯é€‰2ï¼‰å®‰è£… Umi-OCRï¼ˆè‡ªå¸¦ &lt;code&gt;Paddle-OCR&lt;/code&gt; å¼•æ“ï¼Œé€Ÿåº¦ç¨å¿«ï¼‰ï¼š&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;pre&gt;&lt;code&gt;scoop install extras/umi-ocr-paddle
&lt;/code&gt;&lt;/pre&gt; 
 &lt;ul&gt; 
  &lt;li&gt;ä¸è¦åŒæ—¶å®‰è£…äºŒè€…ï¼Œå¿«æ·æ–¹å¼å¯èƒ½ä¼šè¢«è¦†ç›–ã€‚ä½†æ‚¨å¯ä»¥é¢å¤–å¯¼å…¥ &lt;a href="https://github.com/hiroi-sora/Umi-OCR_plugins"&gt;æ’ä»¶&lt;/a&gt; ï¼Œéšæ—¶åˆ‡æ¢ä¸åŒOCRå¼•æ“ã€‚&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;br /&gt; 
&lt;h2&gt;å¼€å§‹ä½¿ç”¨&lt;/h2&gt; 
&lt;p&gt;è½¯ä»¶å‘å¸ƒåŒ…ä¸‹è½½ä¸º &lt;code&gt;.7z&lt;/code&gt; å‹ç¼©åŒ…æˆ– &lt;code&gt;.7z.exe&lt;/code&gt; è‡ªè§£å‹åŒ…ã€‚è‡ªè§£å‹åŒ…å¯åœ¨æ²¡æœ‰å®‰è£…å‹ç¼©è½¯ä»¶çš„ç”µè„‘ä¸Šï¼Œè§£å‹æ–‡ä»¶ã€‚&lt;/p&gt; 
&lt;p&gt;æœ¬è½¯ä»¶æ— éœ€å®‰è£…ã€‚è§£å‹åï¼Œç‚¹å‡» &lt;code&gt;Umi-OCR.exe&lt;/code&gt; å³å¯å¯åŠ¨ç¨‹åºã€‚&lt;/p&gt; 
&lt;p&gt;é‡åˆ°ä»»ä½•é—®é¢˜ï¼Œè¯·æ &lt;a href="https://github.com/hiroi-sora/Umi-OCR/issues"&gt;Issue&lt;/a&gt; ï¼Œæˆ‘ä¼šå°½å¯èƒ½å¸®åŠ©ä½ ã€‚&lt;/p&gt; 
&lt;h2&gt;ç•Œé¢è¯­è¨€&lt;/h2&gt; 
&lt;p&gt;Umi-OCR æ”¯æŒçš„ç•Œé¢å¤šå›½è¯­è¨€ã€‚åœ¨ç¬¬ä¸€æ¬¡æ‰“å¼€è½¯ä»¶æ—¶ï¼Œå°†ä¼šæŒ‰ç…§ä½ çš„ç”µè„‘çš„ç³»ç»Ÿè®¾ç½®ï¼Œè‡ªåŠ¨åˆ‡æ¢è¯­è¨€ã€‚&lt;/p&gt; 
&lt;p&gt;å¦‚æœéœ€è¦æ‰‹åŠ¨åˆ‡æ¢è¯­è¨€ï¼Œè¯·å‚è€ƒä¸‹å›¾ï¼Œ&lt;code&gt;å…¨å±€è®¾ç½®&lt;/code&gt;â†’&lt;code&gt;è¯­è¨€/Language&lt;/code&gt; ã€‚&lt;/p&gt; 
&lt;p align="center"&gt;&lt;img src="https://tupian.li/images/2023/11/19/65599c3f9e600.png" alt="1-æ ‡é¢˜-1.png" style="width: 80%;" /&gt;&lt;/p&gt; 
&lt;h2&gt;æ ‡ç­¾é¡µ&lt;/h2&gt; 
&lt;p&gt;Umi-OCR v2 ç”±ä¸€ç³»åˆ—çµæ´»å¥½ç”¨çš„&lt;strong&gt;æ ‡ç­¾é¡µ&lt;/strong&gt;ç»„æˆã€‚æ‚¨å¯æŒ‰ç…§è‡ªå·±çš„å–œå¥½ï¼Œæ‰“å¼€éœ€è¦çš„æ ‡ç­¾é¡µã€‚&lt;/p&gt; 
&lt;p&gt;æ ‡ç­¾æ å·¦ä¸Šè§’å¯ä»¥åˆ‡æ¢&lt;strong&gt;çª—å£ç½®é¡¶&lt;/strong&gt;ã€‚å³ä¸Šè§’èƒ½å¤Ÿ&lt;strong&gt;é”å®šæ ‡ç­¾é¡µ&lt;/strong&gt;ï¼Œä»¥é˜²æ­¢æ—¥å¸¸ä½¿ç”¨ä¸­è¯¯è§¦å…³é—­æ ‡ç­¾é¡µã€‚&lt;/p&gt; 
&lt;h3&gt;æˆªå›¾OCR&lt;/h3&gt; 
&lt;p align="center"&gt;&lt;img src="https://tupian.li/images/2023/11/19/65599097aba8e.png" alt="2-æˆªå›¾-1.png" style="width: 80%;" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;æˆªå›¾OCR&lt;/strong&gt;ï¼šæ‰“å¼€è¿™ä¸€é¡µåï¼Œå°±å¯ä»¥ç”¨å¿«æ·é”®å”¤èµ·æˆªå›¾ï¼Œè¯†åˆ«å›¾ä¸­çš„æ–‡å­—ã€‚&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;å·¦ä¾§çš„å›¾ç‰‡é¢„è§ˆæ ï¼Œå¯ç›´æ¥ç”¨é¼ æ ‡åˆ’é€‰å¤åˆ¶ã€‚&lt;/li&gt; 
 &lt;li&gt;å³ä¾§çš„è¯†åˆ«è®°å½•æ ï¼Œå¯ä»¥ç¼–è¾‘æ–‡å­—ï¼Œå…è®¸åˆ’é€‰å¤šä¸ªè®°å½•å¤åˆ¶ã€‚&lt;/li&gt; 
 &lt;li&gt;ä¹Ÿæ”¯æŒåœ¨åˆ«å¤„å¤åˆ¶å›¾ç‰‡ï¼Œç²˜è´´åˆ°Umi-OCRè¿›è¡Œè¯†åˆ«ã€‚&lt;/li&gt; 
 &lt;li&gt;å…³äº &lt;a href="https://github.com/hiroi-sora/Umi-OCR/issues/254"&gt;å…¬å¼è¯†åˆ«&lt;/a&gt; åŠŸèƒ½&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;æ–‡æœ¬åå¤„ç†&lt;/h4&gt; 
&lt;p align="center"&gt;&lt;img src="https://tupian.li/images/2023/11/19/6559909f3e378.png" alt="2-æˆªå›¾-2.png" style="width: 80%;" /&gt;&lt;/p&gt; 
&lt;p&gt;å…³äº &lt;strong&gt;OCRæ–‡æœ¬åå¤„ç† - æ’ç‰ˆè§£ææ–¹æ¡ˆ&lt;/strong&gt;ï¼š å¯ä»¥æ•´ç†OCRç»“æœçš„æ’ç‰ˆå’Œé¡ºåºï¼Œä½¿æ–‡æœ¬æ›´é€‚åˆé˜…è¯»å’Œä½¿ç”¨ã€‚é¢„è®¾æ–¹æ¡ˆï¼š&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;å¤šæ -æŒ‰è‡ªç„¶æ®µæ¢è¡Œ&lt;/code&gt;ï¼šé€‚åˆå¤§éƒ¨åˆ†æƒ…æ™¯ï¼Œè‡ªåŠ¨è¯†åˆ«å¤šæ å¸ƒå±€ï¼ŒæŒ‰è‡ªç„¶æ®µè§„åˆ™è¿›è¡Œæ¢è¡Œã€‚&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;å¤šæ -æ€»æ˜¯æ¢è¡Œ&lt;/code&gt;ï¼šæ¯æ®µè¯­å¥éƒ½è¿›è¡Œæ¢è¡Œã€‚&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;å¤šæ -æ— æ¢è¡Œ&lt;/code&gt;ï¼šå¼ºåˆ¶å°†æ‰€æœ‰è¯­å¥åˆå¹¶åˆ°åŒä¸€è¡Œã€‚&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;å•æ -æŒ‰è‡ªç„¶æ®µæ¢è¡Œ&lt;/code&gt;/&lt;code&gt;æ€»æ˜¯æ¢è¡Œ&lt;/code&gt;/&lt;code&gt;æ— æ¢è¡Œ&lt;/code&gt;ï¼šä¸ä¸Šè¿°ç±»ä¼¼ï¼Œä¸è¿‡ ä¸åŒºåˆ†å¤šæ å¸ƒå±€ã€‚&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;å•æ -ä¿ç•™ç¼©è¿›&lt;/code&gt;ï¼šé€‚ç”¨äºè§£æä»£ç æˆªå›¾ï¼Œä¿ç•™è¡Œé¦–ç¼©è¿›å’Œè¡Œä¸­ç©ºæ ¼ã€‚&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;ä¸åšå¤„ç†&lt;/code&gt;ï¼šOCRå¼•æ“çš„åŸå§‹è¾“å‡ºï¼Œé»˜è®¤æ¯æ®µè¯­å¥éƒ½è¿›è¡Œæ¢è¡Œã€‚&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;ä¸Šè¿°æ–¹æ¡ˆï¼Œå‡èƒ½è‡ªåŠ¨å¤„ç†æ¨ªæ’å’Œç«–æ’ï¼ˆä»å³åˆ°å·¦ï¼‰çš„æ’ç‰ˆã€‚ï¼ˆç«–æ’æ–‡å­—è¿˜éœ€è¦OCRå¼•æ“æœ¬èº«æ”¯æŒï¼‰&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h3&gt;æ‰¹é‡OCR&lt;/h3&gt; 
&lt;p align="center"&gt;&lt;img src="https://tupian.li/images/2023/11/19/655990a2511e0.png" alt="3-æ‰¹é‡-1.png" style="width: 80%;" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;æ‰¹é‡OCR&lt;/strong&gt;ï¼šè¿™ä¸€é¡µç”¨äºæ‰¹é‡å¯¼å…¥æœ¬åœ°å›¾ç‰‡è¿›è¡Œè¯†åˆ«ã€‚&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;æ”¯æŒæ ¼å¼ï¼š&lt;code&gt;jpg, jpe, jpeg, jfif, png, webp, bmp, tif, tiff&lt;/code&gt;ã€‚&lt;/li&gt; 
 &lt;li&gt;ä¿å­˜è¯†åˆ«ç»“æœçš„æ”¯æŒæ ¼å¼ï¼š&lt;code&gt;txt, jsonl, md, csv(Excel)&lt;/code&gt;ã€‚&lt;/li&gt; 
 &lt;li&gt;ä¸æˆªå›¾OCRä¸€æ ·ï¼Œæ”¯æŒ&lt;code&gt;æ–‡æœ¬åå¤„ç†&lt;/code&gt;åŠŸèƒ½ï¼Œæ•´ç†OCRæ–‡æœ¬çš„æ’ç‰ˆå’Œé¡ºåºã€‚&lt;/li&gt; 
 &lt;li&gt;æ²¡æœ‰æ•°é‡ä¸Šé™ï¼Œå¯ä¸€æ¬¡æ€§å¯¼å…¥å‡ ç™¾å¼ å›¾ç‰‡è¿›è¡Œä»»åŠ¡ã€‚&lt;/li&gt; 
 &lt;li&gt;æ”¯æŒä»»åŠ¡å®Œæˆåè‡ªåŠ¨å…³æœº/å¾…æœºã€‚&lt;/li&gt; 
 &lt;li&gt;å¦‚æœè¦è¯†åˆ«åƒç´ è¶…å¤§çš„é•¿å›¾æˆ–å¤§å›¾ï¼Œè¯·è°ƒæ•´ï¼š&lt;strong&gt;é¡µé¢çš„è®¾ç½®â†’æ–‡å­—è¯†åˆ«â†’é™åˆ¶å›¾åƒè¾¹é•¿â†’ã€è°ƒé«˜æ•°å€¼ã€‘&lt;/strong&gt;ã€‚&lt;/li&gt; 
 &lt;li&gt;æ‹¥æœ‰ç‰¹æ®ŠåŠŸèƒ½ &lt;code&gt;å¿½ç•¥åŒºåŸŸ&lt;/code&gt; ã€‚&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;å¿½ç•¥åŒºåŸŸ&lt;/h4&gt; 
&lt;p align="center"&gt;&lt;img src="https://tupian.li/images/2023/11/19/6559911d28be7.png" alt="3-æ‰¹é‡-2.png" style="width: 80%;" /&gt;&lt;/p&gt; 
&lt;p&gt;å…³äº &lt;strong&gt;OCRæ–‡æœ¬åå¤„ç† - å¿½ç•¥åŒºåŸŸ&lt;/strong&gt;ï¼š æ‰¹é‡OCRä¸­çš„ä¸€ç§ç‰¹æ®ŠåŠŸèƒ½ï¼Œé€‚ç”¨äºæ’é™¤å›¾ç‰‡ä¸­çš„ä¸æƒ³è¦çš„æ–‡å­—ã€‚&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;åœ¨æ‰¹é‡è¯†åˆ«é¡µçš„å³æ è®¾ç½®ä¸­å¯è¿›å…¥å¿½ç•¥åŒºåŸŸç¼–è¾‘å™¨ã€‚&lt;/li&gt; 
 &lt;li&gt;å¦‚ä¸Šæ–¹æ ·ä¾‹ï¼Œå›¾ç‰‡é¡¶éƒ¨å’Œå³ä¸‹è§’å­˜åœ¨å¤šä¸ªæ°´å° / LOGOã€‚å¦‚æœæ‰¹é‡è¯†åˆ«è¿™ç±»å›¾ç‰‡ï¼Œæ°´å°ä¼šå¯¹è¯†åˆ«ç»“æœé€ æˆå¹²æ‰°ã€‚&lt;/li&gt; 
 &lt;li&gt;æŒ‰ä½å³é”®ï¼Œç»˜åˆ¶å¤šä¸ªçŸ©å½¢æ¡†ã€‚è¿™äº›åŒºåŸŸå†…çš„æ–‡å­—å°†åœ¨ä»»åŠ¡ä¸­è¢«å¿½ç•¥ã€‚&lt;/li&gt; 
 &lt;li&gt;è¯·å°½é‡å°†çŸ©å½¢æ¡†ç”»å¾—å¤§ä¸€äº›ï¼Œå®Œå…¨åŒ…è£¹ä½æ°´å°æ‰€æœ‰å¯èƒ½å‡ºç°çš„ä½ç½®ã€‚&lt;/li&gt; 
 &lt;li&gt;æ³¨æ„ï¼Œåªæœ‰å¤„äºå¿½ç•¥åŒºåŸŸæ¡†å†…éƒ¨çš„æ•´ä¸ªæ–‡æœ¬å—ï¼ˆè€Œä¸æ˜¯å•ä¸ªå­—ç¬¦ï¼‰ä¼šè¢«å¿½ç•¥ã€‚å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œé»„è‰²è¾¹æ¡†çš„æ·±è‰²çŸ©å½¢æ˜¯ä¸€ä¸ªå¿½ç•¥åŒºåŸŸã€‚é‚£ä¹ˆåªæœ‰&lt;code&gt;key_mouse&lt;/code&gt;æ‰ä¼šè¢«å¿½ç•¥ã€‚&lt;code&gt;pubsub_connector.py&lt;/code&gt;ã€&lt;code&gt;pubsub_service.py&lt;/code&gt; è¿™ä¸¤ä¸ªæ–‡æœ¬å—å¾—ä»¥ä¿ç•™ã€‚&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p align="center"&gt;&lt;img src="https://tupian.li/images/2024/05/30/66587bf03ae15.png" alt="å¿½ç•¥åŒºåŸŸèŒƒå›´ç¤ºä¾‹.png" style="width: 80%;" /&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h3&gt;æ–‡æ¡£è¯†åˆ«&lt;/h3&gt; 
&lt;p align="center"&gt;&lt;img src="https://github.com/hiroi-sora/Umi-OCR/assets/56373419/fc2266ee-b9b7-4079-8b10-6610e6da6cf5" alt="" style="width: 80%;" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;æ–‡æ¡£è¯†åˆ«&lt;/strong&gt;ï¼š&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;æ”¯æŒæ ¼å¼ï¼š&lt;code&gt;pdf, xps, epub, mobi, fb2, cbz&lt;/code&gt;ã€‚&lt;/li&gt; 
 &lt;li&gt;å¯¹æ‰«æä»¶è¿›è¡ŒOCRï¼Œæˆ–æå–åŸæœ‰æ–‡æœ¬ã€‚å¯è¾“å‡ºä¸º &lt;strong&gt;åŒå±‚å¯æœç´¢PDF&lt;/strong&gt; ã€‚&lt;/li&gt; 
 &lt;li&gt;æ”¯æŒè®¾å®š &lt;strong&gt;å¿½ç•¥åŒºåŸŸ&lt;/strong&gt; ï¼Œå¯ç”¨äºæ’é™¤é¡µçœ‰é¡µè„šçš„æ–‡å­—ã€‚&lt;/li&gt; 
 &lt;li&gt;å¯è®¾ç½®ä»»åŠ¡å®Œæˆå &lt;strong&gt;è‡ªåŠ¨å…³æœº/ä¼‘çœ &lt;/strong&gt; ã€‚&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h3&gt;äºŒç»´ç &lt;/h3&gt; 
&lt;p align="center"&gt;&lt;img src="https://tupian.li/images/2023/11/19/655991268d6b1.png" alt="4-äºŒç»´ç -1.png" style="width: 80%;" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;æ‰«ç &lt;/strong&gt;ï¼š&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;æˆªå›¾/ç²˜è´´/æ‹–å…¥æœ¬åœ°å›¾ç‰‡ï¼Œè¯»å–å…¶ä¸­çš„äºŒç»´ç ã€æ¡å½¢ç ã€‚&lt;/li&gt; 
 &lt;li&gt;æ”¯æŒä¸€å›¾å¤šç ã€‚&lt;/li&gt; 
 &lt;li&gt;æ”¯æŒ19ç§åè®®ï¼Œå¦‚ä¸‹ï¼š&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;code&gt;Aztec&lt;/code&gt;,&lt;code&gt;Codabar&lt;/code&gt;,&lt;code&gt;Code128&lt;/code&gt;,&lt;code&gt;Code39&lt;/code&gt;,&lt;code&gt;Code93&lt;/code&gt;,&lt;code&gt;DataBar&lt;/code&gt;,&lt;code&gt;DataBarExpanded&lt;/code&gt;,&lt;code&gt;DataMatrix&lt;/code&gt;,&lt;code&gt;EAN13&lt;/code&gt;,&lt;code&gt;EAN8&lt;/code&gt;,&lt;code&gt;ITF&lt;/code&gt;,&lt;code&gt;LinearCodes&lt;/code&gt;,&lt;code&gt;MatrixCodes&lt;/code&gt;,&lt;code&gt;MaxiCode&lt;/code&gt;,&lt;code&gt;MicroQRCode&lt;/code&gt;,&lt;code&gt;PDF417&lt;/code&gt;,&lt;code&gt;QRCode&lt;/code&gt;,&lt;code&gt;UPCA&lt;/code&gt;,&lt;code&gt;UPCE&lt;/code&gt;&lt;/p&gt; 
&lt;p align="center"&gt;&lt;img src="https://tupian.li/images/2023/11/19/6559911cda737.png" alt="4-äºŒç»´ç -2.png" style="width: 80%;" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;ç”Ÿæˆç &lt;/strong&gt;ï¼š&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;è¾“å…¥æ–‡æœ¬ï¼Œç”ŸæˆäºŒç»´ç å›¾ç‰‡ã€‚&lt;/li&gt; 
 &lt;li&gt;æ”¯æŒ19ç§åè®®å’Œ&lt;strong&gt;çº é”™ç­‰çº§&lt;/strong&gt;ç­‰å‚æ•°ã€‚&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h3&gt;å…¨å±€è®¾ç½®&lt;/h3&gt; 
&lt;p align="center"&gt;&lt;img src="https://tupian.li/images/2023/11/19/655991252e780.png" alt="5-å…¨å±€è®¾ç½®-1.png" style="width: 80%;" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;å…¨å±€è®¾ç½®&lt;/strong&gt;ï¼šåœ¨è¿™é‡Œå¯ä»¥è°ƒæ•´è½¯ä»¶çš„å…¨å±€å‚æ•°ã€‚å¸¸ç”¨åŠŸèƒ½å¦‚ä¸‹ï¼š&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;ä¸€é”®æ·»åŠ å¿«æ·æ–¹å¼æˆ–è®¾ç½®å¼€æœºè‡ªå¯ã€‚&lt;/li&gt; 
 &lt;li&gt;æ›´æ”¹ç•Œé¢&lt;strong&gt;è¯­è¨€&lt;/strong&gt;ã€‚Umiæ”¯æŒç¹ä¸­ã€è‹±è¯­ã€æ—¥è¯­ç­‰è¯­è¨€ã€‚&lt;/li&gt; 
 &lt;li&gt;åˆ‡æ¢ç•Œé¢&lt;strong&gt;ä¸»é¢˜&lt;/strong&gt;ã€‚Umiæ‹¥æœ‰å¤šä¸ªäº®/æš—ä¸»é¢˜ã€‚&lt;/li&gt; 
 &lt;li&gt;è°ƒæ•´ç•Œé¢&lt;strong&gt;æ–‡å­—çš„å¤§å°&lt;/strong&gt;å’Œ&lt;strong&gt;å­—ä½“&lt;/strong&gt;ã€‚&lt;/li&gt; 
 &lt;li&gt;åˆ‡æ¢OCRæ’ä»¶ã€‚&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;æ¸²æŸ“å™¨&lt;/strong&gt;ï¼šè½¯ä»¶ç•Œé¢é»˜è®¤æ”¯æŒæ˜¾å¡åŠ é€Ÿæ¸²æŸ“ã€‚å¦‚æœåœ¨ä½ çš„æœºå™¨ä¸Šå‡ºç°æˆªå±é—ªçƒã€UIé”™ä½çš„æƒ…å†µï¼Œè¯·è°ƒæ•´&lt;code&gt;ç•Œé¢å’Œå¤–è§‚&lt;/code&gt; â†’ &lt;code&gt;æ¸²æŸ“å™¨&lt;/code&gt; ï¼Œå°è¯•åˆ‡æ¢åˆ°ä¸åŒæ¸²æŸ“æ–¹æ¡ˆï¼Œæˆ–å…³é—­ç¡¬ä»¶åŠ é€Ÿã€‚&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;è°ƒç”¨æ¥å£ï¼š&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hiroi-sora/Umi-OCR/main/docs/README_CLI.md"&gt;å‘½ä»¤è¡Œæ‰‹å†Œ&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hiroi-sora/Umi-OCR/main/docs/http/README.md"&gt;HTTPæ¥å£æ‰‹å†Œ&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;å…³äºé¡¹ç›®ç»“æ„&lt;/h2&gt; 
&lt;h3&gt;å„ä»“åº“ï¼š&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/hiroi-sora/Umi-OCR"&gt;ä¸»ä»“åº“&lt;/a&gt; ğŸ‘ˆ&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/hiroi-sora/Umi-OCR_plugins"&gt;æ’ä»¶åº“&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/hiroi-sora/Umi-OCR_runtime_windows"&gt;Windows è¿è¡Œåº“&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/hiroi-sora/Umi-OCR_runtime_linux"&gt;Linux è¿è¡Œåº“&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;å·¥ç¨‹ç»“æ„ï¼š&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;**&lt;/code&gt; åç¼€è¡¨ç¤ºæœ¬ä»“åº“(&lt;code&gt;ä¸»ä»“åº“&lt;/code&gt;)åŒ…å«çš„å†…å®¹ã€‚&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Umi-OCR
â”œâ”€ Umi-OCR.exe
â”œâ”€ umi-ocr.sh
â””â”€ UmiOCR-data
   â”œâ”€ main.py **
   â”œâ”€ version.py **
   â”œâ”€ qt_res **
   â”‚  â””â”€ é¡¹ç›®qtèµ„æºï¼ŒåŒ…æ‹¬å›¾æ ‡å’Œqmlæºç 
   â”œâ”€ py_src **
   â”‚  â””â”€ é¡¹ç›®pythonæºç 
   â”œâ”€ plugins
   â”‚  â””â”€ æ’ä»¶
   â””â”€ i18n **
      â””â”€ ç¿»è¯‘æ–‡ä»¶
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;æ”¯æŒçš„ç¦»çº¿OCRå¼•æ“ï¼š&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/hiroi-sora/PaddleOCR-json"&gt;PaddleOCR-json&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/hiroi-sora/RapidOCR-json"&gt;RapidOCR-json&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;è¿è¡Œç¯å¢ƒæ¡†æ¶ï¼š&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/skywind3000/PyStand"&gt;PyStand&lt;/a&gt; å®šåˆ¶ç‰ˆ&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;æ„å»ºé¡¹ç›®&lt;/h2&gt; 
&lt;p&gt;è¯·è·³è½¬ä¸‹è¿°ä»“åº“ï¼Œå®Œæˆå¯¹åº”å¹³å°çš„å¼€å‘/è¿è¡Œç¯å¢ƒéƒ¨ç½²ã€‚&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/hiroi-sora/Umi-OCR_runtime_windows"&gt;Windows&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/hiroi-sora/Umi-OCR_runtime_linux"&gt;Linux&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;è½¯ä»¶æœ¬åœ°åŒ–ç¿»è¯‘ï¼š&lt;/h2&gt; 
&lt;p&gt;æœ¬é¡¹ç›®ä½¿ç”¨ Weblate å¹³å°è¿›è¡ŒUIç•Œé¢çš„æœ¬åœ°åŒ–ç¿»è¯‘åä½œã€‚æˆ‘ä»¬æ¬¢è¿ä»»ä½•è¯‘è€…å‚ä¸ç¿»è¯‘å·¥ä½œï¼Œæ‚¨å¯è¿›å…¥æ­¤é“¾æ¥ &lt;a href="https://hosted.weblate.org/engage/umi-ocr/"&gt;Weblate: Umi-OCR&lt;/a&gt; ï¼Œåœ¨çº¿æ ¡å¯¹ã€è¡¥å……ç°æœ‰è¯­è¨€ï¼Œæˆ–æ·»åŠ æ–°è¯­è¨€ã€‚&lt;/p&gt; 
&lt;p&gt;æ„Ÿè°¢ä»¥ä¸‹è¯‘è€…ï¼Œä¸º Umi-OCR è´¡çŒ®äº†æœ¬åœ°åŒ–ç¿»è¯‘å·¥ä½œï¼š&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;è¯‘è€…&lt;/th&gt; 
   &lt;th&gt;è´¡çŒ®è¯­è¨€&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://hosted.weblate.org/user/q021"&gt;bob&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;English, ç¹é«”ä¸­æ–‡, æ—¥æœ¬èª&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/QZGao"&gt;Qingzheng Gao&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;English, ç¹é«”ä¸­æ–‡&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://hosted.weblate.org/user/ChiaLingWeng"&gt;Weng, Chia-Ling&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;English, ç¹é«”ä¸­æ–‡&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://hosted.weblate.org/user/linzow"&gt;linzow&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;English, ç¹é«”ä¸­æ–‡&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://hosted.weblate.org/user/ultramarkorj9"&gt;Marcos i&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;English, PortuguÃªs&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://hosted.weblate.org/user/qwedc001"&gt;Eric Guo&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;English&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://hosted.weblate.org/user/steven0081"&gt;steven0081&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;English&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://hosted.weblate.org/user/random4t4x14"&gt;Brandon Cagle&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;English&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://hosted.weblate.org/user/plum7x"&gt;plum7x&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;ç¹é«”ä¸­æ–‡&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://hosted.weblate.org/user/hugoalh"&gt;hugoalh&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;ç¹é«”ä¸­æ–‡&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://hosted.weblate.org/user/Anarkiisto"&gt;Anarkiisto&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;ç¹é«”ä¸­æ–‡&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://hosted.weblate.org/user/umren190402"&gt;ãƒ‰ã‚³ãƒ¢å…‰&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;æ—¥æœ¬èª&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://hosted.weblate.org/user/ypf"&gt;æ¨é¹&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;PortuguÃªs&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://hosted.weblate.org/user/1969"&gt;Ğ’ÑÑ‡ĞµÑĞ»Ğ°Ğ² ĞĞ½Ğ°Ñ‚Ğ¾Ğ»ÑŒĞµĞ²Ğ¸Ñ‡ ĞœĞ°Ğ»Ñ‹ÑˆĞµĞ²&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Ğ ÑƒÑÑĞºĞ¸Ğ¹&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://hosted.weblate.org/user/muhammadyusuf.kurbonov2002"&gt;Muhammadyusuf Kurbonov&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Ğ ÑƒÑÑĞºĞ¸Ğ¹&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://hosted.weblate.org/user/TamilNeram/"&gt;à®¤à®®à®¿à®´à¯à®¨à¯‡à®°à®®à¯&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;à®¤à®®à®¿à®´à¯&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;å¦‚æœæœ‰ä¿¡æ¯é”™è¯¯æˆ–äººå‘˜ç¼ºæ¼ï¼Œè¯·åœ¨ &lt;a href="https://github.com/hiroi-sora/Umi-OCR/discussions/449"&gt;è¿™ä¸ªè®¨è®º&lt;/a&gt; ä¸­å›å¤ã€‚&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;èµåŠ©&lt;/h2&gt; 
&lt;p&gt;Umi-OCR é¡¹ç›®ä¸»è¦ç”±ä½œè€… &lt;a href="https://github.com/hiroi-sora"&gt;hiroi-sora&lt;/a&gt; ç”¨ä¸šä½™æ—¶é—´åœ¨å¼€å‘å’Œç»´æŠ¤ã€‚å¦‚æœæ‚¨å–œæ¬¢è¿™æ¬¾è½¯ä»¶ï¼Œæ¬¢è¿èµåŠ©ã€‚&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;å›½å†…ç”¨æˆ·å¯é€šè¿‡ &lt;a href="https://afdian.com/a/hiroi-sora"&gt;çˆ±å‘ç”µ&lt;/a&gt; èµåŠ©ä½œè€…ã€‚&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Star History&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://star-history.com/#hiroi-sora/Umi-OCR&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=hiroi-sora/Umi-OCR&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;&lt;a href="https://raw.githubusercontent.com/hiroi-sora/Umi-OCR/main/CHANGE_LOG.md"&gt;æ›´æ–°æ—¥å¿—&lt;/a&gt;&lt;/h2&gt; 
&lt;h2&gt;å¼€å‘è®¡åˆ’&lt;/h2&gt; 
&lt;details&gt; 
 &lt;summary&gt;å·²å®Œæˆçš„å·¥ä½œ&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;æ ‡ç­¾é¡µæ¡†æ¶ã€‚&lt;/li&gt; 
  &lt;li&gt;OCR APIæ§åˆ¶å™¨ã€‚&lt;/li&gt; 
  &lt;li&gt;OCR ä»»åŠ¡æ§åˆ¶å™¨ã€‚&lt;/li&gt; 
  &lt;li&gt;ä¸»é¢˜ç®¡ç†å™¨ï¼Œæ”¯æŒåˆ‡æ¢æµ…è‰²/æ·±è‰²ä¸»é¢˜ä¸»é¢˜ã€‚&lt;/li&gt; 
  &lt;li&gt;å®ç° &lt;strong&gt;æ‰¹é‡OCR&lt;/strong&gt;ã€‚&lt;/li&gt; 
  &lt;li&gt;å®ç° &lt;strong&gt;æˆªå›¾OCR&lt;/strong&gt;ã€‚&lt;/li&gt; 
  &lt;li&gt;å¿«æ·é”®æœºåˆ¶ã€‚&lt;/li&gt; 
  &lt;li&gt;ç³»ç»Ÿæ‰˜ç›˜èœå•ã€‚&lt;/li&gt; 
  &lt;li&gt;æ–‡æœ¬å—åå¤„ç†ï¼ˆæ’ç‰ˆä¼˜åŒ–ï¼‰ã€‚&lt;/li&gt; 
  &lt;li&gt;å¼•æ“å†…å­˜æ¸…ç†ã€‚&lt;/li&gt; 
  &lt;li&gt;è½¯ä»¶ç•Œé¢å¤šå›½è¯­è¨€ã€‚&lt;/li&gt; 
  &lt;li&gt;å‘½ä»¤è¡Œæ¨¡å¼ã€‚&lt;/li&gt; 
  &lt;li&gt;Win7å…¼å®¹ã€‚&lt;/li&gt; 
  &lt;li&gt;Excelï¼ˆcsvï¼‰è¾“å‡ºæ ¼å¼ã€‚&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;Esc&lt;/code&gt;ä¸­æ–­æˆªå›¾æ“ä½œ&lt;/li&gt; 
  &lt;li&gt;å¤–ç½®ä¸»é¢˜æ–‡ä»¶&lt;/li&gt; 
  &lt;li&gt;å­—ä½“åˆ‡æ¢&lt;/li&gt; 
  &lt;li&gt;åŠ è½½åŠ¨ç”»&lt;/li&gt; 
  &lt;li&gt;å¿½ç•¥åŒºåŸŸã€‚&lt;/li&gt; 
  &lt;li&gt;äºŒç»´ç è¯†åˆ«ã€‚&lt;/li&gt; 
  &lt;li&gt;æ‰¹é‡è¯†åˆ«é¡µé¢çš„å›¾ç‰‡é¢„è§ˆçª—å£ã€‚&lt;/li&gt; 
  &lt;li&gt;PDFè¯†åˆ«ã€‚&lt;/li&gt; 
  &lt;li&gt;è°ƒç”¨æœ¬åœ°å›¾ç‰‡æµè§ˆå™¨æ‰“å¼€å›¾ç‰‡ã€‚ &lt;a href="https://github.com/hiroi-sora/Umi-OCR/issues/335"&gt;#335&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;é‡å¤ä¸Šä¸€æ¬¡æˆªå›¾ã€‚ &lt;a href="https://github.com/hiroi-sora/Umi-OCR/issues/357"&gt;#357&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;ä¿®Bugï¼šæ–‡æ¡£è¯†åˆ«åœ¨Windows7ç³»ç»Ÿçš„å…¼å®¹æ€§é—®é¢˜ã€‚&lt;/li&gt; 
  &lt;li&gt;HTTP/å‘½ä»¤è¡Œæ¥å£æ·»åŠ äºŒç»´ç è¯†åˆ«/ç”ŸæˆåŠŸèƒ½ã€‚ (#423)&lt;/li&gt; 
  &lt;li&gt;äºŒç»´ç æ¥å£çš„æ–‡æ¡£ã€‚&lt;/li&gt; 
  &lt;li&gt;Linux å¹³å°ç§»æ¤ã€‚&lt;/li&gt; 
  &lt;li&gt;HTTP æ–‡æ¡£è¯†åˆ«æ¥å£ã€‚&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;!-- ##### æ­£åœ¨è¿›è¡Œçš„å·¥ä½œ --&gt; 
&lt;h5&gt;è¿œæœŸè®¡åˆ’&lt;/h5&gt; 
&lt;details&gt; 
 &lt;summary&gt;å±•å¼€&lt;/summary&gt; 
 &lt;p&gt;è¿™äº›æ˜¯é¢„æƒ³ä¸­çš„åŠŸèƒ½ï¼Œåœ¨å¼€å‘åˆæœŸå·²é¢„ç•™å¥½æ¥å£ï¼Œå°†åœ¨è¿œæœŸæ…¢æ…¢å®ç°ã€‚&lt;/p&gt; 
 &lt;p&gt;ä½†å¼€å‘é€”ä¸­å—é™äºå®é™…æƒ…å†µï¼Œå¯èƒ½æ›´æ”¹åŠŸèƒ½è®¾è®¡ã€æ–°å¢åŠå–æ¶ˆåŠŸèƒ½ã€‚&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;p&gt;é‡æ„åº•å±‚æ’ä»¶æœºåˆ¶ã€‚&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;p&gt;åœ¨çº¿ OCR API æ’ä»¶ã€‚&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;p&gt;ç‹¬ç«‹çš„æ•°å­¦å…¬å¼è¯†åˆ«æ’ä»¶ã€‚&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;p&gt;â€œæ•°å­¦å…¬å¼â€æ ‡ç­¾é¡µï¼Œæä¾›ç‹¬ç«‹çš„æ•°å­¦å…¬å¼è¯†åˆ«/Latexæ¸²æŸ“ã€‚&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;p&gt;æ£€æŸ¥æ›´æ–°æœºåˆ¶ã€‚&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;p&gt;æ’ç‰ˆè§£æä¹‹å¤–çš„æ–‡æœ¬åå¤„ç†æ¨¡å—ï¼ˆå¦‚ä¿ç•™æ•°å­—ã€åŠå…¨è§’å­—ç¬¦è½¬æ¢ã€æ–‡æœ¬çº é”™ï¼‰ã€‚&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;p&gt;å…³é”®æ¥å£å‡½æ•°æ·»åŠ äº‹ä»¶è§¦å‘æ–¹å¼ã€‚&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;åŸºäºGPUçš„ç¦»çº¿OCRã€‚&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;å›¾ç‰‡ç¿»è¯‘&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;ç¦»çº¿ç¿»è¯‘ã€‚&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;å›ºå®šåŒºåŸŸè¯†åˆ«ã€‚&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;è¯†åˆ«è¡¨æ ¼å›¾ç‰‡ï¼Œè¾“å‡ºä¸ºExcelã€‚&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;å†å²è®°å½•ç³»ç»Ÿã€‚&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;å…¼å®¹ MacOS / Ubuntu ç­‰å¹³å°ã€‚&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt;</description>
    </item>
    
    <item>
      <title>Vector-Wangel/XLeRobot</title>
      <link>https://github.com/Vector-Wangel/XLeRobot</link>
      <description>&lt;p&gt;XLeRobot: Practical Dual-Arm Mobile Home Robot for $660&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;&lt;a href="https://xlerobot.readthedocs.io/en/latest/index.html"&gt;XLeRobot ğŸ¤–&lt;/a&gt;&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/Vector-Wangel/XLeRobot/main/README.md"&gt;&lt;img src="https://img.shields.io/badge/lang-en-blue.svg?sanitize=true" alt="en" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Vector-Wangel/XLeRobot/main/README_CN.md"&gt;&lt;img src="https://img.shields.io/badge/lang-%E4%B8%AD%E6%96%87-brown.svg?sanitize=true" alt="ä¸­æ–‡" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;a href="https://xlerobot.readthedocs.io/en/latest/index.html"&gt; &lt;img width="1725" height="1140" alt="front" src="https://github.com/user-attachments/assets/f9c454ee-2c46-42b4-a5d7-88834a1c95ab" /&gt; &lt;/a&gt; 
&lt;h2&gt;&lt;a href="https://opensource.org/licenses/Apache-2.0"&gt;&lt;img src="https://img.shields.io/badge/License-Apache%202.0-blue.svg?sanitize=true" alt="Apache License" /&gt;&lt;/a&gt; &lt;a href="https://twitter.com/VectorWang2"&gt;&lt;img src="https://img.shields.io/twitter/follow/VectorWang?style=social" alt="Twitter/X" /&gt;&lt;/a&gt; &lt;a href="https://xlerobot.readthedocs.io/en/latest/"&gt;&lt;img src="https://img.shields.io/badge/docs-passing-brightgreen.svg?sanitize=true" alt="Docs status" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/bjZveEUh6F"&gt;&lt;img src="https://img.shields.io/badge/Discord-XLeRobot-7289da?style=flat&amp;amp;logo=discord&amp;amp;logoColor=white" alt="Discord" /&gt;&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;ğŸš€ Bringing Embodied AI to Everyone - Cheaper Than an iPhone! ğŸ“±&lt;/strong&gt;&lt;br /&gt; &lt;strong&gt;ğŸ’µ Starts from $660 cost and â° &amp;lt;4hrs total assembly time!!&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;Built upon the giants: &lt;a href="https://github.com/huggingface/lerobot"&gt;LeRobot&lt;/a&gt;, &lt;a href="https://github.com/TheRobotStudio/SO-ARM100"&gt;SO-100/SO-101&lt;/a&gt;, &lt;a href="https://github.com/SIGRobotics-UIUC/LeKiwi"&gt;Lekiwi&lt;/a&gt;, &lt;a href="https://github.com/timqian/bambot"&gt;Bambot&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src="https://github.com/user-attachments/assets/17e31979-bd5e-4790-be70-566ea8bb181e" width="250" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://github.com/user-attachments/assets/96ff4a3e-3402-47a2-bc6b-b45137ee3fdd" width="250" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://github.com/user-attachments/assets/f6d52acc-bc8d-46f6-b3cd-8821f0306a7f" width="250" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src="https://github.com/user-attachments/assets/59086300-3e6f-4a3c-b5e0-db893eeabc0c" width="250" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://github.com/user-attachments/assets/4ddbc0ff-ca42-4ad0-94c6-4e0f4047fd01" width="250" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://github.com/user-attachments/assets/7abc890e-9c9c-4983-8b25-122573028de5" width="250" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src="https://github.com/user-attachments/assets/e74a602b-0146-49c4-953d-3fa3b038a7f7" width="250" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://github.com/user-attachments/assets/d8090b15-97f3-4abc-98c8-208ae79894d5" width="250" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://github.com/user-attachments/assets/8b54adc3-d61b-42a0-8985-ea28f2e8f64c" width="250" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;hr /&gt; 
&lt;h1&gt;ğŸ“° News&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;2025-09-09: Joined &lt;a href="https://www.seeedstudio.com/embodied-ai-worldwide-hackathon-home-robot.html"&gt;Embodied AI Home Robot Hackathon&lt;/a&gt; (Oct 25â€“26, Bay Area) held by &lt;strong&gt;SEEED x Nvidia x Huggingface&lt;/strong&gt; as mentor! &lt;a href="https://docs.google.com/forms/d/e/1FAIpQLSdYYDegdgIypxuGJNLcoc8kbdmU4jKgl49zg4X-107LAmBN4g/viewform"&gt;Register HERE&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;img width="2400" height="1256" alt="image" src="https://github.com/user-attachments/assets/4132c23b-5c86-4bb9-94b4-a6b12059685b" /&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;2025-08-30: XLeRobot 0.3.0 Release with final outfit touch up and household chores showcase demos. &lt;a href="https://e.tb.cn/h.SZFbBgZABZ8zRPe?tk=ba514rTBRjQ"&gt;&lt;strong&gt;Developer Assembly kit ready for purchase&lt;/strong&gt; in China&lt;/a&gt;. (Non-profit, only for convenient accessiblity. I personally don't earn any from this)&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;img src="https://github.com/user-attachments/assets/1ba9b140-1c9c-418d-be41-954cd9d1fa89" width="150" /&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;2025-07-30: &lt;a href="https://xlerobot.readthedocs.io/en/latest/software/index.html"&gt;Control XLeRobot in real life&lt;/a&gt; with &lt;strong&gt;keyboard/Xbox controller/Switch joycon&lt;/strong&gt; in the wild anywhere. All bluetooth, no wifi needed and zero latency.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/de8f50ad-a370-406c-97fb-fc01638d5624" alt="rea" /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;2025-07-08: &lt;a href="https://xlerobot.readthedocs.io/en/latest/simulation/index.html"&gt;&lt;strong&gt;Simulation&lt;/strong&gt;&lt;/a&gt; with updated urdfs, control scripts (support Quest3 VR, keyboard, Xbox controller, switch joycon), support for new hardware and cameras, RL environment. Get started in 15 min.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/68b77bea-fdcf-4f42-9cf0-efcf1b188358" alt="vr" /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;2025-07-01: &lt;a href="https://xlerobot.readthedocs.io/en/latest/index.html"&gt;&lt;strong&gt;Documentation&lt;/strong&gt; website&lt;/a&gt; out for more orgainized tutorials, demos and resources.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;2025-06-13: &lt;a href="https://xlerobot.readthedocs.io"&gt;&lt;strong&gt;XLeRobot 0.2.0&lt;/strong&gt;&lt;/a&gt; hardware setup, the 1st version fully capable for autonomous household tasks, starts from 660$.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ğŸ’µ Total Cost ğŸ’µ&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] Cost excludes 3D printing, tools, shipping, and taxes.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Price (Buy all the parts yourself)&lt;/th&gt; 
   &lt;th&gt;US&lt;/th&gt; 
   &lt;th&gt;EU&lt;/th&gt; 
   &lt;th&gt;CN&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Basic&lt;/strong&gt; (use your laptop, single RGB head cam)&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;~$660&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;~â‚¬680&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;~Â¥3999&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;â†‘ Stereo dual-eye RGB head cam&lt;/td&gt; 
   &lt;td&gt;+$30&lt;/td&gt; 
   &lt;td&gt;+â‚¬30&lt;/td&gt; 
   &lt;td&gt;+Â¥199&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;+ RasberryPi&lt;/td&gt; 
   &lt;td&gt;+$79&lt;/td&gt; 
   &lt;td&gt;+â‚¬79&lt;/td&gt; 
   &lt;td&gt;+Â¥399&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;â†‘ RealSense RGBD head cam&lt;/td&gt; 
   &lt;td&gt;+$220&lt;/td&gt; 
   &lt;td&gt;+â‚¬230&lt;/td&gt; 
   &lt;td&gt;+Â¥1499&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ğŸš€ Get Started ğŸš€&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] If you are totally new to programming, please spend at least a day to get yourself familiar with basic Python, Ubuntu and Github (with the help of Google and AI). At least you should know how to setup ubuntu system, git clone, pip install, use intepreters (VS Code, Cursor, Pycharm, etc.) and directly run commands in the terminals.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ol&gt; 
 &lt;li&gt;ğŸ’µ &lt;strong&gt;Buy your parts&lt;/strong&gt;: &lt;a href="https://xlerobot.readthedocs.io/en/latest/hardware/getting_started/material.html"&gt;Bill of Materials&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;ğŸ–¨ï¸ &lt;strong&gt;Print your stuff&lt;/strong&gt;: &lt;a href="https://xlerobot.readthedocs.io/en/latest/hardware/getting_started/3d.html"&gt;3D printing&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;ğŸ”¨ &lt;del&gt;Avengers&lt;/del&gt;: &lt;a href="https://xlerobot.readthedocs.io/en/latest/hardware/getting_started/assemble.html"&gt;&lt;strong&gt;Assemble&lt;/strong&gt;!&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;ğŸ’» &lt;strong&gt;Software&lt;/strong&gt;: &lt;a href="https://xlerobot.readthedocs.io/en/latest/software/index.html"&gt;Get your robot moving!&lt;/a&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Contribute&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;ğŸ‘‹ Want to contribute to XLeRobot?&lt;/strong&gt; Please refer to &lt;a href="https://raw.githubusercontent.com/Vector-Wangel/XLeRobot/main/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; for guidance on how to get involved!&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Main Contributors&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://vector-wangel.github.io/"&gt;Gaotian/Vector Wang&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://lzhuoyi.github.io/Zhuoyi_Lu.github.io/"&gt;Zhuoyi Lu&lt;/a&gt;: RL sim2real deploy, teleop on real robot (Xbox, VR, Joycon)&lt;/li&gt; 
 &lt;li&gt;Nicole Yue: Documentation website setup&lt;/li&gt; 
 &lt;li&gt;Yuesong Wang: Mujoco simulation&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;This is just a small brick in the pyramid, made possible by&amp;nbsp;&lt;a href="https://github.com/huggingface/lerobot"&gt;LeRobot&lt;/a&gt;,&amp;nbsp;&lt;a href="https://github.com/TheRobotStudio/SO-ARM100"&gt;SO-100&lt;/a&gt;,&amp;nbsp;&lt;a href="https://github.com/SIGRobotics-UIUC/LeKiwi"&gt;Lekiwi&lt;/a&gt;, and&amp;nbsp;&lt;a href="https://github.com/timqian/bambot"&gt;Bambot&lt;/a&gt;. Thanks to all the talented contributors behind these detailed and professional projects.&lt;/p&gt; 
&lt;p&gt;Looking forward to collaborating with anyone interested in contributing to this project!&lt;/p&gt; 
&lt;h2&gt;About me&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://vector-wangel.github.io/"&gt;Gaotian/Vector Wang&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;I am a CS graduate student at Rice University &lt;a href="https://robotpilab.github.io/"&gt;RobotPi Lab&lt;/a&gt;, focusing on robust object manipulation, where we propse virtual cages and funnels and physics-aware world models to close the Sim2real gap and achieve robust manipulation under uncertainties. One of my papers, Caging in Time, has recently been accepted by International Journal of Robotics Research (IJRR).&lt;/p&gt; 
&lt;p&gt;I built XLeRobot as a personal hobby to instantiate my research theory, also to provide a low-cost platform for people who are interested in robotics and embodied AI to work with.&lt;/p&gt; 
&lt;h2&gt;&lt;a href="https://star-history.com/#Vector-Wangel/XLeRobot&amp;amp;Timeline"&gt;&lt;img src="https://api.star-history.com/svg?repos=Vector-Wangel/XLeRobot&amp;amp;type=Timeline" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/h2&gt; 
&lt;h2&gt;Citation&lt;/h2&gt; 
&lt;p&gt;If you want, you can cite this work with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bibtex"&gt;@misc{wang2025xlerobot,
    author = {Wang, Gaotian and Lu, Zhuoyi},
    title = {XLeRobot: A Practical Low-cost Household Dual-Arm Mobile Robot Design for General Manipulation},
    howpublished = "\url{https://github.com/Vector-Wangel/XLeRobot}",
    year = {2025}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;---&lt;img src="https://github.com/user-attachments/assets/682ef049-bb42-4b50-bf98-74d6311e774d" alt="Generated Image August 27, 2025 - 4_58PM" /&gt;&lt;/p&gt; 
&lt;h2&gt;ğŸª§ Disclaimer ğŸª§&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] If you build, buy, or develop a XLeRobot based on this repo, you will be fully responsible for all the physical and mental damages it does to you or others.&lt;/p&gt; 
&lt;/blockquote&gt;</description>
    </item>
    
    <item>
      <title>Eventual-Inc/Daft</title>
      <link>https://github.com/Eventual-Inc/Daft</link>
      <description>&lt;p&gt;Distributed query engine providing simple and reliable data processing for any modality and scale&lt;/p&gt;&lt;hr&gt;&lt;p&gt;|Banner|&lt;/p&gt; 
&lt;p&gt;|CI| |PyPI| |Latest Tag| |Coverage| |Slack|&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;Website &amp;lt;https://www.daft.ai&amp;gt;&lt;/code&gt;_ â€¢ &lt;code&gt;Docs &amp;lt;https://docs.daft.ai&amp;gt;&lt;/code&gt;_ â€¢ &lt;code&gt;Installation &amp;lt;https://docs.daft.ai/en/stable/install/&amp;gt;&lt;/code&gt;_ â€¢ &lt;code&gt;Daft Quickstart &amp;lt;https://docs.daft.ai/en/stable/quickstart/&amp;gt;&lt;/code&gt;_ â€¢ &lt;code&gt;Community and Support &amp;lt;https://github.com/Eventual-Inc/Daft/discussions&amp;gt;&lt;/code&gt;_&lt;/p&gt; 
&lt;h1&gt;Daft: Unified Engine for Data Analytics, Engineering &amp;amp; ML/AI&lt;/h1&gt; 
&lt;p&gt;|TrendShift|&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;Daft &amp;lt;https://www.daft.ai&amp;gt;&lt;/code&gt;_ is a distributed query engine for large-scale data processing using Python or SQL, implemented in Rust.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Familiar interactive API:&lt;/strong&gt; Lazy Python Dataframe for rapid and interactive iteration, or SQL for analytical queries&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Focus on the what:&lt;/strong&gt; Powerful Query Optimizer that rewrites queries to be as efficient as possible&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Data Catalog integrations:&lt;/strong&gt; Full integration with data catalogs such as Apache Iceberg&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Rich multimodal type-system:&lt;/strong&gt; Supports multimodal types such as Images, URLs, Tensors and more&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Seamless Interchange&lt;/strong&gt;: Built on the &lt;code&gt;Apache Arrow &amp;lt;https://arrow.apache.org/docs/index.html&amp;gt;&lt;/code&gt;_ In-Memory Format&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Built for the cloud:&lt;/strong&gt; &lt;code&gt;Record-setting &amp;lt;https://www.daft.ai/blog/announcing-daft-02&amp;gt;&lt;/code&gt;_ I/O performance for integrations with S3 cloud storage&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Table of Contents&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;About Daft&lt;/code&gt;_&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;Getting Started&lt;/code&gt;_&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;Benchmarks&lt;/code&gt;_&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;Contributing&lt;/code&gt;_&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;Telemetry&lt;/code&gt;_&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;Related Projects&lt;/code&gt;_&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;License&lt;/code&gt;_&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;About Daft&lt;/h2&gt; 
&lt;p&gt;Daft was designed with the following principles in mind:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Any Data&lt;/strong&gt;: Beyond the usual strings/numbers/dates, Daft columns can also hold complex or nested multimodal data such as Images, Embeddings and Python objects efficiently with its Arrow based memory representation. Ingestion and basic transformations of multimodal data is extremely easy and performant in Daft.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Interactive Computing&lt;/strong&gt;: Daft is built for the interactive developer experience through notebooks or REPLs - intelligent caching/query optimizations accelerates your experimentation and data exploration.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Distributed Computing&lt;/strong&gt;: Some workloads can quickly outgrow your local laptop's computational resources - Daft integrates natively with &lt;code&gt;Ray &amp;lt;https://www.ray.io&amp;gt;&lt;/code&gt;_ for running dataframes on large clusters of machines with thousands of CPUs/GPUs.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;p&gt;Installation ^^^^^^^^^^^^&lt;/p&gt; 
&lt;p&gt;Install Daft with &lt;code&gt;pip install daft&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;For more advanced installations (e.g. installing from source or with extra dependencies such as Ray and AWS utilities), please see our &lt;code&gt;Installation Guide &amp;lt;https://docs.daft.ai/en/stable/install/&amp;gt;&lt;/code&gt;_&lt;/p&gt; 
&lt;p&gt;Quickstart ^^^^^^^^^^&lt;/p&gt; 
&lt;p&gt;Check out our &lt;code&gt;quickstart &amp;lt;https://docs.daft.ai/en/stable/quickstart/&amp;gt;&lt;/code&gt;_!&lt;/p&gt; 
&lt;p&gt;In this example, we load images from an AWS S3 bucket's URLs and resize each image in the dataframe:&lt;/p&gt; 
&lt;p&gt;.. code:: python&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;import daft

# Load a dataframe from filepaths in an S3 bucket
df = daft.from_glob_path("s3://daft-public-data/laion-sample-images/*")

# 1. Download column of image URLs as a column of bytes
# 2. Decode the column of bytes into a column of images
df = df.with_column("image", df["path"].url.download().image.decode())

# Resize each image into 32x32
df = df.with_column("resized", df["image"].image.resize(32, 32))

df.show(3)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;|Quickstart Image|&lt;/p&gt; 
&lt;h2&gt;Benchmarks&lt;/h2&gt; 
&lt;p&gt;|Benchmark Image|&lt;/p&gt; 
&lt;p&gt;To see the full benchmarks, detailed setup, and logs, check out our &lt;code&gt;benchmarking page. &amp;lt;https://docs.daft.ai/en/stable/resources/benchmarks/tpch/&amp;gt;&lt;/code&gt;_&lt;/p&gt; 
&lt;p&gt;More Resources ^^^^^^^^^^^^^^&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;Daft Quickstart &amp;lt;https://docs.daft.ai/en/stable/quickstart/&amp;gt;&lt;/code&gt;_ - learn more about Daft's full range of capabilities including dataloading from URLs, joins, user-defined functions (UDF), groupby, aggregations and more.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;User Guide &amp;lt;https://docs.daft.ai/en/stable/&amp;gt;&lt;/code&gt;_ - take a deep-dive into each topic within Daft&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;API Reference &amp;lt;https://docs.daft.ai/en/stable/api/&amp;gt;&lt;/code&gt;_ - API reference for public classes/functions of Daft&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;SQL Reference &amp;lt;https://docs.daft.ai/en/stable/sql/&amp;gt;&lt;/code&gt;_ - Daft SQL reference&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We &amp;lt;3 developers! To start contributing to Daft, please read &lt;code&gt;CONTRIBUTING.md &amp;lt;https://github.com/Eventual-Inc/Daft/blob/main/CONTRIBUTING.md&amp;gt;&lt;/code&gt;_. This document describes the development lifecycle and toolchain for working on Daft. It also details how to add new functionality to the core engine and expose it through a Python API.&lt;/p&gt; 
&lt;p&gt;Here's a list of &lt;code&gt;good first issues &amp;lt;https://github.com/Eventual-Inc/Daft/issues?q=is%3Aopen+is%3Aissue+label%3A%22good+first+issue%22&amp;gt;&lt;/code&gt;_ to get yourself warmed up with Daft. Comment in the issue to pick it up, and feel free to ask any questions!&lt;/p&gt; 
&lt;h2&gt;Telemetry&lt;/h2&gt; 
&lt;p&gt;To help improve Daft, we collect non-identifiable data via Scarf (&lt;a href="https://scarf.sh"&gt;https://scarf.sh&lt;/a&gt;).&lt;/p&gt; 
&lt;p&gt;To disable this behavior, set the environment variable &lt;code&gt;DO_NOT_TRACK=true&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;The data that we collect is:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Non-identifiable:&lt;/strong&gt; Events are keyed by a session ID which is generated on import of Daft&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Metadata-only:&lt;/strong&gt; We do not collect any of our usersâ€™ proprietary code or data&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;For development only:&lt;/strong&gt; We do not buy or sell any user data&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Please see our &lt;code&gt;documentation &amp;lt;https://docs.daft.ai/en/stable/resources/telemetry/&amp;gt;&lt;/code&gt;_ for more details.&lt;/p&gt; 
&lt;p&gt;.. image:: &lt;a href="https://static.scarf.sh/a.png?x-pxid=31f8d5ba-7e09-4d75-8895-5252bbf06cf6"&gt;https://static.scarf.sh/a.png?x-pxid=31f8d5ba-7e09-4d75-8895-5252bbf06cf6&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Related Projects&lt;/h2&gt; 
&lt;p&gt;+---------------------------------------------------+-----------------+---------------+-------------+-----------------+-----------------------------+-------------+ | Engine | Query Optimizer | Multimodal | Distributed | Arrow Backed | Vectorized Execution Engine | Out-of-core | +===================================================+=================+===============+=============+=================+=============================+=============+ | Daft | Yes | Yes | Yes | Yes | Yes | Yes | +---------------------------------------------------+-----------------+---------------+-------------+-----------------+-----------------------------+-------------+ | &lt;code&gt;Pandas &amp;lt;https://github.com/pandas-dev/pandas&amp;gt;&lt;/code&gt;_ | No | Python object | No | optional &amp;gt;= 2.0 | Some(Numpy) | No | +---------------------------------------------------+-----------------+---------------+-------------+-----------------+-----------------------------+-------------+ | &lt;code&gt;Polars &amp;lt;https://github.com/pola-rs/polars&amp;gt;&lt;/code&gt;_ | Yes | Python object | No | Yes | Yes | Yes | +---------------------------------------------------+-----------------+---------------+-------------+-----------------+-----------------------------+-------------+ | &lt;code&gt;Modin &amp;lt;https://github.com/modin-project/modin&amp;gt;&lt;/code&gt;_ | Yes | Python object | Yes | No | Some(Pandas) | Yes | +---------------------------------------------------+-----------------+---------------+-------------+-----------------+-----------------------------+-------------+ | &lt;code&gt;Pyspark &amp;lt;https://github.com/apache/spark&amp;gt;&lt;/code&gt;_ | Yes | No | Yes | Pandas UDF/IO | Pandas UDF | Yes | +---------------------------------------------------+-----------------+---------------+-------------+-----------------+-----------------------------+-------------+ | &lt;code&gt;Dask DF &amp;lt;https://github.com/dask/dask&amp;gt;&lt;/code&gt;_ | No | Python object | Yes | No | Some(Pandas) | Yes | +---------------------------------------------------+-----------------+---------------+-------------+-----------------+-----------------------------+-------------+&lt;/p&gt; 
&lt;p&gt;Check out our &lt;code&gt;engine comparison page &amp;lt;https://docs.daft.ai/en/stable/resources/engine_comparison/&amp;gt;&lt;/code&gt;_ for more details!&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Daft has an Apache 2.0 license - please see the LICENSE file.&lt;/p&gt; 
&lt;p&gt;.. |Quickstart Image| image:: &lt;a href="https://github.com/Eventual-Inc/Daft/assets/17691182/dea2f515-9739-4f3e-ac58-cd96d51e44a8"&gt;https://github.com/Eventual-Inc/Daft/assets/17691182/dea2f515-9739-4f3e-ac58-cd96d51e44a8&lt;/a&gt; :alt: Dataframe code to load a folder of images from AWS S3 and create thumbnails :height: 256&lt;/p&gt; 
&lt;p&gt;.. |Benchmark Image| image:: &lt;a href="https://github-production-user-asset-6210df.s3.amazonaws.com/2550285/243524430-338e427d-f049-40b3-b555-4059d6be7bfd.png"&gt;https://github-production-user-asset-6210df.s3.amazonaws.com/2550285/243524430-338e427d-f049-40b3-b555-4059d6be7bfd.png&lt;/a&gt; :alt: Benchmarks for SF100 TPCH&lt;/p&gt; 
&lt;p&gt;.. |Banner| image:: &lt;a href="https://daft.ai/images/diagram.png"&gt;https://daft.ai/images/diagram.png&lt;/a&gt; :target: &lt;a href="https://www.daft.ai"&gt;https://www.daft.ai&lt;/a&gt; :alt: Daft dataframes can load any data such as PDF documents, images, protobufs, csv, parquet and audio files into a table dataframe structure for easy querying&lt;/p&gt; 
&lt;p&gt;.. |CI| image:: &lt;a href="https://github.com/Eventual-Inc/Daft/actions/workflows/pr-test-suite.yml/badge.svg"&gt;https://github.com/Eventual-Inc/Daft/actions/workflows/pr-test-suite.yml/badge.svg&lt;/a&gt; :target: &lt;a href="https://github.com/Eventual-Inc/Daft/actions/workflows/pr-test-suite.yml?query=branch:main"&gt;https://github.com/Eventual-Inc/Daft/actions/workflows/pr-test-suite.yml?query=branch:main&lt;/a&gt; :alt: GitHub Actions tests&lt;/p&gt; 
&lt;p&gt;.. |PyPI| image:: &lt;a href="https://img.shields.io/pypi/v/daft.svg?label=pip&amp;amp;logo=PyPI&amp;amp;logoColor=white"&gt;https://img.shields.io/pypi/v/daft.svg?label=pip&amp;amp;logo=PyPI&amp;amp;logoColor=white&lt;/a&gt; :target: &lt;a href="https://pypi.org/project/daft"&gt;https://pypi.org/project/daft&lt;/a&gt; :alt: PyPI&lt;/p&gt; 
&lt;p&gt;.. |Latest Tag| image:: &lt;a href="https://img.shields.io/github/v/tag/Eventual-Inc/Daft?label=latest&amp;amp;logo=GitHub"&gt;https://img.shields.io/github/v/tag/Eventual-Inc/Daft?label=latest&amp;amp;logo=GitHub&lt;/a&gt; :target: &lt;a href="https://github.com/Eventual-Inc/Daft/tags"&gt;https://github.com/Eventual-Inc/Daft/tags&lt;/a&gt; :alt: latest tag&lt;/p&gt; 
&lt;p&gt;.. |Coverage| image:: &lt;a href="https://codecov.io/gh/Eventual-Inc/Daft/branch/main/graph/badge.svg?token=J430QVFE89"&gt;https://codecov.io/gh/Eventual-Inc/Daft/branch/main/graph/badge.svg?token=J430QVFE89&lt;/a&gt; :target: &lt;a href="https://codecov.io/gh/Eventual-Inc/Daft"&gt;https://codecov.io/gh/Eventual-Inc/Daft&lt;/a&gt; :alt: Coverage&lt;/p&gt; 
&lt;p&gt;.. |Slack| image:: &lt;a href="https://img.shields.io/badge/slack-@distdata-purple.svg?logo=slack"&gt;https://img.shields.io/badge/slack-@distdata-purple.svg?logo=slack&lt;/a&gt; :target: &lt;a href="https://join.slack.com/t/dist-data/shared_invite/zt-2e77olvxw-uyZcPPV1SRchhi8ah6ZCtg"&gt;https://join.slack.com/t/dist-data/shared_invite/zt-2e77olvxw-uyZcPPV1SRchhi8ah6ZCtg&lt;/a&gt; :alt: slack community&lt;/p&gt; 
&lt;p&gt;.. |TrendShift| image:: &lt;a href="https://trendshift.io/api/badge/repositories/8239"&gt;https://trendshift.io/api/badge/repositories/8239&lt;/a&gt; :target: &lt;a href="https://trendshift.io/repositories/8239"&gt;https://trendshift.io/repositories/8239&lt;/a&gt; :alt: Eventual-Inc/Daft | Trendshift :width: 250px :height: 55px&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>pathwaycom/pathway</title>
      <link>https://github.com/pathwaycom/pathway</link>
      <description>&lt;p&gt;Python ETL framework for stream processing, real-time analytics, LLM pipelines, and RAG.&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;a href="https://pathway.com/"&gt; &lt;img src="https://pathway.com/logo-light.svg?sanitize=true" /&gt; &lt;/a&gt; 
 &lt;br /&gt;
 &lt;br /&gt; 
 &lt;a href="https://trendshift.io/repositories/10388" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/10388" alt="pathwaycom%2Fpathway | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt; 
 &lt;br /&gt;
 &lt;br /&gt; 
&lt;/div&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/pathwaycom/pathway/actions/workflows/ubuntu_test.yml"&gt; &lt;img src="https://github.com/pathwaycom/pathway/actions/workflows/ubuntu_test.yml/badge.svg?sanitize=true" alt="ubuntu" /&gt; &lt;br /&gt; &lt;/a&gt;&lt;a href="https://github.com/pathwaycom/pathway/actions/workflows/release.yml"&gt; &lt;img src="https://github.com/pathwaycom/pathway/actions/workflows/release.yml/badge.svg?sanitize=true" alt="Last release" /&gt;&lt;/a&gt; &lt;a href="https://badge.fury.io/py/pathway"&gt;&lt;img src="https://badge.fury.io/py/pathway.svg?sanitize=true" alt="PyPI version" height="18" /&gt;&lt;/a&gt; &lt;a href="https://badge.fury.io/py/pathway"&gt;&lt;img src="https://static.pepy.tech/badge/pathway" alt="PyPI downloads" height="18" /&gt;&lt;/a&gt; &lt;a href="https://github.com/pathwaycom/pathway/raw/main/LICENSE.txt"&gt; &lt;img src="https://img.shields.io/badge/license-BSL-green" alt="License: BSL" /&gt;&lt;/a&gt; &lt;br /&gt; &lt;a href="https://discord.gg/pathway"&gt; &lt;img src="https://img.shields.io/discord/1042405378304004156?logo=discord" alt="chat on Discord" /&gt;&lt;/a&gt; &lt;a href="https://twitter.com/intent/follow?screen_name=pathway_com"&gt; &lt;img src="https://img.shields.io/twitter/follow/pathwaycom" alt="follow on Twitter" /&gt;&lt;/a&gt; &lt;a href="https://linkedin.com/company/pathway"&gt; &lt;img src="https://img.shields.io/badge/pathway-0077B5?style=social&amp;amp;logo=linkedin" alt="follow on LinkedIn" /&gt;&lt;/a&gt; &lt;a href="https://github.com/dylanhogg/awesome-python/raw/main/README.md"&gt; &lt;img src="https://awesome.re/badge.svg?sanitize=true" alt="Awesome Python" /&gt;&lt;/a&gt; &lt;a href="https://gurubase.io/g/pathway"&gt; &lt;img src="https://img.shields.io/badge/Gurubase-Ask%20Pathway%20Guru-006BFF" alt="Pathway Guru" /&gt;&lt;/a&gt; &lt;br /&gt; &lt;a href="https://raw.githubusercontent.com/pathwaycom/pathway/main/#getting-started"&gt;Getting Started&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/pathwaycom/pathway/main/#deployment"&gt;Deployment&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/pathwaycom/pathway/main/#resources"&gt;Documentation and Support&lt;/a&gt; | &lt;a href="https://pathway.com/blog/"&gt;Blog&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/pathwaycom/pathway/main/#license"&gt;License&lt;/a&gt; &lt;/p&gt; 
&lt;h1&gt;Pathway&lt;a id="pathway"&gt; Live Data Framework&lt;/a&gt;&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://pathway.com"&gt;Pathway&lt;/a&gt; is a Python ETL framework for stream processing, real-time analytics, LLM pipelines, and RAG.&lt;/p&gt; 
&lt;p&gt;Pathway comes with an &lt;strong&gt;easy-to-use Python API&lt;/strong&gt;, allowing you to seamlessly integrate your favorite Python ML libraries. Pathway code is versatile and robust: &lt;strong&gt;you can use it in both development and production environments, handling both batch and streaming data effectively&lt;/strong&gt;. The same code can be used for local development, CI/CD tests, running batch jobs, handling stream replays, and processing data streams.&lt;/p&gt; 
&lt;p&gt;Pathway is powered by a &lt;strong&gt;scalable Rust engine&lt;/strong&gt; based on Differential Dataflow and performs incremental computation. Your Pathway code, despite being written in Python, is run by the Rust engine, enabling multithreading, multiprocessing, and distributed computations. All the pipeline is kept in memory and can be easily deployed with &lt;strong&gt;Docker and Kubernetes&lt;/strong&gt;.&lt;/p&gt; 
&lt;p&gt;You can install Pathway with pip:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;pip install -U pathway
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For any questions, you will find the community and team behind the project &lt;a href="https://discord.com/invite/pathway"&gt;on Discord&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Use-cases and templates&lt;/h2&gt; 
&lt;p&gt;Ready to see what Pathway can do?&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://pathway.com/developers/templates"&gt;Try one of our easy-to-run examples&lt;/a&gt;!&lt;/p&gt; 
&lt;p&gt;Available in both notebook and docker formats, these ready-to-launch examples can be launched in just a few clicks. Pick one and start your hands-on experience with Pathway today!&lt;/p&gt; 
&lt;h3&gt;Event processing and real-time analytics pipelines&lt;/h3&gt; 
&lt;p&gt;With its unified engine for batch and streaming and its full Python compatibility, Pathway makes data processing as easy as possible. It's the ideal solution for a wide range of data processing pipelines, including:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://pathway.com/developers/templates/kafka-etl"&gt;Showcase: Real-time ETL.&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pathway.com/developers/templates/realtime-log-monitoring"&gt;Showcase: Event-driven pipelines with alerting.&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pathway.com/developers/templates/linear_regression_with_kafka/"&gt;Showcase: Realtime analytics.&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pathway.com/developers/user-guide/connecting-to-data/switch-from-batch-to-streaming"&gt;Docs: Switch from batch to streaming.&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;AI Pipelines&lt;/h3&gt; 
&lt;p&gt;Pathway provides dedicated LLM tooling to build live LLM and RAG pipelines. Wrappers for most common LLM services and utilities are included, making working with LLMs and RAGs pipelines incredibly easy. Check out our &lt;a href="https://pathway.com/developers/user-guide/llm-xpack/overview"&gt;LLM xpack documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Don't hesitate to try one of our runnable examples featuring LLM tooling. You can find such examples &lt;a href="https://pathway.com/developers/user-guide/llm-xpack/llm-examples"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://pathway.com/developers/templates/unstructured-to-structured/"&gt;Template: Unstructured data to SQL on-the-fly.&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pathway.com/developers/templates/private-rag-ollama-mistral"&gt;Template: Private RAG with Ollama and Mistral AI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pathway.com/developers/templates/adaptive-rag"&gt;Template: Adaptive RAG&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pathway.com/developers/templates/multimodal-rag"&gt;Template: Multimodal RAG with gpt-4o&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;A wide range of connectors&lt;/strong&gt;: Pathway comes with connectors that connect to external data sources such as Kafka, GDrive, PostgreSQL, or SharePoint. Its Airbyte connector allows you to connect to more than 300 different data sources. If the connector you want is not available, you can build your own custom connector using Pathway Python connector.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Stateless and stateful transformations&lt;/strong&gt;: Pathway supports stateful transformations such as joins, windowing, and sorting. It provides many transformations directly implemented in Rust. In addition to the provided transformation, you can use any Python function. You can implement your own or you can use any Python library to process your data.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Persistence&lt;/strong&gt;: Pathway provides persistence to save the state of the computation. This allows you to restart your pipeline after an update or a crash. Your pipelines are in good hands with Pathway!&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Consistency&lt;/strong&gt;: Pathway handles the time for you, making sure all your computations are consistent. In particular, Pathway manages late and out-of-order points by updating its results whenever new (or late, in this case) data points come into the system. The free version of Pathway gives the "at least once" consistency while the enterprise version provides the "exactly once" consistency.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Scalable Rust engine&lt;/strong&gt;: with Pathway Rust engine, you are free from the usual limits imposed by Python. You can easily do multithreading, multiprocessing, and distributed computations.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;LLM helpers&lt;/strong&gt;: Pathway provides an LLM extension with all the utilities to integrate LLMs with your data pipelines (LLM wrappers, parsers, embedders, splitters), including an in-memory real-time Vector Index, and integrations with LLamaIndex and LangChain. You can quickly build and deploy RAG applications with your live documents.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Getting started&lt;a id="getting-started"&gt;&lt;/a&gt;&lt;/h2&gt; 
&lt;h3&gt;Installation&lt;a id="installation"&gt;&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;Pathway requires Python 3.10 or above.&lt;/p&gt; 
&lt;p&gt;You can install the current release of Pathway using &lt;code&gt;pip&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ pip install -U pathway
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;âš ï¸ Pathway is available on MacOS and Linux. Users of other systems should run Pathway on a Virtual Machine.&lt;/p&gt; 
&lt;h3&gt;Example: computing the sum of positive values in real time.&lt;a id="example"&gt;&lt;/a&gt;&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import pathway as pw

# Define the schema of your data (Optional)
class InputSchema(pw.Schema):
  value: int

# Connect to your data using connectors
input_table = pw.io.csv.read(
  "./input/",
  schema=InputSchema
)

#Define your operations on the data
filtered_table = input_table.filter(input_table.value&amp;gt;=0)
result_table = filtered_table.reduce(
  sum_value = pw.reducers.sum(filtered_table.value)
)

# Load your results to external systems
pw.io.jsonlines.write(result_table, "output.jsonl")

# Run the computation
pw.run()
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Run Pathway &lt;a href="https://colab.research.google.com/drive/1aBIJ2HCng-YEUOMrr0qtj0NeZMEyRz55?usp=sharing"&gt;in Google Colab&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;You can find more examples &lt;a href="https://github.com/pathwaycom/pathway/tree/main/examples"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Deployment&lt;a id="deployment"&gt;&lt;/a&gt;&lt;/h2&gt; 
&lt;h3&gt;Locally&lt;a id="running-pathway-locally"&gt;&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;To use Pathway, you only need to import it:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import pathway as pw
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Now, you can easily create your processing pipeline, and let Pathway handle the updates. Once your pipeline is created, you can launch the computation on streaming data with a one-line command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;pw.run()
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can then run your Pathway project (say, &lt;code&gt;main.py&lt;/code&gt;) just like a normal Python script: &lt;code&gt;$ python main.py&lt;/code&gt;. Pathway comes with a monitoring dashboard that allows you to keep track of the number of messages sent by each connector and the latency of the system. The dashboard also includes log messages.&lt;/p&gt; 
&lt;img src="https://d14l3brkh44201.cloudfront.net/pathway-dashboard.png" width="1326" alt="Pathway dashboard" /&gt; 
&lt;p&gt;Alternatively, you can use the pathway'ish version:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ pathway spawn python main.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Pathway natively supports multithreading. To launch your application with 3 threads, you can do as follows:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ pathway spawn --threads 3 python main.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To jumpstart a Pathway project, you can use our &lt;a href="https://github.com/pathwaycom/cookiecutter-pathway"&gt;cookiecutter template&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Docker&lt;a id="docker"&gt;&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;You can easily run Pathway using docker.&lt;/p&gt; 
&lt;h4&gt;Pathway image&lt;/h4&gt; 
&lt;p&gt;You can use the &lt;a href="https://hub.docker.com/r/pathwaycom/pathway"&gt;Pathway docker image&lt;/a&gt;, using a Dockerfile:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-dockerfile"&gt;FROM pathwaycom/pathway:latest

WORKDIR /app

COPY requirements.txt ./
RUN pip install --no-cache-dir -r requirements.txt

COPY . .

CMD [ "python", "./your-script.py" ]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can then build and run the Docker image:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;docker build -t my-pathway-app .
docker run -it --rm --name my-pathway-app my-pathway-app
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Run a single Python script&lt;/h4&gt; 
&lt;p&gt;When dealing with single-file projects, creating a full-fledged &lt;code&gt;Dockerfile&lt;/code&gt; might seem unnecessary. In such scenarios, you can execute a Python script directly using the Pathway Docker image. For example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;docker run -it --rm --name my-pathway-app -v "$PWD":/app pathwaycom/pathway:latest python my-pathway-app.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Python docker image&lt;/h4&gt; 
&lt;p&gt;You can also use a standard Python image and install Pathway using pip with a Dockerfile:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-dockerfile"&gt;FROM --platform=linux/x86_64 python:3.10

RUN pip install -U pathway
COPY ./pathway-script.py pathway-script.py

CMD ["python", "-u", "pathway-script.py"]
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Kubernetes and cloud&lt;a id="k8s"&gt;&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;Docker containers are ideally suited for deployment on the cloud with Kubernetes. If you want to scale your Pathway application, you may be interested in our Pathway for Enterprise. Pathway for Enterprise is specially tailored towards end-to-end data processing and real time intelligent analytics. It scales using distributed computing on the cloud and supports distributed Kubernetes deployment, with external persistence setup.&lt;/p&gt; 
&lt;p&gt;You can easily deploy Pathway using services like Render: see &lt;a href="https://pathway.com/developers/user-guide/deployment/render-deploy/"&gt;how to deploy Pathway in a few clicks&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;If you are interested, don't hesitate to &lt;a href="mailto:contact@pathway.com"&gt;contact us&lt;/a&gt; to learn more.&lt;/p&gt; 
&lt;h2&gt;Performance&lt;a id="performance"&gt;&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Pathway is made to outperform state-of-the-art technologies designed for streaming and batch data processing tasks, including: Flink, Spark, and Kafka Streaming. It also makes it possible to implement a lot of algorithms/UDF's in streaming mode which are not readily supported by other streaming frameworks (especially: temporal joins, iterative graph algorithms, machine learning routines).&lt;/p&gt; 
&lt;p&gt;If you are curious, here are &lt;a href="https://github.com/pathwaycom/pathway-benchmarks"&gt;some benchmarks to play with&lt;/a&gt;.&lt;/p&gt; 
&lt;img src="https://github.com/pathwaycom/pathway-benchmarks/raw/main/images/bm-wordcount-lineplot.png" width="1326" alt="WordCount Graph" /&gt; 
&lt;h2&gt;Documentation and Support&lt;a id="resources"&gt;&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;The entire documentation of Pathway is available at &lt;a href="https://pathway.com/developers/user-guide/introduction/welcome"&gt;pathway.com/developers/&lt;/a&gt;, including the &lt;a href="https://pathway.com/developers/api-docs/pathway"&gt;API Docs&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;If you have any question, don't hesitate to &lt;a href="https://github.com/pathwaycom/pathway/issues"&gt;open an issue on GitHub&lt;/a&gt;, join us on &lt;a href="https://discord.com/invite/pathway"&gt;Discord&lt;/a&gt;, or send us an email at &lt;a href="mailto:contact@pathway.com"&gt;contact@pathway.com&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;License&lt;a id="license"&gt;&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Pathway is distributed on a &lt;a href="https://github.com/pathwaycom/pathway/raw/main/LICENSE.txt"&gt;BSL 1.1 License&lt;/a&gt; which allows for unlimited non-commercial use, as well as use of the Pathway package &lt;a href="https://pathway.com/license/"&gt;for most commercial purposes&lt;/a&gt;, free of charge. Code in this repository automatically converts to Open Source (Apache 2.0 License) after 4 years. Some &lt;a href="https://github.com/pathwaycom"&gt;public repos&lt;/a&gt; which are complementary to this one (examples, libraries, connectors, etc.) are licensed as Open Source, under the MIT license.&lt;/p&gt; 
&lt;h2&gt;Contribution guidelines&lt;a id="contribution-guidelines"&gt;&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;If you develop a library or connector which you would like to integrate with this repo, we suggest releasing it first as a separate repo on a MIT/Apache 2.0 license.&lt;/p&gt; 
&lt;p&gt;For all concerns regarding core Pathway functionalities, Issues are encouraged. For further information, don't hesitate to engage with Pathway's &lt;a href="https://discord.gg/pathway"&gt;Discord community&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>11cafe/jaaz</title>
      <link>https://github.com/11cafe/jaaz</link>
      <description>&lt;p&gt;The world's first open-source multimodal creative assistant This is a substitute for Canva and Manus that prioritizes privacy and is usable locally.&lt;/p&gt;&lt;hr&gt;&lt;h1 align="center"&gt; &lt;a href="https://jaaz.app" target="_blank"&gt; Jaaz.app&lt;/a&gt; &lt;p align="center"&gt;Open source Canva AI alternative&lt;/p&gt; &lt;p align="center"&gt; &lt;a href="https://jaaz.app"&gt; &lt;img src="https://github.com/user-attachments/assets/e0cffb94-8c6f-4867-800a-c144aceb6d54" alt="Jaaz Logo" /&gt; &lt;/a&gt; &lt;/p&gt; &lt;/h1&gt; 
&lt;p align="center"&gt;The world's first open-source multimodal canvas creative agent&lt;/p&gt; 
&lt;p align="center"&gt;This is a substitute for Canva and Manus that prioritizes privacy and is usable locally.&lt;/p&gt; 
&lt;p&gt; &lt;b&gt;ğŸ“£ [New!] Enterprise Cloud â€œFullâ€ Edition&lt;/b&gt; â€” Private/on-prem deployment &amp;amp; commercial licensing (Docker image or full source). Includes all jaaz.app online features. &lt;b&gt;30% OFF&lt;/b&gt; through &lt;b&gt;Sep 15, 2025&lt;/b&gt;. &lt;a href="mailto:weixuanfu01@gmail.com"&gt;Contact us â†’&lt;/a&gt; &lt;br /&gt; &lt;br /&gt; &lt;b&gt;ğŸ“£ [New!] ä¼ä¸šäº‘ç«¯å®Œæ•´ç‰ˆ&lt;/b&gt; â€” æ”¯æŒ&lt;span&gt;ç§æœ‰åŒ–éƒ¨ç½²&lt;/span&gt;ä¸&lt;span&gt;å•†ä¸šæˆæƒ&lt;/span&gt;ï¼ˆDocker é•œåƒæˆ–æºç äº¤ä»˜ï¼‰ï¼ŒåŒ…å« jaaz.app å…¨é‡çº¿ä¸ŠåŠŸèƒ½ã€‚é™æ—¶ &lt;b&gt;30% OFF&lt;/b&gt;ï¼Œæˆªæ­¢ &lt;b&gt;2025-09-15&lt;/b&gt;ã€‚ &lt;a href="mailto:weixuanfu01@gmail.com"&gt;äº†è§£/æ´½è°ˆ â†’&lt;/a&gt; &lt;/p&gt; 
&lt;br /&gt;
&lt;br /&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/11cafe/jaaz/raw/main/README_zh.md"&gt;ä¸­æ–‡ç‰ˆ&lt;/a&gt;| &lt;a href="https://mxnpt25l6k.feishu.cn/docx/LvcTdlVbFoRAZWxnhBYcqVydnpc"&gt;æ–°æ‰‹æŒ‡å—&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://discord.gg/https://discord.gg/SMRe5n3m"&gt; &lt;img src="https://img.shields.io/badge/Discord-5865F2?logo=discord&amp;amp;logoColor=white&amp;amp;style=for-the-badge" alt="Discord" /&gt; &lt;/a&gt; &lt;a href="https://github.com/11cafe/jaaz/stargazers"&gt; &lt;img src="https://img.shields.io/github/stars/11cafe/jaaz?style=for-the-badge&amp;amp;logo=github" alt="GitHub Stars" /&gt; &lt;/a&gt; 
 &lt;!-- Download for Mac --&gt; &lt;a href="https://jaaz.app/api/downloads/mac-latest"&gt; &lt;img src="https://img.shields.io/badge/For%20Mac-000000?logo=apple&amp;amp;logoColor=white&amp;amp;style=for-the-badge" alt="Download for Mac" /&gt; &lt;/a&gt; 
 &lt;!-- Download for Windows --&gt; &lt;a href="https://jaaz.app/api/downloads/windows-latest"&gt; &lt;img src="https://img.shields.io/badge/For%20Windows-0078D6?logo=laptop&amp;amp;logoColor=white&amp;amp;style=for-the-badge" alt="Download for Windows" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; Magic Canva! &lt;/p&gt;
&lt;p&gt;"Build" your ideas like playing with LEGOâ€”paint directly, point with arrows, and the AI instantly understands and generates results. &lt;img width="900" alt="Screenshot 2025-06-02 at 3 03 49 PM" src="https://github.com/user-attachments/assets/543b170c-14f7-4a73-96bd-909662138592" /&gt; &lt;img width="900" alt="Screenshot 2025-06-02 at 3 03 49 PM" src="https://github.com/user-attachments/assets/7dd9af32-cc60-4145-9b30-7db96d8fa09a" /&gt;&lt;/p&gt; 
&lt;p&gt;Magic video!&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/b7abf987-c65d-49b1-8178-82770873c583"&gt;https://github.com/user-attachments/assets/b7abf987-c65d-49b1-8178-82770873c583&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Create Viral Shorts with a Single Sentence 
 &lt;video src="https://github.com/user-attachments/assets/1c15e792-098a-4557-b310-d9c223f73442" controls width="100%"&gt;&lt;/video&gt;&lt;/p&gt; 
&lt;h2&gt;âœ¨ Getting started &amp;amp; staying tuned with us.&lt;/h2&gt; 
&lt;p&gt;Star us, and you will receive all release notifications from GitHub without any delay! &lt;img width="900" alt="Screenshot 2025-06-02 at 3 03 49 PM" src="https://github.com/user-attachments/assets/1c9a3661-80a4-4fba-a30f-f469898b0aec" /&gt;&lt;/p&gt; 
&lt;h2&gt;âœ¨ Key Features&lt;/h2&gt; 
&lt;p&gt;ğŸ¬ One-Prompt Image &amp;amp; Video Generation Turn one prompt into complete images or videos in seconds.&lt;/p&gt; 
&lt;p&gt;-Supports GPT-4o, Midjourney, VEO3, Kling,veo3,seedance etc.&lt;/p&gt; 
&lt;p&gt;-Auto-optimized prompts &amp;amp; multi-turn refinement&lt;/p&gt; 
&lt;p&gt;ğŸ§™ Magic Canvas&amp;amp;Magic Video Prompt-free creation â€” build like Lego.&lt;/p&gt; 
&lt;p&gt;-Simple sketching and free combination â€” AI instantly understands and generates.&lt;/p&gt; 
&lt;p&gt;-AI understands and generates instantly&lt;/p&gt; 
&lt;p&gt;-No prompt writing needed&lt;/p&gt; 
&lt;p&gt;-Describe steps simply on the video, and AI will generate following them.&lt;/p&gt; 
&lt;p&gt;ğŸ–¼ï¸ Infinite Canvas &amp;amp; Visual Storyboarding Plan scenes with an unlimited canvas&lt;/p&gt; 
&lt;p&gt;-Link layouts, manage media visually&lt;/p&gt; 
&lt;p&gt;-Real-time collaboration supported&lt;/p&gt; 
&lt;p&gt;ğŸ¤– Smart AI Agent System -Chat to insert objects, transfer styles, control logic&lt;/p&gt; 
&lt;p&gt;-Works with local (ComfyUI) &amp;amp; cloud models&lt;/p&gt; 
&lt;p&gt;-Maintains multi-character coherence&lt;/p&gt; 
&lt;p&gt;âš™ï¸ Flexible Deployment &amp;amp; Local Assets -Fully offline or hybrid setup (Ollama + APIs)&lt;/p&gt; 
&lt;p&gt;-Built-in library for media &amp;amp; prompts&lt;/p&gt; 
&lt;p&gt;-Cross-platform: Windows &amp;amp; macOS&lt;/p&gt; 
&lt;p&gt;ğŸ” Privacy &amp;amp; Security -Local-first, no data leaves your device&lt;/p&gt; 
&lt;p&gt;-Open-source, no tracking&lt;/p&gt; 
&lt;p&gt;-Safe for commercial use â€” you own your data&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;p&gt;Download here: &lt;a href="https://jaaz.app/"&gt;https://jaaz.app/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Click the "Log In" button at the top right of the homepage to access API models. With a low-cost plan, you can seamlessly use a variety of powerful APIs.&lt;/p&gt; 
&lt;img width="400" alt="Screenshot 2025-06-02 at 3 08 51 PM" src="https://github.com/user-attachments/assets/0055557d-c247-4801-ac3f-01ed4fa775ae" /&gt; 
&lt;p&gt;Start chatting with agent to generate stories or storyboards!&lt;/p&gt; 
&lt;h2&gt;Cases&lt;/h2&gt; 
&lt;img width="889" height="1103" alt="Frame 122" src="https://github.com/user-attachments/assets/90503110-0f5c-4297-bbfe-6d35e3f54d4c" /&gt; 
&lt;ul&gt; 
 &lt;li&gt;Prompt: Help me place this character in six different scenes, all in front of landmark buildings from around the world. The lighting is harmonious. He takes photos from all over the world, realistic, with warm light, high picture quality, and a picture ratio of 9:16&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/4e2634b3-9068-47cd-a18f-ddde8f218d25" alt="814c563b08f6ef44de0c2c31f0fdd00b-min" /&gt;&lt;/p&gt; 
&lt;img width="1000" alt="Screenshot 2025-06-02 at 3 51 56 AM" src="https://github.com/user-attachments/assets/5d8efe74-99b0-41bc-aa3e-6f7b92b69c36" /&gt; 
&lt;img width="900" alt="Screenshot 2025-06-02 at 3 51 56 AM" src="https://github.com/user-attachments/assets/186982a9-5e4e-4ac1-a42c-c840092fd616" /&gt; 
&lt;img width="900" alt="Screenshot 2025-06-02 at 3 03 49 PM" src="https://github.com/user-attachments/assets/b8508efd-def8-40ed-8ab5-62ed3c26de67" /&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/2065cabd-af32-43b6-bc01-59a935d9a287" alt="image26" /&gt;&lt;/p&gt; 
&lt;h2&gt;Team and Enterprise Support:&lt;/h2&gt; 
&lt;p&gt;Support for multi-user private deployment of enterprise teams, ensuring privacy and security.&lt;/p&gt; 
&lt;p&gt;Please contact via email: &lt;a href="mailto:aifoxdw@gmail.com"&gt;aifoxdw@gmail.com&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;WeChat: aifox1 &lt;img width="600" alt="Screenshot 2025-06-02 at 3 51 56 AM" src="https://github.com/user-attachments/assets/21bcffeb-07e8-40f1-aab8-b05aca7db097" /&gt;&lt;/p&gt; 
&lt;h2&gt;Manual Install (For Linux or local builds)&lt;/h2&gt; 
&lt;p&gt;ğŸŸ  &lt;strong&gt;Need Python version &amp;gt;=3.12&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;First git clone this repo:&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;git clone https://github.com/11cafe/localart&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;cd react&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;npm install --force&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;npx vite build&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;cd ../server&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;pip install -r requirements.txt&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;python main.py&lt;/code&gt;&lt;/p&gt; 
&lt;h2&gt;Development&lt;/h2&gt; 
&lt;p&gt;ğŸŸ  &lt;strong&gt;Need Python version &amp;gt;=3.12&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;VSCode/Cursor Install Extensionsï¼š&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Black Formatter by ms-python (ms-python.black-formatter)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;code&gt;cd react&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;npm install --force &amp;amp;&amp;amp; npm run dev&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;cd server&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;pip install -r requirements.txt&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;python main.py&lt;/code&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>pathwaycom/llm-app</title>
      <link>https://github.com/pathwaycom/llm-app</link>
      <description>&lt;p&gt;Ready-to-run cloud templates for RAG, AI pipelines, and enterprise search with live data. ğŸ³Docker-friendly.âš¡Always in sync with Sharepoint, Google Drive, S3, Kafka, PostgreSQL, real-time data APIs, and more.&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;h1&gt;Pathway AI Pipelines&lt;/h1&gt; 
 &lt;p&gt;&lt;a href="https://trendshift.io/repositories/4400" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/4400" alt="pathwaycom%2Fllm-app | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;img src="https://img.shields.io/badge/Linux-FCC624?style=for-the-badge&amp;amp;logo=linux&amp;amp;logoColor=black" alt="Linux" /&gt; &lt;img src="https://img.shields.io/badge/mac%20os-000000?style=for-the-badge&amp;amp;logo=apple&amp;amp;logoColor=white" alt="macOS" /&gt; &lt;a href="https://discord.gg/pathway"&gt;&lt;img src="https://img.shields.io/badge/Discord-5865F2?style=for-the-badge&amp;amp;logo=discord&amp;amp;logoColor=white" alt="chat on Discord" /&gt;&lt;/a&gt; &lt;a href="https://x.com/intent/follow?screen_name=pathway_com"&gt;&lt;img src="https://img.shields.io/badge/X-000000?style=for-the-badge&amp;amp;logo=x&amp;amp;logoColor=white" alt="follow on X" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;Pathway's &lt;strong&gt;AI Pipelines&lt;/strong&gt; allow you to quickly put in production AI applications that offer &lt;strong&gt;high-accuracy RAG and AI enterprise search at scale&lt;/strong&gt; using the most &lt;strong&gt;up-to-date knowledge&lt;/strong&gt; available in your data sources. It provides you ready-to-deploy &lt;strong&gt;LLM (Large Language Model) App Templates&lt;/strong&gt;. You can test them on your own machine and deploy on-cloud (GCP, AWS, Azure, Render,...) or on-premises.&lt;/p&gt; 
&lt;p&gt;The apps connect and sync (all new data additions, deletions, updates) with data sources on your &lt;strong&gt;file system, Google Drive, Sharepoint, S3, Kafka, PostgreSQL, real-time data APIs&lt;/strong&gt;. They come with no infrastructure dependencies that would need a separate setup. They include &lt;strong&gt;built-in data indexing&lt;/strong&gt; enabling vector search, hybrid search, and full-text search - all done in-memory, with cache.&lt;/p&gt; 
&lt;h2&gt;Application Templates&lt;/h2&gt; 
&lt;p&gt;The application templates provided in this repo scale up to &lt;strong&gt;millions of pages of documents&lt;/strong&gt;. Some of them are optimized for simplicity, some are optimized for amazing accuracy. Pick the one that suits you best. You can use it out of the box, or change some steps of the pipeline - for example, if you would like to add a new data source, or change a Vector Index into a Hybrid Index, it's just a one-line change.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Application (template)&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/pathwaycom/llm-app/main/examples/pipelines/demo-question-answering/"&gt;&lt;code&gt;Question-Answering RAG App&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Basic end-to-end RAG app. A question-answering pipeline that uses the GPT model of choice to provide answers to queries to your documents (PDF, DOCX,...) on a live connected data source (files, Google Drive, Sharepoint,...). You can also try out a &lt;a href="https://pathway.com/solutions/rag-pipelines#try-it-out"&gt;demo REST endpoint&lt;/a&gt;.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/pathwaycom/llm-app/main/examples/pipelines/demo-document-indexing/"&gt;&lt;code&gt;Live Document Indexing (Vector Store / Retriever)&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;A real-time document indexing pipeline for RAG that acts as a vector store service. It performs live indexing on your documents (PDF, DOCX,...) from a connected data source (files, Google Drive, Sharepoint,...). It can be used with any frontend, or integrated as a retriever backend for a &lt;a href="https://pathway.com/blog/langchain-integration"&gt;Langchain&lt;/a&gt; or &lt;a href="https://pathway.com/blog/llamaindex-pathway"&gt;Llamaindex&lt;/a&gt; application. You can also try out a &lt;a href="https://pathway.com/solutions/ai-contract-management#try-it-out"&gt;demo REST endpoint&lt;/a&gt;.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/pathwaycom/llm-app/main/examples/pipelines/gpt_4o_multimodal_rag/"&gt;&lt;code&gt;Multimodal RAG pipeline with GPT4o&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Multimodal RAG using GPT-4o in the parsing stage to index PDFs and other documents from a connected data source files, Google Drive, Sharepoint,...). It is perfect for extracting information from unstructured financial documents in your folders (including charts and tables), updating results as documents change or new ones arrive.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/pathwaycom/llm-app/main/examples/pipelines/unstructured_to_sql_on_the_fly/"&gt;&lt;code&gt;Unstructured-to-SQL pipeline + SQL question-answering&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;A RAG example which connects to unstructured financial data sources (financial report PDFs), structures the data into SQL, and loads it into a PostgreSQL table. It also answers natural language user queries to these financial documents by translating them into SQL using an LLM and executing the query on the PostgreSQL table.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/pathwaycom/llm-app/main/examples/pipelines/adaptive-rag/"&gt;&lt;code&gt;Adaptive RAG App&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;A RAG application using Adaptive RAG, a technique developed by Pathway to reduce token cost in RAG up to 4x while maintaining accuracy.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/pathwaycom/llm-app/main/examples/pipelines/private-rag/"&gt;&lt;code&gt;Private RAG App with Mistral and Ollama&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;A fully private (local) version of the &lt;code&gt;demo-question-answering&lt;/code&gt; RAG pipeline using Pathway, Mistral, and Ollama.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/pathwaycom/llm-app/main/examples/pipelines/slides_ai_search/"&gt;&lt;code&gt;Slides AI Search App&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;An indexing pipeline for retrieving slides. It performs multi-modal of PowerPoint and PDF and maintains live index of your slides."&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;How do these AI Pipelines work?&lt;/h2&gt; 
&lt;p&gt;The apps can be run as &lt;strong&gt;Docker containers&lt;/strong&gt;, and expose an &lt;strong&gt;HTTP API&lt;/strong&gt; to connect the frontend. To allow quick testing and demos, some app templates also include an optional Streamlit UI which connects to this API.&lt;/p&gt; 
&lt;p&gt;The apps rely on the &lt;a href="https://github.com/pathwaycom/pathway"&gt;Pathway Live Data framework&lt;/a&gt; for data source synchronization and for serving API requests (Pathway is a standalone Python library with a Rust engine built into it). They bring you a &lt;strong&gt;simple and unified application logic&lt;/strong&gt; for back-end, embedding, retrieval, LLM tech stack. There is no need to integrate and maintain separate modules for your Gen AI app: &lt;del&gt;Vector Database (e.g. Pinecone/Weaviate/Qdrant) + Cache (e.g. Redis) + API Framework (e.g. Fast API)&lt;/del&gt;. Pathway's default choice of &lt;strong&gt;built-in vector index&lt;/strong&gt; is based on the lightning-fast &lt;a href="https://github.com/unum-cloud/usearch"&gt;usearch&lt;/a&gt; library, and &lt;strong&gt;hybrid full-text indexes&lt;/strong&gt; make use of &lt;a href="https://github.com/quickwit-oss/tantivy"&gt;Tantivy&lt;/a&gt; library. Everything works out of the box.&lt;/p&gt; 
&lt;h2&gt;Getting started&lt;/h2&gt; 
&lt;p&gt;Each of the &lt;a href="https://raw.githubusercontent.com/pathwaycom/llm-app/main/examples/pipelines/"&gt;App templates&lt;/a&gt; in this repo contains a README.md with instructions on how to run it.&lt;/p&gt; 
&lt;p&gt;You can also find &lt;a href="https://pathway.com/developers/templates/"&gt;more ready-to-run code templates&lt;/a&gt; on the Pathway website.&lt;/p&gt; 
&lt;h2&gt;Some visual highlights&lt;/h2&gt; 
&lt;p&gt;Effortlessly extract and organize table and chart data from PDFs, docs, and more with multimodal RAG - in real-time:&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/pathwaycom/llm-app/raw/main/examples/pipelines/gpt_4o_multimodal_rag/gpt4o_with_pathway_comparison.gif" alt="Effortlessly extract and organize table and chart data from PDFs, docs, and more with multimodal RAG - in real-time" /&gt;&lt;/p&gt; 
&lt;p&gt;(Check out &lt;a href="https://raw.githubusercontent.com/pathwaycom/llm-app/main/examples/pipelines/gpt_4o_multimodal_rag/"&gt;&lt;code&gt;Multimodal RAG pipeline with GPT4o&lt;/code&gt;&lt;/a&gt; to see the whole pipeline in the works. You may also check out the &lt;a href="https://raw.githubusercontent.com/pathwaycom/llm-app/main/examples/pipelines/unstructured_to_sql_on_the_fly/"&gt;&lt;code&gt;Unstructured-to-SQL pipeline&lt;/code&gt;&lt;/a&gt; for a minimal example that works with non-multimodal models as well.)&lt;/p&gt; 
&lt;p&gt;Automated real-time knowledge mining and alerting:&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/pathwaycom/llm-app/main/examples/pipelines/drive_alert/drive_alert_demo.gif" alt="Automated real-time knowledge mining and alerting" /&gt;&lt;/p&gt; 
&lt;p&gt;(Check out the &lt;a href="https://github.com/pathwaycom/llm-app/tree/main/examples/pipelines/drive_alert"&gt;&lt;code&gt;Alerting when answers change on Google Drive&lt;/code&gt;&lt;/a&gt; app example.)&lt;/p&gt; 
&lt;h3&gt;Do-it-Yourself Videos&lt;/h3&gt; 
&lt;p&gt;â–¶ï¸ &lt;a href="https://www.youtube.com/watch?v=kcrJSk00duw"&gt;An introduction to building LLM apps with Pathway&lt;/a&gt; - by &lt;a href="https://scholar.google.com/citations?user=Yc94070AAAAJ"&gt;Jan Chorowski&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;â–¶ï¸ &lt;a href="https://www.youtube.com/watch?v=k1XGo7ts4tI"&gt;Let's build a real-world LLM app in 11 minutes&lt;/a&gt; - by &lt;a href="https://substack.com/@paulabartabajo"&gt;Pau Labarta Bajo&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Troubleshooting&lt;/h2&gt; 
&lt;p&gt;To provide feedback or report a bug, please &lt;a href="https://github.com/pathwaycom/pathway/issues"&gt;raise an issue on our issue tracker&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Anyone who wishes to contribute to this project, whether documentation, features, bug fixes, code cleanup, testing, or code reviews, is very much encouraged to do so. If this is your first contribution to a GitHub project, here is a &lt;a href="https://docs.github.com/en/get-started/quickstart/contributing-to-projects"&gt;Get Started Guide&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;If you'd like to make a contribution that needs some more work, just raise your hand on the &lt;a href="https://discord.com/invite/pathway"&gt;Pathway Discord server&lt;/a&gt; (#get-help) and let us know what you are planning!&lt;/p&gt; 
&lt;h2&gt;Supported and maintained by&lt;/h2&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/pathwaycom/"&gt;&lt;img src="https://pathway.com/logo-light.svg?sanitize=true" alt="Pathway" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://pathway.com/solutions/llm-app"&gt; &lt;img src="https://img.shields.io/badge/See%20Pathway's%20offering%20for%20AI%20applications-0000FF" alt="See Pathway's offering for AI applications" /&gt; &lt;/a&gt; &lt;/p&gt;</description>
    </item>
    
    <item>
      <title>juspay/hyperswitch</title>
      <link>https://github.com/juspay/hyperswitch</link>
      <description>&lt;p&gt;An open source payments switch written in Rust to make payments fast, reliable and affordable&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/juspay/hyperswitch/main/docs/imgs/hyperswitch-logo-dark.svg#gh-dark-mode-only" alt="Hyperswitch-Logo" width="40%" /&gt; &lt;img src="https://raw.githubusercontent.com/juspay/hyperswitch/main/docs/imgs/hyperswitch-logo-light.svg#gh-light-mode-only" alt="Hyperswitch-Logo" width="40%" /&gt; &lt;/p&gt; 
&lt;h1 align="center"&gt;Composable Open-Source Payments Infrastructure&lt;/h1&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/juspay/hyperswitch/main/docs/gifs/quickstart.gif" alt="Quickstart demo" /&gt; &lt;/p&gt; 
&lt;!-- @import "[TOC]" {cmd="toc" depthFrom=1 depthTo=6 orderedList=false} --&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/juspay/hyperswitch/actions?query=workflow%3ACI+branch%3Amain"&gt; &lt;img src="https://github.com/juspay/hyperswitch/workflows/CI-push/badge.svg?sanitize=true" /&gt; &lt;/a&gt; &lt;a href="https://github.com/juspay/hyperswitch/raw/main/LICENSE"&gt; &lt;img src="https://img.shields.io/github/license/juspay/hyperswitch" /&gt; &lt;/a&gt; &lt;a href="https://github.com/juspay/hyperswitch/raw/main/LICENSE"&gt; &lt;img src="https://img.shields.io/badge/Made_in-Rust-orange" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://www.linkedin.com/company/hyperswitch/"&gt; &lt;img src="https://img.shields.io/badge/follow-hyperswitch-blue?logo=linkedin&amp;amp;labelColor=grey" /&gt; &lt;/a&gt; &lt;a href="https://x.com/hyperswitchio"&gt; &lt;img src="https://img.shields.io/badge/follow-%40hyperswitchio-white?logo=x&amp;amp;labelColor=grey" /&gt; &lt;/a&gt; &lt;a href="https://inviter.co/hyperswitch-slack"&gt; &lt;img src="https://img.shields.io/badge/chat-on_slack-blue?logo=slack&amp;amp;labelColor=grey&amp;amp;color=%233f0e40" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;hr /&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;ğŸ“ Table of Contents&lt;/strong&gt;&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/juspay/hyperswitch/main/#-what-can-i-do-with-hyperswitch"&gt;What Can I Do with Hyperswitch?&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/juspay/hyperswitch/main/#-quickstart-local-setup"&gt;Quickstart (Local Setup)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/juspay/hyperswitch/main/#cloud-deployment"&gt;Cloud Deployment&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/juspay/hyperswitch/main/#hosted-sandbox-no-setup-required"&gt;Hosted Sandbox (No Setup Required)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/juspay/hyperswitch/main/#-why-hyperswitch"&gt;Why Hyperswitch?&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/juspay/hyperswitch/main/#architectural-overview"&gt;Architectural Overview&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/juspay/hyperswitch/main/#our-vision"&gt;Our Vision&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/juspay/hyperswitch/main/#community--contributions"&gt;Community &amp;amp; Contributions&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/juspay/hyperswitch/main/#feature-requests--bugs"&gt;Feature Requests &amp;amp; Bugs&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/juspay/hyperswitch/main/#versioning"&gt;Versioning&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/juspay/hyperswitch/main/#copyright-and-license"&gt;License&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/juspay/hyperswitch/main/#team-behind-hyperswitch"&gt;Team Behind Hyperswitch&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;summary&gt;&lt;h2&gt; What Can I Do with Hyperswitch?&lt;/h2&gt;&lt;/summary&gt; 
&lt;p&gt;Hyperswitch offers a modular, open-source payments infrastructure designed for flexibility and control. Apart from our Payment Suite offering, this solution allows businesses to pick and integrate only the modules they need on top of their existing payment stack â€” without unnecessary complexity or vendor lock-in.&lt;/p&gt; 
&lt;p&gt;Each module is independent and purpose-built to optimize different aspects of payment processing.&lt;/p&gt; 
&lt;h3&gt; Learn More About The Payment Modules &lt;/h3&gt; 
&lt;details&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Cost Observability&lt;/strong&gt;&lt;br /&gt; Advanced observability tools to audit, monitor, and optimize your payment costs. Detect hidden fees, downgrades, and penalties with self-serve dashboards and actionable insights.&lt;br /&gt; &lt;em&gt;&lt;a href="https://docs.hyperswitch.io/about-hyperswitch/payments-modules/ai-powered-cost-observability"&gt;Read more&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Revenue Recovery&lt;/strong&gt;&lt;br /&gt; Combat passive churn with intelligent retry strategies tuned by card bin, region, method, and more. Offers fine-grained control over retry algorithms, penalty budgets, and recovery transparency.&lt;br /&gt; &lt;em&gt;&lt;a href="https://docs.hyperswitch.io/about-hyperswitch/payments-modules/revenue-recovery"&gt;Read more&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Vault&lt;/strong&gt;&lt;br /&gt; A PCI-compliant vault service to store cards, tokens, wallets, and bank credentials. Provides a unified, secure, and reusable store of customer-linked payment methods.&lt;br /&gt; &lt;em&gt;&lt;a href="https://docs.hyperswitch.io/about-hyperswitch/payments-modules/vault"&gt;Read more&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Intelligent Routing&lt;/strong&gt;&lt;br /&gt; Route each transaction to the PSP with the highest predicted auth rate. Reduce retries, avoid downtime, and minimize latency while maximizing first attempt success.&lt;br /&gt; &lt;em&gt;&lt;a href="https://docs.hyperswitch.io/about-hyperswitch/payments-modules/intelligent-routing"&gt;Read more&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Reconciliation&lt;/strong&gt;&lt;br /&gt; Automate 2-way and 3-way reconciliation with backdated support, staggered scheduling, and customizable outputs. Reduces manual ops effort and increases audit confidence.&lt;br /&gt; &lt;em&gt;&lt;a href="https://docs.hyperswitch.io/about-hyperswitch/payments-modules/reconciliation"&gt;Read more&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Alternate Payment Methods&lt;/strong&gt;&lt;br /&gt; Drop-in widgets for PayPal, Apple Pay, Google Pay, Samsung Pay, Pay by Bank, and BNPL providers like Klarna. Maximizes conversions with seamless one-click checkout.&lt;br /&gt; &lt;em&gt;&lt;a href="https://docs.hyperswitch.io/about-hyperswitch/payments-modules/enable-alternate-payment-method-widgets"&gt;Read more&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;Quickstart&lt;/h2&gt; 
&lt;h3&gt; Local Setup via Docker &lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# One-click local setup

git clone --depth 1 --branch latest https://github.com/juspay/hyperswitch

cd hyperswitch

scripts/setup.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;This script: &lt;/strong&gt;&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Detects Docker/Podman&lt;/li&gt; 
  &lt;li&gt;Offers multiple deployment profiles: 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Standard&lt;/strong&gt;: App server + Control Center&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;Full&lt;/strong&gt;: Includes monitoring + schedulers&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;Minimal&lt;/strong&gt;: Standalone App server&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;Provides access links when done&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;If you need further help, check out our &lt;a href="https://docs.hyperswitch.io/hyperswitch-open-source/overview/unified-local-setup-using-docker"&gt;video tutorial&lt;/a&gt;.&lt;/p&gt; 
 &lt;p&gt;ğŸ‘‰ After setup, &lt;a href="https://docs.hyperswitch.io/hyperswitch-open-source/account-setup/using-hyperswitch-control-center#add-a-payment-processor"&gt;configure a connector&lt;/a&gt; and &lt;a href="https://docs.hyperswitch.io/hyperswitch-open-source/account-setup/test-a-payment"&gt;test a payment&lt;/a&gt;.&lt;/p&gt; 
&lt;/details&gt; 
&lt;h3&gt;Hosted Sandbox (No Setup Required)&lt;/h3&gt; 
&lt;p&gt;Hyperswitch offers a fully hosted sandbox environment that requires no setup. You can explore the Control Center, configure payment connectors, and test payments directly from the UI.&lt;/p&gt; 
&lt;a href="https://app.hyperswitch.io"&gt; &lt;img src="https://github.com/juspay/hyperswitch/raw/main/docs/imgs/try-the-sandbox.png?raw=true" height="35" /&gt; &lt;/a&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt; What you can do in the Hosted Sandbox&lt;/strong&gt;&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Access the full Control Center&lt;/li&gt; 
  &lt;li&gt;Configure payment connectors&lt;/li&gt; 
  &lt;li&gt;View logs, routing rules, and retry strategies&lt;/li&gt; 
  &lt;li&gt;Try payments directly from the UI&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h3&gt;&lt;strong&gt;Cloud Deployment&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;You can deploy to AWS, GCP, or Azure using Helm or CDK scripts. Fastest path:&lt;/p&gt; 
&lt;p&gt;Click to deploy via AWS:&lt;/p&gt; 
&lt;a href="https://console.aws.amazon.com/cloudformation/home?region=us-east-1#/stacks/new?stackName=HyperswitchBootstarp&amp;amp;templateURL=https://hyperswitch-synth.s3.eu-central-1.amazonaws.com/hs-starter-config.yaml"&gt; &lt;img src="https://github.com/juspay/hyperswitch/raw/main/docs/imgs/aws_button.png?raw=true" height="35" /&gt; &lt;/a&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;Cloud Deployment Instructions&lt;/strong&gt;&lt;/summary&gt; 
 &lt;ol&gt; 
  &lt;li&gt;Click the AWS deployment button above to launch the stack.&lt;/li&gt; 
  &lt;li&gt;Follow the guided steps in the AWS Console (approx. 30â€“45 mins).&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;p&gt;âœ… This setup provisions Hyperswitch on your cloud account using CloudFormation.&lt;/p&gt; 
 &lt;p&gt;ğŸ“˜ For full instructions and Helm-based deployments, check out the&lt;br /&gt; &lt;a href="https://docs.hyperswitch.io/hyperswitch-open-source/deploy-on-kubernetes-using-helm"&gt;Cloud Install Guide&lt;/a&gt;.&lt;/p&gt; 
&lt;/details&gt; 
&lt;a href="https://raw.githubusercontent.com/juspay/hyperswitch/main/#architectural-overview"&gt; &lt;h2 id="architectural-overview"&gt;Architectural Overview&lt;/h2&gt; &lt;/a&gt; 
&lt;img src="https://raw.githubusercontent.com/juspay/hyperswitch/main/docs/imgs/features.png" /&gt; 
&lt;img src="https://raw.githubusercontent.com/juspay/hyperswitch/main/docs/imgs/non-functional-features.png" /&gt; 
&lt;img src="https://raw.githubusercontent.com/juspay/hyperswitch/main/docs/imgs/hyperswitch-architecture-v1.png" /&gt; 
&lt;h2&gt;Why Hyperswitch?&lt;/h2&gt; 
&lt;p&gt;Hyperswitch is a commercial open-source payments stack purpose-built for scale, flexibility, and developer experience. Designed with a modular architecture, Hyperswitch lets you pick only the components you needâ€”whether itâ€™s routing, retries, vaulting, or observabilityâ€”without vendor lock-in or bloated integrations.&lt;/p&gt; 
&lt;p&gt;Built in Rust for performance and reliability, Hyperswitch supports global payment methods (cards, wallets, BNPL, UPI, Pay by Bank), exposes smart routing and retry logic, and provides a visual workflow builder in the Control Center. Whether you're integrating a full payment suite or augmenting an existing stack with a single module, Hyperswitch meets you where you are.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;â€œLinux for Paymentsâ€&lt;/strong&gt; â€” Hyperswitch is a well-architected reference for teams who want to own their payments stack.&lt;/p&gt; 
&lt;p&gt;We believe in:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt; Embracing Payment Diversity:&lt;/strong&gt; Innovation comes from enabling choiceâ€”across payment methods, processors, and flows.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt; Open Source by Default:&lt;/strong&gt; Transparency drives trust and builds better, reusable software.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt; Community-Driven Development:&lt;/strong&gt; Our roadmap is shaped by real-world use cases and contributors.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt; Systems-Level Engineering:&lt;/strong&gt; We hold ourselves to a high bar for reliability, security, and performance.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt; Maximizing Value Creation:&lt;/strong&gt; For developers, customers, and partners alike.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt; Community-Driven, Enterprise-Tested:&lt;/strong&gt; Hyperswitch is built in the open with real-world feedback from developers and contributors, and maintained by Juspay, the team powering payment infrastructure for 400+ leading enterprises worldwide.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome contributors from around the world to help build Hyperswitch. Whether you're fixing bugs, improving documentation, or adding new features, your help is appreciated.&lt;/p&gt; 
&lt;p&gt;Please read our &lt;a href="https://github.com/juspay/hyperswitch/raw/main/docs/CONTRIBUTING.md"&gt;contributing guidelines&lt;/a&gt; to get started.&lt;/p&gt; 
&lt;p&gt;Join the conversation on &lt;a href="https://inviter.co/hyperswitch-slack"&gt;Slack&lt;/a&gt; or explore open issues on &lt;a href="https://github.com/juspay/hyperswitch/issues"&gt;GitHub&lt;/a&gt;.&lt;/p&gt; 
&lt;a href="https://raw.githubusercontent.com/juspay/hyperswitch/main/#feature-requests"&gt; &lt;h2 id="feature-requests"&gt;Feature requests &amp;amp; Bugs&lt;/h2&gt; &lt;/a&gt; 
&lt;p&gt;For new product features, enhancements, roadmap discussions, or to share queries and ideas, visit our &lt;a href="https://github.com/juspay/hyperswitch/discussions"&gt;GitHub Discussions&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;For reporting a bug, please read the issue guidelines and search for &lt;a href="https://github.com/juspay/hyperswitch/issues"&gt;existing and closed issues&lt;/a&gt;. If your problem or idea is not addressed yet, please &lt;a href="https://github.com/juspay/hyperswitch/issues/new/choose"&gt;open a new issue&lt;/a&gt;.&lt;/p&gt; 
&lt;a href="https://raw.githubusercontent.com/juspay/hyperswitch/main/#versioning"&gt; &lt;h2 id="versioning"&gt;Versioning&lt;/h2&gt; &lt;/a&gt; 
&lt;p&gt;Check the &lt;a href="https://raw.githubusercontent.com/juspay/hyperswitch/main/CHANGELOG.md"&gt;CHANGELOG.md&lt;/a&gt; file for details.&lt;/p&gt; 
&lt;a href="https://raw.githubusercontent.com/juspay/hyperswitch/main/#copyright-and-license"&gt; &lt;h2 id="copyright-and-license"&gt;Copyright and License&lt;/h2&gt; &lt;/a&gt; 
&lt;p&gt;This product is licensed under the &lt;a href="https://raw.githubusercontent.com/juspay/hyperswitch/main/LICENSE"&gt;Apache 2.0 License&lt;/a&gt;.&lt;/p&gt; 
&lt;a href="https://raw.githubusercontent.com/juspay/hyperswitch/main/#team-behind-hyperswitch"&gt; &lt;h2 id="team-behind-hyperswitch"&gt;Team behind Hyperswitch&lt;/h2&gt; &lt;/a&gt; 
&lt;p&gt;The core team of 150+ engineers building Hyperswitch. Keep up the great work! ğŸ¥‚&lt;/p&gt; 
&lt;a href="https://github.com/juspay/hyperswitch/graphs/contributors"&gt; &lt;img src="https://contributors-img.web.app/image?repo=juspay/hyperswitch" alt="Contributors" /&gt; &lt;/a&gt;</description>
    </item>
    
    <item>
      <title>Stirling-Tools/Stirling-PDF</title>
      <link>https://github.com/Stirling-Tools/Stirling-PDF</link>
      <description>&lt;p&gt;#1 Locally hosted web application that allows you to perform various operations on PDF files&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt;&lt;img src="https://raw.githubusercontent.com/Stirling-Tools/Stirling-PDF/main/docs/stirling.png" width="80" /&gt;&lt;/p&gt; 
&lt;h1 align="center"&gt;Stirling-PDF&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://hub.docker.com/r/frooodle/s-pdf"&gt;&lt;img src="https://img.shields.io/docker/pulls/frooodle/s-pdf" alt="Docker Pulls" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/HYmhKj45pU"&gt;&lt;img src="https://img.shields.io/discord/1068636748814483718?label=Discord" alt="Discord" /&gt;&lt;/a&gt; &lt;a href="https://scorecard.dev/viewer/?uri=github.com/Stirling-Tools/Stirling-PDF"&gt;&lt;img src="https://api.scorecard.dev/projects/github.com/Stirling-Tools/Stirling-PDF/badge" alt="OpenSSF Scorecard" /&gt;&lt;/a&gt; &lt;a href="https://github.com/Stirling-Tools/stirling-pdf"&gt;&lt;img src="https://img.shields.io/github/stars/stirling-tools/stirling-pdf?style=social" alt="GitHub Repo stars" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.producthunt.com/posts/stirling-pdf?embed=true&amp;amp;utm_source=badge-featured&amp;amp;utm_medium=badge&amp;amp;utm_souce=badge-stirling-pdf" target="_blank"&gt;&lt;img src="https://api.producthunt.com/widgets/embed-image/v1/featured.svg?post_id=641239&amp;amp;theme=light" alt="Stirling PDF - Open source locally hosted web PDF editor | Product Hunt" style="width: 250px; height: 54px;" width="250" height="54" /&gt;&lt;/a&gt; &lt;a href="https://cloud.digitalocean.com/apps/new?repo=https://github.com/Stirling-Tools/Stirling-PDF/tree/digitalOcean&amp;amp;refcode=c3210994b1af"&gt;&lt;img src="https://www.deploytodo.com/do-btn-blue.svg?sanitize=true" alt="Deploy to DO" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.stirlingpdf.com"&gt;Stirling-PDF&lt;/a&gt; is a robust, locally hosted web-based PDF manipulation tool using Docker. It enables you to carry out various operations on PDF files, including splitting, merging, converting, reorganizing, adding images, rotating, compressing, and more. This locally hosted web application has evolved to encompass a comprehensive set of features, addressing all your PDF requirements.&lt;/p&gt; 
&lt;p&gt;All files and PDFs exist either exclusively on the client side, reside in server memory only during task execution, or temporarily reside in a file solely for the execution of the task. Any file downloaded by the user will have been deleted from the server by that point.&lt;/p&gt; 
&lt;p&gt;Homepage: &lt;a href="https://stirlingpdf.com"&gt;https://stirlingpdf.com&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;All documentation available at &lt;a href="https://docs.stirlingpdf.com/"&gt;https://docs.stirlingpdf.com/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Stirling-Tools/Stirling-PDF/main/images/stirling-home.jpg" alt="stirling-home" /&gt;&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;50+ PDF Operations&lt;/li&gt; 
 &lt;li&gt;Parallel file processing and downloads&lt;/li&gt; 
 &lt;li&gt;Dark mode support&lt;/li&gt; 
 &lt;li&gt;Custom download options&lt;/li&gt; 
 &lt;li&gt;Custom 'Pipelines' to run multiple features in a automated queue&lt;/li&gt; 
 &lt;li&gt;API for integration with external scripts&lt;/li&gt; 
 &lt;li&gt;Optional Login and Authentication support (see &lt;a href="https://docs.stirlingpdf.com/Advanced%20Configuration/System%20and%20Security"&gt;here&lt;/a&gt; for documentation)&lt;/li&gt; 
 &lt;li&gt;Database Backup and Import (see &lt;a href="https://docs.stirlingpdf.com/Advanced%20Configuration/DATABASE"&gt;here&lt;/a&gt; for documentation)&lt;/li&gt; 
 &lt;li&gt;Enterprise features like SSO (see &lt;a href="https://docs.stirlingpdf.com/Advanced%20Configuration/Single%20Sign-On%20Configuration"&gt;here&lt;/a&gt; for documentation)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;PDF Features&lt;/h2&gt; 
&lt;h3&gt;Page Operations&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;View and modify PDFs - View multi-page PDFs with custom viewing, sorting, and searching. Plus, on-page edit features like annotating, drawing, and adding text and images. (Using PDF.js with Joxit and Liberation fonts)&lt;/li&gt; 
 &lt;li&gt;Full interactive GUI for merging/splitting/rotating/moving PDFs and their pages&lt;/li&gt; 
 &lt;li&gt;Merge multiple PDFs into a single resultant file&lt;/li&gt; 
 &lt;li&gt;Split PDFs into multiple files at specified page numbers or extract all pages as individual files&lt;/li&gt; 
 &lt;li&gt;Reorganize PDF pages into different orders&lt;/li&gt; 
 &lt;li&gt;Rotate PDFs in 90-degree increments&lt;/li&gt; 
 &lt;li&gt;Remove pages&lt;/li&gt; 
 &lt;li&gt;Multi-page layout (format PDFs into a multi-paged page)&lt;/li&gt; 
 &lt;li&gt;Scale page contents size by set percentage&lt;/li&gt; 
 &lt;li&gt;Adjust contrast&lt;/li&gt; 
 &lt;li&gt;Crop PDF&lt;/li&gt; 
 &lt;li&gt;Auto-split PDF (with physically scanned page dividers)&lt;/li&gt; 
 &lt;li&gt;Extract page(s)&lt;/li&gt; 
 &lt;li&gt;Convert PDF to a single page&lt;/li&gt; 
 &lt;li&gt;Overlay PDFs on top of each other&lt;/li&gt; 
 &lt;li&gt;PDF to a single page&lt;/li&gt; 
 &lt;li&gt;Split PDF by sections&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Conversion Operations&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Convert PDFs to and from images&lt;/li&gt; 
 &lt;li&gt;Convert any common file to PDF (using LibreOffice)&lt;/li&gt; 
 &lt;li&gt;Convert PDF to Word/PowerPoint/others (using LibreOffice)&lt;/li&gt; 
 &lt;li&gt;Convert HTML to PDF&lt;/li&gt; 
 &lt;li&gt;Convert PDF to XML&lt;/li&gt; 
 &lt;li&gt;Convert PDF to CSV&lt;/li&gt; 
 &lt;li&gt;URL to PDF&lt;/li&gt; 
 &lt;li&gt;Markdown to PDF&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Security &amp;amp; Permissions&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Add and remove passwords&lt;/li&gt; 
 &lt;li&gt;Change/set PDF permissions&lt;/li&gt; 
 &lt;li&gt;Add watermark(s)&lt;/li&gt; 
 &lt;li&gt;Certify/sign PDFs&lt;/li&gt; 
 &lt;li&gt;Sanitize PDFs&lt;/li&gt; 
 &lt;li&gt;Auto-redact text&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Other Operations&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Add/generate/write signatures&lt;/li&gt; 
 &lt;li&gt;Split by Size or PDF&lt;/li&gt; 
 &lt;li&gt;Repair PDFs&lt;/li&gt; 
 &lt;li&gt;Detect and remove blank pages&lt;/li&gt; 
 &lt;li&gt;Compare two PDFs and show differences in text&lt;/li&gt; 
 &lt;li&gt;Add images to PDFs&lt;/li&gt; 
 &lt;li&gt;Compress PDFs to decrease their filesize (using qpdf)&lt;/li&gt; 
 &lt;li&gt;Extract images from PDF&lt;/li&gt; 
 &lt;li&gt;Remove images from PDF&lt;/li&gt; 
 &lt;li&gt;Extract images from scans&lt;/li&gt; 
 &lt;li&gt;Remove annotations&lt;/li&gt; 
 &lt;li&gt;Add page numbers&lt;/li&gt; 
 &lt;li&gt;Auto-rename files by detecting PDF header text&lt;/li&gt; 
 &lt;li&gt;OCR on PDF (using Tesseract OCR)&lt;/li&gt; 
 &lt;li&gt;PDF/A conversion (using LibreOffice)&lt;/li&gt; 
 &lt;li&gt;Edit metadata&lt;/li&gt; 
 &lt;li&gt;Flatten PDFs&lt;/li&gt; 
 &lt;li&gt;Get all information on a PDF to view or export as JSON&lt;/li&gt; 
 &lt;li&gt;Show/detect embedded JavaScript&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;ğŸ“– Get Started&lt;/h1&gt; 
&lt;p&gt;Visit our comprehensive documentation at &lt;a href="https://docs.stirlingpdf.com"&gt;docs.stirlingpdf.com&lt;/a&gt; for:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Installation guides for all platforms&lt;/li&gt; 
 &lt;li&gt;Configuration options&lt;/li&gt; 
 &lt;li&gt;Feature documentation&lt;/li&gt; 
 &lt;li&gt;API reference&lt;/li&gt; 
 &lt;li&gt;Security setup&lt;/li&gt; 
 &lt;li&gt;Enterprise features&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Supported Languages&lt;/h2&gt; 
&lt;p&gt;Stirling-PDF currently supports 40 languages!&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Language&lt;/th&gt; 
   &lt;th&gt;Progress&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Arabic (Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©) (ar_AR)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/61" alt="61%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Azerbaijani (AzÉ™rbaycan Dili) (az_AZ)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/62" alt="62%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Basque (Euskara) (eu_ES)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/36" alt="36%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Bulgarian (Ğ‘ÑŠĞ»Ğ³Ğ°Ñ€ÑĞºĞ¸) (bg_BG)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/68" alt="68%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Catalan (CatalÃ ) (ca_CA)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/67" alt="67%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Croatian (Hrvatski) (hr_HR)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/60" alt="60%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Czech (ÄŒesky) (cs_CZ)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/69" alt="69%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Danish (Dansk) (da_DK)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/61" alt="61%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Dutch (Nederlands) (nl_NL)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/60" alt="60%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;English (English) (en_GB)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/100" alt="100%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;English (US) (en_US)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/100" alt="100%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;French (FranÃ§ais) (fr_FR)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/88" alt="88%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;German (Deutsch) (de_DE)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/97" alt="97%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Greek (Î•Î»Î»Î·Î½Î¹ÎºÎ¬) (el_GR)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/67" alt="67%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Hindi (à¤¹à¤¿à¤‚à¤¦à¥€) (hi_IN)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/67" alt="67%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Hungarian (Magyar) (hu_HU)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/99" alt="99%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Indonesian (Bahasa Indonesia) (id_ID)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/62" alt="62%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Irish (Gaeilge) (ga_IE)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/68" alt="68%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Italian (Italiano) (it_IT)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/98" alt="98%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Japanese (æ—¥æœ¬èª) (ja_JP)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/92" alt="92%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Korean (í•œêµ­ì–´) (ko_KR)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/67" alt="67%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Norwegian (Norsk) (no_NB)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/66" alt="66%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Persian (ÙØ§Ø±Ø³ÛŒ) (fa_IR)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/64" alt="64%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Polish (Polski) (pl_PL)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/72" alt="72%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Portuguese (PortuguÃªs) (pt_PT)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/68" alt="68%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Portuguese Brazilian (PortuguÃªs) (pt_BR)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/76" alt="76%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Romanian (RomÃ¢nÄƒ) (ro_RO)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/57" alt="57%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Russian (Ğ ÑƒÑÑĞºĞ¸Ğ¹) (ru_RU)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/88" alt="88%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Serbian Latin alphabet (Srpski) (sr_LATN_RS)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/94" alt="94%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Simplified Chinese (ç®€ä½“ä¸­æ–‡) (zh_CN)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/93" alt="93%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Slovakian (Slovensky) (sk_SK)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/51" alt="51%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Slovenian (SlovenÅ¡Äina) (sl_SI)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/71" alt="71%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Spanish (EspaÃ±ol) (es_ES)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/74" alt="74%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Swedish (Svenska) (sv_SE)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/65" alt="65%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Thai (à¹„à¸—à¸¢) (th_TH)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/59" alt="59%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Tibetan (à½–à½¼à½‘à¼‹à½¡à½²à½‚à¼‹) (bo_CN)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/65" alt="65%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Traditional Chinese (ç¹é«”ä¸­æ–‡) (zh_TW)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/99" alt="99%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Turkish (TÃ¼rkÃ§e) (tr_TR)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/99" alt="99%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Ukrainian (Ğ£ĞºÑ€Ğ°Ñ—Ğ½ÑÑŒĞºĞ°) (uk_UA)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/70" alt="70%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Vietnamese (Tiáº¿ng Viá»‡t) (vi_VN)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/57" alt="57%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Malayalam (à´®à´²à´¯à´¾à´³à´‚) (ml_IN)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/73" alt="73%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Stirling PDF Enterprise&lt;/h2&gt; 
&lt;p&gt;Stirling PDF offers an Enterprise edition of its software. This is the same great software but with added features, support and comforts. Check out our &lt;a href="https://docs.stirlingpdf.com/Pro"&gt;Enterprise docs&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;ğŸ¤ Looking to contribute?&lt;/h2&gt; 
&lt;p&gt;Join our community:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Stirling-Tools/Stirling-PDF/main/CONTRIBUTING.md"&gt;Contribution Guidelines&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Stirling-Tools/Stirling-PDF/main/devGuide/HowToAddNewLanguage.md"&gt;Translation Guide (How to add custom languages)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Stirling-Tools/Stirling-PDF/main/devGuide/DeveloperGuide.md"&gt;Developer Guide&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Stirling-Tools/Stirling-PDF/issues"&gt;Issue Tracker&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://discord.gg/HYmhKj45pU"&gt;Discord Community&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>HKUDS/AutoAgent</title>
      <link>https://github.com/HKUDS/AutoAgent</link>
      <description>&lt;p&gt;"AutoAgent: Fully-Automated and Zero-Code LLM Agent Framework"&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a name="readme-top"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/HKUDS/AutoAgent/main/assets/AutoAgent_logo.svg?sanitize=true" alt="Logo" width="200" /&gt; 
 &lt;h1 align="center"&gt;AutoAgent: Fully-Automated &amp;amp; Zero-Code&lt;br /&gt; LLM Agent Framework &lt;/h1&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://autoagent-ai.github.io"&gt;&lt;img src="https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&amp;amp;color=FFE165&amp;amp;logo=homepage&amp;amp;logoColor=white" alt="Credits" /&gt;&lt;/a&gt; 
 &lt;a href="https://join.slack.com/t/metachain-workspace/shared_invite/zt-2zibtmutw-v7xOJObBf9jE2w3x7nctFQ"&gt;&lt;img src="https://img.shields.io/badge/Slack-Join%20Us-red?logo=slack&amp;amp;logoColor=white&amp;amp;style=for-the-badge" alt="Join our Slack community" /&gt;&lt;/a&gt; 
 &lt;a href="https://discord.gg/jQJdXyDB"&gt;&lt;img src="https://img.shields.io/badge/Discord-Join%20Us-purple?logo=discord&amp;amp;logoColor=white&amp;amp;style=for-the-badge" alt="Join our Discord community" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/HKUDS/AutoAgent/raw/main/assets/autoagent-wechat.jpg"&gt;&lt;img src="https://img.shields.io/badge/Wechat-Join%20Us-green?logo=wechat&amp;amp;logoColor=white&amp;amp;style=for-the-badge" alt="Join our Wechat community" /&gt;&lt;/a&gt; 
 &lt;br /&gt; 
 &lt;a href="https://autoagent-ai.github.io/docs"&gt;&lt;img src="https://img.shields.io/badge/Documentation-000?logo=googledocs&amp;amp;logoColor=FFE165&amp;amp;style=for-the-badge" alt="Check out the documentation" /&gt;&lt;/a&gt; 
 &lt;a href="https://arxiv.org/abs/2502.05957"&gt;&lt;img src="https://img.shields.io/badge/Paper%20on%20Arxiv-000?logoColor=FFE165&amp;amp;logo=arxiv&amp;amp;style=for-the-badge" alt="Paper" /&gt;&lt;/a&gt; 
 &lt;a href="https://gaia-benchmark-leaderboard.hf.space/"&gt;&lt;img src="https://img.shields.io/badge/GAIA%20Benchmark-000?logoColor=FFE165&amp;amp;logo=huggingface&amp;amp;style=for-the-badge" alt="Evaluation Benchmark Score" /&gt;&lt;/a&gt; 
 &lt;hr /&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://trendshift.io/repositories/13954" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/13954" alt="HKUDS%2FAutoAgent | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt; 
&lt;/div&gt; 
&lt;p&gt;Welcome to AutoAgent! AutoAgent is a &lt;strong&gt;Fully-Automated&lt;/strong&gt; and highly &lt;strong&gt;Self-Developing&lt;/strong&gt; framework that enables users to create and deploy LLM agents through &lt;strong&gt;Natural Language Alone&lt;/strong&gt;.&lt;/p&gt; 
&lt;h2&gt;âœ¨Key Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;ğŸ† Top Performers on the GAIA Benchmark &lt;br /&gt;AutoAgent has delivering comparable performance to many &lt;strong&gt;Deep Research Agents&lt;/strong&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;âœ¨ Agent and Workflow Create with Ease &lt;br /&gt;AutoAgent leverages natural language to effortlessly build ready-to-use &lt;strong&gt;tools&lt;/strong&gt;, &lt;strong&gt;agents&lt;/strong&gt; and &lt;strong&gt;workflows&lt;/strong&gt; - no coding required.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;ğŸ“š Agentic-RAG with Native Self-Managing Vector Database &lt;br /&gt;AutoAgent equipped with a native self-managing vector database, outperforms industry-leading solutions like &lt;strong&gt;LangChain&lt;/strong&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;ğŸŒ Universal LLM Support &lt;br /&gt;AutoAgent seamlessly integrates with &lt;strong&gt;A Wide Range&lt;/strong&gt; of LLMs (e.g., OpenAI, Anthropic, Deepseek, vLLM, Grok, Huggingface ...)&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;ğŸ”€ Flexible Interaction &lt;br /&gt;Benefit from support for both &lt;strong&gt;function-calling&lt;/strong&gt; and &lt;strong&gt;ReAct&lt;/strong&gt; interaction modes.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;ğŸ¤– Dynamic, Extensible, Lightweight &lt;br /&gt;AutoAgent is your &lt;strong&gt;Personal AI Assistant&lt;/strong&gt;, designed to be dynamic, extensible, customized, and lightweight.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;ğŸš€ Unlock the Future of LLM Agents. Try ğŸ”¥AutoAgentğŸ”¥ Now!&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;!-- &lt;img src="./assets/AutoAgentnew-intro.pdf" alt="Logo" width="100%"&gt; --&gt; 
 &lt;figure&gt; 
  &lt;img src="https://raw.githubusercontent.com/HKUDS/AutoAgent/main/assets/autoagent-intro.svg?sanitize=true" alt="Logo" style="max-width: 100%; height: auto;" /&gt; 
  &lt;figcaption&gt;
   &lt;em&gt;Quick Overview of AutoAgent.&lt;/em&gt;
  &lt;/figcaption&gt; 
 &lt;/figure&gt; 
&lt;/div&gt; 
&lt;h2&gt;ğŸ”¥ News&lt;/h2&gt; 
&lt;div class="scrollable"&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;[2025, Feb 17]&lt;/strong&gt;: &amp;nbsp;ğŸ‰ğŸ‰We've updated and released AutoAgent v0.2.0 (formerly known as MetaChain). Detailed changes include: 1) fix the bug of different LLM providers from issues; 2) add automatic installation of AutoAgent in the container environment according to issues; 3) add more easy-to-use commands for the CLI mode. 4) Rename the project to AutoAgent for better understanding.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;[2025, Feb 10]&lt;/strong&gt;: &amp;nbsp;ğŸ‰ğŸ‰We've released &lt;b&gt;MetaChain!&lt;/b&gt;, including framework, evaluation codes and CLI mode! Check our &lt;a href="https://arxiv.org/abs/2502.05957"&gt;paper&lt;/a&gt; for more details.&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/div&gt; 
&lt;span id="table-of-contents"&gt;&lt;/span&gt; 
&lt;h2&gt;ğŸ“‘ Table of Contents&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/AutoAgent/main/#features"&gt;âœ¨ Features&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/AutoAgent/main/#news"&gt;ğŸ”¥ News&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/AutoAgent/main/#how-to-use"&gt;ğŸ” How to Use AutoAgent&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/AutoAgent/main/#user-mode"&gt;1. &lt;code&gt;user mode&lt;/code&gt; (SOTA ğŸ† Open Deep Research)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/AutoAgent/main/#agent-editor"&gt;2. &lt;code&gt;agent editor&lt;/code&gt; (Agent Creation without Workflow)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/AutoAgent/main/#workflow-editor"&gt;3. &lt;code&gt;workflow editor&lt;/code&gt; (Agent Creation with Workflow)&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/AutoAgent/main/#quick-start"&gt;âš¡ Quick Start&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/AutoAgent/main/#installation"&gt;Installation&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/AutoAgent/main/#api-keys-setup"&gt;API Keys Setup&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/AutoAgent/main/#start-with-cli-mode"&gt;Start with CLI Mode&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/AutoAgent/main/#todo"&gt;â˜‘ï¸ Todo List&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/AutoAgent/main/#reproduce"&gt;ğŸ”¬ How To Reproduce the Results in the Paper&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/AutoAgent/main/#documentation"&gt;ğŸ“– Documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/AutoAgent/main/#community"&gt;ğŸ¤ Join the Community&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/AutoAgent/main/#acknowledgements"&gt;ğŸ™ Acknowledgements&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/AutoAgent/main/#cite"&gt;ğŸŒŸ Cite&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id="how-to-use"&gt;&lt;/span&gt; 
&lt;h2&gt;ğŸ” How to Use AutoAgent&lt;/h2&gt; 
&lt;span id="user-mode"&gt;&lt;/span&gt; 
&lt;h3&gt;1. &lt;code&gt;user mode&lt;/code&gt; (SOTA ğŸ† Open Deep Research)&lt;/h3&gt; 
&lt;p&gt;AutoAgent have an out-of-the-box multi-agent system, which you could choose &lt;code&gt;user mode&lt;/code&gt; in the start page to use it. This multi-agent system is a general AI assistant, having the same functionality with &lt;strong&gt;OpenAI's Deep Research&lt;/strong&gt; and the comparable performance with it in &lt;a href="https://gaia-benchmark-leaderboard.hf.space/"&gt;GAIA&lt;/a&gt; benchmark.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;ğŸš€ &lt;strong&gt;High Performance&lt;/strong&gt;: Matches Deep Research using Claude 3.5 rather than OpenAI's o3 model.&lt;/li&gt; 
 &lt;li&gt;ğŸ”„ &lt;strong&gt;Model Flexibility&lt;/strong&gt;: Compatible with any LLM (including Deepseek-R1, Grok, Gemini, etc.)&lt;/li&gt; 
 &lt;li&gt;ğŸ’° &lt;strong&gt;Cost-Effective&lt;/strong&gt;: Open-source alternative to Deep Research's $200/month subscription&lt;/li&gt; 
 &lt;li&gt;ğŸ¯ &lt;strong&gt;User-Friendly&lt;/strong&gt;: Easy-to-deploy CLI interface for seamless interaction&lt;/li&gt; 
 &lt;li&gt;ğŸ“ &lt;strong&gt;File Support&lt;/strong&gt;: Handles file uploads for enhanced data interaction&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div align="center"&gt; 
 &lt;video width="80%" controls&gt; 
  &lt;source src="./assets/video_v1_compressed.mp4" type="video/mp4" /&gt; 
 &lt;/video&gt; 
 &lt;p&gt;&lt;em&gt;ğŸ¥ Deep Research (aka User Mode)&lt;/em&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;span id="agent-editor"&gt;&lt;/span&gt; 
&lt;h3&gt;2. &lt;code&gt;agent editor&lt;/code&gt; (Agent Creation without Workflow)&lt;/h3&gt; 
&lt;p&gt;The most distinctive feature of AutoAgent is its natural language customization capability. Unlike other agent frameworks, AutoAgent allows you to create tools, agents, and workflows using natural language alone. Simply choose &lt;code&gt;agent editor&lt;/code&gt; or &lt;code&gt;workflow editor&lt;/code&gt; mode to start your journey of building agents through conversations.&lt;/p&gt; 
&lt;p&gt;You can use &lt;code&gt;agent editor&lt;/code&gt; as shown in the following figure.&lt;/p&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr align="center"&gt; 
   &lt;td width="33%"&gt; &lt;img src="https://raw.githubusercontent.com/HKUDS/AutoAgent/main/assets/agent_editor/1-requirement.png" alt="requirement" width="100%" /&gt; &lt;br /&gt; &lt;em&gt;Input what kind of agent you want to create.&lt;/em&gt; &lt;/td&gt; 
   &lt;td width="33%"&gt; &lt;img src="https://raw.githubusercontent.com/HKUDS/AutoAgent/main/assets/agent_editor/2-profiling.png" alt="profiling" width="100%" /&gt; &lt;br /&gt; &lt;em&gt;Automated agent profiling.&lt;/em&gt; &lt;/td&gt; 
   &lt;td width="33%"&gt; &lt;img src="https://raw.githubusercontent.com/HKUDS/AutoAgent/main/assets/agent_editor/3-profiles.png" alt="profiles" width="100%" /&gt; &lt;br /&gt; &lt;em&gt;Output the agent profiles.&lt;/em&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr align="center"&gt; 
   &lt;td width="33%"&gt; &lt;img src="https://raw.githubusercontent.com/HKUDS/AutoAgent/main/assets/agent_editor/4-tools.png" alt="tools" width="100%" /&gt; &lt;br /&gt; &lt;em&gt;Create the desired tools.&lt;/em&gt; &lt;/td&gt; 
   &lt;td width="33%"&gt; &lt;img src="https://raw.githubusercontent.com/HKUDS/AutoAgent/main/assets/agent_editor/5-task.png" alt="task" width="100%" /&gt; &lt;br /&gt; &lt;em&gt;Input what do you want to complete with the agent. (Optional)&lt;/em&gt; &lt;/td&gt; 
   &lt;td width="33%"&gt; &lt;img src="https://raw.githubusercontent.com/HKUDS/AutoAgent/main/assets/agent_editor/6-output-next.png" alt="output" width="100%" /&gt; &lt;br /&gt; &lt;em&gt;Create the desired agent(s) and go to the next step.&lt;/em&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;span id="workflow-editor"&gt;&lt;/span&gt; 
&lt;h3&gt;3. &lt;code&gt;workflow editor&lt;/code&gt; (Agent Creation with Workflow)&lt;/h3&gt; 
&lt;p&gt;You can also create the agent workflows using natural language description with the &lt;code&gt;workflow editor&lt;/code&gt; mode, as shown in the following figure. (Tips: this mode does not support tool creation temporarily.)&lt;/p&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr align="center"&gt; 
   &lt;td width="33%"&gt; &lt;img src="https://raw.githubusercontent.com/HKUDS/AutoAgent/main/assets/workflow_editor/1-requirement.png" alt="requirement" width="100%" /&gt; &lt;br /&gt; &lt;em&gt;Input what kind of workflow you want to create.&lt;/em&gt; &lt;/td&gt; 
   &lt;td width="33%"&gt; &lt;img src="https://raw.githubusercontent.com/HKUDS/AutoAgent/main/assets/workflow_editor/2-profiling.png" alt="profiling" width="100%" /&gt; &lt;br /&gt; &lt;em&gt;Automated workflow profiling.&lt;/em&gt; &lt;/td&gt; 
   &lt;td width="33%"&gt; &lt;img src="https://raw.githubusercontent.com/HKUDS/AutoAgent/main/assets/workflow_editor/3-profiles.png" alt="profiles" width="100%" /&gt; &lt;br /&gt; &lt;em&gt;Output the workflow profiles.&lt;/em&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr align="center"&gt; 
   &lt;td width="33%"&gt; &lt;img src="https://raw.githubusercontent.com/HKUDS/AutoAgent/main/assets/workflow_editor/4-task.png" alt="task" width="66%" /&gt; &lt;br /&gt; &lt;em&gt;Input what do you want to complete with the workflow. (Optional)&lt;/em&gt; &lt;/td&gt; 
   &lt;td width="33%"&gt; &lt;img src="https://raw.githubusercontent.com/HKUDS/AutoAgent/main/assets/workflow_editor/5-output-next.png" alt="output" width="66%" /&gt; &lt;br /&gt; &lt;em&gt;Create the desired workflow(s) and go to the next step.&lt;/em&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;span id="quick-start"&gt;&lt;/span&gt; 
&lt;h2&gt;âš¡ Quick Start&lt;/h2&gt; 
&lt;span id="installation"&gt;&lt;/span&gt; 
&lt;h3&gt;Installation&lt;/h3&gt; 
&lt;h4&gt;AutoAgent Installation&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/HKUDS/AutoAgent.git
cd AutoAgent
pip install -e .
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Docker Installation&lt;/h4&gt; 
&lt;p&gt;We use Docker to containerize the agent-interactive environment. So please install &lt;a href="https://www.docker.com/"&gt;Docker&lt;/a&gt; first. You don't need to manually pull the pre-built image, because we have let Auto-Deep-Research &lt;strong&gt;automatically pull the pre-built image based on your architecture of your machine&lt;/strong&gt;.&lt;/p&gt; 
&lt;span id="api-keys-setup"&gt;&lt;/span&gt; 
&lt;h3&gt;API Keys Setup&lt;/h3&gt; 
&lt;p&gt;Create an environment variable file, just like &lt;code&gt;.env.template&lt;/code&gt;, and set the API keys for the LLMs you want to use. Not every LLM API Key is required, use what you need.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Required Github Tokens of your own
GITHUB_AI_TOKEN=

# Optional API Keys
OPENAI_API_KEY=
DEEPSEEK_API_KEY=
ANTHROPIC_API_KEY=
GEMINI_API_KEY=
HUGGINGFACE_API_KEY=
GROQ_API_KEY=
XAI_API_KEY=
&lt;/code&gt;&lt;/pre&gt; 
&lt;span id="start-with-cli-mode"&gt;&lt;/span&gt; 
&lt;h3&gt;Start with CLI Mode&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[ğŸš¨ &lt;strong&gt;News&lt;/strong&gt;: ] We have updated a more easy-to-use command to start the CLI mode and fix the bug of different LLM providers from issues. You can follow the following steps to start the CLI mode with different LLM providers with much less configuration.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;Command Options:&lt;/h4&gt; 
&lt;p&gt;You can run &lt;code&gt;auto main&lt;/code&gt; to start full part of AutoAgent, including &lt;code&gt;user mode&lt;/code&gt;, &lt;code&gt;agent editor&lt;/code&gt; and &lt;code&gt;workflow editor&lt;/code&gt;. Btw, you can also run &lt;code&gt;auto deep-research&lt;/code&gt; to start more lightweight &lt;code&gt;user mode&lt;/code&gt;, just like the &lt;a href="https://github.com/HKUDS/Auto-Deep-Research"&gt;Auto-Deep-Research&lt;/a&gt; project. Some configuration of this command is shown below.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;--container_name&lt;/code&gt;: Name of the Docker container (default: 'deepresearch')&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--port&lt;/code&gt;: Port for the container (default: 12346)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;COMPLETION_MODEL&lt;/code&gt;: Specify the LLM model to use, you should follow the name of &lt;a href="https://github.com/BerriAI/litellm"&gt;Litellm&lt;/a&gt; to set the model name. (Default: &lt;code&gt;claude-3-5-sonnet-20241022&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;DEBUG&lt;/code&gt;: Enable debug mode for detailed logs (default: False)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;API_BASE_URL&lt;/code&gt;: The base URL for the LLM provider (default: None)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;FN_CALL&lt;/code&gt;: Enable function calling (default: None). Most of time, you could ignore this option because we have already set the default value based on the model name.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;git_clone&lt;/code&gt;: Clone the AutoAgent repository to the local environment (only support with the &lt;code&gt;auto main&lt;/code&gt; command, default: True)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;test_pull_name&lt;/code&gt;: The name of the test pull. (only support with the &lt;code&gt;auto main&lt;/code&gt; command, default: 'autoagent_mirror')&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;More details about &lt;code&gt;git_clone&lt;/code&gt; and &lt;code&gt;test_pull_name&lt;/code&gt;]&lt;/h4&gt; 
&lt;p&gt;In the &lt;code&gt;agent editor&lt;/code&gt; and &lt;code&gt;workflow editor&lt;/code&gt; mode, we should clone a mirror of the AutoAgent repository to the local agent-interactive environment and let our &lt;strong&gt;AutoAgent&lt;/strong&gt; automatically update the AutoAgent itself, such as creating new tools, agents and workflows. So if you want to use the &lt;code&gt;agent editor&lt;/code&gt; and &lt;code&gt;workflow editor&lt;/code&gt; mode, you should set the &lt;code&gt;git_clone&lt;/code&gt; to True and set the &lt;code&gt;test_pull_name&lt;/code&gt; to 'autoagent_mirror' or other branches.&lt;/p&gt; 
&lt;h4&gt;&lt;code&gt;auto main&lt;/code&gt; with different LLM Providers&lt;/h4&gt; 
&lt;p&gt;Then I will show you how to use the full part of AutoAgent with the &lt;code&gt;auto main&lt;/code&gt; command and different LLM providers. If you want to use the &lt;code&gt;auto deep-research&lt;/code&gt; command, you can refer to the &lt;a href="https://github.com/HKUDS/Auto-Deep-Research"&gt;Auto-Deep-Research&lt;/a&gt; project for more details.&lt;/p&gt; 
&lt;h5&gt;Anthropic&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;set the &lt;code&gt;ANTHROPIC_API_KEY&lt;/code&gt; in the &lt;code&gt;.env&lt;/code&gt; file.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;ANTHROPIC_API_KEY=your_anthropic_api_key
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;run the following command to start Auto-Deep-Research.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;auto main # default model is claude-3-5-sonnet-20241022
&lt;/code&gt;&lt;/pre&gt; 
&lt;h5&gt;OpenAI&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;set the &lt;code&gt;OPENAI_API_KEY&lt;/code&gt; in the &lt;code&gt;.env&lt;/code&gt; file.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;OPENAI_API_KEY=your_openai_api_key
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;run the following command to start Auto-Deep-Research.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;COMPLETION_MODEL=gpt-4o auto main
&lt;/code&gt;&lt;/pre&gt; 
&lt;h5&gt;Mistral&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;set the &lt;code&gt;MISTRAL_API_KEY&lt;/code&gt; in the &lt;code&gt;.env&lt;/code&gt; file.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;MISTRAL_API_KEY=your_mistral_api_key
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;run the following command to start Auto-Deep-Research.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;COMPLETION_MODEL=mistral/mistral-large-2407 auto main
&lt;/code&gt;&lt;/pre&gt; 
&lt;h5&gt;Gemini - Google AI Studio&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;set the &lt;code&gt;GEMINI_API_KEY&lt;/code&gt; in the &lt;code&gt;.env&lt;/code&gt; file.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;GEMINI_API_KEY=your_gemini_api_key
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;run the following command to start Auto-Deep-Research.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;COMPLETION_MODEL=gemini/gemini-2.0-flash auto main
&lt;/code&gt;&lt;/pre&gt; 
&lt;h5&gt;Huggingface&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;set the &lt;code&gt;HUGGINGFACE_API_KEY&lt;/code&gt; in the &lt;code&gt;.env&lt;/code&gt; file.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;HUGGINGFACE_API_KEY=your_huggingface_api_key
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;run the following command to start Auto-Deep-Research.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;COMPLETION_MODEL=huggingface/meta-llama/Llama-3.3-70B-Instruct auto main
&lt;/code&gt;&lt;/pre&gt; 
&lt;h5&gt;Groq&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;set the &lt;code&gt;GROQ_API_KEY&lt;/code&gt; in the &lt;code&gt;.env&lt;/code&gt; file.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;GROQ_API_KEY=your_groq_api_key
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;run the following command to start Auto-Deep-Research.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;COMPLETION_MODEL=groq/deepseek-r1-distill-llama-70b auto main
&lt;/code&gt;&lt;/pre&gt; 
&lt;h5&gt;OpenAI-Compatible Endpoints (e.g., Grok)&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;set the &lt;code&gt;OPENAI_API_KEY&lt;/code&gt; in the &lt;code&gt;.env&lt;/code&gt; file.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;OPENAI_API_KEY=your_api_key_for_openai_compatible_endpoints
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;run the following command to start Auto-Deep-Research.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;COMPLETION_MODEL=openai/grok-2-latest API_BASE_URL=https://api.x.ai/v1 auto main
&lt;/code&gt;&lt;/pre&gt; 
&lt;h5&gt;OpenRouter (e.g., DeepSeek-R1)&lt;/h5&gt; 
&lt;p&gt;We recommend using OpenRouter as LLM provider of DeepSeek-R1 temporarily. Because official API of DeepSeek-R1 can not be used efficiently.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;set the &lt;code&gt;OPENROUTER_API_KEY&lt;/code&gt; in the &lt;code&gt;.env&lt;/code&gt; file.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;OPENROUTER_API_KEY=your_openrouter_api_key
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;run the following command to start Auto-Deep-Research.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;COMPLETION_MODEL=openrouter/deepseek/deepseek-r1 auto main
&lt;/code&gt;&lt;/pre&gt; 
&lt;h5&gt;DeepSeek&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;set the &lt;code&gt;DEEPSEEK_API_KEY&lt;/code&gt; in the &lt;code&gt;.env&lt;/code&gt; file.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;DEEPSEEK_API_KEY=your_deepseek_api_key
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;run the following command to start Auto-Deep-Research.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;COMPLETION_MODEL=deepseek/deepseek-chat auto main
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;After the CLI mode is started, you can see the start page of AutoAgent:&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;!-- &lt;img src="./assets/AutoAgentnew-intro.pdf" alt="Logo" width="100%"&gt; --&gt; 
 &lt;figure&gt; 
  &lt;img src="https://raw.githubusercontent.com/HKUDS/AutoAgent/main/assets/cover.png" alt="Logo" style="max-width: 100%; height: auto;" /&gt; 
  &lt;figcaption&gt;
   &lt;em&gt;Start Page of AutoAgent.&lt;/em&gt;
  &lt;/figcaption&gt; 
 &lt;/figure&gt; 
&lt;/div&gt; 
&lt;h3&gt;Tips&lt;/h3&gt; 
&lt;h4&gt;Import browser cookies to browser environment&lt;/h4&gt; 
&lt;p&gt;You can import the browser cookies to the browser environment to let the agent better access some specific websites. For more details, please refer to the &lt;a href="https://raw.githubusercontent.com/HKUDS/AutoAgent/main/AutoAgent/environment/cookie_json/README.md"&gt;cookies&lt;/a&gt; folder.&lt;/p&gt; 
&lt;h4&gt;Add your own API keys for third-party Tool Platforms&lt;/h4&gt; 
&lt;p&gt;If you want to create tools from the third-party tool platforms, such as RapidAPI, you should subscribe tools from the platform and add your own API keys by running &lt;a href="https://raw.githubusercontent.com/HKUDS/AutoAgent/main/process_tool_docs.py"&gt;process_tool_docs.py&lt;/a&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python process_tool_docs.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;More features coming soon! ğŸš€ &lt;strong&gt;Web GUI interface&lt;/strong&gt; under development.&lt;/p&gt; 
&lt;span id="todo"&gt;&lt;/span&gt; 
&lt;h2&gt;â˜‘ï¸ Todo List&lt;/h2&gt; 
&lt;p&gt;AutoAgent is continuously evolving! Here's what's coming:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;ğŸ“Š &lt;strong&gt;More Benchmarks&lt;/strong&gt;: Expanding evaluations to &lt;strong&gt;SWE-bench&lt;/strong&gt;, &lt;strong&gt;WebArena&lt;/strong&gt;, and more&lt;/li&gt; 
 &lt;li&gt;ğŸ–¥ï¸ &lt;strong&gt;GUI Agent&lt;/strong&gt;: Supporting &lt;em&gt;Computer-Use&lt;/em&gt; agents with GUI interaction&lt;/li&gt; 
 &lt;li&gt;ğŸ”§ &lt;strong&gt;Tool Platforms&lt;/strong&gt;: Integration with more platforms like &lt;strong&gt;Composio&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;ğŸ—ï¸ &lt;strong&gt;Code Sandboxes&lt;/strong&gt;: Supporting additional environments like &lt;strong&gt;E2B&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;ğŸ¨ &lt;strong&gt;Web Interface&lt;/strong&gt;: Developing comprehensive GUI for better user experience&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Have ideas or suggestions? Feel free to open an issue! Stay tuned for more exciting updates! ğŸš€&lt;/p&gt; 
&lt;span id="reproduce"&gt;&lt;/span&gt; 
&lt;h2&gt;ğŸ”¬ How To Reproduce the Results in the Paper&lt;/h2&gt; 
&lt;h3&gt;GAIA Benchmark&lt;/h3&gt; 
&lt;p&gt;For the GAIA benchmark, you can run the following command to run the inference.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd path/to/AutoAgent &amp;amp;&amp;amp; sh evaluation/gaia/scripts/run_infer.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For the evaluation, you can run the following command.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd path/to/AutoAgent &amp;amp;&amp;amp; python evaluation/gaia/get_score.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Agentic-RAG&lt;/h3&gt; 
&lt;p&gt;For the Agentic-RAG task, you can run the following command to run the inference.&lt;/p&gt; 
&lt;p&gt;Step1. Turn to &lt;a href="https://huggingface.co/datasets/yixuantt/MultiHopRAG"&gt;this page&lt;/a&gt; and download it. Save them to your datapath.&lt;/p&gt; 
&lt;p&gt;Step2. Run the following command to run the inference.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd path/to/AutoAgent &amp;amp;&amp;amp; sh evaluation/multihoprag/scripts/run_rag.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Step3. The result will be saved in the &lt;code&gt;evaluation/multihoprag/result.json&lt;/code&gt;.&lt;/p&gt; 
&lt;span id="documentation"&gt;&lt;/span&gt; 
&lt;h2&gt;ğŸ“– Documentation&lt;/h2&gt; 
&lt;p&gt;A more detailed documentation is coming soon ğŸš€, and we will update in the &lt;a href="https://AutoAgent-ai.github.io/docs"&gt;Documentation&lt;/a&gt; page.&lt;/p&gt; 
&lt;span id="community"&gt;&lt;/span&gt; 
&lt;h2&gt;ğŸ¤ Join the Community&lt;/h2&gt; 
&lt;p&gt;We want to build a community for AutoAgent, and we welcome everyone to join us. You can join our community by:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://join.slack.com/t/AutoAgent-workspace/shared_invite/zt-2zibtmutw-v7xOJObBf9jE2w3x7nctFQ"&gt;Join our Slack workspace&lt;/a&gt; - Here we talk about research, architecture, and future development.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://discord.gg/z68KRvwB"&gt;Join our Discord server&lt;/a&gt; - This is a community-run server for general discussion, questions, and feedback.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/HKUDS/AutoAgent/issues"&gt;Read or post Github Issues&lt;/a&gt; - Check out the issues we're working on, or add your own ideas.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id="acknowledgements"&gt;&lt;/span&gt; 
&lt;h2&gt;Misc&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://github.com/HKUDS/AutoAgent/stargazers"&gt;&lt;img src="https://reporoster.com/stars/HKUDS/AutoAgent" alt="Stargazers repo roster for @HKUDS/AutoAgent" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://github.com/HKUDS/AutoAgent/network/members"&gt;&lt;img src="https://reporoster.com/forks/HKUDS/AutoAgent" alt="Forkers repo roster for @HKUDS/AutoAgent" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://star-history.com/#HKUDS/AutoAgent&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=HKUDS/AutoAgent&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;ğŸ™ Acknowledgements&lt;/h2&gt; 
&lt;p&gt;Rome wasn't built in a day. AutoAgent stands on the shoulders of giants, and we are deeply grateful for the outstanding work that came before us. Our framework architecture draws inspiration from &lt;a href="https://github.com/openai/swarm"&gt;OpenAI Swarm&lt;/a&gt;, while our user mode's three-agent design benefits from &lt;a href="https://github.com/microsoft/autogen/tree/main/python/packages/autogen-magentic-one"&gt;Magentic-one&lt;/a&gt;'s insights. We've also learned from &lt;a href="https://github.com/All-Hands-AI/OpenHands"&gt;OpenHands&lt;/a&gt; for documentation structure and many other excellent projects for agent-environment interaction design, among others. We express our sincere gratitude and respect to all these pioneering works that have been instrumental in shaping AutoAgent.&lt;/p&gt; 
&lt;span id="cite"&gt;&lt;/span&gt; 
&lt;h2&gt;ğŸŒŸ Cite&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-tex"&gt;@misc{AutoAgent,
      title={{AutoAgent: A Fully-Automated and Zero-Code Framework for LLM Agents}},
      author={Jiabin Tang, Tianyu Fan, Chao Huang},
      year={2025},
      eprint={202502.05957},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2502.05957},
}
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>vercel/examples</title>
      <link>https://github.com/vercel/examples</link>
      <description>&lt;p&gt;Enjoy our curated collection of examples and solutions. Use these patterns to build your own robust and scalable applications.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;a href="https://vercel.com"&gt; &lt;img src="https://assets.vercel.com/image/upload/v1588805858/repositories/vercel/logo.png" height="96" /&gt; &lt;/a&gt;&lt;/p&gt;
&lt;h3 align="center"&gt;&lt;a href="https://vercel.com"&gt;Vercel Examples&lt;/a&gt;&lt;/h3&gt;
&lt;a href="https://vercel.com"&gt; &lt;/a&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/vercel/examples/main/solutions"&gt;Solutions&lt;/a&gt; â€“ Demos, reference architecture, and best practices&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/vercel/examples/main/starter"&gt;Starter&lt;/a&gt; â€“ Functional applications which can act as a starting point&lt;/li&gt; 
 &lt;li&gt;And more!&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Vercel Templates&lt;/h2&gt; 
&lt;p&gt;Multiple examples are being featured in &lt;a href="https://vercel.com/templates"&gt;Vercel's Templates&lt;/a&gt;, visit that page for more advanced filtering options.&lt;/p&gt; 
&lt;h3&gt;For Vercelians&lt;/h3&gt; 
&lt;p&gt;Examples that have front matter metadata will create a new Draft template in &lt;a href="https://app.contentful.com"&gt;Contentful&lt;/a&gt;, for more steps on how to publish a template, read &lt;a href="https://raw.githubusercontent.com/vercel/examples/main/internal/publishing-templates.md"&gt;Publishing Templates&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Adding a new example&lt;/h2&gt; 
&lt;p&gt;To quickly start contributing with a new example, run the following commands:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pnpm i
pnpm new-example
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If the script above isn't used, make sure the example complies with the following:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;It must have a &lt;code&gt;.gitignore&lt;/code&gt; similar to &lt;a href="https://raw.githubusercontent.com/vercel/examples/main/plop-templates/example/.gitignore"&gt;plop-templates/example/.gitignore&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;It must have a &lt;code&gt;package.json&lt;/code&gt; similar to &lt;a href="https://raw.githubusercontent.com/vercel/examples/main/plop-templates/example/package.json"&gt;plop-templates/example/package.json&lt;/a&gt; (usage of Next.js is optional). The license should be &lt;code&gt;MIT&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;It must have a &lt;code&gt;README.md&lt;/code&gt; similar to &lt;a href="https://raw.githubusercontent.com/vercel/examples/main/plop-templates/example/README.md"&gt;plop-templates/example/README.md&lt;/a&gt;. The example has to be able to include a demo URL (the Vercel team will deploy it!) and if it requires environment variables, it must have a &lt;code&gt;.env.example&lt;/code&gt; file and instructions on how to set them up. Take &lt;a href="https://raw.githubusercontent.com/vercel/examples/main/edge-middleware/bot-protection-datadome/README.md"&gt;bot-protection-datadome&lt;/a&gt; as an example. 
  &lt;ul&gt; 
   &lt;li&gt;To customize the Vercel Deploy Button take a look at the &lt;a href="https://vercel.com/docs/deploy-button"&gt;docs&lt;/a&gt;, useful if the deployment has required environment variables.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;If using Next.js, it must have a &lt;code&gt;.eslintrc.json&lt;/code&gt; similar to &lt;a href="https://raw.githubusercontent.com/vercel/examples/main/plop-templates/example/.eslintrc.json"&gt;plop-templates/example/.eslintrc.json&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;All Next.js examples should be using the same styling and layout provided by &lt;code&gt;@vercel/examples-ui&lt;/code&gt;, its usage can be seen in the &lt;a href="https://raw.githubusercontent.com/vercel/examples/main/plop-templates/example"&gt;plop template&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Adding a template&lt;/h3&gt; 
&lt;p&gt;If you would like the example to be featured in &lt;a href="https://vercel.com/templates"&gt;vercel.com/templates&lt;/a&gt; then also add the front matter metadata to the top of the readme, like in &lt;a href="https://raw.githubusercontent.com/vercel/examples/main/edge-middleware/bot-protection-datadome/README.md"&gt;bot-protection-datadome&lt;/a&gt;. To know all the possible values for each metadata take a look at &lt;a href="https://raw.githubusercontent.com/vercel/examples/main/internal/fields.json"&gt;&lt;code&gt;internal/fields.json&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;If you want to add related templates to your template, copy the &lt;code&gt;slug&lt;/code&gt; from the other template into the &lt;code&gt;relatedTemplates&lt;/code&gt; field, for example for &lt;a href="https://vercel.com/templates/next.js/monorepo-turborepo"&gt;vercel.com/templates/next.js/monorepo-turborepo&lt;/a&gt; the slug is &lt;code&gt;monorepo-turborepo&lt;/code&gt;, as written in &lt;a href="https://raw.githubusercontent.com/vercel/examples/main/solutions/monorepo/README.md"&gt;solutions/monorepo/README.md&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;The pre-commit hook&lt;/h3&gt; 
&lt;p&gt;We use &lt;a href="https://typicode.github.io/husky/#/"&gt;Husky&lt;/a&gt; to manage the pre-commit &lt;a href="https://git-scm.com/docs/githooks"&gt;Git hook&lt;/a&gt; in this repo. Husky configures hooks automatically during install, so you don't need to do anything special to get them working, but if it fails to install, you can run the following command to install it manually:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pnpm run prepare
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Code changes automatically go through Prettier and ESLint when you make a commit, &lt;strong&gt;please do not skip these steps&lt;/strong&gt; unless they're broken and in that case let us known by creating an issue.&lt;/p&gt; 
&lt;h2&gt;Read the Docs&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://vercel.com/docs"&gt;Vercel Docs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://nextjs.org/docs"&gt;Next.js Docs&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;If you have any questions or suggestions about the docs, feel free to &lt;a href="https://github.com/vercel/examples/discussions"&gt;open a discussion&lt;/a&gt;, or &lt;a href="https://github.com/vercel/examples/pulls"&gt;submit a PR&lt;/a&gt; with your suggestions!&lt;/p&gt; 
&lt;h2&gt;Provide Feedback&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/vercel/examples/discussions"&gt;Start a Discussion&lt;/a&gt; with a question, piece of feedback, or idea you want to share with the team.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/vercel/examples/issues"&gt;Open an Issue&lt;/a&gt; if you believe you've encountered a bug that you want to flag for the team.&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>ClemensElflein/OpenMower</title>
      <link>https://github.com/ClemensElflein/OpenMower</link>
      <description>&lt;p&gt;Let's upgrade cheap off-the-shelf robotic mowers to modern, smart RTK GPS based lawn mowing robots!&lt;/p&gt;&lt;hr&gt;&lt;h2&gt;I am available for hire&lt;/h2&gt; 
&lt;p&gt;Hello! With a background in software engineering, embedded programming, hardware design, and robotics, I'm on the lookout for new challenges. If you're in search of someone with my skills, let's team up and create something amazing! &lt;a href="https://x-tech.online/"&gt;https://x-tech.online/&lt;/a&gt;&lt;/p&gt; 
&lt;br /&gt; 
&lt;hr /&gt; 
&lt;br /&gt; 
&lt;p align="center"&gt; &lt;a&gt; &lt;/a&gt;&lt;/p&gt;
&lt;h1 align="center"&gt;&lt;a&gt;OpenMower - The DIY Smart Mowing Robot for Everyone&lt;/a&gt;&lt;/h1&gt;
&lt;a&gt; &lt;img align="center" src="https://raw.githubusercontent.com/ClemensElflein/OpenMower/main/img/open_mower_header.jpg" /&gt; &lt;/a&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;br /&gt; 
&lt;p align="center"&gt; &lt;a href="https://raw.githubusercontent.com/ClemensElflein/OpenMower/main/#license"&gt;&lt;img src="https://img.shields.io/badge/License-CC%20BY--NC--SA%204.0-lightgrey.svg?sanitize=true" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;br /&gt; 
&lt;p align="center"&gt;&lt;b&gt;Join the Discord server for OpenMower discussion:&lt;/b&gt; &lt;/p&gt;
&lt;p align="center"&gt;&lt;a href="https://discord.gg/jE7QNaSxW7" target="_blank"&gt;&lt;img src="https://badgen.net/badge/icon/discord?icon=discord&amp;amp;label" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;br /&gt; 
&lt;br /&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!WARNING]&lt;/p&gt; 
 &lt;p align="center"&gt;&lt;b&gt;DISCLAIMER:&lt;/b&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;IF YOU ARE NOT 100% SURE WHAT YOU ARE DOING, PLEASE DON'T TRY THIS AT HOME! ASK IN &lt;a href="https://discord.gg/jE7QNaSxW7"&gt;DISCORD&lt;/a&gt;, IF YOU HAVE ANY QUESTIONS!&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT]&lt;/p&gt; 
 &lt;p align="center"&gt;&lt;b&gt;This project is active!&lt;/b&gt;&lt;/p&gt; 
 &lt;p&gt;This is the hardware repository, so it might seem that the project is inactive, since hardware is pretty stable by now. Most of the development work is done on the ROS code here: &lt;a href="https://github.com/ClemensElflein/open_mower_ros"&gt;https://github.com/ClemensElflein/open_mower_ros&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;br /&gt; 
&lt;h1&gt;About the Project&lt;/h1&gt; 
&lt;p&gt;If you want to see a quick overview, you can check out this video:&lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://www.youtube.com/watch?v=BSF04i3zNGw" target="_blank"&gt;&lt;img src="https://user-images.githubusercontent.com/2864655/161540069-f4263fa7-a47b-49d2-a7bc-d1cdc3a47704.jpg" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p&gt;Let's be honest: The current generation of robotic lawn mowers sucks. Basically all of these bots drive in a random direction until they hit the border of the lawn, rotate for a randomized duration and repeat. &lt;strong&gt;I think we can do better!&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Therefore, we have disassembled the cheapest off-the-shelf robotic mower we could find (YardForce Classic 500) and were surprised that the hardware itself is actually quite decent:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Geared sensored brushless motors for the wheels&lt;/li&gt; 
 &lt;li&gt;A sensored brushless motor for the mower motor itself&lt;/li&gt; 
 &lt;li&gt;The whole construction seems robust, waterproof and all in all thought through&lt;/li&gt; 
 &lt;li&gt;All components are connected using standard connectors, therefore upgrading the hardware is easily possible.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The bottom line is: The bot itself is surprisingly high quality and doesn't need to be changed at all. &lt;strong&gt;We just need some better software in there&lt;/strong&gt;.&lt;/p&gt; 
&lt;h2&gt;Project Goals&lt;/h2&gt; 
&lt;p&gt;Here is a quick overview of this project's goals:&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;âœ”&lt;/span&gt; &lt;strong&gt;Autonomous Lawn Mowing:&lt;/strong&gt; Obviously, the device should be able to mow the lawn automatically.&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;âœ”&lt;/span&gt; &lt;strong&gt;Good Safety:&lt;/strong&gt; The device must be safe, e.g. emergency stop if lifted or crashed.&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;âœ”&lt;/span&gt; &lt;strong&gt;No Perimeter Wire Needed:&lt;/strong&gt; We want to be flexible and support multiple mowing areas.&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;âœ”&lt;/span&gt; &lt;strong&gt;Low Cost:&lt;/strong&gt; It should be cheaper than a mid range off-the-shelf product&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;âœ”&lt;/span&gt; &lt;strong&gt;Open:&lt;/strong&gt; I want to share knowledge and enable others to build an OpenMower as well.&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;âœ”&lt;/span&gt; &lt;strong&gt;Nice to Look At:&lt;/strong&gt; You should not be ashamed to have an OpenMower mowing your lawn.&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;âœ”&lt;/span&gt; &lt;strong&gt;Avoid Obstacles:&lt;/strong&gt; The mower should detect obstacles and avoid them during mowing.&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;âœ”&lt;/span&gt; &lt;strong&gt;Rain Detection:&lt;/strong&gt; The device should be able to detect bad weather conditions and pause mowing until they improve.&lt;/p&gt; 
&lt;h1&gt;Open Mower App&lt;/h1&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/ClemensElflein/OpenMower/main/img/open_mower_app_1.jpg" alt="Open Mower App 1" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/ClemensElflein/OpenMower/main/img/open_mower_app_2.jpg" alt="Open Mower App 2" /&gt;&lt;/p&gt; 
&lt;h2&gt;Current State&lt;/h2&gt; 
&lt;p&gt;The basic mowing function finally works! As you can see in the video, map teaching and mowing work as expected. It even returns to the docking station automatically as soon as the battery gets low and continues once it's recharged.&lt;/p&gt; 
&lt;p&gt;At this point I can recommend that brave tech savvy users can build one for themselves! Since it's quite an expensive and complex project, please don't be shy and ask if you have any questions. I'm glad to help ğŸ™‚&lt;/p&gt; 
&lt;h3&gt;Hardware&lt;/h3&gt; 
&lt;p&gt;By now we have a stable revision of the mainboard as well as two motor controllers to go with it. The &lt;a href="https://github.com/clemensElflein/xesc"&gt;xESC mini&lt;/a&gt; and the &lt;a href="https://github.com/clemensElflein/xesc2040"&gt;xESC 2040&lt;/a&gt;. I'm currently using the xESC mini for my builds and it works very well. The problem with this controller is, its parts are currently hard to source. That's why we created the xESC 2040 based on the RP2040 chip. This is the low-cost variant and its support is currently experimental.&lt;/p&gt; 
&lt;h4&gt;Hardware To-Do:&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Low Level Firmware Implementation 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Voltage / Current Sense&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Emergency Stop Button tracking&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; IMU Communication&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Rain Sensor&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Charging State&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Sound Module&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; UI Board Communication&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Discharge current for more accurate battery charge estimation&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; ROS Hardware Interface&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Software&lt;/h3&gt; 
&lt;p&gt;The basic software is basically done; Our prototype works as intended (but is not able to avoid obstacles yet).&lt;/p&gt; 
&lt;p&gt;The software for the robot can be found in a separate repository: &lt;a href="https://github.com/ClemensElflein/open_mower_ros"&gt;https://github.com/ClemensElflein/open_mower_ros&lt;/a&gt;&lt;/p&gt; 
&lt;h4&gt;Software To-Do:&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Mowing State Machine (Docking / Mowing, ...)&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Path Planning&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Obstacle Avoidance&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; App / Visualization&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;p&gt;If you want to read how to get started building a robot for yourself, check the &lt;a href="https://openmower.de"&gt;OpenMower Website&lt;/a&gt;. There you can find information on which parts to buy, how to install the software and so on. If you find anything missing, please join the Discord server and ask there. Also there's the &lt;a href="https://wiki.openmower.de"&gt;OpenMower Wiki&lt;/a&gt; which is written by the community. It has some additional guides and information.&lt;/p&gt; 
&lt;h1&gt;How You Can Help&lt;/h1&gt; 
&lt;p&gt;You can help by starting an OpenMower build of your own. This helps to validate the concept and helps to create useful documentation for new users.&lt;/p&gt; 
&lt;p&gt;Additionally, you can help by starring ğŸŒŸ and watching ğŸ‘€ this repository, since it will help with visibility. You can also subscribe to my &lt;a href="https://youtube.com/c/ClemensElflein"&gt;YouTube channel&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Compatible Robotic Mowers&lt;/h2&gt; 
&lt;p&gt;While disassembling the bot, I wondered about its mainboard: Instead of "YardForce" it read "GForce". After checking the internet for "GForce" robots, I found that that very similar looking robotic mowers are sold under the Herkules brand. Naturally I tried to dig deeper and actually found evidence that the mainboard is manufactured by some chinese company (SUMEC Hardware).&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/ClemensElflein/OpenMower/main/img/mainboard.jpg" alt="GForce Robot Mower Mainboard" /&gt;&lt;/p&gt; 
&lt;p&gt;It is therefore quite safe to assume that many robot mowers are basically the same device in a different case. This would be a huge win for the community, since this would mean that by making one of those robots smarter, we could upgrade lots of robots.&lt;/p&gt; 
&lt;p&gt;Therefore it might be a good idea to start a list of compatible devices. So if you have a cheap robotic lawn mower, you can check, if it was already disassembled in the list below. If it's not there, it would be nice of you to check, if it contains the same mainboard as ours and add your robot to the list with some some pictures / model numbers.&lt;/p&gt; 
&lt;h3&gt;List of Compatible Mowers&lt;/h3&gt; 
&lt;p&gt;By now, some guys have disassembled their mowers and it doesn't look as good as I initially hoped. The GForce boards are basically just used by YardForce and some rebranded versions for the EU market. My exact hardware was only found in the mower I'm using (YardForce Classic 500) and in recently manufactured SA650 ECOs. The SA650 has a different chassis and we don't have a way of mounting the GPS antenna yet. Therefore at the moment, the only compatible mower is mine (the YardForce Classic 500).&lt;/p&gt; 
&lt;p&gt;If you want to have a look at the disassembled mowers, check the Google Docs &lt;a href="https://docs.google.com/spreadsheets/d/1BX0-KEs5v-VED8-RA4BLE-wRdXHtlmcKy4n9K5vJVAA"&gt;here&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;More Infos&lt;/h1&gt; 
&lt;p&gt;This page only contains the basic overview of the project. To follow my current development state, check out my &lt;a href="https://x-tech.online/"&gt;Blog&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;Patents, Local Laws, Liability&lt;/h1&gt; 
&lt;p&gt;Before building a robot based on the designs published here, please make sure that you are allowed to do so in your specific regions. There may be patents and / or laws prohibiting you of doing so.&lt;/p&gt; 
&lt;p&gt;The code/schematics/PCB files are distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.&lt;/p&gt; 
&lt;p&gt;This basically means: I'm just documenting a project of mine here for free and I don't have the time and resources to check that devices built using this information will be safe to use, legal to use or even work as intended. You will need technical know-how to use this project and I'm not liable for any damages your devices do to anyone or anything.&lt;/p&gt; 
&lt;h1&gt;License&lt;/h1&gt; 
&lt;p&gt;&lt;a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"&gt;&lt;img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png" /&gt;&lt;/a&gt;&lt;br /&gt;This work is licensed under a &lt;a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"&gt;Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Feel free to use the design in your private/educational projects, but don't try to sell the design or products based on it without getting my consent first. The idea here is to share knowledge, not to enable others to simply sell my work. Thank you for understanding.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Cinnamon/kotaemon</title>
      <link>https://github.com/Cinnamon/kotaemon</link>
      <description>&lt;p&gt;An open-source RAG-based tool for chatting with your documents.&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;h1&gt;kotaemon&lt;/h1&gt; 
 &lt;p&gt;An open-source clean &amp;amp; customizable RAG UI for chatting with your documents. Built with both end users and developers in mind.&lt;/p&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Cinnamon/kotaemon/main/docs/images/preview-graph.png" alt="Preview" /&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://trendshift.io/repositories/11607" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/11607" alt="Cinnamon%2Fkotaemon | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://huggingface.co/spaces/cin-model/kotaemon"&gt;Live Demo #1&lt;/a&gt; | &lt;a href="https://huggingface.co/spaces/cin-model/kotaemon-demo"&gt;Live Demo #2&lt;/a&gt; | &lt;a href="https://cinnamon.github.io/kotaemon/online_install/"&gt;Online Install&lt;/a&gt; | &lt;a href="https://colab.research.google.com/drive/1eTfieec_UOowNizTJA1NjawBJH9y_1nn"&gt;Colab Notebook (Local RAG)&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://cinnamon.github.io/kotaemon/"&gt;User Guide&lt;/a&gt; | &lt;a href="https://cinnamon.github.io/kotaemon/development/"&gt;Developer Guide&lt;/a&gt; | &lt;a href="https://github.com/Cinnamon/kotaemon/issues"&gt;Feedback&lt;/a&gt; | &lt;a href="mailto:kotaemon.support@cinnamon.is"&gt;Contact&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://www.python.org/downloads/release/python-31013/"&gt;&lt;img src="https://img.shields.io/badge/python-3.10+-blue.svg?sanitize=true" alt="Python 3.10+" /&gt;&lt;/a&gt; &lt;a href="https://github.com/psf/black"&gt;&lt;img src="https://img.shields.io/badge/code%20style-black-000000.svg?sanitize=true" alt="Code style: black" /&gt;&lt;/a&gt; &lt;a href="https://github.com/Cinnamon/kotaemon/pkgs/container/kotaemon" target="_blank"&gt; &lt;img src="https://img.shields.io/badge/docker_pull-kotaemon:latest-brightgreen" alt="docker pull ghcr.io/cinnamon/kotaemon:latest" /&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/github/downloads/Cinnamon/kotaemon/total.svg?label=downloads&amp;amp;color=blue" alt="download" /&gt; &lt;a href="https://huggingface.co/spaces/cin-model/kotaemon-demo"&gt;&lt;img src="https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Spaces-blue" /&gt;&lt;/a&gt; &lt;a href="https://hellogithub.com/en/repository/d3141471a0244d5798bc654982b263eb" target="_blank"&gt;&lt;img src="https://abroad.hellogithub.com/v1/widgets/recommend.svg?rid=d3141471a0244d5798bc654982b263eb&amp;amp;claim_uid=RLiD9UZ1rEHNaMf&amp;amp;theme=small" alt="Featuredï½œHelloGitHub" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;!-- start-intro --&gt; 
&lt;h2&gt;Introduction&lt;/h2&gt; 
&lt;p&gt;This project serves as a functional RAG UI for both end users who want to do QA on their documents and developers who want to build their own RAG pipeline. &lt;br /&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yml"&gt;+----------------------------------------------------------------------------+
| End users: Those who use apps built with `kotaemon`.                       |
| (You use an app like the one in the demo above)                            |
|     +----------------------------------------------------------------+     |
|     | Developers: Those who built with `kotaemon`.                   |     |
|     | (You have `import kotaemon` somewhere in your project)         |     |
|     |     +----------------------------------------------------+     |     |
|     |     | Contributors: Those who make `kotaemon` better.    |     |     |
|     |     | (You make PR to this repo)                         |     |     |
|     |     +----------------------------------------------------+     |     |
|     +----------------------------------------------------------------+     |
+----------------------------------------------------------------------------+
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;For end users&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Clean &amp;amp; Minimalistic UI&lt;/strong&gt;: A user-friendly interface for RAG-based QA.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Support for Various LLMs&lt;/strong&gt;: Compatible with LLM API providers (OpenAI, AzureOpenAI, Cohere, etc.) and local LLMs (via &lt;code&gt;ollama&lt;/code&gt; and &lt;code&gt;llama-cpp-python&lt;/code&gt;).&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Easy Installation&lt;/strong&gt;: Simple scripts to get you started quickly.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;For developers&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Framework for RAG Pipelines&lt;/strong&gt;: Tools to build your own RAG-based document QA pipeline.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Customizable UI&lt;/strong&gt;: See your RAG pipeline in action with the provided UI, built with &lt;a href="https://github.com/gradio-app/gradio"&gt;Gradio &lt;img src="https://img.shields.io/github/stars/gradio-app/gradio" /&gt;&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Gradio Theme&lt;/strong&gt;: If you use Gradio for development, check out our theme here: &lt;a href="https://github.com/lone17/kotaemon-gradio-theme"&gt;kotaemon-gradio-theme&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Key Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Host your own document QA (RAG) web-UI&lt;/strong&gt;: Support multi-user login, organize your files in private/public collections, collaborate and share your favorite chat with others.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Organize your LLM &amp;amp; Embedding models&lt;/strong&gt;: Support both local LLMs &amp;amp; popular API providers (OpenAI, Azure, Ollama, Groq).&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Hybrid RAG pipeline&lt;/strong&gt;: Sane default RAG pipeline with hybrid (full-text &amp;amp; vector) retriever and re-ranking to ensure best retrieval quality.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Multi-modal QA support&lt;/strong&gt;: Perform Question Answering on multiple documents with figures and tables support. Support multi-modal document parsing (selectable options on UI).&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Advanced citations with document preview&lt;/strong&gt;: By default the system will provide detailed citations to ensure the correctness of LLM answers. View your citations (incl. relevant score) directly in the &lt;em&gt;in-browser PDF viewer&lt;/em&gt; with highlights. Warning when retrieval pipeline return low relevant articles.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Support complex reasoning methods&lt;/strong&gt;: Use question decomposition to answer your complex/multi-hop question. Support agent-based reasoning with &lt;code&gt;ReAct&lt;/code&gt;, &lt;code&gt;ReWOO&lt;/code&gt; and other agents.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Configurable settings UI&lt;/strong&gt;: You can adjust most important aspects of retrieval &amp;amp; generation process on the UI (incl. prompts).&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Extensible&lt;/strong&gt;: Being built on Gradio, you are free to customize or add any UI elements as you like. Also, we aim to support multiple strategies for document indexing &amp;amp; retrieval. &lt;code&gt;GraphRAG&lt;/code&gt; indexing pipeline is provided as an example.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Cinnamon/kotaemon/main/docs/images/preview.png" alt="Preview" /&gt;&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;If you are not a developer and just want to use the app, please check out our easy-to-follow &lt;a href="https://cinnamon.github.io/kotaemon/"&gt;User Guide&lt;/a&gt;. Download the &lt;code&gt;.zip&lt;/code&gt; file from the &lt;a href="https://github.com/Cinnamon/kotaemon/releases/latest"&gt;latest release&lt;/a&gt; to get all the newest features and bug fixes.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;System requirements&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;a href="https://www.python.org/downloads/"&gt;Python&lt;/a&gt; &amp;gt;= 3.10&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.docker.com/"&gt;Docker&lt;/a&gt;: optional, if you &lt;a href="https://raw.githubusercontent.com/Cinnamon/kotaemon/main/#with-docker-recommended"&gt;install with Docker&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.unstructured.io/open-source/installation/full-installation#full-installation"&gt;Unstructured&lt;/a&gt; if you want to process files other than &lt;code&gt;.pdf&lt;/code&gt;, &lt;code&gt;.html&lt;/code&gt;, &lt;code&gt;.mhtml&lt;/code&gt;, and &lt;code&gt;.xlsx&lt;/code&gt; documents. Installation steps differ depending on your operating system. Please visit the link and follow the specific instructions provided there.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;With Docker (recommended)&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;We support both &lt;code&gt;lite&lt;/code&gt; &amp;amp; &lt;code&gt;full&lt;/code&gt; version of Docker images. With &lt;code&gt;full&lt;/code&gt; version, the extra packages of &lt;code&gt;unstructured&lt;/code&gt; will be installed, which can support additional file types (&lt;code&gt;.doc&lt;/code&gt;, &lt;code&gt;.docx&lt;/code&gt;, ...) but the cost is larger docker image size. For most users, the &lt;code&gt;lite&lt;/code&gt; image should work well in most cases.&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;To use the &lt;code&gt;full&lt;/code&gt; version.&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;docker run \
-e GRADIO_SERVER_NAME=0.0.0.0 \
-e GRADIO_SERVER_PORT=7860 \
-v ./ktem_app_data:/app/ktem_app_data \
-p 7860:7860 -it --rm \
ghcr.io/cinnamon/kotaemon:main-full
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;To use the &lt;code&gt;full&lt;/code&gt; version with bundled &lt;strong&gt;Ollama&lt;/strong&gt; for &lt;em&gt;local / private RAG&lt;/em&gt;.&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;# change image name to
docker run &amp;lt;...&amp;gt; ghcr.io/cinnamon/kotaemon:main-ollama
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;To use the &lt;code&gt;lite&lt;/code&gt; version.&lt;/p&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;pre&gt;&lt;code class="language-bash"&gt; # change image name to
 docker run &amp;lt;...&amp;gt; ghcr.io/cinnamon/kotaemon:main-lite
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;We currently support and test two platforms: &lt;code&gt;linux/amd64&lt;/code&gt; and &lt;code&gt;linux/arm64&lt;/code&gt; (for newer Mac). You can specify the platform by passing &lt;code&gt;--platform&lt;/code&gt; in the &lt;code&gt;docker run&lt;/code&gt; command. For example:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;# To run docker with platform linux/arm64
docker run \
-e GRADIO_SERVER_NAME=0.0.0.0 \
-e GRADIO_SERVER_PORT=7860 \
-v ./ktem_app_data:/app/ktem_app_data \
-p 7860:7860 -it --rm \
--platform linux/arm64 \
ghcr.io/cinnamon/kotaemon:main-lite
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Once everything is set up correctly, you can go to &lt;code&gt;http://localhost:7860/&lt;/code&gt; to access the WebUI.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;We use &lt;a href="https://docs.github.com/en/packages/working-with-a-github-packages-registry/working-with-the-container-registry"&gt;GHCR&lt;/a&gt; to store docker images, all images can be found &lt;a href="https://github.com/Cinnamon/kotaemon/pkgs/container/kotaemon"&gt;here.&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Without Docker&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Clone and install required packages on a fresh python environment.&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;# optional (setup env)
conda create -n kotaemon python=3.10
conda activate kotaemon

# clone this repo
git clone https://github.com/Cinnamon/kotaemon
cd kotaemon

pip install -e "libs/kotaemon[all]"
pip install -e "libs/ktem"
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Create a &lt;code&gt;.env&lt;/code&gt; file in the root of this project. Use &lt;code&gt;.env.example&lt;/code&gt; as a template&lt;/p&gt; &lt;p&gt;The &lt;code&gt;.env&lt;/code&gt; file is there to serve use cases where users want to pre-config the models before starting up the app (e.g. deploy the app on HF hub). The file will only be used to populate the db once upon the first run, it will no longer be used in consequent runs.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;(Optional) To enable in-browser &lt;code&gt;PDF_JS&lt;/code&gt; viewer, download &lt;a href="https://github.com/mozilla/pdf.js/releases/download/v4.0.379/pdfjs-4.0.379-dist.zip"&gt;PDF_JS_DIST&lt;/a&gt; then extract it to &lt;code&gt;libs/ktem/ktem/assets/prebuilt&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;img src="https://raw.githubusercontent.com/Cinnamon/kotaemon/main/docs/images/pdf-viewer-setup.png" alt="pdf-setup" width="300" /&gt; 
&lt;ol start="4"&gt; 
 &lt;li&gt; &lt;p&gt;Start the web server:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;python app.py
&lt;/code&gt;&lt;/pre&gt; 
  &lt;ul&gt; 
   &lt;li&gt;The app will be automatically launched in your browser.&lt;/li&gt; 
   &lt;li&gt;Default username and password are both &lt;code&gt;admin&lt;/code&gt;. You can set up additional users directly through the UI.&lt;/li&gt; 
  &lt;/ul&gt; &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Cinnamon/kotaemon/main/docs/images/chat-tab.png" alt="Chat tab" /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Check the &lt;code&gt;Resources&lt;/code&gt; tab and &lt;code&gt;LLMs and Embeddings&lt;/code&gt; and ensure that your &lt;code&gt;api_key&lt;/code&gt; value is set correctly from your &lt;code&gt;.env&lt;/code&gt; file. If it is not set, you can set it there.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Setup GraphRAG&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] Official MS GraphRAG indexing only works with OpenAI or Ollama API. We recommend most users to use NanoGraphRAG implementation for straightforward integration with Kotaemon.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;details&gt; 
 &lt;summary&gt;Setup Nano GRAPHRAG&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Install nano-GraphRAG: &lt;code&gt;pip install nano-graphrag&lt;/code&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;nano-graphrag&lt;/code&gt; install might introduce version conflicts, see &lt;a href="https://github.com/Cinnamon/kotaemon/issues/440"&gt;this issue&lt;/a&gt; 
   &lt;ul&gt; 
    &lt;li&gt;To quickly fix: &lt;code&gt;pip uninstall hnswlib chroma-hnswlib &amp;amp;&amp;amp; pip install chroma-hnswlib&lt;/code&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;Launch Kotaemon with &lt;code&gt;USE_NANO_GRAPHRAG=true&lt;/code&gt; environment variable.&lt;/li&gt; 
  &lt;li&gt;Set your default LLM &amp;amp; Embedding models in Resources setting and it will be recognized automatically from NanoGraphRAG.&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Setup LIGHTRAG&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Install LightRAG: &lt;code&gt;pip install git+https://github.com/HKUDS/LightRAG.git&lt;/code&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;LightRAG&lt;/code&gt; install might introduce version conflicts, see &lt;a href="https://github.com/Cinnamon/kotaemon/issues/440"&gt;this issue&lt;/a&gt; 
   &lt;ul&gt; 
    &lt;li&gt;To quickly fix: &lt;code&gt;pip uninstall hnswlib chroma-hnswlib &amp;amp;&amp;amp; pip install chroma-hnswlib&lt;/code&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;Launch Kotaemon with &lt;code&gt;USE_LIGHTRAG=true&lt;/code&gt; environment variable.&lt;/li&gt; 
  &lt;li&gt;Set your default LLM &amp;amp; Embedding models in Resources setting and it will be recognized automatically from LightRAG.&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Setup MS GRAPHRAG&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Non-Docker Installation&lt;/strong&gt;: If you are not using Docker, install GraphRAG with the following command:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;pip install "graphrag&amp;lt;=0.3.6" future
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Setting Up API KEY&lt;/strong&gt;: To use the GraphRAG retriever feature, ensure you set the &lt;code&gt;GRAPHRAG_API_KEY&lt;/code&gt; environment variable. You can do this directly in your environment or by adding it to a &lt;code&gt;.env&lt;/code&gt; file.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Using Local Models and Custom Settings&lt;/strong&gt;: If you want to use GraphRAG with local models (like &lt;code&gt;Ollama&lt;/code&gt;) or customize the default LLM and other configurations, set the &lt;code&gt;USE_CUSTOMIZED_GRAPHRAG_SETTING&lt;/code&gt; environment variable to true. Then, adjust your settings in the &lt;code&gt;settings.yaml.example&lt;/code&gt; file.&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h3&gt;Setup Local Models (for local/private RAG)&lt;/h3&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/Cinnamon/kotaemon/main/docs/local_model.md"&gt;Local model setup&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Setup multimodal document parsing (OCR, table parsing, figure extraction)&lt;/h3&gt; 
&lt;p&gt;These options are available:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://azure.microsoft.com/en-us/products/ai-services/ai-document-intelligence"&gt;Azure Document Intelligence (API)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://developer.adobe.com/document-services/docs/overview/pdf-extract-api/"&gt;Adobe PDF Extract (API)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/DS4SD/docling"&gt;Docling (local, open-source)&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;To use Docling, first install required dependencies: &lt;code&gt;pip install docling&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Select corresponding loaders in &lt;code&gt;Settings -&amp;gt; Retrieval Settings -&amp;gt; File loader&lt;/code&gt;&lt;/p&gt; 
&lt;h3&gt;Customize your application&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;By default, all application data is stored in the &lt;code&gt;./ktem_app_data&lt;/code&gt; folder. You can back up or copy this folder to transfer your installation to a new machine.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;For advanced users or specific use cases, you can customize these files:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;flowsettings.py&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;.env&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;&lt;code&gt;flowsettings.py&lt;/code&gt;&lt;/h4&gt; 
&lt;p&gt;This file contains the configuration of your application. You can use the example &lt;a href="https://raw.githubusercontent.com/Cinnamon/kotaemon/main/flowsettings.py"&gt;here&lt;/a&gt; as the starting point.&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;Notable settings&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;# setup your preferred document store (with full-text search capabilities)
KH_DOCSTORE=(Elasticsearch | LanceDB | SimpleFileDocumentStore)

# setup your preferred vectorstore (for vector-based search)
KH_VECTORSTORE=(ChromaDB | LanceDB | InMemory | Milvus | Qdrant)

# Enable / disable multimodal QA
KH_REASONINGS_USE_MULTIMODAL=True

# Setup your new reasoning pipeline or modify existing one.
KH_REASONINGS = [
    "ktem.reasoning.simple.FullQAPipeline",
    "ktem.reasoning.simple.FullDecomposeQAPipeline",
    "ktem.reasoning.react.ReactAgentPipeline",
    "ktem.reasoning.rewoo.RewooAgentPipeline",
]
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h4&gt;&lt;code&gt;.env&lt;/code&gt;&lt;/h4&gt; 
&lt;p&gt;This file provides another way to configure your models and credentials.&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;Configure model via the .env file&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;Alternatively, you can configure the models via the &lt;code&gt;.env&lt;/code&gt; file with the information needed to connect to the LLMs. This file is located in the folder of the application. If you don't see it, you can create one.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;Currently, the following providers are supported:&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt; &lt;p&gt;&lt;strong&gt;OpenAI&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;In the &lt;code&gt;.env&lt;/code&gt; file, set the &lt;code&gt;OPENAI_API_KEY&lt;/code&gt; variable with your OpenAI API key in order to enable access to OpenAI's models. There are other variables that can be modified, please feel free to edit them to fit your case. Otherwise, the default parameter should work for most people.&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;OPENAI_API_BASE=https://api.openai.com/v1
OPENAI_API_KEY=&amp;lt;your OpenAI API key here&amp;gt;
OPENAI_CHAT_MODEL=gpt-3.5-turbo
OPENAI_EMBEDDINGS_MODEL=text-embedding-ada-002
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;&lt;strong&gt;Azure OpenAI&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;For OpenAI models via Azure platform, you need to provide your Azure endpoint and API key. Your might also need to provide your developments' name for the chat model and the embedding model depending on how you set up Azure development.&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;AZURE_OPENAI_ENDPOINT=
AZURE_OPENAI_API_KEY=
OPENAI_API_VERSION=2024-02-15-preview
AZURE_OPENAI_CHAT_DEPLOYMENT=gpt-35-turbo
AZURE_OPENAI_EMBEDDINGS_DEPLOYMENT=text-embedding-ada-002
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;&lt;strong&gt;Local Models&lt;/strong&gt;&lt;/p&gt; 
     &lt;ul&gt; 
      &lt;li&gt; &lt;p&gt;Using &lt;code&gt;ollama&lt;/code&gt; OpenAI compatible server:&lt;/p&gt; 
       &lt;ul&gt; 
        &lt;li&gt; &lt;p&gt;Install &lt;a href="https://github.com/ollama/ollama"&gt;ollama&lt;/a&gt; and start the application.&lt;/p&gt; &lt;/li&gt; 
        &lt;li&gt; &lt;p&gt;Pull your model, for example:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;ollama pull llama3.1:8b
ollama pull nomic-embed-text
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
        &lt;li&gt; &lt;p&gt;Set the model names on web UI and make it as default:&lt;/p&gt; &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Cinnamon/kotaemon/main/docs/images/models.png" alt="Models" /&gt;&lt;/p&gt; &lt;/li&gt; 
       &lt;/ul&gt; &lt;/li&gt; 
      &lt;li&gt; &lt;p&gt;Using &lt;code&gt;GGUF&lt;/code&gt; with &lt;code&gt;llama-cpp-python&lt;/code&gt;&lt;/p&gt; &lt;p&gt;You can search and download a LLM to be ran locally from the &lt;a href="https://huggingface.co/models"&gt;Hugging Face Hub&lt;/a&gt;. Currently, these model formats are supported:&lt;/p&gt; 
       &lt;ul&gt; 
        &lt;li&gt; &lt;p&gt;GGUF&lt;/p&gt; &lt;p&gt;You should choose a model whose size is less than your device's memory and should leave about 2 GB. For example, if you have 16 GB of RAM in total, of which 12 GB is available, then you should choose a model that takes up at most 10 GB of RAM. Bigger models tend to give better generation but also take more processing time.&lt;/p&gt; &lt;p&gt;Here are some recommendations and their size in memory:&lt;/p&gt; &lt;/li&gt; 
        &lt;li&gt; &lt;p&gt;&lt;a href="https://huggingface.co/Qwen/Qwen1.5-1.8B-Chat-GGUF/resolve/main/qwen1_5-1_8b-chat-q8_0.gguf?download=true"&gt;Qwen1.5-1.8B-Chat-GGUF&lt;/a&gt;: around 2 GB&lt;/p&gt; &lt;p&gt;Add a new LlamaCpp model with the provided model name on the web UI.&lt;/p&gt; &lt;/li&gt; 
       &lt;/ul&gt; &lt;/li&gt; 
     &lt;/ul&gt; &lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt;
 &lt;/ul&gt;
&lt;/details&gt;   
&lt;h3&gt;Adding your own RAG pipeline&lt;/h3&gt; 
&lt;h4&gt;Custom Reasoning Pipeline&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;Check the default pipeline implementation in &lt;a href="https://raw.githubusercontent.com/Cinnamon/kotaemon/main/libs/ktem/ktem/reasoning/simple.py"&gt;here&lt;/a&gt;. You can make quick adjustment to how the default QA pipeline work.&lt;/li&gt; 
 &lt;li&gt;Add new &lt;code&gt;.py&lt;/code&gt; implementation in &lt;code&gt;libs/ktem/ktem/reasoning/&lt;/code&gt; and later include it in &lt;code&gt;flowssettings&lt;/code&gt; to enable it on the UI.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Custom Indexing Pipeline&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Check sample implementation in &lt;code&gt;libs/ktem/ktem/index/file/graph&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;(more instruction WIP).&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;!-- end-intro --&gt; 
&lt;h2&gt;Citation&lt;/h2&gt; 
&lt;p&gt;Please cite this project as&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-BibTeX"&gt;@misc{kotaemon2024,
    title = {Kotaemon - An open-source RAG-based tool for chatting with any content.},
    author = {The Kotaemon Team},
    year = {2024},
    howpublished = {\url{https://github.com/Cinnamon/kotaemon}},
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Star History&lt;/h2&gt; 
&lt;a href="https://star-history.com/#Cinnamon/kotaemon&amp;amp;Date"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://api.star-history.com/svg?repos=Cinnamon/kotaemon&amp;amp;type=Date&amp;amp;theme=dark" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://api.star-history.com/svg?repos=Cinnamon/kotaemon&amp;amp;type=Date" /&gt; 
  &lt;img alt="Star History Chart" src="https://api.star-history.com/svg?repos=Cinnamon/kotaemon&amp;amp;type=Date" /&gt; 
 &lt;/picture&gt; &lt;/a&gt; 
&lt;h2&gt;Contribution&lt;/h2&gt; 
&lt;p&gt;Since our project is actively being developed, we greatly value your feedback and contributions. Please see our &lt;a href="https://github.com/Cinnamon/kotaemon/raw/main/CONTRIBUTING.md"&gt;Contributing Guide&lt;/a&gt; to get started. Thank you to all our contributors!&lt;/p&gt; 
&lt;a href="https://github.com/Cinnamon/kotaemon/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=Cinnamon/kotaemon" /&gt; &lt;/a&gt;</description>
    </item>
    
  </channel>
</rss>