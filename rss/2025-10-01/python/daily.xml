<rss version="2.0">
  <channel>
    <title>GitHub Python Daily Trending</title>
    <description>Daily Trending of Python in GitHub</description>
    <pubDate>Tue, 30 Sep 2025 01:36:48 GMT</pubDate>
    <link>http://mshibanami.github.io/GitHubTrendingRSS</link>
    
    <item>
      <title>harry0703/MoneyPrinterTurbo</title>
      <link>https://github.com/harry0703/MoneyPrinterTurbo</link>
      <description>&lt;p&gt;利用AI大模型，一键生成高清短视频 Generate short videos with one click using AI LLM.&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;h1 align="center"&gt;MoneyPrinterTurbo 💸&lt;/h1&gt; 
 &lt;p align="center"&gt; &lt;a href="https://github.com/harry0703/MoneyPrinterTurbo/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/harry0703/MoneyPrinterTurbo.svg?style=for-the-badge" alt="Stargazers" /&gt;&lt;/a&gt; &lt;a href="https://github.com/harry0703/MoneyPrinterTurbo/issues"&gt;&lt;img src="https://img.shields.io/github/issues/harry0703/MoneyPrinterTurbo.svg?style=for-the-badge" alt="Issues" /&gt;&lt;/a&gt; &lt;a href="https://github.com/harry0703/MoneyPrinterTurbo/network/members"&gt;&lt;img src="https://img.shields.io/github/forks/harry0703/MoneyPrinterTurbo.svg?style=for-the-badge" alt="Forks" /&gt;&lt;/a&gt; &lt;a href="https://github.com/harry0703/MoneyPrinterTurbo/raw/main/LICENSE"&gt;&lt;img src="https://img.shields.io/github/license/harry0703/MoneyPrinterTurbo.svg?style=for-the-badge" alt="License" /&gt;&lt;/a&gt; &lt;/p&gt; 
 &lt;br /&gt; 
 &lt;h3&gt;简体中文 | &lt;a href="https://raw.githubusercontent.com/harry0703/MoneyPrinterTurbo/main/README-en.md"&gt;English&lt;/a&gt;&lt;/h3&gt; 
 &lt;div align="center"&gt; 
  &lt;a href="https://trendshift.io/repositories/8731" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/8731" alt="harry0703%2FMoneyPrinterTurbo | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt; 
 &lt;/div&gt; 
 &lt;br /&gt; 只需提供一个视频 
 &lt;b&gt;主题&lt;/b&gt; 或 
 &lt;b&gt;关键词&lt;/b&gt; ，就可以全自动生成视频文案、视频素材、视频字幕、视频背景音乐，然后合成一个高清的短视频。 
 &lt;br /&gt; 
 &lt;h4&gt;Web界面&lt;/h4&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/harry0703/MoneyPrinterTurbo/main/docs/webui.jpg" alt="" /&gt;&lt;/p&gt; 
 &lt;h4&gt;API界面&lt;/h4&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/harry0703/MoneyPrinterTurbo/main/docs/api.jpg" alt="" /&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;特别感谢 🙏&lt;/h2&gt; 
&lt;p&gt;由于该项目的 &lt;strong&gt;部署&lt;/strong&gt; 和 &lt;strong&gt;使用&lt;/strong&gt;，对于一些小白用户来说，还是 &lt;strong&gt;有一定的门槛&lt;/strong&gt;，在此特别感谢 &lt;strong&gt;录咖（AI智能 多媒体服务平台）&lt;/strong&gt; 网站基于该项目，提供的免费&lt;code&gt;AI视频生成器&lt;/code&gt;服务，可以不用部署，直接在线使用，非常方便。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;中文版：&lt;a href="https://reccloud.cn"&gt;https://reccloud.cn&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;英文版：&lt;a href="https://reccloud.com"&gt;https://reccloud.com&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/harry0703/MoneyPrinterTurbo/main/docs/reccloud.cn.jpg" alt="" /&gt;&lt;/p&gt; 
&lt;h2&gt;感谢赞助 🙏&lt;/h2&gt; 
&lt;p&gt;感谢佐糖 &lt;a href="https://picwish.cn"&gt;https://picwish.cn&lt;/a&gt; 对该项目的支持和赞助，使得该项目能够持续的更新和维护。&lt;/p&gt; 
&lt;p&gt;佐糖专注于&lt;strong&gt;图像处理领域&lt;/strong&gt;，提供丰富的&lt;strong&gt;图像处理工具&lt;/strong&gt;，将复杂操作极致简化，真正实现让图像处理更简单。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/harry0703/MoneyPrinterTurbo/main/docs/picwish.jpg" alt="picwish.jpg" /&gt;&lt;/p&gt; 
&lt;h2&gt;功能特性 🎯&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; 完整的 &lt;strong&gt;MVC架构&lt;/strong&gt;，代码 &lt;strong&gt;结构清晰&lt;/strong&gt;，易于维护，支持 &lt;code&gt;API&lt;/code&gt; 和 &lt;code&gt;Web界面&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; 支持视频文案 &lt;strong&gt;AI自动生成&lt;/strong&gt;，也可以&lt;strong&gt;自定义文案&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; 支持多种 &lt;strong&gt;高清视频&lt;/strong&gt; 尺寸 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; 竖屏 9:16，&lt;code&gt;1080x1920&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; 横屏 16:9，&lt;code&gt;1920x1080&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; 支持 &lt;strong&gt;批量视频生成&lt;/strong&gt;，可以一次生成多个视频，然后选择一个最满意的&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; 支持 &lt;strong&gt;视频片段时长&lt;/strong&gt; 设置，方便调节素材切换频率&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; 支持 &lt;strong&gt;中文&lt;/strong&gt; 和 &lt;strong&gt;英文&lt;/strong&gt; 视频文案&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; 支持 &lt;strong&gt;多种语音&lt;/strong&gt; 合成，可 &lt;strong&gt;实时试听&lt;/strong&gt; 效果&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; 支持 &lt;strong&gt;字幕生成&lt;/strong&gt;，可以调整 &lt;code&gt;字体&lt;/code&gt;、&lt;code&gt;位置&lt;/code&gt;、&lt;code&gt;颜色&lt;/code&gt;、&lt;code&gt;大小&lt;/code&gt;，同时支持&lt;code&gt;字幕描边&lt;/code&gt;设置&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; 支持 &lt;strong&gt;背景音乐&lt;/strong&gt;，随机或者指定音乐文件，可设置&lt;code&gt;背景音乐音量&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; 视频素材来源 &lt;strong&gt;高清&lt;/strong&gt;，而且 &lt;strong&gt;无版权&lt;/strong&gt;，也可以使用自己的 &lt;strong&gt;本地素材&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; 支持 &lt;strong&gt;OpenAI&lt;/strong&gt;、&lt;strong&gt;Moonshot&lt;/strong&gt;、&lt;strong&gt;Azure&lt;/strong&gt;、&lt;strong&gt;gpt4free&lt;/strong&gt;、&lt;strong&gt;one-api&lt;/strong&gt;、&lt;strong&gt;通义千问&lt;/strong&gt;、&lt;strong&gt;Google Gemini&lt;/strong&gt;、&lt;strong&gt;Ollama&lt;/strong&gt;、&lt;strong&gt;DeepSeek&lt;/strong&gt;、 &lt;strong&gt;文心一言&lt;/strong&gt;, &lt;strong&gt;Pollinations&lt;/strong&gt; 等多种模型接入 
  &lt;ul&gt; 
   &lt;li&gt;中国用户建议使用 &lt;strong&gt;DeepSeek&lt;/strong&gt; 或 &lt;strong&gt;Moonshot&lt;/strong&gt; 作为大模型提供商（国内可直接访问，不需要VPN。注册就送额度，基本够用）&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;后期计划 📅&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; GPT-SoVITS 配音支持&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; 优化语音合成，利用大模型，使其合成的声音，更加自然，情绪更加丰富&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; 增加视频转场效果，使其看起来更加的流畅&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; 增加更多视频素材来源，优化视频素材和文案的匹配度&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; 增加视频长度选项：短、中、长&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; 支持更多的语音合成服务商，比如 OpenAI TTS&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; 自动上传到YouTube平台&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;视频演示 📺&lt;/h2&gt; 
&lt;h3&gt;竖屏 9:16&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="center"&gt;
    &lt;g-emoji class="g-emoji" alias="arrow_forward"&gt;
     ▶️
    &lt;/g-emoji&gt; 《如何增加生活的乐趣》&lt;/th&gt; 
   &lt;th align="center"&gt;
    &lt;g-emoji class="g-emoji" alias="arrow_forward"&gt;
     ▶️
    &lt;/g-emoji&gt; 《金钱的作用》&lt;br /&gt;更真实的合成声音&lt;/th&gt; 
   &lt;th align="center"&gt;
    &lt;g-emoji class="g-emoji" alias="arrow_forward"&gt;
     ▶️
    &lt;/g-emoji&gt; 《生命的意义是什么》&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;
    &lt;video src="https://github.com/harry0703/MoneyPrinterTurbo/assets/4928832/a84d33d5-27a2-4aba-8fd0-9fb2bd91c6a6"&gt;&lt;/video&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;
    &lt;video src="https://github.com/harry0703/MoneyPrinterTurbo/assets/4928832/af2f3b0b-002e-49fe-b161-18ba91c055e8"&gt;&lt;/video&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;
    &lt;video src="https://github.com/harry0703/MoneyPrinterTurbo/assets/4928832/112c9564-d52b-4472-99ad-970b75f66476"&gt;&lt;/video&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;横屏 16:9&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="center"&gt;
    &lt;g-emoji class="g-emoji" alias="arrow_forward"&gt;
     ▶️
    &lt;/g-emoji&gt;《生命的意义是什么》&lt;/th&gt; 
   &lt;th align="center"&gt;
    &lt;g-emoji class="g-emoji" alias="arrow_forward"&gt;
     ▶️
    &lt;/g-emoji&gt;《为什么要运动》&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;
    &lt;video src="https://github.com/harry0703/MoneyPrinterTurbo/assets/4928832/346ebb15-c55f-47a9-a653-114f08bb8073"&gt;&lt;/video&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;
    &lt;video src="https://github.com/harry0703/MoneyPrinterTurbo/assets/4928832/271f2fae-8283-44a0-8aa0-0ed8f9a6fa87"&gt;&lt;/video&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;配置要求 📦&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;建议最低 CPU &lt;strong&gt;4核&lt;/strong&gt; 或以上，内存 &lt;strong&gt;4G&lt;/strong&gt; 或以上，显卡非必须&lt;/li&gt; 
 &lt;li&gt;Windows 10 或 MacOS 11.0 以上系统&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;快速开始 🚀&lt;/h2&gt; 
&lt;h3&gt;在 Google Colab 中运行&lt;/h3&gt; 
&lt;p&gt;免去本地环境配置，点击直接在 Google Colab 中快速体验 MoneyPrinterTurbo&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://colab.research.google.com/github/harry0703/MoneyPrinterTurbo/blob/main/docs/MoneyPrinterTurbo.ipynb"&gt;&lt;img src="https://colab.research.google.com/assets/colab-badge.svg?sanitize=true" alt="Open in Colab" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Windows一键启动包&lt;/h3&gt; 
&lt;p&gt;下载一键启动包，解压直接使用（路径不要有 &lt;strong&gt;中文&lt;/strong&gt;、&lt;strong&gt;特殊字符&lt;/strong&gt;、&lt;strong&gt;空格&lt;/strong&gt;）&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;百度网盘（v1.2.6）: &lt;a href="https://pan.baidu.com/s/1wg0UaIyXpO3SqIpaq790SQ?pwd=sbqx"&gt;https://pan.baidu.com/s/1wg0UaIyXpO3SqIpaq790SQ?pwd=sbqx&lt;/a&gt; 提取码: sbqx&lt;/li&gt; 
 &lt;li&gt;Google Drive (v1.2.6): &lt;a href="https://drive.google.com/file/d/1HsbzfT7XunkrCrHw5ncUjFX8XX4zAuUh/view?usp=sharing"&gt;https://drive.google.com/file/d/1HsbzfT7XunkrCrHw5ncUjFX8XX4zAuUh/view?usp=sharing&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;下载后，建议先&lt;strong&gt;双击执行&lt;/strong&gt; &lt;code&gt;update.bat&lt;/code&gt; 更新到&lt;strong&gt;最新代码&lt;/strong&gt;，然后双击 &lt;code&gt;start.bat&lt;/code&gt; 启动&lt;/p&gt; 
&lt;p&gt;启动后，会自动打开浏览器（如果打开是空白，建议换成 &lt;strong&gt;Chrome&lt;/strong&gt; 或者 &lt;strong&gt;Edge&lt;/strong&gt; 打开）&lt;/p&gt; 
&lt;h2&gt;安装部署 📥&lt;/h2&gt; 
&lt;h3&gt;前提条件&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;尽量不要使用 &lt;strong&gt;中文路径&lt;/strong&gt;，避免出现一些无法预料的问题&lt;/li&gt; 
 &lt;li&gt;请确保你的 &lt;strong&gt;网络&lt;/strong&gt; 是正常的，VPN需要打开&lt;code&gt;全局流量&lt;/code&gt;模式&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;① 克隆代码&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;git clone https://github.com/harry0703/MoneyPrinterTurbo.git
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;② 修改配置文件（可选，建议启动后也可以在 WebUI 里面配置）&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;将 &lt;code&gt;config.example.toml&lt;/code&gt; 文件复制一份，命名为 &lt;code&gt;config.toml&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;按照 &lt;code&gt;config.toml&lt;/code&gt; 文件中的说明，配置好 &lt;code&gt;pexels_api_keys&lt;/code&gt; 和 &lt;code&gt;llm_provider&lt;/code&gt;，并根据 llm_provider 对应的服务商，配置相关的 API Key&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Docker部署 🐳&lt;/h3&gt; 
&lt;h4&gt;① 启动Docker&lt;/h4&gt; 
&lt;p&gt;如果未安装 Docker，请先安装 &lt;a href="https://www.docker.com/products/docker-desktop/"&gt;https://www.docker.com/products/docker-desktop/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;如果是Windows系统，请参考微软的文档：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;a href="https://learn.microsoft.com/zh-cn/windows/wsl/install"&gt;https://learn.microsoft.com/zh-cn/windows/wsl/install&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://learn.microsoft.com/zh-cn/windows/wsl/tutorials/wsl-containers"&gt;https://learn.microsoft.com/zh-cn/windows/wsl/tutorials/wsl-containers&lt;/a&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;cd MoneyPrinterTurbo
docker-compose up
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;注意：最新版的docker安装时会自动以插件的形式安装docker compose，启动命令调整为docker compose up&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;② 访问Web界面&lt;/h4&gt; 
&lt;p&gt;打开浏览器，访问 &lt;a href="http://0.0.0.0:8501"&gt;http://0.0.0.0:8501&lt;/a&gt;&lt;/p&gt; 
&lt;h4&gt;③ 访问API文档&lt;/h4&gt; 
&lt;p&gt;打开浏览器，访问 &lt;a href="http://0.0.0.0:8080/docs"&gt;http://0.0.0.0:8080/docs&lt;/a&gt; 或者 &lt;a href="http://0.0.0.0:8080/redoc"&gt;http://0.0.0.0:8080/redoc&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;手动部署 📦&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;视频教程&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;完整的使用演示：&lt;a href="https://v.douyin.com/iFhnwsKY/"&gt;https://v.douyin.com/iFhnwsKY/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;如何在Windows上部署：&lt;a href="https://v.douyin.com/iFyjoW3M"&gt;https://v.douyin.com/iFyjoW3M&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;① 创建虚拟环境&lt;/h4&gt; 
&lt;p&gt;建议使用 &lt;a href="https://conda.io/projects/conda/en/latest/user-guide/install/index.html"&gt;conda&lt;/a&gt; 创建 python 虚拟环境&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;git clone https://github.com/harry0703/MoneyPrinterTurbo.git
cd MoneyPrinterTurbo
conda create -n MoneyPrinterTurbo python=3.11
conda activate MoneyPrinterTurbo
pip install -r requirements.txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;② 安装好 ImageMagick&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Windows:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;下载 &lt;a href="https://imagemagick.org/script/download.php"&gt;https://imagemagick.org/script/download.php&lt;/a&gt; 选择Windows版本，切记一定要选择 &lt;strong&gt;静态库&lt;/strong&gt; 版本，比如 ImageMagick-7.1.1-32-Q16-x64-&lt;strong&gt;static&lt;/strong&gt;.exe&lt;/li&gt; 
   &lt;li&gt;安装下载好的 ImageMagick，&lt;strong&gt;注意不要修改安装路径&lt;/strong&gt;&lt;/li&gt; 
   &lt;li&gt;修改 &lt;code&gt;配置文件 config.toml&lt;/code&gt; 中的 &lt;code&gt;imagemagick_path&lt;/code&gt; 为你的 &lt;strong&gt;实际安装路径&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;MacOS:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;brew install imagemagick
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Ubuntu&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;sudo apt-get install imagemagick
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;CentOS&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;sudo yum install ImageMagick
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;③ 启动Web界面 🌐&lt;/h4&gt; 
&lt;p&gt;注意需要到 MoneyPrinterTurbo 项目 &lt;code&gt;根目录&lt;/code&gt; 下执行以下命令&lt;/p&gt; 
&lt;h6&gt;Windows&lt;/h6&gt; 
&lt;pre&gt;&lt;code class="language-bat"&gt;webui.bat
&lt;/code&gt;&lt;/pre&gt; 
&lt;h6&gt;MacOS or Linux&lt;/h6&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;sh webui.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;启动后，会自动打开浏览器（如果打开是空白，建议换成 &lt;strong&gt;Chrome&lt;/strong&gt; 或者 &lt;strong&gt;Edge&lt;/strong&gt; 打开）&lt;/p&gt; 
&lt;h4&gt;④ 启动API服务 🚀&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;python main.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;启动后，可以查看 &lt;code&gt;API文档&lt;/code&gt; &lt;a href="http://127.0.0.1:8080/docs"&gt;http://127.0.0.1:8080/docs&lt;/a&gt; 或者 &lt;a href="http://127.0.0.1:8080/redoc"&gt;http://127.0.0.1:8080/redoc&lt;/a&gt; 直接在线调试接口，快速体验。&lt;/p&gt; 
&lt;h2&gt;语音合成 🗣&lt;/h2&gt; 
&lt;p&gt;所有支持的声音列表，可以查看：&lt;a href="https://raw.githubusercontent.com/harry0703/MoneyPrinterTurbo/main/docs/voice-list.txt"&gt;声音列表&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;2024-04-16 v1.1.2 新增了9种Azure的语音合成声音，需要配置API KEY，该声音合成的更加真实。&lt;/p&gt; 
&lt;h2&gt;字幕生成 📜&lt;/h2&gt; 
&lt;p&gt;当前支持2种字幕生成方式：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;edge&lt;/strong&gt;: 生成&lt;code&gt;速度快&lt;/code&gt;，性能更好，对电脑配置没有要求，但是质量可能不稳定&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;whisper&lt;/strong&gt;: 生成&lt;code&gt;速度慢&lt;/code&gt;，性能较差，对电脑配置有一定要求，但是&lt;code&gt;质量更可靠&lt;/code&gt;。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;可以修改 &lt;code&gt;config.toml&lt;/code&gt; 配置文件中的 &lt;code&gt;subtitle_provider&lt;/code&gt; 进行切换&lt;/p&gt; 
&lt;p&gt;建议使用 &lt;code&gt;edge&lt;/code&gt; 模式，如果生成的字幕质量不好，再切换到 &lt;code&gt;whisper&lt;/code&gt; 模式&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;注意：&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ol&gt; 
 &lt;li&gt;whisper 模式下需要到 HuggingFace 下载一个模型文件，大约 3GB 左右，请确保网络通畅&lt;/li&gt; 
 &lt;li&gt;如果留空，表示不生成字幕。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;由于国内无法访问 HuggingFace，可以使用以下方法下载 &lt;code&gt;whisper-large-v3&lt;/code&gt; 的模型文件&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;下载地址：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;百度网盘: &lt;a href="https://pan.baidu.com/s/11h3Q6tsDtjQKTjUu3sc5cA?pwd=xjs9"&gt;https://pan.baidu.com/s/11h3Q6tsDtjQKTjUu3sc5cA?pwd=xjs9&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;夸克网盘：&lt;a href="https://pan.quark.cn/s/3ee3d991d64b"&gt;https://pan.quark.cn/s/3ee3d991d64b&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;模型下载后解压，整个目录放到 &lt;code&gt;.\MoneyPrinterTurbo\models&lt;/code&gt; 里面， 最终的文件路径应该是这样: &lt;code&gt;.\MoneyPrinterTurbo\models\whisper-large-v3&lt;/code&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;MoneyPrinterTurbo  
  ├─models
  │   └─whisper-large-v3
  │          config.json
  │          model.bin
  │          preprocessor_config.json
  │          tokenizer.json
  │          vocabulary.json
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;背景音乐 🎵&lt;/h2&gt; 
&lt;p&gt;用于视频的背景音乐，位于项目的 &lt;code&gt;resource/songs&lt;/code&gt; 目录下。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;当前项目里面放了一些默认的音乐，来自于 YouTube 视频，如有侵权，请删除。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;字幕字体 🅰&lt;/h2&gt; 
&lt;p&gt;用于视频字幕的渲染，位于项目的 &lt;code&gt;resource/fonts&lt;/code&gt; 目录下，你也可以放进去自己的字体。&lt;/p&gt; 
&lt;h2&gt;常见问题 🤔&lt;/h2&gt; 
&lt;h3&gt;❓RuntimeError: No ffmpeg exe could be found&lt;/h3&gt; 
&lt;p&gt;通常情况下，ffmpeg 会被自动下载，并且会被自动检测到。 但是如果你的环境有问题，无法自动下载，可能会遇到如下错误：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;RuntimeError: No ffmpeg exe could be found.
Install ffmpeg on your system, or set the IMAGEIO_FFMPEG_EXE environment variable.
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;此时你可以从 &lt;a href="https://www.gyan.dev/ffmpeg/builds/"&gt;https://www.gyan.dev/ffmpeg/builds/&lt;/a&gt; 下载ffmpeg，解压后，设置 &lt;code&gt;ffmpeg_path&lt;/code&gt; 为你的实际安装路径即可。&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;[app]
# 请根据你的实际路径设置，注意 Windows 路径分隔符为 \\
ffmpeg_path = "C:\\Users\\harry\\Downloads\\ffmpeg.exe"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;❓ImageMagick的安全策略阻止了与临时文件@/tmp/tmpur5hyyto.txt相关的操作&lt;/h3&gt; 
&lt;p&gt;可以在ImageMagick的配置文件policy.xml中找到这些策略。 这个文件通常位于 /etc/ImageMagick-&lt;code&gt;X&lt;/code&gt;/ 或 ImageMagick 安装目录的类似位置。 修改包含&lt;code&gt;pattern="@"&lt;/code&gt;的条目，将&lt;code&gt;rights="none"&lt;/code&gt;更改为&lt;code&gt;rights="read|write"&lt;/code&gt;以允许对文件的读写操作。&lt;/p&gt; 
&lt;h3&gt;❓OSError: [Errno 24] Too many open files&lt;/h3&gt; 
&lt;p&gt;这个问题是由于系统打开文件数限制导致的，可以通过修改系统的文件打开数限制来解决。&lt;/p&gt; 
&lt;p&gt;查看当前限制&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;ulimit -n
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;如果过低，可以调高一些，比如&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;ulimit -n 10240
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;❓Whisper 模型下载失败，出现如下错误&lt;/h3&gt; 
&lt;p&gt;LocalEntryNotfoundEror: Cannot find an appropriate cached snapshotfolderfor the specified revision on the local disk and outgoing trafic has been disabled. To enablerepo look-ups and downloads online, pass 'local files only=False' as input.&lt;/p&gt; 
&lt;p&gt;或者&lt;/p&gt; 
&lt;p&gt;An error occured while synchronizing the model Systran/faster-whisper-large-v3 from the Hugging Face Hub: An error happened while trying to locate the files on the Hub and we cannot find the appropriate snapshot folder for the specified revision on the local disk. Please check your internet connection and try again. Trying to load the model directly from the local cache, if it exists.&lt;/p&gt; 
&lt;p&gt;解决方法：&lt;a href="https://raw.githubusercontent.com/harry0703/MoneyPrinterTurbo/main/#%E5%AD%97%E5%B9%95%E7%94%9F%E6%88%90-"&gt;点击查看如何从网盘手动下载模型&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;反馈建议 📢&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;可以提交 &lt;a href="https://github.com/harry0703/MoneyPrinterTurbo/issues"&gt;issue&lt;/a&gt; 或者 &lt;a href="https://github.com/harry0703/MoneyPrinterTurbo/pulls"&gt;pull request&lt;/a&gt;。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;许可证 📝&lt;/h2&gt; 
&lt;p&gt;点击查看 &lt;a href="https://raw.githubusercontent.com/harry0703/MoneyPrinterTurbo/main/LICENSE"&gt;&lt;code&gt;LICENSE&lt;/code&gt;&lt;/a&gt; 文件&lt;/p&gt; 
&lt;h2&gt;Star History&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://star-history.com/#harry0703/MoneyPrinterTurbo&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=harry0703/MoneyPrinterTurbo&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>onyx-dot-app/onyx</title>
      <link>https://github.com/onyx-dot-app/onyx</link>
      <description>&lt;p&gt;Open Source AI Platform - AI Chat with advanced features that works with every LLM&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a name="readme-top"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2 align="center"&gt; &lt;a href="https://www.onyx.app/"&gt; &lt;img width="50%" src="https://github.com/onyx-dot-app/onyx/raw/logo/OnyxLogoCropped.jpg?raw=true)" /&gt;&lt;/a&gt; &lt;/h2&gt; 
&lt;p align="center"&gt;Open Source AI Platform&lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://discord.gg/TDJ59cGV2X" target="_blank"&gt; &lt;img src="https://img.shields.io/badge/discord-join-blue.svg?logo=discord&amp;amp;logoColor=white" alt="Discord" /&gt; &lt;/a&gt; &lt;a href="https://docs.onyx.app/" target="_blank"&gt; &lt;img src="https://img.shields.io/badge/docs-view-blue" alt="Documentation" /&gt; &lt;/a&gt; &lt;a href="https://docs.onyx.app/" target="_blank"&gt; &lt;img src="https://img.shields.io/website?url=https://www.onyx.app&amp;amp;up_message=visit&amp;amp;up_color=blue" alt="Documentation" /&gt; &lt;/a&gt; &lt;a href="https://github.com/onyx-dot-app/onyx/raw/main/LICENSE" target="_blank"&gt; &lt;img src="https://img.shields.io/static/v1?label=license&amp;amp;message=MIT&amp;amp;color=blue" alt="License" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://www.onyx.app/"&gt;Onyx&lt;/a&gt;&lt;/strong&gt; is a feature-rich, self-hostable Chat UI that works with any LLM. It is easy to deploy and can run in a completely airgapped environment.&lt;/p&gt; 
&lt;p&gt;Onyx comes loaded with advanced features like Agents, Web Search, RAG, MCP, Deep Research, Connectors to 40+ knowledge sources, and more.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] Run Onyx with one command (or see deployment section below):&lt;/p&gt; 
 &lt;pre&gt;&lt;code&gt;curl -fsSL https://raw.githubusercontent.com/onyx-dot-app/onyx/main/deployment/docker_compose/install.sh &amp;gt; install.sh &amp;amp;&amp;amp; chmod +x install.sh &amp;amp;&amp;amp; ./install.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;/blockquote&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;img src="https://github.com/onyx-dot-app/onyx/releases/download/v0.21.1/OnyxChatSilentDemo.gif" alt="Onyx Chat Silent Demo" /&gt;&lt;/p&gt; 
&lt;h2&gt;⭐ Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;🤖 Custom Agents:&lt;/strong&gt; Build AI Agents with unique instructions, knowledge and actions.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;🌍 Web Search:&lt;/strong&gt; Browse the web with Google PSE, Exa, and Serper as well as an in-house scraper or Firecrawl.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;🔍 RAG:&lt;/strong&gt; Best in class hybrid-search + knowledge graph for uploaded files and ingested documents from connectors.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;🔄 Connectors:&lt;/strong&gt; Pull knowledge, metadata, and access information from over 40 applications.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;🔬 Deep Research:&lt;/strong&gt; Get in depth answers with an agentic multi-step search.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;▶️ Actions &amp;amp; MCP:&lt;/strong&gt; Give AI Agents the ability to interact with external systems.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;💻 Code Interpreter:&lt;/strong&gt; Execute code to analyze data, render graphs and create files.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;🎨 Image Generation:&lt;/strong&gt; Generate images based on user prompts.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;👥 Collaboration:&lt;/strong&gt; Chat sharing, feedback gathering, user management, usage analytics, and more.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Onyx works with all LLMs (like OpenAI, Anthropic, Gemini, etc.) and self-hosted LLMs (like Ollama, vLLM, etc.)&lt;/p&gt; 
&lt;p&gt;To learn more about the features, check out our &lt;a href="https://docs.onyx.app/welcome"&gt;documentation&lt;/a&gt;!&lt;/p&gt; 
&lt;h2&gt;🚀 Deployment&lt;/h2&gt; 
&lt;p&gt;Onyx supports deployments in Docker, Kubernetes, Terraform, along with guides for major cloud providers.&lt;/p&gt; 
&lt;p&gt;See guides below:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.onyx.app/deployment/local/docker"&gt;Docker&lt;/a&gt; or &lt;a href="https://docs.onyx.app/deployment/getting_started/quickstart"&gt;Quickstart&lt;/a&gt; (best for most users)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.onyx.app/deployment/local/kubernetes"&gt;Kubernetes&lt;/a&gt; (best for large teams)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.onyx.app/deployment/local/terraform"&gt;Terraform&lt;/a&gt; (best for teams already using Terraform)&lt;/li&gt; 
 &lt;li&gt;Cloud specific guides (best if specifically using &lt;a href="https://docs.onyx.app/deployment/cloud/aws/eks"&gt;AWS EKS&lt;/a&gt;, &lt;a href="https://docs.onyx.app/deployment/cloud/azure"&gt;Azure VMs&lt;/a&gt;, etc.)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP]&lt;br /&gt; &lt;strong&gt;To try Onyx for free without deploying, check out &lt;a href="https://cloud.onyx.app/signup"&gt;Onyx Cloud&lt;/a&gt;&lt;/strong&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;🔍 Other Notable Benefits&lt;/h2&gt; 
&lt;p&gt;Onyx is built for teams of all sizes, from individual users to the largest global enterprises.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Enterprise Search&lt;/strong&gt;: far more than simple RAG, Onyx has custom indexing and retrieval that remains performant and accurate for scales of up to tens of millions of documents.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Security&lt;/strong&gt;: SSO (OIDC/SAML/OAuth2), RBAC, encryption of credentials, etc.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Management UI&lt;/strong&gt;: different user roles such as basic, curator, and admin.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Document Permissioning&lt;/strong&gt;: mirrors user access from external apps for RAG use cases.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;🚧 Roadmap&lt;/h2&gt; 
&lt;p&gt;To see ongoing and upcoming projects, check out our &lt;a href="https://github.com/orgs/onyx-dot-app/projects/2"&gt;roadmap&lt;/a&gt;!&lt;/p&gt; 
&lt;h2&gt;📚 Licensing&lt;/h2&gt; 
&lt;p&gt;There are two editions of Onyx:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Onyx Community Edition (CE) is available freely under the MIT license.&lt;/li&gt; 
 &lt;li&gt;Onyx Enterprise Edition (EE) includes extra features that are primarily useful for larger organizations. For feature details, check out &lt;a href="https://www.onyx.app/pricing"&gt;our website&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;👪 Community&lt;/h2&gt; 
&lt;p&gt;Join our open source community on &lt;strong&gt;&lt;a href="https://discord.gg/TDJ59cGV2X"&gt;Discord&lt;/a&gt;&lt;/strong&gt;!&lt;/p&gt; 
&lt;h2&gt;💡 Contributing&lt;/h2&gt; 
&lt;p&gt;Looking to contribute? Please check out the &lt;a href="https://raw.githubusercontent.com/onyx-dot-app/onyx/main/CONTRIBUTING.md"&gt;Contribution Guide&lt;/a&gt; for more details.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Byaidu/PDFMathTranslate</title>
      <link>https://github.com/Byaidu/PDFMathTranslate</link>
      <description>&lt;p&gt;PDF scientific paper translation with preserved formats - 基于 AI 完整保留排版的 PDF 文档全文双语翻译，支持 Google/DeepL/Ollama/OpenAI 等服务，提供 CLI/GUI/MCP/Docker/Zotero&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;p&gt;English | &lt;a href="https://raw.githubusercontent.com/Byaidu/PDFMathTranslate/main/docs/README_zh-CN.md"&gt;简体中文&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/Byaidu/PDFMathTranslate/main/docs/README_zh-TW.md"&gt;繁體中文&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/Byaidu/PDFMathTranslate/main/docs/README_ja-JP.md"&gt;日本語&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/Byaidu/PDFMathTranslate/main/docs/README_ko-KR.md"&gt;한국어&lt;/a&gt;&lt;/p&gt; 
 &lt;img src="https://raw.githubusercontent.com/Byaidu/PDFMathTranslate/main/docs/images/banner.png" width="320px" alt="PDF2ZH" /&gt; 
 &lt;h2 id="title"&gt;PDFMathTranslate&lt;/h2&gt; 
 &lt;p&gt; 
  &lt;!-- PyPI --&gt; &lt;a href="https://pypi.org/project/pdf2zh/"&gt; &lt;img src="https://img.shields.io/pypi/v/pdf2zh" /&gt;&lt;/a&gt; &lt;a href="https://pepy.tech/projects/pdf2zh"&gt; &lt;img src="https://static.pepy.tech/badge/pdf2zh" /&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/r/byaidu/pdf2zh"&gt; &lt;img src="https://img.shields.io/docker/pulls/byaidu/pdf2zh" /&gt;&lt;/a&gt; &lt;a href="https://hellogithub.com/repository/8ec2cfd3ef744762bf531232fa32bc47" target="_blank"&gt;&lt;img src="https://api.hellogithub.com/v1/widgets/recommend.svg?rid=8ec2cfd3ef744762bf531232fa32bc47&amp;amp;claim_uid=JQ0yfeBNjaTuqDU&amp;amp;theme=small" alt="Featured｜HelloGitHub" /&gt;&lt;/a&gt; &lt;a href="https://gitcode.com/Byaidu/PDFMathTranslate/overview"&gt; &lt;img src="https://gitcode.com/Byaidu/PDFMathTranslate/star/badge.svg?sanitize=true" /&gt;&lt;/a&gt; &lt;a href="https://huggingface.co/spaces/reycn/PDFMathTranslate-Docker"&gt; &lt;img src="https://img.shields.io/badge/%F0%9F%A4%97-Online%20Demo-FF9E0D" /&gt;&lt;/a&gt; &lt;a href="https://www.modelscope.cn/studios/AI-ModelScope/PDFMathTranslate"&gt; &lt;img src="https://img.shields.io/badge/ModelScope-Demo-blue" /&gt;&lt;/a&gt; &lt;a href="https://github.com/Byaidu/PDFMathTranslate/pulls"&gt; &lt;img src="https://img.shields.io/badge/contributions-welcome-green" /&gt;&lt;/a&gt; &lt;a href="https://t.me/+Z9_SgnxmsmA5NzBl"&gt; &lt;img src="https://img.shields.io/badge/Telegram-2CA5E0?style=flat-squeare&amp;amp;logo=telegram&amp;amp;logoColor=white" /&gt;&lt;/a&gt; 
  &lt;!-- License --&gt; &lt;a href="https://raw.githubusercontent.com/Byaidu/PDFMathTranslate/main/LICENSE"&gt; &lt;img src="https://img.shields.io/github/license/Byaidu/PDFMathTranslate" /&gt;&lt;/a&gt; &lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://trendshift.io/repositories/12424" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/12424" alt="Byaidu%2FPDFMathTranslate | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2 id="updates"&gt;1. What does this do?&lt;/h2&gt; 
&lt;p&gt;Scientific PDF document translation preserving layouts.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;📊 Preserve formulas, charts, table of contents, and annotations.&lt;/li&gt; 
 &lt;li&gt;🌐 Support &lt;a href="https://raw.githubusercontent.com/Byaidu/PDFMathTranslate/main/#usage"&gt;multiple languages&lt;/a&gt;, and diverse &lt;a href="https://raw.githubusercontent.com/Byaidu/PDFMathTranslate/main/#usage"&gt;translation services&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;🤖 Provides &lt;a href="https://raw.githubusercontent.com/Byaidu/PDFMathTranslate/main/#usage"&gt;commandline tool&lt;/a&gt;, &lt;a href="https://raw.githubusercontent.com/Byaidu/PDFMathTranslate/main/#install"&gt;interactive user interface&lt;/a&gt;, and &lt;a href="https://raw.githubusercontent.com/Byaidu/PDFMathTranslate/main/#install"&gt;Docker&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/Byaidu/PDFMathTranslate/main/docs/images/preview.gif" width="80%" /&gt; 
&lt;/div&gt; 
&lt;h2 id="updates"&gt;2. Recent Updates&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;[May 9, 2025] pdf2zh 2.0 Preview Version &lt;a href="https://github.com/Byaidu/PDFMathTranslate/issues/586"&gt;#586&lt;/a&gt;: The Windows ZIP file and Docker image are now available.&lt;/p&gt; 
  &lt;blockquote&gt; 
   &lt;p&gt;[!NOTE]&lt;/p&gt; 
   &lt;p&gt;2.0 Moved to a new repository under the organization: &lt;a href="https://github.com/PDFMathTranslate/PDFMathTranslate-next"&gt;PDFMathTranslate/PDFMathTranslate-next&lt;/a&gt;&lt;/p&gt; 
   &lt;p&gt;Version 2.0 official release has been published.&lt;/p&gt; 
  &lt;/blockquote&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;[Mar. 3, 2025] Experimental support for the new backend &lt;a href="https://github.com/funstory-ai/BabelDOC"&gt;BabelDOC&lt;/a&gt; WebUI added as an experimental option (by &lt;a href="https://github.com/awwaawwa"&gt;@awwaawwa&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;[Feb. 22 2025] Better release CI and well-packaged windows-amd64 exe (by &lt;a href="https://github.com/awwaawwa"&gt;@awwaawwa&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2 id="use-section"&gt;3. Use 🌟&lt;/h2&gt; 
&lt;h3 id="demo"&gt;3.1 Online Service 🌟&lt;/h3&gt; 
&lt;p&gt;You can try our application out using either of the following demos:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://pdf2zh.com/"&gt;Public free service&lt;/a&gt; online without installation &lt;em&gt;(recommended)&lt;/em&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://app.immersivetranslate.com/babel-doc/"&gt;Immersive Translate - BabelDOC&lt;/a&gt; 1000 free pages per month. &lt;em&gt;(recommended)&lt;/em&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://huggingface.co/spaces/reycn/PDFMathTranslate-Docker"&gt;Demo hosted on HuggingFace&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.modelscope.cn/studios/AI-ModelScope/PDFMathTranslate"&gt;Demo hosted on ModelScope&lt;/a&gt; without installation.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Note that the computing resources of the demo are limited, so please avoid abusing them.&lt;/p&gt; 
&lt;h3 id="install"&gt;3.2 Local Installation&lt;/h3&gt; 
&lt;p&gt;For different use cases, we provide distinct methods to use our program:&lt;/p&gt; 
&lt;details open&gt; 
 &lt;summary&gt;3.2.1 Python: Install using uv&lt;/summary&gt; 
 &lt;ol&gt; 
  &lt;li&gt; &lt;p&gt;Python installed (3.10 &amp;lt;= version &amp;lt;= 3.12)&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;Install our package:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;pip install uv
uv tool install --python 3.12 pdf2zh
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;Execute translation, files generated in &lt;a href="https://chatgpt.com/share/6745ed36-9acc-800e-8a90-59204bd13444"&gt;current working directory&lt;/a&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;pdf2zh document.pdf
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;/ol&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;3.2.2 Python: Install using pip&lt;/summary&gt; 
 &lt;ol&gt; 
  &lt;li&gt; &lt;p&gt;Python installed (3.10 &amp;lt;= version &amp;lt;= 3.12)&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;Install our package:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;pip install pdf2zh
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;Execute translation, files generated in &lt;a href="https://chatgpt.com/share/6745ed36-9acc-800e-8a90-59204bd13444"&gt;current working directory&lt;/a&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;pdf2zh document.pdf
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;/ol&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;3.3.3 Python: Graphic user interface&lt;/summary&gt; 
 &lt;ol&gt; 
  &lt;li&gt; &lt;p&gt;Python installed (3.10 &amp;lt;= version &amp;lt;= 3.12)&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;Install our package:&lt;/p&gt; &lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;pip install pdf2zh
&lt;/code&gt;&lt;/pre&gt; 
 &lt;ol start="3"&gt; 
  &lt;li&gt; &lt;p&gt;Start using in browser:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;pdf2zh -i
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;If your browser has not been started automatically, goto&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;http://localhost:7860/
&lt;/code&gt;&lt;/pre&gt; &lt;img src="https://raw.githubusercontent.com/Byaidu/PDFMathTranslate/main/docs/images/gui.gif" width="500" /&gt; &lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/Byaidu/PDFMathTranslate/main/docs/README_GUI.md"&gt;documentation for GUI&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;3.2.4 Application: On Windows&lt;/summary&gt; 
 &lt;ol&gt; 
  &lt;li&gt; &lt;p&gt;Download pdf2zh-version-win64.zip from &lt;a href="https://github.com/Byaidu/PDFMathTranslate/releases"&gt;release page&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;Unzip and double-click &lt;code&gt;pdf2zh.exe&lt;/code&gt; to run.&lt;/p&gt; &lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;[!TIP]&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;If you're using Windows and cannot open the file after downloading, please install &lt;a href="https://aka.ms/vs/17/release/vc_redist.x64.exe"&gt;vc_redist.x64.exe&lt;/a&gt; and try again.&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/blockquote&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;3.2.5 Reference manager: Zotero Plugin&lt;/summary&gt; 
 &lt;p&gt;See &lt;a href="https://github.com/guaguastandup/zotero-pdf2zh"&gt;Zotero PDF2zh&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;3.2.6 Docker: Containerized Deployment&lt;/summary&gt; 
 &lt;ol&gt; 
  &lt;li&gt; &lt;p&gt;Pull and run:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;docker pull byaidu/pdf2zh
docker run -d -p 7860:7860 byaidu/pdf2zh
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;Open in browser:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;http://localhost:7860/
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;p&gt;For docker deployment on cloud service:&lt;/p&gt; 
 &lt;div&gt; 
  &lt;a href="https://www.heroku.com/deploy?template=https://github.com/Byaidu/PDFMathTranslate"&gt; &lt;img src="https://www.herokucdn.com/deploy/button.svg?sanitize=true" alt="Deploy" height="26" /&gt;&lt;/a&gt; 
  &lt;a href="https://render.com/deploy"&gt; &lt;img src="https://render.com/images/deploy-to-render-button.svg?sanitize=true" alt="Deploy to Koyeb" height="26" /&gt;&lt;/a&gt; 
  &lt;a href="https://zeabur.com/templates/5FQIGX?referralCode=reycn"&gt; &lt;img src="https://zeabur.com/button.svg?sanitize=true" alt="Deploy on Zeabur" height="26" /&gt;&lt;/a&gt; 
  &lt;a href="https://template.sealos.io/deploy?templateName=pdf2zh"&gt; &lt;img src="https://sealos.io/Deploy-on-Sealos.svg?sanitize=true" alt="Deploy on Sealos" height="26" /&gt;&lt;/a&gt; 
  &lt;a href="https://app.koyeb.com/deploy?type=git&amp;amp;builder=buildpack&amp;amp;repository=github.com/Byaidu/PDFMathTranslate&amp;amp;branch=main&amp;amp;name=pdf-math-translate"&gt; &lt;img src="https://www.koyeb.com/static/images/deploy/button.svg?sanitize=true" alt="Deploy to Koyeb" height="26" /&gt;&lt;/a&gt; 
 &lt;/div&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;[!TIP]&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;If you cannot access Docker Hub, please try the image on &lt;a href="https://github.com/Byaidu/PDFMathTranslate/pkgs/container/pdfmathtranslate"&gt;GitHub Container Registry&lt;/a&gt;.&lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;pre&gt;&lt;code class="language-bash"&gt;docker pull ghcr.io/byaidu/pdfmathtranslate
docker run -d -p 7860:7860 ghcr.io/byaidu/pdfmathtranslate
&lt;/code&gt;&lt;/pre&gt; 
 &lt;/blockquote&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;3.2.* Solutions for network issues in installation&lt;/summary&gt; 
 &lt;p&gt;Users in specific regions may encounter network difficulties when loading the AI model. The current program relies on the AI model (&lt;code&gt;wybxc/DocLayout-YOLO-DocStructBench-onnx&lt;/code&gt;), and some users are unable to download it due to these network issues.&lt;/p&gt; 
 &lt;p&gt;To address issues with downloading this model, use the following environment variable as a workaround:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;set HF_ENDPOINT=https://hf-mirror.com
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;For PowerShell user:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;$env:HF_ENDPOINT = https://hf-mirror.com
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;If the solution does not work to you / you encountered other issues, please refer to &lt;a href="https://github.com/Byaidu/PDFMathTranslate/wiki#-faq--%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98"&gt;Frequently Asked Questions&lt;/a&gt;.&lt;/p&gt; 
&lt;/details&gt; 
&lt;h2 id="usage"&gt;4. Technical Details&lt;/h2&gt; 
&lt;h3&gt;4.1 Advanced options&lt;/h3&gt; 
&lt;p&gt;Execute the translation command in the command line to generate the translated document &lt;code&gt;example-mono.pdf&lt;/code&gt; and the bilingual document &lt;code&gt;example-dual.pdf&lt;/code&gt; in the current working directory. Use Google as the default translation service. More support translation services can find &lt;a href="https://github.com/Byaidu/PDFMathTranslate/raw/main/docs/ADVANCED.md#services"&gt;HERE&lt;/a&gt;.&lt;/p&gt; 
&lt;img src="https://raw.githubusercontent.com/Byaidu/PDFMathTranslate/main/docs/images/cmd.explained.png" width="580px" alt="cmd" /&gt; 
&lt;p&gt;In the following table, we list all advanced options for reference:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Option&lt;/th&gt; 
   &lt;th&gt;Function&lt;/th&gt; 
   &lt;th&gt;Example&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;files&lt;/td&gt; 
   &lt;td&gt;Local files&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;pdf2zh ~/local.pdf&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;links&lt;/td&gt; 
   &lt;td&gt;Online files&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;pdf2zh http://arxiv.org/paper.pdf&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;-i&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/Byaidu/PDFMathTranslate/main/#gui"&gt;Enter GUI&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;pdf2zh -i&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;-p&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/Byaidu/PDFMathTranslate/raw/main/docs/ADVANCED.md#partial"&gt;Partial document translation&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;pdf2zh example.pdf -p 1&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;-li&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/Byaidu/PDFMathTranslate/raw/main/docs/ADVANCED.md#languages"&gt;Source language&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;pdf2zh example.pdf -li en&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;-lo&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/Byaidu/PDFMathTranslate/raw/main/docs/ADVANCED.md#languages"&gt;Target language&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;pdf2zh example.pdf -lo zh&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;-s&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/Byaidu/PDFMathTranslate/raw/main/docs/ADVANCED.md#services"&gt;Translation service&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;pdf2zh example.pdf -s deepl&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;-t&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/Byaidu/PDFMathTranslate/raw/main/docs/ADVANCED.md#threads"&gt;Multi-threads&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;pdf2zh example.pdf -t 1&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;-o&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Output dir&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;pdf2zh example.pdf -o output&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;-f&lt;/code&gt;, &lt;code&gt;-c&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/Byaidu/PDFMathTranslate/raw/main/docs/ADVANCED.md#exceptions"&gt;Exceptions&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;pdf2zh example.pdf -f "(MS.*)"&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;-cp&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Compatibility Mode&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;pdf2zh example.pdf --compatible&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--skip-subset-fonts&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/Byaidu/PDFMathTranslate/raw/main/docs/ADVANCED.md#font-subset"&gt;Skip font subset&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;pdf2zh example.pdf --skip-subset-fonts&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--ignore-cache&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/Byaidu/PDFMathTranslate/raw/main/docs/ADVANCED.md#cache"&gt;Ignore translate cache&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;pdf2zh example.pdf --ignore-cache&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--share&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Public link&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;pdf2zh -i --share&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--authorized&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/Byaidu/PDFMathTranslate/raw/main/docs/ADVANCED.md#auth"&gt;Authorization&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;pdf2zh -i --authorized users.txt [auth.html]&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--prompt&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/Byaidu/PDFMathTranslate/raw/main/docs/ADVANCED.md#prompt"&gt;Custom Prompt&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;pdf2zh --prompt [prompt.txt]&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--onnx&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;[Use Custom DocLayout-YOLO ONNX model]&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;pdf2zh --onnx [onnx/model/path]&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--serverport&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;[Use Custom WebUI port]&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;pdf2zh --serverport 7860&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--dir&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;[batch translate]&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;pdf2zh --dir /path/to/translate/&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--config&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/Byaidu/PDFMathTranslate/raw/main/docs/ADVANCED.md#cofig"&gt;configuration file&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;pdf2zh --config /path/to/config/config.json&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--serverport&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;[custom gradio server port]&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;pdf2zh --serverport 7860&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--babeldoc&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Use Experimental backend &lt;a href="https://funstory-ai.github.io/BabelDOC/"&gt;BabelDOC&lt;/a&gt; to translate&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;pdf2zh --babeldoc&lt;/code&gt; -s openai example.pdf&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--mcp&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Enable MCP STDIO mode&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;pdf2zh --mcp&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--sse&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Enable MCP SSE mode&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;pdf2zh --mcp --sse&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;For detailed explanations, please refer to our document about &lt;a href="https://raw.githubusercontent.com/Byaidu/PDFMathTranslate/main/docs/ADVANCED.md"&gt;Advanced Usage&lt;/a&gt; for a full list of each option.&lt;/p&gt; 
&lt;h3 id="downstream"&gt;4.2 Downstream Development&lt;/h3&gt; For downstream applications, please refer to our document about [API Details](./docs/APIS.md) for further information about: 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Byaidu/PDFMathTranslate/main/docs/APIS.md#api-python"&gt;Python API&lt;/a&gt;, how to use the program in other Python programs&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Byaidu/PDFMathTranslate/main/docs/APIS.md#api-http"&gt;HTTP API&lt;/a&gt;, how to communicate with a server with the program installed&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3 id="downstream"&gt;4.3 Differences between two major forks&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/Byaidu/PDFMathTranslate"&gt;Byaidu/PDFMathTranslate&lt;/a&gt;: The present and the original project for stable release.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/PDFMathTranslate/PDFMathTranslate-next"&gt;PDFMathTranslate/PDFMathTranslate-next&lt;/a&gt;: A fork with web-ui and additional features. This fork handles a large number of marginal cases, improves PDF compatibility, and optimizes cross-column and cross-page semantic consistency, dynamic scaling, and dynamic scaling consistency, among many other translation quality improvements. However, this fork is intended solely for development and does not address compatibility issues and is not designed for community-contributions.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2 id="information"&gt;5. Project Information&lt;/h2&gt; 
&lt;h3 id="citation"&gt;5.1 Citation&lt;/h3&gt; 
&lt;p&gt;This work has been accepted by the &lt;em&gt;Proceedings of the 2025 Conference on Empirical Methods in Natural Language Processing: System Demonstrations&lt;/em&gt; (EMNLP 2025).&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Pre-print version: &lt;a href="https://arxiv.org/abs/2507.03009"&gt;PDFMathTranslate: Scientific Document Translation Preserving Layouts&lt;/a&gt;&lt;/p&gt; &lt;pre&gt;&lt;code&gt;@online{ouyang2025pdfmathtranslate,
  title = {{{PDFMathTranslate}}: {{Scientific Document Translation Preserving Layouts}}},
  shorttitle = {{{PDFMathTranslate}}},
  author = {Ouyang, Rongxin and Chu, Chang and Xin, Zhikuang and Ma, Xiangyao},
  date = {2025-07-08},
  eprint = {2507.03009},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2507.03009},
  url = {http://arxiv.org/abs/2507.03009},
  urldate = {2025-08-27},
  pubstate = {prepublished}
}
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;The citation for the EMNLP proceedings will be provided upon release.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;!-- ```
@inproceedings{zheng-etal-2024-openresearcher,
    title = "{O}pen{R}esearcher: Unleashing {AI} for Accelerated Scientific Research",
    author = "Ouyang, Rongxin  and
      Chu, Chang and
      Xin, Zhikuang and
      Ma, Xiangyao",
    editor = "TBD",
    booktitle = "Proceedings of the 2025 Conference on Empirical Methods in Natural Language Processing: System Demonstrations",
    month = nov,
    year = "2025",
    address = "Miami, Florida, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/TBD/",
    doi = "TBD",
    pages = "TBD",
    abstract = "Language barriers in scientific documents hinder the diffusion and development of science and technologies. However, prior efforts in translating such documents largely overlooked the information in layouts. To bridge the gap, we introduce PDFMathTranslate, the world’s first open-source software for translating scientific documents while preserving layouts. Leveraging the most recent advances in large language models and precise layout detection, we contribute to the community with key improvements in precision, flexibility, and efficiency. The work is open-sourced at https://github.com/byaidu/pdfmathtranslate with more than 222k downloads."
}
``` --&gt; 
&lt;h3 id="acknowledgement"&gt;5.2 Acknowledgement&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://immersivetranslate.com"&gt;Immersive Translation&lt;/a&gt; sponsors monthly Pro membership redemption codes for active contributors to this project, see details at: &lt;a href="https://github.com/funstory-ai/BabelDOC/raw/main/docs/CONTRIBUTOR_REWARD.md"&gt;CONTRIBUTOR_REWARD.md&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;New backend: &lt;a href="https://github.com/funstory-ai/BabelDOC"&gt;BabelDOC&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Document merging: &lt;a href="https://github.com/pymupdf/PyMuPDF"&gt;PyMuPDF&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Document parsing: &lt;a href="https://github.com/pdfminer/pdfminer.six"&gt;Pdfminer.six&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Document extraction: &lt;a href="https://github.com/opendatalab/MinerU"&gt;MinerU&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Document Preview: &lt;a href="https://github.com/freddyaboulton/gradio-pdf"&gt;Gradio PDF&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Multi-threaded translation: &lt;a href="https://github.com/SUSYUSTC/MathTranslate"&gt;MathTranslate&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Layout parsing: &lt;a href="https://github.com/opendatalab/DocLayout-YOLO"&gt;DocLayout-YOLO&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Document standard: &lt;a href="https://zxyle.github.io/PDF-Explained/"&gt;PDF Explained&lt;/a&gt;, &lt;a href="https://pdfa.org/resource/pdf-cheat-sheets/"&gt;PDF Cheat Sheets&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Multilingual Font: &lt;a href="https://github.com/satbyy/go-noto-universal"&gt;Go Noto Universal&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3 id="contrib"&gt;5.3 Contributors&lt;/h3&gt; 
&lt;a href="https://github.com/Byaidu/PDFMathTranslate/graphs/contributors"&gt; &lt;img src="https://opencollective.com/PDFMathTranslate/contributors.svg?width=890&amp;amp;button=false" /&gt; &lt;/a&gt; 
&lt;p&gt;&lt;img src="https://repobeats.axiom.co/api/embed/dfa7583da5332a11468d686fbd29b92320a6a869.svg?sanitize=true" alt="Alt" title="Repobeats analytics image" /&gt;&lt;/p&gt; 
&lt;p&gt;For details on how to contribute, please consult the &lt;a href="https://github.com/Byaidu/PDFMathTranslate/wiki/Contribution-Guide---%E8%B4%A1%E7%8C%AE%E6%8C%87%E5%8D%97"&gt;Contribution Guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h3 id="star_hist"&gt;5.4 Star History&lt;/h3&gt; 
&lt;a href="https://star-history.com/#Byaidu/PDFMathTranslate&amp;amp;Date"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://api.star-history.com/svg?repos=Byaidu/PDFMathTranslate&amp;amp;type=Date&amp;amp;theme=dark" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://api.star-history.com/svg?repos=Byaidu/PDFMathTranslate&amp;amp;type=Date" /&gt; 
  &lt;img alt="Star History Chart" src="https://api.star-history.com/svg?repos=Byaidu/PDFMathTranslate&amp;amp;type=Date" /&gt; 
 &lt;/picture&gt; &lt;/a&gt;</description>
    </item>
    
    <item>
      <title>Shubhamsaboo/awesome-llm-apps</title>
      <link>https://github.com/Shubhamsaboo/awesome-llm-apps</link>
      <description>&lt;p&gt;Collection of awesome LLM apps with AI Agents and RAG using OpenAI, Anthropic, Gemini and opensource models.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;a href="http://www.theunwindai.com"&gt; &lt;img src="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/docs/banner/unwind_black.png" width="900px" alt="Unwind AI" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://www.linkedin.com/in/shubhamsaboo/"&gt; &lt;img src="https://img.shields.io/badge/-Follow%20Shubham%20Saboo-blue?logo=linkedin&amp;amp;style=flat-square" alt="LinkedIn" /&gt; &lt;/a&gt; &lt;a href="https://twitter.com/Saboo_Shubham_"&gt; &lt;img src="https://img.shields.io/twitter/follow/Shubham_Saboo" alt="Twitter" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; 
 &lt;!-- Keep these links. Translations will automatically update with the README. --&gt; &lt;a href="https://www.readme-i18n.com/Shubhamsaboo/awesome-llm-apps?lang=de"&gt;Deutsch&lt;/a&gt; | &lt;a href="https://www.readme-i18n.com/Shubhamsaboo/awesome-llm-apps?lang=es"&gt;Español&lt;/a&gt; | &lt;a href="https://www.readme-i18n.com/Shubhamsaboo/awesome-llm-apps?lang=fr"&gt;français&lt;/a&gt; | &lt;a href="https://www.readme-i18n.com/Shubhamsaboo/awesome-llm-apps?lang=ja"&gt;日本語&lt;/a&gt; | &lt;a href="https://www.readme-i18n.com/Shubhamsaboo/awesome-llm-apps?lang=ko"&gt;한국어&lt;/a&gt; | &lt;a href="https://www.readme-i18n.com/Shubhamsaboo/awesome-llm-apps?lang=pt"&gt;Português&lt;/a&gt; | &lt;a href="https://www.readme-i18n.com/Shubhamsaboo/awesome-llm-apps?lang=ru"&gt;Русский&lt;/a&gt; | &lt;a href="https://www.readme-i18n.com/Shubhamsaboo/awesome-llm-apps?lang=zh"&gt;中文&lt;/a&gt; &lt;/p&gt; 
&lt;hr /&gt; 
&lt;h1&gt;🌟 Awesome LLM Apps&lt;/h1&gt; 
&lt;p&gt;A curated collection of &lt;strong&gt;Awesome LLM apps built with RAG, AI Agents, Multi-agent Teams, MCP, Voice Agents, and more.&lt;/strong&gt; This repository features LLM apps that use models from &lt;img src="https://cdn.simpleicons.org/openai" alt="openai logo" width="25" height="15" /&gt;&lt;strong&gt;OpenAI&lt;/strong&gt; , &lt;img src="https://cdn.simpleicons.org/anthropic" alt="anthropic logo" width="25" height="15" /&gt;&lt;strong&gt;Anthropic&lt;/strong&gt;, &lt;img src="https://cdn.simpleicons.org/googlegemini" alt="google logo" width="25" height="18" /&gt;&lt;strong&gt;Google&lt;/strong&gt;, &lt;img src="https://cdn.simpleicons.org/x" alt="X logo" width="25" height="15" /&gt;&lt;strong&gt;xAI&lt;/strong&gt; and open-source models like &lt;img src="https://cdn.simpleicons.org/alibabacloud" alt="alibaba logo" width="25" height="15" /&gt;&lt;strong&gt;Qwen&lt;/strong&gt; or &lt;img src="https://cdn.simpleicons.org/meta" alt="meta logo" width="25" height="15" /&gt;&lt;strong&gt;Llama&lt;/strong&gt; that you can run locally on your computer.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://trendshift.io/repositories/9876" target="_blank"&gt; &lt;img src="https://trendshift.io/api/badge/repositories/9876" alt="Shubhamsaboo%2Fawesome-llm-apps | Trendshift" style="width: 250px; height: 55px;" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;h2&gt;🤔 Why Awesome LLM Apps?&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;💡 Discover practical and creative ways LLMs can be applied across different domains, from code repositories to email inboxes and more.&lt;/li&gt; 
 &lt;li&gt;🔥 Explore apps that combine LLMs from OpenAI, Anthropic, Gemini, and open-source alternatives with AI Agents, Agent Teams, MCP &amp;amp; RAG.&lt;/li&gt; 
 &lt;li&gt;🎓 Learn from well-documented projects and contribute to the growing open-source ecosystem of LLM-powered applications.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;🙏 Thanks to our sponsors&lt;/h2&gt; 
&lt;table align="center" cellpadding="16" cellspacing="12"&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td align="center"&gt; &lt;a href="https://getunblocked.com/unblocked-mcp/?utm_source=oss&amp;amp;utm_medium=sponsorship&amp;amp;utm_campaign=awesome-llm-apps" target="_blank" rel="noopener" title="Unblocked"&gt; &lt;img src="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/docs/banner/sponsors/unblocked.png" alt="Unblocked" width="6000" /&gt; &lt;/a&gt; &lt;br /&gt; &lt;a href="https://getunblocked.com/unblocked-mcp/?utm_source=oss&amp;amp;utm_medium=sponsorship&amp;amp;utm_campaign=awesome-llm-apps" target="_blank" rel="noopener" style="text-decoration: none; color: #333; font-weight: bold; font-size: 18px;"&gt; Unblocked &lt;/a&gt; &lt;/td&gt; 
   &lt;td align="center"&gt; &lt;a href="https://sponsorunwindai.com/" title="Sponsor Awesome LLM Apps Repo"&gt; &lt;img src="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/docs/banner/sponsor_awesome_llm_apps.png" alt="Sponsor Awesome LLM Apps Repo" width="6000" /&gt; &lt;/a&gt; &lt;br /&gt; &lt;a href="https://sponsorunwindai.com/" style="text-decoration: none; color: #333; font-weight: bold; font-size: 18px;"&gt; Become a Sponsor &lt;/a&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h2&gt;📂 Featured AI Projects&lt;/h2&gt; 
&lt;h3&gt;AI Agents&lt;/h3&gt; 
&lt;h3&gt;🌱 Starter AI Agents&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/starter_ai_agents/ai_blog_to_podcast_agent/"&gt;🎙️ AI Blog to Podcast Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/starter_ai_agents/ai_breakup_recovery_agent/"&gt;❤️‍🩹 AI Breakup Recovery Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/starter_ai_agents/ai_data_analysis_agent/"&gt;📊 AI Data Analysis Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/starter_ai_agents/ai_medical_imaging_agent/"&gt;🩻 AI Medical Imaging Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/starter_ai_agents/ai_meme_generator_agent_browseruse/"&gt;😂 AI Meme Generator Agent (Browser)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/starter_ai_agents/ai_music_generator_agent/"&gt;🎵 AI Music Generator Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/starter_ai_agents/ai_travel_agent/"&gt;🛫 AI Travel Agent (Local &amp;amp; Cloud)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/starter_ai_agents/gemini_multimodal_agent_demo/"&gt;✨ Gemini Multimodal Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/starter_ai_agents/local_news_agent_openai_swarm/"&gt;🌐 Local News Agent (OpenAI Swarm)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/starter_ai_agents/mixture_of_agents/"&gt;🔄 Mixture of Agents&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/starter_ai_agents/xai_finance_agent/"&gt;📊 xAI Finance Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/starter_ai_agents/opeani_research_agent/"&gt;🔍 OpenAI Research Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/starter_ai_agents/web_scrapping_ai_agent/"&gt;🕸️ Web Scrapping AI Agent (Local &amp;amp; Cloud)&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;🚀 Advanced AI Agents&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/single_agent_apps/ai_deep_research_agent/"&gt;🔍 AI Deep Research Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/single_agent_apps/ai_consultant_agent"&gt;🤝 AI Consultant Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/single_agent_apps/ai_system_architect_r1/"&gt;🏗️ AI System Architect Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/single_agent_apps/ai_lead_generation_agent/"&gt;🎯 AI Lead Generation Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/multi_agent_apps/ai_financial_coach_agent/"&gt;💰 AI Financial Coach Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/single_agent_apps/ai_movie_production_agent/"&gt;🎬 AI Movie Production Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/single_agent_apps/ai_investment_agent/"&gt;📈 AI Investment Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/single_agent_apps/ai_health_fitness_agent/"&gt;🏋️‍♂️ AI Health &amp;amp; Fitness Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/multi_agent_apps/product_launch_intelligence_agent"&gt;🚀 AI Product Launch Intelligence Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/single_agent_apps/ai_journalist_agent/"&gt;🗞️ AI Journalist Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/multi_agent_apps/ai_mental_wellbeing_agent/"&gt;🧠 AI Mental Wellbeing Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/single_agent_apps/ai_meeting_agent/"&gt;📑 AI Meeting Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/multi_agent_apps/ai_Self-Evolving_agent/"&gt;🧬 AI Self-Evolving Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/multi_agent_apps/ai_news_and_podcast_agents/"&gt;🎧 AI Social Media News and Podcast Agent&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;🎮 Autonomous Game Playing Agents&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/autonomous_game_playing_agent_apps/ai_3dpygame_r1/"&gt;🎮 AI 3D Pygame Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/autonomous_game_playing_agent_apps/ai_chess_agent/"&gt;♜ AI Chess Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/autonomous_game_playing_agent_apps/ai_tic_tac_toe_agent/"&gt;🎲 AI Tic-Tac-Toe Agent&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;🤝 Multi-agent Teams&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/multi_agent_apps/agent_teams/ai_competitor_intelligence_agent_team/"&gt;🧲 AI Competitor Intelligence Agent Team&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/multi_agent_apps/agent_teams/ai_finance_agent_team/"&gt;💲 AI Finance Agent Team&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/multi_agent_apps/agent_teams/ai_game_design_agent_team/"&gt;🎨 AI Game Design Agent Team&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/multi_agent_apps/agent_teams/ai_legal_agent_team/"&gt;👨‍⚖️ AI Legal Agent Team (Cloud &amp;amp; Local)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/multi_agent_apps/agent_teams/ai_recruitment_agent_team/"&gt;💼 AI Recruitment Agent Team&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/multi_agent_apps/agent_teams/ai_real_estate_agent_team"&gt;🏠 AI Real Estate Agent Team&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/multi_agent_apps/agent_teams/ai_services_agency/"&gt;👨‍💼 AI Services Agency (CrewAI)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/multi_agent_apps/agent_teams/ai_teaching_agent_team/"&gt;👨‍🏫 AI Teaching Agent Team&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/multi_agent_apps/agent_teams/multimodal_coding_agent_team/"&gt;💻 Multimodal Coding Agent Team&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/multi_agent_apps/agent_teams/multimodal_design_agent_team/"&gt;✨ Multimodal Design Agent Team&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/multi_agent_apps/agent_teams/ai_travel_planner_agent_team/"&gt;🌏 AI Travel Planner Agent Team&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;🗣️ Voice AI Agents&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/voice_ai_agents/ai_audio_tour_agent/"&gt;🗣️ AI Audio Tour Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/voice_ai_agents/customer_support_voice_agent/"&gt;📞 Customer Support Voice Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/voice_ai_agents/voice_rag_openaisdk/"&gt;🔊 Voice RAG Agent (OpenAI SDK)&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;img src="https://cdn.simpleicons.org/modelcontextprotocol" alt="mcp logo" width="25" height="20" /&gt; MCP AI Agents&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/mcp_ai_agents/browser_mcp_agent/"&gt;♾️ Browser MCP Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/mcp_ai_agents/github_mcp_agent/"&gt;🐙 GitHub MCP Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/mcp_ai_agents/notion_mcp_agent"&gt;📑 Notion MCP Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/mcp_ai_agents/ai_travel_planner_mcp_agent_team"&gt;🌍 AI Travel Planner MCP Agent&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;📀 RAG (Retrieval Augmented Generation)&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/rag_tutorials/agentic_rag_embedding_gemma"&gt;🔥 Agentic RAG with Embedding Gemma&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/rag_tutorials/agentic_rag_with_reasoning/"&gt;🧐 Agentic RAG with Reasoning&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/rag_tutorials/ai_blog_search/"&gt;📰 AI Blog Search (RAG)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/rag_tutorials/autonomous_rag/"&gt;🔍 Autonomous RAG&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/rag_tutorials/contextualai_rag_agent/"&gt;🔄 Contextual AI RAG Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/rag_tutorials/corrective_rag/"&gt;🔄 Corrective RAG (CRAG)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/rag_tutorials/deepseek_local_rag_agent/"&gt;🐋 Deepseek Local RAG Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/rag_tutorials/gemini_agentic_rag/"&gt;🤔 Gemini Agentic RAG&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/rag_tutorials/hybrid_search_rag/"&gt;👀 Hybrid Search RAG (Cloud)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/rag_tutorials/llama3.1_local_rag/"&gt;🔄 Llama 3.1 Local RAG&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/rag_tutorials/local_hybrid_search_rag/"&gt;🖥️ Local Hybrid Search RAG&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/rag_tutorials/local_rag_agent/"&gt;🦙 Local RAG Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/rag_tutorials/rag-as-a-service/"&gt;🧩 RAG-as-a-Service&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/rag_tutorials/rag_agent_cohere/"&gt;✨ RAG Agent with Cohere&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/rag_tutorials/rag_chain/"&gt;⛓️ Basic RAG Chain&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/rag_tutorials/rag_database_routing/"&gt;📠 RAG with Database Routing&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/rag_tutorials/vision_rag/"&gt;🖼️ Vision RAG&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;💾 LLM Apps with Memory Tutorials&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_llm_apps/llm_apps_with_memory_tutorials/ai_arxiv_agent_memory/"&gt;💾 AI ArXiv Agent with Memory&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_llm_apps/llm_apps_with_memory_tutorials/ai_travel_agent_memory/"&gt;🛩️ AI Travel Agent with Memory&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_llm_apps/llm_apps_with_memory_tutorials/llama3_stateful_chat/"&gt;💬 Llama3 Stateful Chat&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_llm_apps/llm_apps_with_memory_tutorials/llm_app_personalized_memory/"&gt;📝 LLM App with Personalized Memory&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_llm_apps/llm_apps_with_memory_tutorials/local_chatgpt_with_memory/"&gt;🗄️ Local ChatGPT Clone with Memory&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_llm_apps/llm_apps_with_memory_tutorials/multi_llm_memory/"&gt;🧠 Multi-LLM Application with Shared Memory&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;💬 Chat with X Tutorials&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_llm_apps/chat_with_X_tutorials/chat_with_github/"&gt;💬 Chat with GitHub (GPT &amp;amp; Llama3)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_llm_apps/chat_with_X_tutorials/chat_with_gmail/"&gt;📨 Chat with Gmail&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_llm_apps/chat_with_X_tutorials/chat_with_pdf/"&gt;📄 Chat with PDF (GPT &amp;amp; Llama3)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_llm_apps/chat_with_X_tutorials/chat_with_research_papers/"&gt;📚 Chat with Research Papers (ArXiv) (GPT &amp;amp; Llama3)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_llm_apps/chat_with_X_tutorials/chat_with_substack/"&gt;📝 Chat with Substack&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_llm_apps/chat_with_X_tutorials/chat_with_youtube_videos/"&gt;📽️ Chat with YouTube Videos&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;🔧 LLM Fine-tuning Tutorials&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;img src="https://cdn.simpleicons.org/google" alt="google logo" width="20" height="15" /&gt; &lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_llm_apps/llm_finetuning_tutorials/gemma3_finetuning/"&gt;Gemma 3 Fine-tuning&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;img src="https://cdn.simpleicons.org/meta" alt="meta logo" width="25" height="15" /&gt; &lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_llm_apps/llm_finetuning_tutorials/llama3.2_finetuning/"&gt;Llama 3.2 Fine-tuning&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;🧑‍🏫 AI Agent Framework Crash Course&lt;/h3&gt; 
&lt;p&gt;&lt;img src="https://cdn.simpleicons.org/google" alt="google logo" width="25" height="15" /&gt; &lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/ai_agent_framework_crash_course/google_adk_crash_course/"&gt;Google ADK Crash Course&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Starter agent; model‑agnostic (OpenAI, Claude)&lt;/li&gt; 
 &lt;li&gt;Structured outputs (Pydantic)&lt;/li&gt; 
 &lt;li&gt;Tools: built‑in, function, third‑party, MCP tools&lt;/li&gt; 
 &lt;li&gt;Memory; callbacks; Plugins&lt;/li&gt; 
 &lt;li&gt;Simple multi‑agent; Multi‑agent patterns&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://cdn.simpleicons.org/openai" alt="openai logo" width="25" height="15" /&gt; &lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/ai_agent_framework_crash_course/openai_sdk_crash_course/"&gt;OpenAI Agents SDK Crash Course&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Starter agent; function calling; structured outputs&lt;/li&gt; 
 &lt;li&gt;Tools: built‑in, function, third‑party integrations&lt;/li&gt; 
 &lt;li&gt;Memory; callbacks; evaluation&lt;/li&gt; 
 &lt;li&gt;Multi‑agent patterns; agent handoffs&lt;/li&gt; 
 &lt;li&gt;Swarm orchestration; routing logic&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;🚀 Getting Started&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Clone the repository&lt;/strong&gt;&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/Shubhamsaboo/awesome-llm-apps.git 
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Navigate to the desired project directory&lt;/strong&gt;&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;cd awesome-llm-apps/starter_ai_agents/ai_travel_agent
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Install the required dependencies&lt;/strong&gt;&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;pip install -r requirements.txt
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Follow the project-specific instructions&lt;/strong&gt; in each project's &lt;code&gt;README.md&lt;/code&gt; file to set up and run the app.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;&lt;img src="https://cdn.simpleicons.org/github" alt="github logo" width="25" height="20" /&gt; Thank You, Community, for the Support! 🙏&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://star-history.com/#Shubhamsaboo/awesome-llm-apps&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=Shubhamsaboo/awesome-llm-apps&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;🌟 &lt;strong&gt;Don’t miss out on future updates! Star the repo now and be the first to know about new and exciting LLM apps with RAG and AI Agents.&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>roboflow/supervision</title>
      <link>https://github.com/roboflow/supervision</link>
      <description>&lt;p&gt;We write your reusable computer vision tools. 💜&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;p&gt; &lt;a align="center" href="" target="https://supervision.roboflow.com"&gt; &lt;img width="100%" src="https://media.roboflow.com/open-source/supervision/rf-supervision-banner.png?updatedAt=1678995927529" /&gt; &lt;/a&gt; &lt;/p&gt; 
 &lt;br /&gt; 
 &lt;p&gt;&lt;a href="https://github.com/roboflow/notebooks"&gt;notebooks&lt;/a&gt; | &lt;a href="https://github.com/roboflow/inference"&gt;inference&lt;/a&gt; | &lt;a href="https://github.com/autodistill/autodistill"&gt;autodistill&lt;/a&gt; | &lt;a href="https://github.com/roboflow/multimodal-maestro"&gt;maestro&lt;/a&gt;&lt;/p&gt; 
 &lt;br /&gt; 
 &lt;p&gt;&lt;a href="https://badge.fury.io/py/supervision"&gt;&lt;img src="https://badge.fury.io/py/supervision.svg?sanitize=true" alt="version" /&gt;&lt;/a&gt; &lt;a href="https://pypistats.org/packages/supervision"&gt;&lt;img src="https://img.shields.io/pypi/dm/supervision" alt="downloads" /&gt;&lt;/a&gt; &lt;a href="https://snyk.io/advisor/python/supervision"&gt;&lt;img src="https://snyk.io/advisor/python/supervision/badge.svg?sanitize=true" alt="snyk" /&gt;&lt;/a&gt; &lt;a href="https://github.com/roboflow/supervision/raw/main/LICENSE.md"&gt;&lt;img src="https://img.shields.io/pypi/l/supervision" alt="license" /&gt;&lt;/a&gt; &lt;a href="https://badge.fury.io/py/supervision"&gt;&lt;img src="https://img.shields.io/pypi/pyversions/supervision" alt="python-version" /&gt;&lt;/a&gt; &lt;a href="https://colab.research.google.com/github/roboflow/supervision/blob/main/demo.ipynb"&gt;&lt;img src="https://colab.research.google.com/assets/colab-badge.svg?sanitize=true" alt="colab" /&gt;&lt;/a&gt; &lt;a href="https://huggingface.co/spaces/Roboflow/Annotators"&gt;&lt;img src="https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Spaces-blue" alt="gradio" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/GbfgXGJ8Bk"&gt;&lt;img src="https://img.shields.io/discord/1159501506232451173?logo=discord&amp;amp;label=discord&amp;amp;labelColor=fff&amp;amp;color=5865f2&amp;amp;link=https%3A%2F%2Fdiscord.gg%2FGbfgXGJ8Bk" alt="discord" /&gt;&lt;/a&gt; &lt;a href="https://squidfunk.github.io/mkdocs-material/"&gt;&lt;img src="https://img.shields.io/badge/Material_for_MkDocs-526CFE?logo=MaterialForMkDocs&amp;amp;logoColor=white" alt="built-with-material-for-mkdocs" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;div align="center"&gt; 
  &lt;a href="https://trendshift.io/repositories/124" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/124" alt="roboflow%2Fsupervision | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;h2&gt;👋 hello&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;We write your reusable computer vision tools.&lt;/strong&gt; Whether you need to load your dataset from your hard drive, draw detections on an image or video, or count how many detections are in a zone. You can count on us! 🤝&lt;/p&gt; 
&lt;h2&gt;💻 install&lt;/h2&gt; 
&lt;p&gt;Pip install the supervision package in a &lt;a href="https://www.python.org/"&gt;&lt;strong&gt;Python&amp;gt;=3.9&lt;/strong&gt;&lt;/a&gt; environment.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install supervision
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Read more about conda, mamba, and installing from source in our &lt;a href="https://roboflow.github.io/supervision/"&gt;guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;🔥 quickstart&lt;/h2&gt; 
&lt;h3&gt;models&lt;/h3&gt; 
&lt;p&gt;Supervision was designed to be model agnostic. Just plug in any classification, detection, or segmentation model. For your convenience, we have created &lt;a href="https://supervision.roboflow.com/latest/detection/core/#detections"&gt;connectors&lt;/a&gt; for the most popular libraries like Ultralytics, Transformers, or MMDetection.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import cv2
import supervision as sv
from ultralytics import YOLO

image = cv2.imread(...)
model = YOLO("yolov8s.pt")
result = model(image)[0]
detections = sv.Detections.from_ultralytics(result)

len(detections)
# 5
&lt;/code&gt;&lt;/pre&gt; 
&lt;details&gt; 
 &lt;summary&gt;👉 more model connectors&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;inference&lt;/p&gt; &lt;p&gt;Running with &lt;a href="https://github.com/roboflow/inference"&gt;Inference&lt;/a&gt; requires a &lt;a href="https://docs.roboflow.com/api-reference/authentication#retrieve-an-api-key"&gt;Roboflow API KEY&lt;/a&gt;.&lt;/p&gt; &lt;pre&gt;&lt;code class="language-python"&gt;import cv2
import supervision as sv
from inference import get_model

image = cv2.imread(...)
model = get_model(model_id="yolov8s-640", api_key=&amp;lt;ROBOFLOW API KEY&amp;gt;)
result = model.infer(image)[0]
detections = sv.Detections.from_inference(result)

len(detections)
# 5
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h3&gt;annotators&lt;/h3&gt; 
&lt;p&gt;Supervision offers a wide range of highly customizable &lt;a href="https://supervision.roboflow.com/latest/detection/annotators/"&gt;annotators&lt;/a&gt;, allowing you to compose the perfect visualization for your use case.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import cv2
import supervision as sv

image = cv2.imread(...)
detections = sv.Detections(...)

box_annotator = sv.BoxAnnotator()
annotated_frame = box_annotator.annotate(
  scene=image.copy(),
  detections=detections)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;a href="https://github.com/roboflow/supervision/assets/26109316/691e219c-0565-4403-9218-ab5644f39bce"&gt;https://github.com/roboflow/supervision/assets/26109316/691e219c-0565-4403-9218-ab5644f39bce&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;datasets&lt;/h3&gt; 
&lt;p&gt;Supervision provides a set of &lt;a href="https://supervision.roboflow.com/latest/datasets/core/"&gt;utils&lt;/a&gt; that allow you to load, split, merge, and save datasets in one of the supported formats.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import supervision as sv
from roboflow import Roboflow

project = Roboflow().workspace(&amp;lt;WORKSPACE_ID&amp;gt;).project(&amp;lt;PROJECT_ID&amp;gt;)
dataset = project.version(&amp;lt;PROJECT_VERSION&amp;gt;).download("coco")

ds = sv.DetectionDataset.from_coco(
    images_directory_path=f"{dataset.location}/train",
    annotations_path=f"{dataset.location}/train/_annotations.coco.json",
)

path, image, annotation = ds[0]
    # loads image on demand

for path, image, annotation in ds:
    # loads image on demand
&lt;/code&gt;&lt;/pre&gt; 
&lt;details close&gt; 
 &lt;summary&gt;👉 more dataset utils&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;load&lt;/p&gt; &lt;pre&gt;&lt;code class="language-python"&gt;dataset = sv.DetectionDataset.from_yolo(
    images_directory_path=...,
    annotations_directory_path=...,
    data_yaml_path=...
)

dataset = sv.DetectionDataset.from_pascal_voc(
    images_directory_path=...,
    annotations_directory_path=...
)

dataset = sv.DetectionDataset.from_coco(
    images_directory_path=...,
    annotations_path=...
)
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;split&lt;/p&gt; &lt;pre&gt;&lt;code class="language-python"&gt;train_dataset, test_dataset = dataset.split(split_ratio=0.7)
test_dataset, valid_dataset = test_dataset.split(split_ratio=0.5)

len(train_dataset), len(test_dataset), len(valid_dataset)
# (700, 150, 150)
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;merge&lt;/p&gt; &lt;pre&gt;&lt;code class="language-python"&gt;ds_1 = sv.DetectionDataset(...)
len(ds_1)
# 100
ds_1.classes
# ['dog', 'person']

ds_2 = sv.DetectionDataset(...)
len(ds_2)
# 200
ds_2.classes
# ['cat']

ds_merged = sv.DetectionDataset.merge([ds_1, ds_2])
len(ds_merged)
# 300
ds_merged.classes
# ['cat', 'dog', 'person']
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;save&lt;/p&gt; &lt;pre&gt;&lt;code class="language-python"&gt;dataset.as_yolo(
    images_directory_path=...,
    annotations_directory_path=...,
    data_yaml_path=...
)

dataset.as_pascal_voc(
    images_directory_path=...,
    annotations_directory_path=...
)

dataset.as_coco(
    images_directory_path=...,
    annotations_path=...
)
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;convert&lt;/p&gt; &lt;pre&gt;&lt;code class="language-python"&gt;sv.DetectionDataset.from_yolo(
    images_directory_path=...,
    annotations_directory_path=...,
    data_yaml_path=...
).as_pascal_voc(
    images_directory_path=...,
    annotations_directory_path=...
)
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;🎬 tutorials&lt;/h2&gt; 
&lt;p&gt;Want to learn how to use Supervision? Explore our &lt;a href="https://supervision.roboflow.com/develop/how_to/detect_and_annotate/"&gt;how-to guides&lt;/a&gt;, &lt;a href="https://github.com/roboflow/supervision/tree/develop/examples"&gt;end-to-end examples&lt;/a&gt;, &lt;a href="https://roboflow.github.io/cheatsheet-supervision/"&gt;cheatsheet&lt;/a&gt;, and &lt;a href="https://supervision.roboflow.com/develop/cookbooks/"&gt;cookbooks&lt;/a&gt;!&lt;/p&gt; 
&lt;br /&gt; 
&lt;p align="left"&gt; &lt;a href="https://youtu.be/hAWpsIuem10" title="Dwell Time Analysis with Computer Vision | Real-Time Stream Processing"&gt;&lt;img src="https://github.com/SkalskiP/SkalskiP/assets/26109316/a742823d-c158-407d-b30f-063a5d11b4e1" alt="Dwell Time Analysis with Computer Vision | Real-Time Stream Processing" width="300px" align="left" /&gt;&lt;/a&gt; &lt;a href="https://youtu.be/hAWpsIuem10" title="Dwell Time Analysis with Computer Vision | Real-Time Stream Processing"&gt;&lt;strong&gt;Dwell Time Analysis with Computer Vision | Real-Time Stream Processing&lt;/strong&gt;&lt;/a&gt; &lt;/p&gt;
&lt;div&gt;
 &lt;strong&gt;Created: 5 Apr 2024&lt;/strong&gt;
&lt;/div&gt; 
&lt;br /&gt;Learn how to use computer vision to analyze wait times and optimize processes. This tutorial covers object detection, tracking, and calculating time spent in designated zones. Use these techniques to improve customer experience in retail, traffic management, or other scenarios.
&lt;p&gt;&lt;/p&gt; 
&lt;br /&gt; 
&lt;p align="left"&gt; &lt;a href="https://youtu.be/uWP6UjDeZvY" title="Speed Estimation &amp;amp; Vehicle Tracking | Computer Vision | Open Source"&gt;&lt;img src="https://github.com/SkalskiP/SkalskiP/assets/26109316/61a444c8-b135-48ce-b979-2a5ab47c5a91" alt="Speed Estimation &amp;amp; Vehicle Tracking | Computer Vision | Open Source" width="300px" align="left" /&gt;&lt;/a&gt; &lt;a href="https://youtu.be/uWP6UjDeZvY" title="Speed Estimation &amp;amp; Vehicle Tracking | Computer Vision | Open Source"&gt;&lt;strong&gt;Speed Estimation &amp;amp; Vehicle Tracking | Computer Vision | Open Source&lt;/strong&gt;&lt;/a&gt; &lt;/p&gt;
&lt;div&gt;
 &lt;strong&gt;Created: 11 Jan 2024&lt;/strong&gt;
&lt;/div&gt; 
&lt;br /&gt;Learn how to track and estimate the speed of vehicles using YOLO, ByteTrack, and Roboflow Inference. This comprehensive tutorial covers object detection, multi-object tracking, filtering detections, perspective transformation, speed estimation, visualization improvements, and more.
&lt;p&gt;&lt;/p&gt; 
&lt;h2&gt;💜 built with supervision&lt;/h2&gt; 
&lt;p&gt;Did you build something cool using supervision? &lt;a href="https://github.com/roboflow/supervision/discussions/categories/built-with-supervision"&gt;Let us know!&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://user-images.githubusercontent.com/26109316/207858600-ee862b22-0353-440b-ad85-caa0c4777904.mp4"&gt;https://user-images.githubusercontent.com/26109316/207858600-ee862b22-0353-440b-ad85-caa0c4777904.mp4&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/roboflow/supervision/assets/26109316/c9436828-9fbf-4c25-ae8c-60e9c81b3900"&gt;https://github.com/roboflow/supervision/assets/26109316/c9436828-9fbf-4c25-ae8c-60e9c81b3900&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/roboflow/supervision/assets/26109316/3ac6982f-4943-4108-9b7f-51787ef1a69f"&gt;https://github.com/roboflow/supervision/assets/26109316/3ac6982f-4943-4108-9b7f-51787ef1a69f&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;📚 documentation&lt;/h2&gt; 
&lt;p&gt;Visit our &lt;a href="https://roboflow.github.io/supervision"&gt;documentation&lt;/a&gt; page to learn how supervision can help you build computer vision applications faster and more reliably.&lt;/p&gt; 
&lt;h2&gt;🏆 contribution&lt;/h2&gt; 
&lt;p&gt;We love your input! Please see our &lt;a href="https://github.com/roboflow/supervision/raw/main/CONTRIBUTING.md"&gt;contributing guide&lt;/a&gt; to get started. Thank you 🙏 to all our contributors!&lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/roboflow/supervision/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=roboflow/supervision" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;br /&gt; 
&lt;div align="center"&gt; 
 &lt;div align="center"&gt; 
  &lt;a href="https://youtube.com/roboflow"&gt; &lt;img src="https://media.roboflow.com/notebooks/template/icons/purple/youtube.png?ik-sdk-version=javascript-1.4.3&amp;amp;updatedAt=1672949634652" width="3%" /&gt; &lt;/a&gt; 
  &lt;img src="https://raw.githubusercontent.com/ultralytics/assets/main/social/logo-transparent.png" width="3%" /&gt; 
  &lt;a href="https://roboflow.com"&gt; &lt;img src="https://media.roboflow.com/notebooks/template/icons/purple/roboflow-app.png?ik-sdk-version=javascript-1.4.3&amp;amp;updatedAt=1672949746649" width="3%" /&gt; &lt;/a&gt; 
  &lt;img src="https://raw.githubusercontent.com/ultralytics/assets/main/social/logo-transparent.png" width="3%" /&gt; 
  &lt;a href="https://www.linkedin.com/company/roboflow-ai/"&gt; &lt;img src="https://media.roboflow.com/notebooks/template/icons/purple/linkedin.png?ik-sdk-version=javascript-1.4.3&amp;amp;updatedAt=1672949633691" width="3%" /&gt; &lt;/a&gt; 
  &lt;img src="https://raw.githubusercontent.com/ultralytics/assets/main/social/logo-transparent.png" width="3%" /&gt; 
  &lt;a href="https://docs.roboflow.com"&gt; &lt;img src="https://media.roboflow.com/notebooks/template/icons/purple/knowledge.png?ik-sdk-version=javascript-1.4.3&amp;amp;updatedAt=1672949634511" width="3%" /&gt; &lt;/a&gt; 
  &lt;img src="https://raw.githubusercontent.com/ultralytics/assets/main/social/logo-transparent.png" width="3%" /&gt; 
  &lt;a href="https://discuss.roboflow.com"&gt; &lt;img src="https://media.roboflow.com/notebooks/template/icons/purple/forum.png?ik-sdk-version=javascript-1.4.3&amp;amp;updatedAt=1672949633584" width="3%" /&gt; &lt;img src="https://raw.githubusercontent.com/ultralytics/assets/main/social/logo-transparent.png" width="3%" /&gt; &lt;/a&gt;
  &lt;a href="https://blog.roboflow.com"&gt; &lt;img src="https://media.roboflow.com/notebooks/template/icons/purple/blog.png?ik-sdk-version=javascript-1.4.3&amp;amp;updatedAt=1672949633605" width="3%" /&gt; &lt;/a&gt;  
 &lt;/div&gt; 
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>frappe/erpnext</title>
      <link>https://github.com/frappe/erpnext</link>
      <description>&lt;p&gt;Free and Open Source Enterprise Resource Planning (ERP)&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;a href="https://frappe.io/erpnext"&gt; &lt;img src="https://raw.githubusercontent.com/frappe/erpnext/develop/erpnext/public/images/v16/erpnext.svg?sanitize=true" alt="ERPNext Logo" height="80px" width="80xp" /&gt; &lt;/a&gt; 
 &lt;h2&gt;ERPNext&lt;/h2&gt; 
 &lt;p align="center"&gt; &lt;/p&gt;
 &lt;p&gt;Powerful, Intuitive and Open-Source ERP&lt;/p&gt; 
 &lt;p&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://frappe.school"&gt;&lt;img src="https://img.shields.io/badge/Frappe%20School-Learn%20ERPNext-blue?style=flat-square" alt="Learn on Frappe School" /&gt;&lt;/a&gt;&lt;br /&gt;&lt;br /&gt; &lt;a href="https://github.com/frappe/erpnext/actions/workflows/server-tests-mariadb.yml"&gt;&lt;img src="https://github.com/frappe/erpnext/actions/workflows/server-tests-mariadb.yml/badge.svg?event=schedule" alt="CI" /&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/r/frappe/erpnext-worker"&gt;&lt;img src="https://img.shields.io/docker/pulls/frappe/erpnext-worker.svg?sanitize=true" alt="docker pulls" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/frappe/erpnext/develop/erpnext/public/images/v16/hero_image.png" /&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://erpnext-demo.frappe.cloud/api/method/erpnext_demo.erpnext_demo.auth.login_demo"&gt;Live Demo&lt;/a&gt; - 
 &lt;a href="https://frappe.io/erpnext"&gt;Website&lt;/a&gt; - 
 &lt;a href="https://docs.frappe.io/erpnext/"&gt;Documentation&lt;/a&gt; 
&lt;/div&gt; 
&lt;h2&gt;ERPNext&lt;/h2&gt; 
&lt;p&gt;100% Open-Source ERP system to help you run your business.&lt;/p&gt; 
&lt;h3&gt;Motivation&lt;/h3&gt; 
&lt;p&gt;Running a business is a complex task - handling invoices, tracking stock, managing personnel and even more ad-hoc activities. In a market where software is sold separately to manage each of these tasks, ERPNext does all of the above and more, for free.&lt;/p&gt; 
&lt;h3&gt;Key Features&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Accounting&lt;/strong&gt;: All the tools you need to manage cash flow in one place, right from recording transactions to summarizing and analyzing financial reports.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Order Management&lt;/strong&gt;: Track inventory levels, replenish stock, and manage sales orders, customers, suppliers, shipments, deliverables, and order fulfillment.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Manufacturing&lt;/strong&gt;: Simplifies the production cycle, helps track material consumption, exhibits capacity planning, handles subcontracting, and more!&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Asset Management&lt;/strong&gt;: From purchase to perishment, IT infrastructure to equipment. Cover every branch of your organization, all in one centralized system.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Projects&lt;/strong&gt;: Delivery both internal and external Projects on time, budget and Profitability. Track tasks, timesheets, and issues by project.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;details open&gt; 
 &lt;summary&gt;More&lt;/summary&gt; 
 &lt;img src="https://erpnext.com/files/v16_bom.png" /&gt; 
 &lt;img src="https://erpnext.com/files/v16_stock_summary.png" /&gt; 
 &lt;img src="https://erpnext.com/files/v16_job_card.png" /&gt; 
 &lt;img src="https://erpnext.com/files/v16_tasks.png" /&gt; 
&lt;/details&gt; 
&lt;h3&gt;Under the Hood&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/frappe/frappe"&gt;&lt;strong&gt;Frappe Framework&lt;/strong&gt;&lt;/a&gt;: A full-stack web application framework written in Python and Javascript. The framework provides a robust foundation for building web applications, including a database abstraction layer, user authentication, and a REST API.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/frappe/frappe-ui"&gt;&lt;strong&gt;Frappe UI&lt;/strong&gt;&lt;/a&gt;: A Vue-based UI library, to provide a modern user interface. The Frappe UI library provides a variety of components that can be used to build single-page applications on top of the Frappe Framework.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Production Setup&lt;/h2&gt; 
&lt;h3&gt;Managed Hosting&lt;/h3&gt; 
&lt;p&gt;You can try &lt;a href="https://frappecloud.com"&gt;Frappe Cloud&lt;/a&gt;, a simple, user-friendly and sophisticated &lt;a href="https://github.com/frappe/press"&gt;open-source&lt;/a&gt; platform to host Frappe applications with peace of mind.&lt;/p&gt; 
&lt;p&gt;It takes care of installation, setup, upgrades, monitoring, maintenance and support of your Frappe deployments. It is a fully featured developer platform with an ability to manage and control multiple Frappe deployments.&lt;/p&gt; 
&lt;div&gt; 
 &lt;a href="https://erpnext-demo.frappe.cloud/app/home" target="_blank"&gt; 
  &lt;picture&gt; 
   &lt;source media="(prefers-color-scheme: dark)" srcset="https://frappe.io/files/try-on-fc-white.png" /&gt; 
   &lt;img src="https://frappe.io/files/try-on-fc-black.png" alt="Try on Frappe Cloud" height="28" /&gt; 
  &lt;/picture&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;h3&gt;Self-Hosted&lt;/h3&gt; 
&lt;h4&gt;Docker&lt;/h4&gt; 
&lt;p&gt;Prerequisites: docker, docker-compose, git. Refer &lt;a href="https://docs.docker.com"&gt;Docker Documentation&lt;/a&gt; for more details on Docker setup.&lt;/p&gt; 
&lt;p&gt;Run following commands:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;git clone https://github.com/frappe/frappe_docker
cd frappe_docker
docker compose -f pwd.yml up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;After a couple of minutes, site should be accessible on your localhost port: 8080. Use below default login credentials to access the site.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Username: Administrator&lt;/li&gt; 
 &lt;li&gt;Password: admin&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;See &lt;a href="https://github.com/frappe/frappe_docker?tab=readme-ov-file#to-run-on-arm64-architecture-follow-this-instructions"&gt;Frappe Docker&lt;/a&gt; for ARM based docker setup.&lt;/p&gt; 
&lt;h2&gt;Development Setup&lt;/h2&gt; 
&lt;h3&gt;Manual Install&lt;/h3&gt; 
&lt;p&gt;The Easy Way: our install script for bench will install all dependencies (e.g. MariaDB). See &lt;a href="https://github.com/frappe/bench"&gt;https://github.com/frappe/bench&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;p&gt;New passwords will be created for the ERPNext "Administrator" user, the MariaDB root user, and the frappe user (the script displays the passwords and saves them to ~/frappe_passwords.txt).&lt;/p&gt; 
&lt;h3&gt;Local&lt;/h3&gt; 
&lt;p&gt;To setup the repository locally follow the steps mentioned below:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Setup bench by following the &lt;a href="https://frappeframework.com/docs/user/en/installation"&gt;Installation Steps&lt;/a&gt; and start the server&lt;/p&gt; &lt;pre&gt;&lt;code&gt;bench start
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;In a separate terminal window, run the following commands:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;# Create a new site
bench new-site erpnext.localhost
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Get the ERPNext app and install it&lt;/p&gt; &lt;pre&gt;&lt;code&gt;# Get the ERPNext app
bench get-app https://github.com/frappe/erpnext

# Install the app
bench --site erpnext.localhost install-app erpnext
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Open the URL &lt;code&gt;http://erpnext.localhost:8000/app&lt;/code&gt; in your browser, you should see the app running&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Learning and community&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;a href="https://school.frappe.io"&gt;Frappe School&lt;/a&gt; - Learn Frappe Framework and ERPNext from the various courses by the maintainers or from the community.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.erpnext.com/"&gt;Official documentation&lt;/a&gt; - Extensive documentation for ERPNext.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://discuss.erpnext.com/"&gt;Discussion Forum&lt;/a&gt; - Engage with community of ERPNext users and service providers.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://erpnext_public.t.me"&gt;Telegram Group&lt;/a&gt; - Get instant help from huge community of users.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;a href="https://github.com/frappe/erpnext/wiki/Issue-Guidelines"&gt;Issue Guidelines&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://erpnext.com/security"&gt;Report Security Vulnerabilities&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/frappe/erpnext/wiki/Contribution-Guidelines"&gt;Pull Request Requirements&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://crowdin.com/project/frappe"&gt;Translations&lt;/a&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Logo and Trademark Policy&lt;/h2&gt; 
&lt;p&gt;Please read our &lt;a href="https://raw.githubusercontent.com/frappe/erpnext/develop/TRADEMARK_POLICY.md"&gt;Logo and Trademark Policy&lt;/a&gt;.&lt;/p&gt; 
&lt;br /&gt; 
&lt;br /&gt; 
&lt;div align="center" style="padding-top: 0.75rem;"&gt; 
 &lt;a href="https://frappe.io" target="_blank"&gt; 
  &lt;picture&gt; 
   &lt;source media="(prefers-color-scheme: dark)" srcset="https://frappe.io/files/Frappe-white.png" /&gt; 
   &lt;img src="https://frappe.io/files/Frappe-black.png" alt="Frappe Technologies" height="28" /&gt; 
  &lt;/picture&gt; &lt;/a&gt; 
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>THUDM/slime</title>
      <link>https://github.com/THUDM/slime</link>
      <description>&lt;p&gt;slime is an LLM post-training framework for RL Scaling.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;slime&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/THUDM/slime/main/README_zh.md"&gt;中文版&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://thudm.github.io/slime/"&gt;&lt;img src="https://img.shields.io/badge/docs-latest-brightgreen.svg?style=flat" alt="Documentation" /&gt;&lt;/a&gt; &lt;a href="https://deepwiki.com/THUDM/slime"&gt;&lt;img src="https://deepwiki.com/badge.svg?sanitize=true" alt="Ask DeepWiki" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;slime&lt;/strong&gt; is an LLM post-training framework for RL scaling, providing two core capabilities:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;High-Performance Training&lt;/strong&gt;: Supports efficient training in various modes by connecting Megatron with SGLang;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Flexible Data Generation&lt;/strong&gt;: Enables arbitrary training data generation workflows through custom data generation interfaces and server-based engines.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Blogs&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Our vision: &lt;a href="https://lmsys.org/blog/2025-07-09-slime/"&gt;slime: An SGLang-Native Post-Training Framework for RL Scaling&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Our ideas on agentic training: &lt;a href="https://www.notion.so/Agent-Oriented-Design-An-Asynchronous-and-Decoupled-Framework-for-Agentic-RL-2278e692d081802cbdd5d37cef76a547"&gt;Agent-Oriented Design: An Asynchronous and Decoupled Framework for Agentic RL&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;slime has served as the RL framework for GLM-4.5: &lt;a href="https://z.ai/blog/glm-4.5"&gt;GLM-4.5: Reasoning, Coding, and Agentic Abilities&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Table of Contents&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/THUDM/slime/main/#architecture-overview"&gt;Architecture Overview&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/THUDM/slime/main/#quick-start"&gt;Quick Start&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/THUDM/slime/main/#checkpoint-format-conversion"&gt;Checkpoint Format Conversion&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/THUDM/slime/main/#starting-the-training-process"&gt;Starting the Training Process&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/THUDM/slime/main/#argument-descriptions"&gt;Argument Descriptions&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/THUDM/slime/main/#developer-guide"&gt;Developer Guide&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/THUDM/slime/main/#faq--acknowledgements"&gt;FAQ &amp;amp; Acknowledgements&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Architecture Overview&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/THUDM/slime/main/imgs/arch.png" alt="arch" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Module Descriptions&lt;/strong&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;training (Megatron)&lt;/strong&gt;: Responsible for the main training process, reads data from the Data Buffer, and synchronizes parameters to the rollout module after training.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;rollout (SGLang + router)&lt;/strong&gt;: Generates new data (including rewards/verifier outputs) and stores it in the Data Buffer.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;data buffer&lt;/strong&gt;: A bridge module that manages prompt initialization, custom data, and rollout generation methods.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;p&gt;For a comprehensive quick start guide covering environment setup, data preparation, training startup, and key code analysis, please refer to:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/THUDM/slime/main/docs/en/get_started/quick_start.md"&gt;Quick Start Guide&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;We also provide examples for some usecases not covered in the quick start guide, please check &lt;a href="https://raw.githubusercontent.com/THUDM/slime/main/examples/"&gt;examples&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Arguments Walk Through&lt;/h2&gt; 
&lt;p&gt;Arguments in slime are divided into three categories:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Megatron arguments&lt;/strong&gt;: slime reads all arguments set in Megatron via &lt;code&gt;PYTHONPATH&lt;/code&gt;. You can configure Megatron by passing arguments like &lt;code&gt;--tensor-model-parallel-size 2&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;SGLang arguments&lt;/strong&gt;: All arguments for the installed SGLang are supported. These arguments must be prefixed with &lt;code&gt;--sglang-&lt;/code&gt;. For example, &lt;code&gt;--mem-fraction-static&lt;/code&gt; should be passed as &lt;code&gt;--sglang-mem-fraction-static&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;slime-specific arguments&lt;/strong&gt;: Please refer to: &lt;a href="https://raw.githubusercontent.com/THUDM/slime/main/slime/utils/arguments.py"&gt;slime/utils/arguments.py&lt;/a&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;For complete usage instructions, please refer to the &lt;a href="https://raw.githubusercontent.com/THUDM/slime/main/docs/en/get_started/usage.md"&gt;Usage Documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Developer Guide&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Contributions are welcome!&lt;/strong&gt; If you have suggestions for new features, performance tuning, or feedback on user experience, feel free to submit an Issue or PR 😊&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Use &lt;a href="https://pre-commit.com/"&gt;pre-commit&lt;/a&gt; to ensure code style consistency for your commits:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;apt install pre-commit -y
pre-commit install
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;For debugging tips, please refer to the &lt;a href="https://raw.githubusercontent.com/THUDM/slime/main/docs/en/developer_guide/debug.md"&gt;Debugging Guide&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;FAQ &amp;amp; Acknowledgements&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;For frequently asked questions, please see the &lt;a href="https://raw.githubusercontent.com/THUDM/slime/main/docs/en/get_started/qa.md"&gt;Q&amp;amp;A&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Special thanks to the following projects &amp;amp; communities: SGLang, Megatron‑LM, mbridge, OpenRLHF, veRL, Pai-Megatron-Patch and others.&lt;/li&gt; 
 &lt;li&gt;To quote slime, please use:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bibtext"&gt;@misc{slime_github,
  author       = {Zilin Zhu and Chengxing Xie and Xin Lv and slime Contributors},
  title        = {slime: An LLM post-training framework for RL Scaling},
  year         = {2025},
  howpublished = {\url{https://github.com/THUDM/slime}},
  note         = {GitHub repository. Corresponding author: Xin Lv},
  urldate      = {2025-06-19}
}
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>HKUDS/RAG-Anything</title>
      <link>https://github.com/HKUDS/RAG-Anything</link>
      <description>&lt;p&gt;"RAG-Anything: All-in-One RAG Framework"&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;div style="margin: 20px 0;"&gt; 
  &lt;img src="https://raw.githubusercontent.com/HKUDS/RAG-Anything/main/assets/logo.png" width="120" height="120" alt="RAG-Anything Logo" style="border-radius: 20px; box-shadow: 0 8px 32px rgba(0, 217, 255, 0.3);" /&gt; 
 &lt;/div&gt; 
 &lt;h1&gt;🚀 RAG-Anything: All-in-One RAG Framework&lt;/h1&gt; 
 &lt;p&gt;&lt;a href="https://trendshift.io/repositories/14959" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/14959" alt="HKUDS%2FRAG-Anything | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;div align="center"&gt; 
  &lt;img src="https://readme-typing-svg.herokuapp.com?font=Orbitron&amp;amp;size=24&amp;amp;duration=3000&amp;amp;pause=1000&amp;amp;color=00D9FF&amp;amp;center=true&amp;amp;vCenter=true&amp;amp;width=600&amp;amp;lines=Welcome+to+RAG-Anything;Next-Gen+Multimodal+RAG+System;Powered+by+Advanced+AI+Technology" alt="Typing Animation" /&gt; 
 &lt;/div&gt; 
 &lt;div align="center"&gt; 
  &lt;div style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); border-radius: 15px; padding: 25px; text-align: center;"&gt; 
   &lt;p&gt; &lt;a href="https://github.com/HKUDS/RAG-Anything"&gt;&lt;img src="https://img.shields.io/badge/🔥Project-Page-00d9ff?style=for-the-badge&amp;amp;logo=github&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt;&lt;/a&gt; &lt;a href="https://arxiv.org/abs/2410.05779"&gt;&lt;img src="https://img.shields.io/badge/📄arXiv-2410.05779-ff6b6b?style=for-the-badge&amp;amp;logo=arxiv&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt;&lt;/a&gt; &lt;a href="https://github.com/HKUDS/LightRAG"&gt;&lt;img src="https://img.shields.io/badge/⚡Based%20on-LightRAG-4ecdc4?style=for-the-badge&amp;amp;logo=lightning&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt;&lt;/a&gt; &lt;/p&gt; 
   &lt;p&gt; &lt;a href="https://github.com/HKUDS/RAG-Anything/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/HKUDS/RAG-Anything?color=00d9ff&amp;amp;style=for-the-badge&amp;amp;logo=star&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/badge/🐍Python-3.10-4ecdc4?style=for-the-badge&amp;amp;logo=python&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt; &lt;a href="https://pypi.org/project/raganything/"&gt;&lt;img src="https://img.shields.io/pypi/v/raganything.svg?style=for-the-badge&amp;amp;logo=pypi&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e&amp;amp;color=ff6b6b" /&gt;&lt;/a&gt; &lt;a href="https://github.com/astral-sh/uv"&gt;&lt;img src="https://img.shields.io/badge/⚡uv-Ready-ff6b6b?style=for-the-badge&amp;amp;logo=python&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt;&lt;/a&gt; &lt;/p&gt; 
   &lt;p&gt; &lt;a href="https://discord.gg/yF2MmDJyGJ"&gt;&lt;img src="https://img.shields.io/badge/💬Discord-Community-7289da?style=for-the-badge&amp;amp;logo=discord&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt;&lt;/a&gt; &lt;a href="https://github.com/HKUDS/RAG-Anything/issues/7"&gt;&lt;img src="https://img.shields.io/badge/💬WeChat-Group-07c160?style=for-the-badge&amp;amp;logo=wechat&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt;&lt;/a&gt; &lt;/p&gt; 
   &lt;p&gt; &lt;a href="https://raw.githubusercontent.com/HKUDS/RAG-Anything/main/README_zh.md"&gt;&lt;img src="https://img.shields.io/badge/🇨🇳中文版-1a1a2e?style=for-the-badge" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/HKUDS/RAG-Anything/main/README.md"&gt;&lt;img src="https://img.shields.io/badge/🇺🇸English-1a1a2e?style=for-the-badge" /&gt;&lt;/a&gt; &lt;/p&gt; 
  &lt;/div&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;div style="width: 100%; height: 2px; margin: 20px 0; background: linear-gradient(90deg, transparent, #00d9ff, transparent);"&gt;&lt;/div&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://raw.githubusercontent.com/HKUDS/RAG-Anything/main/#-quick-start" style="text-decoration: none;"&gt; &lt;img src="https://img.shields.io/badge/Quick%20Start-Get%20Started%20Now-00d9ff?style=for-the-badge&amp;amp;logo=rocket&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h2&gt;🎉 News&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; [2025.08.12]🎯📢 🔍 RAG-Anything now features &lt;strong&gt;VLM-Enhanced Query&lt;/strong&gt; mode! When documents include images, the system seamlessly integrates them into VLM for advanced multimodal analysis, combining visual and textual context for deeper insights.&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; [2025.07.05]🎯📢 RAG-Anything now features a &lt;a href="https://raw.githubusercontent.com/HKUDS/RAG-Anything/main/docs/context_aware_processing.md"&gt;context configuration module&lt;/a&gt;, enabling intelligent integration of relevant contextual information to enhance multimodal content processing.&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; [2025.07.04]🎯📢 🚀 RAG-Anything now supports multimodal query capabilities, enabling enhanced RAG with seamless processing of text, images, tables, and equations.&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; [2025.07.03]🎯📢 🎉 RAG-Anything has reached 1k🌟 stars on GitHub! Thank you for your incredible support and valuable contributions to the project.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;🌟 System Overview&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Next-Generation Multimodal Intelligence&lt;/em&gt;&lt;/p&gt; 
&lt;div style="background: linear-gradient(135deg, #1a1a2e 0%, #16213e 50%, #0f3460 100%); border-radius: 15px; padding: 25px; margin: 20px 0; border: 2px solid #00d9ff; box-shadow: 0 0 30px rgba(0, 217, 255, 0.3);"&gt; 
 &lt;p&gt;Modern documents increasingly contain diverse multimodal content—text, images, tables, equations, charts, and multimedia—that traditional text-focused RAG systems cannot effectively process. &lt;strong&gt;RAG-Anything&lt;/strong&gt; addresses this challenge as a comprehensive &lt;strong&gt;All-in-One Multimodal Document Processing RAG system&lt;/strong&gt; built on &lt;a href="https://github.com/HKUDS/LightRAG"&gt;LightRAG&lt;/a&gt;.&lt;/p&gt; 
 &lt;p&gt;As a unified solution, RAG-Anything &lt;strong&gt;eliminates the need for multiple specialized tools&lt;/strong&gt;. It provides &lt;strong&gt;seamless processing and querying across all content modalities&lt;/strong&gt; within a single integrated framework. Unlike conventional RAG approaches that struggle with non-textual elements, our all-in-one system delivers &lt;strong&gt;comprehensive multimodal retrieval capabilities&lt;/strong&gt;.&lt;/p&gt; 
 &lt;p&gt;Users can query documents containing &lt;strong&gt;interleaved text&lt;/strong&gt;, &lt;strong&gt;visual diagrams&lt;/strong&gt;, &lt;strong&gt;structured tables&lt;/strong&gt;, and &lt;strong&gt;mathematical formulations&lt;/strong&gt; through &lt;strong&gt;one cohesive interface&lt;/strong&gt;. This consolidated approach makes RAG-Anything particularly valuable for academic research, technical documentation, financial reports, and enterprise knowledge management where rich, mixed-content documents demand a &lt;strong&gt;unified processing framework&lt;/strong&gt;.&lt;/p&gt; 
 &lt;img src="https://raw.githubusercontent.com/HKUDS/RAG-Anything/main/assets/rag_anything_framework.png" alt="RAG-Anything" /&gt; 
&lt;/div&gt; 
&lt;h3&gt;🎯 Key Features&lt;/h3&gt; 
&lt;div style="background: linear-gradient(135deg, #1a1a2e 0%, #16213e 100%); border-radius: 15px; padding: 25px; margin: 20px 0;"&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;🔄 End-to-End Multimodal Pipeline&lt;/strong&gt; - Complete workflow from document ingestion and parsing to intelligent multimodal query answering&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;📄 Universal Document Support&lt;/strong&gt; - Seamless processing of PDFs, Office documents, images, and diverse file formats&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;🧠 Specialized Content Analysis&lt;/strong&gt; - Dedicated processors for images, tables, mathematical equations, and heterogeneous content types&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;🔗 Multimodal Knowledge Graph&lt;/strong&gt; - Automatic entity extraction and cross-modal relationship discovery for enhanced understanding&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;⚡ Adaptive Processing Modes&lt;/strong&gt; - Flexible MinerU-based parsing or direct multimodal content injection workflows&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;📋 Direct Content List Insertion&lt;/strong&gt; - Bypass document parsing by directly inserting pre-parsed content lists from external sources&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;🎯 Hybrid Intelligent Retrieval&lt;/strong&gt; - Advanced search capabilities spanning textual and multimodal content with contextual understanding&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h2&gt;🏗️ Algorithm &amp;amp; Architecture&lt;/h2&gt; 
&lt;div style="background: linear-gradient(135deg, #0f0f23 0%, #1a1a2e 100%); border-radius: 15px; padding: 25px; margin: 20px 0; border-left: 5px solid #00d9ff;"&gt; 
 &lt;h3&gt;Core Algorithm&lt;/h3&gt; 
 &lt;p&gt;&lt;strong&gt;RAG-Anything&lt;/strong&gt; implements an effective &lt;strong&gt;multi-stage multimodal pipeline&lt;/strong&gt; that fundamentally extends traditional RAG architectures to seamlessly handle diverse content modalities through intelligent orchestration and cross-modal understanding.&lt;/p&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;div style="width: 100%; max-width: 600px; margin: 20px auto; padding: 20px; background: linear-gradient(135deg, rgba(0, 217, 255, 0.1) 0%, rgba(0, 217, 255, 0.05) 100%); border-radius: 15px; border: 1px solid rgba(0, 217, 255, 0.2);"&gt; 
  &lt;div style="display: flex; justify-content: space-around; align-items: center; flex-wrap: wrap; gap: 20px;"&gt; 
   &lt;div style="text-align: center;"&gt; 
    &lt;div style="font-size: 24px; margin-bottom: 10px;"&gt;
     📄
    &lt;/div&gt; 
    &lt;div style="font-size: 14px; color: #00d9ff;"&gt;
     Document Parsing
    &lt;/div&gt; 
   &lt;/div&gt; 
   &lt;div style="font-size: 20px; color: #00d9ff;"&gt;
    →
   &lt;/div&gt; 
   &lt;div style="text-align: center;"&gt; 
    &lt;div style="font-size: 24px; margin-bottom: 10px;"&gt;
     🧠
    &lt;/div&gt; 
    &lt;div style="font-size: 14px; color: #00d9ff;"&gt;
     Content Analysis
    &lt;/div&gt; 
   &lt;/div&gt; 
   &lt;div style="font-size: 20px; color: #00d9ff;"&gt;
    →
   &lt;/div&gt; 
   &lt;div style="text-align: center;"&gt; 
    &lt;div style="font-size: 24px; margin-bottom: 10px;"&gt;
     🔍
    &lt;/div&gt; 
    &lt;div style="font-size: 14px; color: #00d9ff;"&gt;
     Knowledge Graph
    &lt;/div&gt; 
   &lt;/div&gt; 
   &lt;div style="font-size: 20px; color: #00d9ff;"&gt;
    →
   &lt;/div&gt; 
   &lt;div style="text-align: center;"&gt; 
    &lt;div style="font-size: 24px; margin-bottom: 10px;"&gt;
     🎯
    &lt;/div&gt; 
    &lt;div style="font-size: 14px; color: #00d9ff;"&gt;
     Intelligent Retrieval
    &lt;/div&gt; 
   &lt;/div&gt; 
  &lt;/div&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;h3&gt;1. Document Parsing Stage&lt;/h3&gt; 
&lt;div style="background: linear-gradient(90deg, #1a1a2e 0%, #16213e 100%); border-radius: 10px; padding: 20px; margin: 15px 0; border-left: 4px solid #4ecdc4;"&gt; 
 &lt;p&gt;The system provides high-fidelity document extraction through adaptive content decomposition. It intelligently segments heterogeneous elements while preserving contextual relationships. Universal format compatibility is achieved via specialized optimized parsers.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Key Components:&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;⚙️ MinerU Integration&lt;/strong&gt;: Leverages &lt;a href="https://github.com/opendatalab/MinerU"&gt;MinerU&lt;/a&gt; for high-fidelity document structure extraction and semantic preservation across complex layouts.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;🧩 Adaptive Content Decomposition&lt;/strong&gt;: Automatically segments documents into coherent text blocks, visual elements, structured tables, mathematical equations, and specialized content types while preserving contextual relationships.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;📁 Universal Format Support&lt;/strong&gt;: Provides comprehensive handling of PDFs, Office documents (DOC/DOCX/PPT/PPTX/XLS/XLSX), images, and emerging formats through specialized parsers with format-specific optimization.&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/div&gt; 
&lt;h3&gt;2. Multi-Modal Content Understanding &amp;amp; Processing&lt;/h3&gt; 
&lt;div style="background: linear-gradient(90deg, #16213e 0%, #0f3460 100%); border-radius: 10px; padding: 20px; margin: 15px 0; border-left: 4px solid #ff6b6b;"&gt; 
 &lt;p&gt;The system automatically categorizes and routes content through optimized channels. It uses concurrent pipelines for parallel text and multimodal processing. Document hierarchy and relationships are preserved during transformation.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Key Components:&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;🎯 Autonomous Content Categorization and Routing&lt;/strong&gt;: Automatically identify, categorize, and route different content types through optimized execution channels.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;⚡ Concurrent Multi-Pipeline Architecture&lt;/strong&gt;: Implements concurrent execution of textual and multimodal content through dedicated processing pipelines. This approach maximizes throughput efficiency while preserving content integrity.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;🏗️ Document Hierarchy Extraction&lt;/strong&gt;: Extracts and preserves original document hierarchy and inter-element relationships during content transformation.&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/div&gt; 
&lt;h3&gt;3. Multimodal Analysis Engine&lt;/h3&gt; 
&lt;div style="background: linear-gradient(90deg, #0f3460 0%, #1a1a2e 100%); border-radius: 10px; padding: 20px; margin: 15px 0; border-left: 4px solid #00d9ff;"&gt; 
 &lt;p&gt;The system deploys modality-aware processing units for heterogeneous data modalities:&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Specialized Analyzers:&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;🔍 Visual Content Analyzer&lt;/strong&gt;:&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Integrate vision model for image analysis.&lt;/li&gt; 
    &lt;li&gt;Generates context-aware descriptive captions based on visual semantics.&lt;/li&gt; 
    &lt;li&gt;Extracts spatial relationships and hierarchical structures between visual elements.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;📊 Structured Data Interpreter&lt;/strong&gt;:&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Performs systematic interpretation of tabular and structured data formats.&lt;/li&gt; 
    &lt;li&gt;Implements statistical pattern recognition algorithms for data trend analysis.&lt;/li&gt; 
    &lt;li&gt;Identifies semantic relationships and dependencies across multiple tabular datasets.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;📐 Mathematical Expression Parser&lt;/strong&gt;:&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Parses complex mathematical expressions and formulas with high accuracy.&lt;/li&gt; 
    &lt;li&gt;Provides native LaTeX format support for seamless integration with academic workflows.&lt;/li&gt; 
    &lt;li&gt;Establishes conceptual mappings between mathematical equations and domain-specific knowledge bases.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;🔧 Extensible Modality Handler&lt;/strong&gt;:&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Provides configurable processing framework for custom and emerging content types.&lt;/li&gt; 
    &lt;li&gt;Enables dynamic integration of new modality processors through plugin architecture.&lt;/li&gt; 
    &lt;li&gt;Supports runtime configuration of processing pipelines for specialized use cases.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/div&gt; 
&lt;h3&gt;4. Multimodal Knowledge Graph Index&lt;/h3&gt; 
&lt;div style="background: linear-gradient(90deg, #1a1a2e 0%, #16213e 100%); border-radius: 10px; padding: 20px; margin: 15px 0; border-left: 4px solid #4ecdc4;"&gt; 
 &lt;p&gt;The multi-modal knowledge graph construction module transforms document content into structured semantic representations. It extracts multimodal entities, establishes cross-modal relationships, and preserves hierarchical organization. The system applies weighted relevance scoring for optimized knowledge retrieval.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Core Functions:&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;🔍 Multi-Modal Entity Extraction&lt;/strong&gt;: Transforms significant multimodal elements into structured knowledge graph entities. The process includes semantic annotations and metadata preservation.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;🔗 Cross-Modal Relationship Mapping&lt;/strong&gt;: Establishes semantic connections and dependencies between textual entities and multimodal components. This is achieved through automated relationship inference algorithms.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;🏗️ Hierarchical Structure Preservation&lt;/strong&gt;: Maintains original document organization through "belongs_to" relationship chains. These chains preserve logical content hierarchy and sectional dependencies.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;⚖️ Weighted Relationship Scoring&lt;/strong&gt;: Assigns quantitative relevance scores to relationship types. Scoring is based on semantic proximity and contextual significance within the document structure.&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/div&gt; 
&lt;h3&gt;5. Modality-Aware Retrieval&lt;/h3&gt; 
&lt;div style="background: linear-gradient(90deg, #16213e 0%, #0f3460 100%); border-radius: 10px; padding: 20px; margin: 15px 0; border-left: 4px solid #ff6b6b;"&gt; 
 &lt;p&gt;The hybrid retrieval system combines vector similarity search with graph traversal algorithms for comprehensive content retrieval. It implements modality-aware ranking mechanisms and maintains relational coherence between retrieved elements to ensure contextually integrated information delivery.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Retrieval Mechanisms:&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;🔀 Vector-Graph Fusion&lt;/strong&gt;: Integrates vector similarity search with graph traversal algorithms. This approach leverages both semantic embeddings and structural relationships for comprehensive content retrieval.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;📊 Modality-Aware Ranking&lt;/strong&gt;: Implements adaptive scoring mechanisms that weight retrieval results based on content type relevance. The system adjusts rankings according to query-specific modality preferences.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;🔗 Relational Coherence Maintenance&lt;/strong&gt;: Maintains semantic and structural relationships between retrieved elements. This ensures coherent information delivery and contextual integrity.&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h2&gt;🚀 Quick Start&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Initialize Your AI Journey&lt;/em&gt;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://user-images.githubusercontent.com/74038190/212284158-e840e285-664b-44d7-b79b-e264b5e54825.gif" width="400" /&gt; 
&lt;/div&gt; 
&lt;h3&gt;Installation&lt;/h3&gt; 
&lt;h4&gt;Option 1: Install from PyPI (Recommended)&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Basic installation
pip install raganything

# With optional dependencies for extended format support:
pip install 'raganything[all]'              # All optional features
pip install 'raganything[image]'            # Image format conversion (BMP, TIFF, GIF, WebP)
pip install 'raganything[text]'             # Text file processing (TXT, MD)
pip install 'raganything[image,text]'       # Multiple features
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Option 2: Install from Source&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Install uv (if not already installed)
curl -LsSf https://astral.sh/uv/install.sh | sh

# Clone and setup the project with uv
git clone https://github.com/HKUDS/RAG-Anything.git
cd RAG-Anything

# Install the package and dependencies in a virtual environment
uv sync

# If you encounter network timeouts (especially for opencv packages):
# UV_HTTP_TIMEOUT=120 uv sync

# Run commands directly with uv (recommended approach)
uv run python examples/raganything_example.py --help

# Install with optional dependencies
uv sync --extra image --extra text  # Specific extras
uv sync --all-extras                 # All optional features
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Optional Dependencies&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;[image]&lt;/code&gt;&lt;/strong&gt; - Enables processing of BMP, TIFF, GIF, WebP image formats (requires Pillow)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;[text]&lt;/code&gt;&lt;/strong&gt; - Enables processing of TXT and MD files (requires ReportLab)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;[all]&lt;/code&gt;&lt;/strong&gt; - Includes all Python optional dependencies&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;⚠️ Office Document Processing Requirements:&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Office documents (.doc, .docx, .ppt, .pptx, .xls, .xlsx) require &lt;strong&gt;LibreOffice&lt;/strong&gt; installation&lt;/li&gt; 
  &lt;li&gt;Download from &lt;a href="https://www.libreoffice.org/download/download/"&gt;LibreOffice official website&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Windows&lt;/strong&gt;: Download installer from official website&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;macOS&lt;/strong&gt;: &lt;code&gt;brew install --cask libreoffice&lt;/code&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Ubuntu/Debian&lt;/strong&gt;: &lt;code&gt;sudo apt-get install libreoffice&lt;/code&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;CentOS/RHEL&lt;/strong&gt;: &lt;code&gt;sudo yum install libreoffice&lt;/code&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;Check MinerU installation:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Verify installation
mineru --version

# Check if properly configured
python -c "from raganything import RAGAnything; rag = RAGAnything(); print('✅ MinerU installed properly' if rag.check_parser_installation() else '❌ MinerU installation issue')"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Models are downloaded automatically on first use. For manual download, refer to &lt;a href="https://github.com/opendatalab/MinerU/raw/master/README.md#22-model-source-configuration"&gt;MinerU Model Source Configuration&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Usage Examples&lt;/h3&gt; 
&lt;h4&gt;1. End-to-End Document Processing&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import asyncio
from raganything import RAGAnything, RAGAnythingConfig
from lightrag.llm.openai import openai_complete_if_cache, openai_embed
from lightrag.utils import EmbeddingFunc

async def main():
    # Set up API configuration
    api_key = "your-api-key"
    base_url = "your-base-url"  # Optional

    # Create RAGAnything configuration
    config = RAGAnythingConfig(
        working_dir="./rag_storage",
        parser="mineru",  # Parser selection: mineru or docling
        parse_method="auto",  # Parse method: auto, ocr, or txt
        enable_image_processing=True,
        enable_table_processing=True,
        enable_equation_processing=True,
    )

    # Define LLM model function
    def llm_model_func(prompt, system_prompt=None, history_messages=[], **kwargs):
        return openai_complete_if_cache(
            "gpt-4o-mini",
            prompt,
            system_prompt=system_prompt,
            history_messages=history_messages,
            api_key=api_key,
            base_url=base_url,
            **kwargs,
        )

    # Define vision model function for image processing
    def vision_model_func(
        prompt, system_prompt=None, history_messages=[], image_data=None, messages=None, **kwargs
    ):
        # If messages format is provided (for multimodal VLM enhanced query), use it directly
        if messages:
            return openai_complete_if_cache(
                "gpt-4o",
                "",
                system_prompt=None,
                history_messages=[],
                messages=messages,
                api_key=api_key,
                base_url=base_url,
                **kwargs,
            )
        # Traditional single image format
        elif image_data:
            return openai_complete_if_cache(
                "gpt-4o",
                "",
                system_prompt=None,
                history_messages=[],
                messages=[
                    {"role": "system", "content": system_prompt}
                    if system_prompt
                    else None,
                    {
                        "role": "user",
                        "content": [
                            {"type": "text", "text": prompt},
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": f"data:image/jpeg;base64,{image_data}"
                                },
                            },
                        ],
                    }
                    if image_data
                    else {"role": "user", "content": prompt},
                ],
                api_key=api_key,
                base_url=base_url,
                **kwargs,
            )
        # Pure text format
        else:
            return llm_model_func(prompt, system_prompt, history_messages, **kwargs)

    # Define embedding function
    embedding_func = EmbeddingFunc(
        embedding_dim=3072,
        max_token_size=8192,
        func=lambda texts: openai_embed(
            texts,
            model="text-embedding-3-large",
            api_key=api_key,
            base_url=base_url,
        ),
    )

    # Initialize RAGAnything
    rag = RAGAnything(
        config=config,
        llm_model_func=llm_model_func,
        vision_model_func=vision_model_func,
        embedding_func=embedding_func,
    )

    # Process a document
    await rag.process_document_complete(
        file_path="path/to/your/document.pdf",
        output_dir="./output",
        parse_method="auto"
    )

    # Query the processed content
    # Pure text query - for basic knowledge base search
    text_result = await rag.aquery(
        "What are the main findings shown in the figures and tables?",
        mode="hybrid"
    )
    print("Text query result:", text_result)

    # Multimodal query with specific multimodal content
    multimodal_result = await rag.aquery_with_multimodal(
    "Explain this formula and its relevance to the document content",
    multimodal_content=[{
        "type": "equation",
        "latex": "P(d|q) = \\frac{P(q|d) \\cdot P(d)}{P(q)}",
        "equation_caption": "Document relevance probability"
    }],
    mode="hybrid"
)
    print("Multimodal query result:", multimodal_result)

if __name__ == "__main__":
    asyncio.run(main())
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;2. Direct Multimodal Content Processing&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import asyncio
from lightrag import LightRAG
from lightrag.llm.openai import openai_complete_if_cache, openai_embed
from lightrag.utils import EmbeddingFunc
from raganything.modalprocessors import ImageModalProcessor, TableModalProcessor

async def process_multimodal_content():
    # Set up API configuration
    api_key = "your-api-key"
    base_url = "your-base-url"  # Optional

    # Initialize LightRAG
    rag = LightRAG(
        working_dir="./rag_storage",
        llm_model_func=lambda prompt, system_prompt=None, history_messages=[], **kwargs: openai_complete_if_cache(
            "gpt-4o-mini",
            prompt,
            system_prompt=system_prompt,
            history_messages=history_messages,
            api_key=api_key,
            base_url=base_url,
            **kwargs,
        ),
        embedding_func=EmbeddingFunc(
            embedding_dim=3072,
            max_token_size=8192,
            func=lambda texts: openai_embed(
                texts,
                model="text-embedding-3-large",
                api_key=api_key,
                base_url=base_url,
            ),
        )
    )
    await rag.initialize_storages()

    # Process an image
    image_processor = ImageModalProcessor(
        lightrag=rag,
        modal_caption_func=lambda prompt, system_prompt=None, history_messages=[], image_data=None, **kwargs: openai_complete_if_cache(
            "gpt-4o",
            "",
            system_prompt=None,
            history_messages=[],
            messages=[
                {"role": "system", "content": system_prompt} if system_prompt else None,
                {"role": "user", "content": [
                    {"type": "text", "text": prompt},
                    {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{image_data}"}}
                ]} if image_data else {"role": "user", "content": prompt}
            ],
            api_key=api_key,
            base_url=base_url,
            **kwargs,
        ) if image_data else openai_complete_if_cache(
            "gpt-4o-mini",
            prompt,
            system_prompt=system_prompt,
            history_messages=history_messages,
            api_key=api_key,
            base_url=base_url,
            **kwargs,
        )
    )

    image_content = {
        "img_path": "path/to/image.jpg",
        "image_caption": ["Figure 1: Experimental results"],
        "image_footnote": ["Data collected in 2024"]
    }

    description, entity_info = await image_processor.process_multimodal_content(
        modal_content=image_content,
        content_type="image",
        file_path="research_paper.pdf",
        entity_name="Experimental Results Figure"
    )

    # Process a table
    table_processor = TableModalProcessor(
        lightrag=rag,
        modal_caption_func=lambda prompt, system_prompt=None, history_messages=[], **kwargs: openai_complete_if_cache(
            "gpt-4o-mini",
            prompt,
            system_prompt=system_prompt,
            history_messages=history_messages,
            api_key=api_key,
            base_url=base_url,
            **kwargs,
        )
    )

    table_content = {
        "table_body": """
        | Method | Accuracy | F1-Score |
        |--------|----------|----------|
        | RAGAnything | 95.2% | 0.94 |
        | Baseline | 87.3% | 0.85 |
        """,
        "table_caption": ["Performance Comparison"],
        "table_footnote": ["Results on test dataset"]
    }

    description, entity_info = await table_processor.process_multimodal_content(
        modal_content=table_content,
        content_type="table",
        file_path="research_paper.pdf",
        entity_name="Performance Results Table"
    )

if __name__ == "__main__":
    asyncio.run(process_multimodal_content())
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;3. Batch Processing&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# Process multiple documents
await rag.process_folder_complete(
    folder_path="./documents",
    output_dir="./output",
    file_extensions=[".pdf", ".docx", ".pptx"],
    recursive=True,
    max_workers=4
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;4. Custom Modal Processors&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from raganything.modalprocessors import GenericModalProcessor

class CustomModalProcessor(GenericModalProcessor):
    async def process_multimodal_content(self, modal_content, content_type, file_path, entity_name):
        # Your custom processing logic
        enhanced_description = await self.analyze_custom_content(modal_content)
        entity_info = self.create_custom_entity(enhanced_description, entity_name)
        return await self._create_entity_and_chunk(enhanced_description, entity_info, file_path)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;5. Query Options&lt;/h4&gt; 
&lt;p&gt;RAG-Anything provides three types of query methods:&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Pure Text Queries&lt;/strong&gt; - Direct knowledge base search using LightRAG:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# Different query modes for text queries
text_result_hybrid = await rag.aquery("Your question", mode="hybrid")
text_result_local = await rag.aquery("Your question", mode="local")
text_result_global = await rag.aquery("Your question", mode="global")
text_result_naive = await rag.aquery("Your question", mode="naive")

# Synchronous version
sync_text_result = rag.query("Your question", mode="hybrid")
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;VLM Enhanced Queries&lt;/strong&gt; - Automatically analyze images in retrieved context using VLM:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# VLM enhanced query (automatically enabled when vision_model_func is provided)
vlm_result = await rag.aquery(
    "Analyze the charts and figures in the document",
    mode="hybrid"
    # vlm_enhanced=True is automatically set when vision_model_func is available
)

# Manually control VLM enhancement
vlm_enabled = await rag.aquery(
    "What do the images show in this document?",
    mode="hybrid",
    vlm_enhanced=True  # Force enable VLM enhancement
)

vlm_disabled = await rag.aquery(
    "What do the images show in this document?",
    mode="hybrid",
    vlm_enhanced=False  # Force disable VLM enhancement
)

# When documents contain images, VLM can see and analyze them directly
# The system will automatically:
# 1. Retrieve relevant context containing image paths
# 2. Load and encode images as base64
# 3. Send both text context and images to VLM for comprehensive analysis
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Multimodal Queries&lt;/strong&gt; - Enhanced queries with specific multimodal content analysis:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# Query with table data
table_result = await rag.aquery_with_multimodal(
    "Compare these performance metrics with the document content",
    multimodal_content=[{
        "type": "table",
        "table_data": """Method,Accuracy,Speed
                        RAGAnything,95.2%,120ms
                        Traditional,87.3%,180ms""",
        "table_caption": "Performance comparison"
    }],
    mode="hybrid"
)

# Query with equation content
equation_result = await rag.aquery_with_multimodal(
    "Explain this formula and its relevance to the document content",
    multimodal_content=[{
        "type": "equation",
        "latex": "P(d|q) = \\frac{P(q|d) \\cdot P(d)}{P(q)}",
        "equation_caption": "Document relevance probability"
    }],
    mode="hybrid"
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;6. Loading Existing LightRAG Instance&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import asyncio
from raganything import RAGAnything, RAGAnythingConfig
from lightrag import LightRAG
from lightrag.llm.openai import openai_complete_if_cache, openai_embed
from lightrag.kg.shared_storage import initialize_pipeline_status
from lightrag.utils import EmbeddingFunc
import os

async def load_existing_lightrag():
    # Set up API configuration
    api_key = "your-api-key"
    base_url = "your-base-url"  # Optional

    # First, create or load existing LightRAG instance
    lightrag_working_dir = "./existing_lightrag_storage"

    # Check if previous LightRAG instance exists
    if os.path.exists(lightrag_working_dir) and os.listdir(lightrag_working_dir):
        print("✅ Found existing LightRAG instance, loading...")
    else:
        print("❌ No existing LightRAG instance found, will create new one")

    # Create/load LightRAG instance with your configuration
    lightrag_instance = LightRAG(
        working_dir=lightrag_working_dir,
        llm_model_func=lambda prompt, system_prompt=None, history_messages=[], **kwargs: openai_complete_if_cache(
            "gpt-4o-mini",
            prompt,
            system_prompt=system_prompt,
            history_messages=history_messages,
            api_key=api_key,
            base_url=base_url,
            **kwargs,
        ),
        embedding_func=EmbeddingFunc(
            embedding_dim=3072,
            max_token_size=8192,
            func=lambda texts: openai_embed(
                texts,
                model="text-embedding-3-large",
                api_key=api_key,
                base_url=base_url,
            ),
        )
    )

    # Initialize storage (this will load existing data if available)
    await lightrag_instance.initialize_storages()
    await initialize_pipeline_status()

    # Define vision model function for image processing
    def vision_model_func(
        prompt, system_prompt=None, history_messages=[], image_data=None, messages=None, **kwargs
    ):
        # If messages format is provided (for multimodal VLM enhanced query), use it directly
        if messages:
            return openai_complete_if_cache(
                "gpt-4o",
                "",
                system_prompt=None,
                history_messages=[],
                messages=messages,
                api_key=api_key,
                base_url=base_url,
                **kwargs,
            )
        # Traditional single image format
        elif image_data:
            return openai_complete_if_cache(
                "gpt-4o",
                "",
                system_prompt=None,
                history_messages=[],
                messages=[
                    {"role": "system", "content": system_prompt}
                    if system_prompt
                    else None,
                    {
                        "role": "user",
                        "content": [
                            {"type": "text", "text": prompt},
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": f"data:image/jpeg;base64,{image_data}"
                                },
                            },
                        ],
                    }
                    if image_data
                    else {"role": "user", "content": prompt},
                ],
                api_key=api_key,
                base_url=base_url,
                **kwargs,
            )
        # Pure text format
        else:
            return lightrag_instance.llm_model_func(prompt, system_prompt, history_messages, **kwargs)

    # Now use existing LightRAG instance to initialize RAGAnything
    rag = RAGAnything(
        lightrag=lightrag_instance,  # Pass existing LightRAG instance
        vision_model_func=vision_model_func,
        # Note: working_dir, llm_model_func, embedding_func, etc. are inherited from lightrag_instance
    )

    # Query existing knowledge base
    result = await rag.aquery(
        "What data has been processed in this LightRAG instance?",
        mode="hybrid"
    )
    print("Query result:", result)

    # Add new multimodal document to existing LightRAG instance
    await rag.process_document_complete(
        file_path="path/to/new/multimodal_document.pdf",
        output_dir="./output"
    )

if __name__ == "__main__":
    asyncio.run(load_existing_lightrag())
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;7. Direct Content List Insertion&lt;/h4&gt; 
&lt;p&gt;For scenarios where you already have a pre-parsed content list (e.g., from external parsers or previous processing), you can directly insert it into RAGAnything without document parsing:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import asyncio
from raganything import RAGAnything, RAGAnythingConfig
from lightrag.llm.openai import openai_complete_if_cache, openai_embed
from lightrag.utils import EmbeddingFunc

async def insert_content_list_example():
    # Set up API configuration
    api_key = "your-api-key"
    base_url = "your-base-url"  # Optional

    # Create RAGAnything configuration
    config = RAGAnythingConfig(
        working_dir="./rag_storage",
        enable_image_processing=True,
        enable_table_processing=True,
        enable_equation_processing=True,
    )

    # Define model functions
    def llm_model_func(prompt, system_prompt=None, history_messages=[], **kwargs):
        return openai_complete_if_cache(
            "gpt-4o-mini",
            prompt,
            system_prompt=system_prompt,
            history_messages=history_messages,
            api_key=api_key,
            base_url=base_url,
            **kwargs,
        )

    def vision_model_func(prompt, system_prompt=None, history_messages=[], image_data=None, messages=None, **kwargs):
        # If messages format is provided (for multimodal VLM enhanced query), use it directly
        if messages:
            return openai_complete_if_cache(
                "gpt-4o",
                "",
                system_prompt=None,
                history_messages=[],
                messages=messages,
                api_key=api_key,
                base_url=base_url,
                **kwargs,
            )
        # Traditional single image format
        elif image_data:
            return openai_complete_if_cache(
                "gpt-4o",
                "",
                system_prompt=None,
                history_messages=[],
                messages=[
                    {"role": "system", "content": system_prompt} if system_prompt else None,
                    {
                        "role": "user",
                        "content": [
                            {"type": "text", "text": prompt},
                            {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{image_data}"}}
                        ],
                    } if image_data else {"role": "user", "content": prompt},
                ],
                api_key=api_key,
                base_url=base_url,
                **kwargs,
            )
        # Pure text format
        else:
            return llm_model_func(prompt, system_prompt, history_messages, **kwargs)

    embedding_func = EmbeddingFunc(
        embedding_dim=3072,
        max_token_size=8192,
        func=lambda texts: openai_embed(
            texts,
            model="text-embedding-3-large",
            api_key=api_key,
            base_url=base_url,
        ),
    )

    # Initialize RAGAnything
    rag = RAGAnything(
        config=config,
        llm_model_func=llm_model_func,
        vision_model_func=vision_model_func,
        embedding_func=embedding_func,
    )

    # Example: Pre-parsed content list from external source
    content_list = [
        {
            "type": "text",
            "text": "This is the introduction section of our research paper.",
            "page_idx": 0  # Page number where this content appears
        },
        {
            "type": "image",
            "img_path": "/absolute/path/to/figure1.jpg",  # IMPORTANT: Use absolute path
            "image_caption": ["Figure 1: System Architecture"],
            "image_footnote": ["Source: Authors' original design"],
            "page_idx": 1  # Page number where this image appears
        },
        {
            "type": "table",
            "table_body": "| Method | Accuracy | F1-Score |\n|--------|----------|----------|\n| Ours | 95.2% | 0.94 |\n| Baseline | 87.3% | 0.85 |",
            "table_caption": ["Table 1: Performance Comparison"],
            "table_footnote": ["Results on test dataset"],
            "page_idx": 2  # Page number where this table appears
        },
        {
            "type": "equation",
            "latex": "P(d|q) = \\frac{P(q|d) \\cdot P(d)}{P(q)}",
            "text": "Document relevance probability formula",
            "page_idx": 3  # Page number where this equation appears
        },
        {
            "type": "text",
            "text": "In conclusion, our method demonstrates superior performance across all metrics.",
            "page_idx": 4  # Page number where this content appears
        }
    ]

    # Insert the content list directly
    await rag.insert_content_list(
        content_list=content_list,
        file_path="research_paper.pdf",  # Reference file name for citation
        split_by_character=None,         # Optional text splitting
        split_by_character_only=False,   # Optional text splitting mode
        doc_id=None,                     # Optional custom document ID (will be auto-generated if not provided)
        display_stats=True               # Show content statistics
    )

    # Query the inserted content
    result = await rag.aquery(
        "What are the key findings and performance metrics mentioned in the research?",
        mode="hybrid"
    )
    print("Query result:", result)

    # You can also insert multiple content lists with different document IDs
    another_content_list = [
        {
            "type": "text",
            "text": "This is content from another document.",
            "page_idx": 0  # Page number where this content appears
        },
        {
            "type": "table",
            "table_body": "| Feature | Value |\n|---------|-------|\n| Speed | Fast |\n| Accuracy | High |",
            "table_caption": ["Feature Comparison"],
            "page_idx": 1  # Page number where this table appears
        }
    ]

    await rag.insert_content_list(
        content_list=another_content_list,
        file_path="another_document.pdf",
        doc_id="custom-doc-id-123"  # Custom document ID
    )

if __name__ == "__main__":
    asyncio.run(insert_content_list_example())
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Content List Format:&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;The &lt;code&gt;content_list&lt;/code&gt; should follow the standard format with each item being a dictionary containing:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Text content&lt;/strong&gt;: &lt;code&gt;{"type": "text", "text": "content text", "page_idx": 0}&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Image content&lt;/strong&gt;: &lt;code&gt;{"type": "image", "img_path": "/absolute/path/to/image.jpg", "image_caption": ["caption"], "image_footnote": ["note"], "page_idx": 1}&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Table content&lt;/strong&gt;: &lt;code&gt;{"type": "table", "table_body": "markdown table", "table_caption": ["caption"], "table_footnote": ["note"], "page_idx": 2}&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Equation content&lt;/strong&gt;: &lt;code&gt;{"type": "equation", "latex": "LaTeX formula", "text": "description", "page_idx": 3}&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Generic content&lt;/strong&gt;: &lt;code&gt;{"type": "custom_type", "content": "any content", "page_idx": 4}&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Important Notes:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;img_path&lt;/code&gt;&lt;/strong&gt;: Must be an absolute path to the image file (e.g., &lt;code&gt;/home/user/images/chart.jpg&lt;/code&gt; or &lt;code&gt;C:\Users\user\images\chart.jpg&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;page_idx&lt;/code&gt;&lt;/strong&gt;: Represents the page number where the content appears in the original document (0-based indexing)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Content ordering&lt;/strong&gt;: Items are processed in the order they appear in the list&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;This method is particularly useful when:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;You have content from external parsers (non-MinerU/Docling)&lt;/li&gt; 
 &lt;li&gt;You want to process programmatically generated content&lt;/li&gt; 
 &lt;li&gt;You need to insert content from multiple sources into a single knowledge base&lt;/li&gt; 
 &lt;li&gt;You have cached parsing results that you want to reuse&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;🛠️ Examples&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Practical Implementation Demos&lt;/em&gt;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://user-images.githubusercontent.com/74038190/212257455-13e3e01e-d6a6-45dc-bb92-3ab87b12dfc1.gif" width="300" /&gt; 
&lt;/div&gt; 
&lt;p&gt;The &lt;code&gt;examples/&lt;/code&gt; directory contains comprehensive usage examples:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;raganything_example.py&lt;/code&gt;&lt;/strong&gt;: End-to-end document processing with MinerU&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;modalprocessors_example.py&lt;/code&gt;&lt;/strong&gt;: Direct multimodal content processing&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;office_document_test.py&lt;/code&gt;&lt;/strong&gt;: Office document parsing test with MinerU (no API key required)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;image_format_test.py&lt;/code&gt;&lt;/strong&gt;: Image format parsing test with MinerU (no API key required)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;text_format_test.py&lt;/code&gt;&lt;/strong&gt;: Text format parsing test with MinerU (no API key required)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Run examples:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# End-to-end processing with parser selection
python examples/raganything_example.py path/to/document.pdf --api-key YOUR_API_KEY --parser mineru

# Direct modal processing
python examples/modalprocessors_example.py --api-key YOUR_API_KEY

# Office document parsing test (MinerU only)
python examples/office_document_test.py --file path/to/document.docx

# Image format parsing test (MinerU only)
python examples/image_format_test.py --file path/to/image.bmp

# Text format parsing test (MinerU only)
python examples/text_format_test.py --file path/to/document.md

# Check LibreOffice installation
python examples/office_document_test.py --check-libreoffice --file dummy

# Check PIL/Pillow installation
python examples/image_format_test.py --check-pillow --file dummy

# Check ReportLab installation
python examples/text_format_test.py --check-reportlab --file dummy
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h2&gt;🔧 Configuration&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;System Optimization Parameters&lt;/em&gt;&lt;/p&gt; 
&lt;h3&gt;Environment Variables&lt;/h3&gt; 
&lt;p&gt;Create a &lt;code&gt;.env&lt;/code&gt; file (refer to &lt;code&gt;.env.example&lt;/code&gt;):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;OPENAI_API_KEY=your_openai_api_key
OPENAI_BASE_URL=your_base_url  # Optional
OUTPUT_DIR=./output             # Default output directory for parsed documents
PARSER=mineru                   # Parser selection: mineru or docling
PARSE_METHOD=auto              # Parse method: auto, ocr, or txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; For backward compatibility, legacy environment variable names are still supported:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;MINERU_PARSE_METHOD&lt;/code&gt; is deprecated, please use &lt;code&gt;PARSE_METHOD&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: API keys are only required for full RAG processing with LLM integration. The parsing test files (&lt;code&gt;office_document_test.py&lt;/code&gt; and &lt;code&gt;image_format_test.py&lt;/code&gt;) only test parser functionality and do not require API keys.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Parser Configuration&lt;/h3&gt; 
&lt;p&gt;RAGAnything now supports multiple parsers, each with specific advantages:&lt;/p&gt; 
&lt;h4&gt;MinerU Parser&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Supports PDF, images, Office documents, and more formats&lt;/li&gt; 
 &lt;li&gt;Powerful OCR and table extraction capabilities&lt;/li&gt; 
 &lt;li&gt;GPU acceleration support&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Docling Parser&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Optimized for Office documents and HTML files&lt;/li&gt; 
 &lt;li&gt;Better document structure preservation&lt;/li&gt; 
 &lt;li&gt;Native support for multiple Office formats&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;MinerU Configuration&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# MinerU 2.0 uses command-line parameters instead of config files
# Check available options:
mineru --help

# Common configurations:
mineru -p input.pdf -o output_dir -m auto    # Automatic parsing mode
mineru -p input.pdf -o output_dir -m ocr     # OCR-focused parsing
mineru -p input.pdf -o output_dir -b pipeline --device cuda  # GPU acceleration
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can also configure parsing through RAGAnything parameters:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# Basic parsing configuration with parser selection
await rag.process_document_complete(
    file_path="document.pdf",
    output_dir="./output/",
    parse_method="auto",          # or "ocr", "txt"
    parser="mineru"               # Optional: "mineru" or "docling"
)

# Advanced parsing configuration with special parameters
await rag.process_document_complete(
    file_path="document.pdf",
    output_dir="./output/",
    parse_method="auto",          # Parsing method: "auto", "ocr", "txt"
    parser="mineru",              # Parser selection: "mineru" or "docling"

    # MinerU special parameters - all supported kwargs:
    lang="ch",                   # Document language for OCR optimization (e.g., "ch", "en", "ja")
    device="cuda:0",             # Inference device: "cpu", "cuda", "cuda:0", "npu", "mps"
    start_page=0,                # Starting page number (0-based, for PDF)
    end_page=10,                 # Ending page number (0-based, for PDF)
    formula=True,                # Enable formula parsing
    table=True,                  # Enable table parsing
    backend="pipeline",          # Parsing backend: pipeline|vlm-transformers|vlm-sglang-engine|vlm-sglang-client.
    source="huggingface",        # Model source: "huggingface", "modelscope", "local"
    # vlm_url="http://127.0.0.1:3000" # Service address when using backend=vlm-sglang-client

    # Standard RAGAnything parameters
    display_stats=True,          # Display content statistics
    split_by_character=None,     # Optional character to split text by
    doc_id=None                  # Optional document ID
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: MinerU 2.0 no longer uses the &lt;code&gt;magic-pdf.json&lt;/code&gt; configuration file. All settings are now passed as command-line parameters or function arguments. RAG-Anything now supports multiple document parsers - you can choose between MinerU and Docling based on your needs.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Processing Requirements&lt;/h3&gt; 
&lt;p&gt;Different content types require specific optional dependencies:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Office Documents&lt;/strong&gt; (.doc, .docx, .ppt, .pptx, .xls, .xlsx): Install &lt;a href="https://www.libreoffice.org/download/download/"&gt;LibreOffice&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Extended Image Formats&lt;/strong&gt; (.bmp, .tiff, .gif, .webp): Install with &lt;code&gt;pip install raganything[image]&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Text Files&lt;/strong&gt; (.txt, .md): Install with &lt;code&gt;pip install raganything[text]&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;📋 Quick Install&lt;/strong&gt;: Use &lt;code&gt;pip install raganything[all]&lt;/code&gt; to enable all format support (Python dependencies only - LibreOffice still needs separate installation)&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;hr /&gt; 
&lt;h2&gt;🧪 Supported Content Types&lt;/h2&gt; 
&lt;h3&gt;Document Formats&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;PDFs&lt;/strong&gt; - Research papers, reports, presentations&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Office Documents&lt;/strong&gt; - DOC, DOCX, PPT, PPTX, XLS, XLSX&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Images&lt;/strong&gt; - JPG, PNG, BMP, TIFF, GIF, WebP&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Text Files&lt;/strong&gt; - TXT, MD&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Multimodal Elements&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Images&lt;/strong&gt; - Photographs, diagrams, charts, screenshots&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Tables&lt;/strong&gt; - Data tables, comparison charts, statistical summaries&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Equations&lt;/strong&gt; - Mathematical formulas in LaTeX format&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Generic Content&lt;/strong&gt; - Custom content types via extensible processors&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;em&gt;For installation of format-specific dependencies, see the &lt;a href="https://raw.githubusercontent.com/HKUDS/RAG-Anything/main/#-configuration"&gt;Configuration&lt;/a&gt; section.&lt;/em&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;📖 Citation&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Academic Reference&lt;/em&gt;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;div style="width: 60px; height: 60px; margin: 20px auto; position: relative;"&gt; 
  &lt;div style="width: 100%; height: 100%; border: 2px solid #00d9ff; border-radius: 50%; position: relative;"&gt; 
   &lt;div style="position: absolute; top: 50%; left: 50%; transform: translate(-50%, -50%); font-size: 24px; color: #00d9ff;"&gt;
    📖
   &lt;/div&gt; 
  &lt;/div&gt; 
  &lt;div style="position: absolute; bottom: -5px; left: 50%; transform: translateX(-50%); width: 20px; height: 20px; background: white; border-right: 2px solid #00d9ff; border-bottom: 2px solid #00d9ff; transform: rotate(45deg);"&gt;&lt;/div&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;p&gt;If you find RAG-Anything useful in your research, please cite our paper:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bibtex"&gt;@article{guo2024lightrag,
  title={LightRAG: Simple and Fast Retrieval-Augmented Generation},
  author={Zirui Guo and Lianghao Xia and Yanhua Yu and Tu Ao and Chao Huang},
  year={2024},
  eprint={2410.05779},
  archivePrefix={arXiv},
  primaryClass={cs.IR}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h2&gt;🔗 Related Projects&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Ecosystem &amp;amp; Extensions&lt;/em&gt;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;table&gt; 
  &lt;tbody&gt;
   &lt;tr&gt; 
    &lt;td align="center"&gt; &lt;a href="https://github.com/HKUDS/LightRAG"&gt; 
      &lt;div style="width: 100px; height: 100px; background: linear-gradient(135deg, rgba(0, 217, 255, 0.1) 0%, rgba(0, 217, 255, 0.05) 100%); border-radius: 15px; border: 1px solid rgba(0, 217, 255, 0.2); display: flex; align-items: center; justify-content: center; margin-bottom: 10px;"&gt; 
       &lt;span style="font-size: 32px;"&gt;⚡&lt;/span&gt; 
      &lt;/div&gt; &lt;b&gt;LightRAG&lt;/b&gt;&lt;br /&gt; &lt;sub&gt;Simple and Fast RAG&lt;/sub&gt; &lt;/a&gt; &lt;/td&gt; 
    &lt;td align="center"&gt; &lt;a href="https://github.com/HKUDS/VideoRAG"&gt; 
      &lt;div style="width: 100px; height: 100px; background: linear-gradient(135deg, rgba(0, 217, 255, 0.1) 0%, rgba(0, 217, 255, 0.05) 100%); border-radius: 15px; border: 1px solid rgba(0, 217, 255, 0.2); display: flex; align-items: center; justify-content: center; margin-bottom: 10px;"&gt; 
       &lt;span style="font-size: 32px;"&gt;🎥&lt;/span&gt; 
      &lt;/div&gt; &lt;b&gt;VideoRAG&lt;/b&gt;&lt;br /&gt; &lt;sub&gt;Extreme Long-Context Video RAG&lt;/sub&gt; &lt;/a&gt; &lt;/td&gt; 
    &lt;td align="center"&gt; &lt;a href="https://github.com/HKUDS/MiniRAG"&gt; 
      &lt;div style="width: 100px; height: 100px; background: linear-gradient(135deg, rgba(0, 217, 255, 0.1) 0%, rgba(0, 217, 255, 0.05) 100%); border-radius: 15px; border: 1px solid rgba(0, 217, 255, 0.2); display: flex; align-items: center; justify-content: center; margin-bottom: 10px;"&gt; 
       &lt;span style="font-size: 32px;"&gt;✨&lt;/span&gt; 
      &lt;/div&gt; &lt;b&gt;MiniRAG&lt;/b&gt;&lt;br /&gt; &lt;sub&gt;Extremely Simple RAG&lt;/sub&gt; &lt;/a&gt; &lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt;
 &lt;/table&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h2&gt;⭐ Star History&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Community Growth Trajectory&lt;/em&gt;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://star-history.com/#HKUDS/RAG-Anything&amp;amp;Date"&gt; 
  &lt;picture&gt; 
   &lt;source media="(prefers-color-scheme: dark)" srcset="https://api.star-history.com/svg?repos=HKUDS/RAG-Anything&amp;amp;type=Date&amp;amp;theme=dark" /&gt; 
   &lt;source media="(prefers-color-scheme: light)" srcset="https://api.star-history.com/svg?repos=HKUDS/RAG-Anything&amp;amp;type=Date" /&gt; 
   &lt;img alt="Star History Chart" src="https://api.star-history.com/svg?repos=HKUDS/RAG-Anything&amp;amp;type=Date" style="border-radius: 15px; box-shadow: 0 0 30px rgba(0, 217, 255, 0.3);" /&gt; 
  &lt;/picture&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h2&gt;🤝 Contribution&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Join the Innovation&lt;/em&gt;&lt;/p&gt; 
&lt;div align="center"&gt;
  We thank all our contributors for their valuable contributions. 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://github.com/HKUDS/RAG-Anything/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=HKUDS/RAG-Anything" style="border-radius: 15px; box-shadow: 0 0 20px rgba(0, 217, 255, 0.3);" /&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;div align="center" style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); border-radius: 15px; padding: 30px; margin: 30px 0;"&gt; 
 &lt;div&gt; 
  &lt;img src="https://user-images.githubusercontent.com/74038190/212284100-561aa473-3905-4a80-b561-0d28506553ee.gif" width="500" /&gt; 
 &lt;/div&gt; 
 &lt;div style="margin-top: 20px;"&gt; 
  &lt;a href="https://github.com/HKUDS/RAG-Anything" style="text-decoration: none;"&gt; &lt;img src="https://img.shields.io/badge/⭐%20Star%20us%20on%20GitHub-1a1a2e?style=for-the-badge&amp;amp;logo=github&amp;amp;logoColor=white" /&gt; &lt;/a&gt; 
  &lt;a href="https://github.com/HKUDS/RAG-Anything/issues" style="text-decoration: none;"&gt; &lt;img src="https://img.shields.io/badge/🐛%20Report%20Issues-ff6b6b?style=for-the-badge&amp;amp;logo=github&amp;amp;logoColor=white" /&gt; &lt;/a&gt; 
  &lt;a href="https://github.com/HKUDS/RAG-Anything/discussions" style="text-decoration: none;"&gt; &lt;img src="https://img.shields.io/badge/💬%20Discussions-4ecdc4?style=for-the-badge&amp;amp;logo=github&amp;amp;logoColor=white" /&gt; &lt;/a&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;div style="width: 100%; max-width: 600px; margin: 20px auto; padding: 20px; background: linear-gradient(135deg, rgba(0, 217, 255, 0.1) 0%, rgba(0, 217, 255, 0.05) 100%); border-radius: 15px; border: 1px solid rgba(0, 217, 255, 0.2);"&gt; 
  &lt;div style="display: flex; justify-content: center; align-items: center; gap: 15px;"&gt; 
   &lt;span style="font-size: 24px;"&gt;⭐&lt;/span&gt; 
   &lt;span style="color: #00d9ff; font-size: 18px;"&gt;Thank you for visiting RAG-Anything!&lt;/span&gt; 
   &lt;span style="font-size: 24px;"&gt;⭐&lt;/span&gt; 
  &lt;/div&gt; 
  &lt;div style="margin-top: 10px; color: #00d9ff; font-size: 16px;"&gt;
   Building the Future of Multimodal AI
  &lt;/div&gt; 
 &lt;/div&gt; 
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>topoteretes/cognee</title>
      <link>https://github.com/topoteretes/cognee</link>
      <description>&lt;p&gt;Memory for AI Agents in 6 lines of code&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;a href="https://github.com/topoteretes/cognee"&gt; &lt;img src="https://raw.githubusercontent.com/topoteretes/cognee/refs/heads/dev/assets/cognee-logo-transparent.png" alt="Cognee Logo" height="60" /&gt; &lt;/a&gt; 
 &lt;br /&gt; 
 &lt;p&gt;cognee - Memory for AI Agents in 6 lines of code&lt;/p&gt; 
 &lt;p align="center"&gt; &lt;a href="https://www.youtube.com/watch?v=1bezuvLwJmw&amp;amp;t=2s"&gt;Demo&lt;/a&gt; . &lt;a href="https://cognee.ai"&gt;Learn more&lt;/a&gt; · &lt;a href="https://discord.gg/NQPKmU5CCg"&gt;Join Discord&lt;/a&gt; · &lt;a href="https://www.reddit.com/r/AIMemory/"&gt;Join r/AIMemory&lt;/a&gt; . &lt;a href="https://docs.cognee.ai/"&gt;Docs&lt;/a&gt; . &lt;a href="https://github.com/topoteretes/cognee-community"&gt;cognee community repo&lt;/a&gt; &lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://GitHub.com/topoteretes/cognee/network/"&gt;&lt;img src="https://img.shields.io/github/forks/topoteretes/cognee.svg?style=social&amp;amp;label=Fork&amp;amp;maxAge=2592000" alt="GitHub forks" /&gt;&lt;/a&gt; &lt;a href="https://GitHub.com/topoteretes/cognee/stargazers/"&gt;&lt;img src="https://img.shields.io/github/stars/topoteretes/cognee.svg?style=social&amp;amp;label=Star&amp;amp;maxAge=2592000" alt="GitHub stars" /&gt;&lt;/a&gt; &lt;a href="https://GitHub.com/topoteretes/cognee/commit/"&gt;&lt;img src="https://badgen.net/github/commits/topoteretes/cognee" alt="GitHub commits" /&gt;&lt;/a&gt; &lt;a href="https://github.com/topoteretes/cognee/tags/"&gt;&lt;img src="https://badgen.net/github/tag/topoteretes/cognee" alt="Github tag" /&gt;&lt;/a&gt; &lt;a href="https://pepy.tech/project/cognee"&gt;&lt;img src="https://static.pepy.tech/badge/cognee" alt="Downloads" /&gt;&lt;/a&gt; &lt;a href="https://github.com/topoteretes/cognee/raw/main/LICENSE"&gt;&lt;img src="https://img.shields.io/github/license/topoteretes/cognee?colorA=00C586&amp;amp;colorB=000000" alt="License" /&gt;&lt;/a&gt; &lt;a href="https://github.com/topoteretes/cognee/graphs/contributors"&gt;&lt;img src="https://img.shields.io/github/contributors/topoteretes/cognee?colorA=00C586&amp;amp;colorB=000000" alt="Contributors" /&gt;&lt;/a&gt; &lt;a href="https://github.com/sponsors/topoteretes"&gt;&lt;img src="https://img.shields.io/badge/Sponsor-❤️-ff69b4.svg" alt="Sponsor" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt; &lt;a href="https://www.producthunt.com/posts/cognee?embed=true&amp;amp;utm_source=badge-top-post-badge&amp;amp;utm_medium=badge&amp;amp;utm_souce=badge-cognee" target="_blank" style="display:inline-block; margin-right:10px;"&gt; &lt;img src="https://api.producthunt.com/widgets/embed-image/v1/top-post-badge.svg?post_id=946346&amp;amp;theme=light&amp;amp;period=daily&amp;amp;t=1744472480704" alt="cognee - Memory for AI Agents  in 5 lines of code | Product Hunt" width="250" height="54" /&gt; &lt;/a&gt; &lt;a href="https://trendshift.io/repositories/13955" target="_blank" style="display:inline-block;"&gt; &lt;img src="https://trendshift.io/api/badge/repositories/13955" alt="topoteretes%2Fcognee | Trendshift" width="250" height="55" /&gt; &lt;/a&gt; &lt;/p&gt; 
 &lt;p&gt;Build dynamic memory for Agents and replace RAG using scalable, modular ECL (Extract, Cognify, Load) pipelines.&lt;/p&gt; 
 &lt;p align="center"&gt; 🌐 Available Languages : 
  &lt;!-- Keep these links. Translations will automatically update with the README. --&gt; &lt;a href="https://www.readme-i18n.com/topoteretes/cognee?lang=de"&gt;Deutsch&lt;/a&gt; | &lt;a href="https://www.readme-i18n.com/topoteretes/cognee?lang=es"&gt;Español&lt;/a&gt; | &lt;a href="https://www.readme-i18n.com/topoteretes/cognee?lang=fr"&gt;français&lt;/a&gt; | &lt;a href="https://www.readme-i18n.com/topoteretes/cognee?lang=ja"&gt;日本語&lt;/a&gt; | &lt;a href="https://www.readme-i18n.com/topoteretes/cognee?lang=ko"&gt;한국어&lt;/a&gt; | &lt;a href="https://www.readme-i18n.com/topoteretes/cognee?lang=pt"&gt;Português&lt;/a&gt; | &lt;a href="https://www.readme-i18n.com/topoteretes/cognee?lang=ru"&gt;Русский&lt;/a&gt; | &lt;a href="https://www.readme-i18n.com/topoteretes/cognee?lang=zh"&gt;中文&lt;/a&gt; &lt;/p&gt; 
 &lt;div style="text-align: center"&gt; 
  &lt;img src="https://raw.githubusercontent.com/topoteretes/cognee/refs/heads/main/assets/cognee_benefits.png" alt="Why cognee?" width="50%" /&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;h2&gt;Get Started&lt;/h2&gt; 
&lt;p&gt;Get started quickly with a Google Colab &lt;a href="https://colab.research.google.com/drive/1jHbWVypDgCLwjE71GSXhRL3YxYhCZzG1?usp=sharing"&gt;notebook&lt;/a&gt; , &lt;a href="https://deepnote.com/workspace/cognee-382213d0-0444-4c89-8265-13770e333c02/project/cognee-demo-78ffacb9-5832-4611-bb1a-560386068b30/notebook/Notebook-1-75b24cda566d4c24ab348f7150792601?utm_source=share-modal&amp;amp;utm_medium=product-shared-content&amp;amp;utm_campaign=notebook&amp;amp;utm_content=78ffacb9-5832-4611-bb1a-560386068b30"&gt;Deepnote notebook&lt;/a&gt; or &lt;a href="https://github.com/topoteretes/cognee/tree/main/cognee-starter-kit"&gt;starter repo&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;About cognee&lt;/h2&gt; 
&lt;p&gt;cognee works locally and stores your data on your device. Our hosted solution is just our deployment of OSS cognee on Modal, with the goal of making development and productionization easier.&lt;/p&gt; 
&lt;p&gt;Self-hosted package:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Interconnects any kind of documents: past conversations, files, images, and audio transcriptions&lt;/li&gt; 
 &lt;li&gt;Replaces RAG systems with a memory layer based on graphs and vectors&lt;/li&gt; 
 &lt;li&gt;Reduces developer effort and cost, while increasing quality and precision&lt;/li&gt; 
 &lt;li&gt;Provides Pythonic data pipelines that manage data ingestion from 30+ data sources&lt;/li&gt; 
 &lt;li&gt;Is highly customizable with custom tasks, pipelines, and a set of built-in search endpoints&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Hosted platform:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Includes a managed UI and a &lt;a href="https://www.cognee.ai"&gt;hosted solution&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Self-Hosted (Open Source)&lt;/h2&gt; 
&lt;h3&gt;📦 Installation&lt;/h3&gt; 
&lt;p&gt;You can install Cognee using either &lt;strong&gt;pip&lt;/strong&gt;, &lt;strong&gt;poetry&lt;/strong&gt;, &lt;strong&gt;uv&lt;/strong&gt; or any other python package manager.&lt;/p&gt; 
&lt;p&gt;Cognee supports Python 3.10 to 3.12&lt;/p&gt; 
&lt;h4&gt;With uv&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uv pip install cognee
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Detailed instructions can be found in our &lt;a href="https://docs.cognee.ai/getting-started/installation#environment-configuration"&gt;docs&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;💻 Basic Usage&lt;/h3&gt; 
&lt;h4&gt;Setup&lt;/h4&gt; 
&lt;pre&gt;&lt;code&gt;import os
os.environ["LLM_API_KEY"] = "YOUR OPENAI_API_KEY"

&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can also set the variables by creating .env file, using our &lt;a href="https://github.com/topoteretes/cognee/raw/main/.env.template"&gt;template.&lt;/a&gt; To use different LLM providers, for more info check out our &lt;a href="https://docs.cognee.ai/setup-configuration/llm-providers"&gt;documentation&lt;/a&gt;&lt;/p&gt; 
&lt;h4&gt;Simple example&lt;/h4&gt; 
&lt;h5&gt;Python&lt;/h5&gt; 
&lt;p&gt;This script will run the default pipeline:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import cognee
import asyncio


async def main():
    # Add text to cognee
    await cognee.add("Cognee turns documents into AI memory.")

    # Generate the knowledge graph
    await cognee.cognify()

    # Add memory algorithms to the graph
    await cognee.memify()

    # Query the knowledge graph
    results = await cognee.search("What does cognee do?")

    # Display the results
    for result in results:
        print(result)


if __name__ == '__main__':
    asyncio.run(main())

&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Example output:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;  Cognee turns documents into AI memory.

&lt;/code&gt;&lt;/pre&gt; 
&lt;h5&gt;Via CLI&lt;/h5&gt; 
&lt;p&gt;Let's get the basics covered&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;cognee-cli add "Cognee turns documents into AI memory."

cognee-cli cognify

cognee-cli search "What does cognee do?"
cognee-cli delete --all

&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;or run&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;cognee-cli -ui
&lt;/code&gt;&lt;/pre&gt;  
&lt;h3&gt;Hosted Platform&lt;/h3&gt; 
&lt;p&gt;Get up and running in minutes with automatic updates, analytics, and enterprise security.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Sign up on &lt;a href="https://www.cognee.ai"&gt;cogwit&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Add your API key to local UI and sync your data to Cogwit&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Demos&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;Cogwit Beta demo:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/fa520cd2-2913-4246-a444-902ea5242cb0"&gt;Cogwit Beta&lt;/a&gt;&lt;/p&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Simple GraphRAG demo&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/d80b0776-4eb9-4b8e-aa22-3691e2d44b8f"&gt;Simple GraphRAG demo&lt;/a&gt;&lt;/p&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt;cognee with Ollama&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/8621d3e8-ecb8-4860-afb2-5594f2ee17db"&gt;cognee with local models&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Your contributions are at the core of making this a true open source project. Any contributions you make are &lt;strong&gt;greatly appreciated&lt;/strong&gt;. See &lt;a href="https://raw.githubusercontent.com/topoteretes/cognee/main/CONTRIBUTING.md"&gt;&lt;code&gt;CONTRIBUTING.md&lt;/code&gt;&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;h2&gt;Code of Conduct&lt;/h2&gt; 
&lt;p&gt;We are committed to making open source an enjoyable and respectful experience for our community. See &lt;a href="https://github.com/topoteretes/cognee/raw/main/CODE_OF_CONDUCT.md"&gt;&lt;code&gt;CODE_OF_CONDUCT&lt;/code&gt;&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;h2&gt;Citation&lt;/h2&gt; 
&lt;p&gt;We now have a paper you can cite:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bibtex"&gt;@misc{markovic2025optimizinginterfaceknowledgegraphs,
      title={Optimizing the Interface Between Knowledge Graphs and LLMs for Complex Reasoning}, 
      author={Vasilije Markovic and Lazar Obradovic and Laszlo Hajdu and Jovan Pavlovic},
      year={2025},
      eprint={2505.24478},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2505.24478}, 
}
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>lfnovo/open-notebook</title>
      <link>https://github.com/lfnovo/open-notebook</link>
      <description>&lt;p&gt;An Open Source implementation of Notebook LM with more flexibility and features&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a id="readme-top"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;!-- [![Contributors][contributors-shield]][contributors-url] --&gt; 
&lt;p&gt;&lt;a href="https://github.com/lfnovo/open-notebook/network/members"&gt;&lt;img src="https://img.shields.io/github/forks/lfnovo/open-notebook.svg?style=for-the-badge" alt="Forks" /&gt;&lt;/a&gt; &lt;a href="https://github.com/lfnovo/open-notebook/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/lfnovo/open-notebook.svg?style=for-the-badge" alt="Stargazers" /&gt;&lt;/a&gt; &lt;a href="https://github.com/lfnovo/open-notebook/issues"&gt;&lt;img src="https://img.shields.io/github/issues/lfnovo/open-notebook.svg?style=for-the-badge" alt="Issues" /&gt;&lt;/a&gt; &lt;a href="https://github.com/lfnovo/open-notebook/raw/master/LICENSE.txt"&gt;&lt;img src="https://img.shields.io/github/license/lfnovo/open-notebook.svg?style=for-the-badge" alt="MIT License" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;!-- [![LinkedIn][linkedin-shield]][linkedin-url] --&gt; 
&lt;!-- PROJECT LOGO --&gt; 
&lt;br /&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://github.com/lfnovo/open-notebook"&gt; &lt;img src="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/assets/hero.svg?sanitize=true" alt="Logo" /&gt; &lt;/a&gt; 
 &lt;h3 align="center"&gt;Open Notebook&lt;/h3&gt; 
 &lt;p align="center"&gt; An open source, privacy-focused alternative to Google's Notebook LM! &lt;br /&gt;&lt;strong&gt;Join our &lt;a href="https://discord.gg/37XJPXfz2w"&gt;Discord server&lt;/a&gt; for help, to share workflow ideas, and suggest features!&lt;/strong&gt; &lt;br /&gt; &lt;a href="https://www.open-notebook.ai"&gt;&lt;strong&gt;Checkout our website »&lt;/strong&gt;&lt;/a&gt; &lt;br /&gt; &lt;br /&gt; &lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/getting-started/index.md"&gt;📚 Get Started&lt;/a&gt; · &lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/user-guide/index.md"&gt;📖 User Guide&lt;/a&gt; · &lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/features/index.md"&gt;✨ Features&lt;/a&gt; · &lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/deployment/index.md"&gt;🚀 Deploy&lt;/a&gt; &lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;📢 Open Notebook is under very active development&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Open Notebook is under active development! We're moving fast and making improvements every week. Your feedback is incredibly valuable to me during this exciting phase and it gives me motivation to keep improving and building this amazing tool. Please feel free to star the project if you find it useful, and don't hesitate to reach out with any questions or suggestions. I'm excited to see how you'll use it and what ideas you'll bring to the project! Let's build something amazing together! 🚀&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;About The Project&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/assets/asset_list.png" alt="New Notebook" /&gt;&lt;/p&gt; 
&lt;p&gt;An open source, privacy-focused alternative to Google's Notebook LM. Why give Google more of our data when we can take control of our own research workflows?&lt;/p&gt; 
&lt;p&gt;In a world dominated by Artificial Intelligence, having the ability to think 🧠 and acquire new knowledge 💡, is a skill that should not be a privilege for a few, nor restricted to a single provider.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Open Notebook empowers you to:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;🔒 &lt;strong&gt;Control your data&lt;/strong&gt; - Keep your research private and secure&lt;/li&gt; 
 &lt;li&gt;🤖 &lt;strong&gt;Choose your AI models&lt;/strong&gt; - Support for 16+ providers including OpenAI, Anthropic, Ollama, LM Studio, and more&lt;/li&gt; 
 &lt;li&gt;📚 &lt;strong&gt;Organize multi-modal content&lt;/strong&gt; - PDFs, videos, audio, web pages, and more&lt;/li&gt; 
 &lt;li&gt;🎙️ &lt;strong&gt;Generate professional podcasts&lt;/strong&gt; - Advanced multi-speaker podcast generation&lt;/li&gt; 
 &lt;li&gt;🔍 &lt;strong&gt;Search intelligently&lt;/strong&gt; - Full-text and vector search across all your content&lt;/li&gt; 
 &lt;li&gt;💬 &lt;strong&gt;Chat with context&lt;/strong&gt; - AI conversations powered by your research&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Learn more about our project at &lt;a href="https://www.open-notebook.ai"&gt;https://www.open-notebook.ai&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;🆚 Open Notebook vs Google Notebook LM&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Feature&lt;/th&gt; 
   &lt;th&gt;Open Notebook&lt;/th&gt; 
   &lt;th&gt;Google Notebook LM&lt;/th&gt; 
   &lt;th&gt;Advantage&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Privacy &amp;amp; Control&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Self-hosted, your data&lt;/td&gt; 
   &lt;td&gt;Google cloud only&lt;/td&gt; 
   &lt;td&gt;Complete data sovereignty&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;AI Provider Choice&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;16+ providers (OpenAI, Anthropic, Ollama, LM Studio, etc.)&lt;/td&gt; 
   &lt;td&gt;Google models only&lt;/td&gt; 
   &lt;td&gt;Flexibility and cost optimization&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Podcast Speakers&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;1-4 speakers with custom profiles&lt;/td&gt; 
   &lt;td&gt;2 speakers only&lt;/td&gt; 
   &lt;td&gt;Extreme flexibility&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Context Control&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;3 granular levels&lt;/td&gt; 
   &lt;td&gt;All-or-nothing&lt;/td&gt; 
   &lt;td&gt;Privacy and performance tuning&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Content Transformations&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Custom and built-in&lt;/td&gt; 
   &lt;td&gt;Limited options&lt;/td&gt; 
   &lt;td&gt;Unlimited processing power&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;API Access&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Full REST API&lt;/td&gt; 
   &lt;td&gt;No API&lt;/td&gt; 
   &lt;td&gt;Complete automation&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Deployment&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Docker, cloud, or local&lt;/td&gt; 
   &lt;td&gt;Google hosted only&lt;/td&gt; 
   &lt;td&gt;Deploy anywhere&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Citations&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Comprehensive with sources&lt;/td&gt; 
   &lt;td&gt;Basic references&lt;/td&gt; 
   &lt;td&gt;Research integrity&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Customization&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Open source, fully customizable&lt;/td&gt; 
   &lt;td&gt;Closed system&lt;/td&gt; 
   &lt;td&gt;Unlimited extensibility&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Cost&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Pay only for AI usage&lt;/td&gt; 
   &lt;td&gt;Monthly subscription + usage&lt;/td&gt; 
   &lt;td&gt;Transparent and controllable&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;Why Choose Open Notebook?&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;🔒 &lt;strong&gt;Privacy First&lt;/strong&gt;: Your sensitive research stays completely private&lt;/li&gt; 
 &lt;li&gt;💰 &lt;strong&gt;Cost Control&lt;/strong&gt;: Choose cheaper AI providers or run locally with Ollama&lt;/li&gt; 
 &lt;li&gt;🎙️ &lt;strong&gt;Better Podcasts&lt;/strong&gt;: Full script control and multi-speaker flexibility vs limited 2-speaker deep-dive format&lt;/li&gt; 
 &lt;li&gt;🔧 &lt;strong&gt;Unlimited Customization&lt;/strong&gt;: Modify, extend, and integrate as needed&lt;/li&gt; 
 &lt;li&gt;🌐 &lt;strong&gt;No Vendor Lock-in&lt;/strong&gt;: Switch providers, deploy anywhere, own your data&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Built With&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://www.python.org/"&gt;&lt;img src="https://img.shields.io/badge/Python-3776AB?style=for-the-badge&amp;amp;logo=python&amp;amp;logoColor=white" alt="Python" /&gt;&lt;/a&gt; &lt;a href="https://surrealdb.com/"&gt;&lt;img src="https://img.shields.io/badge/SurrealDB-FF5E00?style=for-the-badge&amp;amp;logo=databricks&amp;amp;logoColor=white" alt="SurrealDB" /&gt;&lt;/a&gt; &lt;a href="https://www.langchain.com/"&gt;&lt;img src="https://img.shields.io/badge/LangChain-3A3A3A?style=for-the-badge&amp;amp;logo=chainlink&amp;amp;logoColor=white" alt="LangChain" /&gt;&lt;/a&gt; &lt;a href="https://streamlit.io/"&gt;&lt;img src="https://img.shields.io/badge/Streamlit-FF4B4B?style=for-the-badge&amp;amp;logo=streamlit&amp;amp;logoColor=white" alt="Streamlit" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;🚀 Quick Start&lt;/h2&gt; 
&lt;p&gt;Ready to try Open Notebook? Choose your preferred method:&lt;/p&gt; 
&lt;h3&gt;⚡ Instant Setup (Recommended)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Create a new directory for your Open Notebook installation
mkdir open-notebook
cd open-notebook

# Using Docker - Get started in 2 minutes
docker run -d \
  --name open-notebook \
  -p 8502:8502 -p 5055:5055 \
  -v ./notebook_data:/app/data \
  -v ./surreal_data:/mydata \
  -e OPENAI_API_KEY=your_key \
  lfnovo/open_notebook:latest-single
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;What gets created:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;open-notebook/
├── notebook_data/     # Your notebooks and research content
└── surreal_data/      # Database files
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Access your installation:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;🖥️ Main Interface&lt;/strong&gt;: &lt;a href="http://localhost:8502"&gt;http://localhost:8502&lt;/a&gt; (Streamlit UI)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;🔧 API Access&lt;/strong&gt;: &lt;a href="http://localhost:5055"&gt;http://localhost:5055&lt;/a&gt; (REST API)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;📚 API Documentation&lt;/strong&gt;: &lt;a href="http://localhost:5055/docs"&gt;http://localhost:5055/docs&lt;/a&gt; (Interactive Swagger UI)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;⚠️ Important&lt;/strong&gt;:&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;&lt;strong&gt;Run from a dedicated folder&lt;/strong&gt;: Create and run this from inside a new &lt;code&gt;open-notebook&lt;/code&gt; folder so your data volumes are properly organized&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Volume persistence&lt;/strong&gt;: The volumes (&lt;code&gt;-v ./notebook_data:/app/data&lt;/code&gt; and &lt;code&gt;-v ./surreal_data:/mydata&lt;/code&gt;) are essential to persist your data between container restarts. Without them, you'll lose all your notebooks and research when the container stops.&lt;/li&gt; 
 &lt;/ol&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;🛠️ Full Installation&lt;/h3&gt; 
&lt;p&gt;For development or customization:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/lfnovo/open-notebook
cd open-notebook
make start-all
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;📖 Need Help?&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;🤖 AI Installation Assistant&lt;/strong&gt;: We have a &lt;a href="https://chatgpt.com/g/g-68776e2765b48191bd1bae3f30212631-open-notebook-installation-assistant"&gt;CustomGPT built to help you install Open Notebook&lt;/a&gt; - it will guide you through each step!&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;New to Open Notebook?&lt;/strong&gt; Start with our &lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/getting-started/index.md"&gt;Getting Started Guide&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Need installation help?&lt;/strong&gt; Check our &lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/getting-started/installation.md"&gt;Installation Guide&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Want to see it in action?&lt;/strong&gt; Try our &lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/getting-started/quick-start.md"&gt;Quick Start Tutorial&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Provider Support Matrix&lt;/h2&gt; 
&lt;p&gt;Thanks to the &lt;a href="https://github.com/lfnovo/esperanto"&gt;Esperanto&lt;/a&gt; library, we support this providers out of the box!&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Provider&lt;/th&gt; 
   &lt;th&gt;LLM Support&lt;/th&gt; 
   &lt;th&gt;Embedding Support&lt;/th&gt; 
   &lt;th&gt;Speech-to-Text&lt;/th&gt; 
   &lt;th&gt;Text-to-Speech&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;OpenAI&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Anthropic&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;❌&lt;/td&gt; 
   &lt;td&gt;❌&lt;/td&gt; 
   &lt;td&gt;❌&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Groq&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;❌&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;❌&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Google (GenAI)&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;❌&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Vertex AI&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;❌&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Ollama&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;❌&lt;/td&gt; 
   &lt;td&gt;❌&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Perplexity&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;❌&lt;/td&gt; 
   &lt;td&gt;❌&lt;/td&gt; 
   &lt;td&gt;❌&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ElevenLabs&lt;/td&gt; 
   &lt;td&gt;❌&lt;/td&gt; 
   &lt;td&gt;❌&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Azure OpenAI&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;❌&lt;/td&gt; 
   &lt;td&gt;❌&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Mistral&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;❌&lt;/td&gt; 
   &lt;td&gt;❌&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;DeepSeek&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;❌&lt;/td&gt; 
   &lt;td&gt;❌&lt;/td&gt; 
   &lt;td&gt;❌&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Voyage&lt;/td&gt; 
   &lt;td&gt;❌&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;❌&lt;/td&gt; 
   &lt;td&gt;❌&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;xAI&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;❌&lt;/td&gt; 
   &lt;td&gt;❌&lt;/td&gt; 
   &lt;td&gt;❌&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;OpenRouter&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;❌&lt;/td&gt; 
   &lt;td&gt;❌&lt;/td&gt; 
   &lt;td&gt;❌&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;OpenAI Compatible*&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;❌&lt;/td&gt; 
   &lt;td&gt;❌&lt;/td&gt; 
   &lt;td&gt;❌&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;*Supports LM Studio and any OpenAI-compatible endpoint&lt;/p&gt; 
&lt;h2&gt;✨ Key Features&lt;/h2&gt; 
&lt;h3&gt;Core Capabilities&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;🔒 Privacy-First&lt;/strong&gt;: Your data stays under your control - no cloud dependencies&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;🎯 Multi-Notebook Organization&lt;/strong&gt;: Manage multiple research projects seamlessly&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;📚 Universal Content Support&lt;/strong&gt;: PDFs, videos, audio, web pages, Office docs, and more&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;🤖 Multi-Model AI Support&lt;/strong&gt;: 16+ providers including OpenAI, Anthropic, Ollama, Google, LM Studio, and more&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;🎙️ Professional Podcast Generation&lt;/strong&gt;: Advanced multi-speaker podcasts with Episode Profiles&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;🔍 Intelligent Search&lt;/strong&gt;: Full-text and vector search across all your content&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;💬 Context-Aware Chat&lt;/strong&gt;: AI conversations powered by your research materials&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;📝 AI-Assisted Notes&lt;/strong&gt;: Generate insights or write notes manually&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Advanced Features&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;⚡ Reasoning Model Support&lt;/strong&gt;: Full support for thinking models like DeepSeek-R1 and Qwen3&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;🔧 Content Transformations&lt;/strong&gt;: Powerful customizable actions to summarize and extract insights&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;🌐 Comprehensive REST API&lt;/strong&gt;: Full programmatic access for custom integrations &lt;a href="http://localhost:5055/docs"&gt;&lt;img src="https://img.shields.io/badge/API-Documentation-blue?style=flat-square" alt="API Docs" /&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;🔐 Optional Password Protection&lt;/strong&gt;: Secure public deployments with authentication&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;📊 Fine-Grained Context Control&lt;/strong&gt;: Choose exactly what to share with AI models&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;📎 Citations&lt;/strong&gt;: Get answers with proper source citations&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Three-Column Interface&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Sources&lt;/strong&gt;: Manage all your research materials&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Notes&lt;/strong&gt;: Create manual or AI-generated notes&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Chat&lt;/strong&gt;: Converse with AI using your content as context&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=D-760MlGwaI"&gt;&lt;img src="https://img.youtube.com/vi/D-760MlGwaI/0.jpg" alt="Check out our podcast sample" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;📚 Documentation&lt;/h2&gt; 
&lt;h3&gt;Getting Started&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/getting-started/introduction.md"&gt;📖 Introduction&lt;/a&gt;&lt;/strong&gt; - Learn what Open Notebook offers&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/getting-started/quick-start.md"&gt;⚡ Quick Start&lt;/a&gt;&lt;/strong&gt; - Get up and running in 5 minutes&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/getting-started/installation.md"&gt;🔧 Installation&lt;/a&gt;&lt;/strong&gt; - Comprehensive setup guide&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/getting-started/first-notebook.md"&gt;🎯 Your First Notebook&lt;/a&gt;&lt;/strong&gt; - Step-by-step tutorial&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;User Guide&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/user-guide/interface-overview.md"&gt;📱 Interface Overview&lt;/a&gt;&lt;/strong&gt; - Understanding the layout&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/user-guide/notebooks.md"&gt;📚 Notebooks&lt;/a&gt;&lt;/strong&gt; - Organizing your research&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/user-guide/sources.md"&gt;📄 Sources&lt;/a&gt;&lt;/strong&gt; - Managing content types&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/user-guide/notes.md"&gt;📝 Notes&lt;/a&gt;&lt;/strong&gt; - Creating and managing notes&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/user-guide/chat.md"&gt;💬 Chat&lt;/a&gt;&lt;/strong&gt; - AI conversations&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/user-guide/search.md"&gt;🔍 Search&lt;/a&gt;&lt;/strong&gt; - Finding information&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Advanced Topics&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/features/podcasts.md"&gt;🎙️ Podcast Generation&lt;/a&gt;&lt;/strong&gt; - Create professional podcasts&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/features/transformations.md"&gt;🔧 Content Transformations&lt;/a&gt;&lt;/strong&gt; - Customize content processing&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/features/ai-models.md"&gt;🤖 AI Models&lt;/a&gt;&lt;/strong&gt; - AI model configuration&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/development/api-reference.md"&gt;🔧 REST API Reference&lt;/a&gt;&lt;/strong&gt; - Complete API documentation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/deployment/security.md"&gt;🔐 Security&lt;/a&gt;&lt;/strong&gt; - Password protection and privacy&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/deployment/index.md"&gt;🚀 Deployment&lt;/a&gt;&lt;/strong&gt; - Complete deployment guides for all scenarios&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p align="right"&gt;(&lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/#readme-top"&gt;back to top&lt;/a&gt;)&lt;/p&gt; 
&lt;h2&gt;🗺️ Roadmap&lt;/h2&gt; 
&lt;h3&gt;Upcoming Features&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;React Frontend&lt;/strong&gt;: Modern React-based frontend to replace Streamlit&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Live Front-End Updates&lt;/strong&gt;: Real-time UI updates for smoother experience&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Async Processing&lt;/strong&gt;: Faster UI through asynchronous content processing&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Cross-Notebook Sources&lt;/strong&gt;: Reuse research materials across projects&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Bookmark Integration&lt;/strong&gt;: Connect with your favorite bookmarking apps&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Recently Completed ✅&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Comprehensive REST API&lt;/strong&gt;: Full programmatic access to all functionality&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Multi-Model Support&lt;/strong&gt;: 16+ AI providers including OpenAI, Anthropic, Ollama, LM Studio&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Advanced Podcast Generator&lt;/strong&gt;: Professional multi-speaker podcasts with Episode Profiles&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Content Transformations&lt;/strong&gt;: Powerful customizable actions for content processing&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Enhanced Citations&lt;/strong&gt;: Improved layout and finer control for source citations&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Multiple Chat Sessions&lt;/strong&gt;: Manage different conversations within notebooks&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;See the &lt;a href="https://github.com/lfnovo/open-notebook/issues"&gt;open issues&lt;/a&gt; for a full list of proposed features and known issues.&lt;/p&gt; 
&lt;p align="right"&gt;(&lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/#readme-top"&gt;back to top&lt;/a&gt;)&lt;/p&gt; 
&lt;h2&gt;🤝 Community &amp;amp; Contributing&lt;/h2&gt; 
&lt;h3&gt;Join the Community&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;💬 &lt;strong&gt;&lt;a href="https://discord.gg/37XJPXfz2w"&gt;Discord Server&lt;/a&gt;&lt;/strong&gt; - Get help, share ideas, and connect with other users&lt;/li&gt; 
 &lt;li&gt;🐛 &lt;strong&gt;&lt;a href="https://github.com/lfnovo/open-notebook/issues"&gt;GitHub Issues&lt;/a&gt;&lt;/strong&gt; - Report bugs and request features&lt;/li&gt; 
 &lt;li&gt;⭐ &lt;strong&gt;Star this repo&lt;/strong&gt; - Show your support and help others discover Open Notebook&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Contributing&lt;/h3&gt; 
&lt;p&gt;We welcome contributions! We're especially looking for help with:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Frontend Development&lt;/strong&gt;: Help build a modern React-based UI (planned replacement for current Streamlit interface)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Testing &amp;amp; Bug Fixes&lt;/strong&gt;: Make Open Notebook more robust&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Feature Development&lt;/strong&gt;: Build the coolest research tool together&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Documentation&lt;/strong&gt;: Improve guides and tutorials&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Current Tech Stack&lt;/strong&gt;: Python, FastAPI, SurrealDB, Streamlit&lt;br /&gt; &lt;strong&gt;Future Roadmap&lt;/strong&gt;: React frontend, enhanced real-time updates&lt;/p&gt; 
&lt;p&gt;See our &lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/CONTRIBUTING.md"&gt;Contributing Guide&lt;/a&gt; for detailed information on how to get started.&lt;/p&gt; 
&lt;p align="right"&gt;(&lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/#readme-top"&gt;back to top&lt;/a&gt;)&lt;/p&gt; 
&lt;h2&gt;📄 License&lt;/h2&gt; 
&lt;p&gt;Open Notebook is MIT licensed. See the &lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/LICENSE"&gt;LICENSE&lt;/a&gt; file for details.&lt;/p&gt; 
&lt;h2&gt;📞 Contact&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Luis Novo&lt;/strong&gt; - &lt;a href="https://twitter.com/lfnovo"&gt;@lfnovo&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Community Support&lt;/strong&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;💬 &lt;a href="https://discord.gg/37XJPXfz2w"&gt;Discord Server&lt;/a&gt; - Get help, share ideas, and connect with users&lt;/li&gt; 
 &lt;li&gt;🐛 &lt;a href="https://github.com/lfnovo/open-notebook/issues"&gt;GitHub Issues&lt;/a&gt; - Report bugs and request features&lt;/li&gt; 
 &lt;li&gt;🌐 &lt;a href="https://www.open-notebook.ai"&gt;Website&lt;/a&gt; - Learn more about the project&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;🙏 Acknowledgments&lt;/h2&gt; 
&lt;p&gt;Open Notebook is built on the shoulders of amazing open-source projects:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/lfnovo/podcast-creator"&gt;Podcast Creator&lt;/a&gt;&lt;/strong&gt; - Advanced podcast generation capabilities&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/lfnovo/surreal-commands"&gt;Surreal Commands&lt;/a&gt;&lt;/strong&gt; - Background job processing&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/lfnovo/content-core"&gt;Content Core&lt;/a&gt;&lt;/strong&gt; - Content processing and management&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/lfnovo/esperanto"&gt;Esperanto&lt;/a&gt;&lt;/strong&gt; - Multi-provider AI model abstraction&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/docling-project/docling"&gt;Docling&lt;/a&gt;&lt;/strong&gt; - Document processing and parsing&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p align="right"&gt;(&lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/#readme-top"&gt;back to top&lt;/a&gt;)&lt;/p&gt; 
&lt;!-- MARKDOWN LINKS &amp; IMAGES --&gt; 
&lt;!-- https://www.markdownguide.org/basic-syntax/#reference-style-links --&gt;</description>
    </item>
    
    <item>
      <title>commaai/openpilot</title>
      <link>https://github.com/commaai/openpilot</link>
      <description>&lt;p&gt;openpilot is an operating system for robotics. Currently, it upgrades the driver assistance system on 300+ supported cars.&lt;/p&gt;&lt;hr&gt;&lt;div align="center" style="text-align: center;"&gt; 
 &lt;h1&gt;openpilot&lt;/h1&gt; 
 &lt;p&gt; &lt;b&gt;openpilot is an operating system for robotics.&lt;/b&gt; &lt;br /&gt; Currently, it upgrades the driver assistance system in 300+ supported cars. &lt;/p&gt; 
 &lt;h3&gt; &lt;a href="https://docs.comma.ai"&gt;Docs&lt;/a&gt; &lt;span&gt; · &lt;/span&gt; &lt;a href="https://docs.comma.ai/contributing/roadmap/"&gt;Roadmap&lt;/a&gt; &lt;span&gt; · &lt;/span&gt; &lt;a href="https://github.com/commaai/openpilot/raw/master/docs/CONTRIBUTING.md"&gt;Contribute&lt;/a&gt; &lt;span&gt; · &lt;/span&gt; &lt;a href="https://discord.comma.ai"&gt;Community&lt;/a&gt; &lt;span&gt; · &lt;/span&gt; &lt;a href="https://comma.ai/shop"&gt;Try it on a comma 3X&lt;/a&gt; &lt;/h3&gt; 
 &lt;p&gt;Quick start: &lt;code&gt;bash &amp;lt;(curl -fsSL openpilot.comma.ai)&lt;/code&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://github.com/commaai/openpilot/actions/workflows/selfdrive_tests.yaml"&gt;&lt;img src="https://github.com/commaai/openpilot/actions/workflows/selfdrive_tests.yaml/badge.svg?sanitize=true" alt="openpilot tests" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/commaai/openpilot/master/LICENSE"&gt;&lt;img src="https://img.shields.io/badge/License-MIT-yellow.svg?sanitize=true" alt="License: MIT" /&gt;&lt;/a&gt; &lt;a href="https://x.com/comma_ai"&gt;&lt;img src="https://img.shields.io/twitter/follow/comma_ai" alt="X Follow" /&gt;&lt;/a&gt; &lt;a href="https://discord.comma.ai"&gt;&lt;img src="https://img.shields.io/discord/469524606043160576" alt="Discord" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://youtu.be/NmBfgOanCyk" title="Video By Greer Viau"&gt;&lt;img src="https://github.com/commaai/openpilot/assets/8762862/2f7112ae-f748-4f39-b617-fabd689c3772" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://youtu.be/VHKyqZ7t8Gw" title="Video By Logan LeGrand"&gt;&lt;img src="https://github.com/commaai/openpilot/assets/8762862/92351544-2833-40d7-9e0b-7ef7ae37ec4c" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://youtu.be/SUIZYzxtMQs" title="A drive to Taco Bell"&gt;&lt;img src="https://github.com/commaai/openpilot/assets/8762862/05ceefc5-2628-439c-a9b2-89ce77dc6f63" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h2&gt;Using openpilot in a car&lt;/h2&gt; 
&lt;p&gt;To use openpilot in a car, you need four things:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Supported Device:&lt;/strong&gt; a comma 3X, available at &lt;a href="https://comma.ai/shop/comma-3x"&gt;comma.ai/shop&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Software:&lt;/strong&gt; The setup procedure for the comma 3X allows users to enter a URL for custom software. Use the URL &lt;code&gt;openpilot.comma.ai&lt;/code&gt; to install the release version.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Supported Car:&lt;/strong&gt; Ensure that you have one of &lt;a href="https://raw.githubusercontent.com/commaai/openpilot/master/docs/CARS.md"&gt;the 275+ supported cars&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Car Harness:&lt;/strong&gt; You will also need a &lt;a href="https://comma.ai/shop/car-harness"&gt;car harness&lt;/a&gt; to connect your comma 3X to your car.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;We have detailed instructions for &lt;a href="https://comma.ai/setup"&gt;how to install the harness and device in a car&lt;/a&gt;. Note that it's possible to run openpilot on &lt;a href="https://blog.comma.ai/self-driving-car-for-free/"&gt;other hardware&lt;/a&gt;, although it's not plug-and-play.&lt;/p&gt; 
&lt;h3&gt;Branches&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;branch&lt;/th&gt; 
   &lt;th&gt;URL&lt;/th&gt; 
   &lt;th&gt;description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;release3&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;openpilot.comma.ai&lt;/td&gt; 
   &lt;td&gt;This is openpilot's release branch.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;release3-staging&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;openpilot-test.comma.ai&lt;/td&gt; 
   &lt;td&gt;This is the staging branch for releases. Use it to get new releases slightly early.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;nightly&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;openpilot-nightly.comma.ai&lt;/td&gt; 
   &lt;td&gt;This is the bleeding edge development branch. Do not expect this to be stable.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;nightly-dev&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;installer.comma.ai/commaai/nightly-dev&lt;/td&gt; 
   &lt;td&gt;Same as nightly, but includes experimental development features for some cars.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;To start developing openpilot&lt;/h2&gt; 
&lt;p&gt;openpilot is developed by &lt;a href="https://comma.ai/"&gt;comma&lt;/a&gt; and by users like you. We welcome both pull requests and issues on &lt;a href="http://github.com/commaai/openpilot"&gt;GitHub&lt;/a&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Join the &lt;a href="https://discord.comma.ai"&gt;community Discord&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Check out &lt;a href="https://raw.githubusercontent.com/commaai/openpilot/master/docs/CONTRIBUTING.md"&gt;the contributing docs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Check out the &lt;a href="https://raw.githubusercontent.com/commaai/openpilot/master/tools/"&gt;openpilot tools&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Code documentation lives at &lt;a href="https://docs.comma.ai"&gt;https://docs.comma.ai&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Information about running openpilot lives on the &lt;a href="https://github.com/commaai/openpilot/wiki"&gt;community wiki&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Want to get paid to work on openpilot? &lt;a href="https://comma.ai/jobs#open-positions"&gt;comma is hiring&lt;/a&gt; and offers lots of &lt;a href="https://comma.ai/bounties"&gt;bounties&lt;/a&gt; for external contributors.&lt;/p&gt; 
&lt;h2&gt;Safety and Testing&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;openpilot observes &lt;a href="https://en.wikipedia.org/wiki/ISO_26262"&gt;ISO26262&lt;/a&gt; guidelines, see &lt;a href="https://raw.githubusercontent.com/commaai/openpilot/master/docs/SAFETY.md"&gt;SAFETY.md&lt;/a&gt; for more details.&lt;/li&gt; 
 &lt;li&gt;openpilot has software-in-the-loop &lt;a href="https://raw.githubusercontent.com/commaai/openpilot/master/.github/workflows/selfdrive_tests.yaml"&gt;tests&lt;/a&gt; that run on every commit.&lt;/li&gt; 
 &lt;li&gt;The code enforcing the safety model lives in panda and is written in C, see &lt;a href="https://github.com/commaai/panda#code-rigor"&gt;code rigor&lt;/a&gt; for more details.&lt;/li&gt; 
 &lt;li&gt;panda has software-in-the-loop &lt;a href="https://github.com/commaai/panda/tree/master/tests/safety"&gt;safety tests&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Internally, we have a hardware-in-the-loop Jenkins test suite that builds and unit tests the various processes.&lt;/li&gt; 
 &lt;li&gt;panda has additional hardware-in-the-loop &lt;a href="https://github.com/commaai/panda/raw/master/Jenkinsfile"&gt;tests&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;We run the latest openpilot in a testing closet containing 10 comma devices continuously replaying routes.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;details&gt; 
 &lt;summary&gt;MIT Licensed&lt;/summary&gt; 
 &lt;p&gt;openpilot is released under the MIT license. Some parts of the software are released under other licenses as specified.&lt;/p&gt; 
 &lt;p&gt;Any user of this software shall indemnify and hold harmless Comma.ai, Inc. and its directors, officers, employees, agents, stockholders, affiliates, subcontractors and customers from and against all allegations, claims, actions, suits, demands, damages, liabilities, obligations, losses, settlements, judgments, costs and expenses (including without limitation attorneys’ fees and costs) which arise out of, relate to or result from any use of this software by user.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;THIS IS ALPHA QUALITY SOFTWARE FOR RESEARCH PURPOSES ONLY. THIS IS NOT A PRODUCT. YOU ARE RESPONSIBLE FOR COMPLYING WITH LOCAL LAWS AND REGULATIONS. NO WARRANTY EXPRESSED OR IMPLIED.&lt;/strong&gt;&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;User Data and comma Account&lt;/summary&gt; 
 &lt;p&gt;By default, openpilot uploads the driving data to our servers. You can also access your data through &lt;a href="https://connect.comma.ai/"&gt;comma connect&lt;/a&gt;. We use your data to train better models and improve openpilot for everyone.&lt;/p&gt; 
 &lt;p&gt;openpilot is open source software: the user is free to disable data collection if they wish to do so.&lt;/p&gt; 
 &lt;p&gt;openpilot logs the road-facing cameras, CAN, GPS, IMU, magnetometer, thermal sensors, crashes, and operating system logs. The driver-facing camera and microphone are only logged if you explicitly opt-in in settings.&lt;/p&gt; 
 &lt;p&gt;By using openpilot, you agree to &lt;a href="https://comma.ai/privacy"&gt;our Privacy Policy&lt;/a&gt;. You understand that use of this software or its related services will generate certain types of user data, which may be logged and stored at the sole discretion of comma. By accepting this agreement, you grant an irrevocable, perpetual, worldwide right to comma for the use of this data.&lt;/p&gt; 
&lt;/details&gt;</description>
    </item>
    
    <item>
      <title>jsvine/pdfplumber</title>
      <link>https://github.com/jsvine/pdfplumber</link>
      <description>&lt;p&gt;Plumb a PDF for detailed information about each char, rectangle, line, et cetera — and easily extract text and tables.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;pdfplumber&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://pypi.python.org/pypi/pdfplumber"&gt;&lt;img src="https://img.shields.io/pypi/v/pdfplumber.svg?sanitize=true" alt="Version" /&gt;&lt;/a&gt; &lt;img src="https://github.com/jsvine/pdfplumber/workflows/Tests/badge.svg?sanitize=true" alt="Tests" /&gt; &lt;a href="https://codecov.io/gh/jsvine/pdfplumber/branch/stable"&gt;&lt;img src="https://codecov.io/gh/jsvine/pdfplumber/branch/stable/graph/badge.svg?sanitize=true" alt="Code coverage" /&gt;&lt;/a&gt; &lt;a href="https://pypi.python.org/pypi/pdfplumber"&gt;&lt;img src="https://img.shields.io/pypi/pyversions/pdfplumber.svg?sanitize=true" alt="Support Python versions" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Plumb a PDF for detailed information about each text character, rectangle, and line. Plus: Table extraction and visual debugging.&lt;/p&gt; 
&lt;p&gt;Works best on machine-generated, rather than scanned, PDFs. Built on &lt;a href="https://github.com/goulu/pdfminer"&gt;&lt;code&gt;pdfminer.six&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Currently &lt;a href="https://raw.githubusercontent.com/jsvine/pdfplumber/stable/tests/"&gt;tested&lt;/a&gt; on &lt;a href="https://raw.githubusercontent.com/jsvine/pdfplumber/stable/.github/workflows/tests.yml"&gt;Python 3.8, 3.9, 3.10, 3.11&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Translations of this document are available in: &lt;a href="https://github.com/hbh112233abc/pdfplumber/raw/stable/README-CN.md"&gt;Chinese (by @hbh112233abc)&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;To report a bug&lt;/strong&gt; or request a feature, please &lt;a href="https://github.com/jsvine/pdfplumber/issues/new/choose"&gt;file an issue&lt;/a&gt;. &lt;strong&gt;To ask a question&lt;/strong&gt; or request assistance with a specific PDF, please &lt;a href="https://github.com/jsvine/pdfplumber/discussions"&gt;use the discussions forum&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Table of Contents&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jsvine/pdfplumber/stable/#installation"&gt;Installation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jsvine/pdfplumber/stable/#command-line-interface"&gt;Command line interface&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jsvine/pdfplumber/stable/#python-library"&gt;Python library&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jsvine/pdfplumber/stable/#visual-debugging"&gt;Visual debugging&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jsvine/pdfplumber/stable/#extracting-text"&gt;Extracting text&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jsvine/pdfplumber/stable/#extracting-tables"&gt;Extracting tables&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jsvine/pdfplumber/stable/#extracting-form-values"&gt;Extracting form values&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jsvine/pdfplumber/stable/#demonstrations"&gt;Demonstrations&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jsvine/pdfplumber/stable/#comparison-to-other-libraries"&gt;Comparison to other libraries&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jsvine/pdfplumber/stable/#acknowledgments--contributors"&gt;Acknowledgments / Contributors&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jsvine/pdfplumber/stable/#contributing"&gt;Contributing&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;pip install pdfplumber
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Command line interface&lt;/h2&gt; 
&lt;h3&gt;Basic example&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;curl "https://raw.githubusercontent.com/jsvine/pdfplumber/stable/examples/pdfs/background-checks.pdf" &amp;gt; background-checks.pdf
pdfplumber background-checks.pdf &amp;gt; background-checks.csv
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The output will be a CSV containing info about every character, line, and rectangle in the PDF.&lt;/p&gt; 
&lt;h3&gt;Options&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Argument&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--format [format]&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;csv&lt;/code&gt;, &lt;code&gt;json&lt;/code&gt;, or &lt;code&gt;text&lt;/code&gt;. The &lt;code&gt;csv&lt;/code&gt; and &lt;code&gt;json&lt;/code&gt; formats return information about each object. Of those two, the &lt;code&gt;json&lt;/code&gt; format returns more information; it includes PDF-level and page-level metadata, plus dictionary-nested attributes. The &lt;code&gt;text&lt;/code&gt; option returns a plain-text representation of the PDF, using &lt;code&gt;Page.extract_text(layout=True)&lt;/code&gt;.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--pages [list of pages]&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;A space-delimited, &lt;code&gt;1&lt;/code&gt;-indexed list of pages or hyphenated page ranges. E.g., &lt;code&gt;1, 11-15&lt;/code&gt;, which would return data for pages 1, 11, 12, 13, 14, and 15.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--types [list of object types to extract]&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Choices are &lt;code&gt;char&lt;/code&gt;, &lt;code&gt;rect&lt;/code&gt;, &lt;code&gt;line&lt;/code&gt;, &lt;code&gt;curve&lt;/code&gt;, &lt;code&gt;image&lt;/code&gt;, &lt;code&gt;annot&lt;/code&gt;, et cetera. Defaults to all available.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--laparams&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;A JSON-formatted string (e.g., &lt;code&gt;'{"detect_vertical": true}'&lt;/code&gt;) to pass to &lt;code&gt;pdfplumber.open(..., laparams=...)&lt;/code&gt;.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--precision [integer]&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;The number of decimal places to round floating-point numbers. Defaults to no rounding.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Python library&lt;/h2&gt; 
&lt;h3&gt;Basic example&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import pdfplumber

with pdfplumber.open("path/to/file.pdf") as pdf:
    first_page = pdf.pages[0]
    print(first_page.chars[0])
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Loading a PDF&lt;/h3&gt; 
&lt;p&gt;To start working with a PDF, call &lt;code&gt;pdfplumber.open(x)&lt;/code&gt;, where &lt;code&gt;x&lt;/code&gt; can be a:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;path to your PDF file&lt;/li&gt; 
 &lt;li&gt;file object, loaded as bytes&lt;/li&gt; 
 &lt;li&gt;file-like object, loaded as bytes&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The &lt;code&gt;open&lt;/code&gt; method returns an instance of the &lt;code&gt;pdfplumber.PDF&lt;/code&gt; class.&lt;/p&gt; 
&lt;p&gt;To load a password-protected PDF, pass the &lt;code&gt;password&lt;/code&gt; keyword argument, e.g., &lt;code&gt;pdfplumber.open("file.pdf", password = "test")&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;To set layout analysis parameters to &lt;code&gt;pdfminer.six&lt;/code&gt;'s layout engine, pass the &lt;code&gt;laparams&lt;/code&gt; keyword argument, e.g., &lt;code&gt;pdfplumber.open("file.pdf", laparams = { "line_overlap": 0.7 })&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;To &lt;a href="https://unicode.org/reports/tr15/"&gt;pre-normalize Unicode text&lt;/a&gt;, pass &lt;code&gt;unicode_norm=...&lt;/code&gt;, where &lt;code&gt;...&lt;/code&gt; is one of the &lt;a href="https://unicode.org/reports/tr15/#Normalization_Forms_Table"&gt;four Unicode normalization forms&lt;/a&gt;: &lt;code&gt;"NFC"&lt;/code&gt;, &lt;code&gt;"NFD"&lt;/code&gt;, &lt;code&gt;"NFKC"&lt;/code&gt;, or &lt;code&gt;"NFKD"&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Invalid metadata values are treated as a warning by default. If that is not intended, pass &lt;code&gt;strict_metadata=True&lt;/code&gt; to the &lt;code&gt;open&lt;/code&gt; method and &lt;code&gt;pdfplumber.open&lt;/code&gt; will raise an exception if it is unable to parse the metadata.&lt;/p&gt; 
&lt;h3&gt;The &lt;code&gt;pdfplumber.PDF&lt;/code&gt; class&lt;/h3&gt; 
&lt;p&gt;The top-level &lt;code&gt;pdfplumber.PDF&lt;/code&gt; class represents a single PDF and has two main properties:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Property&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;.metadata&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;A dictionary of metadata key/value pairs, drawn from the PDF's &lt;code&gt;Info&lt;/code&gt; trailers. Typically includes "CreationDate," "ModDate," "Producer," et cetera.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;.pages&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;A list containing one &lt;code&gt;pdfplumber.Page&lt;/code&gt; instance per page loaded.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;... and also has the following method:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Method&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;.close()&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Calling this method calls &lt;code&gt;Page.close()&lt;/code&gt; on each page, and also closes the file stream (except in cases when the stream is external, i.e., already opened and passed directly to &lt;code&gt;pdfplumber&lt;/code&gt;).&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;The &lt;code&gt;pdfplumber.Page&lt;/code&gt; class&lt;/h3&gt; 
&lt;p&gt;The &lt;code&gt;pdfplumber.Page&lt;/code&gt; class is at the core of &lt;code&gt;pdfplumber&lt;/code&gt;. Most things you'll do with &lt;code&gt;pdfplumber&lt;/code&gt; will revolve around this class. It has these main properties:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Property&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;.page_number&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;The sequential page number, starting with &lt;code&gt;1&lt;/code&gt; for the first page, &lt;code&gt;2&lt;/code&gt; for the second, and so on.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;.width&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;The page's width.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;.height&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;The page's height.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;.objects&lt;/code&gt; / &lt;code&gt;.chars&lt;/code&gt; / &lt;code&gt;.lines&lt;/code&gt; / &lt;code&gt;.rects&lt;/code&gt; / &lt;code&gt;.curves&lt;/code&gt; / &lt;code&gt;.images&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Each of these properties is a list, and each list contains one dictionary for each such object embedded on the page. For more detail, see "&lt;a href="https://raw.githubusercontent.com/jsvine/pdfplumber/stable/#objects"&gt;Objects&lt;/a&gt;" below.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;... and these main methods:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Method&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;.crop(bounding_box, relative=False, strict=True)&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Returns a version of the page cropped to the bounding box, which should be expressed as 4-tuple with the values &lt;code&gt;(x0, top, x1, bottom)&lt;/code&gt;. Cropped pages retain objects that fall at least partly within the bounding box. If an object falls only partly within the box, its dimensions are sliced to fit the bounding box. If &lt;code&gt;relative=True&lt;/code&gt;, the bounding box is calculated as an offset from the top-left of the page's bounding box, rather than an absolute positioning. (See &lt;a href="https://github.com/jsvine/pdfplumber/issues/245"&gt;Issue #245&lt;/a&gt; for a visual example and explanation.) When &lt;code&gt;strict=True&lt;/code&gt; (the default), the crop's bounding box must fall entirely within the page's bounding box.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;.within_bbox(bounding_box, relative=False, strict=True)&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Similar to &lt;code&gt;.crop&lt;/code&gt;, but only retains objects that fall &lt;em&gt;entirely within&lt;/em&gt; the bounding box.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;.outside_bbox(bounding_box, relative=False, strict=True)&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Similar to &lt;code&gt;.crop&lt;/code&gt; and &lt;code&gt;.within_bbox&lt;/code&gt;, but only retains objects that fall &lt;em&gt;entirely outside&lt;/em&gt; the bounding box.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;.filter(test_function)&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Returns a version of the page with only the &lt;code&gt;.objects&lt;/code&gt; for which &lt;code&gt;test_function(obj)&lt;/code&gt; returns &lt;code&gt;True&lt;/code&gt;.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;... and also has the following method:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Method&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;.close()&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;By default, &lt;code&gt;Page&lt;/code&gt; objects cache their layout and object information to avoid having to reprocess it. When parsing large PDFs, however, these cached properties can require a lot of memory. You can use this method to flush the cache and release the memory.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Additional methods are described in the sections below:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jsvine/pdfplumber/stable/#visual-debugging"&gt;Visual debugging&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jsvine/pdfplumber/stable/#extracting-text"&gt;Extracting text&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jsvine/pdfplumber/stable/#extracting-tables"&gt;Extracting tables&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Objects&lt;/h3&gt; 
&lt;p&gt;Each instance of &lt;code&gt;pdfplumber.PDF&lt;/code&gt; and &lt;code&gt;pdfplumber.Page&lt;/code&gt; provides access to several types of PDF objects, all derived from &lt;a href="https://github.com/pdfminer/pdfminer.six/"&gt;&lt;code&gt;pdfminer.six&lt;/code&gt;&lt;/a&gt; PDF parsing. The following properties each return a Python list of the matching objects:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;.chars&lt;/code&gt;, each representing a single text character.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;.lines&lt;/code&gt;, each representing a single 1-dimensional line.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;.rects&lt;/code&gt;, each representing a single 2-dimensional rectangle.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;.curves&lt;/code&gt;, each representing any series of connected points that &lt;code&gt;pdfminer.six&lt;/code&gt; does not recognize as a line or rectangle.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;.images&lt;/code&gt;, each representing an image.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;.annots&lt;/code&gt;, each representing a single PDF annotation (cf. Section 8.4 of the &lt;a href="https://www.adobe.com/content/dam/acom/en/devnet/acrobat/pdfs/pdf_reference_1-7.pdf"&gt;official PDF specification&lt;/a&gt; for details)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;.hyperlinks&lt;/code&gt;, each representing a single PDF annotation of the subtype &lt;code&gt;Link&lt;/code&gt; and having an &lt;code&gt;URI&lt;/code&gt; action attribute&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Each object is represented as a simple Python &lt;code&gt;dict&lt;/code&gt;, with the following properties:&lt;/p&gt; 
&lt;h4&gt;&lt;code&gt;char&lt;/code&gt; properties&lt;/h4&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Property&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;page_number&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Page number on which this character was found.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;text&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;E.g., "z", or "Z" or " ".&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;fontname&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Name of the character's font face.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;size&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Font size.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;adv&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Equal to text width * the font size * scaling factor.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;upright&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Whether the character is upright.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;height&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Height of the character.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;width&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Width of the character.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;x0&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Distance of left side of character from left side of page.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;x1&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Distance of right side of character from left side of page.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;y0&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Distance of bottom of character from bottom of page.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;y1&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Distance of top of character from bottom of page.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;top&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Distance of top of character from top of page.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;bottom&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Distance of bottom of the character from top of page.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;doctop&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Distance of top of character from top of document.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;matrix&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;The "current transformation matrix" for this character. (See below for details.)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;mcid&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;The &lt;a href="https://ghostscript.com/~robin/pdf_reference17.pdf#page=850"&gt;marked content&lt;/a&gt; section ID for this character if any (otherwise &lt;code&gt;None&lt;/code&gt;). &lt;em&gt;Experimental attribute.&lt;/em&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;tag&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;The &lt;a href="https://ghostscript.com/~robin/pdf_reference17.pdf#page=850"&gt;marked content&lt;/a&gt; section tag for this character if any (otherwise &lt;code&gt;None&lt;/code&gt;). &lt;em&gt;Experimental attribute.&lt;/em&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;ncs&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;TKTK&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;stroking_pattern&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;TKTK&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;non_stroking_pattern&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;TKTK&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;stroking_color&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;The color of the character's outline (i.e., stroke). See &lt;a href="https://raw.githubusercontent.com/jsvine/pdfplumber/stable/docs/colors.md"&gt;docs/colors.md&lt;/a&gt; for details.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;non_stroking_color&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;The character's interior color. See &lt;a href="https://raw.githubusercontent.com/jsvine/pdfplumber/stable/docs/colors.md"&gt;docs/colors.md&lt;/a&gt; for details.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;object_type&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;"char"&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: A character’s &lt;code&gt;matrix&lt;/code&gt; property represents the “current transformation matrix,” as described in Section 4.2.2 of the &lt;a href="https://ghostscript.com/~robin/pdf_reference17.pdf"&gt;PDF Reference&lt;/a&gt; (6th Ed.). The matrix controls the character’s scale, skew, and positional translation. Rotation is a combination of scale and skew, but in most cases can be considered equal to the x-axis skew. The &lt;code&gt;pdfplumber.ctm&lt;/code&gt; submodule defines a class, &lt;code&gt;CTM&lt;/code&gt;, that assists with these calculations. For instance:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from pdfplumber.ctm import CTM
my_char = pdf.pages[0].chars[3]
my_char_ctm = CTM(*my_char["matrix"])
my_char_rotation = my_char_ctm.skew_x
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;&lt;code&gt;line&lt;/code&gt; properties&lt;/h4&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Property&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;page_number&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Page number on which this line was found.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;height&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Height of line.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;width&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Width of line.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;x0&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Distance of left-side extremity from left side of page.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;x1&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Distance of right-side extremity from left side of page.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;y0&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Distance of bottom extremity from bottom of page.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;y1&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Distance of top extremity bottom of page.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;top&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Distance of top of line from top of page.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;bottom&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Distance of bottom of the line from top of page.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;doctop&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Distance of top of line from top of document.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;linewidth&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Thickness of line.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;stroking_color&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;The color of the line. See &lt;a href="https://raw.githubusercontent.com/jsvine/pdfplumber/stable/docs/colors.md"&gt;docs/colors.md&lt;/a&gt; for details.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;non_stroking_color&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;The non-stroking color specified for the line’s path. See &lt;a href="https://raw.githubusercontent.com/jsvine/pdfplumber/stable/docs/colors.md"&gt;docs/colors.md&lt;/a&gt; for details.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;mcid&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;The &lt;a href="https://ghostscript.com/~robin/pdf_reference17.pdf#page=850"&gt;marked content&lt;/a&gt; section ID for this line if any (otherwise &lt;code&gt;None&lt;/code&gt;). &lt;em&gt;Experimental attribute.&lt;/em&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;tag&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;The &lt;a href="https://ghostscript.com/~robin/pdf_reference17.pdf#page=850"&gt;marked content&lt;/a&gt; section tag for this line if any (otherwise &lt;code&gt;None&lt;/code&gt;). &lt;em&gt;Experimental attribute.&lt;/em&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;object_type&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;"line"&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h4&gt;&lt;code&gt;rect&lt;/code&gt; properties&lt;/h4&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Property&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;page_number&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Page number on which this rectangle was found.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;height&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Height of rectangle.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;width&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Width of rectangle.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;x0&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Distance of left side of rectangle from left side of page.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;x1&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Distance of right side of rectangle from left side of page.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;y0&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Distance of bottom of rectangle from bottom of page.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;y1&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Distance of top of rectangle from bottom of page.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;top&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Distance of top of rectangle from top of page.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;bottom&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Distance of bottom of the rectangle from top of page.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;doctop&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Distance of top of rectangle from top of document.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;linewidth&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Thickness of line.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;stroking_color&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;The color of the rectangle's outline. See &lt;a href="https://raw.githubusercontent.com/jsvine/pdfplumber/stable/docs/colors.md"&gt;docs/colors.md&lt;/a&gt; for details.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;non_stroking_color&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;The rectangle’s fill color. See &lt;a href="https://raw.githubusercontent.com/jsvine/pdfplumber/stable/docs/colors.md"&gt;docs/colors.md&lt;/a&gt; for details.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;mcid&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;The &lt;a href="https://ghostscript.com/~robin/pdf_reference17.pdf#page=850"&gt;marked content&lt;/a&gt; section ID for this rect if any (otherwise &lt;code&gt;None&lt;/code&gt;). &lt;em&gt;Experimental attribute.&lt;/em&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;tag&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;The &lt;a href="https://ghostscript.com/~robin/pdf_reference17.pdf#page=850"&gt;marked content&lt;/a&gt; section tag for this rect if any (otherwise &lt;code&gt;None&lt;/code&gt;). &lt;em&gt;Experimental attribute.&lt;/em&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;object_type&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;"rect"&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h4&gt;&lt;code&gt;curve&lt;/code&gt; properties&lt;/h4&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Property&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;page_number&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Page number on which this curve was found.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;pts&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;A list of &lt;code&gt;(x, top)&lt;/code&gt; tuples indicating the &lt;em&gt;points on the curve&lt;/em&gt;.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;path&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;A list of &lt;code&gt;(cmd, *(x, top))&lt;/code&gt; tuples &lt;em&gt;describing the full path description&lt;/em&gt;, including (for example) control points used in Bezier curves.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;height&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Height of curve's bounding box.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;width&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Width of curve's bounding box.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;x0&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Distance of curve's left-most point from left side of page.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;x1&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Distance of curve's right-most point from left side of the page.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;y0&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Distance of curve's lowest point from bottom of page.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;y1&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Distance of curve's highest point from bottom of page.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;top&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Distance of curve's highest point from top of page.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;bottom&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Distance of curve's lowest point from top of page.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;doctop&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Distance of curve's highest point from top of document.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;linewidth&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Thickness of line.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;fill&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Whether the shape defined by the curve's path is filled.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;stroking_color&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;The color of the curve's outline. See &lt;a href="https://raw.githubusercontent.com/jsvine/pdfplumber/stable/docs/colors.md"&gt;docs/colors.md&lt;/a&gt; for details.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;non_stroking_color&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;The curve’s fill color. See &lt;a href="https://raw.githubusercontent.com/jsvine/pdfplumber/stable/docs/colors.md"&gt;docs/colors.md&lt;/a&gt; for details.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;dash&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;A &lt;code&gt;([dash_array], dash_phase)&lt;/code&gt; tuple describing the curve's dash style. See &lt;a href="https://ghostscript.com/~robin/pdf_reference17.pdf#page=218"&gt;Table 4.6 of the PDF specification&lt;/a&gt; for details.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;mcid&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;The &lt;a href="https://ghostscript.com/~robin/pdf_reference17.pdf#page=850"&gt;marked content&lt;/a&gt; section ID for this curve if any (otherwise &lt;code&gt;None&lt;/code&gt;). &lt;em&gt;Experimental attribute.&lt;/em&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;tag&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;The &lt;a href="https://ghostscript.com/~robin/pdf_reference17.pdf#page=850"&gt;marked content&lt;/a&gt; section tag for this curve if any (otherwise &lt;code&gt;None&lt;/code&gt;). &lt;em&gt;Experimental attribute.&lt;/em&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;object_type&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;"curve"&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h4&gt;Derived properties&lt;/h4&gt; 
&lt;p&gt;Additionally, both &lt;code&gt;pdfplumber.PDF&lt;/code&gt; and &lt;code&gt;pdfplumber.Page&lt;/code&gt; provide access to several derived lists of objects: &lt;code&gt;.rect_edges&lt;/code&gt; (which decomposes each rectangle into its four lines), &lt;code&gt;.curve_edges&lt;/code&gt; (which does the same for &lt;code&gt;curve&lt;/code&gt; objects), and &lt;code&gt;.edges&lt;/code&gt; (which combines &lt;code&gt;.rect_edges&lt;/code&gt;, &lt;code&gt;.curve_edges&lt;/code&gt;, and &lt;code&gt;.lines&lt;/code&gt;).&lt;/p&gt; 
&lt;h4&gt;&lt;code&gt;image&lt;/code&gt; properties&lt;/h4&gt; 
&lt;p&gt;&lt;em&gt;Note: Although the positioning and characteristics of &lt;code&gt;image&lt;/code&gt; objects are available via &lt;code&gt;pdfplumber&lt;/code&gt;, this library does not provide direct support for reconstructing image content. For that, please see &lt;a href="https://github.com/jsvine/pdfplumber/discussions/496#discussioncomment-1259772"&gt;this suggestion&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Property&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;page_number&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Page number on which the image was found.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;height&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Height of the image.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;width&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Width of the image.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;x0&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Distance of left side of the image from left side of page.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;x1&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Distance of right side of the image from left side of page.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;y0&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Distance of bottom of the image from bottom of page.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;y1&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Distance of top of the image from bottom of page.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;top&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Distance of top of the image from top of page.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;bottom&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Distance of bottom of the image from top of page.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;doctop&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Distance of top of rectangle from top of document.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;srcsize&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;The image original dimensions, as a &lt;code&gt;(width, height)&lt;/code&gt; tuple.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;colorspace&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Color domain of the image (e.g., RGB).&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;bits&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;The number of bits per color component; e.g., 8 corresponds to 255 possible values for each color component (R, G, and B in an RGB color space).&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;stream&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Pixel values of the image, as a &lt;code&gt;pdfminer.pdftypes.PDFStream&lt;/code&gt; object.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;imagemask&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;A nullable boolean; if &lt;code&gt;True&lt;/code&gt;, "specifies that the image data is to be used as a stencil mask for painting in the current color."&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;name&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;"The name by which this image XObject is referenced in the XObject subdictionary of the current resource dictionary." &lt;a href="https://ghostscript.com/~robin/pdf_reference17.pdf#page=340"&gt;🔗&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;mcid&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;The &lt;a href="https://ghostscript.com/~robin/pdf_reference17.pdf#page=850"&gt;marked content&lt;/a&gt; section ID for this image if any (otherwise &lt;code&gt;None&lt;/code&gt;). &lt;em&gt;Experimental attribute.&lt;/em&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;tag&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;The &lt;a href="https://ghostscript.com/~robin/pdf_reference17.pdf#page=850"&gt;marked content&lt;/a&gt; section tag for this image if any (otherwise &lt;code&gt;None&lt;/code&gt;). &lt;em&gt;Experimental attribute.&lt;/em&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;object_type&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;"image"&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Obtaining higher-level layout objects via &lt;code&gt;pdfminer.six&lt;/code&gt;&lt;/h3&gt; 
&lt;p&gt;If you pass the &lt;code&gt;pdfminer.six&lt;/code&gt;-handling &lt;code&gt;laparams&lt;/code&gt; parameter to &lt;code&gt;pdfplumber.open(...)&lt;/code&gt;, then each page's &lt;code&gt;.objects&lt;/code&gt; dictionary will also contain &lt;code&gt;pdfminer.six&lt;/code&gt;'s higher-level layout objects, such as &lt;code&gt;"textboxhorizontal"&lt;/code&gt;.&lt;/p&gt; 
&lt;h2&gt;Visual debugging&lt;/h2&gt; 
&lt;p&gt;&lt;code&gt;pdfplumber&lt;/code&gt;'s visual debugging tools can be helpful in understanding the structure of a PDF and the objects that have been extracted from it.&lt;/p&gt; 
&lt;h3&gt;Creating a &lt;code&gt;PageImage&lt;/code&gt; with &lt;code&gt;.to_image()&lt;/code&gt;&lt;/h3&gt; 
&lt;p&gt;To turn any page (including cropped pages) into an &lt;code&gt;PageImage&lt;/code&gt; object, call &lt;code&gt;my_page.to_image()&lt;/code&gt;. You can optionally pass &lt;em&gt;one&lt;/em&gt; of the following keyword arguments:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;resolution&lt;/code&gt;: The desired number pixels per inch. Default: &lt;code&gt;72&lt;/code&gt;. Type: &lt;code&gt;int&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;width&lt;/code&gt;: The desired image width in pixels. Default: unset, determined by &lt;code&gt;resolution&lt;/code&gt;. Type: &lt;code&gt;int&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;height&lt;/code&gt;: The desired image width in pixels. Default: unset, determined by &lt;code&gt;resolution&lt;/code&gt;. Type: &lt;code&gt;int&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;antialias&lt;/code&gt;: Whether to use antialiasing when creating the image. Setting to &lt;code&gt;True&lt;/code&gt; creates images with less-jagged text and graphics, but with larger file sizes. Default: &lt;code&gt;False&lt;/code&gt;. Type: &lt;code&gt;bool&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;force_mediabox&lt;/code&gt;: Use the page's &lt;code&gt;.mediabox&lt;/code&gt; dimensions, rather than the &lt;code&gt;.cropbox&lt;/code&gt; dimensions. Default: &lt;code&gt;False&lt;/code&gt;. Type: &lt;code&gt;bool&lt;/code&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For instance:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;im = my_pdf.pages[0].to_image(resolution=150)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;From a script or REPL, &lt;code&gt;im.show()&lt;/code&gt; will open the image in your local image viewer. But &lt;code&gt;PageImage&lt;/code&gt; objects also play nicely with Jupyter notebooks; they automatically render as cell outputs. For example:&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/jsvine/pdfplumber/stable/examples/screenshots/visual-debugging-in-jupyter.png" alt="Visual debugging in Jupyter" title="Visual debugging in Jupyter" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;Note&lt;/em&gt;: &lt;code&gt;.to_image(...)&lt;/code&gt; works as expected with &lt;code&gt;Page.crop(...)&lt;/code&gt;/&lt;code&gt;CroppedPage&lt;/code&gt; instances, but is unable to incorporate changes made via &lt;code&gt;Page.filter(...)&lt;/code&gt;/&lt;code&gt;FilteredPage&lt;/code&gt; instances.&lt;/p&gt; 
&lt;h3&gt;Basic &lt;code&gt;PageImage&lt;/code&gt; methods&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Method&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;im.reset()&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Clears anything you've drawn so far.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;im.copy()&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Copies the image to a new &lt;code&gt;PageImage&lt;/code&gt; object.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;im.show()&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Opens the image in your local image viewer.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;im.save(path_or_fileobject, format="PNG", quantize=True, colors=256, bits=8)&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Saves the annotated image as a PNG file. The default arguments quantize the image to a palette of 256 colors, saving the PNG with 8-bit color depth. You can disable quantization by passing &lt;code&gt;quantize=False&lt;/code&gt; or adjust the size of the color palette by passing &lt;code&gt;colors=N&lt;/code&gt;.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Drawing methods&lt;/h3&gt; 
&lt;p&gt;You can pass explicit coordinates or any &lt;code&gt;pdfplumber&lt;/code&gt; PDF object (e.g., char, line, rect) to these methods.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Single-object method&lt;/th&gt; 
   &lt;th&gt;Bulk method&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;im.draw_line(line, stroke={color}, stroke_width=1)&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;im.draw_lines(list_of_lines, **kwargs)&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Draws a line from a &lt;code&gt;line&lt;/code&gt;, &lt;code&gt;curve&lt;/code&gt;, or a 2-tuple of 2-tuples (e.g., &lt;code&gt;((x, y), (x, y))&lt;/code&gt;).&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;im.draw_vline(location, stroke={color}, stroke_width=1)&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;im.draw_vlines(list_of_locations, **kwargs)&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Draws a vertical line at the x-coordinate indicated by &lt;code&gt;location&lt;/code&gt;.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;im.draw_hline(location, stroke={color}, stroke_width=1)&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;im.draw_hlines(list_of_locations, **kwargs)&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Draws a horizontal line at the y-coordinate indicated by &lt;code&gt;location&lt;/code&gt;.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;im.draw_rect(bbox_or_obj, fill={color}, stroke={color}, stroke_width=1)&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;im.draw_rects(list_of_rects, **kwargs)&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Draws a rectangle from a &lt;code&gt;rect&lt;/code&gt;, &lt;code&gt;char&lt;/code&gt;, etc., or 4-tuple bounding box.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;im.draw_circle(center_or_obj, radius=5, fill={color}, stroke={color})&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;im.draw_circles(list_of_circles, **kwargs)&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Draws a circle at &lt;code&gt;(x, y)&lt;/code&gt; coordinate or at the center of a &lt;code&gt;char&lt;/code&gt;, &lt;code&gt;rect&lt;/code&gt;, etc.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Note: The methods above are built on Pillow's &lt;a href="http://pillow.readthedocs.io/en/latest/reference/ImageDraw.html"&gt;&lt;code&gt;ImageDraw&lt;/code&gt; methods&lt;/a&gt;, but the parameters have been tweaked for consistency with SVG's &lt;code&gt;fill&lt;/code&gt;/&lt;code&gt;stroke&lt;/code&gt;/&lt;code&gt;stroke_width&lt;/code&gt; nomenclature.&lt;/p&gt; 
&lt;h3&gt;Visually debugging the table-finder&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;im.debug_tablefinder(table_settings={})&lt;/code&gt; will return a version of the PageImage with the detected lines (in red), intersections (circles), and tables (light blue) overlaid.&lt;/p&gt; 
&lt;h2&gt;Extracting text&lt;/h2&gt; 
&lt;p&gt;&lt;code&gt;pdfplumber&lt;/code&gt; can extract text from any given page (including cropped and derived pages). It can also attempt to preserve the layout of that text, as well as to identify the coordinates of words and search queries. &lt;code&gt;Page&lt;/code&gt; objects can call the following text-extraction methods:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Method&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;.extract_text(x_tolerance=3, x_tolerance_ratio=None, y_tolerance=3, layout=False, x_density=7.25, y_density=13, line_dir_render=None, char_dir_render=None, **kwargs)&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Collates all of the page's character objects into a single string.
    &lt;ul&gt;
     &lt;li&gt;&lt;p&gt;When &lt;code&gt;layout=False&lt;/code&gt;: Adds spaces where the difference between the &lt;code&gt;x1&lt;/code&gt; of one character and the &lt;code&gt;x0&lt;/code&gt; of the next is greater than &lt;code&gt;x_tolerance&lt;/code&gt;. (If &lt;code&gt;x_tolerance_ratio&lt;/code&gt; is not &lt;code&gt;None&lt;/code&gt;, the extractor uses a dynamic &lt;code&gt;x_tolerance&lt;/code&gt; equal to &lt;code&gt;x_tolerance_ratio * previous_character["size"]&lt;/code&gt;.) Adds newline characters where the difference between the &lt;code&gt;doctop&lt;/code&gt; of one character and the &lt;code&gt;doctop&lt;/code&gt; of the next is greater than &lt;code&gt;y_tolerance&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
     &lt;li&gt;&lt;p&gt;When &lt;code&gt;layout=True&lt;/code&gt; (&lt;em&gt;experimental feature&lt;/em&gt;): Attempts to mimic the structural layout of the text on the page(s), using &lt;code&gt;x_density&lt;/code&gt; and &lt;code&gt;y_density&lt;/code&gt; to determine the minimum number of characters/newlines per "point," the PDF unit of measurement. Passing &lt;code&gt;line_dir_render="ttb"/"btt"/"ltr"/"rtl"&lt;/code&gt; and/or &lt;code&gt;char_dir_render="ttb"/"btt"/"ltr"/"rtl"&lt;/code&gt; will output the the lines/characters in a different direction than the default. All remaining &lt;code&gt;**kwargs&lt;/code&gt; are passed to &lt;code&gt;.extract_words(...)&lt;/code&gt; (see below), the first step in calculating the layout.&lt;/p&gt;&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;.extract_text_simple(x_tolerance=3, y_tolerance=3)&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;A slightly faster but less flexible version of &lt;code&gt;.extract_text(...)&lt;/code&gt;, using a simpler logic.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;.extract_words(x_tolerance=3, x_tolerance_ratio=None, y_tolerance=3, keep_blank_chars=False, use_text_flow=False, line_dir="ttb", char_dir="ltr", line_dir_rotated="ttb", char_dir_rotated="ltr", extra_attrs=[], split_at_punctuation=False, expand_ligatures=True, return_chars=False)&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Returns a list of all word-looking things and their bounding boxes. Words are considered to be sequences of characters where (for "upright" characters) the difference between the &lt;code&gt;x1&lt;/code&gt; of one character and the &lt;code&gt;x0&lt;/code&gt; of the next is less than or equal to &lt;code&gt;x_tolerance&lt;/code&gt; &lt;em&gt;and&lt;/em&gt; where the &lt;code&gt;doctop&lt;/code&gt; of one character and the &lt;code&gt;doctop&lt;/code&gt; of the next is less than or equal to &lt;code&gt;y_tolerance&lt;/code&gt;. (If &lt;code&gt;x_tolerance_ratio&lt;/code&gt; is not &lt;code&gt;None&lt;/code&gt;, the extractor uses a dynamic &lt;code&gt;x_tolerance&lt;/code&gt; equal to &lt;code&gt;x_tolerance_ratio * previous_character["size"]&lt;/code&gt;.) A similar approach is taken for non-upright characters, but instead measuring the vertical, rather than horizontal, distances between them. Changing &lt;code&gt;keep_blank_chars&lt;/code&gt; to &lt;code&gt;True&lt;/code&gt; will mean that blank characters are treated as part of a word, not as a space between words. Changing &lt;code&gt;use_text_flow&lt;/code&gt; to &lt;code&gt;True&lt;/code&gt; will use the PDF's underlying flow of characters as a guide for ordering and segmenting the words, rather than presorting the characters by x/y position. (This mimics how dragging a cursor highlights text in a PDF; as with that, the order does not always appear to be logical.) The arguments &lt;code&gt;line_dir&lt;/code&gt; and &lt;code&gt;char_dir&lt;/code&gt; tell this method the direction in which lines/characters are expected to be read; valid options are "ttb" (top-to-bottom), "btt" (bottom-to-top), "ltr" (left-to-right), and "rtl" (right-to-left). The &lt;code&gt;line_dir_rotated&lt;/code&gt; and &lt;code&gt;char_dir_rotated&lt;/code&gt; arguments are similar, but for text that has been rotated. Passing a list of &lt;code&gt;extra_attrs&lt;/code&gt; (e.g., &lt;code&gt;["fontname", "size"]&lt;/code&gt; will restrict each words to characters that share exactly the same value for each of those &lt;a href="https://raw.githubusercontent.com/jsvine/pdfplumber/stable/#char-properties"&gt;attributes&lt;/a&gt;, and the resulting word dicts will indicate those attributes. Setting &lt;code&gt;split_at_punctuation&lt;/code&gt; to &lt;code&gt;True&lt;/code&gt; will enforce breaking tokens at punctuations specified by &lt;code&gt;string.punctuation&lt;/code&gt;; or you can specify the list of separating punctuation by pass a string, e.g., &lt;code&gt;split_at_punctuation='!"&amp;amp;'()*+,.:;&amp;lt;=&amp;gt;?@[]^`{|}~'&lt;/code&gt;. Unless you set &lt;code&gt;expand_ligatures=False&lt;/code&gt;, ligatures such as &lt;code&gt;ﬁ&lt;/code&gt; will be expanded into their constituent letters (e.g., &lt;code&gt;fi&lt;/code&gt;). Passing &lt;code&gt;return_chars=True&lt;/code&gt; will add, to each word dictionary, a list of its constituent characters, as a list in the &lt;code&gt;"chars"&lt;/code&gt; field.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;.extract_text_lines(layout=False, strip=True, return_chars=True, **kwargs)&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;em&gt;Experimental feature&lt;/em&gt; that returns a list of dictionaries representing the lines of text on the page. The &lt;code&gt;strip&lt;/code&gt; parameter works analogously to Python's &lt;code&gt;str.strip()&lt;/code&gt; method, and returns &lt;code&gt;text&lt;/code&gt; attributes without their surrounding whitespace. (Only relevant when &lt;code&gt;layout = True&lt;/code&gt;.) Setting &lt;code&gt;return_chars&lt;/code&gt; to &lt;code&gt;False&lt;/code&gt; will exclude the individual character objects from the returned text-line dicts. The remaining &lt;code&gt;**kwargs&lt;/code&gt; are those you would pass to &lt;code&gt;.extract_text(layout=True, ...)&lt;/code&gt;.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;.search(pattern, regex=True, case=True, main_group=0, return_groups=True, return_chars=True, layout=False, **kwargs)&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;em&gt;Experimental feature&lt;/em&gt; that allows you to search a page's text, returning a list of all instances that match the query. For each instance, the response dictionary object contains the matching text, any regex group matches, the bounding box coordinates, and the char objects themselves. &lt;code&gt;pattern&lt;/code&gt; can be a compiled regular expression, an uncompiled regular expression, or a non-regex string. If &lt;code&gt;regex&lt;/code&gt; is &lt;code&gt;False&lt;/code&gt;, the pattern is treated as a non-regex string. If &lt;code&gt;case&lt;/code&gt; is &lt;code&gt;False&lt;/code&gt;, the search is performed in a case-insensitive manner. Setting &lt;code&gt;main_group&lt;/code&gt; restricts the results to a specific regex group within the &lt;code&gt;pattern&lt;/code&gt; (default of &lt;code&gt;0&lt;/code&gt; means the entire match). Setting &lt;code&gt;return_groups&lt;/code&gt; and/or &lt;code&gt;return_chars&lt;/code&gt; to &lt;code&gt;False&lt;/code&gt; will exclude the lists of the matched regex groups and/or characters from being added (as &lt;code&gt;"groups"&lt;/code&gt; and &lt;code&gt;"chars"&lt;/code&gt; to the return dicts). The &lt;code&gt;layout&lt;/code&gt; parameter operates as it does for &lt;code&gt;.extract_text(...)&lt;/code&gt;. The remaining &lt;code&gt;**kwargs&lt;/code&gt; are those you would pass to &lt;code&gt;.extract_text(layout=True, ...)&lt;/code&gt;. &lt;strong&gt;Note&lt;/strong&gt;: Zero-width and all-whitespace matches are discarded, because they (generally) have no explicit position on the page.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;.dedupe_chars(tolerance=1, extra_attrs=("fontname", "size"))&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Returns a version of the page with duplicate chars —&amp;nbsp;those sharing the same text, positioning (within &lt;code&gt;tolerance&lt;/code&gt; x/y), and &lt;code&gt;extra_attrs&lt;/code&gt; as other characters —&amp;nbsp;removed. (See &lt;a href="https://github.com/jsvine/pdfplumber/issues/71"&gt;Issue #71&lt;/a&gt; to understand the motivation.)&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Extracting tables&lt;/h2&gt; 
&lt;p&gt;&lt;code&gt;pdfplumber&lt;/code&gt;'s approach to table detection borrows heavily from &lt;a href="https://trepo.tuni.fi/bitstream/handle/123456789/21520/Nurminen.pdf?sequence=3"&gt;Anssi Nurminen's master's thesis&lt;/a&gt;, and is inspired by &lt;a href="https://github.com/tabulapdf/tabula-extractor/issues/16"&gt;Tabula&lt;/a&gt;. It works like this:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;For any given PDF page, find the lines that are (a) explicitly defined and/or (b) implied by the alignment of words on the page.&lt;/li&gt; 
 &lt;li&gt;Merge overlapping, or nearly-overlapping, lines.&lt;/li&gt; 
 &lt;li&gt;Find the intersections of all those lines.&lt;/li&gt; 
 &lt;li&gt;Find the most granular set of rectangles (i.e., cells) that use these intersections as their vertices.&lt;/li&gt; 
 &lt;li&gt;Group contiguous cells into tables.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Table-extraction methods&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;pdfplumber.Page&lt;/code&gt; objects can call the following table methods:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Method&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;.find_tables(table_settings={})&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Returns a list of &lt;code&gt;Table&lt;/code&gt; objects. The &lt;code&gt;Table&lt;/code&gt; object provides access to the &lt;code&gt;.cells&lt;/code&gt;, &lt;code&gt;.rows&lt;/code&gt;, &lt;code&gt;.columns&lt;/code&gt;, and &lt;code&gt;.bbox&lt;/code&gt; properties, as well as the &lt;code&gt;.extract(x_tolerance=3, y_tolerance=3)&lt;/code&gt; method.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;.find_table(table_settings={})&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Similar to &lt;code&gt;.find_tables(...)&lt;/code&gt;, but returns the &lt;em&gt;largest&lt;/em&gt; table on the page, as a &lt;code&gt;Table&lt;/code&gt; object. If multiple tables have the same size —&amp;nbsp;as measured by the number of cells —&amp;nbsp;this method returns the table closest to the top of the page.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;.extract_tables(table_settings={})&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Returns the text extracted from &lt;em&gt;all&lt;/em&gt; tables found on the page, represented as a list of lists of lists, with the structure &lt;code&gt;table -&amp;gt; row -&amp;gt; cell&lt;/code&gt;.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;.extract_table(table_settings={})&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Returns the text extracted from the &lt;em&gt;largest&lt;/em&gt; table on the page (see &lt;code&gt;.find_table(...)&lt;/code&gt; above), represented as a list of lists, with the structure &lt;code&gt;row -&amp;gt; cell&lt;/code&gt;.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;.debug_tablefinder(table_settings={})&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Returns an instance of the &lt;code&gt;TableFinder&lt;/code&gt; class, with access to the &lt;code&gt;.edges&lt;/code&gt;, &lt;code&gt;.intersections&lt;/code&gt;, &lt;code&gt;.cells&lt;/code&gt;, and &lt;code&gt;.tables&lt;/code&gt; properties.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;For example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;pdf = pdfplumber.open("path/to/my.pdf")
page = pdf.pages[0]
page.extract_table()
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/jsvine/pdfplumber/stable/examples/notebooks/extract-table-ca-warn-report.ipynb"&gt;Click here for a more detailed example.&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Table-extraction settings&lt;/h3&gt; 
&lt;p&gt;By default, &lt;code&gt;extract_tables&lt;/code&gt; uses the page's vertical and horizontal lines (or rectangle edges) as cell-separators. But the method is highly customizable via the &lt;code&gt;table_settings&lt;/code&gt; argument. The possible settings, and their defaults:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;{
    "vertical_strategy": "lines", 
    "horizontal_strategy": "lines",
    "explicit_vertical_lines": [],
    "explicit_horizontal_lines": [],
    "snap_tolerance": 3,
    "snap_x_tolerance": 3,
    "snap_y_tolerance": 3,
    "join_tolerance": 3,
    "join_x_tolerance": 3,
    "join_y_tolerance": 3,
    "edge_min_length": 3,
    "min_words_vertical": 3,
    "min_words_horizontal": 1,
    "intersection_tolerance": 3,
    "intersection_x_tolerance": 3,
    "intersection_y_tolerance": 3,
    "text_tolerance": 3,
    "text_x_tolerance": 3,
    "text_y_tolerance": 3,
    "text_*": …, # See below
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Setting&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;"vertical_strategy"&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Either &lt;code&gt;"lines"&lt;/code&gt;, &lt;code&gt;"lines_strict"&lt;/code&gt;, &lt;code&gt;"text"&lt;/code&gt;, or &lt;code&gt;"explicit"&lt;/code&gt;. See explanation below.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;"horizontal_strategy"&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Either &lt;code&gt;"lines"&lt;/code&gt;, &lt;code&gt;"lines_strict"&lt;/code&gt;, &lt;code&gt;"text"&lt;/code&gt;, or &lt;code&gt;"explicit"&lt;/code&gt;. See explanation below.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;"explicit_vertical_lines"&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;A list of vertical lines that explicitly demarcate cells in the table. Can be used in combination with any of the strategies above. Items in the list should be either numbers —&amp;nbsp;indicating the &lt;code&gt;x&lt;/code&gt; coordinate of a line the full height of the page —&amp;nbsp;or &lt;code&gt;line&lt;/code&gt;/&lt;code&gt;rect&lt;/code&gt;/&lt;code&gt;curve&lt;/code&gt; objects.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;"explicit_horizontal_lines"&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;A list of horizontal lines that explicitly demarcate cells in the table. Can be used in combination with any of the strategies above. Items in the list should be either numbers —&amp;nbsp;indicating the &lt;code&gt;y&lt;/code&gt; coordinate of a line the full height of the page —&amp;nbsp;or &lt;code&gt;line&lt;/code&gt;/&lt;code&gt;rect&lt;/code&gt;/&lt;code&gt;curve&lt;/code&gt; objects.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;"snap_tolerance"&lt;/code&gt;, &lt;code&gt;"snap_x_tolerance"&lt;/code&gt;, &lt;code&gt;"snap_y_tolerance"&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Parallel lines within &lt;code&gt;snap_tolerance&lt;/code&gt; points will be "snapped" to the same horizontal or vertical position.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;"join_tolerance"&lt;/code&gt;, &lt;code&gt;"join_x_tolerance"&lt;/code&gt;, &lt;code&gt;"join_y_tolerance"&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Line segments on the same infinite line, and whose ends are within &lt;code&gt;join_tolerance&lt;/code&gt; of one another, will be "joined" into a single line segment.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;"edge_min_length"&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Edges shorter than &lt;code&gt;edge_min_length&lt;/code&gt; will be discarded before attempting to reconstruct the table.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;"min_words_vertical"&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;When using &lt;code&gt;"vertical_strategy": "text"&lt;/code&gt;, at least &lt;code&gt;min_words_vertical&lt;/code&gt; words must share the same alignment.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;"min_words_horizontal"&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;When using &lt;code&gt;"horizontal_strategy": "text"&lt;/code&gt;, at least &lt;code&gt;min_words_horizontal&lt;/code&gt; words must share the same alignment.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;"intersection_tolerance"&lt;/code&gt;, &lt;code&gt;"intersection_x_tolerance"&lt;/code&gt;, &lt;code&gt;"intersection_y_tolerance"&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;When combining edges into cells, orthogonal edges must be within &lt;code&gt;intersection_tolerance&lt;/code&gt; points to be considered intersecting.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;"text_*"&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;All settings prefixed with &lt;code&gt;text_&lt;/code&gt; are then used when extracting text from each discovered table. All possible arguments to &lt;code&gt;Page.extract_text(...)&lt;/code&gt; are also valid here.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;"text_x_tolerance"&lt;/code&gt;, &lt;code&gt;"text_y_tolerance"&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;These &lt;code&gt;text_&lt;/code&gt;-prefixed settings &lt;em&gt;also&lt;/em&gt; apply to the table-identification algorithm when the &lt;code&gt;text&lt;/code&gt; strategy is used. I.e., when that algorithm searches for words, it will expect the individual letters in each word to be no more than &lt;code&gt;text_x_tolerance&lt;/code&gt;/&lt;code&gt;text_y_tolerance&lt;/code&gt; points apart.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Table-extraction strategies&lt;/h3&gt; 
&lt;p&gt;Both &lt;code&gt;vertical_strategy&lt;/code&gt; and &lt;code&gt;horizontal_strategy&lt;/code&gt; accept the following options:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Strategy&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;"lines"&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Use the page's graphical lines —&amp;nbsp;including the sides of rectangle objects —&amp;nbsp;as the borders of potential table-cells.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;"lines_strict"&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Use the page's graphical lines —&amp;nbsp;but &lt;em&gt;not&lt;/em&gt; the sides of rectangle objects —&amp;nbsp;as the borders of potential table-cells.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;"text"&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;For &lt;code&gt;vertical_strategy&lt;/code&gt;: Deduce the (imaginary) lines that connect the left, right, or center of words on the page, and use those lines as the borders of potential table-cells. For &lt;code&gt;horizontal_strategy&lt;/code&gt;, the same but using the tops of words.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;"explicit"&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Only use the lines explicitly defined in &lt;code&gt;explicit_vertical_lines&lt;/code&gt; / &lt;code&gt;explicit_horizontal_lines&lt;/code&gt;.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Notes&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Often it's helpful to crop a page —&amp;nbsp;&lt;code&gt;Page.crop(bounding_box)&lt;/code&gt; —&amp;nbsp;before trying to extract the table.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Table extraction for &lt;code&gt;pdfplumber&lt;/code&gt; was radically redesigned for &lt;code&gt;v0.5.0&lt;/code&gt;, and introduced breaking changes.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Extracting form values&lt;/h2&gt; 
&lt;p&gt;Sometimes PDF files can contain forms that include inputs that people can fill out and save. While values in form fields appear like other text in a PDF file, form data is handled differently. If you want the gory details, see page 671 of this &lt;a href="https://opensource.adobe.com/dc-acrobat-sdk-docs/pdfstandards/pdfreference1.7old.pdf"&gt;specification&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;pdfplumber&lt;/code&gt; doesn't have an interface for working with form data, but you can access it using &lt;code&gt;pdfplumber&lt;/code&gt;'s wrappers around &lt;code&gt;pdfminer&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;For example, this snippet will retrieve form field names and values and store them in a dictionary.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import pdfplumber
from pdfplumber.utils.pdfinternals import resolve_and_decode, resolve

pdf = pdfplumber.open("document_with_form.pdf")

def parse_field_helper(form_data, field, prefix=None):
    """ appends any PDF AcroForm field/value pairs in `field` to provided `form_data` list

        if `field` has child fields, those will be parsed recursively.
    """
    resolved_field = field.resolve()
    field_name = '.'.join(filter(lambda x: x, [prefix, resolve_and_decode(resolved_field.get("T"))]))
    if "Kids" in resolved_field:
        for kid_field in resolved_field["Kids"]:
            parse_field_helper(form_data, kid_field, prefix=field_name)
    if "T" in resolved_field or "TU" in resolved_field:
        # "T" is a field-name, but it's sometimes absent.
        # "TU" is the "alternate field name" and is often more human-readable
        # your PDF may have one, the other, or both.
        alternate_field_name  = resolve_and_decode(resolved_field.get("TU")) if resolved_field.get("TU") else None
        field_value = resolve_and_decode(resolved_field["V"]) if 'V' in resolved_field else None
        form_data.append([field_name, alternate_field_name, field_value])


form_data = []
fields = resolve(resolve(pdf.doc.catalog["AcroForm"])["Fields"])
for field in fields:
    parse_field_helper(form_data, field)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Once you run this script, &lt;code&gt;form_data&lt;/code&gt; is a list containing a three-element tuple for each form element. For instance, a PDF form with a city and state field might look like this.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;[
 ['STATE.0', 'enter STATE', 'CA'],
 ['section 2  accident infoRmation.1.0',
  'enter city of accident',
  'SAN FRANCISCO']
]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;em&gt;Thanks to &lt;a href="https://github.com/jeremybmerrill"&gt;@jeremybmerrill&lt;/a&gt; for helping to maintain the form-parsing code above.&lt;/em&gt;&lt;/p&gt; 
&lt;h2&gt;Demonstrations&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jsvine/pdfplumber/stable/examples/notebooks/extract-table-ca-warn-report.ipynb"&gt;Using &lt;code&gt;extract_table&lt;/code&gt; on a California Worker Adjustment and Retraining Notification (WARN) report&lt;/a&gt;. Demonstrates basic visual debugging and table extraction.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jsvine/pdfplumber/stable/examples/notebooks/extract-table-nics.ipynb"&gt;Using &lt;code&gt;extract_table&lt;/code&gt; on the FBI's National Instant Criminal Background Check System PDFs&lt;/a&gt;. Demonstrates how to use visual debugging to find optimal table extraction settings. Also demonstrates &lt;code&gt;Page.crop(...)&lt;/code&gt; and &lt;code&gt;Page.extract_text(...).&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jsvine/pdfplumber/stable/examples/notebooks/ag-energy-roundup-curves.ipynb"&gt;Inspecting and visualizing &lt;code&gt;curve&lt;/code&gt; objects&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jsvine/pdfplumber/stable/examples/notebooks/san-jose-pd-firearm-report.ipynb"&gt;Extracting fixed-width data from a San Jose PD firearm search report&lt;/a&gt;, an example of using &lt;code&gt;Page.extract_text(...)&lt;/code&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Comparison to other libraries&lt;/h2&gt; 
&lt;p&gt;Several other Python libraries help users to extract information from PDFs. As a broad overview, &lt;code&gt;pdfplumber&lt;/code&gt; distinguishes itself from other PDF processing libraries by combining these features:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Easy access to detailed information about each PDF object&lt;/li&gt; 
 &lt;li&gt;Higher-level, customizable methods for extracting text and tables&lt;/li&gt; 
 &lt;li&gt;Tightly integrated visual debugging&lt;/li&gt; 
 &lt;li&gt;Other useful utility functions, such as filtering objects via a crop-box&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;It's also helpful to know what features &lt;code&gt;pdfplumber&lt;/code&gt; does &lt;strong&gt;not&lt;/strong&gt; provide:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;PDF &lt;em&gt;generation&lt;/em&gt;&lt;/li&gt; 
 &lt;li&gt;PDF &lt;em&gt;modification&lt;/em&gt;&lt;/li&gt; 
 &lt;li&gt;Optical character recognition (OCR)&lt;/li&gt; 
 &lt;li&gt;Strong support for extracting tables from OCR'ed documents&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Specific comparisons&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/pdfminer/pdfminer.six"&gt;&lt;code&gt;pdfminer.six&lt;/code&gt;&lt;/a&gt; provides the foundation for &lt;code&gt;pdfplumber&lt;/code&gt;. It primarily focuses on parsing PDFs, analyzing PDF layouts and object positioning, and extracting text. It does not provide tools for table extraction or visual debugging. License: &lt;a href="https://github.com/pdfminer/pdfminer.six?tab=MIT-1-ov-file"&gt;MIT&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/mstamy2/PyPDF2"&gt;&lt;code&gt;PyPDF2&lt;/code&gt;&lt;/a&gt; is a pure-Python library "capable of splitting, merging, cropping, and transforming the pages of PDF files. It can also add custom data, viewing options, and passwords to PDF files." It can extract page text, but does not provide easy access to shape objects (rectangles, lines, etc.), table-extraction, or visually debugging tools. License: &lt;a href="https://github.com/py-pdf/pypdf?tab=License-1-ov-file#readme"&gt;BSD&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://pymupdf.readthedocs.io/"&gt;&lt;code&gt;pymupdf&lt;/code&gt;&lt;/a&gt; is substantially faster than &lt;code&gt;pdfminer.six&lt;/code&gt; (and thus also &lt;code&gt;pdfplumber&lt;/code&gt;) and can generate and modify PDFs, but the library requires installation of non-Python software (MuPDF). It also does not enable easy access to shape objects (rectangles, lines, etc.), and does not provide table-extraction or visual debugging tools. License: &lt;a href="https://pymupdf.readthedocs.io/en/latest/about.html#license-and-copyright"&gt;AGPL&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/camelot-dev/camelot"&gt;&lt;code&gt;camelot&lt;/code&gt;&lt;/a&gt;, &lt;a href="https://github.com/chezou/tabula-py"&gt;&lt;code&gt;tabula-py&lt;/code&gt;&lt;/a&gt;, and &lt;a href="https://github.com/drj11/pdftables"&gt;&lt;code&gt;pdftables&lt;/code&gt;&lt;/a&gt; all focus primarily on extracting tables. In some cases, they may be better suited to the particular tables you are trying to extract. License: &lt;a href="https://github.com/camelot-dev/camelot?tab=MIT-1-ov-file#readme"&gt;MIT&lt;/a&gt; (&lt;code&gt;camelot&lt;/code&gt;), &lt;a href="https://github.com/chezou/tabula-py?tab=MIT-1-ov-file#readme"&gt;MIT&lt;/a&gt; (&lt;code&gt;tabula-py&lt;/code&gt;), &lt;a href="https://github.com/drj11/pdftables?tab=BSD-2-Clause-1-ov-file#readme"&gt;BSD&lt;/a&gt; (&lt;code&gt;pdftables&lt;/code&gt;).&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Acknowledgments / Contributors&lt;/h2&gt; 
&lt;p&gt;Many thanks to the following users who've contributed ideas, features, and fixes:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jsfenfen"&gt;Jacob Fenton&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/dannguyen"&gt;Dan Nguyen&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jeffbarrera"&gt;Jeff Barrera&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/boblannon"&gt;Bob Lannon&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/dustindall"&gt;Dustin Tindall&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Yevgnen"&gt;@yevgnen&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/meldonization"&gt;@meldonization&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/OisinMoran"&gt;Oisín Moran&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/samkit-jain"&gt;Samkit Jain&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/frascuchon"&gt;Francisco Aranda&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/cheungpat"&gt;Kwok-kuen Cheung&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ubmarco"&gt;Marco&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/idan-david"&gt;Idan David&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/xv44586"&gt;@xv44586&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/alexreg"&gt;Alexander Regueiro&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/trifling"&gt;Daniel Peña&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/bobluda"&gt;@bobluda&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ramcdona"&gt;@ramcdona&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/johnhuge"&gt;@johnhuge&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jhonatan-lopes"&gt;Jhonatan Lopes&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ethanscorey"&gt;Ethan Corey&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/lolipopshock"&gt;Shannon Shen&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/toshi1127"&gt;Matsumoto Toshi&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jwestwsj"&gt;John West&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/dhdaines"&gt;David Huggins-Daines&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jeremybmerrill"&gt;Jeremy B. Merrill&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/echedey-ls"&gt;Echedey Luis&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/afriedman412"&gt;Andy Friedman&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/aronweiler"&gt;Aron Weiler&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/QuentinAndre11"&gt;Quentin André&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/leorouxx"&gt;Léo Roux&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/wodny"&gt;@wodny&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/stolarczyk"&gt;Michal Stolarczyk&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/brandonrobertz"&gt;Brandon Roberts&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ennamarie19"&gt;@ennamarie19&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Pull requests are welcome, but please submit a proposal issue first, as the library is in active development.&lt;/p&gt; 
&lt;p&gt;Current maintainers:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jsvine"&gt;Jeremy Singer-Vine&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/samkit-jain"&gt;Samkit Jain&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>FunAudioLLM/CosyVoice</title>
      <link>https://github.com/FunAudioLLM/CosyVoice</link>
      <description>&lt;p&gt;Multi-lingual large voice generation model, providing inference, training and deployment full-stack ability.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href="https://github.com/Akshay090/svg-banners"&gt;&lt;img src="https://svg-banners.vercel.app/api?type=origin&amp;amp;text1=CosyVoice%F0%9F%A4%A0&amp;amp;text2=Text-to-Speech%20%F0%9F%92%96%20Large%20Language%20Model&amp;amp;width=800&amp;amp;height=210" alt="SVG Banners" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;👉🏻 CosyVoice 👈🏻&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;CosyVoice 3.0&lt;/strong&gt;: &lt;a href="https://funaudiollm.github.io/cosyvoice3/"&gt;Demos&lt;/a&gt;; &lt;a href="https://arxiv.org/abs/2505.17589"&gt;Paper&lt;/a&gt;; &lt;a href="https://github.com/FunAudioLLM/CV3-Eval"&gt;CV3-Eval&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;CosyVoice 2.0&lt;/strong&gt;: &lt;a href="https://funaudiollm.github.io/cosyvoice2/"&gt;Demos&lt;/a&gt;; &lt;a href="https://arxiv.org/abs/2412.10117"&gt;Paper&lt;/a&gt;; &lt;a href="https://www.modelscope.cn/studios/iic/CosyVoice2-0.5B"&gt;Modelscope&lt;/a&gt;; &lt;a href="https://huggingface.co/spaces/FunAudioLLM/CosyVoice2-0.5B"&gt;HuggingFace&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;CosyVoice 1.0&lt;/strong&gt;: &lt;a href="https://fun-audio-llm.github.io"&gt;Demos&lt;/a&gt;; &lt;a href="https://funaudiollm.github.io/pdf/CosyVoice_v1.pdf"&gt;Paper&lt;/a&gt;; &lt;a href="https://www.modelscope.cn/studios/iic/CosyVoice-300M"&gt;Modelscope&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Highlight🔥&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;CosyVoice 2.0&lt;/strong&gt; has been released! Compared to version 1.0, the new version offers more accurate, more stable, faster, and better speech generation capabilities.&lt;/p&gt; 
&lt;h3&gt;Multilingual&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Supported Language&lt;/strong&gt;: Chinese, English, Japanese, Korean, Chinese dialects (Cantonese, Sichuanese, Shanghainese, Tianjinese, Wuhanese, etc.)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Crosslingual &amp;amp; Mixlingual&lt;/strong&gt;：Support zero-shot voice cloning for cross-lingual and code-switching scenarios.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Ultra-Low Latency&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Bidirectional Streaming Support&lt;/strong&gt;: CosyVoice 2.0 integrates offline and streaming modeling technologies.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Rapid First Packet Synthesis&lt;/strong&gt;: Achieves latency as low as 150ms while maintaining high-quality audio output.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;High Accuracy&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Improved Pronunciation&lt;/strong&gt;: Reduces pronunciation errors by 30% to 50% compared to CosyVoice 1.0.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Benchmark Achievements&lt;/strong&gt;: Attains the lowest character error rate on the hard test set of the Seed-TTS evaluation set.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Strong Stability&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Consistency in Timbre&lt;/strong&gt;: Ensures reliable voice consistency for zero-shot and cross-language speech synthesis.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Cross-language Synthesis&lt;/strong&gt;: Marked improvements compared to version 1.0.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Natural Experience&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Enhanced Prosody and Sound Quality&lt;/strong&gt;: Improved alignment of synthesized audio, raising MOS evaluation scores from 5.4 to 5.53.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Emotional and Dialectal Flexibility&lt;/strong&gt;: Now supports more granular emotional controls and accent adjustments.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Roadmap&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;p&gt;2025/08&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Thanks to the contribution from NVIDIA Yuekai Zhang, add triton trtllm runtime support and cosyvoice2 grpo training support&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;p&gt;2025/07&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; release cosyvoice 3.0 eval set&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;p&gt;2025/05&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; add cosyvoice 2.0 vllm support&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;p&gt;2024/12&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; 25hz cosyvoice 2.0 released&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;p&gt;2024/09&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; 25hz cosyvoice base model&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; 25hz cosyvoice voice conversion model&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;p&gt;2024/08&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Repetition Aware Sampling(RAS) inference for llm stability&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Streaming inference mode support, including kv cache and sdpa for rtf optimization&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;p&gt;2024/07&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Flow matching training support&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; WeTextProcessing support when ttsfrd is not available&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Fastapi server and client&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Install&lt;/h2&gt; 
&lt;h3&gt;Clone and install&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Clone the repo&lt;/p&gt; &lt;pre&gt;&lt;code class="language-sh"&gt;git clone --recursive https://github.com/FunAudioLLM/CosyVoice.git
# If you failed to clone the submodule due to network failures, please run the following command until success
cd CosyVoice
git submodule update --init --recursive
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Install Conda: please see &lt;a href="https://docs.conda.io/en/latest/miniconda.html"&gt;https://docs.conda.io/en/latest/miniconda.html&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Create Conda env:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-sh"&gt;conda create -n cosyvoice -y python=3.10
conda activate cosyvoice
pip install -r requirements.txt -i https://mirrors.aliyun.com/pypi/simple/ --trusted-host=mirrors.aliyun.com

# If you encounter sox compatibility issues
# ubuntu
sudo apt-get install sox libsox-dev
# centos
sudo yum install sox sox-devel
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Model download&lt;/h3&gt; 
&lt;p&gt;We strongly recommend that you download our pretrained &lt;code&gt;CosyVoice2-0.5B&lt;/code&gt; &lt;code&gt;CosyVoice-300M&lt;/code&gt; &lt;code&gt;CosyVoice-300M-SFT&lt;/code&gt; &lt;code&gt;CosyVoice-300M-Instruct&lt;/code&gt; model and &lt;code&gt;CosyVoice-ttsfrd&lt;/code&gt; resource.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# SDK模型下载
from modelscope import snapshot_download
snapshot_download('iic/CosyVoice2-0.5B', local_dir='pretrained_models/CosyVoice2-0.5B')
snapshot_download('iic/CosyVoice-300M', local_dir='pretrained_models/CosyVoice-300M')
snapshot_download('iic/CosyVoice-300M-SFT', local_dir='pretrained_models/CosyVoice-300M-SFT')
snapshot_download('iic/CosyVoice-300M-Instruct', local_dir='pretrained_models/CosyVoice-300M-Instruct')
snapshot_download('iic/CosyVoice-ttsfrd', local_dir='pretrained_models/CosyVoice-ttsfrd')
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;# git模型下载，请确保已安装git lfs
mkdir -p pretrained_models
git clone https://www.modelscope.cn/iic/CosyVoice2-0.5B.git pretrained_models/CosyVoice2-0.5B
git clone https://www.modelscope.cn/iic/CosyVoice-300M.git pretrained_models/CosyVoice-300M
git clone https://www.modelscope.cn/iic/CosyVoice-300M-SFT.git pretrained_models/CosyVoice-300M-SFT
git clone https://www.modelscope.cn/iic/CosyVoice-300M-Instruct.git pretrained_models/CosyVoice-300M-Instruct
git clone https://www.modelscope.cn/iic/CosyVoice-ttsfrd.git pretrained_models/CosyVoice-ttsfrd
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Optionally, you can unzip &lt;code&gt;ttsfrd&lt;/code&gt; resource and install &lt;code&gt;ttsfrd&lt;/code&gt; package for better text normalization performance.&lt;/p&gt; 
&lt;p&gt;Notice that this step is not necessary. If you do not install &lt;code&gt;ttsfrd&lt;/code&gt; package, we will use wetext by default.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;cd pretrained_models/CosyVoice-ttsfrd/
unzip resource.zip -d .
pip install ttsfrd_dependency-0.1-py3-none-any.whl
pip install ttsfrd-0.4.2-cp310-cp310-linux_x86_64.whl
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Basic Usage&lt;/h3&gt; 
&lt;p&gt;We strongly recommend using &lt;code&gt;CosyVoice2-0.5B&lt;/code&gt; for better performance. Follow the code below for detailed usage of each model.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import sys
sys.path.append('third_party/Matcha-TTS')
from cosyvoice.cli.cosyvoice import CosyVoice, CosyVoice2
from cosyvoice.utils.file_utils import load_wav
import torchaudio
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;CosyVoice2 Usage&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;cosyvoice = CosyVoice2('pretrained_models/CosyVoice2-0.5B', load_jit=False, load_trt=False, load_vllm=False, fp16=False)

# NOTE if you want to reproduce the results on https://funaudiollm.github.io/cosyvoice2, please add text_frontend=False during inference
# zero_shot usage
prompt_speech_16k = load_wav('./asset/zero_shot_prompt.wav', 16000)
for i, j in enumerate(cosyvoice.inference_zero_shot('收到好友从远方寄来的生日礼物，那份意外的惊喜与深深的祝福让我心中充满了甜蜜的快乐，笑容如花儿般绽放。', '希望你以后能够做的比我还好呦。', prompt_speech_16k, stream=False)):
    torchaudio.save('zero_shot_{}.wav'.format(i), j['tts_speech'], cosyvoice.sample_rate)

# save zero_shot spk for future usage
assert cosyvoice.add_zero_shot_spk('希望你以后能够做的比我还好呦。', prompt_speech_16k, 'my_zero_shot_spk') is True
for i, j in enumerate(cosyvoice.inference_zero_shot('收到好友从远方寄来的生日礼物，那份意外的惊喜与深深的祝福让我心中充满了甜蜜的快乐，笑容如花儿般绽放。', '', '', zero_shot_spk_id='my_zero_shot_spk', stream=False)):
    torchaudio.save('zero_shot_{}.wav'.format(i), j['tts_speech'], cosyvoice.sample_rate)
cosyvoice.save_spkinfo()

# fine grained control, for supported control, check cosyvoice/tokenizer/tokenizer.py#L248
for i, j in enumerate(cosyvoice.inference_cross_lingual('在他讲述那个荒诞故事的过程中，他突然[laughter]停下来，因为他自己也被逗笑了[laughter]。', prompt_speech_16k, stream=False)):
    torchaudio.save('fine_grained_control_{}.wav'.format(i), j['tts_speech'], cosyvoice.sample_rate)

# instruct usage
for i, j in enumerate(cosyvoice.inference_instruct2('收到好友从远方寄来的生日礼物，那份意外的惊喜与深深的祝福让我心中充满了甜蜜的快乐，笑容如花儿般绽放。', '用四川话说这句话', prompt_speech_16k, stream=False)):
    torchaudio.save('instruct_{}.wav'.format(i), j['tts_speech'], cosyvoice.sample_rate)

# bistream usage, you can use generator as input, this is useful when using text llm model as input
# NOTE you should still have some basic sentence split logic because llm can not handle arbitrary sentence length
def text_generator():
    yield '收到好友从远方寄来的生日礼物，'
    yield '那份意外的惊喜与深深的祝福'
    yield '让我心中充满了甜蜜的快乐，'
    yield '笑容如花儿般绽放。'
for i, j in enumerate(cosyvoice.inference_zero_shot(text_generator(), '希望你以后能够做的比我还好呦。', prompt_speech_16k, stream=False)):
    torchaudio.save('zero_shot_{}.wav'.format(i), j['tts_speech'], cosyvoice.sample_rate)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;CosyVoice2 vllm Usage&lt;/h4&gt; 
&lt;p&gt;If you want to use vllm for inference, please install &lt;code&gt;vllm==v0.9.0&lt;/code&gt;. Older vllm version do not support CosyVoice2 inference.&lt;/p&gt; 
&lt;p&gt;Notice that &lt;code&gt;vllm==v0.9.0&lt;/code&gt; has a lot of specific requirements, for example &lt;code&gt;torch==2.7.0&lt;/code&gt;. You can create a new env to in case your hardward do not support vllm and old env is corrupted.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;conda create -n cosyvoice_vllm --clone cosyvoice
conda activate cosyvoice_vllm
pip install vllm==v0.9.0 transformers==4.51.3 -i https://mirrors.aliyun.com/pypi/simple/ --trusted-host=mirrors.aliyun.com
python vllm_example.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;CosyVoice Usage&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;cosyvoice = CosyVoice('pretrained_models/CosyVoice-300M-SFT', load_jit=False, load_trt=False, fp16=False)
# sft usage
print(cosyvoice.list_available_spks())
# change stream=True for chunk stream inference
for i, j in enumerate(cosyvoice.inference_sft('你好，我是通义生成式语音大模型，请问有什么可以帮您的吗？', '中文女', stream=False)):
    torchaudio.save('sft_{}.wav'.format(i), j['tts_speech'], cosyvoice.sample_rate)

cosyvoice = CosyVoice('pretrained_models/CosyVoice-300M')
# zero_shot usage, &amp;lt;|zh|&amp;gt;&amp;lt;|en|&amp;gt;&amp;lt;|jp|&amp;gt;&amp;lt;|yue|&amp;gt;&amp;lt;|ko|&amp;gt; for Chinese/English/Japanese/Cantonese/Korean
prompt_speech_16k = load_wav('./asset/zero_shot_prompt.wav', 16000)
for i, j in enumerate(cosyvoice.inference_zero_shot('收到好友从远方寄来的生日礼物，那份意外的惊喜与深深的祝福让我心中充满了甜蜜的快乐，笑容如花儿般绽放。', '希望你以后能够做的比我还好呦。', prompt_speech_16k, stream=False)):
    torchaudio.save('zero_shot_{}.wav'.format(i), j['tts_speech'], cosyvoice.sample_rate)
# cross_lingual usage
prompt_speech_16k = load_wav('./asset/cross_lingual_prompt.wav', 16000)
for i, j in enumerate(cosyvoice.inference_cross_lingual('&amp;lt;|en|&amp;gt;And then later on, fully acquiring that company. So keeping management in line, interest in line with the asset that\'s coming into the family is a reason why sometimes we don\'t buy the whole thing.', prompt_speech_16k, stream=False)):
    torchaudio.save('cross_lingual_{}.wav'.format(i), j['tts_speech'], cosyvoice.sample_rate)
# vc usage
prompt_speech_16k = load_wav('./asset/zero_shot_prompt.wav', 16000)
source_speech_16k = load_wav('./asset/cross_lingual_prompt.wav', 16000)
for i, j in enumerate(cosyvoice.inference_vc(source_speech_16k, prompt_speech_16k, stream=False)):
    torchaudio.save('vc_{}.wav'.format(i), j['tts_speech'], cosyvoice.sample_rate)

cosyvoice = CosyVoice('pretrained_models/CosyVoice-300M-Instruct')
# instruct usage, support &amp;lt;laughter&amp;gt;&amp;lt;/laughter&amp;gt;&amp;lt;strong&amp;gt;&amp;lt;/strong&amp;gt;[laughter][breath]
for i, j in enumerate(cosyvoice.inference_instruct('在面对挑战时，他展现了非凡的&amp;lt;strong&amp;gt;勇气&amp;lt;/strong&amp;gt;与&amp;lt;strong&amp;gt;智慧&amp;lt;/strong&amp;gt;。', '中文男', 'Theo \'Crimson\', is a fiery, passionate rebel leader. Fights with fervor for justice, but struggles with impulsiveness.', stream=False)):
    torchaudio.save('instruct_{}.wav'.format(i), j['tts_speech'], cosyvoice.sample_rate)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Start web demo&lt;/h4&gt; 
&lt;p&gt;You can use our web demo page to get familiar with CosyVoice quickly.&lt;/p&gt; 
&lt;p&gt;Please see the demo website for details.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# change iic/CosyVoice-300M-SFT for sft inference, or iic/CosyVoice-300M-Instruct for instruct inference
python3 webui.py --port 50000 --model_dir pretrained_models/CosyVoice-300M
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Advanced Usage&lt;/h4&gt; 
&lt;p&gt;For advanced users, we have provided training and inference scripts in &lt;code&gt;examples/libritts/cosyvoice/run.sh&lt;/code&gt;.&lt;/p&gt; 
&lt;h4&gt;Build for deployment&lt;/h4&gt; 
&lt;p&gt;Optionally, if you want service deployment, You can run the following steps.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;cd runtime/python
docker build -t cosyvoice:v1.0 .
# change iic/CosyVoice-300M to iic/CosyVoice-300M-Instruct if you want to use instruct inference
# for grpc usage
docker run -d --runtime=nvidia -p 50000:50000 cosyvoice:v1.0 /bin/bash -c "cd /opt/CosyVoice/CosyVoice/runtime/python/grpc &amp;amp;&amp;amp; python3 server.py --port 50000 --max_conc 4 --model_dir iic/CosyVoice-300M &amp;amp;&amp;amp; sleep infinity"
cd grpc &amp;amp;&amp;amp; python3 client.py --port 50000 --mode &amp;lt;sft|zero_shot|cross_lingual|instruct&amp;gt;
# for fastapi usage
docker run -d --runtime=nvidia -p 50000:50000 cosyvoice:v1.0 /bin/bash -c "cd /opt/CosyVoice/CosyVoice/runtime/python/fastapi &amp;amp;&amp;amp; python3 server.py --port 50000 --model_dir iic/CosyVoice-300M &amp;amp;&amp;amp; sleep infinity"
cd fastapi &amp;amp;&amp;amp; python3 client.py --port 50000 --mode &amp;lt;sft|zero_shot|cross_lingual|instruct&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Using Nvidia TensorRT-LLM for deployment&lt;/h4&gt; 
&lt;p&gt;Using TensorRT-LLM to accelerate cosyvoice2 llm could give 4x acceleration comparing with huggingface transformers implementation. To quick start:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;cd runtime/triton_trtllm
docker compose up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For more details, you could check &lt;a href="https://github.com/FunAudioLLM/CosyVoice/tree/main/runtime/triton_trtllm"&gt;here&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Discussion &amp;amp; Communication&lt;/h2&gt; 
&lt;p&gt;You can directly discuss on &lt;a href="https://github.com/FunAudioLLM/CosyVoice/issues"&gt;Github Issues&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;You can also scan the QR code to join our official Dingding chat group.&lt;/p&gt; 
&lt;img src="https://raw.githubusercontent.com/FunAudioLLM/CosyVoice/main/asset/dingding.png" width="250px" /&gt; 
&lt;h2&gt;Acknowledge&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;We borrowed a lot of code from &lt;a href="https://github.com/modelscope/FunASR"&gt;FunASR&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;We borrowed a lot of code from &lt;a href="https://github.com/modelscope/FunCodec"&gt;FunCodec&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;We borrowed a lot of code from &lt;a href="https://github.com/shivammehta25/Matcha-TTS"&gt;Matcha-TTS&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;We borrowed a lot of code from &lt;a href="https://github.com/yangdongchao/AcademiCodec"&gt;AcademiCodec&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;We borrowed a lot of code from &lt;a href="https://github.com/wenet-e2e/wenet"&gt;WeNet&lt;/a&gt;.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Citations&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bibtex"&gt;@article{du2024cosyvoice,
  title={Cosyvoice: A scalable multilingual zero-shot text-to-speech synthesizer based on supervised semantic tokens},
  author={Du, Zhihao and Chen, Qian and Zhang, Shiliang and Hu, Kai and Lu, Heng and Yang, Yexin and Hu, Hangrui and Zheng, Siqi and Gu, Yue and Ma, Ziyang and others},
  journal={arXiv preprint arXiv:2407.05407},
  year={2024}
}

@article{du2024cosyvoice,
  title={Cosyvoice 2: Scalable streaming speech synthesis with large language models},
  author={Du, Zhihao and Wang, Yuxuan and Chen, Qian and Shi, Xian and Lv, Xiang and Zhao, Tianyu and Gao, Zhifu and Yang, Yexin and Gao, Changfeng and Wang, Hui and others},
  journal={arXiv preprint arXiv:2412.10117},
  year={2024}
}

@article{du2025cosyvoice,
  title={CosyVoice 3: Towards In-the-wild Speech Generation via Scaling-up and Post-training},
  author={Du, Zhihao and Gao, Changfeng and Wang, Yuxuan and Yu, Fan and Zhao, Tianyu and Wang, Hao and Lv, Xiang and Wang, Hui and Shi, Xian and An, Keyu and others},
  journal={arXiv preprint arXiv:2505.17589},
  year={2025}
}

@inproceedings{lyu2025build,
  title={Build LLM-Based Zero-Shot Streaming TTS System with Cosyvoice},
  author={Lyu, Xiang and Wang, Yuxuan and Zhao, Tianyu and Wang, Hao and Liu, Huadai and Du, Zhihao},
  booktitle={ICASSP 2025-2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={1--2},
  year={2025},
  organization={IEEE}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Disclaimer&lt;/h2&gt; 
&lt;p&gt;The content provided above is for academic purposes only and is intended to demonstrate technical capabilities. Some examples are sourced from the internet. If any content infringes on your rights, please contact us to request its removal.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>bregman-arie/devops-exercises</title>
      <link>https://github.com/bregman-arie/devops-exercises</link>
      <description>&lt;p&gt;Linux, Jenkins, AWS, SRE, Prometheus, Docker, Python, Ansible, Git, Kubernetes, Terraform, OpenStack, SQL, NoSQL, Azure, GCP, DNS, Elastic, Network, Virtualization. DevOps Interview Questions&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt;&lt;img src="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/images/devops_exercises.png" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;ℹ&lt;/span&gt; &amp;nbsp;This repo contains questions and exercises on various technical topics, sometimes related to DevOps and SRE&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;📊&lt;/span&gt; &amp;nbsp;There are currently &lt;strong&gt;2624&lt;/strong&gt; exercises and questions&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;⚠&lt;/span&gt; &amp;nbsp;You can use these for preparing for an interview but most of the questions and exercises don't represent an actual interview. Please read &lt;a href="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/faq.md"&gt;FAQ page&lt;/a&gt; for more details&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;🛑&lt;/span&gt; &amp;nbsp;If you are interested in pursuing a career as DevOps engineer, learning some of the concepts mentioned here would be useful, but you should know it's not about learning all the topics and technologies mentioned in this repository&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;📝&lt;/span&gt; &amp;nbsp;You can add more exercises by submitting pull requests :) Read about contribution guidelines &lt;a href="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/CONTRIBUTING.md"&gt;here&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;!-- ALL-TOPICS-LIST:START --&gt; 
&lt;!-- prettier-ignore-start --&gt; 
&lt;!-- markdownlint-disable --&gt; 
&lt;center&gt; 
 &lt;table&gt; 
  &lt;tbody&gt;
   &lt;tr&gt; 
    &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/topics/devops/README.md"&gt;&lt;img src="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/images/devops.png" width="75px;" height="75px;" alt="DevOps" /&gt;&lt;br /&gt;&lt;b&gt;DevOps&lt;/b&gt;&lt;/a&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/topics/git/README.md"&gt;&lt;img src="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/images/git.png" width="75px;" height="75px;" alt="Git" /&gt;&lt;br /&gt;&lt;b&gt;Git&lt;/b&gt;&lt;/a&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/#network"&gt;&lt;img src="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/images/network.png" width="75px;" height="75px;" alt="Network" /&gt;&lt;br /&gt;&lt;b&gt;Network&lt;/b&gt;&lt;/a&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/#hardware"&gt;&lt;img src="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/images/hardware.png" width="75px;" height="75px;" alt="Hardware" /&gt;&lt;br /&gt;&lt;b&gt;Hardware&lt;/b&gt;&lt;/a&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/topics/kubernetes/README.md"&gt;&lt;img src="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/images/kubernetes.png" width="75px;" height="75px;" alt="kubernetes" /&gt;&lt;br /&gt;&lt;b&gt;Kubernetes&lt;/b&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/topics/software_development/README.md"&gt;&lt;img src="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/images/programming.png" width="75px;" height="75px;" alt="programming" /&gt;&lt;br /&gt;&lt;b&gt;Software Development&lt;/b&gt;&lt;/a&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;a href="https://github.com/bregman-arie/python-exercises"&gt;&lt;img src="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/images/python.png" width="75px;" height="75px;" alt="Python" /&gt;&lt;br /&gt;&lt;b&gt;Python&lt;/b&gt;&lt;/a&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;a href="https://github.com/bregman-arie/go-exercises"&gt;&lt;img src="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/images/Go.png" width="75px;" height="75px;" alt="go" /&gt;&lt;br /&gt;&lt;b&gt;Go&lt;/b&gt;&lt;/a&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/topics/perl/README.md"&gt;&lt;img src="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/images/perl.png" width="75px;" height="75px;" alt="perl" /&gt;&lt;br /&gt;&lt;b&gt;Perl&lt;/b&gt;&lt;/a&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/#regex"&gt;&lt;img src="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/images/regex.png" width="75px;" height="75px;" alt="RegEx" /&gt;&lt;br /&gt;&lt;b&gt;Regex&lt;/b&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/topics/cloud/README.md"&gt;&lt;img src="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/images/cloud.png" width="75px;" height="75px;" alt="Cloud" /&gt;&lt;br /&gt;&lt;b&gt;Cloud&lt;/b&gt;&lt;/a&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/topics/aws/README.md"&gt;&lt;img src="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/images/aws.png" width="100px;" height="75px;" alt="aws" /&gt;&lt;br /&gt;&lt;b&gt;AWS&lt;/b&gt;&lt;/a&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/topics/azure/README.md"&gt;&lt;img src="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/images/azure.png" width="75px;" height="75px;" alt="azure" /&gt;&lt;br /&gt;&lt;b&gt;Azure&lt;/b&gt;&lt;/a&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/topics/gcp/README.md"&gt;&lt;img src="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/images/googlecloud.png" width="70px;" height="70px;" alt="Google Cloud Platform" /&gt;&lt;br /&gt;&lt;b&gt;Google Cloud Platform&lt;/b&gt;&lt;/a&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/#openstack/README.md"&gt;&lt;img src="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/images/openstack.png" width="75px;" height="75px;" alt="openstack" /&gt;&lt;br /&gt;&lt;b&gt;OpenStack&lt;/b&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/#operating-system"&gt;&lt;img src="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/images/os.png" width="75px;" height="75px;" alt="Operating System" /&gt;&lt;br /&gt;&lt;b&gt;Operating System&lt;/b&gt;&lt;/a&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/topics/linux/README.md"&gt;&lt;img src="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/images/logos/linux.png" width="75px;" height="75px;" alt="Linux" /&gt;&lt;br /&gt;&lt;b&gt;Linux&lt;/b&gt;&lt;/a&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/#virtualization"&gt;&lt;img src="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/images/virtualization.png" width="75px;" height="75px;" alt="Virtualization" /&gt;&lt;br /&gt;&lt;b&gt;Virtualization&lt;/b&gt;&lt;/a&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/topics/dns/README.md"&gt;&lt;img src="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/images/dns.png" width="75px;" height="75px;" alt="DNS" /&gt;&lt;br /&gt;&lt;b&gt;DNS&lt;/b&gt;&lt;/a&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/topics/shell/README.md"&gt;&lt;img src="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/images/bash.png" width="75px;" height="75px;" alt="Bash" /&gt;&lt;br /&gt;&lt;b&gt;Shell Scripting&lt;/b&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/topics/databases/README.md"&gt;&lt;img src="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/images/databases.png" width="75px;" height="75px;" alt="Databases" /&gt;&lt;br /&gt;&lt;b&gt;Databases&lt;/b&gt;&lt;/a&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/#sql"&gt;&lt;img src="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/images/sql.png" width="75px;" height="75px;" alt="sql" /&gt;&lt;br /&gt;&lt;b&gt;SQL&lt;/b&gt;&lt;/a&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/#mongo"&gt;&lt;img src="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/images/mongo.png" width="75px;" height="75px;" alt="Mongo" /&gt;&lt;br /&gt;&lt;b&gt;Mongo&lt;/b&gt;&lt;/a&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/#testing"&gt;&lt;img src="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/images/testing.png" width="75px;" height="75px;" alt="Testing" /&gt;&lt;br /&gt;&lt;b&gt;Testing&lt;/b&gt;&lt;/a&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/#big-data"&gt;&lt;img src="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/images/big-data.png" width="75px;" height="75px;" alt="Big Data" /&gt;&lt;br /&gt;&lt;b&gt;Big Data&lt;/b&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/topics/cicd/README.md"&gt;&lt;img src="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/images/cicd.png" width="75px;" height="75px;" alt="cicd" /&gt;&lt;br /&gt;&lt;b&gt;CI/CD&lt;/b&gt;&lt;/a&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/#certificates"&gt;&lt;img src="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/images/certificates.png" width="75px;" height="75px;" alt="Certificates" /&gt;&lt;br /&gt;&lt;b&gt;Certificates&lt;/b&gt;&lt;/a&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/topics/containers/README.md"&gt;&lt;img src="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/images/containers.png" width="75px;" height="75px;" alt="Containers" /&gt;&lt;br /&gt;&lt;b&gt;Containers&lt;/b&gt;&lt;/a&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/topics/openshift/README.md"&gt;&lt;img src="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/images/openshift.png" width="75px;" height="75px;" alt="OpenShift" /&gt;&lt;br /&gt;&lt;b&gt;OpenShift&lt;/b&gt;&lt;/a&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/#storage"&gt;&lt;img src="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/images/storage.png" width="75px;" height="75px;" alt="Storage" /&gt;&lt;br /&gt;&lt;b&gt;Storage&lt;/b&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/topics/terraform/README.md"&gt;&lt;img src="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/images/terraform.png" width="75px;" height="75px;" alt="Terraform" /&gt;&lt;br /&gt;&lt;b&gt;Terraform&lt;/b&gt;&lt;/a&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/#puppet"&gt;&lt;img src="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/images/puppet.png" width="75px;" height="75px;" alt="puppet" /&gt;&lt;br /&gt;&lt;b&gt;Puppet&lt;/b&gt;&lt;/a&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/#distributed"&gt;&lt;img src="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/images/distributed.png" width="75px;" height="75px;" alt="Distributed" /&gt;&lt;br /&gt;&lt;b&gt;Distributed&lt;/b&gt;&lt;/a&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/#questions-you-ask"&gt;&lt;img src="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/images/you.png" width="75px;" height="75px;" alt="you" /&gt;&lt;br /&gt;&lt;b&gt;Questions you can ask&lt;/b&gt;&lt;/a&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/topics/ansible/README.md"&gt;&lt;img src="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/images/ansible.png" width="75px;" height="75px;" alt="ansible" /&gt;&lt;br /&gt;&lt;b&gt;Ansible&lt;/b&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/topics/observability/README.md"&gt;&lt;img src="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/images/observability.png" width="75px;" height="75px;" alt="observability" /&gt;&lt;br /&gt;&lt;b&gt;Observability&lt;/b&gt;&lt;/a&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/#prometheus"&gt;&lt;img src="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/images/prometheus.png" width="75px;" height="75px;" alt="Prometheus" /&gt;&lt;br /&gt;&lt;b&gt;Prometheus&lt;/b&gt;&lt;/a&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/topics/circleci/README.md"&gt;&lt;img src="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/images/logos/circleci.png" width="70px;" height="70px;" alt="Circle CI" /&gt;&lt;br /&gt;&lt;b&gt;Circle CI&lt;/b&gt;&lt;/a&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/topics/datadog/README.md"&gt;&lt;img src="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/images/logos/datadog.png" width="80px;" height="80px;" alt="DataDog" /&gt;&lt;br /&gt;&lt;b&gt;&lt;/b&gt;&lt;/a&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/topics/grafana/README.md"&gt;&lt;img src="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/images/logos/grafana.png" width="80px;" height="80px;" alt="Grafana" /&gt;&lt;br /&gt;&lt;b&gt;Grafana&lt;/b&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/topics/argo/README.md"&gt;&lt;img src="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/images/logos/argo.png" width="80px;" height="80px;" alt="Argo" /&gt;&lt;br /&gt;&lt;b&gt;Argo&lt;/b&gt;&lt;/a&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/topics/soft_skills/README.md"&gt;&lt;img src="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/images/HR.png" width="75px;" height="75px;" alt="HR" /&gt;&lt;br /&gt;&lt;b&gt;Soft Skills&lt;/b&gt;&lt;/a&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/topics/security/README.md"&gt;&lt;img src="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/images/security.png" width="75px;" height="75px;" alt="security" /&gt;&lt;br /&gt;&lt;b&gt;Security&lt;/b&gt;&lt;/a&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/#system-design"&gt;&lt;img src="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/images/design.png" width="75px;" height="75px;" alt="Design" /&gt;&lt;br /&gt;&lt;b&gt;System Design&lt;/b&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/topics/chaos_engineering/README.md"&gt;&lt;img src="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/images/logos/chaos_engineering.png" width="75px;" height="75px;" alt="Chaos Engineering" /&gt;&lt;br /&gt;&lt;b&gt;Chaos Engineering&lt;/b&gt;&lt;/a&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/#Misc"&gt;&lt;img src="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/images/general.png" width="75px;" height="75px;" alt="Misc" /&gt;&lt;br /&gt;&lt;b&gt;Misc&lt;/b&gt;&lt;/a&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/#elastic"&gt;&lt;img src="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/images/elastic.png" width="75px;" height="75px;" alt="Elastic" /&gt;&lt;br /&gt;&lt;b&gt;Elastic&lt;/b&gt;&lt;/a&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/topics/kafka/README.md"&gt;&lt;img src="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/images/logos/kafka.png" width="85px;" height="80px;" alt="Kafka" /&gt;&lt;br /&gt;&lt;b&gt;Kafka&lt;/b&gt;&lt;/a&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/topics/node/node_questions_basic.md"&gt;&lt;img src="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/images/nodejs.png" width="85px;" height="80px;" alt="NodeJs" /&gt;&lt;br /&gt;&lt;b&gt;NodeJs&lt;/b&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt;
 &lt;/table&gt; 
&lt;/center&gt; 
&lt;!-- markdownlint-enable --&gt; 
&lt;!-- prettier-ignore-end --&gt; 
&lt;!-- ALL-TOPICS-LIST:END --&gt; 
&lt;h2&gt;DevOps Applications&lt;/h2&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;a href="https://play.google.com/store/apps/details?id=com.codingshell.kubeprep"&gt;&lt;img src="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/images/apps/kubeprep.png" width="200px;" height="300px;" alt="KubePrep" /&gt;&lt;br /&gt;&lt;b&gt;KubePrep&lt;/b&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://play.google.com/store/apps/details?id=com.codingshell.linuxmaster"&gt;&lt;img src="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/images/apps/linux_master.png" width="200px;" height="300px;" alt="Linux Master" /&gt;&lt;br /&gt;&lt;b&gt;Linux Master&lt;/b&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://play.google.com/store/apps/details?id=com.codingshell.system_design_hero"&gt;&lt;img src="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/images/apps/system_design_hero.png" width="200px;" height="300px;" alt="Sytem Design Hero" /&gt;&lt;br /&gt;&lt;b&gt;System Design Hero&lt;/b&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h2&gt;Network&lt;/h2&gt; 
&lt;details&gt; 
 &lt;summary&gt;In general, what do you need in order to communicate?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; 
  &lt;ul&gt; 
   &lt;li&gt;A common language (for the two ends to understand)&lt;/li&gt; 
   &lt;li&gt;A way to address who you want to communicate with&lt;/li&gt; 
   &lt;li&gt;A Connection (so the content of the communication can reach the recipients)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;&lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;What is TCP/IP?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;p&gt;A set of protocols that define how two or more devices can communicate with each other.&lt;/p&gt; &lt;p&gt;To learn more about TCP/IP, read &lt;a href="http://www.penguintutor.com/linux/basic-network-reference"&gt;here&lt;/a&gt;&lt;/p&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;&lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;What is Ethernet?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;p&gt;Ethernet simply refers to the most common type of Local Area Network (LAN) used today. A LAN—in contrast to a WAN (Wide Area Network), which spans a larger geographical area—is a connected network of computers in a small area, like your office, college campus, or even home.&lt;/p&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;&lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;What is a MAC address? What is it used for?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;p&gt;A MAC address is a unique identification number or code used to identify individual devices on the network.&lt;/p&gt; &lt;p&gt;Packets that are sent on the ethernet are always coming from a MAC address and sent to a MAC address. If a network adapter is receiving a packet, it is comparing the packet’s destination MAC address to the adapter’s own MAC address.&lt;/p&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;&lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;When is this MAC address used?: ff:ff:ff:ff:ff:ff&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;When a device sends a packet to the broadcast MAC address (FF:FF:FF:FF:FF:FF​), it is delivered to all stations on the local network. Ethernet broadcasts are used to resolve IP addresses to MAC addresses (by ARP) at the data link layer. &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;What is an IP address?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;An Internet Protocol address (IP address) is a numerical label assigned to each device connected to a computer network that uses the Internet Protocol for communication.An IP address serves two main functions: host or network interface identification and location addressing. &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;Explain the subnet mask and give an example&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;p&gt;A Subnet mask is a 32-bit number that masks an IP address and divides the IP addresses into network addresses and host addresses. Subnet Mask is made by setting network bits to all "1"s and setting host bits to all "0"s. Within a given network, out of the total usable host addresses, two are always reserved for specific purposes and cannot be allocated to any host. These are the first address, which is reserved as a network address (a.k.a network ID), and the last address used for network broadcast.&lt;/p&gt; &lt;p&gt;&lt;a href="https://github.com/philemonnwanne/projects/tree/main/exercises/exe-09"&gt;Example&lt;/a&gt;&lt;/p&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;&lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;What is a private IP address? In which scenarios/system designs, one should use it?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; Private IP addresses are assigned to the hosts in the same network to communicate with one another. As the name "private" suggests, the devices having the private IP addresses assigned can't be reached by the devices from any external network. For example, if I am living in a hostel and I want my hostel mates to join the game server I have hosted, I will ask them to join via my server's private IP address, since the network is local to the hostel. &lt;/b&gt;
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;What is a public IP address? In which scenarios/system designs, one should use it?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; A public IP address is a public-facing IP address. In the event that you were hosting a game server that you want your friends to join, you will give your friends your public IP address to allow their computers to identify and locate your network and server in order for the connection to take place. One time that you would not need to use a public-facing IP address is in the event that you were playing with friends who were connected to the same network as you, in that case, you would use a private IP address. In order for someone to be able to connect to your server that is located internally, you will have to set up a port forward to tell your router to allow traffic from the public domain into your network and vice versa. &lt;/b&gt;
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Explain the OSI model. What layers there are? What each layer is responsible for?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Application: user end (HTTP is here)&lt;/li&gt; 
   &lt;li&gt;Presentation: establishes context between application-layer entities (Encryption is here)&lt;/li&gt; 
   &lt;li&gt;Session: establishes, manages, and terminates the connections&lt;/li&gt; 
   &lt;li&gt;Transport: transfers variable-length data sequences from a source to a destination host (TCP &amp;amp; UDP are here)&lt;/li&gt; 
   &lt;li&gt;Network: transfers datagrams from one network to another (IP is here)&lt;/li&gt; 
   &lt;li&gt;Data link: provides a link between two directly connected nodes (MAC is here)&lt;/li&gt; 
   &lt;li&gt;Physical: the electrical and physical spec of the data connection (Bits are here)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;You can read more about the OSI model in &lt;a href="http://www.penguintutor.com/linux/basic-network-reference"&gt;penguintutor.com&lt;/a&gt; &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;For each of the following determines to which OSI layer it belongs: 
  &lt;ul&gt; 
   &lt;li&gt;Error correction&lt;/li&gt; 
   &lt;li&gt;Packets routing&lt;/li&gt; 
   &lt;li&gt;Cables and electrical signals&lt;/li&gt; 
   &lt;li&gt;MAC address&lt;/li&gt; 
   &lt;li&gt;IP address&lt;/li&gt; 
   &lt;li&gt;Terminate connections&lt;/li&gt; 
   &lt;li&gt;3 way handshake&lt;/li&gt;
  &lt;/ul&gt;&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;li&gt;Error correction - Data link&lt;/li&gt; &lt;li&gt;Packets routing - Network&lt;/li&gt; &lt;li&gt;Cables and electrical signals - Physical&lt;/li&gt; &lt;li&gt;MAC address - Data link&lt;/li&gt; &lt;li&gt;IP address - Network&lt;/li&gt; &lt;li&gt;Terminate connections - Session&lt;/li&gt; &lt;/b&gt;
 &lt;li&gt;&lt;b&gt;3-way handshake - Transport &lt;/b&gt;&lt;/li&gt;
&lt;/details&gt;  
&lt;details&gt; 
 &lt;summary&gt;What delivery schemes are you familiar with?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;p&gt;Unicast: One-to-one communication where there is one sender and one receiver.&lt;/p&gt; &lt;p&gt;Broadcast: Sending a message to everyone in the network. The address ff:ff:ff:ff:ff:ff is used for broadcasting. Two common protocols which use broadcast are ARP and DHCP.&lt;/p&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;Multicast: Sending a message to a group of subscribers. It can be one-to-many or many-to-many. &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;What is CSMA/CD? Is it used in modern ethernet networks?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;p&gt;CSMA/CD stands for Carrier Sense Multiple Access / Collision Detection. Its primary focus is to manage access to a shared medium/bus where only one host can transmit at a given point in time.&lt;/p&gt; &lt;p&gt;CSMA/CD algorithm:&lt;/p&gt; &lt;/b&gt;
 &lt;ol&gt;
  &lt;b&gt; &lt;li&gt;Before sending a frame, it checks whether another host is already transmitting a frame.&lt;/li&gt; &lt;li&gt;If no one is transmitting, it starts transmitting the frame.&lt;/li&gt; &lt;li&gt;If two hosts transmit at the same time, we have a collision.&lt;/li&gt; &lt;li&gt;Both hosts stop sending the frame and they send everyone a 'jam signal' notifying everyone that a collision occurred&lt;/li&gt; &lt;li&gt;They are waiting for a random time before sending it again&lt;/li&gt; &lt;li&gt;Once each host waited for a random time, they try to send the frame again and so the cycle starts again &lt;/li&gt;&lt;/b&gt;
 &lt;/ol&gt;
&lt;/details&gt;  
&lt;details&gt; 
 &lt;summary&gt;Describe the following network devices and the difference between them: 
  &lt;ul&gt; 
   &lt;li&gt;router&lt;/li&gt; 
   &lt;li&gt;switch&lt;/li&gt; 
   &lt;li&gt;hub&lt;/li&gt;
  &lt;/ul&gt;&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt;  &lt;p&gt;A router, switch, and hub are all network devices used to connect devices in a local area network (LAN). However, each device operates differently and has its specific use cases. Here is a brief description of each device and the differences between them:&lt;/p&gt; &lt;/b&gt;
 &lt;ol&gt;
  &lt;b&gt; &lt;li&gt;Router: a network device that connects multiple network segments together. It operates at the&amp;nbsp;network layer (Layer 3)&amp;nbsp;of the OSI model and uses routing protocols to direct data between networks. Routers use IP addresses to identify devices and route data packets to the correct destination.&lt;/li&gt; &lt;li&gt;Switch: a network device that connects multiple devices on a LAN. It operates at the&amp;nbsp;data link layer (Layer 2)&amp;nbsp;of the OSI model and uses MAC addresses to identify devices and direct data packets to the correct destination. Switches allow devices on the same network to communicate with each other more efficiently and can prevent data collisions that can occur when multiple devices send data simultaneously.&lt;/li&gt; &lt;li&gt;Hub: a network device that connects multiple devices through a single cable and is used to connect multiple devices without segmenting a network. However, unlike a switch, it operates at the&amp;nbsp;physical layer (Layer 1)&amp;nbsp;of the OSI model and simply broadcasts data packets to all devices connected to it, regardless of whether the device is the intended recipient or not. This means that data collisions can occur, and the network's efficiency can suffer as a result. Hubs are generally not used in modern network setups, as switches are more efficient and provide better network performance. &lt;/li&gt;&lt;/b&gt;
 &lt;/ol&gt;
&lt;/details&gt;  
&lt;details&gt; 
 &lt;summary&gt;What is a "Collision Domain"?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; A collision domain is a network segment in which devices can potentially interfere with each other by attempting to transmit data at the same time. When two devices transmit data at the same time, it can cause a collision, resulting in lost or corrupted data. In a collision domain, all devices share the same bandwidth, and any device can potentially interfere with the transmission of data by other devices. &lt;/b&gt;
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;What is a "Broadcast Domain"?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; A broadcast domain is a network segment in which all devices can communicate with each other by sending broadcast messages. A broadcast message is a message that is sent to all devices in a network rather than a specific device. In a broadcast domain, all devices can receive and process broadcast messages, regardless of whether the message was intended for them or not. &lt;/b&gt;
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;three computers connected to a switch. How many collision domains are there? How many broadcast domains?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;Three collision domains and one broadcast domain &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;How does a router work?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;p&gt;A router is a physical or virtual appliance that passes information between two or more packet-switched computer networks. A router inspects a given data packet's destination Internet Protocol address (IP address), calculates the best way for it to reach its destination, and then forwards it accordingly.&lt;/p&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;&lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;What is NAT?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;p&gt;Network Address Translation (NAT) is a process in which one or more local IP addresses are translated into one or more Global IP address and vice versa in order to provide Internet access to the local hosts.&lt;/p&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;&lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;What is a proxy? How does it work? What do we need it for?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;p&gt;A proxy server acts as a gateway between you and the internet. It’s an intermediary server separating end users from the websites they browse.&lt;/p&gt; &lt;p&gt;If you’re using a proxy server, internet traffic flows through the proxy server on its way to the address you requested. The request then comes back through that same proxy server (there are exceptions to this rule), and then the proxy server forwards the data received from the website to you.&lt;/p&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;Proxy servers provide varying levels of functionality, security, and privacy depending on your use case, needs, or company policy. &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;What is TCP? How does it work? What is the 3-way handshake?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;p&gt;TCP 3-way handshake or three-way handshake is a process that is used in a TCP/IP network to make a connection between server and client.&lt;/p&gt; &lt;p&gt;A three-way handshake is primarily used to create a TCP socket connection. It works when:&lt;/p&gt; &lt;/b&gt;
 &lt;ul&gt;
  &lt;b&gt; &lt;li&gt;A client node sends an SYN data packet over an IP network to a server on the same or an external network. The objective of this packet is to ask/infer if the server is open for new connections.&lt;/li&gt; &lt;li&gt;The target server must have open ports that can accept and initiate new connections. When the server receives the SYN packet from the client node, it responds and returns a confirmation receipt – the ACK packet or SYN/ACK packet.&lt;/li&gt; &lt;li&gt;The client node receives the SYN/ACK from the server and responds with an ACK packet. &lt;/li&gt;&lt;/b&gt;
 &lt;/ul&gt;
&lt;/details&gt;  
&lt;details&gt; 
 &lt;summary&gt;What is round-trip delay or round-trip time?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;p&gt;From &lt;a href="https://en.wikipedia.org/wiki/Round-trip_delay"&gt;wikipedia&lt;/a&gt;: "the length of time it takes for a signal to be sent plus the length of time it takes for an acknowledgment of that signal to be received"&lt;/p&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;Bonus question: what is the RTT of LAN? &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;How does an SSL handshake work?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; SSL handshake is a process that establishes a secure connection between a client and a server. &lt;/b&gt;
 &lt;ol&gt;
  &lt;b&gt; &lt;li&gt;The client sends a Client Hello message to the server, which includes the client's version of the SSL/TLS protocol, a list of the cryptographic algorithms supported by the client, and a random value.&lt;/li&gt; &lt;li&gt;The server responds with a Server Hello message, which includes the server's version of the SSL/TLS protocol, a random value, and a session ID.&lt;/li&gt; &lt;li&gt;The server sends a Certificate message, which contains the server's certificate.&lt;/li&gt; &lt;li&gt;The server sends a Server Hello Done message, which indicates that the server is done sending messages for the Server Hello phase.&lt;/li&gt; &lt;li&gt;The client sends a Client Key Exchange message, which contains the client's public key.&lt;/li&gt; &lt;li&gt;The client sends a Change Cipher Spec message, which notifies the server that the client is about to send a message encrypted with the new cipher spec.&lt;/li&gt; &lt;li&gt;The client sends an Encrypted Handshake Message, which contains the pre-master secret encrypted with the server's public key.&lt;/li&gt; &lt;li&gt;The server sends a Change Cipher Spec message, which notifies the client that the server is about to send a message encrypted with the new cipher spec.&lt;/li&gt; &lt;li&gt;The server sends an Encrypted Handshake Message, which contains the pre-master secret encrypted with the client's public key.&lt;/li&gt; &lt;li&gt;The client and server can now exchange application data. &lt;/li&gt;&lt;/b&gt;
 &lt;/ol&gt;
&lt;/details&gt;  
&lt;details&gt; 
 &lt;summary&gt;What is the difference between TCP and UDP?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;p&gt;TCP establishes a connection between the client and the server to guarantee the order of the packages, on the other hand, UDP does not establish a connection between the client and server and doesn't handle package orders. This makes UDP more lightweight than TCP and a perfect candidate for services like streaming.&lt;/p&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;&lt;a href="http://www.penguintutor.com/linux/basic-network-reference"&gt;Penguintutor.com&lt;/a&gt; provides a good explanation. &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;What TCP/IP protocols are you familiar with?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Explain the "default gateway"&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;A default gateway serves as an access point or IP router that a networked computer uses to send information to a computer in another network or the internet. &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;What is ARP? How does it work?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;p&gt;ARP stands for Address Resolution Protocol. When you try to ping an IP address on your local network, say 192.168.1.1, your system has to turn the IP address 192.168.1.1 into a MAC address. This involves using ARP to resolve the address, hence its name.&lt;/p&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;Systems keep an ARP look-up table where they store information about what IP addresses are associated with what MAC addresses. When trying to send a packet to an IP address, the system will first consult this table to see if it already knows the MAC address. If there is a value cached, ARP is not used. &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;What is TTL? What does it help to prevent?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;ul&gt;
  &lt;b&gt; &lt;li&gt;TTL (Time to Live) is a value in an IP (Internet Protocol) packet that determines how many hops or routers a packet can travel before it is discarded. Each time a packet is forwarded by a router, the TTL value is decreased by one. When the TTL value reaches zero, the packet is dropped, and an ICMP (Internet Control Message Protocol) message is sent back to the sender indicating that the packet has expired.&lt;/li&gt; &lt;li&gt;TTL is used to prevent packets from circulating indefinitely in the network, which can cause congestion and degrade network performance.&lt;/li&gt; &lt;li&gt;It also helps to prevent packets from being trapped in routing loops, where packets continuously travel between the same set of routers without ever reaching their destination.&lt;/li&gt; &lt;li&gt;In addition, TTL can be used to help detect and prevent IP spoofing attacks, where an attacker attempts to impersonate another device on the network by using a false or fake IP address. By limiting the number of hops that a packet can travel, TTL can help prevent packets from being routed to destinations that are not legitimate. &lt;/li&gt;&lt;/b&gt;
 &lt;/ul&gt;
&lt;/details&gt;  
&lt;details&gt; 
 &lt;summary&gt;What is DHCP? How does it work?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;p&gt;It stands for Dynamic Host Configuration Protocol and allocates IP addresses, subnet masks, and gateways to hosts. This is how it works:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;A host upon entering a network broadcasts a message in search of a DHCP server (DHCP DISCOVER)&lt;/li&gt; 
   &lt;li&gt;An offer message is sent back by the DHCP server as a packet containing lease time, subnet mask, IP addresses, etc (DHCP OFFER)&lt;/li&gt; 
   &lt;li&gt;Depending on which offer is accepted, the client sends back a reply broadcast letting all DHCP servers know (DHCP REQUEST)&lt;/li&gt; 
   &lt;li&gt;The server sends an acknowledgment (DHCP ACK)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;Read more &lt;a href="https://linuxjourney.com/lesson/dhcp-overview"&gt;here&lt;/a&gt; &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;Can you have two DHCP servers on the same network? How does it work?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;p&gt;It is possible to have two DHCP servers on the same network, however, it is not recommended, and it is important to configure them carefully to prevent conflicts and configuration problems.&lt;/p&gt; &lt;/b&gt;
 &lt;ul&gt;
  &lt;b&gt; &lt;li&gt;When two DHCP servers are configured on the same network, there is a&amp;nbsp;risk that both servers will assign IP addresses and other network configuration settings to the same device, which can cause conflicts and connectivity issues. Additionally, if the DHCP servers are configured with different network settings or options, devices on the network may receive conflicting or inconsistent configuration settings.&lt;/li&gt; &lt;li&gt;However, in some cases, it may be necessary to have two DHCP servers on the same network, such as in large networks where one DHCP server may not be able to handle all the requests. In such cases, DHCP servers can be configured to serve different IP address ranges or different subnets, so they do not interfere with each other. &lt;/li&gt;&lt;/b&gt;
 &lt;/ul&gt;
&lt;/details&gt;  
&lt;details&gt; 
 &lt;summary&gt;What is SSL tunneling? How does it work?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; 
  &lt;ul&gt; 
   &lt;li&gt;SSL (Secure Sockets Layer) tunneling is a technique used to establish a secure, encrypted connection between two endpoints over an insecure network, such as the Internet. The SSL tunnel is created by encapsulating the traffic within an SSL connection, which provides confidentiality, integrity, and authentication.&lt;/li&gt; 
  &lt;/ul&gt; &lt;p&gt;Here's how SSL tunneling works:&lt;/p&gt; &lt;/b&gt;
 &lt;ol&gt;
  &lt;b&gt; &lt;li&gt;A client initiates an SSL connection to a server, which involves a handshake process to establish the SSL session.&lt;/li&gt; &lt;li&gt;Once the SSL session is established, the client and server negotiate encryption parameters, such as the encryption algorithm and key length, then exchange digital certificates to authenticate each other.&lt;/li&gt; &lt;li&gt;The client then sends traffic through the SSL tunnel to the server, which decrypts the traffic and forwards it to its destination.&lt;/li&gt; &lt;li&gt;The server sends traffic back through the SSL tunnel to the client, which decrypts the traffic and forwards it to the application. &lt;/li&gt;&lt;/b&gt;
 &lt;/ol&gt;
&lt;/details&gt;  
&lt;details&gt; 
 &lt;summary&gt;What is a socket? Where can you see the list of sockets in your system?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;ul&gt;
  &lt;b&gt; &lt;li&gt;A socket is a software endpoint that enables two-way communication between processes over a network. Sockets provide a standardized interface for network communication, allowing applications to send and receive data across a network. To view the list of open sockets on a Linux system:&amp;nbsp; &lt;em&gt;&lt;strong&gt;netstat -an&lt;/strong&gt;&lt;/em&gt;&lt;/li&gt; &lt;li&gt;This command displays a list of all open sockets, along with their protocol, local address, foreign address, and state. &lt;/li&gt;&lt;/b&gt;
 &lt;/ul&gt;
&lt;/details&gt;  
&lt;details&gt; 
 &lt;summary&gt;What is IPv6? Why should we consider using it if we have IPv4?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; 
  &lt;ul&gt; 
   &lt;li&gt;IPv6 (Internet Protocol version 6) is the latest version of the Internet Protocol (IP), which is used to identify and communicate with devices on a network. IPv6 addresses are 128-bit addresses and are expressed in hexadecimal notation, such as 2001:0db8:85a3:0000:0000:8a2e:0370:7334.&lt;/li&gt; 
  &lt;/ul&gt; &lt;p&gt;There are several reasons why we should consider using IPv6 over IPv4:&lt;/p&gt; &lt;/b&gt;
 &lt;ol&gt;
  &lt;b&gt; &lt;li&gt;Address space: IPv4 has a limited address space, which has been exhausted in many parts of the world. IPv6 provides a much larger address space, allowing for trillions of unique IP addresses.&lt;/li&gt; &lt;li&gt;Security: IPv6 includes built-in support for IPsec, which provides end-to-end encryption and authentication for network traffic.&lt;/li&gt; &lt;li&gt;Performance: IPv6 includes features that can help to improve network performance, such as multicast routing, which allows a single packet to be sent to multiple destinations simultaneously.&lt;/li&gt; &lt;li&gt;Simplified network configuration: IPv6 includes features that can simplify network configuration, such as stateless autoconfiguration, which allows devices to automatically configure their own IPv6 addresses without the need for a DHCP server.&lt;/li&gt; &lt;li&gt;Better mobility support: IPv6 includes features that can improve mobility support, such as Mobile IPv6, which allows devices to maintain their IPv6 addresses as they move between different networks. &lt;/li&gt;&lt;/b&gt;
 &lt;/ol&gt;
&lt;/details&gt;  
&lt;details&gt; 
 &lt;summary&gt;What is VLAN?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;ul&gt;
  &lt;b&gt; &lt;li&gt;A VLAN (Virtual Local Area Network) is a logical network that groups together a set of devices on a physical network, regardless of their physical location. VLANs are created by configuring network switches to assign a specific VLAN ID to frames sent by devices connected to a specific port or group of ports on the switch. &lt;/li&gt;&lt;/b&gt;
 &lt;/ul&gt;
&lt;/details&gt;  
&lt;details&gt; 
 &lt;summary&gt;What is MTU?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;MTU stands for Maximum Transmission Unit. It's the size of the largest PDU (protocol Data Unit) that can be sent in a single transaction. &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;What happens if you send a packet that is bigger than the MTU?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;p&gt;With the IPv4 protocol, the router can fragment the PDU and then send all the fragmented PDU through the transaction.&lt;/p&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;With IPv6 protocol, it issues an error to the user's computer. &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;True or False? Ping is using UDP because it doesn't care about reliable connection&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;False. Ping is actually using ICMP (Internet Control Message Protocol) which is a network protocol used to send diagnostic messages and control messages related to network communication. &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;What is SDN?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;ul&gt;
  &lt;b&gt; &lt;li&gt;SDN stands for Software-Defined Networking. It is an approach to network management that emphasizes the centralization of network control, enabling administrators to manage network behavior through a software abstraction.&lt;/li&gt; &lt;li&gt;In a traditional network, network devices such as routers, switches, and firewalls are configured and managed individually, using specialized software or command-line interfaces. In contrast, SDN separates the network control plane from the data plane, allowing administrators to manage network behavior through a centralized software controller. &lt;/li&gt;&lt;/b&gt;
 &lt;/ul&gt;
&lt;/details&gt;  
&lt;details&gt; 
 &lt;summary&gt;What is ICMP? What is it used for?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; 
  &lt;ul&gt; 
   &lt;li&gt;ICMP stands for Internet Control Message Protocol. It is a protocol used for diagnostic and control purposes in IP networks. It is a part of the Internet Protocol suite, operating at the network layer.&lt;/li&gt; 
  &lt;/ul&gt; &lt;p&gt;ICMP messages are used for a variety of purposes, including:&lt;/p&gt; &lt;/b&gt;
 &lt;ol&gt;
  &lt;b&gt; &lt;li&gt;Error reporting: ICMP messages are used to report errors that occur in the network, such as a packet that could not be delivered to its destination.&lt;/li&gt; &lt;li&gt;Ping: ICMP is used to send ping messages, which are used to test whether a host or network is reachable and to measure the round-trip time for packets.&lt;/li&gt; &lt;li&gt;Path MTU discovery: ICMP is used to discover the Maximum Transmission Unit (MTU) of a path, which is the largest packet size that can be transmitted without fragmentation.&lt;/li&gt; &lt;li&gt;Traceroute: ICMP is used by the traceroute utility to trace the path that packets take through the network.&lt;/li&gt; &lt;li&gt;Router discovery: ICMP is used to discover the routers in a network. &lt;/li&gt;&lt;/b&gt;
 &lt;/ol&gt;
&lt;/details&gt;  
&lt;details&gt; 
 &lt;summary&gt;What is NAT? How does it work?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;NAT stands for Network Address Translation. It’s a way to map multiple local private addresses to a public one before transferring the information. Organizations that want multiple devices to employ a single IP address use NAT, as do most home routers. For example, your computer's private IP could be 192.168.1.100, but your router maps the traffic to its public IP (e.g. 1.1.1.1). Any device on the internet would see the traffic coming from your public IP (1.1.1.1) instead of your private IP (192.168.1.100). &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;Which port number is used in each of the following protocols?: 
  &lt;ul&gt; 
   &lt;li&gt;SSH&lt;/li&gt; 
   &lt;li&gt;SMTP&lt;/li&gt; 
   &lt;li&gt;HTTP&lt;/li&gt; 
   &lt;li&gt;DNS&lt;/li&gt; 
   &lt;li&gt;HTTPS&lt;/li&gt; 
   &lt;li&gt;FTP&lt;/li&gt; 
   &lt;li&gt;SFTP&lt;/li&gt; 
  &lt;/ul&gt; &lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;ul&gt;
  &lt;b&gt; &lt;li&gt;SSH - 22&lt;/li&gt; &lt;li&gt;SMTP - 25&lt;/li&gt; &lt;li&gt;HTTP - 80&lt;/li&gt; &lt;li&gt;DNS - 53&lt;/li&gt; &lt;li&gt;HTTPS - 443&lt;/li&gt; &lt;li&gt;FTP - 21&lt;/li&gt; &lt;li&gt;SFTP - 22 &lt;/li&gt;&lt;/b&gt;
 &lt;/ul&gt;
&lt;/details&gt;  
&lt;details&gt; 
 &lt;summary&gt;Which factors affect network performance?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;p&gt;Several factors can affect network performance, including:&lt;/p&gt; &lt;/b&gt;
 &lt;ol&gt;
  &lt;b&gt; &lt;li&gt;Bandwidth: The available bandwidth of a network connection can significantly impact its performance. Networks with limited bandwidth can experience slow data transfer rates, high latency, and poor responsiveness.&lt;/li&gt; &lt;li&gt;Latency: Latency refers to the delay that occurs when data is transmitted from one point in a network to another. High latency can result in slow network performance, especially for real-time applications like video conferencing and online gaming.&lt;/li&gt; &lt;li&gt;Network congestion: When too many devices are using a network at the same time, network congestion can occur, leading to slow data transfer rates and poor network performance.&lt;/li&gt; &lt;li&gt;Packet loss: Packet loss occurs when packets of data are dropped during transmission. This can result in slower network speeds and lower overall network performance.&lt;/li&gt; &lt;li&gt;Network topology: The physical layout of a network, including the placement of switches, routers, and other network devices, can impact network performance.&lt;/li&gt; &lt;li&gt;Network protocol: Different network protocols have different performance characteristics, which can impact network performance. For example, TCP is a reliable protocol that can guarantee the delivery of data, but it can also result in slower performance due to the overhead required for error checking and retransmission.&lt;/li&gt; &lt;li&gt;Network security: Security measures such as firewalls and encryption can impact network performance, especially if they require significant processing power or introduce additional latency.&lt;/li&gt; &lt;li&gt;Distance: The physical distance between devices on a network can impact network performance, especially for wireless networks where signal strength and interference can affect connectivity and data transfer rates. &lt;/li&gt;&lt;/b&gt;
 &lt;/ol&gt;
&lt;/details&gt;  
&lt;details&gt; 
 &lt;summary&gt;What is APIPA?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;p&gt;APIPA is a set of IP addresses that devices are allocated when the main DHCP server is not reachable&lt;/p&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;&lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;What IP range does APIPA use?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;p&gt;APIPA uses the IP range: 169.254.0.1 - 169.254.255.254.&lt;/p&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;&lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;h4&gt;Control Plane and Data Plane&lt;/h4&gt; 
&lt;details&gt; 
 &lt;summary&gt;What does "control plane" refer to?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;The control plane is a part of the network that decides how to route and forward packets to a different location. &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;What does "data plane" refer to?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;The data plane is a part of the network that actually forwards the data/packets. &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;What does "management plane" refer to?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;It refers to monitoring and management functions. &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;To which plane (data, control, ...) does creating routing tables belong to?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;Control Plane. &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;Explain Spanning Tree Protocol (STP).&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;What is link aggregation? Why is it used?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;What is Asymmetric Routing? How to deal with it?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;What overlay (tunnel) protocols are you familiar with?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;What is GRE? How does it work?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;What is VXLAN? How does it work?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;What is SNAT?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Explain OSPF.&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;p&gt;OSPF (Open Shortest Path First) is a routing protocol that can be implemented on various types of routers. In general, OSPF is supported on most modern routers, including those from vendors such as Cisco, Juniper, and Huawei. The protocol is designed to work with IP-based networks, including both IPv4 and IPv6. Also, it uses a hierarchical network design, where routers are grouped into areas, with each area having its own topology map and routing table. This design helps to reduce the amount of routing information that needs to be exchanged between routers and improve network scalability.&lt;/p&gt; &lt;p&gt;The OSPF 4 Types of routers are:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Internal Router&lt;/li&gt; 
   &lt;li&gt;Area Border Routers&lt;/li&gt; 
   &lt;li&gt;Autonomous Systems Boundary Routers&lt;/li&gt; 
   &lt;li&gt;Backbone Routers&lt;/li&gt; 
  &lt;/ul&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;Learn more about OSPF router types: &lt;a href="https://www.educba.com/ospf-router-types/"&gt;https://www.educba.com/ospf-router-types/&lt;/a&gt; &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;What is latency?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;Latency is the time taken for information to reach its destination from the source. &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;What is bandwidth?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;Bandwidth is the capacity of a communication channel to measure how much data the latter can handle over a specific time period. More bandwidth would imply more traffic handling and thus more data transfer. &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;What is throughput?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;Throughput refers to the measurement of the real amount of data transferred over a certain period of time across any transmission channel. &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;When performing a search query, what is more important, latency or throughput? And how to ensure that we manage global infrastructure? &lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;Latency. To have good latency, a search query should be forwarded to the closest data center. &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;When uploading a video, what is more important, latency or throughput? And how to assure that?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;Throughput. To have good throughput, the upload stream should be routed to an underutilized link. &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;What other considerations (except latency and throughput) are there when forwarding requests?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;ul&gt;
  &lt;b&gt; &lt;li&gt;Keep caches updated (which means the request could be forwarded not to the closest data center) &lt;/li&gt;&lt;/b&gt;
 &lt;/ul&gt;
&lt;/details&gt;  
&lt;details&gt; 
 &lt;summary&gt;Explain Spine &amp;amp; Leaf&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; "Spine &amp;amp; Leaf" is a networking topology commonly used in data center environments to connect multiple switches and manage network traffic efficiently. It is also known as "spine-leaf" architecture or "leaf-spine" topology. This design provides high bandwidth, low latency, and scalability, making it ideal for modern data centers handling large volumes of data and traffic. &lt;p&gt;Within a Spine &amp;amp; Leaf network there are two main tipology of switches:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Spine Switches: Spine switches are high-performance switches arranged in a spine layer. These switches act as the core of the network and are typically interconnected with each leaf switch. Each spine switch is connected to all the leaf switches in the data center.&lt;/li&gt; 
   &lt;li&gt;Leaf Switches: Leaf switches are connected to end devices like servers, storage arrays, and other networking equipment. Each leaf switch is connected to every spine switch in the data center. This creates a non-blocking, full-mesh connectivity between leaf and spine switches, ensuring any leaf switch can communicate with any other leaf switch with maximum throughput.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;The Spine &amp;amp; Leaf architecture has become increasingly popular in data centers due to its ability to handle the demands of modern cloud computing, virtualization, and big data applications, providing a scalable, high-performance, and reliable network infrastructure &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;What is Network Congestion? What can cause it?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;Network congestion occurs when there is too much data to transmit on a network and it doesn't have enough capacity to handle the demand. &lt;br /&gt; This can lead to increased latency and packet loss. The causes can be multiple, such as high network usage, large file transfers, malware, hardware issues, or network design problems. &lt;br /&gt; To prevent network congestion, it's important to monitor your network usage and implement strategies to limit or manage the demand. &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;What can you tell me about the UDP packet format? What about the TCP packet format? How is it different?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;What is the exponential backoff algorithm? Where is it used?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Using Hamming code, what would be the code word for the following data word 100111010001101?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;00110011110100011101 &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;Give examples of protocols found in the application layer&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;ul&gt;
  &lt;b&gt; &lt;li&gt;Hypertext Transfer Protocol (HTTP) - used for the webpages on the internet&lt;/li&gt; &lt;li&gt;Simple Mail Transfer Protocol (SMTP) - email transmission&lt;/li&gt; &lt;li&gt;Telecommunications Network - (TELNET) - terminal emulation to allow a client access to a telnet server&lt;/li&gt; &lt;li&gt;File Transfer Protocol (FTP) - facilitates the transfer of files between any two machines&lt;/li&gt; &lt;li&gt;Domain Name System (DNS) - domain name translation&lt;/li&gt; &lt;li&gt;Dynamic Host Configuration Protocol (DHCP) - allocates IP addresses, subnet masks, and gateways to hosts&lt;/li&gt; &lt;li&gt;Simple Network Management Protocol (SNMP) - gathers data on devices on the network &lt;/li&gt;&lt;/b&gt;
 &lt;/ul&gt;
&lt;/details&gt;  
&lt;details&gt; 
 &lt;summary&gt;Give examples of protocols found in the Network Layer&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;ul&gt;
  &lt;b&gt; &lt;li&gt;Internet Protocol (IP) - assists in routing packets from one machine to another&lt;/li&gt; &lt;li&gt;Internet Control Message Protocol (ICMP) - lets one know what is going such as error messages and debugging information &lt;/li&gt;&lt;/b&gt;
 &lt;/ul&gt;
&lt;/details&gt;  
&lt;details&gt; 
 &lt;summary&gt;What is HSTS?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; HTTP Strict Transport Security is a web server directive that informs user agents and web browsers how to handle its connection through a response header sent at the very beginning and back to the browser. This forces connections over HTTPS encryption, disregarding any script's call to load any resource in that domain over HTTP. &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;Read more [here](&lt;a href="https://www.globalsign.com/en/blog/what-is-hsts-and-how-do-i-use-it#:~:text=HTTP%20Strict%20Transport%20Security%20(HSTS,and%20back%20to%20the%20browser.)"&gt;https://www.globalsign.com/en/blog/what-is-hsts-and-how-do-i-use-it#:~:text=HTTP%20Strict%20Transport%20Security%20(HSTS,and%20back%20to%20the%20browser.)&lt;/a&gt; &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;h4&gt;Network - Misc&lt;/h4&gt; 
&lt;details&gt; 
 &lt;summary&gt;What is the Internet? Is it the same as the World Wide Web?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;The internet refers to a network of networks, transferring huge amounts of data around the globe.&lt;br /&gt; The World Wide Web is an application running on millions of servers, on top of the internet, accessed through what is known as the web browser &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;What is the ISP?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;ISP (Internet Service Provider) is the local internet company provider. &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;h2&gt;Operating System&lt;/h2&gt; 
&lt;h3&gt;Operating System Exercises&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Name&lt;/th&gt; 
   &lt;th&gt;Topic&lt;/th&gt; 
   &lt;th&gt;Objective &amp;amp; Instructions&lt;/th&gt; 
   &lt;th&gt;Solution&lt;/th&gt; 
   &lt;th&gt;Comments&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Fork 101&lt;/td&gt; 
   &lt;td&gt;Fork&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/topics/os/fork_101.md"&gt;Link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/topics/os/solutions/fork_101_solution.md"&gt;Link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Fork 102&lt;/td&gt; 
   &lt;td&gt;Fork&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/topics/os/fork_102.md"&gt;Link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/topics/os/solutions/fork_102_solution.md"&gt;Link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Operating System - Self Assessment&lt;/h3&gt; 
&lt;details&gt; 
 &lt;summary&gt;What is an operating system?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;p&gt;From the book "Operating Systems: Three Easy Pieces":&lt;/p&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;"responsible for making it easy to run programs (even allowing you to seemingly run many at the same time), allowing programs to share memory, enabling programs to interact with devices, and other fun stuff like that". &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;h4&gt;Operating System - Process&lt;/h4&gt; 
&lt;details&gt; 
 &lt;summary&gt;Can you explain what is a process?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;A process is a running program. A program is one or more instructions and the program (or process) is executed by the operating system. &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;If you had to design an API for processes in an operating system, what would this API look like?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;p&gt;It would support the following:&lt;/p&gt; &lt;/b&gt;
 &lt;ul&gt;
  &lt;b&gt; &lt;li&gt;Create - allow to create new processes&lt;/li&gt; &lt;li&gt;Delete - allow to remove/destroy processes&lt;/li&gt; &lt;li&gt;State - allow to check the state of the process, whether it's running, stopped, waiting, etc.&lt;/li&gt; &lt;li&gt;Stop - allow to stop a running process &lt;/li&gt;&lt;/b&gt;
 &lt;/ul&gt;
&lt;/details&gt;  
&lt;details&gt; 
 &lt;summary&gt;How a process is created?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;ul&gt;
  &lt;b&gt; &lt;li&gt;The OS is reading program's code and any additional relevant data&lt;/li&gt; &lt;li&gt;Program's code is loaded into the memory or more specifically, into the address space of the process.&lt;/li&gt; &lt;li&gt;Memory is allocated for program's stack (aka run-time stack). The stack also initialized by the OS with data like argv, argc and parameters to main()&lt;/li&gt; &lt;li&gt;Memory is allocated for program's heap which is required for dynamically allocated data like the data structures linked lists and hash tables&lt;/li&gt; &lt;li&gt;I/O initialization tasks are performed, like in Unix/Linux based systems, where each process has 3 file descriptors (input, output and error)&lt;/li&gt; &lt;li&gt;OS is running the program, starting from main() &lt;/li&gt;&lt;/b&gt;
 &lt;/ul&gt;
&lt;/details&gt;  
&lt;details&gt; 
 &lt;summary&gt;True or False? The loading of the program into the memory is done eagerly (all at once)&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;False. It was true in the past but today's operating systems perform lazy loading, which means only the relevant pieces required for the process to run are loaded first. &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;What are different states of a process?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;ul&gt;
  &lt;b&gt; &lt;li&gt;Running - it's executing instructions&lt;/li&gt; &lt;li&gt;Ready - it's ready to run, but for different reasons it's on hold&lt;/li&gt; &lt;li&gt;Blocked - it's waiting for some operation to complete, for example I/O disk request &lt;/li&gt;&lt;/b&gt;
 &lt;/ul&gt;
&lt;/details&gt;  
&lt;details&gt; 
 &lt;summary&gt;What are some reasons for a process to become blocked?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;ul&gt;
  &lt;b&gt; &lt;li&gt;I/O operations (e.g. Reading from a disk)&lt;/li&gt; &lt;li&gt;Waiting for a packet from a network &lt;/li&gt;&lt;/b&gt;
 &lt;/ul&gt;
&lt;/details&gt;  
&lt;details&gt; 
 &lt;summary&gt;What is Inter Process Communication (IPC)?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;Inter-process communication (IPC) refers to the mechanisms provided by an operating system that allow processes to manage shared data. &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;What is "time sharing"?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;Even when using a system with one physical CPU, it's possible to allow multiple users to work on it and run programs. This is possible with time sharing, where computing resources are shared in a way it seems to the user, the system has multiple CPUs, but in fact it's simply one CPU shared by applying multiprogramming and multi-tasking. &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;What is "space sharing"?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;Somewhat the opposite of time sharing. While in time sharing a resource is used for a while by one entity and then the same resource can be used by another resource, in space sharing the space is shared by multiple entities but in a way where it's not being transferred between them.&lt;br /&gt; It's used by one entity, until this entity decides to get rid of it. Take for example storage. In storage, a file is yours, until you decide to delete it. &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;What component determines which process runs at a given moment in time?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;CPU scheduler &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;h4&gt;Operating System - Memory&lt;/h4&gt; 
&lt;details&gt; 
 &lt;summary&gt;What is "virtual memory" and what purpose does serve?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;Virtual memory combines your computer's RAM with temporary space on your hard disk. When RAM runs low, virtual memory helps to move data from RAM to a space called a paging file. Moving data to paging file can free up the RAM, so your computer can complete its work. In general, the more RAM your computer has, the faster the programs run. &lt;a href="https://www.minitool.com/lib/virtual-memory.html"&gt;https://www.minitool.com/lib/virtual-memory.html&lt;/a&gt; &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;What is demand paging?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;Demand paging is a memory management technique where pages are loaded into physical memory only when accessed by a process. It optimizes memory usage by loading pages on demand, reducing startup latency and space overhead. However, it introduces some latency when accessing pages for the first time. Overall, it’s a cost-effective approach for managing memory resources in operating systems. &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;What is copy-on-write?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; Copy-on-write (COW) is a resource management concept, with the goal to reduce unnecessary copying of information. It is a concept, which is implemented for instance within the POSIX fork syscall, which creates a duplicate process of the calling process. &lt;p&gt;The idea:&lt;/p&gt; &lt;/b&gt;
 &lt;ol&gt;
  &lt;b&gt; &lt;li&gt;If resources are shared between 2 or more entities (for example shared memory segments between 2 processes), the resources don't need to be copied for every entity, but rather every entity has a READ operation access permission on the shared resource. (the shared segments are marked as read-only) (Think of every entity having a pointer to the location of the shared resource, which can be dereferenced to read its value)&lt;/li&gt; &lt;li&gt;If one entity would perform a WRITE operation on a shared resource, a problem would arise, since the resource also would be permanently changed for ALL other entities sharing it. (Think of a process modifying some variables on the stack, or allocatingy some data dynamically on the heap, these changes to the shared resource would also apply for ALL other processes, this is definitely an undesirable behaviour)&lt;/li&gt; &lt;li&gt;As a solution only, if a WRITE operation is about to be performed on a shared resource, this resource gets COPIED first and then the changes are applied. &lt;/li&gt;&lt;/b&gt;
 &lt;/ol&gt;
&lt;/details&gt;  
&lt;details&gt; 
 &lt;summary&gt;What is a kernel, and what does it do?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;p&gt;The kernel is part of the operating system and is responsible for tasks like:&lt;/p&gt; &lt;/b&gt;
 &lt;ul&gt;
  &lt;b&gt; &lt;li&gt;Allocating memory&lt;/li&gt; &lt;li&gt;Schedule processes&lt;/li&gt; &lt;li&gt;Control CPU &lt;/li&gt;&lt;/b&gt;
 &lt;/ul&gt;
&lt;/details&gt;  
&lt;details&gt; 
 &lt;summary&gt;True or False? Some pieces of the code in the kernel are loaded into protected areas of the memory so applications can't overwrite them.&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;True &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;What is POSIX?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;POSIX (Portable Operating System Interface) is a set of standards that define the interface between a Unix-like operating system and application programs. &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;Explain what is Semaphore and what its role in operating systems.&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;A semaphore is a synchronization primitive used in operating systems and concurrent programming to control access to shared resources. It's a variable or abstract data type that acts as a counter or a signaling mechanism for managing access to resources by multiple processes or threads. &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;What is cache? What is buffer?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;Cache: Cache is usually used when processes are reading and writing to the disk to make the process faster, by making similar data used by different programs easily accessible. Buffer: Reserved place in RAM, which is used to hold data for temporary purposes. &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;h2&gt;Virtualization&lt;/h2&gt; 
&lt;details&gt; 
 &lt;summary&gt;What is Virtualization?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;Virtualization uses software to create an abstraction layer over computer hardware, that allows the hardware elements of a single computer - processors, memory, storage and more - to be divided into multiple virtual computers, commonly called virtual machines (VMs). &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;What is a hypervisor?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;p&gt;Red Hat: "A hypervisor is software that creates and runs virtual machines (VMs). A hypervisor, sometimes called a virtual machine monitor (VMM), isolates the hypervisor operating system and resources from the virtual machines and enables the creation and management of those VMs."&lt;/p&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;Read more &lt;a href="https://www.redhat.com/en/topics/virtualization/what-is-a-hypervisor"&gt;here&lt;/a&gt; &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;What types of hypervisors are there?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;Hosted hypervisors and bare-metal hypervisors. &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;What are the advantages and disadvantges of bare-metal hypervisor over a hosted hypervisor?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;p&gt;Due to having its own drivers and a direct access to hardware components, a baremetal hypervisor will often have better performances along with stability and scalability.&lt;/p&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;On the other hand, there will probably be some limitation regarding loading (any) drivers so a hosted hypervisor will usually benefit from having a better hardware compatibility. &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;What types of virtualization are there?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;Operating system virtualization Network functions virtualization Desktop virtualization &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;Is containerization is a type of Virtualization?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;Yes, it's a operating-system-level virtualization, where the kernel is shared and allows to use multiple isolated user-spaces instances. &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;How the introduction of virtual machines changed the industry and the way applications were deployed?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;The introduction of virtual machines allowed companies to deploy multiple business applications on the same hardware, while each application is separated from each other in secured way, where each is running on its own separate operating system. &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;h4&gt;Virtual Machines&lt;/h4&gt; 
&lt;details&gt; 
 &lt;summary&gt;Do we need virtual machines in the age of containers? Are they still relevant?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;Yes, virtual machines are still relevant even in the age of containers. While containers provide a lightweight and portable alternative to virtual machines, they do have certain limitations. Virtual machines still matter because they offer isolation and security, can run different operating systems, and are good for legacy apps. Containers limitations for example are sharing the host kernel. &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;h2&gt;Prometheus&lt;/h2&gt; 
&lt;details&gt; 
 &lt;summary&gt;What is Prometheus? What are some of Prometheus's main features?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;p&gt;Prometheus is a popular open-source systems monitoring and alerting toolkit, originally developed at SoundCloud. It is designed to collect and store time-series data, and to allow for querying and analysis of that data using a powerful query language called PromQL. Prometheus is frequently used to monitor cloud-native applications, microservices, and other modern infrastructure.&lt;/p&gt; &lt;p&gt;Some of the main features of Prometheus include:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;1. Data model: Prometheus uses a flexible data model that allows users to organize and label their time-series data in a way that makes sense for their particular use case. Labels are used to identify different dimensions of the data, such as the source of the data or the environment in which it was collected.

2. Pull-based architecture: Prometheus uses a pull-based model to collect data from targets, meaning that the Prometheus server actively queries its targets for metrics data at regular intervals. This architecture is more scalable and reliable than a push-based model, which would require every target to push data to the server.

3. Time-series database: Prometheus stores all of its data in a time-series database, which allows users to perform queries over time ranges and to aggregate and analyze their data in various ways. The database is optimized for write-heavy workloads, and can handle a high volume of data with low latency.

4. Alerting: Prometheus includes a powerful alerting system that allows users to define rules based on their metrics data and to send alerts when certain conditions are met. Alerts can be sent via email, chat, or other channels, and can be customized to include specific details about the problem.

5. Visualization: Prometheus has a built-in graphing and visualization tool, called PromDash, which allows users to create custom dashboards to monitor their systems and applications. PromDash supports a variety of graph types and visualization options, and can be customized using CSS and JavaScript.
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Overall, Prometheus is a powerful and flexible tool for monitoring and analyzing systems and applications, and is widely used in the industry for cloud-native monitoring and observability.&lt;/p&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;&lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;In what scenarios it might be better to NOT use Prometheus?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;From Prometheus documentation: "if you need 100% accuracy, such as for per-request billing". &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;Describe Prometheus architecture and components&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;p&gt;The Prometheus architecture consists of four major components:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;1. Prometheus Server: The Prometheus server is responsible for collecting and storing metrics data. It has a simple built-in storage layer that allows it to store time-series data in a time-ordered database.

2. Client Libraries: Prometheus provides a range of client libraries that enable applications to expose their metrics data in a format that can be ingested by the Prometheus server. These libraries are available for a range of programming languages, including Java, Python, and Go.

3. Exporters: Exporters are software components that expose existing metrics from third-party systems and make them available for ingestion by the Prometheus server. Prometheus provides exporters for a range of popular technologies, including MySQL, PostgreSQL, and Apache.

4. Alertmanager: The Alertmanager component is responsible for processing alerts generated by the Prometheus server. It can handle alerts from multiple sources and provides a range of features for deduplicating, grouping, and routing alerts to appropriate channels.
&lt;/code&gt;&lt;/pre&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;Overall, the Prometheus architecture is designed to be highly scalable and resilient. The server and client libraries can be deployed in a distributed fashion to support monitoring across large-scale, highly dynamic environments &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;Can you compare Prometheus to other solutions like InfluxDB for example?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;p&gt;Compared to other monitoring solutions, such as InfluxDB, Prometheus is known for its high performance and scalability. It can handle large volumes of data and can easily be integrated with other tools in the monitoring ecosystem. InfluxDB, on the other hand, is known for its ease of use and simplicity. It has a user-friendly interface and provides easy-to-use APIs for collecting and querying data.&lt;/p&gt; &lt;p&gt;Another popular solution, Nagios, is a more traditional monitoring system that relies on a push-based model for collecting data. Nagios has been around for a long time and is known for its stability and reliability. However, compared to Prometheus, Nagios lacks some of the more advanced features, such as multi-dimensional data model and powerful query language.&lt;/p&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;Overall, the choice of a monitoring solution depends on the specific needs and requirements of the organization. While Prometheus is a great choice for large-scale monitoring and alerting, InfluxDB may be a better fit for smaller environments that require ease of use and simplicity. Nagios remains a solid choice for organizations that prioritize stability and reliability over advanced features. &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;What is an Alert?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; In Prometheus, an alert is a notification triggered when a specific condition or threshold is met. Alerts can be configured to trigger when certain metrics cross a certain threshold or when specific events occur. Once an alert is triggered, it can be routed to various channels, such as email, pager, or chat, to notify relevant teams or individuals to take appropriate action. Alerts are a critical component of any monitoring system, as they allow teams to proactively detect and respond to issues before they impact users or cause system downtime. &lt;/b&gt;
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;What is an Instance? What is a Job?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;p&gt;In Prometheus, an instance refers to a single target that is being monitored. For example, a single server or service. A job is a set of instances that perform the same function, such as a set of web servers serving the same application. Jobs allow you to define and manage a group of targets together.&lt;/p&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;In essence, an instance is an individual target that Prometheus collects metrics from, while a job is a collection of similar instances that can be managed as a group. &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;What core metrics types Prometheus supports?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; Prometheus supports several types of metrics, including: &lt;pre&gt;&lt;code&gt;1. Counter: A monotonically increasing value used for tracking counts of events or samples. Examples include the number of requests processed or the total number of errors encountered.

2. Gauge: A value that can go up or down, such as CPU usage or memory usage. Unlike counters, gauge values can be arbitrary, meaning they can go up and down based on changes in the system being monitored.

3. Histogram: A set of observations or events that are divided into buckets based on their value. Histograms help in analyzing the distribution of a metric, such as request latencies or response sizes.

4. Summary: A summary is similar to a histogram, but instead of buckets, it provides a set of quantiles for the observed values. Summaries are useful for monitoring the distribution of request latencies or response sizes over time.
&lt;/code&gt;&lt;/pre&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;Prometheus also supports various functions and operators for aggregating and manipulating metrics, such as sum, max, min, and rate. These features make it a powerful tool for monitoring and alerting on system metrics. &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;What is an exporter? What is it used for?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; The exporter serves as a bridge between the third-party system or application and Prometheus, making it possible for Prometheus to monitor and collect data from that system or application. &lt;p&gt;The exporter acts as a server, listening on a specific network port for requests from Prometheus to scrape metrics. It collects metrics from the third-party system or application and transforms them into a format that can be understood by Prometheus. The exporter then exposes these metrics to Prometheus via an HTTP endpoint, making them available for collection and analysis.&lt;/p&gt; &lt;p&gt;Exporters are commonly used to monitor various types of infrastructure components such as databases, web servers, and storage systems. For example, there are exporters available for monitoring popular databases such as MySQL and PostgreSQL, as well as web servers like Apache and Nginx.&lt;/p&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;Overall, exporters are a critical component of the Prometheus ecosystem, allowing for the monitoring of a wide range of systems and applications, and providing a high degree of flexibility and extensibility to the platform. &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;Which Prometheus best practices?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; Here are three of them: &lt;pre&gt;&lt;code&gt;1. Label carefully: Careful and consistent labeling of metrics is crucial for effective querying and alerting. Labels should be clear, concise, and include all relevant information about the metric.

2. Keep metrics simple: The metrics exposed by exporters should be simple and focus on a single aspect of the system being monitored. This helps avoid confusion and ensures that the metrics are easily understandable by all members of the team.

3. Use alerting sparingly: While alerting is a powerful feature of Prometheus, it should be used sparingly and only for the most critical issues. Setting up too many alerts can lead to alert fatigue and result in important alerts being ignored. It is recommended to set up only the most important alerts and adjust the thresholds over time based on the actual frequency of alerts.
&lt;/code&gt;&lt;/pre&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;&lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;How to get total requests in a given period of time?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; To get the total requests in a given period of time using Prometheus, you can use the *sum* function along with the *rate* function. Here is an example query that will give you the total number of requests in the last hour: &lt;pre&gt;&lt;code&gt;sum(rate(http_requests_total[1h]))
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;In this query, &lt;em&gt;http_requests_total&lt;/em&gt; is the name of the metric that tracks the total number of HTTP requests, and the &lt;em&gt;rate&lt;/em&gt; function calculates the per-second rate of requests over the last hour. The &lt;em&gt;sum&lt;/em&gt; function then adds up all of the requests to give you the total number of requests in the last hour.&lt;/p&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;You can adjust the time range by changing the duration in the &lt;em&gt;rate&lt;/em&gt; function. For example, if you wanted to get the total number of requests in the last day, you could change the function to &lt;em&gt;rate(http_requests_total[1d])&lt;/em&gt;. &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;What HA in Prometheus means?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;HA stands for High Availability. This means that the system is designed to be highly reliable and always available, even in the face of failures or other issues. In practice, this typically involves setting up multiple instances of Prometheus and ensuring that they are all synchronized and able to work together seamlessly. This can be achieved through a variety of techniques, such as load balancing, replication, and failover mechanisms. By implementing HA in Prometheus, users can ensure that their monitoring data is always available and up-to-date, even in the face of hardware or software failures, network issues, or other problems that might otherwise cause downtime or data loss. &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;How do you join two metrics?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; In Prometheus, joining two metrics can be achieved using the *join()* function. The *join()* function combines two or more time series based on their label values. It takes two mandatory arguments: *on* and *table*. The on argument specifies the labels to join *on* and the *table* argument specifies the time series to join. &lt;p&gt;Here's an example of how to join two metrics using the &lt;em&gt;join()&lt;/em&gt; function:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;sum_series(
  join(
    on(service, instance) request_count_total,
    on(service, instance) error_count_total,
  )
)
&lt;/code&gt;&lt;/pre&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;In this example, the &lt;em&gt;join()&lt;/em&gt; function combines the &lt;em&gt;request_count_total&lt;/em&gt; and &lt;em&gt;error_count_total&lt;/em&gt; time series based on their &lt;em&gt;service&lt;/em&gt; and &lt;em&gt;instance&lt;/em&gt; label values. The &lt;em&gt;sum_series()&lt;/em&gt; function then calculates the sum of the resulting time series &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;How to write a query that returns the value of a label?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; To write a query that returns the value of a label in Prometheus, you can use the *label_values* function. The *label_values* function takes two arguments: the name of the label and the name of the metric. &lt;p&gt;For example, if you have a metric called &lt;em&gt;http_requests_total&lt;/em&gt; with a label called &lt;em&gt;method&lt;/em&gt;, and you want to return all the values of the &lt;em&gt;method&lt;/em&gt; label, you can use the following query:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;label_values(http_requests_total, method)
&lt;/code&gt;&lt;/pre&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;This will return a list of all the values for the &lt;em&gt;method&lt;/em&gt; label in the &lt;em&gt;http_requests_total&lt;/em&gt; metric. You can then use this list in further queries or to filter your data. &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;How do you convert cpu_user_seconds to cpu usage in percentage?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; To convert *cpu_user_seconds* to CPU usage in percentage, you need to divide it by the total elapsed time and the number of CPU cores, and then multiply by 100. The formula is as follows: &lt;pre&gt;&lt;code&gt;100 * sum(rate(process_cpu_user_seconds_total{job="&amp;lt;job-name&amp;gt;"}[&amp;lt;time-period&amp;gt;])) by (instance) / (&amp;lt;time-period&amp;gt; * &amp;lt;num-cpu-cores&amp;gt;)
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Here, &lt;em&gt;
    &lt;job-name&gt;&lt;/job-name&gt;&lt;/em&gt; is the name of the job you want to query, &lt;em&gt;
    &lt;time-period&gt;&lt;/time-period&gt;&lt;/em&gt; is the time range you want to query (e.g. &lt;em&gt;5m&lt;/em&gt;, &lt;em&gt;1h&lt;/em&gt;), and &lt;em&gt;
    &lt;num-cpu-cores&gt;&lt;/num-cpu-cores&gt;&lt;/em&gt; is the number of CPU cores on the machine you are querying.&lt;/p&gt; &lt;p&gt;For example, to get the CPU usage in percentage for the last 5 minutes for a job named &lt;em&gt;my-job&lt;/em&gt; running on a machine with 4 CPU cores, you can use the following query:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;100 * sum(rate(process_cpu_user_seconds_total{job="my-job"}[5m])) by (instance) / (5m * 4)
&lt;/code&gt;&lt;/pre&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;&lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;h2&gt;Go&lt;/h2&gt; 
&lt;details&gt; 
 &lt;summary&gt;What are some characteristics of the Go programming language?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Strong and static typing - the type of the variables can't be changed over time and they have to be defined at compile time&lt;/li&gt; 
   &lt;li&gt;Simplicity&lt;/li&gt; 
   &lt;li&gt;Fast compile times&lt;/li&gt; 
   &lt;li&gt;Built-in concurrency&lt;/li&gt; 
   &lt;li&gt;Garbage collected&lt;/li&gt; 
   &lt;li&gt;Platform independent&lt;/li&gt; 
   &lt;li&gt;Compile to standalone binary - anything you need to run your app will be compiled into one binary. Very useful for version management in run-time.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;Go also has good community. &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;What is the difference between &lt;code&gt;var x int = 2&lt;/code&gt; and &lt;code&gt;x := 2&lt;/code&gt;?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;p&gt;The result is the same, a variable with the value 2.&lt;/p&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;With &lt;code&gt;var x int = 2&lt;/code&gt; we are setting the variable type to integer while with &lt;code&gt;x := 2&lt;/code&gt; we are letting Go figure out by itself the type. &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;True or False? In Go we can redeclare variables and once declared we must use it.&lt;/summary&gt; 
 &lt;p&gt;False. We can't redeclare variables but yes, we must use declared variables. &lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;What libraries of Go have you used?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;p&gt;This should be answered based on your usage but some examples are:&lt;/p&gt; &lt;/b&gt;
 &lt;ul&gt;
  &lt;b&gt; &lt;li&gt;fmt - formatted I/O &lt;/li&gt;&lt;/b&gt;
 &lt;/ul&gt;
&lt;/details&gt;  
&lt;details&gt; 
 &lt;summary&gt;What is the problem with the following block of code? How to fix it? &lt;pre&gt;&lt;code&gt;func main() {
    var x float32 = 13.5
    var y int
    y = x
}
&lt;/code&gt;&lt;/pre&gt; &lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;The following block of code tries to convert the integer 101 to a string but instead we get "e". Why is that? How to fix it? &lt;pre&gt;&lt;code class="language-go"&gt;package main

import "fmt"

func main() {
    var x int = 101
    var y string
    y = string(x)
    fmt.Println(y)
}
&lt;/code&gt;&lt;/pre&gt; &lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;It looks what unicode value is set at 101 and uses it for converting the integer to a string. If you want to get "101" you should use the package "strconv" and replace &lt;code&gt;y = string(x)&lt;/code&gt; with &lt;code&gt;y = strconv.Itoa(x)&lt;/code&gt; &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;What is wrong with the following code?: &lt;pre&gt;&lt;code&gt;package main

func main() {
    var x = 2
    var y = 3
    const someConst = x + y
}
&lt;/code&gt;&lt;/pre&gt; &lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;Constants in Go can only be declared using constant expressions. But &lt;code&gt;x&lt;/code&gt;, &lt;code&gt;y&lt;/code&gt; and their sum is variable. &lt;br /&gt; &lt;code&gt;const initializer x + y is not a constant&lt;/code&gt; &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;What will be the output of the following block of code?: &lt;pre&gt;&lt;code class="language-go"&gt;package main

import "fmt"

const (
	x = iota
	y = iota
)
const z = iota

func main() {
	fmt.Printf("%v\n", x)
	fmt.Printf("%v\n", y)
	fmt.Printf("%v\n", z)
}
&lt;/code&gt;&lt;/pre&gt; &lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;Go's iota identifier is used in const declarations to simplify definitions of incrementing numbers. Because it can be used in expressions, it provides a generality beyond that of simple enumerations. &lt;br /&gt; &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt; in the first iota group, &lt;code&gt;z&lt;/code&gt; in the second. &lt;br /&gt; &lt;a href="https://github.com/golang/go/wiki/Iota"&gt;Iota page in Go Wiki&lt;/a&gt; &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;What _ is used for in Go?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;It avoids having to declare all the variables for the returns values. It is called the &lt;a href="https://golang.org/doc/effective_go.html#blank"&gt;blank identifier&lt;/a&gt;. &lt;br /&gt; &lt;a href="https://stackoverflow.com/questions/27764421/what-is-underscore-comma-in-a-go-declaration#answer-27764432"&gt;answer in SO&lt;/a&gt; &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;What will be the output of the following block of code?: &lt;pre&gt;&lt;code class="language-go"&gt;package main

import "fmt"

const (
	_ = iota + 3
	x
)

func main() {
	fmt.Printf("%v\n", x)
}
&lt;/code&gt;&lt;/pre&gt; &lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;Since the first iota is declared with the value &lt;code&gt;3&lt;/code&gt; (&lt;code&gt; + 3&lt;/code&gt;), the next one has the value &lt;code&gt;4&lt;/code&gt; &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;What will be the output of the following block of code?: &lt;pre&gt;&lt;code class="language-go"&gt;package main

import (
	"fmt"
	"sync"
	"time"
)

func main() {
	var wg sync.WaitGroup

	wg.Add(1)
	go func() {
		time.Sleep(time.Second * 2)
		fmt.Println("1")
		wg.Done()
	}()

	go func() {
		fmt.Println("2")
	}()

	wg.Wait()
	fmt.Println("3")
}
&lt;/code&gt;&lt;/pre&gt; &lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;p&gt;Output: 2 1 3&lt;/p&gt; &lt;p&gt;&lt;a href="https://tutorialedge.net/golang/go-waitgroup-tutorial/"&gt;Aritcle about sync/waitgroup&lt;/a&gt;&lt;/p&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;&lt;a href="https://golang.org/pkg/sync/"&gt;Golang package sync&lt;/a&gt; &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;What will be the output of the following block of code?: &lt;pre&gt;&lt;code class="language-go"&gt;package main

import (
	"fmt"
)

func mod1(a []int) {
	for i := range a {
		a[i] = 5
	}

	fmt.Println("1:", a)
}

func mod2(a []int) {
	a = append(a, 125) // !

	for i := range a {
		a[i] = 5
	}

	fmt.Println("2:", a)
}

func main() {
	s1 := []int{1, 2, 3, 4}
	mod1(s1)
	fmt.Println("1:", s1)

	s2 := []int{1, 2, 3, 4}
	mod2(s2)
	fmt.Println("2:", s2)
}
&lt;/code&gt;&lt;/pre&gt; &lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;p&gt;Output: &lt;code&gt;&lt;br /&gt; 1 [5 5 5 5]&lt;br /&gt; 1 [5 5 5 5]&lt;br /&gt; 2 [5 5 5 5 5]&lt;br /&gt; 2 [1 2 3 4]&lt;br /&gt; &lt;/code&gt;&lt;/p&gt; &lt;p&gt;In &lt;code&gt;mod1&lt;/code&gt; a is link, and when we're using &lt;code&gt;a[i]&lt;/code&gt;, we're changing &lt;code&gt;s1&lt;/code&gt; value to. But in &lt;code&gt;mod2&lt;/code&gt;, &lt;code&gt;append&lt;/code&gt; creates new slice, and we're changing only &lt;code&gt;a&lt;/code&gt; value, not &lt;code&gt;s2&lt;/code&gt;.&lt;/p&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;&lt;a href="https://golangbot.com/arrays-and-slices/"&gt;Aritcle about arrays&lt;/a&gt;, &lt;a href="https://blog.golang.org/slices"&gt;Blog post about &lt;code&gt;append&lt;/code&gt;&lt;/a&gt; &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;What will be the output of the following block of code?: &lt;pre&gt;&lt;code class="language-go"&gt;package main

import (
	"container/heap"
	"fmt"
)

// An IntHeap is a min-heap of ints.
type IntHeap []int

func (h IntHeap) Len() int           { return len(h) }
func (h IntHeap) Less(i, j int) bool { return h[i] &amp;lt; h[j] }
func (h IntHeap) Swap(i, j int)      { h[i], h[j] = h[j], h[i] }

func (h *IntHeap) Push(x interface{}) {
	// Push and Pop use pointer receivers because they modify the slice's length,
	// not just its contents.
	*h = append(*h, x.(int))
}

func (h *IntHeap) Pop() interface{} {
	old := *h
	n := len(old)
	x := old[n-1]
	*h = old[0 : n-1]
	return x
}

func main() {
	h := &amp;amp;IntHeap{4, 8, 3, 6}
	heap.Init(h)
	heap.Push(h, 7)

  fmt.Println((*h)[0])
}
&lt;/code&gt;&lt;/pre&gt; &lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;p&gt;Output: 3&lt;/p&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;&lt;a href="https://golang.org/pkg/container/heap/"&gt;Golang container/heap package&lt;/a&gt; &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;h2&gt;Mongo&lt;/h2&gt; 
&lt;details&gt; 
 &lt;summary&gt;What are the advantages of MongoDB? Or in other words, why choosing MongoDB and not other implementation of NoSQL?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;p&gt;MongoDB advantages are as following:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Schemaless&lt;/li&gt; 
   &lt;li&gt;Easy to scale-out&lt;/li&gt; 
   &lt;li&gt;No complex joins&lt;/li&gt; 
   &lt;li&gt;Structure of a single object is clear&lt;/li&gt; 
  &lt;/ul&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;&lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;What is the difference between SQL and NoSQL?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;The main difference is that SQL databases are structured (data is stored in the form of tables with rows and columns - like an excel spreadsheet table) while NoSQL is unstructured, and the data storage can vary depending on how the NoSQL DB is set up, such as key-value pair, document-oriented, etc. &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;In what scenarios would you prefer to use NoSQL/Mongo over SQL?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;ul&gt;
  &lt;b&gt; &lt;li&gt;Heterogeneous data which changes often&lt;/li&gt; &lt;li&gt;Data consistency and integrity is not top priority&lt;/li&gt; &lt;li&gt;Best if the database needs to scale rapidly &lt;/li&gt;&lt;/b&gt;
 &lt;/ul&gt;
&lt;/details&gt;  
&lt;details&gt; 
 &lt;summary&gt;What is a document? What is a collection?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;ul&gt;
  &lt;b&gt; &lt;li&gt;A document is a record in MongoDB, which is stored in BSON (Binary JSON) format and is the basic unit of data in MongoDB.&lt;/li&gt; &lt;li&gt;A collection is a group of related documents stored in a single database in MongoDB. &lt;/li&gt;&lt;/b&gt;
 &lt;/ul&gt;
&lt;/details&gt;  
&lt;details&gt; 
 &lt;summary&gt;What is an aggregator?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;ul&gt;
  &lt;b&gt; &lt;li&gt;An aggregator is a framework in MongoDB that performs operations on a set of data to return a single computed result. &lt;/li&gt;&lt;/b&gt;
 &lt;/ul&gt;
&lt;/details&gt;  
&lt;details&gt; 
 &lt;summary&gt;What is better? Embedded documents or referenced?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;ul&gt;
  &lt;b&gt; &lt;li&gt;There is no definitive answer to which is better, it depends on the specific use case and requirements. Some explanations : Embedded documents provide atomic updates, while referenced documents allow for better normalization. &lt;/li&gt;&lt;/b&gt;
 &lt;/ul&gt;
&lt;/details&gt;  
&lt;details&gt; 
 &lt;summary&gt;Have you performed data retrieval optimizations in Mongo? If not, can you think about ways to optimize a slow data retrieval?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;ul&gt;
  &lt;b&gt; &lt;li&gt;Some ways to optimize data retrieval in MongoDB are: indexing, proper schema design, query optimization and database load balancing. &lt;/li&gt;&lt;/b&gt;
 &lt;/ul&gt;
&lt;/details&gt;  
&lt;h5&gt;Queries&lt;/h5&gt; 
&lt;details&gt; 
 &lt;summary&gt;Explain this query: &lt;code&gt;db.books.find({"name": /abc/})&lt;/code&gt;&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Explain this query: &lt;code&gt;db.books.find().sort({x:1})&lt;/code&gt;&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;What is the difference between find() and find_one()?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;ul&gt;
  &lt;b&gt; &lt;li&gt;&lt;code&gt;find()&lt;/code&gt; returns all documents that match the query conditions.&lt;/li&gt; &lt;li&gt;find_one() returns only one document that matches the query conditions (or null if no match is found). &lt;/li&gt;&lt;/b&gt;
 &lt;/ul&gt;
&lt;/details&gt;  
&lt;details&gt; 
 &lt;summary&gt;How can you export data from Mongo DB?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;ul&gt;
  &lt;b&gt; &lt;li&gt;mongoexport&lt;/li&gt; &lt;li&gt;programming languages &lt;/li&gt;&lt;/b&gt;
 &lt;/ul&gt;
&lt;/details&gt;  
&lt;h2&gt;SQL&lt;/h2&gt; 
&lt;h3&gt;SQL Exercises&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Name&lt;/th&gt; 
   &lt;th&gt;Topic&lt;/th&gt; 
   &lt;th&gt;Objective &amp;amp; Instructions&lt;/th&gt; 
   &lt;th&gt;Solution&lt;/th&gt; 
   &lt;th&gt;Comments&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Functions vs. Comparisons&lt;/td&gt; 
   &lt;td&gt;Query Improvements&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/topics/sql/improve_query.md"&gt;Exercise&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/topics/sql/solutions/improve_query.md"&gt;Solution&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;SQL Self Assessment&lt;/h3&gt; 
&lt;details&gt; 
 &lt;summary&gt;What is SQL?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;SQL (Structured Query Language) is a standard language for relational databases (like MySQL, MariaDB, ...).&lt;br /&gt; It's used for reading, updating, removing and creating data in a relational database. &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;How is SQL Different from NoSQL&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;The main difference is that SQL databases are structured (data is stored in the form of tables with rows and columns - like an excel spreadsheet table) while NoSQL is unstructured, and the data storage can vary depending on how the NoSQL DB is set up, such as key-value pair, document-oriented, etc. &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;When is it best to use SQL? NoSQL?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;p&gt;SQL - Best used when data integrity is crucial. SQL is typically implemented with many businesses and areas within the finance field due to it's ACID compliance.&lt;/p&gt; &lt;p&gt;NoSQL - Great if you need to scale things quickly. NoSQL was designed with web applications in mind, so it works great if you need to quickly spread the same information around to multiple servers&lt;/p&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;Additionally, since NoSQL does not adhere to the strict table with columns and rows structure that Relational Databases require, you can store different data types together. &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;h5&gt;Practical SQL - Basics&lt;/h5&gt; 
&lt;p&gt;For these questions, we will be using the Customers and Orders tables shown below:&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Customers&lt;/strong&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Customer_ID&lt;/th&gt; 
   &lt;th&gt;Customer_Name&lt;/th&gt; 
   &lt;th&gt;Items_in_cart&lt;/th&gt; 
   &lt;th&gt;Cash_spent_to_Date&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;100204&lt;/td&gt; 
   &lt;td&gt;John Smith&lt;/td&gt; 
   &lt;td&gt;0&lt;/td&gt; 
   &lt;td&gt;20.00&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;100205&lt;/td&gt; 
   &lt;td&gt;Jane Smith&lt;/td&gt; 
   &lt;td&gt;3&lt;/td&gt; 
   &lt;td&gt;40.00&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;100206&lt;/td&gt; 
   &lt;td&gt;Bobby Frank&lt;/td&gt; 
   &lt;td&gt;1&lt;/td&gt; 
   &lt;td&gt;100.20&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;ORDERS&lt;/strong&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Customer_ID&lt;/th&gt; 
   &lt;th&gt;Order_ID&lt;/th&gt; 
   &lt;th&gt;Item&lt;/th&gt; 
   &lt;th&gt;Price&lt;/th&gt; 
   &lt;th&gt;Date_sold&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;100206&lt;/td&gt; 
   &lt;td&gt;A123&lt;/td&gt; 
   &lt;td&gt;Rubber Ducky&lt;/td&gt; 
   &lt;td&gt;2.20&lt;/td&gt; 
   &lt;td&gt;2019-09-18&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;100206&lt;/td&gt; 
   &lt;td&gt;A123&lt;/td&gt; 
   &lt;td&gt;Bubble Bath&lt;/td&gt; 
   &lt;td&gt;8.00&lt;/td&gt; 
   &lt;td&gt;2019-09-18&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;100206&lt;/td&gt; 
   &lt;td&gt;Q987&lt;/td&gt; 
   &lt;td&gt;80-Pack TP&lt;/td&gt; 
   &lt;td&gt;90.00&lt;/td&gt; 
   &lt;td&gt;2019-09-20&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;100205&lt;/td&gt; 
   &lt;td&gt;Z001&lt;/td&gt; 
   &lt;td&gt;Cat Food - Tuna Fish&lt;/td&gt; 
   &lt;td&gt;10.00&lt;/td&gt; 
   &lt;td&gt;2019-08-05&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;100205&lt;/td&gt; 
   &lt;td&gt;Z001&lt;/td&gt; 
   &lt;td&gt;Cat Food - Chicken&lt;/td&gt; 
   &lt;td&gt;10.00&lt;/td&gt; 
   &lt;td&gt;2019-08-05&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;100205&lt;/td&gt; 
   &lt;td&gt;Z001&lt;/td&gt; 
   &lt;td&gt;Cat Food - Beef&lt;/td&gt; 
   &lt;td&gt;10.00&lt;/td&gt; 
   &lt;td&gt;2019-08-05&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;100205&lt;/td&gt; 
   &lt;td&gt;Z001&lt;/td&gt; 
   &lt;td&gt;Cat Food - Kitty quesadilla&lt;/td&gt; 
   &lt;td&gt;10.00&lt;/td&gt; 
   &lt;td&gt;2019-08-05&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;100204&lt;/td&gt; 
   &lt;td&gt;X202&lt;/td&gt; 
   &lt;td&gt;Coffee&lt;/td&gt; 
   &lt;td&gt;20.00&lt;/td&gt; 
   &lt;td&gt;2019-04-29&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;details&gt; 
 &lt;summary&gt;How would I select all fields from this table?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;Select * &lt;br /&gt; From Customers; &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;How many items are in John's cart?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;Select Items_in_cart &lt;br /&gt; From Customers &lt;br /&gt; Where Customer_Name = "John Smith"; &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;What is the sum of all the cash spent across all customers?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;Select SUM(Cash_spent_to_Date) as SUM_CASH &lt;br /&gt; From Customers; &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;How many people have items in their cart?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;Select count(1) as Number_of_People_w_items &lt;br /&gt; From Customers &lt;br /&gt; where Items_in_cart &amp;gt; 0; &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;How would you join the customer table to the order table?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;You would join them on the unique key. In this case, the unique key is Customer_ID in both the Customers table and Orders table &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;How would you show which customer ordered which items?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;p&gt;Select c.Customer_Name, o.Item &lt;br /&gt; From Customers c &lt;br /&gt; Left Join Orders o &lt;br /&gt; On c.Customer_ID = o.Customer_ID;&lt;/p&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;&lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;Using a with statement, how would you show who ordered cat food, and the total amount of money spent?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;p&gt;with cat_food as ( &lt;br /&gt; Select Customer_ID, SUM(Price) as TOTAL_PRICE &lt;br /&gt; From Orders &lt;br /&gt; Where Item like "%Cat Food%" &lt;br /&gt; Group by Customer_ID &lt;br /&gt; ) &lt;br /&gt; Select Customer_name, TOTAL_PRICE &lt;br /&gt; From Customers c &lt;br /&gt; Inner JOIN cat_food f &lt;br /&gt; ON c.Customer_ID = f.Customer_ID &lt;br /&gt; where c.Customer_ID in (Select Customer_ID from cat_food);&lt;/p&gt; &lt;p&gt;Although this was a simple statement, the "with" clause really shines when a complex query needs to be run on a table before joining to another. With statements are nice, because you create a pseudo temp when running your query, instead of creating a whole new table.&lt;/p&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;The Sum of all the purchases of cat food weren't readily available, so we used a with statement to create the pseudo table to retrieve the sum of the prices spent by each customer, then join the table normally. &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;Which of the following queries would you use? &lt;pre&gt;&lt;code&gt;SELECT count(*)                             SELECT count(*)
FROM shawarma_purchases                     FROM shawarma_purchases
WHERE                               vs.     WHERE
  YEAR(purchased_at) == '2017'              purchased_at &amp;gt;= '2017-01-01' AND
                                            purchased_at &amp;lt;= '2017-31-12'
&lt;/code&gt;&lt;/pre&gt; &lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;pre&gt;&lt;code&gt;SELECT count(*)
FROM shawarma_purchases
WHERE
  purchased_at &amp;gt;= '2017-01-01' AND
  purchased_at &amp;lt;= '2017-31-12'
&lt;/code&gt;&lt;/pre&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;When you use a function (&lt;code&gt;YEAR(purchased_at)&lt;/code&gt;) it has to scan the whole database as opposed to using indexes and basically the column as it is, in its natural state. &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;h2&gt;OpenStack&lt;/h2&gt; 
&lt;details&gt; 
 &lt;summary&gt;What components/projects of OpenStack are you familiar with?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; I’m most familiar with several core OpenStack components: 
  &lt;ul&gt; 
   &lt;li&gt;Nova for compute resource provisioning, including VM lifecycle management.&lt;/li&gt; 
   &lt;li&gt;Neutron for networking, focusing on creating and managing networks, subnets, and routers.&lt;/li&gt; 
   &lt;li&gt;Cinder for block storage, used to attach and manage storage volumes.&lt;/li&gt; 
   &lt;li&gt;Keystone for identity services, handling authentication and authorization.&lt;/li&gt; 
  &lt;/ul&gt; &lt;p&gt;I’ve implemented these in past projects, configuring them for scalability and security to support multi-tenant environments.&lt;/p&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;&lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;Can you tell me what each of the following services/projects is responsible for?: 
  &lt;ul&gt; 
   &lt;li&gt;Nova&lt;/li&gt; 
   &lt;li&gt;Neutron&lt;/li&gt; 
   &lt;li&gt;Cinder&lt;/li&gt; 
   &lt;li&gt;Glance&lt;/li&gt; 
   &lt;li&gt;Keystone&lt;/li&gt;
  &lt;/ul&gt;&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt;  &lt;/b&gt;
 &lt;ul&gt;
  &lt;b&gt; &lt;li&gt;Nova - Manage virtual instances&lt;/li&gt; &lt;li&gt;Neutron - Manage networking by providing Network as a service (NaaS)&lt;/li&gt; &lt;li&gt;Cinder - Block Storage&lt;/li&gt; &lt;li&gt;Glance - Manage images for virtual machines and containers (search, get and register)&lt;/li&gt; &lt;li&gt;Keystone - Authentication service across the cloud &lt;/li&gt;&lt;/b&gt;
 &lt;/ul&gt;
&lt;/details&gt;  
&lt;details&gt; 
 &lt;summary&gt;Identify the service/project used for each of the following: 
  &lt;ul&gt; 
   &lt;li&gt;Copy or snapshot instances&lt;/li&gt; 
   &lt;li&gt;GUI for viewing and modifying resources&lt;/li&gt; 
   &lt;li&gt;Block Storage&lt;/li&gt; 
   &lt;li&gt;Manage virtual instances&lt;/li&gt; 
  &lt;/ul&gt; &lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;ul&gt;
  &lt;b&gt; &lt;li&gt;Glance - Images Service. Also used for copying or snapshot instances&lt;/li&gt; &lt;li&gt;Horizon - GUI for viewing and modifying resources&lt;/li&gt; &lt;li&gt;Cinder - Block Storage&lt;/li&gt; &lt;li&gt;Nova - Manage virtual instances &lt;/li&gt;&lt;/b&gt;
 &lt;/ul&gt;
&lt;/details&gt;  
&lt;details&gt; 
 &lt;summary&gt;What is a tenant/project?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Determine true or false: 
  &lt;ul&gt; 
   &lt;li&gt;OpenStack is free to use&lt;/li&gt; 
   &lt;li&gt;The service responsible for networking is Glance&lt;/li&gt; 
   &lt;li&gt;The purpose of tenant/project is to share resources between different projects and users of OpenStack&lt;/li&gt;
  &lt;/ul&gt;&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
&lt;/details&gt;  
&lt;details&gt; 
 &lt;summary&gt;Describe in detail how you bring up an instance with a floating IP&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;You get a call from a customer saying: "I can ping my instance but can't connect (ssh) it". What might be the problem?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;What types of networks OpenStack supports?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;How do you debug OpenStack storage issues? (tools, logs, ...)&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;How do you debug OpenStack compute issues? (tools, logs, ...)&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
&lt;/details&gt; 
&lt;h4&gt;OpenStack Deployment &amp;amp; TripleO&lt;/h4&gt; 
&lt;details&gt; 
 &lt;summary&gt;Have you deployed OpenStack in the past? If yes, can you describe how you did it?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Are you familiar with TripleO? How is it different from Devstack or Packstack?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;You can read about TripleO right &lt;a href="https://docs.openstack.org/tripleo-docs/latest"&gt;here&lt;/a&gt; &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;h4&gt;OpenStack Compute&lt;/h4&gt; 
&lt;details&gt; 
 &lt;summary&gt;Can you describe Nova in detail?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;ul&gt;
  &lt;b&gt; &lt;li&gt;Used to provision and manage virtual instances&lt;/li&gt; &lt;li&gt;It supports Multi-Tenancy in different levels - logging, end-user control, auditing, etc.&lt;/li&gt; &lt;li&gt;Highly scalable&lt;/li&gt; &lt;li&gt;Authentication can be done using internal system or LDAP&lt;/li&gt; &lt;li&gt;Supports multiple types of block storage&lt;/li&gt; &lt;li&gt;Tries to be hardware and hypervisor agnostice &lt;/li&gt;&lt;/b&gt;
 &lt;/ul&gt;
&lt;/details&gt;  
&lt;details&gt; 
 &lt;summary&gt;What do you know about Nova architecture and components?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;ul&gt;
  &lt;b&gt; &lt;li&gt;nova-api - the server which serves metadata and compute APIs&lt;/li&gt; &lt;li&gt;the different Nova components communicate by using a queue (Rabbitmq usually) and a database&lt;/li&gt; &lt;li&gt;a request for creating an instance is inspected by nova-scheduler which determines where the instance will be created and running&lt;/li&gt; &lt;li&gt;nova-compute is the component responsible for communicating with the hypervisor for creating the instance and manage its lifecycle &lt;/li&gt;&lt;/b&gt;
 &lt;/ul&gt;
&lt;/details&gt;  
&lt;h4&gt;OpenStack Networking (Neutron)&lt;/h4&gt; 
&lt;details&gt; 
 &lt;summary&gt;Explain Neutron in detail&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;ul&gt;
  &lt;b&gt; &lt;li&gt;One of the core component of OpenStack and a standalone project&lt;/li&gt; &lt;li&gt;Neutron focused on delivering networking as a service&lt;/li&gt; &lt;li&gt;With Neutron, users can set up networks in the cloud and configure and manage a variety of network services&lt;/li&gt; &lt;li&gt;Neutron interacts with: 
    &lt;ul&gt; 
     &lt;li&gt;Keystone - authorize API calls&lt;/li&gt; 
     &lt;li&gt;Nova - nova communicates with neutron to plug NICs into a network&lt;/li&gt; 
     &lt;li&gt;Horizon - supports networking entities in the dashboard and also provides topology view which includes networking details &lt;/li&gt;
    &lt;/ul&gt;&lt;/li&gt;&lt;/b&gt;
 &lt;/ul&gt;
&lt;/details&gt;    
&lt;details&gt; 
 &lt;summary&gt;Explain each of the following components: 
  &lt;ul&gt; 
   &lt;li&gt;neutron-dhcp-agent&lt;/li&gt; 
   &lt;li&gt;neutron-l3-agent&lt;/li&gt; 
   &lt;li&gt;neutron-metering-agent&lt;/li&gt; 
   &lt;li&gt;neutron-*-agtent&lt;/li&gt; 
   &lt;li&gt;neutron-server&lt;/li&gt;
  &lt;/ul&gt;&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt;  &lt;/b&gt;
 &lt;ul&gt;
  &lt;b&gt; &lt;li&gt;neutron-l3-agent - L3/NAT forwarding (provides external network access for VMs for example)&lt;/li&gt; &lt;li&gt;neutron-dhcp-agent - DHCP services&lt;/li&gt; &lt;li&gt;neutron-metering-agent - L3 traffic metering&lt;/li&gt; &lt;li&gt;neutron-*-agtent - manages local vSwitch configuration on each compute (based on chosen plugin)&lt;/li&gt; &lt;li&gt;neutron-server - exposes networking API and passes requests to other plugins if required &lt;/li&gt;&lt;/b&gt;
 &lt;/ul&gt;
&lt;/details&gt;  
&lt;details&gt; 
 &lt;summary&gt;Explain these network types: 
  &lt;ul&gt; 
   &lt;li&gt;Management Network&lt;/li&gt; 
   &lt;li&gt;Guest Network&lt;/li&gt; 
   &lt;li&gt;API Network&lt;/li&gt; 
   &lt;li&gt;External Network&lt;/li&gt;
  &lt;/ul&gt;&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt;  &lt;/b&gt;
 &lt;ul&gt;
  &lt;b&gt; &lt;li&gt;Management Network - used for internal communication between OpenStack components. Any IP address in this network is accessible only within the datacetner&lt;/li&gt; &lt;li&gt;Guest Network - used for communication between instances/VMs&lt;/li&gt; &lt;li&gt;API Network - used for services API communication. Any IP address in this network is publicly accessible&lt;/li&gt; &lt;li&gt;External Network - used for public communication. Any IP address in this network is accessible by anyone on the internet &lt;/li&gt;&lt;/b&gt;
 &lt;/ul&gt;
&lt;/details&gt;  
&lt;details&gt; 
 &lt;summary&gt;In which order should you remove the following entities: 
  &lt;ul&gt; 
   &lt;li&gt;Network&lt;/li&gt; 
   &lt;li&gt;Port&lt;/li&gt; 
   &lt;li&gt;Router&lt;/li&gt; 
   &lt;li&gt;Subnet&lt;/li&gt;
  &lt;/ul&gt;&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt;  
  &lt;ul&gt; 
   &lt;li&gt;Port&lt;/li&gt; 
   &lt;li&gt;Subnet&lt;/li&gt; 
   &lt;li&gt;Router&lt;/li&gt; 
   &lt;li&gt;Network&lt;/li&gt; 
  &lt;/ul&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;There are many reasons for that. One for example: you can't remove router if there are active ports assigned to it. &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;What is a provider network?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;What components and services exist for L2 and L3?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;What is the ML2 plug-in? Explain its architecture&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;What is the L2 agent? How does it works and what is it responsible for?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;What is the L3 agent? How does it works and what is it responsible for?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Explain what the Metadata agent is responsible for&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;What networking entities Neutron supports?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;How do you debug OpenStack networking issues? (tools, logs, ...)&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
&lt;/details&gt; 
&lt;h4&gt;OpenStack - Glance&lt;/h4&gt; 
&lt;details&gt; 
 &lt;summary&gt;Explain Glance in detail&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;ul&gt;
  &lt;b&gt; &lt;li&gt;Glance is the OpenStack image service&lt;/li&gt; &lt;li&gt;It handles requests related to instances disks and images&lt;/li&gt; &lt;li&gt;Glance also used for creating snapshots for quick instances backups&lt;/li&gt; &lt;li&gt;Users can use Glance to create new images or upload existing ones &lt;/li&gt;&lt;/b&gt;
 &lt;/ul&gt;
&lt;/details&gt;  
&lt;details&gt; 
 &lt;summary&gt;Describe Glance architecture&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;ul&gt;
  &lt;b&gt; &lt;li&gt;glance-api - responsible for handling image API calls such as retrieval and storage. It consists of two APIs: 1. registry-api - responsible for internal requests 2. user API - can be accessed publicly&lt;/li&gt; &lt;li&gt;glance-registry - responsible for handling image metadata requests (e.g. size, type, etc). This component is private which means it's not available publicly&lt;/li&gt; &lt;li&gt;metadata definition service - API for custom metadata&lt;/li&gt; &lt;li&gt;database - for storing images metadata&lt;/li&gt; &lt;li&gt;image repository - for storing images. This can be a filesystem, swift object storage, HTTP, etc. &lt;/li&gt;&lt;/b&gt;
 &lt;/ul&gt;
&lt;/details&gt;  
&lt;h4&gt;OpenStack - Swift&lt;/h4&gt; 
&lt;details&gt; 
 &lt;summary&gt;Explain Swift in detail&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;ul&gt;
  &lt;b&gt; &lt;li&gt;Swift is Object Store service and is an highly available, distributed and consistent store designed for storing a lot of data&lt;/li&gt; &lt;li&gt;Swift is distributing data across multiple servers while writing it to multiple disks&lt;/li&gt; &lt;li&gt;One can choose to add additional servers to scale the cluster. All while swift maintaining integrity of the information and data replications. &lt;/li&gt;&lt;/b&gt;
 &lt;/ul&gt;
&lt;/details&gt;  
&lt;details&gt; 
 &lt;summary&gt;Can users store by default an object of 100GB in size?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;Not by default. Object Storage API limits the maximum to 5GB per object but it can be adjusted. &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;Explain the following in regards to Swift: 
  &lt;ul&gt; 
   &lt;li&gt;Container&lt;/li&gt; 
   &lt;li&gt;Account&lt;/li&gt; 
   &lt;li&gt;Object&lt;/li&gt; 
  &lt;/ul&gt; &lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;ul&gt;
  &lt;b&gt; &lt;li&gt;Container - Defines a namespace for objects.&lt;/li&gt; &lt;li&gt;Account - Defines a namespace for containers&lt;/li&gt; &lt;li&gt;Object - Data content (e.g. image, document, ...) &lt;/li&gt;&lt;/b&gt;
 &lt;/ul&gt;
&lt;/details&gt;  
&lt;details&gt; 
 &lt;summary&gt;True or False? there can be two objects with the same name in the same container but not in two different containers&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;False. Two objects can have the same name if they are in different containers. &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;h4&gt;OpenStack - Cinder&lt;/h4&gt; 
&lt;details&gt; 
 &lt;summary&gt;Explain Cinder in detail&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;ul&gt;
  &lt;b&gt; &lt;li&gt;Cinder is OpenStack Block Storage service&lt;/li&gt; &lt;li&gt;It basically provides used with storage resources they can consume with other services such as Nova&lt;/li&gt; &lt;li&gt;One of the most used implementations of storage supported by Cinder is LVM&lt;/li&gt; &lt;li&gt;From user perspective this is transparent which means the user doesn't know where, behind the scenes, the storage is located or what type of storage is used &lt;/li&gt;&lt;/b&gt;
 &lt;/ul&gt;
&lt;/details&gt;  
&lt;details&gt; 
 &lt;summary&gt;Describe Cinder's components&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;ul&gt;
  &lt;b&gt; &lt;li&gt;cinder-api - receives API requests&lt;/li&gt; &lt;li&gt;cinder-volume - manages attached block devices&lt;/li&gt; &lt;li&gt;cinder-scheduler - responsible for storing volumes &lt;/li&gt;&lt;/b&gt;
 &lt;/ul&gt;
&lt;/details&gt;  
&lt;h4&gt;OpenStack - Keystone&lt;/h4&gt; 
&lt;details&gt; 
 &lt;summary&gt;Can you describe the following concepts in regards to Keystone? 
  &lt;ul&gt; 
   &lt;li&gt;Role&lt;/li&gt; 
   &lt;li&gt;Tenant/Project&lt;/li&gt; 
   &lt;li&gt;Service&lt;/li&gt; 
   &lt;li&gt;Endpoint&lt;/li&gt; 
   &lt;li&gt;Token&lt;/li&gt; 
  &lt;/ul&gt; &lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;ul&gt;
  &lt;b&gt; &lt;li&gt;Role - A list of rights and privileges determining what a user or a project can perform&lt;/li&gt; &lt;li&gt;Tenant/Project - Logical representation of a group of resources isolated from other groups of resources. It can be an account, organization, ...&lt;/li&gt; &lt;li&gt;Service - An endpoint which the user can use for accessing different resources&lt;/li&gt; &lt;li&gt;Endpoint - a network address which can be used to access a certain OpenStack service&lt;/li&gt; &lt;li&gt;Token - Used for access resources while describing which resources can be accessed by using a scope &lt;/li&gt;&lt;/b&gt;
 &lt;/ul&gt;
&lt;/details&gt;  
&lt;details&gt; 
 &lt;summary&gt;What are the properties of a service? In other words, how a service is identified?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;p&gt;Using:&lt;/p&gt; &lt;/b&gt;
 &lt;ul&gt;
  &lt;b&gt; &lt;li&gt;Name&lt;/li&gt; &lt;li&gt;ID number&lt;/li&gt; &lt;li&gt;Type&lt;/li&gt; &lt;li&gt;Description &lt;/li&gt;&lt;/b&gt;
 &lt;/ul&gt;
&lt;/details&gt;  
&lt;details&gt; 
 &lt;summary&gt;Explain the following: - PublicURL - InternalURL - AdminURL&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;ul&gt;
  &lt;b&gt; &lt;li&gt;PublicURL - Publicly accessible through public internet&lt;/li&gt; &lt;li&gt;InternalURL - Used for communication between services&lt;/li&gt; &lt;li&gt;AdminURL - Used for administrative management &lt;/li&gt;&lt;/b&gt;
 &lt;/ul&gt;
&lt;/details&gt;  
&lt;details&gt; 
 &lt;summary&gt;What is a service catalog?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;A list of services and their endpoints &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;h4&gt;OpenStack Advanced - Services&lt;/h4&gt; 
&lt;details&gt; 
 &lt;summary&gt;Describe each of the following services 
  &lt;ul&gt; 
   &lt;li&gt;Swift&lt;/li&gt; 
   &lt;li&gt;Sahara&lt;/li&gt; 
   &lt;li&gt;Ironic&lt;/li&gt; 
   &lt;li&gt;Trove&lt;/li&gt; 
   &lt;li&gt;Aodh&lt;/li&gt; 
   &lt;li&gt;Ceilometer&lt;/li&gt; 
  &lt;/ul&gt; &lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;ul&gt;
  &lt;b&gt; &lt;li&gt;Swift - highly available, distributed, eventually consistent object/blob store&lt;/li&gt; &lt;li&gt;Sahara - Manage Hadoop Clusters&lt;/li&gt; &lt;li&gt;Ironic - Bare Metal Provisioning&lt;/li&gt; &lt;li&gt;Trove - Database as a service that runs on OpenStack&lt;/li&gt; &lt;li&gt;Aodh - Alarms Service&lt;/li&gt; &lt;li&gt;Ceilometer - Track and monitor usage &lt;/li&gt;&lt;/b&gt;
 &lt;/ul&gt;
&lt;/details&gt;  
&lt;details&gt; 
 &lt;summary&gt;Identify the service/project used for each of the following: 
  &lt;ul&gt; 
   &lt;li&gt;Database as a service which runs on OpenStack&lt;/li&gt; 
   &lt;li&gt;Bare Metal Provisioning&lt;/li&gt; 
   &lt;li&gt;Track and monitor usage&lt;/li&gt; 
   &lt;li&gt;Alarms Service&lt;/li&gt; 
   &lt;li&gt;Manage Hadoop Clusters&lt;/li&gt; 
   &lt;li&gt;highly available, distributed, eventually consistent object/blob store&lt;/li&gt; 
  &lt;/ul&gt; &lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;ul&gt;
  &lt;b&gt; &lt;li&gt;Database as a service which runs on OpenStack - Trove&lt;/li&gt; &lt;li&gt;Bare Metal Provisioning - Ironic&lt;/li&gt; &lt;li&gt;Track and monitor usage - Ceilometer&lt;/li&gt; &lt;li&gt;Alarms Service - Aodh&lt;/li&gt; &lt;li&gt;Manage Hadoop Clusters&lt;/li&gt; &lt;li&gt;Manage Hadoop Clusters - Sahara&lt;/li&gt; &lt;li&gt;highly available, distributed, eventually consistent object/blob store - Swift &lt;/li&gt;&lt;/b&gt;
 &lt;/ul&gt;
&lt;/details&gt;  
&lt;h4&gt;OpenStack Advanced - Keystone&lt;/h4&gt; 
&lt;details&gt; 
 &lt;summary&gt;Can you describe Keystone service in detail?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;ul&gt;
  &lt;b&gt; &lt;li&gt;You can't have OpenStack deployed without Keystone&lt;/li&gt; &lt;li&gt;It Provides identity, policy and token services 
    &lt;ul&gt; 
     &lt;li&gt;The authentication provided is for both users and services&lt;/li&gt; 
     &lt;li&gt;The authorization supported is token-based and user-based.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; &lt;li&gt;There is a policy defined based on RBAC stored in a JSON file and each line in that file defines the level of access to apply &lt;/li&gt;&lt;/b&gt;
 &lt;/ul&gt;
&lt;/details&gt;  
&lt;details&gt; 
 &lt;summary&gt;Describe Keystone architecture&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;ul&gt;
  &lt;b&gt; &lt;li&gt;There is a service API and admin API through which Keystone gets requests&lt;/li&gt; &lt;li&gt;Keystone has four backends: 
    &lt;ul&gt; 
     &lt;li&gt;Token Backend - Temporary Tokens for users and services&lt;/li&gt; 
     &lt;li&gt;Policy Backend - Rules management and authorization&lt;/li&gt; 
     &lt;li&gt;Identity Backend - users and groups (either standalone DB, LDAP, ...)&lt;/li&gt; 
     &lt;li&gt;Catalog Backend - Endpoints&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; &lt;li&gt;It has pluggable environment where you can integrate with: 
    &lt;ul&gt; 
     &lt;li&gt;LDAP&lt;/li&gt; 
     &lt;li&gt;KVS (Key Value Store)&lt;/li&gt; 
     &lt;li&gt;SQL&lt;/li&gt; 
     &lt;li&gt;PAM&lt;/li&gt; 
     &lt;li&gt;Memcached &lt;/li&gt;
    &lt;/ul&gt;&lt;/li&gt;&lt;/b&gt;
 &lt;/ul&gt;
&lt;/details&gt;    
&lt;details&gt; 
 &lt;summary&gt;Describe the Keystone authentication process&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;ul&gt;
  &lt;b&gt; &lt;li&gt;Keystone gets a call/request and checks whether it's from an authorized user, using username, password and authURL&lt;/li&gt; &lt;li&gt;Once confirmed, Keystone provides a token.&lt;/li&gt; &lt;li&gt;A token contains a list of user's projects so there is no to authenticate every time and a token can submitted instead &lt;/li&gt;&lt;/b&gt;
 &lt;/ul&gt;
&lt;/details&gt;  
&lt;h4&gt;OpenStack Advanced - Compute (Nova)&lt;/h4&gt; 
&lt;details&gt; 
 &lt;summary&gt;What each of the following does?: 
  &lt;ul&gt; 
   &lt;li&gt;nova-api&lt;/li&gt; 
   &lt;li&gt;nova-compuate&lt;/li&gt; 
   &lt;li&gt;nova-conductor&lt;/li&gt; 
   &lt;li&gt;nova-cert&lt;/li&gt; 
   &lt;li&gt;nova-consoleauth&lt;/li&gt; 
   &lt;li&gt;nova-scheduler&lt;/li&gt; 
  &lt;/ul&gt; &lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;ul&gt;
  &lt;b&gt; &lt;li&gt;nova-api - responsible for managing requests/calls&lt;/li&gt; &lt;li&gt;nova-compute - responsible for managing instance lifecycle&lt;/li&gt; &lt;li&gt;nova-conductor - Mediates between nova-compute and the database so nova-compute doesn't access it directly &lt;/li&gt;&lt;/b&gt;
 &lt;/ul&gt;
&lt;/details&gt;  
&lt;details&gt; 
 &lt;summary&gt;What types of Nova proxies are you familiar with?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;ul&gt;
  &lt;b&gt; &lt;li&gt;Nova-novncproxy - Access through VNC connections&lt;/li&gt; &lt;li&gt;Nova-spicehtml5proxy - Access through SPICE&lt;/li&gt; &lt;li&gt;Nova-xvpvncproxy - Access through a VNC connection &lt;/li&gt;&lt;/b&gt;
 &lt;/ul&gt;
&lt;/details&gt;  
&lt;h4&gt;OpenStack Advanced - Networking (Neutron)&lt;/h4&gt; 
&lt;details&gt; 
 &lt;summary&gt;Explain BGP dynamic routing&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;What is the role of network namespaces in OpenStack?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
&lt;/details&gt; 
&lt;h4&gt;OpenStack Advanced - Horizon&lt;/h4&gt; 
&lt;details&gt; 
 &lt;summary&gt;Can you describe Horizon in detail?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;ul&gt;
  &lt;b&gt; &lt;li&gt;Django-based project focusing on providing an OpenStack dashboard and the ability to create additional customized dashboards&lt;/li&gt; &lt;li&gt;You can use it to access the different OpenStack services resources - instances, images, networks, ... 
    &lt;ul&gt; 
     &lt;li&gt;By accessing the dashboard, users can use it to list, create, remove and modify the different resources&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; &lt;li&gt;It's also highly customizable and you can modify or add to it based on your needs &lt;/li&gt;&lt;/b&gt;
 &lt;/ul&gt;
&lt;/details&gt;  
&lt;details&gt; 
 &lt;summary&gt;What can you tell about Horizon architecture?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;ul&gt;
  &lt;b&gt; &lt;li&gt;API is backward compatible&lt;/li&gt; &lt;li&gt;There are three type of dashboards: user, system and settings&lt;/li&gt; &lt;li&gt;It provides core support for all OpenStack core projects such as Neutron, Nova, etc. (out of the box, no need to install extra packages or plugins)&lt;/li&gt; &lt;li&gt;Anyone can extend the dashboards and add new components&lt;/li&gt; &lt;li&gt;Horizon provides templates and core classes from which one can build its own dashboard &lt;/li&gt;&lt;/b&gt;
 &lt;/ul&gt;
&lt;/details&gt;  
&lt;h2&gt;Puppet&lt;/h2&gt; 
&lt;details&gt; 
 &lt;summary&gt;What is Puppet? How does it works?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;ul&gt;
  &lt;b&gt; &lt;li&gt;Puppet is a configuration management tool ensuring that all systems are configured to a desired and predictable state. &lt;/li&gt;&lt;/b&gt;
 &lt;/ul&gt;
&lt;/details&gt;  
&lt;details&gt; 
 &lt;summary&gt;Explain Puppet architecture&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;ul&gt;
  &lt;b&gt; &lt;li&gt;Puppet has a primary-secondary node architecture. The clients are distributed across the network and communicate with the primary-secondary environment where Puppet modules are present. The client agent sends a certificate with its ID to the server; the server then signs that certificate and sends it back to the client. This authentication allows for secure and verifiable communication between the client and the master. &lt;/li&gt;&lt;/b&gt;
 &lt;/ul&gt;
&lt;/details&gt;  
&lt;details&gt; 
 &lt;summary&gt;Can you compare Puppet to other configuration management tools? Why did you chose to use Puppet?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;ul&gt;
  &lt;b&gt; &lt;li&gt;Puppet is often compared to other configuration management tools like Chef, Ansible, SaltStack, and cfengine. The choice to use Puppet often depends on an organization's needs, such as ease of use, scalability, and community support. &lt;/li&gt;&lt;/b&gt;
 &lt;/ul&gt;
&lt;/details&gt;  
&lt;details&gt; 
 &lt;summary&gt;Explain the following: 
  &lt;ul&gt; 
   &lt;li&gt;Module&lt;/li&gt; 
   &lt;li&gt;Manifest&lt;/li&gt; 
   &lt;li&gt;Node&lt;/li&gt; 
  &lt;/ul&gt; &lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;ul&gt;
  &lt;b&gt; &lt;li&gt;Modules - are a collection of manifests, templates, and files&lt;/li&gt; &lt;li&gt;Manifests - are the actual codes for configuring the clients&lt;/li&gt; &lt;li&gt;Node - allows you to assign specific configurations to specific nodes &lt;/li&gt;&lt;/b&gt;
 &lt;/ul&gt;
&lt;/details&gt;  
&lt;details&gt; 
 &lt;summary&gt;Explain Facter&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;ul&gt;
  &lt;b&gt; &lt;li&gt;Facter is a standalone tool in Puppet that collects information about a system and its configuration, such as the operating system, IP addresses, memory, and network interfaces. This information can be used in Puppet manifests to make decisions about how resources should be managed, and to customize the behavior of Puppet based on the characteristics of the system. Facter is integrated into Puppet, and its facts can be used within Puppet manifests to make decisions about resource management. &lt;/li&gt;&lt;/b&gt;
 &lt;/ul&gt;
&lt;/details&gt;  
&lt;details&gt; 
 &lt;summary&gt;What is MCollective?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;ul&gt;
  &lt;b&gt; &lt;li&gt;MCollective is a middleware system that integrates with Puppet to provide orchestration, remote execution, and parallel job execution capabilities. &lt;/li&gt;&lt;/b&gt;
 &lt;/ul&gt;
&lt;/details&gt;  
&lt;details&gt; 
 &lt;summary&gt;Do you have experience with writing modules? Which module have you created and for what?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Explain what is Hiera&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;ul&gt;
  &lt;b&gt; &lt;li&gt;Hiera is a hierarchical data store in Puppet that is used to separate data from code, allowing data to be more easily separated, managed, and reused. &lt;/li&gt;&lt;/b&gt;
 &lt;/ul&gt;
&lt;/details&gt;  
&lt;h2&gt;Elastic&lt;/h2&gt; 
&lt;details&gt; 
 &lt;summary&gt;What is the Elastic Stack?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;p&gt;The Elastic Stack consists of:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Elasticsearch&lt;/li&gt; 
   &lt;li&gt;Kibana&lt;/li&gt; 
   &lt;li&gt;Logstash&lt;/li&gt; 
   &lt;li&gt;Beats&lt;/li&gt; 
   &lt;li&gt;Elastic Hadoop&lt;/li&gt; 
   &lt;li&gt;APM Server&lt;/li&gt; 
  &lt;/ul&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;Elasticsearch, Logstash and Kibana are also known as the ELK stack. &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;Explain what is Elasticsearch&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;p&gt;From the official &lt;a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/documents-indices.html"&gt;docs&lt;/a&gt;:&lt;/p&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;"Elasticsearch is a distributed document store. Instead of storing information as rows of columnar data, Elasticsearch stores complex data structures that have been serialized as JSON documents" &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;What is Logstash?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;p&gt;From the &lt;a href="https://logit.io/blog/post/the-top-50-elk-stack-and-elasticsearch-interview-questions"&gt;blog&lt;/a&gt;:&lt;/p&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;"Logstash is a powerful, flexible pipeline that collects, enriches and transports data. It works as an extract, transform &amp;amp; load (ETL) tool for collecting log messages." &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;Explain what beats are&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;Beats are lightweight data shippers. These data shippers installed on the client where the data resides. Examples of beats: Filebeat, Metricbeat, Auditbeat. There are much more.&lt;br /&gt; &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;What is Kibana?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;p&gt;From the official docs:&lt;/p&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;"Kibana is an open source analytics and visualization platform designed to work with Elasticsearch. You use Kibana to search, view, and interact with data stored in Elasticsearch indices. You can easily perform advanced data analysis and visualize your data in a variety of charts, tables, and maps." &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;Describe what happens from the moment an app logged some information until it's displayed to the user in a dashboard when the Elastic stack is used&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;p&gt;The process may vary based on the chosen architecture and the processing you may want to apply to the logs. One possible workflow is:&lt;/p&gt; &lt;/b&gt;
 &lt;ol&gt;
  &lt;b&gt; &lt;li&gt;The data logged by the application is picked by filebeat and sent to logstash&lt;/li&gt; &lt;li&gt;Logstash process the log based on the defined filters. Once done, the output is sent to Elasticsearch&lt;/li&gt; &lt;li&gt;Elasticsearch stores the document it got and the document is indexed for quick future access&lt;/li&gt; &lt;li&gt;The user creates visualizations in Kibana which based on the indexed data&lt;/li&gt; &lt;li&gt;The user creates a dashboard which composed out of the visualization created in the previous step &lt;/li&gt;&lt;/b&gt;
 &lt;/ol&gt;
&lt;/details&gt;  
&lt;h5&gt;Elasticsearch&lt;/h5&gt; 
&lt;details&gt; 
 &lt;summary&gt;What is a data node?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;This is where data is stored and also where different processing takes place (e.g. when you search for a data). &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;What is a master node?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;p&gt;Part of a master node responsibilities:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Track the status of all the nodes in the cluster&lt;/li&gt; 
   &lt;li&gt;Verify replicas are working and the data is available from every data node.&lt;/li&gt; 
   &lt;li&gt;No hot nodes (no data node that works much harder than other nodes)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;While there can be multiple master nodes in reality only of them is the elected master node. &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;What is an ingest node?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;A node which responsible for processing the data according to ingest pipeline. In case you don't need to use logstash then this node can receive data from beats and process it, similarly to how it can be processed in Logstash. &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;What is Coordinating only node?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;p&gt;From the official docs:&lt;/p&gt; &lt;p&gt;Coordinating only nodes can benefit large clusters by offloading the coordinating node role from data and master-eligible nodes. They join the cluster and receive the full cluster state, like every other node, and they use the cluster state to route requests directly to the appropriate place(s).&lt;/p&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;&lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;How data is stored in Elasticsearch?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;ul&gt;
  &lt;b&gt; &lt;li&gt;Data is stored in an index&lt;/li&gt; &lt;li&gt;The index is spread across the cluster using shards &lt;/li&gt;&lt;/b&gt;
 &lt;/ul&gt;
&lt;/details&gt;  
&lt;details&gt; 
 &lt;summary&gt;What is an Index?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;p&gt;Index in Elasticsearch is in most cases compared to a whole database from the SQL/NoSQL world.&lt;br /&gt; You can choose to have one index to hold all the data of your app or have multiple indices where each index holds different type of your app (e.g. index for each service your app is running).&lt;/p&gt; &lt;p&gt;The official docs also offer a great explanation (in general, it's really good documentation, as every project should have):&lt;/p&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;"An index can be thought of as an optimized collection of documents and each document is a collection of fields, which are the key-value pairs that contain your data" &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;Explain Shards&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;An index is split into shards and documents are hashed to a particular shard. Each shard may be on a different node in a cluster and each one of the shards is a self contained index.&lt;br /&gt; This allows Elasticsearch to scale to an entire cluster of servers. &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;What is an Inverted Index?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;p&gt;From the official docs:&lt;/p&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;"An inverted index lists every unique word that appears in any document and identifies all of the documents each word occurs in." &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;What is a Document?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;Continuing with the comparison to SQL/NoSQL a Document in Elasticsearch is a row in table in the case of SQL or a document in a collection in the case of NoSQL. As in NoSQL a document is a JSON object which holds data on a unit in your app. What is this unit depends on the your app. If your app related to book then each document describes a book. If you are app is about shirts then each document is a shirt. &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;You check the health of your elasticsearch cluster and it's red. What does it mean? What can cause the status to be yellow instead of green?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;Red means some data is unavailable in your cluster. Some shards of your indices are unassigned. There are some other states for the cluster. Yellow means that you have unassigned shards in the cluster. You can be in this state if you have single node and your indices have replicas. Green means that all shards in the cluster are assigned to nodes and your cluster is healthy. &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;True or False? Elasticsearch indexes all data in every field and each indexed field has the same data structure for unified and quick query ability&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;p&gt;False. From the official docs:&lt;/p&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;"Each indexed field has a dedicated, optimized data structure. For example, text fields are stored in inverted indices, and numeric and geo fields are stored in BKD trees." &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;What reserved fields a document has?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;ul&gt;
  &lt;b&gt; &lt;li&gt;_index&lt;/li&gt; &lt;li&gt;_id&lt;/li&gt; &lt;li&gt;_type &lt;/li&gt;&lt;/b&gt;
 &lt;/ul&gt;
&lt;/details&gt;  
&lt;details&gt; 
 &lt;summary&gt;Explain Mapping&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;What are the advantages of defining your own mapping? (or: when would you use your own mapping?)&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;ul&gt;
  &lt;b&gt; &lt;li&gt;You can optimize fields for partial matching&lt;/li&gt; &lt;li&gt;You can define custom formats of known fields (e.g. date)&lt;/li&gt; &lt;li&gt;You can perform language-specific analysis &lt;/li&gt;&lt;/b&gt;
 &lt;/ul&gt;
&lt;/details&gt;  
&lt;details&gt; 
 &lt;summary&gt;Explain Replicas&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;In a network/cloud environment where failures can be expected any time, it is very useful and highly recommended to have a failover mechanism in case a shard/node somehow goes offline or disappears for whatever reason. To this end, Elasticsearch allows you to make one or more copies of your index’s shards into what are called replica shards, or replicas for short. &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;Can you explain Term Frequency &amp;amp; Document Frequency?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;Term Frequency is how often a term appears in a given document and Document Frequency is how often a term appears in all documents. They both are used for determining the relevance of a term by calculating Term Frequency / Document Frequency. &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;You check "Current Phase" under "Index lifecycle management" and you see it's set to "hot". What does it mean?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;"The index is actively being written to". More about the phases &lt;a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.6/ilm-policy-definition.html"&gt;here&lt;/a&gt; &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;What this command does? &lt;code&gt;curl -X PUT "localhost:9200/customer/_doc/1?pretty" -H 'Content-Type: application/json' -d'{ "name": "John Doe" }'&lt;/code&gt;&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;It creates customer index if it doesn't exists and adds a new document with the field name which is set to "John Dow". Also, if it's the first document it will get the ID 1. &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;What will happen if you run the previous command twice? What about running it 100 times?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;ol&gt;
  &lt;b&gt; &lt;li&gt;If name value was different then it would update "name" to the new value&lt;/li&gt; &lt;li&gt;In any case, it bumps version field by one &lt;/li&gt;&lt;/b&gt;
 &lt;/ol&gt;
&lt;/details&gt;  
&lt;details&gt; 
 &lt;summary&gt;What is the Bulk API? What would you use it for?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;Bulk API is used when you need to index multiple documents. For high number of documents it would be significantly faster to use rather than individual requests since there are less network roundtrips. &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;h5&gt;Query DSL&lt;/h5&gt; 
&lt;details&gt; 
 &lt;summary&gt;Explain Elasticsearch query syntax (Booleans, Fields, Ranges)&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Explain what is Relevance Score&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Explain Query Context and Filter Context&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;p&gt;From the official docs:&lt;/p&gt; &lt;p&gt;"In the query context, a query clause answers the question “How well does this document match this query clause?” Besides deciding whether or not the document matches, the query clause also calculates a relevance score in the _score meta-field."&lt;/p&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;"In a filter context, a query clause answers the question “Does this document match this query clause?” The answer is a simple Yes or No — no scores are calculated. Filter context is mostly used for filtering structured data" &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;Describe how would an architecture of production environment with large amounts of data would be different from a small-scale environment&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;p&gt;There are several possible answers for this question. One of them is as follows:&lt;/p&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;A small-scale architecture of elastic will consist of the elastic stack as it is. This means we will have beats, logstash, elastcsearch and kibana.&lt;br /&gt; A production environment with large amounts of data can include some kind of buffering component (e.g. Reddis or RabbitMQ) and also security component such as Nginx. &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;h5&gt;Logstash&lt;/h5&gt; 
&lt;details&gt; 
 &lt;summary&gt;What are Logstash plugins? What plugins types are there?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;ul&gt;
  &lt;b&gt; &lt;li&gt;Input Plugins - how to collect data from different sources&lt;/li&gt; &lt;li&gt;Filter Plugins - processing data&lt;/li&gt; &lt;li&gt;Output Plugins - push data to different outputs/services/platforms &lt;/li&gt;&lt;/b&gt;
 &lt;/ul&gt;
&lt;/details&gt;  
&lt;details&gt; 
 &lt;summary&gt;What is grok?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;A logstash plugin which modifies information in one format and immerse it in another. &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;How grok works?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;What grok patterns are you familiar with?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;What is `_grokparsefailure?`&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;How do you test or debug grok patterns?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;What are Logstash Codecs? What codecs are there?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
&lt;/details&gt; 
&lt;h5&gt;Kibana&lt;/h5&gt; 
&lt;details&gt; 
 &lt;summary&gt;What can you find under "Discover" in Kibana?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;The raw data as it is stored in the index. You can search and filter it. &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;You see in Kibana, after clicking on Discover, "561 hits". What does it mean?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;Total number of documents matching the search results. If not query used then simply the total number of documents. &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;What can you find under "Visualize"?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;"Visualize" is where you can create visual representations for your data (pie charts, graphs, ...) &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;What visualization types are supported/included in Kibana?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;What visualization type would you use for statistical outliers&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Describe in detail how do you create a dashboard in Kibana&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
&lt;/details&gt; 
&lt;h4&gt;Filebeat&lt;/h4&gt; 
&lt;details&gt; 
 &lt;summary&gt;What is Filebeat?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;Filebeat is used to monitor the logging directories inside of VMs or mounted as a sidecar if exporting logs from containers, and then forward these logs onward for further processing, usually to logstash. &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;If one is using ELK, is it a must to also use filebeat? In what scenarios it's useful to use filebeat?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;Filebeat is a typical component of the ELK stack, since it was developed by Elastic to work with the other products (Logstash and Kibana). It's possible to send logs directly to logstash, though this often requires coding changes for the application. Particularly for legacy applications with little test coverage, it might be a better option to use filebeat, since you don't need to make any changes to the application code. &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;What is a harvester?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;Read &lt;a href="https://www.elastic.co/guide/en/beats/filebeat/current/how-filebeat-works.html#harvester"&gt;here&lt;/a&gt; &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;True or False? a single harvester harvest multiple files, according to the limits set in filebeat.yml&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;False. One harvester harvests one file. &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;What are filebeat modules?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;These are pre-configured modules for specific types of logging locations (eg, Traefik, Fargate, HAProxy) to make it easy to configure forwarding logs using filebeat. They have different configurations based on where you're collecting logs from. &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;h4&gt;Elastic Stack&lt;/h4&gt; 
&lt;details&gt; 
 &lt;summary&gt;How do you secure an Elastic Stack?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;You can generate certificates with the provided elastic utils and change configuration to enable security using certificates model. &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;h2&gt;Distributed&lt;/h2&gt; 
&lt;details&gt; 
 &lt;summary&gt;Explain Distributed Computing (or Distributed System)&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;p&gt;According to Martin Kleppmann:&lt;/p&gt; &lt;p&gt;"Many processes running on many machines...only message-passing via an unreliable network with variable delays, and the system may suffer from partial failures, unreliable clocks, and process pauses."&lt;/p&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;Another definition: "Systems that are physically separated, but logically connected" &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;What can cause a system to fail?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;ul&gt;
  &lt;b&gt; &lt;li&gt;Network&lt;/li&gt; &lt;li&gt;CPU&lt;/li&gt; &lt;li&gt;Memory&lt;/li&gt; &lt;li&gt;Disk &lt;/li&gt;&lt;/b&gt;
 &lt;/ul&gt;
&lt;/details&gt;  
&lt;details&gt; 
 &lt;summary&gt;Do you know what is "CAP theorem"? (aka as Brewer's theorem)&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;p&gt;According to the CAP theorem, it's not possible for a distributed data store to provide more than two of the following at the same time:&lt;/p&gt; &lt;/b&gt;
 &lt;ul&gt;
  &lt;b&gt; &lt;li&gt;Availability: Every request receives a response (it doesn't has to be the most recent data)&lt;/li&gt; &lt;li&gt;Consistency: Every request receives a response with the latest/most recent data&lt;/li&gt; &lt;li&gt;Partition tolerance: Even if some the data is lost/dropped, the system keeps running &lt;/li&gt;&lt;/b&gt;
 &lt;/ul&gt;
&lt;/details&gt;  
&lt;details&gt; 
 &lt;summary&gt;What are the problems with the following design? How to improve it?&lt;br /&gt; &lt;img src="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/images/distributed/distributed_design_standby.png" width="500x;" height="350px;" /&gt; &lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; 1. The transition can take time. In other words, noticeable downtime. 2. Standby server is a waste of resources - if first application server is running then the standby does nothing &lt;/b&gt;
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;What are the problems with the following design? How to improve it?&lt;br /&gt; &lt;img src="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/images/distributed/distributed_design_lb.png" width="700x;" height="350px;" /&gt; &lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; Issues: If load balancer dies , we lose the ability to communicate with the application. &lt;p&gt;Ways to improve:&lt;/p&gt; &lt;/b&gt;
 &lt;ul&gt;
  &lt;b&gt; &lt;li&gt;Add another load balancer&lt;/li&gt; &lt;li&gt;Use DNS A record for both load balancers&lt;/li&gt; &lt;li&gt;Use message queue &lt;/li&gt;&lt;/b&gt;
 &lt;/ul&gt;
&lt;/details&gt;  
&lt;details&gt; 
 &lt;summary&gt;What is "Shared-Nothing" architecture?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;It's an architecture in which data is and retrieved from a single, non-shared, source usually exclusively connected to one node as opposed to architectures where the request can get to one of many nodes and the data will be retrieved from one shared location (storage, memory, ...). &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;Explain the Sidecar Pattern (Or sidecar proxy)&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
&lt;/details&gt; 
&lt;h2&gt;Misc&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Name&lt;/th&gt; 
   &lt;th&gt;Topic&lt;/th&gt; 
   &lt;th&gt;Objective &amp;amp; Instructions&lt;/th&gt; 
   &lt;th&gt;Solution&lt;/th&gt; 
   &lt;th&gt;Comments&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Highly Available "Hello World"&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/topics/devops/ha_hello_world.md"&gt;Exercise&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/topics/devops/solutions/ha_hello_world.md"&gt;Solution&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;details&gt; 
 &lt;summary&gt;What happens when you type in a URL in an address bar in a browser?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; 
  &lt;ol&gt; 
   &lt;li&gt;The browser searches for the record of the domain name IP address in the DNS in the following order:&lt;/li&gt; 
  &lt;/ol&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Browser cache&lt;/li&gt; 
   &lt;li&gt;Operating system cache&lt;/li&gt; 
   &lt;li&gt;The DNS server configured on the user's system (can be ISP DNS, public DNS, ...)&lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;ol start="2"&gt; 
   &lt;li&gt;If it couldn't find a DNS record locally, a full DNS resolution is started.&lt;/li&gt; 
   &lt;li&gt;It connects to the server using the TCP protocol&lt;/li&gt; 
   &lt;li&gt;The browser sends an HTTP request to the server&lt;/li&gt; 
   &lt;li&gt;The server sends an HTTP response back to the browser&lt;/li&gt; 
   &lt;li&gt;The browser renders the response (e.g. HTML)&lt;/li&gt; 
   &lt;li&gt;The browser then sends subsequent requests as needed to the server to get the embedded links, javascript, images in the HTML and then steps 3 to 5 are repeated.&lt;/li&gt; 
  &lt;/ol&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;TODO: add more details! &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;h4&gt;API&lt;/h4&gt; 
&lt;details&gt; 
 &lt;summary&gt;Explain what is an API&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;p&gt;I like this definition from &lt;a href="https://blog.christianposta.com/microservices/api-gateways-are-going-through-an-identity-crisis"&gt;blog.christianposta.com&lt;/a&gt;:&lt;/p&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;"An explicitly and purposefully defined interface designed to be invoked over a network that enables software developers to get programmatic access to data and functionality within an organization in a controlled and comfortable way." &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;What is an API specification?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;p&gt;From &lt;a href="https://swagger.io/resources/articles/difference-between-api-documentation-specification"&gt;swagger.io&lt;/a&gt;:&lt;/p&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;"An API specification provides a broad understanding of how an API behaves and how the API links with other APIs. It explains how the API functions and the results to expect when using the API" &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;True or False? API Definition is the same as API Specification&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;p&gt;False. From &lt;a href="https://swagger.io/resources/articles/difference-between-api-documentation-specification"&gt;swagger.io&lt;/a&gt;:&lt;/p&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;"An API definition is similar to an API specification in that it provides an understanding of how an API is organized and how the API functions. But the API definition is aimed at machine consumption instead of human consumption of APIs." &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;What is an API gateway?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;p&gt;An API gateway is like the gatekeeper that controls how different parts talk to each other and how information is exchanged between them.&lt;/p&gt; &lt;p&gt;The API gateway provides a single point of entry for all clients, and it can perform several tasks, including routing requests to the appropriate backend service, load balancing, security and authentication, rate limiting, caching, and monitoring.&lt;/p&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;By using an API gateway, organizations can simplify the management of their APIs, ensure consistent security and governance, and improve the performance and scalability of their backend services. They are also commonly used in microservices architectures, where there are many small, independent services that need to be accessed by different clients. &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;What are the advantages of using/implementing an API gateway?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;p&gt;Advantages:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Simplifies API management: Provides a single entry point for all requests, which simplifies the management and monitoring of multiple APIs.&lt;/li&gt; 
   &lt;li&gt;Improves security: Able to implement security features like authentication, authorization, and encryption to protect the backend services from unauthorized access.&lt;/li&gt; 
   &lt;li&gt;Enhances scalability: Can handle traffic spikes and distribute requests to backend services in a way that maximizes resource utilization and improves overall system performance.&lt;/li&gt; 
   &lt;li&gt;Enables service composition: Can combine different backend services into a single API, providing more granular control over the services that clients can access.&lt;/li&gt; 
   &lt;li&gt;Facilitates integration with external systems: Can be used to expose internal services to external partners or customers, making it easier to integrate with external systems and enabling new business models.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;&lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;What is a Payload in API?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;What is Automation? How it's related or different from Orchestration?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;Automation is the act of automating tasks to reduce human intervention or interaction in regards to IT technology and systems.&lt;br /&gt; While automation focuses on a task level, Orchestration is the process of automating processes and/or workflows which consists of multiple tasks that usually across multiple systems. &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;Tell me about interesting bugs you've found and also fixed&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;What is a Debugger and how it works?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;What services an application might have?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;ul&gt;
  &lt;b&gt; &lt;li&gt;Authorization&lt;/li&gt; &lt;li&gt;Logging&lt;/li&gt; &lt;li&gt;Authentication&lt;/li&gt; &lt;li&gt;Ordering&lt;/li&gt; &lt;li&gt;Front-end&lt;/li&gt; &lt;li&gt;Back-end ... &lt;/li&gt;&lt;/b&gt;
 &lt;/ul&gt;
&lt;/details&gt;  
&lt;details&gt; 
 &lt;summary&gt;What is Metadata?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;Data about data. Basically, it describes the type of information that an underlying data will hold. &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;You can use one of the following formats: JSON, YAML, XML. Which one would you use? Why?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;I can't answer this for you :) &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;What's KPI?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;What's OKR?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;What's DSL (Domain Specific Language)?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;Domain Specific Language (DSLs) are used to create a customised language that represents the domain such that domain experts can easily interpret it. &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;What's the difference between KPI and OKR?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
&lt;/details&gt; 
&lt;h4&gt;YAML&lt;/h4&gt; 
&lt;details&gt; 
 &lt;summary&gt;What is YAML?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;Data serialization language used by many technologies today like Kubernetes, Ansible, etc. &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;True or False? Any valid JSON file is also a valid YAML file&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;True. Because YAML is superset of JSON. &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;What is the format of the following data? &lt;pre&gt;&lt;code&gt;{
    applications: [
        {
            name: "my_app",
            language: "python",
            version: 20.17
        }
    ]
}
&lt;/code&gt;&lt;/pre&gt; &lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; JSON &lt;/b&gt;
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;What is the format of the following data? &lt;pre&gt;&lt;code&gt;applications:
  - app: "my_app"
    language: "python"
    version: 20.17
&lt;/code&gt;&lt;/pre&gt; &lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; YAML &lt;/b&gt;
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;How to write a multi-line string with YAML? What use cases is it good for?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;pre&gt;&lt;code&gt;someMultiLineString: |
  look mama
  I can write a multi-line string
  I love YAML
&lt;/code&gt;&lt;/pre&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;It's good for use cases like writing a shell script where each line of the script is a different command. &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;What is the difference between &lt;code&gt;someMultiLineString: |&lt;/code&gt; to &lt;code&gt;someMultiLineString: &amp;gt;&lt;/code&gt;?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;p&gt;using &lt;code&gt;&amp;gt;&lt;/code&gt; will make the multi-line string to fold into a single line&lt;/p&gt; &lt;pre&gt;&lt;code&gt;someMultiLineString: &amp;gt;
  This is actually
  a single line
  do not let appearances fool you
&lt;/code&gt;&lt;/pre&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;&lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;What are placeholders in YAML?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;p&gt;They allow you reference values instead of directly writing them and it is used like this:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;username: {{ my.user_name }}
&lt;/code&gt;&lt;/pre&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;&lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;How can you define multiple YAML components in one file?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;p&gt;Using this: &lt;code&gt;---&lt;/code&gt; For Examples:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;document_number: 1
---
document_number: 2
&lt;/code&gt;&lt;/pre&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;&lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;h4&gt;Firmware&lt;/h4&gt; 
&lt;details&gt; 
 &lt;summary&gt;Explain what is a firmware&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;&lt;a href="https://en.wikipedia.org/wiki/Firmware"&gt;Wikipedia&lt;/a&gt;: "In computing, firmware is a specific class of computer software that provides the low-level control for a device's specific hardware. Firmware, such as the BIOS of a personal computer, may contain basic functions of a device, and may provide hardware abstraction services to higher-level software such as operating systems." &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;h2&gt;Cassandra&lt;/h2&gt; 
&lt;details&gt; 
 &lt;summary&gt;When running a cassandra cluster, how often do you need to run nodetool repair in order to keep the cluster consistent? 
  &lt;ul&gt; 
   &lt;li&gt;Within the columnFamily GC-grace Once a week&lt;/li&gt; 
   &lt;li&gt;Less than the compacted partition minimum bytes&lt;/li&gt; 
   &lt;li&gt;Depended on the compaction strategy&lt;/li&gt; 
  &lt;/ul&gt; &lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
&lt;/details&gt; 
&lt;h2&gt;HTTP&lt;/h2&gt; 
&lt;details&gt; 
 &lt;summary&gt;What is HTTP?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;&lt;a href="https://avinetworks.com/glossary/layer-7/"&gt;Avinetworks&lt;/a&gt;: HTTP stands for Hypertext Transfer Protocol. HTTP uses TCP port 80 to enable internet communication. It is part of the Application Layer (L7) in OSI Model. &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;Describe HTTP request lifecycle&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;ul&gt;
  &lt;b&gt; &lt;li&gt;Resolve host by request to DNS resolver&lt;/li&gt; &lt;li&gt;Client SYN&lt;/li&gt; &lt;li&gt;Server SYN+ACK&lt;/li&gt; &lt;li&gt;Client SYN&lt;/li&gt; &lt;li&gt;HTTP request&lt;/li&gt; &lt;li&gt;HTTP response &lt;/li&gt;&lt;/b&gt;
 &lt;/ul&gt;
&lt;/details&gt;  
&lt;details&gt; 
 &lt;summary&gt;True or False? HTTP is stateful&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;False. It doesn't maintain state for incoming request. &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;How HTTP request looks like?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;p&gt;It consists of:&lt;/p&gt; &lt;/b&gt;
 &lt;ul&gt;
  &lt;b&gt; &lt;li&gt;Request line - request type&lt;/li&gt; &lt;li&gt;Headers - content info like length, encoding, etc.&lt;/li&gt; &lt;li&gt;Body (not always included) &lt;/li&gt;&lt;/b&gt;
 &lt;/ul&gt;
&lt;/details&gt;  
&lt;details&gt; 
 &lt;summary&gt;What HTTP method types are there?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;ul&gt;
  &lt;b&gt; &lt;li&gt;GET&lt;/li&gt; &lt;li&gt;POST&lt;/li&gt; &lt;li&gt;HEAD&lt;/li&gt; &lt;li&gt;PUT&lt;/li&gt; &lt;li&gt;DELETE&lt;/li&gt; &lt;li&gt;CONNECT&lt;/li&gt; &lt;li&gt;OPTIONS&lt;/li&gt; &lt;li&gt;TRACE &lt;/li&gt;&lt;/b&gt;
 &lt;/ul&gt;
&lt;/details&gt;  
&lt;details&gt; 
 &lt;summary&gt;What HTTP response codes are there?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;ul&gt;
  &lt;b&gt; &lt;li&gt;1xx - informational&lt;/li&gt; &lt;li&gt;2xx - Success&lt;/li&gt; &lt;li&gt;3xx - Redirect&lt;/li&gt; &lt;li&gt;4xx - Error, client fault&lt;/li&gt; &lt;li&gt;5xx - Error, server fault &lt;/li&gt;&lt;/b&gt;
 &lt;/ul&gt;
&lt;/details&gt;  
&lt;details&gt; 
 &lt;summary&gt;What is HTTPS?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;p&gt;HTTPS is a secure version of the HTTP protocol used to transfer data between a web browser and a web server. It encrypts the communication using SSL/TLS encryption to ensure that the data is private and secure.&lt;/p&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;Learn more: &lt;a href="https://www.cloudflare.com/learning/ssl/why-is-http-not-secure/"&gt;https://www.cloudflare.com/learning/ssl/why-is-http-not-secure/&lt;/a&gt; &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;Explain HTTP Cookies&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;p&gt;HTTP is stateless. To share state, we can use Cookies.&lt;/p&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;TODO: explain what is actually a Cookie &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;What is HTTP Pipelining?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;You get "504 Gateway Timeout" error from an HTTP server. What does it mean?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;The server didn't receive a response from another server it communicates with in a timely manner. &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;What is a proxy?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;p&gt;A proxy is a server that acts as a middleman between a client device and a destination server. It can help improve privacy, security, and performance by hiding the client's IP address, filtering content, and caching frequently accessed data.&lt;/p&gt; &lt;/b&gt;
 &lt;ul&gt;
  &lt;b&gt; &lt;li&gt;Proxies can be used for load balancing, distributing traffic across multiple servers to help prevent server overload and improve website or application performance. They can also be used for data analysis, as they can log requests and traffic, providing useful insights into user behavior and preferences. &lt;/li&gt;&lt;/b&gt;
 &lt;/ul&gt;
&lt;/details&gt;  
&lt;details&gt; 
 &lt;summary&gt;What is a reverse proxy?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;p&gt;A reverse proxy is a type of proxy server that sits between a client and a server, but it is used to manage traffic going in the opposite direction of a traditional forward proxy. In a forward proxy, the client sends requests to the proxy server, which then forwards them to the destination server. However, in a reverse proxy, the client sends requests to the destination server, but the requests are intercepted by the reverse proxy before they reach the server.&lt;/p&gt; &lt;/b&gt;
 &lt;ul&gt;
  &lt;b&gt; &lt;li&gt;They're commonly used to improve web server performance, provide high availability and fault tolerance, and enhance security by preventing direct access to the back-end server. They are often used in large-scale web applications and high-traffic websites to manage and distribute requests to multiple servers, resulting in improved scalability and reliability. &lt;/li&gt;&lt;/b&gt;
 &lt;/ul&gt;
&lt;/details&gt;  
&lt;details&gt; 
 &lt;summary&gt;When you publish a project, you usually publish it with a license. What types of licenses are you familiar with and which one do you prefer to use?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Explain what is "X-Forwarded-For"&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;&lt;a href="https://en.wikipedia.org/wiki/X-Forwarded-For"&gt;Wikipedia&lt;/a&gt;: "The X-Forwarded-For (XFF) HTTP header field is a common method for identifying the originating IP address of a client connecting to a web server through an HTTP proxy or load balancer." &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;h4&gt;Load Balancers&lt;/h4&gt; 
&lt;details&gt; 
 &lt;summary&gt;What is a load balancer?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;A load balancer accepts (or denies) incoming network traffic from a client, and based on some criteria (application related, network, etc.) it distributes those communications out to servers (at least one). &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;Why to used a load balancer?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;ul&gt;
  &lt;b&gt; &lt;li&gt;Scalability - using a load balancer, you can possibly add more servers in the backend to handle more requests/traffic from the clients, as opposed to using one server.&lt;/li&gt; &lt;li&gt;Redundancy - if one server in the backend dies, the load balancer will keep forwarding the traffic/requests to the second server so users won't even notice one of the servers in the backend is down. &lt;/li&gt;&lt;/b&gt;
 &lt;/ul&gt;
&lt;/details&gt;  
&lt;details&gt; 
 &lt;summary&gt;What load balancer techniques/algorithms are you familiar with?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;ul&gt;
  &lt;b&gt; &lt;li&gt;Round Robin&lt;/li&gt; &lt;li&gt;Weighted Round Robin&lt;/li&gt; &lt;li&gt;Least Connection&lt;/li&gt; &lt;li&gt;Weighted Least Connection&lt;/li&gt; &lt;li&gt;Resource Based&lt;/li&gt; &lt;li&gt;Fixed Weighting&lt;/li&gt; &lt;li&gt;Weighted Response Time&lt;/li&gt; &lt;li&gt;Source IP Hash&lt;/li&gt; &lt;li&gt;URL Hash &lt;/li&gt;&lt;/b&gt;
 &lt;/ul&gt;
&lt;/details&gt;  
&lt;details&gt; 
 &lt;summary&gt;What are the drawbacks of round robin algorithm in load balancing?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;ul&gt;
  &lt;b&gt; &lt;li&gt;A simple round robin algorithm knows nothing about the load and the spec of each server it forwards the requests to. It is possible, that multiple heavy workloads requests will get to the same server while other servers will got only lightweight requests which will result in one server doing most of the work, maybe even crashing at some point because it unable to handle all the heavy workloads requests by its own.&lt;/li&gt; &lt;li&gt;Each request from the client creates a whole new session. This might be a problem for certain scenarios where you would like to perform multiple operations where the server has to know about the result of operation so basically, being sort of aware of the history it has with the client. In round robin, first request might hit server X, while second request might hit server Y and ask to continue processing the data that was processed on server X already. &lt;/li&gt;&lt;/b&gt;
 &lt;/ul&gt;
&lt;/details&gt;  
&lt;details&gt; 
 &lt;summary&gt;What is an Application Load Balancer?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;In which scenarios would you use ALB?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;At what layers a load balancer can operate?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;L4 and L7 &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;Can you perform load balancing without using a dedicated load balancer instance?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;Yes, you can use DNS for performing load balancing. &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;What is DNS load balancing? What its advantages? When would you use it?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
&lt;/details&gt; 
&lt;h4&gt;Load Balancers - Sticky Sessions&lt;/h4&gt; 
&lt;details&gt; 
 &lt;summary&gt;What are sticky sessions? What are their pros and cons?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;p&gt;Recommended read:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://access.redhat.com/solutions/900933"&gt;Red Hat Article&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;p&gt;Cons:&lt;/p&gt; &lt;/b&gt;
 &lt;ul&gt;
  &lt;b&gt; &lt;li&gt;Can cause uneven load on instance (since requests routed to the same instances) Pros:&lt;/li&gt; &lt;li&gt;Ensures in-proc sessions are not lost when a new request is created &lt;/li&gt;&lt;/b&gt;
 &lt;/ul&gt;
&lt;/details&gt;  
&lt;details&gt; 
 &lt;summary&gt;Name one use case for using sticky sessions&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;You would like to make sure the user doesn't lose the current session data. &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;What sticky sessions use for enabling the "stickiness"?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;Cookies. There are application based cookies and duration based cookies. &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;Explain application-based cookies&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;ul&gt;
  &lt;b&gt; &lt;li&gt;Generated by the application and/or the load balancer&lt;/li&gt; &lt;li&gt;Usually allows to include custom data &lt;/li&gt;&lt;/b&gt;
 &lt;/ul&gt;
&lt;/details&gt;  
&lt;details&gt; 
 &lt;summary&gt;Explain duration-based cookies&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;ul&gt;
  &lt;b&gt; &lt;li&gt;Generated by the load balancer&lt;/li&gt; &lt;li&gt;Session is not sticky anymore once the duration elapsed &lt;/li&gt;&lt;/b&gt;
 &lt;/ul&gt;
&lt;/details&gt;  
&lt;h4&gt;Load Balancers - Load Balancing Algorithms&lt;/h4&gt; 
&lt;details&gt; 
 &lt;summary&gt;Explain each of the following load balancing techniques 
  &lt;ul&gt; 
   &lt;li&gt;Round Robin&lt;/li&gt; 
   &lt;li&gt;Weighted Round Robin&lt;/li&gt; 
   &lt;li&gt;Least Connection&lt;/li&gt; 
   &lt;li&gt;Weighted Least Connection&lt;/li&gt; 
   &lt;li&gt;Resource Based&lt;/li&gt; 
   &lt;li&gt;Fixed Weighting&lt;/li&gt; 
   &lt;li&gt;Weighted Response Time&lt;/li&gt; 
   &lt;li&gt;Source IP Hash&lt;/li&gt; 
   &lt;li&gt;URL Hash&lt;/li&gt; 
  &lt;/ul&gt; &lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Explain use case for connection draining?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; To ensure that a Classic Load Balancer stops sending requests to instances that are de-registering or unhealthy, while keeping the existing connections open, use connection draining. This enables the load balancer to complete in-flight requests made to instances that are de-registering or unhealthy. &lt;p&gt;The maximum timeout value can be set between 1 and 3,600 seconds on both GCP and AWS.&lt;/p&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;&lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;h4&gt;Licenses&lt;/h4&gt; 
&lt;details&gt; 
 &lt;summary&gt;Are you familiar with "Creative Commons"? What do you know about it?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;p&gt;The Creative Commons license is a set of copyright licenses that allow creators to share their work with the public while retaining some control over how it can be used. The license was developed as a response to the restrictive standards of traditional copyright laws, which limited access of creative works. Its creators to choose the terms under which their works can be shared, distributed, and used by others. They're six main types of Creative Commons licenses, each with different levels of restrictions and permissions, the six licenses are:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Attribution (CC BY): Allows others to distribute, remix, and build upon the work, even commercially, as long as they credit the original creator.&lt;/li&gt; 
   &lt;li&gt;Attribution-ShareAlike (CC BY-SA): Allows others to remix and build upon the work, even commercially, as long as they credit the original creator and release any new creations under the same license.&lt;/li&gt; 
   &lt;li&gt;Attribution-NoDerivs (CC BY-ND): Allows others to distribute the work, even commercially, but they cannot remix or change it in any way and must credit the original creator.&lt;/li&gt; 
   &lt;li&gt;Attribution-NonCommercial (CC BY-NC): Allows others to remix and build upon the work, but they cannot use it commercially and must credit the original creator.&lt;/li&gt; 
   &lt;li&gt;Attribution-NonCommercial-ShareAlike (CC BY-NC-SA): Allows others to remix and build upon the work, but they cannot use it commercially, must credit the original creator, and must release any new creations under the same license.&lt;/li&gt; 
   &lt;li&gt;Attribution-NonCommercial-NoDerivs (CC BY-NC-ND): Allows others to download and share the work, but they cannot use it commercially, remix or change it in any way, and must credit the original creator.&lt;/li&gt; 
  &lt;/ul&gt; &lt;p&gt;Simply stated, the Creative Commons licenses are a way for creators to share their work with the public while retaining some control over how it can be used. The licenses promote creativity, innovation, and collaboration, while also respecting the rights of creators while still encouraging the responsible use of creative works.&lt;/p&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;More information: &lt;a href="https://creativecommons.org/licenses/"&gt;https://creativecommons.org/licenses/&lt;/a&gt; &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;Explain the differences between copyleft and permissive licenses&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;In Copyleft, any derivative work must use the same licensing while in permissive licensing there are no such condition. GPL-3 is an example of copyleft license while BSD is an example of permissive license. &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;h4&gt;Random&lt;/h4&gt; 
&lt;details&gt; 
 &lt;summary&gt;How a search engine works?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;How auto completion works?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;What is faster than RAM?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;CPU cache. &lt;a href="https://www.enterprisestorageforum.com/hardware/cache-memory/"&gt;Source&lt;/a&gt; &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;What is a memory leak?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;p&gt;A memory leak is a programming error that occurs when a program fails to release memory that is no longer needed, causing the program to consume increasing amounts of memory over time.&lt;/p&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;The leaks can lead to a variety of problems, including system crashes, performance degradation, and instability. Usually occurring after failed maintenance on older systems and compatibility with new components over time. &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;What is your favorite protocol?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;SSH HTTP DHCP DNS ... &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;What is Cache API?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;What is the C10K problem? Is it relevant today?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;&lt;a href="https://idiallo.com/blog/c10k-2016"&gt;https://idiallo.com/blog/c10k-2016&lt;/a&gt; &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;h2&gt;Storage&lt;/h2&gt; 
&lt;details&gt; 
 &lt;summary&gt;What types of storage are there?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;ul&gt;
  &lt;b&gt; &lt;li&gt;File&lt;/li&gt; &lt;li&gt;Block&lt;/li&gt; &lt;li&gt;Object &lt;/li&gt;&lt;/b&gt;
 &lt;/ul&gt;
&lt;/details&gt;  
&lt;details&gt; 
 &lt;summary&gt;Explain Object Storage&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;ul&gt;
  &lt;b&gt; &lt;li&gt;Data is divided to self-contained objects&lt;/li&gt; &lt;li&gt;Objects can contain metadata &lt;/li&gt;&lt;/b&gt;
 &lt;/ul&gt;
&lt;/details&gt;  
&lt;details&gt; 
 &lt;summary&gt;What are the pros and cons of object storage?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;p&gt;Pros:&lt;/p&gt; &lt;/b&gt;
 &lt;ul&gt;
  &lt;b&gt; &lt;li&gt;Usually with object storage, you pay for what you use as opposed to other storage types where you pay for the storage space you allocate&lt;/li&gt; &lt;li&gt;Scalable storage: Object storage mostly based on a model where what you use, is what you get and you can add storage as need Cons:&lt;/li&gt; &lt;li&gt;Usually performs slower than other types of storage&lt;/li&gt; &lt;li&gt;No granular modification: to change an object, you have re-create it &lt;/li&gt;&lt;/b&gt;
 &lt;/ul&gt;
&lt;/details&gt;  
&lt;details&gt; 
 &lt;summary&gt;What are some use cases for using object storage?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Explain File Storage&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;ul&gt;
  &lt;b&gt; &lt;li&gt;File Storage used for storing data in files, in a hierarchical structure&lt;/li&gt; &lt;li&gt;Some of the devices for file storage: hard drive, flash drive, cloud-based file storage&lt;/li&gt; &lt;li&gt;Files usually organized in directories &lt;/li&gt;&lt;/b&gt;
 &lt;/ul&gt;
&lt;/details&gt;  
&lt;details&gt; 
 &lt;summary&gt;What are the pros and cons of File Storage?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;p&gt;Pros:&lt;/p&gt; &lt;/b&gt;
 &lt;ul&gt;
  &lt;b&gt; &lt;li&gt;Users have full control of their own files and can run variety of operations on the files: delete, read, write and move.&lt;/li&gt; &lt;li&gt;Security mechanism allows for users to have a better control at things such as file locking &lt;/li&gt;&lt;/b&gt;
 &lt;/ul&gt;
&lt;/details&gt;  
&lt;details&gt; 
 &lt;summary&gt;What are some examples of file storage?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;Local filesystem Dropbox Google Drive &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;What types of storage devices are there?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Explain IOPS&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Explain storage throughput&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;What is a filesystem?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;p&gt;A file system is a way for computers and other electronic devices to organize and store data files. It provides a structure that helps to organize data into files and directories, making it easier to find and manage information. A file system is crucial for providing a way to store and manage data in an organized manner.&lt;/p&gt; &lt;p&gt;Commonly used filed systems: Windows:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;NTFS&lt;/li&gt; 
   &lt;li&gt;exFAT&lt;/li&gt; 
  &lt;/ul&gt; &lt;p&gt;Mac OS:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;HFS+ *APFS&lt;/li&gt; 
  &lt;/ul&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;&lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;Explain Dark Data&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Explain MBR&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
&lt;/details&gt; 
&lt;p&gt;&lt;a name="questions-you-ask"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Questions you CAN ask&lt;/h2&gt; 
&lt;p&gt;A list of questions you as a candidate can ask the interviewer during or after the interview. These are only a suggestion, use them carefully. Not every interviewer will be able to answer these (or happy to) which should be perhaps a red flag warning for your regarding working in such place but that's really up to you.&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;What do you like about working here?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;How does the company promote personal growth?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;What is the current level of technical debt you are dealing with?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;p&gt;Be careful when asking this question - all companies, regardless of size, have some level of tech debt. Phrase the question in the light that all companies have the deal with this, but you want to see the current pain points they are dealing with &lt;br /&gt;&lt;/p&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;This is a great way to figure how managers deal with unplanned work, and how good they are at setting expectations with projects. &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;Why I should NOT join you? (or 'what you don't like about working here?')&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;What was your favorite project you've worked on?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;This can give you insights in some of the cool projects a company is working on, and if you would enjoy working on projects like these. This is also a good way to see if the managers are allowing employees to learn and grow with projects outside of the normal work you'd do. &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;If you could change one thing about your day to day, what would it be?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;p&gt;Similar to the tech debt question, this helps you identify any pain points with the company. Additionally, it can be a great way to show how you'd be an asset to the team.&lt;br /&gt;&lt;/p&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;For Example, if they mention they have problem X, and you've solved that in the past, you can show how you'd be able to mitigate that problem. &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;Let's say that we agree and you hire me to this position, after X months, what do you expect that I have achieved?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;Not only this will tell you what is expected from you, it will also provide big hint on the type of work you are going to do in the first months of your job. &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;h2&gt;Testing&lt;/h2&gt; 
&lt;details&gt; 
 &lt;summary&gt;Explain white-box testing&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Explain black-box testing&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;What are unit tests?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;p&gt;Unit test are a software testing technique that involves systimatically breaking down a system and testing each individual part of the assembly. These tests are automated and can be run repeatedly to allow developers to catch edge case scenarios or bugs quickly while developing.&lt;/p&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;The main objective of unit tests are to verify each function is producing proper outputs given a set of inputs. &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;What types of tests would you run to test a web application?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Explain test harness?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;What is A/B testing?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;What is network simulation and how do you perform it?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;What types of performances tests are you familiar with?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Explain the following types of tests: 
  &lt;ul&gt; 
   &lt;li&gt;Load Testing&lt;/li&gt; 
   &lt;li&gt;Stress Testing&lt;/li&gt; 
   &lt;li&gt;Capacity Testing&lt;/li&gt; 
   &lt;li&gt;Volume Testing&lt;/li&gt; 
   &lt;li&gt;Endurance Testing&lt;/li&gt; 
  &lt;/ul&gt; &lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
&lt;/details&gt; 
&lt;h2&gt;Regex&lt;/h2&gt; 
&lt;p&gt;Given a text file, perform the following exercises&lt;/p&gt; 
&lt;h4&gt;Extract&lt;/h4&gt; 
&lt;details&gt; 
 &lt;summary&gt;Extract all the numbers&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;ul&gt;
  &lt;b&gt; &lt;li&gt;"\d+" &lt;/li&gt;&lt;/b&gt;
 &lt;/ul&gt;
&lt;/details&gt;  
&lt;details&gt; 
 &lt;summary&gt;Extract the first word of each line&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;ul&gt;
  &lt;b&gt; &lt;li&gt; &lt;p&gt;"^\w+" Bonus: extract the last word of each line&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;"\w+(?=\W*$)" (in most cases, depends on line formatting) &lt;/p&gt;&lt;/li&gt;&lt;/b&gt;
 &lt;/ul&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt;   
&lt;details&gt; 
 &lt;summary&gt;Extract all the IP addresses&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;ul&gt;
  &lt;b&gt; &lt;li&gt;"\b(?:\d{1,3}\ .){3}\d{1,3}\b" IPV4:(This format looks for 1 to 3 digit sequence 3 times) &lt;/li&gt;&lt;/b&gt;
 &lt;/ul&gt;
&lt;/details&gt;  
&lt;details&gt; 
 &lt;summary&gt;Extract dates in the format of yyyy-mm-dd or yyyy-dd-mm&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Extract email addresses&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;ul&gt;
  &lt;b&gt; &lt;li&gt;"\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\ .[A-Za-z]{2,}\b" &lt;/li&gt;&lt;/b&gt;
 &lt;/ul&gt;
&lt;/details&gt;  
&lt;h4&gt;Replace&lt;/h4&gt; 
&lt;details&gt; 
 &lt;summary&gt;Replace tabs with four spaces&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Replace 'red' with 'green'&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
&lt;/details&gt; 
&lt;h2&gt;System Design&lt;/h2&gt; 
&lt;details&gt; 
 &lt;summary&gt;Explain what a "single point of failure" is. &lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; A "single point of failure", in a system or organization, if it were to fail would cause the entire system to fail or significantly disrupt it's operation. In other words, it is a vulnerability where there is no backup in place to compensate for the failure. &lt;/b&gt;
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;What is CDN?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;CDN (Content Delivery Network) responsible for distributing content geographically. Part of it, is what is known as edge locations, aka cache proxies, that allows users to get their content quickly due to cache features and geographical distribution. &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;Explain Multi-CDN&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;In single CDN, the whole content is originated from content delivery network.&lt;br /&gt; In multi-CDN, content is distributed across multiple different CDNs, each might be on a completely different provider/cloud. &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;What are the benefits of Multi-CDN over a single CDN?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;ul&gt;
  &lt;b&gt; &lt;li&gt;Resiliency: Relying on one CDN means no redundancy. With multiple CDNs you don't need to worry about your CDN being down&lt;/li&gt; &lt;li&gt;Flexibility in Costs: Using one CDN enforces you to specific rates of that CDN. With multiple CDNs you can take into consideration using less expensive CDNs to deliver the content.&lt;/li&gt; &lt;li&gt;Performance: With Multi-CDN there is bigger potential in choosing better locations which more close to the client asking the content&lt;/li&gt; &lt;li&gt;Scale: With multiple CDNs, you can scale services to support more extreme conditions &lt;/li&gt;&lt;/b&gt;
 &lt;/ul&gt;
&lt;/details&gt;  
&lt;details&gt; 
 &lt;summary&gt;Explain "3-Tier Architecture" (including pros and cons)&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; A "3-Tier Architecture" is a pattern used in software development for designing and structuring applications. It divides the application into 3 interconnected layers: Presentation, Business logic and Data storage. PROS: * Scalability * Security * Reusability CONS: * Complexity * Performance overhead * Cost and development time &lt;/b&gt;
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Explain Mono-repo vs. Multi-repo.What are the cons and pros of each approach?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; In a Mono-repo, all the code for an organization is stored in a single,centralized repository. PROS (Mono-repo): * Unified tooling * Code Sharing CONS (Mono-repo): * Increased complexity * Slower cloning &lt;p&gt;In a Multi-repo setup, each component is stored in it's own separate repository. Each repository has it's own version control history. PROS (Multi-repo):&lt;/p&gt; &lt;/b&gt;
 &lt;ul&gt;
  &lt;b&gt; &lt;li&gt;Simpler to manage&lt;/li&gt; &lt;li&gt;Different teams and developers can work on different parts of the project independently, making parallel development easier. CONS (Multi-repo):&lt;/li&gt; &lt;li&gt;Code duplication&lt;/li&gt; &lt;li&gt;Integration challenges &lt;/li&gt;&lt;/b&gt;
 &lt;/ul&gt;
&lt;/details&gt;  
&lt;details&gt; 
 &lt;summary&gt;What are the drawbacks of monolithic architecture?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;ul&gt;
  &lt;b&gt; &lt;li&gt;Not suitable for frequent code changes and the ability to deploy new features&lt;/li&gt; &lt;li&gt;Not designed for today's infrastructure (like public clouds)&lt;/li&gt; &lt;li&gt;Scaling a team to work monolithic architecture is more challenging&lt;/li&gt; &lt;li&gt;If a single component in this architecture fails, then the entire application fails. &lt;/li&gt;&lt;/b&gt;
 &lt;/ul&gt;
&lt;/details&gt;  
&lt;details&gt; 
 &lt;summary&gt;What are the advantages of microservices architecture over a monolithic architecture?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;ul&gt;
  &lt;b&gt; &lt;li&gt;Each of the services individually fail without escalating into an application-wide outage.&lt;/li&gt; &lt;li&gt;Each service can be developed and maintained by a separate team and this team can choose its own tools and coding language &lt;/li&gt;&lt;/b&gt;
 &lt;/ul&gt;
&lt;/details&gt;  
&lt;details&gt; 
 &lt;summary&gt;What's a service mesh?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; It is a layer that facilitates communication management and control between microservices in a containerized application. It handles tasks such as load balancing, encryption, and monitoring. &lt;/b&gt;
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Explain "Loose Coupling"&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; In "Loose Coupling", components of a system communicate with each other with a little understanding of each other's internal workings. This improves scalability and ease of modification in complex systems. &lt;/b&gt;
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;What is a message queue? When is it used?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; It is a communication mechanism used in distributed systems to enable asynchronous communication between different components. It is generally used when the systems use a microservices approach. &lt;/b&gt;
&lt;/details&gt; 
&lt;h4&gt;Scalability&lt;/h4&gt; 
&lt;details&gt; 
 &lt;summary&gt;Explain Scalability&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;The ability easily grow in size and capacity based on demand and usage. &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;Explain Elasticity&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;The ability to grow but also to reduce based on what is required &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;Explain Disaster Recovery&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;Disaster recovery is the process of restoring critical business systems and data after a disruptive event. The goal is to minimize the impact and resume normal business activities quickly. This involves creating a plan, testing it, backing up critical data, and storing it in safe locations. In case of a disaster, the plan is then executed, backups are restored, and systems are hopefully brought back online. The recovery process may take hours or days depending on the damages of infrastructure. This makes business planning important, as a well-designed and tested disaster recovery plan can minimize the impact of a disaster and keep operations going. &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;Explain Fault Tolerance and High Availability&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;p&gt;Fault Tolerance - The ability to self-heal and return to normal capacity. Also the ability to withstand a failure and remain functional.&lt;/p&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;High Availability - Being able to access a resource (in some use cases, using different platforms) &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;What is the difference between high availability and Disaster Recovery?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;&lt;a href="https://www.wintellect.com/high-availability-vs-disaster-recovery"&gt;wintellect.com&lt;/a&gt;: "High availability, simply put, is eliminating single points of failure and disaster recovery is the process of getting a system back to an operational state when a system is rendered inoperative. In essence, disaster recovery picks up when high availability fails, so HA first." &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;Explain Vertical Scaling&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;Vertical Scaling is the process of adding resources to increase power of existing servers. For example, adding more CPUs, adding more RAM, etc. &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;What are the disadvantages of Vertical Scaling?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;With vertical scaling alone, the component still remains a single point of failure. In addition, it has hardware limit where if you don't have more resources, you might not be able to scale vertically. &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;Which type of cloud services usually support vertical scaling?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;Databases, cache. It's common mostly for non-distributed systems. &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;Explain Horizontal Scaling&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;Horizontal Scaling is the process of adding more resources that will be able handle requests as one unit &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;What is the disadvantage of Horizontal Scaling? What is often required in order to perform Horizontal Scaling?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;A load balancer. You can add more resources, but if you would like them to be part of the process, you have to serve them the requests/responses. Also, data inconsistency is a concern with horizontal scaling. &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;Explain in which use cases will you use vertical scaling and in which use cases you will use horizontal scaling&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Explain Resiliency and what ways are there to make a system more resilient&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Explain "Consistent Hashing"&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;How would you update each of the services in the following drawing without having app (foo.com) downtime?&lt;br /&gt; &lt;img src="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/images/design/cdn-no-downtime.png" width="300x;" height="400px;" /&gt; &lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;What is the problem with the following architecture and how would you fix it?&lt;br /&gt; &lt;img src="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/images/design/producers_consumers_issue.png" width="400x;" height="300px;" /&gt; &lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;p&gt;The load on the producers or consumers may be high which will then cause them to hang or crash.&lt;br /&gt; Instead of working in "push mode", the consumers can pull tasks only when they are ready to handle them. It can be fixed by using a streaming platform like Kafka, Kinesis, etc. This platform will make sure to handle the high load/traffic and pass tasks/messages to consumers only when the ready to get them.&lt;/p&gt; &lt;img src="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/images/design/producers_consumers_fix.png" width="300x;" height="200px;" /&gt; &lt;/b&gt;
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Users report that there is huge spike in process time when adding little bit more data to process as an input. What might be the problem?&lt;br /&gt; &lt;img src="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/images/design/input-process-output.png" width="300x;" height="200px;" /&gt; &lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;How would you scale the architecture from the previous question to hundreds of users?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
&lt;/details&gt; 
&lt;h4&gt;Cache&lt;/h4&gt; 
&lt;details&gt; 
 &lt;summary&gt;What is "cache"? In which cases would you use it?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;What is "distributed cache"?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;What is a "cache replacement policy"?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;Take a look &lt;a href="https://en.wikipedia.org/wiki/Cache_replacement_policies"&gt;here&lt;/a&gt; &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;Which cache replacement policies are you familiar with?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;You can find a list &lt;a href="https://en.wikipedia.org/wiki/Cache_replacement_policies"&gt;here&lt;/a&gt; &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;Explain the following cache policies: 
  &lt;ul&gt; 
   &lt;li&gt;FIFO&lt;/li&gt; 
   &lt;li&gt;LIFO&lt;/li&gt; 
   &lt;li&gt;LRU&lt;/li&gt;
  &lt;/ul&gt;&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt;  &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;Read about it &lt;a href="https://en.wikipedia.org/wiki/Cache_replacement_policies"&gt;here&lt;/a&gt; &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;Why not writing everything to cache instead of a database/datastore?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; Caching and databases serve different purposes and are optimized for different use cases. &lt;p&gt;Caching is used to speed up read operations by storing frequently accessed data in memory or on a fast storage medium. By keeping data close to the application, caching reduces the latency and overhead of accessing data from a slower, more distant storage system such as a database or disk.&lt;/p&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;On the other hand, databases are optimized for storing and managing persistent data. Databases are designed to handle concurrent read and write operations, enforce consistency and integrity constraints, and provide features such as indexing and querying. &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;h4&gt;Migrations&lt;/h4&gt; 
&lt;details&gt; 
 &lt;summary&gt;How you prepare for a migration? (or plan a migration)&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;p&gt;You can mention:&lt;/p&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;roll-back &amp;amp; roll-forward cut over dress rehearsals DNS redirection &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;Explain "Branch by Abstraction" technique&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
&lt;/details&gt; 
&lt;h4&gt;Design a system&lt;/h4&gt; 
&lt;details&gt; 
 &lt;summary&gt;Can you design a video streaming website?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Can you design a photo upload website?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;How would you build a URL shortener?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
&lt;/details&gt; 
&lt;h4&gt;More System Design Questions&lt;/h4&gt; 
&lt;p&gt;Additional exercises can be found in &lt;a href="https://github.com/bregman-arie/system-design-notebook"&gt;system-design-notebook repository&lt;/a&gt;.&lt;/p&gt; 
&lt;p align="center"&gt;&lt;a href="https://github.com/bregman-arie/system-design-notebook"&gt;&lt;img src="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/images/system_design_notebook.png" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Hardware&lt;/h2&gt; 
&lt;details&gt; 
 &lt;summary&gt;What is a CPU?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;A central processing unit (CPU) performs basic arithmetic, logic, controlling, and input/output (I/O) operations specified by the instructions in the program. This contrasts with external components such as main memory and I/O circuitry, and specialized processors such as graphics processing units (GPUs). &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;What is RAM?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;RAM (Random Access Memory) is the hardware in a computing device where the operating system (OS), application programs and data in current use are kept so they can be quickly reached by the device's processor. RAM is the main memory in a computer. It is much faster to read from and write to than other kinds of storage, such as a hard disk drive (HDD), solid-state drive (SSD) or optical drive. &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;What is a GPU?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; A GPU, or Graphics Processing Unit, is a specialized electronic circuit designed to expedite image and video processing for display on a computer screen. &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;&lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;What is an embedded system?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;An embedded system is a computer system - a combination of a computer processor, computer memory, and input/output peripheral devices—that has a dedicated function within a larger mechanical or electronic system. It is embedded as part of a complete device often including electrical or electronic hardware and mechanical parts. &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;Can you give an example of an embedded system?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;p&gt;A common example of an embedded system is a microwave oven's digital control panel, which is managed by a microcontroller.&lt;/p&gt; &lt;p&gt;When committed to a certain goal, Raspberry Pi can serve as an embedded system.&lt;/p&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;&lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;What types of storage are there?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;There are several types of storage, including hard disk drives (HDDs), solid-state drives (SSDs), and optical drives (CD/DVD/Blu-ray). Other types of storage include USB flash drives, memory cards, and network-attached storage (NAS). &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;What are some considerations DevOps teams should keep in mind when selecting hardware for their job?&lt;/summary&gt;
 &lt;br /&gt; 
 &lt;p&gt;Choosing the right DevOps hardware is essential for ensuring streamlined CI/CD pipelines, timely feedback loops, and consistent service availability. Here's a distilled guide on what DevOps teams should consider:&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Understanding Workloads&lt;/strong&gt;:&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;CPU&lt;/strong&gt;: Consider the need for multi-core or high-frequency CPUs based on your tasks.&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;RAM&lt;/strong&gt;: Enough memory is vital for activities like large-scale coding or intensive automation.&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;Storage&lt;/strong&gt;: Evaluate storage speed and capacity. SSDs might be preferable for swift operations.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Expandability&lt;/strong&gt;:&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Horizontal Growth&lt;/strong&gt;: Check if you can boost capacity by adding more devices.&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;Vertical Growth&lt;/strong&gt;: Determine if upgrades (like RAM, CPU) to individual machines are feasible.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Connectivity Considerations&lt;/strong&gt;:&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Data Transfer&lt;/strong&gt;: Ensure high-speed network connections for activities like code retrieval and data transfers.&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;Speed&lt;/strong&gt;: Aim for low-latency networks, particularly important for distributed tasks.&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;Backup Routes&lt;/strong&gt;: Think about having backup network routes to avoid downtimes.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Consistent Uptime&lt;/strong&gt;:&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Plan for hardware backups like RAID configurations, backup power sources, or alternate network connections to ensure continuous service.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;System Compatibility&lt;/strong&gt;:&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Make sure your hardware aligns with your software, operating system, and intended platforms.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Power Efficiency&lt;/strong&gt;:&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Hardware that uses energy efficiently can reduce costs in long-term, especially in large setups.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Safety Measures&lt;/strong&gt;:&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Explore hardware-level security features, such as TPM, to enhance protection.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Overseeing &amp;amp; Control&lt;/strong&gt;:&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Tools like ILOM can be beneficial for remote handling.&lt;/li&gt; 
    &lt;li&gt;Make sure the hardware can be seamlessly monitored for health and performance.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Budgeting&lt;/strong&gt;:&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Consider both initial expenses and long-term costs when budgeting.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Support &amp;amp; Community&lt;/strong&gt;:&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Choose hardware from reputable vendors known for reliable support.&lt;/li&gt; 
    &lt;li&gt;Check for available drivers, updates, and community discussions around the hardware.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Planning Ahead&lt;/strong&gt;:&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Opt for hardware that can cater to both present and upcoming requirements.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Operational Environment&lt;/strong&gt;:&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Temperature Control&lt;/strong&gt;: Ensure cooling systems to manage heat from high-performance units.&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;Space Management&lt;/strong&gt;: Assess hardware size considering available rack space.&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;Reliable Power&lt;/strong&gt;: Factor in consistent and backup power sources.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Cloud Coordination&lt;/strong&gt;:&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;If you're leaning towards a hybrid cloud setup, focus on how local hardware will mesh with cloud resources.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Life Span of Hardware&lt;/strong&gt;:&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Be aware of the hardware's expected duration and when you might need replacements or upgrades.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Optimized for Virtualization&lt;/strong&gt;:&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;If utilizing virtual machines or containers, ensure the hardware is compatible and optimized for such workloads.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Adaptability&lt;/strong&gt;:&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Modular hardware allows individual component replacements, offering more flexibility.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Avoiding Single Vendor Dependency&lt;/strong&gt;:&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Try to prevent reliance on a single vendor unless there are clear advantages.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Eco-Friendly Choices&lt;/strong&gt;:&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Prioritize sustainably produced hardware that's energy-efficient and environmentally responsible.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;p&gt;In essence, DevOps teams should choose hardware that is compatible with their tasks, versatile, gives good performance, and stays within their budget. Furthermore, long-term considerations such as maintenance, potential upgrades, and compatibility with impending technological shifts must be prioritized.&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;What is the role of hardware in disaster recovery planning and implementation?&lt;/summary&gt;
 &lt;br /&gt; 
 &lt;p&gt;Hardware is critical in disaster recovery (DR) solutions. While the broader scope of DR includes things like standard procedures, norms, and human roles, it's the hardware that keeps business processes running smoothly. Here's an outline of how hardware works with DR:&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Storing Data and Ensuring Its Duplication&lt;/strong&gt;:&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Backup Equipment&lt;/strong&gt;: Devices like tape storage, backup servers, and external HDDs keep essential data stored safely at a different location.&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;Disk Arrays&lt;/strong&gt;: Systems such as RAID offer a safety net. If one disk crashes, the others compensate.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Alternate Systems for Recovery&lt;/strong&gt;:&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Backup Servers&lt;/strong&gt;: These step in when the main servers falter, maintaining service flow.&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;Traffic Distributors&lt;/strong&gt;: Devices like load balancers share traffic across servers. If a server crashes, they reroute users to operational ones.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Alternate Operation Hubs&lt;/strong&gt;:&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Ready-to-use Centers&lt;/strong&gt;: Locations equipped and primed to take charge immediately when the main center fails.&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;Basic Facilities&lt;/strong&gt;: Locations with necessary equipment but lacking recent data, taking longer to activate.&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;Semi-prepped Facilities&lt;/strong&gt;: Locations somewhat prepared with select systems and data, taking a moderate duration to activate.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Power Backup Mechanisms&lt;/strong&gt;:&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Instant Power Backup&lt;/strong&gt;: Devices like UPS offer power during brief outages, ensuring no abrupt shutdowns.&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;Long-term Power Solutions&lt;/strong&gt;: Generators keep vital systems operational during extended power losses.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Networking Equipment&lt;/strong&gt;:&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Backup Internet Connections&lt;/strong&gt;: Having alternatives ensures connectivity even if one provider faces issues.&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;Secure Connection Tools&lt;/strong&gt;: Devices ensuring safe remote access, especially crucial during DR situations.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;On-site Physical Setup&lt;/strong&gt;:&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Organized Housing&lt;/strong&gt;: Structures like racks to neatly store and manage hardware.&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;Emergency Temperature Control&lt;/strong&gt;: Backup cooling mechanisms to counter server overheating in HVAC malfunctions.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Alternate Communication Channels&lt;/strong&gt;:&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Orbit-based Phones&lt;/strong&gt;: Handy when regular communication methods falter.&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;Direct Communication Devices&lt;/strong&gt;: Devices like radios useful when primary systems are down.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Protection Mechanisms&lt;/strong&gt;:&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Electronic Barriers &amp;amp; Alert Systems&lt;/strong&gt;: Devices like firewalls and intrusion detection keep DR systems safeguarded.&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;Physical Entry Control&lt;/strong&gt;: Systems controlling entry and monitoring, ensuring only cleared personnel have access.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Uniformity and Compatibility in Hardware&lt;/strong&gt;:&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;It's simpler to manage and replace equipment in emergencies if hardware configurations are consistent and compatible.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Equipment for Trials and Upkeep&lt;/strong&gt;:&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;DR drills might use specific equipment to ensure the primary systems remain unaffected. This verifies the equipment's readiness and capacity to manage real crises.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;p&gt;In summary, while software and human interventions are important in disaster recovery operations, it is the hardware that provides the underlying support. It is critical for efficient disaster recovery plans to keep this hardware resilient, duplicated, and routinely assessed.&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;What is a RAID?&lt;/summary&gt;
 &lt;br /&gt; 
 &lt;b&gt; RAID is an acronym that stands for "Redundant Array of Independent Disks." It is a technique that combines numerous hard drives into a single device known as an array in order to improve performance, expand storage capacity, and/or offer redundancy to prevent data loss. RAID levels (for example, RAID 0, RAID 1, and RAID 5) provide varied benefits in terms of performance, redundancy, and storage efficiency. &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;&lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;What is a microcontroller?&lt;/summary&gt;
 &lt;br /&gt; 
 &lt;b&gt; A microcontroller is a small integrated circuit that controls certain tasks in an embedded system. It typically includes a CPU, memory, and input/output peripherals. &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;&lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;What is a Network Interface Controller or NIC?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; A Network Interface Controller (NIC) is a piece of hardware that connects a computer to a network and allows it to communicate with other devices. &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;&lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;What is a DMA?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;Direct memory access (DMA) is a feature of computer systems that allows certain hardware subsystems to access main system memory independently of the central processing unit (CPU).DMA enables devices to share and receive data from the main memory in a computer. It does this while still allowing the CPU to perform other tasks. &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;What is a Real-Time Operating Systems?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;A real-time operating system (RTOS) is an operating system (OS) for real-time computing applications that processes data and events that have critically defined time constraints. An RTOS is distinct from a time-sharing operating system, such as Unix, which manages the sharing of system resources with a scheduler, data buffers, or fixed task prioritization in a multitasking or multiprogramming environment. Processing time requirements need to be fully understood and bound rather than just kept as a minimum. All processing must occur within the defined constraints. Real-time operating systems are event-driven and preemptive, meaning the OS can monitor the relevant priority of competing tasks, and make changes to the task priority. Event-driven systems switch between tasks based on their priorities, while time-sharing systems switch the task based on clock interrupts. &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;List of interrupt types&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;p&gt;There are six classes of interrupts possible:&lt;/p&gt; &lt;/b&gt;
 &lt;ul&gt;
  &lt;b&gt; &lt;li&gt;External&lt;/li&gt; &lt;li&gt;Machine check&lt;/li&gt; &lt;li&gt;I/O&lt;/li&gt; &lt;li&gt;Program&lt;/li&gt; &lt;li&gt;Restart&lt;/li&gt; &lt;li&gt;Supervisor call (SVC) &lt;/li&gt;&lt;/b&gt;
 &lt;/ul&gt;
&lt;/details&gt;  
&lt;h2&gt;Big Data&lt;/h2&gt; 
&lt;details&gt; 
 &lt;summary&gt;Explain what is exactly Big Data&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;p&gt;As defined by Doug Laney:&lt;/p&gt; &lt;/b&gt;
 &lt;ul&gt;
  &lt;b&gt; &lt;li&gt;Volume: Extremely large volumes of data&lt;/li&gt; &lt;li&gt;Velocity: Real time, batch, streams of data&lt;/li&gt; &lt;li&gt;Variety: Various forms of data, structured, semi-structured and unstructured&lt;/li&gt; &lt;li&gt;Veracity or Variability: Inconsistent, sometimes inaccurate, varying data &lt;/li&gt;&lt;/b&gt;
 &lt;/ul&gt;
&lt;/details&gt;  
&lt;details&gt; 
 &lt;summary&gt;What is DataOps? How is it related to DevOps?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;DataOps seeks to reduce the end-to-end cycle time of data analytics, from the origin of ideas to the literal creation of charts, graphs and models that create value. DataOps combines Agile development, DevOps and statistical process controls and applies them to data analytics. &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;What is Data Architecture?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;p&gt;An answer from &lt;a href="https://www.talend.com/resources/what-is-data-architecture"&gt;talend.com&lt;/a&gt;:&lt;/p&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;"Data architecture is the process of standardizing how organizations collect, store, transform, distribute, and use data. The goal is to deliver relevant data to people who need it, when they need it, and help them make sense of it." &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;Explain the different formats of data&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;ul&gt;
  &lt;b&gt; &lt;li&gt;Structured - data that has defined format and length (e.g. numbers, words)&lt;/li&gt; &lt;li&gt;Semi-structured - Doesn't conform to a specific format but is self-describing (e.g. XML, SWIFT)&lt;/li&gt; &lt;li&gt;Unstructured - does not follow a specific format (e.g. images, test messages) &lt;/li&gt;&lt;/b&gt;
 &lt;/ul&gt;
&lt;/details&gt;  
&lt;details&gt; 
 &lt;summary&gt;What is a Data Warehouse?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;&lt;a href="https://en.wikipedia.org/wiki/Data_warehouse"&gt;Wikipedia's explanation on Data Warehouse&lt;/a&gt; &lt;a href="https://aws.amazon.com/data-warehouse"&gt;Amazon's explanation on Data Warehouse&lt;/a&gt; &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;What is Data Lake?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;&lt;a href="https://en.wikipedia.org/wiki/Data_lake"&gt;Data Lake - Wikipedia&lt;/a&gt; &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;Can you explain the difference between a data lake and a data warehouse?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;What is "Data Versioning"? What models of "Data Versioning" are there?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;What is ETL?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
&lt;/details&gt; 
&lt;h4&gt;Apache Hadoop&lt;/h4&gt; 
&lt;details&gt; 
 &lt;summary&gt;Explain what is Hadoop&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;&lt;a href="https://en.wikipedia.org/wiki/Apache_Hadoop"&gt;Apache Hadoop - Wikipedia&lt;/a&gt; &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;Explain Hadoop YARN&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;Responsible for managing the compute resources in clusters and scheduling users' applications &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;Explain Hadoop MapReduce&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;A programming model for large-scale data processing &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;Explain Hadoop Distributed File Systems (HDFS)&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;ul&gt;
  &lt;b&gt; &lt;li&gt;Distributed file system providing high aggregate bandwidth across the cluster.&lt;/li&gt; &lt;li&gt;For a user it looks like a regular file system structure but behind the scenes it's distributed across multiple machines in a cluster&lt;/li&gt; &lt;li&gt;Typical file size is TB and it can scale and supports millions of files&lt;/li&gt; &lt;li&gt;It's fault tolerant which means it provides automatic recovery from faults&lt;/li&gt; &lt;li&gt;It's best suited for running long batch operations rather than live analysis &lt;/li&gt;&lt;/b&gt;
 &lt;/ul&gt;
&lt;/details&gt;  
&lt;details&gt; 
 &lt;summary&gt;What do you know about HDFS architecture?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;p&gt;&lt;a href="http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html"&gt;HDFS Architecture&lt;/a&gt;&lt;/p&gt; &lt;/b&gt;
 &lt;ul&gt;
  &lt;b&gt; &lt;li&gt;Master-slave architecture&lt;/li&gt; &lt;li&gt;Namenode - master, Datanodes - slaves&lt;/li&gt; &lt;li&gt;Files split into blocks&lt;/li&gt; &lt;li&gt;Blocks stored on datanodes&lt;/li&gt; &lt;li&gt;Namenode controls all metadata &lt;/li&gt;&lt;/b&gt;
 &lt;/ul&gt;
&lt;/details&gt;  
&lt;h2&gt;Ceph&lt;/h2&gt; 
&lt;details&gt; 
 &lt;summary&gt;Explain what is Ceph&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; Ceph is an Open-Source Distributed Storage System designed to provide excellent performance, reliability, and scalability. It's often used in cloud computing environments and Data Centers. &lt;/b&gt;
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;True or False? Ceph favor consistency and correctness over performances&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; True &lt;/b&gt;
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Which services or types of storage Ceph supports?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;ul&gt;
  &lt;b&gt; &lt;li&gt;Object (RGW)&lt;/li&gt; &lt;li&gt;Block (RBD)&lt;/li&gt; &lt;li&gt;File (CephFS) &lt;/li&gt;&lt;/b&gt;
 &lt;/ul&gt;
&lt;/details&gt;  
&lt;details&gt; 
 &lt;summary&gt;What is RADOS?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;ul&gt;
  &lt;b&gt; &lt;li&gt;Reliable Autonomic Distributed Object Storage&lt;/li&gt; &lt;li&gt;Provides low-level data object storage service&lt;/li&gt; &lt;li&gt;Strong Consistency&lt;/li&gt; &lt;li&gt;Simplifies design and implementation of higher layers (block, file, object) &lt;/li&gt;&lt;/b&gt;
 &lt;/ul&gt;
&lt;/details&gt;  
&lt;details&gt; 
 &lt;summary&gt;Describe RADOS software components&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;ul&gt;
  &lt;b&gt; &lt;li&gt;Monitor 
    &lt;ul&gt; 
     &lt;li&gt;Central authority for authentication, data placement, policy&lt;/li&gt; 
     &lt;li&gt;Coordination point for all other cluster components&lt;/li&gt; 
     &lt;li&gt;Protect critical cluster state with Paxos&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; &lt;li&gt;Manager 
    &lt;ul&gt; 
     &lt;li&gt;Aggregates real-time metrics (throughput, disk usage, etc.)&lt;/li&gt; 
     &lt;li&gt;Host for pluggable management functions&lt;/li&gt; 
     &lt;li&gt;1 active, 1+ standby per cluster&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; &lt;li&gt;OSD (Object Storage Daemon) 
    &lt;ul&gt; 
     &lt;li&gt;Stores data on an HDD or SSD&lt;/li&gt; 
     &lt;li&gt;Services client IO requests &lt;/li&gt;
    &lt;/ul&gt;&lt;/li&gt;&lt;/b&gt;
 &lt;/ul&gt;
&lt;/details&gt;    
&lt;details&gt; 
 &lt;summary&gt;What is the workflow of retrieving data from Ceph?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; The work flow is as follows: 
  &lt;ol&gt; 
   &lt;li&gt;The client sends a request to the ceph cluster to retrieve data:&lt;/li&gt; 
  &lt;/ol&gt; 
  &lt;blockquote&gt; 
   &lt;p&gt;&lt;strong&gt;Client could be any of the following&lt;/strong&gt;&lt;/p&gt; 
   &lt;blockquote&gt; 
    &lt;ul&gt; 
     &lt;li&gt;Ceph Block Device&lt;/li&gt; 
     &lt;li&gt;Ceph Object Gateway&lt;/li&gt; 
     &lt;li&gt;Any third party ceph client&lt;/li&gt; 
    &lt;/ul&gt; 
   &lt;/blockquote&gt; 
  &lt;/blockquote&gt; 
  &lt;ol start="2"&gt; 
   &lt;li&gt;The client retrieves the latest cluster map from the Ceph Monitor&lt;/li&gt; 
   &lt;li&gt;The client uses the CRUSH algorithm to map the object to a placement group. The placement group is then assigned to a OSD.&lt;/li&gt; 
   &lt;li&gt;Once the placement group and the OSD Daemon are determined, the client can retrieve the data from the appropriate OSD&lt;/li&gt; 
  &lt;/ol&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;&lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;What is the workflow of writing data to Ceph?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; The work flow is as follows: 
  &lt;ol&gt; 
   &lt;li&gt;The client sends a request to the ceph cluster to retrieve data&lt;/li&gt; 
   &lt;li&gt;The client retrieves the latest cluster map from the Ceph Monitor&lt;/li&gt; 
   &lt;li&gt;The client uses the CRUSH algorithm to map the object to a placement group. The placement group is then assigned to a Ceph OSD Daemon dynamically.&lt;/li&gt; 
   &lt;li&gt;The client sends the data to the primary OSD of the determined placement group. If the data is stored in an erasure-coded pool, the primary OSD is responsible for encoding the object into data chunks and coding chunks, and distributing them to the other OSDs.&lt;/li&gt; 
  &lt;/ol&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;&lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;What are "Placement Groups"?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Describe in the detail the following: Objects -&amp;gt; Pool -&amp;gt; Placement Groups -&amp;gt; OSDs&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;What is OMAP?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;What is a metadata server? How it works?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
&lt;/details&gt; 
&lt;h2&gt;Packer&lt;/h2&gt; 
&lt;details&gt; 
 &lt;summary&gt;What is Packer? What is it used for?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;In general, Packer automates machine images creation. It allows you to focus on configuration prior to deployment while making the images. This allows you start the instances much faster in most cases. &lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;Packer follows a "configuration-&amp;gt;deployment" model or "deployment-&amp;gt;configuration"?&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;p&gt;A configuration-&amp;gt;deployment which has some advantages like:&lt;/p&gt; &lt;/b&gt;
 &lt;ol&gt;
  &lt;b&gt; &lt;li&gt;Deployment Speed - you configure once prior to deployment instead of configuring every time you deploy. This allows you to start instances/services much quicker.&lt;/li&gt; &lt;li&gt;More immutable infrastructure - with configuration-&amp;gt;deployment it's not likely to have very different deployments since most of the configuration is done prior to the deployment. Issues like dependencies errors are handled/discovered prior to deployment in this model. &lt;/li&gt;&lt;/b&gt;
 &lt;/ol&gt;
&lt;/details&gt;  
&lt;h2&gt;Release&lt;/h2&gt; 
&lt;details&gt; 
 &lt;summary&gt;Explain Semantic Versioning&lt;/summary&gt;
 &lt;br /&gt;
 &lt;b&gt; &lt;p&gt;&lt;a href="https://semver.org/"&gt;This&lt;/a&gt; page explains it perfectly:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;Given a version number MAJOR.MINOR.PATCH, increment the:

MAJOR version when you make incompatible API changes
MINOR version when you add functionality in a backwards compatible manner
PATCH version when you make backwards compatible bug fixes
Additional labels for pre-release and build metadata are available as extensions to the MAJOR.MINOR.PATCH format.
&lt;/code&gt;&lt;/pre&gt; &lt;/b&gt;
 &lt;p&gt;&lt;b&gt;&lt;/b&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;h2&gt;Certificates&lt;/h2&gt; 
&lt;p&gt;If you are looking for a way to prepare for a certain exam this is the section for you. Here you'll find a list of certificates, each references to a separate file with focused questions that will help you to prepare to the exam. Good luck :)&lt;/p&gt; 
&lt;h4&gt;AWS&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/certificates/aws-cloud-practitioner.md"&gt;Cloud Practitioner&lt;/a&gt; (Latest update: 2020)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/certificates/aws-solutions-architect-associate.md"&gt;Solutions Architect Associate&lt;/a&gt; (Latest update: 2021)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/certificates/aws-cloud-sysops-associate.md"&gt;Cloud SysOps Administration Associate&lt;/a&gt; (Latest update: Oct 2022)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Azure&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/certificates/azure-fundamentals-az-900.md"&gt;AZ-900&lt;/a&gt; (Latest update: 2021)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Kubernetes&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/topics/kubernetes/CKA.md"&gt;Certified Kubernetes Administrator (CKA)&lt;/a&gt; (Latest update: 2022)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Additional DevOps and SRE Projects&lt;/h2&gt; 
&lt;p align="center"&gt;&lt;a href="https://github.com/bregman-arie/sre-checklist"&gt;&lt;img width="500px" src="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/images/sre_checklist.png" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p align="center"&gt;&lt;a href="https://github.com/bregman-arie/howtheydevops"&gt;&lt;img src="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/images/how_they_devops.png" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p align="center"&gt;&lt;a href="https://github.com/bregman-arie/devops-resources"&gt;&lt;img src="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/images/devops_resources.png" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p align="center"&gt;&lt;a href="https://github.com/bregman-arie/infraverse"&gt;&lt;img src="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/images/infraverse.png" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Credits&lt;/h2&gt; 
&lt;p&gt;Thanks to all of our amazing &lt;a href="https://github.com/bregman-arie/devops-exercises/graphs/contributors"&gt;contributors&lt;/a&gt; who make it easy for everyone to learn new things :)&lt;/p&gt; 
&lt;p&gt;Logos credits can be found &lt;a href="https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/credits.md"&gt;here&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://creativecommons.org/licenses/by-nc-nd/3.0/"&gt;&lt;img src="https://img.shields.io/badge/License-CC%20BY--NC--ND%203.0-lightgrey.svg?sanitize=true" alt="License: CC BY-NC-ND 3.0" /&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>yt-dlp/yt-dlp</title>
      <link>https://github.com/yt-dlp/yt-dlp</link>
      <description>&lt;p&gt;A feature-rich command-line audio/video downloader&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#readme"&gt;&lt;img src="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/.github/banner.svg?sanitize=true" alt="YT-DLP" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#installation" title="Installation"&gt;&lt;img src="https://img.shields.io/github/v/release/yt-dlp/yt-dlp?color=brightgreen&amp;amp;label=Download&amp;amp;style=for-the-badge" alt="Release version" /&gt;&lt;/a&gt; &lt;a href="https://pypi.org/project/yt-dlp" title="PyPI"&gt;&lt;img src="https://img.shields.io/badge/-PyPI-blue.svg?logo=pypi&amp;amp;labelColor=555555&amp;amp;style=for-the-badge" alt="PyPI" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/Collaborators.md#collaborators" title="Donate"&gt;&lt;img src="https://img.shields.io/badge/_-Donate-red.svg?logo=githubsponsors&amp;amp;labelColor=555555&amp;amp;style=for-the-badge" alt="Donate" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/H5MNcFW63r" title="Discord"&gt;&lt;img src="https://img.shields.io/discord/807245652072857610?color=blue&amp;amp;labelColor=555555&amp;amp;label=&amp;amp;logo=discord&amp;amp;style=for-the-badge" alt="Discord" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/supportedsites.md" title="Supported Sites"&gt;&lt;img src="https://img.shields.io/badge/-Supported_Sites-brightgreen.svg?style=for-the-badge" alt="Supported Sites" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/LICENSE" title="License"&gt;&lt;img src="https://img.shields.io/badge/-Unlicense-blue.svg?style=for-the-badge" alt="License: Unlicense" /&gt;&lt;/a&gt; &lt;a href="https://github.com/yt-dlp/yt-dlp/actions" title="CI Status"&gt;&lt;img src="https://img.shields.io/github/actions/workflow/status/yt-dlp/yt-dlp/core.yml?branch=master&amp;amp;label=Tests&amp;amp;style=for-the-badge" alt="CI Status" /&gt;&lt;/a&gt; &lt;a href="https://github.com/yt-dlp/yt-dlp/commits" title="Commit History"&gt;&lt;img src="https://img.shields.io/github/commit-activity/m/yt-dlp/yt-dlp?label=commits&amp;amp;style=for-the-badge" alt="Commits" /&gt;&lt;/a&gt; &lt;a href="https://github.com/yt-dlp/yt-dlp/pulse/monthly" title="Last activity"&gt;&lt;img src="https://img.shields.io/github/last-commit/yt-dlp/yt-dlp/master?label=&amp;amp;style=for-the-badge&amp;amp;display_timestamp=committer" alt="Last Commit" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;!-- MANPAGE: END EXCLUDED SECTION --&gt; 
&lt;p&gt;yt-dlp is a feature-rich command-line audio/video downloader with support for &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/supportedsites.md"&gt;thousands of sites&lt;/a&gt;. The project is a fork of &lt;a href="https://github.com/ytdl-org/youtube-dl"&gt;youtube-dl&lt;/a&gt; based on the now inactive &lt;a href="https://github.com/blackjack4494/yt-dlc"&gt;youtube-dlc&lt;/a&gt;.&lt;/p&gt; 
&lt;!-- MANPAGE: MOVE "USAGE AND OPTIONS" SECTION HERE --&gt; 
&lt;!-- MANPAGE: BEGIN EXCLUDED SECTION --&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#installation"&gt;INSTALLATION&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/wiki/Installation"&gt;Detailed instructions&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#release-files"&gt;Release Files&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#update"&gt;Update&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#dependencies"&gt;Dependencies&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#compile"&gt;Compile&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#usage-and-options"&gt;USAGE AND OPTIONS&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#general-options"&gt;General Options&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#network-options"&gt;Network Options&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#geo-restriction"&gt;Geo-restriction&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#video-selection"&gt;Video Selection&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#download-options"&gt;Download Options&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#filesystem-options"&gt;Filesystem Options&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#thumbnail-options"&gt;Thumbnail Options&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#internet-shortcut-options"&gt;Internet Shortcut Options&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#verbosity-and-simulation-options"&gt;Verbosity and Simulation Options&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#workarounds"&gt;Workarounds&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#video-format-options"&gt;Video Format Options&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#subtitle-options"&gt;Subtitle Options&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#authentication-options"&gt;Authentication Options&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#post-processing-options"&gt;Post-processing Options&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#sponsorblock-options"&gt;SponsorBlock Options&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#extractor-options"&gt;Extractor Options&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#preset-aliases"&gt;Preset Aliases&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#configuration"&gt;CONFIGURATION&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#configuration-file-encoding"&gt;Configuration file encoding&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#authentication-with-netrc"&gt;Authentication with netrc&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#notes-about-environment-variables"&gt;Notes about environment variables&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#output-template"&gt;OUTPUT TEMPLATE&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#output-template-examples"&gt;Output template examples&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#format-selection"&gt;FORMAT SELECTION&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#filtering-formats"&gt;Filtering Formats&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#sorting-formats"&gt;Sorting Formats&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#format-selection-examples"&gt;Format Selection examples&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#modifying-metadata"&gt;MODIFYING METADATA&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#modifying-metadata-examples"&gt;Modifying metadata examples&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#extractor-arguments"&gt;EXTRACTOR ARGUMENTS&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#plugins"&gt;PLUGINS&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#installing-plugins"&gt;Installing Plugins&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#developing-plugins"&gt;Developing Plugins&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#embedding-yt-dlp"&gt;EMBEDDING YT-DLP&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#embedding-examples"&gt;Embedding examples&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#changes-from-youtube-dl"&gt;CHANGES FROM YOUTUBE-DL&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#new-features"&gt;New features&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#differences-in-default-behavior"&gt;Differences in default behavior&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#deprecated-options"&gt;Deprecated options&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/CONTRIBUTING.md#contributing-to-yt-dlp"&gt;CONTRIBUTING&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/CONTRIBUTING.md#opening-an-issue"&gt;Opening an Issue&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/CONTRIBUTING.md#developer-instructions"&gt;Developer Instructions&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/wiki"&gt;WIKI&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/wiki/FAQ"&gt;FAQ&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;!-- MANPAGE: END EXCLUDED SECTION --&gt; 
&lt;h1&gt;INSTALLATION&lt;/h1&gt; 
&lt;!-- MANPAGE: BEGIN EXCLUDED SECTION --&gt; 
&lt;p&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp.exe"&gt;&lt;img src="https://img.shields.io/badge/-Windows_x64-blue.svg?style=for-the-badge&amp;amp;logo=windows" alt="Windows" /&gt;&lt;/a&gt; &lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp"&gt;&lt;img src="https://img.shields.io/badge/-Linux/BSD-red.svg?style=for-the-badge&amp;amp;logo=linux" alt="Unix" /&gt;&lt;/a&gt; &lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_macos"&gt;&lt;img src="https://img.shields.io/badge/-MacOS-lightblue.svg?style=for-the-badge&amp;amp;logo=apple" alt="MacOS" /&gt;&lt;/a&gt; &lt;a href="https://pypi.org/project/yt-dlp"&gt;&lt;img src="https://img.shields.io/badge/-PyPI-blue.svg?logo=pypi&amp;amp;labelColor=555555&amp;amp;style=for-the-badge" alt="PyPI" /&gt;&lt;/a&gt; &lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp.tar.gz"&gt;&lt;img src="https://img.shields.io/badge/-Source_tar-green.svg?style=for-the-badge" alt="Source Tarball" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#release-files"&gt;&lt;img src="https://img.shields.io/badge/-Other-grey.svg?style=for-the-badge" alt="Other variants" /&gt;&lt;/a&gt; &lt;a href="https://github.com/yt-dlp/yt-dlp/releases"&gt;&lt;img src="https://img.shields.io/badge/-All_Versions-lightgrey.svg?style=for-the-badge" alt="All versions" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;!-- MANPAGE: END EXCLUDED SECTION --&gt; 
&lt;p&gt;You can install yt-dlp using &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#release-files"&gt;the binaries&lt;/a&gt;, &lt;a href="https://pypi.org/project/yt-dlp"&gt;pip&lt;/a&gt; or one using a third-party package manager. See &lt;a href="https://github.com/yt-dlp/yt-dlp/wiki/Installation"&gt;the wiki&lt;/a&gt; for detailed instructions&lt;/p&gt; 
&lt;!-- MANPAGE: BEGIN EXCLUDED SECTION --&gt; 
&lt;h2&gt;RELEASE FILES&lt;/h2&gt; 
&lt;h4&gt;Recommended&lt;/h4&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;File&lt;/th&gt; 
   &lt;th align="left"&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp"&gt;yt-dlp&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Platform-independent &lt;a href="https://docs.python.org/3/library/zipimport.html"&gt;zipimport&lt;/a&gt; binary. Needs Python (recommended for &lt;strong&gt;Linux/BSD&lt;/strong&gt;)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp.exe"&gt;yt-dlp.exe&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Windows (Win8+) standalone x64 binary (recommended for &lt;strong&gt;Windows&lt;/strong&gt;)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_macos"&gt;yt-dlp_macos&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Universal MacOS (10.15+) standalone executable (recommended for &lt;strong&gt;MacOS&lt;/strong&gt;)&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h4&gt;Alternatives&lt;/h4&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;File&lt;/th&gt; 
   &lt;th align="left"&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_linux"&gt;yt-dlp_linux&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Linux (glibc 2.17+) standalone x86_64 binary&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_linux.zip"&gt;yt-dlp_linux.zip&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Unpackaged Linux (glibc 2.17+) x86_64 executable (no auto-update)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_linux_aarch64"&gt;yt-dlp_linux_aarch64&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Linux (glibc 2.17+) standalone aarch64 binary&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_linux_aarch64.zip"&gt;yt-dlp_linux_aarch64.zip&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Unpackaged Linux (glibc 2.17+) aarch64 executable (no auto-update)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_linux_armv7l.zip"&gt;yt-dlp_linux_armv7l.zip&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Unpackaged Linux (glibc 2.31+) armv7l executable (no auto-update)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_musllinux"&gt;yt-dlp_musllinux&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Linux (musl 1.2+) standalone x86_64 binary&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_musllinux.zip"&gt;yt-dlp_musllinux.zip&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Unpackaged Linux (musl 1.2+) x86_64 executable (no auto-update)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_musllinux_aarch64"&gt;yt-dlp_musllinux_aarch64&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Linux (musl 1.2+) standalone aarch64 binary&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_musllinux_aarch64.zip"&gt;yt-dlp_musllinux_aarch64.zip&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Unpackaged Linux (musl 1.2+) aarch64 executable (no auto-update)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_x86.exe"&gt;yt-dlp_x86.exe&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Windows (Win8+) standalone x86 (32-bit) binary&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_win_x86.zip"&gt;yt-dlp_win_x86.zip&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Unpackaged Windows (Win8+) x86 (32-bit) executable (no auto-update)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_arm64.exe"&gt;yt-dlp_arm64.exe&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Windows (Win10+) standalone ARM64 binary&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_win_arm64.zip"&gt;yt-dlp_win_arm64.zip&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Unpackaged Windows (Win10+) ARM64 executable (no auto-update)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_win.zip"&gt;yt-dlp_win.zip&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Unpackaged Windows (Win8+) x64 executable (no auto-update)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_macos.zip"&gt;yt-dlp_macos.zip&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Unpackaged MacOS (10.15+) executable (no auto-update)&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h4&gt;Misc&lt;/h4&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;File&lt;/th&gt; 
   &lt;th align="left"&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp.tar.gz"&gt;yt-dlp.tar.gz&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Source tarball&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/SHA2-512SUMS"&gt;SHA2-512SUMS&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;GNU-style SHA512 sums&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/SHA2-512SUMS.sig"&gt;SHA2-512SUMS.sig&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;GPG signature file for SHA512 sums&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/SHA2-256SUMS"&gt;SHA2-256SUMS&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;GNU-style SHA256 sums&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/SHA2-256SUMS.sig"&gt;SHA2-256SUMS.sig&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;GPG signature file for SHA256 sums&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;The public key that can be used to verify the GPG signatures is &lt;a href="https://github.com/yt-dlp/yt-dlp/raw/master/public.key"&gt;available here&lt;/a&gt; Example usage:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;curl -L https://github.com/yt-dlp/yt-dlp/raw/master/public.key | gpg --import
gpg --verify SHA2-256SUMS.sig SHA2-256SUMS
gpg --verify SHA2-512SUMS.sig SHA2-512SUMS
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Licensing&lt;/h4&gt; 
&lt;p&gt;While yt-dlp is licensed under the &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/LICENSE"&gt;Unlicense&lt;/a&gt;, many of the release files contain code from other projects with different licenses.&lt;/p&gt; 
&lt;p&gt;Most notably, the PyInstaller-bundled executables include GPLv3+ licensed code, and as such the combined work is licensed under &lt;a href="https://www.gnu.org/licenses/gpl-3.0.html"&gt;GPLv3+&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/THIRD_PARTY_LICENSES.txt"&gt;THIRD_PARTY_LICENSES.txt&lt;/a&gt; for details.&lt;/p&gt; 
&lt;p&gt;The zipimport binary (&lt;code&gt;yt-dlp&lt;/code&gt;), the source tarball (&lt;code&gt;yt-dlp.tar.gz&lt;/code&gt;), and the PyPI source distribution &amp;amp; wheel only contain code licensed under the &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/LICENSE"&gt;Unlicense&lt;/a&gt;.&lt;/p&gt; 
&lt;!-- MANPAGE: END EXCLUDED SECTION --&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: The manpages, shell completion (autocomplete) files etc. are available inside the &lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp.tar.gz"&gt;source tarball&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;UPDATE&lt;/h2&gt; 
&lt;p&gt;You can use &lt;code&gt;yt-dlp -U&lt;/code&gt; to update if you are using the &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#release-files"&gt;release binaries&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;If you &lt;a href="https://github.com/yt-dlp/yt-dlp/wiki/Installation#with-pip"&gt;installed with pip&lt;/a&gt;, simply re-run the same command that was used to install the program&lt;/p&gt; 
&lt;p&gt;For other third-party package managers, see &lt;a href="https://github.com/yt-dlp/yt-dlp/wiki/Installation#third-party-package-managers"&gt;the wiki&lt;/a&gt; or refer to their documentation&lt;/p&gt; 
&lt;p&gt;&lt;a id="update-channels"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;There are currently three release channels for binaries: &lt;code&gt;stable&lt;/code&gt;, &lt;code&gt;nightly&lt;/code&gt; and &lt;code&gt;master&lt;/code&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;stable&lt;/code&gt; is the default channel, and many of its changes have been tested by users of the &lt;code&gt;nightly&lt;/code&gt; and &lt;code&gt;master&lt;/code&gt; channels.&lt;/li&gt; 
 &lt;li&gt;The &lt;code&gt;nightly&lt;/code&gt; channel has releases scheduled to build every day around midnight UTC, for a snapshot of the project's new patches and changes. This is the &lt;strong&gt;recommended channel for regular users&lt;/strong&gt; of yt-dlp. The &lt;code&gt;nightly&lt;/code&gt; releases are available from &lt;a href="https://github.com/yt-dlp/yt-dlp-nightly-builds/releases"&gt;yt-dlp/yt-dlp-nightly-builds&lt;/a&gt; or as development releases of the &lt;code&gt;yt-dlp&lt;/code&gt; PyPI package (which can be installed with pip's &lt;code&gt;--pre&lt;/code&gt; flag).&lt;/li&gt; 
 &lt;li&gt;The &lt;code&gt;master&lt;/code&gt; channel features releases that are built after each push to the master branch, and these will have the very latest fixes and additions, but may also be more prone to regressions. They are available from &lt;a href="https://github.com/yt-dlp/yt-dlp-master-builds/releases"&gt;yt-dlp/yt-dlp-master-builds&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;When using &lt;code&gt;--update&lt;/code&gt;/&lt;code&gt;-U&lt;/code&gt;, a release binary will only update to its current channel. &lt;code&gt;--update-to CHANNEL&lt;/code&gt; can be used to switch to a different channel when a newer version is available. &lt;code&gt;--update-to [CHANNEL@]TAG&lt;/code&gt; can also be used to upgrade or downgrade to specific tags from a channel.&lt;/p&gt; 
&lt;p&gt;You may also use &lt;code&gt;--update-to &amp;lt;repository&amp;gt;&lt;/code&gt; (&lt;code&gt;&amp;lt;owner&amp;gt;/&amp;lt;repository&amp;gt;&lt;/code&gt;) to update to a channel on a completely different repository. Be careful with what repository you are updating to though, there is no verification done for binaries from different repositories.&lt;/p&gt; 
&lt;p&gt;Example usage:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;yt-dlp --update-to master&lt;/code&gt; switch to the &lt;code&gt;master&lt;/code&gt; channel and update to its latest release&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;yt-dlp --update-to stable@2023.07.06&lt;/code&gt; upgrade/downgrade to release to &lt;code&gt;stable&lt;/code&gt; channel tag &lt;code&gt;2023.07.06&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;yt-dlp --update-to 2023.10.07&lt;/code&gt; upgrade/downgrade to tag &lt;code&gt;2023.10.07&lt;/code&gt; if it exists on the current channel&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;yt-dlp --update-to example/yt-dlp@2023.09.24&lt;/code&gt; upgrade/downgrade to the release from the &lt;code&gt;example/yt-dlp&lt;/code&gt; repository, tag &lt;code&gt;2023.09.24&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Important&lt;/strong&gt;: Any user experiencing an issue with the &lt;code&gt;stable&lt;/code&gt; release should install or update to the &lt;code&gt;nightly&lt;/code&gt; release before submitting a bug report:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;# To update to nightly from stable executable/binary:
yt-dlp --update-to nightly

# To install nightly with pip:
python3 -m pip install -U --pre "yt-dlp[default]"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;When running a yt-dlp version that is older than 90 days, you will see a warning message suggesting to update to the latest version. You can suppress this warning by adding &lt;code&gt;--no-update&lt;/code&gt; to your command or configuration file.&lt;/p&gt; 
&lt;h2&gt;DEPENDENCIES&lt;/h2&gt; 
&lt;p&gt;Python versions 3.9+ (CPython) and 3.11+ (PyPy) are supported. Other versions and implementations may or may not work correctly.&lt;/p&gt; 
&lt;!-- Python 3.5+ uses VC++14 and it is already embedded in the binary created
&lt;!x-- https://www.microsoft.com/en-us/download/details.aspx?id=26999 --x&gt;
On Windows, [Microsoft Visual C++ 2010 SP1 Redistributable Package (x86)](https://download.microsoft.com/download/1/6/5/165255E7-1014-4D0A-B094-B6A430A6BFFC/vcredist_x86.exe) is also necessary to run yt-dlp. You probably already have this, but if the executable throws an error due to missing `MSVCR100.dll` you need to install it manually.
--&gt; 
&lt;p&gt;While all the other dependencies are optional, &lt;code&gt;ffmpeg&lt;/code&gt; and &lt;code&gt;ffprobe&lt;/code&gt; are highly recommended&lt;/p&gt; 
&lt;h3&gt;Strongly recommended&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://www.ffmpeg.org"&gt;&lt;strong&gt;ffmpeg&lt;/strong&gt; and &lt;strong&gt;ffprobe&lt;/strong&gt;&lt;/a&gt; - Required for &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#format-selection"&gt;merging separate video and audio files&lt;/a&gt;, as well as for various &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#post-processing-options"&gt;post-processing&lt;/a&gt; tasks. License &lt;a href="https://www.ffmpeg.org/legal.html"&gt;depends on the build&lt;/a&gt;&lt;/p&gt; &lt;p&gt;There are bugs in ffmpeg that cause various issues when used alongside yt-dlp. Since ffmpeg is such an important dependency, we provide &lt;a href="https://github.com/yt-dlp/FFmpeg-Builds#ffmpeg-static-auto-builds"&gt;custom builds&lt;/a&gt; with patches for some of these issues at &lt;a href="https://github.com/yt-dlp/FFmpeg-Builds"&gt;yt-dlp/FFmpeg-Builds&lt;/a&gt;. See &lt;a href="https://github.com/yt-dlp/FFmpeg-Builds#patches-applied"&gt;the readme&lt;/a&gt; for details on the specific issues solved by these builds&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Important&lt;/strong&gt;: What you need is ffmpeg &lt;em&gt;binary&lt;/em&gt;, &lt;strong&gt;NOT&lt;/strong&gt; &lt;a href="https://pypi.org/project/ffmpeg"&gt;the Python package of the same name&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Networking&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/certifi/python-certifi"&gt;&lt;strong&gt;certifi&lt;/strong&gt;&lt;/a&gt;* - Provides Mozilla's root certificate bundle. Licensed under &lt;a href="https://github.com/certifi/python-certifi/raw/master/LICENSE"&gt;MPLv2&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/google/brotli"&gt;&lt;strong&gt;brotli&lt;/strong&gt;&lt;/a&gt;* or &lt;a href="https://github.com/python-hyper/brotlicffi"&gt;&lt;strong&gt;brotlicffi&lt;/strong&gt;&lt;/a&gt; - &lt;a href="https://en.wikipedia.org/wiki/Brotli"&gt;Brotli&lt;/a&gt; content encoding support. Both licensed under MIT &lt;sup&gt;&lt;a href="https://github.com/google/brotli/raw/master/LICENSE"&gt;1&lt;/a&gt; &lt;a href="https://github.com/python-hyper/brotlicffi/raw/master/LICENSE"&gt;2&lt;/a&gt; &lt;/sup&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/aaugustin/websockets"&gt;&lt;strong&gt;websockets&lt;/strong&gt;&lt;/a&gt;* - For downloading over websocket. Licensed under &lt;a href="https://github.com/aaugustin/websockets/raw/main/LICENSE"&gt;BSD-3-Clause&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/psf/requests"&gt;&lt;strong&gt;requests&lt;/strong&gt;&lt;/a&gt;* - HTTP library. For HTTPS proxy and persistent connections support. Licensed under &lt;a href="https://github.com/psf/requests/raw/main/LICENSE"&gt;Apache-2.0&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Impersonation&lt;/h4&gt; 
&lt;p&gt;The following provide support for impersonating browser requests. This may be required for some sites that employ TLS fingerprinting.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/lexiforest/curl_cffi"&gt;&lt;strong&gt;curl_cffi&lt;/strong&gt;&lt;/a&gt; (recommended) - Python binding for &lt;a href="https://github.com/lexiforest/curl-impersonate"&gt;curl-impersonate&lt;/a&gt;. Provides impersonation targets for Chrome, Edge and Safari. Licensed under &lt;a href="https://github.com/lexiforest/curl_cffi/raw/main/LICENSE"&gt;MIT&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Can be installed with the &lt;code&gt;curl-cffi&lt;/code&gt; group, e.g. &lt;code&gt;pip install "yt-dlp[default,curl-cffi]"&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;Currently included in most builds &lt;em&gt;except&lt;/em&gt; &lt;code&gt;yt-dlp&lt;/code&gt; (Unix zipimport binary), &lt;code&gt;yt-dlp_x86&lt;/code&gt; (Windows 32-bit) and &lt;code&gt;yt-dlp_musllinux_aarch64&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Metadata&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/quodlibet/mutagen"&gt;&lt;strong&gt;mutagen&lt;/strong&gt;&lt;/a&gt;* - For &lt;code&gt;--embed-thumbnail&lt;/code&gt; in certain formats. Licensed under &lt;a href="https://github.com/quodlibet/mutagen/raw/master/COPYING"&gt;GPLv2+&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/wez/atomicparsley"&gt;&lt;strong&gt;AtomicParsley&lt;/strong&gt;&lt;/a&gt; - For &lt;code&gt;--embed-thumbnail&lt;/code&gt; in &lt;code&gt;mp4&lt;/code&gt;/&lt;code&gt;m4a&lt;/code&gt; files when &lt;code&gt;mutagen&lt;/code&gt;/&lt;code&gt;ffmpeg&lt;/code&gt; cannot. Licensed under &lt;a href="https://github.com/wez/atomicparsley/raw/master/COPYING"&gt;GPLv2+&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/xattr/xattr"&gt;&lt;strong&gt;xattr&lt;/strong&gt;&lt;/a&gt;, &lt;a href="https://github.com/iustin/pyxattr"&gt;&lt;strong&gt;pyxattr&lt;/strong&gt;&lt;/a&gt; or &lt;a href="http://savannah.nongnu.org/projects/attr"&gt;&lt;strong&gt;setfattr&lt;/strong&gt;&lt;/a&gt; - For writing xattr metadata (&lt;code&gt;--xattrs&lt;/code&gt;) on &lt;strong&gt;Mac&lt;/strong&gt; and &lt;strong&gt;BSD&lt;/strong&gt;. Licensed under &lt;a href="https://github.com/xattr/xattr/raw/master/LICENSE.txt"&gt;MIT&lt;/a&gt;, &lt;a href="https://github.com/iustin/pyxattr/raw/master/COPYING"&gt;LGPL2.1&lt;/a&gt; and &lt;a href="http://git.savannah.nongnu.org/cgit/attr.git/tree/doc/COPYING"&gt;GPLv2+&lt;/a&gt; respectively&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Misc&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Legrandin/pycryptodome"&gt;&lt;strong&gt;pycryptodomex&lt;/strong&gt;&lt;/a&gt;* - For decrypting AES-128 HLS streams and various other data. Licensed under &lt;a href="https://github.com/Legrandin/pycryptodome/raw/master/LICENSE.rst"&gt;BSD-2-Clause&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ariya/phantomjs"&gt;&lt;strong&gt;phantomjs&lt;/strong&gt;&lt;/a&gt; - Used in extractors where javascript needs to be run. Licensed under &lt;a href="https://github.com/ariya/phantomjs/raw/master/LICENSE.BSD"&gt;BSD-3-Clause&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mitya57/secretstorage"&gt;&lt;strong&gt;secretstorage&lt;/strong&gt;&lt;/a&gt;* - For &lt;code&gt;--cookies-from-browser&lt;/code&gt; to access the &lt;strong&gt;Gnome&lt;/strong&gt; keyring while decrypting cookies of &lt;strong&gt;Chromium&lt;/strong&gt;-based browsers on &lt;strong&gt;Linux&lt;/strong&gt;. Licensed under &lt;a href="https://github.com/mitya57/secretstorage/raw/master/LICENSE"&gt;BSD-3-Clause&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Any external downloader that you want to use with &lt;code&gt;--downloader&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Deprecated&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="http://rtmpdump.mplayerhq.hu"&gt;&lt;strong&gt;rtmpdump&lt;/strong&gt;&lt;/a&gt; - For downloading &lt;code&gt;rtmp&lt;/code&gt; streams. ffmpeg can be used instead with &lt;code&gt;--downloader ffmpeg&lt;/code&gt;. Licensed under &lt;a href="http://rtmpdump.mplayerhq.hu"&gt;GPLv2+&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://mplayerhq.hu/design7/info.html"&gt;&lt;strong&gt;mplayer&lt;/strong&gt;&lt;/a&gt; or &lt;a href="https://mpv.io"&gt;&lt;strong&gt;mpv&lt;/strong&gt;&lt;/a&gt; - For downloading &lt;code&gt;rstp&lt;/code&gt;/&lt;code&gt;mms&lt;/code&gt; streams. ffmpeg can be used instead with &lt;code&gt;--downloader ffmpeg&lt;/code&gt;. Licensed under &lt;a href="https://github.com/mpv-player/mpv/raw/master/Copyright"&gt;GPLv2+&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;To use or redistribute the dependencies, you must agree to their respective licensing terms.&lt;/p&gt; 
&lt;p&gt;The standalone release binaries are built with the Python interpreter and the packages marked with &lt;strong&gt;*&lt;/strong&gt; included.&lt;/p&gt; 
&lt;p&gt;If you do not have the necessary dependencies for a task you are attempting, yt-dlp will warn you. All the currently available dependencies are visible at the top of the &lt;code&gt;--verbose&lt;/code&gt; output&lt;/p&gt; 
&lt;h2&gt;COMPILE&lt;/h2&gt; 
&lt;h3&gt;Standalone PyInstaller Builds&lt;/h3&gt; 
&lt;p&gt;To build the standalone executable, you must have Python and &lt;code&gt;pyinstaller&lt;/code&gt; (plus any of yt-dlp's &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#dependencies"&gt;optional dependencies&lt;/a&gt; if needed). The executable will be built for the same CPU architecture as the Python used.&lt;/p&gt; 
&lt;p&gt;You can run the following commands:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;python3 devscripts/install_deps.py --include pyinstaller
python3 devscripts/make_lazy_extractors.py
python3 -m bundle.pyinstaller
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;On some systems, you may need to use &lt;code&gt;py&lt;/code&gt; or &lt;code&gt;python&lt;/code&gt; instead of &lt;code&gt;python3&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;python -m bundle.pyinstaller&lt;/code&gt; accepts any arguments that can be passed to &lt;code&gt;pyinstaller&lt;/code&gt;, such as &lt;code&gt;--onefile/-F&lt;/code&gt; or &lt;code&gt;--onedir/-D&lt;/code&gt;, which is further &lt;a href="https://pyinstaller.org/en/stable/usage.html#what-to-generate"&gt;documented here&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: Pyinstaller versions below 4.4 &lt;a href="https://github.com/pyinstaller/pyinstaller#requirements-and-tested-platforms"&gt;do not support&lt;/a&gt; Python installed from the Windows store without using a virtual environment.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Important&lt;/strong&gt;: Running &lt;code&gt;pyinstaller&lt;/code&gt; directly &lt;strong&gt;instead of&lt;/strong&gt; using &lt;code&gt;python -m bundle.pyinstaller&lt;/code&gt; is &lt;strong&gt;not&lt;/strong&gt; officially supported. This may or may not work correctly.&lt;/p&gt; 
&lt;h3&gt;Platform-independent Binary (UNIX)&lt;/h3&gt; 
&lt;p&gt;You will need the build tools &lt;code&gt;python&lt;/code&gt; (3.9+), &lt;code&gt;zip&lt;/code&gt;, &lt;code&gt;make&lt;/code&gt; (GNU), &lt;code&gt;pandoc&lt;/code&gt;* and &lt;code&gt;pytest&lt;/code&gt;*.&lt;/p&gt; 
&lt;p&gt;After installing these, simply run &lt;code&gt;make&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;You can also run &lt;code&gt;make yt-dlp&lt;/code&gt; instead to compile only the binary without updating any of the additional files. (The build tools marked with &lt;strong&gt;*&lt;/strong&gt; are not needed for this)&lt;/p&gt; 
&lt;h3&gt;Related scripts&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;devscripts/install_deps.py&lt;/code&gt;&lt;/strong&gt; - Install dependencies for yt-dlp.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;devscripts/update-version.py&lt;/code&gt;&lt;/strong&gt; - Update the version number based on the current date.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;devscripts/set-variant.py&lt;/code&gt;&lt;/strong&gt; - Set the build variant of the executable.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;devscripts/make_changelog.py&lt;/code&gt;&lt;/strong&gt; - Create a markdown changelog using short commit messages and update &lt;code&gt;CONTRIBUTORS&lt;/code&gt; file.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;devscripts/make_lazy_extractors.py&lt;/code&gt;&lt;/strong&gt; - Create lazy extractors. Running this before building the binaries (any variant) will improve their startup performance. Set the environment variable &lt;code&gt;YTDLP_NO_LAZY_EXTRACTORS&lt;/code&gt; to something nonempty to forcefully disable lazy extractor loading.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Note: See their &lt;code&gt;--help&lt;/code&gt; for more info.&lt;/p&gt; 
&lt;h3&gt;Forking the project&lt;/h3&gt; 
&lt;p&gt;If you fork the project on GitHub, you can run your fork's &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/.github/workflows/build.yml"&gt;build workflow&lt;/a&gt; to automatically build the selected version(s) as artifacts. Alternatively, you can run the &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/.github/workflows/release.yml"&gt;release workflow&lt;/a&gt; or enable the &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/.github/workflows/release-nightly.yml"&gt;nightly workflow&lt;/a&gt; to create full (pre-)releases.&lt;/p&gt; 
&lt;h1&gt;USAGE AND OPTIONS&lt;/h1&gt; 
&lt;!-- MANPAGE: BEGIN EXCLUDED SECTION --&gt; 
&lt;pre&gt;&lt;code&gt;yt-dlp [OPTIONS] [--] URL [URL...]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Tip: Use &lt;code&gt;CTRL&lt;/code&gt;+&lt;code&gt;F&lt;/code&gt; (or &lt;code&gt;Command&lt;/code&gt;+&lt;code&gt;F&lt;/code&gt;) to search by keywords&lt;/p&gt; 
&lt;!-- MANPAGE: END EXCLUDED SECTION --&gt; 
&lt;!-- Auto generated --&gt; 
&lt;h2&gt;General Options:&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;-h, --help                      Print this help text and exit
--version                       Print program version and exit
-U, --update                    Update this program to the latest version
--no-update                     Do not check for updates (default)
--update-to [CHANNEL]@[TAG]     Upgrade/downgrade to a specific version.
                                CHANNEL can be a repository as well. CHANNEL
                                and TAG default to "stable" and "latest"
                                respectively if omitted; See "UPDATE" for
                                details. Supported channels: stable,
                                nightly, master
-i, --ignore-errors             Ignore download and postprocessing errors.
                                The download will be considered successful
                                even if the postprocessing fails
--no-abort-on-error             Continue with next video on download errors;
                                e.g. to skip unavailable videos in a
                                playlist (default)
--abort-on-error                Abort downloading of further videos if an
                                error occurs (Alias: --no-ignore-errors)
--list-extractors               List all supported extractors and exit
--extractor-descriptions        Output descriptions of all supported
                                extractors and exit
--use-extractors NAMES          Extractor names to use separated by commas.
                                You can also use regexes, "all", "default"
                                and "end" (end URL matching); e.g. --ies
                                "holodex.*,end,youtube". Prefix the name
                                with a "-" to exclude it, e.g. --ies
                                default,-generic. Use --list-extractors for
                                a list of extractor names. (Alias: --ies)
--default-search PREFIX         Use this prefix for unqualified URLs. E.g.
                                "gvsearch2:python" downloads two videos from
                                google videos for the search term "python".
                                Use the value "auto" to let yt-dlp guess
                                ("auto_warning" to emit a warning when
                                guessing). "error" just throws an error. The
                                default value "fixup_error" repairs broken
                                URLs, but emits an error if this is not
                                possible instead of searching
--ignore-config                 Don't load any more configuration files
                                except those given to --config-locations.
                                For backward compatibility, if this option
                                is found inside the system configuration
                                file, the user configuration is not loaded.
                                (Alias: --no-config)
--no-config-locations           Do not load any custom configuration files
                                (default). When given inside a configuration
                                file, ignore all previous --config-locations
                                defined in the current file
--config-locations PATH         Location of the main configuration file;
                                either the path to the config or its
                                containing directory ("-" for stdin). Can be
                                used multiple times and inside other
                                configuration files
--plugin-dirs PATH              Path to an additional directory to search
                                for plugins. This option can be used
                                multiple times to add multiple directories.
                                Use "default" to search the default plugin
                                directories (default)
--no-plugin-dirs                Clear plugin directories to search,
                                including defaults and those provided by
                                previous --plugin-dirs
--flat-playlist                 Do not extract a playlist's URL result
                                entries; some entry metadata may be missing
                                and downloading may be bypassed
--no-flat-playlist              Fully extract the videos of a playlist
                                (default)
--live-from-start               Download livestreams from the start.
                                Currently experimental and only supported
                                for YouTube and Twitch
--no-live-from-start            Download livestreams from the current time
                                (default)
--wait-for-video MIN[-MAX]      Wait for scheduled streams to become
                                available. Pass the minimum number of
                                seconds (or range) to wait between retries
--no-wait-for-video             Do not wait for scheduled streams (default)
--mark-watched                  Mark videos watched (even with --simulate)
--no-mark-watched               Do not mark videos watched (default)
--color [STREAM:]POLICY         Whether to emit color codes in output,
                                optionally prefixed by the STREAM (stdout or
                                stderr) to apply the setting to. Can be one
                                of "always", "auto" (default), "never", or
                                "no_color" (use non color terminal
                                sequences). Use "auto-tty" or "no_color-tty"
                                to decide based on terminal support only.
                                Can be used multiple times
--compat-options OPTS           Options that can help keep compatibility
                                with youtube-dl or youtube-dlc
                                configurations by reverting some of the
                                changes made in yt-dlp. See "Differences in
                                default behavior" for details
--alias ALIASES OPTIONS         Create aliases for an option string. Unless
                                an alias starts with a dash "-", it is
                                prefixed with "--". Arguments are parsed
                                according to the Python string formatting
                                mini-language. E.g. --alias get-audio,-X "-S
                                aext:{0},abr -x --audio-format {0}" creates
                                options "--get-audio" and "-X" that takes an
                                argument (ARG0) and expands to "-S
                                aext:ARG0,abr -x --audio-format ARG0". All
                                defined aliases are listed in the --help
                                output. Alias options can trigger more
                                aliases; so be careful to avoid defining
                                recursive options. As a safety measure, each
                                alias may be triggered a maximum of 100
                                times. This option can be used multiple times
-t, --preset-alias PRESET       Applies a predefined set of options. e.g.
                                --preset-alias mp3. The following presets
                                are available: mp3, aac, mp4, mkv, sleep.
                                See the "Preset Aliases" section at the end
                                for more info. This option can be used
                                multiple times
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Network Options:&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;--proxy URL                     Use the specified HTTP/HTTPS/SOCKS proxy. To
                                enable SOCKS proxy, specify a proper scheme,
                                e.g. socks5://user:pass@127.0.0.1:1080/.
                                Pass in an empty string (--proxy "") for
                                direct connection
--socket-timeout SECONDS        Time to wait before giving up, in seconds
--source-address IP             Client-side IP address to bind to
--impersonate CLIENT[:OS]       Client to impersonate for requests. E.g.
                                chrome, chrome-110, chrome:windows-10. Pass
                                --impersonate="" to impersonate any client.
                                Note that forcing impersonation for all
                                requests may have a detrimental impact on
                                download speed and stability
--list-impersonate-targets      List available clients to impersonate.
-4, --force-ipv4                Make all connections via IPv4
-6, --force-ipv6                Make all connections via IPv6
--enable-file-urls              Enable file:// URLs. This is disabled by
                                default for security reasons.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Geo-restriction:&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;--geo-verification-proxy URL    Use this proxy to verify the IP address for
                                some geo-restricted sites. The default proxy
                                specified by --proxy (or none, if the option
                                is not present) is used for the actual
                                downloading
--xff VALUE                     How to fake X-Forwarded-For HTTP header to
                                try bypassing geographic restriction. One of
                                "default" (only when known to be useful),
                                "never", an IP block in CIDR notation, or a
                                two-letter ISO 3166-2 country code
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Video Selection:&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;-I, --playlist-items ITEM_SPEC  Comma separated playlist_index of the items
                                to download. You can specify a range using
                                "[START]:[STOP][:STEP]". For backward
                                compatibility, START-STOP is also supported.
                                Use negative indices to count from the right
                                and negative STEP to download in reverse
                                order. E.g. "-I 1:3,7,-5::2" used on a
                                playlist of size 15 will download the items
                                at index 1,2,3,7,11,13,15
--min-filesize SIZE             Abort download if filesize is smaller than
                                SIZE, e.g. 50k or 44.6M
--max-filesize SIZE             Abort download if filesize is larger than
                                SIZE, e.g. 50k or 44.6M
--date DATE                     Download only videos uploaded on this date.
                                The date can be "YYYYMMDD" or in the format 
                                [now|today|yesterday][-N[day|week|month|year]].
                                E.g. "--date today-2weeks" downloads only
                                videos uploaded on the same day two weeks ago
--datebefore DATE               Download only videos uploaded on or before
                                this date. The date formats accepted are the
                                same as --date
--dateafter DATE                Download only videos uploaded on or after
                                this date. The date formats accepted are the
                                same as --date
--match-filters FILTER          Generic video filter. Any "OUTPUT TEMPLATE"
                                field can be compared with a number or a
                                string using the operators defined in
                                "Filtering Formats". You can also simply
                                specify a field to match if the field is
                                present, use "!field" to check if the field
                                is not present, and "&amp;amp;" to check multiple
                                conditions. Use a "\" to escape "&amp;amp;" or
                                quotes if needed. If used multiple times,
                                the filter matches if at least one of the
                                conditions is met. E.g. --match-filters
                                !is_live --match-filters "like_count&amp;gt;?100 &amp;amp;
                                description~='(?i)\bcats \&amp;amp; dogs\b'" matches
                                only videos that are not live OR those that
                                have a like count more than 100 (or the like
                                field is not available) and also has a
                                description that contains the phrase "cats &amp;amp;
                                dogs" (caseless). Use "--match-filters -" to
                                interactively ask whether to download each
                                video
--no-match-filters              Do not use any --match-filters (default)
--break-match-filters FILTER    Same as "--match-filters" but stops the
                                download process when a video is rejected
--no-break-match-filters        Do not use any --break-match-filters (default)
--no-playlist                   Download only the video, if the URL refers
                                to a video and a playlist
--yes-playlist                  Download the playlist, if the URL refers to
                                a video and a playlist
--age-limit YEARS               Download only videos suitable for the given
                                age
--download-archive FILE         Download only videos not listed in the
                                archive file. Record the IDs of all
                                downloaded videos in it
--no-download-archive           Do not use archive file (default)
--max-downloads NUMBER          Abort after downloading NUMBER files
--break-on-existing             Stop the download process when encountering
                                a file that is in the archive supplied with
                                the --download-archive option
--no-break-on-existing          Do not stop the download process when
                                encountering a file that is in the archive
                                (default)
--break-per-input               Alters --max-downloads, --break-on-existing,
                                --break-match-filters, and autonumber to
                                reset per input URL
--no-break-per-input            --break-on-existing and similar options
                                terminates the entire download queue
--skip-playlist-after-errors N  Number of allowed failures until the rest of
                                the playlist is skipped
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Download Options:&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;-N, --concurrent-fragments N    Number of fragments of a dash/hlsnative
                                video that should be downloaded concurrently
                                (default is 1)
-r, --limit-rate RATE           Maximum download rate in bytes per second,
                                e.g. 50K or 4.2M
--throttled-rate RATE           Minimum download rate in bytes per second
                                below which throttling is assumed and the
                                video data is re-extracted, e.g. 100K
-R, --retries RETRIES           Number of retries (default is 10), or
                                "infinite"
--file-access-retries RETRIES   Number of times to retry on file access
                                error (default is 3), or "infinite"
--fragment-retries RETRIES      Number of retries for a fragment (default is
                                10), or "infinite" (DASH, hlsnative and ISM)
--retry-sleep [TYPE:]EXPR       Time to sleep between retries in seconds
                                (optionally) prefixed by the type of retry
                                (http (default), fragment, file_access,
                                extractor) to apply the sleep to. EXPR can
                                be a number, linear=START[:END[:STEP=1]] or
                                exp=START[:END[:BASE=2]]. This option can be
                                used multiple times to set the sleep for the
                                different retry types, e.g. --retry-sleep
                                linear=1::2 --retry-sleep fragment:exp=1:20
--skip-unavailable-fragments    Skip unavailable fragments for DASH,
                                hlsnative and ISM downloads (default)
                                (Alias: --no-abort-on-unavailable-fragments)
--abort-on-unavailable-fragments
                                Abort download if a fragment is unavailable
                                (Alias: --no-skip-unavailable-fragments)
--keep-fragments                Keep downloaded fragments on disk after
                                downloading is finished
--no-keep-fragments             Delete downloaded fragments after
                                downloading is finished (default)
--buffer-size SIZE              Size of download buffer, e.g. 1024 or 16K
                                (default is 1024)
--resize-buffer                 The buffer size is automatically resized
                                from an initial value of --buffer-size
                                (default)
--no-resize-buffer              Do not automatically adjust the buffer size
--http-chunk-size SIZE          Size of a chunk for chunk-based HTTP
                                downloading, e.g. 10485760 or 10M (default
                                is disabled). May be useful for bypassing
                                bandwidth throttling imposed by a webserver
                                (experimental)
--playlist-random               Download playlist videos in random order
--lazy-playlist                 Process entries in the playlist as they are
                                received. This disables n_entries,
                                --playlist-random and --playlist-reverse
--no-lazy-playlist              Process videos in the playlist only after
                                the entire playlist is parsed (default)
--hls-use-mpegts                Use the mpegts container for HLS videos;
                                allowing some players to play the video
                                while downloading, and reducing the chance
                                of file corruption if download is
                                interrupted. This is enabled by default for
                                live streams
--no-hls-use-mpegts             Do not use the mpegts container for HLS
                                videos. This is default when not downloading
                                live streams
--download-sections REGEX       Download only chapters that match the
                                regular expression. A "*" prefix denotes
                                time-range instead of chapter. Negative
                                timestamps are calculated from the end.
                                "*from-url" can be used to download between
                                the "start_time" and "end_time" extracted
                                from the URL. Needs ffmpeg. This option can
                                be used multiple times to download multiple
                                sections, e.g. --download-sections
                                "*10:15-inf" --download-sections "intro"
--downloader [PROTO:]NAME       Name or path of the external downloader to
                                use (optionally) prefixed by the protocols
                                (http, ftp, m3u8, dash, rstp, rtmp, mms) to
                                use it for. Currently supports native,
                                aria2c, axel, curl, ffmpeg, httpie, wget.
                                You can use this option multiple times to
                                set different downloaders for different
                                protocols. E.g. --downloader aria2c
                                --downloader "dash,m3u8:native" will use
                                aria2c for http/ftp downloads, and the
                                native downloader for dash/m3u8 downloads
                                (Alias: --external-downloader)
--downloader-args NAME:ARGS     Give these arguments to the external
                                downloader. Specify the downloader name and
                                the arguments separated by a colon ":". For
                                ffmpeg, arguments can be passed to different
                                positions using the same syntax as
                                --postprocessor-args. You can use this
                                option multiple times to give different
                                arguments to different downloaders (Alias:
                                --external-downloader-args)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Filesystem Options:&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;-a, --batch-file FILE           File containing URLs to download ("-" for
                                stdin), one URL per line. Lines starting
                                with "#", ";" or "]" are considered as
                                comments and ignored
--no-batch-file                 Do not read URLs from batch file (default)
-P, --paths [TYPES:]PATH        The paths where the files should be
                                downloaded. Specify the type of file and the
                                path separated by a colon ":". All the same
                                TYPES as --output are supported.
                                Additionally, you can also provide "home"
                                (default) and "temp" paths. All intermediary
                                files are first downloaded to the temp path
                                and then the final files are moved over to
                                the home path after download is finished.
                                This option is ignored if --output is an
                                absolute path
-o, --output [TYPES:]TEMPLATE   Output filename template; see "OUTPUT
                                TEMPLATE" for details
--output-na-placeholder TEXT    Placeholder for unavailable fields in
                                --output (default: "NA")
--restrict-filenames            Restrict filenames to only ASCII characters,
                                and avoid "&amp;amp;" and spaces in filenames
--no-restrict-filenames         Allow Unicode characters, "&amp;amp;" and spaces in
                                filenames (default)
--windows-filenames             Force filenames to be Windows-compatible
--no-windows-filenames          Sanitize filenames only minimally
--trim-filenames LENGTH         Limit the filename length (excluding
                                extension) to the specified number of
                                characters
-w, --no-overwrites             Do not overwrite any files
--force-overwrites              Overwrite all video and metadata files. This
                                option includes --no-continue
--no-force-overwrites           Do not overwrite the video, but overwrite
                                related files (default)
-c, --continue                  Resume partially downloaded files/fragments
                                (default)
--no-continue                   Do not resume partially downloaded
                                fragments. If the file is not fragmented,
                                restart download of the entire file
--part                          Use .part files instead of writing directly
                                into output file (default)
--no-part                       Do not use .part files - write directly into
                                output file
--mtime                         Use the Last-modified header to set the file
                                modification time
--no-mtime                      Do not use the Last-modified header to set
                                the file modification time (default)
--write-description             Write video description to a .description file
--no-write-description          Do not write video description (default)
--write-info-json               Write video metadata to a .info.json file
                                (this may contain personal information)
--no-write-info-json            Do not write video metadata (default)
--write-playlist-metafiles      Write playlist metadata in addition to the
                                video metadata when using --write-info-json,
                                --write-description etc. (default)
--no-write-playlist-metafiles   Do not write playlist metadata when using
                                --write-info-json, --write-description etc.
--clean-info-json               Remove some internal metadata such as
                                filenames from the infojson (default)
--no-clean-info-json            Write all fields to the infojson
--write-comments                Retrieve video comments to be placed in the
                                infojson. The comments are fetched even
                                without this option if the extraction is
                                known to be quick (Alias: --get-comments)
--no-write-comments             Do not retrieve video comments unless the
                                extraction is known to be quick (Alias:
                                --no-get-comments)
--load-info-json FILE           JSON file containing the video information
                                (created with the "--write-info-json" option)
--cookies FILE                  Netscape formatted file to read cookies from
                                and dump cookie jar in
--no-cookies                    Do not read/dump cookies from/to file
                                (default)
--cookies-from-browser BROWSER[+KEYRING][:PROFILE][::CONTAINER]
                                The name of the browser to load cookies
                                from. Currently supported browsers are:
                                brave, chrome, chromium, edge, firefox,
                                opera, safari, vivaldi, whale. Optionally,
                                the KEYRING used for decrypting Chromium
                                cookies on Linux, the name/path of the
                                PROFILE to load cookies from, and the
                                CONTAINER name (if Firefox) ("none" for no
                                container) can be given with their
                                respective separators. By default, all
                                containers of the most recently accessed
                                profile are used. Currently supported
                                keyrings are: basictext, gnomekeyring,
                                kwallet, kwallet5, kwallet6
--no-cookies-from-browser       Do not load cookies from browser (default)
--cache-dir DIR                 Location in the filesystem where yt-dlp can
                                store some downloaded information (such as
                                client ids and signatures) permanently. By
                                default ${XDG_CACHE_HOME}/yt-dlp
--no-cache-dir                  Disable filesystem caching
--rm-cache-dir                  Delete all filesystem cache files
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Thumbnail Options:&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;--write-thumbnail               Write thumbnail image to disk
--no-write-thumbnail            Do not write thumbnail image to disk (default)
--write-all-thumbnails          Write all thumbnail image formats to disk
--list-thumbnails               List available thumbnails of each video.
                                Simulate unless --no-simulate is used
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Internet Shortcut Options:&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;--write-link                    Write an internet shortcut file, depending
                                on the current platform (.url, .webloc or
                                .desktop). The URL may be cached by the OS
--write-url-link                Write a .url Windows internet shortcut. The
                                OS caches the URL based on the file path
--write-webloc-link             Write a .webloc macOS internet shortcut
--write-desktop-link            Write a .desktop Linux internet shortcut
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Verbosity and Simulation Options:&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;-q, --quiet                     Activate quiet mode. If used with --verbose,
                                print the log to stderr
--no-quiet                      Deactivate quiet mode. (Default)
--no-warnings                   Ignore warnings
-s, --simulate                  Do not download the video and do not write
                                anything to disk
--no-simulate                   Download the video even if printing/listing
                                options are used
--ignore-no-formats-error       Ignore "No video formats" error. Useful for
                                extracting metadata even if the videos are
                                not actually available for download
                                (experimental)
--no-ignore-no-formats-error    Throw error when no downloadable video
                                formats are found (default)
--skip-download                 Do not download the video but write all
                                related files (Alias: --no-download)
-O, --print [WHEN:]TEMPLATE     Field name or output template to print to
                                screen, optionally prefixed with when to
                                print it, separated by a ":". Supported
                                values of "WHEN" are the same as that of
                                --use-postprocessor (default: video).
                                Implies --quiet. Implies --simulate unless
                                --no-simulate or later stages of WHEN are
                                used. This option can be used multiple times
--print-to-file [WHEN:]TEMPLATE FILE
                                Append given template to the file. The
                                values of WHEN and TEMPLATE are the same as
                                that of --print. FILE uses the same syntax
                                as the output template. This option can be
                                used multiple times
-j, --dump-json                 Quiet, but print JSON information for each
                                video. Simulate unless --no-simulate is
                                used. See "OUTPUT TEMPLATE" for a
                                description of available keys
-J, --dump-single-json          Quiet, but print JSON information for each
                                URL or infojson passed. Simulate unless
                                --no-simulate is used. If the URL refers to
                                a playlist, the whole playlist information
                                is dumped in a single line
--force-write-archive           Force download archive entries to be written
                                as far as no errors occur, even if -s or
                                another simulation option is used (Alias:
                                --force-download-archive)
--newline                       Output progress bar as new lines
--no-progress                   Do not print progress bar
--progress                      Show progress bar, even if in quiet mode
--console-title                 Display progress in console titlebar
--progress-template [TYPES:]TEMPLATE
                                Template for progress outputs, optionally
                                prefixed with one of "download:" (default),
                                "download-title:" (the console title),
                                "postprocess:",  or "postprocess-title:".
                                The video's fields are accessible under the
                                "info" key and the progress attributes are
                                accessible under "progress" key. E.g.
                                --console-title --progress-template
                                "download-title:%(info.id)s-%(progress.eta)s"
--progress-delta SECONDS        Time between progress output (default: 0)
-v, --verbose                   Print various debugging information
--dump-pages                    Print downloaded pages encoded using base64
                                to debug problems (very verbose)
--write-pages                   Write downloaded intermediary pages to files
                                in the current directory to debug problems
--print-traffic                 Display sent and read HTTP traffic
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Workarounds:&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;--encoding ENCODING             Force the specified encoding (experimental)
--legacy-server-connect         Explicitly allow HTTPS connection to servers
                                that do not support RFC 5746 secure
                                renegotiation
--no-check-certificates         Suppress HTTPS certificate validation
--prefer-insecure               Use an unencrypted connection to retrieve
                                information about the video (Currently
                                supported only for YouTube)
--add-headers FIELD:VALUE       Specify a custom HTTP header and its value,
                                separated by a colon ":". You can use this
                                option multiple times
--bidi-workaround               Work around terminals that lack
                                bidirectional text support. Requires bidiv
                                or fribidi executable in PATH
--sleep-requests SECONDS        Number of seconds to sleep between requests
                                during data extraction
--sleep-interval SECONDS        Number of seconds to sleep before each
                                download. This is the minimum time to sleep
                                when used along with --max-sleep-interval
                                (Alias: --min-sleep-interval)
--max-sleep-interval SECONDS    Maximum number of seconds to sleep. Can only
                                be used along with --min-sleep-interval
--sleep-subtitles SECONDS       Number of seconds to sleep before each
                                subtitle download
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Video Format Options:&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;-f, --format FORMAT             Video format code, see "FORMAT SELECTION"
                                for more details
-S, --format-sort SORTORDER     Sort the formats by the fields given, see
                                "Sorting Formats" for more details
--format-sort-force             Force user specified sort order to have
                                precedence over all fields, see "Sorting
                                Formats" for more details (Alias: --S-force)
--no-format-sort-force          Some fields have precedence over the user
                                specified sort order (default)
--video-multistreams            Allow multiple video streams to be merged
                                into a single file
--no-video-multistreams         Only one video stream is downloaded for each
                                output file (default)
--audio-multistreams            Allow multiple audio streams to be merged
                                into a single file
--no-audio-multistreams         Only one audio stream is downloaded for each
                                output file (default)
--prefer-free-formats           Prefer video formats with free containers
                                over non-free ones of the same quality. Use
                                with "-S ext" to strictly prefer free
                                containers irrespective of quality
--no-prefer-free-formats        Don't give any special preference to free
                                containers (default)
--check-formats                 Make sure formats are selected only from
                                those that are actually downloadable
--check-all-formats             Check all formats for whether they are
                                actually downloadable
--no-check-formats              Do not check that the formats are actually
                                downloadable
-F, --list-formats              List available formats of each video.
                                Simulate unless --no-simulate is used
--merge-output-format FORMAT    Containers that may be used when merging
                                formats, separated by "/", e.g. "mp4/mkv".
                                Ignored if no merge is required. (currently
                                supported: avi, flv, mkv, mov, mp4, webm)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Subtitle Options:&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;--write-subs                    Write subtitle file
--no-write-subs                 Do not write subtitle file (default)
--write-auto-subs               Write automatically generated subtitle file
                                (Alias: --write-automatic-subs)
--no-write-auto-subs            Do not write auto-generated subtitles
                                (default) (Alias: --no-write-automatic-subs)
--list-subs                     List available subtitles of each video.
                                Simulate unless --no-simulate is used
--sub-format FORMAT             Subtitle format; accepts formats preference
                                separated by "/", e.g. "srt" or "ass/srt/best"
--sub-langs LANGS               Languages of the subtitles to download (can
                                be regex) or "all" separated by commas, e.g.
                                --sub-langs "en.*,ja" (where "en.*" is a
                                regex pattern that matches "en" followed by
                                0 or more of any character). You can prefix
                                the language code with a "-" to exclude it
                                from the requested languages, e.g. --sub-
                                langs all,-live_chat. Use --list-subs for a
                                list of available language tags
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Authentication Options:&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;-u, --username USERNAME         Login with this account ID
-p, --password PASSWORD         Account password. If this option is left
                                out, yt-dlp will ask interactively
-2, --twofactor TWOFACTOR       Two-factor authentication code
-n, --netrc                     Use .netrc authentication data
--netrc-location PATH           Location of .netrc authentication data;
                                either the path or its containing directory.
                                Defaults to ~/.netrc
--netrc-cmd NETRC_CMD           Command to execute to get the credentials
                                for an extractor.
--video-password PASSWORD       Video-specific password
--ap-mso MSO                    Adobe Pass multiple-system operator (TV
                                provider) identifier, use --ap-list-mso for
                                a list of available MSOs
--ap-username USERNAME          Multiple-system operator account login
--ap-password PASSWORD          Multiple-system operator account password.
                                If this option is left out, yt-dlp will ask
                                interactively
--ap-list-mso                   List all supported multiple-system operators
--client-certificate CERTFILE   Path to client certificate file in PEM
                                format. May include the private key
--client-certificate-key KEYFILE
                                Path to private key file for client
                                certificate
--client-certificate-password PASSWORD
                                Password for client certificate private key,
                                if encrypted. If not provided, and the key
                                is encrypted, yt-dlp will ask interactively
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Post-Processing Options:&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;-x, --extract-audio             Convert video files to audio-only files
                                (requires ffmpeg and ffprobe)
--audio-format FORMAT           Format to convert the audio to when -x is
                                used. (currently supported: best (default),
                                aac, alac, flac, m4a, mp3, opus, vorbis,
                                wav). You can specify multiple rules using
                                similar syntax as --remux-video
--audio-quality QUALITY         Specify ffmpeg audio quality to use when
                                converting the audio with -x. Insert a value
                                between 0 (best) and 10 (worst) for VBR or a
                                specific bitrate like 128K (default 5)
--remux-video FORMAT            Remux the video into another container if
                                necessary (currently supported: avi, flv,
                                gif, mkv, mov, mp4, webm, aac, aiff, alac,
                                flac, m4a, mka, mp3, ogg, opus, vorbis,
                                wav). If the target container does not
                                support the video/audio codec, remuxing will
                                fail. You can specify multiple rules; e.g.
                                "aac&amp;gt;m4a/mov&amp;gt;mp4/mkv" will remux aac to m4a,
                                mov to mp4 and anything else to mkv
--recode-video FORMAT           Re-encode the video into another format if
                                necessary. The syntax and supported formats
                                are the same as --remux-video
--postprocessor-args NAME:ARGS  Give these arguments to the postprocessors.
                                Specify the postprocessor/executable name
                                and the arguments separated by a colon ":"
                                to give the argument to the specified
                                postprocessor/executable. Supported PP are:
                                Merger, ModifyChapters, SplitChapters,
                                ExtractAudio, VideoRemuxer, VideoConvertor,
                                Metadata, EmbedSubtitle, EmbedThumbnail,
                                SubtitlesConvertor, ThumbnailsConvertor,
                                FixupStretched, FixupM4a, FixupM3u8,
                                FixupTimestamp and FixupDuration. The
                                supported executables are: AtomicParsley,
                                FFmpeg and FFprobe. You can also specify
                                "PP+EXE:ARGS" to give the arguments to the
                                specified executable only when being used by
                                the specified postprocessor. Additionally,
                                for ffmpeg/ffprobe, "_i"/"_o" can be
                                appended to the prefix optionally followed
                                by a number to pass the argument before the
                                specified input/output file, e.g. --ppa
                                "Merger+ffmpeg_i1:-v quiet". You can use
                                this option multiple times to give different
                                arguments to different postprocessors.
                                (Alias: --ppa)
-k, --keep-video                Keep the intermediate video file on disk
                                after post-processing
--no-keep-video                 Delete the intermediate video file after
                                post-processing (default)
--post-overwrites               Overwrite post-processed files (default)
--no-post-overwrites            Do not overwrite post-processed files
--embed-subs                    Embed subtitles in the video (only for mp4,
                                webm and mkv videos)
--no-embed-subs                 Do not embed subtitles (default)
--embed-thumbnail               Embed thumbnail in the video as cover art
--no-embed-thumbnail            Do not embed thumbnail (default)
--embed-metadata                Embed metadata to the video file. Also
                                embeds chapters/infojson if present unless
                                --no-embed-chapters/--no-embed-info-json are
                                used (Alias: --add-metadata)
--no-embed-metadata             Do not add metadata to file (default)
                                (Alias: --no-add-metadata)
--embed-chapters                Add chapter markers to the video file
                                (Alias: --add-chapters)
--no-embed-chapters             Do not add chapter markers (default) (Alias:
                                --no-add-chapters)
--embed-info-json               Embed the infojson as an attachment to
                                mkv/mka video files
--no-embed-info-json            Do not embed the infojson as an attachment
                                to the video file
--parse-metadata [WHEN:]FROM:TO
                                Parse additional metadata like title/artist
                                from other fields; see "MODIFYING METADATA"
                                for details. Supported values of "WHEN" are
                                the same as that of --use-postprocessor
                                (default: pre_process)
--replace-in-metadata [WHEN:]FIELDS REGEX REPLACE
                                Replace text in a metadata field using the
                                given regex. This option can be used
                                multiple times. Supported values of "WHEN"
                                are the same as that of --use-postprocessor
                                (default: pre_process)
--xattrs                        Write metadata to the video file's xattrs
                                (using Dublin Core and XDG standards)
--concat-playlist POLICY        Concatenate videos in a playlist. One of
                                "never", "always", or "multi_video"
                                (default; only when the videos form a single
                                show). All the video files must have the
                                same codecs and number of streams to be
                                concatenable. The "pl_video:" prefix can be
                                used with "--paths" and "--output" to set
                                the output filename for the concatenated
                                files. See "OUTPUT TEMPLATE" for details
--fixup POLICY                  Automatically correct known faults of the
                                file. One of never (do nothing), warn (only
                                emit a warning), detect_or_warn (the
                                default; fix the file if we can, warn
                                otherwise), force (try fixing even if the
                                file already exists)
--ffmpeg-location PATH          Location of the ffmpeg binary; either the
                                path to the binary or its containing directory
--exec [WHEN:]CMD               Execute a command, optionally prefixed with
                                when to execute it, separated by a ":".
                                Supported values of "WHEN" are the same as
                                that of --use-postprocessor (default:
                                after_move). The same syntax as the output
                                template can be used to pass any field as
                                arguments to the command. If no fields are
                                passed, %(filepath,_filename|)q is appended
                                to the end of the command. This option can
                                be used multiple times
--no-exec                       Remove any previously defined --exec
--convert-subs FORMAT           Convert the subtitles to another format
                                (currently supported: ass, lrc, srt, vtt).
                                Use "--convert-subs none" to disable
                                conversion (default) (Alias: --convert-
                                subtitles)
--convert-thumbnails FORMAT     Convert the thumbnails to another format
                                (currently supported: jpg, png, webp). You
                                can specify multiple rules using similar
                                syntax as "--remux-video". Use "--convert-
                                thumbnails none" to disable conversion
                                (default)
--split-chapters                Split video into multiple files based on
                                internal chapters. The "chapter:" prefix can
                                be used with "--paths" and "--output" to set
                                the output filename for the split files. See
                                "OUTPUT TEMPLATE" for details
--no-split-chapters             Do not split video based on chapters (default)
--remove-chapters REGEX         Remove chapters whose title matches the
                                given regular expression. The syntax is the
                                same as --download-sections. This option can
                                be used multiple times
--no-remove-chapters            Do not remove any chapters from the file
                                (default)
--force-keyframes-at-cuts       Force keyframes at cuts when
                                downloading/splitting/removing sections.
                                This is slow due to needing a re-encode, but
                                the resulting video may have fewer artifacts
                                around the cuts
--no-force-keyframes-at-cuts    Do not force keyframes around the chapters
                                when cutting/splitting (default)
--use-postprocessor NAME[:ARGS]
                                The (case-sensitive) name of plugin
                                postprocessors to be enabled, and
                                (optionally) arguments to be passed to it,
                                separated by a colon ":". ARGS are a
                                semicolon ";" delimited list of NAME=VALUE.
                                The "when" argument determines when the
                                postprocessor is invoked. It can be one of
                                "pre_process" (after video extraction),
                                "after_filter" (after video passes filter),
                                "video" (after --format; before
                                --print/--output), "before_dl" (before each
                                video download), "post_process" (after each
                                video download; default), "after_move"
                                (after moving the video file to its final
                                location), "after_video" (after downloading
                                and processing all formats of a video), or
                                "playlist" (at end of playlist). This option
                                can be used multiple times to add different
                                postprocessors
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;SponsorBlock Options:&lt;/h2&gt; 
&lt;p&gt;Make chapter entries for, or remove various segments (sponsor, introductions, etc.) from downloaded YouTube videos using the &lt;a href="https://sponsor.ajay.app"&gt;SponsorBlock API&lt;/a&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;--sponsorblock-mark CATS        SponsorBlock categories to create chapters
                                for, separated by commas. Available
                                categories are sponsor, intro, outro,
                                selfpromo, preview, filler, interaction,
                                music_offtopic, poi_highlight, chapter, all
                                and default (=all). You can prefix the
                                category with a "-" to exclude it. See [1]
                                for descriptions of the categories. E.g.
                                --sponsorblock-mark all,-preview
                                [1] https://wiki.sponsor.ajay.app/w/Segment_Categories
--sponsorblock-remove CATS      SponsorBlock categories to be removed from
                                the video file, separated by commas. If a
                                category is present in both mark and remove,
                                remove takes precedence. The syntax and
                                available categories are the same as for
                                --sponsorblock-mark except that "default"
                                refers to "all,-filler" and poi_highlight,
                                chapter are not available
--sponsorblock-chapter-title TEMPLATE
                                An output template for the title of the
                                SponsorBlock chapters created by
                                --sponsorblock-mark. The only available
                                fields are start_time, end_time, category,
                                categories, name, category_names. Defaults
                                to "[SponsorBlock]: %(category_names)l"
--no-sponsorblock               Disable both --sponsorblock-mark and
                                --sponsorblock-remove
--sponsorblock-api URL          SponsorBlock API location, defaults to
                                https://sponsor.ajay.app
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Extractor Options:&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;--extractor-retries RETRIES     Number of retries for known extractor errors
                                (default is 3), or "infinite"
--allow-dynamic-mpd             Process dynamic DASH manifests (default)
                                (Alias: --no-ignore-dynamic-mpd)
--ignore-dynamic-mpd            Do not process dynamic DASH manifests
                                (Alias: --no-allow-dynamic-mpd)
--hls-split-discontinuity       Split HLS playlists to different formats at
                                discontinuities such as ad breaks
--no-hls-split-discontinuity    Do not split HLS playlists into different
                                formats at discontinuities such as ad breaks
                                (default)
--extractor-args IE_KEY:ARGS    Pass ARGS arguments to the IE_KEY extractor.
                                See "EXTRACTOR ARGUMENTS" for details. You
                                can use this option multiple times to give
                                arguments for different extractors
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Preset Aliases:&lt;/h2&gt; 
&lt;p&gt;Predefined aliases for convenience and ease of use. Note that future versions of yt-dlp may add or adjust presets, but the existing preset names will not be changed or removed&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;-t mp3                          -f 'ba[acodec^=mp3]/ba/b' -x --audio-format
                                mp3

-t aac                          -f
                                'ba[acodec^=aac]/ba[acodec^=mp4a.40.]/ba/b'
                                -x --audio-format aac

-t mp4                          --merge-output-format mp4 --remux-video mp4
                                -S vcodec:h264,lang,quality,res,fps,hdr:12,a
                                codec:aac

-t mkv                          --merge-output-format mkv --remux-video mkv

-t sleep                        --sleep-subtitles 5 --sleep-requests 0.75
                                --sleep-interval 10 --max-sleep-interval 20
&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;CONFIGURATION&lt;/h1&gt; 
&lt;p&gt;You can configure yt-dlp by placing any supported command line option in a configuration file. The configuration is loaded from the following locations:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Main Configuration&lt;/strong&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;The file given to &lt;code&gt;--config-location&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Portable Configuration&lt;/strong&gt;: (Recommended for portable installations)&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;If using a binary, &lt;code&gt;yt-dlp.conf&lt;/code&gt; in the same directory as the binary&lt;/li&gt; 
   &lt;li&gt;If running from source-code, &lt;code&gt;yt-dlp.conf&lt;/code&gt; in the parent directory of &lt;code&gt;yt_dlp&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Home Configuration&lt;/strong&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;yt-dlp.conf&lt;/code&gt; in the home path given to &lt;code&gt;-P&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;If &lt;code&gt;-P&lt;/code&gt; is not given, the current directory is searched&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;User Configuration&lt;/strong&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;${XDG_CONFIG_HOME}/yt-dlp.conf&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;${XDG_CONFIG_HOME}/yt-dlp/config&lt;/code&gt; (recommended on Linux/macOS)&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;${XDG_CONFIG_HOME}/yt-dlp/config.txt&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;${APPDATA}/yt-dlp.conf&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;${APPDATA}/yt-dlp/config&lt;/code&gt; (recommended on Windows)&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;${APPDATA}/yt-dlp/config.txt&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;~/yt-dlp.conf&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;~/yt-dlp.conf.txt&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;~/.yt-dlp/config&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;~/.yt-dlp/config.txt&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;p&gt;See also: &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#notes-about-environment-variables"&gt;Notes about environment variables&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;System Configuration&lt;/strong&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;/etc/yt-dlp.conf&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;/etc/yt-dlp/config&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;/etc/yt-dlp/config.txt&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;E.g. with the following configuration file, yt-dlp will always extract the audio, copy the mtime, use a proxy and save all videos under &lt;code&gt;YouTube&lt;/code&gt; directory in your home directory:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;# Lines starting with # are comments

# Always extract audio
-x

# Copy the mtime
--mtime

# Use this proxy
--proxy 127.0.0.1:3128

# Save all videos under YouTube directory in your home directory
-o ~/YouTube/%(title)s.%(ext)s
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: Options in a configuration file are just the same options aka switches used in regular command line calls; thus there &lt;strong&gt;must be no whitespace&lt;/strong&gt; after &lt;code&gt;-&lt;/code&gt; or &lt;code&gt;--&lt;/code&gt;, e.g. &lt;code&gt;-o&lt;/code&gt; or &lt;code&gt;--proxy&lt;/code&gt; but not &lt;code&gt;- o&lt;/code&gt; or &lt;code&gt;-- proxy&lt;/code&gt;. They must also be quoted when necessary, as if it were a UNIX shell.&lt;/p&gt; 
&lt;p&gt;You can use &lt;code&gt;--ignore-config&lt;/code&gt; if you want to disable all configuration files for a particular yt-dlp run. If &lt;code&gt;--ignore-config&lt;/code&gt; is found inside any configuration file, no further configuration will be loaded. For example, having the option in the portable configuration file prevents loading of home, user, and system configurations. Additionally, (for backward compatibility) if &lt;code&gt;--ignore-config&lt;/code&gt; is found inside the system configuration file, the user configuration is not loaded.&lt;/p&gt; 
&lt;h3&gt;Configuration file encoding&lt;/h3&gt; 
&lt;p&gt;The configuration files are decoded according to the UTF BOM if present, and in the encoding from system locale otherwise.&lt;/p&gt; 
&lt;p&gt;If you want your file to be decoded differently, add &lt;code&gt;# coding: ENCODING&lt;/code&gt; to the beginning of the file (e.g. &lt;code&gt;# coding: shift-jis&lt;/code&gt;). There must be no characters before that, even spaces or BOM.&lt;/p&gt; 
&lt;h3&gt;Authentication with netrc&lt;/h3&gt; 
&lt;p&gt;You may also want to configure automatic credentials storage for extractors that support authentication (by providing login and password with &lt;code&gt;--username&lt;/code&gt; and &lt;code&gt;--password&lt;/code&gt;) in order not to pass credentials as command line arguments on every yt-dlp execution and prevent tracking plain text passwords in the shell command history. You can achieve this using a &lt;a href="https://stackoverflow.com/tags/.netrc/info"&gt;&lt;code&gt;.netrc&lt;/code&gt; file&lt;/a&gt; on a per-extractor basis. For that, you will need to create a &lt;code&gt;.netrc&lt;/code&gt; file in &lt;code&gt;--netrc-location&lt;/code&gt; and restrict permissions to read/write by only you:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;touch ${HOME}/.netrc
chmod a-rwx,u+rw ${HOME}/.netrc
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;After that, you can add credentials for an extractor in the following format, where &lt;em&gt;extractor&lt;/em&gt; is the name of the extractor in lowercase:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;machine &amp;lt;extractor&amp;gt; login &amp;lt;username&amp;gt; password &amp;lt;password&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;E.g.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;machine youtube login myaccount@gmail.com password my_youtube_password
machine twitch login my_twitch_account_name password my_twitch_password
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To activate authentication with the &lt;code&gt;.netrc&lt;/code&gt; file you should pass &lt;code&gt;--netrc&lt;/code&gt; to yt-dlp or place it in the &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#configuration"&gt;configuration file&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;The default location of the .netrc file is &lt;code&gt;~&lt;/code&gt; (see below).&lt;/p&gt; 
&lt;p&gt;As an alternative to using the &lt;code&gt;.netrc&lt;/code&gt; file, which has the disadvantage of keeping your passwords in a plain text file, you can configure a custom shell command to provide the credentials for an extractor. This is done by providing the &lt;code&gt;--netrc-cmd&lt;/code&gt; parameter, it shall output the credentials in the netrc format and return &lt;code&gt;0&lt;/code&gt; on success, other values will be treated as an error. &lt;code&gt;{}&lt;/code&gt; in the command will be replaced by the name of the extractor to make it possible to select the credentials for the right extractor.&lt;/p&gt; 
&lt;p&gt;E.g. To use an encrypted &lt;code&gt;.netrc&lt;/code&gt; file stored as &lt;code&gt;.authinfo.gpg&lt;/code&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;yt-dlp --netrc-cmd 'gpg --decrypt ~/.authinfo.gpg' 'https://www.youtube.com/watch?v=BaW_jenozKc'
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Notes about environment variables&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Environment variables are normally specified as &lt;code&gt;${VARIABLE}&lt;/code&gt;/&lt;code&gt;$VARIABLE&lt;/code&gt; on UNIX and &lt;code&gt;%VARIABLE%&lt;/code&gt; on Windows; but is always shown as &lt;code&gt;${VARIABLE}&lt;/code&gt; in this documentation&lt;/li&gt; 
 &lt;li&gt;yt-dlp also allows using UNIX-style variables on Windows for path-like options; e.g. &lt;code&gt;--output&lt;/code&gt;, &lt;code&gt;--config-location&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;If unset, &lt;code&gt;${XDG_CONFIG_HOME}&lt;/code&gt; defaults to &lt;code&gt;~/.config&lt;/code&gt; and &lt;code&gt;${XDG_CACHE_HOME}&lt;/code&gt; to &lt;code&gt;~/.cache&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;On Windows, &lt;code&gt;~&lt;/code&gt; points to &lt;code&gt;${HOME}&lt;/code&gt; if present; or, &lt;code&gt;${USERPROFILE}&lt;/code&gt; or &lt;code&gt;${HOMEDRIVE}${HOMEPATH}&lt;/code&gt; otherwise&lt;/li&gt; 
 &lt;li&gt;On Windows, &lt;code&gt;${USERPROFILE}&lt;/code&gt; generally points to &lt;code&gt;C:\Users\&amp;lt;user name&amp;gt;&lt;/code&gt; and &lt;code&gt;${APPDATA}&lt;/code&gt; to &lt;code&gt;${USERPROFILE}\AppData\Roaming&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;OUTPUT TEMPLATE&lt;/h1&gt; 
&lt;p&gt;The &lt;code&gt;-o&lt;/code&gt; option is used to indicate a template for the output file names while &lt;code&gt;-P&lt;/code&gt; option is used to specify the path each type of file should be saved to.&lt;/p&gt; 
&lt;!-- MANPAGE: BEGIN EXCLUDED SECTION --&gt; 
&lt;p&gt;&lt;strong&gt;tl;dr:&lt;/strong&gt; &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#output-template-examples"&gt;navigate me to examples&lt;/a&gt;.&lt;/p&gt; 
&lt;!-- MANPAGE: END EXCLUDED SECTION --&gt; 
&lt;p&gt;The simplest usage of &lt;code&gt;-o&lt;/code&gt; is not to set any template arguments when downloading a single file, like in &lt;code&gt;yt-dlp -o funny_video.flv "https://some/video"&lt;/code&gt; (hard-coding file extension like this is &lt;em&gt;not&lt;/em&gt; recommended and could break some post-processing).&lt;/p&gt; 
&lt;p&gt;It may however also contain special sequences that will be replaced when downloading each video. The special sequences may be formatted according to &lt;a href="https://docs.python.org/3/library/stdtypes.html#printf-style-string-formatting"&gt;Python string formatting operations&lt;/a&gt;, e.g. &lt;code&gt;%(NAME)s&lt;/code&gt; or &lt;code&gt;%(NAME)05d&lt;/code&gt;. To clarify, that is a percent symbol followed by a name in parentheses, followed by formatting operations.&lt;/p&gt; 
&lt;p&gt;The field names themselves (the part inside the parenthesis) can also have some special formatting:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Object traversal&lt;/strong&gt;: The dictionaries and lists available in metadata can be traversed by using a dot &lt;code&gt;.&lt;/code&gt; separator; e.g. &lt;code&gt;%(tags.0)s&lt;/code&gt;, &lt;code&gt;%(subtitles.en.-1.ext)s&lt;/code&gt;. You can do Python slicing with colon &lt;code&gt;:&lt;/code&gt;; E.g. &lt;code&gt;%(id.3:7)s&lt;/code&gt;, &lt;code&gt;%(id.6:2:-1)s&lt;/code&gt;, &lt;code&gt;%(formats.:.format_id)s&lt;/code&gt;. Curly braces &lt;code&gt;{}&lt;/code&gt; can be used to build dictionaries with only specific keys; e.g. &lt;code&gt;%(formats.:.{format_id,height})#j&lt;/code&gt;. An empty field name &lt;code&gt;%()s&lt;/code&gt; refers to the entire infodict; e.g. &lt;code&gt;%(.{id,title})s&lt;/code&gt;. Note that all the fields that become available using this method are not listed below. Use &lt;code&gt;-j&lt;/code&gt; to see such fields&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Arithmetic&lt;/strong&gt;: Simple arithmetic can be done on numeric fields using &lt;code&gt;+&lt;/code&gt;, &lt;code&gt;-&lt;/code&gt; and &lt;code&gt;*&lt;/code&gt;. E.g. &lt;code&gt;%(playlist_index+10)03d&lt;/code&gt;, &lt;code&gt;%(n_entries+1-playlist_index)d&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Date/time Formatting&lt;/strong&gt;: Date/time fields can be formatted according to &lt;a href="https://docs.python.org/3/library/datetime.html#strftime-and-strptime-format-codes"&gt;strftime formatting&lt;/a&gt; by specifying it separated from the field name using a &lt;code&gt;&amp;gt;&lt;/code&gt;. E.g. &lt;code&gt;%(duration&amp;gt;%H-%M-%S)s&lt;/code&gt;, &lt;code&gt;%(upload_date&amp;gt;%Y-%m-%d)s&lt;/code&gt;, &lt;code&gt;%(epoch-3600&amp;gt;%H-%M-%S)s&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Alternatives&lt;/strong&gt;: Alternate fields can be specified separated with a &lt;code&gt;,&lt;/code&gt;. E.g. &lt;code&gt;%(release_date&amp;gt;%Y,upload_date&amp;gt;%Y|Unknown)s&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Replacement&lt;/strong&gt;: A replacement value can be specified using a &lt;code&gt;&amp;amp;&lt;/code&gt; separator according to the &lt;a href="https://docs.python.org/3/library/string.html#format-specification-mini-language"&gt;&lt;code&gt;str.format&lt;/code&gt; mini-language&lt;/a&gt;. If the field is &lt;em&gt;not&lt;/em&gt; empty, this replacement value will be used instead of the actual field content. This is done after alternate fields are considered; thus the replacement is used if &lt;em&gt;any&lt;/em&gt; of the alternative fields is &lt;em&gt;not&lt;/em&gt; empty. E.g. &lt;code&gt;%(chapters&amp;amp;has chapters|no chapters)s&lt;/code&gt;, &lt;code&gt;%(title&amp;amp;TITLE={:&amp;gt;20}|NO TITLE)s&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Default&lt;/strong&gt;: A literal default value can be specified for when the field is empty using a &lt;code&gt;|&lt;/code&gt; separator. This overrides &lt;code&gt;--output-na-placeholder&lt;/code&gt;. E.g. &lt;code&gt;%(uploader|Unknown)s&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;More Conversions&lt;/strong&gt;: In addition to the normal format types &lt;code&gt;diouxXeEfFgGcrs&lt;/code&gt;, yt-dlp additionally supports converting to &lt;code&gt;B&lt;/code&gt; = &lt;strong&gt;B&lt;/strong&gt;ytes, &lt;code&gt;j&lt;/code&gt; = &lt;strong&gt;j&lt;/strong&gt;son (flag &lt;code&gt;#&lt;/code&gt; for pretty-printing, &lt;code&gt;+&lt;/code&gt; for Unicode), &lt;code&gt;h&lt;/code&gt; = HTML escaping, &lt;code&gt;l&lt;/code&gt; = a comma separated &lt;strong&gt;l&lt;/strong&gt;ist (flag &lt;code&gt;#&lt;/code&gt; for &lt;code&gt;\n&lt;/code&gt; newline-separated), &lt;code&gt;q&lt;/code&gt; = a string &lt;strong&gt;q&lt;/strong&gt;uoted for the terminal (flag &lt;code&gt;#&lt;/code&gt; to split a list into different arguments), &lt;code&gt;D&lt;/code&gt; = add &lt;strong&gt;D&lt;/strong&gt;ecimal suffixes (e.g. 10M) (flag &lt;code&gt;#&lt;/code&gt; to use 1024 as factor), and &lt;code&gt;S&lt;/code&gt; = &lt;strong&gt;S&lt;/strong&gt;anitize as filename (flag &lt;code&gt;#&lt;/code&gt; for restricted)&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Unicode normalization&lt;/strong&gt;: The format type &lt;code&gt;U&lt;/code&gt; can be used for NFC &lt;a href="https://docs.python.org/3/library/unicodedata.html#unicodedata.normalize"&gt;Unicode normalization&lt;/a&gt;. The alternate form flag (&lt;code&gt;#&lt;/code&gt;) changes the normalization to NFD and the conversion flag &lt;code&gt;+&lt;/code&gt; can be used for NFKC/NFKD compatibility equivalence normalization. E.g. &lt;code&gt;%(title)+.100U&lt;/code&gt; is NFKC&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;To summarize, the general syntax for a field is:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;%(name[.keys][addition][&amp;gt;strf][,alternate][&amp;amp;replacement][|default])[flags][width][.precision][length]type
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Additionally, you can set different output templates for the various metadata files separately from the general output template by specifying the type of file followed by the template separated by a colon &lt;code&gt;:&lt;/code&gt;. The different file types supported are &lt;code&gt;subtitle&lt;/code&gt;, &lt;code&gt;thumbnail&lt;/code&gt;, &lt;code&gt;description&lt;/code&gt;, &lt;code&gt;annotation&lt;/code&gt; (deprecated), &lt;code&gt;infojson&lt;/code&gt;, &lt;code&gt;link&lt;/code&gt;, &lt;code&gt;pl_thumbnail&lt;/code&gt;, &lt;code&gt;pl_description&lt;/code&gt;, &lt;code&gt;pl_infojson&lt;/code&gt;, &lt;code&gt;chapter&lt;/code&gt;, &lt;code&gt;pl_video&lt;/code&gt;. E.g. &lt;code&gt;-o "%(title)s.%(ext)s" -o "thumbnail:%(title)s\%(title)s.%(ext)s"&lt;/code&gt; will put the thumbnails in a folder with the same name as the video. If any of the templates is empty, that type of file will not be written. E.g. &lt;code&gt;--write-thumbnail -o "thumbnail:"&lt;/code&gt; will write thumbnails only for playlists and not for video.&lt;/p&gt; 
&lt;p&gt;&lt;a id="outtmpl-postprocess-note"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: Due to post-processing (i.e. merging etc.), the actual output filename might differ. Use &lt;code&gt;--print after_move:filepath&lt;/code&gt; to get the name after all post-processing is complete.&lt;/p&gt; 
&lt;p&gt;The available fields are:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;id&lt;/code&gt; (string): Video identifier&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;title&lt;/code&gt; (string): Video title&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;fulltitle&lt;/code&gt; (string): Video title ignoring live timestamp and generic title&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;ext&lt;/code&gt; (string): Video filename extension&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;alt_title&lt;/code&gt; (string): A secondary title of the video&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;description&lt;/code&gt; (string): The description of the video&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;display_id&lt;/code&gt; (string): An alternative identifier for the video&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;uploader&lt;/code&gt; (string): Full name of the video uploader&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;uploader_id&lt;/code&gt; (string): Nickname or id of the video uploader&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;uploader_url&lt;/code&gt; (string): URL to the video uploader's profile&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;license&lt;/code&gt; (string): License name the video is licensed under&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;creators&lt;/code&gt; (list): The creators of the video&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;creator&lt;/code&gt; (string): The creators of the video; comma-separated&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;timestamp&lt;/code&gt; (numeric): UNIX timestamp of the moment the video became available&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;upload_date&lt;/code&gt; (string): Video upload date in UTC (YYYYMMDD)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;release_timestamp&lt;/code&gt; (numeric): UNIX timestamp of the moment the video was released&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;release_date&lt;/code&gt; (string): The date (YYYYMMDD) when the video was released in UTC&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;release_year&lt;/code&gt; (numeric): Year (YYYY) when the video or album was released&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;modified_timestamp&lt;/code&gt; (numeric): UNIX timestamp of the moment the video was last modified&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;modified_date&lt;/code&gt; (string): The date (YYYYMMDD) when the video was last modified in UTC&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;channel&lt;/code&gt; (string): Full name of the channel the video is uploaded on&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;channel_id&lt;/code&gt; (string): Id of the channel&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;channel_url&lt;/code&gt; (string): URL of the channel&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;channel_follower_count&lt;/code&gt; (numeric): Number of followers of the channel&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;channel_is_verified&lt;/code&gt; (boolean): Whether the channel is verified on the platform&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;location&lt;/code&gt; (string): Physical location where the video was filmed&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;duration&lt;/code&gt; (numeric): Length of the video in seconds&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;duration_string&lt;/code&gt; (string): Length of the video (HH:mm:ss)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;view_count&lt;/code&gt; (numeric): How many users have watched the video on the platform&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;concurrent_view_count&lt;/code&gt; (numeric): How many users are currently watching the video on the platform.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;like_count&lt;/code&gt; (numeric): Number of positive ratings of the video&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;dislike_count&lt;/code&gt; (numeric): Number of negative ratings of the video&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;repost_count&lt;/code&gt; (numeric): Number of reposts of the video&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;average_rating&lt;/code&gt; (numeric): Average rating given by users, the scale used depends on the webpage&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;comment_count&lt;/code&gt; (numeric): Number of comments on the video (For some extractors, comments are only downloaded at the end, and so this field cannot be used)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;age_limit&lt;/code&gt; (numeric): Age restriction for the video (years)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;live_status&lt;/code&gt; (string): One of "not_live", "is_live", "is_upcoming", "was_live", "post_live" (was live, but VOD is not yet processed)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;is_live&lt;/code&gt; (boolean): Whether this video is a live stream or a fixed-length video&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;was_live&lt;/code&gt; (boolean): Whether this video was originally a live stream&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;playable_in_embed&lt;/code&gt; (string): Whether this video is allowed to play in embedded players on other sites&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;availability&lt;/code&gt; (string): Whether the video is "private", "premium_only", "subscriber_only", "needs_auth", "unlisted" or "public"&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;media_type&lt;/code&gt; (string): The type of media as classified by the site, e.g. "episode", "clip", "trailer"&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;start_time&lt;/code&gt; (numeric): Time in seconds where the reproduction should start, as specified in the URL&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;end_time&lt;/code&gt; (numeric): Time in seconds where the reproduction should end, as specified in the URL&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;extractor&lt;/code&gt; (string): Name of the extractor&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;extractor_key&lt;/code&gt; (string): Key name of the extractor&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;epoch&lt;/code&gt; (numeric): Unix epoch of when the information extraction was completed&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;autonumber&lt;/code&gt; (numeric): Number that will be increased with each download, starting at &lt;code&gt;--autonumber-start&lt;/code&gt;, padded with leading zeros to 5 digits&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;video_autonumber&lt;/code&gt; (numeric): Number that will be increased with each video&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;n_entries&lt;/code&gt; (numeric): Total number of extracted items in the playlist&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;playlist_id&lt;/code&gt; (string): Identifier of the playlist that contains the video&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;playlist_title&lt;/code&gt; (string): Name of the playlist that contains the video&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;playlist&lt;/code&gt; (string): &lt;code&gt;playlist_title&lt;/code&gt; if available or else &lt;code&gt;playlist_id&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;playlist_count&lt;/code&gt; (numeric): Total number of items in the playlist. May not be known if entire playlist is not extracted&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;playlist_index&lt;/code&gt; (numeric): Index of the video in the playlist padded with leading zeros according the final index&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;playlist_autonumber&lt;/code&gt; (numeric): Position of the video in the playlist download queue padded with leading zeros according to the total length of the playlist&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;playlist_uploader&lt;/code&gt; (string): Full name of the playlist uploader&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;playlist_uploader_id&lt;/code&gt; (string): Nickname or id of the playlist uploader&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;playlist_channel&lt;/code&gt; (string): Display name of the channel that uploaded the playlist&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;playlist_channel_id&lt;/code&gt; (string): Identifier of the channel that uploaded the playlist&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;playlist_webpage_url&lt;/code&gt; (string): URL of the playlist webpage&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;webpage_url&lt;/code&gt; (string): A URL to the video webpage which, if given to yt-dlp, should yield the same result again&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;webpage_url_basename&lt;/code&gt; (string): The basename of the webpage URL&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;webpage_url_domain&lt;/code&gt; (string): The domain of the webpage URL&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;original_url&lt;/code&gt; (string): The URL given by the user (or the same as &lt;code&gt;webpage_url&lt;/code&gt; for playlist entries)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;categories&lt;/code&gt; (list): List of categories the video belongs to&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;tags&lt;/code&gt; (list): List of tags assigned to the video&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;cast&lt;/code&gt; (list): List of cast members&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;All the fields in &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#filtering-formats"&gt;Filtering Formats&lt;/a&gt; can also be used&lt;/p&gt; 
&lt;p&gt;Available for the video that belongs to some logical chapter or section:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;chapter&lt;/code&gt; (string): Name or title of the chapter the video belongs to&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;chapter_number&lt;/code&gt; (numeric): Number of the chapter the video belongs to&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;chapter_id&lt;/code&gt; (string): Id of the chapter the video belongs to&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Available for the video that is an episode of some series or program:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;series&lt;/code&gt; (string): Title of the series or program the video episode belongs to&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;series_id&lt;/code&gt; (string): Id of the series or program the video episode belongs to&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;season&lt;/code&gt; (string): Title of the season the video episode belongs to&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;season_number&lt;/code&gt; (numeric): Number of the season the video episode belongs to&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;season_id&lt;/code&gt; (string): Id of the season the video episode belongs to&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;episode&lt;/code&gt; (string): Title of the video episode&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;episode_number&lt;/code&gt; (numeric): Number of the video episode within a season&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;episode_id&lt;/code&gt; (string): Id of the video episode&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Available for the media that is a track or a part of a music album:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;track&lt;/code&gt; (string): Title of the track&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;track_number&lt;/code&gt; (numeric): Number of the track within an album or a disc&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;track_id&lt;/code&gt; (string): Id of the track&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;artists&lt;/code&gt; (list): Artist(s) of the track&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;artist&lt;/code&gt; (string): Artist(s) of the track; comma-separated&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;genres&lt;/code&gt; (list): Genre(s) of the track&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;genre&lt;/code&gt; (string): Genre(s) of the track; comma-separated&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;composers&lt;/code&gt; (list): Composer(s) of the piece&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;composer&lt;/code&gt; (string): Composer(s) of the piece; comma-separated&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;album&lt;/code&gt; (string): Title of the album the track belongs to&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;album_type&lt;/code&gt; (string): Type of the album&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;album_artists&lt;/code&gt; (list): All artists appeared on the album&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;album_artist&lt;/code&gt; (string): All artists appeared on the album; comma-separated&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;disc_number&lt;/code&gt; (numeric): Number of the disc or other physical medium the track belongs to&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Available only when using &lt;code&gt;--download-sections&lt;/code&gt; and for &lt;code&gt;chapter:&lt;/code&gt; prefix when using &lt;code&gt;--split-chapters&lt;/code&gt; for videos with internal chapters:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;section_title&lt;/code&gt; (string): Title of the chapter&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;section_number&lt;/code&gt; (numeric): Number of the chapter within the file&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;section_start&lt;/code&gt; (numeric): Start time of the chapter in seconds&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;section_end&lt;/code&gt; (numeric): End time of the chapter in seconds&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Available only when used in &lt;code&gt;--print&lt;/code&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;urls&lt;/code&gt; (string): The URLs of all requested formats, one in each line&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;filename&lt;/code&gt; (string): Name of the video file. Note that the &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#outtmpl-postprocess-note"&gt;actual filename may differ&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;formats_table&lt;/code&gt; (table): The video format table as printed by &lt;code&gt;--list-formats&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;thumbnails_table&lt;/code&gt; (table): The thumbnail format table as printed by &lt;code&gt;--list-thumbnails&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;subtitles_table&lt;/code&gt; (table): The subtitle format table as printed by &lt;code&gt;--list-subs&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;automatic_captions_table&lt;/code&gt; (table): The automatic subtitle format table as printed by &lt;code&gt;--list-subs&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Available only after the video is downloaded (&lt;code&gt;post_process&lt;/code&gt;/&lt;code&gt;after_move&lt;/code&gt;):&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;filepath&lt;/code&gt;: Actual path of downloaded video file&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Available only in &lt;code&gt;--sponsorblock-chapter-title&lt;/code&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;start_time&lt;/code&gt; (numeric): Start time of the chapter in seconds&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;end_time&lt;/code&gt; (numeric): End time of the chapter in seconds&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;categories&lt;/code&gt; (list): The &lt;a href="https://wiki.sponsor.ajay.app/w/Types#Category"&gt;SponsorBlock categories&lt;/a&gt; the chapter belongs to&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;category&lt;/code&gt; (string): The smallest SponsorBlock category the chapter belongs to&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;category_names&lt;/code&gt; (list): Friendly names of the categories&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;name&lt;/code&gt; (string): Friendly name of the smallest category&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;type&lt;/code&gt; (string): The &lt;a href="https://wiki.sponsor.ajay.app/w/Types#Action_Type"&gt;SponsorBlock action type&lt;/a&gt; of the chapter&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Each aforementioned sequence when referenced in an output template will be replaced by the actual value corresponding to the sequence name. E.g. for &lt;code&gt;-o %(title)s-%(id)s.%(ext)s&lt;/code&gt; and an mp4 video with title &lt;code&gt;yt-dlp test video&lt;/code&gt; and id &lt;code&gt;BaW_jenozKc&lt;/code&gt;, this will result in a &lt;code&gt;yt-dlp test video-BaW_jenozKc.mp4&lt;/code&gt; file created in the current directory.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: Some of the sequences are not guaranteed to be present, since they depend on the metadata obtained by a particular extractor. Such sequences will be replaced with placeholder value provided with &lt;code&gt;--output-na-placeholder&lt;/code&gt; (&lt;code&gt;NA&lt;/code&gt; by default).&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Tip&lt;/strong&gt;: Look at the &lt;code&gt;-j&lt;/code&gt; output to identify which fields are available for the particular URL&lt;/p&gt; 
&lt;p&gt;For numeric sequences, you can use &lt;a href="https://docs.python.org/3/library/stdtypes.html#printf-style-string-formatting"&gt;numeric related formatting&lt;/a&gt;; e.g. &lt;code&gt;%(view_count)05d&lt;/code&gt; will result in a string with view count padded with zeros up to 5 characters, like in &lt;code&gt;00042&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Output templates can also contain arbitrary hierarchical path, e.g. &lt;code&gt;-o "%(playlist)s/%(playlist_index)s - %(title)s.%(ext)s"&lt;/code&gt; which will result in downloading each video in a directory corresponding to this path template. Any missing directory will be automatically created for you.&lt;/p&gt; 
&lt;p&gt;To use percent literals in an output template use &lt;code&gt;%%&lt;/code&gt;. To output to stdout use &lt;code&gt;-o -&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;The current default template is &lt;code&gt;%(title)s [%(id)s].%(ext)s&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;In some cases, you don't want special characters such as 中, spaces, or &amp;amp;, such as when transferring the downloaded filename to a Windows system or the filename through an 8bit-unsafe channel. In these cases, add the &lt;code&gt;--restrict-filenames&lt;/code&gt; flag to get a shorter title.&lt;/p&gt; 
&lt;h4&gt;Output template examples&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;$ yt-dlp --print filename -o "test video.%(ext)s" BaW_jenozKc
test video.webm    # Literal name with correct extension

$ yt-dlp --print filename -o "%(title)s.%(ext)s" BaW_jenozKc
youtube-dl test video ''_ä↭𝕐.webm    # All kinds of weird characters

$ yt-dlp --print filename -o "%(title)s.%(ext)s" BaW_jenozKc --restrict-filenames
youtube-dl_test_video_.webm    # Restricted file name

# Download YouTube playlist videos in separate directory indexed by video order in a playlist
$ yt-dlp -o "%(playlist)s/%(playlist_index)s - %(title)s.%(ext)s" "https://www.youtube.com/playlist?list=PLwiyx1dc3P2JR9N8gQaQN_BCvlSlap7re"

# Download YouTube playlist videos in separate directories according to their uploaded year
$ yt-dlp -o "%(upload_date&amp;gt;%Y)s/%(title)s.%(ext)s" "https://www.youtube.com/playlist?list=PLwiyx1dc3P2JR9N8gQaQN_BCvlSlap7re"

# Prefix playlist index with " - " separator, but only if it is available
$ yt-dlp -o "%(playlist_index&amp;amp;{} - |)s%(title)s.%(ext)s" BaW_jenozKc "https://www.youtube.com/user/TheLinuxFoundation/playlists"

# Download all playlists of YouTube channel/user keeping each playlist in separate directory:
$ yt-dlp -o "%(uploader)s/%(playlist)s/%(playlist_index)s - %(title)s.%(ext)s" "https://www.youtube.com/user/TheLinuxFoundation/playlists"

# Download Udemy course keeping each chapter in separate directory under MyVideos directory in your home
$ yt-dlp -u user -p password -P "~/MyVideos" -o "%(playlist)s/%(chapter_number)s - %(chapter)s/%(title)s.%(ext)s" "https://www.udemy.com/java-tutorial"

# Download entire series season keeping each series and each season in separate directory under C:/MyVideos
$ yt-dlp -P "C:/MyVideos" -o "%(series)s/%(season_number)s - %(season)s/%(episode_number)s - %(episode)s.%(ext)s" "https://videomore.ru/kino_v_detalayah/5_sezon/367617"

# Download video as "C:\MyVideos\uploader\title.ext", subtitles as "C:\MyVideos\subs\uploader\title.ext"
# and put all temporary files in "C:\MyVideos\tmp"
$ yt-dlp -P "C:/MyVideos" -P "temp:tmp" -P "subtitle:subs" -o "%(uploader)s/%(title)s.%(ext)s" BaW_jenozKc --write-subs

# Download video as "C:\MyVideos\uploader\title.ext" and subtitles as "C:\MyVideos\uploader\subs\title.ext"
$ yt-dlp -P "C:/MyVideos" -o "%(uploader)s/%(title)s.%(ext)s" -o "subtitle:%(uploader)s/subs/%(title)s.%(ext)s" BaW_jenozKc --write-subs

# Stream the video being downloaded to stdout
$ yt-dlp -o - BaW_jenozKc
&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;FORMAT SELECTION&lt;/h1&gt; 
&lt;p&gt;By default, yt-dlp tries to download the best available quality if you &lt;strong&gt;don't&lt;/strong&gt; pass any options. This is generally equivalent to using &lt;code&gt;-f bestvideo*+bestaudio/best&lt;/code&gt;. However, if multiple audiostreams is enabled (&lt;code&gt;--audio-multistreams&lt;/code&gt;), the default format changes to &lt;code&gt;-f bestvideo+bestaudio/best&lt;/code&gt;. Similarly, if ffmpeg is unavailable, or if you use yt-dlp to stream to &lt;code&gt;stdout&lt;/code&gt; (&lt;code&gt;-o -&lt;/code&gt;), the default becomes &lt;code&gt;-f best/bestvideo+bestaudio&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Deprecation warning&lt;/strong&gt;: Latest versions of yt-dlp can stream multiple formats to the stdout simultaneously using ffmpeg. So, in future versions, the default for this will be set to &lt;code&gt;-f bv*+ba/b&lt;/code&gt; similar to normal downloads. If you want to preserve the &lt;code&gt;-f b/bv+ba&lt;/code&gt; setting, it is recommended to explicitly specify it in the configuration options.&lt;/p&gt; 
&lt;p&gt;The general syntax for format selection is &lt;code&gt;-f FORMAT&lt;/code&gt; (or &lt;code&gt;--format FORMAT&lt;/code&gt;) where &lt;code&gt;FORMAT&lt;/code&gt; is a &lt;em&gt;selector expression&lt;/em&gt;, i.e. an expression that describes format or formats you would like to download.&lt;/p&gt; 
&lt;!-- MANPAGE: BEGIN EXCLUDED SECTION --&gt; 
&lt;p&gt;&lt;strong&gt;tl;dr:&lt;/strong&gt; &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#format-selection-examples"&gt;navigate me to examples&lt;/a&gt;.&lt;/p&gt; 
&lt;!-- MANPAGE: END EXCLUDED SECTION --&gt; 
&lt;p&gt;The simplest case is requesting a specific format; e.g. with &lt;code&gt;-f 22&lt;/code&gt; you can download the format with format code equal to 22. You can get the list of available format codes for particular video using &lt;code&gt;--list-formats&lt;/code&gt; or &lt;code&gt;-F&lt;/code&gt;. Note that these format codes are extractor specific.&lt;/p&gt; 
&lt;p&gt;You can also use a file extension (currently &lt;code&gt;3gp&lt;/code&gt;, &lt;code&gt;aac&lt;/code&gt;, &lt;code&gt;flv&lt;/code&gt;, &lt;code&gt;m4a&lt;/code&gt;, &lt;code&gt;mp3&lt;/code&gt;, &lt;code&gt;mp4&lt;/code&gt;, &lt;code&gt;ogg&lt;/code&gt;, &lt;code&gt;wav&lt;/code&gt;, &lt;code&gt;webm&lt;/code&gt; are supported) to download the best quality format of a particular file extension served as a single file, e.g. &lt;code&gt;-f webm&lt;/code&gt; will download the best quality format with the &lt;code&gt;webm&lt;/code&gt; extension served as a single file.&lt;/p&gt; 
&lt;p&gt;You can use &lt;code&gt;-f -&lt;/code&gt; to interactively provide the format selector &lt;em&gt;for each video&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;You can also use special names to select particular edge case formats:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;all&lt;/code&gt;: Select &lt;strong&gt;all formats&lt;/strong&gt; separately&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;mergeall&lt;/code&gt;: Select and &lt;strong&gt;merge all formats&lt;/strong&gt; (Must be used with &lt;code&gt;--audio-multistreams&lt;/code&gt;, &lt;code&gt;--video-multistreams&lt;/code&gt; or both)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;b*&lt;/code&gt;, &lt;code&gt;best*&lt;/code&gt;: Select the best quality format that &lt;strong&gt;contains either&lt;/strong&gt; a video or an audio or both (i.e.; &lt;code&gt;vcodec!=none or acodec!=none&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;b&lt;/code&gt;, &lt;code&gt;best&lt;/code&gt;: Select the best quality format that &lt;strong&gt;contains both&lt;/strong&gt; video and audio. Equivalent to &lt;code&gt;best*[vcodec!=none][acodec!=none]&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;bv&lt;/code&gt;, &lt;code&gt;bestvideo&lt;/code&gt;: Select the best quality &lt;strong&gt;video-only&lt;/strong&gt; format. Equivalent to &lt;code&gt;best*[acodec=none]&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;bv*&lt;/code&gt;, &lt;code&gt;bestvideo*&lt;/code&gt;: Select the best quality format that &lt;strong&gt;contains video&lt;/strong&gt;. It may also contain audio. Equivalent to &lt;code&gt;best*[vcodec!=none]&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;ba&lt;/code&gt;, &lt;code&gt;bestaudio&lt;/code&gt;: Select the best quality &lt;strong&gt;audio-only&lt;/strong&gt; format. Equivalent to &lt;code&gt;best*[vcodec=none]&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;ba*&lt;/code&gt;, &lt;code&gt;bestaudio*&lt;/code&gt;: Select the best quality format that &lt;strong&gt;contains audio&lt;/strong&gt;. It may also contain video. Equivalent to &lt;code&gt;best*[acodec!=none]&lt;/code&gt; (&lt;a href="https://github.com/yt-dlp/yt-dlp/issues/979#issuecomment-919629354"&gt;Do not use!&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;w*&lt;/code&gt;, &lt;code&gt;worst*&lt;/code&gt;: Select the worst quality format that contains either a video or an audio&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;w&lt;/code&gt;, &lt;code&gt;worst&lt;/code&gt;: Select the worst quality format that contains both video and audio. Equivalent to &lt;code&gt;worst*[vcodec!=none][acodec!=none]&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;wv&lt;/code&gt;, &lt;code&gt;worstvideo&lt;/code&gt;: Select the worst quality video-only format. Equivalent to &lt;code&gt;worst*[acodec=none]&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;wv*&lt;/code&gt;, &lt;code&gt;worstvideo*&lt;/code&gt;: Select the worst quality format that contains video. It may also contain audio. Equivalent to &lt;code&gt;worst*[vcodec!=none]&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;wa&lt;/code&gt;, &lt;code&gt;worstaudio&lt;/code&gt;: Select the worst quality audio-only format. Equivalent to &lt;code&gt;worst*[vcodec=none]&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;wa*&lt;/code&gt;, &lt;code&gt;worstaudio*&lt;/code&gt;: Select the worst quality format that contains audio. It may also contain video. Equivalent to &lt;code&gt;worst*[acodec!=none]&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For example, to download the worst quality video-only format you can use &lt;code&gt;-f worstvideo&lt;/code&gt;. It is, however, recommended not to use &lt;code&gt;worst&lt;/code&gt; and related options. When your format selector is &lt;code&gt;worst&lt;/code&gt;, the format which is worst in all respects is selected. Most of the time, what you actually want is the video with the smallest filesize instead. So it is generally better to use &lt;code&gt;-S +size&lt;/code&gt; or more rigorously, &lt;code&gt;-S +size,+br,+res,+fps&lt;/code&gt; instead of &lt;code&gt;-f worst&lt;/code&gt;. See &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#sorting-formats"&gt;Sorting Formats&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;p&gt;You can select the n'th best format of a type by using &lt;code&gt;best&amp;lt;type&amp;gt;.&amp;lt;n&amp;gt;&lt;/code&gt;. For example, &lt;code&gt;best.2&lt;/code&gt; will select the 2nd best combined format. Similarly, &lt;code&gt;bv*.3&lt;/code&gt; will select the 3rd best format that contains a video stream.&lt;/p&gt; 
&lt;p&gt;If you want to download multiple videos, and they don't have the same formats available, you can specify the order of preference using slashes. Note that formats on the left hand side are preferred; e.g. &lt;code&gt;-f 22/17/18&lt;/code&gt; will download format 22 if it's available, otherwise it will download format 17 if it's available, otherwise it will download format 18 if it's available, otherwise it will complain that no suitable formats are available for download.&lt;/p&gt; 
&lt;p&gt;If you want to download several formats of the same video use a comma as a separator, e.g. &lt;code&gt;-f 22,17,18&lt;/code&gt; will download all these three formats, of course if they are available. Or a more sophisticated example combined with the precedence feature: &lt;code&gt;-f 136/137/mp4/bestvideo,140/m4a/bestaudio&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;You can merge the video and audio of multiple formats into a single file using &lt;code&gt;-f &amp;lt;format1&amp;gt;+&amp;lt;format2&amp;gt;+...&lt;/code&gt; (requires ffmpeg installed); e.g. &lt;code&gt;-f bestvideo+bestaudio&lt;/code&gt; will download the best video-only format, the best audio-only format and mux them together with ffmpeg.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Deprecation warning&lt;/strong&gt;: Since the &lt;em&gt;below&lt;/em&gt; described behavior is complex and counter-intuitive, this will be removed and multistreams will be enabled by default in the future. A new operator will be instead added to limit formats to single audio/video&lt;/p&gt; 
&lt;p&gt;Unless &lt;code&gt;--video-multistreams&lt;/code&gt; is used, all formats with a video stream except the first one are ignored. Similarly, unless &lt;code&gt;--audio-multistreams&lt;/code&gt; is used, all formats with an audio stream except the first one are ignored. E.g. &lt;code&gt;-f bestvideo+best+bestaudio --video-multistreams --audio-multistreams&lt;/code&gt; will download and merge all 3 given formats. The resulting file will have 2 video streams and 2 audio streams. But &lt;code&gt;-f bestvideo+best+bestaudio --no-video-multistreams&lt;/code&gt; will download and merge only &lt;code&gt;bestvideo&lt;/code&gt; and &lt;code&gt;bestaudio&lt;/code&gt;. &lt;code&gt;best&lt;/code&gt; is ignored since another format containing a video stream (&lt;code&gt;bestvideo&lt;/code&gt;) has already been selected. The order of the formats is therefore important. &lt;code&gt;-f best+bestaudio --no-audio-multistreams&lt;/code&gt; will download only &lt;code&gt;best&lt;/code&gt; while &lt;code&gt;-f bestaudio+best --no-audio-multistreams&lt;/code&gt; will ignore &lt;code&gt;best&lt;/code&gt; and download only &lt;code&gt;bestaudio&lt;/code&gt;.&lt;/p&gt; 
&lt;h2&gt;Filtering Formats&lt;/h2&gt; 
&lt;p&gt;You can also filter the video formats by putting a condition in brackets, as in &lt;code&gt;-f "best[height=720]"&lt;/code&gt; (or &lt;code&gt;-f "[filesize&amp;gt;10M]"&lt;/code&gt; since filters without a selector are interpreted as &lt;code&gt;best&lt;/code&gt;).&lt;/p&gt; 
&lt;p&gt;The following numeric meta fields can be used with comparisons &lt;code&gt;&amp;lt;&lt;/code&gt;, &lt;code&gt;&amp;lt;=&lt;/code&gt;, &lt;code&gt;&amp;gt;&lt;/code&gt;, &lt;code&gt;&amp;gt;=&lt;/code&gt;, &lt;code&gt;=&lt;/code&gt; (equals), &lt;code&gt;!=&lt;/code&gt; (not equals):&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;filesize&lt;/code&gt;: The number of bytes, if known in advance&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;filesize_approx&lt;/code&gt;: An estimate for the number of bytes&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;width&lt;/code&gt;: Width of the video, if known&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;height&lt;/code&gt;: Height of the video, if known&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;aspect_ratio&lt;/code&gt;: Aspect ratio of the video, if known&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;tbr&lt;/code&gt;: Average bitrate of audio and video in &lt;a href="##" title="1000 bits/sec"&gt;kbps&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;abr&lt;/code&gt;: Average audio bitrate in &lt;a href="##" title="1000 bits/sec"&gt;kbps&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;vbr&lt;/code&gt;: Average video bitrate in &lt;a href="##" title="1000 bits/sec"&gt;kbps&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;asr&lt;/code&gt;: Audio sampling rate in Hertz&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;fps&lt;/code&gt;: Frame rate&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;audio_channels&lt;/code&gt;: The number of audio channels&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;stretched_ratio&lt;/code&gt;: &lt;code&gt;width:height&lt;/code&gt; of the video's pixels, if not square&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Also filtering work for comparisons &lt;code&gt;=&lt;/code&gt; (equals), &lt;code&gt;^=&lt;/code&gt; (starts with), &lt;code&gt;$=&lt;/code&gt; (ends with), &lt;code&gt;*=&lt;/code&gt; (contains), &lt;code&gt;~=&lt;/code&gt; (matches regex) and following string meta fields:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;url&lt;/code&gt;: Video URL&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;ext&lt;/code&gt;: File extension&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;acodec&lt;/code&gt;: Name of the audio codec in use&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;vcodec&lt;/code&gt;: Name of the video codec in use&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;container&lt;/code&gt;: Name of the container format&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;protocol&lt;/code&gt;: The protocol that will be used for the actual download, lower-case (&lt;code&gt;http&lt;/code&gt;, &lt;code&gt;https&lt;/code&gt;, &lt;code&gt;rtsp&lt;/code&gt;, &lt;code&gt;rtmp&lt;/code&gt;, &lt;code&gt;rtmpe&lt;/code&gt;, &lt;code&gt;mms&lt;/code&gt;, &lt;code&gt;f4m&lt;/code&gt;, &lt;code&gt;ism&lt;/code&gt;, &lt;code&gt;http_dash_segments&lt;/code&gt;, &lt;code&gt;m3u8&lt;/code&gt;, or &lt;code&gt;m3u8_native&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;language&lt;/code&gt;: Language code&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;dynamic_range&lt;/code&gt;: The dynamic range of the video&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;format_id&lt;/code&gt;: A short description of the format&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;format&lt;/code&gt;: A human-readable description of the format&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;format_note&lt;/code&gt;: Additional info about the format&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;resolution&lt;/code&gt;: Textual description of width and height&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Any string comparison may be prefixed with negation &lt;code&gt;!&lt;/code&gt; in order to produce an opposite comparison, e.g. &lt;code&gt;!*=&lt;/code&gt; (does not contain). The comparand of a string comparison needs to be quoted with either double or single quotes if it contains spaces or special characters other than &lt;code&gt;._-&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: None of the aforementioned meta fields are guaranteed to be present since this solely depends on the metadata obtained by the particular extractor, i.e. the metadata offered by the website. Any other field made available by the extractor can also be used for filtering.&lt;/p&gt; 
&lt;p&gt;Formats for which the value is not known are excluded unless you put a question mark (&lt;code&gt;?&lt;/code&gt;) after the operator. You can combine format filters, so &lt;code&gt;-f "bv[height&amp;lt;=?720][tbr&amp;gt;500]"&lt;/code&gt; selects up to 720p videos (or videos where the height is not known) with a bitrate of at least 500 kbps. You can also use the filters with &lt;code&gt;all&lt;/code&gt; to download all formats that satisfy the filter, e.g. &lt;code&gt;-f "all[vcodec=none]"&lt;/code&gt; selects all audio-only formats.&lt;/p&gt; 
&lt;p&gt;Format selectors can also be grouped using parentheses; e.g. &lt;code&gt;-f "(mp4,webm)[height&amp;lt;480]"&lt;/code&gt; will download the best pre-merged mp4 and webm formats with a height lower than 480.&lt;/p&gt; 
&lt;h2&gt;Sorting Formats&lt;/h2&gt; 
&lt;p&gt;You can change the criteria for being considered the &lt;code&gt;best&lt;/code&gt; by using &lt;code&gt;-S&lt;/code&gt; (&lt;code&gt;--format-sort&lt;/code&gt;). The general format for this is &lt;code&gt;--format-sort field1,field2...&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;The available fields are:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;hasvid&lt;/code&gt;: Gives priority to formats that have a video stream&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;hasaud&lt;/code&gt;: Gives priority to formats that have an audio stream&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;ie_pref&lt;/code&gt;: The format preference&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;lang&lt;/code&gt;: The language preference as determined by the extractor (e.g. original language preferred over audio description)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;quality&lt;/code&gt;: The quality of the format&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;source&lt;/code&gt;: The preference of the source&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;proto&lt;/code&gt;: Protocol used for download (&lt;code&gt;https&lt;/code&gt;/&lt;code&gt;ftps&lt;/code&gt; &amp;gt; &lt;code&gt;http&lt;/code&gt;/&lt;code&gt;ftp&lt;/code&gt; &amp;gt; &lt;code&gt;m3u8_native&lt;/code&gt;/&lt;code&gt;m3u8&lt;/code&gt; &amp;gt; &lt;code&gt;http_dash_segments&lt;/code&gt;&amp;gt; &lt;code&gt;websocket_frag&lt;/code&gt; &amp;gt; &lt;code&gt;mms&lt;/code&gt;/&lt;code&gt;rtsp&lt;/code&gt; &amp;gt; &lt;code&gt;f4f&lt;/code&gt;/&lt;code&gt;f4m&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;vcodec&lt;/code&gt;: Video Codec (&lt;code&gt;av01&lt;/code&gt; &amp;gt; &lt;code&gt;vp9.2&lt;/code&gt; &amp;gt; &lt;code&gt;vp9&lt;/code&gt; &amp;gt; &lt;code&gt;h265&lt;/code&gt; &amp;gt; &lt;code&gt;h264&lt;/code&gt; &amp;gt; &lt;code&gt;vp8&lt;/code&gt; &amp;gt; &lt;code&gt;h263&lt;/code&gt; &amp;gt; &lt;code&gt;theora&lt;/code&gt; &amp;gt; other)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;acodec&lt;/code&gt;: Audio Codec (&lt;code&gt;flac&lt;/code&gt;/&lt;code&gt;alac&lt;/code&gt; &amp;gt; &lt;code&gt;wav&lt;/code&gt;/&lt;code&gt;aiff&lt;/code&gt; &amp;gt; &lt;code&gt;opus&lt;/code&gt; &amp;gt; &lt;code&gt;vorbis&lt;/code&gt; &amp;gt; &lt;code&gt;aac&lt;/code&gt; &amp;gt; &lt;code&gt;mp4a&lt;/code&gt; &amp;gt; &lt;code&gt;mp3&lt;/code&gt; &amp;gt; &lt;code&gt;ac4&lt;/code&gt; &amp;gt; &lt;code&gt;eac3&lt;/code&gt; &amp;gt; &lt;code&gt;ac3&lt;/code&gt; &amp;gt; &lt;code&gt;dts&lt;/code&gt; &amp;gt; other)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;codec&lt;/code&gt;: Equivalent to &lt;code&gt;vcodec,acodec&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;vext&lt;/code&gt;: Video Extension (&lt;code&gt;mp4&lt;/code&gt; &amp;gt; &lt;code&gt;mov&lt;/code&gt; &amp;gt; &lt;code&gt;webm&lt;/code&gt; &amp;gt; &lt;code&gt;flv&lt;/code&gt; &amp;gt; other). If &lt;code&gt;--prefer-free-formats&lt;/code&gt; is used, &lt;code&gt;webm&lt;/code&gt; is preferred.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;aext&lt;/code&gt;: Audio Extension (&lt;code&gt;m4a&lt;/code&gt; &amp;gt; &lt;code&gt;aac&lt;/code&gt; &amp;gt; &lt;code&gt;mp3&lt;/code&gt; &amp;gt; &lt;code&gt;ogg&lt;/code&gt; &amp;gt; &lt;code&gt;opus&lt;/code&gt; &amp;gt; &lt;code&gt;webm&lt;/code&gt; &amp;gt; other). If &lt;code&gt;--prefer-free-formats&lt;/code&gt; is used, the order changes to &lt;code&gt;ogg&lt;/code&gt; &amp;gt; &lt;code&gt;opus&lt;/code&gt; &amp;gt; &lt;code&gt;webm&lt;/code&gt; &amp;gt; &lt;code&gt;mp3&lt;/code&gt; &amp;gt; &lt;code&gt;m4a&lt;/code&gt; &amp;gt; &lt;code&gt;aac&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;ext&lt;/code&gt;: Equivalent to &lt;code&gt;vext,aext&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;filesize&lt;/code&gt;: Exact filesize, if known in advance&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;fs_approx&lt;/code&gt;: Approximate filesize&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;size&lt;/code&gt;: Exact filesize if available, otherwise approximate filesize&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;height&lt;/code&gt;: Height of video&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;width&lt;/code&gt;: Width of video&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;res&lt;/code&gt;: Video resolution, calculated as the smallest dimension.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;fps&lt;/code&gt;: Framerate of video&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;hdr&lt;/code&gt;: The dynamic range of the video (&lt;code&gt;DV&lt;/code&gt; &amp;gt; &lt;code&gt;HDR12&lt;/code&gt; &amp;gt; &lt;code&gt;HDR10+&lt;/code&gt; &amp;gt; &lt;code&gt;HDR10&lt;/code&gt; &amp;gt; &lt;code&gt;HLG&lt;/code&gt; &amp;gt; &lt;code&gt;SDR&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;channels&lt;/code&gt;: The number of audio channels&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;tbr&lt;/code&gt;: Total average bitrate in &lt;a href="##" title="1000 bits/sec"&gt;kbps&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;vbr&lt;/code&gt;: Average video bitrate in &lt;a href="##" title="1000 bits/sec"&gt;kbps&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;abr&lt;/code&gt;: Average audio bitrate in &lt;a href="##" title="1000 bits/sec"&gt;kbps&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;br&lt;/code&gt;: Average bitrate in &lt;a href="##" title="1000 bits/sec"&gt;kbps&lt;/a&gt;, &lt;code&gt;tbr&lt;/code&gt;/&lt;code&gt;vbr&lt;/code&gt;/&lt;code&gt;abr&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;asr&lt;/code&gt;: Audio sample rate in Hz&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Deprecation warning&lt;/strong&gt;: Many of these fields have (currently undocumented) aliases, that may be removed in a future version. It is recommended to use only the documented field names.&lt;/p&gt; 
&lt;p&gt;All fields, unless specified otherwise, are sorted in descending order. To reverse this, prefix the field with a &lt;code&gt;+&lt;/code&gt;. E.g. &lt;code&gt;+res&lt;/code&gt; prefers format with the smallest resolution. Additionally, you can suffix a preferred value for the fields, separated by a &lt;code&gt;:&lt;/code&gt;. E.g. &lt;code&gt;res:720&lt;/code&gt; prefers larger videos, but no larger than 720p and the smallest video if there are no videos less than 720p. For &lt;code&gt;codec&lt;/code&gt; and &lt;code&gt;ext&lt;/code&gt;, you can provide two preferred values, the first for video and the second for audio. E.g. &lt;code&gt;+codec:avc:m4a&lt;/code&gt; (equivalent to &lt;code&gt;+vcodec:avc,+acodec:m4a&lt;/code&gt;) sets the video codec preference to &lt;code&gt;h264&lt;/code&gt; &amp;gt; &lt;code&gt;h265&lt;/code&gt; &amp;gt; &lt;code&gt;vp9&lt;/code&gt; &amp;gt; &lt;code&gt;vp9.2&lt;/code&gt; &amp;gt; &lt;code&gt;av01&lt;/code&gt; &amp;gt; &lt;code&gt;vp8&lt;/code&gt; &amp;gt; &lt;code&gt;h263&lt;/code&gt; &amp;gt; &lt;code&gt;theora&lt;/code&gt; and audio codec preference to &lt;code&gt;mp4a&lt;/code&gt; &amp;gt; &lt;code&gt;aac&lt;/code&gt; &amp;gt; &lt;code&gt;vorbis&lt;/code&gt; &amp;gt; &lt;code&gt;opus&lt;/code&gt; &amp;gt; &lt;code&gt;mp3&lt;/code&gt; &amp;gt; &lt;code&gt;ac3&lt;/code&gt; &amp;gt; &lt;code&gt;dts&lt;/code&gt;. You can also make the sorting prefer the nearest values to the provided by using &lt;code&gt;~&lt;/code&gt; as the delimiter. E.g. &lt;code&gt;filesize~1G&lt;/code&gt; prefers the format with filesize closest to 1 GiB.&lt;/p&gt; 
&lt;p&gt;The fields &lt;code&gt;hasvid&lt;/code&gt; and &lt;code&gt;ie_pref&lt;/code&gt; are always given highest priority in sorting, irrespective of the user-defined order. This behavior can be changed by using &lt;code&gt;--format-sort-force&lt;/code&gt;. Apart from these, the default order used is: &lt;code&gt;lang,quality,res,fps,hdr:12,vcodec,channels,acodec,size,br,asr,proto,ext,hasaud,source,id&lt;/code&gt;. The extractors may override this default order, but they cannot override the user-provided order.&lt;/p&gt; 
&lt;p&gt;Note that the default for hdr is &lt;code&gt;hdr:12&lt;/code&gt;; i.e. Dolby Vision is not preferred. This choice was made since DV formats are not yet fully compatible with most devices. This may be changed in the future.&lt;/p&gt; 
&lt;p&gt;If your format selector is &lt;code&gt;worst&lt;/code&gt;, the last item is selected after sorting. This means it will select the format that is worst in all respects. Most of the time, what you actually want is the video with the smallest filesize instead. So it is generally better to use &lt;code&gt;-f best -S +size,+br,+res,+fps&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Tip&lt;/strong&gt;: You can use the &lt;code&gt;-v -F&lt;/code&gt; to see how the formats have been sorted (worst to best).&lt;/p&gt; 
&lt;h2&gt;Format Selection examples&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Download and merge the best video-only format and the best audio-only format,
# or download the best combined format if video-only format is not available
$ yt-dlp -f "bv+ba/b"

# Download best format that contains video,
# and if it doesn't already have an audio stream, merge it with best audio-only format
$ yt-dlp -f "bv*+ba/b"

# Same as above
$ yt-dlp

# Download the best video-only format and the best audio-only format without merging them
# For this case, an output template should be used since
# by default, bestvideo and bestaudio will have the same file name.
$ yt-dlp -f "bv,ba" -o "%(title)s.f%(format_id)s.%(ext)s"

# Download and merge the best format that has a video stream,
# and all audio-only formats into one file
$ yt-dlp -f "bv*+mergeall[vcodec=none]" --audio-multistreams

# Download and merge the best format that has a video stream,
# and the best 2 audio-only formats into one file
$ yt-dlp -f "bv*+ba+ba.2" --audio-multistreams


# The following examples show the old method (without -S) of format selection
# and how to use -S to achieve a similar but (generally) better result

# Download the worst video available (old method)
$ yt-dlp -f "wv*+wa/w"

# Download the best video available but with the smallest resolution
$ yt-dlp -S "+res"

# Download the smallest video available
$ yt-dlp -S "+size,+br"



# Download the best mp4 video available, or the best video if no mp4 available
$ yt-dlp -f "bv*[ext=mp4]+ba[ext=m4a]/b[ext=mp4] / bv*+ba/b"

# Download the best video with the best extension
# (For video, mp4 &amp;gt; mov &amp;gt; webm &amp;gt; flv. For audio, m4a &amp;gt; aac &amp;gt; mp3 ...)
$ yt-dlp -S "ext"



# Download the best video available but no better than 480p,
# or the worst video if there is no video under 480p
$ yt-dlp -f "bv*[height&amp;lt;=480]+ba/b[height&amp;lt;=480] / wv*+ba/w"

# Download the best video available with the largest height but no better than 480p,
# or the best video with the smallest resolution if there is no video under 480p
$ yt-dlp -S "height:480"

# Download the best video available with the largest resolution but no better than 480p,
# or the best video with the smallest resolution if there is no video under 480p
# Resolution is determined by using the smallest dimension.
# So this works correctly for vertical videos as well
$ yt-dlp -S "res:480"



# Download the best video (that also has audio) but no bigger than 50 MB,
# or the worst video (that also has audio) if there is no video under 50 MB
$ yt-dlp -f "b[filesize&amp;lt;50M] / w"

# Download the largest video (that also has audio) but no bigger than 50 MB,
# or the smallest video (that also has audio) if there is no video under 50 MB
$ yt-dlp -f "b" -S "filesize:50M"

# Download the best video (that also has audio) that is closest in size to 50 MB
$ yt-dlp -f "b" -S "filesize~50M"



# Download best video available via direct link over HTTP/HTTPS protocol,
# or the best video available via any protocol if there is no such video
$ yt-dlp -f "(bv*+ba/b)[protocol^=http][protocol!*=dash] / (bv*+ba/b)"

# Download best video available via the best protocol
# (https/ftps &amp;gt; http/ftp &amp;gt; m3u8_native &amp;gt; m3u8 &amp;gt; http_dash_segments ...)
$ yt-dlp -S "proto"



# Download the best video with either h264 or h265 codec,
# or the best video if there is no such video
$ yt-dlp -f "(bv*[vcodec~='^((he|a)vc|h26[45])']+ba) / (bv*+ba/b)"

# Download the best video with best codec no better than h264,
# or the best video with worst codec if there is no such video
$ yt-dlp -S "codec:h264"

# Download the best video with worst codec no worse than h264,
# or the best video with best codec if there is no such video
$ yt-dlp -S "+codec:h264"



# More complex examples

# Download the best video no better than 720p preferring framerate greater than 30,
# or the worst video (still preferring framerate greater than 30) if there is no such video
$ yt-dlp -f "((bv*[fps&amp;gt;30]/bv*)[height&amp;lt;=720]/(wv*[fps&amp;gt;30]/wv*)) + ba / (b[fps&amp;gt;30]/b)[height&amp;lt;=720]/(w[fps&amp;gt;30]/w)"

# Download the video with the largest resolution no better than 720p,
# or the video with the smallest resolution available if there is no such video,
# preferring larger framerate for formats with the same resolution
$ yt-dlp -S "res:720,fps"



# Download the video with smallest resolution no worse than 480p,
# or the video with the largest resolution available if there is no such video,
# preferring better codec and then larger total bitrate for the same resolution
$ yt-dlp -S "+res:480,codec,br"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;MODIFYING METADATA&lt;/h1&gt; 
&lt;p&gt;The metadata obtained by the extractors can be modified by using &lt;code&gt;--parse-metadata&lt;/code&gt; and &lt;code&gt;--replace-in-metadata&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;--replace-in-metadata FIELDS REGEX REPLACE&lt;/code&gt; is used to replace text in any metadata field using &lt;a href="https://docs.python.org/3/library/re.html#regular-expression-syntax"&gt;Python regular expression&lt;/a&gt;. &lt;a href="https://docs.python.org/3/library/re.html?highlight=backreferences#re.sub"&gt;Backreferences&lt;/a&gt; can be used in the replace string for advanced use.&lt;/p&gt; 
&lt;p&gt;The general syntax of &lt;code&gt;--parse-metadata FROM:TO&lt;/code&gt; is to give the name of a field or an &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#output-template"&gt;output template&lt;/a&gt; to extract data from, and the format to interpret it as, separated by a colon &lt;code&gt;:&lt;/code&gt;. Either a &lt;a href="https://docs.python.org/3/library/re.html#regular-expression-syntax"&gt;Python regular expression&lt;/a&gt; with named capture groups, a single field name, or a similar syntax to the &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#output-template"&gt;output template&lt;/a&gt; (only &lt;code&gt;%(field)s&lt;/code&gt; formatting is supported) can be used for &lt;code&gt;TO&lt;/code&gt;. The option can be used multiple times to parse and modify various fields.&lt;/p&gt; 
&lt;p&gt;Note that these options preserve their relative order, allowing replacements to be made in parsed fields and vice versa. Also, any field thus created can be used in the &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#output-template"&gt;output template&lt;/a&gt; and will also affect the media file's metadata added when using &lt;code&gt;--embed-metadata&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;This option also has a few special uses:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;You can download an additional URL based on the metadata of the currently downloaded video. To do this, set the field &lt;code&gt;additional_urls&lt;/code&gt; to the URL that you want to download. E.g. &lt;code&gt;--parse-metadata "description:(?P&amp;lt;additional_urls&amp;gt;https?://www\.vimeo\.com/\d+)"&lt;/code&gt; will download the first vimeo video found in the description&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;You can use this to change the metadata that is embedded in the media file. To do this, set the value of the corresponding field with a &lt;code&gt;meta_&lt;/code&gt; prefix. For example, any value you set to &lt;code&gt;meta_description&lt;/code&gt; field will be added to the &lt;code&gt;description&lt;/code&gt; field in the file - you can use this to set a different "description" and "synopsis". To modify the metadata of individual streams, use the &lt;code&gt;meta&amp;lt;n&amp;gt;_&lt;/code&gt; prefix (e.g. &lt;code&gt;meta1_language&lt;/code&gt;). Any value set to the &lt;code&gt;meta_&lt;/code&gt; field will overwrite all default values.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: Metadata modification happens before format selection, post-extraction and other post-processing operations. Some fields may be added or changed during these steps, overriding your changes.&lt;/p&gt; 
&lt;p&gt;For reference, these are the fields yt-dlp adds by default to the file metadata:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Metadata fields&lt;/th&gt; 
   &lt;th align="left"&gt;From&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;title&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;track&lt;/code&gt; or &lt;code&gt;title&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;date&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;upload_date&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;description&lt;/code&gt;, &lt;code&gt;synopsis&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;description&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;purl&lt;/code&gt;, &lt;code&gt;comment&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;webpage_url&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;track&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;track_number&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;artist&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;artist&lt;/code&gt;, &lt;code&gt;artists&lt;/code&gt;, &lt;code&gt;creator&lt;/code&gt;, &lt;code&gt;creators&lt;/code&gt;, &lt;code&gt;uploader&lt;/code&gt; or &lt;code&gt;uploader_id&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;composer&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;composer&lt;/code&gt; or &lt;code&gt;composers&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;genre&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;genre&lt;/code&gt; or &lt;code&gt;genres&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;album&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;album&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;album_artist&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;album_artist&lt;/code&gt; or &lt;code&gt;album_artists&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;disc&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;disc_number&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;show&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;series&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;season_number&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;season_number&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;episode_id&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;episode&lt;/code&gt; or &lt;code&gt;episode_id&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;episode_sort&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;episode_number&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;language&lt;/code&gt; of each stream&lt;/td&gt; 
   &lt;td align="left"&gt;the format's &lt;code&gt;language&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: The file format may not support some of these fields&lt;/p&gt; 
&lt;h2&gt;Modifying metadata examples&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Interpret the title as "Artist - Title"
$ yt-dlp --parse-metadata "title:%(artist)s - %(title)s"

# Regex example
$ yt-dlp --parse-metadata "description:Artist - (?P&amp;lt;artist&amp;gt;.+)"

# Set title as "Series name S01E05"
$ yt-dlp --parse-metadata "%(series)s S%(season_number)02dE%(episode_number)02d:%(title)s"

# Prioritize uploader as the "artist" field in video metadata
$ yt-dlp --parse-metadata "%(uploader|)s:%(meta_artist)s" --embed-metadata

# Set "comment" field in video metadata using description instead of webpage_url,
# handling multiple lines correctly
$ yt-dlp --parse-metadata "description:(?s)(?P&amp;lt;meta_comment&amp;gt;.+)" --embed-metadata

# Do not set any "synopsis" in the video metadata
$ yt-dlp --parse-metadata ":(?P&amp;lt;meta_synopsis&amp;gt;)"

# Remove "formats" field from the infojson by setting it to an empty string
$ yt-dlp --parse-metadata "video::(?P&amp;lt;formats&amp;gt;)" --write-info-json

# Replace all spaces and "_" in title and uploader with a `-`
$ yt-dlp --replace-in-metadata "title,uploader" "[ _]" "-"

&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;EXTRACTOR ARGUMENTS&lt;/h1&gt; 
&lt;p&gt;Some extractors accept additional arguments which can be passed using &lt;code&gt;--extractor-args KEY:ARGS&lt;/code&gt;. &lt;code&gt;ARGS&lt;/code&gt; is a &lt;code&gt;;&lt;/code&gt; (semicolon) separated string of &lt;code&gt;ARG=VAL1,VAL2&lt;/code&gt;. E.g. &lt;code&gt;--extractor-args "youtube:player-client=tv,mweb;formats=incomplete" --extractor-args "twitter:api=syndication"&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;Note: In CLI, &lt;code&gt;ARG&lt;/code&gt; can use &lt;code&gt;-&lt;/code&gt; instead of &lt;code&gt;_&lt;/code&gt;; e.g. &lt;code&gt;youtube:player-client"&lt;/code&gt; becomes &lt;code&gt;youtube:player_client"&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;The following extractors use this feature:&lt;/p&gt; 
&lt;h4&gt;youtube&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;lang&lt;/code&gt;: Prefer translated metadata (&lt;code&gt;title&lt;/code&gt;, &lt;code&gt;description&lt;/code&gt; etc) of this language code (case-sensitive). By default, the video primary language metadata is preferred, with a fallback to &lt;code&gt;en&lt;/code&gt; translated. See &lt;a href="https://github.com/yt-dlp/yt-dlp/raw/415b4c9f955b1a0391204bd24a7132590e7b3bdb/yt_dlp/extractor/youtube/_base.py#L402-L409"&gt;youtube/_base.py&lt;/a&gt; for the list of supported content language codes&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;skip&lt;/code&gt;: One or more of &lt;code&gt;hls&lt;/code&gt;, &lt;code&gt;dash&lt;/code&gt; or &lt;code&gt;translated_subs&lt;/code&gt; to skip extraction of the m3u8 manifests, dash manifests and &lt;a href="https://github.com/yt-dlp/yt-dlp/issues/4090#issuecomment-1158102032"&gt;auto-translated subtitles&lt;/a&gt; respectively&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;player_client&lt;/code&gt;: Clients to extract video data from. The currently available clients are &lt;code&gt;web&lt;/code&gt;, &lt;code&gt;web_safari&lt;/code&gt;, &lt;code&gt;web_embedded&lt;/code&gt;, &lt;code&gt;web_music&lt;/code&gt;, &lt;code&gt;web_creator&lt;/code&gt;, &lt;code&gt;mweb&lt;/code&gt;, &lt;code&gt;ios&lt;/code&gt;, &lt;code&gt;android&lt;/code&gt;, &lt;code&gt;android_vr&lt;/code&gt;, &lt;code&gt;tv&lt;/code&gt;, &lt;code&gt;tv_simply&lt;/code&gt; and &lt;code&gt;tv_embedded&lt;/code&gt;. By default, &lt;code&gt;tv,web_safari,web&lt;/code&gt; is used, and &lt;code&gt;tv,web_creator,web&lt;/code&gt; is used with premium accounts. The &lt;code&gt;web_music&lt;/code&gt; client is added for &lt;code&gt;music.youtube.com&lt;/code&gt; URLs when logged-in cookies are used. The &lt;code&gt;web_embedded&lt;/code&gt; client is added for age-restricted videos but only works if the video is embeddable. The &lt;code&gt;tv_embedded&lt;/code&gt; and &lt;code&gt;web_creator&lt;/code&gt; clients are added for age-restricted videos if account age-verification is required. Some clients, such as &lt;code&gt;web&lt;/code&gt; and &lt;code&gt;web_music&lt;/code&gt;, require a &lt;code&gt;po_token&lt;/code&gt; for their formats to be downloadable. Some clients, such as &lt;code&gt;web_creator&lt;/code&gt;, will only work with authentication. Not all clients support authentication via cookies. You can use &lt;code&gt;default&lt;/code&gt; for the default clients, or you can use &lt;code&gt;all&lt;/code&gt; for all clients (not recommended). You can prefix a client with &lt;code&gt;-&lt;/code&gt; to exclude it, e.g. &lt;code&gt;youtube:player_client=default,-ios&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;player_skip&lt;/code&gt;: Skip some network requests that are generally needed for robust extraction. One or more of &lt;code&gt;configs&lt;/code&gt; (skip client configs), &lt;code&gt;webpage&lt;/code&gt; (skip initial webpage), &lt;code&gt;js&lt;/code&gt; (skip js player), &lt;code&gt;initial_data&lt;/code&gt; (skip initial data/next ep request). While these options can help reduce the number of requests needed or avoid some rate-limiting, they could cause issues such as missing formats or metadata. See &lt;a href="https://github.com/yt-dlp/yt-dlp/pull/860"&gt;#860&lt;/a&gt; and &lt;a href="https://github.com/yt-dlp/yt-dlp/issues/12826"&gt;#12826&lt;/a&gt; for more details&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;webpage_skip&lt;/code&gt;: Skip extraction of embedded webpage data. One or both of &lt;code&gt;player_response&lt;/code&gt;, &lt;code&gt;initial_data&lt;/code&gt;. These options are for testing purposes and don't skip any network requests&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;player_params&lt;/code&gt;: YouTube player parameters to use for player requests. Will overwrite any default ones set by yt-dlp.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;player_js_variant&lt;/code&gt;: The player javascript variant to use for n/sig deciphering. The known variants are: &lt;code&gt;main&lt;/code&gt;, &lt;code&gt;tcc&lt;/code&gt;, &lt;code&gt;tce&lt;/code&gt;, &lt;code&gt;es5&lt;/code&gt;, &lt;code&gt;es6&lt;/code&gt;, &lt;code&gt;tv&lt;/code&gt;, &lt;code&gt;tv_es6&lt;/code&gt;, &lt;code&gt;phone&lt;/code&gt;, &lt;code&gt;tablet&lt;/code&gt;. The default is &lt;code&gt;main&lt;/code&gt;, and the others are for debugging purposes. You can use &lt;code&gt;actual&lt;/code&gt; to go with what is prescribed by the site&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;player_js_version&lt;/code&gt;: The player javascript version to use for n/sig deciphering, in the format of &lt;code&gt;signature_timestamp@hash&lt;/code&gt;. Currently, the default is to force &lt;code&gt;20348@0004de42&lt;/code&gt;. You can use &lt;code&gt;actual&lt;/code&gt; to go with what is prescribed by the site&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;comment_sort&lt;/code&gt;: &lt;code&gt;top&lt;/code&gt; or &lt;code&gt;new&lt;/code&gt; (default) - choose comment sorting mode (on YouTube's side)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;max_comments&lt;/code&gt;: Limit the amount of comments to gather. Comma-separated list of integers representing &lt;code&gt;max-comments,max-parents,max-replies,max-replies-per-thread&lt;/code&gt;. Default is &lt;code&gt;all,all,all,all&lt;/code&gt; 
  &lt;ul&gt; 
   &lt;li&gt;E.g. &lt;code&gt;all,all,1000,10&lt;/code&gt; will get a maximum of 1000 replies total, with up to 10 replies per thread. &lt;code&gt;1000,all,100&lt;/code&gt; will get a maximum of 1000 comments, with a maximum of 100 replies total&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;formats&lt;/code&gt;: Change the types of formats to return. &lt;code&gt;dashy&lt;/code&gt; (convert HTTP to DASH), &lt;code&gt;duplicate&lt;/code&gt; (identical content but different URLs or protocol; includes &lt;code&gt;dashy&lt;/code&gt;), &lt;code&gt;incomplete&lt;/code&gt; (cannot be downloaded completely - live dash and post-live m3u8), &lt;code&gt;missing_pot&lt;/code&gt; (include formats that require a PO Token but are missing one)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;innertube_host&lt;/code&gt;: Innertube API host to use for all API requests; e.g. &lt;code&gt;studio.youtube.com&lt;/code&gt;, &lt;code&gt;youtubei.googleapis.com&lt;/code&gt;. Note that cookies exported from one subdomain will not work on others&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;innertube_key&lt;/code&gt;: Innertube API key to use for all API requests. By default, no API key is used&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;raise_incomplete_data&lt;/code&gt;: &lt;code&gt;Incomplete Data Received&lt;/code&gt; raises an error instead of reporting a warning&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;data_sync_id&lt;/code&gt;: Overrides the account Data Sync ID used in Innertube API requests. This may be needed if you are using an account with &lt;code&gt;youtube:player_skip=webpage,configs&lt;/code&gt; or &lt;code&gt;youtubetab:skip=webpage&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;visitor_data&lt;/code&gt;: Overrides the Visitor Data used in Innertube API requests. This should be used with &lt;code&gt;player_skip=webpage,configs&lt;/code&gt; and without cookies. Note: this may have adverse effects if used improperly. If a session from a browser is wanted, you should pass cookies instead (which contain the Visitor ID)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;po_token&lt;/code&gt;: Proof of Origin (PO) Token(s) to use. Comma seperated list of PO Tokens in the format &lt;code&gt;CLIENT.CONTEXT+PO_TOKEN&lt;/code&gt;, e.g. &lt;code&gt;youtube:po_token=web.gvs+XXX,web.player=XXX,web_safari.gvs+YYY&lt;/code&gt;. Context can be any of &lt;code&gt;gvs&lt;/code&gt; (Google Video Server URLs), &lt;code&gt;player&lt;/code&gt; (Innertube player request) or &lt;code&gt;subs&lt;/code&gt; (Subtitles)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;pot_trace&lt;/code&gt;: Enable debug logging for PO Token fetching. Either &lt;code&gt;true&lt;/code&gt; or &lt;code&gt;false&lt;/code&gt; (default)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;fetch_pot&lt;/code&gt;: Policy to use for fetching a PO Token from providers. One of &lt;code&gt;always&lt;/code&gt; (always try fetch a PO Token regardless if the client requires one for the given context), &lt;code&gt;never&lt;/code&gt; (never fetch a PO Token), or &lt;code&gt;auto&lt;/code&gt; (default; only fetch a PO Token if the client requires one for the given context)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;playback_wait&lt;/code&gt;: Duration (in seconds) to wait inbetween the extraction and download stages in order to ensure the formats are available. The default is &lt;code&gt;6&lt;/code&gt; seconds&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;youtubepot-webpo&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;bind_to_visitor_id&lt;/code&gt;: Whether to use the Visitor ID instead of Visitor Data for caching WebPO tokens. Either &lt;code&gt;true&lt;/code&gt; (default) or &lt;code&gt;false&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;youtubetab (YouTube playlists, channels, feeds, etc.)&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;skip&lt;/code&gt;: One or more of &lt;code&gt;webpage&lt;/code&gt; (skip initial webpage download), &lt;code&gt;authcheck&lt;/code&gt; (allow the download of playlists requiring authentication when no initial webpage is downloaded. This may cause unwanted behavior, see &lt;a href="https://github.com/yt-dlp/yt-dlp/pull/1122"&gt;#1122&lt;/a&gt; for more details)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;approximate_date&lt;/code&gt;: Extract approximate &lt;code&gt;upload_date&lt;/code&gt; and &lt;code&gt;timestamp&lt;/code&gt; in flat-playlist. This may cause date-based filters to be slightly off&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;generic&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;fragment_query&lt;/code&gt;: Passthrough any query in mpd/m3u8 manifest URLs to their fragments if no value is provided, or else apply the query string given as &lt;code&gt;fragment_query=VALUE&lt;/code&gt;. Note that if the stream has an HLS AES-128 key, then the query parameters will be passed to the key URI as well, unless the &lt;code&gt;key_query&lt;/code&gt; extractor-arg is passed, or unless an external key URI is provided via the &lt;code&gt;hls_key&lt;/code&gt; extractor-arg. Does not apply to ffmpeg&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;variant_query&lt;/code&gt;: Passthrough the master m3u8 URL query to its variant playlist URLs if no value is provided, or else apply the query string given as &lt;code&gt;variant_query=VALUE&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;key_query&lt;/code&gt;: Passthrough the master m3u8 URL query to its HLS AES-128 decryption key URI if no value is provided, or else apply the query string given as &lt;code&gt;key_query=VALUE&lt;/code&gt;. Note that this will have no effect if the key URI is provided via the &lt;code&gt;hls_key&lt;/code&gt; extractor-arg. Does not apply to ffmpeg&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;hls_key&lt;/code&gt;: An HLS AES-128 key URI &lt;em&gt;or&lt;/em&gt; key (as hex), and optionally the IV (as hex), in the form of &lt;code&gt;(URI|KEY)[,IV]&lt;/code&gt;; e.g. &lt;code&gt;generic:hls_key=ABCDEF1234567980,0xFEDCBA0987654321&lt;/code&gt;. Passing any of these values will force usage of the native HLS downloader and override the corresponding values found in the m3u8 playlist&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;is_live&lt;/code&gt;: Bypass live HLS detection and manually set &lt;code&gt;live_status&lt;/code&gt; - a value of &lt;code&gt;false&lt;/code&gt; will set &lt;code&gt;not_live&lt;/code&gt;, any other value (or no value) will set &lt;code&gt;is_live&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;impersonate&lt;/code&gt;: Target(s) to try and impersonate with the initial webpage request; e.g. &lt;code&gt;generic:impersonate=safari,chrome-110&lt;/code&gt;. Use &lt;code&gt;generic:impersonate&lt;/code&gt; to impersonate any available target, and use &lt;code&gt;generic:impersonate=false&lt;/code&gt; to disable impersonation (default)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;vikichannel&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;video_types&lt;/code&gt;: Types of videos to download - one or more of &lt;code&gt;episodes&lt;/code&gt;, &lt;code&gt;movies&lt;/code&gt;, &lt;code&gt;clips&lt;/code&gt;, &lt;code&gt;trailers&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;youtubewebarchive&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;check_all&lt;/code&gt;: Try to check more at the cost of more requests. One or more of &lt;code&gt;thumbnails&lt;/code&gt;, &lt;code&gt;captures&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;gamejolt&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;comment_sort&lt;/code&gt;: &lt;code&gt;hot&lt;/code&gt; (default), &lt;code&gt;you&lt;/code&gt; (cookies needed), &lt;code&gt;top&lt;/code&gt;, &lt;code&gt;new&lt;/code&gt; - choose comment sorting mode (on GameJolt's side)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;hotstar&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;res&lt;/code&gt;: resolution to ignore - one or more of &lt;code&gt;sd&lt;/code&gt;, &lt;code&gt;hd&lt;/code&gt;, &lt;code&gt;fhd&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;vcodec&lt;/code&gt;: vcodec to ignore - one or more of &lt;code&gt;h264&lt;/code&gt;, &lt;code&gt;h265&lt;/code&gt;, &lt;code&gt;dvh265&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;dr&lt;/code&gt;: dynamic range to ignore - one or more of &lt;code&gt;sdr&lt;/code&gt;, &lt;code&gt;hdr10&lt;/code&gt;, &lt;code&gt;dv&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;instagram&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;app_id&lt;/code&gt;: The value of the &lt;code&gt;X-IG-App-ID&lt;/code&gt; header used for API requests. Default is the web app ID, &lt;code&gt;936619743392459&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;niconicochannelplus&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;max_comments&lt;/code&gt;: Maximum number of comments to extract - default is &lt;code&gt;120&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;tiktok&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;api_hostname&lt;/code&gt;: Hostname to use for mobile API calls, e.g. &lt;code&gt;api22-normal-c-alisg.tiktokv.com&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;app_name&lt;/code&gt;: Default app name to use with mobile API calls, e.g. &lt;code&gt;trill&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;app_version&lt;/code&gt;: Default app version to use with mobile API calls - should be set along with &lt;code&gt;manifest_app_version&lt;/code&gt;, e.g. &lt;code&gt;34.1.2&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;manifest_app_version&lt;/code&gt;: Default numeric app version to use with mobile API calls, e.g. &lt;code&gt;2023401020&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;aid&lt;/code&gt;: Default app ID to use with mobile API calls, e.g. &lt;code&gt;1180&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;app_info&lt;/code&gt;: Enable mobile API extraction with one or more app info strings in the format of &lt;code&gt;&amp;lt;iid&amp;gt;/[app_name]/[app_version]/[manifest_app_version]/[aid]&lt;/code&gt;, where &lt;code&gt;iid&lt;/code&gt; is the unique app install ID. &lt;code&gt;iid&lt;/code&gt; is the only required value; all other values and their &lt;code&gt;/&lt;/code&gt; separators can be omitted, e.g. &lt;code&gt;tiktok:app_info=1234567890123456789&lt;/code&gt; or &lt;code&gt;tiktok:app_info=123,456/trill///1180,789//34.0.1/340001&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;device_id&lt;/code&gt;: Enable mobile API extraction with a genuine device ID to be used with mobile API calls. Default is a random 19-digit string&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;rokfinchannel&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;tab&lt;/code&gt;: Which tab to download - one of &lt;code&gt;new&lt;/code&gt;, &lt;code&gt;top&lt;/code&gt;, &lt;code&gt;videos&lt;/code&gt;, &lt;code&gt;podcasts&lt;/code&gt;, &lt;code&gt;streams&lt;/code&gt;, &lt;code&gt;stacks&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;twitter&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;api&lt;/code&gt;: Select one of &lt;code&gt;graphql&lt;/code&gt; (default), &lt;code&gt;legacy&lt;/code&gt; or &lt;code&gt;syndication&lt;/code&gt; as the API for tweet extraction. Has no effect if logged in&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;stacommu, wrestleuniverse&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;device_id&lt;/code&gt;: UUID value assigned by the website and used to enforce device limits for paid livestream content. Can be found in browser local storage&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;twitch&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;client_id&lt;/code&gt;: Client ID value to be sent with GraphQL requests, e.g. &lt;code&gt;twitch:client_id=kimne78kx3ncx6brgo4mv6wki5h1ko&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;nhkradirulive (NHK らじる★らじる LIVE)&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;area&lt;/code&gt;: Which regional variation to extract. Valid areas are: &lt;code&gt;sapporo&lt;/code&gt;, &lt;code&gt;sendai&lt;/code&gt;, &lt;code&gt;tokyo&lt;/code&gt;, &lt;code&gt;nagoya&lt;/code&gt;, &lt;code&gt;osaka&lt;/code&gt;, &lt;code&gt;hiroshima&lt;/code&gt;, &lt;code&gt;matsuyama&lt;/code&gt;, &lt;code&gt;fukuoka&lt;/code&gt;. Defaults to &lt;code&gt;tokyo&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;nflplusreplay&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;type&lt;/code&gt;: Type(s) of game replays to extract. Valid types are: &lt;code&gt;full_game&lt;/code&gt;, &lt;code&gt;full_game_spanish&lt;/code&gt;, &lt;code&gt;condensed_game&lt;/code&gt; and &lt;code&gt;all_22&lt;/code&gt;. You can use &lt;code&gt;all&lt;/code&gt; to extract all available replay types, which is the default&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;jiocinema&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;refresh_token&lt;/code&gt;: The &lt;code&gt;refreshToken&lt;/code&gt; UUID from browser local storage can be passed to extend the life of your login session when logging in with &lt;code&gt;token&lt;/code&gt; as username and the &lt;code&gt;accessToken&lt;/code&gt; from browser local storage as password&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;jiosaavn&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;bitrate&lt;/code&gt;: Audio bitrates to request. One or more of &lt;code&gt;16&lt;/code&gt;, &lt;code&gt;32&lt;/code&gt;, &lt;code&gt;64&lt;/code&gt;, &lt;code&gt;128&lt;/code&gt;, &lt;code&gt;320&lt;/code&gt;. Default is &lt;code&gt;128,320&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;afreecatvlive&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;cdn&lt;/code&gt;: One or more CDN IDs to use with the API call for stream URLs, e.g. &lt;code&gt;gcp_cdn&lt;/code&gt;, &lt;code&gt;gs_cdn_pc_app&lt;/code&gt;, &lt;code&gt;gs_cdn_mobile_web&lt;/code&gt;, &lt;code&gt;gs_cdn_pc_web&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;soundcloud&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;formats&lt;/code&gt;: Formats to request from the API. Requested values should be in the format of &lt;code&gt;{protocol}_{codec}&lt;/code&gt;, e.g. &lt;code&gt;hls_opus,http_aac&lt;/code&gt;. The &lt;code&gt;*&lt;/code&gt; character functions as a wildcard, e.g. &lt;code&gt;*_mp3&lt;/code&gt;, and can be passed by itself to request all formats. Known protocols include &lt;code&gt;http&lt;/code&gt;, &lt;code&gt;hls&lt;/code&gt; and &lt;code&gt;hls-aes&lt;/code&gt;; known codecs include &lt;code&gt;aac&lt;/code&gt;, &lt;code&gt;opus&lt;/code&gt; and &lt;code&gt;mp3&lt;/code&gt;. Original &lt;code&gt;download&lt;/code&gt; formats are always extracted. Default is &lt;code&gt;http_aac,hls_aac,http_opus,hls_opus,http_mp3,hls_mp3&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;orfon (orf:on)&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;prefer_segments_playlist&lt;/code&gt;: Prefer a playlist of program segments instead of a single complete video when available. If individual segments are desired, use &lt;code&gt;--concat-playlist never --extractor-args "orfon:prefer_segments_playlist"&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;bilibili&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;prefer_multi_flv&lt;/code&gt;: Prefer extracting flv formats over mp4 for older videos that still provide legacy formats&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;sonylivseries&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;sort_order&lt;/code&gt;: Episode sort order for series extraction - one of &lt;code&gt;asc&lt;/code&gt; (ascending, oldest first) or &lt;code&gt;desc&lt;/code&gt; (descending, newest first). Default is &lt;code&gt;asc&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;tver&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;backend&lt;/code&gt;: Backend API to use for extraction - one of &lt;code&gt;streaks&lt;/code&gt; (default) or &lt;code&gt;brightcove&lt;/code&gt; (deprecated)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;vimeo&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;client&lt;/code&gt;: Client to extract video data from. The currently available clients are &lt;code&gt;android&lt;/code&gt;, &lt;code&gt;ios&lt;/code&gt;, and &lt;code&gt;web&lt;/code&gt;. Only one client can be used. The &lt;code&gt;web&lt;/code&gt; client is used by default. The &lt;code&gt;web&lt;/code&gt; client only works with account cookies or login credentials. The &lt;code&gt;android&lt;/code&gt; and &lt;code&gt;ios&lt;/code&gt; clients only work with previously cached OAuth tokens&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;original_format_policy&lt;/code&gt;: Policy for when to try extracting original formats. One of &lt;code&gt;always&lt;/code&gt;, &lt;code&gt;never&lt;/code&gt;, or &lt;code&gt;auto&lt;/code&gt;. The default &lt;code&gt;auto&lt;/code&gt; policy tries to avoid exceeding the web client's API rate-limit by only making an extra request when Vimeo publicizes the video's downloadability&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: These options may be changed/removed in the future without concern for backward compatibility&lt;/p&gt; 
&lt;!-- MANPAGE: MOVE "INSTALLATION" SECTION HERE --&gt; 
&lt;h1&gt;PLUGINS&lt;/h1&gt; 
&lt;p&gt;Note that &lt;strong&gt;all&lt;/strong&gt; plugins are imported even if not invoked, and that &lt;strong&gt;there are no checks&lt;/strong&gt; performed on plugin code. &lt;strong&gt;Use plugins at your own risk and only if you trust the code!&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Plugins can be of &lt;code&gt;&amp;lt;type&amp;gt;&lt;/code&gt;s &lt;code&gt;extractor&lt;/code&gt; or &lt;code&gt;postprocessor&lt;/code&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Extractor plugins do not need to be enabled from the CLI and are automatically invoked when the input URL is suitable for it.&lt;/li&gt; 
 &lt;li&gt;Extractor plugins take priority over built-in extractors.&lt;/li&gt; 
 &lt;li&gt;Postprocessor plugins can be invoked using &lt;code&gt;--use-postprocessor NAME&lt;/code&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Plugins are loaded from the namespace packages &lt;code&gt;yt_dlp_plugins.extractor&lt;/code&gt; and &lt;code&gt;yt_dlp_plugins.postprocessor&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;In other words, the file structure on the disk looks something like:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;    yt_dlp_plugins/
        extractor/
            myplugin.py
        postprocessor/
            myplugin.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;yt-dlp looks for these &lt;code&gt;yt_dlp_plugins&lt;/code&gt; namespace folders in many locations (see below) and loads in plugins from &lt;strong&gt;all&lt;/strong&gt; of them. Set the environment variable &lt;code&gt;YTDLP_NO_PLUGINS&lt;/code&gt; to something nonempty to disable loading plugins entirely.&lt;/p&gt; 
&lt;p&gt;See the &lt;a href="https://github.com/yt-dlp/yt-dlp/wiki/Plugins"&gt;wiki for some known plugins&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Installing Plugins&lt;/h2&gt; 
&lt;p&gt;Plugins can be installed using various methods and locations.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Configuration directories&lt;/strong&gt;: Plugin packages (containing a &lt;code&gt;yt_dlp_plugins&lt;/code&gt; namespace folder) can be dropped into the following standard &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#configuration"&gt;configuration locations&lt;/a&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;User Plugins&lt;/strong&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;code&gt;${XDG_CONFIG_HOME}/yt-dlp/plugins/&amp;lt;package name&amp;gt;/yt_dlp_plugins/&lt;/code&gt; (recommended on Linux/macOS)&lt;/li&gt; 
     &lt;li&gt;&lt;code&gt;${XDG_CONFIG_HOME}/yt-dlp-plugins/&amp;lt;package name&amp;gt;/yt_dlp_plugins/&lt;/code&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;code&gt;${APPDATA}/yt-dlp/plugins/&amp;lt;package name&amp;gt;/yt_dlp_plugins/&lt;/code&gt; (recommended on Windows)&lt;/li&gt; 
     &lt;li&gt;&lt;code&gt;${APPDATA}/yt-dlp-plugins/&amp;lt;package name&amp;gt;/yt_dlp_plugins/&lt;/code&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;code&gt;~/.yt-dlp/plugins/&amp;lt;package name&amp;gt;/yt_dlp_plugins/&lt;/code&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;code&gt;~/yt-dlp-plugins/&amp;lt;package name&amp;gt;/yt_dlp_plugins/&lt;/code&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;System Plugins&lt;/strong&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;code&gt;/etc/yt-dlp/plugins/&amp;lt;package name&amp;gt;/yt_dlp_plugins/&lt;/code&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;code&gt;/etc/yt-dlp-plugins/&amp;lt;package name&amp;gt;/yt_dlp_plugins/&lt;/code&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Executable location&lt;/strong&gt;: Plugin packages can similarly be installed in a &lt;code&gt;yt-dlp-plugins&lt;/code&gt; directory under the executable location (recommended for portable installations):&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Binary: where &lt;code&gt;&amp;lt;root-dir&amp;gt;/yt-dlp.exe&lt;/code&gt;, &lt;code&gt;&amp;lt;root-dir&amp;gt;/yt-dlp-plugins/&amp;lt;package name&amp;gt;/yt_dlp_plugins/&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;Source: where &lt;code&gt;&amp;lt;root-dir&amp;gt;/yt_dlp/__main__.py&lt;/code&gt;, &lt;code&gt;&amp;lt;root-dir&amp;gt;/yt-dlp-plugins/&amp;lt;package name&amp;gt;/yt_dlp_plugins/&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;pip and other locations in &lt;code&gt;PYTHONPATH&lt;/code&gt;&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Plugin packages can be installed and managed using &lt;code&gt;pip&lt;/code&gt;. See &lt;a href="https://github.com/yt-dlp/yt-dlp-sample-plugins"&gt;yt-dlp-sample-plugins&lt;/a&gt; for an example. 
    &lt;ul&gt; 
     &lt;li&gt;Note: plugin files between plugin packages installed with pip must have unique filenames.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;Any path in &lt;code&gt;PYTHONPATH&lt;/code&gt; is searched in for the &lt;code&gt;yt_dlp_plugins&lt;/code&gt; namespace folder. 
    &lt;ul&gt; 
     &lt;li&gt;Note: This does not apply for Pyinstaller builds.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;code&gt;.zip&lt;/code&gt;, &lt;code&gt;.egg&lt;/code&gt; and &lt;code&gt;.whl&lt;/code&gt; archives containing a &lt;code&gt;yt_dlp_plugins&lt;/code&gt; namespace folder in their root are also supported as plugin packages.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;e.g. &lt;code&gt;${XDG_CONFIG_HOME}/yt-dlp/plugins/mypluginpkg.zip&lt;/code&gt; where &lt;code&gt;mypluginpkg.zip&lt;/code&gt; contains &lt;code&gt;yt_dlp_plugins/&amp;lt;type&amp;gt;/myplugin.py&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Run yt-dlp with &lt;code&gt;--verbose&lt;/code&gt; to check if the plugin has been loaded.&lt;/p&gt; 
&lt;h2&gt;Developing Plugins&lt;/h2&gt; 
&lt;p&gt;See the &lt;a href="https://github.com/yt-dlp/yt-dlp-sample-plugins"&gt;yt-dlp-sample-plugins&lt;/a&gt; repo for a template plugin package and the &lt;a href="https://github.com/yt-dlp/yt-dlp/wiki/Plugin-Development"&gt;Plugin Development&lt;/a&gt; section of the wiki for a plugin development guide.&lt;/p&gt; 
&lt;p&gt;All public classes with a name ending in &lt;code&gt;IE&lt;/code&gt;/&lt;code&gt;PP&lt;/code&gt; are imported from each file for extractors and postprocessors respectively. This respects underscore prefix (e.g. &lt;code&gt;_MyBasePluginIE&lt;/code&gt; is private) and &lt;code&gt;__all__&lt;/code&gt;. Modules can similarly be excluded by prefixing the module name with an underscore (e.g. &lt;code&gt;_myplugin.py&lt;/code&gt;).&lt;/p&gt; 
&lt;p&gt;To replace an existing extractor with a subclass of one, set the &lt;code&gt;plugin_name&lt;/code&gt; class keyword argument (e.g. &lt;code&gt;class MyPluginIE(ABuiltInIE, plugin_name='myplugin')&lt;/code&gt; will replace &lt;code&gt;ABuiltInIE&lt;/code&gt; with &lt;code&gt;MyPluginIE&lt;/code&gt;). Since the extractor replaces the parent, you should exclude the subclass extractor from being imported separately by making it private using one of the methods described above.&lt;/p&gt; 
&lt;p&gt;If you are a plugin author, add &lt;a href="https://github.com/topics/yt-dlp-plugins"&gt;yt-dlp-plugins&lt;/a&gt; as a topic to your repository for discoverability.&lt;/p&gt; 
&lt;p&gt;See the &lt;a href="https://github.com/yt-dlp/yt-dlp/raw/master/CONTRIBUTING.md#developer-instructions"&gt;Developer Instructions&lt;/a&gt; on how to write and test an extractor.&lt;/p&gt; 
&lt;h1&gt;EMBEDDING YT-DLP&lt;/h1&gt; 
&lt;p&gt;yt-dlp makes the best effort to be a good command-line program, and thus should be callable from any programming language.&lt;/p&gt; 
&lt;p&gt;Your program should avoid parsing the normal stdout since they may change in future versions. Instead, they should use options such as &lt;code&gt;-J&lt;/code&gt;, &lt;code&gt;--print&lt;/code&gt;, &lt;code&gt;--progress-template&lt;/code&gt;, &lt;code&gt;--exec&lt;/code&gt; etc to create console output that you can reliably reproduce and parse.&lt;/p&gt; 
&lt;p&gt;From a Python program, you can embed yt-dlp in a more powerful fashion, like this:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from yt_dlp import YoutubeDL

URLS = ['https://www.youtube.com/watch?v=BaW_jenozKc']
with YoutubeDL() as ydl:
    ydl.download(URLS)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Most likely, you'll want to use various options. For a list of options available, have a look at &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/yt_dlp/YoutubeDL.py#L183"&gt;&lt;code&gt;yt_dlp/YoutubeDL.py&lt;/code&gt;&lt;/a&gt; or &lt;code&gt;help(yt_dlp.YoutubeDL)&lt;/code&gt; in a Python shell. If you are already familiar with the CLI, you can use &lt;a href="https://github.com/yt-dlp/yt-dlp/raw/master/devscripts/cli_to_api.py"&gt;&lt;code&gt;devscripts/cli_to_api.py&lt;/code&gt;&lt;/a&gt; to translate any CLI switches to &lt;code&gt;YoutubeDL&lt;/code&gt; params.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Tip&lt;/strong&gt;: If you are porting your code from youtube-dl to yt-dlp, one important point to look out for is that we do not guarantee the return value of &lt;code&gt;YoutubeDL.extract_info&lt;/code&gt; to be json serializable, or even be a dictionary. It will be dictionary-like, but if you want to ensure it is a serializable dictionary, pass it through &lt;code&gt;YoutubeDL.sanitize_info&lt;/code&gt; as shown in the &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#extracting-information"&gt;example below&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Embedding examples&lt;/h2&gt; 
&lt;h4&gt;Extracting information&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import json
import yt_dlp

URL = 'https://www.youtube.com/watch?v=BaW_jenozKc'

# ℹ️ See help(yt_dlp.YoutubeDL) for a list of available options and public functions
ydl_opts = {}
with yt_dlp.YoutubeDL(ydl_opts) as ydl:
    info = ydl.extract_info(URL, download=False)

    # ℹ️ ydl.sanitize_info makes the info json-serializable
    print(json.dumps(ydl.sanitize_info(info)))
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Download using an info-json&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import yt_dlp

INFO_FILE = 'path/to/video.info.json'

with yt_dlp.YoutubeDL() as ydl:
    error_code = ydl.download_with_info_file(INFO_FILE)

print('Some videos failed to download' if error_code
      else 'All videos successfully downloaded')
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Extract audio&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import yt_dlp

URLS = ['https://www.youtube.com/watch?v=BaW_jenozKc']

ydl_opts = {
    'format': 'm4a/bestaudio/best',
    # ℹ️ See help(yt_dlp.postprocessor) for a list of available Postprocessors and their arguments
    'postprocessors': [{  # Extract audio using ffmpeg
        'key': 'FFmpegExtractAudio',
        'preferredcodec': 'm4a',
    }]
}

with yt_dlp.YoutubeDL(ydl_opts) as ydl:
    error_code = ydl.download(URLS)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Filter videos&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import yt_dlp

URLS = ['https://www.youtube.com/watch?v=BaW_jenozKc']

def longer_than_a_minute(info, *, incomplete):
    """Download only videos longer than a minute (or with unknown duration)"""
    duration = info.get('duration')
    if duration and duration &amp;lt; 60:
        return 'The video is too short'

ydl_opts = {
    'match_filter': longer_than_a_minute,
}

with yt_dlp.YoutubeDL(ydl_opts) as ydl:
    error_code = ydl.download(URLS)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Adding logger and progress hook&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import yt_dlp

URLS = ['https://www.youtube.com/watch?v=BaW_jenozKc']

class MyLogger:
    def debug(self, msg):
        # For compatibility with youtube-dl, both debug and info are passed into debug
        # You can distinguish them by the prefix '[debug] '
        if msg.startswith('[debug] '):
            pass
        else:
            self.info(msg)

    def info(self, msg):
        pass

    def warning(self, msg):
        pass

    def error(self, msg):
        print(msg)


# ℹ️ See "progress_hooks" in help(yt_dlp.YoutubeDL)
def my_hook(d):
    if d['status'] == 'finished':
        print('Done downloading, now post-processing ...')


ydl_opts = {
    'logger': MyLogger(),
    'progress_hooks': [my_hook],
}

with yt_dlp.YoutubeDL(ydl_opts) as ydl:
    ydl.download(URLS)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Add a custom PostProcessor&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import yt_dlp

URLS = ['https://www.youtube.com/watch?v=BaW_jenozKc']

# ℹ️ See help(yt_dlp.postprocessor.PostProcessor)
class MyCustomPP(yt_dlp.postprocessor.PostProcessor):
    def run(self, info):
        self.to_screen('Doing stuff')
        return [], info


with yt_dlp.YoutubeDL() as ydl:
    # ℹ️ "when" can take any value in yt_dlp.utils.POSTPROCESS_WHEN
    ydl.add_post_processor(MyCustomPP(), when='pre_process')
    ydl.download(URLS)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Use a custom format selector&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import yt_dlp

URLS = ['https://www.youtube.com/watch?v=BaW_jenozKc']

def format_selector(ctx):
    """ Select the best video and the best audio that won't result in an mkv.
    NOTE: This is just an example and does not handle all cases """

    # formats are already sorted worst to best
    formats = ctx.get('formats')[::-1]

    # acodec='none' means there is no audio
    best_video = next(f for f in formats
                      if f['vcodec'] != 'none' and f['acodec'] == 'none')

    # find compatible audio extension
    audio_ext = {'mp4': 'm4a', 'webm': 'webm'}[best_video['ext']]
    # vcodec='none' means there is no video
    best_audio = next(f for f in formats if (
        f['acodec'] != 'none' and f['vcodec'] == 'none' and f['ext'] == audio_ext))

    # These are the minimum required fields for a merged format
    yield {
        'format_id': f'{best_video["format_id"]}+{best_audio["format_id"]}',
        'ext': best_video['ext'],
        'requested_formats': [best_video, best_audio],
        # Must be + separated list of protocols
        'protocol': f'{best_video["protocol"]}+{best_audio["protocol"]}'
    }


ydl_opts = {
    'format': format_selector,
}

with yt_dlp.YoutubeDL(ydl_opts) as ydl:
    ydl.download(URLS)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;CHANGES FROM YOUTUBE-DL&lt;/h1&gt; 
&lt;h3&gt;New features&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Forked from &lt;a href="https://github.com/blackjack4494/yt-dlc/commit/f9401f2a91987068139c5f757b12fc711d4c0cee"&gt;&lt;strong&gt;yt-dlc@f9401f2&lt;/strong&gt;&lt;/a&gt; and merged with &lt;a href="https://github.com/ytdl-org/youtube-dl/commit/a08f2b7e4567cdc50c0614ee0a4ffdff49b8b6e6"&gt;&lt;strong&gt;youtube-dl@a08f2b7&lt;/strong&gt;&lt;/a&gt; (&lt;a href="https://github.com/yt-dlp/yt-dlp/issues/21"&gt;exceptions&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#sponsorblock-options"&gt;SponsorBlock Integration&lt;/a&gt;&lt;/strong&gt;: You can mark/remove sponsor sections in YouTube videos by utilizing the &lt;a href="https://sponsor.ajay.app"&gt;SponsorBlock&lt;/a&gt; API&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#sorting-formats"&gt;Format Sorting&lt;/a&gt;&lt;/strong&gt;: The default format sorting options have been changed so that higher resolution and better codecs will be now preferred instead of simply using larger bitrate. Furthermore, you can now specify the sort order using &lt;code&gt;-S&lt;/code&gt;. This allows for much easier format selection than what is possible by simply using &lt;code&gt;--format&lt;/code&gt; (&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#format-selection-examples"&gt;examples&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Merged with animelover1984/youtube-dl&lt;/strong&gt;: You get most of the features and improvements from &lt;a href="https://github.com/animelover1984/youtube-dl"&gt;animelover1984/youtube-dl&lt;/a&gt; including &lt;code&gt;--write-comments&lt;/code&gt;, &lt;code&gt;BiliBiliSearch&lt;/code&gt;, &lt;code&gt;BilibiliChannel&lt;/code&gt;, Embedding thumbnail in mp4/ogg/opus, playlist infojson etc. See &lt;a href="https://github.com/yt-dlp/yt-dlp/pull/31"&gt;#31&lt;/a&gt; for details.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;YouTube improvements&lt;/strong&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Supports Clips, Stories (&lt;code&gt;ytstories:&amp;lt;channel UCID&amp;gt;&lt;/code&gt;), Search (including filters)&lt;strong&gt;*&lt;/strong&gt;, YouTube Music Search, Channel-specific search, Search prefixes (&lt;code&gt;ytsearch:&lt;/code&gt;, &lt;code&gt;ytsearchdate:&lt;/code&gt;)&lt;strong&gt;*&lt;/strong&gt;, Mixes, and Feeds (&lt;code&gt;:ytfav&lt;/code&gt;, &lt;code&gt;:ytwatchlater&lt;/code&gt;, &lt;code&gt;:ytsubs&lt;/code&gt;, &lt;code&gt;:ythistory&lt;/code&gt;, &lt;code&gt;:ytrec&lt;/code&gt;, &lt;code&gt;:ytnotif&lt;/code&gt;)&lt;/li&gt; 
   &lt;li&gt;Fix for &lt;a href="https://github.com/ytdl-org/youtube-dl/issues/29326"&gt;n-sig based throttling&lt;/a&gt; &lt;strong&gt;*&lt;/strong&gt;&lt;/li&gt; 
   &lt;li&gt;Download livestreams from the start using &lt;code&gt;--live-from-start&lt;/code&gt; (&lt;em&gt;experimental&lt;/em&gt;)&lt;/li&gt; 
   &lt;li&gt;Channel URLs download all uploads of the channel, including shorts and live&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Cookies from browser&lt;/strong&gt;: Cookies can be automatically extracted from all major web browsers using &lt;code&gt;--cookies-from-browser BROWSER[+KEYRING][:PROFILE][::CONTAINER]&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Download time range&lt;/strong&gt;: Videos can be downloaded partially based on either timestamps or chapters using &lt;code&gt;--download-sections&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Split video by chapters&lt;/strong&gt;: Videos can be split into multiple files based on chapters using &lt;code&gt;--split-chapters&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Multi-threaded fragment downloads&lt;/strong&gt;: Download multiple fragments of m3u8/mpd videos in parallel. Use &lt;code&gt;--concurrent-fragments&lt;/code&gt; (&lt;code&gt;-N&lt;/code&gt;) option to set the number of threads used&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Aria2c with HLS/DASH&lt;/strong&gt;: You can use &lt;code&gt;aria2c&lt;/code&gt; as the external downloader for DASH(mpd) and HLS(m3u8) formats&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;New and fixed extractors&lt;/strong&gt;: Many new extractors have been added and a lot of existing ones have been fixed. See the &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/Changelog.md"&gt;changelog&lt;/a&gt; or the &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/supportedsites.md"&gt;list of supported sites&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;New MSOs&lt;/strong&gt;: Philo, Spectrum, SlingTV, Cablevision, RCN etc.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Subtitle extraction from manifests&lt;/strong&gt;: Subtitles can be extracted from streaming media manifests. See &lt;a href="https://github.com/yt-dlp/yt-dlp/commit/be6202f12b97858b9d716e608394b51065d0419f"&gt;commit/be6202f&lt;/a&gt; for details&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Multiple paths and output templates&lt;/strong&gt;: You can give different &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#output-template"&gt;output templates&lt;/a&gt; and download paths for different types of files. You can also set a temporary path where intermediary files are downloaded to using &lt;code&gt;--paths&lt;/code&gt; (&lt;code&gt;-P&lt;/code&gt;)&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Portable Configuration&lt;/strong&gt;: Configuration files are automatically loaded from the home and root directories. See &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#configuration"&gt;CONFIGURATION&lt;/a&gt; for details&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Output template improvements&lt;/strong&gt;: Output templates can now have date-time formatting, numeric offsets, object traversal etc. See &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#output-template"&gt;output template&lt;/a&gt; for details. Even more advanced operations can also be done with the help of &lt;code&gt;--parse-metadata&lt;/code&gt; and &lt;code&gt;--replace-in-metadata&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Other new options&lt;/strong&gt;: Many new options have been added such as &lt;code&gt;--alias&lt;/code&gt;, &lt;code&gt;--print&lt;/code&gt;, &lt;code&gt;--concat-playlist&lt;/code&gt;, &lt;code&gt;--wait-for-video&lt;/code&gt;, &lt;code&gt;--retry-sleep&lt;/code&gt;, &lt;code&gt;--sleep-requests&lt;/code&gt;, &lt;code&gt;--convert-thumbnails&lt;/code&gt;, &lt;code&gt;--force-download-archive&lt;/code&gt;, &lt;code&gt;--force-overwrites&lt;/code&gt;, &lt;code&gt;--break-match-filters&lt;/code&gt; etc&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Improvements&lt;/strong&gt;: Regex and other operators in &lt;code&gt;--format&lt;/code&gt;/&lt;code&gt;--match-filters&lt;/code&gt;, multiple &lt;code&gt;--postprocessor-args&lt;/code&gt; and &lt;code&gt;--downloader-args&lt;/code&gt;, faster archive checking, more &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#format-selection"&gt;format selection options&lt;/a&gt;, merge multi-video/audio, multiple &lt;code&gt;--config-locations&lt;/code&gt;, &lt;code&gt;--exec&lt;/code&gt; at different stages, etc&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Plugins&lt;/strong&gt;: Extractors and PostProcessors can be loaded from an external file. See &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#plugins"&gt;plugins&lt;/a&gt; for details&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Self updater&lt;/strong&gt;: The releases can be updated using &lt;code&gt;yt-dlp -U&lt;/code&gt;, and downgraded using &lt;code&gt;--update-to&lt;/code&gt; if required&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Automated builds&lt;/strong&gt;: &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#update-channels"&gt;Nightly/master builds&lt;/a&gt; can be used with &lt;code&gt;--update-to nightly&lt;/code&gt; and &lt;code&gt;--update-to master&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/Changelog.md"&gt;changelog&lt;/a&gt; or &lt;a href="https://github.com/yt-dlp/yt-dlp/commits"&gt;commits&lt;/a&gt; for the full list of changes&lt;/p&gt; 
&lt;p&gt;Features marked with a &lt;strong&gt;*&lt;/strong&gt; have been back-ported to youtube-dl&lt;/p&gt; 
&lt;h3&gt;Differences in default behavior&lt;/h3&gt; 
&lt;p&gt;Some of yt-dlp's default options are different from that of youtube-dl and youtube-dlc:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;yt-dlp supports only &lt;a href="##" title="Windows 8"&gt;Python 3.9+&lt;/a&gt;, and will remove support for more versions as they &lt;a href="https://devguide.python.org/versions/#python-release-cycle"&gt;become EOL&lt;/a&gt;; while &lt;a href="https://github.com/ytdl-org/youtube-dl/issues/30568#issue-1118238743"&gt;youtube-dl still supports Python 2.6+ and 3.2+&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;The options &lt;code&gt;--auto-number&lt;/code&gt; (&lt;code&gt;-A&lt;/code&gt;), &lt;code&gt;--title&lt;/code&gt; (&lt;code&gt;-t&lt;/code&gt;) and &lt;code&gt;--literal&lt;/code&gt; (&lt;code&gt;-l&lt;/code&gt;), no longer work. See &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#Removed"&gt;removed options&lt;/a&gt; for details&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;avconv&lt;/code&gt; is not supported as an alternative to &lt;code&gt;ffmpeg&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;yt-dlp stores config files in slightly different locations to youtube-dl. See &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#configuration"&gt;CONFIGURATION&lt;/a&gt; for a list of correct locations&lt;/li&gt; 
 &lt;li&gt;The default &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#output-template"&gt;output template&lt;/a&gt; is &lt;code&gt;%(title)s [%(id)s].%(ext)s&lt;/code&gt;. There is no real reason for this change. This was changed before yt-dlp was ever made public and now there are no plans to change it back to &lt;code&gt;%(title)s-%(id)s.%(ext)s&lt;/code&gt;. Instead, you may use &lt;code&gt;--compat-options filename&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;The default &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#sorting-formats"&gt;format sorting&lt;/a&gt; is different from youtube-dl and prefers higher resolution and better codecs rather than higher bitrates. You can use the &lt;code&gt;--format-sort&lt;/code&gt; option to change this to any order you prefer, or use &lt;code&gt;--compat-options format-sort&lt;/code&gt; to use youtube-dl's sorting order. Older versions of yt-dlp preferred VP9 due to its broader compatibility; you can use &lt;code&gt;--compat-options prefer-vp9-sort&lt;/code&gt; to revert to that format sorting preference. These two compat options cannot be used together&lt;/li&gt; 
 &lt;li&gt;The default format selector is &lt;code&gt;bv*+ba/b&lt;/code&gt;. This means that if a combined video + audio format that is better than the best video-only format is found, the former will be preferred. Use &lt;code&gt;-f bv+ba/b&lt;/code&gt; or &lt;code&gt;--compat-options format-spec&lt;/code&gt; to revert this&lt;/li&gt; 
 &lt;li&gt;Unlike youtube-dlc, yt-dlp does not allow merging multiple audio/video streams into one file by default (since this conflicts with the use of &lt;code&gt;-f bv*+ba&lt;/code&gt;). If needed, this feature must be enabled using &lt;code&gt;--audio-multistreams&lt;/code&gt; and &lt;code&gt;--video-multistreams&lt;/code&gt;. You can also use &lt;code&gt;--compat-options multistreams&lt;/code&gt; to enable both&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--no-abort-on-error&lt;/code&gt; is enabled by default. Use &lt;code&gt;--abort-on-error&lt;/code&gt; or &lt;code&gt;--compat-options abort-on-error&lt;/code&gt; to abort on errors instead&lt;/li&gt; 
 &lt;li&gt;When writing metadata files such as thumbnails, description or infojson, the same information (if available) is also written for playlists. Use &lt;code&gt;--no-write-playlist-metafiles&lt;/code&gt; or &lt;code&gt;--compat-options no-playlist-metafiles&lt;/code&gt; to not write these files&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--add-metadata&lt;/code&gt; attaches the &lt;code&gt;infojson&lt;/code&gt; to &lt;code&gt;mkv&lt;/code&gt; files in addition to writing the metadata when used with &lt;code&gt;--write-info-json&lt;/code&gt;. Use &lt;code&gt;--no-embed-info-json&lt;/code&gt; or &lt;code&gt;--compat-options no-attach-info-json&lt;/code&gt; to revert this&lt;/li&gt; 
 &lt;li&gt;Some metadata are embedded into different fields when using &lt;code&gt;--add-metadata&lt;/code&gt; as compared to youtube-dl. Most notably, &lt;code&gt;comment&lt;/code&gt; field contains the &lt;code&gt;webpage_url&lt;/code&gt; and &lt;code&gt;synopsis&lt;/code&gt; contains the &lt;code&gt;description&lt;/code&gt;. You can &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#modifying-metadata"&gt;use &lt;code&gt;--parse-metadata&lt;/code&gt;&lt;/a&gt; to modify this to your liking or use &lt;code&gt;--compat-options embed-metadata&lt;/code&gt; to revert this&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;playlist_index&lt;/code&gt; behaves differently when used with options like &lt;code&gt;--playlist-reverse&lt;/code&gt; and &lt;code&gt;--playlist-items&lt;/code&gt;. See &lt;a href="https://github.com/yt-dlp/yt-dlp/issues/302"&gt;#302&lt;/a&gt; for details. You can use &lt;code&gt;--compat-options playlist-index&lt;/code&gt; if you want to keep the earlier behavior&lt;/li&gt; 
 &lt;li&gt;The output of &lt;code&gt;-F&lt;/code&gt; is listed in a new format. Use &lt;code&gt;--compat-options list-formats&lt;/code&gt; to revert this&lt;/li&gt; 
 &lt;li&gt;Live chats (if available) are considered as subtitles. Use &lt;code&gt;--sub-langs all,-live_chat&lt;/code&gt; to download all subtitles except live chat. You can also use &lt;code&gt;--compat-options no-live-chat&lt;/code&gt; to prevent any live chat/danmaku from downloading&lt;/li&gt; 
 &lt;li&gt;YouTube channel URLs download all uploads of the channel. To download only the videos in a specific tab, pass the tab's URL. If the channel does not show the requested tab, an error will be raised. Also, &lt;code&gt;/live&lt;/code&gt; URLs raise an error if there are no live videos instead of silently downloading the entire channel. You may use &lt;code&gt;--compat-options no-youtube-channel-redirect&lt;/code&gt; to revert all these redirections&lt;/li&gt; 
 &lt;li&gt;Unavailable videos are also listed for YouTube playlists. Use &lt;code&gt;--compat-options no-youtube-unavailable-videos&lt;/code&gt; to remove this&lt;/li&gt; 
 &lt;li&gt;The upload dates extracted from YouTube are in UTC.&lt;/li&gt; 
 &lt;li&gt;If &lt;code&gt;ffmpeg&lt;/code&gt; is used as the downloader, the downloading and merging of formats happen in a single step when possible. Use &lt;code&gt;--compat-options no-direct-merge&lt;/code&gt; to revert this&lt;/li&gt; 
 &lt;li&gt;Thumbnail embedding in &lt;code&gt;mp4&lt;/code&gt; is done with mutagen if possible. Use &lt;code&gt;--compat-options embed-thumbnail-atomicparsley&lt;/code&gt; to force the use of AtomicParsley instead&lt;/li&gt; 
 &lt;li&gt;Some internal metadata such as filenames are removed by default from the infojson. Use &lt;code&gt;--no-clean-infojson&lt;/code&gt; or &lt;code&gt;--compat-options no-clean-infojson&lt;/code&gt; to revert this&lt;/li&gt; 
 &lt;li&gt;When &lt;code&gt;--embed-subs&lt;/code&gt; and &lt;code&gt;--write-subs&lt;/code&gt; are used together, the subtitles are written to disk and also embedded in the media file. You can use just &lt;code&gt;--embed-subs&lt;/code&gt; to embed the subs and automatically delete the separate file. See &lt;a href="https://github.com/yt-dlp/yt-dlp/issues/630#issuecomment-893659460"&gt;#630 (comment)&lt;/a&gt; for more info. &lt;code&gt;--compat-options no-keep-subs&lt;/code&gt; can be used to revert this&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;certifi&lt;/code&gt; will be used for SSL root certificates, if installed. If you want to use system certificates (e.g. self-signed), use &lt;code&gt;--compat-options no-certifi&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;yt-dlp's sanitization of invalid characters in filenames is different/smarter than in youtube-dl. You can use &lt;code&gt;--compat-options filename-sanitization&lt;/code&gt; to revert to youtube-dl's behavior&lt;/li&gt; 
 &lt;li&gt;&lt;del&gt;yt-dlp tries to parse the external downloader outputs into the standard progress output if possible (Currently implemented: &lt;a href="https://github.com/yt-dlp/yt-dlp/issues/5931"&gt;aria2c&lt;/a&gt;). You can use &lt;code&gt;--compat-options no-external-downloader-progress&lt;/code&gt; to get the downloader output as-is&lt;/del&gt;&lt;/li&gt; 
 &lt;li&gt;yt-dlp versions between 2021.09.01 and 2023.01.02 applies &lt;code&gt;--match-filters&lt;/code&gt; to nested playlists. This was an unintentional side-effect of &lt;a href="https://github.com/yt-dlp/yt-dlp/commit/8f18aca8717bb0dd49054555af8d386e5eda3a88"&gt;8f18ac&lt;/a&gt; and is fixed in &lt;a href="https://github.com/yt-dlp/yt-dlp/commit/d7b460d0e5fc710950582baed2e3fc616ed98a80"&gt;d7b460&lt;/a&gt;. Use &lt;code&gt;--compat-options playlist-match-filter&lt;/code&gt; to revert this&lt;/li&gt; 
 &lt;li&gt;yt-dlp versions between 2021.11.10 and 2023.06.21 estimated &lt;code&gt;filesize_approx&lt;/code&gt; values for fragmented/manifest formats. This was added for convenience in &lt;a href="https://github.com/yt-dlp/yt-dlp/commit/f2fe69c7b0d208bdb1f6292b4ae92bc1e1a7444a"&gt;f2fe69&lt;/a&gt;, but was reverted in &lt;a href="https://github.com/yt-dlp/yt-dlp/commit/0dff8e4d1e6e9fb938f4256ea9af7d81f42fd54f"&gt;0dff8e&lt;/a&gt; due to the potentially extreme inaccuracy of the estimated values. Use &lt;code&gt;--compat-options manifest-filesize-approx&lt;/code&gt; to keep extracting the estimated values&lt;/li&gt; 
 &lt;li&gt;yt-dlp uses modern http client backends such as &lt;code&gt;requests&lt;/code&gt;. Use &lt;code&gt;--compat-options prefer-legacy-http-handler&lt;/code&gt; to prefer the legacy http handler (&lt;code&gt;urllib&lt;/code&gt;) to be used for standard http requests.&lt;/li&gt; 
 &lt;li&gt;The sub-modules &lt;code&gt;swfinterp&lt;/code&gt;, &lt;code&gt;casefold&lt;/code&gt; are removed.&lt;/li&gt; 
 &lt;li&gt;Passing &lt;code&gt;--simulate&lt;/code&gt; (or calling &lt;code&gt;extract_info&lt;/code&gt; with &lt;code&gt;download=False&lt;/code&gt;) no longer alters the default format selection. See &lt;a href="https://github.com/yt-dlp/yt-dlp/issues/9843"&gt;#9843&lt;/a&gt; for details.&lt;/li&gt; 
 &lt;li&gt;yt-dlp no longer applies the server modified time to downloaded files by default. Use &lt;code&gt;--mtime&lt;/code&gt; or &lt;code&gt;--compat-options mtime-by-default&lt;/code&gt; to revert this.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For ease of use, a few more compat options are available:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;--compat-options all&lt;/code&gt;: Use all compat options (&lt;strong&gt;Do NOT use this!&lt;/strong&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--compat-options youtube-dl&lt;/code&gt;: Same as &lt;code&gt;--compat-options all,-multistreams,-playlist-match-filter,-manifest-filesize-approx,-allow-unsafe-ext,-prefer-vp9-sort&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--compat-options youtube-dlc&lt;/code&gt;: Same as &lt;code&gt;--compat-options all,-no-live-chat,-no-youtube-channel-redirect,-playlist-match-filter,-manifest-filesize-approx,-allow-unsafe-ext,-prefer-vp9-sort&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--compat-options 2021&lt;/code&gt;: Same as &lt;code&gt;--compat-options 2022,no-certifi,filename-sanitization&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--compat-options 2022&lt;/code&gt;: Same as &lt;code&gt;--compat-options 2023,playlist-match-filter,no-external-downloader-progress,prefer-legacy-http-handler,manifest-filesize-approx&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--compat-options 2023&lt;/code&gt;: Same as &lt;code&gt;--compat-options 2024,prefer-vp9-sort&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--compat-options 2024&lt;/code&gt;: Same as &lt;code&gt;--compat-options mtime-by-default&lt;/code&gt;. Use this to enable all future compat options&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The following compat options restore vulnerable behavior from before security patches:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;--compat-options allow-unsafe-ext&lt;/code&gt;: Allow files with any extension (including unsafe ones) to be downloaded (&lt;a href="https://github.com/yt-dlp/yt-dlp/security/advisories/GHSA-79w7-vh3h-8g4j"&gt;GHSA-79w7-vh3h-8g4j&lt;/a&gt;)&lt;/p&gt; 
  &lt;blockquote&gt; 
   &lt;p&gt;&lt;span&gt;⚠&lt;/span&gt; Only use if a valid file download is rejected because its extension is detected as uncommon&lt;/p&gt; 
   &lt;p&gt;&lt;strong&gt;This option can enable remote code execution! Consider &lt;a href="https://github.com/yt-dlp/yt-dlp/issues/new/choose"&gt;opening an issue&lt;/a&gt; instead!&lt;/strong&gt;&lt;/p&gt; 
  &lt;/blockquote&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Deprecated options&lt;/h3&gt; 
&lt;p&gt;These are all the deprecated options and the current alternative to achieve the same effect&lt;/p&gt; 
&lt;h4&gt;Almost redundant options&lt;/h4&gt; 
&lt;p&gt;While these options are almost the same as their new counterparts, there are some differences that prevents them being redundant&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;-j, --dump-json                  --print "%()j"
-F, --list-formats               --print formats_table
--list-thumbnails                --print thumbnails_table --print playlist:thumbnails_table
--list-subs                      --print automatic_captions_table --print subtitles_table
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Redundant options&lt;/h4&gt; 
&lt;p&gt;While these options are redundant, they are still expected to be used due to their ease of use&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;--get-description                --print description
--get-duration                   --print duration_string
--get-filename                   --print filename
--get-format                     --print format
--get-id                         --print id
--get-thumbnail                  --print thumbnail
-e, --get-title                  --print title
-g, --get-url                    --print urls
--match-title REGEX              --match-filters "title ~= (?i)REGEX"
--reject-title REGEX             --match-filters "title !~= (?i)REGEX"
--min-views COUNT                --match-filters "view_count &amp;gt;=? COUNT"
--max-views COUNT                --match-filters "view_count &amp;lt;=? COUNT"
--break-on-reject                Use --break-match-filters
--user-agent UA                  --add-headers "User-Agent:UA"
--referer URL                    --add-headers "Referer:URL"
--playlist-start NUMBER          -I NUMBER:
--playlist-end NUMBER            -I :NUMBER
--playlist-reverse               -I ::-1
--no-playlist-reverse            Default
--no-colors                      --color no_color
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Not recommended&lt;/h4&gt; 
&lt;p&gt;While these options still work, their use is not recommended since there are other alternatives to achieve the same&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;--force-generic-extractor        --ies generic,default
--exec-before-download CMD       --exec "before_dl:CMD"
--no-exec-before-download        --no-exec
--all-formats                    -f all
--all-subs                       --sub-langs all --write-subs
--print-json                     -j --no-simulate
--autonumber-size NUMBER         Use string formatting, e.g. %(autonumber)03d
--autonumber-start NUMBER        Use internal field formatting like %(autonumber+NUMBER)s
--id                             -o "%(id)s.%(ext)s"
--metadata-from-title FORMAT     --parse-metadata "%(title)s:FORMAT"
--hls-prefer-native              --downloader "m3u8:native"
--hls-prefer-ffmpeg              --downloader "m3u8:ffmpeg"
--list-formats-old               --compat-options list-formats (Alias: --no-list-formats-as-table)
--list-formats-as-table          --compat-options -list-formats [Default]
--geo-bypass                     --xff "default"
--no-geo-bypass                  --xff "never"
--geo-bypass-country CODE        --xff CODE
--geo-bypass-ip-block IP_BLOCK   --xff IP_BLOCK
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Developer options&lt;/h4&gt; 
&lt;p&gt;These options are not intended to be used by the end-user&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;--test                           Download only part of video for testing extractors
--load-pages                     Load pages dumped by --write-pages
--allow-unplayable-formats       List unplayable formats also
--no-allow-unplayable-formats    Default
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Old aliases&lt;/h4&gt; 
&lt;p&gt;These are aliases that are no longer documented for various reasons&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;--clean-infojson                 --clean-info-json
--force-write-download-archive   --force-write-archive
--no-clean-infojson              --no-clean-info-json
--no-split-tracks                --no-split-chapters
--no-write-srt                   --no-write-subs
--prefer-unsecure                --prefer-insecure
--rate-limit RATE                --limit-rate RATE
--split-tracks                   --split-chapters
--srt-lang LANGS                 --sub-langs LANGS
--trim-file-names LENGTH         --trim-filenames LENGTH
--write-srt                      --write-subs
--yes-overwrites                 --force-overwrites
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Sponskrub Options&lt;/h4&gt; 
&lt;p&gt;Support for &lt;a href="https://github.com/faissaloo/SponSkrub"&gt;SponSkrub&lt;/a&gt; has been removed in favor of the &lt;code&gt;--sponsorblock&lt;/code&gt; options&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;--sponskrub                      --sponsorblock-mark all
--no-sponskrub                   --no-sponsorblock
--sponskrub-cut                  --sponsorblock-remove all
--no-sponskrub-cut               --sponsorblock-remove -all
--sponskrub-force                Not applicable
--no-sponskrub-force             Not applicable
--sponskrub-location             Not applicable
--sponskrub-args                 Not applicable
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;No longer supported&lt;/h4&gt; 
&lt;p&gt;These options may no longer work as intended&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;--prefer-avconv                  avconv is not officially supported by yt-dlp (Alias: --no-prefer-ffmpeg)
--prefer-ffmpeg                  Default (Alias: --no-prefer-avconv)
-C, --call-home                  Not implemented
--no-call-home                   Default
--include-ads                    No longer supported
--no-include-ads                 Default
--write-annotations              No supported site has annotations now
--no-write-annotations           Default
--avconv-location                Removed alias for --ffmpeg-location
--cn-verification-proxy URL      Removed alias for --geo-verification-proxy URL
--dump-headers                   Removed alias for --print-traffic
--dump-intermediate-pages        Removed alias for --dump-pages
--youtube-skip-dash-manifest     Removed alias for --extractor-args "youtube:skip=dash" (Alias: --no-youtube-include-dash-manifest)
--youtube-skip-hls-manifest      Removed alias for --extractor-args "youtube:skip=hls" (Alias: --no-youtube-include-hls-manifest)
--youtube-include-dash-manifest  Default (Alias: --no-youtube-skip-dash-manifest)
--youtube-include-hls-manifest   Default (Alias: --no-youtube-skip-hls-manifest)
--youtube-print-sig-code         Removed testing functionality
--dump-user-agent                No longer supported
--xattr-set-filesize             No longer supported
--compat-options seperate-video-versions  No longer needed
--compat-options no-youtube-prefer-utc-upload-date  No longer supported
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Removed&lt;/h4&gt; 
&lt;p&gt;These options were deprecated since 2014 and have now been entirely removed&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;-A, --auto-number                -o "%(autonumber)s-%(id)s.%(ext)s"
-t, -l, --title, --literal       -o "%(title)s-%(id)s.%(ext)s"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;CONTRIBUTING&lt;/h1&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/CONTRIBUTING.md#contributing-to-yt-dlp"&gt;CONTRIBUTING.md&lt;/a&gt; for instructions on &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/CONTRIBUTING.md#opening-an-issue"&gt;Opening an Issue&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/CONTRIBUTING.md#developer-instructions"&gt;Contributing code to the project&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;WIKI&lt;/h1&gt; 
&lt;p&gt;See the &lt;a href="https://github.com/yt-dlp/yt-dlp/wiki"&gt;Wiki&lt;/a&gt; for more information&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>