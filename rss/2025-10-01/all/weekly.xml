<rss version="2.0">
  <channel>
    <title>GitHub All Languages Weekly Trending</title>
    <description>Weekly Trending of All Languages in GitHub</description>
    <pubDate>Tue, 30 Sep 2025 01:41:22 GMT</pubDate>
    <link>http://mshibanami.github.io/GitHubTrendingRSS</link>
    
    <item>
      <title>humanlayer/humanlayer</title>
      <link>https://github.com/humanlayer/humanlayer</link>
      <description>&lt;p&gt;The best way to get AI coding agents to solve hard problems in complex codebases.&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/humanlayer/humanlayer/main/docs/images/wordmark-light.svg?sanitize=true" alt="Wordmark Logo of HumanLayer" /&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;h2&gt;The best way to get Coding Agents to solve hard problems in complex codebases&lt;/h2&gt; 
 &lt;p&gt;&lt;strong&gt;CodeLayer is an open source IDE that lets you orchestrate AI coding agents.&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;It comes with battle-tested workflows that enable AI to solve hard problems in large, complex codebases.&lt;/p&gt; 
 &lt;p&gt;Built on Claude Code. Open source. Scale from your laptop to your entire team.&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://github.com/humanlayer/humanlayer"&gt;&lt;img src="https://img.shields.io/github/stars/humanlayer/humanlayer" alt="GitHub Repo stars" /&gt;&lt;/a&gt; &lt;a href="https://opensource.org/licenses/Apache-2"&gt;&lt;img src="https://img.shields.io/badge/License-Apache-green.svg?sanitize=true" alt="License: Apache-2" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;h3&gt; &lt;p&gt;&lt;a href="https://humanlayer.dev/code"&gt;Join Waitlist&lt;/a&gt; | &lt;a href="https://humanlayer.dev/discord"&gt;Discord&lt;/a&gt;&lt;/p&gt; &lt;/h3&gt; 
 &lt;img referrerpolicy="no-referrer-when-downgrade" src="https://static.scarf.sh/a.png?x-pxid=fcfc0926-d841-47fb-b8a6-6aba3a6c3228" /&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;"Our entire company is using CodeLayer now. We're shipping one banger PR after the other. It is so f-ing good. Unbelievable dude."&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;‚Äì Ren√© Brandel, Founder @ Casco (YC X25)&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;hr /&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Superhuman for Claude Code&lt;/strong&gt; - Keyboard-first workflows designed for builders who value speed and control.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Advanced Context Engineering&lt;/strong&gt; - Scale AI-first dev to your entire team, without devolving into a chaotic slop-fest.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;M U L T I C L A U D E&lt;/strong&gt; - Run Claude Code sessions in parallel. Worktrees? Done. Remote cloud workers? You got it.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;"This has improved my productivity (and token consumption) by at least 50%. Taking a superhuman style approach just makes soo much sense. Also, its so freaking cool to look back at all the work you've done in a day."&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;‚Äì Tyler Brown, Founder @ Revlo.ai&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;hr /&gt; 
&lt;h2&gt;From the team that brought you "Context Engineering"&lt;/h2&gt; 
&lt;p&gt;Leading experts on getting the most out of today's models.&lt;/p&gt; 
&lt;h4&gt;&lt;a href="https://github.com/humanlayer/humanlayer"&gt;Advanced Context Engineering for Coding Agents&lt;/a&gt;&lt;/h4&gt; 
&lt;p&gt;This talk, given at YC on August 20th, 2025 lays out the groundwork for using AI to solve hard problems in complex codebases.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/humanlayer/humanlayer"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://humanlayer.dev/youtube"&gt;YouTube&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;&lt;a href="https://github.com/humanlayer/humanlayer"&gt;12 Factor Agents&lt;/a&gt;&lt;/h4&gt; 
&lt;p&gt;A set of principles for building reliable and scalable LLM applications, inspired by the original 12-Factor App methodology.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/humanlayer/humanlayer"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://humanlayer.dev/youtube"&gt;YouTube&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The original repo that coined the term "context engineering" back in April 2025.&lt;/p&gt; 
&lt;h4&gt;&lt;a href="https://humanlayer.dev/podcast"&gt;ü¶Ñ AI That Works&lt;/a&gt;&lt;/h4&gt; 
&lt;p&gt;A weekly conversation about how we can all get the most juice out of todays models with @hellovai &amp;amp; @dexhorthy&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/humanlayer/humanlayer"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://humanlayer.dev/podcast"&gt;Podcast&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;For Teams&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Invest in outcomes, not tools.&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Want to scale AI-first development to your entire org? Get tailored workflows, custom integrations, and cutting-edge advice.&lt;/p&gt; 
&lt;p&gt;HumanLayer's expert engineers will ship in the trenches with you and your team until everyone is a 100x engineer.&lt;/p&gt; 
&lt;p&gt;üìß Shoot us an email at &lt;strong&gt;&lt;a href="mailto:contact@humanlayer.dev"&gt;contact@humanlayer.dev&lt;/a&gt;&lt;/strong&gt;, mention your team size and current AI development stack.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Coming soon - join the waitlist for early access
npx humanlayer join-waitlist --email ...
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Legacy Documentation&lt;/h2&gt; 
&lt;p&gt;Looking for the HumanLayer SDK documentation? See &lt;a href="https://raw.githubusercontent.com/humanlayer/humanlayer/main/humanlayer.md"&gt;humanlayer.md&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;CodeLayer and the HumanLayer SDK are open-source and we welcome contributions in the form of issues, documentation, pull requests, and more. See &lt;a href="https://raw.githubusercontent.com/humanlayer/humanlayer/main/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;The HumanLayer SDK and CodeLayer sources in this repo are licensed under the Apache 2 License.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://star-history.com/#humanlayer/humanlayer&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=humanlayer/humanlayer&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>coinbase/x402</title>
      <link>https://github.com/coinbase/x402</link>
      <description>&lt;p&gt;A payments protocol for the internet. Built on HTTP.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;x402 payments protocol&lt;/h1&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;"1 line of code to accept digital dollars. No fee, 2 second settlement, $0.001 minimum payment."&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;pre&gt;&lt;code class="language-typescript"&gt;app.use(
  // How much you want to charge, and where you want the funds to land
  paymentMiddleware("0xYourAddress", { "/your-endpoint": "$0.01" })
);
// That's it! See examples/typescript/servers/express.ts for a complete example. Instruction below for running on base-sepolia.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Philosophy&lt;/h2&gt; 
&lt;p&gt;Payments on the internet are fundamentally flawed. Credit Cards are high friction, hard to accept, have minimum payments that are far too high, and don't fit into the programmatic nature of the internet. It's time for an open, internet-native form of payments. A payment rail that doesn't have high minimums + % based fee. Payments that are amazing for humans and AI agents.&lt;/p&gt; 
&lt;h2&gt;Principles&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Open standard:&lt;/strong&gt; the x402 protocol will never force reliance on a single party&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;HTTP Native:&lt;/strong&gt; x402 is meant to seamlessly complement the existing HTTP request made by traditional web services, it should not mandate additional requests outside the scope of a typical client / server flow.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Chain and token agnostic:&lt;/strong&gt; we welcome contributions that add support for new chains, signing standards, or schemes, so long as they meet our acceptance criteria laid out in &lt;a href="https://github.com/coinbase/x402/raw/main/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Trust minimizing:&lt;/strong&gt; all payment schemes must not allow for the facilitator or resource server to move funds, other than in accordance with client intentions&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Easy to use:&lt;/strong&gt; x402 needs to be 10x better than existing ways to pay on the internet. This means abstracting as many details of crypto as possible away from the client and resource server, and into the facilitator. This means the client/server should not need to think about gas, rpc, etc.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Ecosystem&lt;/h2&gt; 
&lt;p&gt;The x402 ecosystem is growing! Check out our &lt;a href="https://x402.org/ecosystem"&gt;ecosystem page&lt;/a&gt; to see projects building with x402, including:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Client-side integrations&lt;/li&gt; 
 &lt;li&gt;Services and endpoints&lt;/li&gt; 
 &lt;li&gt;Ecosystem infrastructure and tooling&lt;/li&gt; 
 &lt;li&gt;Learning and community resources&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Want to add your project to the ecosystem? See our &lt;a href="https://github.com/coinbase/x402/tree/main/typescript/site#adding-your-project-to-the-ecosystem"&gt;demo site README&lt;/a&gt; for detailed instructions on how to submit your project.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Roadmap:&lt;/strong&gt; see &lt;a href="https://github.com/coinbase/x402/raw/main/ROADMAP.md"&gt;ROADMAP.md&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Terms:&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;resource&lt;/code&gt;: Something on the internet. This could be a webpage, file server, RPC service, API, any resource on the internet that accepts HTTP / HTTPS requests.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;client&lt;/code&gt;: An entity wanting to pay for a resource.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;facilitator server&lt;/code&gt;: A server that facilitates verification and execution of on-chain payments.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;resource server&lt;/code&gt;: An HTTP server that provides an API or other resource for a client.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Technical Goals:&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Permissionless and secure for clients and servers&lt;/li&gt; 
 &lt;li&gt;Gasless for client and resource servers&lt;/li&gt; 
 &lt;li&gt;Minimal integration for the resource server and client (1 line for the server, 1 function for the client)&lt;/li&gt; 
 &lt;li&gt;Ability to trade off speed of response for guarantee of payment&lt;/li&gt; 
 &lt;li&gt;Extensible to different payment flows and chains&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;V1 Protocol&lt;/h2&gt; 
&lt;p&gt;The &lt;code&gt;x402&lt;/code&gt; protocol is a chain agnostic standard for payments on top of HTTP, leverage the existing &lt;code&gt;402 Payment Required&lt;/code&gt; HTTP status code to indicate that a payment is required for access to the resource.&lt;/p&gt; 
&lt;p&gt;It specifies:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;A schema for how servers can respond to clients to facilitate payment for a resource (&lt;code&gt;PaymentRequirements&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;A standard header &lt;code&gt;X-PAYMENT&lt;/code&gt; that is set by clients paying for resources&lt;/li&gt; 
 &lt;li&gt;A standard schema and encoding method for data in the &lt;code&gt;X-PAYMENT&lt;/code&gt; header&lt;/li&gt; 
 &lt;li&gt;A recommended flow for how payments should be verified and settled by a resource server&lt;/li&gt; 
 &lt;li&gt;A REST specification for how a resource server can perform verification and settlement against a remote 3rd party server (&lt;code&gt;facilitator&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;A specification for a &lt;code&gt;X-PAYMENT-RESPONSE&lt;/code&gt; header that can be used by resource servers to communicate blockchain transactions details to the client in their HTTP response&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;V1 Protocol Sequencing&lt;/h3&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/coinbase/x402/main/static/x402-protocol-flow.png" alt="" /&gt;&lt;/p&gt; 
&lt;p&gt;The following outlines the flow of a payment using the &lt;code&gt;x402&lt;/code&gt; protocol. Note that steps (1) and (2) are optional if the client already knows the payment details accepted for a resource.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;Client&lt;/code&gt; makes an HTTP request to a &lt;code&gt;resource server&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;Resource server&lt;/code&gt; responds with a &lt;code&gt;402 Payment Required&lt;/code&gt; status and a &lt;code&gt;Payment Required Response&lt;/code&gt; JSON object in the response body.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;Client&lt;/code&gt; selects one of the &lt;code&gt;paymentRequirements&lt;/code&gt; returned by the server response and creates a &lt;code&gt;Payment Payload&lt;/code&gt; based on the &lt;code&gt;scheme&lt;/code&gt; of the &lt;code&gt;paymentRequirements&lt;/code&gt; they have selected.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;Client&lt;/code&gt; sends the HTTP request with the &lt;code&gt;X-PAYMENT&lt;/code&gt; header containing the &lt;code&gt;Payment Payload&lt;/code&gt; to the resource server.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;Resource server&lt;/code&gt; verifies the &lt;code&gt;Payment Payload&lt;/code&gt; is valid either via local verification or by POSTing the &lt;code&gt;Payment Payload&lt;/code&gt; and &lt;code&gt;Payment Requirements&lt;/code&gt; to the &lt;code&gt;/verify&lt;/code&gt; endpoint of a &lt;code&gt;facilitator server&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;Facilitator server&lt;/code&gt; performs verification of the object based on the &lt;code&gt;scheme&lt;/code&gt; and &lt;code&gt;network&lt;/code&gt; of the &lt;code&gt;Payment Payload&lt;/code&gt; and returns a &lt;code&gt;Verification Response&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;If the &lt;code&gt;Verification Response&lt;/code&gt; is valid, the resource server performs the work to fulfill the request. If the &lt;code&gt;Verification Response&lt;/code&gt; is invalid, the resource server returns a &lt;code&gt;402 Payment Required&lt;/code&gt; status and a &lt;code&gt;Payment Required Response&lt;/code&gt; JSON object in the response body.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;Resource server&lt;/code&gt; either settles the payment by interacting with a blockchain directly, or by POSTing the &lt;code&gt;Payment Payload&lt;/code&gt; and &lt;code&gt;Payment PaymentRequirements&lt;/code&gt; to the &lt;code&gt;/settle&lt;/code&gt; endpoint of a &lt;code&gt;facilitator server&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;Facilitator server&lt;/code&gt; submits the payment to the blockchain based on the &lt;code&gt;scheme&lt;/code&gt; and &lt;code&gt;network&lt;/code&gt; of the &lt;code&gt;Payment Payload&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;Facilitator server&lt;/code&gt; waits for the payment to be confirmed on the blockchain.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;Facilitator server&lt;/code&gt; returns a &lt;code&gt;Payment Execution Response&lt;/code&gt; to the resource server.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;Resource server&lt;/code&gt; returns a &lt;code&gt;200 OK&lt;/code&gt; response to the &lt;code&gt;Client&lt;/code&gt; with the resource they requested as the body of the HTTP response, and a &lt;code&gt;X-PAYMENT-RESPONSE&lt;/code&gt; header containing the &lt;code&gt;Settlement Response&lt;/code&gt; as Base64 encoded JSON if the payment was executed successfully.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Type Specifications&lt;/h3&gt; 
&lt;h4&gt;Data types&lt;/h4&gt; 
&lt;p&gt;&lt;strong&gt;Payment Required Response&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json5"&gt;{
  // Version of the x402 payment protocol
  x402Version: int,

  // List of payment requirements that the resource server accepts. A resource server may accept on multiple chains, or in multiple currencies.
  accepts: [paymentRequirements]

  // Message from the resource server to the client to communicate errors in processing payment
  error: string
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;paymentRequirements&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json5"&gt;{
  // Scheme of the payment protocol to use
  scheme: string;

  // Network of the blockchain to send payment on
  network: string;

  // Maximum amount required to pay for the resource in atomic units of the asset
  maxAmountRequired: uint256 as string;

  // URL of resource to pay for
  resource: string;

  // Description of the resource
  description: string;

  // MIME type of the resource response
  mimeType: string;

  // Output schema of the resource response
  outputSchema?: object | null;

  // Address to pay value to
  payTo: string;

  // Maximum time in seconds for the resource server to respond
  maxTimeoutSeconds: number;

  // Address of the EIP-3009 compliant ERC20 contract
  asset: string;

  // Extra information about the payment details specific to the scheme
  // For `exact` scheme on a EVM network, expects extra to contain the records `name` and `version` pertaining to asset
  extra: object | null;
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;&lt;code&gt;Payment Payload&lt;/code&gt;&lt;/strong&gt; (included as the &lt;code&gt;X-PAYMENT&lt;/code&gt; header in base64 encoded json)&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json5"&gt;{
  // Version of the x402 payment protocol
  x402Version: number;

  // scheme is the scheme value of the accepted `paymentRequirements` the client is using to pay
  scheme: string;

  // network is the network id of the accepted `paymentRequirements` the client is using to pay
  network: string;

  // payload is scheme dependent
  payload: &amp;lt;scheme dependent&amp;gt;;
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Facilitator Types &amp;amp; Interface&lt;/h4&gt; 
&lt;p&gt;A &lt;code&gt;facilitator server&lt;/code&gt; is a 3rd party service that can be used by a &lt;code&gt;resource server&lt;/code&gt; to verify and settle payments, without the &lt;code&gt;resource server&lt;/code&gt; needing to have access to a blockchain node or wallet.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;POST /verify&lt;/strong&gt;. Verify a payment with a supported scheme and network:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Request body JSON: &lt;pre&gt;&lt;code class="language-json5"&gt;{
  x402Version: number;
  paymentHeader: string;
  paymentRequirements: paymentRequirements;
}
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;Response: &lt;pre&gt;&lt;code class="language-json5"&gt;{
  isValid: boolean;
  invalidReason: string | null;
}
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;POST /settle&lt;/strong&gt;. Settle a payment with a supported scheme and network:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Request body JSON:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-json5"&gt;{
  x402Version: number;
  paymentHeader: string;
  paymentRequirements: paymentRequirements;
}
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Response:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-json5"&gt;{
  // Whether the payment was successful
  success: boolean;

  // Error message from the facilitator server
  error: string | null;

  // Transaction hash of the settled payment
  txHash: string | null;

  // Network id of the blockchain the payment was settled on
  networkId: string | null;
}
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;GET /supported&lt;/strong&gt;. Get supported payment schemes and networks:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Response: &lt;pre&gt;&lt;code class="language-json5"&gt;{
  kinds: [
    {
      "scheme": string,
      "network": string,
    }
  ]
}
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Schemes&lt;/h3&gt; 
&lt;p&gt;A scheme is a logical way of moving money.&lt;/p&gt; 
&lt;p&gt;Blockchains allow for a large number of flexible ways to move money. To help facilitate an expanding number of payment use cases, the &lt;code&gt;x402&lt;/code&gt; protocol is extensible to different ways of settling payments via its &lt;code&gt;scheme&lt;/code&gt; field.&lt;/p&gt; 
&lt;p&gt;Each payment scheme may have different operational functionality depending on what actions are necessary to fulfill the payment. For example &lt;code&gt;exact&lt;/code&gt;, the first scheme shipping as part of the protocol, would have different behavior than &lt;code&gt;upto&lt;/code&gt;. &lt;code&gt;exact&lt;/code&gt; transfers a specific amount (ex: pay $1 to read an article), while a theoretical &lt;code&gt;upto&lt;/code&gt; would transfer up to an amount, based on the resources consumed during a request (ex: generating tokens from an LLM).&lt;/p&gt; 
&lt;p&gt;See &lt;code&gt;specs/schemes&lt;/code&gt; for more details on schemes, and see &lt;code&gt;specs/schemes/exact/scheme_exact_evm.md&lt;/code&gt; to see the first proposed scheme for exact payment on EVM chains.&lt;/p&gt; 
&lt;h3&gt;Schemes vs Networks&lt;/h3&gt; 
&lt;p&gt;Because a scheme is a logical way of moving money, the way a scheme is implemented can be different for different blockchains. (ex: the way you need to implement &lt;code&gt;exact&lt;/code&gt; on Ethereum is very different from the way you need to implement &lt;code&gt;exact&lt;/code&gt; on Solana).&lt;/p&gt; 
&lt;p&gt;Clients and facilitators must explicitly support different &lt;code&gt;(scheme, network)&lt;/code&gt; pairs in order to be able to create proper payloads and verify / settle payments.&lt;/p&gt; 
&lt;h2&gt;Running example&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Requirements:&lt;/strong&gt; Node.js v24 or higher&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;From &lt;code&gt;examples/typescript&lt;/code&gt; run &lt;code&gt;pnpm install&lt;/code&gt; and &lt;code&gt;pnpm build&lt;/code&gt; to ensure all dependent packages and examples are setup.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Select a server, i.e. express, and &lt;code&gt;cd&lt;/code&gt; into that example. Add your server's ethereum address to get paid to into the &lt;code&gt;.env&lt;/code&gt; file, and then run &lt;code&gt;pnpm dev&lt;/code&gt; in that directory.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Select a client, i.e. axios, and &lt;code&gt;cd&lt;/code&gt; into that example. Add your private key for the account making payments into the &lt;code&gt;.env&lt;/code&gt; file, and then run &lt;code&gt;pnpm dev&lt;/code&gt; in that directory.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;You should see activities in the client terminal, which will display a weather report.&lt;/p&gt; 
&lt;h2&gt;Running tests&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;Navigate to the typescript directory: &lt;code&gt;cd typescript&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Install dependencies: &lt;code&gt;pnpm install&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Run the unit tests: &lt;code&gt;pnpm test&lt;/code&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;This will run the unit tests for the x402 packages.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>kamranahmedse/developer-roadmap</title>
      <link>https://github.com/kamranahmedse/developer-roadmap</link>
      <description>&lt;p&gt;Interactive roadmaps, guides and other educational content to help developers grow in their careers.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;a href="https://roadmap.sh/"&gt;&lt;img src="https://raw.githubusercontent.com/kamranahmedse/developer-roadmap/master/public/img/brand.png" height="128" /&gt;&lt;/a&gt; &lt;/p&gt;
&lt;h2 align="center"&gt;&lt;a href="https://roadmap.sh"&gt;roadmap.sh&lt;/a&gt;&lt;/h2&gt; 
&lt;p align="center"&gt;Community driven roadmaps, articles and resources for developers&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p align="center"&gt; &lt;a href="https://roadmap.sh/roadmaps"&gt; &lt;img src="https://img.shields.io/badge/%E2%9C%A8-Roadmaps%20-0a0a0a.svg?style=flat&amp;amp;colorA=0a0a0a" alt="roadmaps" /&gt; &lt;/a&gt; &lt;a href="https://roadmap.sh/best-practices"&gt; &lt;img src="https://img.shields.io/badge/%E2%9C%A8-Best%20Practices-0a0a0a.svg?style=flat&amp;amp;colorA=0a0a0a" alt="best practices" /&gt; &lt;/a&gt; &lt;a href="https://roadmap.sh/questions"&gt; &lt;img src="https://img.shields.io/badge/%E2%9C%A8-Questions-0a0a0a.svg?style=flat&amp;amp;colorA=0a0a0a" alt="videos" /&gt; &lt;/a&gt; &lt;a href="https://www.youtube.com/channel/UCA0H2KIWgWTwpTFjSxp0now?sub_confirmation=1"&gt; &lt;img src="https://img.shields.io/badge/%E2%9C%A8-YouTube%20Channel-0a0a0a.svg?style=flat&amp;amp;colorA=0a0a0a" alt="roadmaps" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;br /&gt; 
&lt;p&gt;&lt;img src="https://i.imgur.com/waxVImv.png" alt="" /&gt;&lt;/p&gt; 
&lt;p&gt;Roadmaps are now interactive, you can click the nodes to read more about the topics.&lt;/p&gt; 
&lt;h3&gt;&lt;a href="https://roadmap.sh"&gt;View all Roadmaps&lt;/a&gt; &amp;nbsp;¬∑&amp;nbsp; &lt;a href="https://roadmap.sh/best-practices"&gt;Best Practices&lt;/a&gt; &amp;nbsp;¬∑&amp;nbsp; &lt;a href="https://roadmap.sh/questions"&gt;Questions&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;img src="https://i.imgur.com/waxVImv.png" alt="" /&gt;&lt;/p&gt; 
&lt;p&gt;Here is the list of available roadmaps with more being actively worked upon.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Have a look at the &lt;a href="https://roadmap.sh/get-started"&gt;get started&lt;/a&gt; page that might help you pick up a path.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/frontend"&gt;Frontend Roadmap&lt;/a&gt; / &lt;a href="https://roadmap.sh/frontend?r=frontend-beginner"&gt;Frontend Beginner Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/backend"&gt;Backend Roadmap&lt;/a&gt; / &lt;a href="https://roadmap.sh/backend?r=backend-beginner"&gt;Backend Beginner Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/devops"&gt;DevOps Roadmap&lt;/a&gt; / &lt;a href="https://roadmap.sh/devops?r=devops-beginner"&gt;DevOps Beginner Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/full-stack"&gt;Full Stack Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/html"&gt;HTML Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/css"&gt;CSS Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/javascript"&gt;JavaScript Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/typescript"&gt;TypeScript Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/git-github"&gt;Git and GitHub&lt;/a&gt; / &lt;a href="https://roadmap.sh/git-github?r=git-github-beginner"&gt;Git and GitHub Beginner&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/api-design"&gt;API Design Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/computer-science"&gt;Computer Science Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/datastructures-and-algorithms"&gt;Data Structures and Algorithms Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/ai-data-scientist"&gt;AI and Data Scientist Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/ai-engineer"&gt;AI Engineer Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/aws"&gt;AWS Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/cloudflare"&gt;Cloudflare Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/linux"&gt;Linux Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/terraform"&gt;Terraform Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/data-analyst"&gt;Data Analyst Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/bi-analyst"&gt;BI Analyst Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/data-engineer"&gt;Data Engineer Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/machine-learning"&gt;Machine Learning Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/mlops"&gt;MLOps Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/product-manager"&gt;Product Manager Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/engineering-manager"&gt;Engineering Manager Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/qa"&gt;QA Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/python"&gt;Python Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/software-architect"&gt;Software Architect Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/game-developer"&gt;Game Developer Roadmap&lt;/a&gt; / &lt;a href="https://roadmap.sh/server-side-game-developer"&gt;Server Side Game Developer&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/software-design-architecture"&gt;Software Design and Architecture Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/cpp"&gt;C++ Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/react"&gt;React Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/nextjs"&gt;Next.js Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/react-native"&gt;React Native Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/vue"&gt;Vue Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/angular"&gt;Angular Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/nodejs"&gt;Node.js Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/php"&gt;PHP Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/graphql"&gt;GraphQL Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/android"&gt;Android Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/ios"&gt;iOS Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/flutter"&gt;Flutter Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/golang"&gt;Go Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/rust"&gt;Rust Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/java"&gt;Java Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/kotlin"&gt;Kotlin Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/spring-boot"&gt;Spring Boot Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/design-system"&gt;Design System Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/postgresql-dba"&gt;PostgreSQL Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/sql"&gt;SQL Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/redis"&gt;Redis Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/blockchain"&gt;Blockchain Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/aspnet-core"&gt;ASP.NET Core Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/system-design"&gt;System Design Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/kubernetes"&gt;Kubernetes Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/cyber-security"&gt;Cyber Security Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/mongodb"&gt;MongoDB Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/ux-design"&gt;UX Design Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/docker"&gt;Docker Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/prompt-engineering"&gt;Prompt Engineering Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/technical-writer"&gt;Technical Writer Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/devrel"&gt;DevRel Engineer Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/ai-red-teaming"&gt;AI Red Teaming Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/ai-agents"&gt;AI Agents Roadmap&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;There are also interactive best practices:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/best-practices/backend-performance"&gt;Backend Performance Best Practices&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/best-practices/frontend-performance"&gt;Frontend Performance Best Practices&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/best-practices/code-review"&gt;Code Review Best Practices&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/best-practices/api-security"&gt;API Security Best Practices&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/best-practices/aws"&gt;AWS Best Practices&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;..and questions to help you test, rate and improve your knowledge&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/questions/javascript"&gt;JavaScript Questions&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/questions/nodejs"&gt;Node.js Questions&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/questions/react"&gt;React Questions&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/questions/backend"&gt;Backend Questions&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/questions/frontend"&gt;Frontend Questions&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://i.imgur.com/waxVImv.png" alt="" /&gt;&lt;/p&gt; 
&lt;h2&gt;Share with the community&lt;/h2&gt; 
&lt;p&gt;Please consider sharing a post about &lt;a href="https://roadmap.sh"&gt;roadmap.sh&lt;/a&gt; and the value it provides. It really does help!&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://reddit.com/submit?url=https://roadmap.sh&amp;amp;title=Interactive%20roadmaps,%20guides%20and%20other%20educational%20content%20for%20Developers"&gt;&lt;img src="https://img.shields.io/badge/share%20on-reddit-red?logo=reddit" alt="GitHub Repo stars" /&gt;&lt;/a&gt; &lt;a href="https://news.ycombinator.com/submitlink?u=https://roadmap.sh"&gt;&lt;img src="https://img.shields.io/badge/share%20on-hacker%20news-orange?logo=ycombinator" alt="GitHub Repo stars" /&gt;&lt;/a&gt; &lt;a href="https://twitter.com/share?url=https://roadmap.sh&amp;amp;text=Interactive%20roadmaps,%20guides%20and%20other%20educational%20content%20for%20Developers"&gt;&lt;img src="https://img.shields.io/badge/share%20on-twitter-03A9F4?logo=twitter" alt="GitHub Repo stars" /&gt;&lt;/a&gt; &lt;a href="https://www.facebook.com/sharer/sharer.php?u=https://roadmap.sh"&gt;&lt;img src="https://img.shields.io/badge/share%20on-facebook-1976D2?logo=facebook" alt="GitHub Repo stars" /&gt;&lt;/a&gt; &lt;a href="https://www.linkedin.com/shareArticle?url=https://roadmap.sh&amp;amp;title=Interactive%20roadmaps,%20guides%20and%20other%20educational%20content%20for%20Developers"&gt;&lt;img src="https://img.shields.io/badge/share%20on-linkedin-3949AB?logo=linkedin" alt="GitHub Repo stars" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Development&lt;/h2&gt; 
&lt;p&gt;Clone the repository, install the dependencies and start the application&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone git@github.com:kamranahmedse/developer-roadmap.git
cd developer-roadmap
npm install
npm run dev
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Note: use the &lt;code&gt;depth&lt;/code&gt; parameter to reduce the clone size and speed up the clone.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;git clone --depth=1 https://github.com/kamranahmedse/developer-roadmap.git
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Contribution&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Have a look at &lt;a href="https://raw.githubusercontent.com/kamranahmedse/developer-roadmap/master/contributing.md"&gt;contribution docs&lt;/a&gt; for how to update any of the roadmaps&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;Add content to roadmaps&lt;/li&gt; 
 &lt;li&gt;Add new roadmaps&lt;/li&gt; 
 &lt;li&gt;Suggest changes to existing roadmaps&lt;/li&gt; 
 &lt;li&gt;Discuss ideas in issues&lt;/li&gt; 
 &lt;li&gt;Spread the word&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Thanks to all contributors ‚ù§&lt;/h2&gt; 
&lt;a href="https://github.com/kamranahmedse/developer-roadmap/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=kamranahmedse/developer-roadmap" /&gt; &lt;/a&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Have a look at the &lt;a href="https://raw.githubusercontent.com/kamranahmedse/developer-roadmap/master/license"&gt;license file&lt;/a&gt; for details&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>gin-gonic/gin</title>
      <link>https://github.com/gin-gonic/gin</link>
      <description>&lt;p&gt;Gin is a high-performance HTTP web framework written in Go. It provides a Martini-like API but with significantly better performance‚Äîup to 40 times faster‚Äîthanks to httprouter. Gin is designed for building REST APIs, web applications, and microservices.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Gin Web Framework&lt;/h1&gt; 
&lt;img align="right" width="159px" src="https://raw.githubusercontent.com/gin-gonic/logo/master/color.png" /&gt; 
&lt;p&gt;&lt;a href="https://github.com/gin-gonic/gin/actions/workflows/gin.yml"&gt;&lt;img src="https://github.com/gin-gonic/gin/actions/workflows/gin.yml/badge.svg?branch=master" alt="Build Status" /&gt;&lt;/a&gt; &lt;a href="https://codecov.io/gh/gin-gonic/gin"&gt;&lt;img src="https://codecov.io/gh/gin-gonic/gin/branch/master/graph/badge.svg?sanitize=true" alt="codecov" /&gt;&lt;/a&gt; &lt;a href="https://goreportcard.com/report/github.com/gin-gonic/gin"&gt;&lt;img src="https://goreportcard.com/badge/github.com/gin-gonic/gin" alt="Go Report Card" /&gt;&lt;/a&gt; &lt;a href="https://pkg.go.dev/github.com/gin-gonic/gin?tab=doc"&gt;&lt;img src="https://pkg.go.dev/badge/github.com/gin-gonic/gin?status.svg?sanitize=true" alt="Go Reference" /&gt;&lt;/a&gt; &lt;a href="https://sourcegraph.com/github.com/gin-gonic/gin?badge"&gt;&lt;img src="https://sourcegraph.com/github.com/gin-gonic/gin/-/badge.svg?sanitize=true" alt="Sourcegraph" /&gt;&lt;/a&gt; &lt;a href="https://www.codetriage.com/gin-gonic/gin"&gt;&lt;img src="https://www.codetriage.com/gin-gonic/gin/badges/users.svg?sanitize=true" alt="Open Source Helpers" /&gt;&lt;/a&gt; &lt;a href="https://github.com/gin-gonic/gin/releases"&gt;&lt;img src="https://img.shields.io/github/release/gin-gonic/gin.svg?style=flat-square" alt="Release" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üì∞ &lt;a href="https://gin-gonic.com/en/blog/news/gin-1-11-0-release-announcement/"&gt;Announcing Gin 1.11.0!&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Read about the latest features and improvements in Gin 1.11.0 on our official blog.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;Gin is a high-performance HTTP web framework written in &lt;a href="https://go.dev/"&gt;Go&lt;/a&gt;. It provides a Martini-like API but with significantly better performance‚Äîup to 40 times faster‚Äîthanks to &lt;a href="https://github.com/julienschmidt/httprouter"&gt;httprouter&lt;/a&gt;. Gin is designed for building REST APIs, web applications, and microservices where speed and developer productivity are essential.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Why choose Gin?&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Gin combines the simplicity of Express.js-style routing with Go's performance characteristics, making it ideal for:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Building high-throughput REST APIs&lt;/li&gt; 
 &lt;li&gt;Developing microservices that need to handle many concurrent requests&lt;/li&gt; 
 &lt;li&gt;Creating web applications that require fast response times&lt;/li&gt; 
 &lt;li&gt;Prototyping web services quickly with minimal boilerplate&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Gin's key features:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Zero allocation router&lt;/strong&gt; - Extremely memory-efficient routing with no heap allocations&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;High performance&lt;/strong&gt; - Benchmarks show superior speed compared to other Go web frameworks&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Middleware support&lt;/strong&gt; - Extensible middleware system for authentication, logging, CORS, etc.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Crash-free&lt;/strong&gt; - Built-in recovery middleware prevents panics from crashing your server&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;JSON validation&lt;/strong&gt; - Automatic request/response JSON binding and validation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Route grouping&lt;/strong&gt; - Organize related routes and apply common middleware&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Error management&lt;/strong&gt; - Centralized error handling and logging&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Built-in rendering&lt;/strong&gt; - Support for JSON, XML, HTML templates, and more&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Extensible&lt;/strong&gt; - Large ecosystem of community middleware and plugins&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;h3&gt;Prerequisites&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Go version&lt;/strong&gt;: Gin requires &lt;a href="https://go.dev/"&gt;Go&lt;/a&gt; version &lt;a href="https://go.dev/doc/devel/release#go1.23.0"&gt;1.23&lt;/a&gt; or above&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Basic Go knowledge&lt;/strong&gt;: Familiarity with Go syntax and package management is helpful&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Installation&lt;/h3&gt; 
&lt;p&gt;With &lt;a href="https://go.dev/wiki/Modules#how-to-use-modules"&gt;Go's module support&lt;/a&gt;, simply import Gin in your code and Go will automatically fetch it during build:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;import "github.com/gin-gonic/gin"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Your First Gin Application&lt;/h3&gt; 
&lt;p&gt;Here's a complete example that demonstrates Gin's simplicity:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;package main

import (
  "net/http"

  "github.com/gin-gonic/gin"
)

func main() {
  // Create a Gin router with default middleware (logger and recovery)
  r := gin.Default()
  
  // Define a simple GET endpoint
  r.GET("/ping", func(c *gin.Context) {
    // Return JSON response
    c.JSON(http.StatusOK, gin.H{
      "message": "pong",
    })
  })
  
  // Start server on port 8080 (default)
  // Server will listen on 0.0.0.0:8080 (localhost:8080 on Windows)
  r.Run()
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Running the application:&lt;/strong&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Save the code above as &lt;code&gt;main.go&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Run the application:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-sh"&gt;go run main.go
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Open your browser and visit &lt;a href="http://localhost:8080/ping"&gt;&lt;code&gt;http://localhost:8080/ping&lt;/code&gt;&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;You should see: &lt;code&gt;{"message":"pong"}&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;What this example demonstrates:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Creating a Gin router with default middleware&lt;/li&gt; 
 &lt;li&gt;Defining HTTP endpoints with simple handler functions&lt;/li&gt; 
 &lt;li&gt;Returning JSON responses&lt;/li&gt; 
 &lt;li&gt;Starting an HTTP server&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Next Steps&lt;/h3&gt; 
&lt;p&gt;After running your first Gin application, explore these resources to learn more:&lt;/p&gt; 
&lt;h4&gt;üìö Learning Resources&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/gin-gonic/gin/master/docs/doc.md"&gt;Gin Quick Start Guide&lt;/a&gt;&lt;/strong&gt; - Comprehensive tutorial with API examples and build configurations&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/gin-gonic/examples"&gt;Example Repository&lt;/a&gt;&lt;/strong&gt; - Ready-to-run examples demonstrating various Gin use cases: 
  &lt;ul&gt; 
   &lt;li&gt;REST API development&lt;/li&gt; 
   &lt;li&gt;Authentication &amp;amp; middleware&lt;/li&gt; 
   &lt;li&gt;File uploads and downloads&lt;/li&gt; 
   &lt;li&gt;WebSocket connections&lt;/li&gt; 
   &lt;li&gt;Template rendering&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üìñ Documentation&lt;/h2&gt; 
&lt;h3&gt;API Reference&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://pkg.go.dev/github.com/gin-gonic/gin"&gt;Go.dev API Documentation&lt;/a&gt;&lt;/strong&gt; - Complete API reference with examples&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;User Guides&lt;/h3&gt; 
&lt;p&gt;The comprehensive documentation is available on &lt;a href="https://gin-gonic.com"&gt;gin-gonic.com&lt;/a&gt; in multiple languages:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://gin-gonic.com/en/docs/"&gt;English&lt;/a&gt; | &lt;a href="https://gin-gonic.com/zh-cn/docs/"&gt;ÁÆÄ‰Ωì‰∏≠Êñá&lt;/a&gt; | &lt;a href="https://gin-gonic.com/zh-tw/docs/"&gt;ÁπÅÈ´î‰∏≠Êñá&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://gin-gonic.com/ja/docs/"&gt;Êó•Êú¨Ë™û&lt;/a&gt; | &lt;a href="https://gin-gonic.com/ko-kr/docs/"&gt;ÌïúÍµ≠Ïñ¥&lt;/a&gt; | &lt;a href="https://gin-gonic.com/es/docs/"&gt;Espa√±ol&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://gin-gonic.com/tr/docs/"&gt;Turkish&lt;/a&gt; | &lt;a href="https://gin-gonic.com/fa/docs/"&gt;Persian&lt;/a&gt; | &lt;a href="https://gin-gonic.com/pt/docs/"&gt;Portugu√™s&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://gin-gonic.com/ru/docs/"&gt;Russian&lt;/a&gt; | &lt;a href="https://gin-gonic.com/id/docs/"&gt;Indonesian&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Official Tutorials&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://go.dev/doc/tutorial/web-service-gin"&gt;Go.dev Tutorial: Developing a RESTful API with Go and Gin&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;‚ö° Performance Benchmarks&lt;/h2&gt; 
&lt;p&gt;Gin demonstrates exceptional performance compared to other Go web frameworks. It uses a custom version of &lt;a href="https://github.com/julienschmidt/httprouter"&gt;HttpRouter&lt;/a&gt; for maximum efficiency. &lt;a href="https://raw.githubusercontent.com/gin-gonic/gin/master/BENCHMARKS.md"&gt;View detailed benchmarks ‚Üí&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Gin vs. Other Go Frameworks&lt;/strong&gt; (GitHub API routing benchmark):&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Benchmark name&lt;/th&gt; 
   &lt;th align="right"&gt;(1)&lt;/th&gt; 
   &lt;th align="right"&gt;(2)&lt;/th&gt; 
   &lt;th align="right"&gt;(3)&lt;/th&gt; 
   &lt;th align="right"&gt;(4)&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkGin_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;&lt;strong&gt;43550&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;&lt;strong&gt;27364 ns/op&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;&lt;strong&gt;0 B/op&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;&lt;strong&gt;0 allocs/op&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkAce_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;40543&lt;/td&gt; 
   &lt;td align="right"&gt;29670 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;0 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;0 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkAero_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;57632&lt;/td&gt; 
   &lt;td align="right"&gt;20648 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;0 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;0 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkBear_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;9234&lt;/td&gt; 
   &lt;td align="right"&gt;216179 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;86448 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;943 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkBeego_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;7407&lt;/td&gt; 
   &lt;td align="right"&gt;243496 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;71456 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;609 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkBone_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;420&lt;/td&gt; 
   &lt;td align="right"&gt;2922835 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;720160 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;8620 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkChi_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;7620&lt;/td&gt; 
   &lt;td align="right"&gt;238331 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;87696 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;609 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkDenco_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;18355&lt;/td&gt; 
   &lt;td align="right"&gt;64494 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;20224 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;167 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkEcho_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;31251&lt;/td&gt; 
   &lt;td align="right"&gt;38479 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;0 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;0 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkGocraftWeb_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;4117&lt;/td&gt; 
   &lt;td align="right"&gt;300062 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;131656 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;1686 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkGoji_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;3274&lt;/td&gt; 
   &lt;td align="right"&gt;416158 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;56112 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;334 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkGojiv2_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;1402&lt;/td&gt; 
   &lt;td align="right"&gt;870518 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;352720 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;4321 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkGoJsonRest_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;2976&lt;/td&gt; 
   &lt;td align="right"&gt;401507 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;134371 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;2737 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkGoRestful_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;410&lt;/td&gt; 
   &lt;td align="right"&gt;2913158 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;910144 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;2938 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkGorillaMux_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;346&lt;/td&gt; 
   &lt;td align="right"&gt;3384987 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;251650 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;1994 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkGowwwRouter_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;10000&lt;/td&gt; 
   &lt;td align="right"&gt;143025 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;72144 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;501 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkHttpRouter_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;55938&lt;/td&gt; 
   &lt;td align="right"&gt;21360 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;0 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;0 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkHttpTreeMux_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;10000&lt;/td&gt; 
   &lt;td align="right"&gt;153944 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;65856 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;671 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkKocha_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;10000&lt;/td&gt; 
   &lt;td align="right"&gt;106315 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;23304 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;843 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkLARS_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;47779&lt;/td&gt; 
   &lt;td align="right"&gt;25084 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;0 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;0 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkMacaron_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;3266&lt;/td&gt; 
   &lt;td align="right"&gt;371907 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;149409 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;1624 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkMartini_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;331&lt;/td&gt; 
   &lt;td align="right"&gt;3444706 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;226551 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;2325 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkPat_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;273&lt;/td&gt; 
   &lt;td align="right"&gt;4381818 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;1483152 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;26963 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkPossum_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;10000&lt;/td&gt; 
   &lt;td align="right"&gt;164367 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;84448 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;609 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkR2router_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;10000&lt;/td&gt; 
   &lt;td align="right"&gt;160220 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;77328 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;979 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkRivet_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;14625&lt;/td&gt; 
   &lt;td align="right"&gt;82453 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;16272 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;167 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkTango_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;6255&lt;/td&gt; 
   &lt;td align="right"&gt;279611 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;63826 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;1618 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkTigerTonic_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;2008&lt;/td&gt; 
   &lt;td align="right"&gt;687874 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;193856 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;4474 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkTraffic_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;355&lt;/td&gt; 
   &lt;td align="right"&gt;3478508 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;820744 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;14114 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkVulcan_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;6885&lt;/td&gt; 
   &lt;td align="right"&gt;193333 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;19894 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;609 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;ul&gt; 
 &lt;li&gt;(1): Total Repetitions achieved in constant time, higher means more confident result&lt;/li&gt; 
 &lt;li&gt;(2): Single Repetition Duration (ns/op), lower is better&lt;/li&gt; 
 &lt;li&gt;(3): Heap Memory (B/op), lower is better&lt;/li&gt; 
 &lt;li&gt;(4): Average Allocations per Repetition (allocs/op), lower is better&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üîå Middleware Ecosystem&lt;/h2&gt; 
&lt;p&gt;Gin has a rich ecosystem of middleware for common web development needs. Explore community-contributed middleware:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://github.com/gin-contrib"&gt;gin-contrib&lt;/a&gt;&lt;/strong&gt; - Official middleware collection including:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Authentication (JWT, Basic Auth, Sessions)&lt;/li&gt; 
   &lt;li&gt;CORS, Rate limiting, Compression&lt;/li&gt; 
   &lt;li&gt;Logging, Metrics, Tracing&lt;/li&gt; 
   &lt;li&gt;Static file serving, Template engines&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://github.com/gin-gonic/contrib"&gt;gin-gonic/contrib&lt;/a&gt;&lt;/strong&gt; - Additional community middleware&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üè¢ Production Usage&lt;/h2&gt; 
&lt;p&gt;Gin powers many high-traffic applications and services in production:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/appleboy/gorush"&gt;gorush&lt;/a&gt;&lt;/strong&gt; - High-performance push notification server&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/fnproject/fn"&gt;fnproject&lt;/a&gt;&lt;/strong&gt; - Container-native, serverless platform&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/photoprism/photoprism"&gt;photoprism&lt;/a&gt;&lt;/strong&gt; - AI-powered personal photo management&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/luraproject/lura"&gt;lura&lt;/a&gt;&lt;/strong&gt; - Ultra-performant API Gateway framework&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/thoas/picfit"&gt;picfit&lt;/a&gt;&lt;/strong&gt; - Real-time image processing server&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/distribworks/dkron"&gt;dkron&lt;/a&gt;&lt;/strong&gt; - Distributed job scheduling system&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ü§ù Contributing&lt;/h2&gt; 
&lt;p&gt;Gin is the work of hundreds of contributors from around the world. We welcome and appreciate your contributions!&lt;/p&gt; 
&lt;h3&gt;How to Contribute&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;üêõ &lt;strong&gt;Report bugs&lt;/strong&gt; - Help us identify and fix issues&lt;/li&gt; 
 &lt;li&gt;üí° &lt;strong&gt;Suggest features&lt;/strong&gt; - Share your ideas for improvements&lt;/li&gt; 
 &lt;li&gt;üìù &lt;strong&gt;Improve documentation&lt;/strong&gt; - Help make our docs clearer&lt;/li&gt; 
 &lt;li&gt;üîß &lt;strong&gt;Submit code&lt;/strong&gt; - Fix bugs or implement new features&lt;/li&gt; 
 &lt;li&gt;üß™ &lt;strong&gt;Write tests&lt;/strong&gt; - Improve our test coverage&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Getting Started with Contributing&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Check out our &lt;a href="https://raw.githubusercontent.com/gin-gonic/gin/master/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; for detailed guidelines&lt;/li&gt; 
 &lt;li&gt;Join our community discussions and ask questions&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;All contributions are valued and help make Gin better for everyone!&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>harry0703/MoneyPrinterTurbo</title>
      <link>https://github.com/harry0703/MoneyPrinterTurbo</link>
      <description>&lt;p&gt;Âà©Áî®AIÂ§ßÊ®°ÂûãÔºå‰∏ÄÈîÆÁîüÊàêÈ´òÊ∏ÖÁü≠ËßÜÈ¢ë Generate short videos with one click using AI LLM.&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;h1 align="center"&gt;MoneyPrinterTurbo üí∏&lt;/h1&gt; 
 &lt;p align="center"&gt; &lt;a href="https://github.com/harry0703/MoneyPrinterTurbo/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/harry0703/MoneyPrinterTurbo.svg?style=for-the-badge" alt="Stargazers" /&gt;&lt;/a&gt; &lt;a href="https://github.com/harry0703/MoneyPrinterTurbo/issues"&gt;&lt;img src="https://img.shields.io/github/issues/harry0703/MoneyPrinterTurbo.svg?style=for-the-badge" alt="Issues" /&gt;&lt;/a&gt; &lt;a href="https://github.com/harry0703/MoneyPrinterTurbo/network/members"&gt;&lt;img src="https://img.shields.io/github/forks/harry0703/MoneyPrinterTurbo.svg?style=for-the-badge" alt="Forks" /&gt;&lt;/a&gt; &lt;a href="https://github.com/harry0703/MoneyPrinterTurbo/raw/main/LICENSE"&gt;&lt;img src="https://img.shields.io/github/license/harry0703/MoneyPrinterTurbo.svg?style=for-the-badge" alt="License" /&gt;&lt;/a&gt; &lt;/p&gt; 
 &lt;br /&gt; 
 &lt;h3&gt;ÁÆÄ‰Ωì‰∏≠Êñá | &lt;a href="https://raw.githubusercontent.com/harry0703/MoneyPrinterTurbo/main/README-en.md"&gt;English&lt;/a&gt;&lt;/h3&gt; 
 &lt;div align="center"&gt; 
  &lt;a href="https://trendshift.io/repositories/8731" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/8731" alt="harry0703%2FMoneyPrinterTurbo | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt; 
 &lt;/div&gt; 
 &lt;br /&gt; Âè™ÈúÄÊèê‰æõ‰∏Ä‰∏™ËßÜÈ¢ë 
 &lt;b&gt;‰∏ªÈ¢ò&lt;/b&gt; Êàñ 
 &lt;b&gt;ÂÖ≥ÈîÆËØç&lt;/b&gt; ÔºåÂ∞±ÂèØ‰ª•ÂÖ®Ëá™Âä®ÁîüÊàêËßÜÈ¢ëÊñáÊ°à„ÄÅËßÜÈ¢ëÁ¥†Êùê„ÄÅËßÜÈ¢ëÂ≠óÂπï„ÄÅËßÜÈ¢ëËÉåÊôØÈü≥‰πêÔºåÁÑ∂ÂêéÂêàÊàê‰∏Ä‰∏™È´òÊ∏ÖÁöÑÁü≠ËßÜÈ¢ë„ÄÇ 
 &lt;br /&gt; 
 &lt;h4&gt;WebÁïåÈù¢&lt;/h4&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/harry0703/MoneyPrinterTurbo/main/docs/webui.jpg" alt="" /&gt;&lt;/p&gt; 
 &lt;h4&gt;APIÁïåÈù¢&lt;/h4&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/harry0703/MoneyPrinterTurbo/main/docs/api.jpg" alt="" /&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;ÁâπÂà´ÊÑüË∞¢ üôè&lt;/h2&gt; 
&lt;p&gt;Áî±‰∫éËØ•È°πÁõÆÁöÑ &lt;strong&gt;ÈÉ®ÁΩ≤&lt;/strong&gt; Âíå &lt;strong&gt;‰ΩøÁî®&lt;/strong&gt;ÔºåÂØπ‰∫é‰∏Ä‰∫õÂ∞èÁôΩÁî®Êà∑Êù•ËØ¥ÔºåËøòÊòØ &lt;strong&gt;Êúâ‰∏ÄÂÆöÁöÑÈó®Êßõ&lt;/strong&gt;ÔºåÂú®Ê≠§ÁâπÂà´ÊÑüË∞¢ &lt;strong&gt;ÂΩïÂíñÔºàAIÊô∫ËÉΩ Â§öÂ™í‰ΩìÊúçÂä°Âπ≥Âè∞Ôºâ&lt;/strong&gt; ÁΩëÁ´ôÂü∫‰∫éËØ•È°πÁõÆÔºåÊèê‰æõÁöÑÂÖçË¥π&lt;code&gt;AIËßÜÈ¢ëÁîüÊàêÂô®&lt;/code&gt;ÊúçÂä°ÔºåÂèØ‰ª•‰∏çÁî®ÈÉ®ÁΩ≤ÔºåÁõ¥Êé•Âú®Á∫ø‰ΩøÁî®ÔºåÈùûÂ∏∏Êñπ‰æø„ÄÇ&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;‰∏≠ÊñáÁâàÔºö&lt;a href="https://reccloud.cn"&gt;https://reccloud.cn&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Ëã±ÊñáÁâàÔºö&lt;a href="https://reccloud.com"&gt;https://reccloud.com&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/harry0703/MoneyPrinterTurbo/main/docs/reccloud.cn.jpg" alt="" /&gt;&lt;/p&gt; 
&lt;h2&gt;ÊÑüË∞¢ËµûÂä© üôè&lt;/h2&gt; 
&lt;p&gt;ÊÑüË∞¢‰ΩêÁ≥ñ &lt;a href="https://picwish.cn"&gt;https://picwish.cn&lt;/a&gt; ÂØπËØ•È°πÁõÆÁöÑÊîØÊåÅÂíåËµûÂä©Ôºå‰ΩøÂæóËØ•È°πÁõÆËÉΩÂ§üÊåÅÁª≠ÁöÑÊõ¥Êñ∞ÂíåÁª¥Êä§„ÄÇ&lt;/p&gt; 
&lt;p&gt;‰ΩêÁ≥ñ‰∏ìÊ≥®‰∫é&lt;strong&gt;ÂõæÂÉèÂ§ÑÁêÜÈ¢ÜÂüü&lt;/strong&gt;ÔºåÊèê‰æõ‰∏∞ÂØåÁöÑ&lt;strong&gt;ÂõæÂÉèÂ§ÑÁêÜÂ∑•ÂÖ∑&lt;/strong&gt;ÔºåÂ∞ÜÂ§çÊùÇÊìç‰ΩúÊûÅËá¥ÁÆÄÂåñÔºåÁúüÊ≠£ÂÆûÁé∞ËÆ©ÂõæÂÉèÂ§ÑÁêÜÊõ¥ÁÆÄÂçï„ÄÇ&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/harry0703/MoneyPrinterTurbo/main/docs/picwish.jpg" alt="picwish.jpg" /&gt;&lt;/p&gt; 
&lt;h2&gt;ÂäüËÉΩÁâπÊÄß üéØ&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; ÂÆåÊï¥ÁöÑ &lt;strong&gt;MVCÊû∂ÊûÑ&lt;/strong&gt;Ôºå‰ª£Á†Å &lt;strong&gt;ÁªìÊûÑÊ∏ÖÊô∞&lt;/strong&gt;ÔºåÊòì‰∫éÁª¥Êä§ÔºåÊîØÊåÅ &lt;code&gt;API&lt;/code&gt; Âíå &lt;code&gt;WebÁïåÈù¢&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; ÊîØÊåÅËßÜÈ¢ëÊñáÊ°à &lt;strong&gt;AIËá™Âä®ÁîüÊàê&lt;/strong&gt;Ôºå‰πüÂèØ‰ª•&lt;strong&gt;Ëá™ÂÆö‰πâÊñáÊ°à&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; ÊîØÊåÅÂ§öÁßç &lt;strong&gt;È´òÊ∏ÖËßÜÈ¢ë&lt;/strong&gt; Â∞∫ÂØ∏ 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Á´ñÂ±è 9:16Ôºå&lt;code&gt;1080x1920&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Ê®™Â±è 16:9Ôºå&lt;code&gt;1920x1080&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; ÊîØÊåÅ &lt;strong&gt;ÊâπÈáèËßÜÈ¢ëÁîüÊàê&lt;/strong&gt;ÔºåÂèØ‰ª•‰∏ÄÊ¨°ÁîüÊàêÂ§ö‰∏™ËßÜÈ¢ëÔºåÁÑ∂ÂêéÈÄâÊã©‰∏Ä‰∏™ÊúÄÊª°ÊÑèÁöÑ&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; ÊîØÊåÅ &lt;strong&gt;ËßÜÈ¢ëÁâáÊÆµÊó∂Èïø&lt;/strong&gt; ËÆæÁΩÆÔºåÊñπ‰æøË∞ÉËäÇÁ¥†ÊùêÂàáÊç¢È¢ëÁéá&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; ÊîØÊåÅ &lt;strong&gt;‰∏≠Êñá&lt;/strong&gt; Âíå &lt;strong&gt;Ëã±Êñá&lt;/strong&gt; ËßÜÈ¢ëÊñáÊ°à&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; ÊîØÊåÅ &lt;strong&gt;Â§öÁßçËØ≠Èü≥&lt;/strong&gt; ÂêàÊàêÔºåÂèØ &lt;strong&gt;ÂÆûÊó∂ËØïÂê¨&lt;/strong&gt; ÊïàÊûú&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; ÊîØÊåÅ &lt;strong&gt;Â≠óÂπïÁîüÊàê&lt;/strong&gt;ÔºåÂèØ‰ª•Ë∞ÉÊï¥ &lt;code&gt;Â≠ó‰Ωì&lt;/code&gt;„ÄÅ&lt;code&gt;‰ΩçÁΩÆ&lt;/code&gt;„ÄÅ&lt;code&gt;È¢úËâ≤&lt;/code&gt;„ÄÅ&lt;code&gt;Â§ßÂ∞è&lt;/code&gt;ÔºåÂêåÊó∂ÊîØÊåÅ&lt;code&gt;Â≠óÂπïÊèèËæπ&lt;/code&gt;ËÆæÁΩÆ&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; ÊîØÊåÅ &lt;strong&gt;ËÉåÊôØÈü≥‰πê&lt;/strong&gt;ÔºåÈöèÊú∫ÊàñËÄÖÊåáÂÆöÈü≥‰πêÊñá‰ª∂ÔºåÂèØËÆæÁΩÆ&lt;code&gt;ËÉåÊôØÈü≥‰πêÈü≥Èáè&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; ËßÜÈ¢ëÁ¥†ÊùêÊù•Ê∫ê &lt;strong&gt;È´òÊ∏Ö&lt;/strong&gt;ÔºåËÄå‰∏î &lt;strong&gt;Êó†ÁâàÊùÉ&lt;/strong&gt;Ôºå‰πüÂèØ‰ª•‰ΩøÁî®Ëá™Â∑±ÁöÑ &lt;strong&gt;Êú¨Âú∞Á¥†Êùê&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; ÊîØÊåÅ &lt;strong&gt;OpenAI&lt;/strong&gt;„ÄÅ&lt;strong&gt;Moonshot&lt;/strong&gt;„ÄÅ&lt;strong&gt;Azure&lt;/strong&gt;„ÄÅ&lt;strong&gt;gpt4free&lt;/strong&gt;„ÄÅ&lt;strong&gt;one-api&lt;/strong&gt;„ÄÅ&lt;strong&gt;ÈÄö‰πâÂçÉÈóÆ&lt;/strong&gt;„ÄÅ&lt;strong&gt;Google Gemini&lt;/strong&gt;„ÄÅ&lt;strong&gt;Ollama&lt;/strong&gt;„ÄÅ&lt;strong&gt;DeepSeek&lt;/strong&gt;„ÄÅ &lt;strong&gt;ÊñáÂøÉ‰∏ÄË®Ä&lt;/strong&gt;, &lt;strong&gt;Pollinations&lt;/strong&gt; Á≠âÂ§öÁßçÊ®°ÂûãÊé•ÂÖ• 
  &lt;ul&gt; 
   &lt;li&gt;‰∏≠ÂõΩÁî®Êà∑Âª∫ËÆÆ‰ΩøÁî® &lt;strong&gt;DeepSeek&lt;/strong&gt; Êàñ &lt;strong&gt;Moonshot&lt;/strong&gt; ‰Ωú‰∏∫Â§ßÊ®°ÂûãÊèê‰æõÂïÜÔºàÂõΩÂÜÖÂèØÁõ¥Êé•ËÆøÈóÆÔºå‰∏çÈúÄË¶ÅVPN„ÄÇÊ≥®ÂÜåÂ∞±ÈÄÅÈ¢ùÂ∫¶ÔºåÂü∫Êú¨Â§üÁî®Ôºâ&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;ÂêéÊúüËÆ°Âàí üìÖ&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; GPT-SoVITS ÈÖçÈü≥ÊîØÊåÅ&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; ‰ºòÂåñËØ≠Èü≥ÂêàÊàêÔºåÂà©Áî®Â§ßÊ®°ÂûãÔºå‰ΩøÂÖ∂ÂêàÊàêÁöÑÂ£∞Èü≥ÔºåÊõ¥Âä†Ëá™ÁÑ∂ÔºåÊÉÖÁª™Êõ¥Âä†‰∏∞ÂØå&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Â¢ûÂä†ËßÜÈ¢ëËΩ¨Âú∫ÊïàÊûúÔºå‰ΩøÂÖ∂ÁúãËµ∑Êù•Êõ¥Âä†ÁöÑÊµÅÁïÖ&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Â¢ûÂä†Êõ¥Â§öËßÜÈ¢ëÁ¥†ÊùêÊù•Ê∫êÔºå‰ºòÂåñËßÜÈ¢ëÁ¥†ÊùêÂíåÊñáÊ°àÁöÑÂåπÈÖçÂ∫¶&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Â¢ûÂä†ËßÜÈ¢ëÈïøÂ∫¶ÈÄâÈ°πÔºöÁü≠„ÄÅ‰∏≠„ÄÅÈïø&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; ÊîØÊåÅÊõ¥Â§öÁöÑËØ≠Èü≥ÂêàÊàêÊúçÂä°ÂïÜÔºåÊØîÂ¶Ç OpenAI TTS&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Ëá™Âä®‰∏ä‰º†Âà∞YouTubeÂπ≥Âè∞&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ËßÜÈ¢ëÊºîÁ§∫ üì∫&lt;/h2&gt; 
&lt;h3&gt;Á´ñÂ±è 9:16&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="center"&gt;
    &lt;g-emoji class="g-emoji" alias="arrow_forward"&gt;
     ‚ñ∂Ô∏è
    &lt;/g-emoji&gt; „ÄäÂ¶Ç‰ΩïÂ¢ûÂä†ÁîüÊ¥ªÁöÑ‰πêË∂£„Äã&lt;/th&gt; 
   &lt;th align="center"&gt;
    &lt;g-emoji class="g-emoji" alias="arrow_forward"&gt;
     ‚ñ∂Ô∏è
    &lt;/g-emoji&gt; „ÄäÈáëÈí±ÁöÑ‰ΩúÁî®„Äã&lt;br /&gt;Êõ¥ÁúüÂÆûÁöÑÂêàÊàêÂ£∞Èü≥&lt;/th&gt; 
   &lt;th align="center"&gt;
    &lt;g-emoji class="g-emoji" alias="arrow_forward"&gt;
     ‚ñ∂Ô∏è
    &lt;/g-emoji&gt; „ÄäÁîüÂëΩÁöÑÊÑè‰πâÊòØ‰ªÄ‰πà„Äã&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;
    &lt;video src="https://github.com/harry0703/MoneyPrinterTurbo/assets/4928832/a84d33d5-27a2-4aba-8fd0-9fb2bd91c6a6"&gt;&lt;/video&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;
    &lt;video src="https://github.com/harry0703/MoneyPrinterTurbo/assets/4928832/af2f3b0b-002e-49fe-b161-18ba91c055e8"&gt;&lt;/video&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;
    &lt;video src="https://github.com/harry0703/MoneyPrinterTurbo/assets/4928832/112c9564-d52b-4472-99ad-970b75f66476"&gt;&lt;/video&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Ê®™Â±è 16:9&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="center"&gt;
    &lt;g-emoji class="g-emoji" alias="arrow_forward"&gt;
     ‚ñ∂Ô∏è
    &lt;/g-emoji&gt;„ÄäÁîüÂëΩÁöÑÊÑè‰πâÊòØ‰ªÄ‰πà„Äã&lt;/th&gt; 
   &lt;th align="center"&gt;
    &lt;g-emoji class="g-emoji" alias="arrow_forward"&gt;
     ‚ñ∂Ô∏è
    &lt;/g-emoji&gt;„Ää‰∏∫‰ªÄ‰πàË¶ÅËøêÂä®„Äã&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;
    &lt;video src="https://github.com/harry0703/MoneyPrinterTurbo/assets/4928832/346ebb15-c55f-47a9-a653-114f08bb8073"&gt;&lt;/video&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;
    &lt;video src="https://github.com/harry0703/MoneyPrinterTurbo/assets/4928832/271f2fae-8283-44a0-8aa0-0ed8f9a6fa87"&gt;&lt;/video&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;ÈÖçÁΩÆË¶ÅÊ±Ç üì¶&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Âª∫ËÆÆÊúÄ‰Ωé CPU &lt;strong&gt;4Ê†∏&lt;/strong&gt; Êàñ‰ª•‰∏äÔºåÂÜÖÂ≠ò &lt;strong&gt;4G&lt;/strong&gt; Êàñ‰ª•‰∏äÔºåÊòæÂç°ÈùûÂøÖÈ°ª&lt;/li&gt; 
 &lt;li&gt;Windows 10 Êàñ MacOS 11.0 ‰ª•‰∏äÁ≥ªÁªü&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Âø´ÈÄüÂºÄÂßã üöÄ&lt;/h2&gt; 
&lt;h3&gt;Âú® Google Colab ‰∏≠ËøêË°å&lt;/h3&gt; 
&lt;p&gt;ÂÖçÂéªÊú¨Âú∞ÁéØÂ¢ÉÈÖçÁΩÆÔºåÁÇπÂáªÁõ¥Êé•Âú® Google Colab ‰∏≠Âø´ÈÄü‰ΩìÈ™å MoneyPrinterTurbo&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://colab.research.google.com/github/harry0703/MoneyPrinterTurbo/blob/main/docs/MoneyPrinterTurbo.ipynb"&gt;&lt;img src="https://colab.research.google.com/assets/colab-badge.svg?sanitize=true" alt="Open in Colab" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Windows‰∏ÄÈîÆÂêØÂä®ÂåÖ&lt;/h3&gt; 
&lt;p&gt;‰∏ãËΩΩ‰∏ÄÈîÆÂêØÂä®ÂåÖÔºåËß£ÂéãÁõ¥Êé•‰ΩøÁî®ÔºàË∑ØÂæÑ‰∏çË¶ÅÊúâ &lt;strong&gt;‰∏≠Êñá&lt;/strong&gt;„ÄÅ&lt;strong&gt;ÁâπÊÆäÂ≠óÁ¨¶&lt;/strong&gt;„ÄÅ&lt;strong&gt;Á©∫Ê†º&lt;/strong&gt;Ôºâ&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;ÁôæÂ∫¶ÁΩëÁõòÔºàv1.2.6Ôºâ: &lt;a href="https://pan.baidu.com/s/1wg0UaIyXpO3SqIpaq790SQ?pwd=sbqx"&gt;https://pan.baidu.com/s/1wg0UaIyXpO3SqIpaq790SQ?pwd=sbqx&lt;/a&gt; ÊèêÂèñÁ†Å: sbqx&lt;/li&gt; 
 &lt;li&gt;Google Drive (v1.2.6): &lt;a href="https://drive.google.com/file/d/1HsbzfT7XunkrCrHw5ncUjFX8XX4zAuUh/view?usp=sharing"&gt;https://drive.google.com/file/d/1HsbzfT7XunkrCrHw5ncUjFX8XX4zAuUh/view?usp=sharing&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;‰∏ãËΩΩÂêéÔºåÂª∫ËÆÆÂÖà&lt;strong&gt;ÂèåÂáªÊâßË°å&lt;/strong&gt; &lt;code&gt;update.bat&lt;/code&gt; Êõ¥Êñ∞Âà∞&lt;strong&gt;ÊúÄÊñ∞‰ª£Á†Å&lt;/strong&gt;ÔºåÁÑ∂ÂêéÂèåÂáª &lt;code&gt;start.bat&lt;/code&gt; ÂêØÂä®&lt;/p&gt; 
&lt;p&gt;ÂêØÂä®ÂêéÔºå‰ºöËá™Âä®ÊâìÂºÄÊµèËßàÂô®ÔºàÂ¶ÇÊûúÊâìÂºÄÊòØÁ©∫ÁôΩÔºåÂª∫ËÆÆÊç¢Êàê &lt;strong&gt;Chrome&lt;/strong&gt; ÊàñËÄÖ &lt;strong&gt;Edge&lt;/strong&gt; ÊâìÂºÄÔºâ&lt;/p&gt; 
&lt;h2&gt;ÂÆâË£ÖÈÉ®ÁΩ≤ üì•&lt;/h2&gt; 
&lt;h3&gt;ÂâçÊèêÊù°‰ª∂&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Â∞ΩÈáè‰∏çË¶Å‰ΩøÁî® &lt;strong&gt;‰∏≠ÊñáË∑ØÂæÑ&lt;/strong&gt;ÔºåÈÅøÂÖçÂá∫Áé∞‰∏Ä‰∫õÊó†Ê≥ïÈ¢ÑÊñôÁöÑÈóÆÈ¢ò&lt;/li&gt; 
 &lt;li&gt;ËØ∑Á°Æ‰øù‰Ω†ÁöÑ &lt;strong&gt;ÁΩëÁªú&lt;/strong&gt; ÊòØÊ≠£Â∏∏ÁöÑÔºåVPNÈúÄË¶ÅÊâìÂºÄ&lt;code&gt;ÂÖ®Â±ÄÊµÅÈáè&lt;/code&gt;Ê®°Âºè&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;‚ë† ÂÖãÈöÜ‰ª£Á†Å&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;git clone https://github.com/harry0703/MoneyPrinterTurbo.git
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;‚ë° ‰øÆÊîπÈÖçÁΩÆÊñá‰ª∂ÔºàÂèØÈÄâÔºåÂª∫ËÆÆÂêØÂä®Âêé‰πüÂèØ‰ª•Âú® WebUI ÈáåÈù¢ÈÖçÁΩÆÔºâ&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Â∞Ü &lt;code&gt;config.example.toml&lt;/code&gt; Êñá‰ª∂Â§çÂà∂‰∏Ä‰ªΩÔºåÂëΩÂêç‰∏∫ &lt;code&gt;config.toml&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;ÊåâÁÖß &lt;code&gt;config.toml&lt;/code&gt; Êñá‰ª∂‰∏≠ÁöÑËØ¥ÊòéÔºåÈÖçÁΩÆÂ•Ω &lt;code&gt;pexels_api_keys&lt;/code&gt; Âíå &lt;code&gt;llm_provider&lt;/code&gt;ÔºåÂπ∂Ê†πÊçÆ llm_provider ÂØπÂ∫îÁöÑÊúçÂä°ÂïÜÔºåÈÖçÁΩÆÁõ∏ÂÖ≥ÁöÑ API Key&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;DockerÈÉ®ÁΩ≤ üê≥&lt;/h3&gt; 
&lt;h4&gt;‚ë† ÂêØÂä®Docker&lt;/h4&gt; 
&lt;p&gt;Â¶ÇÊûúÊú™ÂÆâË£Ö DockerÔºåËØ∑ÂÖàÂÆâË£Ö &lt;a href="https://www.docker.com/products/docker-desktop/"&gt;https://www.docker.com/products/docker-desktop/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Â¶ÇÊûúÊòØWindowsÁ≥ªÁªüÔºåËØ∑ÂèÇËÄÉÂæÆËΩØÁöÑÊñáÊ°£Ôºö&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;a href="https://learn.microsoft.com/zh-cn/windows/wsl/install"&gt;https://learn.microsoft.com/zh-cn/windows/wsl/install&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://learn.microsoft.com/zh-cn/windows/wsl/tutorials/wsl-containers"&gt;https://learn.microsoft.com/zh-cn/windows/wsl/tutorials/wsl-containers&lt;/a&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;cd MoneyPrinterTurbo
docker-compose up
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Ê≥®ÊÑèÔºöÊúÄÊñ∞ÁâàÁöÑdockerÂÆâË£ÖÊó∂‰ºöËá™Âä®‰ª•Êèí‰ª∂ÁöÑÂΩ¢ÂºèÂÆâË£Ödocker composeÔºåÂêØÂä®ÂëΩ‰ª§Ë∞ÉÊï¥‰∏∫docker compose up&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;‚ë° ËÆøÈóÆWebÁïåÈù¢&lt;/h4&gt; 
&lt;p&gt;ÊâìÂºÄÊµèËßàÂô®ÔºåËÆøÈóÆ &lt;a href="http://0.0.0.0:8501"&gt;http://0.0.0.0:8501&lt;/a&gt;&lt;/p&gt; 
&lt;h4&gt;‚ë¢ ËÆøÈóÆAPIÊñáÊ°£&lt;/h4&gt; 
&lt;p&gt;ÊâìÂºÄÊµèËßàÂô®ÔºåËÆøÈóÆ &lt;a href="http://0.0.0.0:8080/docs"&gt;http://0.0.0.0:8080/docs&lt;/a&gt; ÊàñËÄÖ &lt;a href="http://0.0.0.0:8080/redoc"&gt;http://0.0.0.0:8080/redoc&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;ÊâãÂä®ÈÉ®ÁΩ≤ üì¶&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;ËßÜÈ¢ëÊïôÁ®ã&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;ÂÆåÊï¥ÁöÑ‰ΩøÁî®ÊºîÁ§∫Ôºö&lt;a href="https://v.douyin.com/iFhnwsKY/"&gt;https://v.douyin.com/iFhnwsKY/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Â¶Ç‰ΩïÂú®Windows‰∏äÈÉ®ÁΩ≤Ôºö&lt;a href="https://v.douyin.com/iFyjoW3M"&gt;https://v.douyin.com/iFyjoW3M&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;‚ë† ÂàõÂª∫ËôöÊãüÁéØÂ¢É&lt;/h4&gt; 
&lt;p&gt;Âª∫ËÆÆ‰ΩøÁî® &lt;a href="https://conda.io/projects/conda/en/latest/user-guide/install/index.html"&gt;conda&lt;/a&gt; ÂàõÂª∫ python ËôöÊãüÁéØÂ¢É&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;git clone https://github.com/harry0703/MoneyPrinterTurbo.git
cd MoneyPrinterTurbo
conda create -n MoneyPrinterTurbo python=3.11
conda activate MoneyPrinterTurbo
pip install -r requirements.txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;‚ë° ÂÆâË£ÖÂ•Ω ImageMagick&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Windows:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;‰∏ãËΩΩ &lt;a href="https://imagemagick.org/script/download.php"&gt;https://imagemagick.org/script/download.php&lt;/a&gt; ÈÄâÊã©WindowsÁâàÊú¨ÔºåÂàáËÆ∞‰∏ÄÂÆöË¶ÅÈÄâÊã© &lt;strong&gt;ÈùôÊÄÅÂ∫ì&lt;/strong&gt; ÁâàÊú¨ÔºåÊØîÂ¶Ç ImageMagick-7.1.1-32-Q16-x64-&lt;strong&gt;static&lt;/strong&gt;.exe&lt;/li&gt; 
   &lt;li&gt;ÂÆâË£Ö‰∏ãËΩΩÂ•ΩÁöÑ ImageMagickÔºå&lt;strong&gt;Ê≥®ÊÑè‰∏çË¶Å‰øÆÊîπÂÆâË£ÖË∑ØÂæÑ&lt;/strong&gt;&lt;/li&gt; 
   &lt;li&gt;‰øÆÊîπ &lt;code&gt;ÈÖçÁΩÆÊñá‰ª∂ config.toml&lt;/code&gt; ‰∏≠ÁöÑ &lt;code&gt;imagemagick_path&lt;/code&gt; ‰∏∫‰Ω†ÁöÑ &lt;strong&gt;ÂÆûÈôÖÂÆâË£ÖË∑ØÂæÑ&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;MacOS:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;brew install imagemagick
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Ubuntu&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;sudo apt-get install imagemagick
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;CentOS&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;sudo yum install ImageMagick
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;‚ë¢ ÂêØÂä®WebÁïåÈù¢ üåê&lt;/h4&gt; 
&lt;p&gt;Ê≥®ÊÑèÈúÄË¶ÅÂà∞ MoneyPrinterTurbo È°πÁõÆ &lt;code&gt;Ê†πÁõÆÂΩï&lt;/code&gt; ‰∏ãÊâßË°å‰ª•‰∏ãÂëΩ‰ª§&lt;/p&gt; 
&lt;h6&gt;Windows&lt;/h6&gt; 
&lt;pre&gt;&lt;code class="language-bat"&gt;webui.bat
&lt;/code&gt;&lt;/pre&gt; 
&lt;h6&gt;MacOS or Linux&lt;/h6&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;sh webui.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;ÂêØÂä®ÂêéÔºå‰ºöËá™Âä®ÊâìÂºÄÊµèËßàÂô®ÔºàÂ¶ÇÊûúÊâìÂºÄÊòØÁ©∫ÁôΩÔºåÂª∫ËÆÆÊç¢Êàê &lt;strong&gt;Chrome&lt;/strong&gt; ÊàñËÄÖ &lt;strong&gt;Edge&lt;/strong&gt; ÊâìÂºÄÔºâ&lt;/p&gt; 
&lt;h4&gt;‚ë£ ÂêØÂä®APIÊúçÂä° üöÄ&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;python main.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;ÂêØÂä®ÂêéÔºåÂèØ‰ª•Êü•Áúã &lt;code&gt;APIÊñáÊ°£&lt;/code&gt; &lt;a href="http://127.0.0.1:8080/docs"&gt;http://127.0.0.1:8080/docs&lt;/a&gt; ÊàñËÄÖ &lt;a href="http://127.0.0.1:8080/redoc"&gt;http://127.0.0.1:8080/redoc&lt;/a&gt; Áõ¥Êé•Âú®Á∫øË∞ÉËØïÊé•Âè£ÔºåÂø´ÈÄü‰ΩìÈ™å„ÄÇ&lt;/p&gt; 
&lt;h2&gt;ËØ≠Èü≥ÂêàÊàê üó£&lt;/h2&gt; 
&lt;p&gt;ÊâÄÊúâÊîØÊåÅÁöÑÂ£∞Èü≥ÂàóË°®ÔºåÂèØ‰ª•Êü•ÁúãÔºö&lt;a href="https://raw.githubusercontent.com/harry0703/MoneyPrinterTurbo/main/docs/voice-list.txt"&gt;Â£∞Èü≥ÂàóË°®&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;2024-04-16 v1.1.2 Êñ∞Â¢û‰∫Ü9ÁßçAzureÁöÑËØ≠Èü≥ÂêàÊàêÂ£∞Èü≥ÔºåÈúÄË¶ÅÈÖçÁΩÆAPI KEYÔºåËØ•Â£∞Èü≥ÂêàÊàêÁöÑÊõ¥Âä†ÁúüÂÆû„ÄÇ&lt;/p&gt; 
&lt;h2&gt;Â≠óÂπïÁîüÊàê üìú&lt;/h2&gt; 
&lt;p&gt;ÂΩìÂâçÊîØÊåÅ2ÁßçÂ≠óÂπïÁîüÊàêÊñπÂºèÔºö&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;edge&lt;/strong&gt;: ÁîüÊàê&lt;code&gt;ÈÄüÂ∫¶Âø´&lt;/code&gt;ÔºåÊÄßËÉΩÊõ¥Â•ΩÔºåÂØπÁîµËÑëÈÖçÁΩÆÊ≤°ÊúâË¶ÅÊ±ÇÔºå‰ΩÜÊòØË¥®ÈáèÂèØËÉΩ‰∏çÁ®≥ÂÆö&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;whisper&lt;/strong&gt;: ÁîüÊàê&lt;code&gt;ÈÄüÂ∫¶ÊÖ¢&lt;/code&gt;ÔºåÊÄßËÉΩËæÉÂ∑ÆÔºåÂØπÁîµËÑëÈÖçÁΩÆÊúâ‰∏ÄÂÆöË¶ÅÊ±ÇÔºå‰ΩÜÊòØ&lt;code&gt;Ë¥®ÈáèÊõ¥ÂèØÈù†&lt;/code&gt;„ÄÇ&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;ÂèØ‰ª•‰øÆÊîπ &lt;code&gt;config.toml&lt;/code&gt; ÈÖçÁΩÆÊñá‰ª∂‰∏≠ÁöÑ &lt;code&gt;subtitle_provider&lt;/code&gt; ËøõË°åÂàáÊç¢&lt;/p&gt; 
&lt;p&gt;Âª∫ËÆÆ‰ΩøÁî® &lt;code&gt;edge&lt;/code&gt; Ê®°ÂºèÔºåÂ¶ÇÊûúÁîüÊàêÁöÑÂ≠óÂπïË¥®Èáè‰∏çÂ•ΩÔºåÂÜçÂàáÊç¢Âà∞ &lt;code&gt;whisper&lt;/code&gt; Ê®°Âºè&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Ê≥®ÊÑèÔºö&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ol&gt; 
 &lt;li&gt;whisper Ê®°Âºè‰∏ãÈúÄË¶ÅÂà∞ HuggingFace ‰∏ãËΩΩ‰∏Ä‰∏™Ê®°ÂûãÊñá‰ª∂ÔºåÂ§ßÁ∫¶ 3GB Â∑¶Âè≥ÔºåËØ∑Á°Æ‰øùÁΩëÁªúÈÄöÁïÖ&lt;/li&gt; 
 &lt;li&gt;Â¶ÇÊûúÁïôÁ©∫ÔºåË°®Á§∫‰∏çÁîüÊàêÂ≠óÂπï„ÄÇ&lt;/li&gt; 
&lt;/ol&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Áî±‰∫éÂõΩÂÜÖÊó†Ê≥ïËÆøÈóÆ HuggingFaceÔºåÂèØ‰ª•‰ΩøÁî®‰ª•‰∏ãÊñπÊ≥ï‰∏ãËΩΩ &lt;code&gt;whisper-large-v3&lt;/code&gt; ÁöÑÊ®°ÂûãÊñá‰ª∂&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;‰∏ãËΩΩÂú∞ÂùÄÔºö&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;ÁôæÂ∫¶ÁΩëÁõò: &lt;a href="https://pan.baidu.com/s/11h3Q6tsDtjQKTjUu3sc5cA?pwd=xjs9"&gt;https://pan.baidu.com/s/11h3Q6tsDtjQKTjUu3sc5cA?pwd=xjs9&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Â§∏ÂÖãÁΩëÁõòÔºö&lt;a href="https://pan.quark.cn/s/3ee3d991d64b"&gt;https://pan.quark.cn/s/3ee3d991d64b&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Ê®°Âûã‰∏ãËΩΩÂêéËß£ÂéãÔºåÊï¥‰∏™ÁõÆÂΩïÊîæÂà∞ &lt;code&gt;.\MoneyPrinterTurbo\models&lt;/code&gt; ÈáåÈù¢Ôºå ÊúÄÁªàÁöÑÊñá‰ª∂Ë∑ØÂæÑÂ∫îËØ•ÊòØËøôÊ†∑: &lt;code&gt;.\MoneyPrinterTurbo\models\whisper-large-v3&lt;/code&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;MoneyPrinterTurbo  
  ‚îú‚îÄmodels
  ‚îÇ   ‚îî‚îÄwhisper-large-v3
  ‚îÇ          config.json
  ‚îÇ          model.bin
  ‚îÇ          preprocessor_config.json
  ‚îÇ          tokenizer.json
  ‚îÇ          vocabulary.json
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;ËÉåÊôØÈü≥‰πê üéµ&lt;/h2&gt; 
&lt;p&gt;Áî®‰∫éËßÜÈ¢ëÁöÑËÉåÊôØÈü≥‰πêÔºå‰Ωç‰∫éÈ°πÁõÆÁöÑ &lt;code&gt;resource/songs&lt;/code&gt; ÁõÆÂΩï‰∏ã„ÄÇ&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;ÂΩìÂâçÈ°πÁõÆÈáåÈù¢Êîæ‰∫Ü‰∏Ä‰∫õÈªòËÆ§ÁöÑÈü≥‰πêÔºåÊù•Ëá™‰∫é YouTube ËßÜÈ¢ëÔºåÂ¶ÇÊúâ‰æµÊùÉÔºåËØ∑Âà†Èô§„ÄÇ&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Â≠óÂπïÂ≠ó‰Ωì üÖ∞&lt;/h2&gt; 
&lt;p&gt;Áî®‰∫éËßÜÈ¢ëÂ≠óÂπïÁöÑÊ∏≤ÊüìÔºå‰Ωç‰∫éÈ°πÁõÆÁöÑ &lt;code&gt;resource/fonts&lt;/code&gt; ÁõÆÂΩï‰∏ãÔºå‰Ω†‰πüÂèØ‰ª•ÊîæËøõÂéªËá™Â∑±ÁöÑÂ≠ó‰Ωì„ÄÇ&lt;/p&gt; 
&lt;h2&gt;Â∏∏ËßÅÈóÆÈ¢ò ü§î&lt;/h2&gt; 
&lt;h3&gt;‚ùìRuntimeError: No ffmpeg exe could be found&lt;/h3&gt; 
&lt;p&gt;ÈÄöÂ∏∏ÊÉÖÂÜµ‰∏ãÔºåffmpeg ‰ºöË¢´Ëá™Âä®‰∏ãËΩΩÔºåÂπ∂‰∏î‰ºöË¢´Ëá™Âä®Ê£ÄÊµãÂà∞„ÄÇ ‰ΩÜÊòØÂ¶ÇÊûú‰Ω†ÁöÑÁéØÂ¢ÉÊúâÈóÆÈ¢òÔºåÊó†Ê≥ïËá™Âä®‰∏ãËΩΩÔºåÂèØËÉΩ‰ºöÈÅáÂà∞Â¶Ç‰∏ãÈîôËØØÔºö&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;RuntimeError: No ffmpeg exe could be found.
Install ffmpeg on your system, or set the IMAGEIO_FFMPEG_EXE environment variable.
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Ê≠§Êó∂‰Ω†ÂèØ‰ª•‰ªé &lt;a href="https://www.gyan.dev/ffmpeg/builds/"&gt;https://www.gyan.dev/ffmpeg/builds/&lt;/a&gt; ‰∏ãËΩΩffmpegÔºåËß£ÂéãÂêéÔºåËÆæÁΩÆ &lt;code&gt;ffmpeg_path&lt;/code&gt; ‰∏∫‰Ω†ÁöÑÂÆûÈôÖÂÆâË£ÖË∑ØÂæÑÂç≥ÂèØ„ÄÇ&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;[app]
# ËØ∑Ê†πÊçÆ‰Ω†ÁöÑÂÆûÈôÖË∑ØÂæÑËÆæÁΩÆÔºåÊ≥®ÊÑè Windows Ë∑ØÂæÑÂàÜÈöîÁ¨¶‰∏∫ \\
ffmpeg_path = "C:\\Users\\harry\\Downloads\\ffmpeg.exe"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;‚ùìImageMagickÁöÑÂÆâÂÖ®Á≠ñÁï•ÈòªÊ≠¢‰∫Ü‰∏é‰∏¥Êó∂Êñá‰ª∂@/tmp/tmpur5hyyto.txtÁõ∏ÂÖ≥ÁöÑÊìç‰Ωú&lt;/h3&gt; 
&lt;p&gt;ÂèØ‰ª•Âú®ImageMagickÁöÑÈÖçÁΩÆÊñá‰ª∂policy.xml‰∏≠ÊâæÂà∞Ëøô‰∫õÁ≠ñÁï•„ÄÇ Ëøô‰∏™Êñá‰ª∂ÈÄöÂ∏∏‰Ωç‰∫é /etc/ImageMagick-&lt;code&gt;X&lt;/code&gt;/ Êàñ ImageMagick ÂÆâË£ÖÁõÆÂΩïÁöÑÁ±ª‰ºº‰ΩçÁΩÆ„ÄÇ ‰øÆÊîπÂåÖÂê´&lt;code&gt;pattern="@"&lt;/code&gt;ÁöÑÊù°ÁõÆÔºåÂ∞Ü&lt;code&gt;rights="none"&lt;/code&gt;Êõ¥Êîπ‰∏∫&lt;code&gt;rights="read|write"&lt;/code&gt;‰ª•ÂÖÅËÆ∏ÂØπÊñá‰ª∂ÁöÑËØªÂÜôÊìç‰Ωú„ÄÇ&lt;/p&gt; 
&lt;h3&gt;‚ùìOSError: [Errno 24] Too many open files&lt;/h3&gt; 
&lt;p&gt;Ëøô‰∏™ÈóÆÈ¢òÊòØÁî±‰∫éÁ≥ªÁªüÊâìÂºÄÊñá‰ª∂Êï∞ÈôêÂà∂ÂØºËá¥ÁöÑÔºåÂèØ‰ª•ÈÄöËøá‰øÆÊîπÁ≥ªÁªüÁöÑÊñá‰ª∂ÊâìÂºÄÊï∞ÈôêÂà∂Êù•Ëß£ÂÜ≥„ÄÇ&lt;/p&gt; 
&lt;p&gt;Êü•ÁúãÂΩìÂâçÈôêÂà∂&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;ulimit -n
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Â¶ÇÊûúËøá‰ΩéÔºåÂèØ‰ª•Ë∞ÉÈ´ò‰∏Ä‰∫õÔºåÊØîÂ¶Ç&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;ulimit -n 10240
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;‚ùìWhisper Ê®°Âûã‰∏ãËΩΩÂ§±Ë¥•ÔºåÂá∫Áé∞Â¶Ç‰∏ãÈîôËØØ&lt;/h3&gt; 
&lt;p&gt;LocalEntryNotfoundEror: Cannot find an appropriate cached snapshotfolderfor the specified revision on the local disk and outgoing trafic has been disabled. To enablerepo look-ups and downloads online, pass 'local files only=False' as input.&lt;/p&gt; 
&lt;p&gt;ÊàñËÄÖ&lt;/p&gt; 
&lt;p&gt;An error occured while synchronizing the model Systran/faster-whisper-large-v3 from the Hugging Face Hub: An error happened while trying to locate the files on the Hub and we cannot find the appropriate snapshot folder for the specified revision on the local disk. Please check your internet connection and try again. Trying to load the model directly from the local cache, if it exists.&lt;/p&gt; 
&lt;p&gt;Ëß£ÂÜ≥ÊñπÊ≥ïÔºö&lt;a href="https://raw.githubusercontent.com/harry0703/MoneyPrinterTurbo/main/#%E5%AD%97%E5%B9%95%E7%94%9F%E6%88%90-"&gt;ÁÇπÂáªÊü•ÁúãÂ¶Ç‰Ωï‰ªéÁΩëÁõòÊâãÂä®‰∏ãËΩΩÊ®°Âûã&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;ÂèçÈ¶àÂª∫ËÆÆ üì¢&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;ÂèØ‰ª•Êèê‰∫§ &lt;a href="https://github.com/harry0703/MoneyPrinterTurbo/issues"&gt;issue&lt;/a&gt; ÊàñËÄÖ &lt;a href="https://github.com/harry0703/MoneyPrinterTurbo/pulls"&gt;pull request&lt;/a&gt;„ÄÇ&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ËÆ∏ÂèØËØÅ üìù&lt;/h2&gt; 
&lt;p&gt;ÁÇπÂáªÊü•Áúã &lt;a href="https://raw.githubusercontent.com/harry0703/MoneyPrinterTurbo/main/LICENSE"&gt;&lt;code&gt;LICENSE&lt;/code&gt;&lt;/a&gt; Êñá‰ª∂&lt;/p&gt; 
&lt;h2&gt;Star History&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://star-history.com/#harry0703/MoneyPrinterTurbo&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=harry0703/MoneyPrinterTurbo&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Gar-b-age/CookLikeHOC</title>
      <link>https://github.com/Gar-b-age/CookLikeHOC</link>
      <description>&lt;p&gt;ü•¢ÂÉèËÄÅ‰π°È∏°üêîÈÇ£Ê†∑ÂÅöÈ•≠„ÄÇ‰∏ªË¶ÅÈÉ®ÂàÜ‰∫é2024Âπ¥ÂÆåÂ∑•ÔºåÈùûËÄÅ‰π°È∏°ÂÆòÊñπ‰ªìÂ∫ì„ÄÇÊñáÂ≠óÊù•Ëá™„ÄäËÄÅ‰π°È∏°ËèúÂìÅÊ∫ØÊ∫êÊä•Âëä„ÄãÔºåÂπ∂ÂÅöÂΩíÁ∫≥„ÄÅÁºñËæë‰∏éÊï¥ÁêÜ„ÄÇCookLikeHOC.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Gar-b-age/CookLikeHOC/main/banner.png" alt="pic" /&gt;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/Gar-b-age/CookLikeHOC/main/docker_support/README.md"&gt;&lt;strong&gt;Docker Support&lt;/strong&gt;&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/Gar-b-age/CookLikeHOC/main/docs/development.md"&gt;&lt;strong&gt;Development&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h1&gt;ÂÉèËÄÅ‰π°È∏°ÈÇ£Ê†∑ÂÅöÈ•≠&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://github.com/Gar-b-age/CookLikeHOC/issues/26"&gt;&lt;strong&gt;‰∏Ä‰∫õËØ¥Êòé&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;‰ªìÂ∫ì‰∏ª‰ΩìÈÉ®ÂàÜ‰∫é2024Âπ¥ÂÆåÂ∑•ÔºåÂíå2025Âπ¥9Êúà‰ªΩÁöÑËàÜËÆ∫‰∫ã‰ª∂Êó†ÂÖ≥„ÄÇÊà™Ê≠¢Êèê‰∫§Êó∂Ôºå‰ªìÂ∫ìÁöÑË¥°ÁåÆËÄÖ‰ª¨‰∏éËÄÅ‰π°È∏°ÁöÑÂîØ‰∏ÄÂÖ≥Á≥ªÂè™ÊúâÊ∂àË¥πËÄÖÂíåÂïÜÂÆ∂ÁöÑÂÖ≥Á≥ª„ÄÇÊú¨‰ªìÂ∫ì‰∏çÊòØËÄÅ‰π°È∏°ÁöÑÂÆòÊñπ‰ªìÂ∫ì„ÄÇÂ¶ÇÊûúÊúâ‰ªª‰ΩïÈóÆÈ¢òÊàñÊÑèËßÅÂª∫ËÆÆÔºåÊ¨¢ËøéÊåáÂá∫&lt;/p&gt; 
&lt;h2&gt;Êñ∞Êõ¥Êñ∞&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Ê¨¢ËøéÂ§ßÂÆ∂Êù•Ë¥°ÁåÆÂÆûÊãçÂõæ&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Áé∞Â∑≤‰∏äÁ∫øÁΩëÈ°µÁ´ØÔºå&lt;a href="https://cooklikehoc.soilzhu.su"&gt;ÁÇπÂáªËÆøÈóÆ&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Run with Docker? Check it out &lt;a href="https://github.com/Gar-b-age/CookLikeHOC/tree/main/docker_support"&gt;here&lt;/a&gt;, supported by &lt;a href="https://github.com/honestAnt"&gt;@honestAnt&lt;/a&gt; in &lt;a href="https://github.com/Gar-b-age/CookLikeHOC/pull/141"&gt;PR #141&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;AI ÁªòÂà∂ÁöÑÊâãÁªòÂõæÁâàÂèäAIÈÖçÂõæÊµÅÁ®ãÁâàÁΩëÈ°µÔºö &lt;a href="https://ai.cooklikehoc.soilzhu.su"&gt;ÁÇπÂáªËÆøÈóÆ&lt;/a&gt;, ÊâãÁªòÂõæÁî± &lt;a href="https://github.com/liucongg"&gt;@liucongg&lt;/a&gt; Ë¥°ÁåÆÔºåËßÅ &lt;a href="https://github.com/Gar-b-age/CookLikeHOC/pull/143"&gt;PR #143&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;a href="https://t.me/cooklikehoc"&gt;&lt;img src="https://raw.githubusercontent.com/Gar-b-age/CookLikeHOC/main/tg.png" alt="link" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;„ÄäËÄÅ‰π°È∏°ËèúÂìÅÊ∫ØÊ∫êÊä•Âëä„Äã‰∏≠ÂÖ¨Â∏ÉÁöÑÊâÄÊúâËèúÂìÅÂ∑≤ÁªèÂÖ®ÈÉ®ÂΩïÂÖ•ÂÆåÔºåÊ¨¢ËøéÂ§ßÂÆ∂Êü•ÈòÖÂíåË°•ÂÖÖ„ÄÇ&lt;/p&gt; 
&lt;p&gt;ÊñáÂ≠óË∂ÖÂ§ßÊÆµcopyËá™&lt;a href="https://www.lxjchina.com.cn/display.asp?id=4226"&gt;„ÄäËÄÅ‰π°È∏°ËèúÂìÅÊ∫ØÊ∫êÊä•Âëä„Äã&lt;/a&gt;ÔºåÊúâÁºñËæë‰∏éÊï¥ÁêÜ&lt;/p&gt; 
&lt;p&gt;ÊåáË∑ØÈöîÂ£Å &lt;a href="https://cook.aiursoft.cn/"&gt;How To Cook&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Ëá≥‰∫é‰∏∫‰ªÄ‰πà‰ªìÂ∫ìÂêçË¶ÅÂè´CookLikeHOCÔºåÂõ†‰∏∫Áõ¥Êé•ÂÜôLaoxiangjiÂ§ßÊ¶Ç‰∏çÊñπ‰æøÈòÖËØªÔºåËÄåHome Original ChickenÊòØchina dailyÊä•ÈÅì‰∏≠ÊâÄ‰ΩøÁî®ÁöÑËÄÅ‰π°È∏°ÁöÑËã±ÊñáÂêçÔºåÊïÖÁÆÄÂÜôÊàêHOC„ÄÇ&lt;/p&gt; 
&lt;h2&gt;Contributor&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://contrib.rocks/image?repo=Gar-b-age/CookLikeHOC" alt="cr" /&gt;&lt;/p&gt; 
&lt;h2&gt;Logo&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Gar-b-age/CookLikeHOC/main/logo.png" alt="pic" /&gt;&lt;/p&gt; 
&lt;h2&gt;Star History&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://star-history.com/#Gar-b-age/CookLikeHOC&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=Gar-b-age/CookLikeHOC&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>LadybirdBrowser/ladybird</title>
      <link>https://github.com/LadybirdBrowser/ladybird</link>
      <description>&lt;p&gt;Truly independent web browser&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Ladybird&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://ladybird.org"&gt;Ladybird&lt;/a&gt; is a truly independent web browser, using a novel engine based on web standards.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] Ladybird is in a pre-alpha state, and only suitable for use by developers&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;p&gt;We aim to build a complete, usable browser for the modern web.&lt;/p&gt; 
&lt;p&gt;Ladybird uses a multi-process architecture with a main UI process, several WebContent renderer processes, an ImageDecoder process, and a RequestServer process.&lt;/p&gt; 
&lt;p&gt;Image decoding and network connections are done out of process to be more robust against malicious content. Each tab has its own renderer process, which is sandboxed from the rest of the system.&lt;/p&gt; 
&lt;p&gt;At the moment, many core library support components are inherited from SerenityOS:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;LibWeb: Web rendering engine&lt;/li&gt; 
 &lt;li&gt;LibJS: JavaScript engine&lt;/li&gt; 
 &lt;li&gt;LibWasm: WebAssembly implementation&lt;/li&gt; 
 &lt;li&gt;LibCrypto/LibTLS: Cryptography primitives and Transport Layer Security&lt;/li&gt; 
 &lt;li&gt;LibHTTP: HTTP/1.1 client&lt;/li&gt; 
 &lt;li&gt;LibGfx: 2D Graphics Library, Image Decoding and Rendering&lt;/li&gt; 
 &lt;li&gt;LibUnicode: Unicode and locale support&lt;/li&gt; 
 &lt;li&gt;LibMedia: Audio and video playback&lt;/li&gt; 
 &lt;li&gt;LibCore: Event loop, OS abstraction layer&lt;/li&gt; 
 &lt;li&gt;LibIPC: Inter-process communication&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;How do I build and run this?&lt;/h2&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/LadybirdBrowser/ladybird/master/Documentation/BuildInstructionsLadybird.md"&gt;build instructions&lt;/a&gt; for information on how to build Ladybird.&lt;/p&gt; 
&lt;p&gt;Ladybird runs on Linux, macOS, Windows (with WSL2), and many other *Nixes.&lt;/p&gt; 
&lt;h2&gt;How do I read the documentation?&lt;/h2&gt; 
&lt;p&gt;Code-related documentation can be found in the &lt;a href="https://raw.githubusercontent.com/LadybirdBrowser/ladybird/master/Documentation/"&gt;documentation&lt;/a&gt; folder.&lt;/p&gt; 
&lt;h2&gt;Get in touch and participate!&lt;/h2&gt; 
&lt;p&gt;Join &lt;a href="https://discord.gg/nvfjVJ4Svh"&gt;our Discord server&lt;/a&gt; to participate in development discussion.&lt;/p&gt; 
&lt;p&gt;Please read &lt;a href="https://raw.githubusercontent.com/LadybirdBrowser/ladybird/master/Documentation/GettingStartedContributing.md"&gt;Getting started contributing&lt;/a&gt; if you plan to contribute to Ladybird for the first time.&lt;/p&gt; 
&lt;p&gt;Before opening an issue, please see the &lt;a href="https://raw.githubusercontent.com/LadybirdBrowser/ladybird/master/CONTRIBUTING.md#issue-policy"&gt;issue policy&lt;/a&gt; and the &lt;a href="https://raw.githubusercontent.com/LadybirdBrowser/ladybird/master/ISSUES.md"&gt;detailed issue-reporting guidelines&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;The full contribution guidelines can be found in &lt;a href="https://raw.githubusercontent.com/LadybirdBrowser/ladybird/master/CONTRIBUTING.md"&gt;&lt;code&gt;CONTRIBUTING.md&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Ladybird is licensed under a 2-clause BSD license.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>TheAlgorithms/Python</title>
      <link>https://github.com/TheAlgorithms/Python</link>
      <description>&lt;p&gt;All Algorithms implemented in Python&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;!-- Title: --&gt; 
 &lt;a href="https://github.com/TheAlgorithms/"&gt; &lt;img src="https://raw.githubusercontent.com/TheAlgorithms/website/1cd824df116b27029f17c2d1b42d81731f28a920/public/logo.svg?sanitize=true" height="100" /&gt; &lt;/a&gt; 
 &lt;h1&gt;&lt;a href="https://github.com/TheAlgorithms/"&gt;The Algorithms&lt;/a&gt; - Python&lt;/h1&gt; 
 &lt;!-- Labels: --&gt; 
 &lt;!-- First row: --&gt; 
 &lt;a href="https://gitpod.io/#https://github.com/TheAlgorithms/Python"&gt; &lt;img src="https://img.shields.io/badge/Gitpod-Ready--to--Code-blue?logo=gitpod&amp;amp;style=flat-square" height="20" alt="Gitpod Ready-to-Code" /&gt; &lt;/a&gt; 
 &lt;a href="https://github.com/TheAlgorithms/Python/raw/master/CONTRIBUTING.md"&gt; &lt;img src="https://img.shields.io/static/v1.svg?label=Contributions&amp;amp;message=Welcome&amp;amp;color=0059b3&amp;amp;style=flat-square" height="20" alt="Contributions Welcome" /&gt; &lt;/a&gt; 
 &lt;img src="https://img.shields.io/github/repo-size/TheAlgorithms/Python.svg?label=Repo%20size&amp;amp;style=flat-square" height="20" /&gt; 
 &lt;a href="https://the-algorithms.com/discord"&gt; &lt;img src="https://img.shields.io/discord/808045925556682782.svg?logo=discord&amp;amp;colorB=7289DA&amp;amp;style=flat-square" height="20" alt="Discord chat" /&gt; &lt;/a&gt; 
 &lt;a href="https://gitter.im/TheAlgorithms/community"&gt; &lt;img src="https://img.shields.io/badge/Chat-Gitter-ff69b4.svg?label=Chat&amp;amp;logo=gitter&amp;amp;style=flat-square" height="20" alt="Gitter chat" /&gt; &lt;/a&gt; 
 &lt;!-- Second row: --&gt; 
 &lt;br /&gt; 
 &lt;a href="https://github.com/TheAlgorithms/Python/actions"&gt; &lt;img src="https://img.shields.io/github/actions/workflow/status/TheAlgorithms/Python/build.yml?branch=master&amp;amp;label=CI&amp;amp;logo=github&amp;amp;style=flat-square" height="20" alt="GitHub Workflow Status" /&gt; &lt;/a&gt; 
 &lt;a href="https://github.com/pre-commit/pre-commit"&gt; &lt;img src="https://img.shields.io/badge/pre--commit-enabled-brightgreen?logo=pre-commit&amp;amp;logoColor=white&amp;amp;style=flat-square" height="20" alt="pre-commit" /&gt; &lt;/a&gt; 
 &lt;a href="https://docs.astral.sh/ruff/formatter/"&gt; &lt;img src="https://img.shields.io/static/v1?label=code%20style&amp;amp;message=ruff&amp;amp;color=black&amp;amp;style=flat-square" height="20" alt="code style: black" /&gt; &lt;/a&gt; 
 &lt;!-- Short description: --&gt; 
 &lt;h3&gt;All algorithms implemented in Python - for education üìö&lt;/h3&gt; 
&lt;/div&gt; 
&lt;p&gt;Implementations are for learning purposes only. They may be less efficient than the implementations in the Python standard library. Use them at your discretion.&lt;/p&gt; 
&lt;h2&gt;üöÄ Getting Started&lt;/h2&gt; 
&lt;p&gt;üìã Read through our &lt;a href="https://raw.githubusercontent.com/TheAlgorithms/Python/master/CONTRIBUTING.md"&gt;Contribution Guidelines&lt;/a&gt; before you contribute.&lt;/p&gt; 
&lt;h2&gt;üåê Community Channels&lt;/h2&gt; 
&lt;p&gt;We are on &lt;a href="https://the-algorithms.com/discord"&gt;Discord&lt;/a&gt; and &lt;a href="https://gitter.im/TheAlgorithms/community"&gt;Gitter&lt;/a&gt;! Community channels are a great way for you to ask questions and get help. Please join us!&lt;/p&gt; 
&lt;h2&gt;üìú List of Algorithms&lt;/h2&gt; 
&lt;p&gt;See our &lt;a href="https://raw.githubusercontent.com/TheAlgorithms/Python/master/DIRECTORY.md"&gt;directory&lt;/a&gt; for easier navigation and a better overview of the project.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>LazyVim/LazyVim</title>
      <link>https://github.com/LazyVim/LazyVim</link>
      <description>&lt;p&gt;Neovim config for the lazy&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;img src="https://user-images.githubusercontent.com/292349/213446185-2db63fd5-8c84-459c-9f04-e286382d6e80.png" /&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h4 align="center"&gt; &lt;a href="https://lazyvim.github.io/installation"&gt;Install&lt;/a&gt; ¬∑ &lt;a href="https://lazyvim.github.io/configuration"&gt;Configure&lt;/a&gt; ¬∑ &lt;a href="https://lazyvim.github.io"&gt;Docs&lt;/a&gt; &lt;/h4&gt; 
&lt;div align="center"&gt;
 &lt;p&gt; &lt;a href="https://github.com/LazyVim/LazyVim/releases/latest"&gt; &lt;img alt="Latest release" src="https://img.shields.io/github/v/release/LazyVim/LazyVim?style=for-the-badge&amp;amp;logo=starship&amp;amp;color=C9CBFF&amp;amp;logoColor=D9E0EE&amp;amp;labelColor=302D41&amp;amp;include_prerelease&amp;amp;sort=semver" /&gt; &lt;/a&gt; &lt;a href="https://github.com/LazyVim/LazyVim/pulse"&gt; &lt;img alt="Last commit" src="https://img.shields.io/github/last-commit/LazyVim/LazyVim?style=for-the-badge&amp;amp;logo=starship&amp;amp;color=8bd5ca&amp;amp;logoColor=D9E0EE&amp;amp;labelColor=302D41" /&gt; &lt;/a&gt; &lt;a href="https://github.com/LazyVim/LazyVim/raw/main/LICENSE"&gt; &lt;img alt="License" src="https://img.shields.io/github/license/LazyVim/LazyVim?style=for-the-badge&amp;amp;logo=starship&amp;amp;color=ee999f&amp;amp;logoColor=D9E0EE&amp;amp;labelColor=302D41" /&gt; &lt;/a&gt; &lt;a href="https://github.com/LazyVim/LazyVim/stargazers"&gt; &lt;img alt="Stars" src="https://img.shields.io/github/stars/LazyVim/LazyVim?style=for-the-badge&amp;amp;logo=starship&amp;amp;color=c69ff5&amp;amp;logoColor=D9E0EE&amp;amp;labelColor=302D41" /&gt; &lt;/a&gt; &lt;a href="https://github.com/LazyVim/LazyVim/issues"&gt; &lt;img alt="Issues" src="https://img.shields.io/github/issues/LazyVim/LazyVim?style=for-the-badge&amp;amp;logo=bilibili&amp;amp;color=F5E0DC&amp;amp;logoColor=D9E0EE&amp;amp;labelColor=302D41" /&gt; &lt;/a&gt; &lt;a href="https://github.com/LazyVim/LazyVim"&gt; &lt;img alt="Repo Size" src="https://img.shields.io/github/repo-size/LazyVim/LazyVim?color=%23DDB6F2&amp;amp;label=SIZE&amp;amp;logo=codesandbox&amp;amp;style=for-the-badge&amp;amp;logoColor=D9E0EE&amp;amp;labelColor=302D41" /&gt; &lt;/a&gt; &lt;a href="https://twitter.com/intent/follow?screen_name=folke"&gt; &lt;img alt="follow on Twitter" src="https://img.shields.io/twitter/follow/folke?style=for-the-badge&amp;amp;logo=twitter&amp;amp;color=8aadf3&amp;amp;logoColor=D9E0EE&amp;amp;labelColor=302D41" /&gt; &lt;/a&gt; &lt;/p&gt;
&lt;/div&gt; 
&lt;p&gt;LazyVim is a Neovim setup powered by &lt;a href="https://github.com/folke/lazy.nvim"&gt;üí§ lazy.nvim&lt;/a&gt; to make it easy to customize and extend your config. Rather than having to choose between starting from scratch or using a pre-made distro, LazyVim offers the best of both worlds - the flexibility to tweak your config as needed, along with the convenience of a pre-configured setup.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://user-images.githubusercontent.com/292349/211285846-0b7bb3bf-0462-4029-b64c-4ee1d037fc1c.png" alt="image" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://user-images.githubusercontent.com/292349/213447056-92290767-ea16-430c-8727-ce994c93e9cc.png" alt="image" /&gt;&lt;/p&gt; 
&lt;h2&gt;‚ú® Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;üî• Transform your Neovim into a full-fledged IDE&lt;/li&gt; 
 &lt;li&gt;üí§ Easily customize and extend your config with &lt;a href="https://github.com/folke/lazy.nvim"&gt;lazy.nvim&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üöÄ Blazingly fast&lt;/li&gt; 
 &lt;li&gt;üßπ Sane default settings for options, autocmds, and keymaps&lt;/li&gt; 
 &lt;li&gt;üì¶ Comes with a wealth of plugins pre-configured and ready to use&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;‚ö°Ô∏è Requirements&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Neovim &amp;gt;= &lt;strong&gt;0.11.2&lt;/strong&gt; (needs to be built with &lt;strong&gt;LuaJIT&lt;/strong&gt;)&lt;/li&gt; 
 &lt;li&gt;Git &amp;gt;= &lt;strong&gt;2.19.0&lt;/strong&gt; (for partial clones support)&lt;/li&gt; 
 &lt;li&gt;a &lt;a href="https://www.nerdfonts.com/"&gt;Nerd Font&lt;/a&gt; &lt;strong&gt;&lt;em&gt;(optional)&lt;/em&gt;&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;a &lt;strong&gt;C&lt;/strong&gt; compiler for &lt;code&gt;nvim-treesitter&lt;/code&gt;. See &lt;a href="https://github.com/nvim-treesitter/nvim-treesitter#requirements"&gt;here&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üöÄ Getting Started&lt;/h2&gt; 
&lt;p&gt;You can find a starter template for &lt;strong&gt;LazyVim&lt;/strong&gt; &lt;a href="https://github.com/LazyVim/starter"&gt;here&lt;/a&gt;&lt;/p&gt; 
&lt;details&gt;
 &lt;summary&gt;Try it with Docker&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-sh"&gt;docker run -w /root -it --rm alpine:edge sh -uelic '
  apk add git lazygit fzf curl neovim ripgrep alpine-sdk --update
  git clone https://github.com/LazyVim/starter ~/.config/nvim
  cd ~/.config/nvim
  nvim
'
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt;
 &lt;summary&gt;Install the &lt;a href="https://github.com/LazyVim/starter"&gt;LazyVim Starter&lt;/a&gt;&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;Make a backup of your current Neovim files:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-sh"&gt;mv ~/.config/nvim ~/.config/nvim.bak
mv ~/.local/share/nvim ~/.local/share/nvim.bak
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;Clone the starter&lt;/p&gt; &lt;pre&gt;&lt;code class="language-sh"&gt;git clone https://github.com/LazyVim/starter ~/.config/nvim
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;Remove the &lt;code&gt;.git&lt;/code&gt; folder, so you can add it to your own repo later&lt;/p&gt; &lt;pre&gt;&lt;code class="language-sh"&gt;rm -rf ~/.config/nvim/.git
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;Start Neovim!&lt;/p&gt; &lt;pre&gt;&lt;code class="language-sh"&gt;nvim
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Refer to the comments in the files on how to customize &lt;strong&gt;LazyVim&lt;/strong&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;hr /&gt; 
&lt;p&gt;There's a great video created by &lt;a href="https://github.com/elijahmanor"&gt;@elijahmanor&lt;/a&gt; with a walkthrough to get started.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=N93cTbtLCIM"&gt;&lt;img src="https://img.youtube.com/vi/N93cTbtLCIM/hqdefault.jpg" alt="Watch the video" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/dusty-phillips"&gt;@dusty-phillips&lt;/a&gt; wrote a comprehensive book called &lt;a href="https://lazyvim-ambitious-devs.phillips.codes"&gt;LazyVim for Ambitious Developers&lt;/a&gt; available for free online.&lt;/p&gt; 
&lt;h2&gt;üìÇ File Structure&lt;/h2&gt; 
&lt;p&gt;The files under config will be automatically loaded at the appropriate time, so you don't need to require those files manually. &lt;strong&gt;LazyVim&lt;/strong&gt; comes with a set of default config files that will be loaded &lt;strong&gt;&lt;em&gt;before&lt;/em&gt;&lt;/strong&gt; your own. See &lt;a href="https://github.com/LazyVim/LazyVim/tree/main/lua/lazyvim/config"&gt;here&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;You can add your custom plugin specs under &lt;code&gt;lua/plugins/&lt;/code&gt;. All files there will be automatically loaded by &lt;a href="https://github.com/folke/lazy.nvim"&gt;lazy.nvim&lt;/a&gt;&lt;/p&gt; 
&lt;pre&gt;
~/.config/nvim
‚îú‚îÄ‚îÄ lua
‚îÇ&amp;nbsp;&amp;nbsp; ‚îú‚îÄ‚îÄ config
‚îÇ&amp;nbsp;&amp;nbsp; ‚îÇ&amp;nbsp;&amp;nbsp; ‚îú‚îÄ‚îÄ autocmds.lua
‚îÇ&amp;nbsp;&amp;nbsp; ‚îÇ&amp;nbsp;&amp;nbsp; ‚îú‚îÄ‚îÄ keymaps.lua
‚îÇ&amp;nbsp;&amp;nbsp; ‚îÇ&amp;nbsp;&amp;nbsp; ‚îú‚îÄ‚îÄ lazy.lua
‚îÇ&amp;nbsp;&amp;nbsp; ‚îÇ&amp;nbsp;&amp;nbsp; ‚îî‚îÄ‚îÄ options.lua
‚îÇ&amp;nbsp;&amp;nbsp; ‚îî‚îÄ‚îÄ plugins
‚îÇ&amp;nbsp;&amp;nbsp;     ‚îú‚îÄ‚îÄ spec1.lua
‚îÇ&amp;nbsp;&amp;nbsp;     ‚îú‚îÄ‚îÄ **
‚îÇ&amp;nbsp;&amp;nbsp;     ‚îî‚îÄ‚îÄ spec2.lua
‚îî‚îÄ‚îÄ init.lua
&lt;/pre&gt; 
&lt;h2&gt;‚öôÔ∏è Configuration&lt;/h2&gt; 
&lt;p&gt;Refer to the &lt;a href="https://lazyvim.github.io"&gt;docs&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>HKUDS/RAG-Anything</title>
      <link>https://github.com/HKUDS/RAG-Anything</link>
      <description>&lt;p&gt;"RAG-Anything: All-in-One RAG Framework"&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;div style="margin: 20px 0;"&gt; 
  &lt;img src="https://raw.githubusercontent.com/HKUDS/RAG-Anything/main/assets/logo.png" width="120" height="120" alt="RAG-Anything Logo" style="border-radius: 20px; box-shadow: 0 8px 32px rgba(0, 217, 255, 0.3);" /&gt; 
 &lt;/div&gt; 
 &lt;h1&gt;üöÄ RAG-Anything: All-in-One RAG Framework&lt;/h1&gt; 
 &lt;p&gt;&lt;a href="https://trendshift.io/repositories/14959" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/14959" alt="HKUDS%2FRAG-Anything | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;div align="center"&gt; 
  &lt;img src="https://readme-typing-svg.herokuapp.com?font=Orbitron&amp;amp;size=24&amp;amp;duration=3000&amp;amp;pause=1000&amp;amp;color=00D9FF&amp;amp;center=true&amp;amp;vCenter=true&amp;amp;width=600&amp;amp;lines=Welcome+to+RAG-Anything;Next-Gen+Multimodal+RAG+System;Powered+by+Advanced+AI+Technology" alt="Typing Animation" /&gt; 
 &lt;/div&gt; 
 &lt;div align="center"&gt; 
  &lt;div style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); border-radius: 15px; padding: 25px; text-align: center;"&gt; 
   &lt;p&gt; &lt;a href="https://github.com/HKUDS/RAG-Anything"&gt;&lt;img src="https://img.shields.io/badge/üî•Project-Page-00d9ff?style=for-the-badge&amp;amp;logo=github&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt;&lt;/a&gt; &lt;a href="https://arxiv.org/abs/2410.05779"&gt;&lt;img src="https://img.shields.io/badge/üìÑarXiv-2410.05779-ff6b6b?style=for-the-badge&amp;amp;logo=arxiv&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt;&lt;/a&gt; &lt;a href="https://github.com/HKUDS/LightRAG"&gt;&lt;img src="https://img.shields.io/badge/‚ö°Based%20on-LightRAG-4ecdc4?style=for-the-badge&amp;amp;logo=lightning&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt;&lt;/a&gt; &lt;/p&gt; 
   &lt;p&gt; &lt;a href="https://github.com/HKUDS/RAG-Anything/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/HKUDS/RAG-Anything?color=00d9ff&amp;amp;style=for-the-badge&amp;amp;logo=star&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/badge/üêçPython-3.10-4ecdc4?style=for-the-badge&amp;amp;logo=python&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt; &lt;a href="https://pypi.org/project/raganything/"&gt;&lt;img src="https://img.shields.io/pypi/v/raganything.svg?style=for-the-badge&amp;amp;logo=pypi&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e&amp;amp;color=ff6b6b" /&gt;&lt;/a&gt; &lt;a href="https://github.com/astral-sh/uv"&gt;&lt;img src="https://img.shields.io/badge/‚ö°uv-Ready-ff6b6b?style=for-the-badge&amp;amp;logo=python&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt;&lt;/a&gt; &lt;/p&gt; 
   &lt;p&gt; &lt;a href="https://discord.gg/yF2MmDJyGJ"&gt;&lt;img src="https://img.shields.io/badge/üí¨Discord-Community-7289da?style=for-the-badge&amp;amp;logo=discord&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt;&lt;/a&gt; &lt;a href="https://github.com/HKUDS/RAG-Anything/issues/7"&gt;&lt;img src="https://img.shields.io/badge/üí¨WeChat-Group-07c160?style=for-the-badge&amp;amp;logo=wechat&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt;&lt;/a&gt; &lt;/p&gt; 
   &lt;p&gt; &lt;a href="https://raw.githubusercontent.com/HKUDS/RAG-Anything/main/README_zh.md"&gt;&lt;img src="https://img.shields.io/badge/üá®üá≥‰∏≠ÊñáÁâà-1a1a2e?style=for-the-badge" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/HKUDS/RAG-Anything/main/README.md"&gt;&lt;img src="https://img.shields.io/badge/üá∫üá∏English-1a1a2e?style=for-the-badge" /&gt;&lt;/a&gt; &lt;/p&gt; 
  &lt;/div&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;div style="width: 100%; height: 2px; margin: 20px 0; background: linear-gradient(90deg, transparent, #00d9ff, transparent);"&gt;&lt;/div&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://raw.githubusercontent.com/HKUDS/RAG-Anything/main/#-quick-start" style="text-decoration: none;"&gt; &lt;img src="https://img.shields.io/badge/Quick%20Start-Get%20Started%20Now-00d9ff?style=for-the-badge&amp;amp;logo=rocket&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üéâ News&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; [2025.08.12]üéØüì¢ üîç RAG-Anything now features &lt;strong&gt;VLM-Enhanced Query&lt;/strong&gt; mode! When documents include images, the system seamlessly integrates them into VLM for advanced multimodal analysis, combining visual and textual context for deeper insights.&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; [2025.07.05]üéØüì¢ RAG-Anything now features a &lt;a href="https://raw.githubusercontent.com/HKUDS/RAG-Anything/main/docs/context_aware_processing.md"&gt;context configuration module&lt;/a&gt;, enabling intelligent integration of relevant contextual information to enhance multimodal content processing.&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; [2025.07.04]üéØüì¢ üöÄ RAG-Anything now supports multimodal query capabilities, enabling enhanced RAG with seamless processing of text, images, tables, and equations.&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; [2025.07.03]üéØüì¢ üéâ RAG-Anything has reached 1küåü stars on GitHub! Thank you for your incredible support and valuable contributions to the project.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üåü System Overview&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Next-Generation Multimodal Intelligence&lt;/em&gt;&lt;/p&gt; 
&lt;div style="background: linear-gradient(135deg, #1a1a2e 0%, #16213e 50%, #0f3460 100%); border-radius: 15px; padding: 25px; margin: 20px 0; border: 2px solid #00d9ff; box-shadow: 0 0 30px rgba(0, 217, 255, 0.3);"&gt; 
 &lt;p&gt;Modern documents increasingly contain diverse multimodal content‚Äîtext, images, tables, equations, charts, and multimedia‚Äîthat traditional text-focused RAG systems cannot effectively process. &lt;strong&gt;RAG-Anything&lt;/strong&gt; addresses this challenge as a comprehensive &lt;strong&gt;All-in-One Multimodal Document Processing RAG system&lt;/strong&gt; built on &lt;a href="https://github.com/HKUDS/LightRAG"&gt;LightRAG&lt;/a&gt;.&lt;/p&gt; 
 &lt;p&gt;As a unified solution, RAG-Anything &lt;strong&gt;eliminates the need for multiple specialized tools&lt;/strong&gt;. It provides &lt;strong&gt;seamless processing and querying across all content modalities&lt;/strong&gt; within a single integrated framework. Unlike conventional RAG approaches that struggle with non-textual elements, our all-in-one system delivers &lt;strong&gt;comprehensive multimodal retrieval capabilities&lt;/strong&gt;.&lt;/p&gt; 
 &lt;p&gt;Users can query documents containing &lt;strong&gt;interleaved text&lt;/strong&gt;, &lt;strong&gt;visual diagrams&lt;/strong&gt;, &lt;strong&gt;structured tables&lt;/strong&gt;, and &lt;strong&gt;mathematical formulations&lt;/strong&gt; through &lt;strong&gt;one cohesive interface&lt;/strong&gt;. This consolidated approach makes RAG-Anything particularly valuable for academic research, technical documentation, financial reports, and enterprise knowledge management where rich, mixed-content documents demand a &lt;strong&gt;unified processing framework&lt;/strong&gt;.&lt;/p&gt; 
 &lt;img src="https://raw.githubusercontent.com/HKUDS/RAG-Anything/main/assets/rag_anything_framework.png" alt="RAG-Anything" /&gt; 
&lt;/div&gt; 
&lt;h3&gt;üéØ Key Features&lt;/h3&gt; 
&lt;div style="background: linear-gradient(135deg, #1a1a2e 0%, #16213e 100%); border-radius: 15px; padding: 25px; margin: 20px 0;"&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;üîÑ End-to-End Multimodal Pipeline&lt;/strong&gt; - Complete workflow from document ingestion and parsing to intelligent multimodal query answering&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;üìÑ Universal Document Support&lt;/strong&gt; - Seamless processing of PDFs, Office documents, images, and diverse file formats&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;üß† Specialized Content Analysis&lt;/strong&gt; - Dedicated processors for images, tables, mathematical equations, and heterogeneous content types&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;üîó Multimodal Knowledge Graph&lt;/strong&gt; - Automatic entity extraction and cross-modal relationship discovery for enhanced understanding&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;‚ö° Adaptive Processing Modes&lt;/strong&gt; - Flexible MinerU-based parsing or direct multimodal content injection workflows&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;üìã Direct Content List Insertion&lt;/strong&gt; - Bypass document parsing by directly inserting pre-parsed content lists from external sources&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;üéØ Hybrid Intelligent Retrieval&lt;/strong&gt; - Advanced search capabilities spanning textual and multimodal content with contextual understanding&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üèóÔ∏è Algorithm &amp;amp; Architecture&lt;/h2&gt; 
&lt;div style="background: linear-gradient(135deg, #0f0f23 0%, #1a1a2e 100%); border-radius: 15px; padding: 25px; margin: 20px 0; border-left: 5px solid #00d9ff;"&gt; 
 &lt;h3&gt;Core Algorithm&lt;/h3&gt; 
 &lt;p&gt;&lt;strong&gt;RAG-Anything&lt;/strong&gt; implements an effective &lt;strong&gt;multi-stage multimodal pipeline&lt;/strong&gt; that fundamentally extends traditional RAG architectures to seamlessly handle diverse content modalities through intelligent orchestration and cross-modal understanding.&lt;/p&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;div style="width: 100%; max-width: 600px; margin: 20px auto; padding: 20px; background: linear-gradient(135deg, rgba(0, 217, 255, 0.1) 0%, rgba(0, 217, 255, 0.05) 100%); border-radius: 15px; border: 1px solid rgba(0, 217, 255, 0.2);"&gt; 
  &lt;div style="display: flex; justify-content: space-around; align-items: center; flex-wrap: wrap; gap: 20px;"&gt; 
   &lt;div style="text-align: center;"&gt; 
    &lt;div style="font-size: 24px; margin-bottom: 10px;"&gt;
     üìÑ
    &lt;/div&gt; 
    &lt;div style="font-size: 14px; color: #00d9ff;"&gt;
     Document Parsing
    &lt;/div&gt; 
   &lt;/div&gt; 
   &lt;div style="font-size: 20px; color: #00d9ff;"&gt;
    ‚Üí
   &lt;/div&gt; 
   &lt;div style="text-align: center;"&gt; 
    &lt;div style="font-size: 24px; margin-bottom: 10px;"&gt;
     üß†
    &lt;/div&gt; 
    &lt;div style="font-size: 14px; color: #00d9ff;"&gt;
     Content Analysis
    &lt;/div&gt; 
   &lt;/div&gt; 
   &lt;div style="font-size: 20px; color: #00d9ff;"&gt;
    ‚Üí
   &lt;/div&gt; 
   &lt;div style="text-align: center;"&gt; 
    &lt;div style="font-size: 24px; margin-bottom: 10px;"&gt;
     üîç
    &lt;/div&gt; 
    &lt;div style="font-size: 14px; color: #00d9ff;"&gt;
     Knowledge Graph
    &lt;/div&gt; 
   &lt;/div&gt; 
   &lt;div style="font-size: 20px; color: #00d9ff;"&gt;
    ‚Üí
   &lt;/div&gt; 
   &lt;div style="text-align: center;"&gt; 
    &lt;div style="font-size: 24px; margin-bottom: 10px;"&gt;
     üéØ
    &lt;/div&gt; 
    &lt;div style="font-size: 14px; color: #00d9ff;"&gt;
     Intelligent Retrieval
    &lt;/div&gt; 
   &lt;/div&gt; 
  &lt;/div&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;h3&gt;1. Document Parsing Stage&lt;/h3&gt; 
&lt;div style="background: linear-gradient(90deg, #1a1a2e 0%, #16213e 100%); border-radius: 10px; padding: 20px; margin: 15px 0; border-left: 4px solid #4ecdc4;"&gt; 
 &lt;p&gt;The system provides high-fidelity document extraction through adaptive content decomposition. It intelligently segments heterogeneous elements while preserving contextual relationships. Universal format compatibility is achieved via specialized optimized parsers.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Key Components:&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;‚öôÔ∏è MinerU Integration&lt;/strong&gt;: Leverages &lt;a href="https://github.com/opendatalab/MinerU"&gt;MinerU&lt;/a&gt; for high-fidelity document structure extraction and semantic preservation across complex layouts.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;üß© Adaptive Content Decomposition&lt;/strong&gt;: Automatically segments documents into coherent text blocks, visual elements, structured tables, mathematical equations, and specialized content types while preserving contextual relationships.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;üìÅ Universal Format Support&lt;/strong&gt;: Provides comprehensive handling of PDFs, Office documents (DOC/DOCX/PPT/PPTX/XLS/XLSX), images, and emerging formats through specialized parsers with format-specific optimization.&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/div&gt; 
&lt;h3&gt;2. Multi-Modal Content Understanding &amp;amp; Processing&lt;/h3&gt; 
&lt;div style="background: linear-gradient(90deg, #16213e 0%, #0f3460 100%); border-radius: 10px; padding: 20px; margin: 15px 0; border-left: 4px solid #ff6b6b;"&gt; 
 &lt;p&gt;The system automatically categorizes and routes content through optimized channels. It uses concurrent pipelines for parallel text and multimodal processing. Document hierarchy and relationships are preserved during transformation.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Key Components:&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;üéØ Autonomous Content Categorization and Routing&lt;/strong&gt;: Automatically identify, categorize, and route different content types through optimized execution channels.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;‚ö° Concurrent Multi-Pipeline Architecture&lt;/strong&gt;: Implements concurrent execution of textual and multimodal content through dedicated processing pipelines. This approach maximizes throughput efficiency while preserving content integrity.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;üèóÔ∏è Document Hierarchy Extraction&lt;/strong&gt;: Extracts and preserves original document hierarchy and inter-element relationships during content transformation.&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/div&gt; 
&lt;h3&gt;3. Multimodal Analysis Engine&lt;/h3&gt; 
&lt;div style="background: linear-gradient(90deg, #0f3460 0%, #1a1a2e 100%); border-radius: 10px; padding: 20px; margin: 15px 0; border-left: 4px solid #00d9ff;"&gt; 
 &lt;p&gt;The system deploys modality-aware processing units for heterogeneous data modalities:&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Specialized Analyzers:&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;üîç Visual Content Analyzer&lt;/strong&gt;:&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Integrate vision model for image analysis.&lt;/li&gt; 
    &lt;li&gt;Generates context-aware descriptive captions based on visual semantics.&lt;/li&gt; 
    &lt;li&gt;Extracts spatial relationships and hierarchical structures between visual elements.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;üìä Structured Data Interpreter&lt;/strong&gt;:&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Performs systematic interpretation of tabular and structured data formats.&lt;/li&gt; 
    &lt;li&gt;Implements statistical pattern recognition algorithms for data trend analysis.&lt;/li&gt; 
    &lt;li&gt;Identifies semantic relationships and dependencies across multiple tabular datasets.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;üìê Mathematical Expression Parser&lt;/strong&gt;:&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Parses complex mathematical expressions and formulas with high accuracy.&lt;/li&gt; 
    &lt;li&gt;Provides native LaTeX format support for seamless integration with academic workflows.&lt;/li&gt; 
    &lt;li&gt;Establishes conceptual mappings between mathematical equations and domain-specific knowledge bases.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;üîß Extensible Modality Handler&lt;/strong&gt;:&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Provides configurable processing framework for custom and emerging content types.&lt;/li&gt; 
    &lt;li&gt;Enables dynamic integration of new modality processors through plugin architecture.&lt;/li&gt; 
    &lt;li&gt;Supports runtime configuration of processing pipelines for specialized use cases.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/div&gt; 
&lt;h3&gt;4. Multimodal Knowledge Graph Index&lt;/h3&gt; 
&lt;div style="background: linear-gradient(90deg, #1a1a2e 0%, #16213e 100%); border-radius: 10px; padding: 20px; margin: 15px 0; border-left: 4px solid #4ecdc4;"&gt; 
 &lt;p&gt;The multi-modal knowledge graph construction module transforms document content into structured semantic representations. It extracts multimodal entities, establishes cross-modal relationships, and preserves hierarchical organization. The system applies weighted relevance scoring for optimized knowledge retrieval.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Core Functions:&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;üîç Multi-Modal Entity Extraction&lt;/strong&gt;: Transforms significant multimodal elements into structured knowledge graph entities. The process includes semantic annotations and metadata preservation.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;üîó Cross-Modal Relationship Mapping&lt;/strong&gt;: Establishes semantic connections and dependencies between textual entities and multimodal components. This is achieved through automated relationship inference algorithms.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;üèóÔ∏è Hierarchical Structure Preservation&lt;/strong&gt;: Maintains original document organization through "belongs_to" relationship chains. These chains preserve logical content hierarchy and sectional dependencies.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;‚öñÔ∏è Weighted Relationship Scoring&lt;/strong&gt;: Assigns quantitative relevance scores to relationship types. Scoring is based on semantic proximity and contextual significance within the document structure.&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/div&gt; 
&lt;h3&gt;5. Modality-Aware Retrieval&lt;/h3&gt; 
&lt;div style="background: linear-gradient(90deg, #16213e 0%, #0f3460 100%); border-radius: 10px; padding: 20px; margin: 15px 0; border-left: 4px solid #ff6b6b;"&gt; 
 &lt;p&gt;The hybrid retrieval system combines vector similarity search with graph traversal algorithms for comprehensive content retrieval. It implements modality-aware ranking mechanisms and maintains relational coherence between retrieved elements to ensure contextually integrated information delivery.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Retrieval Mechanisms:&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;üîÄ Vector-Graph Fusion&lt;/strong&gt;: Integrates vector similarity search with graph traversal algorithms. This approach leverages both semantic embeddings and structural relationships for comprehensive content retrieval.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;üìä Modality-Aware Ranking&lt;/strong&gt;: Implements adaptive scoring mechanisms that weight retrieval results based on content type relevance. The system adjusts rankings according to query-specific modality preferences.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;üîó Relational Coherence Maintenance&lt;/strong&gt;: Maintains semantic and structural relationships between retrieved elements. This ensures coherent information delivery and contextual integrity.&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üöÄ Quick Start&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Initialize Your AI Journey&lt;/em&gt;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://user-images.githubusercontent.com/74038190/212284158-e840e285-664b-44d7-b79b-e264b5e54825.gif" width="400" /&gt; 
&lt;/div&gt; 
&lt;h3&gt;Installation&lt;/h3&gt; 
&lt;h4&gt;Option 1: Install from PyPI (Recommended)&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Basic installation
pip install raganything

# With optional dependencies for extended format support:
pip install 'raganything[all]'              # All optional features
pip install 'raganything[image]'            # Image format conversion (BMP, TIFF, GIF, WebP)
pip install 'raganything[text]'             # Text file processing (TXT, MD)
pip install 'raganything[image,text]'       # Multiple features
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Option 2: Install from Source&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Install uv (if not already installed)
curl -LsSf https://astral.sh/uv/install.sh | sh

# Clone and setup the project with uv
git clone https://github.com/HKUDS/RAG-Anything.git
cd RAG-Anything

# Install the package and dependencies in a virtual environment
uv sync

# If you encounter network timeouts (especially for opencv packages):
# UV_HTTP_TIMEOUT=120 uv sync

# Run commands directly with uv (recommended approach)
uv run python examples/raganything_example.py --help

# Install with optional dependencies
uv sync --extra image --extra text  # Specific extras
uv sync --all-extras                 # All optional features
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Optional Dependencies&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;[image]&lt;/code&gt;&lt;/strong&gt; - Enables processing of BMP, TIFF, GIF, WebP image formats (requires Pillow)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;[text]&lt;/code&gt;&lt;/strong&gt; - Enables processing of TXT and MD files (requires ReportLab)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;[all]&lt;/code&gt;&lt;/strong&gt; - Includes all Python optional dependencies&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;‚ö†Ô∏è Office Document Processing Requirements:&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Office documents (.doc, .docx, .ppt, .pptx, .xls, .xlsx) require &lt;strong&gt;LibreOffice&lt;/strong&gt; installation&lt;/li&gt; 
  &lt;li&gt;Download from &lt;a href="https://www.libreoffice.org/download/download/"&gt;LibreOffice official website&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Windows&lt;/strong&gt;: Download installer from official website&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;macOS&lt;/strong&gt;: &lt;code&gt;brew install --cask libreoffice&lt;/code&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Ubuntu/Debian&lt;/strong&gt;: &lt;code&gt;sudo apt-get install libreoffice&lt;/code&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;CentOS/RHEL&lt;/strong&gt;: &lt;code&gt;sudo yum install libreoffice&lt;/code&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;Check MinerU installation:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Verify installation
mineru --version

# Check if properly configured
python -c "from raganything import RAGAnything; rag = RAGAnything(); print('‚úÖ MinerU installed properly' if rag.check_parser_installation() else '‚ùå MinerU installation issue')"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Models are downloaded automatically on first use. For manual download, refer to &lt;a href="https://github.com/opendatalab/MinerU/raw/master/README.md#22-model-source-configuration"&gt;MinerU Model Source Configuration&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Usage Examples&lt;/h3&gt; 
&lt;h4&gt;1. End-to-End Document Processing&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import asyncio
from raganything import RAGAnything, RAGAnythingConfig
from lightrag.llm.openai import openai_complete_if_cache, openai_embed
from lightrag.utils import EmbeddingFunc

async def main():
    # Set up API configuration
    api_key = "your-api-key"
    base_url = "your-base-url"  # Optional

    # Create RAGAnything configuration
    config = RAGAnythingConfig(
        working_dir="./rag_storage",
        parser="mineru",  # Parser selection: mineru or docling
        parse_method="auto",  # Parse method: auto, ocr, or txt
        enable_image_processing=True,
        enable_table_processing=True,
        enable_equation_processing=True,
    )

    # Define LLM model function
    def llm_model_func(prompt, system_prompt=None, history_messages=[], **kwargs):
        return openai_complete_if_cache(
            "gpt-4o-mini",
            prompt,
            system_prompt=system_prompt,
            history_messages=history_messages,
            api_key=api_key,
            base_url=base_url,
            **kwargs,
        )

    # Define vision model function for image processing
    def vision_model_func(
        prompt, system_prompt=None, history_messages=[], image_data=None, messages=None, **kwargs
    ):
        # If messages format is provided (for multimodal VLM enhanced query), use it directly
        if messages:
            return openai_complete_if_cache(
                "gpt-4o",
                "",
                system_prompt=None,
                history_messages=[],
                messages=messages,
                api_key=api_key,
                base_url=base_url,
                **kwargs,
            )
        # Traditional single image format
        elif image_data:
            return openai_complete_if_cache(
                "gpt-4o",
                "",
                system_prompt=None,
                history_messages=[],
                messages=[
                    {"role": "system", "content": system_prompt}
                    if system_prompt
                    else None,
                    {
                        "role": "user",
                        "content": [
                            {"type": "text", "text": prompt},
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": f"data:image/jpeg;base64,{image_data}"
                                },
                            },
                        ],
                    }
                    if image_data
                    else {"role": "user", "content": prompt},
                ],
                api_key=api_key,
                base_url=base_url,
                **kwargs,
            )
        # Pure text format
        else:
            return llm_model_func(prompt, system_prompt, history_messages, **kwargs)

    # Define embedding function
    embedding_func = EmbeddingFunc(
        embedding_dim=3072,
        max_token_size=8192,
        func=lambda texts: openai_embed(
            texts,
            model="text-embedding-3-large",
            api_key=api_key,
            base_url=base_url,
        ),
    )

    # Initialize RAGAnything
    rag = RAGAnything(
        config=config,
        llm_model_func=llm_model_func,
        vision_model_func=vision_model_func,
        embedding_func=embedding_func,
    )

    # Process a document
    await rag.process_document_complete(
        file_path="path/to/your/document.pdf",
        output_dir="./output",
        parse_method="auto"
    )

    # Query the processed content
    # Pure text query - for basic knowledge base search
    text_result = await rag.aquery(
        "What are the main findings shown in the figures and tables?",
        mode="hybrid"
    )
    print("Text query result:", text_result)

    # Multimodal query with specific multimodal content
    multimodal_result = await rag.aquery_with_multimodal(
    "Explain this formula and its relevance to the document content",
    multimodal_content=[{
        "type": "equation",
        "latex": "P(d|q) = \\frac{P(q|d) \\cdot P(d)}{P(q)}",
        "equation_caption": "Document relevance probability"
    }],
    mode="hybrid"
)
    print("Multimodal query result:", multimodal_result)

if __name__ == "__main__":
    asyncio.run(main())
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;2. Direct Multimodal Content Processing&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import asyncio
from lightrag import LightRAG
from lightrag.llm.openai import openai_complete_if_cache, openai_embed
from lightrag.utils import EmbeddingFunc
from raganything.modalprocessors import ImageModalProcessor, TableModalProcessor

async def process_multimodal_content():
    # Set up API configuration
    api_key = "your-api-key"
    base_url = "your-base-url"  # Optional

    # Initialize LightRAG
    rag = LightRAG(
        working_dir="./rag_storage",
        llm_model_func=lambda prompt, system_prompt=None, history_messages=[], **kwargs: openai_complete_if_cache(
            "gpt-4o-mini",
            prompt,
            system_prompt=system_prompt,
            history_messages=history_messages,
            api_key=api_key,
            base_url=base_url,
            **kwargs,
        ),
        embedding_func=EmbeddingFunc(
            embedding_dim=3072,
            max_token_size=8192,
            func=lambda texts: openai_embed(
                texts,
                model="text-embedding-3-large",
                api_key=api_key,
                base_url=base_url,
            ),
        )
    )
    await rag.initialize_storages()

    # Process an image
    image_processor = ImageModalProcessor(
        lightrag=rag,
        modal_caption_func=lambda prompt, system_prompt=None, history_messages=[], image_data=None, **kwargs: openai_complete_if_cache(
            "gpt-4o",
            "",
            system_prompt=None,
            history_messages=[],
            messages=[
                {"role": "system", "content": system_prompt} if system_prompt else None,
                {"role": "user", "content": [
                    {"type": "text", "text": prompt},
                    {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{image_data}"}}
                ]} if image_data else {"role": "user", "content": prompt}
            ],
            api_key=api_key,
            base_url=base_url,
            **kwargs,
        ) if image_data else openai_complete_if_cache(
            "gpt-4o-mini",
            prompt,
            system_prompt=system_prompt,
            history_messages=history_messages,
            api_key=api_key,
            base_url=base_url,
            **kwargs,
        )
    )

    image_content = {
        "img_path": "path/to/image.jpg",
        "image_caption": ["Figure 1: Experimental results"],
        "image_footnote": ["Data collected in 2024"]
    }

    description, entity_info = await image_processor.process_multimodal_content(
        modal_content=image_content,
        content_type="image",
        file_path="research_paper.pdf",
        entity_name="Experimental Results Figure"
    )

    # Process a table
    table_processor = TableModalProcessor(
        lightrag=rag,
        modal_caption_func=lambda prompt, system_prompt=None, history_messages=[], **kwargs: openai_complete_if_cache(
            "gpt-4o-mini",
            prompt,
            system_prompt=system_prompt,
            history_messages=history_messages,
            api_key=api_key,
            base_url=base_url,
            **kwargs,
        )
    )

    table_content = {
        "table_body": """
        | Method | Accuracy | F1-Score |
        |--------|----------|----------|
        | RAGAnything | 95.2% | 0.94 |
        | Baseline | 87.3% | 0.85 |
        """,
        "table_caption": ["Performance Comparison"],
        "table_footnote": ["Results on test dataset"]
    }

    description, entity_info = await table_processor.process_multimodal_content(
        modal_content=table_content,
        content_type="table",
        file_path="research_paper.pdf",
        entity_name="Performance Results Table"
    )

if __name__ == "__main__":
    asyncio.run(process_multimodal_content())
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;3. Batch Processing&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# Process multiple documents
await rag.process_folder_complete(
    folder_path="./documents",
    output_dir="./output",
    file_extensions=[".pdf", ".docx", ".pptx"],
    recursive=True,
    max_workers=4
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;4. Custom Modal Processors&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from raganything.modalprocessors import GenericModalProcessor

class CustomModalProcessor(GenericModalProcessor):
    async def process_multimodal_content(self, modal_content, content_type, file_path, entity_name):
        # Your custom processing logic
        enhanced_description = await self.analyze_custom_content(modal_content)
        entity_info = self.create_custom_entity(enhanced_description, entity_name)
        return await self._create_entity_and_chunk(enhanced_description, entity_info, file_path)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;5. Query Options&lt;/h4&gt; 
&lt;p&gt;RAG-Anything provides three types of query methods:&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Pure Text Queries&lt;/strong&gt; - Direct knowledge base search using LightRAG:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# Different query modes for text queries
text_result_hybrid = await rag.aquery("Your question", mode="hybrid")
text_result_local = await rag.aquery("Your question", mode="local")
text_result_global = await rag.aquery("Your question", mode="global")
text_result_naive = await rag.aquery("Your question", mode="naive")

# Synchronous version
sync_text_result = rag.query("Your question", mode="hybrid")
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;VLM Enhanced Queries&lt;/strong&gt; - Automatically analyze images in retrieved context using VLM:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# VLM enhanced query (automatically enabled when vision_model_func is provided)
vlm_result = await rag.aquery(
    "Analyze the charts and figures in the document",
    mode="hybrid"
    # vlm_enhanced=True is automatically set when vision_model_func is available
)

# Manually control VLM enhancement
vlm_enabled = await rag.aquery(
    "What do the images show in this document?",
    mode="hybrid",
    vlm_enhanced=True  # Force enable VLM enhancement
)

vlm_disabled = await rag.aquery(
    "What do the images show in this document?",
    mode="hybrid",
    vlm_enhanced=False  # Force disable VLM enhancement
)

# When documents contain images, VLM can see and analyze them directly
# The system will automatically:
# 1. Retrieve relevant context containing image paths
# 2. Load and encode images as base64
# 3. Send both text context and images to VLM for comprehensive analysis
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Multimodal Queries&lt;/strong&gt; - Enhanced queries with specific multimodal content analysis:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# Query with table data
table_result = await rag.aquery_with_multimodal(
    "Compare these performance metrics with the document content",
    multimodal_content=[{
        "type": "table",
        "table_data": """Method,Accuracy,Speed
                        RAGAnything,95.2%,120ms
                        Traditional,87.3%,180ms""",
        "table_caption": "Performance comparison"
    }],
    mode="hybrid"
)

# Query with equation content
equation_result = await rag.aquery_with_multimodal(
    "Explain this formula and its relevance to the document content",
    multimodal_content=[{
        "type": "equation",
        "latex": "P(d|q) = \\frac{P(q|d) \\cdot P(d)}{P(q)}",
        "equation_caption": "Document relevance probability"
    }],
    mode="hybrid"
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;6. Loading Existing LightRAG Instance&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import asyncio
from raganything import RAGAnything, RAGAnythingConfig
from lightrag import LightRAG
from lightrag.llm.openai import openai_complete_if_cache, openai_embed
from lightrag.kg.shared_storage import initialize_pipeline_status
from lightrag.utils import EmbeddingFunc
import os

async def load_existing_lightrag():
    # Set up API configuration
    api_key = "your-api-key"
    base_url = "your-base-url"  # Optional

    # First, create or load existing LightRAG instance
    lightrag_working_dir = "./existing_lightrag_storage"

    # Check if previous LightRAG instance exists
    if os.path.exists(lightrag_working_dir) and os.listdir(lightrag_working_dir):
        print("‚úÖ Found existing LightRAG instance, loading...")
    else:
        print("‚ùå No existing LightRAG instance found, will create new one")

    # Create/load LightRAG instance with your configuration
    lightrag_instance = LightRAG(
        working_dir=lightrag_working_dir,
        llm_model_func=lambda prompt, system_prompt=None, history_messages=[], **kwargs: openai_complete_if_cache(
            "gpt-4o-mini",
            prompt,
            system_prompt=system_prompt,
            history_messages=history_messages,
            api_key=api_key,
            base_url=base_url,
            **kwargs,
        ),
        embedding_func=EmbeddingFunc(
            embedding_dim=3072,
            max_token_size=8192,
            func=lambda texts: openai_embed(
                texts,
                model="text-embedding-3-large",
                api_key=api_key,
                base_url=base_url,
            ),
        )
    )

    # Initialize storage (this will load existing data if available)
    await lightrag_instance.initialize_storages()
    await initialize_pipeline_status()

    # Define vision model function for image processing
    def vision_model_func(
        prompt, system_prompt=None, history_messages=[], image_data=None, messages=None, **kwargs
    ):
        # If messages format is provided (for multimodal VLM enhanced query), use it directly
        if messages:
            return openai_complete_if_cache(
                "gpt-4o",
                "",
                system_prompt=None,
                history_messages=[],
                messages=messages,
                api_key=api_key,
                base_url=base_url,
                **kwargs,
            )
        # Traditional single image format
        elif image_data:
            return openai_complete_if_cache(
                "gpt-4o",
                "",
                system_prompt=None,
                history_messages=[],
                messages=[
                    {"role": "system", "content": system_prompt}
                    if system_prompt
                    else None,
                    {
                        "role": "user",
                        "content": [
                            {"type": "text", "text": prompt},
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": f"data:image/jpeg;base64,{image_data}"
                                },
                            },
                        ],
                    }
                    if image_data
                    else {"role": "user", "content": prompt},
                ],
                api_key=api_key,
                base_url=base_url,
                **kwargs,
            )
        # Pure text format
        else:
            return lightrag_instance.llm_model_func(prompt, system_prompt, history_messages, **kwargs)

    # Now use existing LightRAG instance to initialize RAGAnything
    rag = RAGAnything(
        lightrag=lightrag_instance,  # Pass existing LightRAG instance
        vision_model_func=vision_model_func,
        # Note: working_dir, llm_model_func, embedding_func, etc. are inherited from lightrag_instance
    )

    # Query existing knowledge base
    result = await rag.aquery(
        "What data has been processed in this LightRAG instance?",
        mode="hybrid"
    )
    print("Query result:", result)

    # Add new multimodal document to existing LightRAG instance
    await rag.process_document_complete(
        file_path="path/to/new/multimodal_document.pdf",
        output_dir="./output"
    )

if __name__ == "__main__":
    asyncio.run(load_existing_lightrag())
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;7. Direct Content List Insertion&lt;/h4&gt; 
&lt;p&gt;For scenarios where you already have a pre-parsed content list (e.g., from external parsers or previous processing), you can directly insert it into RAGAnything without document parsing:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import asyncio
from raganything import RAGAnything, RAGAnythingConfig
from lightrag.llm.openai import openai_complete_if_cache, openai_embed
from lightrag.utils import EmbeddingFunc

async def insert_content_list_example():
    # Set up API configuration
    api_key = "your-api-key"
    base_url = "your-base-url"  # Optional

    # Create RAGAnything configuration
    config = RAGAnythingConfig(
        working_dir="./rag_storage",
        enable_image_processing=True,
        enable_table_processing=True,
        enable_equation_processing=True,
    )

    # Define model functions
    def llm_model_func(prompt, system_prompt=None, history_messages=[], **kwargs):
        return openai_complete_if_cache(
            "gpt-4o-mini",
            prompt,
            system_prompt=system_prompt,
            history_messages=history_messages,
            api_key=api_key,
            base_url=base_url,
            **kwargs,
        )

    def vision_model_func(prompt, system_prompt=None, history_messages=[], image_data=None, messages=None, **kwargs):
        # If messages format is provided (for multimodal VLM enhanced query), use it directly
        if messages:
            return openai_complete_if_cache(
                "gpt-4o",
                "",
                system_prompt=None,
                history_messages=[],
                messages=messages,
                api_key=api_key,
                base_url=base_url,
                **kwargs,
            )
        # Traditional single image format
        elif image_data:
            return openai_complete_if_cache(
                "gpt-4o",
                "",
                system_prompt=None,
                history_messages=[],
                messages=[
                    {"role": "system", "content": system_prompt} if system_prompt else None,
                    {
                        "role": "user",
                        "content": [
                            {"type": "text", "text": prompt},
                            {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{image_data}"}}
                        ],
                    } if image_data else {"role": "user", "content": prompt},
                ],
                api_key=api_key,
                base_url=base_url,
                **kwargs,
            )
        # Pure text format
        else:
            return llm_model_func(prompt, system_prompt, history_messages, **kwargs)

    embedding_func = EmbeddingFunc(
        embedding_dim=3072,
        max_token_size=8192,
        func=lambda texts: openai_embed(
            texts,
            model="text-embedding-3-large",
            api_key=api_key,
            base_url=base_url,
        ),
    )

    # Initialize RAGAnything
    rag = RAGAnything(
        config=config,
        llm_model_func=llm_model_func,
        vision_model_func=vision_model_func,
        embedding_func=embedding_func,
    )

    # Example: Pre-parsed content list from external source
    content_list = [
        {
            "type": "text",
            "text": "This is the introduction section of our research paper.",
            "page_idx": 0  # Page number where this content appears
        },
        {
            "type": "image",
            "img_path": "/absolute/path/to/figure1.jpg",  # IMPORTANT: Use absolute path
            "image_caption": ["Figure 1: System Architecture"],
            "image_footnote": ["Source: Authors' original design"],
            "page_idx": 1  # Page number where this image appears
        },
        {
            "type": "table",
            "table_body": "| Method | Accuracy | F1-Score |\n|--------|----------|----------|\n| Ours | 95.2% | 0.94 |\n| Baseline | 87.3% | 0.85 |",
            "table_caption": ["Table 1: Performance Comparison"],
            "table_footnote": ["Results on test dataset"],
            "page_idx": 2  # Page number where this table appears
        },
        {
            "type": "equation",
            "latex": "P(d|q) = \\frac{P(q|d) \\cdot P(d)}{P(q)}",
            "text": "Document relevance probability formula",
            "page_idx": 3  # Page number where this equation appears
        },
        {
            "type": "text",
            "text": "In conclusion, our method demonstrates superior performance across all metrics.",
            "page_idx": 4  # Page number where this content appears
        }
    ]

    # Insert the content list directly
    await rag.insert_content_list(
        content_list=content_list,
        file_path="research_paper.pdf",  # Reference file name for citation
        split_by_character=None,         # Optional text splitting
        split_by_character_only=False,   # Optional text splitting mode
        doc_id=None,                     # Optional custom document ID (will be auto-generated if not provided)
        display_stats=True               # Show content statistics
    )

    # Query the inserted content
    result = await rag.aquery(
        "What are the key findings and performance metrics mentioned in the research?",
        mode="hybrid"
    )
    print("Query result:", result)

    # You can also insert multiple content lists with different document IDs
    another_content_list = [
        {
            "type": "text",
            "text": "This is content from another document.",
            "page_idx": 0  # Page number where this content appears
        },
        {
            "type": "table",
            "table_body": "| Feature | Value |\n|---------|-------|\n| Speed | Fast |\n| Accuracy | High |",
            "table_caption": ["Feature Comparison"],
            "page_idx": 1  # Page number where this table appears
        }
    ]

    await rag.insert_content_list(
        content_list=another_content_list,
        file_path="another_document.pdf",
        doc_id="custom-doc-id-123"  # Custom document ID
    )

if __name__ == "__main__":
    asyncio.run(insert_content_list_example())
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Content List Format:&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;The &lt;code&gt;content_list&lt;/code&gt; should follow the standard format with each item being a dictionary containing:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Text content&lt;/strong&gt;: &lt;code&gt;{"type": "text", "text": "content text", "page_idx": 0}&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Image content&lt;/strong&gt;: &lt;code&gt;{"type": "image", "img_path": "/absolute/path/to/image.jpg", "image_caption": ["caption"], "image_footnote": ["note"], "page_idx": 1}&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Table content&lt;/strong&gt;: &lt;code&gt;{"type": "table", "table_body": "markdown table", "table_caption": ["caption"], "table_footnote": ["note"], "page_idx": 2}&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Equation content&lt;/strong&gt;: &lt;code&gt;{"type": "equation", "latex": "LaTeX formula", "text": "description", "page_idx": 3}&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Generic content&lt;/strong&gt;: &lt;code&gt;{"type": "custom_type", "content": "any content", "page_idx": 4}&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Important Notes:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;img_path&lt;/code&gt;&lt;/strong&gt;: Must be an absolute path to the image file (e.g., &lt;code&gt;/home/user/images/chart.jpg&lt;/code&gt; or &lt;code&gt;C:\Users\user\images\chart.jpg&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;page_idx&lt;/code&gt;&lt;/strong&gt;: Represents the page number where the content appears in the original document (0-based indexing)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Content ordering&lt;/strong&gt;: Items are processed in the order they appear in the list&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;This method is particularly useful when:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;You have content from external parsers (non-MinerU/Docling)&lt;/li&gt; 
 &lt;li&gt;You want to process programmatically generated content&lt;/li&gt; 
 &lt;li&gt;You need to insert content from multiple sources into a single knowledge base&lt;/li&gt; 
 &lt;li&gt;You have cached parsing results that you want to reuse&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üõ†Ô∏è Examples&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Practical Implementation Demos&lt;/em&gt;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://user-images.githubusercontent.com/74038190/212257455-13e3e01e-d6a6-45dc-bb92-3ab87b12dfc1.gif" width="300" /&gt; 
&lt;/div&gt; 
&lt;p&gt;The &lt;code&gt;examples/&lt;/code&gt; directory contains comprehensive usage examples:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;raganything_example.py&lt;/code&gt;&lt;/strong&gt;: End-to-end document processing with MinerU&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;modalprocessors_example.py&lt;/code&gt;&lt;/strong&gt;: Direct multimodal content processing&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;office_document_test.py&lt;/code&gt;&lt;/strong&gt;: Office document parsing test with MinerU (no API key required)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;image_format_test.py&lt;/code&gt;&lt;/strong&gt;: Image format parsing test with MinerU (no API key required)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;text_format_test.py&lt;/code&gt;&lt;/strong&gt;: Text format parsing test with MinerU (no API key required)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Run examples:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# End-to-end processing with parser selection
python examples/raganything_example.py path/to/document.pdf --api-key YOUR_API_KEY --parser mineru

# Direct modal processing
python examples/modalprocessors_example.py --api-key YOUR_API_KEY

# Office document parsing test (MinerU only)
python examples/office_document_test.py --file path/to/document.docx

# Image format parsing test (MinerU only)
python examples/image_format_test.py --file path/to/image.bmp

# Text format parsing test (MinerU only)
python examples/text_format_test.py --file path/to/document.md

# Check LibreOffice installation
python examples/office_document_test.py --check-libreoffice --file dummy

# Check PIL/Pillow installation
python examples/image_format_test.py --check-pillow --file dummy

# Check ReportLab installation
python examples/text_format_test.py --check-reportlab --file dummy
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üîß Configuration&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;System Optimization Parameters&lt;/em&gt;&lt;/p&gt; 
&lt;h3&gt;Environment Variables&lt;/h3&gt; 
&lt;p&gt;Create a &lt;code&gt;.env&lt;/code&gt; file (refer to &lt;code&gt;.env.example&lt;/code&gt;):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;OPENAI_API_KEY=your_openai_api_key
OPENAI_BASE_URL=your_base_url  # Optional
OUTPUT_DIR=./output             # Default output directory for parsed documents
PARSER=mineru                   # Parser selection: mineru or docling
PARSE_METHOD=auto              # Parse method: auto, ocr, or txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; For backward compatibility, legacy environment variable names are still supported:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;MINERU_PARSE_METHOD&lt;/code&gt; is deprecated, please use &lt;code&gt;PARSE_METHOD&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: API keys are only required for full RAG processing with LLM integration. The parsing test files (&lt;code&gt;office_document_test.py&lt;/code&gt; and &lt;code&gt;image_format_test.py&lt;/code&gt;) only test parser functionality and do not require API keys.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Parser Configuration&lt;/h3&gt; 
&lt;p&gt;RAGAnything now supports multiple parsers, each with specific advantages:&lt;/p&gt; 
&lt;h4&gt;MinerU Parser&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Supports PDF, images, Office documents, and more formats&lt;/li&gt; 
 &lt;li&gt;Powerful OCR and table extraction capabilities&lt;/li&gt; 
 &lt;li&gt;GPU acceleration support&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Docling Parser&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Optimized for Office documents and HTML files&lt;/li&gt; 
 &lt;li&gt;Better document structure preservation&lt;/li&gt; 
 &lt;li&gt;Native support for multiple Office formats&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;MinerU Configuration&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# MinerU 2.0 uses command-line parameters instead of config files
# Check available options:
mineru --help

# Common configurations:
mineru -p input.pdf -o output_dir -m auto    # Automatic parsing mode
mineru -p input.pdf -o output_dir -m ocr     # OCR-focused parsing
mineru -p input.pdf -o output_dir -b pipeline --device cuda  # GPU acceleration
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can also configure parsing through RAGAnything parameters:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# Basic parsing configuration with parser selection
await rag.process_document_complete(
    file_path="document.pdf",
    output_dir="./output/",
    parse_method="auto",          # or "ocr", "txt"
    parser="mineru"               # Optional: "mineru" or "docling"
)

# Advanced parsing configuration with special parameters
await rag.process_document_complete(
    file_path="document.pdf",
    output_dir="./output/",
    parse_method="auto",          # Parsing method: "auto", "ocr", "txt"
    parser="mineru",              # Parser selection: "mineru" or "docling"

    # MinerU special parameters - all supported kwargs:
    lang="ch",                   # Document language for OCR optimization (e.g., "ch", "en", "ja")
    device="cuda:0",             # Inference device: "cpu", "cuda", "cuda:0", "npu", "mps"
    start_page=0,                # Starting page number (0-based, for PDF)
    end_page=10,                 # Ending page number (0-based, for PDF)
    formula=True,                # Enable formula parsing
    table=True,                  # Enable table parsing
    backend="pipeline",          # Parsing backend: pipeline|vlm-transformers|vlm-sglang-engine|vlm-sglang-client.
    source="huggingface",        # Model source: "huggingface", "modelscope", "local"
    # vlm_url="http://127.0.0.1:3000" # Service address when using backend=vlm-sglang-client

    # Standard RAGAnything parameters
    display_stats=True,          # Display content statistics
    split_by_character=None,     # Optional character to split text by
    doc_id=None                  # Optional document ID
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: MinerU 2.0 no longer uses the &lt;code&gt;magic-pdf.json&lt;/code&gt; configuration file. All settings are now passed as command-line parameters or function arguments. RAG-Anything now supports multiple document parsers - you can choose between MinerU and Docling based on your needs.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Processing Requirements&lt;/h3&gt; 
&lt;p&gt;Different content types require specific optional dependencies:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Office Documents&lt;/strong&gt; (.doc, .docx, .ppt, .pptx, .xls, .xlsx): Install &lt;a href="https://www.libreoffice.org/download/download/"&gt;LibreOffice&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Extended Image Formats&lt;/strong&gt; (.bmp, .tiff, .gif, .webp): Install with &lt;code&gt;pip install raganything[image]&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Text Files&lt;/strong&gt; (.txt, .md): Install with &lt;code&gt;pip install raganything[text]&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;üìã Quick Install&lt;/strong&gt;: Use &lt;code&gt;pip install raganything[all]&lt;/code&gt; to enable all format support (Python dependencies only - LibreOffice still needs separate installation)&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üß™ Supported Content Types&lt;/h2&gt; 
&lt;h3&gt;Document Formats&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;PDFs&lt;/strong&gt; - Research papers, reports, presentations&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Office Documents&lt;/strong&gt; - DOC, DOCX, PPT, PPTX, XLS, XLSX&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Images&lt;/strong&gt; - JPG, PNG, BMP, TIFF, GIF, WebP&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Text Files&lt;/strong&gt; - TXT, MD&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Multimodal Elements&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Images&lt;/strong&gt; - Photographs, diagrams, charts, screenshots&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Tables&lt;/strong&gt; - Data tables, comparison charts, statistical summaries&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Equations&lt;/strong&gt; - Mathematical formulas in LaTeX format&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Generic Content&lt;/strong&gt; - Custom content types via extensible processors&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;em&gt;For installation of format-specific dependencies, see the &lt;a href="https://raw.githubusercontent.com/HKUDS/RAG-Anything/main/#-configuration"&gt;Configuration&lt;/a&gt; section.&lt;/em&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üìñ Citation&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Academic Reference&lt;/em&gt;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;div style="width: 60px; height: 60px; margin: 20px auto; position: relative;"&gt; 
  &lt;div style="width: 100%; height: 100%; border: 2px solid #00d9ff; border-radius: 50%; position: relative;"&gt; 
   &lt;div style="position: absolute; top: 50%; left: 50%; transform: translate(-50%, -50%); font-size: 24px; color: #00d9ff;"&gt;
    üìñ
   &lt;/div&gt; 
  &lt;/div&gt; 
  &lt;div style="position: absolute; bottom: -5px; left: 50%; transform: translateX(-50%); width: 20px; height: 20px; background: white; border-right: 2px solid #00d9ff; border-bottom: 2px solid #00d9ff; transform: rotate(45deg);"&gt;&lt;/div&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;p&gt;If you find RAG-Anything useful in your research, please cite our paper:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bibtex"&gt;@article{guo2024lightrag,
  title={LightRAG: Simple and Fast Retrieval-Augmented Generation},
  author={Zirui Guo and Lianghao Xia and Yanhua Yu and Tu Ao and Chao Huang},
  year={2024},
  eprint={2410.05779},
  archivePrefix={arXiv},
  primaryClass={cs.IR}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üîó Related Projects&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Ecosystem &amp;amp; Extensions&lt;/em&gt;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;table&gt; 
  &lt;tbody&gt;
   &lt;tr&gt; 
    &lt;td align="center"&gt; &lt;a href="https://github.com/HKUDS/LightRAG"&gt; 
      &lt;div style="width: 100px; height: 100px; background: linear-gradient(135deg, rgba(0, 217, 255, 0.1) 0%, rgba(0, 217, 255, 0.05) 100%); border-radius: 15px; border: 1px solid rgba(0, 217, 255, 0.2); display: flex; align-items: center; justify-content: center; margin-bottom: 10px;"&gt; 
       &lt;span style="font-size: 32px;"&gt;‚ö°&lt;/span&gt; 
      &lt;/div&gt; &lt;b&gt;LightRAG&lt;/b&gt;&lt;br /&gt; &lt;sub&gt;Simple and Fast RAG&lt;/sub&gt; &lt;/a&gt; &lt;/td&gt; 
    &lt;td align="center"&gt; &lt;a href="https://github.com/HKUDS/VideoRAG"&gt; 
      &lt;div style="width: 100px; height: 100px; background: linear-gradient(135deg, rgba(0, 217, 255, 0.1) 0%, rgba(0, 217, 255, 0.05) 100%); border-radius: 15px; border: 1px solid rgba(0, 217, 255, 0.2); display: flex; align-items: center; justify-content: center; margin-bottom: 10px;"&gt; 
       &lt;span style="font-size: 32px;"&gt;üé•&lt;/span&gt; 
      &lt;/div&gt; &lt;b&gt;VideoRAG&lt;/b&gt;&lt;br /&gt; &lt;sub&gt;Extreme Long-Context Video RAG&lt;/sub&gt; &lt;/a&gt; &lt;/td&gt; 
    &lt;td align="center"&gt; &lt;a href="https://github.com/HKUDS/MiniRAG"&gt; 
      &lt;div style="width: 100px; height: 100px; background: linear-gradient(135deg, rgba(0, 217, 255, 0.1) 0%, rgba(0, 217, 255, 0.05) 100%); border-radius: 15px; border: 1px solid rgba(0, 217, 255, 0.2); display: flex; align-items: center; justify-content: center; margin-bottom: 10px;"&gt; 
       &lt;span style="font-size: 32px;"&gt;‚ú®&lt;/span&gt; 
      &lt;/div&gt; &lt;b&gt;MiniRAG&lt;/b&gt;&lt;br /&gt; &lt;sub&gt;Extremely Simple RAG&lt;/sub&gt; &lt;/a&gt; &lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt;
 &lt;/table&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h2&gt;‚≠ê Star History&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Community Growth Trajectory&lt;/em&gt;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://star-history.com/#HKUDS/RAG-Anything&amp;amp;Date"&gt; 
  &lt;picture&gt; 
   &lt;source media="(prefers-color-scheme: dark)" srcset="https://api.star-history.com/svg?repos=HKUDS/RAG-Anything&amp;amp;type=Date&amp;amp;theme=dark" /&gt; 
   &lt;source media="(prefers-color-scheme: light)" srcset="https://api.star-history.com/svg?repos=HKUDS/RAG-Anything&amp;amp;type=Date" /&gt; 
   &lt;img alt="Star History Chart" src="https://api.star-history.com/svg?repos=HKUDS/RAG-Anything&amp;amp;type=Date" style="border-radius: 15px; box-shadow: 0 0 30px rgba(0, 217, 255, 0.3);" /&gt; 
  &lt;/picture&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ü§ù Contribution&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Join the Innovation&lt;/em&gt;&lt;/p&gt; 
&lt;div align="center"&gt;
  We thank all our contributors for their valuable contributions. 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://github.com/HKUDS/RAG-Anything/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=HKUDS/RAG-Anything" style="border-radius: 15px; box-shadow: 0 0 20px rgba(0, 217, 255, 0.3);" /&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;div align="center" style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); border-radius: 15px; padding: 30px; margin: 30px 0;"&gt; 
 &lt;div&gt; 
  &lt;img src="https://user-images.githubusercontent.com/74038190/212284100-561aa473-3905-4a80-b561-0d28506553ee.gif" width="500" /&gt; 
 &lt;/div&gt; 
 &lt;div style="margin-top: 20px;"&gt; 
  &lt;a href="https://github.com/HKUDS/RAG-Anything" style="text-decoration: none;"&gt; &lt;img src="https://img.shields.io/badge/‚≠ê%20Star%20us%20on%20GitHub-1a1a2e?style=for-the-badge&amp;amp;logo=github&amp;amp;logoColor=white" /&gt; &lt;/a&gt; 
  &lt;a href="https://github.com/HKUDS/RAG-Anything/issues" style="text-decoration: none;"&gt; &lt;img src="https://img.shields.io/badge/üêõ%20Report%20Issues-ff6b6b?style=for-the-badge&amp;amp;logo=github&amp;amp;logoColor=white" /&gt; &lt;/a&gt; 
  &lt;a href="https://github.com/HKUDS/RAG-Anything/discussions" style="text-decoration: none;"&gt; &lt;img src="https://img.shields.io/badge/üí¨%20Discussions-4ecdc4?style=for-the-badge&amp;amp;logo=github&amp;amp;logoColor=white" /&gt; &lt;/a&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;div style="width: 100%; max-width: 600px; margin: 20px auto; padding: 20px; background: linear-gradient(135deg, rgba(0, 217, 255, 0.1) 0%, rgba(0, 217, 255, 0.05) 100%); border-radius: 15px; border: 1px solid rgba(0, 217, 255, 0.2);"&gt; 
  &lt;div style="display: flex; justify-content: center; align-items: center; gap: 15px;"&gt; 
   &lt;span style="font-size: 24px;"&gt;‚≠ê&lt;/span&gt; 
   &lt;span style="color: #00d9ff; font-size: 18px;"&gt;Thank you for visiting RAG-Anything!&lt;/span&gt; 
   &lt;span style="font-size: 24px;"&gt;‚≠ê&lt;/span&gt; 
  &lt;/div&gt; 
  &lt;div style="margin-top: 10px; color: #00d9ff; font-size: 16px;"&gt;
   Building the Future of Multimodal AI
  &lt;/div&gt; 
 &lt;/div&gt; 
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>microsoft/AI-For-Beginners</title>
      <link>https://github.com/microsoft/AI-For-Beginners</link>
      <description>&lt;p&gt;12 Weeks, 24 Lessons, AI for All!&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href="https://github.com/microsoft/AI-For-Beginners/raw/main/LICENSE"&gt;&lt;img src="https://img.shields.io/github/license/microsoft/AI-For-Beginners.svg?sanitize=true" alt="GitHub license" /&gt;&lt;/a&gt; &lt;a href="https://GitHub.com/microsoft/AI-For-Beginners/graphs/contributors/"&gt;&lt;img src="https://img.shields.io/github/contributors/microsoft/AI-For-Beginners.svg?sanitize=true" alt="GitHub contributors" /&gt;&lt;/a&gt; &lt;a href="https://GitHub.com/microsoft/AI-For-Beginners/issues/"&gt;&lt;img src="https://img.shields.io/github/issues/microsoft/AI-For-Beginners.svg?sanitize=true" alt="GitHub issues" /&gt;&lt;/a&gt; &lt;a href="https://GitHub.com/microsoft/AI-For-Beginners/pulls/"&gt;&lt;img src="https://img.shields.io/github/issues-pr/microsoft/AI-For-Beginners.svg?sanitize=true" alt="GitHub pull-requests" /&gt;&lt;/a&gt; &lt;a href="http://makeapullrequest.com"&gt;&lt;img src="https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat-square" alt="PRs Welcome" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://GitHub.com/microsoft/AI-For-Beginners/watchers/"&gt;&lt;img src="https://img.shields.io/github/watchers/microsoft/AI-For-Beginners.svg?style=social&amp;amp;label=Watch" alt="GitHub watchers" /&gt;&lt;/a&gt; &lt;a href="https://GitHub.com/microsoft/AI-For-Beginners/network/"&gt;&lt;img src="https://img.shields.io/github/forks/microsoft/AI-For-Beginners.svg?style=social&amp;amp;label=Fork" alt="GitHub forks" /&gt;&lt;/a&gt; &lt;a href="https://GitHub.com/microsoft/AI-For-Beginners/stargazers/"&gt;&lt;img src="https://img.shields.io/github/stars/microsoft/AI-For-Beginners.svg?style=social&amp;amp;label=Star" alt="GitHub stars" /&gt;&lt;/a&gt; &lt;a href="https://mybinder.org/v2/gh/microsoft/ai-for-beginners/HEAD"&gt;&lt;img src="https://mybinder.org/badge_logo.svg?sanitize=true" alt="Binder" /&gt;&lt;/a&gt; &lt;a href="https://gitter.im/Microsoft/ai-for-beginners?utm_source=badge&amp;amp;utm_medium=badge&amp;amp;utm_campaign=pr-badge"&gt;&lt;img src="https://badges.gitter.im/Microsoft/ai-for-beginners.svg?sanitize=true" alt="Gitter" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://discord.gg/zxKYvhSnVp?WT.mc_id=academic-000002-leestott"&gt;&lt;img src="https://dcbadge.vercel.app/api/server/ByRwuEEgH4" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Artificial Intelligence for Beginners - A Curriculum&lt;/h1&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="center"&gt;&lt;img src="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/sketchnotes/ai-overview.png" alt="Sketchnote by @girlie_mac https://twitter.com/girlie_mac" /&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;AI For Beginners - &lt;em&gt;Sketchnote by &lt;a href="https://twitter.com/girlie_mac"&gt;@girlie_mac&lt;/a&gt;&lt;/em&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Explore the world of &lt;strong&gt;Artificial Intelligence&lt;/strong&gt; (AI) with our 12-week, 24-lesson curriculum! It includes practical lessons, quizzes, and labs. The curriculum is beginner-friendly and covers tools like TensorFlow and PyTorch, as well as ethics in AI&lt;/p&gt; 
&lt;h3&gt;üåê Multi-Language Support&lt;/h3&gt; 
&lt;h4&gt;Supported via GitHub Action (Automated &amp;amp; Always Up-to-Date)&lt;/h4&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/fr/README.md"&gt;French&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/es/README.md"&gt;Spanish&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/de/README.md"&gt;German&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/ru/README.md"&gt;Russian&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/ar/README.md"&gt;Arabic&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/fa/README.md"&gt;Persian (Farsi)&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/ur/README.md"&gt;Urdu&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/zh/README.md"&gt;Chinese (Simplified)&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/mo/README.md"&gt;Chinese (Traditional, Macau)&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/hk/README.md"&gt;Chinese (Traditional, Hong Kong)&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/tw/README.md"&gt;Chinese (Traditional, Taiwan)&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/ja/README.md"&gt;Japanese&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/ko/README.md"&gt;Korean&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/hi/README.md"&gt;Hindi&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/bn/README.md"&gt;Bengali&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/mr/README.md"&gt;Marathi&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/ne/README.md"&gt;Nepali&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/pa/README.md"&gt;Punjabi (Gurmukhi)&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/pt/README.md"&gt;Portuguese (Portugal)&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/br/README.md"&gt;Portuguese (Brazil)&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/it/README.md"&gt;Italian&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/pl/README.md"&gt;Polish&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/tr/README.md"&gt;Turkish&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/el/README.md"&gt;Greek&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/th/README.md"&gt;Thai&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/sv/README.md"&gt;Swedish&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/da/README.md"&gt;Danish&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/no/README.md"&gt;Norwegian&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/fi/README.md"&gt;Finnish&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/nl/README.md"&gt;Dutch&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/he/README.md"&gt;Hebrew&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/vi/README.md"&gt;Vietnamese&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/id/README.md"&gt;Indonesian&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/ms/README.md"&gt;Malay&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/tl/README.md"&gt;Tagalog (Filipino)&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/sw/README.md"&gt;Swahili&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/hu/README.md"&gt;Hungarian&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/cs/README.md"&gt;Czech&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/sk/README.md"&gt;Slovak&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/ro/README.md"&gt;Romanian&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/bg/README.md"&gt;Bulgarian&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/sr/README.md"&gt;Serbian (Cyrillic)&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/hr/README.md"&gt;Croatian&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/sl/README.md"&gt;Slovenian&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/uk/README.md"&gt;Ukrainian&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/my/README.md"&gt;Burmese (Myanmar)&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;If you wish to have additional translations languages supported are listed &lt;a href="https://github.com/Azure/co-op-translator/raw/main/getting_started/supported-languages.md"&gt;here&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;Join the Community&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://discord.gg/kzRShWzttr"&gt;&lt;img src="https://dcbadge.limes.pink/api/server/kzRShWzttr" alt="Azure AI Discord" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;What you will learn&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="http://soshnikov.com/courses/ai-for-beginners/mindmap.html"&gt;Mindmap of the Course&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;In this curriculum, you will learn:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Different approaches to Artificial Intelligence, including the "good old" symbolic approach with &lt;strong&gt;Knowledge Representation&lt;/strong&gt; and reasoning (&lt;a href="https://en.wikipedia.org/wiki/Symbolic_artificial_intelligence"&gt;GOFAI&lt;/a&gt;).&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Neural Networks&lt;/strong&gt; and &lt;strong&gt;Deep Learning&lt;/strong&gt;, which are at the core of modern AI. We will illustrate the concepts behind these important topics using code in two of the most popular frameworks - &lt;a href="http://Tensorflow.org"&gt;TensorFlow&lt;/a&gt; and &lt;a href="http://pytorch.org"&gt;PyTorch&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Neural Architectures&lt;/strong&gt; for working with images and text. We will cover recent models but may be a bit lacking in the state-of-the-art.&lt;/li&gt; 
 &lt;li&gt;Less popular AI approaches, such as &lt;strong&gt;Genetic Algorithms&lt;/strong&gt; and &lt;strong&gt;Multi-Agent Systems&lt;/strong&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;What we will not cover in this curriculum:&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;a href="https://learn.microsoft.com/en-us/collections/7w28iy2xrqzdj0?WT.mc_id=academic-77998-bethanycheum"&gt;Find all additional resources for this course in our Microsoft Learn collection&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;Business cases of using &lt;strong&gt;AI in Business&lt;/strong&gt;. Consider taking &lt;a href="https://docs.microsoft.com/learn/paths/introduction-ai-for-business-users/?WT.mc_id=academic-77998-bethanycheum"&gt;Introduction to AI for business users&lt;/a&gt; learning path on Microsoft Learn, or &lt;a href="https://www.microsoft.com/ai/ai-business-school/?WT.mc_id=academic-77998-bethanycheum"&gt;AI Business School&lt;/a&gt;, developed in cooperation with &lt;a href="https://www.insead.edu/"&gt;INSEAD&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Classic Machine Learning&lt;/strong&gt;, which is well described in our &lt;a href="http://github.com/Microsoft/ML-for-Beginners"&gt;Machine Learning for Beginners Curriculum&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Practical AI applications built using &lt;strong&gt;&lt;a href="https://azure.microsoft.com/services/cognitive-services/?WT.mc_id=academic-77998-bethanycheum"&gt;Cognitive Services&lt;/a&gt;&lt;/strong&gt;. For this, we recommend that you start with modules Microsoft Learn for &lt;a href="https://docs.microsoft.com/learn/paths/create-computer-vision-solutions-azure-cognitive-services/?WT.mc_id=academic-77998-bethanycheum"&gt;vision&lt;/a&gt;, &lt;a href="https://docs.microsoft.com/learn/paths/explore-natural-language-processing/?WT.mc_id=academic-77998-bethanycheum"&gt;natural language processing&lt;/a&gt;, &lt;strong&gt;&lt;a href="https://learn.microsoft.com/en-us/training/paths/develop-ai-solutions-azure-openai/?WT.mc_id=academic-77998-bethanycheum"&gt;Generative AI with Azure OpenAI Service&lt;/a&gt;&lt;/strong&gt; and others.&lt;/li&gt; 
 &lt;li&gt;Specific ML &lt;strong&gt;Cloud Frameworks&lt;/strong&gt;, such as &lt;a href="https://azure.microsoft.com/services/machine-learning/?WT.mc_id=academic-77998-bethanycheum"&gt;Azure Machine Learning&lt;/a&gt;, &lt;a href="https://learn.microsoft.com/en-us/training/paths/get-started-fabric/?WT.mc_id=academic-77998-bethanycheum"&gt;Microsoft Fabric&lt;/a&gt;, or &lt;a href="https://docs.microsoft.com/learn/paths/data-engineer-azure-databricks?WT.mc_id=academic-77998-bethanycheum"&gt;Azure Databricks&lt;/a&gt;. Consider using &lt;a href="https://docs.microsoft.com/learn/paths/build-ai-solutions-with-azure-ml-service/?WT.mc_id=academic-77998-bethanycheum"&gt;Build and operate machine learning solutions with Azure Machine Learning&lt;/a&gt; and &lt;a href="https://docs.microsoft.com/learn/paths/build-operate-machine-learning-solutions-azure-databricks/?WT.mc_id=academic-77998-bethanycheum"&gt;Build and Operate Machine Learning Solutions with Azure Databricks&lt;/a&gt; learning paths.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Conversational AI&lt;/strong&gt; and &lt;strong&gt;Chat Bots&lt;/strong&gt;. There is a separate &lt;a href="https://docs.microsoft.com/learn/paths/create-conversational-ai-solutions/?WT.mc_id=academic-77998-bethanycheum"&gt;Create conversational AI solutions&lt;/a&gt; learning path, and you can also refer to &lt;a href="https://soshnikov.com/azure/hello-bot-conversational-ai-on-microsoft-platform/"&gt;this blog post&lt;/a&gt; for more detail.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Deep Mathematics&lt;/strong&gt; behind deep learning. For this, we would recommend &lt;a href="https://www.amazon.com/Deep-Learning-Adaptive-Computation-Machine/dp/0262035618"&gt;Deep Learning&lt;/a&gt; by Ian Goodfellow, Yoshua Bengio and Aaron Courville, which is also available online at &lt;a href="https://www.deeplearningbook.org/"&gt;https://www.deeplearningbook.org/&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For a gentle introduction to &lt;em&gt;AI in the Cloud&lt;/em&gt; topics you may consider taking the &lt;a href="https://docs.microsoft.com/learn/paths/get-started-with-artificial-intelligence-on-azure/?WT.mc_id=academic-77998-bethanycheum"&gt;Get started with artificial intelligence on Azure&lt;/a&gt; Learning Path.&lt;/p&gt; 
&lt;h1&gt;Content&lt;/h1&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="center"&gt;&lt;/th&gt; 
   &lt;th align="center"&gt;Lesson Link&lt;/th&gt; 
   &lt;th align="center"&gt;PyTorch/Keras/TensorFlow&lt;/th&gt; 
   &lt;th&gt;Lab&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;0&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/0-course-setup/setup.md"&gt;Course Setup&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/0-course-setup/how-to-run.md"&gt;Setup Your Development Environment&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;I&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/1-Intro/README.md"&gt;&lt;strong&gt;Introduction to AI&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;01&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/1-Intro/README.md"&gt;Introduction and History of AI&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;-&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;II&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;Symbolic AI&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;02&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/2-Symbolic/README.md"&gt;Knowledge Representation and Expert Systems&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/2-Symbolic/Animals.ipynb"&gt;Expert Systems&lt;/a&gt; / &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/2-Symbolic/FamilyOntology.ipynb"&gt;Ontology&lt;/a&gt; /&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/2-Symbolic/MSConceptGraph.ipynb"&gt;Concept Graph&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;III&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/3-NeuralNetworks/README.md"&gt;&lt;strong&gt;Introduction to Neural Networks&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;03&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/3-NeuralNetworks/03-Perceptron/README.md"&gt;Perceptron&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/3-NeuralNetworks/03-Perceptron/Perceptron.ipynb"&gt;Notebook&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/3-NeuralNetworks/03-Perceptron/lab/README.md"&gt;Lab&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;04&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/3-NeuralNetworks/04-OwnFramework/README.md"&gt;Multi-Layered Perceptron and Creating our own Framework&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/3-NeuralNetworks/04-OwnFramework/OwnFramework.ipynb"&gt;Notebook&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/3-NeuralNetworks/04-OwnFramework/lab/README.md"&gt;Lab&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;05&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/3-NeuralNetworks/05-Frameworks/README.md"&gt;Intro to Frameworks (PyTorch/TensorFlow) and Overfitting&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/3-NeuralNetworks/05-Frameworks/IntroPyTorch.ipynb"&gt;PyTorch&lt;/a&gt; / &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/3-NeuralNetworks/05-Frameworks/IntroKeras.ipynb"&gt;Keras&lt;/a&gt; / &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/3-NeuralNetworks/05-Frameworks/IntroKerasTF.ipynb"&gt;TensorFlow&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/3-NeuralNetworks/05-Frameworks/lab/README.md"&gt;Lab&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;IV&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/README.md"&gt;&lt;strong&gt;Computer Vision&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://docs.microsoft.com/learn/modules/intro-computer-vision-pytorch/?WT.mc_id=academic-77998-cacaste"&gt;PyTorch&lt;/a&gt; / &lt;a href="https://docs.microsoft.com/learn/modules/intro-computer-vision-TensorFlow/?WT.mc_id=academic-77998-cacaste"&gt;TensorFlow&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://learn.microsoft.com/en-us/collections/7w28iy2xrqzdj0?WT.mc_id=academic-77998-bethanycheum"&gt;Explore Computer Vision on Microsoft Azure&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;06&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/06-IntroCV/README.md"&gt;Intro to Computer Vision. OpenCV&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/06-IntroCV/OpenCV.ipynb"&gt;Notebook&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/06-IntroCV/lab/README.md"&gt;Lab&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;07&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/07-ConvNets/README.md"&gt;Convolutional Neural Networks&lt;/a&gt; &amp;amp; &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/07-ConvNets/CNN_Architectures.md"&gt;CNN Architectures&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/07-ConvNets/ConvNetsPyTorch.ipynb"&gt;PyTorch&lt;/a&gt; /&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/07-ConvNets/ConvNetsTF.ipynb"&gt;TensorFlow&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/07-ConvNets/lab/README.md"&gt;Lab&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;08&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/08-TransferLearning/README.md"&gt;Pre-trained Networks and Transfer Learning&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/08-TransferLearning/TrainingTricks.md"&gt;Training Tricks&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/08-TransferLearning/TransferLearningPyTorch.ipynb"&gt;PyTorch&lt;/a&gt; / &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/3-NeuralNetworks/05-Frameworks/IntroKerasTF.ipynb"&gt;TensorFlow&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/08-TransferLearning/lab/README.md"&gt;Lab&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;09&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/09-Autoencoders/README.md"&gt;Autoencoders and VAEs&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/09-Autoencoders/AutoEncodersPyTorch.ipynb"&gt;PyTorch&lt;/a&gt; / &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/09-Autoencoders/AutoencodersTF.ipynb"&gt;TensorFlow&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;10&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/10-GANs/README.md"&gt;Generative Adversarial Networks &amp;amp; Artistic Style Transfer&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/10-GANs/GANPyTorch.ipynb"&gt;PyTorch&lt;/a&gt; / &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/10-GANs/GANTF.ipynb"&gt;TensorFlow&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;11&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/11-ObjectDetection/README.md"&gt;Object Detection&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/11-ObjectDetection/ObjectDetection.ipynb"&gt;TensorFlow&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/11-ObjectDetection/lab/README.md"&gt;Lab&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;12&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/12-Segmentation/README.md"&gt;Semantic Segmentation. U-Net&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/12-Segmentation/SemanticSegmentationPytorch.ipynb"&gt;PyTorch&lt;/a&gt; / &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/12-Segmentation/SemanticSegmentationTF.ipynb"&gt;TensorFlow&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;V&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/5-NLP/README.md"&gt;&lt;strong&gt;Natural Language Processing&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://docs.microsoft.com/learn/modules/intro-natural-language-processing-pytorch/?WT.mc_id=academic-77998-cacaste"&gt;PyTorch&lt;/a&gt; /&lt;a href="https://docs.microsoft.com/learn/modules/intro-natural-language-processing-TensorFlow/?WT.mc_id=academic-77998-cacaste"&gt;TensorFlow&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://learn.microsoft.com/en-us/collections/7w28iy2xrqzdj0?WT.mc_id=academic-77998-bethanycheum"&gt;Explore Natural Language Processing on Microsoft Azure&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;13&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/5-NLP/13-TextRep/README.md"&gt;Text Representation. Bow/TF-IDF&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/microsoft/AI-For-Beginners/raw/main/lessons/5-NLP/13-TextRep/TextRepresentationPyTorch.ipynb"&gt;PyTorch&lt;/a&gt; / &lt;a href="https://github.com/microsoft/AI-For-Beginners/raw/main/lessons/5-NLP/13-TextRep/TextRepresentationTF.ipynb"&gt;TensorFlow&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;14&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/5-NLP/14-Embeddings/README.md"&gt;Semantic word embeddings. Word2Vec and GloVe&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/microsoft/AI-For-Beginners/raw/main/lessons/5-NLP/14-Embeddings/EmbeddingsPyTorch.ipynb"&gt;PyTorch&lt;/a&gt; / &lt;a href="https://github.com/microsoft/AI-For-Beginners/raw/main/lessons/5-NLP/14-Embeddings/EmbeddingsTF.ipynb"&gt;TensorFlow&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;15&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/5-NLP/15-LanguageModeling/README.md"&gt;Language Modeling. Training your own embeddings&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/microsoft/AI-For-Beginners/raw/main/lessons/5-NLP/15-LanguageModeling/CBoW-PyTorch.ipynb"&gt;PyTorch&lt;/a&gt; / &lt;a href="https://github.com/microsoft/AI-For-Beginners/raw/main/lessons/5-NLP/15-LanguageModeling/CBoW-TF.ipynb"&gt;TensorFlow&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/5-NLP/15-LanguageModeling/lab/README.md"&gt;Lab&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;16&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/5-NLP/16-RNN/README.md"&gt;Recurrent Neural Networks&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/microsoft/AI-For-Beginners/raw/main/lessons/5-NLP/16-RNN/RNNPyTorch.ipynb"&gt;PyTorch&lt;/a&gt; / &lt;a href="https://github.com/microsoft/AI-For-Beginners/raw/main/lessons/5-NLP/16-RNN/RNNTF.ipynb"&gt;TensorFlow&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;17&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/5-NLP/17-GenerativeNetworks/README.md"&gt;Generative Recurrent Networks&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/microsoft/AI-For-Beginners/raw/main/lessons/5-NLP/17-GenerativeNetworks/GenerativePyTorch.ipynb"&gt;PyTorch&lt;/a&gt; / &lt;a href="https://github.com/microsoft/AI-For-Beginners/raw/main/lessons/5-NLP/17-GenerativeNetworks/GenerativeTF.ipynb"&gt;TensorFlow&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/5-NLP/17-GenerativeNetworks/lab/README.md"&gt;Lab&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;18&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/5-NLP/18-Transformers/README.md"&gt;Transformers. BERT.&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/microsoft/AI-For-Beginners/raw/main/lessons/5-NLP/18-Transformers/TransformersPyTorch.ipynb"&gt;PyTorch&lt;/a&gt; /&lt;a href="https://github.com/microsoft/AI-For-Beginners/raw/main/lessons/5-NLP/18-Transformers/TransformersTF.ipynb"&gt;TensorFlow&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;19&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/5-NLP/19-NER/README.md"&gt;Named Entity Recognition&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://microsoft.github.io/AI-For-Beginners/lessons/5-NLP/19-NER/NER-TF.ipynb"&gt;TensorFlow&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/5-NLP/19-NER/lab/README.md"&gt;Lab&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;20&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/5-NLP/20-LangModels/README.md"&gt;Large Language Models, Prompt Programming and Few-Shot Tasks&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://microsoft.github.io/AI-For-Beginners/lessons/5-NLP/20-LangModels/GPT-PyTorch.ipynb"&gt;PyTorch&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;VI&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;Other AI Techniques&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;21&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/6-Other/21-GeneticAlgorithms/README.md"&gt;Genetic Algorithms&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/6-Other/21-GeneticAlgorithms/Genetic.ipynb"&gt;Notebook&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;22&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/6-Other/22-DeepRL/README.md"&gt;Deep Reinforcement Learning&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/6-Other/22-DeepRL/CartPole-RL-PyTorch.ipynb"&gt;PyTorch&lt;/a&gt; /&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/6-Other/22-DeepRL/CartPole-RL-TF.ipynb"&gt;TensorFlow&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/6-Other/22-DeepRL/lab/README.md"&gt;Lab&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;23&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/6-Other/23-MultiagentSystems/README.md"&gt;Multi-Agent Systems&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;VII&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;AI Ethics&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;24&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/7-Ethics/README.md"&gt;AI Ethics and Responsible AI&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://docs.microsoft.com/learn/paths/responsible-ai-business-principles/?WT.mc_id=academic-77998-cacaste"&gt;Microsoft Learn: Responsible AI Principles&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;IX&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;Extras&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;25&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/X-Extras/X1-MultiModal/README.md"&gt;Multi-Modal Networks, CLIP and VQGAN&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/X-Extras/X1-MultiModal/Clip.ipynb"&gt;Notebook&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Each lesson contains&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Pre-reading material&lt;/li&gt; 
 &lt;li&gt;Executable Jupyter Notebooks, which are often specific to the framework (&lt;strong&gt;PyTorch&lt;/strong&gt; or &lt;strong&gt;TensorFlow&lt;/strong&gt;). The executable notebook also contains a lot of theoretical material, so to understand the topic you need to go through at least one version of the notebook (either PyTorch or TensorFlow).&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Labs&lt;/strong&gt; available for some topics, which give you an opportunity to try applying the material you have learned to a specific problem.&lt;/li&gt; 
 &lt;li&gt;Some sections contain links to &lt;a href="https://learn.microsoft.com/en-us/collections/7w28iy2xrqzdj0?WT.mc_id=academic-77998-bethanycheum"&gt;&lt;strong&gt;MS Learn&lt;/strong&gt;&lt;/a&gt; modules that cover related topics.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;We have created a &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/0-course-setup/setup.md"&gt;setup lesson&lt;/a&gt; to help you with setting up your development environment. - For Educators, we have created a &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/0-course-setup/for-teachers.md"&gt;curricula setup lesson&lt;/a&gt; for you too!&lt;/li&gt; 
 &lt;li&gt;How to &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/0-course-setup/how-to-run.md"&gt;Run the code in a VSCode or a Codepace&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Follow these steps:&lt;/p&gt; 
&lt;p&gt;Fork the Repository: Click on the "Fork" button at the top-right corner of this page.&lt;/p&gt; 
&lt;p&gt;Clone the Repository: &lt;code&gt;git clone https://github.com/microsoft/AI-For-Beginners.git&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;Don't forget to star (üåü) this repo to find it easier later.&lt;/p&gt; 
&lt;h2&gt;Meet other Learners&lt;/h2&gt; 
&lt;p&gt;Join our &lt;a href="https://aka.ms/genai-discord?WT.mc_id=academic-105485-bethanycheum"&gt;official AI Discord server&lt;/a&gt; to meet and network with other learners taking this course and get support.&lt;/p&gt; 
&lt;p&gt;If you have product feedback or questions whilst building visit our &lt;a href="https://aka.ms/foundry/forum"&gt;Azure AI Foundry Developer Forum&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Quizzes&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;A note about quizzes&lt;/strong&gt;: All quizzes are contained in the Quiz-app folder in etc\quiz-app, or &lt;a href="https://ff-quizzes.netlify.app/"&gt;Online Here&lt;/a&gt; They are linked from within the lessons the quiz app can be run locally or deployed to Azure; follow the instruction in the &lt;code&gt;quiz-app&lt;/code&gt; folder. They are gradually being localized.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Help Wanted&lt;/h2&gt; 
&lt;p&gt;Do you have suggestions or found spelling or code errors? Raise an issue or create a pull request.&lt;/p&gt; 
&lt;h2&gt;Special Thanks&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;‚úçÔ∏è Primary Author:&lt;/strong&gt; &lt;a href="http://soshnikov.com"&gt;Dmitry Soshnikov&lt;/a&gt;, PhD&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üî• Editor:&lt;/strong&gt; &lt;a href="https://twitter.com/jenlooper"&gt;Jen Looper&lt;/a&gt;, PhD&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üé® Sketchnote illustrator:&lt;/strong&gt; &lt;a href="https://twitter.com/girlie_mac"&gt;Tomomi Imura&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;‚úÖ Quiz Creator:&lt;/strong&gt; &lt;a href="https://github.com/CinnamonXI"&gt;Lateefah Bello&lt;/a&gt;, &lt;a href="https://studentambassadors.microsoft.com/"&gt;MLSA&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üôè Core Contributors:&lt;/strong&gt; &lt;a href="https://github.com/Pe4enIks"&gt;Evgenii Pishchik&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Other Curricula&lt;/h2&gt; 
&lt;p&gt;Our team produces other curricula! Check out:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://aka.ms/genai-beginners"&gt;Generative AI for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/microsoft/Generative-AI-for-beginners-dotnet"&gt;Generative AI for Beginners .NET&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/microsoft/generative-ai-with-javascript"&gt;Generative AI with JavaScript&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/microsoft/Generative-AI-for-beginners-java"&gt;Generative AI with Java&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://aka.ms/ai-beginners"&gt;AI for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://aka.ms/datascience-beginners"&gt;Data Science for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://aka.ms/ml-beginners"&gt;ML for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/microsoft/Security-101"&gt;Cybersecurity for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://aka.ms/webdev-beginners"&gt;Web Dev for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://aka.ms/iot-beginners"&gt;IoT for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/microsoft/xr-development-for-beginners"&gt;XR Development for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/microsoft/Mastering-GitHub-Copilot-for-Paired-Programming"&gt;Mastering GitHub Copilot for Agentic use&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/microsoft/mastering-github-copilot-for-dotnet-csharp-developers"&gt;Mastering GitHub Copilot for C#/.NET Developers&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/microsoft/CopilotAdventures"&gt;Choose Your Own Copilot Adventure&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>OpenZeppelin/openzeppelin-contracts</title>
      <link>https://github.com/OpenZeppelin/openzeppelin-contracts</link>
      <description>&lt;p&gt;OpenZeppelin Contracts is a library for secure smart contract development.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;&lt;img src="https://raw.githubusercontent.com/OpenZeppelin/openzeppelin-contracts/master/logo.svg?sanitize=true" alt="OpenZeppelin" height="40px" /&gt;&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://github.com/OpenZeppelin/openzeppelin-contracts/releases/latest"&gt;&lt;img src="https://img.shields.io/github/v/tag/OpenZeppelin/openzeppelin-contracts.svg?filter=v*&amp;amp;sort=semver&amp;amp;label=github" alt="Github Release" /&gt;&lt;/a&gt; &lt;a href="https://www.npmjs.org/package/@openzeppelin/contracts"&gt;&lt;img src="https://img.shields.io/npm/v/@openzeppelin/contracts.svg?sanitize=true" alt="NPM Package" /&gt;&lt;/a&gt; &lt;a href="https://codecov.io/gh/OpenZeppelin/openzeppelin-contracts"&gt;&lt;img src="https://codecov.io/gh/OpenZeppelin/openzeppelin-contracts/graph/badge.svg?sanitize=true" alt="Coverage Status" /&gt;&lt;/a&gt; &lt;a href="https://www.gitpoap.io/gh/OpenZeppelin/openzeppelin-contracts"&gt;&lt;img src="https://public-api.gitpoap.io/v1/repo/OpenZeppelin/openzeppelin-contracts/badge" alt="GitPOAPs" /&gt;&lt;/a&gt; &lt;a href="https://docs.openzeppelin.com/contracts"&gt;&lt;img src="https://img.shields.io/badge/docs-%F0%9F%93%84-yellow" alt="Docs" /&gt;&lt;/a&gt; &lt;a href="https://forum.openzeppelin.com/"&gt;&lt;img src="https://img.shields.io/badge/forum-%F0%9F%92%AC-yellow" alt="Forum" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;A library for secure smart contract development.&lt;/strong&gt; Build on a solid foundation of community-vetted code.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Implementations of standards like &lt;a href="https://docs.openzeppelin.com/contracts/erc20"&gt;ERC20&lt;/a&gt; and &lt;a href="https://docs.openzeppelin.com/contracts/erc721"&gt;ERC721&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Flexible &lt;a href="https://docs.openzeppelin.com/contracts/access-control"&gt;role-based permissioning&lt;/a&gt; scheme.&lt;/li&gt; 
 &lt;li&gt;Reusable &lt;a href="https://docs.openzeppelin.com/contracts/utilities"&gt;Solidity components&lt;/a&gt; to build custom contracts and complex decentralized systems.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span&gt;üßô&lt;/span&gt; &lt;strong&gt;Not sure how to get started?&lt;/strong&gt; Check out &lt;a href="https://wizard.openzeppelin.com/"&gt;Contracts Wizard&lt;/a&gt; ‚Äî an interactive smart contract generator.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] OpenZeppelin Contracts uses semantic versioning to communicate backwards compatibility of its API and storage layout. For upgradeable contracts, the storage layout of different major versions should be assumed incompatible, for example, it is unsafe to upgrade from 4.9.3 to 5.0.0. Learn more at &lt;a href="https://docs.openzeppelin.com/contracts/backwards-compatibility"&gt;Backwards Compatibility&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Overview&lt;/h2&gt; 
&lt;h3&gt;Installation&lt;/h3&gt; 
&lt;h4&gt;Hardhat (npm)&lt;/h4&gt; 
&lt;pre&gt;&lt;code&gt;$ npm install @openzeppelin/contracts
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Foundry (git)&lt;/h4&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!WARNING] When installing via git, it is a common error to use the &lt;code&gt;master&lt;/code&gt; branch. This is a development branch that should be avoided in favor of tagged releases. The release process involves security measures that the &lt;code&gt;master&lt;/code&gt; branch does not guarantee.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!WARNING] Foundry installs the latest version initially, but subsequent &lt;code&gt;forge update&lt;/code&gt; commands will use the &lt;code&gt;master&lt;/code&gt; branch.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;pre&gt;&lt;code&gt;$ forge install OpenZeppelin/openzeppelin-contracts
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Add &lt;code&gt;@openzeppelin/contracts/=lib/openzeppelin-contracts/contracts/&lt;/code&gt; in &lt;code&gt;remappings.txt&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;Usage&lt;/h3&gt; 
&lt;p&gt;Once installed, you can use the contracts in the library by importing them:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-solidity"&gt;pragma solidity ^0.8.20;

import {ERC721} from "@openzeppelin/contracts/token/ERC721/ERC721.sol";

contract MyCollectible is ERC721 {
    constructor() ERC721("MyCollectible", "MCO") {
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;em&gt;If you're new to smart contract development, head to &lt;a href="https://docs.openzeppelin.com/learn/developing-smart-contracts"&gt;Developing Smart Contracts&lt;/a&gt; to learn about creating a new project and compiling your contracts.&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;To keep your system secure, you should &lt;strong&gt;always&lt;/strong&gt; use the installed code as-is, and neither copy-paste it from online sources nor modify it yourself. The library is designed so that only the contracts and functions you use are deployed, so you don't need to worry about it needlessly increasing gas costs.&lt;/p&gt; 
&lt;h2&gt;Learn More&lt;/h2&gt; 
&lt;p&gt;The guides in the &lt;a href="https://docs.openzeppelin.com/contracts"&gt;documentation site&lt;/a&gt; will teach about different concepts, and how to use the related contracts that OpenZeppelin Contracts provides:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.openzeppelin.com/contracts/access-control"&gt;Access Control&lt;/a&gt;: decide who can perform each of the actions on your system.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.openzeppelin.com/contracts/tokens"&gt;Tokens&lt;/a&gt;: create tradeable assets or collectibles for popular ERC standards like ERC-20, ERC-721, ERC-1155, and ERC-6909.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.openzeppelin.com/contracts/utilities"&gt;Utilities&lt;/a&gt;: generic useful tools including non-overflowing math, signature verification, and trustless paying systems.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The &lt;a href="https://docs.openzeppelin.com/contracts/api/token/ERC20"&gt;full API&lt;/a&gt; is also thoroughly documented, and serves as a great reference when developing your smart contract application. You can also ask for help or follow Contracts' development in the &lt;a href="https://forum.openzeppelin.com"&gt;community forum&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Finally, you may want to take a look at the &lt;a href="https://blog.openzeppelin.com/"&gt;guides on our blog&lt;/a&gt;, which cover several common use cases and good practices. The following articles provide great background reading, though please note that some of the referenced tools have changed, as the tooling in the ecosystem continues to rapidly evolve.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://blog.openzeppelin.com/the-hitchhikers-guide-to-smart-contracts-in-ethereum-848f08001f05"&gt;The Hitchhiker‚Äôs Guide to Smart Contracts in Ethereum&lt;/a&gt; will help you get an overview of the various tools available for smart contract development, and help you set up your environment.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://blog.openzeppelin.com/a-gentle-introduction-to-ethereum-programming-part-1-783cc7796094"&gt;A Gentle Introduction to Ethereum Programming, Part 1&lt;/a&gt; provides very useful information on an introductory level, including many basic concepts from the Ethereum platform.&lt;/li&gt; 
 &lt;li&gt;For a more in-depth dive, you may read the guide &lt;a href="https://blog.openzeppelin.com/designing-the-architecture-for-your-ethereum-application-9cec086f8317"&gt;Designing the Architecture for Your Ethereum Application&lt;/a&gt;, which discusses how to better structure your application and its relationship to the real world.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Security&lt;/h2&gt; 
&lt;p&gt;This project is maintained by &lt;a href="https://openzeppelin.com"&gt;OpenZeppelin&lt;/a&gt; with the goal of providing a secure and reliable library of smart contract components for the ecosystem. We address security through risk management in various areas such as engineering and open source best practices, scoping and API design, multi-layered review processes, and incident response preparedness.&lt;/p&gt; 
&lt;p&gt;The &lt;a href="https://contracts.openzeppelin.com/security"&gt;OpenZeppelin Contracts Security Center&lt;/a&gt; contains more details about the secure development process.&lt;/p&gt; 
&lt;p&gt;The security policy is detailed in &lt;a href="https://raw.githubusercontent.com/OpenZeppelin/openzeppelin-contracts/master/SECURITY.md"&gt;&lt;code&gt;SECURITY.md&lt;/code&gt;&lt;/a&gt; as well, and specifies how you can report security vulnerabilities, which versions will receive security patches, and how to stay informed about them. We run a &lt;a href="https://immunefi.com/bounty/openzeppelin"&gt;bug bounty program on Immunefi&lt;/a&gt; to reward the responsible disclosure of vulnerabilities.&lt;/p&gt; 
&lt;p&gt;The engineering guidelines we follow to promote project quality can be found in &lt;a href="https://raw.githubusercontent.com/OpenZeppelin/openzeppelin-contracts/master/GUIDELINES.md"&gt;&lt;code&gt;GUIDELINES.md&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Past audits can be found in &lt;a href="https://raw.githubusercontent.com/OpenZeppelin/openzeppelin-contracts/master/audits"&gt;&lt;code&gt;audits/&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Smart contracts are a nascent technology and carry a high level of technical risk and uncertainty. Although OpenZeppelin is well known for its security audits, using OpenZeppelin Contracts is not a substitute for a security audit.&lt;/p&gt; 
&lt;p&gt;OpenZeppelin Contracts is made available under the MIT License, which disclaims all warranties in relation to the project and which limits the liability of those that contribute and maintain the project, including OpenZeppelin. As set out further in the Terms, you acknowledge that you are solely responsible for any use of OpenZeppelin Contracts and you assume all risks associated with any such use.&lt;/p&gt; 
&lt;h2&gt;Contribute&lt;/h2&gt; 
&lt;p&gt;OpenZeppelin Contracts exists thanks to its contributors. There are many ways you can participate and help build high quality software. Check out the &lt;a href="https://raw.githubusercontent.com/OpenZeppelin/openzeppelin-contracts/master/CONTRIBUTING.md"&gt;contribution guide&lt;/a&gt;!&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;OpenZeppelin Contracts is released under the &lt;a href="https://raw.githubusercontent.com/OpenZeppelin/openzeppelin-contracts/master/LICENSE"&gt;MIT License&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Legal&lt;/h2&gt; 
&lt;p&gt;Your use of this Project is governed by the terms found at &lt;a href="http://www.openzeppelin.com/tos"&gt;www.openzeppelin.com/tos&lt;/a&gt; (the "Terms").&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>WECENG/ticket-purchase</title>
      <link>https://github.com/WECENG/ticket-purchase</link>
      <description>&lt;p&gt;Â§ßÈ∫¶Ëá™Âä®Êä¢Á•®ÔºåÊîØÊåÅ‰∫∫Âëò„ÄÅÂüéÂ∏Ç„ÄÅÊó•ÊúüÂú∫Ê¨°„ÄÅ‰ª∑Ê†ºÈÄâÊã©&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Â§ßÈ∫¶Êä¢Á•®ËÑöÊú¨ V1.0&lt;/h1&gt; 
&lt;h3&gt;ÁâπÂæÅ&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Ëá™Âä®Êó†Âª∂Êó∂Êä¢Á•®&lt;/li&gt; 
 &lt;li&gt;ÊîØÊåÅ‰∫∫Âëò„ÄÅÂüéÂ∏Ç„ÄÅÊó•ÊúüÂú∫Ê¨°„ÄÅ‰ª∑Ê†ºÈÄâÊã©&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ÂäüËÉΩ‰ªãÁªç&lt;/h2&gt; 
&lt;p&gt;ÈÄöËøáseleniumÊâìÂºÄÈ°µÈù¢ËøõË°åÁôªÂΩïÔºåÊ®°ÊãüÁî®Êà∑Ë¥≠Á•®ÊµÅÁ®ãËá™Âä®Ë¥≠Á•®&lt;/p&gt; 
&lt;p&gt;ÂÖ∂ÊµÅÁ®ãÂõæÂ¶Ç‰∏ã:&lt;/p&gt; 
&lt;img src="img/Â§ßÈ∫¶Êä¢Á•®ÊµÅÁ®ã.png" width="50%" height="50%" /&gt; 
&lt;h2&gt;ÂáÜÂ§áÂ∑•‰Ωú&lt;/h2&gt; 
&lt;h3&gt;1. ÈÖçÁΩÆÁéØÂ¢É&lt;/h3&gt; 
&lt;h4&gt;1.1ÂÆâË£Öpython3ÁéØÂ¢É&lt;/h4&gt; 
&lt;p&gt;&lt;strong&gt;Windows&lt;/strong&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;ËÆøÈóÆPythonÂÆòÊñπÁΩëÁ´ôÔºö&lt;a href="https://www.python.org/downloads/windows/"&gt;https://www.python.org/downloads/windows/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;‰∏ãËΩΩÊúÄÊñ∞ÁöÑPython 3.9+ÁâàÊú¨ÁöÑÂÆâË£ÖÁ®ãÂ∫è„ÄÇ&lt;/li&gt; 
 &lt;li&gt;ËøêË°åÂÆâË£ÖÁ®ãÂ∫è„ÄÇ&lt;/li&gt; 
 &lt;li&gt;Âú®ÂÆâË£ÖÁ®ãÂ∫è‰∏≠ÔºåÁ°Æ‰øùÂãæÈÄâ "Add Python X.X to PATH" ÈÄâÈ°πÔºåËøôÂ∞ÜËá™Âä®Â∞ÜPythonÊ∑ªÂä†Âà∞Á≥ªÁªüÁéØÂ¢ÉÂèòÈáè‰∏≠ÔºåÊñπ‰æøÂú®ÂëΩ‰ª§Ë°å‰∏≠‰ΩøÁî®Python„ÄÇ&lt;/li&gt; 
 &lt;li&gt;ÂÆåÊàêÂÆâË£ÖÂêéÔºå‰Ω†ÂèØ‰ª•Âú®ÂëΩ‰ª§ÊèêÁ§∫Á¨¶ÊàñPowerShell‰∏≠ËæìÂÖ• &lt;code&gt;python3&lt;/code&gt; Êù•ÂêØÂä®PythonËß£ÈáäÂô®„ÄÇ&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;macOS&lt;/strong&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;‰Ω†ÂèØ‰ª•‰ΩøÁî®HomebrewÊù•ÂÆâË£ÖPython 3„ÄÇ&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;ÂÆâË£ÖHomebrewÔºàÂ¶ÇÊûúÊú™ÂÆâË£ÖÔºâÔºöÊâìÂºÄÁªàÁ´ØÂπ∂ËøêË°å‰ª•‰∏ãÂëΩ‰ª§Ôºö&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;/bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;ÂÆâË£ÖPython 3ÔºöËøêË°å‰ª•‰∏ãÂëΩ‰ª§Êù•ÂÆâË£ÖPython 3Ôºö&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;brew install python@3
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;1.2 ÂÆâË£ÖÊâÄÈúÄË¶ÅÁöÑÁéØÂ¢É&lt;/h4&gt; 
&lt;p&gt;Âú®ÂëΩ‰ª§Á™óÂè£ËæìÂÖ•Â¶Ç‰∏ãÊåá‰ª§&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;pip3 install selenium
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;1.3 ‰∏ãËΩΩgoogle chromeÊµèËßàÂô®&lt;/h4&gt; 
&lt;p&gt;‰∏ãËΩΩÂú∞ÂùÄ: &lt;a href="https://www.google.cn/intl/zh-CN/chrome/?brand=YTUH&amp;amp;gclid=Cj0KCQjwj5mpBhDJARIsAOVjBdoV_1sBwdqKGHV3rUU1vJmNKZdy5QNzbRT8F5O0-_jq1WHXurE8a7MaAkWrEALw_wcB&amp;amp;gclsrc=aw.ds"&gt;https://www.google.cn/intl/zh-CN/chrome/?brand=YTUH&amp;amp;gclid=Cj0KCQjwj5mpBhDJARIsAOVjBdoV_1sBwdqKGHV3rUU1vJmNKZdy5QNzbRT8F5O0-_jq1WHXurE8a7MaAkWrEALw_wcB&amp;amp;gclsrc=aw.ds&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;2. ‰øÆÊîπÈÖçÁΩÆÊñá‰ª∂&lt;/h3&gt; 
&lt;p&gt;Âú®ËøêË°åÁ®ãÂ∫è‰πãÂâçÔºåÈúÄË¶ÅÂÖà‰øÆÊîπ&lt;code&gt;config.json&lt;/code&gt;Êñá‰ª∂„ÄÇËØ•Êñá‰ª∂Áî®‰∫éÊåáÂÆöÁî®Êà∑ÈúÄË¶ÅÊä¢Á•®ÁöÑÁõ∏ÂÖ≥‰ø°ÊÅØÔºåÂåÖÊã¨ÊºîÂî±‰ºöÁöÑÂú∫Ê¨°„ÄÅËßÇÊºîÁöÑ‰∫∫Âëò„ÄÅÂüéÂ∏Ç„ÄÅÊó•Êúü„ÄÅ‰ª∑Ê†ºÁ≠â„ÄÇÊñá‰ª∂ÁªìÊûúÂ¶Ç‰∏ãÂõæÊâÄÁ§∫Ôºö&lt;/p&gt; 
&lt;img src="https://raw.githubusercontent.com/WECENG/ticket-purchase/master/img/config_json.png" width="50%" height="50%" /&gt; 
&lt;h4&gt;2.1 Êñá‰ª∂ÂÜÖÂÆπËØ¥Êòé&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;index_url&lt;/code&gt;‰∏∫Â§ßÈ∫¶ÁΩëÁöÑÂú∞ÂùÄÔºå&lt;strong&gt;Êó†ÈúÄ‰øÆÊîπ&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;login_url&lt;/code&gt;‰∏∫Â§ßÈ∫¶ÁΩëÁöÑÁôªÂΩïÂú∞ÂùÄÔºå&lt;strong&gt;Êó†ÈúÄ‰øÆÊîπ&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;target_url&lt;/code&gt;‰∏∫Áî®Êà∑ÈúÄË¶ÅÊä¢ÁöÑÊºîÂî±‰ºöÁ•®ÁöÑÁõÆÊ†áÂú∞ÂùÄÔºå&lt;strong&gt;ÂæÖ‰øÆÊîπ&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;users&lt;/code&gt;‰∏∫ËßÇÊºî‰∫∫ÁöÑÂßìÂêçÔºå&lt;strong&gt;ËßÇÊºî‰∫∫ÈúÄË¶ÅÁî®Êà∑Âú®ÊâãÊú∫Â§ßÈ∫¶APP‰∏≠ÂÖàÂ°´ÂÜôÂ•ΩÔºåÁÑ∂ÂêéÂÜçÂ°´ÂÖ•ËØ•ÈÖçÁΩÆÊñá‰ª∂‰∏≠&lt;/strong&gt;Ôºå&lt;strong&gt;ÂæÖ‰øÆÊîπ&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;city&lt;/code&gt;‰∏∫ÂüéÂ∏ÇÔºå&lt;strong&gt;Â¶ÇÊûúÁî®Êà∑ÈúÄË¶ÅÊä¢ÁöÑÊºîÂî±‰ºöÁ•®ÈúÄË¶ÅÈÄâÊã©ÂüéÂ∏ÇÔºåËØ∑ÊääÂüéÂ∏ÇÂ°´ÂÖ•Ê≠§Â§Ñ„ÄÇÂ¶ÇÊó†ÈúÄÈÄâÊã©ÔºåÂàô‰∏çÂ°´&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;date&lt;/code&gt;‰∏∫Âú∫Ê¨°Êó•ÊúüÔºå&lt;strong&gt;ÂæÖ‰øÆÊîπÔºåÂèØÂ§öÈÄâ&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;price&lt;/code&gt;‰∏∫Á•®Ê°£ÁöÑ‰ª∑Ê†ºÔºå&lt;strong&gt;ÂæÖ‰øÆÊîπÔºåÂèØÂ§öÈÄâ&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;if_commit_order&lt;/code&gt;‰∏∫ÊòØÂê¶Ë¶ÅËá™Âä®Êèê‰∫§ËÆ¢ÂçïÔºå&lt;strong&gt;ÊîπÊàê true&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;if_listen‰∏∫ÊòØÂê¶ÂõûÊµÅÁõëÂê¨Ôºå&lt;strong&gt;ÊîπÊàêtrue&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;2.2 Á§∫‰æãËØ¥Êòé&lt;/h4&gt; 
&lt;p&gt;ËøõÂÖ•Â§ßÈ∫¶ÁΩë&lt;a href="https://www.damai.cn/%EF%BC%8C%E9%80%89%E6%8B%A9%E4%BD%A0%E9%9C%80%E8%A6%81%E6%8A%A2%E7%A5%A8%E7%9A%84%E6%BC%94%E5%94%B1%E4%BC%9A%E3%80%82%E5%81%87%E8%AE%BE%E5%A6%82%E4%B8%8B%E5%9B%BE%E6%89%80%E7%A4%BA%EF%BC%9A"&gt;https://www.damai.cn/ÔºåÈÄâÊã©‰Ω†ÈúÄË¶ÅÊä¢Á•®ÁöÑÊºîÂî±‰ºö„ÄÇÂÅáËÆæÂ¶Ç‰∏ãÂõæÊâÄÁ§∫Ôºö&lt;/a&gt;&lt;/p&gt; 
&lt;img src="https://raw.githubusercontent.com/WECENG/ticket-purchase/master/img/example.png" width="50%" height="50%" /&gt; 
&lt;p&gt;Êé•‰∏ãÊù•ÊåâÁÖß‰∏ãÂõæÁöÑÊ†áÊ≥®ÂØπÈÖçÁΩÆÊñá‰ª∂ËøõË°å‰øÆÊîπÔºö&lt;/p&gt; 
&lt;img src="https://raw.githubusercontent.com/WECENG/ticket-purchase/master/img/example_detail.png" width="50%" height="50%" /&gt; 
&lt;p&gt;ÊúÄÁªà&lt;code&gt;config.json&lt;/code&gt;ÁöÑÊñá‰ª∂ÂÜÖÂÆπÂ¶Ç‰∏ãÔºö&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "index_url": "https://www.damai.cn/",
  "login_url": "https://passport.damai.cn/login?ru=https%3A%2F%2Fwww.damai.cn%2F",
  "target_url": "https://detail.damai.cn/item.htm?spm=a2oeg.home.card_0.ditem_1.591b23e1JQGWHg&amp;amp;id=740680932762",
  "users": [
    "ÂêçÂ≠ó1",
    "ÂêçÂ≠ó2"
  ],
  "city": "ÂπøÂ∑û",
  "date": "2023-10-28",
  "price": "1039",
  "if_listen":true,
  "if_commit_order": true
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;3.ËøêË°åÁ®ãÂ∫è&lt;/h3&gt; 
&lt;p&gt;ËøêË°åÁ®ãÂ∫èÂºÄÂßãÊä¢Á•®ÔºåËøõÂÖ•ÂëΩ‰ª§Á™óÂè£ÔºåÊâßË°åÂ¶Ç‰∏ãÂëΩ‰ª§Ôºö&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;cd damai
python3 damai.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;Â§ßÈ∫¶appÊä¢Á•®&lt;/h1&gt; 
&lt;p&gt;Â§ßÈ∫¶appÊä¢Á•®ËÑöÊú¨ÈúÄË¶Å‰æùËµñappiumÔºåÂõ†Ê≠§ÈúÄË¶ÅÁé∞Âú®ÂÆâË£Öappium server&amp;amp;clientÁéØÂ¢ÉÔºåÊ≠•È™§Â¶Ç‰∏ãÔºö&lt;/p&gt; 
&lt;h2&gt;appium server&lt;/h2&gt; 
&lt;h3&gt;‰∏ãËΩΩ&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;ÂÖàÂÆâË£ÖÂ•ΩnodeÁéØÂ¢ÉÔºàÂÖ∑Â§ánpmÔºânodeÁâàÊú¨Âè∑18.0.0&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;ÂÖà‰∏ãËΩΩÂπ∂ÂÆâË£ÖÂ•Ωandroid sdkÔºåÂπ∂ÈÖçÁΩÆÁéØÂ¢ÉÂèòÈáèÔºàappium serverËøêË°åÈúÄ‰æùËµñandroid sdk)&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;‰∏ãËΩΩappium&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;npm install -g appium
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Êü•ÁúãappiumÊòØÂê¶ÂÆâË£ÖÊàêÂäü&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;appium -v
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;‰∏ãËΩΩUiAutomator2È©±Âä®&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;npm install appium-uiautomator2-driver
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;‚Äã ÂèØËÉΩ‰ºöÈÅáÂà∞Â¶Ç‰∏ãÈîôËØØÔºö&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-tex"&gt;‚ûú  xcode git:(master) ‚úó npm install appium-uiautomator2-driver

npm ERR! code 1
npm ERR! path /Users/chenweicheng/Documents/xcode/node_modules/appium-uiautomator2-driver/node_modules/appium-chromedriver
npm ERR! command failed
npm ERR! command sh -c node install-npm.js
npm ERR! [11:57:54] Error installing Chromedriver: Request failed with status code 404
npm ERR! [11:57:54] AxiosError: Request failed with status code 404
npm ERR!     at settle (/Users/chenweicheng/Documents/xcode/node_modules/appium-uiautomator2-driver/node_modules/axios/lib/core/settle.js:19:12)
npm ERR!     at IncomingMessage.handleStreamEnd (/Users/chenweicheng/Documents/xcode/node_modules/appium-uiautomator2-driver/node_modules/axios/lib/adapters/http.js:572:11)
npm ERR!     at IncomingMessage.emit (node:events:539:35)
npm ERR!     at endReadableNT (node:internal/streams/readable:1344:12)
npm ERR!     at processTicksAndRejections (node:internal/process/task_queues:82:21)
npm ERR! [11:57:54] Downloading Chromedriver can be skipped by setting the'APPIUM_SKIP_CHROMEDRIVER_INSTALL' environment variable.

npm ERR! A complete log of this run can be found in:
npm ERR!     /Users/chenweicheng/.npm/_logs/2023-10-26T03_57_35_950Z-debug-0.log
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;‚Äã Ëß£ÂÜ≥ÂäûÊ≥ïÔºàÊ∑ªÂä†ÁéØÂ¢ÉÂèòÈáèÔºåÈîôËØØÂéüÂõ†ÊòØÊ≤°ÊúâÊâæÂà∞chromeÊµèËßàÂô®È©±Âä®ÔºåÂøΩÁï•Âç≥ÂèØÔºâ&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;export APPIUM_SKIP_CHROMEDRIVER_INSTALL=true
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;ÂêØÂä®&lt;/h3&gt; 
&lt;p&gt;ÂêØÂä®appium serverÂπ∂‰ΩøÁî®uiautomator2È©±Âä®&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;appium --use-plugins uiautomator2
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;ÂêØÂä®ÊàêÂäüÂ∞ÜÂá∫Áé∞Â¶Ç‰∏ã‰ø°ÊÅØÔºö&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;[Appium] Welcome to Appium v2.2.1 (REV 2176894a5be5da17a362bf3f20678641a78f4b69)
[Appium] Non-default server args:
[Appium] {
[Appium]   usePlugins: [
[Appium]     'uiautomator2'
[Appium]   ]
[Appium] }
[Appium] Attempting to load driver uiautomator2...
[Appium] Requiring driver at /Users/chenweicheng/Documents/xcode/node_modules/appium-uiautomator2-driver
[Appium] Appium REST http interface listener started on http://0.0.0.0:4723
[Appium] You can provide the following URLs in your client code to connect to this server:
[Appium] 	http://127.0.0.1:4723/ (only accessible from the same host)
[Appium] 	http://172.31.102.45:4723/
[Appium] 	http://198.18.0.1:4723/
[Appium] Available drivers:
[Appium]   - uiautomator2@2.32.3 (automationName 'UiAutomator2')
[Appium] No plugins have been installed. Use the "appium plugin" command to install the one(s) you want to use.
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;ÂÖ∂‰∏≠&lt;code&gt;[Appium] http://127.0.0.1:4723/ (only accessible from the same host) [Appium] http://172.31.102.45:4723/ [Appium] http://198.18.0.1:4723/&lt;/code&gt;‰∏∫appium serverËøûÊé•Âú∞ÂùÄ&lt;/p&gt; 
&lt;h2&gt;appium client&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;ÂÖà‰∏ãËΩΩÂπ∂ÂÆâË£ÖÂ•Ωpython3Âíåpip3&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;ÂÆâË£Ö&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;pip3 install appium-python-client
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Âú®‰ª£Á†Å‰∏≠ÂºïÂÖ•Âπ∂‰ΩøÁî®appium&lt;/p&gt; &lt;pre&gt;&lt;code class="language-python"&gt;from appium import webdriver
from appium.options.common.base import AppiumOptions

device_app_info = AppiumOptions()
device_app_info.set_capability('platformName', 'Android')
device_app_info.set_capability('platformVersion', '10')
device_app_info.set_capability('deviceName', 'YourDeviceName')
device_app_info.set_capability('appPackage', 'cn.damai')
device_app_info.set_capability('appActivity', '.launcher.splash.SplashMainActivity')
device_app_info.set_capability('unicodeKeyboard', True)
device_app_info.set_capability('resetKeyboard', True)
device_app_info.set_capability('noReset', True)
device_app_info.set_capability('newCommandTimeout', 6000)
device_app_info.set_capability('automationName', 'UiAutomator2')

# ËøûÊé•appium serverÔºåserverÂú∞ÂùÄÊü•ÁúãappiumÂêØÂä®‰ø°ÊÅØ
driver = webdriver.Remote('http://127.0.0.1:4723', options=device_app_info)

&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;ÂêØÂä®ËÑöÊú¨Á®ãÂ∫è&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;cd damai_appium
python3 damai_appium.py
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>elastic/elasticsearch</title>
      <link>https://github.com/elastic/elasticsearch</link>
      <description>&lt;p&gt;Free and Open Source, Distributed, RESTful Search Engine&lt;/p&gt;&lt;hr&gt;</description>
    </item>
    
    <item>
      <title>bytedance/Dolphin</title>
      <link>https://github.com/bytedance/Dolphin</link>
      <description>&lt;p&gt;The official repo for ‚ÄúDolphin: Document Image Parsing via Heterogeneous Anchor Prompting‚Äù, ACL, 2025.&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/bytedance/Dolphin/master/assets/dolphin.png" width="300" /&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://arxiv.org/abs/2505.14059"&gt; &lt;img src="https://img.shields.io/badge/Paper-arXiv-red" /&gt; &lt;/a&gt; 
 &lt;a href="https://huggingface.co/ByteDance/Dolphin"&gt; &lt;img src="https://img.shields.io/badge/HuggingFace-Dolphin-yellow" /&gt; &lt;/a&gt; 
 &lt;a href="https://modelscope.cn/models/ByteDance/Dolphin"&gt; &lt;img src="https://img.shields.io/badge/ModelScope-Dolphin-purple" /&gt; &lt;/a&gt; 
 &lt;a href="https://huggingface.co/spaces/ByteDance/Dolphin"&gt; &lt;img src="https://img.shields.io/badge/Demo-Dolphin-blue" /&gt; &lt;/a&gt; 
 &lt;a href="https://github.com/bytedance/Dolphin"&gt; &lt;img src="https://img.shields.io/badge/Code-Github-green" /&gt; &lt;/a&gt; 
 &lt;a href="https://opensource.org/licenses/MIT"&gt; &lt;img src="https://img.shields.io/badge/License-MIT-lightgray" /&gt; &lt;/a&gt; 
 &lt;br /&gt; 
&lt;/div&gt; 
&lt;br /&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/bytedance/Dolphin/master/assets/demo.gif" width="800" /&gt; 
&lt;/div&gt; 
&lt;h1&gt;Dolphin: Document Image Parsing via Heterogeneous Anchor Prompting&lt;/h1&gt; 
&lt;p&gt;Dolphin (&lt;strong&gt;Do&lt;/strong&gt;cument Image &lt;strong&gt;P&lt;/strong&gt;arsing via &lt;strong&gt;H&lt;/strong&gt;eterogeneous Anchor Prompt&lt;strong&gt;in&lt;/strong&gt;g) is a novel multimodal document image parsing model following an analyze-then-parse paradigm. This repository contains the demo code and pre-trained models for Dolphin.&lt;/p&gt; 
&lt;h2&gt;üìë Overview&lt;/h2&gt; 
&lt;p&gt;Document image parsing is challenging due to its complexly intertwined elements such as text paragraphs, figures, formulas, and tables. Dolphin addresses these challenges through a two-stage approach:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;üîç Stage 1&lt;/strong&gt;: Comprehensive page-level layout analysis by generating element sequence in natural reading order&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üß© Stage 2&lt;/strong&gt;: Efficient parallel parsing of document elements using heterogeneous anchors and task-specific prompts&lt;/li&gt; 
&lt;/ol&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/bytedance/Dolphin/master/assets/framework.png" width="680" /&gt; 
&lt;/div&gt; 
&lt;p&gt;Dolphin achieves promising performance across diverse page-level and element-level parsing tasks while ensuring superior efficiency through its lightweight architecture and parallel parsing mechanism.&lt;/p&gt; 
&lt;h2&gt;üöÄ Demo&lt;/h2&gt; 
&lt;p&gt;Try our demo on &lt;a href="https://huggingface.co/spaces/ByteDance/Dolphin"&gt;Demo-Dolphin&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;üìÖ Changelog&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;üî• &lt;strong&gt;2025.07.10&lt;/strong&gt; Released the &lt;em&gt;Fox-Page Benchmark&lt;/em&gt;, a manually refined subset of the original &lt;a href="https://github.com/ucaslcl/Fox"&gt;Fox dataset&lt;/a&gt;. Download via: &lt;a href="https://pan.baidu.com/share/init?surl=t746ULp6iU5bUraVrPlMSw&amp;amp;pwd=fox1"&gt;Baidu Yun&lt;/a&gt; | &lt;a href="https://drive.google.com/file/d/1yZQZqI34QCqvhB4Tmdl3X_XEvYvQyP0q/view?usp=sharing"&gt;Google Drive&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;üî• &lt;strong&gt;2025.06.30&lt;/strong&gt; Added &lt;a href="https://github.com/bytedance/Dolphin/raw/master/deployment/tensorrt_llm/ReadMe.md"&gt;TensorRT-LLM support&lt;/a&gt; for accelerated inferenceÔºÅ&lt;/li&gt; 
 &lt;li&gt;üî• &lt;strong&gt;2025.06.27&lt;/strong&gt; Added &lt;a href="https://github.com/bytedance/Dolphin/raw/master/deployment/vllm/ReadMe.md"&gt;vLLM support&lt;/a&gt; for accelerated inferenceÔºÅ&lt;/li&gt; 
 &lt;li&gt;üî• &lt;strong&gt;2025.06.13&lt;/strong&gt; Added multi-page PDF document parsing capability.&lt;/li&gt; 
 &lt;li&gt;üî• &lt;strong&gt;2025.05.21&lt;/strong&gt; Our demo is released at &lt;a href="http://115.190.42.15:8888/dolphin/"&gt;link&lt;/a&gt;. Check it out!&lt;/li&gt; 
 &lt;li&gt;üî• &lt;strong&gt;2025.05.20&lt;/strong&gt; The pretrained model and inference code of Dolphin are released.&lt;/li&gt; 
 &lt;li&gt;üî• &lt;strong&gt;2025.05.16&lt;/strong&gt; Our paper has been accepted by ACL 2025. Paper link: &lt;a href="https://arxiv.org/abs/2505.14059"&gt;arXiv&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üõ†Ô∏è Installation&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Clone the repository:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/ByteDance/Dolphin.git
cd Dolphin
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Install the dependencies:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;pip install -r requirements.txt
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Download the pre-trained models using one of the following options:&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Option A: Original Model Format (config-based)&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;Download from &lt;a href="https://pan.baidu.com/s/15zcARoX0CTOHKbW8bFZovQ?pwd=9rpx"&gt;Baidu Yun&lt;/a&gt; or &lt;a href="https://drive.google.com/drive/folders/1PQJ3UutepXvunizZEw-uGaQ0BCzf-mie?usp=sharing"&gt;Google Drive&lt;/a&gt; and put them in the &lt;code&gt;./checkpoints&lt;/code&gt; folder.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Option B: Hugging Face Model Format&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;Visit our Huggingface &lt;a href="https://huggingface.co/ByteDance/Dolphin"&gt;model card&lt;/a&gt;, or download model by:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;# Download the model from Hugging Face Hub
git lfs install
git clone https://huggingface.co/ByteDance/Dolphin ./hf_model
# Or use the Hugging Face CLI
pip install huggingface_hub
huggingface-cli download ByteDance/Dolphin --local-dir ./hf_model
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;‚ö° Inference&lt;/h2&gt; 
&lt;p&gt;Dolphin provides two inference frameworks with support for two parsing granularities:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Page-level Parsing&lt;/strong&gt;: Parse the entire document page into a structured JSON and Markdown format&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Element-level Parsing&lt;/strong&gt;: Parse individual document elements (text, table, formula)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üìÑ Page-level Parsing&lt;/h3&gt; 
&lt;h4&gt;Using Original Framework (config-based)&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Process a single document image
python demo_page.py --config ./config/Dolphin.yaml --input_path ./demo/page_imgs/page_1.jpeg --save_dir ./results

# Process a single document pdf
python demo_page.py --config ./config/Dolphin.yaml --input_path ./demo/page_imgs/page_6.pdf --save_dir ./results

# Process all documents in a directory
python demo_page.py --config ./config/Dolphin.yaml --input_path ./demo/page_imgs --save_dir ./results

# Process with custom batch size for parallel element decoding
python demo_page.py --config ./config/Dolphin.yaml --input_path ./demo/page_imgs --save_dir ./results --max_batch_size 8
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Using Hugging Face Framework&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Process a single document image
python demo_page_hf.py --model_path ./hf_model --input_path ./demo/page_imgs/page_1.jpeg --save_dir ./results

# Process a single document pdf
python demo_page_hf.py --model_path ./hf_model --input_path ./demo/page_imgs/page_6.pdf --save_dir ./results

# Process all documents in a directory
python demo_page_hf.py --model_path ./hf_model --input_path ./demo/page_imgs --save_dir ./results

# Process with custom batch size for parallel element decoding
python demo_page_hf.py --model_path ./hf_model --input_path ./demo/page_imgs --save_dir ./results --max_batch_size 16
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;üß© Element-level Parsing&lt;/h3&gt; 
&lt;h4&gt;Using Original Framework (config-based)&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Process a single table image
python demo_element.py --config ./config/Dolphin.yaml --input_path ./demo/element_imgs/table_1.jpeg --element_type table

# Process a single formula image
python demo_element.py --config ./config/Dolphin.yaml --input_path ./demo/element_imgs/line_formula.jpeg --element_type formula

# Process a single text paragraph image
python demo_element.py --config ./config/Dolphin.yaml --input_path ./demo/element_imgs/para_1.jpg --element_type text
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Using Hugging Face Framework&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Process a single table image
python demo_element_hf.py --model_path ./hf_model --input_path ./demo/element_imgs/table_1.jpeg --element_type table

# Process a single formula image
python demo_element_hf.py --model_path ./hf_model --input_path ./demo/element_imgs/line_formula.jpeg --element_type formula

# Process a single text paragraph image
python demo_element_hf.py --model_path ./hf_model --input_path ./demo/element_imgs/para_1.jpg --element_type text
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;üåü Key Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;üîÑ Two-stage analyze-then-parse approach based on a single VLM&lt;/li&gt; 
 &lt;li&gt;üìä Promising performance on document parsing tasks&lt;/li&gt; 
 &lt;li&gt;üîç Natural reading order element sequence generation&lt;/li&gt; 
 &lt;li&gt;üß© Heterogeneous anchor prompting for different document elements&lt;/li&gt; 
 &lt;li&gt;‚è±Ô∏è Efficient parallel parsing mechanism&lt;/li&gt; 
 &lt;li&gt;ü§ó Support for Hugging Face Transformers for easier integration&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üìÆ Notice&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Call for Bad Cases:&lt;/strong&gt; If you have encountered any cases where the model performs poorly, we would greatly appreciate it if you could share them in the issue. We are continuously working to optimize and improve the model.&lt;/p&gt; 
&lt;h2&gt;üíñ Acknowledgement&lt;/h2&gt; 
&lt;p&gt;We would like to acknowledge the following open-source projects that provided inspiration and reference for this work:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/clovaai/donut/"&gt;Donut&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/facebookresearch/nougat"&gt;Nougat&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Ucas-HaoranWei/GOT-OCR2.0"&gt;GOT&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/opendatalab/MinerU/tree/master"&gt;MinerU&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/microsoft/Swin-Transformer"&gt;Swin&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/huggingface/transformers"&gt;Hugging Face Transformers&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üìù Citation&lt;/h2&gt; 
&lt;p&gt;If you find this code useful for your research, please use the following BibTeX entry.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bibtex"&gt;@article{feng2025dolphin,
  title={Dolphin: Document Image Parsing via Heterogeneous Anchor Prompting},
  author={Feng, Hao and Wei, Shu and Fei, Xiang and Shi, Wei and Han, Yingdong and Liao, Lei and Lu, Jinghui and Wu, Binghong and Liu, Qi and Lin, Chunhui and others},
  journal={arXiv preprint arXiv:2505.14059},
  year={2025}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Star History&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://www.star-history.com/#bytedance/Dolphin&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=bytedance/Dolphin&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>knownsec/aipyapp</title>
      <link>https://github.com/knownsec/aipyapp</link>
      <description>&lt;p&gt;AI-Powered Python &amp; Python-Powered AI (Python-Use)&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/3af4e228-79b2-4fa0-a45c-c38276c6db91" alt="logo" /&gt;&lt;/p&gt; 
&lt;h1&gt;Python use&lt;/h1&gt; 
&lt;p&gt;AIPy is an implementation of the Python-use concept, demonstrating its practical value and potential.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Mission&lt;/strong&gt;: unleash the full potential of large language models.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Vision&lt;/strong&gt;: a future where LLMs can think independently and proactively leverage AIPy to solve complex problems.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;What&lt;/h2&gt; 
&lt;p&gt;Python use provides the entire Python execution environment to LLM. Imagine LLM sitting in front of a computer, typing various commands into the Python command-line interpreter, pressing Enter to execute, observing the results, and then typing and executing more code.&lt;/p&gt; 
&lt;p&gt;Unlike Agents, Python use does not define any tools interface. LLM can freely use all the features provided by the Python runtime environment.&lt;/p&gt; 
&lt;h2&gt;Why&lt;/h2&gt; 
&lt;p&gt;If you are a data engineer, you are likely familiar with the following scenarios:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Handling various data file formats: csv/excel, json, html, sqlite, parquet, etc.&lt;/li&gt; 
 &lt;li&gt;Performing operations like data cleaning, transformation, computation, aggregation, sorting, grouping, filtering, analysis, and visualization.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;This process often requires:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Starting Python, importing pandas as pd, and typing a bunch of commands to process data.&lt;/li&gt; 
 &lt;li&gt;Generating a bunch of intermediate temporary files.&lt;/li&gt; 
 &lt;li&gt;Describing your needs to ChatGPT/Claude, copying the generated data processing code, and running it manually.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;So, why not start the Python command-line interpreter, directly describe your data processing needs, and let it be done automatically? The benefits are:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;No need to manually input a bunch of Python commands temporarily.&lt;/li&gt; 
 &lt;li&gt;No need to describe your needs to GPT, copy the program, and run it manually.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;This is the problem Python use aims to solve!&lt;/p&gt; 
&lt;h2&gt;How&lt;/h2&gt; 
&lt;p&gt;Python use (aipython) is a Python command-line interpreter integrated with LLM. You can:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Enter and execute Python commands as usual.&lt;/li&gt; 
 &lt;li&gt;Describe your needs in natural language, and aipython will automatically generate Python commands and execute them.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Moreover, the two modes can access data interchangeably. For example, after aipython processes your natural language commands, you can use standard Python commands to view various data.&lt;/p&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;p&gt;AIPython has two running modes:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Task mode: Very simple and easy to use, just input your task, suitable for users unfamiliar with Python.&lt;/li&gt; 
 &lt;li&gt;Python mode: Suitable for users familiar with Python, allowing both task input and Python commands, ideal for advanced users.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The default running mode is task mode, which can be switched to Python mode using the &lt;code&gt;--python&lt;/code&gt; parameter.&lt;/p&gt; 
&lt;h3&gt;Basic Config&lt;/h3&gt; 
&lt;p&gt;~/.aipyapp/aipyapp.toml:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;[llm.deepseek]
type = "deepseek"
api_key = "Your DeepSeek API Key"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Task Mode&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;uv run aipy&lt;/code&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt; Get the latest posts from Reddit r/LocalLLaMA
......
......
&amp;gt;&amp;gt;&amp;gt; /done
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;code&gt;pip install aipyapp&lt;/code&gt; and run with &lt;code&gt;aipy&lt;/code&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;-&amp;gt; % aipy
üöÄ Python use - AIPython (0.1.22) [https://aipy.app]
&amp;gt;&amp;gt; Get the latest posts from Reddit r/LocalLLaMA
......
&amp;gt;&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Python Mode&lt;/h3&gt; 
&lt;h4&gt;Basic Usage&lt;/h4&gt; 
&lt;p&gt;Automatic task processing:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt; ai("Get the title of Google's homepage")
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Automatically Request to Install Third-Party Libraries&lt;/h4&gt; 
&lt;pre&gt;&lt;code&gt;Python use - AIPython (Quit with 'exit()')
&amp;gt;&amp;gt;&amp;gt; ai("Use psutil to list all processes on MacOS")

üì¶ LLM requests to install third-party packages: ['psutil']
If you agree and have installed, please enter 'y [y/n] (n): y

&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Thanks&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Hei Ge: Product manager/senior user/chief tester&lt;/li&gt; 
 &lt;li&gt;Sonnet 3.7: Generated the first version of the code, which was almost ready to use without modification.&lt;/li&gt; 
 &lt;li&gt;ChatGPT: Provided many suggestions and code snippets, especially for the command-line interface.&lt;/li&gt; 
 &lt;li&gt;Codeium: Intelligent code completion&lt;/li&gt; 
 &lt;li&gt;Copilot: Code improvement suggestions and README translation&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>basecamp/omarchy</title>
      <link>https://github.com/basecamp/omarchy</link>
      <description>&lt;p&gt;Opinionated Arch/Hyprland Setup&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Omarchy&lt;/h1&gt; 
&lt;p&gt;Turn a fresh Arch installation into a fully-configured, beautiful, and modern web development system based on Hyprland by running a single command. That's the one-line pitch for Omarchy (like it was for Omakub). No need to write bespoke configs for every essential tool just to get started or to be up on all the latest command-line tools. Omarchy is an opinionated take on what Linux can be at its best.&lt;/p&gt; 
&lt;p&gt;Read more at &lt;a href="https://omarchy.org"&gt;omarchy.org&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Omarchy is released under the &lt;a href="https://opensource.org/licenses/MIT"&gt;MIT License&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>oauth2-proxy/oauth2-proxy</title>
      <link>https://github.com/oauth2-proxy/oauth2-proxy</link>
      <description>&lt;p&gt;A reverse proxy that provides authentication with Google, Azure, OpenID Connect and many more identity providers.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href="https://github.com/oauth2-proxy/oauth2-proxy/actions/workflows/ci.yml"&gt;&lt;img src="https://github.com/oauth2-proxy/oauth2-proxy/actions/workflows/ci.yml/badge.svg?sanitize=true" alt="Continuous Integration" /&gt;&lt;/a&gt; &lt;a href="https://goreportcard.com/report/github.com/oauth2-proxy/oauth2-proxy"&gt;&lt;img src="https://goreportcard.com/badge/github.com/oauth2-proxy/oauth2-proxy" alt="Go Report Card" /&gt;&lt;/a&gt; &lt;a href="https://godoc.org/github.com/oauth2-proxy/oauth2-proxy"&gt;&lt;img src="https://godoc.org/github.com/oauth2-proxy/oauth2-proxy?status.svg?sanitize=true" alt="GoDoc" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/oauth2-proxy/oauth2-proxy/master/LICENSE"&gt;&lt;img src="https://img.shields.io/badge/license-MIT-blue.svg?sanitize=true" alt="MIT licensed" /&gt;&lt;/a&gt; &lt;a href="https://codeclimate.com/github/oauth2-proxy/oauth2-proxy/maintainability"&gt;&lt;img src="https://api.codeclimate.com/v1/badges/a58ff79407212e2beacb/maintainability" alt="Maintainability" /&gt;&lt;/a&gt; &lt;a href="https://codeclimate.com/github/oauth2-proxy/oauth2-proxy/test_coverage"&gt;&lt;img src="https://api.codeclimate.com/v1/badges/a58ff79407212e2beacb/test_coverage" alt="Test Coverage" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/oauth2-proxy/oauth2-proxy/master/docs/static/img/logos/OAuth2_Proxy_horizontal.svg?sanitize=true" alt="OAuth2 Proxy" /&gt;&lt;/p&gt; 
&lt;p&gt;OAuth2-Proxy is a flexible, open-source tool that can act as either a standalone reverse proxy or a middleware component integrated into existing reverse proxy or load balancer setups. It provides a simple and secure way to protect your web applications with OAuth2 / OIDC authentication. As a reverse proxy, it intercepts requests to your application and redirects users to an OAuth2 provider for authentication. As a middleware, it can be seamlessly integrated into your existing infrastructure to handle authentication for multiple applications.&lt;/p&gt; 
&lt;p&gt;OAuth2-Proxy supports a lot of OAuth2 as well as OIDC providers. Either through a generic OIDC client or a specific implementation for Google, Microsoft Entra ID, GitHub, login.gov and others. Through specialised provider implementations oauth2-proxy can extract more details about the user like preferred usernames and groups. Those details can then be forwarded as HTTP headers to your upstream applications.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/oauth2-proxy/oauth2-proxy/master/docs/static/img/simplified-architecture.svg?sanitize=true" alt="Simplified Architecture" /&gt;&lt;/p&gt; 
&lt;h2&gt;Get Started&lt;/h2&gt; 
&lt;p&gt;OAuth2-Proxy's &lt;a href="https://oauth2-proxy.github.io/oauth2-proxy/installation"&gt;Installation Docs&lt;/a&gt; cover how to install and configure your setup. Additionally you can take a further look at the &lt;a href="https://github.com/oauth2-proxy/oauth2-proxy/tree/master/contrib/local-environment"&gt;example setup files&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Releases&lt;/h2&gt; 
&lt;h3&gt;Binaries&lt;/h3&gt; 
&lt;p&gt;We publish oauth2-proxy as compiled binaries on GitHub for all major architectures as well as more exotic ones like &lt;code&gt;ppc64le&lt;/code&gt; as well as &lt;code&gt;s390x&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Check out the &lt;a href="https://github.com/oauth2-proxy/oauth2-proxy/releases/latest"&gt;latest release&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Images&lt;/h3&gt; 
&lt;p&gt;From &lt;code&gt;v7.6.0&lt;/code&gt; and up the base image has been changed from Alpine to &lt;a href="https://github.com/GoogleContainerTools/distroless"&gt;GoogleContainerTools/distroless&lt;/a&gt;. This image comes with even fewer installed dependencies and thus should improve security. The image therefore is also slightly smaller than Alpine. For debugging purposes (and those who really need it. e.g. &lt;code&gt;armv6&lt;/code&gt;) we still provide images based on Alpine. The tags of these images are suffixed with &lt;code&gt;-alpine&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Since 2023-11-18 we build nightly images directly from the &lt;code&gt;master&lt;/code&gt; branch and provide them at &lt;code&gt;quay.io/oauth2-proxy/oauth2-proxy-nightly&lt;/code&gt;. These images are considered unstable and therefore should &lt;strong&gt;NOT&lt;/strong&gt; be used for production purposes unless you know what you're doing.&lt;/p&gt; 
&lt;h2&gt;Sponsors&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://upload.wikimedia.org/wikipedia/commons/9/96/Microsoft_logo_%282012%29.svg?sanitize=true" alt="Microsoft" /&gt; Microsoft Azure credits for open source projects&lt;/p&gt; 
&lt;p&gt;Would you like to sponsor the project then please contact us at &lt;a href="mailto:sponsors@oauth2-proxy.dev"&gt;sponsors@oauth2-proxy.dev&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Getting Involved&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://gophers.slack.com/archives/CM2RSS25N"&gt;&lt;img src="https://img.shields.io/badge/slack-Gopher_%23oauth2--proxy-red?logo=slack" alt="Slack" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Join the #oauth2-proxy &lt;a href="https://gophers.slack.com/archives/CM2RSS25N"&gt;Slack channel&lt;/a&gt; to chat with other users of oauth2-proxy or reach out to the maintainers directly. Use the &lt;a href="https://invite.slack.golangbridge.org/"&gt;public invite link&lt;/a&gt; to get an invite for the Gopher Slack space.&lt;/p&gt; 
&lt;p&gt;OAuth2-Proxy is a community-driven project. We rely on the contributÔ∏èions of our users to continually improve it. While review times can vary, we appreciate your patience and understanding. As a volunteer-driven project, we strive to keep this project stable and might take longer to merge changes.&lt;/p&gt; 
&lt;p&gt;If you want to contribute to the project. Please see our &lt;a href="https://oauth2-proxy.github.io/oauth2-proxy/community/contribution"&gt;Contributing&lt;/a&gt; guide.&lt;/p&gt; 
&lt;p&gt;Who uses OAuth2-Proxy? Have a look at our new &lt;a href="https://raw.githubusercontent.com/oauth2-proxy/oauth2-proxy/master/ADOPTERS.md"&gt;ADOPTERS&lt;/a&gt; file and feel free to open a PR to add your organisation.&lt;/p&gt; 
&lt;p&gt;Thanks to all the people who already contributed ‚ù§&lt;/p&gt; 
&lt;a href="https://github.com/oauth2-proxy/oauth2-proxy/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=oauth2-proxy/oauth2-proxy&amp;amp;columns=15&amp;amp;max=75" /&gt; &lt;img src="https://img.shields.io/github/contributors/oauth2-proxy/oauth2-proxy" /&gt; &lt;/a&gt; 
&lt;p&gt;Made with &lt;a href="https://contrib.rocks"&gt;contrib.rocks&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Security&lt;/h2&gt; 
&lt;p&gt;If you believe you have found a vulnerability within OAuth2 Proxy or any of its dependencies, please do &lt;strong&gt;NOT&lt;/strong&gt; open an issue or PR on GitHub, please do &lt;strong&gt;NOT&lt;/strong&gt; post any details publicly.&lt;/p&gt; 
&lt;p&gt;Security disclosures &lt;strong&gt;MUST&lt;/strong&gt; be done in private. If you have found an issue that you would like to bring to the attention of the maintainers, please compose an email and send it to the list of people listed in our &lt;a href="https://raw.githubusercontent.com/oauth2-proxy/oauth2-proxy/master/MAINTAINERS"&gt;MAINTAINERS&lt;/a&gt; file.&lt;/p&gt; 
&lt;p&gt;For more details read our full &lt;a href="https://oauth2-proxy.github.io/oauth2-proxy/community/security#security-disclosures"&gt;Security Docs&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Security Notice for v6.0.0 and older&lt;/h3&gt; 
&lt;p&gt;If you are running a version older than v6.0.0 we &lt;strong&gt;strongly recommend&lt;/strong&gt; to the current version.&lt;/p&gt; 
&lt;p&gt;See &lt;a href="https://github.com/oauth2-proxy/oauth2-proxy/security/advisories/GHSA-5m6c-jp6f-2vcv"&gt;open redirect vulnerability&lt;/a&gt; for details.&lt;/p&gt; 
&lt;h2&gt;Repository History&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;2018-11-27:&lt;/strong&gt; This repository was forked from &lt;a href="https://github.com/bitly/oauth2_proxy"&gt;bitly/OAuth2_Proxy&lt;/a&gt;. Versions v3.0.0 and up are from this fork and will have diverged from any changes in the original fork. A list of changes can be seen in the &lt;a href="https://raw.githubusercontent.com/oauth2-proxy/oauth2-proxy/master/CHANGELOG.md"&gt;CHANGELOG&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2020-03-29:&lt;/strong&gt; This project was formerly hosted as &lt;code&gt;pusher/oauth2_proxy&lt;/code&gt; but has been renamed to &lt;code&gt;oauth2-proxy/oauth2-proxy&lt;/code&gt;. Going forward, all images shall be available at &lt;code&gt;quay.io/oauth2-proxy/oauth2-proxy&lt;/code&gt; and binaries will be named &lt;code&gt;oauth2-proxy&lt;/code&gt;.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;OAuth2-Proxy is distributed under &lt;a href="https://raw.githubusercontent.com/oauth2-proxy/oauth2-proxy/master/LICENSE"&gt;The MIT License&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>WebGoat/WebGoat</title>
      <link>https://github.com/WebGoat/WebGoat</link>
      <description>&lt;p&gt;WebGoat is a deliberately insecure application&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;WebGoat: A deliberately insecure Web Application&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://github.com/WebGoat/WebGoat/actions/workflows/build.yml"&gt;&lt;img src="https://github.com/WebGoat/WebGoat/actions/workflows/build.yml/badge.svg?branch=develop" alt="Build" /&gt;&lt;/a&gt; &lt;a href="https://jdk.java.net/"&gt;&lt;img src="https://img.shields.io/badge/java%20jdk-23-green.svg?sanitize=true" alt="java-jdk" /&gt;&lt;/a&gt; &lt;a href="https://owasp.org/projects/"&gt;&lt;img src="https://img.shields.io/badge/OWASP-Lab%20project-f7b73c.svg?sanitize=true" alt="OWASP Labs" /&gt;&lt;/a&gt; &lt;a href="https://github.com/WebGoat/WebGoat/releases/latest"&gt;&lt;img src="https://img.shields.io/github/release/WebGoat/WebGoat.svg?sanitize=true" alt="GitHub release" /&gt;&lt;/a&gt; &lt;a href="https://gitter.im/OWASPWebGoat/community?utm_source=badge&amp;amp;utm_medium=badge&amp;amp;utm_campaign=pr-badge"&gt;&lt;img src="https://badges.gitter.im/OWASPWebGoat/community.svg?sanitize=true" alt="Gitter" /&gt;&lt;/a&gt; &lt;a href="https://github.com/WebGoat/WebGoat/discussions"&gt;&lt;img src="https://img.shields.io/github/discussions/WebGoat/WebGoat" alt="Discussions" /&gt;&lt;/a&gt; &lt;a href="https://conventionalcommits.org"&gt;&lt;img src="https://img.shields.io/badge/Conventional%20Commits-1.0.0-%23FE5196?logo=conventionalcommits&amp;amp;logoColor=white" alt="Conventional Commits" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Introduction&lt;/h1&gt; 
&lt;p&gt;WebGoat is a deliberately insecure web application maintained by &lt;a href="http://www.owasp.org/"&gt;OWASP&lt;/a&gt; designed to teach web application security lessons.&lt;/p&gt; 
&lt;p&gt;This program is a demonstration of common server-side application flaws. The exercises are intended to be used by people to learn about application security and penetration testing techniques.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;WARNING 1:&lt;/strong&gt; &lt;em&gt;While running this program your machine will be extremely vulnerable to attack. You should disconnect from the Internet while using this program.&lt;/em&gt; WebGoat's default configuration binds to localhost to minimize the exposure.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;WARNING 2:&lt;/strong&gt; &lt;em&gt;This program is for educational purposes only. If you attempt these techniques without authorization, you are very likely to get caught. If you are caught engaging in unauthorized hacking, most companies will fire you. Claiming that you were doing security research will not work as that is the first thing that all hackers claim.&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/WebGoat/WebGoat/main/docs/images/webgoat.png" alt="WebGoat" /&gt;&lt;/p&gt; 
&lt;h1&gt;Installation instructions:&lt;/h1&gt; 
&lt;p&gt;For more details check &lt;a href="https://raw.githubusercontent.com/WebGoat/WebGoat/main/CONTRIBUTING.md"&gt;the Contribution guide&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;1. Run using Docker&lt;/h2&gt; 
&lt;p&gt;Already have a browser and ZAP and/or Burp installed on your machine in this case you can run the WebGoat image directly using Docker.&lt;/p&gt; 
&lt;p&gt;Every release is also published on &lt;a href="https://hub.docker.com/r/webgoat/webgoat"&gt;DockerHub&lt;/a&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;docker run -it -p 127.0.0.1:8080:8080 -p 127.0.0.1:9090:9090 webgoat/webgoat
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For some lessons you need the container run in the same timezone. For this you can set the TZ environment variable. E.g.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;docker run -it -p 127.0.0.1:8080:8080 -p 127.0.0.1:9090:9090 -e TZ=America/Boise webgoat/webgoat
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you want to use OWASP ZAP or another proxy, you can no longer use 127.0.0.1 or localhost. but you can use custom host entries. For example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;127.0.0.1 www.webgoat.local www.webwolf.local
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then you can run the container with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;docker run -it -p 127.0.0.1:8080:8080 -p 127.0.0.1:9090:9090 -e WEBGOAT_HOST=www.webgoat.local -e WEBWOLF_HOST=www.webwolf.local -e TZ=America/Boise webgoat/webgoat
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then visit &lt;a href="http://www.webgoat.local:8080/WebGoat/"&gt;http://www.webgoat.local:8080/WebGoat/&lt;/a&gt; and &lt;a href="http://www.webwolf.local:9090/WebWolf/"&gt;http://www.webwolf.local:9090/WebWolf/&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;2. Run using Docker with complete Linux Desktop&lt;/h2&gt; 
&lt;p&gt;Instead of installing tools locally we have a complete Docker image based on running a desktop in your browser. This way you only have to run a Docker image which will give you the best user experience.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;docker run -p 127.0.0.1:3000:3000 webgoat/webgoat-desktop
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;3. Standalone&lt;/h2&gt; 
&lt;p&gt;Download the latest WebGoat release from &lt;a href="https://github.com/WebGoat/WebGoat/releases"&gt;https://github.com/WebGoat/WebGoat/releases&lt;/a&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;export TZ=Europe/Amsterdam # or your timezone
java -Dfile.encoding=UTF-8 -jar webgoat-2023.8.jar
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Click the link in the log to start WebGoat.&lt;/p&gt; 
&lt;h3&gt;3.1 Running on a different port&lt;/h3&gt; 
&lt;p&gt;If for some reason you want to run WebGoat on a different port, you can do so by adding the following parameter:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;java -jar webgoat-2023.8.jar --webgoat.port=8001 --webwolf.port=8002
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For a full overview of all the parameters you can use, please check the [WebGoat properties file](webgoat-container/src/main/resources/application-{webgoat, webwolf}.properties).&lt;/p&gt; 
&lt;h2&gt;4. Run from the sources&lt;/h2&gt; 
&lt;h3&gt;Prerequisites:&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Java 23&lt;/li&gt; 
 &lt;li&gt;Your favorite IDE&lt;/li&gt; 
 &lt;li&gt;Git, or Git support in your IDE&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Open a command shell/window:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-Shell"&gt;git clone git@github.com:WebGoat/WebGoat.git
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Now let's start by compiling the project.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-Shell"&gt;cd WebGoat
git checkout &amp;lt;&amp;lt;branch_name&amp;gt;&amp;gt;
# On Linux/Mac:
./mvnw clean install

# On Windows:
./mvnw.cmd clean install

# Using docker or podman, you can than build the container locally
docker build -f Dockerfile . -t webgoat/webgoat
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Now we are ready to run the project. WebGoat is using Spring Boot.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-Shell"&gt;# On Linux/Mac:
./mvnw spring-boot:run
# On Windows:
./mvnw.cmd spring-boot:run

&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;... you should be running WebGoat on &lt;a href="http://localhost:8080/WebGoat"&gt;http://localhost:8080/WebGoat&lt;/a&gt; momentarily.&lt;/p&gt; 
&lt;p&gt;Note: The above link will redirect you to login page if you are not logged in. LogIn/Create account to proceed.&lt;/p&gt; 
&lt;p&gt;To change the IP address add the following variable to the &lt;code&gt;WebGoat/webgoat-container/src/main/resources/application.properties&lt;/code&gt; file:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;server.address=x.x.x.x
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;4. Run with custom menu&lt;/h2&gt; 
&lt;p&gt;For specialist only. There is a way to set up WebGoat with a personalized menu. You can leave out some menu categories or individual lessons by setting certain environment variables.&lt;/p&gt; 
&lt;p&gt;For instance running as a jar on a Linux/macOS it will look like this:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-Shell"&gt;export TZ=Europe/Amsterdam # or your timezone
export EXCLUDE_CATEGORIES="CLIENT_SIDE,GENERAL,CHALLENGE"
export EXCLUDE_LESSONS="SqlInjectionAdvanced,SqlInjectionMitigations"
java -jar target/webgoat-2023.8-SNAPSHOT.jar
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or in a docker run it would (once this version is pushed into docker hub) look like this:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-Shell"&gt;docker run -d -p 127.0.0.1:8080:8080 -p 127.0.0.1:9090:9090 -e EXCLUDE_CATEGORIES="CLIENT_SIDE,GENERAL,CHALLENGE" -e EXCLUDE_LESSONS="SqlInjectionAdvanced,SqlInjectionMitigations" webgoat/webgoat
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>TanStack/router</title>
      <link>https://github.com/TanStack/router</link>
      <description>&lt;p&gt;ü§ñ Fully typesafe Router for React (and friends) w/ built-in caching, 1st class search-param APIs, client-side cache integration and isomorphic rendering.&lt;/p&gt;&lt;hr&gt;&lt;img src="https://static.scarf.sh/a.png?x-pxid=d988eb79-b0fc-4a2b-8514-6a1ab932d188" /&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td&gt; &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/TanStack/router/main/media/header_router.png" alt="TanStack Router" /&gt;&lt;/p&gt; &lt;h2&gt;TanStack Router&lt;/h2&gt; &lt;p&gt;A modern router designed for type safety, data‚Äëdriven navigation, and seamless developer experience.&lt;/p&gt; 
    &lt;ul&gt; 
     &lt;li&gt;End‚Äëto‚Äëend type safety (routes, params, loaders)&lt;/li&gt; 
     &lt;li&gt;Schema‚Äëdriven search params with validation&lt;/li&gt; 
     &lt;li&gt;Built‚Äëin caching, prefetching &amp;amp; invalidation&lt;/li&gt; 
     &lt;li&gt;Nested layouts, transitions &amp;amp; error boundaries&lt;/li&gt; 
    &lt;/ul&gt; &lt;h3&gt;&lt;a href="https://tanstack.com/router"&gt;Read the Router Docs ‚Üí&lt;/a&gt;&lt;/h3&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/TanStack/router/main/media/header_start.png" alt="TanStack Start" /&gt;&lt;/p&gt; &lt;h2&gt;TanStack Start&lt;/h2&gt; &lt;p&gt;A full‚Äëstack framework built on Router, designed for server rendering, streaming, and production‚Äëready deployments.&lt;/p&gt; 
    &lt;ul&gt; 
     &lt;li&gt;Full‚Äëdocument SSR &amp;amp; streaming&lt;/li&gt; 
     &lt;li&gt;Server functions &amp;amp; end‚Äëto‚Äëend type safety&lt;/li&gt; 
     &lt;li&gt;Deployment‚Äëready bundling &amp;amp; builds&lt;/li&gt; 
     &lt;li&gt;All the power of TanStack Router, plus full‚Äëstack features&lt;/li&gt; 
    &lt;/ul&gt; &lt;h3&gt;&lt;a href="https://tanstack.com/start"&gt;Read the Start Docs ‚Üí&lt;/a&gt;&lt;/h3&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;br /&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://npmjs.com/package/@tanstack/react-router"&gt; &lt;img src="https://img.shields.io/npm/dm/@tanstack/react-router.svg?sanitize=true" alt="npm downloads" /&gt; &lt;/a&gt; 
 &lt;a href="https://github.com/tanstack/router"&gt; &lt;img src="https://img.shields.io/github/stars/tanstack/router.svg?style=social&amp;amp;label=Star" alt="GitHub stars" /&gt; &lt;/a&gt; 
 &lt;a href="https://bundlephobia.com/result?p=@tanstack/react-router"&gt; &lt;img src="https://badgen.net/bundlephobia/minzip/@tanstack/react-router" alt="Bundle size" /&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://raw.githubusercontent.com/TanStack/router/main/#badge"&gt; &lt;img alt="semantic-release" src="https://img.shields.io/badge/%20%20%F0%9F%93%A6%F0%9F%9A%80-semantic--release-e10079.svg?sanitize=true" /&gt; &lt;/a&gt; 
 &lt;a href="https://bestofjs.org/projects/tanstack-router"&gt;&lt;img alt="Best of JS" src="https://img.shields.io/endpoint?url=https://bestofjs-serverless.now.sh/api/project-badge?fullName=TanStack%2Frouter%26since=daily" /&gt;&lt;/a&gt; 
 &lt;a href="https://twitter.com/tan_stack"&gt;&lt;img src="https://img.shields.io/twitter/follow/tan_stack.svg?style=social" alt="Follow @TanStack" /&gt;&lt;/a&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;h3&gt;&lt;a href="https://github.com/sponsors/tannerlinsley/"&gt;Become a Sponsor!&lt;/a&gt;&lt;/h3&gt; 
&lt;/div&gt; 
&lt;h2&gt;Get Involved&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;We welcome issues and pull requests!&lt;/li&gt; 
 &lt;li&gt;Participate in &lt;a href="https://github.com/TanStack/router/discussions"&gt;GitHub discussions&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Chat with the community on &lt;a href="https://discord.com/invite/WrRKjPJ"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;See &lt;a href="https://raw.githubusercontent.com/TanStack/router/main/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; for setup instructions&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Partners&lt;/h2&gt; 
&lt;table align="center"&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td&gt; &lt;a href="https://www.coderabbit.ai/?via=tanstack&amp;amp;dub_id=aCcEEdAOqqutX6OS"&gt; 
     &lt;picture&gt; 
      &lt;source media="(prefers-color-scheme: dark)" srcset="https://tanstack.com/assets/coderabbit-dark-CMcuvjEy.svg" height="40" /&gt; 
      &lt;source media="(prefers-color-scheme: light)" srcset="https://tanstack.com/assets/coderabbit-light-DVMJ2jHi.svg" height="40" /&gt; 
      &lt;img src="https://tanstack.com/assets/coderabbit-dark-CMcuvjEy.svg?sanitize=true" height="40" alt="CodeRabbit" /&gt; 
     &lt;/picture&gt; &lt;/a&gt; &lt;/td&gt; 
   &lt;td padding="20"&gt; &lt;a href="https://www.cloudflare.com?utm_source=tanstack"&gt; 
     &lt;picture&gt; 
      &lt;source media="(prefers-color-scheme: dark)" srcset="https://tanstack.com/assets/cloudflare-white-DQDB7UaL.svg" height="60" /&gt; 
      &lt;source media="(prefers-color-scheme: light)" srcset="https://tanstack.com/assets/cloudflare-black-CPufaW0B.svg" height="60" /&gt; 
      &lt;img src="https://tanstack.com/assets/cloudflare-black-CPufaW0B.svg?sanitize=true" height="60" alt="Cloudflare" /&gt; 
     &lt;/picture&gt; &lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://netlify.com?utm_source=tanstack"&gt; 
     &lt;picture&gt; 
      &lt;source media="(prefers-color-scheme: dark)" srcset="https://raw.githubusercontent.com/tanstack/tanstack.com/main/src/images/netlify-dark.svg" height="70" /&gt; 
      &lt;source media="(prefers-color-scheme: light)" srcset="https://raw.githubusercontent.com/tannerlinsley/files/master/partners/netlify.svg" height="70" /&gt; 
      &lt;img src="https://raw.githubusercontent.com/tanstack/tanstack.com/main/src/images/netlify-dark.svg?sanitize=true" height="70" alt="Netlify" /&gt; 
     &lt;/picture&gt; &lt;/a&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;a href="https://neon.tech?utm_source=tanstack"&gt; 
     &lt;picture&gt; 
      &lt;source media="(prefers-color-scheme: dark)" srcset="https://raw.githubusercontent.com/tanstack/tanstack.com/main/src/images/neon-dark.svg" height="50" /&gt; 
      &lt;source media="(prefers-color-scheme: light)" srcset="https://raw.githubusercontent.com/tannerlinsley/files/master/partners/neon.svg" height="50" /&gt; 
      &lt;img src="https://raw.githubusercontent.com/tannerlinsley/files/master/partners/neon.svg?sanitize=true" height="50" alt="Neon" /&gt; 
     &lt;/picture&gt; &lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://go.clerk.com/wOwHtuJ"&gt; 
     &lt;picture&gt; 
      &lt;source media="(prefers-color-scheme: dark)" srcset="https://tanstack.com/assets/clerk-logo-dark-CRE22T_2.svg" height="40" /&gt; 
      &lt;source media="(prefers-color-scheme: light)" srcset="https://raw.githubusercontent.com/tannerlinsley/files/master/partners/clerk.svg" height="40" /&gt; 
      &lt;img src="https://tanstack.com/assets/clerk-logo-dark-CRE22T_2.svg?sanitize=true" height="40" alt="Clerk" /&gt; 
     &lt;/picture&gt; &lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://convex.dev?utm_source=tanstack"&gt; 
     &lt;picture&gt; 
      &lt;source media="(prefers-color-scheme: dark)" srcset="https://raw.githubusercontent.com/tanstack/tanstack.com/main/src/images/convex-white.svg" height="30" /&gt; 
      &lt;source media="(prefers-color-scheme: light)" srcset="https://raw.githubusercontent.com/tannerlinsley/files/master/partners/convex.svg" height="30" /&gt; 
      &lt;img src="https://raw.githubusercontent.com/tannerlinsley/files/master/partners/convex.svg?sanitize=true" height="30" alt="Convex" /&gt; 
     &lt;/picture&gt; &lt;/a&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;a href="https://sentry.io?utm_source=tanstack"&gt; 
     &lt;picture&gt; 
      &lt;source media="(prefers-color-scheme: dark)" srcset="https://raw.githubusercontent.com/tanstack/tanstack.com/main/src/images/sentry-wordmark-light.svg" height="50" /&gt; 
      &lt;source media="(prefers-color-scheme: light)" srcset="https://raw.githubusercontent.com/tannerlinsley/files/master/partners/sentry.svg" height="50" /&gt; 
      &lt;img src="https://raw.githubusercontent.com/tannerlinsley/files/master/partners/sentry.svg?sanitize=true" height="50" alt="Sentry" /&gt; 
     &lt;/picture&gt; &lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://www.prisma.io?utm_source=tanstack&amp;amp;via=tanstack"&gt; 
     &lt;picture&gt; 
      &lt;source media="(prefers-color-scheme: dark)" srcset="https://tanstack.com/assets/prisma-dark-DwgDxLwn.svg" height="50" /&gt; 
      &lt;source media="(prefers-color-scheme: light)" srcset="https://tanstack.com/assets/prisma-light-Cloa3Onm.svg" height="50" /&gt; 
      &lt;img src="https://tanstack.com/assets/prisma-dark-DwgDxLwn.svg?sanitize=true" height="50" alt="Prisma" /&gt; 
     &lt;/picture&gt; &lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://strapi.link/tanstack-start"&gt; 
     &lt;picture&gt; 
      &lt;source media="(prefers-color-scheme: dark)" srcset="https://tanstack.com/assets/strapi-dark-CQ84tQTk.svg" height="40" /&gt; 
      &lt;source media="(prefers-color-scheme: light)" srcset="https://tanstack.com/assets/strapi-light-6x7linao.svg" height="40" /&gt; 
      &lt;img src="https://tanstack.com/assets/strapi-dark-CQ84tQTk.svg?sanitize=true" height="40" alt="Strapi" /&gt; 
     &lt;/picture&gt; &lt;/a&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/TanStack/router/main/media/partner_logo.svg?sanitize=true" alt="Router &amp;amp; you?" height="65" /&gt; 
 &lt;p&gt; We're looking for TanStack Router &amp;amp; Start Partners to join our mission! Partner with us to push the boundaries of TanStack Router &amp;amp; Start and build amazing things together. &lt;/p&gt; 
 &lt;a href="mailto:partners@tanstack.com?subject=TanStack Router &amp;amp; Start Partnership"&gt;&lt;b&gt;LET'S CHAT&lt;/b&gt;&lt;/a&gt; 
&lt;/div&gt; 
&lt;h2&gt;Explore the TanStack Ecosystem&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tanstack/config"&gt;&lt;b&gt;TanStack Config&lt;/b&gt;&lt;/a&gt; ‚Äì Tooling for JS/TS packages&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tanstack/db"&gt;&lt;b&gt;TanStack DB&lt;/b&gt;&lt;/a&gt; ‚Äì Reactive sync client store&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tanstack/devtools"&gt;&lt;b&gt;TanStack DevTools&lt;/b&gt;&lt;/a&gt; ‚Äì Unified devtools panel&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tanstack/form"&gt;&lt;b&gt;TanStack Form&lt;/b&gt;&lt;/a&gt; ‚Äì Type‚Äësafe form state&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tanstack/pacer"&gt;&lt;b&gt;TanStack Pacer&lt;/b&gt;&lt;/a&gt; ‚Äì Debouncing, throttling, batching &lt;br /&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tanstack/query"&gt;&lt;b&gt;TanStack Query&lt;/b&gt;&lt;/a&gt; ‚Äì Async state &amp;amp; caching&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tanstack/ranger"&gt;&lt;b&gt;TanStack Ranger&lt;/b&gt;&lt;/a&gt; ‚Äì Range &amp;amp; slider primitives&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tanstack/store"&gt;&lt;b&gt;TanStack Store&lt;/b&gt;&lt;/a&gt; ‚Äì Reactive data store&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tanstack/table"&gt;&lt;b&gt;TanStack Table&lt;/b&gt;&lt;/a&gt; ‚Äì Headless datagrids&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tanstack/virtual"&gt;&lt;b&gt;TanStack Virtual&lt;/b&gt;&lt;/a&gt; ‚Äì Virtualized rendering&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;‚Ä¶ and more at &lt;a href="https://tanstack.com"&gt;&lt;b&gt;TanStack.com ¬ª&lt;/b&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;!-- Use the force, Luke --&gt;</description>
    </item>
    
    <item>
      <title>fmtlib/fmt</title>
      <link>https://github.com/fmtlib/fmt</link>
      <description>&lt;p&gt;A modern formatting library&lt;/p&gt;&lt;hr&gt;&lt;img src="https://user-images.githubusercontent.com/576385/156254208-f5b743a9-88cf-439d-b0c0-923d53e8d551.png" alt="{fmt}" width="25%" /&gt; 
&lt;p&gt;&lt;a href="https://github.com/fmtlib/fmt/actions?query=workflow%3Alinux"&gt;&lt;img src="https://github.com/fmtlib/fmt/workflows/linux/badge.svg?sanitize=true" alt="image" /&gt;&lt;/a&gt; &lt;a href="https://github.com/fmtlib/fmt/actions?query=workflow%3Amacos"&gt;&lt;img src="https://github.com/fmtlib/fmt/workflows/macos/badge.svg?sanitize=true" alt="image" /&gt;&lt;/a&gt; &lt;a href="https://github.com/fmtlib/fmt/actions?query=workflow%3Awindows"&gt;&lt;img src="https://github.com/fmtlib/fmt/workflows/windows/badge.svg?sanitize=true" alt="image" /&gt;&lt;/a&gt; &lt;a href="https://bugs.chromium.org/p/oss-fuzz/issues/list?%0Acolspec=ID%20Type%20Component%20Status%20Proj%20Reported%20Owner%20%0ASummary&amp;amp;q=proj%3Dfmt&amp;amp;can=1"&gt;&lt;img src="https://oss-fuzz-build-logs.storage.googleapis.com/badges/fmt.svg?sanitize=true" alt="fmt is continuously fuzzed at oss-fuzz" /&gt;&lt;/a&gt; &lt;a href="https://www.bestpractices.dev/projects/8880"&gt;&lt;img src="https://www.bestpractices.dev/projects/8880/badge" alt="OpenSSF Best Practices" /&gt;&lt;/a&gt; &lt;a href="https://securityscorecards.dev/viewer/?uri=github.com/fmtlib/fmt"&gt;&lt;img src="https://api.securityscorecards.dev/projects/github.com/fmtlib/fmt/badge" alt="image" /&gt;&lt;/a&gt; &lt;a href="https://stackoverflow.com/questions/tagged/fmt"&gt;&lt;img src="https://img.shields.io/badge/stackoverflow-fmt-blue.svg?sanitize=true" alt="Ask questions at StackOverflow with the tag fmt" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;{fmt}&lt;/strong&gt; is an open-source formatting library providing a fast and safe alternative to C stdio and C++ iostreams.&lt;/p&gt; 
&lt;p&gt;If you like this project, please consider donating to one of the funds that help victims of the war in Ukraine: &lt;a href="https://www.stopputin.net/"&gt;https://www.stopputin.net/&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://fmt.dev"&gt;Documentation&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://hackingcpp.com/cpp/libs/fmt.html"&gt;Cheat Sheets&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Q&amp;amp;A: ask questions on &lt;a href="https://stackoverflow.com/questions/tagged/fmt"&gt;StackOverflow with the tag fmt&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Try {fmt} in &lt;a href="https://godbolt.org/z/8Mx1EW73v"&gt;Compiler Explorer&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;Features&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;Simple &lt;a href="https://fmt.dev/latest/api/"&gt;format API&lt;/a&gt; with positional arguments for localization&lt;/li&gt; 
 &lt;li&gt;Implementation of &lt;a href="https://en.cppreference.com/w/cpp/utility/format"&gt;C++20 std::format&lt;/a&gt; and &lt;a href="https://en.cppreference.com/w/cpp/io/print"&gt;C++23 std::print&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://fmt.dev/latest/syntax/"&gt;Format string syntax&lt;/a&gt; similar to Python's &lt;a href="https://docs.python.org/3/library/stdtypes.html#str.format"&gt;format&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Fast IEEE 754 floating-point formatter with correct rounding, shortness and round-trip guarantees using the &lt;a href="https://github.com/jk-jeon/dragonbox"&gt;Dragonbox&lt;/a&gt; algorithm&lt;/li&gt; 
 &lt;li&gt;Portable Unicode support&lt;/li&gt; 
 &lt;li&gt;Safe &lt;a href="https://fmt.dev/latest/api/#printf-formatting"&gt;printf implementation&lt;/a&gt; including the POSIX extension for positional arguments&lt;/li&gt; 
 &lt;li&gt;Extensibility: &lt;a href="https://fmt.dev/latest/api/#formatting-user-defined-types"&gt;support for user-defined types&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;High performance: faster than common standard library implementations of &lt;code&gt;(s)printf&lt;/code&gt;, iostreams, &lt;code&gt;to_string&lt;/code&gt; and &lt;code&gt;to_chars&lt;/code&gt;, see &lt;a href="https://raw.githubusercontent.com/fmtlib/fmt/master/#speed-tests"&gt;Speed tests&lt;/a&gt; and &lt;a href="http://www.zverovich.net/2020/06/13/fast-int-to-string-revisited.html"&gt;Converting a hundred million integers to strings per second&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Small code size both in terms of source code with the minimum configuration consisting of just three files, &lt;code&gt;base.h&lt;/code&gt;, &lt;code&gt;format.h&lt;/code&gt; and &lt;code&gt;format-inl.h&lt;/code&gt;, and compiled code; see &lt;a href="https://raw.githubusercontent.com/fmtlib/fmt/master/#compile-time-and-code-bloat"&gt;Compile time and code bloat&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Reliability: the library has an extensive set of &lt;a href="https://github.com/fmtlib/fmt/tree/master/test"&gt;tests&lt;/a&gt; and is &lt;a href="https://bugs.chromium.org/p/oss-fuzz/issues/list?colspec=ID%20Type%20Component%20Status%20Proj%20Reported%20Owner%20Summary&amp;amp;q=proj%3Dfmt&amp;amp;can=1"&gt;continuously fuzzed&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Safety: the library is fully type-safe, errors in format strings can be reported at compile time, automatic memory management prevents buffer overflow errors&lt;/li&gt; 
 &lt;li&gt;Ease of use: small self-contained code base, no external dependencies, permissive MIT &lt;a href="https://github.com/fmtlib/fmt/raw/master/LICENSE"&gt;license&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://fmt.dev/latest/#portability"&gt;Portability&lt;/a&gt; with consistent output across platforms and support for older compilers&lt;/li&gt; 
 &lt;li&gt;Clean warning-free codebase even on high warning levels such as &lt;code&gt;-Wall -Wextra -pedantic&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Locale independence by default&lt;/li&gt; 
 &lt;li&gt;Optional header-only configuration enabled with the &lt;code&gt;FMT_HEADER_ONLY&lt;/code&gt; macro&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;See the &lt;a href="https://fmt.dev"&gt;documentation&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;h1&gt;Examples&lt;/h1&gt; 
&lt;p&gt;&lt;strong&gt;Print to stdout&lt;/strong&gt; (&lt;a href="https://godbolt.org/z/Tevcjh"&gt;run&lt;/a&gt;)&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-c++"&gt;#include &amp;lt;fmt/base.h&amp;gt;

int main() {
  fmt::print("Hello, world!\n");
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Format a string&lt;/strong&gt; (&lt;a href="https://godbolt.org/z/oK8h33"&gt;run&lt;/a&gt;)&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-c++"&gt;std::string s = fmt::format("The answer is {}.", 42);
// s == "The answer is 42."
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Format a string using positional arguments&lt;/strong&gt; (&lt;a href="https://godbolt.org/z/Yn7Txe"&gt;run&lt;/a&gt;)&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-c++"&gt;std::string s = fmt::format("I'd rather be {1} than {0}.", "right", "happy");
// s == "I'd rather be happy than right."
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Print dates and times&lt;/strong&gt; (&lt;a href="https://godbolt.org/z/c31ExdY3W"&gt;run&lt;/a&gt;)&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-c++"&gt;#include &amp;lt;fmt/chrono.h&amp;gt;

int main() {
  auto now = std::chrono::system_clock::now();
  fmt::print("Date and time: {}\n", now);
  fmt::print("Time: {:%H:%M}\n", now);
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Output:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Date and time: 2023-12-26 19:10:31.557195597
Time: 19:10
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Print a container&lt;/strong&gt; (&lt;a href="https://godbolt.org/z/MxM1YqjE7"&gt;run&lt;/a&gt;)&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-c++"&gt;#include &amp;lt;vector&amp;gt;
#include &amp;lt;fmt/ranges.h&amp;gt;

int main() {
  std::vector&amp;lt;int&amp;gt; v = {1, 2, 3};
  fmt::print("{}\n", v);
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Output:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;[1, 2, 3]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Check a format string at compile time&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-c++"&gt;std::string s = fmt::format("{:d}", "I am not a number");
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This gives a compile-time error in C++20 because &lt;code&gt;d&lt;/code&gt; is an invalid format specifier for a string.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Write a file from a single thread&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-c++"&gt;#include &amp;lt;fmt/os.h&amp;gt;

int main() {
  auto out = fmt::output_file("guide.txt");
  out.print("Don't {}", "Panic");
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This can be &lt;a href="http://www.zverovich.net/2020/08/04/optimal-file-buffer-size.html"&gt;5 to 9 times faster than fprintf&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Print with colors and text styles&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-c++"&gt;#include &amp;lt;fmt/color.h&amp;gt;

int main() {
  fmt::print(fg(fmt::color::crimson) | fmt::emphasis::bold,
             "Hello, {}!\n", "world");
  fmt::print(fg(fmt::color::floral_white) | bg(fmt::color::slate_gray) |
             fmt::emphasis::underline, "Ol√°, {}!\n", "Mundo");
  fmt::print(fg(fmt::color::steel_blue) | fmt::emphasis::italic,
             "‰Ω†Â•Ω{}ÔºÅ\n", "‰∏ñÁïå");
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Output on a modern terminal with Unicode support:&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/fmtlib/fmt/assets/%0A576385/2a93c904-d6fa-4aa6-b453-2618e1c327d7" alt="image" /&gt;&lt;/p&gt; 
&lt;h1&gt;Benchmarks&lt;/h1&gt; 
&lt;h2&gt;Speed tests&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Library&lt;/th&gt; 
   &lt;th&gt;Method&lt;/th&gt; 
   &lt;th&gt;Run Time, s&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;libc&lt;/td&gt; 
   &lt;td&gt;printf&lt;/td&gt; 
   &lt;td&gt;0.91&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;libc++&lt;/td&gt; 
   &lt;td&gt;std::ostream&lt;/td&gt; 
   &lt;td&gt;2.49&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;{fmt} 9.1&lt;/td&gt; 
   &lt;td&gt;fmt::print&lt;/td&gt; 
   &lt;td&gt;0.74&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Boost Format 1.80&lt;/td&gt; 
   &lt;td&gt;boost::format&lt;/td&gt; 
   &lt;td&gt;6.26&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Folly Format&lt;/td&gt; 
   &lt;td&gt;folly::format&lt;/td&gt; 
   &lt;td&gt;1.87&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;{fmt} is the fastest of the benchmarked methods, ~20% faster than &lt;code&gt;printf&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;The above results were generated by building &lt;code&gt;tinyformat_test.cpp&lt;/code&gt; on macOS 12.6.1 with &lt;code&gt;clang++ -O3 -DNDEBUG -DSPEED_TEST -DHAVE_FORMAT&lt;/code&gt;, and taking the best of three runs. In the test, the format string &lt;code&gt;"%0.10f:%04d:%+g:%s:%p:%c:%%\n"&lt;/code&gt; or equivalent is filled 2,000,000 times with output sent to &lt;code&gt;/dev/null&lt;/code&gt;; for further details refer to the &lt;a href="https://github.com/fmtlib/format-benchmark/raw/master/src/tinyformat-test.cc"&gt;source&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;{fmt} is up to 20-30x faster than &lt;code&gt;std::ostringstream&lt;/code&gt; and &lt;code&gt;sprintf&lt;/code&gt; on IEEE754 &lt;code&gt;float&lt;/code&gt; and &lt;code&gt;double&lt;/code&gt; formatting (&lt;a href="https://github.com/fmtlib/dtoa-benchmark"&gt;dtoa-benchmark&lt;/a&gt;) and faster than &lt;a href="https://github.com/google/double-conversion"&gt;double-conversion&lt;/a&gt; and &lt;a href="https://github.com/ulfjack/ryu"&gt;ryu&lt;/a&gt;:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://fmt.dev/unknown_mac64_clang12.0.html"&gt;&lt;img src="https://user-images.githubusercontent.com/576385/95684665-11719600-0ba8-11eb-8e5b-972ff4e49428.png" alt="image" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Compile time and code bloat&lt;/h2&gt; 
&lt;p&gt;The script &lt;a href="https://github.com/fmtlib/format-benchmark/raw/master/bloat-test.py"&gt;bloat-test.py&lt;/a&gt; from &lt;a href="https://github.com/fmtlib/format-benchmark"&gt;format-benchmark&lt;/a&gt; tests compile time and code bloat for nontrivial projects. It generates 100 translation units and uses &lt;code&gt;printf()&lt;/code&gt; or its alternative five times in each to simulate a medium-sized project. The resulting executable size and compile time (Apple clang version 15.0.0 (clang-1500.1.0.2.5), macOS Sonoma, best of three) is shown in the following tables.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Optimized build (-O3)&lt;/strong&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Method&lt;/th&gt; 
   &lt;th&gt;Compile Time, s&lt;/th&gt; 
   &lt;th&gt;Executable size, KiB&lt;/th&gt; 
   &lt;th&gt;Stripped size, KiB&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;printf&lt;/td&gt; 
   &lt;td&gt;1.6&lt;/td&gt; 
   &lt;td&gt;54&lt;/td&gt; 
   &lt;td&gt;50&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;IOStreams&lt;/td&gt; 
   &lt;td&gt;25.9&lt;/td&gt; 
   &lt;td&gt;98&lt;/td&gt; 
   &lt;td&gt;84&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;fmt 83652df&lt;/td&gt; 
   &lt;td&gt;4.8&lt;/td&gt; 
   &lt;td&gt;54&lt;/td&gt; 
   &lt;td&gt;50&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;tinyformat&lt;/td&gt; 
   &lt;td&gt;29.1&lt;/td&gt; 
   &lt;td&gt;161&lt;/td&gt; 
   &lt;td&gt;136&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Boost Format&lt;/td&gt; 
   &lt;td&gt;55.0&lt;/td&gt; 
   &lt;td&gt;530&lt;/td&gt; 
   &lt;td&gt;317&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;{fmt} is fast to compile and is comparable to &lt;code&gt;printf&lt;/code&gt; in terms of per-call binary size (within a rounding error on this system).&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Non-optimized build&lt;/strong&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Method&lt;/th&gt; 
   &lt;th&gt;Compile Time, s&lt;/th&gt; 
   &lt;th&gt;Executable size, KiB&lt;/th&gt; 
   &lt;th&gt;Stripped size, KiB&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;printf&lt;/td&gt; 
   &lt;td&gt;1.4&lt;/td&gt; 
   &lt;td&gt;54&lt;/td&gt; 
   &lt;td&gt;50&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;IOStreams&lt;/td&gt; 
   &lt;td&gt;23.4&lt;/td&gt; 
   &lt;td&gt;92&lt;/td&gt; 
   &lt;td&gt;68&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;{fmt} 83652df&lt;/td&gt; 
   &lt;td&gt;4.4&lt;/td&gt; 
   &lt;td&gt;89&lt;/td&gt; 
   &lt;td&gt;85&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;tinyformat&lt;/td&gt; 
   &lt;td&gt;24.5&lt;/td&gt; 
   &lt;td&gt;204&lt;/td&gt; 
   &lt;td&gt;161&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Boost Format&lt;/td&gt; 
   &lt;td&gt;36.4&lt;/td&gt; 
   &lt;td&gt;831&lt;/td&gt; 
   &lt;td&gt;462&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;code&gt;libc&lt;/code&gt;, &lt;code&gt;lib(std)c++&lt;/code&gt;, and &lt;code&gt;libfmt&lt;/code&gt; are all linked as shared libraries to compare formatting function overhead only. Boost Format is a header-only library so it doesn't provide any linkage options.&lt;/p&gt; 
&lt;h2&gt;Running the tests&lt;/h2&gt; 
&lt;p&gt;Please refer to &lt;a href="https://fmt.dev/latest/get-started/#building-from-source"&gt;Building the library&lt;/a&gt; for instructions on how to build the library and run the unit tests.&lt;/p&gt; 
&lt;p&gt;Benchmarks reside in a separate repository, &lt;a href="https://github.com/fmtlib/format-benchmark"&gt;format-benchmarks&lt;/a&gt;, so to run the benchmarks you first need to clone this repository and generate Makefiles with CMake:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ git clone --recursive https://github.com/fmtlib/format-benchmark.git
$ cd format-benchmark
$ cmake .
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then you can run the speed test:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ make speed-test
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;or the bloat test:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ make bloat-test
&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;Migrating code&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://clang.llvm.org/extra/clang-tidy/"&gt;clang-tidy&lt;/a&gt; v18 provides the &lt;a href="https://clang.llvm.org/extra/clang-tidy/checks/modernize/use-std-print.html"&gt;modernize-use-std-print&lt;/a&gt; check that is capable of converting occurrences of &lt;code&gt;printf&lt;/code&gt; and &lt;code&gt;fprintf&lt;/code&gt; to &lt;code&gt;fmt::print&lt;/code&gt; if configured to do so. (By default it converts to &lt;code&gt;std::print&lt;/code&gt;.)&lt;/p&gt; 
&lt;h1&gt;Notable projects using this library&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://play0ad.com/"&gt;0 A.D.&lt;/a&gt;: a free, open-source, cross-platform real-time strategy game&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ampl/mp"&gt;AMPL/MP&lt;/a&gt;: an open-source library for mathematical programming&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/apple/foundationdb"&gt;Apple's FoundationDB&lt;/a&gt;: an open-source, distributed, transactional key-value store&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/aseprite/aseprite"&gt;Aseprite&lt;/a&gt;: animated sprite editor &amp;amp; pixel art tool&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.aviobook.aero/en"&gt;AvioBook&lt;/a&gt;: a comprehensive aircraft operations suite&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://battle.net/"&gt;Blizzard Battle.net&lt;/a&gt;: an online gaming platform&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://celestia.space/"&gt;Celestia&lt;/a&gt;: real-time 3D visualization of space&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://ceph.com/"&gt;Ceph&lt;/a&gt;: a scalable distributed storage system&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://ccache.dev/"&gt;ccache&lt;/a&gt;: a compiler cache&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ClickHouse/ClickHouse"&gt;ClickHouse&lt;/a&gt;: an analytical database management system&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.contextvision.com/"&gt;ContextVision&lt;/a&gt;: medical imaging software&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/contour-terminal/contour/"&gt;Contour&lt;/a&gt;: a modern terminal emulator&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://cuauv.org/"&gt;CUAUV&lt;/a&gt;: Cornell University's autonomous underwater vehicle&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://drake.mit.edu/"&gt;Drake&lt;/a&gt;: a planning, control, and analysis toolbox for nonlinear dynamical systems (MIT)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/envoyproxy/envoy"&gt;Envoy&lt;/a&gt;: C++ L7 proxy and communication bus (Lyft)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://fivem.net/"&gt;FiveM&lt;/a&gt;: a modification framework for GTA V&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/MengRao/fmtlog"&gt;fmtlog&lt;/a&gt;: a performant fmtlib-style logging library with latency in nanoseconds&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/facebook/folly"&gt;Folly&lt;/a&gt;: Facebook open-source library&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://gemrb.org/"&gt;GemRB&lt;/a&gt;: a portable open-source implementation of Bioware's Infinity Engine&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://store.steampowered.com/app/1247360/Grand_Mountain_Adventure/"&gt;Grand Mountain Adventure&lt;/a&gt;: a beautiful open-world ski &amp;amp; snowboarding game&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pvpgn/pvpgn-server"&gt;HarpyWar/pvpgn&lt;/a&gt;: Player vs Player Gaming Network with tweaks&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/kbengine/kbengine"&gt;KBEngine&lt;/a&gt;: an open-source MMOG server engine&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://keypirinha.com/"&gt;Keypirinha&lt;/a&gt;: a semantic launcher for Windows&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://kodi.tv/"&gt;Kodi&lt;/a&gt; (formerly xbmc): home theater software&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://kth.cash/"&gt;Knuth&lt;/a&gt;: high-performance Bitcoin full-node&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/contour-terminal/libunicode/"&gt;libunicode&lt;/a&gt;: a modern C++17 Unicode library&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://mariadb.org/"&gt;MariaDB&lt;/a&gt;: relational database management system&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/microsoft/verona"&gt;Microsoft Verona&lt;/a&gt;: research programming language for concurrent ownership&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://mongodb.com/"&gt;MongoDB&lt;/a&gt;: distributed document database&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/duckie/mongo_smasher"&gt;MongoDB Smasher&lt;/a&gt;: a small tool to generate randomized datasets&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://openspaceproject.com/"&gt;OpenSpace&lt;/a&gt;: an open-source astrovisualization framework&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.polserver.com/"&gt;PenUltima Online (POL)&lt;/a&gt;: an MMO server, compatible with most Ultima Online clients&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pytorch/pytorch"&gt;PyTorch&lt;/a&gt;: an open-source machine learning library&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.quasardb.net/"&gt;quasardb&lt;/a&gt;: a distributed, high-performance, associative database&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/odygrd/quill"&gt;Quill&lt;/a&gt;: asynchronous low-latency logging library&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ravijanjam/qkw"&gt;QKW&lt;/a&gt;: generalizing aliasing to simplify navigation, and execute complex multi-line terminal command sequences&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/HunanTV/redis-cerberus"&gt;redis-cerberus&lt;/a&gt;: a Redis cluster proxy&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://vectorized.io/redpanda"&gt;redpanda&lt;/a&gt;: a 10x faster Kafka¬Æ replacement for mission-critical systems written in C++&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://rpclib.net/"&gt;rpclib&lt;/a&gt;: a modern C++ msgpack-RPC server and client library&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.salesforce.com/analytics-cloud/overview/"&gt;Salesforce Analytics Cloud&lt;/a&gt;: business intelligence software&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.scylladb.com/"&gt;Scylla&lt;/a&gt;: a Cassandra-compatible NoSQL data store that can handle 1 million transactions per second on a single server&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://www.seastar-project.org/"&gt;Seastar&lt;/a&gt;: an advanced, open-source C++ framework for high-performance server applications on modern hardware&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/gabime/spdlog"&gt;spdlog&lt;/a&gt;: super fast C++ logging library&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.stellar.org/"&gt;Stellar&lt;/a&gt;: financial platform&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.touchsurgery.com/"&gt;Touch Surgery&lt;/a&gt;: surgery simulator&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/TrinityCore/TrinityCore"&gt;TrinityCore&lt;/a&gt;: open-source MMORPG framework&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://userver.tech/"&gt;üêô userver framework&lt;/a&gt;: open-source asynchronous framework with a rich set of abstractions and database drivers&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/microsoft/terminal"&gt;Windows Terminal&lt;/a&gt;: the new Windows terminal&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://github.com/search?q=fmtlib&amp;amp;type=Code"&gt;More...&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;If you are aware of other projects using this library, please let me know by &lt;a href="mailto:victor.zverovich@gmail.com"&gt;email&lt;/a&gt; or by submitting an &lt;a href="https://github.com/fmtlib/fmt/issues"&gt;issue&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;Motivation&lt;/h1&gt; 
&lt;p&gt;So why yet another formatting library?&lt;/p&gt; 
&lt;p&gt;There are plenty of methods for doing this task, from standard ones like the printf family of function and iostreams to Boost Format and FastFormat libraries. The reason for creating a new library is that every existing solution that I found either had serious issues or didn't provide all the features I needed.&lt;/p&gt; 
&lt;h2&gt;printf&lt;/h2&gt; 
&lt;p&gt;The good thing about &lt;code&gt;printf&lt;/code&gt; is that it is pretty fast and readily available being a part of the C standard library. The main drawback is that it doesn't support user-defined types. &lt;code&gt;printf&lt;/code&gt; also has safety issues although they are somewhat mitigated with &lt;a href="https://gcc.gnu.org/onlinedocs/gcc/Function-Attributes.html"&gt;__attribute__ ((format (printf, ...))&lt;/a&gt; in GCC. There is a POSIX extension that adds positional arguments required for &lt;a href="https://en.wikipedia.org/wiki/Internationalization_and_localization"&gt;i18n&lt;/a&gt; to &lt;code&gt;printf&lt;/code&gt; but it is not a part of C99 and may not be available on some platforms.&lt;/p&gt; 
&lt;h2&gt;iostreams&lt;/h2&gt; 
&lt;p&gt;The main issue with iostreams is best illustrated with an example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-c++"&gt;std::cout &amp;lt;&amp;lt; std::setprecision(2) &amp;lt;&amp;lt; std::fixed &amp;lt;&amp;lt; 1.23456 &amp;lt;&amp;lt; "\n";
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;which is a lot of typing compared to printf:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-c++"&gt;printf("%.2f\n", 1.23456);
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Matthew Wilson, the author of FastFormat, called this "chevron hell". iostreams don't support positional arguments by design.&lt;/p&gt; 
&lt;p&gt;The good part is that iostreams support user-defined types and are safe although error handling is awkward.&lt;/p&gt; 
&lt;h2&gt;Boost Format&lt;/h2&gt; 
&lt;p&gt;This is a very powerful library that supports both &lt;code&gt;printf&lt;/code&gt;-like format strings and positional arguments. Its main drawback is performance. According to various benchmarks, it is much slower than other methods considered here. Boost Format also has excessive build times and severe code bloat issues (see &lt;a href="https://raw.githubusercontent.com/fmtlib/fmt/master/#benchmarks"&gt;Benchmarks&lt;/a&gt;).&lt;/p&gt; 
&lt;h2&gt;FastFormat&lt;/h2&gt; 
&lt;p&gt;This is an interesting library that is fast, safe and has positional arguments. However, it has significant limitations, citing its author:&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Three features that have no hope of being accommodated within the current design are:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Leading zeros (or any other non-space padding)&lt;/li&gt; 
  &lt;li&gt;Octal/hexadecimal encoding&lt;/li&gt; 
  &lt;li&gt;Runtime width/alignment specification&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;It is also quite big and has a heavy dependency, on STLSoft, which might be too restrictive for use in some projects.&lt;/p&gt; 
&lt;h2&gt;Boost Spirit.Karma&lt;/h2&gt; 
&lt;p&gt;This is not a formatting library but I decided to include it here for completeness. As iostreams, it suffers from the problem of mixing verbatim text with arguments. The library is pretty fast, but slower on integer formatting than &lt;code&gt;fmt::format_to&lt;/code&gt; with format string compilation on Karma's own benchmark, see &lt;a href="http://www.zverovich.net/2020/06/13/fast-int-to-string-revisited.html"&gt;Converting a hundred million integers to strings per second&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;License&lt;/h1&gt; 
&lt;p&gt;{fmt} is distributed under the MIT &lt;a href="https://github.com/fmtlib/fmt/raw/master/LICENSE"&gt;license&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;Documentation License&lt;/h1&gt; 
&lt;p&gt;The &lt;a href="https://fmt.dev/latest/syntax/"&gt;Format String Syntax&lt;/a&gt; section in the documentation is based on the one from Python &lt;a href="https://docs.python.org/3/library/string.html#module-string"&gt;string module documentation&lt;/a&gt;. For this reason, the documentation is distributed under the Python Software Foundation license available in &lt;a href="https://raw.github.com/fmtlib/fmt/master/doc/python-license.txt"&gt;doc/python-license.txt&lt;/a&gt;. It only applies if you distribute the documentation of {fmt}.&lt;/p&gt; 
&lt;h1&gt;Maintainers&lt;/h1&gt; 
&lt;p&gt;The {fmt} library is maintained by Victor Zverovich (&lt;a href="https://github.com/vitaut"&gt;vitaut&lt;/a&gt;) with contributions from many other people. See &lt;a href="https://github.com/fmtlib/fmt/graphs/contributors"&gt;Contributors&lt;/a&gt; and &lt;a href="https://github.com/fmtlib/fmt/releases"&gt;Releases&lt;/a&gt; for some of the names. Let us know if your contribution is not listed or mentioned incorrectly and we'll make it right.&lt;/p&gt; 
&lt;h1&gt;Security Policy&lt;/h1&gt; 
&lt;p&gt;To report a security issue, please disclose it at &lt;a href="https://github.com/fmtlib/fmt/security/advisories/new"&gt;security advisory&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;This project is maintained by a team of volunteers on a reasonable-effort basis. As such, please give us at least &lt;em&gt;90&lt;/em&gt; days to work on a fix before public exposure.&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>