<rss version="2.0">
  <channel>
    <title>GitHub All Languages Weekly Trending</title>
    <description>Weekly Trending of All Languages in GitHub</description>
    <pubDate>Tue, 30 Sep 2025 01:41:22 GMT</pubDate>
    <link>http://mshibanami.github.io/GitHubTrendingRSS</link>
    
    <item>
      <title>humanlayer/humanlayer</title>
      <link>https://github.com/humanlayer/humanlayer</link>
      <description>&lt;p&gt;The best way to get AI coding agents to solve hard problems in complex codebases.&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/humanlayer/humanlayer/main/docs/images/wordmark-light.svg?sanitize=true" alt="Wordmark Logo of HumanLayer" /&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;h2&gt;The best way to get Coding Agents to solve hard problems in complex codebases&lt;/h2&gt; 
 &lt;p&gt;&lt;strong&gt;CodeLayer is an open source IDE that lets you orchestrate AI coding agents.&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;It comes with battle-tested workflows that enable AI to solve hard problems in large, complex codebases.&lt;/p&gt; 
 &lt;p&gt;Built on Claude Code. Open source. Scale from your laptop to your entire team.&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://github.com/humanlayer/humanlayer"&gt;&lt;img src="https://img.shields.io/github/stars/humanlayer/humanlayer" alt="GitHub Repo stars" /&gt;&lt;/a&gt; &lt;a href="https://opensource.org/licenses/Apache-2"&gt;&lt;img src="https://img.shields.io/badge/License-Apache-green.svg?sanitize=true" alt="License: Apache-2" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;h3&gt; &lt;p&gt;&lt;a href="https://humanlayer.dev/code"&gt;Join Waitlist&lt;/a&gt; | &lt;a href="https://humanlayer.dev/discord"&gt;Discord&lt;/a&gt;&lt;/p&gt; &lt;/h3&gt; 
 &lt;img referrerpolicy="no-referrer-when-downgrade" src="https://static.scarf.sh/a.png?x-pxid=fcfc0926-d841-47fb-b8a6-6aba3a6c3228" /&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;"Our entire company is using CodeLayer now. We're shipping one banger PR after the other. It is so f-ing good. Unbelievable dude."&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;– René Brandel, Founder @ Casco (YC X25)&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;hr /&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Superhuman for Claude Code&lt;/strong&gt; - Keyboard-first workflows designed for builders who value speed and control.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Advanced Context Engineering&lt;/strong&gt; - Scale AI-first dev to your entire team, without devolving into a chaotic slop-fest.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;M U L T I C L A U D E&lt;/strong&gt; - Run Claude Code sessions in parallel. Worktrees? Done. Remote cloud workers? You got it.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;"This has improved my productivity (and token consumption) by at least 50%. Taking a superhuman style approach just makes soo much sense. Also, its so freaking cool to look back at all the work you've done in a day."&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;– Tyler Brown, Founder @ Revlo.ai&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;hr /&gt; 
&lt;h2&gt;From the team that brought you "Context Engineering"&lt;/h2&gt; 
&lt;p&gt;Leading experts on getting the most out of today's models.&lt;/p&gt; 
&lt;h4&gt;&lt;a href="https://github.com/humanlayer/humanlayer"&gt;Advanced Context Engineering for Coding Agents&lt;/a&gt;&lt;/h4&gt; 
&lt;p&gt;This talk, given at YC on August 20th, 2025 lays out the groundwork for using AI to solve hard problems in complex codebases.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/humanlayer/humanlayer"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://humanlayer.dev/youtube"&gt;YouTube&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;&lt;a href="https://github.com/humanlayer/humanlayer"&gt;12 Factor Agents&lt;/a&gt;&lt;/h4&gt; 
&lt;p&gt;A set of principles for building reliable and scalable LLM applications, inspired by the original 12-Factor App methodology.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/humanlayer/humanlayer"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://humanlayer.dev/youtube"&gt;YouTube&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The original repo that coined the term "context engineering" back in April 2025.&lt;/p&gt; 
&lt;h4&gt;&lt;a href="https://humanlayer.dev/podcast"&gt;🦄 AI That Works&lt;/a&gt;&lt;/h4&gt; 
&lt;p&gt;A weekly conversation about how we can all get the most juice out of todays models with @hellovai &amp;amp; @dexhorthy&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/humanlayer/humanlayer"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://humanlayer.dev/podcast"&gt;Podcast&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;For Teams&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Invest in outcomes, not tools.&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Want to scale AI-first development to your entire org? Get tailored workflows, custom integrations, and cutting-edge advice.&lt;/p&gt; 
&lt;p&gt;HumanLayer's expert engineers will ship in the trenches with you and your team until everyone is a 100x engineer.&lt;/p&gt; 
&lt;p&gt;📧 Shoot us an email at &lt;strong&gt;&lt;a href="mailto:contact@humanlayer.dev"&gt;contact@humanlayer.dev&lt;/a&gt;&lt;/strong&gt;, mention your team size and current AI development stack.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Coming soon - join the waitlist for early access
npx humanlayer join-waitlist --email ...
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Legacy Documentation&lt;/h2&gt; 
&lt;p&gt;Looking for the HumanLayer SDK documentation? See &lt;a href="https://raw.githubusercontent.com/humanlayer/humanlayer/main/humanlayer.md"&gt;humanlayer.md&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;CodeLayer and the HumanLayer SDK are open-source and we welcome contributions in the form of issues, documentation, pull requests, and more. See &lt;a href="https://raw.githubusercontent.com/humanlayer/humanlayer/main/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;The HumanLayer SDK and CodeLayer sources in this repo are licensed under the Apache 2 License.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://star-history.com/#humanlayer/humanlayer&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=humanlayer/humanlayer&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>coinbase/x402</title>
      <link>https://github.com/coinbase/x402</link>
      <description>&lt;p&gt;A payments protocol for the internet. Built on HTTP.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;x402 payments protocol&lt;/h1&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;"1 line of code to accept digital dollars. No fee, 2 second settlement, $0.001 minimum payment."&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;pre&gt;&lt;code class="language-typescript"&gt;app.use(
  // How much you want to charge, and where you want the funds to land
  paymentMiddleware("0xYourAddress", { "/your-endpoint": "$0.01" })
);
// That's it! See examples/typescript/servers/express.ts for a complete example. Instruction below for running on base-sepolia.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Philosophy&lt;/h2&gt; 
&lt;p&gt;Payments on the internet are fundamentally flawed. Credit Cards are high friction, hard to accept, have minimum payments that are far too high, and don't fit into the programmatic nature of the internet. It's time for an open, internet-native form of payments. A payment rail that doesn't have high minimums + % based fee. Payments that are amazing for humans and AI agents.&lt;/p&gt; 
&lt;h2&gt;Principles&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Open standard:&lt;/strong&gt; the x402 protocol will never force reliance on a single party&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;HTTP Native:&lt;/strong&gt; x402 is meant to seamlessly complement the existing HTTP request made by traditional web services, it should not mandate additional requests outside the scope of a typical client / server flow.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Chain and token agnostic:&lt;/strong&gt; we welcome contributions that add support for new chains, signing standards, or schemes, so long as they meet our acceptance criteria laid out in &lt;a href="https://github.com/coinbase/x402/raw/main/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Trust minimizing:&lt;/strong&gt; all payment schemes must not allow for the facilitator or resource server to move funds, other than in accordance with client intentions&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Easy to use:&lt;/strong&gt; x402 needs to be 10x better than existing ways to pay on the internet. This means abstracting as many details of crypto as possible away from the client and resource server, and into the facilitator. This means the client/server should not need to think about gas, rpc, etc.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Ecosystem&lt;/h2&gt; 
&lt;p&gt;The x402 ecosystem is growing! Check out our &lt;a href="https://x402.org/ecosystem"&gt;ecosystem page&lt;/a&gt; to see projects building with x402, including:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Client-side integrations&lt;/li&gt; 
 &lt;li&gt;Services and endpoints&lt;/li&gt; 
 &lt;li&gt;Ecosystem infrastructure and tooling&lt;/li&gt; 
 &lt;li&gt;Learning and community resources&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Want to add your project to the ecosystem? See our &lt;a href="https://github.com/coinbase/x402/tree/main/typescript/site#adding-your-project-to-the-ecosystem"&gt;demo site README&lt;/a&gt; for detailed instructions on how to submit your project.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Roadmap:&lt;/strong&gt; see &lt;a href="https://github.com/coinbase/x402/raw/main/ROADMAP.md"&gt;ROADMAP.md&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Terms:&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;resource&lt;/code&gt;: Something on the internet. This could be a webpage, file server, RPC service, API, any resource on the internet that accepts HTTP / HTTPS requests.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;client&lt;/code&gt;: An entity wanting to pay for a resource.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;facilitator server&lt;/code&gt;: A server that facilitates verification and execution of on-chain payments.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;resource server&lt;/code&gt;: An HTTP server that provides an API or other resource for a client.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Technical Goals:&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Permissionless and secure for clients and servers&lt;/li&gt; 
 &lt;li&gt;Gasless for client and resource servers&lt;/li&gt; 
 &lt;li&gt;Minimal integration for the resource server and client (1 line for the server, 1 function for the client)&lt;/li&gt; 
 &lt;li&gt;Ability to trade off speed of response for guarantee of payment&lt;/li&gt; 
 &lt;li&gt;Extensible to different payment flows and chains&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;V1 Protocol&lt;/h2&gt; 
&lt;p&gt;The &lt;code&gt;x402&lt;/code&gt; protocol is a chain agnostic standard for payments on top of HTTP, leverage the existing &lt;code&gt;402 Payment Required&lt;/code&gt; HTTP status code to indicate that a payment is required for access to the resource.&lt;/p&gt; 
&lt;p&gt;It specifies:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;A schema for how servers can respond to clients to facilitate payment for a resource (&lt;code&gt;PaymentRequirements&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;A standard header &lt;code&gt;X-PAYMENT&lt;/code&gt; that is set by clients paying for resources&lt;/li&gt; 
 &lt;li&gt;A standard schema and encoding method for data in the &lt;code&gt;X-PAYMENT&lt;/code&gt; header&lt;/li&gt; 
 &lt;li&gt;A recommended flow for how payments should be verified and settled by a resource server&lt;/li&gt; 
 &lt;li&gt;A REST specification for how a resource server can perform verification and settlement against a remote 3rd party server (&lt;code&gt;facilitator&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;A specification for a &lt;code&gt;X-PAYMENT-RESPONSE&lt;/code&gt; header that can be used by resource servers to communicate blockchain transactions details to the client in their HTTP response&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;V1 Protocol Sequencing&lt;/h3&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/coinbase/x402/main/static/x402-protocol-flow.png" alt="" /&gt;&lt;/p&gt; 
&lt;p&gt;The following outlines the flow of a payment using the &lt;code&gt;x402&lt;/code&gt; protocol. Note that steps (1) and (2) are optional if the client already knows the payment details accepted for a resource.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;Client&lt;/code&gt; makes an HTTP request to a &lt;code&gt;resource server&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;Resource server&lt;/code&gt; responds with a &lt;code&gt;402 Payment Required&lt;/code&gt; status and a &lt;code&gt;Payment Required Response&lt;/code&gt; JSON object in the response body.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;Client&lt;/code&gt; selects one of the &lt;code&gt;paymentRequirements&lt;/code&gt; returned by the server response and creates a &lt;code&gt;Payment Payload&lt;/code&gt; based on the &lt;code&gt;scheme&lt;/code&gt; of the &lt;code&gt;paymentRequirements&lt;/code&gt; they have selected.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;Client&lt;/code&gt; sends the HTTP request with the &lt;code&gt;X-PAYMENT&lt;/code&gt; header containing the &lt;code&gt;Payment Payload&lt;/code&gt; to the resource server.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;Resource server&lt;/code&gt; verifies the &lt;code&gt;Payment Payload&lt;/code&gt; is valid either via local verification or by POSTing the &lt;code&gt;Payment Payload&lt;/code&gt; and &lt;code&gt;Payment Requirements&lt;/code&gt; to the &lt;code&gt;/verify&lt;/code&gt; endpoint of a &lt;code&gt;facilitator server&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;Facilitator server&lt;/code&gt; performs verification of the object based on the &lt;code&gt;scheme&lt;/code&gt; and &lt;code&gt;network&lt;/code&gt; of the &lt;code&gt;Payment Payload&lt;/code&gt; and returns a &lt;code&gt;Verification Response&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;If the &lt;code&gt;Verification Response&lt;/code&gt; is valid, the resource server performs the work to fulfill the request. If the &lt;code&gt;Verification Response&lt;/code&gt; is invalid, the resource server returns a &lt;code&gt;402 Payment Required&lt;/code&gt; status and a &lt;code&gt;Payment Required Response&lt;/code&gt; JSON object in the response body.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;Resource server&lt;/code&gt; either settles the payment by interacting with a blockchain directly, or by POSTing the &lt;code&gt;Payment Payload&lt;/code&gt; and &lt;code&gt;Payment PaymentRequirements&lt;/code&gt; to the &lt;code&gt;/settle&lt;/code&gt; endpoint of a &lt;code&gt;facilitator server&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;Facilitator server&lt;/code&gt; submits the payment to the blockchain based on the &lt;code&gt;scheme&lt;/code&gt; and &lt;code&gt;network&lt;/code&gt; of the &lt;code&gt;Payment Payload&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;Facilitator server&lt;/code&gt; waits for the payment to be confirmed on the blockchain.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;Facilitator server&lt;/code&gt; returns a &lt;code&gt;Payment Execution Response&lt;/code&gt; to the resource server.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;Resource server&lt;/code&gt; returns a &lt;code&gt;200 OK&lt;/code&gt; response to the &lt;code&gt;Client&lt;/code&gt; with the resource they requested as the body of the HTTP response, and a &lt;code&gt;X-PAYMENT-RESPONSE&lt;/code&gt; header containing the &lt;code&gt;Settlement Response&lt;/code&gt; as Base64 encoded JSON if the payment was executed successfully.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Type Specifications&lt;/h3&gt; 
&lt;h4&gt;Data types&lt;/h4&gt; 
&lt;p&gt;&lt;strong&gt;Payment Required Response&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json5"&gt;{
  // Version of the x402 payment protocol
  x402Version: int,

  // List of payment requirements that the resource server accepts. A resource server may accept on multiple chains, or in multiple currencies.
  accepts: [paymentRequirements]

  // Message from the resource server to the client to communicate errors in processing payment
  error: string
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;paymentRequirements&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json5"&gt;{
  // Scheme of the payment protocol to use
  scheme: string;

  // Network of the blockchain to send payment on
  network: string;

  // Maximum amount required to pay for the resource in atomic units of the asset
  maxAmountRequired: uint256 as string;

  // URL of resource to pay for
  resource: string;

  // Description of the resource
  description: string;

  // MIME type of the resource response
  mimeType: string;

  // Output schema of the resource response
  outputSchema?: object | null;

  // Address to pay value to
  payTo: string;

  // Maximum time in seconds for the resource server to respond
  maxTimeoutSeconds: number;

  // Address of the EIP-3009 compliant ERC20 contract
  asset: string;

  // Extra information about the payment details specific to the scheme
  // For `exact` scheme on a EVM network, expects extra to contain the records `name` and `version` pertaining to asset
  extra: object | null;
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;&lt;code&gt;Payment Payload&lt;/code&gt;&lt;/strong&gt; (included as the &lt;code&gt;X-PAYMENT&lt;/code&gt; header in base64 encoded json)&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json5"&gt;{
  // Version of the x402 payment protocol
  x402Version: number;

  // scheme is the scheme value of the accepted `paymentRequirements` the client is using to pay
  scheme: string;

  // network is the network id of the accepted `paymentRequirements` the client is using to pay
  network: string;

  // payload is scheme dependent
  payload: &amp;lt;scheme dependent&amp;gt;;
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Facilitator Types &amp;amp; Interface&lt;/h4&gt; 
&lt;p&gt;A &lt;code&gt;facilitator server&lt;/code&gt; is a 3rd party service that can be used by a &lt;code&gt;resource server&lt;/code&gt; to verify and settle payments, without the &lt;code&gt;resource server&lt;/code&gt; needing to have access to a blockchain node or wallet.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;POST /verify&lt;/strong&gt;. Verify a payment with a supported scheme and network:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Request body JSON: &lt;pre&gt;&lt;code class="language-json5"&gt;{
  x402Version: number;
  paymentHeader: string;
  paymentRequirements: paymentRequirements;
}
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;Response: &lt;pre&gt;&lt;code class="language-json5"&gt;{
  isValid: boolean;
  invalidReason: string | null;
}
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;POST /settle&lt;/strong&gt;. Settle a payment with a supported scheme and network:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Request body JSON:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-json5"&gt;{
  x402Version: number;
  paymentHeader: string;
  paymentRequirements: paymentRequirements;
}
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Response:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-json5"&gt;{
  // Whether the payment was successful
  success: boolean;

  // Error message from the facilitator server
  error: string | null;

  // Transaction hash of the settled payment
  txHash: string | null;

  // Network id of the blockchain the payment was settled on
  networkId: string | null;
}
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;GET /supported&lt;/strong&gt;. Get supported payment schemes and networks:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Response: &lt;pre&gt;&lt;code class="language-json5"&gt;{
  kinds: [
    {
      "scheme": string,
      "network": string,
    }
  ]
}
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Schemes&lt;/h3&gt; 
&lt;p&gt;A scheme is a logical way of moving money.&lt;/p&gt; 
&lt;p&gt;Blockchains allow for a large number of flexible ways to move money. To help facilitate an expanding number of payment use cases, the &lt;code&gt;x402&lt;/code&gt; protocol is extensible to different ways of settling payments via its &lt;code&gt;scheme&lt;/code&gt; field.&lt;/p&gt; 
&lt;p&gt;Each payment scheme may have different operational functionality depending on what actions are necessary to fulfill the payment. For example &lt;code&gt;exact&lt;/code&gt;, the first scheme shipping as part of the protocol, would have different behavior than &lt;code&gt;upto&lt;/code&gt;. &lt;code&gt;exact&lt;/code&gt; transfers a specific amount (ex: pay $1 to read an article), while a theoretical &lt;code&gt;upto&lt;/code&gt; would transfer up to an amount, based on the resources consumed during a request (ex: generating tokens from an LLM).&lt;/p&gt; 
&lt;p&gt;See &lt;code&gt;specs/schemes&lt;/code&gt; for more details on schemes, and see &lt;code&gt;specs/schemes/exact/scheme_exact_evm.md&lt;/code&gt; to see the first proposed scheme for exact payment on EVM chains.&lt;/p&gt; 
&lt;h3&gt;Schemes vs Networks&lt;/h3&gt; 
&lt;p&gt;Because a scheme is a logical way of moving money, the way a scheme is implemented can be different for different blockchains. (ex: the way you need to implement &lt;code&gt;exact&lt;/code&gt; on Ethereum is very different from the way you need to implement &lt;code&gt;exact&lt;/code&gt; on Solana).&lt;/p&gt; 
&lt;p&gt;Clients and facilitators must explicitly support different &lt;code&gt;(scheme, network)&lt;/code&gt; pairs in order to be able to create proper payloads and verify / settle payments.&lt;/p&gt; 
&lt;h2&gt;Running example&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Requirements:&lt;/strong&gt; Node.js v24 or higher&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;From &lt;code&gt;examples/typescript&lt;/code&gt; run &lt;code&gt;pnpm install&lt;/code&gt; and &lt;code&gt;pnpm build&lt;/code&gt; to ensure all dependent packages and examples are setup.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Select a server, i.e. express, and &lt;code&gt;cd&lt;/code&gt; into that example. Add your server's ethereum address to get paid to into the &lt;code&gt;.env&lt;/code&gt; file, and then run &lt;code&gt;pnpm dev&lt;/code&gt; in that directory.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Select a client, i.e. axios, and &lt;code&gt;cd&lt;/code&gt; into that example. Add your private key for the account making payments into the &lt;code&gt;.env&lt;/code&gt; file, and then run &lt;code&gt;pnpm dev&lt;/code&gt; in that directory.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;You should see activities in the client terminal, which will display a weather report.&lt;/p&gt; 
&lt;h2&gt;Running tests&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;Navigate to the typescript directory: &lt;code&gt;cd typescript&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Install dependencies: &lt;code&gt;pnpm install&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Run the unit tests: &lt;code&gt;pnpm test&lt;/code&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;This will run the unit tests for the x402 packages.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>kamranahmedse/developer-roadmap</title>
      <link>https://github.com/kamranahmedse/developer-roadmap</link>
      <description>&lt;p&gt;Interactive roadmaps, guides and other educational content to help developers grow in their careers.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;a href="https://roadmap.sh/"&gt;&lt;img src="https://raw.githubusercontent.com/kamranahmedse/developer-roadmap/master/public/img/brand.png" height="128" /&gt;&lt;/a&gt; &lt;/p&gt;
&lt;h2 align="center"&gt;&lt;a href="https://roadmap.sh"&gt;roadmap.sh&lt;/a&gt;&lt;/h2&gt; 
&lt;p align="center"&gt;Community driven roadmaps, articles and resources for developers&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p align="center"&gt; &lt;a href="https://roadmap.sh/roadmaps"&gt; &lt;img src="https://img.shields.io/badge/%E2%9C%A8-Roadmaps%20-0a0a0a.svg?style=flat&amp;amp;colorA=0a0a0a" alt="roadmaps" /&gt; &lt;/a&gt; &lt;a href="https://roadmap.sh/best-practices"&gt; &lt;img src="https://img.shields.io/badge/%E2%9C%A8-Best%20Practices-0a0a0a.svg?style=flat&amp;amp;colorA=0a0a0a" alt="best practices" /&gt; &lt;/a&gt; &lt;a href="https://roadmap.sh/questions"&gt; &lt;img src="https://img.shields.io/badge/%E2%9C%A8-Questions-0a0a0a.svg?style=flat&amp;amp;colorA=0a0a0a" alt="videos" /&gt; &lt;/a&gt; &lt;a href="https://www.youtube.com/channel/UCA0H2KIWgWTwpTFjSxp0now?sub_confirmation=1"&gt; &lt;img src="https://img.shields.io/badge/%E2%9C%A8-YouTube%20Channel-0a0a0a.svg?style=flat&amp;amp;colorA=0a0a0a" alt="roadmaps" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;br /&gt; 
&lt;p&gt;&lt;img src="https://i.imgur.com/waxVImv.png" alt="" /&gt;&lt;/p&gt; 
&lt;p&gt;Roadmaps are now interactive, you can click the nodes to read more about the topics.&lt;/p&gt; 
&lt;h3&gt;&lt;a href="https://roadmap.sh"&gt;View all Roadmaps&lt;/a&gt; &amp;nbsp;·&amp;nbsp; &lt;a href="https://roadmap.sh/best-practices"&gt;Best Practices&lt;/a&gt; &amp;nbsp;·&amp;nbsp; &lt;a href="https://roadmap.sh/questions"&gt;Questions&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;img src="https://i.imgur.com/waxVImv.png" alt="" /&gt;&lt;/p&gt; 
&lt;p&gt;Here is the list of available roadmaps with more being actively worked upon.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Have a look at the &lt;a href="https://roadmap.sh/get-started"&gt;get started&lt;/a&gt; page that might help you pick up a path.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/frontend"&gt;Frontend Roadmap&lt;/a&gt; / &lt;a href="https://roadmap.sh/frontend?r=frontend-beginner"&gt;Frontend Beginner Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/backend"&gt;Backend Roadmap&lt;/a&gt; / &lt;a href="https://roadmap.sh/backend?r=backend-beginner"&gt;Backend Beginner Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/devops"&gt;DevOps Roadmap&lt;/a&gt; / &lt;a href="https://roadmap.sh/devops?r=devops-beginner"&gt;DevOps Beginner Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/full-stack"&gt;Full Stack Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/html"&gt;HTML Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/css"&gt;CSS Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/javascript"&gt;JavaScript Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/typescript"&gt;TypeScript Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/git-github"&gt;Git and GitHub&lt;/a&gt; / &lt;a href="https://roadmap.sh/git-github?r=git-github-beginner"&gt;Git and GitHub Beginner&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/api-design"&gt;API Design Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/computer-science"&gt;Computer Science Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/datastructures-and-algorithms"&gt;Data Structures and Algorithms Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/ai-data-scientist"&gt;AI and Data Scientist Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/ai-engineer"&gt;AI Engineer Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/aws"&gt;AWS Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/cloudflare"&gt;Cloudflare Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/linux"&gt;Linux Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/terraform"&gt;Terraform Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/data-analyst"&gt;Data Analyst Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/bi-analyst"&gt;BI Analyst Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/data-engineer"&gt;Data Engineer Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/machine-learning"&gt;Machine Learning Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/mlops"&gt;MLOps Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/product-manager"&gt;Product Manager Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/engineering-manager"&gt;Engineering Manager Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/qa"&gt;QA Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/python"&gt;Python Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/software-architect"&gt;Software Architect Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/game-developer"&gt;Game Developer Roadmap&lt;/a&gt; / &lt;a href="https://roadmap.sh/server-side-game-developer"&gt;Server Side Game Developer&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/software-design-architecture"&gt;Software Design and Architecture Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/cpp"&gt;C++ Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/react"&gt;React Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/nextjs"&gt;Next.js Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/react-native"&gt;React Native Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/vue"&gt;Vue Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/angular"&gt;Angular Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/nodejs"&gt;Node.js Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/php"&gt;PHP Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/graphql"&gt;GraphQL Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/android"&gt;Android Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/ios"&gt;iOS Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/flutter"&gt;Flutter Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/golang"&gt;Go Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/rust"&gt;Rust Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/java"&gt;Java Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/kotlin"&gt;Kotlin Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/spring-boot"&gt;Spring Boot Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/design-system"&gt;Design System Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/postgresql-dba"&gt;PostgreSQL Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/sql"&gt;SQL Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/redis"&gt;Redis Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/blockchain"&gt;Blockchain Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/aspnet-core"&gt;ASP.NET Core Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/system-design"&gt;System Design Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/kubernetes"&gt;Kubernetes Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/cyber-security"&gt;Cyber Security Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/mongodb"&gt;MongoDB Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/ux-design"&gt;UX Design Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/docker"&gt;Docker Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/prompt-engineering"&gt;Prompt Engineering Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/technical-writer"&gt;Technical Writer Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/devrel"&gt;DevRel Engineer Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/ai-red-teaming"&gt;AI Red Teaming Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/ai-agents"&gt;AI Agents Roadmap&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;There are also interactive best practices:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/best-practices/backend-performance"&gt;Backend Performance Best Practices&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/best-practices/frontend-performance"&gt;Frontend Performance Best Practices&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/best-practices/code-review"&gt;Code Review Best Practices&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/best-practices/api-security"&gt;API Security Best Practices&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/best-practices/aws"&gt;AWS Best Practices&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;..and questions to help you test, rate and improve your knowledge&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/questions/javascript"&gt;JavaScript Questions&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/questions/nodejs"&gt;Node.js Questions&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/questions/react"&gt;React Questions&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/questions/backend"&gt;Backend Questions&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://roadmap.sh/questions/frontend"&gt;Frontend Questions&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://i.imgur.com/waxVImv.png" alt="" /&gt;&lt;/p&gt; 
&lt;h2&gt;Share with the community&lt;/h2&gt; 
&lt;p&gt;Please consider sharing a post about &lt;a href="https://roadmap.sh"&gt;roadmap.sh&lt;/a&gt; and the value it provides. It really does help!&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://reddit.com/submit?url=https://roadmap.sh&amp;amp;title=Interactive%20roadmaps,%20guides%20and%20other%20educational%20content%20for%20Developers"&gt;&lt;img src="https://img.shields.io/badge/share%20on-reddit-red?logo=reddit" alt="GitHub Repo stars" /&gt;&lt;/a&gt; &lt;a href="https://news.ycombinator.com/submitlink?u=https://roadmap.sh"&gt;&lt;img src="https://img.shields.io/badge/share%20on-hacker%20news-orange?logo=ycombinator" alt="GitHub Repo stars" /&gt;&lt;/a&gt; &lt;a href="https://twitter.com/share?url=https://roadmap.sh&amp;amp;text=Interactive%20roadmaps,%20guides%20and%20other%20educational%20content%20for%20Developers"&gt;&lt;img src="https://img.shields.io/badge/share%20on-twitter-03A9F4?logo=twitter" alt="GitHub Repo stars" /&gt;&lt;/a&gt; &lt;a href="https://www.facebook.com/sharer/sharer.php?u=https://roadmap.sh"&gt;&lt;img src="https://img.shields.io/badge/share%20on-facebook-1976D2?logo=facebook" alt="GitHub Repo stars" /&gt;&lt;/a&gt; &lt;a href="https://www.linkedin.com/shareArticle?url=https://roadmap.sh&amp;amp;title=Interactive%20roadmaps,%20guides%20and%20other%20educational%20content%20for%20Developers"&gt;&lt;img src="https://img.shields.io/badge/share%20on-linkedin-3949AB?logo=linkedin" alt="GitHub Repo stars" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Development&lt;/h2&gt; 
&lt;p&gt;Clone the repository, install the dependencies and start the application&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone git@github.com:kamranahmedse/developer-roadmap.git
cd developer-roadmap
npm install
npm run dev
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Note: use the &lt;code&gt;depth&lt;/code&gt; parameter to reduce the clone size and speed up the clone.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;git clone --depth=1 https://github.com/kamranahmedse/developer-roadmap.git
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Contribution&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Have a look at &lt;a href="https://raw.githubusercontent.com/kamranahmedse/developer-roadmap/master/contributing.md"&gt;contribution docs&lt;/a&gt; for how to update any of the roadmaps&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;Add content to roadmaps&lt;/li&gt; 
 &lt;li&gt;Add new roadmaps&lt;/li&gt; 
 &lt;li&gt;Suggest changes to existing roadmaps&lt;/li&gt; 
 &lt;li&gt;Discuss ideas in issues&lt;/li&gt; 
 &lt;li&gt;Spread the word&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Thanks to all contributors ❤&lt;/h2&gt; 
&lt;a href="https://github.com/kamranahmedse/developer-roadmap/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=kamranahmedse/developer-roadmap" /&gt; &lt;/a&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Have a look at the &lt;a href="https://raw.githubusercontent.com/kamranahmedse/developer-roadmap/master/license"&gt;license file&lt;/a&gt; for details&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>gin-gonic/gin</title>
      <link>https://github.com/gin-gonic/gin</link>
      <description>&lt;p&gt;Gin is a high-performance HTTP web framework written in Go. It provides a Martini-like API but with significantly better performance—up to 40 times faster—thanks to httprouter. Gin is designed for building REST APIs, web applications, and microservices.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Gin Web Framework&lt;/h1&gt; 
&lt;img align="right" width="159px" src="https://raw.githubusercontent.com/gin-gonic/logo/master/color.png" /&gt; 
&lt;p&gt;&lt;a href="https://github.com/gin-gonic/gin/actions/workflows/gin.yml"&gt;&lt;img src="https://github.com/gin-gonic/gin/actions/workflows/gin.yml/badge.svg?branch=master" alt="Build Status" /&gt;&lt;/a&gt; &lt;a href="https://codecov.io/gh/gin-gonic/gin"&gt;&lt;img src="https://codecov.io/gh/gin-gonic/gin/branch/master/graph/badge.svg?sanitize=true" alt="codecov" /&gt;&lt;/a&gt; &lt;a href="https://goreportcard.com/report/github.com/gin-gonic/gin"&gt;&lt;img src="https://goreportcard.com/badge/github.com/gin-gonic/gin" alt="Go Report Card" /&gt;&lt;/a&gt; &lt;a href="https://pkg.go.dev/github.com/gin-gonic/gin?tab=doc"&gt;&lt;img src="https://pkg.go.dev/badge/github.com/gin-gonic/gin?status.svg?sanitize=true" alt="Go Reference" /&gt;&lt;/a&gt; &lt;a href="https://sourcegraph.com/github.com/gin-gonic/gin?badge"&gt;&lt;img src="https://sourcegraph.com/github.com/gin-gonic/gin/-/badge.svg?sanitize=true" alt="Sourcegraph" /&gt;&lt;/a&gt; &lt;a href="https://www.codetriage.com/gin-gonic/gin"&gt;&lt;img src="https://www.codetriage.com/gin-gonic/gin/badges/users.svg?sanitize=true" alt="Open Source Helpers" /&gt;&lt;/a&gt; &lt;a href="https://github.com/gin-gonic/gin/releases"&gt;&lt;img src="https://img.shields.io/github/release/gin-gonic/gin.svg?style=flat-square" alt="Release" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;📰 &lt;a href="https://gin-gonic.com/en/blog/news/gin-1-11-0-release-announcement/"&gt;Announcing Gin 1.11.0!&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Read about the latest features and improvements in Gin 1.11.0 on our official blog.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;Gin is a high-performance HTTP web framework written in &lt;a href="https://go.dev/"&gt;Go&lt;/a&gt;. It provides a Martini-like API but with significantly better performance—up to 40 times faster—thanks to &lt;a href="https://github.com/julienschmidt/httprouter"&gt;httprouter&lt;/a&gt;. Gin is designed for building REST APIs, web applications, and microservices where speed and developer productivity are essential.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Why choose Gin?&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Gin combines the simplicity of Express.js-style routing with Go's performance characteristics, making it ideal for:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Building high-throughput REST APIs&lt;/li&gt; 
 &lt;li&gt;Developing microservices that need to handle many concurrent requests&lt;/li&gt; 
 &lt;li&gt;Creating web applications that require fast response times&lt;/li&gt; 
 &lt;li&gt;Prototyping web services quickly with minimal boilerplate&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Gin's key features:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Zero allocation router&lt;/strong&gt; - Extremely memory-efficient routing with no heap allocations&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;High performance&lt;/strong&gt; - Benchmarks show superior speed compared to other Go web frameworks&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Middleware support&lt;/strong&gt; - Extensible middleware system for authentication, logging, CORS, etc.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Crash-free&lt;/strong&gt; - Built-in recovery middleware prevents panics from crashing your server&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;JSON validation&lt;/strong&gt; - Automatic request/response JSON binding and validation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Route grouping&lt;/strong&gt; - Organize related routes and apply common middleware&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Error management&lt;/strong&gt; - Centralized error handling and logging&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Built-in rendering&lt;/strong&gt; - Support for JSON, XML, HTML templates, and more&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Extensible&lt;/strong&gt; - Large ecosystem of community middleware and plugins&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;h3&gt;Prerequisites&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Go version&lt;/strong&gt;: Gin requires &lt;a href="https://go.dev/"&gt;Go&lt;/a&gt; version &lt;a href="https://go.dev/doc/devel/release#go1.23.0"&gt;1.23&lt;/a&gt; or above&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Basic Go knowledge&lt;/strong&gt;: Familiarity with Go syntax and package management is helpful&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Installation&lt;/h3&gt; 
&lt;p&gt;With &lt;a href="https://go.dev/wiki/Modules#how-to-use-modules"&gt;Go's module support&lt;/a&gt;, simply import Gin in your code and Go will automatically fetch it during build:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;import "github.com/gin-gonic/gin"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Your First Gin Application&lt;/h3&gt; 
&lt;p&gt;Here's a complete example that demonstrates Gin's simplicity:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;package main

import (
  "net/http"

  "github.com/gin-gonic/gin"
)

func main() {
  // Create a Gin router with default middleware (logger and recovery)
  r := gin.Default()
  
  // Define a simple GET endpoint
  r.GET("/ping", func(c *gin.Context) {
    // Return JSON response
    c.JSON(http.StatusOK, gin.H{
      "message": "pong",
    })
  })
  
  // Start server on port 8080 (default)
  // Server will listen on 0.0.0.0:8080 (localhost:8080 on Windows)
  r.Run()
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Running the application:&lt;/strong&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Save the code above as &lt;code&gt;main.go&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Run the application:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-sh"&gt;go run main.go
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Open your browser and visit &lt;a href="http://localhost:8080/ping"&gt;&lt;code&gt;http://localhost:8080/ping&lt;/code&gt;&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;You should see: &lt;code&gt;{"message":"pong"}&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;What this example demonstrates:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Creating a Gin router with default middleware&lt;/li&gt; 
 &lt;li&gt;Defining HTTP endpoints with simple handler functions&lt;/li&gt; 
 &lt;li&gt;Returning JSON responses&lt;/li&gt; 
 &lt;li&gt;Starting an HTTP server&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Next Steps&lt;/h3&gt; 
&lt;p&gt;After running your first Gin application, explore these resources to learn more:&lt;/p&gt; 
&lt;h4&gt;📚 Learning Resources&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/gin-gonic/gin/master/docs/doc.md"&gt;Gin Quick Start Guide&lt;/a&gt;&lt;/strong&gt; - Comprehensive tutorial with API examples and build configurations&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/gin-gonic/examples"&gt;Example Repository&lt;/a&gt;&lt;/strong&gt; - Ready-to-run examples demonstrating various Gin use cases: 
  &lt;ul&gt; 
   &lt;li&gt;REST API development&lt;/li&gt; 
   &lt;li&gt;Authentication &amp;amp; middleware&lt;/li&gt; 
   &lt;li&gt;File uploads and downloads&lt;/li&gt; 
   &lt;li&gt;WebSocket connections&lt;/li&gt; 
   &lt;li&gt;Template rendering&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;📖 Documentation&lt;/h2&gt; 
&lt;h3&gt;API Reference&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://pkg.go.dev/github.com/gin-gonic/gin"&gt;Go.dev API Documentation&lt;/a&gt;&lt;/strong&gt; - Complete API reference with examples&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;User Guides&lt;/h3&gt; 
&lt;p&gt;The comprehensive documentation is available on &lt;a href="https://gin-gonic.com"&gt;gin-gonic.com&lt;/a&gt; in multiple languages:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://gin-gonic.com/en/docs/"&gt;English&lt;/a&gt; | &lt;a href="https://gin-gonic.com/zh-cn/docs/"&gt;简体中文&lt;/a&gt; | &lt;a href="https://gin-gonic.com/zh-tw/docs/"&gt;繁體中文&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://gin-gonic.com/ja/docs/"&gt;日本語&lt;/a&gt; | &lt;a href="https://gin-gonic.com/ko-kr/docs/"&gt;한국어&lt;/a&gt; | &lt;a href="https://gin-gonic.com/es/docs/"&gt;Español&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://gin-gonic.com/tr/docs/"&gt;Turkish&lt;/a&gt; | &lt;a href="https://gin-gonic.com/fa/docs/"&gt;Persian&lt;/a&gt; | &lt;a href="https://gin-gonic.com/pt/docs/"&gt;Português&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://gin-gonic.com/ru/docs/"&gt;Russian&lt;/a&gt; | &lt;a href="https://gin-gonic.com/id/docs/"&gt;Indonesian&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Official Tutorials&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://go.dev/doc/tutorial/web-service-gin"&gt;Go.dev Tutorial: Developing a RESTful API with Go and Gin&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;⚡ Performance Benchmarks&lt;/h2&gt; 
&lt;p&gt;Gin demonstrates exceptional performance compared to other Go web frameworks. It uses a custom version of &lt;a href="https://github.com/julienschmidt/httprouter"&gt;HttpRouter&lt;/a&gt; for maximum efficiency. &lt;a href="https://raw.githubusercontent.com/gin-gonic/gin/master/BENCHMARKS.md"&gt;View detailed benchmarks →&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Gin vs. Other Go Frameworks&lt;/strong&gt; (GitHub API routing benchmark):&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Benchmark name&lt;/th&gt; 
   &lt;th align="right"&gt;(1)&lt;/th&gt; 
   &lt;th align="right"&gt;(2)&lt;/th&gt; 
   &lt;th align="right"&gt;(3)&lt;/th&gt; 
   &lt;th align="right"&gt;(4)&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkGin_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;&lt;strong&gt;43550&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;&lt;strong&gt;27364 ns/op&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;&lt;strong&gt;0 B/op&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;&lt;strong&gt;0 allocs/op&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkAce_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;40543&lt;/td&gt; 
   &lt;td align="right"&gt;29670 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;0 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;0 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkAero_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;57632&lt;/td&gt; 
   &lt;td align="right"&gt;20648 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;0 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;0 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkBear_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;9234&lt;/td&gt; 
   &lt;td align="right"&gt;216179 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;86448 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;943 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkBeego_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;7407&lt;/td&gt; 
   &lt;td align="right"&gt;243496 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;71456 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;609 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkBone_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;420&lt;/td&gt; 
   &lt;td align="right"&gt;2922835 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;720160 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;8620 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkChi_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;7620&lt;/td&gt; 
   &lt;td align="right"&gt;238331 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;87696 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;609 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkDenco_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;18355&lt;/td&gt; 
   &lt;td align="right"&gt;64494 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;20224 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;167 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkEcho_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;31251&lt;/td&gt; 
   &lt;td align="right"&gt;38479 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;0 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;0 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkGocraftWeb_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;4117&lt;/td&gt; 
   &lt;td align="right"&gt;300062 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;131656 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;1686 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkGoji_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;3274&lt;/td&gt; 
   &lt;td align="right"&gt;416158 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;56112 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;334 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkGojiv2_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;1402&lt;/td&gt; 
   &lt;td align="right"&gt;870518 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;352720 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;4321 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkGoJsonRest_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;2976&lt;/td&gt; 
   &lt;td align="right"&gt;401507 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;134371 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;2737 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkGoRestful_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;410&lt;/td&gt; 
   &lt;td align="right"&gt;2913158 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;910144 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;2938 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkGorillaMux_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;346&lt;/td&gt; 
   &lt;td align="right"&gt;3384987 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;251650 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;1994 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkGowwwRouter_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;10000&lt;/td&gt; 
   &lt;td align="right"&gt;143025 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;72144 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;501 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkHttpRouter_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;55938&lt;/td&gt; 
   &lt;td align="right"&gt;21360 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;0 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;0 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkHttpTreeMux_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;10000&lt;/td&gt; 
   &lt;td align="right"&gt;153944 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;65856 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;671 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkKocha_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;10000&lt;/td&gt; 
   &lt;td align="right"&gt;106315 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;23304 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;843 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkLARS_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;47779&lt;/td&gt; 
   &lt;td align="right"&gt;25084 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;0 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;0 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkMacaron_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;3266&lt;/td&gt; 
   &lt;td align="right"&gt;371907 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;149409 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;1624 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkMartini_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;331&lt;/td&gt; 
   &lt;td align="right"&gt;3444706 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;226551 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;2325 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkPat_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;273&lt;/td&gt; 
   &lt;td align="right"&gt;4381818 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;1483152 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;26963 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkPossum_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;10000&lt;/td&gt; 
   &lt;td align="right"&gt;164367 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;84448 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;609 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkR2router_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;10000&lt;/td&gt; 
   &lt;td align="right"&gt;160220 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;77328 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;979 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkRivet_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;14625&lt;/td&gt; 
   &lt;td align="right"&gt;82453 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;16272 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;167 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkTango_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;6255&lt;/td&gt; 
   &lt;td align="right"&gt;279611 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;63826 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;1618 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkTigerTonic_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;2008&lt;/td&gt; 
   &lt;td align="right"&gt;687874 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;193856 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;4474 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkTraffic_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;355&lt;/td&gt; 
   &lt;td align="right"&gt;3478508 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;820744 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;14114 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkVulcan_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;6885&lt;/td&gt; 
   &lt;td align="right"&gt;193333 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;19894 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;609 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;ul&gt; 
 &lt;li&gt;(1): Total Repetitions achieved in constant time, higher means more confident result&lt;/li&gt; 
 &lt;li&gt;(2): Single Repetition Duration (ns/op), lower is better&lt;/li&gt; 
 &lt;li&gt;(3): Heap Memory (B/op), lower is better&lt;/li&gt; 
 &lt;li&gt;(4): Average Allocations per Repetition (allocs/op), lower is better&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;🔌 Middleware Ecosystem&lt;/h2&gt; 
&lt;p&gt;Gin has a rich ecosystem of middleware for common web development needs. Explore community-contributed middleware:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://github.com/gin-contrib"&gt;gin-contrib&lt;/a&gt;&lt;/strong&gt; - Official middleware collection including:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Authentication (JWT, Basic Auth, Sessions)&lt;/li&gt; 
   &lt;li&gt;CORS, Rate limiting, Compression&lt;/li&gt; 
   &lt;li&gt;Logging, Metrics, Tracing&lt;/li&gt; 
   &lt;li&gt;Static file serving, Template engines&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://github.com/gin-gonic/contrib"&gt;gin-gonic/contrib&lt;/a&gt;&lt;/strong&gt; - Additional community middleware&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;🏢 Production Usage&lt;/h2&gt; 
&lt;p&gt;Gin powers many high-traffic applications and services in production:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/appleboy/gorush"&gt;gorush&lt;/a&gt;&lt;/strong&gt; - High-performance push notification server&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/fnproject/fn"&gt;fnproject&lt;/a&gt;&lt;/strong&gt; - Container-native, serverless platform&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/photoprism/photoprism"&gt;photoprism&lt;/a&gt;&lt;/strong&gt; - AI-powered personal photo management&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/luraproject/lura"&gt;lura&lt;/a&gt;&lt;/strong&gt; - Ultra-performant API Gateway framework&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/thoas/picfit"&gt;picfit&lt;/a&gt;&lt;/strong&gt; - Real-time image processing server&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/distribworks/dkron"&gt;dkron&lt;/a&gt;&lt;/strong&gt; - Distributed job scheduling system&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;🤝 Contributing&lt;/h2&gt; 
&lt;p&gt;Gin is the work of hundreds of contributors from around the world. We welcome and appreciate your contributions!&lt;/p&gt; 
&lt;h3&gt;How to Contribute&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;🐛 &lt;strong&gt;Report bugs&lt;/strong&gt; - Help us identify and fix issues&lt;/li&gt; 
 &lt;li&gt;💡 &lt;strong&gt;Suggest features&lt;/strong&gt; - Share your ideas for improvements&lt;/li&gt; 
 &lt;li&gt;📝 &lt;strong&gt;Improve documentation&lt;/strong&gt; - Help make our docs clearer&lt;/li&gt; 
 &lt;li&gt;🔧 &lt;strong&gt;Submit code&lt;/strong&gt; - Fix bugs or implement new features&lt;/li&gt; 
 &lt;li&gt;🧪 &lt;strong&gt;Write tests&lt;/strong&gt; - Improve our test coverage&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Getting Started with Contributing&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Check out our &lt;a href="https://raw.githubusercontent.com/gin-gonic/gin/master/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; for detailed guidelines&lt;/li&gt; 
 &lt;li&gt;Join our community discussions and ask questions&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;All contributions are valued and help make Gin better for everyone!&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>harry0703/MoneyPrinterTurbo</title>
      <link>https://github.com/harry0703/MoneyPrinterTurbo</link>
      <description>&lt;p&gt;利用AI大模型，一键生成高清短视频 Generate short videos with one click using AI LLM.&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;h1 align="center"&gt;MoneyPrinterTurbo 💸&lt;/h1&gt; 
 &lt;p align="center"&gt; &lt;a href="https://github.com/harry0703/MoneyPrinterTurbo/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/harry0703/MoneyPrinterTurbo.svg?style=for-the-badge" alt="Stargazers" /&gt;&lt;/a&gt; &lt;a href="https://github.com/harry0703/MoneyPrinterTurbo/issues"&gt;&lt;img src="https://img.shields.io/github/issues/harry0703/MoneyPrinterTurbo.svg?style=for-the-badge" alt="Issues" /&gt;&lt;/a&gt; &lt;a href="https://github.com/harry0703/MoneyPrinterTurbo/network/members"&gt;&lt;img src="https://img.shields.io/github/forks/harry0703/MoneyPrinterTurbo.svg?style=for-the-badge" alt="Forks" /&gt;&lt;/a&gt; &lt;a href="https://github.com/harry0703/MoneyPrinterTurbo/raw/main/LICENSE"&gt;&lt;img src="https://img.shields.io/github/license/harry0703/MoneyPrinterTurbo.svg?style=for-the-badge" alt="License" /&gt;&lt;/a&gt; &lt;/p&gt; 
 &lt;br /&gt; 
 &lt;h3&gt;简体中文 | &lt;a href="https://raw.githubusercontent.com/harry0703/MoneyPrinterTurbo/main/README-en.md"&gt;English&lt;/a&gt;&lt;/h3&gt; 
 &lt;div align="center"&gt; 
  &lt;a href="https://trendshift.io/repositories/8731" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/8731" alt="harry0703%2FMoneyPrinterTurbo | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt; 
 &lt;/div&gt; 
 &lt;br /&gt; 只需提供一个视频 
 &lt;b&gt;主题&lt;/b&gt; 或 
 &lt;b&gt;关键词&lt;/b&gt; ，就可以全自动生成视频文案、视频素材、视频字幕、视频背景音乐，然后合成一个高清的短视频。 
 &lt;br /&gt; 
 &lt;h4&gt;Web界面&lt;/h4&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/harry0703/MoneyPrinterTurbo/main/docs/webui.jpg" alt="" /&gt;&lt;/p&gt; 
 &lt;h4&gt;API界面&lt;/h4&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/harry0703/MoneyPrinterTurbo/main/docs/api.jpg" alt="" /&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;特别感谢 🙏&lt;/h2&gt; 
&lt;p&gt;由于该项目的 &lt;strong&gt;部署&lt;/strong&gt; 和 &lt;strong&gt;使用&lt;/strong&gt;，对于一些小白用户来说，还是 &lt;strong&gt;有一定的门槛&lt;/strong&gt;，在此特别感谢 &lt;strong&gt;录咖（AI智能 多媒体服务平台）&lt;/strong&gt; 网站基于该项目，提供的免费&lt;code&gt;AI视频生成器&lt;/code&gt;服务，可以不用部署，直接在线使用，非常方便。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;中文版：&lt;a href="https://reccloud.cn"&gt;https://reccloud.cn&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;英文版：&lt;a href="https://reccloud.com"&gt;https://reccloud.com&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/harry0703/MoneyPrinterTurbo/main/docs/reccloud.cn.jpg" alt="" /&gt;&lt;/p&gt; 
&lt;h2&gt;感谢赞助 🙏&lt;/h2&gt; 
&lt;p&gt;感谢佐糖 &lt;a href="https://picwish.cn"&gt;https://picwish.cn&lt;/a&gt; 对该项目的支持和赞助，使得该项目能够持续的更新和维护。&lt;/p&gt; 
&lt;p&gt;佐糖专注于&lt;strong&gt;图像处理领域&lt;/strong&gt;，提供丰富的&lt;strong&gt;图像处理工具&lt;/strong&gt;，将复杂操作极致简化，真正实现让图像处理更简单。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/harry0703/MoneyPrinterTurbo/main/docs/picwish.jpg" alt="picwish.jpg" /&gt;&lt;/p&gt; 
&lt;h2&gt;功能特性 🎯&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; 完整的 &lt;strong&gt;MVC架构&lt;/strong&gt;，代码 &lt;strong&gt;结构清晰&lt;/strong&gt;，易于维护，支持 &lt;code&gt;API&lt;/code&gt; 和 &lt;code&gt;Web界面&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; 支持视频文案 &lt;strong&gt;AI自动生成&lt;/strong&gt;，也可以&lt;strong&gt;自定义文案&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; 支持多种 &lt;strong&gt;高清视频&lt;/strong&gt; 尺寸 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; 竖屏 9:16，&lt;code&gt;1080x1920&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; 横屏 16:9，&lt;code&gt;1920x1080&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; 支持 &lt;strong&gt;批量视频生成&lt;/strong&gt;，可以一次生成多个视频，然后选择一个最满意的&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; 支持 &lt;strong&gt;视频片段时长&lt;/strong&gt; 设置，方便调节素材切换频率&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; 支持 &lt;strong&gt;中文&lt;/strong&gt; 和 &lt;strong&gt;英文&lt;/strong&gt; 视频文案&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; 支持 &lt;strong&gt;多种语音&lt;/strong&gt; 合成，可 &lt;strong&gt;实时试听&lt;/strong&gt; 效果&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; 支持 &lt;strong&gt;字幕生成&lt;/strong&gt;，可以调整 &lt;code&gt;字体&lt;/code&gt;、&lt;code&gt;位置&lt;/code&gt;、&lt;code&gt;颜色&lt;/code&gt;、&lt;code&gt;大小&lt;/code&gt;，同时支持&lt;code&gt;字幕描边&lt;/code&gt;设置&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; 支持 &lt;strong&gt;背景音乐&lt;/strong&gt;，随机或者指定音乐文件，可设置&lt;code&gt;背景音乐音量&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; 视频素材来源 &lt;strong&gt;高清&lt;/strong&gt;，而且 &lt;strong&gt;无版权&lt;/strong&gt;，也可以使用自己的 &lt;strong&gt;本地素材&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; 支持 &lt;strong&gt;OpenAI&lt;/strong&gt;、&lt;strong&gt;Moonshot&lt;/strong&gt;、&lt;strong&gt;Azure&lt;/strong&gt;、&lt;strong&gt;gpt4free&lt;/strong&gt;、&lt;strong&gt;one-api&lt;/strong&gt;、&lt;strong&gt;通义千问&lt;/strong&gt;、&lt;strong&gt;Google Gemini&lt;/strong&gt;、&lt;strong&gt;Ollama&lt;/strong&gt;、&lt;strong&gt;DeepSeek&lt;/strong&gt;、 &lt;strong&gt;文心一言&lt;/strong&gt;, &lt;strong&gt;Pollinations&lt;/strong&gt; 等多种模型接入 
  &lt;ul&gt; 
   &lt;li&gt;中国用户建议使用 &lt;strong&gt;DeepSeek&lt;/strong&gt; 或 &lt;strong&gt;Moonshot&lt;/strong&gt; 作为大模型提供商（国内可直接访问，不需要VPN。注册就送额度，基本够用）&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;后期计划 📅&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; GPT-SoVITS 配音支持&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; 优化语音合成，利用大模型，使其合成的声音，更加自然，情绪更加丰富&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; 增加视频转场效果，使其看起来更加的流畅&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; 增加更多视频素材来源，优化视频素材和文案的匹配度&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; 增加视频长度选项：短、中、长&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; 支持更多的语音合成服务商，比如 OpenAI TTS&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; 自动上传到YouTube平台&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;视频演示 📺&lt;/h2&gt; 
&lt;h3&gt;竖屏 9:16&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="center"&gt;
    &lt;g-emoji class="g-emoji" alias="arrow_forward"&gt;
     ▶️
    &lt;/g-emoji&gt; 《如何增加生活的乐趣》&lt;/th&gt; 
   &lt;th align="center"&gt;
    &lt;g-emoji class="g-emoji" alias="arrow_forward"&gt;
     ▶️
    &lt;/g-emoji&gt; 《金钱的作用》&lt;br /&gt;更真实的合成声音&lt;/th&gt; 
   &lt;th align="center"&gt;
    &lt;g-emoji class="g-emoji" alias="arrow_forward"&gt;
     ▶️
    &lt;/g-emoji&gt; 《生命的意义是什么》&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;
    &lt;video src="https://github.com/harry0703/MoneyPrinterTurbo/assets/4928832/a84d33d5-27a2-4aba-8fd0-9fb2bd91c6a6"&gt;&lt;/video&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;
    &lt;video src="https://github.com/harry0703/MoneyPrinterTurbo/assets/4928832/af2f3b0b-002e-49fe-b161-18ba91c055e8"&gt;&lt;/video&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;
    &lt;video src="https://github.com/harry0703/MoneyPrinterTurbo/assets/4928832/112c9564-d52b-4472-99ad-970b75f66476"&gt;&lt;/video&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;横屏 16:9&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="center"&gt;
    &lt;g-emoji class="g-emoji" alias="arrow_forward"&gt;
     ▶️
    &lt;/g-emoji&gt;《生命的意义是什么》&lt;/th&gt; 
   &lt;th align="center"&gt;
    &lt;g-emoji class="g-emoji" alias="arrow_forward"&gt;
     ▶️
    &lt;/g-emoji&gt;《为什么要运动》&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;
    &lt;video src="https://github.com/harry0703/MoneyPrinterTurbo/assets/4928832/346ebb15-c55f-47a9-a653-114f08bb8073"&gt;&lt;/video&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;
    &lt;video src="https://github.com/harry0703/MoneyPrinterTurbo/assets/4928832/271f2fae-8283-44a0-8aa0-0ed8f9a6fa87"&gt;&lt;/video&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;配置要求 📦&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;建议最低 CPU &lt;strong&gt;4核&lt;/strong&gt; 或以上，内存 &lt;strong&gt;4G&lt;/strong&gt; 或以上，显卡非必须&lt;/li&gt; 
 &lt;li&gt;Windows 10 或 MacOS 11.0 以上系统&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;快速开始 🚀&lt;/h2&gt; 
&lt;h3&gt;在 Google Colab 中运行&lt;/h3&gt; 
&lt;p&gt;免去本地环境配置，点击直接在 Google Colab 中快速体验 MoneyPrinterTurbo&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://colab.research.google.com/github/harry0703/MoneyPrinterTurbo/blob/main/docs/MoneyPrinterTurbo.ipynb"&gt;&lt;img src="https://colab.research.google.com/assets/colab-badge.svg?sanitize=true" alt="Open in Colab" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Windows一键启动包&lt;/h3&gt; 
&lt;p&gt;下载一键启动包，解压直接使用（路径不要有 &lt;strong&gt;中文&lt;/strong&gt;、&lt;strong&gt;特殊字符&lt;/strong&gt;、&lt;strong&gt;空格&lt;/strong&gt;）&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;百度网盘（v1.2.6）: &lt;a href="https://pan.baidu.com/s/1wg0UaIyXpO3SqIpaq790SQ?pwd=sbqx"&gt;https://pan.baidu.com/s/1wg0UaIyXpO3SqIpaq790SQ?pwd=sbqx&lt;/a&gt; 提取码: sbqx&lt;/li&gt; 
 &lt;li&gt;Google Drive (v1.2.6): &lt;a href="https://drive.google.com/file/d/1HsbzfT7XunkrCrHw5ncUjFX8XX4zAuUh/view?usp=sharing"&gt;https://drive.google.com/file/d/1HsbzfT7XunkrCrHw5ncUjFX8XX4zAuUh/view?usp=sharing&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;下载后，建议先&lt;strong&gt;双击执行&lt;/strong&gt; &lt;code&gt;update.bat&lt;/code&gt; 更新到&lt;strong&gt;最新代码&lt;/strong&gt;，然后双击 &lt;code&gt;start.bat&lt;/code&gt; 启动&lt;/p&gt; 
&lt;p&gt;启动后，会自动打开浏览器（如果打开是空白，建议换成 &lt;strong&gt;Chrome&lt;/strong&gt; 或者 &lt;strong&gt;Edge&lt;/strong&gt; 打开）&lt;/p&gt; 
&lt;h2&gt;安装部署 📥&lt;/h2&gt; 
&lt;h3&gt;前提条件&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;尽量不要使用 &lt;strong&gt;中文路径&lt;/strong&gt;，避免出现一些无法预料的问题&lt;/li&gt; 
 &lt;li&gt;请确保你的 &lt;strong&gt;网络&lt;/strong&gt; 是正常的，VPN需要打开&lt;code&gt;全局流量&lt;/code&gt;模式&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;① 克隆代码&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;git clone https://github.com/harry0703/MoneyPrinterTurbo.git
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;② 修改配置文件（可选，建议启动后也可以在 WebUI 里面配置）&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;将 &lt;code&gt;config.example.toml&lt;/code&gt; 文件复制一份，命名为 &lt;code&gt;config.toml&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;按照 &lt;code&gt;config.toml&lt;/code&gt; 文件中的说明，配置好 &lt;code&gt;pexels_api_keys&lt;/code&gt; 和 &lt;code&gt;llm_provider&lt;/code&gt;，并根据 llm_provider 对应的服务商，配置相关的 API Key&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Docker部署 🐳&lt;/h3&gt; 
&lt;h4&gt;① 启动Docker&lt;/h4&gt; 
&lt;p&gt;如果未安装 Docker，请先安装 &lt;a href="https://www.docker.com/products/docker-desktop/"&gt;https://www.docker.com/products/docker-desktop/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;如果是Windows系统，请参考微软的文档：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;a href="https://learn.microsoft.com/zh-cn/windows/wsl/install"&gt;https://learn.microsoft.com/zh-cn/windows/wsl/install&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://learn.microsoft.com/zh-cn/windows/wsl/tutorials/wsl-containers"&gt;https://learn.microsoft.com/zh-cn/windows/wsl/tutorials/wsl-containers&lt;/a&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;cd MoneyPrinterTurbo
docker-compose up
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;注意：最新版的docker安装时会自动以插件的形式安装docker compose，启动命令调整为docker compose up&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;② 访问Web界面&lt;/h4&gt; 
&lt;p&gt;打开浏览器，访问 &lt;a href="http://0.0.0.0:8501"&gt;http://0.0.0.0:8501&lt;/a&gt;&lt;/p&gt; 
&lt;h4&gt;③ 访问API文档&lt;/h4&gt; 
&lt;p&gt;打开浏览器，访问 &lt;a href="http://0.0.0.0:8080/docs"&gt;http://0.0.0.0:8080/docs&lt;/a&gt; 或者 &lt;a href="http://0.0.0.0:8080/redoc"&gt;http://0.0.0.0:8080/redoc&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;手动部署 📦&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;视频教程&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;完整的使用演示：&lt;a href="https://v.douyin.com/iFhnwsKY/"&gt;https://v.douyin.com/iFhnwsKY/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;如何在Windows上部署：&lt;a href="https://v.douyin.com/iFyjoW3M"&gt;https://v.douyin.com/iFyjoW3M&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;① 创建虚拟环境&lt;/h4&gt; 
&lt;p&gt;建议使用 &lt;a href="https://conda.io/projects/conda/en/latest/user-guide/install/index.html"&gt;conda&lt;/a&gt; 创建 python 虚拟环境&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;git clone https://github.com/harry0703/MoneyPrinterTurbo.git
cd MoneyPrinterTurbo
conda create -n MoneyPrinterTurbo python=3.11
conda activate MoneyPrinterTurbo
pip install -r requirements.txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;② 安装好 ImageMagick&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Windows:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;下载 &lt;a href="https://imagemagick.org/script/download.php"&gt;https://imagemagick.org/script/download.php&lt;/a&gt; 选择Windows版本，切记一定要选择 &lt;strong&gt;静态库&lt;/strong&gt; 版本，比如 ImageMagick-7.1.1-32-Q16-x64-&lt;strong&gt;static&lt;/strong&gt;.exe&lt;/li&gt; 
   &lt;li&gt;安装下载好的 ImageMagick，&lt;strong&gt;注意不要修改安装路径&lt;/strong&gt;&lt;/li&gt; 
   &lt;li&gt;修改 &lt;code&gt;配置文件 config.toml&lt;/code&gt; 中的 &lt;code&gt;imagemagick_path&lt;/code&gt; 为你的 &lt;strong&gt;实际安装路径&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;MacOS:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;brew install imagemagick
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Ubuntu&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;sudo apt-get install imagemagick
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;CentOS&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;sudo yum install ImageMagick
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;③ 启动Web界面 🌐&lt;/h4&gt; 
&lt;p&gt;注意需要到 MoneyPrinterTurbo 项目 &lt;code&gt;根目录&lt;/code&gt; 下执行以下命令&lt;/p&gt; 
&lt;h6&gt;Windows&lt;/h6&gt; 
&lt;pre&gt;&lt;code class="language-bat"&gt;webui.bat
&lt;/code&gt;&lt;/pre&gt; 
&lt;h6&gt;MacOS or Linux&lt;/h6&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;sh webui.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;启动后，会自动打开浏览器（如果打开是空白，建议换成 &lt;strong&gt;Chrome&lt;/strong&gt; 或者 &lt;strong&gt;Edge&lt;/strong&gt; 打开）&lt;/p&gt; 
&lt;h4&gt;④ 启动API服务 🚀&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;python main.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;启动后，可以查看 &lt;code&gt;API文档&lt;/code&gt; &lt;a href="http://127.0.0.1:8080/docs"&gt;http://127.0.0.1:8080/docs&lt;/a&gt; 或者 &lt;a href="http://127.0.0.1:8080/redoc"&gt;http://127.0.0.1:8080/redoc&lt;/a&gt; 直接在线调试接口，快速体验。&lt;/p&gt; 
&lt;h2&gt;语音合成 🗣&lt;/h2&gt; 
&lt;p&gt;所有支持的声音列表，可以查看：&lt;a href="https://raw.githubusercontent.com/harry0703/MoneyPrinterTurbo/main/docs/voice-list.txt"&gt;声音列表&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;2024-04-16 v1.1.2 新增了9种Azure的语音合成声音，需要配置API KEY，该声音合成的更加真实。&lt;/p&gt; 
&lt;h2&gt;字幕生成 📜&lt;/h2&gt; 
&lt;p&gt;当前支持2种字幕生成方式：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;edge&lt;/strong&gt;: 生成&lt;code&gt;速度快&lt;/code&gt;，性能更好，对电脑配置没有要求，但是质量可能不稳定&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;whisper&lt;/strong&gt;: 生成&lt;code&gt;速度慢&lt;/code&gt;，性能较差，对电脑配置有一定要求，但是&lt;code&gt;质量更可靠&lt;/code&gt;。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;可以修改 &lt;code&gt;config.toml&lt;/code&gt; 配置文件中的 &lt;code&gt;subtitle_provider&lt;/code&gt; 进行切换&lt;/p&gt; 
&lt;p&gt;建议使用 &lt;code&gt;edge&lt;/code&gt; 模式，如果生成的字幕质量不好，再切换到 &lt;code&gt;whisper&lt;/code&gt; 模式&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;注意：&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ol&gt; 
 &lt;li&gt;whisper 模式下需要到 HuggingFace 下载一个模型文件，大约 3GB 左右，请确保网络通畅&lt;/li&gt; 
 &lt;li&gt;如果留空，表示不生成字幕。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;由于国内无法访问 HuggingFace，可以使用以下方法下载 &lt;code&gt;whisper-large-v3&lt;/code&gt; 的模型文件&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;下载地址：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;百度网盘: &lt;a href="https://pan.baidu.com/s/11h3Q6tsDtjQKTjUu3sc5cA?pwd=xjs9"&gt;https://pan.baidu.com/s/11h3Q6tsDtjQKTjUu3sc5cA?pwd=xjs9&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;夸克网盘：&lt;a href="https://pan.quark.cn/s/3ee3d991d64b"&gt;https://pan.quark.cn/s/3ee3d991d64b&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;模型下载后解压，整个目录放到 &lt;code&gt;.\MoneyPrinterTurbo\models&lt;/code&gt; 里面， 最终的文件路径应该是这样: &lt;code&gt;.\MoneyPrinterTurbo\models\whisper-large-v3&lt;/code&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;MoneyPrinterTurbo  
  ├─models
  │   └─whisper-large-v3
  │          config.json
  │          model.bin
  │          preprocessor_config.json
  │          tokenizer.json
  │          vocabulary.json
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;背景音乐 🎵&lt;/h2&gt; 
&lt;p&gt;用于视频的背景音乐，位于项目的 &lt;code&gt;resource/songs&lt;/code&gt; 目录下。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;当前项目里面放了一些默认的音乐，来自于 YouTube 视频，如有侵权，请删除。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;字幕字体 🅰&lt;/h2&gt; 
&lt;p&gt;用于视频字幕的渲染，位于项目的 &lt;code&gt;resource/fonts&lt;/code&gt; 目录下，你也可以放进去自己的字体。&lt;/p&gt; 
&lt;h2&gt;常见问题 🤔&lt;/h2&gt; 
&lt;h3&gt;❓RuntimeError: No ffmpeg exe could be found&lt;/h3&gt; 
&lt;p&gt;通常情况下，ffmpeg 会被自动下载，并且会被自动检测到。 但是如果你的环境有问题，无法自动下载，可能会遇到如下错误：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;RuntimeError: No ffmpeg exe could be found.
Install ffmpeg on your system, or set the IMAGEIO_FFMPEG_EXE environment variable.
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;此时你可以从 &lt;a href="https://www.gyan.dev/ffmpeg/builds/"&gt;https://www.gyan.dev/ffmpeg/builds/&lt;/a&gt; 下载ffmpeg，解压后，设置 &lt;code&gt;ffmpeg_path&lt;/code&gt; 为你的实际安装路径即可。&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;[app]
# 请根据你的实际路径设置，注意 Windows 路径分隔符为 \\
ffmpeg_path = "C:\\Users\\harry\\Downloads\\ffmpeg.exe"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;❓ImageMagick的安全策略阻止了与临时文件@/tmp/tmpur5hyyto.txt相关的操作&lt;/h3&gt; 
&lt;p&gt;可以在ImageMagick的配置文件policy.xml中找到这些策略。 这个文件通常位于 /etc/ImageMagick-&lt;code&gt;X&lt;/code&gt;/ 或 ImageMagick 安装目录的类似位置。 修改包含&lt;code&gt;pattern="@"&lt;/code&gt;的条目，将&lt;code&gt;rights="none"&lt;/code&gt;更改为&lt;code&gt;rights="read|write"&lt;/code&gt;以允许对文件的读写操作。&lt;/p&gt; 
&lt;h3&gt;❓OSError: [Errno 24] Too many open files&lt;/h3&gt; 
&lt;p&gt;这个问题是由于系统打开文件数限制导致的，可以通过修改系统的文件打开数限制来解决。&lt;/p&gt; 
&lt;p&gt;查看当前限制&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;ulimit -n
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;如果过低，可以调高一些，比如&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;ulimit -n 10240
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;❓Whisper 模型下载失败，出现如下错误&lt;/h3&gt; 
&lt;p&gt;LocalEntryNotfoundEror: Cannot find an appropriate cached snapshotfolderfor the specified revision on the local disk and outgoing trafic has been disabled. To enablerepo look-ups and downloads online, pass 'local files only=False' as input.&lt;/p&gt; 
&lt;p&gt;或者&lt;/p&gt; 
&lt;p&gt;An error occured while synchronizing the model Systran/faster-whisper-large-v3 from the Hugging Face Hub: An error happened while trying to locate the files on the Hub and we cannot find the appropriate snapshot folder for the specified revision on the local disk. Please check your internet connection and try again. Trying to load the model directly from the local cache, if it exists.&lt;/p&gt; 
&lt;p&gt;解决方法：&lt;a href="https://raw.githubusercontent.com/harry0703/MoneyPrinterTurbo/main/#%E5%AD%97%E5%B9%95%E7%94%9F%E6%88%90-"&gt;点击查看如何从网盘手动下载模型&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;反馈建议 📢&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;可以提交 &lt;a href="https://github.com/harry0703/MoneyPrinterTurbo/issues"&gt;issue&lt;/a&gt; 或者 &lt;a href="https://github.com/harry0703/MoneyPrinterTurbo/pulls"&gt;pull request&lt;/a&gt;。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;许可证 📝&lt;/h2&gt; 
&lt;p&gt;点击查看 &lt;a href="https://raw.githubusercontent.com/harry0703/MoneyPrinterTurbo/main/LICENSE"&gt;&lt;code&gt;LICENSE&lt;/code&gt;&lt;/a&gt; 文件&lt;/p&gt; 
&lt;h2&gt;Star History&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://star-history.com/#harry0703/MoneyPrinterTurbo&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=harry0703/MoneyPrinterTurbo&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Gar-b-age/CookLikeHOC</title>
      <link>https://github.com/Gar-b-age/CookLikeHOC</link>
      <description>&lt;p&gt;🥢像老乡鸡🐔那样做饭。主要部分于2024年完工，非老乡鸡官方仓库。文字来自《老乡鸡菜品溯源报告》，并做归纳、编辑与整理。CookLikeHOC.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Gar-b-age/CookLikeHOC/main/banner.png" alt="pic" /&gt;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/Gar-b-age/CookLikeHOC/main/docker_support/README.md"&gt;&lt;strong&gt;Docker Support&lt;/strong&gt;&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/Gar-b-age/CookLikeHOC/main/docs/development.md"&gt;&lt;strong&gt;Development&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h1&gt;像老乡鸡那样做饭&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://github.com/Gar-b-age/CookLikeHOC/issues/26"&gt;&lt;strong&gt;一些说明&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;仓库主体部分于2024年完工，和2025年9月份的舆论事件无关。截止提交时，仓库的贡献者们与老乡鸡的唯一关系只有消费者和商家的关系。本仓库不是老乡鸡的官方仓库。如果有任何问题或意见建议，欢迎指出&lt;/p&gt; 
&lt;h2&gt;新更新&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;欢迎大家来贡献实拍图&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;现已上线网页端，&lt;a href="https://cooklikehoc.soilzhu.su"&gt;点击访问&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Run with Docker? Check it out &lt;a href="https://github.com/Gar-b-age/CookLikeHOC/tree/main/docker_support"&gt;here&lt;/a&gt;, supported by &lt;a href="https://github.com/honestAnt"&gt;@honestAnt&lt;/a&gt; in &lt;a href="https://github.com/Gar-b-age/CookLikeHOC/pull/141"&gt;PR #141&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;AI 绘制的手绘图版及AI配图流程版网页： &lt;a href="https://ai.cooklikehoc.soilzhu.su"&gt;点击访问&lt;/a&gt;, 手绘图由 &lt;a href="https://github.com/liucongg"&gt;@liucongg&lt;/a&gt; 贡献，见 &lt;a href="https://github.com/Gar-b-age/CookLikeHOC/pull/143"&gt;PR #143&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;a href="https://t.me/cooklikehoc"&gt;&lt;img src="https://raw.githubusercontent.com/Gar-b-age/CookLikeHOC/main/tg.png" alt="link" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;《老乡鸡菜品溯源报告》中公布的所有菜品已经全部录入完，欢迎大家查阅和补充。&lt;/p&gt; 
&lt;p&gt;文字超大段copy自&lt;a href="https://www.lxjchina.com.cn/display.asp?id=4226"&gt;《老乡鸡菜品溯源报告》&lt;/a&gt;，有编辑与整理&lt;/p&gt; 
&lt;p&gt;指路隔壁 &lt;a href="https://cook.aiursoft.cn/"&gt;How To Cook&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;至于为什么仓库名要叫CookLikeHOC，因为直接写Laoxiangji大概不方便阅读，而Home Original Chicken是china daily报道中所使用的老乡鸡的英文名，故简写成HOC。&lt;/p&gt; 
&lt;h2&gt;Contributor&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://contrib.rocks/image?repo=Gar-b-age/CookLikeHOC" alt="cr" /&gt;&lt;/p&gt; 
&lt;h2&gt;Logo&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Gar-b-age/CookLikeHOC/main/logo.png" alt="pic" /&gt;&lt;/p&gt; 
&lt;h2&gt;Star History&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://star-history.com/#Gar-b-age/CookLikeHOC&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=Gar-b-age/CookLikeHOC&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>LadybirdBrowser/ladybird</title>
      <link>https://github.com/LadybirdBrowser/ladybird</link>
      <description>&lt;p&gt;Truly independent web browser&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Ladybird&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://ladybird.org"&gt;Ladybird&lt;/a&gt; is a truly independent web browser, using a novel engine based on web standards.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] Ladybird is in a pre-alpha state, and only suitable for use by developers&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;p&gt;We aim to build a complete, usable browser for the modern web.&lt;/p&gt; 
&lt;p&gt;Ladybird uses a multi-process architecture with a main UI process, several WebContent renderer processes, an ImageDecoder process, and a RequestServer process.&lt;/p&gt; 
&lt;p&gt;Image decoding and network connections are done out of process to be more robust against malicious content. Each tab has its own renderer process, which is sandboxed from the rest of the system.&lt;/p&gt; 
&lt;p&gt;At the moment, many core library support components are inherited from SerenityOS:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;LibWeb: Web rendering engine&lt;/li&gt; 
 &lt;li&gt;LibJS: JavaScript engine&lt;/li&gt; 
 &lt;li&gt;LibWasm: WebAssembly implementation&lt;/li&gt; 
 &lt;li&gt;LibCrypto/LibTLS: Cryptography primitives and Transport Layer Security&lt;/li&gt; 
 &lt;li&gt;LibHTTP: HTTP/1.1 client&lt;/li&gt; 
 &lt;li&gt;LibGfx: 2D Graphics Library, Image Decoding and Rendering&lt;/li&gt; 
 &lt;li&gt;LibUnicode: Unicode and locale support&lt;/li&gt; 
 &lt;li&gt;LibMedia: Audio and video playback&lt;/li&gt; 
 &lt;li&gt;LibCore: Event loop, OS abstraction layer&lt;/li&gt; 
 &lt;li&gt;LibIPC: Inter-process communication&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;How do I build and run this?&lt;/h2&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/LadybirdBrowser/ladybird/master/Documentation/BuildInstructionsLadybird.md"&gt;build instructions&lt;/a&gt; for information on how to build Ladybird.&lt;/p&gt; 
&lt;p&gt;Ladybird runs on Linux, macOS, Windows (with WSL2), and many other *Nixes.&lt;/p&gt; 
&lt;h2&gt;How do I read the documentation?&lt;/h2&gt; 
&lt;p&gt;Code-related documentation can be found in the &lt;a href="https://raw.githubusercontent.com/LadybirdBrowser/ladybird/master/Documentation/"&gt;documentation&lt;/a&gt; folder.&lt;/p&gt; 
&lt;h2&gt;Get in touch and participate!&lt;/h2&gt; 
&lt;p&gt;Join &lt;a href="https://discord.gg/nvfjVJ4Svh"&gt;our Discord server&lt;/a&gt; to participate in development discussion.&lt;/p&gt; 
&lt;p&gt;Please read &lt;a href="https://raw.githubusercontent.com/LadybirdBrowser/ladybird/master/Documentation/GettingStartedContributing.md"&gt;Getting started contributing&lt;/a&gt; if you plan to contribute to Ladybird for the first time.&lt;/p&gt; 
&lt;p&gt;Before opening an issue, please see the &lt;a href="https://raw.githubusercontent.com/LadybirdBrowser/ladybird/master/CONTRIBUTING.md#issue-policy"&gt;issue policy&lt;/a&gt; and the &lt;a href="https://raw.githubusercontent.com/LadybirdBrowser/ladybird/master/ISSUES.md"&gt;detailed issue-reporting guidelines&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;The full contribution guidelines can be found in &lt;a href="https://raw.githubusercontent.com/LadybirdBrowser/ladybird/master/CONTRIBUTING.md"&gt;&lt;code&gt;CONTRIBUTING.md&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Ladybird is licensed under a 2-clause BSD license.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>TheAlgorithms/Python</title>
      <link>https://github.com/TheAlgorithms/Python</link>
      <description>&lt;p&gt;All Algorithms implemented in Python&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;!-- Title: --&gt; 
 &lt;a href="https://github.com/TheAlgorithms/"&gt; &lt;img src="https://raw.githubusercontent.com/TheAlgorithms/website/1cd824df116b27029f17c2d1b42d81731f28a920/public/logo.svg?sanitize=true" height="100" /&gt; &lt;/a&gt; 
 &lt;h1&gt;&lt;a href="https://github.com/TheAlgorithms/"&gt;The Algorithms&lt;/a&gt; - Python&lt;/h1&gt; 
 &lt;!-- Labels: --&gt; 
 &lt;!-- First row: --&gt; 
 &lt;a href="https://gitpod.io/#https://github.com/TheAlgorithms/Python"&gt; &lt;img src="https://img.shields.io/badge/Gitpod-Ready--to--Code-blue?logo=gitpod&amp;amp;style=flat-square" height="20" alt="Gitpod Ready-to-Code" /&gt; &lt;/a&gt; 
 &lt;a href="https://github.com/TheAlgorithms/Python/raw/master/CONTRIBUTING.md"&gt; &lt;img src="https://img.shields.io/static/v1.svg?label=Contributions&amp;amp;message=Welcome&amp;amp;color=0059b3&amp;amp;style=flat-square" height="20" alt="Contributions Welcome" /&gt; &lt;/a&gt; 
 &lt;img src="https://img.shields.io/github/repo-size/TheAlgorithms/Python.svg?label=Repo%20size&amp;amp;style=flat-square" height="20" /&gt; 
 &lt;a href="https://the-algorithms.com/discord"&gt; &lt;img src="https://img.shields.io/discord/808045925556682782.svg?logo=discord&amp;amp;colorB=7289DA&amp;amp;style=flat-square" height="20" alt="Discord chat" /&gt; &lt;/a&gt; 
 &lt;a href="https://gitter.im/TheAlgorithms/community"&gt; &lt;img src="https://img.shields.io/badge/Chat-Gitter-ff69b4.svg?label=Chat&amp;amp;logo=gitter&amp;amp;style=flat-square" height="20" alt="Gitter chat" /&gt; &lt;/a&gt; 
 &lt;!-- Second row: --&gt; 
 &lt;br /&gt; 
 &lt;a href="https://github.com/TheAlgorithms/Python/actions"&gt; &lt;img src="https://img.shields.io/github/actions/workflow/status/TheAlgorithms/Python/build.yml?branch=master&amp;amp;label=CI&amp;amp;logo=github&amp;amp;style=flat-square" height="20" alt="GitHub Workflow Status" /&gt; &lt;/a&gt; 
 &lt;a href="https://github.com/pre-commit/pre-commit"&gt; &lt;img src="https://img.shields.io/badge/pre--commit-enabled-brightgreen?logo=pre-commit&amp;amp;logoColor=white&amp;amp;style=flat-square" height="20" alt="pre-commit" /&gt; &lt;/a&gt; 
 &lt;a href="https://docs.astral.sh/ruff/formatter/"&gt; &lt;img src="https://img.shields.io/static/v1?label=code%20style&amp;amp;message=ruff&amp;amp;color=black&amp;amp;style=flat-square" height="20" alt="code style: black" /&gt; &lt;/a&gt; 
 &lt;!-- Short description: --&gt; 
 &lt;h3&gt;All algorithms implemented in Python - for education 📚&lt;/h3&gt; 
&lt;/div&gt; 
&lt;p&gt;Implementations are for learning purposes only. They may be less efficient than the implementations in the Python standard library. Use them at your discretion.&lt;/p&gt; 
&lt;h2&gt;🚀 Getting Started&lt;/h2&gt; 
&lt;p&gt;📋 Read through our &lt;a href="https://raw.githubusercontent.com/TheAlgorithms/Python/master/CONTRIBUTING.md"&gt;Contribution Guidelines&lt;/a&gt; before you contribute.&lt;/p&gt; 
&lt;h2&gt;🌐 Community Channels&lt;/h2&gt; 
&lt;p&gt;We are on &lt;a href="https://the-algorithms.com/discord"&gt;Discord&lt;/a&gt; and &lt;a href="https://gitter.im/TheAlgorithms/community"&gt;Gitter&lt;/a&gt;! Community channels are a great way for you to ask questions and get help. Please join us!&lt;/p&gt; 
&lt;h2&gt;📜 List of Algorithms&lt;/h2&gt; 
&lt;p&gt;See our &lt;a href="https://raw.githubusercontent.com/TheAlgorithms/Python/master/DIRECTORY.md"&gt;directory&lt;/a&gt; for easier navigation and a better overview of the project.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>LazyVim/LazyVim</title>
      <link>https://github.com/LazyVim/LazyVim</link>
      <description>&lt;p&gt;Neovim config for the lazy&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;img src="https://user-images.githubusercontent.com/292349/213446185-2db63fd5-8c84-459c-9f04-e286382d6e80.png" /&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h4 align="center"&gt; &lt;a href="https://lazyvim.github.io/installation"&gt;Install&lt;/a&gt; · &lt;a href="https://lazyvim.github.io/configuration"&gt;Configure&lt;/a&gt; · &lt;a href="https://lazyvim.github.io"&gt;Docs&lt;/a&gt; &lt;/h4&gt; 
&lt;div align="center"&gt;
 &lt;p&gt; &lt;a href="https://github.com/LazyVim/LazyVim/releases/latest"&gt; &lt;img alt="Latest release" src="https://img.shields.io/github/v/release/LazyVim/LazyVim?style=for-the-badge&amp;amp;logo=starship&amp;amp;color=C9CBFF&amp;amp;logoColor=D9E0EE&amp;amp;labelColor=302D41&amp;amp;include_prerelease&amp;amp;sort=semver" /&gt; &lt;/a&gt; &lt;a href="https://github.com/LazyVim/LazyVim/pulse"&gt; &lt;img alt="Last commit" src="https://img.shields.io/github/last-commit/LazyVim/LazyVim?style=for-the-badge&amp;amp;logo=starship&amp;amp;color=8bd5ca&amp;amp;logoColor=D9E0EE&amp;amp;labelColor=302D41" /&gt; &lt;/a&gt; &lt;a href="https://github.com/LazyVim/LazyVim/raw/main/LICENSE"&gt; &lt;img alt="License" src="https://img.shields.io/github/license/LazyVim/LazyVim?style=for-the-badge&amp;amp;logo=starship&amp;amp;color=ee999f&amp;amp;logoColor=D9E0EE&amp;amp;labelColor=302D41" /&gt; &lt;/a&gt; &lt;a href="https://github.com/LazyVim/LazyVim/stargazers"&gt; &lt;img alt="Stars" src="https://img.shields.io/github/stars/LazyVim/LazyVim?style=for-the-badge&amp;amp;logo=starship&amp;amp;color=c69ff5&amp;amp;logoColor=D9E0EE&amp;amp;labelColor=302D41" /&gt; &lt;/a&gt; &lt;a href="https://github.com/LazyVim/LazyVim/issues"&gt; &lt;img alt="Issues" src="https://img.shields.io/github/issues/LazyVim/LazyVim?style=for-the-badge&amp;amp;logo=bilibili&amp;amp;color=F5E0DC&amp;amp;logoColor=D9E0EE&amp;amp;labelColor=302D41" /&gt; &lt;/a&gt; &lt;a href="https://github.com/LazyVim/LazyVim"&gt; &lt;img alt="Repo Size" src="https://img.shields.io/github/repo-size/LazyVim/LazyVim?color=%23DDB6F2&amp;amp;label=SIZE&amp;amp;logo=codesandbox&amp;amp;style=for-the-badge&amp;amp;logoColor=D9E0EE&amp;amp;labelColor=302D41" /&gt; &lt;/a&gt; &lt;a href="https://twitter.com/intent/follow?screen_name=folke"&gt; &lt;img alt="follow on Twitter" src="https://img.shields.io/twitter/follow/folke?style=for-the-badge&amp;amp;logo=twitter&amp;amp;color=8aadf3&amp;amp;logoColor=D9E0EE&amp;amp;labelColor=302D41" /&gt; &lt;/a&gt; &lt;/p&gt;
&lt;/div&gt; 
&lt;p&gt;LazyVim is a Neovim setup powered by &lt;a href="https://github.com/folke/lazy.nvim"&gt;💤 lazy.nvim&lt;/a&gt; to make it easy to customize and extend your config. Rather than having to choose between starting from scratch or using a pre-made distro, LazyVim offers the best of both worlds - the flexibility to tweak your config as needed, along with the convenience of a pre-configured setup.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://user-images.githubusercontent.com/292349/211285846-0b7bb3bf-0462-4029-b64c-4ee1d037fc1c.png" alt="image" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://user-images.githubusercontent.com/292349/213447056-92290767-ea16-430c-8727-ce994c93e9cc.png" alt="image" /&gt;&lt;/p&gt; 
&lt;h2&gt;✨ Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;🔥 Transform your Neovim into a full-fledged IDE&lt;/li&gt; 
 &lt;li&gt;💤 Easily customize and extend your config with &lt;a href="https://github.com/folke/lazy.nvim"&gt;lazy.nvim&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;🚀 Blazingly fast&lt;/li&gt; 
 &lt;li&gt;🧹 Sane default settings for options, autocmds, and keymaps&lt;/li&gt; 
 &lt;li&gt;📦 Comes with a wealth of plugins pre-configured and ready to use&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;⚡️ Requirements&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Neovim &amp;gt;= &lt;strong&gt;0.11.2&lt;/strong&gt; (needs to be built with &lt;strong&gt;LuaJIT&lt;/strong&gt;)&lt;/li&gt; 
 &lt;li&gt;Git &amp;gt;= &lt;strong&gt;2.19.0&lt;/strong&gt; (for partial clones support)&lt;/li&gt; 
 &lt;li&gt;a &lt;a href="https://www.nerdfonts.com/"&gt;Nerd Font&lt;/a&gt; &lt;strong&gt;&lt;em&gt;(optional)&lt;/em&gt;&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;a &lt;strong&gt;C&lt;/strong&gt; compiler for &lt;code&gt;nvim-treesitter&lt;/code&gt;. See &lt;a href="https://github.com/nvim-treesitter/nvim-treesitter#requirements"&gt;here&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;🚀 Getting Started&lt;/h2&gt; 
&lt;p&gt;You can find a starter template for &lt;strong&gt;LazyVim&lt;/strong&gt; &lt;a href="https://github.com/LazyVim/starter"&gt;here&lt;/a&gt;&lt;/p&gt; 
&lt;details&gt;
 &lt;summary&gt;Try it with Docker&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-sh"&gt;docker run -w /root -it --rm alpine:edge sh -uelic '
  apk add git lazygit fzf curl neovim ripgrep alpine-sdk --update
  git clone https://github.com/LazyVim/starter ~/.config/nvim
  cd ~/.config/nvim
  nvim
'
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt;
 &lt;summary&gt;Install the &lt;a href="https://github.com/LazyVim/starter"&gt;LazyVim Starter&lt;/a&gt;&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;Make a backup of your current Neovim files:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-sh"&gt;mv ~/.config/nvim ~/.config/nvim.bak
mv ~/.local/share/nvim ~/.local/share/nvim.bak
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;Clone the starter&lt;/p&gt; &lt;pre&gt;&lt;code class="language-sh"&gt;git clone https://github.com/LazyVim/starter ~/.config/nvim
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;Remove the &lt;code&gt;.git&lt;/code&gt; folder, so you can add it to your own repo later&lt;/p&gt; &lt;pre&gt;&lt;code class="language-sh"&gt;rm -rf ~/.config/nvim/.git
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;Start Neovim!&lt;/p&gt; &lt;pre&gt;&lt;code class="language-sh"&gt;nvim
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Refer to the comments in the files on how to customize &lt;strong&gt;LazyVim&lt;/strong&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;hr /&gt; 
&lt;p&gt;There's a great video created by &lt;a href="https://github.com/elijahmanor"&gt;@elijahmanor&lt;/a&gt; with a walkthrough to get started.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=N93cTbtLCIM"&gt;&lt;img src="https://img.youtube.com/vi/N93cTbtLCIM/hqdefault.jpg" alt="Watch the video" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/dusty-phillips"&gt;@dusty-phillips&lt;/a&gt; wrote a comprehensive book called &lt;a href="https://lazyvim-ambitious-devs.phillips.codes"&gt;LazyVim for Ambitious Developers&lt;/a&gt; available for free online.&lt;/p&gt; 
&lt;h2&gt;📂 File Structure&lt;/h2&gt; 
&lt;p&gt;The files under config will be automatically loaded at the appropriate time, so you don't need to require those files manually. &lt;strong&gt;LazyVim&lt;/strong&gt; comes with a set of default config files that will be loaded &lt;strong&gt;&lt;em&gt;before&lt;/em&gt;&lt;/strong&gt; your own. See &lt;a href="https://github.com/LazyVim/LazyVim/tree/main/lua/lazyvim/config"&gt;here&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;You can add your custom plugin specs under &lt;code&gt;lua/plugins/&lt;/code&gt;. All files there will be automatically loaded by &lt;a href="https://github.com/folke/lazy.nvim"&gt;lazy.nvim&lt;/a&gt;&lt;/p&gt; 
&lt;pre&gt;
~/.config/nvim
├── lua
│&amp;nbsp;&amp;nbsp; ├── config
│&amp;nbsp;&amp;nbsp; │&amp;nbsp;&amp;nbsp; ├── autocmds.lua
│&amp;nbsp;&amp;nbsp; │&amp;nbsp;&amp;nbsp; ├── keymaps.lua
│&amp;nbsp;&amp;nbsp; │&amp;nbsp;&amp;nbsp; ├── lazy.lua
│&amp;nbsp;&amp;nbsp; │&amp;nbsp;&amp;nbsp; └── options.lua
│&amp;nbsp;&amp;nbsp; └── plugins
│&amp;nbsp;&amp;nbsp;     ├── spec1.lua
│&amp;nbsp;&amp;nbsp;     ├── **
│&amp;nbsp;&amp;nbsp;     └── spec2.lua
└── init.lua
&lt;/pre&gt; 
&lt;h2&gt;⚙️ Configuration&lt;/h2&gt; 
&lt;p&gt;Refer to the &lt;a href="https://lazyvim.github.io"&gt;docs&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>HKUDS/RAG-Anything</title>
      <link>https://github.com/HKUDS/RAG-Anything</link>
      <description>&lt;p&gt;"RAG-Anything: All-in-One RAG Framework"&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;div style="margin: 20px 0;"&gt; 
  &lt;img src="https://raw.githubusercontent.com/HKUDS/RAG-Anything/main/assets/logo.png" width="120" height="120" alt="RAG-Anything Logo" style="border-radius: 20px; box-shadow: 0 8px 32px rgba(0, 217, 255, 0.3);" /&gt; 
 &lt;/div&gt; 
 &lt;h1&gt;🚀 RAG-Anything: All-in-One RAG Framework&lt;/h1&gt; 
 &lt;p&gt;&lt;a href="https://trendshift.io/repositories/14959" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/14959" alt="HKUDS%2FRAG-Anything | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;div align="center"&gt; 
  &lt;img src="https://readme-typing-svg.herokuapp.com?font=Orbitron&amp;amp;size=24&amp;amp;duration=3000&amp;amp;pause=1000&amp;amp;color=00D9FF&amp;amp;center=true&amp;amp;vCenter=true&amp;amp;width=600&amp;amp;lines=Welcome+to+RAG-Anything;Next-Gen+Multimodal+RAG+System;Powered+by+Advanced+AI+Technology" alt="Typing Animation" /&gt; 
 &lt;/div&gt; 
 &lt;div align="center"&gt; 
  &lt;div style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); border-radius: 15px; padding: 25px; text-align: center;"&gt; 
   &lt;p&gt; &lt;a href="https://github.com/HKUDS/RAG-Anything"&gt;&lt;img src="https://img.shields.io/badge/🔥Project-Page-00d9ff?style=for-the-badge&amp;amp;logo=github&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt;&lt;/a&gt; &lt;a href="https://arxiv.org/abs/2410.05779"&gt;&lt;img src="https://img.shields.io/badge/📄arXiv-2410.05779-ff6b6b?style=for-the-badge&amp;amp;logo=arxiv&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt;&lt;/a&gt; &lt;a href="https://github.com/HKUDS/LightRAG"&gt;&lt;img src="https://img.shields.io/badge/⚡Based%20on-LightRAG-4ecdc4?style=for-the-badge&amp;amp;logo=lightning&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt;&lt;/a&gt; &lt;/p&gt; 
   &lt;p&gt; &lt;a href="https://github.com/HKUDS/RAG-Anything/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/HKUDS/RAG-Anything?color=00d9ff&amp;amp;style=for-the-badge&amp;amp;logo=star&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/badge/🐍Python-3.10-4ecdc4?style=for-the-badge&amp;amp;logo=python&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt; &lt;a href="https://pypi.org/project/raganything/"&gt;&lt;img src="https://img.shields.io/pypi/v/raganything.svg?style=for-the-badge&amp;amp;logo=pypi&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e&amp;amp;color=ff6b6b" /&gt;&lt;/a&gt; &lt;a href="https://github.com/astral-sh/uv"&gt;&lt;img src="https://img.shields.io/badge/⚡uv-Ready-ff6b6b?style=for-the-badge&amp;amp;logo=python&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt;&lt;/a&gt; &lt;/p&gt; 
   &lt;p&gt; &lt;a href="https://discord.gg/yF2MmDJyGJ"&gt;&lt;img src="https://img.shields.io/badge/💬Discord-Community-7289da?style=for-the-badge&amp;amp;logo=discord&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt;&lt;/a&gt; &lt;a href="https://github.com/HKUDS/RAG-Anything/issues/7"&gt;&lt;img src="https://img.shields.io/badge/💬WeChat-Group-07c160?style=for-the-badge&amp;amp;logo=wechat&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt;&lt;/a&gt; &lt;/p&gt; 
   &lt;p&gt; &lt;a href="https://raw.githubusercontent.com/HKUDS/RAG-Anything/main/README_zh.md"&gt;&lt;img src="https://img.shields.io/badge/🇨🇳中文版-1a1a2e?style=for-the-badge" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/HKUDS/RAG-Anything/main/README.md"&gt;&lt;img src="https://img.shields.io/badge/🇺🇸English-1a1a2e?style=for-the-badge" /&gt;&lt;/a&gt; &lt;/p&gt; 
  &lt;/div&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;div style="width: 100%; height: 2px; margin: 20px 0; background: linear-gradient(90deg, transparent, #00d9ff, transparent);"&gt;&lt;/div&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://raw.githubusercontent.com/HKUDS/RAG-Anything/main/#-quick-start" style="text-decoration: none;"&gt; &lt;img src="https://img.shields.io/badge/Quick%20Start-Get%20Started%20Now-00d9ff?style=for-the-badge&amp;amp;logo=rocket&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h2&gt;🎉 News&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; [2025.08.12]🎯📢 🔍 RAG-Anything now features &lt;strong&gt;VLM-Enhanced Query&lt;/strong&gt; mode! When documents include images, the system seamlessly integrates them into VLM for advanced multimodal analysis, combining visual and textual context for deeper insights.&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; [2025.07.05]🎯📢 RAG-Anything now features a &lt;a href="https://raw.githubusercontent.com/HKUDS/RAG-Anything/main/docs/context_aware_processing.md"&gt;context configuration module&lt;/a&gt;, enabling intelligent integration of relevant contextual information to enhance multimodal content processing.&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; [2025.07.04]🎯📢 🚀 RAG-Anything now supports multimodal query capabilities, enabling enhanced RAG with seamless processing of text, images, tables, and equations.&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; [2025.07.03]🎯📢 🎉 RAG-Anything has reached 1k🌟 stars on GitHub! Thank you for your incredible support and valuable contributions to the project.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;🌟 System Overview&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Next-Generation Multimodal Intelligence&lt;/em&gt;&lt;/p&gt; 
&lt;div style="background: linear-gradient(135deg, #1a1a2e 0%, #16213e 50%, #0f3460 100%); border-radius: 15px; padding: 25px; margin: 20px 0; border: 2px solid #00d9ff; box-shadow: 0 0 30px rgba(0, 217, 255, 0.3);"&gt; 
 &lt;p&gt;Modern documents increasingly contain diverse multimodal content—text, images, tables, equations, charts, and multimedia—that traditional text-focused RAG systems cannot effectively process. &lt;strong&gt;RAG-Anything&lt;/strong&gt; addresses this challenge as a comprehensive &lt;strong&gt;All-in-One Multimodal Document Processing RAG system&lt;/strong&gt; built on &lt;a href="https://github.com/HKUDS/LightRAG"&gt;LightRAG&lt;/a&gt;.&lt;/p&gt; 
 &lt;p&gt;As a unified solution, RAG-Anything &lt;strong&gt;eliminates the need for multiple specialized tools&lt;/strong&gt;. It provides &lt;strong&gt;seamless processing and querying across all content modalities&lt;/strong&gt; within a single integrated framework. Unlike conventional RAG approaches that struggle with non-textual elements, our all-in-one system delivers &lt;strong&gt;comprehensive multimodal retrieval capabilities&lt;/strong&gt;.&lt;/p&gt; 
 &lt;p&gt;Users can query documents containing &lt;strong&gt;interleaved text&lt;/strong&gt;, &lt;strong&gt;visual diagrams&lt;/strong&gt;, &lt;strong&gt;structured tables&lt;/strong&gt;, and &lt;strong&gt;mathematical formulations&lt;/strong&gt; through &lt;strong&gt;one cohesive interface&lt;/strong&gt;. This consolidated approach makes RAG-Anything particularly valuable for academic research, technical documentation, financial reports, and enterprise knowledge management where rich, mixed-content documents demand a &lt;strong&gt;unified processing framework&lt;/strong&gt;.&lt;/p&gt; 
 &lt;img src="https://raw.githubusercontent.com/HKUDS/RAG-Anything/main/assets/rag_anything_framework.png" alt="RAG-Anything" /&gt; 
&lt;/div&gt; 
&lt;h3&gt;🎯 Key Features&lt;/h3&gt; 
&lt;div style="background: linear-gradient(135deg, #1a1a2e 0%, #16213e 100%); border-radius: 15px; padding: 25px; margin: 20px 0;"&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;🔄 End-to-End Multimodal Pipeline&lt;/strong&gt; - Complete workflow from document ingestion and parsing to intelligent multimodal query answering&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;📄 Universal Document Support&lt;/strong&gt; - Seamless processing of PDFs, Office documents, images, and diverse file formats&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;🧠 Specialized Content Analysis&lt;/strong&gt; - Dedicated processors for images, tables, mathematical equations, and heterogeneous content types&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;🔗 Multimodal Knowledge Graph&lt;/strong&gt; - Automatic entity extraction and cross-modal relationship discovery for enhanced understanding&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;⚡ Adaptive Processing Modes&lt;/strong&gt; - Flexible MinerU-based parsing or direct multimodal content injection workflows&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;📋 Direct Content List Insertion&lt;/strong&gt; - Bypass document parsing by directly inserting pre-parsed content lists from external sources&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;🎯 Hybrid Intelligent Retrieval&lt;/strong&gt; - Advanced search capabilities spanning textual and multimodal content with contextual understanding&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h2&gt;🏗️ Algorithm &amp;amp; Architecture&lt;/h2&gt; 
&lt;div style="background: linear-gradient(135deg, #0f0f23 0%, #1a1a2e 100%); border-radius: 15px; padding: 25px; margin: 20px 0; border-left: 5px solid #00d9ff;"&gt; 
 &lt;h3&gt;Core Algorithm&lt;/h3&gt; 
 &lt;p&gt;&lt;strong&gt;RAG-Anything&lt;/strong&gt; implements an effective &lt;strong&gt;multi-stage multimodal pipeline&lt;/strong&gt; that fundamentally extends traditional RAG architectures to seamlessly handle diverse content modalities through intelligent orchestration and cross-modal understanding.&lt;/p&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;div style="width: 100%; max-width: 600px; margin: 20px auto; padding: 20px; background: linear-gradient(135deg, rgba(0, 217, 255, 0.1) 0%, rgba(0, 217, 255, 0.05) 100%); border-radius: 15px; border: 1px solid rgba(0, 217, 255, 0.2);"&gt; 
  &lt;div style="display: flex; justify-content: space-around; align-items: center; flex-wrap: wrap; gap: 20px;"&gt; 
   &lt;div style="text-align: center;"&gt; 
    &lt;div style="font-size: 24px; margin-bottom: 10px;"&gt;
     📄
    &lt;/div&gt; 
    &lt;div style="font-size: 14px; color: #00d9ff;"&gt;
     Document Parsing
    &lt;/div&gt; 
   &lt;/div&gt; 
   &lt;div style="font-size: 20px; color: #00d9ff;"&gt;
    →
   &lt;/div&gt; 
   &lt;div style="text-align: center;"&gt; 
    &lt;div style="font-size: 24px; margin-bottom: 10px;"&gt;
     🧠
    &lt;/div&gt; 
    &lt;div style="font-size: 14px; color: #00d9ff;"&gt;
     Content Analysis
    &lt;/div&gt; 
   &lt;/div&gt; 
   &lt;div style="font-size: 20px; color: #00d9ff;"&gt;
    →
   &lt;/div&gt; 
   &lt;div style="text-align: center;"&gt; 
    &lt;div style="font-size: 24px; margin-bottom: 10px;"&gt;
     🔍
    &lt;/div&gt; 
    &lt;div style="font-size: 14px; color: #00d9ff;"&gt;
     Knowledge Graph
    &lt;/div&gt; 
   &lt;/div&gt; 
   &lt;div style="font-size: 20px; color: #00d9ff;"&gt;
    →
   &lt;/div&gt; 
   &lt;div style="text-align: center;"&gt; 
    &lt;div style="font-size: 24px; margin-bottom: 10px;"&gt;
     🎯
    &lt;/div&gt; 
    &lt;div style="font-size: 14px; color: #00d9ff;"&gt;
     Intelligent Retrieval
    &lt;/div&gt; 
   &lt;/div&gt; 
  &lt;/div&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;h3&gt;1. Document Parsing Stage&lt;/h3&gt; 
&lt;div style="background: linear-gradient(90deg, #1a1a2e 0%, #16213e 100%); border-radius: 10px; padding: 20px; margin: 15px 0; border-left: 4px solid #4ecdc4;"&gt; 
 &lt;p&gt;The system provides high-fidelity document extraction through adaptive content decomposition. It intelligently segments heterogeneous elements while preserving contextual relationships. Universal format compatibility is achieved via specialized optimized parsers.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Key Components:&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;⚙️ MinerU Integration&lt;/strong&gt;: Leverages &lt;a href="https://github.com/opendatalab/MinerU"&gt;MinerU&lt;/a&gt; for high-fidelity document structure extraction and semantic preservation across complex layouts.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;🧩 Adaptive Content Decomposition&lt;/strong&gt;: Automatically segments documents into coherent text blocks, visual elements, structured tables, mathematical equations, and specialized content types while preserving contextual relationships.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;📁 Universal Format Support&lt;/strong&gt;: Provides comprehensive handling of PDFs, Office documents (DOC/DOCX/PPT/PPTX/XLS/XLSX), images, and emerging formats through specialized parsers with format-specific optimization.&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/div&gt; 
&lt;h3&gt;2. Multi-Modal Content Understanding &amp;amp; Processing&lt;/h3&gt; 
&lt;div style="background: linear-gradient(90deg, #16213e 0%, #0f3460 100%); border-radius: 10px; padding: 20px; margin: 15px 0; border-left: 4px solid #ff6b6b;"&gt; 
 &lt;p&gt;The system automatically categorizes and routes content through optimized channels. It uses concurrent pipelines for parallel text and multimodal processing. Document hierarchy and relationships are preserved during transformation.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Key Components:&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;🎯 Autonomous Content Categorization and Routing&lt;/strong&gt;: Automatically identify, categorize, and route different content types through optimized execution channels.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;⚡ Concurrent Multi-Pipeline Architecture&lt;/strong&gt;: Implements concurrent execution of textual and multimodal content through dedicated processing pipelines. This approach maximizes throughput efficiency while preserving content integrity.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;🏗️ Document Hierarchy Extraction&lt;/strong&gt;: Extracts and preserves original document hierarchy and inter-element relationships during content transformation.&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/div&gt; 
&lt;h3&gt;3. Multimodal Analysis Engine&lt;/h3&gt; 
&lt;div style="background: linear-gradient(90deg, #0f3460 0%, #1a1a2e 100%); border-radius: 10px; padding: 20px; margin: 15px 0; border-left: 4px solid #00d9ff;"&gt; 
 &lt;p&gt;The system deploys modality-aware processing units for heterogeneous data modalities:&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Specialized Analyzers:&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;🔍 Visual Content Analyzer&lt;/strong&gt;:&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Integrate vision model for image analysis.&lt;/li&gt; 
    &lt;li&gt;Generates context-aware descriptive captions based on visual semantics.&lt;/li&gt; 
    &lt;li&gt;Extracts spatial relationships and hierarchical structures between visual elements.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;📊 Structured Data Interpreter&lt;/strong&gt;:&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Performs systematic interpretation of tabular and structured data formats.&lt;/li&gt; 
    &lt;li&gt;Implements statistical pattern recognition algorithms for data trend analysis.&lt;/li&gt; 
    &lt;li&gt;Identifies semantic relationships and dependencies across multiple tabular datasets.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;📐 Mathematical Expression Parser&lt;/strong&gt;:&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Parses complex mathematical expressions and formulas with high accuracy.&lt;/li&gt; 
    &lt;li&gt;Provides native LaTeX format support for seamless integration with academic workflows.&lt;/li&gt; 
    &lt;li&gt;Establishes conceptual mappings between mathematical equations and domain-specific knowledge bases.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;🔧 Extensible Modality Handler&lt;/strong&gt;:&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Provides configurable processing framework for custom and emerging content types.&lt;/li&gt; 
    &lt;li&gt;Enables dynamic integration of new modality processors through plugin architecture.&lt;/li&gt; 
    &lt;li&gt;Supports runtime configuration of processing pipelines for specialized use cases.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/div&gt; 
&lt;h3&gt;4. Multimodal Knowledge Graph Index&lt;/h3&gt; 
&lt;div style="background: linear-gradient(90deg, #1a1a2e 0%, #16213e 100%); border-radius: 10px; padding: 20px; margin: 15px 0; border-left: 4px solid #4ecdc4;"&gt; 
 &lt;p&gt;The multi-modal knowledge graph construction module transforms document content into structured semantic representations. It extracts multimodal entities, establishes cross-modal relationships, and preserves hierarchical organization. The system applies weighted relevance scoring for optimized knowledge retrieval.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Core Functions:&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;🔍 Multi-Modal Entity Extraction&lt;/strong&gt;: Transforms significant multimodal elements into structured knowledge graph entities. The process includes semantic annotations and metadata preservation.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;🔗 Cross-Modal Relationship Mapping&lt;/strong&gt;: Establishes semantic connections and dependencies between textual entities and multimodal components. This is achieved through automated relationship inference algorithms.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;🏗️ Hierarchical Structure Preservation&lt;/strong&gt;: Maintains original document organization through "belongs_to" relationship chains. These chains preserve logical content hierarchy and sectional dependencies.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;⚖️ Weighted Relationship Scoring&lt;/strong&gt;: Assigns quantitative relevance scores to relationship types. Scoring is based on semantic proximity and contextual significance within the document structure.&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/div&gt; 
&lt;h3&gt;5. Modality-Aware Retrieval&lt;/h3&gt; 
&lt;div style="background: linear-gradient(90deg, #16213e 0%, #0f3460 100%); border-radius: 10px; padding: 20px; margin: 15px 0; border-left: 4px solid #ff6b6b;"&gt; 
 &lt;p&gt;The hybrid retrieval system combines vector similarity search with graph traversal algorithms for comprehensive content retrieval. It implements modality-aware ranking mechanisms and maintains relational coherence between retrieved elements to ensure contextually integrated information delivery.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Retrieval Mechanisms:&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;🔀 Vector-Graph Fusion&lt;/strong&gt;: Integrates vector similarity search with graph traversal algorithms. This approach leverages both semantic embeddings and structural relationships for comprehensive content retrieval.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;📊 Modality-Aware Ranking&lt;/strong&gt;: Implements adaptive scoring mechanisms that weight retrieval results based on content type relevance. The system adjusts rankings according to query-specific modality preferences.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;🔗 Relational Coherence Maintenance&lt;/strong&gt;: Maintains semantic and structural relationships between retrieved elements. This ensures coherent information delivery and contextual integrity.&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h2&gt;🚀 Quick Start&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Initialize Your AI Journey&lt;/em&gt;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://user-images.githubusercontent.com/74038190/212284158-e840e285-664b-44d7-b79b-e264b5e54825.gif" width="400" /&gt; 
&lt;/div&gt; 
&lt;h3&gt;Installation&lt;/h3&gt; 
&lt;h4&gt;Option 1: Install from PyPI (Recommended)&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Basic installation
pip install raganything

# With optional dependencies for extended format support:
pip install 'raganything[all]'              # All optional features
pip install 'raganything[image]'            # Image format conversion (BMP, TIFF, GIF, WebP)
pip install 'raganything[text]'             # Text file processing (TXT, MD)
pip install 'raganything[image,text]'       # Multiple features
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Option 2: Install from Source&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Install uv (if not already installed)
curl -LsSf https://astral.sh/uv/install.sh | sh

# Clone and setup the project with uv
git clone https://github.com/HKUDS/RAG-Anything.git
cd RAG-Anything

# Install the package and dependencies in a virtual environment
uv sync

# If you encounter network timeouts (especially for opencv packages):
# UV_HTTP_TIMEOUT=120 uv sync

# Run commands directly with uv (recommended approach)
uv run python examples/raganything_example.py --help

# Install with optional dependencies
uv sync --extra image --extra text  # Specific extras
uv sync --all-extras                 # All optional features
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Optional Dependencies&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;[image]&lt;/code&gt;&lt;/strong&gt; - Enables processing of BMP, TIFF, GIF, WebP image formats (requires Pillow)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;[text]&lt;/code&gt;&lt;/strong&gt; - Enables processing of TXT and MD files (requires ReportLab)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;[all]&lt;/code&gt;&lt;/strong&gt; - Includes all Python optional dependencies&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;⚠️ Office Document Processing Requirements:&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Office documents (.doc, .docx, .ppt, .pptx, .xls, .xlsx) require &lt;strong&gt;LibreOffice&lt;/strong&gt; installation&lt;/li&gt; 
  &lt;li&gt;Download from &lt;a href="https://www.libreoffice.org/download/download/"&gt;LibreOffice official website&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Windows&lt;/strong&gt;: Download installer from official website&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;macOS&lt;/strong&gt;: &lt;code&gt;brew install --cask libreoffice&lt;/code&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Ubuntu/Debian&lt;/strong&gt;: &lt;code&gt;sudo apt-get install libreoffice&lt;/code&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;CentOS/RHEL&lt;/strong&gt;: &lt;code&gt;sudo yum install libreoffice&lt;/code&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;Check MinerU installation:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Verify installation
mineru --version

# Check if properly configured
python -c "from raganything import RAGAnything; rag = RAGAnything(); print('✅ MinerU installed properly' if rag.check_parser_installation() else '❌ MinerU installation issue')"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Models are downloaded automatically on first use. For manual download, refer to &lt;a href="https://github.com/opendatalab/MinerU/raw/master/README.md#22-model-source-configuration"&gt;MinerU Model Source Configuration&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Usage Examples&lt;/h3&gt; 
&lt;h4&gt;1. End-to-End Document Processing&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import asyncio
from raganything import RAGAnything, RAGAnythingConfig
from lightrag.llm.openai import openai_complete_if_cache, openai_embed
from lightrag.utils import EmbeddingFunc

async def main():
    # Set up API configuration
    api_key = "your-api-key"
    base_url = "your-base-url"  # Optional

    # Create RAGAnything configuration
    config = RAGAnythingConfig(
        working_dir="./rag_storage",
        parser="mineru",  # Parser selection: mineru or docling
        parse_method="auto",  # Parse method: auto, ocr, or txt
        enable_image_processing=True,
        enable_table_processing=True,
        enable_equation_processing=True,
    )

    # Define LLM model function
    def llm_model_func(prompt, system_prompt=None, history_messages=[], **kwargs):
        return openai_complete_if_cache(
            "gpt-4o-mini",
            prompt,
            system_prompt=system_prompt,
            history_messages=history_messages,
            api_key=api_key,
            base_url=base_url,
            **kwargs,
        )

    # Define vision model function for image processing
    def vision_model_func(
        prompt, system_prompt=None, history_messages=[], image_data=None, messages=None, **kwargs
    ):
        # If messages format is provided (for multimodal VLM enhanced query), use it directly
        if messages:
            return openai_complete_if_cache(
                "gpt-4o",
                "",
                system_prompt=None,
                history_messages=[],
                messages=messages,
                api_key=api_key,
                base_url=base_url,
                **kwargs,
            )
        # Traditional single image format
        elif image_data:
            return openai_complete_if_cache(
                "gpt-4o",
                "",
                system_prompt=None,
                history_messages=[],
                messages=[
                    {"role": "system", "content": system_prompt}
                    if system_prompt
                    else None,
                    {
                        "role": "user",
                        "content": [
                            {"type": "text", "text": prompt},
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": f"data:image/jpeg;base64,{image_data}"
                                },
                            },
                        ],
                    }
                    if image_data
                    else {"role": "user", "content": prompt},
                ],
                api_key=api_key,
                base_url=base_url,
                **kwargs,
            )
        # Pure text format
        else:
            return llm_model_func(prompt, system_prompt, history_messages, **kwargs)

    # Define embedding function
    embedding_func = EmbeddingFunc(
        embedding_dim=3072,
        max_token_size=8192,
        func=lambda texts: openai_embed(
            texts,
            model="text-embedding-3-large",
            api_key=api_key,
            base_url=base_url,
        ),
    )

    # Initialize RAGAnything
    rag = RAGAnything(
        config=config,
        llm_model_func=llm_model_func,
        vision_model_func=vision_model_func,
        embedding_func=embedding_func,
    )

    # Process a document
    await rag.process_document_complete(
        file_path="path/to/your/document.pdf",
        output_dir="./output",
        parse_method="auto"
    )

    # Query the processed content
    # Pure text query - for basic knowledge base search
    text_result = await rag.aquery(
        "What are the main findings shown in the figures and tables?",
        mode="hybrid"
    )
    print("Text query result:", text_result)

    # Multimodal query with specific multimodal content
    multimodal_result = await rag.aquery_with_multimodal(
    "Explain this formula and its relevance to the document content",
    multimodal_content=[{
        "type": "equation",
        "latex": "P(d|q) = \\frac{P(q|d) \\cdot P(d)}{P(q)}",
        "equation_caption": "Document relevance probability"
    }],
    mode="hybrid"
)
    print("Multimodal query result:", multimodal_result)

if __name__ == "__main__":
    asyncio.run(main())
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;2. Direct Multimodal Content Processing&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import asyncio
from lightrag import LightRAG
from lightrag.llm.openai import openai_complete_if_cache, openai_embed
from lightrag.utils import EmbeddingFunc
from raganything.modalprocessors import ImageModalProcessor, TableModalProcessor

async def process_multimodal_content():
    # Set up API configuration
    api_key = "your-api-key"
    base_url = "your-base-url"  # Optional

    # Initialize LightRAG
    rag = LightRAG(
        working_dir="./rag_storage",
        llm_model_func=lambda prompt, system_prompt=None, history_messages=[], **kwargs: openai_complete_if_cache(
            "gpt-4o-mini",
            prompt,
            system_prompt=system_prompt,
            history_messages=history_messages,
            api_key=api_key,
            base_url=base_url,
            **kwargs,
        ),
        embedding_func=EmbeddingFunc(
            embedding_dim=3072,
            max_token_size=8192,
            func=lambda texts: openai_embed(
                texts,
                model="text-embedding-3-large",
                api_key=api_key,
                base_url=base_url,
            ),
        )
    )
    await rag.initialize_storages()

    # Process an image
    image_processor = ImageModalProcessor(
        lightrag=rag,
        modal_caption_func=lambda prompt, system_prompt=None, history_messages=[], image_data=None, **kwargs: openai_complete_if_cache(
            "gpt-4o",
            "",
            system_prompt=None,
            history_messages=[],
            messages=[
                {"role": "system", "content": system_prompt} if system_prompt else None,
                {"role": "user", "content": [
                    {"type": "text", "text": prompt},
                    {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{image_data}"}}
                ]} if image_data else {"role": "user", "content": prompt}
            ],
            api_key=api_key,
            base_url=base_url,
            **kwargs,
        ) if image_data else openai_complete_if_cache(
            "gpt-4o-mini",
            prompt,
            system_prompt=system_prompt,
            history_messages=history_messages,
            api_key=api_key,
            base_url=base_url,
            **kwargs,
        )
    )

    image_content = {
        "img_path": "path/to/image.jpg",
        "image_caption": ["Figure 1: Experimental results"],
        "image_footnote": ["Data collected in 2024"]
    }

    description, entity_info = await image_processor.process_multimodal_content(
        modal_content=image_content,
        content_type="image",
        file_path="research_paper.pdf",
        entity_name="Experimental Results Figure"
    )

    # Process a table
    table_processor = TableModalProcessor(
        lightrag=rag,
        modal_caption_func=lambda prompt, system_prompt=None, history_messages=[], **kwargs: openai_complete_if_cache(
            "gpt-4o-mini",
            prompt,
            system_prompt=system_prompt,
            history_messages=history_messages,
            api_key=api_key,
            base_url=base_url,
            **kwargs,
        )
    )

    table_content = {
        "table_body": """
        | Method | Accuracy | F1-Score |
        |--------|----------|----------|
        | RAGAnything | 95.2% | 0.94 |
        | Baseline | 87.3% | 0.85 |
        """,
        "table_caption": ["Performance Comparison"],
        "table_footnote": ["Results on test dataset"]
    }

    description, entity_info = await table_processor.process_multimodal_content(
        modal_content=table_content,
        content_type="table",
        file_path="research_paper.pdf",
        entity_name="Performance Results Table"
    )

if __name__ == "__main__":
    asyncio.run(process_multimodal_content())
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;3. Batch Processing&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# Process multiple documents
await rag.process_folder_complete(
    folder_path="./documents",
    output_dir="./output",
    file_extensions=[".pdf", ".docx", ".pptx"],
    recursive=True,
    max_workers=4
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;4. Custom Modal Processors&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from raganything.modalprocessors import GenericModalProcessor

class CustomModalProcessor(GenericModalProcessor):
    async def process_multimodal_content(self, modal_content, content_type, file_path, entity_name):
        # Your custom processing logic
        enhanced_description = await self.analyze_custom_content(modal_content)
        entity_info = self.create_custom_entity(enhanced_description, entity_name)
        return await self._create_entity_and_chunk(enhanced_description, entity_info, file_path)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;5. Query Options&lt;/h4&gt; 
&lt;p&gt;RAG-Anything provides three types of query methods:&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Pure Text Queries&lt;/strong&gt; - Direct knowledge base search using LightRAG:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# Different query modes for text queries
text_result_hybrid = await rag.aquery("Your question", mode="hybrid")
text_result_local = await rag.aquery("Your question", mode="local")
text_result_global = await rag.aquery("Your question", mode="global")
text_result_naive = await rag.aquery("Your question", mode="naive")

# Synchronous version
sync_text_result = rag.query("Your question", mode="hybrid")
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;VLM Enhanced Queries&lt;/strong&gt; - Automatically analyze images in retrieved context using VLM:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# VLM enhanced query (automatically enabled when vision_model_func is provided)
vlm_result = await rag.aquery(
    "Analyze the charts and figures in the document",
    mode="hybrid"
    # vlm_enhanced=True is automatically set when vision_model_func is available
)

# Manually control VLM enhancement
vlm_enabled = await rag.aquery(
    "What do the images show in this document?",
    mode="hybrid",
    vlm_enhanced=True  # Force enable VLM enhancement
)

vlm_disabled = await rag.aquery(
    "What do the images show in this document?",
    mode="hybrid",
    vlm_enhanced=False  # Force disable VLM enhancement
)

# When documents contain images, VLM can see and analyze them directly
# The system will automatically:
# 1. Retrieve relevant context containing image paths
# 2. Load and encode images as base64
# 3. Send both text context and images to VLM for comprehensive analysis
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Multimodal Queries&lt;/strong&gt; - Enhanced queries with specific multimodal content analysis:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# Query with table data
table_result = await rag.aquery_with_multimodal(
    "Compare these performance metrics with the document content",
    multimodal_content=[{
        "type": "table",
        "table_data": """Method,Accuracy,Speed
                        RAGAnything,95.2%,120ms
                        Traditional,87.3%,180ms""",
        "table_caption": "Performance comparison"
    }],
    mode="hybrid"
)

# Query with equation content
equation_result = await rag.aquery_with_multimodal(
    "Explain this formula and its relevance to the document content",
    multimodal_content=[{
        "type": "equation",
        "latex": "P(d|q) = \\frac{P(q|d) \\cdot P(d)}{P(q)}",
        "equation_caption": "Document relevance probability"
    }],
    mode="hybrid"
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;6. Loading Existing LightRAG Instance&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import asyncio
from raganything import RAGAnything, RAGAnythingConfig
from lightrag import LightRAG
from lightrag.llm.openai import openai_complete_if_cache, openai_embed
from lightrag.kg.shared_storage import initialize_pipeline_status
from lightrag.utils import EmbeddingFunc
import os

async def load_existing_lightrag():
    # Set up API configuration
    api_key = "your-api-key"
    base_url = "your-base-url"  # Optional

    # First, create or load existing LightRAG instance
    lightrag_working_dir = "./existing_lightrag_storage"

    # Check if previous LightRAG instance exists
    if os.path.exists(lightrag_working_dir) and os.listdir(lightrag_working_dir):
        print("✅ Found existing LightRAG instance, loading...")
    else:
        print("❌ No existing LightRAG instance found, will create new one")

    # Create/load LightRAG instance with your configuration
    lightrag_instance = LightRAG(
        working_dir=lightrag_working_dir,
        llm_model_func=lambda prompt, system_prompt=None, history_messages=[], **kwargs: openai_complete_if_cache(
            "gpt-4o-mini",
            prompt,
            system_prompt=system_prompt,
            history_messages=history_messages,
            api_key=api_key,
            base_url=base_url,
            **kwargs,
        ),
        embedding_func=EmbeddingFunc(
            embedding_dim=3072,
            max_token_size=8192,
            func=lambda texts: openai_embed(
                texts,
                model="text-embedding-3-large",
                api_key=api_key,
                base_url=base_url,
            ),
        )
    )

    # Initialize storage (this will load existing data if available)
    await lightrag_instance.initialize_storages()
    await initialize_pipeline_status()

    # Define vision model function for image processing
    def vision_model_func(
        prompt, system_prompt=None, history_messages=[], image_data=None, messages=None, **kwargs
    ):
        # If messages format is provided (for multimodal VLM enhanced query), use it directly
        if messages:
            return openai_complete_if_cache(
                "gpt-4o",
                "",
                system_prompt=None,
                history_messages=[],
                messages=messages,
                api_key=api_key,
                base_url=base_url,
                **kwargs,
            )
        # Traditional single image format
        elif image_data:
            return openai_complete_if_cache(
                "gpt-4o",
                "",
                system_prompt=None,
                history_messages=[],
                messages=[
                    {"role": "system", "content": system_prompt}
                    if system_prompt
                    else None,
                    {
                        "role": "user",
                        "content": [
                            {"type": "text", "text": prompt},
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": f"data:image/jpeg;base64,{image_data}"
                                },
                            },
                        ],
                    }
                    if image_data
                    else {"role": "user", "content": prompt},
                ],
                api_key=api_key,
                base_url=base_url,
                **kwargs,
            )
        # Pure text format
        else:
            return lightrag_instance.llm_model_func(prompt, system_prompt, history_messages, **kwargs)

    # Now use existing LightRAG instance to initialize RAGAnything
    rag = RAGAnything(
        lightrag=lightrag_instance,  # Pass existing LightRAG instance
        vision_model_func=vision_model_func,
        # Note: working_dir, llm_model_func, embedding_func, etc. are inherited from lightrag_instance
    )

    # Query existing knowledge base
    result = await rag.aquery(
        "What data has been processed in this LightRAG instance?",
        mode="hybrid"
    )
    print("Query result:", result)

    # Add new multimodal document to existing LightRAG instance
    await rag.process_document_complete(
        file_path="path/to/new/multimodal_document.pdf",
        output_dir="./output"
    )

if __name__ == "__main__":
    asyncio.run(load_existing_lightrag())
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;7. Direct Content List Insertion&lt;/h4&gt; 
&lt;p&gt;For scenarios where you already have a pre-parsed content list (e.g., from external parsers or previous processing), you can directly insert it into RAGAnything without document parsing:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import asyncio
from raganything import RAGAnything, RAGAnythingConfig
from lightrag.llm.openai import openai_complete_if_cache, openai_embed
from lightrag.utils import EmbeddingFunc

async def insert_content_list_example():
    # Set up API configuration
    api_key = "your-api-key"
    base_url = "your-base-url"  # Optional

    # Create RAGAnything configuration
    config = RAGAnythingConfig(
        working_dir="./rag_storage",
        enable_image_processing=True,
        enable_table_processing=True,
        enable_equation_processing=True,
    )

    # Define model functions
    def llm_model_func(prompt, system_prompt=None, history_messages=[], **kwargs):
        return openai_complete_if_cache(
            "gpt-4o-mini",
            prompt,
            system_prompt=system_prompt,
            history_messages=history_messages,
            api_key=api_key,
            base_url=base_url,
            **kwargs,
        )

    def vision_model_func(prompt, system_prompt=None, history_messages=[], image_data=None, messages=None, **kwargs):
        # If messages format is provided (for multimodal VLM enhanced query), use it directly
        if messages:
            return openai_complete_if_cache(
                "gpt-4o",
                "",
                system_prompt=None,
                history_messages=[],
                messages=messages,
                api_key=api_key,
                base_url=base_url,
                **kwargs,
            )
        # Traditional single image format
        elif image_data:
            return openai_complete_if_cache(
                "gpt-4o",
                "",
                system_prompt=None,
                history_messages=[],
                messages=[
                    {"role": "system", "content": system_prompt} if system_prompt else None,
                    {
                        "role": "user",
                        "content": [
                            {"type": "text", "text": prompt},
                            {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{image_data}"}}
                        ],
                    } if image_data else {"role": "user", "content": prompt},
                ],
                api_key=api_key,
                base_url=base_url,
                **kwargs,
            )
        # Pure text format
        else:
            return llm_model_func(prompt, system_prompt, history_messages, **kwargs)

    embedding_func = EmbeddingFunc(
        embedding_dim=3072,
        max_token_size=8192,
        func=lambda texts: openai_embed(
            texts,
            model="text-embedding-3-large",
            api_key=api_key,
            base_url=base_url,
        ),
    )

    # Initialize RAGAnything
    rag = RAGAnything(
        config=config,
        llm_model_func=llm_model_func,
        vision_model_func=vision_model_func,
        embedding_func=embedding_func,
    )

    # Example: Pre-parsed content list from external source
    content_list = [
        {
            "type": "text",
            "text": "This is the introduction section of our research paper.",
            "page_idx": 0  # Page number where this content appears
        },
        {
            "type": "image",
            "img_path": "/absolute/path/to/figure1.jpg",  # IMPORTANT: Use absolute path
            "image_caption": ["Figure 1: System Architecture"],
            "image_footnote": ["Source: Authors' original design"],
            "page_idx": 1  # Page number where this image appears
        },
        {
            "type": "table",
            "table_body": "| Method | Accuracy | F1-Score |\n|--------|----------|----------|\n| Ours | 95.2% | 0.94 |\n| Baseline | 87.3% | 0.85 |",
            "table_caption": ["Table 1: Performance Comparison"],
            "table_footnote": ["Results on test dataset"],
            "page_idx": 2  # Page number where this table appears
        },
        {
            "type": "equation",
            "latex": "P(d|q) = \\frac{P(q|d) \\cdot P(d)}{P(q)}",
            "text": "Document relevance probability formula",
            "page_idx": 3  # Page number where this equation appears
        },
        {
            "type": "text",
            "text": "In conclusion, our method demonstrates superior performance across all metrics.",
            "page_idx": 4  # Page number where this content appears
        }
    ]

    # Insert the content list directly
    await rag.insert_content_list(
        content_list=content_list,
        file_path="research_paper.pdf",  # Reference file name for citation
        split_by_character=None,         # Optional text splitting
        split_by_character_only=False,   # Optional text splitting mode
        doc_id=None,                     # Optional custom document ID (will be auto-generated if not provided)
        display_stats=True               # Show content statistics
    )

    # Query the inserted content
    result = await rag.aquery(
        "What are the key findings and performance metrics mentioned in the research?",
        mode="hybrid"
    )
    print("Query result:", result)

    # You can also insert multiple content lists with different document IDs
    another_content_list = [
        {
            "type": "text",
            "text": "This is content from another document.",
            "page_idx": 0  # Page number where this content appears
        },
        {
            "type": "table",
            "table_body": "| Feature | Value |\n|---------|-------|\n| Speed | Fast |\n| Accuracy | High |",
            "table_caption": ["Feature Comparison"],
            "page_idx": 1  # Page number where this table appears
        }
    ]

    await rag.insert_content_list(
        content_list=another_content_list,
        file_path="another_document.pdf",
        doc_id="custom-doc-id-123"  # Custom document ID
    )

if __name__ == "__main__":
    asyncio.run(insert_content_list_example())
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Content List Format:&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;The &lt;code&gt;content_list&lt;/code&gt; should follow the standard format with each item being a dictionary containing:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Text content&lt;/strong&gt;: &lt;code&gt;{"type": "text", "text": "content text", "page_idx": 0}&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Image content&lt;/strong&gt;: &lt;code&gt;{"type": "image", "img_path": "/absolute/path/to/image.jpg", "image_caption": ["caption"], "image_footnote": ["note"], "page_idx": 1}&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Table content&lt;/strong&gt;: &lt;code&gt;{"type": "table", "table_body": "markdown table", "table_caption": ["caption"], "table_footnote": ["note"], "page_idx": 2}&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Equation content&lt;/strong&gt;: &lt;code&gt;{"type": "equation", "latex": "LaTeX formula", "text": "description", "page_idx": 3}&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Generic content&lt;/strong&gt;: &lt;code&gt;{"type": "custom_type", "content": "any content", "page_idx": 4}&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Important Notes:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;img_path&lt;/code&gt;&lt;/strong&gt;: Must be an absolute path to the image file (e.g., &lt;code&gt;/home/user/images/chart.jpg&lt;/code&gt; or &lt;code&gt;C:\Users\user\images\chart.jpg&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;page_idx&lt;/code&gt;&lt;/strong&gt;: Represents the page number where the content appears in the original document (0-based indexing)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Content ordering&lt;/strong&gt;: Items are processed in the order they appear in the list&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;This method is particularly useful when:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;You have content from external parsers (non-MinerU/Docling)&lt;/li&gt; 
 &lt;li&gt;You want to process programmatically generated content&lt;/li&gt; 
 &lt;li&gt;You need to insert content from multiple sources into a single knowledge base&lt;/li&gt; 
 &lt;li&gt;You have cached parsing results that you want to reuse&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;🛠️ Examples&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Practical Implementation Demos&lt;/em&gt;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://user-images.githubusercontent.com/74038190/212257455-13e3e01e-d6a6-45dc-bb92-3ab87b12dfc1.gif" width="300" /&gt; 
&lt;/div&gt; 
&lt;p&gt;The &lt;code&gt;examples/&lt;/code&gt; directory contains comprehensive usage examples:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;raganything_example.py&lt;/code&gt;&lt;/strong&gt;: End-to-end document processing with MinerU&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;modalprocessors_example.py&lt;/code&gt;&lt;/strong&gt;: Direct multimodal content processing&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;office_document_test.py&lt;/code&gt;&lt;/strong&gt;: Office document parsing test with MinerU (no API key required)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;image_format_test.py&lt;/code&gt;&lt;/strong&gt;: Image format parsing test with MinerU (no API key required)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;text_format_test.py&lt;/code&gt;&lt;/strong&gt;: Text format parsing test with MinerU (no API key required)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Run examples:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# End-to-end processing with parser selection
python examples/raganything_example.py path/to/document.pdf --api-key YOUR_API_KEY --parser mineru

# Direct modal processing
python examples/modalprocessors_example.py --api-key YOUR_API_KEY

# Office document parsing test (MinerU only)
python examples/office_document_test.py --file path/to/document.docx

# Image format parsing test (MinerU only)
python examples/image_format_test.py --file path/to/image.bmp

# Text format parsing test (MinerU only)
python examples/text_format_test.py --file path/to/document.md

# Check LibreOffice installation
python examples/office_document_test.py --check-libreoffice --file dummy

# Check PIL/Pillow installation
python examples/image_format_test.py --check-pillow --file dummy

# Check ReportLab installation
python examples/text_format_test.py --check-reportlab --file dummy
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h2&gt;🔧 Configuration&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;System Optimization Parameters&lt;/em&gt;&lt;/p&gt; 
&lt;h3&gt;Environment Variables&lt;/h3&gt; 
&lt;p&gt;Create a &lt;code&gt;.env&lt;/code&gt; file (refer to &lt;code&gt;.env.example&lt;/code&gt;):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;OPENAI_API_KEY=your_openai_api_key
OPENAI_BASE_URL=your_base_url  # Optional
OUTPUT_DIR=./output             # Default output directory for parsed documents
PARSER=mineru                   # Parser selection: mineru or docling
PARSE_METHOD=auto              # Parse method: auto, ocr, or txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; For backward compatibility, legacy environment variable names are still supported:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;MINERU_PARSE_METHOD&lt;/code&gt; is deprecated, please use &lt;code&gt;PARSE_METHOD&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: API keys are only required for full RAG processing with LLM integration. The parsing test files (&lt;code&gt;office_document_test.py&lt;/code&gt; and &lt;code&gt;image_format_test.py&lt;/code&gt;) only test parser functionality and do not require API keys.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Parser Configuration&lt;/h3&gt; 
&lt;p&gt;RAGAnything now supports multiple parsers, each with specific advantages:&lt;/p&gt; 
&lt;h4&gt;MinerU Parser&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Supports PDF, images, Office documents, and more formats&lt;/li&gt; 
 &lt;li&gt;Powerful OCR and table extraction capabilities&lt;/li&gt; 
 &lt;li&gt;GPU acceleration support&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Docling Parser&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Optimized for Office documents and HTML files&lt;/li&gt; 
 &lt;li&gt;Better document structure preservation&lt;/li&gt; 
 &lt;li&gt;Native support for multiple Office formats&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;MinerU Configuration&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# MinerU 2.0 uses command-line parameters instead of config files
# Check available options:
mineru --help

# Common configurations:
mineru -p input.pdf -o output_dir -m auto    # Automatic parsing mode
mineru -p input.pdf -o output_dir -m ocr     # OCR-focused parsing
mineru -p input.pdf -o output_dir -b pipeline --device cuda  # GPU acceleration
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can also configure parsing through RAGAnything parameters:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# Basic parsing configuration with parser selection
await rag.process_document_complete(
    file_path="document.pdf",
    output_dir="./output/",
    parse_method="auto",          # or "ocr", "txt"
    parser="mineru"               # Optional: "mineru" or "docling"
)

# Advanced parsing configuration with special parameters
await rag.process_document_complete(
    file_path="document.pdf",
    output_dir="./output/",
    parse_method="auto",          # Parsing method: "auto", "ocr", "txt"
    parser="mineru",              # Parser selection: "mineru" or "docling"

    # MinerU special parameters - all supported kwargs:
    lang="ch",                   # Document language for OCR optimization (e.g., "ch", "en", "ja")
    device="cuda:0",             # Inference device: "cpu", "cuda", "cuda:0", "npu", "mps"
    start_page=0,                # Starting page number (0-based, for PDF)
    end_page=10,                 # Ending page number (0-based, for PDF)
    formula=True,                # Enable formula parsing
    table=True,                  # Enable table parsing
    backend="pipeline",          # Parsing backend: pipeline|vlm-transformers|vlm-sglang-engine|vlm-sglang-client.
    source="huggingface",        # Model source: "huggingface", "modelscope", "local"
    # vlm_url="http://127.0.0.1:3000" # Service address when using backend=vlm-sglang-client

    # Standard RAGAnything parameters
    display_stats=True,          # Display content statistics
    split_by_character=None,     # Optional character to split text by
    doc_id=None                  # Optional document ID
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: MinerU 2.0 no longer uses the &lt;code&gt;magic-pdf.json&lt;/code&gt; configuration file. All settings are now passed as command-line parameters or function arguments. RAG-Anything now supports multiple document parsers - you can choose between MinerU and Docling based on your needs.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Processing Requirements&lt;/h3&gt; 
&lt;p&gt;Different content types require specific optional dependencies:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Office Documents&lt;/strong&gt; (.doc, .docx, .ppt, .pptx, .xls, .xlsx): Install &lt;a href="https://www.libreoffice.org/download/download/"&gt;LibreOffice&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Extended Image Formats&lt;/strong&gt; (.bmp, .tiff, .gif, .webp): Install with &lt;code&gt;pip install raganything[image]&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Text Files&lt;/strong&gt; (.txt, .md): Install with &lt;code&gt;pip install raganything[text]&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;📋 Quick Install&lt;/strong&gt;: Use &lt;code&gt;pip install raganything[all]&lt;/code&gt; to enable all format support (Python dependencies only - LibreOffice still needs separate installation)&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;hr /&gt; 
&lt;h2&gt;🧪 Supported Content Types&lt;/h2&gt; 
&lt;h3&gt;Document Formats&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;PDFs&lt;/strong&gt; - Research papers, reports, presentations&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Office Documents&lt;/strong&gt; - DOC, DOCX, PPT, PPTX, XLS, XLSX&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Images&lt;/strong&gt; - JPG, PNG, BMP, TIFF, GIF, WebP&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Text Files&lt;/strong&gt; - TXT, MD&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Multimodal Elements&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Images&lt;/strong&gt; - Photographs, diagrams, charts, screenshots&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Tables&lt;/strong&gt; - Data tables, comparison charts, statistical summaries&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Equations&lt;/strong&gt; - Mathematical formulas in LaTeX format&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Generic Content&lt;/strong&gt; - Custom content types via extensible processors&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;em&gt;For installation of format-specific dependencies, see the &lt;a href="https://raw.githubusercontent.com/HKUDS/RAG-Anything/main/#-configuration"&gt;Configuration&lt;/a&gt; section.&lt;/em&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;📖 Citation&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Academic Reference&lt;/em&gt;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;div style="width: 60px; height: 60px; margin: 20px auto; position: relative;"&gt; 
  &lt;div style="width: 100%; height: 100%; border: 2px solid #00d9ff; border-radius: 50%; position: relative;"&gt; 
   &lt;div style="position: absolute; top: 50%; left: 50%; transform: translate(-50%, -50%); font-size: 24px; color: #00d9ff;"&gt;
    📖
   &lt;/div&gt; 
  &lt;/div&gt; 
  &lt;div style="position: absolute; bottom: -5px; left: 50%; transform: translateX(-50%); width: 20px; height: 20px; background: white; border-right: 2px solid #00d9ff; border-bottom: 2px solid #00d9ff; transform: rotate(45deg);"&gt;&lt;/div&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;p&gt;If you find RAG-Anything useful in your research, please cite our paper:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bibtex"&gt;@article{guo2024lightrag,
  title={LightRAG: Simple and Fast Retrieval-Augmented Generation},
  author={Zirui Guo and Lianghao Xia and Yanhua Yu and Tu Ao and Chao Huang},
  year={2024},
  eprint={2410.05779},
  archivePrefix={arXiv},
  primaryClass={cs.IR}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h2&gt;🔗 Related Projects&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Ecosystem &amp;amp; Extensions&lt;/em&gt;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;table&gt; 
  &lt;tbody&gt;
   &lt;tr&gt; 
    &lt;td align="center"&gt; &lt;a href="https://github.com/HKUDS/LightRAG"&gt; 
      &lt;div style="width: 100px; height: 100px; background: linear-gradient(135deg, rgba(0, 217, 255, 0.1) 0%, rgba(0, 217, 255, 0.05) 100%); border-radius: 15px; border: 1px solid rgba(0, 217, 255, 0.2); display: flex; align-items: center; justify-content: center; margin-bottom: 10px;"&gt; 
       &lt;span style="font-size: 32px;"&gt;⚡&lt;/span&gt; 
      &lt;/div&gt; &lt;b&gt;LightRAG&lt;/b&gt;&lt;br /&gt; &lt;sub&gt;Simple and Fast RAG&lt;/sub&gt; &lt;/a&gt; &lt;/td&gt; 
    &lt;td align="center"&gt; &lt;a href="https://github.com/HKUDS/VideoRAG"&gt; 
      &lt;div style="width: 100px; height: 100px; background: linear-gradient(135deg, rgba(0, 217, 255, 0.1) 0%, rgba(0, 217, 255, 0.05) 100%); border-radius: 15px; border: 1px solid rgba(0, 217, 255, 0.2); display: flex; align-items: center; justify-content: center; margin-bottom: 10px;"&gt; 
       &lt;span style="font-size: 32px;"&gt;🎥&lt;/span&gt; 
      &lt;/div&gt; &lt;b&gt;VideoRAG&lt;/b&gt;&lt;br /&gt; &lt;sub&gt;Extreme Long-Context Video RAG&lt;/sub&gt; &lt;/a&gt; &lt;/td&gt; 
    &lt;td align="center"&gt; &lt;a href="https://github.com/HKUDS/MiniRAG"&gt; 
      &lt;div style="width: 100px; height: 100px; background: linear-gradient(135deg, rgba(0, 217, 255, 0.1) 0%, rgba(0, 217, 255, 0.05) 100%); border-radius: 15px; border: 1px solid rgba(0, 217, 255, 0.2); display: flex; align-items: center; justify-content: center; margin-bottom: 10px;"&gt; 
       &lt;span style="font-size: 32px;"&gt;✨&lt;/span&gt; 
      &lt;/div&gt; &lt;b&gt;MiniRAG&lt;/b&gt;&lt;br /&gt; &lt;sub&gt;Extremely Simple RAG&lt;/sub&gt; &lt;/a&gt; &lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt;
 &lt;/table&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h2&gt;⭐ Star History&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Community Growth Trajectory&lt;/em&gt;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://star-history.com/#HKUDS/RAG-Anything&amp;amp;Date"&gt; 
  &lt;picture&gt; 
   &lt;source media="(prefers-color-scheme: dark)" srcset="https://api.star-history.com/svg?repos=HKUDS/RAG-Anything&amp;amp;type=Date&amp;amp;theme=dark" /&gt; 
   &lt;source media="(prefers-color-scheme: light)" srcset="https://api.star-history.com/svg?repos=HKUDS/RAG-Anything&amp;amp;type=Date" /&gt; 
   &lt;img alt="Star History Chart" src="https://api.star-history.com/svg?repos=HKUDS/RAG-Anything&amp;amp;type=Date" style="border-radius: 15px; box-shadow: 0 0 30px rgba(0, 217, 255, 0.3);" /&gt; 
  &lt;/picture&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h2&gt;🤝 Contribution&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Join the Innovation&lt;/em&gt;&lt;/p&gt; 
&lt;div align="center"&gt;
  We thank all our contributors for their valuable contributions. 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://github.com/HKUDS/RAG-Anything/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=HKUDS/RAG-Anything" style="border-radius: 15px; box-shadow: 0 0 20px rgba(0, 217, 255, 0.3);" /&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;div align="center" style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); border-radius: 15px; padding: 30px; margin: 30px 0;"&gt; 
 &lt;div&gt; 
  &lt;img src="https://user-images.githubusercontent.com/74038190/212284100-561aa473-3905-4a80-b561-0d28506553ee.gif" width="500" /&gt; 
 &lt;/div&gt; 
 &lt;div style="margin-top: 20px;"&gt; 
  &lt;a href="https://github.com/HKUDS/RAG-Anything" style="text-decoration: none;"&gt; &lt;img src="https://img.shields.io/badge/⭐%20Star%20us%20on%20GitHub-1a1a2e?style=for-the-badge&amp;amp;logo=github&amp;amp;logoColor=white" /&gt; &lt;/a&gt; 
  &lt;a href="https://github.com/HKUDS/RAG-Anything/issues" style="text-decoration: none;"&gt; &lt;img src="https://img.shields.io/badge/🐛%20Report%20Issues-ff6b6b?style=for-the-badge&amp;amp;logo=github&amp;amp;logoColor=white" /&gt; &lt;/a&gt; 
  &lt;a href="https://github.com/HKUDS/RAG-Anything/discussions" style="text-decoration: none;"&gt; &lt;img src="https://img.shields.io/badge/💬%20Discussions-4ecdc4?style=for-the-badge&amp;amp;logo=github&amp;amp;logoColor=white" /&gt; &lt;/a&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;div style="width: 100%; max-width: 600px; margin: 20px auto; padding: 20px; background: linear-gradient(135deg, rgba(0, 217, 255, 0.1) 0%, rgba(0, 217, 255, 0.05) 100%); border-radius: 15px; border: 1px solid rgba(0, 217, 255, 0.2);"&gt; 
  &lt;div style="display: flex; justify-content: center; align-items: center; gap: 15px;"&gt; 
   &lt;span style="font-size: 24px;"&gt;⭐&lt;/span&gt; 
   &lt;span style="color: #00d9ff; font-size: 18px;"&gt;Thank you for visiting RAG-Anything!&lt;/span&gt; 
   &lt;span style="font-size: 24px;"&gt;⭐&lt;/span&gt; 
  &lt;/div&gt; 
  &lt;div style="margin-top: 10px; color: #00d9ff; font-size: 16px;"&gt;
   Building the Future of Multimodal AI
  &lt;/div&gt; 
 &lt;/div&gt; 
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>microsoft/AI-For-Beginners</title>
      <link>https://github.com/microsoft/AI-For-Beginners</link>
      <description>&lt;p&gt;12 Weeks, 24 Lessons, AI for All!&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href="https://github.com/microsoft/AI-For-Beginners/raw/main/LICENSE"&gt;&lt;img src="https://img.shields.io/github/license/microsoft/AI-For-Beginners.svg?sanitize=true" alt="GitHub license" /&gt;&lt;/a&gt; &lt;a href="https://GitHub.com/microsoft/AI-For-Beginners/graphs/contributors/"&gt;&lt;img src="https://img.shields.io/github/contributors/microsoft/AI-For-Beginners.svg?sanitize=true" alt="GitHub contributors" /&gt;&lt;/a&gt; &lt;a href="https://GitHub.com/microsoft/AI-For-Beginners/issues/"&gt;&lt;img src="https://img.shields.io/github/issues/microsoft/AI-For-Beginners.svg?sanitize=true" alt="GitHub issues" /&gt;&lt;/a&gt; &lt;a href="https://GitHub.com/microsoft/AI-For-Beginners/pulls/"&gt;&lt;img src="https://img.shields.io/github/issues-pr/microsoft/AI-For-Beginners.svg?sanitize=true" alt="GitHub pull-requests" /&gt;&lt;/a&gt; &lt;a href="http://makeapullrequest.com"&gt;&lt;img src="https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat-square" alt="PRs Welcome" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://GitHub.com/microsoft/AI-For-Beginners/watchers/"&gt;&lt;img src="https://img.shields.io/github/watchers/microsoft/AI-For-Beginners.svg?style=social&amp;amp;label=Watch" alt="GitHub watchers" /&gt;&lt;/a&gt; &lt;a href="https://GitHub.com/microsoft/AI-For-Beginners/network/"&gt;&lt;img src="https://img.shields.io/github/forks/microsoft/AI-For-Beginners.svg?style=social&amp;amp;label=Fork" alt="GitHub forks" /&gt;&lt;/a&gt; &lt;a href="https://GitHub.com/microsoft/AI-For-Beginners/stargazers/"&gt;&lt;img src="https://img.shields.io/github/stars/microsoft/AI-For-Beginners.svg?style=social&amp;amp;label=Star" alt="GitHub stars" /&gt;&lt;/a&gt; &lt;a href="https://mybinder.org/v2/gh/microsoft/ai-for-beginners/HEAD"&gt;&lt;img src="https://mybinder.org/badge_logo.svg?sanitize=true" alt="Binder" /&gt;&lt;/a&gt; &lt;a href="https://gitter.im/Microsoft/ai-for-beginners?utm_source=badge&amp;amp;utm_medium=badge&amp;amp;utm_campaign=pr-badge"&gt;&lt;img src="https://badges.gitter.im/Microsoft/ai-for-beginners.svg?sanitize=true" alt="Gitter" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://discord.gg/zxKYvhSnVp?WT.mc_id=academic-000002-leestott"&gt;&lt;img src="https://dcbadge.vercel.app/api/server/ByRwuEEgH4" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Artificial Intelligence for Beginners - A Curriculum&lt;/h1&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="center"&gt;&lt;img src="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/sketchnotes/ai-overview.png" alt="Sketchnote by @girlie_mac https://twitter.com/girlie_mac" /&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;AI For Beginners - &lt;em&gt;Sketchnote by &lt;a href="https://twitter.com/girlie_mac"&gt;@girlie_mac&lt;/a&gt;&lt;/em&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Explore the world of &lt;strong&gt;Artificial Intelligence&lt;/strong&gt; (AI) with our 12-week, 24-lesson curriculum! It includes practical lessons, quizzes, and labs. The curriculum is beginner-friendly and covers tools like TensorFlow and PyTorch, as well as ethics in AI&lt;/p&gt; 
&lt;h3&gt;🌐 Multi-Language Support&lt;/h3&gt; 
&lt;h4&gt;Supported via GitHub Action (Automated &amp;amp; Always Up-to-Date)&lt;/h4&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/fr/README.md"&gt;French&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/es/README.md"&gt;Spanish&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/de/README.md"&gt;German&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/ru/README.md"&gt;Russian&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/ar/README.md"&gt;Arabic&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/fa/README.md"&gt;Persian (Farsi)&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/ur/README.md"&gt;Urdu&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/zh/README.md"&gt;Chinese (Simplified)&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/mo/README.md"&gt;Chinese (Traditional, Macau)&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/hk/README.md"&gt;Chinese (Traditional, Hong Kong)&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/tw/README.md"&gt;Chinese (Traditional, Taiwan)&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/ja/README.md"&gt;Japanese&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/ko/README.md"&gt;Korean&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/hi/README.md"&gt;Hindi&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/bn/README.md"&gt;Bengali&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/mr/README.md"&gt;Marathi&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/ne/README.md"&gt;Nepali&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/pa/README.md"&gt;Punjabi (Gurmukhi)&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/pt/README.md"&gt;Portuguese (Portugal)&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/br/README.md"&gt;Portuguese (Brazil)&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/it/README.md"&gt;Italian&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/pl/README.md"&gt;Polish&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/tr/README.md"&gt;Turkish&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/el/README.md"&gt;Greek&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/th/README.md"&gt;Thai&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/sv/README.md"&gt;Swedish&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/da/README.md"&gt;Danish&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/no/README.md"&gt;Norwegian&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/fi/README.md"&gt;Finnish&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/nl/README.md"&gt;Dutch&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/he/README.md"&gt;Hebrew&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/vi/README.md"&gt;Vietnamese&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/id/README.md"&gt;Indonesian&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/ms/README.md"&gt;Malay&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/tl/README.md"&gt;Tagalog (Filipino)&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/sw/README.md"&gt;Swahili&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/hu/README.md"&gt;Hungarian&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/cs/README.md"&gt;Czech&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/sk/README.md"&gt;Slovak&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/ro/README.md"&gt;Romanian&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/bg/README.md"&gt;Bulgarian&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/sr/README.md"&gt;Serbian (Cyrillic)&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/hr/README.md"&gt;Croatian&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/sl/README.md"&gt;Slovenian&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/uk/README.md"&gt;Ukrainian&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/translations/my/README.md"&gt;Burmese (Myanmar)&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;If you wish to have additional translations languages supported are listed &lt;a href="https://github.com/Azure/co-op-translator/raw/main/getting_started/supported-languages.md"&gt;here&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;Join the Community&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://discord.gg/kzRShWzttr"&gt;&lt;img src="https://dcbadge.limes.pink/api/server/kzRShWzttr" alt="Azure AI Discord" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;What you will learn&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="http://soshnikov.com/courses/ai-for-beginners/mindmap.html"&gt;Mindmap of the Course&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;In this curriculum, you will learn:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Different approaches to Artificial Intelligence, including the "good old" symbolic approach with &lt;strong&gt;Knowledge Representation&lt;/strong&gt; and reasoning (&lt;a href="https://en.wikipedia.org/wiki/Symbolic_artificial_intelligence"&gt;GOFAI&lt;/a&gt;).&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Neural Networks&lt;/strong&gt; and &lt;strong&gt;Deep Learning&lt;/strong&gt;, which are at the core of modern AI. We will illustrate the concepts behind these important topics using code in two of the most popular frameworks - &lt;a href="http://Tensorflow.org"&gt;TensorFlow&lt;/a&gt; and &lt;a href="http://pytorch.org"&gt;PyTorch&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Neural Architectures&lt;/strong&gt; for working with images and text. We will cover recent models but may be a bit lacking in the state-of-the-art.&lt;/li&gt; 
 &lt;li&gt;Less popular AI approaches, such as &lt;strong&gt;Genetic Algorithms&lt;/strong&gt; and &lt;strong&gt;Multi-Agent Systems&lt;/strong&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;What we will not cover in this curriculum:&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;a href="https://learn.microsoft.com/en-us/collections/7w28iy2xrqzdj0?WT.mc_id=academic-77998-bethanycheum"&gt;Find all additional resources for this course in our Microsoft Learn collection&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;Business cases of using &lt;strong&gt;AI in Business&lt;/strong&gt;. Consider taking &lt;a href="https://docs.microsoft.com/learn/paths/introduction-ai-for-business-users/?WT.mc_id=academic-77998-bethanycheum"&gt;Introduction to AI for business users&lt;/a&gt; learning path on Microsoft Learn, or &lt;a href="https://www.microsoft.com/ai/ai-business-school/?WT.mc_id=academic-77998-bethanycheum"&gt;AI Business School&lt;/a&gt;, developed in cooperation with &lt;a href="https://www.insead.edu/"&gt;INSEAD&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Classic Machine Learning&lt;/strong&gt;, which is well described in our &lt;a href="http://github.com/Microsoft/ML-for-Beginners"&gt;Machine Learning for Beginners Curriculum&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Practical AI applications built using &lt;strong&gt;&lt;a href="https://azure.microsoft.com/services/cognitive-services/?WT.mc_id=academic-77998-bethanycheum"&gt;Cognitive Services&lt;/a&gt;&lt;/strong&gt;. For this, we recommend that you start with modules Microsoft Learn for &lt;a href="https://docs.microsoft.com/learn/paths/create-computer-vision-solutions-azure-cognitive-services/?WT.mc_id=academic-77998-bethanycheum"&gt;vision&lt;/a&gt;, &lt;a href="https://docs.microsoft.com/learn/paths/explore-natural-language-processing/?WT.mc_id=academic-77998-bethanycheum"&gt;natural language processing&lt;/a&gt;, &lt;strong&gt;&lt;a href="https://learn.microsoft.com/en-us/training/paths/develop-ai-solutions-azure-openai/?WT.mc_id=academic-77998-bethanycheum"&gt;Generative AI with Azure OpenAI Service&lt;/a&gt;&lt;/strong&gt; and others.&lt;/li&gt; 
 &lt;li&gt;Specific ML &lt;strong&gt;Cloud Frameworks&lt;/strong&gt;, such as &lt;a href="https://azure.microsoft.com/services/machine-learning/?WT.mc_id=academic-77998-bethanycheum"&gt;Azure Machine Learning&lt;/a&gt;, &lt;a href="https://learn.microsoft.com/en-us/training/paths/get-started-fabric/?WT.mc_id=academic-77998-bethanycheum"&gt;Microsoft Fabric&lt;/a&gt;, or &lt;a href="https://docs.microsoft.com/learn/paths/data-engineer-azure-databricks?WT.mc_id=academic-77998-bethanycheum"&gt;Azure Databricks&lt;/a&gt;. Consider using &lt;a href="https://docs.microsoft.com/learn/paths/build-ai-solutions-with-azure-ml-service/?WT.mc_id=academic-77998-bethanycheum"&gt;Build and operate machine learning solutions with Azure Machine Learning&lt;/a&gt; and &lt;a href="https://docs.microsoft.com/learn/paths/build-operate-machine-learning-solutions-azure-databricks/?WT.mc_id=academic-77998-bethanycheum"&gt;Build and Operate Machine Learning Solutions with Azure Databricks&lt;/a&gt; learning paths.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Conversational AI&lt;/strong&gt; and &lt;strong&gt;Chat Bots&lt;/strong&gt;. There is a separate &lt;a href="https://docs.microsoft.com/learn/paths/create-conversational-ai-solutions/?WT.mc_id=academic-77998-bethanycheum"&gt;Create conversational AI solutions&lt;/a&gt; learning path, and you can also refer to &lt;a href="https://soshnikov.com/azure/hello-bot-conversational-ai-on-microsoft-platform/"&gt;this blog post&lt;/a&gt; for more detail.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Deep Mathematics&lt;/strong&gt; behind deep learning. For this, we would recommend &lt;a href="https://www.amazon.com/Deep-Learning-Adaptive-Computation-Machine/dp/0262035618"&gt;Deep Learning&lt;/a&gt; by Ian Goodfellow, Yoshua Bengio and Aaron Courville, which is also available online at &lt;a href="https://www.deeplearningbook.org/"&gt;https://www.deeplearningbook.org/&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For a gentle introduction to &lt;em&gt;AI in the Cloud&lt;/em&gt; topics you may consider taking the &lt;a href="https://docs.microsoft.com/learn/paths/get-started-with-artificial-intelligence-on-azure/?WT.mc_id=academic-77998-bethanycheum"&gt;Get started with artificial intelligence on Azure&lt;/a&gt; Learning Path.&lt;/p&gt; 
&lt;h1&gt;Content&lt;/h1&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="center"&gt;&lt;/th&gt; 
   &lt;th align="center"&gt;Lesson Link&lt;/th&gt; 
   &lt;th align="center"&gt;PyTorch/Keras/TensorFlow&lt;/th&gt; 
   &lt;th&gt;Lab&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;0&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/0-course-setup/setup.md"&gt;Course Setup&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/0-course-setup/how-to-run.md"&gt;Setup Your Development Environment&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;I&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/1-Intro/README.md"&gt;&lt;strong&gt;Introduction to AI&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;01&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/1-Intro/README.md"&gt;Introduction and History of AI&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;-&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;II&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;Symbolic AI&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;02&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/2-Symbolic/README.md"&gt;Knowledge Representation and Expert Systems&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/2-Symbolic/Animals.ipynb"&gt;Expert Systems&lt;/a&gt; / &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/2-Symbolic/FamilyOntology.ipynb"&gt;Ontology&lt;/a&gt; /&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/2-Symbolic/MSConceptGraph.ipynb"&gt;Concept Graph&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;III&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/3-NeuralNetworks/README.md"&gt;&lt;strong&gt;Introduction to Neural Networks&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;03&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/3-NeuralNetworks/03-Perceptron/README.md"&gt;Perceptron&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/3-NeuralNetworks/03-Perceptron/Perceptron.ipynb"&gt;Notebook&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/3-NeuralNetworks/03-Perceptron/lab/README.md"&gt;Lab&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;04&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/3-NeuralNetworks/04-OwnFramework/README.md"&gt;Multi-Layered Perceptron and Creating our own Framework&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/3-NeuralNetworks/04-OwnFramework/OwnFramework.ipynb"&gt;Notebook&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/3-NeuralNetworks/04-OwnFramework/lab/README.md"&gt;Lab&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;05&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/3-NeuralNetworks/05-Frameworks/README.md"&gt;Intro to Frameworks (PyTorch/TensorFlow) and Overfitting&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/3-NeuralNetworks/05-Frameworks/IntroPyTorch.ipynb"&gt;PyTorch&lt;/a&gt; / &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/3-NeuralNetworks/05-Frameworks/IntroKeras.ipynb"&gt;Keras&lt;/a&gt; / &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/3-NeuralNetworks/05-Frameworks/IntroKerasTF.ipynb"&gt;TensorFlow&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/3-NeuralNetworks/05-Frameworks/lab/README.md"&gt;Lab&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;IV&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/README.md"&gt;&lt;strong&gt;Computer Vision&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://docs.microsoft.com/learn/modules/intro-computer-vision-pytorch/?WT.mc_id=academic-77998-cacaste"&gt;PyTorch&lt;/a&gt; / &lt;a href="https://docs.microsoft.com/learn/modules/intro-computer-vision-TensorFlow/?WT.mc_id=academic-77998-cacaste"&gt;TensorFlow&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://learn.microsoft.com/en-us/collections/7w28iy2xrqzdj0?WT.mc_id=academic-77998-bethanycheum"&gt;Explore Computer Vision on Microsoft Azure&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;06&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/06-IntroCV/README.md"&gt;Intro to Computer Vision. OpenCV&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/06-IntroCV/OpenCV.ipynb"&gt;Notebook&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/06-IntroCV/lab/README.md"&gt;Lab&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;07&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/07-ConvNets/README.md"&gt;Convolutional Neural Networks&lt;/a&gt; &amp;amp; &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/07-ConvNets/CNN_Architectures.md"&gt;CNN Architectures&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/07-ConvNets/ConvNetsPyTorch.ipynb"&gt;PyTorch&lt;/a&gt; /&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/07-ConvNets/ConvNetsTF.ipynb"&gt;TensorFlow&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/07-ConvNets/lab/README.md"&gt;Lab&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;08&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/08-TransferLearning/README.md"&gt;Pre-trained Networks and Transfer Learning&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/08-TransferLearning/TrainingTricks.md"&gt;Training Tricks&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/08-TransferLearning/TransferLearningPyTorch.ipynb"&gt;PyTorch&lt;/a&gt; / &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/3-NeuralNetworks/05-Frameworks/IntroKerasTF.ipynb"&gt;TensorFlow&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/08-TransferLearning/lab/README.md"&gt;Lab&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;09&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/09-Autoencoders/README.md"&gt;Autoencoders and VAEs&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/09-Autoencoders/AutoEncodersPyTorch.ipynb"&gt;PyTorch&lt;/a&gt; / &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/09-Autoencoders/AutoencodersTF.ipynb"&gt;TensorFlow&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;10&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/10-GANs/README.md"&gt;Generative Adversarial Networks &amp;amp; Artistic Style Transfer&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/10-GANs/GANPyTorch.ipynb"&gt;PyTorch&lt;/a&gt; / &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/10-GANs/GANTF.ipynb"&gt;TensorFlow&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;11&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/11-ObjectDetection/README.md"&gt;Object Detection&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/11-ObjectDetection/ObjectDetection.ipynb"&gt;TensorFlow&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/11-ObjectDetection/lab/README.md"&gt;Lab&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;12&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/12-Segmentation/README.md"&gt;Semantic Segmentation. U-Net&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/12-Segmentation/SemanticSegmentationPytorch.ipynb"&gt;PyTorch&lt;/a&gt; / &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/12-Segmentation/SemanticSegmentationTF.ipynb"&gt;TensorFlow&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;V&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/5-NLP/README.md"&gt;&lt;strong&gt;Natural Language Processing&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://docs.microsoft.com/learn/modules/intro-natural-language-processing-pytorch/?WT.mc_id=academic-77998-cacaste"&gt;PyTorch&lt;/a&gt; /&lt;a href="https://docs.microsoft.com/learn/modules/intro-natural-language-processing-TensorFlow/?WT.mc_id=academic-77998-cacaste"&gt;TensorFlow&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://learn.microsoft.com/en-us/collections/7w28iy2xrqzdj0?WT.mc_id=academic-77998-bethanycheum"&gt;Explore Natural Language Processing on Microsoft Azure&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;13&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/5-NLP/13-TextRep/README.md"&gt;Text Representation. Bow/TF-IDF&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/microsoft/AI-For-Beginners/raw/main/lessons/5-NLP/13-TextRep/TextRepresentationPyTorch.ipynb"&gt;PyTorch&lt;/a&gt; / &lt;a href="https://github.com/microsoft/AI-For-Beginners/raw/main/lessons/5-NLP/13-TextRep/TextRepresentationTF.ipynb"&gt;TensorFlow&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;14&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/5-NLP/14-Embeddings/README.md"&gt;Semantic word embeddings. Word2Vec and GloVe&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/microsoft/AI-For-Beginners/raw/main/lessons/5-NLP/14-Embeddings/EmbeddingsPyTorch.ipynb"&gt;PyTorch&lt;/a&gt; / &lt;a href="https://github.com/microsoft/AI-For-Beginners/raw/main/lessons/5-NLP/14-Embeddings/EmbeddingsTF.ipynb"&gt;TensorFlow&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;15&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/5-NLP/15-LanguageModeling/README.md"&gt;Language Modeling. Training your own embeddings&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/microsoft/AI-For-Beginners/raw/main/lessons/5-NLP/15-LanguageModeling/CBoW-PyTorch.ipynb"&gt;PyTorch&lt;/a&gt; / &lt;a href="https://github.com/microsoft/AI-For-Beginners/raw/main/lessons/5-NLP/15-LanguageModeling/CBoW-TF.ipynb"&gt;TensorFlow&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/5-NLP/15-LanguageModeling/lab/README.md"&gt;Lab&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;16&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/5-NLP/16-RNN/README.md"&gt;Recurrent Neural Networks&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/microsoft/AI-For-Beginners/raw/main/lessons/5-NLP/16-RNN/RNNPyTorch.ipynb"&gt;PyTorch&lt;/a&gt; / &lt;a href="https://github.com/microsoft/AI-For-Beginners/raw/main/lessons/5-NLP/16-RNN/RNNTF.ipynb"&gt;TensorFlow&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;17&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/5-NLP/17-GenerativeNetworks/README.md"&gt;Generative Recurrent Networks&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/microsoft/AI-For-Beginners/raw/main/lessons/5-NLP/17-GenerativeNetworks/GenerativePyTorch.ipynb"&gt;PyTorch&lt;/a&gt; / &lt;a href="https://github.com/microsoft/AI-For-Beginners/raw/main/lessons/5-NLP/17-GenerativeNetworks/GenerativeTF.ipynb"&gt;TensorFlow&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/5-NLP/17-GenerativeNetworks/lab/README.md"&gt;Lab&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;18&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/5-NLP/18-Transformers/README.md"&gt;Transformers. BERT.&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/microsoft/AI-For-Beginners/raw/main/lessons/5-NLP/18-Transformers/TransformersPyTorch.ipynb"&gt;PyTorch&lt;/a&gt; /&lt;a href="https://github.com/microsoft/AI-For-Beginners/raw/main/lessons/5-NLP/18-Transformers/TransformersTF.ipynb"&gt;TensorFlow&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;19&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/5-NLP/19-NER/README.md"&gt;Named Entity Recognition&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://microsoft.github.io/AI-For-Beginners/lessons/5-NLP/19-NER/NER-TF.ipynb"&gt;TensorFlow&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/5-NLP/19-NER/lab/README.md"&gt;Lab&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;20&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/5-NLP/20-LangModels/README.md"&gt;Large Language Models, Prompt Programming and Few-Shot Tasks&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://microsoft.github.io/AI-For-Beginners/lessons/5-NLP/20-LangModels/GPT-PyTorch.ipynb"&gt;PyTorch&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;VI&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;Other AI Techniques&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;21&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/6-Other/21-GeneticAlgorithms/README.md"&gt;Genetic Algorithms&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/6-Other/21-GeneticAlgorithms/Genetic.ipynb"&gt;Notebook&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;22&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/6-Other/22-DeepRL/README.md"&gt;Deep Reinforcement Learning&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/6-Other/22-DeepRL/CartPole-RL-PyTorch.ipynb"&gt;PyTorch&lt;/a&gt; /&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/6-Other/22-DeepRL/CartPole-RL-TF.ipynb"&gt;TensorFlow&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/6-Other/22-DeepRL/lab/README.md"&gt;Lab&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;23&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/6-Other/23-MultiagentSystems/README.md"&gt;Multi-Agent Systems&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;VII&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;AI Ethics&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;24&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/7-Ethics/README.md"&gt;AI Ethics and Responsible AI&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://docs.microsoft.com/learn/paths/responsible-ai-business-principles/?WT.mc_id=academic-77998-cacaste"&gt;Microsoft Learn: Responsible AI Principles&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;IX&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;Extras&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;25&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/X-Extras/X1-MultiModal/README.md"&gt;Multi-Modal Networks, CLIP and VQGAN&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/X-Extras/X1-MultiModal/Clip.ipynb"&gt;Notebook&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Each lesson contains&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Pre-reading material&lt;/li&gt; 
 &lt;li&gt;Executable Jupyter Notebooks, which are often specific to the framework (&lt;strong&gt;PyTorch&lt;/strong&gt; or &lt;strong&gt;TensorFlow&lt;/strong&gt;). The executable notebook also contains a lot of theoretical material, so to understand the topic you need to go through at least one version of the notebook (either PyTorch or TensorFlow).&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Labs&lt;/strong&gt; available for some topics, which give you an opportunity to try applying the material you have learned to a specific problem.&lt;/li&gt; 
 &lt;li&gt;Some sections contain links to &lt;a href="https://learn.microsoft.com/en-us/collections/7w28iy2xrqzdj0?WT.mc_id=academic-77998-bethanycheum"&gt;&lt;strong&gt;MS Learn&lt;/strong&gt;&lt;/a&gt; modules that cover related topics.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;We have created a &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/0-course-setup/setup.md"&gt;setup lesson&lt;/a&gt; to help you with setting up your development environment. - For Educators, we have created a &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/0-course-setup/for-teachers.md"&gt;curricula setup lesson&lt;/a&gt; for you too!&lt;/li&gt; 
 &lt;li&gt;How to &lt;a href="https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/0-course-setup/how-to-run.md"&gt;Run the code in a VSCode or a Codepace&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Follow these steps:&lt;/p&gt; 
&lt;p&gt;Fork the Repository: Click on the "Fork" button at the top-right corner of this page.&lt;/p&gt; 
&lt;p&gt;Clone the Repository: &lt;code&gt;git clone https://github.com/microsoft/AI-For-Beginners.git&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;Don't forget to star (🌟) this repo to find it easier later.&lt;/p&gt; 
&lt;h2&gt;Meet other Learners&lt;/h2&gt; 
&lt;p&gt;Join our &lt;a href="https://aka.ms/genai-discord?WT.mc_id=academic-105485-bethanycheum"&gt;official AI Discord server&lt;/a&gt; to meet and network with other learners taking this course and get support.&lt;/p&gt; 
&lt;p&gt;If you have product feedback or questions whilst building visit our &lt;a href="https://aka.ms/foundry/forum"&gt;Azure AI Foundry Developer Forum&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Quizzes&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;A note about quizzes&lt;/strong&gt;: All quizzes are contained in the Quiz-app folder in etc\quiz-app, or &lt;a href="https://ff-quizzes.netlify.app/"&gt;Online Here&lt;/a&gt; They are linked from within the lessons the quiz app can be run locally or deployed to Azure; follow the instruction in the &lt;code&gt;quiz-app&lt;/code&gt; folder. They are gradually being localized.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Help Wanted&lt;/h2&gt; 
&lt;p&gt;Do you have suggestions or found spelling or code errors? Raise an issue or create a pull request.&lt;/p&gt; 
&lt;h2&gt;Special Thanks&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;✍️ Primary Author:&lt;/strong&gt; &lt;a href="http://soshnikov.com"&gt;Dmitry Soshnikov&lt;/a&gt;, PhD&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;🔥 Editor:&lt;/strong&gt; &lt;a href="https://twitter.com/jenlooper"&gt;Jen Looper&lt;/a&gt;, PhD&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;🎨 Sketchnote illustrator:&lt;/strong&gt; &lt;a href="https://twitter.com/girlie_mac"&gt;Tomomi Imura&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;✅ Quiz Creator:&lt;/strong&gt; &lt;a href="https://github.com/CinnamonXI"&gt;Lateefah Bello&lt;/a&gt;, &lt;a href="https://studentambassadors.microsoft.com/"&gt;MLSA&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;🙏 Core Contributors:&lt;/strong&gt; &lt;a href="https://github.com/Pe4enIks"&gt;Evgenii Pishchik&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Other Curricula&lt;/h2&gt; 
&lt;p&gt;Our team produces other curricula! Check out:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://aka.ms/genai-beginners"&gt;Generative AI for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/microsoft/Generative-AI-for-beginners-dotnet"&gt;Generative AI for Beginners .NET&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/microsoft/generative-ai-with-javascript"&gt;Generative AI with JavaScript&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/microsoft/Generative-AI-for-beginners-java"&gt;Generative AI with Java&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://aka.ms/ai-beginners"&gt;AI for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://aka.ms/datascience-beginners"&gt;Data Science for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://aka.ms/ml-beginners"&gt;ML for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/microsoft/Security-101"&gt;Cybersecurity for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://aka.ms/webdev-beginners"&gt;Web Dev for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://aka.ms/iot-beginners"&gt;IoT for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/microsoft/xr-development-for-beginners"&gt;XR Development for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/microsoft/Mastering-GitHub-Copilot-for-Paired-Programming"&gt;Mastering GitHub Copilot for Agentic use&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/microsoft/mastering-github-copilot-for-dotnet-csharp-developers"&gt;Mastering GitHub Copilot for C#/.NET Developers&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/microsoft/CopilotAdventures"&gt;Choose Your Own Copilot Adventure&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>OpenZeppelin/openzeppelin-contracts</title>
      <link>https://github.com/OpenZeppelin/openzeppelin-contracts</link>
      <description>&lt;p&gt;OpenZeppelin Contracts is a library for secure smart contract development.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;&lt;img src="https://raw.githubusercontent.com/OpenZeppelin/openzeppelin-contracts/master/logo.svg?sanitize=true" alt="OpenZeppelin" height="40px" /&gt;&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://github.com/OpenZeppelin/openzeppelin-contracts/releases/latest"&gt;&lt;img src="https://img.shields.io/github/v/tag/OpenZeppelin/openzeppelin-contracts.svg?filter=v*&amp;amp;sort=semver&amp;amp;label=github" alt="Github Release" /&gt;&lt;/a&gt; &lt;a href="https://www.npmjs.org/package/@openzeppelin/contracts"&gt;&lt;img src="https://img.shields.io/npm/v/@openzeppelin/contracts.svg?sanitize=true" alt="NPM Package" /&gt;&lt;/a&gt; &lt;a href="https://codecov.io/gh/OpenZeppelin/openzeppelin-contracts"&gt;&lt;img src="https://codecov.io/gh/OpenZeppelin/openzeppelin-contracts/graph/badge.svg?sanitize=true" alt="Coverage Status" /&gt;&lt;/a&gt; &lt;a href="https://www.gitpoap.io/gh/OpenZeppelin/openzeppelin-contracts"&gt;&lt;img src="https://public-api.gitpoap.io/v1/repo/OpenZeppelin/openzeppelin-contracts/badge" alt="GitPOAPs" /&gt;&lt;/a&gt; &lt;a href="https://docs.openzeppelin.com/contracts"&gt;&lt;img src="https://img.shields.io/badge/docs-%F0%9F%93%84-yellow" alt="Docs" /&gt;&lt;/a&gt; &lt;a href="https://forum.openzeppelin.com/"&gt;&lt;img src="https://img.shields.io/badge/forum-%F0%9F%92%AC-yellow" alt="Forum" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;A library for secure smart contract development.&lt;/strong&gt; Build on a solid foundation of community-vetted code.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Implementations of standards like &lt;a href="https://docs.openzeppelin.com/contracts/erc20"&gt;ERC20&lt;/a&gt; and &lt;a href="https://docs.openzeppelin.com/contracts/erc721"&gt;ERC721&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Flexible &lt;a href="https://docs.openzeppelin.com/contracts/access-control"&gt;role-based permissioning&lt;/a&gt; scheme.&lt;/li&gt; 
 &lt;li&gt;Reusable &lt;a href="https://docs.openzeppelin.com/contracts/utilities"&gt;Solidity components&lt;/a&gt; to build custom contracts and complex decentralized systems.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span&gt;🧙&lt;/span&gt; &lt;strong&gt;Not sure how to get started?&lt;/strong&gt; Check out &lt;a href="https://wizard.openzeppelin.com/"&gt;Contracts Wizard&lt;/a&gt; — an interactive smart contract generator.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] OpenZeppelin Contracts uses semantic versioning to communicate backwards compatibility of its API and storage layout. For upgradeable contracts, the storage layout of different major versions should be assumed incompatible, for example, it is unsafe to upgrade from 4.9.3 to 5.0.0. Learn more at &lt;a href="https://docs.openzeppelin.com/contracts/backwards-compatibility"&gt;Backwards Compatibility&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Overview&lt;/h2&gt; 
&lt;h3&gt;Installation&lt;/h3&gt; 
&lt;h4&gt;Hardhat (npm)&lt;/h4&gt; 
&lt;pre&gt;&lt;code&gt;$ npm install @openzeppelin/contracts
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Foundry (git)&lt;/h4&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!WARNING] When installing via git, it is a common error to use the &lt;code&gt;master&lt;/code&gt; branch. This is a development branch that should be avoided in favor of tagged releases. The release process involves security measures that the &lt;code&gt;master&lt;/code&gt; branch does not guarantee.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!WARNING] Foundry installs the latest version initially, but subsequent &lt;code&gt;forge update&lt;/code&gt; commands will use the &lt;code&gt;master&lt;/code&gt; branch.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;pre&gt;&lt;code&gt;$ forge install OpenZeppelin/openzeppelin-contracts
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Add &lt;code&gt;@openzeppelin/contracts/=lib/openzeppelin-contracts/contracts/&lt;/code&gt; in &lt;code&gt;remappings.txt&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;Usage&lt;/h3&gt; 
&lt;p&gt;Once installed, you can use the contracts in the library by importing them:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-solidity"&gt;pragma solidity ^0.8.20;

import {ERC721} from "@openzeppelin/contracts/token/ERC721/ERC721.sol";

contract MyCollectible is ERC721 {
    constructor() ERC721("MyCollectible", "MCO") {
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;em&gt;If you're new to smart contract development, head to &lt;a href="https://docs.openzeppelin.com/learn/developing-smart-contracts"&gt;Developing Smart Contracts&lt;/a&gt; to learn about creating a new project and compiling your contracts.&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;To keep your system secure, you should &lt;strong&gt;always&lt;/strong&gt; use the installed code as-is, and neither copy-paste it from online sources nor modify it yourself. The library is designed so that only the contracts and functions you use are deployed, so you don't need to worry about it needlessly increasing gas costs.&lt;/p&gt; 
&lt;h2&gt;Learn More&lt;/h2&gt; 
&lt;p&gt;The guides in the &lt;a href="https://docs.openzeppelin.com/contracts"&gt;documentation site&lt;/a&gt; will teach about different concepts, and how to use the related contracts that OpenZeppelin Contracts provides:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.openzeppelin.com/contracts/access-control"&gt;Access Control&lt;/a&gt;: decide who can perform each of the actions on your system.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.openzeppelin.com/contracts/tokens"&gt;Tokens&lt;/a&gt;: create tradeable assets or collectibles for popular ERC standards like ERC-20, ERC-721, ERC-1155, and ERC-6909.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.openzeppelin.com/contracts/utilities"&gt;Utilities&lt;/a&gt;: generic useful tools including non-overflowing math, signature verification, and trustless paying systems.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The &lt;a href="https://docs.openzeppelin.com/contracts/api/token/ERC20"&gt;full API&lt;/a&gt; is also thoroughly documented, and serves as a great reference when developing your smart contract application. You can also ask for help or follow Contracts' development in the &lt;a href="https://forum.openzeppelin.com"&gt;community forum&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Finally, you may want to take a look at the &lt;a href="https://blog.openzeppelin.com/"&gt;guides on our blog&lt;/a&gt;, which cover several common use cases and good practices. The following articles provide great background reading, though please note that some of the referenced tools have changed, as the tooling in the ecosystem continues to rapidly evolve.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://blog.openzeppelin.com/the-hitchhikers-guide-to-smart-contracts-in-ethereum-848f08001f05"&gt;The Hitchhiker’s Guide to Smart Contracts in Ethereum&lt;/a&gt; will help you get an overview of the various tools available for smart contract development, and help you set up your environment.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://blog.openzeppelin.com/a-gentle-introduction-to-ethereum-programming-part-1-783cc7796094"&gt;A Gentle Introduction to Ethereum Programming, Part 1&lt;/a&gt; provides very useful information on an introductory level, including many basic concepts from the Ethereum platform.&lt;/li&gt; 
 &lt;li&gt;For a more in-depth dive, you may read the guide &lt;a href="https://blog.openzeppelin.com/designing-the-architecture-for-your-ethereum-application-9cec086f8317"&gt;Designing the Architecture for Your Ethereum Application&lt;/a&gt;, which discusses how to better structure your application and its relationship to the real world.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Security&lt;/h2&gt; 
&lt;p&gt;This project is maintained by &lt;a href="https://openzeppelin.com"&gt;OpenZeppelin&lt;/a&gt; with the goal of providing a secure and reliable library of smart contract components for the ecosystem. We address security through risk management in various areas such as engineering and open source best practices, scoping and API design, multi-layered review processes, and incident response preparedness.&lt;/p&gt; 
&lt;p&gt;The &lt;a href="https://contracts.openzeppelin.com/security"&gt;OpenZeppelin Contracts Security Center&lt;/a&gt; contains more details about the secure development process.&lt;/p&gt; 
&lt;p&gt;The security policy is detailed in &lt;a href="https://raw.githubusercontent.com/OpenZeppelin/openzeppelin-contracts/master/SECURITY.md"&gt;&lt;code&gt;SECURITY.md&lt;/code&gt;&lt;/a&gt; as well, and specifies how you can report security vulnerabilities, which versions will receive security patches, and how to stay informed about them. We run a &lt;a href="https://immunefi.com/bounty/openzeppelin"&gt;bug bounty program on Immunefi&lt;/a&gt; to reward the responsible disclosure of vulnerabilities.&lt;/p&gt; 
&lt;p&gt;The engineering guidelines we follow to promote project quality can be found in &lt;a href="https://raw.githubusercontent.com/OpenZeppelin/openzeppelin-contracts/master/GUIDELINES.md"&gt;&lt;code&gt;GUIDELINES.md&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Past audits can be found in &lt;a href="https://raw.githubusercontent.com/OpenZeppelin/openzeppelin-contracts/master/audits"&gt;&lt;code&gt;audits/&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Smart contracts are a nascent technology and carry a high level of technical risk and uncertainty. Although OpenZeppelin is well known for its security audits, using OpenZeppelin Contracts is not a substitute for a security audit.&lt;/p&gt; 
&lt;p&gt;OpenZeppelin Contracts is made available under the MIT License, which disclaims all warranties in relation to the project and which limits the liability of those that contribute and maintain the project, including OpenZeppelin. As set out further in the Terms, you acknowledge that you are solely responsible for any use of OpenZeppelin Contracts and you assume all risks associated with any such use.&lt;/p&gt; 
&lt;h2&gt;Contribute&lt;/h2&gt; 
&lt;p&gt;OpenZeppelin Contracts exists thanks to its contributors. There are many ways you can participate and help build high quality software. Check out the &lt;a href="https://raw.githubusercontent.com/OpenZeppelin/openzeppelin-contracts/master/CONTRIBUTING.md"&gt;contribution guide&lt;/a&gt;!&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;OpenZeppelin Contracts is released under the &lt;a href="https://raw.githubusercontent.com/OpenZeppelin/openzeppelin-contracts/master/LICENSE"&gt;MIT License&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Legal&lt;/h2&gt; 
&lt;p&gt;Your use of this Project is governed by the terms found at &lt;a href="http://www.openzeppelin.com/tos"&gt;www.openzeppelin.com/tos&lt;/a&gt; (the "Terms").&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>WECENG/ticket-purchase</title>
      <link>https://github.com/WECENG/ticket-purchase</link>
      <description>&lt;p&gt;大麦自动抢票，支持人员、城市、日期场次、价格选择&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;大麦抢票脚本 V1.0&lt;/h1&gt; 
&lt;h3&gt;特征&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;自动无延时抢票&lt;/li&gt; 
 &lt;li&gt;支持人员、城市、日期场次、价格选择&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;功能介绍&lt;/h2&gt; 
&lt;p&gt;通过selenium打开页面进行登录，模拟用户购票流程自动购票&lt;/p&gt; 
&lt;p&gt;其流程图如下:&lt;/p&gt; 
&lt;img src="img/大麦抢票流程.png" width="50%" height="50%" /&gt; 
&lt;h2&gt;准备工作&lt;/h2&gt; 
&lt;h3&gt;1. 配置环境&lt;/h3&gt; 
&lt;h4&gt;1.1安装python3环境&lt;/h4&gt; 
&lt;p&gt;&lt;strong&gt;Windows&lt;/strong&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;访问Python官方网站：&lt;a href="https://www.python.org/downloads/windows/"&gt;https://www.python.org/downloads/windows/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;下载最新的Python 3.9+版本的安装程序。&lt;/li&gt; 
 &lt;li&gt;运行安装程序。&lt;/li&gt; 
 &lt;li&gt;在安装程序中，确保勾选 "Add Python X.X to PATH" 选项，这将自动将Python添加到系统环境变量中，方便在命令行中使用Python。&lt;/li&gt; 
 &lt;li&gt;完成安装后，你可以在命令提示符或PowerShell中输入 &lt;code&gt;python3&lt;/code&gt; 来启动Python解释器。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;macOS&lt;/strong&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;你可以使用Homebrew来安装Python 3。&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;安装Homebrew（如果未安装）：打开终端并运行以下命令：&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;/bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;安装Python 3：运行以下命令来安装Python 3：&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;brew install python@3
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;1.2 安装所需要的环境&lt;/h4&gt; 
&lt;p&gt;在命令窗口输入如下指令&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;pip3 install selenium
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;1.3 下载google chrome浏览器&lt;/h4&gt; 
&lt;p&gt;下载地址: &lt;a href="https://www.google.cn/intl/zh-CN/chrome/?brand=YTUH&amp;amp;gclid=Cj0KCQjwj5mpBhDJARIsAOVjBdoV_1sBwdqKGHV3rUU1vJmNKZdy5QNzbRT8F5O0-_jq1WHXurE8a7MaAkWrEALw_wcB&amp;amp;gclsrc=aw.ds"&gt;https://www.google.cn/intl/zh-CN/chrome/?brand=YTUH&amp;amp;gclid=Cj0KCQjwj5mpBhDJARIsAOVjBdoV_1sBwdqKGHV3rUU1vJmNKZdy5QNzbRT8F5O0-_jq1WHXurE8a7MaAkWrEALw_wcB&amp;amp;gclsrc=aw.ds&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;2. 修改配置文件&lt;/h3&gt; 
&lt;p&gt;在运行程序之前，需要先修改&lt;code&gt;config.json&lt;/code&gt;文件。该文件用于指定用户需要抢票的相关信息，包括演唱会的场次、观演的人员、城市、日期、价格等。文件结果如下图所示：&lt;/p&gt; 
&lt;img src="https://raw.githubusercontent.com/WECENG/ticket-purchase/master/img/config_json.png" width="50%" height="50%" /&gt; 
&lt;h4&gt;2.1 文件内容说明&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;index_url&lt;/code&gt;为大麦网的地址，&lt;strong&gt;无需修改&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;login_url&lt;/code&gt;为大麦网的登录地址，&lt;strong&gt;无需修改&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;target_url&lt;/code&gt;为用户需要抢的演唱会票的目标地址，&lt;strong&gt;待修改&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;users&lt;/code&gt;为观演人的姓名，&lt;strong&gt;观演人需要用户在手机大麦APP中先填写好，然后再填入该配置文件中&lt;/strong&gt;，&lt;strong&gt;待修改&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;city&lt;/code&gt;为城市，&lt;strong&gt;如果用户需要抢的演唱会票需要选择城市，请把城市填入此处。如无需选择，则不填&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;date&lt;/code&gt;为场次日期，&lt;strong&gt;待修改，可多选&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;price&lt;/code&gt;为票档的价格，&lt;strong&gt;待修改，可多选&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;if_commit_order&lt;/code&gt;为是否要自动提交订单，&lt;strong&gt;改成 true&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;if_listen为是否回流监听，&lt;strong&gt;改成true&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;2.2 示例说明&lt;/h4&gt; 
&lt;p&gt;进入大麦网&lt;a href="https://www.damai.cn/%EF%BC%8C%E9%80%89%E6%8B%A9%E4%BD%A0%E9%9C%80%E8%A6%81%E6%8A%A2%E7%A5%A8%E7%9A%84%E6%BC%94%E5%94%B1%E4%BC%9A%E3%80%82%E5%81%87%E8%AE%BE%E5%A6%82%E4%B8%8B%E5%9B%BE%E6%89%80%E7%A4%BA%EF%BC%9A"&gt;https://www.damai.cn/，选择你需要抢票的演唱会。假设如下图所示：&lt;/a&gt;&lt;/p&gt; 
&lt;img src="https://raw.githubusercontent.com/WECENG/ticket-purchase/master/img/example.png" width="50%" height="50%" /&gt; 
&lt;p&gt;接下来按照下图的标注对配置文件进行修改：&lt;/p&gt; 
&lt;img src="https://raw.githubusercontent.com/WECENG/ticket-purchase/master/img/example_detail.png" width="50%" height="50%" /&gt; 
&lt;p&gt;最终&lt;code&gt;config.json&lt;/code&gt;的文件内容如下：&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "index_url": "https://www.damai.cn/",
  "login_url": "https://passport.damai.cn/login?ru=https%3A%2F%2Fwww.damai.cn%2F",
  "target_url": "https://detail.damai.cn/item.htm?spm=a2oeg.home.card_0.ditem_1.591b23e1JQGWHg&amp;amp;id=740680932762",
  "users": [
    "名字1",
    "名字2"
  ],
  "city": "广州",
  "date": "2023-10-28",
  "price": "1039",
  "if_listen":true,
  "if_commit_order": true
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;3.运行程序&lt;/h3&gt; 
&lt;p&gt;运行程序开始抢票，进入命令窗口，执行如下命令：&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;cd damai
python3 damai.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;大麦app抢票&lt;/h1&gt; 
&lt;p&gt;大麦app抢票脚本需要依赖appium，因此需要现在安装appium server&amp;amp;client环境，步骤如下：&lt;/p&gt; 
&lt;h2&gt;appium server&lt;/h2&gt; 
&lt;h3&gt;下载&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;先安装好node环境（具备npm）node版本号18.0.0&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;先下载并安装好android sdk，并配置环境变量（appium server运行需依赖android sdk)&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;下载appium&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;npm install -g appium
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;查看appium是否安装成功&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;appium -v
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;下载UiAutomator2驱动&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;npm install appium-uiautomator2-driver
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;​ 可能会遇到如下错误：&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-tex"&gt;➜  xcode git:(master) ✗ npm install appium-uiautomator2-driver

npm ERR! code 1
npm ERR! path /Users/chenweicheng/Documents/xcode/node_modules/appium-uiautomator2-driver/node_modules/appium-chromedriver
npm ERR! command failed
npm ERR! command sh -c node install-npm.js
npm ERR! [11:57:54] Error installing Chromedriver: Request failed with status code 404
npm ERR! [11:57:54] AxiosError: Request failed with status code 404
npm ERR!     at settle (/Users/chenweicheng/Documents/xcode/node_modules/appium-uiautomator2-driver/node_modules/axios/lib/core/settle.js:19:12)
npm ERR!     at IncomingMessage.handleStreamEnd (/Users/chenweicheng/Documents/xcode/node_modules/appium-uiautomator2-driver/node_modules/axios/lib/adapters/http.js:572:11)
npm ERR!     at IncomingMessage.emit (node:events:539:35)
npm ERR!     at endReadableNT (node:internal/streams/readable:1344:12)
npm ERR!     at processTicksAndRejections (node:internal/process/task_queues:82:21)
npm ERR! [11:57:54] Downloading Chromedriver can be skipped by setting the'APPIUM_SKIP_CHROMEDRIVER_INSTALL' environment variable.

npm ERR! A complete log of this run can be found in:
npm ERR!     /Users/chenweicheng/.npm/_logs/2023-10-26T03_57_35_950Z-debug-0.log
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;​ 解决办法（添加环境变量，错误原因是没有找到chrome浏览器驱动，忽略即可）&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;export APPIUM_SKIP_CHROMEDRIVER_INSTALL=true
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;启动&lt;/h3&gt; 
&lt;p&gt;启动appium server并使用uiautomator2驱动&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;appium --use-plugins uiautomator2
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;启动成功将出现如下信息：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;[Appium] Welcome to Appium v2.2.1 (REV 2176894a5be5da17a362bf3f20678641a78f4b69)
[Appium] Non-default server args:
[Appium] {
[Appium]   usePlugins: [
[Appium]     'uiautomator2'
[Appium]   ]
[Appium] }
[Appium] Attempting to load driver uiautomator2...
[Appium] Requiring driver at /Users/chenweicheng/Documents/xcode/node_modules/appium-uiautomator2-driver
[Appium] Appium REST http interface listener started on http://0.0.0.0:4723
[Appium] You can provide the following URLs in your client code to connect to this server:
[Appium] 	http://127.0.0.1:4723/ (only accessible from the same host)
[Appium] 	http://172.31.102.45:4723/
[Appium] 	http://198.18.0.1:4723/
[Appium] Available drivers:
[Appium]   - uiautomator2@2.32.3 (automationName 'UiAutomator2')
[Appium] No plugins have been installed. Use the "appium plugin" command to install the one(s) you want to use.
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;其中&lt;code&gt;[Appium] http://127.0.0.1:4723/ (only accessible from the same host) [Appium] http://172.31.102.45:4723/ [Appium] http://198.18.0.1:4723/&lt;/code&gt;为appium server连接地址&lt;/p&gt; 
&lt;h2&gt;appium client&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;先下载并安装好python3和pip3&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;安装&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;pip3 install appium-python-client
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;在代码中引入并使用appium&lt;/p&gt; &lt;pre&gt;&lt;code class="language-python"&gt;from appium import webdriver
from appium.options.common.base import AppiumOptions

device_app_info = AppiumOptions()
device_app_info.set_capability('platformName', 'Android')
device_app_info.set_capability('platformVersion', '10')
device_app_info.set_capability('deviceName', 'YourDeviceName')
device_app_info.set_capability('appPackage', 'cn.damai')
device_app_info.set_capability('appActivity', '.launcher.splash.SplashMainActivity')
device_app_info.set_capability('unicodeKeyboard', True)
device_app_info.set_capability('resetKeyboard', True)
device_app_info.set_capability('noReset', True)
device_app_info.set_capability('newCommandTimeout', 6000)
device_app_info.set_capability('automationName', 'UiAutomator2')

# 连接appium server，server地址查看appium启动信息
driver = webdriver.Remote('http://127.0.0.1:4723', options=device_app_info)

&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;启动脚本程序&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;cd damai_appium
python3 damai_appium.py
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>elastic/elasticsearch</title>
      <link>https://github.com/elastic/elasticsearch</link>
      <description>&lt;p&gt;Free and Open Source, Distributed, RESTful Search Engine&lt;/p&gt;&lt;hr&gt;</description>
    </item>
    
    <item>
      <title>bytedance/Dolphin</title>
      <link>https://github.com/bytedance/Dolphin</link>
      <description>&lt;p&gt;The official repo for “Dolphin: Document Image Parsing via Heterogeneous Anchor Prompting”, ACL, 2025.&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/bytedance/Dolphin/master/assets/dolphin.png" width="300" /&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://arxiv.org/abs/2505.14059"&gt; &lt;img src="https://img.shields.io/badge/Paper-arXiv-red" /&gt; &lt;/a&gt; 
 &lt;a href="https://huggingface.co/ByteDance/Dolphin"&gt; &lt;img src="https://img.shields.io/badge/HuggingFace-Dolphin-yellow" /&gt; &lt;/a&gt; 
 &lt;a href="https://modelscope.cn/models/ByteDance/Dolphin"&gt; &lt;img src="https://img.shields.io/badge/ModelScope-Dolphin-purple" /&gt; &lt;/a&gt; 
 &lt;a href="https://huggingface.co/spaces/ByteDance/Dolphin"&gt; &lt;img src="https://img.shields.io/badge/Demo-Dolphin-blue" /&gt; &lt;/a&gt; 
 &lt;a href="https://github.com/bytedance/Dolphin"&gt; &lt;img src="https://img.shields.io/badge/Code-Github-green" /&gt; &lt;/a&gt; 
 &lt;a href="https://opensource.org/licenses/MIT"&gt; &lt;img src="https://img.shields.io/badge/License-MIT-lightgray" /&gt; &lt;/a&gt; 
 &lt;br /&gt; 
&lt;/div&gt; 
&lt;br /&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/bytedance/Dolphin/master/assets/demo.gif" width="800" /&gt; 
&lt;/div&gt; 
&lt;h1&gt;Dolphin: Document Image Parsing via Heterogeneous Anchor Prompting&lt;/h1&gt; 
&lt;p&gt;Dolphin (&lt;strong&gt;Do&lt;/strong&gt;cument Image &lt;strong&gt;P&lt;/strong&gt;arsing via &lt;strong&gt;H&lt;/strong&gt;eterogeneous Anchor Prompt&lt;strong&gt;in&lt;/strong&gt;g) is a novel multimodal document image parsing model following an analyze-then-parse paradigm. This repository contains the demo code and pre-trained models for Dolphin.&lt;/p&gt; 
&lt;h2&gt;📑 Overview&lt;/h2&gt; 
&lt;p&gt;Document image parsing is challenging due to its complexly intertwined elements such as text paragraphs, figures, formulas, and tables. Dolphin addresses these challenges through a two-stage approach:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;🔍 Stage 1&lt;/strong&gt;: Comprehensive page-level layout analysis by generating element sequence in natural reading order&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;🧩 Stage 2&lt;/strong&gt;: Efficient parallel parsing of document elements using heterogeneous anchors and task-specific prompts&lt;/li&gt; 
&lt;/ol&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/bytedance/Dolphin/master/assets/framework.png" width="680" /&gt; 
&lt;/div&gt; 
&lt;p&gt;Dolphin achieves promising performance across diverse page-level and element-level parsing tasks while ensuring superior efficiency through its lightweight architecture and parallel parsing mechanism.&lt;/p&gt; 
&lt;h2&gt;🚀 Demo&lt;/h2&gt; 
&lt;p&gt;Try our demo on &lt;a href="https://huggingface.co/spaces/ByteDance/Dolphin"&gt;Demo-Dolphin&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;📅 Changelog&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;🔥 &lt;strong&gt;2025.07.10&lt;/strong&gt; Released the &lt;em&gt;Fox-Page Benchmark&lt;/em&gt;, a manually refined subset of the original &lt;a href="https://github.com/ucaslcl/Fox"&gt;Fox dataset&lt;/a&gt;. Download via: &lt;a href="https://pan.baidu.com/share/init?surl=t746ULp6iU5bUraVrPlMSw&amp;amp;pwd=fox1"&gt;Baidu Yun&lt;/a&gt; | &lt;a href="https://drive.google.com/file/d/1yZQZqI34QCqvhB4Tmdl3X_XEvYvQyP0q/view?usp=sharing"&gt;Google Drive&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;🔥 &lt;strong&gt;2025.06.30&lt;/strong&gt; Added &lt;a href="https://github.com/bytedance/Dolphin/raw/master/deployment/tensorrt_llm/ReadMe.md"&gt;TensorRT-LLM support&lt;/a&gt; for accelerated inference！&lt;/li&gt; 
 &lt;li&gt;🔥 &lt;strong&gt;2025.06.27&lt;/strong&gt; Added &lt;a href="https://github.com/bytedance/Dolphin/raw/master/deployment/vllm/ReadMe.md"&gt;vLLM support&lt;/a&gt; for accelerated inference！&lt;/li&gt; 
 &lt;li&gt;🔥 &lt;strong&gt;2025.06.13&lt;/strong&gt; Added multi-page PDF document parsing capability.&lt;/li&gt; 
 &lt;li&gt;🔥 &lt;strong&gt;2025.05.21&lt;/strong&gt; Our demo is released at &lt;a href="http://115.190.42.15:8888/dolphin/"&gt;link&lt;/a&gt;. Check it out!&lt;/li&gt; 
 &lt;li&gt;🔥 &lt;strong&gt;2025.05.20&lt;/strong&gt; The pretrained model and inference code of Dolphin are released.&lt;/li&gt; 
 &lt;li&gt;🔥 &lt;strong&gt;2025.05.16&lt;/strong&gt; Our paper has been accepted by ACL 2025. Paper link: &lt;a href="https://arxiv.org/abs/2505.14059"&gt;arXiv&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;🛠️ Installation&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Clone the repository:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/ByteDance/Dolphin.git
cd Dolphin
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Install the dependencies:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;pip install -r requirements.txt
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Download the pre-trained models using one of the following options:&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Option A: Original Model Format (config-based)&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;Download from &lt;a href="https://pan.baidu.com/s/15zcARoX0CTOHKbW8bFZovQ?pwd=9rpx"&gt;Baidu Yun&lt;/a&gt; or &lt;a href="https://drive.google.com/drive/folders/1PQJ3UutepXvunizZEw-uGaQ0BCzf-mie?usp=sharing"&gt;Google Drive&lt;/a&gt; and put them in the &lt;code&gt;./checkpoints&lt;/code&gt; folder.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Option B: Hugging Face Model Format&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;Visit our Huggingface &lt;a href="https://huggingface.co/ByteDance/Dolphin"&gt;model card&lt;/a&gt;, or download model by:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;# Download the model from Hugging Face Hub
git lfs install
git clone https://huggingface.co/ByteDance/Dolphin ./hf_model
# Or use the Hugging Face CLI
pip install huggingface_hub
huggingface-cli download ByteDance/Dolphin --local-dir ./hf_model
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;⚡ Inference&lt;/h2&gt; 
&lt;p&gt;Dolphin provides two inference frameworks with support for two parsing granularities:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Page-level Parsing&lt;/strong&gt;: Parse the entire document page into a structured JSON and Markdown format&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Element-level Parsing&lt;/strong&gt;: Parse individual document elements (text, table, formula)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;📄 Page-level Parsing&lt;/h3&gt; 
&lt;h4&gt;Using Original Framework (config-based)&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Process a single document image
python demo_page.py --config ./config/Dolphin.yaml --input_path ./demo/page_imgs/page_1.jpeg --save_dir ./results

# Process a single document pdf
python demo_page.py --config ./config/Dolphin.yaml --input_path ./demo/page_imgs/page_6.pdf --save_dir ./results

# Process all documents in a directory
python demo_page.py --config ./config/Dolphin.yaml --input_path ./demo/page_imgs --save_dir ./results

# Process with custom batch size for parallel element decoding
python demo_page.py --config ./config/Dolphin.yaml --input_path ./demo/page_imgs --save_dir ./results --max_batch_size 8
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Using Hugging Face Framework&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Process a single document image
python demo_page_hf.py --model_path ./hf_model --input_path ./demo/page_imgs/page_1.jpeg --save_dir ./results

# Process a single document pdf
python demo_page_hf.py --model_path ./hf_model --input_path ./demo/page_imgs/page_6.pdf --save_dir ./results

# Process all documents in a directory
python demo_page_hf.py --model_path ./hf_model --input_path ./demo/page_imgs --save_dir ./results

# Process with custom batch size for parallel element decoding
python demo_page_hf.py --model_path ./hf_model --input_path ./demo/page_imgs --save_dir ./results --max_batch_size 16
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;🧩 Element-level Parsing&lt;/h3&gt; 
&lt;h4&gt;Using Original Framework (config-based)&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Process a single table image
python demo_element.py --config ./config/Dolphin.yaml --input_path ./demo/element_imgs/table_1.jpeg --element_type table

# Process a single formula image
python demo_element.py --config ./config/Dolphin.yaml --input_path ./demo/element_imgs/line_formula.jpeg --element_type formula

# Process a single text paragraph image
python demo_element.py --config ./config/Dolphin.yaml --input_path ./demo/element_imgs/para_1.jpg --element_type text
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Using Hugging Face Framework&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Process a single table image
python demo_element_hf.py --model_path ./hf_model --input_path ./demo/element_imgs/table_1.jpeg --element_type table

# Process a single formula image
python demo_element_hf.py --model_path ./hf_model --input_path ./demo/element_imgs/line_formula.jpeg --element_type formula

# Process a single text paragraph image
python demo_element_hf.py --model_path ./hf_model --input_path ./demo/element_imgs/para_1.jpg --element_type text
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;🌟 Key Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;🔄 Two-stage analyze-then-parse approach based on a single VLM&lt;/li&gt; 
 &lt;li&gt;📊 Promising performance on document parsing tasks&lt;/li&gt; 
 &lt;li&gt;🔍 Natural reading order element sequence generation&lt;/li&gt; 
 &lt;li&gt;🧩 Heterogeneous anchor prompting for different document elements&lt;/li&gt; 
 &lt;li&gt;⏱️ Efficient parallel parsing mechanism&lt;/li&gt; 
 &lt;li&gt;🤗 Support for Hugging Face Transformers for easier integration&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;📮 Notice&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Call for Bad Cases:&lt;/strong&gt; If you have encountered any cases where the model performs poorly, we would greatly appreciate it if you could share them in the issue. We are continuously working to optimize and improve the model.&lt;/p&gt; 
&lt;h2&gt;💖 Acknowledgement&lt;/h2&gt; 
&lt;p&gt;We would like to acknowledge the following open-source projects that provided inspiration and reference for this work:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/clovaai/donut/"&gt;Donut&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/facebookresearch/nougat"&gt;Nougat&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Ucas-HaoranWei/GOT-OCR2.0"&gt;GOT&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/opendatalab/MinerU/tree/master"&gt;MinerU&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/microsoft/Swin-Transformer"&gt;Swin&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/huggingface/transformers"&gt;Hugging Face Transformers&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;📝 Citation&lt;/h2&gt; 
&lt;p&gt;If you find this code useful for your research, please use the following BibTeX entry.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bibtex"&gt;@article{feng2025dolphin,
  title={Dolphin: Document Image Parsing via Heterogeneous Anchor Prompting},
  author={Feng, Hao and Wei, Shu and Fei, Xiang and Shi, Wei and Han, Yingdong and Liao, Lei and Lu, Jinghui and Wu, Binghong and Liu, Qi and Lin, Chunhui and others},
  journal={arXiv preprint arXiv:2505.14059},
  year={2025}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Star History&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://www.star-history.com/#bytedance/Dolphin&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=bytedance/Dolphin&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>knownsec/aipyapp</title>
      <link>https://github.com/knownsec/aipyapp</link>
      <description>&lt;p&gt;AI-Powered Python &amp; Python-Powered AI (Python-Use)&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/3af4e228-79b2-4fa0-a45c-c38276c6db91" alt="logo" /&gt;&lt;/p&gt; 
&lt;h1&gt;Python use&lt;/h1&gt; 
&lt;p&gt;AIPy is an implementation of the Python-use concept, demonstrating its practical value and potential.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Mission&lt;/strong&gt;: unleash the full potential of large language models.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Vision&lt;/strong&gt;: a future where LLMs can think independently and proactively leverage AIPy to solve complex problems.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;What&lt;/h2&gt; 
&lt;p&gt;Python use provides the entire Python execution environment to LLM. Imagine LLM sitting in front of a computer, typing various commands into the Python command-line interpreter, pressing Enter to execute, observing the results, and then typing and executing more code.&lt;/p&gt; 
&lt;p&gt;Unlike Agents, Python use does not define any tools interface. LLM can freely use all the features provided by the Python runtime environment.&lt;/p&gt; 
&lt;h2&gt;Why&lt;/h2&gt; 
&lt;p&gt;If you are a data engineer, you are likely familiar with the following scenarios:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Handling various data file formats: csv/excel, json, html, sqlite, parquet, etc.&lt;/li&gt; 
 &lt;li&gt;Performing operations like data cleaning, transformation, computation, aggregation, sorting, grouping, filtering, analysis, and visualization.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;This process often requires:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Starting Python, importing pandas as pd, and typing a bunch of commands to process data.&lt;/li&gt; 
 &lt;li&gt;Generating a bunch of intermediate temporary files.&lt;/li&gt; 
 &lt;li&gt;Describing your needs to ChatGPT/Claude, copying the generated data processing code, and running it manually.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;So, why not start the Python command-line interpreter, directly describe your data processing needs, and let it be done automatically? The benefits are:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;No need to manually input a bunch of Python commands temporarily.&lt;/li&gt; 
 &lt;li&gt;No need to describe your needs to GPT, copy the program, and run it manually.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;This is the problem Python use aims to solve!&lt;/p&gt; 
&lt;h2&gt;How&lt;/h2&gt; 
&lt;p&gt;Python use (aipython) is a Python command-line interpreter integrated with LLM. You can:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Enter and execute Python commands as usual.&lt;/li&gt; 
 &lt;li&gt;Describe your needs in natural language, and aipython will automatically generate Python commands and execute them.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Moreover, the two modes can access data interchangeably. For example, after aipython processes your natural language commands, you can use standard Python commands to view various data.&lt;/p&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;p&gt;AIPython has two running modes:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Task mode: Very simple and easy to use, just input your task, suitable for users unfamiliar with Python.&lt;/li&gt; 
 &lt;li&gt;Python mode: Suitable for users familiar with Python, allowing both task input and Python commands, ideal for advanced users.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The default running mode is task mode, which can be switched to Python mode using the &lt;code&gt;--python&lt;/code&gt; parameter.&lt;/p&gt; 
&lt;h3&gt;Basic Config&lt;/h3&gt; 
&lt;p&gt;~/.aipyapp/aipyapp.toml:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;[llm.deepseek]
type = "deepseek"
api_key = "Your DeepSeek API Key"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Task Mode&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;uv run aipy&lt;/code&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt; Get the latest posts from Reddit r/LocalLLaMA
......
......
&amp;gt;&amp;gt;&amp;gt; /done
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;code&gt;pip install aipyapp&lt;/code&gt; and run with &lt;code&gt;aipy&lt;/code&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;-&amp;gt; % aipy
🚀 Python use - AIPython (0.1.22) [https://aipy.app]
&amp;gt;&amp;gt; Get the latest posts from Reddit r/LocalLLaMA
......
&amp;gt;&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Python Mode&lt;/h3&gt; 
&lt;h4&gt;Basic Usage&lt;/h4&gt; 
&lt;p&gt;Automatic task processing:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt; ai("Get the title of Google's homepage")
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Automatically Request to Install Third-Party Libraries&lt;/h4&gt; 
&lt;pre&gt;&lt;code&gt;Python use - AIPython (Quit with 'exit()')
&amp;gt;&amp;gt;&amp;gt; ai("Use psutil to list all processes on MacOS")

📦 LLM requests to install third-party packages: ['psutil']
If you agree and have installed, please enter 'y [y/n] (n): y

&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Thanks&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Hei Ge: Product manager/senior user/chief tester&lt;/li&gt; 
 &lt;li&gt;Sonnet 3.7: Generated the first version of the code, which was almost ready to use without modification.&lt;/li&gt; 
 &lt;li&gt;ChatGPT: Provided many suggestions and code snippets, especially for the command-line interface.&lt;/li&gt; 
 &lt;li&gt;Codeium: Intelligent code completion&lt;/li&gt; 
 &lt;li&gt;Copilot: Code improvement suggestions and README translation&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>basecamp/omarchy</title>
      <link>https://github.com/basecamp/omarchy</link>
      <description>&lt;p&gt;Opinionated Arch/Hyprland Setup&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Omarchy&lt;/h1&gt; 
&lt;p&gt;Turn a fresh Arch installation into a fully-configured, beautiful, and modern web development system based on Hyprland by running a single command. That's the one-line pitch for Omarchy (like it was for Omakub). No need to write bespoke configs for every essential tool just to get started or to be up on all the latest command-line tools. Omarchy is an opinionated take on what Linux can be at its best.&lt;/p&gt; 
&lt;p&gt;Read more at &lt;a href="https://omarchy.org"&gt;omarchy.org&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Omarchy is released under the &lt;a href="https://opensource.org/licenses/MIT"&gt;MIT License&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>oauth2-proxy/oauth2-proxy</title>
      <link>https://github.com/oauth2-proxy/oauth2-proxy</link>
      <description>&lt;p&gt;A reverse proxy that provides authentication with Google, Azure, OpenID Connect and many more identity providers.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href="https://github.com/oauth2-proxy/oauth2-proxy/actions/workflows/ci.yml"&gt;&lt;img src="https://github.com/oauth2-proxy/oauth2-proxy/actions/workflows/ci.yml/badge.svg?sanitize=true" alt="Continuous Integration" /&gt;&lt;/a&gt; &lt;a href="https://goreportcard.com/report/github.com/oauth2-proxy/oauth2-proxy"&gt;&lt;img src="https://goreportcard.com/badge/github.com/oauth2-proxy/oauth2-proxy" alt="Go Report Card" /&gt;&lt;/a&gt; &lt;a href="https://godoc.org/github.com/oauth2-proxy/oauth2-proxy"&gt;&lt;img src="https://godoc.org/github.com/oauth2-proxy/oauth2-proxy?status.svg?sanitize=true" alt="GoDoc" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/oauth2-proxy/oauth2-proxy/master/LICENSE"&gt;&lt;img src="https://img.shields.io/badge/license-MIT-blue.svg?sanitize=true" alt="MIT licensed" /&gt;&lt;/a&gt; &lt;a href="https://codeclimate.com/github/oauth2-proxy/oauth2-proxy/maintainability"&gt;&lt;img src="https://api.codeclimate.com/v1/badges/a58ff79407212e2beacb/maintainability" alt="Maintainability" /&gt;&lt;/a&gt; &lt;a href="https://codeclimate.com/github/oauth2-proxy/oauth2-proxy/test_coverage"&gt;&lt;img src="https://api.codeclimate.com/v1/badges/a58ff79407212e2beacb/test_coverage" alt="Test Coverage" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/oauth2-proxy/oauth2-proxy/master/docs/static/img/logos/OAuth2_Proxy_horizontal.svg?sanitize=true" alt="OAuth2 Proxy" /&gt;&lt;/p&gt; 
&lt;p&gt;OAuth2-Proxy is a flexible, open-source tool that can act as either a standalone reverse proxy or a middleware component integrated into existing reverse proxy or load balancer setups. It provides a simple and secure way to protect your web applications with OAuth2 / OIDC authentication. As a reverse proxy, it intercepts requests to your application and redirects users to an OAuth2 provider for authentication. As a middleware, it can be seamlessly integrated into your existing infrastructure to handle authentication for multiple applications.&lt;/p&gt; 
&lt;p&gt;OAuth2-Proxy supports a lot of OAuth2 as well as OIDC providers. Either through a generic OIDC client or a specific implementation for Google, Microsoft Entra ID, GitHub, login.gov and others. Through specialised provider implementations oauth2-proxy can extract more details about the user like preferred usernames and groups. Those details can then be forwarded as HTTP headers to your upstream applications.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/oauth2-proxy/oauth2-proxy/master/docs/static/img/simplified-architecture.svg?sanitize=true" alt="Simplified Architecture" /&gt;&lt;/p&gt; 
&lt;h2&gt;Get Started&lt;/h2&gt; 
&lt;p&gt;OAuth2-Proxy's &lt;a href="https://oauth2-proxy.github.io/oauth2-proxy/installation"&gt;Installation Docs&lt;/a&gt; cover how to install and configure your setup. Additionally you can take a further look at the &lt;a href="https://github.com/oauth2-proxy/oauth2-proxy/tree/master/contrib/local-environment"&gt;example setup files&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Releases&lt;/h2&gt; 
&lt;h3&gt;Binaries&lt;/h3&gt; 
&lt;p&gt;We publish oauth2-proxy as compiled binaries on GitHub for all major architectures as well as more exotic ones like &lt;code&gt;ppc64le&lt;/code&gt; as well as &lt;code&gt;s390x&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Check out the &lt;a href="https://github.com/oauth2-proxy/oauth2-proxy/releases/latest"&gt;latest release&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Images&lt;/h3&gt; 
&lt;p&gt;From &lt;code&gt;v7.6.0&lt;/code&gt; and up the base image has been changed from Alpine to &lt;a href="https://github.com/GoogleContainerTools/distroless"&gt;GoogleContainerTools/distroless&lt;/a&gt;. This image comes with even fewer installed dependencies and thus should improve security. The image therefore is also slightly smaller than Alpine. For debugging purposes (and those who really need it. e.g. &lt;code&gt;armv6&lt;/code&gt;) we still provide images based on Alpine. The tags of these images are suffixed with &lt;code&gt;-alpine&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Since 2023-11-18 we build nightly images directly from the &lt;code&gt;master&lt;/code&gt; branch and provide them at &lt;code&gt;quay.io/oauth2-proxy/oauth2-proxy-nightly&lt;/code&gt;. These images are considered unstable and therefore should &lt;strong&gt;NOT&lt;/strong&gt; be used for production purposes unless you know what you're doing.&lt;/p&gt; 
&lt;h2&gt;Sponsors&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://upload.wikimedia.org/wikipedia/commons/9/96/Microsoft_logo_%282012%29.svg?sanitize=true" alt="Microsoft" /&gt; Microsoft Azure credits for open source projects&lt;/p&gt; 
&lt;p&gt;Would you like to sponsor the project then please contact us at &lt;a href="mailto:sponsors@oauth2-proxy.dev"&gt;sponsors@oauth2-proxy.dev&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Getting Involved&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://gophers.slack.com/archives/CM2RSS25N"&gt;&lt;img src="https://img.shields.io/badge/slack-Gopher_%23oauth2--proxy-red?logo=slack" alt="Slack" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Join the #oauth2-proxy &lt;a href="https://gophers.slack.com/archives/CM2RSS25N"&gt;Slack channel&lt;/a&gt; to chat with other users of oauth2-proxy or reach out to the maintainers directly. Use the &lt;a href="https://invite.slack.golangbridge.org/"&gt;public invite link&lt;/a&gt; to get an invite for the Gopher Slack space.&lt;/p&gt; 
&lt;p&gt;OAuth2-Proxy is a community-driven project. We rely on the contribut️ions of our users to continually improve it. While review times can vary, we appreciate your patience and understanding. As a volunteer-driven project, we strive to keep this project stable and might take longer to merge changes.&lt;/p&gt; 
&lt;p&gt;If you want to contribute to the project. Please see our &lt;a href="https://oauth2-proxy.github.io/oauth2-proxy/community/contribution"&gt;Contributing&lt;/a&gt; guide.&lt;/p&gt; 
&lt;p&gt;Who uses OAuth2-Proxy? Have a look at our new &lt;a href="https://raw.githubusercontent.com/oauth2-proxy/oauth2-proxy/master/ADOPTERS.md"&gt;ADOPTERS&lt;/a&gt; file and feel free to open a PR to add your organisation.&lt;/p&gt; 
&lt;p&gt;Thanks to all the people who already contributed ❤&lt;/p&gt; 
&lt;a href="https://github.com/oauth2-proxy/oauth2-proxy/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=oauth2-proxy/oauth2-proxy&amp;amp;columns=15&amp;amp;max=75" /&gt; &lt;img src="https://img.shields.io/github/contributors/oauth2-proxy/oauth2-proxy" /&gt; &lt;/a&gt; 
&lt;p&gt;Made with &lt;a href="https://contrib.rocks"&gt;contrib.rocks&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Security&lt;/h2&gt; 
&lt;p&gt;If you believe you have found a vulnerability within OAuth2 Proxy or any of its dependencies, please do &lt;strong&gt;NOT&lt;/strong&gt; open an issue or PR on GitHub, please do &lt;strong&gt;NOT&lt;/strong&gt; post any details publicly.&lt;/p&gt; 
&lt;p&gt;Security disclosures &lt;strong&gt;MUST&lt;/strong&gt; be done in private. If you have found an issue that you would like to bring to the attention of the maintainers, please compose an email and send it to the list of people listed in our &lt;a href="https://raw.githubusercontent.com/oauth2-proxy/oauth2-proxy/master/MAINTAINERS"&gt;MAINTAINERS&lt;/a&gt; file.&lt;/p&gt; 
&lt;p&gt;For more details read our full &lt;a href="https://oauth2-proxy.github.io/oauth2-proxy/community/security#security-disclosures"&gt;Security Docs&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Security Notice for v6.0.0 and older&lt;/h3&gt; 
&lt;p&gt;If you are running a version older than v6.0.0 we &lt;strong&gt;strongly recommend&lt;/strong&gt; to the current version.&lt;/p&gt; 
&lt;p&gt;See &lt;a href="https://github.com/oauth2-proxy/oauth2-proxy/security/advisories/GHSA-5m6c-jp6f-2vcv"&gt;open redirect vulnerability&lt;/a&gt; for details.&lt;/p&gt; 
&lt;h2&gt;Repository History&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;2018-11-27:&lt;/strong&gt; This repository was forked from &lt;a href="https://github.com/bitly/oauth2_proxy"&gt;bitly/OAuth2_Proxy&lt;/a&gt;. Versions v3.0.0 and up are from this fork and will have diverged from any changes in the original fork. A list of changes can be seen in the &lt;a href="https://raw.githubusercontent.com/oauth2-proxy/oauth2-proxy/master/CHANGELOG.md"&gt;CHANGELOG&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2020-03-29:&lt;/strong&gt; This project was formerly hosted as &lt;code&gt;pusher/oauth2_proxy&lt;/code&gt; but has been renamed to &lt;code&gt;oauth2-proxy/oauth2-proxy&lt;/code&gt;. Going forward, all images shall be available at &lt;code&gt;quay.io/oauth2-proxy/oauth2-proxy&lt;/code&gt; and binaries will be named &lt;code&gt;oauth2-proxy&lt;/code&gt;.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;OAuth2-Proxy is distributed under &lt;a href="https://raw.githubusercontent.com/oauth2-proxy/oauth2-proxy/master/LICENSE"&gt;The MIT License&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>WebGoat/WebGoat</title>
      <link>https://github.com/WebGoat/WebGoat</link>
      <description>&lt;p&gt;WebGoat is a deliberately insecure application&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;WebGoat: A deliberately insecure Web Application&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://github.com/WebGoat/WebGoat/actions/workflows/build.yml"&gt;&lt;img src="https://github.com/WebGoat/WebGoat/actions/workflows/build.yml/badge.svg?branch=develop" alt="Build" /&gt;&lt;/a&gt; &lt;a href="https://jdk.java.net/"&gt;&lt;img src="https://img.shields.io/badge/java%20jdk-23-green.svg?sanitize=true" alt="java-jdk" /&gt;&lt;/a&gt; &lt;a href="https://owasp.org/projects/"&gt;&lt;img src="https://img.shields.io/badge/OWASP-Lab%20project-f7b73c.svg?sanitize=true" alt="OWASP Labs" /&gt;&lt;/a&gt; &lt;a href="https://github.com/WebGoat/WebGoat/releases/latest"&gt;&lt;img src="https://img.shields.io/github/release/WebGoat/WebGoat.svg?sanitize=true" alt="GitHub release" /&gt;&lt;/a&gt; &lt;a href="https://gitter.im/OWASPWebGoat/community?utm_source=badge&amp;amp;utm_medium=badge&amp;amp;utm_campaign=pr-badge"&gt;&lt;img src="https://badges.gitter.im/OWASPWebGoat/community.svg?sanitize=true" alt="Gitter" /&gt;&lt;/a&gt; &lt;a href="https://github.com/WebGoat/WebGoat/discussions"&gt;&lt;img src="https://img.shields.io/github/discussions/WebGoat/WebGoat" alt="Discussions" /&gt;&lt;/a&gt; &lt;a href="https://conventionalcommits.org"&gt;&lt;img src="https://img.shields.io/badge/Conventional%20Commits-1.0.0-%23FE5196?logo=conventionalcommits&amp;amp;logoColor=white" alt="Conventional Commits" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Introduction&lt;/h1&gt; 
&lt;p&gt;WebGoat is a deliberately insecure web application maintained by &lt;a href="http://www.owasp.org/"&gt;OWASP&lt;/a&gt; designed to teach web application security lessons.&lt;/p&gt; 
&lt;p&gt;This program is a demonstration of common server-side application flaws. The exercises are intended to be used by people to learn about application security and penetration testing techniques.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;WARNING 1:&lt;/strong&gt; &lt;em&gt;While running this program your machine will be extremely vulnerable to attack. You should disconnect from the Internet while using this program.&lt;/em&gt; WebGoat's default configuration binds to localhost to minimize the exposure.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;WARNING 2:&lt;/strong&gt; &lt;em&gt;This program is for educational purposes only. If you attempt these techniques without authorization, you are very likely to get caught. If you are caught engaging in unauthorized hacking, most companies will fire you. Claiming that you were doing security research will not work as that is the first thing that all hackers claim.&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/WebGoat/WebGoat/main/docs/images/webgoat.png" alt="WebGoat" /&gt;&lt;/p&gt; 
&lt;h1&gt;Installation instructions:&lt;/h1&gt; 
&lt;p&gt;For more details check &lt;a href="https://raw.githubusercontent.com/WebGoat/WebGoat/main/CONTRIBUTING.md"&gt;the Contribution guide&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;1. Run using Docker&lt;/h2&gt; 
&lt;p&gt;Already have a browser and ZAP and/or Burp installed on your machine in this case you can run the WebGoat image directly using Docker.&lt;/p&gt; 
&lt;p&gt;Every release is also published on &lt;a href="https://hub.docker.com/r/webgoat/webgoat"&gt;DockerHub&lt;/a&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;docker run -it -p 127.0.0.1:8080:8080 -p 127.0.0.1:9090:9090 webgoat/webgoat
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For some lessons you need the container run in the same timezone. For this you can set the TZ environment variable. E.g.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;docker run -it -p 127.0.0.1:8080:8080 -p 127.0.0.1:9090:9090 -e TZ=America/Boise webgoat/webgoat
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you want to use OWASP ZAP or another proxy, you can no longer use 127.0.0.1 or localhost. but you can use custom host entries. For example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;127.0.0.1 www.webgoat.local www.webwolf.local
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then you can run the container with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;docker run -it -p 127.0.0.1:8080:8080 -p 127.0.0.1:9090:9090 -e WEBGOAT_HOST=www.webgoat.local -e WEBWOLF_HOST=www.webwolf.local -e TZ=America/Boise webgoat/webgoat
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then visit &lt;a href="http://www.webgoat.local:8080/WebGoat/"&gt;http://www.webgoat.local:8080/WebGoat/&lt;/a&gt; and &lt;a href="http://www.webwolf.local:9090/WebWolf/"&gt;http://www.webwolf.local:9090/WebWolf/&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;2. Run using Docker with complete Linux Desktop&lt;/h2&gt; 
&lt;p&gt;Instead of installing tools locally we have a complete Docker image based on running a desktop in your browser. This way you only have to run a Docker image which will give you the best user experience.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;docker run -p 127.0.0.1:3000:3000 webgoat/webgoat-desktop
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;3. Standalone&lt;/h2&gt; 
&lt;p&gt;Download the latest WebGoat release from &lt;a href="https://github.com/WebGoat/WebGoat/releases"&gt;https://github.com/WebGoat/WebGoat/releases&lt;/a&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;export TZ=Europe/Amsterdam # or your timezone
java -Dfile.encoding=UTF-8 -jar webgoat-2023.8.jar
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Click the link in the log to start WebGoat.&lt;/p&gt; 
&lt;h3&gt;3.1 Running on a different port&lt;/h3&gt; 
&lt;p&gt;If for some reason you want to run WebGoat on a different port, you can do so by adding the following parameter:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;java -jar webgoat-2023.8.jar --webgoat.port=8001 --webwolf.port=8002
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For a full overview of all the parameters you can use, please check the [WebGoat properties file](webgoat-container/src/main/resources/application-{webgoat, webwolf}.properties).&lt;/p&gt; 
&lt;h2&gt;4. Run from the sources&lt;/h2&gt; 
&lt;h3&gt;Prerequisites:&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Java 23&lt;/li&gt; 
 &lt;li&gt;Your favorite IDE&lt;/li&gt; 
 &lt;li&gt;Git, or Git support in your IDE&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Open a command shell/window:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-Shell"&gt;git clone git@github.com:WebGoat/WebGoat.git
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Now let's start by compiling the project.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-Shell"&gt;cd WebGoat
git checkout &amp;lt;&amp;lt;branch_name&amp;gt;&amp;gt;
# On Linux/Mac:
./mvnw clean install

# On Windows:
./mvnw.cmd clean install

# Using docker or podman, you can than build the container locally
docker build -f Dockerfile . -t webgoat/webgoat
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Now we are ready to run the project. WebGoat is using Spring Boot.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-Shell"&gt;# On Linux/Mac:
./mvnw spring-boot:run
# On Windows:
./mvnw.cmd spring-boot:run

&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;... you should be running WebGoat on &lt;a href="http://localhost:8080/WebGoat"&gt;http://localhost:8080/WebGoat&lt;/a&gt; momentarily.&lt;/p&gt; 
&lt;p&gt;Note: The above link will redirect you to login page if you are not logged in. LogIn/Create account to proceed.&lt;/p&gt; 
&lt;p&gt;To change the IP address add the following variable to the &lt;code&gt;WebGoat/webgoat-container/src/main/resources/application.properties&lt;/code&gt; file:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;server.address=x.x.x.x
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;4. Run with custom menu&lt;/h2&gt; 
&lt;p&gt;For specialist only. There is a way to set up WebGoat with a personalized menu. You can leave out some menu categories or individual lessons by setting certain environment variables.&lt;/p&gt; 
&lt;p&gt;For instance running as a jar on a Linux/macOS it will look like this:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-Shell"&gt;export TZ=Europe/Amsterdam # or your timezone
export EXCLUDE_CATEGORIES="CLIENT_SIDE,GENERAL,CHALLENGE"
export EXCLUDE_LESSONS="SqlInjectionAdvanced,SqlInjectionMitigations"
java -jar target/webgoat-2023.8-SNAPSHOT.jar
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or in a docker run it would (once this version is pushed into docker hub) look like this:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-Shell"&gt;docker run -d -p 127.0.0.1:8080:8080 -p 127.0.0.1:9090:9090 -e EXCLUDE_CATEGORIES="CLIENT_SIDE,GENERAL,CHALLENGE" -e EXCLUDE_LESSONS="SqlInjectionAdvanced,SqlInjectionMitigations" webgoat/webgoat
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>TanStack/router</title>
      <link>https://github.com/TanStack/router</link>
      <description>&lt;p&gt;🤖 Fully typesafe Router for React (and friends) w/ built-in caching, 1st class search-param APIs, client-side cache integration and isomorphic rendering.&lt;/p&gt;&lt;hr&gt;&lt;img src="https://static.scarf.sh/a.png?x-pxid=d988eb79-b0fc-4a2b-8514-6a1ab932d188" /&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td&gt; &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/TanStack/router/main/media/header_router.png" alt="TanStack Router" /&gt;&lt;/p&gt; &lt;h2&gt;TanStack Router&lt;/h2&gt; &lt;p&gt;A modern router designed for type safety, data‑driven navigation, and seamless developer experience.&lt;/p&gt; 
    &lt;ul&gt; 
     &lt;li&gt;End‑to‑end type safety (routes, params, loaders)&lt;/li&gt; 
     &lt;li&gt;Schema‑driven search params with validation&lt;/li&gt; 
     &lt;li&gt;Built‑in caching, prefetching &amp;amp; invalidation&lt;/li&gt; 
     &lt;li&gt;Nested layouts, transitions &amp;amp; error boundaries&lt;/li&gt; 
    &lt;/ul&gt; &lt;h3&gt;&lt;a href="https://tanstack.com/router"&gt;Read the Router Docs →&lt;/a&gt;&lt;/h3&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/TanStack/router/main/media/header_start.png" alt="TanStack Start" /&gt;&lt;/p&gt; &lt;h2&gt;TanStack Start&lt;/h2&gt; &lt;p&gt;A full‑stack framework built on Router, designed for server rendering, streaming, and production‑ready deployments.&lt;/p&gt; 
    &lt;ul&gt; 
     &lt;li&gt;Full‑document SSR &amp;amp; streaming&lt;/li&gt; 
     &lt;li&gt;Server functions &amp;amp; end‑to‑end type safety&lt;/li&gt; 
     &lt;li&gt;Deployment‑ready bundling &amp;amp; builds&lt;/li&gt; 
     &lt;li&gt;All the power of TanStack Router, plus full‑stack features&lt;/li&gt; 
    &lt;/ul&gt; &lt;h3&gt;&lt;a href="https://tanstack.com/start"&gt;Read the Start Docs →&lt;/a&gt;&lt;/h3&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;br /&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://npmjs.com/package/@tanstack/react-router"&gt; &lt;img src="https://img.shields.io/npm/dm/@tanstack/react-router.svg?sanitize=true" alt="npm downloads" /&gt; &lt;/a&gt; 
 &lt;a href="https://github.com/tanstack/router"&gt; &lt;img src="https://img.shields.io/github/stars/tanstack/router.svg?style=social&amp;amp;label=Star" alt="GitHub stars" /&gt; &lt;/a&gt; 
 &lt;a href="https://bundlephobia.com/result?p=@tanstack/react-router"&gt; &lt;img src="https://badgen.net/bundlephobia/minzip/@tanstack/react-router" alt="Bundle size" /&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://raw.githubusercontent.com/TanStack/router/main/#badge"&gt; &lt;img alt="semantic-release" src="https://img.shields.io/badge/%20%20%F0%9F%93%A6%F0%9F%9A%80-semantic--release-e10079.svg?sanitize=true" /&gt; &lt;/a&gt; 
 &lt;a href="https://bestofjs.org/projects/tanstack-router"&gt;&lt;img alt="Best of JS" src="https://img.shields.io/endpoint?url=https://bestofjs-serverless.now.sh/api/project-badge?fullName=TanStack%2Frouter%26since=daily" /&gt;&lt;/a&gt; 
 &lt;a href="https://twitter.com/tan_stack"&gt;&lt;img src="https://img.shields.io/twitter/follow/tan_stack.svg?style=social" alt="Follow @TanStack" /&gt;&lt;/a&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;h3&gt;&lt;a href="https://github.com/sponsors/tannerlinsley/"&gt;Become a Sponsor!&lt;/a&gt;&lt;/h3&gt; 
&lt;/div&gt; 
&lt;h2&gt;Get Involved&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;We welcome issues and pull requests!&lt;/li&gt; 
 &lt;li&gt;Participate in &lt;a href="https://github.com/TanStack/router/discussions"&gt;GitHub discussions&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Chat with the community on &lt;a href="https://discord.com/invite/WrRKjPJ"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;See &lt;a href="https://raw.githubusercontent.com/TanStack/router/main/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; for setup instructions&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Partners&lt;/h2&gt; 
&lt;table align="center"&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td&gt; &lt;a href="https://www.coderabbit.ai/?via=tanstack&amp;amp;dub_id=aCcEEdAOqqutX6OS"&gt; 
     &lt;picture&gt; 
      &lt;source media="(prefers-color-scheme: dark)" srcset="https://tanstack.com/assets/coderabbit-dark-CMcuvjEy.svg" height="40" /&gt; 
      &lt;source media="(prefers-color-scheme: light)" srcset="https://tanstack.com/assets/coderabbit-light-DVMJ2jHi.svg" height="40" /&gt; 
      &lt;img src="https://tanstack.com/assets/coderabbit-dark-CMcuvjEy.svg?sanitize=true" height="40" alt="CodeRabbit" /&gt; 
     &lt;/picture&gt; &lt;/a&gt; &lt;/td&gt; 
   &lt;td padding="20"&gt; &lt;a href="https://www.cloudflare.com?utm_source=tanstack"&gt; 
     &lt;picture&gt; 
      &lt;source media="(prefers-color-scheme: dark)" srcset="https://tanstack.com/assets/cloudflare-white-DQDB7UaL.svg" height="60" /&gt; 
      &lt;source media="(prefers-color-scheme: light)" srcset="https://tanstack.com/assets/cloudflare-black-CPufaW0B.svg" height="60" /&gt; 
      &lt;img src="https://tanstack.com/assets/cloudflare-black-CPufaW0B.svg?sanitize=true" height="60" alt="Cloudflare" /&gt; 
     &lt;/picture&gt; &lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://netlify.com?utm_source=tanstack"&gt; 
     &lt;picture&gt; 
      &lt;source media="(prefers-color-scheme: dark)" srcset="https://raw.githubusercontent.com/tanstack/tanstack.com/main/src/images/netlify-dark.svg" height="70" /&gt; 
      &lt;source media="(prefers-color-scheme: light)" srcset="https://raw.githubusercontent.com/tannerlinsley/files/master/partners/netlify.svg" height="70" /&gt; 
      &lt;img src="https://raw.githubusercontent.com/tanstack/tanstack.com/main/src/images/netlify-dark.svg?sanitize=true" height="70" alt="Netlify" /&gt; 
     &lt;/picture&gt; &lt;/a&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;a href="https://neon.tech?utm_source=tanstack"&gt; 
     &lt;picture&gt; 
      &lt;source media="(prefers-color-scheme: dark)" srcset="https://raw.githubusercontent.com/tanstack/tanstack.com/main/src/images/neon-dark.svg" height="50" /&gt; 
      &lt;source media="(prefers-color-scheme: light)" srcset="https://raw.githubusercontent.com/tannerlinsley/files/master/partners/neon.svg" height="50" /&gt; 
      &lt;img src="https://raw.githubusercontent.com/tannerlinsley/files/master/partners/neon.svg?sanitize=true" height="50" alt="Neon" /&gt; 
     &lt;/picture&gt; &lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://go.clerk.com/wOwHtuJ"&gt; 
     &lt;picture&gt; 
      &lt;source media="(prefers-color-scheme: dark)" srcset="https://tanstack.com/assets/clerk-logo-dark-CRE22T_2.svg" height="40" /&gt; 
      &lt;source media="(prefers-color-scheme: light)" srcset="https://raw.githubusercontent.com/tannerlinsley/files/master/partners/clerk.svg" height="40" /&gt; 
      &lt;img src="https://tanstack.com/assets/clerk-logo-dark-CRE22T_2.svg?sanitize=true" height="40" alt="Clerk" /&gt; 
     &lt;/picture&gt; &lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://convex.dev?utm_source=tanstack"&gt; 
     &lt;picture&gt; 
      &lt;source media="(prefers-color-scheme: dark)" srcset="https://raw.githubusercontent.com/tanstack/tanstack.com/main/src/images/convex-white.svg" height="30" /&gt; 
      &lt;source media="(prefers-color-scheme: light)" srcset="https://raw.githubusercontent.com/tannerlinsley/files/master/partners/convex.svg" height="30" /&gt; 
      &lt;img src="https://raw.githubusercontent.com/tannerlinsley/files/master/partners/convex.svg?sanitize=true" height="30" alt="Convex" /&gt; 
     &lt;/picture&gt; &lt;/a&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;a href="https://sentry.io?utm_source=tanstack"&gt; 
     &lt;picture&gt; 
      &lt;source media="(prefers-color-scheme: dark)" srcset="https://raw.githubusercontent.com/tanstack/tanstack.com/main/src/images/sentry-wordmark-light.svg" height="50" /&gt; 
      &lt;source media="(prefers-color-scheme: light)" srcset="https://raw.githubusercontent.com/tannerlinsley/files/master/partners/sentry.svg" height="50" /&gt; 
      &lt;img src="https://raw.githubusercontent.com/tannerlinsley/files/master/partners/sentry.svg?sanitize=true" height="50" alt="Sentry" /&gt; 
     &lt;/picture&gt; &lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://www.prisma.io?utm_source=tanstack&amp;amp;via=tanstack"&gt; 
     &lt;picture&gt; 
      &lt;source media="(prefers-color-scheme: dark)" srcset="https://tanstack.com/assets/prisma-dark-DwgDxLwn.svg" height="50" /&gt; 
      &lt;source media="(prefers-color-scheme: light)" srcset="https://tanstack.com/assets/prisma-light-Cloa3Onm.svg" height="50" /&gt; 
      &lt;img src="https://tanstack.com/assets/prisma-dark-DwgDxLwn.svg?sanitize=true" height="50" alt="Prisma" /&gt; 
     &lt;/picture&gt; &lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://strapi.link/tanstack-start"&gt; 
     &lt;picture&gt; 
      &lt;source media="(prefers-color-scheme: dark)" srcset="https://tanstack.com/assets/strapi-dark-CQ84tQTk.svg" height="40" /&gt; 
      &lt;source media="(prefers-color-scheme: light)" srcset="https://tanstack.com/assets/strapi-light-6x7linao.svg" height="40" /&gt; 
      &lt;img src="https://tanstack.com/assets/strapi-dark-CQ84tQTk.svg?sanitize=true" height="40" alt="Strapi" /&gt; 
     &lt;/picture&gt; &lt;/a&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/TanStack/router/main/media/partner_logo.svg?sanitize=true" alt="Router &amp;amp; you?" height="65" /&gt; 
 &lt;p&gt; We're looking for TanStack Router &amp;amp; Start Partners to join our mission! Partner with us to push the boundaries of TanStack Router &amp;amp; Start and build amazing things together. &lt;/p&gt; 
 &lt;a href="mailto:partners@tanstack.com?subject=TanStack Router &amp;amp; Start Partnership"&gt;&lt;b&gt;LET'S CHAT&lt;/b&gt;&lt;/a&gt; 
&lt;/div&gt; 
&lt;h2&gt;Explore the TanStack Ecosystem&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tanstack/config"&gt;&lt;b&gt;TanStack Config&lt;/b&gt;&lt;/a&gt; – Tooling for JS/TS packages&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tanstack/db"&gt;&lt;b&gt;TanStack DB&lt;/b&gt;&lt;/a&gt; – Reactive sync client store&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tanstack/devtools"&gt;&lt;b&gt;TanStack DevTools&lt;/b&gt;&lt;/a&gt; – Unified devtools panel&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tanstack/form"&gt;&lt;b&gt;TanStack Form&lt;/b&gt;&lt;/a&gt; – Type‑safe form state&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tanstack/pacer"&gt;&lt;b&gt;TanStack Pacer&lt;/b&gt;&lt;/a&gt; – Debouncing, throttling, batching &lt;br /&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tanstack/query"&gt;&lt;b&gt;TanStack Query&lt;/b&gt;&lt;/a&gt; – Async state &amp;amp; caching&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tanstack/ranger"&gt;&lt;b&gt;TanStack Ranger&lt;/b&gt;&lt;/a&gt; – Range &amp;amp; slider primitives&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tanstack/store"&gt;&lt;b&gt;TanStack Store&lt;/b&gt;&lt;/a&gt; – Reactive data store&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tanstack/table"&gt;&lt;b&gt;TanStack Table&lt;/b&gt;&lt;/a&gt; – Headless datagrids&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tanstack/virtual"&gt;&lt;b&gt;TanStack Virtual&lt;/b&gt;&lt;/a&gt; – Virtualized rendering&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;… and more at &lt;a href="https://tanstack.com"&gt;&lt;b&gt;TanStack.com »&lt;/b&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;!-- Use the force, Luke --&gt;</description>
    </item>
    
    <item>
      <title>fmtlib/fmt</title>
      <link>https://github.com/fmtlib/fmt</link>
      <description>&lt;p&gt;A modern formatting library&lt;/p&gt;&lt;hr&gt;&lt;img src="https://user-images.githubusercontent.com/576385/156254208-f5b743a9-88cf-439d-b0c0-923d53e8d551.png" alt="{fmt}" width="25%" /&gt; 
&lt;p&gt;&lt;a href="https://github.com/fmtlib/fmt/actions?query=workflow%3Alinux"&gt;&lt;img src="https://github.com/fmtlib/fmt/workflows/linux/badge.svg?sanitize=true" alt="image" /&gt;&lt;/a&gt; &lt;a href="https://github.com/fmtlib/fmt/actions?query=workflow%3Amacos"&gt;&lt;img src="https://github.com/fmtlib/fmt/workflows/macos/badge.svg?sanitize=true" alt="image" /&gt;&lt;/a&gt; &lt;a href="https://github.com/fmtlib/fmt/actions?query=workflow%3Awindows"&gt;&lt;img src="https://github.com/fmtlib/fmt/workflows/windows/badge.svg?sanitize=true" alt="image" /&gt;&lt;/a&gt; &lt;a href="https://bugs.chromium.org/p/oss-fuzz/issues/list?%0Acolspec=ID%20Type%20Component%20Status%20Proj%20Reported%20Owner%20%0ASummary&amp;amp;q=proj%3Dfmt&amp;amp;can=1"&gt;&lt;img src="https://oss-fuzz-build-logs.storage.googleapis.com/badges/fmt.svg?sanitize=true" alt="fmt is continuously fuzzed at oss-fuzz" /&gt;&lt;/a&gt; &lt;a href="https://www.bestpractices.dev/projects/8880"&gt;&lt;img src="https://www.bestpractices.dev/projects/8880/badge" alt="OpenSSF Best Practices" /&gt;&lt;/a&gt; &lt;a href="https://securityscorecards.dev/viewer/?uri=github.com/fmtlib/fmt"&gt;&lt;img src="https://api.securityscorecards.dev/projects/github.com/fmtlib/fmt/badge" alt="image" /&gt;&lt;/a&gt; &lt;a href="https://stackoverflow.com/questions/tagged/fmt"&gt;&lt;img src="https://img.shields.io/badge/stackoverflow-fmt-blue.svg?sanitize=true" alt="Ask questions at StackOverflow with the tag fmt" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;{fmt}&lt;/strong&gt; is an open-source formatting library providing a fast and safe alternative to C stdio and C++ iostreams.&lt;/p&gt; 
&lt;p&gt;If you like this project, please consider donating to one of the funds that help victims of the war in Ukraine: &lt;a href="https://www.stopputin.net/"&gt;https://www.stopputin.net/&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://fmt.dev"&gt;Documentation&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://hackingcpp.com/cpp/libs/fmt.html"&gt;Cheat Sheets&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Q&amp;amp;A: ask questions on &lt;a href="https://stackoverflow.com/questions/tagged/fmt"&gt;StackOverflow with the tag fmt&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Try {fmt} in &lt;a href="https://godbolt.org/z/8Mx1EW73v"&gt;Compiler Explorer&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;Features&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;Simple &lt;a href="https://fmt.dev/latest/api/"&gt;format API&lt;/a&gt; with positional arguments for localization&lt;/li&gt; 
 &lt;li&gt;Implementation of &lt;a href="https://en.cppreference.com/w/cpp/utility/format"&gt;C++20 std::format&lt;/a&gt; and &lt;a href="https://en.cppreference.com/w/cpp/io/print"&gt;C++23 std::print&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://fmt.dev/latest/syntax/"&gt;Format string syntax&lt;/a&gt; similar to Python's &lt;a href="https://docs.python.org/3/library/stdtypes.html#str.format"&gt;format&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Fast IEEE 754 floating-point formatter with correct rounding, shortness and round-trip guarantees using the &lt;a href="https://github.com/jk-jeon/dragonbox"&gt;Dragonbox&lt;/a&gt; algorithm&lt;/li&gt; 
 &lt;li&gt;Portable Unicode support&lt;/li&gt; 
 &lt;li&gt;Safe &lt;a href="https://fmt.dev/latest/api/#printf-formatting"&gt;printf implementation&lt;/a&gt; including the POSIX extension for positional arguments&lt;/li&gt; 
 &lt;li&gt;Extensibility: &lt;a href="https://fmt.dev/latest/api/#formatting-user-defined-types"&gt;support for user-defined types&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;High performance: faster than common standard library implementations of &lt;code&gt;(s)printf&lt;/code&gt;, iostreams, &lt;code&gt;to_string&lt;/code&gt; and &lt;code&gt;to_chars&lt;/code&gt;, see &lt;a href="https://raw.githubusercontent.com/fmtlib/fmt/master/#speed-tests"&gt;Speed tests&lt;/a&gt; and &lt;a href="http://www.zverovich.net/2020/06/13/fast-int-to-string-revisited.html"&gt;Converting a hundred million integers to strings per second&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Small code size both in terms of source code with the minimum configuration consisting of just three files, &lt;code&gt;base.h&lt;/code&gt;, &lt;code&gt;format.h&lt;/code&gt; and &lt;code&gt;format-inl.h&lt;/code&gt;, and compiled code; see &lt;a href="https://raw.githubusercontent.com/fmtlib/fmt/master/#compile-time-and-code-bloat"&gt;Compile time and code bloat&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Reliability: the library has an extensive set of &lt;a href="https://github.com/fmtlib/fmt/tree/master/test"&gt;tests&lt;/a&gt; and is &lt;a href="https://bugs.chromium.org/p/oss-fuzz/issues/list?colspec=ID%20Type%20Component%20Status%20Proj%20Reported%20Owner%20Summary&amp;amp;q=proj%3Dfmt&amp;amp;can=1"&gt;continuously fuzzed&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Safety: the library is fully type-safe, errors in format strings can be reported at compile time, automatic memory management prevents buffer overflow errors&lt;/li&gt; 
 &lt;li&gt;Ease of use: small self-contained code base, no external dependencies, permissive MIT &lt;a href="https://github.com/fmtlib/fmt/raw/master/LICENSE"&gt;license&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://fmt.dev/latest/#portability"&gt;Portability&lt;/a&gt; with consistent output across platforms and support for older compilers&lt;/li&gt; 
 &lt;li&gt;Clean warning-free codebase even on high warning levels such as &lt;code&gt;-Wall -Wextra -pedantic&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Locale independence by default&lt;/li&gt; 
 &lt;li&gt;Optional header-only configuration enabled with the &lt;code&gt;FMT_HEADER_ONLY&lt;/code&gt; macro&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;See the &lt;a href="https://fmt.dev"&gt;documentation&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;h1&gt;Examples&lt;/h1&gt; 
&lt;p&gt;&lt;strong&gt;Print to stdout&lt;/strong&gt; (&lt;a href="https://godbolt.org/z/Tevcjh"&gt;run&lt;/a&gt;)&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-c++"&gt;#include &amp;lt;fmt/base.h&amp;gt;

int main() {
  fmt::print("Hello, world!\n");
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Format a string&lt;/strong&gt; (&lt;a href="https://godbolt.org/z/oK8h33"&gt;run&lt;/a&gt;)&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-c++"&gt;std::string s = fmt::format("The answer is {}.", 42);
// s == "The answer is 42."
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Format a string using positional arguments&lt;/strong&gt; (&lt;a href="https://godbolt.org/z/Yn7Txe"&gt;run&lt;/a&gt;)&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-c++"&gt;std::string s = fmt::format("I'd rather be {1} than {0}.", "right", "happy");
// s == "I'd rather be happy than right."
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Print dates and times&lt;/strong&gt; (&lt;a href="https://godbolt.org/z/c31ExdY3W"&gt;run&lt;/a&gt;)&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-c++"&gt;#include &amp;lt;fmt/chrono.h&amp;gt;

int main() {
  auto now = std::chrono::system_clock::now();
  fmt::print("Date and time: {}\n", now);
  fmt::print("Time: {:%H:%M}\n", now);
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Output:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Date and time: 2023-12-26 19:10:31.557195597
Time: 19:10
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Print a container&lt;/strong&gt; (&lt;a href="https://godbolt.org/z/MxM1YqjE7"&gt;run&lt;/a&gt;)&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-c++"&gt;#include &amp;lt;vector&amp;gt;
#include &amp;lt;fmt/ranges.h&amp;gt;

int main() {
  std::vector&amp;lt;int&amp;gt; v = {1, 2, 3};
  fmt::print("{}\n", v);
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Output:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;[1, 2, 3]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Check a format string at compile time&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-c++"&gt;std::string s = fmt::format("{:d}", "I am not a number");
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This gives a compile-time error in C++20 because &lt;code&gt;d&lt;/code&gt; is an invalid format specifier for a string.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Write a file from a single thread&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-c++"&gt;#include &amp;lt;fmt/os.h&amp;gt;

int main() {
  auto out = fmt::output_file("guide.txt");
  out.print("Don't {}", "Panic");
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This can be &lt;a href="http://www.zverovich.net/2020/08/04/optimal-file-buffer-size.html"&gt;5 to 9 times faster than fprintf&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Print with colors and text styles&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-c++"&gt;#include &amp;lt;fmt/color.h&amp;gt;

int main() {
  fmt::print(fg(fmt::color::crimson) | fmt::emphasis::bold,
             "Hello, {}!\n", "world");
  fmt::print(fg(fmt::color::floral_white) | bg(fmt::color::slate_gray) |
             fmt::emphasis::underline, "Olá, {}!\n", "Mundo");
  fmt::print(fg(fmt::color::steel_blue) | fmt::emphasis::italic,
             "你好{}！\n", "世界");
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Output on a modern terminal with Unicode support:&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/fmtlib/fmt/assets/%0A576385/2a93c904-d6fa-4aa6-b453-2618e1c327d7" alt="image" /&gt;&lt;/p&gt; 
&lt;h1&gt;Benchmarks&lt;/h1&gt; 
&lt;h2&gt;Speed tests&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Library&lt;/th&gt; 
   &lt;th&gt;Method&lt;/th&gt; 
   &lt;th&gt;Run Time, s&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;libc&lt;/td&gt; 
   &lt;td&gt;printf&lt;/td&gt; 
   &lt;td&gt;0.91&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;libc++&lt;/td&gt; 
   &lt;td&gt;std::ostream&lt;/td&gt; 
   &lt;td&gt;2.49&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;{fmt} 9.1&lt;/td&gt; 
   &lt;td&gt;fmt::print&lt;/td&gt; 
   &lt;td&gt;0.74&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Boost Format 1.80&lt;/td&gt; 
   &lt;td&gt;boost::format&lt;/td&gt; 
   &lt;td&gt;6.26&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Folly Format&lt;/td&gt; 
   &lt;td&gt;folly::format&lt;/td&gt; 
   &lt;td&gt;1.87&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;{fmt} is the fastest of the benchmarked methods, ~20% faster than &lt;code&gt;printf&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;The above results were generated by building &lt;code&gt;tinyformat_test.cpp&lt;/code&gt; on macOS 12.6.1 with &lt;code&gt;clang++ -O3 -DNDEBUG -DSPEED_TEST -DHAVE_FORMAT&lt;/code&gt;, and taking the best of three runs. In the test, the format string &lt;code&gt;"%0.10f:%04d:%+g:%s:%p:%c:%%\n"&lt;/code&gt; or equivalent is filled 2,000,000 times with output sent to &lt;code&gt;/dev/null&lt;/code&gt;; for further details refer to the &lt;a href="https://github.com/fmtlib/format-benchmark/raw/master/src/tinyformat-test.cc"&gt;source&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;{fmt} is up to 20-30x faster than &lt;code&gt;std::ostringstream&lt;/code&gt; and &lt;code&gt;sprintf&lt;/code&gt; on IEEE754 &lt;code&gt;float&lt;/code&gt; and &lt;code&gt;double&lt;/code&gt; formatting (&lt;a href="https://github.com/fmtlib/dtoa-benchmark"&gt;dtoa-benchmark&lt;/a&gt;) and faster than &lt;a href="https://github.com/google/double-conversion"&gt;double-conversion&lt;/a&gt; and &lt;a href="https://github.com/ulfjack/ryu"&gt;ryu&lt;/a&gt;:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://fmt.dev/unknown_mac64_clang12.0.html"&gt;&lt;img src="https://user-images.githubusercontent.com/576385/95684665-11719600-0ba8-11eb-8e5b-972ff4e49428.png" alt="image" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Compile time and code bloat&lt;/h2&gt; 
&lt;p&gt;The script &lt;a href="https://github.com/fmtlib/format-benchmark/raw/master/bloat-test.py"&gt;bloat-test.py&lt;/a&gt; from &lt;a href="https://github.com/fmtlib/format-benchmark"&gt;format-benchmark&lt;/a&gt; tests compile time and code bloat for nontrivial projects. It generates 100 translation units and uses &lt;code&gt;printf()&lt;/code&gt; or its alternative five times in each to simulate a medium-sized project. The resulting executable size and compile time (Apple clang version 15.0.0 (clang-1500.1.0.2.5), macOS Sonoma, best of three) is shown in the following tables.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Optimized build (-O3)&lt;/strong&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Method&lt;/th&gt; 
   &lt;th&gt;Compile Time, s&lt;/th&gt; 
   &lt;th&gt;Executable size, KiB&lt;/th&gt; 
   &lt;th&gt;Stripped size, KiB&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;printf&lt;/td&gt; 
   &lt;td&gt;1.6&lt;/td&gt; 
   &lt;td&gt;54&lt;/td&gt; 
   &lt;td&gt;50&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;IOStreams&lt;/td&gt; 
   &lt;td&gt;25.9&lt;/td&gt; 
   &lt;td&gt;98&lt;/td&gt; 
   &lt;td&gt;84&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;fmt 83652df&lt;/td&gt; 
   &lt;td&gt;4.8&lt;/td&gt; 
   &lt;td&gt;54&lt;/td&gt; 
   &lt;td&gt;50&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;tinyformat&lt;/td&gt; 
   &lt;td&gt;29.1&lt;/td&gt; 
   &lt;td&gt;161&lt;/td&gt; 
   &lt;td&gt;136&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Boost Format&lt;/td&gt; 
   &lt;td&gt;55.0&lt;/td&gt; 
   &lt;td&gt;530&lt;/td&gt; 
   &lt;td&gt;317&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;{fmt} is fast to compile and is comparable to &lt;code&gt;printf&lt;/code&gt; in terms of per-call binary size (within a rounding error on this system).&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Non-optimized build&lt;/strong&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Method&lt;/th&gt; 
   &lt;th&gt;Compile Time, s&lt;/th&gt; 
   &lt;th&gt;Executable size, KiB&lt;/th&gt; 
   &lt;th&gt;Stripped size, KiB&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;printf&lt;/td&gt; 
   &lt;td&gt;1.4&lt;/td&gt; 
   &lt;td&gt;54&lt;/td&gt; 
   &lt;td&gt;50&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;IOStreams&lt;/td&gt; 
   &lt;td&gt;23.4&lt;/td&gt; 
   &lt;td&gt;92&lt;/td&gt; 
   &lt;td&gt;68&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;{fmt} 83652df&lt;/td&gt; 
   &lt;td&gt;4.4&lt;/td&gt; 
   &lt;td&gt;89&lt;/td&gt; 
   &lt;td&gt;85&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;tinyformat&lt;/td&gt; 
   &lt;td&gt;24.5&lt;/td&gt; 
   &lt;td&gt;204&lt;/td&gt; 
   &lt;td&gt;161&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Boost Format&lt;/td&gt; 
   &lt;td&gt;36.4&lt;/td&gt; 
   &lt;td&gt;831&lt;/td&gt; 
   &lt;td&gt;462&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;code&gt;libc&lt;/code&gt;, &lt;code&gt;lib(std)c++&lt;/code&gt;, and &lt;code&gt;libfmt&lt;/code&gt; are all linked as shared libraries to compare formatting function overhead only. Boost Format is a header-only library so it doesn't provide any linkage options.&lt;/p&gt; 
&lt;h2&gt;Running the tests&lt;/h2&gt; 
&lt;p&gt;Please refer to &lt;a href="https://fmt.dev/latest/get-started/#building-from-source"&gt;Building the library&lt;/a&gt; for instructions on how to build the library and run the unit tests.&lt;/p&gt; 
&lt;p&gt;Benchmarks reside in a separate repository, &lt;a href="https://github.com/fmtlib/format-benchmark"&gt;format-benchmarks&lt;/a&gt;, so to run the benchmarks you first need to clone this repository and generate Makefiles with CMake:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ git clone --recursive https://github.com/fmtlib/format-benchmark.git
$ cd format-benchmark
$ cmake .
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then you can run the speed test:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ make speed-test
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;or the bloat test:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ make bloat-test
&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;Migrating code&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://clang.llvm.org/extra/clang-tidy/"&gt;clang-tidy&lt;/a&gt; v18 provides the &lt;a href="https://clang.llvm.org/extra/clang-tidy/checks/modernize/use-std-print.html"&gt;modernize-use-std-print&lt;/a&gt; check that is capable of converting occurrences of &lt;code&gt;printf&lt;/code&gt; and &lt;code&gt;fprintf&lt;/code&gt; to &lt;code&gt;fmt::print&lt;/code&gt; if configured to do so. (By default it converts to &lt;code&gt;std::print&lt;/code&gt;.)&lt;/p&gt; 
&lt;h1&gt;Notable projects using this library&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://play0ad.com/"&gt;0 A.D.&lt;/a&gt;: a free, open-source, cross-platform real-time strategy game&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ampl/mp"&gt;AMPL/MP&lt;/a&gt;: an open-source library for mathematical programming&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/apple/foundationdb"&gt;Apple's FoundationDB&lt;/a&gt;: an open-source, distributed, transactional key-value store&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/aseprite/aseprite"&gt;Aseprite&lt;/a&gt;: animated sprite editor &amp;amp; pixel art tool&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.aviobook.aero/en"&gt;AvioBook&lt;/a&gt;: a comprehensive aircraft operations suite&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://battle.net/"&gt;Blizzard Battle.net&lt;/a&gt;: an online gaming platform&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://celestia.space/"&gt;Celestia&lt;/a&gt;: real-time 3D visualization of space&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://ceph.com/"&gt;Ceph&lt;/a&gt;: a scalable distributed storage system&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://ccache.dev/"&gt;ccache&lt;/a&gt;: a compiler cache&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ClickHouse/ClickHouse"&gt;ClickHouse&lt;/a&gt;: an analytical database management system&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.contextvision.com/"&gt;ContextVision&lt;/a&gt;: medical imaging software&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/contour-terminal/contour/"&gt;Contour&lt;/a&gt;: a modern terminal emulator&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://cuauv.org/"&gt;CUAUV&lt;/a&gt;: Cornell University's autonomous underwater vehicle&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://drake.mit.edu/"&gt;Drake&lt;/a&gt;: a planning, control, and analysis toolbox for nonlinear dynamical systems (MIT)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/envoyproxy/envoy"&gt;Envoy&lt;/a&gt;: C++ L7 proxy and communication bus (Lyft)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://fivem.net/"&gt;FiveM&lt;/a&gt;: a modification framework for GTA V&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/MengRao/fmtlog"&gt;fmtlog&lt;/a&gt;: a performant fmtlib-style logging library with latency in nanoseconds&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/facebook/folly"&gt;Folly&lt;/a&gt;: Facebook open-source library&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://gemrb.org/"&gt;GemRB&lt;/a&gt;: a portable open-source implementation of Bioware's Infinity Engine&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://store.steampowered.com/app/1247360/Grand_Mountain_Adventure/"&gt;Grand Mountain Adventure&lt;/a&gt;: a beautiful open-world ski &amp;amp; snowboarding game&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pvpgn/pvpgn-server"&gt;HarpyWar/pvpgn&lt;/a&gt;: Player vs Player Gaming Network with tweaks&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/kbengine/kbengine"&gt;KBEngine&lt;/a&gt;: an open-source MMOG server engine&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://keypirinha.com/"&gt;Keypirinha&lt;/a&gt;: a semantic launcher for Windows&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://kodi.tv/"&gt;Kodi&lt;/a&gt; (formerly xbmc): home theater software&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://kth.cash/"&gt;Knuth&lt;/a&gt;: high-performance Bitcoin full-node&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/contour-terminal/libunicode/"&gt;libunicode&lt;/a&gt;: a modern C++17 Unicode library&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://mariadb.org/"&gt;MariaDB&lt;/a&gt;: relational database management system&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/microsoft/verona"&gt;Microsoft Verona&lt;/a&gt;: research programming language for concurrent ownership&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://mongodb.com/"&gt;MongoDB&lt;/a&gt;: distributed document database&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/duckie/mongo_smasher"&gt;MongoDB Smasher&lt;/a&gt;: a small tool to generate randomized datasets&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://openspaceproject.com/"&gt;OpenSpace&lt;/a&gt;: an open-source astrovisualization framework&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.polserver.com/"&gt;PenUltima Online (POL)&lt;/a&gt;: an MMO server, compatible with most Ultima Online clients&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pytorch/pytorch"&gt;PyTorch&lt;/a&gt;: an open-source machine learning library&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.quasardb.net/"&gt;quasardb&lt;/a&gt;: a distributed, high-performance, associative database&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/odygrd/quill"&gt;Quill&lt;/a&gt;: asynchronous low-latency logging library&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ravijanjam/qkw"&gt;QKW&lt;/a&gt;: generalizing aliasing to simplify navigation, and execute complex multi-line terminal command sequences&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/HunanTV/redis-cerberus"&gt;redis-cerberus&lt;/a&gt;: a Redis cluster proxy&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://vectorized.io/redpanda"&gt;redpanda&lt;/a&gt;: a 10x faster Kafka® replacement for mission-critical systems written in C++&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://rpclib.net/"&gt;rpclib&lt;/a&gt;: a modern C++ msgpack-RPC server and client library&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.salesforce.com/analytics-cloud/overview/"&gt;Salesforce Analytics Cloud&lt;/a&gt;: business intelligence software&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.scylladb.com/"&gt;Scylla&lt;/a&gt;: a Cassandra-compatible NoSQL data store that can handle 1 million transactions per second on a single server&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://www.seastar-project.org/"&gt;Seastar&lt;/a&gt;: an advanced, open-source C++ framework for high-performance server applications on modern hardware&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/gabime/spdlog"&gt;spdlog&lt;/a&gt;: super fast C++ logging library&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.stellar.org/"&gt;Stellar&lt;/a&gt;: financial platform&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.touchsurgery.com/"&gt;Touch Surgery&lt;/a&gt;: surgery simulator&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/TrinityCore/TrinityCore"&gt;TrinityCore&lt;/a&gt;: open-source MMORPG framework&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://userver.tech/"&gt;🐙 userver framework&lt;/a&gt;: open-source asynchronous framework with a rich set of abstractions and database drivers&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/microsoft/terminal"&gt;Windows Terminal&lt;/a&gt;: the new Windows terminal&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://github.com/search?q=fmtlib&amp;amp;type=Code"&gt;More...&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;If you are aware of other projects using this library, please let me know by &lt;a href="mailto:victor.zverovich@gmail.com"&gt;email&lt;/a&gt; or by submitting an &lt;a href="https://github.com/fmtlib/fmt/issues"&gt;issue&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;Motivation&lt;/h1&gt; 
&lt;p&gt;So why yet another formatting library?&lt;/p&gt; 
&lt;p&gt;There are plenty of methods for doing this task, from standard ones like the printf family of function and iostreams to Boost Format and FastFormat libraries. The reason for creating a new library is that every existing solution that I found either had serious issues or didn't provide all the features I needed.&lt;/p&gt; 
&lt;h2&gt;printf&lt;/h2&gt; 
&lt;p&gt;The good thing about &lt;code&gt;printf&lt;/code&gt; is that it is pretty fast and readily available being a part of the C standard library. The main drawback is that it doesn't support user-defined types. &lt;code&gt;printf&lt;/code&gt; also has safety issues although they are somewhat mitigated with &lt;a href="https://gcc.gnu.org/onlinedocs/gcc/Function-Attributes.html"&gt;__attribute__ ((format (printf, ...))&lt;/a&gt; in GCC. There is a POSIX extension that adds positional arguments required for &lt;a href="https://en.wikipedia.org/wiki/Internationalization_and_localization"&gt;i18n&lt;/a&gt; to &lt;code&gt;printf&lt;/code&gt; but it is not a part of C99 and may not be available on some platforms.&lt;/p&gt; 
&lt;h2&gt;iostreams&lt;/h2&gt; 
&lt;p&gt;The main issue with iostreams is best illustrated with an example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-c++"&gt;std::cout &amp;lt;&amp;lt; std::setprecision(2) &amp;lt;&amp;lt; std::fixed &amp;lt;&amp;lt; 1.23456 &amp;lt;&amp;lt; "\n";
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;which is a lot of typing compared to printf:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-c++"&gt;printf("%.2f\n", 1.23456);
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Matthew Wilson, the author of FastFormat, called this "chevron hell". iostreams don't support positional arguments by design.&lt;/p&gt; 
&lt;p&gt;The good part is that iostreams support user-defined types and are safe although error handling is awkward.&lt;/p&gt; 
&lt;h2&gt;Boost Format&lt;/h2&gt; 
&lt;p&gt;This is a very powerful library that supports both &lt;code&gt;printf&lt;/code&gt;-like format strings and positional arguments. Its main drawback is performance. According to various benchmarks, it is much slower than other methods considered here. Boost Format also has excessive build times and severe code bloat issues (see &lt;a href="https://raw.githubusercontent.com/fmtlib/fmt/master/#benchmarks"&gt;Benchmarks&lt;/a&gt;).&lt;/p&gt; 
&lt;h2&gt;FastFormat&lt;/h2&gt; 
&lt;p&gt;This is an interesting library that is fast, safe and has positional arguments. However, it has significant limitations, citing its author:&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Three features that have no hope of being accommodated within the current design are:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Leading zeros (or any other non-space padding)&lt;/li&gt; 
  &lt;li&gt;Octal/hexadecimal encoding&lt;/li&gt; 
  &lt;li&gt;Runtime width/alignment specification&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;It is also quite big and has a heavy dependency, on STLSoft, which might be too restrictive for use in some projects.&lt;/p&gt; 
&lt;h2&gt;Boost Spirit.Karma&lt;/h2&gt; 
&lt;p&gt;This is not a formatting library but I decided to include it here for completeness. As iostreams, it suffers from the problem of mixing verbatim text with arguments. The library is pretty fast, but slower on integer formatting than &lt;code&gt;fmt::format_to&lt;/code&gt; with format string compilation on Karma's own benchmark, see &lt;a href="http://www.zverovich.net/2020/06/13/fast-int-to-string-revisited.html"&gt;Converting a hundred million integers to strings per second&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;License&lt;/h1&gt; 
&lt;p&gt;{fmt} is distributed under the MIT &lt;a href="https://github.com/fmtlib/fmt/raw/master/LICENSE"&gt;license&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;Documentation License&lt;/h1&gt; 
&lt;p&gt;The &lt;a href="https://fmt.dev/latest/syntax/"&gt;Format String Syntax&lt;/a&gt; section in the documentation is based on the one from Python &lt;a href="https://docs.python.org/3/library/string.html#module-string"&gt;string module documentation&lt;/a&gt;. For this reason, the documentation is distributed under the Python Software Foundation license available in &lt;a href="https://raw.github.com/fmtlib/fmt/master/doc/python-license.txt"&gt;doc/python-license.txt&lt;/a&gt;. It only applies if you distribute the documentation of {fmt}.&lt;/p&gt; 
&lt;h1&gt;Maintainers&lt;/h1&gt; 
&lt;p&gt;The {fmt} library is maintained by Victor Zverovich (&lt;a href="https://github.com/vitaut"&gt;vitaut&lt;/a&gt;) with contributions from many other people. See &lt;a href="https://github.com/fmtlib/fmt/graphs/contributors"&gt;Contributors&lt;/a&gt; and &lt;a href="https://github.com/fmtlib/fmt/releases"&gt;Releases&lt;/a&gt; for some of the names. Let us know if your contribution is not listed or mentioned incorrectly and we'll make it right.&lt;/p&gt; 
&lt;h1&gt;Security Policy&lt;/h1&gt; 
&lt;p&gt;To report a security issue, please disclose it at &lt;a href="https://github.com/fmtlib/fmt/security/advisories/new"&gt;security advisory&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;This project is maintained by a team of volunteers on a reasonable-effort basis. As such, please give us at least &lt;em&gt;90&lt;/em&gt; days to work on a fix before public exposure.&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>