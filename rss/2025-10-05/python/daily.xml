<rss version="2.0">
  <channel>
    <title>GitHub Python Daily Trending</title>
    <description>Daily Trending of Python in GitHub</description>
    <pubDate>Sat, 04 Oct 2025 01:38:24 GMT</pubDate>
    <link>http://mshibanami.github.io/GitHubTrendingRSS</link>
    
    <item>
      <title>dlt-hub/dlt</title>
      <link>https://github.com/dlt-hub/dlt</link>
      <description>&lt;p&gt;data load tool (dlt) is an open source Python library that makes data loading easy üõ†Ô∏è&lt;/p&gt;&lt;hr&gt;&lt;h1 align="center"&gt; &lt;strong&gt;data load tool (dlt) ‚Äî the open-source Python library for data loading&lt;/strong&gt; &lt;/h1&gt; 
&lt;p align="center"&gt; Be it a Google Colab notebook, AWS Lambda function, an Airflow DAG, your local laptop,&lt;br /&gt;or a GPT-4 assisted development playground‚Äî&lt;strong&gt;dlt&lt;/strong&gt; can be dropped in anywhere. &lt;/p&gt; 
&lt;h3 align="center"&gt; &lt;p&gt;üöÄ Join our thriving community of likeminded developers and build the future together!&lt;/p&gt; &lt;/h3&gt; 
&lt;div align="center"&gt; 
 &lt;a target="_blank" href="https://dlthub.com/community" style="background:none"&gt; &lt;img src="https://img.shields.io/badge/slack-join-dlt.svg?labelColor=191937&amp;amp;color=6F6FF7&amp;amp;logo=slack" style="width: 260px;" /&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;a target="_blank" href="https://pypi.org/project/dlt/" style="background:none"&gt; &lt;img src="https://img.shields.io/pypi/v/dlt?labelColor=191937&amp;amp;color=6F6FF7" /&gt; &lt;/a&gt; 
 &lt;a target="_blank" href="https://pypi.org/project/dlt/" style="background:none"&gt; &lt;img src="https://img.shields.io/pypi/pyversions/dlt?labelColor=191937&amp;amp;color=6F6FF7" /&gt; &lt;/a&gt; 
 &lt;a target="_blank" href="https://pypi.org/project/dlt/" style="background:none"&gt; &lt;img src="https://img.shields.io/pypi/dm/dlt?labelColor=191937&amp;amp;color=6F6FF7" /&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;dlt supports Python 3.9 through Python 3.14 (beta 4). Note that some optional extras are not yet available for Python 3.14, so support for this version is considered experimental.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;pip install dlt
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;More options: &lt;a href="https://dlthub.com/docs/reference/installation#31-install-dlt-via-pixi-or-conda"&gt;Install via Conda or Pixi&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;p&gt;Load chess game data from chess.com API and save it in DuckDB:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import dlt
from dlt.sources.helpers import requests

# Create a dlt pipeline that will load
# chess player data to the DuckDB destination
pipeline = dlt.pipeline(
    pipeline_name='chess_pipeline',
    destination='duckdb',
    dataset_name='player_data'
)

# Grab some player data from Chess.com API
data = []
for player in ['magnuscarlsen', 'rpragchess']:
    response = requests.get(f'https://api.chess.com/pub/player/{player}')
    response.raise_for_status()
    data.append(response.json())

# Extract, normalize, and load the data
pipeline.run(data, table_name='player')
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Try it out in our &lt;strong&gt;&lt;a href="https://colab.research.google.com/drive/1NfSB1DpwbbHX9_t5vlalBTf13utwpMGx?usp=sharing"&gt;Colab Demo&lt;/a&gt;&lt;/strong&gt; or directly on our wasm-based &lt;a href="https://dlthub.com/docs/tutorial/playground"&gt;playground&lt;/a&gt; in our docs.&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Automatic Schema:&lt;/strong&gt; Data structure inspection and schema creation for the destination.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Data Normalization:&lt;/strong&gt; Consistent and verified data before loading.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Seamless Integration:&lt;/strong&gt; Colab, AWS Lambda, Airflow, and local environments.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Scalable:&lt;/strong&gt; Adapts to growing data needs in production.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Easy Maintenance:&lt;/strong&gt; Clear data pipeline structure for updates.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Rapid Exploration:&lt;/strong&gt; Quickly explore and gain insights from new data sources.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Versatile Usage:&lt;/strong&gt; Suitable for ad-hoc exploration to advanced loading infrastructures.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Start in Seconds with CLI:&lt;/strong&gt; Powerful CLI for managing, deploying and inspecting local pipelines.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Incremental Loading:&lt;/strong&gt; Load only new or changed data and avoid loading old records again.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Open Source:&lt;/strong&gt; Free and Apache 2.0 Licensed.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Ready to use Sources and Destinations&lt;/h2&gt; 
&lt;p&gt;Explore ready to use sources (e.g. Google Sheets) in the &lt;a href="https://dlthub.com/docs/dlt-ecosystem/verified-sources"&gt;Verified Sources docs&lt;/a&gt; and supported destinations (e.g. DuckDB) in the &lt;a href="https://dlthub.com/docs/dlt-ecosystem/destinations"&gt;Destinations docs&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;For detailed usage and configuration, please refer to the &lt;a href="https://dlthub.com/docs"&gt;official documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Examples&lt;/h2&gt; 
&lt;p&gt;You can find examples for various use cases in the &lt;a href="https://raw.githubusercontent.com/dlt-hub/dlt/devel/docs/examples"&gt;examples&lt;/a&gt; folder, or in the &lt;a href="https://dlthub.com/docs/examples"&gt;code examples section&lt;/a&gt; of our docs page.&lt;/p&gt; 
&lt;h2&gt;Adding as dependency&lt;/h2&gt; 
&lt;p&gt;&lt;code&gt;dlt&lt;/code&gt; follows the semantic versioning with the &lt;a href="https://peps.python.org/pep-0440/#semantic-versioning"&gt;&lt;code&gt;MAJOR.MINOR.PATCH&lt;/code&gt;&lt;/a&gt; pattern.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;major&lt;/code&gt; means breaking changes and removed deprecations&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;minor&lt;/code&gt; new features, sometimes automatic migrations&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;patch&lt;/code&gt; bug fixes&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;We suggest that you allow only &lt;code&gt;patch&lt;/code&gt; level updates automatically:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Using the &lt;a href="https://packaging.python.org/en/latest/specifications/version-specifiers/#compatible-release"&gt;Compatible Release Specifier&lt;/a&gt;. For example &lt;strong&gt;dlt~=1.0&lt;/strong&gt; allows only versions &lt;strong&gt;&amp;gt;=1.0&lt;/strong&gt; and less than &lt;strong&gt;&amp;lt;1.1&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;Poetry &lt;a href="https://python-poetry.org/docs/dependency-specification/"&gt;caret requirements&lt;/a&gt;. For example &lt;strong&gt;^1.0&lt;/strong&gt; allows only versions &lt;strong&gt;&amp;gt;=1.0&lt;/strong&gt; to &lt;strong&gt;&amp;lt;1.0&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Please also see our &lt;a href="https://github.com/dlt-hub/dlt/releases"&gt;release notes&lt;/a&gt; for notable changes between versions.&lt;/p&gt; 
&lt;h2&gt;Get Involved&lt;/h2&gt; 
&lt;p&gt;The dlt project is quickly growing, and we're excited to have you join our community! Here's how you can get involved:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Connect with the Community&lt;/strong&gt;: Join other dlt users and contributors on our &lt;a href="https://dlthub.com/community"&gt;Slack&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Report issues and suggest features&lt;/strong&gt;: Please use the &lt;a href="https://github.com/dlt-hub/dlt/issues"&gt;GitHub Issues&lt;/a&gt; to report bugs or suggest new features. Before creating a new issue, make sure to search the tracker for possible duplicates and add a comment if you find one.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Track progress of our work and our plans&lt;/strong&gt;: Please check out our &lt;a href="https://github.com/orgs/dlt-hub/projects/9"&gt;public Github project&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Improve documentation&lt;/strong&gt;: Help us enhance the dlt documentation.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contribute code&lt;/h2&gt; 
&lt;p&gt;Please read &lt;a href="https://raw.githubusercontent.com/dlt-hub/dlt/devel/CONTRIBUTING.md"&gt;CONTRIBUTING&lt;/a&gt; before you make a PR.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;üì£ &lt;strong&gt;New destinations are unlikely to be merged&lt;/strong&gt; due to high maintenance cost (but we are happy to improve SQLAlchemy destination to handle more dialects)&lt;/li&gt; 
 &lt;li&gt;Significant changes require tests and docs and in many cases writing tests will be more laborious than writing code&lt;/li&gt; 
 &lt;li&gt;Bugfixes and improvements are welcome! You'll get help with writing tests and docs + a decent review.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;&lt;code&gt;dlt&lt;/code&gt; is released under the &lt;a href="https://raw.githubusercontent.com/dlt-hub/dlt/devel/LICENSE.txt"&gt;Apache 2.0 License&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>swisskyrepo/PayloadsAllTheThings</title>
      <link>https://github.com/swisskyrepo/PayloadsAllTheThings</link>
      <description>&lt;p&gt;A list of useful payloads and bypass for Web Application Security and Pentest/CTF&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Payloads All The Things&lt;/h1&gt; 
&lt;p&gt;A list of useful payloads and bypasses for Web Application Security. Feel free to improve with your payloads and techniques!&lt;/p&gt; 
&lt;p&gt;You can also contribute with a &lt;span&gt;üçª&lt;/span&gt; IRL, or using the sponsor button.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/sponsors/swisskyrepo"&gt;&lt;img src="https://img.shields.io/static/v1?label=Sponsor&amp;amp;message=%E2%9D%A4&amp;amp;logo=GitHub&amp;amp;link=https://github.com/sponsors/swisskyrepo" alt="Sponsor" /&gt;&lt;/a&gt; &lt;a href="https://twitter.com/intent/tweet?text=Payloads%20All%20The%20Things,%20a%20list%20of%20useful%20payloads%20and%20bypasses%20for%20Web%20Application%20Security%20-%20by%20@pentest_swissky&amp;amp;url=https://github.com/swisskyrepo/PayloadsAllTheThings/"&gt;&lt;img src="https://img.shields.io/twitter/url/http/shields.io.svg?style=social" alt="Tweet" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;An alternative display version is available at &lt;a href="https://swisskyrepo.github.io/PayloadsAllTheThings/"&gt;PayloadsAllTheThingsWeb&lt;/a&gt;.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/swisskyrepo/PayloadsAllTheThings/master/.github/banner.png" alt="banner" /&gt; &lt;/p&gt; 
&lt;h2&gt;&lt;span&gt;üìñ&lt;/span&gt; Documentation&lt;/h2&gt; 
&lt;p&gt;Every section contains the following files, you can use the &lt;code&gt;_template_vuln&lt;/code&gt; folder to create a new chapter:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;README.md - vulnerability description and how to exploit it, including several payloads&lt;/li&gt; 
 &lt;li&gt;Intruder - a set of files to give to Burp Intruder&lt;/li&gt; 
 &lt;li&gt;Images - pictures for the README.md&lt;/li&gt; 
 &lt;li&gt;Files - some files referenced in the README.md&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;You might also like the other projects from the AllTheThings family :&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://swisskyrepo.github.io/InternalAllTheThings/"&gt;InternalAllTheThings&lt;/a&gt; - Active Directory and Internal Pentest Cheatsheets&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://swisskyrepo.github.io/HardwareAllTheThings/"&gt;HardwareAllTheThings&lt;/a&gt; - Hardware/IOT Pentesting Wiki&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;You want more? Check the &lt;a href="https://github.com/swisskyrepo/PayloadsAllTheThings/raw/master/_LEARNING_AND_SOCIALS/BOOKS.md"&gt;Books&lt;/a&gt; and &lt;a href="https://github.com/swisskyrepo/PayloadsAllTheThings/raw/master/_LEARNING_AND_SOCIALS/YOUTUBE.md"&gt;YouTube channel&lt;/a&gt; selections.&lt;/p&gt; 
&lt;h2&gt;&lt;span&gt;üßëüíª&lt;/span&gt; Contributions&lt;/h2&gt; 
&lt;p&gt;Be sure to read &lt;a href="https://github.com/swisskyrepo/PayloadsAllTheThings/raw/master/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt;&lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/swisskyrepo/PayloadsAllTheThings/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=swisskyrepo/PayloadsAllTheThings&amp;amp;max=36" alt="sponsors-list" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p&gt;Thanks again for your contribution! &lt;span&gt;‚ù§Ô∏è&lt;/span&gt;&lt;/p&gt; 
&lt;h2&gt;&lt;span&gt;üçª&lt;/span&gt; Sponsors&lt;/h2&gt; 
&lt;p&gt;This project is proudly sponsored by these companies.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Logo&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://serpapi.com"&gt;&lt;img src="https://avatars.githubusercontent.com/u/34724717?s=40&amp;amp;v=4" alt="sponsor-serpapi" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;SerpApi&lt;/strong&gt; is a real time API to access Google search results. It solves the issues of having to rent proxies, solving captchas, and JSON parsing.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://projectdiscovery.io/"&gt;&lt;img src="https://avatars.githubusercontent.com/u/50994705?s=40&amp;amp;v=4" alt="sponsor-projectdiscovery" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;ProjectDiscovery&lt;/strong&gt; - Detect real, exploitable vulnerabilities. Harness the power of Nuclei for fast and accurate findings without false positives.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://www.vaadata.com/"&gt;&lt;img src="https://avatars.githubusercontent.com/u/48131541?s=40&amp;amp;v=4" alt="sponsor-vaadata" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;VAADATA&lt;/strong&gt; - Ethical Hacking Services&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt;</description>
    </item>
    
    <item>
      <title>getsentry/sentry</title>
      <link>https://github.com/getsentry/sentry</link>
      <description>&lt;p&gt;Developer-first error tracking and performance monitoring&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;/p&gt;
&lt;p align="center"&gt; &lt;a href="https://sentry.io/?utm_source=github&amp;amp;utm_medium=logo" target="_blank"&gt; &lt;img src="https://sentry-brand.storage.googleapis.com/sentry-wordmark-dark-280x84.png" alt="Sentry" width="280" height="84" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; Users and logs provide clues. Sentry provides answers. &lt;/p&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;h1&gt;What's Sentry?&lt;/h1&gt; 
&lt;p&gt;Sentry is the debugging platform that helps every developer detect, trace, and fix issues. Code breaks, fix it faster.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://github.com/getsentry/sentry/raw/master/.github/screenshots/issue-details.png" width="270" /&gt; &lt;img src="https://github.com/getsentry/sentry/raw/master/.github/screenshots/seer.png" width="270" /&gt; &lt;img src="https://github.com/getsentry/sentry/raw/master/.github/screenshots/insights.png" width="270" /&gt; &lt;img src="https://github.com/getsentry/sentry/raw/master/.github/screenshots/traces.png" width="270" /&gt; &lt;img src="https://github.com/getsentry/sentry/raw/master/.github/screenshots/trace-explorer.png" width="270" /&gt; &lt;img src="https://github.com/getsentry/sentry/raw/master/.github/screenshots/replays.png" width="270" /&gt; &lt;img src="https://github.com/getsentry/sentry/raw/master/.github/screenshots/insights.png" width="270" /&gt; &lt;img src="https://github.com/getsentry/sentry/raw/master/.github/screenshots/logs.png" width="270" /&gt; &lt;img src="https://github.com/getsentry/sentry/raw/master/.github/screenshots/uptime.png" width="270" /&gt; &lt;/p&gt; 
&lt;h2&gt;Official Sentry SDKs&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/getsentry/sentry-javascript"&gt;JavaScript&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/getsentry/sentry-electron/"&gt;Electron&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/getsentry/sentry-react-native"&gt;React-Native&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/getsentry/sentry-python"&gt;Python&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/getsentry/sentry-ruby"&gt;Ruby&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/getsentry/sentry-php"&gt;PHP&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/getsentry/sentry-laravel"&gt;Laravel&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/getsentry/sentry-go"&gt;Go&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/getsentry/sentry-rust"&gt;Rust&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/getsentry/sentry-java"&gt;Java/Kotlin&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/getsentry/sentry-cocoa"&gt;Objective-C/Swift&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/getsentry/sentry-dotnet"&gt;C#/F#&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/getsentry/sentry-native"&gt;C/C++&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/getsentry/sentry-dart"&gt;Dart/Flutter&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/getsentry/perl-raven"&gt;Perl&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/getsentry/sentry-clj/"&gt;Clojure&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/getsentry/sentry-elixir"&gt;Elixir&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/getsentry/sentry-unity"&gt;Unity&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/getsentry/sentry-unreal"&gt;Unreal Engine&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/getsentry/sentry-godot"&gt;Godot Engine&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/getsentry/sentry-powershell"&gt;PowerShell&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Resources&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.sentry.io/"&gt;Documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/getsentry/sentry/discussions"&gt;Discussions&lt;/a&gt; (Bugs, feature requests, general questions)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://discord.gg/PXa5Apfe7K"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.sentry.io/internal/contributing/"&gt;Contributing&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/getsentry/sentry/issues"&gt;Bug Tracker&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/getsentry/sentry"&gt;Code&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://explore.transifex.com/getsentry/sentry/"&gt;Transifex&lt;/a&gt; (Translate Sentry!)&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>microsoft/agent-framework</title>
      <link>https://github.com/microsoft/agent-framework</link>
      <description>&lt;p&gt;A framework for building, orchestrating and deploying AI agents and multi-agent workflows with support for Python and .NET.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/microsoft/agent-framework/main/docs/assets/readme-banner.png" alt="Microsoft Agent Framework" /&gt;&lt;/p&gt; 
&lt;h1&gt;Welcome to Microsoft Agent Framework!&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://discord.gg/b5zjErwbQM"&gt;&lt;img src="https://dcbadge.limes.pink/api/server/b5zjErwbQM?style=flat" alt="Microsoft Azure AI Foundry Discord" /&gt;&lt;/a&gt; &lt;a href="https://learn.microsoft.com/en-us/agent-framework/"&gt;&lt;img src="https://img.shields.io/badge/MS%20Learn-Documentation-blue" alt="MS Learn Documentation" /&gt;&lt;/a&gt; &lt;a href="https://pypi.org/project/agent-framework/"&gt;&lt;img src="https://img.shields.io/pypi/v/agent-framework" alt="PyPI" /&gt;&lt;/a&gt; &lt;a href="https://www.nuget.org/profiles/MicrosoftAgentFramework/"&gt;&lt;img src="https://img.shields.io/nuget/v/Microsoft.Agents.AI" alt="NuGet" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Welcome to Microsoft's comprehensive multi-language framework for building, orchestrating, and deploying AI agents with support for both .NET and Python implementations. This framework provides everything from simple chat agents to complex multi-agent workflows with graph-based orchestration.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://www.youtube.com/watch?v=AAgdMhftj8w" title="Watch the full Agent Framework introduction (30 min)"&gt; &lt;img src="https://img.youtube.com/vi/AAgdMhftj8w/hqdefault.jpg" alt="Watch the full Agent Framework introduction (30 min)" width="480" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://www.youtube.com/watch?v=AAgdMhftj8w"&gt; Watch the full Agent Framework introduction (30 min) &lt;/a&gt; &lt;/p&gt; 
&lt;h2&gt;üìã Getting Started&lt;/h2&gt; 
&lt;h3&gt;üì¶ Installation&lt;/h3&gt; 
&lt;p&gt;Python&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install agent-framework --pre
# This will install all sub-packages, see `python/packages` for individual packages.
# It may take a minute on first install on Windows.
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;.NET&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;dotnet add package Microsoft.Agents.AI
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;üìö Documentation&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://learn.microsoft.com/agent-framework/overview/agent-framework-overview"&gt;Overview&lt;/a&gt;&lt;/strong&gt; - High level overview of the framework&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://learn.microsoft.com/agent-framework/tutorials/quick-start"&gt;Quick Start&lt;/a&gt;&lt;/strong&gt; - Get started with a simple agent&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://learn.microsoft.com/agent-framework/tutorials/overview"&gt;Tutorials&lt;/a&gt;&lt;/strong&gt; - Step by step tutorials&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://learn.microsoft.com/en-us/agent-framework/user-guide/overview"&gt;User Guide&lt;/a&gt;&lt;/strong&gt; - In-depth user guide for building agents and workflows&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://learn.microsoft.com/en-us/agent-framework/migration-guide/from-semantic-kernel"&gt;Migration from Semantic Kernel&lt;/a&gt;&lt;/strong&gt; - Guide to migrate from Semantic Kernel&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://learn.microsoft.com/en-us/agent-framework/migration-guide/from-autogen"&gt;Migration from AutoGen&lt;/a&gt;&lt;/strong&gt; - Guide to migrate from AutoGen&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;‚ú® &lt;strong&gt;Highlights&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Graph-based Workflows&lt;/strong&gt;: Connect agents and deterministic functions using data flows with streaming, checkpointing, human-in-the-loop, and time-travel capabilities 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/agent-framework/main/python/samples/getting_started/workflows/"&gt;Python workflows&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/agent-framework/main/dotnet/samples/GettingStarted/Workflows/"&gt;.NET workflows&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;AF Labs&lt;/strong&gt;: Experimental packages for cutting-edge features including benchmarking, reinforcement learning, and research initiatives 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/agent-framework/main/python/packages/lab/"&gt;Labs directory&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;DevUI&lt;/strong&gt;: Interactive developer UI for agent development, testing, and debugging workflows 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/agent-framework/main/python/packages/devui/"&gt;DevUI package&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p align="center"&gt; &lt;a href="https://www.youtube.com/watch?v=mOAaGY4WPvc"&gt; &lt;img src="https://img.youtube.com/vi/mOAaGY4WPvc/hqdefault.jpg" alt="See the DevUI in action" width="480" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://www.youtube.com/watch?v=mOAaGY4WPvc"&gt; See the DevUI in action (1 min) &lt;/a&gt; &lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Python and C#/.NET Support&lt;/strong&gt;: Full framework support for both Python and C#/.NET implementations with consistent APIs 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/agent-framework/main/python/packages/"&gt;Python packages&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/agent-framework/main/dotnet/src/"&gt;.NET source&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Observability&lt;/strong&gt;: Built-in OpenTelemetry integration for distributed tracing, monitoring, and debugging 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/agent-framework/main/python/samples/getting_started/observability/"&gt;Python observability&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/agent-framework/main/dotnet/samples/GettingStarted/AgentOpenTelemetry/"&gt;.NET telemetry&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Multiple Agent Provider Support&lt;/strong&gt;: Support for various LLM providers with more being added continuously 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/agent-framework/main/python/samples/getting_started/agents/"&gt;Python examples&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/agent-framework/main/dotnet/samples/GettingStarted/AgentProviders/"&gt;.NET examples&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Middleware&lt;/strong&gt;: Flexible middleware system for request/response processing, exception handling, and custom pipelines 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/agent-framework/main/python/samples/getting_started/middleware/"&gt;Python middleware&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/agent-framework/main/dotnet/samples/GettingStarted/Agents/Agent_Step14_Middleware/"&gt;.NET middleware&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üí¨ &lt;strong&gt;We want your feedback!&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;For bugs, please file a &lt;a href="https://github.com/microsoft/agent-framework/issues"&gt;GitHub issue&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Quickstart&lt;/h2&gt; 
&lt;h3&gt;Basic Agent - Python&lt;/h3&gt; 
&lt;p&gt;Create a simple Azure Responses Agent that writes a haiku about the Microsoft Agent Framework&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# pip install agent-framework --pre
# Use `az login` to authenticate with Azure CLI
import os
import asyncio
from agent_framework.azure import AzureOpenAIResponsesClient
from azure.identity import AzureCliCredential


async def main():
    # Initialize a chat agent with Azure OpenAI Responses
    # the endpoint, deployment name, and api version can be set via environment variables
    # or they can be passed in directly to the AzureOpenAIResponsesClient constructor
    agent = AzureOpenAIResponsesClient(
        # endpoint=os.environ["AZURE_OPENAI_ENDPOINT"],
        # deployment_name=os.environ["AZURE_OPENAI_RESPONSES_DEPLOYMENT_NAME"],
        # api_version=os.environ["AZURE_OPENAI_API_VERSION"],
        # api_key=os.environ["AZURE_OPENAI_API_KEY"],  # Optional if using AzureCliCredential
        credential=AzureCliCredential(), # Optional, if using api_key
    ).create_agent(
        name="HaikuBot",
        instructions="You are an upbeat assistant that writes beautifully.",
    )

    print(await agent.run("Write a haiku about Microsoft Agent Framework."))

if __name__ == "__main__":
    asyncio.run(main())
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Basic Agent - .NET&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-c#"&gt;// dotnet add package Microsoft.Agents.AI.OpenAI --prerelease
// dotnet add package Azure.AI.OpenAI
// dotnet add package Azure.Identity
// Use `az login` to authenticate with Azure CLI
using System;
using Azure.AI.OpenAI;
using Azure.Identity;
using Microsoft.Agents.AI;
using OpenAI;

var endpoint = Environment.GetEnvironmentVariable("AZURE_OPENAI_ENDPOINT")!;
var deploymentName = Environment.GetEnvironmentVariable("AZURE_OPENAI_DEPLOYMENT_NAME")!;

var agent = new AzureOpenAIClient(new Uri(endpoint), new AzureCliCredential())
    .GetOpenAIResponseClient(deploymentName)
    .CreateAIAgent(name: "HaikuBot", instructions: "You are an upbeat assistant that writes beautifully.");

Console.WriteLine(await agent.RunAsync("Write a haiku about Microsoft Agent Framework."));
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;More Examples &amp;amp; Samples&lt;/h2&gt; 
&lt;h3&gt;Python&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/agent-framework/main/python/samples/getting_started/agents"&gt;Getting Started with Agents&lt;/a&gt;: basic agent creation and tool usage&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/agent-framework/main/python/samples/getting_started/chat_client"&gt;Chat Client Examples&lt;/a&gt;: direct chat client usage patterns&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/agent-framework/main/python/samples/getting_started/workflows"&gt;Getting Started with Workflows&lt;/a&gt;: basic workflow creation and integration with agents&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;.NET&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/agent-framework/main/dotnet/samples/GettingStarted/Agents"&gt;Getting Started with Agents&lt;/a&gt;: basic agent creation and tool usage&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/agent-framework/main/dotnet/samples/GettingStarted/AgentProviders"&gt;Agent Provider Samples&lt;/a&gt;: samples showing different agent providers&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/agent-framework/main/dotnet/samples/GettingStarted/Workflows"&gt;Workflow Samples&lt;/a&gt;: advanced multi-agent patterns and workflow orchestration&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributor Resources&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/agent-framework/main/CONTRIBUTING.md"&gt;Contributing Guide&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/agent-framework/main/python/DEV_SETUP.md"&gt;Python Development Guide&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/agent-framework/main/docs/design"&gt;Design Documents&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/agent-framework/main/docs/decisions"&gt;Architectural Decision Records&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Important Notes&lt;/h2&gt; 
&lt;p&gt;If you use the Microsoft Agent Framework to build applications that operate with third-party servers or agents, you do so at your own risk. We recommend reviewing all data being shared with third-party servers or agents and being cognizant of third-party practices for retention and location of data. It is your responsibility to manage whether your data will flow outside of your organization's Azure compliance and geographic boundaries and any related implications.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>coleam00/ottomator-agents</title>
      <link>https://github.com/coleam00/ottomator-agents</link>
      <description>&lt;p&gt;All the open source AI Agents hosted on the oTTomator Live Agent Studio platform!&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;What is the Live Agent Studio?&lt;/h1&gt; 
&lt;p&gt;The &lt;a href="https://studio.ottomator.ai"&gt;Live Agent Studio&lt;/a&gt; is a community-driven platform developed by &lt;a href="https://ottomator.ai"&gt;oTTomator&lt;/a&gt; for you to explore cutting-edge AI agents and learn how to implement them for yourself or your business! All agents on this platform are open source and, over time, will cover a very large variety of use cases.&lt;/p&gt; 
&lt;p&gt;The goal with the studio is to build an educational platform for you to learn how to do incredible things with AI, while still providing practical value so that you‚Äôll want to use the agents just for the sake of what they can do for you!&lt;/p&gt; 
&lt;p&gt;This platform is still in beta ‚Äì expect longer response times under load, a rapidly growing agent library over the coming months, and a lot more content on this platform soon on Cole Medin‚Äôs YouTube channel!&lt;/p&gt; 
&lt;h1&gt;What is this Repository for?&lt;/h1&gt; 
&lt;p&gt;This repository contains the source code/workflow JSON for all the agents on the Live Agent Studio! Every agent being added to the platform is currently be open sourced here so we can not only create a curated collection of cutting-edge agents together as a community, but also learn from one another!&lt;/p&gt; 
&lt;h2&gt;Tokens&lt;/h2&gt; 
&lt;p&gt;Most agents on the Live Agent Studio cost tokens to use, which are purchasable on the platform. However, when you first sign in you are given some tokens to start so you can use the agents free of charge! The biggest reason agents cost tokens is that we pay for the LLM usage since we host all the agents developed by you and the rest of the community!&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://studio.ottomator.ai/pricing"&gt;Purchase Tokens&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Future Plans&lt;/h2&gt; 
&lt;p&gt;As the Live Agent Studio develops, it will become the go-to place to stay on top of what is possible with AI agents! Anytime there is a new AI technology, groundbreaking agent research, or a new tool/library to build agents with, it‚Äôll be featured through agents on the platform. It‚Äôs a tall order, but we have big plans for the oTTomator community, and we‚Äôre confident we can grow to accomplish this!&lt;/p&gt; 
&lt;h2&gt;FAQ&lt;/h2&gt; 
&lt;h3&gt;I want to build an agent to showcase in the Live Agent Studio! How do I do that?&lt;/h3&gt; 
&lt;p&gt;Head on over here to learn how to build an agent for the platform:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://studio.ottomator.ai/guide"&gt;Developer Guide&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Also check out &lt;a href="https://raw.githubusercontent.com/coleam00/ottomator-agents/main/~sample-n8n-agent~"&gt;the sample n8n agent&lt;/a&gt; for a starting point of building an n8n agent for the Live Agent Studio, and &lt;a href="https://raw.githubusercontent.com/coleam00/ottomator-agents/main/~sample-python-agent~"&gt;the sample Python agent&lt;/a&gt; for Python.&lt;/p&gt; 
&lt;h3&gt;How many tokens does it cost to use an agent?&lt;/h3&gt; 
&lt;p&gt;Each agent will charge tokens per prompt. The number of tokens depends on the agent, as some agents use larger LLMs, some call LLMs multiple times, and some use paid APIs.&lt;/p&gt; 
&lt;h3&gt;Where can I go to talk about all these agents and get help implementing them myself?&lt;/h3&gt; 
&lt;p&gt;Head on over to our Think Tank community and feel free to make a post!&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://thinktank.ottomator.ai"&gt;Think Tank Community&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;¬© 2024 Live Agent Studio. All rights reserved.&lt;br /&gt; Created by oTTomator&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>lukas-blecher/LaTeX-OCR</title>
      <link>https://github.com/lukas-blecher/LaTeX-OCR</link>
      <description>&lt;p&gt;pix2tex: Using a ViT to convert images of equations into LaTeX code.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;pix2tex - LaTeX OCR&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://github.com/lukas-blecher/LaTeX-OCR"&gt;&lt;img src="https://img.shields.io/github/license/lukas-blecher/LaTeX-OCR" alt="GitHub" /&gt;&lt;/a&gt; &lt;a href="https://pix2tex.readthedocs.io/en/latest/?badge=latest"&gt;&lt;img src="https://readthedocs.org/projects/pix2tex/badge/?version=latest" alt="Documentation Status" /&gt;&lt;/a&gt; &lt;a href="https://pypi.org/project/pix2tex"&gt;&lt;img src="https://img.shields.io/pypi/v/pix2tex?logo=pypi" alt="PyPI" /&gt;&lt;/a&gt; &lt;a href="https://pypi.org/project/pix2tex"&gt;&lt;img src="https://img.shields.io/pypi/dm/pix2tex?logo=pypi" alt="PyPI - Downloads" /&gt;&lt;/a&gt; &lt;a href="https://github.com/lukas-blecher/LaTeX-OCR/releases"&gt;&lt;img src="https://img.shields.io/github/downloads/lukas-blecher/LaTeX-OCR/total?color=blue&amp;amp;logo=github" alt="GitHub all releases" /&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/r/lukasblecher/pix2tex"&gt;&lt;img src="https://img.shields.io/docker/pulls/lukasblecher/pix2tex?logo=docker" alt="Docker Pulls" /&gt;&lt;/a&gt; &lt;a href="https://colab.research.google.com/github/lukas-blecher/LaTeX-OCR/blob/main/notebooks/LaTeX_OCR_test.ipynb"&gt;&lt;img src="https://colab.research.google.com/assets/colab-badge.svg?sanitize=true" alt="Open In Colab" /&gt;&lt;/a&gt; &lt;a href="https://huggingface.co/spaces/lukbl/LaTeX-OCR"&gt;&lt;img src="https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Spaces-blue" alt="Hugging Face Spaces" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;The goal of this project is to create a learning based system that takes an image of a math formula and returns corresponding LaTeX code.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://user-images.githubusercontent.com/55287601/109183599-69431f00-778e-11eb-9809-d42b9451e018.png" alt="header" /&gt;&lt;/p&gt; 
&lt;h2&gt;Using the model&lt;/h2&gt; 
&lt;p&gt;To run the model you need Python 3.7+&lt;/p&gt; 
&lt;p&gt;If you don't have PyTorch installed. Follow their instructions &lt;a href="https://pytorch.org/get-started/locally/"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Install the package &lt;code&gt;pix2tex&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;pip install "pix2tex[gui]"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Model checkpoints will be downloaded automatically.&lt;/p&gt; 
&lt;p&gt;There are three ways to get a prediction from an image.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;You can use the command line tool by calling &lt;code&gt;pix2tex&lt;/code&gt;. Here you can parse already existing images from the disk and images in your clipboard.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Thanks to &lt;a href="https://github.com/katie-lim"&gt;@katie-lim&lt;/a&gt;, you can use a nice user interface as a quick way to get the model prediction. Just call the GUI with &lt;code&gt;latexocr&lt;/code&gt;. From here you can take a screenshot and the predicted latex code is rendered using &lt;a href="https://www.mathjax.org/"&gt;MathJax&lt;/a&gt; and copied to your clipboard.&lt;/p&gt; &lt;p&gt;Under linux, it is possible to use the GUI with &lt;code&gt;gnome-screenshot&lt;/code&gt; (which comes with multiple monitor support). For other Wayland compositers, &lt;code&gt;grim&lt;/code&gt; and &lt;code&gt;slurp&lt;/code&gt; will be used for wlroots-based Wayland compositers and &lt;code&gt;spectacle&lt;/code&gt; for KDE Plasma. Note that &lt;code&gt;gnome-screenshot&lt;/code&gt; is not compatible with wlroots or Qt based compositers. Since &lt;code&gt;gnome-screenshot&lt;/code&gt; will be preferred when available, you may have to set the environment variable &lt;code&gt;SCREENSHOT_TOOL&lt;/code&gt; to &lt;code&gt;grim&lt;/code&gt; or &lt;code&gt;spectacle&lt;/code&gt; in these cases (other available values are &lt;code&gt;gnome-screenshot&lt;/code&gt; and &lt;code&gt;pil&lt;/code&gt;).&lt;/p&gt; &lt;p&gt;&lt;img src="https://user-images.githubusercontent.com/55287601/117812740-77b7b780-b262-11eb-81f6-fc19766ae2ae.gif" alt="demo" /&gt;&lt;/p&gt; &lt;p&gt;If the model is unsure about the what's in the image it might output a different prediction every time you click "Retry". With the &lt;code&gt;temperature&lt;/code&gt; parameter you can control this behavior (low temperature will produce the same result).&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;You can use an API. This has additional dependencies. Install via &lt;code&gt;pip install -U "pix2tex[api]"&lt;/code&gt; and run&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;python -m pix2tex.api.run
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;to start a &lt;a href="https://streamlit.io/"&gt;Streamlit&lt;/a&gt; demo that connects to the API at port 8502. There is also a docker image available for the API: &lt;a href="https://hub.docker.com/r/lukasblecher/pix2tex"&gt;https://hub.docker.com/r/lukasblecher/pix2tex&lt;/a&gt; &lt;a href="https://hub.docker.com/r/lukasblecher/pix2tex"&gt;&lt;img src="https://img.shields.io/docker/image-size/lukasblecher/pix2tex?logo=docker" alt="Docker Image Size (latest by date)" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;pre&gt;&lt;code&gt;docker pull lukasblecher/pix2tex:api
docker run --rm -p 8502:8502 lukasblecher/pix2tex:api
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;To also run the streamlit demo run&lt;/p&gt; &lt;pre&gt;&lt;code&gt;docker run --rm -it -p 8501:8501 --entrypoint python lukasblecher/pix2tex:api pix2tex/api/run.py
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;and navigate to &lt;a href="http://localhost:8501/"&gt;http://localhost:8501/&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Use from within Python&lt;/p&gt; &lt;pre&gt;&lt;code class="language-python"&gt;from PIL import Image
from pix2tex.cli import LatexOCR

img = Image.open('path/to/image.png')
model = LatexOCR()
print(model(img))
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;The model works best with images of smaller resolution. That's why I added a preprocessing step where another neural network predicts the optimal resolution of the input image. This model will automatically resize the custom image to best resemble the training data and thus increase performance of images found in the wild. Still it's not perfect and might not be able to handle huge images optimally, so don't zoom in all the way before taking a picture.&lt;/p&gt; 
&lt;p&gt;Always double check the result carefully. You can try to redo the prediction with an other resolution if the answer was wrong.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Want to use the package?&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;I'm trying to compile a documentation right now.&lt;/p&gt; 
&lt;p&gt;Visit here: &lt;a href="https://pix2tex.readthedocs.io/"&gt;https://pix2tex.readthedocs.io/&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Training the model &lt;a href="https://colab.research.google.com/github/lukas-blecher/LaTeX-OCR/blob/main/notebooks/LaTeX_OCR_training.ipynb"&gt;&lt;img src="https://colab.research.google.com/assets/colab-badge.svg?sanitize=true" alt="Open In Colab" /&gt;&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Install a couple of dependencies &lt;code&gt;pip install "pix2tex[train]"&lt;/code&gt;.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;First we need to combine the images with their ground truth labels. I wrote a dataset class (which needs further improving) that saves the relative paths to the images with the LaTeX code they were rendered with. To generate the dataset pickle file run&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code&gt;python -m pix2tex.dataset.dataset --equations path_to_textfile --images path_to_images --out dataset.pkl
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To use your own tokenizer pass it via &lt;code&gt;--tokenizer&lt;/code&gt; (See below).&lt;/p&gt; 
&lt;p&gt;You can find my generated training data on the &lt;a href="https://drive.google.com/drive/folders/13CA4vAmOmD_I_dSbvLp-Lf0s6KiaNfuO"&gt;Google Drive&lt;/a&gt; as well (formulae.zip - images, math.txt - labels). Repeat the step for the validation and test data. All use the same label text file.&lt;/p&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Edit the &lt;code&gt;data&lt;/code&gt; (and &lt;code&gt;valdata&lt;/code&gt;) entry in the config file to the newly generated &lt;code&gt;.pkl&lt;/code&gt; file. Change other hyperparameters if you want to. See &lt;code&gt;pix2tex/model/settings/config.yaml&lt;/code&gt; for a template.&lt;/li&gt; 
 &lt;li&gt;Now for the actual training run&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code&gt;python -m pix2tex.train --config path_to_config_file
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you want to use your own data you might be interested in creating your own tokenizer with&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;python -m pix2tex.dataset.dataset --equations path_to_textfile --vocab-size 8000 --out tokenizer.json
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Don't forget to update the path to the tokenizer in the config file and set &lt;code&gt;num_tokens&lt;/code&gt; to your vocabulary size.&lt;/p&gt; 
&lt;h2&gt;Model&lt;/h2&gt; 
&lt;p&gt;The model consist of a ViT [&lt;a href="https://raw.githubusercontent.com/lukas-blecher/LaTeX-OCR/main/#References"&gt;1&lt;/a&gt;] encoder with a ResNet backbone and a Transformer [&lt;a href="https://raw.githubusercontent.com/lukas-blecher/LaTeX-OCR/main/#References"&gt;2&lt;/a&gt;] decoder.&lt;/p&gt; 
&lt;h3&gt;Performance&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;BLEU score&lt;/th&gt; 
   &lt;th&gt;normed edit distance&lt;/th&gt; 
   &lt;th&gt;token accuracy&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;0.88&lt;/td&gt; 
   &lt;td&gt;0.10&lt;/td&gt; 
   &lt;td&gt;0.60&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Data&lt;/h2&gt; 
&lt;p&gt;We need paired data for the network to learn. Luckily there is a lot of LaTeX code on the internet, e.g. &lt;a href="https://www.wikipedia.org"&gt;wikipedia&lt;/a&gt;, &lt;a href="https://www.arxiv.org"&gt;arXiv&lt;/a&gt;. We also use the formulae from the &lt;a href="https://zenodo.org/record/56198#.V2px0jXT6eA"&gt;im2latex-100k&lt;/a&gt; [&lt;a href="https://raw.githubusercontent.com/lukas-blecher/LaTeX-OCR/main/#References"&gt;3&lt;/a&gt;] dataset. All of it can be found &lt;a href="https://drive.google.com/drive/folders/13CA4vAmOmD_I_dSbvLp-Lf0s6KiaNfuO"&gt;here&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Dataset Requirements&lt;/h3&gt; 
&lt;p&gt;In order to render the math in many different fonts we use XeLaTeX, generate a PDF and finally convert it to a PNG. For the last step we need to use some third party tools:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.ctan.org/pkg/xetex"&gt;XeLaTeX&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://imagemagick.org/"&gt;ImageMagick&lt;/a&gt; with &lt;a href="https://www.ghostscript.com/index.html"&gt;Ghostscript&lt;/a&gt;. (for converting pdf to png)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://nodejs.org/"&gt;Node.js&lt;/a&gt; to run &lt;a href="https://github.com/KaTeX/KaTeX"&gt;KaTeX&lt;/a&gt; (for normalizing Latex code)&lt;/li&gt; 
 &lt;li&gt;Python 3.7+ &amp;amp; dependencies (specified in &lt;code&gt;setup.py&lt;/code&gt;)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Fonts&lt;/h3&gt; 
&lt;p&gt;Latin Modern Math, GFSNeohellenicMath.otf, Asana Math, XITS Math, Cambria Math&lt;/p&gt; 
&lt;h2&gt;TODO&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; add more evaluation metrics&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; create a GUI&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; add beam search&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; support handwritten formulae (kinda done, see training colab notebook)&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; reduce model size (distillation)&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; find optimal hyperparameters&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; tweak model structure&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; fix data scraping and scrape more data&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; trace the model (&lt;a href="https://github.com/lukas-blecher/LaTeX-OCR/issues/2"&gt;#2&lt;/a&gt;)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contribution&lt;/h2&gt; 
&lt;p&gt;Contributions of any kind are welcome.&lt;/p&gt; 
&lt;h2&gt;Acknowledgment&lt;/h2&gt; 
&lt;p&gt;Code taken and modified from &lt;a href="https://github.com/lucidrains"&gt;lucidrains&lt;/a&gt;, &lt;a href="https://github.com/rwightman/pytorch-image-models"&gt;rwightman&lt;/a&gt;, &lt;a href="https://github.com/harvardnlp/im2markup"&gt;im2markup&lt;/a&gt;, &lt;a href="https://github.com/soskek/arxiv_leaks"&gt;arxiv_leaks&lt;/a&gt;, &lt;a href="https://github.com/pkra/MathJax-single-file"&gt;pkra: Mathjax&lt;/a&gt;, &lt;a href="https://github.com/harupy/snipping-tool"&gt;harupy: snipping tool&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;References&lt;/h2&gt; 
&lt;p&gt;[1] &lt;a href="https://arxiv.org/abs/2010.11929"&gt;An Image is Worth 16x16 Words&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[2] &lt;a href="https://arxiv.org/abs/1706.03762"&gt;Attention Is All You Need&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[3] &lt;a href="https://arxiv.org/abs/1609.04938v2"&gt;Image-to-Markup Generation with Coarse-to-Fine Attention&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>scikit-learn/scikit-learn</title>
      <link>https://github.com/scikit-learn/scikit-learn</link>
      <description>&lt;p&gt;scikit-learn: machine learning in Python&lt;/p&gt;&lt;hr&gt;&lt;p&gt;.. -&lt;em&gt;- mode: rst -&lt;/em&gt;-&lt;/p&gt; 
&lt;p&gt;|Azure| |Codecov| |CircleCI| |Nightly wheels| |Ruff| |PythonVersion| |PyPI| |DOI| |Benchmark|&lt;/p&gt; 
&lt;p&gt;.. |Azure| image:: &lt;a href="https://dev.azure.com/scikit-learn/scikit-learn/_apis/build/status/scikit-learn.scikit-learn?branchName=main"&gt;https://dev.azure.com/scikit-learn/scikit-learn/_apis/build/status/scikit-learn.scikit-learn?branchName=main&lt;/a&gt; :target: &lt;a href="https://dev.azure.com/scikit-learn/scikit-learn/_build/latest?definitionId=1&amp;amp;branchName=main"&gt;https://dev.azure.com/scikit-learn/scikit-learn/_build/latest?definitionId=1&amp;amp;branchName=main&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;.. |CircleCI| image:: &lt;a href="https://circleci.com/gh/scikit-learn/scikit-learn/tree/main.svg?style=shield"&gt;https://circleci.com/gh/scikit-learn/scikit-learn/tree/main.svg?style=shield&lt;/a&gt; :target: &lt;a href="https://circleci.com/gh/scikit-learn/scikit-learn"&gt;https://circleci.com/gh/scikit-learn/scikit-learn&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;.. |Codecov| image:: &lt;a href="https://codecov.io/gh/scikit-learn/scikit-learn/branch/main/graph/badge.svg?token=Pk8G9gg3y9"&gt;https://codecov.io/gh/scikit-learn/scikit-learn/branch/main/graph/badge.svg?token=Pk8G9gg3y9&lt;/a&gt; :target: &lt;a href="https://codecov.io/gh/scikit-learn/scikit-learn"&gt;https://codecov.io/gh/scikit-learn/scikit-learn&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;.. |Nightly wheels| image:: &lt;a href="https://github.com/scikit-learn/scikit-learn/actions/workflows/wheels.yml/badge.svg?event=schedule"&gt;https://github.com/scikit-learn/scikit-learn/actions/workflows/wheels.yml/badge.svg?event=schedule&lt;/a&gt; :target: &lt;a href="https://github.com/scikit-learn/scikit-learn/actions?query=workflow%3A%22Wheel+builder%22+event%3Aschedule"&gt;https://github.com/scikit-learn/scikit-learn/actions?query=workflow%3A%22Wheel+builder%22+event%3Aschedule&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;.. |Ruff| image:: &lt;a href="https://img.shields.io/badge/code%20style-ruff-000000.svg"&gt;https://img.shields.io/badge/code%20style-ruff-000000.svg&lt;/a&gt; :target: &lt;a href="https://github.com/astral-sh/ruff"&gt;https://github.com/astral-sh/ruff&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;.. |PythonVersion| image:: &lt;a href="https://img.shields.io/pypi/pyversions/scikit-learn.svg"&gt;https://img.shields.io/pypi/pyversions/scikit-learn.svg&lt;/a&gt; :target: &lt;a href="https://pypi.org/project/scikit-learn/"&gt;https://pypi.org/project/scikit-learn/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;.. |PyPI| image:: &lt;a href="https://img.shields.io/pypi/v/scikit-learn"&gt;https://img.shields.io/pypi/v/scikit-learn&lt;/a&gt; :target: &lt;a href="https://pypi.org/project/scikit-learn"&gt;https://pypi.org/project/scikit-learn&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;.. |DOI| image:: &lt;a href="https://zenodo.org/badge/21369/scikit-learn/scikit-learn.svg"&gt;https://zenodo.org/badge/21369/scikit-learn/scikit-learn.svg&lt;/a&gt; :target: &lt;a href="https://zenodo.org/badge/latestdoi/21369/scikit-learn/scikit-learn"&gt;https://zenodo.org/badge/latestdoi/21369/scikit-learn/scikit-learn&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;.. |Benchmark| image:: &lt;a href="https://img.shields.io/badge/Benchmarked%20by-asv-blue"&gt;https://img.shields.io/badge/Benchmarked%20by-asv-blue&lt;/a&gt; :target: &lt;a href="https://scikit-learn.org/scikit-learn-benchmarks"&gt;https://scikit-learn.org/scikit-learn-benchmarks&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;.. |PythonMinVersion| replace:: 3.10 .. |NumPyMinVersion| replace:: 1.24.1 .. |SciPyMinVersion| replace:: 1.10.0 .. |JoblibMinVersion| replace:: 1.3.0 .. |ThreadpoolctlMinVersion| replace:: 3.2.0 .. |MatplotlibMinVersion| replace:: 3.6.1 .. |Scikit-ImageMinVersion| replace:: 0.19.0 .. |PandasMinVersion| replace:: 1.5.0 .. |SeabornMinVersion| replace:: 0.9.1 .. |PytestMinVersion| replace:: 7.1.2 .. |PlotlyMinVersion| replace:: 5.14.0&lt;/p&gt; 
&lt;p&gt;.. image:: &lt;a href="https://raw.githubusercontent.com/scikit-learn/scikit-learn/main/doc/logos/scikit-learn-logo.png"&gt;https://raw.githubusercontent.com/scikit-learn/scikit-learn/main/doc/logos/scikit-learn-logo.png&lt;/a&gt; :target: &lt;a href="https://scikit-learn.org/"&gt;https://scikit-learn.org/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;scikit-learn&lt;/strong&gt; is a Python module for machine learning built on top of SciPy and is distributed under the 3-Clause BSD license.&lt;/p&gt; 
&lt;p&gt;The project was started in 2007 by David Cournapeau as a Google Summer of Code project, and since then many volunteers have contributed. See the &lt;code&gt;About us &amp;lt;https://scikit-learn.org/dev/about.html#authors&amp;gt;&lt;/code&gt;__ page for a list of core contributors.&lt;/p&gt; 
&lt;p&gt;It is currently maintained by a team of volunteers.&lt;/p&gt; 
&lt;p&gt;Website: &lt;a href="https://scikit-learn.org"&gt;https://scikit-learn.org&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;Dependencies&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;
scikit-learn requires:

- Python (&amp;gt;= |PythonMinVersion|)
- NumPy (&amp;gt;= |NumPyMinVersion|)
- SciPy (&amp;gt;= |SciPyMinVersion|)
- joblib (&amp;gt;= |JoblibMinVersion|)
- threadpoolctl (&amp;gt;= |ThreadpoolctlMinVersion|)

=======

Scikit-learn plotting capabilities (i.e., functions start with ``plot_`` and
classes end with ``Display``) require Matplotlib (&amp;gt;= |MatplotlibMinVersion|).
For running the examples Matplotlib &amp;gt;= |MatplotlibMinVersion| is required.
A few examples require scikit-image &amp;gt;= |Scikit-ImageMinVersion|, a few examples
require pandas &amp;gt;= |PandasMinVersion|, some examples require seaborn &amp;gt;=
|SeabornMinVersion| and Plotly &amp;gt;= |PlotlyMinVersion|.

User installation
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you already have a working installation of NumPy and SciPy, the easiest way to install scikit-learn is using &lt;code&gt;pip&lt;/code&gt;::&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;pip install -U scikit-learn
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;or &lt;code&gt;conda&lt;/code&gt;::&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;conda install -c conda-forge scikit-learn
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The documentation includes more detailed &lt;code&gt;installation instructions &amp;lt;https://scikit-learn.org/stable/install.html&amp;gt;&lt;/code&gt;_.&lt;/p&gt; 
&lt;h2&gt;Changelog&lt;/h2&gt; 
&lt;p&gt;See the &lt;code&gt;changelog &amp;lt;https://scikit-learn.org/dev/whats_new.html&amp;gt;&lt;/code&gt;__ for a history of notable changes to scikit-learn.&lt;/p&gt; 
&lt;h2&gt;Development&lt;/h2&gt; 
&lt;p&gt;We welcome new contributors of all experience levels. The scikit-learn community goals are to be helpful, welcoming, and effective. The &lt;code&gt;Development Guide &amp;lt;https://scikit-learn.org/stable/developers/index.html&amp;gt;&lt;/code&gt;_ has detailed information about contributing code, documentation, tests, and more. We've included some basic information in this README.&lt;/p&gt; 
&lt;p&gt;Important links&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;
- Official source code repo: https://github.com/scikit-learn/scikit-learn
- Download releases: https://pypi.org/project/scikit-learn/
- Issue tracker: https://github.com/scikit-learn/scikit-learn/issues

Source code
~~~~~~~~~~~

You can check the latest sources with the command::

    git clone https://github.com/scikit-learn/scikit-learn.git

Contributing
~~~~~~~~~~~~

To learn more about making a contribution to scikit-learn, please see our
`Contributing guide
&amp;lt;https://scikit-learn.org/dev/developers/contributing.html&amp;gt;`_.

Testing
~~~~~~~

After installation, you can launch the test suite from outside the source
directory (you will need to have ``pytest`` &amp;gt;= |PytestMinVersion| installed)::

    pytest sklearn

See the web page https://scikit-learn.org/dev/developers/contributing.html#testing-and-improving-test-coverage
for more information.

    Random number generation can be controlled during testing by setting
    the ``SKLEARN_SEED`` environment variable.

Submitting a Pull Request
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Before opening a Pull Request, have a look at the full Contributing page to make sure your code complies with our guidelines: &lt;a href="https://scikit-learn.org/stable/developers/index.html"&gt;https://scikit-learn.org/stable/developers/index.html&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Project History&lt;/h2&gt; 
&lt;p&gt;The project was started in 2007 by David Cournapeau as a Google Summer of Code project, and since then many volunteers have contributed. See the &lt;code&gt;About us &amp;lt;https://scikit-learn.org/dev/about.html#authors&amp;gt;&lt;/code&gt;__ page for a list of core contributors.&lt;/p&gt; 
&lt;p&gt;The project is currently maintained by a team of volunteers.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: &lt;code&gt;scikit-learn&lt;/code&gt; was previously referred to as &lt;code&gt;scikits.learn&lt;/code&gt;.&lt;/p&gt; 
&lt;h2&gt;Help and Support&lt;/h2&gt; 
&lt;p&gt;Documentation&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;
- HTML documentation (stable release): https://scikit-learn.org
- HTML documentation (development version): https://scikit-learn.org/dev/
- FAQ: https://scikit-learn.org/stable/faq.html

Communication
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Main Channels ^^^^^^^^^^^^^&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Website&lt;/strong&gt;: &lt;a href="https://scikit-learn.org"&gt;https://scikit-learn.org&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Blog&lt;/strong&gt;: &lt;a href="https://blog.scikit-learn.org"&gt;https://blog.scikit-learn.org&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Mailing list&lt;/strong&gt;: &lt;a href="https://mail.python.org/mailman/listinfo/scikit-learn"&gt;https://mail.python.org/mailman/listinfo/scikit-learn&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Developer &amp;amp; Support ^^^^^^^^^^^^^^^^^^^^^^&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;GitHub Discussions&lt;/strong&gt;: &lt;a href="https://github.com/scikit-learn/scikit-learn/discussions"&gt;https://github.com/scikit-learn/scikit-learn/discussions&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Stack Overflow&lt;/strong&gt;: &lt;a href="https://stackoverflow.com/questions/tagged/scikit-learn"&gt;https://stackoverflow.com/questions/tagged/scikit-learn&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Discord&lt;/strong&gt;: &lt;a href="https://discord.gg/h9qyrK8Jc8"&gt;https://discord.gg/h9qyrK8Jc8&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Social Media Platforms ^^^^^^^^^^^^^^^^^^^^^^&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;LinkedIn&lt;/strong&gt;: &lt;a href="https://www.linkedin.com/company/scikit-learn"&gt;https://www.linkedin.com/company/scikit-learn&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;YouTube&lt;/strong&gt;: &lt;a href="https://www.youtube.com/channel/UCJosFjYm0ZYVUARxuOZqnnw/playlists"&gt;https://www.youtube.com/channel/UCJosFjYm0ZYVUARxuOZqnnw/playlists&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Facebook&lt;/strong&gt;: &lt;a href="https://www.facebook.com/scikitlearnofficial/"&gt;https://www.facebook.com/scikitlearnofficial/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Instagram&lt;/strong&gt;: &lt;a href="https://www.instagram.com/scikitlearnofficial/"&gt;https://www.instagram.com/scikitlearnofficial/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;TikTok&lt;/strong&gt;: &lt;a href="https://www.tiktok.com/@scikit.learn"&gt;https://www.tiktok.com/@scikit.learn&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Bluesky&lt;/strong&gt;: &lt;a href="https://bsky.app/profile/scikit-learn.org"&gt;https://bsky.app/profile/scikit-learn.org&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Mastodon&lt;/strong&gt;: &lt;a href="https://mastodon.social/@sklearn@fosstodon.org"&gt;https://mastodon.social/@sklearn@fosstodon.org&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Resources ^^^^^^^^^&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Calendar&lt;/strong&gt;: &lt;a href="https://blog.scikit-learn.org/calendar/"&gt;https://blog.scikit-learn.org/calendar/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Logos &amp;amp; Branding&lt;/strong&gt;: &lt;a href="https://github.com/scikit-learn/scikit-learn/tree/main/doc/logos"&gt;https://github.com/scikit-learn/scikit-learn/tree/main/doc/logos&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Citation&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;
If you use scikit-learn in a scientific publication, we would appreciate citations: https://scikit-learn.org/stable/about.html#citing-scikit-learn
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>airweave-ai/airweave</title>
      <link>https://github.com/airweave-ai/airweave</link>
      <description>&lt;p&gt;Airweave lets agents search any app&lt;/p&gt;&lt;hr&gt;&lt;picture&gt; 
 &lt;source media="(prefers-color-scheme: dark)" srcset="frontend/public/logo-airweave-darkbg.svg" /&gt; 
 &lt;source media="(prefers-color-scheme: light)" srcset="frontend/public/logo-airweave-lightbg.svg" /&gt; 
 &lt;img width="1673" alt="airweave-lettermark" style="padding-bottom: 12px;" src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/public/logo-airweave-darkbg.svg?sanitize=true" /&gt; 
&lt;/picture&gt; 
&lt;div align="center"&gt; 
 &lt;h1&gt;Make Any App Searchable for AI Agents&lt;/h1&gt; 
 &lt;p&gt;&lt;a href="https://github.com/airweave-ai/airweave/actions/workflows/ruff.yml"&gt;&lt;img src="https://github.com/airweave-ai/airweave/actions/workflows/ruff.yml/badge.svg?sanitize=true" alt="Ruff" /&gt;&lt;/a&gt; &lt;a href="https://github.com/airweave-ai/airweave/actions/workflows/eslint.yml"&gt;&lt;img src="https://github.com/airweave-ai/airweave/actions/workflows/eslint.yml/badge.svg?sanitize=true" alt="ESLint" /&gt;&lt;/a&gt; &lt;a href="https://github.com/airweave-ai/airweave/actions/workflows/test-public-api.yml"&gt;&lt;img src="https://github.com/airweave-ai/airweave/actions/workflows/test-public-api.yml/badge.svg?sanitize=true" alt="System Tests" /&gt;&lt;/a&gt; &lt;a href="https://codecov.io/gh/airweave-ai/airweave"&gt;&lt;img src="https://codecov.io/gh/airweave-ai/airweave/branch/main/graph/badge.svg?sanitize=true" alt="Codecov" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/gDuebsWGkn"&gt;&lt;img src="https://img.shields.io/discord/1323415085011701870?label=Discord&amp;amp;logo=discord&amp;amp;logoColor=white&amp;amp;style=flat-square" alt="Discord" /&gt;&lt;/a&gt; &lt;br /&gt;&lt;/p&gt; 
 &lt;div style="padding-top: 16px;"&gt; 
  &lt;a href="https://trendshift.io/repositories/13748" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/13748" alt="airweave-ai%2Fairweave | Trendshift" style="width: 250px; height: 55px; margin-right: 24px;" width="250" height="55" /&gt;&lt;/a&gt;&amp;nbsp;&amp;nbsp;
  &lt;a href="https://www.ycombinator.com/launches/NX7-airweave-let-agents-search-any-app" target="_blank"&gt;&lt;img src="https://www.ycombinator.com/launches/NX7-airweave-let-agents-search-any-app/upvote_embed.svg?sanitize=true" alt="Launch YC: Airweave - Let Agents Search Any App" style="margin-left: 12px;" /&gt;&lt;/a&gt; 
 &lt;/div&gt; 
 &lt;br /&gt; 
 &lt;p&gt;‚≠ê &lt;strong&gt;Help us reach more developers and grow the Airweave community. Star this repo!&lt;/strong&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;Overview&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Airweave is a tool that lets agents search any app.&lt;/strong&gt; It connects to apps, productivity tools, databases, or document stores and transforms their contents into searchable knowledge bases, accessible through a standardized interface for agents.&lt;/p&gt; 
&lt;p&gt;The search interface is exposed via REST API or MCP. When using MCP, Airweave essentially builds a semantically searchable MCP server. The platform handles everything from auth and extraction to embedding and serving.&lt;/p&gt; 
&lt;p&gt;üì∫ Check out the quick demo below:&lt;/p&gt; 
&lt;p&gt;
 &lt;video width="100%" src="https://github.com/user-attachments/assets/995e4a36-3f88-4d8e-b401-6ca43db0c7bf" controls&gt;&lt;/video&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/airweave-ai/airweave/tree/main/examples"&gt;&lt;strong&gt;üîó Example notebooks&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Table of Contents&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/airweave-ai/airweave/main/#airweave"&gt;Airweave&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/airweave-ai/airweave/main/#overview"&gt;Overview&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/airweave-ai/airweave/main/#table-of-contents"&gt;Table of Contents&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/airweave-ai/airweave/main/#-quick-start"&gt;üöÄ Quick Start&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/airweave-ai/airweave/main/#-supported-integrations"&gt;üîå Supported Integrations&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/airweave-ai/airweave/main/#-usage"&gt;üíª Usage&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/airweave-ai/airweave/main/#frontend"&gt;Frontend&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/airweave-ai/airweave/main/#api"&gt;API&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/airweave-ai/airweave/main/#-sdks"&gt;üì¶ SDKs&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/airweave-ai/airweave/main/#python"&gt;Python&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/airweave-ai/airweave/main/#typescriptjavascript"&gt;TypeScript/JavaScript&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/airweave-ai/airweave/main/#-key-features"&gt;üîë Key Features&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/airweave-ai/airweave/main/#-tech-stack"&gt;üîß Technology Stack&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/airweave-ai/airweave/main/#-contributing"&gt;üë• Contributing&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/airweave-ai/airweave/main/#-license"&gt;üìÑ License&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/airweave-ai/airweave/main/#-connect"&gt;üîó Connect&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üöÄ Quick Start&lt;/h2&gt; 
&lt;h3&gt;Managed Service: &lt;a href="https://app.airweave.ai/"&gt;Airweave Cloud&lt;/a&gt;&lt;/h3&gt; 
&lt;h3&gt;Self-hosted:&lt;/h3&gt; 
&lt;p&gt;Make sure docker and docker-compose are installed, then...&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# 1. Clone the repository
git clone https://github.com/airweave-ai/airweave.git
cd airweave

# 2. Build and run
chmod +x start.sh
./start.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;That's it! Access the dashboard at &lt;a href="http://localhost:8080"&gt;http://localhost:8080&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üîå Supported Integrations&lt;/h2&gt; 
&lt;!-- START_APP_GRID --&gt; 
&lt;p align="center"&gt; &lt;/p&gt;
&lt;div style="display: inline-block; text-align: center; padding: 4px;"&gt; 
 &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/asana.svg?sanitize=true" alt="Asana" width="40" height="40" style="margin: 4px; padding: 2px;" /&gt;
 &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/bitbucket.svg?sanitize=true" alt="Bitbucket" width="40" height="40" style="margin: 4px; padding: 2px;" /&gt;
 &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/confluence.svg?sanitize=true" alt="Confluence" width="40" height="40" style="margin: 4px; padding: 2px;" /&gt;
 &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/dropbox.svg?sanitize=true" alt="Dropbox" width="40" height="40" style="margin: 4px; padding: 2px;" /&gt;
 &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/github.svg?sanitize=true" alt="Github" width="40" height="40" style="margin: 4px; padding: 2px;" /&gt;
 &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/gmail.svg?sanitize=true" alt="Gmail" width="40" height="40" style="margin: 4px; padding: 2px;" /&gt;
 &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/google_calendar.svg?sanitize=true" alt="Google Calendar" width="40" height="40" style="margin: 4px; padding: 2px;" /&gt;
 &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/google_drive.svg?sanitize=true" alt="Google Drive" width="40" height="40" style="margin: 4px; padding: 2px;" /&gt; 
 &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/hubspot.svg?sanitize=true" alt="Hubspot" width="40" height="40" style="margin: 4px; padding: 2px;" /&gt;
 &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/jira.svg?sanitize=true" alt="Jira" width="40" height="40" style="margin: 4px; padding: 2px;" /&gt;
 &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/linear.svg?sanitize=true" alt="Linear" width="40" height="40" style="margin: 4px; padding: 2px;" /&gt;
 &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/monday.svg?sanitize=true" alt="Monday" width="40" height="40" style="margin: 4px; padding: 2px;" /&gt;
 &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/notion.svg?sanitize=true" alt="Notion" width="40" height="40" style="margin: 4px; padding: 2px;" /&gt;
 &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/onedrive.svg?sanitize=true" alt="Onedrive" width="40" height="40" style="margin: 4px; padding: 2px;" /&gt;
 &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/outlook_calendar.svg?sanitize=true" alt="Outlook Calendar" width="40" height="40" style="margin: 4px; padding: 2px;" /&gt;
 &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/outlook_mail.svg?sanitize=true" alt="Outlook Mail" width="40" height="40" style="margin: 4px; padding: 2px;" /&gt;
 &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/postgresql.svg?sanitize=true" alt="Postgresql" width="40" height="40" style="margin: 4px; padding: 2px;" /&gt; 
 &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/slack.svg?sanitize=true" alt="Slack" width="40" height="40" style="margin: 4px; padding: 2px;" /&gt;
 &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/stripe.svg?sanitize=true" alt="Stripe" width="40" height="40" style="margin: 4px; padding: 2px;" /&gt;
 &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/todoist.svg?sanitize=true" alt="Todoist" width="40" height="40" style="margin: 4px; padding: 2px;" /&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;!-- END_APP_GRID --&gt; 
&lt;h2&gt;üíª Usage&lt;/h2&gt; 
&lt;h3&gt;Frontend&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Access the UI at &lt;code&gt;http://localhost:8080&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Connect sources, configure syncs, and query data&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;API&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Swagger docs: &lt;code&gt;http://localhost:8001/docs&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Create connections, trigger syncs, and search data&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üì¶ SDKs&lt;/h2&gt; 
&lt;h3&gt;Python&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install airweave-sdk
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from airweave import AirweaveSDK

client = AirweaveSDK(
    api_key="YOUR_API_KEY",
    base_url="http://localhost:8001"
)
client.collections.create(
    name="name",
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;TypeScript/JavaScript&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;npm install @airweave/sdk
# or
yarn add @airweave/sdk
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-typescript"&gt;import { AirweaveSDKClient, AirweaveSDKEnvironment } from "@airweave/sdk";

const client = new AirweaveSDKClient({
    apiKey: "YOUR_API_KEY",
    environment: AirweaveSDKEnvironment.Local
});
await client.collections.create({
    name: "name",
});
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;üîë Key Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Data synchronization&lt;/strong&gt; from 25+ sources with minimal config&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Entity extraction&lt;/strong&gt; and transformation pipeline&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Multi-tenant&lt;/strong&gt; architecture with OAuth2&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Incremental updates&lt;/strong&gt; using content hashing&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Semantic search&lt;/strong&gt; for agent queries&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Versioning&lt;/strong&gt; for data changes&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üîß Tech Stack&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Frontend&lt;/strong&gt;: React/TypeScript with ShadCN&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Backend&lt;/strong&gt;: FastAPI (Python)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Databases&lt;/strong&gt;: PostgreSQL (metadata), Qdrant (vectors)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Deployment&lt;/strong&gt;: Docker Compose (dev), Kubernetes (prod)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üë• Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome contributions! Please check &lt;a href="https://github.com/airweave-ai/airweave/raw/main/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; for details.&lt;/p&gt; 
&lt;h2&gt;üìÑ License&lt;/h2&gt; 
&lt;p&gt;Airweave is released under the &lt;a href="https://raw.githubusercontent.com/airweave-ai/airweave/main/LICENSE"&gt;MIT&lt;/a&gt; license.&lt;/p&gt; 
&lt;h2&gt;üîó Connect&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://discord.com/invite/484HY9Ehxt"&gt;Discord&lt;/a&gt;&lt;/strong&gt; - Get help and discuss features&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/airweave-ai/airweave/issues"&gt;GitHub Issues&lt;/a&gt;&lt;/strong&gt; - Report bugs or request features&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://x.com/airweave_ai"&gt;Twitter&lt;/a&gt;&lt;/strong&gt; - Follow for updates&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>google/tunix</title>
      <link>https://github.com/google/tunix</link>
      <description>&lt;p&gt;A JAX-native LLM Post-Training Library&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Tunix: A JAX-native LLM Post-Training Library&lt;/h1&gt; 
&lt;div align="left"&gt; 
 &lt;p&gt;&lt;a href="https://tunix.readthedocs.io/en/latest/index.html"&gt;&lt;img src="https://img.shields.io/badge/documentation-blue" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;strong&gt;Tunix(Tune-in-JAX)&lt;/strong&gt; is a JAX based library designed to streamline the post-training of Large Language Models. It provides efficient and scalable supports for:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Supervised Fine-Tuning&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Reinforcement Learning (RL)&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Knowledge Distillation&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Tunix leverages the power of JAX for accelerated computation and seamless integration with JAX-based modeling framework &lt;a href="https://flax.readthedocs.io/en/latest/nnx_basics.html"&gt;Flax NNX&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Current Status: Early Development&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Tunix is in early development. We're actively working to expand its capabilities, usability and improve its performance. Stay tuned for upcoming updates and new features!&lt;/p&gt; 
&lt;h2&gt;Key Features &amp;amp; Highlights&lt;/h2&gt; 
&lt;p&gt;Tunix is still under development, here's a glimpse of the current features:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Supervised Fine-Tuning:&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Full Weights Fine-Tuning&lt;/li&gt; 
   &lt;li&gt;Parameter-Efficient Fine-Tuning (PEFT) with LoRA/Q-LoRA Layers&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Reinforcement Learning (RL):&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Proximal Policy Optimization (PPO)&lt;/li&gt; 
   &lt;li&gt;Group Relative Policy Optimization (GRPO)&lt;/li&gt; 
   &lt;li&gt;Token-level Group Sequence Policy Optimization (GSPO-token)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Preference Fine-Tuning:&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Preference alignments with Direct Preference Optimization (DPO)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Knowledge Distillation:&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Logit Strategy: A classic approach where the student learns to match the teacher's output probability distribution.&lt;/li&gt; 
   &lt;li&gt;Attention Transfer &amp;amp; Projection Strategies: Methods to align the attention mechanisms between the student and teacher models.&lt;/li&gt; 
   &lt;li&gt;Feature Pooling &amp;amp; Projection Strategies: General techniques for matching intermediate feature representations, even between models of different architectures.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Modularity:&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Components are designed to be reusable and composable&lt;/li&gt; 
   &lt;li&gt;Easy to customize and extend&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Efficiency:&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Native support of common model sharding strategies such as DP, FSDP and TP&lt;/li&gt; 
   &lt;li&gt;Designed for distributed training on accelerators (TPU)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Upcoming&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Agentic RL Training:&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Async Rollout&lt;/li&gt; 
   &lt;li&gt;Multi-turn &amp;amp; multi-step support&lt;/li&gt; 
   &lt;li&gt;Tool usage&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Advanced Algorithms:&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Addtional state-of-the-art RL and distillation algorithms&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Scalability:&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Multi-host distributed training&lt;/li&gt; 
   &lt;li&gt;Optimized rollout with vLLM&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;User Guides:&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;More advanced RL recipe&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;You can install Tunix in several ways:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;From PyPI (recommended):&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;pip install "tunix[prod]"
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Directly from GitHub (latest main branch)&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;pip install git+https://github.com/google/tunix
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt;From source (editable install) If you plan to modify the codebase and run it in development mode:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;git clone https://github.com/google/tunix.git
cd tunix
pip install -e ".[dev]"

&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;p&gt;To get started, we have a bunch of detailed examples and tutorials.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/google/tunix/raw/main/examples/qlora_demo.ipynb"&gt;PEFT Gemma with QLoRA&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/google/tunix/raw/main/examples/grpo_demo.ipynb"&gt;Training Gemma on grade school Math problems using GRPO&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/google/tunix/raw/main/examples/logit_distillation.ipynb"&gt;Logit Distillation using Gemma models&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;To setup Jupyter notebook on single host GCP TPU VM, please refer to the &lt;a href="https://github.com/google/tunix/raw/main/scripts/setup_notebook_tpu_single_host.sh"&gt;setup script&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;We plan to provide clear, concise documentation and more examples in the near future.&lt;/p&gt; 
&lt;h2&gt;Contributing and Feedbacks&lt;/h2&gt; 
&lt;p&gt;We welcome contributions! As Tunix is in early development, the contribution process is still being formalized. A rough draft of the contribution process is present &lt;a href="https://github.com/google/tunix/raw/main/CONTRIBUTING.md"&gt;here&lt;/a&gt;. In the meantime, you can make feature requests, report issues and ask questions in our &lt;a href="https://github.com/google/tunix/discussions"&gt;Tunix GitHub discussion forum&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Collaborations and Partnership&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://github.com/lmgame-org/GRL/raw/tunix_integration_dev/README.md"&gt;GRL&lt;/a&gt; (Game Reinforcement Learning), developed by &lt;a href="https://hao-ai-lab.github.io/"&gt;Hao AI Lab&lt;/a&gt; from UCSD, is an open-source framework for post-training large language models through multi-turn RL on challenging games. In collaboration with Tunix, GRL integrates seamless TPU support‚Äîletting users quickly run scalable, reproducible RL experiments (like PPO rollouts on Qwen2.5-0.5B-Instruct) on TPU v4 meshes with &lt;a href="https://github.com/lmgame-org/GRL/raw/tunix_integration_dev/README.md#5-launch-the-quick-test-defaults-to-qwen2505b-supports-4-tpu-v4-with-mesh-22"&gt;minimal setup&lt;/a&gt;. This partnership empowers the community to push LLM capabilities further, combining Tunix‚Äôs optimized TPU runtime with GRL‚Äôs flexible game RL pipeline for cutting-edge research and easy reproducibility.&lt;/p&gt; 
&lt;h2&gt;Stay Tuned!&lt;/h2&gt; 
&lt;p&gt;Thank you for your interest in Tunix. We're working hard to bring you a powerful and efficient library for LLM post-training. Please follow our progress and check back for updates!&lt;/p&gt; 
&lt;h2&gt;Acknowledgements&lt;/h2&gt; 
&lt;p&gt;Thank you to all our wonderful contributors!&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/google/tunix/graphs/contributors"&gt;&lt;img src="https://contrib.rocks/image?repo=google/tunix" alt="Contributors" /&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>SigmaHQ/sigma</title>
      <link>https://github.com/SigmaHQ/sigma</link>
      <description>&lt;p&gt;Main Sigma Rule Repository&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Sigma - Generic Signature Format for SIEM Systems&lt;/h1&gt; 
&lt;a href="https://sigmahq.io/"&gt; &lt;p align="center"&gt; &lt;br /&gt; 
  &lt;picture&gt; 
   &lt;source media="(prefers-color-scheme: dark)" srcset="./images/sigma_logo_dark.png" /&gt; 
   &lt;img width="454" alt="Sigma Logo" src="https://raw.githubusercontent.com/SigmaHQ/sigma/master/images/sigma_logo_light.png" /&gt; 
  &lt;/picture&gt; &lt;/p&gt; &lt;/a&gt; 
&lt;br /&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/SigmaHQ/sigma/actions?query=branch%3Amaster"&gt;&lt;img src="https://github.com/SigmaHQ/sigma/actions/workflows/sigma-test.yml/badge.svg?branch=master" alt="Sigma Build Status" /&gt;&lt;/a&gt; &lt;a href="https://sigmahq.io/"&gt;&lt;img src="https://cdn.jsdelivr.net/gh/SigmaHQ/sigmahq.github.io@master/images/Sigma%20Official%20Badge.svg?sanitize=true" alt="Sigma Official Badge" /&gt;&lt;/a&gt; &lt;img alt="GitHub Repo stars" src="https://img.shields.io/github/stars/SigmaHQ/sigma" /&gt; &lt;img alt="GitHub all releases" src="https://img.shields.io/github/downloads/SigmaHq/Sigma/total" /&gt; &lt;br /&gt; &lt;a href="https://opensourcesecurityindex.io/" target="_blank" rel="noopener"&gt; &lt;img style="width: 170px;" src="https://opensourcesecurityindex.io/badge.svg?sanitize=true" alt="Open Source Security Index - Fastest Growing Open Source Security Projects" width="170" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p&gt;Welcome to the Sigma main rule repository. The place where detection engineers, threat hunters and all defensive security practitioners collaborate on detection rules. The repository offers more than 3000 detection rules of different type and aims to make reliable detections accessible to all at no cost.&lt;/p&gt; 
&lt;p&gt;Currently the repository offers three types of rules:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/SigmaHQ/sigma/master/rules/"&gt;Generic Detection Rules&lt;/a&gt; - Are threat agnostic, their aim is to detect a behavior or an implementation of a technique or procedure that was, can or will be used by a potential threat actor.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/SigmaHQ/sigma/master/rules-threat-hunting/"&gt;Threat Hunting Rules&lt;/a&gt; - Are broader in scope and are meant to give the analyst a starting point to hunt for potential suspicious or malicious activity&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/SigmaHQ/sigma/master/rules-emerging-threats/"&gt;Emerging Threat Rules&lt;/a&gt; - Are rules that cover specific threats, that are timely and relevant for certain periods of time. These threats include specific APT campaigns, exploitation of Zero-Day vulnerabilities, specific malware used during an attack,...etc.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Explore Sigma&lt;/h2&gt; 
&lt;p&gt;To start exploring the Sigma ecosystem, please visit the official website &lt;a href="https://sigmahq.io"&gt;sigmahq.io&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;What is Sigma&lt;/h3&gt; 
&lt;p&gt;Sigma is a generic and open signature format that allows you to describe relevant log events in a straightforward manner. The rule format is very flexible, easy to write and applicable to any type of log file.&lt;/p&gt; 
&lt;p&gt;The main purpose of this project is to provide a structured form in which researchers or analysts can describe their once developed detection methods and make them shareable with others.&lt;/p&gt; 
&lt;p&gt;Sigma is for log files what &lt;a href="https://www.snort.org/"&gt;Snort&lt;/a&gt; is for network traffic and &lt;a href="https://github.com/VirusTotal/yara"&gt;YARA&lt;/a&gt; is for files.&lt;/p&gt; 
&lt;picture&gt; 
 &lt;source media="(prefers-color-scheme: dark)" srcset="./images/Sigma_description_dark.png" /&gt; 
 &lt;img alt="Sigma Description - A diagram showing Yaml Files (Sigma Rules) moving through a Sigma Convertor, and coming out as many SIEM logos, showing how Sigma rules can be converted to many different available SIEM query languages" src="https://raw.githubusercontent.com/SigmaHQ/sigma/master/images/Sigma_description_light.png" /&gt; 
&lt;/picture&gt; 
&lt;h3&gt;Why Sigma&lt;/h3&gt; 
&lt;p&gt;Today, everyone collects log data for analysis. People start working on their own, processing numerous white papers, blog posts and log analysis guidelines, extracting the necessary information and build their own searches and dashboard. Some of their searches and correlations are great and very useful but they lack a standardized format in which they can share their work with others.&lt;/p&gt; 
&lt;p&gt;Others provide excellent analyses, include IOCs and YARA rules to detect the malicious files and network connections, but have no way to describe a specific or generic detection method in log events. Sigma is meant to be an open standard in which such detection mechanisms can be defined, shared and collected in order to improve the detection capabilities for everyone.&lt;/p&gt; 
&lt;h3&gt;üåü Key Features&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;A continuously growing list of detection and hunting rules, peer reviewed by a community of professional Detection Engineers.&lt;/li&gt; 
 &lt;li&gt;Vendor agnostic detection rules.&lt;/li&gt; 
 &lt;li&gt;Easily shareable across communities and reports&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üèóÔ∏è Rule Creation&lt;/h2&gt; 
&lt;p&gt;To start writing Sigma rules please check the following guides:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/SigmaHQ/sigma/wiki/Rule-Creation-Guide"&gt;Rule Creation Guide&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.nextron-systems.com/2018/02/10/write-sigma-rules/"&gt;How to Write Sigma Rules - Nextron Systems&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üîé Contributing &amp;amp; Making PRs&lt;/h2&gt; 
&lt;p&gt;Please refer to the &lt;a href="https://raw.githubusercontent.com/SigmaHQ/sigma/master/CONTRIBUTING.md"&gt;CONTRIBUTING&lt;/a&gt; guide for detailed instructions on how you can start contributing new rules.&lt;/p&gt; 
&lt;h2&gt;üì¶ Rule Packages&lt;/h2&gt; 
&lt;p&gt;You can download the latest rule packages from the &lt;a href="https://github.com/SigmaHQ/sigma/releases/latest"&gt;release page&lt;/a&gt; and start leveraging Sigma rules today.&lt;/p&gt; 
&lt;h2&gt;üß¨ Rule Usage and Conversion&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;You can start converting Sigma rules today using &lt;a href="https://github.com/SigmaHQ/sigma-cli"&gt;Sigma CLI&lt;/a&gt; or &lt;a href="https://sigconverter.io"&gt;sigconverter.io&lt;/a&gt; the GUI interface&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;To integrate Sigma rules in your own toolchain or products use &lt;a href="https://github.com/SigmaHQ/pySigma"&gt;pySigma&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üö® Reporting False Positives or New Rule Ideas&lt;/h2&gt; 
&lt;p&gt;If you find a false positive or would like to propose a new detection rule idea but do not have the time to create one, please create a new issue on the &lt;a href="https://github.com/SigmaHQ/sigma/issues/new/choose"&gt;GitHub repository&lt;/a&gt; by selecting one of the available templates.&lt;/p&gt; 
&lt;h2&gt;üìö Resources &amp;amp; Further Reading&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=OheVuE9Ifhs"&gt;Hack.lu 2017 Sigma - Generic Signatures for Log Events by Thomas Patzke&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.sans.org/webcasts/mitre-att-ck-sigma-alerting-110010" title="MITRE ATT&amp;amp;CK¬Æ and Sigma Alerting"&gt;MITRE ATT&amp;amp;CK¬Æ and Sigma Alerting SANS Webcast Recording&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.slideshare.net/secret/gvgxeXoKblXRcA"&gt;Sigma - Generic Signatures for SIEM Systems by Florian Roth&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Projects or Products that use or integrate Sigma rules&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.alphasoc.com/detections_and_findings/sigma_community/"&gt;AlphaSOC&lt;/a&gt; - Leverages Sigma rules to increase coverage across all supported log sources&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mtnmunuklu/alterix"&gt;alterix&lt;/a&gt; - Converts Sigma rules to the query language of CRYPTTECH's SIEM&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.attackiq.com/2024/01/10/sigmaiq-attackiqs-latest-innovation-for-actionable-detections/"&gt;AttackIQ&lt;/a&gt; - Sigma Rules integrated in AttackIQ's platform, and &lt;a href="https://github.com/AttackIQ/SigmAIQ"&gt;SigmAIQ&lt;/a&gt; for Sigma rule conversion and LLM apps&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/atc-project/atomic-threat-coverage"&gt;Atomic Threat Coverage&lt;/a&gt; (Since December 2018)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://attackrulemap.com/"&gt;AttackRuleMap - Mapping of Atomic Red Team tests and Sigma Rules&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/confluentinc/confluent-sigma"&gt;Confluent Sigma&lt;/a&gt; - Kafka Streams supported Sigma rules&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://detection.studio/?ref=sigmahq_readme"&gt;Detection Studio&lt;/a&gt; - Convert Sigma rules to any supported SIEM.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://community.ibm.com/community/user/security/blogs/gladys-koskas1/2023/08/02/qradar-natively-supports-sigma-for-rules-creation"&gt;IBM QRadar&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://impede.ai/"&gt;Impede Detection Platform&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.joesecurity.org/blog/8225577975210857708"&gt;Joe Sandbox&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://limacharlie.io/"&gt;LimaCharlie&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://www.misp-project.org/2017/03/26/MISP.2.4.70.released.html"&gt;MISP&lt;/a&gt; (Since Version 2.4.70, March 2017)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.nextron-systems.com/aurora/"&gt;Nextron's Aurora Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.nextron-systems.com/thor/"&gt;Nextron's THOR Scanner&lt;/a&gt; - Scan with Sigma rules on endpoints&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://globenewswire.com/news-release/2019/03/04/1745907/0/en/RANK-Software-to-Help-MSSPs-Scale-Cybersecurity-Offerings.html"&gt;RANK VASA&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.securityonion.net/en/latest/sigma.html"&gt;Security Onion&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.sekoia.io"&gt;Sekoia.io XDR&lt;/a&gt; - XDR supporting Sigma and Sigma Correlation rules languages&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/muchdogesec/sigma2stix"&gt;sigma2stix&lt;/a&gt; - Converts the entire SigmaHQ Ruleset into STIX 2.1 Objects. 
  &lt;ul&gt; 
   &lt;li&gt;A versioned archive of sigma2stix STIX 2.1 data is also available to &lt;a href="https://github.com/muchdogesec/cti_knowledge_base_store/tree/main/sigma-rules"&gt;download here&lt;/a&gt;.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/3CORESec/SIEGMA"&gt;SIŒ£GMA&lt;/a&gt; - SIEM consumable generator that utilizes Sigma for query conversion&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://tdm.socprime.com/sigma/"&gt;SOC Prime&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/dstaulcu/TA-Sigma-Searches"&gt;TA-Sigma-Searches&lt;/a&gt; (Splunk App)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/google/timesketch/commit/0c6c4b65a6c0f2051d074e87bbb2da2424fa6c35"&gt;TimeSketch&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/P4T12ICK/ypsilon"&gt;ypsilon&lt;/a&gt; - Automated Use Case Testing&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üìú Maintainers&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://twitter.com/nas_bench"&gt;Nasreddine Bencherchali (@nas_bench)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://twitter.com/cyb3rops"&gt;Florian Roth (@cyb3rops)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://twitter.com/phantinuss"&gt;Christian Burkard (@phantinuss)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://twitter.com/frack113"&gt;Fran√ßois Hubaut (@frack113)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://twitter.com/blubbfiction"&gt;Thomas Patzke (@blubbfiction)&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Credits&lt;/h2&gt; 
&lt;p&gt;This project would've never reached this height without the help of the hundreds of contributors. Thanks to all past and present contributors for their help.&lt;/p&gt; 
&lt;h2&gt;Licenses&lt;/h2&gt; 
&lt;p&gt;The content of this repository is released under the &lt;a href="https://github.com/SigmaHQ/Detection-Rule-License"&gt;Detection Rule License (DRL) 1.1&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>pathwaycom/pathway</title>
      <link>https://github.com/pathwaycom/pathway</link>
      <description>&lt;p&gt;Python ETL framework for stream processing, real-time analytics, LLM pipelines, and RAG.&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;a href="https://pathway.com/"&gt; &lt;img src="https://pathway.com/logo-light.svg?sanitize=true" /&gt; &lt;/a&gt; 
 &lt;br /&gt;
 &lt;br /&gt; 
 &lt;a href="https://trendshift.io/repositories/10388" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/10388" alt="pathwaycom%2Fpathway | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt; 
 &lt;br /&gt;
 &lt;br /&gt; 
&lt;/div&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/pathwaycom/pathway/actions/workflows/ubuntu_test.yml"&gt; &lt;img src="https://github.com/pathwaycom/pathway/actions/workflows/ubuntu_test.yml/badge.svg?sanitize=true" alt="ubuntu" /&gt; &lt;br /&gt; &lt;/a&gt;&lt;a href="https://github.com/pathwaycom/pathway/actions/workflows/release.yml"&gt; &lt;img src="https://github.com/pathwaycom/pathway/actions/workflows/release.yml/badge.svg?sanitize=true" alt="Last release" /&gt;&lt;/a&gt; &lt;a href="https://badge.fury.io/py/pathway"&gt;&lt;img src="https://badge.fury.io/py/pathway.svg?sanitize=true" alt="PyPI version" height="18" /&gt;&lt;/a&gt; &lt;a href="https://badge.fury.io/py/pathway"&gt;&lt;img src="https://static.pepy.tech/badge/pathway" alt="PyPI downloads" height="18" /&gt;&lt;/a&gt; &lt;a href="https://github.com/pathwaycom/pathway/raw/main/LICENSE.txt"&gt; &lt;img src="https://img.shields.io/badge/license-BSL-green" alt="License: BSL" /&gt;&lt;/a&gt; &lt;br /&gt; &lt;a href="https://discord.gg/pathway"&gt; &lt;img src="https://img.shields.io/discord/1042405378304004156?logo=discord" alt="chat on Discord" /&gt;&lt;/a&gt; &lt;a href="https://twitter.com/intent/follow?screen_name=pathway_com"&gt; &lt;img src="https://img.shields.io/twitter/follow/pathwaycom" alt="follow on Twitter" /&gt;&lt;/a&gt; &lt;a href="https://linkedin.com/company/pathway"&gt; &lt;img src="https://img.shields.io/badge/pathway-0077B5?style=social&amp;amp;logo=linkedin" alt="follow on LinkedIn" /&gt;&lt;/a&gt; &lt;a href="https://github.com/dylanhogg/awesome-python/raw/main/README.md"&gt; &lt;img src="https://awesome.re/badge.svg?sanitize=true" alt="Awesome Python" /&gt;&lt;/a&gt; &lt;a href="https://gurubase.io/g/pathway"&gt; &lt;img src="https://img.shields.io/badge/Gurubase-Ask%20Pathway%20Guru-006BFF" alt="Pathway Guru" /&gt;&lt;/a&gt; &lt;br /&gt; &lt;a href="https://raw.githubusercontent.com/pathwaycom/pathway/main/#getting-started"&gt;Getting Started&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/pathwaycom/pathway/main/#deployment"&gt;Deployment&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/pathwaycom/pathway/main/#resources"&gt;Documentation and Support&lt;/a&gt; | &lt;a href="https://pathway.com/blog/"&gt;Blog&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/pathwaycom/pathway/main/#license"&gt;License&lt;/a&gt; &lt;/p&gt; 
&lt;h1&gt;Pathway&lt;a id="pathway"&gt; Live Data Framework&lt;/a&gt;&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://pathway.com"&gt;Pathway&lt;/a&gt; is a Python ETL framework for stream processing, real-time analytics, LLM pipelines, and RAG.&lt;/p&gt; 
&lt;p&gt;Pathway comes with an &lt;strong&gt;easy-to-use Python API&lt;/strong&gt;, allowing you to seamlessly integrate your favorite Python ML libraries. Pathway code is versatile and robust: &lt;strong&gt;you can use it in both development and production environments, handling both batch and streaming data effectively&lt;/strong&gt;. The same code can be used for local development, CI/CD tests, running batch jobs, handling stream replays, and processing data streams.&lt;/p&gt; 
&lt;p&gt;Pathway is powered by a &lt;strong&gt;scalable Rust engine&lt;/strong&gt; based on Differential Dataflow and performs incremental computation. Your Pathway code, despite being written in Python, is run by the Rust engine, enabling multithreading, multiprocessing, and distributed computations. All the pipeline is kept in memory and can be easily deployed with &lt;strong&gt;Docker and Kubernetes&lt;/strong&gt;.&lt;/p&gt; 
&lt;p&gt;You can install Pathway with pip:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;pip install -U pathway
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For any questions, you will find the community and team behind the project &lt;a href="https://discord.com/invite/pathway"&gt;on Discord&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Use-cases and templates&lt;/h2&gt; 
&lt;p&gt;Ready to see what Pathway can do?&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://pathway.com/developers/templates"&gt;Try one of our easy-to-run examples&lt;/a&gt;!&lt;/p&gt; 
&lt;p&gt;Available in both notebook and docker formats, these ready-to-launch examples can be launched in just a few clicks. Pick one and start your hands-on experience with Pathway today!&lt;/p&gt; 
&lt;h3&gt;Event processing and real-time analytics pipelines&lt;/h3&gt; 
&lt;p&gt;With its unified engine for batch and streaming and its full Python compatibility, Pathway makes data processing as easy as possible. It's the ideal solution for a wide range of data processing pipelines, including:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://pathway.com/developers/templates/kafka-etl"&gt;Showcase: Real-time ETL.&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pathway.com/developers/templates/realtime-log-monitoring"&gt;Showcase: Event-driven pipelines with alerting.&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pathway.com/developers/templates/linear_regression_with_kafka"&gt;Showcase: Realtime analytics.&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pathway.com/developers/user-guide/connecting-to-data/switch-from-batch-to-streaming"&gt;Docs: Switch from batch to streaming.&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;AI Pipelines&lt;/h3&gt; 
&lt;p&gt;Pathway provides dedicated LLM tooling to build live LLM and RAG pipelines. Wrappers for most common LLM services and utilities are included, making working with LLMs and RAGs pipelines incredibly easy. Check out our &lt;a href="https://pathway.com/developers/user-guide/llm-xpack/overview"&gt;LLM xpack documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Don't hesitate to try one of our runnable examples featuring LLM tooling. You can find such examples &lt;a href="https://pathway.com/developers/user-guide/llm-xpack/llm-examples"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://pathway.com/developers/templates/unstructured-to-structured"&gt;Template: Unstructured data to SQL on-the-fly.&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pathway.com/developers/templates/private-rag-ollama-mistral"&gt;Template: Private RAG with Ollama and Mistral AI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pathway.com/developers/templates/adaptive-rag"&gt;Template: Adaptive RAG&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pathway.com/developers/templates/multimodal-rag"&gt;Template: Multimodal RAG with gpt-4o&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;A wide range of connectors&lt;/strong&gt;: Pathway comes with connectors that connect to external data sources such as Kafka, GDrive, PostgreSQL, or SharePoint. Its Airbyte connector allows you to connect to more than 300 different data sources. If the connector you want is not available, you can build your own custom connector using Pathway Python connector.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Stateless and stateful transformations&lt;/strong&gt;: Pathway supports stateful transformations such as joins, windowing, and sorting. It provides many transformations directly implemented in Rust. In addition to the provided transformation, you can use any Python function. You can implement your own or you can use any Python library to process your data.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Persistence&lt;/strong&gt;: Pathway provides persistence to save the state of the computation. This allows you to restart your pipeline after an update or a crash. Your pipelines are in good hands with Pathway!&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Consistency&lt;/strong&gt;: Pathway handles the time for you, making sure all your computations are consistent. In particular, Pathway manages late and out-of-order points by updating its results whenever new (or late, in this case) data points come into the system. The free version of Pathway gives the "at least once" consistency while the enterprise version provides the "exactly once" consistency.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Scalable Rust engine&lt;/strong&gt;: with Pathway Rust engine, you are free from the usual limits imposed by Python. You can easily do multithreading, multiprocessing, and distributed computations.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;LLM helpers&lt;/strong&gt;: Pathway provides an LLM extension with all the utilities to integrate LLMs with your data pipelines (LLM wrappers, parsers, embedders, splitters), including an in-memory real-time Vector Index, and integrations with LLamaIndex and LangChain. You can quickly build and deploy RAG applications with your live documents.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Getting started&lt;a id="getting-started"&gt;&lt;/a&gt;&lt;/h2&gt; 
&lt;h3&gt;Installation&lt;a id="installation"&gt;&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;Pathway requires Python 3.10 or above.&lt;/p&gt; 
&lt;p&gt;You can install the current release of Pathway using &lt;code&gt;pip&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ pip install -U pathway
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;‚ö†Ô∏è Pathway is available on MacOS and Linux. Users of other systems should run Pathway on a Virtual Machine.&lt;/p&gt; 
&lt;h3&gt;Example: computing the sum of positive values in real time.&lt;a id="example"&gt;&lt;/a&gt;&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import pathway as pw

# Define the schema of your data (Optional)
class InputSchema(pw.Schema):
  value: int

# Connect to your data using connectors
input_table = pw.io.csv.read(
  "./input/",
  schema=InputSchema
)

#Define your operations on the data
filtered_table = input_table.filter(input_table.value&amp;gt;=0)
result_table = filtered_table.reduce(
  sum_value = pw.reducers.sum(filtered_table.value)
)

# Load your results to external systems
pw.io.jsonlines.write(result_table, "output.jsonl")

# Run the computation
pw.run()
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Run Pathway &lt;a href="https://colab.research.google.com/drive/1aBIJ2HCng-YEUOMrr0qtj0NeZMEyRz55?usp=sharing"&gt;in Google Colab&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;You can find more examples &lt;a href="https://github.com/pathwaycom/pathway/tree/main/examples"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Deployment&lt;a id="deployment"&gt;&lt;/a&gt;&lt;/h2&gt; 
&lt;h3&gt;Locally&lt;a id="running-pathway-locally"&gt;&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;To use Pathway, you only need to import it:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import pathway as pw
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Now, you can easily create your processing pipeline, and let Pathway handle the updates. Once your pipeline is created, you can launch the computation on streaming data with a one-line command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;pw.run()
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can then run your Pathway project (say, &lt;code&gt;main.py&lt;/code&gt;) just like a normal Python script: &lt;code&gt;$ python main.py&lt;/code&gt;. Pathway comes with a monitoring dashboard that allows you to keep track of the number of messages sent by each connector and the latency of the system. The dashboard also includes log messages.&lt;/p&gt; 
&lt;img src="https://d14l3brkh44201.cloudfront.net/pathway-dashboard.png" width="1326" alt="Pathway dashboard" /&gt; 
&lt;p&gt;Alternatively, you can use the pathway'ish version:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ pathway spawn python main.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Pathway natively supports multithreading. To launch your application with 3 threads, you can do as follows:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ pathway spawn --threads 3 python main.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To jumpstart a Pathway project, you can use our &lt;a href="https://github.com/pathwaycom/cookiecutter-pathway"&gt;cookiecutter template&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Docker&lt;a id="docker"&gt;&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;You can easily run Pathway using docker.&lt;/p&gt; 
&lt;h4&gt;Pathway image&lt;/h4&gt; 
&lt;p&gt;You can use the &lt;a href="https://hub.docker.com/r/pathwaycom/pathway"&gt;Pathway docker image&lt;/a&gt;, using a Dockerfile:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-dockerfile"&gt;FROM pathwaycom/pathway:latest

WORKDIR /app

COPY requirements.txt ./
RUN pip install --no-cache-dir -r requirements.txt

COPY . .

CMD [ "python", "./your-script.py" ]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can then build and run the Docker image:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;docker build -t my-pathway-app .
docker run -it --rm --name my-pathway-app my-pathway-app
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Run a single Python script&lt;/h4&gt; 
&lt;p&gt;When dealing with single-file projects, creating a full-fledged &lt;code&gt;Dockerfile&lt;/code&gt; might seem unnecessary. In such scenarios, you can execute a Python script directly using the Pathway Docker image. For example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;docker run -it --rm --name my-pathway-app -v "$PWD":/app pathwaycom/pathway:latest python my-pathway-app.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Python docker image&lt;/h4&gt; 
&lt;p&gt;You can also use a standard Python image and install Pathway using pip with a Dockerfile:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-dockerfile"&gt;FROM --platform=linux/x86_64 python:3.10

RUN pip install -U pathway
COPY ./pathway-script.py pathway-script.py

CMD ["python", "-u", "pathway-script.py"]
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Kubernetes and cloud&lt;a id="k8s"&gt;&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;Docker containers are ideally suited for deployment on the cloud with Kubernetes. If you want to scale your Pathway application, you may be interested in our Pathway for Enterprise. Pathway for Enterprise is specially tailored towards end-to-end data processing and real time intelligent analytics. It scales using distributed computing on the cloud and supports distributed Kubernetes deployment, with external persistence setup.&lt;/p&gt; 
&lt;p&gt;You can easily deploy Pathway using services like Render: see &lt;a href="https://pathway.com/developers/user-guide/deployment/render-deploy/"&gt;how to deploy Pathway in a few clicks&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;If you are interested, don't hesitate to &lt;a href="mailto:contact@pathway.com"&gt;contact us&lt;/a&gt; to learn more.&lt;/p&gt; 
&lt;h2&gt;Performance&lt;a id="performance"&gt;&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Pathway is made to outperform state-of-the-art technologies designed for streaming and batch data processing tasks, including: Flink, Spark, and Kafka Streaming. It also makes it possible to implement a lot of algorithms/UDF's in streaming mode which are not readily supported by other streaming frameworks (especially: temporal joins, iterative graph algorithms, machine learning routines).&lt;/p&gt; 
&lt;p&gt;If you are curious, here are &lt;a href="https://github.com/pathwaycom/pathway-benchmarks"&gt;some benchmarks to play with&lt;/a&gt;.&lt;/p&gt; 
&lt;img src="https://github.com/pathwaycom/pathway-benchmarks/raw/main/images/bm-wordcount-lineplot.png" width="1326" alt="WordCount Graph" /&gt; 
&lt;h2&gt;Documentation and Support&lt;a id="resources"&gt;&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;The entire documentation of Pathway is available at &lt;a href="https://pathway.com/developers/user-guide/introduction/welcome"&gt;pathway.com/developers/&lt;/a&gt;, including the &lt;a href="https://pathway.com/developers/api-docs/pathway"&gt;API Docs&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;If you have any question, don't hesitate to &lt;a href="https://github.com/pathwaycom/pathway/issues"&gt;open an issue on GitHub&lt;/a&gt;, join us on &lt;a href="https://discord.com/invite/pathway"&gt;Discord&lt;/a&gt;, or send us an email at &lt;a href="mailto:contact@pathway.com"&gt;contact@pathway.com&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;License&lt;a id="license"&gt;&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Pathway is distributed on a &lt;a href="https://github.com/pathwaycom/pathway/raw/main/LICENSE.txt"&gt;BSL 1.1 License&lt;/a&gt; which allows for unlimited non-commercial use, as well as use of the Pathway package &lt;a href="https://pathway.com/license/"&gt;for most commercial purposes&lt;/a&gt;, free of charge. Code in this repository automatically converts to Open Source (Apache 2.0 License) after 4 years. Some &lt;a href="https://github.com/pathwaycom"&gt;public repos&lt;/a&gt; which are complementary to this one (examples, libraries, connectors, etc.) are licensed as Open Source, under the MIT license.&lt;/p&gt; 
&lt;h2&gt;Contribution guidelines&lt;a id="contribution-guidelines"&gt;&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;If you develop a library or connector which you would like to integrate with this repo, we suggest releasing it first as a separate repo on a MIT/Apache 2.0 license.&lt;/p&gt; 
&lt;p&gt;For all concerns regarding core Pathway functionalities, Issues are encouraged. For further information, don't hesitate to engage with Pathway's &lt;a href="https://discord.gg/pathway"&gt;Discord community&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>unslothai/unsloth</title>
      <link>https://github.com/unslothai/unsloth</link>
      <description>&lt;p&gt;Fine-tuning &amp; Reinforcement Learning for LLMs. ü¶• Train OpenAI gpt-oss, DeepSeek-R1, Qwen3, Gemma 3, TTS 2x faster with 70% less VRAM.&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://unsloth.ai"&gt;
   &lt;picture&gt; 
    &lt;source media="(prefers-color-scheme: dark)" srcset="https://raw.githubusercontent.com/unslothai/unsloth/main/images/unsloth%20logo%20white%20text.png" /&gt; 
    &lt;source media="(prefers-color-scheme: light)" srcset="https://raw.githubusercontent.com/unslothai/unsloth/main/images/unsloth%20logo%20black%20text.png" /&gt; 
    &lt;img alt="unsloth logo" src="https://raw.githubusercontent.com/unslothai/unsloth/main/images/unsloth%20logo%20black%20text.png" height="110" style="max-width: 100%;" /&gt; 
   &lt;/picture&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3.1_(8B)-Alpaca.ipynb"&gt;&lt;img src="https://raw.githubusercontent.com/unslothai/unsloth/main/images/start free finetune button.png" width="154" /&gt;&lt;/a&gt; &lt;a href="https://discord.com/invite/unsloth"&gt;&lt;img src="https://raw.githubusercontent.com/unslothai/unsloth/main/images/Discord button.png" width="165" /&gt;&lt;/a&gt; &lt;a href="https://docs.unsloth.ai"&gt;&lt;img src="https://raw.githubusercontent.com/unslothai/unsloth/refs/heads/main/images/Documentation%20Button.png" width="137" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;h3&gt;Train gpt-oss, DeepSeek, Gemma, Qwen &amp;amp; Llama 2x faster with 70% less VRAM!&lt;/h3&gt; 
 &lt;p&gt;&lt;img src="https://i.ibb.co/sJ7RhGG/image-41.png" alt="" /&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;‚ú® Train for Free&lt;/h2&gt; 
&lt;p&gt;Notebooks are beginner friendly. Read our &lt;a href="https://docs.unsloth.ai/get-started/fine-tuning-guide"&gt;guide&lt;/a&gt;. Add dataset, click "Run All", and export your trained model to GGUF, Ollama, vLLM or Hugging Face.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Unsloth supports&lt;/th&gt; 
   &lt;th&gt;Free Notebooks&lt;/th&gt; 
   &lt;th&gt;Performance&lt;/th&gt; 
   &lt;th&gt;Memory use&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;gpt-oss (20B)&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/gpt-oss-(20B)-Fine-tuning.ipynb"&gt;‚ñ∂Ô∏è Start for free&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;1.5x faster&lt;/td&gt; 
   &lt;td&gt;70% less&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Gemma 3n (4B)&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Gemma3N_(4B)-Conversational.ipynb"&gt;‚ñ∂Ô∏è Start for free&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;1.5x faster&lt;/td&gt; 
   &lt;td&gt;50% less&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Qwen3 (14B)&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Qwen3_(14B)-Reasoning-Conversational.ipynb"&gt;‚ñ∂Ô∏è Start for free&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;2x faster&lt;/td&gt; 
   &lt;td&gt;70% less&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;gpt-oss (20B): GRPO&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/gpt-oss-(20B)-GRPO.ipynb"&gt;‚ñ∂Ô∏è Start for free&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;2x faster&lt;/td&gt; 
   &lt;td&gt;80% less&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Qwen2.5-VL (7B): GSPO&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Qwen2_5_7B_VL_GRPO.ipynb"&gt;‚ñ∂Ô∏è Start for free&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;1.5x faster&lt;/td&gt; 
   &lt;td&gt;80% less&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Phi-4 (14B)&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Phi_4-Conversational.ipynb"&gt;‚ñ∂Ô∏è Start for free&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;2x faster&lt;/td&gt; 
   &lt;td&gt;70% less&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Llama 3.2 Vision (11B)&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3.2_(11B)-Vision.ipynb"&gt;‚ñ∂Ô∏è Start for free&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;2x faster&lt;/td&gt; 
   &lt;td&gt;50% less&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Llama 3.1 (8B)&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3.1_(8B)-Alpaca.ipynb"&gt;‚ñ∂Ô∏è Start for free&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;2x faster&lt;/td&gt; 
   &lt;td&gt;70% less&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Mistral v0.3 (7B)&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Mistral_v0.3_(7B)-Conversational.ipynb"&gt;‚ñ∂Ô∏è Start for free&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;2.2x faster&lt;/td&gt; 
   &lt;td&gt;75% less&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Orpheus-TTS (3B)&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Orpheus_(3B)-TTS.ipynb"&gt;‚ñ∂Ô∏è Start for free&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;1.5x faster&lt;/td&gt; 
   &lt;td&gt;50% less&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;ul&gt; 
 &lt;li&gt;See all our notebooks for: &lt;a href="https://github.com/unslothai/notebooks?tab=readme-ov-file#-kaggle-notebooks"&gt;Kaggle&lt;/a&gt;, &lt;a href="https://docs.unsloth.ai/get-started/unsloth-notebooks#grpo-reasoning-rl-notebooks"&gt;GRPO&lt;/a&gt;, &lt;strong&gt;&lt;a href="https://docs.unsloth.ai/get-started/unsloth-notebooks#text-to-speech-tts-notebooks"&gt;TTS&lt;/a&gt;&lt;/strong&gt; &amp;amp; &lt;a href="https://docs.unsloth.ai/get-started/unsloth-notebooks#vision-multimodal-notebooks"&gt;Vision&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;See &lt;a href="https://docs.unsloth.ai/get-started/all-our-models"&gt;all our models&lt;/a&gt; and &lt;a href="https://docs.unsloth.ai/get-started/unsloth-notebooks"&gt;all our notebooks&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;See detailed documentation for Unsloth &lt;a href="https://docs.unsloth.ai/"&gt;here&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;‚ö° Quickstart&lt;/h2&gt; 
&lt;h3&gt;Linux or WSL&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install unsloth
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Windows&lt;/h3&gt; 
&lt;p&gt;For Windows, &lt;code&gt;pip install unsloth&lt;/code&gt; works only if you have Pytorch installed. Read our &lt;a href="https://docs.unsloth.ai/get-started/installing-+-updating/windows-installation"&gt;Windows Guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Docker&lt;/h3&gt; 
&lt;p&gt;Use our official &lt;a href="https://hub.docker.com/r/unsloth/unsloth"&gt;Unsloth Docker image&lt;/a&gt; &lt;code&gt;unsloth/unsloth&lt;/code&gt; container. Read our &lt;a href="https://docs.unsloth.ai/get-started/install-and-update/docker"&gt;Docker Guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Blackwell&lt;/h3&gt; 
&lt;p&gt;For RTX 50x, B200, 6000 GPUs, simply do &lt;code&gt;pip install unsloth&lt;/code&gt;. Read our &lt;a href="https://docs.unsloth.ai/basics/training-llms-with-blackwell-rtx-50-series-and-unsloth"&gt;Blackwell Guide&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;h2&gt;ü¶• Unsloth.ai News&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Docker&lt;/strong&gt;: Use Unsloth with no setup &amp;amp; environment issues with our new image. &lt;a href="https://docs.unsloth.ai/new/how-to-train-llms-with-unsloth-and-docker"&gt;Guide&lt;/a&gt; ‚Ä¢ &lt;a href="https://hub.docker.com/r/unsloth/unsloth"&gt;Docker image&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;gpt-oss RL&lt;/strong&gt;: Introducing the fastest possible inference for gpt-oss RL! &lt;a href="https://docs.unsloth.ai/new/gpt-oss-reinforcement-learning"&gt;Read blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Vision RL&lt;/strong&gt;: You can now train VLMs with GRPO or GSPO in Unsloth! &lt;a href="https://docs.unsloth.ai/new/vision-reinforcement-learning-vlm-rl"&gt;Read guide&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Memory-efficient RL&lt;/strong&gt;: We're introducing even better RL. Our new kernels &amp;amp; algos allows faster RL with 50% less VRAM &amp;amp; 10√ó more context. &lt;a href="https://docs.unsloth.ai/new/memory-efficient-rl"&gt;Read blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;gpt-oss&lt;/strong&gt; by OpenAI: For details on &lt;a href="https://docs.unsloth.ai/new/long-context-gpt-oss-training"&gt;Unsloth Flex Attention&lt;/a&gt;, long-context training, bug fixes, &lt;a href="https://docs.unsloth.ai/basics/gpt-oss"&gt;Read our Guide&lt;/a&gt;. 20B works on a 14GB GPU and 120B on 65GB VRAM. &lt;a href="https://huggingface.co/collections/unsloth/gpt-oss-6892433695ce0dee42f31681"&gt;gpt-oss uploads&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Gemma 3n&lt;/strong&gt; by Google: &lt;a href="https://docs.unsloth.ai/basics/gemma-3n-how-to-run-and-fine-tune"&gt;Read Blog&lt;/a&gt;. We &lt;a href="https://huggingface.co/collections/unsloth/gemma-3n-685d3874830e49e1c93f9339"&gt;uploaded GGUFs, 4-bit models&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.unsloth.ai/basics/text-to-speech-tts-fine-tuning"&gt;Text-to-Speech (TTS)&lt;/a&gt;&lt;/strong&gt; is now supported, including &lt;code&gt;sesame/csm-1b&lt;/code&gt; and STT &lt;code&gt;openai/whisper-large-v3&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.unsloth.ai/basics/qwen3-how-to-run-and-fine-tune"&gt;Qwen3&lt;/a&gt;&lt;/strong&gt; is now supported. Qwen3-30B-A3B fits on 17.5GB VRAM.&lt;/li&gt; 
 &lt;li&gt;Introducing &lt;strong&gt;&lt;a href="https://docs.unsloth.ai/basics/unsloth-dynamic-2.0-ggufs"&gt;Dynamic 2.0&lt;/a&gt;&lt;/strong&gt; quants that set new benchmarks on 5-shot MMLU &amp;amp; Aider Polyglot.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://unsloth.ai/blog/gemma3#everything"&gt;&lt;strong&gt;EVERYTHING&lt;/strong&gt; is now supported&lt;/a&gt; - all models (TTS, BERT, Mamba), FFT, etc. &lt;a href="https://docs.unsloth.ai/basics/multi-gpu-training-with-unsloth"&gt;MultiGPU&lt;/a&gt; coming soon. Enable FFT with &lt;code&gt;full_finetuning = True&lt;/code&gt;, 8-bit with &lt;code&gt;load_in_8bit = True&lt;/code&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;details&gt; 
 &lt;summary&gt;Click for more news&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;üì£ &lt;a href="https://unsloth.ai/blog/deepseek-r1"&gt;DeepSeek-R1&lt;/a&gt; - run or fine-tune them &lt;a href="https://unsloth.ai/blog/deepseek-r1"&gt;with our guide&lt;/a&gt;. All model uploads: &lt;a href="https://huggingface.co/collections/unsloth/deepseek-r1-all-versions-678e1c48f5d2fce87892ace5"&gt;here&lt;/a&gt;.&lt;/li&gt; 
  &lt;li&gt;üì£ Introducing Long-context &lt;a href="https://unsloth.ai/blog/grpo"&gt;Reasoning (GRPO)&lt;/a&gt; in Unsloth. Train your own reasoning model with just 5GB VRAM. Transform Llama, Phi, Mistral etc. into reasoning LLMs!&lt;/li&gt; 
  &lt;li&gt;üì£ Introducing Unsloth &lt;a href="https://unsloth.ai/blog/dynamic-4bit"&gt;Dynamic 4-bit Quantization&lt;/a&gt;! We dynamically opt not to quantize certain parameters and this greatly increases accuracy while only using &amp;lt;10% more VRAM than BnB 4-bit. See our collection on &lt;a href="https://huggingface.co/collections/unsloth/unsloth-4-bit-dynamic-quants-67503bb873f89e15276c44e7"&gt;Hugging Face here.&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;üì£ &lt;strong&gt;&lt;a href="https://unsloth.ai/blog/llama4"&gt;Llama 4&lt;/a&gt;&lt;/strong&gt; by Meta, including Scout &amp;amp; Maverick are now supported.&lt;/li&gt; 
  &lt;li&gt;üì£ &lt;a href="https://unsloth.ai/blog/phi4"&gt;Phi-4&lt;/a&gt; by Microsoft: We also &lt;a href="https://unsloth.ai/blog/phi4"&gt;fixed bugs&lt;/a&gt; in Phi-4 and &lt;a href="https://huggingface.co/collections/unsloth/phi-4-all-versions-677eecf93784e61afe762afa"&gt;uploaded GGUFs, 4-bit&lt;/a&gt;.&lt;/li&gt; 
  &lt;li&gt;üì£ &lt;a href="https://unsloth.ai/blog/vision"&gt;Vision models&lt;/a&gt; now supported! &lt;a href="https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3.2_(11B)-Vision.ipynb"&gt;Llama 3.2 Vision (11B)&lt;/a&gt;, &lt;a href="https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Qwen2_VL_(7B)-Vision.ipynb"&gt;Qwen 2.5 VL (7B)&lt;/a&gt; and &lt;a href="https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Pixtral_(12B)-Vision.ipynb"&gt;Pixtral (12B) 2409&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;üì£ &lt;a href="https://huggingface.co/collections/unsloth/llama-33-all-versions-67535d7d994794b9d7cf5e9f"&gt;Llama 3.3 (70B)&lt;/a&gt;, Meta's latest model is supported.&lt;/li&gt; 
  &lt;li&gt;üì£ We worked with Apple to add &lt;a href="https://arxiv.org/abs/2411.09009"&gt;Cut Cross Entropy&lt;/a&gt;. Unsloth now supports 89K context for Meta's Llama 3.3 (70B) on a 80GB GPU - 13x longer than HF+FA2. For Llama 3.1 (8B), Unsloth enables 342K context, surpassing its native 128K support.&lt;/li&gt; 
  &lt;li&gt;üì£ We found and helped fix a &lt;a href="https://unsloth.ai/blog/gradient"&gt;gradient accumulation bug&lt;/a&gt;! Please update Unsloth and transformers.&lt;/li&gt; 
  &lt;li&gt;üì£ We cut memory usage by a &lt;a href="https://unsloth.ai/blog/long-context"&gt;further 30%&lt;/a&gt; and now support &lt;a href="https://unsloth.ai/blog/long-context"&gt;4x longer context windows&lt;/a&gt;!&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;üîó Links and Resources&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Type&lt;/th&gt; 
   &lt;th&gt;Links&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;üìö &lt;strong&gt;Documentation &amp;amp; Wiki&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://docs.unsloth.ai"&gt;Read Our Docs&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img width="16" src="https://upload.wikimedia.org/wikipedia/commons/6/6f/Logo_of_Twitter.svg?sanitize=true" /&gt;&amp;nbsp; &lt;strong&gt;Twitter (aka X)&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://twitter.com/unslothai"&gt;Follow us on X&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;üíæ &lt;strong&gt;Installation&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://docs.unsloth.ai/get-started/installing-+-updating"&gt;Pip install&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;üîÆ &lt;strong&gt;Our Models&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://docs.unsloth.ai/get-started/all-our-models"&gt;Unsloth Releases&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;‚úçÔ∏è &lt;strong&gt;Blog&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://unsloth.ai/blog"&gt;Read our Blogs&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img width="15" src="https://redditinc.com/hs-fs/hubfs/Reddit%20Inc/Brand/Reddit_Logo.png" /&gt;&amp;nbsp; &lt;strong&gt;Reddit&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://reddit.com/r/unsloth"&gt;Join our Reddit&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;‚≠ê Key Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Supports &lt;strong&gt;full-finetuning&lt;/strong&gt;, pretraining, 4b-bit, 16-bit and &lt;strong&gt;8-bit&lt;/strong&gt; training&lt;/li&gt; 
 &lt;li&gt;Supports &lt;strong&gt;all models&lt;/strong&gt; including &lt;a href="https://docs.unsloth.ai/basics/text-to-speech-tts-fine-tuning"&gt;TTS&lt;/a&gt;, multimodal, &lt;a href="https://docs.unsloth.ai/get-started/unsloth-notebooks#other-important-notebooks"&gt;BERT&lt;/a&gt; and more! Any model that works in transformers, works in Unsloth.&lt;/li&gt; 
 &lt;li&gt;The most efficient library for &lt;a href="https://docs.unsloth.ai/get-started/reinforcement-learning-rl-guide"&gt;Reinforcement Learning (RL)&lt;/a&gt;, using 80% less VRAM. Supports GRPO, GSPO, DrGRPO, DAPO etc.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;0% loss in accuracy&lt;/strong&gt; - no approximation methods - all exact.&lt;/li&gt; 
 &lt;li&gt;All kernels written in &lt;a href="https://openai.com/index/triton/"&gt;OpenAI's Triton&lt;/a&gt; language. Manual backprop engine.&lt;/li&gt; 
 &lt;li&gt;Supports NVIDIA (since 2018), AMD and Intel GPUs. Minimum CUDA Capability 7.0 (V100, T4, Titan V, RTX 20, 30, 40x, A100, H100, L40 etc)&lt;/li&gt; 
 &lt;li&gt;Works on &lt;strong&gt;Linux&lt;/strong&gt;, WSL and &lt;strong&gt;Windows&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;If you trained a model with ü¶•Unsloth, you can use this cool sticker! &amp;nbsp; &lt;img src="https://raw.githubusercontent.com/unslothai/unsloth/main/images/made with unsloth.png" width="200" align="center" /&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üíæ Install Unsloth&lt;/h2&gt; 
&lt;p&gt;You can also see our documentation for more detailed installation and updating instructions &lt;a href="https://docs.unsloth.ai/get-started/installing-+-updating"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Unsloth does not support Python 3.14. Use 3.13 or lower.&lt;/p&gt; 
&lt;h3&gt;Pip Installation&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Install with pip (recommended) for Linux devices:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;pip install unsloth
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;To update Unsloth:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;pip install --upgrade --force-reinstall --no-cache-dir unsloth unsloth_zoo
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See &lt;a href="https://github.com/unslothai/unsloth/edit/main/README.md#advanced-pip-installation"&gt;here&lt;/a&gt; for advanced pip install instructions.&lt;/p&gt; 
&lt;h3&gt;Windows Installation&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Install NVIDIA Video Driver:&lt;/strong&gt; You should install the latest version of your GPUs driver. Download drivers here: &lt;a href="https://www.nvidia.com/Download/index.aspx"&gt;NVIDIA GPU Drive&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Install Visual Studio C++:&lt;/strong&gt; You will need Visual Studio, with C++ installed. By default, C++ is not installed with &lt;a href="https://visualstudio.microsoft.com/vs/community/"&gt;Visual Studio&lt;/a&gt;, so make sure you select all of the C++ options. Also select options for Windows 10/11 SDK. For detailed instructions with options, see &lt;a href="https://docs.unsloth.ai/get-started/installing-+-updating"&gt;here&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Install CUDA Toolkit:&lt;/strong&gt; Follow the instructions to install &lt;a href="https://developer.nvidia.com/cuda-toolkit-archive"&gt;CUDA Toolkit&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Install PyTorch:&lt;/strong&gt; You will need the correct version of PyTorch that is compatible with your CUDA drivers, so make sure to select them carefully. &lt;a href="https://pytorch.org/get-started/locally/"&gt;Install PyTorch&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Install Unsloth:&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;pip install unsloth
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Notes&lt;/h4&gt; 
&lt;p&gt;To run Unsloth directly on Windows:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Install Triton from this Windows fork and follow the instructions &lt;a href="https://github.com/woct0rdho/triton-windows"&gt;here&lt;/a&gt; (be aware that the Windows fork requires PyTorch &amp;gt;= 2.4 and CUDA 12)&lt;/li&gt; 
 &lt;li&gt;In the &lt;code&gt;SFTConfig&lt;/code&gt;, set &lt;code&gt;dataset_num_proc=1&lt;/code&gt; to avoid a crashing issue:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;SFTConfig(
    dataset_num_proc=1,
    ...
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Advanced/Troubleshooting&lt;/h4&gt; 
&lt;p&gt;For &lt;strong&gt;advanced installation instructions&lt;/strong&gt; or if you see weird errors during installations:&lt;/p&gt; 
&lt;p&gt;First try using an isolated environment via then &lt;code&gt;pip install unsloth&lt;/code&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python -m venv unsloth
source unsloth/bin/activate
pip install unsloth
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol&gt; 
 &lt;li&gt;Install &lt;code&gt;torch&lt;/code&gt; and &lt;code&gt;triton&lt;/code&gt;. Go to &lt;a href="https://pytorch.org"&gt;https://pytorch.org&lt;/a&gt; to install it. For example &lt;code&gt;pip install torch torchvision torchaudio triton&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Confirm if CUDA is installed correctly. Try &lt;code&gt;nvcc&lt;/code&gt;. If that fails, you need to install &lt;code&gt;cudatoolkit&lt;/code&gt; or CUDA drivers.&lt;/li&gt; 
 &lt;li&gt;Install &lt;code&gt;xformers&lt;/code&gt; manually via:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install ninja
pip install -v --no-build-isolation -U git+https://github.com/facebookresearch/xformers.git@main#egg=xformers
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code&gt;Check if `xformers` succeeded with `python -m xformers.info` Go to https://github.com/facebookresearch/xformers. Another option is to install `flash-attn` for Ampere GPUs and ignore `xformers`
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="5"&gt; 
 &lt;li&gt;For GRPO runs, you can try installing &lt;code&gt;vllm&lt;/code&gt; and seeing if &lt;code&gt;pip install vllm&lt;/code&gt; succeeds.&lt;/li&gt; 
 &lt;li&gt;Double check that your versions of Python, CUDA, CUDNN, &lt;code&gt;torch&lt;/code&gt;, &lt;code&gt;triton&lt;/code&gt;, and &lt;code&gt;xformers&lt;/code&gt; are compatible with one another. The &lt;a href="https://github.com/pytorch/pytorch/raw/main/RELEASE.md#release-compatibility-matrix"&gt;PyTorch Compatibility Matrix&lt;/a&gt; may be useful.&lt;/li&gt; 
 &lt;li&gt;Finally, install &lt;code&gt;bitsandbytes&lt;/code&gt; and check it with &lt;code&gt;python -m bitsandbytes&lt;/code&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Conda Installation (Optional)&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;‚ö†Ô∏èOnly use Conda if you have it. If not, use Pip&lt;/code&gt;. Select either &lt;code&gt;pytorch-cuda=11.8,12.1&lt;/code&gt; for CUDA 11.8 or CUDA 12.1. We support &lt;code&gt;python=3.10,3.11,3.12&lt;/code&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;conda create --name unsloth_env \
    python=3.11 \
    pytorch-cuda=12.1 \
    pytorch cudatoolkit xformers -c pytorch -c nvidia -c xformers \
    -y
conda activate unsloth_env

pip install unsloth
&lt;/code&gt;&lt;/pre&gt; 
&lt;details&gt; 
 &lt;summary&gt;If you're looking to install Conda in a Linux environment, &lt;a href="https://docs.anaconda.com/miniconda/"&gt;read here&lt;/a&gt;, or run the below üîΩ&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;mkdir -p ~/miniconda3
wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O ~/miniconda3/miniconda.sh
bash ~/miniconda3/miniconda.sh -b -u -p ~/miniconda3
rm -rf ~/miniconda3/miniconda.sh
~/miniconda3/bin/conda init bash
~/miniconda3/bin/conda init zsh
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h3&gt;Advanced Pip Installation&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;‚ö†Ô∏èDo **NOT** use this if you have Conda.&lt;/code&gt; Pip is a bit more complex since there are dependency issues. The pip command is different for &lt;code&gt;torch 2.2,2.3,2.4,2.5&lt;/code&gt; and CUDA versions.&lt;/p&gt; 
&lt;p&gt;For other torch versions, we support &lt;code&gt;torch211&lt;/code&gt;, &lt;code&gt;torch212&lt;/code&gt;, &lt;code&gt;torch220&lt;/code&gt;, &lt;code&gt;torch230&lt;/code&gt;, &lt;code&gt;torch240&lt;/code&gt; and for CUDA versions, we support &lt;code&gt;cu118&lt;/code&gt; and &lt;code&gt;cu121&lt;/code&gt; and &lt;code&gt;cu124&lt;/code&gt;. For Ampere devices (A100, H100, RTX3090) and above, use &lt;code&gt;cu118-ampere&lt;/code&gt; or &lt;code&gt;cu121-ampere&lt;/code&gt; or &lt;code&gt;cu124-ampere&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;For example, if you have &lt;code&gt;torch 2.4&lt;/code&gt; and &lt;code&gt;CUDA 12.1&lt;/code&gt;, use:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install --upgrade pip
pip install "unsloth[cu121-torch240] @ git+https://github.com/unslothai/unsloth.git"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Another example, if you have &lt;code&gt;torch 2.5&lt;/code&gt; and &lt;code&gt;CUDA 12.4&lt;/code&gt;, use:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install --upgrade pip
pip install "unsloth[cu124-torch250] @ git+https://github.com/unslothai/unsloth.git"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;And other examples:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install "unsloth[cu121-ampere-torch240] @ git+https://github.com/unslothai/unsloth.git"
pip install "unsloth[cu118-ampere-torch240] @ git+https://github.com/unslothai/unsloth.git"
pip install "unsloth[cu121-torch240] @ git+https://github.com/unslothai/unsloth.git"
pip install "unsloth[cu118-torch240] @ git+https://github.com/unslothai/unsloth.git"

pip install "unsloth[cu121-torch230] @ git+https://github.com/unslothai/unsloth.git"
pip install "unsloth[cu121-ampere-torch230] @ git+https://github.com/unslothai/unsloth.git"

pip install "unsloth[cu121-torch250] @ git+https://github.com/unslothai/unsloth.git"
pip install "unsloth[cu124-ampere-torch250] @ git+https://github.com/unslothai/unsloth.git"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or, run the below in a terminal to get the &lt;strong&gt;optimal&lt;/strong&gt; pip installation command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;wget -qO- https://raw.githubusercontent.com/unslothai/unsloth/main/unsloth/_auto_install.py | python -
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or, run the below manually in a Python REPL:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;try: import torch
except: raise ImportError('Install torch via `pip install torch`')
from packaging.version import Version as V
import re
v = V(re.match(r"[0-9\.]{3,}", torch.__version__).group(0))
cuda = str(torch.version.cuda)
is_ampere = torch.cuda.get_device_capability()[0] &amp;gt;= 8
USE_ABI = torch._C._GLIBCXX_USE_CXX11_ABI
if cuda not in ("11.8", "12.1", "12.4", "12.6", "12.8"): raise RuntimeError(f"CUDA = {cuda} not supported!")
if   v &amp;lt;= V('2.1.0'): raise RuntimeError(f"Torch = {v} too old!")
elif v &amp;lt;= V('2.1.1'): x = 'cu{}{}-torch211'
elif v &amp;lt;= V('2.1.2'): x = 'cu{}{}-torch212'
elif v  &amp;lt; V('2.3.0'): x = 'cu{}{}-torch220'
elif v  &amp;lt; V('2.4.0'): x = 'cu{}{}-torch230'
elif v  &amp;lt; V('2.5.0'): x = 'cu{}{}-torch240'
elif v  &amp;lt; V('2.5.1'): x = 'cu{}{}-torch250'
elif v &amp;lt;= V('2.5.1'): x = 'cu{}{}-torch251'
elif v  &amp;lt; V('2.7.0'): x = 'cu{}{}-torch260'
elif v  &amp;lt; V('2.7.9'): x = 'cu{}{}-torch270'
elif v  &amp;lt; V('2.8.0'): x = 'cu{}{}-torch271'
elif v  &amp;lt; V('2.8.9'): x = 'cu{}{}-torch280'
else: raise RuntimeError(f"Torch = {v} too new!")
if v &amp;gt; V('2.6.9') and cuda not in ("11.8", "12.6", "12.8"): raise RuntimeError(f"CUDA = {cuda} not supported!")
x = x.format(cuda.replace(".", ""), "-ampere" if is_ampere else "")
print(f'pip install --upgrade pip &amp;amp;&amp;amp; pip install "unsloth[{x}] @ git+https://github.com/unslothai/unsloth.git"')
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Docker Installation&lt;/h3&gt; 
&lt;p&gt;You can use our pre-built Docker container with all dependencies to use Unsloth instantly with no setup required. &lt;a href="https://docs.unsloth.ai/get-started/install-and-update/docker"&gt;Read our guide&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;This container requires installing &lt;a href="https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html"&gt;NVIDIA's Container Toolkit&lt;/a&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run -d -e JUPYTER_PASSWORD="mypassword" \
  -p 8888:8888 -p 2222:22 \
  -v $(pwd)/work:/workspace/work \
  --gpus all \
  unsloth/unsloth
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Access Jupyter Lab at &lt;code&gt;http://localhost:8888&lt;/code&gt; and start fine-tuning!&lt;/p&gt; 
&lt;h2&gt;üìú Documentation&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Go to our official &lt;a href="https://docs.unsloth.ai"&gt;Documentation&lt;/a&gt; for saving to GGUF, checkpointing, evaluation and more!&lt;/li&gt; 
 &lt;li&gt;We support Huggingface's transformers, TRL, Trainer, Seq2SeqTrainer or even Pytorch code!&lt;/li&gt; 
 &lt;li&gt;If you want to download models or datasets from the ModelScope community, please use an environment variable: &lt;code&gt;UNSLOTH_USE_MODELSCOPE=1&lt;/code&gt;, and install the modelscope library by: &lt;code&gt;pip install modelscope -U&lt;/code&gt;. unsloth_cli.py also supports this.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from unsloth import FastLanguageModel, FastModel
import torch
from trl import SFTTrainer, SFTConfig
from datasets import load_dataset
max_seq_length = 2048 # Supports RoPE Scaling internally, so choose any!
# Get LAION dataset
url = "https://huggingface.co/datasets/laion/OIG/resolve/main/unified_chip2.jsonl"
dataset = load_dataset("json", data_files = {"train" : url}, split = "train")

# 4bit pre quantized models we support for 4x faster downloading + no OOMs.
fourbit_models = [
    "unsloth/Meta-Llama-3.1-8B-bnb-4bit",      # Llama-3.1 2x faster
    "unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit",
    "unsloth/Meta-Llama-3.1-70B-bnb-4bit",
    "unsloth/Meta-Llama-3.1-405B-bnb-4bit",    # 4bit for 405b!
    "unsloth/Mistral-Small-Instruct-2409",     # Mistral 22b 2x faster!
    "unsloth/mistral-7b-instruct-v0.3-bnb-4bit",
    "unsloth/Phi-3.5-mini-instruct",           # Phi-3.5 2x faster!
    "unsloth/Phi-3-medium-4k-instruct",
    "unsloth/gemma-2-9b-bnb-4bit",
    "unsloth/gemma-2-27b-bnb-4bit",            # Gemma 2x faster!

    "unsloth/Llama-3.2-1B-bnb-4bit",           # NEW! Llama 3.2 models
    "unsloth/Llama-3.2-1B-Instruct-bnb-4bit",
    "unsloth/Llama-3.2-3B-bnb-4bit",
    "unsloth/Llama-3.2-3B-Instruct-bnb-4bit",

    "unsloth/Llama-3.3-70B-Instruct-bnb-4bit" # NEW! Llama 3.3 70B!
] # More models at https://huggingface.co/unsloth

model, tokenizer = FastModel.from_pretrained(
    model_name = "unsloth/gemma-3-4B-it",
    max_seq_length = 2048, # Choose any for long context!
    load_in_4bit = True,  # 4 bit quantization to reduce memory
    load_in_8bit = False, # [NEW!] A bit more accurate, uses 2x memory
    full_finetuning = False, # [NEW!] We have full finetuning now!
    # token = "hf_...", # use one if using gated models
)

# Do model patching and add fast LoRA weights
model = FastLanguageModel.get_peft_model(
    model,
    r = 16,
    target_modules = ["q_proj", "k_proj", "v_proj", "o_proj",
                      "gate_proj", "up_proj", "down_proj",],
    lora_alpha = 16,
    lora_dropout = 0, # Supports any, but = 0 is optimized
    bias = "none",    # Supports any, but = "none" is optimized
    # [NEW] "unsloth" uses 30% less VRAM, fits 2x larger batch sizes!
    use_gradient_checkpointing = "unsloth", # True or "unsloth" for very long context
    random_state = 3407,
    max_seq_length = max_seq_length,
    use_rslora = False,  # We support rank stabilized LoRA
    loftq_config = None, # And LoftQ
)

trainer = SFTTrainer(
    model = model,
    train_dataset = dataset,
    tokenizer = tokenizer,
    args = SFTConfig(
        max_seq_length = max_seq_length,
        per_device_train_batch_size = 2,
        gradient_accumulation_steps = 4,
        warmup_steps = 10,
        max_steps = 60,
        logging_steps = 1,
        output_dir = "outputs",
        optim = "adamw_8bit",
        seed = 3407,
    ),
)
trainer.train()

# Go to https://github.com/unslothai/unsloth/wiki for advanced tips like
# (1) Saving to GGUF / merging to 16bit for vLLM
# (2) Continued training from a saved LoRA adapter
# (3) Adding an evaluation loop / OOMs
# (4) Customized chat templates
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;a name="RL"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üí° Reinforcement Learning&lt;/h2&gt; 
&lt;p&gt;RL including GRPO, GSPO, DrGRPO, DAPO, PPO, Reward Modelling, Online DPO all work with Unsloth. List of RL notebooks:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;gpt-oss GSPO notebook: &lt;a href="https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/gpt-oss-(20B)-GRPO.ipynb"&gt;Link&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Qwen2.5-VL GSPO notebook: &lt;a href="https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Qwen2_5_7B_VL_GRPO.ipynb"&gt;Link&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Advanced Qwen3 GRPO notebook: &lt;a href="https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Qwen3_(4B)-GRPO.ipynb"&gt;Link&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;ORPO notebook: &lt;a href="https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3_(8B)-ORPO.ipynb"&gt;Link&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;DPO Zephyr notebook: &lt;a href="https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Zephyr_(7B)-DPO.ipynb"&gt;Link&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;KTO notebook: &lt;a href="https://colab.research.google.com/drive/1MRgGtLWuZX4ypSfGguFgC-IblTvO2ivM?usp=sharing"&gt;Link&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;SimPO notebook: &lt;a href="https://colab.research.google.com/drive/1Hs5oQDovOay4mFA6Y9lQhVJ8TnbFLFh2?usp=sharing"&gt;Link&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;details&gt; 
 &lt;summary&gt;Click for DPO code&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;import os
os.environ["CUDA_VISIBLE_DEVICES"] = "0" # Optional set GPU device ID

from unsloth import FastLanguageModel
import torch
from trl import DPOTrainer, DPOConfig
max_seq_length = 2048

model, tokenizer = FastLanguageModel.from_pretrained(
    model_name = "unsloth/zephyr-sft-bnb-4bit",
    max_seq_length = max_seq_length,
    load_in_4bit = True,
)

# Do model patching and add fast LoRA weights
model = FastLanguageModel.get_peft_model(
    model,
    r = 64,
    target_modules = ["q_proj", "k_proj", "v_proj", "o_proj",
                      "gate_proj", "up_proj", "down_proj",],
    lora_alpha = 64,
    lora_dropout = 0, # Supports any, but = 0 is optimized
    bias = "none",    # Supports any, but = "none" is optimized
    # [NEW] "unsloth" uses 30% less VRAM, fits 2x larger batch sizes!
    use_gradient_checkpointing = "unsloth", # True or "unsloth" for very long context
    random_state = 3407,
    max_seq_length = max_seq_length,
)

dpo_trainer = DPOTrainer(
    model = model,
    ref_model = None,
    train_dataset = YOUR_DATASET_HERE,
    # eval_dataset = YOUR_DATASET_HERE,
    tokenizer = tokenizer,
    args = DPOConfig(
        per_device_train_batch_size = 4,
        gradient_accumulation_steps = 8,
        warmup_ratio = 0.1,
        num_train_epochs = 3,
        logging_steps = 1,
        optim = "adamw_8bit",
        seed = 42,
        output_dir = "outputs",
        max_length = 1024,
        max_prompt_length = 512,
        beta = 0.1,
    ),
)
dpo_trainer.train()
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h2&gt;ü•á Performance Benchmarking&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;For our most detailed benchmarks, read our &lt;a href="https://unsloth.ai/blog/llama3-3"&gt;Llama 3.3 Blog&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Benchmarking of Unsloth was also conducted by &lt;a href="https://huggingface.co/blog/unsloth-trl"&gt;ü§óHugging Face&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;We tested using the Alpaca Dataset, a batch size of 2, gradient accumulation steps of 4, rank = 32, and applied QLoRA on all linear layers (q, k, v, o, gate, up, down):&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Model&lt;/th&gt; 
   &lt;th&gt;VRAM&lt;/th&gt; 
   &lt;th&gt;ü¶• Unsloth speed&lt;/th&gt; 
   &lt;th&gt;ü¶• VRAM reduction&lt;/th&gt; 
   &lt;th&gt;ü¶• Longer context&lt;/th&gt; 
   &lt;th&gt;üòä Hugging Face + FA2&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Llama 3.3 (70B)&lt;/td&gt; 
   &lt;td&gt;80GB&lt;/td&gt; 
   &lt;td&gt;2x&lt;/td&gt; 
   &lt;td&gt;&amp;gt;75%&lt;/td&gt; 
   &lt;td&gt;13x longer&lt;/td&gt; 
   &lt;td&gt;1x&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Llama 3.1 (8B)&lt;/td&gt; 
   &lt;td&gt;80GB&lt;/td&gt; 
   &lt;td&gt;2x&lt;/td&gt; 
   &lt;td&gt;&amp;gt;70%&lt;/td&gt; 
   &lt;td&gt;12x longer&lt;/td&gt; 
   &lt;td&gt;1x&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Context length benchmarks&lt;/h3&gt; 
&lt;h4&gt;Llama 3.1 (8B) max. context length&lt;/h4&gt; 
&lt;p&gt;We tested Llama 3.1 (8B) Instruct and did 4bit QLoRA on all linear layers (Q, K, V, O, gate, up and down) with rank = 32 with a batch size of 1. We padded all sequences to a certain maximum sequence length to mimic long context finetuning workloads.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;GPU VRAM&lt;/th&gt; 
   &lt;th&gt;ü¶•Unsloth context length&lt;/th&gt; 
   &lt;th&gt;Hugging Face + FA2&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;8 GB&lt;/td&gt; 
   &lt;td&gt;2,972&lt;/td&gt; 
   &lt;td&gt;OOM&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;12 GB&lt;/td&gt; 
   &lt;td&gt;21,848&lt;/td&gt; 
   &lt;td&gt;932&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;16 GB&lt;/td&gt; 
   &lt;td&gt;40,724&lt;/td&gt; 
   &lt;td&gt;2,551&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;24 GB&lt;/td&gt; 
   &lt;td&gt;78,475&lt;/td&gt; 
   &lt;td&gt;5,789&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;40 GB&lt;/td&gt; 
   &lt;td&gt;153,977&lt;/td&gt; 
   &lt;td&gt;12,264&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;48 GB&lt;/td&gt; 
   &lt;td&gt;191,728&lt;/td&gt; 
   &lt;td&gt;15,502&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;80 GB&lt;/td&gt; 
   &lt;td&gt;342,733&lt;/td&gt; 
   &lt;td&gt;28,454&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h4&gt;Llama 3.3 (70B) max. context length&lt;/h4&gt; 
&lt;p&gt;We tested Llama 3.3 (70B) Instruct on a 80GB A100 and did 4bit QLoRA on all linear layers (Q, K, V, O, gate, up and down) with rank = 32 with a batch size of 1. We padded all sequences to a certain maximum sequence length to mimic long context finetuning workloads.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;GPU VRAM&lt;/th&gt; 
   &lt;th&gt;ü¶•Unsloth context length&lt;/th&gt; 
   &lt;th&gt;Hugging Face + FA2&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;48 GB&lt;/td&gt; 
   &lt;td&gt;12,106&lt;/td&gt; 
   &lt;td&gt;OOM&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;80 GB&lt;/td&gt; 
   &lt;td&gt;89,389&lt;/td&gt; 
   &lt;td&gt;6,916&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;br /&gt; 
&lt;p&gt;&lt;img src="https://i.ibb.co/sJ7RhGG/image-41.png" alt="" /&gt; &lt;br /&gt;&lt;/p&gt; 
&lt;h3&gt;Citation&lt;/h3&gt; 
&lt;p&gt;You can cite the Unsloth repo as follows:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bibtex"&gt;@software{unsloth,
  author = {Daniel Han, Michael Han and Unsloth team},
  title = {Unsloth},
  url = {http://github.com/unslothai/unsloth},
  year = {2023}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Thank You to&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;The &lt;a href="https://github.com/ggml-org/llama.cpp"&gt;llama.cpp library&lt;/a&gt; that lets users save models with Unsloth&lt;/li&gt; 
 &lt;li&gt;The Hugging Face team and their libraries: &lt;a href="https://github.com/huggingface/transformers"&gt;transformers&lt;/a&gt; and &lt;a href="https://github.com/huggingface/trl"&gt;TRL&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/erikwijmans"&gt;Erik&lt;/a&gt; for his help adding &lt;a href="https://github.com/apple/ml-cross-entropy"&gt;Apple's ML Cross Entropy&lt;/a&gt; in Unsloth&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Etherll"&gt;Etherl&lt;/a&gt; for adding support for &lt;a href="https://github.com/unslothai/notebooks/pull/34"&gt;TTS, diffusion and BERT models&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;And of course for every single person who has contributed or has used Unsloth!&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>emcie-co/parlant</title>
      <link>https://github.com/emcie-co/parlant</link>
      <description>&lt;p&gt;LLM agents built for control. Designed for real-world use. Deployed in minutes.&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://github.com/emcie-co/parlant/blob/develop/docs/LogoTransparentLight.png?raw=true" /&gt; 
  &lt;img alt="Parlant - AI Agent Framework" src="https://github.com/emcie-co/parlant/raw/develop/docs/LogoTransparentDark.png?raw=true" width="400" /&gt; 
 &lt;/picture&gt; 
 &lt;h3&gt;Finally, LLM agents that actually follow instructions&lt;/h3&gt; 
 &lt;p&gt; &lt;a href="https://www.parlant.io/" target="_blank"&gt;üåê Website&lt;/a&gt; ‚Ä¢ &lt;a href="https://www.parlant.io/docs/quickstart/installation" target="_blank"&gt;‚ö° Quick Start&lt;/a&gt; ‚Ä¢ &lt;a href="https://discord.gg/duxWqxKk6J" target="_blank"&gt;üí¨ Discord&lt;/a&gt; ‚Ä¢ &lt;a href="https://www.parlant.io/docs/quickstart/examples" target="_blank"&gt;üìñ Examples&lt;/a&gt; &lt;/p&gt; 
 &lt;p&gt; 
  &lt;!-- Keep these links. Translations will automatically update with the README. --&gt; &lt;a href="https://zdoc.app/de/emcie-co/parlant"&gt;Deutsch&lt;/a&gt; | &lt;a href="https://zdoc.app/es/emcie-co/parlant"&gt;Espa√±ol&lt;/a&gt; | &lt;a href="https://zdoc.app/fr/emcie-co/parlant"&gt;fran√ßais&lt;/a&gt; | &lt;a href="https://zdoc.app/ja/emcie-co/parlant"&gt;Êó•Êú¨Ë™û&lt;/a&gt; | &lt;a href="https://zdoc.app/ko/emcie-co/parlant"&gt;ÌïúÍµ≠Ïñ¥&lt;/a&gt; | &lt;a href="https://zdoc.app/pt/emcie-co/parlant"&gt;Portugu√™s&lt;/a&gt; | &lt;a href="https://zdoc.app/ru/emcie-co/parlant"&gt;–†—É—Å—Å–∫–∏–π&lt;/a&gt; | &lt;a href="https://zdoc.app/zh/emcie-co/parlant"&gt;‰∏≠Êñá&lt;/a&gt; &lt;/p&gt; 
 &lt;p&gt; &lt;a href="https://pypi.org/project/parlant/"&gt;&lt;img alt="PyPI" src="https://img.shields.io/pypi/v/parlant?color=blue" /&gt;&lt;/a&gt; &lt;img alt="Python 3.10+" src="https://img.shields.io/badge/python-3.10+-blue" /&gt; &lt;a href="https://opensource.org/licenses/Apache-2.0"&gt;&lt;img alt="License" src="https://img.shields.io/badge/license-Apache%202.0-green" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/duxWqxKk6J"&gt;&lt;img alt="Discord" src="https://img.shields.io/discord/1312378700993663007?color=7289da&amp;amp;logo=discord&amp;amp;logoColor=white" /&gt;&lt;/a&gt; &lt;img alt="GitHub Repo stars" src="https://img.shields.io/github/stars/emcie-co/parlant?style=social" /&gt; &lt;/p&gt; 
 &lt;a href="https://trendshift.io/repositories/12768" target="_blank"&gt; &lt;img src="https://trendshift.io/api/badge/repositories/12768" alt="Trending on TrendShift" style="width: 250px; height: 55px;" width="250" height="55" /&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;h2&gt;üéØ The Problem Every AI Developer Faces&lt;/h2&gt; 
&lt;p&gt;You build an AI agent. It works great in testing. Then real users start talking to it and...&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;‚ùå It ignores your carefully crafted system prompts&lt;/li&gt; 
 &lt;li&gt;‚ùå It hallucinates responses in critical moments&lt;/li&gt; 
 &lt;li&gt;‚ùå It can't handle edge cases consistently&lt;/li&gt; 
 &lt;li&gt;‚ùå Each conversation feels like a roll of the dice&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Sound familiar?&lt;/strong&gt; You're not alone. This is the #1 pain point for developers building production AI agents.&lt;/p&gt; 
&lt;h2&gt;‚ö° The Solution: Stop Fighting Prompts, Teach Principles&lt;/h2&gt; 
&lt;p&gt;Parlant flips the script on AI agent development. Instead of hoping your LLM will follow instructions, &lt;strong&gt;Parlant ensures it&lt;/strong&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# Traditional approach: Cross your fingers ü§û
system_prompt = "You are a helpful assistant. Please follow these 47 rules..."

# Parlant approach: Ensured compliance ‚úÖ
await agent.create_guideline(
    condition="Customer asks about refunds",
    action="Check order status first to see if eligible",
    tools=[check_order_status],
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;‚úÖ &lt;a href="https://www.parlant.io/blog/how-parlant-guarantees-compliance"&gt;Blog: How Parlant Ensures Agent Compliance&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üÜö &lt;a href="https://www.parlant.io/blog/parlant-vs-dspy"&gt;Blog: Parlant vs DSPy&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Parlant gives you all the structure you need to build customer-facing agents that behave exactly as your business requires:&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://parlant.io/docs/concepts/customization/journeys"&gt;Journeys&lt;/a&gt;&lt;/strong&gt;: Define clear customer journeys and how your agent should respond at each step.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://parlant.io/docs/concepts/customization/guidelines"&gt;Behavioral Guidelines&lt;/a&gt;&lt;/strong&gt;: Easily craft agent behavior; Parlant will match the relevant elements contextually.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://parlant.io/docs/concepts/customization/tools"&gt;Tool Use&lt;/a&gt;&lt;/strong&gt;: Attach external APIs, data fetchers, or backend services to specific interaction events.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://parlant.io/docs/concepts/customization/glossary"&gt;Domain Adaptation&lt;/a&gt;&lt;/strong&gt;: Teach your agent domain-specific terminology and craft personalized responses.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://parlant.io/docs/concepts/customization/canned-responses"&gt;Canned Responses&lt;/a&gt;&lt;/strong&gt;: Use response templates to eliminate hallucinations and guarantee style consistency.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://parlant.io/docs/advanced/explainability"&gt;Explainability&lt;/a&gt;&lt;/strong&gt;: Understand why and when each guideline was matched and followed.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;div align="center"&gt; 
 &lt;h2&gt;üöÄ Get Your Agent Running in 60 Seconds&lt;/h2&gt; 
&lt;/div&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install parlant
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import parlant.sdk as p

@p.tool
async def get_weather(context: p.ToolContext, city: str) -&amp;gt; p.ToolResult:
    # Your weather API logic here
    return p.ToolResult(f"Sunny, 72¬∞F in {city}")

@p.tool
async def get_datetime(context: p.ToolContext) -&amp;gt; p.ToolResult:
    from datetime import datetime
    return p.ToolResult(datetime.now())

async def main():
    async with p.Server() as server:
        agent = await server.create_agent(
            name="WeatherBot",
            description="Helpful weather assistant"
        )

        # Have the agent's context be updated on every response (though
        # update interval is customizable) using a context variable.
        await agent.create_variable(name="current-datetime", tool=get_datetime)

        # Control and guide agent behavior with natural language
        await agent.create_guideline(
            condition="User asks about weather",
            action="Get current weather and provide a friendly response with suggestions",
            tools=[get_weather]
        )

        # Add other (reliably enforced) behavioral modeling elements
        # ...

        # üéâ Test playground ready at http://localhost:8800
        # Integrate the official React widget into your app,
        # or follow the tutorial to build your own frontend!

if __name__ == "__main__":
    import asyncio
    asyncio.run(main())
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;That's it!&lt;/strong&gt; Your agent is running with ensured rule-following behavior.&lt;/p&gt; 
&lt;h2&gt;üé¨ See It In Action&lt;/h2&gt; 
&lt;img alt="Parlant Demo" src="https://github.com/emcie-co/parlant/raw/develop/docs/demo.gif?raw=true" width="100%" /&gt; 
&lt;h2&gt;üî• Why Developers Are Switching to Parlant&lt;/h2&gt; 
&lt;table width="100%"&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td width="50%"&gt; &lt;h3&gt;üèóÔ∏è &lt;strong&gt;Traditional AI Frameworks&lt;/strong&gt;&lt;/h3&gt; &lt;/td&gt; 
   &lt;td width="50%"&gt; &lt;h3&gt;‚ö° &lt;strong&gt;Parlant&lt;/strong&gt;&lt;/h3&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="50%"&gt; 
    &lt;ul&gt; 
     &lt;li&gt;Write complex system prompts&lt;/li&gt; 
     &lt;li&gt;Hope the LLM follows them&lt;/li&gt; 
     &lt;li&gt;Debug unpredictable behaviors&lt;/li&gt; 
     &lt;li&gt;Scale by prompt engineering&lt;/li&gt; 
     &lt;li&gt;Cross fingers for reliability&lt;/li&gt; 
    &lt;/ul&gt; &lt;/td&gt; 
   &lt;td width="50%"&gt; 
    &lt;ul&gt; 
     &lt;li&gt;Define rules in natural language&lt;/li&gt; 
     &lt;li&gt;&lt;strong&gt;Ensured&lt;/strong&gt; rule compliance&lt;/li&gt; 
     &lt;li&gt;Predictable, consistent behavior&lt;/li&gt; 
     &lt;li&gt;Scale by adding guidelines&lt;/li&gt; 
     &lt;li&gt;Production-ready from day one&lt;/li&gt; 
    &lt;/ul&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h2&gt;üéØ Perfect For Your Use Case&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th align="center"&gt;&lt;strong&gt;Financial Services&lt;/strong&gt;&lt;/th&gt; 
    &lt;th align="center"&gt;&lt;strong&gt;Healthcare&lt;/strong&gt;&lt;/th&gt; 
    &lt;th align="center"&gt;&lt;strong&gt;E-commerce&lt;/strong&gt;&lt;/th&gt; 
    &lt;th align="center"&gt;&lt;strong&gt;Legal Tech&lt;/strong&gt;&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;Compliance-first design&lt;/td&gt; 
    &lt;td align="center"&gt;HIPAA-ready agents&lt;/td&gt; 
    &lt;td align="center"&gt;Customer service at scale&lt;/td&gt; 
    &lt;td align="center"&gt;Precise legal guidance&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;Built-in risk management&lt;/td&gt; 
    &lt;td align="center"&gt;Patient data protection&lt;/td&gt; 
    &lt;td align="center"&gt;Order processing automation&lt;/td&gt; 
    &lt;td align="center"&gt;Document review assistance&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/div&gt; 
&lt;h2&gt;üõ†Ô∏è Enterprise-Grade Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;üß≠ Conversational Journeys&lt;/strong&gt; - Lead the customer step-by-step to a goal&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üéØ Dynamic Guideline Matching&lt;/strong&gt; - Context-aware rule application&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üîß Reliable Tool Integration&lt;/strong&gt; - APIs, databases, external services&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üìä Conversation Analytics&lt;/strong&gt; - Deep insights into agent behavior&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üîÑ Iterative Refinement&lt;/strong&gt; - Continuously improve agent responses&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üõ°Ô∏è Built-in Guardrails&lt;/strong&gt; - Prevent hallucination and off-topic responses&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üì± React Widget&lt;/strong&gt; - &lt;a href="https://github.com/emcie-co/parlant-chat-react"&gt;Drop-in chat UI for any web app&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üîç Full Explainability&lt;/strong&gt; - Understand every decision your agent makes&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üìà Join 10,000+ Developers Building Better AI&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;strong&gt;Companies using Parlant:&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;Financial institutions ‚Ä¢ Healthcare providers ‚Ä¢ Legal firms ‚Ä¢ E-commerce platforms&lt;/em&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://star-history.com/#emcie-co/parlant&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=emcie-co/parlant&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;üåü What Developers Are Saying&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;em&gt;"By far the most elegant conversational AI framework that I've come across! Developing with Parlant is pure joy."&lt;/em&gt; &lt;strong&gt;‚Äî Vishal Ahuja, Senior Lead, Customer-Facing Conversational AI @ JPMorgan Chase&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;üèÉ‚Äç‚ôÇÔ∏è Quick Start Paths&lt;/h2&gt; 
&lt;table border="0"&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;üéØ I want to test it myself&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.parlant.io/docs/quickstart/installation"&gt;‚Üí 5-minute quickstart&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;üõ†Ô∏è I want to see an example&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.parlant.io/docs/quickstart/examples"&gt;‚Üí Healthcare agent example&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;üöÄ I want to get involved&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://discord.gg/duxWqxKk6J"&gt;‚Üí Join our Discord community&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h2&gt;ü§ù Community &amp;amp; Support&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;üí¨ &lt;strong&gt;&lt;a href="https://discord.gg/duxWqxKk6J"&gt;Discord Community&lt;/a&gt;&lt;/strong&gt; - Get help from the team and community&lt;/li&gt; 
 &lt;li&gt;üìñ &lt;strong&gt;&lt;a href="https://parlant.io/docs/quickstart/installation"&gt;Documentation&lt;/a&gt;&lt;/strong&gt; - Comprehensive guides and examples&lt;/li&gt; 
 &lt;li&gt;üêõ &lt;strong&gt;&lt;a href="https://github.com/emcie-co/parlant/issues"&gt;GitHub Issues&lt;/a&gt;&lt;/strong&gt; - Bug reports and feature requests&lt;/li&gt; 
 &lt;li&gt;üìß &lt;strong&gt;&lt;a href="https://parlant.io/contact"&gt;Direct Support&lt;/a&gt;&lt;/strong&gt; - Direct line to our engineering team&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üìÑ License&lt;/h2&gt; 
&lt;p&gt;Apache 2.0 - Use it anywhere, including commercial projects.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;strong&gt;Ready to build AI agents that actually work?&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;‚≠ê &lt;strong&gt;Star this repo&lt;/strong&gt; ‚Ä¢ üöÄ &lt;strong&gt;&lt;a href="https://parlant.io/"&gt;Try Parlant now&lt;/a&gt;&lt;/strong&gt; ‚Ä¢ üí¨ &lt;strong&gt;&lt;a href="https://discord.gg/duxWqxKk6J"&gt;Join Discord&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;Built with ‚ù§Ô∏è by the team at &lt;a href="https://emcie.co"&gt;Emcie&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>yichuan-w/LEANN</title>
      <link>https://github.com/yichuan-w/LEANN</link>
      <description>&lt;p&gt;RAG on Everything with LEANN. Enjoy 97% storage savings while running a fast, accurate, and 100% private RAG application on your personal device.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/yichuan-w/LEANN/main/assets/logo-text.png" alt="LEANN Logo" width="400" /&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://img.shields.io/badge/Python-3.9%20%7C%203.10%20%7C%203.11%20%7C%203.12%20%7C%203.13-blue.svg?sanitize=true" alt="Python Versions" /&gt; &lt;img src="https://github.com/yichuan-w/LEANN/actions/workflows/build-and-publish.yml/badge.svg?sanitize=true" alt="CI Status" /&gt; &lt;img src="https://img.shields.io/badge/Platform-Ubuntu%20%26%20Arch%20%26%20WSL%20%7C%20macOS%20(ARM64%2FIntel)-lightgrey" alt="Platform" /&gt; &lt;img src="https://img.shields.io/badge/License-MIT-green.svg?sanitize=true" alt="MIT License" /&gt; &lt;img src="https://img.shields.io/badge/MCP-Native%20Integration-blue" alt="MCP Integration" /&gt; &lt;a href="https://join.slack.com/t/leann-e2u9779/shared_invite/zt-3ckd2f6w1-OX08~NN4gkWhh10PRVBj1Q"&gt;&lt;img src="https://img.shields.io/badge/Slack-Join-4A154B?logo=slack&amp;amp;logoColor=white" alt="Join Slack" /&gt; &lt;/a&gt;&lt;a href="https://raw.githubusercontent.com/yichuan-w/LEANN/main/assets/wechat_user_group.JPG" title="Join WeChat group"&gt;&lt;img src="https://img.shields.io/badge/WeChat-Join-2DC100?logo=wechat&amp;amp;logoColor=white" alt="Join WeChat group" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;h2 align="center" tabindex="-1" class="heading-element" dir="auto"&gt; The smallest vector index in the world. RAG Everything with LEANN! &lt;/h2&gt; 
&lt;p&gt;LEANN is an innovative vector database that democratizes personal AI. Transform your laptop into a powerful RAG system that can index and search through millions of documents while using &lt;strong&gt;97% less storage&lt;/strong&gt; than traditional solutions &lt;strong&gt;without accuracy loss&lt;/strong&gt;.&lt;/p&gt; 
&lt;p&gt;LEANN achieves this through &lt;em&gt;graph-based selective recomputation&lt;/em&gt; with &lt;em&gt;high-degree preserving pruning&lt;/em&gt;, computing embeddings on-demand instead of storing them all. &lt;a href="https://raw.githubusercontent.com/yichuan-w/LEANN/main/#%EF%B8%8F-architecture--how-it-works"&gt;Illustration Fig ‚Üí&lt;/a&gt; | &lt;a href="https://arxiv.org/abs/2506.08276"&gt;Paper ‚Üí&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Ready to RAG Everything?&lt;/strong&gt; Transform your laptop into a personal AI assistant that can semantic search your &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/yichuan-w/LEANN/main/#-personal-data-manager-process-any-documents-pdf-txt-md"&gt;file system&lt;/a&gt;&lt;/strong&gt;, &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/yichuan-w/LEANN/main/#-your-personal-email-secretary-rag-on-apple-mail"&gt;emails&lt;/a&gt;&lt;/strong&gt;, &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/yichuan-w/LEANN/main/#-time-machine-for-the-web-rag-your-entire-browser-history"&gt;browser history&lt;/a&gt;&lt;/strong&gt;, &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/yichuan-w/LEANN/main/#-wechat-detective-unlock-your-golden-memories"&gt;chat history&lt;/a&gt;&lt;/strong&gt; (&lt;a href="https://raw.githubusercontent.com/yichuan-w/LEANN/main/#-wechat-detective-unlock-your-golden-memories"&gt;WeChat&lt;/a&gt;, &lt;a href="https://raw.githubusercontent.com/yichuan-w/LEANN/main/#-imessage-history-your-personal-conversation-archive"&gt;iMessage&lt;/a&gt;), &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/yichuan-w/LEANN/main/#-chatgpt-chat-history-your-personal-ai-conversation-archive"&gt;agent memory&lt;/a&gt;&lt;/strong&gt; (&lt;a href="https://raw.githubusercontent.com/yichuan-w/LEANN/main/#-chatgpt-chat-history-your-personal-ai-conversation-archive"&gt;ChatGPT&lt;/a&gt;, &lt;a href="https://raw.githubusercontent.com/yichuan-w/LEANN/main/#-claude-chat-history-your-personal-ai-conversation-archive"&gt;Claude&lt;/a&gt;), &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/yichuan-w/LEANN/main/#-claude-code-integration-transform-your-development-workflow"&gt;codebase&lt;/a&gt;&lt;/strong&gt;* , or external knowledge bases (i.e., 60M documents) - all on your laptop, with zero cloud costs and complete privacy.&lt;/p&gt; 
&lt;p&gt;* Claude Code only supports basic &lt;code&gt;grep&lt;/code&gt;-style keyword search. &lt;strong&gt;LEANN&lt;/strong&gt; is a drop-in &lt;strong&gt;semantic search MCP service fully compatible with Claude Code&lt;/strong&gt;, unlocking intelligent retrieval without changing your workflow. üî• Check out &lt;a href="https://raw.githubusercontent.com/yichuan-w/LEANN/main/packages/leann-mcp/README.md"&gt;the easy setup ‚Üí&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Why LEANN?&lt;/h2&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/yichuan-w/LEANN/main/assets/effects.png" alt="LEANN vs Traditional Vector DB Storage Comparison" width="70%" /&gt; &lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;The numbers speak for themselves:&lt;/strong&gt; Index 60 million text chunks in just 6GB instead of 201GB. From emails to browser history, everything fits on your laptop. &lt;a href="https://raw.githubusercontent.com/yichuan-w/LEANN/main/#-storage-comparison"&gt;See detailed benchmarks for different applications below ‚Üì&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;üîí &lt;strong&gt;Privacy:&lt;/strong&gt; Your data never leaves your laptop. No OpenAI, no cloud, no "terms of service".&lt;/p&gt; 
&lt;p&gt;ü™∂ &lt;strong&gt;Lightweight:&lt;/strong&gt; Graph-based recomputation eliminates heavy embedding storage, while smart graph pruning and CSR format minimize graph storage overhead. Always less storage, less memory usage!&lt;/p&gt; 
&lt;p&gt;üì¶ &lt;strong&gt;Portable:&lt;/strong&gt; Transfer your entire knowledge base between devices (even with others) with minimal cost - your personal AI memory travels with you.&lt;/p&gt; 
&lt;p&gt;üìà &lt;strong&gt;Scalability:&lt;/strong&gt; Handle messy personal data that would crash traditional vector DBs, easily managing your growing personalized data and agent generated memory!&lt;/p&gt; 
&lt;p&gt;‚ú® &lt;strong&gt;No Accuracy Loss:&lt;/strong&gt; Maintain the same search quality as heavyweight solutions while using 97% less storage.&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;h3&gt;üì¶ Prerequisites: Install uv&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://docs.astral.sh/uv/getting-started/installation/#installation-methods"&gt;Install uv&lt;/a&gt; first if you don't have it. Typically, you can install it with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -LsSf https://astral.sh/uv/install.sh | sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;üöÄ Quick Install&lt;/h3&gt; 
&lt;p&gt;Clone the repository to access all examples and try amazing applications,&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/yichuan-w/LEANN.git leann
cd leann
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;and install LEANN from &lt;a href="https://pypi.org/project/leann/"&gt;PyPI&lt;/a&gt; to run them immediately:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uv venv
source .venv/bin/activate
uv pip install leann
&lt;/code&gt;&lt;/pre&gt; 
&lt;!--
&gt; Low-resource? See ‚ÄúLow-resource setups‚Äù in the [Configuration Guide](docs/configuration-guide.md#low-resource-setups). --&gt; 
&lt;details&gt; 
 &lt;summary&gt; &lt;strong&gt;üîß Build from Source (Recommended for development)&lt;/strong&gt; &lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/yichuan-w/LEANN.git leann
cd leann
git submodule update --init --recursive
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;macOS:&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;Note: DiskANN requires MacOS 13.3 or later.&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;brew install libomp boost protobuf zeromq pkgconf
uv sync --extra diskann
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;Linux (Ubuntu/Debian):&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;Note: On Ubuntu 20.04, you may need to build a newer Abseil and pin Protobuf (e.g., v3.20.x) for building DiskANN. See &lt;a href="https://github.com/yichuan-w/LEANN/issues/30"&gt;Issue #30&lt;/a&gt; for a step-by-step note.&lt;/p&gt; 
 &lt;p&gt;You can manually install &lt;a href="https://www.intel.com/content/www/us/en/developer/tools/oneapi/onemkl.html"&gt;Intel oneAPI MKL&lt;/a&gt; instead of &lt;code&gt;libmkl-full-dev&lt;/code&gt; for DiskANN. You can also use &lt;code&gt;libopenblas-dev&lt;/code&gt; for building HNSW only, by removing &lt;code&gt;--extra diskann&lt;/code&gt; in the command below.&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;sudo apt-get update &amp;amp;&amp;amp; sudo apt-get install -y \
  libomp-dev libboost-all-dev protobuf-compiler libzmq3-dev \
  pkg-config libabsl-dev libaio-dev libprotobuf-dev \
  libmkl-full-dev

uv sync --extra diskann
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;Linux (Arch Linux):&lt;/strong&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;sudo pacman -Syu &amp;amp;&amp;amp; sudo pacman -S --needed base-devel cmake pkgconf git gcc \
  boost boost-libs protobuf abseil-cpp libaio zeromq

# For MKL in DiskANN
sudo pacman -S --needed base-devel git
git clone https://aur.archlinux.org/paru-bin.git
cd paru-bin &amp;amp;&amp;amp; makepkg -si
paru -S intel-oneapi-mkl intel-oneapi-compiler
source /opt/intel/oneapi/setvars.sh

uv sync --extra diskann
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;Linux (RHEL / CentOS Stream / Oracle / Rocky / AlmaLinux):&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;See &lt;a href="https://github.com/yichuan-w/LEANN/issues/50"&gt;Issue #50&lt;/a&gt; for more details.&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;sudo dnf groupinstall -y "Development Tools"
sudo dnf install -y libomp-devel boost-devel protobuf-compiler protobuf-devel \
  abseil-cpp-devel libaio-devel zeromq-devel pkgconf-pkg-config

# For MKL in DiskANN
sudo dnf install -y intel-oneapi-mkl intel-oneapi-mkl-devel \
  intel-oneapi-openmp || sudo dnf install -y intel-oneapi-compiler
source /opt/intel/oneapi/setvars.sh

uv sync --extra diskann
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;p&gt;Our declarative API makes RAG as easy as writing a config file.&lt;/p&gt; 
&lt;p&gt;Check out &lt;a href="https://raw.githubusercontent.com/yichuan-w/LEANN/main/demo.ipynb"&gt;demo.ipynb&lt;/a&gt; or &lt;a href="https://colab.research.google.com/github/yichuan-w/LEANN/blob/main/demo.ipynb"&gt;&lt;img src="https://colab.research.google.com/assets/colab-badge.svg?sanitize=true" alt="Open In Colab" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from leann import LeannBuilder, LeannSearcher, LeannChat
from pathlib import Path
INDEX_PATH = str(Path("./").resolve() / "demo.leann")

# Build an index
builder = LeannBuilder(backend_name="hnsw")
builder.add_text("LEANN saves 97% storage compared to traditional vector databases.")
builder.add_text("Tung Tung Tung Sahur called‚Äîthey need their banana‚Äëcrocodile hybrid back")
builder.build_index(INDEX_PATH)

# Search
searcher = LeannSearcher(INDEX_PATH)
results = searcher.search("fantastical AI-generated creatures", top_k=1)

# Chat with your data
chat = LeannChat(INDEX_PATH, llm_config={"type": "hf", "model": "Qwen/Qwen3-0.6B"})
response = chat.ask("How much storage does LEANN save?", top_k=1)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;RAG on Everything!&lt;/h2&gt; 
&lt;p&gt;LEANN supports RAG on various data sources including documents (&lt;code&gt;.pdf&lt;/code&gt;, &lt;code&gt;.txt&lt;/code&gt;, &lt;code&gt;.md&lt;/code&gt;), Apple Mail, Google Search History, WeChat, ChatGPT conversations, Claude conversations, iMessage conversations, and more.&lt;/p&gt; 
&lt;h3&gt;Generation Model Setup&lt;/h3&gt; 
&lt;h4&gt;LLM Backend&lt;/h4&gt; 
&lt;p&gt;LEANN supports many LLM providers for text generation (HuggingFace, Ollama, and Any OpenAI compatible API).&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;üîë OpenAI API Setup (Default)&lt;/strong&gt;&lt;/summary&gt; 
 &lt;p&gt;Set your OpenAI API key as an environment variable:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;export OPENAI_API_KEY="your-api-key-here"
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Make sure to use &lt;code&gt;--llm openai&lt;/code&gt; flag when using the CLI. You can also specify the model name with &lt;code&gt;--llm-model &amp;lt;model-name&amp;gt;&lt;/code&gt; flag.&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;üõ†Ô∏è Supported LLM &amp;amp; Embedding Providers (via OpenAI Compatibility)&lt;/strong&gt;&lt;/summary&gt; 
 &lt;p&gt;Thanks to the widespread adoption of the OpenAI API format, LEANN is compatible out-of-the-box with a vast array of LLM and embedding providers. Simply set the &lt;code&gt;OPENAI_BASE_URL&lt;/code&gt; and &lt;code&gt;OPENAI_API_KEY&lt;/code&gt; environment variables to connect to your preferred service.&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-sh"&gt;export OPENAI_API_KEY="xxx"
export OPENAI_BASE_URL="http://localhost:1234/v1" # base url of the provider
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;To use OpenAI compatible endpoint with the CLI interface:&lt;/p&gt; 
 &lt;p&gt;If you are using it for text generation, make sure to use &lt;code&gt;--llm openai&lt;/code&gt; flag and specify the model name with &lt;code&gt;--llm-model &amp;lt;model-name&amp;gt;&lt;/code&gt; flag.&lt;/p&gt; 
 &lt;p&gt;If you are using it for embedding, set the &lt;code&gt;--embedding-mode openai&lt;/code&gt; flag and specify the model name with &lt;code&gt;--embedding-model &amp;lt;MODEL&amp;gt;&lt;/code&gt;.&lt;/p&gt; 
 &lt;hr /&gt; 
 &lt;p&gt;Below is a list of base URLs for common providers to get you started.&lt;/p&gt; 
 &lt;h3&gt;üñ•Ô∏è Local Inference Engines (Recommended for full privacy)&lt;/h3&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;Provider&lt;/th&gt; 
    &lt;th&gt;Sample Base URL&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;Ollama&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;http://localhost:11434/v1&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;LM Studio&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;http://localhost:1234/v1&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;vLLM&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;http://localhost:8000/v1&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;llama.cpp&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;http://localhost:8080/v1&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;SGLang&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;http://localhost:30000/v1&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;LiteLLM&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;http://localhost:4000&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
 &lt;hr /&gt; 
 &lt;h3&gt;‚òÅÔ∏è Cloud Providers&lt;/h3&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;&lt;strong&gt;üö® A Note on Privacy:&lt;/strong&gt; Before choosing a cloud provider, carefully review their privacy and data retention policies. Depending on their terms, your data may be used for their own purposes, including but not limited to human reviews and model training, which can lead to serious consequences if not handled properly.&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;Provider&lt;/th&gt; 
    &lt;th&gt;Base URL&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;OpenAI&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;https://api.openai.com/v1&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;OpenRouter&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;https://openrouter.ai/api/v1&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;Gemini&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;https://generativelanguage.googleapis.com/v1beta/openai/&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;x.AI (Grok)&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;https://api.x.ai/v1&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;Groq AI&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;https://api.groq.com/openai/v1&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;DeepSeek&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;https://api.deepseek.com/v1&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;SiliconFlow&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;https://api.siliconflow.cn/v1&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;Zhipu (BigModel)&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;https://open.bigmodel.cn/api/paas/v4/&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;Mistral AI&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;https://api.mistral.ai/v1&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
 &lt;p&gt;If your provider isn't on this list, don't worry! Check their documentation for an OpenAI-compatible endpoint‚Äîchances are, it's OpenAI Compatible too!&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;üîß Ollama Setup (Recommended for full privacy)&lt;/strong&gt;&lt;/summary&gt; 
 &lt;p&gt;&lt;strong&gt;macOS:&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;First, &lt;a href="https://ollama.com/download/mac"&gt;download Ollama for macOS&lt;/a&gt;.&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# Pull a lightweight model (recommended for consumer hardware)
ollama pull llama3.2:1b
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;Linux:&lt;/strong&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# Install Ollama
curl -fsSL https://ollama.ai/install.sh | sh

# Start Ollama service manually
ollama serve &amp;amp;

# Pull a lightweight model (recommended for consumer hardware)
ollama pull llama3.2:1b
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h2&gt;‚≠ê Flexible Configuration&lt;/h2&gt; 
&lt;p&gt;LEANN provides flexible parameters for embedding models, search strategies, and data processing to fit your specific needs.&lt;/p&gt; 
&lt;p&gt;üìö &lt;strong&gt;Need configuration best practices?&lt;/strong&gt; Check our &lt;a href="https://raw.githubusercontent.com/yichuan-w/LEANN/main/docs/configuration-guide.md"&gt;Configuration Guide&lt;/a&gt; for detailed optimization tips, model selection advice, and solutions to common issues like slow embeddings or poor search quality.&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;üìã Click to expand: Common Parameters (Available in All Examples)&lt;/strong&gt;&lt;/summary&gt; 
 &lt;p&gt;All RAG examples share these common parameters. &lt;strong&gt;Interactive mode&lt;/strong&gt; is available in all examples - simply run without &lt;code&gt;--query&lt;/code&gt; to start a continuous Q&amp;amp;A session where you can ask multiple questions. Type 'quit' to exit.&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# Core Parameters (General preprocessing for all examples)
--index-dir DIR              # Directory to store the index (default: current directory)
--query "YOUR QUESTION"      # Single query mode. Omit for interactive chat (type 'quit' to exit), and now you can play with your index interactively
--max-items N                # Limit data preprocessing (default: -1, process all data)
--force-rebuild              # Force rebuild index even if it exists

# Embedding Parameters
--embedding-model MODEL      # e.g., facebook/contriever, text-embedding-3-small, mlx-community/Qwen3-Embedding-0.6B-8bit or nomic-embed-text
--embedding-mode MODE        # sentence-transformers, openai, mlx, or ollama

# LLM Parameters (Text generation models)
--llm TYPE                   # LLM backend: openai, ollama, or hf (default: openai)
--llm-model MODEL            # Model name (default: gpt-4o) e.g., gpt-4o-mini, llama3.2:1b, Qwen/Qwen2.5-1.5B-Instruct
--thinking-budget LEVEL      # Thinking budget for reasoning models: low/medium/high (supported by o3, o3-mini, GPT-Oss:20b, and other reasoning models)

# Search Parameters
--top-k N                    # Number of results to retrieve (default: 20)
--search-complexity N        # Search complexity for graph traversal (default: 32)

# Chunking Parameters
--chunk-size N               # Size of text chunks (default varies by source: 256 for most, 192 for WeChat)
--chunk-overlap N            # Overlap between chunks (default varies: 25-128 depending on source)

# Index Building Parameters
--backend-name NAME          # Backend to use: hnsw or diskann (default: hnsw)
--graph-degree N             # Graph degree for index construction (default: 32)
--build-complexity N         # Build complexity for index construction (default: 64)
--compact / --no-compact     # Use compact storage (default: true). Must be `no-compact` for `no-recompute` build.
--recompute / --no-recompute # Enable/disable embedding recomputation (default: enabled). Should not do a `no-recompute` search in a `recompute` build.
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h3&gt;üìÑ Personal Data Manager: Process Any Documents (&lt;code&gt;.pdf&lt;/code&gt;, &lt;code&gt;.txt&lt;/code&gt;, &lt;code&gt;.md&lt;/code&gt;)!&lt;/h3&gt; 
&lt;p&gt;Ask questions directly about your personal PDFs, documents, and any directory containing your files!&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/yichuan-w/LEANN/main/videos/paper_clear.gif" alt="LEANN Document Search Demo" width="600" /&gt; &lt;/p&gt; 
&lt;p&gt;The example below asks a question about summarizing our paper (uses default data in &lt;code&gt;data/&lt;/code&gt;, which is a directory with diverse data sources: two papers, Pride and Prejudice, and a Technical report about LLM in Huawei in Chinese), and this is the &lt;strong&gt;easiest example&lt;/strong&gt; to run here:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;source .venv/bin/activate # Don't forget to activate the virtual environment
python -m apps.document_rag --query "What are the main techniques LEANN explores?"
&lt;/code&gt;&lt;/pre&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;üìã Click to expand: Document-Specific Arguments&lt;/strong&gt;&lt;/summary&gt; 
 &lt;h4&gt;Parameters&lt;/h4&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;--data-dir DIR           # Directory containing documents to process (default: data)
--file-types .ext .ext   # Filter by specific file types (optional - all LlamaIndex supported types if omitted)
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h4&gt;Example Commands&lt;/h4&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# Process all documents with larger chunks for academic papers
python -m apps.document_rag --data-dir "~/Documents/Papers" --chunk-size 1024

# Filter only markdown and Python files with smaller chunks
python -m apps.document_rag --data-dir "./docs" --chunk-size 256 --file-types .md .py

# Enable AST-aware chunking for code files
python -m apps.document_rag --enable-code-chunking --data-dir "./my_project"

# Or use the specialized code RAG for better code understanding
python -m apps.code_rag --repo-dir "./my_codebase" --query "How does authentication work?"
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h3&gt;üìß Your Personal Email Secretary: RAG on Apple Mail!&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; The examples below currently support macOS only. Windows support coming soon.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/yichuan-w/LEANN/main/videos/mail_clear.gif" alt="LEANN Email Search Demo" width="600" /&gt; &lt;/p&gt; 
&lt;p&gt;Before running the example below, you need to grant full disk access to your terminal/VS Code in System Preferences ‚Üí Privacy &amp;amp; Security ‚Üí Full Disk Access.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python -m apps.email_rag --query "What's the food I ordered by DoorDash or Uber Eats mostly?"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;780K email chunks ‚Üí 78MB storage.&lt;/strong&gt; Finally, search your email like you search Google.&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;üìã Click to expand: Email-Specific Arguments&lt;/strong&gt;&lt;/summary&gt; 
 &lt;h4&gt;Parameters&lt;/h4&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;--mail-path PATH         # Path to specific mail directory (auto-detects if omitted)
--include-html          # Include HTML content in processing (useful for newsletters)
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h4&gt;Example Commands&lt;/h4&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# Search work emails from a specific account
python -m apps.email_rag --mail-path "~/Library/Mail/V10/WORK_ACCOUNT"

# Find all receipts and order confirmations (includes HTML)
python -m apps.email_rag --query "receipt order confirmation invoice" --include-html
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;üìã Click to expand: Example queries you can try&lt;/strong&gt;&lt;/summary&gt; 
 &lt;p&gt;Once the index is built, you can ask questions like:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;"Find emails from my boss about deadlines"&lt;/li&gt; 
  &lt;li&gt;"What did John say about the project timeline?"&lt;/li&gt; 
  &lt;li&gt;"Show me emails about travel expenses"&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h3&gt;üîç Time Machine for the Web: RAG Your Entire Chrome Browser History!&lt;/h3&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/yichuan-w/LEANN/main/videos/google_clear.gif" alt="LEANN Browser History Search Demo" width="600" /&gt; &lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python -m apps.browser_rag --query "Tell me my browser history about machine learning?"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;38K browser entries ‚Üí 6MB storage.&lt;/strong&gt; Your browser history becomes your personal search engine.&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;üìã Click to expand: Browser-Specific Arguments&lt;/strong&gt;&lt;/summary&gt; 
 &lt;h4&gt;Parameters&lt;/h4&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;--chrome-profile PATH    # Path to Chrome profile directory (auto-detects if omitted)
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h4&gt;Example Commands&lt;/h4&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# Search academic research from your browsing history
python -m apps.browser_rag --query "arxiv papers machine learning transformer architecture"

# Track competitor analysis across work profile
python -m apps.browser_rag --chrome-profile "~/Library/Application Support/Google/Chrome/Work Profile" --max-items 5000
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;üìã Click to expand: How to find your Chrome profile&lt;/strong&gt;&lt;/summary&gt; 
 &lt;p&gt;The default Chrome profile path is configured for a typical macOS setup. If you need to find your specific Chrome profile:&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;Open Terminal&lt;/li&gt; 
  &lt;li&gt;Run: &lt;code&gt;ls ~/Library/Application\ Support/Google/Chrome/&lt;/code&gt;&lt;/li&gt; 
  &lt;li&gt;Look for folders like "Default", "Profile 1", "Profile 2", etc.&lt;/li&gt; 
  &lt;li&gt;Use the full path as your &lt;code&gt;--chrome-profile&lt;/code&gt; argument&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;p&gt;&lt;strong&gt;Common Chrome profile locations:&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;macOS: &lt;code&gt;~/Library/Application Support/Google/Chrome/Default&lt;/code&gt;&lt;/li&gt; 
  &lt;li&gt;Linux: &lt;code&gt;~/.config/google-chrome/Default&lt;/code&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;üí¨ Click to expand: Example queries you can try&lt;/strong&gt;&lt;/summary&gt; 
 &lt;p&gt;Once the index is built, you can ask questions like:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;"What websites did I visit about machine learning?"&lt;/li&gt; 
  &lt;li&gt;"Find my search history about programming"&lt;/li&gt; 
  &lt;li&gt;"What YouTube videos did I watch recently?"&lt;/li&gt; 
  &lt;li&gt;"Show me websites I visited about travel planning"&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h3&gt;üí¨ WeChat Detective: Unlock Your Golden Memories!&lt;/h3&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/yichuan-w/LEANN/main/videos/wechat_clear.gif" alt="LEANN WeChat Search Demo" width="600" /&gt; &lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python -m apps.wechat_rag --query "Show me all group chats about weekend plans"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;400K messages ‚Üí 64MB storage&lt;/strong&gt; Search years of chat history in any language.&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;üîß Click to expand: Installation Requirements&lt;/strong&gt;&lt;/summary&gt; 
 &lt;p&gt;First, you need to install the &lt;a href="https://github.com/sunnyyoung/WeChatTweak-CLI"&gt;WeChat exporter&lt;/a&gt;,&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;brew install sunnyyoung/repo/wechattweak-cli
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;or install it manually (if you have issues with Homebrew):&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;sudo packages/wechat-exporter/wechattweak-cli install
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;Troubleshooting:&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;Installation issues&lt;/strong&gt;: Check the &lt;a href="https://github.com/sunnyyoung/WeChatTweak-CLI/issues/41"&gt;WeChatTweak-CLI issues page&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Export errors&lt;/strong&gt;: If you encounter the error below, try restarting WeChat &lt;pre&gt;&lt;code class="language-bash"&gt;Failed to export WeChat data. Please ensure WeChat is running and WeChatTweak is installed.
Failed to find or export WeChat data. Exiting.
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;üìã Click to expand: WeChat-Specific Arguments&lt;/strong&gt;&lt;/summary&gt; 
 &lt;h4&gt;Parameters&lt;/h4&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;--export-dir DIR         # Directory to store exported WeChat data (default: wechat_export_direct)
--force-export          # Force re-export even if data exists
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h4&gt;Example Commands&lt;/h4&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# Search for travel plans discussed in group chats
python -m apps.wechat_rag --query "travel plans" --max-items 10000

# Re-export and search recent chats (useful after new messages)
python -m apps.wechat_rag --force-export --query "work schedule"
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;üí¨ Click to expand: Example queries you can try&lt;/strong&gt;&lt;/summary&gt; 
 &lt;p&gt;Once the index is built, you can ask questions like:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;"ÊàëÊÉ≥‰π∞È≠îÊúØÂ∏àÁ∫¶Áø∞ÈÄäÁöÑÁêÉË°£ÔºåÁªôÊàë‰∏Ä‰∫õÂØπÂ∫îËÅäÂ§©ËÆ∞ÂΩï?" (Chinese: Show me chat records about buying Magic Johnson's jersey)&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h3&gt;ü§ñ ChatGPT Chat History: Your Personal AI Conversation Archive!&lt;/h3&gt; 
&lt;p&gt;Transform your ChatGPT conversations into a searchable knowledge base! Search through all your ChatGPT discussions about coding, research, brainstorming, and more.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python -m apps.chatgpt_rag --export-path chatgpt_export.html --query "How do I create a list in Python?"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Unlock your AI conversation history.&lt;/strong&gt; Never lose track of valuable insights from your ChatGPT discussions again.&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;üìã Click to expand: How to Export ChatGPT Data&lt;/strong&gt;&lt;/summary&gt; 
 &lt;p&gt;&lt;strong&gt;Step-by-step export process:&lt;/strong&gt;&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;&lt;strong&gt;Sign in to ChatGPT&lt;/strong&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Click your profile icon&lt;/strong&gt; in the top right corner&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Navigate to Settings&lt;/strong&gt; ‚Üí &lt;strong&gt;Data Controls&lt;/strong&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Click "Export"&lt;/strong&gt; under Export Data&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Confirm the export&lt;/strong&gt; request&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Download the ZIP file&lt;/strong&gt; from the email link (expires in 24 hours)&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Extract or use directly&lt;/strong&gt; with LEANN&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;p&gt;&lt;strong&gt;Supported formats:&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;code&gt;.html&lt;/code&gt; files from ChatGPT exports&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;.zip&lt;/code&gt; archives from ChatGPT&lt;/li&gt; 
  &lt;li&gt;Directories with multiple export files&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;üìã Click to expand: ChatGPT-Specific Arguments&lt;/strong&gt;&lt;/summary&gt; 
 &lt;h4&gt;Parameters&lt;/h4&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;--export-path PATH           # Path to ChatGPT export file (.html/.zip) or directory (default: ./chatgpt_export)
--separate-messages         # Process each message separately instead of concatenated conversations
--chunk-size N              # Text chunk size (default: 512)
--chunk-overlap N           # Overlap between chunks (default: 128)
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h4&gt;Example Commands&lt;/h4&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# Basic usage with HTML export
python -m apps.chatgpt_rag --export-path conversations.html

# Process ZIP archive from ChatGPT
python -m apps.chatgpt_rag --export-path chatgpt_export.zip

# Search with specific query
python -m apps.chatgpt_rag --export-path chatgpt_data.html --query "Python programming help"

# Process individual messages for fine-grained search
python -m apps.chatgpt_rag --separate-messages --export-path chatgpt_export.html

# Process directory containing multiple exports
python -m apps.chatgpt_rag --export-path ./chatgpt_exports/ --max-items 1000
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;üí° Click to expand: Example queries you can try&lt;/strong&gt;&lt;/summary&gt; 
 &lt;p&gt;Once your ChatGPT conversations are indexed, you can search with queries like:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;"What did I ask ChatGPT about Python programming?"&lt;/li&gt; 
  &lt;li&gt;"Show me conversations about machine learning algorithms"&lt;/li&gt; 
  &lt;li&gt;"Find discussions about web development frameworks"&lt;/li&gt; 
  &lt;li&gt;"What coding advice did ChatGPT give me?"&lt;/li&gt; 
  &lt;li&gt;"Search for conversations about debugging techniques"&lt;/li&gt; 
  &lt;li&gt;"Find ChatGPT's recommendations for learning resources"&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h3&gt;ü§ñ Claude Chat History: Your Personal AI Conversation Archive!&lt;/h3&gt; 
&lt;p&gt;Transform your Claude conversations into a searchable knowledge base! Search through all your Claude discussions about coding, research, brainstorming, and more.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python -m apps.claude_rag --export-path claude_export.json --query "What did I ask about Python dictionaries?"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Unlock your AI conversation history.&lt;/strong&gt; Never lose track of valuable insights from your Claude discussions again.&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;üìã Click to expand: How to Export Claude Data&lt;/strong&gt;&lt;/summary&gt; 
 &lt;p&gt;&lt;strong&gt;Step-by-step export process:&lt;/strong&gt;&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;&lt;strong&gt;Open Claude&lt;/strong&gt; in your browser&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Navigate to Settings&lt;/strong&gt; (look for gear icon or settings menu)&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Find Export/Download&lt;/strong&gt; options in your account settings&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Download conversation data&lt;/strong&gt; (usually in JSON format)&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Place the file&lt;/strong&gt; in your project directory&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;p&gt;&lt;em&gt;Note: Claude export methods may vary depending on the interface you're using. Check Claude's help documentation for the most current export instructions.&lt;/em&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Supported formats:&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;code&gt;.json&lt;/code&gt; files (recommended)&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;.zip&lt;/code&gt; archives containing JSON data&lt;/li&gt; 
  &lt;li&gt;Directories with multiple export files&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;üìã Click to expand: Claude-Specific Arguments&lt;/strong&gt;&lt;/summary&gt; 
 &lt;h4&gt;Parameters&lt;/h4&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;--export-path PATH           # Path to Claude export file (.json/.zip) or directory (default: ./claude_export)
--separate-messages         # Process each message separately instead of concatenated conversations
--chunk-size N              # Text chunk size (default: 512)
--chunk-overlap N           # Overlap between chunks (default: 128)
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h4&gt;Example Commands&lt;/h4&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# Basic usage with JSON export
python -m apps.claude_rag --export-path my_claude_conversations.json

# Process ZIP archive from Claude
python -m apps.claude_rag --export-path claude_export.zip

# Search with specific query
python -m apps.claude_rag --export-path claude_data.json --query "machine learning advice"

# Process individual messages for fine-grained search
python -m apps.claude_rag --separate-messages --export-path claude_export.json

# Process directory containing multiple exports
python -m apps.claude_rag --export-path ./claude_exports/ --max-items 1000
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;üí° Click to expand: Example queries you can try&lt;/strong&gt;&lt;/summary&gt; 
 &lt;p&gt;Once your Claude conversations are indexed, you can search with queries like:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;"What did I ask Claude about Python programming?"&lt;/li&gt; 
  &lt;li&gt;"Show me conversations about machine learning algorithms"&lt;/li&gt; 
  &lt;li&gt;"Find discussions about software architecture patterns"&lt;/li&gt; 
  &lt;li&gt;"What debugging advice did Claude give me?"&lt;/li&gt; 
  &lt;li&gt;"Search for conversations about data structures"&lt;/li&gt; 
  &lt;li&gt;"Find Claude's recommendations for learning resources"&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h3&gt;üí¨ iMessage History: Your Personal Conversation Archive!&lt;/h3&gt; 
&lt;p&gt;Transform your iMessage conversations into a searchable knowledge base! Search through all your text messages, group chats, and conversations with friends, family, and colleagues.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python -m apps.imessage_rag --query "What did we discuss about the weekend plans?"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Unlock your message history.&lt;/strong&gt; Never lose track of important conversations, shared links, or memorable moments from your iMessage history.&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;üìã Click to expand: How to Access iMessage Data&lt;/strong&gt;&lt;/summary&gt; 
 &lt;p&gt;&lt;strong&gt;iMessage data location:&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;iMessage conversations are stored in a SQLite database on your Mac at:&lt;/p&gt; 
 &lt;pre&gt;&lt;code&gt;~/Library/Messages/chat.db
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;Important setup requirements:&lt;/strong&gt;&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Grant Full Disk Access&lt;/strong&gt; to your terminal or IDE:&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Open &lt;strong&gt;System Preferences&lt;/strong&gt; ‚Üí &lt;strong&gt;Security &amp;amp; Privacy&lt;/strong&gt; ‚Üí &lt;strong&gt;Privacy&lt;/strong&gt;&lt;/li&gt; 
    &lt;li&gt;Select &lt;strong&gt;Full Disk Access&lt;/strong&gt; from the left sidebar&lt;/li&gt; 
    &lt;li&gt;Click the &lt;strong&gt;+&lt;/strong&gt; button and add your terminal app (Terminal, iTerm2) or IDE (VS Code, etc.)&lt;/li&gt; 
    &lt;li&gt;Restart your terminal/IDE after granting access&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Alternative: Use a backup database&lt;/strong&gt;&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;If you have Time Machine backups or manual copies of the database&lt;/li&gt; 
    &lt;li&gt;Use &lt;code&gt;--db-path&lt;/code&gt; to specify a custom location&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;p&gt;&lt;strong&gt;Supported formats:&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Direct access to &lt;code&gt;~/Library/Messages/chat.db&lt;/code&gt; (default)&lt;/li&gt; 
  &lt;li&gt;Custom database path with &lt;code&gt;--db-path&lt;/code&gt;&lt;/li&gt; 
  &lt;li&gt;Works with backup copies of the database&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;üìã Click to expand: iMessage-Specific Arguments&lt;/strong&gt;&lt;/summary&gt; 
 &lt;h4&gt;Parameters&lt;/h4&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;--db-path PATH                    # Path to chat.db file (default: ~/Library/Messages/chat.db)
--concatenate-conversations       # Group messages by conversation (default: True)
--no-concatenate-conversations    # Process each message individually
--chunk-size N                    # Text chunk size (default: 1000)
--chunk-overlap N                 # Overlap between chunks (default: 200)
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h4&gt;Example Commands&lt;/h4&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# Basic usage (requires Full Disk Access)
python -m apps.imessage_rag

# Search with specific query
python -m apps.imessage_rag --query "family dinner plans"

# Use custom database path
python -m apps.imessage_rag --db-path /path/to/backup/chat.db

# Process individual messages instead of conversations
python -m apps.imessage_rag --no-concatenate-conversations

# Limit processing for testing
python -m apps.imessage_rag --max-items 100 --query "weekend"
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;üí° Click to expand: Example queries you can try&lt;/strong&gt;&lt;/summary&gt; 
 &lt;p&gt;Once your iMessage conversations are indexed, you can search with queries like:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;"What did we discuss about vacation plans?"&lt;/li&gt; 
  &lt;li&gt;"Find messages about restaurant recommendations"&lt;/li&gt; 
  &lt;li&gt;"Show me conversations with John about the project"&lt;/li&gt; 
  &lt;li&gt;"Search for shared links about technology"&lt;/li&gt; 
  &lt;li&gt;"Find group chat discussions about weekend events"&lt;/li&gt; 
  &lt;li&gt;"What did mom say about the family gathering?"&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h3&gt;üöÄ Claude Code Integration: Transform Your Development Workflow!&lt;/h3&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;NEW!! AST‚ÄëAware Code Chunking&lt;/strong&gt;&lt;/summary&gt; 
 &lt;p&gt;LEANN features intelligent code chunking that preserves semantic boundaries (functions, classes, methods) for Python, Java, C#, and TypeScript, improving code understanding compared to text-based chunking.&lt;/p&gt; 
 &lt;p&gt;üìñ Read the &lt;a href="https://raw.githubusercontent.com/yichuan-w/LEANN/main/docs/ast_chunking_guide.md"&gt;AST Chunking Guide ‚Üí&lt;/a&gt;&lt;/p&gt; 
&lt;/details&gt; 
&lt;p&gt;&lt;strong&gt;The future of code assistance is here.&lt;/strong&gt; Transform your development workflow with LEANN's native MCP integration for Claude Code. Index your entire codebase and get intelligent code assistance directly in your IDE.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Key features:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;üîç &lt;strong&gt;Semantic code search&lt;/strong&gt; across your entire project, fully local index and lightweight&lt;/li&gt; 
 &lt;li&gt;üß† &lt;strong&gt;AST-aware chunking&lt;/strong&gt; preserves code structure (functions, classes)&lt;/li&gt; 
 &lt;li&gt;üìö &lt;strong&gt;Context-aware assistance&lt;/strong&gt; for debugging and development&lt;/li&gt; 
 &lt;li&gt;üöÄ &lt;strong&gt;Zero-config setup&lt;/strong&gt; with automatic language detection&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Install LEANN globally for MCP integration
uv tool install leann-core --with leann
claude mcp add --scope user leann-server -- leann_mcp
# Setup is automatic - just start using Claude Code!
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Try our fully agentic pipeline with auto query rewriting, semantic search planning, and more:&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/yichuan-w/LEANN/main/assets/mcp_leann.png" alt="LEANN MCP Integration" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;üî• Ready to supercharge your coding?&lt;/strong&gt; &lt;a href="https://raw.githubusercontent.com/yichuan-w/LEANN/main/packages/leann-mcp/README.md"&gt;Complete Setup Guide ‚Üí&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üñ•Ô∏è Command Line Interface&lt;/h2&gt; 
&lt;p&gt;LEANN includes a powerful CLI for document processing and search. Perfect for quick document indexing and interactive chat.&lt;/p&gt; 
&lt;h3&gt;Installation&lt;/h3&gt; 
&lt;p&gt;If you followed the Quick Start, &lt;code&gt;leann&lt;/code&gt; is already installed in your virtual environment:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;source .venv/bin/activate
leann --help
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;To make it globally available:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Install the LEANN CLI globally using uv tool
uv tool install leann-core --with leann


# Now you can use leann from anywhere without activating venv
leann --help
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: Global installation is required for Claude Code integration. The &lt;code&gt;leann_mcp&lt;/code&gt; server depends on the globally available &lt;code&gt;leann&lt;/code&gt; command.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Usage Examples&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# build from a specific directory, and my_docs is the index name(Here you can also build from multiple dict or multiple files)
leann build my-docs --docs ./your_documents

# Search your documents
leann search my-docs "machine learning concepts"

# Interactive chat with your documents
leann ask my-docs --interactive

# Ask a single question (non-interactive)
leann ask my-docs "Where are prompts configured?"

# List all your indexes
leann list

# Remove an index
leann remove my-docs
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Key CLI features:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Auto-detects document formats (PDF, TXT, MD, DOCX, PPTX + code files)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üß† AST-aware chunking&lt;/strong&gt; for Python, Java, C#, TypeScript files&lt;/li&gt; 
 &lt;li&gt;Smart text chunking with overlap for all other content&lt;/li&gt; 
 &lt;li&gt;Multiple LLM providers (Ollama, OpenAI, HuggingFace)&lt;/li&gt; 
 &lt;li&gt;Organized index storage in &lt;code&gt;.leann/indexes/&lt;/code&gt; (project-local)&lt;/li&gt; 
 &lt;li&gt;Support for advanced search parameters&lt;/li&gt; 
&lt;/ul&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;üìã Click to expand: Complete CLI Reference&lt;/strong&gt;&lt;/summary&gt; 
 &lt;p&gt;You can use &lt;code&gt;leann --help&lt;/code&gt;, or &lt;code&gt;leann build --help&lt;/code&gt;, &lt;code&gt;leann search --help&lt;/code&gt;, &lt;code&gt;leann ask --help&lt;/code&gt;, &lt;code&gt;leann list --help&lt;/code&gt;, &lt;code&gt;leann remove --help&lt;/code&gt; to get the complete CLI reference.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Build Command:&lt;/strong&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;leann build INDEX_NAME --docs DIRECTORY|FILE [DIRECTORY|FILE ...] [OPTIONS]

Options:
  --backend {hnsw,diskann}     Backend to use (default: hnsw)
  --embedding-model MODEL      Embedding model (default: facebook/contriever)
  --graph-degree N             Graph degree (default: 32)
  --complexity N               Build complexity (default: 64)
  --force                      Force rebuild existing index
  --compact / --no-compact     Use compact storage (default: true). Must be `no-compact` for `no-recompute` build.
  --recompute / --no-recompute Enable recomputation (default: true)
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;Search Command:&lt;/strong&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;leann search INDEX_NAME QUERY [OPTIONS]

Options:
  --top-k N                     Number of results (default: 5)
  --complexity N                Search complexity (default: 64)
  --recompute / --no-recompute  Enable/disable embedding recomputation (default: enabled). Should not do a `no-recompute` search in a `recompute` build.
  --pruning-strategy {global,local,proportional}
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;Ask Command:&lt;/strong&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;leann ask INDEX_NAME [OPTIONS]

Options:
  --llm {ollama,openai,hf}    LLM provider (default: ollama)
  --model MODEL               Model name (default: qwen3:8b)
  --interactive              Interactive chat mode
  --top-k N                  Retrieval count (default: 20)
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;List Command:&lt;/strong&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;leann list

# Lists all indexes across all projects with status indicators:
# ‚úÖ - Index is complete and ready to use
# ‚ùå - Index is incomplete or corrupted
# üìÅ - CLI-created index (in .leann/indexes/)
# üìÑ - App-created index (*.leann.meta.json files)
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;Remove Command:&lt;/strong&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;leann remove INDEX_NAME [OPTIONS]

Options:
  --force, -f    Force removal without confirmation

# Smart removal: automatically finds and safely removes indexes
# - Shows all matching indexes across projects
# - Requires confirmation for cross-project removal
# - Interactive selection when multiple matches found
# - Supports both CLI and app-created indexes
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h2&gt;üöÄ Advanced Features&lt;/h2&gt; 
&lt;h3&gt;üéØ Metadata Filtering&lt;/h3&gt; 
&lt;p&gt;LEANN supports a simple metadata filtering system to enable sophisticated use cases like document filtering by date/type, code search by file extension, and content management based on custom criteria.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# Add metadata during indexing
builder.add_text(
    "def authenticate_user(token): ...",
    metadata={"file_extension": ".py", "lines_of_code": 25}
)

# Search with filters
results = searcher.search(
    query="authentication function",
    metadata_filters={
        "file_extension": {"==": ".py"},
        "lines_of_code": {"&amp;lt;": 100}
    }
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Supported operators&lt;/strong&gt;: &lt;code&gt;==&lt;/code&gt;, &lt;code&gt;!=&lt;/code&gt;, &lt;code&gt;&amp;lt;&lt;/code&gt;, &lt;code&gt;&amp;lt;=&lt;/code&gt;, &lt;code&gt;&amp;gt;&lt;/code&gt;, &lt;code&gt;&amp;gt;=&lt;/code&gt;, &lt;code&gt;in&lt;/code&gt;, &lt;code&gt;not_in&lt;/code&gt;, &lt;code&gt;contains&lt;/code&gt;, &lt;code&gt;starts_with&lt;/code&gt;, &lt;code&gt;ends_with&lt;/code&gt;, &lt;code&gt;is_true&lt;/code&gt;, &lt;code&gt;is_false&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;üìñ &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/yichuan-w/LEANN/main/docs/metadata_filtering.md"&gt;Complete Metadata filtering guide ‚Üí&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;h3&gt;üîç Grep Search&lt;/h3&gt; 
&lt;p&gt;For exact text matching instead of semantic search, use the &lt;code&gt;use_grep&lt;/code&gt; parameter:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# Exact text search
results = searcher.search("banana‚Äëcrocodile", use_grep=True, top_k=1)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Use cases&lt;/strong&gt;: Finding specific code patterns, error messages, function names, or exact phrases where semantic similarity isn't needed.&lt;/p&gt; 
&lt;p&gt;üìñ &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/yichuan-w/LEANN/main/docs/grep_search.md"&gt;Complete grep search guide ‚Üí&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;üèóÔ∏è Architecture &amp;amp; How It Works&lt;/h2&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/yichuan-w/LEANN/main/assets/arch.png" alt="LEANN Architecture" width="800" /&gt; &lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;The magic:&lt;/strong&gt; Most vector DBs store every single embedding (expensive). LEANN stores a pruned graph structure (cheap) and recomputes embeddings only when needed (fast).&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Core techniques:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Graph-based selective recomputation:&lt;/strong&gt; Only compute embeddings for nodes in the search path&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;High-degree preserving pruning:&lt;/strong&gt; Keep important "hub" nodes while removing redundant connections&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Dynamic batching:&lt;/strong&gt; Efficiently batch embedding computations for GPU utilization&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Two-level search:&lt;/strong&gt; Smart graph traversal that prioritizes promising nodes&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Backends:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;HNSW&lt;/strong&gt; (default): Ideal for most datasets with maximum storage savings through full recomputation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;DiskANN&lt;/strong&gt;: Advanced option with superior search performance, using PQ-based graph traversal with real-time reranking for the best speed-accuracy trade-off&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Benchmarks&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/yichuan-w/LEANN/main/benchmarks/diskann_vs_hnsw_speed_comparison.py"&gt;DiskANN vs HNSW Performance Comparison ‚Üí&lt;/a&gt;&lt;/strong&gt; - Compare search performance between both backends&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/yichuan-w/LEANN/main/benchmarks/compare_faiss_vs_leann.py"&gt;Simple Example: Compare LEANN vs FAISS ‚Üí&lt;/a&gt;&lt;/strong&gt; - See storage savings in action&lt;/p&gt; 
&lt;h3&gt;üìä Storage Comparison&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;System&lt;/th&gt; 
   &lt;th&gt;DPR (2.1M)&lt;/th&gt; 
   &lt;th&gt;Wiki (60M)&lt;/th&gt; 
   &lt;th&gt;Chat (400K)&lt;/th&gt; 
   &lt;th&gt;Email (780K)&lt;/th&gt; 
   &lt;th&gt;Browser (38K)&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Traditional vector database (e.g., FAISS)&lt;/td&gt; 
   &lt;td&gt;3.8 GB&lt;/td&gt; 
   &lt;td&gt;201 GB&lt;/td&gt; 
   &lt;td&gt;1.8 GB&lt;/td&gt; 
   &lt;td&gt;2.4 GB&lt;/td&gt; 
   &lt;td&gt;130 MB&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;LEANN&lt;/td&gt; 
   &lt;td&gt;324 MB&lt;/td&gt; 
   &lt;td&gt;6 GB&lt;/td&gt; 
   &lt;td&gt;64 MB&lt;/td&gt; 
   &lt;td&gt;79 MB&lt;/td&gt; 
   &lt;td&gt;6.4 MB&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Savings&lt;/td&gt; 
   &lt;td&gt;91%&lt;/td&gt; 
   &lt;td&gt;97%&lt;/td&gt; 
   &lt;td&gt;97%&lt;/td&gt; 
   &lt;td&gt;97%&lt;/td&gt; 
   &lt;td&gt;95%&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Reproduce Our Results&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uv run benchmarks/run_evaluation.py    # Will auto-download evaluation data and run benchmarks
uv run benchmarks/run_evaluation.py benchmarks/data/indices/rpj_wiki/rpj_wiki --num-queries 2000    # After downloading data, you can run the benchmark with our biggest index
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The evaluation script downloads data automatically on first run. The last three results were tested with partial personal data, and you can reproduce them with your own data!&lt;/p&gt; 
&lt;h2&gt;üî¨ Paper&lt;/h2&gt; 
&lt;p&gt;If you find Leann useful, please cite:&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://arxiv.org/abs/2506.08276"&gt;LEANN: A Low-Storage Vector Index&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bibtex"&gt;@misc{wang2025leannlowstoragevectorindex,
      title={LEANN: A Low-Storage Vector Index},
      author={Yichuan Wang and Shu Liu and Zhifei Li and Yongji Wu and Ziming Mao and Yilong Zhao and Xiao Yan and Zhiying Xu and Yang Zhou and Ion Stoica and Sewon Min and Matei Zaharia and Joseph E. Gonzalez},
      year={2025},
      eprint={2506.08276},
      archivePrefix={arXiv},
      primaryClass={cs.DB},
      url={https://arxiv.org/abs/2506.08276},
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;‚ú® &lt;a href="https://raw.githubusercontent.com/yichuan-w/LEANN/main/docs/features.md"&gt;Detailed Features ‚Üí&lt;/a&gt;&lt;/h2&gt; 
&lt;h2&gt;ü§ù &lt;a href="https://raw.githubusercontent.com/yichuan-w/LEANN/main/docs/CONTRIBUTING.md"&gt;CONTRIBUTING ‚Üí&lt;/a&gt;&lt;/h2&gt; 
&lt;h2&gt;‚ùì &lt;a href="https://raw.githubusercontent.com/yichuan-w/LEANN/main/docs/faq.md"&gt;FAQ ‚Üí&lt;/a&gt;&lt;/h2&gt; 
&lt;h2&gt;üìà &lt;a href="https://raw.githubusercontent.com/yichuan-w/LEANN/main/docs/roadmap.md"&gt;Roadmap ‚Üí&lt;/a&gt;&lt;/h2&gt; 
&lt;h2&gt;üìÑ License&lt;/h2&gt; 
&lt;p&gt;MIT License - see &lt;a href="https://raw.githubusercontent.com/yichuan-w/LEANN/main/LICENSE"&gt;LICENSE&lt;/a&gt; for details.&lt;/p&gt; 
&lt;h2&gt;üôè Acknowledgments&lt;/h2&gt; 
&lt;p&gt;Core Contributors: &lt;a href="https://yichuan-w.github.io/"&gt;Yichuan Wang&lt;/a&gt; &amp;amp; &lt;a href="https://github.com/andylizf"&gt;Zhifei Li&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Active Contributors: &lt;a href="https://github.com/gabriel-dehan"&gt;Gabriel Dehan&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;We welcome more contributors! Feel free to open issues or submit PRs.&lt;/p&gt; 
&lt;p&gt;This work is done at &lt;a href="https://sky.cs.berkeley.edu/"&gt;&lt;strong&gt;Berkeley Sky Computing Lab&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Star History&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://www.star-history.com/#yichuan-w/LEANN&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=yichuan-w/LEANN&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p align="center"&gt; &lt;strong&gt;‚≠ê Star us on GitHub if Leann is useful for your research or applications!&lt;/strong&gt; &lt;/p&gt; 
&lt;p align="center"&gt; Made with ‚ù§Ô∏è by the Leann team &lt;/p&gt;</description>
    </item>
    
    <item>
      <title>EbookFoundation/free-programming-books</title>
      <link>https://github.com/EbookFoundation/free-programming-books</link>
      <description>&lt;p&gt;üìö Freely available programming books&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;List of Free Learning Resources In Many Languages&lt;/h1&gt; 
&lt;div align="center" markdown="1"&gt; 
 &lt;p&gt;&lt;a href="https://github.com/sindresorhus/awesome"&gt;&lt;img src="https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg?sanitize=true" alt="Awesome" /&gt;&lt;/a&gt;&amp;nbsp; &lt;a href="https://creativecommons.org/licenses/by/4.0/"&gt;&lt;img src="https://img.shields.io/badge/License-CC%20BY%204.0-lightgrey.svg?sanitize=true" alt="License: CC BY 4.0" /&gt;&lt;/a&gt;&amp;nbsp; &lt;a href="https://github.com/EbookFoundation/free-programming-books/pulls?q=is%3Apr+is%3Amerged+created%3A2025-10-01..2025-10-31"&gt;&lt;img src="https://img.shields.io/github/hacktoberfest/2025/EbookFoundation/free-programming-books?label=Hacktoberfest+2025" alt="Hacktoberfest 2025 stats" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;Search the list at &lt;a href="https://ebookfoundation.github.io/free-programming-books-search/"&gt;https://ebookfoundation.github.io/free-programming-books-search/&lt;/a&gt; &lt;a href="https://ebookfoundation.github.io/free-programming-books-search/"&gt;&lt;img src="https://img.shields.io/website?style=flat&amp;amp;logo=www&amp;amp;logoColor=whitesmoke&amp;amp;label=Dynamic%20search%20site&amp;amp;down_color=red&amp;amp;down_message=down&amp;amp;up_color=green&amp;amp;up_message=up&amp;amp;url=https%3A%2F%2Febookfoundation.github.io%2Ffree-programming-books-search%2F" alt="https://ebookfoundation.github.io/free-programming-books-search/" /&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;This page is available as an easy-to-read website. Access it by clicking on &lt;a href="https://ebookfoundation.github.io/free-programming-books/"&gt;&lt;img src="https://img.shields.io/website?style=flat&amp;amp;logo=www&amp;amp;logoColor=whitesmoke&amp;amp;label=Static%20site&amp;amp;down_color=red&amp;amp;down_message=down&amp;amp;up_color=green&amp;amp;up_message=up&amp;amp;url=https%3A%2F%2Febookfoundation.github.io%2Ffree-programming-books%2F" alt="https://ebookfoundation.github.io/free-programming-books/" /&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;form action="https://ebookfoundation.github.io/free-programming-books-search"&gt; 
  &lt;input type="text" id="fpbSearch" name="search" required placeholder="Search Book or Author" /&gt; 
  &lt;label for="submit"&gt; &lt;/label&gt; 
  &lt;input type="submit" id="submit" name="submit" value="Search" /&gt; 
 &lt;/form&gt; 
&lt;/div&gt; 
&lt;h2&gt;Intro&lt;/h2&gt; 
&lt;p&gt;This list was originally a clone of &lt;a href="https://web.archive.org/web/20140606191453/http://stackoverflow.com/questions/194812/list-of-freely-available-programming-books/392926"&gt;StackOverflow - List of Freely Available Programming Books&lt;/a&gt; with contributions from Karan Bhangui and George Stocker.&lt;/p&gt; 
&lt;p&gt;The list was moved to GitHub by Victor Felder for collaborative updating and maintenance. It has grown to become one of &lt;a href="https://octoverse.github.com/"&gt;GitHub's most popular repositories&lt;/a&gt;.&lt;/p&gt; 
&lt;div align="center" markdown="1"&gt; 
 &lt;p&gt;&lt;a href="https://github.com/EbookFoundation/free-programming-books/network"&gt;&lt;img src="https://img.shields.io/github/forks/EbookFoundation/free-programming-books?style=flat&amp;amp;logo=github&amp;amp;logoColor=whitesmoke&amp;amp;label=Forks" alt="GitHub repo forks" /&gt;&lt;/a&gt;&amp;nbsp; &lt;a href="https://github.com/EbookFoundation/free-programming-books/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/EbookFoundation/free-programming-books?style=flat&amp;amp;logo=github&amp;amp;logoColor=whitesmoke&amp;amp;label=Stars" alt="GitHub repo stars" /&gt;&lt;/a&gt;&amp;nbsp; &lt;a href="https://github.com/EbookFoundation/free-programming-books/graphs/contributors"&gt;&lt;img src="https://img.shields.io/github/contributors-anon/EbookFoundation/free-programming-books?style=flat&amp;amp;logo=github&amp;amp;logoColor=whitesmoke&amp;amp;label=Contributors" alt="GitHub repo contributors" /&gt;&lt;/a&gt;&lt;br /&gt; &lt;a href="https://github.com/sponsors/EbookFoundation"&gt;&lt;img src="https://img.shields.io/github/sponsors/EbookFoundation?style=flat&amp;amp;logo=github&amp;amp;logoColor=whitesmoke&amp;amp;label=Sponsors" alt="GitHub org sponsors" /&gt;&lt;/a&gt;&amp;nbsp; &lt;a href="https://github.com/EbookFoundation/free-programming-books/watchers"&gt;&lt;img src="https://img.shields.io/github/watchers/EbookFoundation/free-programming-books?style=flat&amp;amp;logo=github&amp;amp;logoColor=whitesmoke&amp;amp;label=Watchers" alt="GitHub repo watchers" /&gt;&lt;/a&gt;&amp;nbsp; &lt;a href="https://github.com/EbookFoundation/free-programming-books/archive/refs/heads/main.zip"&gt;&lt;img src="https://img.shields.io/github/repo-size/EbookFoundation/free-programming-books?style=flat&amp;amp;logo=github&amp;amp;logoColor=whitesmoke&amp;amp;label=Repo%20Size" alt="GitHub repo size" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;The &lt;a href="https://ebookfoundation.org"&gt;Free Ebook Foundation&lt;/a&gt; now administers the repo, a not-for-profit organization devoted to promoting the creation, distribution, archiving, and sustainability of free ebooks. &lt;a href="https://ebookfoundation.org/contributions.html"&gt;Donations&lt;/a&gt; to the Free Ebook Foundation are tax-deductible in the US.&lt;/p&gt; 
&lt;h2&gt;How To Contribute&lt;/h2&gt; 
&lt;p&gt;Please read &lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/docs/CONTRIBUTING.md"&gt;CONTRIBUTING&lt;/a&gt;. If you're new to GitHub, &lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/docs/HOWTO.md"&gt;welcome&lt;/a&gt;! Remember to abide by our adapted from &lt;img src="https://img.shields.io/badge/Contributor%20Covenant-1.3-4baaaa.svg?sanitize=true" alt="Contributor Covenant 1.3" /&gt; &lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/docs/CODE_OF_CONDUCT.md"&gt;Code of Conduct&lt;/a&gt; too (&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/#translations"&gt;translations&lt;/a&gt; also available).&lt;/p&gt; 
&lt;p&gt;Click on these badges to see how you might be able to help:&lt;/p&gt; 
&lt;div align="center" markdown="1"&gt; 
 &lt;p&gt;&lt;a href="https://github.com/EbookFoundation/free-programming-books/issues"&gt;&lt;img src="https://img.shields.io/github/issues/EbookFoundation/free-programming-books?style=flat&amp;amp;logo=github&amp;amp;logoColor=red&amp;amp;label=Issues" alt="GitHub repo Issues" /&gt;&lt;/a&gt;&amp;nbsp; &lt;a href="https://github.com/EbookFoundation/free-programming-books/issues?q=is%3Aopen+is%3Aissue+label%3A%22good+first+issue%22"&gt;&lt;img src="https://img.shields.io/github/issues/EbookFoundation/free-programming-books/good%20first%20issue?style=flat&amp;amp;logo=github&amp;amp;logoColor=green&amp;amp;label=Good%20First%20issues" alt="GitHub repo Good Issues for newbies" /&gt;&lt;/a&gt;&amp;nbsp; &lt;a href="https://github.com/EbookFoundation/free-programming-books/issues?q=is%3Aopen+is%3Aissue+label%3A%22help+wanted%22"&gt;&lt;img src="https://img.shields.io/github/issues/EbookFoundation/free-programming-books/help%20wanted?style=flat&amp;amp;logo=github&amp;amp;logoColor=b545d1&amp;amp;label=%22Help%20Wanted%22%20issues" alt="GitHub Help Wanted issues" /&gt;&lt;/a&gt;&lt;br /&gt; &lt;a href="https://github.com/EbookFoundation/free-programming-books/pulls"&gt;&lt;img src="https://img.shields.io/github/issues-pr/EbookFoundation/free-programming-books?style=flat&amp;amp;logo=github&amp;amp;logoColor=orange&amp;amp;label=PRs" alt="GitHub repo PRs" /&gt;&lt;/a&gt;&amp;nbsp; &lt;a href="https://github.com/EbookFoundation/free-programming-books/pulls?q=is%3Apr+is%3Amerged"&gt;&lt;img src="https://img.shields.io/github/issues-search/EbookFoundation/free-programming-books?style=flat&amp;amp;logo=github&amp;amp;logoColor=green&amp;amp;label=Merged%20PRs&amp;amp;query=is%3Amerged" alt="GitHub repo Merged PRs" /&gt;&lt;/a&gt;&amp;nbsp; &lt;a href="https://github.com/EbookFoundation/free-programming-books/pulls?q=is%3Aopen+is%3Aissue+label%3A%22help+wanted%22"&gt;&lt;img src="https://img.shields.io/github/issues-pr/EbookFoundation/free-programming-books/help%20wanted?style=flat&amp;amp;logo=github&amp;amp;logoColor=b545d1&amp;amp;label=%22Help%20Wanted%22%20PRs" alt="GitHub Help Wanted PRs" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;How To Share&lt;/h2&gt; 
&lt;div align="left" markdown="1"&gt; 
 &lt;a href="https://www.facebook.com/share.php?u=https%3A%2F%2Fgithub.com%2FEbookFoundation%2Ffree-programming-books&amp;amp;p%5Bimages%5D%5B0%5D=&amp;amp;p%5Btitle%5D=Free%20Programming%20Books&amp;amp;p%5Bsummary%5D="&gt;Share on Facebook&lt;/a&gt;
 &lt;br /&gt; 
 &lt;a href="http://www.linkedin.com/shareArticle?mini=true&amp;amp;url=https://github.com/EbookFoundation/free-programming-books&amp;amp;title=Free%20Programming%20Books&amp;amp;summary=&amp;amp;source="&gt;Share on LinkedIn&lt;/a&gt;
 &lt;br /&gt; 
 &lt;a href="https://toot.kytta.dev/?text=https://github.com/EbookFoundation/free-programming-books"&gt;Share on Mastodon/Fediverse&lt;/a&gt;
 &lt;br /&gt; 
 &lt;a href="https://t.me/share/url?url=https://github.com/EbookFoundation/free-programming-books"&gt;Share on Telegram&lt;/a&gt;
 &lt;br /&gt; 
 &lt;a href="https://twitter.com/intent/tweet?text=https://github.com/EbookFoundation/free-programming-books%0AFree%20Programming%20Books"&gt;Share on ùïè (Twitter)&lt;/a&gt;
 &lt;br /&gt; 
&lt;/div&gt; 
&lt;h2&gt;Resources&lt;/h2&gt; 
&lt;p&gt;This project lists books and other resources grouped by genres:&lt;/p&gt; 
&lt;h3&gt;Books&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-langs.md"&gt;English, By Programming Language&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-subjects.md"&gt;English, By Subject&lt;/a&gt;&lt;/p&gt; 
&lt;h4&gt;Other Languages&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-ar.md"&gt;Arabic / al arabiya / ÿßŸÑÿπÿ±ÿ®Ÿäÿ©&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-hy.md"&gt;Armenian / ’Ä’°’µ’•÷Ä’•’∂&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-az.md"&gt;Azerbaijani / –ê–∑”ô—Ä–±–∞—ò“π–∞–Ω –¥–∏–ª–∏ / ÿ¢ÿ∞ÿ±ÿ®ÿßŸäÿ¨ÿßŸÜÿ¨ÿß ÿØŸäŸÑŸä&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-bn.md"&gt;Bengali / ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-bg.md"&gt;Bulgarian / –±—ä–ª–≥–∞—Ä—Å–∫–∏&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-my.md"&gt;Burmese / ·Äô·Äº·Äî·Ä∫·Äô·Ä¨·Äò·Ä¨·Äû·Ä¨&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-zh.md"&gt;Chinese / ‰∏≠Êñá&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-cs.md"&gt;Czech / ƒçe≈°tina / ƒçesk√Ω jazyk&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-ca.md"&gt;Catalan / catalan/ catal√†&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-da.md"&gt;Danish / dansk&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-nl.md"&gt;Dutch / Nederlands&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-et.md"&gt;Estonian / eesti keel&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-fi.md"&gt;Finnish / suomi / suomen kieli&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-fr.md"&gt;French / fran√ßais&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-de.md"&gt;German / Deutsch&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-el.md"&gt;Greek / ŒµŒªŒªŒ∑ŒΩŒπŒ∫Œ¨&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-he.md"&gt;Hebrew / ◊¢◊ë◊®◊ô◊™&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-hi.md"&gt;Hindi / ‡§π‡§ø‡§®‡•ç‡§¶‡•Ä&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-hu.md"&gt;Hungarian / magyar / magyar nyelv&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-id.md"&gt;Indonesian / Bahasa Indonesia&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-it.md"&gt;Italian / italiano&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-ja.md"&gt;Japanese / Êó•Êú¨Ë™û&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-ko.md"&gt;Korean / ÌïúÍµ≠Ïñ¥&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-lv.md"&gt;Latvian / Latvie≈°u&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-ml.md"&gt;Malayalam / ‡¥Æ‡¥≤‡¥Ø‡¥æ‡¥≥‡¥Ç&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-no.md"&gt;Norwegian / Norsk&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-fa_IR.md"&gt;Persian / Farsi (Iran) / ŸÅÿßÿ±ÿ≥Ÿâ&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-pl.md"&gt;Polish / polski / jƒôzyk polski / polszczyzna&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-pt_BR.md"&gt;Portuguese (Brazil)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-pt_PT.md"&gt;Portuguese (Portugal)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-ro.md"&gt;Romanian (Romania) / limba rom√¢nƒÉ / rom√¢n&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-ru.md"&gt;Russian / –†—É—Å—Å–∫–∏–π —è–∑—ã–∫&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-sr.md"&gt;Serbian / —Å—Ä–ø—Å–∫–∏ —ò–µ–∑–∏–∫ / srpski jezik&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-sk.md"&gt;Slovak / slovenƒçina&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-es.md"&gt;Spanish / espa√±ol / castellano&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-sv.md"&gt;Swedish / Svenska&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-ta.md"&gt;Tamil / ‡Æ§‡ÆÆ‡Æø‡Æ¥‡Øç&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-te.md"&gt;Telugu / ‡∞§‡±Ü‡∞≤‡±Å‡∞ó‡±Å&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-th.md"&gt;Thai / ‡πÑ‡∏ó‡∏¢&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-tr.md"&gt;Turkish / T√ºrk√ße&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-uk.md"&gt;Ukrainian / –£–∫—Ä–∞—ó–Ω—Å—å–∫–∞&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-vi.md"&gt;Vietnamese / Ti·∫øng Vi·ªát&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Cheat Sheets&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/more/free-programming-cheatsheets.md"&gt;All Languages&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Free Online Courses&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-ar.md"&gt;Arabic / al arabiya / ÿßŸÑÿπÿ±ÿ®Ÿäÿ©&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-bn.md"&gt;Bengali / ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-bg.md"&gt;Bulgarian / –±—ä–ª–≥–∞—Ä—Å–∫–∏&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-my.md"&gt;Burmese / ·Äô·Äº·Äî·Ä∫·Äô·Ä¨·Äò·Ä¨·Äû·Ä¨&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-zh.md"&gt;Chinese / ‰∏≠Êñá&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-en.md"&gt;English&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-fi.md"&gt;Finnish / suomi / suomen kieli&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-fr.md"&gt;French / fran√ßais&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-de.md"&gt;German / Deutsch&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-el.md"&gt;Greek / ŒµŒªŒªŒ∑ŒΩŒπŒ∫Œ¨&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-he.md"&gt;Hebrew / ◊¢◊ë◊®◊ô◊™&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-hi.md"&gt;Hindi / ‡§π‡§ø‡§Ç‡§¶‡•Ä&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-id.md"&gt;Indonesian / Bahasa Indonesia&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-it.md"&gt;Italian / italiano&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-ja.md"&gt;Japanese / Êó•Êú¨Ë™û&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-kn.md"&gt;Kannada/‡≤ï‡≤®‡≥ç‡≤®‡≤°&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-kk.md"&gt;Kazakh / “õ–∞–∑–∞“õ—à–∞&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-km.md"&gt;Khmer / ·ûó·û∂·ûü·û∂·ûÅ·üí·ûò·üÇ·ûö&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-ko.md"&gt;Korean / ÌïúÍµ≠Ïñ¥&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-ml.md"&gt;Malayalam / ‡¥Æ‡¥≤‡¥Ø‡¥æ‡¥≥‡¥Ç&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-mr.md"&gt;Marathi / ‡§Æ‡§∞‡§æ‡§†‡•Ä&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-ne.md"&gt;Nepali / ‡§®‡•á‡§™‡§æ‡§≤‡•Ä&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-no.md"&gt;Norwegian / Norsk&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-fa_IR.md"&gt;Persian / Farsi (Iran) / ŸÅÿßÿ±ÿ≥Ÿâ&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-pl.md"&gt;Polish / polski / jƒôzyk polski / polszczyzna&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-pt_BR.md"&gt;Portuguese (Brazil)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-pt_PT.md"&gt;Portuguese (Portugal)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-ru.md"&gt;Russian / –†—É—Å—Å–∫–∏–π —è–∑—ã–∫&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-si.md"&gt;Sinhala / ‡∑É‡∑í‡∂Ç‡∑Ñ‡∂Ω&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-es.md"&gt;Spanish / espa√±ol / castellano&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-sv.md"&gt;Swedish / svenska&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-ta.md"&gt;Tamil / ‡Æ§‡ÆÆ‡Æø‡Æ¥‡Øç&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-te.md"&gt;Telugu / ‡∞§‡±Ü‡∞≤‡±Å‡∞ó‡±Å&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-th.md"&gt;Thai / ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-tr.md"&gt;Turkish / T√ºrk√ße&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-uk.md"&gt;Ukrainian / –£–∫—Ä–∞—ó–Ω—Å—å–∫–∞&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-ur.md"&gt;Urdu / ÿßÿ±ÿØŸà&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-vi.md"&gt;Vietnamese / Ti·∫øng Vi·ªát&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Interactive Programming Resources&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/more/free-programming-interactive-tutorials-zh.md"&gt;Chinese / ‰∏≠Êñá&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/more/free-programming-interactive-tutorials-en.md"&gt;English&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/more/free-programming-interactive-tutorials-de.md"&gt;German / Deutsch&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/more/free-programming-interactive-tutorials-ja.md"&gt;Japanese / Êó•Êú¨Ë™û&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/more/free-programming-interactive-tutorials-ru.md"&gt;Russian / –†—É—Å—Å–∫–∏–π —è–∑—ã–∫&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Problem Sets and Competitive Programming&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/more/problem-sets-competitive-programming.md"&gt;Problem Sets&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Podcast - Screencast&lt;/h3&gt; 
&lt;p&gt;Free Podcasts and Screencasts:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-ar.md"&gt;Arabic / al Arabiya / ÿßŸÑÿπÿ±ÿ®Ÿäÿ©&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-my.md"&gt;Burmese / ·Äô·Äº·Äî·Ä∫·Äô·Ä¨·Äò·Ä¨·Äû·Ä¨&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-zh.md"&gt;Chinese / ‰∏≠Êñá&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-cs.md"&gt;Czech / ƒçe≈°tina / ƒçesk√Ω jazyk&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-nl.md"&gt;Dutch / Nederlands&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-en.md"&gt;English&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-fi.md"&gt;Finnish / Suomi&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-fr.md"&gt;French / fran√ßais&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-de.md"&gt;German / Deutsch&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-he.md"&gt;Hebrew / ◊¢◊ë◊®◊ô◊™&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-id.md"&gt;Indonesian / Bahasa Indonesia&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-fa_IR.md"&gt;Persian / Farsi (Iran) / ŸÅÿßÿ±ÿ≥Ÿâ&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-pl.md"&gt;Polish / polski / jƒôzyk polski / polszczyzna&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-pt_BR.md"&gt;Portuguese (Brazil)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-pt_PT.md"&gt;Portuguese (Portugal)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-ru.md"&gt;Russian / –†—É—Å—Å–∫–∏–π —è–∑—ã–∫&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-si.md"&gt;Sinhala / ‡∑É‡∑í‡∂Ç‡∑Ñ‡∂Ω&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-es.md"&gt;Spanish / espa√±ol / castellano&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-sv.md"&gt;Swedish / Svenska&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-tr.md"&gt;Turkish / T√ºrk√ße&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-uk.md"&gt;Ukrainian / –£–∫—Ä–∞—ó–Ω—Å—å–∫–∞&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Programming Playgrounds&lt;/h3&gt; 
&lt;p&gt;Write, compile, and run your code within a browser. Try it out!&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/more/free-programming-playgrounds-zh.md"&gt;Chinese / ‰∏≠Êñá&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/more/free-programming-playgrounds.md"&gt;English&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/more/free-programming-playgrounds-de.md"&gt;German / Deutsch&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Translations&lt;/h2&gt; 
&lt;p&gt;Volunteers have translated many of our Contributing, How-to, and Code of Conduct documents into languages covered by our lists.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;English 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/docs/CODE_OF_CONDUCT.md"&gt;Code of Conduct&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/docs/CONTRIBUTING.md"&gt;Contributing&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/docs/HOWTO.md"&gt;How-to&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;... &lt;em&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/docs/README.md#translations"&gt;More languages&lt;/a&gt;&lt;/em&gt; ...&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;You might notice that there are &lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/docs/README.md#translations"&gt;some missing translations here&lt;/a&gt; - perhaps you would like to help out by &lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/docs/CONTRIBUTING.md#help-out-by-contributing-a-translation"&gt;contributing a translation&lt;/a&gt;?&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Each file included in this repository is licensed under the &lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/LICENSE"&gt;CC BY License&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>hsliuping/TradingAgents-CN</title>
      <link>https://github.com/hsliuping/TradingAgents-CN</link>
      <description>&lt;p&gt;Âü∫‰∫éÂ§öÊô∫ËÉΩ‰ΩìLLMÁöÑ‰∏≠ÊñáÈáëËûç‰∫§ÊòìÊ°ÜÊû∂ - TradingAgents‰∏≠ÊñáÂ¢ûÂº∫Áâà&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;TradingAgents ‰∏≠ÊñáÂ¢ûÂº∫Áâà&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://opensource.org/licenses/Apache-2.0"&gt;&lt;img src="https://img.shields.io/badge/License-Apache%202.0-blue.svg?sanitize=true" alt="License" /&gt;&lt;/a&gt; &lt;a href="https://www.python.org/"&gt;&lt;img src="https://img.shields.io/badge/Python-3.10%2B-blue.svg?sanitize=true" alt="Python" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/hsliuping/TradingAgents-CN/main/VERSION"&gt;&lt;img src="https://img.shields.io/badge/Version-cn--0.1.15-green.svg?sanitize=true" alt="Version" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/hsliuping/TradingAgents-CN/main/docs/"&gt;&lt;img src="https://img.shields.io/badge/docs-%E4%B8%AD%E6%96%87%E6%96%87%E6%A1%A3-green.svg?sanitize=true" alt="Documentation" /&gt;&lt;/a&gt; &lt;a href="https://github.com/TauricResearch/TradingAgents"&gt;&lt;img src="https://img.shields.io/badge/%E5%9F%BA%E4%BA%8E-TauricResearch/TradingAgents-orange.svg?sanitize=true" alt="Original" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;üöÄ &lt;strong&gt;ÊúÄÊñ∞ÁâàÊú¨ cn-0.1.15&lt;/strong&gt;: ÂºÄÂèëËÄÖ‰ΩìÈ™å‰∏éLLMÁîüÊÄÅÁ≥ªÁªüÂ§ßÂçáÁ∫ßÔºÅÊñ∞Â¢ûÂçÉÂ∏ÜÂ§ßÊ®°ÂûãÊîØÊåÅ„ÄÅÂÆåÊï¥ÂºÄÂèëÂ∑•ÂÖ∑Èìæ„ÄÅÂ≠¶ÊúØÁ†îÁ©∂ËµÑÊñô„ÄÅ‰ºÅ‰∏öÁ∫ßÂ∑•‰ΩúÊµÅËßÑËåÉÔºÅ&lt;/p&gt; 
 &lt;p&gt;üéØ &lt;strong&gt;Ê†∏ÂøÉÂäüËÉΩ&lt;/strong&gt;: ÂéüÁîüOpenAIÊîØÊåÅ | Google AIÂÖ®Èù¢ÈõÜÊàê | Ëá™ÂÆö‰πâÁ´ØÁÇπÈÖçÁΩÆ | Êô∫ËÉΩÊ®°ÂûãÈÄâÊã© | Â§öLLMÊèê‰æõÂïÜÊîØÊåÅ | Ê®°ÂûãÈÄâÊã©ÊåÅ‰πÖÂåñ | DockerÂÆπÂô®ÂåñÈÉ®ÁΩ≤ | ‰∏ì‰∏öÊä•ÂëäÂØºÂá∫ | ÂÆåÊï¥AËÇ°ÊîØÊåÅ | ‰∏≠ÊñáÊú¨Âú∞Âåñ&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Âü∫‰∫éÂ§öÊô∫ËÉΩ‰ΩìÂ§ßËØ≠Ë®ÄÊ®°ÂûãÁöÑ&lt;strong&gt;‰∏≠ÊñáÈáëËûç‰∫§ÊòìÂÜ≥Á≠ñÊ°ÜÊû∂&lt;/strong&gt;„ÄÇ‰∏ì‰∏∫‰∏≠ÊñáÁî®Êà∑‰ºòÂåñÔºåÊèê‰æõÂÆåÊï¥ÁöÑAËÇ°/Ê∏ØËÇ°/ÁæéËÇ°ÂàÜÊûêËÉΩÂäõ„ÄÇ&lt;/p&gt; 
&lt;h2&gt;üôè Ëá¥Êï¨Ê∫êÈ°πÁõÆ&lt;/h2&gt; 
&lt;p&gt;ÊÑüË∞¢ &lt;a href="https://github.com/TauricResearch"&gt;Tauric Research&lt;/a&gt; Âõ¢ÈòüÂàõÈÄ†ÁöÑÈù©ÂëΩÊÄßÂ§öÊô∫ËÉΩ‰Ωì‰∫§ÊòìÊ°ÜÊû∂ &lt;a href="https://github.com/TauricResearch/TradingAgents"&gt;TradingAgents&lt;/a&gt;ÔºÅ&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;üéØ Êàë‰ª¨ÁöÑ‰ΩøÂëΩ&lt;/strong&gt;: ‰∏∫‰∏≠ÂõΩÁî®Êà∑Êèê‰æõÂÆåÊï¥ÁöÑ‰∏≠ÊñáÂåñ‰ΩìÈ™åÔºåÊîØÊåÅAËÇ°/Ê∏ØËÇ°Â∏ÇÂú∫ÔºåÈõÜÊàêÂõΩ‰∫ßÂ§ßÊ®°ÂûãÔºåÊé®Âä®AIÈáëËûçÊäÄÊúØÂú®‰∏≠ÊñáÁ§æÂå∫ÁöÑÊôÆÂèäÂ∫îÁî®„ÄÇ&lt;/p&gt; 
&lt;h2&gt;üÜï v0.1.15 ÈáçÂ§ßÊõ¥Êñ∞&lt;/h2&gt; 
&lt;h3&gt;ü§ñ LLMÁîüÊÄÅÁ≥ªÁªüÂ§ßÂçáÁ∫ß&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;ÂçÉÂ∏ÜÂ§ßÊ®°ÂûãÊîØÊåÅ&lt;/strong&gt;: Êñ∞Â¢ûÁôæÂ∫¶ÂçÉÂ∏Ü(ERNIE)Â§ßÊ®°ÂûãÂÆåÊï¥ÈõÜÊàê&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;LLMÈÄÇÈÖçÂô®ÈáçÊûÑ&lt;/strong&gt;: Áªü‰∏ÄÁöÑOpenAIÂÖºÂÆπÈÄÇÈÖçÂô®Êû∂ÊûÑ&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Â§öÂéÇÂïÜÊîØÊåÅ&lt;/strong&gt;: ÊîØÊåÅÊõ¥Â§öÂõΩ‰∫ßÂ§ßÊ®°ÂûãÊèê‰æõÂïÜ&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ÈõÜÊàêÊåáÂçó&lt;/strong&gt;: ÂÆåÊï¥ÁöÑLLMÈõÜÊàêÂºÄÂèëÊñáÊ°£ÂíåÊµãËØïÂ∑•ÂÖ∑&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üìö Â≠¶ÊúØÁ†îÁ©∂ÊîØÊåÅ&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;TradingAgentsËÆ∫Êñá&lt;/strong&gt;: ÂÆåÊï¥ÁöÑ‰∏≠ÊñáÁøªËØëÁâàÊú¨ÂíåÊ∑±Â∫¶Ëß£ËØª&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ÊäÄÊúØÂçöÂÆ¢&lt;/strong&gt;: ËØ¶ÁªÜÁöÑÊäÄÊúØÂàÜÊûêÂíåÂÆûÁé∞ÂéüÁêÜËß£ËØª&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Â≠¶ÊúØËµÑÊñô&lt;/strong&gt;: PDFËÆ∫ÊñáÂíåÁõ∏ÂÖ≥Á†îÁ©∂ËµÑÊñô&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ÂºïÁî®ÊîØÊåÅ&lt;/strong&gt;: Ê†áÂáÜÁöÑÂ≠¶ÊúØÂºïÁî®Ê†ºÂºèÂíåÂèÇËÄÉÊñáÁåÆ&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üõ†Ô∏è ÂºÄÂèëËÄÖ‰ΩìÈ™åÂçáÁ∫ß&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;ÂºÄÂèëÂ∑•‰ΩúÊµÅ&lt;/strong&gt;: Ê†áÂáÜÂåñÁöÑÂºÄÂèëÊµÅÁ®ãÂíåÂàÜÊîØÁÆ°ÁêÜËßÑËåÉ&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ÂÆâË£ÖÈ™åËØÅ&lt;/strong&gt;: ÂÆåÊï¥ÁöÑÂÆâË£ÖÊµãËØïÂíåÈ™åËØÅËÑöÊú¨&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ÊñáÊ°£ÈáçÊûÑ&lt;/strong&gt;: ÁªìÊûÑÂåñÁöÑÊñáÊ°£Á≥ªÁªüÂíåÂø´ÈÄüÂºÄÂßãÊåáÂçó&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;PRÊ®°Êùø&lt;/strong&gt;: Ê†áÂáÜÂåñÁöÑPull RequestÊ®°ÊùøÂíå‰ª£Á†ÅÂÆ°Êü•ÊµÅÁ®ã&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üîß ‰ºÅ‰∏öÁ∫ßÂ∑•ÂÖ∑Èìæ&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;ÂàÜÊîØ‰øùÊä§&lt;/strong&gt;: GitHubÂàÜÊîØ‰øùÊä§Á≠ñÁï•ÂíåÂÆâÂÖ®ËßÑÂàô&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Á¥ßÊÄ•Á®ãÂ∫è&lt;/strong&gt;: ÂÆåÊï¥ÁöÑÁ¥ßÊÄ•Â§ÑÁêÜÂíåÊïÖÈöúÊÅ¢Â§çÁ®ãÂ∫è&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ÊµãËØïÊ°ÜÊû∂&lt;/strong&gt;: Â¢ûÂº∫ÁöÑÊµãËØïË¶ÜÁõñÂíåÈ™åËØÅÂ∑•ÂÖ∑&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ÈÉ®ÁΩ≤ÊåáÂçó&lt;/strong&gt;: ‰ºÅ‰∏öÁ∫ßÈÉ®ÁΩ≤ÂíåÈÖçÁΩÆÁÆ°ÁêÜ&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üìã v0.1.14 ÂäüËÉΩÂõûÈ°æ&lt;/h2&gt; 
&lt;h3&gt;üë• Áî®Êà∑ÊùÉÈôêÁÆ°ÁêÜÁ≥ªÁªü&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;ÂÆåÊï¥Áî®Êà∑ÁÆ°ÁêÜ&lt;/strong&gt;: Êñ∞Â¢ûÁî®Êà∑Ê≥®ÂÜå„ÄÅÁôªÂΩï„ÄÅÊùÉÈôêÊéßÂà∂ÂäüËÉΩ&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ËßíËâ≤ÊùÉÈôê&lt;/strong&gt;: ÊîØÊåÅÂ§öÁ∫ßÁî®Êà∑ËßíËâ≤ÂíåÊùÉÈôêÁÆ°ÁêÜ&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;‰ºöËØùÁÆ°ÁêÜ&lt;/strong&gt;: ÂÆâÂÖ®ÁöÑÁî®Êà∑‰ºöËØùÂíåÁä∂ÊÄÅÁÆ°ÁêÜ&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Áî®Êà∑Ê¥ªÂä®Êó•Âøó&lt;/strong&gt;: ÂÆåÊï¥ÁöÑÁî®Êà∑Êìç‰ΩúËÆ∞ÂΩïÂíåÂÆ°ËÆ°ÂäüËÉΩ&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üîê WebÁî®Êà∑ËÆ§ËØÅÁ≥ªÁªü&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;ÁôªÂΩïÁªÑ‰ª∂&lt;/strong&gt;: Áé∞‰ª£ÂåñÁöÑÁî®Êà∑ÁôªÂΩïÁïåÈù¢&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ËÆ§ËØÅÁÆ°ÁêÜÂô®&lt;/strong&gt;: Áªü‰∏ÄÁöÑÁî®Êà∑ËÆ§ËØÅÂíåÊéàÊùÉÁÆ°ÁêÜ&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ÂÆâÂÖ®Â¢ûÂº∫&lt;/strong&gt;: ÂØÜÁ†ÅÂä†ÂØÜ„ÄÅ‰ºöËØùÂÆâÂÖ®Á≠âÂÆâÂÖ®Êú∫Âà∂&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Áî®Êà∑‰ª™Ë°®Êùø&lt;/strong&gt;: ‰∏™ÊÄßÂåñÁöÑÁî®Êà∑Ê¥ªÂä®‰ª™Ë°®Êùø&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üóÑÔ∏è Êï∞ÊçÆÁÆ°ÁêÜ‰ºòÂåñ&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;MongoDBÈõÜÊàêÂ¢ûÂº∫&lt;/strong&gt;: ÊîπËøõÁöÑMongoDBËøûÊé•ÂíåÊï∞ÊçÆÁÆ°ÁêÜ&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Êï∞ÊçÆÁõÆÂΩïÈáçÁªÑ&lt;/strong&gt;: ‰ºòÂåñÁöÑÊï∞ÊçÆÂ≠òÂÇ®ÁªìÊûÑÂíåÁÆ°ÁêÜ&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Êï∞ÊçÆËøÅÁßªËÑöÊú¨&lt;/strong&gt;: ÂÆåÊï¥ÁöÑÊï∞ÊçÆËøÅÁßªÂíåÂ§á‰ªΩÂ∑•ÂÖ∑&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ÁºìÂ≠ò‰ºòÂåñ&lt;/strong&gt;: ÊèêÂçáÊï∞ÊçÆÂä†ËΩΩÂíåÂàÜÊûêÁªìÊûúÁºìÂ≠òÊÄßËÉΩ&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üß™ ÊµãËØïË¶ÜÁõñÂ¢ûÂº∫&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;ÂäüËÉΩÊµãËØïËÑöÊú¨&lt;/strong&gt;: Êñ∞Â¢û6‰∏™‰∏ìÈ°πÂäüËÉΩÊµãËØïËÑöÊú¨&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Â∑•ÂÖ∑Â§ÑÁêÜÂô®ÊµãËØï&lt;/strong&gt;: GoogleÂ∑•ÂÖ∑Â§ÑÁêÜÂô®‰øÆÂ§çÈ™åËØÅ&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ÂºïÂØºËá™Âä®ÈöêËóèÊµãËØï&lt;/strong&gt;: UI‰∫§‰∫íÂäüËÉΩÊµãËØï&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Âú®Á∫øÂ∑•ÂÖ∑ÈÖçÁΩÆÊµãËØï&lt;/strong&gt;: Â∑•ÂÖ∑ÈÖçÁΩÆÂíåÈÄâÊã©ÈÄªËæëÊµãËØï&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ÁúüÂÆûÂú∫ÊôØÊµãËØï&lt;/strong&gt;: ÂÆûÈôÖ‰ΩøÁî®Âú∫ÊôØÁöÑÁ´ØÂà∞Á´ØÊµãËØï&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ÁæéËÇ°Áã¨Á´ãÊÄßÊµãËØï&lt;/strong&gt;: ÁæéËÇ°ÂàÜÊûêÂäüËÉΩÁã¨Á´ãÊÄßÈ™åËØÅ&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üÜï v0.1.13 ÈáçÂ§ßÊõ¥Êñ∞&lt;/h2&gt; 
&lt;h3&gt;ü§ñ ÂéüÁîüOpenAIÁ´ØÁÇπÊîØÊåÅ&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Ëá™ÂÆö‰πâOpenAIÁ´ØÁÇπ&lt;/strong&gt;: ÊîØÊåÅÈÖçÁΩÆ‰ªªÊÑèOpenAIÂÖºÂÆπÁöÑAPIÁ´ØÁÇπ&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ÁÅµÊ¥ªÊ®°ÂûãÈÄâÊã©&lt;/strong&gt;: ÂèØ‰ª•‰ΩøÁî®‰ªª‰ΩïOpenAIÊ†ºÂºèÁöÑÊ®°ÂûãÔºå‰∏çÈôê‰∫éÂÆòÊñπÊ®°Âûã&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Êô∫ËÉΩÈÄÇÈÖçÂô®&lt;/strong&gt;: Êñ∞Â¢ûÂéüÁîüOpenAIÈÄÇÈÖçÂô®ÔºåÊèê‰æõÊõ¥Â•ΩÁöÑÂÖºÂÆπÊÄßÂíåÊÄßËÉΩ&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ÈÖçÁΩÆÁÆ°ÁêÜ&lt;/strong&gt;: Áªü‰∏ÄÁöÑÁ´ØÁÇπÂíåÊ®°ÂûãÈÖçÁΩÆÁÆ°ÁêÜÁ≥ªÁªü&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üß† Google AIÁîüÊÄÅÁ≥ªÁªüÂÖ®Èù¢ÈõÜÊàê&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;‰∏âÂ§ßGoogle AIÂåÖÊîØÊåÅ&lt;/strong&gt;: langchain-google-genai„ÄÅgoogle-generativeai„ÄÅgoogle-genai&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;9‰∏™È™åËØÅÊ®°Âûã&lt;/strong&gt;: gemini-2.5-pro, gemini-2.5-flash, gemini-2.0-flashÁ≠âÊúÄÊñ∞Ê®°Âûã&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;GoogleÂ∑•ÂÖ∑Â§ÑÁêÜÂô®&lt;/strong&gt;: ‰∏ìÈó®ÁöÑGoogle AIÂ∑•ÂÖ∑Ë∞ÉÁî®Â§ÑÁêÜÂô®&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Êô∫ËÉΩÈôçÁ∫ßÊú∫Âà∂&lt;/strong&gt;: È´òÁ∫ßÂäüËÉΩÂ§±Ë¥•Êó∂Ëá™Âä®ÈôçÁ∫ßÂà∞Âü∫Á°ÄÂäüËÉΩ&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üîß LLMÈÄÇÈÖçÂô®Êû∂ÊûÑ‰ºòÂåñ&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;GoogleOpenAIAdapter&lt;/strong&gt;: Êñ∞Â¢ûGoogle AIÁöÑOpenAIÂÖºÂÆπÈÄÇÈÖçÂô®&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Áªü‰∏ÄÊé•Âè£&lt;/strong&gt;: ÊâÄÊúâLLMÊèê‰æõÂïÜ‰ΩøÁî®Áªü‰∏ÄÁöÑË∞ÉÁî®Êé•Âè£&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ÈîôËØØÂ§ÑÁêÜÂ¢ûÂº∫&lt;/strong&gt;: ÊîπËøõÁöÑÂºÇÂ∏∏Â§ÑÁêÜÂíåËá™Âä®ÈáçËØïÊú∫Âà∂&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ÊÄßËÉΩÁõëÊéß&lt;/strong&gt;: Ê∑ªÂä†LLMË∞ÉÁî®ÊÄßËÉΩÁõëÊéßÂíåÁªüËÆ°&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üé® WebÁïåÈù¢Êô∫ËÉΩ‰ºòÂåñ&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Êô∫ËÉΩÊ®°ÂûãÈÄâÊã©&lt;/strong&gt;: Ê†πÊçÆÂèØÁî®ÊÄßËá™Âä®ÈÄâÊã©ÊúÄ‰Ω≥Ê®°Âûã&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;KeyError‰øÆÂ§ç&lt;/strong&gt;: ÂΩªÂ∫ïËß£ÂÜ≥Ê®°ÂûãÈÄâÊã©‰∏≠ÁöÑKeyErrorÈóÆÈ¢ò&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;UIÂìçÂ∫î‰ºòÂåñ&lt;/strong&gt;: ÊîπËøõÊ®°ÂûãÂàáÊç¢ÁöÑÂìçÂ∫îÈÄüÂ∫¶ÂíåÁî®Êà∑‰ΩìÈ™å&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ÈîôËØØÊèêÁ§∫&lt;/strong&gt;: Êõ¥ÂèãÂ•ΩÁöÑÈîôËØØÊèêÁ§∫ÂíåËß£ÂÜ≥Âª∫ËÆÆ&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üÜï v0.1.12 ÈáçÂ§ßÊõ¥Êñ∞&lt;/h2&gt; 
&lt;h3&gt;üß† Êô∫ËÉΩÊñ∞ÈóªÂàÜÊûêÊ®°Âùó&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Êô∫ËÉΩÊñ∞ÈóªËøáÊª§Âô®&lt;/strong&gt;: Âü∫‰∫éAIÁöÑÊñ∞ÈóªÁõ∏ÂÖ≥ÊÄßËØÑÂàÜÂíåË¥®ÈáèËØÑ‰º∞&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Â§öÂ±ÇÊ¨°ËøáÊª§Êú∫Âà∂&lt;/strong&gt;: Âü∫Á°ÄËøáÊª§„ÄÅÂ¢ûÂº∫ËøáÊª§„ÄÅÈõÜÊàêËøáÊª§‰∏âÁ∫ßÂ§ÑÁêÜ&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Êñ∞ÈóªË¥®ÈáèËØÑ‰º∞&lt;/strong&gt;: Ëá™Âä®ËØÜÂà´ÂíåËøáÊª§‰ΩéË¥®Èáè„ÄÅÈáçÂ§ç„ÄÅÊó†ÂÖ≥Êñ∞Èóª&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Áªü‰∏ÄÊñ∞ÈóªÂ∑•ÂÖ∑&lt;/strong&gt;: Êï¥ÂêàÂ§ö‰∏™Êñ∞ÈóªÊ∫êÔºåÊèê‰æõÁªü‰∏ÄÁöÑÊñ∞ÈóªËé∑ÂèñÊé•Âè£&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üîß ÊäÄÊúØ‰øÆÂ§çÂíå‰ºòÂåñ&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;DashScopeÈÄÇÈÖçÂô®‰øÆÂ§ç&lt;/strong&gt;: Ëß£ÂÜ≥Â∑•ÂÖ∑Ë∞ÉÁî®ÂÖºÂÆπÊÄßÈóÆÈ¢ò&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;DeepSeekÊ≠ªÂæ™ÁéØ‰øÆÂ§ç&lt;/strong&gt;: ‰øÆÂ§çÊñ∞ÈóªÂàÜÊûêÂ∏àÁöÑÊó†ÈôêÂæ™ÁéØÈóÆÈ¢ò&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;LLMÂ∑•ÂÖ∑Ë∞ÉÁî®Â¢ûÂº∫&lt;/strong&gt;: ÊèêÂçáÂ∑•ÂÖ∑Ë∞ÉÁî®ÁöÑÂèØÈù†ÊÄßÂíåÁ®≥ÂÆöÊÄß&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Êñ∞ÈóªÊ£ÄÁ¥¢Âô®‰ºòÂåñ&lt;/strong&gt;: Â¢ûÂº∫Êñ∞ÈóªÊï∞ÊçÆËé∑ÂèñÂíåÂ§ÑÁêÜËÉΩÂäõ&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üìö ÂÆåÂñÑÊµãËØïÂíåÊñáÊ°£&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;ÂÖ®Èù¢ÊµãËØïË¶ÜÁõñ&lt;/strong&gt;: Êñ∞Â¢û15+‰∏™ÊµãËØïÊñá‰ª∂ÔºåË¶ÜÁõñÊâÄÊúâÊñ∞ÂäüËÉΩ&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ËØ¶ÁªÜÊäÄÊúØÊñáÊ°£&lt;/strong&gt;: Êñ∞Â¢û8‰∏™ÊäÄÊúØÂàÜÊûêÊä•ÂëäÂíå‰øÆÂ§çÊñáÊ°£&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Áî®Êà∑ÊåáÂçóÂÆåÂñÑ&lt;/strong&gt;: Êñ∞Â¢ûÊñ∞ÈóªËøáÊª§‰ΩøÁî®ÊåáÂçóÂíåÊúÄ‰Ω≥ÂÆûË∑µ&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ÊºîÁ§∫ËÑöÊú¨&lt;/strong&gt;: Êèê‰æõÂÆåÊï¥ÁöÑÊñ∞ÈóªËøáÊª§ÂäüËÉΩÊºîÁ§∫&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üóÇÔ∏è È°πÁõÆÁªìÊûÑ‰ºòÂåñ&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;ÊñáÊ°£ÂàÜÁ±ªÊï¥ÁêÜ&lt;/strong&gt;: ÊåâÂäüËÉΩÂ∞ÜÊñáÊ°£ÂàÜÁ±ªÂà∞docsÂ≠êÁõÆÂΩï&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Á§∫‰æã‰ª£Á†ÅÂΩí‰Ωç&lt;/strong&gt;: ÊºîÁ§∫ËÑöÊú¨Áªü‰∏ÄÂà∞examplesÁõÆÂΩï&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Ê†πÁõÆÂΩïÊï¥Ê¥Å&lt;/strong&gt;: ‰øùÊåÅÊ†πÁõÆÂΩïÁÆÄÊ¥ÅÔºåÊèêÂçáÈ°πÁõÆ‰∏ì‰∏öÂ∫¶&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üéØ Ê†∏ÂøÉÁâπÊÄß&lt;/h2&gt; 
&lt;h3&gt;ü§ñ Â§öÊô∫ËÉΩ‰ΩìÂçè‰ΩúÊû∂ÊûÑ&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;‰∏ì‰∏öÂàÜÂ∑•&lt;/strong&gt;: Âü∫Êú¨Èù¢„ÄÅÊäÄÊúØÈù¢„ÄÅÊñ∞ÈóªÈù¢„ÄÅÁ§æ‰∫§Â™í‰ΩìÂõõÂ§ßÂàÜÊûêÂ∏à&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ÁªìÊûÑÂåñËæ©ËÆ∫&lt;/strong&gt;: ÁúãÊ∂®/ÁúãË∑åÁ†îÁ©∂ÂëòËøõË°åÊ∑±Â∫¶ÂàÜÊûê&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Êô∫ËÉΩÂÜ≥Á≠ñ&lt;/strong&gt;: ‰∫§ÊòìÂëòÂü∫‰∫éÊâÄÊúâËæìÂÖ•ÂÅöÂá∫ÊúÄÁªàÊäïËµÑÂª∫ËÆÆ&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;È£éÈô©ÁÆ°ÁêÜ&lt;/strong&gt;: Â§öÂ±ÇÊ¨°È£éÈô©ËØÑ‰º∞ÂíåÁÆ°ÁêÜÊú∫Âà∂&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üñ•Ô∏è WebÁïåÈù¢Â±ïÁ§∫&lt;/h2&gt; 
&lt;h3&gt;üì∏ ÁïåÈù¢Êà™Âõæ&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;üé® &lt;strong&gt;Áé∞‰ª£ÂåñWebÁïåÈù¢&lt;/strong&gt;: Âü∫‰∫éStreamlitÊûÑÂª∫ÁöÑÂìçÂ∫îÂºèWebÂ∫îÁî®ÔºåÊèê‰æõÁõ¥ËßÇÁöÑËÇ°Á•®ÂàÜÊûê‰ΩìÈ™å&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;üè† ‰∏ªÁïåÈù¢ - ÂàÜÊûêÈÖçÁΩÆ&lt;/h4&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/hsliuping/TradingAgents-CN/main/images/README/1755003162925.png" alt="1755003162925" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/hsliuping/TradingAgents-CN/main/images/README/1755002619976.png" alt="1755002619976" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;Êô∫ËÉΩÈÖçÁΩÆÈù¢ÊùøÔºåÊîØÊåÅÂ§öÂ∏ÇÂú∫ËÇ°Á•®ÂàÜÊûêÔºå5Á∫ßÁ†îÁ©∂Ê∑±Â∫¶ÈÄâÊã©&lt;/em&gt;&lt;/p&gt; 
&lt;h4&gt;üìä ÂÆûÊó∂ÂàÜÊûêËøõÂ∫¶&lt;/h4&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/hsliuping/TradingAgents-CN/main/images/README/1755002731483.png" alt="1755002731483" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;ÂÆûÊó∂ËøõÂ∫¶Ë∑üË∏™ÔºåÂèØËßÜÂåñÂàÜÊûêËøáÁ®ãÔºåÊô∫ËÉΩÊó∂Èó¥È¢Ñ‰º∞&lt;/em&gt;&lt;/p&gt; 
&lt;h4&gt;üìà ÂàÜÊûêÁªìÊûúÂ±ïÁ§∫&lt;/h4&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/hsliuping/TradingAgents-CN/main/images/README/1755002901204.png" alt="1755002901204" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/hsliuping/TradingAgents-CN/main/images/README/1755002924844.png" alt="1755002924844" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/hsliuping/TradingAgents-CN/main/images/README/1755002939905.png" alt="1755002939905" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/hsliuping/TradingAgents-CN/main/images/README/1755002968608.png" alt="1755002968608" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/hsliuping/TradingAgents-CN/main/images/README/1755002985903.png" alt="1755002985903" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/hsliuping/TradingAgents-CN/main/images/README/1755003004403.png" alt="1755003004403" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/hsliuping/TradingAgents-CN/main/images/README/1755003019759.png" alt="1755003019759" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/hsliuping/TradingAgents-CN/main/images/README/1755003033939.png" alt="1755003033939" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/hsliuping/TradingAgents-CN/main/images/README/1755003048242.png" alt="1755003048242" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/hsliuping/TradingAgents-CN/main/images/README/1755003064598.png" alt="1755003064598" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/hsliuping/TradingAgents-CN/main/images/README/1755003090603.png" alt="1755003090603" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;‰∏ì‰∏öÊäïËµÑÊä•ÂëäÔºåÂ§öÁª¥Â∫¶ÂàÜÊûêÁªìÊûúÔºå‰∏ÄÈîÆÂØºÂá∫ÂäüËÉΩ&lt;/em&gt;&lt;/p&gt; 
&lt;h3&gt;üéØ Ê†∏ÂøÉÂäüËÉΩÁâπËâ≤&lt;/h3&gt; 
&lt;h4&gt;üìã &lt;strong&gt;Êô∫ËÉΩÂàÜÊûêÈÖçÁΩÆ&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;üåç Â§öÂ∏ÇÂú∫ÊîØÊåÅ&lt;/strong&gt;: ÁæéËÇ°„ÄÅAËÇ°„ÄÅÊ∏ØËÇ°‰∏ÄÁ´ôÂºèÂàÜÊûê&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üéØ 5Á∫ßÁ†îÁ©∂Ê∑±Â∫¶&lt;/strong&gt;: ‰ªé2ÂàÜÈíüÂø´ÈÄüÂàÜÊûêÂà∞25ÂàÜÈíüÂÖ®Èù¢Á†îÁ©∂&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ü§ñ Êô∫ËÉΩ‰ΩìÈÄâÊã©&lt;/strong&gt;: Â∏ÇÂú∫ÊäÄÊúØ„ÄÅÂü∫Êú¨Èù¢„ÄÅÊñ∞Èóª„ÄÅÁ§æ‰∫§Â™í‰ΩìÂàÜÊûêÂ∏à&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üìÖ ÁÅµÊ¥ªÊó∂Èó¥ËÆæÁΩÆ&lt;/strong&gt;: ÊîØÊåÅÂéÜÂè≤‰ªªÊÑèÊó∂Èó¥ÁÇπÂàÜÊûê&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;üöÄ &lt;strong&gt;ÂÆûÊó∂ËøõÂ∫¶Ë∑üË∏™&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;üìä ÂèØËßÜÂåñËøõÂ∫¶&lt;/strong&gt;: ÂÆûÊó∂ÊòæÁ§∫ÂàÜÊûêËøõÂ±ïÂíåÂâ©‰ΩôÊó∂Èó¥&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üîÑ Êô∫ËÉΩÊ≠•È™§ËØÜÂà´&lt;/strong&gt;: Ëá™Âä®ËØÜÂà´ÂΩìÂâçÂàÜÊûêÈò∂ÊÆµ&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;‚è±Ô∏è ÂáÜÁ°ÆÊó∂Èó¥È¢Ñ‰º∞&lt;/strong&gt;: Âü∫‰∫éÂéÜÂè≤Êï∞ÊçÆÁöÑÊô∫ËÉΩÊó∂Èó¥ËÆ°ÁÆó&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üíæ Áä∂ÊÄÅÊåÅ‰πÖÂåñ&lt;/strong&gt;: È°µÈù¢Âà∑Êñ∞‰∏ç‰∏¢Â§±ÂàÜÊûêËøõÂ∫¶&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;üìà &lt;strong&gt;‰∏ì‰∏öÁªìÊûúÂ±ïÁ§∫&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;üéØ ÊäïËµÑÂÜ≥Á≠ñ&lt;/strong&gt;: ÊòéÁ°ÆÁöÑ‰π∞ÂÖ•/ÊåÅÊúâ/ÂçñÂá∫Âª∫ËÆÆ&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üìä Â§öÁª¥ÂàÜÊûê&lt;/strong&gt;: ÊäÄÊúØÈù¢„ÄÅÂü∫Êú¨Èù¢„ÄÅÊñ∞ÈóªÈù¢ÁªºÂêàËØÑ‰º∞&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üî¢ ÈáèÂåñÊåáÊ†á&lt;/strong&gt;: ÁΩÆ‰ø°Â∫¶„ÄÅÈ£éÈô©ËØÑÂàÜ„ÄÅÁõÆÊ†á‰ª∑‰Ωç&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üìÑ ‰∏ì‰∏öÊä•Âëä&lt;/strong&gt;: ÊîØÊåÅMarkdown/Word/PDFÊ†ºÂºèÂØºÂá∫&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;ü§ñ &lt;strong&gt;Â§öLLMÊ®°ÂûãÁÆ°ÁêÜ&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;üåê 4Â§ßÊèê‰æõÂïÜ&lt;/strong&gt;: DashScope„ÄÅDeepSeek„ÄÅGoogle AI„ÄÅOpenRouter&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üéØ 60+Ê®°ÂûãÈÄâÊã©&lt;/strong&gt;: ‰ªéÁªèÊµéÂûãÂà∞ÊóóËà∞Á∫ßÊ®°ÂûãÂÖ®Ë¶ÜÁõñ&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üíæ ÈÖçÁΩÆÊåÅ‰πÖÂåñ&lt;/strong&gt;: URLÂèÇÊï∞Â≠òÂÇ®ÔºåÂà∑Êñ∞‰øùÊåÅËÆæÁΩÆ&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;‚ö° Âø´ÈÄüÂàáÊç¢&lt;/strong&gt;: 5‰∏™ÁÉ≠Èó®Ê®°Âûã‰∏ÄÈîÆÈÄâÊã©ÊåâÈíÆ&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üéÆ WebÁïåÈù¢Êìç‰ΩúÊåáÂçó&lt;/h3&gt; 
&lt;h4&gt;üöÄ &lt;strong&gt;Âø´ÈÄüÂºÄÂßãÊµÅÁ®ã&lt;/strong&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;ÂêØÂä®Â∫îÁî®&lt;/strong&gt;: &lt;code&gt;python start_web.py&lt;/code&gt; Êàñ &lt;code&gt;docker-compose up -d&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ËÆøÈóÆÁïåÈù¢&lt;/strong&gt;: ÊµèËßàÂô®ÊâìÂºÄ &lt;code&gt;http://localhost:8501&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ÈÖçÁΩÆÊ®°Âûã&lt;/strong&gt;: ‰æßËæπÊ†èÈÄâÊã©LLMÊèê‰æõÂïÜÂíåÊ®°Âûã&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ËæìÂÖ•ËÇ°Á•®&lt;/strong&gt;: ËæìÂÖ•ËÇ°Á•®‰ª£Á†ÅÔºàÂ¶Ç AAPL„ÄÅ000001„ÄÅ0700.HKÔºâ&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ÈÄâÊã©Ê∑±Â∫¶&lt;/strong&gt;: Ê†πÊçÆÈúÄÊ±ÇÈÄâÊã©1-5Á∫ßÁ†îÁ©∂Ê∑±Â∫¶&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ÂºÄÂßãÂàÜÊûê&lt;/strong&gt;: ÁÇπÂáª"üöÄ ÂºÄÂßãÂàÜÊûê"ÊåâÈíÆ&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Êü•ÁúãÁªìÊûú&lt;/strong&gt;: ÂÆûÊó∂Ë∑üË∏™ËøõÂ∫¶ÔºåÊü•ÁúãÂàÜÊûêÊä•Âëä&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ÂØºÂá∫Êä•Âëä&lt;/strong&gt;: ‰∏ÄÈîÆÂØºÂá∫‰∏ì‰∏öÊ†ºÂºèÊä•Âëä&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;üìä &lt;strong&gt;ÊîØÊåÅÁöÑËÇ°Á•®‰ª£Á†ÅÊ†ºÂºè&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;üá∫üá∏ ÁæéËÇ°&lt;/strong&gt;: &lt;code&gt;AAPL&lt;/code&gt;, &lt;code&gt;TSLA&lt;/code&gt;, &lt;code&gt;MSFT&lt;/code&gt;, &lt;code&gt;NVDA&lt;/code&gt;, &lt;code&gt;GOOGL&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üá®üá≥ AËÇ°&lt;/strong&gt;: &lt;code&gt;000001&lt;/code&gt;, &lt;code&gt;600519&lt;/code&gt;, &lt;code&gt;300750&lt;/code&gt;, &lt;code&gt;002415&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üá≠üá∞ Ê∏ØËÇ°&lt;/strong&gt;: &lt;code&gt;0700.HK&lt;/code&gt;, &lt;code&gt;9988.HK&lt;/code&gt;, &lt;code&gt;3690.HK&lt;/code&gt;, &lt;code&gt;1810.HK&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;üéØ &lt;strong&gt;Á†îÁ©∂Ê∑±Â∫¶ËØ¥Êòé&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;1Á∫ß (2-4ÂàÜÈíü)&lt;/strong&gt;: Âø´ÈÄüÊ¶ÇËßàÔºåÂü∫Á°ÄÊäÄÊúØÊåáÊ†á&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;2Á∫ß (4-6ÂàÜÈíü)&lt;/strong&gt;: Ê†áÂáÜÂàÜÊûêÔºåÊäÄÊúØ+Âü∫Êú¨Èù¢&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;3Á∫ß (6-10ÂàÜÈíü)&lt;/strong&gt;: Ê∑±Â∫¶ÂàÜÊûêÔºåÂä†ÂÖ•Êñ∞ÈóªÊÉÖÁª™ ‚≠ê &lt;strong&gt;Êé®Ëçê&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;4Á∫ß (10-15ÂàÜÈíü)&lt;/strong&gt;: ÂÖ®Èù¢ÂàÜÊûêÔºåÂ§öËΩÆÊô∫ËÉΩ‰ΩìËæ©ËÆ∫&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;5Á∫ß (15-25ÂàÜÈíü)&lt;/strong&gt;: ÊúÄÊ∑±Â∫¶ÂàÜÊûêÔºåÂÆåÊï¥Á†îÁ©∂Êä•Âëä&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;üí° &lt;strong&gt;‰ΩøÁî®ÊäÄÂ∑ß&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;üîÑ ÂÆûÊó∂Âà∑Êñ∞&lt;/strong&gt;: ÂàÜÊûêËøáÁ®ã‰∏≠ÂèØÈöèÊó∂Âà∑Êñ∞È°µÈù¢ÔºåËøõÂ∫¶‰∏ç‰∏¢Â§±&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üì± ÁßªÂä®ÈÄÇÈÖç&lt;/strong&gt;: ÊîØÊåÅÊâãÊú∫ÂíåÂπ≥ÊùøËÆæÂ§áËÆøÈóÆ&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üé® Ê∑±Ëâ≤Ê®°Âºè&lt;/strong&gt;: Ëá™Âä®ÈÄÇÈÖçÁ≥ªÁªü‰∏ªÈ¢òËÆæÁΩÆ&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;‚å®Ô∏è Âø´Êç∑ÈîÆ&lt;/strong&gt;: ÊîØÊåÅEnterÈîÆÂø´ÈÄüÊèê‰∫§ÂàÜÊûê&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üìã ÂéÜÂè≤ËÆ∞ÂΩï&lt;/strong&gt;: Ëá™Âä®‰øùÂ≠òÊúÄËøëÁöÑÂàÜÊûêÈÖçÁΩÆ&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;üìñ &lt;strong&gt;ËØ¶ÁªÜÊåáÂçó&lt;/strong&gt;: ÂÆåÊï¥ÁöÑWebÁïåÈù¢‰ΩøÁî®ËØ¥ÊòéËØ∑ÂèÇËÄÉ &lt;a href="https://raw.githubusercontent.com/hsliuping/TradingAgents-CN/main/docs/usage/web-interface-detailed-guide.md"&gt;üñ•Ô∏è WebÁïåÈù¢ËØ¶ÁªÜ‰ΩøÁî®ÊåáÂçó&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;üéØ ÂäüËÉΩÁâπÊÄß&lt;/h2&gt; 
&lt;h3&gt;üöÄ Êô∫ËÉΩÊñ∞ÈóªÂàÜÊûê‚ú® &lt;strong&gt;v0.1.12ÈáçÂ§ßÂçáÁ∫ß&lt;/strong&gt;&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;ÂäüËÉΩÁâπÊÄß&lt;/th&gt; 
   &lt;th&gt;Áä∂ÊÄÅ&lt;/th&gt; 
   &lt;th&gt;ËØ¶ÁªÜËØ¥Êòé&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;üß† Êô∫ËÉΩÊñ∞ÈóªÂàÜÊûê&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;üÜï v0.1.12&lt;/td&gt; 
   &lt;td&gt;AIÊñ∞ÈóªËøáÊª§ÔºåË¥®ÈáèËØÑ‰º∞ÔºåÁõ∏ÂÖ≥ÊÄßÂàÜÊûê&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;üîß Êñ∞ÈóªËøáÊª§Âô®&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;üÜï v0.1.12&lt;/td&gt; 
   &lt;td&gt;Â§öÂ±ÇÊ¨°ËøáÊª§ÔºåÂü∫Á°Ä/Â¢ûÂº∫/ÈõÜÊàê‰∏âÁ∫ßÂ§ÑÁêÜ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;üì∞ Áªü‰∏ÄÊñ∞ÈóªÂ∑•ÂÖ∑&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;üÜï v0.1.12&lt;/td&gt; 
   &lt;td&gt;Êï¥ÂêàÂ§öÊ∫êÊñ∞ÈóªÔºåÁªü‰∏ÄÊé•Âè£ÔºåÊô∫ËÉΩÊ£ÄÁ¥¢&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;ü§ñ Â§öLLMÊèê‰æõÂïÜ&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;üÜï v0.1.11&lt;/td&gt; 
   &lt;td&gt;4Â§ßÊèê‰æõÂïÜÔºå60+Ê®°ÂûãÔºåÊô∫ËÉΩÂàÜÁ±ªÁÆ°ÁêÜ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;üíæ Ê®°ÂûãÈÄâÊã©ÊåÅ‰πÖÂåñ&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;üÜï v0.1.11&lt;/td&gt; 
   &lt;td&gt;URLÂèÇÊï∞Â≠òÂÇ®ÔºåÂà∑Êñ∞‰øùÊåÅÔºåÈÖçÁΩÆÂàÜ‰∫´&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;üéØ Âø´ÈÄüÈÄâÊã©ÊåâÈíÆ&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;üÜï v0.1.11&lt;/td&gt; 
   &lt;td&gt;‰∏ÄÈîÆÂàáÊç¢ÁÉ≠Èó®Ê®°ÂûãÔºåÊèêÂçáÊìç‰ΩúÊïàÁéá&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;üìä ÂÆûÊó∂ËøõÂ∫¶ÊòæÁ§∫&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ v0.1.10&lt;/td&gt; 
   &lt;td&gt;ÂºÇÊ≠•ËøõÂ∫¶Ë∑üË∏™ÔºåÊô∫ËÉΩÊ≠•È™§ËØÜÂà´ÔºåÂáÜÁ°ÆÊó∂Èó¥ËÆ°ÁÆó&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;üíæ Êô∫ËÉΩ‰ºöËØùÁÆ°ÁêÜ&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ v0.1.10&lt;/td&gt; 
   &lt;td&gt;Áä∂ÊÄÅÊåÅ‰πÖÂåñÔºåËá™Âä®ÈôçÁ∫ßÔºåË∑®È°µÈù¢ÊÅ¢Â§ç&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;üéØ ‰∏ÄÈîÆÊü•ÁúãÊä•Âëä&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ v0.1.10&lt;/td&gt; 
   &lt;td&gt;ÂàÜÊûêÂÆåÊàêÂêé‰∏ÄÈîÆÊü•ÁúãÔºåÊô∫ËÉΩÁªìÊûúÊÅ¢Â§ç&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;üñ•Ô∏è StreamlitÁïåÈù¢&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ ÂÆåÊï¥ÊîØÊåÅ&lt;/td&gt; 
   &lt;td&gt;Áé∞‰ª£ÂåñÂìçÂ∫îÂºèÁïåÈù¢ÔºåÂÆûÊó∂‰∫§‰∫íÂíåÊï∞ÊçÆÂèØËßÜÂåñ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;‚öôÔ∏è ÈÖçÁΩÆÁÆ°ÁêÜ&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ ÂÆåÊï¥ÊîØÊåÅ&lt;/td&gt; 
   &lt;td&gt;WebÁ´ØAPIÂØÜÈí•ÁÆ°ÁêÜÔºåÊ®°ÂûãÈÄâÊã©ÔºåÂèÇÊï∞ÈÖçÁΩÆ&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;üé® CLIÁî®Êà∑‰ΩìÈ™å ‚ú® &lt;strong&gt;v0.1.9‰ºòÂåñ&lt;/strong&gt;&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;ÂäüËÉΩÁâπÊÄß&lt;/th&gt; 
   &lt;th&gt;Áä∂ÊÄÅ&lt;/th&gt; 
   &lt;th&gt;ËØ¶ÁªÜËØ¥Êòé&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;üñ•Ô∏è ÁïåÈù¢‰∏éÊó•ÂøóÂàÜÁ¶ª&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ ÂÆåÊï¥ÊîØÊåÅ&lt;/td&gt; 
   &lt;td&gt;Áî®Êà∑ÁïåÈù¢Ê∏ÖÁàΩÁæéËßÇÔºåÊäÄÊúØÊó•ÂøóÁã¨Á´ãÁÆ°ÁêÜ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;üîÑ Êô∫ËÉΩËøõÂ∫¶ÊòæÁ§∫&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ ÂÆåÊï¥ÊîØÊåÅ&lt;/td&gt; 
   &lt;td&gt;Â§öÈò∂ÊÆµËøõÂ∫¶Ë∑üË∏™ÔºåÈò≤Ê≠¢ÈáçÂ§çÊèêÁ§∫&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;‚è±Ô∏è Êó∂Èó¥È¢Ñ‰º∞ÂäüËÉΩ&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ ÂÆåÊï¥ÊîØÊåÅ&lt;/td&gt; 
   &lt;td&gt;Êô∫ËÉΩÂàÜÊûêÈò∂ÊÆµÊòæÁ§∫È¢ÑËÆ°ËÄóÊó∂&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;üåà RichÂΩ©Ëâ≤ËæìÂá∫&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ ÂÆåÊï¥ÊîØÊåÅ&lt;/td&gt; 
   &lt;td&gt;ÂΩ©Ëâ≤ËøõÂ∫¶ÊåáÁ§∫ÔºåÁä∂ÊÄÅÂõæÊ†áÔºåËßÜËßâÊïàÊûúÊèêÂçá&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;üß† LLMÊ®°ÂûãÊîØÊåÅ ‚ú® &lt;strong&gt;v0.1.13ÂÖ®Èù¢ÂçáÁ∫ß&lt;/strong&gt;&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Ê®°ÂûãÊèê‰æõÂïÜ&lt;/th&gt; 
   &lt;th&gt;ÊîØÊåÅÊ®°Âûã&lt;/th&gt; 
   &lt;th&gt;ÁâπËâ≤ÂäüËÉΩ&lt;/th&gt; 
   &lt;th&gt;Êñ∞Â¢ûÂäüËÉΩ&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;üá®üá≥ ÈòøÈáåÁôæÁÇº&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;qwen-turbo/plus/max&lt;/td&gt; 
   &lt;td&gt;‰∏≠Êñá‰ºòÂåñÔºåÊàêÊú¨ÊïàÁõäÈ´ò&lt;/td&gt; 
   &lt;td&gt;‚úÖ ÈõÜÊàê&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;üá®üá≥ DeepSeek&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;deepseek-chat&lt;/td&gt; 
   &lt;td&gt;Â∑•ÂÖ∑Ë∞ÉÁî®ÔºåÊÄß‰ª∑ÊØîÊûÅÈ´ò&lt;/td&gt; 
   &lt;td&gt;‚úÖ ÈõÜÊàê&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;üåç Google AI&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;9‰∏™È™åËØÅÊ®°Âûã&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;ÊúÄÊñ∞Gemini 2.5Á≥ªÂàó&lt;/td&gt; 
   &lt;td&gt;üÜï ÂçáÁ∫ß&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;‚îú‚îÄ&lt;strong&gt;ÊúÄÊñ∞ÊóóËà∞&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;gemini-2.5-pro/flash&lt;/td&gt; 
   &lt;td&gt;ÊúÄÊñ∞ÊóóËà∞ÔºåË∂ÖÂø´ÂìçÂ∫î&lt;/td&gt; 
   &lt;td&gt;üÜï Êñ∞Â¢û&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;‚îú‚îÄ&lt;strong&gt;Á®≥ÂÆöÊé®Ëçê&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;gemini-2.0-flash&lt;/td&gt; 
   &lt;td&gt;Êé®Ëçê‰ΩøÁî®ÔºåÂπ≥Ë°°ÊÄßËÉΩ&lt;/td&gt; 
   &lt;td&gt;üÜï Êñ∞Â¢û&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;‚îú‚îÄ&lt;strong&gt;ÁªèÂÖ∏Âº∫Â§ß&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;gemini-1.5-pro/flash&lt;/td&gt; 
   &lt;td&gt;ÁªèÂÖ∏Á®≥ÂÆöÔºåÈ´òË¥®ÈáèÂàÜÊûê&lt;/td&gt; 
   &lt;td&gt;‚úÖ ÈõÜÊàê&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;‚îî‚îÄ&lt;strong&gt;ËΩªÈáèÂø´ÈÄü&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;gemini-2.5-flash-lite&lt;/td&gt; 
   &lt;td&gt;ËΩªÈáèÁ∫ß‰ªªÂä°ÔºåÂø´ÈÄüÂìçÂ∫î&lt;/td&gt; 
   &lt;td&gt;üÜï Êñ∞Â¢û&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;üåê ÂéüÁîüOpenAI&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Ëá™ÂÆö‰πâÁ´ØÁÇπÊîØÊåÅ&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;‰ªªÊÑèOpenAIÂÖºÂÆπÁ´ØÁÇπ&lt;/td&gt; 
   &lt;td&gt;üÜï Êñ∞Â¢û&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;üåê OpenRouter&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;60+Ê®°ÂûãËÅöÂêàÂπ≥Âè∞&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;‰∏Ä‰∏™APIËÆøÈóÆÊâÄÊúâ‰∏ªÊµÅÊ®°Âûã&lt;/td&gt; 
   &lt;td&gt;‚úÖ ÈõÜÊàê&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;‚îú‚îÄ&lt;strong&gt;OpenAI&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;o4-mini-high, o3-pro, GPT-4o&lt;/td&gt; 
   &lt;td&gt;ÊúÄÊñ∞oÁ≥ªÂàóÔºåÊé®ÁêÜ‰∏ì‰∏öÁâà&lt;/td&gt; 
   &lt;td&gt;‚úÖ ÈõÜÊàê&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;‚îú‚îÄ&lt;strong&gt;Anthropic&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Claude 4 Opus/Sonnet/Haiku&lt;/td&gt; 
   &lt;td&gt;È°∂Á∫ßÊÄßËÉΩÔºåÂπ≥Ë°°ÁâàÊú¨&lt;/td&gt; 
   &lt;td&gt;‚úÖ ÈõÜÊàê&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;‚îú‚îÄ&lt;strong&gt;Meta&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Llama 4 Maverick/Scout&lt;/td&gt; 
   &lt;td&gt;ÊúÄÊñ∞Llama 4Á≥ªÂàó&lt;/td&gt; 
   &lt;td&gt;‚úÖ ÈõÜÊàê&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;‚îî‚îÄ&lt;strong&gt;Ëá™ÂÆö‰πâ&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;‰ªªÊÑèOpenRouterÊ®°ÂûãID&lt;/td&gt; 
   &lt;td&gt;Êó†ÈôêÊâ©Â±ïÔºå‰∏™ÊÄßÂåñÈÄâÊã©&lt;/td&gt; 
   &lt;td&gt;‚úÖ ÈõÜÊàê&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;üéØ Âø´ÈÄüÈÄâÊã©&lt;/strong&gt;: 5‰∏™ÁÉ≠Èó®Ê®°ÂûãÂø´ÈÄüÊåâÈíÆ | &lt;strong&gt;üíæ ÊåÅ‰πÖÂåñ&lt;/strong&gt;: URLÂèÇÊï∞Â≠òÂÇ®ÔºåÂà∑Êñ∞‰øùÊåÅ | &lt;strong&gt;üîÑ Êô∫ËÉΩÂàáÊç¢&lt;/strong&gt;: ‰∏ÄÈîÆÂàáÊç¢‰∏çÂêåÊèê‰æõÂïÜ&lt;/p&gt; 
&lt;h3&gt;üìä Êï∞ÊçÆÊ∫ê‰∏éÂ∏ÇÂú∫&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Â∏ÇÂú∫Á±ªÂûã&lt;/th&gt; 
   &lt;th&gt;Êï∞ÊçÆÊ∫ê&lt;/th&gt; 
   &lt;th&gt;Ë¶ÜÁõñËåÉÂõ¥&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;üá®üá≥ AËÇ°&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Tushare, AkShare, ÈÄöËææ‰ø°&lt;/td&gt; 
   &lt;td&gt;Ê≤™Ê∑±‰∏§Â∏ÇÔºåÂÆûÊó∂Ë°åÊÉÖÔºåË¥¢Êä•Êï∞ÊçÆ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;üá≠üá∞ Ê∏ØËÇ°&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;AkShare, Yahoo Finance&lt;/td&gt; 
   &lt;td&gt;Ê∏Ø‰∫§ÊâÄÔºåÂÆûÊó∂Ë°åÊÉÖÔºåÂü∫Êú¨Èù¢&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;üá∫üá∏ ÁæéËÇ°&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;FinnHub, Yahoo Finance&lt;/td&gt; 
   &lt;td&gt;NYSE, NASDAQÔºåÂÆûÊó∂Êï∞ÊçÆ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;üì∞ Êñ∞Èóª&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Google News&lt;/td&gt; 
   &lt;td&gt;ÂÆûÊó∂Êñ∞ÈóªÔºåÂ§öËØ≠Ë®ÄÊîØÊåÅ&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;ü§ñ Êô∫ËÉΩ‰ΩìÂõ¢Èòü&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;ÂàÜÊûêÂ∏àÂõ¢Èòü&lt;/strong&gt;: üìàÂ∏ÇÂú∫ÂàÜÊûê | üí∞Âü∫Êú¨Èù¢ÂàÜÊûê | üì∞Êñ∞ÈóªÂàÜÊûê | üí¨ÊÉÖÁª™ÂàÜÊûê &lt;strong&gt;Á†îÁ©∂Âõ¢Èòü&lt;/strong&gt;: üêÇÁúãÊ∂®Á†îÁ©∂Âëò | üêªÁúãË∑åÁ†îÁ©∂Âëò | üéØ‰∫§ÊòìÂÜ≥Á≠ñÂëò &lt;strong&gt;ÁÆ°ÁêÜÂ±Ç&lt;/strong&gt;: üõ°Ô∏èÈ£éÈô©ÁÆ°ÁêÜÂëò | üëîÁ†îÁ©∂‰∏ªÁÆ°&lt;/p&gt; 
&lt;h2&gt;üöÄ Âø´ÈÄüÂºÄÂßã&lt;/h2&gt; 
&lt;h3&gt;üê≥ DockerÈÉ®ÁΩ≤ (Êé®Ëçê)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# 1. ÂÖãÈöÜÈ°πÁõÆ
git clone https://github.com/hsliuping/TradingAgents-CN.git
cd TradingAgents-CN

# 2. ÈÖçÁΩÆÁéØÂ¢ÉÂèòÈáè
cp .env.example .env
# ÁºñËæë .env Êñá‰ª∂ÔºåÂ°´ÂÖ•APIÂØÜÈí•

# 3. ÂêØÂä®ÊúçÂä°
# È¶ñÊ¨°ÂêØÂä®Êàñ‰ª£Á†ÅÂèòÊõ¥Êó∂ÔºàÈúÄË¶ÅÊûÑÂª∫ÈïúÂÉèÔºâ
docker-compose up -d --build

# Êó•Â∏∏ÂêØÂä®ÔºàÈïúÂÉèÂ∑≤Â≠òÂú®ÔºåÊó†‰ª£Á†ÅÂèòÊõ¥Ôºâ
docker-compose up -d

# Êô∫ËÉΩÂêØÂä®ÔºàËá™Âä®Âà§Êñ≠ÊòØÂê¶ÈúÄË¶ÅÊûÑÂª∫Ôºâ
# WindowsÁéØÂ¢É
powershell -ExecutionPolicy Bypass -File scripts\smart_start.ps1

# Linux/MacÁéØÂ¢É
chmod +x scripts/smart_start.sh &amp;amp;&amp;amp; ./scripts/smart_start.sh

# 4. ËÆøÈóÆÂ∫îÁî®
# WebÁïåÈù¢: http://localhost:8501
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;üíª Êú¨Âú∞ÈÉ®ÁΩ≤&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# 1. ÂçáÁ∫ßpip (ÈáçË¶ÅÔºÅÈÅøÂÖçÂÆâË£ÖÈîôËØØ)
python -m pip install --upgrade pip

# 2. ÂÆâË£Ö‰æùËµñ
pip install -e .

# 3. ÂêØÂä®Â∫îÁî®
python start_web.py

# 4. ËÆøÈóÆ http://localhost:8501
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;üìä ÂºÄÂßãÂàÜÊûê&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;ÈÄâÊã©Ê®°Âûã&lt;/strong&gt;: DeepSeek V3 / ÈÄö‰πâÂçÉÈóÆ / Gemini&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ËæìÂÖ•ËÇ°Á•®&lt;/strong&gt;: &lt;code&gt;000001&lt;/code&gt; (AËÇ°) / &lt;code&gt;AAPL&lt;/code&gt; (ÁæéËÇ°) / &lt;code&gt;0700.HK&lt;/code&gt; (Ê∏ØËÇ°)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ÂºÄÂßãÂàÜÊûê&lt;/strong&gt;: ÁÇπÂáª"üöÄ ÂºÄÂßãÂàÜÊûê"ÊåâÈíÆ&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ÂÆûÊó∂Ë∑üË∏™&lt;/strong&gt;: ËßÇÂØüÂÆûÊó∂ËøõÂ∫¶ÂíåÂàÜÊûêÊ≠•È™§&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Êü•ÁúãÊä•Âëä&lt;/strong&gt;: ÁÇπÂáª"üìä Êü•ÁúãÂàÜÊûêÊä•Âëä"ÊåâÈíÆ&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ÂØºÂá∫Êä•Âëä&lt;/strong&gt;: ÊîØÊåÅWord/PDF/MarkdownÊ†ºÂºè&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;üîê Áî®Êà∑ÊùÉÈôêÁÆ°ÁêÜ&lt;/h2&gt; 
&lt;h3&gt;üîë ÈªòËÆ§Ë¥¶Âè∑‰ø°ÊÅØ&lt;/h3&gt; 
&lt;p&gt;Á≥ªÁªüÊèê‰æõ‰ª•‰∏ãÈªòËÆ§Ë¥¶Âè∑ÔºåÈ¶ñÊ¨°ÂêØÂä®Êó∂Ëá™Âä®ÂàõÂª∫Ôºö&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Áî®Êà∑Âêç&lt;/th&gt; 
   &lt;th&gt;ÂØÜÁ†Å&lt;/th&gt; 
   &lt;th&gt;ËßíËâ≤&lt;/th&gt; 
   &lt;th&gt;ÊùÉÈôêËØ¥Êòé&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;admin&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;admin123&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;ÁÆ°ÁêÜÂëò&lt;/td&gt; 
   &lt;td&gt;ÂÆåÊï¥Á≥ªÁªüÊùÉÈôêÔºåÁî®Êà∑ÁÆ°ÁêÜÔºåÁ≥ªÁªüÈÖçÁΩÆ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;user&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;user123&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;ÊôÆÈÄöÁî®Êà∑&lt;/td&gt; 
   &lt;td&gt;ËÇ°Á•®ÂàÜÊûêÔºåÊä•ÂëäÊü•ÁúãÔºåÂü∫Á°ÄÂäüËÉΩ&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;‚ö†Ô∏è &lt;strong&gt;ÂÆâÂÖ®ÊèêÈÜí&lt;/strong&gt;: È¶ñÊ¨°ÁôªÂΩïÂêéËØ∑Á´ãÂç≥‰øÆÊîπÈªòËÆ§ÂØÜÁ†ÅÔºÅ&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;üõ°Ô∏è ÊùÉÈôêÊéßÂà∂‰ΩìÁ≥ª&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;üîê ÁôªÂΩïËÆ§ËØÅ&lt;/strong&gt;: Âü∫‰∫éÁî®Êà∑ÂêçÂØÜÁ†ÅÁöÑÂÆâÂÖ®ËÆ§ËØÅ&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üë• ËßíËâ≤ÁÆ°ÁêÜ&lt;/strong&gt;: ÁÆ°ÁêÜÂëò„ÄÅÊôÆÈÄöÁî®Êà∑Á≠âÂ§öÁ∫ßÊùÉÈôê&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;‚è∞ ‰ºöËØùÁÆ°ÁêÜ&lt;/strong&gt;: Ëá™Âä®Ë∂ÖÊó∂‰øùÊä§ÔºåÂÆâÂÖ®ÁôªÂá∫&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üìä Êìç‰ΩúÊó•Âøó&lt;/strong&gt;: ÂÆåÊï¥ÁöÑÁî®Êà∑Ê¥ªÂä®ËÆ∞ÂΩï&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üõ†Ô∏è Áî®Êà∑ÁÆ°ÁêÜÂ∑•ÂÖ∑&lt;/h3&gt; 
&lt;p&gt;Á≥ªÁªüÊèê‰æõÂÆåÊï¥ÁöÑÂëΩ‰ª§Ë°åÁî®Êà∑ÁÆ°ÁêÜÂ∑•ÂÖ∑Ôºö&lt;/p&gt; 
&lt;h4&gt;Windows Áî®Êà∑&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-powershell"&gt;# ‰ΩøÁî® PowerShell ËÑöÊú¨
.\scripts\user_manager.ps1 list                    # ÂàóÂá∫ÊâÄÊúâÁî®Êà∑
.\scripts\user_manager.ps1 change-password admin   # ‰øÆÊîπÂØÜÁ†Å
.\scripts\user_manager.ps1 create newuser trader  # ÂàõÂª∫Êñ∞Áî®Êà∑
.\scripts\user_manager.ps1 delete olduser         # Âà†Èô§Áî®Êà∑

# Êàñ‰ΩøÁî®ÊâπÂ§ÑÁêÜÊñá‰ª∂
.\scripts\user_manager.bat list
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Python ËÑöÊú¨ÔºàË∑®Âπ≥Âè∞Ôºâ&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Áõ¥Êé•‰ΩøÁî® Python ËÑöÊú¨
python scripts/user_password_manager.py list
python scripts/user_password_manager.py change-password admin
python scripts/user_password_manager.py create newuser --role trader
python scripts/user_password_manager.py delete olduser
python scripts/user_password_manager.py reset  # ÈáçÁΩÆ‰∏∫ÈªòËÆ§ÈÖçÁΩÆ
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;üìã ÊîØÊåÅÁöÑÁî®Êà∑Êìç‰Ωú&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;üìù ÂàóÂá∫Áî®Êà∑&lt;/strong&gt;: Êü•ÁúãÊâÄÊúâÁî®Êà∑ÂèäÂÖ∂ËßíËâ≤ÊùÉÈôê&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üîë ‰øÆÊîπÂØÜÁ†Å&lt;/strong&gt;: ÂÆâÂÖ®ÁöÑÂØÜÁ†ÅÊõ¥Êñ∞Êú∫Âà∂&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üë§ ÂàõÂª∫Áî®Êà∑&lt;/strong&gt;: ÊîØÊåÅËá™ÂÆö‰πâËßíËâ≤ÂíåÊùÉÈôê&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üóëÔ∏è Âà†Èô§Áî®Êà∑&lt;/strong&gt;: ÂÆâÂÖ®ÁöÑÁî®Êà∑Âà†Èô§ÂäüËÉΩ&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üîÑ ÈáçÁΩÆÈÖçÁΩÆ&lt;/strong&gt;: ÊÅ¢Â§çÈªòËÆ§Áî®Êà∑ËÆæÁΩÆ&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üìÅ ÈÖçÁΩÆÊñá‰ª∂‰ΩçÁΩÆ&lt;/h3&gt; 
&lt;p&gt;Áî®Êà∑ÈÖçÁΩÆÂ≠òÂÇ®Âú®Ôºö&lt;code&gt;web/config/users.json&lt;/code&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;üìö &lt;strong&gt;ËØ¶ÁªÜÊñáÊ°£&lt;/strong&gt;: ÂÆåÊï¥ÁöÑÁî®Êà∑ÁÆ°ÁêÜÊåáÂçóËØ∑ÂèÇËÄÉ &lt;a href="https://raw.githubusercontent.com/hsliuping/TradingAgents-CN/main/scripts/USER_MANAGEMENT.md"&gt;scripts/USER_MANAGEMENT.md&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;üöß ÂΩìÂâçÁâàÊú¨ÈôêÂà∂&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;‚ùå ÊöÇ‰∏çÊîØÊåÅÂú®Á∫øÁî®Êà∑Ê≥®ÂÜå&lt;/li&gt; 
 &lt;li&gt;‚ùå ÊöÇ‰∏çÊîØÊåÅWebÁïåÈù¢ÁöÑËßíËâ≤ÁÆ°ÁêÜ&lt;/li&gt; 
 &lt;li&gt;‚úÖ ÊîØÊåÅÂÆåÊï¥ÁöÑÂëΩ‰ª§Ë°åÁî®Êà∑ÁÆ°ÁêÜ&lt;/li&gt; 
 &lt;li&gt;‚úÖ ÊîØÊåÅÂÆåÊï¥ÁöÑÊùÉÈôêÊéßÂà∂Ê°ÜÊû∂&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üéØ Ê†∏ÂøÉ‰ºòÂäø&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;üß† Êô∫ËÉΩÊñ∞ÈóªÂàÜÊûê&lt;/strong&gt;: v0.1.12Êñ∞Â¢ûAIÈ©±Âä®ÁöÑÊñ∞ÈóªËøáÊª§ÂíåË¥®ÈáèËØÑ‰º∞Á≥ªÁªü&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üîß Â§öÂ±ÇÊ¨°ËøáÊª§&lt;/strong&gt;: Âü∫Á°Ä„ÄÅÂ¢ûÂº∫„ÄÅÈõÜÊàê‰∏âÁ∫ßÊñ∞ÈóªËøáÊª§Êú∫Âà∂&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üì∞ Áªü‰∏ÄÊñ∞ÈóªÂ∑•ÂÖ∑&lt;/strong&gt;: Êï¥ÂêàÂ§öÊ∫êÊñ∞ÈóªÔºåÊèê‰æõÁªü‰∏ÄÁöÑÊô∫ËÉΩÊ£ÄÁ¥¢Êé•Âè£&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üÜï Â§öLLMÈõÜÊàê&lt;/strong&gt;: v0.1.11Êñ∞Â¢û4Â§ßÊèê‰æõÂïÜÔºå60+Ê®°ÂûãÔºå‰∏ÄÁ´ôÂºèAI‰ΩìÈ™å&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üíæ ÈÖçÁΩÆÊåÅ‰πÖÂåñ&lt;/strong&gt;: Ê®°ÂûãÈÄâÊã©ÁúüÊ≠£ÊåÅ‰πÖÂåñÔºåURLÂèÇÊï∞Â≠òÂÇ®ÔºåÂà∑Êñ∞‰øùÊåÅ&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üéØ Âø´ÈÄüÂàáÊç¢&lt;/strong&gt;: 5‰∏™ÁÉ≠Èó®Ê®°ÂûãÂø´ÈÄüÊåâÈíÆÔºå‰∏ÄÈîÆÂàáÊç¢‰∏çÂêåAI&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üÜï ÂÆûÊó∂ËøõÂ∫¶&lt;/strong&gt;: v0.1.10ÂºÇÊ≠•ËøõÂ∫¶Ë∑üË∏™ÔºåÂëäÂà´ÈªëÁõíÁ≠âÂæÖ&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üíæ Êô∫ËÉΩ‰ºöËØù&lt;/strong&gt;: Áä∂ÊÄÅÊåÅ‰πÖÂåñÔºåÈ°µÈù¢Âà∑Êñ∞‰∏ç‰∏¢Â§±ÂàÜÊûêÁªìÊûú&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üîê Áî®Êà∑ÊùÉÈôê&lt;/strong&gt;: v0.1.14Êñ∞Â¢ûÂÆåÊï¥ÁöÑÁî®Êà∑ËÆ§ËØÅÂíåÊùÉÈôêÁÆ°ÁêÜ‰ΩìÁ≥ª&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üá®üá≥ ‰∏≠ÂõΩ‰ºòÂåñ&lt;/strong&gt;: AËÇ°/Ê∏ØËÇ°Êï∞ÊçÆ + ÂõΩ‰∫ßLLM + ‰∏≠ÊñáÁïåÈù¢&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üê≥ ÂÆπÂô®Âåñ&lt;/strong&gt;: Docker‰∏ÄÈîÆÈÉ®ÁΩ≤ÔºåÁéØÂ¢ÉÈöîÁ¶ªÔºåÂø´ÈÄüÊâ©Â±ï&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üìÑ ‰∏ì‰∏öÊä•Âëä&lt;/strong&gt;: Â§öÊ†ºÂºèÂØºÂá∫ÔºåËá™Âä®ÁîüÊàêÊäïËµÑÂª∫ËÆÆ&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üõ°Ô∏è Á®≥ÂÆöÂèØÈù†&lt;/strong&gt;: Â§öÂ±ÇÊï∞ÊçÆÊ∫êÔºåÊô∫ËÉΩÈôçÁ∫ßÔºåÈîôËØØÊÅ¢Â§ç&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üîß ÊäÄÊúØÊû∂ÊûÑ&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Ê†∏ÂøÉÊäÄÊúØ&lt;/strong&gt;: Python 3.10+ | LangChain | Streamlit | MongoDB | Redis &lt;strong&gt;AIÊ®°Âûã&lt;/strong&gt;: DeepSeek V3 | ÈòøÈáåÁôæÁÇº | Google AI | OpenRouter(60+Ê®°Âûã) | OpenAI &lt;strong&gt;Êï∞ÊçÆÊ∫ê&lt;/strong&gt;: Tushare | AkShare | FinnHub | Yahoo Finance &lt;strong&gt;ÈÉ®ÁΩ≤&lt;/strong&gt;: Docker | Docker Compose | Êú¨Âú∞ÈÉ®ÁΩ≤&lt;/p&gt; 
&lt;h2&gt;üìö ÊñáÊ°£ÂíåÊîØÊåÅ&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;üìñ ÂÆåÊï¥ÊñáÊ°£&lt;/strong&gt;: &lt;a href="https://raw.githubusercontent.com/hsliuping/TradingAgents-CN/main/docs/"&gt;docs/&lt;/a&gt; - ÂÆâË£ÖÊåáÂçó„ÄÅ‰ΩøÁî®ÊïôÁ®ã„ÄÅAPIÊñáÊ°£&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üö® ÊïÖÈöúÊéíÈô§&lt;/strong&gt;: &lt;a href="https://raw.githubusercontent.com/hsliuping/TradingAgents-CN/main/docs/troubleshooting/"&gt;troubleshooting/&lt;/a&gt; - Â∏∏ËßÅÈóÆÈ¢òËß£ÂÜ≥ÊñπÊ°à&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üîÑ Êõ¥Êñ∞Êó•Âøó&lt;/strong&gt;: &lt;a href="https://raw.githubusercontent.com/hsliuping/TradingAgents-CN/main/docs/releases/CHANGELOG.md"&gt;CHANGELOG.md&lt;/a&gt; - ËØ¶ÁªÜÁâàÊú¨ÂéÜÂè≤&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üöÄ Âø´ÈÄüÂºÄÂßã&lt;/strong&gt;: &lt;a href="https://raw.githubusercontent.com/hsliuping/TradingAgents-CN/main/QUICKSTART.md"&gt;QUICKSTART.md&lt;/a&gt; - 5ÂàÜÈíüÂø´ÈÄüÈÉ®ÁΩ≤ÊåáÂçó&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üÜö ‰∏≠ÊñáÂ¢ûÂº∫ÁâπËâ≤&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Áõ∏ÊØîÂéüÁâàÊñ∞Â¢û&lt;/strong&gt;: Êô∫ËÉΩÊñ∞ÈóªÂàÜÊûê | Â§öÂ±ÇÊ¨°Êñ∞ÈóªËøáÊª§ | Êñ∞ÈóªË¥®ÈáèËØÑ‰º∞ | Áªü‰∏ÄÊñ∞ÈóªÂ∑•ÂÖ∑ | Â§öLLMÊèê‰æõÂïÜÈõÜÊàê | Ê®°ÂûãÈÄâÊã©ÊåÅ‰πÖÂåñ | Âø´ÈÄüÂàáÊç¢ÊåâÈíÆ | | ÂÆûÊó∂ËøõÂ∫¶ÊòæÁ§∫ | Êô∫ËÉΩ‰ºöËØùÁÆ°ÁêÜ | ‰∏≠ÊñáÁïåÈù¢ | AËÇ°Êï∞ÊçÆ | ÂõΩ‰∫ßLLM | DockerÈÉ®ÁΩ≤ | ‰∏ì‰∏öÊä•ÂëäÂØºÂá∫ | Áªü‰∏ÄÊó•ÂøóÁÆ°ÁêÜ | WebÈÖçÁΩÆÁïåÈù¢ | ÊàêÊú¨‰ºòÂåñ&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;DockerÈÉ®ÁΩ≤ÂåÖÂê´ÁöÑÊúçÂä°&lt;/strong&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;üåê &lt;strong&gt;WebÂ∫îÁî®&lt;/strong&gt;: TradingAgents-CN‰∏ªÁ®ãÂ∫è&lt;/li&gt; 
 &lt;li&gt;üóÑÔ∏è &lt;strong&gt;MongoDB&lt;/strong&gt;: Êï∞ÊçÆÊåÅ‰πÖÂåñÂ≠òÂÇ®&lt;/li&gt; 
 &lt;li&gt;‚ö° &lt;strong&gt;Redis&lt;/strong&gt;: È´òÈÄüÁºìÂ≠ò&lt;/li&gt; 
 &lt;li&gt;üìä &lt;strong&gt;MongoDB Express&lt;/strong&gt;: Êï∞ÊçÆÂ∫ìÁÆ°ÁêÜÁïåÈù¢&lt;/li&gt; 
 &lt;li&gt;üéõÔ∏è &lt;strong&gt;Redis Commander&lt;/strong&gt;: ÁºìÂ≠òÁÆ°ÁêÜÁïåÈù¢&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;üíª ÊñπÂºè‰∫åÔºöÊú¨Âú∞ÈÉ®ÁΩ≤&lt;/h4&gt; 
&lt;p&gt;&lt;strong&gt;ÈÄÇÁî®Âú∫ÊôØ&lt;/strong&gt;: ÂºÄÂèëÁéØÂ¢É„ÄÅËá™ÂÆö‰πâÈÖçÁΩÆ„ÄÅÁ¶ªÁ∫ø‰ΩøÁî®&lt;/p&gt; 
&lt;h3&gt;ÁéØÂ¢ÉË¶ÅÊ±Ç&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Python 3.10+ (Êé®Ëçê 3.11)&lt;/li&gt; 
 &lt;li&gt;4GB+ RAM (Êé®Ëçê 8GB+)&lt;/li&gt; 
 &lt;li&gt;Á®≥ÂÆöÁöÑÁΩëÁªúËøûÊé•&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;ÂÆâË£ÖÊ≠•È™§&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# 1. ÂÖãÈöÜÈ°πÁõÆ
git clone https://github.com/hsliuping/TradingAgents-CN.git
cd TradingAgents-CN

# 2. ÂàõÂª∫ËôöÊãüÁéØÂ¢É
python -m venv env
# Windows
env\Scripts\activate
# Linux/macOS
source env/bin/activate

# 3. ÂçáÁ∫ßpip
python -m pip install --upgrade pip

# 4. ÂÆâË£ÖÊâÄÊúâ‰æùËµñ
pip install -r requirements.txt
#ÊàñËÄÖ‰ΩøÁî®pip install -e .
pip install -e .

# Ê≥®ÊÑèÔºörequirements.txtÂ∑≤ÂåÖÂê´ÊâÄÊúâÂøÖÈúÄ‰æùËµñÔºö
# - Êï∞ÊçÆÂ∫ìÊîØÊåÅ (MongoDB + Redis)
# - Â§öÂ∏ÇÂú∫Êï∞ÊçÆÊ∫ê (Tushare, AKShare, FinnHubÁ≠â)
# - WebÁïåÈù¢ÂíåÊä•ÂëäÂØºÂá∫ÂäüËÉΩ
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;ÈÖçÁΩÆAPIÂØÜÈí•&lt;/h3&gt; 
&lt;h4&gt;üá®üá≥ Êé®ËçêÔºö‰ΩøÁî®ÈòøÈáåÁôæÁÇºÔºàÂõΩ‰∫ßÂ§ßÊ®°ÂûãÔºâ&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Â§çÂà∂ÈÖçÁΩÆÊ®°Êùø
cp .env.example .env

# ÁºñËæë .env Êñá‰ª∂ÔºåÈÖçÁΩÆ‰ª•‰∏ãÂøÖÈúÄÁöÑAPIÂØÜÈí•Ôºö
DASHSCOPE_API_KEY=your_dashscope_api_key_here
FINNHUB_API_KEY=your_finnhub_api_key_here

# Êé®ËçêÔºöTushare APIÔºà‰∏ì‰∏öAËÇ°Êï∞ÊçÆÔºâ
TUSHARE_TOKEN=your_tushare_token_here
TUSHARE_ENABLED=true

# ÂèØÈÄâÔºöÂÖ∂‰ªñAIÊ®°ÂûãAPI
GOOGLE_API_KEY=your_google_api_key_here
DEEPSEEK_API_KEY=your_deepseek_api_key_here

# Êï∞ÊçÆÂ∫ìÈÖçÁΩÆÔºàÂèØÈÄâÔºåÊèêÂçáÊÄßËÉΩÔºâ
# Êú¨Âú∞ÈÉ®ÁΩ≤‰ΩøÁî®Ê†áÂáÜÁ´ØÂè£
MONGODB_ENABLED=false  # ËÆæ‰∏∫trueÂêØÁî®MongoDB
REDIS_ENABLED=false    # ËÆæ‰∏∫trueÂêØÁî®Redis
MONGODB_HOST=localhost
MONGODB_PORT=27017     # Ê†áÂáÜMongoDBÁ´ØÂè£
REDIS_HOST=localhost
REDIS_PORT=6379        # Ê†áÂáÜRedisÁ´ØÂè£

# DockerÈÉ®ÁΩ≤Êó∂ÈúÄË¶Å‰øÆÊîπ‰∏ªÊú∫Âêç
# MONGODB_HOST=mongodb
# REDIS_HOST=redis
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;üìã ÈÉ®ÁΩ≤Ê®°ÂºèÈÖçÁΩÆËØ¥Êòé&lt;/h4&gt; 
&lt;p&gt;&lt;strong&gt;Êú¨Âú∞ÈÉ®ÁΩ≤Ê®°Âºè&lt;/strong&gt;Ôºö&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Êï∞ÊçÆÂ∫ìÈÖçÁΩÆÔºàÊú¨Âú∞ÈÉ®ÁΩ≤Ôºâ
MONGODB_ENABLED=true
REDIS_ENABLED=true
MONGODB_HOST=localhost      # Êú¨Âú∞‰∏ªÊú∫
MONGODB_PORT=27017         # Ê†áÂáÜÁ´ØÂè£
REDIS_HOST=localhost       # Êú¨Âú∞‰∏ªÊú∫
REDIS_PORT=6379           # Ê†áÂáÜÁ´ØÂè£
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;DockerÈÉ®ÁΩ≤Ê®°Âºè&lt;/strong&gt;Ôºö&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Êï∞ÊçÆÂ∫ìÈÖçÁΩÆÔºàDockerÈÉ®ÁΩ≤Ôºâ
MONGODB_ENABLED=true
REDIS_ENABLED=true
MONGODB_HOST=mongodb       # DockerÂÆπÂô®ÊúçÂä°Âêç
MONGODB_PORT=27017        # Ê†áÂáÜÁ´ØÂè£
REDIS_HOST=redis          # DockerÂÆπÂô®ÊúçÂä°Âêç
REDIS_PORT=6379          # Ê†áÂáÜÁ´ØÂè£
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;üí° &lt;strong&gt;ÈÖçÁΩÆÊèêÁ§∫&lt;/strong&gt;Ôºö&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Êú¨Âú∞ÈÉ®ÁΩ≤ÔºöÈúÄË¶ÅÊâãÂä®ÂêØÂä®MongoDBÂíåRedisÊúçÂä°&lt;/li&gt; 
  &lt;li&gt;DockerÈÉ®ÁΩ≤ÔºöÊï∞ÊçÆÂ∫ìÊúçÂä°ÈÄöËøádocker-composeËá™Âä®ÂêØÂä®&lt;/li&gt; 
  &lt;li&gt;Á´ØÂè£ÂÜ≤Á™ÅÔºöÂ¶ÇÊûúÊú¨Âú∞Â∑≤ÊúâÊï∞ÊçÆÂ∫ìÊúçÂä°ÔºåÂèØ‰øÆÊîπdocker-compose.yml‰∏≠ÁöÑÁ´ØÂè£Êò†Â∞Ñ&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;üåç ÂèØÈÄâÔºö‰ΩøÁî®ÂõΩÂ§ñÊ®°Âûã&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# OpenAI (ÈúÄË¶ÅÁßëÂ≠¶‰∏äÁΩë)
OPENAI_API_KEY=your_openai_api_key

# Anthropic (ÈúÄË¶ÅÁßëÂ≠¶‰∏äÁΩë)
ANTHROPIC_API_KEY=your_anthropic_api_key
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;üóÑÔ∏è Êï∞ÊçÆÂ∫ìÈÖçÁΩÆÔºàMongoDB + RedisÔºâ&lt;/h3&gt; 
&lt;h4&gt;È´òÊÄßËÉΩÊï∞ÊçÆÂ≠òÂÇ®ÊîØÊåÅ&lt;/h4&gt; 
&lt;p&gt;Êú¨È°πÁõÆÊîØÊåÅ &lt;strong&gt;MongoDB&lt;/strong&gt; Âíå &lt;strong&gt;Redis&lt;/strong&gt; Êï∞ÊçÆÂ∫ìÔºåÊèê‰æõÔºö&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;üìä ËÇ°Á•®Êï∞ÊçÆÁºìÂ≠ò&lt;/strong&gt;: ÂáèÂ∞ëAPIË∞ÉÁî®ÔºåÊèêÂçáÂìçÂ∫îÈÄüÂ∫¶&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üîÑ Êô∫ËÉΩÈôçÁ∫ßÊú∫Âà∂&lt;/strong&gt;: MongoDB ‚Üí API ‚Üí Êú¨Âú∞ÁºìÂ≠òÁöÑÂ§öÂ±ÇÊï∞ÊçÆÊ∫ê&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;‚ö° È´òÊÄßËÉΩÁºìÂ≠ò&lt;/strong&gt;: RedisÁºìÂ≠òÁÉ≠ÁÇπÊï∞ÊçÆÔºåÊØ´ÁßíÁ∫ßÂìçÂ∫î&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üõ°Ô∏è Êï∞ÊçÆÊåÅ‰πÖÂåñ&lt;/strong&gt;: MongoDBÂ≠òÂÇ®ÂéÜÂè≤Êï∞ÊçÆÔºåÊîØÊåÅÁ¶ªÁ∫øÂàÜÊûê&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Êï∞ÊçÆÂ∫ìÈÉ®ÁΩ≤ÊñπÂºè&lt;/h4&gt; 
&lt;p&gt;&lt;strong&gt;üê≥ DockerÈÉ®ÁΩ≤ÔºàÊé®ËçêÔºâ&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Â¶ÇÊûúÊÇ®‰ΩøÁî®DockerÈÉ®ÁΩ≤ÔºåÊï∞ÊçÆÂ∫ìÂ∑≤Ëá™Âä®ÂåÖÂê´Âú®ÂÜÖÔºö&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# DockerÈÉ®ÁΩ≤‰ºöËá™Âä®ÂêØÂä®ÊâÄÊúâÊúçÂä°ÔºåÂåÖÊã¨Ôºö
docker-compose up -d --build
# - WebÂ∫îÁî® (Á´ØÂè£8501)
# - MongoDB (Á´ØÂè£27017)
# - Redis (Á´ØÂè£6379)
# - Êï∞ÊçÆÂ∫ìÁÆ°ÁêÜÁïåÈù¢ (Á´ØÂè£8081, 8082)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;üíª Êú¨Âú∞ÈÉ®ÁΩ≤ - Êï∞ÊçÆÂ∫ìÈÖçÁΩÆ&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Â¶ÇÊûúÊÇ®‰ΩøÁî®Êú¨Âú∞ÈÉ®ÁΩ≤ÔºåÂèØ‰ª•ÈÄâÊã©‰ª•‰∏ãÊñπÂºèÔºö&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;ÊñπÂºè‰∏ÄÔºö‰ªÖÂêØÂä®Êï∞ÊçÆÂ∫ìÊúçÂä°&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# ‰ªÖÂêØÂä® MongoDB + Redis ÊúçÂä°Ôºà‰∏çÂêØÂä®WebÂ∫îÁî®Ôºâ
docker-compose up -d mongodb redis mongo-express redis-commander

# Êü•ÁúãÊúçÂä°Áä∂ÊÄÅ
docker-compose ps

# ÂÅúÊ≠¢ÊúçÂä°
docker-compose down
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;ÊñπÂºè‰∫åÔºöÂÆåÂÖ®Êú¨Âú∞ÂÆâË£Ö&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Êï∞ÊçÆÂ∫ì‰æùËµñÂ∑≤ÂåÖÂê´Âú®requirements.txt‰∏≠ÔºåÊó†ÈúÄÈ¢ùÂ§ñÂÆâË£Ö

# ÂêØÂä® MongoDB (ÈªòËÆ§Á´ØÂè£ 27017)
mongod --dbpath ./data/mongodb

# ÂêØÂä® Redis (ÈªòËÆ§Á´ØÂè£ 6379)
redis-server
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;‚ö†Ô∏è &lt;strong&gt;ÈáçË¶ÅËØ¥Êòé&lt;/strong&gt;:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;üê≥ DockerÈÉ®ÁΩ≤&lt;/strong&gt;: Êï∞ÊçÆÂ∫ìËá™Âä®ÂåÖÂê´ÔºåÊó†ÈúÄÈ¢ùÂ§ñÈÖçÁΩÆ&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;üíª Êú¨Âú∞ÈÉ®ÁΩ≤&lt;/strong&gt;: ÂèØÈÄâÊã©‰ªÖÂêØÂä®Êï∞ÊçÆÂ∫ìÊúçÂä°ÊàñÂÆåÂÖ®Êú¨Âú∞ÂÆâË£Ö&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;üìã Êé®Ëçê&lt;/strong&gt;: ‰ΩøÁî®DockerÈÉ®ÁΩ≤‰ª•Ëé∑ÂæóÊúÄ‰Ω≥‰ΩìÈ™åÂíå‰∏ÄËá¥ÊÄß&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;Êï∞ÊçÆÂ∫ìÈÖçÁΩÆÈÄâÈ°π&lt;/h4&gt; 
&lt;p&gt;&lt;strong&gt;ÁéØÂ¢ÉÂèòÈáèÈÖçÁΩÆ&lt;/strong&gt;ÔºàÊé®ËçêÔºâÔºö&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# MongoDB ÈÖçÁΩÆ
MONGODB_HOST=localhost
MONGODB_PORT=27017
MONGODB_DATABASE=trading_agents
MONGODB_USERNAME=admin
MONGODB_PASSWORD=your_password

# Redis ÈÖçÁΩÆ
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_PASSWORD=your_redis_password
REDIS_DB=0
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;ÈÖçÁΩÆÊñá‰ª∂ÊñπÂºè&lt;/strong&gt;Ôºö&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# config/database_config.py
DATABASE_CONFIG = {
    'mongodb': {
        'host': 'localhost',
        'port': 27017,
        'database': 'trading_agents',
        'username': 'admin',
        'password': 'your_password'
    },
    'redis': {
        'host': 'localhost',
        'port': 6379,
        'password': 'your_redis_password',
        'db': 0
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Êï∞ÊçÆÂ∫ìÂäüËÉΩÁâπÊÄß&lt;/h4&gt; 
&lt;p&gt;&lt;strong&gt;MongoDB ÂäüËÉΩ&lt;/strong&gt;Ôºö&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;‚úÖ ËÇ°Á•®Âü∫Á°Ä‰ø°ÊÅØÂ≠òÂÇ®&lt;/li&gt; 
 &lt;li&gt;‚úÖ ÂéÜÂè≤‰ª∑Ê†ºÊï∞ÊçÆÁºìÂ≠ò&lt;/li&gt; 
 &lt;li&gt;‚úÖ ÂàÜÊûêÁªìÊûúÊåÅ‰πÖÂåñ&lt;/li&gt; 
 &lt;li&gt;‚úÖ Áî®Êà∑ÈÖçÁΩÆÁÆ°ÁêÜ&lt;/li&gt; 
 &lt;li&gt;‚úÖ Ëá™Âä®Êï∞ÊçÆÂêåÊ≠•&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Redis ÂäüËÉΩ&lt;/strong&gt;Ôºö&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;‚ö° ÂÆûÊó∂‰ª∑Ê†ºÊï∞ÊçÆÁºìÂ≠ò&lt;/li&gt; 
 &lt;li&gt;‚ö° APIÂìçÂ∫îÁªìÊûúÁºìÂ≠ò&lt;/li&gt; 
 &lt;li&gt;‚ö° ‰ºöËØùÁä∂ÊÄÅÁÆ°ÁêÜ&lt;/li&gt; 
 &lt;li&gt;‚ö° ÁÉ≠ÁÇπÊï∞ÊçÆÈ¢ÑÂä†ËΩΩ&lt;/li&gt; 
 &lt;li&gt;‚ö° ÂàÜÂ∏ÉÂºèÈîÅÊîØÊåÅ&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Êô∫ËÉΩÈôçÁ∫ßÊú∫Âà∂&lt;/h4&gt; 
&lt;p&gt;Á≥ªÁªüÈááÁî®Â§öÂ±ÇÊï∞ÊçÆÊ∫êÈôçÁ∫ßÁ≠ñÁï•ÔºåÁ°Æ‰øùÈ´òÂèØÁî®ÊÄßÔºö&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;üìä Êï∞ÊçÆËé∑ÂèñÊµÅÁ®ãÔºö
1. üîç Ê£ÄÊü• Redis ÁºìÂ≠ò (ÊØ´ÁßíÁ∫ß)
2. üìö Êü•ËØ¢ MongoDB Â≠òÂÇ® (ÁßíÁ∫ß)
3. üåê Ë∞ÉÁî®ÈÄöËææ‰ø°API (ÁßíÁ∫ß)
4. üíæ Êú¨Âú∞Êñá‰ª∂ÁºìÂ≠ò (Â§áÁî®)
5. ‚ùå ËøîÂõûÈîôËØØ‰ø°ÊÅØ
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;ÈÖçÁΩÆÈôçÁ∫ßÁ≠ñÁï•&lt;/strong&gt;Ôºö&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# Âú® .env Êñá‰ª∂‰∏≠ÈÖçÁΩÆ
ENABLE_MONGODB=true
ENABLE_REDIS=true
ENABLE_FALLBACK=true

# ÁºìÂ≠òËøáÊúüÊó∂Èó¥ÔºàÁßíÔºâ
REDIS_CACHE_TTL=300
MONGODB_CACHE_TTL=3600
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;ÊÄßËÉΩ‰ºòÂåñÂª∫ËÆÆ&lt;/h4&gt; 
&lt;p&gt;&lt;strong&gt;Áîü‰∫ßÁéØÂ¢ÉÈÖçÁΩÆ&lt;/strong&gt;Ôºö&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# MongoDB ‰ºòÂåñ
MONGODB_MAX_POOL_SIZE=50
MONGODB_MIN_POOL_SIZE=5
MONGODB_MAX_IDLE_TIME=30000

# Redis ‰ºòÂåñ
REDIS_MAX_CONNECTIONS=20
REDIS_CONNECTION_POOL_SIZE=10
REDIS_SOCKET_TIMEOUT=5
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Êï∞ÊçÆÂ∫ìÁÆ°ÁêÜÂ∑•ÂÖ∑&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# ÂàùÂßãÂåñÊï∞ÊçÆÂ∫ì
python scripts/setup/init_database.py

# Á≥ªÁªüÁä∂ÊÄÅÊ£ÄÊü•
python scripts/validation/check_system_status.py

# Ê∏ÖÁêÜÁºìÂ≠òÂ∑•ÂÖ∑
python scripts/maintenance/cleanup_cache.py --days 7
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;ÊïÖÈöúÊéíÈô§&lt;/h4&gt; 
&lt;p&gt;&lt;strong&gt;Â∏∏ËßÅÈóÆÈ¢òËß£ÂÜ≥&lt;/strong&gt;Ôºö&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;ü™ü Windows 10 ChromaDBÂÖºÂÆπÊÄßÈóÆÈ¢ò&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;&lt;strong&gt;ÈóÆÈ¢òÁé∞Ë±°&lt;/strong&gt;ÔºöÂú®Windows 10‰∏äÂá∫Áé∞ &lt;code&gt;Configuration error: An instance of Chroma already exists for ephemeral with different settings&lt;/code&gt; ÈîôËØØÔºåËÄåWindows 11Ê≠£Â∏∏„ÄÇ&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Âø´ÈÄüËß£ÂÜ≥ÊñπÊ°à&lt;/strong&gt;Ôºö&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;# ÊñπÊ°à1ÔºöÁ¶ÅÁî®ÂÜÖÂ≠òÂäüËÉΩÔºàÊé®ËçêÔºâ
# Âú® .env Êñá‰ª∂‰∏≠Ê∑ªÂä†Ôºö
MEMORY_ENABLED=false

# ÊñπÊ°à2Ôºö‰ΩøÁî®‰∏ìÁî®‰øÆÂ§çËÑöÊú¨
powershell -ExecutionPolicy Bypass -File scripts\fix_chromadb_win10.ps1

# ÊñπÊ°à3ÔºöÁÆ°ÁêÜÂëòÊùÉÈôêËøêË°å
# Âè≥ÈîÆPowerShell -&amp;gt; "‰ª•ÁÆ°ÁêÜÂëòË∫´‰ªΩËøêË°å"
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&lt;strong&gt;ËØ¶ÁªÜËß£ÂÜ≥ÊñπÊ°à&lt;/strong&gt;ÔºöÂèÇËÄÉ &lt;a href="https://raw.githubusercontent.com/hsliuping/TradingAgents-CN/main/docs/troubleshooting/windows10-chromadb-fix.md"&gt;Windows 10ÂÖºÂÆπÊÄßÊåáÂçó&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;MongoDBËøûÊé•Â§±Ë¥•&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;&lt;strong&gt;DockerÈÉ®ÁΩ≤&lt;/strong&gt;Ôºö&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;# Ê£ÄÊü•ÊúçÂä°Áä∂ÊÄÅ
docker-compose logs mongodb

# ÈáçÂêØÊúçÂä°
docker-compose restart mongodb
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&lt;strong&gt;Êú¨Âú∞ÈÉ®ÁΩ≤&lt;/strong&gt;Ôºö&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;# Ê£ÄÊü•MongoDBËøõÁ®ã
ps aux | grep mongod

# ÈáçÂêØMongoDB
sudo systemctl restart mongod  # Linux
brew services restart mongodb  # macOS
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;RedisËøûÊé•Ë∂ÖÊó∂&lt;/strong&gt;&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;# Ê£ÄÊü•RedisÁä∂ÊÄÅ
redis-cli ping

# Ê∏ÖÁêÜRedisÁºìÂ≠ò
redis-cli flushdb
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;ÁºìÂ≠òÈóÆÈ¢ò&lt;/strong&gt;&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;# Ê£ÄÊü•Á≥ªÁªüÁä∂ÊÄÅÂíåÁºìÂ≠ò
python scripts/validation/check_system_status.py

# Ê∏ÖÁêÜËøáÊúüÁºìÂ≠ò
python scripts/maintenance/cleanup_cache.py --days 7
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;üí° &lt;strong&gt;ÊèêÁ§∫&lt;/strong&gt;: Âç≥‰Ωø‰∏çÈÖçÁΩÆÊï∞ÊçÆÂ∫ìÔºåÁ≥ªÁªü‰ªçÂèØÊ≠£Â∏∏ËøêË°åÔºå‰ºöËá™Âä®ÈôçÁ∫ßÂà∞APIÁõ¥Êé•Ë∞ÉÁî®Ê®°Âºè„ÄÇÊï∞ÊçÆÂ∫ìÈÖçÁΩÆÊòØÂèØÈÄâÁöÑÊÄßËÉΩ‰ºòÂåñÂäüËÉΩ„ÄÇ&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;üìö &lt;strong&gt;ËØ¶ÁªÜÊñáÊ°£&lt;/strong&gt;: Êõ¥Â§öÊï∞ÊçÆÂ∫ìÈÖçÁΩÆ‰ø°ÊÅØËØ∑ÂèÇËÄÉ &lt;a href="https://raw.githubusercontent.com/hsliuping/TradingAgents-CN/main/docs/architecture/database-architecture.md"&gt;Êï∞ÊçÆÂ∫ìÊû∂ÊûÑÊñáÊ°£&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;üì§ Êä•ÂëäÂØºÂá∫ÂäüËÉΩ&lt;/h3&gt; 
&lt;h4&gt;Êñ∞Â¢ûÂäüËÉΩÔºö‰∏ì‰∏öÂàÜÊûêÊä•ÂëäÂØºÂá∫&lt;/h4&gt; 
&lt;p&gt;Êú¨È°πÁõÆÁé∞Â∑≤ÊîØÊåÅÂ∞ÜËÇ°Á•®ÂàÜÊûêÁªìÊûúÂØºÂá∫‰∏∫Â§öÁßç‰∏ì‰∏öÊ†ºÂºèÔºö&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;ÊîØÊåÅÁöÑÂØºÂá∫Ê†ºÂºè&lt;/strong&gt;Ôºö&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;üìÑ Markdown (.md)&lt;/strong&gt; - ËΩªÈáèÁ∫ßÊ†áËÆ∞ËØ≠Ë®ÄÔºåÈÄÇÂêàÊäÄÊúØÁî®Êà∑ÂíåÁâàÊú¨ÊéßÂà∂&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üìù Word (.docx)&lt;/strong&gt; - Microsoft WordÊñáÊ°£ÔºåÈÄÇÂêàÂïÜÂä°Êä•ÂëäÂíåËøõ‰∏ÄÊ≠•ÁºñËæë&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üìä PDF (.pdf)&lt;/strong&gt; - ‰æøÊê∫ÂºèÊñáÊ°£Ê†ºÂºèÔºåÈÄÇÂêàÊ≠£ÂºèÂàÜ‰∫´ÂíåÊâìÂç∞&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Êä•ÂëäÂÜÖÂÆπÁªìÊûÑ&lt;/strong&gt;Ôºö&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;üéØ &lt;strong&gt;ÊäïËµÑÂÜ≥Á≠ñÊëòË¶Å&lt;/strong&gt; - ‰π∞ÂÖ•/ÊåÅÊúâ/ÂçñÂá∫Âª∫ËÆÆÔºåÁΩÆ‰ø°Â∫¶ÔºåÈ£éÈô©ËØÑÂàÜ&lt;/li&gt; 
 &lt;li&gt;üìä &lt;strong&gt;ËØ¶ÁªÜÂàÜÊûêÊä•Âëä&lt;/strong&gt; - ÊäÄÊúØÂàÜÊûêÔºåÂü∫Êú¨Èù¢ÂàÜÊûêÔºåÂ∏ÇÂú∫ÊÉÖÁª™ÔºåÊñ∞Èóª‰∫ã‰ª∂&lt;/li&gt; 
 &lt;li&gt;‚ö†Ô∏è &lt;strong&gt;È£éÈô©ÊèêÁ§∫&lt;/strong&gt; - ÂÆåÊï¥ÁöÑÊäïËµÑÈ£éÈô©Â£∞ÊòéÂíåÂÖçË¥£Êù°Ê¨æ&lt;/li&gt; 
 &lt;li&gt;üìã &lt;strong&gt;ÈÖçÁΩÆ‰ø°ÊÅØ&lt;/strong&gt; - ÂàÜÊûêÂèÇÊï∞ÔºåÊ®°Âûã‰ø°ÊÅØÔºåÁîüÊàêÊó∂Èó¥&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;‰ΩøÁî®ÊñπÊ≥ï&lt;/strong&gt;Ôºö&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;ÂÆåÊàêËÇ°Á•®ÂàÜÊûêÂêéÔºåÂú®ÁªìÊûúÈ°µÈù¢Â∫ïÈÉ®ÊâæÂà∞"üì§ ÂØºÂá∫Êä•Âëä"ÈÉ®ÂàÜ&lt;/li&gt; 
 &lt;li&gt;ÈÄâÊã©ÈúÄË¶ÅÁöÑÊ†ºÂºèÔºöMarkdown„ÄÅWordÊàñPDF&lt;/li&gt; 
 &lt;li&gt;ÁÇπÂáªÂØºÂá∫ÊåâÈíÆÔºåÁ≥ªÁªüËá™Âä®ÁîüÊàêÂπ∂Êèê‰æõ‰∏ãËΩΩ&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;ÂÆâË£ÖÂØºÂá∫‰æùËµñ&lt;/strong&gt;Ôºö&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# ÂÆâË£ÖPython‰æùËµñ
pip install markdown pypandoc

# ÂÆâË£ÖÁ≥ªÁªüÂ∑•ÂÖ∑ÔºàÁî®‰∫éPDFÂØºÂá∫Ôºâ
# Windows: choco install pandoc wkhtmltopdf
# macOS: brew install pandoc wkhtmltopdf
# Linux: sudo apt-get install pandoc wkhtmltopdf
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;üìö &lt;strong&gt;ËØ¶ÁªÜÊñáÊ°£&lt;/strong&gt;: ÂÆåÊï¥ÁöÑÂØºÂá∫ÂäüËÉΩ‰ΩøÁî®ÊåáÂçóËØ∑ÂèÇËÄÉ &lt;a href="https://raw.githubusercontent.com/hsliuping/TradingAgents-CN/main/docs/EXPORT_GUIDE.md"&gt;ÂØºÂá∫ÂäüËÉΩÊåáÂçó&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;üöÄ ÂêØÂä®Â∫îÁî®&lt;/h3&gt; 
&lt;h4&gt;üê≥ DockerÂêØÂä®ÔºàÊé®ËçêÔºâ&lt;/h4&gt; 
&lt;p&gt;Â¶ÇÊûúÊÇ®‰ΩøÁî®DockerÈÉ®ÁΩ≤ÔºåÂ∫îÁî®Â∑≤ÁªèËá™Âä®ÂêØÂä®Ôºö&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Â∫îÁî®Â∑≤Âú®Docker‰∏≠ËøêË°åÔºåÁõ¥Êé•ËÆøÈóÆÔºö
# WebÁïåÈù¢: http://localhost:8501
# Êï∞ÊçÆÂ∫ìÁÆ°ÁêÜ: http://localhost:8081
# ÁºìÂ≠òÁÆ°ÁêÜ: http://localhost:8082

# Êü•ÁúãËøêË°åÁä∂ÊÄÅ
docker-compose ps

# Êü•ÁúãÊó•Âøó
docker-compose logs -f web
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;üíª Êú¨Âú∞ÂêØÂä®&lt;/h4&gt; 
&lt;p&gt;Â¶ÇÊûúÊÇ®‰ΩøÁî®Êú¨Âú∞ÈÉ®ÁΩ≤Ôºö&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# 1. ÊøÄÊ¥ªËôöÊãüÁéØÂ¢É
# Windows
.\env\Scripts\activate
# Linux/macOS
source env/bin/activate

# 2. ÂÆâË£ÖÈ°πÁõÆÂà∞ËôöÊãüÁéØÂ¢ÉÔºàÈáçË¶ÅÔºÅÔºâ
pip install -e .

# 3. ÂêØÂä®WebÁÆ°ÁêÜÁïåÈù¢
# ÊñπÊ≥ï1Ôºö‰ΩøÁî®È°πÁõÆÂêØÂä®ËÑöÊú¨ÔºàÊé®ËçêÔºâ
python start_web.py

# ÊñπÊ≥ï2Ôºö‰ΩøÁî®ÂéüÂßãÂêØÂä®ËÑöÊú¨
python web/run_web.py

# ÊñπÊ≥ï3ÔºöÁõ¥Êé•‰ΩøÁî®streamlitÔºàÈúÄË¶ÅÂÖàÂÆâË£ÖÈ°πÁõÆÔºâ
streamlit run web/app.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;ÁÑ∂ÂêéÂú®ÊµèËßàÂô®‰∏≠ËÆøÈóÆ &lt;code&gt;http://localhost:8501&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;WebÁïåÈù¢ÁâπËâ≤ÂäüËÉΩ&lt;/strong&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;üá∫üá∏ &lt;strong&gt;ÁæéËÇ°ÂàÜÊûê&lt;/strong&gt;: ÊîØÊåÅ AAPL, TSLA, NVDA Á≠âÁæéËÇ°‰ª£Á†Å&lt;/li&gt; 
 &lt;li&gt;üá®üá≥ &lt;strong&gt;AËÇ°ÂàÜÊûê&lt;/strong&gt;: ÊîØÊåÅ 000001, 600519, 300750 Á≠âAËÇ°‰ª£Á†Å&lt;/li&gt; 
 &lt;li&gt;üìä &lt;strong&gt;ÂÆûÊó∂Êï∞ÊçÆ&lt;/strong&gt;: ÈÄöËææ‰ø°APIÊèê‰æõAËÇ°ÂÆûÊó∂Ë°åÊÉÖÊï∞ÊçÆ&lt;/li&gt; 
 &lt;li&gt;ü§ñ &lt;strong&gt;Êô∫ËÉΩ‰ΩìÈÄâÊã©&lt;/strong&gt;: ÂèØÈÄâÊã©‰∏çÂêåÁöÑÂàÜÊûêÂ∏àÁªÑÂêà&lt;/li&gt; 
 &lt;li&gt;üì§ &lt;strong&gt;Êä•ÂëäÂØºÂá∫&lt;/strong&gt;: ‰∏ÄÈîÆÂØºÂá∫Markdown/Word/PDFÊ†ºÂºè‰∏ì‰∏öÂàÜÊûêÊä•Âëä&lt;/li&gt; 
 &lt;li&gt;üéØ &lt;strong&gt;5Á∫ßÁ†îÁ©∂Ê∑±Â∫¶&lt;/strong&gt;: ‰ªéÂø´ÈÄüÂàÜÊûê(2-4ÂàÜÈíü)Âà∞ÂÖ®Èù¢ÂàÜÊûê(15-25ÂàÜÈíü)&lt;/li&gt; 
 &lt;li&gt;üìä &lt;strong&gt;Êô∫ËÉΩÂàÜÊûêÂ∏àÈÄâÊã©&lt;/strong&gt;: Â∏ÇÂú∫ÊäÄÊúØ„ÄÅÂü∫Êú¨Èù¢„ÄÅÊñ∞Èóª„ÄÅÁ§æ‰∫§Â™í‰ΩìÂàÜÊûêÂ∏à&lt;/li&gt; 
 &lt;li&gt;üîÑ &lt;strong&gt;ÂÆûÊó∂ËøõÂ∫¶ÊòæÁ§∫&lt;/strong&gt;: ÂèØËßÜÂåñÂàÜÊûêËøáÁ®ãÔºåÈÅøÂÖçÁ≠âÂæÖÁÑ¶Ëôë&lt;/li&gt; 
 &lt;li&gt;üìà &lt;strong&gt;ÁªìÊûÑÂåñÁªìÊûú&lt;/strong&gt;: ÊäïËµÑÂª∫ËÆÆ„ÄÅÁõÆÊ†á‰ª∑‰Ωç„ÄÅÁΩÆ‰ø°Â∫¶„ÄÅÈ£éÈô©ËØÑ‰º∞&lt;/li&gt; 
 &lt;li&gt;üá®üá≥ &lt;strong&gt;ÂÆåÂÖ®‰∏≠ÊñáÂåñ&lt;/strong&gt;: ÁïåÈù¢ÂíåÂàÜÊûêÁªìÊûúÂÖ®‰∏≠ÊñáÊòæÁ§∫&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Á†îÁ©∂Ê∑±Â∫¶Á∫ßÂà´ËØ¥Êòé&lt;/strong&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;1Á∫ß - Âø´ÈÄüÂàÜÊûê&lt;/strong&gt; (2-4ÂàÜÈíü): Êó•Â∏∏ÁõëÊéßÔºåÂü∫Á°ÄÂÜ≥Á≠ñ&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;2Á∫ß - Âü∫Á°ÄÂàÜÊûê&lt;/strong&gt; (4-6ÂàÜÈíü): Â∏∏ËßÑÊäïËµÑÔºåÂπ≥Ë°°ÈÄüÂ∫¶&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;3Á∫ß - Ê†áÂáÜÂàÜÊûê&lt;/strong&gt; (6-10ÂàÜÈíü): ÈáçË¶ÅÂÜ≥Á≠ñÔºåÊé®ËçêÈªòËÆ§&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;4Á∫ß - Ê∑±Â∫¶ÂàÜÊûê&lt;/strong&gt; (10-15ÂàÜÈíü): ÈáçÂ§ßÊäïËµÑÔºåËØ¶ÁªÜÁ†îÁ©∂&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;5Á∫ß - ÂÖ®Èù¢ÂàÜÊûê&lt;/strong&gt; (15-25ÂàÜÈíü): ÊúÄÈáçË¶ÅÂÜ≥Á≠ñÔºåÊúÄÂÖ®Èù¢ÂàÜÊûê&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;üíª ‰ª£Á†ÅË∞ÉÁî®ÔºàÈÄÇÂêàÂºÄÂèëËÄÖÔºâ&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from tradingagents.graph.trading_graph import TradingAgentsGraph
from tradingagents.default_config import DEFAULT_CONFIG

# ÈÖçÁΩÆÈòøÈáåÁôæÁÇº
config = DEFAULT_CONFIG.copy()
config["llm_provider"] = "dashscope"
config["deep_think_llm"] = "qwen-plus"      # Ê∑±Â∫¶ÂàÜÊûê
config["quick_think_llm"] = "qwen-turbo"    # Âø´ÈÄü‰ªªÂä°

# ÂàõÂª∫‰∫§ÊòìÊô∫ËÉΩ‰Ωì
ta = TradingAgentsGraph(debug=True, config=config)

# ÂàÜÊûêËÇ°Á•® (‰ª•ËãπÊûúÂÖ¨Âè∏‰∏∫‰æã)
state, decision = ta.propagate("AAPL", "2024-01-15")

# ËæìÂá∫ÂàÜÊûêÁªìÊûú
print(f"Êé®ËçêÂä®‰Ωú: {decision['action']}")
print(f"ÁΩÆ‰ø°Â∫¶: {decision['confidence']:.1%}")
print(f"È£éÈô©ËØÑÂàÜ: {decision['risk_score']:.1%}")
print(f"Êé®ÁêÜËøáÁ®ã: {decision['reasoning']}")
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Âø´ÈÄüÂêØÂä®ËÑöÊú¨&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# ÈòøÈáåÁôæÁÇºÊºîÁ§∫ÔºàÊé®Ëçê‰∏≠ÊñáÁî®Êà∑Ôºâ
python examples/dashscope/demo_dashscope_chinese.py

# ÈòøÈáåÁôæÁÇºÂÆåÊï¥ÊºîÁ§∫
python examples/dashscope/demo_dashscope.py

# ÈòøÈáåÁôæÁÇºÁÆÄÂåñÊµãËØï
python examples/dashscope/demo_dashscope_simple.py

# OpenAIÊºîÁ§∫ÔºàÈúÄË¶ÅÂõΩÂ§ñAPIÔºâ
python examples/openai/demo_openai.py

# ÈõÜÊàêÊµãËØï
python tests/integration/test_dashscope_integration.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;üìÅ Êï∞ÊçÆÁõÆÂΩïÈÖçÁΩÆ&lt;/h4&gt; 
&lt;p&gt;&lt;strong&gt;Êñ∞ÂäüËÉΩ&lt;/strong&gt;: ÁÅµÊ¥ªÈÖçÁΩÆÊï∞ÊçÆÂ≠òÂÇ®Ë∑ØÂæÑÔºåÊîØÊåÅÂ§öÁßçÈÖçÁΩÆÊñπÂºèÔºö&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Êü•ÁúãÂΩìÂâçÊï∞ÊçÆÁõÆÂΩïÈÖçÁΩÆ
python -m cli.main data-config --show

# ËÆæÁΩÆËá™ÂÆö‰πâÊï∞ÊçÆÁõÆÂΩï
python -m cli.main data-config --set /path/to/your/data

# ÈáçÁΩÆ‰∏∫ÈªòËÆ§ÈÖçÁΩÆ
python -m cli.main data-config --reset
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;ÁéØÂ¢ÉÂèòÈáèÈÖçÁΩÆ&lt;/strong&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Windows
set TRADING_AGENTS_DATA_DIR=C:\MyTradingData

# Linux/macOS
export TRADING_AGENTS_DATA_DIR=/home/user/trading_data
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Á®ãÂ∫èÂåñÈÖçÁΩÆ&lt;/strong&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from tradingagents.config_manager import ConfigManager

# ËÆæÁΩÆÊï∞ÊçÆÁõÆÂΩï
config_manager = ConfigManager()
config_manager.set_data_directory("/path/to/data")

# Ëé∑ÂèñÈÖçÁΩÆ
data_dir = config_manager.get_data_directory()
print(f"Êï∞ÊçÆÁõÆÂΩï: {data_dir}")
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;ÈÖçÁΩÆ‰ºòÂÖàÁ∫ß&lt;/strong&gt;: Á®ãÂ∫èËÆæÁΩÆ &amp;gt; ÁéØÂ¢ÉÂèòÈáè &amp;gt; ÈÖçÁΩÆÊñá‰ª∂ &amp;gt; ÈªòËÆ§ÂÄº&lt;/p&gt; 
&lt;p&gt;ËØ¶ÁªÜËØ¥ÊòéËØ∑ÂèÇËÄÉ: &lt;a href="https://raw.githubusercontent.com/hsliuping/TradingAgents-CN/main/docs/configuration/data-directory-configuration.md"&gt;üìÅ Êï∞ÊçÆÁõÆÂΩïÈÖçÁΩÆÊåáÂçó&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;‰∫§‰∫íÂºèÂàÜÊûê&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# ÂêØÂä®‰∫§‰∫íÂºèÂëΩ‰ª§Ë°åÁïåÈù¢
python -m cli.main
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;üéØ &lt;strong&gt;Âø´ÈÄüÂØºËà™&lt;/strong&gt; - ÊâæÂà∞ÊÇ®ÈúÄË¶ÅÁöÑÂÜÖÂÆπ&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;üéØ&lt;strong&gt;ÊàëÊÉ≥Ë¶Å...&lt;/strong&gt;&lt;/th&gt; 
   &lt;th&gt;üìñ&lt;strong&gt;Êé®ËçêÊñáÊ°£&lt;/strong&gt;&lt;/th&gt; 
   &lt;th&gt;‚è±Ô∏è&lt;strong&gt;ÈòÖËØªÊó∂Èó¥&lt;/strong&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Âø´ÈÄü‰∏äÊâã&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/hsliuping/TradingAgents-CN/main/docs/overview/quick-start.md"&gt;üöÄ Âø´ÈÄüÂºÄÂßã&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;10ÂàÜÈíü&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;‰∫ÜËß£Êû∂ÊûÑ&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/hsliuping/TradingAgents-CN/main/docs/architecture/system-architecture.md"&gt;üèõÔ∏è Á≥ªÁªüÊû∂ÊûÑ&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;15ÂàÜÈíü&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Áúã‰ª£Á†ÅÁ§∫‰æã&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/hsliuping/TradingAgents-CN/main/docs/examples/basic-examples.md"&gt;üìö Âü∫Á°ÄÁ§∫‰æã&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;20ÂàÜÈíü&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Ëß£ÂÜ≥ÈóÆÈ¢ò&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/hsliuping/TradingAgents-CN/main/docs/faq/faq.md"&gt;üÜò Â∏∏ËßÅÈóÆÈ¢ò&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;5ÂàÜÈíü&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Ê∑±Â∫¶Â≠¶‰π†&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/hsliuping/TradingAgents-CN/main/#-%E8%AF%A6%E7%BB%86%E6%96%87%E6%A1%A3%E7%9B%AE%E5%BD%95"&gt;üìÅ ÂÆåÊï¥ÊñáÊ°£ÁõÆÂΩï&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;2Â∞èÊó∂+&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;üí° &lt;strong&gt;ÊèêÁ§∫&lt;/strong&gt;: Êàë‰ª¨ÁöÑ &lt;code&gt;docs/&lt;/code&gt; ÁõÆÂΩïÂåÖÂê´‰∫Ü &lt;strong&gt;50,000+Â≠ó&lt;/strong&gt; ÁöÑËØ¶ÁªÜ‰∏≠ÊñáÊñáÊ°£ÔºåËøôÊòØ‰∏éÂéüÁâàÊúÄÂ§ßÁöÑÂå∫Âà´ÔºÅ&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;üìö ÂÆåÊï¥ÊñáÊ°£‰ΩìÁ≥ª - Ê†∏ÂøÉ‰∫ÆÁÇπ&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;üåü ËøôÊòØÊú¨È°πÁõÆ‰∏éÂéüÁâàÊúÄÂ§ßÁöÑÂå∫Âà´ÔºÅ&lt;/strong&gt; Êàë‰ª¨ÊûÑÂª∫‰∫Ü‰∏öÁïåÊúÄÂÆåÊï¥ÁöÑ‰∏≠ÊñáÈáëËûçAIÊ°ÜÊû∂ÊñáÊ°£‰ΩìÁ≥ªÔºåÂåÖÂê´Ë∂ÖËøá &lt;strong&gt;50,000Â≠ó&lt;/strong&gt; ÁöÑËØ¶ÁªÜÊäÄÊúØÊñáÊ°£Ôºå&lt;strong&gt;20+&lt;/strong&gt; ‰∏™‰∏ì‰∏öÊñáÊ°£Êñá‰ª∂Ôºå&lt;strong&gt;100+&lt;/strong&gt; ‰∏™‰ª£Á†ÅÁ§∫‰æã„ÄÇ&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;üéØ ‰∏∫‰ªÄ‰πàÈÄâÊã©Êàë‰ª¨ÁöÑÊñáÊ°£Ôºü&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;ÂØπÊØîÁª¥Â∫¶&lt;/th&gt; 
   &lt;th&gt;ÂéüÁâà TradingAgents&lt;/th&gt; 
   &lt;th&gt;üöÄ&lt;strong&gt;‰∏≠ÊñáÂ¢ûÂº∫Áâà&lt;/strong&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;ÊñáÊ°£ËØ≠Ë®Ä&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Ëã±ÊñáÂü∫Á°ÄËØ¥Êòé&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;ÂÆåÊï¥‰∏≠Êñá‰ΩìÁ≥ª&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;ÊñáÊ°£Ê∑±Â∫¶&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;ÁÆÄÂçï‰ªãÁªç&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Ê∑±Â∫¶ÊäÄÊúØÂâñÊûê&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Êû∂ÊûÑËØ¥Êòé&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Ê¶ÇÂøµÊÄßÊèèËø∞&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;ËØ¶ÁªÜËÆæËÆ°ÊñáÊ°£ + Êû∂ÊûÑÂõæ&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;‰ΩøÁî®ÊåáÂçó&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Âü∫Á°ÄÁ§∫‰æã&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;‰ªéÂÖ•Èó®Âà∞‰∏ìÂÆ∂ÁöÑÂÆåÊï¥Ë∑ØÂæÑ&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;ÊïÖÈöúÊéíÈô§&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Êó†&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;ËØ¶ÁªÜFAQ + Ëß£ÂÜ≥ÊñπÊ°à&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;‰ª£Á†ÅÁ§∫‰æã&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Â∞ëÈáèÁ§∫‰æã&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;100+ ÂÆûÁî®Á§∫‰æã&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;üìñ ÊñáÊ°£ÂØºËà™ - ÊåâÂ≠¶‰π†Ë∑ØÂæÑÁªÑÁªá&lt;/h3&gt; 
&lt;h4&gt;üöÄ &lt;strong&gt;Êñ∞ÊâãÂÖ•Èó®Ë∑ØÂæÑ&lt;/strong&gt; (Êé®Ëçê‰ªéËøôÈáåÂºÄÂßã)&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hsliuping/TradingAgents-CN/main/docs/overview/project-overview.md"&gt;üìã È°πÁõÆÊ¶ÇËø∞&lt;/a&gt; - &lt;strong&gt;‰∫ÜËß£È°πÁõÆËÉåÊôØÂíåÊ†∏ÂøÉ‰ª∑ÂÄº&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hsliuping/TradingAgents-CN/main/docs/overview/installation.md"&gt;‚öôÔ∏è ËØ¶ÁªÜÂÆâË£Ö&lt;/a&gt; - &lt;strong&gt;ÂêÑÂπ≥Âè∞ËØ¶ÁªÜÂÆâË£ÖÊåáÂçó&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hsliuping/TradingAgents-CN/main/docs/overview/quick-start.md"&gt;üöÄ Âø´ÈÄüÂºÄÂßã&lt;/a&gt; - &lt;strong&gt;10ÂàÜÈíü‰∏äÊâãÊåáÂçó&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hsliuping/TradingAgents-CN/main/docs/examples/basic-examples.md"&gt;üìö Âü∫Á°ÄÁ§∫‰æã&lt;/a&gt; - &lt;strong&gt;8‰∏™ÂÆûÁî®ÁöÑÂÖ•Èó®Á§∫‰æã&lt;/strong&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;üèóÔ∏è &lt;strong&gt;Êû∂ÊûÑÁêÜËß£Ë∑ØÂæÑ&lt;/strong&gt; (Ê∑±ÂÖ•‰∫ÜËß£Á≥ªÁªüËÆæËÆ°)&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hsliuping/TradingAgents-CN/main/docs/architecture/system-architecture.md"&gt;üèõÔ∏è Á≥ªÁªüÊû∂ÊûÑ&lt;/a&gt; - &lt;strong&gt;ÂÆåÊï¥ÁöÑÁ≥ªÁªüÊû∂ÊûÑËÆæËÆ°&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hsliuping/TradingAgents-CN/main/docs/architecture/agent-architecture.md"&gt;ü§ñ Êô∫ËÉΩ‰ΩìÊû∂ÊûÑ&lt;/a&gt; - &lt;strong&gt;Â§öÊô∫ËÉΩ‰ΩìÂçè‰ΩúÊú∫Âà∂&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hsliuping/TradingAgents-CN/main/docs/architecture/data-flow-architecture.md"&gt;üìä Êï∞ÊçÆÊµÅÊû∂ÊûÑ&lt;/a&gt; - &lt;strong&gt;Êï∞ÊçÆÂ§ÑÁêÜÂÖ®ÊµÅÁ®ã&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hsliuping/TradingAgents-CN/main/docs/architecture/graph-structure.md"&gt;üîÑ ÂõæÁªìÊûÑËÆæËÆ°&lt;/a&gt; - &lt;strong&gt;LangGraphÂ∑•‰ΩúÊµÅÁ®ã&lt;/strong&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;ü§ñ &lt;strong&gt;Êô∫ËÉΩ‰ΩìÊ∑±Â∫¶Ëß£Êûê&lt;/strong&gt; (‰∫ÜËß£ÊØè‰∏™Êô∫ËÉΩ‰ΩìÁöÑËÆæËÆ°)&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hsliuping/TradingAgents-CN/main/docs/agents/analysts.md"&gt;üìà ÂàÜÊûêÂ∏àÂõ¢Èòü&lt;/a&gt; - &lt;strong&gt;ÂõõÁ±ª‰∏ì‰∏öÂàÜÊûêÂ∏àËØ¶Ëß£&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hsliuping/TradingAgents-CN/main/docs/agents/researchers.md"&gt;üî¨ Á†îÁ©∂ÂëòÂõ¢Èòü&lt;/a&gt; - &lt;strong&gt;ÁúãÊ∂®/ÁúãË∑åËæ©ËÆ∫Êú∫Âà∂&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hsliuping/TradingAgents-CN/main/docs/agents/trader.md"&gt;üíº ‰∫§ÊòìÂëòÊô∫ËÉΩ‰Ωì&lt;/a&gt; - &lt;strong&gt;‰∫§ÊòìÂÜ≥Á≠ñÂà∂ÂÆöÊµÅÁ®ã&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hsliuping/TradingAgents-CN/main/docs/agents/risk-management.md"&gt;üõ°Ô∏è È£éÈô©ÁÆ°ÁêÜ&lt;/a&gt; - &lt;strong&gt;Â§öÂ±ÇÊ¨°È£éÈô©ËØÑ‰º∞&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hsliuping/TradingAgents-CN/main/docs/agents/managers.md"&gt;üëî ÁÆ°ÁêÜÂ±ÇÊô∫ËÉΩ‰Ωì&lt;/a&gt; - &lt;strong&gt;ÂçèË∞ÉÂíåÂÜ≥Á≠ñÁÆ°ÁêÜ&lt;/strong&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;üìä &lt;strong&gt;Êï∞ÊçÆÂ§ÑÁêÜ‰∏ìÈ¢ò&lt;/strong&gt; (ÊéåÊè°Êï∞ÊçÆÂ§ÑÁêÜÊäÄÊúØ)&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hsliuping/TradingAgents-CN/main/docs/data/data-sources.md"&gt;üîå Êï∞ÊçÆÊ∫êÈõÜÊàê&lt;/a&gt; - &lt;strong&gt;Â§öÊï∞ÊçÆÊ∫êAPIÈõÜÊàê&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hsliuping/TradingAgents-CN/main/docs/data/data-processing.md"&gt;‚öôÔ∏è Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã&lt;/a&gt; - &lt;strong&gt;Êï∞ÊçÆÊ∏ÖÊ¥óÂíåËΩ¨Êç¢&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hsliuping/TradingAgents-CN/main/docs/data/caching.md"&gt;üíæ ÁºìÂ≠òÁ≠ñÁï•&lt;/a&gt; - &lt;strong&gt;Â§öÂ±ÇÁºìÂ≠ò‰ºòÂåñÊÄßËÉΩ&lt;/strong&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;‚öôÔ∏è &lt;strong&gt;ÈÖçÁΩÆÂíå‰ºòÂåñ&lt;/strong&gt; (ÊÄßËÉΩË∞É‰ºòÂíåÂÆöÂà∂)&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hsliuping/TradingAgents-CN/main/docs/configuration/config-guide.md"&gt;üìù ÈÖçÁΩÆÊåáÂçó&lt;/a&gt; - &lt;strong&gt;ËØ¶ÁªÜÈÖçÁΩÆÈÄâÈ°πËØ¥Êòé&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hsliuping/TradingAgents-CN/main/docs/configuration/llm-config.md"&gt;üß† LLMÈÖçÁΩÆ&lt;/a&gt; - &lt;strong&gt;Â§ßËØ≠Ë®ÄÊ®°Âûã‰ºòÂåñ&lt;/strong&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;üí° &lt;strong&gt;È´òÁ∫ßÂ∫îÁî®&lt;/strong&gt; (Êâ©Â±ïÂºÄÂèëÂíåÂÆûÊàò)&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hsliuping/TradingAgents-CN/main/docs/examples/basic-examples.md"&gt;üìö Âü∫Á°ÄÁ§∫‰æã&lt;/a&gt; - &lt;strong&gt;8‰∏™ÂÆûÁî®Âü∫Á°ÄÁ§∫‰æã&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hsliuping/TradingAgents-CN/main/docs/examples/advanced-examples.md"&gt;üöÄ È´òÁ∫ßÁ§∫‰æã&lt;/a&gt; - &lt;strong&gt;Â§çÊùÇÂú∫ÊôØÂíåÊâ©Â±ïÂºÄÂèë&lt;/strong&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;‚ùì &lt;strong&gt;ÈóÆÈ¢òËß£ÂÜ≥&lt;/strong&gt; (ÈÅáÂà∞ÈóÆÈ¢òÊó∂Êü•Áúã)&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hsliuping/TradingAgents-CN/main/docs/faq/faq.md"&gt;üÜò Â∏∏ËßÅÈóÆÈ¢ò&lt;/a&gt; - &lt;strong&gt;ËØ¶ÁªÜFAQÂíåËß£ÂÜ≥ÊñπÊ°à&lt;/strong&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;üìä ÊñáÊ°£ÁªüËÆ°Êï∞ÊçÆ&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;üìÑ &lt;strong&gt;ÊñáÊ°£Êñá‰ª∂Êï∞&lt;/strong&gt;: 20+ ‰∏™‰∏ì‰∏öÊñáÊ°£&lt;/li&gt; 
 &lt;li&gt;üìù &lt;strong&gt;ÊÄªÂ≠óÊï∞&lt;/strong&gt;: 50,000+ Â≠óËØ¶ÁªÜÂÜÖÂÆπ&lt;/li&gt; 
 &lt;li&gt;üíª &lt;strong&gt;‰ª£Á†ÅÁ§∫‰æã&lt;/strong&gt;: 100+ ‰∏™ÂÆûÁî®Á§∫‰æã&lt;/li&gt; 
 &lt;li&gt;üìà &lt;strong&gt;Êû∂ÊûÑÂõæË°®&lt;/strong&gt;: 10+ ‰∏™‰∏ì‰∏öÂõæË°®&lt;/li&gt; 
 &lt;li&gt;üéØ &lt;strong&gt;Ë¶ÜÁõñËåÉÂõ¥&lt;/strong&gt;: ‰ªéÂÖ•Èó®Âà∞‰∏ìÂÆ∂ÁöÑÂÆåÊï¥Ë∑ØÂæÑ&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üé® ÊñáÊ°£ÁâπËâ≤&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;üá®üá≥ ÂÆåÂÖ®‰∏≠ÊñáÂåñ&lt;/strong&gt;: ‰∏ì‰∏∫‰∏≠ÊñáÁî®Êà∑‰ºòÂåñÁöÑË°®ËææÊñπÂºè&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üìä ÂõæÊñáÂπ∂ËåÇ&lt;/strong&gt;: ‰∏∞ÂØåÁöÑÊû∂ÊûÑÂõæÂíåÊµÅÁ®ãÂõæ&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üíª ‰ª£Á†Å‰∏∞ÂØå&lt;/strong&gt;: ÊØè‰∏™Ê¶ÇÂøµÈÉΩÊúâÂØπÂ∫îÁöÑ‰ª£Á†ÅÁ§∫‰æã&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üîç Ê∑±Â∫¶ÂâñÊûê&lt;/strong&gt;: ‰∏ç‰ªÖÂëäËØâ‰Ω†ÊÄé‰πàÂÅöÔºåËøòÂëäËØâ‰Ω†‰∏∫‰ªÄ‰πàËøôÊ†∑ÂÅö&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üõ†Ô∏è ÂÆûÁî®ÂØºÂêë&lt;/strong&gt;: ÊâÄÊúâÊñáÊ°£ÈÉΩÈù¢ÂêëÂÆûÈôÖÂ∫îÁî®Âú∫ÊôØ&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üìö ËØ¶ÁªÜÊñáÊ°£ÁõÆÂΩï&lt;/h2&gt; 
&lt;h3&gt;üìÅ &lt;strong&gt;docs/ ÁõÆÂΩïÁªìÊûÑ&lt;/strong&gt; - ÂÆåÊï¥ÁöÑÁü•ËØÜ‰ΩìÁ≥ª&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;docs/
‚îú‚îÄ‚îÄ üìñ overview/              # È°πÁõÆÊ¶ÇËßà - Êñ∞ÊâãÂøÖËØª
‚îÇ   ‚îú‚îÄ‚îÄ project-overview.md   # üìã È°πÁõÆËØ¶ÁªÜ‰ªãÁªç
‚îÇ   ‚îú‚îÄ‚îÄ quick-start.md        # üöÄ 10ÂàÜÈíüÂø´ÈÄü‰∏äÊâã
‚îÇ   ‚îî‚îÄ‚îÄ installation.md       # ‚öôÔ∏è ËØ¶ÁªÜÂÆâË£ÖÊåáÂçó
‚îÇ
‚îú‚îÄ‚îÄ üèóÔ∏è architecture/          # Á≥ªÁªüÊû∂ÊûÑ - Ê∑±Â∫¶ÁêÜËß£
‚îÇ   ‚îú‚îÄ‚îÄ system-architecture.md    # üèõÔ∏è Êï¥‰ΩìÊû∂ÊûÑËÆæËÆ°
‚îÇ   ‚îú‚îÄ‚îÄ agent-architecture.md     # ü§ñ Êô∫ËÉΩ‰ΩìÂçè‰ΩúÊú∫Âà∂
‚îÇ   ‚îú‚îÄ‚îÄ data-flow-architecture.md # üìä Êï∞ÊçÆÊµÅÂ§ÑÁêÜÊû∂ÊûÑ
‚îÇ   ‚îî‚îÄ‚îÄ graph-structure.md        # üîÑ LangGraphÂ∑•‰ΩúÊµÅ
‚îÇ
‚îú‚îÄ‚îÄ ü§ñ agents/               # Êô∫ËÉΩ‰ΩìËØ¶Ëß£ - Ê†∏ÂøÉÁªÑ‰ª∂
‚îÇ   ‚îú‚îÄ‚îÄ analysts.md          # üìà ÂõõÁ±ª‰∏ì‰∏öÂàÜÊûêÂ∏à
‚îÇ   ‚îú‚îÄ‚îÄ researchers.md       # üî¨ ÁúãÊ∂®/ÁúãË∑åËæ©ËÆ∫Êú∫Âà∂
‚îÇ   ‚îú‚îÄ‚îÄ trader.md           # üíº ‰∫§ÊòìÂÜ≥Á≠ñÂà∂ÂÆö
‚îÇ   ‚îú‚îÄ‚îÄ risk-management.md  # üõ°Ô∏è Â§öÂ±ÇÈ£éÈô©ËØÑ‰º∞
‚îÇ   ‚îî‚îÄ‚îÄ managers.md         # üëî ÁÆ°ÁêÜÂ±ÇÂçèË∞É
‚îÇ
‚îú‚îÄ‚îÄ üìä data/                 # Êï∞ÊçÆÂ§ÑÁêÜ - ÊäÄÊúØÊ†∏ÂøÉ
‚îÇ   ‚îú‚îÄ‚îÄ data-sources.md      # üîå Â§öÊï∞ÊçÆÊ∫êÈõÜÊàê
‚îÇ   ‚îú‚îÄ‚îÄ data-processing.md   # ‚öôÔ∏è Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã
‚îÇ   ‚îî‚îÄ‚îÄ caching.md          # üíæ ÁºìÂ≠ò‰ºòÂåñÁ≠ñÁï•
‚îÇ
‚îú‚îÄ‚îÄ ‚öôÔ∏è configuration/        # ÈÖçÁΩÆ‰ºòÂåñ - ÊÄßËÉΩË∞É‰ºò
‚îÇ   ‚îú‚îÄ‚îÄ config-guide.md      # üìù ËØ¶ÁªÜÈÖçÁΩÆËØ¥Êòé
‚îÇ   ‚îî‚îÄ‚îÄ llm-config.md       # üß† LLMÊ®°Âûã‰ºòÂåñ
‚îÇ
‚îú‚îÄ‚îÄ üí° examples/             # Á§∫‰æãÊïôÁ®ã - ÂÆûÊàòÂ∫îÁî®
‚îÇ   ‚îú‚îÄ‚îÄ basic-examples.md    # üìö 8‰∏™Âü∫Á°ÄÁ§∫‰æã
‚îÇ   ‚îî‚îÄ‚îÄ advanced-examples.md # üöÄ È´òÁ∫ßÂºÄÂèëÁ§∫‰æã
‚îÇ
‚îî‚îÄ‚îÄ ‚ùì faq/                  # ÈóÆÈ¢òËß£ÂÜ≥ - ÁñëÈöæËß£Á≠î
    ‚îî‚îÄ‚îÄ faq.md              # üÜò Â∏∏ËßÅÈóÆÈ¢òFAQ
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;üéØ &lt;strong&gt;ÈáçÁÇπÊé®ËçêÊñáÊ°£&lt;/strong&gt; (ÂøÖËØªÁ≤æÈÄâ)&lt;/h3&gt; 
&lt;h4&gt;üî• &lt;strong&gt;ÊúÄÂèóÊ¨¢ËøéÁöÑÊñáÊ°£&lt;/strong&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/hsliuping/TradingAgents-CN/main/docs/overview/project-overview.md"&gt;üìã È°πÁõÆÊ¶ÇËø∞&lt;/a&gt;&lt;/strong&gt; - ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê&lt;/p&gt; 
  &lt;blockquote&gt; 
   &lt;p&gt;‰∫ÜËß£È°πÁõÆÁöÑÊ†∏ÂøÉ‰ª∑ÂÄºÂíåÊäÄÊúØÁâπËâ≤Ôºå5ÂàÜÈíüËØªÊáÇÊï¥‰∏™Ê°ÜÊû∂&lt;/p&gt; 
  &lt;/blockquote&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/hsliuping/TradingAgents-CN/main/docs/architecture/system-architecture.md"&gt;üèõÔ∏è Á≥ªÁªüÊû∂ÊûÑ&lt;/a&gt;&lt;/strong&gt; - ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê&lt;/p&gt; 
  &lt;blockquote&gt; 
   &lt;p&gt;Ê∑±Â∫¶Ëß£ÊûêÂ§öÊô∫ËÉΩ‰ΩìÂçè‰ΩúÊú∫Âà∂ÔºåÂåÖÂê´ËØ¶ÁªÜÊû∂ÊûÑÂõæ&lt;/p&gt; 
  &lt;/blockquote&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/hsliuping/TradingAgents-CN/main/docs/examples/basic-examples.md"&gt;üìö Âü∫Á°ÄÁ§∫‰æã&lt;/a&gt;&lt;/strong&gt; - ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê&lt;/p&gt; 
  &lt;blockquote&gt; 
   &lt;p&gt;8‰∏™ÂÆûÁî®Á§∫‰æãÔºå‰ªéËÇ°Á•®ÂàÜÊûêÂà∞ÊäïËµÑÁªÑÂêà‰ºòÂåñ&lt;/p&gt; 
  &lt;/blockquote&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;üöÄ &lt;strong&gt;ÊäÄÊúØÊ∑±Â∫¶ÊñáÊ°£&lt;/strong&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/hsliuping/TradingAgents-CN/main/docs/architecture/agent-architecture.md"&gt;ü§ñ Êô∫ËÉΩ‰ΩìÊû∂ÊûÑ&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
  &lt;blockquote&gt; 
   &lt;p&gt;Â§öÊô∫ËÉΩ‰ΩìËÆæËÆ°Ê®°ÂºèÂíåÂçè‰ΩúÊú∫Âà∂ËØ¶Ëß£&lt;/p&gt; 
  &lt;/blockquote&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/hsliuping/TradingAgents-CN/main/docs/architecture/data-flow-architecture.md"&gt;üìä Êï∞ÊçÆÊµÅÊû∂ÊûÑ&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
  &lt;blockquote&gt; 
   &lt;p&gt;Êï∞ÊçÆËé∑Âèñ„ÄÅÂ§ÑÁêÜ„ÄÅÁºìÂ≠òÁöÑÂÆåÊï¥ÊµÅÁ®ã&lt;/p&gt; 
  &lt;/blockquote&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/hsliuping/TradingAgents-CN/main/docs/agents/researchers.md"&gt;üî¨ Á†îÁ©∂ÂëòÂõ¢Èòü&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
  &lt;blockquote&gt; 
   &lt;p&gt;ÁúãÊ∂®/ÁúãË∑åÁ†îÁ©∂ÂëòËæ©ËÆ∫Êú∫Âà∂ÁöÑÂàõÊñ∞ËÆæËÆ°&lt;/p&gt; 
  &lt;/blockquote&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;üíº &lt;strong&gt;ÂÆûÁî®Â∑•ÂÖ∑ÊñáÊ°£&lt;/strong&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/hsliuping/TradingAgents-CN/main/docs/usage/web-interface-guide.md"&gt;üåê WebÁïåÈù¢ÊåáÂçó&lt;/a&gt;&lt;/strong&gt; - ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê&lt;/p&gt; 
  &lt;blockquote&gt; 
   &lt;p&gt;ÂÆåÊï¥ÁöÑWebÁïåÈù¢‰ΩøÁî®ÊïôÁ®ãÔºåÂåÖÂê´5Á∫ßÁ†îÁ©∂Ê∑±Â∫¶ËØ¶ÁªÜËØ¥Êòé&lt;/p&gt; 
  &lt;/blockquote&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/hsliuping/TradingAgents-CN/main/docs/usage/investment_analysis_guide.md"&gt;üí∞ ÊäïËµÑÂàÜÊûêÊåáÂçó&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
  &lt;blockquote&gt; 
   &lt;p&gt;‰ªéÂü∫Á°ÄÂà∞È´òÁ∫ßÁöÑÂÆåÊï¥ÊäïËµÑÂàÜÊûêÊïôÁ®ã&lt;/p&gt; 
  &lt;/blockquote&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/hsliuping/TradingAgents-CN/main/docs/configuration/llm-config.md"&gt;üß† LLMÈÖçÁΩÆ&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
  &lt;blockquote&gt; 
   &lt;p&gt;Â§öLLMÊ®°ÂûãÈÖçÁΩÆÂíåÊàêÊú¨‰ºòÂåñÁ≠ñÁï•&lt;/p&gt; 
  &lt;/blockquote&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/hsliuping/TradingAgents-CN/main/docs/data/caching.md"&gt;üíæ ÁºìÂ≠òÁ≠ñÁï•&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
  &lt;blockquote&gt; 
   &lt;p&gt;Â§öÂ±ÇÁºìÂ≠òËÆæËÆ°ÔºåÊòæËëóÈôç‰ΩéAPIË∞ÉÁî®ÊàêÊú¨&lt;/p&gt; 
  &lt;/blockquote&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/hsliuping/TradingAgents-CN/main/docs/faq/faq.md"&gt;üÜò Â∏∏ËßÅÈóÆÈ¢ò&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
  &lt;blockquote&gt; 
   &lt;p&gt;ËØ¶ÁªÜÁöÑFAQÂíåÊïÖÈöúÊéíÈô§ÊåáÂçó&lt;/p&gt; 
  &lt;/blockquote&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;üìñ &lt;strong&gt;ÊåâÊ®°ÂùóÊµèËßàÊñáÊ°£&lt;/strong&gt;&lt;/h3&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;üìñ Ê¶ÇËßàÊñáÊ°£&lt;/strong&gt; - È°πÁõÆÂÖ•Èó®ÂøÖËØª&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hsliuping/TradingAgents-CN/main/docs/overview/project-overview.md"&gt;üìã È°πÁõÆÊ¶ÇËø∞&lt;/a&gt; - ËØ¶ÁªÜÁöÑÈ°πÁõÆËÉåÊôØÂíåÁâπÊÄß‰ªãÁªç&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hsliuping/TradingAgents-CN/main/docs/overview/quick-start.md"&gt;üöÄ Âø´ÈÄüÂºÄÂßã&lt;/a&gt; - ‰ªéÂÆâË£ÖÂà∞Á¨¨‰∏ÄÊ¨°ËøêË°åÁöÑÂÆåÊï¥ÊåáÂçó&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hsliuping/TradingAgents-CN/main/docs/overview/installation.md"&gt;‚öôÔ∏è ËØ¶ÁªÜÂÆâË£Ö&lt;/a&gt; - ÂêÑÂπ≥Âè∞ËØ¶ÁªÜÂÆâË£ÖËØ¥Êòé&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;üèóÔ∏è Êû∂ÊûÑÊñáÊ°£&lt;/strong&gt; - Ê∑±Â∫¶ÁêÜËß£Á≥ªÁªüËÆæËÆ°&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hsliuping/TradingAgents-CN/main/docs/architecture/system-architecture.md"&gt;üèõÔ∏è Á≥ªÁªüÊû∂ÊûÑ&lt;/a&gt; - ÂÆåÊï¥ÁöÑÁ≥ªÁªüÊû∂ÊûÑËÆæËÆ°&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hsliuping/TradingAgents-CN/main/docs/architecture/agent-architecture.md"&gt;ü§ñ Êô∫ËÉΩ‰ΩìÊû∂ÊûÑ&lt;/a&gt; - Êô∫ËÉΩ‰ΩìËÆæËÆ°Ê®°ÂºèÂíåÂçè‰ΩúÊú∫Âà∂&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hsliuping/TradingAgents-CN/main/docs/architecture/data-flow-architecture.md"&gt;üìä Êï∞ÊçÆÊµÅÊû∂ÊûÑ&lt;/a&gt; - Êï∞ÊçÆËé∑Âèñ„ÄÅÂ§ÑÁêÜÂíåÂàÜÂèëÊµÅÁ®ã&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hsliuping/TradingAgents-CN/main/docs/architecture/graph-structure.md"&gt;üîÑ ÂõæÁªìÊûÑËÆæËÆ°&lt;/a&gt; - LangGraphÂ∑•‰ΩúÊµÅÁ®ãËÆæËÆ°&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;ü§ñ Êô∫ËÉΩ‰ΩìÊñáÊ°£&lt;/strong&gt; - Ê†∏ÂøÉÁªÑ‰ª∂ËØ¶Ëß£&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hsliuping/TradingAgents-CN/main/docs/agents/analysts.md"&gt;üìà ÂàÜÊûêÂ∏àÂõ¢Èòü&lt;/a&gt; - ÂõõÁ±ª‰∏ì‰∏öÂàÜÊûêÂ∏àËØ¶Ëß£&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hsliuping/TradingAgents-CN/main/docs/agents/researchers.md"&gt;üî¨ Á†îÁ©∂ÂëòÂõ¢Èòü&lt;/a&gt; - ÁúãÊ∂®/ÁúãË∑åÁ†îÁ©∂ÂëòÂíåËæ©ËÆ∫Êú∫Âà∂&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hsliuping/TradingAgents-CN/main/docs/agents/trader.md"&gt;üíº ‰∫§ÊòìÂëòÊô∫ËÉΩ‰Ωì&lt;/a&gt; - ‰∫§ÊòìÂÜ≥Á≠ñÂà∂ÂÆöÊµÅÁ®ã&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hsliuping/TradingAgents-CN/main/docs/agents/risk-management.md"&gt;üõ°Ô∏è È£éÈô©ÁÆ°ÁêÜ&lt;/a&gt; - Â§öÂ±ÇÊ¨°È£éÈô©ËØÑ‰º∞‰ΩìÁ≥ª&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hsliuping/TradingAgents-CN/main/docs/agents/managers.md"&gt;üëî ÁÆ°ÁêÜÂ±ÇÊô∫ËÉΩ‰Ωì&lt;/a&gt; - ÂçèË∞ÉÂíåÂÜ≥Á≠ñÁÆ°ÁêÜ&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;üìä Êï∞ÊçÆÂ§ÑÁêÜ&lt;/strong&gt; - ÊäÄÊúØÊ†∏ÂøÉÂÆûÁé∞&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hsliuping/TradingAgents-CN/main/docs/data/data-sources.md"&gt;üîå Êï∞ÊçÆÊ∫êÈõÜÊàê&lt;/a&gt; - ÊîØÊåÅÁöÑÊï∞ÊçÆÊ∫êÂíåAPIÈõÜÊàê&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hsliuping/TradingAgents-CN/main/docs/data/data-processing.md"&gt;‚öôÔ∏è Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã&lt;/a&gt; - Êï∞ÊçÆÊ∏ÖÊ¥ó„ÄÅËΩ¨Êç¢ÂíåÈ™åËØÅ&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hsliuping/TradingAgents-CN/main/docs/data/caching.md"&gt;üíæ ÁºìÂ≠òÁ≠ñÁï•&lt;/a&gt; - Â§öÂ±ÇÁºìÂ≠ò‰ºòÂåñÊÄßËÉΩ&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;‚öôÔ∏è ÈÖçÁΩÆ‰∏éÈÉ®ÁΩ≤&lt;/strong&gt; - ÊÄßËÉΩË∞É‰ºòÊåáÂçó&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hsliuping/TradingAgents-CN/main/docs/configuration/config-guide.md"&gt;üìù ÈÖçÁΩÆÊåáÂçó&lt;/a&gt; - ËØ¶ÁªÜÁöÑÈÖçÁΩÆÈÄâÈ°πËØ¥Êòé&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hsliuping/TradingAgents-CN/main/docs/configuration/llm-config.md"&gt;üß† LLMÈÖçÁΩÆ&lt;/a&gt; - Â§ßËØ≠Ë®ÄÊ®°ÂûãÈÖçÁΩÆ‰ºòÂåñ&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;üí° Á§∫‰æãÂíåÊïôÁ®ã&lt;/strong&gt; - ÂÆûÊàòÂ∫îÁî®ÊåáÂçó&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hsliuping/TradingAgents-CN/main/docs/examples/basic-examples.md"&gt;üìö Âü∫Á°ÄÁ§∫‰æã&lt;/a&gt; - 8‰∏™ÂÆûÁî®ÁöÑÂü∫Á°ÄÁ§∫‰æã&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hsliuping/TradingAgents-CN/main/docs/examples/advanced-examples.md"&gt;üöÄ È´òÁ∫ßÁ§∫‰æã&lt;/a&gt; - Â§çÊùÇÂú∫ÊôØÂíåÊâ©Â±ïÂºÄÂèë&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;‚ùì Â∏ÆÂä©ÊñáÊ°£&lt;/strong&gt; - ÈóÆÈ¢òËß£ÂÜ≥ÊñπÊ°à&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hsliuping/TradingAgents-CN/main/docs/faq/faq.md"&gt;üÜò Â∏∏ËßÅÈóÆÈ¢ò&lt;/a&gt; - ËØ¶ÁªÜÁöÑFAQÂíåËß£ÂÜ≥ÊñπÊ°à&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;üí∞ ÊàêÊú¨ÊéßÂà∂&lt;/h2&gt; 
&lt;h3&gt;ÂÖ∏Âûã‰ΩøÁî®ÊàêÊú¨&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;ÁªèÊµéÊ®°Âºè&lt;/strong&gt;: $0.01-0.05/Ê¨°ÂàÜÊûê (‰ΩøÁî® gpt-4o-mini)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Ê†áÂáÜÊ®°Âºè&lt;/strong&gt;: $0.05-0.15/Ê¨°ÂàÜÊûê (‰ΩøÁî® gpt-4o)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;È´òÁ≤æÂ∫¶Ê®°Âºè&lt;/strong&gt;: $0.10-0.30/Ê¨°ÂàÜÊûê (‰ΩøÁî® gpt-4o + Â§öËΩÆËæ©ËÆ∫)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;ÊàêÊú¨‰ºòÂåñÂª∫ËÆÆ&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# ‰ΩéÊàêÊú¨ÈÖçÁΩÆÁ§∫‰æã
cost_optimized_config = {
    "deep_think_llm": "gpt-4o-mini",
    "quick_think_llm": "gpt-4o-mini", 
    "max_debate_rounds": 1,
    "online_tools": False  # ‰ΩøÁî®ÁºìÂ≠òÊï∞ÊçÆ
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;ü§ù Ë¥°ÁåÆÊåáÂçó&lt;/h2&gt; 
&lt;p&gt;Êàë‰ª¨Ê¨¢ËøéÂêÑÁßçÂΩ¢ÂºèÁöÑË¥°ÁåÆÔºö&lt;/p&gt; 
&lt;h3&gt;Ë¥°ÁåÆÁ±ªÂûã&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;üêõ &lt;strong&gt;Bug‰øÆÂ§ç&lt;/strong&gt; - ÂèëÁé∞Âπ∂‰øÆÂ§çÈóÆÈ¢ò&lt;/li&gt; 
 &lt;li&gt;‚ú® &lt;strong&gt;Êñ∞ÂäüËÉΩ&lt;/strong&gt; - Ê∑ªÂä†Êñ∞ÁöÑÂäüËÉΩÁâπÊÄß&lt;/li&gt; 
 &lt;li&gt;üìö &lt;strong&gt;ÊñáÊ°£ÊîπËøõ&lt;/strong&gt; - ÂÆåÂñÑÊñáÊ°£ÂíåÊïôÁ®ã&lt;/li&gt; 
 &lt;li&gt;üåê &lt;strong&gt;Êú¨Âú∞Âåñ&lt;/strong&gt; - ÁøªËØëÂíåÊú¨Âú∞ÂåñÂ∑•‰Ωú&lt;/li&gt; 
 &lt;li&gt;üé® &lt;strong&gt;‰ª£Á†Å‰ºòÂåñ&lt;/strong&gt; - ÊÄßËÉΩ‰ºòÂåñÂíå‰ª£Á†ÅÈáçÊûÑ&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Ë¥°ÁåÆÊµÅÁ®ã&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Fork Êú¨‰ªìÂ∫ì&lt;/li&gt; 
 &lt;li&gt;ÂàõÂª∫ÁâπÊÄßÂàÜÊîØ (&lt;code&gt;git checkout -b feature/AmazingFeature&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;Êèê‰∫§Êõ¥Êîπ (&lt;code&gt;git commit -m 'Add some AmazingFeature'&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;Êé®ÈÄÅÂà∞ÂàÜÊîØ (&lt;code&gt;git push origin feature/AmazingFeature&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;ÂàõÂª∫ Pull Request&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;üìã Êü•ÁúãË¥°ÁåÆËÄÖ&lt;/h3&gt; 
&lt;p&gt;Êü•ÁúãÊâÄÊúâË¥°ÁåÆËÄÖÂíåËØ¶ÁªÜË¥°ÁåÆÂÜÖÂÆπÔºö&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/hsliuping/TradingAgents-CN/main/CONTRIBUTORS.md"&gt;ü§ù Ë¥°ÁåÆËÄÖÂêçÂçï&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;üìÑ ËÆ∏ÂèØËØÅ&lt;/h2&gt; 
&lt;p&gt;Êú¨È°πÁõÆÂü∫‰∫é Apache 2.0 ËÆ∏ÂèØËØÅÂºÄÊ∫ê„ÄÇËØ¶ËßÅ &lt;a href="https://raw.githubusercontent.com/hsliuping/TradingAgents-CN/main/LICENSE"&gt;LICENSE&lt;/a&gt; Êñá‰ª∂„ÄÇ&lt;/p&gt; 
&lt;h3&gt;ËÆ∏ÂèØËØÅËØ¥Êòé&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;‚úÖ ÂïÜ‰∏ö‰ΩøÁî®&lt;/li&gt; 
 &lt;li&gt;‚úÖ ‰øÆÊîπÂíåÂàÜÂèë&lt;/li&gt; 
 &lt;li&gt;‚úÖ ÁßÅ‰∫∫‰ΩøÁî®&lt;/li&gt; 
 &lt;li&gt;‚úÖ ‰∏ìÂà©‰ΩøÁî®&lt;/li&gt; 
 &lt;li&gt;‚ùó ÈúÄË¶Å‰øùÁïôÁâàÊùÉÂ£∞Êòé&lt;/li&gt; 
 &lt;li&gt;‚ùó ÈúÄË¶ÅÂåÖÂê´ËÆ∏ÂèØËØÅÂâØÊú¨&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üôè Ëá¥Ë∞¢‰∏éÊÑüÊÅ©&lt;/h2&gt; 
&lt;h3&gt;üåü ÂêëÊ∫êÈ°πÁõÆÂºÄÂèëËÄÖËá¥Êï¨&lt;/h3&gt; 
&lt;p&gt;Êàë‰ª¨Âêë &lt;a href="https://github.com/TauricResearch"&gt;Tauric Research&lt;/a&gt; Âõ¢ÈòüË°®ËææÊúÄÊ∑±ÁöÑÊï¨ÊÑèÂíåÊÑüË∞¢Ôºö&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;üéØ ÊÑøÊôØÈ¢ÜÂØºËÄÖ&lt;/strong&gt;: ÊÑüË∞¢ÊÇ®‰ª¨Âú®AIÈáëËûçÈ¢ÜÂüüÁöÑÂâçÁûªÊÄßÊÄùËÄÉÂíåÂàõÊñ∞ÂÆûË∑µ&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üíé ÁèçË¥µÊ∫êÁ†Å&lt;/strong&gt;: ÊÑüË∞¢ÊÇ®‰ª¨ÂºÄÊ∫êÁöÑÊØè‰∏ÄË°å‰ª£Á†ÅÔºåÂÆÉ‰ª¨ÂáùËÅöÁùÄÊó†Êï∞ÁöÑÊô∫ÊÖßÂíåÂøÉË°Ä&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üèóÔ∏è Êû∂ÊûÑÂ§ßÂ∏à&lt;/strong&gt;: ÊÑüË∞¢ÊÇ®‰ª¨ËÆæËÆ°‰∫ÜÂ¶ÇÊ≠§‰ºòÈõÖ„ÄÅÂèØÊâ©Â±ïÁöÑÂ§öÊô∫ËÉΩ‰ΩìÊ°ÜÊû∂&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üí° ÊäÄÊúØÂÖàÈ©±&lt;/strong&gt;: ÊÑüË∞¢ÊÇ®‰ª¨Â∞ÜÂâçÊ≤øAIÊäÄÊúØ‰∏éÈáëËûçÂÆûÂä°ÂÆåÁæéÁªìÂêà&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üîÑ ÊåÅÁª≠Ë¥°ÁåÆ&lt;/strong&gt;: ÊÑüË∞¢ÊÇ®‰ª¨ÊåÅÁª≠ÁöÑÁª¥Êä§„ÄÅÊõ¥Êñ∞ÂíåÊîπËøõÂ∑•‰Ωú&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;ü§ù Á§æÂå∫Ë¥°ÁåÆËÄÖËá¥Ë∞¢&lt;/h3&gt; 
&lt;p&gt;ÊÑüË∞¢ÊâÄÊúâ‰∏∫TradingAgents-CNÈ°πÁõÆÂÅöÂá∫Ë¥°ÁåÆÁöÑÂºÄÂèëËÄÖÂíåÁî®Êà∑ÔºÅ&lt;/p&gt; 
&lt;p&gt;ËØ¶ÁªÜÁöÑË¥°ÁåÆËÄÖÂêçÂçïÂíåË¥°ÁåÆÂÜÖÂÆπËØ∑Êü•ÁúãÔºö&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/hsliuping/TradingAgents-CN/main/CONTRIBUTORS.md"&gt;üìã Ë¥°ÁåÆËÄÖÂêçÂçï&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;ÂåÖÊã¨‰ΩÜ‰∏çÈôê‰∫éÔºö&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;üê≥ &lt;strong&gt;DockerÂÆπÂô®Âåñ&lt;/strong&gt; - ÈÉ®ÁΩ≤ÊñπÊ°à‰ºòÂåñ&lt;/li&gt; 
 &lt;li&gt;üìÑ &lt;strong&gt;Êä•ÂëäÂØºÂá∫ÂäüËÉΩ&lt;/strong&gt; - Â§öÊ†ºÂºèËæìÂá∫ÊîØÊåÅ&lt;/li&gt; 
 &lt;li&gt;üêõ &lt;strong&gt;Bug‰øÆÂ§ç&lt;/strong&gt; - Á≥ªÁªüÁ®≥ÂÆöÊÄßÊèêÂçá&lt;/li&gt; 
 &lt;li&gt;üîß &lt;strong&gt;‰ª£Á†Å‰ºòÂåñ&lt;/strong&gt; - Áî®Êà∑‰ΩìÈ™åÊîπËøõ&lt;/li&gt; 
 &lt;li&gt;üìù &lt;strong&gt;ÊñáÊ°£ÂÆåÂñÑ&lt;/strong&gt; - ‰ΩøÁî®ÊåáÂçóÂíåÊïôÁ®ã&lt;/li&gt; 
 &lt;li&gt;üåç &lt;strong&gt;Á§æÂå∫Âª∫ËÆæ&lt;/strong&gt; - ÈóÆÈ¢òÂèçÈ¶àÂíåÊé®Âπø&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üåç ÂºÄÊ∫êË¥°ÁåÆ&lt;/strong&gt;: ÊÑüË∞¢ÊÇ®‰ª¨ÈÄâÊã©Apache 2.0ÂçèËÆÆÔºåÁªô‰∫àÂºÄÂèëËÄÖÊúÄÂ§ßÁöÑËá™Áî±&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üìö Áü•ËØÜÂàÜ‰∫´&lt;/strong&gt;: ÊÑüË∞¢ÊÇ®‰ª¨Êèê‰æõÁöÑËØ¶ÁªÜÊñáÊ°£ÂíåÊúÄ‰Ω≥ÂÆûË∑µÊåáÂØº&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;ÁâπÂà´ÊÑüË∞¢&lt;/strong&gt;Ôºö&lt;a href="https://github.com/TauricResearch/TradingAgents"&gt;TradingAgents&lt;/a&gt; È°πÁõÆ‰∏∫Êàë‰ª¨Êèê‰æõ‰∫ÜÂùöÂÆûÁöÑÊäÄÊúØÂü∫Á°Ä„ÄÇËôΩÁÑ∂Apache 2.0ÂçèËÆÆËµã‰∫à‰∫ÜÊàë‰ª¨‰ΩøÁî®Ê∫êÁ†ÅÁöÑÊùÉÂà©Ôºå‰ΩÜÊàë‰ª¨Ê∑±Áü•ÊØè‰∏ÄË°å‰ª£Á†ÅÁöÑÁèçË¥µ‰ª∑ÂÄºÔºåÂ∞ÜÊ∞∏ËøúÈì≠ËÆ∞Âπ∂ÊÑüË∞¢ÊÇ®‰ª¨ÁöÑÊó†ÁßÅË¥°ÁåÆ„ÄÇ&lt;/p&gt; 
&lt;h3&gt;üá®üá≥ Êé®Âπø‰ΩøÂëΩÁöÑÂàùÂøÉ&lt;/h3&gt; 
&lt;p&gt;ÂàõÂª∫Ëøô‰∏™‰∏≠ÊñáÂ¢ûÂº∫ÁâàÊú¨ÔºåÊàë‰ª¨ÊÄÄÁùÄ‰ª•‰∏ãÂàùÂøÉÔºö&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;üåâ ÊäÄÊúØ‰º†Êí≠&lt;/strong&gt;: ËÆ©‰ºòÁßÄÁöÑTradingAgentsÊäÄÊúØÂú®‰∏≠ÂõΩÂæóÂà∞Êõ¥ÂπøÊ≥õÁöÑÂ∫îÁî®&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üéì ÊïôËÇ≤ÊôÆÂèä&lt;/strong&gt;: ‰∏∫‰∏≠ÂõΩÁöÑAIÈáëËûçÊïôËÇ≤Êèê‰æõÊõ¥Â•ΩÁöÑÂ∑•ÂÖ∑ÂíåËµÑÊ∫ê&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ü§ù ÊñáÂåñÊ°•Ê¢Å&lt;/strong&gt;: Âú®‰∏≠Ë•øÊñπÊäÄÊúØÁ§æÂå∫‰πãÈó¥Êê≠Âª∫‰∫§ÊµÅÂêà‰ΩúÁöÑÊ°•Ê¢Å&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üöÄ ÂàõÊñ∞Êé®Âä®&lt;/strong&gt;: Êé®Âä®‰∏≠ÂõΩÈáëËûçÁßëÊäÄÈ¢ÜÂüüÁöÑAIÊäÄÊúØÂàõÊñ∞ÂíåÂ∫îÁî®&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üåç ÂºÄÊ∫êÁ§æÂå∫&lt;/h3&gt; 
&lt;p&gt;ÊÑüË∞¢ÊâÄÊúâ‰∏∫Êú¨È°πÁõÆË¥°ÁåÆ‰ª£Á†Å„ÄÅÊñáÊ°£„ÄÅÂª∫ËÆÆÂíåÂèçÈ¶àÁöÑÂºÄÂèëËÄÖÂíåÁî®Êà∑„ÄÇÊ≠£ÊòØÂõ†‰∏∫Êúâ‰∫ÜÂ§ßÂÆ∂ÁöÑÊîØÊåÅÔºåÊàë‰ª¨ÊâçËÉΩÊõ¥Â•ΩÂú∞ÊúçÂä°‰∏≠ÊñáÁî®Êà∑Á§æÂå∫„ÄÇ&lt;/p&gt; 
&lt;h3&gt;ü§ù Âêà‰ΩúÂÖ±Ëµ¢&lt;/h3&gt; 
&lt;p&gt;Êàë‰ª¨ÊâøËØ∫Ôºö&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Â∞äÈáçÂéüÂàõ&lt;/strong&gt;: ÂßãÁªàÂ∞äÈáçÊ∫êÈ°πÁõÆÁöÑÁü•ËØÜ‰∫ßÊùÉÂíåÂºÄÊ∫êÂçèËÆÆ&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ÂèçÈ¶àË¥°ÁåÆ&lt;/strong&gt;: Â∞ÜÊúâ‰ª∑ÂÄºÁöÑÊîπËøõÂíåÂàõÊñ∞ÂèçÈ¶àÁªôÊ∫êÈ°πÁõÆÂíåÂºÄÊ∫êÁ§æÂå∫&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ÊåÅÁª≠ÊîπËøõ&lt;/strong&gt;: ‰∏çÊñ≠ÂÆåÂñÑ‰∏≠ÊñáÂ¢ûÂº∫ÁâàÊú¨ÔºåÊèê‰æõÊõ¥Â•ΩÁöÑÁî®Êà∑‰ΩìÈ™å&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ÂºÄÊîæÂêà‰Ωú&lt;/strong&gt;: Ê¨¢Ëøé‰∏éÊ∫êÈ°πÁõÆÂõ¢ÈòüÂíåÂÖ®ÁêÉÂºÄÂèëËÄÖËøõË°åÊäÄÊúØ‰∫§ÊµÅ‰∏éÂêà‰Ωú&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üìà ÁâàÊú¨ÂéÜÂè≤&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;v0.1.13&lt;/strong&gt; (2025-08-02): ü§ñ ÂéüÁîüOpenAIÊîØÊåÅ‰∏éGoogle AIÁîüÊÄÅÁ≥ªÁªüÂÖ®Èù¢ÈõÜÊàê ‚ú® &lt;strong&gt;ÊúÄÊñ∞ÁâàÊú¨&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;v0.1.12&lt;/strong&gt; (2025-07-29): üß† Êô∫ËÉΩÊñ∞ÈóªÂàÜÊûêÊ®°Âùó‰∏éÈ°πÁõÆÁªìÊûÑ‰ºòÂåñ&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;v0.1.11&lt;/strong&gt; (2025-07-27): ü§ñ Â§öLLMÊèê‰æõÂïÜÈõÜÊàê‰∏éÊ®°ÂûãÈÄâÊã©ÊåÅ‰πÖÂåñ&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;v0.1.10&lt;/strong&gt; (2025-07-18): üöÄ WebÁïåÈù¢ÂÆûÊó∂ËøõÂ∫¶ÊòæÁ§∫‰∏éÊô∫ËÉΩ‰ºöËØùÁÆ°ÁêÜ&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;v0.1.9&lt;/strong&gt; (2025-07-16): üéØ CLIÁî®Êà∑‰ΩìÈ™åÈáçÂ§ß‰ºòÂåñ‰∏éÁªü‰∏ÄÊó•ÂøóÁÆ°ÁêÜ&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;v0.1.8&lt;/strong&gt; (2025-07-15): üé® WebÁïåÈù¢ÂÖ®Èù¢‰ºòÂåñ‰∏éÁî®Êà∑‰ΩìÈ™åÊèêÂçá&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;v0.1.7&lt;/strong&gt; (2025-07-13): üê≥ ÂÆπÂô®ÂåñÈÉ®ÁΩ≤‰∏é‰∏ì‰∏öÊä•ÂëäÂØºÂá∫&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;v0.1.6&lt;/strong&gt; (2025-07-11): üîß ÈòøÈáåÁôæÁÇº‰øÆÂ§ç‰∏éÊï∞ÊçÆÊ∫êÂçáÁ∫ß&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;v0.1.5&lt;/strong&gt; (2025-07-08): üìä Ê∑ªÂä†DeepseekÊ®°ÂûãÊîØÊåÅ&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;v0.1.4&lt;/strong&gt; (2025-07-05): üèóÔ∏è Êû∂ÊûÑ‰ºòÂåñ‰∏éÈÖçÁΩÆÁÆ°ÁêÜÈáçÊûÑ&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;v0.1.3&lt;/strong&gt; (2025-06-28): üá®üá≥ AËÇ°Â∏ÇÂú∫ÂÆåÊï¥ÊîØÊåÅ&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;v0.1.2&lt;/strong&gt; (2025-06-15): üåê WebÁïåÈù¢ÂíåÈÖçÁΩÆÁÆ°ÁêÜ&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;v0.1.1&lt;/strong&gt; (2025-06-01): üß† ÂõΩ‰∫ßLLMÈõÜÊàê&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;üìã &lt;strong&gt;ËØ¶ÁªÜÊõ¥Êñ∞Êó•Âøó&lt;/strong&gt;: &lt;a href="https://raw.githubusercontent.com/hsliuping/TradingAgents-CN/main/docs/releases/CHANGELOG.md"&gt;CHANGELOG.md&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üìû ËÅîÁ≥ªÊñπÂºè&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;GitHub Issues&lt;/strong&gt;: &lt;a href="https://github.com/hsliuping/TradingAgents-CN/issues"&gt;Êèê‰∫§ÈóÆÈ¢òÂíåÂª∫ËÆÆ&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ÈÇÆÁÆ±&lt;/strong&gt;: &lt;a href="mailto:hsliup@163.com"&gt;hsliup@163.com&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;È°πÁõÆÔº±Ôº±Áæ§Ôºö782124367&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ÂéüÈ°πÁõÆ&lt;/strong&gt;: &lt;a href="https://github.com/TauricResearch/TradingAgents"&gt;TauricResearch/TradingAgents&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ÊñáÊ°£&lt;/strong&gt;: &lt;a href="https://raw.githubusercontent.com/hsliuping/TradingAgents-CN/main/docs/"&gt;ÂÆåÊï¥ÊñáÊ°£ÁõÆÂΩï&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;‚ö†Ô∏è È£éÈô©ÊèêÁ§∫&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;ÈáçË¶ÅÂ£∞Êòé&lt;/strong&gt;: Êú¨Ê°ÜÊû∂‰ªÖÁî®‰∫éÁ†îÁ©∂ÂíåÊïôËÇ≤ÁõÆÁöÑÔºå‰∏çÊûÑÊàêÊäïËµÑÂª∫ËÆÆ„ÄÇ&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;üìä ‰∫§ÊòìË°®Áé∞ÂèØËÉΩÂõ†Â§öÁßçÂõ†Á¥†ËÄåÂºÇ&lt;/li&gt; 
 &lt;li&gt;ü§ñ AIÊ®°ÂûãÁöÑÈ¢ÑÊµãÂ≠òÂú®‰∏çÁ°ÆÂÆöÊÄß&lt;/li&gt; 
 &lt;li&gt;üí∞ ÊäïËµÑÊúâÈ£éÈô©ÔºåÂÜ≥Á≠ñÈúÄË∞®ÊÖé&lt;/li&gt; 
 &lt;li&gt;üë®‚Äçüíº Âª∫ËÆÆÂí®ËØ¢‰∏ì‰∏öË¥¢Âä°È°æÈóÆ&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;strong&gt;üåü Â¶ÇÊûúËøô‰∏™È°πÁõÆÂØπÊÇ®ÊúâÂ∏ÆÂä©ÔºåËØ∑ÁªôÊàë‰ª¨‰∏Ä‰∏™ StarÔºÅ&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://github.com/hsliuping/TradingAgents-CN"&gt;‚≠ê Star this repo&lt;/a&gt; | &lt;a href="https://github.com/hsliuping/TradingAgents-CN/fork"&gt;üç¥ Fork this repo&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/hsliuping/TradingAgents-CN/main/docs/"&gt;üìñ Read the docs&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>Lightricks/LTX-Video</title>
      <link>https://github.com/Lightricks/LTX-Video</link>
      <description>&lt;p&gt;Official repository for LTX-Video&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;h1&gt;LTX-Video&lt;/h1&gt; 
 &lt;p&gt;&lt;a href="https://www.lightricks.com/ltxv"&gt;&lt;img src="https://img.shields.io/badge/Website-LTXV-181717?logo=google-chrome" alt="Website" /&gt;&lt;/a&gt; &lt;a href="https://huggingface.co/Lightricks/LTX-Video"&gt;&lt;img src="https://img.shields.io/badge/HuggingFace-Model-orange?logo=huggingface" alt="Model" /&gt;&lt;/a&gt; &lt;a href="https://app.ltx.studio/motion-workspace?videoModel=ltxv-13b"&gt;&lt;img src="https://img.shields.io/badge/Demo-Try%20Now-brightgreen?logo=vercel" alt="Demo" /&gt;&lt;/a&gt; &lt;a href="https://arxiv.org/abs/2501.00103"&gt;&lt;img src="https://img.shields.io/badge/Paper-arXiv-B31B1B?logo=arxiv" alt="Paper" /&gt;&lt;/a&gt; &lt;a href="https://github.com/Lightricks/LTX-Video-Trainer"&gt;&lt;img src="https://img.shields.io/badge/LTXV-Trainer-9146FF?logo=github" alt="Trainer" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/Mn8BRgUKKy"&gt;&lt;img src="https://img.shields.io/badge/Join-Discord-5865F2?logo=discord" alt="Discord" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;This is the official repository for LTX-Video.&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;Table of Contents&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Lightricks/LTX-Video/main/#introduction"&gt;Introduction&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Lightricks/LTX-Video/main/#news"&gt;What's new&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Lightricks/LTX-Video/main/#models"&gt;Models&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Lightricks/LTX-Video/main/#quick-start-guide"&gt;Quick Start Guide&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Lightricks/LTX-Video/main/#online-inference"&gt;Online demo&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Lightricks/LTX-Video/main/#run-locally"&gt;Run locally&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Lightricks/LTX-Video/main/#installation"&gt;Installation&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Lightricks/LTX-Video/main/#inference"&gt;Inference&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Lightricks/LTX-Video/main/#comfyui-integration"&gt;ComfyUI Integration&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Lightricks/LTX-Video/main/#diffusers-integration"&gt;Diffusers Integration&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Lightricks/LTX-Video/main/#model-user-guide"&gt;Model User Guide&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Lightricks/LTX-Video/main/#community-contribution"&gt;Community Contribution&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Lightricks/LTX-Video/main/#training"&gt;Training&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Lightricks/LTX-Video/main/#control-models"&gt;Control Models&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Lightricks/LTX-Video/main/#join-us-"&gt;Join Us!&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Lightricks/LTX-Video/main/#acknowledgement"&gt;Acknowledgement&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Introduction&lt;/h1&gt; 
&lt;p&gt;LTX-Video is the first DiT-based video generation model that can generate high-quality videos in &lt;em&gt;real-time&lt;/em&gt;. It can generate 30 FPS videos at 1216√ó704 resolution, faster than it takes to watch them. The model is trained on a large-scale dataset of diverse videos and can generate high-resolution videos with realistic and diverse content.&lt;/p&gt; 
&lt;p&gt;The model supports image-to-video, keyframe-based animation, video extension (both forward and backward), video-to-video transformations, and any combination of these features.&lt;/p&gt; 
&lt;h3&gt;Image-to-video examples&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="center"&gt;&lt;/th&gt; 
   &lt;th align="center"&gt;&lt;/th&gt; 
   &lt;th align="center"&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;img src="https://raw.githubusercontent.com/Lightricks/LTX-Video/main/docs/_static/ltx-video_i2v_example_00001.gif" alt="example1" /&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;img src="https://raw.githubusercontent.com/Lightricks/LTX-Video/main/docs/_static/ltx-video_i2v_example_00002.gif" alt="example2" /&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;img src="https://raw.githubusercontent.com/Lightricks/LTX-Video/main/docs/_static/ltx-video_i2v_example_00003.gif" alt="example3" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;img src="https://raw.githubusercontent.com/Lightricks/LTX-Video/main/docs/_static/ltx-video_i2v_example_00004.gif" alt="example4" /&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;img src="https://raw.githubusercontent.com/Lightricks/LTX-Video/main/docs/_static/ltx-video_i2v_example_00005.gif" alt="example5" /&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;img src="https://raw.githubusercontent.com/Lightricks/LTX-Video/main/docs/_static/ltx-video_i2v_example_00006.gif" alt="example6" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;img src="https://raw.githubusercontent.com/Lightricks/LTX-Video/main/docs/_static/ltx-video_i2v_example_00007.gif" alt="example7" /&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;img src="https://raw.githubusercontent.com/Lightricks/LTX-Video/main/docs/_static/ltx-video_i2v_example_00008.gif" alt="example8" /&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;img src="https://raw.githubusercontent.com/Lightricks/LTX-Video/main/docs/_static/ltx-video_i2v_example_00009.gif" alt="example9" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Controlled video examples&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="center"&gt;&lt;/th&gt; 
   &lt;th align="center"&gt;&lt;/th&gt; 
   &lt;th align="center"&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;img src="https://raw.githubusercontent.com/Lightricks/LTX-Video/main/docs/_static/ltx-video_ic_2v_example_00000.gif" alt="control0" /&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;img src="https://raw.githubusercontent.com/Lightricks/LTX-Video/main/docs/_static/ltx-video_ic_2v_example_00001.gif" alt="control1" /&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;img src="https://raw.githubusercontent.com/Lightricks/LTX-Video/main/docs/_static/ltx-video_ic_2v_example_00002.gif" alt="control2" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="center"&gt;&lt;/th&gt; 
   &lt;th align="center"&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;img src="https://raw.githubusercontent.com/Lightricks/LTX-Video/main/docs/_static/ltx-video_ic_2v_example_00003.gif" alt="control3" /&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;img src="https://raw.githubusercontent.com/Lightricks/LTX-Video/main/docs/_static/ltx-video_ic_2v_example_00004.gif" alt="control4" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h1&gt;News&lt;/h1&gt; 
&lt;h2&gt;July, 16th, 2025: New Distilled models v0.9.8 with up to 60 seconds of video:&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Long shot generation in LTXV-13B! 
  &lt;ul&gt; 
   &lt;li&gt;LTX-Video now supports up to 60 seconds of video.&lt;/li&gt; 
   &lt;li&gt;Compatible also with the official IC-LoRAs.&lt;/li&gt; 
   &lt;li&gt;Try now in &lt;a href="https://github.com/Lightricks/ComfyUI-LTXVideo/tree/master/example_workflows/ltxv-13b-i2v-long-multi-prompt.json"&gt;ComfyUI&lt;/a&gt;.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Release a new distilled models: 
  &lt;ul&gt; 
   &lt;li&gt;13B distilled model &lt;a href="https://github.com/Lightricks/LTX-Video/raw/main/configs/ltxv-13b-0.9.8-distilled.yaml"&gt;ltxv-13b-0.9.8-distilled&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;2B distilled model &lt;a href="https://github.com/Lightricks/LTX-Video/raw/main/configs/ltxv-2b-0.9.8-distilled.yaml"&gt;ltxv-2b-0.9.8-distilled&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;Both models are distilled from the same base model &lt;a href="https://github.com/Lightricks/LTX-Video/raw/main/configs/ltxv-13b-0.9.8-dev.yaml"&gt;ltxv-13b-0.9.8-dev&lt;/a&gt; and are compatible for use together in the same multiscale pipeline.&lt;/li&gt; 
   &lt;li&gt;Improved prompt understanding and detail generation&lt;/li&gt; 
   &lt;li&gt;Includes corresponding FP8 weights and workflows.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Release a new detailer model &lt;a href="https://huggingface.co/Lightricks/LTX-Video-ICLoRA-detailer-13b-0.9.8"&gt;LTX-Video-ICLoRA-detailer-13B-0.9.8&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Available in &lt;a href="https://github.com/Lightricks/ComfyUI-LTXVideo/tree/master/example_workflows/ltxv-13b-upscale.json"&gt;ComfyUI&lt;/a&gt;.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;July, 8th, 2025: New Control Models Released!&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Released three new control models for LTX-Video on HuggingFace: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Depth Control&lt;/strong&gt;: &lt;a href="https://huggingface.co/Lightricks/LTX-Video-ICLoRA-depth-13b-0.9.7"&gt;LTX-Video-ICLoRA-depth-13b-0.9.7&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Pose Control&lt;/strong&gt;: &lt;a href="https://huggingface.co/Lightricks/LTX-Video-ICLoRA-pose-13b-0.9.7"&gt;LTX-Video-ICLoRA-pose-13b-0.9.7&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Canny Control&lt;/strong&gt;: &lt;a href="https://huggingface.co/Lightricks/LTX-Video-ICLoRA-canny-13b-0.9.7"&gt;LTX-Video-ICLoRA-canny-13b-0.9.7&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;May, 14th, 2025: New distilled model 13B v0.9.7:&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Release a new 13B distilled model &lt;a href="https://huggingface.co/Lightricks/LTX-Video/blob/main/ltxv-13b-0.9.7-distilled.safetensors"&gt;ltxv-13b-0.9.7-distilled&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Amazing for iterative work - generates HD videos in 10 seconds, with low-res preview after just 3 seconds (on H100)!&lt;/li&gt; 
   &lt;li&gt;Does not require classifier-free guidance and spatio-temporal guidance.&lt;/li&gt; 
   &lt;li&gt;Supports sampling with 8 (recommended), or less diffusion steps.&lt;/li&gt; 
   &lt;li&gt;Also released a LoRA version of the distilled model, &lt;a href="https://huggingface.co/Lightricks/LTX-Video/blob/main/ltxv-13b-0.9.7-distilled-lora128.safetensors"&gt;ltxv-13b-0.9.7-distilled-lora128&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;Requires only 1GB of VRAM&lt;/li&gt; 
     &lt;li&gt;Can be used with the full 13B model for fast inference&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Release a new quantized distilled model &lt;a href="https://huggingface.co/Lightricks/LTX-Video/blob/main/ltxv-13b-0.9.7-distilled-fp8.safetensors"&gt;ltxv-13b-0.9.7-distilled-fp8&lt;/a&gt; for &lt;em&gt;real-time&lt;/em&gt; generation (on H100) with even less VRAM&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;May, 5th, 2025: New model 13B v0.9.7:&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Release a new 13B model &lt;a href="https://huggingface.co/Lightricks/LTX-Video/blob/main/ltxv-13b-0.9.7-dev.safetensors"&gt;ltxv-13b-0.9.7-dev&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Release a new quantized model &lt;a href="https://huggingface.co/Lightricks/LTX-Video/blob/main/ltxv-13b-0.9.7-dev-fp8.safetensors"&gt;ltxv-13b-0.9.7-dev-fp8&lt;/a&gt; for faster inference with less VRam&lt;/li&gt; 
 &lt;li&gt;Release a new upscalers 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://huggingface.co/Lightricks/LTX-Video/blob/main/ltxv-temporal-upscaler-0.9.7.safetensors"&gt;ltxv-temporal-upscaler-0.9.7&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://huggingface.co/Lightricks/LTX-Video/blob/main/ltxv-spatial-upscaler-0.9.7.safetensors"&gt;ltxv-spatial-upscaler-0.9.7&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Breakthrough prompt adherence and physical understanding.&lt;/li&gt; 
 &lt;li&gt;New Pipeline for multi-scale video rendering for fast and high quality results&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;April, 15th, 2025: New checkpoints v0.9.6:&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Release a new checkpoint &lt;a href="https://huggingface.co/Lightricks/LTX-Video/blob/main/ltxv-2b-0.9.6-dev-04-25.safetensors"&gt;ltxv-2b-0.9.6-dev-04-25&lt;/a&gt; with improved quality&lt;/li&gt; 
 &lt;li&gt;Release a new distilled model &lt;a href="https://huggingface.co/Lightricks/LTX-Video/blob/main/ltxv-2b-0.9.6-distilled-04-25.safetensors"&gt;ltxv-2b-0.9.6-distilled-04-25&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;15x faster inference than non-distilled model.&lt;/li&gt; 
   &lt;li&gt;Does not require classifier-free guidance and spatio-temporal guidance.&lt;/li&gt; 
   &lt;li&gt;Supports sampling with 8 (recommended), or less diffusion steps.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Improved prompt adherence, motion quality and fine details.&lt;/li&gt; 
 &lt;li&gt;New default resolution and FPS: 1216 √ó 704 pixels at 30 FPS 
  &lt;ul&gt; 
   &lt;li&gt;Still real time on H100 with the distilled model.&lt;/li&gt; 
   &lt;li&gt;Other resolutions and FPS are still supported.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Support stochastic inference (can improve visual quality when using the distilled model)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;March, 5th, 2025: New checkpoint v0.9.5&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;New license for commercial use (&lt;a href="https://huggingface.co/Lightricks/LTX-Video/ltx-video-2b-v0.9.5.license.txt"&gt;OpenRail-M&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;Release a new checkpoint v0.9.5 with improved quality&lt;/li&gt; 
 &lt;li&gt;Support keyframes and video extension&lt;/li&gt; 
 &lt;li&gt;Support higher resolutions&lt;/li&gt; 
 &lt;li&gt;Improved prompt understanding&lt;/li&gt; 
 &lt;li&gt;Improved VAE&lt;/li&gt; 
 &lt;li&gt;New online web app in &lt;a href="https://app.ltx.studio/ltx-video"&gt;LTX-Studio&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Automatic prompt enhancement&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;February, 20th, 2025: More inference options&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Improve STG (Spatiotemporal Guidance) for LTX-Video&lt;/li&gt; 
 &lt;li&gt;Support MPS on macOS with PyTorch 2.3.0&lt;/li&gt; 
 &lt;li&gt;Add support for 8-bit model, LTX-VideoQ8&lt;/li&gt; 
 &lt;li&gt;Add TeaCache for LTX-Video&lt;/li&gt; 
 &lt;li&gt;Add &lt;a href="https://raw.githubusercontent.com/Lightricks/LTX-Video/main/#comfyui-integration"&gt;ComfyUI-LTXTricks&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Add Diffusion-Pipe&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;December 31st, 2024: Research paper&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Release the &lt;a href="https://arxiv.org/abs/2501.00103"&gt;research paper&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;December 20th, 2024: New checkpoint v0.9.1&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Release a new checkpoint v0.9.1 with improved quality&lt;/li&gt; 
 &lt;li&gt;Support for STG / PAG&lt;/li&gt; 
 &lt;li&gt;Support loading checkpoints of LTX-Video in Diffusers format (conversion is done on-the-fly)&lt;/li&gt; 
 &lt;li&gt;Support offloading unused parts to CPU&lt;/li&gt; 
 &lt;li&gt;Support the new timestep-conditioned VAE decoder&lt;/li&gt; 
 &lt;li&gt;Reference contributions from the community in the readme file&lt;/li&gt; 
 &lt;li&gt;Relax transformers dependency&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;November 21th, 2024: Initial release v0.9.0&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Initial release of LTX-Video&lt;/li&gt; 
 &lt;li&gt;Support text-to-video and image-to-video generation&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Models &amp;amp; Workflows&lt;/h1&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Name&lt;/th&gt; 
   &lt;th&gt;Notes&lt;/th&gt; 
   &lt;th&gt;inference.py config&lt;/th&gt; 
   &lt;th&gt;ComfyUI workflow (Recommended)&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ltxv-13b-0.9.8-dev&lt;/td&gt; 
   &lt;td&gt;Highest quality, requires more VRAM&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/Lightricks/LTX-Video/raw/main/configs/ltxv-13b-0.9.8-dev.yaml"&gt;ltxv-13b-0.9.8-dev.yaml&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/Lightricks/ComfyUI-LTXVideo/raw/master/example_workflows/ltxv-13b-i2v-base.json"&gt;ltxv-13b-i2v-base.json&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://app.ltx.studio/motion-workspace?videoModel=ltxv-13b"&gt;ltxv-13b-0.9.8-mix&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Mix ltxv-13b-dev and ltxv-13b-distilled in the same multi-scale rendering workflow for balanced speed-quality&lt;/td&gt; 
   &lt;td&gt;N/A&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/Lightricks/ComfyUI-LTXVideo/raw/master/example_workflows/ltxv-13b-i2v-mixed-multiscale.json"&gt;ltxv-13b-i2v-mixed-multiscale.json&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://app.ltx.studio/motion-workspace?videoModel=ltxv"&gt;ltxv-13b-0.9.8-distilled&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Faster, less VRAM usage, slight quality reduction compared to 13b. Ideal for rapid iterations&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/Lightricks/LTX-Video/raw/main/configs/ltxv-13b-0.9.8-distilled.yaml"&gt;ltxv-13b-0.9.8-distilled.yaml&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/Lightricks/ComfyUI-LTXVideo/raw/master/example_workflows/13b-distilled/ltxv-13b-dist-i2v-base.json"&gt;ltxv-13b-dist-i2v-base.json&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ltxv-2b-0.9.8-distilled&lt;/td&gt; 
   &lt;td&gt;Smaller model, slight quality reduction compared to 13b distilled. Ideal for fast generation with light VRAM usage&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/Lightricks/LTX-Video/raw/main/configs/ltxv-2b-0.9.8-distilled.yaml"&gt;ltxv-2b-0.9.8-distilled.yaml&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;N/A&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ltxv-13b-0.9.8-dev-fp8&lt;/td&gt; 
   &lt;td&gt;Quantized version of ltxv-13b&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/Lightricks/LTX-Video/raw/main/configs/ltxv-13b-0.9.8-dev-fp8.yaml"&gt;ltxv-13b-0.9.8-dev-fp8.yaml&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/Lightricks/ComfyUI-LTXVideo/raw/master/example_workflows/ltxv-13b-i2v-base-fp8.json"&gt;ltxv-13b-i2v-base-fp8.json&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ltxv-13b-0.9.8-distilled-fp8&lt;/td&gt; 
   &lt;td&gt;Quantized version of ltxv-13b-distilled&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/Lightricks/LTX-Video/raw/main/configs/ltxv-13b-0.9.8-distilled-fp8.yaml"&gt;ltxv-13b-0.9.8-distilled-fp8.yaml&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/Lightricks/ComfyUI-LTXVideo/raw/master/example_workflows/13b-distilled/ltxv-13b-dist-i2v-base-fp8.json"&gt;ltxv-13b-dist-i2v-base-fp8.json&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ltxv-2b-0.9.8-distilled-fp8&lt;/td&gt; 
   &lt;td&gt;Quantized version of ltxv-2b-distilled&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/Lightricks/LTX-Video/raw/main/configs/ltxv-2b-0.9.8-distilled-fp8.yaml"&gt;ltxv-2b-0.9.8-distilled-fp8.yaml&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;N/A&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ltxv-2b-0.9.6&lt;/td&gt; 
   &lt;td&gt;Good quality, lower VRAM requirement than ltxv-13b&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/Lightricks/LTX-Video/raw/main/configs/ltxv-2b-0.9.6-dev.yaml"&gt;ltxv-2b-0.9.6-dev.yaml&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/Lightricks/ComfyUI-LTXVideo/raw/master/example_workflows/low_level/ltxvideo-i2v.json"&gt;ltxvideo-i2v.json&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ltxv-2b-0.9.6-distilled&lt;/td&gt; 
   &lt;td&gt;15√ó faster, real-time capable, fewer steps needed, no STG/CFG required&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/Lightricks/LTX-Video/raw/main/configs/ltxv-2b-0.9.6-distilled.yaml"&gt;ltxv-2b-0.9.6-distilled.yaml&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/Lightricks/ComfyUI-LTXVideo/raw/master/example_workflows/low_level/ltxvideo-i2v-distilled.json"&gt;ltxvideo-i2v-distilled.json&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h1&gt;Quick Start Guide&lt;/h1&gt; 
&lt;h2&gt;Online inference&lt;/h2&gt; 
&lt;p&gt;The model is accessible right away via the following links:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://app.ltx.studio/motion-workspace?videoModel=ltxv-13b"&gt;LTX-Studio image-to-video (13B-mix)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://app.ltx.studio/motion-workspace?videoModel=ltxv"&gt;LTX-Studio image-to-video (13B distilled)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://fal.ai/models/fal-ai/ltx-video-13b-dev/image-to-video"&gt;Fal.ai image-to-video (13B full)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://fal.ai/models/fal-ai/ltx-video-13b-distilled/image-to-video"&gt;Fal.ai image-to-video (13B distilled)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://replicate.com/lightricks/ltx-video"&gt;Replicate image-to-video&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Run locally&lt;/h2&gt; 
&lt;h3&gt;Installation&lt;/h3&gt; 
&lt;p&gt;The codebase was tested with Python 3.10.5, CUDA version 12.2, and supports PyTorch &amp;gt;= 2.1.2. On macOS, MPS was tested with PyTorch 2.3.0, and should support PyTorch == 2.3 or &amp;gt;= 2.6.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/Lightricks/LTX-Video.git
cd LTX-Video

# create env
python -m venv env
source env/bin/activate
python -m pip install -e .\[inference\]
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;FP8 Kernels (optional)&lt;/h4&gt; 
&lt;p&gt;&lt;a href="https://github.com/Lightricks/LTXVideo-Q8-Kernels"&gt;FP8 kernels&lt;/a&gt; developed for LTX-Video provide performance boost on supported graphics cards (Ada architecture and later). To install FP8 kernels, follow the instructions in that repository.&lt;/p&gt; 
&lt;h3&gt;Inference&lt;/h3&gt; 
&lt;p&gt;üìù &lt;strong&gt;Note:&lt;/strong&gt; For best results, we recommend using our &lt;a href="https://raw.githubusercontent.com/Lightricks/LTX-Video/main/#comfyui-integration"&gt;ComfyUI&lt;/a&gt; workflow. We're working on updating the inference.py script to match the high quality and output fidelity of ComfyUI.&lt;/p&gt; 
&lt;p&gt;To use our model, please follow the inference code in &lt;a href="https://raw.githubusercontent.com/Lightricks/LTX-Video/main/inference.py"&gt;inference.py&lt;/a&gt;:&lt;/p&gt; 
&lt;h4&gt;For image-to-video generation:&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python inference.py --prompt "PROMPT" --conditioning_media_paths IMAGE_PATH --conditioning_start_frames 0 --height HEIGHT --width WIDTH --num_frames NUM_FRAMES --seed SEED --pipeline_config configs/ltxv-13b-0.9.8-distilled.yaml
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Extending a video:&lt;/h4&gt; 
&lt;p&gt;üìù &lt;strong&gt;Note:&lt;/strong&gt; Input video segments must contain a multiple of 8 frames plus 1 (e.g., 9, 17, 25, etc.), and the target frame number should be a multiple of 8.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python inference.py --prompt "PROMPT" --conditioning_media_paths VIDEO_PATH --conditioning_start_frames START_FRAME --height HEIGHT --width WIDTH --num_frames NUM_FRAMES --seed SEED --pipeline_config configs/ltxv-13b-0.9.8-distilled.yaml
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;For video generation with multiple conditions:&lt;/h4&gt; 
&lt;p&gt;You can now generate a video conditioned on a set of images and/or short video segments. Simply provide a list of paths to the images or video segments you want to condition on, along with their target frame numbers in the generated video. You can also specify the conditioning strength for each item (default: 1.0).&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python inference.py --prompt "PROMPT" --conditioning_media_paths IMAGE_OR_VIDEO_PATH_1 IMAGE_OR_VIDEO_PATH_2 --conditioning_start_frames TARGET_FRAME_1 TARGET_FRAME_2 --height HEIGHT --width WIDTH --num_frames NUM_FRAMES --seed SEED --pipeline_config configs/ltxv-13b-0.9.8-distilled.yaml
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Using as a library&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from ltx_video.inference import infer, InferenceConfig

infer(
    InferenceConfig(
        pipeline_config="configs/ltxv-13b-0.9.8-distilled.yaml",
        prompt=PROMPT,
        height=HEIGHT,
        width=WIDTH,
        num_frames=NUM_FRAMES,
        output_path="output.mp4",
    )
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;ComfyUI Integration&lt;/h2&gt; 
&lt;p&gt;To use our model with ComfyUI, please follow the instructions at &lt;a href="https://github.com/Lightricks/ComfyUI-LTXVideo/"&gt;https://github.com/Lightricks/ComfyUI-LTXVideo/&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Diffusers Integration&lt;/h2&gt; 
&lt;p&gt;To use our model with the Diffusers Python library, check out the &lt;a href="https://huggingface.co/docs/diffusers/main/en/api/pipelines/ltx_video"&gt;official documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Diffusers also support an 8-bit version of LTX-Video, &lt;a href="https://raw.githubusercontent.com/Lightricks/LTX-Video/main/#ltx-videoq8"&gt;see details below&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Model User Guide&lt;/h1&gt; 
&lt;h2&gt;üìù Prompt Engineering&lt;/h2&gt; 
&lt;p&gt;When writing prompts, focus on detailed, chronological descriptions of actions and scenes. Include specific movements, appearances, camera angles, and environmental details - all in a single flowing paragraph. Start directly with the action, and keep descriptions literal and precise. Think like a cinematographer describing a shot list. Keep within 200 words. For best results, build your prompts using this structure:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Start with main action in a single sentence&lt;/li&gt; 
 &lt;li&gt;Add specific details about movements and gestures&lt;/li&gt; 
 &lt;li&gt;Describe character/object appearances precisely&lt;/li&gt; 
 &lt;li&gt;Include background and environment details&lt;/li&gt; 
 &lt;li&gt;Specify camera angles and movements&lt;/li&gt; 
 &lt;li&gt;Describe lighting and colors&lt;/li&gt; 
 &lt;li&gt;Note any changes or sudden events&lt;/li&gt; 
 &lt;li&gt;See &lt;a href="https://raw.githubusercontent.com/Lightricks/LTX-Video/main/#introduction"&gt;examples&lt;/a&gt; for more inspiration.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Automatic Prompt Enhancement&lt;/h3&gt; 
&lt;p&gt;When using &lt;code&gt;LTXVideoPipeline&lt;/code&gt; directly, you can enable prompt enhancement by setting &lt;code&gt;enhance_prompt=True&lt;/code&gt;.&lt;/p&gt; 
&lt;h2&gt;üéÆ Parameter Guide&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Resolution Preset: Higher resolutions for detailed scenes, lower for faster generation and simpler scenes. The model works on resolutions that are divisible by 32 and number of frames that are divisible by 8 + 1 (e.g. 257). In case the resolution or number of frames are not divisible by 32 or 8 + 1, the input will be padded with -1 and then cropped to the desired resolution and number of frames. The model works best on resolutions under 720 x 1280 and number of frames below 257&lt;/li&gt; 
 &lt;li&gt;Seed: Save seed values to recreate specific styles or compositions you like&lt;/li&gt; 
 &lt;li&gt;Guidance Scale: 3-3.5 are the recommended values&lt;/li&gt; 
 &lt;li&gt;Inference Steps: More steps (40+) for quality, fewer steps (20-30) for speed&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;üìù For advanced parameters usage, please see &lt;code&gt;python inference.py --help&lt;/code&gt;&lt;/p&gt; 
&lt;h2&gt;Community Contribution&lt;/h2&gt; 
&lt;h3&gt;ComfyUI-LTXTricks üõ†Ô∏è&lt;/h3&gt; 
&lt;p&gt;A community project providing additional nodes for enhanced control over the LTX Video model. It includes implementations of advanced techniques like RF-Inversion, RF-Edit, FlowEdit, and more. These nodes enable workflows such as Image and Video to Video (I+V2V), enhanced sampling via Spatiotemporal Skip Guidance (STG), and interpolation with precise frame settings.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Repository:&lt;/strong&gt; &lt;a href="https://github.com/logtd/ComfyUI-LTXTricks"&gt;ComfyUI-LTXTricks&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Features:&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;üîÑ &lt;strong&gt;RF-Inversion:&lt;/strong&gt; Implements &lt;a href="https://rf-inversion.github.io/"&gt;RF-Inversion&lt;/a&gt; with an &lt;a href="https://github.com/logtd/ComfyUI-LTXTricks/raw/main/example_workflows/example_ltx_inversion.json"&gt;example workflow here&lt;/a&gt;.&lt;/li&gt; 
   &lt;li&gt;‚úÇÔ∏è &lt;strong&gt;RF-Edit:&lt;/strong&gt; Implements &lt;a href="https://github.com/wangjiangshan0725/RF-Solver-Edit"&gt;RF-Solver-Edit&lt;/a&gt; with an &lt;a href="https://github.com/logtd/ComfyUI-LTXTricks/raw/main/example_workflows/example_ltx_rf_edit.json"&gt;example workflow here&lt;/a&gt;.&lt;/li&gt; 
   &lt;li&gt;üåä &lt;strong&gt;FlowEdit:&lt;/strong&gt; Implements &lt;a href="https://github.com/fallenshock/FlowEdit"&gt;FlowEdit&lt;/a&gt; with an &lt;a href="https://github.com/logtd/ComfyUI-LTXTricks/raw/main/example_workflows/example_ltx_flow_edit.json"&gt;example workflow here&lt;/a&gt;.&lt;/li&gt; 
   &lt;li&gt;üé• &lt;strong&gt;I+V2V:&lt;/strong&gt; Enables Video to Video with a reference image. &lt;a href="https://github.com/logtd/ComfyUI-LTXTricks/raw/main/example_workflows/example_ltx_iv2v.json"&gt;Example workflow&lt;/a&gt;.&lt;/li&gt; 
   &lt;li&gt;‚ú® &lt;strong&gt;Enhance:&lt;/strong&gt; Partial implementation of &lt;a href="https://junhahyung.github.io/STGuidance/"&gt;STGuidance&lt;/a&gt;. &lt;a href="https://github.com/logtd/ComfyUI-LTXTricks/raw/main/example_workflows/example_ltxv_stg.json"&gt;Example workflow&lt;/a&gt;.&lt;/li&gt; 
   &lt;li&gt;üñºÔ∏è &lt;strong&gt;Interpolation and Frame Setting:&lt;/strong&gt; Nodes for precise control of latents per frame. &lt;a href="https://github.com/logtd/ComfyUI-LTXTricks/raw/main/example_workflows/example_ltx_interpolation.json"&gt;Example workflow&lt;/a&gt;.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;LTX-VideoQ8 üé± &lt;a id="ltx-videoq8"&gt;&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;LTX-VideoQ8&lt;/strong&gt; is an 8-bit optimized version of &lt;a href="https://github.com/Lightricks/LTX-Video"&gt;LTX-Video&lt;/a&gt;, designed for faster performance on NVIDIA ADA GPUs.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Repository:&lt;/strong&gt; &lt;a href="https://github.com/KONAKONA666/LTX-Video"&gt;LTX-VideoQ8&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Features:&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;üöÄ Up to 3X speed-up with no accuracy loss&lt;/li&gt; 
   &lt;li&gt;üé• Generate 720x480x121 videos in under a minute on RTX 4060 (8GB VRAM)&lt;/li&gt; 
   &lt;li&gt;üõ†Ô∏è Fine-tune 2B transformer models with precalculated latents&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Community Discussion:&lt;/strong&gt; &lt;a href="https://www.reddit.com/r/StableDiffusion/comments/1h79ks2/fast_ltx_video_on_rtx_4060_and_other_ada_gpus/"&gt;Reddit Thread&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Diffusers integration:&lt;/strong&gt; A diffusers integration for the 8-bit model is already out! &lt;a href="https://github.com/sayakpaul/q8-ltx-video"&gt;Details here&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;TeaCache for LTX-Video üçµ &lt;a id="TeaCache"&gt;&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;TeaCache&lt;/strong&gt; is a training-free caching approach that leverages timestep differences across model outputs to accelerate LTX-Video inference by up to 2x without significant visual quality degradation.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Repository:&lt;/strong&gt; &lt;a href="https://github.com/ali-vilab/TeaCache/tree/main/TeaCache4LTX-Video"&gt;TeaCache4LTX-Video&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Features:&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;üöÄ Speeds up LTX-Video inference.&lt;/li&gt; 
   &lt;li&gt;üìä Adjustable trade-offs between speed (up to 2x) and visual quality using configurable parameters.&lt;/li&gt; 
   &lt;li&gt;üõ†Ô∏è No retraining required: Works directly with existing models.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Your Contribution&lt;/h3&gt; 
&lt;p&gt;...is welcome! If you have a project or tool that integrates with LTX-Video, please let us know by opening an issue or pull request.&lt;/p&gt; 
&lt;h1&gt;‚ö°Ô∏è Training&lt;/h1&gt; 
&lt;p&gt;We provide an open-source repository for fine-tuning the LTX-Video model: &lt;a href="https://github.com/Lightricks/LTX-Video-Trainer"&gt;LTX-Video-Trainer&lt;/a&gt;. This repository supports both the 2B and 13B model variants, enabling full fine-tuning as well as LoRA (Low-Rank Adaptation) fine-tuning for more efficient training. This includes:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Control LoRAs&lt;/strong&gt;: Train custom control models like depth, pose, and canny control&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Effect LoRAs&lt;/strong&gt;: Create specialized effects and transformations for video generation&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Explore the repository to customize the model for your specific use cases! More information and training instructions can be found in the &lt;a href="https://github.com/Lightricks/LTX-Video-Trainer/raw/main/README.md"&gt;README&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;üé¨ Control Models&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://github.com/Lightricks/ComfyUI-LTXVideo"&gt;ComfyUI-LTXVideo&lt;/a&gt; repository now contains workflows and models for 3 specialized models that enable precise control over LTX-Video generation:&lt;/p&gt; 
&lt;p&gt;Pose Control, Depth Control and Canny Control&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Example ComfyUI Workflow (for all control types):&lt;/strong&gt; &lt;a href="https://github.com/Lightricks/ComfyUI-LTXVideo/raw/master/example_workflows/ic_lora/ic-lora.json"&gt;ic-lora.json&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;üöÄ Join Us&lt;/h1&gt; 
&lt;p&gt;Want to work on cutting-edge AI research and make a real impact on millions of users worldwide?&lt;/p&gt; 
&lt;p&gt;At &lt;strong&gt;Lightricks&lt;/strong&gt;, an AI-first company, we're revolutionizing how visual content is created.&lt;/p&gt; 
&lt;p&gt;If you are passionate about AI, computer vision, and video generation, we would love to hear from you!&lt;/p&gt; 
&lt;p&gt;Please visit our &lt;a href="https://careers.lightricks.com/careers?query=&amp;amp;office=all&amp;amp;department=R%26D"&gt;careers page&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;h1&gt;Acknowledgement&lt;/h1&gt; 
&lt;p&gt;We are grateful for the following awesome projects when implementing LTX-Video:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/facebookresearch/DiT"&gt;DiT&lt;/a&gt; and &lt;a href="https://github.com/PixArt-alpha/PixArt-alpha"&gt;PixArt-alpha&lt;/a&gt;: vision transformers for image generation.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Citation&lt;/h2&gt; 
&lt;p&gt;üìÑ Our tech report is out! If you find our work helpful, please ‚≠êÔ∏è star the repository and cite our paper.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;@article{HaCohen2024LTXVideo,
  title={LTX-Video: Realtime Video Latent Diffusion},
  author={HaCohen, Yoav and Chiprut, Nisan and Brazowski, Benny and Shalem, Daniel and Moshe, Dudu and Richardson, Eitan and Levin, Eran and Shiran, Guy and Zabari, Nir and Gordon, Ori and Panet, Poriya and Weissbuch, Sapir and Kulikov, Victor and Bitterman, Yaki and Melumian, Zeev and Bibi, Ofir},
  journal={arXiv preprint arXiv:2501.00103},
  year={2024}
}
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
  </channel>
</rss>