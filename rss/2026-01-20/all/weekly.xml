<rss version="2.0">
  <channel>
    <title>GitHub All Languages Weekly Trending</title>
    <description>Weekly Trending of All Languages in GitHub</description>
    <pubDate>Mon, 19 Jan 2026 01:41:22 GMT</pubDate>
    <link>http://mshibanami.github.io/GitHubTrendingRSS</link>
    
    <item>
      <title>obra/superpowers</title>
      <link>https://github.com/obra/superpowers</link>
      <description>&lt;p&gt;An agentic skills framework &amp; software development methodology that works.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Superpowers&lt;/h1&gt; 
&lt;p&gt;Superpowers is a complete software development workflow for your coding agents, built on top of a set of composable "skills" and some initial instructions that make sure your agent uses them.&lt;/p&gt; 
&lt;h2&gt;How it works&lt;/h2&gt; 
&lt;p&gt;It starts from the moment you fire up your coding agent. As soon as it sees that you're building something, it &lt;em&gt;doesn't&lt;/em&gt; just jump into trying to write code. Instead, it steps back and asks you what you're really trying to do.&lt;/p&gt; 
&lt;p&gt;Once it's teased a spec out of the conversation, it shows it to you in chunks short enough to actually read and digest.&lt;/p&gt; 
&lt;p&gt;After you've signed off on the design, your agent puts together an implementation plan that's clear enough for an enthusiastic junior engineer with poor taste, no judgement, no project context, and an aversion to testing to follow. It emphasizes true red/green TDD, YAGNI (You Aren't Gonna Need It), and DRY.&lt;/p&gt; 
&lt;p&gt;Next up, once you say "go", it launches a &lt;em&gt;subagent-driven-development&lt;/em&gt; process, having agents work through each engineering task, inspecting and reviewing their work, and continuing forward. It's not uncommon for Claude to be able to work autonomously for a couple hours at a time without deviating from the plan you put together.&lt;/p&gt; 
&lt;p&gt;There's a bunch more to it, but that's the core of the system. And because the skills trigger automatically, you don't need to do anything special. Your coding agent just has Superpowers.&lt;/p&gt; 
&lt;h2&gt;Sponsorship&lt;/h2&gt; 
&lt;p&gt;If Superpowers has helped you do stuff that makes money and you are so inclined, I'd greatly appreciate it if you'd consider &lt;a href="https://github.com/sponsors/obra"&gt;sponsoring my opensource work&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Thanks!&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Jesse&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; Installation differs by platform. Claude Code has a built-in plugin system. Codex and OpenCode require manual setup.&lt;/p&gt; 
&lt;h3&gt;Claude Code (via Plugin Marketplace)&lt;/h3&gt; 
&lt;p&gt;In Claude Code, register the marketplace first:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;/plugin marketplace add obra/superpowers-marketplace
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then install the plugin from this marketplace:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;/plugin install superpowers@superpowers-marketplace
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Verify Installation&lt;/h3&gt; 
&lt;p&gt;Check that commands appear:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;/help
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code&gt;# Should see:
# /superpowers:brainstorm - Interactive design refinement
# /superpowers:write-plan - Create implementation plan
# /superpowers:execute-plan - Execute plan in batches
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Codex&lt;/h3&gt; 
&lt;p&gt;Tell Codex:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Fetch and follow instructions from https://raw.githubusercontent.com/obra/superpowers/refs/heads/main/.codex/INSTALL.md
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Detailed docs:&lt;/strong&gt; &lt;a href="https://raw.githubusercontent.com/obra/superpowers/main/docs/README.codex.md"&gt;docs/README.codex.md&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;OpenCode&lt;/h3&gt; 
&lt;p&gt;Tell OpenCode:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Fetch and follow instructions from https://raw.githubusercontent.com/obra/superpowers/refs/heads/main/.opencode/INSTALL.md
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Detailed docs:&lt;/strong&gt; &lt;a href="https://raw.githubusercontent.com/obra/superpowers/main/docs/README.opencode.md"&gt;docs/README.opencode.md&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;The Basic Workflow&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;brainstorming&lt;/strong&gt; - Activates before writing code. Refines rough ideas through questions, explores alternatives, presents design in sections for validation. Saves design document.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;using-git-worktrees&lt;/strong&gt; - Activates after design approval. Creates isolated workspace on new branch, runs project setup, verifies clean test baseline.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;writing-plans&lt;/strong&gt; - Activates with approved design. Breaks work into bite-sized tasks (2-5 minutes each). Every task has exact file paths, complete code, verification steps.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;subagent-driven-development&lt;/strong&gt; or &lt;strong&gt;executing-plans&lt;/strong&gt; - Activates with plan. Dispatches fresh subagent per task with two-stage review (spec compliance, then code quality), or executes in batches with human checkpoints.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;test-driven-development&lt;/strong&gt; - Activates during implementation. Enforces RED-GREEN-REFACTOR: write failing test, watch it fail, write minimal code, watch it pass, commit. Deletes code written before tests.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;requesting-code-review&lt;/strong&gt; - Activates between tasks. Reviews against plan, reports issues by severity. Critical issues block progress.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;finishing-a-development-branch&lt;/strong&gt; - Activates when tasks complete. Verifies tests, presents options (merge/PR/keep/discard), cleans up worktree.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;The agent checks for relevant skills before any task.&lt;/strong&gt; Mandatory workflows, not suggestions.&lt;/p&gt; 
&lt;h2&gt;What's Inside&lt;/h2&gt; 
&lt;h3&gt;Skills Library&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Testing&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;test-driven-development&lt;/strong&gt; - RED-GREEN-REFACTOR cycle (includes testing anti-patterns reference)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Debugging&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;systematic-debugging&lt;/strong&gt; - 4-phase root cause process (includes root-cause-tracing, defense-in-depth, condition-based-waiting techniques)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;verification-before-completion&lt;/strong&gt; - Ensure it's actually fixed&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Collaboration&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;brainstorming&lt;/strong&gt; - Socratic design refinement&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;writing-plans&lt;/strong&gt; - Detailed implementation plans&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;executing-plans&lt;/strong&gt; - Batch execution with checkpoints&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;dispatching-parallel-agents&lt;/strong&gt; - Concurrent subagent workflows&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;requesting-code-review&lt;/strong&gt; - Pre-review checklist&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;receiving-code-review&lt;/strong&gt; - Responding to feedback&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;using-git-worktrees&lt;/strong&gt; - Parallel development branches&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;finishing-a-development-branch&lt;/strong&gt; - Merge/PR decision workflow&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;subagent-driven-development&lt;/strong&gt; - Fast iteration with two-stage review (spec compliance, then code quality)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Meta&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;writing-skills&lt;/strong&gt; - Create new skills following best practices (includes testing methodology)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;using-superpowers&lt;/strong&gt; - Introduction to the skills system&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Philosophy&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Test-Driven Development&lt;/strong&gt; - Write tests first, always&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Systematic over ad-hoc&lt;/strong&gt; - Process over guessing&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Complexity reduction&lt;/strong&gt; - Simplicity as primary goal&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Evidence over claims&lt;/strong&gt; - Verify before declaring success&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Read more: &lt;a href="https://blog.fsck.com/2025/10/09/superpowers/"&gt;Superpowers for Claude Code&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Skills live directly in this repository. To contribute:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Fork the repository&lt;/li&gt; 
 &lt;li&gt;Create a branch for your skill&lt;/li&gt; 
 &lt;li&gt;Follow the &lt;code&gt;writing-skills&lt;/code&gt; skill for creating and testing new skills&lt;/li&gt; 
 &lt;li&gt;Submit a PR&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;See &lt;code&gt;skills/writing-skills/SKILL.md&lt;/code&gt; for the complete guide.&lt;/p&gt; 
&lt;h2&gt;Updating&lt;/h2&gt; 
&lt;p&gt;Skills update automatically when you update the plugin:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;/plugin update superpowers
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;MIT License - see LICENSE file for details&lt;/p&gt; 
&lt;h2&gt;Support&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Issues&lt;/strong&gt;: &lt;a href="https://github.com/obra/superpowers/issues"&gt;https://github.com/obra/superpowers/issues&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Marketplace&lt;/strong&gt;: &lt;a href="https://github.com/obra/superpowers-marketplace"&gt;https://github.com/obra/superpowers-marketplace&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>DataTalksClub/data-engineering-zoomcamp</title>
      <link>https://github.com/DataTalksClub/data-engineering-zoomcamp</link>
      <description>&lt;p&gt;Data Engineering Zoomcamp is a free 9-week course on building production-ready data pipelines. The next cohort starts in January 2026. Join the course here üëáüèº&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;img width="100%" src="https://raw.githubusercontent.com/DataTalksClub/data-engineering-zoomcamp/main/images/architecture/arch_v4_workshops.jpg" alt="Data Engineering Zoomcamp Overview" /&gt; &lt;/p&gt; 
&lt;h1 align="center"&gt; &lt;strong&gt;Data Engineering Zoomcamp: A Free 9-Week Course on Data Engineering Fundamentals&lt;/strong&gt; &lt;/h1&gt; 
&lt;p align="center"&gt; Master the fundamentals of data engineering by building an end-to-end data pipeline from scratch. Gain hands-on experience with industry-standard tools and best practices. &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://airtable.com/shr6oVXeQvSI5HuWD"&gt;&lt;img src="https://user-images.githubusercontent.com/875246/185755203-17945fd1-6b64-46f2-8377-1011dcb1a444.png" height="50" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://datatalks.club/slack.html"&gt;Join Slack&lt;/a&gt; ‚Ä¢ &lt;a href="https://app.slack.com/client/T01ATQK62F8/C01FABYF2RG"&gt;#course-data-engineering Channel&lt;/a&gt; ‚Ä¢ &lt;a href="https://t.me/dezoomcamp"&gt;Telegram Announcements&lt;/a&gt; ‚Ä¢ &lt;a href="https://www.youtube.com/playlist?list=PL3MmuxUbc_hJed7dXYoJw8DoCuVHhGEQb"&gt;Course Playlist&lt;/a&gt; ‚Ä¢ &lt;a href="https://datatalks.club/faq/data-engineering-zoomcamp.html"&gt;FAQ&lt;/a&gt; &lt;/p&gt; 
&lt;h2&gt;How to Enroll&lt;/h2&gt; 
&lt;h3&gt;2026 Cohort&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Start Date&lt;/strong&gt;: 12 January 2026&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Register Here&lt;/strong&gt;: &lt;a href="https://airtable.com/shr6oVXeQvSI5HuWD"&gt;Sign up&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Self-Paced Learning&lt;/h3&gt; 
&lt;p&gt;All course materials are freely available for independent study. Follow these steps:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Watch the course videos.&lt;/li&gt; 
 &lt;li&gt;Join the &lt;a href="https://datatalks.club/slack.html"&gt;Slack community&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Refer to the &lt;a href="https://datatalks.club/faq/data-engineering-zoomcamp.html"&gt;FAQ document&lt;/a&gt; for guidance.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Syllabus Overview&lt;/h2&gt; 
&lt;p&gt;The course consists of structured modules, hands-on workshops, and a final project to reinforce your learning.&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;Prerequisites&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;To get the most out of this course, you should have:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Basic coding experience&lt;/li&gt; 
 &lt;li&gt;Familiarity with SQL&lt;/li&gt; 
 &lt;li&gt;Experience with Python (helpful but not required)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;No prior data engineering experience is necessary.&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;Modules&lt;/strong&gt;&lt;/h3&gt; 
&lt;h4&gt;&lt;a href="https://raw.githubusercontent.com/DataTalksClub/data-engineering-zoomcamp/main/01-docker-terraform/"&gt;Module 1: Containerization and Infrastructure as Code&lt;/a&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Introduction to GCP&lt;/li&gt; 
 &lt;li&gt;Docker and Docker Compose&lt;/li&gt; 
 &lt;li&gt;Running PostgreSQL with Docker&lt;/li&gt; 
 &lt;li&gt;Infrastructure setup with Terraform&lt;/li&gt; 
 &lt;li&gt;Homework&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;&lt;a href="https://raw.githubusercontent.com/DataTalksClub/data-engineering-zoomcamp/main/02-workflow-orchestration/"&gt;Module 2: Workflow Orchestration&lt;/a&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Data Lakes and Workflow Orchestration&lt;/li&gt; 
 &lt;li&gt;Workflow orchestration with Kestra&lt;/li&gt; 
 &lt;li&gt;Homework&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;&lt;a href="https://raw.githubusercontent.com/DataTalksClub/data-engineering-zoomcamp/main/cohorts/2025/workshops/dlt/README.md"&gt;Workshop 1: Data Ingestion&lt;/a&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;API reading and pipeline scalability&lt;/li&gt; 
 &lt;li&gt;Data normalization and incremental loading&lt;/li&gt; 
 &lt;li&gt;Homework&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;&lt;a href="https://raw.githubusercontent.com/DataTalksClub/data-engineering-zoomcamp/main/03-data-warehouse/"&gt;Module 3: Data Warehousing&lt;/a&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Introduction to BigQuery&lt;/li&gt; 
 &lt;li&gt;Partitioning, clustering, and best practices&lt;/li&gt; 
 &lt;li&gt;Machine learning in BigQuery&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;&lt;a href="https://raw.githubusercontent.com/DataTalksClub/data-engineering-zoomcamp/main/04-analytics-engineering/"&gt;Module 4: Analytics Engineering&lt;/a&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;dbt (data build tool) with DuckDB &amp;amp; BigQuery&lt;/li&gt; 
 &lt;li&gt;Testing, documentation, and deployment&lt;/li&gt; 
 &lt;li&gt;Data visualization with Streamlit &amp;amp; Looker Studio&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;&lt;a href="https://raw.githubusercontent.com/DataTalksClub/data-engineering-zoomcamp/main/05-batch/"&gt;Module 5: Batch Processing&lt;/a&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Introduction to Apache Spark&lt;/li&gt; 
 &lt;li&gt;DataFrames and SQL&lt;/li&gt; 
 &lt;li&gt;Internals of GroupBy and Joins&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;&lt;a href="https://raw.githubusercontent.com/DataTalksClub/data-engineering-zoomcamp/main/06-streaming/"&gt;Module 6: Streaming&lt;/a&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Introduction to Kafka&lt;/li&gt; 
 &lt;li&gt;Kafka Streams and KSQL&lt;/li&gt; 
 &lt;li&gt;Schema management with Avro&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;&lt;a href="https://raw.githubusercontent.com/DataTalksClub/data-engineering-zoomcamp/main/projects/"&gt;Final Project&lt;/a&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Apply all concepts learned in a real-world scenario&lt;/li&gt; 
 &lt;li&gt;Peer review and feedback process&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Testimonials&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Thank you for what you do! The Data Engineering Zoomcamp gave me skills that helped me land my first tech job.&lt;/p&gt; 
 &lt;p&gt;‚Äî &lt;a href="https://www.linkedin.com/in/claytor/"&gt;Tim Claytor&lt;/a&gt; (&lt;a href="https://www.linkedin.com/feed/update/urn:li:activity:7396882073308938240?commentUrn=urn%3Ali%3Acomment%3A%28activity%3A7396882073308938240%2C7396889959711793152%29&amp;amp;dashCommentUrn=urn%3Ali%3Afsd_comment%3A%287396889959711793152%2Curn%3Ali%3Aactivity%3A7396882073308938240%29"&gt;Source&lt;/a&gt;)&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Three months might seem like a long time, but the growth and learning during this period are truly remarkable. It was a great experience with a lot of learning, connecting with like-minded people from all around the world, and having fun. I must admit, this was really hard. But the feeling of accomplishment and learning made it all worthwhile. And I would do it again!&lt;/p&gt; 
 &lt;p&gt;‚Äî &lt;a href="https://www.linkedin.com/in/nevenka-lukic/"&gt;Nevenka Lukic&lt;/a&gt; (&lt;a href="https://www.linkedin.com/posts/nevenka-lukic_data-engineering-zoomcamp-final-project-activity-7181985646033461248-Lc1O?utm_source=share&amp;amp;utm_medium=member_desktop&amp;amp;rcm=ACoAADJu9vMBW6iyIYswCQnN6t8UJLkXH2tQPi4"&gt;Source&lt;/a&gt;)&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;One of the significant things I inferred from the Zoomcamp is to prioritize fundamentals and principles over ever-evolving tools and tech stacks. Hugely grateful to Alexey Grigorev for putting together this incredible course and offering it for free.&lt;/p&gt; 
 &lt;p&gt;‚Äî &lt;a href="https://www.linkedin.com/in/siddhartha-gogoi/"&gt;Siddhartha Gogoi&lt;/a&gt; (&lt;a href="https://www.linkedin.com/posts/activity-7325692407675604992-XSKI?utm_source=share&amp;amp;utm_medium=member_desktop&amp;amp;rcm=ACoAADJu9vMBW6iyIYswCQnN6t8UJLkXH2tQPi4"&gt;Source&lt;/a&gt;)&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Such a fun deep dive into data engineering, cloud automation, and orchestration. I learned so much along the way. Big shoutout to Alexey Grigorev and the DataTalksClub team for the opportunity and guidance throughout the 3 months of the free course.&lt;/p&gt; 
 &lt;p&gt;‚Äî &lt;a href="https://www.linkedin.com/in/assitan-niar%C3%A9-data/"&gt;Assitan NIARE&lt;/a&gt; (&lt;a href="https://www.linkedin.com/posts/activity-7317441554023874561-E3wm?utm_source=share&amp;amp;utm_medium=member_desktop&amp;amp;rcm=ACoAADJu9vMBW6iyIYswCQnN6t8UJLkXH2tQPi4"&gt;Source&lt;/a&gt;)&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;If you‚Äôre serious about breaking into data engineering, start here. The repo‚Äôs structure, community, and hands-on focus make it unparalleled.&lt;/p&gt; 
 &lt;p&gt;‚Äî &lt;a href="https://www.linkedin.com/in/wadyosama/"&gt;Wady Osama&lt;/a&gt; (&lt;a href="https://www.linkedin.com/posts/wadyosama_dataengineering-zoomcamp-dezoomcamp-activity-7292126824711520258-puJm?utm_source=share&amp;amp;utm_medium=member_desktop&amp;amp;rcm=ACoAADJu9vMBW6iyIYswCQnN6t8UJLkXH2tQPi4"&gt;Source&lt;/a&gt;)&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Community &amp;amp; Support&lt;/h2&gt; 
&lt;h3&gt;&lt;strong&gt;Getting Help on Slack&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;Join the &lt;a href="https://app.slack.com/client/T01ATQK62F8/C01FABYF2RG"&gt;&lt;code&gt;#course-data-engineering&lt;/code&gt;&lt;/a&gt; channel on &lt;a href="https://datatalks.club/slack.html"&gt;DataTalks.Club Slack&lt;/a&gt; for discussions, troubleshooting, and networking.&lt;/p&gt; 
&lt;p&gt;To keep discussions organized:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Follow &lt;a href="https://raw.githubusercontent.com/DataTalksClub/data-engineering-zoomcamp/main/asking-questions.md"&gt;our guidelines&lt;/a&gt; when posting questions.&lt;/li&gt; 
 &lt;li&gt;Review the &lt;a href="https://datatalks.club/slack/guidelines.html"&gt;community guidelines&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Meet the Instructors&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://linkedin.com/in/agrigorev"&gt;Alexey Grigorev&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.linkedin.com/in/michaelshoemaker1/"&gt;Michael Shoemaker&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.linkedin.com/in/wrussell1999/"&gt;Will Russell&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.linkedin.com/in/anna-geller-12a86811a/"&gt;Anna Geller&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.linkedin.com/in/jmperafan/"&gt;Juan Manuel Perafan&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.linkedin.com/in/diana-gromakovskaia/"&gt;Diana Gromakovskaia&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Past instructors:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.linkedin.com/in/victoriaperezmola/"&gt;Victoria Perez Mola&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://linkedin.com/in/ankushkhanna2"&gt;Ankush Khanna&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.linkedin.com/in/vaidyasejal/"&gt;Sejal Vaidya&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.linkedin.com/in/iremerturk/"&gt;Irem Erturk&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.linkedin.com/in/lgsoliveira/"&gt;Luis Oliveira&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.linkedin.com/in/eczachly"&gt;Zach Wilson&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Sponsors &amp;amp; Supporters&lt;/h2&gt; 
&lt;p&gt;A special thanks to our course sponsors for making this initiative possible!&lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://kestra.io/"&gt; &lt;img height="120" src="https://raw.githubusercontent.com/DataTalksClub/data-engineering-zoomcamp/main/images/kestra.svg?sanitize=true" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://getbruin.com/"&gt; &lt;img height="110" src="https://raw.githubusercontent.com/DataTalksClub/data-engineering-zoomcamp/main/images/bruin.svg?sanitize=true" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://dlthub.com/"&gt; &lt;img height="90" src="https://raw.githubusercontent.com/DataTalksClub/data-engineering-zoomcamp/main/images/dlthub.png" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p&gt;Interested in supporting our community? Reach out to &lt;a href="mailto:alexey@datatalks.club"&gt;alexey@datatalks.club&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;About DataTalks.Club&lt;/h2&gt; 
&lt;p align="center"&gt; &lt;img width="40%" src="https://github.com/user-attachments/assets/1243a44a-84c8-458d-9439-aaf6f3a32d89" alt="DataTalks.Club" /&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://datatalks.club/"&gt;DataTalks.Club&lt;/a&gt; is a global online community of data enthusiasts. It's a place to discuss data, learn, share knowledge, ask and answer questions, and support each other. &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://datatalks.club/"&gt;Website&lt;/a&gt; ‚Ä¢ &lt;a href="https://datatalks.club/slack.html"&gt;Join Slack Community&lt;/a&gt; ‚Ä¢ &lt;a href="https://us19.campaign-archive.com/home/?u=0d7822ab98152f5afc118c176&amp;amp;id=97178021aa"&gt;Newsletter&lt;/a&gt; ‚Ä¢ &lt;a href="http://lu.ma/dtc-events"&gt;Upcoming Events&lt;/a&gt; ‚Ä¢ &lt;a href="https://www.youtube.com/@DataTalksClub/featured"&gt;YouTube&lt;/a&gt; ‚Ä¢ &lt;a href="https://github.com/DataTalksClub"&gt;GitHub&lt;/a&gt; ‚Ä¢ &lt;a href="https://www.linkedin.com/company/datatalks-club/"&gt;LinkedIn&lt;/a&gt; ‚Ä¢ &lt;a href="https://twitter.com/DataTalksClub"&gt;Twitter&lt;/a&gt; &lt;/p&gt; 
&lt;p&gt;All the activity at DataTalks.Club mainly happens on &lt;a href="https://datatalks.club/slack.html"&gt;Slack&lt;/a&gt;. We post updates there and discuss different aspects of data, career questions, and more.&lt;/p&gt; 
&lt;p&gt;At DataTalksClub, we organize online events, community activities, and free courses. You can learn more about what we do at &lt;a href="https://www.notion.so/DataTalksClub-Community-Navigation-bf070ad27ba44bf6bbc9222082f0e5a8?pvs=21"&gt;DataTalksClub Community Navigation&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>twitter/the-algorithm</title>
      <link>https://github.com/twitter/the-algorithm</link>
      <description>&lt;p&gt;Source code for the X Recommendation Algorithm&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;X's Recommendation Algorithm&lt;/h1&gt; 
&lt;p&gt;X's Recommendation Algorithm is a set of services and jobs that are responsible for serving feeds of posts and other content across all X product surfaces (e.g. For You Timeline, Search, Explore, Notifications). For an introduction to how the algorithm works, please refer to our &lt;a href="https://blog.x.com/engineering/en_us/topics/open-source/2023/twitter-recommendation-algorithm"&gt;engineering blog&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Architecture&lt;/h2&gt; 
&lt;p&gt;Product surfaces at X are built on a shared set of data, models, and software frameworks. The shared components included in this repository are listed below:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Type&lt;/th&gt; 
   &lt;th&gt;Component&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Data&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/twitter/the-algorithm/main/tweetypie/server/README.md"&gt;tweetypie&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Core service that handles the reading and writing of post data.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/twitter/the-algorithm/main/unified_user_actions/README.md"&gt;unified-user-actions&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Real-time stream of user actions on X.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/twitter/the-algorithm/main/user-signal-service/README.md"&gt;user-signal-service&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Centralized platform to retrieve explicit (e.g. likes, replies) and implicit (e.g. profile visits, tweet clicks) user signals.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Model&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/twitter/the-algorithm/main/src/scala/com/twitter/simclusters_v2/README.md"&gt;SimClusters&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Community detection and sparse embeddings into those communities.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/twitter/the-algorithm-ml/raw/main/projects/twhin/README.md"&gt;TwHIN&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Dense knowledge graph embeddings for Users and Posts.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/twitter/the-algorithm/main/trust_and_safety_models/README.md"&gt;trust-and-safety-models&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Models for detecting NSFW or abusive content.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/twitter/the-algorithm/main/src/scala/com/twitter/interaction_graph/README.md"&gt;real-graph&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Model to predict the likelihood of an X User interacting with another User.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/twitter/the-algorithm/main/src/scala/com/twitter/graph/batch/job/tweepcred/README"&gt;tweepcred&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Page-Rank algorithm for calculating X User reputation.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/twitter/the-algorithm/main/recos-injector/README.md"&gt;recos-injector&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Streaming event processor for building input streams for &lt;a href="https://github.com/twitter/GraphJet"&gt;GraphJet&lt;/a&gt; based services.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/twitter/the-algorithm/main/graph-feature-service/README.md"&gt;graph-feature-service&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Serves graph features for a directed pair of users (e.g. how many of User A's following liked posts from User B).&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/twitter/the-algorithm/main/topic-social-proof/README.md"&gt;topic-social-proof&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Identifies topics related to individual posts.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/twitter/the-algorithm/main/representation-scorer/README.md"&gt;representation-scorer&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Compute scores between pairs of entities (Users, Posts, etc.) using embedding similarity.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Software framework&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/twitter/the-algorithm/main/navi/README.md"&gt;navi&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;High performance, machine learning model serving written in Rust.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/twitter/the-algorithm/main/product-mixer/README.md"&gt;product-mixer&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Software framework for building feeds of content.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/twitter/the-algorithm/main/timelines/data_processing/ml_util/aggregation_framework/README.md"&gt;timelines-aggregation-framework&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Framework for generating aggregate features in batch or real time.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/twitter/the-algorithm/main/representation-manager/README.md"&gt;representation-manager&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Service to retrieve embeddings (i.e. SimClusers and TwHIN).&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/twitter/the-algorithm/main/twml/README.md"&gt;twml&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Legacy machine learning framework built on TensorFlow v1.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;The product surfaces currently included in this repository are the For You Timeline and Recommended Notifications.&lt;/p&gt; 
&lt;h3&gt;For You Timeline&lt;/h3&gt; 
&lt;p&gt;The diagram below illustrates how major services and jobs interconnect to construct a For You Timeline.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/twitter/the-algorithm/main/docs/system-diagram.png" alt="" /&gt;&lt;/p&gt; 
&lt;p&gt;The core components of the For You Timeline included in this repository are listed below:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Type&lt;/th&gt; 
   &lt;th&gt;Component&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Candidate Source&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/twitter/the-algorithm/main/src/java/com/twitter/search/README.md"&gt;search-index&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Find and rank In-Network posts. ~50% of posts come from this candidate source.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/twitter/the-algorithm/main/tweet-mixer"&gt;tweet-mixer&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Coordination layer for fetching Out-of-Network tweet candidates from underlying compute services.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/twitter/the-algorithm/main/src/scala/com/twitter/recos/user_tweet_entity_graph/README.md"&gt;user-tweet-entity-graph&lt;/a&gt; (UTEG)&lt;/td&gt; 
   &lt;td&gt;Maintains an in memory User to Post interaction graph, and finds candidates based on traversals of this graph. This is built on the &lt;a href="https://github.com/twitter/GraphJet"&gt;GraphJet&lt;/a&gt; framework. Several other GraphJet based features and candidate sources are located &lt;a href="https://raw.githubusercontent.com/twitter/the-algorithm/main/src/scala/com/twitter/recos"&gt;here&lt;/a&gt;.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/twitter/the-algorithm/main/follow-recommendations-service/README.md"&gt;follow-recommendation-service&lt;/a&gt; (FRS)&lt;/td&gt; 
   &lt;td&gt;Provides Users with recommendations for accounts to follow, and posts from those accounts.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Ranking&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/twitter/the-algorithm/main/src/python/twitter/deepbird/projects/timelines/scripts/models/earlybird/README.md"&gt;light-ranker&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Light Ranker model used by search index (Earlybird) to rank posts.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/twitter/the-algorithm-ml/raw/main/projects/home/recap/README.md"&gt;heavy-ranker&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Neural network for ranking candidate posts. One of the main signals used to select timeline posts post candidate sourcing.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Post mixing &amp;amp; filtering&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/twitter/the-algorithm/main/home-mixer/README.md"&gt;home-mixer&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Main service used to construct and serve the Home Timeline. Built on &lt;a href="https://raw.githubusercontent.com/twitter/the-algorithm/main/product-mixer/README.md"&gt;product-mixer&lt;/a&gt;.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/twitter/the-algorithm/main/visibilitylib/README.md"&gt;visibility-filters&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Responsible for filtering X content to support legal compliance, improve product quality, increase user trust, protect revenue through the use of hard-filtering, visible product treatments, and coarse-grained downranking.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/twitter/the-algorithm/main/timelineranker/README.md"&gt;timelineranker&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Legacy service which provides relevance-scored posts from the Earlybird Search Index and UTEG service.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Recommended Notifications&lt;/h3&gt; 
&lt;p&gt;The core components of Recommended Notifications included in this repository are listed below:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Type&lt;/th&gt; 
   &lt;th&gt;Component&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Service&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/twitter/the-algorithm/main/pushservice/README.md"&gt;pushservice&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Main recommendation service at X used to surface recommendations to our users via notifications.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Ranking&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/twitter/the-algorithm/main/pushservice/src/main/python/models/light_ranking/README.md"&gt;pushservice-light-ranker&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Light Ranker model used by pushservice to rank posts. Bridges candidate generation and heavy ranking by pre-selecting highly-relevant candidates from the initial huge candidate pool.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/twitter/the-algorithm/main/pushservice/src/main/python/models/heavy_ranking/README.md"&gt;pushservice-heavy-ranker&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Multi-task learning model to predict the probabilities that the target users will open and engage with the sent notifications.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Build and test code&lt;/h2&gt; 
&lt;p&gt;We include Bazel BUILD files for most components, but not a top-level BUILD or WORKSPACE file. We plan to add a more complete build and test system in the future.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We invite the community to submit GitHub issues and pull requests for suggestions on improving the recommendation algorithm. We are working on tools to manage these suggestions and sync changes to our internal repository. Any security concerns or issues should be routed to our official &lt;a href="https://hackerone.com/x"&gt;bug bounty program&lt;/a&gt; through HackerOne. We hope to benefit from the collective intelligence and expertise of the global community in helping us identify issues and suggest improvements, ultimately leading to a better X.&lt;/p&gt; 
&lt;p&gt;Read our blog on the open source initiative &lt;a href="https://blog.x.com/en_us/topics/company/2023/a-new-era-of-transparency-for-twitter"&gt;here&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>home-assistant/home-assistant.io</title>
      <link>https://github.com/home-assistant/home-assistant.io</link>
      <description>&lt;p&gt;üìò Home Assistant User documentation&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href="https://www.home-assistant.io/join-chat/"&gt;&lt;img src="https://img.shields.io/discord/330944238910963714.svg?sanitize=true" alt="Discord" /&gt;&lt;/a&gt; &lt;a href="https://creativecommons.org/licenses/by-nc-sa/4.0/"&gt;&lt;img src="https://img.shields.io/badge/License-CC%20BY--NC--SA%204.0-lightgrey.svg?sanitize=true" alt="License: CC BY-NC-SA 4.0" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.netlify.com"&gt;&lt;img src="https://www.netlify.com/img/global/badges/netlify-color-bg.svg?sanitize=true" alt="Deploys by netlify" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Home Assistant website&lt;/h1&gt; 
&lt;p&gt;This is the source for the &lt;a href="https://home-assistant.io"&gt;Home-Assistant.io website&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Access&lt;/h2&gt; 
&lt;p&gt;You can access the site at the following URLs, depending on the target branch:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Production&lt;/strong&gt; (&lt;code&gt;current&lt;/code&gt; branch): &lt;a href="https://www.home-assistant.io"&gt;https://www.home-assistant.io&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Beta&lt;/strong&gt; (&lt;code&gt;rc&lt;/code&gt; branch): &lt;a href="https://rc.home-assistant.io"&gt;https://rc.home-assistant.io&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Development&lt;/strong&gt; (&lt;code&gt;next&lt;/code&gt; branch): &lt;a href="https://next.home-assistant.io"&gt;https://next.home-assistant.io&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Additionally, Netlify provides a preview deployment for every pull request, linked in the first PR comment.&lt;/p&gt; 
&lt;h2&gt;Setup&lt;/h2&gt; 
&lt;p&gt;Setting up to contribute to documentation and the process for submitting pull requests is explained in the &lt;a href="https://developers.home-assistant.io/docs/documenting/"&gt;developer documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Site preview&lt;/h2&gt; 
&lt;p&gt;In order to make the preview available on &lt;code&gt;http://127.0.0.1:4000&lt;/code&gt;, use the following &lt;a href="https://bundler.io/"&gt;bundler&lt;/a&gt; command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;bundle exec rake preview
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If the preview is not running on your local machine, pass the IP of the target machine from where it should be served as a parameter, i.e. to access on &lt;code&gt;http://192.168.0.123:4000&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;bundle exec rake preview[192.168.0.123]
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Speeding up site generation&lt;/h2&gt; 
&lt;p&gt;Every release we post long changelogs to the website. This slows down generation of the website significantly! We include some tools to temporarily exclude the blog posts that you're not working on out of the way.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;bundle exec rake isolate[filename-of-blogpost]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;When you're done working on the site, run the following command to move the posts back again:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;bundle exec rake integrate
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;a href="https://www.openhomefoundation.org/"&gt;&lt;img src="https://www.openhomefoundation.org/badges/home-assistant.png" alt="Home Assistant - A project from the Open Home Foundation" /&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>hacksider/Deep-Live-Cam</title>
      <link>https://github.com/hacksider/Deep-Live-Cam</link>
      <description>&lt;p&gt;real time face swap and one-click video deepfake with only a single image&lt;/p&gt;&lt;hr&gt;&lt;h1 align="center"&gt;Deep-Live-Cam 2.0.1c&lt;/h1&gt; 
&lt;p align="center"&gt; Real-time face swap and video deepfake with a single click and only a single image. &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://trendshift.io/repositories/11395" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/11395" alt="hacksider%2FDeep-Live-Cam | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/hacksider/Deep-Live-Cam/main/media/demo.gif" alt="Demo GIF" width="800" /&gt; &lt;/p&gt; 
&lt;h2&gt;Disclaimer&lt;/h2&gt; 
&lt;p&gt;This deepfake software is designed to be a productive tool for the AI-generated media industry. It can assist artists in animating custom characters, creating engaging content, and even using models for clothing design.&lt;/p&gt; 
&lt;p&gt;We are aware of the potential for unethical applications and are committed to preventative measures. A built-in check prevents the program from processing inappropriate media (nudity, graphic content, sensitive material like war footage, etc.). We will continue to develop this project responsibly, adhering to the law and ethics. We may shut down the project or add watermarks if legally required.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Ethical Use: Users are expected to use this software responsibly and legally. If using a real person's face, obtain their consent and clearly label any output as a deepfake when sharing online.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Content Restrictions: The software includes built-in checks to prevent processing inappropriate media, such as nudity, graphic content, or sensitive material.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Legal Compliance: We adhere to all relevant laws and ethical guidelines. If legally required, we may shut down the project or add watermarks to the output.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;User Responsibility: We are not responsible for end-user actions. Users must ensure their use of the software aligns with ethical standards and legal requirements.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;By using this software, you agree to these terms and commit to using it in a manner that respects the rights and dignity of others.&lt;/p&gt; 
&lt;p&gt;Users are expected to use this software responsibly and legally. If using a real person's face, obtain their consent and clearly label any output as a deepfake when sharing online. We are not responsible for end-user actions.&lt;/p&gt; 
&lt;h2&gt;Exclusive v2.4 Quick Start - Pre-built (Windows/Mac Silicon)&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://deeplivecam.net/index.php/quickstart"&gt; &lt;img src="https://raw.githubusercontent.com/hacksider/Deep-Live-Cam/main/media/Download.png" width="285" height="77" /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;a href="https://deeplivecam.net/index.php/quickstart"&gt; &lt;h5&gt;This is the fastest build you can get if you have a discrete NVIDIA or AMD GPU or Mac Silicon, And you'll receive special priority support.&lt;/h5&gt; &lt;h6&gt;These Pre-builts are perfect for non-technical users or those who don't have time to, or can't manually install all the requirements. Just a heads-up: this is an open-source project, so you can also install it manually.&lt;/h6&gt; &lt;h2&gt;TLDR; Live Deepfake in just 3 Clicks&lt;/h2&gt; &lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/af825228-852c-411b-b787-ffd9aac72fc6" alt="easysteps" /&gt;&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;Select a face&lt;/li&gt; 
  &lt;li&gt;Select which camera to use&lt;/li&gt; 
  &lt;li&gt;Press live!&lt;/li&gt; 
 &lt;/ol&gt; &lt;h2&gt;Features &amp;amp; Uses - Everything is in real-time&lt;/h2&gt; &lt;h3&gt;Mouth Mask&lt;/h3&gt; &lt;p&gt;&lt;strong&gt;Retain your original mouth for accurate movement using Mouth Mask&lt;/strong&gt;&lt;/p&gt; &lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/hacksider/Deep-Live-Cam/main/media/ludwig.gif" alt="resizable-gif" /&gt; &lt;/p&gt; &lt;h3&gt;Face Mapping&lt;/h3&gt; &lt;p&gt;&lt;strong&gt;Use different faces on multiple subjects simultaneously&lt;/strong&gt;&lt;/p&gt; &lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/hacksider/Deep-Live-Cam/main/media/streamers.gif" alt="face_mapping_source" /&gt; &lt;/p&gt; &lt;h3&gt;Your Movie, Your Face&lt;/h3&gt; &lt;p&gt;&lt;strong&gt;Watch movies with any face in real-time&lt;/strong&gt;&lt;/p&gt; &lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/hacksider/Deep-Live-Cam/main/media/movie.gif" alt="movie" /&gt; &lt;/p&gt; &lt;h3&gt;Live Show&lt;/h3&gt; &lt;p&gt;&lt;strong&gt;Run Live shows and performances&lt;/strong&gt;&lt;/p&gt; &lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/hacksider/Deep-Live-Cam/main/media/live_show.gif" alt="show" /&gt; &lt;/p&gt; &lt;h3&gt;Memes&lt;/h3&gt; &lt;p&gt;&lt;strong&gt;Create Your Most Viral Meme Yet&lt;/strong&gt;&lt;/p&gt; &lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/hacksider/Deep-Live-Cam/main/media/meme.gif" alt="show" width="450" /&gt; &lt;br /&gt; &lt;sub&gt;Created using Many Faces feature in Deep-Live-Cam&lt;/sub&gt; &lt;/p&gt; &lt;h3&gt;Omegle&lt;/h3&gt; &lt;p&gt;&lt;strong&gt;Surprise people on Omegle&lt;/strong&gt;&lt;/p&gt; &lt;p align="center"&gt; 
  &lt;video src="https://github.com/user-attachments/assets/2e9b9b82-fa04-4b70-9f56-b1f68e7672d0" width="450" controls&gt;&lt;/video&gt; &lt;/p&gt; &lt;h2&gt;Installation (Manual)&lt;/h2&gt; &lt;p&gt;&lt;strong&gt;Please be aware that the installation requires technical skills and is not for beginners. Consider downloading the quickstart version.&lt;/strong&gt;&lt;/p&gt; &lt;/a&gt;
&lt;details&gt;
 &lt;a href="https://deeplivecam.net/index.php/quickstart"&gt; &lt;summary&gt;Click to see the process&lt;/summary&gt; &lt;h3&gt;Installation&lt;/h3&gt; &lt;p&gt;This is more likely to work on your computer but will be slower as it utilizes the CPU.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;1. Set up Your Platform&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Python (3.11 recommended)&lt;/li&gt; 
   &lt;li&gt;pip&lt;/li&gt; 
   &lt;li&gt;git&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=OlNWCpFdVMA"&gt;ffmpeg&lt;/a&gt; - &lt;code&gt;iex (irm ffmpeg.tc.ht)&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://visualstudio.microsoft.com/visual-cpp-build-tools/"&gt;Visual Studio 2022 Runtimes (Windows)&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt;&lt;/a&gt; 
 &lt;p&gt;&lt;strong&gt;2. Clone the Repository&lt;/strong&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/hacksider/Deep-Live-Cam.git
cd Deep-Live-Cam
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;3. Download the Models&lt;/strong&gt;&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/hacksider/deep-live-cam/resolve/main/GFPGANv1.4.pth"&gt;GFPGANv1.4&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/hacksider/deep-live-cam/resolve/main/inswapper_128_fp16.onnx"&gt;inswapper_128_fp16.onnx&lt;/a&gt;&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;p&gt;Place these files in the "&lt;strong&gt;models&lt;/strong&gt;" folder.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;4. Install Dependencies&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;We highly recommend using a &lt;code&gt;venv&lt;/code&gt; to avoid issues.&lt;/p&gt; 
 &lt;p&gt;For Windows:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;python -m venv venv
venv\Scripts\activate
pip install -r requirements.txt
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;For Linux:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# Ensure you use the installed Python 3.10
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;For macOS:&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;Apple Silicon (M1/M2/M3) requires specific setup:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# Install Python 3.11 (specific version is important)
brew install python@3.11

# Install tkinter package (required for the GUI)
brew install python-tk@3.10

# Create and activate virtual environment with Python 3.11
python3.11 -m venv venv
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;** In case something goes wrong and you need to reinstall the virtual environment **&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# Deactivate the virtual environment
rm -rf venv

# Reinstall the virtual environment
python -m venv venv
source venv/bin/activate

# install the dependencies again
pip install -r requirements.txt

# gfpgan and basicsrs issue fix
pip install git+https://github.com/xinntao/BasicSR.git@master
pip uninstall gfpgan -y
pip install git+https://github.com/TencentARC/GFPGAN.git@master
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;Run:&lt;/strong&gt; If you don't have a GPU, you can run Deep-Live-Cam using &lt;code&gt;python run.py&lt;/code&gt;. Note that initial execution will download models (~300MB).&lt;/p&gt; 
 &lt;h3&gt;GPU Acceleration&lt;/h3&gt; 
 &lt;p&gt;&lt;strong&gt;CUDA Execution Provider (Nvidia)&lt;/strong&gt;&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;Install &lt;a href="https://developer.nvidia.com/cuda-12-8-0-download-archive"&gt;CUDA Toolkit 12.8.0&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Install &lt;a href="https://developer.nvidia.com/rdp/cudnn-archive"&gt;cuDNN v8.9.7 for CUDA 12.x&lt;/a&gt; (required for onnxruntime-gpu): 
   &lt;ul&gt; 
    &lt;li&gt;Download cuDNN v8.9.7 for CUDA 12.x&lt;/li&gt; 
    &lt;li&gt;Make sure the cuDNN bin directory is in your system PATH&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;Install dependencies:&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;pip install -U torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu128
pip uninstall onnxruntime onnxruntime-gpu
pip install onnxruntime-gpu==1.21.0
&lt;/code&gt;&lt;/pre&gt; 
 &lt;ol start="3"&gt; 
  &lt;li&gt;Usage:&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;python run.py --execution-provider cuda
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;CoreML Execution Provider (Apple Silicon)&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;Apple Silicon (M1/M2/M3) specific installation:&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;Make sure you've completed the macOS setup above using Python 3.10.&lt;/li&gt; 
  &lt;li&gt;Install dependencies:&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;pip uninstall onnxruntime onnxruntime-silicon
pip install onnxruntime-silicon==1.13.1
&lt;/code&gt;&lt;/pre&gt; 
 &lt;ol start="3"&gt; 
  &lt;li&gt;Usage (important: specify Python 3.10):&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;python3.10 run.py --execution-provider coreml
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;Important Notes for macOS:&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;You &lt;strong&gt;must&lt;/strong&gt; use Python 3.10, not newer versions like 3.11 or 3.13&lt;/li&gt; 
  &lt;li&gt;Always run with &lt;code&gt;python3.10&lt;/code&gt; command not just &lt;code&gt;python&lt;/code&gt; if you have multiple Python versions installed&lt;/li&gt; 
  &lt;li&gt;If you get error about &lt;code&gt;_tkinter&lt;/code&gt; missing, reinstall the tkinter package: &lt;code&gt;brew reinstall python-tk@3.10&lt;/code&gt;&lt;/li&gt; 
  &lt;li&gt;If you get model loading errors, check that your models are in the correct folder&lt;/li&gt; 
  &lt;li&gt;If you encounter conflicts with other Python versions, consider uninstalling them: &lt;pre&gt;&lt;code class="language-bash"&gt;# List all installed Python versions
brew list | grep python

# Uninstall conflicting versions if needed
brew uninstall --ignore-dependencies python@3.11 python@3.13

# Keep only Python 3.11
brew cleanup
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;CoreML Execution Provider (Apple Legacy)&lt;/strong&gt;&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;Install dependencies:&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;pip uninstall onnxruntime onnxruntime-coreml
pip install onnxruntime-coreml==1.21.0
&lt;/code&gt;&lt;/pre&gt; 
 &lt;ol start="2"&gt; 
  &lt;li&gt;Usage:&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;python run.py --execution-provider coreml
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;DirectML Execution Provider (Windows)&lt;/strong&gt;&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;Install dependencies:&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;pip uninstall onnxruntime onnxruntime-directml
pip install onnxruntime-directml==1.21.0
&lt;/code&gt;&lt;/pre&gt; 
 &lt;ol start="2"&gt; 
  &lt;li&gt;Usage:&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;python run.py --execution-provider directml
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;OpenVINO‚Ñ¢ Execution Provider (Intel)&lt;/strong&gt;&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;Install dependencies:&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;pip uninstall onnxruntime onnxruntime-openvino
pip install onnxruntime-openvino==1.21.0
&lt;/code&gt;&lt;/pre&gt; 
 &lt;ol start="2"&gt; 
  &lt;li&gt;Usage:&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;python run.py --execution-provider openvino
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;1. Image/Video Mode&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Execute &lt;code&gt;python run.py&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Choose a source face image and a target image/video.&lt;/li&gt; 
 &lt;li&gt;Click "Start".&lt;/li&gt; 
 &lt;li&gt;The output will be saved in a directory named after the target video.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;2. Webcam Mode&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Execute &lt;code&gt;python run.py&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Select a source face image.&lt;/li&gt; 
 &lt;li&gt;Click "Live".&lt;/li&gt; 
 &lt;li&gt;Wait for the preview to appear (10-30 seconds).&lt;/li&gt; 
 &lt;li&gt;Use a screen capture tool like OBS to stream.&lt;/li&gt; 
 &lt;li&gt;To change the face, select a new source image.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Command Line Arguments (Unmaintained)&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;options:
  -h, --help                                               show this help message and exit
  -s SOURCE_PATH, --source SOURCE_PATH                     select a source image
  -t TARGET_PATH, --target TARGET_PATH                     select a target image or video
  -o OUTPUT_PATH, --output OUTPUT_PATH                     select output file or directory
  --frame-processor FRAME_PROCESSOR [FRAME_PROCESSOR ...]  frame processors (choices: face_swapper, face_enhancer, ...)
  --keep-fps                                               keep original fps
  --keep-audio                                             keep original audio
  --keep-frames                                            keep temporary frames
  --many-faces                                             process every face
  --map-faces                                              map source target faces
  --mouth-mask                                             mask the mouth region
  --video-encoder {libx264,libx265,libvpx-vp9}             adjust output video encoder
  --video-quality [0-51]                                   adjust output video quality
  --live-mirror                                            the live camera display as you see it in the front-facing camera frame
  --live-resizable                                         the live camera frame is resizable
  --max-memory MAX_MEMORY                                  maximum amount of RAM in GB
  --execution-provider {cpu} [{cpu} ...]                   available execution provider (choices: cpu, ...)
  --execution-threads EXECUTION_THREADS                    number of execution threads
  -v, --version                                            show program's version number and exit
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Looking for a CLI mode? Using the -s/--source argument will make the run program in cli mode.&lt;/p&gt; 
&lt;h2&gt;Press&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;We are always open to criticism and are ready to improve, that's why we didn't cherry-pick anything.&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://arstechnica.com/information-technology/2024/08/new-ai-tool-enables-real-time-face-swapping-on-webcams-raising-fraud-concerns/"&gt;&lt;em&gt;"Deep-Live-Cam goes viral, allowing anyone to become a digital doppelganger"&lt;/em&gt;&lt;/a&gt; - Ars Technica&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://dataconomy.com/2024/08/15/what-is-deep-live-cam-github-deepfake/"&gt;&lt;em&gt;"Thanks Deep Live Cam, shapeshifters are among us now"&lt;/em&gt;&lt;/a&gt; - Dataconomy&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.newsbytesapp.com/news/science/deep-live-cam-ai-impersonation-tool-goes-viral/story"&gt;&lt;em&gt;"This free AI tool lets you become anyone during video-calls"&lt;/em&gt;&lt;/a&gt; - NewsBytes&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.creativebloq.com/ai/ok-this-viral-ai-live-stream-software-is-truly-terrifying"&gt;&lt;em&gt;"OK, this viral AI live stream software is truly terrifying"&lt;/em&gt;&lt;/a&gt; - Creative Bloq&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://petapixel.com/2024/08/14/deep-live-cam-deepfake-ai-tool-lets-you-become-anyone-in-a-video-call-with-single-photo-mark-zuckerberg-jd-vance-elon-musk/"&gt;&lt;em&gt;"Deepfake AI Tool Lets You Become Anyone in a Video Call With Single Photo"&lt;/em&gt;&lt;/a&gt; - PetaPixel&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.techeblog.com/deep-live-cam-ai-transform-face/"&gt;&lt;em&gt;"Deep-Live-Cam Uses AI to Transform Your Face in Real-Time, Celebrities Included"&lt;/em&gt;&lt;/a&gt; - TechEBlog&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://telegrafi.com/en/a-tool-that-makes-you-look-like-anyone-during-a-video-call-is-going-viral-on-the-Internet/"&gt;&lt;em&gt;"An AI tool that "makes you look like anyone" during a video call is going viral online"&lt;/em&gt;&lt;/a&gt; - Telegrafi&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://decrypt.co/244565/this-deepfake-tool-turning-images-into-livestreams-is-topping-the-github-charts"&gt;&lt;em&gt;"This Deepfake Tool Turning Images Into Livestreams is Topping the GitHub Charts"&lt;/em&gt;&lt;/a&gt; - Emerge&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.digitalmusicnews.com/2024/08/15/face-swapping-ai-real-time-mimic/"&gt;&lt;em&gt;"New Real-Time Face-Swapping AI Allows Anyone to Mimic Famous Faces"&lt;/em&gt;&lt;/a&gt; - Digital Music News&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.diyphotography.net/this-real-time-webcam-deepfake-tool-raises-alarms-about-the-future-of-identity-theft/"&gt;&lt;em&gt;"This real-time webcam deepfake tool raises alarms about the future of identity theft"&lt;/em&gt;&lt;/a&gt; - DIYPhotography&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/watch?time_continue=1074&amp;amp;v=py4Tc-Y8BcY"&gt;&lt;em&gt;"That's Crazy, Oh God. That's Fucking Freaky Dude... That's So Wild Dude"&lt;/em&gt;&lt;/a&gt; - SomeOrdinaryGamers&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/live/mFsCe7AIxq8?feature=shared&amp;amp;t=2686"&gt;&lt;em&gt;"Alright look look look, now look chat, we can do any face we want to look like chat"&lt;/em&gt;&lt;/a&gt; - IShowSpeed&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=wnCghLjqv3s&amp;amp;t=551s"&gt;&lt;em&gt;"They do a pretty good job matching poses, expression and even the lighting"&lt;/em&gt;&lt;/a&gt; - TechLinked (LTT)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.golem.de/news/deepfakes-als-sean-connery-an-der-redaktionskonferenz-teilnahm-2408-188172.html"&gt;&lt;em&gt;"Als Sean Connery an der Redaktionskonferenz teilnahm"&lt;/em&gt;&lt;/a&gt; - Golem.de (German)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://youtu.be/JbUPRmXRUtE?t=3964"&gt;&lt;em&gt;"What the F&lt;/em&gt;**! Why do I look like Vinny Jr? I look exactly like Vinny Jr!? No, this shit is crazy! Bro This is F*** Crazy! "*&lt;/a&gt; - IShowSpeed&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Credits&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://ffmpeg.org/"&gt;ffmpeg&lt;/a&gt;: for making video-related operations easy&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/henryruhs"&gt;Henry&lt;/a&gt;: One of the major contributor in this repo&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/deepinsight"&gt;deepinsight&lt;/a&gt;: for their &lt;a href="https://github.com/deepinsight/insightface"&gt;insightface&lt;/a&gt; project which provided a well-made library and models. Please be reminded that the &lt;a href="https://github.com/deepinsight/insightface?tab=readme-ov-file#license"&gt;use of the model is for non-commercial research purposes only&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/havok2-htwo"&gt;havok2-htwo&lt;/a&gt;: for sharing the code for webcam&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/GosuDRM"&gt;GosuDRM&lt;/a&gt;: for the open version of roop&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pereiraroland26"&gt;pereiraroland26&lt;/a&gt;: Multiple faces support&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/vic4key"&gt;vic4key&lt;/a&gt;: For supporting/contributing to this project&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/kier007"&gt;kier007&lt;/a&gt;: for improving the user experience&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/qitianai"&gt;qitianai&lt;/a&gt;: for multi-lingual support&lt;/li&gt; 
 &lt;li&gt;and &lt;a href="https://github.com/hacksider/Deep-Live-Cam/graphs/contributors"&gt;all developers&lt;/a&gt; behind libraries used in this project.&lt;/li&gt; 
 &lt;li&gt;Footnote: Please be informed that the base author of the code is &lt;a href="https://github.com/s0md3v/roop"&gt;s0md3v&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;All the wonderful users who helped make this project go viral by starring the repo ‚ù§Ô∏è&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://github.com/hacksider/Deep-Live-Cam/stargazers"&gt;&lt;img src="https://reporoster.com/stars/hacksider/Deep-Live-Cam" alt="Stargazers" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Contributions&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://repobeats.axiom.co/api/embed/fec8e29c45dfdb9c5916f3a7830e1249308d20e1.svg?sanitize=true" alt="Alt" title="Repobeats analytics image" /&gt;&lt;/p&gt; 
&lt;h2&gt;Stars to the Moon üöÄ&lt;/h2&gt; 
&lt;a href="https://star-history.com/#hacksider/deep-live-cam&amp;amp;Date"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://api.star-history.com/svg?repos=hacksider/deep-live-cam&amp;amp;type=Date&amp;amp;theme=dark" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://api.star-history.com/svg?repos=hacksider/deep-live-cam&amp;amp;type=Date" /&gt; 
  &lt;img alt="Star History Chart" src="https://api.star-history.com/svg?repos=hacksider/deep-live-cam&amp;amp;type=Date" /&gt; 
 &lt;/picture&gt; &lt;/a&gt;</description>
    </item>
    
    <item>
      <title>frankbria/ralph-claude-code</title>
      <link>https://github.com/frankbria/ralph-claude-code</link>
      <description>&lt;p&gt;Autonomous AI development loop for Claude Code with intelligent exit detection&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Ralph for Claude Code&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://github.com/frankbria/ralph-claude-code/actions/workflows/test.yml"&gt;&lt;img src="https://github.com/frankbria/ralph-claude-code/actions/workflows/test.yml/badge.svg?sanitize=true" alt="CI" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/frankbria/ralph-claude-code/main/LICENSE"&gt;&lt;img src="https://img.shields.io/badge/License-MIT-blue.svg?sanitize=true" alt="License: MIT" /&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/badge/version-0.9.9-blue" alt="Version" /&gt; &lt;img src="https://img.shields.io/badge/tests-308%20passing-green" alt="Tests" /&gt; &lt;a href="https://github.com/frankbria/ralph-claude-code/issues"&gt;&lt;img src="https://img.shields.io/github/issues/frankbria/ralph-claude-code" alt="GitHub Issues" /&gt;&lt;/a&gt; &lt;a href="https://github.com/hesreallyhim/awesome-claude-code"&gt;&lt;img src="https://awesome.re/mentioned-badge.svg?sanitize=true" alt="Mentioned in Awesome Claude Code" /&gt;&lt;/a&gt; &lt;a href="https://x.com/FrankBria18044"&gt;&lt;img src="https://img.shields.io/twitter/follow/FrankBria18044?style=social" alt="Follow on X" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Autonomous AI development loop with intelligent exit detection and rate limiting&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Ralph is an implementation of the Geoffrey Huntley's technique for Claude Code that enables continuous autonomous development cycles he named after &lt;a href="https://ghuntley.com/ralph/"&gt;Ralph Wiggum&lt;/a&gt;. It enables continuous autonomous development cycles where Claude Code iteratively improves your project until completion, with built-in safeguards to prevent infinite loops and API overuse.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Install once, use everywhere&lt;/strong&gt; - Ralph becomes a global command available in any directory.&lt;/p&gt; 
&lt;h2&gt;Project Status&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Version&lt;/strong&gt;: v0.9.9 - Active Development &lt;strong&gt;Core Features&lt;/strong&gt;: Working and tested &lt;strong&gt;Test Coverage&lt;/strong&gt;: 308 tests, 100% pass rate&lt;/p&gt; 
&lt;h3&gt;What's Working Now&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Autonomous development loops with intelligent exit detection&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Dual-condition exit gate&lt;/strong&gt;: Requires BOTH completion indicators AND explicit EXIT_SIGNAL&lt;/li&gt; 
 &lt;li&gt;Rate limiting with hourly reset (100 calls/hour, configurable)&lt;/li&gt; 
 &lt;li&gt;Circuit breaker with advanced error detection (prevents runaway loops)&lt;/li&gt; 
 &lt;li&gt;Response analyzer with semantic understanding and two-stage error filtering&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;JSON output format support with automatic fallback to text parsing&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Session continuity with &lt;code&gt;--continue&lt;/code&gt; flag for context preservation&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Session expiration with configurable timeout (default: 24 hours)&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Modern CLI flags: &lt;code&gt;--output-format&lt;/code&gt;, &lt;code&gt;--allowed-tools&lt;/code&gt;, &lt;code&gt;--no-continue&lt;/code&gt;&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;Multi-line error matching for accurate stuck loop detection&lt;/li&gt; 
 &lt;li&gt;5-hour API limit handling with user prompts&lt;/li&gt; 
 &lt;li&gt;tmux integration for live monitoring&lt;/li&gt; 
 &lt;li&gt;PRD import functionality&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;CI/CD pipeline with GitHub Actions&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Dedicated uninstall script for clean removal&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;308 passing tests across 11 test files&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Recent Improvements&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;v0.9.9 - EXIT_SIGNAL Gate &amp;amp; Uninstall Script&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Fixed premature exit bug: completion indicators now require Claude's explicit &lt;code&gt;EXIT_SIGNAL: true&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Added dual-condition check preventing exits when Claude reports work in progress&lt;/li&gt; 
 &lt;li&gt;Added &lt;code&gt;response_analyzer.sh&lt;/code&gt; fix to respect explicit EXIT_SIGNAL over heuristics&lt;/li&gt; 
 &lt;li&gt;Added dedicated &lt;code&gt;uninstall.sh&lt;/code&gt; script for clean Ralph removal&lt;/li&gt; 
 &lt;li&gt;Session expiration with configurable timeout (default: 24 hours)&lt;/li&gt; 
 &lt;li&gt;Added 32 new tests for EXIT_SIGNAL behavior and session expiration&lt;/li&gt; 
 &lt;li&gt;Test count: 308 (up from 276)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;v0.9.8 - Modern CLI for PRD Import&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Modernized &lt;code&gt;ralph_import.sh&lt;/code&gt; to use Claude Code CLI JSON output format&lt;/li&gt; 
 &lt;li&gt;JSON output format support with &lt;code&gt;--output-format json&lt;/code&gt; for structured responses&lt;/li&gt; 
 &lt;li&gt;Enhanced error handling with structured JSON error messages&lt;/li&gt; 
 &lt;li&gt;Improved file verification with JSON-derived status information&lt;/li&gt; 
 &lt;li&gt;Backward compatibility with older CLI versions (automatic text fallback)&lt;/li&gt; 
 &lt;li&gt;Added 11 new tests for modern CLI features&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;v0.9.7 - Session Lifecycle Management&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Complete session lifecycle management with automatic reset triggers&lt;/li&gt; 
 &lt;li&gt;Session auto-reset on: circuit breaker open, manual interrupt, project completion&lt;/li&gt; 
 &lt;li&gt;Added &lt;code&gt;--reset-session&lt;/code&gt; CLI flag for manual session reset&lt;/li&gt; 
 &lt;li&gt;Session history tracking (last 50 transitions) for debugging&lt;/li&gt; 
 &lt;li&gt;Added 26 new tests for session continuity features&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;v0.9.6 - JSON Output &amp;amp; Session Management&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Extended &lt;code&gt;parse_json_response()&lt;/code&gt; to support Claude Code CLI JSON format&lt;/li&gt; 
 &lt;li&gt;Added session management functions: &lt;code&gt;store_session_id()&lt;/code&gt;, &lt;code&gt;get_last_session_id()&lt;/code&gt;, &lt;code&gt;should_resume_session()&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Cross-platform epoch time utilities in date_utils.sh&lt;/li&gt; 
 &lt;li&gt;Added 16 new tests covering Claude CLI format and session management&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;v0.9.5 - PRD Import Tests&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Added 22 comprehensive tests for &lt;code&gt;ralph_import.sh&lt;/code&gt; PRD conversion script&lt;/li&gt; 
 &lt;li&gt;Tests cover: file format support, output file creation, project naming, error handling&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;v0.9.4 - Project Setup Tests&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Added 36 comprehensive tests for &lt;code&gt;setup.sh&lt;/code&gt; project initialization script&lt;/li&gt; 
 &lt;li&gt;Tests cover: directory creation, template copying, git initialization&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;v0.9.3 - Installation Tests&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Added 14 comprehensive tests for &lt;code&gt;install.sh&lt;/code&gt; global installation script&lt;/li&gt; 
 &lt;li&gt;Tests cover: directory creation, command installation, dependency detection&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;v0.9.2 - Prompt File Fix&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Fixed critical bug: replaced non-existent &lt;code&gt;--prompt-file&lt;/code&gt; CLI flag with &lt;code&gt;-p&lt;/code&gt; flag&lt;/li&gt; 
 &lt;li&gt;Modern CLI mode now correctly passes prompt content via &lt;code&gt;-p "$(cat file)"&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Added error handling for missing prompt files in &lt;code&gt;build_claude_command()&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;v0.9.1 - Modern CLI Commands (Phase 1.1)&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;JSON output format support with &lt;code&gt;--output-format json&lt;/code&gt; (default)&lt;/li&gt; 
 &lt;li&gt;Session continuity using &lt;code&gt;--continue&lt;/code&gt; flag for cross-loop context&lt;/li&gt; 
 &lt;li&gt;Tool permissions via &lt;code&gt;--allowed-tools&lt;/code&gt; flag&lt;/li&gt; 
 &lt;li&gt;CI/CD pipeline with kcov coverage reporting&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;v0.9.0 - Circuit Breaker Enhancements&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Fixed multi-line error matching in stuck loop detection&lt;/li&gt; 
 &lt;li&gt;Eliminated JSON field false positives (e.g., &lt;code&gt;"is_error": false&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;Added two-stage error filtering for accurate detection&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;In Progress&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Expanding test coverage&lt;/li&gt; 
 &lt;li&gt;Log rotation functionality&lt;/li&gt; 
 &lt;li&gt;Dry-run mode&lt;/li&gt; 
 &lt;li&gt;Configuration file support (.ralphrc)&lt;/li&gt; 
 &lt;li&gt;Metrics and analytics tracking&lt;/li&gt; 
 &lt;li&gt;Desktop notifications&lt;/li&gt; 
 &lt;li&gt;Git backup and rollback system&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Timeline to v1.0&lt;/strong&gt;: ~4 weeks | &lt;a href="https://raw.githubusercontent.com/frankbria/ralph-claude-code/main/IMPLEMENTATION_PLAN.md"&gt;Full roadmap&lt;/a&gt; | &lt;strong&gt;Contributions welcome!&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Autonomous Development Loop&lt;/strong&gt; - Continuously executes Claude Code with your project requirements&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Intelligent Exit Detection&lt;/strong&gt; - Dual-condition check requiring BOTH completion indicators AND explicit EXIT_SIGNAL&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Session Continuity&lt;/strong&gt; - Preserves context across loop iterations with automatic session management&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Session Expiration&lt;/strong&gt; - Configurable timeout (default: 24 hours) with automatic session reset&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Rate Limiting&lt;/strong&gt; - Built-in API call management with hourly limits and countdown timers&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;5-Hour API Limit Handling&lt;/strong&gt; - Detects Claude's 5-hour usage limit and offers wait/exit options&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Live Monitoring&lt;/strong&gt; - Real-time dashboard showing loop status, progress, and logs&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Task Management&lt;/strong&gt; - Structured approach with prioritized task lists and progress tracking&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Project Templates&lt;/strong&gt; - Quick setup for new projects with best-practice structure&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Comprehensive Logging&lt;/strong&gt; - Detailed execution logs with timestamps and status tracking&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Configurable Timeouts&lt;/strong&gt; - Set execution timeout for Claude Code operations (1-120 minutes)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Verbose Progress Mode&lt;/strong&gt; - Optional detailed progress updates during execution&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Response Analyzer&lt;/strong&gt; - AI-powered analysis of Claude Code responses with semantic understanding&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Circuit Breaker&lt;/strong&gt; - Advanced error detection with two-stage filtering, multi-line error matching, and automatic recovery&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;CI/CD Integration&lt;/strong&gt; - GitHub Actions workflow with automated testing&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Clean Uninstall&lt;/strong&gt; - Dedicated uninstall script for complete removal&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;p&gt;Ralph has two phases: &lt;strong&gt;one-time installation&lt;/strong&gt; and &lt;strong&gt;per-project setup&lt;/strong&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;INSTALL ONCE              USE MANY TIMES
+-----------------+          +----------------------+
| ./install.sh    |    -&amp;gt;    | ralph-setup project1 |
|                 |          | ralph-setup project2 |
| Adds global     |          | ralph-setup project3 |
| commands        |          | ...                  |
+-----------------+          +----------------------+
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Phase 1: Install Ralph (One Time Only)&lt;/h3&gt; 
&lt;p&gt;Install Ralph globally on your system:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/frankbria/ralph-claude-code.git
cd ralph-claude-code
./install.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This adds &lt;code&gt;ralph&lt;/code&gt;, &lt;code&gt;ralph-monitor&lt;/code&gt;, and &lt;code&gt;ralph-setup&lt;/code&gt; commands to your PATH.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: You only need to do this once per system. After installation, you can delete the cloned repository if desired.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Phase 2: Initialize New Projects (Per Project)&lt;/h3&gt; 
&lt;p&gt;For each new project you want Ralph to work on:&lt;/p&gt; 
&lt;h4&gt;Option A: Import Existing PRD/Specifications&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Convert existing PRD/specs to Ralph format (recommended)
ralph-import my-requirements.md my-project
cd my-project

# Review and adjust the generated files:
# - PROMPT.md (Ralph instructions)
# - @fix_plan.md (task priorities)
# - specs/requirements.md (technical specs)

# Start autonomous development
ralph --monitor
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Option B: Manual Project Setup&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Create blank Ralph project
ralph-setup my-awesome-project
cd my-awesome-project

# Configure your project requirements manually
# Edit PROMPT.md with your project goals
# Edit specs/ with detailed specifications
# Edit @fix_plan.md with initial priorities

# Start autonomous development
ralph --monitor
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Ongoing Usage (After Setup)&lt;/h3&gt; 
&lt;p&gt;Once Ralph is installed and your project is initialized:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Navigate to any Ralph project and run:
ralph --monitor              # Integrated tmux monitoring (recommended)

# Or use separate terminals:
ralph                        # Terminal 1: Ralph loop
ralph-monitor               # Terminal 2: Live monitor dashboard
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Uninstalling Ralph&lt;/h3&gt; 
&lt;p&gt;To completely remove Ralph from your system:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Run the uninstall script
./uninstall.sh

# Or if you deleted the repo, download and run:
curl -sL https://raw.githubusercontent.com/frankbria/ralph-claude-code/main/uninstall.sh | bash
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;How It Works&lt;/h2&gt; 
&lt;p&gt;Ralph operates on a simple but powerful cycle:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Read Instructions&lt;/strong&gt; - Loads &lt;code&gt;PROMPT.md&lt;/code&gt; with your project requirements&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Execute Claude Code&lt;/strong&gt; - Runs Claude Code with current context and priorities&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Track Progress&lt;/strong&gt; - Updates task lists and logs execution results&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Evaluate Completion&lt;/strong&gt; - Checks for exit conditions and project completion signals&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Repeat&lt;/strong&gt; - Continues until project is complete or limits are reached&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Intelligent Exit Detection&lt;/h3&gt; 
&lt;p&gt;Ralph uses a &lt;strong&gt;dual-condition check&lt;/strong&gt; to prevent premature exits during productive iterations:&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Exit requires BOTH conditions:&lt;/strong&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;code&gt;completion_indicators &amp;gt;= 2&lt;/code&gt; (heuristic detection from natural language patterns)&lt;/li&gt; 
 &lt;li&gt;Claude's explicit &lt;code&gt;EXIT_SIGNAL: true&lt;/code&gt; in the RALPH_STATUS block&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;Example behavior:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Loop 5: Claude outputs "Phase complete, moving to next feature"
        ‚Üí completion_indicators: 3 (high confidence from patterns)
        ‚Üí EXIT_SIGNAL: false (Claude says more work needed)
        ‚Üí Result: CONTINUE (respects Claude's explicit intent)

Loop 8: Claude outputs "All tasks complete, project ready"
        ‚Üí completion_indicators: 4
        ‚Üí EXIT_SIGNAL: true (Claude confirms done)
        ‚Üí Result: EXIT with "project_complete"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Other exit conditions:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;All tasks in &lt;code&gt;@fix_plan.md&lt;/code&gt; marked complete&lt;/li&gt; 
 &lt;li&gt;Multiple consecutive "done" signals from Claude Code&lt;/li&gt; 
 &lt;li&gt;Too many test-focused loops (indicating feature completeness)&lt;/li&gt; 
 &lt;li&gt;Claude API 5-hour usage limit reached (with user prompt to wait or exit)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Importing Existing Requirements&lt;/h2&gt; 
&lt;p&gt;Ralph can convert existing PRDs, specifications, or requirement documents into the proper Ralph format using Claude Code.&lt;/p&gt; 
&lt;h3&gt;Supported Formats&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Markdown&lt;/strong&gt; (.md) - Product requirements, technical specs&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Text files&lt;/strong&gt; (.txt) - Plain text requirements&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;JSON&lt;/strong&gt; (.json) - Structured requirement data&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Word documents&lt;/strong&gt; (.docx) - Business requirements&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;PDFs&lt;/strong&gt; (.pdf) - Design documents, specifications&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Any text-based format&lt;/strong&gt; - Ralph will intelligently parse the content&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Usage Examples&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Convert a markdown PRD
ralph-import product-requirements.md my-app

# Convert a text specification
ralph-import requirements.txt webapp

# Convert a JSON API spec
ralph-import api-spec.json backend-service

# Let Ralph auto-name the project from filename
ralph-import design-doc.pdf
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;What Gets Generated&lt;/h3&gt; 
&lt;p&gt;Ralph-import creates a complete project with:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;PROMPT.md&lt;/strong&gt; - Converted into Ralph development instructions&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;@fix_plan.md&lt;/strong&gt; - Requirements broken down into prioritized tasks&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;specs/requirements.md&lt;/strong&gt; - Technical specifications extracted from your document&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Standard Ralph structure&lt;/strong&gt; - All necessary directories and template files&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The conversion is intelligent and preserves your original requirements while making them actionable for autonomous development.&lt;/p&gt; 
&lt;h3&gt;Modern CLI Features (v0.9.8)&lt;/h3&gt; 
&lt;p&gt;Ralph-import uses modern Claude Code CLI features for improved reliability:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;JSON Output Format&lt;/strong&gt;: Structured responses enable precise parsing of conversion results&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Automatic Fallback&lt;/strong&gt;: Gracefully handles older CLI versions with text-based parsing&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Enhanced Error Reporting&lt;/strong&gt;: Extracts specific error messages and codes from JSON responses&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Session Tracking&lt;/strong&gt;: Captures session IDs for potential continuation of interrupted conversions&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: These features require Claude Code CLI version 2.0.76 or later. Older versions will work with standard text output.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Configuration&lt;/h2&gt; 
&lt;h3&gt;Rate Limiting &amp;amp; Circuit Breaker&lt;/h3&gt; 
&lt;p&gt;Ralph includes intelligent rate limiting and circuit breaker functionality:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Default: 100 calls per hour
ralph --calls 50

# With integrated monitoring
ralph --monitor --calls 50

# Check current usage
ralph --status
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The circuit breaker automatically:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Detects API errors and rate limit issues with advanced two-stage filtering&lt;/li&gt; 
 &lt;li&gt;Opens circuit after 3 loops with no progress or 5 loops with same errors&lt;/li&gt; 
 &lt;li&gt;Eliminates false positives from JSON fields containing "error"&lt;/li&gt; 
 &lt;li&gt;Accurately detects stuck loops with multi-line error matching&lt;/li&gt; 
 &lt;li&gt;Gradually recovers with half-open monitoring state&lt;/li&gt; 
 &lt;li&gt;Provides detailed error tracking and logging with state history&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Claude API 5-Hour Limit&lt;/h3&gt; 
&lt;p&gt;When Claude's 5-hour usage limit is reached, Ralph:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Detects the limit error automatically&lt;/li&gt; 
 &lt;li&gt;Prompts you to choose: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Option 1&lt;/strong&gt;: Wait 60 minutes for the limit to reset (with countdown timer)&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Option 2&lt;/strong&gt;: Exit gracefully (or auto-exits after 30-second timeout)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Prevents endless retry loops that waste time&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Custom Prompts&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Use custom prompt file
ralph --prompt my_custom_instructions.md

# With integrated monitoring
ralph --monitor --prompt my_custom_instructions.md
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Execution Timeouts&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Set Claude Code execution timeout (default: 15 minutes)
ralph --timeout 30  # 30-minute timeout for complex tasks

# With monitoring and custom timeout
ralph --monitor --timeout 60  # 60-minute timeout

# Short timeout for quick iterations
ralph --verbose --timeout 5  # 5-minute timeout with progress
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Verbose Mode&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Enable detailed progress updates during execution
ralph --verbose

# Combine with other options
ralph --monitor --verbose --timeout 30
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Session Continuity&lt;/h3&gt; 
&lt;p&gt;Ralph maintains session context across loop iterations for improved coherence:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Sessions are enabled by default with --continue flag
ralph --monitor                 # Uses session continuity

# Start fresh without session context
ralph --no-continue             # Isolated iterations

# Reset session manually (clears context)
ralph --reset-session           # Clears current session

# Check session status
cat .ralph_session              # View current session file
cat .ralph_session_history      # View session transition history
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Session Auto-Reset Triggers:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Circuit breaker opens (stagnation detected)&lt;/li&gt; 
 &lt;li&gt;Manual interrupt (Ctrl+C / SIGINT)&lt;/li&gt; 
 &lt;li&gt;Project completion (graceful exit)&lt;/li&gt; 
 &lt;li&gt;Manual circuit breaker reset (&lt;code&gt;--reset-circuit&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;Session expiration (default: 24 hours)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Sessions are persisted to &lt;code&gt;.ralph_session&lt;/code&gt; with a configurable expiration (default: 24 hours). The last 50 session transitions are logged to &lt;code&gt;.ralph_session_history&lt;/code&gt; for debugging.&lt;/p&gt; 
&lt;h3&gt;Exit Thresholds&lt;/h3&gt; 
&lt;p&gt;Modify these variables in &lt;code&gt;~/.ralph/ralph_loop.sh&lt;/code&gt;:&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Exit Detection Thresholds:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;MAX_CONSECUTIVE_TEST_LOOPS=3     # Exit after 3 test-only loops
MAX_CONSECUTIVE_DONE_SIGNALS=2   # Exit after 2 "done" signals
TEST_PERCENTAGE_THRESHOLD=30     # Flag if 30%+ loops are test-only
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Circuit Breaker Thresholds:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;CB_NO_PROGRESS_THRESHOLD=3       # Open circuit after 3 loops with no file changes
CB_SAME_ERROR_THRESHOLD=5        # Open circuit after 5 loops with repeated errors
CB_OUTPUT_DECLINE_THRESHOLD=70   # Open circuit if output declines by &amp;gt;70%
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Completion Indicators with EXIT_SIGNAL Gate:&lt;/strong&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;completion_indicators&lt;/th&gt; 
   &lt;th&gt;EXIT_SIGNAL&lt;/th&gt; 
   &lt;th&gt;Result&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&amp;gt;= 2&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;true&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Exit&lt;/strong&gt; ("project_complete")&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&amp;gt;= 2&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;false&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Continue&lt;/strong&gt; (Claude still working)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&amp;gt;= 2&lt;/td&gt; 
   &lt;td&gt;missing&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Continue&lt;/strong&gt; (defaults to false)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&amp;lt; 2&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;true&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Continue&lt;/strong&gt; (threshold not met)&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Project Structure&lt;/h2&gt; 
&lt;p&gt;Ralph creates a standardized structure for each project:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;my-project/
‚îú‚îÄ‚îÄ PROMPT.md           # Main development instructions for Ralph
‚îú‚îÄ‚îÄ @fix_plan.md        # Prioritized task list (@ prefix = Ralph control file)
‚îú‚îÄ‚îÄ @AGENT.md           # Build and run instructions
‚îú‚îÄ‚îÄ specs/              # Project specifications and requirements
‚îÇ   ‚îî‚îÄ‚îÄ stdlib/         # Standard library specifications
‚îú‚îÄ‚îÄ src/                # Source code implementation
‚îú‚îÄ‚îÄ examples/           # Usage examples and test cases
‚îú‚îÄ‚îÄ logs/               # Ralph execution logs
‚îî‚îÄ‚îÄ docs/generated/     # Auto-generated documentation
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Best Practices&lt;/h2&gt; 
&lt;h3&gt;Writing Effective Prompts&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Be Specific&lt;/strong&gt; - Clear requirements lead to better results&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Prioritize&lt;/strong&gt; - Use &lt;code&gt;@fix_plan.md&lt;/code&gt; to guide Ralph's focus&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Set Boundaries&lt;/strong&gt; - Define what's in/out of scope&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Include Examples&lt;/strong&gt; - Show expected inputs/outputs&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Project Specifications&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Place detailed requirements in &lt;code&gt;specs/&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Use &lt;code&gt;@fix_plan.md&lt;/code&gt; for prioritized task tracking&lt;/li&gt; 
 &lt;li&gt;Keep &lt;code&gt;@AGENT.md&lt;/code&gt; updated with build instructions&lt;/li&gt; 
 &lt;li&gt;Document key decisions and architecture&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Monitoring Progress&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Use &lt;code&gt;ralph-monitor&lt;/code&gt; for live status updates&lt;/li&gt; 
 &lt;li&gt;Check logs in &lt;code&gt;logs/&lt;/code&gt; for detailed execution history&lt;/li&gt; 
 &lt;li&gt;Monitor &lt;code&gt;status.json&lt;/code&gt; for programmatic access&lt;/li&gt; 
 &lt;li&gt;Watch for exit condition signals&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;System Requirements&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Bash 4.0+&lt;/strong&gt; - For script execution&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Claude Code CLI&lt;/strong&gt; - &lt;code&gt;npm install -g @anthropic-ai/claude-code&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;tmux&lt;/strong&gt; - Terminal multiplexer for integrated monitoring (recommended)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;jq&lt;/strong&gt; - JSON processing for status tracking&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Git&lt;/strong&gt; - Version control (projects are initialized as git repos)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Standard Unix tools&lt;/strong&gt; - grep, date, etc.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Testing Requirements (Development)&lt;/h3&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/frankbria/ralph-claude-code/main/TESTING.md"&gt;TESTING.md&lt;/a&gt; for the comprehensive testing guide.&lt;/p&gt; 
&lt;p&gt;If you want to run the test suite:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Install BATS testing framework
npm install -g bats bats-support bats-assert

# Run all tests (308 tests)
npm test

# Run specific test suites
bats tests/unit/test_rate_limiting.bats
bats tests/unit/test_exit_detection.bats
bats tests/unit/test_json_parsing.bats
bats tests/unit/test_cli_modern.bats
bats tests/unit/test_cli_parsing.bats
bats tests/unit/test_session_continuity.bats
bats tests/integration/test_loop_execution.bats
bats tests/integration/test_prd_import.bats
bats tests/integration/test_project_setup.bats
bats tests/integration/test_installation.bats

# Run error detection and circuit breaker tests
./tests/test_error_detection.sh
./tests/test_stuck_loop_detection.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Current test status:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;308 tests&lt;/strong&gt; across 11 test files&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;100% pass rate&lt;/strong&gt; (308/308 passing)&lt;/li&gt; 
 &lt;li&gt;Comprehensive unit and integration tests&lt;/li&gt; 
 &lt;li&gt;Specialized tests for JSON parsing, CLI flags, circuit breaker, EXIT_SIGNAL behavior, and installation workflows&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note on Coverage&lt;/strong&gt;: Bash code coverage measurement with kcov has fundamental limitations when tracing subprocess executions. Test pass rate (100%) is the quality gate. See &lt;a href="https://github.com/bats-core/bats-core/issues/15"&gt;bats-core#15&lt;/a&gt; for details.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Installing tmux&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Ubuntu/Debian
sudo apt-get install tmux

# macOS
brew install tmux

# CentOS/RHEL
sudo yum install tmux
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Monitoring and Debugging&lt;/h2&gt; 
&lt;h3&gt;Live Dashboard&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Integrated tmux monitoring (recommended)
ralph --monitor

# Manual monitoring in separate terminal
ralph-monitor
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Shows real-time:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Current loop count and status&lt;/li&gt; 
 &lt;li&gt;API calls used vs. limit&lt;/li&gt; 
 &lt;li&gt;Recent log entries&lt;/li&gt; 
 &lt;li&gt;Rate limit countdown&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;tmux Controls:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;Ctrl+B&lt;/code&gt; then &lt;code&gt;D&lt;/code&gt; - Detach from session (keeps Ralph running)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;Ctrl+B&lt;/code&gt; then &lt;code&gt;‚Üê/‚Üí&lt;/code&gt; - Switch between panes&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;tmux list-sessions&lt;/code&gt; - View active sessions&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;tmux attach -t &amp;lt;session-name&amp;gt;&lt;/code&gt; - Reattach to session&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Status Checking&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# JSON status output
ralph --status

# Manual log inspection
tail -f logs/ralph.log
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Common Issues&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Rate Limits&lt;/strong&gt; - Ralph automatically waits and displays countdown&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;5-Hour API Limit&lt;/strong&gt; - Ralph detects and prompts for user action (wait or exit)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Stuck Loops&lt;/strong&gt; - Check &lt;code&gt;@fix_plan.md&lt;/code&gt; for unclear or conflicting tasks&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Early Exit&lt;/strong&gt; - Review exit thresholds if Ralph stops too soon&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Premature Exit&lt;/strong&gt; - Check if Claude is setting &lt;code&gt;EXIT_SIGNAL: false&lt;/code&gt; (Ralph now respects this)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Execution Timeouts&lt;/strong&gt; - Increase &lt;code&gt;--timeout&lt;/code&gt; value for complex operations&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Missing Dependencies&lt;/strong&gt; - Ensure Claude Code CLI and tmux are installed&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;tmux Session Lost&lt;/strong&gt; - Use &lt;code&gt;tmux list-sessions&lt;/code&gt; and &lt;code&gt;tmux attach&lt;/code&gt; to reconnect&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Session Expired&lt;/strong&gt; - Sessions expire after 24 hours by default; use &lt;code&gt;--reset-session&lt;/code&gt; to start fresh&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Ralph is actively seeking contributors! We're working toward v1.0.0 with clear priorities and a detailed roadmap.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;See &lt;a href="https://raw.githubusercontent.com/frankbria/ralph-claude-code/main/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; for the complete contributor guide&lt;/strong&gt; including:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Getting started and setup instructions&lt;/li&gt; 
 &lt;li&gt;Development workflow and commit conventions&lt;/li&gt; 
 &lt;li&gt;Code style guidelines&lt;/li&gt; 
 &lt;li&gt;Testing requirements (100% pass rate mandatory)&lt;/li&gt; 
 &lt;li&gt;Pull request process and code review guidelines&lt;/li&gt; 
 &lt;li&gt;Quality standards and checklists&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Quick Start&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Fork and clone
git clone https://github.com/YOUR_USERNAME/ralph-claude-code.git
cd ralph-claude-code

# Install dependencies and run tests
npm install
npm test  # All 308 tests must pass
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Priority Contribution Areas&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Test Implementation&lt;/strong&gt; - Help expand test coverage&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Feature Development&lt;/strong&gt; - Log rotation, dry-run mode, config files, metrics&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Documentation&lt;/strong&gt; - Tutorials, troubleshooting guides, examples&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Real-World Testing&lt;/strong&gt; - Use Ralph, report bugs, share feedback&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;Every contribution matters&lt;/strong&gt; - from fixing typos to implementing major features!&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the MIT License - see the &lt;a href="https://raw.githubusercontent.com/frankbria/ralph-claude-code/main/LICENSE"&gt;LICENSE&lt;/a&gt; file for details.&lt;/p&gt; 
&lt;h2&gt;Acknowledgments&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Inspired by the &lt;a href="https://ghuntley.com/ralph/"&gt;Ralph technique&lt;/a&gt; created by Geoffrey Huntley&lt;/li&gt; 
 &lt;li&gt;Built for &lt;a href="https://claude.ai/code"&gt;Claude Code&lt;/a&gt; by Anthropic&lt;/li&gt; 
 &lt;li&gt;Community feedback and contributions&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Related Projects&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://claude.ai/code"&gt;Claude Code&lt;/a&gt; - The AI coding assistant that powers Ralph&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/paul-gauthier/aider"&gt;Aider&lt;/a&gt; - Original Ralph technique implementation&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Command Reference&lt;/h2&gt; 
&lt;h3&gt;Installation Commands (Run Once)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;./install.sh              # Install Ralph globally
./uninstall.sh            # Remove Ralph from system (dedicated script)
./install.sh uninstall    # Alternative: Remove Ralph from system
./install.sh --help       # Show installation help
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Ralph Loop Options&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;ralph [OPTIONS]
  -h, --help              Show help message
  -c, --calls NUM         Set max calls per hour (default: 100)
  -p, --prompt FILE       Set prompt file (default: PROMPT.md)
  -s, --status            Show current status and exit
  -m, --monitor           Start with tmux session and live monitor
  -v, --verbose           Show detailed progress updates during execution
  -t, --timeout MIN       Set Claude Code execution timeout in minutes (1-120, default: 15)
  --output-format FORMAT  Set output format: json (default) or text
  --allowed-tools TOOLS   Set allowed Claude tools (default: Write,Bash(git *),Read)
  --no-continue           Disable session continuity (start fresh each loop)
  --reset-circuit         Reset the circuit breaker
  --circuit-status        Show circuit breaker status
  --reset-session         Reset session state manually
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Project Commands (Per Project)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;ralph-setup project-name     # Create new Ralph project
ralph-import prd.md project  # Convert PRD/specs to Ralph project
ralph --monitor              # Start with integrated monitoring
ralph --status               # Check current loop status
ralph --verbose              # Enable detailed progress updates
ralph --timeout 30           # Set 30-minute execution timeout
ralph --calls 50             # Limit to 50 API calls per hour
ralph --reset-session        # Reset session state manually
ralph-monitor                # Manual monitoring dashboard
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;tmux Session Management&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;tmux list-sessions        # View active Ralph sessions
tmux attach -t &amp;lt;name&amp;gt;     # Reattach to detached session
# Ctrl+B then D           # Detach from session (keeps running)
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Development Roadmap&lt;/h2&gt; 
&lt;p&gt;Ralph is under active development with a clear path to v1.0.0. See &lt;a href="https://raw.githubusercontent.com/frankbria/ralph-claude-code/main/IMPLEMENTATION_PLAN.md"&gt;IMPLEMENTATION_PLAN.md&lt;/a&gt; for the complete roadmap.&lt;/p&gt; 
&lt;h3&gt;Current Status: v0.9.9&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;What's Delivered:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Core loop functionality with intelligent exit detection&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Dual-condition exit gate&lt;/strong&gt; (completion indicators + EXIT_SIGNAL)&lt;/li&gt; 
 &lt;li&gt;Rate limiting (100 calls/hour) and circuit breaker pattern&lt;/li&gt; 
 &lt;li&gt;Response analyzer with semantic understanding&lt;/li&gt; 
 &lt;li&gt;308 comprehensive tests (100% pass rate)&lt;/li&gt; 
 &lt;li&gt;tmux integration and live monitoring&lt;/li&gt; 
 &lt;li&gt;PRD import functionality with modern CLI JSON parsing&lt;/li&gt; 
 &lt;li&gt;Installation system and project templates&lt;/li&gt; 
 &lt;li&gt;Modern CLI commands with JSON output support&lt;/li&gt; 
 &lt;li&gt;CI/CD pipeline with GitHub Actions&lt;/li&gt; 
 &lt;li&gt;Comprehensive installation test suite&lt;/li&gt; 
 &lt;li&gt;Session lifecycle management with auto-reset triggers&lt;/li&gt; 
 &lt;li&gt;Session expiration with configurable timeout&lt;/li&gt; 
 &lt;li&gt;Dedicated uninstall script&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Test Coverage Breakdown:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Unit Tests: 164 (CLI parsing, JSON, exit detection, rate limiting, session continuity)&lt;/li&gt; 
 &lt;li&gt;Integration Tests: 144 (loop execution, edge cases, installation, project setup, PRD import)&lt;/li&gt; 
 &lt;li&gt;Test Files: 11&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Path to v1.0.0 (~4 weeks)&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Enhanced Testing&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Installation and setup workflow tests&lt;/li&gt; 
 &lt;li&gt;tmux integration tests&lt;/li&gt; 
 &lt;li&gt;Monitor dashboard tests&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Core Features&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Log rotation functionality&lt;/li&gt; 
 &lt;li&gt;Dry-run mode&lt;/li&gt; 
 &lt;li&gt;Configuration file support - .ralphrc&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Advanced Features &amp;amp; Polish&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Metrics and analytics tracking&lt;/li&gt; 
 &lt;li&gt;Desktop notifications&lt;/li&gt; 
 &lt;li&gt;Git backup and rollback system&lt;/li&gt; 
 &lt;li&gt;End-to-end tests&lt;/li&gt; 
 &lt;li&gt;Final documentation and release prep&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/frankbria/ralph-claude-code/main/IMPLEMENTATION_STATUS.md"&gt;IMPLEMENTATION_STATUS.md&lt;/a&gt; for detailed progress tracking.&lt;/p&gt; 
&lt;h3&gt;How to Contribute&lt;/h3&gt; 
&lt;p&gt;Ralph is seeking contributors! See &lt;a href="https://raw.githubusercontent.com/frankbria/ralph-claude-code/main/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; for the complete guide. Priority areas:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Test Implementation&lt;/strong&gt; - Help expand test coverage (&lt;a href="https://raw.githubusercontent.com/frankbria/ralph-claude-code/main/IMPLEMENTATION_PLAN.md"&gt;see plan&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Feature Development&lt;/strong&gt; - Log rotation, dry-run mode, config files&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Documentation&lt;/strong&gt; - Usage examples, tutorials, troubleshooting guides&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Bug Reports&lt;/strong&gt; - Real-world usage feedback and edge cases&lt;/li&gt; 
&lt;/ol&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;strong&gt;Ready to let AI build your project?&lt;/strong&gt; Start with &lt;code&gt;./install.sh&lt;/code&gt; and let Ralph take it from there!&lt;/p&gt; 
&lt;h2&gt;Star History&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://www.star-history.com/#frankbria/ralph-claude-code&amp;amp;type=date&amp;amp;legend=top-left"&gt;&lt;img src="https://api.star-history.com/svg?repos=frankbria/ralph-claude-code&amp;amp;type=date&amp;amp;legend=top-left" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>OpenBMB/ChatDev</title>
      <link>https://github.com/OpenBMB/ChatDev</link>
      <description>&lt;p&gt;ChatDev 2.0: Dev All through LLM-powered Multi-Agent Collaboration&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;ChatDev 2.0 - DevAll&lt;/h1&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/frontend/public/media/logo.png" alt="DevAll Logo" width="500" /&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;strong&gt;A Zero-Code Multi-Agent Platform for Developing Everything&lt;/strong&gt; &lt;/p&gt; 
&lt;p align="center"&gt; „Äê&lt;a href="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/README.md"&gt;English&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/README-zh.md"&gt;ÁÆÄ‰Ωì‰∏≠Êñá&lt;/a&gt;„Äë &lt;/p&gt; 
&lt;p align="center"&gt; „Äêüìö &lt;a href="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/#developers"&gt;Developers&lt;/a&gt; | üë• &lt;a href="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/#primary-contributors"&gt;Contributors&lt;/a&gt;ÔΩú‚≠êÔ∏è &lt;a href="https://github.com/OpenBMB/ChatDev/tree/chatdev1.0"&gt;ChatDev 1.0 (Legacy)&lt;/a&gt;„Äë &lt;/p&gt; 
&lt;h2&gt;üìñ Overview&lt;/h2&gt; 
&lt;p&gt;ChatDev has evolved from a specialized software development multi-agent system into a comprehensive multi-agent orchestration platform.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/OpenBMB/ChatDev/tree/main"&gt;&lt;strong&gt;ChatDev 2.0 (DevAll)&lt;/strong&gt;&lt;/a&gt; is a &lt;strong&gt;Zero-Code Multi-Agent Platform&lt;/strong&gt; for "Developing Everything". It empowers users to rapidly build and execute customized multi-agent systems through simple configuration. No coding is required‚Äîusers can define agents, workflows, and tasks to orchestrate complex scenarios such as data visualization, 3D generation, and deep research.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/OpenBMB/ChatDev/tree/chatdev1.0"&gt;&lt;strong&gt;ChatDev 1.0 (Legacy)&lt;/strong&gt;&lt;/a&gt; operates as a &lt;strong&gt;Virtual Software Company&lt;/strong&gt;. It utilizes various intelligent agents (e.g., CEO, CTO, Programmer) participating in specialized functional seminars to automate the entire software development life cycle‚Äîincluding designing, coding, testing, and documenting. It serves as the foundational paradigm for communicative agent collaboration.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üéâ News&lt;/h2&gt; 
&lt;p&gt;‚Ä¢ &lt;strong&gt;Jan 07, 2026: üöÄ We are excited to announce the official release of ChatDev 2.0 (DevAll)!&lt;/strong&gt; This version introduces a zero-code multi-agent orchestration platform. The classic ChatDev (v1.x) has been moved to the &lt;a href="https://github.com/OpenBMB/ChatDev/tree/chatdev1.0"&gt;&lt;code&gt;chatdev1.0&lt;/code&gt;&lt;/a&gt; branch for maintenance. More details about ChatDev 2.0 can be found on &lt;a href="https://x.com/OpenBMB/status/2008916790399701335"&gt;our official post&lt;/a&gt;.&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;Old News&lt;/summary&gt; 
 &lt;p&gt;‚Ä¢Sep 24, 2025: üéâ Our paper &lt;a href="https://arxiv.org/abs/2505.19591"&gt;Multi-Agent Collaboration via Evolving Orchestration&lt;/a&gt; has been accepted to NeurIPS 2025. The implementation is available in the &lt;code&gt;puppeteer&lt;/code&gt; branch of this repository.&lt;/p&gt; 
 &lt;p&gt;‚Ä¢May 26, 2025: üéâ We propose a novel puppeteer-style paradigm for multi-agent collaboration among large language model based agents. By leveraging a learnable central orchestrator optimized with reinforcement learning, our method dynamically activates and sequences agents to construct efficient, context-aware reasoning paths. This approach not only improves reasoning quality but also reduces computational costs, enabling scalable and adaptable multi-agent cooperation in complex tasks. See our paper in &lt;a href="https://arxiv.org/abs/2505.19591"&gt;Multi-Agent Collaboration via Evolving Orchestration&lt;/a&gt;.&lt;/p&gt; 
 &lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/puppeteer.png" width="800" /&gt; &lt;/p&gt; 
 &lt;p&gt;‚Ä¢June 25, 2024: üéâTo foster development in LLM-powered multi-agent collaborationü§ñü§ñ and related fields, the ChatDev team has curated a collection of seminal papersüìÑ presented in a &lt;a href="https://github.com/OpenBMB/ChatDev/tree/main/MultiAgentEbook"&gt;open-source&lt;/a&gt; interactive e-booküìö format. Now you can explore the latest advancements on the &lt;a href="https://thinkwee.top/multiagent_ebook"&gt;Ebook Website&lt;/a&gt; and download the &lt;a href="https://github.com/OpenBMB/ChatDev/raw/main/MultiAgentEbook/papers.csv"&gt;paper list&lt;/a&gt;.&lt;/p&gt; 
 &lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/ebook.png" width="800" /&gt; &lt;/p&gt; 
 &lt;p&gt;‚Ä¢June 12, 2024: We introduced Multi-Agent Collaboration Networks (MacNet) üéâ, which utilize directed acyclic graphs to facilitate effective task-oriented collaboration among agents through linguistic interactions ü§ñü§ñ. MacNet supports co-operation across various topologies and among more than a thousand agents without exceeding context limits. More versatile and scalable, MacNet can be considered as a more advanced version of ChatDev's chain-shaped topology. Our preprint paper is available at &lt;a href="https://arxiv.org/abs/2406.07155"&gt;https://arxiv.org/abs/2406.07155&lt;/a&gt;. This technique has been incorporated into the &lt;a href="https://github.com/OpenBMB/ChatDev/tree/macnet"&gt;macnet&lt;/a&gt; branch, enhancing support for diverse organizational structures and offering richer solutions beyond software development (e.g., logical reasoning, data analysis, story generation, and more).&lt;/p&gt; 
 &lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/macnet.png" width="500" /&gt; &lt;/p&gt; 
 &lt;p&gt;‚Ä¢ May 07, 2024, we introduced "Iterative Experience Refinement" (IER), a novel method where instructor and assistant agents enhance shortcut-oriented experiences to efficiently adapt to new tasks. This approach encompasses experience acquisition, utilization, propagation and elimination across a series of tasks and making the pricess shorter and efficient. Our preprint paper is available at &lt;a href="https://arxiv.org/abs/2405.04219"&gt;https://arxiv.org/abs/2405.04219&lt;/a&gt;, and this technique will soon be incorporated into ChatDev.&lt;/p&gt; 
 &lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/ier.png" width="220" /&gt; &lt;/p&gt; 
 &lt;p&gt;‚Ä¢ January 25, 2024: We have integrated Experiential Co-Learning Module into ChatDev. Please see the &lt;a href="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/wiki.md#co-tracking"&gt;Experiential Co-Learning Guide&lt;/a&gt;.&lt;/p&gt; 
 &lt;p&gt;‚Ä¢ December 28, 2023: We present Experiential Co-Learning, an innovative approach where instructor and assistant agents accumulate shortcut-oriented experiences to effectively solve new tasks, reducing repetitive errors and enhancing efficiency. Check out our preprint paper at &lt;a href="https://arxiv.org/abs/2312.17025"&gt;https://arxiv.org/abs/2312.17025&lt;/a&gt; and this technique will soon be integrated into ChatDev.&lt;/p&gt; 
 &lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/ecl.png" width="860" /&gt; &lt;/p&gt; ‚Ä¢ November 15, 2023: We launched ChatDev as a SaaS platform that enables software developers and innovative entrepreneurs to build software efficiently at a very low cost and remove the barrier to entry. Try it out at https://chatdev.modelbest.cn/. 
 &lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/saas.png" width="560" /&gt; &lt;/p&gt; 
 &lt;p&gt;‚Ä¢ November 2, 2023: ChatDev is now supported with a new feature: incremental development, which allows agents to develop upon existing codes. Try &lt;code&gt;--config "incremental" --path "[source_code_directory_path]"&lt;/code&gt; to start it.&lt;/p&gt; 
 &lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/increment.png" width="700" /&gt; &lt;/p&gt; 
 &lt;p&gt;‚Ä¢ October 26, 2023: ChatDev is now supported with Docker for safe execution (thanks to contribution from &lt;a href="https://github.com/ManindraDeMel"&gt;ManindraDeMel&lt;/a&gt;). Please see &lt;a href="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/wiki.md#docker-start"&gt;Docker Start Guide&lt;/a&gt;.&lt;/p&gt; 
 &lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/docker.png" width="400" /&gt; &lt;/p&gt; 
 &lt;p&gt;‚Ä¢ September 25, 2023: The &lt;strong&gt;Git&lt;/strong&gt; mode is now available, enabling the programmer &lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/visualizer/static/figures/programmer.png" height="20" /&gt; to utilize Git for version control. To enable this feature, simply set &lt;code&gt;"git_management"&lt;/code&gt; to &lt;code&gt;"True"&lt;/code&gt; in &lt;code&gt;ChatChainConfig.json&lt;/code&gt;. See &lt;a href="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/wiki.md#git-mode"&gt;guide&lt;/a&gt;.&lt;/p&gt; 
 &lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/github.png" width="600" /&gt; &lt;/p&gt; 
 &lt;p&gt;‚Ä¢ September 20, 2023: The &lt;strong&gt;Human-Agent-Interaction&lt;/strong&gt; mode is now available! You can get involved with the ChatDev team by playing the role of reviewer &lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/visualizer/static/figures/reviewer.png" height="20" /&gt; and making suggestions to the programmer &lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/visualizer/static/figures/programmer.png" height="20" /&gt;; try &lt;code&gt;python3 run.py --task [description_of_your_idea] --config "Human"&lt;/code&gt;. See &lt;a href="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/wiki.md#human-agent-interaction"&gt;guide&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/WareHouse/Gomoku_HumanAgentInteraction_20230920135038"&gt;example&lt;/a&gt;.&lt;/p&gt; 
 &lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/Human_intro.png" width="600" /&gt; &lt;/p&gt; 
 &lt;p&gt;‚Ä¢ September 1, 2023: The &lt;strong&gt;Art&lt;/strong&gt; mode is available now! You can activate the designer agent &lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/visualizer/static/figures/designer.png" height="20" /&gt; to generate images used in the software; try &lt;code&gt;python3 run.py --task [description_of_your_idea] --config "Art"&lt;/code&gt;. See &lt;a href="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/wiki.md#art"&gt;guide&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/WareHouse/gomokugameArtExample_THUNLP_20230831122822"&gt;example&lt;/a&gt;.&lt;/p&gt; 
 &lt;p&gt;‚Ä¢ August 28, 2023: The system is publicly available.&lt;/p&gt; 
 &lt;p&gt;‚Ä¢ August 17, 2023: The v1.0.0 version was ready for release.&lt;/p&gt; 
 &lt;p&gt;‚Ä¢ July 30, 2023: Users can customize ChatChain, Phasea and Role settings. Additionally, both online Log mode and replay mode are now supported.&lt;/p&gt; 
 &lt;p&gt;‚Ä¢ July 16, 2023: The &lt;a href="https://arxiv.org/abs/2307.07924"&gt;preprint paper&lt;/a&gt; associated with this project was published.&lt;/p&gt; 
 &lt;p&gt;‚Ä¢ June 30, 2023: The initial version of the ChatDev repository was released.&lt;/p&gt; 
&lt;/details&gt; 
&lt;h2&gt;üöÄ Quick Start&lt;/h2&gt; 
&lt;h3&gt;üìã Prerequisites&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;OS&lt;/strong&gt;: macOS / Linux / WSL / Windows&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Python&lt;/strong&gt;: 3.12+&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Node.js&lt;/strong&gt;: 18+&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Package Manager&lt;/strong&gt;: &lt;a href="https://docs.astral.sh/uv/"&gt;uv&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üì¶ Installation&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Backend Dependencies&lt;/strong&gt; (Python managed by &lt;code&gt;uv&lt;/code&gt;):&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;uv sync
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Frontend Dependencies&lt;/strong&gt; (Vite + Vue 3):&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;cd frontend &amp;amp;&amp;amp; npm install
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;‚ö°Ô∏è Run the Application&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Start Backend&lt;/strong&gt; :&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;# Run from the project root
uv run python server_main.py --port 6400 --reload
&lt;/code&gt;&lt;/pre&gt; 
  &lt;blockquote&gt; 
   &lt;p&gt;Remove &lt;code&gt;--reload&lt;/code&gt; if output files (e.g., GameDev) trigger restarts, which interrupts tasks and loses progress.&lt;/p&gt; 
  &lt;/blockquote&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Start Frontend&lt;/strong&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;cd frontend
VITE_API_BASE_URL=http://localhost:6400 npm run dev
&lt;/code&gt;&lt;/pre&gt; 
  &lt;blockquote&gt; 
   &lt;p&gt;Then access the Web Console at &lt;strong&gt;&lt;a href="http://localhost:5173"&gt;http://localhost:5173&lt;/a&gt;&lt;/strong&gt;.&lt;/p&gt; 
  &lt;/blockquote&gt; 
  &lt;blockquote&gt; 
   &lt;p&gt;&lt;strong&gt;üí° Tip&lt;/strong&gt;: If the frontend fails to connect to the backend, the default port &lt;code&gt;6400&lt;/code&gt; may already be occupied. Please switch both services to an available port, for example:&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Backend&lt;/strong&gt;: start with &lt;code&gt;--port 6401&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;Frontend&lt;/strong&gt;: set &lt;code&gt;VITE_API_BASE_URL=http://localhost:6401&lt;/code&gt;&lt;/li&gt; 
   &lt;/ul&gt; 
  &lt;/blockquote&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;üîë Configuration&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Environment Variables&lt;/strong&gt;: Create a &lt;code&gt;.env&lt;/code&gt; file in the project root.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Model Keys&lt;/strong&gt;: Set &lt;code&gt;API_KEY&lt;/code&gt; and &lt;code&gt;BASE_URL&lt;/code&gt; in &lt;code&gt;.env&lt;/code&gt; for your LLM provider.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;YAML placeholders&lt;/strong&gt;: Use &lt;code&gt;${VAR}&lt;/code&gt;Ôºàe.g., &lt;code&gt;${API_KEY}&lt;/code&gt;Ôºâin configuration files to reference these variables.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üí° How to Use&lt;/h2&gt; 
&lt;h3&gt;üñ•Ô∏è Web Console&lt;/h3&gt; 
&lt;p&gt;The DevAll interface provides a seamless experience for both construction and execution&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Tutorial&lt;/strong&gt;: Comprehensive step-by-step guides and documentation integrated directly into the platform to help you get started quickly.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/tutorial-en.png" /&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Workflow&lt;/strong&gt;: A visual canvas to design your multi-agent systems. Configure node parameters, define context flows, and orchestrate complex agent interactions with drag-and-drop ease.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/workflow.gif" /&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Launch&lt;/strong&gt;: Initiate workflows, monitor real-time logs, inspect intermediate artifacts, and provide human-in-the-loop feedback.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/launch.gif" /&gt; 
&lt;h3&gt;üß∞ Python SDK&lt;/h3&gt; 
&lt;p&gt;For automation and batch processing, use our lightweight Python SDK to execute workflows programmatically and retrieve results directly.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from runtime.sdk import run_workflow

# Execute a workflow and get the final node message
result = run_workflow(
    yaml_file="yaml_instance/demo.yaml",
    task_prompt="Summarize the attached document in one sentence.",
    attachments=["/path/to/document.pdf"],
    variables={"API_KEY": "sk-xxxx"} # Override .env variables if needed
)

if result.final_message:
    print(f"Output: {result.final_message.text_content()}")
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;a id="developers"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;‚öôÔ∏è For Developers&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;For secondary development and extensions, please proceed with this section.&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Extend DevAll with new nodes, providers, and tools. The project is organized into a modular structure:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Core Systems&lt;/strong&gt;: &lt;code&gt;server/&lt;/code&gt; hosts the FastAPI backend, while &lt;code&gt;runtime/&lt;/code&gt; manages agent abstraction and tool execution.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Orchestration&lt;/strong&gt;: &lt;code&gt;workflow/&lt;/code&gt; handles the multi-agent logic, driven by configurations in &lt;code&gt;entity/&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Frontend&lt;/strong&gt;: &lt;code&gt;frontend/&lt;/code&gt; contains the Vue 3 Web Console.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Extensibility&lt;/strong&gt;: &lt;code&gt;functions/&lt;/code&gt; is the place for custom Python tools.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Relevant reference documentation:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Getting Started&lt;/strong&gt;: &lt;a href="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/docs/user_guide/en/index.md"&gt;Start Guide&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Core Modules&lt;/strong&gt;: &lt;a href="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/docs/user_guide/en/workflow_authoring.md"&gt;Workflow Authoring&lt;/a&gt;, &lt;a href="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/docs/user_guide/en/modules/memory.md"&gt;Memory&lt;/a&gt;, and &lt;a href="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/docs/user_guide/en/modules/tooling/index.md"&gt;Tooling&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üåü Featured Workflows&lt;/h2&gt; 
&lt;p&gt;We provide robust, out-of-the-box templates for common scenarios. All runnable workflow configs are located in &lt;code&gt;yaml_instance/&lt;/code&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Demos&lt;/strong&gt;: Files named &lt;code&gt;demo_*.yaml&lt;/code&gt; showcase specific features or modules.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Implementations&lt;/strong&gt;: Files named directly (e.g., &lt;code&gt;ChatDev_v1.yaml&lt;/code&gt;) are full in-house or recreated workflows. As follows:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üìã Workflow Collection&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Category&lt;/th&gt; 
   &lt;th align="left"&gt;Workflow&lt;/th&gt; 
   &lt;th align="left"&gt;Case&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;üìà Data Visualization&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;data_visualization_basic.yaml&lt;/code&gt;&lt;br /&gt;&lt;code&gt;data_visualization_enhanced.yaml&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/cases/data_analysis/data_analysis.gif" width="100%" /&gt;&lt;br /&gt;Prompt: &lt;em&gt;"Create 4‚Äì6 high-quality PNG charts for my large real-estate transactions dataset."&lt;/em&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;üõ†Ô∏è 3D Generation&lt;/strong&gt;&lt;br /&gt;&lt;em&gt;(Requires &lt;a href="https://www.blender.org/"&gt;Blender&lt;/a&gt; &amp;amp; &lt;a href="https://github.com/ahujasid/blender-mcp"&gt;blender-mcp&lt;/a&gt;)&lt;/em&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;blender_3d_builder_simple.yaml&lt;/code&gt;&lt;br /&gt;&lt;code&gt;blender_3d_builder_hub.yaml&lt;/code&gt;&lt;br /&gt;&lt;code&gt;blender_scientific_illustration.yaml&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/cases/3d_generation/3d.gif" width="100%" /&gt;&lt;br /&gt;Prompt: &lt;em&gt;"Please build a Christmas tree."&lt;/em&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;üéÆ Game Dev&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;GameDev_v1.yaml&lt;/code&gt;&lt;br /&gt;&lt;code&gt;ChatDev_v1.yaml&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/cases/game_development/game.gif" width="100%" /&gt;&lt;br /&gt;Prompt: &lt;em&gt;"Please help me design and develop a Tank Battle game."&lt;/em&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;üìö Deep Research&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;deep_research_v1.yaml&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/cases/deep_research/deep_research.gif" width="85%" /&gt;&lt;br /&gt;Prompt: &lt;em&gt;"Research about recent advances in the field of LLM-based agent RL"&lt;/em&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;üéì Teach Video&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;teach_video.yaml&lt;/code&gt; (Please run command &lt;code&gt;uv add manim&lt;/code&gt; before running this workflow)&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/cases/video_generation/video.gif" width="140%" /&gt;&lt;br /&gt;Prompt: &lt;em&gt;"ËÆ≤‰∏Ä‰∏ã‰ªÄ‰πàÊòØÂá∏‰ºòÂåñ"&lt;/em&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;hr /&gt; 
&lt;h3&gt;üí° Usage Guide&lt;/h3&gt; 
&lt;p&gt;For those implementations, you can use the &lt;strong&gt;Launch&lt;/strong&gt; tab to execute them.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Select&lt;/strong&gt;: Choose a workflow in the &lt;strong&gt;Launch&lt;/strong&gt; tab.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Upload&lt;/strong&gt;: Upload necessary files (e.g., &lt;code&gt;.csv&lt;/code&gt; for data analysis) if required.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Prompt&lt;/strong&gt;: Enter your request (e.g., &lt;em&gt;"Visualize the sales trends"&lt;/em&gt; or &lt;em&gt;"Design a snake game"&lt;/em&gt;).&lt;/li&gt; 
&lt;/ol&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ü§ù Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome contributions from the community! Whether you're fixing bugs, adding new workflow templates, or sharing high-quality cases/artifacts produced by DevAll, your help is much appreciated. Feel free to contribute by submitting &lt;strong&gt;Issues&lt;/strong&gt; or &lt;strong&gt;Pull Requests&lt;/strong&gt;.&lt;/p&gt; 
&lt;p&gt;By contributing to DevAll, you'll be recognized in our &lt;strong&gt;Contributors&lt;/strong&gt; list below. Check out our &lt;a href="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/#developers"&gt;Developer Guide&lt;/a&gt; to get started!&lt;/p&gt; 
&lt;h3&gt;üë• Contributors&lt;/h3&gt; 
&lt;h4&gt;Primary Contributors&lt;/h4&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/NA-Wen"&gt;&lt;img src="https://github.com/NA-Wen.png?size=100" width="64px;" alt="" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;NA-Wen&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/zxrys"&gt;&lt;img src="https://github.com/zxrys.png?size=100" width="64px;" alt="" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;zxrys&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/swugi"&gt;&lt;img src="https://github.com/swugi.png?size=100" width="64px;" alt="" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;swugi&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/huatl98"&gt;&lt;img src="https://github.com/huatl98.png?size=100" width="64px;" alt="" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;huatl98&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h4&gt;Contributors&lt;/h4&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/shiowen"&gt;&lt;img src="https://github.com/shiowen.png?size=100" width="64px;" alt="" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;shiowen&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/kilo2127"&gt;&lt;img src="https://github.com/kilo2127.png?size=100" width="64px;" alt="" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;kilo2127&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/AckerlyLau"&gt;&lt;img src="https://github.com/AckerlyLau.png?size=100" width="64px;" alt="" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;AckerlyLau&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h2&gt;ü§ù Acknowledgments&lt;/h2&gt; 
&lt;p&gt;&lt;a href="http://nlp.csai.tsinghua.edu.cn/"&gt;&lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/thunlp.png" height="50pt" /&gt;&lt;/a&gt;&amp;nbsp;&amp;nbsp; &lt;a href="https://modelbest.cn/"&gt;&lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/modelbest.png" height="50pt" /&gt;&lt;/a&gt;&amp;nbsp;&amp;nbsp; &lt;a href="https://github.com/OpenBMB/AgentVerse/"&gt;&lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/agentverse.png" height="50pt" /&gt;&lt;/a&gt;&amp;nbsp;&amp;nbsp; &lt;a href="https://github.com/OpenBMB/RepoAgent"&gt;&lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/repoagent.png" height="50pt" /&gt;&lt;/a&gt; &lt;a href="https://app.commanddash.io/agent?github=https://github.com/OpenBMB/ChatDev"&gt;&lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/CommandDash.png" height="50pt" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/www.teachmaster.cn"&gt;&lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/teachmaster.png" height="50pt" /&gt;&lt;/a&gt; &lt;a href="https://github.com/OpenBMB/AppCopilot"&gt;&lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/appcopilot.png" height="50pt" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üîé Citation&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;@article{chatdev,
    title = {ChatDev: Communicative Agents for Software Development},
    author = {Chen Qian and Wei Liu and Hongzhang Liu and Nuo Chen and Yufan Dang and Jiahao Li and Cheng Yang and Weize Chen and Yusheng Su and Xin Cong and Juyuan Xu and Dahai Li and Zhiyuan Liu and Maosong Sun},
    journal = {arXiv preprint arXiv:2307.07924},
    url = {https://arxiv.org/abs/2307.07924},
    year = {2023}
}

@article{colearning,
    title = {Experiential Co-Learning of Software-Developing Agents},
    author = {Chen Qian and Yufan Dang and Jiahao Li and Wei Liu and Zihao Xie and Yifei Wang and Weize Chen and Cheng Yang and Xin Cong and Xiaoyin Che and Zhiyuan Liu and Maosong Sun},
    journal = {arXiv preprint arXiv:2312.17025},
    url = {https://arxiv.org/abs/2312.17025},
    year = {2023}
}

@article{macnet,
    title={Scaling Large-Language-Model-based Multi-Agent Collaboration},
    author={Chen Qian and Zihao Xie and Yifei Wang and Wei Liu and Yufan Dang and Zhuoyun Du and Weize Chen and Cheng Yang and Zhiyuan Liu and Maosong Sun}
    journal={arXiv preprint arXiv:2406.07155},
    url = {https://arxiv.org/abs/2406.07155},
    year={2024}
}

@article{iagents,
    title={Autonomous Agents for Collaborative Task under Information Asymmetry},
    author={Wei Liu and Chenxi Wang and Yifei Wang and Zihao Xie and Rennai Qiu and Yufan Dnag and Zhuoyun Du and Weize Chen and Cheng Yang and Chen Qian},
    journal={arXiv preprint arXiv:2406.14928},
    url = {https://arxiv.org/abs/2406.14928},
    year={2024}
}

@article{puppeteer,
      title={Multi-Agent Collaboration via Evolving Orchestration}, 
      author={Yufan Dang and Chen Qian and Xueheng Luo and Jingru Fan and Zihao Xie and Ruijie Shi and Weize Chen and Cheng Yang and Xiaoyin Che and Ye Tian and Xuantang Xiong and Lei Han and Zhiyuan Liu and Maosong Sun},
      journal={arXiv preprint arXiv:2505.19591},
      url={https://arxiv.org/abs/2505.19591},
      year={2025}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;üì¨ Contact&lt;/h2&gt; 
&lt;p&gt;If you have any questions, feedback, or would like to get in touch, please feel free to reach out to us via email at &lt;a href="mailto:qianc62@gmail.com"&gt;qianc62@gmail.com&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>bytedance/UI-TARS-desktop</title>
      <link>https://github.com/bytedance/UI-TARS-desktop</link>
      <description>&lt;p&gt;The Open-Source Multimodal AI Agent Stack: Connecting Cutting-Edge AI Models and Agent Infra&lt;/p&gt;&lt;hr&gt;&lt;picture&gt; 
 &lt;img alt="Agent TARS Banner" src="https://raw.githubusercontent.com/bytedance/UI-TARS-desktop/main/images/tars.png" /&gt; 
&lt;/picture&gt; 
&lt;br /&gt; 
&lt;h2&gt;Introduction&lt;/h2&gt; 
&lt;p&gt;English | &lt;a href="https://raw.githubusercontent.com/bytedance/UI-TARS-desktop/main/README.zh-CN.md"&gt;ÁÆÄ‰Ωì‰∏≠Êñá&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://trendshift.io/repositories/13584"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/13584" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;b&gt;TARS&lt;sup&gt;*&lt;/sup&gt;&lt;/b&gt; is a Multimodal AI Agent stack, currently shipping two projects: &lt;a href="https://raw.githubusercontent.com/bytedance/UI-TARS-desktop/main/#agent-tars"&gt;Agent TARS&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/bytedance/UI-TARS-desktop/main/#ui-tars-desktop"&gt;UI-TARS-desktop&lt;/a&gt;:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th width="50%" align="center"&gt;&lt;a href="https://raw.githubusercontent.com/bytedance/UI-TARS-desktop/main/#agent-tars"&gt;Agent TARS&lt;/a&gt;&lt;/th&gt; 
   &lt;th width="50%" align="center"&gt;&lt;a href="https://raw.githubusercontent.com/bytedance/UI-TARS-desktop/main/#ui-tars-desktop"&gt;UI-TARS-desktop&lt;/a&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt; 
    &lt;video src="https://github.com/user-attachments/assets/c9489936-afdc-4d12-adda-d4b90d2a869d" width="50%"&gt;&lt;/video&gt; &lt;/td&gt; 
   &lt;td align="center"&gt; 
    &lt;video src="https://github.com/user-attachments/assets/e0914ce9-ad33-494b-bdec-0c25c1b01a27" width="50%"&gt;&lt;/video&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt; &lt;b&gt;Agent TARS&lt;/b&gt; is a general multimodal AI Agent stack, it brings the power of GUI Agent and Vision into your terminal, computer, browser and product. &lt;br /&gt; &lt;br /&gt; It primarily ships with a &lt;a href="https://agent-tars.com/guide/basic/cli.html" target="_blank"&gt;CLI&lt;/a&gt; and &lt;a href="https://agent-tars.com/guide/basic/web-ui.html" target="_blank"&gt;Web UI&lt;/a&gt; for usage. It aims to provide a workflow that is closer to human-like task completion through cutting-edge multimodal LLMs and seamless integration with various real-world &lt;a href="https://agent-tars.com/guide/basic/mcp.html" target="_blank"&gt;MCP&lt;/a&gt; tools. &lt;/td&gt; 
   &lt;td align="left"&gt; &lt;b&gt;UI-TARS Desktop&lt;/b&gt; is a desktop application that provides a native GUI Agent based on the &lt;a href="https://github.com/bytedance/UI-TARS" target="_blank"&gt;UI-TARS&lt;/a&gt; model. &lt;br /&gt; &lt;br /&gt; It primarily ships a &lt;a href="https://github.com/bytedance/UI-TARS-desktop/raw/main/docs/quick-start.md#get-model-and-run-local-operator" target="_blank"&gt;local&lt;/a&gt; and &lt;a href="https://github.com/bytedance/UI-TARS-desktop/raw/main/docs/quick-start.md#run-remote-operator" target="_blank"&gt;remote&lt;/a&gt; computer as well as browser operators. &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Table of Contents&lt;/h2&gt; 
&lt;!-- START doctoc generated TOC please keep comment here to allow auto update --&gt; 
&lt;!-- DON'T EDIT THIS SECTION, INSTEAD RE-RUN doctoc TO UPDATE --&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/bytedance/UI-TARS-desktop/main/#news"&gt;News&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/bytedance/UI-TARS-desktop/main/#agent-tars"&gt;Agent TARS&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/bytedance/UI-TARS-desktop/main/#showcase"&gt;Showcase&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/bytedance/UI-TARS-desktop/main/#core-features"&gt;Core Features&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/bytedance/UI-TARS-desktop/main/#quick-start"&gt;Quick Start&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/bytedance/UI-TARS-desktop/main/#documentation"&gt;Documentation&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/bytedance/UI-TARS-desktop/main/#ui-tars-desktop"&gt;UI-TARS Desktop&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/bytedance/UI-TARS-desktop/main/#showcase-1"&gt;Showcase&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/bytedance/UI-TARS-desktop/main/#features"&gt;Features&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/bytedance/UI-TARS-desktop/main/#quick-start-1"&gt;Quick Start&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/bytedance/UI-TARS-desktop/main/#contributing"&gt;Contributing&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/bytedance/UI-TARS-desktop/main/#license"&gt;License&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/bytedance/UI-TARS-desktop/main/#citation"&gt;Citation&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;!-- END doctoc generated TOC please keep comment here to allow auto update --&gt; 
&lt;h2&gt;News&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;[2025-11-05]&lt;/strong&gt; üéâ We're excited to announce the release of &lt;a href="https://github.com/bytedance/UI-TARS-desktop/releases/tag/v0.3.0"&gt;Agent TARS CLI v0.3.0&lt;/a&gt;! This version brings streaming support for multiple tools (shell commands, multi-file structured display), runtime settings with timing statistics for tool calls and deep thinking, Event Stream Viewer for data flow tracking and debugging. Additionally, it features exclusive support for &lt;a href="https://github.com/agent-infra/sandbox"&gt;AIO agent Sandbox&lt;/a&gt; as isolated all-in-one tools execution environment.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;[2025-06-25]&lt;/strong&gt; We released a Agent TARS Beta and Agent TARS CLI - &lt;a href="https://agent-tars.com/blog/2025-06-25-introducing-agent-tars-beta.html"&gt;Introducing Agent TARS Beta&lt;/a&gt;, a multimodal AI agent that aims to explore a work form that is closer to human-like task completion through rich multimodal capabilities (such as GUI Agent, Vision) and seamless integration with various real-world tools.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;[2025-06-12]&lt;/strong&gt; - üéÅ We are thrilled to announce the release of UI-TARS Desktop v0.2.0! This update introduces two powerful new features: &lt;strong&gt;Remote Computer Operator&lt;/strong&gt; and &lt;strong&gt;Remote Browser Operator&lt;/strong&gt;‚Äîboth completely free. No configuration required: simply click to remotely control any computer or browser, and experience a new level of convenience and intelligence.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;[2025-04-17]&lt;/strong&gt; - üéâ We're thrilled to announce the release of new UI-TARS Desktop application v0.1.0, featuring a redesigned Agent UI. The application enhances the computer using experience, introduces new browser operation features, and supports &lt;a href="https://seed-tars.com/1.5"&gt;the advanced UI-TARS-1.5 model&lt;/a&gt; for improved performance and precise control.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;[2025-02-20]&lt;/strong&gt; - üì¶ Introduced &lt;a href="https://raw.githubusercontent.com/bytedance/UI-TARS-desktop/main/docs/sdk.md"&gt;UI TARS SDK&lt;/a&gt;, is a powerful cross-platform toolkit for building GUI automation agents.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;[2025-01-23]&lt;/strong&gt; - üöÄ We updated the &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/bytedance/UI-TARS-desktop/main/docs/deployment.md#cloud-deployment"&gt;Cloud Deployment&lt;/a&gt;&lt;/strong&gt; section in the ‰∏≠ÊñáÁâà: &lt;a href="https://bytedance.sg.larkoffice.com/docx/TCcudYwyIox5vyxiSDLlgIsTgWf#U94rdCxzBoJMLex38NPlHL21gNb"&gt;GUIÊ®°ÂûãÈÉ®ÁΩ≤ÊïôÁ®ã&lt;/a&gt; with new information related to the ModelScope platform. You can now use the ModelScope platform for deployment.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;br /&gt; 
&lt;h2&gt;Agent TARS&lt;/h2&gt; 
&lt;p&gt; &lt;a href="https://npmjs.com/package/@agent-tars/cli?activeTab=readme"&gt;&lt;img src="https://img.shields.io/npm/v/@agent-tars/cli?style=for-the-badge&amp;amp;colorA=1a1a2e&amp;amp;colorB=3B82F6&amp;amp;logo=npm&amp;amp;logoColor=white" alt="npm version" /&gt;&lt;/a&gt; &lt;a href="https://npmcharts.com/compare/@agent-tars/cli?minimal=true"&gt;&lt;img src="https://img.shields.io/npm/dm/@agent-tars/cli.svg?style=for-the-badge&amp;amp;colorA=1a1a2e&amp;amp;colorB=0EA5E9&amp;amp;logo=npm&amp;amp;logoColor=white" alt="downloads" /&gt;&lt;/a&gt; &lt;a href="https://nodejs.org/en/about/previous-releases"&gt;&lt;img src="https://img.shields.io/node/v/@agent-tars/cli.svg?style=for-the-badge&amp;amp;colorA=1a1a2e&amp;amp;colorB=06B6D4&amp;amp;logo=node.js&amp;amp;logoColor=white" alt="node version" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/HnKcSBgTVx"&gt;&lt;img src="https://img.shields.io/badge/Discord-Join%20Community-5865F2?style=for-the-badge&amp;amp;logo=discord&amp;amp;logoColor=white" alt="Discord Community" /&gt;&lt;/a&gt; &lt;a href="https://twitter.com/agent_tars"&gt;&lt;img src="https://img.shields.io/badge/Twitter-Follow%20%40agent__tars-1DA1F2?style=for-the-badge&amp;amp;logo=twitter&amp;amp;logoColor=white" alt="Official Twitter" /&gt;&lt;/a&gt; &lt;a href="https://applink.larkoffice.com/client/chat/chatter/add_by_link?link_token=deen76f4-ea3c-4964-93a3-78f126f39651"&gt;&lt;img src="https://img.shields.io/badge/È£û‰π¶Áæ§-Âä†ÂÖ•‰∫§ÊµÅÁæ§-00D4AA?style=for-the-badge&amp;amp;logo=lark&amp;amp;logoColor=white" alt="È£û‰π¶‰∫§ÊµÅÁæ§" /&gt;&lt;/a&gt; &lt;a href="https://deepwiki.com/bytedance/UI-TARS-desktop"&gt;&lt;img src="https://img.shields.io/badge/DeepWiki-Ask%20AI-8B5CF6?style=for-the-badge&amp;amp;logo=gitbook&amp;amp;logoColor=white" alt="Ask DeepWiki" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p&gt;&lt;b&gt;Agent TARS&lt;/b&gt; is a general multimodal AI Agent stack, it brings the power of GUI Agent and Vision into your terminal, computer, browser and product. &lt;br /&gt; &lt;br /&gt; It primarily ships with a &lt;a href="https://agent-tars.com/guide/basic/cli.html" target="_blank"&gt;CLI&lt;/a&gt; and &lt;a href="https://agent-tars.com/guide/basic/web-ui.html" target="_blank"&gt;Web UI&lt;/a&gt; for usage. It aims to provide a workflow that is closer to human-like task completion through cutting-edge multimodal LLMs and seamless integration with various real-world &lt;a href="https://agent-tars.com/guide/basic/mcp.html" target="_blank"&gt;MCP&lt;/a&gt; tools.&lt;/p&gt; 
&lt;h3&gt;Showcase&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;Please help me book the earliest flight from San Jose to New York on September 1st and the last return flight on September 6th on Priceline
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/772b0eef-aef7-4ab9-8cb0-9611820539d8"&gt;https://github.com/user-attachments/assets/772b0eef-aef7-4ab9-8cb0-9611820539d8&lt;/a&gt;&lt;/p&gt; 
&lt;br /&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th width="50%" align="center"&gt;Booking Hotel&lt;/th&gt; 
   &lt;th width="50%" align="center"&gt;Generate Chart with extra MCP Servers&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt; 
    &lt;video src="https://github.com/user-attachments/assets/c9489936-afdc-4d12-adda-d4b90d2a869d" width="50%"&gt;&lt;/video&gt; &lt;/td&gt; 
   &lt;td align="center"&gt; 
    &lt;video src="https://github.com/user-attachments/assets/a9fd72d0-01bb-4233-aa27-ca95194bbce9" width="50%"&gt;&lt;/video&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt; &lt;b&gt;Instruction:&lt;/b&gt; &lt;i&gt;I am in Los Angeles from September 1st to September 6th, with a budget of $5,000. Please help me book a Ritz-Carlton hotel closest to the airport on booking.com and compile a transportation guide for me&lt;/i&gt; &lt;/td&gt; 
   &lt;td align="left"&gt; &lt;b&gt;Instruction:&lt;/b&gt; &lt;i&gt;Draw me a chart of Hangzhou's weather for one month&lt;/i&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;For more use cases, please check out &lt;a href="https://github.com/bytedance/UI-TARS-desktop/issues/842"&gt;#842&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Core Features&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;üñ±Ô∏è &lt;strong&gt;One-Click Out-of-the-box CLI&lt;/strong&gt; - Supports both &lt;strong&gt;headful&lt;/strong&gt; &lt;a href="https://agent-tars.com/guide/basic/web-ui.html"&gt;Web UI&lt;/a&gt; and &lt;strong&gt;headless&lt;/strong&gt; &lt;a href="https://agent-tars.com/guide/advanced/server.html"&gt;server&lt;/a&gt;) &lt;a href="https://agent-tars.com/guide/basic/cli.html"&gt;execution&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;üåê &lt;strong&gt;Hybrid Browser Agent&lt;/strong&gt; - Control browsers using &lt;a href="https://agent-tars.com/guide/basic/browser.html#visual-grounding"&gt;GUI Agent&lt;/a&gt;, &lt;a href="https://agent-tars.com/guide/basic/browser.html#dom"&gt;DOM&lt;/a&gt;, or a hybrid strategy.&lt;/li&gt; 
 &lt;li&gt;üîÑ &lt;strong&gt;Event Stream&lt;/strong&gt; - Protocol-driven Event Stream drives &lt;a href="https://agent-tars.com/beta#context-engineering"&gt;Context Engineering&lt;/a&gt; and &lt;a href="https://agent-tars.com/blog/2025-06-25-introducing-agent-tars-beta.html#easy-to-build-applications"&gt;Agent UI&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;üß∞ &lt;strong&gt;MCP Integration&lt;/strong&gt; - The kernel is built on MCP and also supports mounting &lt;a href="https://agent-tars.com/guide/basic/mcp.html"&gt;MCP Servers&lt;/a&gt; to connect to real-world tools.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Quick Start&lt;/h3&gt; 
&lt;img alt="Agent TARS CLI" src="https://agent-tars.com/agent-tars-cli.png" /&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Launch with `npx`.
npx @agent-tars/cli@latest

# Install globally, required Node.js &amp;gt;= 22
npm install @agent-tars/cli@latest -g

# Run with your preferred model provider
agent-tars --provider volcengine --model doubao-1-5-thinking-vision-pro-250428 --apiKey your-api-key
agent-tars --provider anthropic --model claude-3-7-sonnet-latest --apiKey your-api-key
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Visit the comprehensive &lt;a href="https://agent-tars.com/guide/get-started/quick-start.html"&gt;Quick Start&lt;/a&gt; guide for detailed setup instructions.&lt;/p&gt; 
&lt;h3&gt;Documentation&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;üåü &lt;strong&gt;Explore Agent TARS Universe&lt;/strong&gt; üåü&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th width="20%" align="center"&gt;Category&lt;/th&gt; 
   &lt;th width="30%" align="center"&gt;Resource Link&lt;/th&gt; 
   &lt;th width="50%" align="left"&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;üè† &lt;strong&gt;Central Hub&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="center"&gt; &lt;a href="https://agent-tars.com"&gt; &lt;img src="https://img.shields.io/badge/Visit-Website-4F46E5?style=for-the-badge&amp;amp;logo=globe&amp;amp;logoColor=white" alt="Website" /&gt; &lt;/a&gt; &lt;/td&gt; 
   &lt;td align="left"&gt;Your gateway to Agent TARS ecosystem&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;üìö &lt;strong&gt;Quick Start&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="center"&gt; &lt;a href="https://agent-tars.com/guide/get-started/quick-start.html"&gt; &lt;img src="https://img.shields.io/badge/Get-Started-06B6D4?style=for-the-badge&amp;amp;logo=rocket&amp;amp;logoColor=white" alt="Quick Start" /&gt; &lt;/a&gt; &lt;/td&gt; 
   &lt;td align="left"&gt;Zero to hero in 5 minutes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;üöÄ &lt;strong&gt;What's New&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="center"&gt; &lt;a href="https://agent-tars.com/beta"&gt; &lt;img src="https://img.shields.io/badge/Read-Blog-F59E0B?style=for-the-badge&amp;amp;logo=rss&amp;amp;logoColor=white" alt="Blog" /&gt; &lt;/a&gt; &lt;/td&gt; 
   &lt;td align="left"&gt;Discover cutting-edge features &amp;amp; vision&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;üõ†Ô∏è &lt;strong&gt;Developer Zone&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="center"&gt; &lt;a href="https://agent-tars.com/guide/get-started/introduction.html"&gt; &lt;img src="https://img.shields.io/badge/View-Docs-10B981?style=for-the-badge&amp;amp;logo=gitbook&amp;amp;logoColor=white" alt="Docs" /&gt; &lt;/a&gt; &lt;/td&gt; 
   &lt;td align="left"&gt;Master every command &amp;amp; features&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;üéØ &lt;strong&gt;Showcase&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="center"&gt; &lt;a href="https://github.com/bytedance/UI-TARS-desktop/issues/842"&gt; &lt;img src="https://img.shields.io/badge/View-Examples-8B5CF6?style=for-the-badge&amp;amp;logo=github&amp;amp;logoColor=white" alt="Examples" /&gt; &lt;/a&gt; &lt;/td&gt; 
   &lt;td align="left"&gt;View use cases built by the official and community&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;üîß &lt;strong&gt;Reference&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="center"&gt; &lt;a href="https://agent-tars.com/api/"&gt; &lt;img src="https://img.shields.io/badge/API-Reference-EF4444?style=for-the-badge&amp;amp;logo=book&amp;amp;logoColor=white" alt="API" /&gt; &lt;/a&gt; &lt;/td&gt; 
   &lt;td align="left"&gt;Complete technical reference&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;br /&gt; 
&lt;br /&gt; 
&lt;br /&gt; 
&lt;h2&gt;UI-TARS Desktop&lt;/h2&gt; 
&lt;p align="center"&gt; &lt;img alt="UI-TARS" width="260" src="https://raw.githubusercontent.com/bytedance/UI-TARS-desktop/main/apps/ui-tars/resources/icon.png" /&gt; &lt;/p&gt; 
&lt;p&gt;UI-TARS Desktop is a native GUI agent for your local computer, driven by &lt;a href="https://github.com/bytedance/UI-TARS"&gt;UI-TARS&lt;/a&gt; and Seed-1.5-VL/1.6 series models.&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt; &amp;nbsp;&amp;nbsp; üìë &lt;a href="https://arxiv.org/abs/2501.12326"&gt;Paper&lt;/a&gt; &amp;nbsp;&amp;nbsp; | ü§ó &lt;a href="https://huggingface.co/ByteDance-Seed/UI-TARS-1.5-7B"&gt;Hugging Face Models&lt;/a&gt;&amp;nbsp;&amp;nbsp; | &amp;nbsp;&amp;nbsp;ü´® &lt;a href="https://discord.gg/pTXwYVjfcs"&gt;Discord&lt;/a&gt;&amp;nbsp;&amp;nbsp; | &amp;nbsp;&amp;nbsp;ü§ñ &lt;a href="https://www.modelscope.cn/collections/UI-TARS-bccb56fa1ef640"&gt;ModelScope&lt;/a&gt;&amp;nbsp;&amp;nbsp; &lt;br /&gt; üñ•Ô∏è Desktop Application &amp;nbsp;&amp;nbsp; | &amp;nbsp;&amp;nbsp; üëì &lt;a href="https://github.com/web-infra-dev/midscene"&gt;Midscene (use in browser)&lt;/a&gt; &amp;nbsp;&amp;nbsp; &lt;/p&gt; 
&lt;/div&gt; 
&lt;h3&gt;Showcase&lt;/h3&gt; 
&lt;!-- // FIXME: Choose only two demo, one local computer and one remote computer showcase. --&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="center"&gt;Instruction&lt;/th&gt; 
   &lt;th align="center"&gt;Local Operator&lt;/th&gt; 
   &lt;th align="center"&gt;Remote Operator&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;Please help me open the autosave feature of VS Code and delay AutoSave operations for 500 milliseconds in the VS Code setting.&lt;/td&gt; 
   &lt;td align="center"&gt;
    &lt;video src="https://github.com/user-attachments/assets/e0914ce9-ad33-494b-bdec-0c25c1b01a27" height="300"&gt;&lt;/video&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;
    &lt;video src="https://github.com/user-attachments/assets/01e49b69-7070-46c8-b3e3-2aaaaec71800" height="300"&gt;&lt;/video&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;Could you help me check the latest open issue of the UI-TARS-Desktop project on GitHub?&lt;/td&gt; 
   &lt;td align="center"&gt;
    &lt;video src="https://github.com/user-attachments/assets/3d159f54-d24a-4268-96c0-e149607e9199" height="300"&gt;&lt;/video&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;
    &lt;video src="https://github.com/user-attachments/assets/072fb72d-7394-4bfa-95f5-4736e29f7e58" height="300"&gt;&lt;/video&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Features&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;ü§ñ Natural language control powered by Vision-Language Model&lt;/li&gt; 
 &lt;li&gt;üñ•Ô∏è Screenshot and visual recognition support&lt;/li&gt; 
 &lt;li&gt;üéØ Precise mouse and keyboard control&lt;/li&gt; 
 &lt;li&gt;üíª Cross-platform support (Windows/MacOS/Browser)&lt;/li&gt; 
 &lt;li&gt;üîÑ Real-time feedback and status display&lt;/li&gt; 
 &lt;li&gt;üîê Private and secure - fully local processing&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Quick Start&lt;/h3&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/bytedance/UI-TARS-desktop/main/docs/quick-start.md"&gt;Quick Start&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/bytedance/UI-TARS-desktop/main/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the Apache License 2.0.&lt;/p&gt; 
&lt;h2&gt;Citation&lt;/h2&gt; 
&lt;p&gt;If you find our paper and code useful in your research, please consider giving a star &lt;span&gt;‚≠ê&lt;/span&gt; and citation &lt;span&gt;üìù&lt;/span&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-BibTeX"&gt;@article{qin2025ui,
  title={UI-TARS: Pioneering Automated GUI Interaction with Native Agents},
  author={Qin, Yujia and Ye, Yining and Fang, Junjie and Wang, Haoming and Liang, Shihao and Tian, Shizuo and Zhang, Junda and Li, Jiahao and Li, Yunxin and Huang, Shijue and others},
  journal={arXiv preprint arXiv:2501.12326},
  year={2025}
}
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>anomalyco/opencode</title>
      <link>https://github.com/anomalyco/opencode</link>
      <description>&lt;p&gt;The open source coding agent.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;a href="https://opencode.ai"&gt; 
  &lt;picture&gt; 
   &lt;source srcset="packages/console/app/src/asset/logo-ornate-dark.svg" media="(prefers-color-scheme: dark)" /&gt; 
   &lt;source srcset="packages/console/app/src/asset/logo-ornate-light.svg" media="(prefers-color-scheme: light)" /&gt; 
   &lt;img src="https://raw.githubusercontent.com/anomalyco/opencode/dev/packages/console/app/src/asset/logo-ornate-light.svg?sanitize=true" alt="OpenCode logo" /&gt; 
  &lt;/picture&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt;The open source AI coding agent.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://opencode.ai/discord"&gt;&lt;img alt="Discord" src="https://img.shields.io/discord/1391832426048651334?style=flat-square&amp;amp;label=discord" /&gt;&lt;/a&gt; &lt;a href="https://www.npmjs.com/package/opencode-ai"&gt;&lt;img alt="npm" src="https://img.shields.io/npm/v/opencode-ai?style=flat-square" /&gt;&lt;/a&gt; &lt;a href="https://github.com/anomalyco/opencode/actions/workflows/publish.yml"&gt;&lt;img alt="Build status" src="https://img.shields.io/github/actions/workflow/status/anomalyco/opencode/publish.yml?style=flat-square&amp;amp;branch=dev" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p&gt;&lt;a href="https://opencode.ai"&gt;&lt;img src="https://raw.githubusercontent.com/anomalyco/opencode/dev/packages/web/src/assets/lander/screenshot.png" alt="OpenCode Terminal UI" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h3&gt;Installation&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# YOLO
curl -fsSL https://opencode.ai/install | bash

# Package managers
npm i -g opencode-ai@latest        # or bun/pnpm/yarn
scoop install opencode             # Windows
choco install opencode             # Windows
brew install anomalyco/tap/opencode # macOS and Linux (recommended, always up to date)
brew install opencode              # macOS and Linux (official brew formula, updated less)
paru -S opencode-bin               # Arch Linux
mise use -g opencode               # Any OS
nix run nixpkgs#opencode           # or github:anomalyco/opencode for latest dev branch
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] Remove versions older than 0.1.x before installing.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Desktop App (BETA)&lt;/h3&gt; 
&lt;p&gt;OpenCode is also available as a desktop application. Download directly from the &lt;a href="https://github.com/anomalyco/opencode/releases"&gt;releases page&lt;/a&gt; or &lt;a href="https://opencode.ai/download"&gt;opencode.ai/download&lt;/a&gt;.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Platform&lt;/th&gt; 
   &lt;th&gt;Download&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;macOS (Apple Silicon)&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;opencode-desktop-darwin-aarch64.dmg&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;macOS (Intel)&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;opencode-desktop-darwin-x64.dmg&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Windows&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;opencode-desktop-windows-x64.exe&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;.deb&lt;/code&gt;, &lt;code&gt;.rpm&lt;/code&gt;, or AppImage&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# macOS (Homebrew)
brew install --cask opencode-desktop
# Windows (Scoop)
scoop bucket add extras; scoop install extras/opencode-desktop
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Installation Directory&lt;/h4&gt; 
&lt;p&gt;The install script respects the following priority order for the installation path:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;code&gt;$OPENCODE_INSTALL_DIR&lt;/code&gt; - Custom installation directory&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;$XDG_BIN_DIR&lt;/code&gt; - XDG Base Directory Specification compliant path&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;$HOME/bin&lt;/code&gt; - Standard user binary directory (if exists or can be created)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;$HOME/.opencode/bin&lt;/code&gt; - Default fallback&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Examples
OPENCODE_INSTALL_DIR=/usr/local/bin curl -fsSL https://opencode.ai/install | bash
XDG_BIN_DIR=$HOME/.local/bin curl -fsSL https://opencode.ai/install | bash
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Agents&lt;/h3&gt; 
&lt;p&gt;OpenCode includes two built-in agents you can switch between with the &lt;code&gt;Tab&lt;/code&gt; key.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;build&lt;/strong&gt; - Default, full access agent for development work&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;plan&lt;/strong&gt; - Read-only agent for analysis and code exploration 
  &lt;ul&gt; 
   &lt;li&gt;Denies file edits by default&lt;/li&gt; 
   &lt;li&gt;Asks permission before running bash commands&lt;/li&gt; 
   &lt;li&gt;Ideal for exploring unfamiliar codebases or planning changes&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Also, included is a &lt;strong&gt;general&lt;/strong&gt; subagent for complex searches and multistep tasks. This is used internally and can be invoked using &lt;code&gt;@general&lt;/code&gt; in messages.&lt;/p&gt; 
&lt;p&gt;Learn more about &lt;a href="https://opencode.ai/docs/agents"&gt;agents&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Documentation&lt;/h3&gt; 
&lt;p&gt;For more info on how to configure OpenCode &lt;a href="https://opencode.ai/docs"&gt;&lt;strong&gt;head over to our docs&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Contributing&lt;/h3&gt; 
&lt;p&gt;If you're interested in contributing to OpenCode, please read our &lt;a href="https://raw.githubusercontent.com/anomalyco/opencode/dev/CONTRIBUTING.md"&gt;contributing docs&lt;/a&gt; before submitting a pull request.&lt;/p&gt; 
&lt;h3&gt;Building on OpenCode&lt;/h3&gt; 
&lt;p&gt;If you are working on a project that's related to OpenCode and is using "opencode" as a part of its name; for example, "opencode-dashboard" or "opencode-mobile", please add a note to your README to clarify that it is not built by the OpenCode team and is not affiliated with us in any way.&lt;/p&gt; 
&lt;h3&gt;FAQ&lt;/h3&gt; 
&lt;h4&gt;How is this different from Claude Code?&lt;/h4&gt; 
&lt;p&gt;It's very similar to Claude Code in terms of capability. Here are the key differences:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;100% open source&lt;/li&gt; 
 &lt;li&gt;Not coupled to any provider. Although we recommend the models we provide through &lt;a href="https://opencode.ai/zen"&gt;OpenCode Zen&lt;/a&gt;; OpenCode can be used with Claude, OpenAI, Google or even local models. As models evolve the gaps between them will close and pricing will drop so being provider-agnostic is important.&lt;/li&gt; 
 &lt;li&gt;Out of the box LSP support&lt;/li&gt; 
 &lt;li&gt;A focus on TUI. OpenCode is built by neovim users and the creators of &lt;a href="https://terminal.shop"&gt;terminal.shop&lt;/a&gt;; we are going to push the limits of what's possible in the terminal.&lt;/li&gt; 
 &lt;li&gt;A client/server architecture. This for example can allow OpenCode to run on your computer, while you can drive it remotely from a mobile app. Meaning that the TUI frontend is just one of the possible clients.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;strong&gt;Join our community&lt;/strong&gt; &lt;a href="https://discord.gg/opencode"&gt;Discord&lt;/a&gt; | &lt;a href="https://x.com/opencode"&gt;X.com&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>anthropics/claude-code</title>
      <link>https://github.com/anthropics/claude-code</link>
      <description>&lt;p&gt;Claude Code is an agentic coding tool that lives in your terminal, understands your codebase, and helps you code faster by executing routine tasks, explaining complex code, and handling git workflows - all through natural language commands.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Claude Code&lt;/h1&gt; 
&lt;p&gt;&lt;img src="https://img.shields.io/badge/Node.js-18%2B-brightgreen?style=flat-square" alt="" /&gt; &lt;a href="https://www.npmjs.com/package/@anthropic-ai/claude-code"&gt;&lt;img src="https://img.shields.io/npm/v/@anthropic-ai/claude-code.svg?style=flat-square" alt="npm" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Claude Code is an agentic coding tool that lives in your terminal, understands your codebase, and helps you code faster by executing routine tasks, explaining complex code, and handling git workflows -- all through natural language commands. Use it in your terminal, IDE, or tag @claude on Github.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Learn more in the &lt;a href="https://code.claude.com/docs/en/overview"&gt;official documentation&lt;/a&gt;&lt;/strong&gt;.&lt;/p&gt; 
&lt;img src="https://raw.githubusercontent.com/anthropics/claude-code/main/demo.gif" /&gt; 
&lt;h2&gt;Get started&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] Installation via npm is deprecated. Use one of the recommended methods below.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;For more installation options, uninstall steps, and troubleshooting, see the &lt;a href="https://code.claude.com/docs/en/setup"&gt;setup documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Install Claude Code:&lt;/p&gt; &lt;p&gt;&lt;strong&gt;MacOS/Linux (Recommended):&lt;/strong&gt;&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;curl -fsSL https://claude.ai/install.sh | bash
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&lt;strong&gt;Homebrew (MacOS/Linux):&lt;/strong&gt;&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;brew install --cask claude-code
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&lt;strong&gt;Windows (Recommended):&lt;/strong&gt;&lt;/p&gt; &lt;pre&gt;&lt;code class="language-powershell"&gt;irm https://claude.ai/install.ps1 | iex
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&lt;strong&gt;WinGet (Windows):&lt;/strong&gt;&lt;/p&gt; &lt;pre&gt;&lt;code class="language-powershell"&gt;winget install Anthropic.ClaudeCode
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&lt;strong&gt;NPM (Deprecated):&lt;/strong&gt;&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;npm install -g @anthropic-ai/claude-code
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Navigate to your project directory and run &lt;code&gt;claude&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Plugins&lt;/h2&gt; 
&lt;p&gt;This repository includes several Claude Code plugins that extend functionality with custom commands and agents. See the &lt;a href="https://raw.githubusercontent.com/anthropics/claude-code/main/plugins/README.md"&gt;plugins directory&lt;/a&gt; for detailed documentation on available plugins.&lt;/p&gt; 
&lt;h2&gt;Reporting Bugs&lt;/h2&gt; 
&lt;p&gt;We welcome your feedback. Use the &lt;code&gt;/bug&lt;/code&gt; command to report issues directly within Claude Code, or file a &lt;a href="https://github.com/anthropics/claude-code/issues"&gt;GitHub issue&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Connect on Discord&lt;/h2&gt; 
&lt;p&gt;Join the &lt;a href="https://anthropic.com/discord"&gt;Claude Developers Discord&lt;/a&gt; to connect with other developers using Claude Code. Get help, share feedback, and discuss your projects with the community.&lt;/p&gt; 
&lt;h2&gt;Data collection, usage, and retention&lt;/h2&gt; 
&lt;p&gt;When you use Claude Code, we collect feedback, which includes usage data (such as code acceptance or rejections), associated conversation data, and user feedback submitted via the &lt;code&gt;/bug&lt;/code&gt; command.&lt;/p&gt; 
&lt;h3&gt;How we use your data&lt;/h3&gt; 
&lt;p&gt;See our &lt;a href="https://code.claude.com/docs/en/data-usage"&gt;data usage policies&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Privacy safeguards&lt;/h3&gt; 
&lt;p&gt;We have implemented several safeguards to protect your data, including limited retention periods for sensitive information, restricted access to user session data, and clear policies against using feedback for model training.&lt;/p&gt; 
&lt;p&gt;For full details, please review our &lt;a href="https://www.anthropic.com/legal/commercial-terms"&gt;Commercial Terms of Service&lt;/a&gt; and &lt;a href="https://www.anthropic.com/legal/privacy"&gt;Privacy Policy&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>