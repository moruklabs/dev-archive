<rss version="2.0">
  <channel>
    <title>GitHub Go Weekly Trending</title>
    <description>Weekly Trending of Go in GitHub</description>
    <pubDate>Mon, 19 Jan 2026 01:44:11 GMT</pubDate>
    <link>http://mshibanami.github.io/GitHubTrendingRSS</link>
    
    <item>
      <title>kgateway-dev/kgateway</title>
      <link>https://github.com/kgateway-dev/kgateway</link>
      <description>&lt;p&gt;The Cloud-Native API Gateway and AI Gateway&lt;/p&gt;&lt;hr&gt;&lt;h1 align="center"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://raw.githubusercontent.com/kgateway-dev/kgateway.dev/main/static/logo-dark.svg" alt="kgateway" width="400" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://raw.githubusercontent.com/kgateway-dev/kgateway.dev/main/static/logo.svg" alt="kgateway" width="400" /&gt; 
  &lt;img alt="kgateway" src="https://raw.githubusercontent.com/kgateway-dev/kgateway.dev/main/static/logo.svg?sanitize=true" /&gt; 
 &lt;/picture&gt; &lt;br /&gt; The most widely deployed gateway in Kubernetes for microservices and AI agents &lt;/h1&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://github.com/kgateway-dev/kgateway/releases"&gt; &lt;img src="https://img.shields.io/github/v/release/kgateway-dev/kgateway?style=flat&amp;amp;label=Latest%20version" alt="Release" /&gt; &lt;/a&gt; 
 &lt;a href="https://opensource.org/licenses/Apache-2.0"&gt; &lt;img src="https://img.shields.io/badge/License-Apache2.0-brightgreen.svg?style=flat" alt="License: Apache 2.0" /&gt; &lt;/a&gt; 
 &lt;a href="https://github.com/kgateway-dev/kgateway"&gt; &lt;img src="https://img.shields.io/github/stars/kgateway-dev/kgateway.svg?style=flat&amp;amp;logo=github&amp;amp;label=Stars" alt="Stars" /&gt; &lt;/a&gt; 
 &lt;a href="https://www.bestpractices.dev/projects/10534"&gt;&lt;img src="https://www.bestpractices.dev/projects/10534/badge" alt="OpenSSF Best Practices" /&gt;&lt;/a&gt; 
&lt;/div&gt; 
&lt;h2&gt;About kgateway&lt;/h2&gt; 
&lt;p&gt;Kgateway is the most mature and widely deployed gateway in the market today. Built on open source and open standards, &lt;strong&gt;kgateway is a dual control plane that implements the &lt;a href="https://gateway-api.sigs.k8s.io/"&gt;Kubernetes Gateway API&lt;/a&gt; for both &lt;a href="https://github.com/envoyproxy/envoy"&gt;Envoy&lt;/a&gt; and &lt;a href="https://github.com/agentgateway/agentgateway"&gt;agentgateway&lt;/a&gt;&lt;/strong&gt;. This unique architecture enables kgateway to provide unified API connectivity spanning from traditional HTTP/gRPC workloads to advanced AI agent orchestration.&lt;/p&gt; 
&lt;p&gt;With a control plane that scales from lightweight microgateway deployments between services, to massively parallel centralized gateways handling billions of API calls, to advanced AI gateway use cases for safety, security, and governance, kgateway brings omni-directional API connectivity to any cloud and any environment.&lt;/p&gt; 
&lt;h3&gt;Use Cases&lt;/h3&gt; 
&lt;p&gt;Kgateway is designed for:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Advanced Ingress Controller and Next-Gen API Gateway&lt;/strong&gt;: Aggregate web APIs and apply functions like authentication, authorization and rate limiting in one place. Powered by &lt;a href="https://www.envoyproxy.io"&gt;Envoy&lt;/a&gt; or &lt;a href="https://github.com/agentgateway/agentgateway"&gt;agentgateway&lt;/a&gt; and programmed with the &lt;a href="https://gateway-api.sigs.k8s.io/"&gt;Gateway API&lt;/a&gt;, kgateway is a world-leading Cloud Native ingress.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;AI Gateway for LLM Consumption&lt;/strong&gt;: Protect models, tools, agents, and data from inappropriate access. Manage traffic to LLM providers, enrich prompts at a system level, and apply prompt guards for safety and compliance.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Inference Gateway for Generative Models&lt;/strong&gt;: Intelligently route to AI inference workloads in Kubernetes environments utilizing the &lt;a href="https://gateway-api-inference-extension.sigs.k8s.io/"&gt;Inference Extension&lt;/a&gt; project.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Native MCP and Agent-to-Agent Gateway&lt;/strong&gt;: Federate Model Context Protocol tool services and secure agent-to-agent communications with a single scalable endpoint powered by agentgateway.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Hybrid Application Migration&lt;/strong&gt;: Route to backends implemented as microservices, serverless functions or legacy apps. Gradually migrate from legacy code while maintaining existing systems.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Kgateway is feature-rich, fast, and flexible. It excels in function-level routing, supports legacy apps, microservices and serverless, offers robust discovery capabilities, integrates seamlessly with open-source projects, and is designed to support hybrid applications with various technologies, architectures, protocols, and clouds.&lt;/p&gt; 
&lt;h3&gt;History&lt;/h3&gt; 
&lt;p&gt;The project was launched in 2018 as &lt;strong&gt;Gloo&lt;/strong&gt; by Solo.io and has been &lt;a href="https://www.solo.io/blog/announcing-gloo-1-0-a-production-ready-envoy-based-api-gateway"&gt;production-ready since 2019&lt;/a&gt;. Since then, it has steadily evolved to become the most trusted and feature-rich API gateway for Kubernetes, processing billions of API requests for many of the world's biggest companies. Please see &lt;a href="https://github.com/kgateway-dev/kgateway/issues/10363"&gt;the migration plan&lt;/a&gt; for more information about the transition from Gloo to kgateway.&lt;/p&gt; 
&lt;h2&gt;Get involved&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://kgateway.dev/slack/"&gt;Join us on our Slack channel&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://kgateway.dev/docs"&gt;Check out the docs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://kgateway.dev/blog/"&gt;Read the kgateway blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/kgateway-dev/community"&gt;Learn more about the community&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/@kgateway-dev"&gt;Watch a video on our YouTube channel&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Follow us on &lt;a href="https://x.com/kgatewaydev"&gt;X&lt;/a&gt;, &lt;a href="https://bsky.app/profile/kgateway.dev"&gt;Bluesky&lt;/a&gt;, &lt;a href="https://mastodon.social/@kgateway"&gt;Mastodon&lt;/a&gt; or &lt;a href="https://www.linkedin.com/company/kgateway/"&gt;LinkedIn&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing to kgateway&lt;/h2&gt; 
&lt;p&gt;Please refer to &lt;a href="https://raw.githubusercontent.com/kgateway-dev/kgateway/main/devel/contributing/README.md"&gt;devel/contributing/README.md&lt;/a&gt; as a starting point for contributing to the project.&lt;/p&gt; 
&lt;h2&gt;Releasing kgateway&lt;/h2&gt; 
&lt;p&gt;Please refer to &lt;a href="https://raw.githubusercontent.com/kgateway-dev/kgateway/main/devel/contributing/releasing.md"&gt;devel/contributing/releasing.md&lt;/a&gt; as a starting point for understanding releases of the project.&lt;/p&gt; 
&lt;h2&gt;Security&lt;/h2&gt; 
&lt;p&gt;See our &lt;a href="https://raw.githubusercontent.com/kgateway-dev/kgateway/main/SECURITY.md"&gt;SECURITY.md&lt;/a&gt; file for details.&lt;/p&gt; 
&lt;h2&gt;Thanks&lt;/h2&gt; 
&lt;p&gt;Kgateway would not be possible without the valuable open source work of projects in the community. We would like to extend a special thank-you to &lt;a href="https://www.envoyproxy.io"&gt;Envoy&lt;/a&gt; and &lt;a href="https://github.com/agentgateway/agentgateway"&gt;agentgateway&lt;/a&gt;, the two data planes upon which we build our dual control plane architecture.&lt;/p&gt; 
&lt;h2&gt;Contributors&lt;/h2&gt; 
&lt;p&gt;Thanks to all contributors who are helping to make kgateway better!&lt;/p&gt; 
&lt;a href="https://github.com/kgateway-dev/kgateway/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=kgateway-dev/kgateway" /&gt; &lt;/a&gt; 
&lt;h2&gt;Star History&lt;/h2&gt; 
&lt;a href="https://www.star-history.com/#kgateway-dev/kgateway&amp;amp;Date"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://api.star-history.com/svg?repos=kgateway-dev/kgateway&amp;amp;type=Date&amp;amp;theme=dark" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://api.star-history.com/svg?repos=kgateway-dev/kgateway&amp;amp;type=Date" /&gt; 
  &lt;img alt="Star history of kgateway-dev/kgateway over time" src="https://api.star-history.com/svg?repos=kgateway-dev/kgateway&amp;amp;type=Date" /&gt; 
 &lt;/picture&gt; &lt;/a&gt; 
&lt;hr /&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/cncf/artwork/main/other/cncf-sandbox/horizontal/color/cncf-sandbox-horizontal-color.svg?sanitize=true" width="300" alt="Cloud Native Computing Foundation logo" /&gt; 
 &lt;p&gt;kgateway is a &lt;a href="https://cncf.io"&gt;Cloud Native Computing Foundation&lt;/a&gt; sandbox project.&lt;/p&gt; 
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>docker/cli</title>
      <link>https://github.com/docker/cli</link>
      <description>&lt;p&gt;The Docker CLI&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Docker CLI&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://pkg.go.dev/github.com/docker/cli"&gt;&lt;img src="https://pkg.go.dev/badge/github.com/docker/cli" alt="PkgGoDev" /&gt;&lt;/a&gt; &lt;a href="https://github.com/docker/cli/actions?query=workflow%3Abuild"&gt;&lt;img src="https://img.shields.io/github/actions/workflow/status/docker/cli/build.yml?branch=master&amp;amp;label=build&amp;amp;logo=github" alt="Build Status" /&gt;&lt;/a&gt; &lt;a href="https://github.com/docker/cli/actions?query=workflow%3Atest"&gt;&lt;img src="https://img.shields.io/github/actions/workflow/status/docker/cli/test.yml?branch=master&amp;amp;label=test&amp;amp;logo=github" alt="Test Status" /&gt;&lt;/a&gt; &lt;a href="https://goreportcard.com/report/github.com/docker/cli"&gt;&lt;img src="https://goreportcard.com/badge/github.com/docker/cli" alt="Go Report Card" /&gt;&lt;/a&gt; &lt;a href="https://scorecard.dev/viewer/?uri=github.com/docker/cli"&gt;&lt;img src="https://api.scorecard.dev/projects/github.com/docker/cli/badge" alt="OpenSSF Scorecard" /&gt;&lt;/a&gt; &lt;a href="https://codecov.io/gh/docker/cli"&gt;&lt;img src="https://img.shields.io/codecov/c/github/docker/cli?logo=codecov" alt="Codecov" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;About&lt;/h2&gt; 
&lt;p&gt;This repository is the home of the Docker CLI.&lt;/p&gt; 
&lt;h2&gt;Development&lt;/h2&gt; 
&lt;p&gt;&lt;code&gt;docker/cli&lt;/code&gt; is developed using Docker.&lt;/p&gt; 
&lt;p&gt;Build CLI from source:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;docker buildx bake
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Build binaries for all supported platforms:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;docker buildx bake cross
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Build for a specific platform:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;docker buildx bake --set binary.platform=linux/arm64 
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Build dynamic binary for glibc or musl:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;USE_GLIBC=1 docker buildx bake dynbinary 
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Run all linting:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;docker buildx bake lint shellcheck
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Run test:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;docker buildx bake test
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;List all the available targets:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;make help
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;In-container development environment&lt;/h3&gt; 
&lt;p&gt;Start an interactive development environment:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;make -f docker.Makefile shell
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Legal&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Brought to you courtesy of our legal counsel. For more context, see the &lt;a href="https://github.com/docker/cli/raw/master/NOTICE"&gt;NOTICE&lt;/a&gt; document in this repo.&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;Use and transfer of Docker may be subject to certain restrictions by the United States and other governments.&lt;/p&gt; 
&lt;p&gt;It is your responsibility to ensure that your use and/or transfer does not violate applicable laws.&lt;/p&gt; 
&lt;p&gt;For more information, see &lt;a href="https://www.bis.doc.gov"&gt;https://www.bis.doc.gov&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Licensing&lt;/h2&gt; 
&lt;p&gt;docker/cli is licensed under the Apache License, Version 2.0. See &lt;a href="https://github.com/docker/docker/raw/master/LICENSE"&gt;LICENSE&lt;/a&gt; for the full license text.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>juicedata/juicefs</title>
      <link>https://github.com/juicedata/juicefs</link>
      <description>&lt;p&gt;JuiceFS is a distributed POSIX file system built on top of Redis and S3.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt;&lt;a href="https://github.com/juicedata/juicefs"&gt;&lt;img alt="JuiceFS Logo" src="https://raw.githubusercontent.com/juicedata/juicefs/main/docs/en/images/juicefs-logo-new.svg?sanitize=true" width="50%" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/juicedata/juicefs/releases/latest"&gt;&lt;img alt="Latest Stable Release" src="https://img.shields.io/github/v/release/juicedata/juicefs" /&gt;&lt;/a&gt; &lt;a href="https://github.com/juicedata/juicefs/actions/workflows/unittests.yml"&gt;&lt;img alt="GitHub Workflow Status" src="https://img.shields.io/github/actions/workflow/status/juicedata/juicefs/unittests.yml?branch=main&amp;amp;label=Unit%20Testing" /&gt;&lt;/a&gt; &lt;a href="https://github.com/juicedata/juicefs/actions/workflows/integrationtests.yml"&gt;&lt;img alt="GitHub Workflow Status" src="https://img.shields.io/github/actions/workflow/status/juicedata/juicefs/integrationtests.yml?branch=main&amp;amp;label=Integration%20Testing" /&gt;&lt;/a&gt; &lt;a href="https://goreportcard.com/report/github.com/juicedata/juicefs"&gt;&lt;img alt="Go Report" src="https://goreportcard.com/badge/github.com/juicedata/juicefs" /&gt;&lt;/a&gt; &lt;a href="https://juicefs.com/docs/community/introduction"&gt;&lt;img alt="English doc" src="https://img.shields.io/badge/docs-Doc%20Center-brightgreen" /&gt;&lt;/a&gt; &lt;a href="https://go.juicefs.com/slack"&gt;&lt;img alt="Join Slack" src="https://badgen.net/badge/Slack/Join%20JuiceFS/0abd59?icon=slack" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;JuiceFS&lt;/strong&gt; is a high-performance &lt;a href="https://en.wikipedia.org/wiki/POSIX"&gt;POSIX&lt;/a&gt; file system released under Apache License 2.0, particularly designed for the cloud-native environment. The data, stored via JuiceFS, will be persisted in Object Storage &lt;em&gt;(e.g. Amazon S3)&lt;/em&gt;, and the corresponding metadata can be persisted in various compatible database engines such as Redis, MySQL, and TiKV based on the scenarios and requirements.&lt;/p&gt; 
&lt;p&gt;With JuiceFS, massive cloud storage can be directly connected to big data, machine learning, artificial intelligence, and various application platforms in production environments. Without modifying code, the massive cloud storage can be used as efficiently as local storage.&lt;/p&gt; 
&lt;p&gt;üìñ &lt;strong&gt;Document&lt;/strong&gt;: &lt;a href="https://juicefs.com/docs/community/quick_start_guide"&gt;Quick Start Guide&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Highlighted Features&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Fully POSIX-compatible&lt;/strong&gt;: Use as a local file system, seamlessly docking with existing applications without breaking business workflow.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Fully Hadoop-compatible&lt;/strong&gt;: JuiceFS' &lt;a href="https://juicefs.com/docs/community/hadoop_java_sdk"&gt;Hadoop Java SDK&lt;/a&gt; is compatible with Hadoop 2.x and Hadoop 3.x as well as a variety of components in the Hadoop ecosystems.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;S3-compatible&lt;/strong&gt;: JuiceFS' &lt;a href="https://juicefs.com/docs/community/s3_gateway"&gt;S3 Gateway&lt;/a&gt; provides an S3-compatible interface.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Cloud Native&lt;/strong&gt;: A &lt;a href="https://juicefs.com/docs/community/how_to_use_on_kubernetes"&gt;Kubernetes CSI Driver&lt;/a&gt; is provided for easily using JuiceFS in Kubernetes.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Shareable&lt;/strong&gt;: JuiceFS is a shared file storage that can be read and written by thousands of clients.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Strong Consistency&lt;/strong&gt;: The confirmed modification will be immediately visible on all the servers mounted with the same file system.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Outstanding Performance&lt;/strong&gt;: The latency can be as low as a few milliseconds, and the throughput can be expanded nearly unlimitedly &lt;em&gt;(depending on the size of the Object Storage)&lt;/em&gt;. &lt;a href="https://juicefs.com/docs/community/benchmark"&gt;Test results&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Data Encryption&lt;/strong&gt;: Supports data encryption in transit and at rest (please refer to &lt;a href="https://juicefs.com/docs/community/security/encrypt"&gt;the guide&lt;/a&gt; for more information).&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Global File Locks&lt;/strong&gt;: JuiceFS supports both BSD locks (flock) and POSIX record locks (fcntl).&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Data Compression&lt;/strong&gt;: JuiceFS supports &lt;a href="https://lz4.github.io/lz4"&gt;LZ4&lt;/a&gt; or &lt;a href="https://facebook.github.io/zstd"&gt;Zstandard&lt;/a&gt; to compress all your data.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/juicedata/juicefs/main/#architecture"&gt;Architecture&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/juicedata/juicefs/main/#getting-started"&gt;Getting Started&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/juicedata/juicefs/main/#advanced-topics"&gt;Advanced Topics&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/juicedata/juicefs/main/#posix-compatibility"&gt;POSIX Compatibility&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/juicedata/juicefs/main/#performance-benchmark"&gt;Performance Benchmark&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/juicedata/juicefs/main/#supported-object-storage"&gt;Supported Object Storage&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/juicedata/juicefs/main/#who-is-using"&gt;Who is using&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/juicedata/juicefs/main/#roadmap"&gt;Roadmap&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/juicedata/juicefs/main/#reporting-issues"&gt;Reporting Issues&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/juicedata/juicefs/main/#contributing"&gt;Contributing&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/juicedata/juicefs/main/#community"&gt;Community&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/juicedata/juicefs/main/#usage-tracking"&gt;Usage Tracking&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/juicedata/juicefs/main/#license"&gt;License&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/juicedata/juicefs/main/#credits"&gt;Credits&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/juicedata/juicefs/main/#faq"&gt;FAQ&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Architecture&lt;/h2&gt; 
&lt;p&gt;JuiceFS consists of three parts:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;JuiceFS Client&lt;/strong&gt;: Coordinates Object Storage and metadata storage engine as well as implementation of file system interfaces such as POSIX, Hadoop, Kubernetes, and S3 gateway.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Data Storage&lt;/strong&gt;: Stores data, with supports of a variety of data storage media, e.g., local disk, public or private cloud Object Storage, and HDFS.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Metadata Engine&lt;/strong&gt;: Stores the corresponding metadata that contains information of file name, file size, permission group, creation and modification time and directory structure, etc., with supports of different metadata engines, e.g., Redis, MySQL, SQLite and TiKV.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/juicedata/juicefs/main/docs/en/images/juicefs-arch-new.png" alt="JuiceFS Architecture" /&gt;&lt;/p&gt; 
&lt;p&gt;JuiceFS can store the metadata of file system on different metadata engines, like Redis, which is a fast, open-source, in-memory key-value data storage, particularly suitable for storing metadata; meanwhile, all the data will be stored in Object Storage through JuiceFS client. &lt;a href="https://juicefs.com/docs/community/architecture"&gt;Learn more&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/juicedata/juicefs/main/docs/en/images/data-structure-diagram.svg?sanitize=true" alt="data-structure-diagram" /&gt;&lt;/p&gt; 
&lt;p&gt;Each file stored in JuiceFS is split into &lt;strong&gt;"Chunk"&lt;/strong&gt; s at a fixed size with the default upper limit of 64 MiB. Each Chunk is composed of one or more &lt;strong&gt;"Slice"&lt;/strong&gt;(s), and the length of the slice varies depending on how the file is written. Each slice is composed of size-fixed &lt;strong&gt;"Block"&lt;/strong&gt; s, which are 4 MiB by default. These blocks will be stored in Object Storage in the end; at the same time, the metadata information of the file and its Chunks, Slices, and Blocks will be stored in metadata engines via JuiceFS. &lt;a href="https://juicefs.com/docs/community/architecture/#how-juicefs-store-files"&gt;Learn more&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/juicedata/juicefs/main/docs/en/images/how-juicefs-stores-files.svg?sanitize=true" alt="How JuiceFS stores your files" /&gt;&lt;/p&gt; 
&lt;p&gt;When using JuiceFS, files will eventually be split into Chunks, Slices and Blocks and stored in Object Storage. Therefore, the source files stored in JuiceFS cannot be found in the file browser of the Object Storage platform; instead, there are only a chunks directory and a bunch of digitally numbered directories and files in the bucket. Don't panic! This is just the secret of the high-performance operation of JuiceFS!&lt;/p&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;p&gt;Before you begin, make sure you have:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;One supported metadata engine, see &lt;a href="https://juicefs.com/docs/community/databases_for_metadata"&gt;How to Set Up Metadata Engine&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;One supported Object Storage for storing data blocks, see &lt;a href="https://juicefs.com/docs/community/how_to_setup_object_storage"&gt;Supported Object Storage&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://juicefs.com/docs/community/installation"&gt;JuiceFS Client&lt;/a&gt; downloaded and installed&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Please refer to &lt;a href="https://juicefs.com/docs/community/quick_start_guide"&gt;Quick Start Guide&lt;/a&gt; to start using JuiceFS right away!&lt;/p&gt; 
&lt;h3&gt;Command Reference&lt;/h3&gt; 
&lt;p&gt;Check out all the command line options in &lt;a href="https://juicefs.com/docs/community/command_reference"&gt;command reference&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Containers&lt;/h3&gt; 
&lt;p&gt;JuiceFS can be used as a persistent volume for Docker and Podman, please check &lt;a href="https://juicefs.com/docs/community/juicefs_on_docker"&gt;here&lt;/a&gt; for details.&lt;/p&gt; 
&lt;h3&gt;Kubernetes&lt;/h3&gt; 
&lt;p&gt;It is also very easy to use JuiceFS on Kubernetes. Please find more information &lt;a href="https://juicefs.com/docs/community/how_to_use_on_kubernetes"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Hadoop Java SDK&lt;/h3&gt; 
&lt;p&gt;If you wanna use JuiceFS in Hadoop, check &lt;a href="https://juicefs.com/docs/community/hadoop_java_sdk"&gt;Hadoop Java SDK&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Advanced Topics&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://juicefs.com/docs/community/redis_best_practices"&gt;Redis Best Practices&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://juicefs.com/docs/community/how_to_setup_object_storage"&gt;How to Setup Object Storage&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://juicefs.com/docs/community/cache"&gt;Cache&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://juicefs.com/docs/community/fault_diagnosis_and_analysis"&gt;Fault Diagnosis and Analysis&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://juicefs.com/docs/community/fuse_mount_options"&gt;FUSE Mount Options&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://juicefs.com/docs/community/installation#windows"&gt;Using JuiceFS on Windows&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://juicefs.com/docs/community/s3_gateway"&gt;S3 Gateway&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Please refer to &lt;a href="https://juicefs.com/docs/community/introduction"&gt;JuiceFS Document Center&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;h2&gt;POSIX Compatibility&lt;/h2&gt; 
&lt;p&gt;JuiceFS has passed all of the compatibility tests (8813 in total) in the latest &lt;a href="https://github.com/pjd/pjdfstest"&gt;pjdfstest&lt;/a&gt; .&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;All tests successful.

Test Summary Report
-------------------
/root/soft/pjdfstest/tests/chown/00.t          (Wstat: 0 Tests: 1323 Failed: 0)
  TODO passed:   693, 697, 708-709, 714-715, 729, 733
Files=235, Tests=8813, 233 wallclock secs ( 2.77 usr  0.38 sys +  2.57 cusr  3.93 csys =  9.65 CPU)
Result: PASS
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Aside from the POSIX features covered by pjdfstest, JuiceFS also provides:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Close-to-open consistency&lt;/strong&gt;. Once a file is written &lt;em&gt;and&lt;/em&gt; closed, it is guaranteed to view the written data in the following opens and reads from any client. Within the same mount point, all the written data can be read immediately.&lt;/li&gt; 
 &lt;li&gt;Rename and all other metadata operations are atomic, which are guaranteed by supported metadata engine transaction.&lt;/li&gt; 
 &lt;li&gt;Opened files remain accessible after unlink from same mount point.&lt;/li&gt; 
 &lt;li&gt;Mmap (tested with FSx).&lt;/li&gt; 
 &lt;li&gt;Fallocate with punch hole support.&lt;/li&gt; 
 &lt;li&gt;Extended attributes (xattr).&lt;/li&gt; 
 &lt;li&gt;BSD locks (flock).&lt;/li&gt; 
 &lt;li&gt;POSIX record locks (fcntl).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Performance Benchmark&lt;/h2&gt; 
&lt;h3&gt;Basic benchmark&lt;/h3&gt; 
&lt;p&gt;JuiceFS provides a subcommand that can run a few basic benchmarks to help you understand how it works in your environment:&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/juicedata/juicefs/main/docs/en/images/juicefs-bench.png" alt="JuiceFS Bench" /&gt;&lt;/p&gt; 
&lt;h3&gt;Throughput&lt;/h3&gt; 
&lt;p&gt;A sequential read/write benchmark has also been performed on JuiceFS, &lt;a href="https://aws.amazon.com/efs"&gt;EFS&lt;/a&gt; and &lt;a href="https://github.com/s3fs-fuse/s3fs-fuse"&gt;S3FS&lt;/a&gt; by &lt;a href="https://github.com/axboe/fio"&gt;fio&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/juicedata/juicefs/main/docs/en/images/sequential-read-write-benchmark.svg?sanitize=true" alt="Sequential Read Write Benchmark" /&gt;&lt;/p&gt; 
&lt;p&gt;Above result figure shows that JuiceFS can provide 10X more throughput than the other two (see &lt;a href="https://juicefs.com/docs/community/fio"&gt;more details&lt;/a&gt;).&lt;/p&gt; 
&lt;h3&gt;Metadata IOPS&lt;/h3&gt; 
&lt;p&gt;A simple mdtest benchmark has been performed on JuiceFS, &lt;a href="https://aws.amazon.com/efs"&gt;EFS&lt;/a&gt; and &lt;a href="https://github.com/s3fs-fuse/s3fs-fuse"&gt;S3FS&lt;/a&gt; by &lt;a href="https://github.com/hpc/ior"&gt;mdtest&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/juicedata/juicefs/main/docs/en/images/metadata-benchmark.svg?sanitize=true" alt="Metadata Benchmark" /&gt;&lt;/p&gt; 
&lt;p&gt;The result shows that JuiceFS can provide significantly more metadata IOPS than the other two (see &lt;a href="https://juicefs.com/docs/community/mdtest"&gt;more details&lt;/a&gt;).&lt;/p&gt; 
&lt;h3&gt;Analyze performance&lt;/h3&gt; 
&lt;p&gt;See &lt;a href="https://juicefs.com/docs/community/fault_diagnosis_and_analysis#performance-monitor"&gt;Real-Time Performance Monitoring&lt;/a&gt; if you encountered performance issues.&lt;/p&gt; 
&lt;h2&gt;Supported Object Storage&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Amazon S3 &lt;em&gt;(and other S3 compatible Object Storage services)&lt;/em&gt;&lt;/li&gt; 
 &lt;li&gt;Google Cloud Storage&lt;/li&gt; 
 &lt;li&gt;Azure Blob Storage&lt;/li&gt; 
 &lt;li&gt;Alibaba Cloud Object Storage Service (OSS)&lt;/li&gt; 
 &lt;li&gt;Tencent Cloud Object Storage (COS)&lt;/li&gt; 
 &lt;li&gt;Qiniu Cloud Object Storage (Kodo)&lt;/li&gt; 
 &lt;li&gt;QingStor Object Storage&lt;/li&gt; 
 &lt;li&gt;Ceph RGW&lt;/li&gt; 
 &lt;li&gt;MinIO&lt;/li&gt; 
 &lt;li&gt;Local disk&lt;/li&gt; 
 &lt;li&gt;Redis&lt;/li&gt; 
 &lt;li&gt;...&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;JuiceFS supports numerous Object Storage services. &lt;a href="https://juicefs.com/docs/community/how_to_setup_object_storage#supported-object-storage"&gt;Learn more&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Who is using&lt;/h2&gt; 
&lt;p&gt;JuiceFS is production ready and used by thousands of machines in production. A list of users has been assembled and documented &lt;a href="https://juicefs.com/docs/community/adopters"&gt;here&lt;/a&gt;. In addition JuiceFS has several collaborative projects that integrate with other open source projects, which we have documented &lt;a href="https://juicefs.com/docs/community/integrations"&gt;here&lt;/a&gt;. If you are also using JuiceFS, please feel free to let us know, and you are welcome to share your specific experience with everyone.&lt;/p&gt; 
&lt;p&gt;The storage format is stable, and will be supported by all future releases.&lt;/p&gt; 
&lt;h2&gt;Roadmap&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Gateway Optimization&lt;/li&gt; 
 &lt;li&gt;Resumable Sync&lt;/li&gt; 
 &lt;li&gt;Read-ahead Optimization&lt;/li&gt; 
 &lt;li&gt;Optimization for Large-scale Scenarios&lt;/li&gt; 
 &lt;li&gt;Snapshots&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Reporting Issues&lt;/h2&gt; 
&lt;p&gt;We use &lt;a href="https://github.com/juicedata/juicefs/issues"&gt;GitHub Issues&lt;/a&gt; to track community reported issues. You can also &lt;a href="https://raw.githubusercontent.com/juicedata/juicefs/main/#community"&gt;contact&lt;/a&gt; the community for any questions.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Thank you for your contribution! Please refer to the &lt;a href="https://juicefs.com/docs/community/development/contributing_guide"&gt;JuiceFS Contributing Guide&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;h2&gt;Community&lt;/h2&gt; 
&lt;p&gt;Welcome to join the &lt;a href="https://github.com/juicedata/juicefs/discussions"&gt;Discussions&lt;/a&gt; and the &lt;a href="https://go.juicefs.com/slack"&gt;Slack channel&lt;/a&gt; to connect with JuiceFS team members and other users.&lt;/p&gt; 
&lt;h2&gt;Usage Tracking&lt;/h2&gt; 
&lt;p&gt;JuiceFS collects &lt;strong&gt;anonymous&lt;/strong&gt; usage data by default to help us better understand how the community is using JuiceFS. Only core metrics (e.g. version number) will be reported, and user data and any other sensitive data will not be included. The related code can be viewed &lt;a href="https://raw.githubusercontent.com/juicedata/juicefs/main/pkg/usage/usage.go"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;You could also disable reporting easily by command line option &lt;code&gt;--no-usage-report&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;juicefs mount --no-usage-report
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;JuiceFS is open-sourced under Apache License 2.0, see &lt;a href="https://raw.githubusercontent.com/juicedata/juicefs/main/LICENSE"&gt;LICENSE&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Credits&lt;/h2&gt; 
&lt;p&gt;The design of JuiceFS was inspired by &lt;a href="https://research.google/pubs/pub51"&gt;Google File System&lt;/a&gt;, &lt;a href="https://hadoop.apache.org"&gt;HDFS&lt;/a&gt; and &lt;a href="https://moosefs.com"&gt;MooseFS&lt;/a&gt;. Thanks for their great work!&lt;/p&gt; 
&lt;h2&gt;FAQ&lt;/h2&gt; 
&lt;h3&gt;Why doesn't JuiceFS support XXX Object Storage?&lt;/h3&gt; 
&lt;p&gt;JuiceFS supports many Object Storage services. Please check out &lt;a href="https://juicefs.com/docs/community/how_to_setup_object_storage#supported-object-storage"&gt;this list&lt;/a&gt; first. If the Object Storage you want to use is compatible with S3, you could treat it as S3. Otherwise, try reporting any issue.&lt;/p&gt; 
&lt;h3&gt;Can I use Redis Cluster as metadata engine?&lt;/h3&gt; 
&lt;p&gt;Yes. Since &lt;a href="https://github.com/juicedata/juicefs/releases/tag/v1.0.0-beta3"&gt;v1.0.0 Beta3&lt;/a&gt; JuiceFS supports the use of &lt;a href="https://redis.io/docs/manual/scaling"&gt;Redis Cluster&lt;/a&gt; as the metadata engine, but it should be noted that Redis Cluster requires that the keys of all operations in a transaction must be in the same hash slot, so a JuiceFS file system can only use one hash slot.&lt;/p&gt; 
&lt;p&gt;See &lt;a href="https://juicefs.com/docs/community/redis_best_practices"&gt;"Redis Best Practices"&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;h3&gt;What's the difference between JuiceFS and XXX?&lt;/h3&gt; 
&lt;p&gt;See &lt;a href="https://juicefs.com/docs/community/comparison/juicefs_vs_alluxio"&gt;"Comparison with Others"&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;p&gt;For more FAQs, please see the &lt;a href="https://juicefs.com/docs/community/faq"&gt;full list&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Stargazers over time&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://star-history.com/#juicedata/juicefs&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=juicedata/juicefs&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>IceWhaleTech/CasaOS</title>
      <link>https://github.com/IceWhaleTech/CasaOS</link>
      <description>&lt;p&gt;CasaOS - A simple, easy-to-use, elegant open-source Personal Cloud system.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;CasaOS - Your Personal Cloud&lt;/h1&gt; 
&lt;!-- Readme i18n links --&gt; 
&lt;!-- &gt; English | [‰∏≠Êñá](#) | [Fran√ßais](#) --&gt; 
&lt;p align="center"&gt; 
 &lt;!-- CasaOS Banner --&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://raw.githubusercontent.com/IceWhaleTech/logo/main/casaos/casaos_banner_dark_night_800x300.png" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://raw.githubusercontent.com/IceWhaleTech/logo/main/casaos/casaos_banner_twilight_blue_800x300.png" /&gt; 
  &lt;img alt="CasaOS" src="https://raw.githubusercontent.com/IceWhaleTech/logo/main/casaos/casaos_banner_twilight_blue_800x300.png" /&gt; 
 &lt;/picture&gt; &lt;br /&gt; &lt;i&gt;Connect with the community, establish autonomy, reduce the cost of SaaS, and MAXIMIZE the potential for a personalized copilot.&lt;/i&gt; &lt;br /&gt; &lt;br /&gt; 
 &lt;!-- CasaOS Badges --&gt; &lt;a href="https://github.com/IceWhaleTech/CasaOS" target="_blank"&gt; &lt;img alt="CasaOS Version" src="https://img.shields.io/github/v/release/IceWhaleTech/CasaOS?color=162453&amp;amp;style=flat-square&amp;amp;label=CasaOS" /&gt; &lt;/a&gt; &lt;a href="https://github.com/IceWhaleTech/CasaOS/raw/main/LICENSE" target="_blank"&gt; &lt;img alt="CasaOS License" src="https://img.shields.io/github/license/IceWhaleTech/CasaOS?color=162453&amp;amp;style=flat-square&amp;amp;label=License" /&gt; &lt;/a&gt; &lt;a href="https://github.com/IceWhaleTech/CasaOS/pulls" target="_blank"&gt; &lt;img alt="CasaOS Pull Requests" src="https://img.shields.io/github/issues-pr/IceWhaleTech/CasaOS?color=162453&amp;amp;style=flat-square&amp;amp;label=PRs" /&gt; &lt;/a&gt; &lt;a href="https://github.com/IceWhaleTech/CasaOS/issues" target="_blank"&gt; &lt;img alt="CasaOS Issues" src="https://img.shields.io/github/issues/IceWhaleTech/CasaOS?color=162453&amp;amp;style=flat-square&amp;amp;label=Issues" /&gt; &lt;/a&gt; &lt;a href="https://codecov.io/gh/IceWhaleTech/CasaOS"&gt; &lt;img src="https://codecov.io/gh/IceWhaleTech/CasaOS/branch/main/graph/badge.svg?token=l9uMKGlkxM" /&gt; &lt;/a&gt; &lt;a href="https://github.com/IceWhaleTech/CasaOS/stargazers" target="_blank"&gt; &lt;img alt="CasaOS Stargazers" src="https://img.shields.io/github/stars/IceWhaleTech/CasaOS?color=162453&amp;amp;style=flat-square&amp;amp;label=Stars" /&gt; &lt;/a&gt; 
 &lt;!-- &lt;a href="https://github.com/IceWhaleTech/CasaOS/releases" target="_blank"&gt;
    &lt;img alt="CasaOS Downloads" src="https://img.shields.io/github/downloads/IceWhaleTech/CasaOS/total?color=162453&amp;style=flat-square" /&gt;
    &lt;/a&gt; --&gt; &lt;br /&gt; 
 &lt;!-- CasaOS Community --&gt; &lt;a href="https://discord.gg/knqAbbBbeX" target="_blank"&gt; &lt;img alt="IceWhale Discord" src="https://img.shields.io/discord/884667213326463016?color=162453&amp;amp;style=flat-square&amp;amp;label=Discord&amp;amp;logo=discord&amp;amp;logoColor=fff" /&gt; &lt;/a&gt; &lt;a href="https://github.com/IceWhaleTech/CasaOS/discussions" target="_blank"&gt; &lt;img alt="CasaOS GitHub Discussions" src="https://img.shields.io/github/discussions/IceWhaleTech/CasaOS?color=162453&amp;amp;style=flat-square&amp;amp;label=Discussions&amp;amp;logo=github" /&gt; &lt;/a&gt; 
 &lt;!-- ALL-CONTRIBUTORS-BADGE:START - Do not remove or modify this section --&gt; &lt;a href="https://raw.githubusercontent.com/IceWhaleTech/CasaOS/main/#credits"&gt; &lt;img alt="All Contributors" src="https://img.shields.io/static/v1?label=All%20Contributors&amp;amp;message=15&amp;amp;color=162453&amp;amp;style=flat-square&amp;amp;logo=Handshake&amp;amp;logoColor=fff" /&gt; &lt;/a&gt; 
 &lt;!-- CasaOS YouTube --&gt; &lt;a href="https://www.youtube.com/channel/UC2zMrUYT17AJhIl9XWZzT8g" target="_blank"&gt; &lt;img alt="YouTube Tutorial Views" src="https://img.shields.io/youtube/channel/views/UC2zMrUYT17AJhIl9XWZzT8g?style=flat-square&amp;amp;logo=youtube&amp;amp;logoColor=red&amp;amp;label=YouTube%20Tutorial%20Views" /&gt; &lt;/a&gt; &lt;br /&gt; &lt;a href="http://bit.ly/45JQIiL" target="_blank"&gt; &lt;img alt="twitter ZimaSpace" src="https://img.shields.io/twitter/follow/ZimaSpace?style=flat-square&amp;amp;logo=X&amp;amp;label=Contact%20Us%20%40%20ZimaSpace&amp;amp;labelColor=555&amp;amp;color=555" /&gt; &lt;/a&gt; &lt;a href="http://bit.ly/4lgHj7V" target="_blank"&gt; &lt;img alt="facebook ZimaSpace" src="https://img.shields.io/badge/ZimaSpace-1877F2?style=flat-square&amp;amp;logo=Facebook&amp;amp;logoColor=fff&amp;amp;label=Contact%20Us&amp;amp;labelColor=555&amp;amp;color=162453" /&gt; &lt;/a&gt; &lt;br /&gt; 
 &lt;!-- CasaOS Links --&gt; &lt;a href="https://www.casaos.io" target="_blank"&gt;Website&lt;/a&gt; | &lt;a href="http://demo.casaos.io" target="_blank"&gt;Demo&lt;/a&gt; | &lt;a href="https://github.com/IceWhaleTech/CasaOS" target="_blank"&gt;GitHub&lt;/a&gt; &lt;br /&gt; &lt;br /&gt; 
 &lt;!-- CasaOS Snapshots --&gt; &lt;kbd&gt; 
  &lt;picture&gt; 
   &lt;source media="(prefers-color-scheme: dark)" srcset="snapshot-dark.jpg" /&gt; 
   &lt;source media="(prefers-color-scheme: light)" srcset="snapshot-light.jpg" /&gt; 
   &lt;img alt="CasaOS Snapshot" src="https://raw.githubusercontent.com/IceWhaleTech/CasaOS/main/snapshot-light.jpg" /&gt; 
  &lt;/picture&gt; &lt;/kbd&gt; &lt;/p&gt; 
&lt;h2&gt;Why do you need Personal Cloud?&lt;/h2&gt; 
&lt;p&gt;In 2020, the team noticed three important trends:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;The cost of computing power and storage was decreasing fast.&lt;/li&gt; 
 &lt;li&gt;A part of cloud computing was moving towards edge computing.&lt;/li&gt; 
 &lt;li&gt;The issue of consumer data asset ownership and attribution had been ignored.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Based on these trends, the team proposed a thought experiment internally: what if personal clouds were available under $100 in next five years? This personal cloud would provide a low-cost data collaboration solution as a personal data center, storing and managing data for creators and small organizations. A distributed collaborative computing network can be formed by personal servers located around the world. It could also control and connect all smart devices, providing cross-ecosystem local intelligent services.&lt;/p&gt; 
&lt;p&gt;Furthermore, the personal cloud could combine personal data to train personalized AI assistants. The idea is that this technology would be an effective way to solve the issue of consumer data asset ownership and , as well as provide a more affordable and efficient computing solution for individuals and small organizations.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;If you think what we are doing is valuable. Please &lt;strong&gt;give us a star ‚≠ê&lt;/strong&gt; and &lt;strong&gt;fork it ü§û&lt;/strong&gt;!&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Friendly UI designed for home scenarios 
  &lt;ul&gt; 
   &lt;li&gt;No code, no forms, intuitive, design for humanity&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Multiple hardware and base system support 
  &lt;ul&gt; 
   &lt;li&gt;ZimaBoard, NUC, RPi, old computers, whatever is available.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Selected apps in the app store, one-click installation 
  &lt;ul&gt; 
   &lt;li&gt;Nextcloud, HomeAssistant, AdGuard, Jellyfin, *arr and more!&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Easily install numerous Docker apps 
  &lt;ul&gt; 
   &lt;li&gt;Over 100,000 apps from the Docker ecosystem can be easily installed&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Elegant drive and file management 
  &lt;ul&gt; 
   &lt;li&gt;What you see is what you get. No technical background required.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Well-designed system/app widgets 
  &lt;ul&gt; 
   &lt;li&gt;What you care about, at a glance. Resource usage, app status, and more!&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;p&gt;CasaOS fully supports ZimaBoard, Intel NUC, and Raspberry Pi. Also, more computers and development boards and fully compatible with Ubuntu, Debian, Raspberry Pi OS, and CentOS with one-liner installation.&lt;/p&gt; 
&lt;h3&gt;Hardware Compatibility&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;amd64 / x86-64&lt;/li&gt; 
 &lt;li&gt;arm64&lt;/li&gt; 
 &lt;li&gt;armv7&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;System Compatibility&lt;/h3&gt; 
&lt;p&gt;Official Support&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Debian 12 (‚úÖ Tested, Recommended)&lt;/li&gt; 
 &lt;li&gt;Ubuntu Server 20.04 (‚úÖ Tested)&lt;/li&gt; 
 &lt;li&gt;Raspberry Pi OS (‚úÖ Tested)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Community Support&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Elementary 6.1 (‚úÖ Tested)&lt;/li&gt; 
 &lt;li&gt;Armbian 22.04 (‚úÖ Tested)&lt;/li&gt; 
 &lt;li&gt;Alpine (üöß Not Fully Tested Yet)&lt;/li&gt; 
 &lt;li&gt;OpenWrt (üöß Not Fully Tested Yet)&lt;/li&gt; 
 &lt;li&gt;ArchLinux (üöß Not Fully Tested Yet)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Quick Setup CasaOS&lt;/h3&gt; 
&lt;p&gt;Freshly install a system from the list above and run this command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;wget -qO- https://get.casaos.io | sudo bash
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;or&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;curl -fsSL https://get.casaos.io | sudo bash
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Update CasaOS&lt;/h3&gt; 
&lt;p&gt;CasaOS can be updated from the User Interface (UI), via &lt;code&gt;Settings ... Update&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Alternatively it can be updated from a terminal session. To update from a terminal session, it must be done either from a secure shell (ssh) session to the device or from a directly attached terminal and keyboard to the device running CasaOS, this cannot be done from the terminal via the CasaOS User Interface (UI). To update to the latest release of CasaOS from a terminal session run this command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;wget -qO- https://get.casaos.io/update | sudo bash
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;or&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;curl -fsSL https://get.casaos.io/update | sudo bash
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To determine version of CasaOS from a terminal session run this command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;casaos -v
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Uninstall CasaOS&lt;/h3&gt; 
&lt;p&gt;v0.3.3 or newer&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;casaos-uninstall
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Before v0.3.3&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;curl -fsSL https://get.icewhale.io/casaos-uninstall.sh | sudo bash
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Community&lt;/h2&gt; 
&lt;p&gt;The word Casa comes from the Spanish word for "home". Project CasaOS originated as a pre-installed system for the crowdfunded product &lt;a href="https://www.zimaboard.com"&gt;ZimaBoard&lt;/a&gt; on Kickstarter.&lt;/p&gt; 
&lt;p&gt;After looking at many systems and software on the market, the team found no server system designed for home scenarios, sadly true.&lt;/p&gt; 
&lt;p&gt;So, we set out to build this open-source project to develop CasaOS with our own hands, everyone in the community, and you.&lt;/p&gt; 
&lt;p&gt;We believe that through community-driven collaborative innovation and open communication with global developers, we can reshape the digital home experience like never before.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;A warm welcome for you to get help or share great ideas in the &lt;a href="https://discord.gg/knqAbbBbeX"&gt;Discord&lt;/a&gt;!&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://discord.gg/knqAbbBbeX"&gt;&lt;img src="https://discordapp.com/api/guilds/884667213326463016/widget.png?style=banner2" alt="Discord Card" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;CasaOS is a community-driven open source project and the people involved are CasaOS users. That means CasaOS will always need contributions from community members just like you!&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;See &lt;a href="https://wiki.casaos.io/en/contribute"&gt;https://wiki.casaos.io/en/contribute&lt;/a&gt; for ways of contributing to CasaOS&lt;/li&gt; 
 &lt;li&gt;See &lt;a href="https://wiki.casaos.io/en/contribute/development"&gt;https://wiki.casaos.io/en/contribute/development&lt;/a&gt; if you want to be involved in code contribution specifically&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Credits&lt;/h2&gt; 
&lt;p&gt;Many thanks to everyone who has helped CasaOS so far!&lt;/p&gt; 
&lt;p&gt;Everyone's contribution is greatly appreciated. (&lt;a href="https://allcontributors.org/docs/en/emoji-key"&gt;Emoji Key&lt;/a&gt;)&lt;/p&gt; 
&lt;!-- ALL-CONTRIBUTORS-LIST:START - Do not remove or modify this section --&gt; 
&lt;!-- prettier-ignore-start --&gt; 
&lt;!-- markdownlint-disable --&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/jerrykuku"&gt;&lt;img src="https://avatars.githubusercontent.com/u/9485680?v=4?s=100" width="100px;" alt="" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;ËÄÅÁ´≠Âäõ&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/IceWhaleTech/CasaOS/commits?author=jerrykuku" title="Code"&gt;üíª&lt;/a&gt; &lt;a href="https://github.com/IceWhaleTech/CasaOS/commits?author=jerrykuku" title="Documentation"&gt;üìñ&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/IceWhaleTech/CasaOS/main/#ideas-jerrykuku" title="Ideas, Planning, &amp;amp; Feedback"&gt;ü§î&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/IceWhaleTech/CasaOS/main/#infra-jerrykuku" title="Infrastructure (Hosting, Build-Tools, etc)"&gt;üöá&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/IceWhaleTech/CasaOS/main/#maintenance-jerrykuku" title="Maintenance"&gt;üöß&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/IceWhaleTech/CasaOS/main/#platform-jerrykuku" title="Packaging/porting to new platform"&gt;üì¶&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/IceWhaleTech/CasaOS/main/#question-jerrykuku" title="Answering Questions"&gt;üí¨&lt;/a&gt; &lt;a href="https://github.com/IceWhaleTech/CasaOS/pulls?q=is%3Apr+reviewed-by%3Ajerrykuku" title="Reviewed Pull Requests"&gt;üëÄ&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/LinkLeong"&gt;&lt;img src="https://avatars.githubusercontent.com/u/13556972?v=4?s=100" width="100px;" alt="" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;link&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/IceWhaleTech/CasaOS/commits?author=LinkLeong" title="Code"&gt;üíª&lt;/a&gt; &lt;a href="https://github.com/IceWhaleTech/CasaOS/commits?author=LinkLeong" title="Documentation"&gt;üìñ&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/IceWhaleTech/CasaOS/main/#ideas-LinkLeong" title="Ideas, Planning, &amp;amp; Feedback"&gt;ü§î&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/IceWhaleTech/CasaOS/main/#infra-LinkLeong" title="Infrastructure (Hosting, Build-Tools, etc)"&gt;üöá&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/IceWhaleTech/CasaOS/main/#maintenance-LinkLeong" title="Maintenance"&gt;üöß&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/IceWhaleTech/CasaOS/main/#question-LinkLeong" title="Answering Questions"&gt;üí¨&lt;/a&gt; &lt;a href="https://github.com/IceWhaleTech/CasaOS/pulls?q=is%3Apr+reviewed-by%3ALinkLeong" title="Reviewed Pull Requests"&gt;üëÄ&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/tigerinus"&gt;&lt;img src="https://avatars.githubusercontent.com/u/7172560?v=4?s=100" width="100px;" alt="" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Â§™Êàà&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/IceWhaleTech/CasaOS/commits?author=tigerinus" title="Code"&gt;üíª&lt;/a&gt; &lt;a href="https://github.com/IceWhaleTech/CasaOS/commits?author=tigerinus" title="Documentation"&gt;üìñ&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/IceWhaleTech/CasaOS/main/#ideas-tigerinus" title="Ideas, Planning, &amp;amp; Feedback"&gt;ü§î&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/IceWhaleTech/CasaOS/main/#infra-tigerinus" title="Infrastructure (Hosting, Build-Tools, etc)"&gt;üöá&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/IceWhaleTech/CasaOS/main/#maintenance-tigerinus" title="Maintenance"&gt;üöß&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/IceWhaleTech/CasaOS/main/#mentoring-tigerinus" title="Mentoring"&gt;üßë‚Äçüè´&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/IceWhaleTech/CasaOS/main/#security-tigerinus" title="Security"&gt;üõ°Ô∏è&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/IceWhaleTech/CasaOS/main/#question-tigerinus" title="Answering Questions"&gt;üí¨&lt;/a&gt; &lt;a href="https://github.com/IceWhaleTech/CasaOS/pulls?q=is%3Apr+reviewed-by%3Atigerinus" title="Reviewed Pull Requests"&gt;üëÄ&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/Lauren-ED209"&gt;&lt;img src="https://avatars.githubusercontent.com/u/8243355?v=4?s=100" width="100px;" alt="" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Lauren&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://raw.githubusercontent.com/IceWhaleTech/CasaOS/main/#ideas-Lauren-ED209" title="Ideas, Planning, &amp;amp; Feedback"&gt;ü§î&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/IceWhaleTech/CasaOS/main/#fundingFinding-Lauren-ED209" title="Funding Finding"&gt;üîç&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/IceWhaleTech/CasaOS/main/#projectManagement-Lauren-ED209" title="Project Management"&gt;üìÜ&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/IceWhaleTech/CasaOS/main/#question-Lauren-ED209" title="Answering Questions"&gt;üí¨&lt;/a&gt; &lt;a href="https://github.com/IceWhaleTech/CasaOS/commits?author=Lauren-ED209" title="Tests"&gt;‚ö†Ô∏è&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://JohnGuan.Cn"&gt;&lt;img src="https://avatars.githubusercontent.com/u/3358477?v=4?s=100" width="100px;" alt="" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;John Guan&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://raw.githubusercontent.com/IceWhaleTech/CasaOS/main/#blog-JohnGuan" title="Blogposts"&gt;üìù&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/IceWhaleTech/CasaOS/main/#content-JohnGuan" title="Content"&gt;üñã&lt;/a&gt; &lt;a href="https://github.com/IceWhaleTech/CasaOS/commits?author=JohnGuan" title="Documentation"&gt;üìñ&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/IceWhaleTech/CasaOS/main/#ideas-JohnGuan" title="Ideas, Planning, &amp;amp; Feedback"&gt;ü§î&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/IceWhaleTech/CasaOS/main/#eventOrganizing-JohnGuan" title="Event Organizing"&gt;üìã&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/IceWhaleTech/CasaOS/main/#mentoring-JohnGuan" title="Mentoring"&gt;üßë‚Äçüè´&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/IceWhaleTech/CasaOS/main/#question-JohnGuan" title="Answering Questions"&gt;üí¨&lt;/a&gt; &lt;a href="https://github.com/IceWhaleTech/CasaOS/pulls?q=is%3Apr+reviewed-by%3AJohnGuan" title="Reviewed Pull Requests"&gt;üëÄ&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://blog.tippybits.com"&gt;&lt;img src="https://avatars.githubusercontent.com/u/17506770?v=4?s=100" width="100px;" alt="" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;David Tippett&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/IceWhaleTech/CasaOS/commits?author=dtaivpp" title="Documentation"&gt;üìñ&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/IceWhaleTech/CasaOS/main/#ideas-dtaivpp" title="Ideas, Planning, &amp;amp; Feedback"&gt;ü§î&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/IceWhaleTech/CasaOS/main/#question-dtaivpp" title="Answering Questions"&gt;üí¨&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/zarevskaya"&gt;&lt;img src="https://avatars.githubusercontent.com/u/60230221?v=4?s=100" width="100px;" alt="" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Skaya&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://raw.githubusercontent.com/IceWhaleTech/CasaOS/main/#mentoring-zarevskaya" title="Mentoring"&gt;üßë‚Äçüè´&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/IceWhaleTech/CasaOS/main/#question-zarevskaya" title="Answering Questions"&gt;üí¨&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/IceWhaleTech/CasaOS/main/#tutorial-zarevskaya" title="Tutorials"&gt;‚úÖ&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/IceWhaleTech/CasaOS/main/#translation-zarevskaya" title="Translation"&gt;üåç&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/AuthorShin"&gt;&lt;img src="https://avatars.githubusercontent.com/u/4959043?v=4?s=100" width="100px;" alt="" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;AuthorShin&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/IceWhaleTech/CasaOS/commits?author=AuthorShin" title="Tests"&gt;‚ö†Ô∏è&lt;/a&gt; &lt;a href="https://github.com/IceWhaleTech/CasaOS/issues?q=author%3AAuthorShin" title="Bug reports"&gt;üêõ&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/IceWhaleTech/CasaOS/main/#question-AuthorShin" title="Answering Questions"&gt;üí¨&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/IceWhaleTech/CasaOS/main/#ideas-AuthorShin" title="Ideas, Planning, &amp;amp; Feedback"&gt;ü§î&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/baptiste313"&gt;&lt;img src="https://avatars.githubusercontent.com/u/93325157?v=4?s=100" width="100px;" alt="" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;baptiste313&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://raw.githubusercontent.com/IceWhaleTech/CasaOS/main/#translation-baptiste313" title="Translation"&gt;üåç&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/DrMxrcy"&gt;&lt;img src="https://avatars.githubusercontent.com/u/58747968?v=4?s=100" width="100px;" alt="" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;DrMxrcy&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/IceWhaleTech/CasaOS/commits?author=DrMxrcy" title="Tests"&gt;‚ö†Ô∏è&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/IceWhaleTech/CasaOS/main/#ideas-DrMxrcy" title="Ideas, Planning, &amp;amp; Feedback"&gt;ü§î&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/IceWhaleTech/CasaOS/main/#question-DrMxrcy" title="Answering Questions"&gt;üí¨&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/Joooost"&gt;&lt;img src="https://avatars.githubusercontent.com/u/12090673?v=4?s=100" width="100px;" alt="" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Joooost&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://raw.githubusercontent.com/IceWhaleTech/CasaOS/main/#ideas-Joooost" title="Ideas, Planning, &amp;amp; Feedback"&gt;ü§î&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://potyarkin.ml"&gt;&lt;img src="https://avatars.githubusercontent.com/u/334908?v=4?s=100" width="100px;" alt="" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Vitaly Potyarkin&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://raw.githubusercontent.com/IceWhaleTech/CasaOS/main/#ideas-sio" title="Ideas, Planning, &amp;amp; Feedback"&gt;ü§î&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/bearfrieze"&gt;&lt;img src="https://avatars.githubusercontent.com/u/1023813?v=4?s=100" width="100px;" alt="" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Bj√∏rn Friese&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://raw.githubusercontent.com/IceWhaleTech/CasaOS/main/#ideas-bearfrieze" title="Ideas, Planning, &amp;amp; Feedback"&gt;ü§î&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/Protektor-Desura"&gt;&lt;img src="https://avatars.githubusercontent.com/u/1195496?v=4?s=100" width="100px;" alt="" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Protektor&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/IceWhaleTech/CasaOS/issues?q=author%3AProtektor-Desura" title="Bug reports"&gt;üêõ&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/IceWhaleTech/CasaOS/main/#ideas-Protektor-Desura" title="Ideas, Planning, &amp;amp; Feedback"&gt;ü§î&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/IceWhaleTech/CasaOS/main/#question-Protektor-Desura" title="Answering Questions"&gt;üí¨&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/llwaini"&gt;&lt;img src="https://avatars.githubusercontent.com/u/59589857?v=4?s=100" width="100px;" alt="" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;llwaini&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://raw.githubusercontent.com/IceWhaleTech/CasaOS/main/#projectManagement-llwaini" title="Project Management"&gt;üìÜ&lt;/a&gt; &lt;a href="https://github.com/IceWhaleTech/CasaOS/commits?author=llwaini" title="Tests"&gt;‚ö†Ô∏è&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/IceWhaleTech/CasaOS/main/#tutorial-llwaini" title="Tutorials"&gt;‚úÖ&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/CorrectRoadH"&gt;&lt;img src="https://avatars.githubusercontent.com/u/29306285?v=4?s=100" width="100px;" alt="" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;CorrectRoadH&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/IceWhaleTech/CasaOS/commits?author=correctroadh" title="Code"&gt;üíª&lt;/a&gt; &lt;a href="https://github.com/IceWhaleTech/CasaOS/commits?author=correctroadh" title="Documentation"&gt;üìñ&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/zhanghengxin"&gt;&lt;img src="https://avatars.githubusercontent.com/u/24197448?v=4?s=100" width="100px;" alt="" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;zhanghengxin&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/IceWhaleTech/CasaOS/commits?author=zhanghengxin" title="Code"&gt;üíª&lt;/a&gt; &lt;a href="https://github.com/IceWhaleTech/CasaOS/commits?author=zhanghengxin" title="Documentation"&gt;üìñ&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;!-- markdownlint-restore --&gt; 
&lt;!-- prettier-ignore-end --&gt; 
&lt;!-- ALL-CONTRIBUTORS-LIST:END --&gt; 
&lt;p&gt;This project follows the &lt;a href="https://github.com/all-contributors/all-contributors"&gt;all-contributors&lt;/a&gt; specification. Contributions of any kind are welcome!&lt;/p&gt; 
&lt;h2&gt;Changelog&lt;/h2&gt; 
&lt;p&gt;Detailed changes for each release are documented in the &lt;a href="https://github.com/IceWhaleTech/CasaOS/releases"&gt;release notes&lt;/a&gt;.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p align="center"&gt; &lt;a href="https://dashboard.trackgit.com/token/l5q8egi92tfhlxd70l2l"&gt; &lt;img src="https://us-central1-trackgit-analytics.cloudfunctions.net/token/ping/l5q8egi92tfhlxd70l2l" alt="trackgit-views" /&gt; &lt;/a&gt; &lt;/p&gt;</description>
    </item>
    
    <item>
      <title>juanfont/headscale</title>
      <link>https://github.com/juanfont/headscale</link>
      <description>&lt;p&gt;An open source, self-hosted implementation of the Tailscale control server&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/juanfont/headscale/main/docs/assets/logo/headscale3_header_stacked_left.png" alt="headscale logo" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/juanfont/headscale/actions/workflows/test.yml/badge.svg?sanitize=true" alt="ci" /&gt;&lt;/p&gt; 
&lt;p&gt;An open source, self-hosted implementation of the Tailscale control server.&lt;/p&gt; 
&lt;p&gt;Join our &lt;a href="https://discord.gg/c84AZQhmpx"&gt;Discord server&lt;/a&gt; for a chat.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; Always select the same GitHub tag as the released version you use to ensure you have the correct example configuration. The &lt;code&gt;main&lt;/code&gt; branch might contain unreleased changes. The documentation is available for stable and development versions:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://headscale.net/stable/"&gt;Documentation for the stable version&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://headscale.net/development/"&gt;Documentation for the development version&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;What is Tailscale&lt;/h2&gt; 
&lt;p&gt;Tailscale is &lt;a href="https://tailscale.com/"&gt;a modern VPN&lt;/a&gt; built on top of &lt;a href="https://www.wireguard.com/"&gt;Wireguard&lt;/a&gt;. It &lt;a href="https://tailscale.com/blog/how-tailscale-works/"&gt;works like an overlay network&lt;/a&gt; between the computers of your networks - using &lt;a href="https://tailscale.com/blog/how-nat-traversal-works/"&gt;NAT traversal&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Everything in Tailscale is Open Source, except the GUI clients for proprietary OS (Windows and macOS/iOS), and the control server.&lt;/p&gt; 
&lt;p&gt;The control server works as an exchange point of Wireguard public keys for the nodes in the Tailscale network. It assigns the IP addresses of the clients, creates the boundaries between each user, enables sharing machines between users, and exposes the advertised routes of your nodes.&lt;/p&gt; 
&lt;p&gt;A &lt;a href="https://tailscale.com/kb/1136/tailnet/"&gt;Tailscale network (tailnet)&lt;/a&gt; is private network which Tailscale assigns to a user in terms of private users or an organisation.&lt;/p&gt; 
&lt;h2&gt;Design goal&lt;/h2&gt; 
&lt;p&gt;Headscale aims to implement a self-hosted, open source alternative to the &lt;a href="https://tailscale.com/"&gt;Tailscale&lt;/a&gt; control server. Headscale's goal is to provide self-hosters and hobbyists with an open-source server they can use for their projects and labs. It implements a narrow scope, a &lt;em&gt;single&lt;/em&gt; Tailscale network (tailnet), suitable for a personal use, or a small open-source organisation.&lt;/p&gt; 
&lt;h2&gt;Supporting Headscale&lt;/h2&gt; 
&lt;p&gt;If you like &lt;code&gt;headscale&lt;/code&gt; and find it useful, there is a sponsorship and donation buttons available in the repo.&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;p&gt;Please see &lt;a href="https://headscale.net/stable/about/features/"&gt;"Features" in the documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Client OS support&lt;/h2&gt; 
&lt;p&gt;Please see &lt;a href="https://headscale.net/stable/about/clients/"&gt;"Client and operating system support" in the documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Running headscale&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Please note that we do not support nor encourage the use of reverse proxies and container to run Headscale.&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Please have a look at the &lt;a href="https://headscale.net/stable/"&gt;&lt;code&gt;documentation&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;For NixOS users, a module is available in &lt;a href="https://raw.githubusercontent.com/juanfont/headscale/main/nix/"&gt;&lt;code&gt;nix/&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Talks&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Fosdem 2023 (video): &lt;a href="https://fosdem.org/2023/schedule/event/goheadscale/"&gt;Headscale: How we are using integration testing to reimplement Tailscale&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;presented by Juan Font Alonso and Kristoffer Dalby&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Disclaimer&lt;/h2&gt; 
&lt;p&gt;This project is not associated with Tailscale Inc.&lt;/p&gt; 
&lt;p&gt;However, one of the active maintainers for Headscale &lt;a href="https://tailscale.com/blog/opensource"&gt;is employed by Tailscale&lt;/a&gt; and he is allowed to spend work hours contributing to the project. Contributions from this maintainer are reviewed by other maintainers.&lt;/p&gt; 
&lt;p&gt;The maintainers work together on setting the direction for the project. The underlying principle is to serve the community of self-hosters, enthusiasts and hobbyists - while having a sustainable project.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Please read the &lt;a href="https://raw.githubusercontent.com/juanfont/headscale/main/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; file.&lt;/p&gt; 
&lt;h3&gt;Requirements&lt;/h3&gt; 
&lt;p&gt;To contribute to headscale you would need the latest version of &lt;a href="https://golang.org"&gt;Go&lt;/a&gt; and &lt;a href="https://buf.build"&gt;Buf&lt;/a&gt; (Protobuf generator).&lt;/p&gt; 
&lt;p&gt;We recommend using &lt;a href="https://nixos.org/"&gt;Nix&lt;/a&gt; to setup a development environment. This can be done with &lt;code&gt;nix develop&lt;/code&gt;, which will install the tools and give you a shell. This guarantees that you will have the same dev env as &lt;code&gt;headscale&lt;/code&gt; maintainers.&lt;/p&gt; 
&lt;h3&gt;Code style&lt;/h3&gt; 
&lt;p&gt;To ensure we have some consistency with a growing number of contributions, this project has adopted linting and style/formatting rules:&lt;/p&gt; 
&lt;p&gt;The &lt;strong&gt;Go&lt;/strong&gt; code is linted with &lt;a href="https://golangci-lint.run"&gt;&lt;code&gt;golangci-lint&lt;/code&gt;&lt;/a&gt; and formatted with &lt;a href="https://github.com/segmentio/golines"&gt;&lt;code&gt;golines&lt;/code&gt;&lt;/a&gt; (width 88) and &lt;a href="https://github.com/mvdan/gofumpt"&gt;&lt;code&gt;gofumpt&lt;/code&gt;&lt;/a&gt;. Please configure your editor to run the tools while developing and make sure to run &lt;code&gt;make lint&lt;/code&gt; and &lt;code&gt;make fmt&lt;/code&gt; before committing any code.&lt;/p&gt; 
&lt;p&gt;The &lt;strong&gt;Proto&lt;/strong&gt; code is linted with &lt;a href="https://docs.buf.build/lint/overview"&gt;&lt;code&gt;buf&lt;/code&gt;&lt;/a&gt; and formatted with &lt;a href="https://clang.llvm.org/docs/ClangFormat.html"&gt;&lt;code&gt;clang-format&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;The &lt;strong&gt;rest&lt;/strong&gt; (Markdown, YAML, etc) is formatted with &lt;a href="https://prettier.io"&gt;&lt;code&gt;prettier&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Check out the &lt;code&gt;.golangci.yaml&lt;/code&gt; and &lt;code&gt;Makefile&lt;/code&gt; to see the specific configuration.&lt;/p&gt; 
&lt;h3&gt;Install development tools&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Go&lt;/li&gt; 
 &lt;li&gt;Buf&lt;/li&gt; 
 &lt;li&gt;Protobuf tools&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Install and activate:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;nix develop
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Testing and building&lt;/h3&gt; 
&lt;p&gt;Some parts of the project require the generation of Go code from Protobuf (if changes are made in &lt;code&gt;proto/&lt;/code&gt;) and it must be (re-)generated with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;make generate
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: Please check in changes from &lt;code&gt;gen/&lt;/code&gt; in a separate commit to make it easier to review.&lt;/p&gt; 
&lt;p&gt;To run the tests:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;make test
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To build the program:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;make build
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Development workflow&lt;/h3&gt; 
&lt;p&gt;We recommend using Nix for dependency management to ensure you have all required tools. If you prefer to manage dependencies yourself, you can use Make directly:&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;With Nix (recommended):&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;nix develop
make test
make build
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;With your own dependencies:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;make test
make build
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The Makefile will warn you if any required tools are missing and suggest running &lt;code&gt;nix develop&lt;/code&gt;. Run &lt;code&gt;make help&lt;/code&gt; to see all available targets.&lt;/p&gt; 
&lt;h2&gt;Contributors&lt;/h2&gt; 
&lt;a href="https://github.com/juanfont/headscale/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=juanfont/headscale" /&gt; &lt;/a&gt; 
&lt;p&gt;Made with &lt;a href="https://contrib.rocks"&gt;contrib.rocks&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>docker/mcp-gateway</title>
      <link>https://github.com/docker/mcp-gateway</link>
      <description>&lt;p&gt;docker mcp CLI plugin / MCP Gateway&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Docker MCP Plugin and Docker MCP Gateway&lt;/h1&gt; 
&lt;p&gt;&lt;img src="https://github.com/docker/mcp-gateway/actions/workflows/ci.yml/badge.svg?sanitize=true" alt="build" /&gt;&lt;/p&gt; 
&lt;p&gt;The &lt;a href="https://docs.docker.com/ai/mcp-catalog-and-toolkit/toolkit/"&gt;MCP Toolkit&lt;/a&gt;, in Docker Desktop, allows developers to configure and consume MCP servers from the &lt;a href="https://hub.docker.com/mcp"&gt;Docker MCP Catalog&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Underneath, the Toolkit is powered by a docker CLI plugin: &lt;code&gt;docker-mcp&lt;/code&gt;. This repository is the code of this CLI plugin. It can work in Docker Desktop or independently.&lt;/p&gt; 
&lt;p&gt;The main feature of this CLI is the &lt;strong&gt;Docker MCP Gateway&lt;/strong&gt; which allows easy and secure running and deployment of MCP servers. See &lt;a href="https://raw.githubusercontent.com/docker/mcp-gateway/main/#Features"&gt;Features&lt;/a&gt; for a list of all the features.&lt;/p&gt; 
&lt;h2&gt;What is MCP?&lt;/h2&gt; 
&lt;p&gt;The &lt;a href="https://spec.modelcontextprotocol.io/"&gt;Model Context Protocol (MCP)&lt;/a&gt; is an open protocol that standardizes how AI applications connect to external data sources and tools. It provides a secure, controlled way for language models to access and interact with various services, databases, and APIs.&lt;/p&gt; 
&lt;h2&gt;Overview&lt;/h2&gt; 
&lt;p&gt;Developers face criticial barriers when integrating Model Context Protocol (MCP) tools into production workflows:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Managing MCP server lifecycle&lt;/strong&gt; Each local MCP sever in the catalog runs in an isolated Docker container. npx and uvx servers are granted minimal host privileges.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Providing a unified interface&lt;/strong&gt; AI models access MCP servers through a single Gateway.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Handling authentication and security&lt;/strong&gt; Keep secrets out of environment variables using Docker Desktop's secrets management.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Supports dynamic tool discovery&lt;/strong&gt; and configuration. Each MCP client (eg VS Code, Cursor, Claude Desktop, etc.) connects to the same Gateway configuration, ensuring consistency across different clients.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Enables OAuth flows&lt;/strong&gt; for MCPs that require OAuth access token service connections.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;üê≥ &lt;strong&gt;Container-based Servers&lt;/strong&gt;: Run MCP servers as Docker containers with proper isolation.&lt;/li&gt; 
 &lt;li&gt;üîß &lt;strong&gt;Server Management&lt;/strong&gt;: List, inspect, and call MCP tools, resources and prompts from multiple servers.&lt;/li&gt; 
 &lt;li&gt;üîê &lt;strong&gt;Secrets Management&lt;/strong&gt;: Secure handling of API keys and credentials via Docker Desktop.&lt;/li&gt; 
 &lt;li&gt;üåê &lt;strong&gt;OAuth Integration&lt;/strong&gt;: Built-in OAuth flows for service authentication.&lt;/li&gt; 
 &lt;li&gt;üìã &lt;strong&gt;Server Catalog&lt;/strong&gt;: Manage and configure multiple MCP catalogs.&lt;/li&gt; 
 &lt;li&gt;üîç &lt;strong&gt;Dynamic Discovery&lt;/strong&gt;: Automatic tool, prompt, and resource discovery from running servers.&lt;/li&gt; 
 &lt;li&gt;üìä &lt;strong&gt;Monitoring&lt;/strong&gt;: Built-in logging and call tracing capabilities.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;h3&gt;Prerequisites&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Docker Desktop (with MCP Toolkit feature enabled)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div align="left"&gt; 
 &lt;img src="https://raw.githubusercontent.com/docker/mcp-gateway/main/img/enable_toolkit.png" width="400" /&gt; 
&lt;/div&gt; - Go 1.24+ (for development) 
&lt;h3&gt;Install as Docker CLI Plugin&lt;/h3&gt; 
&lt;p&gt;The MCP cli will already be installed on recent versions of Docker Desktop but you can build and install the latest version by following these steps:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Clone the repository
git clone https://github.com/docker/mcp-gateway.git
cd mcp-gateway
mkdir -p "$HOME/.docker/cli-plugins/"

# Build and install the plugin
make docker-mcp
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;After installation, the plugin will be available as:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker mcp --help
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;h3&gt;Catalog Management&lt;/h3&gt; 
&lt;p&gt;Manage the catalogs available to the MCP gateway. The &lt;a href="https://hub.docker.com/mcp"&gt;default catalog&lt;/a&gt; is available with the name 'docker-mcp'.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Manage server catalogs
docker mcp catalog --help

# Initialize the default Docker MCP Catalog
docker mcp catalog init

# List available catalogs
docker mcp catalog ls

# Show all servers in a catalog
docker mcp catalog show docker-mcp
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;more about &lt;a href="https://raw.githubusercontent.com/docker/mcp-gateway/main/docs/catalog.md"&gt;the MCP Catalog&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;more about &lt;a href="https://raw.githubusercontent.com/docker/mcp-gateway/main/docs/catalog.md#importing-from-the-oss-mcp-community-registry"&gt;importing from the OSS MCP Community Registry&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;MCP Gateway Operations&lt;/h3&gt; 
&lt;p&gt;Start up an MCP Gateway. This can be used for one client, or to service multiple clients if using either &lt;code&gt;sse&lt;/code&gt; or &lt;code&gt;streaming&lt;/code&gt; transports.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Run the MCP gateway (stdio)
docker mcp gateway run

# Run the MCP gateway (streaming)
docker mcp gateway run --port 8080 --transport streaming
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;more about &lt;a href="https://raw.githubusercontent.com/docker/mcp-gateway/main/docs/mcp-gateway.md"&gt;the MCP Gateway&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/docker/mcp-gateway/main/docs/self-configured.md"&gt;running an unpublished local image&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Server Management&lt;/h3&gt; 
&lt;p&gt;Enable and disable the set of MCP servers that will be available for default clients. The MCP gateway can be configured to expose different sets of servers and tools but enabling and disabling servers here impacts the default gateway configuration.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# List enabled servers
docker mcp server ls

# Enable one or more servers
docker mcp server enable &amp;lt;server-name&amp;gt; [server-name...]

# Disable servers
docker mcp server disable &amp;lt;server-name&amp;gt; [server-name...]

# Get detailed information about a server
docker mcp server inspect &amp;lt;server-name&amp;gt;

# Reset (disable all servers)
docker mcp server reset
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Configuration Management&lt;/h3&gt; 
&lt;p&gt;Configure any MCP servers that require custom runtime configuration.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Read current configuration
docker mcp config read

# Write new configuration
docker mcp config write '&amp;lt;yaml-config&amp;gt;'

# Reset configuration to defaults
docker mcp config reset
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Secrets and OAuth&lt;/h3&gt; 
&lt;p&gt;Configure MCP servers that require either secrets or OAuth.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Manage secrets
docker mcp secret --help

# Handle OAuth flows
docker mcp oauth --help

# Manage access policies
docker mcp policy --help

# export any desktop secrets needed by either server1 or server2
#   (temporary requirement to export secrets for docker cloud runs - this command
#    will no longer be required once Docker Cloud can access secret stores) 
docker mcp secret export server1 server2
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Tool Management&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Show available commands
docker mcp --help

# Count available tools
docker mcp tools count

# List all available MCP tools
docker mcp tools ls

# List all available MCP tools in JSON format
docker mcp tools ls --format=json

# Inspect a specific tool
docker mcp tools inspect &amp;lt;tool-name&amp;gt;

# Call a tool with arguments
docker mcp tools call &amp;lt;tool-name&amp;gt; [arguments...]
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Configuration&lt;/h2&gt; 
&lt;p&gt;The MCP CLI uses several configuration files:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;docker-mcp.yaml&lt;/code&gt;&lt;/strong&gt;: Server catalog defining available MCP servers&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;registry.yaml&lt;/code&gt;&lt;/strong&gt;: Registry of enabled servers&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;config.yaml&lt;/code&gt;&lt;/strong&gt;: Configuration per server&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;tools.yaml&lt;/code&gt;&lt;/strong&gt;: Enabled tools per server&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Configuration files are typically stored in &lt;code&gt;~/.docker/mcp/&lt;/code&gt;. This is in this directory that Docker Desktop's MCP Toolkit with store its configuration.&lt;/p&gt; 
&lt;h3&gt;Environment Variables&lt;/h3&gt; 
&lt;p&gt;The MCP CLI respects the following environment variables for client configuration:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;CLAUDE_CONFIG_DIR&lt;/code&gt;&lt;/strong&gt;: Override the default Claude Code configuration directory (&lt;code&gt;~/.claude&lt;/code&gt;). When set, Claude Code will use &lt;code&gt;$CLAUDE_CONFIG_DIR/.claude.json&lt;/code&gt; instead of &lt;code&gt;~/.claude.json&lt;/code&gt; for its MCP server configuration. This is useful for: 
  &lt;ul&gt; 
   &lt;li&gt;Maintaining separate Claude Code installations for work and personal use&lt;/li&gt; 
   &lt;li&gt;Testing configuration changes in isolation&lt;/li&gt; 
   &lt;li&gt;Managing multiple Claude Code profiles&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Example usage:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Set custom Claude Code configuration directory
export CLAUDE_CONFIG_DIR=/path/to/custom/config

# Connect MCP Gateway to Claude Code
docker mcp client connect claude-code --global

# Claude Code will now use /path/to/custom/config/.claude.json
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Architecture&lt;/h2&gt; 
&lt;p&gt;The Docker MCP CLI implements a gateway pattern:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;AI Client ‚Üí MCP Gateway ‚Üí MCP Servers (Docker Containers)
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;AI Client&lt;/strong&gt;: Language model or AI application&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;MCP Gateway&lt;/strong&gt;: This CLI tool managing protocol translation and routing&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;MCP Servers&lt;/strong&gt;: Individual MCP servers running in Docker containers&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/docker/mcp-gateway/main/docs/message-flow.md"&gt;docs/message-flow.md&lt;/a&gt; for detailed message flow diagrams.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;The build instructions are available in the &lt;a href="https://raw.githubusercontent.com/docker/mcp-gateway/main/CONTRIBUTING.md"&gt;contribution guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the MIT License - see the &lt;a href="https://raw.githubusercontent.com/docker/mcp-gateway/main/LICENSE"&gt;LICENSE&lt;/a&gt; file for details.&lt;/p&gt; 
&lt;h2&gt;Support&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;üí¨ &lt;a href="https://raw.githubusercontent.com/docker/mcp-gateway/main/docs/troubleshooting.md"&gt;Troubleshooting&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üìñ &lt;a href="https://modelcontextprotocol.io/specification/2025-11-25"&gt;MCP Specification&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üê≥ &lt;a href="https://docs.docker.com/desktop/"&gt;Docker Desktop Documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üêõ &lt;a href="https://github.com/docker/mcp-gateway/issues"&gt;Report Issues&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üí¨ &lt;a href="https://github.com/docker/mcp-gateway/discussions"&gt;Discussions&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>maximhq/bifrost</title>
      <link>https://github.com/maximhq/bifrost</link>
      <description>&lt;p&gt;Fastest LLM gateway (50x faster than LiteLLM) with adaptive load balancer, cluster mode, guardrails, 1000+ models support &amp; &lt;100 ¬µs overhead at 5k RPS.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Bifrost&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://goreportcard.com/report/github.com/maximhq/bifrost/core"&gt;&lt;img src="https://goreportcard.com/badge/github.com/maximhq/bifrost/core" alt="Go Report Card" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/exN5KAydbU"&gt;&lt;img src="https://dcbadge.limes.pink/api/server/https://discord.gg/exN5KAydbU?style=flat" alt="Discord badge" /&gt;&lt;/a&gt; &lt;a href="https://snyk.io/test/github/maximhq/bifrost"&gt;&lt;img src="https://snyk.io/test/github/maximhq/bifrost/badge.svg?sanitize=true" alt="Known Vulnerabilities" /&gt;&lt;/a&gt; &lt;a href="https://codecov.io/gh/maximhq/bifrost"&gt;&lt;img src="https://codecov.io/gh/maximhq/bifrost/branch/main/graph/badge.svg?sanitize=true" alt="codecov" /&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/docker/pulls/maximhq/bifrost" alt="Docker Pulls" /&gt; &lt;a href="https://app.getpostman.com/run-collection/31642484-2ba0e658-4dcd-49f4-845a-0c7ed745b916?action=collection%2Ffork&amp;amp;source=rip_markdown&amp;amp;collection-url=entityId%3D31642484-2ba0e658-4dcd-49f4-845a-0c7ed745b916%26entityType%3Dcollection%26workspaceId%3D63e853c8-9aec-477f-909c-7f02f543150e"&gt;&lt;img src="https://run.pstmn.io/button.svg?sanitize=true" alt="Run In Postman" style="width: 95px; height: 21px;" /&gt;&lt;/a&gt; &lt;a href="https://artifacthub.io/packages/search?repo=bifrost"&gt;&lt;img src="https://img.shields.io/endpoint?url=https://artifacthub.io/badge/repository/bifrost" alt="Artifact Hub" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/maximhq/bifrost/main/LICENSE"&gt;&lt;img src="https://img.shields.io/github/license/maximhq/bifrost" alt="License" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;The fastest way to build AI applications that never go down&lt;/h2&gt; 
&lt;p&gt;Bifrost is a high-performance AI gateway that unifies access to 15+ providers (OpenAI, Anthropic, AWS Bedrock, Google Vertex, and more) through a single OpenAI-compatible API. Deploy in seconds with zero configuration and get automatic failover, load balancing, semantic caching, and enterprise-grade features.&lt;/p&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/maximhq/bifrost/main/docs/media/getting-started.png" alt="Get started" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Go from zero to production-ready AI gateway in under a minute.&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Step 1:&lt;/strong&gt; Start Bifrost Gateway&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Install and run locally
npx -y @maximhq/bifrost

# Or use Docker
docker run -p 8080:8080 maximhq/bifrost
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Step 2:&lt;/strong&gt; Configure via Web UI&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Open the built-in web interface
open http://localhost:8080
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Step 3:&lt;/strong&gt; Make your first API call&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -X POST http://localhost:8080/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "openai/gpt-4o-mini",
    "messages": [{"role": "user", "content": "Hello, Bifrost!"}]
  }'
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;That's it!&lt;/strong&gt; Your AI gateway is running with a web interface for visual configuration, real-time monitoring, and analytics.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Complete Setup Guides:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.getbifrost.ai/quickstart/gateway/setting-up"&gt;Gateway Setup&lt;/a&gt; - HTTP API deployment&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.getbifrost.ai/quickstart/go-sdk/setting-up"&gt;Go SDK Setup&lt;/a&gt; - Direct integration&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Enterprise Deployments&lt;/h2&gt; 
&lt;p&gt;Bifrost supports enterprise-grade, private deployments for teams running production AI systems at scale. In addition to private networking, custom security controls, and governance, enterprise deployments unlock advanced capabilities including adaptive load balancing, clustering, guardrails, MCP gateway and and other features designed for enterprise-grade scale and reliability.&lt;/p&gt; 
&lt;p&gt;üëâ &lt;a href="https://www.getmaxim.ai/bifrost/enterprise" target="_blank"&gt;Explore enterprise capabilities&lt;/a&gt;&lt;/p&gt; 
&lt;div align="left"&gt; 
 &lt;a href="https://calendly.com/maximai/bifrost-demo"&gt; &lt;img src="https://raw.githubusercontent.com/maximhq/bifrost/main/.github/assets/book-demo-button.png" alt="Book a Demo" width="170" style="margin-top:5px;" /&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Key Features&lt;/h2&gt; 
&lt;h3&gt;Core Infrastructure&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.getbifrost.ai/features/unified-interface"&gt;Unified Interface&lt;/a&gt;&lt;/strong&gt; - Single OpenAI-compatible API for all providers&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.getbifrost.ai/quickstart/gateway/provider-configuration"&gt;Multi-Provider Support&lt;/a&gt;&lt;/strong&gt; - OpenAI, Anthropic, AWS Bedrock, Google Vertex, Azure, Cerebras, Cohere, Mistral, Ollama, Groq, and more&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.getbifrost.ai/features/fallbacks"&gt;Automatic Fallbacks&lt;/a&gt;&lt;/strong&gt; - Seamless failover between providers and models with zero downtime&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.getbifrost.ai/features/fallbacks"&gt;Load Balancing&lt;/a&gt;&lt;/strong&gt; - Intelligent request distribution across multiple API keys and providers&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Advanced Features&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.getbifrost.ai/features/mcp"&gt;Model Context Protocol (MCP)&lt;/a&gt;&lt;/strong&gt; - Enable AI models to use external tools (filesystem, web search, databases)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.getbifrost.ai/features/semantic-caching"&gt;Semantic Caching&lt;/a&gt;&lt;/strong&gt; - Intelligent response caching based on semantic similarity to reduce costs and latency&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.getbifrost.ai/quickstart/gateway/streaming"&gt;Multimodal Support&lt;/a&gt;&lt;/strong&gt; - Support for text,images, audio, and streaming, all behind a common interface.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.getbifrost.ai/enterprise/custom-plugins"&gt;Custom Plugins&lt;/a&gt;&lt;/strong&gt; - Extensible middleware architecture for analytics, monitoring, and custom logic&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.getbifrost.ai/features/governance"&gt;Governance&lt;/a&gt;&lt;/strong&gt; - Usage tracking, rate limiting, and fine-grained access control&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Enterprise &amp;amp; Security&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.getbifrost.ai/features/governance"&gt;Budget Management&lt;/a&gt;&lt;/strong&gt; - Hierarchical cost control with virtual keys, teams, and customer budgets&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.getbifrost.ai/features/sso-with-google-github"&gt;SSO Integration&lt;/a&gt;&lt;/strong&gt; - Google and GitHub authentication support&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.getbifrost.ai/features/observability"&gt;Observability&lt;/a&gt;&lt;/strong&gt; - Native Prometheus metrics, distributed tracing, and comprehensive logging&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.getbifrost.ai/enterprise/vault-support"&gt;Vault Support&lt;/a&gt;&lt;/strong&gt; - Secure API key management with HashiCorp Vault integration&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Developer Experience&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.getbifrost.ai/quickstart/gateway/setting-up"&gt;Zero-Config Startup&lt;/a&gt;&lt;/strong&gt; - Start immediately with dynamic provider configuration&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.getbifrost.ai/features/drop-in-replacement"&gt;Drop-in Replacement&lt;/a&gt;&lt;/strong&gt; - Replace OpenAI/Anthropic/GenAI APIs with one line of code&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.getbifrost.ai/integrations/what-is-an-integration"&gt;SDK Integrations&lt;/a&gt;&lt;/strong&gt; - Native support for popular AI SDKs with zero code changes&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.getbifrost.ai/quickstart/gateway/provider-configuration"&gt;Configuration Flexibility&lt;/a&gt;&lt;/strong&gt; - Web UI, API-driven, or file-based configuration options&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Repository Structure&lt;/h2&gt; 
&lt;p&gt;Bifrost uses a modular architecture for maximum flexibility:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-text"&gt;bifrost/
‚îú‚îÄ‚îÄ npx/                 # NPX script for easy installation
‚îú‚îÄ‚îÄ core/                # Core functionality and shared components
‚îÇ   ‚îú‚îÄ‚îÄ providers/       # Provider-specific implementations (OpenAI, Anthropic, etc.)
‚îÇ   ‚îú‚îÄ‚îÄ schemas/         # Interfaces and structs used throughout Bifrost
‚îÇ   ‚îî‚îÄ‚îÄ bifrost.go       # Main Bifrost implementation
‚îú‚îÄ‚îÄ framework/           # Framework components for data persistence
‚îÇ   ‚îú‚îÄ‚îÄ configstore/     # Configuration storages
‚îÇ   ‚îú‚îÄ‚îÄ logstore/        # Request logging storages
‚îÇ   ‚îî‚îÄ‚îÄ vectorstore/     # Vector storages
‚îú‚îÄ‚îÄ transports/          # HTTP gateway and other interface layers
‚îÇ   ‚îî‚îÄ‚îÄ bifrost-http/    # HTTP transport implementation
‚îú‚îÄ‚îÄ ui/                  # Web interface for HTTP gateway
‚îú‚îÄ‚îÄ plugins/             # Extensible plugin system
‚îÇ   ‚îú‚îÄ‚îÄ governance/      # Budget management and access control
‚îÇ   ‚îú‚îÄ‚îÄ jsonparser/      # JSON parsing and manipulation utilities
‚îÇ   ‚îú‚îÄ‚îÄ logging/         # Request logging and analytics
‚îÇ   ‚îú‚îÄ‚îÄ maxim/           # Maxim's observability integration
‚îÇ   ‚îú‚îÄ‚îÄ mocker/          # Mock responses for testing and development
‚îÇ   ‚îú‚îÄ‚îÄ semanticcache/   # Intelligent response caching
‚îÇ   ‚îî‚îÄ‚îÄ telemetry/       # Monitoring and observability
‚îú‚îÄ‚îÄ docs/                # Documentation and guides
‚îî‚îÄ‚îÄ tests/               # Comprehensive test suites
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Getting Started Options&lt;/h2&gt; 
&lt;p&gt;Choose the deployment method that fits your needs:&lt;/p&gt; 
&lt;h3&gt;1. Gateway (HTTP API)&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Best for:&lt;/strong&gt; Language-agnostic integration, microservices, and production deployments&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# NPX - Get started in 30 seconds
npx -y @maximhq/bifrost

# Docker - Production ready
docker run -p 8080:8080 -v $(pwd)/data:/app/data maximhq/bifrost
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Features:&lt;/strong&gt; Web UI, real-time monitoring, multi-provider management, zero-config startup&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Learn More:&lt;/strong&gt; &lt;a href="https://docs.getbifrost.ai/quickstart/gateway/setting-up"&gt;Gateway Setup Guide&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;2. Go SDK&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Best for:&lt;/strong&gt; Direct Go integration with maximum performance and control&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;go get github.com/maximhq/bifrost/core
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Features:&lt;/strong&gt; Native Go APIs, embedded deployment, custom middleware integration&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Learn More:&lt;/strong&gt; &lt;a href="https://docs.getbifrost.ai/quickstart/go-sdk/setting-up"&gt;Go SDK Guide&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;3. Drop-in Replacement&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Best for:&lt;/strong&gt; Migrating existing applications with zero code changes&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-diff"&gt;# OpenAI SDK
- base_url = "https://api.openai.com"
+ base_url = "http://localhost:8080/openai"

# Anthropic SDK  
- base_url = "https://api.anthropic.com"
+ base_url = "http://localhost:8080/anthropic"

# Google GenAI SDK
- api_endpoint = "https://generativelanguage.googleapis.com"
+ api_endpoint = "http://localhost:8080/genai"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Learn More:&lt;/strong&gt; &lt;a href="https://docs.getbifrost.ai/integrations/what-is-an-integration"&gt;Integration Guides&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Performance&lt;/h2&gt; 
&lt;p&gt;Bifrost adds virtually zero overhead to your AI requests. In sustained 5,000 RPS benchmarks, the gateway added only &lt;strong&gt;11 ¬µs&lt;/strong&gt; of overhead per request.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Metric&lt;/th&gt; 
   &lt;th&gt;t3.medium&lt;/th&gt; 
   &lt;th&gt;t3.xlarge&lt;/th&gt; 
   &lt;th&gt;Improvement&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Added latency (Bifrost overhead)&lt;/td&gt; 
   &lt;td&gt;59 ¬µs&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;11 ¬µs&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;-81%&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Success rate @ 5k RPS&lt;/td&gt; 
   &lt;td&gt;100%&lt;/td&gt; 
   &lt;td&gt;100%&lt;/td&gt; 
   &lt;td&gt;No failed requests&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Avg. queue wait time&lt;/td&gt; 
   &lt;td&gt;47 ¬µs&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;1.67 ¬µs&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;-96%&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Avg. request latency (incl. provider)&lt;/td&gt; 
   &lt;td&gt;2.12 s&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;1.61 s&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;-24%&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;Key Performance Highlights:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Perfect Success Rate&lt;/strong&gt; - 100% request success rate even at 5k RPS&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Minimal Overhead&lt;/strong&gt; - Less than 15 ¬µs additional latency per request&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Efficient Queuing&lt;/strong&gt; - Sub-microsecond average wait times&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Fast Key Selection&lt;/strong&gt; - ~10 ns to pick weighted API keys&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Complete Benchmarks:&lt;/strong&gt; &lt;a href="https://docs.getbifrost.ai/benchmarking/getting-started"&gt;Performance Analysis&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Complete Documentation:&lt;/strong&gt; &lt;a href="https://docs.getbifrost.ai"&gt;https://docs.getbifrost.ai&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Quick Start&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.getbifrost.ai/quickstart/gateway/setting-up"&gt;Gateway Setup&lt;/a&gt; - HTTP API deployment in 30 seconds&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.getbifrost.ai/quickstart/go-sdk/setting-up"&gt;Go SDK Setup&lt;/a&gt; - Direct Go integration&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.getbifrost.ai/quickstart/gateway/provider-configuration"&gt;Provider Configuration&lt;/a&gt; - Multi-provider setup&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Features&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.getbifrost.ai/features/unified-interface"&gt;Multi-Provider Support&lt;/a&gt; - Single API for all providers&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.getbifrost.ai/features/mcp"&gt;MCP Integration&lt;/a&gt; - External tool calling&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.getbifrost.ai/features/semantic-caching"&gt;Semantic Caching&lt;/a&gt; - Intelligent response caching&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.getbifrost.ai/features/fallbacks"&gt;Fallbacks &amp;amp; Load Balancing&lt;/a&gt; - Reliability features&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.getbifrost.ai/features/governance"&gt;Budget Management&lt;/a&gt; - Cost control and governance&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Integrations&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.getbifrost.ai/integrations/openai-sdk"&gt;OpenAI SDK&lt;/a&gt; - Drop-in OpenAI replacement&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.getbifrost.ai/integrations/anthropic-sdk"&gt;Anthropic SDK&lt;/a&gt; - Drop-in Anthropic replacement&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.getbifrost.ai/integrations/bedrock-sdk"&gt;AWS Bedrock SDK&lt;/a&gt; - AWS Bedrock integration&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.getbifrost.ai/integrations/genai-sdk"&gt;Google GenAI SDK&lt;/a&gt; - Drop-in GenAI replacement&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.getbifrost.ai/integrations/litellm-sdk"&gt;LiteLLM SDK&lt;/a&gt; - LiteLLM integration&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.getbifrost.ai/integrations/langchain-sdk"&gt;Langchain SDK&lt;/a&gt; - Langchain integration&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Enterprise&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.getbifrost.ai/enterprise/custom-plugins"&gt;Custom Plugins&lt;/a&gt; - Extend functionality&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.getbifrost.ai/enterprise/clustering"&gt;Clustering&lt;/a&gt; - Multi-node deployment&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.getbifrost.ai/enterprise/vault-support"&gt;Vault Support&lt;/a&gt; - Secure key management&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.getbifrost.ai/deployment/docker-setup"&gt;Production Deployment&lt;/a&gt; - Scaling and monitoring&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Need Help?&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://discord.gg/exN5KAydbU"&gt;Join our Discord&lt;/a&gt;&lt;/strong&gt; for community support and discussions.&lt;/p&gt; 
&lt;p&gt;Get help with:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Quick setup assistance and troubleshooting&lt;/li&gt; 
 &lt;li&gt;Best practices and configuration tips&lt;/li&gt; 
 &lt;li&gt;Community discussions and support&lt;/li&gt; 
 &lt;li&gt;Real-time help with integrations&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome contributions of all kinds! See our &lt;a href="https://docs.getbifrost.ai/contributing/setting-up-repo"&gt;Contributing Guide&lt;/a&gt; for:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Setting up the development environment&lt;/li&gt; 
 &lt;li&gt;Code conventions and best practices&lt;/li&gt; 
 &lt;li&gt;How to submit pull requests&lt;/li&gt; 
 &lt;li&gt;Building and testing locally&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For development requirements and build instructions, see our &lt;a href="https://docs.getbifrost.ai/contributing/setting-up-repo#development-environment-setup"&gt;Development Setup Guide&lt;/a&gt;.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the Apache 2.0 License - see the &lt;a href="https://raw.githubusercontent.com/maximhq/bifrost/main/LICENSE"&gt;LICENSE&lt;/a&gt; file for details.&lt;/p&gt; 
&lt;p&gt;Built with ‚ù§Ô∏è by &lt;a href="https://github.com/maximhq"&gt;Maxim&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>cilium/cilium</title>
      <link>https://github.com/cilium/cilium</link>
      <description>&lt;p&gt;eBPF-based Networking, Security, and Observability&lt;/p&gt;&lt;hr&gt;&lt;p&gt;.. raw:: html&lt;/p&gt; 
&lt;picture&gt; 
 &lt;source media="(prefers-color-scheme: light)" srcset="https://cdn.jsdelivr.net/gh/cilium/cilium@main/Documentation/images/logo.png" width="350" alt="Cilium Logo" /&gt; 
 &lt;img src="https://cdn.jsdelivr.net/gh/cilium/cilium@main/Documentation/images/logo-dark.png" width="350" alt="Cilium Logo" /&gt; 
&lt;/picture&gt; 
&lt;p&gt;|cii| |go-report| |clomonitor| |artifacthub| |slack| |go-doc| |rtd| |apache| |bsd| |gpl| |fossa| |gateway-api| |codespaces|&lt;/p&gt; 
&lt;p&gt;Cilium is a networking, observability, and security solution with an eBPF-based dataplane. It provides a simple flat Layer 3 network with the ability to span multiple clusters in either a native routing or overlay mode. It is L7-protocol aware and can enforce network policies on L3-L7 using an identity based security model that is decoupled from network addressing.&lt;/p&gt; 
&lt;p&gt;Cilium implements distributed load balancing for traffic between pods and to external services, and is able to fully replace kube-proxy, using efficient hash tables in eBPF allowing for almost unlimited scale. It also supports advanced functionality like integrated ingress and egress gateway, bandwidth management and service mesh, and provides deep network and security visibility and monitoring.&lt;/p&gt; 
&lt;p&gt;A new Linux kernel technology called eBPF_ is at the foundation of Cilium. It supports dynamic insertion of eBPF bytecode into the Linux kernel at various integration points such as: network IO, application sockets, and tracepoints to implement security, networking and visibility logic. eBPF is highly efficient and flexible. To learn more about eBPF, visit &lt;code&gt;eBPF.io&lt;/code&gt;_.&lt;/p&gt; 
&lt;p&gt;.. image:: Documentation/images/cilium-overview.png :alt: Overview of Cilium features for networking, observability, service mesh, and runtime security&lt;/p&gt; 
&lt;p&gt;.. raw:: html&lt;/p&gt; 
&lt;a href="https://cncf.io/"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://github.com/cncf/artwork/blob/main/other/cncf-member/graduated/color/cncf-graduated-color.svg" /&gt; 
  &lt;img src="https://github.com/cncf/artwork/raw/main/other/cncf-member/graduated/white/cncf-graduated-white.svg?sanitize=true" alt="CNCF Graduated Project" height="80" /&gt; 
 &lt;/picture&gt; &lt;/a&gt; 
&lt;a href="https://ebpf.io/"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset=".github/assets/ebpf-horizontal.svg" /&gt; 
  &lt;img src="https://raw.githubusercontent.com/cilium/cilium/main/.github/assets/ebpf-horizontal-dark-back.svg?sanitize=true" alt="eBPF Logo" height="80" align="right" /&gt; 
 &lt;/picture&gt; &lt;/a&gt; 
&lt;h1&gt;Stable Releases&lt;/h1&gt; 
&lt;p&gt;The Cilium community maintains minor stable releases for the last three minor Cilium versions. Older Cilium stable versions from minor releases prior to that are considered EOL.&lt;/p&gt; 
&lt;p&gt;For upgrades to new minor releases please consult the &lt;code&gt;Cilium Upgrade Guide&lt;/code&gt;_.&lt;/p&gt; 
&lt;p&gt;Listed below are the actively maintained release branches along with their latest patch release, corresponding image pull tags and their release notes:&lt;/p&gt; 
&lt;p&gt;+---------------------------------------------------------+------------+------------------------------------+----------------------------------------------------------------------------+ | &lt;code&gt;v1.18 &amp;lt;https://github.com/cilium/cilium/tree/v1.18&amp;gt;&lt;/code&gt;__ | 2026-01-13 | &lt;code&gt;quay.io/cilium/cilium:v1.18.6&lt;/code&gt; | &lt;code&gt;Release Notes &amp;lt;https://github.com/cilium/cilium/releases/tag/v1.18.6&amp;gt;&lt;/code&gt;__ | +---------------------------------------------------------+------------+------------------------------------+----------------------------------------------------------------------------+ | &lt;code&gt;v1.17 &amp;lt;https://github.com/cilium/cilium/tree/v1.17&amp;gt;&lt;/code&gt;__ | 2026-01-13 | &lt;code&gt;quay.io/cilium/cilium:v1.17.12&lt;/code&gt; | &lt;code&gt;Release Notes &amp;lt;https://github.com/cilium/cilium/releases/tag/v1.17.12&amp;gt;&lt;/code&gt;__ | +---------------------------------------------------------+------------+------------------------------------+----------------------------------------------------------------------------+ | &lt;code&gt;v1.16 &amp;lt;https://github.com/cilium/cilium/tree/v1.16&amp;gt;&lt;/code&gt;__ | 2026-01-13 | &lt;code&gt;quay.io/cilium/cilium:v1.16.19&lt;/code&gt; | &lt;code&gt;Release Notes &amp;lt;https://github.com/cilium/cilium/releases/tag/v1.16.19&amp;gt;&lt;/code&gt;__ | +---------------------------------------------------------+------------+------------------------------------+----------------------------------------------------------------------------+&lt;/p&gt; 
&lt;h2&gt;Architectures&lt;/h2&gt; 
&lt;p&gt;Cilium images are distributed for AMD64 and AArch64 architectures.&lt;/p&gt; 
&lt;h2&gt;Software Bill of Materials&lt;/h2&gt; 
&lt;p&gt;Starting with Cilium version 1.13.0, all images include a Software Bill of Materials (SBOM). The SBOM is generated in &lt;code&gt;SPDX&lt;/code&gt;_ format. More information on this is available on &lt;code&gt;Cilium SBOM&lt;/code&gt;_.&lt;/p&gt; 
&lt;p&gt;.. _&lt;code&gt;SPDX&lt;/code&gt;: &lt;a href="https://spdx.dev/"&gt;https://spdx.dev/&lt;/a&gt; .. _&lt;code&gt;Cilium SBOM&lt;/code&gt;: &lt;a href="https://docs.cilium.io/en/latest/configuration/sbom/"&gt;https://docs.cilium.io/en/latest/configuration/sbom/&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Development&lt;/h1&gt; 
&lt;p&gt;For development and testing purpose, the Cilium community publishes snapshots, early release candidates (RC) and CI container images build from the &lt;code&gt;main branch &amp;lt;https://github.com/cilium/cilium/commits/main&amp;gt;&lt;/code&gt;_. These images are not for use in production.&lt;/p&gt; 
&lt;p&gt;For testing upgrades to new development releases please consult the latest development build of the &lt;code&gt;Cilium Upgrade Guide&lt;/code&gt;_.&lt;/p&gt; 
&lt;p&gt;Listed below are branches for testing along with their snapshots or RC releases, corresponding image pull tags and their release notes where applicable:&lt;/p&gt; 
&lt;p&gt;+----------------------------------------------------------------------------+------------+-----------------------------------------+---------------------------------------------------------------------------------+ | &lt;code&gt;main &amp;lt;https://github.com/cilium/cilium/commits/main&amp;gt;&lt;/code&gt;__ | daily | &lt;code&gt;quay.io/cilium/cilium-ci:latest&lt;/code&gt; | N/A | +----------------------------------------------------------------------------+------------+-----------------------------------------+---------------------------------------------------------------------------------+ | &lt;code&gt;v1.19.0-rc.0 &amp;lt;https://github.com/cilium/cilium/commits/v1.19.0-rc.0&amp;gt;&lt;/code&gt;__ | 2026-01-15 | &lt;code&gt;quay.io/cilium/cilium:v1.19.0-rc.0&lt;/code&gt; | &lt;code&gt;Release Notes &amp;lt;https://github.com/cilium/cilium/releases/tag/v1.19.0-rc.0&amp;gt;&lt;/code&gt;__ | +----------------------------------------------------------------------------+------------+-----------------------------------------+---------------------------------------------------------------------------------+&lt;/p&gt; 
&lt;h1&gt;Functionality Overview&lt;/h1&gt; 
&lt;p&gt;.. begin-functionality-overview&lt;/p&gt; 
&lt;h2&gt;CNI (Container Network Interface)&lt;/h2&gt; 
&lt;p&gt;&lt;code&gt;Cilium as a CNI plugin &amp;lt;https://cilium.io/use-cases/cni/&amp;gt;&lt;/code&gt;_ provides a fast, scalable, and secure networking layer for Kubernetes clusters. Built on eBPF, it offers several deployment options:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Overlay networking:&lt;/strong&gt; encapsulation-based virtual network spanning all hosts with support for VXLAN and Geneve. It works on almost any network infrastructure as the only requirement is IP connectivity between hosts which is typically already given.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Native routing mode:&lt;/strong&gt; Use of the regular routing table of the Linux host. The network is required to be capable of routing the IP addresses of the application containers. It integrates with cloud routers, routing daemons, and IPv6-native infrastructure.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Flexible routing options:&lt;/strong&gt; Cilium can automate route learning and advertisement in common topologies such as using L2 neighbor discovery when nodes share a layer 2 domain, or BGP when routing across layer 3 boundaries.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Each mode is designed for maximum interoperability with existing infrastructure while minimizing operational burden.&lt;/p&gt; 
&lt;h2&gt;Load Balancing&lt;/h2&gt; 
&lt;p&gt;Cilium implements distributed load balancing for traffic between application containers and to/from external services. The load balancing is implemented in eBPF using efficient hashtables enabling high service density and low latency at scale.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;East-west load balancing&lt;/strong&gt; rewrites service connections at the socket level (&lt;code&gt;connect()&lt;/code&gt;), avoiding the overhead of per-packet NAT and fully &lt;code&gt;replacing kube-proxy &amp;lt;https://cilium.io/use-cases/kube-proxy/&amp;gt;&lt;/code&gt;_.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;North-south load balancing&lt;/strong&gt; supports XDP for high-throughput scenarios and &lt;code&gt;layer 4 load balancing &amp;lt;https://cilium.io/use-cases/load-balancer/&amp;gt;&lt;/code&gt;_ including Direct Server Return (DSR), and Maglev consistent hashing.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Cluster Mesh&lt;/h2&gt; 
&lt;p&gt;Cilium &lt;code&gt;Cluster Mesh &amp;lt;https://cilium.io/use-cases/cluster-mesh/&amp;gt;&lt;/code&gt;_ enables secure, seamless connectivity across multiple Kubernetes clusters. For operators running hybrid or multi-cloud environments, Cluster Mesh ensures a consistent security and connectivity experience.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Global service discovery&lt;/strong&gt;: Workloads across clusters can discover and connect to services as if they were local. This enables fault tolerance, like automatically failing over to backends in another cluster, and exposes shared services like logging, auth, or databases across environments.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Unified identity model:&lt;/strong&gt; Security policies are enforced based on identity, not IP address, across all clusters.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Network Policy&lt;/h2&gt; 
&lt;p&gt;Cilium &lt;code&gt;Network Policy &amp;lt;https://cilium.io/use-cases/network-policy/&amp;gt;&lt;/code&gt;_ provides identity-aware enforcement across L3-L7. Typical container firewalls secure workloads by filtering on source IP addresses and destination ports. This concept requires the firewalls on all servers to be manipulated whenever a container is started anywhere in the cluster.&lt;/p&gt; 
&lt;p&gt;In order to avoid this situation which limits scale, Cilium assigns a security identity to groups of application containers which share identical security policies. The identity is then associated with all network packets emitted by the application containers, allowing to validate the identity at the receiving node.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Identity-based security&lt;/strong&gt; removes reliance on brittle IP addresses.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;L3/L4 policies&lt;/strong&gt; restrict traffic based on labels, protocols, and ports.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;DNS-based policies:&lt;/strong&gt; Allow or deny traffic to FQDNs or wildcard domains (e.g., &lt;code&gt;api.example.com&lt;/code&gt;, &lt;code&gt;*.trusted.com&lt;/code&gt;). This is especially useful for securing egress traffic to third-party services.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;L7-aware policies&lt;/strong&gt; allow filtering by HTTP method, URL path, gRPC call, and more:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;Example: Allow only GET requests to &lt;code&gt;/public/.*&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;Enforce the presence of headers like &lt;code&gt;X-Token: [0-9]+&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;CIDR-based egress and ingress policies are also supported for controlling access to external IPs, ideal for integrating with legacy systems or regulatory boundaries.&lt;/p&gt; 
&lt;h2&gt;Service Mesh&lt;/h2&gt; 
&lt;p&gt;With Cilium &lt;code&gt;Service Mesh &amp;lt;https://cilium.io/use-cases/service-mesh/&amp;gt;&lt;/code&gt;_, operators gain the benefits of fine-grained traffic control, encryption, observability, access control, without the cost and complexity of traditional proxy-based designs. Key features include:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Mutual authentication&lt;/strong&gt; with automatic identity-based encryption between workloads using IPSec or WireGuard.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;L7-aware policy enforcement&lt;/strong&gt; for security and compliance.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Deep integration with the Kubernetes Gateway API :&lt;/strong&gt; Acts as a &lt;code&gt;Gateway API &amp;lt;https://cilium.io/use-cases/gateway-api/&amp;gt;&lt;/code&gt;_ compliant data plane, allowing you to declaratively manage ingress, traffic splitting, and routing behavior using Kubernetes-native CRDs.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Observability and Troubleshooting&lt;/h2&gt; 
&lt;p&gt;Observability is built into Cilium from the ground up, providing rich visibility that helps operators diagnose and understand system behavior including:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Hubble&lt;/strong&gt;: A fully integrated observability platform that offers real-time service maps, flow visibility with identity and label metadata, and DNS-aware filtering and protocol-specific insights&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Metrics and alerting&lt;/strong&gt;: Integration with Prometheus, Grafana, and other monitoring systems.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Drop reasons and audit trails&lt;/strong&gt;: Get actionable insights into why traffic was dropped, including policy or port violations and issues like failed DNS lookups.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;.. end-functionality-overview&lt;/p&gt; 
&lt;h1&gt;Getting Started&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;Why Cilium?&lt;/code&gt;_&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;Getting Started&lt;/code&gt;_&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;Architecture and Concepts&lt;/code&gt;_&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;Installing Cilium&lt;/code&gt;_&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;Frequently Asked Questions&lt;/code&gt;_&lt;/li&gt; 
 &lt;li&gt;Contributing_&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Community&lt;/h1&gt; 
&lt;h2&gt;Slack&lt;/h2&gt; 
&lt;p&gt;Join the Cilium &lt;code&gt;Slack channel &amp;lt;https://slack.cilium.io&amp;gt;&lt;/code&gt;_ to chat with Cilium developers and other Cilium users. This is a good place to learn about Cilium, ask questions, and share your experiences.&lt;/p&gt; 
&lt;h2&gt;Special Interest Groups (SIG)&lt;/h2&gt; 
&lt;p&gt;See &lt;code&gt;Special Interest groups &amp;lt;https://github.com/cilium/community/blob/main/sigs.yaml&amp;gt;&lt;/code&gt;_ for a list of all SIGs and their meeting times.&lt;/p&gt; 
&lt;h2&gt;Developer meetings&lt;/h2&gt; 
&lt;p&gt;The Cilium developer community hangs out on Zoom to chat. Everybody is welcome.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Weekly, Wednesday, 5:00 pm &lt;code&gt;Europe/Zurich time &amp;lt;https://time.is/Canton_of_Zurich&amp;gt;&lt;/code&gt;__ (CET/CEST), usually equivalent to 8:00 am PT, or 11:00 am ET. &lt;code&gt;Meeting Notes and Zoom Info&lt;/code&gt;_&lt;/li&gt; 
 &lt;li&gt;Third Wednesday of each month, 9:00 am &lt;code&gt;Japan time &amp;lt;https://time.is/Tokyo&amp;gt;&lt;/code&gt;__ (JST). &lt;code&gt;APAC Meeting Notes and Zoom Info&lt;/code&gt;_&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;eBPF &amp;amp; Cilium Office Hours livestream&lt;/h2&gt; 
&lt;p&gt;We host a weekly community &lt;code&gt;YouTube livestream called eCHO &amp;lt;https://www.youtube.com/channel/UCJFUxkVQTBJh3LD1wYBWvuQ&amp;gt;&lt;/code&gt;_ which (very loosely!) stands for eBPF &amp;amp; Cilium Office Hours. Join us live, catch up with past episodes, or head over to the &lt;code&gt;eCHO repo &amp;lt;https://github.com/isovalent/eCHO&amp;gt;&lt;/code&gt;_ and let us know your ideas for topics we should cover.&lt;/p&gt; 
&lt;h2&gt;Governance&lt;/h2&gt; 
&lt;p&gt;The Cilium project is governed by a group of &lt;code&gt;Maintainers and Committers &amp;lt;https://raw.githubusercontent.com/cilium/cilium/main/MAINTAINERS.md&amp;gt;&lt;/code&gt;&lt;strong&gt;. How they are selected and govern is outlined in our &lt;code&gt;governance document &amp;lt;https://github.com/cilium/community/blob/main/GOVERNANCE.md&amp;gt;&lt;/code&gt;&lt;/strong&gt;.&lt;/p&gt; 
&lt;h2&gt;Adopters&lt;/h2&gt; 
&lt;p&gt;A list of adopters of the Cilium project who are deploying it in production, and of their use cases, can be found in file &lt;code&gt;USERS.md &amp;lt;https://github.com/cilium/cilium/blob/main/USERS.md&amp;gt;&lt;/code&gt;__.&lt;/p&gt; 
&lt;h1&gt;License&lt;/h1&gt; 
&lt;p&gt;.. _apache-license: LICENSE .. _bsd-license: bpf/LICENSE.BSD-2-Clause .. _gpl-license: bpf/LICENSE.GPL-2.0&lt;/p&gt; 
&lt;p&gt;The Cilium user space components are licensed under the &lt;code&gt;Apache License, Version 2.0 &amp;lt;apache-license_&amp;gt;&lt;/code&gt;&lt;strong&gt;. The BPF code templates are dual-licensed under the &lt;code&gt;General Public License, Version 2.0 (only) &amp;lt;gpl-license_&amp;gt;&lt;/code&gt;&lt;/strong&gt; and the &lt;code&gt;2-Clause BSD License &amp;lt;bsd-license_&amp;gt;&lt;/code&gt;__ (you can use the terms of either license, at your option).&lt;/p&gt; 
&lt;p&gt;.. _&lt;code&gt;Cilium Upgrade Guide&lt;/code&gt;: &lt;a href="https://docs.cilium.io/en/stable/operations/upgrade/"&gt;https://docs.cilium.io/en/stable/operations/upgrade/&lt;/a&gt; .. _&lt;code&gt;Why Cilium?&lt;/code&gt;: &lt;a href="https://docs.cilium.io/en/stable/overview/intro"&gt;https://docs.cilium.io/en/stable/overview/intro&lt;/a&gt; .. _&lt;code&gt;Getting Started&lt;/code&gt;: &lt;a href="https://docs.cilium.io/en/stable/#getting-started"&gt;https://docs.cilium.io/en/stable/#getting-started&lt;/a&gt; .. _&lt;code&gt;Architecture and Concepts&lt;/code&gt;: &lt;a href="https://docs.cilium.io/en/stable/overview/component-overview/"&gt;https://docs.cilium.io/en/stable/overview/component-overview/&lt;/a&gt; .. _&lt;code&gt;Installing Cilium&lt;/code&gt;: &lt;a href="https://docs.cilium.io/en/stable/gettingstarted/k8s-install-default/"&gt;https://docs.cilium.io/en/stable/gettingstarted/k8s-install-default/&lt;/a&gt; .. _&lt;code&gt;Frequently Asked Questions&lt;/code&gt;: &lt;a href="https://github.com/cilium/cilium/issues?utf8=%E2%9C%93&amp;amp;q=is%3Aissue+label%3Akind%2Fquestion+"&gt;https://github.com/cilium/cilium/issues?utf8=%E2%9C%93&amp;amp;q=is%3Aissue+label%3Akind%2Fquestion+&lt;/a&gt; .. _Contributing: &lt;a href="https://docs.cilium.io/en/stable/contributing/development/"&gt;https://docs.cilium.io/en/stable/contributing/development/&lt;/a&gt; .. _Prerequisites: &lt;a href="https://docs.cilium.io/en/stable/operations/system_requirements/"&gt;https://docs.cilium.io/en/stable/operations/system_requirements/&lt;/a&gt; .. _&lt;code&gt;eBPF&lt;/code&gt;: &lt;a href="https://ebpf.io"&gt;https://ebpf.io&lt;/a&gt; .. _&lt;code&gt;eBPF.io&lt;/code&gt;: &lt;a href="https://ebpf.io"&gt;https://ebpf.io&lt;/a&gt; .. _&lt;code&gt;Meeting Notes and Zoom Info&lt;/code&gt;: &lt;a href="https://docs.google.com/document/d/1Y_4chDk4rznD6UgXPlPvn3Dc7l-ZutGajUv1eF0VDwQ/edit#"&gt;https://docs.google.com/document/d/1Y_4chDk4rznD6UgXPlPvn3Dc7l-ZutGajUv1eF0VDwQ/edit#&lt;/a&gt; .. _&lt;code&gt;APAC Meeting Notes and Zoom Info&lt;/code&gt;: &lt;a href="https://docs.google.com/document/d/1egv4qLydr0geP-GjQexYKm4tz3_tHy-LCBjVQcXcT5M/edit#"&gt;https://docs.google.com/document/d/1egv4qLydr0geP-GjQexYKm4tz3_tHy-LCBjVQcXcT5M/edit#&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;.. |go-report| image:: &lt;a href="https://goreportcard.com/badge/github.com/cilium/cilium"&gt;https://goreportcard.com/badge/github.com/cilium/cilium&lt;/a&gt; :alt: Go Report Card :target: &lt;a href="https://goreportcard.com/report/github.com/cilium/cilium"&gt;https://goreportcard.com/report/github.com/cilium/cilium&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;.. |go-doc| image:: &lt;a href="https://godoc.org/github.com/cilium/cilium?status.svg"&gt;https://godoc.org/github.com/cilium/cilium?status.svg&lt;/a&gt; :alt: GoDoc :target: &lt;a href="https://godoc.org/github.com/cilium/cilium"&gt;https://godoc.org/github.com/cilium/cilium&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;.. |rtd| image:: &lt;a href="https://readthedocs.org/projects/docs/badge/?version=latest"&gt;https://readthedocs.org/projects/docs/badge/?version=latest&lt;/a&gt; :alt: Read the Docs :target: &lt;a href="https://docs.cilium.io/"&gt;https://docs.cilium.io/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;.. |apache| image:: &lt;a href="https://img.shields.io/badge/license-Apache-blue.svg"&gt;https://img.shields.io/badge/license-Apache-blue.svg&lt;/a&gt; :alt: Apache licensed :target: apache-license_&lt;/p&gt; 
&lt;p&gt;.. |bsd| image:: &lt;a href="https://img.shields.io/badge/license-BSD-blue.svg"&gt;https://img.shields.io/badge/license-BSD-blue.svg&lt;/a&gt; :alt: BSD licensed :target: bsd-license_&lt;/p&gt; 
&lt;p&gt;.. |gpl| image:: &lt;a href="https://img.shields.io/badge/license-GPL-blue.svg"&gt;https://img.shields.io/badge/license-GPL-blue.svg&lt;/a&gt; :alt: GPL licensed :target: gpl-license_&lt;/p&gt; 
&lt;p&gt;.. |slack| image:: &lt;a href="https://img.shields.io/badge/slack-cilium-brightgreen.svg?logo=slack"&gt;https://img.shields.io/badge/slack-cilium-brightgreen.svg?logo=slack&lt;/a&gt; :alt: Join the Cilium slack channel :target: &lt;a href="https://slack.cilium.io"&gt;https://slack.cilium.io&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;.. |cii| image:: &lt;a href="https://bestpractices.coreinfrastructure.org/projects/1269/badge"&gt;https://bestpractices.coreinfrastructure.org/projects/1269/badge&lt;/a&gt; :alt: CII Best Practices :target: &lt;a href="https://bestpractices.coreinfrastructure.org/projects/1269"&gt;https://bestpractices.coreinfrastructure.org/projects/1269&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;.. |clomonitor| image:: &lt;a href="https://img.shields.io/endpoint?url=https://clomonitor.io/api/projects/cncf/cilium/badge"&gt;https://img.shields.io/endpoint?url=https://clomonitor.io/api/projects/cncf/cilium/badge&lt;/a&gt; :alt: CLOMonitor :target: &lt;a href="https://clomonitor.io/projects/cncf/cilium"&gt;https://clomonitor.io/projects/cncf/cilium&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;.. |artifacthub| image:: &lt;a href="https://img.shields.io/endpoint?url=https://artifacthub.io/badge/repository/cilium"&gt;https://img.shields.io/endpoint?url=https://artifacthub.io/badge/repository/cilium&lt;/a&gt; :alt: Artifact Hub :target: &lt;a href="https://artifacthub.io/packages/helm/cilium/cilium"&gt;https://artifacthub.io/packages/helm/cilium/cilium&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;.. |fossa| image:: &lt;a href="https://app.fossa.com/api/projects/custom%2B162%2Fgit%40github.com%3Acilium%2Fcilium.git.svg?type=shield"&gt;https://app.fossa.com/api/projects/custom%2B162%2Fgit%40github.com%3Acilium%2Fcilium.git.svg?type=shield&lt;/a&gt; :alt: FOSSA Status :target: &lt;a href="https://app.fossa.com/projects/custom%2B162%2Fgit%40github.com%3Acilium%2Fcilium.git?ref=badge_shield"&gt;https://app.fossa.com/projects/custom%2B162%2Fgit%40github.com%3Acilium%2Fcilium.git?ref=badge_shield&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;.. |gateway-api| image:: &lt;a href="https://img.shields.io/badge/Gateway%20API%20Conformance%20v1.2.0-Cilium-green"&gt;https://img.shields.io/badge/Gateway%20API%20Conformance%20v1.2.0-Cilium-green&lt;/a&gt; :alt: Gateway API Status :target: &lt;a href="https://github.com/kubernetes-sigs/gateway-api/tree/main/conformance/reports/v1.2.0/cilium-cilium"&gt;https://github.com/kubernetes-sigs/gateway-api/tree/main/conformance/reports/v1.2.0/cilium-cilium&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;.. |codespaces| image:: &lt;a href="https://img.shields.io/badge/Open_in_GitHub_Codespaces-gray?logo=github"&gt;https://img.shields.io/badge/Open_in_GitHub_Codespaces-gray?logo=github&lt;/a&gt; :alt: Github Codespaces :target: &lt;a href="https://github.com/codespaces/new?hide_repo_select=true&amp;amp;ref=master&amp;amp;repo=48109239&amp;amp;machine=standardLinux32gb&amp;amp;location=WestEurope"&gt;https://github.com/codespaces/new?hide_repo_select=true&amp;amp;ref=master&amp;amp;repo=48109239&amp;amp;machine=standardLinux32gb&amp;amp;location=WestEurope&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>ArvinLovegood/go-stock</title>
      <link>https://github.com/ArvinLovegood/go-stock</link>
      <description>&lt;p&gt;ü¶Ñü¶Ñü¶ÑAIËµãËÉΩËÇ°Á•®ÂàÜÊûêÔºöAIÂä†ÊåÅÁöÑËÇ°Á•®ÂàÜÊûê/ÈÄâËÇ°Â∑•ÂÖ∑„ÄÇËÇ°Á•®Ë°åÊÉÖËé∑ÂèñÔºåAIÁÉ≠ÁÇπËµÑËÆØÂàÜÊûêÔºåAIËµÑÈáë/Ë¥¢Âä°ÂàÜÊûêÔºåÊ∂®Ë∑åÊä•Ë≠¶Êé®ÈÄÅ„ÄÇÊîØÊåÅAËÇ°ÔºåÊ∏ØËÇ°ÔºåÁæéËÇ°„ÄÇÊîØÊåÅÂ∏ÇÂú∫Êï¥‰Ωì/‰∏™ËÇ°ÊÉÖÁª™ÂàÜÊûêÔºåAIËæÖÂä©ÈÄâËÇ°Á≠â„ÄÇÊï∞ÊçÆÂÖ®ÈÉ®‰øùÁïôÂú®Êú¨Âú∞„ÄÇÊîØÊåÅDeepSeekÔºåOpenAIÔºå OllamaÔºåLMStudioÔºåAnythingLLMÔºåÁ°ÖÂü∫ÊµÅÂä®ÔºåÁÅ´Â±±ÊñπËàüÔºåÈòøÈáå‰∫ëÁôæÁÇºÁ≠âÂπ≥Âè∞ÊàñÊ®°Âûã„ÄÇ&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;go-stock : Âü∫‰∫éÂ§ßËØ≠Ë®ÄÊ®°ÂûãÁöÑAIËµãËÉΩËÇ°Á•®ÂàÜÊûêÂ∑•ÂÖ∑&lt;/h1&gt; 
&lt;h2&gt;&lt;img src="https://raw.githubusercontent.com/ArvinLovegood/go-stock/dev/build/appicon.png" alt="go-stock" /&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://img.shields.io/github/v/release/ArvinLovegood/go-stock?link=https%3A%2F%2Fgithub.com%2FArvinLovegood%2Fgo-stock%2Freleases&amp;amp;link=https%3A%2F%2Fgithub.com%2FArvinLovegood%2Fgo-stock%2Freleases" alt="GitHub Release" /&gt; &lt;a href="https://github.com/ArvinLovegood/go-stock"&gt;&lt;img src="https://img.shields.io/github/stars/ArvinLovegood/go-stock?link=https%3A%2F%2Fgithub.com%2FArvinLovegood%2Fgo-stock" alt="GitHub Repo stars" /&gt;&lt;/a&gt; &lt;a href="https://gitee.com/arvinlovegood_admin/go-stock"&gt;&lt;img src="https://gitee.com/arvinlovegood_admin/go-stock/badge/star.svg?theme=dark" alt="star" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;üåüÂÖ¨‰ºóÂè∑&lt;/h3&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/ArvinLovegood/go-stock/dev/build/screenshot/%E6%89%AB%E7%A0%81_%E6%90%9C%E7%B4%A2%E8%81%94%E5%90%88%E4%BC%A0%E6%92%AD%E6%A0%B7%E5%BC%8F-%E7%99%BD%E8%89%B2%E7%89%88.png" alt="Êâ´Á†Å_ÊêúÁ¥¢ËÅîÂêà‰º†Êí≠Ê†∑Âºè-ÁôΩËâ≤Áâà.png" /&gt;&lt;/p&gt; 
&lt;h3&gt;üìà ‰∫§ÊµÅÁæ§&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;QQ‰∫§ÊµÅÁæ§Ôºö&lt;a href="http://qm.qq.com/cgi-bin/qm/qr?_wv=1027&amp;amp;k=0YQ8qD3exahsD4YLNhzQTWe5ssstWC89&amp;amp;authKey=usOMMRFtIQDC%2FYcatHYapcxQbJ7PwXPHK9OypTXWzNjAq%2FRVvQu9bj2lRgb%2BSZ3p&amp;amp;noverify=0&amp;amp;group_code=491605333"&gt;ÁÇπÂáªÈìæÊé•Âä†ÂÖ•Áæ§ËÅä„Äêgo-stock‰∫§ÊµÅÁæ§„ÄëÔºö491605333(ÂÆöÊúüÊ∏ÖÁêÜÔºåÈöèÁºòÂÖ•Áæ§)&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;‚ú® ÁÆÄ‰ªã&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Êú¨È°πÁõÆÂü∫‰∫éWailsÂíåNaiveUIÂºÄÂèëÔºåÁªìÂêàAIÂ§ßÊ®°ÂûãÊûÑÂª∫ÁöÑËÇ°Á•®ÂàÜÊûêÂ∑•ÂÖ∑„ÄÇ&lt;/li&gt; 
 &lt;li&gt;ÁõÆÂâçÂ∑≤ÊîØÊåÅAËÇ°ÔºåÊ∏ØËÇ°ÔºåÁæéËÇ°ÔºåÊú™Êù•ËÆ°ÂàíÂä†ÂÖ•Âü∫ÈáëÔºåETFÁ≠âÊîØÊåÅ„ÄÇ&lt;/li&gt; 
 &lt;li&gt;ÊîØÊåÅÂ∏ÇÂú∫Êï¥‰Ωì/‰∏™ËÇ°ÊÉÖÁª™ÂàÜÊûêÔºåKÁ∫øÊäÄÊúØÊåáÊ†áÂàÜÊûêÁ≠âÂäüËÉΩ„ÄÇ&lt;/li&gt; 
 &lt;li&gt;Êú¨È°πÁõÆ‰ªÖ‰æõÂ®±‰πêÔºå‰∏çÂñúÂãøÂñ∑ÔºåAIÂàÜÊûêËÇ°Á•®ÁªìÊûú‰ªÖ‰æõÂ≠¶‰π†Á†îÁ©∂ÔºåÊäïËµÑÊúâÈ£éÈô©ÔºåËØ∑Ë∞®ÊÖé‰ΩøÁî®„ÄÇ&lt;/li&gt; 
 &lt;li&gt;ÂºÄÂèëÁéØÂ¢É‰∏ªË¶ÅÂü∫‰∫éWindows10+ÔºåÂÖ∂‰ªñÂπ≥Âè∞Êú™ÊµãËØïÊàñÂäüËÉΩÂèóÈôê„ÄÇ&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üì¶ Á´ãÂç≥‰ΩìÈ™å&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;ÁªøËâ≤ÁâàÔºö&lt;a href="https://github.com/ArvinLovegood/go-stock/releases"&gt;go-stock-windows-amd64.exe&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;MACOSÁªøËâ≤ÁâàÔºö&lt;a href="https://github.com/ArvinLovegood/go-stock/releases"&gt;go-stock-darwin-universal&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üí¨ ÊîØÊåÅÂ§ßÊ®°Âûã/Âπ≥Âè∞&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Ê®°Âûã&lt;/th&gt; 
   &lt;th&gt;Áä∂ÊÄÅ&lt;/th&gt; 
   &lt;th&gt;Â§áÊ≥®&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://platform.openai.com/"&gt;OpenAI&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;ÂèØÊé•ÂÖ•‰ªª‰Ωï OpenAI Êé•Âè£Ê†ºÂºèÊ®°Âûã&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://ollama.com/"&gt;Ollama&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;Êú¨Âú∞Â§ßÊ®°ÂûãËøêË°åÂπ≥Âè∞&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://lmstudio.ai/"&gt;LMStudio&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;Êú¨Âú∞Â§ßÊ®°ÂûãËøêË°åÂπ≥Âè∞&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://anythingllm.com/"&gt;AnythingLLM&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;Êú¨Âú∞Áü•ËØÜÂ∫ì&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://www.deepseek.com/"&gt;DeepSeek&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;deepseek-reasoner,deepseek-chat&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://cloud.siliconflow.cn/i/foufCerk"&gt;Â§ßÊ®°ÂûãËÅöÂêàÂπ≥Âè∞&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;Â¶ÇÔºö&lt;a href="https://cloud.siliconflow.cn/i/foufCerk"&gt;Á°ÖÂü∫ÊµÅÂä®&lt;/a&gt;Ôºå&lt;a href="https://www.volcengine.com/experience/ark?utm_term=202502dsinvite&amp;amp;ac=DSASUQY5&amp;amp;rc=IJSE43PZ"&gt;ÁÅ´Â±±ÊñπËàü&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;&lt;span style="color: #568DF4;"&gt;ÂêÑ‰Ωç‰∫≤Áà±ÁöÑÊúãÂèã‰ª¨ÔºåÂ¶ÇÊûúÊÇ®ÂØπËøô‰∏™È°πÁõÆÊÑüÂÖ¥Ë∂£ÔºåËØ∑ÂÖàÁªôÊàë‰∏Ä‰∏™&lt;i style="color: #EA2626;"&gt;star&lt;/i&gt;ÂêßÔºåË∞¢Ë∞¢ÔºÅ&lt;/span&gt;üíï&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;ÁÅ´Â±±ÊñπËàüÔºöÊñ∞Áî®Êà∑ÊØè‰∏™Ê®°ÂûãÊ≥®ÂÜåÂç≥ÈÄÅ50‰∏átokensÔºå&lt;a href="https://www.volcengine.com/experience/ark?utm_term=202502dsinvite&amp;amp;ac=DSASUQY5&amp;amp;rc=IJSE43PZ"&gt;Ê≥®ÂÜåÈìæÊé•&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Á°ÖÂü∫ÊµÅÂä®(siliconflow)ÔºåÊ≥®ÂÜåÂç≥ÈÄÅ2000‰∏áTokensÔºå&lt;a href="https://cloud.siliconflow.cn/i/foufCerk"&gt;Ê≥®ÂÜåÈìæÊé•&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;TushareÂ§ßÊï∞ÊçÆÂºÄÊîæÁ§æÂå∫,ÂÖçË¥πÊèê‰æõÂêÑÁ±ªÈáëËûçÊï∞ÊçÆ,Âä©ÂäõË°å‰∏öÂíåÈáèÂåñÁ†îÁ©∂(Ê≥®ÊÑèÔºöTushareÂè™ÈúÄË¶Å120ÁßØÂàÜÂç≥ÂèØÔºåÊ≥®ÂÜåÂÆåÊàê‰∏™‰∫∫ËµÑÊñôË°•ÂÖÖÂç≥ÂèØÂæó120ÁßØÂàÜÔºÅÔºÅÔºÅ)Ôºå&lt;a href="https://tushare.pro/register?reg=701944"&gt;Ê≥®ÂÜåÈìæÊé•&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;ËΩØ‰ª∂Âø´ÈÄüËø≠‰ª£ÂºÄÂèë‰∏≠,ËØ∑Â§ßÂÆ∂‰ºòÂÖàÊµãËØïÂíå‰ΩøÁî®ÊúÄÊñ∞ÂèëÂ∏ÉÁöÑÁâàÊú¨„ÄÇ&lt;/li&gt; 
 &lt;li&gt;Ê¨¢ËøéÂ§ßÂÆ∂ÊèêÂá∫ÂÆùË¥µÁöÑÂª∫ËÆÆÔºåÊ¨¢ËøéÊèêissue,PR„ÄÇÂΩìÁÑ∂Êõ¥Ê¨¢Ëøé&lt;a href="https://raw.githubusercontent.com/ArvinLovegood/go-stock/dev/#%E9%83%BD%E5%88%92%E5%88%B0%E8%BF%99%E4%BA%86%E5%A6%82%E6%9E%9C%E6%88%91%E7%9A%84%E9%A1%B9%E7%9B%AE%E5%AF%B9%E6%82%A8%E6%9C%89%E5%B8%AE%E5%8A%A9%E8%AF%B7%E8%B5%9E%E5%8A%A9%E6%88%91%E5%90%A7"&gt;ËµûÂä©Êàë&lt;/a&gt;„ÄÇüíï&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;ÊîØÊåÅÂºÄÊ∫êüíïËÆ°Âàí&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;ËµûÂä©ËÆ°Âàí&lt;/th&gt; 
   &lt;th&gt;ËµûÂä©Á≠âÁ∫ß&lt;/th&gt; 
   &lt;th align="left"&gt;ÊùÉÁõäËØ¥Êòé&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;ÊØèÊúà 0 RMB&lt;/td&gt; 
   &lt;td&gt;vip0&lt;/td&gt; 
   &lt;td align="left"&gt;üåü ÂÖ®ÈÉ®ÂäüËÉΩ,ËΩØ‰ª∂Ëá™Âä®Êõ¥Êñ∞(‰ªéGitHub‰∏ãËΩΩ),Ëá™Ë°åËß£ÂÜ≥githubÂπ≥Âè∞ÁΩëÁªúÈóÆÈ¢ò„ÄÇ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;ÊØèÊúàËµûÂä© 18.8 RMB&lt;br /&gt;ÊØèÂπ¥ËµûÂä© 120 RMB&lt;/td&gt; 
   &lt;td&gt;vip1&lt;/td&gt; 
   &lt;td align="left"&gt;üíï ÂÖ®ÈÉ®ÂäüËÉΩ,ËΩØ‰ª∂Ëá™Âä®Êõ¥Êñ∞(‰ªéCDN‰∏ãËΩΩ),Êõ¥Êñ∞Âø´ÈÄü‰æøÊç∑„ÄÇAIÈÖçÁΩÆÊåáÂØºÔºåÊèêÁ§∫ËØçÂèÇËÄÉÁ≠â&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;ÊØèÊúàËµûÂä© 28.8 RMB&lt;br /&gt;ÊØèÂπ¥ËµûÂä© 240 RMB&lt;/td&gt; 
   &lt;td&gt;vip2&lt;/td&gt; 
   &lt;td align="left"&gt;üíï üíï vip1ÂÖ®ÈÉ®ÂäüËÉΩ,Ëµ†ÈÄÅÁ°ÖÂü∫ÊµÅÂä®AIÂàÜÊûêÊúçÂä°,ÂêØÂä®Êó∂Ëá™Âä®ÂêåÊ≠•ÊúÄËøë24Â∞èÊó∂Â∏ÇÂú∫ËµÑËÆØ(ÂåÖÊã¨Â§ñÂ™íÁÆÄËÆØ)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;ÊØèÊúàËµûÂä© X RMB&lt;/td&gt; 
   &lt;td&gt;vipX&lt;/td&gt; 
   &lt;td align="left"&gt;üß© Êõ¥Â§öËÆ°ÂàíÔºåËßÜgo-stockÂºÄÊ∫êÈ°πÁõÆÂèëÂ±ïÊÉÖÂÜµËÄåÂÆö...(ÊâøÊé•GitHubÈ°πÁõÆREADMEÂπøÂëäÊé®Âπøüíñ)&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;üß© ÈáçÂ§ßÂäüËÉΩÂºÄÂèëËÆ°Âàí&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;ÂäüËÉΩËØ¥Êòé&lt;/th&gt; 
   &lt;th&gt;Áä∂ÊÄÅ&lt;/th&gt; 
   &lt;th&gt;Â§áÊ≥®&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ËÇ°Á•®ÂàÜÊûêÁü•ËØÜÂ∫ì&lt;/td&gt; 
   &lt;td&gt;üöß&lt;/td&gt; 
   &lt;td&gt;Êú™Êù•ËÆ°Âàí&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;AiÊô∫ËÉΩÈÄâËÇ°&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;AiÊô∫ËÉΩÈÄâËÇ°ÂäüËÉΩ(Â∏ÇÂú∫Ë°åÊÉÖ-„ÄãAIÊÄªÁªì/AIÊô∫ËÉΩ‰ΩìÂäüËÉΩ)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ETFÊîØÊåÅ&lt;/td&gt; 
   &lt;td&gt;üöß&lt;/td&gt; 
   &lt;td&gt;ETFÊï∞ÊçÆÊîØÊåÅ (ÁõÆÂâçÂèØ‰ª•Êü•ÁúãÂáÄÂÄºÂíå‰º∞ÂÄº)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ÁæéËÇ°ÊîØÊåÅ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;ÁæéËÇ°Êï∞ÊçÆÊîØÊåÅ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Ê∏ØËÇ°ÊîØÊåÅ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;Ê∏ØËÇ°Êï∞ÊçÆÊîØÊåÅ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Â§öËΩÆÂØπËØù&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;AIÂàÜÊûêÂêéÂèØÁªßÁª≠ÂØπËØùÊèêÈóÆ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Ëá™ÂÆö‰πâAIÂàÜÊûêÊèêÈóÆÊ®°Êùø&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;ÂèØÈÖçÁΩÆÁöÑÊèêÈóÆÊ®°Êùø &lt;a href="https://github.com/ArvinLovegood/go-stock/releases/tag/v2025.2.12.7-alpha"&gt;v2025.2.12.7-alpha&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;‰∏çÂÜçÂº∫Âà∂‰æùËµñChromeÊµèËßàÂô®&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;ÈªòËÆ§‰ΩøÁî®edgeÊµèËßàÂô®ÊäìÂèñÊñ∞ÈóªËµÑËÆØ&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;üëÄ Êõ¥Êñ∞Êó•Âøó&lt;/h2&gt; 
&lt;h3&gt;2025.12.16 Êñ∞Â¢ûAIÊÄùËÄÉÊ®°Âºè‰∏éÁÉ≠Èó®ÈÄâËÇ°Á≠ñÁï•ÂäüËÉΩ&lt;/h3&gt; 
&lt;h3&gt;2025.11.21 Êñ∞Â¢ûÂ∏¶È¢ëÁéáÊùÉÈáçÁöÑÊÉÖÊÑüÂàÜÊûêÂäüËÉΩ&lt;/h3&gt; 
&lt;h3&gt;2025.10.30 Ê∑ªÂä†AIÊô∫ËÉΩ‰ΩìÂäüËÉΩÂºÄÂÖ≥(ÈªòËÆ§ÂÖ≥Èó≠ÔºåÂõ†‰∏∫‰ΩøÁî®‰ΩìÈ™å‰∏çÁêÜÊÉ≥)ÔºåÁßªÈô§È°µÈù¢Ê∞¥Âç∞&lt;/h3&gt; 
&lt;h3&gt;2025.09.27 Ê∑ªÂä†Êú∫ÊûÑ/Âà∏ÂïÜÁöÑÁ†îÁ©∂Êä•ÂëäAIÂ∑•ÂÖ∑ÂáΩÊï∞&lt;/h3&gt; 
&lt;h3&gt;2025.08.09 Ê∑ªÂä†AIÊô∫ËÉΩ‰ΩìËÅäÂ§©ÂäüËÉΩ&lt;/h3&gt; 
&lt;h3&gt;2025.07.08 ÂÆûÁé∞ËΩØ‰ª∂Ëá™Âä®Êõ¥Êñ∞ÂäüËÉΩ&lt;/h3&gt; 
&lt;h3&gt;2025.07.07 Âç°ÁâáÊ∑ªÂä†Ëø∑‰Ω†ÂàÜÊó∂Âõæ&lt;/h3&gt; 
&lt;h3&gt;2025.07.05 MacOsÊîØÊåÅ&lt;/h3&gt; 
&lt;h3&gt;2025.07.01 AIÂàÜÊûêÈõÜÊàêÂ∑•ÂÖ∑ÂáΩÊï∞ÔºåAIÂàÜÊûêÂ∞ÜÊõ¥Âä†Êô∫ËÉΩ&lt;/h3&gt; 
&lt;h3&gt;2025.06.30 Ê∑ªÂä†ÊåáÊ†áÈÄâËÇ°ÂäüËÉΩ&lt;/h3&gt; 
&lt;h3&gt;2025.06.27 Ê∑ªÂä†Ë¥¢ÁªèÊó•ÂéÜÂíåÈáçÂ§ß‰∫ã‰ª∂Êó∂Èó¥ËΩ¥ÂäüËÉΩ&lt;/h3&gt; 
&lt;h3&gt;2025.06.25 Ê∑ªÂä†ÁÉ≠Èó®ËÇ°Á•®„ÄÅ‰∫ã‰ª∂ÂíåËØùÈ¢òÂäüËÉΩ&lt;/h3&gt; 
&lt;h3&gt;2025.06.18 Êõ¥Êñ∞ÂÜÖÁΩÆËÇ°Á•®Âü∫Á°ÄÊï∞ÊçÆ,ËΩØ‰ª∂ÂÜÖÂÆûÊó∂Â∏ÇÂú∫ËµÑËÆØ‰ø°ÊÅØÊèêÈÜíÔºåÊ∑ªÂä†Ë°å‰∏öÁ†îÁ©∂ÂäüËÉΩ&lt;/h3&gt; 
&lt;h3&gt;2025.06.15 Ê∑ªÂä†ÂÖ¨Âè∏ÂÖ¨Âëä‰ø°ÊÅØÊêúÁ¥¢/Êü•ÁúãÂäüËÉΩ&lt;/h3&gt; 
&lt;h3&gt;2025.06.15 Ê∑ªÂä†‰∏™ËÇ°Á†îÊä•Âà∞ÂºπÂá∫ËèúÂçï&lt;/h3&gt; 
&lt;h3&gt;2025.06.13 Ê∑ªÂä†‰∏™ËÇ°Á†îÊä•ÂäüËÉΩ&lt;/h3&gt; 
&lt;h3&gt;2025.06.12 Ê∑ªÂä†ÈæôËôéÊ¶úÂäüËÉΩÔºåÊñ∞Â¢ûË°å‰∏öÊéíÂêçÂàÜÁ±ª&lt;/h3&gt; 
&lt;h3&gt;2025.05.30 ‰ºòÂåñËÇ°Á•®ÂàÜÊó∂ÂõæÊòæÁ§∫&lt;/h3&gt; 
&lt;h3&gt;2025.05.20 ‰øÆÂ§çË¥¢ËÅîÁ§æÁîµÊä•Ëé∑ÂèñÈóÆÈ¢ò&lt;/h3&gt; 
&lt;h3&gt;2025.05.16 ‰ºòÂåñËµÑÈáëË∂ãÂäøÂõæË°®ÁªÑ‰ª∂&lt;/h3&gt; 
&lt;h3&gt;2025.05.15 ÈáçÊûÑÂ∫îÁî®Âä†ËΩΩÂíåÊï∞ÊçÆÂàùÂßãÂåñÈÄªËæëÔºåÊ∑ªÂä†ËÇ°Á•®ËµÑÈáëË∂ãÂäøÂäüËÉΩÔºåËµÑÈáëË∂ãÂäøÂõæË°®Â¢ûÂä†‰∏ªÂäõÂΩìÊó•ÂáÄÊµÅÂÖ•Êï∞ÊçÆÂπ∂‰ºòÂåñÂ±ïÁ§∫ÊïàÊûú&lt;/h3&gt; 
&lt;h3&gt;2025.05.14 Ê∑ªÂä†‰∏™ËÇ°ËµÑÈáëÊµÅÂêëÂäüËÉΩÔºåÊéíË°åÊ¶úÂ¢ûÂä†ËÇ°Á•®Ë°åÊÉÖKÁ∫øÂõæÂºπÁ™ó&lt;/h3&gt; 
&lt;h3&gt;2025.05.13 Ê∑ªÂä†Ë°å‰∏öÊéíÂêçÂäüËÉΩ&lt;/h3&gt; 
&lt;h3&gt;2025.05.09 Ê∑ªÂä†AËÇ°ÁõòÂè£Êï∞ÊçÆËß£ÊûêÂíåÂ±ïÁ§∫ÂäüËÉΩ&lt;/h3&gt; 
&lt;h3&gt;2025.05.07 ‰ºòÂåñÂàÜÊó∂ÂõæÁöÑÂ±ïÁ§∫&lt;/h3&gt; 
&lt;h3&gt;2025.04.29 Ë°•ÂÖ®Ê∏ØËÇ°/ÁæéËÇ°Âü∫Á°ÄÊï∞ÊçÆÔºå‰ºòÂåñÊ∏ØËÇ°ËÇ°‰ª∑Âª∂ËøüÈóÆÈ¢òÔºå‰ºòÂåñÂàùÂßãÂåñÈÄªËæë&lt;/h3&gt; 
&lt;h3&gt;2025.04.25 Â∏ÇÂú∫ËµÑËÆØÊîØÊåÅAIÂàÜÊûêÂíåÊÄªÁªìÔºöËÆ©AIÂ∏Æ‰Ω†ËØªÂ∏ÇÂú∫ÔºÅ&lt;/h3&gt; 
&lt;h3&gt;2025.04.24 Êñ∞Â¢ûÂ∏ÇÂú∫Ë°åÊÉÖÊ®°ÂùóÔºöÂç≥Êó∂ÊéåÊè°ÂÖ®ÁêÉÂ∏ÇÂú∫Ë°åÊÉÖËµÑËÆØ/Âä®ÊÄÅÔºå‰ªéÊ≠§ÂÜç‰πü‰∏çÁî®ÂÅ∑Êë∏ÂéªÂêÑÂ§ßË¥¢ÁªèÁΩëÁ´ôÂï¶„ÄÇgo-stock‰∏ÄÈîÆÂ∏Æ‰Ω†ÊêûÂÆöÔºÅ&lt;/h3&gt; 
&lt;h3&gt;2025.04.22 ‰ºòÂåñKÁ∫øÂõæÂ±ïÁ§∫ÔºåÊîØÊåÅÊãâ‰º∏ÊîæÂ§ßÔºåÁúãÂæóÊõ¥ËàíÊúçÂï¶ÔºÅ&lt;/h3&gt; 
&lt;h3&gt;2025.04.21 Ê∏ØËÇ°ÔºåÁæéËÇ°KÁ∫øÊï∞ÊçÆËé∑Âèñ‰ºòÂåñ&lt;/h3&gt; 
&lt;h3&gt;2025.04.01 ‰ºòÂåñÈÉ®ÂàÜËÆæÁΩÆÈÄâÈ°πÔºåÈÅøÂÖçÈáçÂêØËΩØ‰ª∂&lt;/h3&gt; 
&lt;h3&gt;2025.03.31 ‰ºòÂåñÊï∞ÊçÆÁà¨Âèñ&lt;/h3&gt; 
&lt;h3&gt;2025.03.30 AIËá™Âä®ÂÆöÊó∂ÂàÜÊûêÂäüËÉΩ&lt;/h3&gt; 
&lt;h3&gt;2025.03.29 Â§öÊèêÁ§∫ËØçÊ®°ÊùøÁÆ°ÁêÜÔºåAIÂàÜÊûêÊó∂ÊîØÊåÅÈÄâÊã©‰∏çÂêåÊèêÁ§∫ËØçÊ®°Êùø&lt;/h3&gt; 
&lt;h3&gt;2025.03.28 AIÂàÜÊûêÁªìÊûú‰øùÂ≠ò‰∏∫markdownÊñá‰ª∂Êó∂ÔºåÊîØÊåÅ‰øùÂ≠ò‰ΩçÁΩÆÁõÆÂΩïÈÄâÊã©&lt;/h3&gt; 
&lt;h3&gt;2025.03.15 Ëá™ÂÆö‰πâÁà¨Ëô´‰ΩøÁî®ÁöÑÊµèËßàÂô®Ë∑ØÂæÑÈÖçÁΩÆ&lt;/h3&gt; 
&lt;h3&gt;2025.03.14 ‰ºòÂåñÁºñËØëÊûÑÂª∫ÔºåÂ§ßÂπÖÂáèÂ∞ëÁºñËØëÂêéÁöÑÁ®ãÂ∫èÊñá‰ª∂Â§ßÂ∞è&lt;/h3&gt; 
&lt;h3&gt;2025.03.09 Âü∫Èáë‰º∞ÂÄºÂíåÂáÄÂÄºÁõëÊéßÊü•Áúã&lt;/h3&gt; 
&lt;h3&gt;2025.03.06 È°πÁõÆÁ§æÂå∫ÂàÜ‰∫´ÂäüËÉΩ&lt;/h3&gt; 
&lt;h3&gt;2025.02.28 ÁæéËÇ°Êï∞ÊçÆÊîØÊåÅ&lt;/h3&gt; 
&lt;h3&gt;2025.02.23 ÂºπÂπïÂäüËÉΩÔºåÁõØÁõò‰∏çÂÜçÂ≠§ÂçïÔºåÊó†ËÅäÂàí‰∏™Ê∞¥ÔºÅüòé&lt;/h3&gt; 
&lt;h3&gt;2025.02.22 Ê∏ØËÇ°Êï∞ÊçÆÊîØÊåÅ(ÁõÆÂâçÊúâÂª∂Ëøü)&lt;/h3&gt; 
&lt;h3&gt;2025.02.16 AIÂàÜÊûêÂêéÂèØÁªßÁª≠ÂØπËØùÊèêÈóÆ&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ArvinLovegood/go-stock/releases/tag/v2025.2.16.1-alpha"&gt;v2025.2.16.1-alpha&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;2025.02.12 ÂèØÈÖçÁΩÆÁöÑÊèêÈóÆÊ®°Êùø&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ArvinLovegood/go-stock/releases/tag/v2025.2.12.7-alpha"&gt;v2025.2.12.7-alpha&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ü¶Ñ ÈáçÂ§ßÊõ¥Êñ∞&lt;/h2&gt; 
&lt;h3&gt;BIG NEWS !!! ÈáçÂ§ßÊõ¥Êñ∞ÔºÅÔºÅÔºÅ&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;2025.11.21 Êñ∞Â¢ûÂ∏¶È¢ëÁéáÊùÉÈáçÁöÑÊÉÖÊÑüÂàÜÊûêÂäüËÉΩ &lt;img src="https://raw.githubusercontent.com/ArvinLovegood/go-stock/dev/build/screenshot/img15.png" alt="img_1.png" /&gt;&lt;/li&gt; 
 &lt;li&gt;2025.04.25 Â∏ÇÂú∫ËµÑËÆØÊîØÊåÅAIÂàÜÊûêÂíåÊÄªÁªìÔºöËÆ©AIÂ∏Æ‰Ω†ËØªÂ∏ÇÂú∫ÔºÅ &lt;img src="https://raw.githubusercontent.com/ArvinLovegood/go-stock/dev/img.png" alt="img.png" /&gt;&lt;/li&gt; 
 &lt;li&gt;2025.04.24 Êñ∞Â¢ûÂ∏ÇÂú∫Ë°åÊÉÖÊ®°ÂùóÔºöÂç≥Êó∂ÊéåÊè°ÂÖ®ÁêÉÂ∏ÇÂú∫Ë°åÊÉÖËµÑËÆØ/Âä®ÊÄÅÔºå‰ªéÊ≠§ÂÜç‰πü‰∏çÁî®ÂÅ∑Êë∏ÂéªÂêÑÂ§ßË¥¢ÁªèÁΩëÁ´ôÂï¶„ÄÇgo-stock‰∏ÄÈîÆÂ∏Æ‰Ω†ÊêûÂÆöÔºÅ &lt;img src="https://raw.githubusercontent.com/ArvinLovegood/go-stock/dev/build/screenshot/img13.png" alt="img.png" /&gt; &lt;img src="https://raw.githubusercontent.com/ArvinLovegood/go-stock/dev/build/screenshot/img_13.png" alt="img_13.png" /&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;img src="https://raw.githubusercontent.com/ArvinLovegood/go-stock/dev/build/screenshot/img_14.png" alt="img_14.png" /&gt;&lt;/li&gt; 
 &lt;li&gt;2025.01.17 Êñ∞Â¢ûAIÂ§ßÊ®°ÂûãÂàÜÊûêËÇ°Á•®ÂäüËÉΩ &lt;img src="https://raw.githubusercontent.com/ArvinLovegood/go-stock/dev/build/screenshot/img.png" alt="img_5.png" /&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üì∏ ÂäüËÉΩÊà™Âõæ&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/ArvinLovegood/go-stock/dev/build/screenshot/img_6.png" alt="img_1.png" /&gt;&lt;/p&gt; 
&lt;h3&gt;ËÆæÁΩÆ&lt;/h3&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/ArvinLovegood/go-stock/dev/build/screenshot/img_4.png" alt="img_12.png" /&gt;&lt;/p&gt; 
&lt;h3&gt;ÊàêÊú¨ËÆæÁΩÆ&lt;/h3&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/ArvinLovegood/go-stock/dev/build/screenshot/img_7.png" alt="img.png" /&gt;&lt;/p&gt; 
&lt;h3&gt;Êó•K&lt;/h3&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/ArvinLovegood/go-stock/dev/build/screenshot/img_12.png" alt="img_12.png" /&gt;&lt;/p&gt; 
&lt;h3&gt;ÂàÜÊó∂&lt;/h3&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/ArvinLovegood/go-stock/dev/build/screenshot/img_9.png" alt="img_3.png" /&gt;&lt;/p&gt; 
&lt;h3&gt;ÈíâÈíâÊä•Ë≠¶ÈÄöÁü•&lt;/h3&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/ArvinLovegood/go-stock/dev/build/screenshot/img_5.png" alt="img_4.png" /&gt;&lt;/p&gt; 
&lt;h3&gt;AIÂàÜÊûêËÇ°Á•®&lt;/h3&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/ArvinLovegood/go-stock/dev/build/screenshot/img.png" alt="img_5.png" /&gt;&lt;/p&gt; 
&lt;h3&gt;ÁâàÊú¨‰ø°ÊÅØÊèêÁ§∫&lt;/h3&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/ArvinLovegood/go-stock/dev/build/screenshot/img_11.png" alt="img_11.png" /&gt;&lt;/p&gt; 
&lt;h2&gt;üíï ÊÑüË∞¢‰ª•‰∏ãÈ°πÁõÆ&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.naiveui.com/"&gt;NaiveUI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://wails.io/"&gt;Wails&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://vuejs.org/"&gt;Vue&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://vitejs.dev/"&gt;Vite&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://tushare.pro/register?reg=701944"&gt;Tushare&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üòò ËµûÂä©Êàë&lt;/h2&gt; 
&lt;h3&gt;ÈÉΩÂàíÂà∞Ëøô‰∫ÜÔºåÂ¶ÇÊûúÊàëÁöÑÈ°πÁõÆÂØπÊÇ®ÊúâÂ∏ÆÂä©ÔºåËØ∑ËµûÂä©ÊàëÂêßÔºÅüòäüòäüòä&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;ÊîØ‰ªòÂÆù&lt;/th&gt; 
   &lt;th&gt;ÂæÆ‰ø°&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/ArvinLovegood/go-stock/dev/build/screenshot/alipay.jpg" alt="alipay.jpg" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/ArvinLovegood/go-stock/dev/build/screenshot/wxpay.jpg" alt="wxpay.jpg" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;‚≠ê Star History&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://star-history.com/#ArvinLovegood/go-stock&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=ArvinLovegood/go-stock&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;ü§ñ Áä∂ÊÄÅ&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://repobeats.axiom.co/api/embed/40b07d415a42c2264a18c4fe1b6f182ff1470687.svg?sanitize=true" alt="Alt" title="Repobeats analytics image" /&gt;&lt;/p&gt; 
&lt;h2&gt;üê≥ ÂÖ≥‰∫éÊäÄÊúØÊîØÊåÅÁî≥Êòé&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Êú¨ËΩØ‰ª∂Âü∫‰∫éÂºÄÊ∫êÊäÄÊúØÊûÑÂª∫Ôºå‰ΩøÁî®Wails„ÄÅNaiveUI„ÄÅVue„ÄÅAIÂ§ßÊ®°ÂûãÁ≠âÂºÄÊ∫êÈ°πÁõÆ„ÄÇ ÊäÄÊúØ‰∏äÂ¶ÇÊúâÈóÆÈ¢òÔºåÂèØ‰ª•ÂÖàÂêëÂØπÂ∫îÁöÑÂºÄÊ∫êÁ§æÂå∫ËØ∑Ê±ÇÂ∏ÆÂä©„ÄÇ&lt;/li&gt; 
 &lt;li&gt;ÂºÄÊ∫ê‰∏çÊòìÔºåÊú¨‰∫∫Á≤æÂäõÂíåÊó∂Èó¥ÊúâÈôêÔºåÂ¶ÇÈúÄ‰∏ÄÂØπ‰∏ÄÊäÄÊúØÊîØÊåÅÔºåËØ∑ÂÖàËµûÂä©„ÄÇËÅîÁ≥ªQQ(Â§áÊ≥® ÊäÄÊúØÊîØÊåÅ)Ôºö506808970&lt;/li&gt; 
&lt;/ul&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;ÊäÄÊúØÊîØÊåÅÊñπÂºè&lt;/th&gt; 
   &lt;th align="center"&gt;ËµûÂä©(ÂÖÉ)&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;Âä† QQÔºö506808970&lt;/td&gt; 
   &lt;td align="center"&gt;100/Ê¨°&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;ÈïøÊúüÊäÄÊúØÊîØÊåÅÔºà‰∏çÈôêÊ¨°Êï∞ÔºåÊñ∞ÂäüËÉΩ‰ºòÂÖà‰ΩìÈ™åÁ≠âÔºâ&lt;/td&gt; 
   &lt;td align="center"&gt;5000&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/ArvinLovegood/go-stock/dev/LICENSE"&gt;Apache License 2.0&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>gotenberg/gotenberg</title>
      <link>https://github.com/gotenberg/gotenberg</link>
      <description>&lt;p&gt;A developer-friendly API for converting numerous document formats into PDF files, and more!&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;img src="https://user-images.githubusercontent.com/8983173/130322857-185831e2-f041-46eb-a17f-0a69d066c4e5.png" alt="Gotenberg Logo" width="150" height="150" /&gt; &lt;/p&gt;
&lt;h3 align="center"&gt;Gotenberg&lt;/h3&gt; 
&lt;p align="center"&gt;A containerized API for seamless PDF conversion&lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://hub.docker.com/r/gotenberg/gotenberg"&gt;&lt;img alt="Total downloads (gotenberg/gotenberg)" src="https://img.shields.io/docker/pulls/gotenberg/gotenberg" /&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/r/thecodingmachine/gotenberg"&gt;&lt;img alt="Total downloads (thecodingmachine/gotenberg)" src="https://img.shields.io/docker/pulls/thecodingmachine/gotenberg" /&gt;&lt;/a&gt; &lt;a href="https://github.com/gotenberg/gotenberg/actions/workflows/continuous-integration.yml"&gt;&lt;img alt="Continuous Integration" src="https://github.com/gotenberg/gotenberg/actions/workflows/continuous-integration.yml/badge.svg?sanitize=true" /&gt;&lt;/a&gt; &lt;a href="https://pkg.go.dev/github.com/gotenberg/gotenberg/v8"&gt;&lt;img alt="Go Reference" src="https://pkg.go.dev/badge/github.com/gotenberg/gotenberg.svg?sanitize=true" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://trendshift.io/repositories/2996"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/2996" alt="gotenberg%2Fgotenberg | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt;&lt;a href="https://gotenberg.dev/docs/getting-started/introduction"&gt;Documentation&lt;/a&gt; ¬∑ &lt;a href="https://gotenberg.dev/docs/getting-started/installation#live-demo-"&gt;Live Demo&lt;/a&gt; üî•&lt;/p&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;strong&gt;Gotenberg&lt;/strong&gt; provides a developer-friendly API to interact with powerful tools like Chromium and LibreOffice for converting numerous document formats (HTML, Markdown, Word, Excel, etc.) into PDF files, and more!&lt;/p&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;p&gt;Open a terminal and run the following command:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;docker run --rm -p 3000:3000 gotenberg/gotenberg:8
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Alternatively, using the historic Docker repository from our sponsor &lt;a href="https://www.thecodingmachine.com"&gt;TheCodingMachine&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;docker run --rm -p 3000:3000 thecodingmachine/gotenberg:8
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The API is now available on your host at &lt;a href="http://localhost:3000"&gt;http://localhost:3000&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Head to the &lt;a href="https://gotenberg.dev/docs/getting-started/introduction"&gt;documentation&lt;/a&gt; to learn how to interact with it üöÄ&lt;/p&gt; 
&lt;h2&gt;Sponsors&lt;/h2&gt; 
&lt;p align="center"&gt; &lt;a href="https://thecodingmachine.com"&gt; &lt;img src="https://user-images.githubusercontent.com/8983173/130324668-9d6e7b35-53a3-49c7-a574-38190d2bd6b0.png" alt="TheCodingMachine Logo" width="333" height="163" /&gt; &lt;/a&gt; &lt;a href="https://pdfme.com?utm_source=gotenberg_github&amp;amp;utm_medium=website" target="_blank"&gt; &lt;img src="https://github.com/user-attachments/assets/2a75dd40-ca18-4d34-acd5-5dd474595168" alt="pdfme Logo" width="333" height="163" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p&gt;Sponsorships help maintain and improve Gotenberg - &lt;a href="https://github.com/sponsors/gulien"&gt;become a sponsor&lt;/a&gt; ‚ù§Ô∏è&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p align="center"&gt; &lt;strong&gt;Powered by&lt;/strong&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://jb.gg/OpenSource"&gt; &lt;img src="https://resources.jetbrains.com/storage/products/company/brand/logos/jetbrains.svg?sanitize=true" alt="JetBrains logo" width="200" /&gt; &lt;/a&gt; &lt;/p&gt;</description>
    </item>
    
    <item>
      <title>temporalio/temporal</title>
      <link>https://github.com/temporalio/temporal</link>
      <description>&lt;p&gt;Temporal service&lt;/p&gt;&lt;hr&gt;&lt;div class="title-block" style="text-align: center;" align="center"&gt; 
 &lt;h1&gt;Temporal‚Äîdurable execution platform&lt;/h1&gt; 
 &lt;p&gt;&lt;img title="temporal logo" src="https://avatars.githubusercontent.com/u/56493103?s=320" width="320" height="320" /&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://github.com/temporalio/temporal/releases/latest"&gt;&lt;img src="https://img.shields.io/github/v/release/temporalio/temporal" alt="GitHub Release" /&gt;&lt;/a&gt; &lt;a href="https://github.com/temporalio/temporal/raw/main/LICENSE"&gt;&lt;img src="https://img.shields.io/github/license/temporalio/temporal" alt="GitHub License" /&gt;&lt;/a&gt; &lt;a href="https://app.codecov.io/gh/temporalio/temporal"&gt;&lt;img src="https://img.shields.io/badge/codecov-report-blue" alt="Code Coverage" /&gt;&lt;/a&gt; &lt;a href="https://community.temporal.io"&gt;&lt;img src="https://img.shields.io/static/v1?label=community&amp;amp;message=get%20help&amp;amp;color=informational" alt="Community" /&gt;&lt;/a&gt; &lt;a href="https://goreportcard.com/report/github.com/temporalio/temporal"&gt;&lt;img src="https://goreportcard.com/badge/github.com/temporalio/temporal" alt="Go Report Card" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/temporalio/temporal/main/#introduction"&gt;Introduction&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚Ä¢&amp;nbsp;&amp;nbsp;&lt;/strong&gt; &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/temporalio/temporal/main/#getting-started"&gt;Getting Started&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚Ä¢&amp;nbsp;&amp;nbsp;&lt;/strong&gt; &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/temporalio/temporal/main/#contributing"&gt;Contributing&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚Ä¢&amp;nbsp;&amp;nbsp;&lt;/strong&gt; &lt;strong&gt;&lt;a href="https://docs.temporal.io/"&gt;Temporal Docs&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚Ä¢&amp;nbsp;&amp;nbsp;&lt;/strong&gt; &lt;strong&gt;&lt;a href="https://learn.temporal.io/courses/temporal_101/"&gt;Temporal 101&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;Introduction&lt;/h2&gt; 
&lt;p&gt;Temporal is a durable execution platform that enables developers to build scalable applications without sacrificing productivity or reliability. The Temporal server executes units of application logic called Workflows in a resilient manner that automatically handles intermittent failures, and retries failed operations.&lt;/p&gt; 
&lt;p&gt;Temporal is a mature technology that originated as a fork of Uber's Cadence. It is developed by &lt;a href="https://temporal.io/"&gt;Temporal Technologies&lt;/a&gt;, a startup by the creators of Cadence.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://youtu.be/wIpz4ioK0gI" title="Getting to know Temporal"&gt;&lt;img src="https://github.com/temporalio/temporal/assets/251288/693d18b5-01de-4a3b-b47b-96347b84f610" alt="image" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;h3&gt;Download and Start Temporal Server Locally&lt;/h3&gt; 
&lt;p&gt;Execute the following commands to start a pre-built image along with all the dependencies.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;brew install temporal
temporal server start-dev
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Refer to &lt;a href="https://docs.temporal.io/cli/#installation"&gt;Temporal CLI&lt;/a&gt; documentation for more installation options.&lt;/p&gt; 
&lt;h3&gt;Run the Samples&lt;/h3&gt; 
&lt;p&gt;Clone or download samples for &lt;a href="https://github.com/temporalio/samples-go"&gt;Go&lt;/a&gt; or &lt;a href="https://github.com/temporalio/samples-java"&gt;Java&lt;/a&gt; and run them with the local Temporal server. We have a number of &lt;a href="https://github.com/temporalio/samples-java#helloworld"&gt;HelloWorld type scenarios&lt;/a&gt; available, as well as more advanced ones. Note that the sets of samples are currently different between Go and Java.&lt;/p&gt; 
&lt;h3&gt;Use CLI&lt;/h3&gt; 
&lt;p&gt;Use &lt;a href="https://docs.temporal.io/cli/"&gt;Temporal CLI&lt;/a&gt; to interact with the running Temporal server.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;temporal operator namespace list
temporal workflow list
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Use Temporal Web UI&lt;/h3&gt; 
&lt;p&gt;Try &lt;a href="https://docs.temporal.io/web-ui"&gt;Temporal Web UI&lt;/a&gt; by opening &lt;a href="http://localhost:8233"&gt;http://localhost:8233&lt;/a&gt; for viewing your sample workflows executing on Temporal.&lt;/p&gt; 
&lt;h2&gt;Repository&lt;/h2&gt; 
&lt;p&gt;This repository contains the source code of the Temporal server. To implement Workflows, Activities and Workers, use one of the &lt;a href="https://docs.temporal.io/dev-guide/"&gt;supported languages&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We'd love your help in making Temporal great.&lt;/p&gt; 
&lt;p&gt;Helpful links to get started:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/temporalio/proposals"&gt;work on or propose a new feature&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/temporalio/temporal/main/docs/architecture/README.md"&gt;learn about the Temporal Server architecture&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/temporalio/temporal/main/CONTRIBUTING.md"&gt;learn how to build and run the Temporal Server locally&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/temporalio/temporal/main/docs/development/testing.md"&gt;learn about Temporal Server testing tools and best practices&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;join the Temporal community &lt;a href="https://community.temporal.io"&gt;forum&lt;/a&gt; and &lt;a href="https://t.mp/slack"&gt;Slack&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://github.com/temporalio/temporal/raw/main/LICENSE"&gt;MIT License&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>korotovsky/slack-mcp-server</title>
      <link>https://github.com/korotovsky/slack-mcp-server</link>
      <description>&lt;p&gt;The most powerful MCP Slack Server with no permission requirements, Apps support, multiple transports Stdio and SSE, DMs, Group DMs and smart history fetch logic.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Slack MCP Server&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://archestra.ai/mcp-catalog/korotovsky__slack-mcp-server"&gt;&lt;img src="https://archestra.ai/mcp-catalog/api/badge/quality/korotovsky/slack-mcp-server" alt="Trust Score" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Model Context Protocol (MCP) server for Slack Workspaces. The most powerful MCP Slack server ‚Äî supports Stdio, SSE and HTTP transports, proxy settings, DMs, Group DMs, Smart History fetch (by date or count), may work via OAuth or in complete stealth mode with no permissions and scopes in Workspace üòè.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT]&lt;br /&gt; We need your support! Each month, over 30,000 engineers visit this repository, and more than 9,000 are already using it.&lt;/p&gt; 
 &lt;p&gt;If you appreciate the work our &lt;a href="https://github.com/korotovsky/slack-mcp-server/graphs/contributors"&gt;contributors&lt;/a&gt; have put into this project, please consider giving the repository a star.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;This feature-rich Slack MCP Server has:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Stealth and OAuth Modes&lt;/strong&gt;: Run the server without requiring additional permissions or bot installations (stealth mode), or use secure OAuth tokens for access without needing to refresh or extract tokens from the browser (OAuth mode).&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Enterprise Workspaces Support&lt;/strong&gt;: Possibility to integrate with Enterprise Slack setups.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Channel and Thread Support with &lt;code&gt;#Name&lt;/code&gt; &lt;code&gt;@Lookup&lt;/code&gt;&lt;/strong&gt;: Fetch messages from channels and threads, including activity messages, and retrieve channels using their names (e.g., #general) as well as their IDs.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Smart History&lt;/strong&gt;: Fetch messages with pagination by date (d1, 7d, 1m) or message count.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Search Messages&lt;/strong&gt;: Search messages in channels, threads, and DMs using various filters like date, user, and content.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Safe Message Posting&lt;/strong&gt;: The &lt;code&gt;conversations_add_message&lt;/code&gt; tool is disabled by default for safety. Enable it via an environment variable, with optional channel restrictions.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;DM and Group DM support&lt;/strong&gt;: Retrieve direct messages and group direct messages.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Embedded user information&lt;/strong&gt;: Embed user information in messages, for better context.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Cache support&lt;/strong&gt;: Cache users and channels for faster access.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Stdio/SSE/HTTP Transports &amp;amp; Proxy Support&lt;/strong&gt;: Use the server with any MCP client that supports Stdio, SSE or HTTP transports, and configure it to route outgoing requests through a proxy if needed.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Analytics Demo&lt;/h3&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/korotovsky/slack-mcp-server/master/images/feature-1.gif" alt="Analytics" /&gt;&lt;/p&gt; 
&lt;h3&gt;Add Message Demo&lt;/h3&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/korotovsky/slack-mcp-server/master/images/feature-2.gif" alt="Add Message" /&gt;&lt;/p&gt; 
&lt;h2&gt;Tools&lt;/h2&gt; 
&lt;h3&gt;1. conversations_history:&lt;/h3&gt; 
&lt;p&gt;Get messages from the channel (or DM) by channel_id, the last row/column in the response is used as 'cursor' parameter for pagination if not empty&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Parameters:&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;channel_id&lt;/code&gt; (string, required): - &lt;code&gt;channel_id&lt;/code&gt; (string): ID of the channel in format Cxxxxxxxxxx or its name starting with &lt;code&gt;#...&lt;/code&gt; or &lt;code&gt;@...&lt;/code&gt; aka &lt;code&gt;#general&lt;/code&gt; or &lt;code&gt;@username_dm&lt;/code&gt;.&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;include_activity_messages&lt;/code&gt; (boolean, default: false): If true, the response will include activity messages such as &lt;code&gt;channel_join&lt;/code&gt; or &lt;code&gt;channel_leave&lt;/code&gt;. Default is boolean false.&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;cursor&lt;/code&gt; (string, optional): Cursor for pagination. Use the value of the last row and column in the response as next_cursor field returned from the previous request.&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;limit&lt;/code&gt; (string, default: "1d"): Limit of messages to fetch in format of maximum ranges of time (e.g. 1d - 1 day, 1w - 1 week, 30d - 30 days, 90d - 90 days which is a default limit for free tier history) or number of messages (e.g. 50). Must be empty when 'cursor' is provided.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;2. conversations_replies:&lt;/h3&gt; 
&lt;p&gt;Get a thread of messages posted to a conversation by channelID and &lt;code&gt;thread_ts&lt;/code&gt;, the last row/column in the response is used as &lt;code&gt;cursor&lt;/code&gt; parameter for pagination if not empty.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Parameters:&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;channel_id&lt;/code&gt; (string, required): ID of the channel in format &lt;code&gt;Cxxxxxxxxxx&lt;/code&gt; or its name starting with &lt;code&gt;#...&lt;/code&gt; or &lt;code&gt;@...&lt;/code&gt; aka &lt;code&gt;#general&lt;/code&gt; or &lt;code&gt;@username_dm&lt;/code&gt;.&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;thread_ts&lt;/code&gt; (string, required): Unique identifier of either a thread‚Äôs parent message or a message in the thread. ts must be the timestamp in format &lt;code&gt;1234567890.123456&lt;/code&gt; of an existing message with 0 or more replies.&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;include_activity_messages&lt;/code&gt; (boolean, default: false): If true, the response will include activity messages such as 'channel_join' or 'channel_leave'. Default is boolean false.&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;cursor&lt;/code&gt; (string, optional): Cursor for pagination. Use the value of the last row and column in the response as next_cursor field returned from the previous request.&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;limit&lt;/code&gt; (string, default: "1d"): Limit of messages to fetch in format of maximum ranges of time (e.g. 1d - 1 day, 1w - 1 week, 30d - 30 days, 90d - 90 days which is a default limit for free tier history) or number of messages (e.g. 50). Must be empty when 'cursor' is provided.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;3. conversations_add_message&lt;/h3&gt; 
&lt;p&gt;Add a message to a public channel, private channel, or direct message (DM, or IM) conversation by channel_id and thread_ts.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; Posting messages is disabled by default for safety. To enable, set the &lt;code&gt;SLACK_MCP_ADD_MESSAGE_TOOL&lt;/code&gt; environment variable. If set to a comma-separated list of channel IDs, posting is enabled only for those specific channels. See the Environment Variables section below for details.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Parameters:&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;channel_id&lt;/code&gt; (string, required): ID of the channel in format &lt;code&gt;Cxxxxxxxxxx&lt;/code&gt; or its name starting with &lt;code&gt;#...&lt;/code&gt; or &lt;code&gt;@...&lt;/code&gt; aka &lt;code&gt;#general&lt;/code&gt; or &lt;code&gt;@username_dm&lt;/code&gt;.&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;thread_ts&lt;/code&gt; (string, optional): Unique identifier of either a thread‚Äôs parent message or a message in the thread_ts must be the timestamp in format &lt;code&gt;1234567890.123456&lt;/code&gt; of an existing message with 0 or more replies. Optional, if not provided the message will be added to the channel itself, otherwise it will be added to the thread.&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;payload&lt;/code&gt; (string, required): Message payload in specified content_type format. Example: 'Hello, world!' for text/plain or '# Hello, world!' for text/markdown.&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;content_type&lt;/code&gt; (string, default: "text/markdown"): Content type of the message. Default is 'text/markdown'. Allowed values: 'text/markdown', 'text/plain'.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;4. conversations_search_messages&lt;/h3&gt; 
&lt;p&gt;Search messages in a public channel, private channel, or direct message (DM, or IM) conversation using filters. All filters are optional, if not provided then search_query is required.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: This tool is not available when using bot tokens (&lt;code&gt;xoxb-*&lt;/code&gt;). Bot tokens cannot use the &lt;code&gt;search.messages&lt;/code&gt; API.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Parameters:&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;search_query&lt;/code&gt; (string, optional): Search query to filter messages. Example: 'marketing report' or full URL of Slack message e.g. '&lt;a href="https://slack.com/archives/C1234567890/p1234567890123456"&gt;https://slack.com/archives/C1234567890/p1234567890123456&lt;/a&gt;', then the tool will return a single message matching given URL, herewith all other parameters will be ignored.&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;filter_in_channel&lt;/code&gt; (string, optional): Filter messages in a specific channel by its ID or name. Example: &lt;code&gt;C1234567890&lt;/code&gt; or &lt;code&gt;#general&lt;/code&gt;. If not provided, all channels will be searched.&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;filter_in_im_or_mpim&lt;/code&gt; (string, optional): Filter messages in a direct message (DM) or multi-person direct message (MPIM) conversation by its ID or name. Example: &lt;code&gt;D1234567890&lt;/code&gt; or &lt;code&gt;@username_dm&lt;/code&gt;. If not provided, all DMs and MPIMs will be searched.&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;filter_users_with&lt;/code&gt; (string, optional): Filter messages with a specific user by their ID or display name in threads and DMs. Example: &lt;code&gt;U1234567890&lt;/code&gt; or &lt;code&gt;@username&lt;/code&gt;. If not provided, all threads and DMs will be searched.&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;filter_users_from&lt;/code&gt; (string, optional): Filter messages from a specific user by their ID or display name. Example: &lt;code&gt;U1234567890&lt;/code&gt; or &lt;code&gt;@username&lt;/code&gt;. If not provided, all users will be searched.&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;filter_date_before&lt;/code&gt; (string, optional): Filter messages sent before a specific date in format &lt;code&gt;YYYY-MM-DD&lt;/code&gt;. Example: &lt;code&gt;2023-10-01&lt;/code&gt;, &lt;code&gt;July&lt;/code&gt;, &lt;code&gt;Yesterday&lt;/code&gt; or &lt;code&gt;Today&lt;/code&gt;. If not provided, all dates will be searched.&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;filter_date_after&lt;/code&gt; (string, optional): Filter messages sent after a specific date in format &lt;code&gt;YYYY-MM-DD&lt;/code&gt;. Example: &lt;code&gt;2023-10-01&lt;/code&gt;, &lt;code&gt;July&lt;/code&gt;, &lt;code&gt;Yesterday&lt;/code&gt; or &lt;code&gt;Today&lt;/code&gt;. If not provided, all dates will be searched.&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;filter_date_on&lt;/code&gt; (string, optional): Filter messages sent on a specific date in format &lt;code&gt;YYYY-MM-DD&lt;/code&gt;. Example: &lt;code&gt;2023-10-01&lt;/code&gt;, &lt;code&gt;July&lt;/code&gt;, &lt;code&gt;Yesterday&lt;/code&gt; or &lt;code&gt;Today&lt;/code&gt;. If not provided, all dates will be searched.&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;filter_date_during&lt;/code&gt; (string, optional): Filter messages sent during a specific period in format &lt;code&gt;YYYY-MM-DD&lt;/code&gt;. Example: &lt;code&gt;July&lt;/code&gt;, &lt;code&gt;Yesterday&lt;/code&gt; or &lt;code&gt;Today&lt;/code&gt;. If not provided, all dates will be searched.&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;filter_threads_only&lt;/code&gt; (boolean, default: false): If true, the response will include only messages from threads. Default is boolean false.&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;cursor&lt;/code&gt; (string, default: ""): Cursor for pagination. Use the value of the last row and column in the response as next_cursor field returned from the previous request.&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;limit&lt;/code&gt; (number, default: 20): The maximum number of items to return. Must be an integer between 1 and 100.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;5. channels_list:&lt;/h3&gt; 
&lt;p&gt;Get list of channels&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Parameters:&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;channel_types&lt;/code&gt; (string, required): Comma-separated channel types. Allowed values: &lt;code&gt;mpim&lt;/code&gt;, &lt;code&gt;im&lt;/code&gt;, &lt;code&gt;public_channel&lt;/code&gt;, &lt;code&gt;private_channel&lt;/code&gt;. Example: &lt;code&gt;public_channel,private_channel,im&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;sort&lt;/code&gt; (string, optional): Type of sorting. Allowed values: &lt;code&gt;popularity&lt;/code&gt; - sort by number of members/participants in each channel.&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;limit&lt;/code&gt; (number, default: 100): The maximum number of items to return. Must be an integer between 1 and 1000 (maximum 999).&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;cursor&lt;/code&gt; (string, optional): Cursor for pagination. Use the value of the last row and column in the response as next_cursor field returned from the previous request.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Resources&lt;/h2&gt; 
&lt;p&gt;The Slack MCP Server exposes two special directory resources for easy access to workspace metadata:&lt;/p&gt; 
&lt;h3&gt;1. &lt;code&gt;slack://&amp;lt;workspace&amp;gt;/channels&lt;/code&gt; ‚Äî Directory of Channels&lt;/h3&gt; 
&lt;p&gt;Fetches a CSV directory of all channels in the workspace, including public channels, private channels, DMs, and group DMs.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;URI:&lt;/strong&gt; &lt;code&gt;slack://&amp;lt;workspace&amp;gt;/channels&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Format:&lt;/strong&gt; &lt;code&gt;text/csv&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Fields:&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;id&lt;/code&gt;: Channel ID (e.g., &lt;code&gt;C1234567890&lt;/code&gt;)&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;name&lt;/code&gt;: Channel name (e.g., &lt;code&gt;#general&lt;/code&gt;, &lt;code&gt;@username_dm&lt;/code&gt;)&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;topic&lt;/code&gt;: Channel topic (if any)&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;purpose&lt;/code&gt;: Channel purpose/description&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;memberCount&lt;/code&gt;: Number of members in the channel&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;2. &lt;code&gt;slack://&amp;lt;workspace&amp;gt;/users&lt;/code&gt; ‚Äî Directory of Users&lt;/h3&gt; 
&lt;p&gt;Fetches a CSV directory of all users in the workspace.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;URI:&lt;/strong&gt; &lt;code&gt;slack://&amp;lt;workspace&amp;gt;/users&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Format:&lt;/strong&gt; &lt;code&gt;text/csv&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Fields:&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;userID&lt;/code&gt;: User ID (e.g., &lt;code&gt;U1234567890&lt;/code&gt;)&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;userName&lt;/code&gt;: Slack username (e.g., &lt;code&gt;john&lt;/code&gt;)&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;realName&lt;/code&gt;: User‚Äôs real name (e.g., &lt;code&gt;John Doe&lt;/code&gt;)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Setup Guide&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/korotovsky/slack-mcp-server/master/docs/01-authentication-setup.md"&gt;Authentication Setup&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/korotovsky/slack-mcp-server/master/docs/02-installation.md"&gt;Installation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/korotovsky/slack-mcp-server/master/docs/03-configuration-and-usage.md"&gt;Configuration and Usage&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Environment Variables (Quick Reference)&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Variable&lt;/th&gt; 
   &lt;th&gt;Required?&lt;/th&gt; 
   &lt;th&gt;Default&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;SLACK_MCP_XOXC_TOKEN&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Yes*&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;nil&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Slack browser token (&lt;code&gt;xoxc-...&lt;/code&gt;)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;SLACK_MCP_XOXD_TOKEN&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Yes*&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;nil&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Slack browser cookie &lt;code&gt;d&lt;/code&gt; (&lt;code&gt;xoxd-...&lt;/code&gt;)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;SLACK_MCP_XOXP_TOKEN&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Yes*&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;nil&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;User OAuth token (&lt;code&gt;xoxp-...&lt;/code&gt;) ‚Äî alternative to xoxc/xoxd&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;SLACK_MCP_XOXB_TOKEN&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Yes*&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;nil&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Bot token (&lt;code&gt;xoxb-...&lt;/code&gt;) ‚Äî alternative to xoxp/xoxc/xoxd. Bot has limited access (invited channels only, no search)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;SLACK_MCP_PORT&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;13080&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Port for the MCP server to listen on&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;SLACK_MCP_HOST&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;127.0.0.1&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Host for the MCP server to listen on&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;SLACK_MCP_API_KEY&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;nil&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Bearer token for SSE and HTTP transports&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;SLACK_MCP_PROXY&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;nil&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Proxy URL for outgoing requests&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;SLACK_MCP_USER_AGENT&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;nil&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Custom User-Agent (for Enterprise Slack environments)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;SLACK_MCP_CUSTOM_TLS&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;nil&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Send custom TLS-handshake to Slack servers based on &lt;code&gt;SLACK_MCP_USER_AGENT&lt;/code&gt; or default User-Agent. (for Enterprise Slack environments)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;SLACK_MCP_SERVER_CA&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;nil&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Path to CA certificate&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;SLACK_MCP_SERVER_CA_TOOLKIT&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;nil&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Inject HTTPToolkit CA certificate to root trust-store for MitM debugging&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;SLACK_MCP_SERVER_CA_INSECURE&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;false&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Trust all insecure requests (NOT RECOMMENDED)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;SLACK_MCP_ADD_MESSAGE_TOOL&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;nil&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Enable message posting via &lt;code&gt;conversations_add_message&lt;/code&gt; by setting it to true for all channels, a comma-separated list of channel IDs to whitelist specific channels, or use &lt;code&gt;!&lt;/code&gt; before a channel ID to allow all except specified ones, while an empty value disables posting by default.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;SLACK_MCP_ADD_MESSAGE_MARK&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;nil&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;When the &lt;code&gt;conversations_add_message&lt;/code&gt; tool is enabled, any new message sent will automatically be marked as read.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;SLACK_MCP_ADD_MESSAGE_UNFURLING&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;nil&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Enable to let Slack unfurl posted links or set comma-separated list of domains e.g. &lt;code&gt;github.com,slack.com&lt;/code&gt; to whitelist unfurling only for them. If text contains whitelisted and unknown domain unfurling will be disabled for security reasons.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;SLACK_MCP_USERS_CACHE&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;~/Library/Caches/slack-mcp-server/users_cache.json&lt;/code&gt; (macOS)&lt;br /&gt;&lt;code&gt;~/.cache/slack-mcp-server/users_cache.json&lt;/code&gt; (Linux)&lt;br /&gt;&lt;code&gt;%LocalAppData%/slack-mcp-server/users_cache.json&lt;/code&gt; (Windows)&lt;/td&gt; 
   &lt;td&gt;Path to the users cache file. Used to cache Slack user information to avoid repeated API calls on startup.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;SLACK_MCP_CHANNELS_CACHE&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;~/Library/Caches/slack-mcp-server/channels_cache_v2.json&lt;/code&gt; (macOS)&lt;br /&gt;&lt;code&gt;~/.cache/slack-mcp-server/channels_cache_v2.json&lt;/code&gt; (Linux)&lt;br /&gt;&lt;code&gt;%LocalAppData%/slack-mcp-server/channels_cache_v2.json&lt;/code&gt; (Windows)&lt;/td&gt; 
   &lt;td&gt;Path to the channels cache file. Used to cache Slack channel information to avoid repeated API calls on startup.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;SLACK_MCP_LOG_LEVEL&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;info&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Log-level for stdout or stderr. Valid values are: &lt;code&gt;debug&lt;/code&gt;, &lt;code&gt;info&lt;/code&gt;, &lt;code&gt;warn&lt;/code&gt;, &lt;code&gt;error&lt;/code&gt;, &lt;code&gt;panic&lt;/code&gt; and &lt;code&gt;fatal&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;*You need one of: &lt;code&gt;xoxp&lt;/code&gt; (user), &lt;code&gt;xoxb&lt;/code&gt; (bot), or both &lt;code&gt;xoxc&lt;/code&gt;/&lt;code&gt;xoxd&lt;/code&gt; tokens for authentication.&lt;/p&gt; 
&lt;h3&gt;Limitations matrix &amp;amp; Cache&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Users Cache&lt;/th&gt; 
   &lt;th&gt;Channels Cache&lt;/th&gt; 
   &lt;th&gt;Limitations&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;span&gt;‚ùå&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;‚ùå&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;No cache, No LLM context enhancement with user data, tool &lt;code&gt;channels_list&lt;/code&gt; will be fully not functional. Tools &lt;code&gt;conversations_*&lt;/code&gt; will have limited capabilities and you won't be able to search messages by &lt;code&gt;@userHandle&lt;/code&gt; or &lt;code&gt;#channel-name&lt;/code&gt;, getting messages by &lt;code&gt;@userHandle&lt;/code&gt; or &lt;code&gt;#channel-name&lt;/code&gt; won't be available either.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;span&gt;‚úÖ&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;‚ùå&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;No channels cache, tool &lt;code&gt;channels_list&lt;/code&gt; will be fully not functional. Tools &lt;code&gt;conversations_*&lt;/code&gt; will have limited capabilities and you won't be able to search messages by &lt;code&gt;@userHandle&lt;/code&gt; or &lt;code&gt;#channel-name&lt;/code&gt;, getting messages by &lt;code&gt;@userHandle&lt;/code&gt; or &lt;code&gt;#channel-name&lt;/code&gt; won't be available either.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;span&gt;‚úÖ&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;‚úÖ&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;No limitations, fully functional Slack MCP Server.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Debugging Tools&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Run the inspector with stdio transport
npx @modelcontextprotocol/inspector go run mcp/mcp-server.go --transport stdio

# View logs
tail -n 20 -f ~/Library/Logs/Claude/mcp*.log
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Security&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Never share API tokens&lt;/li&gt; 
 &lt;li&gt;Keep .env files secure and private&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Licensed under MIT - see &lt;a href="https://raw.githubusercontent.com/korotovsky/slack-mcp-server/master/LICENSE"&gt;LICENSE&lt;/a&gt; file. This is not an official Slack product.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>actions/actions-runner-controller</title>
      <link>https://github.com/actions/actions-runner-controller</link>
      <description>&lt;p&gt;Kubernetes controller for GitHub Actions self-hosted runners&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Actions Runner Controller (ARC)&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://bestpractices.coreinfrastructure.org/projects/6061"&gt;&lt;img src="https://bestpractices.coreinfrastructure.org/projects/6061/badge" alt="CII Best Practices" /&gt;&lt;/a&gt; &lt;a href="https://github.com/jonico/awesome-runners"&gt;&lt;img src="https://img.shields.io/badge/listed%20on-awesome--runners-blue.svg?sanitize=true" alt="awesome-runners" /&gt;&lt;/a&gt; &lt;a href="https://artifacthub.io/packages/search?repo=actions-runner-controller"&gt;&lt;img src="https://img.shields.io/endpoint?url=https://artifacthub.io/badge/repository/actions-runner-controller" alt="Artifact Hub" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;About&lt;/h2&gt; 
&lt;p&gt;Actions Runner Controller (ARC) is a Kubernetes operator that orchestrates and scales self-hosted runners for GitHub Actions.&lt;/p&gt; 
&lt;p&gt;With ARC, you can create runner scale sets that automatically scale based on the number of workflows running in your repository, organization, or enterprise. Because controlled runners can be ephemeral and based on containers, new runner instances can scale up or down rapidly and cleanly. For more information about autoscaling, see &lt;a href="https://docs.github.com/en/actions/hosting-your-own-runners/managing-self-hosted-runners/autoscaling-with-self-hosted-runners"&gt;"Autoscaling with self-hosted runners."&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;You can set up ARC on Kubernetes using Helm, then create and run a workflow that uses runner scale sets. For more information about runner scale sets, see &lt;a href="https://docs.github.com/en/actions/hosting-your-own-runners/managing-self-hosted-runners-with-actions-runner-controller/deploying-runner-scale-sets-with-actions-runner-controller#runner-scale-set"&gt;"Deploying runner scale sets with Actions Runner Controller."&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;People&lt;/h2&gt; 
&lt;p&gt;Actions Runner Controller (ARC) is an open-source project currently developed and maintained in collaboration with the GitHub Actions team, external maintainers @mumoshu and @toast-gear, various &lt;a href="https://github.com/actions/actions-runner-controller/graphs/contributors"&gt;contributors&lt;/a&gt;, and the &lt;a href="https://github.com/actions/actions-runner-controller/discussions"&gt;awesome community&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;If you think the project is awesome and is adding value to your business, please consider directly sponsoring &lt;a href="https://github.com/sponsors/actions-runner-controller"&gt;community maintainers&lt;/a&gt; and individual contributors via GitHub Sponsors.&lt;/p&gt; 
&lt;p&gt;If you are already the employer of one of the contributors, sponsoring via GitHub Sponsors might not be an option. Just support them by other means!&lt;/p&gt; 
&lt;p&gt;See &lt;a href="https://github.com/sponsors/actions-runner-controller"&gt;the sponsorship dashboard&lt;/a&gt; for the former and the current sponsors.&lt;/p&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;p&gt;To give ARC a try with just a handful of commands, please refer to the &lt;a href="https://docs.github.com/en/actions/hosting-your-own-runners/managing-self-hosted-runners-with-actions-runner-controller/quickstart-for-actions-runner-controller"&gt;Quickstart guide&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;For an overview of ARC, please refer to &lt;a href="https://docs.github.com/en/actions/hosting-your-own-runners/managing-self-hosted-runners-with-actions-runner-controller/about-actions-runner-controller"&gt;About ARC&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;With the introduction of &lt;a href="https://github.com/actions/actions-runner-controller/discussions/2775"&gt;autoscaling runner scale sets&lt;/a&gt;, the existing &lt;a href="https://raw.githubusercontent.com/actions/actions-runner-controller/master/docs/automatically-scaling-runners.md"&gt;autoscaling modes&lt;/a&gt; are now legacy. The legacy modes have certain use cases and will continue to be maintained by the community only.&lt;/p&gt; 
&lt;p&gt;For further information on what is supported by GitHub and what's managed by the community, please refer to &lt;a href="https://github.com/actions/actions-runner-controller/discussions/2775"&gt;this announcement discussion.&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Documentation&lt;/h3&gt; 
&lt;p&gt;ARC documentation is available on &lt;a href="https://docs.github.com/en/actions/hosting-your-own-runners/managing-self-hosted-runners-with-actions-runner-controller/quickstart-for-actions-runner-controller"&gt;docs.github.com&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Legacy documentation&lt;/h3&gt; 
&lt;p&gt;The following documentation is for the legacy autoscaling modes that continue to be maintained by the community:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/actions/actions-runner-controller/master/docs/quickstart.md"&gt;Quickstart guide&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/actions/actions-runner-controller/master/docs/about-arc.md"&gt;About ARC&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/actions/actions-runner-controller/master/docs/installing-arc.md"&gt;Installing ARC&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/actions/actions-runner-controller/master/docs/authenticating-to-the-github-api.md"&gt;Authenticating to the GitHub API&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/actions/actions-runner-controller/master/docs/deploying-arc-runners.md"&gt;Deploying ARC runners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/actions/actions-runner-controller/master/docs/choosing-runner-destination.md"&gt;Adding ARC runners to a repository, organization, or enterprise&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/actions/actions-runner-controller/master/docs/automatically-scaling-runners.md"&gt;Automatically scaling runners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/actions/actions-runner-controller/master/docs/using-custom-volumes.md"&gt;Using custom volumes&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/actions/actions-runner-controller/master/docs/using-arc-runners-in-a-workflow.md"&gt;Using ARC runners in a workflow&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/actions/actions-runner-controller/master/docs/managing-access-with-runner-groups.md"&gt;Managing access with runner groups&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/actions/actions-runner-controller/master/docs/configuring-windows-runners.md"&gt;Configuring Windows runners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/actions/actions-runner-controller/master/docs/using-arc-across-organizations.md"&gt;Using ARC across organizations&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/actions/actions-runner-controller/master/docs/using-entrypoint-features.md"&gt;Using entrypoint features&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/actions/actions-runner-controller/master/docs/deploying-alternative-runners.md"&gt;Deploying alternative runners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/actions/actions-runner-controller/master/docs/monitoring-and-troubleshooting.md"&gt;Monitoring and troubleshooting&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome contributions from the community. For more details on contributing to the project (including requirements), please refer to "&lt;a href="https://github.com/actions/actions-runner-controller/raw/master/CONTRIBUTING.md"&gt;Getting Started with Contributing&lt;/a&gt;."&lt;/p&gt; 
&lt;h2&gt;Troubleshooting&lt;/h2&gt; 
&lt;p&gt;We are very happy to help you with any issues you have. Please refer to the "&lt;a href="https://github.com/actions/actions-runner-controller/raw/master/TROUBLESHOOTING.md"&gt;Troubleshooting&lt;/a&gt;" section for common issues.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>rancher/rancher</title>
      <link>https://github.com/rancher/rancher</link>
      <description>&lt;p&gt;Complete container management platform&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Rancher&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://store.docker.com/community/images/rancher/rancher"&gt;&lt;img src="https://img.shields.io/docker/pulls/rancher/rancher.svg?sanitize=true" alt="Docker Pulls" /&gt;&lt;/a&gt; &lt;a href="https://goreportcard.com/report/github.com/rancher/rancher"&gt;&lt;img src="https://goreportcard.com/badge/github.com/rancher/rancher" alt="Go Report Card" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Rancher is an open source container management platform built for organizations that deploy containers in production. Rancher makes it easy to run Kubernetes everywhere, meet IT requirements, and empower DevOps teams.&lt;/p&gt; 
&lt;h2&gt;Stable Release&lt;/h2&gt; 
&lt;!-- stable v2.13.1 DO NOT REMOVE THIS LINE --&gt; 
&lt;ul&gt; 
 &lt;li&gt;v2.13.1 - &lt;code&gt;rancher/rancher:v2.13.1&lt;/code&gt; / &lt;code&gt;rancher/rancher:stable&lt;/code&gt; - Read the full release &lt;a href="https://github.com/rancher/rancher/releases/tag/v2.13.1"&gt;notes&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;To get automated notifications of our latest release, you can watch the announcements category in our &lt;a href="http://forums.rancher.com/c/announcements"&gt;forums&lt;/a&gt;, or subscribe to the RSS feed &lt;code&gt;https://forums.rancher.com/c/announcements.rss&lt;/code&gt;.&lt;/p&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;sudo docker run -d --restart=unless-stopped -p 80:80 -p 443:443 --privileged rancher/rancher
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Open your browser to &lt;a href="https://localhost"&gt;https://localhost&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;See &lt;a href="https://ranchermanager.docs.rancher.com/v2.8/pages-for-subheaders/installation-and-upgrade"&gt;Installing/Upgrading Rancher&lt;/a&gt; for all installation options.&lt;/p&gt; 
&lt;h3&gt;Minimum Requirements&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Operating Systems 
  &lt;ul&gt; 
   &lt;li&gt;Please see &lt;a href="https://rancher.com/support-matrix/"&gt;Support Matrix&lt;/a&gt; for specific OS versions for each Rancher version. Note that the link will default to the support matrix for the latest version of Rancher. Use the left navigation menu to select a different Rancher version.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Hardware &amp;amp; Software 
  &lt;ul&gt; 
   &lt;li&gt;Please see &lt;a href="https://ranchermanager.docs.rancher.com/v2.8/pages-for-subheaders/installation-requirements"&gt;Installation Requirements&lt;/a&gt; for hardware and software requirements.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Using Rancher&lt;/h3&gt; 
&lt;p&gt;To learn more about using Rancher, please refer to our &lt;a href="https://ranchermanager.docs.rancher.com/v2.8"&gt;Rancher Documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Source Code&lt;/h2&gt; 
&lt;p&gt;This repo is a meta-repo used for packaging and contains the majority of Rancher codebase. For other Rancher projects and modules, &lt;a href="https://github.com/rancher/rancher/raw/release/v2.8/go.mod"&gt;see go.mod&lt;/a&gt; for the full list.&lt;/p&gt; 
&lt;p&gt;Rancher also includes other open source libraries and projects, &lt;a href="https://github.com/rancher/rancher/raw/release/v2.8/go.mod"&gt;see go.mod&lt;/a&gt; for the full list.&lt;/p&gt; 
&lt;h2&gt;Build configuration&lt;/h2&gt; 
&lt;p&gt;Refer to the &lt;a href="https://raw.githubusercontent.com/rancher/rancher/main/docs/build.md"&gt;build docs&lt;/a&gt; on how to customize the building and packaging of Rancher.&lt;/p&gt; 
&lt;h2&gt;Support, Discussion, and Community&lt;/h2&gt; 
&lt;p&gt;If you need any help with Rancher, please join us at either our &lt;a href="http://forums.rancher.com/"&gt;Rancher forums&lt;/a&gt; or &lt;a href="https://slack.rancher.io/"&gt;Slack&lt;/a&gt; where most of our team hangs out at.&lt;/p&gt; 
&lt;p&gt;Please submit any Rancher bugs, issues, and feature requests to &lt;a href="https://github.com/rancher/rancher/issues"&gt;rancher/rancher&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;For security issues, please first check our &lt;a href="https://github.com/rancher/rancher/security"&gt;security policy&lt;/a&gt; and email &lt;a href="mailto:security-rancher@suse.com"&gt;security-rancher@suse.com&lt;/a&gt; instead of posting a public issue in GitHub. You may (but are not required to) use the GPG key located on &lt;a href="https://keybase.io/rancher"&gt;Keybase&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;License&lt;/h1&gt; 
&lt;p&gt;Copyright (c) 2014-2025 &lt;a href="http://rancher.com"&gt;SUSE&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License. You may obtain a copy of the License at&lt;/p&gt; 
&lt;p&gt;&lt;a href="http://www.apache.org/licenses/LICENSE-2.0"&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>memodb-io/Acontext</title>
      <link>https://github.com/memodb-io/Acontext</link>
      <description>&lt;p&gt;Data platform for context engineering. Context data platform that stores, observes and learns. Join the community‚ù§Ô∏è: https://discord.acontext.io&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;a href="https://discord.acontext.io"&gt; &lt;img alt="Show Acontext header banner" src="https://raw.githubusercontent.com/memodb-io/Acontext/main/assets/Acontext-header-banner.png" /&gt; &lt;/a&gt; 
 &lt;p&gt; &lt;/p&gt;
 &lt;h4&gt;Context Data Platform for Building Cloud-native AI Agents&lt;/h4&gt; 
 &lt;p&gt;&lt;/p&gt; 
 &lt;p align="center"&gt; &lt;a href="https://pypi.org/project/acontext/"&gt;&lt;img src="https://img.shields.io/pypi/v/acontext.svg?sanitize=true" /&gt;&lt;/a&gt; &lt;a href="https://www.npmjs.com/package/@acontext/acontext"&gt;&lt;img src="https://img.shields.io/npm/v/@acontext/acontext.svg?logo=npm&amp;amp;logoColor=fff&amp;amp;style=flat&amp;amp;labelColor=2C2C2C&amp;amp;color=28CF8D" /&gt;&lt;/a&gt; &lt;a href="https://github.com/memodb-io/acontext/actions/workflows/core-test.yaml"&gt;&lt;img src="https://github.com/memodb-io/acontext/actions/workflows/core-test.yaml/badge.svg?sanitize=true" /&gt;&lt;/a&gt; &lt;a href="https://github.com/memodb-io/acontext/actions/workflows/api-test.yaml"&gt;&lt;img src="https://github.com/memodb-io/acontext/actions/workflows/api-test.yaml/badge.svg?sanitize=true" /&gt;&lt;/a&gt; &lt;a href="https://github.com/memodb-io/acontext/actions/workflows/cli-test.yaml"&gt;&lt;img src="https://github.com/memodb-io/acontext/actions/workflows/cli-test.yaml/badge.svg?sanitize=true" /&gt;&lt;/a&gt; &lt;/p&gt; 
 &lt;p align="center"&gt; &lt;a href="https://x.com/acontext_io"&gt;&lt;img src="https://img.shields.io/twitter/follow/acontext_io?style=social" alt="Twitter Follow" /&gt;&lt;/a&gt; &lt;a href="https://discord.acontext.io"&gt;&lt;img src="https://img.shields.io/badge/dynamic/json?label=Acontext&amp;amp;style=flat&amp;amp;query=approximate_member_count&amp;amp;url=https%3A%2F%2Fdiscord.com%2Fapi%2Fv10%2Finvites%2FSG9xJcqVBu%3Fwith_counts%3Dtrue&amp;amp;logo=discord&amp;amp;logoColor=white&amp;amp;suffix=+members&amp;amp;color=36393f&amp;amp;labelColor=5765F2" alt="Acontext Discord" /&gt;&lt;/a&gt; &lt;/p&gt; 
 &lt;div align="center"&gt; 
  &lt;!-- Keep these links. Translations will automatically update with the README. --&gt; 
  &lt;a href="https://raw.githubusercontent.com/memodb-io/Acontext/main/readme/de/README.md"&gt;Deutsch&lt;/a&gt; | 
  &lt;a href="https://raw.githubusercontent.com/memodb-io/Acontext/main/readme/es/README.md"&gt;Espa√±ol&lt;/a&gt; | 
  &lt;a href="https://raw.githubusercontent.com/memodb-io/Acontext/main/readme/fr/README.md"&gt;Fran√ßais&lt;/a&gt; | 
  &lt;a href="https://raw.githubusercontent.com/memodb-io/Acontext/main/readme/ja/README.md"&gt;Êó•Êú¨Ë™û&lt;/a&gt; | 
  &lt;a href="https://raw.githubusercontent.com/memodb-io/Acontext/main/readme/ko/README.md"&gt;ÌïúÍµ≠Ïñ¥&lt;/a&gt; | 
  &lt;a href="https://raw.githubusercontent.com/memodb-io/Acontext/main/readme/pt/README.md"&gt;Portugu√™s&lt;/a&gt; | 
  &lt;a href="https://raw.githubusercontent.com/memodb-io/Acontext/main/readme/ru/README.md"&gt;–†—É—Å—Å–∫–∏–π&lt;/a&gt; | 
  &lt;a href="https://raw.githubusercontent.com/memodb-io/Acontext/main/readme/zh/README.md"&gt;‰∏≠Êñá&lt;/a&gt; 
 &lt;/div&gt; 
 &lt;br /&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;em&gt;Everyone is telling you how to use their agents. But what if YOU need to build an agent for 100,000 users, how would you start?&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;üì¶ Problem 1: 99% of your DB is just LLM messages.&lt;/strong&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Poor schema design makes your most valuable data expensive and slow. Acontext handles context storage and retrieval via PG, Redis, and S3.&lt;/p&gt; 
 &lt;p&gt;ChatGPT, Gemini, Anthropic, images, audio, files... we've got you covered.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;‚è∞ Problem 2: Long-running agents are a nightmare.&lt;/strong&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;You know context engineering, but you're always writing it from scratch. Acontext comes with built-in context editing methods and a todo agent out of the box.&lt;/p&gt; 
 &lt;p&gt;Managing agent state? Piece of cake.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;üëÄ Problem 3: You can't see how your agent is doing.&lt;/strong&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;How satisfied are your users, really? Acontext tracks tasks per session and shows you your agent's actual success rate.&lt;/p&gt; 
 &lt;p&gt;Stop obsessing over token costs, improve the agent first.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;üß† Problem 4: Your agent is hit or miss.&lt;/strong&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Can it learn from its wins? Acontext's experience agent remembers successful runs and turns them into reusable tool-use SOPs.&lt;/p&gt; 
 &lt;p&gt;Consistency is everything.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;To solve those problems at once, Acontext becomes the &lt;strong&gt;Context Data Platform&lt;/strong&gt;:&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;picture&gt; 
  &lt;img alt="Acontext Learning" src="https://raw.githubusercontent.com/memodb-io/Acontext/main/assets/acontext-components.jpg" width="100%" /&gt; 
 &lt;/picture&gt; 
 &lt;p&gt;Context Data Platform that Store, Observe and Learn&lt;/p&gt; 
&lt;/div&gt; 
&lt;h1&gt;üí° Core Features&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Context Engineering&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://docs.acontext.io/store/messages/multi-provider"&gt;Session&lt;/a&gt;: unified message storage for any llm, any modal.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://docs.acontext.io/store/disk"&gt;Disk&lt;/a&gt;: save/download artifacts with file path.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://docs.acontext.io/store/editing"&gt;Context Editing&lt;/a&gt; - manage your context window in one api.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;div align="center"&gt; 
 &lt;picture&gt; 
  &lt;img alt="Acontext Learning" src="https://raw.githubusercontent.com/memodb-io/Acontext/main/assets/acontext-context-engineering.png" width="80%" /&gt; 
 &lt;/picture&gt; 
 &lt;p&gt;Context Engineering in Acontext&lt;/p&gt; 
&lt;/div&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Observe agent tasks and user feedback&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://docs.acontext.io/observe/agent_tasks"&gt;Task&lt;/a&gt;: collect agent's working status, progress and preferences in near real-time.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Agent self-learning&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://docs.acontext.io/learn/advance/experience-agent"&gt;Experience&lt;/a&gt;: let agent learn SOPs for each user.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;View everything in one &lt;a href="https://docs.acontext.io/observe/dashboard"&gt;dashboard&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div align="center"&gt; 
 &lt;picture&gt; 
  &lt;img alt="Dashboard" src="https://raw.githubusercontent.com/memodb-io/Acontext/main/docs/images/dashboard/BI.png" width="80%" /&gt; 
 &lt;/picture&gt; 
 &lt;p&gt;Dashboard of Agent Success Rate and Other Metrics&lt;/p&gt; 
&lt;/div&gt; 
&lt;h1&gt;üèóÔ∏è How it works?&lt;/h1&gt; 
&lt;details&gt; 
 &lt;summary&gt;click to open&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-mermaid"&gt;graph TB
    subgraph "Client Layer"
        PY["pip install acontext"]
        TS["npm i @acontext/acontext"]
    end
    
    subgraph "Acontext Backend"
      subgraph " "
          API["API&amp;lt;br/&amp;gt;localhost:8029"]
          CORE["Core"]
          API --&amp;gt;|FastAPI &amp;amp; MQ| CORE
      end
      
      subgraph " "
          Infrastructure["Infrastructures"]
          PG["PostgreSQL"]
          S3["S3"]
          REDIS["Redis"]
          MQ["RabbitMQ"]
      end
    end
    
    subgraph "Dashboard"
        UI["Web Dashboard&amp;lt;br/&amp;gt;localhost:3000"]
    end
    
    PY --&amp;gt;|RESTFUL API| API
    TS --&amp;gt;|RESTFUL API| API
    UI --&amp;gt;|RESTFUL API| API
    API --&amp;gt; Infrastructure
    CORE --&amp;gt; Infrastructure

    Infrastructure --&amp;gt; PG
    Infrastructure --&amp;gt; S3
    Infrastructure --&amp;gt; REDIS
    Infrastructure --&amp;gt; MQ
    
    
    style PY fill:#3776ab,stroke:#fff,stroke-width:2px,color:#fff
    style TS fill:#3178c6,stroke:#fff,stroke-width:2px,color:#fff
    style API fill:#00add8,stroke:#fff,stroke-width:2px,color:#fff
    style CORE fill:#ffd43b,stroke:#333,stroke-width:2px,color:#333
    style UI fill:#000,stroke:#fff,stroke-width:2px,color:#fff
    style PG fill:#336791,stroke:#fff,stroke-width:2px,color:#fff
    style S3 fill:#ff9900,stroke:#fff,stroke-width:2px,color:#fff
    style REDIS fill:#dc382d,stroke:#fff,stroke-width:2px,color:#fff
    style MQ fill:#ff6600,stroke:#fff,stroke-width:2px,color:#fff
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h2&gt;How They Work Together&lt;/h2&gt; 
 &lt;pre&gt;&lt;code class="language-txt"&gt;‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ User ‚îÇ‚óÑ‚îÄ‚îÄ‚ñ∫‚îÇ Your Agent ‚îÇ‚óÑ‚îÄ‚îÄ‚ñ∫‚îÇ   Session    ‚îÇ    ‚îÇ Artifact Disk ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ≤‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                  ‚îÇ                  ‚îÇ # if enable
                  ‚îÇ         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                  ‚îÇ         ‚îÇ Observed Tasks  ‚îÇ
                  ‚îÇ         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                  ‚îÇ                  ‚îÇ # if enable
                  ‚îÇ         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                  ‚îÇ         ‚îÇ   Learn Skills  ‚îÇ
                  ‚îÇ         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                      Search skills
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h2&gt;Data Structures&lt;/h2&gt; 
 &lt;details&gt; 
  &lt;summary&gt;üìñ Task Structure&lt;/summary&gt; 
  &lt;pre&gt;&lt;code class="language-json"&gt;{
  "task_description": "Star https://github.com/memodb-io/Acontext",
  "progresses": [
    "I have navigated to Acontext repo",
    "Tried to Star but a pop-up required me to login",
    ...
  ],
  "user_preferences": [
    "user wants to use outlook email to login"
  ]
}
&lt;/code&gt;&lt;/pre&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt;üìñ Skill Structure&lt;/summary&gt; 
  &lt;pre&gt;&lt;code class="language-json"&gt;{
    "use_when": "star a repo on github.com",
    "preferences": "use user's outlook account",
    "tool_sops": [
        {"tool_name": "goto", "action": "goto github.com"},
        {"tool_name": "click", "action": "find login button if any. login first"},
        ...
    ]
}
&lt;/code&gt;&lt;/pre&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt;üìñ Space Structure&lt;/summary&gt; 
  &lt;pre&gt;&lt;code class="language-txt"&gt;/
‚îî‚îÄ‚îÄ github/ (folder)
    ‚îî‚îÄ‚îÄ GTM (page)
        ‚îú‚îÄ‚îÄ find_trending_repos (sop)
        ‚îî‚îÄ‚îÄ find_contributor_emails (sop)
    ‚îî‚îÄ‚îÄ basic_ops (page)
        ‚îú‚îÄ‚îÄ create_repo (sop)
        ‚îî‚îÄ‚îÄ delete_repo (sop)
    ...
&lt;/code&gt;&lt;/pre&gt; 
 &lt;/details&gt; 
&lt;/details&gt; 
&lt;h1&gt;üöÄ Connect to Acontext&lt;/h1&gt; 
&lt;ol&gt; 
 &lt;li&gt;Go to &lt;a href="https://acontext.io"&gt;Acontext.io&lt;/a&gt;, claim your free credits.&lt;/li&gt; 
 &lt;li&gt;Go through a one-click onboarding to get your API Key: &lt;code&gt;sk-ac-xxx&lt;/code&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;div align="center"&gt; 
 &lt;picture&gt; 
  &lt;img alt="Dashboard" src="https://raw.githubusercontent.com/memodb-io/Acontext/main/assets/onboard.png" width="80%" /&gt; 
 &lt;/picture&gt; 
&lt;/div&gt; 
&lt;details&gt; 
 &lt;summary&gt;üíª Self-host Acontext&lt;/summary&gt; 
 &lt;p&gt;We have an &lt;code&gt;acontext-cli&lt;/code&gt; to help you do quick proof-of-concept. Download it first in your terminal:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;curl -fsSL https://install.acontext.io | sh
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;You should have &lt;a href="https://www.docker.com/get-started/"&gt;docker&lt;/a&gt; installed and an OpenAI API Key to start an Acontext backend on your computer:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;mkdir acontext_server &amp;amp;&amp;amp; cd acontext_server
acontext docker up
&lt;/code&gt;&lt;/pre&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;[!IMPORTANT]&lt;/p&gt; 
  &lt;p&gt;Make sure your LLM has the ability to &lt;a href="https://platform.openai.com/docs/guides/function-calling"&gt;call tools&lt;/a&gt;. By default, Acontext will use &lt;code&gt;gpt-4.1&lt;/code&gt;.&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;p&gt;&lt;code&gt;acontext docker up&lt;/code&gt; will create/use &lt;code&gt;.env&lt;/code&gt; and &lt;code&gt;config.yaml&lt;/code&gt; for Acontext, and create a &lt;code&gt;db&lt;/code&gt; folder to persist data.&lt;/p&gt; 
 &lt;p&gt;Once it's done, you can access the following endpoints:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Acontext API Base URL: &lt;a href="http://localhost:8029/api/v1"&gt;http://localhost:8029/api/v1&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Acontext Dashboard: &lt;a href="http://localhost:3000/"&gt;http://localhost:3000/&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h1&gt;üßê Use Acontext to build Agent&lt;/h1&gt; 
&lt;p&gt;Download end-to-end scripts with &lt;code&gt;acontext&lt;/code&gt;:&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Python&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;acontext create my-proj --template-path "python/openai-basic"
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;More examples on Python:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;code&gt;python/openai-agent-basic&lt;/code&gt;: self-learning agent in openai agent sdk.&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;python/agno-basic&lt;/code&gt;: self-learning agent in agno framework.&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;python/openai-agent-artifacts&lt;/code&gt;: agent that can edit and download artifacts.&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;Typescript&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;acontext create my-proj --template-path "typescript/openai-basic"
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;More examples on Typescript:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;code&gt;typescript/vercel-ai-basic&lt;/code&gt;: self-learning agent in @vercel/ai-sdk&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE]&lt;/p&gt; 
 &lt;p&gt;Check our example repo for more templates: &lt;a href="https://github.com/memodb-io/Acontext-Examples"&gt;Acontext-Examples&lt;/a&gt;.&lt;/p&gt; 
 &lt;p&gt;We're cooking more full-stack Agent Applications! &lt;a href="https://discord.acontext.io"&gt;Tell us what you want!&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Step-by-step Quickstart&lt;/h2&gt; 
&lt;details&gt; 
 &lt;summary&gt;click to open&lt;/summary&gt; 
 &lt;p&gt;We're maintaining Python &lt;a href="https://pypi.org/project/acontext/"&gt;&lt;img src="https://img.shields.io/pypi/v/acontext.svg?sanitize=true" alt="pypi" /&gt;&lt;/a&gt; and Typescript &lt;a href="https://www.npmjs.com/package/@acontext/acontext"&gt;&lt;img src="https://img.shields.io/npm/v/@acontext/acontext.svg?logo=npm&amp;amp;logoColor=fff&amp;amp;style=flat&amp;amp;labelColor=2C2C2C&amp;amp;color=28CF8D" alt="npm" /&gt;&lt;/a&gt; SDKs. The snippets below are using Python.&lt;/p&gt; 
 &lt;h2&gt;Install SDKs&lt;/h2&gt; 
 &lt;pre&gt;&lt;code&gt;pip install acontext # for Python
npm i @acontext/acontext # for Typescript
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h2&gt;Initialize Client&lt;/h2&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;import os
from acontext import AcontextClient

client = AcontextClient(
    api_key=os.getenv("ACONTEXT_API_KEY"),
)

# If you're using self-hosted Acontext:
# client = AcontextClient(
#     base_url="http://localhost:8029/api/v1",
#     api_key="sk-ac-your-root-api-bearer-token",
# )
&lt;/code&gt;&lt;/pre&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;&lt;a href="https://docs.acontext.io/settings/core"&gt;üìñ async client doc&lt;/a&gt;&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;h2&gt;Store&lt;/h2&gt; 
 &lt;p&gt;Acontext can manage agent sessions and artifacts.&lt;/p&gt; 
 &lt;h3&gt;Save Messages &lt;a href="https://docs.acontext.io/api-reference/session/store-message-to-session"&gt;üìñ&lt;/a&gt;&lt;/h3&gt; 
 &lt;p&gt;Acontext offers persistent storage for message data. When you call &lt;code&gt;session.store_message&lt;/code&gt;, Acontext will persist the message and start to monitor this session:&lt;/p&gt; 
 &lt;details&gt; 
  &lt;summary&gt;Code Snippet&lt;/summary&gt; 
  &lt;pre&gt;&lt;code class="language-python"&gt;session = client.sessions.create()

messages = [
    {"role": "user", "content": "I need to write a landing page of iPhone 15 pro max"},
    {
        "role": "assistant",
        "content": "Sure, my plan is below:\n1. Search for the latest news about iPhone 15 pro max\n2. Init Next.js project for the landing page\n3. Deploy the landing page to the website",
    }
]

# Save messages
for msg in messages:
    client.sessions.store_message(session_id=session.id, blob=msg, format="openai")
&lt;/code&gt;&lt;/pre&gt; 
  &lt;blockquote&gt; 
   &lt;p&gt;&lt;a href="https://docs.acontext.io/store/messages/multi-modal"&gt;üìñ&lt;/a&gt; We also support multi-modal message storage and anthropic SDK.&lt;/p&gt; 
  &lt;/blockquote&gt; 
 &lt;/details&gt; 
 &lt;h3&gt;Load Messages &lt;a href="https://docs.acontext.io/api-reference/session/get-messages-from-session"&gt;üìñ&lt;/a&gt;&lt;/h3&gt; 
 &lt;p&gt;Obtain your session messages using &lt;code&gt;sessions.get_messages&lt;/code&gt;&lt;/p&gt; 
 &lt;details&gt; 
  &lt;summary&gt;Code Snippet&lt;/summary&gt; 
  &lt;pre&gt;&lt;code class="language-python"&gt;r = client.sessions.get_messages(session.id)
new_msg = r.items

new_msg.append({"role": "user", "content": "How are you doing?"})
r = openai_client.chat.completions.create(model="gpt-4.1", messages=new_msg)
print(r.choices[0].message.content)
client.sessions.store_message(session_id=session.id, blob=r.choices[0].message)
&lt;/code&gt;&lt;/pre&gt; 
 &lt;/details&gt; 
 &lt;div align="center"&gt; 
  &lt;picture&gt; 
   &lt;img alt="Session" src="https://raw.githubusercontent.com/memodb-io/Acontext/main/docs/images/dashboard/message_viewer.png" width="100%" /&gt; 
  &lt;/picture&gt; 
  &lt;p&gt;You can view sessions in your local Dashboard&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;h3&gt;Artifacts &lt;a href="https://docs.acontext.io/store/disk"&gt;üìñ&lt;/a&gt;&lt;/h3&gt; 
 &lt;p&gt;Create a disk for your agent to store and read artifacts using file paths:&lt;/p&gt; 
 &lt;details&gt; 
  &lt;summary&gt;Code Snippet&lt;/summary&gt; 
  &lt;pre&gt;&lt;code class="language-python"&gt;from acontext import FileUpload

disk = client.disks.create()

file = FileUpload(
    filename="todo.md",
    content=b"# Sprint Plan\n\n## Goals\n- Complete user authentication\n- Fix critical bugs"
)
artifact = client.disks.artifacts.upsert(
    disk.id,
    file=file,
    file_path="/todo/"
)


print(client.disks.artifacts.list(
    disk.id,
    path="/todo/"
))

result = client.disks.artifacts.get(
    disk.id,
    file_path="/todo/",
    filename="todo.md",
    with_public_url=True,
    with_content=True
)
print(f"‚úì File content: {result.content.raw}")
print(f"‚úì Download URL: {result.public_url}")        
&lt;/code&gt;&lt;/pre&gt; 
 &lt;/details&gt; 
 &lt;div align="center"&gt; 
  &lt;picture&gt; 
   &lt;img alt="Artifacts" src="https://raw.githubusercontent.com/memodb-io/Acontext/main/docs/images/dashboard/artifact_viewer.png" width="100%" /&gt; 
  &lt;/picture&gt; 
  &lt;p&gt;You can view artifacts in your local Dashboard&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;h2&gt;Observe &lt;a href="https://docs.acontext.io/observe"&gt;üìñ&lt;/a&gt;&lt;/h2&gt; 
 &lt;p&gt;For every session, Acontext will &lt;strong&gt;automatically&lt;/strong&gt; launch a background agent to track the task progress and user feedback. &lt;strong&gt;It's like a background TODO agent&lt;/strong&gt;. Acontext will use it to observe your daily agent success rate.&lt;/p&gt; 
 &lt;p&gt;You can use the SDK to retrieve the current state of the agent session, for Context Engineering like Reduction and Compression.&lt;/p&gt; 
 &lt;details&gt; 
  &lt;summary&gt;Full Script&lt;/summary&gt; 
  &lt;pre&gt;&lt;code class="language-python"&gt;from acontext import AcontextClient

# Initialize client
client = AcontextClient(
    base_url="http://localhost:8029/api/v1", api_key="sk-ac-your-root-api-bearer-token"
)

# Create a project and session
session = client.sessions.create()

# Conversation messages
messages = [
    {"role": "user", "content": "I need to write a landing page of iPhone 15 pro max"},
    {
        "role": "assistant",
        "content": "Sure, my plan is below:\n1. Search for the latest news about iPhone 15 pro max\n2. Init Next.js project for the landing page\n3. Deploy the landing page to the website",
    },
    {
        "role": "user",
        "content": "That sounds good. Let's first collect the message and report to me before any landing page coding.",
    },
    {
        "role": "assistant",
        "content": "Sure, I will first collect the message then report to you before any landing page coding.",
      	"tool_calls": [
            {
                "id": "call_001",
                "type": "function",
                "function": {
                    "name": "search_news",
                    "arguments": "{\"query\": \"iPhone news\"}"
                }
            }
        ]
    },
]

# Store messages in a loop
for msg in messages:
    client.sessions.store_message(session_id=session.id, blob=msg, format="openai")

# Wait for task extraction to complete
client.sessions.flush(session.id)

# Display extracted tasks
tasks_response = client.sessions.get_tasks(session.id)
print(tasks_response)
for task in tasks_response.items:
    print(f"\nTask #{task.order}:")
    print(f"  ID: {task.id}")
    print(f"  Title: {task.data.task_description}")
    print(f"  Status: {task.status}")

    # Show progress updates if available
    if task.data.progresses:
        print(f"  Progress updates: {len(task.data.progresses)}")
        for progress in task.data.progresses:
            print(f"    - {progress}")

    # Show user preferences if available
    if task.data.user_preferences:
        print("  User preferences:")
        for pref in task.data.user_preferences:
            print(f"    - {pref}")

&lt;/code&gt;&lt;/pre&gt; 
  &lt;blockquote&gt; 
   &lt;p&gt;&lt;code&gt;flush&lt;/code&gt; is a blocking call, it will wait for the task extraction to complete. You don't need to call it in production, Acontext has a &lt;a href="https://docs.acontext.io/observe/buffer"&gt;buffer mechanism&lt;/a&gt; to ensure the task extraction is completed right on time.&lt;/p&gt; 
  &lt;/blockquote&gt; 
 &lt;/details&gt; 
 &lt;p&gt;Example Task Return:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-txt"&gt;Task #1:
  Title: Search for the latest news about iPhone 15 Pro Max and report findings to the user before any landing page coding.
  Status: success
  Progress updates: 2
    - I confirmed that the first step will be reporting before moving on to landing page development.
    - I have already collected all the iPhone 15 pro max info and reported to the user, waiting for approval for next step.
  User preferences:
    - user expects a report on latest news about iPhone 15 pro max before any coding work on the landing page.

Task #2:
  Title: Initialize a Next.js project for the iPhone 15 Pro Max landing page.
  Status: pending

Task #3:
  Title: Deploy the completed landing page to the website.
  Status: pending
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;You can view the session tasks' statuses in the Dashboard:&lt;/p&gt; 
 &lt;div align="center"&gt; 
  &lt;picture&gt; 
   &lt;img alt="Acontext Learning" src="https://raw.githubusercontent.com/memodb-io/Acontext/main/docs/images/dashboard/session_task_viewer.png" width="100%" /&gt; 
  &lt;/picture&gt; 
  &lt;p&gt;A Task Demo&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;h2&gt;Self-learning&lt;/h2&gt; 
 &lt;p&gt;Acontext can gather a bunch of sessions and learn skills (SOPs) on how to call tools for certain tasks.&lt;/p&gt; 
 &lt;h3&gt;Learn Skills to a &lt;code&gt;Space&lt;/code&gt; &lt;a href="https://docs.acontext.io/learn/skill-space"&gt;üìñ&lt;/a&gt;&lt;/h3&gt; 
 &lt;div align="center"&gt; 
  &lt;picture&gt; 
   &lt;img alt="A Space Demo" src="https://raw.githubusercontent.com/memodb-io/Acontext/main/assets/acontext_dataflow.png" width="100%" /&gt; 
  &lt;/picture&gt; 
  &lt;p&gt;How self-learning works?&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;p&gt;A &lt;code&gt;Space&lt;/code&gt; can store skills, and memories in a Notion-like system. You first need to connect a session to &lt;code&gt;Space&lt;/code&gt; to enable the learning process:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;# Step 1: Create a Space for skill learning
space = client.spaces.create()
print(f"Created Space: {space.id}")

# Step 2: Create a session attached to the space
session = client.sessions.create(space_id=space.id)

# ... push the agent working context
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;The learning happens in the background and is not real-time (delay around 10-30s).&lt;/p&gt; 
 &lt;p&gt;What Acontext will do in the background:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-mermaid"&gt;graph LR
    A[Task Completed] --&amp;gt; B[Task Extraction]
    B --&amp;gt; C{Space Connected?}
    C --&amp;gt;|Yes| D[Queue for Learning]
    C --&amp;gt;|No| E[Skip Learning]
    D --&amp;gt; F[Extract SOP]
    F --&amp;gt; G{Hard Enough?}
    G --&amp;gt;|No - Too Simple| H[Skip Learning]
    G --&amp;gt;|Yes - Complex| I[Store as Skill Block]
    I --&amp;gt; J[Available for Future Sessions]
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Eventually, SOP blocks with tool-call pattern will be saved to &lt;code&gt;Space&lt;/code&gt;. You can view every &lt;code&gt;Space&lt;/code&gt; in the Dashboard:&lt;/p&gt; 
 &lt;div align="center"&gt; 
  &lt;picture&gt; 
   &lt;img alt="A Space Demo" src="https://raw.githubusercontent.com/memodb-io/Acontext/main/docs/images/dashboard/skill_viewer.png" width="100%" /&gt; 
  &lt;/picture&gt; 
  &lt;p&gt;A Space Demo&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;h3&gt;Search Skills from a &lt;code&gt;Space&lt;/code&gt; &lt;a href="https://docs.acontext.io/learn/search-skills"&gt;üìñ&lt;/a&gt;&lt;/h3&gt; 
 &lt;p&gt;To search skills from a &lt;code&gt;Space&lt;/code&gt; and use them in the next session:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;result = client.spaces.experience_search(
    space_id=space.id,
    query="I need to implement authentication",
  	mode="fast"
)
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Acontext supports &lt;code&gt;fast&lt;/code&gt; and &lt;code&gt;agentic&lt;/code&gt; modes for search. The former uses embeddings to match skills. The latter uses an Experience Agent to explore the entire &lt;code&gt;Space&lt;/code&gt; and tries to cover every skill needed.&lt;/p&gt; 
 &lt;p&gt;The return is a list of sop blocks, which look like below:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-json"&gt;{
    "use_when": "star a github repo",
    "preferences": "use personal account. star but not fork",
    "tool_sops": [
        {"tool_name": "goto", "action": "goto the user given github repo url"},
        {"tool_name": "click", "action": "find login button if any, and start to login first"},
        ...
    ]
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h1&gt;üîç Document&lt;/h1&gt; 
&lt;p&gt;To understand what Acontext can do better, please view &lt;a href="https://docs.acontext.io/"&gt;our docs&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;‚ù§Ô∏è Stay Updated&lt;/h1&gt; 
&lt;p&gt;Star Acontext on Github to support and receive instant notifications&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/memodb-io/Acontext/main/assets/star_acontext.gif" alt="click_star" /&gt;&lt;/p&gt; 
&lt;h1&gt;ü§ù Stay Together&lt;/h1&gt; 
&lt;p&gt;Join the community for support and discussions:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://discord.acontext.io"&gt;Discuss with Builders on Acontext Discord&lt;/a&gt; üëª&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://x.com/acontext_io"&gt;Follow Acontext on X&lt;/a&gt; ùïè&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;üåü Contributing&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;Check our &lt;a href="https://raw.githubusercontent.com/memodb-io/Acontext/main/ROADMAP.md"&gt;roadmap.md&lt;/a&gt; first.&lt;/li&gt; 
 &lt;li&gt;Read &lt;a href="https://raw.githubusercontent.com/memodb-io/Acontext/main/CONTRIBUTING.md"&gt;contributing.md&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;üìë LICENSE&lt;/h1&gt; 
&lt;p&gt;This project is currently licensed under &lt;a href="https://raw.githubusercontent.com/memodb-io/Acontext/main/LICENSE"&gt;Apache License 2.0&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;ü•á Badges&lt;/h1&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/memodb-io/Acontext/main/assets/badge-made-with-acontext.svg?sanitize=true" alt="Made with Acontext" /&gt; &lt;img src="https://raw.githubusercontent.com/memodb-io/Acontext/main/assets/badge-made-with-acontext-dark.svg?sanitize=true" alt="Made with Acontext (dark)" /&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-md"&gt;[![Made with Acontext](https://assets.memodb.io/Acontext/badge-made-with-acontext.svg)](https://acontext.io)

[![Made with Acontext](https://assets.memodb.io/Acontext/badge-made-with-acontext-dark.svg)](https://acontext.io)
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>mudler/LocalAI</title>
      <link>https://github.com/mudler/LocalAI</link>
      <description>&lt;p&gt;ü§ñ The free, Open Source alternative to OpenAI, Claude and others. Self-hosted and local-first. Drop-in replacement for OpenAI, running on consumer-grade hardware. No GPU required. Runs gguf, transformers, diffusers and many more. Features: Generate Text, MCP, Audio, Video, Images, Voice Cloning, Distributed, P2P and decentralized inference&lt;/p&gt;&lt;hr&gt;&lt;h1 align="center"&gt; &lt;br /&gt; &lt;img width="300" src="https://raw.githubusercontent.com/mudler/LocalAI/master/core/http/static/logo.png" /&gt; &lt;br /&gt; &lt;br /&gt; &lt;/h1&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/go-skynet/LocalAI/fork" target="blank"&gt; &lt;img src="https://img.shields.io/github/forks/go-skynet/LocalAI?style=for-the-badge" alt="LocalAI forks" /&gt; &lt;/a&gt; &lt;a href="https://github.com/go-skynet/LocalAI/stargazers" target="blank"&gt; &lt;img src="https://img.shields.io/github/stars/go-skynet/LocalAI?style=for-the-badge" alt="LocalAI stars" /&gt; &lt;/a&gt; &lt;a href="https://github.com/go-skynet/LocalAI/pulls" target="blank"&gt; &lt;img src="https://img.shields.io/github/issues-pr/go-skynet/LocalAI?style=for-the-badge" alt="LocalAI pull-requests" /&gt; &lt;/a&gt; &lt;a href="https://github.com/go-skynet/LocalAI/releases"&gt; &lt;img src="https://img.shields.io/github/release/go-skynet/LocalAI?&amp;amp;label=Latest&amp;amp;style=for-the-badge" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://hub.docker.com/r/localai/localai" target="blank"&gt; &lt;img src="https://img.shields.io/badge/dockerhub-images-important.svg?logo=Docker" alt="LocalAI Docker hub" /&gt; &lt;/a&gt; &lt;a href="https://quay.io/repository/go-skynet/local-ai?tab=tags&amp;amp;tag=latest" target="blank"&gt; &lt;img src="https://img.shields.io/badge/quay.io-images-important.svg?" alt="LocalAI Quay.io" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://twitter.com/LocalAI_API" target="blank"&gt; &lt;img src="https://img.shields.io/badge/X-%23000000.svg?style=for-the-badge&amp;amp;logo=X&amp;amp;logoColor=white&amp;amp;label=LocalAI_API" alt="Follow LocalAI_API" /&gt; &lt;/a&gt; &lt;a href="https://discord.gg/uJAeKSAGDy" target="blank"&gt; &lt;img src="https://img.shields.io/badge/dynamic/json?color=blue&amp;amp;label=Discord&amp;amp;style=for-the-badge&amp;amp;query=approximate_member_count&amp;amp;url=https%3A%2F%2Fdiscordapp.com%2Fapi%2Finvites%2FuJAeKSAGDy%3Fwith_counts%3Dtrue&amp;amp;logo=discord" alt="Join LocalAI Discord Community" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://trendshift.io/repositories/5539" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/5539" alt="mudler%2FLocalAI | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;span&gt;üí°&lt;/span&gt; Get help - &lt;a href="https://localai.io/faq/"&gt;‚ùìFAQ&lt;/a&gt; &lt;a href="https://github.com/go-skynet/LocalAI/discussions"&gt;üí≠Discussions&lt;/a&gt; &lt;a href="https://discord.gg/uJAeKSAGDy"&gt;&lt;span&gt;üí¨&lt;/span&gt; Discord&lt;/a&gt; &lt;a href="https://localai.io/"&gt;&lt;span&gt;üìñ&lt;/span&gt; Documentation website&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://localai.io/basics/getting_started/"&gt;üíª Quickstart&lt;/a&gt; &lt;a href="https://models.localai.io/"&gt;üñºÔ∏è Models&lt;/a&gt; &lt;a href="https://github.com/mudler/LocalAI/issues?q=is%3Aissue+is%3Aopen+label%3Aroadmap"&gt;üöÄ Roadmap&lt;/a&gt; &lt;a href="https://github.com/mudler/LocalAI-examples"&gt;üõ´ Examples&lt;/a&gt; Try on &lt;a href="https://t.me/localaiofficial_bot"&gt;&lt;img src="https://img.shields.io/badge/Telegram-2CA5E0?style=for-the-badge&amp;amp;logo=telegram&amp;amp;logoColor=white" alt="Telegram" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;a href="https://github.com/go-skynet/LocalAI/actions/workflows/test.yml"&gt;&lt;img src="https://github.com/go-skynet/LocalAI/actions/workflows/test.yml/badge.svg?sanitize=true" alt="tests" /&gt;&lt;/a&gt;&lt;a href="https://github.com/go-skynet/LocalAI/actions/workflows/release.yaml"&gt;&lt;img src="https://github.com/go-skynet/LocalAI/actions/workflows/release.yaml/badge.svg?sanitize=true" alt="Build and Release" /&gt;&lt;/a&gt;&lt;a href="https://github.com/go-skynet/LocalAI/actions/workflows/image.yml"&gt;&lt;img src="https://github.com/go-skynet/LocalAI/actions/workflows/image.yml/badge.svg?sanitize=true" alt="build container images" /&gt;&lt;/a&gt;&lt;a href="https://github.com/go-skynet/LocalAI/actions/workflows/bump_deps.yaml"&gt;&lt;img src="https://github.com/go-skynet/LocalAI/actions/workflows/bump_deps.yaml/badge.svg?sanitize=true" alt="Bump dependencies" /&gt;&lt;/a&gt;&lt;a href="https://artifacthub.io/packages/search?repo=localai"&gt;&lt;img src="https://img.shields.io/endpoint?url=https://artifacthub.io/badge/repository/localai" alt="Artifact Hub" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;LocalAI&lt;/strong&gt; is the free, Open Source OpenAI alternative. LocalAI act as a drop-in replacement REST API that's compatible with OpenAI (Elevenlabs, Anthropic... ) API specifications for local AI inferencing. It allows you to run LLMs, generate images, audio (and not only) locally or on-prem with consumer grade hardware, supporting multiple model families. Does not require GPU. It is created and maintained by &lt;a href="https://github.com/mudler"&gt;Ettore Di Giacinto&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;üìöüÜï Local Stack Family&lt;/h2&gt; 
&lt;p&gt;üÜï LocalAI is now part of a comprehensive suite of AI tools designed to work together:&lt;/p&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td width="50%" valign="top"&gt; &lt;a href="https://github.com/mudler/LocalAGI"&gt; &lt;img src="https://raw.githubusercontent.com/mudler/LocalAGI/refs/heads/main/webui/react-ui/public/logo_2.png" width="300" alt="LocalAGI Logo" /&gt; &lt;/a&gt; &lt;/td&gt; 
   &lt;td width="50%" valign="top"&gt; &lt;h3&gt;&lt;a href="https://github.com/mudler/LocalAGI"&gt;LocalAGI&lt;/a&gt;&lt;/h3&gt; &lt;p&gt;A powerful Local AI agent management platform that serves as a drop-in replacement for OpenAI's Responses API, enhanced with advanced agentic capabilities.&lt;/p&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="50%" valign="top"&gt; &lt;a href="https://github.com/mudler/LocalRecall"&gt; &lt;img src="https://raw.githubusercontent.com/mudler/LocalRecall/refs/heads/main/static/localrecall_horizontal.png" width="300" alt="LocalRecall Logo" /&gt; &lt;/a&gt; &lt;/td&gt; 
   &lt;td width="50%" valign="top"&gt; &lt;h3&gt;&lt;a href="https://github.com/mudler/LocalRecall"&gt;LocalRecall&lt;/a&gt;&lt;/h3&gt; &lt;p&gt;A REST-ful API and knowledge base management system that provides persistent memory and storage capabilities for AI agents.&lt;/p&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h2&gt;Screenshots / Video&lt;/h2&gt; 
&lt;h3&gt;Youtube video&lt;/h3&gt; 
&lt;h1 align="center"&gt; &lt;br /&gt; &lt;a href="https://www.youtube.com/watch?v=PDqYhB9nNHA" target="_blank"&gt; &lt;img width="300" src="https://img.youtube.com/vi/PDqYhB9nNHA/0.jpg" /&gt; &lt;/a&gt;&lt;br /&gt; &lt;br /&gt; &lt;/h1&gt; 
&lt;h3&gt;Screenshots&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Talk Interface&lt;/th&gt; 
   &lt;th&gt;Generate Audio&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/mudler/LocalAI/master/docs/assets/images/screenshots/screenshot_tts.png" alt="Screenshot 2025-03-31 at 12-01-36 LocalAI - Talk" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/mudler/LocalAI/master/docs/assets/images/screenshots/screenshot_tts.png" alt="Screenshot 2025-03-31 at 12-01-29 LocalAI - Generate audio with voice-en-us-ryan-low" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Models Overview&lt;/th&gt; 
   &lt;th&gt;Generate Images&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/mudler/LocalAI/master/docs/assets/images/screenshots/screenshot_gallery.png" alt="Screenshot 2025-03-31 at 12-01-20 LocalAI - Models" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/mudler/LocalAI/master/docs/assets/images/screenshots/screenshot_image.png" alt="Screenshot 2025-03-31 at 12-31-41 LocalAI - Generate images with flux 1-dev" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Chat Interface&lt;/th&gt; 
   &lt;th&gt;Home&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/mudler/LocalAI/master/docs/assets/images/screenshots/screenshot_chat.png" alt="Screenshot 2025-03-31 at 11-57-44 LocalAI - Chat with localai-functioncall-qwen2 5-7b-v0 5" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/mudler/LocalAI/master/docs/assets/images/screenshots/screenshot_home.png" alt="Screenshot 2025-03-31 at 11-57-23 LocalAI API - c2a39e3 (c2a39e3639227cfd94ffffe9f5691239acc275a8)" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Login&lt;/th&gt; 
   &lt;th&gt;Swarm&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/mudler/LocalAI/master/docs/assets/images/screenshots/screenshot_login.png" alt="Screenshot 2025-03-31 at 12-09-59 " /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/mudler/LocalAI/master/docs/assets/images/screenshots/screenshot_p2p.png" alt="Screenshot 2025-03-31 at 12-10-39 LocalAI - P2P dashboard" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;üíª Quickstart&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;‚ö†Ô∏è &lt;strong&gt;Note:&lt;/strong&gt; The &lt;code&gt;install.sh&lt;/code&gt; script is currently experiencing issues due to the heavy changes currently undergoing in LocalAI and may produce broken or misconfigured installations. Please use Docker installation (see below) or manual binary installation until &lt;a href="https://github.com/mudler/LocalAI/issues/8032"&gt;issue #8032&lt;/a&gt; is resolved.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Run the installer script:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Basic installation
curl https://localai.io/install.sh | sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For more installation options, see &lt;a href="https://localai.io/installation/"&gt;Installer Options&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;macOS Download:&lt;/h3&gt; 
&lt;a href="https://github.com/mudler/LocalAI/releases/latest/download/LocalAI.dmg"&gt; &lt;img src="https://img.shields.io/badge/Download-macOS-blue?style=for-the-badge&amp;amp;logo=apple&amp;amp;logoColor=white" alt="Download LocalAI for macOS" /&gt; &lt;/a&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Note: the DMGs are not signed by Apple as quarantined. See &lt;a href="https://github.com/mudler/LocalAI/issues/6268"&gt;https://github.com/mudler/LocalAI/issues/6268&lt;/a&gt; for a workaround, fix is tracked here: &lt;a href="https://github.com/mudler/LocalAI/issues/6244"&gt;https://github.com/mudler/LocalAI/issues/6244&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Containers (Docker, podman, ...)&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;üí° Docker Run vs Docker Start&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;code&gt;docker run&lt;/code&gt; creates and starts a new container. If a container with the same name already exists, this command will fail.&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;docker start&lt;/code&gt; starts an existing container that was previously created with &lt;code&gt;docker run&lt;/code&gt;.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;If you've already run LocalAI before and want to start it again, use: &lt;code&gt;docker start -i local-ai&lt;/code&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;CPU only image:&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run -ti --name local-ai -p 8080:8080 localai/localai:latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;NVIDIA GPU Images:&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# CUDA 13.0
docker run -ti --name local-ai -p 8080:8080 --gpus all localai/localai:latest-gpu-nvidia-cuda-13

# CUDA 12.0
docker run -ti --name local-ai -p 8080:8080 --gpus all localai/localai:latest-gpu-nvidia-cuda-12

# NVIDIA Jetson (L4T) ARM64
# CUDA 12 (for Nvidia AGX Orin and similar platforms)
docker run -ti --name local-ai -p 8080:8080 --gpus all localai/localai:latest-nvidia-l4t-arm64

# CUDA 13 (for Nvidia DGX Spark)
docker run -ti --name local-ai -p 8080:8080 --gpus all localai/localai:latest-nvidia-l4t-arm64-cuda-13
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;AMD GPU Images (ROCm):&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run -ti --name local-ai -p 8080:8080 --device=/dev/kfd --device=/dev/dri --group-add=video localai/localai:latest-gpu-hipblas
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Intel GPU Images (oneAPI):&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run -ti --name local-ai -p 8080:8080 --device=/dev/dri/card1 --device=/dev/dri/renderD128 localai/localai:latest-gpu-intel
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Vulkan GPU Images:&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run -ti --name local-ai -p 8080:8080 localai/localai:latest-gpu-vulkan
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;AIO Images (pre-downloaded models):&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# CPU version
docker run -ti --name local-ai -p 8080:8080 localai/localai:latest-aio-cpu

# NVIDIA CUDA 13 version
docker run -ti --name local-ai -p 8080:8080 --gpus all localai/localai:latest-aio-gpu-nvidia-cuda-13

# NVIDIA CUDA 12 version
docker run -ti --name local-ai -p 8080:8080 --gpus all localai/localai:latest-aio-gpu-nvidia-cuda-12

# Intel GPU version
docker run -ti --name local-ai -p 8080:8080 localai/localai:latest-aio-gpu-intel

# AMD GPU version
docker run -ti --name local-ai -p 8080:8080 --device=/dev/kfd --device=/dev/dri --group-add=video localai/localai:latest-aio-gpu-hipblas
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For more information about the AIO images and pre-downloaded models, see &lt;a href="https://localai.io/basics/container/"&gt;Container Documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;To load models:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# From the model gallery (see available models with `local-ai models list`, in the WebUI from the model tab, or visiting https://models.localai.io)
local-ai run llama-3.2-1b-instruct:q4_k_m
# Start LocalAI with the phi-2 model directly from huggingface
local-ai run huggingface://TheBloke/phi-2-GGUF/phi-2.Q8_0.gguf
# Install and run a model from the Ollama OCI registry
local-ai run ollama://gemma:2b
# Run a model from a configuration file
local-ai run https://gist.githubusercontent.com/.../phi-2.yaml
# Install and run a model from a standard OCI registry (e.g., Docker Hub)
local-ai run oci://localai/phi-2:latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;‚ö° &lt;strong&gt;Automatic Backend Detection&lt;/strong&gt;: When you install models from the gallery or YAML files, LocalAI automatically detects your system's GPU capabilities (NVIDIA, AMD, Intel) and downloads the appropriate backend. For advanced configuration options, see &lt;a href="https://localai.io/features/gpu-acceleration/#automatic-backend-detection"&gt;GPU Acceleration&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;For more information, see &lt;a href="https://localai.io/basics/getting_started/index.html"&gt;üíª Getting started&lt;/a&gt;, if you are interested in our roadmap items and future enhancements, you can see the &lt;a href="https://github.com/mudler/LocalAI/issues?q=is%3Aissue+is%3Aopen+label%3Aroadmap"&gt;Issues labeled as Roadmap here&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üì∞ Latest project news&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;December 2025: &lt;a href="https://github.com/mudler/LocalAI/pull/7583"&gt;Dynamic Memory Resource reclaimer&lt;/a&gt;, &lt;a href="https://github.com/mudler/LocalAI/pull/7584"&gt;Automatic fitting of models to multiple GPUS(llama.cpp)&lt;/a&gt;, &lt;a href="https://github.com/mudler/LocalAI/pull/7494"&gt;Added Vibevoice backend&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;November 2025: Major improvements to the UX. Among these: &lt;a href="https://github.com/mudler/LocalAI/pull/7245"&gt;Import models via URL&lt;/a&gt; and &lt;a href="https://github.com/mudler/LocalAI/pull/7325"&gt;Multiple chats and history&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;October 2025: üîå &lt;a href="https://localai.io/docs/features/mcp/"&gt;Model Context Protocol (MCP)&lt;/a&gt; support added for agentic capabilities with external tools&lt;/li&gt; 
 &lt;li&gt;September 2025: New Launcher application for MacOS and Linux, extended support to many backends for Mac and Nvidia L4T devices. Models: Added MLX-Audio, WAN 2.2. WebUI improvements and Python-based backends now ships portable python environments.&lt;/li&gt; 
 &lt;li&gt;August 2025: MLX, MLX-VLM, Diffusers and llama.cpp are now supported on Mac M1/M2/M3+ chips ( with &lt;code&gt;development&lt;/code&gt; suffix in the gallery ): &lt;a href="https://github.com/mudler/LocalAI/pull/6049"&gt;https://github.com/mudler/LocalAI/pull/6049&lt;/a&gt; &lt;a href="https://github.com/mudler/LocalAI/pull/6119"&gt;https://github.com/mudler/LocalAI/pull/6119&lt;/a&gt; &lt;a href="https://github.com/mudler/LocalAI/pull/6121"&gt;https://github.com/mudler/LocalAI/pull/6121&lt;/a&gt; &lt;a href="https://github.com/mudler/LocalAI/pull/6060"&gt;https://github.com/mudler/LocalAI/pull/6060&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;July/August 2025: üîç &lt;a href="https://localai.io/features/object-detection/"&gt;Object Detection&lt;/a&gt; added to the API featuring &lt;a href="https://github.com/roboflow/rf-detr"&gt;rf-detr&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;July 2025: All backends migrated outside of the main binary. LocalAI is now more lightweight, small, and automatically downloads the required backend to run the model. &lt;a href="https://github.com/mudler/LocalAI/releases/tag/v3.2.0"&gt;Read the release notes&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;June 2025: &lt;a href="https://github.com/mudler/LocalAI/pull/5607"&gt;Backend management&lt;/a&gt; has been added. Attention: extras images are going to be deprecated from the next release! Read &lt;a href="https://github.com/mudler/LocalAI/pull/5607"&gt;the backend management PR&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;May 2025: &lt;a href="https://github.com/mudler/LocalAI/pull/5466"&gt;Audio input&lt;/a&gt; and &lt;a href="https://github.com/mudler/LocalAI/pull/5396"&gt;Reranking&lt;/a&gt; in llama.cpp backend, &lt;a href="https://github.com/mudler/LocalAI/pull/5392"&gt;Realtime API&lt;/a&gt;, Support to Gemma, SmollVLM, and more multimodal models (available in the gallery).&lt;/li&gt; 
 &lt;li&gt;May 2025: Important: image name changes &lt;a href="https://github.com/mudler/LocalAI/releases/tag/v2.29.0"&gt;See release&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Apr 2025: Rebrand, WebUI enhancements&lt;/li&gt; 
 &lt;li&gt;Apr 2025: &lt;a href="https://github.com/mudler/LocalAGI"&gt;LocalAGI&lt;/a&gt; and &lt;a href="https://github.com/mudler/LocalRecall"&gt;LocalRecall&lt;/a&gt; join the LocalAI family stack.&lt;/li&gt; 
 &lt;li&gt;Apr 2025: WebUI overhaul, AIO images updates&lt;/li&gt; 
 &lt;li&gt;Feb 2025: Backend cleanup, Breaking changes, new backends (kokoro, OutelTTS, faster-whisper), Nvidia L4T images&lt;/li&gt; 
 &lt;li&gt;Jan 2025: LocalAI model release: &lt;a href="https://huggingface.co/mudler/LocalAI-functioncall-phi-4-v0.3"&gt;https://huggingface.co/mudler/LocalAI-functioncall-phi-4-v0.3&lt;/a&gt;, SANA support in diffusers: &lt;a href="https://github.com/mudler/LocalAI/pull/4603"&gt;https://github.com/mudler/LocalAI/pull/4603&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Dec 2024: stablediffusion.cpp backend (ggml) added ( &lt;a href="https://github.com/mudler/LocalAI/pull/4289"&gt;https://github.com/mudler/LocalAI/pull/4289&lt;/a&gt; )&lt;/li&gt; 
 &lt;li&gt;Nov 2024: Bark.cpp backend added ( &lt;a href="https://github.com/mudler/LocalAI/pull/4287"&gt;https://github.com/mudler/LocalAI/pull/4287&lt;/a&gt; )&lt;/li&gt; 
 &lt;li&gt;Nov 2024: Voice activity detection models (&lt;strong&gt;VAD&lt;/strong&gt;) added to the API: &lt;a href="https://github.com/mudler/LocalAI/pull/4204"&gt;https://github.com/mudler/LocalAI/pull/4204&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Oct 2024: examples moved to &lt;a href="https://github.com/mudler/LocalAI-examples"&gt;LocalAI-examples&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Aug 2024: üÜï FLUX-1, &lt;a href="https://explorer.localai.io"&gt;P2P Explorer&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;July 2024: üî•üî• üÜï P2P Dashboard, LocalAI Federated mode and AI Swarms: &lt;a href="https://github.com/mudler/LocalAI/pull/2723"&gt;https://github.com/mudler/LocalAI/pull/2723&lt;/a&gt;. P2P Global community pools: &lt;a href="https://github.com/mudler/LocalAI/issues/3113"&gt;https://github.com/mudler/LocalAI/issues/3113&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;May 2024: üî•üî• Decentralized P2P llama.cpp: &lt;a href="https://github.com/mudler/LocalAI/pull/2343"&gt;https://github.com/mudler/LocalAI/pull/2343&lt;/a&gt; (peer2peer llama.cpp!) üëâ Docs &lt;a href="https://localai.io/features/distribute/"&gt;https://localai.io/features/distribute/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;May 2024: üî•üî• Distributed inferencing: &lt;a href="https://github.com/mudler/LocalAI/pull/2324"&gt;https://github.com/mudler/LocalAI/pull/2324&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;April 2024: Reranker API: &lt;a href="https://github.com/mudler/LocalAI/pull/2121"&gt;https://github.com/mudler/LocalAI/pull/2121&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Roadmap items: &lt;a href="https://github.com/mudler/LocalAI/issues?q=is%3Aissue+is%3Aopen+label%3Aroadmap"&gt;List of issues&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üöÄ &lt;a href="https://localai.io/features/"&gt;Features&lt;/a&gt;&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;üß© &lt;a href="https://localai.io/backends/"&gt;Backend Gallery&lt;/a&gt;: Install/remove backends on the fly, powered by OCI images ‚Äî fully customizable and API-driven.&lt;/li&gt; 
 &lt;li&gt;üìñ &lt;a href="https://localai.io/features/text-generation/"&gt;Text generation with GPTs&lt;/a&gt; (&lt;code&gt;llama.cpp&lt;/code&gt;, &lt;code&gt;transformers&lt;/code&gt;, &lt;code&gt;vllm&lt;/code&gt; ... &lt;a href="https://localai.io/model-compatibility/index.html#model-compatibility-table"&gt;&lt;span&gt;üìñ&lt;/span&gt; and more&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;üó£ &lt;a href="https://localai.io/features/text-to-audio/"&gt;Text to Audio&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üîà &lt;a href="https://localai.io/features/audio-to-text/"&gt;Audio to Text&lt;/a&gt; (Audio transcription with &lt;code&gt;whisper.cpp&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;üé® &lt;a href="https://localai.io/features/image-generation"&gt;Image generation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üî• &lt;a href="https://localai.io/features/openai-functions/"&gt;OpenAI-alike tools API&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üß† &lt;a href="https://localai.io/features/embeddings/"&gt;Embeddings generation for vector databases&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;‚úçÔ∏è &lt;a href="https://localai.io/features/constrained_grammars/"&gt;Constrained grammars&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üñºÔ∏è &lt;a href="https://localai.io/models/"&gt;Download Models directly from Huggingface &lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;ü•Ω &lt;a href="https://localai.io/features/gpt-vision/"&gt;Vision API&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üîç &lt;a href="https://localai.io/features/object-detection/"&gt;Object Detection&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üìà &lt;a href="https://localai.io/features/reranker/"&gt;Reranker API&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üÜïüñß &lt;a href="https://localai.io/features/distribute/"&gt;P2P Inferencing&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üÜïüîå &lt;a href="https://localai.io/docs/features/mcp/"&gt;Model Context Protocol (MCP)&lt;/a&gt; - Agentic capabilities with external tools and &lt;a href="https://github.com/mudler/LocalAGI"&gt;LocalAGI's Agentic capabilities&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üîä Voice activity detection (Silero-VAD support)&lt;/li&gt; 
 &lt;li&gt;üåç Integrated WebUI!&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üß© Supported Backends &amp;amp; Acceleration&lt;/h2&gt; 
&lt;p&gt;LocalAI supports a comprehensive range of AI backends with multiple acceleration options:&lt;/p&gt; 
&lt;h3&gt;Text Generation &amp;amp; Language Models&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Backend&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Acceleration Support&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;llama.cpp&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;LLM inference in C/C++&lt;/td&gt; 
   &lt;td&gt;CUDA 12/13, ROCm, Intel SYCL, Vulkan, Metal, CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;vLLM&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Fast LLM inference with PagedAttention&lt;/td&gt; 
   &lt;td&gt;CUDA 12/13, ROCm, Intel&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;transformers&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;HuggingFace transformers framework&lt;/td&gt; 
   &lt;td&gt;CUDA 12/13, ROCm, Intel, CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;exllama2&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;GPTQ inference library&lt;/td&gt; 
   &lt;td&gt;CUDA 12/13&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;MLX&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Apple Silicon LLM inference&lt;/td&gt; 
   &lt;td&gt;Metal (M1/M2/M3+)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;MLX-VLM&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Apple Silicon Vision-Language Models&lt;/td&gt; 
   &lt;td&gt;Metal (M1/M2/M3+)&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Audio &amp;amp; Speech Processing&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Backend&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Acceleration Support&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;whisper.cpp&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;OpenAI Whisper in C/C++&lt;/td&gt; 
   &lt;td&gt;CUDA 12/13, ROCm, Intel SYCL, Vulkan, CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;faster-whisper&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Fast Whisper with CTranslate2&lt;/td&gt; 
   &lt;td&gt;CUDA 12/13, ROCm, Intel, CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;bark&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Text-to-audio generation&lt;/td&gt; 
   &lt;td&gt;CUDA 12/13, ROCm, Intel&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;bark-cpp&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;C++ implementation of Bark&lt;/td&gt; 
   &lt;td&gt;CUDA, Metal, CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;coqui&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Advanced TTS with 1100+ languages&lt;/td&gt; 
   &lt;td&gt;CUDA 12/13, ROCm, Intel, CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;kokoro&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Lightweight TTS model&lt;/td&gt; 
   &lt;td&gt;CUDA 12/13, ROCm, Intel, CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;chatterbox&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Production-grade TTS&lt;/td&gt; 
   &lt;td&gt;CUDA 12/13, CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;piper&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Fast neural TTS system&lt;/td&gt; 
   &lt;td&gt;CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;kitten-tts&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Kitten TTS models&lt;/td&gt; 
   &lt;td&gt;CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;silero-vad&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Voice Activity Detection&lt;/td&gt; 
   &lt;td&gt;CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;neutts&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Text-to-speech with voice cloning&lt;/td&gt; 
   &lt;td&gt;CUDA 12/13, ROCm, CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;vibevoice&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Real-time TTS with voice cloning&lt;/td&gt; 
   &lt;td&gt;CUDA 12/13, ROCm, Intel, CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;pocket-tts&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Lightweight CPU-based TTS&lt;/td&gt; 
   &lt;td&gt;CUDA 12/13, ROCm, Intel, CPU&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Image &amp;amp; Video Generation&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Backend&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Acceleration Support&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;stablediffusion.cpp&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Stable Diffusion in C/C++&lt;/td&gt; 
   &lt;td&gt;CUDA 12/13, Intel SYCL, Vulkan, CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;diffusers&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;HuggingFace diffusion models&lt;/td&gt; 
   &lt;td&gt;CUDA 12/13, ROCm, Intel, Metal, CPU&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Specialized AI Tasks&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Backend&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Acceleration Support&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;rfdetr&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Real-time object detection&lt;/td&gt; 
   &lt;td&gt;CUDA 12/13, Intel, CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;rerankers&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Document reranking API&lt;/td&gt; 
   &lt;td&gt;CUDA 12/13, ROCm, Intel, CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;local-store&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Vector database&lt;/td&gt; 
   &lt;td&gt;CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;huggingface&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;HuggingFace API integration&lt;/td&gt; 
   &lt;td&gt;API-based&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Hardware Acceleration Matrix&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Acceleration Type&lt;/th&gt; 
   &lt;th&gt;Supported Backends&lt;/th&gt; 
   &lt;th&gt;Hardware Support&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;NVIDIA CUDA 12&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;All CUDA-compatible backends&lt;/td&gt; 
   &lt;td&gt;Nvidia hardware&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;NVIDIA CUDA 13&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;All CUDA-compatible backends&lt;/td&gt; 
   &lt;td&gt;Nvidia hardware&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;AMD ROCm&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;llama.cpp, whisper, vllm, transformers, diffusers, rerankers, coqui, kokoro, bark, neutts, vibevoice, pocket-tts&lt;/td&gt; 
   &lt;td&gt;AMD Graphics&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Intel oneAPI&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;llama.cpp, whisper, stablediffusion, vllm, transformers, diffusers, rfdetr, rerankers, exllama2, coqui, kokoro, bark, vibevoice, pocket-tts&lt;/td&gt; 
   &lt;td&gt;Intel Arc, Intel iGPUs&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Apple Metal&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;llama.cpp, whisper, diffusers, MLX, MLX-VLM, bark-cpp&lt;/td&gt; 
   &lt;td&gt;Apple M1/M2/M3+&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Vulkan&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;llama.cpp, whisper, stablediffusion&lt;/td&gt; 
   &lt;td&gt;Cross-platform GPUs&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;NVIDIA Jetson (CUDA 12)&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;llama.cpp, whisper, stablediffusion, diffusers, rfdetr&lt;/td&gt; 
   &lt;td&gt;ARM64 embedded AI (AGX Orin, etc.)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;NVIDIA Jetson (CUDA 13)&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;llama.cpp, whisper, stablediffusion, diffusers, rfdetr&lt;/td&gt; 
   &lt;td&gt;ARM64 embedded AI (DGX Spark)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;CPU Optimized&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;All backends&lt;/td&gt; 
   &lt;td&gt;AVX/AVX2/AVX512, quantization support&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;üîó Community and integrations&lt;/h3&gt; 
&lt;p&gt;Build and deploy custom containers:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/sozercan/aikit"&gt;https://github.com/sozercan/aikit&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;WebUIs:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Jirubizu/localai-admin"&gt;https://github.com/Jirubizu/localai-admin&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/go-skynet/LocalAI-frontend"&gt;https://github.com/go-skynet/LocalAI-frontend&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;QA-Pilot(An interactive chat project that leverages LocalAI LLMs for rapid understanding and navigation of GitHub code repository) &lt;a href="https://github.com/reid41/QA-Pilot"&gt;https://github.com/reid41/QA-Pilot&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Agentic Libraries:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mudler/cogito"&gt;https://github.com/mudler/cogito&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;MCPs:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mudler/MCPs"&gt;https://github.com/mudler/MCPs&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Model galleries&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/go-skynet/model-gallery"&gt;https://github.com/go-skynet/model-gallery&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Voice:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/richiejp/VoxInput"&gt;https://github.com/richiejp/VoxInput&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Other:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Helm chart &lt;a href="https://github.com/go-skynet/helm-charts"&gt;https://github.com/go-skynet/helm-charts&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;VSCode extension &lt;a href="https://github.com/badgooooor/localai-vscode-plugin"&gt;https://github.com/badgooooor/localai-vscode-plugin&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Langchain: &lt;a href="https://python.langchain.com/docs/integrations/providers/localai/"&gt;https://python.langchain.com/docs/integrations/providers/localai/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Terminal utility &lt;a href="https://github.com/djcopley/ShellOracle"&gt;https://github.com/djcopley/ShellOracle&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Local Smart assistant &lt;a href="https://github.com/mudler/LocalAGI"&gt;https://github.com/mudler/LocalAGI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Home Assistant &lt;a href="https://github.com/sammcj/homeassistant-localai"&gt;https://github.com/sammcj/homeassistant-localai&lt;/a&gt; / &lt;a href="https://github.com/drndos/hass-openai-custom-conversation"&gt;https://github.com/drndos/hass-openai-custom-conversation&lt;/a&gt; / &lt;a href="https://github.com/valentinfrlch/ha-gpt4vision"&gt;https://github.com/valentinfrlch/ha-gpt4vision&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Discord bot &lt;a href="https://github.com/mudler/LocalAGI/tree/main/examples/discord"&gt;https://github.com/mudler/LocalAGI/tree/main/examples/discord&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Slack bot &lt;a href="https://github.com/mudler/LocalAGI/tree/main/examples/slack"&gt;https://github.com/mudler/LocalAGI/tree/main/examples/slack&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Shell-Pilot(Interact with LLM using LocalAI models via pure shell scripts on your Linux or MacOS system) &lt;a href="https://github.com/reid41/shell-pilot"&gt;https://github.com/reid41/shell-pilot&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Telegram bot &lt;a href="https://github.com/mudler/LocalAI/tree/master/examples/telegram-bot"&gt;https://github.com/mudler/LocalAI/tree/master/examples/telegram-bot&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Another Telegram Bot &lt;a href="https://github.com/JackBekket/Hellper"&gt;https://github.com/JackBekket/Hellper&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Auto-documentation &lt;a href="https://github.com/JackBekket/Reflexia"&gt;https://github.com/JackBekket/Reflexia&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Github bot which answer on issues, with code and documentation as context &lt;a href="https://github.com/JackBekket/GitHelper"&gt;https://github.com/JackBekket/GitHelper&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Github Actions: &lt;a href="https://github.com/marketplace/actions/start-localai"&gt;https://github.com/marketplace/actions/start-localai&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Examples: &lt;a href="https://github.com/mudler/LocalAI/tree/master/examples/"&gt;https://github.com/mudler/LocalAI/tree/master/examples/&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üîó Resources&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://localai.io/docs/advanced/fine-tuning/"&gt;LLM finetuning guide&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://localai.io/basics/build/index.html"&gt;How to build locally&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://localai.io/basics/getting_started/index.html#run-localai-in-kubernetes"&gt;How to install in Kubernetes&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://localai.io/docs/integrations/"&gt;Projects integrating LocalAI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://io.midori-ai.xyz/howtos/"&gt;How tos section&lt;/a&gt; (curated by our community)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;&lt;span&gt;üìñ&lt;/span&gt; üé• &lt;a href="https://localai.io/basics/news/#media-blogs-social"&gt;Media, Blogs, Social&lt;/a&gt;&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.suse.com/c/running-ai-locally/"&gt;Run Visual studio code with LocalAI (SUSE)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üÜï &lt;a href="https://mudler.pm/posts/local-ai-jetson-nano-devkit/"&gt;Run LocalAI on Jetson Nano Devkit&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.pulumi.com/blog/low-code-llm-apps-with-local-ai-flowise-and-pulumi/"&gt;Run LocalAI on AWS EKS with Pulumi&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://staleks.hashnode.dev/installing-localai-on-aws-ec2-instance"&gt;Run LocalAI on AWS&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://mudler.pm/posts/smart-slackbot-for-teams/"&gt;Create a slackbot for teams and OSS projects that answer to documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=PKrDNuJ_dfE"&gt;LocalAI meets k8sgpt&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://mudler.pm/posts/localai-question-answering/"&gt;Question Answering on Documents locally with LangChain, LocalAI, Chroma, and GPT4All&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://medium.com/@tyler_97636/k8sgpt-localai-unlock-kubernetes-superpowers-for-free-584790de9b65"&gt;Tutorial to use k8sgpt with LocalAI&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Citation&lt;/h2&gt; 
&lt;p&gt;If you utilize this repository, data in a downstream project, please consider citing it with:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;@misc{localai,
  author = {Ettore Di Giacinto},
  title = {LocalAI: The free, Open source OpenAI alternative},
  year = {2023},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/go-skynet/LocalAI}},
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;‚ù§Ô∏è Sponsors&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Do you find LocalAI useful?&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Support the project by becoming &lt;a href="https://github.com/sponsors/mudler"&gt;a backer or sponsor&lt;/a&gt;. Your logo will show up here with a link to your website.&lt;/p&gt; 
&lt;p&gt;A huge thank you to our generous sponsors who support this project covering CI expenses, and our &lt;a href="https://github.com/sponsors/mudler"&gt;Sponsor list&lt;/a&gt;:&lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://www.spectrocloud.com/" target="blank"&gt; &lt;img height="200" src="https://github.com/user-attachments/assets/72eab1dd-8b93-4fc0-9ade-84db49f24962" /&gt; &lt;/a&gt; &lt;a href="https://www.premai.io/" target="blank"&gt; &lt;img height="200" src="https://github.com/mudler/LocalAI/assets/2420543/42e4ca83-661e-4f79-8e46-ae43689683d6" /&gt; &lt;br /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;h3&gt;Individual sponsors&lt;/h3&gt; 
&lt;p&gt;A special thanks to individual sponsors that contributed to the project, a full list is in &lt;a href="https://github.com/sponsors/mudler"&gt;Github&lt;/a&gt; and &lt;a href="https://buymeacoffee.com/mudler"&gt;buymeacoffee&lt;/a&gt;, a special shout out goes to &lt;a href="https://github.com/drikster80"&gt;drikster80&lt;/a&gt; for being generous. Thank you everyone!&lt;/p&gt; 
&lt;h2&gt;üåü Star history&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://star-history.com/#go-skynet/LocalAI&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=go-skynet/LocalAI&amp;amp;type=Date" alt="LocalAI Star history Chart" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üìñ License&lt;/h2&gt; 
&lt;p&gt;LocalAI is a community-driven project created by &lt;a href="https://github.com/mudler/"&gt;Ettore Di Giacinto&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;MIT - Author Ettore Di Giacinto &lt;a href="mailto:mudler@localai.io"&gt;mudler@localai.io&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üôá Acknowledgements&lt;/h2&gt; 
&lt;p&gt;LocalAI couldn't have been built without the help of great software already available from the community. Thank you!&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ggerganov/llama.cpp"&gt;llama.cpp&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tatsu-lab/stanford_alpaca"&gt;https://github.com/tatsu-lab/stanford_alpaca&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/cornelk/llama-go"&gt;https://github.com/cornelk/llama-go&lt;/a&gt; for the initial ideas&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/antimatter15/alpaca.cpp"&gt;https://github.com/antimatter15/alpaca.cpp&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/EdVince/Stable-Diffusion-NCNN"&gt;https://github.com/EdVince/Stable-Diffusion-NCNN&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ggerganov/whisper.cpp"&gt;https://github.com/ggerganov/whisper.cpp&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/rhasspy/piper"&gt;https://github.com/rhasspy/piper&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ü§ó Contributors&lt;/h2&gt; 
&lt;p&gt;This is a community project, a special thanks to our contributors! ü§ó &lt;a href="https://github.com/go-skynet/LocalAI/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=go-skynet/LocalAI" /&gt; &lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>ollama/ollama</title>
      <link>https://github.com/ollama/ollama</link>
      <description>&lt;p&gt;Get up and running with OpenAI gpt-oss, DeepSeek-R1, Gemma 3 and other models.&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt;
  &amp;nbsp; 
 &lt;a href="https://ollama.com"&gt; &lt;img alt="ollama" width="240" src="https://github.com/ollama/ollama/assets/3325447/0d0b44e2-8f4a-4e99-9b52-a5c1c741c8f7" /&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;h1&gt;Ollama&lt;/h1&gt; 
&lt;p&gt;Get up and running with large language models.&lt;/p&gt; 
&lt;h3&gt;macOS&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://ollama.com/download/Ollama.dmg"&gt;Download&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Windows&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://ollama.com/download/OllamaSetup.exe"&gt;Download&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Linux&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;curl -fsSL https://ollama.com/install.sh | sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;a href="https://docs.ollama.com/linux#manual-install"&gt;Manual install instructions&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Docker&lt;/h3&gt; 
&lt;p&gt;The official &lt;a href="https://hub.docker.com/r/ollama/ollama"&gt;Ollama Docker image&lt;/a&gt; &lt;code&gt;ollama/ollama&lt;/code&gt; is available on Docker Hub.&lt;/p&gt; 
&lt;h3&gt;Libraries&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ollama/ollama-python"&gt;ollama-python&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ollama/ollama-js"&gt;ollama-js&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Community&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://discord.gg/ollama"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://reddit.com/r/ollama"&gt;Reddit&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Quickstart&lt;/h2&gt; 
&lt;p&gt;To run and chat with &lt;a href="https://ollama.com/library/gemma3"&gt;Gemma 3&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;ollama run gemma3
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Model library&lt;/h2&gt; 
&lt;p&gt;Ollama supports a list of models available on &lt;a href="https://ollama.com/library" title="ollama model library"&gt;ollama.com/library&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Here are some example models that can be downloaded:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Model&lt;/th&gt; 
   &lt;th&gt;Parameters&lt;/th&gt; 
   &lt;th&gt;Size&lt;/th&gt; 
   &lt;th&gt;Download&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Gemma 3&lt;/td&gt; 
   &lt;td&gt;1B&lt;/td&gt; 
   &lt;td&gt;815MB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run gemma3:1b&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Gemma 3&lt;/td&gt; 
   &lt;td&gt;4B&lt;/td&gt; 
   &lt;td&gt;3.3GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run gemma3&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Gemma 3&lt;/td&gt; 
   &lt;td&gt;12B&lt;/td&gt; 
   &lt;td&gt;8.1GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run gemma3:12b&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Gemma 3&lt;/td&gt; 
   &lt;td&gt;27B&lt;/td&gt; 
   &lt;td&gt;17GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run gemma3:27b&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;QwQ&lt;/td&gt; 
   &lt;td&gt;32B&lt;/td&gt; 
   &lt;td&gt;20GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run qwq&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;DeepSeek-R1&lt;/td&gt; 
   &lt;td&gt;7B&lt;/td&gt; 
   &lt;td&gt;4.7GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run deepseek-r1&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;DeepSeek-R1&lt;/td&gt; 
   &lt;td&gt;671B&lt;/td&gt; 
   &lt;td&gt;404GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run deepseek-r1:671b&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Llama 4&lt;/td&gt; 
   &lt;td&gt;109B&lt;/td&gt; 
   &lt;td&gt;67GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run llama4:scout&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Llama 4&lt;/td&gt; 
   &lt;td&gt;400B&lt;/td&gt; 
   &lt;td&gt;245GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run llama4:maverick&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Llama 3.3&lt;/td&gt; 
   &lt;td&gt;70B&lt;/td&gt; 
   &lt;td&gt;43GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run llama3.3&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Llama 3.2&lt;/td&gt; 
   &lt;td&gt;3B&lt;/td&gt; 
   &lt;td&gt;2.0GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run llama3.2&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Llama 3.2&lt;/td&gt; 
   &lt;td&gt;1B&lt;/td&gt; 
   &lt;td&gt;1.3GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run llama3.2:1b&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Llama 3.2 Vision&lt;/td&gt; 
   &lt;td&gt;11B&lt;/td&gt; 
   &lt;td&gt;7.9GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run llama3.2-vision&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Llama 3.2 Vision&lt;/td&gt; 
   &lt;td&gt;90B&lt;/td&gt; 
   &lt;td&gt;55GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run llama3.2-vision:90b&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Llama 3.1&lt;/td&gt; 
   &lt;td&gt;8B&lt;/td&gt; 
   &lt;td&gt;4.7GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run llama3.1&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Llama 3.1&lt;/td&gt; 
   &lt;td&gt;405B&lt;/td&gt; 
   &lt;td&gt;231GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run llama3.1:405b&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Phi 4&lt;/td&gt; 
   &lt;td&gt;14B&lt;/td&gt; 
   &lt;td&gt;9.1GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run phi4&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Phi 4 Mini&lt;/td&gt; 
   &lt;td&gt;3.8B&lt;/td&gt; 
   &lt;td&gt;2.5GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run phi4-mini&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Mistral&lt;/td&gt; 
   &lt;td&gt;7B&lt;/td&gt; 
   &lt;td&gt;4.1GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run mistral&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Moondream 2&lt;/td&gt; 
   &lt;td&gt;1.4B&lt;/td&gt; 
   &lt;td&gt;829MB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run moondream&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Neural Chat&lt;/td&gt; 
   &lt;td&gt;7B&lt;/td&gt; 
   &lt;td&gt;4.1GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run neural-chat&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Starling&lt;/td&gt; 
   &lt;td&gt;7B&lt;/td&gt; 
   &lt;td&gt;4.1GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run starling-lm&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Code Llama&lt;/td&gt; 
   &lt;td&gt;7B&lt;/td&gt; 
   &lt;td&gt;3.8GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run codellama&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Llama 2 Uncensored&lt;/td&gt; 
   &lt;td&gt;7B&lt;/td&gt; 
   &lt;td&gt;3.8GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run llama2-uncensored&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;LLaVA&lt;/td&gt; 
   &lt;td&gt;7B&lt;/td&gt; 
   &lt;td&gt;4.5GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run llava&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Granite-3.3&lt;/td&gt; 
   &lt;td&gt;8B&lt;/td&gt; 
   &lt;td&gt;4.9GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run granite3.3&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] You should have at least 8 GB of RAM available to run the 7B models, 16 GB to run the 13B models, and 32 GB to run the 33B models.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Customize a model&lt;/h2&gt; 
&lt;h3&gt;Import from GGUF&lt;/h3&gt; 
&lt;p&gt;Ollama supports importing GGUF models in the Modelfile:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Create a file named &lt;code&gt;Modelfile&lt;/code&gt;, with a &lt;code&gt;FROM&lt;/code&gt; instruction with the local filepath to the model you want to import.&lt;/p&gt; &lt;pre&gt;&lt;code&gt;FROM ./vicuna-33b.Q4_0.gguf
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Create the model in Ollama&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;ollama create example -f Modelfile
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Run the model&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;ollama run example
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Import from Safetensors&lt;/h3&gt; 
&lt;p&gt;See the &lt;a href="https://docs.ollama.com/import"&gt;guide&lt;/a&gt; on importing models for more information.&lt;/p&gt; 
&lt;h3&gt;Customize a prompt&lt;/h3&gt; 
&lt;p&gt;Models from the Ollama library can be customized with a prompt. For example, to customize the &lt;code&gt;llama3.2&lt;/code&gt; model:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;ollama pull llama3.2
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Create a &lt;code&gt;Modelfile&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;FROM llama3.2

# set the temperature to 1 [higher is more creative, lower is more coherent]
PARAMETER temperature 1

# set the system message
SYSTEM """
You are Mario from Super Mario Bros. Answer as Mario, the assistant, only.
"""
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Next, create and run the model:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;ollama create mario -f ./Modelfile
ollama run mario
&amp;gt;&amp;gt;&amp;gt; hi
Hello! It's your friend Mario.
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For more information on working with a Modelfile, see the &lt;a href="https://docs.ollama.com/modelfile"&gt;Modelfile&lt;/a&gt; documentation.&lt;/p&gt; 
&lt;h2&gt;CLI Reference&lt;/h2&gt; 
&lt;h3&gt;Create a model&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;ollama create&lt;/code&gt; is used to create a model from a Modelfile.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;ollama create mymodel -f ./Modelfile
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Pull a model&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;ollama pull llama3.2
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;This command can also be used to update a local model. Only the diff will be pulled.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Remove a model&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;ollama rm llama3.2
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Copy a model&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;ollama cp llama3.2 my-model
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Multiline input&lt;/h3&gt; 
&lt;p&gt;For multiline input, you can wrap text with &lt;code&gt;"""&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt; """Hello,
... world!
... """
I'm a basic program that prints the famous "Hello, world!" message to the console.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Multimodal models&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;ollama run llava "What's in this image? /Users/jmorgan/Desktop/smile.png"
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Output&lt;/strong&gt;: The image features a yellow smiley face, which is likely the central focus of the picture.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Pass the prompt as an argument&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;ollama run llama3.2 "Summarize this file: $(cat README.md)"
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Output&lt;/strong&gt;: Ollama is a lightweight, extensible framework for building and running language models on the local machine. It provides a simple API for creating, running, and managing models, as well as a library of pre-built models that can be easily used in a variety of applications.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Show model information&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;ollama show llama3.2
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;List models on your computer&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;ollama list
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;List which models are currently loaded&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;ollama ps
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Stop a model which is currently running&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;ollama stop llama3.2
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Generate embeddings from the CLI&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;ollama run embeddinggemma "Your text to embed"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can also pipe text for scripted workflows:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;echo "Your text to embed" | ollama run embeddinggemma
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Start Ollama&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;ollama serve&lt;/code&gt; is used when you want to start ollama without running the desktop application.&lt;/p&gt; 
&lt;h2&gt;Building&lt;/h2&gt; 
&lt;p&gt;See the &lt;a href="https://github.com/ollama/ollama/raw/main/docs/development.md"&gt;developer guide&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Running local builds&lt;/h3&gt; 
&lt;p&gt;Next, start the server:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;./ollama serve
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Finally, in a separate shell, run a model:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;./ollama run llama3.2
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Building with MLX (experimental)&lt;/h2&gt; 
&lt;p&gt;First build the MLX libraries:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;cmake --preset MLX
cmake --build --preset MLX --parallel
cmake --install build --component MLX
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;When building with the &lt;code&gt;-tags mlx&lt;/code&gt; flag, the main &lt;code&gt;ollama&lt;/code&gt; binary includes MLX support for experimental features like image generation:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;go build -tags mlx .
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Finally, start the server:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;./ollama serve
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Building MLX with CUDA&lt;/h3&gt; 
&lt;p&gt;When building with CUDA, use the preset "MLX CUDA 13" or "MLX CUDA 12" to enable CUDA with default architectures:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;cmake --preset 'MLX CUDA 13'
cmake --build --preset 'MLX CUDA 13' --parallel
cmake --install build --component MLX
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;REST API&lt;/h2&gt; 
&lt;p&gt;Ollama has a REST API for running and managing models.&lt;/p&gt; 
&lt;h3&gt;Generate a response&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;curl http://localhost:11434/api/generate -d '{
  "model": "llama3.2",
  "prompt":"Why is the sky blue?"
}'
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Chat with a model&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;curl http://localhost:11434/api/chat -d '{
  "model": "llama3.2",
  "messages": [
    { "role": "user", "content": "why is the sky blue?" }
  ]
}'
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See the &lt;a href="https://raw.githubusercontent.com/ollama/ollama/main/docs/api.md"&gt;API documentation&lt;/a&gt; for all endpoints.&lt;/p&gt; 
&lt;h2&gt;Community Integrations&lt;/h2&gt; 
&lt;h3&gt;Web &amp;amp; Desktop&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/onyx-dot-app/onyx"&gt;Onyx&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/open-webui/open-webui"&gt;Open WebUI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/aws-samples/swift-chat"&gt;SwiftChat (macOS with ReactNative)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/AugustDev/enchanted"&gt;Enchanted (macOS native)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/fmaclen/hollama"&gt;Hollama&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ParisNeo/lollms-webui"&gt;Lollms WebUI (Single user)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ParisNeo/lollms"&gt;Lollms (Multi users)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/danny-avila/LibreChat"&gt;LibreChat&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/bionic-gpt/bionic-gpt"&gt;Bionic GPT&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/rtcfirefly/ollama-ui"&gt;HTML UI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/bajahaw/ai-ui"&gt;AI-UI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jikkuatwork/saddle"&gt;Saddle&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.tagspaces.org"&gt;TagSpaces&lt;/a&gt; (A platform for file-based apps, &lt;a href="https://docs.tagspaces.org/ai/"&gt;utilizing Ollama&lt;/a&gt; for the generation of tags and descriptions)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ivanfioravanti/chatbot-ollama"&gt;Chatbot UI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mckaywrigley/chatbot-ui"&gt;Chatbot UI v2&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ollama-interface/Ollama-Gui?tab=readme-ov-file"&gt;Typescript UI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/richawo/minimal-llm-ui"&gt;Minimalistic React UI for Ollama Models&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/kevinhermawan/Ollamac"&gt;Ollamac&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/enricoros/big-AGI"&gt;big-AGI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/cheshire-cat-ai/core"&gt;Cheshire Cat assistant framework&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/semperai/amica"&gt;Amica&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/BruceMacD/chatd"&gt;chatd&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/kghandour/Ollama-SwiftUI"&gt;Ollama-SwiftUI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/langgenius/dify"&gt;Dify.AI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://mindmac.app"&gt;MindMac&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jakobhoeg/nextjs-ollama-llm-ui"&gt;NextJS Web Interface for Ollama&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://msty.app"&gt;Msty&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Bin-Huang/Chatbox"&gt;Chatbox&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tgraupmann/WinForm_Ollama_Copilot"&gt;WinForm Ollama Copilot&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ChatGPTNextWeb/ChatGPT-Next-Web"&gt;NextChat&lt;/a&gt; with &lt;a href="https://docs.nextchat.dev/models/ollama"&gt;Get Started Doc&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mmo80/alpaca-webui"&gt;Alpaca WebUI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/enoch1118/ollamaGUI"&gt;OllamaGUI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/InternLM/OpenAOE"&gt;OpenAOE&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/leonid20000/OdinRunes"&gt;Odin Runes&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mrdjohnson/llm-x"&gt;LLM-X&lt;/a&gt; (Progressive Web App)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Mintplex-Labs/anything-llm"&gt;AnythingLLM (Docker + MacOs/Windows/Linux native app)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/rapidarchitect/ollama_basic_chat"&gt;Ollama Basic Chat: Uses HyperDiv Reactive UI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/drazdra/ollama-chats"&gt;Ollama-chats RPG&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://intellibar.app/"&gt;IntelliBar&lt;/a&gt; (AI-powered assistant for macOS)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/AliAhmedNada/jirapt"&gt;Jirapt&lt;/a&gt; (Jira Integration to generate issues, tasks, epics)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/AliAhmedNada/ojira"&gt;ojira&lt;/a&gt; (Jira chrome plugin to easily generate descriptions for tasks)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/reid41/QA-Pilot"&gt;QA-Pilot&lt;/a&gt; (Interactive chat tool that can leverage Ollama models for rapid understanding and navigation of GitHub code repositories)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/sugarforever/chat-ollama"&gt;ChatOllama&lt;/a&gt; (Open Source Chatbot based on Ollama with Knowledge Bases)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Nagi-ovo/CRAG-Ollama-Chat"&gt;CRAG Ollama Chat&lt;/a&gt; (Simple Web Search with Corrective RAG)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/infiniflow/ragflow"&gt;RAGFlow&lt;/a&gt; (Open-source Retrieval-Augmented Generation engine based on deep document understanding)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/StreamDeploy-DevRel/streamdeploy-llm-app-scaffold"&gt;StreamDeploy&lt;/a&gt; (LLM Application Scaffold)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/swuecho/chat"&gt;chat&lt;/a&gt; (chat web app for teams)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/lobehub/lobe-chat"&gt;Lobe Chat&lt;/a&gt; with &lt;a href="https://lobehub.com/docs/self-hosting/examples/ollama"&gt;Integrating Doc&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/datvodinh/rag-chatbot.git"&gt;Ollama RAG Chatbot&lt;/a&gt; (Local Chat with multiple PDFs using Ollama and RAG)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.nurgo-software.com/products/brainsoup"&gt;BrainSoup&lt;/a&gt; (Flexible native client with RAG &amp;amp; multi-agent automation)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Renset/macai"&gt;macai&lt;/a&gt; (macOS client for Ollama, ChatGPT, and other compatible API back-ends)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/josStorer/RWKV-Runner"&gt;RWKV-Runner&lt;/a&gt; (RWKV offline LLM deployment tool, also usable as a client for ChatGPT and Ollama)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/dezoito/ollama-grid-search"&gt;Ollama Grid Search&lt;/a&gt; (app to evaluate and compare models)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Otacon/olpaka"&gt;Olpaka&lt;/a&gt; (User-friendly Flutter Web App for Ollama)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://casibase.org"&gt;Casibase&lt;/a&gt; (An open source AI knowledge base and dialogue system combining the latest RAG, SSO, ollama support, and multiple large language models.)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/CrazyNeil/OllamaSpring"&gt;OllamaSpring&lt;/a&gt; (Ollama Client for macOS)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/kartikm7/llocal"&gt;LLocal.in&lt;/a&gt; (Easy to use Electron Desktop Client for Ollama)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/dcSpark/shinkai-apps"&gt;Shinkai Desktop&lt;/a&gt; (Two click install Local AI using Ollama + Files + RAG)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/zeyoyt/ailama"&gt;AiLama&lt;/a&gt; (A Discord User App that allows you to interact with Ollama anywhere in Discord)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/rapidarchitect/ollama_mesop/"&gt;Ollama with Google Mesop&lt;/a&gt; (Mesop Chat Client implementation with Ollama)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/SciPhi-AI/R2R"&gt;R2R&lt;/a&gt; (Open-source RAG engine)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/elearningshow/ollama-kis"&gt;Ollama-Kis&lt;/a&gt; (A simple easy-to-use GUI with sample custom LLM for Drivers Education)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://opengpa.org"&gt;OpenGPA&lt;/a&gt; (Open-source offline-first Enterprise Agentic Application)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mateuszmigas/painting-droid"&gt;Painting Droid&lt;/a&gt; (Painting app with AI integrations)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.kerlig.com/"&gt;Kerlig AI&lt;/a&gt; (AI writing assistant for macOS)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/MindWorkAI/AI-Studio"&gt;AI Studio&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/gyopak/sidellama"&gt;Sidellama&lt;/a&gt; (browser-based LLM client)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/trypromptly/LLMStack"&gt;LLMStack&lt;/a&gt; (No-code multi-agent framework to build LLM agents and workflows)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://boltai.com"&gt;BoltAI for Mac&lt;/a&gt; (AI Chat Client for Mac)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/av/harbor"&gt;Harbor&lt;/a&gt; (Containerized LLM Toolkit with Ollama as default backend)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/szczyglis-dev/py-gpt"&gt;PyGPT&lt;/a&gt; (AI desktop assistant for Linux, Windows, and Mac)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Jeffser/Alpaca"&gt;Alpaca&lt;/a&gt; (An Ollama client application for Linux and macOS made with GTK4 and Adwaita)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Significant-Gravitas/AutoGPT/raw/master/docs/content/platform/ollama.md"&gt;AutoGPT&lt;/a&gt; (AutoGPT Ollama integration)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.jonathanhecl.com/go-crew/"&gt;Go-CREW&lt;/a&gt; (Powerful Offline RAG in Golang)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/openvmp/partcad/"&gt;PartCAD&lt;/a&gt; (CAD model generation with OpenSCAD and CadQuery)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ollama4j/ollama4j-web-ui"&gt;Ollama4j Web UI&lt;/a&gt; - Java-based Web UI for Ollama built with Vaadin, Spring Boot, and Ollama4j&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/kspviswa/pyOllaMx"&gt;PyOllaMx&lt;/a&gt; - macOS application capable of chatting with both Ollama and Apple MLX models.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/cline/cline"&gt;Cline&lt;/a&gt; - Formerly known as Claude Dev is a VS Code extension for multi-file/whole-repo coding&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/voideditor/void"&gt;Void&lt;/a&gt; (Open source AI code editor and Cursor alternative)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/kangfenmao/cherry-studio"&gt;Cherry Studio&lt;/a&gt; (Desktop client with Ollama support)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/1runeberg/confichat"&gt;ConfiChat&lt;/a&gt; (Lightweight, standalone, multi-platform, and privacy-focused LLM chat interface with optional encryption)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/nickthecook/archyve"&gt;Archyve&lt;/a&gt; (RAG-enabling document library)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/rapidarchitect/ollama-crew-mesop"&gt;crewAI with Mesop&lt;/a&gt; (Mesop Web Interface to run crewAI with Ollama)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/chyok/ollama-gui"&gt;Tkinter-based client&lt;/a&gt; (Python tkinter-based Client for Ollama)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/trendy-design/llmchat"&gt;LLMChat&lt;/a&gt; (Privacy focused, 100% local, intuitive all-in-one chat interface)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Leon-Sander/Local-Multimodal-AI-Chat"&gt;Local Multimodal AI Chat&lt;/a&gt; (Ollama-based LLM Chat with support for multiple features, including PDF RAG, voice chat, image-based interactions, and integration with OpenAI.)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/xark-argo/argo"&gt;ARGO&lt;/a&gt; (Locally download and run Ollama and Huggingface models with RAG and deep research on Mac/Windows/Linux)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/EliasPereirah/OrionChat"&gt;OrionChat&lt;/a&gt; - OrionChat is a web interface for chatting with different AI providers&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/bklieger-groq/g1"&gt;G1&lt;/a&gt; (Prototype of using prompting strategies to improve the LLM's reasoning through o1-like reasoning chains.)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/lemonit-eric-mao/ollama-web-management"&gt;Web management&lt;/a&gt; (Web management page)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/promptery/promptery"&gt;Promptery&lt;/a&gt; (desktop client for Ollama.)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/JHubi1/ollama-app"&gt;Ollama App&lt;/a&gt; (Modern and easy-to-use multi-platform client for Ollama)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/annilq/chat-ollama"&gt;chat-ollama&lt;/a&gt; (a React Native client for Ollama)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tcsenpai/spacellama"&gt;SpaceLlama&lt;/a&gt; (Firefox and Chrome extension to quickly summarize web pages with ollama in a sidebar)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tcsenpai/youlama"&gt;YouLama&lt;/a&gt; (Webapp to quickly summarize any YouTube video, supporting Invidious as well)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tcsenpai/dualmind"&gt;DualMind&lt;/a&gt; (Experimental app allowing two models to talk to each other in the terminal or in a web interface)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/h1ddenpr0cess20/ollamarama-matrix"&gt;ollamarama-matrix&lt;/a&gt; (Ollama chatbot for the Matrix chat protocol)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/anan1213095357/ollama-chat-app"&gt;ollama-chat-app&lt;/a&gt; (Flutter-based chat app)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.perfectmemory.ai/"&gt;Perfect Memory AI&lt;/a&gt; (Productivity AI assists personalized by what you have seen on your screen, heard, and said in the meetings)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/hexastack/hexabot"&gt;Hexabot&lt;/a&gt; (A conversational AI builder)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/rapidarchitect/reddit_analyzer"&gt;Reddit Rate&lt;/a&gt; (Search and Rate Reddit topics with a weighted summation)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/adarshM84/OpenTalkGpt"&gt;OpenTalkGpt&lt;/a&gt; (Chrome Extension to manage open-source models supported by Ollama, create custom models, and chat with models from a user-friendly UI)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/vinhnx/vt.ai"&gt;VT&lt;/a&gt; (A minimal multimodal AI chat app, with dynamic conversation routing. Supports local models via Ollama)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/nosia-ai/nosia"&gt;Nosia&lt;/a&gt; (Easy to install and use RAG platform based on Ollama)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/nbonamy/witsy"&gt;Witsy&lt;/a&gt; (An AI Desktop application available for Mac/Windows/Linux)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/US-Artificial-Intelligence/abbey"&gt;Abbey&lt;/a&gt; (A configurable AI interface server with notebooks, document storage, and YouTube support)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/dmayboroda/minima"&gt;Minima&lt;/a&gt; (RAG with on-premises or fully local workflow)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/AidfulAI/aidful-ollama-model-delete"&gt;aidful-ollama-model-delete&lt;/a&gt; (User interface for simplified model cleanup)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ItzCrazyKns/Perplexica"&gt;Perplexica&lt;/a&gt; (An AI-powered search engine &amp;amp; an open-source alternative to Perplexity AI)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/oslook/ollama-webui"&gt;Ollama Chat WebUI for Docker &lt;/a&gt; (Support for local docker deployment, lightweight ollama webui)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://aka.ms/ai-tooklit/ollama-docs"&gt;AI Toolkit for Visual Studio Code&lt;/a&gt; (Microsoft-official VS Code extension to chat, test, evaluate models with Ollama support, and use them in your AI applications.)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/anilkay/MinimalNextOllamaChat"&gt;MinimalNextOllamaChat&lt;/a&gt; (Minimal Web UI for Chat and Model Control)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/TilmanGriesel/chipper"&gt;Chipper&lt;/a&gt; AI interface for tinkerers (Ollama, Haystack RAG, Python)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/CosmicEventHorizon/ChibiChat"&gt;ChibiChat&lt;/a&gt; (Kotlin-based Android app to chat with Ollama and Koboldcpp API endpoints)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/qusaismael/localllm"&gt;LocalLLM&lt;/a&gt; (Minimal Web-App to run ollama models on it with a GUI)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/buiducnhat/ollamazing"&gt;Ollamazing&lt;/a&gt; (Web extension to run Ollama models)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/benhaotang/OpenDeepResearcher-via-searxng"&gt;OpenDeepResearcher-via-searxng&lt;/a&gt; (A Deep Research equivalent endpoint with Ollama support for running locally)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/AIDotNet/AntSK"&gt;AntSK&lt;/a&gt; (Out-of-the-box &amp;amp; Adaptable RAG Chatbot)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/1Panel-dev/MaxKB/"&gt;MaxKB&lt;/a&gt; (Ready-to-use &amp;amp; flexible RAG Chatbot)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/danielekp/yla"&gt;yla&lt;/a&gt; (Web interface to freely interact with your customized models)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/RockChinQ/LangBot"&gt;LangBot&lt;/a&gt; (LLM-based instant messaging bots platform, with Agents, RAG features, supports multiple platforms)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/1Panel-dev/1Panel/"&gt;1Panel&lt;/a&gt; (Web-based Linux Server Management Tool)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Soulter/AstrBot/"&gt;AstrBot&lt;/a&gt; (User-friendly LLM-based multi-platform chatbot with a WebUI, supporting RAG, LLM agents, and plugins integration)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ibrahimcetin/reins"&gt;Reins&lt;/a&gt; (Easily tweak parameters, customize system prompts per chat, and enhance your AI experiments with reasoning model support.)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Aharon-Bensadoun/Flufy"&gt;Flufy&lt;/a&gt; (A beautiful chat interface for interacting with Ollama's API. Built with React, TypeScript, and Material-UI.)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/zeozeozeo/ellama"&gt;Ellama&lt;/a&gt; (Friendly native app to chat with an Ollama instance)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mediar-ai/screenpipe"&gt;screenpipe&lt;/a&gt; Build agents powered by your screen history&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/hengkysteen/ollamb"&gt;Ollamb&lt;/a&gt; (Simple yet rich in features, cross-platform built with Flutter and designed for Ollama. Try the &lt;a href="https://hengkysteen.github.io/demo/ollamb/"&gt;web demo&lt;/a&gt;.)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Writeopia/Writeopia"&gt;Writeopia&lt;/a&gt; (Text editor with integration with Ollama)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/AppFlowy-IO/AppFlowy"&gt;AppFlowy&lt;/a&gt; (AI collaborative workspace with Ollama, cross-platform and self-hostable)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/cushydigit/lumina.git"&gt;Lumina&lt;/a&gt; (A lightweight, minimal React.js frontend for interacting with Ollama servers)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pypi.org/project/tiny-notepad"&gt;Tiny Notepad&lt;/a&gt; (A lightweight, notepad-like interface to chat with ollama available on PyPI)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/hellotunamayo/macLlama"&gt;macLlama (macOS native)&lt;/a&gt; (A native macOS GUI application for interacting with Ollama models, featuring a chat interface.)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/philberndt/GPTranslate"&gt;GPTranslate&lt;/a&gt; (A fast and lightweight, AI powered desktop translation application written with Rust and Tauri. Features real-time translation with OpenAI/Azure/Ollama.)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/NGC13009/ollama-launcher"&gt;ollama launcher&lt;/a&gt; (A launcher for Ollama, aiming to provide users with convenient functions such as ollama server launching, management, or configuration.)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Aj-Seven/ai-hub"&gt;ai-hub&lt;/a&gt; (AI Hub supports multiple models via API keys and Chat support via Ollama API.)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://gitlab.com/mayan-edms/mayan-edms"&gt;Mayan EDMS&lt;/a&gt; (Open source document management system to organize, tag, search, and automate your files with powerful Ollama driven workflows.)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/doolijb/serene-pub"&gt;Serene Pub&lt;/a&gt; (Beginner friendly, open source AI Roleplaying App for Windows, Mac OS and Linux. Search, download and use models with Ollama all inside the app.)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/aqerd/andes"&gt;Andes&lt;/a&gt; (A Visual Studio Code extension that provides a local UI interface for Ollama models)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/kdeps/kdeps"&gt;KDeps&lt;/a&gt; (Kdeps is an offline-first AI framework for building Dockerized full-stack AI applications declaratively using Apple PKL and integrates APIs with Ollama on the backend.)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/KashyapTan/clueless"&gt;Clueless&lt;/a&gt; (Open Source &amp;amp; Local Cluely: A desktop application LLM assistant to help you talk to anything on your screen using locally served Ollama models. Also undetectable to screenshare)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/carbonatedWaterOrg/ollama-co2"&gt;ollama-co2&lt;/a&gt; (FastAPI web interface for monitoring and managing local and remote Ollama servers with real-time model monitoring and concurrent downloads)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://hillnote.com"&gt;Hillnote&lt;/a&gt; (A Markdown-first workspace designed to supercharge your AI workflow. Create documents ready to integrate with Claude, ChatGPT, Gemini, Cursor, and more - all while keeping your work on your device.)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Cloud&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://cloud.google.com/run/docs/tutorials/gpu-gemma2-with-ollama"&gt;Google Cloud&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://fly.io/docs/python/do-more/add-ollama/"&gt;Fly.io&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.koyeb.com/deploy/ollama"&gt;Koyeb&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Tutorial&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/datawhalechina/handy-ollama"&gt;handy-ollama&lt;/a&gt; (Chinese Tutorial for Ollama by &lt;a href="https://github.com/datawhalechina"&gt;Datawhale &lt;/a&gt; - China's Largest Open Source AI Learning Community)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Terminal&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ggozad/oterm"&gt;oterm&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/s-kostyaev/ellama"&gt;Ellama Emacs client&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/zweifisch/ollama"&gt;Emacs client&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/paradoxical-dev/neollama"&gt;neollama&lt;/a&gt; UI client for interacting with models from within Neovim&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/David-Kunz/gen.nvim"&gt;gen.nvim&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/nomnivore/ollama.nvim"&gt;ollama.nvim&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/marco-souza/ollero.nvim"&gt;ollero.nvim&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/gerazov/ollama-chat.nvim"&gt;ollama-chat.nvim&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/huynle/ogpt.nvim"&gt;ogpt.nvim&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/karthink/gptel"&gt;gptel Emacs client&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/dustinblackman/oatmeal"&gt;Oatmeal&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pgibler/cmdh"&gt;cmdh&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/npahlfer/ooo"&gt;ooo&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/reid41/shell-pilot"&gt;shell-pilot&lt;/a&gt;(Interact with models via pure shell scripts on Linux or macOS)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pythops/tenere"&gt;tenere&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/taketwo/llm-ollama"&gt;llm-ollama&lt;/a&gt; for &lt;a href="https://llm.datasette.io/en/stable/"&gt;Datasette's LLM CLI&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/anaisbetts/typechat-cli"&gt;typechat-cli&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/djcopley/ShellOracle"&gt;ShellOracle&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/yusufcanb/tlm"&gt;tlm&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ericcurtin/podman-ollama"&gt;podman-ollama&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/sammcj/gollama"&gt;gollama&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/paulrobello/parllama"&gt;ParLlama&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/cognitivetech/ollama-ebook-summary/"&gt;Ollama eBook Summary&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/rapidarchitect/ollama_moe"&gt;Ollama Mixture of Experts (MOE) in 50 lines of code&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pepo-ec/vim-intelligence-bridge"&gt;vim-intelligence-bridge&lt;/a&gt; Simple interaction of "Ollama" with the Vim editor&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://x-cmd.com/mod/ollama"&gt;x-cmd ollama&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/drunkwcodes/bb7"&gt;bb7&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/marcusziade/Swollama"&gt;SwollamaCLI&lt;/a&gt; bundled with the Swollama Swift package. &lt;a href="https://github.com/marcusziade/Swollama?tab=readme-ov-file#cli-usage"&gt;Demo&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/sigoden/aichat"&gt;aichat&lt;/a&gt; All-in-one LLM CLI tool featuring Shell Assistant, Chat-REPL, RAG, AI tools &amp;amp; agents, with access to OpenAI, Claude, Gemini, Ollama, Groq, and more.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/rrg92/powershai"&gt;PowershAI&lt;/a&gt; PowerShell module that brings AI to terminal on Windows, including support for Ollama&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Abyss-c0re/deepshell"&gt;DeepShell&lt;/a&gt; Your self-hosted AI assistant. Interactive Shell, Files and Folders analysis.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/xyproto/orbiton"&gt;orbiton&lt;/a&gt; Configuration-free text editor and IDE with support for tab completion with Ollama.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/molbal/orca-cli"&gt;orca-cli&lt;/a&gt; Ollama Registry CLI Application - Browse, pull, and download models from Ollama Registry in your terminal.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jonathanhecl/gguf-to-ollama"&gt;GGUF-to-Ollama&lt;/a&gt; - Importing GGUF to Ollama made easy (multiplatform)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/rapidarchitect/ollama_strands"&gt;AWS-Strands-With-Ollama&lt;/a&gt; - AWS Strands Agents with Ollama Examples&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/attogram/ollama-multirun"&gt;ollama-multirun&lt;/a&gt; - A bash shell script to run a single prompt against any or all of your locally installed ollama models, saving the output and performance statistics as easily navigable web pages. (&lt;a href="https://attogram.github.io/ai_test_zone/"&gt;Demo&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/attogram/ollama-bash-toolshed"&gt;ollama-bash-toolshed&lt;/a&gt; - Bash scripts to chat with tool using models. Add new tools to your shed with ease. Runs on Ollama.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mags0ft/hle-eval-ollama"&gt;hle-eval-ollama&lt;/a&gt; - Runs benchmarks like "Humanity's Last Exam" (HLE) on your favorite local Ollama models and evaluates the quality of their responses&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/vinhnx/vtcode"&gt;VT Code&lt;/a&gt; - VT Code is a Rust-based terminal coding agent with semantic code intelligence via Tree-sitter. Ollama integration for running local/cloud models with configurable endpoints.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Apple Vision Pro&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/aws-samples/swift-chat"&gt;SwiftChat&lt;/a&gt; (Cross-platform AI chat app supporting Apple Vision Pro via "Designed for iPad")&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/AugustDev/enchanted"&gt;Enchanted&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Database&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/timescale/pgai"&gt;pgai&lt;/a&gt; - PostgreSQL as a vector database (Create and search embeddings from Ollama models using pgvector) 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/timescale/pgai/raw/main/docs/vectorizer-quick-start.md"&gt;Get started guide&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mindsdb/mindsdb/raw/staging/mindsdb/integrations/handlers/ollama_handler/README.md"&gt;MindsDB&lt;/a&gt; (Connects Ollama models with nearly 200 data platforms and apps)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/philippgille/chromem-go/raw/v0.5.0/embed_ollama.go"&gt;chromem-go&lt;/a&gt; with &lt;a href="https://github.com/philippgille/chromem-go/tree/v0.5.0/examples/rag-wikipedia-ollama"&gt;example&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/dbkangaroo/kangaroo"&gt;Kangaroo&lt;/a&gt; (AI-powered SQL client and admin tool for popular databases)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Package managers&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://archlinux.org/packages/extra/x86_64/ollama/"&gt;Pacman&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/gentoo/guru/tree/master/app-misc/ollama"&gt;Gentoo&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://formulae.brew.sh/formula/ollama"&gt;Homebrew&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://artifacthub.io/packages/helm/ollama-helm/ollama"&gt;Helm Chart&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://codeberg.org/tusharhero/ollama-guix"&gt;Guix channel&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://search.nixos.org/packages?show=ollama&amp;amp;from=0&amp;amp;size=50&amp;amp;sort=relevance&amp;amp;type=packages&amp;amp;query=ollama"&gt;Nix package&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://flox.dev/blog/ollama-part-one"&gt;Flox&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Libraries&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://python.langchain.com/docs/integrations/chat/ollama/"&gt;LangChain&lt;/a&gt; and &lt;a href="https://js.langchain.com/docs/integrations/chat/ollama/"&gt;LangChain.js&lt;/a&gt; with &lt;a href="https://js.langchain.com/docs/tutorials/local_rag/"&gt;example&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://firebase.google.com/docs/genkit/plugins/ollama"&gt;Firebase Genkit&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/crewAIInc/crewAI"&gt;crewAI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://remembersoftwares.github.io/yacana/"&gt;Yacana&lt;/a&gt; (User-friendly multi-agent framework for brainstorming and executing predetermined flows with built-in tool integration)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/strands-agents/sdk-python"&gt;Strands Agents&lt;/a&gt; (A model-driven approach to building AI agents in just a few lines of code)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/spring-projects/spring-ai"&gt;Spring AI&lt;/a&gt; with &lt;a href="https://docs.spring.io/spring-ai/reference/api/chat/ollama-chat.html"&gt;reference&lt;/a&gt; and &lt;a href="https://github.com/tzolov/ollama-tools"&gt;example&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tmc/langchaingo/"&gt;LangChainGo&lt;/a&gt; with &lt;a href="https://github.com/tmc/langchaingo/tree/main/examples/ollama-completion-example"&gt;example&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/langchain4j/langchain4j"&gt;LangChain4j&lt;/a&gt; with &lt;a href="https://github.com/langchain4j/langchain4j-examples/tree/main/ollama-examples/src/main/java"&gt;example&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Abraxas-365/langchain-rust"&gt;LangChainRust&lt;/a&gt; with &lt;a href="https://github.com/Abraxas-365/langchain-rust/raw/main/examples/llm_ollama.rs"&gt;example&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tryAGI/LangChain"&gt;LangChain for .NET&lt;/a&gt; with &lt;a href="https://github.com/tryAGI/LangChain/raw/main/examples/LangChain.Samples.OpenAI/Program.cs"&gt;example&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/theodo-group/LLPhant?tab=readme-ov-file#ollama"&gt;LLPhant&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.llamaindex.ai/en/stable/examples/llm/ollama/"&gt;LlamaIndex&lt;/a&gt; and &lt;a href="https://ts.llamaindex.ai/modules/llms/available_llms/ollama"&gt;LlamaIndexTS&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/BerriAI/litellm"&gt;LiteLLM&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/presbrey/ollamafarm"&gt;OllamaFarm for Go&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/awaescher/OllamaSharp"&gt;OllamaSharp for .NET&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/gbaptista/ollama-ai"&gt;Ollama for Ruby&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pepperoni21/ollama-rs"&gt;Ollama-rs for Rust&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jmont-dev/ollama-hpp"&gt;Ollama-hpp for C++&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ollama4j/ollama4j"&gt;Ollama4j for Java&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://modelfusion.dev/integration/model-provider/ollama"&gt;ModelFusion Typescript Library&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/kevinhermawan/OllamaKit"&gt;OllamaKit for Swift&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/breitburg/dart-ollama"&gt;Ollama for Dart&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/cloudstudio/ollama-laravel"&gt;Ollama for Laravel&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/davidmigloz/langchain_dart"&gt;LangChainDart&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/microsoft/semantic-kernel/tree/main/python/semantic_kernel/connectors/ai/ollama"&gt;Semantic Kernel - Python&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/deepset-ai/haystack-integrations/raw/main/integrations/ollama.md"&gt;Haystack&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/brainlid/langchain"&gt;Elixir LangChain&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/JBGruber/rollama"&gt;Ollama for R - rollama&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/hauselin/ollama-r"&gt;Ollama for R - ollama-r&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/lebrunel/ollama-ex"&gt;Ollama-ex for Elixir&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/b-tocs/abap_btocs_ollama"&gt;Ollama Connector for SAP ABAP&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://testcontainers.com/modules/ollama/"&gt;Testcontainers&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://portkey.ai/docs/welcome/integration-guides/ollama"&gt;Portkey&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/svilupp/PromptingTools.jl"&gt;PromptingTools.jl&lt;/a&gt; with an &lt;a href="https://svilupp.github.io/PromptingTools.jl/dev/examples/working_with_ollama"&gt;example&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Project-Llama/llamascript"&gt;LlamaScript&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/emirsahin1/llm-axe"&gt;llm-axe&lt;/a&gt; (Python Toolkit for Building LLM Powered Apps)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.gollm.co/examples/ollama-example"&gt;Gollm&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jonathanhecl/gollama"&gt;Gollama for Golang&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/xyproto/ollamaclient"&gt;Ollamaclient for Golang&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://gitlab.com/tozd/go/fun"&gt;High-level function abstraction in Go&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ArdaGnsrn/ollama-php"&gt;Ollama PHP&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/agents-flex/agents-flex"&gt;Agents-Flex for Java&lt;/a&gt; with &lt;a href="https://github.com/agents-flex/agents-flex/tree/main/agents-flex-llm/agents-flex-llm-ollama/src/test/java/com/agentsflex/llm/ollama"&gt;example&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/parakeet-nest/parakeet"&gt;Parakeet&lt;/a&gt; is a GoLang library, made to simplify the development of small generative AI applications with Ollama.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/andygill/haverscript"&gt;Haverscript&lt;/a&gt; with &lt;a href="https://github.com/andygill/haverscript/tree/main/examples"&gt;examples&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mattt/ollama-swift"&gt;Ollama for Swift&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/guitaripod/Swollama"&gt;Swollama for Swift&lt;/a&gt; with &lt;a href="https://guitaripod.github.io/Swollama/documentation/swollama"&gt;DocC&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/prasad89/golamify"&gt;GoLamify&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tusharad/ollama-haskell"&gt;Ollama for Haskell&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/nbonamy/multi-llm-ts"&gt;multi-llm-ts&lt;/a&gt; (A Typescript/JavaScript library allowing access to different LLM in a unified API)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/lofcz/llmtornado"&gt;LlmTornado&lt;/a&gt; (C# library providing a unified interface for major FOSS &amp;amp; Commercial inference APIs)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/dravenk/ollama-zig"&gt;Ollama for Zig&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/lunary-ai/abso"&gt;Abso&lt;/a&gt; (OpenAI-compatible TypeScript SDK for any LLM provider)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/goodreasonai/nichey"&gt;Nichey&lt;/a&gt; is a Python package for generating custom wikis for your research topic&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/kassane/ollama-d"&gt;Ollama for D&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/HardCodeDev777/OllamaPlusPlus"&gt;OllamaPlusPlus&lt;/a&gt; (Very simple C++ library for Ollama)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mozilla-ai/any-llm"&gt;any-llm&lt;/a&gt; (A single interface to use different llm providers by &lt;a href="https://www.mozilla.ai/"&gt;mozilla.ai&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mozilla-ai/any-agent"&gt;any-agent&lt;/a&gt; (A single interface to use and evaluate different agent frameworks by &lt;a href="https://www.mozilla.ai/"&gt;mozilla.ai&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/cognizant-ai-lab/neuro-san-studio"&gt;Neuro SAN&lt;/a&gt; (Data-driven multi-agent orchestration framework) with &lt;a href="https://github.com/cognizant-ai-lab/neuro-san-studio/raw/main/docs/user_guide.md#ollama"&gt;example&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ai-bot-pro/achatbot-go"&gt;achatbot-go&lt;/a&gt; a multimodal(text/audio/image) chatbot.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/attogram/ollama-bash-lib"&gt;Ollama Bash Lib&lt;/a&gt; - A Bash Library for Ollama. Run LLM prompts straight from your shell, and more&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Mobile&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/aws-samples/swift-chat"&gt;SwiftChat&lt;/a&gt; (Lightning-fast Cross-platform AI chat app with native UI for Android, iOS, and iPad)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/AugustDev/enchanted"&gt;Enchanted&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Mobile-Artificial-Intelligence/maid"&gt;Maid&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/JHubi1/ollama-app"&gt;Ollama App&lt;/a&gt; (Modern and easy-to-use multi-platform client for Ollama)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/1runeberg/confichat"&gt;ConfiChat&lt;/a&gt; (Lightweight, standalone, multi-platform, and privacy-focused LLM chat interface with optional encryption)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/sunshine0523/OllamaServer"&gt;Ollama Android Chat&lt;/a&gt; (No need for Termux, start the Ollama service with one click on an Android device)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ibrahimcetin/reins"&gt;Reins&lt;/a&gt; (Easily tweak parameters, customize system prompts per chat, and enhance your AI experiments with reasoning model support.)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Extensions &amp;amp; Plugins&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/MassimilianoPasquini97/raycast_ollama"&gt;Raycast extension&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mxyng/discollama"&gt;Discollama&lt;/a&gt; (Discord bot inside the Ollama discord channel)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/continuedev/continue"&gt;Continue&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/thewh1teagle/vibe"&gt;Vibe&lt;/a&gt; (Transcribe and analyze meetings with Ollama)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/hinterdupfinger/obsidian-ollama"&gt;Obsidian Ollama plugin&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/omagdy7/ollama-logseq"&gt;Logseq Ollama plugin&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/andersrex/notesollama"&gt;NotesOllama&lt;/a&gt; (Apple Notes Ollama plugin)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/samalba/dagger-chatbot"&gt;Dagger Chatbot&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mekb-turtle/discord-ai-bot"&gt;Discord AI Bot&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ruecat/ollama-telegram"&gt;Ollama Telegram Bot&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ej52/hass-ollama-conversation"&gt;Hass Ollama Conversation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/abrenneke/rivet-plugin-ollama"&gt;Rivet plugin&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/longy2k/obsidian-bmo-chatbot"&gt;Obsidian BMO Chatbot plugin&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/herval/cliobot"&gt;Cliobot&lt;/a&gt; (Telegram bot with Ollama support)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/logancyang/obsidian-copilot"&gt;Copilot for Obsidian plugin&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pfrankov/obsidian-local-gpt"&gt;Obsidian Local GPT plugin&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.openinterpreter.com/language-model-setup/local-models/ollama"&gt;Open Interpreter&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ex3ndr/llama-coder"&gt;Llama Coder&lt;/a&gt; (Copilot alternative using Ollama)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/bernardo-bruning/ollama-copilot"&gt;Ollama Copilot&lt;/a&gt; (Proxy that allows you to use Ollama as a copilot like GitHub Copilot)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/rjmacarthy/twinny"&gt;twinny&lt;/a&gt; (Copilot and Copilot chat alternative using Ollama)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/RussellCanfield/wingman-ai"&gt;Wingman-AI&lt;/a&gt; (Copilot code and chat alternative using Ollama and Hugging Face)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/n4ze3m/page-assist"&gt;Page Assist&lt;/a&gt; (Chrome Extension)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/imoize/plasmoid-ollamacontrol"&gt;Plasmoid Ollama Control&lt;/a&gt; (KDE Plasma extension that allows you to quickly manage/control Ollama model)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tusharhero/aitelegrambot"&gt;AI Telegram Bot&lt;/a&gt; (Telegram bot using Ollama in backend)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/yaroslavyaroslav/OpenAI-sublime-text"&gt;AI ST Completion&lt;/a&gt; (Sublime Text 4 AI assistant plugin with Ollama support)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/kevinthedang/discord-ollama"&gt;Discord-Ollama Chat Bot&lt;/a&gt; (Generalized TypeScript Discord Bot w/ Tuning Documentation)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/josStorer/chatGPTBox"&gt;ChatGPTBox: All in one browser extension&lt;/a&gt; with &lt;a href="https://github.com/josStorer/chatGPTBox/issues/616#issuecomment-1975186467"&gt;Integrating Tutorial&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/rapmd73/Companion"&gt;Discord AI chat/moderation bot&lt;/a&gt; Chat/moderation bot written in python. Uses Ollama to create personalities.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/nischalj10/headless-ollama"&gt;Headless Ollama&lt;/a&gt; (Scripts to automatically install ollama client &amp;amp; models on any OS for apps that depend on ollama server)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/xuyangbocn/terraform-aws-self-host-llm"&gt;Terraform AWS Ollama &amp;amp; Open WebUI&lt;/a&gt; (A Terraform module to deploy on AWS a ready-to-use Ollama service, together with its front-end Open WebUI service.)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jakubburkiewicz/node-red-contrib-ollama"&gt;node-red-contrib-ollama&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ivostoykov/localAI"&gt;Local AI Helper&lt;/a&gt; (Chrome and Firefox extensions that enable interactions with the active tab and customisable API endpoints. Includes secure storage for user prompts.)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/SilasMarvin/lsp-ai"&gt;LSP-AI&lt;/a&gt; (Open-source language server for AI-powered functionality)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Palm1r/QodeAssist"&gt;QodeAssist&lt;/a&gt; (AI-powered coding assistant plugin for Qt Creator)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ECuiDev/obsidian-quiz-generator"&gt;Obsidian Quiz Generator plugin&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/philffm/ai-summary-helper"&gt;AI Summary Helper plugin&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/suncloudsmoon/TextCraft"&gt;TextCraft&lt;/a&gt; (Copilot in Word alternative using Ollama)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/zeitlings/alfred-ollama"&gt;Alfred Ollama&lt;/a&gt; (Alfred Workflow)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/adarshM84/TextLLaMA"&gt;TextLLaMA&lt;/a&gt; A Chrome Extension that helps you write emails, correct grammar, and translate into any language&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/zyphixor/simple-discord-ai"&gt;Simple-Discord-AI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/innightwolfsleep/llm_telegram_bot"&gt;LLM Telegram Bot&lt;/a&gt; (telegram bot, primary for RP. Oobabooga-like buttons, &lt;a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui"&gt;A1111&lt;/a&gt; API integration e.t.c)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/sammcj/mcp-llm"&gt;mcp-llm&lt;/a&gt; (MCP Server to allow LLMs to call other LLMs)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/HardCodeDev777/SimpleOllamaUnity"&gt;SimpleOllamaUnity&lt;/a&gt; (Unity Engine extension for communicating with Ollama in a few lines of code. Also works at runtime)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/HardCodeDev777/UnityCodeLama"&gt;UnityCodeLama&lt;/a&gt; (Unity Editor tool to analyze scripts via Ollama)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/NativeMindBrowser/NativeMindExtension"&gt;NativeMind&lt;/a&gt; (Private, on-device AI Assistant, no cloud dependencies)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://gmai.premex.se/"&gt;GMAI - Gradle Managed AI&lt;/a&gt; (Gradle plugin for automated Ollama lifecycle management during build phases)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/nomyo-ai/nomyo-router"&gt;NOMYO Router&lt;/a&gt; (A transparent Ollama proxy with model deployment aware routing which auto-manages multiple Ollama instances in a given network)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Supported backends&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ggml-org/llama.cpp"&gt;llama.cpp&lt;/a&gt; project founded by Georgi Gerganov.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Observability&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.comet.com/docs/opik/cookbook/ollama"&gt;Opik&lt;/a&gt; is an open-source platform to debug, evaluate, and monitor your LLM applications, RAG systems, and agentic workflows with comprehensive tracing, automated evaluations, and production-ready dashboards. Opik supports native integration to Ollama.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://lunary.ai/docs/integrations/ollama"&gt;Lunary&lt;/a&gt; is the leading open-source LLM observability platform. It provides a variety of enterprise-grade features such as real-time analytics, prompt templates management, PII masking, and comprehensive agent tracing.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/openlit/openlit"&gt;OpenLIT&lt;/a&gt; is an OpenTelemetry-native tool for monitoring Ollama Applications &amp;amp; GPUs using traces and metrics.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.honeyhive.ai/integrations/ollama"&gt;HoneyHive&lt;/a&gt; is an AI observability and evaluation platform for AI agents. Use HoneyHive to evaluate agent performance, interrogate failures, and monitor quality in production.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://langfuse.com/docs/integrations/ollama"&gt;Langfuse&lt;/a&gt; is an open source LLM observability platform that enables teams to collaboratively monitor, evaluate and debug AI applications.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://mlflow.org/docs/latest/llms/tracing/index.html#automatic-tracing"&gt;MLflow Tracing&lt;/a&gt; is an open source LLM observability tool with a convenient API to log and visualize traces, making it easy to debug and evaluate GenAI applications.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Security&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ParisNeo/ollama_proxy_server"&gt;Ollama Fortress&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>charmbracelet/crush</title>
      <link>https://github.com/charmbracelet/crush</link>
      <description>&lt;p&gt;Glamourous agentic coding for all üíò&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Crush&lt;/h1&gt; 
&lt;p align="center"&gt; &lt;a href="https://stuff.charm.sh/crush/charm-crush.png"&gt;&lt;img width="450" alt="Charm Crush Logo" src="https://github.com/user-attachments/assets/cf8ca3ce-8b02-43f0-9d0f-5a331488da4b" /&gt;&lt;/a&gt;&lt;br /&gt; &lt;a href="https://github.com/charmbracelet/crush/releases"&gt;&lt;img src="https://img.shields.io/github/release/charmbracelet/crush" alt="Latest Release" /&gt;&lt;/a&gt; &lt;a href="https://github.com/charmbracelet/crush/actions"&gt;&lt;img src="https://github.com/charmbracelet/crush/actions/workflows/build.yml/badge.svg?sanitize=true" alt="Build Status" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt;Your new coding bestie, now available in your favourite terminal.&lt;br /&gt;Your tools, your code, and your workflows, wired into your LLM of choice.&lt;/p&gt; 
&lt;p align="center"&gt;‰Ω†ÁöÑÊñ∞ÁºñÁ®ã‰ºô‰º¥ÔºåÁé∞Âú®Â∞±Âú®‰Ω†ÊúÄÁà±ÁöÑÁªàÁ´Ø‰∏≠„ÄÇ&lt;br /&gt;‰Ω†ÁöÑÂ∑•ÂÖ∑„ÄÅ‰ª£Á†ÅÂíåÂ∑•‰ΩúÊµÅÔºåÈÉΩ‰∏éÊÇ®ÈÄâÊã©ÁöÑ LLM Ê®°ÂûãÁ¥ßÂØÜÁõ∏Ëøû„ÄÇ&lt;/p&gt; 
&lt;p align="center"&gt;&lt;img width="800" alt="Crush Demo" src="https://github.com/user-attachments/assets/58280caf-851b-470a-b6f7-d5c4ea8a1968" /&gt;&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Multi-Model:&lt;/strong&gt; choose from a wide range of LLMs or add your own via OpenAI- or Anthropic-compatible APIs&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Flexible:&lt;/strong&gt; switch LLMs mid-session while preserving context&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Session-Based:&lt;/strong&gt; maintain multiple work sessions and contexts per project&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;LSP-Enhanced:&lt;/strong&gt; Crush uses LSPs for additional context, just like you do&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Extensible:&lt;/strong&gt; add capabilities via MCPs (&lt;code&gt;http&lt;/code&gt;, &lt;code&gt;stdio&lt;/code&gt;, and &lt;code&gt;sse&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Works Everywhere:&lt;/strong&gt; first-class support in every terminal on macOS, Linux, Windows (PowerShell and WSL), Android, FreeBSD, OpenBSD, and NetBSD&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Industrial Grade:&lt;/strong&gt; built on the Charm ecosystem, powering 25k+ applications, from leading open source projects to business-critical infrastructure&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;Use a package manager:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Homebrew
brew install charmbracelet/tap/crush

# NPM
npm install -g @charmland/crush

# Arch Linux (btw)
yay -S crush-bin

# Nix
nix run github:numtide/nix-ai-tools#crush

# FreeBSD
pkg install crush
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Windows users:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Winget
winget install charmbracelet.crush

# Scoop
scoop bucket add charm https://github.com/charmbracelet/scoop-bucket.git
scoop install crush
&lt;/code&gt;&lt;/pre&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;Nix (NUR)&lt;/strong&gt;&lt;/summary&gt; 
 &lt;p&gt;Crush is available via the official Charm &lt;a href="https://github.com/nix-community/NUR"&gt;NUR&lt;/a&gt; in &lt;code&gt;nur.repos.charmbracelet.crush&lt;/code&gt;, which is the most up-to-date way to get Crush in Nix.&lt;/p&gt; 
 &lt;p&gt;You can also try out Crush via the NUR with &lt;code&gt;nix-shell&lt;/code&gt;:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# Add the NUR channel.
nix-channel --add https://github.com/nix-community/NUR/archive/main.tar.gz nur
nix-channel --update

# Get Crush in a Nix shell.
nix-shell -p '(import &amp;lt;nur&amp;gt; { pkgs = import &amp;lt;nixpkgs&amp;gt; {}; }).repos.charmbracelet.crush'
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h3&gt;NixOS &amp;amp; Home Manager Module Usage via NUR&lt;/h3&gt; 
 &lt;p&gt;Crush provides NixOS and Home Manager modules via NUR. You can use these modules directly in your flake by importing them from NUR. Since it auto detects whether its a home manager or nixos context you can use the import the exact same way :)&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-nix"&gt;{
  inputs = {
    nixpkgs.url = "github:NixOS/nixpkgs/nixos-unstable";
    nur.url = "github:nix-community/NUR";
  };

  outputs = { self, nixpkgs, nur, ... }: {
    nixosConfigurations.your-hostname = nixpkgs.lib.nixosSystem {
      system = "x86_64-linux";
      modules = [
        nur.modules.nixos.default
        nur.repos.charmbracelet.modules.crush
        {
          programs.crush = {
            enable = true;
            settings = {
              providers = {
                openai = {
                  id = "openai";
                  name = "OpenAI";
                  base_url = "https://api.openai.com/v1";
                  type = "openai";
                  api_key = "sk-fake123456789abcdef...";
                  models = [
                    {
                      id = "gpt-4";
                      name = "GPT-4";
                    }
                  ];
                };
              };
              lsp = {
                go = { command = "gopls"; enabled = true; };
                nix = { command = "nil"; enabled = true; };
              };
              options = {
                context_paths = [ "/etc/nixos/configuration.nix" ];
                tui = { compact_mode = true; };
                debug = false;
              };
            };
          };
        }
      ];
    };
  };
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;Debian/Ubuntu&lt;/strong&gt;&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;sudo mkdir -p /etc/apt/keyrings
curl -fsSL https://repo.charm.sh/apt/gpg.key | sudo gpg --dearmor -o /etc/apt/keyrings/charm.gpg
echo "deb [signed-by=/etc/apt/keyrings/charm.gpg] https://repo.charm.sh/apt/ * *" | sudo tee /etc/apt/sources.list.d/charm.list
sudo apt update &amp;amp;&amp;amp; sudo apt install crush
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;Fedora/RHEL&lt;/strong&gt;&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;echo '[charm]
name=Charm
baseurl=https://repo.charm.sh/yum/
enabled=1
gpgcheck=1
gpgkey=https://repo.charm.sh/yum/gpg.key' | sudo tee /etc/yum.repos.d/charm.repo
sudo yum install crush
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;p&gt;Or, download it:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/charmbracelet/crush/releases"&gt;Packages&lt;/a&gt; are available in Debian and RPM formats&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/charmbracelet/crush/releases"&gt;Binaries&lt;/a&gt; are available for Linux, macOS, Windows, FreeBSD, OpenBSD, and NetBSD&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Or just install it with Go:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;go install github.com/charmbracelet/crush@latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!WARNING] Productivity may increase when using Crush and you may find yourself nerd sniped when first using the application. If the symptoms persist, join the &lt;a href="https://charm.land/discord"&gt;Discord&lt;/a&gt; and nerd snipe the rest of us.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;p&gt;The quickest way to get started is to grab an API key for your preferred provider such as Anthropic, OpenAI, Groq, or OpenRouter and just start Crush. You'll be prompted to enter your API key.&lt;/p&gt; 
&lt;p&gt;That said, you can also set environment variables for preferred providers.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Environment Variable&lt;/th&gt; 
   &lt;th&gt;Provider&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;ANTHROPIC_API_KEY&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Anthropic&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OPENAI_API_KEY&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;OpenAI&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OPENROUTER_API_KEY&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;OpenRouter&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;GEMINI_API_KEY&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Google Gemini&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;CEREBRAS_API_KEY&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Cerebras&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;HF_TOKEN&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Huggingface Inference&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;VERTEXAI_PROJECT&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Google Cloud VertexAI (Gemini)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;VERTEXAI_LOCATION&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Google Cloud VertexAI (Gemini)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;GROQ_API_KEY&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Groq&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;AWS_ACCESS_KEY_ID&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Amazon Bedrock (Claude)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;AWS_SECRET_ACCESS_KEY&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Amazon Bedrock (Claude)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;AWS_REGION&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Amazon Bedrock (Claude)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;AWS_PROFILE&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Amazon Bedrock (Custom Profile)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;AWS_BEARER_TOKEN_BEDROCK&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Amazon Bedrock&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;AZURE_OPENAI_API_ENDPOINT&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Azure OpenAI models&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;AZURE_OPENAI_API_KEY&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Azure OpenAI models (optional when using Entra ID)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;AZURE_OPENAI_API_VERSION&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Azure OpenAI models&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;By the Way&lt;/h3&gt; 
&lt;p&gt;Is there a provider you‚Äôd like to see in Crush? Is there an existing model that needs an update?&lt;/p&gt; 
&lt;p&gt;Crush‚Äôs default model listing is managed in &lt;a href="https://github.com/charmbracelet/catwalk"&gt;Catwalk&lt;/a&gt;, a community-supported, open source repository of Crush-compatible models, and you‚Äôre welcome to contribute.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/charmbracelet/catwalk"&gt;&lt;img width="174" height="174" alt="Catwalk Badge" src="https://github.com/user-attachments/assets/95b49515-fe82-4409-b10d-5beb0873787d" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Configuration&lt;/h2&gt; 
&lt;p&gt;Crush runs great with no configuration. That said, if you do need or want to customize Crush, configuration can be added either local to the project itself, or globally, with the following priority:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;code&gt;.crush.json&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;crush.json&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;$HOME/.config/crush/crush.json&lt;/code&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Configuration itself is stored as a JSON object:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "this-setting": { "this": "that" },
  "that-setting": ["ceci", "cela"]
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;As an additional note, Crush also stores ephemeral data, such as application state, in one additional location:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Unix
$HOME/.local/share/crush/crush.json

# Windows
%LOCALAPPDATA%\crush\crush.json
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] You can override the user and data config locations by setting:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;code&gt;CRUSH_GLOBAL_CONFIG&lt;/code&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;CRUSH_GLOBAL_DATA&lt;/code&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;LSPs&lt;/h3&gt; 
&lt;p&gt;Crush can use LSPs for additional context to help inform its decisions, just like you would. LSPs can be added manually like so:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "$schema": "https://charm.land/crush.json",
  "lsp": {
    "go": {
      "command": "gopls",
      "env": {
        "GOTOOLCHAIN": "go1.24.5"
      }
    },
    "typescript": {
      "command": "typescript-language-server",
      "args": ["--stdio"]
    },
    "nix": {
      "command": "nil"
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;MCPs&lt;/h3&gt; 
&lt;p&gt;Crush also supports Model Context Protocol (MCP) servers through three transport types: &lt;code&gt;stdio&lt;/code&gt; for command-line servers, &lt;code&gt;http&lt;/code&gt; for HTTP endpoints, and &lt;code&gt;sse&lt;/code&gt; for Server-Sent Events. Environment variable expansion is supported using &lt;code&gt;$(echo $VAR)&lt;/code&gt; syntax.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "$schema": "https://charm.land/crush.json",
  "mcp": {
    "filesystem": {
      "type": "stdio",
      "command": "node",
      "args": ["/path/to/mcp-server.js"],
      "timeout": 120,
      "disabled": false,
      "disabled_tools": ["some-tool-name"],
      "env": {
        "NODE_ENV": "production"
      }
    },
    "github": {
      "type": "http",
      "url": "https://api.githubcopilot.com/mcp/",
      "timeout": 120,
      "disabled": false,
      "disabled_tools": ["create_issue", "create_pull_request"],
      "headers": {
        "Authorization": "Bearer $GH_PAT"
      }
    },
    "streaming-service": {
      "type": "sse",
      "url": "https://example.com/mcp/sse",
      "timeout": 120,
      "disabled": false,
      "headers": {
        "API-Key": "$(echo $API_KEY)"
      }
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Ignoring Files&lt;/h3&gt; 
&lt;p&gt;Crush respects &lt;code&gt;.gitignore&lt;/code&gt; files by default, but you can also create a &lt;code&gt;.crushignore&lt;/code&gt; file to specify additional files and directories that Crush should ignore. This is useful for excluding files that you want in version control but don't want Crush to consider when providing context.&lt;/p&gt; 
&lt;p&gt;The &lt;code&gt;.crushignore&lt;/code&gt; file uses the same syntax as &lt;code&gt;.gitignore&lt;/code&gt; and can be placed in the root of your project or in subdirectories.&lt;/p&gt; 
&lt;h3&gt;Allowing Tools&lt;/h3&gt; 
&lt;p&gt;By default, Crush will ask you for permission before running tool calls. If you'd like, you can allow tools to be executed without prompting you for permissions. Use this with care.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "$schema": "https://charm.land/crush.json",
  "permissions": {
    "allowed_tools": [
      "view",
      "ls",
      "grep",
      "edit",
      "mcp_context7_get-library-doc"
    ]
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can also skip all permission prompts entirely by running Crush with the &lt;code&gt;--yolo&lt;/code&gt; flag. Be very, very careful with this feature.&lt;/p&gt; 
&lt;h3&gt;Disabling Built-In Tools&lt;/h3&gt; 
&lt;p&gt;If you'd like to prevent Crush from using certain built-in tools entirely, you can disable them via the &lt;code&gt;options.disabled_tools&lt;/code&gt; list. Disabled tools are completely hidden from the agent.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "$schema": "https://charm.land/crush.json",
  "options": {
    "disabled_tools": [
      "bash",
      "sourcegraph"
    ]
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To disable tools from MCP servers, see the &lt;a href="https://raw.githubusercontent.com/charmbracelet/crush/main/#mcps"&gt;MCP config section&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Agent Skills&lt;/h3&gt; 
&lt;p&gt;Crush supports the &lt;a href="https://agentskills.io"&gt;Agent Skills&lt;/a&gt; open standard for extending agent capabilities with reusable skill packages. Skills are folders containing a &lt;code&gt;SKILL.md&lt;/code&gt; file with instructions that Crush can discover and activate on demand.&lt;/p&gt; 
&lt;p&gt;Skills are discovered from:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;~/.config/crush/skills/&lt;/code&gt; on Unix (default, can be overridden with &lt;code&gt;CRUSH_SKILLS_DIR&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;%LOCALAPPDATA%\crush\skills\&lt;/code&gt; on Windows (default, can be overridden with &lt;code&gt;CRUSH_SKILLS_DIR&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;Additional paths configured via &lt;code&gt;options.skills_paths&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-jsonc"&gt;{
  "$schema": "https://charm.land/crush.json",
  "options": {
    "skills_paths": [
      "~/.config/crush/skills", // Windows: "%LOCALAPPDATA%\\crush\\skills",
      "./project-skills"
    ]
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can get started with example skills from &lt;a href="https://github.com/anthropics/skills"&gt;anthropics/skills&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Unix
mkdir -p ~/.config/crush/skills
cd ~/.config/crush/skills
git clone https://github.com/anthropics/skills.git _temp
mv _temp/skills/* . &amp;amp;&amp;amp; rm -rf _temp
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-powershell"&gt;# Windows (PowerShell)
mkdir -Force "$env:LOCALAPPDATA\crush\skills"
cd "$env:LOCALAPPDATA\crush\skills"
git clone https://github.com/anthropics/skills.git _temp
mv _temp/skills/* . ; rm -r -force _temp
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Initialization&lt;/h3&gt; 
&lt;p&gt;When you initialize a project, Crush analyzes your codebase and creates a context file that helps it work more effectively in future sessions. By default, this file is named &lt;code&gt;AGENTS.md&lt;/code&gt;, but you can customize the name and location with the &lt;code&gt;initialize_as&lt;/code&gt; option:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "$schema": "https://charm.land/crush.json",
  "options": {
    "initialize_as": "AGENTS.md"
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This is useful if you prefer a different naming convention or want to place the file in a specific directory (e.g., &lt;code&gt;CRUSH.md&lt;/code&gt; or &lt;code&gt;docs/LLMs.md&lt;/code&gt;). Crush will fill the file with project-specific context like build commands, code patterns, and conventions it discovered during initialization.&lt;/p&gt; 
&lt;h3&gt;Attribution Settings&lt;/h3&gt; 
&lt;p&gt;By default, Crush adds attribution information to Git commits and pull requests it creates. You can customize this behavior with the &lt;code&gt;attribution&lt;/code&gt; option:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "$schema": "https://charm.land/crush.json",
  "options": {
    "attribution": {
      "trailer_style": "co-authored-by",
      "generated_with": true
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;trailer_style&lt;/code&gt;: Controls the attribution trailer added to commit messages (default: &lt;code&gt;assisted-by&lt;/code&gt;) 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;assisted-by&lt;/code&gt;: Adds &lt;code&gt;Assisted-by: [Model Name] via Crush &amp;lt;crush@charm.land&amp;gt;&lt;/code&gt; (includes the model name)&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;co-authored-by&lt;/code&gt;: Adds &lt;code&gt;Co-Authored-By: Crush &amp;lt;crush@charm.land&amp;gt;&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;none&lt;/code&gt;: No attribution trailer&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;generated_with&lt;/code&gt;: When true (default), adds &lt;code&gt;üíò Generated with Crush&lt;/code&gt; line to commit messages and PR descriptions&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Custom Providers&lt;/h3&gt; 
&lt;p&gt;Crush supports custom provider configurations for both OpenAI-compatible and Anthropic-compatible APIs.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] Note that we support two "types" for OpenAI. Make sure to choose the right one to ensure the best experience!&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;code&gt;openai&lt;/code&gt; should be used when proxying or routing requests through OpenAI.&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;openai-compat&lt;/code&gt; should be used when using non-OpenAI providers that have OpenAI-compatible APIs.&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;OpenAI-Compatible APIs&lt;/h4&gt; 
&lt;p&gt;Here‚Äôs an example configuration for Deepseek, which uses an OpenAI-compatible API. Don't forget to set &lt;code&gt;DEEPSEEK_API_KEY&lt;/code&gt; in your environment.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "$schema": "https://charm.land/crush.json",
  "providers": {
    "deepseek": {
      "type": "openai-compat",
      "base_url": "https://api.deepseek.com/v1",
      "api_key": "$DEEPSEEK_API_KEY",
      "models": [
        {
          "id": "deepseek-chat",
          "name": "Deepseek V3",
          "cost_per_1m_in": 0.27,
          "cost_per_1m_out": 1.1,
          "cost_per_1m_in_cached": 0.07,
          "cost_per_1m_out_cached": 1.1,
          "context_window": 64000,
          "default_max_tokens": 5000
        }
      ]
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Anthropic-Compatible APIs&lt;/h4&gt; 
&lt;p&gt;Custom Anthropic-compatible providers follow this format:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "$schema": "https://charm.land/crush.json",
  "providers": {
    "custom-anthropic": {
      "type": "anthropic",
      "base_url": "https://api.anthropic.com/v1",
      "api_key": "$ANTHROPIC_API_KEY",
      "extra_headers": {
        "anthropic-version": "2023-06-01"
      },
      "models": [
        {
          "id": "claude-sonnet-4-20250514",
          "name": "Claude Sonnet 4",
          "cost_per_1m_in": 3,
          "cost_per_1m_out": 15,
          "cost_per_1m_in_cached": 3.75,
          "cost_per_1m_out_cached": 0.3,
          "context_window": 200000,
          "default_max_tokens": 50000,
          "can_reason": true,
          "supports_attachments": true
        }
      ]
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Amazon Bedrock&lt;/h3&gt; 
&lt;p&gt;Crush currently supports running Anthropic models through Bedrock, with caching disabled.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;A Bedrock provider will appear once you have AWS configured, i.e. &lt;code&gt;aws configure&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Crush also expects the &lt;code&gt;AWS_REGION&lt;/code&gt; or &lt;code&gt;AWS_DEFAULT_REGION&lt;/code&gt; to be set&lt;/li&gt; 
 &lt;li&gt;To use a specific AWS profile set &lt;code&gt;AWS_PROFILE&lt;/code&gt; in your environment, i.e. &lt;code&gt;AWS_PROFILE=myprofile crush&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Alternatively to &lt;code&gt;aws configure&lt;/code&gt;, you can also just set &lt;code&gt;AWS_BEARER_TOKEN_BEDROCK&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Vertex AI Platform&lt;/h3&gt; 
&lt;p&gt;Vertex AI will appear in the list of available providers when &lt;code&gt;VERTEXAI_PROJECT&lt;/code&gt; and &lt;code&gt;VERTEXAI_LOCATION&lt;/code&gt; are set. You will also need to be authenticated:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;gcloud auth application-default login
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To add specific models to the configuration, configure as such:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "$schema": "https://charm.land/crush.json",
  "providers": {
    "vertexai": {
      "models": [
        {
          "id": "claude-sonnet-4@20250514",
          "name": "VertexAI Sonnet 4",
          "cost_per_1m_in": 3,
          "cost_per_1m_out": 15,
          "cost_per_1m_in_cached": 3.75,
          "cost_per_1m_out_cached": 0.3,
          "context_window": 200000,
          "default_max_tokens": 50000,
          "can_reason": true,
          "supports_attachments": true
        }
      ]
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Local Models&lt;/h3&gt; 
&lt;p&gt;Local models can also be configured via OpenAI-compatible API. Here are two common examples:&lt;/p&gt; 
&lt;h4&gt;Ollama&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "providers": {
    "ollama": {
      "name": "Ollama",
      "base_url": "http://localhost:11434/v1/",
      "type": "openai-compat",
      "models": [
        {
          "name": "Qwen 3 30B",
          "id": "qwen3:30b",
          "context_window": 256000,
          "default_max_tokens": 20000
        }
      ]
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;LM Studio&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "providers": {
    "lmstudio": {
      "name": "LM Studio",
      "base_url": "http://localhost:1234/v1/",
      "type": "openai-compat",
      "models": [
        {
          "name": "Qwen 3 30B",
          "id": "qwen/qwen3-30b-a3b-2507",
          "context_window": 256000,
          "default_max_tokens": 20000
        }
      ]
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Logging&lt;/h2&gt; 
&lt;p&gt;Sometimes you need to look at logs. Luckily, Crush logs all sorts of stuff. Logs are stored in &lt;code&gt;./.crush/logs/crush.log&lt;/code&gt; relative to the project.&lt;/p&gt; 
&lt;p&gt;The CLI also contains some helper commands to make perusing recent logs easier:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Print the last 1000 lines
crush logs

# Print the last 500 lines
crush logs --tail 500

# Follow logs in real time
crush logs --follow
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Want more logging? Run &lt;code&gt;crush&lt;/code&gt; with the &lt;code&gt;--debug&lt;/code&gt; flag, or enable it in the config:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "$schema": "https://charm.land/crush.json",
  "options": {
    "debug": true,
    "debug_lsp": true
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Provider Auto-Updates&lt;/h2&gt; 
&lt;p&gt;By default, Crush automatically checks for the latest and greatest list of providers and models from &lt;a href="https://github.com/charmbracelet/catwalk"&gt;Catwalk&lt;/a&gt;, the open source Crush provider database. This means that when new providers and models are available, or when model metadata changes, Crush automatically updates your local configuration.&lt;/p&gt; 
&lt;h3&gt;Disabling automatic provider updates&lt;/h3&gt; 
&lt;p&gt;For those with restricted internet access, or those who prefer to work in air-gapped environments, this might not be want you want, and this feature can be disabled.&lt;/p&gt; 
&lt;p&gt;To disable automatic provider updates, set &lt;code&gt;disable_provider_auto_update&lt;/code&gt; into your &lt;code&gt;crush.json&lt;/code&gt; config:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "$schema": "https://charm.land/crush.json",
  "options": {
    "disable_provider_auto_update": true
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or set the &lt;code&gt;CRUSH_DISABLE_PROVIDER_AUTO_UPDATE&lt;/code&gt; environment variable:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;export CRUSH_DISABLE_PROVIDER_AUTO_UPDATE=1
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Manually updating providers&lt;/h3&gt; 
&lt;p&gt;Manually updating providers is possible with the &lt;code&gt;crush update-providers&lt;/code&gt; command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Update providers remotely from Catwalk.
crush update-providers

# Update providers from a custom Catwalk base URL.
crush update-providers https://example.com/

# Update providers from a local file.
crush update-providers /path/to/local-providers.json

# Reset providers to the embedded version, embedded at crush at build time.
crush update-providers embedded

# For more info:
crush update-providers --help
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Metrics&lt;/h2&gt; 
&lt;p&gt;Crush records pseudonymous usage metrics (tied to a device-specific hash), which maintainers rely on to inform development and support priorities. The metrics include solely usage metadata; prompts and responses are NEVER collected.&lt;/p&gt; 
&lt;p&gt;Details on exactly what‚Äôs collected are in the source code (&lt;a href="https://github.com/charmbracelet/crush/tree/main/internal/event"&gt;here&lt;/a&gt; and &lt;a href="https://github.com/charmbracelet/crush/raw/main/internal/llm/agent/event.go"&gt;here&lt;/a&gt;).&lt;/p&gt; 
&lt;p&gt;You can opt out of metrics collection at any time by setting the environment variable by setting the following in your environment:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;export CRUSH_DISABLE_METRICS=1
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or by setting the following in your config:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "options": {
    "disable_metrics": true
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Crush also respects the &lt;a href="https://consoledonottrack.com"&gt;&lt;code&gt;DO_NOT_TRACK&lt;/code&gt;&lt;/a&gt; convention which can be enabled via &lt;code&gt;export DO_NOT_TRACK=1&lt;/code&gt;.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;See the &lt;a href="https://github.com/charmbracelet/crush?tab=contributing-ov-file#contributing"&gt;contributing guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Whatcha think?&lt;/h2&gt; 
&lt;p&gt;We‚Äôd love to hear your thoughts on this project. Need help? We gotchu. You can find us on:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://twitter.com/charmcli"&gt;Twitter&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://charm.land/slack"&gt;Slack&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://charm.land/discord"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://mastodon.social/@charmcli"&gt;The Fediverse&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://bsky.app/profile/charm.land"&gt;Bluesky&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://github.com/charmbracelet/crush/raw/main/LICENSE.md"&gt;FSL-1.1-MIT&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;Part of &lt;a href="https://charm.land"&gt;Charm&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://charm.land/"&gt;&lt;img alt="The Charm logo" width="400" src="https://stuff.charm.sh/charm-banner-next.jpg" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;!--prettier-ignore--&gt; 
&lt;p&gt;CharmÁÉ≠Áà±ÂºÄÊ∫ê ‚Ä¢ Charm loves open source&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>golangci/golangci-lint</title>
      <link>https://github.com/golangci/golangci-lint</link>
      <description>&lt;p&gt;Fast linters runner for Go&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;img alt="golangci-lint logo" src="https://raw.githubusercontent.com/golangci/golangci-lint/main/assets/go.png" height="150" /&gt; &lt;/p&gt;
&lt;h3 align="center"&gt;golangci-lint&lt;/h3&gt; 
&lt;p align="center"&gt;Fast linters runner for Go&lt;/p&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;code&gt;golangci-lint&lt;/code&gt; is a fast Go linters runner.&lt;/p&gt; 
&lt;p&gt;It runs linters in parallel, uses caching, supports YAML configuration, integrates with all major IDEs, and includes over a hundred linters.&lt;/p&gt; 
&lt;h2&gt;Install &lt;code&gt;golangci-lint&lt;/code&gt;&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://golangci-lint.run/docs/welcome/install/local"&gt;On my machine&lt;/a&gt;;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://golangci-lint.run/docs/welcome/install/ci"&gt;On CI/CD systems&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;Documentation is hosted at &lt;a href="https://golangci-lint.run"&gt;https://golangci-lint.run&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Social Networks&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://gophers.slack.com/archives/CS0TBRKPC"&gt;&lt;img src="https://img.shields.io/badge/Slack-4285F4?logo=slack&amp;amp;logoColor=white" alt="Join Slack" /&gt;&lt;/a&gt; &lt;a href="https://fosstodon.org/@golangcilint"&gt;&lt;img src="https://img.shields.io/badge/Mastodon-6364FF?logo=mastodon&amp;amp;logoColor=white" alt="Follow on Mastodon" /&gt;&lt;/a&gt; &lt;a href="https://bsky.app/profile/golangci-lint.run"&gt;&lt;img src="https://img.shields.io/badge/Bluesky-0a7aff?logo=bluesky&amp;amp;logoColor=white" alt="Follow on Bluesky" /&gt;&lt;/a&gt; &lt;a href="https://twitter.com/golangci"&gt;&lt;img src="https://img.shields.io/badge/Twitter-1DA1F2?logo=x&amp;amp;logoColor=white" alt="Follow on Twitter" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Support Us&lt;/h2&gt; 
&lt;p&gt;&lt;code&gt;golangci-lint&lt;/code&gt; is a free and open-source project built by volunteers.&lt;/p&gt; 
&lt;p&gt;If you value it, consider supporting us, we appreciate it! &lt;span&gt;‚ù§Ô∏è&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://donate.golangci.org"&gt;&lt;img src="https://img.shields.io/badge/Support-golangci_lint-blue?style=for-the-badge" alt="Golangci-lint" /&gt;&lt;/a&gt; &lt;a href="https://golangci-lint.run/docs/product/thanks/"&gt;&lt;img src="https://img.shields.io/badge/Support-Linter_Authors-blue?style=for-the-badge" alt="Linter Authors" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Badges&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://github.com/golangci/golangci-lint/workflows/CI/badge.svg?sanitize=true" alt="Build Status" /&gt; &lt;a href="https://raw.githubusercontent.com/golangci/golangci-lint/main/LICENSE"&gt;&lt;img src="https://img.shields.io/github/license/golangci/golangci-lint" alt="License" /&gt;&lt;/a&gt; &lt;a href="https://github.com/golangci/golangci-lint/releases/latest"&gt;&lt;img src="https://img.shields.io/github/release/golangci/golangci-lint.svg?sanitize=true" alt="Release" /&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/r/golangci/golangci-lint"&gt;&lt;img src="https://img.shields.io/docker/pulls/golangci/golangci-lint" alt="Docker" /&gt;&lt;/a&gt; &lt;a href="https://somsubhra.github.io/github-release-stats/?username=golangci&amp;amp;repository=golangci-lint"&gt;&lt;img src="https://img.shields.io/github/downloads/golangci/golangci-lint/total.svg?logo=github" alt="GitHub Releases Stats of golangci-lint" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Contributors&lt;/h2&gt; 
&lt;p&gt;This project exists thanks to all the people who contribute. &lt;a href="https://golangci-lint.run/docs/contributing/"&gt;How to contribute&lt;/a&gt;.&lt;/p&gt; 
&lt;a href="https://github.com/golangci/golangci-lint/graphs/contributors"&gt; &lt;img src="https://opencollective.com/golangci-lint/contributors.svg?width=890&amp;amp;button=false&amp;amp;skip=golangcidev,CLAassistant,renovate,fossabot,golangcibot,kortschak,golangci-releaser,dependabot%5Bbot%5D" /&gt; &lt;/a&gt; 
&lt;h2&gt;Sponsors&lt;/h2&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p float="left"&gt; &lt;a href="https://www.jetbrains.com/go/?utm_source=OSS&amp;amp;utm_medium=referral&amp;amp;utm_campaign=golangci" target="_blank"&gt; 
  &lt;picture&gt; 
   &lt;source media="(prefers-color-scheme: dark)" srcset="assets/goland-white.svg" /&gt; 
   &lt;source media="(prefers-color-scheme: light)" srcset="assets/goland.svg" /&gt; 
   &lt;img alt="The complete IDE crafted for professional Go developers." src="https://raw.githubusercontent.com/golangci/golangci-lint/main/assets/goland.svg?sanitize=true" width="150" /&gt; 
  &lt;/picture&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;h2&gt;Stargazers over time&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://starchart.cc/golangci/golangci-lint"&gt;&lt;img src="https://starchart.cc/golangci/golangci-lint.svg?variant=adaptive" alt="Stargazers over time" /&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>kserve/kserve</title>
      <link>https://github.com/kserve/kserve</link>
      <description>&lt;p&gt;Standardized Distributed Generative and Predictive AI Inference Platform for Scalable, Multi-Framework Deployment on Kubernetes&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;KServe&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://pkg.go.dev/github.com/kserve/kserve"&gt;&lt;img src="https://img.shields.io/badge/go.dev-reference-007d9c?logo=go&amp;amp;logoColor=white" alt="go.dev reference" /&gt;&lt;/a&gt; &lt;a href="https://github.com/kserve/kserve/actions/workflows/go.yml"&gt;&lt;img src="https://img.shields.io/endpoint?url=https://gist.githubusercontent.com/andyi2it/5174bd748ac63a6e4803afea902e9810/raw/coverage.json" alt="Coverage Status" /&gt;&lt;/a&gt; &lt;a href="https://goreportcard.com/report/github.com/kserve/kserve"&gt;&lt;img src="https://goreportcard.com/badge/github.com/kserve/kserve" alt="Go Report Card" /&gt;&lt;/a&gt; &lt;a href="https://bestpractices.coreinfrastructure.org/projects/6643"&gt;&lt;img src="https://bestpractices.coreinfrastructure.org/projects/6643/badge" alt="OpenSSF Best Practices" /&gt;&lt;/a&gt; &lt;a href="https://github.com/kserve/kserve/releases"&gt;&lt;img src="https://img.shields.io/github/release-pre/kserve/kserve.svg?sort=semver" alt="Releases" /&gt;&lt;/a&gt; &lt;a href="https://github.com/kserve/kserve/raw/master/LICENSE"&gt;&lt;img src="https://img.shields.io/github/license/kserve/kserve.svg?sanitize=true" alt="LICENSE" /&gt;&lt;/a&gt; &lt;a href="https://github.com/kserve/community/raw/main/README.md#questions-and-issues"&gt;&lt;img src="https://img.shields.io/badge/slack-join_chat-white.svg?logo=slack&amp;amp;style=social" alt="Slack Status" /&gt;&lt;/a&gt; &lt;a href="https://gurubase.io/g/kserve"&gt;&lt;img src="https://img.shields.io/badge/Gurubase-Ask%20KServe%20Guru-006BFF" alt="Gurubase" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;KServe is a standardized distributed generative and predictive AI inference platform for scalable, multi-framework deployment on Kubernetes.&lt;/p&gt; 
&lt;p&gt;KServe is being &lt;a href="https://kserve.github.io/website/docs/community/adopters"&gt;used by many organizations&lt;/a&gt; and is a &lt;a href="https://www.cncf.io/"&gt;Cloud Native Computing Foundation (CNCF)&lt;/a&gt; incubating project.&lt;/p&gt; 
&lt;p&gt;For more details, visit the &lt;a href="https://kserve.github.io/website/"&gt;KServe website&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/kserve/kserve/master/docs/diagrams/kserve_new.png" alt="KServe" /&gt;&lt;/p&gt; 
&lt;h3&gt;Why KServe?&lt;/h3&gt; 
&lt;p&gt;Single platform that unifies Generative and Predictive AI inference on Kubernetes. Simple enough for quick deployments, yet powerful enough to handle enterprise-scale AI workloads with advanced features.&lt;/p&gt; 
&lt;h3&gt;Features&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Generative AI&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;üß† &lt;strong&gt;LLM-Optimized&lt;/strong&gt;: OpenAI-compatible inference protocol for seamless integration with large language models&lt;/li&gt; 
 &lt;li&gt;üöÖ &lt;strong&gt;GPU Acceleration&lt;/strong&gt;: High-performance serving with GPU support and optimized memory management for large models&lt;/li&gt; 
 &lt;li&gt;üíæ &lt;strong&gt;Model Caching&lt;/strong&gt;: Intelligent model caching to reduce loading times and improve response latency for frequently used models&lt;/li&gt; 
 &lt;li&gt;üóÇÔ∏è &lt;strong&gt;KV Cache Offloading&lt;/strong&gt;: Advanced memory management with KV cache offloading to CPU/disk for handling longer sequences efficiently&lt;/li&gt; 
 &lt;li&gt;üìà &lt;strong&gt;Autoscaling&lt;/strong&gt;: Request-based autoscaling capabilities optimized for generative workload patterns&lt;/li&gt; 
 &lt;li&gt;üîß &lt;strong&gt;Hugging Face Ready&lt;/strong&gt;: Native support for Hugging Face models with streamlined deployment workflows&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Predictive AI&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;üßÆ &lt;strong&gt;Multi-Framework&lt;/strong&gt;: Support for TensorFlow, PyTorch, scikit-learn, XGBoost, ONNX, and more&lt;/li&gt; 
 &lt;li&gt;üîÄ &lt;strong&gt;Intelligent Routing&lt;/strong&gt;: Seamless request routing between predictor, transformer, and explainer components with automatic traffic management&lt;/li&gt; 
 &lt;li&gt;üîÑ &lt;strong&gt;Advanced Deployments&lt;/strong&gt;: Canary rollouts, inference pipelines, and ensembles with InferenceGraph&lt;/li&gt; 
 &lt;li&gt;‚ö° &lt;strong&gt;Autoscaling&lt;/strong&gt;: Request-based autoscaling with scale-to-zero for predictive workloads&lt;/li&gt; 
 &lt;li&gt;üîç &lt;strong&gt;Model Explainability&lt;/strong&gt;: Built-in support for model explanations and feature attribution to understand prediction reasoning&lt;/li&gt; 
 &lt;li&gt;üìä &lt;strong&gt;Advanced Monitoring&lt;/strong&gt;: Enables payload logging, outlier detection, adversarial detection, and drift detection&lt;/li&gt; 
 &lt;li&gt;üí∞ &lt;strong&gt;Cost Efficient&lt;/strong&gt;: Scale-to-zero on expensive resources when not in use, reducing infrastructure costs&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Learn More&lt;/h3&gt; 
&lt;p&gt;To learn more about KServe, how to use various supported features, and how to participate in the KServe community, please follow the &lt;a href="https://kserve.github.io/website"&gt;KServe website documentation&lt;/a&gt;. Additionally, we have compiled a list of &lt;a href="https://kserve.github.io/website/docs/community/presentations"&gt;presentations and demos&lt;/a&gt; to dive through various details.&lt;/p&gt; 
&lt;h3&gt;&lt;span&gt;üõ†&lt;/span&gt; Installation&lt;/h3&gt; 
&lt;h4&gt;Standalone Installation&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://kserve.github.io/website/docs/admin-guide/overview#raw-kubernetes-deployment"&gt;Standard Kubernetes Installation&lt;/a&gt;&lt;/strong&gt;: Compared to Serverless Installation, this is a more &lt;strong&gt;lightweight&lt;/strong&gt; installation. However, this option does not support canary deployment and request based autoscaling with scale-to-zero.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://kserve.github.io/website/docs/admin-guide/overview#serverless-deployment"&gt;Knative Installation&lt;/a&gt;&lt;/strong&gt;: KServe by default installs Knative for &lt;strong&gt;serverless deployment&lt;/strong&gt; for InferenceService.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://kserve.github.io/website/docs/admin-guide/overview#modelmesh-deployment"&gt;ModelMesh Installation&lt;/a&gt;&lt;/strong&gt;: You can optionally install ModelMesh to enable &lt;strong&gt;high-scale&lt;/strong&gt;, &lt;strong&gt;high-density&lt;/strong&gt; and &lt;strong&gt;frequently-changing model serving&lt;/strong&gt; use cases.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://kserve.github.io/website/docs/getting-started/quickstart-guide"&gt;Quick Installation&lt;/a&gt;&lt;/strong&gt;: Install KServe on your local machine.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Kubeflow Installation&lt;/h4&gt; 
&lt;p&gt;KServe is an important addon component of Kubeflow, please learn more from the &lt;a href="https://www.kubeflow.org/docs/external-add-ons/kserve/kserve"&gt;Kubeflow KServe documentation&lt;/a&gt;. Check out the following guides for running &lt;a href="https://awslabs.github.io/kubeflow-manifests/main/docs/component-guides/kserve"&gt;on AWS&lt;/a&gt; or &lt;a href="https://github.com/kserve/kserve/raw/master/docs/OPENSHIFT_GUIDE.md"&gt;on OpenShift Container Platform&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;&lt;span&gt;üõ´&lt;/span&gt; &lt;a href="https://kserve.github.io/website/docs/getting-started/genai-first-isvc"&gt;Create your first InferenceService&lt;/a&gt;&lt;/h3&gt; 
&lt;h3&gt;&lt;span&gt;üí°&lt;/span&gt; &lt;a href="https://raw.githubusercontent.com/kserve/kserve/master/ROADMAP.md"&gt;Roadmap&lt;/a&gt;&lt;/h3&gt; 
&lt;h3&gt;&lt;span&gt;üìò&lt;/span&gt; &lt;a href="https://kserve.github.io/website/docs/reference/crd-api"&gt;InferenceService API Reference&lt;/a&gt;&lt;/h3&gt; 
&lt;h3&gt;&lt;span&gt;üß∞&lt;/span&gt; &lt;a href="https://kserve.github.io/website/docs/developer-guide"&gt;Developer Guide&lt;/a&gt;&lt;/h3&gt; 
&lt;h3&gt;&lt;span&gt;‚úç&lt;/span&gt; &lt;a href="https://kserve.github.io/website/docs/developer-guide/contribution"&gt;Contributor Guide&lt;/a&gt;&lt;/h3&gt; 
&lt;h3&gt;&lt;span&gt;ü§ù&lt;/span&gt; &lt;a href="https://kserve.github.io/website/docs/community/adopters"&gt;Adopters&lt;/a&gt;&lt;/h3&gt; 
&lt;h3&gt;Star History&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://www.star-history.com/#kserve/kserve&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=kserve/kserve&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Tencent/WeKnora</title>
      <link>https://github.com/Tencent/WeKnora</link>
      <description>&lt;p&gt;LLM-powered framework for deep document understanding, semantic retrieval, and context-aware answers using RAG paradigm.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; 
 &lt;picture&gt; 
  &lt;img src="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/images/logo.png" alt="WeKnora Logo" height="120" /&gt; 
 &lt;/picture&gt; &lt;/p&gt; 
&lt;p align="center"&gt; 
 &lt;picture&gt; 
  &lt;a href="https://trendshift.io/repositories/15289" target="_blank"&gt; &lt;img src="https://trendshift.io/api/badge/repositories/15289" alt="Tencent%2FWeKnora | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt; &lt;/a&gt; 
 &lt;/picture&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://weknora.weixin.qq.com" target="_blank"&gt; &lt;img alt="ÂÆòÊñπÁΩëÁ´ô" src="https://img.shields.io/badge/ÂÆòÊñπÁΩëÁ´ô-WeKnora-4e6b99" /&gt; &lt;/a&gt; &lt;a href="https://chatbot.weixin.qq.com" target="_blank"&gt; &lt;img alt="ÂæÆ‰ø°ÂØπËØùÂºÄÊîæÂπ≥Âè∞" src="https://img.shields.io/badge/ÂæÆ‰ø°ÂØπËØùÂºÄÊîæÂπ≥Âè∞-5ac725" /&gt; &lt;/a&gt; &lt;a href="https://github.com/Tencent/WeKnora/raw/main/LICENSE"&gt; &lt;img src="https://img.shields.io/badge/License-MIT-ffffff?labelColor=d4eaf7&amp;amp;color=2e6cc4" alt="License" /&gt; &lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/CHANGELOG.md"&gt; &lt;img alt="Version" src="https://img.shields.io/badge/version-0.2.10-2e6cc4?labelColor=d4eaf7" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; | &lt;b&gt;English&lt;/b&gt; | &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/README_CN.md"&gt;&lt;b&gt;ÁÆÄ‰Ωì‰∏≠Êñá&lt;/b&gt;&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/README_JA.md"&gt;&lt;b&gt;Êó•Êú¨Ë™û&lt;/b&gt;&lt;/a&gt; | &lt;/p&gt; 
&lt;p align="center"&gt; &lt;/p&gt;
&lt;h4 align="center"&gt; &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/#-overview"&gt;Overview&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/#-architecture"&gt;Architecture&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/#-key-features"&gt;Key Features&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/#-getting-started"&gt;Getting Started&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/#-api-reference"&gt;API Reference&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/#-developer-guide"&gt;Developer Guide&lt;/a&gt;&lt;/p&gt; &lt;/h4&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;h1&gt;üí° WeKnora - LLM-Powered Document Understanding &amp;amp; Retrieval Framework&lt;/h1&gt; 
&lt;h2&gt;üìå Overview&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://weknora.weixin.qq.com"&gt;&lt;strong&gt;WeKnora&lt;/strong&gt;&lt;/a&gt; is an LLM-powered framework designed for deep document understanding and semantic retrieval, especially for handling complex, heterogeneous documents.&lt;/p&gt; 
&lt;p&gt;It adopts a modular architecture that combines multimodal preprocessing, semantic vector indexing, intelligent retrieval, and large language model inference. At its core, WeKnora follows the &lt;strong&gt;RAG (Retrieval-Augmented Generation)&lt;/strong&gt; paradigm, enabling high-quality, context-aware answers by combining relevant document chunks with model reasoning.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Website:&lt;/strong&gt; &lt;a href="https://weknora.weixin.qq.com"&gt;https://weknora.weixin.qq.com&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;‚ú® Latest Updates&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;v0.2.0 Highlights:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;ü§ñ &lt;strong&gt;Agent Mode&lt;/strong&gt;: New ReACT Agent mode that can call built-in tools, MCP tools, and web search, providing comprehensive summary reports through multiple iterations and reflection&lt;/li&gt; 
 &lt;li&gt;üìö &lt;strong&gt;Multi-Type Knowledge Bases&lt;/strong&gt;: Support for FAQ and document knowledge base types, with new features including folder import, URL import, tag management, and online entry&lt;/li&gt; 
 &lt;li&gt;‚öôÔ∏è &lt;strong&gt;Conversation Strategy&lt;/strong&gt;: Support for configuring Agent models, normal mode models, retrieval thresholds, and Prompts, with precise control over multi-turn conversation behavior&lt;/li&gt; 
 &lt;li&gt;üåê &lt;strong&gt;Web Search&lt;/strong&gt;: Support for extensible web search engines with built-in DuckDuckGo search engine&lt;/li&gt; 
 &lt;li&gt;üîå &lt;strong&gt;MCP Tool Integration&lt;/strong&gt;: Support for extending Agent capabilities through MCP, with built-in uvx and npx launchers, supporting multiple transport methods&lt;/li&gt; 
 &lt;li&gt;üé® &lt;strong&gt;New UI&lt;/strong&gt;: Optimized conversation interface with Agent mode/normal mode switching, tool call process display, and comprehensive knowledge base management interface upgrade&lt;/li&gt; 
 &lt;li&gt;‚ö° &lt;strong&gt;Infrastructure Upgrade&lt;/strong&gt;: Introduced MQ async task management, support for automatic database migration, and fast development mode&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üîí Security Notice&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Important:&lt;/strong&gt; Starting from v0.1.3, WeKnora includes login authentication functionality to enhance system security. For production deployments, we strongly recommend:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Deploy WeKnora services in internal/private network environments rather than public internet&lt;/li&gt; 
 &lt;li&gt;Avoid exposing the service directly to public networks to prevent potential information leakage&lt;/li&gt; 
 &lt;li&gt;Configure proper firewall rules and access controls for your deployment environment&lt;/li&gt; 
 &lt;li&gt;Regularly update to the latest version for security patches and improvements&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üèóÔ∏è Architecture&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/images/architecture.png" alt="weknora-architecture.png" /&gt;&lt;/p&gt; 
&lt;p&gt;WeKnora employs a modern modular design to build a complete document understanding and retrieval pipeline. The system primarily includes document parsing, vector processing, retrieval engine, and large model inference as core modules, with each component being flexibly configurable and extendable.&lt;/p&gt; 
&lt;h2&gt;üéØ Key Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;ü§ñ Agent Mode&lt;/strong&gt;: Support for ReACT Agent mode that can use built-in tools to retrieve knowledge bases, MCP tools, and web search tools to access external services, providing comprehensive summary reports through multiple iterations and reflection&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üîç Precise Understanding&lt;/strong&gt;: Structured content extraction from PDFs, Word documents, images and more into unified semantic views&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üß† Intelligent Reasoning&lt;/strong&gt;: Leverages LLMs to understand document context and user intent for accurate Q&amp;amp;A and multi-turn conversations&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üìö Multi-Type Knowledge Bases&lt;/strong&gt;: Support for FAQ and document knowledge base types, with folder import, URL import, tag management, and online entry capabilities&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üîß Flexible Extension&lt;/strong&gt;: All components from parsing and embedding to retrieval and generation are decoupled for easy customization&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;‚ö° Efficient Retrieval&lt;/strong&gt;: Hybrid retrieval strategies combining keywords, vectors, and knowledge graphs, with cross-knowledge base retrieval support&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üåê Web Search&lt;/strong&gt;: Support for extensible web search engines with built-in DuckDuckGo search engine&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üîå MCP Tool Integration&lt;/strong&gt;: Support for extending Agent capabilities through MCP, with built-in uvx and npx launchers, supporting multiple transport methods&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;‚öôÔ∏è Conversation Strategy&lt;/strong&gt;: Support for configuring Agent models, normal mode models, retrieval thresholds, and Prompts, with precise control over multi-turn conversation behavior&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üéØ User-Friendly&lt;/strong&gt;: Intuitive web interface and standardized APIs for zero technical barriers&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üîí Secure &amp;amp; Controlled&lt;/strong&gt;: Support for local deployment and private cloud, ensuring complete data sovereignty&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üìä Application Scenarios&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Scenario&lt;/th&gt; 
   &lt;th&gt;Applications&lt;/th&gt; 
   &lt;th&gt;Core Value&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Enterprise Knowledge Management&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Internal document retrieval, policy Q&amp;amp;A, operation manual search&lt;/td&gt; 
   &lt;td&gt;Improve knowledge discovery efficiency, reduce training costs&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Academic Research Analysis&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Paper retrieval, research report analysis, scholarly material organization&lt;/td&gt; 
   &lt;td&gt;Accelerate literature review, assist research decisions&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Product Technical Support&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Product manual Q&amp;amp;A, technical documentation search, troubleshooting&lt;/td&gt; 
   &lt;td&gt;Enhance customer service quality, reduce support burden&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Legal &amp;amp; Compliance Review&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Contract clause retrieval, regulatory policy search, case analysis&lt;/td&gt; 
   &lt;td&gt;Improve compliance efficiency, reduce legal risks&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Medical Knowledge Assistance&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Medical literature retrieval, treatment guideline search, case analysis&lt;/td&gt; 
   &lt;td&gt;Support clinical decisions, improve diagnosis quality&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;üß© Feature Matrix&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Module&lt;/th&gt; 
   &lt;th&gt;Support&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Agent Mode&lt;/td&gt; 
   &lt;td&gt;‚úÖ ReACT Agent Mode&lt;/td&gt; 
   &lt;td&gt;Support for using built-in tools to retrieve knowledge bases, MCP tools, and web search, with cross-knowledge base retrieval and multiple iterations&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Knowledge Base Types&lt;/td&gt; 
   &lt;td&gt;‚úÖ FAQ / Document&lt;/td&gt; 
   &lt;td&gt;Support for creating FAQ and document knowledge base types, with folder import, URL import, tag management, and online entry&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Document Formats&lt;/td&gt; 
   &lt;td&gt;‚úÖ PDF / Word / Txt / Markdown / Images (with OCR / Caption)&lt;/td&gt; 
   &lt;td&gt;Support for structured and unstructured documents with text extraction from images&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Model Management&lt;/td&gt; 
   &lt;td&gt;‚úÖ Centralized configuration, built-in model sharing&lt;/td&gt; 
   &lt;td&gt;Centralized model configuration with model selection in knowledge base settings, support for multi-tenant shared built-in models&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Embedding Models&lt;/td&gt; 
   &lt;td&gt;‚úÖ Local models, BGE / GTE APIs, etc.&lt;/td&gt; 
   &lt;td&gt;Customizable embedding models, compatible with local deployment and cloud vector generation APIs&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Vector DB Integration&lt;/td&gt; 
   &lt;td&gt;‚úÖ PostgreSQL (pgvector), Elasticsearch&lt;/td&gt; 
   &lt;td&gt;Support for mainstream vector index backends, flexible switching for different retrieval scenarios&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Retrieval Strategies&lt;/td&gt; 
   &lt;td&gt;‚úÖ BM25 / Dense Retrieval / GraphRAG&lt;/td&gt; 
   &lt;td&gt;Support for sparse/dense recall and knowledge graph-enhanced retrieval with customizable retrieve-rerank-generate pipelines&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;LLM Integration&lt;/td&gt; 
   &lt;td&gt;‚úÖ Support for Qwen, DeepSeek, etc., with thinking/non-thinking mode switching&lt;/td&gt; 
   &lt;td&gt;Compatible with local models (e.g., via Ollama) or external API services with flexible inference configuration&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Conversation Strategy&lt;/td&gt; 
   &lt;td&gt;‚úÖ Agent models, normal mode models, retrieval thresholds, Prompt configuration&lt;/td&gt; 
   &lt;td&gt;Support for configuring Agent models, normal mode models, retrieval thresholds, online Prompt configuration, precise control over multi-turn conversation behavior&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Web Search&lt;/td&gt; 
   &lt;td&gt;‚úÖ Extensible search engines, DuckDuckGo / Google&lt;/td&gt; 
   &lt;td&gt;Support for extensible web search engines with built-in DuckDuckGo search engine&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;MCP Tools&lt;/td&gt; 
   &lt;td&gt;‚úÖ uvx, npx launchers, Stdio/HTTP Streamable/SSE&lt;/td&gt; 
   &lt;td&gt;Support for extending Agent capabilities through MCP, with built-in uvx and npx launchers, supporting three transport methods&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;QA Capabilities&lt;/td&gt; 
   &lt;td&gt;‚úÖ Context-aware, multi-turn dialogue, prompt templates&lt;/td&gt; 
   &lt;td&gt;Support for complex semantic modeling, instruction control and chain-of-thought Q&amp;amp;A with configurable prompts and context windows&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;E2E Testing&lt;/td&gt; 
   &lt;td&gt;‚úÖ Retrieval+generation process visualization and metric evaluation&lt;/td&gt; 
   &lt;td&gt;End-to-end testing tools for evaluating recall hit rates, answer coverage, BLEU/ROUGE and other metrics&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Deployment Modes&lt;/td&gt; 
   &lt;td&gt;‚úÖ Support for local deployment / Docker images&lt;/td&gt; 
   &lt;td&gt;Meets private, offline deployment and flexible operation requirements, with fast development mode support&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;User Interfaces&lt;/td&gt; 
   &lt;td&gt;‚úÖ Web UI + RESTful API&lt;/td&gt; 
   &lt;td&gt;Interactive interface and standard API endpoints, with Agent mode/normal mode switching and tool call process display&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Task Management&lt;/td&gt; 
   &lt;td&gt;‚úÖ MQ async tasks, automatic database migration&lt;/td&gt; 
   &lt;td&gt;MQ-based async task state maintenance, support for automatic database schema and data migration during version upgrades&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;üöÄ Getting Started&lt;/h2&gt; 
&lt;h3&gt;üõ† Prerequisites&lt;/h3&gt; 
&lt;p&gt;Make sure the following tools are installed on your system:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.docker.com/"&gt;Docker&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.docker.com/compose/"&gt;Docker Compose&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://git-scm.com/"&gt;Git&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üì¶ Installation&lt;/h3&gt; 
&lt;h4&gt;‚ë† Clone the repository&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Clone the main repository
git clone https://github.com/Tencent/WeKnora.git
cd WeKnora
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;‚ë° Configure environment variables&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Copy example env file
cp .env.example .env

# Edit .env and set required values
# All variables are documented in the .env.example comments
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;‚ë¢ Start the services (include Ollama)&lt;/h4&gt; 
&lt;p&gt;Check the images that need to be started in the .env file.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;./scripts/start_all.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;or&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;make start-all
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;‚ë¢.0 Start ollama services (Optional)&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;ollama serve &amp;gt; /dev/null 2&amp;gt;&amp;amp;1 &amp;amp;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;‚ë¢.1 Activate different combinations of features&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Minimum core services&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker compose up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;All features enabled&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker-compose --profile full up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;Tracing logs required&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker-compose --profile jaeger up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;Neo4j knowledge graph required&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker-compose --profile neo4j up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;Minio file storage service required&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker-compose --profile minio up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;Multiple options combination&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker-compose --profile neo4j --profile minio up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;‚ë£ Stop the services&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;./scripts/start_all.sh --stop
# Or
make stop-all
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;üåê Access Services&lt;/h3&gt; 
&lt;p&gt;Once started, services will be available at:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Web UI: &lt;code&gt;http://localhost&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Backend API: &lt;code&gt;http://localhost:8080&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Jaeger Tracing: &lt;code&gt;http://localhost:16686&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üîå Using WeChat Dialog Open Platform&lt;/h3&gt; 
&lt;p&gt;WeKnora serves as the core technology framework for the &lt;a href="https://chatbot.weixin.qq.com"&gt;WeChat Dialog Open Platform&lt;/a&gt;, providing a more convenient usage approach:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Zero-code Deployment&lt;/strong&gt;: Simply upload knowledge to quickly deploy intelligent Q&amp;amp;A services within the WeChat ecosystem, achieving an "ask and answer" experience&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Efficient Question Management&lt;/strong&gt;: Support for categorized management of high-frequency questions, with rich data tools to ensure accurate, reliable, and easily maintainable answers&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;WeChat Ecosystem Integration&lt;/strong&gt;: Through the WeChat Dialog Open Platform, WeKnora's intelligent Q&amp;amp;A capabilities can be seamlessly integrated into WeChat Official Accounts, Mini Programs, and other WeChat scenarios, enhancing user interaction experiences&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üîó Access WeKnora via MCP Server&lt;/h3&gt; 
&lt;h4&gt;1Ô∏è‚É£ Clone the repository&lt;/h4&gt; 
&lt;pre&gt;&lt;code&gt;git clone https://github.com/Tencent/WeKnora
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;2Ô∏è‚É£ Configure MCP Server&lt;/h4&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;It is recommended to directly refer to the &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/mcp-server/MCP_CONFIG.md"&gt;MCP Configuration Guide&lt;/a&gt; for configuration.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Configure the MCP client to connect to the server:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "mcpServers": {
    "weknora": {
      "args": [
        "path/to/WeKnora/mcp-server/run_server.py"
      ],
      "command": "python",
      "env":{
        "WEKNORA_API_KEY":"Enter your WeKnora instance, open developer tools, check the request header x-api-key starting with sk",
        "WEKNORA_BASE_URL":"http(s)://your-weknora-address/api/v1"
      }
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Run directly using stdio command:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;pip install weknora-mcp-server
python -m weknora-mcp-server
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;üîß Initialization Configuration Guide&lt;/h2&gt; 
&lt;p&gt;To help users quickly configure various models and reduce trial-and-error costs, we've improved the original configuration file initialization method by adding a Web UI interface for model configuration. Before using, please ensure the code is updated to the latest version. The specific steps are as follows: If this is your first time using this project, you can skip steps ‚ë†‚ë° and go directly to steps ‚ë¢‚ë£.&lt;/p&gt; 
&lt;h3&gt;‚ë† Stop the services&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;./scripts/start_all.sh --stop
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;‚ë° Clear existing data tables (recommended when no important data exists)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;make clean-db
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;‚ë¢ Compile and start services&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;./scripts/start_all.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;‚ë£ Access Web UI&lt;/h3&gt; 
&lt;p&gt;&lt;a href="http://localhost"&gt;http://localhost&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;On your first visit, you will be automatically redirected to the registration/login page. After completing registration, please create a new knowledge base and finish the relevant settings on its configuration page.&lt;/p&gt; 
&lt;h2&gt;üì± Interface Showcase&lt;/h2&gt; 
&lt;h3&gt;Web UI Interface&lt;/h3&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td&gt;&lt;b&gt;Knowledge Base Management&lt;/b&gt;&lt;br /&gt;&lt;img src="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/images/knowledgebases.png" alt="Knowledge Base Management" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;b&gt;Conversation Settings&lt;/b&gt;&lt;br /&gt;&lt;img src="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/images/settings.png" alt="Conversation Settings" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td colspan="2"&gt;&lt;b&gt;Agent Mode Tool Call Process&lt;/b&gt;&lt;br /&gt;&lt;img src="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/images/agent-qa.png" alt="Agent Mode Tool Call Process" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;Knowledge Base Management:&lt;/strong&gt; Support for creating FAQ and document knowledge base types, with multiple import methods including drag-and-drop, folder import, and URL import. Automatically identifies document structures and extracts core knowledge to establish indexes. Supports tag management and online entry. The system clearly displays processing progress and document status, achieving efficient knowledge base management.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Agent Mode:&lt;/strong&gt; Support for ReACT Agent mode that can use built-in tools to retrieve knowledge bases, call user-configured MCP tools and web search tools to access external services, providing comprehensive summary reports through multiple iterations and reflection. Supports cross-knowledge base retrieval, allowing selection of multiple knowledge bases for simultaneous retrieval.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Conversation Strategy:&lt;/strong&gt; Support for configuring Agent models, normal mode models, retrieval thresholds, and online Prompt configuration, with precise control over multi-turn conversation behavior and retrieval execution methods. The conversation input box supports Agent mode/normal mode switching, enabling/disabling web search, and selecting conversation models.&lt;/p&gt; 
&lt;h3&gt;Document Knowledge Graph&lt;/h3&gt; 
&lt;p&gt;WeKnora supports transforming documents into knowledge graphs, displaying the relationships between different sections of the documents. Once the knowledge graph feature is enabled, the system analyzes and constructs an internal semantic association network that not only helps users understand document content but also provides structured support for indexing and retrieval, enhancing the relevance and breadth of search results.&lt;/p&gt; 
&lt;p&gt;For detailed configuration, please refer to the &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/KnowledgeGraph.md"&gt;Knowledge Graph Configuration Guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;MCP Server&lt;/h3&gt; 
&lt;p&gt;Please refer to the &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/mcp-server/MCP_CONFIG.md"&gt;MCP Configuration Guide&lt;/a&gt; for the necessary setup.&lt;/p&gt; 
&lt;h2&gt;üìò API Reference&lt;/h2&gt; 
&lt;p&gt;Troubleshooting FAQ: &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/QA.md"&gt;Troubleshooting FAQ&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Detailed API documentation is available at: &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/api/README.md"&gt;API Docs&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üß≠ Developer Guide&lt;/h2&gt; 
&lt;h3&gt;‚ö° Fast Development Mode (Recommended)&lt;/h3&gt; 
&lt;p&gt;If you need to frequently modify code, &lt;strong&gt;you don't need to rebuild Docker images every time&lt;/strong&gt;! Use fast development mode:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Method 1: Using Make commands (Recommended)
make dev-start      # Start infrastructure
make dev-app        # Start backend (new terminal)
make dev-frontend   # Start frontend (new terminal)

# Method 2: One-click start
./scripts/quick-dev.sh

# Method 3: Using scripts
./scripts/dev.sh start     # Start infrastructure
./scripts/dev.sh app       # Start backend (new terminal)
./scripts/dev.sh frontend  # Start frontend (new terminal)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Development Advantages:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;‚úÖ Frontend modifications auto hot-reload (no restart needed)&lt;/li&gt; 
 &lt;li&gt;‚úÖ Backend modifications quick restart (5-10 seconds, supports Air hot-reload)&lt;/li&gt; 
 &lt;li&gt;‚úÖ No need to rebuild Docker images&lt;/li&gt; 
 &lt;li&gt;‚úÖ Support IDE breakpoint debugging&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Detailed Documentation:&lt;/strong&gt; &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/%E5%BC%80%E5%8F%91%E6%8C%87%E5%8D%97.md"&gt;Development Environment Quick Start&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;üìÅ Directory Structure&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;WeKnora/
‚îú‚îÄ‚îÄ client/      # go client
‚îú‚îÄ‚îÄ cmd/         # Main entry point
‚îú‚îÄ‚îÄ config/      # Configuration files
‚îú‚îÄ‚îÄ docker/      # docker images files
‚îú‚îÄ‚îÄ docreader/   # Document parsing app
‚îú‚îÄ‚îÄ docs/        # Project documentation
‚îú‚îÄ‚îÄ frontend/    # Frontend app
‚îú‚îÄ‚îÄ internal/    # Core business logic
‚îú‚îÄ‚îÄ mcp-server/  # MCP server
‚îú‚îÄ‚îÄ migrations/  # DB migration scripts
‚îî‚îÄ‚îÄ scripts/     # Shell scripts
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;ü§ù Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome community contributions! For suggestions, bugs, or feature requests, please submit an &lt;a href="https://github.com/Tencent/WeKnora/issues"&gt;Issue&lt;/a&gt; or directly create a Pull Request.&lt;/p&gt; 
&lt;h3&gt;üéØ How to Contribute&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;üêõ &lt;strong&gt;Bug Fixes&lt;/strong&gt;: Discover and fix system defects&lt;/li&gt; 
 &lt;li&gt;‚ú® &lt;strong&gt;New Features&lt;/strong&gt;: Propose and implement new capabilities&lt;/li&gt; 
 &lt;li&gt;üìö &lt;strong&gt;Documentation&lt;/strong&gt;: Improve project documentation&lt;/li&gt; 
 &lt;li&gt;üß™ &lt;strong&gt;Test Cases&lt;/strong&gt;: Write unit and integration tests&lt;/li&gt; 
 &lt;li&gt;üé® &lt;strong&gt;UI/UX Enhancements&lt;/strong&gt;: Improve user interface and experience&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üìã Contribution Process&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Fork the project&lt;/strong&gt; to your GitHub account&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Create a feature branch&lt;/strong&gt; &lt;code&gt;git checkout -b feature/amazing-feature&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Commit changes&lt;/strong&gt; &lt;code&gt;git commit -m 'Add amazing feature'&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Push branch&lt;/strong&gt; &lt;code&gt;git push origin feature/amazing-feature&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Create a Pull Request&lt;/strong&gt; with detailed description of changes&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;üé® Code Standards&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Follow &lt;a href="https://github.com/golang/go/wiki/CodeReviewComments"&gt;Go Code Review Comments&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Format code using &lt;code&gt;gofmt&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Add necessary unit tests&lt;/li&gt; 
 &lt;li&gt;Update relevant documentation&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üìù Commit Guidelines&lt;/h3&gt; 
&lt;p&gt;Use &lt;a href="https://www.conventionalcommits.org/"&gt;Conventional Commits&lt;/a&gt; standard:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;feat: Add document batch upload functionality
fix: Resolve vector retrieval precision issue
docs: Update API documentation
test: Add retrieval engine test cases
refactor: Restructure document parsing module
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;üë• Contributors&lt;/h2&gt; 
&lt;p&gt;Thanks to these excellent contributors:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/Tencent/WeKnora/graphs/contributors"&gt;&lt;img src="https://contrib.rocks/image?repo=Tencent/WeKnora" alt="Contributors" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üìÑ License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/LICENSE"&gt;MIT License&lt;/a&gt;. You are free to use, modify, and distribute the code with proper attribution.&lt;/p&gt; 
&lt;h2&gt;üìà Project Statistics&lt;/h2&gt; 
&lt;a href="https://www.star-history.com/#Tencent/WeKnora&amp;amp;type=date&amp;amp;legend=top-left"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://api.star-history.com/svg?repos=Tencent/WeKnora&amp;amp;type=date&amp;amp;theme=dark&amp;amp;legend=top-left" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://api.star-history.com/svg?repos=Tencent/WeKnora&amp;amp;type=date&amp;amp;legend=top-left" /&gt; 
  &lt;img alt="Star History Chart" src="https://api.star-history.com/svg?repos=Tencent/WeKnora&amp;amp;type=date&amp;amp;legend=top-left" /&gt; 
 &lt;/picture&gt; &lt;/a&gt;</description>
    </item>
    
  </channel>
</rss>