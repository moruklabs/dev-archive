<rss version="2.0">
  <channel>
    <title>GitHub Python Daily Trending</title>
    <description>Daily Trending of Python in GitHub</description>
    <pubDate>Fri, 12 Sep 2025 01:37:44 GMT</pubDate>
    <link>http://mshibanami.github.io/GitHubTrendingRSS</link>
    
    <item>
      <title>Physical-Intelligence/openpi</title>
      <link>https://github.com/Physical-Intelligence/openpi</link>
      <description>&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;openpi&lt;/h1&gt; 
&lt;p&gt;openpi holds open-source models and packages for robotics, published by the &lt;a href="https://www.physicalintelligence.company/"&gt;Physical Intelligence team&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Currently, this repo contains three types of models:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;the &lt;a href="https://www.physicalintelligence.company/blog/pi0"&gt;π₀ model&lt;/a&gt;, a flow-based vision-language-action model (VLA).&lt;/li&gt; 
 &lt;li&gt;the &lt;a href="https://www.physicalintelligence.company/research/fast"&gt;π₀-FAST model&lt;/a&gt;, an autoregressive VLA, based on the FAST action tokenizer.&lt;/li&gt; 
 &lt;li&gt;the &lt;a href="https://www.physicalintelligence.company/blog/pi05"&gt;π₀.₅ model&lt;/a&gt;, an upgraded version of π₀ with better open-world generalization trained with &lt;a href="https://www.physicalintelligence.company/research/knowledge_insulation"&gt;knowledge insulation&lt;/a&gt;. Note that, in this repository, we currently only support the flow matching head for both $\pi_{0.5}$ training and inference.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For all models, we provide &lt;em&gt;base model&lt;/em&gt; checkpoints, pre-trained on 10k+ hours of robot data, and examples for using them out of the box or fine-tuning them to your own datasets.&lt;/p&gt; 
&lt;p&gt;This is an experiment: $\pi_0$ was developed for our own robots, which differ from the widely used platforms such as &lt;a href="https://tonyzhaozh.github.io/aloha/"&gt;ALOHA&lt;/a&gt; and &lt;a href="https://droid-dataset.github.io/"&gt;DROID&lt;/a&gt;, and though we are optimistic that researchers and practitioners will be able to run creative new experiments adapting $\pi_0$ to their own platforms, we do not expect every such attempt to be successful. All this is to say: $\pi_0$ may or may not work for you, but you are welcome to try it and see!&lt;/p&gt; 
&lt;h2&gt;Updates&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;[Sept 2025] We released PyTorch support in openpi.&lt;/li&gt; 
 &lt;li&gt;[Sept 2025] We released pi05, an upgraded version of pi0 with better open-world generalization.&lt;/li&gt; 
 &lt;li&gt;[Sept 2025]: We have added an &lt;a href="https://raw.githubusercontent.com/Physical-Intelligence/openpi/main/examples/droid/README_train.md#data-filtering"&gt;improved idle filter&lt;/a&gt; for DROID training.&lt;/li&gt; 
 &lt;li&gt;[Jun 2025]: We have added &lt;a href="https://raw.githubusercontent.com/Physical-Intelligence/openpi/main/examples/droid/README_train.md"&gt;instructions&lt;/a&gt; for using &lt;code&gt;openpi&lt;/code&gt; to train VLAs on the full &lt;a href="https://droid-dataset.github.io/"&gt;DROID dataset&lt;/a&gt;. This is an approximate open-source implementation of the training pipeline used to train pi0-FAST-DROID.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Requirements&lt;/h2&gt; 
&lt;p&gt;To run the models in this repository, you will need an NVIDIA GPU with at least the following specifications. These estimations assume a single GPU, but you can also use multiple GPUs with model parallelism to reduce per-GPU memory requirements by configuring &lt;code&gt;fsdp_devices&lt;/code&gt; in the training config. Please also note that the current training script does not yet support multi-node training.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Mode&lt;/th&gt; 
   &lt;th&gt;Memory Required&lt;/th&gt; 
   &lt;th&gt;Example GPU&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Inference&lt;/td&gt; 
   &lt;td&gt;&amp;gt; 8 GB&lt;/td&gt; 
   &lt;td&gt;RTX 4090&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Fine-Tuning (LoRA)&lt;/td&gt; 
   &lt;td&gt;&amp;gt; 22.5 GB&lt;/td&gt; 
   &lt;td&gt;RTX 4090&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Fine-Tuning (Full)&lt;/td&gt; 
   &lt;td&gt;&amp;gt; 70 GB&lt;/td&gt; 
   &lt;td&gt;A100 (80GB) / H100&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;The repo has been tested with Ubuntu 22.04, we do not currently support other operating systems.&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;When cloning this repo, make sure to update submodules:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone --recurse-submodules git@github.com:Physical-Intelligence/openpi.git

# Or if you already cloned the repo:
git submodule update --init --recursive
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;We use &lt;a href="https://docs.astral.sh/uv/"&gt;uv&lt;/a&gt; to manage Python dependencies. See the &lt;a href="https://docs.astral.sh/uv/getting-started/installation/"&gt;uv installation instructions&lt;/a&gt; to set it up. Once uv is installed, run the following to set up the environment:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;GIT_LFS_SKIP_SMUDGE=1 uv sync
GIT_LFS_SKIP_SMUDGE=1 uv pip install -e .
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;NOTE: &lt;code&gt;GIT_LFS_SKIP_SMUDGE=1&lt;/code&gt; is needed to pull LeRobot as a dependency.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Docker&lt;/strong&gt;: As an alternative to uv installation, we provide instructions for installing openpi using Docker. If you encounter issues with your system setup, consider using Docker to simplify installation. See &lt;a href="https://raw.githubusercontent.com/Physical-Intelligence/openpi/main/docs/docker.md"&gt;Docker Setup&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;h2&gt;Model Checkpoints&lt;/h2&gt; 
&lt;h3&gt;Base Models&lt;/h3&gt; 
&lt;p&gt;We provide multiple base VLA model checkpoints. These checkpoints have been pre-trained on 10k+ hours of robot data, and can be used for fine-tuning.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Model&lt;/th&gt; 
   &lt;th&gt;Use Case&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Checkpoint Path&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;$\pi_0$&lt;/td&gt; 
   &lt;td&gt;Fine-Tuning&lt;/td&gt; 
   &lt;td&gt;Base &lt;a href="https://www.physicalintelligence.company/blog/pi0"&gt;π₀ model&lt;/a&gt; for fine-tuning&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;gs://openpi-assets/checkpoints/pi0_base&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;$\pi_0$-FAST&lt;/td&gt; 
   &lt;td&gt;Fine-Tuning&lt;/td&gt; 
   &lt;td&gt;Base autoregressive &lt;a href="https://www.physicalintelligence.company/research/fast"&gt;π₀-FAST model&lt;/a&gt; for fine-tuning&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;gs://openpi-assets/checkpoints/pi0_fast_base&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;$\pi_{0.5}$&lt;/td&gt; 
   &lt;td&gt;Fine-Tuning&lt;/td&gt; 
   &lt;td&gt;Base &lt;a href="https://www.physicalintelligence.company/blog/pi05"&gt;π₀.₅ model&lt;/a&gt; for fine-tuning&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;gs://openpi-assets/checkpoints/pi05_base&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Fine-Tuned Models&lt;/h3&gt; 
&lt;p&gt;We also provide "expert" checkpoints for various robot platforms and tasks. These models are fine-tuned from the base models above and intended to run directly on the target robot. These may or may not work on your particular robot. Since these checkpoints were fine-tuned on relatively small datasets collected with more widely available robots, such as ALOHA and the DROID Franka setup, they might not generalize to your particular setup, though we found some of these, especially the DROID checkpoint, to generalize quite broadly in practice.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Model&lt;/th&gt; 
   &lt;th&gt;Use Case&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Checkpoint Path&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;$\pi_0$-FAST-DROID&lt;/td&gt; 
   &lt;td&gt;Inference&lt;/td&gt; 
   &lt;td&gt;$\pi_0$-FAST model fine-tuned on the &lt;a href="https://droid-dataset.github.io/"&gt;DROID dataset&lt;/a&gt;: can perform a wide range of simple table-top manipulation tasks 0-shot in new scenes on the DROID robot platform&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;gs://openpi-assets/checkpoints/pi0_fast_droid&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;$\pi_0$-DROID&lt;/td&gt; 
   &lt;td&gt;Fine-Tuning&lt;/td&gt; 
   &lt;td&gt;$\pi_0$ model fine-tuned on the &lt;a href="https://droid-dataset.github.io/"&gt;DROID dataset&lt;/a&gt;: faster inference than $\pi_0$-FAST-DROID, but may not follow language commands as well&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;gs://openpi-assets/checkpoints/pi0_droid&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;$\pi_0$-ALOHA-towel&lt;/td&gt; 
   &lt;td&gt;Inference&lt;/td&gt; 
   &lt;td&gt;$\pi_0$ model fine-tuned on internal &lt;a href="https://tonyzhaozh.github.io/aloha/"&gt;ALOHA&lt;/a&gt; data: can fold diverse towels 0-shot on ALOHA robot platforms&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;gs://openpi-assets/checkpoints/pi0_aloha_towel&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;$\pi_0$-ALOHA-tupperware&lt;/td&gt; 
   &lt;td&gt;Inference&lt;/td&gt; 
   &lt;td&gt;$\pi_0$ model fine-tuned on internal &lt;a href="https://tonyzhaozh.github.io/aloha/"&gt;ALOHA&lt;/a&gt; data: can unpack food from a tupperware container&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;gs://openpi-assets/checkpoints/pi0_aloha_tupperware&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;$\pi_0$-ALOHA-pen-uncap&lt;/td&gt; 
   &lt;td&gt;Inference&lt;/td&gt; 
   &lt;td&gt;$\pi_0$ model fine-tuned on public &lt;a href="https://dit-policy.github.io/"&gt;ALOHA&lt;/a&gt; data: can uncap a pen&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;gs://openpi-assets/checkpoints/pi0_aloha_pen_uncap&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;$\pi_{0.5}$-LIBERO&lt;/td&gt; 
   &lt;td&gt;Inference&lt;/td&gt; 
   &lt;td&gt;$\pi_{0.5}$ model fine-tuned for the &lt;a href="https://libero-project.github.io/datasets"&gt;LIBERO&lt;/a&gt; benchmark: gets state-of-the-art performance (see &lt;a href="https://raw.githubusercontent.com/Physical-Intelligence/openpi/main/examples/libero/README.md"&gt;LIBERO README&lt;/a&gt;)&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;gs://openpi-assets/checkpoints/pi05_libero&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;$\pi_{0.5}$-DROID&lt;/td&gt; 
   &lt;td&gt;Inference / Fine-Tuning&lt;/td&gt; 
   &lt;td&gt;$\pi_{0.5}$ model fine-tuned on the &lt;a href="https://droid-dataset.github.io/"&gt;DROID dataset&lt;/a&gt; with &lt;a href="https://www.physicalintelligence.company/research/knowledge_insulation"&gt;knowledge insulation&lt;/a&gt;: fast inference and good language-following&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;gs://openpi-assets/checkpoints/pi05_droid&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;By default, checkpoints are automatically downloaded from &lt;code&gt;gs://openpi-assets&lt;/code&gt; and are cached in &lt;code&gt;~/.cache/openpi&lt;/code&gt; when needed. You can overwrite the download path by setting the &lt;code&gt;OPENPI_DATA_HOME&lt;/code&gt; environment variable.&lt;/p&gt; 
&lt;h2&gt;Running Inference for a Pre-Trained Model&lt;/h2&gt; 
&lt;p&gt;Our pre-trained model checkpoints can be run with a few lines of code (here our $\pi_0$-FAST-DROID model):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from openpi.training import config as _config
from openpi.policies import policy_config
from openpi.shared import download

config = _config.get_config("pi05_droid")
checkpoint_dir = download.maybe_download("gs://openpi-assets/checkpoints/pi05_droid")

# Create a trained policy.
policy = policy_config.create_trained_policy(config, checkpoint_dir)

# Run inference on a dummy example.
example = {
    "observation/exterior_image_1_left": ...,
    "observation/wrist_image_left": ...,
    ...
    "prompt": "pick up the fork"
}
action_chunk = policy.infer(example)["actions"]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can also test this out in the &lt;a href="https://raw.githubusercontent.com/Physical-Intelligence/openpi/main/examples/inference.ipynb"&gt;example notebook&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;We provide detailed step-by-step examples for running inference of our pre-trained checkpoints on &lt;a href="https://raw.githubusercontent.com/Physical-Intelligence/openpi/main/examples/droid/README.md"&gt;DROID&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/Physical-Intelligence/openpi/main/examples/aloha_real/README.md"&gt;ALOHA&lt;/a&gt; robots.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Remote Inference&lt;/strong&gt;: We provide &lt;a href="https://raw.githubusercontent.com/Physical-Intelligence/openpi/main/docs/remote_inference.md"&gt;examples and code&lt;/a&gt; for running inference of our models &lt;strong&gt;remotely&lt;/strong&gt;: the model can run on a different server and stream actions to the robot via a websocket connection. This makes it easy to use more powerful GPUs off-robot and keep robot and policy environments separate.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Test inference without a robot&lt;/strong&gt;: We provide a &lt;a href="https://raw.githubusercontent.com/Physical-Intelligence/openpi/main/examples/simple_client/README.md"&gt;script&lt;/a&gt; for testing inference without a robot. This script will generate a random observation and run inference with the model. See &lt;a href="https://raw.githubusercontent.com/Physical-Intelligence/openpi/main/examples/simple_client/README.md"&gt;here&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;h2&gt;Fine-Tuning Base Models on Your Own Data&lt;/h2&gt; 
&lt;p&gt;We will fine-tune the $\pi_{0.5}$ model on the &lt;a href="https://libero-project.github.io/datasets"&gt;LIBERO dataset&lt;/a&gt; as a running example for how to fine-tune a base model on your own data. We will explain three steps:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Convert your data to a LeRobot dataset (which we use for training)&lt;/li&gt; 
 &lt;li&gt;Defining training configs and running training&lt;/li&gt; 
 &lt;li&gt;Spinning up a policy server and running inference&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;1. Convert your data to a LeRobot dataset&lt;/h3&gt; 
&lt;p&gt;We provide a minimal example script for converting LIBERO data to a LeRobot dataset in &lt;a href="https://raw.githubusercontent.com/Physical-Intelligence/openpi/main/examples/libero/convert_libero_data_to_lerobot.py"&gt;&lt;code&gt;examples/libero/convert_libero_data_to_lerobot.py&lt;/code&gt;&lt;/a&gt;. You can easily modify it to convert your own data! You can download the raw LIBERO dataset from &lt;a href="https://huggingface.co/datasets/openvla/modified_libero_rlds"&gt;here&lt;/a&gt;, and run the script with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uv run examples/libero/convert_libero_data_to_lerobot.py --data_dir /path/to/your/libero/data
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; If you just want to fine-tune on LIBERO, you can skip this step, because our LIBERO fine-tuning configs point to a pre-converted LIBERO dataset. This step is merely an example that you can adapt to your own data.&lt;/p&gt; 
&lt;h3&gt;2. Defining training configs and running training&lt;/h3&gt; 
&lt;p&gt;To fine-tune a base model on your own data, you need to define configs for data processing and training. We provide example configs with detailed comments for LIBERO below, which you can modify for your own dataset:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Physical-Intelligence/openpi/main/src/openpi/policies/libero_policy.py"&gt;&lt;code&gt;LiberoInputs&lt;/code&gt; and &lt;code&gt;LiberoOutputs&lt;/code&gt;&lt;/a&gt;: Defines the data mapping from the LIBERO environment to the model and vice versa. Will be used for both, training and inference.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Physical-Intelligence/openpi/main/src/openpi/training/config.py"&gt;&lt;code&gt;LeRobotLiberoDataConfig&lt;/code&gt;&lt;/a&gt;: Defines how to process raw LIBERO data from LeRobot dataset for training.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Physical-Intelligence/openpi/main/src/openpi/training/config.py"&gt;&lt;code&gt;TrainConfig&lt;/code&gt;&lt;/a&gt;: Defines fine-tuning hyperparameters, data config, and weight loader.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;We provide example fine-tuning configs for &lt;a href="https://raw.githubusercontent.com/Physical-Intelligence/openpi/main/src/openpi/training/config.py"&gt;π₀&lt;/a&gt;, &lt;a href="https://raw.githubusercontent.com/Physical-Intelligence/openpi/main/src/openpi/training/config.py"&gt;π₀-FAST&lt;/a&gt;, and &lt;a href="https://raw.githubusercontent.com/Physical-Intelligence/openpi/main/src/openpi/training/config.py"&gt;π₀.₅&lt;/a&gt; on LIBERO data.&lt;/p&gt; 
&lt;p&gt;Before we can run training, we need to compute the normalization statistics for the training data. Run the script below with the name of your training config:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uv run scripts/compute_norm_stats.py --config-name pi05_libero
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Now we can kick off training with the following command (the &lt;code&gt;--overwrite&lt;/code&gt; flag is used to overwrite existing checkpoints if you rerun fine-tuning with the same config):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;XLA_PYTHON_CLIENT_MEM_FRACTION=0.9 uv run scripts/train.py pi05_libero --exp-name=my_experiment --overwrite
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The command will log training progress to the console and save checkpoints to the &lt;code&gt;checkpoints&lt;/code&gt; directory. You can also monitor training progress on the Weights &amp;amp; Biases dashboard. For maximally using the GPU memory, set &lt;code&gt;XLA_PYTHON_CLIENT_MEM_FRACTION=0.9&lt;/code&gt; before running training -- this enables JAX to use up to 90% of the GPU memory (vs. the default of 75%).&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; We provide functionality for &lt;em&gt;reloading&lt;/em&gt; normalization statistics for state / action normalization from pre-training. This can be beneficial if you are fine-tuning to a new task on a robot that was part of our pre-training mixture. For more details on how to reload normalization statistics, see the &lt;a href="https://raw.githubusercontent.com/Physical-Intelligence/openpi/main/docs/norm_stats.md"&gt;norm_stats.md&lt;/a&gt; file.&lt;/p&gt; 
&lt;h3&gt;3. Spinning up a policy server and running inference&lt;/h3&gt; 
&lt;p&gt;Once training is complete, we can run inference by spinning up a policy server and then querying it from a LIBERO evaluation script. Launching a model server is easy (we use the checkpoint for iteration 20,000 for this example, modify as needed):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uv run scripts/serve_policy.py policy:checkpoint --policy.config=pi05_libero --policy.dir=checkpoints/pi05_libero/my_experiment/20000
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This will spin up a server that listens on port 8000 and waits for observations to be sent to it. We can then run an evaluation script (or robot runtime) that queries the server.&lt;/p&gt; 
&lt;p&gt;For running the LIBERO eval in particular, we provide (and recommend using) a Dockerized workflow that handles both the policy server and the evaluation script together. See the &lt;a href="https://raw.githubusercontent.com/Physical-Intelligence/openpi/main/examples/libero/README.md"&gt;LIBERO README&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;p&gt;If you want to embed a policy server call in your own robot runtime, we have a minimal example of how to do so in the &lt;a href="https://raw.githubusercontent.com/Physical-Intelligence/openpi/main/docs/remote_inference.md"&gt;remote inference docs&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;More Examples&lt;/h3&gt; 
&lt;p&gt;We provide more examples for how to fine-tune and run inference with our models on the ALOHA platform in the following READMEs:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Physical-Intelligence/openpi/main/examples/aloha_sim"&gt;ALOHA Simulator&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Physical-Intelligence/openpi/main/examples/aloha_real"&gt;ALOHA Real&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Physical-Intelligence/openpi/main/examples/ur5"&gt;UR5&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;PyTorch Support&lt;/h2&gt; 
&lt;p&gt;openpi now provides PyTorch implementations of π₀ and π₀.₅ models alongside the original JAX versions! The PyTorch implementation has been validated on the LIBERO benchmark (both inference and finetuning). A few features are currently not supported (this may change in the future):&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;The π₀-FAST model&lt;/li&gt; 
 &lt;li&gt;Mixed precision training&lt;/li&gt; 
 &lt;li&gt;FSDP (fully-sharded data parallelism) training&lt;/li&gt; 
 &lt;li&gt;LoRA (low-rank adaptation) training&lt;/li&gt; 
 &lt;li&gt;EMA (exponential moving average) weights during training&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Setup&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Make sure that you have the latest version of all dependencies installed: &lt;code&gt;uv sync&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Double check that you have transformers 4.53.2 installed: &lt;code&gt;uv pip show transformers&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Apply the transformers library patches:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;cp -r ./src/openpi/models_pytorch/transformers_replace/* .venv/lib/python3.11/site-packages/transformers/
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;This overwrites several files in the transformers library with necessary model changes: 1) supporting AdaRMS, 2) correctly controlling the precision of activations, and 3) allowing the KV cache to be used without being updated.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;WARNING&lt;/strong&gt;: With the default uv link mode (hardlink), this will permanently affect the transformers library in your uv cache, meaning the changes will survive reinstallations of transformers and could even propagate to other projects that use transformers. To fully undo this operation, you must run &lt;code&gt;uv cache clean transformers&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;Converting JAX Models to PyTorch&lt;/h3&gt; 
&lt;p&gt;To convert a JAX model checkpoint to PyTorch format:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uv run examples/convert_jax_model_to_pytorch.py \
    --checkpoint_dir /path/to/jax/checkpoint \
    --config_name &amp;lt;config name&amp;gt; \
    --output_path /path/to/converted/pytorch/checkpoint
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Running Inference with PyTorch&lt;/h3&gt; 
&lt;p&gt;The PyTorch implementation uses the same API as the JAX version - you only need to change the checkpoint path to point to the converted PyTorch model:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from openpi.training import config as _config
from openpi.policies import policy_config
from openpi.shared import download

config = _config.get_config("pi05_droid")
checkpoint_dir = "/path/to/converted/pytorch/checkpoint"

# Create a trained policy (automatically detects PyTorch format)
policy = policy_config.create_trained_policy(config, checkpoint_dir)

# Run inference (same API as JAX)
action_chunk = policy.infer(example)["actions"]
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Policy Server with PyTorch&lt;/h3&gt; 
&lt;p&gt;The policy server works identically with PyTorch models - just point to the converted checkpoint directory:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uv run scripts/serve_policy.py policy:checkpoint \
    --policy.config=pi05_droid \
    --policy.dir=/path/to/converted/pytorch/checkpoint
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Finetuning with PyTorch&lt;/h3&gt; 
&lt;p&gt;To finetune a model in PyTorch:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Convert the JAX base model to PyTorch format:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;uv run examples/convert_jax_model_to_pytorch.py \
    --config_name &amp;lt;config name&amp;gt; \
    --checkpoint_dir /path/to/jax/base/model \
    --output_path /path/to/pytorch/base/model
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Specify the converted PyTorch model path in your config using &lt;code&gt;pytorch_weight_path&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Launch training using one of these modes:&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Single GPU training:
uv run scripts/train_pytorch.py &amp;lt;config_name&amp;gt; --exp_name &amp;lt;run_name&amp;gt; --save_interval &amp;lt;interval&amp;gt;

# Example:
uv run scripts/train_pytorch.py debug --exp_name pytorch_test
uv run scripts/train_pytorch.py debug --exp_name pytorch_test --resume  # Resume from latest checkpoint

# Multi-GPU training (single node):
uv run torchrun --standalone --nnodes=1 --nproc_per_node=&amp;lt;num_gpus&amp;gt; scripts/train_pytorch.py &amp;lt;config_name&amp;gt; --exp_name &amp;lt;run_name&amp;gt;

# Example:
uv run torchrun --standalone --nnodes=1 --nproc_per_node=2 scripts/train_pytorch.py pi0_aloha_sim --exp_name pytorch_ddp_test
uv run torchrun --standalone --nnodes=1 --nproc_per_node=2 scripts/train_pytorch.py pi0_aloha_sim --exp_name pytorch_ddp_test --resume

# Multi-Node Training:
uv run torchrun \
    --nnodes=&amp;lt;num_nodes&amp;gt; \
    --nproc_per_node=&amp;lt;gpus_per_node&amp;gt; \
    --node_rank=&amp;lt;rank_of_node&amp;gt; \
    --master_addr=&amp;lt;master_ip&amp;gt; \
    --master_port=&amp;lt;port&amp;gt; \
    scripts/train_pytorch.py &amp;lt;config_name&amp;gt; --exp_name=&amp;lt;run_name&amp;gt; --save_interval &amp;lt;interval&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Precision Settings&lt;/h3&gt; 
&lt;p&gt;JAX and PyTorch implementations handle precision as follows:&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;JAX:&lt;/strong&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Inference: most weights and computations in bfloat16, with a few computations in float32 for stability&lt;/li&gt; 
 &lt;li&gt;Training: defaults to mixed precision: weights and gradients in float32, (most) activations and computations in bfloat16. You can change to full float32 training by setting &lt;code&gt;dtype&lt;/code&gt; to float32 in the config.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;PyTorch:&lt;/strong&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Inference: matches JAX -- most weights and computations in bfloat16, with a few weights converted to float32 for stability&lt;/li&gt; 
 &lt;li&gt;Training: supports either full bfloat16 (default) or full float32. You can change it by setting &lt;code&gt;pytorch_training_precision&lt;/code&gt; in the config. bfloat16 uses less memory but exhibits higher losses compared to float32. Mixed precision is not yet supported.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;With torch.compile, inference speed is comparable between JAX and PyTorch.&lt;/p&gt; 
&lt;h2&gt;Troubleshooting&lt;/h2&gt; 
&lt;p&gt;We will collect common issues and their solutions here. If you encounter an issue, please check here first. If you can't find a solution, please file an issue on the repo (see &lt;a href="https://raw.githubusercontent.com/Physical-Intelligence/openpi/main/CONTRIBUTING.md"&gt;here&lt;/a&gt; for guidelines).&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Issue&lt;/th&gt; 
   &lt;th&gt;Resolution&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;uv sync&lt;/code&gt; fails with dependency conflicts&lt;/td&gt; 
   &lt;td&gt;Try removing the virtual environment directory (&lt;code&gt;rm -rf .venv&lt;/code&gt;) and running &lt;code&gt;uv sync&lt;/code&gt; again. If issues persist, check that you have the latest version of &lt;code&gt;uv&lt;/code&gt; installed (&lt;code&gt;uv self update&lt;/code&gt;).&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Training runs out of GPU memory&lt;/td&gt; 
   &lt;td&gt;Make sure you set &lt;code&gt;XLA_PYTHON_CLIENT_MEM_FRACTION=0.9&lt;/code&gt; (or higher) before running training to allow JAX to use more GPU memory. You can also use &lt;code&gt;--fsdp-devices &amp;lt;n&amp;gt;&lt;/code&gt; where &lt;code&gt;&amp;lt;n&amp;gt;&lt;/code&gt; is your number of GPUs, to enable &lt;a href="https://engineering.fb.com/2021/07/15/open-source/fsdp/"&gt;fully-sharded data parallelism&lt;/a&gt;, which reduces memory usage in exchange for slower training (the amount of slowdown depends on your particular setup). If you are still running out of memory, you may way to consider disabling EMA.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Policy server connection errors&lt;/td&gt; 
   &lt;td&gt;Check that the server is running and listening on the expected port. Verify network connectivity and firewall settings between client and server.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Missing norm stats error when training&lt;/td&gt; 
   &lt;td&gt;Run &lt;code&gt;scripts/compute_norm_stats.py&lt;/code&gt; with your config name before starting training.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Dataset download fails&lt;/td&gt; 
   &lt;td&gt;Check your internet connection. For HuggingFace datasets, ensure you're logged in (&lt;code&gt;huggingface-cli login&lt;/code&gt;).&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;CUDA/GPU errors&lt;/td&gt; 
   &lt;td&gt;Verify NVIDIA drivers are installed correctly. For Docker, ensure nvidia-container-toolkit is installed. Check GPU compatibility. You do NOT need CUDA libraries installed at a system level --- they will be installed via uv. You may even want to try &lt;em&gt;uninstalling&lt;/em&gt; system CUDA libraries if you run into CUDA issues, since system libraries can sometimes cause conflicts.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Import errors when running examples&lt;/td&gt; 
   &lt;td&gt;Make sure you've installed all dependencies with &lt;code&gt;uv sync&lt;/code&gt;. Some examples may have additional requirements listed in their READMEs.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Action dimensions mismatch&lt;/td&gt; 
   &lt;td&gt;Verify your data processing transforms match the expected input/output dimensions of your robot. Check the action space definitions in your policy classes.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Diverging training loss&lt;/td&gt; 
   &lt;td&gt;Check the &lt;code&gt;q01&lt;/code&gt;, &lt;code&gt;q99&lt;/code&gt;, and &lt;code&gt;std&lt;/code&gt; values in &lt;code&gt;norm_stats.json&lt;/code&gt; for your dataset. Certain dimensions that are rarely used can end up with very small &lt;code&gt;q01&lt;/code&gt;, &lt;code&gt;q99&lt;/code&gt;, or &lt;code&gt;std&lt;/code&gt; values, leading to huge states and actions after normalization. You can manually adjust the norm stats as a workaround.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt;</description>
    </item>
    
    <item>
      <title>PaddlePaddle/PaddleOCR</title>
      <link>https://github.com/PaddlePaddle/PaddleOCR</link>
      <description>&lt;p&gt;Awesome multilingual OCR and Document Parsing toolkits based on PaddlePaddle (practical ultra lightweight OCR system, support 80+ languages recognition, provide data annotation and synthesis tools, support training and deployment among server, mobile, embedded and IoT devices)&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;p&gt; &lt;img width="100%" src="https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/main/docs/images/Banner.png" alt="PaddleOCR Banner" /&gt; &lt;/p&gt; 
 &lt;p&gt;English | &lt;a href="https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/main/readme/README_cn.md"&gt;简体中文&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/main/readme/README_tcn.md"&gt;繁體中文&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/main/readme/README_ja.md"&gt;日本語&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/main/readme/README_ko.md"&gt;한국어&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/main/readme/README_fr.md"&gt;Français&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/main/readme/README_ru.md"&gt;Русский&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/main/readme/README_es.md"&gt;Español&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/main/readme/README_ar.md"&gt;العربية&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://github.com/PaddlePaddle/PaddleOCR"&gt;&lt;img src="https://img.shields.io/github/stars/PaddlePaddle/PaddleOCR?color=ccf" alt="stars" /&gt;&lt;/a&gt; &lt;a href="https://arxiv.org/abs/2507.05595"&gt;&lt;img src="https://img.shields.io/badge/arXiv-2507.05595-b31b1b.svg?logo=arXiv" alt="arXiv" /&gt;&lt;/a&gt; &lt;a href="https://pepy.tech/project/paddleocr"&gt;&lt;img src="https://static.pepy.tech/badge/paddleocr/month" alt="PyPI Downloads" /&gt;&lt;/a&gt; &lt;a href="https://pepy.tech/project/paddleocr"&gt;&lt;img src="https://static.pepy.tech/badge/paddleocr" alt="PyPI Downloads" /&gt;&lt;/a&gt; &lt;a href="https://github.com/PaddlePaddle/PaddleOCR/network/dependents"&gt;&lt;img src="https://img.shields.io/badge/Used%20by-5.9k%2B%20repositories-blue" alt="Used by" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;img src="https://img.shields.io/badge/python-3.8~3.12-aff.svg?sanitize=true" alt="python" /&gt; &lt;img src="https://img.shields.io/badge/os-linux%2C%20win%2C%20mac-pink.svg?sanitize=true" alt="os" /&gt; &lt;img src="https://img.shields.io/badge/hardware-cpu%2C%20gpu%2C%20xpu%2C%20npu-yellow.svg?sanitize=true" alt="hardware" /&gt; &lt;a href="https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/main/LICENSE"&gt;&lt;img src="https://img.shields.io/badge/license-Apache_2.0-green" alt="License" /&gt;&lt;/a&gt; &lt;a href="https://deepwiki.com/PaddlePaddle/PaddleOCR"&gt;&lt;img src="https://deepwiki.com/badge.svg?sanitize=true" alt="Ask DeepWiki" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;PaddleOCR is an industry-leading, production-ready OCR and document AI engine, offering end-to-end solutions from text extraction to intelligent document understanding&lt;/strong&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h1&gt;PaddleOCR&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://www.paddlepaddle.org.cn/en"&gt;&lt;img src="https://img.shields.io/badge/PaddlePaddle-3.0-orange" alt="Framework" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/main/#"&gt;&lt;img src="https://img.shields.io/badge/Recognition%20Accuracy-%F0%9F%8F%86-green" alt="Accuracy" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/main/#"&gt;&lt;img src="https://img.shields.io/badge/Support_Languages-80+-brightgreen" alt="Multi-Language" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/main/#"&gt;&lt;img src="https://img.shields.io/badge/Handwriting-%E2%9C%93-success" alt="Handwriting" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/main/#"&gt;&lt;img src="https://img.shields.io/badge/Heterogeneous%20Hardware-Kunlunxin%20%7C%20Ascend_NPU-red" alt="Hardware" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] PaddleOCR now provides an MCP server that supports integration with Agent applications like Claude Desktop. For details, please refer to &lt;a href="https://paddlepaddle.github.io/PaddleOCR/latest/en/version3.x/deployment/mcp_server.html"&gt;PaddleOCR MCP Server&lt;/a&gt;.&lt;/p&gt; 
 &lt;p&gt;The PaddleOCR 3.0 Technical Report is now available. See details at: &lt;a href="https://arxiv.org/abs/2507.05595"&gt;PaddleOCR 3.0 Technical Report&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;PaddleOCR&lt;/strong&gt; converts documents and images into &lt;strong&gt;structured, AI-friendly data&lt;/strong&gt; (like JSON and Markdown) with &lt;strong&gt;industry-leading accuracy&lt;/strong&gt;—powering AI applications for everyone from indie developers and startups to large enterprises worldwide. With over &lt;strong&gt;50,000 stars&lt;/strong&gt; and deep integration into leading projects like &lt;strong&gt;MinerU, RAGFlow, and OmniParser&lt;/strong&gt;, PaddleOCR has become the &lt;strong&gt;premier solution&lt;/strong&gt; for developers building intelligent document applications in the &lt;strong&gt;AI era&lt;/strong&gt;.&lt;/p&gt; 
&lt;h3&gt;PaddleOCR 3.0 Core Features&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://aistudio.baidu.com/community/app/91660/webUI"&gt;&lt;img src="https://img.shields.io/badge/PP_OCRv5-Demo_on_AI_Studio-green" alt="AI Studio" /&gt;&lt;/a&gt; &lt;a href="https://aistudio.baidu.com/community/app/518494/webUI"&gt;&lt;img src="https://img.shields.io/badge/PP_StructureV3-Demo_on_AI_Studio-green" alt="AI Studio" /&gt;&lt;/a&gt; &lt;a href="https://aistudio.baidu.com/community/app/518493/webUI"&gt;&lt;img src="https://img.shields.io/badge/PP_ChatOCRv4-Demo_on_AI_Studio-green" alt="AI Studio" /&gt;&lt;/a&gt; &lt;a href="https://www.modelscope.cn/organization/PaddlePaddle"&gt;&lt;img src="https://img.shields.io/badge/%F0%9F%A4%96_Demo_on_ModelScope-purple" alt="ModelScope" /&gt;&lt;/a&gt; &lt;a href="https://huggingface.co/PaddlePaddle"&gt;&lt;img src="https://img.shields.io/badge/Demo_on_HuggingFace-purple.svg?logo=huggingface" alt="HuggingFace" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;PP-OCRv5 — Universal Scene Text Recognition&lt;/strong&gt;&lt;br /&gt; &lt;strong&gt;Single model supports five text types&lt;/strong&gt; (Simplified Chinese, Traditional Chinese, English, Japanese, and Pinyin) with &lt;strong&gt;13% accuracy improvement&lt;/strong&gt;. Solves multilingual mixed document recognition challenges.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;PP-StructureV3 — Complex Document Parsing&lt;/strong&gt;&lt;br /&gt; Intelligently converts complex PDFs and document images into &lt;strong&gt;Markdown and JSON files that preserve original structure&lt;/strong&gt;. &lt;strong&gt;Outperforms&lt;/strong&gt; numerous commercial solutions in public benchmarks. &lt;strong&gt;Perfectly maintains document layout and hierarchical structure&lt;/strong&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;PP-ChatOCRv4 — Intelligent Information Extraction&lt;/strong&gt;&lt;br /&gt; Natively integrates ERNIE 4.5 to &lt;strong&gt;precisely extract key information&lt;/strong&gt; from massive documents, with 15% accuracy improvement over previous generation. Makes documents "&lt;strong&gt;understand&lt;/strong&gt;" your questions and provide accurate answers.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;In addition to providing an outstanding model library, PaddleOCR 3.0 also offers user-friendly tools covering model training, inference, and service deployment, so developers can rapidly bring AI applications to production.&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt; &lt;img width="100%" src="https://raw.githubusercontent.com/cuicheng01/PaddleX_doc_images/main/images/paddleocr/README/Arch.jpg" alt="PaddleOCR Architecture" /&gt; &lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;strong&gt;Special Note&lt;/strong&gt;: PaddleOCR 3.x introduces several significant interface changes. &lt;strong&gt;Old code written based on PaddleOCR 2.x is likely incompatible with PaddleOCR 3.x&lt;/strong&gt;. Please ensure that the documentation you are reading matches the version of PaddleOCR you are using. &lt;a href="https://paddlepaddle.github.io/PaddleOCR/latest/en/update/upgrade_notes.html"&gt;This document&lt;/a&gt; explains the reasons for the upgrade and the major changes from PaddleOCR 2.x to 3.x.&lt;/p&gt; 
&lt;h2&gt;📣 Recent updates&lt;/h2&gt; 
&lt;h3&gt;🔥🔥2025.08.21: Release of PaddleOCR 3.2.0, includes:&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Significant Model Additions:&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Introduced training, inference, and deployment for PP-OCRv5 recognition models in English, Thai, and Greek. &lt;strong&gt;The PP-OCRv5 English model delivers an 11% improvement in English scenarios compared to the main PP-OCRv5 model, with the Thai and Greek recognition models achieving accuracies of 82.68% and 89.28%, respectively.&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Deployment Capability Upgrades:&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Full support for PaddlePaddle framework versions 3.1.0 and 3.1.1.&lt;/strong&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Comprehensive upgrade of the PP-OCRv5 C++ local deployment solution, now supporting both Linux and Windows, with feature parity and identical accuracy to the Python implementation.&lt;/strong&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;High-performance inference now supports CUDA 12, and inference can be performed using either the Paddle Inference or ONNX Runtime backends.&lt;/strong&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;The high-stability service-oriented deployment solution is now fully open-sourced, allowing users to customize Docker images and SDKs as required.&lt;/strong&gt;&lt;/li&gt; 
   &lt;li&gt;The high-stability service-oriented deployment solution also supports invocation via manually constructed HTTP requests, enabling client-side code development in any programming language.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Benchmark Support:&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;All production lines now support fine-grained benchmarking, enabling measurement of end-to-end inference time as well as per-layer and per-module latency data to assist with performance analysis. &lt;a href="https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/main/docs/version3.x/pipeline_usage/instructions/benchmark.en.md"&gt;Here's&lt;/a&gt; how to set up and use the benchmark feature.&lt;/strong&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Documentation has been updated to include key metrics for commonly used configurations on mainstream hardware, such as inference latency and memory usage, providing deployment references for users.&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Bug Fixes:&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Resolved the issue of failed log saving during model training.&lt;/li&gt; 
   &lt;li&gt;Upgraded the data augmentation component for formula models for compatibility with newer versions of the albumentations dependency, and fixed deadlock warnings when using the tokenizers package in multi-process scenarios.&lt;/li&gt; 
   &lt;li&gt;Fixed inconsistencies in switch behaviors (e.g., &lt;code&gt;use_chart_parsing&lt;/code&gt;) in the PP-StructureV3 configuration files compared to other pipelines.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Other Enhancements:&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Separated core and optional dependencies. Only minimal core dependencies are required for basic text recognition; additional dependencies for document parsing and information extraction can be installed as needed.&lt;/strong&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Enabled support for NVIDIA RTX 50 series graphics cards on Windows; users can refer to the &lt;a href="https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/main/docs/version3.x/installation.en.md"&gt;installation guide&lt;/a&gt; for the corresponding PaddlePaddle framework versions.&lt;/strong&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;PP-OCR series models now support returning single-character coordinates.&lt;/strong&gt;&lt;/li&gt; 
   &lt;li&gt;Added AIStudio, ModelScope, and other model download sources, allowing users to specify the source for model downloads.&lt;/li&gt; 
   &lt;li&gt;Added support for chart-to-table conversion via the PP-Chart2Table module.&lt;/li&gt; 
   &lt;li&gt;Optimized documentation descriptions to improve usability.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;2025.08.15: PaddleOCR 3.1.1 Released&lt;/strong&gt;&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Bug Fixes:&lt;/strong&gt;&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Added the missing methods &lt;code&gt;save_vector&lt;/code&gt;, &lt;code&gt;save_visual_info_list&lt;/code&gt;, &lt;code&gt;load_vector&lt;/code&gt;, and &lt;code&gt;load_visual_info_list&lt;/code&gt; in the &lt;code&gt;PP-ChatOCRv4&lt;/code&gt; class.&lt;/li&gt; 
    &lt;li&gt;Added the missing parameters &lt;code&gt;glossary&lt;/code&gt; and &lt;code&gt;llm_request_interval&lt;/code&gt; to the &lt;code&gt;translate&lt;/code&gt; method in the &lt;code&gt;PPDocTranslation&lt;/code&gt; class.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Documentation Improvements:&lt;/strong&gt;&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Added a demo to the MCP documentation.&lt;/li&gt; 
    &lt;li&gt;Added information about the PaddlePaddle and PaddleOCR version used for performance metrics testing in the documentation.&lt;/li&gt; 
    &lt;li&gt;Fixed errors and omissions in the production line document translation.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Others:&lt;/strong&gt;&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Changed the MCP server dependency to use the pure Python library &lt;code&gt;puremagic&lt;/code&gt; instead of &lt;code&gt;python-magic&lt;/code&gt; to reduce installation issues.&lt;/li&gt; 
    &lt;li&gt;Retested PP-OCRv5 performance metrics with PaddleOCR version 3.1.0 and updated the documentation.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;2025.06.29: PaddleOCR 3.1.0 Released&lt;/strong&gt;&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Key Models and Pipelines:&lt;/strong&gt;&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Added PP-OCRv5 Multilingual Text Recognition Model&lt;/strong&gt;, which supports the training and inference process for text recognition models in 37 languages, including French, Spanish, Portuguese, Russian, Korean, etc. &lt;strong&gt;Average accuracy improved by over 30%.&lt;/strong&gt; &lt;a href="https://paddlepaddle.github.io/PaddleOCR/latest/en/version3.x/algorithm/PP-OCRv5/PP-OCRv5_multi_languages.html"&gt;Details&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;Upgraded the &lt;strong&gt;PP-Chart2Table model&lt;/strong&gt; in PP-StructureV3, further enhancing the capability of converting charts to tables. On internal custom evaluation sets, the metric (RMS-F1) &lt;strong&gt;increased by 9.36 percentage points (71.24% -&amp;gt; 80.60%).&lt;/strong&gt;&lt;/li&gt; 
    &lt;li&gt;Newly launched &lt;strong&gt;document translation pipeline, PP-DocTranslation, based on PP-StructureV3 and ERNIE 4.5&lt;/strong&gt;, which supports the translation of Markdown format documents, various complex-layout PDF documents, and document images, with the results saved as Markdown format documents. &lt;a href="https://paddlepaddle.github.io/PaddleOCR/latest/en/version3.x/pipeline_usage/PP-DocTranslation.html"&gt;Details&lt;/a&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;New MCP server:&lt;/strong&gt; &lt;a href="https://paddlepaddle.github.io/PaddleOCR/latest/en/version3.x/deployment/mcp_server.html"&gt;Details&lt;/a&gt;&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Supports both OCR and PP-StructureV3 pipelines.&lt;/strong&gt;&lt;/li&gt; 
    &lt;li&gt;Supports three working modes: local Python library, AIStudio Community Cloud Service, and self-hosted service.&lt;/li&gt; 
    &lt;li&gt;Supports invoking local services via stdio and remote services via Streamable HTTP.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Documentation Optimization:&lt;/strong&gt; Improved the descriptions in some user guides for a smoother reading experience.&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;2025.06.26: PaddleOCR 3.0.3 Released&lt;/strong&gt;&lt;/summary&gt; - Bug Fix: Resolved the issue where the `enable_mkldnn` parameter was not effective, restoring the default behavior of using MKL-DNN for CPU inference. 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;2025.06.19: PaddleOCR 3.0.2 Released&lt;/strong&gt;&lt;/summary&gt; - **New Features:** 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;The default download source has been changed from &lt;code&gt;BOS&lt;/code&gt; to &lt;code&gt;HuggingFace&lt;/code&gt;. Users can also change the environment variable &lt;code&gt;PADDLE_PDX_MODEL_SOURCE&lt;/code&gt; to &lt;code&gt;BOS&lt;/code&gt; to set the model download source back to Baidu Object Storage (BOS).&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;Added service invocation examples for six languages—C++, Java, Go, C#, Node.js, and PHP—for pipelines like PP-OCRv5, PP-StructureV3, and PP-ChatOCRv4.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;Improved the layout partition sorting algorithm in the PP-StructureV3 pipeline, enhancing the sorting logic for complex vertical layouts to deliver better results.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;Enhanced model selection logic: when a language is specified but a model version is not, the system will automatically select the latest model version supporting that language.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;Set a default upper limit for MKL-DNN cache size to prevent unlimited growth, while also allowing users to configure cache capacity.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;Updated default configurations for high-performance inference to support Paddle MKL-DNN acceleration and optimized the logic for automatic configuration selection for smarter choices.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;Adjusted the logic for obtaining the default device to consider the actual support for computing devices by the installed Paddle framework, making program behavior more intuitive.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;Added Android example for PP-OCRv5. &lt;a href="https://paddlepaddle.github.io/PaddleOCR/latest/en/version3.x/deployment/on_device_deployment.html"&gt;Details&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Bug Fixes:&lt;/strong&gt;&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Fixed an issue with some CLI parameters in PP-StructureV3 not taking effect.&lt;/li&gt; 
    &lt;li&gt;Resolved an issue where &lt;code&gt;export_paddlex_config_to_yaml&lt;/code&gt; would not function correctly in certain cases.&lt;/li&gt; 
    &lt;li&gt;Corrected the discrepancy between the actual behavior of &lt;code&gt;save_path&lt;/code&gt; and its documentation description.&lt;/li&gt; 
    &lt;li&gt;Fixed potential multithreading errors when using MKL-DNN in basic service deployment.&lt;/li&gt; 
    &lt;li&gt;Corrected channel order errors in image preprocessing for the Latex-OCR model.&lt;/li&gt; 
    &lt;li&gt;Fixed channel order errors in saving visualized images within the text recognition module.&lt;/li&gt; 
    &lt;li&gt;Resolved channel order errors in visualized table results within PP-StructureV3 pipeline.&lt;/li&gt; 
    &lt;li&gt;Fixed an overflow issue in the calculation of &lt;code&gt;overlap_ratio&lt;/code&gt; under extremely special circumstances in the PP-StructureV3 pipeline.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Documentation Improvements:&lt;/strong&gt;&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Updated the description of the &lt;code&gt;enable_mkldnn&lt;/code&gt; parameter in the documentation to accurately reflect the program's actual behavior.&lt;/li&gt; 
    &lt;li&gt;Fixed errors in the documentation regarding the &lt;code&gt;lang&lt;/code&gt; and &lt;code&gt;ocr_version&lt;/code&gt; parameters.&lt;/li&gt; 
    &lt;li&gt;Added instructions for exporting pipeline configuration files via CLI.&lt;/li&gt; 
    &lt;li&gt;Fixed missing columns in the performance data table for PP-OCRv5.&lt;/li&gt; 
    &lt;li&gt;Refined benchmark metrics for PP-StructureV3 across different configurations.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Others:&lt;/strong&gt;&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Relaxed version restrictions on dependencies like numpy and pandas, restoring support for Python 3.12.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;History Log&lt;/strong&gt;&lt;/summary&gt; 
 &lt;p&gt;2025.06.05: &lt;strong&gt;PaddleOCR 3.0.1 Released&lt;/strong&gt;, includes:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;Optimisation of certain models and model configurations:&lt;/strong&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Updated the default model configuration for PP-OCRv5, changing both detection and recognition from mobile to server models. To improve default performance in most scenarios, the parameter &lt;code&gt;limit_side_len&lt;/code&gt; in the configuration has been changed from 736 to 64.&lt;/li&gt; 
    &lt;li&gt;Added a new text line orientation classification model &lt;code&gt;PP-LCNet_x1_0_textline_ori&lt;/code&gt; with an accuracy of 99.42%. The default text line orientation classifier for OCR, PP-StructureV3, and PP-ChatOCRv4 pipelines has been updated to this model.&lt;/li&gt; 
    &lt;li&gt;Optimized the text line orientation classification model &lt;code&gt;PP-LCNet_x0_25_textline_ori&lt;/code&gt;, improving accuracy by 3.3 percentage points to a current accuracy of 98.85%.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Optimizations and fixes for some issues in version 3.0.0, &lt;a href="https://paddlepaddle.github.io/PaddleOCR/latest/en/update/update.html"&gt;details&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;🔥🔥2025.05.20: Official Release of &lt;strong&gt;PaddleOCR v3.0&lt;/strong&gt;, including:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;PP-OCRv5&lt;/strong&gt;: High-Accuracy Text Recognition Model for All Scenarios - Instant Text from Images/PDFs.&lt;/p&gt; 
   &lt;ol&gt; 
    &lt;li&gt;🌐 Single-model support for &lt;strong&gt;five&lt;/strong&gt; text types - Seamlessly process &lt;strong&gt;Simplified Chinese, Traditional Chinese, Simplified Chinese Pinyin, English&lt;/strong&gt; and &lt;strong&gt;Japanese&lt;/strong&gt; within a single model.&lt;/li&gt; 
    &lt;li&gt;✍️ Improved &lt;strong&gt;handwriting recognition&lt;/strong&gt;: Significantly better at complex cursive scripts and non-standard handwriting.&lt;/li&gt; 
    &lt;li&gt;🎯 &lt;strong&gt;13-point accuracy gain&lt;/strong&gt; over PP-OCRv4, achieving state-of-the-art performance across a variety of real-world scenarios.&lt;/li&gt; 
   &lt;/ol&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;PP-StructureV3&lt;/strong&gt;: General-Purpose Document Parsing – Unleash SOTA Images/PDFs Parsing for Real-World Scenarios!&lt;/p&gt; 
   &lt;ol&gt; 
    &lt;li&gt;🧮 &lt;strong&gt;High-Accuracy multi-scene PDF parsing&lt;/strong&gt;, leading both open- and closed-source solutions on the OmniDocBench benchmark.&lt;/li&gt; 
    &lt;li&gt;🧠 Specialized capabilities include &lt;strong&gt;seal recognition&lt;/strong&gt;, &lt;strong&gt;chart-to-table conversion&lt;/strong&gt;, &lt;strong&gt;table recognition with nested formulas/images&lt;/strong&gt;, &lt;strong&gt;vertical text document parsing&lt;/strong&gt;, and &lt;strong&gt;complex table structure analysis&lt;/strong&gt;.&lt;/li&gt; 
   &lt;/ol&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;PP-ChatOCRv4&lt;/strong&gt;: Intelligent Document Understanding – Extract Key Information, not just text from Images/PDFs.&lt;/p&gt; 
   &lt;ol&gt; 
    &lt;li&gt;🔥 &lt;strong&gt;15-point accuracy gain&lt;/strong&gt; in key-information extraction on PDF/PNG/JPG files over the previous generation.&lt;/li&gt; 
    &lt;li&gt;💻 Native support for &lt;strong&gt;ERNIE 4.5&lt;/strong&gt;, with compatibility for large-model deployments via PaddleNLP, Ollama, vLLM, and more.&lt;/li&gt; 
    &lt;li&gt;🤝 Integrated &lt;a href="https://github.com/PaddlePaddle/PaddleMIX/tree/develop/paddlemix/examples/ppdocbee2"&gt;PP-DocBee2&lt;/a&gt;, enabling extraction and understanding of printed text, handwriting, seals, tables, charts, and other common elements in complex documents.&lt;/li&gt; 
   &lt;/ol&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;a href="https://paddlepaddle.github.io/PaddleOCR/latest/en/update/update.html"&gt;History Log&lt;/a&gt;&lt;/p&gt; 
&lt;/details&gt; 
&lt;h2&gt;⚡ Quick Start&lt;/h2&gt; 
&lt;h3&gt;1. Run online demo&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://aistudio.baidu.com/community/app/91660/webUI"&gt;&lt;img src="https://img.shields.io/badge/PP_OCRv5-AI_Studio-green" alt="AI Studio" /&gt;&lt;/a&gt; &lt;a href="https://aistudio.baidu.com/community/app/518494/webUI"&gt;&lt;img src="https://img.shields.io/badge/PP_StructureV3-AI_Studio-green" alt="AI Studio" /&gt;&lt;/a&gt; &lt;a href="https://aistudio.baidu.com/community/app/518493/webUI"&gt;&lt;img src="https://img.shields.io/badge/PP_ChatOCRv4-AI_Studio-green" alt="AI Studio" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;2. Installation&lt;/h3&gt; 
&lt;p&gt;Install PaddlePaddle refer to &lt;a href="https://www.paddlepaddle.org.cn/en/install/quick?docurl=/documentation/docs/en/develop/install/pip/linux-pip_en.html"&gt;Installation Guide&lt;/a&gt;, after then, install the PaddleOCR toolkit.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# If you only want to use the basic text recognition feature (returns text position coordinates and content), including the PP-OCR series
python -m pip install paddleocr
# If you want to use all features such as document parsing, document understanding, document translation, key information extraction, etc.
# python -m pip install "paddleocr[all]"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Starting from version 3.2.0, in addition to the &lt;code&gt;all&lt;/code&gt; dependency group demonstrated above, PaddleOCR also supports installing partial optional features by specifying other dependency groups. All dependency groups provided by PaddleOCR are as follows:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Dependency Group Name&lt;/th&gt; 
   &lt;th&gt;Corresponding Functionality&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;doc-parser&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Document parsing: can be used to extract layout elements such as tables, formulas, stamps, images, etc. from documents; includes models like PP-StructureV3&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;ie&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Information extraction: can be used to extract key information from documents, such as names, dates, addresses, amounts, etc.; includes models like PP-ChatOCRv4&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;trans&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Document translation: can be used to translate documents from one language to another; includes models like PP-DocTranslation&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;all&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Complete functionality&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;3. Run inference by CLI&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Run PP-OCRv5 inference
paddleocr ocr -i https://paddle-model-ecology.bj.bcebos.com/paddlex/imgs/demo_image/general_ocr_002.png --use_doc_orientation_classify False --use_doc_unwarping False --use_textline_orientation False  

# Run PP-StructureV3 inference
paddleocr pp_structurev3 -i https://paddle-model-ecology.bj.bcebos.com/paddlex/imgs/demo_image/pp_structure_v3_demo.png --use_doc_orientation_classify False --use_doc_unwarping False

# Get the Qianfan API Key at first, and then run PP-ChatOCRv4 inference
paddleocr pp_chatocrv4_doc -i https://paddle-model-ecology.bj.bcebos.com/paddlex/imgs/demo_image/vehicle_certificate-1.png -k 驾驶室准乘人数 --qianfan_api_key your_api_key --use_doc_orientation_classify False --use_doc_unwarping False 

# Get more information about "paddleocr ocr"
paddleocr ocr --help
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;4. Run inference by API&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;4.1 PP-OCRv5 Example&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# Initialize PaddleOCR instance
from paddleocr import PaddleOCR
ocr = PaddleOCR(
    use_doc_orientation_classify=False,
    use_doc_unwarping=False,
    use_textline_orientation=False)

# Run OCR inference on a sample image 
result = ocr.predict(
    input="https://paddle-model-ecology.bj.bcebos.com/paddlex/imgs/demo_image/general_ocr_002.png")

# Visualize the results and save the JSON results
for res in result:
    res.print()
    res.save_to_img("output")
    res.save_to_json("output")
&lt;/code&gt;&lt;/pre&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;4.2 PP-StructureV3 Example&lt;/strong&gt;&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;from pathlib import Path
from paddleocr import PPStructureV3

pipeline = PPStructureV3(
    use_doc_orientation_classify=False,
    use_doc_unwarping=False
)

# For Image
output = pipeline.predict(
    input="https://paddle-model-ecology.bj.bcebos.com/paddlex/imgs/demo_image/pp_structure_v3_demo.png",
)

# Visualize the results and save the JSON results
for res in output:
    res.print() 
    res.save_to_json(save_path="output") 
    res.save_to_markdown(save_path="output")           
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;4.3 PP-ChatOCRv4 Example&lt;/strong&gt;&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;from paddleocr import PPChatOCRv4Doc

chat_bot_config = {
    "module_name": "chat_bot",
    "model_name": "ernie-3.5-8k",
    "base_url": "https://qianfan.baidubce.com/v2",
    "api_type": "openai",
    "api_key": "api_key",  # your api_key
}

retriever_config = {
    "module_name": "retriever",
    "model_name": "embedding-v1",
    "base_url": "https://qianfan.baidubce.com/v2",
    "api_type": "qianfan",
    "api_key": "api_key",  # your api_key
}

pipeline = PPChatOCRv4Doc(
    use_doc_orientation_classify=False,
    use_doc_unwarping=False
)

visual_predict_res = pipeline.visual_predict(
    input="https://paddle-model-ecology.bj.bcebos.com/paddlex/imgs/demo_image/vehicle_certificate-1.png",
    use_common_ocr=True,
    use_seal_recognition=True,
    use_table_recognition=True,
)

mllm_predict_info = None
use_mllm = False
# If a multimodal large model is used, the local mllm service needs to be started. You can refer to the documentation: https://github.com/PaddlePaddle/PaddleX/blob/release/3.0/docs/pipeline_usage/tutorials/vlm_pipelines/doc_understanding.en.md performs deployment and updates the mllm_chat_bot_config configuration.
if use_mllm:
    mllm_chat_bot_config = {
        "module_name": "chat_bot",
        "model_name": "PP-DocBee",
        "base_url": "http://127.0.0.1:8080/",  # your local mllm service url
        "api_type": "openai",
        "api_key": "api_key",  # your api_key
    }

    mllm_predict_res = pipeline.mllm_pred(
        input="https://paddle-model-ecology.bj.bcebos.com/paddlex/imgs/demo_image/vehicle_certificate-1.png",
        key_list=["驾驶室准乘人数"],
        mllm_chat_bot_config=mllm_chat_bot_config,
    )
    mllm_predict_info = mllm_predict_res["mllm_res"]

visual_info_list = []
for res in visual_predict_res:
    visual_info_list.append(res["visual_info"])
    layout_parsing_result = res["layout_parsing_result"]

vector_info = pipeline.build_vector(
    visual_info_list, flag_save_bytes_vector=True, retriever_config=retriever_config
)
chat_result = pipeline.chat(
    key_list=["驾驶室准乘人数"],
    visual_info=visual_info_list,
    vector_info=vector_info,
    mllm_predict_info=mllm_predict_info,
    chat_bot_config=chat_bot_config,
    retriever_config=retriever_config,
)
print(chat_result)
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h3&gt;5. Chinese Heterogeneous AI Accelerators&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://paddlepaddle.github.io/PaddleOCR/latest/version3.x/other_devices_support/paddlepaddle_install_NPU.html"&gt;Huawei Ascend&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://paddlepaddle.github.io/PaddleOCR/latest/version3.x/other_devices_support/paddlepaddle_install_XPU.html"&gt;KUNLUNXIN&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;🧩 More Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Convert models to ONNX format: &lt;a href="https://paddlepaddle.github.io/PaddleOCR/latest/en/version3.x/deployment/obtaining_onnx_models.html"&gt;Obtaining ONNX Models&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Accelerate inference using engines like OpenVINO, ONNX Runtime, TensorRT, or perform inference using ONNX format models: &lt;a href="https://paddlepaddle.github.io/PaddleOCR/latest/en/version3.x/deployment/high_performance_inference.html"&gt;High-Performance Inference&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Accelerate inference using multi-GPU and multi-process: &lt;a href="https://paddlepaddle.github.io/PaddleOCR/latest/en/version3.x/pipeline_usage/instructions/parallel_inference.html"&gt;Parallel Inference for Pipelines&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Integrate PaddleOCR into applications written in C++, C#, Java, etc.: &lt;a href="https://paddlepaddle.github.io/PaddleOCR/latest/en/version3.x/deployment/serving.html"&gt;Serving&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;⛰️ Advanced Tutorials&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://paddlepaddle.github.io/PaddleOCR/latest/version3.x/pipeline_usage/OCR.html"&gt;PP-OCRv5 Tutorial&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://paddlepaddle.github.io/PaddleOCR/latest/version3.x/pipeline_usage/PP-StructureV3.html"&gt;PP-StructureV3 Tutorial&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://paddlepaddle.github.io/PaddleOCR/latest/version3.x/pipeline_usage/PP-ChatOCRv4.html"&gt;PP-ChatOCRv4 Tutorial&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;🔄 Quick Overview of Execution Results&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt; &lt;img width="100%" src="https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/main/docs/images/demo.gif" alt="PP-OCRv5 Demo" /&gt; &lt;/p&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt; &lt;img width="100%" src="https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/main/docs/images/blue_v3.gif" alt="PP-StructureV3 Demo" /&gt; &lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;✨ Stay Tuned&lt;/h2&gt; 
&lt;p&gt;⭐ &lt;strong&gt;Star this repository to keep up with exciting updates and new releases, including powerful OCR and document parsing capabilities!&lt;/strong&gt; ⭐&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt; &lt;img width="1200" src="https://raw.githubusercontent.com/cuicheng01/PaddleX_doc_images/main/images/paddleocr/README/star_paddleocr.en.gif" alt="Star-Project" /&gt; &lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;👩‍👩‍👧‍👦 Community&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th align="center"&gt;PaddlePaddle WeChat official account&lt;/th&gt; 
    &lt;th align="center"&gt;Join the tech discussion group&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;&lt;img src="https://raw.githubusercontent.com/cuicheng01/PaddleX_doc_images/refs/heads/main/images/paddleocr/README/qrcode_for_paddlepaddle_official_account.jpg" width="150" /&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;img src="https://raw.githubusercontent.com/cuicheng01/PaddleX_doc_images/refs/heads/main/images/paddleocr/README/qr_code_for_the_questionnaire.jpg" width="150" /&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/div&gt; 
&lt;h2&gt;😃 Awesome Projects Leveraging PaddleOCR&lt;/h2&gt; 
&lt;p&gt;PaddleOCR wouldn't be where it is today without its incredible community! 💗 A massive thank you to all our longtime partners, new collaborators, and everyone who's poured their passion into PaddleOCR — whether we've named you or not. Your support fuels our fire!&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;Project Name&lt;/th&gt; 
    &lt;th&gt;Description&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://github.com/infiniflow/ragflow"&gt;RAGFlow&lt;/a&gt; &lt;a href="https://github.com/infiniflow/ragflow"&gt;&lt;img src="https://img.shields.io/github/stars/infiniflow/ragflow" /&gt;&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;RAG engine based on deep document understanding.&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://github.com/opendatalab/MinerU"&gt;MinerU&lt;/a&gt; &lt;a href="https://github.com/opendatalab/MinerU"&gt;&lt;img src="https://img.shields.io/github/stars/opendatalab/MinerU" /&gt;&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;Multi-type Document to Markdown Conversion Tool&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://github.com/hiroi-sora/Umi-OCR"&gt;Umi-OCR&lt;/a&gt; &lt;a href="https://github.com/hiroi-sora/Umi-OCR"&gt;&lt;img src="https://img.shields.io/github/stars/hiroi-sora/Umi-OCR" /&gt;&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;Free, Open-source, Batch Offline OCR Software.&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://github.com/microsoft/OmniParser"&gt;OmniParser&lt;/a&gt;&lt;a href="https://github.com/microsoft/OmniParser"&gt;&lt;img src="https://img.shields.io/github/stars/microsoft/OmniParser" /&gt;&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;OmniParser: Screen Parsing tool for Pure Vision Based GUI Agent.&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://github.com/netease-youdao/QAnything"&gt;QAnything&lt;/a&gt;&lt;a href="https://github.com/netease-youdao/QAnything"&gt;&lt;img src="https://img.shields.io/github/stars/netease-youdao/QAnything" /&gt;&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;Question and Answer based on Anything.&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://github.com/opendatalab/PDF-Extract-Kit"&gt;PDF-Extract-Kit&lt;/a&gt; &lt;a href="https://github.com/opendatalab/PDF-Extract-Kit"&gt;&lt;img src="https://img.shields.io/github/stars/opendatalab/PDF-Extract-Kit" /&gt;&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;A powerful open-source toolkit designed to efficiently extract high-quality content from complex and diverse PDF documents.&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://github.com/PantsuDango/Dango-Translator"&gt;Dango-Translator&lt;/a&gt;&lt;a href="https://github.com/PantsuDango/Dango-Translator"&gt;&lt;img src="https://img.shields.io/github/stars/PantsuDango/Dango-Translator" /&gt;&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;Recognize text on the screen, translate it and show the translation results in real time.&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/main/awesome_projects.md"&gt;Learn more projects&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/main/awesome_projects.md"&gt;More projects based on PaddleOCR&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/div&gt; 
&lt;h2&gt;👩‍👩‍👧‍👦 Contributors&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://github.com/PaddlePaddle/PaddleOCR/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=PaddlePaddle/PaddleOCR&amp;amp;max=400&amp;amp;columns=20" width="800" /&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;h2&gt;🌟 Star&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt; &lt;img width="800" src="https://api.star-history.com/svg?repos=PaddlePaddle/PaddleOCR&amp;amp;type=Date" alt="Star-history" /&gt; &lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;📄 License&lt;/h2&gt; 
&lt;p&gt;This project is released under the &lt;a href="https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/main/LICENSE"&gt;Apache 2.0 license&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;🎓 Citation&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;@misc{cui2025paddleocr30technicalreport,
      title={PaddleOCR 3.0 Technical Report}, 
      author={Cheng Cui and Ting Sun and Manhui Lin and Tingquan Gao and Yubo Zhang and Jiaxuan Liu and Xueqing Wang and Zelun Zhang and Changda Zhou and Hongen Liu and Yue Zhang and Wenyu Lv and Kui Huang and Yichao Zhang and Jing Zhang and Jun Zhang and Yi Liu and Dianhai Yu and Yanjun Ma},
      year={2025},
      eprint={2507.05595},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2507.05595}, 
}
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>karpathy/nanoGPT</title>
      <link>https://github.com/karpathy/nanoGPT</link>
      <description>&lt;p&gt;The simplest, fastest repository for training/finetuning medium-sized GPTs.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;nanoGPT&lt;/h1&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/karpathy/nanoGPT/master/assets/nanogpt.jpg" alt="nanoGPT" /&gt;&lt;/p&gt; 
&lt;p&gt;The simplest, fastest repository for training/finetuning medium-sized GPTs. It is a rewrite of &lt;a href="https://github.com/karpathy/minGPT"&gt;minGPT&lt;/a&gt; that prioritizes teeth over education. Still under active development, but currently the file &lt;code&gt;train.py&lt;/code&gt; reproduces GPT-2 (124M) on OpenWebText, running on a single 8XA100 40GB node in about 4 days of training. The code itself is plain and readable: &lt;code&gt;train.py&lt;/code&gt; is a ~300-line boilerplate training loop and &lt;code&gt;model.py&lt;/code&gt; a ~300-line GPT model definition, which can optionally load the GPT-2 weights from OpenAI. That's it.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/karpathy/nanoGPT/master/assets/gpt2_124M_loss.png" alt="repro124m" /&gt;&lt;/p&gt; 
&lt;p&gt;Because the code is so simple, it is very easy to hack to your needs, train new models from scratch, or finetune pretrained checkpoints (e.g. biggest one currently available as a starting point would be the GPT-2 1.3B model from OpenAI).&lt;/p&gt; 
&lt;h2&gt;install&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;pip install torch numpy transformers datasets tiktoken wandb tqdm
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Dependencies:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://pytorch.org"&gt;pytorch&lt;/a&gt; &amp;lt;3&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://numpy.org/install/"&gt;numpy&lt;/a&gt; &amp;lt;3&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;transformers&lt;/code&gt; for huggingface transformers &amp;lt;3 (to load GPT-2 checkpoints)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;datasets&lt;/code&gt; for huggingface datasets &amp;lt;3 (if you want to download + preprocess OpenWebText)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;tiktoken&lt;/code&gt; for OpenAI's fast BPE code &amp;lt;3&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;wandb&lt;/code&gt; for optional logging &amp;lt;3&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;tqdm&lt;/code&gt; for progress bars &amp;lt;3&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;quick start&lt;/h2&gt; 
&lt;p&gt;If you are not a deep learning professional and you just want to feel the magic and get your feet wet, the fastest way to get started is to train a character-level GPT on the works of Shakespeare. First, we download it as a single (1MB) file and turn it from raw text into one large stream of integers:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;python data/shakespeare_char/prepare.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This creates a &lt;code&gt;train.bin&lt;/code&gt; and &lt;code&gt;val.bin&lt;/code&gt; in that data directory. Now it is time to train your GPT. The size of it very much depends on the computational resources of your system:&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;I have a GPU&lt;/strong&gt;. Great, we can quickly train a baby GPT with the settings provided in the &lt;a href="https://raw.githubusercontent.com/karpathy/nanoGPT/master/config/train_shakespeare_char.py"&gt;config/train_shakespeare_char.py&lt;/a&gt; config file:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;python train.py config/train_shakespeare_char.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you peek inside it, you'll see that we're training a GPT with a context size of up to 256 characters, 384 feature channels, and it is a 6-layer Transformer with 6 heads in each layer. On one A100 GPU this training run takes about 3 minutes and the best validation loss is 1.4697. Based on the configuration, the model checkpoints are being written into the &lt;code&gt;--out_dir&lt;/code&gt; directory &lt;code&gt;out-shakespeare-char&lt;/code&gt;. So once the training finishes we can sample from the best model by pointing the sampling script at this directory:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;python sample.py --out_dir=out-shakespeare-char
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This generates a few samples, for example:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;ANGELO:
And cowards it be strawn to my bed,
And thrust the gates of my threats,
Because he that ale away, and hang'd
An one with him.

DUKE VINCENTIO:
I thank your eyes against it.

DUKE VINCENTIO:
Then will answer him to save the malm:
And what have you tyrannous shall do this?

DUKE VINCENTIO:
If you have done evils of all disposition
To end his power, the day of thrust for a common men
That I leave, to fight with over-liking
Hasting in a roseman.
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;lol &lt;code&gt;¯\_(ツ)_/¯&lt;/code&gt;. Not bad for a character-level model after 3 minutes of training on a GPU. Better results are quite likely obtainable by instead finetuning a pretrained GPT-2 model on this dataset (see finetuning section later).&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;I only have a macbook&lt;/strong&gt; (or other cheap computer). No worries, we can still train a GPT but we want to dial things down a notch. I recommend getting the bleeding edge PyTorch nightly (&lt;a href="https://pytorch.org/get-started/locally/"&gt;select it here&lt;/a&gt; when installing) as it is currently quite likely to make your code more efficient. But even without it, a simple train run could look as follows:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;python train.py config/train_shakespeare_char.py --device=cpu --compile=False --eval_iters=20 --log_interval=1 --block_size=64 --batch_size=12 --n_layer=4 --n_head=4 --n_embd=128 --max_iters=2000 --lr_decay_iters=2000 --dropout=0.0
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Here, since we are running on CPU instead of GPU we must set both &lt;code&gt;--device=cpu&lt;/code&gt; and also turn off PyTorch 2.0 compile with &lt;code&gt;--compile=False&lt;/code&gt;. Then when we evaluate we get a bit more noisy but faster estimate (&lt;code&gt;--eval_iters=20&lt;/code&gt;, down from 200), our context size is only 64 characters instead of 256, and the batch size only 12 examples per iteration, not 64. We'll also use a much smaller Transformer (4 layers, 4 heads, 128 embedding size), and decrease the number of iterations to 2000 (and correspondingly usually decay the learning rate to around max_iters with &lt;code&gt;--lr_decay_iters&lt;/code&gt;). Because our network is so small we also ease down on regularization (&lt;code&gt;--dropout=0.0&lt;/code&gt;). This still runs in about ~3 minutes, but gets us a loss of only 1.88 and therefore also worse samples, but it's still good fun:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;python sample.py --out_dir=out-shakespeare-char --device=cpu
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Generates samples like this:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;GLEORKEN VINGHARD III:
Whell's the couse, the came light gacks,
And the for mought you in Aut fries the not high shee
bot thou the sought bechive in that to doth groan you,
No relving thee post mose the wear
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Not bad for ~3 minutes on a CPU, for a hint of the right character gestalt. If you're willing to wait longer, feel free to tune the hyperparameters, increase the size of the network, the context length (&lt;code&gt;--block_size&lt;/code&gt;), the length of training, etc.&lt;/p&gt; 
&lt;p&gt;Finally, on Apple Silicon Macbooks and with a recent PyTorch version make sure to add &lt;code&gt;--device=mps&lt;/code&gt; (short for "Metal Performance Shaders"); PyTorch then uses the on-chip GPU that can &lt;em&gt;significantly&lt;/em&gt; accelerate training (2-3X) and allow you to use larger networks. See &lt;a href="https://github.com/karpathy/nanoGPT/issues/28"&gt;Issue 28&lt;/a&gt; for more.&lt;/p&gt; 
&lt;h2&gt;reproducing GPT-2&lt;/h2&gt; 
&lt;p&gt;A more serious deep learning professional may be more interested in reproducing GPT-2 results. So here we go - we first tokenize the dataset, in this case the &lt;a href="https://openwebtext2.readthedocs.io/en/latest/"&gt;OpenWebText&lt;/a&gt;, an open reproduction of OpenAI's (private) WebText:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;python data/openwebtext/prepare.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This downloads and tokenizes the &lt;a href="https://huggingface.co/datasets/openwebtext"&gt;OpenWebText&lt;/a&gt; dataset. It will create a &lt;code&gt;train.bin&lt;/code&gt; and &lt;code&gt;val.bin&lt;/code&gt; which holds the GPT2 BPE token ids in one sequence, stored as raw uint16 bytes. Then we're ready to kick off training. To reproduce GPT-2 (124M) you'll want at least an 8X A100 40GB node and run:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;torchrun --standalone --nproc_per_node=8 train.py config/train_gpt2.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This will run for about 4 days using PyTorch Distributed Data Parallel (DDP) and go down to loss of ~2.85. Now, a GPT-2 model just evaluated on OWT gets a val loss of about 3.11, but if you finetune it it will come down to ~2.85 territory (due to an apparent domain gap), making the two models ~match.&lt;/p&gt; 
&lt;p&gt;If you're in a cluster environment and you are blessed with multiple GPU nodes you can make GPU go brrrr e.g. across 2 nodes like:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;# Run on the first (master) node with example IP 123.456.123.456:
torchrun --nproc_per_node=8 --nnodes=2 --node_rank=0 --master_addr=123.456.123.456 --master_port=1234 train.py
# Run on the worker node:
torchrun --nproc_per_node=8 --nnodes=2 --node_rank=1 --master_addr=123.456.123.456 --master_port=1234 train.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;It is a good idea to benchmark your interconnect (e.g. iperf3). In particular, if you don't have Infiniband then also prepend &lt;code&gt;NCCL_IB_DISABLE=1&lt;/code&gt; to the above launches. Your multinode training will work, but most likely &lt;em&gt;crawl&lt;/em&gt;. By default checkpoints are periodically written to the &lt;code&gt;--out_dir&lt;/code&gt;. We can sample from the model by simply &lt;code&gt;python sample.py&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Finally, to train on a single GPU simply run the &lt;code&gt;python train.py&lt;/code&gt; script. Have a look at all of its args, the script tries to be very readable, hackable and transparent. You'll most likely want to tune a number of those variables depending on your needs.&lt;/p&gt; 
&lt;h2&gt;baselines&lt;/h2&gt; 
&lt;p&gt;OpenAI GPT-2 checkpoints allow us to get some baselines in place for openwebtext. We can get the numbers as follows:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;$ python train.py config/eval_gpt2.py
$ python train.py config/eval_gpt2_medium.py
$ python train.py config/eval_gpt2_large.py
$ python train.py config/eval_gpt2_xl.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;and observe the following losses on train and val:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;model&lt;/th&gt; 
   &lt;th&gt;params&lt;/th&gt; 
   &lt;th&gt;train loss&lt;/th&gt; 
   &lt;th&gt;val loss&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;gpt2&lt;/td&gt; 
   &lt;td&gt;124M&lt;/td&gt; 
   &lt;td&gt;3.11&lt;/td&gt; 
   &lt;td&gt;3.12&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;gpt2-medium&lt;/td&gt; 
   &lt;td&gt;350M&lt;/td&gt; 
   &lt;td&gt;2.85&lt;/td&gt; 
   &lt;td&gt;2.84&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;gpt2-large&lt;/td&gt; 
   &lt;td&gt;774M&lt;/td&gt; 
   &lt;td&gt;2.66&lt;/td&gt; 
   &lt;td&gt;2.67&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;gpt2-xl&lt;/td&gt; 
   &lt;td&gt;1558M&lt;/td&gt; 
   &lt;td&gt;2.56&lt;/td&gt; 
   &lt;td&gt;2.54&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;However, we have to note that GPT-2 was trained on (closed, never released) WebText, while OpenWebText is just a best-effort open reproduction of this dataset. This means there is a dataset domain gap. Indeed, taking the GPT-2 (124M) checkpoint and finetuning on OWT directly for a while reaches loss down to ~2.85. This then becomes the more appropriate baseline w.r.t. reproduction.&lt;/p&gt; 
&lt;h2&gt;finetuning&lt;/h2&gt; 
&lt;p&gt;Finetuning is no different than training, we just make sure to initialize from a pretrained model and train with a smaller learning rate. For an example of how to finetune a GPT on new text go to &lt;code&gt;data/shakespeare&lt;/code&gt; and run &lt;code&gt;prepare.py&lt;/code&gt; to download the tiny shakespeare dataset and render it into a &lt;code&gt;train.bin&lt;/code&gt; and &lt;code&gt;val.bin&lt;/code&gt;, using the OpenAI BPE tokenizer from GPT-2. Unlike OpenWebText this will run in seconds. Finetuning can take very little time, e.g. on a single GPU just a few minutes. Run an example finetuning like:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;python train.py config/finetune_shakespeare.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This will load the config parameter overrides in &lt;code&gt;config/finetune_shakespeare.py&lt;/code&gt; (I didn't tune them much though). Basically, we initialize from a GPT2 checkpoint with &lt;code&gt;init_from&lt;/code&gt; and train as normal, except shorter and with a small learning rate. If you're running out of memory try decreasing the model size (they are &lt;code&gt;{'gpt2', 'gpt2-medium', 'gpt2-large', 'gpt2-xl'}&lt;/code&gt;) or possibly decreasing the &lt;code&gt;block_size&lt;/code&gt; (context length). The best checkpoint (lowest validation loss) will be in the &lt;code&gt;out_dir&lt;/code&gt; directory, e.g. in &lt;code&gt;out-shakespeare&lt;/code&gt; by default, per the config file. You can then run the code in &lt;code&gt;sample.py --out_dir=out-shakespeare&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;THEODORE:
Thou shalt sell me to the highest bidder: if I die,
I sell thee to the first; if I go mad,
I sell thee to the second; if I
lie, I sell thee to the third; if I slay,
I sell thee to the fourth: so buy or sell,
I tell thee again, thou shalt not sell my
possession.

JULIET:
And if thou steal, thou shalt not sell thyself.

THEODORE:
I do not steal; I sell the stolen goods.

THEODORE:
Thou know'st not what thou sell'st; thou, a woman,
Thou art ever a victim, a thing of no worth:
Thou hast no right, no right, but to be sold.
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Whoa there, GPT, entering some dark place over there. I didn't really tune the hyperparameters in the config too much, feel free to try!&lt;/p&gt; 
&lt;h2&gt;sampling / inference&lt;/h2&gt; 
&lt;p&gt;Use the script &lt;code&gt;sample.py&lt;/code&gt; to sample either from pre-trained GPT-2 models released by OpenAI, or from a model you trained yourself. For example, here is a way to sample from the largest available &lt;code&gt;gpt2-xl&lt;/code&gt; model:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;python sample.py \
    --init_from=gpt2-xl \
    --start="What is the answer to life, the universe, and everything?" \
    --num_samples=5 --max_new_tokens=100
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you'd like to sample from a model you trained, use the &lt;code&gt;--out_dir&lt;/code&gt; to point the code appropriately. You can also prompt the model with some text from a file, e.g. &lt;code&gt;python sample.py --start=FILE:prompt.txt&lt;/code&gt;.&lt;/p&gt; 
&lt;h2&gt;efficiency notes&lt;/h2&gt; 
&lt;p&gt;For simple model benchmarking and profiling, &lt;code&gt;bench.py&lt;/code&gt; might be useful. It's identical to what happens in the meat of the training loop of &lt;code&gt;train.py&lt;/code&gt;, but omits much of the other complexities.&lt;/p&gt; 
&lt;p&gt;Note that the code by default uses &lt;a href="https://pytorch.org/get-started/pytorch-2.0/"&gt;PyTorch 2.0&lt;/a&gt;. At the time of writing (Dec 29, 2022) this makes &lt;code&gt;torch.compile()&lt;/code&gt; available in the nightly release. The improvement from the one line of code is noticeable, e.g. cutting down iteration time from ~250ms / iter to 135ms / iter. Nice work PyTorch team!&lt;/p&gt; 
&lt;h2&gt;todos&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Investigate and add FSDP instead of DDP&lt;/li&gt; 
 &lt;li&gt;Eval zero-shot perplexities on standard evals (e.g. LAMBADA? HELM? etc.)&lt;/li&gt; 
 &lt;li&gt;Finetune the finetuning script, I think the hyperparams are not great&lt;/li&gt; 
 &lt;li&gt;Schedule for linear batch size increase during training&lt;/li&gt; 
 &lt;li&gt;Incorporate other embeddings (rotary, alibi)&lt;/li&gt; 
 &lt;li&gt;Separate out the optim buffers from model params in checkpoints I think&lt;/li&gt; 
 &lt;li&gt;Additional logging around network health (e.g. gradient clip events, magnitudes)&lt;/li&gt; 
 &lt;li&gt;Few more investigations around better init etc.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;troubleshooting&lt;/h2&gt; 
&lt;p&gt;Note that by default this repo uses PyTorch 2.0 (i.e. &lt;code&gt;torch.compile&lt;/code&gt;). This is fairly new and experimental, and not yet available on all platforms (e.g. Windows). If you're running into related error messages try to disable this by adding &lt;code&gt;--compile=False&lt;/code&gt; flag. This will slow down the code but at least it will run.&lt;/p&gt; 
&lt;p&gt;For some context on this repository, GPT, and language modeling it might be helpful to watch my &lt;a href="https://karpathy.ai/zero-to-hero.html"&gt;Zero To Hero series&lt;/a&gt;. Specifically, the &lt;a href="https://www.youtube.com/watch?v=kCc8FmEb1nY"&gt;GPT video&lt;/a&gt; is popular if you have some prior language modeling context.&lt;/p&gt; 
&lt;p&gt;For more questions/discussions feel free to stop by &lt;strong&gt;#nanoGPT&lt;/strong&gt; on Discord:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://discord.gg/3zy8kqD9Cp"&gt;&lt;img src="https://dcbadge.vercel.app/api/server/3zy8kqD9Cp?compact=true&amp;amp;style=flat" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;acknowledgements&lt;/h2&gt; 
&lt;p&gt;All nanoGPT experiments are powered by GPUs on &lt;a href="https://lambdalabs.com"&gt;Lambda labs&lt;/a&gt;, my favorite Cloud GPU provider. Thank you Lambda labs for sponsoring nanoGPT!&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>ahujasid/blender-mcp</title>
      <link>https://github.com/ahujasid/blender-mcp</link>
      <description>&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;BlenderMCP - Blender Model Context Protocol Integration&lt;/h1&gt; 
&lt;p&gt;BlenderMCP connects Blender to Claude AI through the Model Context Protocol (MCP), allowing Claude to directly interact with and control Blender. This integration enables prompt assisted 3D modeling, scene creation, and manipulation.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;We have no official website. Any website you see online is unofficial and has no affiliation with this project. Use them at your own risk.&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=lCyQ717DuzQ"&gt;Full tutorial&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Join the Community&lt;/h3&gt; 
&lt;p&gt;Give feedback, get inspired, and build on top of the MCP: &lt;a href="https://discord.gg/z5apgR8TFU"&gt;Discord&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Supporters&lt;/h3&gt; 
&lt;div align="center" markdown="1"&gt; 
 &lt;sup&gt;Special thanks to:&lt;/sup&gt; 
 &lt;br /&gt; 
 &lt;br /&gt; 
 &lt;a href="https://www.warp.dev/blender-mcp"&gt; &lt;img alt="Warp sponsorship" width="400" src="https://github.com/user-attachments/assets/c21102f7-bab9-4344-a731-0cf6b341cab2" /&gt; &lt;/a&gt; 
 &lt;h3&gt;&lt;a href="https://www.warp.dev/blender-mcp"&gt;Warp, the intelligent terminal for developers&lt;/a&gt;&lt;/h3&gt; 
 &lt;p&gt;&lt;a href="https://www.warp.dev/blender-mcp"&gt;Available for MacOS, Linux, &amp;amp; Windows&lt;/a&gt;&lt;br /&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;strong&gt;Other supporters:&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.coderabbit.ai/"&gt;CodeRabbit&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/satishgoda"&gt;Satish Goda&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;All supporters:&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/sponsors/ahujasid"&gt;Support this project&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Release notes (1.2.0)&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;View screenshots for Blender viewport to better understand the scene&lt;/li&gt; 
 &lt;li&gt;Search and download Sketchfab models&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Previously added features:&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Support for Poly Haven assets through their API&lt;/li&gt; 
 &lt;li&gt;Support to generate 3D models using Hyper3D Rodin&lt;/li&gt; 
 &lt;li&gt;For newcomers, you can go straight to Installation. For existing users, see the points below&lt;/li&gt; 
 &lt;li&gt;Download the latest addon.py file and replace the older one, then add it to Blender&lt;/li&gt; 
 &lt;li&gt;Delete the MCP server from Claude and add it back again, and you should be good to go!&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Two-way communication&lt;/strong&gt;: Connect Claude AI to Blender through a socket-based server&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Object manipulation&lt;/strong&gt;: Create, modify, and delete 3D objects in Blender&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Material control&lt;/strong&gt;: Apply and modify materials and colors&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Scene inspection&lt;/strong&gt;: Get detailed information about the current Blender scene&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Code execution&lt;/strong&gt;: Run arbitrary Python code in Blender from Claude&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Components&lt;/h2&gt; 
&lt;p&gt;The system consists of two main components:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Blender Addon (&lt;code&gt;addon.py&lt;/code&gt;)&lt;/strong&gt;: A Blender addon that creates a socket server within Blender to receive and execute commands&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;MCP Server (&lt;code&gt;src/blender_mcp/server.py&lt;/code&gt;)&lt;/strong&gt;: A Python server that implements the Model Context Protocol and connects to the Blender addon&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;h3&gt;Prerequisites&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Blender 3.0 or newer&lt;/li&gt; 
 &lt;li&gt;Python 3.10 or newer&lt;/li&gt; 
 &lt;li&gt;uv package manager:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;If you're on Mac, please install uv as&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;brew install uv
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;On Windows&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;powershell -c "irm https://astral.sh/uv/install.ps1 | iex" 
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;and then&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;set Path=C:\Users\nntra\.local\bin;%Path%
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Otherwise installation instructions are on their website: &lt;a href="https://docs.astral.sh/uv/getting-started/installation/"&gt;Install uv&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;⚠️ Do not proceed before installing UV&lt;/strong&gt;&lt;/p&gt; 
&lt;h3&gt;Environment Variables&lt;/h3&gt; 
&lt;p&gt;The following environment variables can be used to configure the Blender connection:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;BLENDER_HOST&lt;/code&gt;: Host address for Blender socket server (default: "localhost")&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;BLENDER_PORT&lt;/code&gt;: Port number for Blender socket server (default: 9876)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;export BLENDER_HOST='host.docker.internal'
export BLENDER_PORT=9876
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Claude for Desktop Integration&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=neoK_WMq92g"&gt;Watch the setup instruction video&lt;/a&gt; (Assuming you have already installed uv)&lt;/p&gt; 
&lt;p&gt;Go to Claude &amp;gt; Settings &amp;gt; Developer &amp;gt; Edit Config &amp;gt; claude_desktop_config.json to include the following:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
    "mcpServers": {
        "blender": {
            "command": "uvx",
            "args": [
                "blender-mcp"
            ]
        }
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Cursor integration&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://cursor.com/install-mcp?name=blender&amp;amp;config=eyJjb21tYW5kIjoidXZ4IGJsZW5kZXItbWNwIn0%3D"&gt;&lt;img src="https://cursor.com/deeplink/mcp-install-dark.svg?sanitize=true" alt="Install MCP Server" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;For Mac users, go to Settings &amp;gt; MCP and paste the following&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;To use as a global server, use "add new global MCP server" button and paste&lt;/li&gt; 
 &lt;li&gt;To use as a project specific server, create &lt;code&gt;.cursor/mcp.json&lt;/code&gt; in the root of the project and paste&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
    "mcpServers": {
        "blender": {
            "command": "uvx",
            "args": [
                "blender-mcp"
            ]
        }
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For Windows users, go to Settings &amp;gt; MCP &amp;gt; Add Server, add a new server with the following settings:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
    "mcpServers": {
        "blender": {
            "command": "cmd",
            "args": [
                "/c",
                "uvx",
                "blender-mcp"
            ]
        }
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=wgWsJshecac"&gt;Cursor setup video&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;⚠️ Only run one instance of the MCP server (either on Cursor or Claude Desktop), not both&lt;/strong&gt;&lt;/p&gt; 
&lt;h3&gt;Visual Studio Code Integration&lt;/h3&gt; 
&lt;p&gt;&lt;em&gt;Prerequisites&lt;/em&gt;: Make sure you have &lt;a href="https://code.visualstudio.com/"&gt;Visual Studio Code&lt;/a&gt; installed before proceeding.&lt;/p&gt; 
&lt;p&gt;&lt;a href="vscode:mcp/install?%7B%22name%22%3A%22blender-mcp%22%2C%22type%22%3A%22stdio%22%2C%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22blender-mcp%22%5D%7D"&gt;&lt;img src="https://img.shields.io/badge/VS_Code-Install_blender--mcp_server-0098FF?style=flat-square&amp;amp;logo=visualstudiocode&amp;amp;logoColor=ffffff" alt="Install in VS Code" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Installing the Blender Addon&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Download the &lt;code&gt;addon.py&lt;/code&gt; file from this repo&lt;/li&gt; 
 &lt;li&gt;Open Blender&lt;/li&gt; 
 &lt;li&gt;Go to Edit &amp;gt; Preferences &amp;gt; Add-ons&lt;/li&gt; 
 &lt;li&gt;Click "Install..." and select the &lt;code&gt;addon.py&lt;/code&gt; file&lt;/li&gt; 
 &lt;li&gt;Enable the addon by checking the box next to "Interface: Blender MCP"&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;h3&gt;Starting the Connection&lt;/h3&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/ahujasid/blender-mcp/main/assets/addon-instructions.png" alt="BlenderMCP in the sidebar" /&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;In Blender, go to the 3D View sidebar (press N if not visible)&lt;/li&gt; 
 &lt;li&gt;Find the "BlenderMCP" tab&lt;/li&gt; 
 &lt;li&gt;Turn on the Poly Haven checkbox if you want assets from their API (optional)&lt;/li&gt; 
 &lt;li&gt;Click "Connect to Claude"&lt;/li&gt; 
 &lt;li&gt;Make sure the MCP server is running in your terminal&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Using with Claude&lt;/h3&gt; 
&lt;p&gt;Once the config file has been set on Claude, and the addon is running on Blender, you will see a hammer icon with tools for the Blender MCP.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/ahujasid/blender-mcp/main/assets/hammer-icon.png" alt="BlenderMCP in the sidebar" /&gt;&lt;/p&gt; 
&lt;h4&gt;Capabilities&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Get scene and object information&lt;/li&gt; 
 &lt;li&gt;Create, delete and modify shapes&lt;/li&gt; 
 &lt;li&gt;Apply or create materials for objects&lt;/li&gt; 
 &lt;li&gt;Execute any Python code in Blender&lt;/li&gt; 
 &lt;li&gt;Download the right models, assets and HDRIs through &lt;a href="https://polyhaven.com/"&gt;Poly Haven&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;AI generated 3D models through &lt;a href="https://hyper3d.ai/"&gt;Hyper3D Rodin&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Example Commands&lt;/h3&gt; 
&lt;p&gt;Here are some examples of what you can ask Claude to do:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;"Create a low poly scene in a dungeon, with a dragon guarding a pot of gold" &lt;a href="https://www.youtube.com/watch?v=DqgKuLYUv00"&gt;Demo&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;"Create a beach vibe using HDRIs, textures, and models like rocks and vegetation from Poly Haven" &lt;a href="https://www.youtube.com/watch?v=I29rn92gkC4"&gt;Demo&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Give a reference image, and create a Blender scene out of it &lt;a href="https://www.youtube.com/watch?v=FDRb03XPiRo"&gt;Demo&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;"Generate a 3D model of a garden gnome through Hyper3D"&lt;/li&gt; 
 &lt;li&gt;"Get information about the current scene, and make a threejs sketch from it" &lt;a href="https://www.youtube.com/watch?v=jxbNI5L7AH8"&gt;Demo&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;"Make this car red and metallic"&lt;/li&gt; 
 &lt;li&gt;"Create a sphere and place it above the cube"&lt;/li&gt; 
 &lt;li&gt;"Make the lighting like a studio"&lt;/li&gt; 
 &lt;li&gt;"Point the camera at the scene, and make it isometric"&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Hyper3D integration&lt;/h2&gt; 
&lt;p&gt;Hyper3D's free trial key allows you to generate a limited number of models per day. If the daily limit is reached, you can wait for the next day's reset or obtain your own key from hyper3d.ai and fal.ai.&lt;/p&gt; 
&lt;h2&gt;Troubleshooting&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Connection issues&lt;/strong&gt;: Make sure the Blender addon server is running, and the MCP server is configured on Claude, DO NOT run the uvx command in the terminal. Sometimes, the first command won't go through but after that it starts working.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Timeout errors&lt;/strong&gt;: Try simplifying your requests or breaking them into smaller steps&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Poly Haven integration&lt;/strong&gt;: Claude is sometimes erratic with its behaviour&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Have you tried turning it off and on again?&lt;/strong&gt;: If you're still having connection errors, try restarting both Claude and the Blender server&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Technical Details&lt;/h2&gt; 
&lt;h3&gt;Communication Protocol&lt;/h3&gt; 
&lt;p&gt;The system uses a simple JSON-based protocol over TCP sockets:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Commands&lt;/strong&gt; are sent as JSON objects with a &lt;code&gt;type&lt;/code&gt; and optional &lt;code&gt;params&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Responses&lt;/strong&gt; are JSON objects with a &lt;code&gt;status&lt;/code&gt; and &lt;code&gt;result&lt;/code&gt; or &lt;code&gt;message&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Limitations &amp;amp; Security Considerations&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;The &lt;code&gt;execute_blender_code&lt;/code&gt; tool allows running arbitrary Python code in Blender, which can be powerful but potentially dangerous. Use with caution in production environments. ALWAYS save your work before using it.&lt;/li&gt; 
 &lt;li&gt;Poly Haven requires downloading models, textures, and HDRI images. If you do not want to use it, please turn it off in the checkbox in Blender.&lt;/li&gt; 
 &lt;li&gt;Complex operations might need to be broken down into smaller steps&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Contributions are welcome! Please feel free to submit a Pull Request.&lt;/p&gt; 
&lt;h2&gt;Disclaimer&lt;/h2&gt; 
&lt;p&gt;This is a third-party integration and not made by Blender. Made by &lt;a href="https://x.com/sidahuj"&gt;Siddharth&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>python/cpython</title>
      <link>https://github.com/python/cpython</link>
      <description>&lt;p&gt;The Python programming language&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;This is Python version 3.15.0 alpha 0&lt;/h1&gt; 
&lt;p&gt;.. image:: &lt;a href="https://github.com/python/cpython/actions/workflows/build.yml/badge.svg?branch=main&amp;amp;event=push"&gt;https://github.com/python/cpython/actions/workflows/build.yml/badge.svg?branch=main&amp;amp;event=push&lt;/a&gt; :alt: CPython build status on GitHub Actions :target: &lt;a href="https://github.com/python/cpython/actions"&gt;https://github.com/python/cpython/actions&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;.. image:: &lt;a href="https://dev.azure.com/python/cpython/_apis/build/status/Azure%20Pipelines%20CI?branchName=main"&gt;https://dev.azure.com/python/cpython/_apis/build/status/Azure%20Pipelines%20CI?branchName=main&lt;/a&gt; :alt: CPython build status on Azure DevOps :target: &lt;a href="https://dev.azure.com/python/cpython/_build/latest?definitionId=4&amp;amp;branchName=main"&gt;https://dev.azure.com/python/cpython/_build/latest?definitionId=4&amp;amp;branchName=main&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;.. image:: &lt;a href="https://img.shields.io/badge/discourse-join_chat-brightgreen.svg"&gt;https://img.shields.io/badge/discourse-join_chat-brightgreen.svg&lt;/a&gt; :alt: Python Discourse chat :target: &lt;a href="https://discuss.python.org/"&gt;https://discuss.python.org/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Copyright © 2001 Python Software Foundation. All rights reserved.&lt;/p&gt; 
&lt;p&gt;See the end of this file for further copyright and license information.&lt;/p&gt; 
&lt;p&gt;.. contents::&lt;/p&gt; 
&lt;h2&gt;General Information&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Website: &lt;a href="https://www.python.org"&gt;https://www.python.org&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Source code: &lt;a href="https://github.com/python/cpython"&gt;https://github.com/python/cpython&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Issue tracker: &lt;a href="https://github.com/python/cpython/issues"&gt;https://github.com/python/cpython/issues&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Documentation: &lt;a href="https://docs.python.org"&gt;https://docs.python.org&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Developer's Guide: &lt;a href="https://devguide.python.org/"&gt;https://devguide.python.org/&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing to CPython&lt;/h2&gt; 
&lt;p&gt;For more complete instructions on contributing to CPython development, see the &lt;code&gt;Developer Guide&lt;/code&gt;_.&lt;/p&gt; 
&lt;p&gt;.. _Developer Guide: &lt;a href="https://devguide.python.org/"&gt;https://devguide.python.org/&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Using Python&lt;/h2&gt; 
&lt;p&gt;Installable Python kits, and information about using Python, are available at &lt;code&gt;python.org&lt;/code&gt;_.&lt;/p&gt; 
&lt;p&gt;.. _python.org: &lt;a href="https://www.python.org/"&gt;https://www.python.org/&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Build Instructions&lt;/h2&gt; 
&lt;p&gt;On Unix, Linux, BSD, macOS, and Cygwin::&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;./configure
make
make test
sudo make install
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This will install Python as &lt;code&gt;python3&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;You can pass many options to the configure script; run &lt;code&gt;./configure --help&lt;/code&gt; to find out more. On macOS case-insensitive file systems and on Cygwin, the executable is called &lt;code&gt;python.exe&lt;/code&gt;; elsewhere it's just &lt;code&gt;python&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Building a complete Python installation requires the use of various additional third-party libraries, depending on your build platform and configure options. Not all standard library modules are buildable or usable on all platforms. Refer to the &lt;code&gt;Install dependencies &amp;lt;https://devguide.python.org/getting-started/setup-building.html#build-dependencies&amp;gt;&lt;/code&gt;_ section of the &lt;code&gt;Developer Guide&lt;/code&gt;_ for current detailed information on dependencies for various Linux distributions and macOS.&lt;/p&gt; 
&lt;p&gt;On macOS, there are additional configure and build options related to macOS framework and universal builds. Refer to &lt;code&gt;Mac/README.rst &amp;lt;https://github.com/python/cpython/blob/main/Mac/README.rst&amp;gt;&lt;/code&gt;_.&lt;/p&gt; 
&lt;p&gt;On Windows, see &lt;code&gt;PCbuild/readme.txt &amp;lt;https://github.com/python/cpython/blob/main/PCbuild/readme.txt&amp;gt;&lt;/code&gt;_.&lt;/p&gt; 
&lt;p&gt;To build Windows installer, see &lt;code&gt;Tools/msi/README.txt &amp;lt;https://github.com/python/cpython/blob/main/Tools/msi/README.txt&amp;gt;&lt;/code&gt;_.&lt;/p&gt; 
&lt;p&gt;If you wish, you can create a subdirectory and invoke configure from there. For example::&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;mkdir debug
cd debug
../configure --with-pydebug
make
make test
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;(This will fail if you &lt;em&gt;also&lt;/em&gt; built at the top-level directory. You should do a &lt;code&gt;make clean&lt;/code&gt; at the top-level first.)&lt;/p&gt; 
&lt;p&gt;To get an optimized build of Python, &lt;code&gt;configure --enable-optimizations&lt;/code&gt; before you run &lt;code&gt;make&lt;/code&gt;. This sets the default make targets up to enable Profile Guided Optimization (PGO) and may be used to auto-enable Link Time Optimization (LTO) on some platforms. For more details, see the sections below.&lt;/p&gt; 
&lt;p&gt;Profile Guided Optimization ^^^^^^^^^^^^^^^^^^^^^^^^^^^&lt;/p&gt; 
&lt;p&gt;PGO takes advantage of recent versions of the GCC or Clang compilers. If used, either via &lt;code&gt;configure --enable-optimizations&lt;/code&gt; or by manually running &lt;code&gt;make profile-opt&lt;/code&gt; regardless of configure flags, the optimized build process will perform the following steps:&lt;/p&gt; 
&lt;p&gt;The entire Python directory is cleaned of temporary files that may have resulted from a previous compilation.&lt;/p&gt; 
&lt;p&gt;An instrumented version of the interpreter is built, using suitable compiler flags for each flavor. Note that this is just an intermediary step. The binary resulting from this step is not good for real-life workloads as it has profiling instructions embedded inside.&lt;/p&gt; 
&lt;p&gt;After the instrumented interpreter is built, the Makefile will run a training workload. This is necessary in order to profile the interpreter's execution. Note also that any output, both stdout and stderr, that may appear at this step is suppressed.&lt;/p&gt; 
&lt;p&gt;The final step is to build the actual interpreter, using the information collected from the instrumented one. The end result will be a Python binary that is optimized; suitable for distribution or production installation.&lt;/p&gt; 
&lt;p&gt;Link Time Optimization ^^^^^^^^^^^^^^^^^^^^^^&lt;/p&gt; 
&lt;p&gt;Enabled via configure's &lt;code&gt;--with-lto&lt;/code&gt; flag. LTO takes advantage of the ability of recent compiler toolchains to optimize across the otherwise arbitrary &lt;code&gt;.o&lt;/code&gt; file boundary when building final executables or shared libraries for additional performance gains.&lt;/p&gt; 
&lt;h2&gt;What's New&lt;/h2&gt; 
&lt;p&gt;We have a comprehensive overview of the changes in the &lt;code&gt;What's new in Python 3.15 &amp;lt;https://docs.python.org/3.15/whatsnew/3.15.html&amp;gt;&lt;/code&gt;_ document. For a more detailed change log, read &lt;code&gt;Misc/NEWS &amp;lt;https://github.com/python/cpython/tree/main/Misc/NEWS.d&amp;gt;&lt;/code&gt;&lt;em&gt;, but a full accounting of changes can only be gleaned from the &lt;code&gt;commit history &amp;lt;https://github.com/python/cpython/commits/main&amp;gt;&lt;/code&gt;&lt;/em&gt;.&lt;/p&gt; 
&lt;p&gt;If you want to install multiple versions of Python, see the section below entitled "Installing multiple versions".&lt;/p&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;&lt;code&gt;Documentation for Python 3.15 &amp;lt;https://docs.python.org/3.15/&amp;gt;&lt;/code&gt;_ is online, updated daily.&lt;/p&gt; 
&lt;p&gt;It can also be downloaded in many formats for faster access. The documentation is downloadable in HTML, PDF, and reStructuredText formats; the latter version is primarily for documentation authors, translators, and people with special formatting requirements.&lt;/p&gt; 
&lt;p&gt;For information about building Python's documentation, refer to &lt;code&gt;Doc/README.rst &amp;lt;https://github.com/python/cpython/blob/main/Doc/README.rst&amp;gt;&lt;/code&gt;_.&lt;/p&gt; 
&lt;h2&gt;Testing&lt;/h2&gt; 
&lt;p&gt;To test the interpreter, type &lt;code&gt;make test&lt;/code&gt; in the top-level directory. The test set produces some output. You can generally ignore the messages about skipped tests due to optional features which can't be imported. If a message is printed about a failed test or a traceback or core dump is produced, something is wrong.&lt;/p&gt; 
&lt;p&gt;By default, tests are prevented from overusing resources like disk space and memory. To enable these tests, run &lt;code&gt;make buildbottest&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;If any tests fail, you can re-run the failing test(s) in verbose mode. For example, if &lt;code&gt;test_os&lt;/code&gt; and &lt;code&gt;test_gdb&lt;/code&gt; failed, you can run::&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;make test TESTOPTS="-v test_os test_gdb"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If the failure persists and appears to be a problem with Python rather than your environment, you can &lt;code&gt;file a bug report &amp;lt;https://github.com/python/cpython/issues&amp;gt;&lt;/code&gt;_ and include relevant output from that command to show the issue.&lt;/p&gt; 
&lt;p&gt;See &lt;code&gt;Running &amp;amp; Writing Tests &amp;lt;https://devguide.python.org/testing/run-write-tests.html&amp;gt;&lt;/code&gt;_ for more on running tests.&lt;/p&gt; 
&lt;h2&gt;Installing multiple versions&lt;/h2&gt; 
&lt;p&gt;On Unix and Mac systems if you intend to install multiple versions of Python using the same installation prefix (&lt;code&gt;--prefix&lt;/code&gt; argument to the configure script) you must take care that your primary python executable is not overwritten by the installation of a different version. All files and directories installed using &lt;code&gt;make altinstall&lt;/code&gt; contain the major and minor version and can thus live side-by-side. &lt;code&gt;make install&lt;/code&gt; also creates &lt;code&gt;${prefix}/bin/python3&lt;/code&gt; which refers to &lt;code&gt;${prefix}/bin/python3.X&lt;/code&gt;. If you intend to install multiple versions using the same prefix you must decide which version (if any) is your "primary" version. Install that version using &lt;code&gt;make install&lt;/code&gt;. Install all other versions using &lt;code&gt;make altinstall&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;For example, if you want to install Python 2.7, 3.6, and 3.15 with 3.15 being the primary version, you would execute &lt;code&gt;make install&lt;/code&gt; in your 3.15 build directory and &lt;code&gt;make altinstall&lt;/code&gt; in the others.&lt;/p&gt; 
&lt;h2&gt;Release Schedule&lt;/h2&gt; 
&lt;p&gt;See &lt;code&gt;PEP 790 &amp;lt;https://peps.python.org/pep-0790/&amp;gt;&lt;/code&gt;__ for Python 3.15 release details.&lt;/p&gt; 
&lt;h2&gt;Copyright and License Information&lt;/h2&gt; 
&lt;p&gt;Copyright © 2001 Python Software Foundation. All rights reserved.&lt;/p&gt; 
&lt;p&gt;Copyright © 2000 BeOpen.com. All rights reserved.&lt;/p&gt; 
&lt;p&gt;Copyright © 1995-2001 Corporation for National Research Initiatives. All rights reserved.&lt;/p&gt; 
&lt;p&gt;Copyright © 1991-1995 Stichting Mathematisch Centrum. All rights reserved.&lt;/p&gt; 
&lt;p&gt;See the &lt;code&gt;LICENSE &amp;lt;https://github.com/python/cpython/blob/main/LICENSE&amp;gt;&lt;/code&gt;_ for information on the history of this software, terms &amp;amp; conditions for usage, and a DISCLAIMER OF ALL WARRANTIES.&lt;/p&gt; 
&lt;p&gt;This Python distribution contains &lt;em&gt;no&lt;/em&gt; GNU General Public License (GPL) code, so it may be used in proprietary projects. There are interfaces to some GNU code but these are entirely optional.&lt;/p&gt; 
&lt;p&gt;All trademarks referenced herein are property of their respective holders.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>rwv/chinese-dos-games</title>
      <link>https://github.com/rwv/chinese-dos-games</link>
      <description>&lt;p&gt;🎮 Chinese DOS games collections.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;🎮 中文 DOS 游戏&lt;/h1&gt; 
&lt;p&gt;网址： &lt;a href="https://dos.lol"&gt;https://dos.lol&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;中文 DOS 游戏合集，目前共有 1898 款游戏。&lt;/p&gt; 
&lt;h2&gt;下载游戏文件&lt;/h2&gt; 
&lt;p&gt;在根目录下运行 Python 3 脚本&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;python download_data.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;若下载出错请参见 &lt;a href="https://github.com/rwv/chinese-dos-games/issues/26"&gt;Issue #26&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;游戏列表&lt;/h2&gt; 
&lt;p&gt;参见 &lt;a href="https://dos.lol/games"&gt;https://dos.lol/games&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;IPFS&lt;/h2&gt; 
&lt;p&gt;IPNS Hash: &lt;a href="https://ipfs.io/ipns/k2k4r8oyknzob8jjqpj6toer4dw3jc6srsbqlbsalktnw1fopb7iyqd2"&gt;&lt;code&gt;k2k4r8oyknzob8jjqpj6toer4dw3jc6srsbqlbsalktnw1fopb7iyqd2&lt;/code&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;网站源代码&lt;/h2&gt; 
&lt;p&gt;请参见 &lt;a href="https://github.com/rwv/chinese-dos-games-web"&gt;rwv/chinese-dos-games-web: 🌐 Source code of https://dos.zczc.cz&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;版权问题&lt;/h2&gt; 
&lt;p&gt;本人明白此项目存在版权上的侵权，如版权方介意的话，请联系 &lt;a href="mailto:chinese.dos.games@outlook.com"&gt;chinese.dos.games@outlook.com&lt;/a&gt;，本人将立刻删除有关文件。&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;欢迎提 &lt;a href="https://github.com/rwv/chinese-dos-games/issues"&gt;Issue&lt;/a&gt; 和 &lt;a href="https://github.com/rwv/chinese-dos-games/pulls"&gt;Pull request&lt;/a&gt; 来增加新的游戏!&lt;/p&gt; 
&lt;p&gt;PR 具体参见 &lt;a href="https://github.com/rwv/chinese-dos-games/raw/master/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Credits&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/dreamlayers/em-dosbox"&gt;dreamlayers/em-dosbox: An Emscripten port of DOSBox&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/db48x/emularity"&gt;db48x/emularity: easily embed emulators&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://tieba.baidu.com/p/3962261741"&gt;衡兰若芷制作的DOS游戏合集&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>sentient-agi/ROMA</title>
      <link>https://github.com/sentient-agi/ROMA</link>
      <description>&lt;p&gt;Recursive-Open-Meta-Agent v0.1 (Beta). A meta-agent framework to build high-performance multi-agent systems.&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;div align="center"&gt; 
  &lt;img src="https://raw.githubusercontent.com/sentient-agi/ROMA/main/assets/sentient-logo.png" alt="alt text" width="60%" /&gt; 
 &lt;/div&gt; 
 &lt;h1&gt;ROMA: Recursive Open Meta-Agents&lt;/h1&gt; 
 &lt;p align="center"&gt; &lt;strong&gt;Building hierarchical high-performance multi-agent systems made easy! (Beta) &lt;/strong&gt; &lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://trendshift.io/repositories/14848" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/14848" alt="sentient-agi%2FROMA | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p align="center"&gt; &lt;a href="https://sentient.xyz/" target="_blank" style="margin: 2px;"&gt; &lt;img alt="Homepage" src="https://img.shields.io/badge/Sentient-Homepage-%23EAEAEA?logo=data%3Aimage%2Fsvg%2Bxml%3Bbase64%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%2BPC9zdmc%2B&amp;amp;link=https%3A%2F%2Fhuggingface.co%2FSentientagi" style="display: inline-block; vertical-align: middle;" /&gt; &lt;/a&gt; &lt;a href="https://github.com/sentient-agi" target="_blank" style="margin: 2px;"&gt; &lt;img alt="GitHub" src="https://img.shields.io/badge/Github-sentient_agi-181717?logo=github" style="display: inline-block; vertical-align: middle;" /&gt; &lt;/a&gt; &lt;a href="https://huggingface.co/Sentientagi" target="_blank" style="margin: 2px;"&gt; &lt;img alt="Hugging Face" src="https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-SentientAGI-ffc107?color=ffc107&amp;amp;logoColor=white" style="display: inline-block; vertical-align: middle;" /&gt; &lt;/a&gt; &lt;/p&gt;
&lt;/div&gt; 
&lt;div align="center" style="line-height: 1;"&gt; 
 &lt;a href="https://discord.gg/sentientfoundation" target="_blank" style="margin: 2px;"&gt; &lt;img alt="Discord" src="https://img.shields.io/badge/Discord-SentientAGI-7289da?logo=discord&amp;amp;logoColor=white&amp;amp;color=7289da" style="display: inline-block; vertical-align: middle;" /&gt; &lt;/a&gt; 
 &lt;a href="https://x.com/SentientAGI" target="_blank" style="margin: 2px;"&gt; &lt;img alt="Twitter Follow" src="https://img.shields.io/badge/-SentientAGI-grey?logo=x&amp;amp;link=https%3A%2F%2Fx.com%2FSentientAGI%2F" style="display: inline-block; vertical-align: middle;" /&gt; &lt;/a&gt; 
 &lt;p&gt;&lt;/p&gt; 
 &lt;p align="center"&gt; &lt;a href="https://www.sentient.xyz/blog/recursive-open-meta-agent"&gt;Technical Blog&lt;/a&gt; • &lt;a href="https://raw.githubusercontent.com/sentient-agi/ROMA/main/docs/"&gt;Paper (Coming soon)&lt;/a&gt; • &lt;a href="https://www.sentient.xyz/"&gt;Build Agents for $$$&lt;/a&gt; &lt;/p&gt; 
&lt;/div&gt; 
&lt;hr /&gt;  
&lt;h2&gt;📖 Documentation&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/sentient-agi/ROMA/main/docs/INTRODUCTION.md"&gt;🚀 Introduction&lt;/a&gt;&lt;/strong&gt; - Understand the vision and architecture behind ROMA&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/sentient-agi/ROMA/main/docs/SETUP.md"&gt;📦 Setup&lt;/a&gt;&lt;/strong&gt; - Detailed configuration options and environment setup&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/sentient-agi/ROMA/main/docs/AGENTS_GUIDE.md"&gt;🤖 Agents Guide&lt;/a&gt;&lt;/strong&gt; - Learn how to create and customize your own agents&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/sentient-agi/ROMA/main/docs/CONFIGURATION.md"&gt;⚙️ Configuration&lt;/a&gt;&lt;/strong&gt; - Detailed configuration options and environment setup&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/sentient-agi/ROMA/main/docs/ROADMAP.md"&gt;🗺️ Roadmap&lt;/a&gt;&lt;/strong&gt; - See what's coming next for ROMA&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;🎯 What is ROMA?&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/sentient-agi/ROMA/main/assets/roma_run.gif" alt="alt text" width="80%" /&gt; 
&lt;/div&gt; 
&lt;br /&gt; 
&lt;p&gt;&lt;strong&gt;ROMA&lt;/strong&gt; is a &lt;strong&gt;meta-agent framework&lt;/strong&gt; that uses recursive hierarchical structures to solve complex problems. By breaking down tasks into parallelizable components, ROMA enables agents to tackle sophisticated reasoning challenges while maintaining transparency that makes context-engineering and iteration straightforward. The framework offers &lt;strong&gt;parallel problem solving&lt;/strong&gt; where agents work simultaneously on different parts of complex tasks, &lt;strong&gt;transparent development&lt;/strong&gt; with a clear structure for easy debugging, and &lt;strong&gt;proven performance&lt;/strong&gt; demonstrated through our search agent's strong benchmark results. We've shown the framework's effectiveness, but this is just the beginning. As an &lt;strong&gt;open-source and extensible&lt;/strong&gt; platform, ROMA is designed for community-driven development, allowing you to build and customize agents for your specific needs while benefiting from the collective improvements of the community.&lt;/p&gt; 
&lt;h2&gt;🏗️ How It Works&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;ROMA&lt;/strong&gt; framework processes tasks through a recursive &lt;strong&gt;plan–execute loop&lt;/strong&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;def solve(task):
    if is_atomic(task):                 # Step 1: Atomizer
        return execute(task)            # Step 2: Executor
    else:
        subtasks = plan(task)           # Step 2: Planner
        results = []
        for subtask in subtasks:
            results.append(solve(subtask))  # Recursive call
        return aggregate(results)       # Step 3: Aggregator

# Entry point:
answer = solve(initial_request)
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Atomizer&lt;/strong&gt; – Decides whether a request is &lt;strong&gt;atomic&lt;/strong&gt; (directly executable) or requires &lt;strong&gt;planning&lt;/strong&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Planner&lt;/strong&gt; – If planning is needed, the task is broken into smaller &lt;strong&gt;subtasks&lt;/strong&gt;. Each subtask is fed back into the &lt;strong&gt;Atomizer&lt;/strong&gt;, making the process recursive.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Executors&lt;/strong&gt; – Handle atomic tasks. Executors can be &lt;strong&gt;LLMs, APIs, or even other agents&lt;/strong&gt; — as long as they implement an &lt;code&gt;agent.execute()&lt;/code&gt; interface.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Aggregator&lt;/strong&gt; – Collects and integrates results from subtasks. Importantly, the Aggregator produces the &lt;strong&gt;answer to the original parent task&lt;/strong&gt;, not just raw child outputs.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;📐 Information Flow&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Top-down:&lt;/strong&gt; Tasks are decomposed into subtasks recursively.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Bottom-up:&lt;/strong&gt; Subtask results are aggregated upwards into solutions for parent tasks.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Left-to-right:&lt;/strong&gt; If a subtask depends on the output of a previous one, it waits until that subtask completes before execution.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;This structure makes the system flexible, recursive, and dependency-aware — capable of decomposing complex problems into smaller steps while ensuring results are integrated coherently.&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;Click to view the system flow diagram&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-mermaid"&gt;flowchart TB
    A[Your Request] --&amp;gt; B{Atomizer}
    B --&amp;gt;|Plan Needed| C[Planner]
    B --&amp;gt;|Atomic Task| D[Executor]

    %% Planner spawns subtasks
    C --&amp;gt; E[Subtasks]
    E --&amp;gt; G[Aggregator]

    %% Recursion
    E -.-&amp;gt; B  

    %% Execution + Aggregation
    D --&amp;gt; F[Final Result]
    G --&amp;gt; F

    style A fill:#e1f5fe
    style F fill:#c8e6c9
    style B fill:#fff3e0
    style C fill:#ffe0b2
    style D fill:#d1c4e9
    style G fill:#c5cae9

&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt;
&lt;br /&gt; 
&lt;h3&gt;🚀 30-Second Quick Start&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/sentient-agi/ROMA.git
cd ROMA

# Run the automated setup
./setup.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Choose between:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Docker Setup&lt;/strong&gt; (Recommended) - One-command setup with isolation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Native Setup&lt;/strong&gt; - Direct installation for development&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;🛠️ Technical Stack&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Framework&lt;/strong&gt;: Built on &lt;a href="https://raw.githubusercontent.com/sentient-agi/ROMA/main/%5Bhttps://github.com/your/agnoagents%5D(https://github.com/agno-agi/agno)"&gt;AgnoAgents&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Backend&lt;/strong&gt;: Python 3.12+ with FastAPI/Flask&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Frontend&lt;/strong&gt;: React + TypeScript with real-time WebSocket&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;LLM Support&lt;/strong&gt;: Any provider via LiteLLM&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Data Persistence&lt;/strong&gt;: Enterprise S3 mounting with security validation 
  &lt;ul&gt; 
   &lt;li&gt;🔒 &lt;strong&gt;goofys FUSE mounting&lt;/strong&gt; for zero-latency file access&lt;/li&gt; 
   &lt;li&gt;🛡️ &lt;strong&gt;Path injection protection&lt;/strong&gt; with comprehensive validation&lt;/li&gt; 
   &lt;li&gt;🔐 &lt;strong&gt;AWS credentials verification&lt;/strong&gt; before operations&lt;/li&gt; 
   &lt;li&gt;📁 &lt;strong&gt;Dynamic Docker Compose&lt;/strong&gt; with secure volume mounting&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Code Execution&lt;/strong&gt;: E2B sandboxes with unified S3 integration&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Security&lt;/strong&gt;: Production-grade validation and error handling&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Features&lt;/strong&gt;: Multi-modal, tools, MCP, hooks, caching&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;📦 Installation Options&lt;/h2&gt; 
&lt;h3&gt;Quick Start (Recommended)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Main setup (choose Docker or Native)
./setup.sh

# Optional: Setup E2B sandbox integration
./setup.sh --e2b

# Test E2B integration  
./setup.sh --test-e2b
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Command Line Options&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;./setup.sh --docker     # Run Docker setup directly
./setup.sh --docker-from-scratch  # Rebuild Docker images/containers from scratch (down -v, no cache)
./setup.sh --native     # Run native setup directly (macOS/Ubuntu/Debian)
./setup.sh --e2b        # Setup E2B template (requires E2B_API_KEY + AWS creds)
./setup.sh --test-e2b   # Test E2B template integration
./setup.sh --help       # Show all available options
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Manual Installation&lt;/h3&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/sentient-agi/ROMA/main/docs/SETUP.md"&gt;setup docs&lt;/a&gt; for detailed instructions.&lt;/p&gt; 
&lt;h3&gt;🏗️ Optional: E2B Sandbox Integration&lt;/h3&gt; 
&lt;p&gt;For secure code execution capabilities, optionally set up E2B sandboxes:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# After main setup, configure E2B (requires E2B_API_KEY and AWS credentials in .env)
./setup.sh --e2b

# Test E2B integration
./setup.sh --test-e2b
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;E2B Features:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;🔒 &lt;strong&gt;Secure Code Execution&lt;/strong&gt; - Run untrusted code in isolated sandboxes&lt;/li&gt; 
 &lt;li&gt;☁️ &lt;strong&gt;S3 Integration&lt;/strong&gt; - Automatic data sync between local and sandbox environments&lt;/li&gt; 
 &lt;li&gt;🚀 &lt;strong&gt;goofys Mounting&lt;/strong&gt; - High-performance S3 filesystem mounting&lt;/li&gt; 
 &lt;li&gt;🔧 &lt;strong&gt;AWS Credentials&lt;/strong&gt; - Passed securely via Docker build arguments&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;🤖 Pre-built Agents&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; These agents are demonstrations built using ROMA's framework through simple vibe-prompting and minimal manual tuning. They showcase how easily you can create high-performance agents with ROMA, rather than being production-final solutions. Our mission is to empower the community to build, share, and get rewarded for creating innovative agent recipes and use-cases.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;ROMA comes with example agents that demonstrate the framework's capabilities:&lt;/p&gt; 
&lt;h3&gt;🔍 General Task Solver&lt;/h3&gt; 
&lt;p&gt;A versatile agent powered by ChatGPT Search Preview for handling diverse tasks:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Intelligent Search&lt;/strong&gt;: Leverages OpenAI's latest search capabilities for real-time information&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Flexible Planning&lt;/strong&gt;: Adapts task decomposition based on query complexity&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Multi-Domain&lt;/strong&gt;: Handles everything from technical questions to creative projects&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Quick Prototyping&lt;/strong&gt;: Perfect for testing ROMA's capabilities without domain-specific setup&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Perfect for: General research, fact-checking, exploratory analysis, quick information gathering&lt;/p&gt; 
&lt;h3&gt;🔬 Deep Research Agent&lt;/h3&gt; 
&lt;p&gt;A comprehensive research system that breaks down complex research questions into manageable sub-tasks:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Smart Task Decomposition&lt;/strong&gt;: Automatically splits research topics into search, analysis, and synthesis phases&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Parallel Information Gathering&lt;/strong&gt;: Executes multiple searches simultaneously for faster results&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Multi-Source Integration&lt;/strong&gt;: Combines results from web search, Wikipedia, and specialized APIs&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Intelligent Synthesis&lt;/strong&gt;: Aggregates findings into coherent, well-structured reports&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Perfect for: Academic research, market analysis, competitive intelligence, technical documentation&lt;/p&gt; 
&lt;h3&gt;💹 Crypto Analytics Agent&lt;/h3&gt; 
&lt;p&gt;Specialized financial analysis agent with deep blockchain and DeFi expertise:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Real-Time Market Data&lt;/strong&gt;: Integrates with Binance, CoinGecko, and DefiLlama APIs&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;On-Chain Analytics&lt;/strong&gt;: Access to Arkham Intelligence for wallet tracking and token flows&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Technical Analysis&lt;/strong&gt;: Advanced charting with OHLC data and market indicators&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;DeFi Metrics&lt;/strong&gt;: TVL tracking, yield analysis, protocol comparisons&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Secure Execution&lt;/strong&gt;: Runs analysis in E2B sandboxes with data persistence&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Perfect for: Token research, portfolio analysis, DeFi protocol evaluation, market trend analysis&lt;/p&gt; 
&lt;p&gt;All three agents demonstrate ROMA's recursive architecture in action, showing how complex queries that would overwhelm single-pass systems can be elegantly decomposed and solved. They serve as templates and inspiration for building your own specialized agents.&lt;/p&gt; 
&lt;h3&gt;Your First Agent in 5 Minutes&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;./setup.sh  # Automated setup with Docker or native installation
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Access all the pre-defined agents through the frontend on &lt;code&gt;localhost:3000&lt;/code&gt; after setting up the backend on &lt;code&gt;localhost:5000&lt;/code&gt;. Please checkout &lt;a href="https://raw.githubusercontent.com/sentient-agi/ROMA/main/docs/SETUP.md"&gt;Setup&lt;/a&gt; and the &lt;a href="https://raw.githubusercontent.com/sentient-agi/ROMA/main/docs/AGENTS_GUIDE.md"&gt;Agents guide&lt;/a&gt; to get started!&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/sentient-agi/ROMA/main/assets/agent_customization.png" alt="alt text" width="60%" /&gt; 
&lt;/div&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# Your first agent in 3 lines
from sentientresearchagent import SentientAgent

agent = SentientAgent.create()
result = await agent.run("Create a podcast about AI safety")
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;📊 Benchmarks&lt;/h2&gt; 
&lt;p&gt;We evaluate our simple implementation of a search system using ROMA, called ROMA-Search across three benchmarks: &lt;strong&gt;SEAL-0&lt;/strong&gt;, &lt;strong&gt;FRAMES&lt;/strong&gt;, and &lt;strong&gt;SimpleQA&lt;/strong&gt;.&lt;br /&gt; Below are the performance graphs for each benchmark.&lt;/p&gt; 
&lt;h3&gt;&lt;a href="https://huggingface.co/datasets/vtllms/sealqa"&gt;SEAL-0&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;SealQA is a new challenging benchmark for evaluating Search-Augmented Language models on fact-seeking questions where web search yields conflicting, noisy, or unhelpful results.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/sentient-agi/ROMA/main/assets/seal-0-full.001.jpeg" alt="SEAL-0 Results" /&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h3&gt;&lt;a href="https://huggingface.co/datasets/google/frames-benchmark"&gt;FRAMES&lt;/a&gt;&lt;/h3&gt; 
&lt;details&gt; 
 &lt;summary&gt;View full results&lt;/summary&gt; 
 &lt;p&gt;A comprehensive evaluation dataset designed to test the capabilities of Retrieval-Augmented Generation (RAG) systems across factuality, retrieval accuracy, and reasoning.&lt;/p&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/sentient-agi/ROMA/main/assets/FRAMES-full.001.jpeg" alt="FRAMES Results" /&gt;&lt;/p&gt; 
&lt;/details&gt; 
&lt;hr /&gt; 
&lt;h3&gt;&lt;a href="https://openai.com/index/introducing-simpleqa/"&gt;SimpleQA&lt;/a&gt;&lt;/h3&gt; 
&lt;details&gt; 
 &lt;summary&gt;View full results&lt;/summary&gt; 
 &lt;p&gt;Factuality benchmark that measures the ability for language models to answer short, fact-seeking questions.&lt;/p&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/sentient-agi/ROMA/main/assets/simpleQAFull.001.jpeg" alt="SimpleQA Results" /&gt;&lt;/p&gt; 
&lt;/details&gt; 
&lt;h2&gt;✨ Features&lt;/h2&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td width="50%"&gt; &lt;h3&gt;🔄 &lt;strong&gt;Recursive Task Decomposition&lt;/strong&gt;&lt;/h3&gt; &lt;p&gt;Automatically breaks down complex tasks into manageable subtasks with intelligent dependency management. Runs independent sub-tasks in &lt;strong&gt;parallel&lt;/strong&gt;.&lt;/p&gt; &lt;/td&gt; 
   &lt;td width="50%"&gt; &lt;h3&gt;🤖 &lt;strong&gt;Agent Agnostic&lt;/strong&gt;&lt;/h3&gt; &lt;p&gt;Works with any provider (OpenAI, Anthropic, Google, local models) through unified interface, as long as it has an &lt;code&gt;agent.run()&lt;/code&gt; command, then you can use it!&lt;/p&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="50%"&gt; &lt;h3&gt;🔍 &lt;strong&gt;Complete Transparency&lt;/strong&gt;&lt;/h3&gt; &lt;p&gt;Stage tracing shows exactly what happens at each step - debug and optimize with full visibility&lt;/p&gt; &lt;/td&gt; 
   &lt;td width="50%"&gt; &lt;h3&gt;🔌 Connect Any Tool&lt;/h3&gt; &lt;p&gt;Seamlessly integrate external tools and protocols with configurable intervention points. Already includes production-grade connectors such as E2B, file-read-write, and more.&lt;/p&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h2&gt;🙏 Acknowledgments&lt;/h2&gt; 
&lt;p&gt;This framework would not have been possible if it wasn't for these amazing open-source contributions!&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Inspired by the hierarchical planning approach described in &lt;a href="https://arxiv.org/abs/2503.08275"&gt;"Beyond Outlining: Heterogeneous Recursive Planning"&lt;/a&gt; by Xiong et al.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pydantic/pydantic"&gt;Pydantic&lt;/a&gt; - Data validation using Python type annotations&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/sentient-agi/ROMA/main/%5Bhttps://github.com/agno-ai/agno%5D(https://github.com/agno-agi/agno)"&gt;Agno&lt;/a&gt; - Framework for building AI agents&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/e2b-dev/e2b"&gt;E2B&lt;/a&gt; - Cloud runtime for AI agents&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;📚 Citation&lt;/h2&gt; 
&lt;p&gt;If you use the ROMA repo in your research, please cite:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bibtex"&gt;@software{al_zubi_2025_17052592,
  author       = {Al-Zubi, Salah and
                  Nama, Baran and
                  Kaz, Arda and
                  Oh, Sewoong},
  title        = {SentientResearchAgent: A Hierarchical AI Agent
                   Framework for Research and Analysis
                  },
  month        = sep,
  year         = 2025,
  publisher    = {Zenodo},
  version      = {ROMA},
  doi          = {10.5281/zenodo.17052592},
  url          = {https://doi.org/10.5281/zenodo.17052592},
  swhid        = {swh:1:dir:69cd1552103e0333dd0c39fc4f53cb03196017ce
                   ;origin=https://doi.org/10.5281/zenodo.17052591;vi
                   sit=swh:1:snp:f50bf99634f9876adb80c027361aec9dff97
                   3433;anchor=swh:1:rel:afa7caa843ce1279f5b4b29b5d3d
                   5e3fe85edc95;path=salzubi401-ROMA-b31c382
                  },
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;📄 License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the MIT License - see the &lt;a href="https://raw.githubusercontent.com/sentient-agi/ROMA/main/LICENSE"&gt;LICENSE&lt;/a&gt; file for details.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>QwenLM/Qwen3</title>
      <link>https://github.com/QwenLM/Qwen3</link>
      <description>&lt;p&gt;Qwen3 is the large language model series developed by Qwen team, Alibaba Cloud.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Qwen3&lt;/h1&gt; 
&lt;p align="center"&gt; &lt;img src="https://qianwen-res.oss-accelerate-overseas.aliyuncs.com/logo_qwen3.png" width="400" /&gt; &lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p align="center"&gt; 💜 &lt;a href="https://chat.qwen.ai/"&gt;&lt;b&gt;Qwen Chat&lt;/b&gt;&lt;/a&gt;&amp;nbsp;&amp;nbsp; | &amp;nbsp;&amp;nbsp;🤗 &lt;a href="https://huggingface.co/Qwen"&gt;Hugging Face&lt;/a&gt;&amp;nbsp;&amp;nbsp; | &amp;nbsp;&amp;nbsp;🤖 &lt;a href="https://modelscope.cn/organization/qwen"&gt;ModelScope&lt;/a&gt;&amp;nbsp;&amp;nbsp; | &amp;nbsp;&amp;nbsp; 📑 &lt;a href="https://arxiv.org/abs/2505.09388"&gt;Paper&lt;/a&gt; &amp;nbsp;&amp;nbsp; | &amp;nbsp;&amp;nbsp; 📑 &lt;a href="https://qwenlm.github.io/blog/qwen3/"&gt;Blog&lt;/a&gt; &amp;nbsp;&amp;nbsp; ｜ &amp;nbsp;&amp;nbsp;📖 &lt;a href="https://qwen.readthedocs.io/"&gt;Documentation&lt;/a&gt; &lt;br /&gt; 🖥️ &lt;a href="https://huggingface.co/spaces/Qwen/Qwen3-Demo"&gt;Demo&lt;/a&gt;&amp;nbsp;&amp;nbsp; | &amp;nbsp;&amp;nbsp;💬 &lt;a href="https://github.com/QwenLM/Qwen/raw/main/assets/wechat.png"&gt;WeChat (微信)&lt;/a&gt;&amp;nbsp;&amp;nbsp; | &amp;nbsp;&amp;nbsp;🫨 &lt;a href="https://discord.gg/CV4E9rpNSD"&gt;Discord&lt;/a&gt;&amp;nbsp;&amp;nbsp; &lt;/p&gt; 
&lt;p&gt;Visit our Hugging Face or ModelScope organization (click links above), search checkpoints with names starting with &lt;code&gt;Qwen3-&lt;/code&gt; or visit the &lt;a href="https://huggingface.co/collections/Qwen/qwen3-67dd247413f0e2e4f653967f"&gt;Qwen3 collection&lt;/a&gt;, and you will find all you need! Enjoy!&lt;/p&gt; 
&lt;p&gt;To learn more about Qwen3, feel free to read our documentation [&lt;a href="https://qwen.readthedocs.io/en/latest/"&gt;EN&lt;/a&gt;|&lt;a href="https://qwen.readthedocs.io/zh-cn/latest/"&gt;ZH&lt;/a&gt;]. Our documentation consists of the following sections:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Quickstart: the basic usages and demonstrations;&lt;/li&gt; 
 &lt;li&gt;Inference: the guidance for the inference with Transformers, including batch inference, streaming, etc.;&lt;/li&gt; 
 &lt;li&gt;Run Locally: the instructions for running LLM locally on CPU and GPU, with frameworks like llama.cpp and Ollama;&lt;/li&gt; 
 &lt;li&gt;Deployment: the demonstration of how to deploy Qwen for large-scale inference with frameworks like SGLang, vLLM, TGI, etc.;&lt;/li&gt; 
 &lt;li&gt;Quantization: the practice of quantizing LLMs with GPTQ, AWQ, as well as the guidance for how to make high-quality quantized GGUF files;&lt;/li&gt; 
 &lt;li&gt;Training: the instructions for post-training, including SFT and RLHF (TODO) with frameworks like Axolotl, LLaMA-Factory, etc.&lt;/li&gt; 
 &lt;li&gt;Framework: the usage of Qwen with frameworks for application, e.g., RAG, Agent, etc.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Introduction&lt;/h2&gt; 
&lt;h3&gt;Qwen3-2507&lt;/h3&gt; 
&lt;p&gt;Over the past three months, we continued to explore the potential of the Qwen3 families and we are excited to introduce the updated &lt;strong&gt;Qwen3-2507&lt;/strong&gt; in two variants, Qwen3-Instruct-2507 and Qwen3-Thinking-2507, and three sizes, 235B-A22B, 30B-A3B, and 4B.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Qwen3-Instruct-2507&lt;/strong&gt; is the updated version of the previous Qwen3 non-thinking mode, featuring the following key enhancements:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Significant improvements&lt;/strong&gt; in general capabilities, including &lt;strong&gt;instruction following, logical reasoning, text comprehension, mathematics, science, coding and tool usage&lt;/strong&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Substantial gains&lt;/strong&gt; in long-tail knowledge coverage across &lt;strong&gt;multiple languages&lt;/strong&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Markedly better alignment&lt;/strong&gt; with user preferences in &lt;strong&gt;subjective and open-ended tasks&lt;/strong&gt;, enabling more helpful responses and higher-quality text generation.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Enhanced capabilities&lt;/strong&gt; in &lt;strong&gt;256K-token long-context understanding&lt;/strong&gt;, extendable up to &lt;strong&gt;1 million tokens&lt;/strong&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Qwen3-Thinking-2507&lt;/strong&gt; is the continuation of Qwen3 thinking model, with improved quality and depth of reasoning, featuring the following key enhancements:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Significantly improved performance&lt;/strong&gt; on reasoning tasks, including logical reasoning, mathematics, science, coding, and academic benchmarks that typically require human expertise — achieving &lt;strong&gt;state-of-the-art results among open-weight thinking models&lt;/strong&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Markedly better general capabilities&lt;/strong&gt;, such as instruction following, tool usage, text generation, and alignment with human preferences.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Enhanced 256K long-context understanding&lt;/strong&gt; capabilities, extendable up to &lt;strong&gt;1 million tokens&lt;/strong&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;b&gt;Previous Qwen3 Release&lt;/b&gt;&lt;/summary&gt; 
 &lt;h3&gt;Qwen3 (aka Qwen3-2504)&lt;/h3&gt; 
 &lt;p&gt; We are excited to announce the release of Qwen3, the latest addition to the Qwen family of large language models. These models represent our most advanced and intelligent systems to date, improving from our experience in building QwQ and Qwen2.5. We are making the weights of Qwen3 available to the public, including both dense and Mixture-of-Expert (MoE) models. &lt;br /&gt;&lt;br /&gt; The highlights from Qwen3 include: &lt;/p&gt;
 &lt;ul&gt; 
  &lt;li&gt;&lt;b&gt;Dense and Mixture-of-Experts (MoE) models of various sizes&lt;/b&gt;, available in 0.6B, 1.7B, 4B, 8B, 14B, 32B and 30B-A3B, 235B-A22B.&lt;/li&gt; 
  &lt;li&gt;&lt;b&gt;Seamless switching between thinking mode&lt;/b&gt; (for complex logical reasoning, math, and coding) and &lt;b&gt;non-thinking mode&lt;/b&gt; (for efficient, general-purpose chat), ensuring optimal performance across various scenarios.&lt;/li&gt; 
  &lt;li&gt;&lt;b&gt;Significantly enhancement in reasoning capabilities&lt;/b&gt;, surpassing previous QwQ (in thinking mode) and Qwen2.5 instruct models (in non-thinking mode) on mathematics, code generation, and commonsense logical reasoning.&lt;/li&gt; 
  &lt;li&gt;&lt;b&gt;Superior human preference alignment&lt;/b&gt;, excelling in creative writing, role-playing, multi-turn dialogues, and instruction following, to deliver a more natural, engaging, and immersive conversational experience.&lt;/li&gt; 
  &lt;li&gt;&lt;b&gt;Expertise in agent capabilities&lt;/b&gt;, enabling precise integration with external tools in both thinking and unthinking modes and achieving leading performance among open-source models in complex agent-based tasks.&lt;/li&gt; 
  &lt;li&gt;&lt;b&gt;Support of 100+ languages and dialects&lt;/b&gt; with strong capabilities for &lt;b&gt;multilingual instruction following&lt;/b&gt; and &lt;b&gt;translation&lt;/b&gt;.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;/p&gt; 
&lt;/details&gt; 
&lt;h2&gt;News&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;2025.08.08: You can now use Qwen3-2507 to handle ultra-long inputs of &lt;strong&gt;1 million tokens&lt;/strong&gt;! See the update modelcards (&lt;a href="https://huggingface.co/Qwen/Qwen3-235B-A22B-Instruct-2507"&gt;235B-A22B-Instruct-2507&lt;/a&gt;, &lt;a href="https://huggingface.co/Qwen/Qwen3-235B-A22B-Thinking-2507"&gt;235B-A22B-Thinking-2507&lt;/a&gt;, &lt;a href="https://huggingface.co/Qwen/Qwen3-30B-A3B-Instruct-2507"&gt;A30B-A3B-Instruct-2507&lt;/a&gt;, &lt;a href="https://huggingface.co/Qwen/Qwen3-30B-A3B-Thinking-2507"&gt;A30B-A3B-Thinking-2507&lt;/a&gt;) for how to enable this feature.&lt;/li&gt; 
 &lt;li&gt;2025.08.06: The final open release of Qwen3-2507, &lt;a href="https://huggingface.co/Qwen/Qwen3-4B-Instruct-2507"&gt;Qwen3-4B-Instruct-2507&lt;/a&gt; and &lt;a href="https://huggingface.co/Qwen/Qwen3-4B-Thinking-2507"&gt;Qwen3-4B-Thinking-2507&lt;/a&gt;, is out!&lt;/li&gt; 
 &lt;li&gt;2025.07.31: Qwen3-30B-A3B-Thinking-2507 is released. Check out the &lt;a href="https://huggingface.co/Qwen/Qwen3-30B-A3B-Thinking-2507"&gt;modelcard&lt;/a&gt; for more details!&lt;/li&gt; 
 &lt;li&gt;2025.07.30: Qwen3-30B-A3B-Instruct-2507 is released. Check out the &lt;a href="https://huggingface.co/Qwen/Qwen3-30B-A3B-Instruct-2507"&gt;modelcard&lt;/a&gt; for more details!&lt;/li&gt; 
 &lt;li&gt;2025.07.25: We released the updated version of Qwen3-235B-A22B thinking mode, named Qwen3-235B-A22B-Thinking-2507. Check out the &lt;a href="https://huggingface.co/Qwen/Qwen3-235B-A22B-Thinking-2507"&gt;modelcard&lt;/a&gt; for more details!&lt;/li&gt; 
 &lt;li&gt;2025.07.21: We released the updated version of Qwen3-235B-A22B non-thinking mode, named Qwen3-235B-A22B-Instruct-2507, featuring significant enhancements over the previous version and supporting 256K-token long-context understanding. Check our &lt;a href="https://huggingface.co/Qwen/Qwen3-235B-A22B-Instruct-2507"&gt;modelcard&lt;/a&gt; for more details!&lt;/li&gt; 
 &lt;li&gt;2025.04.29: We released the Qwen3 series. Check our &lt;a href="https://qwenlm.github.io/blog/qwen3"&gt;blog&lt;/a&gt; for more details!&lt;/li&gt; 
 &lt;li&gt;2024.09.19: We released the Qwen2.5 series. This time there are 3 extra model sizes: 3B, 14B, and 32B for more possibilities. Check our &lt;a href="https://qwenlm.github.io/blog/qwen2.5"&gt;blog&lt;/a&gt; for more!&lt;/li&gt; 
 &lt;li&gt;2024.06.06: We released the Qwen2 series. Check our &lt;a href="https://qwenlm.github.io/blog/qwen2/"&gt;blog&lt;/a&gt;!&lt;/li&gt; 
 &lt;li&gt;2024.03.28: We released the first MoE model of Qwen: Qwen1.5-MoE-A2.7B! Temporarily, only HF transformers and vLLM support the model. We will soon add the support of llama.cpp, mlx-lm, etc. Check our &lt;a href="https://qwenlm.github.io/blog/qwen-moe/"&gt;blog&lt;/a&gt; for more information!&lt;/li&gt; 
 &lt;li&gt;2024.02.05: We released the Qwen1.5 series.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Performance&lt;/h2&gt; 
&lt;p&gt;Detailed evaluation results are reported in this &lt;a href="https://qwenlm.github.io/blog/qwen3/"&gt;📑 blog (Qwen3-2504)&lt;/a&gt; and this &lt;a href=""&gt;📑 blog (Qwen3-2507) [coming soon]&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;For requirements on GPU memory and the respective throughput, see results &lt;a href="https://qwen.readthedocs.io/en/latest/getting_started/speed_benchmark.html"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Run Qwen3&lt;/h2&gt; 
&lt;h3&gt;🤗 Transformers&lt;/h3&gt; 
&lt;p&gt;Transformers is a library of pretrained natural language processing for inference and training. The latest version of &lt;code&gt;transformers&lt;/code&gt; is recommended and &lt;code&gt;transformers&amp;gt;=4.51.0&lt;/code&gt; is required.&lt;/p&gt; 
&lt;h4&gt;Qwen3-Instruct-2507&lt;/h4&gt; 
&lt;p&gt;The following contains a code snippet illustrating how to use Qwen3-30B-A3B-Instruct-2507 to generate content based on given inputs.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from transformers import AutoModelForCausalLM, AutoTokenizer

model_name = "Qwen/Qwen3-30B-A3B-Instruct-2507"

# load the tokenizer and the model
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForCausalLM.from_pretrained(
    model_name,
    torch_dtype="auto",
    device_map="auto"
)

# prepare the model input
prompt = "Give me a short introduction to large language model."
messages = [
    {"role": "user", "content": prompt}
]
text = tokenizer.apply_chat_template(
    messages,
    tokenize=False,
    add_generation_prompt=True,
)
model_inputs = tokenizer([text], return_tensors="pt").to(model.device)

# conduct text completion
generated_ids = model.generate(
    **model_inputs,
    max_new_tokens=16384
)
output_ids = generated_ids[0][len(model_inputs.input_ids[0]):].tolist() 

content = tokenizer.decode(output_ids, skip_special_tokens=True)

print("content:", content)
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!Note] Qwen3-Instruct-2507 supports only non-thinking mode and does not generate &lt;code&gt;&amp;lt;think&amp;gt;&amp;lt;/think&amp;gt;&lt;/code&gt; blocks in its output. Meanwhile, specifying &lt;code&gt;enable_thinking=False&lt;/code&gt; is no longer required.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;Qwen3-Thinking-2507&lt;/h4&gt; 
&lt;p&gt;The following contains a code snippet illustrating how to use Qwen3-30B-A3B-Thinking-2507 to generate content based on given inputs.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from transformers import AutoModelForCausalLM, AutoTokenizer

model_name = "Qwen/Qwen3-30B-A3B-Thinking-2507"

# load the tokenizer and the model
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForCausalLM.from_pretrained(
    model_name,
    torch_dtype="auto",
    device_map="auto"
)

# prepare the model input
prompt = "Give me a short introduction to large language model."
messages = [
    {"role": "user", "content": prompt}
]
text = tokenizer.apply_chat_template(
    messages,
    tokenize=False,
    add_generation_prompt=True,
)
model_inputs = tokenizer([text], return_tensors="pt").to(model.device)

# conduct text completion
generated_ids = model.generate(
    **model_inputs,
    max_new_tokens=32768
)
output_ids = generated_ids[0][len(model_inputs.input_ids[0]):].tolist() 

# parsing thinking content
try:
    # rindex finding 151668 (&amp;lt;/think&amp;gt;)
    index = len(output_ids) - output_ids[::-1].index(151668)
except ValueError:
    index = 0

thinking_content = tokenizer.decode(output_ids[:index], skip_special_tokens=True).strip("\n")
content = tokenizer.decode(output_ids[index:], skip_special_tokens=True).strip("\n")

print("thinking content:", thinking_content)  # no opening &amp;lt;think&amp;gt; tag
print("content:", content)

&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!Note] Qwen3-Thinking-2507 supports only thinking mode. Additionally, to enforce model thinking, the default chat template automatically includes &lt;code&gt;&amp;lt;think&amp;gt;&lt;/code&gt;. Therefore, it is normal for the model's output to contain only &lt;code&gt;&amp;lt;/think&amp;gt;&lt;/code&gt; without an explicit opening &lt;code&gt;&amp;lt;think&amp;gt;&lt;/code&gt; tag.&lt;/p&gt; 
 &lt;p&gt;Qwen3-Thinking-2507 also features an increased thinking length. We strongly recommend its use in highly complex reasoning tasks with adequate maximum generation length.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;b&gt;Switching Thinking/Non-thinking Modes for Previous Qwen3 Models&lt;/b&gt;&lt;/summary&gt; 
 &lt;p&gt; By default, Qwen3 models will think before response. This could be controlled by &lt;/p&gt;
 &lt;ul&gt; 
  &lt;li&gt;&lt;code&gt;enable_thinking=False&lt;/code&gt;: Passing &lt;code&gt;enable_thinking=False&lt;/code&gt; to `tokenizer.apply_chat_template` will strictly prevent the model from generating thinking content.&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;/think&lt;/code&gt; and &lt;code&gt;/no_think&lt;/code&gt; instructions: Use those words in the system or user message to signify whether Qwen3 should think. In multi-turn conversations, the latest instruction is followed.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;/p&gt; 
&lt;/details&gt; 
&lt;h3&gt;ModelScope&lt;/h3&gt; 
&lt;p&gt;We strongly advise users especially those in mainland China to use ModelScope. ModelScope adopts a Python API similar to Transformers. The CLI tool &lt;code&gt;modelscope download&lt;/code&gt; can help you solve issues concerning downloading checkpoints. For vLLM and SGLang, the environment variable &lt;code&gt;VLLM_USE_MODELSCOPE=true&lt;/code&gt; and &lt;code&gt;SGLANG_USE_MODELSCOPE=true&lt;/code&gt; can be used respectively.&lt;/p&gt; 
&lt;h3&gt;llama.cpp&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://github.com/ggml-org/llama.cpp"&gt;&lt;code&gt;llama.cpp&lt;/code&gt;&lt;/a&gt; enables LLM inference with minimal setup and state-of-the-art performance on a wide range of hardware. &lt;code&gt;llama.cpp&amp;gt;=b5401&lt;/code&gt; is recommended for the full support of Qwen3.&lt;/p&gt; 
&lt;p&gt;To use the CLI, run the following in a terminal:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;./llama-cli -hf Qwen/Qwen3-8B-GGUF:Q8_0 --jinja --color -ngl 99 -fa -sm row --temp 0.6 --top-k 20 --top-p 0.95 --min-p 0 -c 40960 -n 32768 --no-context-shift
# CTRL+C to exit
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To use the API server, run the following in a terminal:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;./llama-server -hf Qwen/Qwen3-8B-GGUF:Q8_0 --jinja --reasoning-format deepseek -ngl 99 -fa -sm row --temp 0.6 --top-k 20 --top-p 0.95 --min-p 0 -c 40960 -n 32768 --no-context-shift --port 8080
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;A simple web front end will be at &lt;code&gt;http://localhost:8080&lt;/code&gt; and an OpenAI-compatible API will be at &lt;code&gt;http://localhost:8080/v1&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;For additional guides, please refer to &lt;a href="https://qwen.readthedocs.io/en/latest/run_locally/llama.cpp.html"&gt;our documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!Note] llama.cpp adopts "rotating context management" and infinite generation is made possible by evicting earlier tokens. It could configured by parameters and the commands above effectively disable it. For more details, please refer to &lt;a href="https://qwen.readthedocs.io/en/latest/run_locally/llama.cpp.html#llama-cli"&gt;our documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Ollama&lt;/h3&gt; 
&lt;p&gt;After &lt;a href="https://ollama.com/"&gt;installing Ollama&lt;/a&gt;, you can initiate the Ollama service with the following command (Ollama v0.9.0 or higher is recommended):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;ollama serve
# You need to keep this service running whenever you are using ollama
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To pull a model checkpoint and run the model, use the &lt;code&gt;ollama run&lt;/code&gt; command. You can specify a model size by adding a suffix to &lt;code&gt;qwen3&lt;/code&gt;, such as &lt;code&gt;:8b&lt;/code&gt; or &lt;code&gt;:30b-a3b&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;ollama run qwen3:8b
# Setting parameters, type "/set parameter num_ctx 40960" and "/set parameter num_predict 32768"
# To exit, type "/bye" and press ENTER
# For Qwen3-2504 models,
# - To enable thinking, which is the default, type "/set think"
# - To disable thinking, type "/set nothink"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can also access the Ollama service via its OpenAI-compatible API. Please note that you need to (1) keep &lt;code&gt;ollama serve&lt;/code&gt; running while using the API, and (2) execute &lt;code&gt;ollama run qwen3:8b&lt;/code&gt; before utilizing this API to ensure that the model checkpoint is prepared. The API is at &lt;code&gt;http://localhost:11434/v1/&lt;/code&gt; by default.&lt;/p&gt; 
&lt;p&gt;For additional details, please visit &lt;a href="https://ollama.com/"&gt;ollama.ai&lt;/a&gt;.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!Note] Ollama's naming may not be consistent with the Qwen's original naming. For example, &lt;code&gt;qwen3:30b-a3b&lt;/code&gt; in Ollama points to &lt;code&gt;qwen3:30b-a3b-thinking-2507-q4_K_M&lt;/code&gt; as of August 2025. Please check &lt;a href="https://ollama.com/library/qwen3/tags"&gt;https://ollama.com/library/qwen3/tags&lt;/a&gt; before use.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!Note] Ollama adopts the same "rotating context management" with llama.cpp. However, its default settings (&lt;code&gt;num_ctx&lt;/code&gt; 2048 and &lt;code&gt;num_predict&lt;/code&gt; -1), suggesting infinite generation with a 2048-token context, could lead to trouble for Qwen3 models. We recommend setting &lt;code&gt;num_ctx&lt;/code&gt; and &lt;code&gt;num_predict&lt;/code&gt; properly.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;LMStudio&lt;/h3&gt; 
&lt;p&gt;Qwen3 has already been supported by &lt;a href="https://lmstudio.ai/"&gt;lmstudio.ai&lt;/a&gt;. You can directly use LMStudio with our GGUF files.&lt;/p&gt; 
&lt;h3&gt;ExecuTorch&lt;/h3&gt; 
&lt;p&gt;To export and run on ExecuTorch (iOS, Android, Mac, Linux, and more), please follow this &lt;a href="https://github.com/pytorch/executorch/raw/main/examples/models/qwen3/README.md"&gt;example&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;MNN&lt;/h3&gt; 
&lt;p&gt;To export and run on MNN, which supports Qwen3 on mobile devices, please visit &lt;a href="https://github.com/alibaba/MNN"&gt;Alibaba MNN&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;MLX LM&lt;/h3&gt; 
&lt;p&gt;If you are running on Apple Silicon, &lt;a href="https://github.com/ml-explore/mlx-lm"&gt;&lt;code&gt;mlx-lm&lt;/code&gt;&lt;/a&gt; also supports Qwen3 (&lt;code&gt;mlx-lm&amp;gt;=0.24.0&lt;/code&gt;). Look for models ending with MLX on Hugging Face Hub.&lt;/p&gt; 
&lt;h3&gt;OpenVINO&lt;/h3&gt; 
&lt;p&gt;If you are running on Intel CPU or GPU, &lt;a href="https://github.com/openvinotoolkit"&gt;OpenVINO toolkit&lt;/a&gt; supports Qwen3. You can follow this &lt;a href="https://github.com/openvinotoolkit/openvino_notebooks/raw/latest/notebooks/llm-chatbot/llm-chatbot.ipynb"&gt;chatbot example&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Deploy Qwen3&lt;/h2&gt; 
&lt;p&gt;Qwen3 is supported by multiple inference frameworks. Here we demonstrate the usage of &lt;code&gt;SGLang&lt;/code&gt;, &lt;code&gt;vLLM&lt;/code&gt; and &lt;code&gt;TensorRT-LLM&lt;/code&gt;. You can also find Qwen3 models from various inference providers, e.g., &lt;a href="https://www.alibabacloud.com/en/product/modelstudio"&gt;Alibaba Cloud Model Studio&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;SGLang&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://github.com/sgl-project/sglang"&gt;SGLang&lt;/a&gt; is a fast serving framework for large language models and vision language models. SGLang could be used to launch a server with OpenAI-compatible API service. &lt;code&gt;sglang&amp;gt;=0.4.6.post1&lt;/code&gt; is required.&lt;/p&gt; 
&lt;p&gt;For Qwen3-Instruct-2507,&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;python -m sglang.launch_server --model-path Qwen/Qwen3-30B-A3B-Instruct-2507 --port 30000 --context-length 262144
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For Qwen3-Thinking-2507,&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;python -m sglang.launch_server --model-path Qwen/Qwen3-30B-A3B-Thinking-2507 --port 30000 --context-length 262144 --reasoning-parser deepseek-r1
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For Qwen3, it is&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;python -m sglang.launch_server --model-path Qwen/Qwen3-8B --port 30000 --context-length 131072 --reasoning-parser qwen3
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;An OpenAI-compatible API will be available at &lt;code&gt;http://localhost:30000/v1&lt;/code&gt;.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!Note] Due to the preprocessing of API requests in SGLang, which drops all &lt;code&gt;reasoning_content&lt;/code&gt; fields, the quality of &lt;strong&gt;multi-step tool use with Qwen3 thinking models&lt;/strong&gt; may be suboptimal, which requires the existence of the related thinking content. While the fixes are being worked on, as a workdaround, we recommend passing the content as it is, without extracting thinking content, and the chat template will correctly handle the processing.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;vLLM&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://github.com/vllm-project/vllm"&gt;vLLM&lt;/a&gt; is a high-throughput and memory-efficient inference and serving engine for LLMs. &lt;code&gt;vllm&amp;gt;=0.9.0&lt;/code&gt; is recommended.&lt;/p&gt; 
&lt;p&gt;For Qwen3-Instruct-2507,&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;vllm serve Qwen/Qwen3-30B-A3B-Instruct-2507 --port 8000 --max-model-len 262144
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For Qwen3-Thinking-2507,&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;vllm serve Qwen/Qwen3-30B-A3B-Thinking-2507 --port 8000 --max-model-len 262144 --enable-reasoning --reasoning-parser deepseek_r1
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For Qwen3, it is&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;vllm serve Qwen/Qwen3-8B --port 8000 --max-model-len 131072 --enable-reasoning --reasoning-parser qwen3
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;An OpenAI-compatible API will be available at &lt;code&gt;http://localhost:8000/v1&lt;/code&gt;.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!Note] Due to the preprocessing of API requests in vLLM, which drops all &lt;code&gt;reasoning_content&lt;/code&gt; fields, the quality of &lt;strong&gt;multi-step tool use with Qwen3 thinking models&lt;/strong&gt; may be suboptimal, which requires the existence of the related thinking content. While the fixes are being worked on, as a workdaround, we recommend passing the content as it is, without extracting thinking content, and the chat template will correctly handle the processing.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;TensorRT-LLM&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://github.com/NVIDIA/TensorRT-LLM"&gt;TensorRT-LLM&lt;/a&gt; is an open-source LLM inference engine from NVIDIA, which provides optimizations including custom attention kernels, quantization and more on NVIDIA GPUs. Qwen3 is supported in its re-architected &lt;a href="https://nvidia.github.io/TensorRT-LLM/torch.html"&gt;PyTorch backend&lt;/a&gt;. &lt;code&gt;tensorrt_llm&amp;gt;=0.20.0rc3&lt;/code&gt; is recommended. Please refer to the &lt;a href="https://github.com/NVIDIA/TensorRT-LLM/raw/main/examples/models/core/qwen/README.md#qwen3"&gt;README&lt;/a&gt; page for more details.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;trtllm-serve Qwen/Qwen3-8B --host localhost --port 8000 --backend pytorch
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;An OpenAI-compatible API will be available at &lt;code&gt;http://localhost:8000/v1&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;MindIE&lt;/h3&gt; 
&lt;p&gt;For deployment on Ascend NPUs, please visit &lt;a href="https://modelers.cn/"&gt;Modelers&lt;/a&gt; and search for Qwen3.&lt;/p&gt; 
&lt;!-- 
### OpenLLM

[OpenLLM](https://github.com/bentoml/OpenLLM) allows you to easily run Qwen2.5 as OpenAI-compatible APIs. You can start a model server using `openllm serve`. For example:

```bash
openllm serve qwen2.5:7b
```

The server is active at `http://localhost:3000/`, providing OpenAI-compatible APIs. You can create an OpenAI client to call its chat API. For more information, refer to [our documentation](https://qwen.readthedocs.io/en/latest/deployment/openllm.html). --&gt; 
&lt;h2&gt;Build with Qwen3&lt;/h2&gt; 
&lt;h3&gt;Tool Use&lt;/h3&gt; 
&lt;p&gt;For tool use capabilities, we recommend taking a look at &lt;a href="https://github.com/QwenLM/Qwen-Agent"&gt;Qwen-Agent&lt;/a&gt;, which provides a wrapper around these APIs to support tool use or function calling with MCP support. Tool use with Qwen3 can also be conducted with SGLang, vLLM, Transformers, llama.cpp, Ollama, etc. Follow guides in our documentation to see how to enable the support.&lt;/p&gt; 
&lt;h3&gt;Finetuning&lt;/h3&gt; 
&lt;p&gt;We advise you to use training frameworks, including &lt;a href="https://github.com/OpenAccess-AI-Collective/axolotl"&gt;Axolotl&lt;/a&gt;, &lt;a href="https://github.com/unslothai/unsloth"&gt;UnSloth&lt;/a&gt;, &lt;a href="https://github.com/modelscope/swift"&gt;Swift&lt;/a&gt;, &lt;a href="https://github.com/hiyouga/LLaMA-Factory"&gt;Llama-Factory&lt;/a&gt;, etc., to finetune your models with SFT, DPO, GRPO, etc.&lt;/p&gt; 
&lt;h2&gt;License Agreement&lt;/h2&gt; 
&lt;p&gt;All our open-weight models are licensed under Apache 2.0. You can find the license files in the respective Hugging Face repositories.&lt;/p&gt; 
&lt;h2&gt;Citation&lt;/h2&gt; 
&lt;p&gt;If you find our work helpful, feel free to give us a cite.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bibtex"&gt;@article{qwen3,
    title={Qwen3 Technical Report}, 
    author={An Yang and Anfeng Li and Baosong Yang and Beichen Zhang and Binyuan Hui and Bo Zheng and Bowen Yu and Chang Gao and Chengen Huang and Chenxu Lv and Chujie Zheng and Dayiheng Liu and Fan Zhou and Fei Huang and Feng Hu and Hao Ge and Haoran Wei and Huan Lin and Jialong Tang and Jian Yang and Jianhong Tu and Jianwei Zhang and Jianxin Yang and Jiaxi Yang and Jing Zhou and Jingren Zhou and Junyang Lin and Kai Dang and Keqin Bao and Kexin Yang and Le Yu and Lianghao Deng and Mei Li and Mingfeng Xue and Mingze Li and Pei Zhang and Peng Wang and Qin Zhu and Rui Men and Ruize Gao and Shixuan Liu and Shuang Luo and Tianhao Li and Tianyi Tang and Wenbiao Yin and Xingzhang Ren and Xinyu Wang and Xinyu Zhang and Xuancheng Ren and Yang Fan and Yang Su and Yichang Zhang and Yinger Zhang and Yu Wan and Yuqiong Liu and Zekun Wang and Zeyu Cui and Zhenru Zhang and Zhipeng Zhou and Zihan Qiu},
    journal = {arXiv preprint arXiv:2505.09388},
    year={2025}
}

@article{qwen2.5,
    title   = {Qwen2.5 Technical Report}, 
    author  = {An Yang and Baosong Yang and Beichen Zhang and Binyuan Hui and Bo Zheng and Bowen Yu and Chengyuan Li and Dayiheng Liu and Fei Huang and Haoran Wei and Huan Lin and Jian Yang and Jianhong Tu and Jianwei Zhang and Jianxin Yang and Jiaxi Yang and Jingren Zhou and Junyang Lin and Kai Dang and Keming Lu and Keqin Bao and Kexin Yang and Le Yu and Mei Li and Mingfeng Xue and Pei Zhang and Qin Zhu and Rui Men and Runji Lin and Tianhao Li and Tingyu Xia and Xingzhang Ren and Xuancheng Ren and Yang Fan and Yang Su and Yichang Zhang and Yu Wan and Yuqiong Liu and Zeyu Cui and Zhenru Zhang and Zihan Qiu},
    journal = {arXiv preprint arXiv:2412.15115},
    year    = {2024}
}

@article{qwen2,
    title   = {Qwen2 Technical Report}, 
    author  = {An Yang and Baosong Yang and Binyuan Hui and Bo Zheng and Bowen Yu and Chang Zhou and Chengpeng Li and Chengyuan Li and Dayiheng Liu and Fei Huang and Guanting Dong and Haoran Wei and Huan Lin and Jialong Tang and Jialin Wang and Jian Yang and Jianhong Tu and Jianwei Zhang and Jianxin Ma and Jin Xu and Jingren Zhou and Jinze Bai and Jinzheng He and Junyang Lin and Kai Dang and Keming Lu and Keqin Chen and Kexin Yang and Mei Li and Mingfeng Xue and Na Ni and Pei Zhang and Peng Wang and Ru Peng and Rui Men and Ruize Gao and Runji Lin and Shijie Wang and Shuai Bai and Sinan Tan and Tianhang Zhu and Tianhao Li and Tianyu Liu and Wenbin Ge and Xiaodong Deng and Xiaohuan Zhou and Xingzhang Ren and Xinyu Zhang and Xipin Wei and Xuancheng Ren and Yang Fan and Yang Yao and Yichang Zhang and Yu Wan and Yunfei Chu and Yuqiong Liu and Zeyu Cui and Zhenru Zhang and Zhihao Fan},
    journal = {arXiv preprint arXiv:2407.10671},
    year    = {2024}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Contact Us&lt;/h2&gt; 
&lt;p&gt;If you are interested to leave a message to either our research team or product team, join our &lt;a href="https://discord.gg/z3GAxXZ9Ce"&gt;Discord&lt;/a&gt; or &lt;a href="https://raw.githubusercontent.com/QwenLM/Qwen3/main/assets/wechat.png"&gt;WeChat groups&lt;/a&gt;!&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>mxrch/GHunt</title>
      <link>https://github.com/mxrch/GHunt</link>
      <description>&lt;p&gt;🕵️‍♂️ Offensive Google framework.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/mxrch/GHunt/master/assets/long_banner.png" alt="" /&gt;&lt;/p&gt; 
&lt;br /&gt; 
&lt;h4&gt;🌐 GHunt Online version : &lt;a href="https://osint.industries"&gt;https://osint.industries&lt;/a&gt;&lt;/h4&gt; 
&lt;h4&gt;🐍 Now Python 3.13 compatible !&lt;/h4&gt; 
&lt;br /&gt; 
&lt;p&gt;&lt;img src="https://img.shields.io/badge/Python-3.10%2B-brightgreen" alt="Python minimum version" /&gt;&lt;/p&gt; 
&lt;h1&gt;😊 Description&lt;/h1&gt; 
&lt;p&gt;GHunt (v2) is an offensive Google framework, designed to evolve efficiently.&lt;br /&gt; It's currently focused on OSINT, but any use related with Google is possible.&lt;/p&gt; 
&lt;p&gt;Features :&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;CLI usage and modules&lt;/li&gt; 
 &lt;li&gt;Python library usage&lt;/li&gt; 
 &lt;li&gt;Fully async&lt;/li&gt; 
 &lt;li&gt;JSON export&lt;/li&gt; 
 &lt;li&gt;Browser extension to ease login&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;✔️ Requirements&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;Python &amp;gt;= 3.10&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;⚙️ Installation&lt;/h1&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;$ pip3 install pipx
$ pipx ensurepath
$ pipx install ghunt
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;It will automatically use venvs to avoid dependency conflicts with other projects.&lt;/p&gt; 
&lt;h1&gt;💃 Usage&lt;/h1&gt; 
&lt;h2&gt;Login&lt;/h2&gt; 
&lt;p&gt;First, launch the listener by doing &lt;code&gt;ghunt login&lt;/code&gt; and choose between 1 of the 2 first methods :&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;$ ghunt login

[1] (Companion) Put GHunt on listening mode (currently not compatible with docker)
[2] (Companion) Paste base64-encoded cookies
[3] Enter manually all cookies

Choice =&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then, use GHunt Companion to complete the login.&lt;/p&gt; 
&lt;p&gt;The extension is available on the following stores :&lt;br /&gt; &lt;br /&gt; &lt;a href="https://addons.mozilla.org/en-US/firefox/addon/ghunt-companion/"&gt;&lt;img src="https://files.catbox.moe/5g2ld5.png" alt="Firefox" /&gt;&lt;/a&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;a href="https://chrome.google.com/webstore/detail/ghunt-companion/dpdcofblfbmmnikcbmmiakkclocadjab"&gt;&lt;img src="https://developer.chrome.com/static/docs/webstore/branding/image/206x58-chrome-web-bcb82d15b2486.png" alt="Chrome" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Modules&lt;/h2&gt; 
&lt;p&gt;Then, profit :&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;Usage: ghunt [-h] {login,email,gaia,drive,geolocate} ...

Positional Arguments:
  {login,email,gaia,drive,geolocate}
    login               Authenticate GHunt to Google.
    email               Get information on an email address.
    gaia                Get information on a Gaia ID.
    drive               Get information on a Drive file or folder.
    geolocate           Geolocate a BSSID.
    spiderdal           Find assets using Digital Assets Links.

Options:
  -h, --help            show this help message and exit
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;📄 You can also use --json with email, gaia, drive and geolocate modules to export in JSON ! Example :&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;$ ghunt email &amp;lt;email_address&amp;gt; --json user_data.json
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Have fun 🥰💞&lt;/strong&gt;&lt;/p&gt; 
&lt;h1&gt;🧑‍💻 Developers&lt;/h1&gt; 
&lt;p&gt;📕 I started writing some docs &lt;a href="https://github.com/mxrch/GHunt/wiki"&gt;here&lt;/a&gt; and examples &lt;a href="https://github.com/mxrch/GHunt/tree/master/examples"&gt;here&lt;/a&gt;, feel free to contribute !&lt;/p&gt; 
&lt;p&gt;To use GHunt as a lib, you can't use pipx because it uses a venv.&lt;br /&gt; So you should install GHunt with pip :&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;$ pip3 install ghunt
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;And now, you should be able to &lt;code&gt;import ghunt&lt;/code&gt; in your projects !&lt;br /&gt; You can right now play with the &lt;a href="https://github.com/mxrch/GHunt/tree/master/examples"&gt;examples&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;📮 Details&lt;/h1&gt; 
&lt;h2&gt;Obvious disclaimer&lt;/h2&gt; 
&lt;p&gt;This tool is for educational purposes only, I am not responsible for its use.&lt;/p&gt; 
&lt;h2&gt;Less obvious disclaimer&lt;/h2&gt; 
&lt;p&gt;This project is under &lt;a href="https://choosealicense.com/licenses/agpl-3.0/"&gt;AGPL Licence&lt;/a&gt;, and you have to respect it.&lt;br /&gt; &lt;strong&gt;Use it only in personal, criminal investigations, pentesting, or open-source projects.&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;Thanks&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/novitae"&gt;novitae&lt;/a&gt; for being my Python colleague&lt;/li&gt; 
 &lt;li&gt;All the people on &lt;a href="https://discord.gg/sg2YcrC6x9"&gt;Malfrats Industries&lt;/a&gt; and elsewhere for the beta test !&lt;/li&gt; 
 &lt;li&gt;The HideAndSec team 💗 (blog : &lt;a href="https://hideandsec.sh"&gt;https://hideandsec.sh&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://dribbble.com/jouiniamine"&gt;Med Amine Jouini&lt;/a&gt; for his beautiful rework of the Google logo, which I was inspired by &lt;em&gt;a lot&lt;/em&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Sponsors&lt;/h2&gt; 
&lt;p&gt;Thanks to these awesome people for supporting me !&lt;/p&gt; 
&lt;!-- sponsors --&gt;
&lt;a href="https://github.com/BlWasp"&gt;&lt;img src="https://github.com/BlWasp.png" width="50px" alt="BlWasp" /&gt;&lt;/a&gt;&amp;nbsp;&amp;nbsp;
&lt;a href="https://github.com/gingeleski"&gt;&lt;img src="https://github.com/gingeleski.png" width="50px" alt="gingeleski" /&gt;&lt;/a&gt;&amp;nbsp;&amp;nbsp;
&lt;a href="https://github.com/ADS-Fund"&gt;&lt;img src="https://github.com/ADS-Fund.png" width="50px" alt="ADS-Fund" /&gt;&lt;/a&gt;&amp;nbsp;&amp;nbsp;
&lt;!-- sponsors --&gt; 
&lt;p&gt;&lt;br /&gt; You like my work ?&lt;br /&gt; &lt;a href="https://github.com/sponsors/mxrch"&gt;Sponsor me&lt;/a&gt; on GitHub ! 🤗&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>HKUDS/AutoAgent</title>
      <link>https://github.com/HKUDS/AutoAgent</link>
      <description>&lt;p&gt;"AutoAgent: Fully-Automated and Zero-Code LLM Agent Framework"&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a name="readme-top"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/HKUDS/AutoAgent/main/assets/AutoAgent_logo.svg?sanitize=true" alt="Logo" width="200" /&gt; 
 &lt;h1 align="center"&gt;AutoAgent: Fully-Automated &amp;amp; Zero-Code&lt;br /&gt; LLM Agent Framework &lt;/h1&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://autoagent-ai.github.io"&gt;&lt;img src="https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&amp;amp;color=FFE165&amp;amp;logo=homepage&amp;amp;logoColor=white" alt="Credits" /&gt;&lt;/a&gt; 
 &lt;a href="https://join.slack.com/t/metachain-workspace/shared_invite/zt-2zibtmutw-v7xOJObBf9jE2w3x7nctFQ"&gt;&lt;img src="https://img.shields.io/badge/Slack-Join%20Us-red?logo=slack&amp;amp;logoColor=white&amp;amp;style=for-the-badge" alt="Join our Slack community" /&gt;&lt;/a&gt; 
 &lt;a href="https://discord.gg/jQJdXyDB"&gt;&lt;img src="https://img.shields.io/badge/Discord-Join%20Us-purple?logo=discord&amp;amp;logoColor=white&amp;amp;style=for-the-badge" alt="Join our Discord community" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/HKUDS/AutoAgent/raw/main/assets/autoagent-wechat.jpg"&gt;&lt;img src="https://img.shields.io/badge/Wechat-Join%20Us-green?logo=wechat&amp;amp;logoColor=white&amp;amp;style=for-the-badge" alt="Join our Wechat community" /&gt;&lt;/a&gt; 
 &lt;br /&gt; 
 &lt;a href="https://autoagent-ai.github.io/docs"&gt;&lt;img src="https://img.shields.io/badge/Documentation-000?logo=googledocs&amp;amp;logoColor=FFE165&amp;amp;style=for-the-badge" alt="Check out the documentation" /&gt;&lt;/a&gt; 
 &lt;a href="https://arxiv.org/abs/2502.05957"&gt;&lt;img src="https://img.shields.io/badge/Paper%20on%20Arxiv-000?logoColor=FFE165&amp;amp;logo=arxiv&amp;amp;style=for-the-badge" alt="Paper" /&gt;&lt;/a&gt; 
 &lt;a href="https://gaia-benchmark-leaderboard.hf.space/"&gt;&lt;img src="https://img.shields.io/badge/GAIA%20Benchmark-000?logoColor=FFE165&amp;amp;logo=huggingface&amp;amp;style=for-the-badge" alt="Evaluation Benchmark Score" /&gt;&lt;/a&gt; 
 &lt;hr /&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://trendshift.io/repositories/13954" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/13954" alt="HKUDS%2FAutoAgent | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt; 
&lt;/div&gt; 
&lt;p&gt;Welcome to AutoAgent! AutoAgent is a &lt;strong&gt;Fully-Automated&lt;/strong&gt; and highly &lt;strong&gt;Self-Developing&lt;/strong&gt; framework that enables users to create and deploy LLM agents through &lt;strong&gt;Natural Language Alone&lt;/strong&gt;.&lt;/p&gt; 
&lt;h2&gt;✨Key Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;🏆 Top Performers on the GAIA Benchmark &lt;br /&gt;AutoAgent has delivering comparable performance to many &lt;strong&gt;Deep Research Agents&lt;/strong&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;✨ Agent and Workflow Create with Ease &lt;br /&gt;AutoAgent leverages natural language to effortlessly build ready-to-use &lt;strong&gt;tools&lt;/strong&gt;, &lt;strong&gt;agents&lt;/strong&gt; and &lt;strong&gt;workflows&lt;/strong&gt; - no coding required.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;📚 Agentic-RAG with Native Self-Managing Vector Database &lt;br /&gt;AutoAgent equipped with a native self-managing vector database, outperforms industry-leading solutions like &lt;strong&gt;LangChain&lt;/strong&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;🌐 Universal LLM Support &lt;br /&gt;AutoAgent seamlessly integrates with &lt;strong&gt;A Wide Range&lt;/strong&gt; of LLMs (e.g., OpenAI, Anthropic, Deepseek, vLLM, Grok, Huggingface ...)&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;🔀 Flexible Interaction &lt;br /&gt;Benefit from support for both &lt;strong&gt;function-calling&lt;/strong&gt; and &lt;strong&gt;ReAct&lt;/strong&gt; interaction modes.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;🤖 Dynamic, Extensible, Lightweight &lt;br /&gt;AutoAgent is your &lt;strong&gt;Personal AI Assistant&lt;/strong&gt;, designed to be dynamic, extensible, customized, and lightweight.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;🚀 Unlock the Future of LLM Agents. Try 🔥AutoAgent🔥 Now!&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;!-- &lt;img src="./assets/AutoAgentnew-intro.pdf" alt="Logo" width="100%"&gt; --&gt; 
 &lt;figure&gt; 
  &lt;img src="https://raw.githubusercontent.com/HKUDS/AutoAgent/main/assets/autoagent-intro.svg?sanitize=true" alt="Logo" style="max-width: 100%; height: auto;" /&gt; 
  &lt;figcaption&gt;
   &lt;em&gt;Quick Overview of AutoAgent.&lt;/em&gt;
  &lt;/figcaption&gt; 
 &lt;/figure&gt; 
&lt;/div&gt; 
&lt;h2&gt;🔥 News&lt;/h2&gt; 
&lt;div class="scrollable"&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;[2025, Feb 17]&lt;/strong&gt;: &amp;nbsp;🎉🎉We've updated and released AutoAgent v0.2.0 (formerly known as MetaChain). Detailed changes include: 1) fix the bug of different LLM providers from issues; 2) add automatic installation of AutoAgent in the container environment according to issues; 3) add more easy-to-use commands for the CLI mode. 4) Rename the project to AutoAgent for better understanding.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;[2025, Feb 10]&lt;/strong&gt;: &amp;nbsp;🎉🎉We've released &lt;b&gt;MetaChain!&lt;/b&gt;, including framework, evaluation codes and CLI mode! Check our &lt;a href="https://arxiv.org/abs/2502.05957"&gt;paper&lt;/a&gt; for more details.&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/div&gt; 
&lt;span id="table-of-contents"&gt;&lt;/span&gt; 
&lt;h2&gt;📑 Table of Contents&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/AutoAgent/main/#features"&gt;✨ Features&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/AutoAgent/main/#news"&gt;🔥 News&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/AutoAgent/main/#how-to-use"&gt;🔍 How to Use AutoAgent&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/AutoAgent/main/#user-mode"&gt;1. &lt;code&gt;user mode&lt;/code&gt; (SOTA 🏆 Open Deep Research)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/AutoAgent/main/#agent-editor"&gt;2. &lt;code&gt;agent editor&lt;/code&gt; (Agent Creation without Workflow)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/AutoAgent/main/#workflow-editor"&gt;3. &lt;code&gt;workflow editor&lt;/code&gt; (Agent Creation with Workflow)&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/AutoAgent/main/#quick-start"&gt;⚡ Quick Start&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/AutoAgent/main/#installation"&gt;Installation&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/AutoAgent/main/#api-keys-setup"&gt;API Keys Setup&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/AutoAgent/main/#start-with-cli-mode"&gt;Start with CLI Mode&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/AutoAgent/main/#todo"&gt;☑️ Todo List&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/AutoAgent/main/#reproduce"&gt;🔬 How To Reproduce the Results in the Paper&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/AutoAgent/main/#documentation"&gt;📖 Documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/AutoAgent/main/#community"&gt;🤝 Join the Community&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/AutoAgent/main/#acknowledgements"&gt;🙏 Acknowledgements&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/AutoAgent/main/#cite"&gt;🌟 Cite&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id="how-to-use"&gt;&lt;/span&gt; 
&lt;h2&gt;🔍 How to Use AutoAgent&lt;/h2&gt; 
&lt;span id="user-mode"&gt;&lt;/span&gt; 
&lt;h3&gt;1. &lt;code&gt;user mode&lt;/code&gt; (SOTA 🏆 Open Deep Research)&lt;/h3&gt; 
&lt;p&gt;AutoAgent have an out-of-the-box multi-agent system, which you could choose &lt;code&gt;user mode&lt;/code&gt; in the start page to use it. This multi-agent system is a general AI assistant, having the same functionality with &lt;strong&gt;OpenAI's Deep Research&lt;/strong&gt; and the comparable performance with it in &lt;a href="https://gaia-benchmark-leaderboard.hf.space/"&gt;GAIA&lt;/a&gt; benchmark.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;🚀 &lt;strong&gt;High Performance&lt;/strong&gt;: Matches Deep Research using Claude 3.5 rather than OpenAI's o3 model.&lt;/li&gt; 
 &lt;li&gt;🔄 &lt;strong&gt;Model Flexibility&lt;/strong&gt;: Compatible with any LLM (including Deepseek-R1, Grok, Gemini, etc.)&lt;/li&gt; 
 &lt;li&gt;💰 &lt;strong&gt;Cost-Effective&lt;/strong&gt;: Open-source alternative to Deep Research's $200/month subscription&lt;/li&gt; 
 &lt;li&gt;🎯 &lt;strong&gt;User-Friendly&lt;/strong&gt;: Easy-to-deploy CLI interface for seamless interaction&lt;/li&gt; 
 &lt;li&gt;📁 &lt;strong&gt;File Support&lt;/strong&gt;: Handles file uploads for enhanced data interaction&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div align="center"&gt; 
 &lt;video width="80%" controls&gt; 
  &lt;source src="./assets/video_v1_compressed.mp4" type="video/mp4" /&gt; 
 &lt;/video&gt; 
 &lt;p&gt;&lt;em&gt;🎥 Deep Research (aka User Mode)&lt;/em&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;span id="agent-editor"&gt;&lt;/span&gt; 
&lt;h3&gt;2. &lt;code&gt;agent editor&lt;/code&gt; (Agent Creation without Workflow)&lt;/h3&gt; 
&lt;p&gt;The most distinctive feature of AutoAgent is its natural language customization capability. Unlike other agent frameworks, AutoAgent allows you to create tools, agents, and workflows using natural language alone. Simply choose &lt;code&gt;agent editor&lt;/code&gt; or &lt;code&gt;workflow editor&lt;/code&gt; mode to start your journey of building agents through conversations.&lt;/p&gt; 
&lt;p&gt;You can use &lt;code&gt;agent editor&lt;/code&gt; as shown in the following figure.&lt;/p&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr align="center"&gt; 
   &lt;td width="33%"&gt; &lt;img src="https://raw.githubusercontent.com/HKUDS/AutoAgent/main/assets/agent_editor/1-requirement.png" alt="requirement" width="100%" /&gt; &lt;br /&gt; &lt;em&gt;Input what kind of agent you want to create.&lt;/em&gt; &lt;/td&gt; 
   &lt;td width="33%"&gt; &lt;img src="https://raw.githubusercontent.com/HKUDS/AutoAgent/main/assets/agent_editor/2-profiling.png" alt="profiling" width="100%" /&gt; &lt;br /&gt; &lt;em&gt;Automated agent profiling.&lt;/em&gt; &lt;/td&gt; 
   &lt;td width="33%"&gt; &lt;img src="https://raw.githubusercontent.com/HKUDS/AutoAgent/main/assets/agent_editor/3-profiles.png" alt="profiles" width="100%" /&gt; &lt;br /&gt; &lt;em&gt;Output the agent profiles.&lt;/em&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr align="center"&gt; 
   &lt;td width="33%"&gt; &lt;img src="https://raw.githubusercontent.com/HKUDS/AutoAgent/main/assets/agent_editor/4-tools.png" alt="tools" width="100%" /&gt; &lt;br /&gt; &lt;em&gt;Create the desired tools.&lt;/em&gt; &lt;/td&gt; 
   &lt;td width="33%"&gt; &lt;img src="https://raw.githubusercontent.com/HKUDS/AutoAgent/main/assets/agent_editor/5-task.png" alt="task" width="100%" /&gt; &lt;br /&gt; &lt;em&gt;Input what do you want to complete with the agent. (Optional)&lt;/em&gt; &lt;/td&gt; 
   &lt;td width="33%"&gt; &lt;img src="https://raw.githubusercontent.com/HKUDS/AutoAgent/main/assets/agent_editor/6-output-next.png" alt="output" width="100%" /&gt; &lt;br /&gt; &lt;em&gt;Create the desired agent(s) and go to the next step.&lt;/em&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;span id="workflow-editor"&gt;&lt;/span&gt; 
&lt;h3&gt;3. &lt;code&gt;workflow editor&lt;/code&gt; (Agent Creation with Workflow)&lt;/h3&gt; 
&lt;p&gt;You can also create the agent workflows using natural language description with the &lt;code&gt;workflow editor&lt;/code&gt; mode, as shown in the following figure. (Tips: this mode does not support tool creation temporarily.)&lt;/p&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr align="center"&gt; 
   &lt;td width="33%"&gt; &lt;img src="https://raw.githubusercontent.com/HKUDS/AutoAgent/main/assets/workflow_editor/1-requirement.png" alt="requirement" width="100%" /&gt; &lt;br /&gt; &lt;em&gt;Input what kind of workflow you want to create.&lt;/em&gt; &lt;/td&gt; 
   &lt;td width="33%"&gt; &lt;img src="https://raw.githubusercontent.com/HKUDS/AutoAgent/main/assets/workflow_editor/2-profiling.png" alt="profiling" width="100%" /&gt; &lt;br /&gt; &lt;em&gt;Automated workflow profiling.&lt;/em&gt; &lt;/td&gt; 
   &lt;td width="33%"&gt; &lt;img src="https://raw.githubusercontent.com/HKUDS/AutoAgent/main/assets/workflow_editor/3-profiles.png" alt="profiles" width="100%" /&gt; &lt;br /&gt; &lt;em&gt;Output the workflow profiles.&lt;/em&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr align="center"&gt; 
   &lt;td width="33%"&gt; &lt;img src="https://raw.githubusercontent.com/HKUDS/AutoAgent/main/assets/workflow_editor/4-task.png" alt="task" width="66%" /&gt; &lt;br /&gt; &lt;em&gt;Input what do you want to complete with the workflow. (Optional)&lt;/em&gt; &lt;/td&gt; 
   &lt;td width="33%"&gt; &lt;img src="https://raw.githubusercontent.com/HKUDS/AutoAgent/main/assets/workflow_editor/5-output-next.png" alt="output" width="66%" /&gt; &lt;br /&gt; &lt;em&gt;Create the desired workflow(s) and go to the next step.&lt;/em&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;span id="quick-start"&gt;&lt;/span&gt; 
&lt;h2&gt;⚡ Quick Start&lt;/h2&gt; 
&lt;span id="installation"&gt;&lt;/span&gt; 
&lt;h3&gt;Installation&lt;/h3&gt; 
&lt;h4&gt;AutoAgent Installation&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/HKUDS/AutoAgent.git
cd AutoAgent
pip install -e .
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Docker Installation&lt;/h4&gt; 
&lt;p&gt;We use Docker to containerize the agent-interactive environment. So please install &lt;a href="https://www.docker.com/"&gt;Docker&lt;/a&gt; first. You don't need to manually pull the pre-built image, because we have let Auto-Deep-Research &lt;strong&gt;automatically pull the pre-built image based on your architecture of your machine&lt;/strong&gt;.&lt;/p&gt; 
&lt;span id="api-keys-setup"&gt;&lt;/span&gt; 
&lt;h3&gt;API Keys Setup&lt;/h3&gt; 
&lt;p&gt;Create an environment variable file, just like &lt;code&gt;.env.template&lt;/code&gt;, and set the API keys for the LLMs you want to use. Not every LLM API Key is required, use what you need.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Required Github Tokens of your own
GITHUB_AI_TOKEN=

# Optional API Keys
OPENAI_API_KEY=
DEEPSEEK_API_KEY=
ANTHROPIC_API_KEY=
GEMINI_API_KEY=
HUGGINGFACE_API_KEY=
GROQ_API_KEY=
XAI_API_KEY=
&lt;/code&gt;&lt;/pre&gt; 
&lt;span id="start-with-cli-mode"&gt;&lt;/span&gt; 
&lt;h3&gt;Start with CLI Mode&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[🚨 &lt;strong&gt;News&lt;/strong&gt;: ] We have updated a more easy-to-use command to start the CLI mode and fix the bug of different LLM providers from issues. You can follow the following steps to start the CLI mode with different LLM providers with much less configuration.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;Command Options:&lt;/h4&gt; 
&lt;p&gt;You can run &lt;code&gt;auto main&lt;/code&gt; to start full part of AutoAgent, including &lt;code&gt;user mode&lt;/code&gt;, &lt;code&gt;agent editor&lt;/code&gt; and &lt;code&gt;workflow editor&lt;/code&gt;. Btw, you can also run &lt;code&gt;auto deep-research&lt;/code&gt; to start more lightweight &lt;code&gt;user mode&lt;/code&gt;, just like the &lt;a href="https://github.com/HKUDS/Auto-Deep-Research"&gt;Auto-Deep-Research&lt;/a&gt; project. Some configuration of this command is shown below.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;--container_name&lt;/code&gt;: Name of the Docker container (default: 'deepresearch')&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--port&lt;/code&gt;: Port for the container (default: 12346)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;COMPLETION_MODEL&lt;/code&gt;: Specify the LLM model to use, you should follow the name of &lt;a href="https://github.com/BerriAI/litellm"&gt;Litellm&lt;/a&gt; to set the model name. (Default: &lt;code&gt;claude-3-5-sonnet-20241022&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;DEBUG&lt;/code&gt;: Enable debug mode for detailed logs (default: False)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;API_BASE_URL&lt;/code&gt;: The base URL for the LLM provider (default: None)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;FN_CALL&lt;/code&gt;: Enable function calling (default: None). Most of time, you could ignore this option because we have already set the default value based on the model name.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;git_clone&lt;/code&gt;: Clone the AutoAgent repository to the local environment (only support with the &lt;code&gt;auto main&lt;/code&gt; command, default: True)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;test_pull_name&lt;/code&gt;: The name of the test pull. (only support with the &lt;code&gt;auto main&lt;/code&gt; command, default: 'autoagent_mirror')&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;More details about &lt;code&gt;git_clone&lt;/code&gt; and &lt;code&gt;test_pull_name&lt;/code&gt;]&lt;/h4&gt; 
&lt;p&gt;In the &lt;code&gt;agent editor&lt;/code&gt; and &lt;code&gt;workflow editor&lt;/code&gt; mode, we should clone a mirror of the AutoAgent repository to the local agent-interactive environment and let our &lt;strong&gt;AutoAgent&lt;/strong&gt; automatically update the AutoAgent itself, such as creating new tools, agents and workflows. So if you want to use the &lt;code&gt;agent editor&lt;/code&gt; and &lt;code&gt;workflow editor&lt;/code&gt; mode, you should set the &lt;code&gt;git_clone&lt;/code&gt; to True and set the &lt;code&gt;test_pull_name&lt;/code&gt; to 'autoagent_mirror' or other branches.&lt;/p&gt; 
&lt;h4&gt;&lt;code&gt;auto main&lt;/code&gt; with different LLM Providers&lt;/h4&gt; 
&lt;p&gt;Then I will show you how to use the full part of AutoAgent with the &lt;code&gt;auto main&lt;/code&gt; command and different LLM providers. If you want to use the &lt;code&gt;auto deep-research&lt;/code&gt; command, you can refer to the &lt;a href="https://github.com/HKUDS/Auto-Deep-Research"&gt;Auto-Deep-Research&lt;/a&gt; project for more details.&lt;/p&gt; 
&lt;h5&gt;Anthropic&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;set the &lt;code&gt;ANTHROPIC_API_KEY&lt;/code&gt; in the &lt;code&gt;.env&lt;/code&gt; file.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;ANTHROPIC_API_KEY=your_anthropic_api_key
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;run the following command to start Auto-Deep-Research.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;auto main # default model is claude-3-5-sonnet-20241022
&lt;/code&gt;&lt;/pre&gt; 
&lt;h5&gt;OpenAI&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;set the &lt;code&gt;OPENAI_API_KEY&lt;/code&gt; in the &lt;code&gt;.env&lt;/code&gt; file.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;OPENAI_API_KEY=your_openai_api_key
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;run the following command to start Auto-Deep-Research.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;COMPLETION_MODEL=gpt-4o auto main
&lt;/code&gt;&lt;/pre&gt; 
&lt;h5&gt;Mistral&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;set the &lt;code&gt;MISTRAL_API_KEY&lt;/code&gt; in the &lt;code&gt;.env&lt;/code&gt; file.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;MISTRAL_API_KEY=your_mistral_api_key
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;run the following command to start Auto-Deep-Research.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;COMPLETION_MODEL=mistral/mistral-large-2407 auto main
&lt;/code&gt;&lt;/pre&gt; 
&lt;h5&gt;Gemini - Google AI Studio&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;set the &lt;code&gt;GEMINI_API_KEY&lt;/code&gt; in the &lt;code&gt;.env&lt;/code&gt; file.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;GEMINI_API_KEY=your_gemini_api_key
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;run the following command to start Auto-Deep-Research.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;COMPLETION_MODEL=gemini/gemini-2.0-flash auto main
&lt;/code&gt;&lt;/pre&gt; 
&lt;h5&gt;Huggingface&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;set the &lt;code&gt;HUGGINGFACE_API_KEY&lt;/code&gt; in the &lt;code&gt;.env&lt;/code&gt; file.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;HUGGINGFACE_API_KEY=your_huggingface_api_key
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;run the following command to start Auto-Deep-Research.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;COMPLETION_MODEL=huggingface/meta-llama/Llama-3.3-70B-Instruct auto main
&lt;/code&gt;&lt;/pre&gt; 
&lt;h5&gt;Groq&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;set the &lt;code&gt;GROQ_API_KEY&lt;/code&gt; in the &lt;code&gt;.env&lt;/code&gt; file.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;GROQ_API_KEY=your_groq_api_key
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;run the following command to start Auto-Deep-Research.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;COMPLETION_MODEL=groq/deepseek-r1-distill-llama-70b auto main
&lt;/code&gt;&lt;/pre&gt; 
&lt;h5&gt;OpenAI-Compatible Endpoints (e.g., Grok)&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;set the &lt;code&gt;OPENAI_API_KEY&lt;/code&gt; in the &lt;code&gt;.env&lt;/code&gt; file.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;OPENAI_API_KEY=your_api_key_for_openai_compatible_endpoints
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;run the following command to start Auto-Deep-Research.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;COMPLETION_MODEL=openai/grok-2-latest API_BASE_URL=https://api.x.ai/v1 auto main
&lt;/code&gt;&lt;/pre&gt; 
&lt;h5&gt;OpenRouter (e.g., DeepSeek-R1)&lt;/h5&gt; 
&lt;p&gt;We recommend using OpenRouter as LLM provider of DeepSeek-R1 temporarily. Because official API of DeepSeek-R1 can not be used efficiently.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;set the &lt;code&gt;OPENROUTER_API_KEY&lt;/code&gt; in the &lt;code&gt;.env&lt;/code&gt; file.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;OPENROUTER_API_KEY=your_openrouter_api_key
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;run the following command to start Auto-Deep-Research.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;COMPLETION_MODEL=openrouter/deepseek/deepseek-r1 auto main
&lt;/code&gt;&lt;/pre&gt; 
&lt;h5&gt;DeepSeek&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;set the &lt;code&gt;DEEPSEEK_API_KEY&lt;/code&gt; in the &lt;code&gt;.env&lt;/code&gt; file.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;DEEPSEEK_API_KEY=your_deepseek_api_key
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;run the following command to start Auto-Deep-Research.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;COMPLETION_MODEL=deepseek/deepseek-chat auto main
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;After the CLI mode is started, you can see the start page of AutoAgent:&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;!-- &lt;img src="./assets/AutoAgentnew-intro.pdf" alt="Logo" width="100%"&gt; --&gt; 
 &lt;figure&gt; 
  &lt;img src="https://raw.githubusercontent.com/HKUDS/AutoAgent/main/assets/cover.png" alt="Logo" style="max-width: 100%; height: auto;" /&gt; 
  &lt;figcaption&gt;
   &lt;em&gt;Start Page of AutoAgent.&lt;/em&gt;
  &lt;/figcaption&gt; 
 &lt;/figure&gt; 
&lt;/div&gt; 
&lt;h3&gt;Tips&lt;/h3&gt; 
&lt;h4&gt;Import browser cookies to browser environment&lt;/h4&gt; 
&lt;p&gt;You can import the browser cookies to the browser environment to let the agent better access some specific websites. For more details, please refer to the &lt;a href="https://raw.githubusercontent.com/HKUDS/AutoAgent/main/AutoAgent/environment/cookie_json/README.md"&gt;cookies&lt;/a&gt; folder.&lt;/p&gt; 
&lt;h4&gt;Add your own API keys for third-party Tool Platforms&lt;/h4&gt; 
&lt;p&gt;If you want to create tools from the third-party tool platforms, such as RapidAPI, you should subscribe tools from the platform and add your own API keys by running &lt;a href="https://raw.githubusercontent.com/HKUDS/AutoAgent/main/process_tool_docs.py"&gt;process_tool_docs.py&lt;/a&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python process_tool_docs.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;More features coming soon! 🚀 &lt;strong&gt;Web GUI interface&lt;/strong&gt; under development.&lt;/p&gt; 
&lt;span id="todo"&gt;&lt;/span&gt; 
&lt;h2&gt;☑️ Todo List&lt;/h2&gt; 
&lt;p&gt;AutoAgent is continuously evolving! Here's what's coming:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;📊 &lt;strong&gt;More Benchmarks&lt;/strong&gt;: Expanding evaluations to &lt;strong&gt;SWE-bench&lt;/strong&gt;, &lt;strong&gt;WebArena&lt;/strong&gt;, and more&lt;/li&gt; 
 &lt;li&gt;🖥️ &lt;strong&gt;GUI Agent&lt;/strong&gt;: Supporting &lt;em&gt;Computer-Use&lt;/em&gt; agents with GUI interaction&lt;/li&gt; 
 &lt;li&gt;🔧 &lt;strong&gt;Tool Platforms&lt;/strong&gt;: Integration with more platforms like &lt;strong&gt;Composio&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;🏗️ &lt;strong&gt;Code Sandboxes&lt;/strong&gt;: Supporting additional environments like &lt;strong&gt;E2B&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;🎨 &lt;strong&gt;Web Interface&lt;/strong&gt;: Developing comprehensive GUI for better user experience&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Have ideas or suggestions? Feel free to open an issue! Stay tuned for more exciting updates! 🚀&lt;/p&gt; 
&lt;span id="reproduce"&gt;&lt;/span&gt; 
&lt;h2&gt;🔬 How To Reproduce the Results in the Paper&lt;/h2&gt; 
&lt;h3&gt;GAIA Benchmark&lt;/h3&gt; 
&lt;p&gt;For the GAIA benchmark, you can run the following command to run the inference.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd path/to/AutoAgent &amp;amp;&amp;amp; sh evaluation/gaia/scripts/run_infer.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For the evaluation, you can run the following command.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd path/to/AutoAgent &amp;amp;&amp;amp; python evaluation/gaia/get_score.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Agentic-RAG&lt;/h3&gt; 
&lt;p&gt;For the Agentic-RAG task, you can run the following command to run the inference.&lt;/p&gt; 
&lt;p&gt;Step1. Turn to &lt;a href="https://huggingface.co/datasets/yixuantt/MultiHopRAG"&gt;this page&lt;/a&gt; and download it. Save them to your datapath.&lt;/p&gt; 
&lt;p&gt;Step2. Run the following command to run the inference.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd path/to/AutoAgent &amp;amp;&amp;amp; sh evaluation/multihoprag/scripts/run_rag.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Step3. The result will be saved in the &lt;code&gt;evaluation/multihoprag/result.json&lt;/code&gt;.&lt;/p&gt; 
&lt;span id="documentation"&gt;&lt;/span&gt; 
&lt;h2&gt;📖 Documentation&lt;/h2&gt; 
&lt;p&gt;A more detailed documentation is coming soon 🚀, and we will update in the &lt;a href="https://AutoAgent-ai.github.io/docs"&gt;Documentation&lt;/a&gt; page.&lt;/p&gt; 
&lt;span id="community"&gt;&lt;/span&gt; 
&lt;h2&gt;🤝 Join the Community&lt;/h2&gt; 
&lt;p&gt;We want to build a community for AutoAgent, and we welcome everyone to join us. You can join our community by:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://join.slack.com/t/AutoAgent-workspace/shared_invite/zt-2zibtmutw-v7xOJObBf9jE2w3x7nctFQ"&gt;Join our Slack workspace&lt;/a&gt; - Here we talk about research, architecture, and future development.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://discord.gg/z68KRvwB"&gt;Join our Discord server&lt;/a&gt; - This is a community-run server for general discussion, questions, and feedback.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/HKUDS/AutoAgent/issues"&gt;Read or post Github Issues&lt;/a&gt; - Check out the issues we're working on, or add your own ideas.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id="acknowledgements"&gt;&lt;/span&gt; 
&lt;h2&gt;Misc&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://github.com/HKUDS/AutoAgent/stargazers"&gt;&lt;img src="https://reporoster.com/stars/HKUDS/AutoAgent" alt="Stargazers repo roster for @HKUDS/AutoAgent" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://github.com/HKUDS/AutoAgent/network/members"&gt;&lt;img src="https://reporoster.com/forks/HKUDS/AutoAgent" alt="Forkers repo roster for @HKUDS/AutoAgent" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://star-history.com/#HKUDS/AutoAgent&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=HKUDS/AutoAgent&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;🙏 Acknowledgements&lt;/h2&gt; 
&lt;p&gt;Rome wasn't built in a day. AutoAgent stands on the shoulders of giants, and we are deeply grateful for the outstanding work that came before us. Our framework architecture draws inspiration from &lt;a href="https://github.com/openai/swarm"&gt;OpenAI Swarm&lt;/a&gt;, while our user mode's three-agent design benefits from &lt;a href="https://github.com/microsoft/autogen/tree/main/python/packages/autogen-magentic-one"&gt;Magentic-one&lt;/a&gt;'s insights. We've also learned from &lt;a href="https://github.com/All-Hands-AI/OpenHands"&gt;OpenHands&lt;/a&gt; for documentation structure and many other excellent projects for agent-environment interaction design, among others. We express our sincere gratitude and respect to all these pioneering works that have been instrumental in shaping AutoAgent.&lt;/p&gt; 
&lt;span id="cite"&gt;&lt;/span&gt; 
&lt;h2&gt;🌟 Cite&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-tex"&gt;@misc{AutoAgent,
      title={{AutoAgent: A Fully-Automated and Zero-Code Framework for LLM Agents}},
      author={Jiabin Tang, Tianyu Fan, Chao Huang},
      year={2025},
      eprint={202502.05957},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2502.05957},
}
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>commaai/opendbc</title>
      <link>https://github.com/commaai/opendbc</link>
      <description>&lt;p&gt;a Python API for your car&lt;/p&gt;&lt;hr&gt;&lt;div align="center" style="text-align: center;"&gt; 
 &lt;h1&gt;opendbc&lt;/h1&gt; 
 &lt;p&gt; &lt;b&gt;opendbc is a Python API for your car.&lt;/b&gt; &lt;br /&gt; Control the gas, brake, steering, and more. Read the speed, steering angle, and more. &lt;/p&gt; 
 &lt;h3&gt; &lt;a href="https://docs.comma.ai"&gt;Docs&lt;/a&gt; &lt;span&gt; · &lt;/span&gt; &lt;a href="https://github.com/commaai/openpilot/raw/master/docs/CONTRIBUTING.md"&gt;Contribute&lt;/a&gt; &lt;span&gt; · &lt;/span&gt; &lt;a href="https://discord.comma.ai"&gt;Discord&lt;/a&gt; &lt;/h3&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/commaai/opendbc/master/LICENSE"&gt;&lt;img src="https://img.shields.io/badge/License-MIT-yellow.svg?sanitize=true" alt="License: MIT" /&gt;&lt;/a&gt; &lt;a href="https://x.com/comma_ai"&gt;&lt;img src="https://img.shields.io/twitter/follow/comma_ai" alt="X Follow" /&gt;&lt;/a&gt; &lt;a href="https://discord.comma.ai"&gt;&lt;img src="https://img.shields.io/discord/469524606043160576" alt="Discord" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;p&gt;Most cars since 2016 have electronically-actuatable steering, gas, and brakes thanks to &lt;a href="https://en.wikipedia.org/wiki/Lane_departure_warning_system#Lane_keeping_and_next_technologies"&gt;LKAS&lt;/a&gt; and &lt;a href="https://en.wikipedia.org/wiki/Adaptive_cruise_control"&gt;ACC&lt;/a&gt;. The goal of this project is to support controlling the steering, gas, and brakes on every single one of those cars.&lt;/p&gt; 
&lt;p&gt;While the primary focus is on supporting ADAS interfaces for &lt;a href="https://github.com/commaai/openpilot"&gt;openpilot&lt;/a&gt;, we're also interested in reading and writing as many things as we can (EV charge status, lock/unlocking doors, etc) such that we can build the best vehicle management app ever.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;This README and the &lt;a href="https://raw.githubusercontent.com/commaai/opendbc/master/docs/CARS.md"&gt;supported cars list&lt;/a&gt; are all the docs for the opendbc project. Everything you need to know to use, contribute, and extend opendbc are in these docs.&lt;/p&gt; 
&lt;h2&gt;Quick start&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/commaai/opendbc.git
cd opendbc

# you probably just want to use this. it's an all-in-one for dependency
# installation, compiling, linting, and tests. it's also what runs in CI
./test.sh

# here are the individual commands it runs
pip3 install -e .[testing,docs]  # install dependencies
scons -j8                        # build with 8 cores
pytest .                         # run the tests
lefthook run lint                # run the linter
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/commaai/opendbc/master/examples/"&gt;&lt;code&gt;examples/&lt;/code&gt;&lt;/a&gt; contains small example programs that can read state from the car and control the steering, gas, and brakes. &lt;a href="https://raw.githubusercontent.com/commaai/opendbc/master/examples/joystick.py"&gt;&lt;code&gt;examples/joystick.py&lt;/code&gt;&lt;/a&gt; allows you to control a car with a joystick.&lt;/p&gt; 
&lt;h3&gt;Project Structure&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/commaai/opendbc/master/opendbc/dbc/"&gt;&lt;code&gt;opendbc/dbc/&lt;/code&gt;&lt;/a&gt; is a repository of &lt;a href="https://en.wikipedia.org/wiki/CAN_bus#DBC_(CAN_Database_Files)"&gt;DBC&lt;/a&gt; files&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/commaai/opendbc/master/opendbc/can/"&gt;&lt;code&gt;opendbc/can/&lt;/code&gt;&lt;/a&gt; is a library for parsing and building CAN messages from DBC files&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/commaai/opendbc/master/opendbc/car/"&gt;&lt;code&gt;opendbc/car/&lt;/code&gt;&lt;/a&gt; is a high-level library for interfacing with cars using Python&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/commaai/opendbc/master/opendbc/safety/"&gt;&lt;code&gt;opendbc/safety/&lt;/code&gt;&lt;/a&gt; is the functional safety for all the cars supported by &lt;code&gt;opendbc/car/&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;How to Port a Car&lt;/h2&gt; 
&lt;p&gt;This guide covers everything from adding support to a new car all the way to improving existing cars (e.g. adding longitudinal control or radar parsing). If similar cars to yours are already compatible, most of this work is likely already done for you.&lt;/p&gt; 
&lt;p&gt;At its most basic, a car port will control the steering on a car. A "complete" car port will have all of: lateral control, longitudinal control, good tuning for both lateral and longitudinal, radar parsing (if equipped), fuzzy fingerprinting, and more. The new car support docs will clearly communicate each car's support level.&lt;/p&gt; 
&lt;h3&gt;Connect to the Car&lt;/h3&gt; 
&lt;p&gt;The first step is to get connected to the car with a comma 3X and a car harness. The car harness gets you connected to two different CAN buses and splits one of those buses to send our own actuation messages.&lt;/p&gt; 
&lt;p&gt;If you're lucky, a harness compatible with your car will already be designed and sold on comma.ai/shop. If you're not so lucky, start with a "developer harness" from comma.ai/shop and crimp on whatever connector you need.&lt;/p&gt; 
&lt;h3&gt;Structure of a port&lt;/h3&gt; 
&lt;p&gt;Depending on the brand, most of this basic structure will already be in place.&lt;/p&gt; 
&lt;p&gt;The entirety of a car port lives in &lt;code&gt;opendbc/car/&amp;lt;brand&amp;gt;/&lt;/code&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;carstate.py&lt;/code&gt;: parses out the relevant information from the CAN stream using the car's DBC file&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;carcontroller.py&lt;/code&gt;: outputs CAN messages to control the car&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;&amp;lt;brand&amp;gt;can.py&lt;/code&gt;: thin Python helpers around the DBC file to build CAN messages&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;fingerprints.py&lt;/code&gt;: database of ECU firmware versions for identifying car models&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;interface.py&lt;/code&gt;: high level class for interfacing with the car&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;radar_interface.py&lt;/code&gt;: parses out the radar&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;values.py&lt;/code&gt;: enumerates the brand's supported cars&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Reverse Engineer CAN messages&lt;/h3&gt; 
&lt;p&gt;Start off by recording a route with lots of interesting events: enable LKAS and ACC, turn the steering wheel both extremes, etc. Then, load up that route in &lt;a href="https://github.com/commaai/openpilot/tree/master/tools/cabana"&gt;cabana&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Tuning&lt;/h3&gt; 
&lt;h4&gt;Longitudinal&lt;/h4&gt; 
&lt;p&gt;Use the &lt;a href="https://github.com/commaai/openpilot/tree/master/tools/longitudinal_maneuvers"&gt;longitudinal maneuvers&lt;/a&gt; report to evaluate your car's longitudinal control and tune it.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;All opendbc development is coordinated on GitHub and &lt;a href="https://discord.comma.ai"&gt;Discord&lt;/a&gt;. Check out the &lt;code&gt;#dev-opendbc-cars&lt;/code&gt; channel and &lt;code&gt;Vehicle Specific&lt;/code&gt; section.&lt;/p&gt; 
&lt;h3&gt;Roadmap&lt;/h3&gt; 
&lt;p&gt;Short term&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;code&gt;pip install opendbc&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; 100% type coverage&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; 100% line coverage&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Make car ports easier: refactors, tools, tests, and docs&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Expose the state of all supported cars better: &lt;a href="https://github.com/commaai/opendbc/issues/1144"&gt;https://github.com/commaai/opendbc/issues/1144&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Longer term&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Extend support to every car with LKAS + ACC interfaces&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Automatic lateral and longitudinal control/tuning evaluation&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Auto-tuning for &lt;a href="https://blog.comma.ai/090release/#torqued-an-auto-tuner-for-lateral-control"&gt;lateral&lt;/a&gt; and longitudinal control&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://en.wikipedia.org/wiki/Automated_emergency_braking_system"&gt;Automatic Emergency Braking&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Contributions towards anything here are welcome.&lt;/p&gt; 
&lt;h2&gt;Safety Model&lt;/h2&gt; 
&lt;p&gt;When a &lt;a href="https://comma.ai/shop/panda"&gt;panda&lt;/a&gt; powers up with &lt;a href="https://raw.githubusercontent.com/commaai/opendbc/master/opendbc/safety"&gt;opendbc safety firmware&lt;/a&gt;, by default it's in &lt;code&gt;SAFETY_SILENT&lt;/code&gt; mode. While in &lt;code&gt;SAFETY_SILENT&lt;/code&gt; mode, the CAN buses are forced to be silent. In order to send messages, you have to select a safety mode. Some of safety modes (for example &lt;code&gt;SAFETY_ALLOUTPUT&lt;/code&gt;) are disabled in release firmwares. In order to use them, compile and flash your own build.&lt;/p&gt; 
&lt;p&gt;Safety modes optionally support &lt;code&gt;controls_allowed&lt;/code&gt;, which allows or blocks a subset of messages based on a customizable state in the board.&lt;/p&gt; 
&lt;h2&gt;Code Rigor&lt;/h2&gt; 
&lt;p&gt;The opendbc safety firmware is written for its use in conjunction with &lt;a href="https://github.com/commaai/openpilot"&gt;openpilot&lt;/a&gt; and &lt;a href="https://github.com/commaai/panda"&gt;panda&lt;/a&gt;. The safety firmware, through its safety model, provides and enforces the &lt;a href="https://github.com/commaai/openpilot/raw/master/docs/SAFETY.md"&gt;openpilot safety&lt;/a&gt;. Due to its critical function, it's important that the application code rigor within the &lt;code&gt;safety&lt;/code&gt; folder is held to high standards.&lt;/p&gt; 
&lt;p&gt;These are the &lt;a href="https://github.com/commaai/opendbc/actions"&gt;CI regression tests&lt;/a&gt; we have in place:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;A generic static code analysis is performed by &lt;a href="https://github.com/danmar/cppcheck/"&gt;cppcheck&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;In addition, &lt;a href="https://github.com/danmar/cppcheck/"&gt;cppcheck&lt;/a&gt; has a specific addon to check for &lt;a href="https://misra.org.uk/"&gt;MISRA C:2012&lt;/a&gt; violations. See &lt;a href="https://raw.githubusercontent.com/commaai/opendbc/master/opendbc/safety/tests/misra/coverage_table"&gt;current coverage&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Compiler options are relatively strict: the flags &lt;code&gt;-Wall -Wextra -Wstrict-prototypes -Werror&lt;/code&gt; are enforced.&lt;/li&gt; 
 &lt;li&gt;The &lt;a href="https://raw.githubusercontent.com/commaai/opendbc/master/opendbc/safety"&gt;safety logic&lt;/a&gt; is tested and verified by &lt;a href="https://raw.githubusercontent.com/commaai/opendbc/master/opendbc/safety/tests"&gt;unit tests&lt;/a&gt; for each supported car variant.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The above tests are themselves tested by:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;a &lt;a href="https://raw.githubusercontent.com/commaai/opendbc/master/opendbc/safety/tests/misra/test_mutation.py"&gt;mutation test&lt;/a&gt; on the MISRA coverage&lt;/li&gt; 
 &lt;li&gt;100% line coverage enforced on the safety unit tests&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;In addition, we run the &lt;a href="https://github.com/astral-sh/ruff"&gt;ruff linter&lt;/a&gt; and &lt;a href="https://mypy-lang.org/"&gt;mypy&lt;/a&gt; on the car interface library.&lt;/p&gt; 
&lt;h3&gt;Bounties&lt;/h3&gt; 
&lt;p&gt;Every car port is eligible for a bounty:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;$2000 - &lt;a href="https://github.com/orgs/commaai/projects/26/views/1?pane=issue&amp;amp;itemId=47913774"&gt;Any car brand / platform port&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;$250 - &lt;a href="https://github.com/orgs/commaai/projects/26/views/1?pane=issue&amp;amp;itemId=47913790"&gt;Any car model port&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;$300 - &lt;a href="https://github.com/orgs/commaai/projects/26/views/1?pane=issue&amp;amp;itemId=73445563"&gt;Reverse Engineering a new Actuation Message&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;In addition to the standard bounties, we also offer higher value bounties for more popular cars. See those at &lt;a href="https://raw.githubusercontent.com/commaai/opendbc/master/comma.ai/bounties"&gt;comma.ai/bounties&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;FAQ&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;&lt;strong&gt;How do I use this?&lt;/strong&gt;&lt;/em&gt; A &lt;a href="https://comma.ai/shop/comma-3x"&gt;comma 3X&lt;/a&gt; is custom-designed to be the best way to run and develop opendbc and openpilot.&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;&lt;strong&gt;Which cars are supported?&lt;/strong&gt;&lt;/em&gt; See the &lt;a href="https://raw.githubusercontent.com/commaai/opendbc/master/docs/CARS.md"&gt;supported cars list&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;&lt;strong&gt;Can I add support for my car?&lt;/strong&gt;&lt;/em&gt; Yes, most car support comes from the community. Read the guide &lt;a href="https://github.com/commaai/opendbc/raw/docs/README.md#how-to-port-a-car"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;&lt;strong&gt;Which cars can be supported?&lt;/strong&gt;&lt;/em&gt; Any car with LKAS and ACC. More info &lt;a href="https://github.com/commaai/openpilot/raw/master/docs/CARS.md#dont-see-your-car-here"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;&lt;strong&gt;How does this work?&lt;/strong&gt;&lt;/em&gt; In short, we designed hardware to replace your car's built-in lane keep and adaptive cruise features. See &lt;a href="https://www.youtube.com/watch?v=FL8CxUSfipM"&gt;this talk&lt;/a&gt; for an in-depth explanation.&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;&lt;strong&gt;Is there a timeline or roadmap for adding car support?&lt;/strong&gt;&lt;/em&gt; No, most car support comes from the community, with comma doing final safety and quality validation. The more complete the community car port is and the more popular the car is, the more likely we are to pick it up as the next one to validate.&lt;/p&gt; 
&lt;h3&gt;Terms&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;port&lt;/strong&gt;: refers to the integration and support of a specific car&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;lateral control&lt;/strong&gt;: aka steering control&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;longitudinal control&lt;/strong&gt;: aka gas/brakes control&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;fingerprinting&lt;/strong&gt;: automatic process for identifying the car&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://en.wikipedia.org/wiki/Lane_departure_warning_system"&gt;LKAS&lt;/a&gt;&lt;/strong&gt;: lane keeping assist&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://en.wikipedia.org/wiki/Adaptive_cruise_control"&gt;ACC&lt;/a&gt;&lt;/strong&gt;: adaptive cruise control&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://comma.ai/shop/car-harness"&gt;harness&lt;/a&gt;&lt;/strong&gt;: car-specific hardware to attach to the car and intercept the ADAS messages&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/commaai/panda"&gt;panda&lt;/a&gt;&lt;/strong&gt;: hardware used to get on a car's CAN bus&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://en.wikipedia.org/wiki/Electronic_control_unit"&gt;ECU&lt;/a&gt;&lt;/strong&gt;: computers or control modules inside the car&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://en.wikipedia.org/wiki/CAN_bus"&gt;CAN bus&lt;/a&gt;&lt;/strong&gt;: a bus that connects the ECUs in a car&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/commaai/openpilot/tree/master/tools/cabana#readme"&gt;cabana&lt;/a&gt;&lt;/strong&gt;: our tool for reverse engineering CAN messages&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://en.wikipedia.org/wiki/CAN_bus#DBC"&gt;DBC file&lt;/a&gt;&lt;/strong&gt;: contains definitions for messages on a CAN bus&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/commaai/openpilot"&gt;openpilot&lt;/a&gt;&lt;/strong&gt;: an ADAS system for cars supported by opendbc&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/commaai"&gt;comma&lt;/a&gt;&lt;/strong&gt;: the company behind opendbc&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://comma.ai/shop/comma-3x"&gt;comma 3X&lt;/a&gt;&lt;/strong&gt;: the hardware used to run openpilot&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;More resources&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=nNU6ipme878&amp;amp;pp=ygUoY29tbWEgY29uIDIwMjEgaG93IGRvIHdlIGNvbnRyb2wgdGhlIGNhcg%3D%3D"&gt;&lt;em&gt;How Do We Control The Car?&lt;/em&gt;&lt;/a&gt; by &lt;a href="https://github.com/robbederks"&gt;@robbederks&lt;/a&gt; from COMMA_CON 2021&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=XxPS5TpTUnI&amp;amp;t=142s&amp;amp;pp=ygUPamFzb24gY29tbWEgY29u"&gt;&lt;em&gt;How to Port a Car&lt;/em&gt;&lt;/a&gt; by &lt;a href="https://github.com/jyoung8607"&gt;@jyoung8607&lt;/a&gt; from COMMA_CON 2023&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://huggingface.co/datasets/commaai/commaCarSegments"&gt;commaCarSegments&lt;/a&gt;: a massive dataset of CAN data from 300 different car models&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/commaai/openpilot/tree/master/tools/cabana#readme"&gt;cabana&lt;/a&gt;: our tool for reverse engineering CAN messages&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/commaai/openpilot/raw/master/selfdrive/debug/can_print_changes.py"&gt;can_print_changes.py&lt;/a&gt;: diff the whole CAN bus across two drives, such as one without any LKAS and one with LKAS&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/commaai/openpilot/tree/master/tools/longitudinal_maneuvers"&gt;longitudinal maneuvers&lt;/a&gt;: a tool for evaluating and tuning longitudinal control&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://commaai.github.io/opendbc-data/"&gt;opendbc data&lt;/a&gt;: a repository of longitudinal maneuver evaluations&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Come work with us -- &lt;a href="https://comma.ai/jobs"&gt;comma.ai/jobs&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;comma is hiring engineers to work on opendbc and &lt;a href="https://github.com/commaai/openpilot"&gt;openpilot&lt;/a&gt;. We love hiring contributors.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>agno-agi/agno</title>
      <link>https://github.com/agno-agi/agno</link>
      <description>&lt;p&gt;High-performance runtime for multi-agent systems. Build, run and manage secure multi-agent systems in your cloud.&lt;/p&gt;&lt;hr&gt;&lt;div align="center" id="top"&gt; 
 &lt;a href="https://docs.agno.com"&gt; 
  &lt;picture&gt; 
   &lt;source media="(prefers-color-scheme: dark)" srcset="https://agno-public.s3.us-east-1.amazonaws.com/assets/logo-dark.svg" /&gt; 
   &lt;source media="(prefers-color-scheme: light)" srcset="https://agno-public.s3.us-east-1.amazonaws.com/assets/logo-light.svg" /&gt; 
   &lt;img src="https://agno-public.s3.us-east-1.amazonaws.com/assets/logo-light.svg?sanitize=true" alt="Agno" /&gt; 
  &lt;/picture&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://docs.agno.com"&gt;📚 Documentation&lt;/a&gt; &amp;nbsp;|&amp;nbsp; 
 &lt;a href="https://docs.agno.com/examples/introduction"&gt;💡 Examples&lt;/a&gt; &amp;nbsp;|&amp;nbsp; 
 &lt;a href="https://github.com/agno-agi/agno/stargazers"&gt;🌟 Star Us&lt;/a&gt; 
&lt;/div&gt; 
&lt;h2&gt;What is Agno?&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://docs.agno.com"&gt;Agno&lt;/a&gt; is a high-performance runtime for multi-agent systems. Use it to build, run and manage secure multi-agent systems in your cloud.&lt;/p&gt; 
&lt;p&gt;Agno gives you the fastest framework for building agents with session management, memory, knowledge, human in the loop and MCP support. You can put agents together as an autonomous multi-agent team, or build step-based agentic workflows for full control over complex multi-step processes.&lt;/p&gt; 
&lt;p&gt;In 10 lines of code, we can build an Agent that will fetch the top stories from HackerNews and summarize them.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from agno.agent import Agent
from agno.models.anthropic import Claude
from agno.tools.hackernews import HackerNewsTools

agent = Agent(
    model=Claude(id="claude-sonnet-4-0"),
    tools=[HackerNewsTools()],
    markdown=True,
)
agent.print_response("Summarize the top 5 stories on hackernews", stream=True)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;But the real advantage of Agno is its &lt;a href="https://docs.agno.com/agent-os/introduction"&gt;AgentOS&lt;/a&gt; runtime:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;You get a pre-built FastAPI app for running your agentic system, meaning you start building your product on day one. This is a remarkable advantage over other solutions or rolling your own.&lt;/li&gt; 
 &lt;li&gt;You also get a control plane which connects directly to your AgentOS for testing, monitoring and managing your system. This gives you unmatched visibility and control over your system.&lt;/li&gt; 
 &lt;li&gt;Your AgentOS runs in your cloud and you get complete data privacy because no data ever leaves your system. This is incredible for security conscious enterprises that can't send traces to external services.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;For organizations building agents, Agno provides the complete solution. You get the fastest framework for building agents (speed of development and execution), a pre-built FastAPI app that lets you build your product on day one, and a control plane for managing your system.&lt;/p&gt; 
&lt;p&gt;We bring a novel architecture that no other framework provides, your AgentOS runs securely in your cloud, and the control plane connects directly to it from your browser. You don't need to send data to external services or pay retention costs, you get complete privacy and control.&lt;/p&gt; 
&lt;h2&gt;Getting started&lt;/h2&gt; 
&lt;p&gt;If you're new to Agno, follow our &lt;a href="https://docs.agno.com/introduction/quickstart"&gt;quickstart&lt;/a&gt; to build your first Agent and run it using the AgentOS.&lt;/p&gt; 
&lt;p&gt;After that, checkout the &lt;a href="https://docs.agno.com/examples/introduction"&gt;examples gallery&lt;/a&gt; and build real-world applications with Agno.&lt;/p&gt; 
&lt;h2&gt;Documentation, Community &amp;amp; More examples&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Docs: &lt;a href="https://docs.agno.com" target="_blank" rel="noopener noreferrer"&gt;docs.agno.com&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Cookbook: &lt;a href="https://github.com/agno-agi/agno/tree/main/cookbook" target="_blank" rel="noopener noreferrer"&gt;Cookbook&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Community forum: &lt;a href="https://community.agno.com/" target="_blank" rel="noopener noreferrer"&gt;community.agno.com&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Discord: &lt;a href="https://discord.gg/4MtYHHrgA8" target="_blank" rel="noopener noreferrer"&gt;discord&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Setup your coding agent to use Agno&lt;/h2&gt; 
&lt;p&gt;For LLMs and AI assistants to understand and navigate Agno's documentation, we provide an &lt;a href="https://docs.agno.com/llms.txt"&gt;llms.txt&lt;/a&gt; or &lt;a href="https://docs.agno.com/llms-full.txt"&gt;llms-full.txt&lt;/a&gt; file.&lt;/p&gt; 
&lt;p&gt;This file is built for AI systems to efficiently parse and reference our documentation.&lt;/p&gt; 
&lt;h3&gt;IDE Integration&lt;/h3&gt; 
&lt;p&gt;When building Agno agents, using Agno documentation as a source in your IDE is a great way to speed up your development. Here's how to integrate with Cursor:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;In Cursor, go to the "Cursor Settings" menu.&lt;/li&gt; 
 &lt;li&gt;Find the "Indexing &amp;amp; Docs" section.&lt;/li&gt; 
 &lt;li&gt;Add &lt;code&gt;https://docs.agno.com/llms-full.txt&lt;/code&gt; to the list of documentation URLs.&lt;/li&gt; 
 &lt;li&gt;Save the changes.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Now, Cursor will have access to the Agno documentation. You can do the same with other IDEs like VSCode, Windsurf etc.&lt;/p&gt; 
&lt;h2&gt;Performance&lt;/h2&gt; 
&lt;p&gt;At Agno, we're obsessed with performance. Why? because even simple AI workflows can spawn thousands of Agents. Scale that to a modest number of users and performance becomes a bottleneck. Agno is designed for building highly performant agentic systems:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Agent instantiation: ~3μs on average&lt;/li&gt; 
 &lt;li&gt;Memory footprint: ~6.5Kib on average&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Tested on an Apple M4 Mackbook Pro.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;While an Agent's run-time is bottlenecked by inference, we must do everything possible to minimize execution time, reduce memory usage, and parallelize tool calls. These numbers may seem trivial at first, but our experience shows that they add up even at a reasonably small scale.&lt;/p&gt; 
&lt;h3&gt;Instantiation time&lt;/h3&gt; 
&lt;p&gt;Let's measure the time it takes for an Agent with 1 tool to start up. We'll run the evaluation 1000 times to get a baseline measurement.&lt;/p&gt; 
&lt;p&gt;You should run the evaluation yourself on your own machine, please, do not take these results at face value.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;# Setup virtual environment
./scripts/perf_setup.sh
source .venvs/perfenv/bin/activate
# OR Install dependencies manually
# pip install openai agno langgraph langchain_openai

# Agno
python evals/performance/instantiation_with_tool.py

# LangGraph
python evals/performance/other/langgraph_instantiation.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;The following evaluation is run on an Apple M4 Mackbook Pro. It also runs as a Github action on this repo.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;LangGraph is on the right, &lt;strong&gt;let's start it first and give it a head start&lt;/strong&gt;.&lt;/p&gt; 
&lt;p&gt;Agno is on the left, notice how it finishes before LangGraph gets 1/2 way through the runtime measurement, and hasn't even started the memory measurement. That's how fast Agno is.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/ba466d45-75dd-45ac-917b-0a56c5742e23"&gt;https://github.com/user-attachments/assets/ba466d45-75dd-45ac-917b-0a56c5742e23&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Memory usage&lt;/h3&gt; 
&lt;p&gt;To measure memory usage, we use the &lt;code&gt;tracemalloc&lt;/code&gt; library. We first calculate a baseline memory usage by running an empty function, then run the Agent 1000x times and calculate the difference. This gives a (reasonably) isolated measurement of the memory usage of the Agent.&lt;/p&gt; 
&lt;p&gt;We recommend running the evaluation yourself on your own machine, and digging into the code to see how it works. If we've made a mistake, please let us know.&lt;/p&gt; 
&lt;h3&gt;Conclusion&lt;/h3&gt; 
&lt;p&gt;Agno agents are designed for performance and while we do share some benchmarks against other frameworks, we should be mindful that accuracy and reliability are more important than speed.&lt;/p&gt; 
&lt;p&gt;Given that each framework is different and we won't be able to tune their performance like we do with Agno, for future benchmarks we'll only be comparing against ourselves.&lt;/p&gt; 
&lt;h2&gt;Contributions&lt;/h2&gt; 
&lt;p&gt;We welcome contributions, read our &lt;a href="https://github.com/agno-agi/agno/raw/v2.0/CONTRIBUTING.md"&gt;contributing guide&lt;/a&gt; to get started.&lt;/p&gt; 
&lt;h2&gt;Telemetry&lt;/h2&gt; 
&lt;p&gt;Agno logs which model an agent used so we can prioritize updates to the most popular providers. You can disable this by setting &lt;code&gt;AGNO_TELEMETRY=false&lt;/code&gt; in your environment.&lt;/p&gt; 
&lt;p align="left"&gt; &lt;a href="https://raw.githubusercontent.com/agno-agi/agno/main/#top"&gt;⬆️ Back to Top&lt;/a&gt; &lt;/p&gt;</description>
    </item>
    
    <item>
      <title>gto76/python-cheatsheet</title>
      <link>https://github.com/gto76/python-cheatsheet</link>
      <description>&lt;p&gt;Comprehensive Python Cheatsheet&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Comprehensive Python Cheatsheet&lt;/h1&gt; 
&lt;p&gt;&lt;sup&gt;&lt;a href="https://raw.githubusercontent.com/gto76/python-cheatsheet/main/README.md"&gt;Download text file&lt;/a&gt;, &lt;a href="https://github.com/gto76/python-cheatsheet"&gt;Fork me on GitHub&lt;/a&gt; or &lt;a href="https://github.com/gto76/python-cheatsheet/wiki/Frequently-Asked-Questions"&gt;Check out FAQ&lt;/a&gt;. &lt;/sup&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/gto76/python-cheatsheet/main/web/image_888.jpeg" alt="Monty Python" /&gt;&lt;/p&gt; 
&lt;h2&gt;Contents&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/strong&gt; &lt;strong&gt;1. Collections:&lt;/strong&gt; &lt;strong&gt;&amp;nbsp;&lt;/strong&gt; &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/gto76/python-cheatsheet/main/#list"&gt;&lt;code&gt;List&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;&lt;strong&gt;,&lt;/strong&gt; &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/gto76/python-cheatsheet/main/#dictionary"&gt;&lt;code&gt;Dictionary&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;&lt;strong&gt;,&lt;/strong&gt; &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/gto76/python-cheatsheet/main/#set"&gt;&lt;code&gt;Set&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;&lt;strong&gt;,&lt;/strong&gt; &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/gto76/python-cheatsheet/main/#tuple"&gt;&lt;code&gt;Tuple&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;&lt;strong&gt;,&lt;/strong&gt; &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/gto76/python-cheatsheet/main/#range"&gt;&lt;code&gt;Range&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;&lt;strong&gt;,&lt;/strong&gt; &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/gto76/python-cheatsheet/main/#enumerate"&gt;&lt;code&gt;Enumerate&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;&lt;strong&gt;,&lt;/strong&gt; &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/gto76/python-cheatsheet/main/#iterator"&gt;&lt;code&gt;Iterator&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;&lt;strong&gt;,&lt;/strong&gt; &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/gto76/python-cheatsheet/main/#generator"&gt;&lt;code&gt;Generator&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;&lt;strong&gt;.&lt;/strong&gt;&lt;br /&gt; &lt;strong&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/strong&gt; &lt;strong&gt;2. Types:&lt;/strong&gt; &lt;strong&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/strong&gt; &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/gto76/python-cheatsheet/main/#type"&gt;&lt;code&gt;Type&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;&lt;strong&gt;,&lt;/strong&gt; &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/gto76/python-cheatsheet/main/#string"&gt;&lt;code&gt;String&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;&lt;strong&gt;,&lt;/strong&gt; &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/gto76/python-cheatsheet/main/#regex"&gt;&lt;code&gt;Regular_Exp&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;&lt;strong&gt;,&lt;/strong&gt; &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/gto76/python-cheatsheet/main/#format"&gt;&lt;code&gt;Format&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;&lt;strong&gt;,&lt;/strong&gt; &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/gto76/python-cheatsheet/main/#numbers-1"&gt;&lt;code&gt;Numbers&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;&lt;strong&gt;,&lt;/strong&gt; &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/gto76/python-cheatsheet/main/#combinatorics"&gt;&lt;code&gt;Combinatorics&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;&lt;strong&gt;,&lt;/strong&gt; &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/gto76/python-cheatsheet/main/#datetime"&gt;&lt;code&gt;Datetime&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;&lt;strong&gt;.&lt;/strong&gt;&lt;br /&gt; &lt;strong&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/strong&gt; &lt;strong&gt;3. Syntax:&lt;/strong&gt; &lt;strong&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/strong&gt; &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/gto76/python-cheatsheet/main/#function"&gt;&lt;code&gt;Function&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;&lt;strong&gt;,&lt;/strong&gt; &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/gto76/python-cheatsheet/main/#inline"&gt;&lt;code&gt;Inline&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;&lt;strong&gt;,&lt;/strong&gt; &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/gto76/python-cheatsheet/main/#imports"&gt;&lt;code&gt;Import&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;&lt;strong&gt;,&lt;/strong&gt; &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/gto76/python-cheatsheet/main/#decorator"&gt;&lt;code&gt;Decorator&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;&lt;strong&gt;,&lt;/strong&gt; &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/gto76/python-cheatsheet/main/#class"&gt;&lt;code&gt;Class&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;&lt;strong&gt;,&lt;/strong&gt; &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/gto76/python-cheatsheet/main/#duck-types"&gt;&lt;code&gt;Duck_Type&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;&lt;strong&gt;,&lt;/strong&gt; &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/gto76/python-cheatsheet/main/#enum"&gt;&lt;code&gt;Enum&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;&lt;strong&gt;,&lt;/strong&gt; &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/gto76/python-cheatsheet/main/#exceptions"&gt;&lt;code&gt;Except&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;&lt;strong&gt;.&lt;/strong&gt;&lt;br /&gt; &lt;strong&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/strong&gt; &lt;strong&gt;4. System:&lt;/strong&gt; &lt;strong&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/strong&gt; &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/gto76/python-cheatsheet/main/#exit"&gt;&lt;code&gt;Exit&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;&lt;strong&gt;,&lt;/strong&gt; &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/gto76/python-cheatsheet/main/#print"&gt;&lt;code&gt;Print&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;&lt;strong&gt;,&lt;/strong&gt; &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/gto76/python-cheatsheet/main/#input"&gt;&lt;code&gt;Input&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;&lt;strong&gt;,&lt;/strong&gt; &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/gto76/python-cheatsheet/main/#command-line-arguments"&gt;&lt;code&gt;Command_Line_Arguments&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;&lt;strong&gt;,&lt;/strong&gt; &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/gto76/python-cheatsheet/main/#open"&gt;&lt;code&gt;Open&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;&lt;strong&gt;,&lt;/strong&gt; &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/gto76/python-cheatsheet/main/#paths"&gt;&lt;code&gt;Path&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;&lt;strong&gt;,&lt;/strong&gt; &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/gto76/python-cheatsheet/main/#os-commands"&gt;&lt;code&gt;OS_Commands&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;&lt;strong&gt;.&lt;/strong&gt;&lt;br /&gt; &lt;strong&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/strong&gt; &lt;strong&gt;5. Data:&lt;/strong&gt; &lt;strong&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/strong&gt; &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/gto76/python-cheatsheet/main/#json"&gt;&lt;code&gt;JSON&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;&lt;strong&gt;,&lt;/strong&gt; &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/gto76/python-cheatsheet/main/#pickle"&gt;&lt;code&gt;Pickle&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;&lt;strong&gt;,&lt;/strong&gt; &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/gto76/python-cheatsheet/main/#csv"&gt;&lt;code&gt;CSV&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;&lt;strong&gt;,&lt;/strong&gt; &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/gto76/python-cheatsheet/main/#sqlite"&gt;&lt;code&gt;SQLite&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;&lt;strong&gt;,&lt;/strong&gt; &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/gto76/python-cheatsheet/main/#bytes"&gt;&lt;code&gt;Bytes&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;&lt;strong&gt;,&lt;/strong&gt; &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/gto76/python-cheatsheet/main/#struct"&gt;&lt;code&gt;Struct&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;&lt;strong&gt;,&lt;/strong&gt; &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/gto76/python-cheatsheet/main/#array"&gt;&lt;code&gt;Array&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;&lt;strong&gt;,&lt;/strong&gt; &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/gto76/python-cheatsheet/main/#memory-view"&gt;&lt;code&gt;Memory_View&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;&lt;strong&gt;,&lt;/strong&gt; &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/gto76/python-cheatsheet/main/#deque"&gt;&lt;code&gt;Deque&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;&lt;strong&gt;.&lt;/strong&gt;&lt;br /&gt; &lt;strong&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/strong&gt; &lt;strong&gt;6. Advanced:&lt;/strong&gt; &lt;strong&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/strong&gt; &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/gto76/python-cheatsheet/main/#operator"&gt;&lt;code&gt;Operator&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;&lt;strong&gt;,&lt;/strong&gt; &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/gto76/python-cheatsheet/main/#match-statement"&gt;&lt;code&gt;Match_Stmt&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;&lt;strong&gt;,&lt;/strong&gt; &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/gto76/python-cheatsheet/main/#logging"&gt;&lt;code&gt;Logging&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;&lt;strong&gt;,&lt;/strong&gt; &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/gto76/python-cheatsheet/main/#introspection"&gt;&lt;code&gt;Introspection&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;&lt;strong&gt;,&lt;/strong&gt; &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/gto76/python-cheatsheet/main/#threading"&gt;&lt;code&gt;Threading&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;&lt;strong&gt;,&lt;/strong&gt; &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/gto76/python-cheatsheet/main/#coroutines"&gt;&lt;code&gt;Coroutines&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;&lt;strong&gt;.&lt;/strong&gt;&lt;br /&gt; &lt;strong&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/strong&gt; &lt;strong&gt;7. Libraries:&lt;/strong&gt; &lt;strong&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/strong&gt; &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/gto76/python-cheatsheet/main/#progress-bar"&gt;&lt;code&gt;Progress_Bar&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;&lt;strong&gt;,&lt;/strong&gt; &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/gto76/python-cheatsheet/main/#plot"&gt;&lt;code&gt;Plot&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;&lt;strong&gt;,&lt;/strong&gt; &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/gto76/python-cheatsheet/main/#table"&gt;&lt;code&gt;Table&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;&lt;strong&gt;,&lt;/strong&gt; &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/gto76/python-cheatsheet/main/#console-app"&gt;&lt;code&gt;Console_App&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;&lt;strong&gt;,&lt;/strong&gt; &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/gto76/python-cheatsheet/main/#gui-app"&gt;&lt;code&gt;GUI&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;&lt;strong&gt;,&lt;/strong&gt; &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/gto76/python-cheatsheet/main/#scraping"&gt;&lt;code&gt;Scraping&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;&lt;strong&gt;,&lt;/strong&gt; &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/gto76/python-cheatsheet/main/#web-app"&gt;&lt;code&gt;Web&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;&lt;strong&gt;,&lt;/strong&gt; &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/gto76/python-cheatsheet/main/#profiling"&gt;&lt;code&gt;Profile&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;&lt;strong&gt;.&lt;/strong&gt;&lt;br /&gt; &lt;strong&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/strong&gt; &lt;strong&gt;8. Multimedia:&lt;/strong&gt; &lt;strong&gt;&amp;nbsp;&amp;nbsp;&lt;/strong&gt; &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/gto76/python-cheatsheet/main/#numpy"&gt;&lt;code&gt;NumPy&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;&lt;strong&gt;,&lt;/strong&gt; &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/gto76/python-cheatsheet/main/#image"&gt;&lt;code&gt;Image&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;&lt;strong&gt;,&lt;/strong&gt; &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/gto76/python-cheatsheet/main/#animation"&gt;&lt;code&gt;Animation&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;&lt;strong&gt;,&lt;/strong&gt; &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/gto76/python-cheatsheet/main/#audio"&gt;&lt;code&gt;Audio&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;&lt;strong&gt;,&lt;/strong&gt; &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/gto76/python-cheatsheet/main/#synthesizer"&gt;&lt;code&gt;Synthesizer&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;&lt;strong&gt;,&lt;/strong&gt; &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/gto76/python-cheatsheet/main/#pygame"&gt;&lt;code&gt;Pygame&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;&lt;strong&gt;,&lt;/strong&gt; &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/gto76/python-cheatsheet/main/#pandas"&gt;&lt;code&gt;Pandas&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;&lt;strong&gt;,&lt;/strong&gt; &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/gto76/python-cheatsheet/main/#plotly"&gt;&lt;code&gt;Plotly&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;&lt;strong&gt;.&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;Main&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;if __name__ == '__main__':      # Skips next line if file was imported.
    main()                      # Runs `def main(): ...` function.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;List&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;list&amp;gt; = [&amp;lt;el_1&amp;gt;, &amp;lt;el_2&amp;gt;, ...]  # Creates a list object. Also list(&amp;lt;collection&amp;gt;).
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;el&amp;gt;   = &amp;lt;list&amp;gt;[index]          # First index is 0. Last -1. Allows assignments.
&amp;lt;list&amp;gt; = &amp;lt;list&amp;gt;[&amp;lt;slice&amp;gt;]        # Also &amp;lt;list&amp;gt;[from_inclusive : to_exclusive : ±step].
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;list&amp;gt;.append(&amp;lt;el&amp;gt;)             # Appends element to the end. Also &amp;lt;list&amp;gt; += [&amp;lt;el&amp;gt;].
&amp;lt;list&amp;gt;.extend(&amp;lt;collection&amp;gt;)     # Appends elements to the end. Also &amp;lt;list&amp;gt; += &amp;lt;coll&amp;gt;.
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;list&amp;gt;.sort()                   # Sorts the elements in ascending order.
&amp;lt;list&amp;gt;.reverse()                # Reverses the order of list's elements.
&amp;lt;list&amp;gt; = sorted(&amp;lt;collection&amp;gt;)   # Returns a new list with sorted elements.
&amp;lt;iter&amp;gt; = reversed(&amp;lt;list&amp;gt;)       # Returns reversed iterator of elements.
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;el&amp;gt;  = max(&amp;lt;collection&amp;gt;)       # Returns largest element. Also min(&amp;lt;el_1&amp;gt;, ...).
&amp;lt;num&amp;gt; = sum(&amp;lt;collection&amp;gt;)       # Returns sum of elements. Also math.prod(&amp;lt;coll&amp;gt;).
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;elementwise_sum  = [sum(pair) for pair in zip(list_a, list_b)]
sorted_by_second = sorted(&amp;lt;collection&amp;gt;, key=lambda el: el[1])
sorted_by_both   = sorted(&amp;lt;collection&amp;gt;, key=lambda el: (el[1], el[0]))
flatter_list     = list(itertools.chain.from_iterable(&amp;lt;list&amp;gt;))
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;For details about sort(), sorted(), min() and max() see &lt;a href="https://raw.githubusercontent.com/gto76/python-cheatsheet/main/#sortable"&gt;Sortable&lt;/a&gt;.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Module &lt;a href="https://raw.githubusercontent.com/gto76/python-cheatsheet/main/#operator"&gt;operator&lt;/a&gt; has function itemgetter() that can replace listed &lt;a href="https://raw.githubusercontent.com/gto76/python-cheatsheet/main/#lambda"&gt;lambdas&lt;/a&gt;.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;This text uses the term collection instead of iterable. For rationale see &lt;a href="https://raw.githubusercontent.com/gto76/python-cheatsheet/main/#collection"&gt;Collection&lt;/a&gt;.&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;int&amp;gt; = len(&amp;lt;list&amp;gt;)             # Returns number of items. Also works on dict, set and string.
&amp;lt;int&amp;gt; = &amp;lt;list&amp;gt;.count(&amp;lt;el&amp;gt;)      # Returns number of occurrences. Also `if &amp;lt;el&amp;gt; in &amp;lt;coll&amp;gt;: ...`.
&amp;lt;int&amp;gt; = &amp;lt;list&amp;gt;.index(&amp;lt;el&amp;gt;)      # Returns index of the first occurrence or raises ValueError.
&amp;lt;el&amp;gt;  = &amp;lt;list&amp;gt;.pop()            # Removes and returns item from the end or at index if passed.
&amp;lt;list&amp;gt;.insert(&amp;lt;int&amp;gt;, &amp;lt;el&amp;gt;)      # Inserts item at passed index and moves the rest to the right.
&amp;lt;list&amp;gt;.remove(&amp;lt;el&amp;gt;)             # Removes first occurrence of the item or raises ValueError.
&amp;lt;list&amp;gt;.clear()                  # Removes all list's items. Also works on dictionary and set.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Dictionary&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;dict&amp;gt; = {key_1: val_1, key_2: val_2, ...}      # Use `&amp;lt;dict&amp;gt;[key]` to get or set the value.
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;view&amp;gt; = &amp;lt;dict&amp;gt;.keys()                          # Collection of keys that reflects changes.
&amp;lt;view&amp;gt; = &amp;lt;dict&amp;gt;.values()                        # Collection of values that reflects changes.
&amp;lt;view&amp;gt; = &amp;lt;dict&amp;gt;.items()                         # Coll. of key-value tuples that reflects chgs.
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;value  = &amp;lt;dict&amp;gt;.get(key, default=None)          # Returns default argument if key is missing.
value  = &amp;lt;dict&amp;gt;.setdefault(key, default=None)   # Returns and writes default if key is missing.
&amp;lt;dict&amp;gt; = collections.defaultdict(&amp;lt;type&amp;gt;)        # Returns a dict with default value `&amp;lt;type&amp;gt;()`.
&amp;lt;dict&amp;gt; = collections.defaultdict(lambda: 1)     # Returns a dict with default value 1.
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;dict&amp;gt; = dict(&amp;lt;collection&amp;gt;)                     # Creates a dict from coll. of key-value pairs.
&amp;lt;dict&amp;gt; = dict(zip(keys, values))                # Creates a dict from two collections.
&amp;lt;dict&amp;gt; = dict.fromkeys(keys [, value])          # Creates a dict from collection of keys.
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;dict&amp;gt;.update(&amp;lt;dict&amp;gt;)                           # Adds items. Replaces ones with matching keys.
value = &amp;lt;dict&amp;gt;.pop(key)                         # Removes item or raises KeyError if missing.
{k for k, v in &amp;lt;dict&amp;gt;.items() if v == value}    # Returns set of keys that point to the value.
{k: v for k, v in &amp;lt;dict&amp;gt;.items() if k in keys}  # Filters the dictionary by specified keys.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Counter&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;gt;&amp;gt;&amp;gt; from collections import Counter
&amp;gt;&amp;gt;&amp;gt; counter = Counter(['blue', 'blue', 'blue', 'red', 'red'])
&amp;gt;&amp;gt;&amp;gt; counter['yellow'] += 1
&amp;gt;&amp;gt;&amp;gt; print(counter.most_common())
[('blue', 3), ('red', 2), ('yellow', 1)]
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Set&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;set&amp;gt; = {&amp;lt;el_1&amp;gt;, &amp;lt;el_2&amp;gt;, ...}                   # Use `set()` for empty set.
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;set&amp;gt;.add(&amp;lt;el&amp;gt;)                                 # Or: &amp;lt;set&amp;gt; |= {&amp;lt;el&amp;gt;}
&amp;lt;set&amp;gt;.update(&amp;lt;collection&amp;gt; [, ...])              # Or: &amp;lt;set&amp;gt; |= &amp;lt;set&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;set&amp;gt;  = &amp;lt;set&amp;gt;.union(&amp;lt;coll.&amp;gt;)                   # Or: &amp;lt;set&amp;gt; | &amp;lt;set&amp;gt;
&amp;lt;set&amp;gt;  = &amp;lt;set&amp;gt;.intersection(&amp;lt;coll.&amp;gt;)            # Or: &amp;lt;set&amp;gt; &amp;amp; &amp;lt;set&amp;gt;
&amp;lt;set&amp;gt;  = &amp;lt;set&amp;gt;.difference(&amp;lt;coll.&amp;gt;)              # Or: &amp;lt;set&amp;gt; - &amp;lt;set&amp;gt;
&amp;lt;set&amp;gt;  = &amp;lt;set&amp;gt;.symmetric_difference(&amp;lt;coll.&amp;gt;)    # Or: &amp;lt;set&amp;gt; ^ &amp;lt;set&amp;gt;
&amp;lt;bool&amp;gt; = &amp;lt;set&amp;gt;.issubset(&amp;lt;coll.&amp;gt;)                # Or: &amp;lt;set&amp;gt; &amp;lt;= &amp;lt;set&amp;gt;
&amp;lt;bool&amp;gt; = &amp;lt;set&amp;gt;.issuperset(&amp;lt;coll.&amp;gt;)              # Or: &amp;lt;set&amp;gt; &amp;gt;= &amp;lt;set&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;el&amp;gt; = &amp;lt;set&amp;gt;.pop()                              # Raises KeyError if empty.
&amp;lt;set&amp;gt;.remove(&amp;lt;el&amp;gt;)                              # Raises KeyError if missing.
&amp;lt;set&amp;gt;.discard(&amp;lt;el&amp;gt;)                             # Doesn't raise an error.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Frozen Set&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Is immutable and hashable.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;That means it can be used as a key in a dictionary or as an element in a set.&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;frozenset&amp;gt; = frozenset(&amp;lt;collection&amp;gt;)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Tuple&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Tuple is an immutable and hashable list.&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;tuple&amp;gt; = ()                               # Empty tuple.
&amp;lt;tuple&amp;gt; = (&amp;lt;el&amp;gt;,)                          # Or: &amp;lt;el&amp;gt;,
&amp;lt;tuple&amp;gt; = (&amp;lt;el_1&amp;gt;, &amp;lt;el_2&amp;gt; [, ...])         # Or: &amp;lt;el_1&amp;gt;, &amp;lt;el_2&amp;gt; [, ...]
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Named Tuple&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Tuple's subclass with named elements.&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;gt;&amp;gt;&amp;gt; from collections import namedtuple
&amp;gt;&amp;gt;&amp;gt; Point = namedtuple('Point', 'x y')
&amp;gt;&amp;gt;&amp;gt; p = Point(1, y=2)
&amp;gt;&amp;gt;&amp;gt; print(p)
Point(x=1, y=2)
&amp;gt;&amp;gt;&amp;gt; p.x, p[1]
(1, 2)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Range&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Immutable and hashable sequence of integers.&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;range&amp;gt; = range(stop)                      # I.e. range(to_exclusive).
&amp;lt;range&amp;gt; = range(start, stop)               # I.e. range(from_inclusive, to_exclusive).
&amp;lt;range&amp;gt; = range(start, stop, ±step)        # I.e. range(from_inclusive, to_exclusive, ±step).
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;gt;&amp;gt;&amp;gt; [i for i in range(3)]
[0, 1, 2]
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Enumerate&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;for i, el in enumerate(&amp;lt;coll&amp;gt;, start=0):   # Returns next element and its index on each pass.
    ...
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Iterator&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Potentially endless stream of elements.&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;iter&amp;gt; = iter(&amp;lt;collection&amp;gt;)                # `iter(&amp;lt;iter&amp;gt;)` returns unmodified iterator.
&amp;lt;iter&amp;gt; = iter(&amp;lt;function&amp;gt;, to_exclusive)    # A sequence of return values until 'to_exclusive'.
&amp;lt;el&amp;gt;   = next(&amp;lt;iter&amp;gt; [, default])          # Raises StopIteration or returns 'default' on end.
&amp;lt;list&amp;gt; = list(&amp;lt;iter&amp;gt;)                      # Returns a list of iterator's remaining elements.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Itertools&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import itertools as it
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;iter&amp;gt; = it.count(start=0, step=1)         # Returns updated value endlessly. Accepts floats.
&amp;lt;iter&amp;gt; = it.repeat(&amp;lt;el&amp;gt; [, times])         # Returns element endlessly or 'times' times.
&amp;lt;iter&amp;gt; = it.cycle(&amp;lt;collection&amp;gt;)            # Repeats the passed sequence of elements endlessly.
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;iter&amp;gt; = it.chain(&amp;lt;coll&amp;gt;, &amp;lt;coll&amp;gt; [, ...])  # Empties collections in order (only figuratively).
&amp;lt;iter&amp;gt; = it.chain.from_iterable(&amp;lt;coll&amp;gt;)    # Empties collections inside a collection in order.
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;iter&amp;gt; = it.islice(&amp;lt;coll&amp;gt;, to_exclusive)   # Only returns first 'to_exclusive' elements.
&amp;lt;iter&amp;gt; = it.islice(&amp;lt;coll&amp;gt;, from_inc, …)    # `to_exclusive, +step_size`. Indices can be None.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Generator&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Any function that contains a yield statement returns a generator.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Generators and iterators are interchangeable.&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;def count(start, step):
    while True:
        yield start
        start += step
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;gt;&amp;gt;&amp;gt; counter = count(10, 2)
&amp;gt;&amp;gt;&amp;gt; next(counter), next(counter), next(counter)
(10, 12, 14)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Type&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Everything is an object.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Every object has a type.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Type and class are synonymous.&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;type&amp;gt; = type(&amp;lt;el&amp;gt;)                          # Or: &amp;lt;el&amp;gt;.__class__
&amp;lt;bool&amp;gt; = isinstance(&amp;lt;el&amp;gt;, &amp;lt;type&amp;gt;)            # Or: issubclass(type(&amp;lt;el&amp;gt;), &amp;lt;type&amp;gt;)
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;gt;&amp;gt;&amp;gt; type('a'), 'a'.__class__, str
(&amp;lt;class 'str'&amp;gt;, &amp;lt;class 'str'&amp;gt;, &amp;lt;class 'str'&amp;gt;)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Some types do not have built-in names, so they must be imported:&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from types import FunctionType, MethodType, LambdaType, GeneratorType, ModuleType
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Abstract Base Classes&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Each abstract base class specifies a set of virtual subclasses. These classes are then recognized by isinstance() and issubclass() as subclasses of the ABC, although they are really not. ABC can also manually decide whether or not a specific class is its virtual subclass, usually based on which methods the class has implemented. For instance, Iterable ABC looks for method iter(), while Collection ABC looks for iter(), contains() and len().&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;gt;&amp;gt;&amp;gt; from collections.abc import Iterable, Collection, Sequence
&amp;gt;&amp;gt;&amp;gt; isinstance([1, 2, 3], Iterable)
True
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-text"&gt;+------------------+------------+------------+------------+
|                  |  Iterable  | Collection |  Sequence  |
+------------------+------------+------------+------------+
| list, range, str |    yes     |    yes     |    yes     |
| dict, set        |    yes     |    yes     |            |
| iter             |    yes     |            |            |
+------------------+------------+------------+------------+
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;gt;&amp;gt;&amp;gt; from numbers import Number, Complex, Real, Rational, Integral
&amp;gt;&amp;gt;&amp;gt; isinstance(123, Number)
True
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-text"&gt;+--------------------+----------+----------+----------+----------+----------+
|                    |  Number  |  Complex |   Real   | Rational | Integral |
+--------------------+----------+----------+----------+----------+----------+
| int                |   yes    |   yes    |   yes    |   yes    |   yes    |
| fractions.Fraction |   yes    |   yes    |   yes    |   yes    |          |
| float              |   yes    |   yes    |   yes    |          |          |
| complex            |   yes    |   yes    |          |          |          |
| decimal.Decimal    |   yes    |          |          |          |          |
+--------------------+----------+----------+----------+----------+----------+
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;String&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Immutable sequence of characters.&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;str&amp;gt;  = &amp;lt;str&amp;gt;.strip()                       # Strips all whitespace characters from both ends.
&amp;lt;str&amp;gt;  = &amp;lt;str&amp;gt;.strip('&amp;lt;chars&amp;gt;')              # Strips passed characters. Also lstrip/rstrip().
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;list&amp;gt; = &amp;lt;str&amp;gt;.split()                       # Splits on one or more whitespace characters.
&amp;lt;list&amp;gt; = &amp;lt;str&amp;gt;.split(sep=None, maxsplit=-1)  # Splits on 'sep' string at most 'maxsplit' times.
&amp;lt;list&amp;gt; = &amp;lt;str&amp;gt;.splitlines(keepends=False)    # On [\n\r\f\v\x1c-\x1e\x85\u2028\u2029] and \r\n.
&amp;lt;str&amp;gt;  = &amp;lt;str&amp;gt;.join(&amp;lt;coll_of_strings&amp;gt;)       # Joins elements by using string as a separator.
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;bool&amp;gt; = &amp;lt;sub_str&amp;gt; in &amp;lt;str&amp;gt;                  # Checks if string contains the substring.
&amp;lt;bool&amp;gt; = &amp;lt;str&amp;gt;.startswith(&amp;lt;sub_str&amp;gt;)         # Pass tuple of strings for multiple options.
&amp;lt;int&amp;gt;  = &amp;lt;str&amp;gt;.find(&amp;lt;sub_str&amp;gt;)               # Returns start index of the first match or -1.
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;str&amp;gt;  = &amp;lt;str&amp;gt;.lower()                       # Lowers the case. Also upper/capitalize/title().
&amp;lt;str&amp;gt;  = &amp;lt;str&amp;gt;.casefold()                    # Same, but converts ẞ/ß to ss, Σ/ς to σ, etc.
&amp;lt;str&amp;gt;  = &amp;lt;str&amp;gt;.replace(old, new [, count])   # Replaces 'old' with 'new' at most 'count' times.
&amp;lt;str&amp;gt;  = &amp;lt;str&amp;gt;.translate(&amp;lt;table&amp;gt;)            # Use `str.maketrans(&amp;lt;dict&amp;gt;)` to generate table.
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;str&amp;gt;  = chr(&amp;lt;int&amp;gt;)                          # Converts passed integer to Unicode character.
&amp;lt;int&amp;gt;  = ord(&amp;lt;str&amp;gt;)                          # Converts passed Unicode character to integer.
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Use &lt;code&gt;'unicodedata.normalize("NFC", &amp;lt;str&amp;gt;)'&lt;/code&gt; on strings like &lt;code&gt;'Motörhead'&lt;/code&gt; before comparing them to other strings, because &lt;code&gt;'ö'&lt;/code&gt; can be stored as one or two characters.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;'NFC'&lt;/code&gt; converts such characters to a single character, while &lt;code&gt;'NFD'&lt;/code&gt; converts them to two.&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Property Methods&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;bool&amp;gt; = &amp;lt;str&amp;gt;.isdecimal()                   # Checks for [0-9]. Also [०-९] and [٠-٩].
&amp;lt;bool&amp;gt; = &amp;lt;str&amp;gt;.isdigit()                     # Checks for [²³¹…] and isdecimal().
&amp;lt;bool&amp;gt; = &amp;lt;str&amp;gt;.isnumeric()                   # Checks for [¼½¾…], [零〇一…] and isdigit().
&amp;lt;bool&amp;gt; = &amp;lt;str&amp;gt;.isalnum()                     # Checks for [a-zA-Z…] and isnumeric().
&amp;lt;bool&amp;gt; = &amp;lt;str&amp;gt;.isprintable()                 # Checks for [ !#$%…] and isalnum().
&amp;lt;bool&amp;gt; = &amp;lt;str&amp;gt;.isspace()                     # Checks for [ \t\n\r\f\v\x1c-\x1f\x85…].
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Regex&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Functions for regular expression matching.&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import re
&amp;lt;str&amp;gt;   = re.sub(r'&amp;lt;regex&amp;gt;', new, text, count=0)  # Substitutes all occurrences with 'new'.
&amp;lt;list&amp;gt;  = re.findall(r'&amp;lt;regex&amp;gt;', text)            # Returns all occurrences of the pattern.
&amp;lt;list&amp;gt;  = re.split(r'&amp;lt;regex&amp;gt;', text, maxsplit=0)  # Add brackets around regex to keep matches.
&amp;lt;Match&amp;gt; = re.search(r'&amp;lt;regex&amp;gt;', text)             # First occurrence of the pattern or None.
&amp;lt;Match&amp;gt; = re.match(r'&amp;lt;regex&amp;gt;', text)              # Searches only at the beginning of the text.
&amp;lt;iter&amp;gt;  = re.finditer(r'&amp;lt;regex&amp;gt;', text)           # Returns all occurrences as Match objects.
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Raw string literals do not interpret escape sequences, thus enabling us to use regex-specific escape sequences that cause SyntaxWarning in normal string literals (since 3.12).&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Argument 'new' of re.sub() can be a function that accepts Match object and returns a str.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Argument &lt;code&gt;'flags=re.IGNORECASE'&lt;/code&gt; can be used with all functions that are listed above.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Argument &lt;code&gt;'flags=re.MULTILINE'&lt;/code&gt; makes &lt;code&gt;'^'&lt;/code&gt; and &lt;code&gt;'$'&lt;/code&gt; match the start/end of each line.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Argument &lt;code&gt;'flags=re.DOTALL'&lt;/code&gt; makes &lt;code&gt;'.'&lt;/code&gt; also accept the &lt;code&gt;'\n'&lt;/code&gt; (besides all other chars).&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;'re.compile(&amp;lt;regex&amp;gt;)'&lt;/code&gt; returns a Pattern object with methods sub(), findall(), etc.&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Match Object&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;str&amp;gt;   = &amp;lt;Match&amp;gt;.group()                         # Returns the whole match. Also group(0).
&amp;lt;str&amp;gt;   = &amp;lt;Match&amp;gt;.group(1)                        # Returns part inside the first brackets.
&amp;lt;tuple&amp;gt; = &amp;lt;Match&amp;gt;.groups()                        # Returns all bracketed parts as strings.
&amp;lt;int&amp;gt;   = &amp;lt;Match&amp;gt;.start()                         # Returns start index of the whole match.
&amp;lt;int&amp;gt;   = &amp;lt;Match&amp;gt;.end()                           # Returns its exclusive end index.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Special Sequences&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;'\d' == '[0-9]'                                   # Also [०-९…]. Matches a decimal character.
'\w' == '[a-zA-Z0-9_]'                            # Also [ª²³…]. Matches an alphanumeric or _.
'\s' == '[ \t\n\r\f\v]'                           # Also [\x1c-\x1f…]. Matches a whitespace.
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;By default, decimal characters and alphanumerics from all alphabets are matched unless &lt;code&gt;'flags=re.ASCII'&lt;/code&gt; is used. It restricts special sequence matches to the first 128 Unicode characters and also prevents &lt;code&gt;'\s'&lt;/code&gt; from accepting &lt;code&gt;'\x1c'&lt;/code&gt;, &lt;code&gt;'\x1d'&lt;/code&gt;, &lt;code&gt;'\x1e'&lt;/code&gt; and &lt;code&gt;'\x1f'&lt;/code&gt; (non-printable characters that divide text into files, tables, rows and fields, respectively).&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Use a capital letter for negation (all non-ASCII characters will be matched when used in combination with ASCII flag).&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Format&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-perl"&gt;&amp;lt;str&amp;gt; = f'{&amp;lt;el_1&amp;gt;}, {&amp;lt;el_2&amp;gt;}'            # Curly braces can also contain expressions.
&amp;lt;str&amp;gt; = '{}, {}'.format(&amp;lt;el_1&amp;gt;, &amp;lt;el_2&amp;gt;)  # Same as '{0}, {a}'.format(&amp;lt;el_1&amp;gt;, a=&amp;lt;el_2&amp;gt;).
&amp;lt;str&amp;gt; = '%s, %s' % (&amp;lt;el_1&amp;gt;, &amp;lt;el_2&amp;gt;)      # Redundant and inferior C-style formatting.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Example&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;gt;&amp;gt;&amp;gt; Person = collections.namedtuple('Person', 'name height')
&amp;gt;&amp;gt;&amp;gt; person = Person('Jean-Luc', 187)
&amp;gt;&amp;gt;&amp;gt; f'{person.name} is {person.height / 100} meters tall.'
'Jean-Luc is 1.87 meters tall.'
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;General Options&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;{&amp;lt;el&amp;gt;:&amp;lt;10}                               # '&amp;lt;el&amp;gt;      '
{&amp;lt;el&amp;gt;:^10}                               # '   &amp;lt;el&amp;gt;   '
{&amp;lt;el&amp;gt;:&amp;gt;10}                               # '      &amp;lt;el&amp;gt;'
{&amp;lt;el&amp;gt;:.&amp;lt;10}                              # '&amp;lt;el&amp;gt;......'
{&amp;lt;el&amp;gt;:0}                                 # '&amp;lt;el&amp;gt;'
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Objects are rendered by calling the &lt;code&gt;'format(&amp;lt;el&amp;gt;, "&amp;lt;options&amp;gt;")'&lt;/code&gt; function.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Options inside curly braces can be generated dynamically: &lt;code&gt;f'{&amp;lt;el&amp;gt;:{&amp;lt;str/int&amp;gt;}[…]}'&lt;/code&gt;.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Adding &lt;code&gt;'='&lt;/code&gt; to the expression prepends it to the output: &lt;code&gt;f'{1+1=}'&lt;/code&gt; returns &lt;code&gt;'1+1=2'&lt;/code&gt;.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Adding &lt;code&gt;'!r'&lt;/code&gt; to the expression converts object to string by calling its &lt;a href="https://raw.githubusercontent.com/gto76/python-cheatsheet/main/#class"&gt;repr()&lt;/a&gt; method.&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Strings&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;{'abcde':10}                             # 'abcde     '
{'abcde':10.3}                           # 'abc       '
{'abcde':.3}                             # 'abc'
{'abcde'!r:10}                           # "'abcde'   "
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Numbers&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;{123456:10}                              # '    123456'
{123456:10,}                             # '   123,456'
{123456:10_}                             # '   123_456'
{123456:+10}                             # '   +123456'
{123456:=+10}                            # '+   123456'
{123456: }                               # ' 123456'
{-123456: }                              # '-123456'
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Floats&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;{1.23456:10.3}                           # '      1.23'
{1.23456:10.3f}                          # '     1.235'
{1.23456:10.3e}                          # ' 1.235e+00'
{1.23456:10.3%}                          # '  123.456%'
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Comparison of presentation types:&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-text"&gt;+--------------+----------------+----------------+----------------+----------------+
|              |    {&amp;lt;float&amp;gt;}   |   {&amp;lt;float&amp;gt;:f}  |   {&amp;lt;float&amp;gt;:e}  |   {&amp;lt;float&amp;gt;:%}  |
+--------------+----------------+----------------+----------------+----------------+
|  0.000056789 |   '5.6789e-05' |    '0.000057'  | '5.678900e-05' |    '0.005679%' |
|  0.00056789  |   '0.00056789' |    '0.000568'  | '5.678900e-04' |    '0.056789%' |
|  0.0056789   |   '0.0056789'  |    '0.005679'  | '5.678900e-03' |    '0.567890%' |
|  0.056789    |   '0.056789'   |    '0.056789'  | '5.678900e-02' |    '5.678900%' |
|  0.56789     |   '0.56789'    |    '0.567890'  | '5.678900e-01' |   '56.789000%' |
|  5.6789      |   '5.6789'     |    '5.678900'  | '5.678900e+00' |  '567.890000%' |
| 56.789       |  '56.789'      |   '56.789000'  | '5.678900e+01' | '5678.900000%' |
+--------------+----------------+----------------+----------------+----------------+
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-text"&gt;+--------------+----------------+----------------+----------------+----------------+
|              |  {&amp;lt;float&amp;gt;:.2}  |  {&amp;lt;float&amp;gt;:.2f} |  {&amp;lt;float&amp;gt;:.2e} |  {&amp;lt;float&amp;gt;:.2%} |
+--------------+----------------+----------------+----------------+----------------+
|  0.000056789 |    '5.7e-05'   |      '0.00'    |   '5.68e-05'   |      '0.01%'   |
|  0.00056789  |    '0.00057'   |      '0.00'    |   '5.68e-04'   |      '0.06%'   |
|  0.0056789   |    '0.0057'    |      '0.01'    |   '5.68e-03'   |      '0.57%'   |
|  0.056789    |    '0.057'     |      '0.06'    |   '5.68e-02'   |      '5.68%'   |
|  0.56789     |    '0.57'      |      '0.57'    |   '5.68e-01'   |     '56.79%'   |
|  5.6789      |    '5.7'       |      '5.68'    |   '5.68e+00'   |    '567.89%'   |
| 56.789       |    '5.7e+01'   |     '56.79'    |   '5.68e+01'   |   '5678.90%'   |
+--------------+----------------+----------------+----------------+----------------+
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;'{&amp;lt;float&amp;gt;:g}'&lt;/code&gt; is &lt;code&gt;'{&amp;lt;float&amp;gt;:.6}'&lt;/code&gt; with stripped zeros, exponent starting at &lt;code&gt;'1e+06'&lt;/code&gt;.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;When both rounding up and rounding down are possible, the one that returns result with even last digit is chosen. That makes &lt;code&gt;'{6.5:.0f}'&lt;/code&gt; a &lt;code&gt;'6'&lt;/code&gt; and &lt;code&gt;'{7.5:.0f}'&lt;/code&gt; an &lt;code&gt;'8'&lt;/code&gt;.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;This rule only effects numbers that can be represented exactly by a float (&lt;code&gt;.5&lt;/code&gt;, &lt;code&gt;.25&lt;/code&gt;, …).&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Ints&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;{90:c}                                   # 'Z'. Unicode character with value 90.
{90:b}                                   # '1011010'. Binary representation of the int.
{90:X}                                   # '5A'. Hexadecimal with upper-case letters.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Numbers&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;int&amp;gt;      = int(&amp;lt;float/str/bool&amp;gt;)             # Whole number of any size. Truncates floats.
&amp;lt;float&amp;gt;    = float(&amp;lt;int/str/bool&amp;gt;)             # 64-bit decimal number. Also &amp;lt;float&amp;gt;e±&amp;lt;int&amp;gt;.
&amp;lt;complex&amp;gt;  = complex(real=0, imag=0)           # A complex number. Also `&amp;lt;float&amp;gt; ± &amp;lt;float&amp;gt;j`.
&amp;lt;Fraction&amp;gt; = fractions.Fraction(&amp;lt;int&amp;gt;, &amp;lt;int&amp;gt;)  # E.g. `Fraction(1, 2) / 3 == Fraction(1, 6)`.
&amp;lt;Decimal&amp;gt;  = decimal.Decimal(&amp;lt;str/int/tuple&amp;gt;)  # E.g. `Decimal((1, (2, 3), 4)) == -230_000`.
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;'int(&amp;lt;str&amp;gt;)'&lt;/code&gt; and &lt;code&gt;'float(&amp;lt;str&amp;gt;)'&lt;/code&gt; raise ValueError if passed string is malformed.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Decimal objects store numbers exactly, unlike most floats where &lt;code&gt;'1.1 + 2.2 != 3.3'&lt;/code&gt;.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Floats can be compared with: &lt;code&gt;'math.isclose(&amp;lt;float&amp;gt;, &amp;lt;float&amp;gt;, rel_tol=1e-09)'&lt;/code&gt;.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Precision of decimal operations is set with: &lt;code&gt;'decimal.getcontext().prec = &amp;lt;int&amp;gt;'&lt;/code&gt;.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Bools can be used anywhere ints can, because bool is a subclass of int: &lt;code&gt;'True + 1 == 2'&lt;/code&gt;.&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Built-in Functions&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;num&amp;gt; = pow(&amp;lt;num&amp;gt;, &amp;lt;num&amp;gt;)                      # E.g. `pow(2, 3) == 2 ** 3 == 8`.
&amp;lt;num&amp;gt; = abs(&amp;lt;num&amp;gt;)                             # E.g. `abs(complex(3, 4)) == 5`.
&amp;lt;num&amp;gt; = round(&amp;lt;num&amp;gt; [, ±ndigits])              # E.g. `round(123, -1) == 120`.
&amp;lt;num&amp;gt; = min(&amp;lt;collection&amp;gt;)                      # Also max(&amp;lt;num&amp;gt;, &amp;lt;num&amp;gt; [, ...]).
&amp;lt;num&amp;gt; = sum(&amp;lt;collection&amp;gt;)                      # Also math.prod(&amp;lt;collection&amp;gt;).
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Math&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from math import floor, ceil, trunc            # They convert floats into integers.
from math import pi, inf, nan, isnan           # `inf * 0` and `nan + 1` return nan.
from math import sqrt, factorial               # `sqrt(-1)` will raise ValueError.
from math import sin, cos, tan                 # Also: asin, acos, degrees, radians.
from math import log, log10, log2              # Log accepts base as second argument.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Statistics&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from statistics import mean, median, mode      # Mode returns the most common item.
from statistics import variance, stdev         # Also: pvariance, pstdev, quantiles.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Random&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from random import random, randint, uniform    # Also: gauss, choice, shuffle, seed.
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;float&amp;gt; = random()                             # Returns a float inside [0, 1).
&amp;lt;num&amp;gt;   = randint/uniform(a, b)                # Returns an int/float inside [a, b].
&amp;lt;float&amp;gt; = gauss(mean, stdev)                   # Also triangular(low, high, mode).
&amp;lt;el&amp;gt;    = choice(&amp;lt;sequence&amp;gt;)                   # Keeps it intact. Also sample(p, n).
shuffle(&amp;lt;list&amp;gt;)                                # Works on all mutable sequences.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Hexadecimal Numbers&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;int&amp;gt; = 0x&amp;lt;hex&amp;gt;                                # E.g. `0xFF == 255`. Also 0b&amp;lt;bin&amp;gt;.
&amp;lt;int&amp;gt; = int('±&amp;lt;hex&amp;gt;', 16)                      # Also int('±0x&amp;lt;hex&amp;gt;/±0b&amp;lt;bin&amp;gt;', 0).
&amp;lt;str&amp;gt; = hex(&amp;lt;int&amp;gt;)                             # Returns '[-]0x&amp;lt;hex&amp;gt;'. Also bin().
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Bitwise Operators&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;int&amp;gt; = &amp;lt;int&amp;gt; &amp;amp; &amp;lt;int&amp;gt;                          # E.g. `0b1100 &amp;amp; 0b1010 == 0b1000`.
&amp;lt;int&amp;gt; = &amp;lt;int&amp;gt; | &amp;lt;int&amp;gt;                          # E.g. `0b1100 | 0b1010 == 0b1110`.
&amp;lt;int&amp;gt; = &amp;lt;int&amp;gt; ^ &amp;lt;int&amp;gt;                          # E.g. `0b1100 ^ 0b1010 == 0b0110`.
&amp;lt;int&amp;gt; = &amp;lt;int&amp;gt; &amp;lt;&amp;lt; n_bits                        # E.g. `0b1111 &amp;lt;&amp;lt; 4 == 0b11110000`.
&amp;lt;int&amp;gt; = ~&amp;lt;int&amp;gt;                                 # E.g. `~0b1 == -0b10 == -(0b1+1)`.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Combinatorics&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import itertools as it
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;gt;&amp;gt;&amp;gt; list(it.product('abc', repeat=2))        #   a  b  c
[('a', 'a'), ('a', 'b'), ('a', 'c'),         # a x  x  x
 ('b', 'a'), ('b', 'b'), ('b', 'c'),         # b x  x  x
 ('c', 'a'), ('c', 'b'), ('c', 'c')]         # c x  x  x
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;gt;&amp;gt;&amp;gt; list(it.permutations('abc', 2))          #   a  b  c
[('a', 'b'), ('a', 'c'),                     # a .  x  x
 ('b', 'a'), ('b', 'c'),                     # b x  .  x
 ('c', 'a'), ('c', 'b')]                     # c x  x  .
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;gt;&amp;gt;&amp;gt; list(it.combinations('abc', 2))          #   a  b  c
[('a', 'b'), ('a', 'c'),                     # a .  x  x
 ('b', 'c')                                  # b .  .  x
]                                            # c .  .  .
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Datetime&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Provides 'date', 'time', 'datetime' and 'timedelta' classes. All are immutable and hashable.&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# $ pip3 install python-dateutil
from datetime import date, time, datetime, timedelta, timezone
import zoneinfo, dateutil.tz
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;D&amp;gt;  = date(year, month, day)               # Only accepts valid dates from 1 to 9999 AD.
&amp;lt;T&amp;gt;  = time(hour=0, minute=0, second=0)     # Also: `microsecond=0, tzinfo=None, fold=0`.
&amp;lt;DT&amp;gt; = datetime(year, month, day, hour=0)   # Also: `minute=0, second=0, microsecond=0, …`.
&amp;lt;TD&amp;gt; = timedelta(weeks=0, days=0, hours=0)  # Also: `minutes=0, seconds=0, microseconds=0`.
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Times and datetimes that have defined timezone are called aware and ones that don't, naive. If time or datetime object is naive, it is presumed to be in the system's timezone!&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;'fold=1'&lt;/code&gt; means the second pass in case of time jumping back (usually for one hour).&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Timedelta normalizes arguments to ±days, seconds (&amp;lt; 86 400) and microseconds (&amp;lt; 1M). Its str() method returns &lt;code&gt;'[±D, ]H:MM:SS[.…]'&lt;/code&gt; and total_seconds() a float of all seconds.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Use &lt;code&gt;'&amp;lt;D/DT&amp;gt;.weekday()'&lt;/code&gt; to get the day of the week as an integer, with Monday being 0.&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Now&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;D/DTn&amp;gt; = D/DT.today()                      # Current local date or naive DT. Also DT.now().
&amp;lt;DTa&amp;gt;   = DT.now(&amp;lt;tzinfo&amp;gt;)                  # Aware DT from current time in passed timezone.
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;To extract time use &lt;code&gt;'&amp;lt;DTn&amp;gt;.time()'&lt;/code&gt;, &lt;code&gt;'&amp;lt;DTa&amp;gt;.time()'&lt;/code&gt; or &lt;code&gt;'&amp;lt;DTa&amp;gt;.timetz()'&lt;/code&gt;.&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Timezones&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;tzinfo&amp;gt; = timezone.utc                     # Coordinated universal time (UK without DST).
&amp;lt;tzinfo&amp;gt; = timezone(&amp;lt;timedelta&amp;gt;)            # Timezone with fixed offset from universal time.
&amp;lt;tzinfo&amp;gt; = dateutil.tz.tzlocal()            # Local timezone with dynamic offset from UTC.
&amp;lt;tzinfo&amp;gt; = zoneinfo.ZoneInfo('&amp;lt;iana_key&amp;gt;')  # 'Continent/City_Name' zone with dynamic offset.
&amp;lt;DTa&amp;gt;    = &amp;lt;DT&amp;gt;.astimezone([&amp;lt;tzinfo&amp;gt;])      # Converts DT to the passed or local fixed zone.
&amp;lt;Ta/DTa&amp;gt; = &amp;lt;T/DT&amp;gt;.replace(tzinfo=&amp;lt;tzinfo&amp;gt;)  # Changes object's timezone without conversion.
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Timezones returned by tzlocal(), ZoneInfo() and implicit local timezone of naive objects have offsets that vary through time due to DST and historical changes of the base offset.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;To get ZoneInfo() to work on Windows run &lt;code&gt;'&amp;gt; pip3 install tzdata'&lt;/code&gt;.&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Encode&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;D/T/DT&amp;gt; = D/T/DT.fromisoformat(&amp;lt;str&amp;gt;)      # Object from ISO string. Raises ValueError.
&amp;lt;DT&amp;gt;     = DT.strptime(&amp;lt;str&amp;gt;, '&amp;lt;format&amp;gt;')   # Datetime from custom string. See Format.
&amp;lt;D/DTn&amp;gt;  = D/DT.fromordinal(&amp;lt;int&amp;gt;)          # D/DT from days since the Gregorian NYE 1.
&amp;lt;DTn&amp;gt;    = DT.fromtimestamp(&amp;lt;float&amp;gt;)        # Local naive DT from seconds since the Epoch.
&amp;lt;DTa&amp;gt;    = DT.fromtimestamp(&amp;lt;float&amp;gt;, &amp;lt;tz&amp;gt;)  # Aware datetime from seconds since the Epoch.
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;ISO strings come in following forms: &lt;code&gt;'YYYY-MM-DD'&lt;/code&gt;, &lt;code&gt;'HH:MM:SS.mmmuuu[±HH:MM]'&lt;/code&gt;, or both separated by an arbitrary character. All parts following the hours are optional.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Python uses the Unix Epoch: &lt;code&gt;'1970-01-01 00:00 UTC'&lt;/code&gt;, &lt;code&gt;'1970-01-01 01:00 CET'&lt;/code&gt;, ...&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Decode&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;str&amp;gt;    = &amp;lt;D/T/DT&amp;gt;.isoformat(sep='T')      # Also `timespec='auto/hours/minutes/seconds…'`.
&amp;lt;str&amp;gt;    = &amp;lt;D/T/DT&amp;gt;.strftime('&amp;lt;format&amp;gt;')    # Custom string representation of the object.
&amp;lt;int&amp;gt;    = &amp;lt;D/DT&amp;gt;.toordinal()               # Days since NYE 1. Ignores DT's time and zone.
&amp;lt;float&amp;gt;  = &amp;lt;DTn&amp;gt;.timestamp()                # Seconds since the Epoch, from local naive DT.
&amp;lt;float&amp;gt;  = &amp;lt;DTa&amp;gt;.timestamp()                # Seconds since the Epoch, from aware datetime.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Format&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;gt;&amp;gt;&amp;gt; dt = datetime.strptime('2025-08-14 23:39:00.00 +0200', '%Y-%m-%d %H:%M:%S.%f %z')
&amp;gt;&amp;gt;&amp;gt; dt.strftime("%dth of %B '%y (%a), %I:%M %p %Z")
"14th of August '25 (Thu), 11:39 PM UTC+02:00"
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;'%z'&lt;/code&gt; accepts &lt;code&gt;'±HH[:]MM'&lt;/code&gt; and returns &lt;code&gt;'±HHMM'&lt;/code&gt; or empty string if object is naive.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;'%Z'&lt;/code&gt; accepts &lt;code&gt;'UTC/GMT'&lt;/code&gt; and local timezone's code and returns timezone's name, &lt;code&gt;'UTC[±HH:MM]'&lt;/code&gt; if timezone is nameless, or an empty string if object is naive.&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Arithmetics&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;bool&amp;gt;   = &amp;lt;D/T/DTn&amp;gt; &amp;gt; &amp;lt;D/T/DTn&amp;gt;            # Ignores time jumps (fold attribute). Also ==.
&amp;lt;bool&amp;gt;   = &amp;lt;DTa&amp;gt;     &amp;gt; &amp;lt;DTa&amp;gt;                # Ignores time jumps if they share tzinfo object.
&amp;lt;TD&amp;gt;     = &amp;lt;D/DTn&amp;gt;   - &amp;lt;D/DTn&amp;gt;              # Ignores jumps. Convert to UTC for actual delta.
&amp;lt;TD&amp;gt;     = &amp;lt;DTa&amp;gt;     - &amp;lt;DTa&amp;gt;                # Ignores jumps if they share the tzinfo object.
&amp;lt;D/DT&amp;gt;   = &amp;lt;D/DT&amp;gt;    ± &amp;lt;TD&amp;gt;                 # Returned datetime can fall into missing hour.
&amp;lt;TD&amp;gt;     = &amp;lt;TD&amp;gt;      * &amp;lt;float&amp;gt;              # Also `&amp;lt;TD&amp;gt; = abs(&amp;lt;TD&amp;gt;)`, `&amp;lt;TD&amp;gt; = &amp;lt;TD&amp;gt; ± &amp;lt;TD&amp;gt;`.
&amp;lt;float&amp;gt;  = &amp;lt;TD&amp;gt;      / &amp;lt;TD&amp;gt;                 # Also `(&amp;lt;int&amp;gt;, &amp;lt;TD&amp;gt;) = divmod(&amp;lt;TD&amp;gt;, &amp;lt;TD&amp;gt;)`.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Function&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Independent block of code that returns a value when called.&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;def &amp;lt;func_name&amp;gt;(&amp;lt;nondefault_args&amp;gt;): ...                  # E.g. `def func(x, y): ...`.
def &amp;lt;func_name&amp;gt;(&amp;lt;default_args&amp;gt;): ...                     # E.g. `def func(x=0, y=0): ...`.
def &amp;lt;func_name&amp;gt;(&amp;lt;nondefault_args&amp;gt;, &amp;lt;default_args&amp;gt;): ...  # E.g. `def func(x, y=0): ...`.
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Function returns None if it doesn't encounter &lt;code&gt;'return &amp;lt;obj/exp&amp;gt;'&lt;/code&gt; statement.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Run &lt;code&gt;'global &amp;lt;var_name&amp;gt;'&lt;/code&gt; inside the function before assigning to global variable.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Default values are evaluated when function is first encountered in the scope. Any mutation of a mutable default value will persist between invocations!&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Function Call&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;obj&amp;gt; = &amp;lt;function&amp;gt;(&amp;lt;positional_args&amp;gt;)                    # E.g. `func(0, 0)`.
&amp;lt;obj&amp;gt; = &amp;lt;function&amp;gt;(&amp;lt;keyword_args&amp;gt;)                       # E.g. `func(x=0, y=0)`.
&amp;lt;obj&amp;gt; = &amp;lt;function&amp;gt;(&amp;lt;positional_args&amp;gt;, &amp;lt;keyword_args&amp;gt;)    # E.g. `func(0, y=0)`.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Splat Operator&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Splat expands a collection into positional arguments, while splatty-splat expands a dictionary into keyword arguments.&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;args, kwargs = (1, 2), {'z': 3}
func(*args, **kwargs)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Is the same as:&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;func(1, 2, z=3)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Inside Function Definition&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Splat combines zero or more positional arguments into a tuple, while splatty-splat combines zero or more keyword arguments into a dictionary.&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;def add(*a):
    return sum(a)
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;gt;&amp;gt;&amp;gt; add(1, 2, 3)
6
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Allowed compositions of arguments and the ways they can be called:&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-text"&gt;+---------------------------+--------------+--------------+----------------+
|                           |  func(1, 2)  | func(1, y=2) | func(x=1, y=2) |
+---------------------------+--------------+--------------+----------------+
| func(x, *args, **kwargs): |     yes      |     yes      |      yes       |
| func(*args, y, **kwargs): |              |     yes      |      yes       |
| func(*, x, **kwargs):     |              |              |      yes       |
+---------------------------+--------------+--------------+----------------+
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Other Uses&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;list&amp;gt;  = [*&amp;lt;collection&amp;gt; [, ...]]  # Or: list(&amp;lt;coll&amp;gt;) [+ ...]
&amp;lt;tuple&amp;gt; = (*&amp;lt;collection&amp;gt;, [...])   # Or: tuple(&amp;lt;coll&amp;gt;) [+ ...]
&amp;lt;set&amp;gt;   = {*&amp;lt;collection&amp;gt; [, ...]}  # Or: set(&amp;lt;coll&amp;gt;) [| ...]
&amp;lt;dict&amp;gt;  = {**&amp;lt;dict&amp;gt; [, ...]}       # Or: &amp;lt;dict&amp;gt; | ...
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;head, *body, tail = &amp;lt;collection&amp;gt;   # Head or tail can be omitted.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Inline&lt;/h2&gt; 
&lt;h3&gt;Lambda&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;func&amp;gt; = lambda: &amp;lt;return_value&amp;gt;                     # A single statement function.
&amp;lt;func&amp;gt; = lambda &amp;lt;arg_1&amp;gt;, &amp;lt;arg_2&amp;gt;: &amp;lt;return_value&amp;gt;    # Also allows default arguments.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Comprehensions&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;list&amp;gt; = [i+1 for i in range(10)]                   # Returns [1, 2, ..., 10].
&amp;lt;iter&amp;gt; = (i for i in range(10) if i &amp;gt; 5)            # Returns iter([6, 7, 8, 9]).
&amp;lt;set&amp;gt;  = {i+5 for i in range(10)}                   # Returns {5, 6, ..., 14}.
&amp;lt;dict&amp;gt; = {i: i*2 for i in range(10)}                # Returns {0: 0, 1: 2, ..., 9: 18}.
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;gt;&amp;gt;&amp;gt; [l+r for l in 'abc' for r in 'abc']             # Inner loop is on the right side.
['aa', 'ab', 'ac', ..., 'cc']
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Map, Filter, Reduce&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from functools import reduce
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;iter&amp;gt; = map(lambda x: x + 1, range(10))            # Returns iter([1, 2, ..., 10]).
&amp;lt;iter&amp;gt; = filter(lambda x: x &amp;gt; 5, range(10))         # Returns iter([6, 7, 8, 9]).
&amp;lt;obj&amp;gt;  = reduce(lambda out, x: out + x, range(10))  # Returns 45.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Any, All&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;bool&amp;gt; = any(&amp;lt;collection&amp;gt;)                          # Is `bool(&amp;lt;el&amp;gt;)` True for any el?
&amp;lt;bool&amp;gt; = all(&amp;lt;collection&amp;gt;)                          # True for all? Also True if empty.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Conditional Expression&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;obj&amp;gt; = &amp;lt;exp&amp;gt; if &amp;lt;condition&amp;gt; else &amp;lt;exp&amp;gt;             # Only one expression is evaluated.
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;gt;&amp;gt;&amp;gt; [i if i else 'zero' for i in (0, 1, 2, 3)]      # `any([0, '', [], None]) == False`
['zero', 1, 2, 3]
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;And, Or&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;obj&amp;gt; = &amp;lt;exp&amp;gt; and &amp;lt;exp&amp;gt; [and ...]                   # Returns first false or last object.
&amp;lt;obj&amp;gt; = &amp;lt;exp&amp;gt; or &amp;lt;exp&amp;gt; [or ...]                     # Returns first true or last object.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Walrus Operator&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;gt;&amp;gt;&amp;gt; [i for ch in '0123' if (i := int(ch)) &amp;gt; 0]      # Assigns to variable mid-sentence.
[1, 2, 3]
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Named Tuple, Enum, Dataclass&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from collections import namedtuple
Point = namedtuple('Point', 'x y')                  # Creates tuple's subclass.
point = Point(0, 0)                                 # Returns its instance.

from enum import Enum
Direction = Enum('Direction', 'N E S W')            # Creates Enum's subclass.
direction = Direction.N                             # Returns its member.

from dataclasses import make_dataclass
Player = make_dataclass('Player', ['loc', 'dir'])   # Creates a class.
player = Player(point, direction)                   # Returns its instance.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Imports&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Mechanism that makes code in one file available to another file.&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import &amp;lt;module&amp;gt;            # Imports a built-in or '&amp;lt;module&amp;gt;.py'.
import &amp;lt;package&amp;gt;           # Imports a built-in or '&amp;lt;package&amp;gt;/__init__.py'.
import &amp;lt;package&amp;gt;.&amp;lt;module&amp;gt;  # Imports a built-in or '&amp;lt;package&amp;gt;/&amp;lt;module&amp;gt;.py'.
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Package is a collection of modules, but it can also define its own functions, classes, etc.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;On a filesystem this corresponds to a directory of Python files with an optional init script.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Running &lt;code&gt;'import &amp;lt;package&amp;gt;'&lt;/code&gt; does not automatically provide access to the package's modules unless they are explicitly imported in the &lt;code&gt;'&amp;lt;package&amp;gt;/__init__.py'&lt;/code&gt; script.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Directory of the file that is passed to python command serves as a root of local imports.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;For relative imports use &lt;code&gt;'from .[…][&amp;lt;pkg/module&amp;gt;[.…]] import &amp;lt;obj&amp;gt;'&lt;/code&gt;.&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Closure&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;We have/get a closure in Python when a nested function references a value of its enclosing function and then the enclosing function returns its nested function.&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;def get_multiplier(a):
    def out(b):
        return a * b
    return out
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;gt;&amp;gt;&amp;gt; multiply_by_3 = get_multiplier(3)
&amp;gt;&amp;gt;&amp;gt; multiply_by_3(10)
30
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Any value that is referenced from within multiple nested functions gets shared.&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Partial&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from functools import partial
&amp;lt;function&amp;gt; = partial(&amp;lt;function&amp;gt; [, &amp;lt;arg_1&amp;gt; [, ...]])
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;gt;&amp;gt;&amp;gt; def multiply(a, b):
...     return a * b
&amp;gt;&amp;gt;&amp;gt; multiply_by_3 = partial(multiply, 3)
&amp;gt;&amp;gt;&amp;gt; multiply_by_3(10)
30
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Partial is also useful in cases when a function needs to be passed as an argument because it enables us to set its arguments beforehand (&lt;code&gt;'collections.defaultdict(&amp;lt;func&amp;gt;)'&lt;/code&gt;, &lt;code&gt;'iter(&amp;lt;func&amp;gt;, to_exc)'&lt;/code&gt; and &lt;code&gt;'dataclasses.field(default_factory=&amp;lt;func&amp;gt;)'&lt;/code&gt;).&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Non-Local&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;If variable is being assigned to anywhere in the scope, it is regarded as a local variable, unless it is declared as a 'global' or a 'nonlocal'.&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;def get_counter():
    i = 0
    def out():
        nonlocal i
        i += 1
        return i
    return out
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;gt;&amp;gt;&amp;gt; counter = get_counter()
&amp;gt;&amp;gt;&amp;gt; counter(), counter(), counter()
(1, 2, 3)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Decorator&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;A decorator takes a function, adds some functionality and returns it. It can be any &lt;a href="https://raw.githubusercontent.com/gto76/python-cheatsheet/main/#callable"&gt;callable&lt;/a&gt;, but is usually implemented as a function that returns a &lt;a href="https://raw.githubusercontent.com/gto76/python-cheatsheet/main/#closure"&gt;closure&lt;/a&gt;.&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;@decorator_name
def function_that_gets_passed_to_decorator():
    ...
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Debugger Example&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Decorator that prints function's name every time the function is called.&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from functools import wraps

def debug(func):
    @wraps(func)
    def out(*args, **kwargs):
        print(func.__name__)
        return func(*args, **kwargs)
    return out

@debug
def add(x, y):
    return x + y
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Wraps is a helper decorator that copies the metadata of the passed function (func) to the function it is wrapping (out). Without it, &lt;code&gt;'add.__name__'&lt;/code&gt; would return &lt;code&gt;'out'&lt;/code&gt;.&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Cache&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Decorator that caches function's return values. All function's arguments must be hashable.&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from functools import cache

@cache
def fib(n):
    return n if n &amp;lt; 2 else fib(n-2) + fib(n-1)
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Potential problem with cache is that it can grow indefinitely. To clear stored values run &lt;code&gt;'&amp;lt;func&amp;gt;.cache_clear()'&lt;/code&gt;, or use &lt;code&gt;'@lru_cache(maxsize=&amp;lt;int&amp;gt;)'&lt;/code&gt; decorator instead.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;CPython interpreter limits recursion depth to 3000 by default. To increase it run &lt;code&gt;'sys.setrecursionlimit(&amp;lt;int&amp;gt;)'&lt;/code&gt;.&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Parametrized Decorator&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;A decorator that accepts arguments and returns a normal decorator that accepts a function.&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from functools import wraps

def debug(print_result=False):
    def decorator(func):
        @wraps(func)
        def out(*args, **kwargs):
            result = func(*args, **kwargs)
            print(func.__name__, result if print_result else '')
            return result
        return out
    return decorator

@debug(print_result=True)
def add(x, y):
    return x + y
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Using only &lt;code&gt;'@debug'&lt;/code&gt; to decorate the add() function would not work here, because debug would then receive the add() function as a 'print_result' argument. Decorators can however manually check if the argument they received is a function and act accordingly.&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Class&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;A template for creating user-defined objects.&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;class MyClass:
    def __init__(self, a):
        self.a = a
    def __str__(self):
        return str(self.a)
    def __repr__(self):
        class_name = self.__class__.__name__
        return f'{class_name}({self.a!r})'

    @classmethod
    def get_class_name(cls):
        return cls.__name__
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;gt;&amp;gt;&amp;gt; obj = MyClass(1)
&amp;gt;&amp;gt;&amp;gt; obj.a, str(obj), repr(obj)
(1, '1', 'MyClass(1)')
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Methods whose names start and end with two underscores are called special methods. They are executed when object is passed to a built-in function or used as an operand, for&amp;nbsp;example, &lt;code&gt;'print(a)'&lt;/code&gt; calls &lt;code&gt;'a.__str__()'&lt;/code&gt; and &lt;code&gt;'a + b'&lt;/code&gt; calls &lt;code&gt;'a.__add__(b)'&lt;/code&gt;.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Methods decorated with &lt;code&gt;'@staticmethod'&lt;/code&gt; receive neither 'self' nor 'cls' argument.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Return value of str() special method should be readable and of repr() unambiguous. If only repr() is defined, it will also be used for str().&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Expressions that call the str() method:&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;print(&amp;lt;obj&amp;gt;)
f'{&amp;lt;obj&amp;gt;}'
logging.warning(&amp;lt;obj&amp;gt;)
csv.writer(&amp;lt;file&amp;gt;).writerow([&amp;lt;obj&amp;gt;])
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Expressions that call the repr() method:&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;print/str/repr([&amp;lt;obj&amp;gt;])
print/str/repr({&amp;lt;obj&amp;gt;: &amp;lt;obj&amp;gt;})
f'{&amp;lt;obj&amp;gt;!r}'
Z = make_dataclass('Z', ['a']); print/str/repr(Z(&amp;lt;obj&amp;gt;))
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Subclass&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Inheritance is a mechanism that enables a class to extend some other class (that is, subclass to extend its parent), and by doing so inherit all of its methods and attributes.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Subclass can then add its own methods and attributes or override inherited ones by reusing their names.&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;class Person:
    def __init__(self, name):
        self.name = name
    def __repr__(self):
        return f'Person({self.name!r})'
    def __lt__(self, other):
        return self.name &amp;lt; other.name

class Employee(Person):
    def __init__(self, name, staff_num):
        super().__init__(name)
        self.staff_num = staff_num
    def __repr__(self):
        return f'Employee({self.name!r}, {self.staff_num})'
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;gt;&amp;gt;&amp;gt; people = {Person('Ann'), Employee('Bob', 0)}
&amp;gt;&amp;gt;&amp;gt; sorted(people)
[Person('Ann'), Employee('Bob', 0)]
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Type Annotations&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;They add type hints to variables, arguments and functions (&lt;code&gt;'def f() -&amp;gt; &amp;lt;type&amp;gt;:'&lt;/code&gt;).&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Hints are used by type checkers like &lt;a href="https://pypi.org/project/mypy/"&gt;mypy&lt;/a&gt;, data validation libraries such as &lt;a href="https://pypi.org/project/pydantic/"&gt;Pydantic&lt;/a&gt; and lately also by &lt;a href="https://pypi.org/project/Cython/"&gt;Cython&lt;/a&gt; compiler. However, they are not enforced by CPython interpreter.&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from collections import abc

&amp;lt;name&amp;gt;: &amp;lt;type&amp;gt; [| ...] [= &amp;lt;obj&amp;gt;]
&amp;lt;name&amp;gt;: list/set/abc.Iterable/abc.Sequence[&amp;lt;type&amp;gt;] [= &amp;lt;obj&amp;gt;]
&amp;lt;name&amp;gt;: tuple/dict[&amp;lt;type&amp;gt;, ...] [= &amp;lt;obj&amp;gt;]
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Dataclass&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Decorator that uses class variables to generate init(), repr() and eq() special methods.&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from dataclasses import dataclass, field, make_dataclass

@dataclass(order=False, frozen=False)
class &amp;lt;class_name&amp;gt;:
    &amp;lt;attr_name&amp;gt;: &amp;lt;type&amp;gt;
    &amp;lt;attr_name&amp;gt;: &amp;lt;type&amp;gt; = &amp;lt;default_value&amp;gt;
    &amp;lt;attr_name&amp;gt;: list/dict/set = field(default_factory=list/dict/set)
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Objects can be made &lt;a href="https://raw.githubusercontent.com/gto76/python-cheatsheet/main/#sortable"&gt;sortable&lt;/a&gt; with &lt;code&gt;'order=True'&lt;/code&gt; and immutable with &lt;code&gt;'frozen=True'&lt;/code&gt;.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;For object to be &lt;a href="https://raw.githubusercontent.com/gto76/python-cheatsheet/main/#hashable"&gt;hashable&lt;/a&gt;, all attributes must be hashable and 'frozen' must be True.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Function field() is needed because &lt;code&gt;'&amp;lt;attr_name&amp;gt;: list = []'&lt;/code&gt; would make a list that is shared among all instances. Its 'default_factory' argument accepts any &lt;a href="https://raw.githubusercontent.com/gto76/python-cheatsheet/main/#callable"&gt;callable&lt;/a&gt; object.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;For attributes of arbitrary type use &lt;code&gt;'typing.Any'&lt;/code&gt;.&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;P = make_dataclass('P', ['x', 'y'])
P = make_dataclass('P', [('x', float), ('y', float)])
P = make_dataclass('P', [('x', float, 0), ('y', float, 0)])
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Property&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Pythonic way of implementing getters and setters.&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;class Person:
    @property
    def name(self):
        return ' '.join(self._name)

    @name.setter
    def name(self, value):
        self._name = value.split()
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;gt;&amp;gt;&amp;gt; person = Person()
&amp;gt;&amp;gt;&amp;gt; person.name = '\t Guido  van Rossum \n'
&amp;gt;&amp;gt;&amp;gt; person.name
'Guido van Rossum'
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Slots&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Mechanism that restricts objects to attributes listed in 'slots'.&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;class MyClassWithSlots:
    __slots__ = ['a']
    def __init__(self):
        self.a = 1
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Copy&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from copy import copy, deepcopy
&amp;lt;object&amp;gt; = copy/deepcopy(&amp;lt;object&amp;gt;)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Duck Types&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;A duck type is an implicit type that prescribes a set of special methods. Any object that has those methods defined is considered a member of that duck type.&lt;/strong&gt;&lt;/p&gt; 
&lt;h3&gt;Comparable&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;If eq() method is not overridden, it returns &lt;code&gt;'id(self) == id(other)'&lt;/code&gt;, which is the same as &lt;code&gt;'self is other'&lt;/code&gt;. That means all user-defined objects compare not equal by default (because id() returns object's memory address that is guaranteed to be unique).&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Only the left side object has eq() method called, unless it returns NotImplemented, in which case the right object is consulted. Result is False if both return NotImplemented.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Ne() automatically works on any object that has eq() defined.&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;class MyComparable:
    def __init__(self, a):
        self.a = a
    def __eq__(self, other):
        if isinstance(other, type(self)):
            return self.a == other.a
        return NotImplemented
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Hashable&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Hashable object needs both hash() and eq() methods and its hash value must not change.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Hashable objects that compare equal must have the same hash value, meaning default hash() that returns &lt;code&gt;'id(self)'&lt;/code&gt; will not do. That is why Python automatically makes classes unhashable if you only implement eq().&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;class MyHashable:
    def __init__(self, a):
        self._a = a
    @property
    def a(self):
        return self._a
    def __eq__(self, other):
        if isinstance(other, type(self)):
            return self.a == other.a
        return NotImplemented
    def __hash__(self):
        return hash(self.a)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Sortable&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;With 'total_ordering' decorator, you only need to provide eq() and one of lt(), gt(), le() or ge() special methods (used by &amp;lt;, &amp;gt;, &amp;lt;=, &amp;gt;=) and the rest will be automatically generated.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Functions sorted() and min() only require lt() method, while max() only requires gt(). However, it is best to define them all so that confusion doesn't arise in other contexts.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;When two lists, strings or dataclasses are compared, their values get compared in order until a pair of unequal values is found. The comparison of this two values is then returned. The shorter sequence is considered smaller in case of all values being equal.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;To sort collection of strings in proper alphabetical order pass &lt;code&gt;'key=locale.strxfrm'&lt;/code&gt; to sorted() after running &lt;code&gt;'locale.setlocale(locale.LC_COLLATE, "en_US.UTF-8")'&lt;/code&gt;.&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from functools import total_ordering

@total_ordering
class MySortable:
    def __init__(self, a):
        self.a = a
    def __eq__(self, other):
        if isinstance(other, type(self)):
            return self.a == other.a
        return NotImplemented
    def __lt__(self, other):
        if isinstance(other, type(self)):
            return self.a &amp;lt; other.a
        return NotImplemented
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Iterator&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Any object that has methods next() and iter() is an iterator.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Next() should return next item or raise StopIteration exception.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Iter() should return an iterator of remaining items, i.e. 'self'.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Any object that has iter() method can be used in a for loop.&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;class Counter:
    def __init__(self):
        self.i = 0
    def __next__(self):
        self.i += 1
        return self.i
    def __iter__(self):
        return self
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;gt;&amp;gt;&amp;gt; counter = Counter()
&amp;gt;&amp;gt;&amp;gt; next(counter), next(counter), next(counter)
(1, 2, 3)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Python has many different iterator objects:&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Sequence iterators returned by the &lt;a href="https://raw.githubusercontent.com/gto76/python-cheatsheet/main/#iterator"&gt;iter()&lt;/a&gt; function, such as list_iterator, etc.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Objects returned by the &lt;a href="https://raw.githubusercontent.com/gto76/python-cheatsheet/main/#itertools"&gt;itertools&lt;/a&gt; module, such as count, repeat and cycle.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Generators returned by the &lt;a href="https://raw.githubusercontent.com/gto76/python-cheatsheet/main/#generator"&gt;generator functions&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/gto76/python-cheatsheet/main/#comprehensions"&gt;generator expressions&lt;/a&gt;.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;File objects returned by the &lt;a href="https://raw.githubusercontent.com/gto76/python-cheatsheet/main/#open"&gt;open()&lt;/a&gt; function, etc.&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Callable&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;All functions and classes have a call() method that is executed when they are called.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Use &lt;code&gt;'callable(&amp;lt;obj&amp;gt;)'&lt;/code&gt; or &lt;code&gt;'isinstance(&amp;lt;obj&amp;gt;, collections.abc.Callable)'&lt;/code&gt; to check if object is callable. You can also call the object and check if it raised TypeError.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;When this cheatsheet uses &lt;code&gt;'&amp;lt;function&amp;gt;'&lt;/code&gt; as an argument, it means &lt;code&gt;'&amp;lt;callable&amp;gt;'&lt;/code&gt;.&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;class Counter:
    def __init__(self):
        self.i = 0
    def __call__(self):
        self.i += 1
        return self.i
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;gt;&amp;gt;&amp;gt; counter = Counter()
&amp;gt;&amp;gt;&amp;gt; counter(), counter(), counter()
(1, 2, 3)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Context Manager&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;With statements only work on objects that have enter() and exit() special methods.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Enter() should lock the resources and optionally return an object (file, lock, etc.).&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Exit() should release the resources (for example close a file, release a lock, etc.).&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Any exception that happens inside the with block is passed to the exit() method.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;The exit() method can suppress the exception by returning a true value.&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;class MyOpen:
    def __init__(self, filename):
        self.filename = filename
    def __enter__(self):
        self.file = open(self.filename)
        return self.file
    def __exit__(self, exc_type, exception, traceback):
        self.file.close()
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;gt;&amp;gt;&amp;gt; with open('test.txt', 'w') as file:
...     file.write('Hello World!')
&amp;gt;&amp;gt;&amp;gt; with MyOpen('test.txt') as file:
...     print(file.read())
Hello World!
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Iterable Duck Types&lt;/h2&gt; 
&lt;h3&gt;Iterable&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Only required method is iter(). It should return an iterator of object's items.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Contains() automatically works on any object that has iter() defined.&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;class MyIterable:
    def __init__(self, a):
        self.a = a
    def __iter__(self):
        return iter(self.a)
    def __contains__(self, el):
        return el in self.a
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;gt;&amp;gt;&amp;gt; obj = MyIterable([1, 2, 3])
&amp;gt;&amp;gt;&amp;gt; [el for el in obj]
[1, 2, 3]
&amp;gt;&amp;gt;&amp;gt; 1 in obj
True
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Collection&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Only required methods are iter() and len(). Len() should return the number of items.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;This cheatsheet actually means &lt;code&gt;'&amp;lt;iterable&amp;gt;'&lt;/code&gt; when it uses the &lt;code&gt;'&amp;lt;collection&amp;gt;'&lt;/code&gt;.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;I chose not to use the name 'iterable' because it sounds scarier and more vague than 'collection'. The main drawback of this decision is that the reader could think a certain function doesn't accept iterators when it does, since iterators are the only built-in objects that are iterable but are not collections.&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;class MyCollection:
    def __init__(self, a):
        self.a = a
    def __iter__(self):
        return iter(self.a)
    def __contains__(self, el):
        return el in self.a
    def __len__(self):
        return len(self.a)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Sequence&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Only required methods are getitem() and len(). Getitem() should return the item at the passed index or raise IndexError (it may also support negative indices and/or slices).&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Iter() and contains() automatically work on any object that has getitem() defined.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Reversed() automatically works on any object that has getitem() and len() defined. It returns reversed iterator of object's items.&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;class MySequence:
    def __init__(self, a):
        self.a = a
    def __iter__(self):
        return iter(self.a)
    def __contains__(self, el):
        return el in self.a
    def __len__(self):
        return len(self.a)
    def __getitem__(self, i):
        return self.a[i]
    def __reversed__(self):
        return reversed(self.a)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Discrepancies between glossary definitions and abstract base classes:&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Python's glossary defines iterable as any object with special methods iter() and/or getitem() and sequence as any object with getitem() and len(). It doesn't define collection.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Passing ABC Iterable to isinstance() or issubclass() only checks whether object/class has special method iter(), while ABC Collection checks for iter(), contains() and len().&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;ABC Sequence&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;It's a richer interface than the basic sequence that also requires just getitem() and len().&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Extending it generates iter(), contains(), reversed(), index() and count() special methods.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Unlike &lt;code&gt;'abc.Iterable'&lt;/code&gt; and &lt;code&gt;'abc.Collection'&lt;/code&gt;, it is not a duck type. That is why &lt;code&gt;'issubclass(MySequence, abc.Sequence)'&lt;/code&gt; would return False even if MySequence had all the methods defined. It however recognizes list, tuple, range, str, bytes, bytearray, array, memoryview and deque, since they are registered as Sequence's virtual subclasses.&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from collections import abc

class MyAbcSequence(abc.Sequence):
    def __init__(self, a):
        self.a = a
    def __len__(self):
        return len(self.a)
    def __getitem__(self, i):
        return self.a[i]
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Table of required and automatically available special methods:&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-text"&gt;+------------+------------+------------+------------+--------------+
|            |  Iterable  | Collection |  Sequence  | abc.Sequence |
+------------+------------+------------+------------+--------------+
| iter()     |    REQ     |    REQ     |    Yes     |     Yes      |
| contains() |    Yes     |    Yes     |    Yes     |     Yes      |
| len()      |            |    REQ     |    REQ     |     REQ      |
| getitem()  |            |            |    REQ     |     REQ      |
| reversed() |            |            |    Yes     |     Yes      |
| index()    |            |            |            |     Yes      |
| count()    |            |            |            |     Yes      |
+------------+------------+------------+------------+--------------+
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Method iter() is required for &lt;code&gt;'isinstance(&amp;lt;obj&amp;gt;, abc.Iterable)'&lt;/code&gt; to return True, however any object with getitem() will work with any code expecting an iterable.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;MutableSequence, Set, MutableSet, Mapping and MutableMapping ABCs are also extendable. Use &lt;code&gt;'&amp;lt;abc&amp;gt;.__abstractmethods__'&lt;/code&gt; to get names of required methods.&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Enum&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Class of named constants called members.&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from enum import Enum, auto
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;class &amp;lt;enum_name&amp;gt;(Enum):
    &amp;lt;member_name&amp;gt; = auto()              # Increment of the last numeric value or 1.
    &amp;lt;member_name&amp;gt; = &amp;lt;value&amp;gt;             # Values don't have to be hashable or unique.
    &amp;lt;member_name&amp;gt; = &amp;lt;el_1&amp;gt;, &amp;lt;el_2&amp;gt;      # Values can be collections. This is a tuple.
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Methods receive the member they were called on as the 'self' argument.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Accessing a member named after a reserved keyword causes SyntaxError.&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;member&amp;gt; = &amp;lt;enum&amp;gt;.&amp;lt;member_name&amp;gt;         # Returns a member. Raises AttributeError.
&amp;lt;member&amp;gt; = &amp;lt;enum&amp;gt;['&amp;lt;member_name&amp;gt;']      # Returns a member. Raises KeyError.
&amp;lt;member&amp;gt; = &amp;lt;enum&amp;gt;(&amp;lt;value&amp;gt;)              # Returns a member. Raises ValueError.
&amp;lt;str&amp;gt;    = &amp;lt;member&amp;gt;.name                # Returns the member's name.
&amp;lt;obj&amp;gt;    = &amp;lt;member&amp;gt;.value               # Returns the member's value.
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;list&amp;gt;   = list(&amp;lt;enum&amp;gt;)                 # Returns a list of enum's members.
&amp;lt;list&amp;gt;   = &amp;lt;enum&amp;gt;._member_names_        # Returns a list of member names.
&amp;lt;list&amp;gt;   = [m.value for m in &amp;lt;enum&amp;gt;]    # Returns a list of member values.
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;enum&amp;gt;   = type(&amp;lt;member&amp;gt;)               # Returns an enum. Also &amp;lt;memb&amp;gt;.__class__.
&amp;lt;iter&amp;gt;   = itertools.cycle(&amp;lt;enum&amp;gt;)      # Returns an endless iterator of members.
&amp;lt;member&amp;gt; = random.choice(list(&amp;lt;enum&amp;gt;))  # Randomly selects one of the members.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Inline&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;Cutlery = Enum('Cutlery', 'FORK KNIFE SPOON')
Cutlery = Enum('Cutlery', ['FORK', 'KNIFE', 'SPOON'])
Cutlery = Enum('Cutlery', {'FORK': 1, 'KNIFE': 2, 'SPOON': 3})
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;User-defined functions cannot be values, so they must be wrapped:&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from functools import partial
LogicOp = Enum('LogicOp', {'AND': partial(lambda l, r: l and r),
                           'OR':  partial(lambda l, r: l or r)})
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Exceptions&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;try:
    &amp;lt;code&amp;gt;
except &amp;lt;exception&amp;gt;:
    &amp;lt;code&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Complex Example&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;try:
    &amp;lt;code_1&amp;gt;
except &amp;lt;exception_a&amp;gt;:
    &amp;lt;code_2_a&amp;gt;
except &amp;lt;exception_b&amp;gt;:
    &amp;lt;code_2_b&amp;gt;
else:
    &amp;lt;code_2_c&amp;gt;
finally:
    &amp;lt;code_3&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Code inside the &lt;code&gt;'else'&lt;/code&gt; block will only be executed if &lt;code&gt;'try'&lt;/code&gt; block had no exceptions.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Code inside the &lt;code&gt;'finally'&lt;/code&gt; block will always be executed (unless a signal is received).&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;All variables that are initialized in executed blocks are also visible in all subsequent blocks, as well as outside the try statement (only the function block delimits scope).&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;To catch signals use &lt;code&gt;'signal.signal(signal_number, handler_function)'&lt;/code&gt;.&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Catching Exceptions&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;except &amp;lt;exception&amp;gt;: ...
except &amp;lt;exception&amp;gt; as &amp;lt;name&amp;gt;: ...
except (&amp;lt;exception&amp;gt;, [...]): ...
except (&amp;lt;exception&amp;gt;, [...]) as &amp;lt;name&amp;gt;: ...
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Also catches subclasses, e.g. &lt;code&gt;'IndexError'&lt;/code&gt; is caught by &lt;code&gt;'except LookupError:'&lt;/code&gt;.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Use &lt;code&gt;'traceback.print_exc()'&lt;/code&gt; to print the full error message to standard error stream.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Use &lt;code&gt;'print(&amp;lt;name&amp;gt;)'&lt;/code&gt; to print just the cause of the exception (that is, its arguments).&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Use &lt;code&gt;'logging.exception(&amp;lt;str&amp;gt;)'&lt;/code&gt; to log the passed message, followed by the full error message of the caught exception. For details about setting up the logger see &lt;a href="https://raw.githubusercontent.com/gto76/python-cheatsheet/main/#logging"&gt;Logging&lt;/a&gt;.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Use &lt;code&gt;'sys.exc_info()'&lt;/code&gt; to get exception type, object, and traceback of caught exception.&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Raising Exceptions&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;raise &amp;lt;exception&amp;gt;
raise &amp;lt;exception&amp;gt;()
raise &amp;lt;exception&amp;gt;(&amp;lt;obj&amp;gt; [, ...])
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Re-raising caught exception:&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;except &amp;lt;exception&amp;gt; [as &amp;lt;name&amp;gt;]:
    ...
    raise
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Exception Object&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;arguments = &amp;lt;name&amp;gt;.args
exc_type  = &amp;lt;name&amp;gt;.__class__
filename  = &amp;lt;name&amp;gt;.__traceback__.tb_frame.f_code.co_filename
func_name = &amp;lt;name&amp;gt;.__traceback__.tb_frame.f_code.co_name
line_str  = linecache.getline(filename, &amp;lt;name&amp;gt;.__traceback__.tb_lineno)
trace_str = ''.join(traceback.format_tb(&amp;lt;name&amp;gt;.__traceback__))
error_msg = ''.join(traceback.format_exception(type(&amp;lt;name&amp;gt;), &amp;lt;name&amp;gt;, &amp;lt;name&amp;gt;.__traceback__))
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Built-in Exceptions&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-text"&gt;BaseException
 +-- SystemExit                   # Raised by the sys.exit() function (see #Exit for details).
 +-- KeyboardInterrupt            # Raised when the user hits the interrupt key (control-c).
 +-- Exception                    # User-defined exceptions should be derived from this class.
      +-- ArithmeticError         # Base class for arithmetic errors such as ZeroDivisionError.
      +-- AssertionError          # Raised by `assert &amp;lt;exp&amp;gt;` if expression returns false value.
      +-- AttributeError          # Raised when object doesn't have requested attribute/method.
      +-- EOFError                # Raised by input() when it hits an end-of-file condition.
      +-- LookupError             # Base class for errors when a collection can't find an item.
      |    +-- IndexError         # Raised when index of a sequence (list/str) is out of range.
      |    +-- KeyError           # Raised when a dictionary key or set element is missing.
      +-- MemoryError             # Out of memory. May be too late to start deleting variables.
      +-- NameError               # Raised when nonexistent name (variable/func/class) is used.
      |    +-- UnboundLocalError  # Raised when local name is used before it's being defined.
      +-- OSError                 # Errors such as FileExistsError, TimeoutError (see #Open).
      |    +-- ConnectionError    # Errors such as BrokenPipeError and ConnectionAbortedError.
      +-- RuntimeError            # Raised by errors that don't fall into other categories.
      |    +-- NotImplementedEr…  # Can be raised by abstract methods or by unfinished code.
      |    +-- RecursionError     # Raised if max recursion depth is exceeded (3k by default).
      +-- StopIteration           # Raised when exhausted (empty) iterator is passed to next().
      +-- TypeError               # When an argument of the wrong type is passed to function.
      +-- ValueError              # When argument has the right type but inappropriate value.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Collections and their exceptions:&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-text"&gt;+-----------+------------+------------+------------+
|           |    List    |    Set     |    Dict    |
+-----------+------------+------------+------------+
| getitem() | IndexError |            |  KeyError  |
| pop()     | IndexError |  KeyError  |  KeyError  |
| remove()  | ValueError |  KeyError  |            |
| index()   | ValueError |            |            |
+-----------+------------+------------+------------+
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Useful built-in exceptions:&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;raise TypeError('Argument is of the wrong type!')
raise ValueError('Argument has the right type but an inappropriate value!')
raise RuntimeError('I am too lazy to define my own exception!')
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;User-defined Exceptions&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;class MyError(Exception): pass
class MyInputError(MyError): pass
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Exit&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Exits the interpreter by raising SystemExit exception.&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import sys
sys.exit()                        # Exits with exit code 0 (success).
sys.exit(&amp;lt;int&amp;gt;)                   # Exits with the passed exit code.
sys.exit(&amp;lt;obj&amp;gt;)                   # Prints to stderr and exits with 1.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Print&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;print(&amp;lt;el_1&amp;gt;, ..., sep=' ', end='\n', file=sys.stdout, flush=False)
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Use &lt;code&gt;'file=sys.stderr'&lt;/code&gt; for messages about errors so they can be processed separately.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Stdout and stderr streams hold output in a buffer until they receive a string containing '\n' or '\r', buffer reaches 4096 characters, &lt;code&gt;'flush=True'&lt;/code&gt; is used, or program exits.&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Pretty Print&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from pprint import pprint
pprint(&amp;lt;collection&amp;gt;, width=80, depth=None, compact=False, sort_dicts=True)
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Each item is printed on its own line if collection exceeds 'width' characters.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Nested collections that are 'depth' levels deep get printed as '...'.&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Input&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;str&amp;gt; = input()
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Reads a line from the user input or pipe if present (trailing newline gets stripped).&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;If argument is passed, it gets printed to the standard output before input is read.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;EOFError is raised if user hits EOF (ctrl-d/ctrl-z⏎) or if stream is already exhausted.&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Command Line Arguments&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import sys
scripts_path = sys.argv[0]
arguments    = sys.argv[1:]
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Argument Parser&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from argparse import ArgumentParser, FileType
p = ArgumentParser(description=&amp;lt;str&amp;gt;)                             # Returns a parser object.
p.add_argument('-&amp;lt;short_name&amp;gt;', '--&amp;lt;name&amp;gt;', action='store_true')  # Flag (defaults to False).
p.add_argument('-&amp;lt;short_name&amp;gt;', '--&amp;lt;name&amp;gt;', type=&amp;lt;type&amp;gt;)          # Option (defaults to None).
p.add_argument('&amp;lt;name&amp;gt;', type=&amp;lt;type&amp;gt;, nargs=1)                    # Mandatory first argument.
p.add_argument('&amp;lt;name&amp;gt;', type=&amp;lt;type&amp;gt;, nargs='+')                  # Mandatory remaining args.
p.add_argument('&amp;lt;name&amp;gt;', type=&amp;lt;type&amp;gt;, nargs='?/*')                # Optional argument/s.
args  = p.parse_args()                                            # Exits on parsing error.
&amp;lt;obj&amp;gt; = args.&amp;lt;name&amp;gt;                                               # Returns `&amp;lt;type&amp;gt;(&amp;lt;arg&amp;gt;)`.
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Use &lt;code&gt;'help=&amp;lt;str&amp;gt;'&lt;/code&gt; to set argument description that will be displayed in help message.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Use &lt;code&gt;'default=&amp;lt;obj&amp;gt;'&lt;/code&gt; to override None as option's or optional argument's default value.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Use &lt;code&gt;'type=FileType(&amp;lt;mode&amp;gt;)'&lt;/code&gt; for files. It accepts 'encoding', but 'newline' is None.&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Open&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Opens a file and returns the corresponding file object.&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;file&amp;gt; = open(&amp;lt;path&amp;gt;, mode='r', encoding=None, newline=None)
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;'encoding=None'&lt;/code&gt; means that the default encoding is used, which is platform dependent. Best practice is to use &lt;code&gt;'encoding="utf-8"'&lt;/code&gt; until it becomes the default (Python 3.15).&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;'newline=None'&lt;/code&gt; means all different end of line combinations are converted to '\n' on read, while on write all '\n' characters are converted to system's default line separator.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;'newline=""'&lt;/code&gt; means no conversions take place, but input is still broken into chunks by readline() and readlines() on every '\n', '\r' and '\r\n'.&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Modes&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;'r'&lt;/code&gt; - Read. Used by default.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;'w'&lt;/code&gt; - Write. Deletes existing contents.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;'x'&lt;/code&gt; - Write or fail if the file already exists.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;'a'&lt;/code&gt; - Append. Creates new file if it doesn't exist.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;'w+'&lt;/code&gt; - Read and write. Deletes existing contents.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;'r+'&lt;/code&gt; - Read and write from the start.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;'a+'&lt;/code&gt; - Read and write from the end.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;'b'&lt;/code&gt; - Binary mode (&lt;code&gt;'rb'&lt;/code&gt;, &lt;code&gt;'wb'&lt;/code&gt;, &lt;code&gt;'xb'&lt;/code&gt;, …).&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Exceptions&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;'FileNotFoundError'&lt;/code&gt; can be raised when reading with &lt;code&gt;'r'&lt;/code&gt; or &lt;code&gt;'r+'&lt;/code&gt;.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;'FileExistsError'&lt;/code&gt; can be raised when writing with &lt;code&gt;'x'&lt;/code&gt;.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;'IsADirectoryError'&lt;/code&gt; and &lt;code&gt;'PermissionError'&lt;/code&gt; can be raised by any.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;'OSError'&lt;/code&gt; is the parent class of all listed exceptions.&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;File Object&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;file&amp;gt;.seek(0)                      # Moves current position to the start of file.
&amp;lt;file&amp;gt;.seek(offset)                 # Moves 'offset' chars/bytes from the start.
&amp;lt;file&amp;gt;.seek(0, 2)                   # Moves current position to the end of file.
&amp;lt;bin_file&amp;gt;.seek(±offset, origin)    # Origin: 0 start, 1 current position, 2 end.
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;str/bytes&amp;gt; = &amp;lt;file&amp;gt;.read(size=-1)  # Reads 'size' chars/bytes or until the EOF.
&amp;lt;str/bytes&amp;gt; = &amp;lt;file&amp;gt;.readline()     # Returns a line or empty string/bytes on EOF.
&amp;lt;list&amp;gt;      = &amp;lt;file&amp;gt;.readlines()    # Returns remaining lines. Also list(&amp;lt;file&amp;gt;).
&amp;lt;str/bytes&amp;gt; = next(&amp;lt;file&amp;gt;)          # Returns a line using a read-ahead buffer.
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;file&amp;gt;.write(&amp;lt;str/bytes&amp;gt;)           # Writes a str or bytes object to write buffer.
&amp;lt;file&amp;gt;.writelines(&amp;lt;collection&amp;gt;)     # Writes a coll. of strings or bytes objects.
&amp;lt;file&amp;gt;.flush()                      # Flushes write buffer. Runs every 4096/8192 B.
&amp;lt;file&amp;gt;.close()                      # Closes the file after flushing write buffer.
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Methods do not add or strip trailing newlines, not even writelines().&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Read Text from File&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;def read_file(filename):
    with open(filename, encoding='utf-8') as file:
        return file.readlines()
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Write Text to File&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;def write_to_file(filename, text):
    with open(filename, 'w', encoding='utf-8') as file:
        file.write(text)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Paths&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import os, glob
from pathlib import Path
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;str&amp;gt;  = os.getcwd()                # Returns working dir. Starts as shell's $PWD.
&amp;lt;str&amp;gt;  = os.path.join(&amp;lt;path&amp;gt;, ...)  # Uses os.sep to join strings or Path objects.
&amp;lt;str&amp;gt;  = os.path.realpath(&amp;lt;path&amp;gt;)   # Resolves symlinks and calls path.abspath().
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;str&amp;gt;  = os.path.basename(&amp;lt;path&amp;gt;)   # Returns final component of the path.
&amp;lt;str&amp;gt;  = os.path.dirname(&amp;lt;path&amp;gt;)    # Returns path without the final component.
&amp;lt;tup.&amp;gt; = os.path.splitext(&amp;lt;path&amp;gt;)   # Splits on last period of the final component.
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;list&amp;gt; = os.listdir(path='.')       # Returns all filenames located at the path.
&amp;lt;list&amp;gt; = glob.glob('&amp;lt;pattern&amp;gt;')     # Returns paths matching the wildcard pattern.
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;bool&amp;gt; = os.path.exists(&amp;lt;path&amp;gt;)     # Checks if path exists. Also &amp;lt;Path&amp;gt;.exists().
&amp;lt;bool&amp;gt; = os.path.isfile(&amp;lt;path&amp;gt;)     # Also &amp;lt;Path&amp;gt;.is_file() and &amp;lt;DirEntry&amp;gt;.is_file().
&amp;lt;bool&amp;gt; = os.path.isdir(&amp;lt;path&amp;gt;)      # Also &amp;lt;Path&amp;gt;.is_dir() and &amp;lt;DirEntry&amp;gt;.is_dir().
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;stat&amp;gt; = os.stat(&amp;lt;path&amp;gt;)            # File's status. Also &amp;lt;Path/DirEntry&amp;gt;.stat().
&amp;lt;num&amp;gt;  = &amp;lt;stat&amp;gt;.st_mtime/st_size/…  # Returns modification time, size in bytes, etc.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;DirEntry&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Unlike listdir(), scandir() returns DirEntry objects that cache isfile, isdir, and on Windows also stat information, thus significantly increasing the performance of code that requires it.&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;iter&amp;gt; = os.scandir(path='.')       # Returns DirEntry objects located at the path.
&amp;lt;str&amp;gt;  = &amp;lt;DirEntry&amp;gt;.path            # Is absolute if 'path' argument was absolute.
&amp;lt;str&amp;gt;  = &amp;lt;DirEntry&amp;gt;.name            # Returns path's final component as a string.
&amp;lt;file&amp;gt; = open(&amp;lt;DirEntry&amp;gt;)           # Opens the file and returns its file object.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Path Object&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;Path&amp;gt; = Path(&amp;lt;path&amp;gt; [, ...])       # Accepts strings, Paths, and DirEntry objects.
&amp;lt;Path&amp;gt; = &amp;lt;path&amp;gt; / &amp;lt;path&amp;gt; [/ ...]    # First or second path must be a Path object.
&amp;lt;Path&amp;gt; = &amp;lt;Path&amp;gt;.resolve()           # Returns absolute path with resolved symlinks.
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;Path&amp;gt; = Path()                     # Returns current working dir. Also Path('.').
&amp;lt;Path&amp;gt; = Path.cwd()                 # Returns absolute CWD. Also Path().resolve().
&amp;lt;Path&amp;gt; = Path.home()                # Returns user's home directory (absolute).
&amp;lt;Path&amp;gt; = Path(__file__).resolve()   # Returns module's path if CWD wasn't changed.
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;Path&amp;gt; = &amp;lt;Path&amp;gt;.parent              # Returns Path without the final component.
&amp;lt;str&amp;gt;  = &amp;lt;Path&amp;gt;.name                # Returns path's final component as a string.
&amp;lt;str&amp;gt;  = &amp;lt;Path&amp;gt;.suffix              # Returns name's last extension, e.g. '.gz'.
&amp;lt;str&amp;gt;  = &amp;lt;Path&amp;gt;.stem                # Returns name without the last extension.
&amp;lt;tup.&amp;gt; = &amp;lt;Path&amp;gt;.parts               # Returns all path's components as strings.
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;iter&amp;gt; = &amp;lt;Path&amp;gt;.iterdir()           # Returns directory contents as Path objects.
&amp;lt;iter&amp;gt; = &amp;lt;Path&amp;gt;.glob('&amp;lt;pattern&amp;gt;')   # Returns Paths matching the wildcard pattern.
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;str&amp;gt;  = str(&amp;lt;Path&amp;gt;)                # Returns path as string. Also &amp;lt;Path&amp;gt;.as_uri().
&amp;lt;file&amp;gt; = open(&amp;lt;Path&amp;gt;)               # Also &amp;lt;Path&amp;gt;.read_text/write_bytes(&amp;lt;args&amp;gt;).
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;OS Commands&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import os, shutil, subprocess
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;os.chdir(&amp;lt;path&amp;gt;)                    # Changes the current working directory (CWD).
os.mkdir(&amp;lt;path&amp;gt;, mode=0o777)        # Creates a directory. Permissions are in octal.
os.makedirs(&amp;lt;path&amp;gt;, mode=0o777)     # Creates all path's dirs. Also `exist_ok=False`.
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;shutil.copy(from, to)               # Copies the file. 'to' can exist or be a dir.
shutil.copy2(from, to)              # Also copies creation and modification time.
shutil.copytree(from, to)           # Copies the directory. 'to' must not exist.
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;os.rename(from, to)                 # Renames or moves the file or directory 'from'.
os.replace(from, to)                # Same, but overwrites file 'to' even on Windows.
shutil.move(from, to)               # Rename() that moves into 'to' if it's a dir.
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;os.remove(&amp;lt;path&amp;gt;)                   # Deletes the file. Or `pip3 install send2trash`.
os.rmdir(&amp;lt;path&amp;gt;)                    # Deletes the empty directory or raises OSError.
shutil.rmtree(&amp;lt;path&amp;gt;)               # Deletes the directory and all of its contents.
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Paths can be either strings, Path objects, or DirEntry objects.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Functions report OS related errors by raising OSError or one of its &lt;a href="https://raw.githubusercontent.com/gto76/python-cheatsheet/main/#exceptions-1"&gt;subclasses&lt;/a&gt;.&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Shell Commands&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;pipe&amp;gt; = os.popen('&amp;lt;commands&amp;gt;')     # Executes commands in sh/cmd. Returns combined stdout.
&amp;lt;str&amp;gt;  = &amp;lt;pipe&amp;gt;.read(size=-1)       # Reads 'size' chars or until EOF. Also readline/s().
&amp;lt;int&amp;gt;  = &amp;lt;pipe&amp;gt;.close()             # Returns None if last command exited with returncode 0.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Sends "1 + 1" to the basic calculator and captures its output:&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;gt;&amp;gt;&amp;gt; subprocess.run('bc', input='1 + 1\n', capture_output=True, text=True)
CompletedProcess(args='bc', returncode=0, stdout='2\n', stderr='')
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Sends test.in to the basic calculator running in standard mode and saves its output to test.out:&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;gt;&amp;gt;&amp;gt; from shlex import split
&amp;gt;&amp;gt;&amp;gt; os.popen('echo 1 + 1 &amp;gt; test.in')
&amp;gt;&amp;gt;&amp;gt; subprocess.run(split('bc -s'), stdin=open('test.in'), stdout=open('test.out', 'w'))
CompletedProcess(args=['bc', '-s'], returncode=0)
&amp;gt;&amp;gt;&amp;gt; open('test.out').read()
'2\n'
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;JSON&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Text file format for storing collections of strings and numbers.&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import json
&amp;lt;str&amp;gt;  = json.dumps(&amp;lt;list/dict&amp;gt;)    # Converts collection to JSON string.
&amp;lt;coll&amp;gt; = json.loads(&amp;lt;str&amp;gt;)          # Converts JSON string to collection.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Read Collection from JSON File&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;def read_json_file(filename):
    with open(filename, encoding='utf-8') as file:
        return json.load(file)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Write Collection to JSON File&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;def write_to_json_file(filename, collection):
    with open(filename, 'w', encoding='utf-8') as file:
        json.dump(collection, file, ensure_ascii=False, indent=2)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Pickle&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Binary file format for storing Python objects.&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import pickle
&amp;lt;bytes&amp;gt;  = pickle.dumps(&amp;lt;object&amp;gt;)   # Converts object to bytes object.
&amp;lt;object&amp;gt; = pickle.loads(&amp;lt;bytes&amp;gt;)    # Converts bytes object to object.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Read Object from Pickle File&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;def read_pickle_file(filename):
    with open(filename, 'rb') as file:
        return pickle.load(file)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Write Object to Pickle File&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;def write_to_pickle_file(filename, an_object):
    with open(filename, 'wb') as file:
        pickle.dump(an_object, file)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;CSV&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Text file format for storing spreadsheets.&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import csv
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;file&amp;gt;   = open(&amp;lt;path&amp;gt;, newline='')       # Opens the CSV (text) file for reading.
&amp;lt;reader&amp;gt; = csv.reader(&amp;lt;file&amp;gt;)             # Also: `dialect='excel', delimiter=','`.
&amp;lt;list&amp;gt;   = next(&amp;lt;reader&amp;gt;)                 # Returns next row as a list of strings.
&amp;lt;list&amp;gt;   = list(&amp;lt;reader&amp;gt;)                 # Returns a list of all remaining rows.
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Without the &lt;code&gt;'newline=""'&lt;/code&gt; argument, every '\r\n' sequence that is embedded inside a quoted field will get converted to '\n'! For details about newline argument see &lt;a href="https://raw.githubusercontent.com/gto76/python-cheatsheet/main/#open"&gt;Open&lt;/a&gt;.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;To print the spreadsheet to the console use &lt;a href="https://raw.githubusercontent.com/gto76/python-cheatsheet/main/#table"&gt;Tabulate&lt;/a&gt; or PrettyTable library.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;For XML and binary Excel files (xlsx, xlsm and xlsb) use &lt;a href="https://raw.githubusercontent.com/gto76/python-cheatsheet/main/#fileformats"&gt;Pandas&lt;/a&gt; library.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Reader accepts any iterator (or collection) of strings, not just files.&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Write&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;file&amp;gt;   = open(&amp;lt;path&amp;gt;, 'w', newline='')  # Opens the CSV (text) file for writing.
&amp;lt;writer&amp;gt; = csv.writer(&amp;lt;file&amp;gt;)             # Also: `dialect='excel', delimiter=','`.
&amp;lt;writer&amp;gt;.writerow(&amp;lt;collection&amp;gt;)           # Encodes each object using `str(&amp;lt;el&amp;gt;)`.
&amp;lt;writer&amp;gt;.writerows(&amp;lt;coll_of_coll&amp;gt;)        # Appends multiple rows to the file.
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;If file is opened without the &lt;code&gt;'newline=""'&lt;/code&gt; argument, '\r' will be added in front of every '\n' on platforms that use '\r\n' line endings (i.e., newlines may get doubled on Windows)!&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Open existing file with &lt;code&gt;'mode="a"'&lt;/code&gt; to append to it or &lt;code&gt;'mode="w"'&lt;/code&gt; to overwrite it.&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Parameters&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;'dialect'&lt;/code&gt; - Master parameter that sets the default values. String or a 'csv.Dialect' object.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;'delimiter'&lt;/code&gt; - A one-character string that separates fields (comma, tab, semicolon, etc.).&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;'lineterminator'&lt;/code&gt; - How writer terminates rows. Reader looks for '\n', '\r' and '\r\n'.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;'quotechar'&lt;/code&gt; - Character for quoting fields containing delimiters, quotechars, '\n' or '\r'.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;'escapechar'&lt;/code&gt; - Character for escaping quotechars (not needed if doublequote is True).&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;'doublequote'&lt;/code&gt; - Whether quotechars inside fields are/get doubled instead of escaped.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;'quoting'&lt;/code&gt; - 0: As necessary, 1: All, 2: All but numbers which are read as floats, 3: None.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;'skipinitialspace'&lt;/code&gt; - Is space character at the start of the field stripped by the reader.&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Dialects&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-text"&gt;+------------------+--------------+--------------+--------------+
|                  |     excel    |   excel-tab  |     unix     |
+------------------+--------------+--------------+--------------+
| delimiter        |       ','    |      '\t'    |       ','    |
| lineterminator   |    '\r\n'    |    '\r\n'    |      '\n'    |
| quotechar        |       '"'    |       '"'    |       '"'    |
| escapechar       |      None    |      None    |      None    |
| doublequote      |      True    |      True    |      True    |
| quoting          |         0    |         0    |         1    |
| skipinitialspace |     False    |     False    |     False    |
+------------------+--------------+--------------+--------------+
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Read Rows from CSV File&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;def read_csv_file(filename, **csv_params):
    with open(filename, encoding='utf-8', newline='') as file:
        return list(csv.reader(file, **csv_params))
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Write Rows to CSV File&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;def write_to_csv_file(filename, rows, mode='w', **csv_params):
    with open(filename, mode, encoding='utf-8', newline='') as file:
        writer = csv.writer(file, **csv_params)
        writer.writerows(rows)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;SQLite&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;A server-less database engine that stores each database into its own file.&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import sqlite3
&amp;lt;conn&amp;gt; = sqlite3.connect(&amp;lt;path&amp;gt;)               # Opens existing or new file. Also ':memory:'.
&amp;lt;conn&amp;gt;.close()                                 # Closes connection. Discards uncommitted data.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Read&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;cursor&amp;gt; = &amp;lt;conn&amp;gt;.execute('&amp;lt;query&amp;gt;')           # Can raise a subclass of sqlite3.Error.
&amp;lt;tuple&amp;gt;  = &amp;lt;cursor&amp;gt;.fetchone()                 # Returns the next row. Also next(&amp;lt;cursor&amp;gt;).
&amp;lt;list&amp;gt;   = &amp;lt;cursor&amp;gt;.fetchall()                 # Returns remaining rows. Also list(&amp;lt;cursor&amp;gt;).
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Write&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;conn&amp;gt;.execute('&amp;lt;query&amp;gt;')                      # Can raise a subclass of sqlite3.Error.
&amp;lt;conn&amp;gt;.commit()                                # Saves all changes since the last commit.
&amp;lt;conn&amp;gt;.rollback()                              # Discards all changes since the last commit.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Or:&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;with &amp;lt;conn&amp;gt;:                                   # Exits the block with commit() or rollback(),
    &amp;lt;conn&amp;gt;.execute('&amp;lt;query&amp;gt;')                  # depending on whether any exception occurred.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Placeholders&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;conn&amp;gt;.execute('&amp;lt;query&amp;gt;', &amp;lt;list/tuple&amp;gt;)        # Replaces every question mark with an item.
&amp;lt;conn&amp;gt;.execute('&amp;lt;query&amp;gt;', &amp;lt;dict/namedtuple&amp;gt;)   # Replaces every :&amp;lt;key&amp;gt; with a matching value.
&amp;lt;conn&amp;gt;.executemany('&amp;lt;query&amp;gt;', &amp;lt;coll_of_coll&amp;gt;)  # Runs execute() once for each collection.
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Passed values can be of type str, int, float, bytes, None, or bool (stored as 1 or 0).&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;SQLite does not restrict columns to any type unless table is declared as strict.&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Example&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Values are not actually saved in this example because &lt;code&gt;'conn.commit()'&lt;/code&gt; is omitted!&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;gt;&amp;gt;&amp;gt; conn = sqlite3.connect('test.db')
&amp;gt;&amp;gt;&amp;gt; conn.execute('CREATE TABLE person (name TEXT, height INTEGER) STRICT')
&amp;gt;&amp;gt;&amp;gt; conn.execute('INSERT INTO person VALUES (?, ?)', ('Jean-Luc', 187))
&amp;gt;&amp;gt;&amp;gt; conn.execute('SELECT rowid, * FROM person').fetchall()
[(1, 'Jean-Luc', 187)]
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;SQLAlchemy&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Library for interacting with various DB systems via SQL, method chaining, or ORM.&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# $ pip3 install sqlalchemy
from sqlalchemy import create_engine, text
&amp;lt;engine&amp;gt; = create_engine('&amp;lt;url&amp;gt;')              # Url: 'dialect://user:password@host/dbname'.
&amp;lt;conn&amp;gt;   = &amp;lt;engine&amp;gt;.connect()                  # Creates a connection. Also &amp;lt;conn&amp;gt;.close().
&amp;lt;cursor&amp;gt; = &amp;lt;conn&amp;gt;.execute(text('&amp;lt;query&amp;gt;'), …)  # `&amp;lt;dict&amp;gt;`. Replaces every :&amp;lt;key&amp;gt; with value.
with &amp;lt;conn&amp;gt;.begin(): ...                       # Exits the block with commit or rollback.
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-text"&gt;+-----------------+--------------+----------------------------------+
| Dialect         | pip3 install |           Dependencies           |
+-----------------+--------------+----------------------------------+
| mysql           | mysqlclient  | www.pypi.org/project/mysqlclient |
| postgresql      | psycopg2     | www.pypi.org/project/psycopg2    |
| mssql           | pyodbc       | www.pypi.org/project/pyodbc      |
| oracle+oracledb | oracledb     | www.pypi.org/project/oracledb    |
+-----------------+--------------+----------------------------------+
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Bytes&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;A bytes object is an immutable sequence of single bytes. Mutable version is called bytearray.&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;bytes&amp;gt; = b'&amp;lt;str&amp;gt;'                       # Only accepts ASCII characters and \x00-\xff.
&amp;lt;int&amp;gt;   = &amp;lt;bytes&amp;gt;[index]                 # Returns an integer in range from 0 to 255.
&amp;lt;bytes&amp;gt; = &amp;lt;bytes&amp;gt;[&amp;lt;slice&amp;gt;]               # Returns bytes even if it has only one element.
&amp;lt;bytes&amp;gt; = &amp;lt;bytes&amp;gt;.join(&amp;lt;coll_of_bytes&amp;gt;)  # Joins elements by using bytes as a separator.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Encode&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;bytes&amp;gt; = bytes(&amp;lt;coll_of_ints&amp;gt;)          # Integers must be in range from 0 to 255.
&amp;lt;bytes&amp;gt; = bytes(&amp;lt;str&amp;gt;, 'utf-8')          # Encodes the string. Also &amp;lt;str&amp;gt;.encode().
&amp;lt;bytes&amp;gt; = bytes.fromhex('&amp;lt;hex&amp;gt;')         # Hex pairs can be separated by whitespaces.
&amp;lt;bytes&amp;gt; = &amp;lt;int&amp;gt;.to_bytes(n_bytes, …)     # `byteorder='big/little', signed=False`.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Decode&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;list&amp;gt;  = list(&amp;lt;bytes&amp;gt;)                  # Returns integers in range from 0 to 255.
&amp;lt;str&amp;gt;   = str(&amp;lt;bytes&amp;gt;, 'utf-8')          # Returns a string. Also &amp;lt;bytes&amp;gt;.decode().
&amp;lt;str&amp;gt;   = &amp;lt;bytes&amp;gt;.hex()                  # Returns hex pairs. Accepts `sep=&amp;lt;str&amp;gt;`.
&amp;lt;int&amp;gt;   = int.from_bytes(&amp;lt;bytes&amp;gt;, …)     # `byteorder='big/little', signed=False`.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Read Bytes from File&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;def read_bytes(filename):
    with open(filename, 'rb') as file:
        return file.read()
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Write Bytes to File&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;def write_bytes(filename, bytes_obj):
    with open(filename, 'wb') as file:
        file.write(bytes_obj)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Struct&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Module that performs conversions between a sequence of numbers and a bytes object.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;System’s type sizes, byte order, and alignment rules are used by default.&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from struct import pack, unpack

&amp;lt;bytes&amp;gt; = pack('&amp;lt;format&amp;gt;', &amp;lt;el_1&amp;gt; [, ...])  # Packs numbers according to format string.
&amp;lt;tuple&amp;gt; = unpack('&amp;lt;format&amp;gt;', &amp;lt;bytes&amp;gt;)       # Use iter_unpack() to get iterator of tuples.
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;gt;&amp;gt;&amp;gt; pack('&amp;gt;hhl', 1, 2, 3)
b'\x00\x01\x00\x02\x00\x00\x00\x03'
&amp;gt;&amp;gt;&amp;gt; unpack('&amp;gt;hhl', b'\x00\x01\x00\x02\x00\x00\x00\x03')
(1, 2, 3)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Format&lt;/h3&gt; 
&lt;h4&gt;For standard type sizes and manual alignment (padding) start format string with:&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;'='&lt;/code&gt; - System's byte order (usually little-endian).&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;'&amp;lt;'&lt;/code&gt; - Little-endian (i.e. least significant byte first).&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;'&amp;gt;'&lt;/code&gt; - Big-endian (also &lt;code&gt;'!'&lt;/code&gt;).&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Besides numbers, pack() and unpack() also support bytes objects as a part of the sequence:&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;'c'&lt;/code&gt; - A bytes object with a single element. For pad byte use &lt;code&gt;'x'&lt;/code&gt;.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;'&amp;lt;n&amp;gt;s'&lt;/code&gt; - A bytes object with n elements (not effected by byte order).&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Integer types. Use a capital letter for unsigned type. Minimum and standard sizes are in brackets:&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;'b'&lt;/code&gt; - char (1/1)&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;'h'&lt;/code&gt; - short (2/2)&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;'i'&lt;/code&gt; - int (2/4)&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;'l'&lt;/code&gt; - long (4/4)&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;'q'&lt;/code&gt; - long long (8/8)&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Floating point types (struct always uses standard sizes):&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;'f'&lt;/code&gt; - float (4/4)&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;'d'&lt;/code&gt; - double (8/8)&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Array&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;List that can only hold numbers of a predefined type. Available types and their minimum sizes in bytes are listed above. Type sizes and byte order are always determined by the system, however bytes of each element can be reversed (by calling the byteswap() method).&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from array import array
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;array&amp;gt; = array('&amp;lt;typecode&amp;gt;', &amp;lt;coll_of_nums&amp;gt;)  # Creates an array from collection of numbers.
&amp;lt;array&amp;gt; = array('&amp;lt;typecode&amp;gt;', &amp;lt;bytes&amp;gt;)         # Writes passed bytes to the array's memory.
&amp;lt;array&amp;gt; = array('&amp;lt;typecode&amp;gt;', &amp;lt;array&amp;gt;)         # Treats passed array as a sequence of numbers.
&amp;lt;array&amp;gt;.fromfile(&amp;lt;file&amp;gt;, n_items)              # Appends file contents to the array's memory.
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;bytes&amp;gt; = bytes(&amp;lt;array&amp;gt;)                       # Returns a copy of array's memory as bytes.
&amp;lt;file&amp;gt;.write(&amp;lt;array&amp;gt;)                          # Writes array's memory to the binary file.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Memory View&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;A sequence object that points to the memory of another bytes-like object. Each element can reference a single or multiple consecutive bytes, depending on format. Order and number of elements can be changed with slicing.&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;mview&amp;gt; = memoryview(&amp;lt;bytes/bytearray/array&amp;gt;)  # Immutable if bytes is passed, else mutable.
&amp;lt;obj&amp;gt;   = &amp;lt;mview&amp;gt;[index]                       # Returns ints/floats. Bytes if format is 'c'.
&amp;lt;mview&amp;gt; = &amp;lt;mview&amp;gt;[&amp;lt;slice&amp;gt;]                     # Returns memoryview with rearranged elements.
&amp;lt;mview&amp;gt; = &amp;lt;mview&amp;gt;.cast('&amp;lt;typecode&amp;gt;')           # Only works between B/b/c and other types.
&amp;lt;mview&amp;gt;.release()                              # Releases memory buffer of the base object.
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;bytes&amp;gt; = bytes(&amp;lt;mview&amp;gt;)                       # Returns a new bytes object. Also bytearray().
&amp;lt;bytes&amp;gt; = &amp;lt;bytes&amp;gt;.join(&amp;lt;coll_of_mviews&amp;gt;)       # Joins memoryviews using bytes as a separator.
&amp;lt;array&amp;gt; = array('&amp;lt;typecode&amp;gt;', &amp;lt;mview&amp;gt;)         # Treats memoryview as a sequence of numbers.
&amp;lt;file&amp;gt;.write(&amp;lt;mview&amp;gt;)                          # Writes `bytes(&amp;lt;mview&amp;gt;)` to the binary file.
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;list&amp;gt;  = list(&amp;lt;mview&amp;gt;)                        # Returns a list of ints, floats or bytes.
&amp;lt;str&amp;gt;   = str(&amp;lt;mview&amp;gt;, 'utf-8')                # Treats passed memoryview as a bytes object.
&amp;lt;str&amp;gt;   = &amp;lt;mview&amp;gt;.hex()                        # Returns hex pairs. Accepts `sep=&amp;lt;str&amp;gt;`.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Deque&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;List with efficient appends and pops from either side.&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from collections import deque
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;deque&amp;gt; = deque(&amp;lt;collection&amp;gt;)                  # Use `maxlen=&amp;lt;int&amp;gt;` to set size limit.
&amp;lt;deque&amp;gt;.appendleft(&amp;lt;el&amp;gt;)                       # Opposite element is dropped if full.
&amp;lt;deque&amp;gt;.extendleft(&amp;lt;collection&amp;gt;)               # Prepends reversed coll. to the deque.
&amp;lt;deque&amp;gt;.rotate(n=1)                            # Last element becomes the first one.
&amp;lt;el&amp;gt; = &amp;lt;deque&amp;gt;.popleft()                       # Raises IndexError if deque is empty.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Operator&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Module of functions that provide the functionality of operators. Functions are grouped by operator precedence, from least to most binding. Functions and operators in first, third and fifth line are also ordered by precedence within a group.&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import operator as op
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;bool&amp;gt; = op.not_(&amp;lt;obj&amp;gt;)                                        # or, and, not (or/and missing)
&amp;lt;bool&amp;gt; = op.eq/ne/lt/ge/is_/is_not/contains(&amp;lt;obj&amp;gt;, &amp;lt;obj&amp;gt;)      # ==, !=, &amp;lt;, &amp;gt;=, is, is not, in
&amp;lt;obj&amp;gt;  = op.or_/xor/and_(&amp;lt;int/set&amp;gt;, &amp;lt;int/set&amp;gt;)                 # |, ^, &amp;amp; (sorted by precedence)
&amp;lt;int&amp;gt;  = op.lshift/rshift(&amp;lt;int&amp;gt;, &amp;lt;int&amp;gt;)                        # &amp;lt;&amp;lt;, &amp;gt;&amp;gt; (i.e. &amp;lt;int&amp;gt; &amp;lt;&amp;lt; n_bits)
&amp;lt;obj&amp;gt;  = op.add/sub/mul/truediv/floordiv/mod(&amp;lt;obj&amp;gt;, &amp;lt;obj&amp;gt;)     # +, -, *, /, //, % (two groups)
&amp;lt;num&amp;gt;  = op.neg/invert(&amp;lt;num&amp;gt;)                                  # -, ~ (negate and bitwise not)
&amp;lt;num&amp;gt;  = op.pow(&amp;lt;num&amp;gt;, &amp;lt;num&amp;gt;)                                  # ** (pow() accepts 3 arguments)
&amp;lt;func&amp;gt; = op.itemgetter/attrgetter/methodcaller(&amp;lt;obj&amp;gt; [, ...])  # [index/key], .name, .name([…])
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;elementwise_sum  = map(op.add, list_a, list_b)
sorted_by_second = sorted(&amp;lt;coll&amp;gt;, key=op.itemgetter(1))
sorted_by_both   = sorted(&amp;lt;coll&amp;gt;, key=op.itemgetter(1, 0))
first_element    = op.methodcaller('pop', 0)(&amp;lt;list&amp;gt;)
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Most operators call the object's special method that is named after them (second object is passed as an argument), while logical operators call their own code that relies on bool().&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Comparisons can be chained: &lt;code&gt;'x &amp;lt; y &amp;lt; z'&lt;/code&gt; gets converted to &lt;code&gt;'(x &amp;lt; y) and (y &amp;lt; z)&lt;/code&gt;'.&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Match Statement&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Executes the first block with matching pattern.&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;match &amp;lt;object/expression&amp;gt;:
    case &amp;lt;pattern&amp;gt; [if &amp;lt;condition&amp;gt;]:
        &amp;lt;code&amp;gt;
    ...
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Patterns&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;value_pattern&amp;gt; = 1/'abc'/True/None/math.pi        # Matches the literal or a dotted name.
&amp;lt;class_pattern&amp;gt; = &amp;lt;type&amp;gt;()                         # Matches any object of that type (or ABC).
&amp;lt;wildcard_patt&amp;gt; = _                                # Matches any object. Useful in last case.
&amp;lt;capture_patt&amp;gt;  = &amp;lt;name&amp;gt;                           # Matches any object and binds it to name.
&amp;lt;as_pattern&amp;gt;    = &amp;lt;pattern&amp;gt; as &amp;lt;name&amp;gt;              # Binds match to name. Also &amp;lt;type&amp;gt;(&amp;lt;name&amp;gt;).
&amp;lt;or_pattern&amp;gt;    = &amp;lt;pattern&amp;gt; | &amp;lt;pattern&amp;gt; [| ...]    # Matches if any of listed patterns match.
&amp;lt;sequence_patt&amp;gt; = [&amp;lt;pattern&amp;gt;, ...]                 # Matches a sequence. All items must match.
&amp;lt;mapping_patt&amp;gt;  = {&amp;lt;value_pattern&amp;gt;: &amp;lt;patt&amp;gt;, ...}   # Matches a dict that has matching items.
&amp;lt;class_pattern&amp;gt; = &amp;lt;type&amp;gt;(&amp;lt;attr_name&amp;gt;=&amp;lt;patt&amp;gt;, ...)  # Matches an object if attributes match.
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Sequence pattern can also be written as a tuple, either with or without the brackets.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Use &lt;code&gt;'*&amp;lt;name&amp;gt;'&lt;/code&gt; and &lt;code&gt;'**&amp;lt;name&amp;gt;'&lt;/code&gt; in sequence/mapping patterns to bind remaining items.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Sequence pattern must match all items of the collection, while mapping pattern does not.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Patterns can be surrounded with brackets to override their precedence: &lt;code&gt;'|'&lt;/code&gt; &amp;gt; &lt;code&gt;'as'&lt;/code&gt; &amp;gt; &lt;code&gt;','&lt;/code&gt;. For example, &lt;code&gt;'[1, 2]'&lt;/code&gt; is matched by the &lt;code&gt;'case 1|2, 2|3 as x if x == 2:'&lt;/code&gt; block.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;All names that are bound in the matching case, as well as variables initialized in its body, are visible after the match statement (only function block delimits scope).&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Example&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;gt;&amp;gt;&amp;gt; from pathlib import Path
&amp;gt;&amp;gt;&amp;gt; match Path('/home/gto/python-cheatsheet/README.md'):
...     case Path(
...         parts=['/', 'home', user, *_]
...     ) as p if p.name.lower().startswith('readme') and p.is_file():
...         print(f'{p.name} is a readme file that belongs to user {user}.')
README.md is a readme file that belongs to user gto.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Logging&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import logging as log
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;log.basicConfig(filename=&amp;lt;path&amp;gt;, level='DEBUG')   # Configures the root logger (see Setup).
log.debug/info/warning/error/critical(&amp;lt;str&amp;gt;)      # Sends passed message to the root logger.
&amp;lt;Logger&amp;gt; = log.getLogger(__name__)                # Returns a logger named after the module.
&amp;lt;Logger&amp;gt;.&amp;lt;level&amp;gt;(&amp;lt;str&amp;gt;)                           # Sends the message. Same levels as above.
&amp;lt;Logger&amp;gt;.exception(&amp;lt;str&amp;gt;)                         # Error() that appends caught exception.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Setup&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;log.basicConfig(
    filename=None,                                # Logs to stderr or appends to file.
    format='%(levelname)s:%(name)s:%(message)s',  # Add '%(asctime)s' for local datetime.
    level=log.WARNING,                            # Drops messages with lower priority.
    handlers=[log.StreamHandler(sys.stderr)]      # Uses FileHandler if filename is set.
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;Formatter&amp;gt; = log.Formatter('&amp;lt;format&amp;gt;')           # Formats messages according to format str.
&amp;lt;Handler&amp;gt; = log.FileHandler(&amp;lt;path&amp;gt;, mode='a')     # Appends to file. Also `encoding=None`.
&amp;lt;Handler&amp;gt;.setFormatter(&amp;lt;Formatter&amp;gt;)               # Only outputs bare messages by default.
&amp;lt;Handler&amp;gt;.setLevel(&amp;lt;int/str&amp;gt;)                     # Prints or saves every message by default.
&amp;lt;Logger&amp;gt;.addHandler(&amp;lt;Handler&amp;gt;)                    # Logger can have more than one handler.
&amp;lt;Logger&amp;gt;.setLevel(&amp;lt;int/str&amp;gt;)                      # What is sent to its/ancestors' handlers.
&amp;lt;Logger&amp;gt;.propagate = &amp;lt;bool&amp;gt;                       # Cuts off ancestors' handlers if False.
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Parent logger can be specified by naming the child logger &lt;code&gt;'&amp;lt;parent&amp;gt;.&amp;lt;name&amp;gt;'&lt;/code&gt;.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;If logger doesn't have a set level, it inherits it from the first ancestor that does.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Formatter also accepts: pathname, filename, funcName, lineno, thread and process.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;RotatingFileHandler creates and deletes files based on 'maxBytes', 'backupCount' args.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;An object with &lt;code&gt;'filter(&amp;lt;LogRecord&amp;gt;)'&lt;/code&gt; method (or the method itself) can be added to loggers and handlers via addFilter(). Message is dropped if filter() returns a false value.&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Creates a logger that writes all messages to a file and sends them to the root's handler that prints warnings or higher:&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;gt;&amp;gt;&amp;gt; logger = log.getLogger('my_module')
&amp;gt;&amp;gt;&amp;gt; handler = log.FileHandler('test.log', encoding='utf-8')
&amp;gt;&amp;gt;&amp;gt; handler.setFormatter(log.Formatter('%(asctime)s %(levelname)s:%(name)s:%(message)s'))
&amp;gt;&amp;gt;&amp;gt; logger.addHandler(handler)
&amp;gt;&amp;gt;&amp;gt; logger.setLevel('DEBUG')
&amp;gt;&amp;gt;&amp;gt; log.basicConfig()
&amp;gt;&amp;gt;&amp;gt; log.root.handlers[0].setLevel('WARNING')
&amp;gt;&amp;gt;&amp;gt; logger.critical('Running out of disk space.')
CRITICAL:my_module:Running out of disk space.
&amp;gt;&amp;gt;&amp;gt; print(open('test.log').read())
2023-02-07 23:21:01,430 CRITICAL:my_module:Running out of disk space.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Introspection&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;list&amp;gt; = dir()                      # Local names of variables, functions, classes and modules.
&amp;lt;dict&amp;gt; = vars()                     # Dict of local names and their objects. Same as locals().
&amp;lt;dict&amp;gt; = globals()                  # Dict of global names and their objects, e.g. __builtin__.
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;list&amp;gt; = dir(&amp;lt;obj&amp;gt;)                 # Returns names of object's attributes (including methods).
&amp;lt;dict&amp;gt; = vars(&amp;lt;obj&amp;gt;)                # Returns dict of writable attributes. Also &amp;lt;obj&amp;gt;.__dict__.
&amp;lt;bool&amp;gt; = hasattr(&amp;lt;obj&amp;gt;, '&amp;lt;name&amp;gt;')   # Checks if object possesses attribute with passed name.
value  = getattr(&amp;lt;obj&amp;gt;, '&amp;lt;name&amp;gt;')   # Returns the object's attribute or raises AttributeError.
setattr(&amp;lt;obj&amp;gt;, '&amp;lt;name&amp;gt;', value)     # Sets attribute. Only works on objects with __dict__ attr.
delattr(&amp;lt;obj&amp;gt;, '&amp;lt;name&amp;gt;')            # Deletes attribute from __dict__. Also `del &amp;lt;obj&amp;gt;.&amp;lt;name&amp;gt;`.
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;Sig&amp;gt;  = inspect.signature(&amp;lt;func&amp;gt;)  # Returns Signature object of the passed function or class.
&amp;lt;dict&amp;gt; = &amp;lt;Sig&amp;gt;.parameters           # Returns dict of Parameters. Also &amp;lt;Sig&amp;gt;.return_annotation.
&amp;lt;memb&amp;gt; = &amp;lt;Param&amp;gt;.kind               # Returns ParameterKind member (Parameter.KEYWORD_ONLY, …).
&amp;lt;type&amp;gt; = &amp;lt;Param&amp;gt;.annotation         # Returns Parameter.empty if missing. Also &amp;lt;Param&amp;gt;.default.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Threading&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;CPython interpreter can only run a single thread at a time. Using multiple threads won't result in a faster execution, unless at least one of the threads contains an I/O operation.&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from threading import Thread, Lock, RLock, Semaphore, Event, Barrier
from concurrent.futures import ThreadPoolExecutor, as_completed
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Thread&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;Thread&amp;gt; = Thread(target=&amp;lt;function&amp;gt;)           # Use `args=&amp;lt;collection&amp;gt;` to set the arguments.
&amp;lt;Thread&amp;gt;.start()                               # Starts the thread. Also &amp;lt;Thread&amp;gt;.is_alive().
&amp;lt;Thread&amp;gt;.join()                                # Waits for the thread to finish executing.
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Use &lt;code&gt;'kwargs=&amp;lt;dict&amp;gt;'&lt;/code&gt; to pass keyword arguments to the function.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Use &lt;code&gt;'daemon=True'&lt;/code&gt;, or the program won't be able to exit while the thread is alive.&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Lock&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;lock&amp;gt; = Lock/RLock()                          # RLock can only be released by acquirer thread.
&amp;lt;lock&amp;gt;.acquire()                               # Blocks (waits) until lock becomes available.
&amp;lt;lock&amp;gt;.release()                               # Releases the lock so it can be acquired again.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Or:&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;with &amp;lt;lock&amp;gt;:                                   # Enters the block by calling method acquire().
    ...                                        # Exits it by calling release(), even on error.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Semaphore, Event, Barrier&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;Semaphore&amp;gt; = Semaphore(value=1)               # Lock that can be acquired by 'value' threads.
&amp;lt;Event&amp;gt;     = Event()                          # Method wait() blocks until set() is called.
&amp;lt;Barrier&amp;gt;   = Barrier(&amp;lt;int&amp;gt;)                   # Wait() blocks until it's called int times.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Queue&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;Queue&amp;gt; = queue.Queue(maxsize=0)               # A first-in-first-out queue. It's thread safe.
&amp;lt;Queue&amp;gt;.put(&amp;lt;obj&amp;gt;)                             # Call blocks until queue stops being full.
&amp;lt;Queue&amp;gt;.put_nowait(&amp;lt;obj&amp;gt;)                      # Raises queue.Full exception if queue is full.
&amp;lt;obj&amp;gt; = &amp;lt;Queue&amp;gt;.get()                          # Call blocks until queue stops being empty.
&amp;lt;obj&amp;gt; = &amp;lt;Queue&amp;gt;.get_nowait()                   # Raises queue.Empty exception if it's empty.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Thread Pool Executor&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;Exec&amp;gt; = ThreadPoolExecutor(max_workers=None)  # Also `with ThreadPoolExecutor() as &amp;lt;name&amp;gt;: …`.
&amp;lt;iter&amp;gt; = &amp;lt;Exec&amp;gt;.map(&amp;lt;func&amp;gt;, &amp;lt;args_1&amp;gt;, ...)     # Multithreaded and non-lazy map(). Keeps order.
&amp;lt;Futr&amp;gt; = &amp;lt;Exec&amp;gt;.submit(&amp;lt;func&amp;gt;, &amp;lt;arg_1&amp;gt;, ...)   # Creates a thread and returns its Future obj.
&amp;lt;Exec&amp;gt;.shutdown()                              # Waits for all threads to finish executing.
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;bool&amp;gt; = &amp;lt;Future&amp;gt;.done()                       # Checks if the thread has finished executing.
&amp;lt;obj&amp;gt;  = &amp;lt;Future&amp;gt;.result(timeout=None)         # Raises TimeoutError after 'timeout' seconds.
&amp;lt;bool&amp;gt; = &amp;lt;Future&amp;gt;.cancel()                     # Cancels or returns False if running/finished.
&amp;lt;iter&amp;gt; = as_completed(&amp;lt;coll_of_Futures&amp;gt;)       # `next(&amp;lt;iter&amp;gt;)` returns next completed Future.
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Map() and as_completed() also accept 'timeout'. It causes futures.TimeoutError when next() is called/blocking. Map() times from original call and as_completed() from first call to next(). As_completed() fails if next() is called too late, even if all threads are done.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Exceptions that happen inside threads are raised when map iterator's next() or Future's result() are called. Future's exception() method returns an exception object or None.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ProcessPoolExecutor provides true parallelism but: everything sent to/from workers must be &lt;a href="https://raw.githubusercontent.com/gto76/python-cheatsheet/main/#pickle"&gt;pickable&lt;/a&gt;, queues must be sent using executor's 'initargs' and 'initializer' parameters, and executor should only be reachable via &lt;code&gt;'if __name__ == "__main__": ...'&lt;/code&gt;.&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Coroutines&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Coroutines have a lot in common with threads, but unlike threads, they only give up control when they call another coroutine and they don’t consume as much memory.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Coroutine definition starts with &lt;code&gt;'async'&lt;/code&gt; keyword and its call with &lt;code&gt;'await'&lt;/code&gt;.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Use &lt;code&gt;'asyncio.run(&amp;lt;coroutine&amp;gt;)'&lt;/code&gt; to start the first/main coroutine.&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import asyncio as aio
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;coro&amp;gt; = &amp;lt;async_function&amp;gt;(&amp;lt;args&amp;gt;)          # Creates a coroutine by calling async def function.
&amp;lt;obj&amp;gt;  = await &amp;lt;coroutine&amp;gt;                 # Starts the coroutine. Returns its result or None.
&amp;lt;task&amp;gt; = aio.create_task(&amp;lt;coroutine&amp;gt;)      # Schedules it for execution. Always keep the task.
&amp;lt;obj&amp;gt;  = await &amp;lt;task&amp;gt;                      # Returns coroutine's result. Also &amp;lt;task&amp;gt;.cancel().
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;coro&amp;gt; = aio.gather(&amp;lt;coro/task&amp;gt;, ...)      # Schedules coros. Returns list of results on await.
&amp;lt;coro&amp;gt; = aio.wait(&amp;lt;tasks&amp;gt;, return_when=…)  # `'ALL/FIRST_COMPLETED'`. Returns (done, pending).
&amp;lt;iter&amp;gt; = aio.as_completed(&amp;lt;coros/tasks&amp;gt;)   # Iter of coros that return next result on await.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Runs a terminal game where you control an asterisk that must avoid numbers:&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import asyncio, collections, curses, curses.textpad, enum, random

P = collections.namedtuple('P', 'x y')     # Position (x and y coordinates).
D = enum.Enum('D', 'n e s w')              # Direction (north, east, etc.).
W, H = 15, 7                               # Width and height of the field.

def main(screen):
    curses.curs_set(0)                     # Makes the cursor invisible.
    screen.nodelay(True)                   # Makes getch() non-blocking.
    asyncio.run(main_coroutine(screen))    # Starts running asyncio code.

async def main_coroutine(screen):
    moves = asyncio.Queue()
    state = {'*': P(0, 0)} | {id_: P(W//2, H//2) for id_ in range(10)}
    ai    = [random_controller(id_, moves) for id_ in range(10)]
    mvc   = [controller(screen, moves), model(moves, state), view(state, screen)]
    tasks = [asyncio.create_task(coro) for coro in ai + mvc]
    await asyncio.wait(tasks, return_when=asyncio.FIRST_COMPLETED)

async def random_controller(id_, moves):
    while True:
        d = random.choice(list(D))
        moves.put_nowait((id_, d))
        await asyncio.sleep(random.triangular(0.01, 0.65))

async def controller(screen, moves):
    while True:
        key_mappings = {258: D.s, 259: D.n, 260: D.w, 261: D.e}
        if d := key_mappings.get(screen.getch()):
            moves.put_nowait(('*', d))
        await asyncio.sleep(0.005)

async def model(moves, state):
    while state['*'] not in (state[id_] for id_ in range(10)):
        id_, d = await moves.get()
        deltas = {D.n: P(0, -1), D.e: P(1, 0), D.s: P(0, 1), D.w: P(-1, 0)}
        state[id_] = P((state[id_].x + deltas[d].x) % W, (state[id_].y + deltas[d].y) % H)

async def view(state, screen):
    offset = P(curses.COLS//2 - W//2, curses.LINES//2 - H//2)
    while True:
        screen.erase()
        curses.textpad.rectangle(screen, offset.y-1, offset.x-1, offset.y+H, offset.x+W)
        for id_, p in state.items():
            screen.addstr(offset.y + (p.y - state['*'].y + H//2) % H,
                          offset.x + (p.x - state['*'].x + W//2) % W, str(id_))
        screen.refresh()
        await asyncio.sleep(0.005)

if __name__ == '__main__':
    curses.wrapper(main)
&lt;/code&gt;&lt;/pre&gt; 
&lt;br /&gt; 
&lt;h1&gt;Libraries&lt;/h1&gt; 
&lt;h2&gt;Progress Bar&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# $ pip3 install tqdm
&amp;gt;&amp;gt;&amp;gt; import tqdm, time
&amp;gt;&amp;gt;&amp;gt; for el in tqdm.tqdm([1, 2, 3], desc='Processing'):
...     time.sleep(1)
Processing: 100%|████████████████████| 3/3 [00:03&amp;lt;00:00,  1.00s/it]
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Plot&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# $ pip3 install matplotlib
import matplotlib.pyplot as plt

plt.plot/bar/scatter(x_data, y_data [, label=&amp;lt;str&amp;gt;])  # Also plt.plot(y_data).
plt.legend()                                          # Adds a legend of labels.
plt.title/xlabel/ylabel(&amp;lt;str&amp;gt;)                        # Adds title or axis label.
plt.show()                                            # Also plt.savefig(&amp;lt;path&amp;gt;).
plt.clf()                                             # Clears the plot (figure).
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Table&lt;/h2&gt; 
&lt;h4&gt;Prints a CSV spreadsheet to the console:&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# $ pip3 install tabulate
import csv, tabulate
with open('test.csv', encoding='utf-8', newline='') as file:
    rows = list(csv.reader(file))
print(tabulate.tabulate(rows, headers='firstrow'))
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Console App&lt;/h2&gt; 
&lt;h4&gt;Runs a basic file explorer in the console:&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# $ pip3 install windows-curses
import curses, os
from curses import A_REVERSE, KEY_UP, KEY_DOWN, KEY_LEFT, KEY_RIGHT

def main(screen):
    ch, first, selected, paths = 0, 0, 0, os.listdir()
    while ch != ord('q'):
        height, width = screen.getmaxyx()
        screen.erase()
        for y, filename in enumerate(paths[first : first+height]):
            color = A_REVERSE if filename == paths[selected] else 0
            screen.addnstr(y, 0, filename, width-1, color)
        ch = screen.getch()
        selected -= (ch == KEY_UP) and (selected &amp;gt; 0)
        selected += (ch == KEY_DOWN) and (selected &amp;lt; len(paths)-1)
        first -= (first &amp;gt; selected)
        first += (first &amp;lt; selected-(height-1))
        if ch in [KEY_LEFT, KEY_RIGHT, ord('\n')]:
            new_dir = '..' if ch == KEY_LEFT else paths[selected]
            if os.path.isdir(new_dir):
                os.chdir(new_dir)
                first, selected, paths = 0, 0, os.listdir()

if __name__ == '__main__':
    curses.wrapper(main)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;GUI App&lt;/h2&gt; 
&lt;h4&gt;Runs a desktop app for converting weights from metric units into pounds:&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# $ pip3 install PySimpleGUI
import PySimpleGUI as sg

text_box = sg.Input(default_text='100', enable_events=True, key='QUANTITY')
dropdown = sg.InputCombo(['g', 'kg', 't'], 'kg', readonly=True, enable_events=True, k='UNIT')
label    = sg.Text('100 kg is 220.462 lbs.', key='OUTPUT')
window   = sg.Window('Weight Converter', [[text_box, dropdown], [label], [sg.Button('Close')]])

while True:
    event, values = window.read()
    if event in [sg.WIN_CLOSED, 'Close']:
        break
    try:
        quantity = float(values['QUANTITY'])
    except ValueError:
        continue
    unit = values['UNIT']
    lbs = quantity * {'g': 0.001, 'kg': 1, 't': 1000}[unit] / 0.45359237
    window['OUTPUT'].update(value=f'{quantity} {unit} is {lbs:g} lbs.')
window.close()
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Scraping&lt;/h2&gt; 
&lt;h4&gt;Scrapes Python's URL and logo from its Wikipedia page:&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# $ pip3 install requests beautifulsoup4
import requests, bs4, os

get = lambda url: requests.get(url, headers={'User-Agent': 'cpc-bot'})
response = get('https://en.wikipedia.org/wiki/Python_(programming_language)')
document = bs4.BeautifulSoup(response.text, 'html.parser')
table = document.find('table', class_='infobox vevent')
python_url = table.find('th', text='Website').next_sibling.a['href']
logo_url = table.find('img')['src']
filename = os.path.basename(logo_url)
with open(filename, 'wb') as file:
    file.write(get(f'https:{logo_url}').content)
print(f'URL: {python_url}, logo: file://{os.path.abspath(filename)}')
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Selenium&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Library for scraping websites with dynamic content.&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# $ pip3 install selenium
from selenium import webdriver
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;Drv&amp;gt; = webdriver.Chrome/Firefox/Safari/Edge()  # Opens the browser. Also &amp;lt;Driver&amp;gt;.quit().
&amp;lt;Drv&amp;gt;.implicitly_wait(seconds)                  # Sets timeout for find_element/s() methods.
&amp;lt;Drv&amp;gt;.get('&amp;lt;url&amp;gt;')                              # Blocks until browser fires the load event.
&amp;lt;str&amp;gt; = &amp;lt;Drv&amp;gt;.page_source                       # Returns HTML of the page's current state.
&amp;lt;El&amp;gt;  = &amp;lt;Drv/El&amp;gt;.find_element('xpath', &amp;lt;str&amp;gt;)   # Accepts '//&amp;lt;tag&amp;gt;[@&amp;lt;attr_name&amp;gt;="&amp;lt;val&amp;gt;"]…'.
&amp;lt;str&amp;gt; = &amp;lt;El&amp;gt;.get_attribute('&amp;lt;name&amp;gt;')            # Returns attribute or property if exists.
&amp;lt;El&amp;gt;.click/clear()                              # Also &amp;lt;El&amp;gt;.text and &amp;lt;El&amp;gt;.send_keys(&amp;lt;str&amp;gt;).
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;XPath — also available in lxml, Scrapy, and browser's console via &lt;code&gt;'$x("&amp;lt;xpath&amp;gt;")'&lt;/code&gt;:&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;xpath&amp;gt;     = //&amp;lt;element&amp;gt;[/ or // &amp;lt;element&amp;gt;]    # E.g. …/child, …//descendant, …/../sibling.
&amp;lt;xpath&amp;gt;     = //&amp;lt;element&amp;gt;/following::&amp;lt;element&amp;gt;  # Next element. Also preceding::, parent::.
&amp;lt;element&amp;gt;   = &amp;lt;tag&amp;gt;&amp;lt;conditions&amp;gt;&amp;lt;index&amp;gt;          # Tag accepts */a/…. Use [1/2/…] for index.
&amp;lt;condition&amp;gt; = [&amp;lt;sub_cond&amp;gt; [and/or &amp;lt;sub_cond&amp;gt;]]  # Use not(&amp;lt;sub_cond&amp;gt;) to negate condition.
&amp;lt;sub_cond&amp;gt;  = @&amp;lt;attr&amp;gt;[="&amp;lt;val&amp;gt;"]                 # `text()=` and `.=` match (complete) text.
&amp;lt;sub_cond&amp;gt;  = contains(@&amp;lt;attr&amp;gt;, "&amp;lt;val&amp;gt;")        # Is &amp;lt;val&amp;gt; a substring of attribute's value?
&amp;lt;sub_cond&amp;gt;  = [//]&amp;lt;element&amp;gt;                     # Has matching child? Descendant if //&amp;lt;el&amp;gt;.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Web App&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Flask is a micro web framework/server. If you just want to open a html file in a web browser use &lt;code&gt;'webbrowser.open(&amp;lt;path&amp;gt;)'&lt;/code&gt; instead.&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# $ pip3 install flask
import flask as fl
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;app = fl.Flask(__name__)                   # Returns the app object. Put at the top.
app.run(host=None, port=None, debug=None)  # Or: $ flask --app FILE run [--ARG[=VAL]]…
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Starts the app at &lt;code&gt;'http://localhost:5000'&lt;/code&gt;. Use &lt;code&gt;'host="0.0.0.0"'&lt;/code&gt; to run externally.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Install a WSGI server like &lt;a href="https://flask.palletsprojects.com/en/latest/deploying/waitress/"&gt;Waitress&lt;/a&gt; and a HTTP server such as &lt;a href="https://flask.palletsprojects.com/en/latest/deploying/nginx/"&gt;Nginx&lt;/a&gt; for better security.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Debug mode restarts the app whenever script changes and displays errors in the browser.&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Serving Files&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;@app.route('/img/&amp;lt;path:filename&amp;gt;')
def serve_file(filename):
    return fl.send_from_directory('DIRNAME', filename)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Serving HTML&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;@app.route('/&amp;lt;sport&amp;gt;')
def serve_html(sport):
    return fl.render_template_string('&amp;lt;h1&amp;gt;{{title}}&amp;lt;/h1&amp;gt;', title=sport)
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;'fl.render_template(filename, &amp;lt;kwargs&amp;gt;)'&lt;/code&gt; renders a file located in 'templates' dir.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;'fl.abort(&amp;lt;int&amp;gt;)'&lt;/code&gt; returns error code and &lt;code&gt;'return fl.redirect(&amp;lt;url&amp;gt;)'&lt;/code&gt; redirects.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;'fl.request.args[&amp;lt;str&amp;gt;]'&lt;/code&gt; returns parameter from query string (URL part right of '?').&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;'fl.session[&amp;lt;str&amp;gt;] = &amp;lt;obj&amp;gt;'&lt;/code&gt; stores session data. It requires secret key to be set at the startup with &lt;code&gt;'app.secret_key = &amp;lt;str&amp;gt;'&lt;/code&gt;.&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Serving JSON&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;@app.post('/&amp;lt;sport&amp;gt;/odds')
def serve_json(sport):
    team = fl.request.form['team']
    return {'team': team, 'odds': [2.09, 3.74, 3.68]}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Starts the app in its own thread and queries its REST API:&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# $ pip3 install requests
&amp;gt;&amp;gt;&amp;gt; import threading, requests
&amp;gt;&amp;gt;&amp;gt; threading.Thread(target=app.run, daemon=True).start()
&amp;gt;&amp;gt;&amp;gt; url = 'http://localhost:5000/football/odds'
&amp;gt;&amp;gt;&amp;gt; response = requests.post(url, data={'team': 'arsenal f.c.'})
&amp;gt;&amp;gt;&amp;gt; response.json()
{'team': 'arsenal f.c.', 'odds': [2.09, 3.74, 3.68]}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Profiling&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from time import perf_counter
start_time = perf_counter()
...
duration_in_seconds = perf_counter() - start_time
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Timing a Snippet&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;gt;&amp;gt;&amp;gt; from timeit import timeit
&amp;gt;&amp;gt;&amp;gt; timeit('list(range(10000))', number=1000, globals=globals(), setup='pass')
0.19373
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Profiling by Line&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-text"&gt;$ pip3 install line_profiler
$ echo '@profile
def main():
    a = list(range(10000))
    b = set(range(10000))
main()' &amp;gt; test.py
$ kernprof -lv test.py
Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
     1                                           @profile
     2                                           def main():
     3         1        253.4    253.4     32.2      a = list(range(10000))
     4         1        534.1    534.1     67.8      b = set(range(10000))
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Call and Flame Graphs&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;$ apt/brew install graphviz &amp;amp;&amp;amp; pip3 install gprof2dot snakeviz  # Or download installer.
$ tail --lines=+2 test.py &amp;gt; test.py                             # Removes first line.
$ python3 -m cProfile -o test.prof test.py                      # Runs built-in profiler.
$ gprof2dot --format=pstats test.prof | dot -T png -o test.png  # Generates call graph.
$ xdg-open/open test.png                                        # Displays call graph.
$ snakeviz test.prof                                            # Displays flame graph.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Sampling and Memory Profilers&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-text"&gt;+--------------+------------+-------------------------------+-------+------+
| pip3 install |   Target   |          How to run           | Lines | Live |
+--------------+------------+-------------------------------+-------+------+
| pyinstrument |    CPU     | pyinstrument test.py          |  No   | No   |
| py-spy       |    CPU     | py-spy top -- python3 test.py |  No   | Yes  |
| scalene      | CPU+Memory | scalene test.py               |  Yes  | No   |
| memray       |   Memory   | memray run --live test.py     |  Yes  | Yes  |
+--------------+------------+-------------------------------+-------+------+
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;NumPy&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Array manipulation mini-language. It can run up to one hundred times faster than the equivalent Python code. An even faster alternative that runs on a GPU is called CuPy.&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# $ pip3 install numpy
import numpy as np
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;array&amp;gt; = np.array(&amp;lt;list/list_of_lists/…&amp;gt;)              # Returns a 1d/2d/… NumPy array.
&amp;lt;array&amp;gt; = np.zeros/ones/empty(&amp;lt;shape&amp;gt;)                  # Also np.full(&amp;lt;shape&amp;gt;, &amp;lt;el&amp;gt;).
&amp;lt;array&amp;gt; = np.arange(from_inc, to_exc, ±step)            # Also np.linspace(start, stop, len).
&amp;lt;array&amp;gt; = np.random.randint(from_inc, to_exc, &amp;lt;shape&amp;gt;)  # Also np.random.random(&amp;lt;shape&amp;gt;).
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;view&amp;gt;  = &amp;lt;array&amp;gt;.reshape(&amp;lt;shape&amp;gt;)                      # Also `&amp;lt;array&amp;gt;.shape = &amp;lt;shape&amp;gt;`.
&amp;lt;array&amp;gt; = &amp;lt;array&amp;gt;.flatten()                             # Also `&amp;lt;view&amp;gt; = &amp;lt;array&amp;gt;.ravel()`.
&amp;lt;view&amp;gt;  = &amp;lt;array&amp;gt;.transpose()                           # Flips the table over its diagonal.
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;array&amp;gt; = np.copy/abs/sqrt/log/int64(&amp;lt;array&amp;gt;)           # Returns new array of the same shape.
&amp;lt;array&amp;gt; = &amp;lt;array&amp;gt;.sum/max/mean/argmax/all(axis)         # Aggregates specified dimension.
&amp;lt;array&amp;gt; = np.apply_along_axis(&amp;lt;func&amp;gt;, axis, &amp;lt;array&amp;gt;)    # Func can return a scalar or array.
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;array&amp;gt; = np.concatenate(&amp;lt;list_of_arrays&amp;gt;, axis=0)      # Links arrays along first axis (rows).
&amp;lt;array&amp;gt; = np.vstack/column_stack(&amp;lt;list_of_arrays&amp;gt;)      # Treats 1d arrays as rows or columns.
&amp;lt;array&amp;gt; = np.tile/repeat(&amp;lt;array&amp;gt;, &amp;lt;int/list&amp;gt; [, axis])  # Tiles array or repeats its elements.
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Shape is a tuple of dimension sizes. A 100x50 RGB image has shape (50, 100, 3).&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Axis is an index of a dimension. Leftmost dimension has index 0. Summing the RGB image along axis 2 will return a greyscale image with shape (50, 100).&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Indexing&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-perl"&gt;&amp;lt;el&amp;gt;       = &amp;lt;2d&amp;gt;[row_index, col_index]                 # Or: &amp;lt;3d&amp;gt;[&amp;lt;int&amp;gt;, &amp;lt;int&amp;gt;, &amp;lt;int&amp;gt;]
&amp;lt;1d_view&amp;gt;  = &amp;lt;2d&amp;gt;[row_index]                            # Or: &amp;lt;3d&amp;gt;[&amp;lt;int&amp;gt;, &amp;lt;int&amp;gt;, &amp;lt;slice&amp;gt;]
&amp;lt;1d_view&amp;gt;  = &amp;lt;2d&amp;gt;[:, col_index]                         # Or: &amp;lt;3d&amp;gt;[&amp;lt;int&amp;gt;, &amp;lt;slice&amp;gt;, &amp;lt;int&amp;gt;]
&amp;lt;2d_view&amp;gt;  = &amp;lt;2d&amp;gt;[from:to_row_i, from:to_col_i]         # Or: &amp;lt;3d&amp;gt;[&amp;lt;int&amp;gt;, &amp;lt;slice&amp;gt;, &amp;lt;slice&amp;gt;]
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-perl"&gt;&amp;lt;1d_array&amp;gt; = &amp;lt;2d&amp;gt;[row_indices, col_indices]             # Or: &amp;lt;3d&amp;gt;[&amp;lt;int/1d&amp;gt;, &amp;lt;1d&amp;gt;, &amp;lt;1d&amp;gt;]
&amp;lt;2d_array&amp;gt; = &amp;lt;2d&amp;gt;[row_indices]                          # Or: &amp;lt;3d&amp;gt;[&amp;lt;int/1d&amp;gt;, &amp;lt;1d&amp;gt;, &amp;lt;slice&amp;gt;]
&amp;lt;2d_array&amp;gt; = &amp;lt;2d&amp;gt;[:, col_indices]                       # Or: &amp;lt;3d&amp;gt;[&amp;lt;int/1d&amp;gt;, &amp;lt;slice&amp;gt;, &amp;lt;1d&amp;gt;]
&amp;lt;2d_array&amp;gt; = &amp;lt;2d&amp;gt;[np.ix_(row_indices, col_indices)]     # Or: &amp;lt;3d&amp;gt;[&amp;lt;int/1d/2d&amp;gt;, &amp;lt;2d&amp;gt;, &amp;lt;2d&amp;gt;]
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-perl"&gt;&amp;lt;2d_bools&amp;gt; = &amp;lt;2d&amp;gt; &amp;gt; &amp;lt;el/1d/2d&amp;gt;                          # 1d object must have size of a row.
&amp;lt;1/2d_arr&amp;gt; = &amp;lt;2d&amp;gt;[&amp;lt;2d/1d_bools&amp;gt;]                        # 1d_bools must have size of a column.
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;':'&lt;/code&gt; returns a slice of all dimension's indices. Omitted dimensions default to &lt;code&gt;':'&lt;/code&gt;.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Python converts &lt;code&gt;'obj[i, j]'&lt;/code&gt; to &lt;code&gt;'obj[(i, j)]'&lt;/code&gt;. This makes &lt;code&gt;'&amp;lt;2d&amp;gt;[row_i, col_i]'&lt;/code&gt; and &lt;code&gt;'&amp;lt;2d&amp;gt;[row_indices]'&lt;/code&gt; indistinguishable to NumPy if tuple of two indices is passed!&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;'ix_([1, 2], [3, 4])'&lt;/code&gt; returns &lt;code&gt;'[[1], [2]]'&lt;/code&gt; and &lt;code&gt;'[[3, 4]]'&lt;/code&gt;. Due to broadcasting rules, this is the same as using &lt;code&gt;'[[1, 1], [2, 2]]'&lt;/code&gt; and &lt;code&gt;'[[3, 4], [3, 4]]'&lt;/code&gt;.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Any value that is broadcastable to the indexed shape can be assigned to the selection.&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Broadcasting&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;A set of rules by which NumPy functions operate on arrays of different shapes.&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;left  = np.array([0.1,  0.6,  0.8])                     # `left.shape  == (3,)`
right = np.array([[0.1], [0.6], [0.8]])                 # `right.shape == (3, 1)`
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;1. If array shapes differ in length, left-pad the shorter shape with ones:&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;left  = np.array([[0.1,  0.6,  0.8]])                   # `left.shape  == (1, 3)`
right = np.array([[0.1], [0.6], [0.8]])                 # `right.shape == (3, 1)`
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;2. If any dimensions differ in size, expand the ones that have size 1 by duplicating their elements:&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;left  = np.array([[0.1,  0.6,  0.8],                    # `left.shape  == (3, 3)`
                  [0.1,  0.6,  0.8],
                  [0.1,  0.6,  0.8]])

right = np.array([[0.1,  0.1,  0.1],                    # `right.shape == (3, 3)`
                  [0.6,  0.6,  0.6],
                  [0.8,  0.8,  0.8]])
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Example&lt;/h3&gt; 
&lt;h4&gt;For each point returns index of its nearest point (&lt;code&gt;[0.1, 0.6, 0.8] =&amp;gt; [1, 2, 1]&lt;/code&gt;):&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;gt;&amp;gt;&amp;gt; print(points := np.array([0.1, 0.6, 0.8]))
[0.1  0.6  0.8]
&amp;gt;&amp;gt;&amp;gt; print(wrapped_points := points.reshape(3, 1))
[[0.1]
 [0.6]
 [0.8]]
&amp;gt;&amp;gt;&amp;gt; print(deltas := points - wrapped_points)
[[ 0.   0.5  0.7]
 [-0.5  0.   0.2]
 [-0.7 -0.2  0. ]]
&amp;gt;&amp;gt;&amp;gt; deltas[range(3), range(3)] = np.inf
&amp;gt;&amp;gt;&amp;gt; print(distances := np.abs(deltas))
[[inf  0.5  0.7]
 [0.5  inf  0.2]
 [0.7  0.2  inf]]
&amp;gt;&amp;gt;&amp;gt; print(distances.argmin(axis=1))
[1 2 1]
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Image&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# $ pip3 install pillow
from PIL import Image
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;Image&amp;gt; = Image.new('&amp;lt;mode&amp;gt;', (width, height))  # Creates new image. Also `color=&amp;lt;int/tuple&amp;gt;`.
&amp;lt;Image&amp;gt; = Image.open(&amp;lt;path&amp;gt;)                    # Identifies format based on file's contents.
&amp;lt;Image&amp;gt; = &amp;lt;Image&amp;gt;.convert('&amp;lt;mode&amp;gt;')             # Converts image to the new mode (see Modes).
&amp;lt;Image&amp;gt;.save(&amp;lt;path&amp;gt;)                            # Accepts `quality=&amp;lt;int&amp;gt;` if extension is jpg.
&amp;lt;Image&amp;gt;.show()                                  # Displays image in default preview app.
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;int/tup&amp;gt; = &amp;lt;Image&amp;gt;.getpixel((x, y))            # Returns pixel's value (its color).
&amp;lt;ImgCore&amp;gt; = &amp;lt;Image&amp;gt;.getdata()                   # Returns a flattened view of pixel values.
&amp;lt;Image&amp;gt;.putpixel((x, y), &amp;lt;int/tuple&amp;gt;)           # Updates pixel's value. Clips passed int/s.
&amp;lt;Image&amp;gt;.putdata(&amp;lt;list/ImgCore&amp;gt;)                 # Updates pixels with a copy of the sequence.
&amp;lt;Image&amp;gt;.paste(&amp;lt;Image&amp;gt;, (x, y))                  # Draws passed image at the specified location.
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;Image&amp;gt; = &amp;lt;Image&amp;gt;.filter(&amp;lt;Filter&amp;gt;)              # Use ImageFilter.&amp;lt;name&amp;gt;(&amp;lt;args&amp;gt;) for Filter.
&amp;lt;Image&amp;gt; = &amp;lt;Enhance&amp;gt;.enhance(&amp;lt;float&amp;gt;)            # Use ImageEnhance.&amp;lt;name&amp;gt;(&amp;lt;Image&amp;gt;) for Enhance.
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;array&amp;gt; = np.array(&amp;lt;Image&amp;gt;)                     # Creates a 2d/3d NumPy array from the image.
&amp;lt;Image&amp;gt; = Image.fromarray(np.uint8(&amp;lt;array&amp;gt;))    # Use &amp;lt;array&amp;gt;.clip(0, 255) to clip the values.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Modes&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;'L'&lt;/code&gt; - Lightness (greyscale image). Each pixel is an integer between 0 and 255.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;'RGB'&lt;/code&gt; - Red, green, blue (true color image). Each pixel is a tuple of three integers.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;'RGBA'&lt;/code&gt; - RGB with alpha. Low alpha (i.e. fourth int) makes pixel more transparent.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;'HSV'&lt;/code&gt; - Hue, saturation, value. Three ints representing color in HSV color space.&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Examples&lt;/h3&gt; 
&lt;h4&gt;Creates a PNG image of a rainbow gradient:&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;WIDTH, HEIGHT = 100, 100
n_pixels = WIDTH * HEIGHT
hues = (255 * i/n_pixels for i in range(n_pixels))
img = Image.new('HSV', (WIDTH, HEIGHT))
img.putdata([(int(h), 255, 255) for h in hues])
img.convert('RGB').save('test.png')
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Adds noise to the PNG image and displays it:&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from random import randint
add_noise = lambda value: max(0, min(255, value + randint(-20, 20)))
img = Image.open('test.png').convert('HSV')
img.putdata([(add_noise(h), s, v) for h, s, v in img.getdata()])
img.show()
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Image Draw&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from PIL import ImageDraw
&amp;lt;Draw&amp;gt; = ImageDraw.Draw(&amp;lt;Image&amp;gt;)                # Object for adding 2D graphics to the image.
&amp;lt;Draw&amp;gt;.point((x, y))                            # Draws a point. Also `fill=&amp;lt;int/tuple/str&amp;gt;`.
&amp;lt;Draw&amp;gt;.line((x1, y1, x2, y2 [, ...]))           # For anti-aliasing use &amp;lt;Image&amp;gt;.resize((w, h)).
&amp;lt;Draw&amp;gt;.arc((x1, y1, x2, y2), deg1, deg2)        # Draws in clockwise dir. Also pieslice().
&amp;lt;Draw&amp;gt;.rectangle((x1, y1, x2, y2))              # Also rounded_rectangle(), regular_polygon().
&amp;lt;Draw&amp;gt;.polygon((x1, y1, x2, y2, ...))           # Last point gets connected to the first one.
&amp;lt;Draw&amp;gt;.ellipse((x1, y1, x2, y2))                # To rotate use &amp;lt;Image&amp;gt;.rotate(anticlock_deg).
&amp;lt;Draw&amp;gt;.text((x, y), &amp;lt;str&amp;gt;, font=&amp;lt;Font&amp;gt;)         # `&amp;lt;Font&amp;gt; = ImageFont.truetype(&amp;lt;path&amp;gt;, size)`.
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Use &lt;code&gt;'fill=&amp;lt;color&amp;gt;'&lt;/code&gt; to set the primary color.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Use &lt;code&gt;'width=&amp;lt;int&amp;gt;'&lt;/code&gt; to set the width of lines or contours.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Use &lt;code&gt;'outline=&amp;lt;color&amp;gt;'&lt;/code&gt; to set the color of the contours.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Color can be an int, tuple, &lt;code&gt;'#rrggbb[aa]'&lt;/code&gt; string or a color name.&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Animation&lt;/h2&gt; 
&lt;h4&gt;Creates a GIF of a bouncing ball:&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# $ pip3 install imageio
from PIL import Image, ImageDraw
import imageio

WIDTH, HEIGHT, R = 126, 126, 10
frames = []
for velocity in range(1, 16):
    y = sum(range(velocity))
    frame = Image.new('L', (WIDTH, HEIGHT))
    draw = ImageDraw.Draw(frame)
    draw.ellipse((WIDTH/2-R, y, WIDTH/2+R, y+R*2), fill='white')
    frames.append(frame)
frames += reversed(frames[1:-1])
imageio.mimsave('test.gif', frames, duration=0.03)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Audio&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import wave
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;Wave&amp;gt;  = wave.open('&amp;lt;path&amp;gt;')         # Opens the WAV file for reading.
&amp;lt;int&amp;gt;   = &amp;lt;Wave&amp;gt;.getframerate()       # Returns number of frames per second.
&amp;lt;int&amp;gt;   = &amp;lt;Wave&amp;gt;.getnchannels()       # Returns number of samples per frame.
&amp;lt;int&amp;gt;   = &amp;lt;Wave&amp;gt;.getsampwidth()       # Returns number of bytes per sample.
&amp;lt;tuple&amp;gt; = &amp;lt;Wave&amp;gt;.getparams()          # Returns namedtuple of all parameters.
&amp;lt;bytes&amp;gt; = &amp;lt;Wave&amp;gt;.readframes(nframes)  # Returns all frames if -1 is passed.
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;Wave&amp;gt; = wave.open('&amp;lt;path&amp;gt;', 'wb')    # Creates/truncates a file for writing.
&amp;lt;Wave&amp;gt;.setframerate(&amp;lt;int&amp;gt;)            # Pass 44100 for CD, 48000 for video.
&amp;lt;Wave&amp;gt;.setnchannels(&amp;lt;int&amp;gt;)            # Pass 1 for mono, 2 for stereo.
&amp;lt;Wave&amp;gt;.setsampwidth(&amp;lt;int&amp;gt;)            # Pass 2 for CD, 3 for hi-res sound.
&amp;lt;Wave&amp;gt;.setparams(&amp;lt;tuple&amp;gt;)             # Tuple must contain all parameters.
&amp;lt;Wave&amp;gt;.writeframes(&amp;lt;bytes&amp;gt;)           # Appends frames to the file.
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Bytes object contains a sequence of frames, each consisting of one or more samples.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;In a stereo signal, the first sample of a frame belongs to the left channel.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Each sample consists of one or more bytes that, when converted to an integer, indicate the displacement of a speaker membrane at a given moment.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;If sample width is one byte, then the integer should be encoded unsigned. For all other sizes, the integer should be encoded signed with little-endian byte order.&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Sample Values&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-text"&gt;+-----------+-----------+------+-----------+
| sampwidth |    min    | zero |    max    |
+-----------+-----------+------+-----------+
|     1     |         0 |  128 |       255 |
|     2     |    -32768 |    0 |     32767 |
|     3     |  -8388608 |    0 |   8388607 |
+-----------+-----------+------+-----------+
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Read Float Samples from WAV File&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;def read_wav_file(filename):
    def get_int(bytes_obj):
        an_int = int.from_bytes(bytes_obj, 'little', signed=(p.sampwidth != 1))
        return an_int - 128 * (p.sampwidth == 1)
    with wave.open(filename) as file:
        p = file.getparams()
        frames = file.readframes(-1)
    bytes_samples = (frames[i : i + p.sampwidth] for i in range(0, len(frames), p.sampwidth))
    return [get_int(b) / pow(2, (p.sampwidth * 8) - 1) for b in bytes_samples], p
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Write Float Samples to WAV File&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;def write_to_wav_file(filename, samples_f, p=None, nchannels=1, sampwidth=2, framerate=44100):
    def get_bytes(a_float):
        a_float = max(-1, min(1 - 2e-16, a_float))
        a_float += (p.sampwidth == 1)
        a_float *= pow(2, (p.sampwidth * 8) - 1)
        return int(a_float).to_bytes(p.sampwidth, 'little', signed=(p.sampwidth != 1))
    if p is None:
        p = wave._wave_params(nchannels, sampwidth, framerate, 0, 'NONE', 'not compressed')
    with wave.open(filename, 'wb') as file:
        file.setparams(p)
        file.writeframes(b''.join(get_bytes(f) for f in samples_f))
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Examples&lt;/h3&gt; 
&lt;h4&gt;Saves a 440 Hz sine wave to a mono WAV file:&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from math import pi, sin
samples_f = (sin(i * 2 * pi * 440 / 44100) for i in range(100_000))
write_to_wav_file('test.wav', samples_f)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Adds noise to the WAV file:&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from random import uniform
samples_f, params = read_wav_file('test.wav')
samples_f = (f + uniform(-0.05, 0.05) for f in samples_f)
write_to_wav_file('test.wav', samples_f, p=params)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Plays the WAV file:&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# $ pip3 install simpleaudio
from simpleaudio import play_buffer
with wave.open('test.wav') as file:
    frames, p = file.readframes(-1), file.getparams()
    play_buffer(frames, p.nchannels, p.sampwidth, p.framerate).wait_done()
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Text to Speech&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# $ pip3 install pyttsx3
import pyttsx3
engine = pyttsx3.init()
engine.say('Sally sells seashells by the seashore.')
engine.runAndWait()
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Synthesizer&lt;/h2&gt; 
&lt;h4&gt;Plays Popcorn by Gershon Kingsley:&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# $ pip3 install simpleaudio
import itertools as it, math, array, simpleaudio

def play_notes(notes, bpm=132, f=44100):
    get_pause   = lambda n_beats: it.repeat(0, int(n_beats * 60/bpm * f))
    sin_f       = lambda i, hz: math.sin(i * 2 * math.pi * hz / f)
    get_wave    = lambda hz, n_beats: (sin_f(i, hz) for i in range(int(n_beats * 60/bpm * f)))
    get_hz      = lambda note: 440 * 2 ** ((int(note[:2]) - 69) / 12)
    get_nbeats  = lambda note: 1/2 if '♩' in note else 1/4 if '♪' in note else 1
    get_samples = lambda n: get_wave(get_hz(n), get_nbeats(n)) if n else get_pause(1/4)
    samples_f   = it.chain.from_iterable(get_samples(n) for n in notes.split(','))
    samples_i   = array.array('h', (int(fl * 5000) for fl in samples_f))
    simpleaudio.play_buffer(samples_i, 1, 2, f).wait_done()

play_notes('83♩,81♪,,83♪,,78♪,,74♪,,78♪,,71♪,,,,83♪,,81♪,,83♪,,78♪,,74♪,,78♪,,71♪,,,,'
           '83♩,85♪,,86♪,,85♪,,86♪,,83♪,,85♩,83♪,,85♪,,81♪,,83♪,,81♪,,83♪,,79♪,,83♪,,,,')
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Pygame&lt;/h2&gt; 
&lt;h4&gt;Opes a window and draws a square that can be moved with arrow keys:&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# $ pip3 install pygame
import pygame as pg

pg.init()
screen = pg.display.set_mode((500, 500))
rect = pg.Rect(240, 240, 20, 20)
while not pg.event.get(pg.QUIT):
    for event in pg.event.get(pg.KEYDOWN):
        dx = (event.key == pg.K_RIGHT) - (event.key == pg.K_LEFT)
        dy = (event.key == pg.K_DOWN) - (event.key == pg.K_UP)
        rect = rect.move((dx * 20, dy * 20))
    screen.fill(pg.Color('black'))
    pg.draw.rect(screen, pg.Color('white'), rect)
    pg.display.flip()
pg.quit()
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Rect&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Object for storing rectangular coordinates.&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;Rect&amp;gt; = pg.Rect(x, y, width, height)           # Creates Rect object. Truncates passed floats.
&amp;lt;int&amp;gt;  = &amp;lt;Rect&amp;gt;.x/y/centerx/centery/…           # `top/right/bottom/left`. Allows assignments.
&amp;lt;tup.&amp;gt; = &amp;lt;Rect&amp;gt;.topleft/center/…                # `topright/bottomright/bottomleft/size`. Same.
&amp;lt;Rect&amp;gt; = &amp;lt;Rect&amp;gt;.move((delta_x, delta_y))        # Use move_ip() to move the rectangle in-place.
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;bool&amp;gt; = &amp;lt;Rect&amp;gt;.collidepoint((x, y))            # Checks whether rectangle contains the point.
&amp;lt;bool&amp;gt; = &amp;lt;Rect&amp;gt;.colliderect(&amp;lt;Rect&amp;gt;)             # Checks whether the two rectangles overlap.
&amp;lt;int&amp;gt;  = &amp;lt;Rect&amp;gt;.collidelist(&amp;lt;list_of_Rect&amp;gt;)     # Returns index of first colliding Rect or -1.
&amp;lt;list&amp;gt; = &amp;lt;Rect&amp;gt;.collidelistall(&amp;lt;list_of_Rect&amp;gt;)  # Returns indices of all colliding rectangles.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Surface&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Object for representing images.&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;Surf&amp;gt; = pg.display.set_mode((width, height))   # Opens a new window and returns its surface.
&amp;lt;Surf&amp;gt; = pg.Surface((width, height))            # New RGB surface. RGBA if `flags=pg.SRCALPHA`.
&amp;lt;Surf&amp;gt; = pg.image.load(&amp;lt;path/file&amp;gt;)             # Loads the image. Format depends on source.
&amp;lt;Surf&amp;gt; = pg.surfarray.make_surface(&amp;lt;np_array&amp;gt;)  # Also `&amp;lt;np_arr&amp;gt; = surfarray.pixels3d(&amp;lt;Surf&amp;gt;)`.
&amp;lt;Surf&amp;gt; = &amp;lt;Surf&amp;gt;.subsurface(&amp;lt;Rect&amp;gt;)              # Creates a new surface from the cutout.
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;Surf&amp;gt;.fill(color)                              # Pass tuple of ints or pg.Color('&amp;lt;name/hex&amp;gt;').
&amp;lt;Surf&amp;gt;.set_at((x, y), color)                    # Updates pixel. Also &amp;lt;Surf&amp;gt;.get_at((x, y)).
&amp;lt;Surf&amp;gt;.blit(&amp;lt;Surf&amp;gt;, (x, y))                     # Draws passed surface at specified location.
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from pygame.transform import scale, rotate      # Also: flip, smoothscale, scale_by.
&amp;lt;Surf&amp;gt; = scale(&amp;lt;Surf&amp;gt;, (width, height))         # Scales the surface. `smoothscale()` blurs it.
&amp;lt;Surf&amp;gt; = rotate(&amp;lt;Surf&amp;gt;, angle)                  # Rotates the surface for counterclock degrees.
&amp;lt;Surf&amp;gt; = flip(&amp;lt;Surf&amp;gt;, flip_x=False)             # Mirrors the surface. Also `flip_y=False`.
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from pygame.draw import line, arc, rect         # Also: ellipse, polygon, circle, aaline.
line(&amp;lt;Surf&amp;gt;, color, (x1, y1), (x2, y2))         # Draws a line to the surface. Also `width=1`.
arc(&amp;lt;Surf&amp;gt;, color, &amp;lt;Rect&amp;gt;, from_rad, to_rad)    # Also ellipse(&amp;lt;Surf&amp;gt;, color, &amp;lt;Rect&amp;gt;, width=0).
rect(&amp;lt;Surf&amp;gt;, color, &amp;lt;Rect&amp;gt;, width=0)            # Also polygon(&amp;lt;Surf&amp;gt;, color, points, width=0).
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;Font&amp;gt; = pg.font.Font(&amp;lt;path/file&amp;gt;, size)        # Loads TTF file. Pass None for default font.
&amp;lt;Surf&amp;gt; = &amp;lt;Font&amp;gt;.render(text, antialias, color)  # Accepts background color as fourth argument.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Sound&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;Sound&amp;gt; = pg.mixer.Sound(&amp;lt;path/file/bytes&amp;gt;)     # WAV file or bytes/array of signed shorts.
&amp;lt;Sound&amp;gt;.play/stop()                             # Also set_volume(&amp;lt;float&amp;gt;) and fadeout(msec).
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Basic Mario Brothers Example&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import collections, dataclasses, enum, io, itertools as it, pygame as pg, urllib.request
from random import randint

P = collections.namedtuple('P', 'x y')          # Position
D = enum.Enum('D', 'n e s w')                   # Direction
W, H, MAX_S = 50, 50, P(5, 10)                  # Width, Height, Max speed

def main():
    def get_screen():
        pg.init()
        return pg.display.set_mode((W*16, H*16))
    def get_images():
        url = 'https://gto76.github.io/python-cheatsheet/web/mario_bros.png'
        img = pg.image.load(io.BytesIO(urllib.request.urlopen(url).read()))
        return [img.subsurface(get_rect(x, 0)) for x in range(img.get_width() // 16)]
    def get_mario():
        Mario = dataclasses.make_dataclass('Mario', 'rect spd facing_left frame_cycle'.split())
        return Mario(get_rect(1, 1), P(0, 0), False, it.cycle(range(3)))
    def get_tiles():
        border = [(x, y) for x in range(W) for y in range(H) if x in [0, W-1] or y in [0, H-1]]
        platforms = [(randint(1, W-2), randint(2, H-2)) for _ in range(W*H // 10)]
        return [get_rect(x, y) for x, y in border + platforms]
    def get_rect(x, y):
        return pg.Rect(x*16, y*16, 16, 16)
    run(get_screen(), get_images(), get_mario(), get_tiles())

def run(screen, images, mario, tiles):
    clock = pg.time.Clock()
    pressed = set()
    while not pg.event.get(pg.QUIT):
        clock.tick(28)
        pressed |= {e.key for e in pg.event.get(pg.KEYDOWN)}
        pressed -= {e.key for e in pg.event.get(pg.KEYUP)}
        update_speed(mario, tiles, pressed)
        update_position(mario, tiles)
        draw(screen, images, mario, tiles)

def update_speed(mario, tiles, pressed):
    x, y = mario.spd
    x += 2 * ((pg.K_RIGHT in pressed) - (pg.K_LEFT in pressed))
    x += (x &amp;lt; 0) - (x &amp;gt; 0)
    y += 1 if D.s not in get_boundaries(mario.rect, tiles) else (pg.K_UP in pressed) * -10
    mario.spd = P(x=max(-MAX_S.x, min(MAX_S.x, x)), y=max(-MAX_S.y, min(MAX_S.y, y)))

def update_position(mario, tiles):
    x, y = mario.rect.topleft
    n_steps = max(abs(s) for s in mario.spd)
    for _ in range(n_steps):
        mario.spd = stop_on_collision(mario.spd, get_boundaries(mario.rect, tiles))
        x, y = x + (mario.spd.x / n_steps), y + (mario.spd.y / n_steps)
        mario.rect.topleft = x, y

def get_boundaries(rect, tiles):
    deltas = {D.n: P(0, -1), D.e: P(1, 0), D.s: P(0, 1), D.w: P(-1, 0)}
    return {d for d, delta in deltas.items() if rect.move(delta).collidelist(tiles) != -1}

def stop_on_collision(spd, bounds):
    return P(x=0 if (D.w in bounds and spd.x &amp;lt; 0) or (D.e in bounds and spd.x &amp;gt; 0) else spd.x,
             y=0 if (D.n in bounds and spd.y &amp;lt; 0) or (D.s in bounds and spd.y &amp;gt; 0) else spd.y)

def draw(screen, images, mario, tiles):
    screen.fill((85, 168, 255))
    mario.facing_left = mario.spd.x &amp;lt; 0 if mario.spd.x else mario.facing_left
    is_airborne = D.s not in get_boundaries(mario.rect, tiles)
    image_index = 4 if is_airborne else next(mario.frame_cycle) if mario.spd.x else 6
    screen.blit(images[image_index + (mario.facing_left * 9)], mario.rect)
    for t in tiles:
        is_border = t.x in [0, (W-1)*16] or t.y in [0, (H-1)*16]
        screen.blit(images[18 if is_border else 19], t)
    pg.display.flip()

if __name__ == '__main__':
    main()
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Pandas&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Data analysis library. For examples see &lt;a href="https://raw.githubusercontent.com/gto76/python-cheatsheet/main/#plotly"&gt;Plotly&lt;/a&gt;.&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# $ pip3 install pandas matplotlib
import pandas as pd, matplotlib.pyplot as plt
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Series&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Ordered dictionary with a name.&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;gt;&amp;gt;&amp;gt; s = pd.Series([1, 2], index=['x', 'y'], name='a'); s
x    1
y    2
Name: a, dtype: int64
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;S&amp;gt;  = pd.Series(&amp;lt;list&amp;gt;)                       # Uses list's indices for 'index'.
&amp;lt;S&amp;gt;  = pd.Series(&amp;lt;dict&amp;gt;)                       # Uses dictionary's keys for 'index'.
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;el&amp;gt; = &amp;lt;S&amp;gt;.loc[key]                            # Or: &amp;lt;S&amp;gt;.iloc[i]
&amp;lt;S&amp;gt;  = &amp;lt;S&amp;gt;.loc[coll_of_keys]                   # Or: &amp;lt;S&amp;gt;.iloc[coll_of_i]
&amp;lt;S&amp;gt;  = &amp;lt;S&amp;gt;.loc[from_key : to_key_inc]          # Or: &amp;lt;S&amp;gt;.iloc[from_i : to_i_exc]
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;el&amp;gt; = &amp;lt;S&amp;gt;[key/i]                              # Or: &amp;lt;S&amp;gt;.&amp;lt;key&amp;gt;
&amp;lt;S&amp;gt;  = &amp;lt;S&amp;gt;[coll_of_keys/coll_of_i]             # Or: &amp;lt;S&amp;gt;[key/i : key/i]
&amp;lt;S&amp;gt;  = &amp;lt;S&amp;gt;[&amp;lt;S_of_bools&amp;gt;]                       # Or: &amp;lt;S&amp;gt;.loc/iloc[&amp;lt;S_of_bools&amp;gt;]
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;S&amp;gt;  = &amp;lt;S&amp;gt; &amp;gt; &amp;lt;el/S&amp;gt;                            # Returns S of bools. For logic use &amp;amp;, |, ~.
&amp;lt;S&amp;gt;  = &amp;lt;S&amp;gt; + &amp;lt;el/S&amp;gt;                            # Items with non-matching keys get value NaN.
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;S&amp;gt;  = &amp;lt;S&amp;gt;.head/describe/sort_values()         # Also &amp;lt;S&amp;gt;.unique/value_counts/round/dropna().
&amp;lt;S&amp;gt;  = &amp;lt;S&amp;gt;.str.strip/lower/contains/replace()  # Also split().str[i] or split(expand=True).
&amp;lt;S&amp;gt;  = &amp;lt;S&amp;gt;.dt.year/month/day/hour              # Use pd.to_datetime(&amp;lt;S&amp;gt;) to get S of datetimes.
&amp;lt;S&amp;gt;  = &amp;lt;S&amp;gt;.dt.to_period('y/m/d/h')             # Quantizes datetimes into Period objects.
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;S&amp;gt;.plot.line/area/bar/pie/hist()              # Generates a plot. Accepts `title=&amp;lt;str&amp;gt;`.
plt.show()                                     # Displays the plot. Also plt.savefig(&amp;lt;path&amp;gt;).
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Use &lt;code&gt;'print(&amp;lt;S&amp;gt;.to_string())'&lt;/code&gt; to print a Series that has more than sixty items.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Use &lt;code&gt;'&amp;lt;S&amp;gt;.index'&lt;/code&gt; to get collection of keys and &lt;code&gt;'&amp;lt;S&amp;gt;.index = &amp;lt;coll&amp;gt;'&lt;/code&gt; to update them.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Only pass a list or Series to loc/iloc because &lt;code&gt;'obj[x, y]'&lt;/code&gt; is converted to &lt;code&gt;'obj[(x, y)]'&lt;/code&gt; and &lt;code&gt;'&amp;lt;S&amp;gt;.loc[key_1, key_2]'&lt;/code&gt; is how you retrieve a value from a multi-indexed Series.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Pandas uses NumPy types like &lt;code&gt;'np.int64'&lt;/code&gt;. Series is converted to &lt;code&gt;'float64'&lt;/code&gt; if np.nan is assigned to any item. Use &lt;code&gt;'&amp;lt;S&amp;gt;.astype(&amp;lt;str/type&amp;gt;)'&lt;/code&gt; to get converted Series.&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Series — Aggregate, Transform, Map:&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;el&amp;gt; = &amp;lt;S&amp;gt;.sum/max/mean/std/idxmax/count()     # Or: &amp;lt;S&amp;gt;.agg(lambda &amp;lt;S&amp;gt;: &amp;lt;el&amp;gt;)
&amp;lt;S&amp;gt;  = &amp;lt;S&amp;gt;.rank/diff/cumsum/ffill/interpol…()  # Or: &amp;lt;S&amp;gt;.agg/transform(lambda &amp;lt;S&amp;gt;: &amp;lt;S&amp;gt;)
&amp;lt;S&amp;gt;  = &amp;lt;S&amp;gt;.isna/fillna/isin([&amp;lt;el/coll&amp;gt;])       # Or: &amp;lt;S&amp;gt;.agg/transform/map(lambda &amp;lt;el&amp;gt;: &amp;lt;el&amp;gt;)
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-text"&gt;+--------------+-------------+-------------+---------------+
|              |    'sum'    |   ['sum']   | {'s': 'sum'}  |
+--------------+-------------+-------------+---------------+
| s.apply(…)   |      3      |    sum  3   |     s  3      |
| s.agg(…)     |             |             |               |
+--------------+-------------+-------------+---------------+
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-text"&gt;+--------------+-------------+-------------+---------------+
|              |    'rank'   |   ['rank']  | {'r': 'rank'} |
+--------------+-------------+-------------+---------------+
| s.apply(…)   |             |      rank   |               |
| s.agg(…)     |    x  1.0   |   x   1.0   |   r  x  1.0   |
|              |    y  2.0   |   y   2.0   |      y  2.0   |
+--------------+-------------+-------------+---------------+
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;DataFrame&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Table with labeled rows and columns.&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;gt;&amp;gt;&amp;gt; df = pd.DataFrame([[1, 2], [3, 4]], index=['a', 'b'], columns=['x', 'y']); df
   x  y
a  1  2
b  3  4
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;DF&amp;gt;   = pd.DataFrame(&amp;lt;list_of_rows&amp;gt;)          # Rows can be either lists, dicts or series.
&amp;lt;DF&amp;gt;   = pd.DataFrame(&amp;lt;dict_of_columns&amp;gt;)       # Columns can be either lists, dicts or series.
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;el&amp;gt;   = &amp;lt;DF&amp;gt;.loc[row_key, col_key]            # Or: &amp;lt;DF&amp;gt;.iloc[row_i, col_i]
&amp;lt;S/DF&amp;gt; = &amp;lt;DF&amp;gt;.loc[row_key/s]                   # Or: &amp;lt;DF&amp;gt;.iloc[row_i/s]
&amp;lt;S/DF&amp;gt; = &amp;lt;DF&amp;gt;.loc[:, col_key/s]                # Or: &amp;lt;DF&amp;gt;.iloc[:, col_i/s]
&amp;lt;DF&amp;gt;   = &amp;lt;DF&amp;gt;.loc[row_bools, col_bools]        # Or: &amp;lt;DF&amp;gt;.iloc[row_bools, col_bools]
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;S/DF&amp;gt; = &amp;lt;DF&amp;gt;[col_key/s]                       # Or: &amp;lt;DF&amp;gt;.&amp;lt;col_key&amp;gt;
&amp;lt;DF&amp;gt;   = &amp;lt;DF&amp;gt;[&amp;lt;S_of_bools&amp;gt;]                    # Filters rows. For example `df[df.x &amp;gt; 1]`.
&amp;lt;DF&amp;gt;   = &amp;lt;DF&amp;gt;[&amp;lt;DF_of_bools&amp;gt;]                   # Assigns NaN to items that are False in bools.
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;DF&amp;gt;   = &amp;lt;DF&amp;gt; &amp;gt; &amp;lt;el/S/DF&amp;gt;                      # Returns DF of bools. Treats series as a row.
&amp;lt;DF&amp;gt;   = &amp;lt;DF&amp;gt; + &amp;lt;el/S/DF&amp;gt;                      # Items with non-matching keys get value NaN.
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;DF&amp;gt;   = &amp;lt;DF&amp;gt;.set_index(col_key)               # Replaces row keys with column's values.
&amp;lt;DF&amp;gt;   = &amp;lt;DF&amp;gt;.reset_index(drop=False)          # Drops or moves row keys to column named index.
&amp;lt;DF&amp;gt;   = &amp;lt;DF&amp;gt;.sort_index(ascending=True)       # Sorts rows by row keys. Use `axis=1` for cols.
&amp;lt;DF&amp;gt;   = &amp;lt;DF&amp;gt;.sort_values(col_key/s)           # Sorts rows by passed column/s. Also `axis=1`.
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;DF&amp;gt;   = &amp;lt;DF&amp;gt;.head/tail/sample(&amp;lt;int&amp;gt;)          # Returns first, last, or random n rows.
&amp;lt;DF&amp;gt;   = &amp;lt;DF&amp;gt;.describe()                       # Describes columns. Also info(), corr(), shape.
&amp;lt;DF&amp;gt;   = &amp;lt;DF&amp;gt;.query('&amp;lt;query&amp;gt;')                 # Filters rows. For example `df.query('x &amp;gt; 1')`.
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;DF&amp;gt;.plot.line/area/bar/scatter(x=col_key, …)  # `y=col_key/s`. Also hist/box(column/by=col_k).
plt.show()                                     # Displays the plot. Also plt.savefig(&amp;lt;path&amp;gt;).
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;DataFrame — Merge, Join, Concat:&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;gt;&amp;gt;&amp;gt; df_2 = pd.DataFrame([[4, 5], [6, 7]], index=['b', 'c'], columns=['y', 'z']); df_2
   y  z
b  4  5
c  6  7
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-text"&gt;+-----------------------+---------------+------------+------------+---------------------------+
|                       |    'outer'    |   'inner'  |   'left'   |       Description         |
+-----------------------+---------------+------------+------------+---------------------------+
| df.merge(df_2,        |    x   y   z  | x   y   z  | x   y   z  | Merges on column if 'on'  |
|          on='y',      | 0  1   2   .  | 3   4   5  | 1   2   .  | or 'left_on/right_on' are |
|          how=…)       | 1  3   4   5  |            | 3   4   5  | set, else on shared cols. |
|                       | 2  .   6   7  |            |            | Uses 'inner' by default.  |
+-----------------------+---------------+------------+------------+---------------------------+
| df.join(df_2,         |    x yl yr  z |            | x yl yr  z | Merges on row keys.       |
|         lsuffix='l',  | a  1  2  .  . | x yl yr  z | 1  2  .  . | Uses 'left' by default.   |
|         rsuffix='r',  | b  3  4  4  5 | 3  4  4  5 | 3  4  4  5 | If Series is passed, it   |
|         how=…)        | c  .  .  6  7 |            |            | is treated as a column.   |
+-----------------------+---------------+------------+------------+---------------------------+
| pd.concat([df, df_2], |    x   y   z  |     y      |            | Adds rows at the bottom.  |
|           axis=0,     | a  1   2   .  |     2      |            | Uses 'outer' by default.  |
|           join=…)     | b  3   4   .  |     4      |            | A Series is treated as a  |
|                       | b  .   4   5  |     4      |            | column. To add a row use  |
|                       | c  .   6   7  |     6      |            | pd.concat([df, DF([s])]). |
+-----------------------+---------------+------------+------------+---------------------------+
| pd.concat([df, df_2], |    x  y  y  z |            |            | Adds columns at the       |
|           axis=1,     | a  1  2  .  . | x  y  y  z |            | right end. Uses 'outer'   |
|           join=…)     | b  3  4  4  5 | 3  4  4  5 |            | by default. A Series is   |
|                       | c  .  .  6  7 |            |            | treated as a column.      |
+-----------------------+---------------+------------+------------+---------------------------+
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;DataFrame — Aggregate, Transform, Map:&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;S&amp;gt;  = &amp;lt;DF&amp;gt;.sum/max/mean/std/idxmax/count()    # Or: &amp;lt;DF&amp;gt;.apply/agg(lambda &amp;lt;S&amp;gt;: &amp;lt;el&amp;gt;)
&amp;lt;DF&amp;gt; = &amp;lt;DF&amp;gt;.rank/diff/cumsum/ffill/interpo…()  # Or: &amp;lt;DF&amp;gt;.apply/agg/transform(lambda &amp;lt;S&amp;gt;: &amp;lt;S&amp;gt;)
&amp;lt;DF&amp;gt; = &amp;lt;DF&amp;gt;.isna/fillna/isin([&amp;lt;el/coll&amp;gt;])      # Or: &amp;lt;DF&amp;gt;.applymap(lambda &amp;lt;el&amp;gt;: &amp;lt;el&amp;gt;)
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-text"&gt;+-----------------+---------------+---------------+---------------+
|                 |     'sum'     |    ['sum']    | {'x': 'sum'}  |
+-----------------+---------------+---------------+---------------+
| df.apply(…)     |      x  4     |        x  y   |     x  4      |
| df.agg(…)       |      y  6     |   sum  4  6   |               |
+-----------------+---------------+---------------+---------------+
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-text"&gt;+-----------------+---------------+---------------+---------------+
|                 |     'rank'    |    ['rank']   | {'x': 'rank'} |
+-----------------+---------------+---------------+---------------+
| df.apply(…)     |               |       x    y  |               |
| df.agg(…)       |       x    y  |    rank rank  |         x     |
| df.transform(…) |  a  1.0  1.0  |  a  1.0  1.0  |    a  1.0     |
|                 |  b  2.0  2.0  |  b  2.0  2.0  |    b  2.0     |
+-----------------+---------------+---------------+---------------+
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Listed methods process the columns unless they receive &lt;code&gt;'axis=1'&lt;/code&gt;. Exceptions to this rule are &lt;code&gt;'&amp;lt;DF&amp;gt;.dropna()'&lt;/code&gt;, &lt;code&gt;'&amp;lt;DF&amp;gt;.drop(row_key/s)'&lt;/code&gt; and &lt;code&gt;'&amp;lt;DF&amp;gt;.rename(&amp;lt;dict/func&amp;gt;)'&lt;/code&gt;.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Fifth result's columns are indexed with a multi-index. This means we need a tuple of column keys to specify a column: &lt;code&gt;'&amp;lt;DF&amp;gt;.loc[row_key, (col_key_1, col_key_2)]'&lt;/code&gt;.&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Multi-Index&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;DF&amp;gt; = &amp;lt;DF&amp;gt;.loc[row_key_1]                     # Or: &amp;lt;DF&amp;gt;.xs(row_key_1)
&amp;lt;DF&amp;gt; = &amp;lt;DF&amp;gt;.loc[:, (slice(None), col_key_2)]   # Or: &amp;lt;DF&amp;gt;.xs(col_key_2, axis=1, level=1)
&amp;lt;DF&amp;gt; = &amp;lt;DF&amp;gt;.set_index(col_keys)                # Creates index from cols. Also `append=False`.
&amp;lt;DF&amp;gt; = &amp;lt;DF&amp;gt;.pivot_table(index=col_key/s)       # `columns=key/s, values=key/s, aggfunc='mean'`.
&amp;lt;S&amp;gt;  = &amp;lt;DF&amp;gt;.stack/unstack(level=-1)            # Combines col keys with row keys or vice versa.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;File Formats&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;S/DF&amp;gt; = pd.read_json/pickle(&amp;lt;path/url/file&amp;gt;)  # Also io.StringIO(&amp;lt;str&amp;gt;), io.BytesIO(&amp;lt;bytes&amp;gt;).
&amp;lt;DF&amp;gt;   = pd.read_csv/excel(&amp;lt;path/url/file&amp;gt;)    # Also `header/index_col/dtype/usecols/…=&amp;lt;obj&amp;gt;`.
&amp;lt;list&amp;gt; = pd.read_html(&amp;lt;path/url/file&amp;gt;)         # Raises ImportError if webpage has zero tables.
&amp;lt;S/DF&amp;gt; = pd.read_parquet/feather/hdf(&amp;lt;path…&amp;gt;)  # Function read_hdf() accepts `key=&amp;lt;s/df_name&amp;gt;`.
&amp;lt;DF&amp;gt;   = pd.read_sql('&amp;lt;table/query&amp;gt;', &amp;lt;conn&amp;gt;)  # Pass SQLite3/Alchemy connection. See #SQLite.
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;DF&amp;gt;.to_json/csv/html/latex/parquet(&amp;lt;path&amp;gt;)    # Returns a string/bytes if path is omitted.
&amp;lt;DF&amp;gt;.to_pickle/excel/feather/hdf(&amp;lt;path&amp;gt;)       # Method to_hdf() requires `key=&amp;lt;s/df_name&amp;gt;`.
&amp;lt;DF&amp;gt;.to_sql('&amp;lt;table_name&amp;gt;', &amp;lt;connection&amp;gt;)      # Also `if_exists='fail/replace/append'`.
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;'$ pip3 install "pandas[excel]" odfpy lxml pyarrow'&lt;/code&gt; installs dependencies.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Csv functions use the same dialect as standard library's csv module (e.g. &lt;code&gt;'sep=","'&lt;/code&gt;).&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Read_csv() only parses dates of columns that are listed in 'parse_dates'. It automatically tries to detect the format, but it can be helped with 'date_format' or 'dayfirst' arguments.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;We get a dataframe with DatetimeIndex if 'parse_dates' argument includes 'index_col'. Its &lt;code&gt;'resample("y/m/d/h")'&lt;/code&gt; method returns Resampler object that is similar to GroupBy.&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;GroupBy&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Object that groups together rows of a dataframe based on the value of the passed column.&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;GB&amp;gt; = &amp;lt;DF&amp;gt;.groupby(col_key/s)                 # Splits DF into groups based on passed column.
&amp;lt;DF&amp;gt; = &amp;lt;GB&amp;gt;.apply/filter(&amp;lt;func&amp;gt;)               # Filter drops a group if func returns False.
&amp;lt;DF&amp;gt; = &amp;lt;GB&amp;gt;.get_group(&amp;lt;el&amp;gt;)                    # Selects a group by grouping column's value.
&amp;lt;S&amp;gt;  = &amp;lt;GB&amp;gt;.size()                             # S of group sizes. Same keys as get_group().
&amp;lt;GB&amp;gt; = &amp;lt;GB&amp;gt;[col_key]                           # Single column GB. All operations return S.
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;DF&amp;gt; = &amp;lt;GB&amp;gt;.sum/max/mean/std/idxmax/count()    # Or: &amp;lt;GB&amp;gt;.agg(lambda &amp;lt;S&amp;gt;: &amp;lt;el&amp;gt;)
&amp;lt;DF&amp;gt; = &amp;lt;GB&amp;gt;.rank/diff/cumsum/ffill()           # Or: &amp;lt;GB&amp;gt;.transform(lambda &amp;lt;S&amp;gt;: &amp;lt;S&amp;gt;)
&amp;lt;DF&amp;gt; = &amp;lt;GB&amp;gt;.fillna(&amp;lt;el&amp;gt;)                       # Or: &amp;lt;GB&amp;gt;.transform(lambda &amp;lt;S&amp;gt;: &amp;lt;S&amp;gt;)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Divides rows into groups and sums their columns. Result has a named index that creates column &lt;code&gt;'z'&lt;/code&gt; on reset_index():&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;gt;&amp;gt;&amp;gt; df = pd.DataFrame([[1, 2, 3], [4, 5, 6], [7, 8, 6]], list('abc'), list('xyz'))
&amp;gt;&amp;gt;&amp;gt; gb = df.groupby('z'); gb.apply(print)
   x  y  z
a  1  2  3
   x  y  z
b  4  5  6
c  7  8  6
&amp;gt;&amp;gt;&amp;gt; gb.sum()
    x   y
z
3   1   2
6  11  13
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Rolling&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Object for rolling window calculations.&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;RS/RDF/RGB&amp;gt; = &amp;lt;S/DF/GB&amp;gt;.rolling(win_size)     # Also: `min_periods=None, center=False`.
&amp;lt;RS/RDF/RGB&amp;gt; = &amp;lt;RDF/RGB&amp;gt;[col_key/s]            # Or: &amp;lt;RDF/RGB&amp;gt;.&amp;lt;col_key&amp;gt;
&amp;lt;S/DF&amp;gt;       = &amp;lt;R&amp;gt;.mean/sum/max()              # Or: &amp;lt;R&amp;gt;.apply/agg(&amp;lt;agg_func/str&amp;gt;)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Plotly&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# $ pip3 install plotly kaleido pandas
import plotly.express as px, pandas as pd
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;Fig&amp;gt; = px.line(&amp;lt;DF&amp;gt; [, y=col_key/s [, x=col_key]])   # Also px.line(y=&amp;lt;list&amp;gt; [, x=&amp;lt;list&amp;gt;]).
&amp;lt;Fig&amp;gt;.update_layout(paper_bgcolor='#rrggbb')          # Also `margin=dict(t=0, r=0, b=0, l=0)`.
&amp;lt;Fig&amp;gt;.write_html/json/image('&amp;lt;path&amp;gt;')                 # Use &amp;lt;Fig&amp;gt;.show() to display the plot.
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;&amp;lt;Fig&amp;gt; = px.area/bar/box(&amp;lt;DF&amp;gt;, x=col_key, y=col_keys)  # Also `color=col_key`. All are optional.
&amp;lt;Fig&amp;gt; = px.scatter(&amp;lt;DF&amp;gt;, x=col_key, y=col_keys)       # Also `color/size/symbol=col_key`. Same.
&amp;lt;Fig&amp;gt; = px.scatter_3d(&amp;lt;DF&amp;gt;, x=col_key, y=col_key, …)  # `z=col_key`. Also color, size, symbol.
&amp;lt;Fig&amp;gt; = px.histogram(&amp;lt;DF&amp;gt;, x=col_keys, y=col_key)     # Also color, nbins. All are optional.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Displays a line chart of total COVID-19 deaths per million grouped by continent:&lt;/h4&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/gto76/python-cheatsheet/main/web/covid_deaths.png" alt="Covid Deaths" /&gt;&lt;/p&gt; 
&lt;div id="2a950764-39fc-416d-97fe-0a6226a3095f" class="plotly-graph-div" style="height:312px; width:914px;"&gt;&lt;/div&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;covid = pd.read_csv('https://raw.githubusercontent.com/owid/covid-19-data/8dde8ca49b'
                    '6e648c17dd420b2726ca0779402651/public/data/owid-covid-data.csv',
                    usecols=['iso_code', 'date', 'population', 'total_deaths'])
continents = pd.read_csv('https://gto76.github.io/python-cheatsheet/web/continents.csv',
                         usecols=['Three_Letter_Country_Code', 'Continent_Name'])
df = pd.merge(covid, continents, left_on='iso_code', right_on='Three_Letter_Country_Code')
df = df.groupby(['Continent_Name', 'date']).sum().reset_index()
df['Total Deaths per Million'] = df.total_deaths * 1e6 / df.population
df = df[df.date &amp;gt; '2020-03-14']
df = df.rename({'date': 'Date', 'Continent_Name': 'Continent'}, axis='columns')
px.line(df, x='Date', y='Total Deaths per Million', color='Continent')
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Displays a multi-axis line chart of total COVID-19 cases and changes in prices of Bitcoin, Dow Jones and gold:&lt;/h4&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/gto76/python-cheatsheet/main/web/covid_cases.png" alt="Covid Cases" /&gt;&lt;/p&gt; 
&lt;div id="e23ccacc-a456-478b-b467-7282a2165921" class="plotly-graph-div" style="height:285px; width:935px;"&gt;&lt;/div&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# $ pip3 install pandas lxml selenium plotly
import pandas as pd, selenium.webdriver, io, plotly.graph_objects as go

def main():
    covid, (bitcoin, gold, dow) = get_covid_cases(), get_tickers()
    df = wrangle_data(covid, bitcoin, gold, dow)
    display_data(df)

def get_covid_cases():
    url = 'https://catalog.ourworldindata.org/garden/covid/latest/compact/compact.csv'
    df = pd.read_csv(url, parse_dates=['date'])
    df = df[df.country == 'World']
    s = df.set_index('date').total_cases
    return s.rename('Total Cases')

def get_tickers():
    with selenium.webdriver.Chrome() as driver:
        driver.implicitly_wait(10)
        symbols = {'Bitcoin': 'BTC-USD', 'Gold': 'GC=F', 'Dow Jones': '%5EDJI'}
        return [get_ticker(driver, name, symbol) for name, symbol in symbols.items()]

def get_ticker(driver, name, symbol):
    url = f'https://finance.yahoo.com/quote/{symbol}/history/'
    driver.get(url + '?period1=1579651200&amp;amp;period2=9999999999')
    if buttons := driver.find_elements('xpath', '//button[@name="reject"]'):
        buttons[0].click()
    html = io.StringIO(driver.page_source)
    dataframes = pd.read_html(html, parse_dates=['Date'])
    s = dataframes[0].set_index('Date').Open
    return s.rename(name)

def wrangle_data(covid, bitcoin, gold, dow):
    df = pd.concat([bitcoin, gold, dow], axis=1)  # Creates table by joining columns on dates.
    df = df.sort_index().interpolate()            # Sorts rows by date and interpolates NaN-s.
    df = df.loc['2020-02-23':'2021-12-20']        # Keeps rows between specified dates.
    df = (df / df.iloc[0]) * 100                  # Calculates percentages relative to day 1.
    df = df.join(covid)                           # Adds column with covid cases.
    return df.sort_values(df.index[-1], axis=1)   # Sorts columns by last day's value.

def display_data(df):
    figure = go.Figure()
    for col_name in reversed(df.columns):
        yaxis = 'y1' if col_name == 'Total Cases' else 'y2'
        trace = go.Scatter(x=df.index, y=df[col_name], yaxis=yaxis, name=col_name)
        figure.add_trace(trace)
    figure.update_layout(
        width=944,
        height=423,
        yaxis1=dict(title='Total Cases', rangemode='tozero'),
        yaxis2=dict(title='%', rangemode='tozero', overlaying='y', side='right'),
        colorway=['#EF553B', '#636EFA', '#00CC96', '#FFA152'],
        legend=dict(x=1.08)
    )
    figure.show()

if __name__ == '__main__':
    main()
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Appendix&lt;/h2&gt; 
&lt;h3&gt;Cython&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Library that compiles Python-like code into C.&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# $ pip3 install cython
import pyximport; pyximport.install()                # Module that runs Cython scripts.
import &amp;lt;cython_script&amp;gt;                               # Script must have '.pyx' extension.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;All &lt;code&gt;'cdef'&lt;/code&gt; definitions are optional, but they contribute to the speed-up:&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;cdef &amp;lt;type&amp;gt; &amp;lt;var_name&amp;gt; [= &amp;lt;obj/var&amp;gt;]                 # Either Python or C type variable.
cdef &amp;lt;ctype&amp;gt; *&amp;lt;pointer_name&amp;gt; [= &amp;amp;&amp;lt;var&amp;gt;]              # Use &amp;lt;pointer&amp;gt;[0] to get the value.
cdef &amp;lt;ctype&amp;gt;[size] &amp;lt;array_name&amp;gt; [= &amp;lt;coll/array&amp;gt;]     # Also `&amp;lt;ctype&amp;gt;[:] &amp;lt;mview&amp;gt; = &amp;lt;array&amp;gt;`.
cdef &amp;lt;ctype&amp;gt; *&amp;lt;array_name&amp;gt; [= &amp;lt;coll/array/pointer&amp;gt;]  # E.g. `&amp;lt;&amp;lt;ctype&amp;gt; *&amp;gt; malloc(n_bytes)`.
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;cdef &amp;lt;type&amp;gt; &amp;lt;func_name&amp;gt;(&amp;lt;type&amp;gt; [*]&amp;lt;arg_name&amp;gt;): ...   # Omitted types default to `object`.
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;cdef class &amp;lt;class_name&amp;gt;:                             # Also `cdef struct &amp;lt;struct_name&amp;gt;:`.
    cdef public &amp;lt;type&amp;gt; [*]&amp;lt;attr_name&amp;gt;                # Also `... &amp;lt;ctype&amp;gt; [*]&amp;lt;field_name&amp;gt;`.
    def __init__(self, &amp;lt;type&amp;gt; &amp;lt;arg_name&amp;gt;):           # Also `cdef __dealloc__(self):`.
        self.&amp;lt;attr_name&amp;gt; = &amp;lt;arg_name&amp;gt;                # Also `... free(&amp;lt;array/pointer&amp;gt;)`.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Virtual Environments&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;System for installing libraries directly into project's directory.&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-perl"&gt;$ python3 -m venv NAME      # Creates virtual environment in current directory.
$ source NAME/bin/activate  # Activates it. On Windows run `NAME\Scripts\activate`.
$ pip3 install LIBRARY      # Installs the library into active environment.
$ python3 FILE              # Runs the script in active environment. Also `./FILE`.
$ deactivate                # Deactivates the active virtual environment.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Basic Script Template&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Run the script with &lt;code&gt;'$ python3 FILE'&lt;/code&gt; or &lt;code&gt;'$ chmod u+x FILE; ./FILE'&lt;/code&gt;. To automatically start the debugger when uncaught exception occurs run &lt;code&gt;'$ python3 -m pdb -cc FILE'&lt;/code&gt;.&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;#!/usr/bin/env python3
#
# Usage: .py
#

from sys import argv, exit
from collections import defaultdict, namedtuple
from dataclasses import make_dataclass
from enum import Enum
import functools as ft, itertools as it, operator as op, re


def main():
    pass


###
##  UTIL
#

def read_file(filename):
    with open(filename, encoding='utf-8') as file:
        return file.readlines()


if __name__ == '__main__':
    main()
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Index&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Ctrl+F / ⌘F is usually sufficient.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Searching &lt;code&gt;'#&amp;lt;title&amp;gt;'&lt;/code&gt; on the &lt;a href="https://gto76.github.io/python-cheatsheet/"&gt;webpage&lt;/a&gt; will limit the search to the titles.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Click on the title's &lt;code&gt;'🔗'&lt;/code&gt; to get a link to its section.&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>1Panel-dev/MaxKB</title>
      <link>https://github.com/1Panel-dev/MaxKB</link>
      <description>&lt;p&gt;🔥 MaxKB is an open-source platform for building enterprise-grade agents. MaxKB 是强大易用的开源企业级智能体平台。&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt;&lt;img src="https://github.com/1Panel-dev/maxkb/assets/52996290/c0694996-0eed-40d8-b369-322bf2a380bf" alt="MaxKB" width="300" /&gt;&lt;/p&gt; 
&lt;h3 align="center"&gt;Open-source platform for building enterprise-grade agents&lt;/h3&gt; 
&lt;h3 align="center"&gt;强大易用的企业级智能体平台&lt;/h3&gt; 
&lt;p align="center"&gt;&lt;a href="https://trendshift.io/repositories/9113" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/9113" alt="1Panel-dev%2FMaxKB | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://www.gnu.org/licenses/gpl-3.0.html#license-text"&gt;&lt;img src="https://img.shields.io/github/license/1Panel-dev/maxkb?color=%231890FF" alt="License: GPL v3" /&gt;&lt;/a&gt; &lt;a href="https://github.com/1Panel-dev/maxkb/releases/latest"&gt;&lt;img src="https://img.shields.io/github/v/release/1Panel-dev/maxkb" alt="Latest release" /&gt;&lt;/a&gt; &lt;a href="https://github.com/1Panel-dev/maxkb"&gt;&lt;img src="https://img.shields.io/github/stars/1Panel-dev/maxkb?color=%231890FF&amp;amp;style=flat-square" alt="Stars" /&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/r/1panel/maxkb"&gt;&lt;img src="https://img.shields.io/docker/pulls/1panel/maxkb?label=downloads" alt="Download" /&gt;&lt;/a&gt;&lt;br /&gt; [&lt;a href="https://raw.githubusercontent.com/1Panel-dev/MaxKB/v2/README_CN.md"&gt;中文(简体)&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/1Panel-dev/MaxKB/v2/README.md"&gt;English&lt;/a&gt;] &lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;MaxKB = Max Knowledge Brain, it is an open-source platform for building enterprise-grade agents. MaxKB integrates Retrieval-Augmented Generation (RAG) pipelines, supports robust workflows, and provides advanced MCP tool-use capabilities. MaxKB is widely applied in scenarios such as intelligent customer service, corporate internal knowledge bases, academic research, and education.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;RAG Pipeline&lt;/strong&gt;: Supports direct uploading of documents / automatic crawling of online documents, with features for automatic text splitting, vectorization. This effectively reduces hallucinations in large models, providing a superior smart Q&amp;amp;A interaction experience.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Agentic Workflow&lt;/strong&gt;: Equipped with a powerful workflow engine, function library and MCP tool-use, enabling the orchestration of AI processes to meet the needs of complex business scenarios.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Seamless Integration&lt;/strong&gt;: Facilitates zero-coding rapid integration into third-party business systems, quickly equipping existing systems with intelligent Q&amp;amp;A capabilities to enhance user satisfaction.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Model-Agnostic&lt;/strong&gt;: Supports various large models, including private models (such as DeepSeek, Llama, Qwen, etc.) and public models (like OpenAI, Claude, Gemini, etc.).&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Multi Modal&lt;/strong&gt;: Native support for input and output text, image, audio and video.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Quick start&lt;/h2&gt; 
&lt;p&gt;Execute the script below to start a MaxKB container using Docker:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run -d --name=maxkb --restart=always -p 8080:8080 -v ~/.maxkb:/opt/maxkb 1panel/maxkb
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Access MaxKB web interface at &lt;code&gt;http://your_server_ip:8080&lt;/code&gt; with default admin credentials:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;username: admin&lt;/li&gt; 
 &lt;li&gt;password: MaxKB@123..&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;中国用户如遇到 Docker 镜像 Pull 失败问题，请参照该 &lt;a href="https://maxkb.cn/docs/v2/installation/offline_installtion/"&gt;离线安装文档&lt;/a&gt; 进行安装。&lt;/p&gt; 
&lt;h2&gt;Screenshots&lt;/h2&gt; 
&lt;table style="border-collapse: collapse; border: 1px solid black;"&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td style="padding: 5px;background-color:#fff;"&gt;&lt;img src="https://github.com/user-attachments/assets/eb285512-a66a-4752-8941-c65ed1592238" alt="MaxKB Demo1" /&gt;&lt;/td&gt; 
   &lt;td style="padding: 5px;background-color:#fff;"&gt;&lt;img src="https://github.com/user-attachments/assets/f732f1f5-472c-4fd2-93c1-a277eda83d04" alt="MaxKB Demo2" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td style="padding: 5px;background-color:#fff;"&gt;&lt;img src="https://github.com/user-attachments/assets/c927474a-9a23-4830-822f-5db26025c9b2" alt="MaxKB Demo3" /&gt;&lt;/td&gt; 
   &lt;td style="padding: 5px;background-color:#fff;"&gt;&lt;img src="https://github.com/user-attachments/assets/e6268996-a46d-4e58-9f30-31139df78ad2" alt="MaxKB Demo4" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h2&gt;Technical stack&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Frontend：&lt;a href="https://vuejs.org/"&gt;Vue.js&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Backend：&lt;a href="https://www.djangoproject.com/"&gt;Python / Django&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;LLM Framework：&lt;a href="https://www.langchain.com/"&gt;LangChain&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Database：&lt;a href="https://www.postgresql.org/"&gt;PostgreSQL + pgvector&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Star History&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://star-history.com/#1Panel-dev/MaxKB&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=1Panel-dev/MaxKB&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Licensed under The GNU General Public License version 3 (GPLv3) (the "License"); you may not use this file except in compliance with the License. You may obtain a copy of the License at&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.gnu.org/licenses/gpl-3.0.html"&gt;https://www.gnu.org/licenses/gpl-3.0.html&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Azure/azure-sdk-for-python</title>
      <link>https://github.com/Azure/azure-sdk-for-python</link>
      <description>&lt;p&gt;This repository is for active development of the Azure SDK for Python. For consumers of the SDK we recommend visiting our public developer docs at https://learn.microsoft.com/python/azure/ or our versioned developer docs at https://azure.github.io/azure-sdk-for-python.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Azure SDK for Python&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://azure.github.io/azure-sdk/releases/latest/python.html"&gt;&lt;img src="https://img.shields.io/badge/packages-latest-blue.svg?sanitize=true" alt="Packages" /&gt;&lt;/a&gt; &lt;a href="https://azuresdkartifacts.blob.core.windows.net/azure-sdk-for-python/dependencies/dependencies.html"&gt;&lt;img src="https://img.shields.io/badge/dependency-report-blue.svg?sanitize=true" alt="Dependencies" /&gt;&lt;/a&gt; &lt;a href="https://azuresdkartifacts.blob.core.windows.net/azure-sdk-for-python/dependencies/dependencyGraph/index.html"&gt;&lt;img src="https://img.shields.io/badge/dependency-graph-blue.svg?sanitize=true" alt="DepGraph" /&gt;&lt;/a&gt; &lt;a href="https://pypi.python.org/pypi/azure/"&gt;&lt;img src="https://img.shields.io/pypi/pyversions/azure-core.svg?maxAge=2592000" alt="Python" /&gt;&lt;/a&gt; &lt;a href="https://dev.azure.com/azure-sdk/public/_build/latest?definitionId=458&amp;amp;branchName=main"&gt;&lt;img src="https://dev.azure.com/azure-sdk/public/_apis/build/status/python/python%20-%20core%20-%20ci?branchName=main" alt="Build Status" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;This repository is for the active development of the Azure SDK for Python. For consumers of the SDK we recommend visiting our &lt;a href="https://docs.microsoft.com/python/azure/"&gt;public developer docs&lt;/a&gt; or our versioned &lt;a href="https://azure.github.io/azure-sdk-for-python"&gt;developer docs&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Getting started&lt;/h2&gt; 
&lt;p&gt;For your convenience, each service has a separate set of libraries that you can choose to use instead of one, large Azure package. To get started with a specific library, see the &lt;code&gt;README.md&lt;/code&gt; (or &lt;code&gt;README.rst&lt;/code&gt;) file located in the library's project folder.&lt;/p&gt; 
&lt;p&gt;You can find service libraries in the &lt;code&gt;/sdk&lt;/code&gt; directory.&lt;/p&gt; 
&lt;h3&gt;Prerequisites&lt;/h3&gt; 
&lt;p&gt;The client libraries are supported on Python 3.9 or later. For more details, please read our page on &lt;a href="https://github.com/Azure/azure-sdk-for-python/wiki/Azure-SDKs-Python-version-support-policy"&gt;Azure SDK for Python version support policy&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Packages available&lt;/h2&gt; 
&lt;p&gt;Each service might have a number of libraries available from each of the following categories:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Azure/azure-sdk-for-python/main/#client-new-releases"&gt;Client - New Releases&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Azure/azure-sdk-for-python/main/#client-previous-versions"&gt;Client - Previous Versions&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Azure/azure-sdk-for-python/main/#management-new-releases"&gt;Management - New Releases&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Azure/azure-sdk-for-python/main/#management-previous-versions"&gt;Management - Previous Versions&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Client: New Releases&lt;/h3&gt; 
&lt;p&gt;New wave of packages that we are announcing as &lt;strong&gt;GA&lt;/strong&gt; and several that are currently releasing in &lt;strong&gt;preview&lt;/strong&gt;. These libraries allow you to use and consume existing resources and interact with them, for example: upload a blob. These libraries share several core functionalities such as: retries, logging, transport protocols, authentication protocols, etc. that can be found in the &lt;a href="https://github.com/Azure/azure-sdk-for-python/raw/main/sdk/core/azure-core"&gt;azure-core&lt;/a&gt; library. You can learn more about these libraries by reading guidelines that they follow &lt;a href="https://azure.github.io/azure-sdk/python/guidelines/index.html"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;You can find the &lt;a href="https://azure.github.io/azure-sdk/releases/latest/index.html#python"&gt;most up to date list of all of the new packages on our page&lt;/a&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;NOTE: If you need to ensure your code is ready for production use one of the stable, non-preview libraries.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Client: Previous Versions&lt;/h3&gt; 
&lt;p&gt;Last stable versions of packages that have been provided for usage with Azure and are production-ready. These libraries provide you with similar functionalities to the Preview ones as they allow you to use and consume existing resources and interact with them, for example: upload a blob. They might not implement the &lt;a href="https://azure.github.io/azure-sdk/python/guidelines/index.html"&gt;guidelines&lt;/a&gt; or have the same feature set as the November releases. They do however offer wider coverage of services.&lt;/p&gt; 
&lt;h3&gt;Management: New Releases&lt;/h3&gt; 
&lt;p&gt;A new set of management libraries that follow the &lt;a href="https://azure.github.io/azure-sdk/python/guidelines/"&gt;Azure SDK Design Guidelines for Python&lt;/a&gt; are now available. These new libraries provide a number of core capabilities that are shared amongst all Azure SDKs, including the intuitive Azure Identity library, an HTTP Pipeline with custom policies, error-handling, distributed tracing, and much more. Documentation and code samples for these new libraries can be found &lt;a href="https://aka.ms/azsdk/python/mgmt"&gt;here&lt;/a&gt;. In addition, a migration guide that shows how to transition from older versions of libraries is located &lt;a href="https://github.com/Azure/azure-sdk-for-python/raw/main/doc/sphinx/mgmt_quickstart.rst#migration-guide"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;You can find the &lt;a href="https://azure.github.io/azure-sdk/releases/latest/mgmt/python.html"&gt;most up to date list of all of the new packages on our page&lt;/a&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;NOTE: If you need to ensure your code is ready for production use one of the stable, non-preview libraries. Also, if you are experiencing authentication issues with the management libraries after upgrading certain packages, it's possible that you upgraded to the new versions of SDK without changing the authentication code, please refer to the migration guide mentioned above for proper instructions.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Management: Previous Versions&lt;/h3&gt; 
&lt;p&gt;For a complete list of management libraries that enable you to provision and manage Azure resources, please &lt;a href="https://azure.github.io/azure-sdk/releases/latest/all/python.html"&gt;check here&lt;/a&gt;. They might not have the same feature set as the new releases but they do offer wider coverage of services. Management libraries can be identified by namespaces that start with &lt;code&gt;azure-mgmt-&lt;/code&gt;, e.g. &lt;code&gt;azure-mgmt-compute&lt;/code&gt;&lt;/p&gt; 
&lt;h2&gt;Need help?&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;For detailed documentation visit our &lt;a href="https://aka.ms/python-docs"&gt;Azure SDK for Python documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;File an issue via &lt;a href="https://github.com/Azure/azure-sdk-for-python/issues"&gt;GitHub Issues&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Check &lt;a href="https://stackoverflow.com/questions/tagged/azure+python"&gt;previous questions&lt;/a&gt; or ask new ones on StackOverflow using &lt;code&gt;azure&lt;/code&gt; and &lt;code&gt;python&lt;/code&gt; tags.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Data Collection&lt;/h2&gt; 
&lt;p&gt;The software may collect information about you and your use of the software and send it to Microsoft. Microsoft may use this information to provide services and improve our products and services. You may turn off the telemetry as described below. You can learn more about data collection and use in the help documentation and Microsoft’s &lt;a href="https://go.microsoft.com/fwlink/?LinkID=824704"&gt;privacy statement&lt;/a&gt;. For more information on the data collected by the Azure SDK, please visit the &lt;a href="https://azure.github.io/azure-sdk/general_azurecore.html#telemetry-policy"&gt;Telemetry Guidelines&lt;/a&gt; page.&lt;/p&gt; 
&lt;h3&gt;Telemetry Configuration&lt;/h3&gt; 
&lt;p&gt;Telemetry collection is on by default.&lt;/p&gt; 
&lt;p&gt;To opt out, you can disable telemetry at client construction. Define a &lt;code&gt;NoUserAgentPolicy&lt;/code&gt; class that is a subclass of &lt;code&gt;UserAgentPolicy&lt;/code&gt; with an &lt;code&gt;on_request&lt;/code&gt; method that does nothing. Then pass instance of this class as kwargs &lt;code&gt;user_agent_policy=NoUserAgentPolicy()&lt;/code&gt; during client creation. This will disable telemetry for all methods in the client. Do this for every new client.&lt;/p&gt; 
&lt;p&gt;The example below uses the &lt;code&gt;azure-storage-blob&lt;/code&gt; package. In your code, you can replace &lt;code&gt;azure-storage-blob&lt;/code&gt; with the package you are using.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import os
from azure.identity import ManagedIdentityCredential
from azure.storage.blob import BlobServiceClient
from azure.core.pipeline.policies import UserAgentPolicy


# Create your credential you want to use
mi_credential = ManagedIdentityCredential()

account_url = "https://&amp;lt;storageaccountname&amp;gt;.blob.core.windows.net"

# Set up user-agent override
class NoUserAgentPolicy(UserAgentPolicy):
    def on_request(self, request):
        pass

# Create the BlobServiceClient object
blob_service_client = BlobServiceClient(account_url, credential=mi_credential, user_agent_policy=NoUserAgentPolicy())

container_client = blob_service_client.get_container_client(container=&amp;lt;container_name&amp;gt;) 
# TODO: do something with the container client like download blob to a file
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Reporting security issues and security bugs&lt;/h3&gt; 
&lt;p&gt;Security issues and bugs should be reported privately, via email, to the Microsoft Security Response Center (MSRC) &lt;a href="mailto:secure@microsoft.com"&gt;secure@microsoft.com&lt;/a&gt;. You should receive a response within 24 hours. If for some reason you do not, please follow up via email to ensure we received your original message. Further information, including the MSRC PGP key, can be found in the &lt;a href="https://www.microsoft.com/msrc/faqs-report-an-issue"&gt;Security TechCenter&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;For details on contributing to this repository, see the &lt;a href="https://github.com/Azure/azure-sdk-for-python/raw/main/CONTRIBUTING.md"&gt;contributing guide&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;This project welcomes contributions and suggestions. Most contributions require you to agree to a Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us the rights to use your contribution. For details, visit &lt;a href="https://cla.microsoft.com"&gt;https://cla.microsoft.com&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;When you submit a pull request, a CLA-bot will automatically determine whether you need to provide a CLA and decorate the PR appropriately (e.g., label, comment). Simply follow the instructions provided by the bot. You will only need to do this once across all repositories using our CLA.&lt;/p&gt; 
&lt;p&gt;This project has adopted the &lt;a href="https://opensource.microsoft.com/codeofconduct/"&gt;Microsoft Open Source Code of Conduct&lt;/a&gt;. For more information see the &lt;a href="https://opensource.microsoft.com/codeofconduct/faq/"&gt;Code of Conduct FAQ&lt;/a&gt; or contact &lt;a href="mailto:opencode@microsoft.com"&gt;opencode@microsoft.com&lt;/a&gt; with any additional questions or comments.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>marketcalls/openalgo</title>
      <link>https://github.com/marketcalls/openalgo</link>
      <description>&lt;p&gt;Open Source Algo Trading Platform for Everyone&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;OpenAlgo - Take Control of Your Algo Platform&lt;/h1&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://pepy.tech/projects/openalgo"&gt;&lt;img src="https://static.pepy.tech/badge/openalgo" alt="PyPI Downloads" /&gt;&lt;/a&gt; &lt;a href="https://pepy.tech/projects/openalgo"&gt;&lt;img src="https://static.pepy.tech/badge/openalgo/month" alt="PyPI Downloads" /&gt;&lt;/a&gt; &lt;a href="https://twitter.com/openalgoHQ"&gt;&lt;img src="https://img.shields.io/twitter/follow/openalgoHQ" alt="X (formerly Twitter) Follow" /&gt;&lt;/a&gt; &lt;a href="https://youtube.com/@openalgoHQ"&gt;&lt;img src="https://img.shields.io/youtube/channel/subscribers/UCw7eVneIEyiTApy4RtxrJsQ" alt="YouTube Channel Subscribers" /&gt;&lt;/a&gt; &lt;a href="https://discord.com/invite/UPh7QPsNhP"&gt;&lt;img src="https://img.shields.io/discord/1219847221055455263" alt="Discord" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/marketcalls/openalgo/main/static/images/image.png" alt="OpenAlgo - Your Personal Algo Trading Platform" /&gt;&lt;/p&gt; 
&lt;p&gt;OpenAlgo is an open-source, Flask-based Python application designed to bridge the gap between traders and major trading platforms such as Amibroker, Tradingview, Python, Chartink, MetaTrader, Excel, and Google Spreadsheets. With a focus on simplifying algotrading, OpenAlgo facilitates easy integration, automation, and execution of trading strategies, providing a user-friendly interface to enhance trading performance.&lt;/p&gt; 
&lt;h2&gt;Installation Guide&lt;/h2&gt; 
&lt;p&gt;For detailed installation instructions, please refer to &lt;a href="https://docs.openalgo.in/getting-started"&gt;INSTALL.md&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;What is OpenAlgo?&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=kAS3jTb3OkI" title="Watch the OpenAlgo Tutorial Video"&gt;&lt;img src="https://img.youtube.com/vi/kAS3jTb3OkI/0.jpg" alt="What is OpenAlgo" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Supported Brokers&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;5paisa&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;5paisa (XTS)&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;AliceBlue&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;AngelOne&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Compositedge&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Definedge&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Dhan&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Dhan (Sandbox)&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Firstock&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Flattrade&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Fyers&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;IBulls&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Indmoney&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Kotak&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Paytm&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Pocketful&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Shoonya&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Tradejini&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Upstox&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Wisdom Capital&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Zebu&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Zerodha&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;h3&gt;WebSocket Architecture with ZMQ Integration&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Unified WebSocket Proxy Server&lt;/strong&gt;: Central WebSocket server (port 8765) that handles client authentication and subscription management&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ZeroMQ (ZMQ) Message Bus&lt;/strong&gt;: High-performance message queue for real-time market data distribution 
  &lt;ul&gt; 
   &lt;li&gt;Publisher-Subscriber pattern for efficient data broadcasting&lt;/li&gt; 
   &lt;li&gt;Dynamic port binding with automatic port management&lt;/li&gt; 
   &lt;li&gt;Broker adapters publish to ZMQ, proxy server subscribes and routes to clients&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Broker-Specific Adapters&lt;/strong&gt;: Each broker has a dedicated adapter implementing the base WebSocket interface 
  &lt;ul&gt; 
   &lt;li&gt;Handles broker-specific WebSocket protocols and data formats&lt;/li&gt; 
   &lt;li&gt;Transforms broker data to unified OpenAlgo format&lt;/li&gt; 
   &lt;li&gt;Supports multiple subscription modes: LTP (Last Traded Price), Quote, and Market Depth&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Real-Time Market Data&lt;/strong&gt;: Live streaming of market data with support for: 
  &lt;ul&gt; 
   &lt;li&gt;LTP updates&lt;/li&gt; 
   &lt;li&gt;Full quotes with OHLC data&lt;/li&gt; 
   &lt;li&gt;Market depth (5/20/30 levels based on broker support)&lt;/li&gt; 
   &lt;li&gt;Auto-reconnection and connection management&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Unified API Layer (&lt;code&gt;/api/v1/&lt;/code&gt;)&lt;/h3&gt; 
&lt;p&gt;OpenAlgo provides a RESTful API with standardized endpoints across all supported brokers:&lt;/p&gt; 
&lt;h4&gt;Order Management APIs&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;/api/v1/placeorder&lt;/code&gt;&lt;/strong&gt;: Place regular orders with standard parameters&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;/api/v1/placesmartorder&lt;/code&gt;&lt;/strong&gt;: Smart order routing with advanced logic&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;/api/v1/modifyorder&lt;/code&gt;&lt;/strong&gt;: Modify existing orders&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;/api/v1/cancelorder&lt;/code&gt;&lt;/strong&gt;: Cancel specific orders&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;/api/v1/cancelallorder&lt;/code&gt;&lt;/strong&gt;: Cancel all pending orders&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;/api/v1/closeposition&lt;/code&gt;&lt;/strong&gt;: Close open positions&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;/api/v1/basketorder&lt;/code&gt;&lt;/strong&gt;: Execute multiple orders in a single request&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;/api/v1/splitorder&lt;/code&gt;&lt;/strong&gt;: Split large orders into smaller chunks&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Account &amp;amp; Portfolio APIs&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;/api/v1/funds&lt;/code&gt;&lt;/strong&gt;: Get account funds and margins&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;/api/v1/orderbook&lt;/code&gt;&lt;/strong&gt;: Retrieve all orders for the day&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;/api/v1/tradebook&lt;/code&gt;&lt;/strong&gt;: Get executed trades&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;/api/v1/positionbook&lt;/code&gt;&lt;/strong&gt;: View current open positions&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;/api/v1/holdings&lt;/code&gt;&lt;/strong&gt;: Get demat holdings&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;/api/v1/openposition&lt;/code&gt;&lt;/strong&gt;: Check specific position details&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;/api/v1/orderstatus&lt;/code&gt;&lt;/strong&gt;: Get real-time order status&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Market Data APIs&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;/api/v1/quotes&lt;/code&gt;&lt;/strong&gt;: Get real-time quotes for symbols&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;/api/v1/history&lt;/code&gt;&lt;/strong&gt;: Fetch historical OHLC data&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;/api/v1/depth&lt;/code&gt;&lt;/strong&gt;: Get market depth/order book&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;/api/v1/ticker&lt;/code&gt;&lt;/strong&gt;: Stream real-time price updates&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Utility APIs&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;/api/v1/search&lt;/code&gt;&lt;/strong&gt;: Search for symbols across exchanges&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;/api/v1/symbol&lt;/code&gt;&lt;/strong&gt;: Get symbol details and mappings&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;/api/v1/expiry&lt;/code&gt;&lt;/strong&gt;: Get option expiry dates&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;/api/v1/intervals&lt;/code&gt;&lt;/strong&gt;: Get supported time intervals for historical data&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;/api/v1/analyzer&lt;/code&gt;&lt;/strong&gt;: Test and analyze API requests without execution&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;/api/v1/ping&lt;/code&gt;&lt;/strong&gt;: Test API connectivity and authentication&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Common Broker Integration Pattern&lt;/h3&gt; 
&lt;p&gt;Each broker integration follows a standardized structure:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Authentication API&lt;/strong&gt; (&lt;code&gt;auth_api.py&lt;/code&gt;): Handle login and session management&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Order API&lt;/strong&gt; (&lt;code&gt;order_api.py&lt;/code&gt;): Place, modify, cancel orders and manage positions&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Data API&lt;/strong&gt; (&lt;code&gt;data.py&lt;/code&gt;): Fetch quotes, historical data, and market information&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Funds API&lt;/strong&gt; (&lt;code&gt;funds.py&lt;/code&gt;): Get account balance and margin details&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Symbol Mapping&lt;/strong&gt; (&lt;code&gt;transform_data.py&lt;/code&gt;): Convert between OpenAlgo and broker formats&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;WebSocket Streaming&lt;/strong&gt; (&lt;code&gt;broker_adapter.py&lt;/code&gt;): Real-time data streaming&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;ChartInk Platform Integration&lt;/strong&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Direct integration with ChartInk for strategy execution&lt;/li&gt; 
   &lt;li&gt;Automated scanning and trading based on ChartInk signals&lt;/li&gt; 
   &lt;li&gt;Real-time strategy monitoring and management&lt;/li&gt; 
   &lt;li&gt;Custom strategy configuration and deployment&lt;/li&gt; 
   &lt;li&gt;Seamless execution of ChartInk strategies through your broker&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Advanced Monitoring Tools&lt;/strong&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Latency Monitor&lt;/strong&gt;: Track and analyze order execution performance 
    &lt;ul&gt; 
     &lt;li&gt;Real-time latency tracking across different brokers&lt;/li&gt; 
     &lt;li&gt;Detailed breakdown of execution times&lt;/li&gt; 
     &lt;li&gt;Performance comparison between brokers&lt;/li&gt; 
     &lt;li&gt;Order execution success rates and patterns&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Traffic Monitor&lt;/strong&gt;: Monitor system performance and API usage 
    &lt;ul&gt; 
     &lt;li&gt;Real-time API request tracking&lt;/li&gt; 
     &lt;li&gt;Endpoint-specific analytics&lt;/li&gt; 
     &lt;li&gt;Error rate monitoring&lt;/li&gt; 
     &lt;li&gt;System performance metrics&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;PnL Tracker&lt;/strong&gt;: Real-time profit and loss monitoring with advanced charting 
    &lt;ul&gt; 
     &lt;li&gt;Intraday PnL curve visualization from 9 AM IST&lt;/li&gt; 
     &lt;li&gt;Current MTM, Max MTM with time, Min MTM with time&lt;/li&gt; 
     &lt;li&gt;Maximum drawdown tracking&lt;/li&gt; 
     &lt;li&gt;Interactive charts powered by TradingView Lightweight Charts&lt;/li&gt; 
     &lt;li&gt;Manual refresh control for performance optimization&lt;/li&gt; 
     &lt;li&gt;IST timezone support for accurate time display For detailed information about monitoring tools, see &lt;a href="https://raw.githubusercontent.com/marketcalls/openalgo/main/docs/traffic.md"&gt;traffic.md&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Modern UI with DaisyUI&lt;/strong&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Sleek and responsive interface built with DaisyUI components&lt;/li&gt; 
   &lt;li&gt;Three distinct themes: 
    &lt;ul&gt; 
     &lt;li&gt;Light theme for normal mode&lt;/li&gt; 
     &lt;li&gt;Dark theme for reduced eye strain&lt;/li&gt; 
     &lt;li&gt;Garden theme for analyzer mode&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;Instant theme switching with state preservation&lt;/li&gt; 
   &lt;li&gt;Theme-aware syntax highlighting for code and JSON&lt;/li&gt; 
   &lt;li&gt;Mobile-friendly layout with drawer navigation&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Real-Time Trading Updates&lt;/strong&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Instant order book updates via WebSocket&lt;/li&gt; 
   &lt;li&gt;Live trade book monitoring with automatic refresh&lt;/li&gt; 
   &lt;li&gt;Real-time position tracking&lt;/li&gt; 
   &lt;li&gt;Dynamic log updates for trade activities&lt;/li&gt; 
   &lt;li&gt;Contextual notifications with sound alerts&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;API Analyzer&lt;/strong&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Real-time request validation and testing&lt;/li&gt; 
   &lt;li&gt;Strategy testing without live execution&lt;/li&gt; 
   &lt;li&gt;Detailed request/response analysis&lt;/li&gt; 
   &lt;li&gt;Comprehensive error detection&lt;/li&gt; 
   &lt;li&gt;Dedicated garden theme for better focus&lt;/li&gt; 
   &lt;li&gt;See &lt;a href="https://raw.githubusercontent.com/marketcalls/openalgo/main/docs/Analyzer.md"&gt;Analyzer.md&lt;/a&gt; for detailed documentation&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Comprehensive Integration&lt;/strong&gt;: Seamlessly connect with Amibroker, Tradingview, Excel, and Google Spreadsheets for smooth data and strategy transition.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;User-Friendly Interface&lt;/strong&gt;: A straightforward Flask-based application interface accessible to traders of all levels of expertise.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Real-Time Execution&lt;/strong&gt;: Implement your trading strategies in real time, ensuring immediate action to capitalize on market opportunities.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Customizable Strategies&lt;/strong&gt;: Easily adapt and tailor your trading strategies to meet your specific needs, with extensive options for customization and automation.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Secure and Reliable&lt;/strong&gt;: With a focus on security and reliability, OpenAlgo provides a dependable platform for your algotrading activities, safeguarding your data and trades.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Rate Limiting Controls&lt;/h3&gt; 
&lt;p&gt;OpenAlgo implements comprehensive rate limiting to protect against abuse and ensure fair usage:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Configurable Rate Limits&lt;/strong&gt;: All rate limits are environment variable controlled&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;LOGIN_RATE_LIMIT_MIN&lt;/code&gt;: Login attempts per minute (default: 5 per minute)&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;LOGIN_RATE_LIMIT_HOUR&lt;/code&gt;: Login attempts per hour (default: 25 per hour)&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;API_RATE_LIMIT&lt;/code&gt;: General API endpoints (default: 10 per second)&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;ORDER_RATE_LIMIT&lt;/code&gt;: Order placement/modification/cancellation (default: 10 per second)&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;SMART_ORDER_RATE_LIMIT&lt;/code&gt;: Smart order operations&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;WEBHOOK_RATE_LIMIT&lt;/code&gt;: Webhook endpoint limits&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;STRATEGY_RATE_LIMIT&lt;/code&gt;: Strategy operation limits&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Moving Window Strategy&lt;/strong&gt;: Uses Flask-Limiter with moving-window strategy for accurate rate limiting&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;IP-based Limiting&lt;/strong&gt;: Rate limits are applied per IP address&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Graceful Handling&lt;/strong&gt;: Clear error messages when rate limits are exceeded&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Security Features&lt;/h3&gt; 
&lt;h4&gt;Browser-Level Security&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Content Security Policy (CSP)&lt;/strong&gt;: Configurable CSP headers to prevent XSS attacks 
  &lt;ul&gt; 
   &lt;li&gt;Customizable directives via environment variables&lt;/li&gt; 
   &lt;li&gt;Default restrictive policies for scripts, styles, and resources&lt;/li&gt; 
   &lt;li&gt;WebSocket support for real-time features&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;CORS Protection&lt;/strong&gt;: Controlled Cross-Origin Resource Sharing 
  &lt;ul&gt; 
   &lt;li&gt;Configurable allowed origins, methods, and headers&lt;/li&gt; 
   &lt;li&gt;Supports credentials for authenticated requests&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;CSRF Protection&lt;/strong&gt;: Built-in CSRF token validation for state-changing operations&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Secure Headers&lt;/strong&gt;: X-Frame-Options, X-Content-Type-Options, and other security headers&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Session Security&lt;/strong&gt;: Secure session management with proper cookie settings&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Database-Level Security&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Password Hashing&lt;/strong&gt;: Uses Argon2 (winner of Password Hashing Competition) for secure password storage&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Token Encryption&lt;/strong&gt;: Auth tokens encrypted using Fernet symmetric encryption 
  &lt;ul&gt; 
   &lt;li&gt;PBKDF2 key derivation for encryption keys&lt;/li&gt; 
   &lt;li&gt;Automatic encryption/decryption of sensitive tokens&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;API Key Security&lt;/strong&gt;: 
  &lt;ul&gt; 
   &lt;li&gt;Hashed storage using Argon2 with pepper&lt;/li&gt; 
   &lt;li&gt;Encrypted storage for retrieval&lt;/li&gt; 
   &lt;li&gt;Time-based caching with TTL&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;SQL Injection Protection&lt;/strong&gt;: Uses SQLAlchemy ORM with parameterized queries&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Connection Pooling&lt;/strong&gt;: Optimized database connections with proper pool management&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;API Analyzer&lt;/h3&gt; 
&lt;p&gt;The API Analyzer is a comprehensive testing and validation tool that provides:&lt;/p&gt; 
&lt;h4&gt;For Traders&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Risk-Free Testing&lt;/strong&gt;: Test all trading operations without actual execution&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Real-Time Validation&lt;/strong&gt;: Instant feedback on order parameters and strategy logic&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Strategy Monitoring&lt;/strong&gt;: Track multiple strategies simultaneously&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Visual Feedback&lt;/strong&gt;: Garden theme UI with instant notifications and sound alerts&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Cost Savings&lt;/strong&gt;: Avoid trading errors and optimize parameters without financial risk&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;For Developers&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Complete API Testing&lt;/strong&gt;: Test all endpoints with detailed request/response analysis&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Validation Engine&lt;/strong&gt;: Automatic parameter validation, symbol checks, and range verification&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;WebSocket Monitoring&lt;/strong&gt;: Real-time event tracking and debugging&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Performance Metrics&lt;/strong&gt;: Track API usage, latency, and error rates&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Debug Tools&lt;/strong&gt;: Complete request inspection and error analysis&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The analyzer supports all major operations: Place Order, Smart Orders, Modifications, Cancellations, and Position Management. See &lt;a href="https://raw.githubusercontent.com/marketcalls/openalgo/main/docs/Analyzer.md"&gt;Analyzer.md&lt;/a&gt; for detailed documentation.&lt;/p&gt; 
&lt;h3&gt;OpenAlgo FOSS Universe&lt;/h3&gt; 
&lt;p&gt;OpenAlgo is part of a larger ecosystem of open-source trading tools. The Mini FOSS Universe includes:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;OpenAlgo Core&lt;/strong&gt;: Python Flask + Tailwind + DaisyUI (this repository)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Historify&lt;/strong&gt;: Full Stack Stock Market Data Management Platform&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Python Library&lt;/strong&gt;: Native Python integration for algo trading&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Node.js Library&lt;/strong&gt;: JavaScript/TypeScript support for trading applications&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Excel Add-in&lt;/strong&gt;: Direct Excel integration for strategy development&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Model Context Protocol&lt;/strong&gt;: AI Agents integration for intelligent trading&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Chrome Plugin&lt;/strong&gt;: Browser-based trading tools&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Fast Scalper&lt;/strong&gt;: High-performance trading built with Rust + Tauri&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Web Portal&lt;/strong&gt;: Modern UI built with NextJS + ShadcnUI&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Documentation&lt;/strong&gt;: Comprehensive guides on Gitbook&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Built for traders, by traders - making algo trading more accessible, powerful, and open for everyone. Visit &lt;a href="https://docs.openalgo.in/mini-foss-universe"&gt;docs.openalgo.in/mini-foss-universe&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;h3&gt;Local MCP (Model Context Protocol) Integration&lt;/h3&gt; 
&lt;p&gt;OpenAlgo includes native MCP server capabilities, enabling AI assistants to execute trades and manage portfolios directly:&lt;/p&gt; 
&lt;h4&gt;Key Features&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;AI-Powered Trading&lt;/strong&gt;: Connect AI assistants like Claude Desktop, Cursor, or Windsurf to execute trades&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Full Trading Capabilities&lt;/strong&gt;: 
  &lt;ul&gt; 
   &lt;li&gt;Order Management: Place, modify, cancel orders (market/limit/stop-loss)&lt;/li&gt; 
   &lt;li&gt;Smart Orders: Automatic position sizing and basket orders&lt;/li&gt; 
   &lt;li&gt;Position Management: Close positions, track P&amp;amp;L&lt;/li&gt; 
   &lt;li&gt;Market Data: Real-time quotes, market depth, historical data&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Multi-Platform Support&lt;/strong&gt;: Works with any MCP-compatible AI client&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Local &amp;amp; Secure&lt;/strong&gt;: Runs locally with your OpenAlgo instance&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Available MCP Tools&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Order Operations&lt;/strong&gt;: &lt;code&gt;place_order&lt;/code&gt;, &lt;code&gt;place_smart_order&lt;/code&gt;, &lt;code&gt;place_basket_order&lt;/code&gt;, &lt;code&gt;modify_order&lt;/code&gt;, &lt;code&gt;cancel_order&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Position Tracking&lt;/strong&gt;: &lt;code&gt;get_open_position&lt;/code&gt;, &lt;code&gt;get_position_book&lt;/code&gt;, &lt;code&gt;close_all_positions&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Market Data&lt;/strong&gt;: &lt;code&gt;get_quote&lt;/code&gt;, &lt;code&gt;get_market_depth&lt;/code&gt;, &lt;code&gt;get_historical_data&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Account Info&lt;/strong&gt;: &lt;code&gt;get_funds&lt;/code&gt;, &lt;code&gt;get_holdings&lt;/code&gt;, &lt;code&gt;get_order_book&lt;/code&gt;, &lt;code&gt;get_trade_book&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Instrument Search&lt;/strong&gt;: &lt;code&gt;search_instruments&lt;/code&gt;, &lt;code&gt;get_symbol_info&lt;/code&gt;, &lt;code&gt;get_expiry_dates&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Quick Setup&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;Start your OpenAlgo server&lt;/li&gt; 
 &lt;li&gt;Generate an API key from Settings → API Keys&lt;/li&gt; 
 &lt;li&gt;Configure your AI assistant with the MCP server path and API key&lt;/li&gt; 
 &lt;li&gt;Start trading with natural language commands like "Buy 100 shares of RELIANCE"&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;For detailed MCP setup instructions, see &lt;a href="https://raw.githubusercontent.com/marketcalls/openalgo/main/mcp/README.md"&gt;mcp/README.md&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;For detailed documentation on OpenAlgo, including setup guides, API references, and usage examples, refer to &lt;a href="https://docs.openalgo.in"&gt;https://docs.openalgo.in&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Minimum Hardware Requirements&lt;/h3&gt; 
&lt;p&gt;To run OpenAlgo we recommend:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;2GB RAM or 0.5GB RAM with 2GB of Swap Memory&lt;/li&gt; 
 &lt;li&gt;1GB disk space&lt;/li&gt; 
 &lt;li&gt;1vCPU&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome contributions to OpenAlgo! If you're interested in improving the application or adding new features, please feel free to fork the repository, make your changes, and submit a pull request.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;OpenAlgo is released under the AGPL V3.0 License. See the &lt;code&gt;LICENSE&lt;/code&gt; file for more details.&lt;/p&gt; 
&lt;h2&gt;Repo Activity&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://repobeats.axiom.co/api/embed/0b6b18194a3089cb47ab8ae588caabb14aa9972b.svg?sanitize=true" alt="Alt" title="Repobeats analytics image" /&gt;&lt;/p&gt; 
&lt;h2&gt;Disclaimer&lt;/h2&gt; 
&lt;p&gt;This software is for educational purposes only. Do not risk money which you are afraid to lose. USE THE SOFTWARE AT YOUR OWN RISK. THE AUTHORS AND ALL AFFILIATES ASSUME NO RESPONSIBILITY FOR YOUR TRADING RESULTS.&lt;/p&gt; 
&lt;h2&gt;Credits and Acknowledgements&lt;/h2&gt; 
&lt;h3&gt;Third-Party Libraries&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://github.com/saadeghi/daisyui"&gt;DaisyUI&lt;/a&gt;&lt;/strong&gt; - The most popular component library for Tailwind CSS&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;License: MIT&lt;/li&gt; 
   &lt;li&gt;Version: 4.12.21&lt;/li&gt; 
   &lt;li&gt;Used for modern, responsive UI components throughout the application&lt;/li&gt; 
   &lt;li&gt;Provides theming system (Light, Dark, Garden themes)&lt;/li&gt; 
   &lt;li&gt;Powers the entire user interface design&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://github.com/tradingview/lightweight-charts"&gt;TradingView Lightweight Charts&lt;/a&gt;&lt;/strong&gt; - Advanced financial charting library&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;License: Apache 2.0&lt;/li&gt; 
   &lt;li&gt;Version: 5.0.8&lt;/li&gt; 
   &lt;li&gt;Used for interactive intraday PnL and drawdown visualization in PnL Tracker&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Support&lt;/h2&gt; 
&lt;p&gt;For any questions not covered by the documentation or for further information about OpenAlgo, join our &lt;a href="https://discord.com/invite/UPh7QPsNhP"&gt;Discord server&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>