<rss version="2.0">
  <channel>
    <title>GitHub All Languages Daily Trending</title>
    <description>Daily Trending of All Languages in GitHub</description>
    <pubDate>Sun, 14 Dec 2025 01:31:53 GMT</pubDate>
    <link>http://mshibanami.github.io/GitHubTrendingRSS</link>
    
    <item>
      <title>CopilotKit/CopilotKit</title>
      <link>https://github.com/CopilotKit/CopilotKit</link>
      <description>&lt;p&gt;React UI + elegant infrastructure for AI Copilots, AI chatbots, and in-app AI agents. The Agentic last-mile ü™Å&lt;/p&gt;&lt;hr&gt;&lt;a href="https://go.copilotkit.ai/v150-whats-new" target="_blank"&gt; &lt;img width="1595" height="284" alt="Introducing CopilotKit  v1 50!" src="https://github.com/user-attachments/assets/5d852a9b-290a-44b7-8c6a-9f75e51f1713" /&gt; &lt;/a&gt;
&lt;a&gt;&lt;/a&gt; 
&lt;br /&gt; 
&lt;a href="https://go.copilotkit.ai/copilotkit-docs" target="_blank"&gt; &lt;img width="4096" height="1588" alt="header" src="https://github.com/user-attachments/assets/dd638592-fb74-4e22-8c55-49dfc4d0e462" /&gt; &lt;/a&gt;
&lt;a&gt;&lt;/a&gt; 
&lt;br /&gt; 
&lt;div align="start" style="display:flex;justify-content:start;gap:16px;height:20px;margin: 0;"&gt; 
 &lt;a href="https://www.npmjs.com/package/@copilotkit/react-core" target="_blank"&gt; &lt;img src="https://img.shields.io/npm/v/%40copilotkit%2Freact-core?logo=npm&amp;amp;logoColor=%23FFFFFF&amp;amp;label=Version&amp;amp;color=%236963ff" alt="NPM" /&gt; &lt;/a&gt; 
 &lt;a href="https://github.com/copilotkit/copilotkit/raw/main/LICENSE" target="_blank"&gt; &lt;img src="https://img.shields.io/github/license/copilotkit/copilotkit?color=%236963ff&amp;amp;label=License" alt="MIT" /&gt; &lt;/a&gt; 
 &lt;a href="https://discord.gg/6dffbvGU3D" target="_blank"&gt; &lt;img src="https://img.shields.io/discord/1122926057641742418?logo=discord&amp;amp;logoColor=%23FFFFFF&amp;amp;label=Discord&amp;amp;color=%236963ff" alt="Discord" /&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;br /&gt; 
&lt;div&gt; 
 &lt;a href="https://www.producthunt.com/posts/copilotkit" target="_blank"&gt; &lt;img src="https://api.producthunt.com/widgets/embed-image/v1/top-post-badge.svg?post_id=428778&amp;amp;theme=light&amp;amp;period=daily" /&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;h2&gt;‚ö°Ô∏è Quick Install&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;  npx copilotkit@latest create
&lt;/code&gt;&lt;/pre&gt; 
&lt;br /&gt; 
&lt;p&gt;&lt;a href="https://docs.copilotkit.ai/?ref=github_readme"&gt;Read the Docs ‚Üí&lt;/a&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp; &lt;a href="https://cloud.copilotkit.ai?ref=github_readme"&gt;Try Copilot Cloud ‚Üí&lt;/a&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp; &lt;a href="https://discord.gg/6dffbvGU3D?ref=github_readme"&gt;Join our Discord ‚Üí&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üöÄ Getting Started&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;Install: Run a simple CLI command&lt;/li&gt; 
 &lt;li&gt;Configure: Add CopilotKit provider to your app&lt;/li&gt; 
 &lt;li&gt;Customize: Use headless UI or the customizable pre-built components&lt;/li&gt; 
 &lt;li&gt;Deploy: You're done!&lt;/li&gt; 
&lt;/ol&gt; 
&lt;br /&gt; 
&lt;a href="https://docs.copilotkit.ai/#get-started-now?ref=github_readme" target="_blank"&gt; Complete getting started guide ‚Üí &lt;/a&gt; 
&lt;br /&gt; 
&lt;br /&gt; 
&lt;img width="4096" height="2341" alt="Best in class support across the ecosystem" src="https://github.com/user-attachments/assets/bf399131-2a92-49f8-8748-38ed72353f9c" /&gt; 
&lt;h2&gt;‚≠êÔ∏è useAgent&lt;/h2&gt; 
&lt;p&gt;The v2 hook &lt;code&gt;useAgent&lt;/code&gt; is a proper superset of &lt;code&gt;useCoAgent&lt;/code&gt;, which gives more control over the agent connection.&lt;/p&gt; 
&lt;p&gt;Check out the &lt;a href="https://go.copilotkit.ai/useagent-docs"&gt;useAgent docs&lt;/a&gt; to learn more.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/46b7d161-a988-4453-9ca9-c0eca4c33da6"&gt;https://github.com/user-attachments/assets/46b7d161-a988-4453-9ca9-c0eca4c33da6&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;‚ú® Why CopilotKit?&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Minutes to integrate&amp;nbsp;- Get started quickly with our CLI&lt;/li&gt; 
 &lt;li&gt;Framework agnostic&amp;nbsp;- Works with React, Next.js, AGUI, and more&lt;/li&gt; 
 &lt;li&gt;Production-ready UI&amp;nbsp;- Use customizable components or build with headless UI&lt;/li&gt; 
 &lt;li&gt;Built-in security&amp;nbsp;- Prompt injection protection&lt;/li&gt; 
 &lt;li&gt;Open source&amp;nbsp;- Full transparency and community-driven&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üßë‚Äçüíª Real life use cases&lt;/h2&gt; 
&lt;p&gt;&lt;span&gt;Deploy deeply-integrated AI assistants &amp;amp; agents that work alongside your users inside your applications.&lt;/span&gt;&lt;/p&gt; 
&lt;img width="4096" height="2725" alt="Headless UI" src="https://github.com/user-attachments/assets/4dbe1e74-8b46-4798-a658-f79ee5a66189" /&gt; 
&lt;h2&gt;üñ•Ô∏è Code Samples&lt;/h2&gt; 
&lt;p&gt;&lt;span&gt;Drop in these building blocks and tailor them to your needs.&lt;/span&gt;&lt;/p&gt; 
&lt;h3&gt;Build with Headless APIs and Pre-Built Components&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-ts"&gt;// Headless UI with full control
const { copilotkit } = useCopilotKit();
const { agent } = useAgent({ agentId: "my_agent" });
const { messages, addMessage, setMessages, state, ... } = agent;

copilotkit.runAgent({ agent })

// Pre-built components with deep customization options (CSS + pass custom sub-components)
&amp;lt;CopilotSidebar 
  instructions={"You are assisting the user as best as you can. Answer in the best way possible given the data you have."} 
  labels={{ title: "Sidebar Assistant", initial: "Need any help?" }} 
/&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Deeply integrate LLMs or agents into your application&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-ts"&gt;// Programmatically access and control your agents
const { agent } = useAgent({ agentId: "my_agent" });

// Render and update your agent's state
return &amp;lt;div&amp;gt;
  &amp;lt;h1&amp;gt;{agent.state.city}&amp;lt;/h1&amp;gt; 
  &amp;lt;button onClick={() =&amp;gt; agent.setState({ city: "NYC" })}&amp;gt;
    Set City
  &amp;lt;/button&amp;gt;
&amp;lt;/div&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-ts"&gt;// Build generative UI based on your agent's state
useCoAgentStateRender({
  name: "my_agent",
  render: ({ state }) =&amp;gt; &amp;lt;WeatherDisplay {...state.final_response} /&amp;gt;,
});
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-ts"&gt;// Frontend actions + generative UI, with full streaming support
useFrontendTool({
  name: "appendToSpreadsheet",
  description: "Append rows to the current spreadsheet",
  parameters: [
    { name: "rows", type: "object[]", attributes: [{ name: "cells", type: "object[]", attributes: [{ name: "value", type: "string" }] }] }
  ],
  render: ({ status, args }) =&amp;gt; &amp;lt;Spreadsheet data={canonicalSpreadsheetData(args.rows)} /&amp;gt;,
  handler: ({ rows }) =&amp;gt; setSpreadsheet({ ...spreadsheet, rows: [...spreadsheet.rows, ...canonicalSpreadsheetData(rows)] }),
});
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-ts"&gt;// Human in the Loop (Approval)
useHumanInTheLoop({
  name: "email_tool",
  parameters: [
    {
      name: "email_draft",
      type: "string",
      description: "The email content",
      required: true,
    },
  ],
  render: ({ args, status, respond }) =&amp;gt; {
    return (
      &amp;lt;EmailConfirmation
        emailContent={args.email_draft || ""}
        isExecuting={status === "executing"}
        onCancel={() =&amp;gt; respond?.({ approved: false })}
        onSend={() =&amp;gt;
          respond?.({
            approved: true,
            metadata: { sentAt: new Date().toISOString() },
          })
        }
      /&amp;gt;
    );
  },
});
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-ts"&gt;// Build generative UI on-top of your agent's tool calls
useRenderToolCall({
  name: "get_weather", // tool defined in your agent
  args: [{
    name: "city",
    type: "string",
    required: true,
  }],
  render: ({ args, result }) =&amp;gt; {
    &amp;lt;WeatherCard  
      city={args.city}
      temperature={result.temperature}
      description={result.description}
    /&amp;gt;
  }
})
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;üèÜ Featured Examples&lt;/h2&gt; 
&lt;p align="center"&gt; &lt;a href="https://www.copilotkit.ai/examples/form-filling-copilot"&gt; &lt;img width="290" height="304" alt="Banner 2 A" src="https://github.com/user-attachments/assets/90c42b54-8931-45ad-9c0b-53f7f67453a1" /&gt; &lt;/a&gt; &lt;a href="https://www.copilotkit.ai/examples/state-machine-copilot"&gt; &lt;img width="290" height="304" alt="Banner 2 A-1" src="https://github.com/user-attachments/assets/609c62eb-76af-4866-a353-5e3545470ec3" /&gt; &lt;/a&gt; &lt;a href="https://www.copilotkit.ai/examples/chat-with-your-data"&gt; &lt;img width="290" height="304" alt="Banner 2 A-2" src="https://github.com/user-attachments/assets/c614ac4e-d2b3-4514-9ef1-fdba04c0a082" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;h2&gt;üñ•Ô∏è AG-UI: The Agent‚ÄìUser Interaction Protocol&lt;/h2&gt; 
&lt;p&gt;Connect agent workflow to user-facing apps, with deep partnerships and 1st-party integrations across the agentic stack‚Äîincluding LangGraph, CrewAI, and more.&lt;/p&gt; 
&lt;a href="https://github.com/ag-ui-protocol/ag-ui" target="_blank"&gt; Learn more in the AG-UI README ‚Üí &lt;/a&gt; 
&lt;h2&gt;ü§ù Community&lt;/h2&gt; 
&lt;h3&gt;Have questions or need help?&lt;/h3&gt; 
&lt;a href="https://discord.gg/6dffbvGU3D?ref=github_readme" target="_blank"&gt; Join our Discord ‚Üí &lt;/a&gt; 
&lt;br /&gt; 
&lt;a href="https://docs.copilotkit.ai/?ref=github_readme" target="_blank"&gt; Read the Docs ‚Üí &lt;/a&gt; 
&lt;br /&gt; 
&lt;a href="https://cloud.copilotkit.ai?ref=github_readme" target="_blank"&gt; Try Copilot Cloud ‚Üí &lt;/a&gt; 
&lt;h3&gt;Stay up to date with our latest releases!&lt;/h3&gt; 
&lt;a href="https://www.linkedin.com/company/copilotkit/" target="_blank"&gt; Follow us on LinkedIn ‚Üí &lt;/a&gt; 
&lt;br /&gt; 
&lt;a href="https://x.com/copilotkit" target="_blank"&gt; Follow us on X ‚Üí &lt;/a&gt; 
&lt;h2&gt;üôãüèΩ‚Äç‚ôÇÔ∏è Contributing&lt;/h2&gt; 
&lt;p&gt;Thanks for your interest in contributing to CopilotKit! üíú&lt;/p&gt; 
&lt;p&gt;We value all contributions, whether it's through code, documentation, creating demo apps, or just spreading the word.&lt;/p&gt; 
&lt;p&gt;Here are a few useful resources to help you get started:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;For code contributions, &lt;a href="https://raw.githubusercontent.com/CopilotKit/CopilotKit/main/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;For documentation-related contributions, &lt;a href="https://docs.copilotkit.ai/contributing/docs-contributions?ref=github_readme"&gt;check out the documentation contributions guide&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Want to contribute but not sure how? &lt;a href="https://discord.gg/6dffbvGU3D"&gt;Join our Discord&lt;/a&gt; and we'll help you out!&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üìÑ License&lt;/h2&gt; 
&lt;p&gt;This repository's source code is available under the &lt;a href="https://github.com/CopilotKit/CopilotKit/raw/main/LICENSE"&gt;MIT License&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>tursodatabase/turso</title>
      <link>https://github.com/tursodatabase/turso</link>
      <description>&lt;p&gt;Turso is an in-process SQL database, compatible with SQLite.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/tursodatabase/turso/main/assets/turso.png" alt="Turso Database" width="800" /&gt; &lt;/p&gt;
&lt;h1 align="center"&gt;Turso Database&lt;/h1&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;p align="center"&gt; An in-process SQL database, compatible with SQLite. &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a title="Build Status" target="_blank" href="https://github.com/tursodatabase/turso/actions/workflows/rust.yml"&gt;&lt;img src="https://img.shields.io/github/actions/workflow/status/tursodatabase/turso/rust.yml?style=flat-square" /&gt;&lt;/a&gt; &lt;a title="Releases" target="_blank" href="https://github.com/tursodatabase/turso/releases"&gt;&lt;img src="https://img.shields.io/github/release/tursodatabase/turso?style=flat-square&amp;amp;color=9CF" /&gt;&lt;/a&gt; &lt;a title="Rust" target="_blank" href="https://crates.io/crates/turso"&gt;&lt;img alt="Crate" src="https://img.shields.io/crates/v/turso" /&gt;&lt;/a&gt; &lt;a title="JavaScript" target="_blank" href="https://www.npmjs.com/package/@tursodatabase/database"&gt;&lt;img alt="NPM" src="https://img.shields.io/npm/v/@tursodatabase/database" /&gt;&lt;/a&gt; &lt;a title="Python" target="_blank" href="https://pypi.org/project/pyturso/"&gt;&lt;img alt="PyPI" src="https://img.shields.io/pypi/v/pyturso" /&gt;&lt;/a&gt; &lt;a title="Java" target="_blank" href="https://central.sonatype.com/artifact/tech.turso/turso"&gt;&lt;img alt="Maven Central" src="https://img.shields.io/maven-central/v/tech.turso/turso" /&gt;&lt;/a&gt; &lt;a title="MIT" target="_blank" href="https://github.com/tursodatabase/turso/raw/main/LICENSE.md"&gt;&lt;img src="http://img.shields.io/badge/license-MIT-orange.svg?style=flat-square" /&gt;&lt;/a&gt; &lt;br /&gt; &lt;a title="GitHub Pull Requests" target="_blank" href="https://github.com/tursodatabase/turso/pulls"&gt;&lt;img src="https://img.shields.io/github/issues-pr-closed/tursodatabase/turso.svg?style=flat-square&amp;amp;color=FF9966" /&gt;&lt;/a&gt; &lt;a title="GitHub Commits" target="_blank" href="https://github.com/tursodatabase/turso/commits/main"&gt;&lt;img src="https://img.shields.io/github/commit-activity/m/tursodatabase/turso.svg?style=flat-square" /&gt;&lt;/a&gt; &lt;a title="Last Commit" target="_blank" href="https://github.com/tursodatabase/turso/commits/main"&gt;&lt;img src="https://img.shields.io/github/last-commit/tursodatabase/turso.svg?style=flat-square&amp;amp;color=FF9900" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a title="Developer's Discord" target="_blank" href="https://discord.gg/jgjmyYgHwB"&gt;&lt;img alt="Chat with the Core Developers on Discord" src="https://img.shields.io/discord/1258658826257961020?label=Discord&amp;amp;logo=Discord&amp;amp;style=social&amp;amp;label=Core%20Developers" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a title="Users's Discord" target="_blank" href="https://tur.so/discord"&gt;&lt;img alt="Chat with other users of Turso (and Turso Cloud) on Discord" src="https://img.shields.io/discord/933071162680958986?label=Discord&amp;amp;logo=Discord&amp;amp;style=social&amp;amp;label=Users" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;About&lt;/h2&gt; 
&lt;p&gt;Turso Database is an in-process SQL database written in Rust, compatible with SQLite.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;‚ö†Ô∏è Warning:&lt;/strong&gt; This software is in BETA. It may still contain bugs and unexpected behavior. Use caution with production data and ensure you have backups.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Features and Roadmap&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;SQLite compatibility&lt;/strong&gt; for SQL dialect, file formats, and the C API [see &lt;a href="https://raw.githubusercontent.com/tursodatabase/turso/main/COMPAT.md"&gt;document&lt;/a&gt; for details]&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Change data capture (CDC)&lt;/strong&gt; for real-time tracking of database changes.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Multi-language support&lt;/strong&gt; for 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/tursodatabase/turso-go"&gt;Go&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tursodatabase/turso/main/bindings/javascript"&gt;JavaScript&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tursodatabase/turso/main/bindings/java"&gt;Java&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tursodatabase/turso/main/bindings/python"&gt;Python&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tursodatabase/turso/main/bindings/rust"&gt;Rust&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tursodatabase/turso/main/bindings/javascript"&gt;WebAssembly&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Asynchronous I/O&lt;/strong&gt; support on Linux with &lt;code&gt;io_uring&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Cross-platform&lt;/strong&gt; support for Linux, macOS, Windows and browsers (through WebAssembly)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Vector support&lt;/strong&gt; support including exact search and vector manipulation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Improved schema management&lt;/strong&gt; including extended &lt;code&gt;ALTER&lt;/code&gt; support and faster schema changes.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The database has the following experimental features:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;BEGIN CONCURRENT&lt;/code&gt;&lt;/strong&gt; for improved write throughput using multi-version concurrency control (MVCC).&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Encryption at rest&lt;/strong&gt; for protecting the data locally.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Incremental computation&lt;/strong&gt; using DBSP for incremental view mainatenance and query subscriptions.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The following features are on our current roadmap:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Vector indexing&lt;/strong&gt; for fast approximate vector search, similar to &lt;a href="https://turso.tech/vector"&gt;libSQL vector search&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;p&gt;Please see the &lt;a href="https://raw.githubusercontent.com/tursodatabase/turso/main/docs/manual.md"&gt;Turso Database Manual&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;üíª Command Line&lt;/summary&gt; 
 &lt;br /&gt; You can install the latest `turso` release with: 
 &lt;pre&gt;&lt;code class="language-shell"&gt;curl --proto '=https' --tlsv1.2 -LsSf \
  https://github.com/tursodatabase/turso/releases/latest/download/turso_cli-installer.sh | sh
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Then launch the interactive shell:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;$ tursodb
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;This will start the Turso interactive shell where you can execute SQL statements:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-console"&gt;Turso
Enter ".help" for usage hints.
Connected to a transient in-memory database.
Use ".open FILENAME" to reopen on a persistent database
turso&amp;gt; CREATE TABLE users (id INT, username TEXT);
turso&amp;gt; INSERT INTO users VALUES (1, 'alice');
turso&amp;gt; INSERT INTO users VALUES (2, 'bob');
turso&amp;gt; SELECT * FROM users;
1|alice
2|bob
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;You can also build and run the latest development version with:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;cargo run
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;If you like docker, we got you covered. Simply run this in the root folder:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;make docker-cli-build &amp;amp;&amp;amp; \
make docker-cli-run
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;ü¶Ä Rust&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;pre&gt;&lt;code class="language-console"&gt;cargo add turso
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Example usage:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-rust"&gt;let db = Builder::new_local("sqlite.db").build().await?;
let conn = db.connect()?;

let res = conn.query("SELECT * FROM users", ()).await?;
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;‚ú® JavaScript&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;pre&gt;&lt;code class="language-console"&gt;npm i @tursodatabase/database
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Example usage:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-js"&gt;import { connect } from '@tursodatabase/database';

const db = await connect('sqlite.db');
const stmt = db.prepare('SELECT * FROM users');
const users = stmt.all();
console.log(users);
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;üêç Python&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;pre&gt;&lt;code class="language-console"&gt;uv pip install pyturso
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Example usage:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;import turso

con = turso.connect("sqlite.db")
cur = con.cursor()
res = cur.execute("SELECT * FROM users")
print(res.fetchone())
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;ü¶´ Go&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;pre&gt;&lt;code class="language-console"&gt;go get github.com/tursodatabase/turso-go
go install github.com/tursodatabase/turso-go
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Example usage:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-go"&gt;import (
    "database/sql"
    _ "github.com/tursodatabase/turso-go"
)

conn, _ = sql.Open("turso", "sqlite.db")
defer conn.Close()

stmt, _ := conn.Prepare("select * from users")
defer stmt.Close()

rows, _ = stmt.Query()
for rows.Next() {
    var id int
    var username string
    _ := rows.Scan(&amp;amp;id, &amp;amp;username)
    fmt.Printf("User: ID: %d, Username: %s\n", id, username)
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;‚òïÔ∏è Java&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;p&gt;We integrated Turso Database into JDBC. For detailed instructions on how to use Turso Database with java, please refer to the &lt;a href="https://raw.githubusercontent.com/tursodatabase/turso/main/bindings/java/README.md"&gt;README.md under bindings/java&lt;/a&gt;.&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;ü§ñ MCP Server Mode&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;p&gt;The Turso CLI includes a built-in &lt;a href="https://modelcontextprotocol.io/"&gt;Model Context Protocol (MCP)&lt;/a&gt; server that allows AI assistants to interact with your databases.&lt;/p&gt; 
 &lt;p&gt;Start the MCP server with:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;tursodb your_database.db --mcp
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h3&gt;Configuration&lt;/h3&gt; 
 &lt;p&gt;Add Turso to your MCP client configuration:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-json"&gt;{
  "mcpServers": {
    "turso": {
      "command": "/path/to/.turso/tursodb",
      "args": ["/path/to/your/database.db", "--mcp"]
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h3&gt;Available Tools&lt;/h3&gt; 
 &lt;p&gt;The MCP server provides nine tools for database interaction:&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;&lt;strong&gt;&lt;code&gt;open_database&lt;/code&gt;&lt;/strong&gt; - Open a new database&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;&lt;code&gt;current_database&lt;/code&gt;&lt;/strong&gt; - Describe the current database&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;&lt;code&gt;list_tables&lt;/code&gt;&lt;/strong&gt; - List all tables in the database&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;&lt;code&gt;describe_table&lt;/code&gt;&lt;/strong&gt; - Describe the structure of a specific table&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;&lt;code&gt;execute_query&lt;/code&gt;&lt;/strong&gt; - Execute read-only SELECT queries&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;&lt;code&gt;insert_data&lt;/code&gt;&lt;/strong&gt; - Insert new data into tables&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;&lt;code&gt;update_data&lt;/code&gt;&lt;/strong&gt; - Update existing data in tables&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;&lt;code&gt;delete_data&lt;/code&gt;&lt;/strong&gt; - Delete data from tables&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;&lt;code&gt;schema_change&lt;/code&gt;&lt;/strong&gt; - Execute schema modification statements (CREATE TABLE, ALTER TABLE, DROP TABLE)&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;p&gt;Once connected, you can ask your AI assistant:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;"Show me all tables in the database"&lt;/li&gt; 
  &lt;li&gt;"What's the schema for the users table?"&lt;/li&gt; 
  &lt;li&gt;"Find all posts with more than 100 upvotes"&lt;/li&gt; 
  &lt;li&gt;"Insert a new user with name 'Alice' and email '&lt;a href="mailto:alice@example.com"&gt;alice@example.com&lt;/a&gt;'"&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;MCP Clients&lt;/h3&gt; 
 &lt;details&gt; 
  &lt;summary&gt;Claude Code&lt;/summary&gt; 
  &lt;p&gt;If you're using &lt;a href="https://claude.ai/code"&gt;Claude Code&lt;/a&gt;, you can easily connect to your Turso MCP server using the built-in MCP management commands:&lt;/p&gt; 
  &lt;h4&gt;Quick Setup&lt;/h4&gt; 
  &lt;ol&gt; 
   &lt;li&gt; &lt;p&gt;&lt;strong&gt;Add the MCP server&lt;/strong&gt; to Claude Code:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;claude mcp add my-database -- tursodb ./path/to/your/database.db --mcp
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;strong&gt;Restart Claude Code&lt;/strong&gt; to activate the connection&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;strong&gt;Start querying&lt;/strong&gt; your database through natural language!&lt;/p&gt; &lt;/li&gt; 
  &lt;/ol&gt; 
  &lt;h4&gt;Command Breakdown&lt;/h4&gt; 
  &lt;pre&gt;&lt;code class="language-bash"&gt;claude mcp add my-database -- tursodb ./path/to/your/database.db --mcp
#              ‚Üë            ‚Üë       ‚Üë                           ‚Üë
#              |            |       |                           |
#              Name         |       Database path               MCP flag
#                          Separator
&lt;/code&gt;&lt;/pre&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;code&gt;my-database&lt;/code&gt;&lt;/strong&gt; - Choose any name for your MCP server&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;code&gt;--&lt;/code&gt;&lt;/strong&gt; - Required separator between Claude options and your command&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;code&gt;tursodb&lt;/code&gt;&lt;/strong&gt; - The Turso database CLI&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;code&gt;./path/to/your/database.db&lt;/code&gt;&lt;/strong&gt; - Path to your SQLite database file&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;code&gt;--mcp&lt;/code&gt;&lt;/strong&gt; - Enables MCP server mode&lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;h4&gt;Example Usage&lt;/h4&gt; 
  &lt;pre&gt;&lt;code class="language-bash"&gt;# For a local project database
cd /your/project
claude mcp add my-project-db -- tursodb ./data/app.db --mcp

# For an absolute path
claude mcp add analytics-db -- tursodb /Users/you/databases/analytics.db --mcp

# For a specific project (local scope)
claude mcp add project-db --local -- tursodb ./database.db --mcp
&lt;/code&gt;&lt;/pre&gt; 
  &lt;h4&gt;Managing MCP Servers&lt;/h4&gt; 
  &lt;pre&gt;&lt;code class="language-bash"&gt;# List all configured MCP servers
claude mcp list

# Get details about a specific server
claude mcp get my-database

# Remove an MCP server
claude mcp remove my-database
&lt;/code&gt;&lt;/pre&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt;Claude Desktop&lt;/summary&gt; 
  &lt;p&gt;For Claude Desktop, add the configuration to your &lt;code&gt;claude_desktop_config.json&lt;/code&gt; file:&lt;/p&gt; 
  &lt;pre&gt;&lt;code class="language-json"&gt;{
  "mcpServers": {
    "turso": {
      "command": "/path/to/.turso/tursodb",
      "args": ["./path/to/your/database.db.db", "--mcp"]
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt;Cursor&lt;/summary&gt; 
  &lt;p&gt;For Cursor, configure MCP in your settings:&lt;/p&gt; 
  &lt;ol&gt; 
   &lt;li&gt;Open Cursor settings&lt;/li&gt; 
   &lt;li&gt;Navigate to Extensions ‚Üí MCP&lt;/li&gt; 
   &lt;li&gt;Add a new server with: 
    &lt;ul&gt; 
     &lt;li&gt;&lt;strong&gt;Name&lt;/strong&gt;: &lt;code&gt;turso&lt;/code&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;strong&gt;Command&lt;/strong&gt;: &lt;code&gt;/path/to/.turso/tursodb&lt;/code&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;strong&gt;Args&lt;/strong&gt;: &lt;code&gt;["./path/to/your/database.db.db", "--mcp"]&lt;/code&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ol&gt; 
  &lt;p&gt;Alternatively, you can add it to your Cursor configuration file directly.&lt;/p&gt; 
 &lt;/details&gt; 
 &lt;h3&gt;Direct JSON-RPC Usage&lt;/h3&gt; 
 &lt;p&gt;The MCP server runs as a single process that handles multiple JSON-RPC requests over stdin/stdout. Here's how to interact with it directly:&lt;/p&gt; 
 &lt;h4&gt;Example with In-Memory Database&lt;/h4&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;cat &amp;lt;&amp;lt; 'EOF' | tursodb --mcp
{"jsonrpc": "2.0", "id": 1, "method": "initialize", "params": {"protocolVersion": "2024-11-05", "capabilities": {}, "clientInfo": {"name": "client", "version": "1.0"}}}
{"jsonrpc": "2.0", "id": 2, "method": "tools/call", "params": {"name": "schema_change", "arguments": {"query": "CREATE TABLE users (id INTEGER, name TEXT, email TEXT)"}}}
{"jsonrpc": "2.0", "id": 3, "method": "tools/call", "params": {"name": "list_tables", "arguments": {}}}
{"jsonrpc": "2.0", "id": 4, "method": "tools/call", "params": {"name": "insert_data", "arguments": {"query": "INSERT INTO users VALUES (1, 'Alice', 'alice@example.com')"}}}
{"jsonrpc": "2.0", "id": 5, "method": "tools/call", "params": {"name": "execute_query", "arguments": {"query": "SELECT * FROM users"}}}
EOF
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h4&gt;Example with Existing Database&lt;/h4&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# Working with an existing database file
cat &amp;lt;&amp;lt; 'EOF' | tursodb mydb.db --mcp
{"jsonrpc": "2.0", "id": 1, "method": "initialize", "params": {"protocolVersion": "2024-11-05", "capabilities": {}, "clientInfo": {"name": "client", "version": "1.0"}}}
{"jsonrpc": "2.0", "id": 2, "method": "tools/call", "params": {"name": "list_tables", "arguments": {}}}
EOF
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We'd love to have you contribute to Turso Database! Please check out the &lt;a href="https://raw.githubusercontent.com/tursodatabase/turso/main/CONTRIBUTING.md"&gt;contribution guide&lt;/a&gt; to get started.&lt;/p&gt; 
&lt;h3&gt;Found a data corruption bug? Get up to $1,000.00&lt;/h3&gt; 
&lt;p&gt;SQLite is loved because it is the most reliable database in the world. The next evolution of SQLite has to match or surpass this level of reliability. Turso is built with &lt;a href="https://raw.githubusercontent.com/tursodatabase/turso/main/simulator/"&gt;Deterministic Simulation Testing&lt;/a&gt; from the ground up, and is also tested by &lt;a href="https://antithesis.com"&gt;Antithesis&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Even during Alpha, if you find a bug that leads to a data corruption and demonstrate how our simulator failed to catch it, you can get up to $1,000.00. As the project matures we will increase the size of the prize, and the scope of the bugs.&lt;/p&gt; 
&lt;p&gt;List of rewarded cases:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;B-Tree interior cell replacement issue in btrees with depth &amp;gt;=3 (&lt;a href="https://github.com/tursodatabase/turso/issues/2106"&gt;#2106&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;Don't allow autovacuum to be flipped on non-empty databases (&lt;a href="https://github.com/tursodatabase/turso/pull/3830"&gt;#3830&lt;/a&gt;)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;More details &lt;a href="https://turso.algora.io"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Turso core staff are not eligible.&lt;/p&gt; 
&lt;h2&gt;FAQ&lt;/h2&gt; 
&lt;h3&gt;Is Turso Database ready for production use?&lt;/h3&gt; 
&lt;p&gt;Turso Database is currently under heavy development and is &lt;strong&gt;not&lt;/strong&gt; ready for production use.&lt;/p&gt; 
&lt;h3&gt;How is Turso Database different from Turso's libSQL?&lt;/h3&gt; 
&lt;p&gt;Turso Database is a project to build the next evolution of SQLite in Rust, with a strong open contribution focus and features like native async support, vector search, and more. The libSQL project is also an attempt to evolve SQLite in a similar direction, but through a fork rather than a rewrite.&lt;/p&gt; 
&lt;p&gt;Rewriting SQLite in Rust started as an unassuming experiment, and due to its incredible success, replaces libSQL as our intended direction. At this point, libSQL is production ready, Turso Database is not - although it is evolving rapidly. More details &lt;a href="https://turso.tech/blog/we-will-rewrite-sqlite-and-we-are-going-all-in"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Publications&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Pekka Enberg, Sasu Tarkoma, Jon Crowcroft Ashwin Rao (2024). Serverless Runtime / Database Co-Design With Asynchronous I/O. In &lt;em&gt;EdgeSys ‚Äò24&lt;/em&gt;. &lt;a href="https://penberg.org/papers/penberg-edgesys24.pdf"&gt;[PDF]&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Pekka Enberg, Sasu Tarkoma, and Ashwin Rao (2023). Towards Database and Serverless Runtime Co-Design. In &lt;em&gt;CoNEXT-SW ‚Äô23&lt;/em&gt;. [&lt;a href="https://penberg.org/papers/penberg-conext-sw-23.pdf"&gt;PDF&lt;/a&gt;] [&lt;a href="https://penberg.org/papers/penberg-conext-sw-23-slides.pdf"&gt;Slides&lt;/a&gt;]&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the &lt;a href="https://raw.githubusercontent.com/tursodatabase/turso/main/LICENSE.md"&gt;MIT license&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Contribution&lt;/h3&gt; 
&lt;p&gt;Unless you explicitly state otherwise, any contribution intentionally submitted for inclusion in Turso Database by you, shall be licensed as MIT, without any additional terms or conditions.&lt;/p&gt; 
&lt;h2&gt;Partners&lt;/h2&gt; 
&lt;p&gt;Thanks to all the partners of Turso!&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://antithesis.com/"&gt;&lt;img src="https://raw.githubusercontent.com/tursodatabase/turso/main/assets/antithesis.jpg" width="400" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://blacksmith.sh"&gt;&lt;img src="https://raw.githubusercontent.com/tursodatabase/turso/main/assets/blacksmith.svg?sanitize=true" width="400" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://nyrkio.com/"&gt;&lt;img src="https://raw.githubusercontent.com/tursodatabase/turso/main/assets/turso-nyrkio.png" width="400" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Contributors&lt;/h2&gt; 
&lt;p&gt;Thanks to all the contributors to Turso Database!&lt;/p&gt; 
&lt;a href="https://github.com/tursodatabase/turso/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=tursodatabase/turso" /&gt; &lt;/a&gt;</description>
    </item>
    
    <item>
      <title>DayuanJiang/next-ai-draw-io</title>
      <link>https://github.com/DayuanJiang/next-ai-draw-io</link>
      <description>&lt;p&gt;A next.js web application that integrates AI capabilities with draw.io diagrams. This app allows you to create, modify, and enhance diagrams through natural language commands and AI-assisted visualization.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Next AI Draw.io&lt;/h1&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;strong&gt;AI-Powered Diagram Creation Tool - Chat, Draw, Visualize&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;English | &lt;a href="https://raw.githubusercontent.com/DayuanJiang/next-ai-draw-io/main/docs/README_CN.md"&gt;‰∏≠Êñá&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/DayuanJiang/next-ai-draw-io/main/docs/README_JA.md"&gt;Êó•Êú¨Ë™û&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://next-ai-drawio.jiang.jp/"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/15449" alt="TrendShift" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://opensource.org/licenses/Apache-2.0"&gt;&lt;img src="https://img.shields.io/badge/License-Apache%202.0-blue.svg?sanitize=true" alt="License: Apache 2.0" /&gt;&lt;/a&gt; &lt;a href="https://nextjs.org/"&gt;&lt;img src="https://img.shields.io/badge/Next.js-16.x-black" alt="Next.js" /&gt;&lt;/a&gt; &lt;a href="https://react.dev/"&gt;&lt;img src="https://img.shields.io/badge/React-19.x-61dafb" alt="React" /&gt;&lt;/a&gt; &lt;a href="https://github.com/sponsors/DayuanJiang"&gt;&lt;img src="https://img.shields.io/badge/Sponsor-%E2%9D%A4-ea4aaa" alt="Sponsor" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://next-ai-drawio.jiang.jp/"&gt;&lt;img src="https://raw.githubusercontent.com/DayuanJiang/next-ai-draw-io/main/public/live-demo-button.svg?sanitize=true" alt="Live Demo" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;A Next.js web application that integrates AI capabilities with draw.io diagrams. Create, modify, and enhance diagrams through natural language commands and AI-assisted visualization.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/9d60a3e8-4a1c-4b5e-acbb-26af2d3eabd1"&gt;https://github.com/user-attachments/assets/9d60a3e8-4a1c-4b5e-acbb-26af2d3eabd1&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Table of Contents&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/DayuanJiang/next-ai-draw-io/main/#next-ai-drawio-"&gt;Next AI Draw.io &lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/DayuanJiang/next-ai-draw-io/main/#table-of-contents"&gt;Table of Contents&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/DayuanJiang/next-ai-draw-io/main/#examples"&gt;Examples&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/DayuanJiang/next-ai-draw-io/main/#features"&gt;Features&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/DayuanJiang/next-ai-draw-io/main/#getting-started"&gt;Getting Started&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/DayuanJiang/next-ai-draw-io/main/#try-it-online"&gt;Try it Online&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/DayuanJiang/next-ai-draw-io/main/#run-with-docker-recommended"&gt;Run with Docker (Recommended)&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/DayuanJiang/next-ai-draw-io/main/#installation"&gt;Installation&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/DayuanJiang/next-ai-draw-io/main/#deployment"&gt;Deployment&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/DayuanJiang/next-ai-draw-io/main/#multi-provider-support"&gt;Multi-Provider Support&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/DayuanJiang/next-ai-draw-io/main/#how-it-works"&gt;How It Works&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/DayuanJiang/next-ai-draw-io/main/#project-structure"&gt;Project Structure&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/DayuanJiang/next-ai-draw-io/main/#support--contact"&gt;Support &amp;amp; Contact&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/DayuanJiang/next-ai-draw-io/main/#star-history"&gt;Star History&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Examples&lt;/h2&gt; 
&lt;p&gt;Here are some example prompts and their generated diagrams:&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;table width="100%"&gt; 
  &lt;tbody&gt;
   &lt;tr&gt; 
    &lt;td colspan="2" valign="top" align="center"&gt; &lt;strong&gt;Animated transformer connectors&lt;/strong&gt;&lt;br /&gt; &lt;p&gt;&lt;strong&gt;Prompt:&lt;/strong&gt; Give me a **animated connector** diagram of transformer's architecture.&lt;/p&gt; &lt;img src="https://raw.githubusercontent.com/DayuanJiang/next-ai-draw-io/main/public/animated_connectors.svg?sanitize=true" alt="Transformer Architecture with Animated Connectors" width="480" /&gt; &lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td width="50%" valign="top"&gt; &lt;strong&gt;GCP architecture diagram&lt;/strong&gt;&lt;br /&gt; &lt;p&gt;&lt;strong&gt;Prompt:&lt;/strong&gt; Generate a GCP architecture diagram with **GCP icons**. In this diagram, users connect to a frontend hosted on an instance.&lt;/p&gt; &lt;img src="https://raw.githubusercontent.com/DayuanJiang/next-ai-draw-io/main/public/gcp_demo.svg?sanitize=true" alt="GCP Architecture Diagram" width="480" /&gt; &lt;/td&gt; 
    &lt;td width="50%" valign="top"&gt; &lt;strong&gt;AWS architecture diagram&lt;/strong&gt;&lt;br /&gt; &lt;p&gt;&lt;strong&gt;Prompt:&lt;/strong&gt; Generate a AWS architecture diagram with **AWS icons**. In this diagram, users connect to a frontend hosted on an instance.&lt;/p&gt; &lt;img src="https://raw.githubusercontent.com/DayuanJiang/next-ai-draw-io/main/public/aws_demo.svg?sanitize=true" alt="AWS Architecture Diagram" width="480" /&gt; &lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td width="50%" valign="top"&gt; &lt;strong&gt;Azure architecture diagram&lt;/strong&gt;&lt;br /&gt; &lt;p&gt;&lt;strong&gt;Prompt:&lt;/strong&gt; Generate a Azure architecture diagram with **Azure icons**. In this diagram, users connect to a frontend hosted on an instance.&lt;/p&gt; &lt;img src="https://raw.githubusercontent.com/DayuanJiang/next-ai-draw-io/main/public/azure_demo.svg?sanitize=true" alt="Azure Architecture Diagram" width="480" /&gt; &lt;/td&gt; 
    &lt;td width="50%" valign="top"&gt; &lt;strong&gt;Cat sketch prompt&lt;/strong&gt;&lt;br /&gt; &lt;p&gt;&lt;strong&gt;Prompt:&lt;/strong&gt; Draw a cute cat for me.&lt;/p&gt; &lt;img src="https://raw.githubusercontent.com/DayuanJiang/next-ai-draw-io/main/public/cat_demo.svg?sanitize=true" alt="Cat Drawing" width="240" /&gt; &lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt;
 &lt;/table&gt; 
&lt;/div&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;LLM-Powered Diagram Creation&lt;/strong&gt;: Leverage Large Language Models to create and manipulate draw.io diagrams directly through natural language commands&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Image-Based Diagram Replication&lt;/strong&gt;: Upload existing diagrams or images and have the AI replicate and enhance them automatically&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;PDF &amp;amp; Text File Upload&lt;/strong&gt;: Upload PDF documents and text files to extract content and generate diagrams from existing documents&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;AI Reasoning Display&lt;/strong&gt;: View the AI's thinking process for supported models (OpenAI o1/o3, Gemini, Claude, etc.)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Diagram History&lt;/strong&gt;: Comprehensive version control that tracks all changes, allowing you to view and restore previous versions of your diagrams before the AI editing.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Interactive Chat Interface&lt;/strong&gt;: Communicate with AI to refine your diagrams in real-time&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Cloud Architecture Diagram Support&lt;/strong&gt;: Specialized support for generating cloud architecture diagrams (AWS, GCP, Azure)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Animated Connectors&lt;/strong&gt;: Create dynamic and animated connectors between diagram elements for better visualization&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;h3&gt;Try it Online&lt;/h3&gt; 
&lt;p&gt;No installation needed! Try the app directly on our demo site:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://next-ai-drawio.jiang.jp/"&gt;&lt;img src="https://raw.githubusercontent.com/DayuanJiang/next-ai-draw-io/main/public/live-demo-button.svg?sanitize=true" alt="Live Demo" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Note: Due to high traffic, the demo site currently uses minimax-m2. For best results, we recommend self-hosting with Claude Sonnet 4.5 or Claude Opus 4.5.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Bring Your Own API Key&lt;/strong&gt;: You can use your own API key to bypass usage limits on the demo site. Click the Settings icon in the chat panel to configure your provider and API key. Your key is stored locally in your browser and is never stored on the server.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Run with Docker (Recommended)&lt;/h3&gt; 
&lt;p&gt;If you just want to run it locally, the best way is to use Docker.&lt;/p&gt; 
&lt;p&gt;First, install Docker if you haven't already: &lt;a href="https://docs.docker.com/get-docker/"&gt;Get Docker&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Then run:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run -d -p 3000:3000 \
  -e AI_PROVIDER=openai \
  -e AI_MODEL=gpt-4o \
  -e OPENAI_API_KEY=your_api_key \
  ghcr.io/dayuanjiang/next-ai-draw-io:latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or use an env file:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cp env.example .env
# Edit .env with your configuration
docker run -d -p 3000:3000 --env-file .env ghcr.io/dayuanjiang/next-ai-draw-io:latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Open &lt;a href="http://localhost:3000"&gt;http://localhost:3000&lt;/a&gt; in your browser.&lt;/p&gt; 
&lt;p&gt;Replace the environment variables with your preferred AI provider configuration. See &lt;a href="https://raw.githubusercontent.com/DayuanJiang/next-ai-draw-io/main/#multi-provider-support"&gt;Multi-Provider Support&lt;/a&gt; for available options.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Offline Deployment:&lt;/strong&gt; If &lt;code&gt;embed.diagrams.net&lt;/code&gt; is blocked, see &lt;a href="https://raw.githubusercontent.com/DayuanJiang/next-ai-draw-io/main/docs/offline-deployment.md"&gt;Offline Deployment&lt;/a&gt; for configuration options.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Installation&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Clone the repository:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/DayuanJiang/next-ai-draw-io
cd next-ai-draw-io
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Install dependencies:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;npm install
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt;Configure your AI provider:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Create a &lt;code&gt;.env.local&lt;/code&gt; file in the root directory:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cp env.example .env.local
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Edit &lt;code&gt;.env.local&lt;/code&gt; and configure your chosen provider:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Set &lt;code&gt;AI_PROVIDER&lt;/code&gt; to your chosen provider (bedrock, openai, anthropic, google, azure, ollama, openrouter, deepseek, siliconflow)&lt;/li&gt; 
 &lt;li&gt;Set &lt;code&gt;AI_MODEL&lt;/code&gt; to the specific model you want to use&lt;/li&gt; 
 &lt;li&gt;Add the required API keys for your provider&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;TEMPERATURE&lt;/code&gt;: Optional temperature setting (e.g., &lt;code&gt;0&lt;/code&gt; for deterministic output). Leave unset for models that don't support it (e.g., reasoning models).&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;ACCESS_CODE_LIST&lt;/code&gt;: Optional access password(s), can be comma-separated for multiple passwords.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Warning: If you do not set &lt;code&gt;ACCESS_CODE_LIST&lt;/code&gt;, anyone can access your deployed site directly, which may lead to rapid depletion of your token. It is recommended to set this option.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;See the &lt;a href="https://raw.githubusercontent.com/DayuanJiang/next-ai-draw-io/main/docs/ai-providers.md"&gt;Provider Configuration Guide&lt;/a&gt; for detailed setup instructions for each provider.&lt;/p&gt; 
&lt;ol start="4"&gt; 
 &lt;li&gt;Run the development server:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;npm run dev
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="5"&gt; 
 &lt;li&gt;Open &lt;a href="http://localhost:3000"&gt;http://localhost:3000&lt;/a&gt; in your browser to see the application.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Deployment&lt;/h2&gt; 
&lt;p&gt;The easiest way to deploy your Next.js app is to use the &lt;a href="https://vercel.com/new"&gt;Vercel Platform&lt;/a&gt; from the creators of Next.js.&lt;/p&gt; 
&lt;p&gt;Check out the &lt;a href="https://nextjs.org/docs/app/building-your-application/deploying"&gt;Next.js deployment documentation&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;p&gt;Or you can deploy by this button. &lt;a href="https://vercel.com/new/clone?repository-url=https%3A%2F%2Fgithub.com%2FDayuanJiang%2Fnext-ai-draw-io"&gt;&lt;img src="https://vercel.com/button" alt="Deploy with Vercel" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Be sure to &lt;strong&gt;set the environment variables&lt;/strong&gt; in the Vercel dashboard as you did in your local &lt;code&gt;.env.local&lt;/code&gt; file.&lt;/p&gt; 
&lt;h2&gt;Multi-Provider Support&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;AWS Bedrock (default)&lt;/li&gt; 
 &lt;li&gt;OpenAI&lt;/li&gt; 
 &lt;li&gt;Anthropic&lt;/li&gt; 
 &lt;li&gt;Google AI&lt;/li&gt; 
 &lt;li&gt;Azure OpenAI&lt;/li&gt; 
 &lt;li&gt;Ollama&lt;/li&gt; 
 &lt;li&gt;OpenRouter&lt;/li&gt; 
 &lt;li&gt;DeepSeek&lt;/li&gt; 
 &lt;li&gt;SiliconFlow&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;All providers except AWS Bedrock and OpenRouter support custom endpoints.&lt;/p&gt; 
&lt;p&gt;üìñ &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/DayuanJiang/next-ai-draw-io/main/docs/ai-providers.md"&gt;Detailed Provider Configuration Guide&lt;/a&gt;&lt;/strong&gt; - See setup instructions for each provider.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Model Requirements&lt;/strong&gt;: This task requires strong model capabilities for generating long-form text with strict formatting constraints (draw.io XML). Recommended models include Claude Sonnet 4.5, GPT-5.1, Gemini 3 Pro, and DeepSeek V3.2/R1.&lt;/p&gt; 
&lt;p&gt;Note that &lt;code&gt;claude&lt;/code&gt; series has trained on draw.io diagrams with cloud architecture logos like AWS, Azue, GCP. So if you want to create cloud architecture diagrams, this is the best choice.&lt;/p&gt; 
&lt;h2&gt;How It Works&lt;/h2&gt; 
&lt;p&gt;The application uses the following technologies:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Next.js&lt;/strong&gt;: For the frontend framework and routing&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Vercel AI SDK&lt;/strong&gt; (&lt;code&gt;ai&lt;/code&gt; + &lt;code&gt;@ai-sdk/*&lt;/code&gt;): For streaming AI responses and multi-provider support&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;react-drawio&lt;/strong&gt;: For diagram representation and manipulation&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Diagrams are represented as XML that can be rendered in draw.io. The AI processes your commands and generates or modifies this XML accordingly.&lt;/p&gt; 
&lt;h2&gt;Project Structure&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;app/                  # Next.js App Router
  api/chat/           # Chat API endpoint with AI tools
  page.tsx            # Main page with DrawIO embed
components/           # React components
  chat-panel.tsx      # Chat interface with diagram control
  chat-input.tsx      # User input component with file upload
  history-dialog.tsx  # Diagram version history viewer
  ui/                 # UI components (buttons, cards, etc.)
contexts/             # React context providers
  diagram-context.tsx # Global diagram state management
lib/                  # Utility functions and helpers
  ai-providers.ts     # Multi-provider AI configuration
  utils.ts            # XML processing and conversion utilities
public/               # Static assets including example images
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Support &amp;amp; Contact&lt;/h2&gt; 
&lt;p&gt;If you find this project useful, please consider &lt;a href="https://github.com/sponsors/DayuanJiang"&gt;sponsoring&lt;/a&gt; to help me host the live demo site!&lt;/p&gt; 
&lt;p&gt;For support or inquiries, please open an issue on the GitHub repository or contact the maintainer at:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Email: me[at]jiang.jp&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Star History&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://www.star-history.com/#DayuanJiang/next-ai-draw-io&amp;amp;type=date&amp;amp;legend=top-left"&gt;&lt;img src="https://api.star-history.com/svg?repos=DayuanJiang/next-ai-draw-io&amp;amp;type=date&amp;amp;legend=top-left" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt;</description>
    </item>
    
    <item>
      <title>ChromeDevTools/chrome-devtools-mcp</title>
      <link>https://github.com/ChromeDevTools/chrome-devtools-mcp</link>
      <description>&lt;p&gt;Chrome DevTools for coding agents&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Chrome DevTools MCP&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://npmjs.org/package/chrome-devtools-mcp"&gt;&lt;img src="https://img.shields.io/npm/v/chrome-devtools-mcp.svg?sanitize=true" alt="npm chrome-devtools-mcp package" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;chrome-devtools-mcp&lt;/code&gt; lets your coding agent (such as Gemini, Claude, Cursor or Copilot) control and inspect a live Chrome browser. It acts as a Model-Context-Protocol (MCP) server, giving your AI coding assistant access to the full power of Chrome DevTools for reliable automation, in-depth debugging, and performance analysis.&lt;/p&gt; 
&lt;h2&gt;&lt;a href="https://raw.githubusercontent.com/ChromeDevTools/chrome-devtools-mcp/main/docs/tool-reference.md"&gt;Tool reference&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/ChromeDevTools/chrome-devtools-mcp/main/CHANGELOG.md"&gt;Changelog&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/ChromeDevTools/chrome-devtools-mcp/main/CONTRIBUTING.md"&gt;Contributing&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/ChromeDevTools/chrome-devtools-mcp/main/docs/troubleshooting.md"&gt;Troubleshooting&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/ChromeDevTools/chrome-devtools-mcp/main/docs/design-principles.md"&gt;Design Principles&lt;/a&gt;&lt;/h2&gt; 
&lt;h2&gt;Key features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Get performance insights&lt;/strong&gt;: Uses &lt;a href="https://github.com/ChromeDevTools/devtools-frontend"&gt;Chrome DevTools&lt;/a&gt; to record traces and extract actionable performance insights.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Advanced browser debugging&lt;/strong&gt;: Analyze network requests, take screenshots and check the browser console.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Reliable automation&lt;/strong&gt;. Uses &lt;a href="https://github.com/puppeteer/puppeteer"&gt;puppeteer&lt;/a&gt; to automate actions in Chrome and automatically wait for action results.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Disclaimers&lt;/h2&gt; 
&lt;p&gt;&lt;code&gt;chrome-devtools-mcp&lt;/code&gt; exposes content of the browser instance to the MCP clients allowing them to inspect, debug, and modify any data in the browser or DevTools. Avoid sharing sensitive or personal information that you don't want to share with MCP clients.&lt;/p&gt; 
&lt;h2&gt;Requirements&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://nodejs.org/"&gt;Node.js&lt;/a&gt; v20.19 or a newer &lt;a href="https://github.com/nodejs/Release#release-schedule"&gt;latest maintenance LTS&lt;/a&gt; version.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.google.com/chrome/"&gt;Chrome&lt;/a&gt; current stable version or newer.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.npmjs.com/"&gt;npm&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Getting started&lt;/h2&gt; 
&lt;p&gt;Add the following config to your MCP client:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "mcpServers": {
    "chrome-devtools": {
      "command": "npx",
      "args": ["-y", "chrome-devtools-mcp@latest"]
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE]&lt;br /&gt; Using &lt;code&gt;chrome-devtools-mcp@latest&lt;/code&gt; ensures that your MCP client will always use the latest version of the Chrome DevTools MCP server.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;MCP Client configuration&lt;/h3&gt; 
&lt;details&gt; 
 &lt;summary&gt;Amp&lt;/summary&gt; Follow https://ampcode.com/manual#mcp and use the config provided above. You can also install the Chrome DevTools MCP server using the CLI: 
 &lt;pre&gt;&lt;code class="language-bash"&gt;amp mcp add chrome-devtools -- npx chrome-devtools-mcp@latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Antigravity&lt;/summary&gt; 
 &lt;p&gt;To use the Chrome DevTools MCP server follow the instructions from &lt;a href="https://antigravity.google/docs/mcp"&gt;Antigravity's docs&lt;/a&gt;&lt;a&gt;&lt;/a&gt; to install a custom MCP server. Add the following config to the MCP servers config:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;{
  "mcpServers": {
    "chrome-devtools": {
      "command": "npx",
      "args": [
        "chrome-devtools-mcp@latest",
        "--browser-url=http://127.0.0.1:9222",
        "-y"
      ]
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;This will make the Chrome DevTools MCP server automatically connect to the browser that Antigravity is using. If you are not using port 9222, make sure to adjust accordingly.&lt;/p&gt; 
 &lt;p&gt;Chrome DevTools MCP will not start the browser instance automatically using this approach as as the Chrome DevTools MCP server runs in Antigravity's built-in browser. If the browser is not already running, you have to start it first by clicking the Chrome icon at the top right corner.&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Claude Code&lt;/summary&gt; Use the Claude Code CLI to add the Chrome DevTools MCP server (
 &lt;a href="https://docs.anthropic.com/en/docs/claude-code/mcp"&gt;guide&lt;/a&gt;): 
 &lt;pre&gt;&lt;code class="language-bash"&gt;claude mcp add chrome-devtools npx chrome-devtools-mcp@latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Cline&lt;/summary&gt; Follow https://docs.cline.bot/mcp/configuring-mcp-servers and use the config provided above. 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Codex&lt;/summary&gt; Follow the 
 &lt;a href="https://github.com/openai/codex/raw/main/docs/advanced.md#model-context-protocol-mcp"&gt;configure MCP guide&lt;/a&gt; using the standard config from above. You can also install the Chrome DevTools MCP server using the Codex CLI: 
 &lt;pre&gt;&lt;code class="language-bash"&gt;codex mcp add chrome-devtools -- npx chrome-devtools-mcp@latest
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;On Windows 11&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;Configure the Chrome install location and increase the startup timeout by updating &lt;code&gt;.codex/config.toml&lt;/code&gt; and adding the following &lt;code&gt;env&lt;/code&gt; and &lt;code&gt;startup_timeout_ms&lt;/code&gt; parameters:&lt;/p&gt; 
 &lt;pre&gt;&lt;code&gt;[mcp_servers.chrome-devtools]
command = "cmd"
args = [
    "/c",
    "npx",
    "-y",
    "chrome-devtools-mcp@latest",
]
env = { SystemRoot="C:\\Windows", PROGRAMFILES="C:\\Program Files" }
startup_timeout_ms = 20_000
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Copilot CLI&lt;/summary&gt; 
 &lt;p&gt;Start Copilot CLI:&lt;/p&gt; 
 &lt;pre&gt;&lt;code&gt;copilot
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Start the dialog to add a new MCP server by running:&lt;/p&gt; 
 &lt;pre&gt;&lt;code&gt;/mcp add
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Configure the following fields and press &lt;code&gt;CTRL+S&lt;/code&gt; to save the configuration:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;Server name:&lt;/strong&gt; &lt;code&gt;chrome-devtools&lt;/code&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Server Type:&lt;/strong&gt; &lt;code&gt;[1] Local&lt;/code&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Command:&lt;/strong&gt; &lt;code&gt;npx -y chrome-devtools-mcp@latest&lt;/code&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Copilot / VS Code&lt;/summary&gt; 
 &lt;p&gt;&lt;strong&gt;Click the button to install:&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://vscode.dev/redirect/mcp/install?name=io.github.ChromeDevTools%2Fchrome-devtools-mcp&amp;amp;config=%7B%22command%22%3A%22npx%22%2C%22args%22%3A%5B%22-y%22%2C%22chrome-devtools-mcp%22%5D%2C%22env%22%3A%7B%7D%7D"&gt;&lt;img src="https://img.shields.io/badge/VS_Code-VS_Code?style=flat-square&amp;amp;label=Install%20Server&amp;amp;color=0098FF" alt="Install in VS Code" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://insiders.vscode.dev/redirect?url=vscode-insiders%3Amcp%2Finstall%3F%257B%2522name%2522%253A%2522io.github.ChromeDevTools%252Fchrome-devtools-mcp%2522%252C%2522config%2522%253A%257B%2522command%2522%253A%2522npx%2522%252C%2522args%2522%253A%255B%2522-y%2522%252C%2522chrome-devtools-mcp%2522%255D%252C%2522env%2522%253A%257B%257D%257D%257D"&gt;&lt;img src="https://img.shields.io/badge/VS_Code_Insiders-VS_Code_Insiders?style=flat-square&amp;amp;label=Install%20Server&amp;amp;color=24bfa5" alt="Install in VS Code Insiders" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Or install manually:&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;Follow the MCP install &lt;a href="https://code.visualstudio.com/docs/copilot/chat/mcp-servers#_add-an-mcp-server"&gt;guide&lt;/a&gt;, with the standard config from above. You can also install the Chrome DevTools MCP server using the VS Code CLI:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;code --add-mcp '{"name":"io.github.ChromeDevTools/chrome-devtools-mcp","command":"npx","args":["-y","chrome-devtools-mcp"],"env":{}}'
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Cursor&lt;/summary&gt; 
 &lt;p&gt;&lt;strong&gt;Click the button to install:&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://cursor.com/en/install-mcp?name=chrome-devtools&amp;amp;config=eyJjb21tYW5kIjoibnB4IC15IGNocm9tZS1kZXZ0b29scy1tY3BAbGF0ZXN0In0%3D"&gt;&lt;img src="https://cursor.com/deeplink/mcp-install-dark.svg?sanitize=true" alt="Install in Cursor" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Or install manually:&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;Go to &lt;code&gt;Cursor Settings&lt;/code&gt; -&amp;gt; &lt;code&gt;MCP&lt;/code&gt; -&amp;gt; &lt;code&gt;New MCP Server&lt;/code&gt;. Use the config provided above.&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Factory CLI&lt;/summary&gt; Use the Factory CLI to add the Chrome DevTools MCP server (
 &lt;a href="https://docs.factory.ai/cli/configuration/mcp"&gt;guide&lt;/a&gt;): 
 &lt;pre&gt;&lt;code class="language-bash"&gt;droid mcp add chrome-devtools "npx -y chrome-devtools-mcp@latest"
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Gemini CLI&lt;/summary&gt; Install the Chrome DevTools MCP server using the Gemini CLI. 
 &lt;p&gt;&lt;strong&gt;Project wide:&lt;/strong&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;gemini mcp add chrome-devtools npx chrome-devtools-mcp@latest
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;Globally:&lt;/strong&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;gemini mcp add -s user chrome-devtools npx chrome-devtools-mcp@latest
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Alternatively, follow the &lt;a href="https://github.com/google-gemini/gemini-cli/raw/main/docs/tools/mcp-server.md#how-to-set-up-your-mcp-server"&gt;MCP guide&lt;/a&gt; and use the standard config from above.&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Gemini Code Assist&lt;/summary&gt; Follow the 
 &lt;a href="https://cloud.google.com/gemini/docs/codeassist/use-agentic-chat-pair-programmer#configure-mcp-servers"&gt;configure MCP guide&lt;/a&gt; using the standard config from above. 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;JetBrains AI Assistant &amp;amp; Junie&lt;/summary&gt; 
 &lt;p&gt;Go to &lt;code&gt;Settings | Tools | AI Assistant | Model Context Protocol (MCP)&lt;/code&gt; -&amp;gt; &lt;code&gt;Add&lt;/code&gt;. Use the config provided above. The same way chrome-devtools-mcp can be configured for JetBrains Junie in &lt;code&gt;Settings | Tools | Junie | MCP Settings&lt;/code&gt; -&amp;gt; &lt;code&gt;Add&lt;/code&gt;. Use the config provided above.&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Kiro&lt;/summary&gt; 
 &lt;p&gt;In &lt;strong&gt;Kiro Settings&lt;/strong&gt;, go to &lt;code&gt;Configure MCP&lt;/code&gt; &amp;gt; &lt;code&gt;Open Workspace or User MCP Config&lt;/code&gt; &amp;gt; Use the configuration snippet provided above.&lt;/p&gt; 
 &lt;p&gt;Or, from the IDE &lt;strong&gt;Activity Bar&lt;/strong&gt; &amp;gt; &lt;code&gt;Kiro&lt;/code&gt; &amp;gt; &lt;code&gt;MCP Servers&lt;/code&gt; &amp;gt; &lt;code&gt;Click Open MCP Config&lt;/code&gt;. Use the configuration snippet provided above.&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Qoder&lt;/summary&gt; 
 &lt;p&gt;In &lt;strong&gt;Qoder Settings&lt;/strong&gt;, go to &lt;code&gt;MCP Server&lt;/code&gt; &amp;gt; &lt;code&gt;+ Add&lt;/code&gt; &amp;gt; Use the configuration snippet provided above.&lt;/p&gt; 
 &lt;p&gt;Alternatively, follow the &lt;a href="https://docs.qoder.com/user-guide/chat/model-context-protocol"&gt;MCP guide&lt;/a&gt; and use the standard config from above.&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Qoder CLI&lt;/summary&gt; 
 &lt;p&gt;Install the Chrome DevTools MCP server using the Qoder CLI (&lt;a href="https://docs.qoder.com/cli/using-cli#mcp-servsers"&gt;guide&lt;/a&gt;):&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Project wide:&lt;/strong&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;qodercli mcp add chrome-devtools -- npx chrome-devtools-mcp@latest
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;Globally:&lt;/strong&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;qodercli mcp add -s user chrome-devtools -- npx chrome-devtools-mcp@latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Visual Studio&lt;/summary&gt; 
 &lt;p&gt;&lt;strong&gt;Click the button to install:&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://vs-open.link/mcp-install?%7B%22name%22%3A%22chrome-devtools%22%2C%22command%22%3A%22npx%22%2C%22args%22%3A%5B%22chrome-devtools-mcp%40latest%22%5D%7D"&gt;&lt;img src="https://img.shields.io/badge/Visual_Studio-Install-C16FDE?logo=visualstudio&amp;amp;logoColor=white" alt="Install in Visual Studio" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Warp&lt;/summary&gt; 
 &lt;p&gt;Go to &lt;code&gt;Settings | AI | Manage MCP Servers&lt;/code&gt; -&amp;gt; &lt;code&gt;+ Add&lt;/code&gt; to &lt;a href="https://docs.warp.dev/knowledge-and-collaboration/mcp#adding-an-mcp-server"&gt;add an MCP Server&lt;/a&gt;. Use the config provided above.&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Windsurf&lt;/summary&gt; Follow the 
 &lt;a href="https://docs.windsurf.com/windsurf/cascade/mcp#mcp-config-json"&gt;configure MCP guide&lt;/a&gt; using the standard config from above. 
&lt;/details&gt; 
&lt;h3&gt;Your first prompt&lt;/h3&gt; 
&lt;p&gt;Enter the following prompt in your MCP Client to check if everything is working:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Check the performance of https://developers.chrome.com
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Your MCP client should open the browser and record a performance trace.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE]&lt;br /&gt; The MCP server will start the browser automatically once the MCP client uses a tool that requires a running browser instance. Connecting to the Chrome DevTools MCP server on its own will not automatically start the browser.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Tools&lt;/h2&gt; 
&lt;p&gt;If you run into any issues, checkout our &lt;a href="https://raw.githubusercontent.com/ChromeDevTools/chrome-devtools-mcp/main/docs/troubleshooting.md"&gt;troubleshooting guide&lt;/a&gt;.&lt;/p&gt; 
&lt;!-- BEGIN AUTO GENERATED TOOLS --&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Input automation&lt;/strong&gt; (8 tools) 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ChromeDevTools/chrome-devtools-mcp/main/docs/tool-reference.md#click"&gt;&lt;code&gt;click&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ChromeDevTools/chrome-devtools-mcp/main/docs/tool-reference.md#drag"&gt;&lt;code&gt;drag&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ChromeDevTools/chrome-devtools-mcp/main/docs/tool-reference.md#fill"&gt;&lt;code&gt;fill&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ChromeDevTools/chrome-devtools-mcp/main/docs/tool-reference.md#fill_form"&gt;&lt;code&gt;fill_form&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ChromeDevTools/chrome-devtools-mcp/main/docs/tool-reference.md#handle_dialog"&gt;&lt;code&gt;handle_dialog&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ChromeDevTools/chrome-devtools-mcp/main/docs/tool-reference.md#hover"&gt;&lt;code&gt;hover&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ChromeDevTools/chrome-devtools-mcp/main/docs/tool-reference.md#press_key"&gt;&lt;code&gt;press_key&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ChromeDevTools/chrome-devtools-mcp/main/docs/tool-reference.md#upload_file"&gt;&lt;code&gt;upload_file&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Navigation automation&lt;/strong&gt; (6 tools) 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ChromeDevTools/chrome-devtools-mcp/main/docs/tool-reference.md#close_page"&gt;&lt;code&gt;close_page&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ChromeDevTools/chrome-devtools-mcp/main/docs/tool-reference.md#list_pages"&gt;&lt;code&gt;list_pages&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ChromeDevTools/chrome-devtools-mcp/main/docs/tool-reference.md#navigate_page"&gt;&lt;code&gt;navigate_page&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ChromeDevTools/chrome-devtools-mcp/main/docs/tool-reference.md#new_page"&gt;&lt;code&gt;new_page&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ChromeDevTools/chrome-devtools-mcp/main/docs/tool-reference.md#select_page"&gt;&lt;code&gt;select_page&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ChromeDevTools/chrome-devtools-mcp/main/docs/tool-reference.md#wait_for"&gt;&lt;code&gt;wait_for&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Emulation&lt;/strong&gt; (2 tools) 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ChromeDevTools/chrome-devtools-mcp/main/docs/tool-reference.md#emulate"&gt;&lt;code&gt;emulate&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ChromeDevTools/chrome-devtools-mcp/main/docs/tool-reference.md#resize_page"&gt;&lt;code&gt;resize_page&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Performance&lt;/strong&gt; (3 tools) 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ChromeDevTools/chrome-devtools-mcp/main/docs/tool-reference.md#performance_analyze_insight"&gt;&lt;code&gt;performance_analyze_insight&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ChromeDevTools/chrome-devtools-mcp/main/docs/tool-reference.md#performance_start_trace"&gt;&lt;code&gt;performance_start_trace&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ChromeDevTools/chrome-devtools-mcp/main/docs/tool-reference.md#performance_stop_trace"&gt;&lt;code&gt;performance_stop_trace&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Network&lt;/strong&gt; (2 tools) 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ChromeDevTools/chrome-devtools-mcp/main/docs/tool-reference.md#get_network_request"&gt;&lt;code&gt;get_network_request&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ChromeDevTools/chrome-devtools-mcp/main/docs/tool-reference.md#list_network_requests"&gt;&lt;code&gt;list_network_requests&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Debugging&lt;/strong&gt; (5 tools) 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ChromeDevTools/chrome-devtools-mcp/main/docs/tool-reference.md#evaluate_script"&gt;&lt;code&gt;evaluate_script&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ChromeDevTools/chrome-devtools-mcp/main/docs/tool-reference.md#get_console_message"&gt;&lt;code&gt;get_console_message&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ChromeDevTools/chrome-devtools-mcp/main/docs/tool-reference.md#list_console_messages"&gt;&lt;code&gt;list_console_messages&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ChromeDevTools/chrome-devtools-mcp/main/docs/tool-reference.md#take_screenshot"&gt;&lt;code&gt;take_screenshot&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ChromeDevTools/chrome-devtools-mcp/main/docs/tool-reference.md#take_snapshot"&gt;&lt;code&gt;take_snapshot&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;!-- END AUTO GENERATED TOOLS --&gt; 
&lt;h2&gt;Configuration&lt;/h2&gt; 
&lt;p&gt;The Chrome DevTools MCP server supports the following configuration option:&lt;/p&gt; 
&lt;!-- BEGIN AUTO GENERATED OPTIONS --&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;--autoConnect&lt;/code&gt;/ &lt;code&gt;--auto-connect&lt;/code&gt;&lt;/strong&gt; If specified, automatically connects to a browser (Chrome 145+) running in the user data directory identified by the channel param. Requires remote debugging being enabled in Chrome here: chrome://inspect/#remote-debugging.&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Type:&lt;/strong&gt; boolean&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Default:&lt;/strong&gt; &lt;code&gt;false&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;--browserUrl&lt;/code&gt;/ &lt;code&gt;--browser-url&lt;/code&gt;, &lt;code&gt;-u&lt;/code&gt;&lt;/strong&gt; Connect to a running, debuggable Chrome instance (e.g. &lt;code&gt;http://127.0.0.1:9222&lt;/code&gt;). For more details see: &lt;a href="https://github.com/ChromeDevTools/chrome-devtools-mcp#connecting-to-a-running-chrome-instance"&gt;https://github.com/ChromeDevTools/chrome-devtools-mcp#connecting-to-a-running-chrome-instance&lt;/a&gt;.&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Type:&lt;/strong&gt; string&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;--wsEndpoint&lt;/code&gt;/ &lt;code&gt;--ws-endpoint&lt;/code&gt;, &lt;code&gt;-w&lt;/code&gt;&lt;/strong&gt; WebSocket endpoint to connect to a running Chrome instance (e.g., ws://127.0.0.1:9222/devtools/browser/
   &lt;id&gt;
    ). Alternative to --browserUrl.
   &lt;/id&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Type:&lt;/strong&gt; string&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;--wsHeaders&lt;/code&gt;/ &lt;code&gt;--ws-headers&lt;/code&gt;&lt;/strong&gt; Custom headers for WebSocket connection in JSON format (e.g., '{"Authorization":"Bearer token"}'). Only works with --wsEndpoint.&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Type:&lt;/strong&gt; string&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;--headless&lt;/code&gt;&lt;/strong&gt; Whether to run in headless (no UI) mode.&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Type:&lt;/strong&gt; boolean&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Default:&lt;/strong&gt; &lt;code&gt;false&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;--executablePath&lt;/code&gt;/ &lt;code&gt;--executable-path&lt;/code&gt;, &lt;code&gt;-e&lt;/code&gt;&lt;/strong&gt; Path to custom Chrome executable.&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Type:&lt;/strong&gt; string&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;--isolated&lt;/code&gt;&lt;/strong&gt; If specified, creates a temporary user-data-dir that is automatically cleaned up after the browser is closed. Defaults to false.&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Type:&lt;/strong&gt; boolean&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;--userDataDir&lt;/code&gt;/ &lt;code&gt;--user-data-dir&lt;/code&gt;&lt;/strong&gt; Path to the user data directory for Chrome. Default is $HOME/.cache/chrome-devtools-mcp/chrome-profile$CHANNEL_SUFFIX_IF_NON_STABLE&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Type:&lt;/strong&gt; string&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;--channel&lt;/code&gt;&lt;/strong&gt; Specify a different Chrome channel that should be used. The default is the stable channel version.&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Type:&lt;/strong&gt; string&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Choices:&lt;/strong&gt; &lt;code&gt;stable&lt;/code&gt;, &lt;code&gt;canary&lt;/code&gt;, &lt;code&gt;beta&lt;/code&gt;, &lt;code&gt;dev&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;--logFile&lt;/code&gt;/ &lt;code&gt;--log-file&lt;/code&gt;&lt;/strong&gt; Path to a file to write debug logs to. Set the env variable &lt;code&gt;DEBUG&lt;/code&gt; to &lt;code&gt;*&lt;/code&gt; to enable verbose logs. Useful for submitting bug reports.&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Type:&lt;/strong&gt; string&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;--viewport&lt;/code&gt;&lt;/strong&gt; Initial viewport size for the Chrome instances started by the server. For example, &lt;code&gt;1280x720&lt;/code&gt;. In headless mode, max size is 3840x2160px.&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Type:&lt;/strong&gt; string&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;--proxyServer&lt;/code&gt;/ &lt;code&gt;--proxy-server&lt;/code&gt;&lt;/strong&gt; Proxy server configuration for Chrome passed as --proxy-server when launching the browser. See &lt;a href="https://www.chromium.org/developers/design-documents/network-settings/"&gt;https://www.chromium.org/developers/design-documents/network-settings/&lt;/a&gt; for details.&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Type:&lt;/strong&gt; string&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;--acceptInsecureCerts&lt;/code&gt;/ &lt;code&gt;--accept-insecure-certs&lt;/code&gt;&lt;/strong&gt; If enabled, ignores errors relative to self-signed and expired certificates. Use with caution.&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Type:&lt;/strong&gt; boolean&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;--chromeArg&lt;/code&gt;/ &lt;code&gt;--chrome-arg&lt;/code&gt;&lt;/strong&gt; Additional arguments for Chrome. Only applies when Chrome is launched by chrome-devtools-mcp.&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Type:&lt;/strong&gt; array&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;--categoryEmulation&lt;/code&gt;/ &lt;code&gt;--category-emulation&lt;/code&gt;&lt;/strong&gt; Set to false to exclude tools related to emulation.&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Type:&lt;/strong&gt; boolean&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Default:&lt;/strong&gt; &lt;code&gt;true&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;--categoryPerformance&lt;/code&gt;/ &lt;code&gt;--category-performance&lt;/code&gt;&lt;/strong&gt; Set to false to exclude tools related to performance.&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Type:&lt;/strong&gt; boolean&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Default:&lt;/strong&gt; &lt;code&gt;true&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;--categoryNetwork&lt;/code&gt;/ &lt;code&gt;--category-network&lt;/code&gt;&lt;/strong&gt; Set to false to exclude tools related to network.&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Type:&lt;/strong&gt; boolean&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Default:&lt;/strong&gt; &lt;code&gt;true&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;!-- END AUTO GENERATED OPTIONS --&gt; 
&lt;p&gt;Pass them via the &lt;code&gt;args&lt;/code&gt; property in the JSON configuration. For example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "mcpServers": {
    "chrome-devtools": {
      "command": "npx",
      "args": [
        "chrome-devtools-mcp@latest",
        "--channel=canary",
        "--headless=true",
        "--isolated=true"
      ]
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Connecting via WebSocket with custom headers&lt;/h3&gt; 
&lt;p&gt;You can connect directly to a Chrome WebSocket endpoint and include custom headers (e.g., for authentication):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "mcpServers": {
    "chrome-devtools": {
      "command": "npx",
      "args": [
        "chrome-devtools-mcp@latest",
        "--wsEndpoint=ws://127.0.0.1:9222/devtools/browser/&amp;lt;id&amp;gt;",
        "--wsHeaders={\"Authorization\":\"Bearer YOUR_TOKEN\"}"
      ]
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To get the WebSocket endpoint from a running Chrome instance, visit &lt;code&gt;http://127.0.0.1:9222/json/version&lt;/code&gt; and look for the &lt;code&gt;webSocketDebuggerUrl&lt;/code&gt; field.&lt;/p&gt; 
&lt;p&gt;You can also run &lt;code&gt;npx chrome-devtools-mcp@latest --help&lt;/code&gt; to see all available configuration options.&lt;/p&gt; 
&lt;h2&gt;Concepts&lt;/h2&gt; 
&lt;h3&gt;User data directory&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;chrome-devtools-mcp&lt;/code&gt; starts a Chrome's stable channel instance using the following user data directory:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Linux / macOS: &lt;code&gt;$HOME/.cache/chrome-devtools-mcp/chrome-profile-$CHANNEL&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Windows: &lt;code&gt;%HOMEPATH%/.cache/chrome-devtools-mcp/chrome-profile-$CHANNEL&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The user data directory is not cleared between runs and shared across all instances of &lt;code&gt;chrome-devtools-mcp&lt;/code&gt;. Set the &lt;code&gt;isolated&lt;/code&gt; option to &lt;code&gt;true&lt;/code&gt; to use a temporary user data dir instead which will be cleared automatically after the browser is closed.&lt;/p&gt; 
&lt;h3&gt;Connecting to a running Chrome instance&lt;/h3&gt; 
&lt;p&gt;By default, the Chrome DevTools MCP server will start a new Chrome instance with a dedicated profile. This might not be ideal in all situations:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;If you would like to maintain the same application state when alternating between manual site testing and agent-driven testing.&lt;/li&gt; 
 &lt;li&gt;When the MCP needs to sign into a website. Some accounts may prevent sign-in when the browser is controlled via WebDriver (the default launch mechanism for the Chrome DevTools MCP server).&lt;/li&gt; 
 &lt;li&gt;If you're running your LLM inside a sandboxed environment, but you would like to connect to a Chrome instance that runs outside the sandbox.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;In these cases, start Chrome first and let the Chrome DevTools MCP server connect to it. There are two ways to do so:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Automatic connection (available in Chrome 144)&lt;/strong&gt;: best for sharing state between manual and agent-driven testing.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Manual connection via remote debugging port&lt;/strong&gt;: best when running inside a sandboxed environment.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Automatically connecting to a running Chrome instance&lt;/h4&gt; 
&lt;p&gt;&lt;strong&gt;Step 1:&lt;/strong&gt; Set up remote debugging in Chrome&lt;/p&gt; 
&lt;p&gt;In Chrome, do the following to set up remote debugging:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Navigate to &lt;code&gt;chrome://inspect/#remote-debugging&lt;/code&gt; to enable remote debugging.&lt;/li&gt; 
 &lt;li&gt;Follow the dialog UI to allow or disallow incoming debugging connections.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;Step 2:&lt;/strong&gt; Configure Chrome DevTools MCP server to automatically connect to a running Chrome Instance&lt;/p&gt; 
&lt;p&gt;To connect the &lt;code&gt;chrome-devtools-mcp&lt;/code&gt; server to the running Chrome instance, use &lt;code&gt;--autoConnect&lt;/code&gt; command line argument for the MCP server.&lt;/p&gt; 
&lt;p&gt;The following code snippet is an example configuration for gemini-cli:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "mcpServers": {
    "chrome-devtools": {
      "command": "npx",
      "args": [
        "chrome-devtools-mcp@latest",
        "--autoConnect",
        "--channel=canary"
      ]
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Note: you have to specify &lt;code&gt;--channel=canary&lt;/code&gt; until Chrome M144 has reached the stable channel.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Step 3:&lt;/strong&gt; Test your setup&lt;/p&gt; 
&lt;p&gt;Make sure your browser is running. Open gemini-cli and run the following prompt:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-none"&gt;Check the performance of https://developers.chrome.com
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Note: The &lt;code&gt;autoConnect&lt;/code&gt; option requires the user to start Chrome.&lt;/p&gt; 
&lt;p&gt;The Chrome DevTools MCP server will try to connect to your running Chrome instance. It shows a dialog asking for user permission.&lt;/p&gt; 
&lt;p&gt;Clicking &lt;strong&gt;Allow&lt;/strong&gt; results in the Chrome DevTools MCP server opening &lt;a href="http://developers.chrome.com"&gt;developers.chrome.com&lt;/a&gt; and taking a performance trace.&lt;/p&gt; 
&lt;h4&gt;Manual connection using port forwarding&lt;/h4&gt; 
&lt;p&gt;You can connect to a running Chrome instance by using the &lt;code&gt;--browser-url&lt;/code&gt; option. This is useful if you are running the MCP server in a sandboxed environment that does not allow starting a new Chrome instance.&lt;/p&gt; 
&lt;p&gt;Here is a step-by-step guide on how to connect to a running Chrome instance:&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Step 1: Configure the MCP client&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Add the &lt;code&gt;--browser-url&lt;/code&gt; option to your MCP client configuration. The value of this option should be the URL of the running Chrome instance. &lt;code&gt;http://127.0.0.1:9222&lt;/code&gt; is a common default.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "mcpServers": {
    "chrome-devtools": {
      "command": "npx",
      "args": [
        "chrome-devtools-mcp@latest",
        "--browser-url=http://127.0.0.1:9222"
      ]
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Step 2: Start the Chrome browser&lt;/strong&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!WARNING]&lt;br /&gt; Enabling the remote debugging port opens up a debugging port on the running browser instance. Any application on your machine can connect to this port and control the browser. Make sure that you are not browsing any sensitive websites while the debugging port is open.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Start the Chrome browser with the remote debugging port enabled. Make sure to close any running Chrome instances before starting a new one with the debugging port enabled. The port number you choose must be the same as the one you specified in the &lt;code&gt;--browser-url&lt;/code&gt; option in your MCP client configuration.&lt;/p&gt; 
&lt;p&gt;For security reasons, &lt;a href="https://developer.chrome.com/blog/remote-debugging-port"&gt;Chrome requires you to use a non-default user data directory&lt;/a&gt; when enabling the remote debugging port. You can specify a custom directory using the &lt;code&gt;--user-data-dir&lt;/code&gt; flag. This ensures that your regular browsing profile and data are not exposed to the debugging session.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;macOS&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;/Applications/Google\ Chrome.app/Contents/MacOS/Google\ Chrome --remote-debugging-port=9222 --user-data-dir=/tmp/chrome-profile-stable
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Linux&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;/usr/bin/google-chrome --remote-debugging-port=9222 --user-data-dir=/tmp/chrome-profile-stable
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Windows&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;"C:\Program Files\Google\Chrome\Application\chrome.exe" --remote-debugging-port=9222 --user-data-dir="%TEMP%\chrome-profile-stable"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Step 3: Test your setup&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;After configuring the MCP client and starting the Chrome browser, you can test your setup by running a simple prompt in your MCP client:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Check the performance of https://developers.chrome.com
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Your MCP client should connect to the running Chrome instance and receive a performance report.&lt;/p&gt; 
&lt;p&gt;If you hit VM-to-host port forwarding issues, see the ‚ÄúRemote debugging between virtual machine (VM) and host fails‚Äù section in &lt;a href="https://raw.githubusercontent.com/ChromeDevTools/chrome-devtools-mcp/main/docs/troubleshooting.md#remote-debugging-between-virtual-machine-vm-and-host-fails"&gt;&lt;code&gt;docs/troubleshooting.md&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;For more details on remote debugging, see the &lt;a href="https://developer.chrome.com/docs/devtools/remote-debugging/"&gt;Chrome DevTools documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Known limitations&lt;/h2&gt; 
&lt;h3&gt;Operating system sandboxes&lt;/h3&gt; 
&lt;p&gt;Some MCP clients allow sandboxing the MCP server using macOS Seatbelt or Linux containers. If sandboxes are enabled, &lt;code&gt;chrome-devtools-mcp&lt;/code&gt; is not able to start Chrome that requires permissions to create its own sandboxes. As a workaround, either disable sandboxing for &lt;code&gt;chrome-devtools-mcp&lt;/code&gt; in your MCP client or use &lt;code&gt;--browser-url&lt;/code&gt; to connect to a Chrome instance that you start manually outside of the MCP client sandbox.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>thedotmack/claude-mem</title>
      <link>https://github.com/thedotmack/claude-mem</link>
      <description>&lt;p&gt;A Claude Code plugin that automatically captures everything Claude does during your coding sessions, compresses it with AI (using Claude's agent-sdk), and injects relevant context back into future sessions.&lt;/p&gt;&lt;hr&gt;&lt;h1 align="center"&gt; &lt;br /&gt; &lt;a href="https://github.com/thedotmack/claude-mem"&gt; 
  &lt;picture&gt; 
   &lt;source media="(prefers-color-scheme: dark)" srcset="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/public/claude-mem-logo-for-dark-mode.webp" /&gt; 
   &lt;source media="(prefers-color-scheme: light)" srcset="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/public/claude-mem-logo-for-light-mode.webp" /&gt; 
   &lt;img src="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/public/claude-mem-logo-for-light-mode.webp" alt="Claude-Mem" width="400" /&gt; 
  &lt;/picture&gt; &lt;/a&gt; &lt;br /&gt; &lt;/h1&gt; 
&lt;h4 align="center"&gt;Persistent memory compression system built for &lt;a href="https://claude.com/claude-code" target="_blank"&gt;Claude Code&lt;/a&gt;.&lt;/h4&gt; 
&lt;p align="center"&gt; &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/LICENSE"&gt; &lt;img src="https://img.shields.io/badge/License-AGPL%203.0-blue.svg?sanitize=true" alt="License" /&gt; &lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/package.json"&gt; &lt;img src="https://img.shields.io/badge/version-6.5.0-green.svg?sanitize=true" alt="Version" /&gt; &lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/package.json"&gt; &lt;img src="https://img.shields.io/badge/node-%3E%3D18.0.0-brightgreen.svg?sanitize=true" alt="Node" /&gt; &lt;/a&gt; &lt;a href="https://github.com/thedotmack/awesome-claude-code"&gt; &lt;img src="https://awesome.re/mentioned-badge.svg?sanitize=true" alt="Mentioned in Awesome Claude Code" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://trendshift.io/repositories/15496" target="_blank"&gt; 
  &lt;picture&gt; 
   &lt;source media="(prefers-color-scheme: dark)" srcset="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/public/trendshift-badge-dark.svg" /&gt; 
   &lt;source media="(prefers-color-scheme: light)" srcset="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/public/trendshift-badge.svg" /&gt; 
   &lt;img src="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/public/trendshift-badge.svg?sanitize=true" alt="thedotmack/claude-mem | Trendshift" width="250" height="55" /&gt; 
  &lt;/picture&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;br /&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/thedotmack/claude-mem"&gt; 
  &lt;picture&gt; 
   &lt;img src="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/public/cm-preview.gif" alt="Claude-Mem Preview" width="800" /&gt; 
  &lt;/picture&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/#quick-start"&gt;Quick Start&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/#how-it-works"&gt;How It Works&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/#mcp-search-tools"&gt;Search Tools&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/#documentation"&gt;Documentation&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/#configuration"&gt;Configuration&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/#troubleshooting"&gt;Troubleshooting&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/#license"&gt;License&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; Claude-Mem seamlessly preserves context across sessions by automatically capturing tool usage observations, generating semantic summaries, and making them available to future sessions. This enables Claude to maintain continuity of knowledge about projects even after sessions end or reconnect. &lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;p&gt;Start a new Claude Code session in the terminal and enter the following commands:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&amp;gt; /plugin marketplace add thedotmack/claude-mem

&amp;gt; /plugin install claude-mem
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Restart Claude Code. Context from previous sessions will automatically appear in new sessions.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Key Features:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;üß† &lt;strong&gt;Persistent Memory&lt;/strong&gt; - Context survives across sessions&lt;/li&gt; 
 &lt;li&gt;üìä &lt;strong&gt;Progressive Disclosure&lt;/strong&gt; - Layered memory retrieval with token cost visibility&lt;/li&gt; 
 &lt;li&gt;üîç &lt;strong&gt;Skill-Based Search&lt;/strong&gt; - Query your project history with mem-search skill (~2,250 token savings)&lt;/li&gt; 
 &lt;li&gt;üñ•Ô∏è &lt;strong&gt;Web Viewer UI&lt;/strong&gt; - Real-time memory stream at &lt;a href="http://localhost:37777"&gt;http://localhost:37777&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üíª &lt;strong&gt;Claude Desktop Skill&lt;/strong&gt; - Search memory from Claude Desktop conversations&lt;/li&gt; 
 &lt;li&gt;üîí &lt;strong&gt;Privacy Control&lt;/strong&gt; - Use &lt;code&gt;&amp;lt;private&amp;gt;&lt;/code&gt; tags to exclude sensitive content from storage&lt;/li&gt; 
 &lt;li&gt;‚öôÔ∏è &lt;strong&gt;Context Configuration&lt;/strong&gt; - Fine-grained control over what context gets injected&lt;/li&gt; 
 &lt;li&gt;ü§ñ &lt;strong&gt;Automatic Operation&lt;/strong&gt; - No manual intervention required&lt;/li&gt; 
 &lt;li&gt;üîó &lt;strong&gt;Citations&lt;/strong&gt; - Reference past decisions with &lt;code&gt;claude-mem://&lt;/code&gt; URIs&lt;/li&gt; 
 &lt;li&gt;üß™ &lt;strong&gt;Beta Channel&lt;/strong&gt; - Try experimental features like Endless Mode via version switching&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;üìö &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/"&gt;View Full Documentation&lt;/a&gt;&lt;/strong&gt; - Browse markdown docs on GitHub&lt;/p&gt; 
&lt;p&gt;üíª &lt;strong&gt;Local Preview&lt;/strong&gt;: Run Mintlify docs locally:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd docs
npx mintlify dev
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Getting Started&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.claude-mem.ai/installation"&gt;Installation Guide&lt;/a&gt;&lt;/strong&gt; - Quick start &amp;amp; advanced installation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.claude-mem.ai/usage/getting-started"&gt;Usage Guide&lt;/a&gt;&lt;/strong&gt; - How Claude-Mem works automatically&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.claude-mem.ai/usage/search-tools"&gt;Search Tools&lt;/a&gt;&lt;/strong&gt; - Query your project history with natural language&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.claude-mem.ai/beta-features"&gt;Beta Features&lt;/a&gt;&lt;/strong&gt; - Try experimental features like Endless Mode&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Best Practices&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.claude-mem.ai/context-engineering"&gt;Context Engineering&lt;/a&gt;&lt;/strong&gt; - AI agent context optimization principles&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.claude-mem.ai/progressive-disclosure"&gt;Progressive Disclosure&lt;/a&gt;&lt;/strong&gt; - Philosophy behind Claude-Mem's context priming strategy&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Architecture&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.claude-mem.ai/architecture/overview"&gt;Overview&lt;/a&gt;&lt;/strong&gt; - System components &amp;amp; data flow&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.claude-mem.ai/architecture-evolution"&gt;Architecture Evolution&lt;/a&gt;&lt;/strong&gt; - The journey from v3 to v5&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.claude-mem.ai/hooks-architecture"&gt;Hooks Architecture&lt;/a&gt;&lt;/strong&gt; - How Claude-Mem uses lifecycle hooks&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.claude-mem.ai/architecture/hooks"&gt;Hooks Reference&lt;/a&gt;&lt;/strong&gt; - 7 hook scripts explained&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.claude-mem.ai/architecture/worker-service"&gt;Worker Service&lt;/a&gt;&lt;/strong&gt; - HTTP API &amp;amp; Bun management&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.claude-mem.ai/architecture/database"&gt;Database&lt;/a&gt;&lt;/strong&gt; - SQLite schema &amp;amp; FTS5 search&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.claude-mem.ai/architecture/search-architecture"&gt;Search Architecture&lt;/a&gt;&lt;/strong&gt; - Hybrid search with Chroma vector database&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Configuration &amp;amp; Development&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.claude-mem.ai/configuration"&gt;Configuration&lt;/a&gt;&lt;/strong&gt; - Environment variables &amp;amp; settings&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.claude-mem.ai/development"&gt;Development&lt;/a&gt;&lt;/strong&gt; - Building, testing, contributing&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.claude-mem.ai/troubleshooting"&gt;Troubleshooting&lt;/a&gt;&lt;/strong&gt; - Common issues &amp;amp; solutions&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;How It Works&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Session Start ‚Üí Inject recent observations as context      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ User Prompts ‚Üí Create session, save user prompts           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Tool Executions ‚Üí Capture observations (Read, Write, etc.)  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Worker Processes ‚Üí Extract learnings via Claude Agent SDK   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Session Ends ‚Üí Generate summary, ready for next session     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Core Components:&lt;/strong&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;5 Lifecycle Hooks&lt;/strong&gt; - SessionStart, UserPromptSubmit, PostToolUse, Stop, SessionEnd (6 hook scripts)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Smart Install&lt;/strong&gt; - Cached dependency checker (pre-hook script, not a lifecycle hook)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Worker Service&lt;/strong&gt; - HTTP API on port 37777 with web viewer UI and 10 search endpoints, managed by Bun&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;SQLite Database&lt;/strong&gt; - Stores sessions, observations, summaries with FTS5 full-text search&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;mem-search Skill&lt;/strong&gt; - Natural language queries with progressive disclosure (~2,250 token savings vs MCP)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Chroma Vector Database&lt;/strong&gt; - Hybrid semantic + keyword search for intelligent context retrieval&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;See &lt;a href="https://docs.claude-mem.ai/architecture/overview"&gt;Architecture Overview&lt;/a&gt; for details.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;mem-search Skill&lt;/h2&gt; 
&lt;p&gt;Claude-Mem provides intelligent search through the mem-search skill that auto-invokes when you ask about past work:&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;How It Works:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Just ask naturally: &lt;em&gt;"What did we do last session?"&lt;/em&gt; or &lt;em&gt;"Did we fix this bug before?"&lt;/em&gt;&lt;/li&gt; 
 &lt;li&gt;Claude automatically invokes the mem-search skill to find relevant context&lt;/li&gt; 
 &lt;li&gt;~2,250 token savings per session start vs MCP approach&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Available Search Operations:&lt;/strong&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Search Observations&lt;/strong&gt; - Full-text search across observations&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Search Sessions&lt;/strong&gt; - Full-text search across session summaries&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Search Prompts&lt;/strong&gt; - Search raw user requests&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;By Concept&lt;/strong&gt; - Find by concept tags (discovery, problem-solution, pattern, etc.)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;By File&lt;/strong&gt; - Find observations referencing specific files&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;By Type&lt;/strong&gt; - Find by type (decision, bugfix, feature, refactor, discovery, change)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Recent Context&lt;/strong&gt; - Get recent session context for a project&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Timeline&lt;/strong&gt; - Get unified timeline of context around a specific point in time&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Timeline by Query&lt;/strong&gt; - Search for observations and get timeline context around best match&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;API Help&lt;/strong&gt; - Get search API documentation&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;Example Natural Language Queries:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;"What bugs did we fix last session?"
"How did we implement authentication?"
"What changes were made to worker-service.ts?"
"Show me recent work on this project"
"What was happening when we added the viewer UI?"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See &lt;a href="https://docs.claude-mem.ai/usage/search-tools"&gt;Search Tools Guide&lt;/a&gt; for detailed examples.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Beta Features &amp;amp; Endless Mode&lt;/h2&gt; 
&lt;p&gt;Claude-Mem offers a &lt;strong&gt;beta channel&lt;/strong&gt; with experimental features. Switch between stable and beta versions directly from the web viewer UI.&lt;/p&gt; 
&lt;h3&gt;How to Try Beta&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Open &lt;a href="http://localhost:37777"&gt;http://localhost:37777&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Click Settings (gear icon)&lt;/li&gt; 
 &lt;li&gt;In &lt;strong&gt;Version Channel&lt;/strong&gt;, click "Try Beta (Endless Mode)"&lt;/li&gt; 
 &lt;li&gt;Wait for the worker to restart&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Your memory data is preserved when switching versions.&lt;/p&gt; 
&lt;h3&gt;Endless Mode (Beta)&lt;/h3&gt; 
&lt;p&gt;The flagship beta feature is &lt;strong&gt;Endless Mode&lt;/strong&gt; - a biomimetic memory architecture that dramatically extends session length:&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;The Problem&lt;/strong&gt;: Standard Claude Code sessions hit context limits after ~50 tool uses. Each tool adds 1-10k+ tokens, and Claude re-synthesizes all previous outputs on every response (O(N¬≤) complexity).&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;The Solution&lt;/strong&gt;: Endless Mode compresses tool outputs into ~500-token observations and transforms the transcript in real-time:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Working Memory (Context):     Compressed observations (~500 tokens each)
Archive Memory (Disk):        Full tool outputs preserved for recall
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Expected Results&lt;/strong&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;~95% token reduction in context window&lt;/li&gt; 
 &lt;li&gt;~20x more tool uses before context exhaustion&lt;/li&gt; 
 &lt;li&gt;Linear O(N) scaling instead of quadratic O(N¬≤)&lt;/li&gt; 
 &lt;li&gt;Full transcripts preserved for perfect recall&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Caveats&lt;/strong&gt;: Adds latency (60-90s per tool for observation generation), still experimental.&lt;/p&gt; 
&lt;p&gt;See &lt;a href="https://docs.claude-mem.ai/beta-features"&gt;Beta Features Documentation&lt;/a&gt; for details.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;What's New&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;v6.4.9 - Context Configuration Settings:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;11 new settings for fine-grained control over context injection&lt;/li&gt; 
 &lt;li&gt;Configure token economics display, observation filtering by type/concept&lt;/li&gt; 
 &lt;li&gt;Control number of observations and which fields to display&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;v6.4.0 - Dual-Tag Privacy System:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;&amp;lt;private&amp;gt;&lt;/code&gt; tags for user-controlled privacy - wrap sensitive content to exclude from storage&lt;/li&gt; 
 &lt;li&gt;System-level &lt;code&gt;&amp;lt;claude-mem-context&amp;gt;&lt;/code&gt; tags prevent recursive observation storage&lt;/li&gt; 
 &lt;li&gt;Edge processing ensures private content never reaches database&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;v6.3.0 - Version Channel:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Switch between stable and beta versions from the web viewer UI&lt;/li&gt; 
 &lt;li&gt;Try experimental features like Endless Mode without manual git operations&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Previous Highlights:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;v6.0.0&lt;/strong&gt;: Major session management &amp;amp; transcript processing improvements&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;v5.5.0&lt;/strong&gt;: mem-search skill enhancement with 100% effectiveness rate&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;v5.4.0&lt;/strong&gt;: Skill-based search architecture (~2,250 tokens saved per session)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;v5.1.0&lt;/strong&gt;: Web-based viewer UI with real-time updates&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;v5.0.0&lt;/strong&gt;: Hybrid search with Chroma vector database&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/CHANGELOG.md"&gt;CHANGELOG.md&lt;/a&gt; for complete version history.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;System Requirements&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Node.js&lt;/strong&gt;: 18.0.0 or higher&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Claude Code&lt;/strong&gt;: Latest version with plugin support&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Bun&lt;/strong&gt;: JavaScript runtime and process manager (auto-installed if missing)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;uv&lt;/strong&gt;: Python package manager for vector search (auto-installed if missing)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;SQLite 3&lt;/strong&gt;: For persistent storage (bundled)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Key Benefits&lt;/h2&gt; 
&lt;h3&gt;Progressive Disclosure Context&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Layered memory retrieval&lt;/strong&gt; mirrors human memory patterns&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Layer 1 (Index)&lt;/strong&gt;: See what observations exist with token costs at session start&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Layer 2 (Details)&lt;/strong&gt;: Fetch full narratives on-demand via MCP search&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Layer 3 (Perfect Recall)&lt;/strong&gt;: Access source code and original transcripts&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Smart decision-making&lt;/strong&gt;: Token counts help Claude choose between fetching details or reading code&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Type indicators&lt;/strong&gt;: Visual cues (üî¥ critical, üü§ decision, üîµ informational) highlight observation importance&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Automatic Memory&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Context automatically injected when Claude starts&lt;/li&gt; 
 &lt;li&gt;No manual commands or configuration needed&lt;/li&gt; 
 &lt;li&gt;Works transparently in the background&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Full History Search&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Search across all sessions and observations&lt;/li&gt; 
 &lt;li&gt;FTS5 full-text search for fast queries&lt;/li&gt; 
 &lt;li&gt;Citations link back to specific observations&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Structured Observations&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;AI-powered extraction of learnings&lt;/li&gt; 
 &lt;li&gt;Categorized by type (decision, bugfix, feature, etc.)&lt;/li&gt; 
 &lt;li&gt;Tagged with concepts and file references&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Multi-Prompt Sessions&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Sessions span multiple user prompts&lt;/li&gt; 
 &lt;li&gt;Context preserved across &lt;code&gt;/clear&lt;/code&gt; commands&lt;/li&gt; 
 &lt;li&gt;Track entire conversation threads&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Configuration&lt;/h2&gt; 
&lt;p&gt;Settings are managed in &lt;code&gt;~/.claude-mem/settings.json&lt;/code&gt;. The file is auto-created with defaults on first run.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Available Settings:&lt;/strong&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Setting&lt;/th&gt; 
   &lt;th&gt;Default&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;CLAUDE_MEM_MODEL&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;claude-haiku-4-5&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;AI model for observations&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;CLAUDE_MEM_WORKER_PORT&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;37777&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Worker service port&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;CLAUDE_MEM_WORKER_HOST&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;127.0.0.1&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Worker bind address (use &lt;code&gt;0.0.0.0&lt;/code&gt; for remote access)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;CLAUDE_MEM_DATA_DIR&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;~/.claude-mem&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Data directory location&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;CLAUDE_MEM_LOG_LEVEL&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;INFO&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Log verbosity (DEBUG, INFO, WARN, ERROR, SILENT)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;CLAUDE_MEM_PYTHON_VERSION&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;3.13&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Python version for chroma-mcp&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;CLAUDE_CODE_PATH&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;em&gt;(auto-detect)&lt;/em&gt;&lt;/td&gt; 
   &lt;td&gt;Path to Claude executable&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;CLAUDE_MEM_CONTEXT_OBSERVATIONS&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;50&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Number of observations to inject at SessionStart&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;Settings Management:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Edit settings via CLI helper
./claude-mem-settings.sh

# Or edit directly
nano ~/.claude-mem/settings.json

# View current settings
curl http://localhost:37777/api/settings
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Settings File Format:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "CLAUDE_MEM_MODEL": "claude-haiku-4-5",
  "CLAUDE_MEM_WORKER_PORT": "37777",
  "CLAUDE_MEM_CONTEXT_OBSERVATIONS": "50"
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See &lt;a href="https://docs.claude-mem.ai/configuration"&gt;Configuration Guide&lt;/a&gt; for details.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Development&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Clone and build
git clone https://github.com/thedotmack/claude-mem.git
cd claude-mem
npm install
npm run build

# Run tests
npm test

# Start worker
npm run worker:start

# View logs
npm run worker:logs
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See &lt;a href="https://docs.claude-mem.ai/development"&gt;Development Guide&lt;/a&gt; for detailed instructions.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Troubleshooting&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Quick Diagnostic:&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;If you're experiencing issues, describe the problem to Claude and the troubleshoot skill will automatically activate to diagnose and provide fixes.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Common Issues:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Worker not starting ‚Üí &lt;code&gt;npm run worker:restart&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;No context appearing ‚Üí &lt;code&gt;npm run test:context&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Database issues ‚Üí &lt;code&gt;sqlite3 ~/.claude-mem/claude-mem.db "PRAGMA integrity_check;"&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Search not working ‚Üí Check FTS5 tables exist&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;See &lt;a href="https://docs.claude-mem.ai/troubleshooting"&gt;Troubleshooting Guide&lt;/a&gt; for complete solutions.&lt;/p&gt; 
&lt;h3&gt;Windows Known Issues&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Console Window Visibility&lt;/strong&gt;: On Windows, a console window may briefly appear when the worker service starts. This is a cosmetic issue that we're working to resolve. We've prioritized stability by removing a workaround that was causing libuv crashes. The window does not affect functionality and will be addressed in a future release when the MCP SDK provides proper window hiding support.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Contributions are welcome! Please:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Fork the repository&lt;/li&gt; 
 &lt;li&gt;Create a feature branch&lt;/li&gt; 
 &lt;li&gt;Make your changes with tests&lt;/li&gt; 
 &lt;li&gt;Update documentation&lt;/li&gt; 
 &lt;li&gt;Submit a Pull Request&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;See &lt;a href="https://docs.claude-mem.ai/development"&gt;Development Guide&lt;/a&gt; for contribution workflow.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the &lt;strong&gt;GNU Affero General Public License v3.0&lt;/strong&gt; (AGPL-3.0).&lt;/p&gt; 
&lt;p&gt;Copyright (C) 2025 Alex Newman (@thedotmack). All rights reserved.&lt;/p&gt; 
&lt;p&gt;See the &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/LICENSE"&gt;LICENSE&lt;/a&gt; file for full details.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;What This Means:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;You can use, modify, and distribute this software freely&lt;/li&gt; 
 &lt;li&gt;If you modify and deploy on a network server, you must make your source code available&lt;/li&gt; 
 &lt;li&gt;Derivative works must also be licensed under AGPL-3.0&lt;/li&gt; 
 &lt;li&gt;There is NO WARRANTY for this software&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Support&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Documentation&lt;/strong&gt;: &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/"&gt;docs/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Issues&lt;/strong&gt;: &lt;a href="https://github.com/thedotmack/claude-mem/issues"&gt;GitHub Issues&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Repository&lt;/strong&gt;: &lt;a href="https://github.com/thedotmack/claude-mem"&gt;github.com/thedotmack/claude-mem&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Author&lt;/strong&gt;: Alex Newman (&lt;a href="https://github.com/thedotmack"&gt;@thedotmack&lt;/a&gt;)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;strong&gt;Built with Claude Agent SDK&lt;/strong&gt; | &lt;strong&gt;Powered by Claude Code&lt;/strong&gt; | &lt;strong&gt;Made with TypeScript&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>agentsmd/agents.md</title>
      <link>https://github.com/agentsmd/agents.md</link>
      <description>&lt;p&gt;AGENTS.md ‚Äî a simple, open format for guiding coding agents&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;AGENTS.md&lt;/h1&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/agentsmd/agents.md/main/public/og.png" alt="AGENTS.md logo" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://agents.md"&gt;AGENTS.md&lt;/a&gt; is a simple, open format for guiding coding agents.&lt;/p&gt; 
&lt;p&gt;Think of AGENTS.md as a README for agents: a dedicated, predictable place to provide context and instructions to help AI coding agents work on your project.&lt;/p&gt; 
&lt;p&gt;Below is a minimal example of an AGENTS.md file:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-markdown"&gt;# Sample AGENTS.md file

## Dev environment tips
- Use `pnpm dlx turbo run where &amp;lt;project_name&amp;gt;` to jump to a package instead of scanning with `ls`.
- Run `pnpm install --filter &amp;lt;project_name&amp;gt;` to add the package to your workspace so Vite, ESLint, and TypeScript can see it.
- Use `pnpm create vite@latest &amp;lt;project_name&amp;gt; -- --template react-ts` to spin up a new React + Vite package with TypeScript checks ready.
- Check the name field inside each package's package.json to confirm the right name‚Äîskip the top-level one.

## Testing instructions
- Find the CI plan in the .github/workflows folder.
- Run `pnpm turbo run test --filter &amp;lt;project_name&amp;gt;` to run every check defined for that package.
- From the package root you can just call `pnpm test`. The commit should pass all tests before you merge.
- To focus on one step, add the Vitest pattern: `pnpm vitest run -t "&amp;lt;test name&amp;gt;"`.
- Fix any test or type errors until the whole suite is green.
- After moving files or changing imports, run `pnpm lint --filter &amp;lt;project_name&amp;gt;` to be sure ESLint and TypeScript rules still pass.
- Add or update tests for the code you change, even if nobody asked.

## PR instructions
- Title format: [&amp;lt;project_name&amp;gt;] &amp;lt;Title&amp;gt;
- Always run `pnpm lint` and `pnpm test` before committing.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Website&lt;/h2&gt; 
&lt;p&gt;This repository also includes a basic Next.js website hosted at &lt;a href="https://agents.md/"&gt;https://agents.md/&lt;/a&gt; that explains the project‚Äôs goals in a simple way, and featuring some examples.&lt;/p&gt; 
&lt;h3&gt;Running the app locally&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Install dependencies: &lt;pre&gt;&lt;code class="language-bash"&gt;pnpm install
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;Start the development server: &lt;pre&gt;&lt;code class="language-bash"&gt;pnpm run dev
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;Open your browser and go to &lt;a href="http://localhost:3000"&gt;http://localhost:3000&lt;/a&gt;&lt;/li&gt; 
&lt;/ol&gt;</description>
    </item>
    
    <item>
      <title>shadcn-ui/ui</title>
      <link>https://github.com/shadcn-ui/ui</link>
      <description>&lt;p&gt;A set of beautifully-designed, accessible components and a code distribution platform. Works with your favorite frameworks. Open Source. Open Code.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;shadcn/ui&lt;/h1&gt; 
&lt;p&gt;A set of beautifully designed components that you can customize, extend, and build on. Start here then make it your own. Open Source. Open Code. &lt;strong&gt;Use this to build your own component library&lt;/strong&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/shadcn-ui/ui/main/apps/v4/public/opengraph-image.png" alt="hero" /&gt;&lt;/p&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;Visit &lt;a href="http://ui.shadcn.com/docs"&gt;http://ui.shadcn.com/docs&lt;/a&gt; to view the documentation.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Please read the &lt;a href="https://raw.githubusercontent.com/shadcn-ui/ui/main/CONTRIBUTING.md"&gt;contributing guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Licensed under the &lt;a href="https://github.com/shadcn/ui/raw/main/LICENSE.md"&gt;MIT license&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>YimMenu/YimMenuV2</title>
      <link>https://github.com/YimMenu/YimMenuV2</link>
      <description>&lt;p&gt;Experimental menu for GTA 5: Enhanced&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;YimMenuV2&lt;/h1&gt; 
&lt;p&gt;Experimental menu for GTA 5: Enhanced&lt;/p&gt; 
&lt;h2&gt;How to use&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;Download the latest version of FSL from &lt;a href="https://www.unknowncheats.me/forum/grand-theft-auto-v/616977-fsl-local-gtao-saves.html"&gt;here&lt;/a&gt; and place version.dll in your GTA V directory. Using FSL is now optional but highly recommended for account safety&lt;/li&gt; 
 &lt;li&gt;Download YimMenuV2 from &lt;a href="https://github.com/YimMenu/YimMenuV2/releases/tag/nightly"&gt;GitHub Releases&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Download an injector, such as &lt;a href="https://www.unknowncheats.me/forum/general-programming-and-reversing/124013-xenos-injector-v2-3-2-a.html"&gt;Xenos&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Open Rockstar Launcher, select Grand Theft Auto V Enhanced, go to settings, and disable BattlEye. If you are using Steam or Epic Games, you may have to pass the -nobattleye command line parameter as well&lt;/li&gt; 
 &lt;li&gt;Launch GTA V, then use your injector to inject YimMenuV2.dll at the main menu&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;How to open the menu?&lt;/h2&gt; 
&lt;p&gt;Press the &lt;code&gt;INSERT&lt;/code&gt; key or &lt;code&gt;Ctrl+\&lt;/code&gt; to open the menu&lt;/p&gt; 
&lt;h2&gt;Common issues&lt;/h2&gt; 
&lt;h3&gt;I keep getting desynced from public sessions every five minutes&lt;/h3&gt; 
&lt;p&gt;We currently do not have a BattlEye bypass, and legitimate hosts will eventually remove you due to a heartbeat failure. There is currently no way to stop this other than using an actual (private) bypass&lt;/p&gt; 
&lt;h3&gt;I removed FSL and all my progress disappeared!&lt;/h3&gt; 
&lt;p&gt;FSL reroutes account save data to disk, so any progress made with FSL will only show up if you have FSL enabled. If you don't want this, you can also use YimMenuV2 without FSL, but this is not recommended&lt;/p&gt; 
&lt;h3&gt;I removed FSL and the game doesn't start up anymore&lt;/h3&gt; 
&lt;p&gt;This is a known issue; delete "Documents/GTAV Enhanced/Profiles" to fix&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>langgenius/dify</title>
      <link>https://github.com/langgenius/dify</link>
      <description>&lt;p&gt;Production-ready platform for agentic workflow development.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/langgenius/dify/main/images/GitHub_README_if.png" alt="cover-v5-optimized" /&gt;&lt;/p&gt; 
&lt;p align="center"&gt; üìå &lt;a href="https://dify.ai/blog/introducing-dify-workflow-file-upload-a-demo-on-ai-podcast"&gt;Introducing Dify Workflow File Upload: Recreate Google NotebookLM Podcast&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://cloud.dify.ai"&gt;Dify Cloud&lt;/a&gt; ¬∑ &lt;a href="https://docs.dify.ai/getting-started/install-self-hosted"&gt;Self-hosting&lt;/a&gt; ¬∑ &lt;a href="https://docs.dify.ai"&gt;Documentation&lt;/a&gt; ¬∑ &lt;a href="https://dify.ai/pricing"&gt;Dify edition overview&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://dify.ai" target="_blank"&gt; &lt;img alt="Static Badge" src="https://img.shields.io/badge/Product-F04438" /&gt;&lt;/a&gt; &lt;a href="https://dify.ai/pricing" target="_blank"&gt; &lt;img alt="Static Badge" src="https://img.shields.io/badge/free-pricing?logo=free&amp;amp;color=%20%23155EEF&amp;amp;label=pricing&amp;amp;labelColor=%20%23528bff" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/FngNHpbcY7" target="_blank"&gt; &lt;img src="https://img.shields.io/discord/1082486657678311454?logo=discord&amp;amp;labelColor=%20%235462eb&amp;amp;logoColor=%20%23f5f5f5&amp;amp;color=%20%235462eb" alt="chat on Discord" /&gt;&lt;/a&gt; &lt;a href="https://reddit.com/r/difyai" target="_blank"&gt; &lt;img src="https://img.shields.io/reddit/subreddit-subscribers/difyai?style=plastic&amp;amp;logo=reddit&amp;amp;label=r%2Fdifyai&amp;amp;labelColor=white" alt="join Reddit" /&gt;&lt;/a&gt; &lt;a href="https://twitter.com/intent/follow?screen_name=dify_ai" target="_blank"&gt; &lt;img src="https://img.shields.io/twitter/follow/dify_ai?logo=X&amp;amp;color=%20%23f5f5f5" alt="follow on X(Twitter)" /&gt;&lt;/a&gt; &lt;a href="https://www.linkedin.com/company/langgenius/" target="_blank"&gt; &lt;img src="https://custom-icon-badges.demolab.com/badge/LinkedIn-0A66C2?logo=linkedin-white&amp;amp;logoColor=fff" alt="follow on LinkedIn" /&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/u/langgenius" target="_blank"&gt; &lt;img alt="Docker Pulls" src="https://img.shields.io/docker/pulls/langgenius/dify-web?labelColor=%20%23FDB062&amp;amp;color=%20%23f79009" /&gt;&lt;/a&gt; &lt;a href="https://github.com/langgenius/dify/graphs/commit-activity" target="_blank"&gt; &lt;img alt="Commits last month" src="https://img.shields.io/github/commit-activity/m/langgenius/dify?labelColor=%20%2332b583&amp;amp;color=%20%2312b76a" /&gt;&lt;/a&gt; &lt;a href="https://github.com/langgenius/dify/" target="_blank"&gt; &lt;img alt="Issues closed" src="https://img.shields.io/github/issues-search?query=repo%3Alanggenius%2Fdify%20is%3Aclosed&amp;amp;label=issues%20closed&amp;amp;labelColor=%20%237d89b0&amp;amp;color=%20%235d6b98" /&gt;&lt;/a&gt; &lt;a href="https://github.com/langgenius/dify/discussions/" target="_blank"&gt; &lt;img alt="Discussion posts" src="https://img.shields.io/github/discussions/langgenius/dify?labelColor=%20%239b8afb&amp;amp;color=%20%237a5af8" /&gt;&lt;/a&gt; &lt;a href="https://insights.linuxfoundation.org/project/langgenius-dify" target="_blank"&gt; &lt;img alt="LFX Health Score" src="https://insights.linuxfoundation.org/api/badge/health-score?project=langgenius-dify" /&gt;&lt;/a&gt; &lt;a href="https://insights.linuxfoundation.org/project/langgenius-dify" target="_blank"&gt; &lt;img alt="LFX Contributors" src="https://insights.linuxfoundation.org/api/badge/contributors?project=langgenius-dify" /&gt;&lt;/a&gt; &lt;a href="https://insights.linuxfoundation.org/project/langgenius-dify" target="_blank"&gt; &lt;img alt="LFX Active Contributors" src="https://insights.linuxfoundation.org/api/badge/active-contributors?project=langgenius-dify" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://raw.githubusercontent.com/langgenius/dify/main/README.md"&gt;&lt;img alt="README in English" src="https://img.shields.io/badge/English-d9d9d9" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/langgenius/dify/main/docs/zh-TW/README.md"&gt;&lt;img alt="ÁπÅÈ´î‰∏≠ÊñáÊñá‰ª∂" src="https://img.shields.io/badge/ÁπÅÈ´î‰∏≠Êñá-d9d9d9" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/langgenius/dify/main/docs/zh-CN/README.md"&gt;&lt;img alt="ÁÆÄ‰Ωì‰∏≠ÊñáÊñá‰ª∂" src="https://img.shields.io/badge/ÁÆÄ‰Ωì‰∏≠Êñá-d9d9d9" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/langgenius/dify/main/docs/ja-JP/README.md"&gt;&lt;img alt="Êó•Êú¨Ë™û„ÅÆREADME" src="https://img.shields.io/badge/Êó•Êú¨Ë™û-d9d9d9" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/langgenius/dify/main/docs/es-ES/README.md"&gt;&lt;img alt="README en Espa√±ol" src="https://img.shields.io/badge/Espa√±ol-d9d9d9" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/langgenius/dify/main/docs/fr-FR/README.md"&gt;&lt;img alt="README en Fran√ßais" src="https://img.shields.io/badge/Fran√ßais-d9d9d9" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/langgenius/dify/main/docs/tlh/README.md"&gt;&lt;img alt="README tlhIngan Hol" src="https://img.shields.io/badge/Klingon-d9d9d9" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/langgenius/dify/main/docs/ko-KR/README.md"&gt;&lt;img alt="README in Korean" src="https://img.shields.io/badge/ÌïúÍµ≠Ïñ¥-d9d9d9" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/langgenius/dify/main/docs/ar-SA/README.md"&gt;&lt;img alt="README ÿ®ÿßŸÑÿπÿ±ÿ®Ÿäÿ©" src="https://img.shields.io/badge/ÿßŸÑÿπÿ±ÿ®Ÿäÿ©-d9d9d9" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/langgenius/dify/main/docs/tr-TR/README.md"&gt;&lt;img alt="T√ºrk√ße README" src="https://img.shields.io/badge/T√ºrk√ße-d9d9d9" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/langgenius/dify/main/docs/vi-VN/README.md"&gt;&lt;img alt="README Ti·∫øng Vi·ªát" src="https://img.shields.io/badge/Ti%E1%BA%BFng%20Vi%E1%BB%87t-d9d9d9" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/langgenius/dify/main/docs/de-DE/README.md"&gt;&lt;img alt="README in Deutsch" src="https://img.shields.io/badge/German-d9d9d9" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/langgenius/dify/main/docs/bn-BD/README.md"&gt;&lt;img alt="README in ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ" src="https://img.shields.io/badge/‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ-d9d9d9" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p&gt;Dify is an open-source platform for developing LLM applications. Its intuitive interface combines agentic AI workflows, RAG pipelines, agent capabilities, model management, observability features, and more‚Äîallowing you to quickly move from prototype to production.&lt;/p&gt; 
&lt;h2&gt;Quick start&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Before installing Dify, make sure your machine meets the following minimum system requirements:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;CPU &amp;gt;= 2 Core&lt;/li&gt; 
  &lt;li&gt;RAM &amp;gt;= 4 GiB&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;br /&gt; 
&lt;p&gt;The easiest way to start the Dify server is through &lt;a href="https://raw.githubusercontent.com/langgenius/dify/main/docker/docker-compose.yaml"&gt;Docker Compose&lt;/a&gt;. Before running Dify with the following commands, make sure that &lt;a href="https://docs.docker.com/get-docker/"&gt;Docker&lt;/a&gt; and &lt;a href="https://docs.docker.com/compose/install/"&gt;Docker Compose&lt;/a&gt; are installed on your machine:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd dify
cd docker
cp .env.example .env
docker compose up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;After running, you can access the Dify dashboard in your browser at &lt;a href="http://localhost/install"&gt;http://localhost/install&lt;/a&gt; and start the initialization process.&lt;/p&gt; 
&lt;h4&gt;Seeking help&lt;/h4&gt; 
&lt;p&gt;Please refer to our &lt;a href="https://docs.dify.ai/getting-started/install-self-hosted/faqs"&gt;FAQ&lt;/a&gt; if you encounter problems setting up Dify. Reach out to &lt;a href="https://raw.githubusercontent.com/langgenius/dify/main/#community--contact"&gt;the community and us&lt;/a&gt; if you are still having issues.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;If you'd like to contribute to Dify or do additional development, refer to our &lt;a href="https://docs.dify.ai/getting-started/install-self-hosted/local-source-code"&gt;guide to deploying from source code&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Key features&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;1. Workflow&lt;/strong&gt;: Build and test powerful AI workflows on a visual canvas, leveraging all the following features and beyond.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2. Comprehensive model support&lt;/strong&gt;: Seamless integration with hundreds of proprietary / open-source LLMs from dozens of inference providers and self-hosted solutions, covering GPT, Mistral, Llama3, and any OpenAI API-compatible models. A full list of supported model providers can be found &lt;a href="https://docs.dify.ai/getting-started/readme/model-providers"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/langgenius/dify/assets/13230914/5a17bdbe-097a-4100-8363-40255b70f6e3" alt="providers-v5" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;3. Prompt IDE&lt;/strong&gt;: Intuitive interface for crafting prompts, comparing model performance, and adding additional features such as text-to-speech to a chat-based app.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;4. RAG Pipeline&lt;/strong&gt;: Extensive RAG capabilities that cover everything from document ingestion to retrieval, with out-of-box support for text extraction from PDFs, PPTs, and other common document formats.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;5. Agent capabilities&lt;/strong&gt;: You can define agents based on LLM Function Calling or ReAct, and add pre-built or custom tools for the agent. Dify provides 50+ built-in tools for AI agents, such as Google Search, DALL¬∑E, Stable Diffusion and WolframAlpha.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;6. LLMOps&lt;/strong&gt;: Monitor and analyze application logs and performance over time. You could continuously improve prompts, datasets, and models based on production data and annotations.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;7. Backend-as-a-Service&lt;/strong&gt;: All of Dify's offerings come with corresponding APIs, so you could effortlessly integrate Dify into your own business logic.&lt;/p&gt; 
&lt;h2&gt;Using Dify&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Cloud &lt;br /&gt;&lt;/strong&gt; We host a &lt;a href="https://dify.ai"&gt;Dify Cloud&lt;/a&gt; service for anyone to try with zero setup. It provides all the capabilities of the self-deployed version, and includes 200 free GPT-4 calls in the sandbox plan.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Self-hosting Dify Community Edition&lt;br /&gt;&lt;/strong&gt; Quickly get Dify running in your environment with this &lt;a href="https://raw.githubusercontent.com/langgenius/dify/main/#quick-start"&gt;starter guide&lt;/a&gt;. Use our &lt;a href="https://docs.dify.ai"&gt;documentation&lt;/a&gt; for further references and more in-depth instructions.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Dify for enterprise / organizations&lt;br /&gt;&lt;/strong&gt; We provide additional enterprise-centric features. &lt;a href="mailto:business@dify.ai?subject=%5BGitHub%5DBusiness%20License%20Inquiry"&gt;Send us an email&lt;/a&gt; to discuss your enterprise needs. &lt;br /&gt;&lt;/p&gt; 
  &lt;blockquote&gt; 
   &lt;p&gt;For startups and small businesses using AWS, check out &lt;a href="https://aws.amazon.com/marketplace/pp/prodview-t22mebxzwjhu6"&gt;Dify Premium on AWS Marketplace&lt;/a&gt; and deploy it to your own AWS VPC with one click. It's an affordable AMI offering with the option to create apps with custom logo and branding.&lt;/p&gt; 
  &lt;/blockquote&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Staying ahead&lt;/h2&gt; 
&lt;p&gt;Star Dify on GitHub and be instantly notified of new releases.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/langgenius/dify/assets/13230914/b823edc1-6388-4e25-ad45-2f6b187adbb4" alt="star-us" /&gt;&lt;/p&gt; 
&lt;h2&gt;Advanced Setup&lt;/h2&gt; 
&lt;h3&gt;Custom configurations&lt;/h3&gt; 
&lt;p&gt;If you need to customize the configuration, please refer to the comments in our &lt;a href="https://raw.githubusercontent.com/langgenius/dify/main/docker/.env.example"&gt;.env.example&lt;/a&gt; file and update the corresponding values in your &lt;code&gt;.env&lt;/code&gt; file. Additionally, you might need to make adjustments to the &lt;code&gt;docker-compose.yaml&lt;/code&gt; file itself, such as changing image versions, port mappings, or volume mounts, based on your specific deployment environment and requirements. After making any changes, please re-run &lt;code&gt;docker-compose up -d&lt;/code&gt;. You can find the full list of available environment variables &lt;a href="https://docs.dify.ai/getting-started/install-self-hosted/environments"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h4&gt;Customizing Suggested Questions&lt;/h4&gt; 
&lt;p&gt;You can now customize the "Suggested Questions After Answer" feature to better fit your use case. For example, to generate longer, more technical questions:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# In your .env file
SUGGESTED_QUESTIONS_PROMPT='Please help me predict the five most likely technical follow-up questions a developer would ask. Focus on implementation details, best practices, and architecture considerations. Keep each question between 40-60 characters. Output must be JSON array: ["question1","question2","question3","question4","question5"]'
SUGGESTED_QUESTIONS_MAX_TOKENS=512
SUGGESTED_QUESTIONS_TEMPERATURE=0.3
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See the &lt;a href="https://raw.githubusercontent.com/langgenius/dify/main/docs/suggested-questions-configuration.md"&gt;Suggested Questions Configuration Guide&lt;/a&gt; for detailed examples and usage instructions.&lt;/p&gt; 
&lt;h3&gt;Metrics Monitoring with Grafana&lt;/h3&gt; 
&lt;p&gt;Import the dashboard to Grafana, using Dify's PostgreSQL database as data source, to monitor metrics in granularity of apps, tenants, messages, and more.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/bowenliang123/dify-grafana-dashboard"&gt;Grafana Dashboard by @bowenliang123&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Deployment with Kubernetes&lt;/h3&gt; 
&lt;p&gt;If you'd like to configure a highly-available setup, there are community-contributed &lt;a href="https://helm.sh/"&gt;Helm Charts&lt;/a&gt; and YAML files which allow Dify to be deployed on Kubernetes.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/douban/charts/tree/master/charts/dify"&gt;Helm Chart by @LeoQuote&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/BorisPolonsky/dify-helm"&gt;Helm Chart by @BorisPolonsky&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/magicsong/ai-charts"&gt;Helm Chart by @magicsong&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Winson-030/dify-kubernetes"&gt;YAML file by @Winson-030&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/wyy-holding/dify-k8s"&gt;YAML file by @wyy-holding&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Zhoneym/DifyAI-Kubernetes"&gt;üöÄ NEW! YAML files (Supports Dify v1.6.0) by @Zhoneym&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Using Terraform for Deployment&lt;/h4&gt; 
&lt;p&gt;Deploy Dify to Cloud Platform with a single click using &lt;a href="https://www.terraform.io/"&gt;terraform&lt;/a&gt;&lt;/p&gt; 
&lt;h5&gt;Azure Global&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/nikawang/dify-azure-terraform"&gt;Azure Terraform by @nikawang&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h5&gt;Google Cloud&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/DeNA/dify-google-cloud-terraform"&gt;Google Cloud Terraform by @sotazum&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Using AWS CDK for Deployment&lt;/h4&gt; 
&lt;p&gt;Deploy Dify to AWS with &lt;a href="https://aws.amazon.com/cdk/"&gt;CDK&lt;/a&gt;&lt;/p&gt; 
&lt;h5&gt;AWS&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/aws-samples/solution-for-deploying-dify-on-aws"&gt;AWS CDK by @KevinZhao (EKS based)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/aws-samples/dify-self-hosted-on-aws"&gt;AWS CDK by @tmokmss (ECS based)&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Using Alibaba Cloud Computing Nest&lt;/h4&gt; 
&lt;p&gt;Quickly deploy Dify to Alibaba cloud with &lt;a href="https://computenest.console.aliyun.com/service/instance/create/default?type=user&amp;amp;ServiceName=Dify%E7%A4%BE%E5%8C%BA%E7%89%88"&gt;Alibaba Cloud Computing Nest&lt;/a&gt;&lt;/p&gt; 
&lt;h4&gt;Using Alibaba Cloud Data Management&lt;/h4&gt; 
&lt;p&gt;One-Click deploy Dify to Alibaba Cloud with &lt;a href="https://www.alibabacloud.com/help/en/dms/dify-in-invitational-preview/"&gt;Alibaba Cloud Data Management&lt;/a&gt;&lt;/p&gt; 
&lt;h4&gt;Deploy to AKS with Azure Devops Pipeline&lt;/h4&gt; 
&lt;p&gt;One-Click deploy Dify to AKS with &lt;a href="https://github.com/Ruiruiz30/Dify-helm-chart-AKS"&gt;Azure Devops Pipeline Helm Chart by @LeoZhang&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;For those who'd like to contribute code, see our &lt;a href="https://github.com/langgenius/dify/raw/main/CONTRIBUTING.md"&gt;Contribution Guide&lt;/a&gt;. At the same time, please consider supporting Dify by sharing it on social media and at events and conferences.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;We are looking for contributors to help translate Dify into languages other than Mandarin or English. If you are interested in helping, please see the &lt;a href="https://github.com/langgenius/dify/raw/main/web/i18n-config/README.md"&gt;i18n README&lt;/a&gt; for more information, and leave us a comment in the &lt;code&gt;global-users&lt;/code&gt; channel of our &lt;a href="https://discord.gg/8Tpq4AcN9c"&gt;Discord Community Server&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Community &amp;amp; contact&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/langgenius/dify/discussions"&gt;GitHub Discussion&lt;/a&gt;. Best for: sharing feedback and asking questions.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/langgenius/dify/issues"&gt;GitHub Issues&lt;/a&gt;. Best for: bugs you encounter using Dify.AI, and feature proposals. See our &lt;a href="https://github.com/langgenius/dify/raw/main/CONTRIBUTING.md"&gt;Contribution Guide&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://discord.gg/FngNHpbcY7"&gt;Discord&lt;/a&gt;. Best for: sharing your applications and hanging out with the community.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://twitter.com/dify_ai"&gt;X(Twitter)&lt;/a&gt;. Best for: sharing your applications and hanging out with the community.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Contributors&lt;/strong&gt;&lt;/p&gt; 
&lt;a href="https://github.com/langgenius/dify/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=langgenius/dify" /&gt; &lt;/a&gt; 
&lt;h2&gt;Star history&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://star-history.com/#langgenius/dify&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=langgenius/dify&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Security disclosure&lt;/h2&gt; 
&lt;p&gt;To protect your privacy, please avoid posting security issues on GitHub. Instead, report issues to &lt;a href="mailto:security@dify.ai"&gt;security@dify.ai&lt;/a&gt;, and our team will respond with detailed answer.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This repository is licensed under the &lt;a href="https://raw.githubusercontent.com/langgenius/dify/main/LICENSE"&gt;Dify Open Source License&lt;/a&gt;, based on Apache 2.0 with additional conditions.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>datawhalechina/hello-agents</title>
      <link>https://github.com/datawhalechina/hello-agents</link>
      <description>&lt;p&gt;üìö „Ää‰ªéÈõ∂ÂºÄÂßãÊûÑÂª∫Êô∫ËÉΩ‰Ωì„Äã‚Äî‚Äî‰ªéÈõ∂ÂºÄÂßãÁöÑÊô∫ËÉΩ‰ΩìÂéüÁêÜ‰∏éÂÆûË∑µÊïôÁ®ã&lt;/p&gt;&lt;hr&gt;&lt;div align="right"&gt; 
 &lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/README_EN.md"&gt;English&lt;/a&gt; | ‰∏≠Êñá 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/images/hello-agents.png" alt="alt text" width="100%" /&gt; 
 &lt;h1&gt;Hello-Agents&lt;/h1&gt; 
 &lt;h3&gt;ü§ñ „Ää‰ªéÈõ∂ÂºÄÂßãÊûÑÂª∫Êô∫ËÉΩ‰Ωì„Äã&lt;/h3&gt; 
 &lt;p&gt;&lt;em&gt;‰ªéÂü∫Á°ÄÁêÜËÆ∫Âà∞ÂÆûÈôÖÂ∫îÁî®ÔºåÂÖ®Èù¢ÊéåÊè°Êô∫ËÉΩ‰ΩìÁ≥ªÁªüÁöÑËÆæËÆ°‰∏éÂÆûÁé∞&lt;/em&gt;&lt;/p&gt; 
 &lt;img src="https://img.shields.io/github/stars/datawhalechina/Hello-Agents?style=flat&amp;amp;logo=github" alt="GitHub stars" /&gt; 
 &lt;img src="https://img.shields.io/github/forks/datawhalechina/Hello-Agents?style=flat&amp;amp;logo=github" alt="GitHub forks" /&gt; 
 &lt;img src="https://img.shields.io/badge/language-Chinese-brightgreen?style=flat" alt="Language" /&gt; 
 &lt;a href="https://github.com/datawhalechina/Hello-Agents"&gt;&lt;img src="https://img.shields.io/badge/GitHub-Project-blue?style=flat&amp;amp;logo=github" alt="GitHub Project" /&gt;&lt;/a&gt; 
 &lt;a href="https://datawhalechina.github.io/hello-agents/"&gt;&lt;img src="https://img.shields.io/badge/Âú®Á∫øÈòÖËØª-Online%20Reading-green?style=flat&amp;amp;logo=gitbook" alt="Online Reading" /&gt;&lt;/a&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üéØ È°πÁõÆ‰ªãÁªç&lt;/h2&gt; 
&lt;p&gt;‚ÄÉ‚ÄÉÂ¶ÇÊûúËØ¥ 2024 Âπ¥ÊòØ"ÁôæÊ®°Â§ßÊàò"ÁöÑÂÖÉÂπ¥ÔºåÈÇ£‰πà 2025 Âπ¥Êó†ÁñëÂºÄÂêØ‰∫Ü"Agent ÂÖÉÂπ¥"„ÄÇÊäÄÊúØÁöÑÁÑ¶ÁÇπÊ≠£‰ªéËÆ≠ÁªÉÊõ¥Â§ßÁöÑÂü∫Á°ÄÊ®°ÂûãÔºåËΩ¨ÂêëÊûÑÂª∫Êõ¥ËÅ™ÊòéÁöÑÊô∫ËÉΩ‰ΩìÂ∫îÁî®„ÄÇÁÑ∂ËÄåÔºåÂΩìÂâçÁ≥ªÁªüÊÄß„ÄÅÈáçÂÆûË∑µÁöÑÊïôÁ®ãÂç¥ÊûÅÂ∫¶ÂåÆ‰πè„ÄÇ‰∏∫Ê≠§ÔºåÊàë‰ª¨ÂèëËµ∑‰∫Ü Hello-Agents È°πÁõÆÔºåÂ∏åÊúõËÉΩ‰∏∫Á§æÂå∫Êèê‰æõ‰∏ÄÊú¨‰ªéÈõ∂ÂºÄÂßã„ÄÅÁêÜËÆ∫‰∏éÂÆûÊàòÂπ∂ÈáçÁöÑÊô∫ËÉΩ‰ΩìÁ≥ªÁªüÊûÑÂª∫ÊåáÂçó„ÄÇ&lt;/p&gt; 
&lt;p&gt;‚ÄÉ‚ÄÉHello-Agents ÊòØ Datawhale Á§æÂå∫ÁöÑ&lt;strong&gt;Á≥ªÁªüÊÄßÊô∫ËÉΩ‰ΩìÂ≠¶‰π†ÊïôÁ®ã&lt;/strong&gt;„ÄÇÂ¶Ç‰ªä Agent ÊûÑÂª∫‰∏ªË¶ÅÂàÜ‰∏∫‰∏§Ê¥æÔºå‰∏ÄÊ¥æÊòØ DifyÔºåCozeÔºån8n ËøôÁ±ªËΩØ‰ª∂Â∑•Á®ãÁ±ª AgentÔºåÂÖ∂Êú¨Ë¥®ÊòØÊµÅÁ®ãÈ©±Âä®ÁöÑËΩØ‰ª∂ÂºÄÂèëÔºåLLM ‰Ωú‰∏∫Êï∞ÊçÆÂ§ÑÁêÜÁöÑÂêéÁ´ØÔºõÂè¶‰∏ÄÊ¥æÂàôÊòØ AI ÂéüÁîüÁöÑ AgentÔºåÂç≥ÁúüÊ≠£‰ª• AI È©±Âä®ÁöÑ Agent„ÄÇÊú¨ÊïôÁ®ãÊó®Âú®Â∏¶È¢ÜÂ§ßÂÆ∂Ê∑±ÂÖ•ÁêÜËß£Âπ∂ÊûÑÂª∫ÂêéËÄÖ‚Äî‚ÄîÁúüÊ≠£ÁöÑ AI Native Agent„ÄÇÊïôÁ®ãÂ∞ÜÂ∏¶È¢Ü‰Ω†Á©øÈÄèÊ°ÜÊû∂Ë°®Ë±°Ôºå‰ªéÊô∫ËÉΩ‰ΩìÁöÑÊ†∏ÂøÉÂéüÁêÜÂá∫ÂèëÔºåÊ∑±ÂÖ•ÂÖ∂Ê†∏ÂøÉÊû∂ÊûÑÔºåÁêÜËß£ÂÖ∂ÁªèÂÖ∏ËåÉÂºèÔºåÂπ∂ÊúÄÁªà‰∫≤ÊâãÊûÑÂª∫Ëµ∑Â±û‰∫éËá™Â∑±ÁöÑÂ§öÊô∫ËÉΩ‰ΩìÂ∫îÁî®„ÄÇÊàë‰ª¨Áõ∏‰ø°ÔºåÊúÄÂ•ΩÁöÑÂ≠¶‰π†ÊñπÂºèÂ∞±ÊòØÂä®ÊâãÂÆûË∑µ„ÄÇÂ∏åÊúõËøôÊú¨ÊïôÁ®ãËÉΩÊàê‰∏∫‰Ω†Êé¢Á¥¢Êô∫ËÉΩ‰Ωì‰∏ñÁïåÁöÑËµ∑ÁÇπÔºåËÉΩÂ§ü‰ªé‰∏ÄÂêçÂ§ßËØ≠Ë®ÄÊ®°ÂûãÁöÑ"‰ΩøÁî®ËÄÖ"ÔºåËúïÂèò‰∏∫‰∏ÄÂêçÊô∫ËÉΩ‰ΩìÁ≥ªÁªüÁöÑ"ÊûÑÂª∫ËÄÖ"„ÄÇ&lt;/p&gt; 
&lt;h2&gt;üìö Âø´ÈÄüÂºÄÂßã&lt;/h2&gt; 
&lt;h3&gt;Âú®Á∫øÈòÖËØª&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://datawhalechina.github.io/hello-agents/"&gt;üåê ÁÇπÂáªËøôÈáåÂºÄÂßãÂú®Á∫øÈòÖËØª&lt;/a&gt;&lt;/strong&gt; - Êó†ÈúÄ‰∏ãËΩΩÔºåÈöèÊó∂ÈöèÂú∞Â≠¶‰π†&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://book.heterocat.com.cn/"&gt;üìñ Cookbook(ÊµãËØïÁâà)&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;h3&gt;Êú¨Âú∞ÈòÖËØª&lt;/h3&gt; 
&lt;p&gt;Â¶ÇÊûúÊÇ®Â∏åÊúõÂú®Êú¨Âú∞ÈòÖËØªÊàñË¥°ÁåÆÂÜÖÂÆπÔºåËØ∑ÂèÇËÄÉ‰∏ãÊñπÁöÑÂ≠¶‰π†ÊåáÂçó„ÄÇ&lt;/p&gt; 
&lt;h3&gt;‚ú® ‰Ω†Â∞ÜÊî∂Ëé∑‰ªÄ‰πàÔºü&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;üìñ &lt;strong&gt;Datawhale ÂºÄÊ∫êÂÖçË¥π&lt;/strong&gt; ÂÆåÂÖ®ÂÖçË¥πÂ≠¶‰π†Êú¨È°πÁõÆÊâÄÊúâÂÜÖÂÆπÔºå‰∏éÁ§æÂå∫ÂÖ±ÂêåÊàêÈïø&lt;/li&gt; 
 &lt;li&gt;üîç &lt;strong&gt;ÁêÜËß£Ê†∏ÂøÉÂéüÁêÜ&lt;/strong&gt; Ê∑±ÂÖ•ÁêÜËß£Êô∫ËÉΩ‰ΩìÁöÑÊ¶ÇÂøµ„ÄÅÂéÜÂè≤‰∏éÁªèÂÖ∏ËåÉÂºè&lt;/li&gt; 
 &lt;li&gt;üèóÔ∏è &lt;strong&gt;‰∫≤ÊâãÂÆûÁé∞&lt;/strong&gt; ÊéåÊè°ÁÉ≠Èó®‰Ωé‰ª£Á†ÅÂπ≥Âè∞ÂíåÊô∫ËÉΩ‰Ωì‰ª£Á†ÅÊ°ÜÊû∂ÁöÑ‰ΩøÁî®&lt;/li&gt; 
 &lt;li&gt;üõ†Ô∏è &lt;strong&gt;Ëá™Á†îÊ°ÜÊû∂&lt;a href="https://github.com/jjyaoao/helloagents"&gt;HelloAgents&lt;/a&gt;&lt;/strong&gt; Âü∫‰∫é Openai ÂéüÁîü API ‰ªéÈõ∂ÊûÑÂª∫‰∏Ä‰∏™Ëá™Â∑±ÁöÑÊô∫ËÉΩ‰ΩìÊ°ÜÊû∂&lt;/li&gt; 
 &lt;li&gt;‚öôÔ∏è &lt;strong&gt;ÊéåÊè°È´òÁ∫ßÊäÄËÉΩ&lt;/strong&gt; ‰∏ÄÊ≠•Ê≠•ÂÆûÁé∞‰∏ä‰∏ãÊñáÂ∑•Á®ã„ÄÅMemory„ÄÅÂçèËÆÆ„ÄÅËØÑ‰º∞Á≠âÁ≥ªÁªüÊÄßÊäÄÊúØ&lt;/li&gt; 
 &lt;li&gt;ü§ù &lt;strong&gt;Ê®°ÂûãËÆ≠ÁªÉ&lt;/strong&gt; ÊéåÊè° Agentic RLÔºå‰ªé SFT Âà∞ GRPO ÁöÑÂÖ®ÊµÅÁ®ãÂÆûÊàòËÆ≠ÁªÉ LLM&lt;/li&gt; 
 &lt;li&gt;üöÄ &lt;strong&gt;È©±Âä®ÁúüÂÆûÊ°à‰æã&lt;/strong&gt; ÂÆûÊàòÂºÄÂèëÊô∫ËÉΩÊóÖË°åÂä©Êâã„ÄÅËµõÂçöÂ∞èÈïáÁ≠âÁªºÂêàÈ°πÁõÆ&lt;/li&gt; 
 &lt;li&gt;üìñ &lt;strong&gt;Ê±ÇËÅåÈù¢ËØï&lt;/strong&gt; Â≠¶‰π†Êô∫ËÉΩ‰ΩìÊ±ÇËÅåÁõ∏ÂÖ≥Èù¢ËØïÈóÆÈ¢ò&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üìñ ÂÜÖÂÆπÂØºËà™&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Á´†ËäÇ&lt;/th&gt; 
   &lt;th&gt;ÂÖ≥ÈîÆÂÜÖÂÆπ&lt;/th&gt; 
   &lt;th&gt;Áä∂ÊÄÅ&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/%E5%89%8D%E8%A8%80.md"&gt;ÂâçË®Ä&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;È°πÁõÆÁöÑÁºòËµ∑„ÄÅËÉåÊôØÂèäËØªËÄÖÂª∫ËÆÆ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Á¨¨‰∏ÄÈÉ®ÂàÜÔºöÊô∫ËÉΩ‰Ωì‰∏éËØ≠Ë®ÄÊ®°ÂûãÂü∫Á°Ä&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/chapter1/%E7%AC%AC%E4%B8%80%E7%AB%A0%20%E5%88%9D%E8%AF%86%E6%99%BA%E8%83%BD%E4%BD%93.md"&gt;Á¨¨‰∏ÄÁ´† ÂàùËØÜÊô∫ËÉΩ‰Ωì&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Êô∫ËÉΩ‰ΩìÂÆö‰πâ„ÄÅÁ±ªÂûã„ÄÅËåÉÂºè‰∏éÂ∫îÁî®&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/chapter2/%E7%AC%AC%E4%BA%8C%E7%AB%A0%20%E6%99%BA%E8%83%BD%E4%BD%93%E5%8F%91%E5%B1%95%E5%8F%B2.md"&gt;Á¨¨‰∫åÁ´† Êô∫ËÉΩ‰ΩìÂèëÂ±ïÂè≤&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‰ªéÁ¨¶Âè∑‰∏ª‰πâÂà∞ LLM È©±Âä®ÁöÑÊô∫ËÉΩ‰ΩìÊºîËøõ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/chapter3/%E7%AC%AC%E4%B8%89%E7%AB%A0%20%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80.md"&gt;Á¨¨‰∏âÁ´† Â§ßËØ≠Ë®ÄÊ®°ÂûãÂü∫Á°Ä&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Transformer„ÄÅÊèêÁ§∫„ÄÅ‰∏ªÊµÅ LLM ÂèäÂÖ∂Â±ÄÈôê&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Á¨¨‰∫åÈÉ®ÂàÜÔºöÊûÑÂª∫‰Ω†ÁöÑÂ§ßËØ≠Ë®ÄÊ®°ÂûãÊô∫ËÉΩ‰Ωì&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/chapter4/%E7%AC%AC%E5%9B%9B%E7%AB%A0%20%E6%99%BA%E8%83%BD%E4%BD%93%E7%BB%8F%E5%85%B8%E8%8C%83%E5%BC%8F%E6%9E%84%E5%BB%BA.md"&gt;Á¨¨ÂõõÁ´† Êô∫ËÉΩ‰ΩìÁªèÂÖ∏ËåÉÂºèÊûÑÂª∫&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;ÊâãÊääÊâãÂÆûÁé∞ ReAct„ÄÅPlan-and-Solve„ÄÅReflection&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/chapter5/%E7%AC%AC%E4%BA%94%E7%AB%A0%20%E5%9F%BA%E4%BA%8E%E4%BD%8E%E4%BB%A3%E7%A0%81%E5%B9%B3%E5%8F%B0%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93%E6%90%AD%E5%BB%BA.md"&gt;Á¨¨‰∫îÁ´† Âü∫‰∫é‰Ωé‰ª£Á†ÅÂπ≥Âè∞ÁöÑÊô∫ËÉΩ‰ΩìÊê≠Âª∫&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‰∫ÜËß£ Coze„ÄÅDify„ÄÅn8n Á≠â‰Ωé‰ª£Á†ÅÊô∫ËÉΩ‰ΩìÂπ≥Âè∞‰ΩøÁî®&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/chapter6/%E7%AC%AC%E5%85%AD%E7%AB%A0%20%E6%A1%86%E6%9E%B6%E5%BC%80%E5%8F%91%E5%AE%9E%E8%B7%B5.md"&gt;Á¨¨ÂÖ≠Á´† Ê°ÜÊû∂ÂºÄÂèëÂÆûË∑µ&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;AutoGen„ÄÅAgentScope„ÄÅLangGraph Á≠â‰∏ªÊµÅÊ°ÜÊû∂Â∫îÁî®&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/chapter7/%E7%AC%AC%E4%B8%83%E7%AB%A0%20%E6%9E%84%E5%BB%BA%E4%BD%A0%E7%9A%84Agent%E6%A1%86%E6%9E%B6.md"&gt;Á¨¨‰∏ÉÁ´† ÊûÑÂª∫‰Ω†ÁöÑAgentÊ°ÜÊû∂&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‰ªé 0 ÂºÄÂßãÊûÑÂª∫Êô∫ËÉΩ‰ΩìÊ°ÜÊû∂&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Á¨¨‰∏âÈÉ®ÂàÜÔºöÈ´òÁ∫ßÁü•ËØÜÊâ©Â±ï&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/chapter8/%E7%AC%AC%E5%85%AB%E7%AB%A0%20%E8%AE%B0%E5%BF%86%E4%B8%8E%E6%A3%80%E7%B4%A2.md"&gt;Á¨¨ÂÖ´Á´† ËÆ∞ÂøÜ‰∏éÊ£ÄÁ¥¢&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;ËÆ∞ÂøÜÁ≥ªÁªüÔºåRAGÔºåÂ≠òÂÇ®&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/chapter9/%E7%AC%AC%E4%B9%9D%E7%AB%A0%20%E4%B8%8A%E4%B8%8B%E6%96%87%E5%B7%A5%E7%A8%8B.md"&gt;Á¨¨‰πùÁ´† ‰∏ä‰∏ãÊñáÂ∑•Á®ã&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;ÊåÅÁª≠‰∫§‰∫íÁöÑ"ÊÉÖÂ¢ÉÁêÜËß£"&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/chapter10/%E7%AC%AC%E5%8D%81%E7%AB%A0%20%E6%99%BA%E8%83%BD%E4%BD%93%E9%80%9A%E4%BF%A1%E5%8D%8F%E8%AE%AE.md"&gt;Á¨¨ÂçÅÁ´† Êô∫ËÉΩ‰ΩìÈÄö‰ø°ÂçèËÆÆ&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;MCP„ÄÅA2A„ÄÅANP Á≠âÂçèËÆÆËß£Êûê&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/chapter11/%E7%AC%AC%E5%8D%81%E4%B8%80%E7%AB%A0%20Agentic-RL.md"&gt;Á¨¨ÂçÅ‰∏ÄÁ´† Agentic-RL&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‰ªé SFT Âà∞ GRPO ÁöÑ LLM ËÆ≠ÁªÉÂÆûÊàò&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/chapter12/%E7%AC%AC%E5%8D%81%E4%BA%8C%E7%AB%A0%20%E6%99%BA%E8%83%BD%E4%BD%93%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0.md"&gt;Á¨¨ÂçÅ‰∫åÁ´† Êô∫ËÉΩ‰ΩìÊÄßËÉΩËØÑ‰º∞&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Ê†∏ÂøÉÊåáÊ†á„ÄÅÂü∫ÂáÜÊµãËØï‰∏éËØÑ‰º∞Ê°ÜÊû∂&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Á¨¨ÂõõÈÉ®ÂàÜÔºöÁªºÂêàÊ°à‰æãËøõÈò∂&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/chapter13/%E7%AC%AC%E5%8D%81%E4%B8%89%E7%AB%A0%20%E6%99%BA%E8%83%BD%E6%97%85%E8%A1%8C%E5%8A%A9%E6%89%8B.md"&gt;Á¨¨ÂçÅ‰∏âÁ´† Êô∫ËÉΩÊóÖË°åÂä©Êâã&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;MCP ‰∏éÂ§öÊô∫ËÉΩ‰ΩìÂçè‰ΩúÁöÑÁúüÂÆû‰∏ñÁïåÂ∫îÁî®&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/chapter14/%E7%AC%AC%E5%8D%81%E5%9B%9B%E7%AB%A0%20%E8%87%AA%E5%8A%A8%E5%8C%96%E6%B7%B1%E5%BA%A6%E7%A0%94%E7%A9%B6%E6%99%BA%E8%83%BD%E4%BD%93.md"&gt;Á¨¨ÂçÅÂõõÁ´† Ëá™Âä®ÂåñÊ∑±Â∫¶Á†îÁ©∂Êô∫ËÉΩ‰Ωì&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;DeepResearch Agent Â§çÁé∞‰∏éËß£Êûê&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/chapter15/%E7%AC%AC%E5%8D%81%E4%BA%94%E7%AB%A0%20%E6%9E%84%E5%BB%BA%E8%B5%9B%E5%8D%9A%E5%B0%8F%E9%95%87.md"&gt;Á¨¨ÂçÅ‰∫îÁ´† ÊûÑÂª∫ËµõÂçöÂ∞èÈïá&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Agent ‰∏éÊ∏∏ÊàèÁöÑÁªìÂêàÔºåÊ®°ÊãüÁ§æ‰ºöÂä®ÊÄÅ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Á¨¨‰∫îÈÉ®ÂàÜÔºöÊØï‰∏öËÆæËÆ°ÂèäÊú™Êù•Â±ïÊúõ&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/chapter16/%E7%AC%AC%E5%8D%81%E5%85%AD%E7%AB%A0%20%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1.md"&gt;Á¨¨ÂçÅÂÖ≠Á´† ÊØï‰∏öËÆæËÆ°&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;ÊûÑÂª∫Â±û‰∫é‰Ω†ÁöÑÂÆåÊï¥Â§öÊô∫ËÉΩ‰ΩìÂ∫îÁî®&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Á§æÂå∫Ë¥°ÁåÆÁ≤æÈÄâ (Community Blog)&lt;/h3&gt; 
&lt;p&gt;‚ÄÉ‚ÄÉÊ¨¢ËøéÂ§ßÂÆ∂Â∞ÜÂú®Â≠¶‰π† Hello-Agents Êàñ Agent Áõ∏ÂÖ≥ÊäÄÊúØ‰∏≠ÁöÑÁã¨Âà∞ËßÅËß£„ÄÅÂÆûË∑µÊÄªÁªìÔºå‰ª• PR ÁöÑÂΩ¢ÂºèË¥°ÁåÆÂà∞Á§æÂå∫Á≤æÈÄâ„ÄÇÂ¶ÇÊûúÊòØÁã¨Á´ã‰∫éÊ≠£ÊñáÁöÑÂÜÖÂÆπÔºå‰πüÂèØ‰ª•ÊäïÁ®øËá≥ Extra-ChapterÔºÅ&lt;strong&gt;ÊúüÂæÖ‰Ω†ÁöÑÁ¨¨‰∏ÄÊ¨°Ë¥°ÁåÆÔºÅ&lt;/strong&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Á§æÂå∫Á≤æÈÄâ&lt;/th&gt; 
   &lt;th&gt;ÂÜÖÂÆπÊÄªÁªì&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/datawhalechina/hello-agents/raw/main/Extra-Chapter/Extra01-%E9%9D%A2%E8%AF%95%E9%97%AE%E9%A2%98%E6%80%BB%E7%BB%93.md"&gt;01-AgentÈù¢ËØïÈ¢òÊÄªÁªì&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Agent Â≤ó‰ΩçÁõ∏ÂÖ≥Èù¢ËØïÈóÆÈ¢ò&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/datawhalechina/hello-agents/raw/main/Extra-Chapter/Extra01-%E5%8F%82%E8%80%83%E7%AD%94%E6%A1%88.md"&gt;01-AgentÈù¢ËØïÈ¢òÁ≠îÊ°à&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Áõ∏ÂÖ≥Èù¢ËØïÈóÆÈ¢òÁ≠îÊ°à&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/datawhalechina/hello-agents/raw/main/Extra-Chapter/Extra02-%E4%B8%8A%E4%B8%8B%E6%96%87%E5%B7%A5%E7%A8%8B%E8%A1%A5%E5%85%85%E7%9F%A5%E8%AF%86.md"&gt;02-‰∏ä‰∏ãÊñáÂ∑•Á®ãÂÜÖÂÆπË°•ÂÖÖ&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‰∏ä‰∏ãÊñáÂ∑•Á®ãÂÜÖÂÆπÊâ©Â±ï&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/datawhalechina/hello-agents/raw/main/Extra-Chapter/Extra03-Dify%E6%99%BA%E8%83%BD%E4%BD%93%E5%88%9B%E5%BB%BA%E4%BF%9D%E5%A7%86%E7%BA%A7%E6%93%8D%E4%BD%9C%E6%B5%81%E7%A8%8B.md"&gt;03-DifyÊô∫ËÉΩ‰ΩìÂàõÂª∫‰øùÂßÜÁ∫ßÊïôÁ®ã&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;DifyÊô∫ËÉΩ‰ΩìÂàõÂª∫‰øùÂßÜÁ∫ßÊïôÁ®ã&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/datawhalechina/hello-agents/raw/main/Extra-Chapter/Extra04-DatawhaleFAQ.md"&gt;04-Hello-agentsËØæÁ®ãÂ∏∏ËßÅÈóÆÈ¢ò&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;DatawhaleËØæÁ®ãÂ∏∏ËßÅÈóÆÈ¢ò&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;PDF ÁâàÊú¨‰∏ãËΩΩ&lt;/h3&gt; 
&lt;p&gt;‚ÄÉ‚ÄÉ&lt;em&gt;&lt;strong&gt;Êú¨ Hello-Agents PDF ÊïôÁ®ãÂÆåÂÖ®ÂºÄÊ∫êÂÖçË¥π„ÄÇ‰∏∫Èò≤Ê≠¢ÂêÑÁ±ªËê•ÈîÄÂè∑Âä†Ê∞¥Âç∞ÂêéË¥©ÂçñÁªôÂ§öÊô∫ËÉΩ‰ΩìÁ≥ªÁªüÂàùÂ≠¶ËÄÖÔºåÊàë‰ª¨ÁâπÂú∞Âú® PDF Êñá‰ª∂‰∏≠È¢ÑÂÖàÊ∑ªÂä†‰∫Ü‰∏çÂΩ±ÂìçÈòÖËØªÁöÑ Datawhale ÂºÄÊ∫êÊ†áÂøóÊ∞¥Âç∞ÔºåÊï¨ËØ∑Ë∞ÖËß£ÔΩû&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;em&gt;Hello-Agents PDF : &lt;a href="https://github.com/datawhalechina/hello-agents/releases/tag/V1.0.0"&gt;https://github.com/datawhalechina/hello-agents/releases/tag/V1.0.0&lt;/a&gt;&lt;/em&gt;&lt;br /&gt; &lt;em&gt;Hello-Agents PDF ÂõΩÂÜÖ‰∏ãËΩΩÂú∞ÂùÄ : &lt;a href="https://www.datawhale.cn/learn/summary/239"&gt;https://www.datawhale.cn/learn/summary/239&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;üí° Â¶Ç‰ΩïÂ≠¶‰π†&lt;/h2&gt; 
&lt;p&gt;‚ÄÉ‚ÄÉÊ¨¢Ëøé‰Ω†ÔºåÊú™Êù•ÁöÑÊô∫ËÉΩÁ≥ªÁªüÊûÑÂª∫ËÄÖÔºÅÂú®ÂºÄÂêØËøôÊÆµÊøÄÂä®‰∫∫ÂøÉÁöÑÊóÖÁ®ã‰πãÂâçÔºåËØ∑ÂÖÅËÆ∏Êàë‰ª¨Áªô‰Ω†‰∏Ä‰∫õÊ∏ÖÊô∞ÁöÑÊåáÂºï„ÄÇ&lt;/p&gt; 
&lt;p&gt;‚ÄÉ‚ÄÉÊú¨È°πÁõÆÂÜÖÂÆπÂÖºÈ°æÁêÜËÆ∫‰∏éÂÆûÊàòÔºåÊó®Âú®Â∏ÆÂä©‰Ω†Á≥ªÁªüÊÄßÂú∞ÊéåÊè°‰ªéÂçï‰∏™Êô∫ËÉΩ‰ΩìÂà∞Â§öÊô∫ËÉΩ‰ΩìÁ≥ªÁªüÁöÑËÆæËÆ°‰∏éÂºÄÂèëÂÖ®ÊµÅÁ®ã„ÄÇÂõ†Ê≠§ÔºåÂ∞§ÂÖ∂ÈÄÇÂêàÊúâ‰∏ÄÂÆöÁºñÁ®ãÂü∫Á°ÄÁöÑ &lt;strong&gt;AI ÂºÄÂèëËÄÖ„ÄÅËΩØ‰ª∂Â∑•Á®ãÂ∏à„ÄÅÂú®Ê†°Â≠¶Áîü&lt;/strong&gt; ‰ª•ÂèäÂØπÂâçÊ≤ø AI ÊäÄÊúØÊä±ÊúâÊµìÂéöÂÖ¥Ë∂£ÁöÑ &lt;strong&gt;Ëá™Â≠¶ËÄÖ&lt;/strong&gt;„ÄÇÂú®Â≠¶‰π†Êú¨È°πÁõÆ‰πãÂâçÔºåÊàë‰ª¨Â∏åÊúõ‰Ω†ÂÖ∑Â§áÂü∫Á°ÄÁöÑ Python ÁºñÁ®ãËÉΩÂäõÔºåÂπ∂ÂØπÂ§ßËØ≠Ë®ÄÊ®°ÂûãÊúâÂü∫Êú¨ÁöÑÊ¶ÇÂøµÊÄß‰∫ÜËß£Ôºà‰æãÂ¶ÇÔºåÁü•ÈÅìÂ¶Ç‰ΩïÈÄöËøá API Ë∞ÉÁî®‰∏Ä‰∏™ LLMÔºâ„ÄÇÈ°πÁõÆÁöÑÈáçÁÇπÊòØÂ∫îÁî®‰∏éÊûÑÂª∫ÔºåÂõ†Ê≠§‰Ω†Êó†ÈúÄÂÖ∑Â§áÊ∑±ÂéöÁöÑÁÆóÊ≥ïÊàñÊ®°ÂûãËÆ≠ÁªÉËÉåÊôØ„ÄÇ&lt;/p&gt; 
&lt;p&gt;‚ÄÉ‚ÄÉÈ°πÁõÆÂàÜ‰∏∫‰∫îÂ§ßÈÉ®ÂàÜÔºåÊØè‰∏ÄÈÉ®ÂàÜÈÉΩÊòØÈÄöÂæÄ‰∏ã‰∏ÄÈò∂ÊÆµÁöÑÂùöÂÆûÈò∂Ê¢ØÔºö&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Á¨¨‰∏ÄÈÉ®ÂàÜÔºöÊô∫ËÉΩ‰Ωì‰∏éËØ≠Ë®ÄÊ®°ÂûãÂü∫Á°Ä&lt;/strong&gt;ÔºàÁ¨¨‰∏ÄÁ´†ÔΩûÁ¨¨‰∏âÁ´†ÔºâÔºåÊàë‰ª¨Â∞Ü‰ªéÊô∫ËÉΩ‰ΩìÁöÑÂÆö‰πâ„ÄÅÁ±ªÂûã‰∏éÂèëÂ±ïÂéÜÂè≤ËÆ≤Ëµ∑Ôºå‰∏∫‰Ω†Ê¢≥ÁêÜ"Êô∫ËÉΩ‰Ωì"Ëøô‰∏ÄÊ¶ÇÂøµÁöÑÊù•ÈæôÂéªËÑâ„ÄÇÈöèÂêéÔºåÊàë‰ª¨‰ºöÂø´ÈÄüÂ∑©Âõ∫Â§ßËØ≠Ë®ÄÊ®°ÂûãÁöÑÊ†∏ÂøÉÁü•ËØÜÔºå‰∏∫‰Ω†ÁöÑÂÆûË∑µ‰πãÊóÖÊâì‰∏ãÂùöÂÆûÁöÑÁêÜËÆ∫Âú∞Âü∫„ÄÇ&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Á¨¨‰∫åÈÉ®ÂàÜÔºöÊûÑÂª∫‰Ω†ÁöÑÂ§ßËØ≠Ë®ÄÊ®°ÂûãÊô∫ËÉΩ‰Ωì&lt;/strong&gt;ÔºàÁ¨¨ÂõõÁ´†ÔΩûÁ¨¨‰∏ÉÁ´†ÔºâÔºåËøôÊòØ‰Ω†Âä®ÊâãÂÆûË∑µÁöÑËµ∑ÁÇπ„ÄÇ‰Ω†Â∞Ü‰∫≤ÊâãÂÆûÁé∞ ReAct Á≠âÁªèÂÖ∏ËåÉÂºèÔºå‰ΩìÈ™å Coze Á≠â‰Ωé‰ª£Á†ÅÂπ≥Âè∞ÁöÑ‰æøÊç∑ÔºåÂπ∂ÊéåÊè° Langgraph Á≠â‰∏ªÊµÅÊ°ÜÊû∂ÁöÑÂ∫îÁî®„ÄÇÊúÄÁªàÔºåÊàë‰ª¨Ëøò‰ºöÂ∏¶‰Ω†‰ªéÈõ∂ÂºÄÂßãÊûÑÂª∫‰∏Ä‰∏™Â±û‰∫éËá™Â∑±ÁöÑÊô∫ËÉΩ‰ΩìÊ°ÜÊû∂ÔºåËÆ©‰Ω†ÂÖºÂÖ∑‚ÄúÁî®ËΩÆÂ≠ê‚Äù‰∏é‚ÄúÈÄ†ËΩÆÂ≠ê‚ÄùÁöÑËÉΩÂäõ„ÄÇ&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Á¨¨‰∏âÈÉ®ÂàÜÔºöÈ´òÁ∫ßÁü•ËØÜÊâ©Â±ï&lt;/strong&gt;ÔºàÁ¨¨ÂÖ´Á´†ÔΩûÁ¨¨ÂçÅ‰∫åÁ´†ÔºâÔºåÂú®Ëøô‰∏ÄÈÉ®ÂàÜÔºå‰Ω†ÁöÑÊô∫ËÉΩ‰ΩìÂ∞Ü‚ÄúÂ≠¶‰ºö‚ÄùÊÄùËÄÉ‰∏éÂçè‰Ωú„ÄÇÊàë‰ª¨Â∞Ü‰ΩøÁî®Á¨¨‰∫åÈÉ®ÂàÜÁöÑËá™Á†îÊ°ÜÊû∂ÔºåÊ∑±ÂÖ•Êé¢Á¥¢ËÆ∞ÂøÜ‰∏éÊ£ÄÁ¥¢„ÄÅ‰∏ä‰∏ãÊñáÂ∑•Á®ã„ÄÅAgent ËÆ≠ÁªÉÁ≠âÊ†∏ÂøÉÊäÄÊúØÔºåÂπ∂Â≠¶‰π†Â§öÊô∫ËÉΩ‰ΩìÈó¥ÁöÑÈÄö‰ø°ÂçèËÆÆ„ÄÇÊúÄÁªàÔºå‰Ω†Â∞ÜÊéåÊè°ËØÑ‰º∞Êô∫ËÉΩ‰ΩìÁ≥ªÁªüÊÄßËÉΩÁöÑ‰∏ì‰∏öÊñπÊ≥ï„ÄÇ&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Á¨¨ÂõõÈÉ®ÂàÜÔºöÁªºÂêàÊ°à‰æãËøõÈò∂&lt;/strong&gt;ÔºàÁ¨¨ÂçÅ‰∏âÁ´†ÔΩûÁ¨¨ÂçÅ‰∫îÁ´†ÔºâÔºåËøôÈáåÊòØÁêÜËÆ∫‰∏éÂÆûË∑µÁöÑ‰∫§Ê±áÁÇπ„ÄÇ‰Ω†Â∞ÜÊääÊâÄÂ≠¶Ëûç‰ºöË¥ØÈÄöÔºå‰∫≤ÊâãÊâìÈÄ†Êô∫ËÉΩÊóÖË°åÂä©Êâã„ÄÅËá™Âä®ÂåñÊ∑±Â∫¶Á†îÁ©∂Êô∫ËÉΩ‰ΩìÔºå‰πÉËá≥‰∏Ä‰∏™Ê®°ÊãüÁ§æ‰ºöÂä®ÊÄÅÁöÑËµõÂçöÂ∞èÈïáÔºåÂú®ÁúüÂÆûÊúâË∂£ÁöÑÈ°πÁõÆ‰∏≠Ê∑¨ÁÇº‰Ω†ÁöÑÊûÑÂª∫ËÉΩÂäõ„ÄÇ&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Á¨¨‰∫îÈÉ®ÂàÜÔºöÊØï‰∏öËÆæËÆ°ÂèäÊú™Êù•Â±ïÊúõ&lt;/strong&gt;ÔºàÁ¨¨ÂçÅÂÖ≠Á´†ÔºâÔºåÂú®ÊóÖÁ®ãÁöÑÁªàÁÇπÔºå‰Ω†Â∞ÜËøéÊù•‰∏Ä‰∏™ÊØï‰∏öËÆæËÆ°ÔºåÊûÑÂª∫‰∏Ä‰∏™ÂÆåÊï¥ÁöÑ„ÄÅÂ±û‰∫é‰Ω†Ëá™Â∑±ÁöÑÂ§öÊô∫ËÉΩ‰ΩìÂ∫îÁî®ÔºåÂÖ®Èù¢Ê£ÄÈ™å‰Ω†ÁöÑÂ≠¶‰π†ÊàêÊûú„ÄÇÊàë‰ª¨ËøòÂ∞Ü‰∏é‰Ω†‰∏ÄÂêåÂ±ïÊúõÊô∫ËÉΩ‰ΩìÁöÑÊú™Êù•ÔºåÊé¢Á¥¢ÊøÄÂä®‰∫∫ÂøÉÁöÑÂâçÊ≤øÊñπÂêë„ÄÇ&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;‚ÄÉ‚ÄÉÊô∫ËÉΩ‰ΩìÊòØ‰∏Ä‰∏™È£ûÈÄüÂèëÂ±ï‰∏îÊûÅÂ∫¶‰æùËµñÂÆûË∑µÁöÑÈ¢ÜÂüü„ÄÇ‰∏∫‰∫ÜËé∑ÂæóÊúÄ‰Ω≥ÁöÑÂ≠¶‰π†ÊïàÊûúÔºåÊàë‰ª¨Âú®È°πÁõÆÁöÑ&lt;code&gt;code&lt;/code&gt;Êñá‰ª∂Â§πÂÜÖÊèê‰æõ‰∫ÜÈÖçÂ•óÁöÑÂÖ®ÈÉ®‰ª£Á†ÅÔºåÂº∫ÁÉàÂª∫ËÆÆ‰Ω†&lt;strong&gt;Â∞ÜÁêÜËÆ∫‰∏éÂÆûË∑µÁõ∏ÁªìÂêà&lt;/strong&gt;„ÄÇËØ∑Âä°ÂøÖ‰∫≤ÊâãËøêË°å„ÄÅË∞ÉËØïÁîöËá≥‰øÆÊîπÈ°πÁõÆÈáåÊèê‰æõÁöÑÊØè‰∏Ä‰ªΩ‰ª£Á†Å„ÄÇÊ¨¢Ëøé‰Ω†ÈöèÊó∂ÂÖ≥Ê≥® Datawhale ‰ª•ÂèäÂÖ∂‰ªñ Agent Áõ∏ÂÖ≥Á§æÂå∫ÔºåÂΩìÈÅáÂà∞ÈóÆÈ¢òÊó∂Ôºå‰Ω†ÂèØ‰ª•ÈöèÊó∂Âú®Êú¨È°πÁõÆÁöÑ issue Âå∫ÊèêÈóÆ„ÄÇ&lt;/p&gt; 
&lt;p&gt;‚ÄÉ‚ÄÉÁé∞Âú®ÔºåÂáÜÂ§áÂ•ΩËøõÂÖ•Êô∫ËÉΩ‰ΩìÁöÑÂ•áÂ¶ô‰∏ñÁïå‰∫ÜÂêóÔºüËÆ©Êàë‰ª¨Âç≥ÂàªÂêØÁ®ãÔºÅ&lt;/p&gt; 
&lt;h2&gt;‰∏ã‰∏ÄÊ≠•ËßÑÂàí&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;[]Ëã±ÊñáÁâàÊïôÁ®ã&lt;/li&gt; 
 &lt;li&gt;[]ÂèåËØ≠ËßÜÈ¢ëËØæÁ®ã[Ëã±Êñá+‰∏≠Êñá]ÔºàÂ∞Ü‰ºöÊõ¥Âä†ÁªÜËá¥ÔºåÂÆûË∑µËØæÂ∏¶È¢ÜÂ§ßÂÆ∂‰ªéËÆæËÆ°ÊÄùË∑ØÂà∞ÂÆûÊñΩÔºåÊéà‰∫∫‰ª•È±º‰πüÊéà‰∫∫‰ª•Ê∏îÔºâ&lt;/li&gt; 
 &lt;li&gt;[]ÂÖ±ÂàõÁ¨¨16Á´†ÔºàÊâìÈÄ†ÂêÑÁ±ªAgentÂ∫îÁî®,Êõ¥ÊâìÈÄ†AgentÁîüÊÄÅÔºâ&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ü§ù Â¶Ç‰ΩïË¥°ÁåÆ&lt;/h2&gt; 
&lt;p&gt;Êàë‰ª¨ÊòØ‰∏Ä‰∏™ÂºÄÊîæÁöÑÂºÄÊ∫êÁ§æÂå∫ÔºåÊ¨¢Ëøé‰ªª‰ΩïÂΩ¢ÂºèÁöÑË¥°ÁåÆÔºÅ&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;üêõ &lt;strong&gt;Êä•Âëä Bug&lt;/strong&gt; - ÂèëÁé∞ÂÜÖÂÆπÊàñ‰ª£Á†ÅÈóÆÈ¢òÔºåËØ∑Êèê‰∫§ Issue&lt;/li&gt; 
 &lt;li&gt;üí° &lt;strong&gt;ÊèêÂá∫Âª∫ËÆÆ&lt;/strong&gt; - ÂØπÈ°πÁõÆÊúâÂ•ΩÊÉ≥Ê≥ïÔºåÊ¨¢ËøéÂèëËµ∑ËÆ®ËÆ∫&lt;/li&gt; 
 &lt;li&gt;üìù &lt;strong&gt;ÂÆåÂñÑÂÜÖÂÆπ&lt;/strong&gt; - Â∏ÆÂä©ÊîπËøõÊïôÁ®ãÔºåÊèê‰∫§‰Ω†ÁöÑ Pull Request&lt;/li&gt; 
 &lt;li&gt;‚úçÔ∏è &lt;strong&gt;ÂàÜ‰∫´ÂÆûË∑µ&lt;/strong&gt; - Âú®"Á§æÂå∫Ë¥°ÁåÆÁ≤æÈÄâ"‰∏≠ÂàÜ‰∫´‰Ω†ÁöÑÂ≠¶‰π†Á¨îËÆ∞ÂíåÈ°πÁõÆ&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üôè Ëá¥Ë∞¢&lt;/h2&gt; 
&lt;h3&gt;Ê†∏ÂøÉË¥°ÁåÆËÄÖ&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jjyaoao"&gt;ÈôàÊÄùÂ∑û-È°πÁõÆË¥üË¥£‰∫∫&lt;/a&gt; (Datawhale ÊàêÂëò, ÂÖ®ÊñáÂÜô‰ΩúÂíåÊ†°ÂØπ)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/fengju0213"&gt;Â≠ôÈü¨-È°πÁõÆË¥üË¥£‰∫∫&lt;/a&gt; (Datawhale ÊàêÂëò, Á¨¨‰πùÁ´†ÂÜÖÂÆπÂíåÊ†°ÂØπ)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Tsumugii24"&gt;ÂßúËàíÂá°-È°πÁõÆË¥üË¥£‰∫∫&lt;/a&gt;ÔºàDatawhale ÊàêÂëò, Á´†ËäÇ‰π†È¢òËÆæËÆ°ÂíåÊ†°ÂØπÔºâ&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/HeteroCat"&gt;ÈªÑ‰Ω©Êûó-DatawhaleÊÑèÂêëÊàêÂëò&lt;/a&gt; (Agent ÂºÄÂèëÂ∑•Á®ãÂ∏à, Á¨¨‰∫îÁ´†ÂÜÖÂÆπË¥°ÁåÆËÄÖ)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/fancyboi999"&gt;ÊõæÈë´Ê∞ë-AgentÂ∑•Á®ãÂ∏à&lt;/a&gt; (ÁâõÂÆ¢ÁßëÊäÄ, Á¨¨ÂçÅÂõõÁ´†Ê°à‰æãÂºÄÂèë)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://xinzhongzhu.github.io/"&gt;Êú±‰ø°Âø†-ÊåáÂØº‰∏ìÂÆ∂&lt;/a&gt; (DatawhaleÈ¶ñÂ∏≠ÁßëÂ≠¶ÂÆ∂-ÊµôÊ±üÂ∏àËåÉÂ§ßÂ≠¶Êù≠Â∑û‰∫∫Â∑•Êô∫ËÉΩÁ†îÁ©∂Èô¢ÊïôÊéà)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Extra-Chapter Ë¥°ÁåÆËÄÖ&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/WHQAQ11"&gt;WH&lt;/a&gt; (ÂÜÖÂÆπË¥°ÁåÆËÄÖ)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/thunderbolt-fire"&gt;Âë®Â••Êù∞-DWË¥°ÁåÆËÄÖÂõ¢Èòü&lt;/a&gt; (Ë•øÂÆâ‰∫§ÈÄöÂ§ßÂ≠¶, Extra02 ÂÜÖÂÆπË¥°ÁåÆ)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Tasselszcx"&gt;Âº†ÂÆ∏Êó≠-‰∏™‰∫∫ÂºÄÂèëËÄÖ&lt;/a&gt;(Â∏ùÂõΩÁêÜÂ∑•Â≠¶Èô¢, Extra03 ÂÜÖÂÆπË¥°ÁåÆ)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/XiaoMa-PM"&gt;ÈªÑÂÆèÊôó-DWË¥°ÁåÆËÄÖÂõ¢Èòü&lt;/a&gt; (Ê∑±Âú≥Â§ßÂ≠¶, Extra04 ÂÜÖÂÆπË¥°ÁåÆ)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;ÁâπÂà´ÊÑüË∞¢&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;ÊÑüË∞¢ &lt;a href="https://github.com/Sm1les"&gt;@Sm1les&lt;/a&gt; ÂØπÊú¨È°πÁõÆÁöÑÂ∏ÆÂä©‰∏éÊîØÊåÅ&lt;/li&gt; 
 &lt;li&gt;ÊÑüË∞¢ÊâÄÊúâ‰∏∫Êú¨È°πÁõÆÂÅöÂá∫Ë¥°ÁåÆÁöÑÂºÄÂèëËÄÖ‰ª¨ ‚ù§Ô∏è&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div align="center" style="margin-top: 30px;"&gt; 
 &lt;a href="https://github.com/datawhalechina/Hello-Agents/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=datawhalechina/Hello-Agents" /&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;h2&gt;Star History&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/images/star-history-20251212.png" alt="Datawhale" width="90%" /&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;‚≠ê Â¶ÇÊûúËøô‰∏™È°πÁõÆÂØπ‰Ω†ÊúâÂ∏ÆÂä©ÔºåËØ∑ÁªôÊàë‰ª¨‰∏Ä‰∏™ StarÔºÅ&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;ÂÖ≥‰∫é Datawhale&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/images/datawhale.png" alt="Datawhale" width="30%" /&gt; 
 &lt;p&gt;Êâ´Êèè‰∫åÁª¥Á†ÅÂÖ≥Ê≥® Datawhale ÂÖ¨‰ºóÂè∑ÔºåËé∑ÂèñÊõ¥Â§ö‰ºòË¥®ÂºÄÊ∫êÂÜÖÂÆπ&lt;/p&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üìú ÂºÄÊ∫êÂçèËÆÆ&lt;/h2&gt; 
&lt;p&gt;Êú¨‰ΩúÂìÅÈááÁî®&lt;a href="http://creativecommons.org/licenses/by-nc-sa/4.0/"&gt;Áü•ËØÜÂÖ±‰∫´ÁΩ≤Âêç-ÈùûÂïÜ‰∏öÊÄß‰ΩøÁî®-Áõ∏ÂêåÊñπÂºèÂÖ±‰∫´ 4.0 ÂõΩÈôÖËÆ∏ÂèØÂçèËÆÆ&lt;/a&gt;ËøõË°åËÆ∏ÂèØ„ÄÇ&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>mindsdb/mindsdb</title>
      <link>https://github.com/mindsdb/mindsdb</link>
      <description>&lt;p&gt;Federated query engine for AI - The only MCP Server you'll ever need&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a name="readme-top"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://pypi.org/project/MindsDB/" target="_blank"&gt;&lt;img src="https://badge.fury.io/py/MindsDB.svg?sanitize=true" alt="MindsDB Release" /&gt;&lt;/a&gt; 
 &lt;a href="https://www.python.org/downloads/" target="_blank"&gt;&lt;img src="https://img.shields.io/badge/python-3.10.x%7C%203.11.x%7C%203.12.x%7C%203.13.x-brightgreen.svg?sanitize=true" alt="Python supported" /&gt;&lt;/a&gt; 
 &lt;a href="https://hub.docker.com/u/mindsdb" target="_blank"&gt;&lt;img src="https://img.shields.io/docker/pulls/mindsdb/mindsdb" alt="Docker pulls" /&gt;&lt;/a&gt; 
 &lt;br /&gt; 
 &lt;br /&gt; 
 &lt;p&gt;&lt;a href="https://trendshift.io/repositories/3068" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/3068" alt="mindsdb%2Fmindsdb | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;a href="https://github.com/mindsdb/mindsdb"&gt; &lt;img src="https://raw.githubusercontent.com/mindsdb/mindsdb/main/docs/assets/mindsdb_logo.png" alt="MindsDB" width="300" /&gt; &lt;/a&gt; 
 &lt;p align="center"&gt; &lt;br /&gt; &lt;a href="https://www.mindsdb.com?utm_medium=community&amp;amp;utm_source=github&amp;amp;utm_campaign=mindsdb%20repo"&gt;Website&lt;/a&gt; ¬∑ &lt;a href="https://docs.mindsdb.com?utm_medium=community&amp;amp;utm_source=github&amp;amp;utm_campaign=mindsdb%20repo"&gt;Docs&lt;/a&gt; ¬∑ &lt;a href="https://mindsdb.com/contact"&gt;Contact us for a Demo&lt;/a&gt; ¬∑ &lt;a href="https://mindsdb.com/joincommunity?utm_medium=community&amp;amp;utm_source=github&amp;amp;utm_campaign=mindsdb%20repo"&gt;Community Slack&lt;/a&gt; &lt;/p&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;p&gt;MindsDB enables humans, AI, agents, and applications to get highly accurate answers across large scale data sources.&lt;/p&gt; 
&lt;a href="https://www.youtube.com/watch?v=MX3OKpnsoLM" target="_blank"&gt; &lt;img src="https://github.com/user-attachments/assets/119e7b82-f901-4214-a26f-ff7c5ad86064" alt="MindsDB Demo" /&gt; &lt;/a&gt; 
&lt;h2&gt;Install MindsDB Server&lt;/h2&gt; 
&lt;p&gt;MindsDB is an open-source server that can be deployed anywhere - from your laptop to the cloud, and everywhere in between. And yes, you can customize it to your heart's content.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.mindsdb.com/setup/self-hosted/docker-desktop"&gt;Using Docker Desktop&lt;/a&gt;. This is the fastest and recommended way to get started and have it all running.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.mindsdb.com/setup/self-hosted/docker"&gt;Using Docker&lt;/a&gt;. This is also simple, but gives you more flexibility on how to further customize your server.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://docs.mindsdb.com/mcp/overview"&gt;MindsDB has an MCP server built in&lt;/a&gt; that enables your MCP applications to connect, unify and respond to questions over large-scale federated data‚Äîspanning databases, data warehouses, and SaaS applications.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h1&gt;Core Philosophy: Connect, Unify, Respond&lt;/h1&gt; 
&lt;p&gt;MindsDB's architecture is built around three fundamental capabilities:&lt;/p&gt; 
&lt;h2&gt;&lt;a href="https://docs.mindsdb.com/integrations/data-overview"&gt;Connect&lt;/a&gt; Your Data&lt;/h2&gt; 
&lt;p&gt;You can connect to hundreds of enterprise &lt;a href="https://docs.mindsdb.com/integrations/data-overview"&gt;data sources (learn more)&lt;/a&gt;. These integrations allow MindsDB to access data wherever it resides, forming the foundation for all other capabilities.&lt;/p&gt; 
&lt;h2&gt;&lt;a href="https://docs.mindsdb.com/mindsdb_sql/overview"&gt;Unify&lt;/a&gt; Your Data&lt;/h2&gt; 
&lt;p&gt;In many situations, it‚Äôs important to be able to prepare and unify data before generating responses from it. MindsDB SQL offers knowledge bases and views that allow indexing and organizing structured and unstructured data as if it were unified in a single system.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.mindsdb.com/mindsdb_sql/knowledge-bases"&gt;&lt;strong&gt;KNOWLEDGE BASES&lt;/strong&gt;&lt;/a&gt; ‚Äì Index and organize unstructured data for efficient Q&amp;amp;A.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.mindsdb.com/mindsdb_sql/sql/create/view"&gt;&lt;strong&gt;VIEWS&lt;/strong&gt;&lt;/a&gt; ‚Äì Simplify data access by creating unified views across different sources (no-ETL).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Unification of data can be automated using JOBs&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.mindsdb.com/mindsdb_sql/sql/create/jobs"&gt;&lt;strong&gt;JOBS&lt;/strong&gt;&lt;/a&gt; ‚Äì Schedule synchronization and transformation tasks for real-time processing.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;&lt;a href="https://docs.mindsdb.com/mindsdb_sql/agents/agent"&gt;Respond&lt;/a&gt; From Your Data&lt;/h2&gt; 
&lt;p&gt;Chat with Your Data&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.mindsdb.com/mindsdb_sql/agents/agent"&gt;&lt;strong&gt;AGENTS&lt;/strong&gt;&lt;/a&gt; ‚Äì Configure built-in agents specialized in answering questions over your connected and unified data.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.mindsdb.com/mcp/overview"&gt;&lt;strong&gt;MCP&lt;/strong&gt;&lt;/a&gt; ‚Äì Connect to MindsDB through the MCP (Model Context Protocol) for seamless interaction.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ü§ù Contribute&lt;/h2&gt; 
&lt;p&gt;Interested in contributing to MindsDB? Follow our &lt;a href="https://docs.mindsdb.com/contribute/install?utm_medium=community&amp;amp;utm_source=github&amp;amp;utm_campaign=mindsdb%20repo"&gt;installation guide for development&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;You can find our &lt;a href="https://docs.mindsdb.com/contribute/contribute?utm_medium=community&amp;amp;utm_source=github&amp;amp;utm_campaign=mindsdb%20repo"&gt;contribution guide here&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;We welcome suggestions! Feel free to open new issues with your ideas, and we‚Äôll guide you.&lt;/p&gt; 
&lt;p&gt;This project adheres to a &lt;a href="https://github.com/mindsdb/mindsdb/raw/main/CODE_OF_CONDUCT.md"&gt;Contributor Code of Conduct&lt;/a&gt;. By participating, you agree to follow its terms.&lt;/p&gt; 
&lt;p&gt;Also, check out our &lt;a href="https://mindsdb.com/community?utm_medium=community&amp;amp;utm_source=github&amp;amp;utm_campaign=mindsdb%20repo"&gt;community rewards and programs&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;ü§ç Support&lt;/h2&gt; 
&lt;p&gt;If you find a bug, please submit an &lt;a href="https://github.com/mindsdb/mindsdb/issues/new/choose"&gt;issue on GitHub&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Here‚Äôs how you can get community support:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Ask a question in our &lt;a href="https://mindsdb.com/joincommunity?utm_medium=community&amp;amp;utm_source=github&amp;amp;utm_campaign=mindsdb%20repo"&gt;Slack Community&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Join our &lt;a href="https://github.com/mindsdb/mindsdb/discussions"&gt;GitHub Discussions&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Post on &lt;a href="https://stackoverflow.com/questions/tagged/mindsdb"&gt;Stack Overflow&lt;/a&gt; with the MindsDB tag.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For commercial support, please &lt;a href="https://mindsdb.com/contact?utm_medium=community&amp;amp;utm_source=github&amp;amp;utm_campaign=mindsdb%20repo"&gt;contact the MindsDB team&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;üíö Current Contributors&lt;/h2&gt; 
&lt;a href="https://github.com/mindsdb/mindsdb/graphs/contributors"&gt; &lt;img src="https://contributors-img.web.app/image?repo=mindsdb/mindsdb" /&gt; &lt;/a&gt; 
&lt;p&gt;Generated with &lt;a href="https://contributors-img.web.app"&gt;contributors-img&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;üîî Subscribe for Updates&lt;/h2&gt; 
&lt;p&gt;Join our &lt;a href="https://mindsdb.com/joincommunity"&gt;Slack community&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Tencent/WeKnora</title>
      <link>https://github.com/Tencent/WeKnora</link>
      <description>&lt;p&gt;LLM-powered framework for deep document understanding, semantic retrieval, and context-aware answers using RAG paradigm.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; 
 &lt;picture&gt; 
  &lt;img src="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/images/logo.png" alt="WeKnora Logo" height="120" /&gt; 
 &lt;/picture&gt; &lt;/p&gt; 
&lt;p align="center"&gt; 
 &lt;picture&gt; 
  &lt;a href="https://trendshift.io/repositories/15289" target="_blank"&gt; &lt;img src="https://trendshift.io/api/badge/repositories/15289" alt="Tencent%2FWeKnora | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt; &lt;/a&gt; 
 &lt;/picture&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://weknora.weixin.qq.com" target="_blank"&gt; &lt;img alt="ÂÆòÊñπÁΩëÁ´ô" src="https://img.shields.io/badge/ÂÆòÊñπÁΩëÁ´ô-WeKnora-4e6b99" /&gt; &lt;/a&gt; &lt;a href="https://chatbot.weixin.qq.com" target="_blank"&gt; &lt;img alt="ÂæÆ‰ø°ÂØπËØùÂºÄÊîæÂπ≥Âè∞" src="https://img.shields.io/badge/ÂæÆ‰ø°ÂØπËØùÂºÄÊîæÂπ≥Âè∞-5ac725" /&gt; &lt;/a&gt; &lt;a href="https://github.com/Tencent/WeKnora/raw/main/LICENSE"&gt; &lt;img src="https://img.shields.io/badge/License-MIT-ffffff?labelColor=d4eaf7&amp;amp;color=2e6cc4" alt="License" /&gt; &lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/CHANGELOG.md"&gt; &lt;img alt="Version" src="https://img.shields.io/badge/version-0.2.0-2e6cc4?labelColor=d4eaf7" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; | &lt;b&gt;English&lt;/b&gt; | &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/README_CN.md"&gt;&lt;b&gt;ÁÆÄ‰Ωì‰∏≠Êñá&lt;/b&gt;&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/README_JA.md"&gt;&lt;b&gt;Êó•Êú¨Ë™û&lt;/b&gt;&lt;/a&gt; | &lt;/p&gt; 
&lt;p align="center"&gt; &lt;/p&gt;
&lt;h4 align="center"&gt; &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/#-overview"&gt;Overview&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/#-architecture"&gt;Architecture&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/#-key-features"&gt;Key Features&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/#-getting-started"&gt;Getting Started&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/#-api-reference"&gt;API Reference&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/#-developer-guide"&gt;Developer Guide&lt;/a&gt;&lt;/p&gt; &lt;/h4&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;h1&gt;üí° WeKnora - LLM-Powered Document Understanding &amp;amp; Retrieval Framework&lt;/h1&gt; 
&lt;h2&gt;üìå Overview&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://weknora.weixin.qq.com"&gt;&lt;strong&gt;WeKnora&lt;/strong&gt;&lt;/a&gt; is an LLM-powered framework designed for deep document understanding and semantic retrieval, especially for handling complex, heterogeneous documents.&lt;/p&gt; 
&lt;p&gt;It adopts a modular architecture that combines multimodal preprocessing, semantic vector indexing, intelligent retrieval, and large language model inference. At its core, WeKnora follows the &lt;strong&gt;RAG (Retrieval-Augmented Generation)&lt;/strong&gt; paradigm, enabling high-quality, context-aware answers by combining relevant document chunks with model reasoning.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Website:&lt;/strong&gt; &lt;a href="https://weknora.weixin.qq.com"&gt;https://weknora.weixin.qq.com&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;‚ú® Latest Updates&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;v0.2.0 Highlights:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;ü§ñ &lt;strong&gt;Agent Mode&lt;/strong&gt;: New ReACT Agent mode that can call built-in tools, MCP tools, and web search, providing comprehensive summary reports through multiple iterations and reflection&lt;/li&gt; 
 &lt;li&gt;üìö &lt;strong&gt;Multi-Type Knowledge Bases&lt;/strong&gt;: Support for FAQ and document knowledge base types, with new features including folder import, URL import, tag management, and online entry&lt;/li&gt; 
 &lt;li&gt;‚öôÔ∏è &lt;strong&gt;Conversation Strategy&lt;/strong&gt;: Support for configuring Agent models, normal mode models, retrieval thresholds, and Prompts, with precise control over multi-turn conversation behavior&lt;/li&gt; 
 &lt;li&gt;üåê &lt;strong&gt;Web Search&lt;/strong&gt;: Support for extensible web search engines with built-in DuckDuckGo search engine&lt;/li&gt; 
 &lt;li&gt;üîå &lt;strong&gt;MCP Tool Integration&lt;/strong&gt;: Support for extending Agent capabilities through MCP, with built-in uvx and npx launchers, supporting multiple transport methods&lt;/li&gt; 
 &lt;li&gt;üé® &lt;strong&gt;New UI&lt;/strong&gt;: Optimized conversation interface with Agent mode/normal mode switching, tool call process display, and comprehensive knowledge base management interface upgrade&lt;/li&gt; 
 &lt;li&gt;‚ö° &lt;strong&gt;Infrastructure Upgrade&lt;/strong&gt;: Introduced MQ async task management, support for automatic database migration, and fast development mode&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üîí Security Notice&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Important:&lt;/strong&gt; Starting from v0.1.3, WeKnora includes login authentication functionality to enhance system security. For production deployments, we strongly recommend:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Deploy WeKnora services in internal/private network environments rather than public internet&lt;/li&gt; 
 &lt;li&gt;Avoid exposing the service directly to public networks to prevent potential information leakage&lt;/li&gt; 
 &lt;li&gt;Configure proper firewall rules and access controls for your deployment environment&lt;/li&gt; 
 &lt;li&gt;Regularly update to the latest version for security patches and improvements&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üèóÔ∏è Architecture&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/images/architecture.png" alt="weknora-architecture.png" /&gt;&lt;/p&gt; 
&lt;p&gt;WeKnora employs a modern modular design to build a complete document understanding and retrieval pipeline. The system primarily includes document parsing, vector processing, retrieval engine, and large model inference as core modules, with each component being flexibly configurable and extendable.&lt;/p&gt; 
&lt;h2&gt;üéØ Key Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;ü§ñ Agent Mode&lt;/strong&gt;: Support for ReACT Agent mode that can use built-in tools to retrieve knowledge bases, MCP tools, and web search tools to access external services, providing comprehensive summary reports through multiple iterations and reflection&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üîç Precise Understanding&lt;/strong&gt;: Structured content extraction from PDFs, Word documents, images and more into unified semantic views&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üß† Intelligent Reasoning&lt;/strong&gt;: Leverages LLMs to understand document context and user intent for accurate Q&amp;amp;A and multi-turn conversations&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üìö Multi-Type Knowledge Bases&lt;/strong&gt;: Support for FAQ and document knowledge base types, with folder import, URL import, tag management, and online entry capabilities&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üîß Flexible Extension&lt;/strong&gt;: All components from parsing and embedding to retrieval and generation are decoupled for easy customization&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;‚ö° Efficient Retrieval&lt;/strong&gt;: Hybrid retrieval strategies combining keywords, vectors, and knowledge graphs, with cross-knowledge base retrieval support&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üåê Web Search&lt;/strong&gt;: Support for extensible web search engines with built-in DuckDuckGo search engine&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üîå MCP Tool Integration&lt;/strong&gt;: Support for extending Agent capabilities through MCP, with built-in uvx and npx launchers, supporting multiple transport methods&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;‚öôÔ∏è Conversation Strategy&lt;/strong&gt;: Support for configuring Agent models, normal mode models, retrieval thresholds, and Prompts, with precise control over multi-turn conversation behavior&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üéØ User-Friendly&lt;/strong&gt;: Intuitive web interface and standardized APIs for zero technical barriers&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üîí Secure &amp;amp; Controlled&lt;/strong&gt;: Support for local deployment and private cloud, ensuring complete data sovereignty&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üìä Application Scenarios&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Scenario&lt;/th&gt; 
   &lt;th&gt;Applications&lt;/th&gt; 
   &lt;th&gt;Core Value&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Enterprise Knowledge Management&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Internal document retrieval, policy Q&amp;amp;A, operation manual search&lt;/td&gt; 
   &lt;td&gt;Improve knowledge discovery efficiency, reduce training costs&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Academic Research Analysis&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Paper retrieval, research report analysis, scholarly material organization&lt;/td&gt; 
   &lt;td&gt;Accelerate literature review, assist research decisions&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Product Technical Support&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Product manual Q&amp;amp;A, technical documentation search, troubleshooting&lt;/td&gt; 
   &lt;td&gt;Enhance customer service quality, reduce support burden&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Legal &amp;amp; Compliance Review&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Contract clause retrieval, regulatory policy search, case analysis&lt;/td&gt; 
   &lt;td&gt;Improve compliance efficiency, reduce legal risks&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Medical Knowledge Assistance&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Medical literature retrieval, treatment guideline search, case analysis&lt;/td&gt; 
   &lt;td&gt;Support clinical decisions, improve diagnosis quality&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;üß© Feature Matrix&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Module&lt;/th&gt; 
   &lt;th&gt;Support&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Agent Mode&lt;/td&gt; 
   &lt;td&gt;‚úÖ ReACT Agent Mode&lt;/td&gt; 
   &lt;td&gt;Support for using built-in tools to retrieve knowledge bases, MCP tools, and web search, with cross-knowledge base retrieval and multiple iterations&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Knowledge Base Types&lt;/td&gt; 
   &lt;td&gt;‚úÖ FAQ / Document&lt;/td&gt; 
   &lt;td&gt;Support for creating FAQ and document knowledge base types, with folder import, URL import, tag management, and online entry&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Document Formats&lt;/td&gt; 
   &lt;td&gt;‚úÖ PDF / Word / Txt / Markdown / Images (with OCR / Caption)&lt;/td&gt; 
   &lt;td&gt;Support for structured and unstructured documents with text extraction from images&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Model Management&lt;/td&gt; 
   &lt;td&gt;‚úÖ Centralized configuration, built-in model sharing&lt;/td&gt; 
   &lt;td&gt;Centralized model configuration with model selection in knowledge base settings, support for multi-tenant shared built-in models&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Embedding Models&lt;/td&gt; 
   &lt;td&gt;‚úÖ Local models, BGE / GTE APIs, etc.&lt;/td&gt; 
   &lt;td&gt;Customizable embedding models, compatible with local deployment and cloud vector generation APIs&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Vector DB Integration&lt;/td&gt; 
   &lt;td&gt;‚úÖ PostgreSQL (pgvector), Elasticsearch&lt;/td&gt; 
   &lt;td&gt;Support for mainstream vector index backends, flexible switching for different retrieval scenarios&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Retrieval Strategies&lt;/td&gt; 
   &lt;td&gt;‚úÖ BM25 / Dense Retrieval / GraphRAG&lt;/td&gt; 
   &lt;td&gt;Support for sparse/dense recall and knowledge graph-enhanced retrieval with customizable retrieve-rerank-generate pipelines&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;LLM Integration&lt;/td&gt; 
   &lt;td&gt;‚úÖ Support for Qwen, DeepSeek, etc., with thinking/non-thinking mode switching&lt;/td&gt; 
   &lt;td&gt;Compatible with local models (e.g., via Ollama) or external API services with flexible inference configuration&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Conversation Strategy&lt;/td&gt; 
   &lt;td&gt;‚úÖ Agent models, normal mode models, retrieval thresholds, Prompt configuration&lt;/td&gt; 
   &lt;td&gt;Support for configuring Agent models, normal mode models, retrieval thresholds, online Prompt configuration, precise control over multi-turn conversation behavior&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Web Search&lt;/td&gt; 
   &lt;td&gt;‚úÖ Extensible search engines, DuckDuckGo&lt;/td&gt; 
   &lt;td&gt;Support for extensible web search engines with built-in DuckDuckGo search engine&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;MCP Tools&lt;/td&gt; 
   &lt;td&gt;‚úÖ uvx, npx launchers, Stdio/HTTP Streamable/SSE&lt;/td&gt; 
   &lt;td&gt;Support for extending Agent capabilities through MCP, with built-in uvx and npx launchers, supporting three transport methods&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;QA Capabilities&lt;/td&gt; 
   &lt;td&gt;‚úÖ Context-aware, multi-turn dialogue, prompt templates&lt;/td&gt; 
   &lt;td&gt;Support for complex semantic modeling, instruction control and chain-of-thought Q&amp;amp;A with configurable prompts and context windows&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;E2E Testing&lt;/td&gt; 
   &lt;td&gt;‚úÖ Retrieval+generation process visualization and metric evaluation&lt;/td&gt; 
   &lt;td&gt;End-to-end testing tools for evaluating recall hit rates, answer coverage, BLEU/ROUGE and other metrics&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Deployment Modes&lt;/td&gt; 
   &lt;td&gt;‚úÖ Support for local deployment / Docker images&lt;/td&gt; 
   &lt;td&gt;Meets private, offline deployment and flexible operation requirements, with fast development mode support&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;User Interfaces&lt;/td&gt; 
   &lt;td&gt;‚úÖ Web UI + RESTful API&lt;/td&gt; 
   &lt;td&gt;Interactive interface and standard API endpoints, with Agent mode/normal mode switching and tool call process display&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Task Management&lt;/td&gt; 
   &lt;td&gt;‚úÖ MQ async tasks, automatic database migration&lt;/td&gt; 
   &lt;td&gt;MQ-based async task state maintenance, support for automatic database schema and data migration during version upgrades&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;üöÄ Getting Started&lt;/h2&gt; 
&lt;h3&gt;üõ† Prerequisites&lt;/h3&gt; 
&lt;p&gt;Make sure the following tools are installed on your system:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.docker.com/"&gt;Docker&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.docker.com/compose/"&gt;Docker Compose&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://git-scm.com/"&gt;Git&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üì¶ Installation&lt;/h3&gt; 
&lt;h4&gt;‚ë† Clone the repository&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Clone the main repository
git clone https://github.com/Tencent/WeKnora.git
cd WeKnora
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;‚ë° Configure environment variables&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Copy example env file
cp .env.example .env

# Edit .env and set required values
# All variables are documented in the .env.example comments
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;‚ë¢ Start the services (include Ollama)&lt;/h4&gt; 
&lt;p&gt;Check the images that need to be started in the .env file.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;./scripts/start_all.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;or&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;make start-all
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;‚ë¢.0 Start ollama services (Optional)&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;ollama serve &amp;gt; /dev/null 2&amp;gt;&amp;amp;1 &amp;amp;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;‚ë¢.1 Activate different combinations of features&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Minimum core services&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker compose up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;All features enabled&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker-compose --profile full up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;Tracing logs required&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker-compose --profile jaeger up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;Neo4j knowledge graph required&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker-compose --profile neo4j up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;Minio file storage service required&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker-compose --profile minio up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;Multiple options combination&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker-compose --profile neo4j --profile minio up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;‚ë£ Stop the services&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;./scripts/start_all.sh --stop
# Or
make stop-all
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;üåê Access Services&lt;/h3&gt; 
&lt;p&gt;Once started, services will be available at:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Web UI: &lt;code&gt;http://localhost&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Backend API: &lt;code&gt;http://localhost:8080&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Jaeger Tracing: &lt;code&gt;http://localhost:16686&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üîå Using WeChat Dialog Open Platform&lt;/h3&gt; 
&lt;p&gt;WeKnora serves as the core technology framework for the &lt;a href="https://chatbot.weixin.qq.com"&gt;WeChat Dialog Open Platform&lt;/a&gt;, providing a more convenient usage approach:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Zero-code Deployment&lt;/strong&gt;: Simply upload knowledge to quickly deploy intelligent Q&amp;amp;A services within the WeChat ecosystem, achieving an "ask and answer" experience&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Efficient Question Management&lt;/strong&gt;: Support for categorized management of high-frequency questions, with rich data tools to ensure accurate, reliable, and easily maintainable answers&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;WeChat Ecosystem Integration&lt;/strong&gt;: Through the WeChat Dialog Open Platform, WeKnora's intelligent Q&amp;amp;A capabilities can be seamlessly integrated into WeChat Official Accounts, Mini Programs, and other WeChat scenarios, enhancing user interaction experiences&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üîó Access WeKnora via MCP Server&lt;/h3&gt; 
&lt;h4&gt;1Ô∏è‚É£ Clone the repository&lt;/h4&gt; 
&lt;pre&gt;&lt;code&gt;git clone https://github.com/Tencent/WeKnora
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;2Ô∏è‚É£ Configure MCP Server&lt;/h4&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;It is recommended to directly refer to the &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/mcp-server/MCP_CONFIG.md"&gt;MCP Configuration Guide&lt;/a&gt; for configuration.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Configure the MCP client to connect to the server:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "mcpServers": {
    "weknora": {
      "args": [
        "path/to/WeKnora/mcp-server/run_server.py"
      ],
      "command": "python",
      "env":{
        "WEKNORA_API_KEY":"Enter your WeKnora instance, open developer tools, check the request header x-api-key starting with sk",
        "WEKNORA_BASE_URL":"http(s)://your-weknora-address/api/v1"
      }
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Run directly using stdio command:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;pip install weknora-mcp-server
python -m weknora-mcp-server
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;üîß Initialization Configuration Guide&lt;/h2&gt; 
&lt;p&gt;To help users quickly configure various models and reduce trial-and-error costs, we've improved the original configuration file initialization method by adding a Web UI interface for model configuration. Before using, please ensure the code is updated to the latest version. The specific steps are as follows: If this is your first time using this project, you can skip steps ‚ë†‚ë° and go directly to steps ‚ë¢‚ë£.&lt;/p&gt; 
&lt;h3&gt;‚ë† Stop the services&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;./scripts/start_all.sh --stop
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;‚ë° Clear existing data tables (recommended when no important data exists)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;make clean-db
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;‚ë¢ Compile and start services&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;./scripts/start_all.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;‚ë£ Access Web UI&lt;/h3&gt; 
&lt;p&gt;&lt;a href="http://localhost"&gt;http://localhost&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;On your first visit, you will be automatically redirected to the registration/login page. After completing registration, please create a new knowledge base and finish the relevant settings on its configuration page.&lt;/p&gt; 
&lt;h2&gt;üì± Interface Showcase&lt;/h2&gt; 
&lt;h3&gt;Web UI Interface&lt;/h3&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td&gt;&lt;b&gt;Knowledge Base Management&lt;/b&gt;&lt;br /&gt;&lt;img src="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/images/knowledgebases.png" alt="Knowledge Base Management" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;b&gt;Conversation Settings&lt;/b&gt;&lt;br /&gt;&lt;img src="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/images/settings.png" alt="Conversation Settings" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td colspan="2"&gt;&lt;b&gt;Agent Mode Tool Call Process&lt;/b&gt;&lt;br /&gt;&lt;img src="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/images/agent-qa.png" alt="Agent Mode Tool Call Process" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;Knowledge Base Management:&lt;/strong&gt; Support for creating FAQ and document knowledge base types, with multiple import methods including drag-and-drop, folder import, and URL import. Automatically identifies document structures and extracts core knowledge to establish indexes. Supports tag management and online entry. The system clearly displays processing progress and document status, achieving efficient knowledge base management.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Agent Mode:&lt;/strong&gt; Support for ReACT Agent mode that can use built-in tools to retrieve knowledge bases, call user-configured MCP tools and web search tools to access external services, providing comprehensive summary reports through multiple iterations and reflection. Supports cross-knowledge base retrieval, allowing selection of multiple knowledge bases for simultaneous retrieval.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Conversation Strategy:&lt;/strong&gt; Support for configuring Agent models, normal mode models, retrieval thresholds, and online Prompt configuration, with precise control over multi-turn conversation behavior and retrieval execution methods. The conversation input box supports Agent mode/normal mode switching, enabling/disabling web search, and selecting conversation models.&lt;/p&gt; 
&lt;h3&gt;Document Knowledge Graph&lt;/h3&gt; 
&lt;p&gt;WeKnora supports transforming documents into knowledge graphs, displaying the relationships between different sections of the documents. Once the knowledge graph feature is enabled, the system analyzes and constructs an internal semantic association network that not only helps users understand document content but also provides structured support for indexing and retrieval, enhancing the relevance and breadth of search results.&lt;/p&gt; 
&lt;p&gt;For detailed configuration, please refer to the &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/KnowledgeGraph.md"&gt;Knowledge Graph Configuration Guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;MCP Server&lt;/h3&gt; 
&lt;p&gt;Please refer to the &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/mcp-server/MCP_CONFIG.md"&gt;MCP Configuration Guide&lt;/a&gt; for the necessary setup.&lt;/p&gt; 
&lt;h2&gt;üìò API Reference&lt;/h2&gt; 
&lt;p&gt;Troubleshooting FAQ: &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/QA.md"&gt;Troubleshooting FAQ&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Detailed API documentation is available at: &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/API.md"&gt;API Docs&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üß≠ Developer Guide&lt;/h2&gt; 
&lt;h3&gt;‚ö° Fast Development Mode (Recommended)&lt;/h3&gt; 
&lt;p&gt;If you need to frequently modify code, &lt;strong&gt;you don't need to rebuild Docker images every time&lt;/strong&gt;! Use fast development mode:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Method 1: Using Make commands (Recommended)
make dev-start      # Start infrastructure
make dev-app        # Start backend (new terminal)
make dev-frontend   # Start frontend (new terminal)

# Method 2: One-click start
./scripts/quick-dev.sh

# Method 3: Using scripts
./scripts/dev.sh start     # Start infrastructure
./scripts/dev.sh app       # Start backend (new terminal)
./scripts/dev.sh frontend  # Start frontend (new terminal)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Development Advantages:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;‚úÖ Frontend modifications auto hot-reload (no restart needed)&lt;/li&gt; 
 &lt;li&gt;‚úÖ Backend modifications quick restart (5-10 seconds, supports Air hot-reload)&lt;/li&gt; 
 &lt;li&gt;‚úÖ No need to rebuild Docker images&lt;/li&gt; 
 &lt;li&gt;‚úÖ Support IDE breakpoint debugging&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Detailed Documentation:&lt;/strong&gt; &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/%E5%BC%80%E5%8F%91%E6%8C%87%E5%8D%97.md"&gt;Development Environment Quick Start&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;üìÅ Directory Structure&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;WeKnora/
‚îú‚îÄ‚îÄ client/      # go client
‚îú‚îÄ‚îÄ cmd/         # Main entry point
‚îú‚îÄ‚îÄ config/      # Configuration files
‚îú‚îÄ‚îÄ docker/      # docker images files
‚îú‚îÄ‚îÄ docreader/   # Document parsing app
‚îú‚îÄ‚îÄ docs/        # Project documentation
‚îú‚îÄ‚îÄ frontend/    # Frontend app
‚îú‚îÄ‚îÄ internal/    # Core business logic
‚îú‚îÄ‚îÄ mcp-server/  # MCP server
‚îú‚îÄ‚îÄ migrations/  # DB migration scripts
‚îî‚îÄ‚îÄ scripts/     # Shell scripts
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;ü§ù Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome community contributions! For suggestions, bugs, or feature requests, please submit an &lt;a href="https://github.com/Tencent/WeKnora/issues"&gt;Issue&lt;/a&gt; or directly create a Pull Request.&lt;/p&gt; 
&lt;h3&gt;üéØ How to Contribute&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;üêõ &lt;strong&gt;Bug Fixes&lt;/strong&gt;: Discover and fix system defects&lt;/li&gt; 
 &lt;li&gt;‚ú® &lt;strong&gt;New Features&lt;/strong&gt;: Propose and implement new capabilities&lt;/li&gt; 
 &lt;li&gt;üìö &lt;strong&gt;Documentation&lt;/strong&gt;: Improve project documentation&lt;/li&gt; 
 &lt;li&gt;üß™ &lt;strong&gt;Test Cases&lt;/strong&gt;: Write unit and integration tests&lt;/li&gt; 
 &lt;li&gt;üé® &lt;strong&gt;UI/UX Enhancements&lt;/strong&gt;: Improve user interface and experience&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üìã Contribution Process&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Fork the project&lt;/strong&gt; to your GitHub account&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Create a feature branch&lt;/strong&gt; &lt;code&gt;git checkout -b feature/amazing-feature&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Commit changes&lt;/strong&gt; &lt;code&gt;git commit -m 'Add amazing feature'&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Push branch&lt;/strong&gt; &lt;code&gt;git push origin feature/amazing-feature&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Create a Pull Request&lt;/strong&gt; with detailed description of changes&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;üé® Code Standards&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Follow &lt;a href="https://github.com/golang/go/wiki/CodeReviewComments"&gt;Go Code Review Comments&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Format code using &lt;code&gt;gofmt&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Add necessary unit tests&lt;/li&gt; 
 &lt;li&gt;Update relevant documentation&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üìù Commit Guidelines&lt;/h3&gt; 
&lt;p&gt;Use &lt;a href="https://www.conventionalcommits.org/"&gt;Conventional Commits&lt;/a&gt; standard:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;feat: Add document batch upload functionality
fix: Resolve vector retrieval precision issue
docs: Update API documentation
test: Add retrieval engine test cases
refactor: Restructure document parsing module
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;üë• Contributors&lt;/h2&gt; 
&lt;p&gt;Thanks to these excellent contributors:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/Tencent/WeKnora/graphs/contributors"&gt;&lt;img src="https://contrib.rocks/image?repo=Tencent/WeKnora" alt="Contributors" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üìÑ License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/LICENSE"&gt;MIT License&lt;/a&gt;. You are free to use, modify, and distribute the code with proper attribution.&lt;/p&gt; 
&lt;h2&gt;üìà Project Statistics&lt;/h2&gt; 
&lt;a href="https://www.star-history.com/#Tencent/WeKnora&amp;amp;type=date&amp;amp;legend=top-left"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://api.star-history.com/svg?repos=Tencent/WeKnora&amp;amp;type=date&amp;amp;theme=dark&amp;amp;legend=top-left" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://api.star-history.com/svg?repos=Tencent/WeKnora&amp;amp;type=date&amp;amp;legend=top-left" /&gt; 
  &lt;img alt="Star History Chart" src="https://api.star-history.com/svg?repos=Tencent/WeKnora&amp;amp;type=date&amp;amp;legend=top-left" /&gt; 
 &lt;/picture&gt; &lt;/a&gt;</description>
    </item>
    
    <item>
      <title>simstudioai/sim</title>
      <link>https://github.com/simstudioai/sim</link>
      <description>&lt;p&gt;Open-source platform to build and deploy AI agent workflows.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;a href="https://sim.ai" target="_blank" rel="noopener noreferrer"&gt; &lt;img src="https://raw.githubusercontent.com/simstudioai/sim/main/apps/sim/public/logo/reverse/text/large.png" alt="Sim Logo" width="500" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt;Build and deploy AI agent workflows in minutes.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://sim.ai" target="_blank" rel="noopener noreferrer"&gt;&lt;img src="https://img.shields.io/badge/sim.ai-6F3DFA" alt="Sim.ai" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/Hr4UWYEcTT" target="_blank" rel="noopener noreferrer"&gt;&lt;img src="https://img.shields.io/badge/Discord-Join%20Server-5865F2?logo=discord&amp;amp;logoColor=white" alt="Discord" /&gt;&lt;/a&gt; &lt;a href="https://x.com/simdotai" target="_blank" rel="noopener noreferrer"&gt;&lt;img src="https://img.shields.io/twitter/follow/simstudioai?style=social" alt="Twitter" /&gt;&lt;/a&gt; &lt;a href="https://docs.sim.ai" target="_blank" rel="noopener noreferrer"&gt;&lt;img src="https://img.shields.io/badge/Docs-6F3DFA.svg?sanitize=true" alt="Documentation" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;h3&gt;Build Workflows with Ease&lt;/h3&gt; 
&lt;p&gt;Design agent workflows visually on a canvas‚Äîconnect agents, tools, and blocks, then run them instantly.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/simstudioai/sim/main/apps/sim/public/static/workflow.gif" alt="Workflow Builder Demo" width="800" /&gt; &lt;/p&gt; 
&lt;h3&gt;Supercharge with Copilot&lt;/h3&gt; 
&lt;p&gt;Leverage Copilot to generate nodes, fix errors, and iterate on flows directly from natural language.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/simstudioai/sim/main/apps/sim/public/static/copilot.gif" alt="Copilot Demo" width="800" /&gt; &lt;/p&gt; 
&lt;h3&gt;Integrate Vector Databases&lt;/h3&gt; 
&lt;p&gt;Upload documents to a vector store and let agents answer questions grounded in your specific content.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/simstudioai/sim/main/apps/sim/public/static/knowledge.gif" alt="Knowledge Uploads and Retrieval Demo" width="800" /&gt; &lt;/p&gt; 
&lt;h2&gt;Quickstart&lt;/h2&gt; 
&lt;h3&gt;Cloud-hosted: &lt;a href="https://sim.ai"&gt;sim.ai&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://sim.ai" target="_blank" rel="noopener noreferrer"&gt;&lt;img src="https://img.shields.io/badge/sim.ai-6F3DFA?logo=data:image/svg%2bxml;base64,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&amp;amp;logoColor=white" alt="Sim.ai" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Self-hosted: NPM Package&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;npx simstudio
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;‚Üí &lt;a href="http://localhost:3000"&gt;http://localhost:3000&lt;/a&gt;&lt;/p&gt; 
&lt;h4&gt;Note&lt;/h4&gt; 
&lt;p&gt;Docker must be installed and running on your machine.&lt;/p&gt; 
&lt;h4&gt;Options&lt;/h4&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Flag&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;-p, --port &amp;lt;port&amp;gt;&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Port to run Sim on (default &lt;code&gt;3000&lt;/code&gt;)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--no-pull&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Skip pulling latest Docker images&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Self-hosted: Docker Compose&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Clone the repository
git clone https://github.com/simstudioai/sim.git

# Navigate to the project directory
cd sim

# Start Sim
docker compose -f docker-compose.prod.yml up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Access the application at &lt;a href="http://localhost:3000/"&gt;http://localhost:3000/&lt;/a&gt;&lt;/p&gt; 
&lt;h4&gt;Using Local Models with Ollama&lt;/h4&gt; 
&lt;p&gt;Run Sim with local AI models using &lt;a href="https://ollama.ai"&gt;Ollama&lt;/a&gt; - no external APIs required:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Start with GPU support (automatically downloads gemma3:4b model)
docker compose -f docker-compose.ollama.yml --profile setup up -d

# For CPU-only systems:
docker compose -f docker-compose.ollama.yml --profile cpu --profile setup up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Wait for the model to download, then visit &lt;a href="http://localhost:3000"&gt;http://localhost:3000&lt;/a&gt;. Add more models with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker compose -f docker-compose.ollama.yml exec ollama ollama pull llama3.1:8b
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Using an External Ollama Instance&lt;/h4&gt; 
&lt;p&gt;If you already have Ollama running on your host machine (outside Docker), you need to configure the &lt;code&gt;OLLAMA_URL&lt;/code&gt; to use &lt;code&gt;host.docker.internal&lt;/code&gt; instead of &lt;code&gt;localhost&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Docker Desktop (macOS/Windows)
OLLAMA_URL=http://host.docker.internal:11434 docker compose -f docker-compose.prod.yml up -d

# Linux (add extra_hosts or use host IP)
docker compose -f docker-compose.prod.yml up -d  # Then set OLLAMA_URL to your host's IP
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Why?&lt;/strong&gt; When running inside Docker, &lt;code&gt;localhost&lt;/code&gt; refers to the container itself, not your host machine. &lt;code&gt;host.docker.internal&lt;/code&gt; is a special DNS name that resolves to the host.&lt;/p&gt; 
&lt;p&gt;For Linux users, you can either:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Use your host machine's actual IP address (e.g., &lt;code&gt;http://192.168.1.100:11434&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;Add &lt;code&gt;extra_hosts: ["host.docker.internal:host-gateway"]&lt;/code&gt; to the simstudio service in your compose file&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Using vLLM&lt;/h4&gt; 
&lt;p&gt;Sim also supports &lt;a href="https://docs.vllm.ai/"&gt;vLLM&lt;/a&gt; for self-hosted models with OpenAI-compatible API:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Set these environment variables
VLLM_BASE_URL=http://your-vllm-server:8000
VLLM_API_KEY=your_optional_api_key  # Only if your vLLM instance requires auth
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;When running with Docker, use &lt;code&gt;host.docker.internal&lt;/code&gt; if vLLM is on your host machine (same as Ollama above).&lt;/p&gt; 
&lt;h3&gt;Self-hosted: Dev Containers&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Open VS Code with the &lt;a href="https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.remote-containers"&gt;Remote - Containers extension&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Open the project and click "Reopen in Container" when prompted&lt;/li&gt; 
 &lt;li&gt;Run &lt;code&gt;bun run dev:full&lt;/code&gt; in the terminal or use the &lt;code&gt;sim-start&lt;/code&gt; alias 
  &lt;ul&gt; 
   &lt;li&gt;This starts both the main application and the realtime socket server&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Self-hosted: Manual Setup&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Requirements:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://bun.sh/"&gt;Bun&lt;/a&gt; runtime&lt;/li&gt; 
 &lt;li&gt;PostgreSQL 12+ with &lt;a href="https://github.com/pgvector/pgvector"&gt;pgvector extension&lt;/a&gt; (required for AI embeddings)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; Sim uses vector embeddings for AI features like knowledge bases and semantic search, which requires the &lt;code&gt;pgvector&lt;/code&gt; PostgreSQL extension.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Clone and install dependencies:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/simstudioai/sim.git
cd sim
bun install
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Set up PostgreSQL with pgvector:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;You need PostgreSQL with the &lt;code&gt;vector&lt;/code&gt; extension for embedding support. Choose one option:&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Option A: Using Docker (Recommended)&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Start PostgreSQL with pgvector extension
docker run --name simstudio-db \
  -e POSTGRES_PASSWORD=your_password \
  -e POSTGRES_DB=simstudio \
  -p 5432:5432 -d \
  pgvector/pgvector:pg17
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Option B: Manual Installation&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Install PostgreSQL 12+ and the pgvector extension&lt;/li&gt; 
 &lt;li&gt;See &lt;a href="https://github.com/pgvector/pgvector#installation"&gt;pgvector installation guide&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt;Set up environment:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd apps/sim
cp .env.example .env  # Configure with required variables (DATABASE_URL, BETTER_AUTH_SECRET, BETTER_AUTH_URL)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Update your &lt;code&gt;.env&lt;/code&gt; file with the database URL:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;DATABASE_URL="postgresql://postgres:your_password@localhost:5432/simstudio"
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="4"&gt; 
 &lt;li&gt;Set up the database:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;First, configure the database package environment:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd packages/db
cp .env.example .env 
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Update your &lt;code&gt;packages/db/.env&lt;/code&gt; file with the database URL:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;DATABASE_URL="postgresql://postgres:your_password@localhost:5432/simstudio"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then run the migrations:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;bunx drizzle-kit migrate --config=./drizzle.config.ts
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="5"&gt; 
 &lt;li&gt;Start the development servers:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;Recommended approach - run both servers together (from project root):&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;bun run dev:full
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This starts both the main Next.js application and the realtime socket server required for full functionality.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Alternative - run servers separately:&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Next.js app (from project root):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;bun run dev
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Realtime socket server (from &lt;code&gt;apps/sim&lt;/code&gt; directory in a separate terminal):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd apps/sim
bun run dev:sockets
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Copilot API Keys&lt;/h2&gt; 
&lt;p&gt;Copilot is a Sim-managed service. To use Copilot on a self-hosted instance:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Go to &lt;a href="https://sim.ai"&gt;https://sim.ai&lt;/a&gt; ‚Üí Settings ‚Üí Copilot and generate a Copilot API key&lt;/li&gt; 
 &lt;li&gt;Set &lt;code&gt;COPILOT_API_KEY&lt;/code&gt; environment variable in your self-hosted apps/sim/.env file to that value&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Environment Variables&lt;/h2&gt; 
&lt;p&gt;Key environment variables for self-hosted deployments (see &lt;code&gt;apps/sim/.env.example&lt;/code&gt; for full list):&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Variable&lt;/th&gt; 
   &lt;th&gt;Required&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;DATABASE_URL&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;PostgreSQL connection string with pgvector&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;BETTER_AUTH_SECRET&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Auth secret (&lt;code&gt;openssl rand -hex 32&lt;/code&gt;)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;BETTER_AUTH_URL&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Your app URL (e.g., &lt;code&gt;http://localhost:3000&lt;/code&gt;)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;NEXT_PUBLIC_APP_URL&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Public app URL (same as above)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;ENCRYPTION_KEY&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Encryption key (&lt;code&gt;openssl rand -hex 32&lt;/code&gt;)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OLLAMA_URL&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;Ollama server URL (default: &lt;code&gt;http://localhost:11434&lt;/code&gt;)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;VLLM_BASE_URL&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;vLLM server URL for self-hosted models&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;COPILOT_API_KEY&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;API key from sim.ai for Copilot features&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Troubleshooting&lt;/h2&gt; 
&lt;h3&gt;Ollama models not showing in dropdown (Docker)&lt;/h3&gt; 
&lt;p&gt;If you're running Ollama on your host machine and Sim in Docker, change &lt;code&gt;OLLAMA_URL&lt;/code&gt; from &lt;code&gt;localhost&lt;/code&gt; to &lt;code&gt;host.docker.internal&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;OLLAMA_URL=http://host.docker.internal:11434 docker compose -f docker-compose.prod.yml up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/simstudioai/sim/main/#using-an-external-ollama-instance"&gt;Using an External Ollama Instance&lt;/a&gt; for details.&lt;/p&gt; 
&lt;h3&gt;Database connection issues&lt;/h3&gt; 
&lt;p&gt;Ensure PostgreSQL has the pgvector extension installed. When using Docker, wait for the database to be healthy before running migrations.&lt;/p&gt; 
&lt;h3&gt;Port conflicts&lt;/h3&gt; 
&lt;p&gt;If ports 3000, 3002, or 5432 are in use, configure alternatives:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Custom ports
NEXT_PUBLIC_APP_URL=http://localhost:3100 POSTGRES_PORT=5433 docker compose up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Tech Stack&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Framework&lt;/strong&gt;: &lt;a href="https://nextjs.org/"&gt;Next.js&lt;/a&gt; (App Router)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Runtime&lt;/strong&gt;: &lt;a href="https://bun.sh/"&gt;Bun&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Database&lt;/strong&gt;: PostgreSQL with &lt;a href="https://orm.drizzle.team"&gt;Drizzle ORM&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Authentication&lt;/strong&gt;: &lt;a href="https://better-auth.com"&gt;Better Auth&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;UI&lt;/strong&gt;: &lt;a href="https://ui.shadcn.com/"&gt;Shadcn&lt;/a&gt;, &lt;a href="https://tailwindcss.com"&gt;Tailwind CSS&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;State Management&lt;/strong&gt;: &lt;a href="https://zustand-demo.pmnd.rs/"&gt;Zustand&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Flow Editor&lt;/strong&gt;: &lt;a href="https://reactflow.dev/"&gt;ReactFlow&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Docs&lt;/strong&gt;: &lt;a href="https://fumadocs.vercel.app/"&gt;Fumadocs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Monorepo&lt;/strong&gt;: &lt;a href="https://turborepo.org/"&gt;Turborepo&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Realtime&lt;/strong&gt;: &lt;a href="https://socket.io/"&gt;Socket.io&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Background Jobs&lt;/strong&gt;: &lt;a href="https://trigger.dev/"&gt;Trigger.dev&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Remote Code Execution&lt;/strong&gt;: &lt;a href="https://www.e2b.dev/"&gt;E2B&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome contributions! Please see our &lt;a href="https://raw.githubusercontent.com/simstudioai/sim/main/.github/CONTRIBUTING.md"&gt;Contributing Guide&lt;/a&gt; for details.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the Apache License 2.0 - see the &lt;a href="https://raw.githubusercontent.com/simstudioai/sim/main/LICENSE"&gt;LICENSE&lt;/a&gt; file for details.&lt;/p&gt; 
&lt;p align="center"&gt;Made with ‚ù§Ô∏è by the Sim Team&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>karpathy/nanoGPT</title>
      <link>https://github.com/karpathy/nanoGPT</link>
      <description>&lt;p&gt;The simplest, fastest repository for training/finetuning medium-sized GPTs.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;nanoGPT&lt;/h1&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/karpathy/nanoGPT/master/assets/nanogpt.jpg" alt="nanoGPT" /&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;strong&gt;Update Nov 2025&lt;/strong&gt; nanoGPT has a new and improved cousin called &lt;a href="https://github.com/karpathy/nanochat"&gt;nanochat&lt;/a&gt;. It is very likely you meant to use/find nanochat instead. nanoGPT (this repo) is now very old and deprecated but I will leave it up for posterity.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;The simplest, fastest repository for training/finetuning medium-sized GPTs. It is a rewrite of &lt;a href="https://github.com/karpathy/minGPT"&gt;minGPT&lt;/a&gt; that prioritizes teeth over education. Still under active development, but currently the file &lt;code&gt;train.py&lt;/code&gt; reproduces GPT-2 (124M) on OpenWebText, running on a single 8XA100 40GB node in about 4 days of training. The code itself is plain and readable: &lt;code&gt;train.py&lt;/code&gt; is a ~300-line boilerplate training loop and &lt;code&gt;model.py&lt;/code&gt; a ~300-line GPT model definition, which can optionally load the GPT-2 weights from OpenAI. That's it.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/karpathy/nanoGPT/master/assets/gpt2_124M_loss.png" alt="repro124m" /&gt;&lt;/p&gt; 
&lt;p&gt;Because the code is so simple, it is very easy to hack to your needs, train new models from scratch, or finetune pretrained checkpoints (e.g. biggest one currently available as a starting point would be the GPT-2 1.3B model from OpenAI).&lt;/p&gt; 
&lt;h2&gt;install&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;pip install torch numpy transformers datasets tiktoken wandb tqdm
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Dependencies:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://pytorch.org"&gt;pytorch&lt;/a&gt; &amp;lt;3&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://numpy.org/install/"&gt;numpy&lt;/a&gt; &amp;lt;3&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;transformers&lt;/code&gt; for huggingface transformers &amp;lt;3 (to load GPT-2 checkpoints)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;datasets&lt;/code&gt; for huggingface datasets &amp;lt;3 (if you want to download + preprocess OpenWebText)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;tiktoken&lt;/code&gt; for OpenAI's fast BPE code &amp;lt;3&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;wandb&lt;/code&gt; for optional logging &amp;lt;3&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;tqdm&lt;/code&gt; for progress bars &amp;lt;3&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;quick start&lt;/h2&gt; 
&lt;p&gt;If you are not a deep learning professional and you just want to feel the magic and get your feet wet, the fastest way to get started is to train a character-level GPT on the works of Shakespeare. First, we download it as a single (1MB) file and turn it from raw text into one large stream of integers:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;python data/shakespeare_char/prepare.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This creates a &lt;code&gt;train.bin&lt;/code&gt; and &lt;code&gt;val.bin&lt;/code&gt; in that data directory. Now it is time to train your GPT. The size of it very much depends on the computational resources of your system:&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;I have a GPU&lt;/strong&gt;. Great, we can quickly train a baby GPT with the settings provided in the &lt;a href="https://raw.githubusercontent.com/karpathy/nanoGPT/master/config/train_shakespeare_char.py"&gt;config/train_shakespeare_char.py&lt;/a&gt; config file:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;python train.py config/train_shakespeare_char.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you peek inside it, you'll see that we're training a GPT with a context size of up to 256 characters, 384 feature channels, and it is a 6-layer Transformer with 6 heads in each layer. On one A100 GPU this training run takes about 3 minutes and the best validation loss is 1.4697. Based on the configuration, the model checkpoints are being written into the &lt;code&gt;--out_dir&lt;/code&gt; directory &lt;code&gt;out-shakespeare-char&lt;/code&gt;. So once the training finishes we can sample from the best model by pointing the sampling script at this directory:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;python sample.py --out_dir=out-shakespeare-char
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This generates a few samples, for example:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;ANGELO:
And cowards it be strawn to my bed,
And thrust the gates of my threats,
Because he that ale away, and hang'd
An one with him.

DUKE VINCENTIO:
I thank your eyes against it.

DUKE VINCENTIO:
Then will answer him to save the malm:
And what have you tyrannous shall do this?

DUKE VINCENTIO:
If you have done evils of all disposition
To end his power, the day of thrust for a common men
That I leave, to fight with over-liking
Hasting in a roseman.
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;lol &lt;code&gt;¬Ø\_(„ÉÑ)_/¬Ø&lt;/code&gt;. Not bad for a character-level model after 3 minutes of training on a GPU. Better results are quite likely obtainable by instead finetuning a pretrained GPT-2 model on this dataset (see finetuning section later).&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;I only have a macbook&lt;/strong&gt; (or other cheap computer). No worries, we can still train a GPT but we want to dial things down a notch. I recommend getting the bleeding edge PyTorch nightly (&lt;a href="https://pytorch.org/get-started/locally/"&gt;select it here&lt;/a&gt; when installing) as it is currently quite likely to make your code more efficient. But even without it, a simple train run could look as follows:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;python train.py config/train_shakespeare_char.py --device=cpu --compile=False --eval_iters=20 --log_interval=1 --block_size=64 --batch_size=12 --n_layer=4 --n_head=4 --n_embd=128 --max_iters=2000 --lr_decay_iters=2000 --dropout=0.0
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Here, since we are running on CPU instead of GPU we must set both &lt;code&gt;--device=cpu&lt;/code&gt; and also turn off PyTorch 2.0 compile with &lt;code&gt;--compile=False&lt;/code&gt;. Then when we evaluate we get a bit more noisy but faster estimate (&lt;code&gt;--eval_iters=20&lt;/code&gt;, down from 200), our context size is only 64 characters instead of 256, and the batch size only 12 examples per iteration, not 64. We'll also use a much smaller Transformer (4 layers, 4 heads, 128 embedding size), and decrease the number of iterations to 2000 (and correspondingly usually decay the learning rate to around max_iters with &lt;code&gt;--lr_decay_iters&lt;/code&gt;). Because our network is so small we also ease down on regularization (&lt;code&gt;--dropout=0.0&lt;/code&gt;). This still runs in about ~3 minutes, but gets us a loss of only 1.88 and therefore also worse samples, but it's still good fun:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;python sample.py --out_dir=out-shakespeare-char --device=cpu
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Generates samples like this:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;GLEORKEN VINGHARD III:
Whell's the couse, the came light gacks,
And the for mought you in Aut fries the not high shee
bot thou the sought bechive in that to doth groan you,
No relving thee post mose the wear
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Not bad for ~3 minutes on a CPU, for a hint of the right character gestalt. If you're willing to wait longer, feel free to tune the hyperparameters, increase the size of the network, the context length (&lt;code&gt;--block_size&lt;/code&gt;), the length of training, etc.&lt;/p&gt; 
&lt;p&gt;Finally, on Apple Silicon Macbooks and with a recent PyTorch version make sure to add &lt;code&gt;--device=mps&lt;/code&gt; (short for "Metal Performance Shaders"); PyTorch then uses the on-chip GPU that can &lt;em&gt;significantly&lt;/em&gt; accelerate training (2-3X) and allow you to use larger networks. See &lt;a href="https://github.com/karpathy/nanoGPT/issues/28"&gt;Issue 28&lt;/a&gt; for more.&lt;/p&gt; 
&lt;h2&gt;reproducing GPT-2&lt;/h2&gt; 
&lt;p&gt;A more serious deep learning professional may be more interested in reproducing GPT-2 results. So here we go - we first tokenize the dataset, in this case the &lt;a href="https://openwebtext2.readthedocs.io/en/latest/"&gt;OpenWebText&lt;/a&gt;, an open reproduction of OpenAI's (private) WebText:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;python data/openwebtext/prepare.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This downloads and tokenizes the &lt;a href="https://huggingface.co/datasets/openwebtext"&gt;OpenWebText&lt;/a&gt; dataset. It will create a &lt;code&gt;train.bin&lt;/code&gt; and &lt;code&gt;val.bin&lt;/code&gt; which holds the GPT2 BPE token ids in one sequence, stored as raw uint16 bytes. Then we're ready to kick off training. To reproduce GPT-2 (124M) you'll want at least an 8X A100 40GB node and run:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;torchrun --standalone --nproc_per_node=8 train.py config/train_gpt2.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This will run for about 4 days using PyTorch Distributed Data Parallel (DDP) and go down to loss of ~2.85. Now, a GPT-2 model just evaluated on OWT gets a val loss of about 3.11, but if you finetune it it will come down to ~2.85 territory (due to an apparent domain gap), making the two models ~match.&lt;/p&gt; 
&lt;p&gt;If you're in a cluster environment and you are blessed with multiple GPU nodes you can make GPU go brrrr e.g. across 2 nodes like:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;# Run on the first (master) node with example IP 123.456.123.456:
torchrun --nproc_per_node=8 --nnodes=2 --node_rank=0 --master_addr=123.456.123.456 --master_port=1234 train.py
# Run on the worker node:
torchrun --nproc_per_node=8 --nnodes=2 --node_rank=1 --master_addr=123.456.123.456 --master_port=1234 train.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;It is a good idea to benchmark your interconnect (e.g. iperf3). In particular, if you don't have Infiniband then also prepend &lt;code&gt;NCCL_IB_DISABLE=1&lt;/code&gt; to the above launches. Your multinode training will work, but most likely &lt;em&gt;crawl&lt;/em&gt;. By default checkpoints are periodically written to the &lt;code&gt;--out_dir&lt;/code&gt;. We can sample from the model by simply &lt;code&gt;python sample.py&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Finally, to train on a single GPU simply run the &lt;code&gt;python train.py&lt;/code&gt; script. Have a look at all of its args, the script tries to be very readable, hackable and transparent. You'll most likely want to tune a number of those variables depending on your needs.&lt;/p&gt; 
&lt;h2&gt;baselines&lt;/h2&gt; 
&lt;p&gt;OpenAI GPT-2 checkpoints allow us to get some baselines in place for openwebtext. We can get the numbers as follows:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;$ python train.py config/eval_gpt2.py
$ python train.py config/eval_gpt2_medium.py
$ python train.py config/eval_gpt2_large.py
$ python train.py config/eval_gpt2_xl.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;and observe the following losses on train and val:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;model&lt;/th&gt; 
   &lt;th&gt;params&lt;/th&gt; 
   &lt;th&gt;train loss&lt;/th&gt; 
   &lt;th&gt;val loss&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;gpt2&lt;/td&gt; 
   &lt;td&gt;124M&lt;/td&gt; 
   &lt;td&gt;3.11&lt;/td&gt; 
   &lt;td&gt;3.12&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;gpt2-medium&lt;/td&gt; 
   &lt;td&gt;350M&lt;/td&gt; 
   &lt;td&gt;2.85&lt;/td&gt; 
   &lt;td&gt;2.84&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;gpt2-large&lt;/td&gt; 
   &lt;td&gt;774M&lt;/td&gt; 
   &lt;td&gt;2.66&lt;/td&gt; 
   &lt;td&gt;2.67&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;gpt2-xl&lt;/td&gt; 
   &lt;td&gt;1558M&lt;/td&gt; 
   &lt;td&gt;2.56&lt;/td&gt; 
   &lt;td&gt;2.54&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;However, we have to note that GPT-2 was trained on (closed, never released) WebText, while OpenWebText is just a best-effort open reproduction of this dataset. This means there is a dataset domain gap. Indeed, taking the GPT-2 (124M) checkpoint and finetuning on OWT directly for a while reaches loss down to ~2.85. This then becomes the more appropriate baseline w.r.t. reproduction.&lt;/p&gt; 
&lt;h2&gt;finetuning&lt;/h2&gt; 
&lt;p&gt;Finetuning is no different than training, we just make sure to initialize from a pretrained model and train with a smaller learning rate. For an example of how to finetune a GPT on new text go to &lt;code&gt;data/shakespeare&lt;/code&gt; and run &lt;code&gt;prepare.py&lt;/code&gt; to download the tiny shakespeare dataset and render it into a &lt;code&gt;train.bin&lt;/code&gt; and &lt;code&gt;val.bin&lt;/code&gt;, using the OpenAI BPE tokenizer from GPT-2. Unlike OpenWebText this will run in seconds. Finetuning can take very little time, e.g. on a single GPU just a few minutes. Run an example finetuning like:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;python train.py config/finetune_shakespeare.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This will load the config parameter overrides in &lt;code&gt;config/finetune_shakespeare.py&lt;/code&gt; (I didn't tune them much though). Basically, we initialize from a GPT2 checkpoint with &lt;code&gt;init_from&lt;/code&gt; and train as normal, except shorter and with a small learning rate. If you're running out of memory try decreasing the model size (they are &lt;code&gt;{'gpt2', 'gpt2-medium', 'gpt2-large', 'gpt2-xl'}&lt;/code&gt;) or possibly decreasing the &lt;code&gt;block_size&lt;/code&gt; (context length). The best checkpoint (lowest validation loss) will be in the &lt;code&gt;out_dir&lt;/code&gt; directory, e.g. in &lt;code&gt;out-shakespeare&lt;/code&gt; by default, per the config file. You can then run the code in &lt;code&gt;sample.py --out_dir=out-shakespeare&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;THEODORE:
Thou shalt sell me to the highest bidder: if I die,
I sell thee to the first; if I go mad,
I sell thee to the second; if I
lie, I sell thee to the third; if I slay,
I sell thee to the fourth: so buy or sell,
I tell thee again, thou shalt not sell my
possession.

JULIET:
And if thou steal, thou shalt not sell thyself.

THEODORE:
I do not steal; I sell the stolen goods.

THEODORE:
Thou know'st not what thou sell'st; thou, a woman,
Thou art ever a victim, a thing of no worth:
Thou hast no right, no right, but to be sold.
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Whoa there, GPT, entering some dark place over there. I didn't really tune the hyperparameters in the config too much, feel free to try!&lt;/p&gt; 
&lt;h2&gt;sampling / inference&lt;/h2&gt; 
&lt;p&gt;Use the script &lt;code&gt;sample.py&lt;/code&gt; to sample either from pre-trained GPT-2 models released by OpenAI, or from a model you trained yourself. For example, here is a way to sample from the largest available &lt;code&gt;gpt2-xl&lt;/code&gt; model:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;python sample.py \
    --init_from=gpt2-xl \
    --start="What is the answer to life, the universe, and everything?" \
    --num_samples=5 --max_new_tokens=100
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you'd like to sample from a model you trained, use the &lt;code&gt;--out_dir&lt;/code&gt; to point the code appropriately. You can also prompt the model with some text from a file, e.g. &lt;code&gt;python sample.py --start=FILE:prompt.txt&lt;/code&gt;.&lt;/p&gt; 
&lt;h2&gt;efficiency notes&lt;/h2&gt; 
&lt;p&gt;For simple model benchmarking and profiling, &lt;code&gt;bench.py&lt;/code&gt; might be useful. It's identical to what happens in the meat of the training loop of &lt;code&gt;train.py&lt;/code&gt;, but omits much of the other complexities.&lt;/p&gt; 
&lt;p&gt;Note that the code by default uses &lt;a href="https://pytorch.org/get-started/pytorch-2.0/"&gt;PyTorch 2.0&lt;/a&gt;. At the time of writing (Dec 29, 2022) this makes &lt;code&gt;torch.compile()&lt;/code&gt; available in the nightly release. The improvement from the one line of code is noticeable, e.g. cutting down iteration time from ~250ms / iter to 135ms / iter. Nice work PyTorch team!&lt;/p&gt; 
&lt;h2&gt;todos&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Investigate and add FSDP instead of DDP&lt;/li&gt; 
 &lt;li&gt;Eval zero-shot perplexities on standard evals (e.g. LAMBADA? HELM? etc.)&lt;/li&gt; 
 &lt;li&gt;Finetune the finetuning script, I think the hyperparams are not great&lt;/li&gt; 
 &lt;li&gt;Schedule for linear batch size increase during training&lt;/li&gt; 
 &lt;li&gt;Incorporate other embeddings (rotary, alibi)&lt;/li&gt; 
 &lt;li&gt;Separate out the optim buffers from model params in checkpoints I think&lt;/li&gt; 
 &lt;li&gt;Additional logging around network health (e.g. gradient clip events, magnitudes)&lt;/li&gt; 
 &lt;li&gt;Few more investigations around better init etc.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;troubleshooting&lt;/h2&gt; 
&lt;p&gt;Note that by default this repo uses PyTorch 2.0 (i.e. &lt;code&gt;torch.compile&lt;/code&gt;). This is fairly new and experimental, and not yet available on all platforms (e.g. Windows). If you're running into related error messages try to disable this by adding &lt;code&gt;--compile=False&lt;/code&gt; flag. This will slow down the code but at least it will run.&lt;/p&gt; 
&lt;p&gt;For some context on this repository, GPT, and language modeling it might be helpful to watch my &lt;a href="https://karpathy.ai/zero-to-hero.html"&gt;Zero To Hero series&lt;/a&gt;. Specifically, the &lt;a href="https://www.youtube.com/watch?v=kCc8FmEb1nY"&gt;GPT video&lt;/a&gt; is popular if you have some prior language modeling context.&lt;/p&gt; 
&lt;p&gt;For more questions/discussions feel free to stop by &lt;strong&gt;#nanoGPT&lt;/strong&gt; on Discord:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://discord.gg/3zy8kqD9Cp"&gt;&lt;img src="https://dcbadge.vercel.app/api/server/3zy8kqD9Cp?compact=true&amp;amp;style=flat" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;acknowledgements&lt;/h2&gt; 
&lt;p&gt;All nanoGPT experiments are powered by GPUs on &lt;a href="https://lambdalabs.com"&gt;Lambda labs&lt;/a&gt;, my favorite Cloud GPU provider. Thank you Lambda labs for sponsoring nanoGPT!&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>spipm/Depixelization_poc</title>
      <link>https://github.com/spipm/Depixelization_poc</link>
      <description>&lt;p&gt;Depix is a PoC for a technique to recover plaintext from pixelized screenshots.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Depix&lt;/h1&gt; 
&lt;p&gt;Depix is a PoC for a technique to recover plaintext from pixelized screenshots.&lt;/p&gt; 
&lt;p&gt;This implementation works on pixelized images that were created with a linear box filter. In &lt;a href="https://www.spipm.nl/2030.html"&gt;this article&lt;/a&gt; I cover background information on pixelization and similar research.&lt;/p&gt; 
&lt;h2&gt;Example&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/spipm/Depixelization_poc/main/docs/img/Recovering_prototype_latest.png" alt="image" /&gt;&lt;/p&gt; 
&lt;h2&gt;Updates&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;24 dec '24: Made repo private, changed the name and made it public again. It just had a ridiculous amount of stars because of the media hype, which didn't feel right. I made this as a quick PoC for a company back in the day, because someone pixelated part of a password for an account with Domain Admin rights. The hype got running by the catchy image and eventually this repo had 26152 stars. If I ever get this much stars again, I want it to be for a project that I'm that hyped about as well. &lt;img src="https://raw.githubusercontent.com/spipm/Depixelization_poc/main/images/stars.png" alt="image" /&gt;&lt;/li&gt; 
 &lt;li&gt;27 nov '23: Refactored and removed all this pip stuff. I like scripts I can just run. If a package can't be found, just install it. Also added &lt;code&gt;tool_show_boxes.py&lt;/code&gt; to show how bad the box detector is (you have to really cut out the pixels exactly). Made a TODO to create a version that just cuts out boxes of static size.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Install the dependencies&lt;/li&gt; 
 &lt;li&gt;Run Depix:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;python3 depix.py \
    -p /path/to/your/input/image.png \
    -s images/searchimages/debruinseq_notepad_Windows10_closeAndSpaced.png \
    -o /path/to/your/output.png
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Example usage&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Depixelize example image created with Notepad and pixelized with Greenshot. Greenshot averages by averaging the gamma-encoded 0-255 values, which is Depix's default mode.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;python3 depix.py \
    -p images/testimages/testimage3_pixels.png \
    -s images/searchimages/debruinseq_notepad_Windows10_closeAndSpaced.png
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Result: &lt;img src="https://raw.githubusercontent.com/spipm/Depixelization_poc/main/docs/img/example_output_multiword.png" alt="image" /&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Depixelize example image created with Sublime and pixelized with Gimp, where averaging is done in linear sRGB. The backgroundcolor option filters out the background color of the editor.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;python3 depix.py \
    -p images/testimages/sublime_screenshot_pixels_gimp.png \
    -s images/searchimages/debruin_sublime_Linux_small.png \
    --backgroundcolor 40,41,35 \
    --averagetype linear
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Result: &lt;img src="https://raw.githubusercontent.com/spipm/Depixelization_poc/main/docs/img/output_depixelizedExample_linear.png" alt="image" /&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;(Optional) You can view if the box detector thingie finds your pixels with &lt;code&gt;tool_show_boxes.py&lt;/code&gt;. Consider a smaller batch of pixels if this looks all mangled. Example of good looking boxes:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;python3 tool_show_boxes.py \ 
    -p images/testimages/testimage3_pixels.png \
    -s images/searchimages/debruinseq_notepad_Windows10_closeAndSpaced.png
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;(Optional) You can create pixelized image by using &lt;code&gt;tool_gen_pixelated.py&lt;/code&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;python3 tool_gen_pixelated.py -i /path/to/image.png -o pixed_output.png
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;For a detailed explanation, please try to run &lt;code&gt;$ python3 depix.py -h&lt;/code&gt; and &lt;code&gt;tool_gen_pixelated.py&lt;/code&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;About&lt;/h2&gt; 
&lt;h3&gt;Making a Search Image&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Cut out the pixelated blocks from the screenshot as a single rectangle.&lt;/li&gt; 
 &lt;li&gt;Paste a &lt;a href="https://en.wikipedia.org/wiki/De_Bruijn_sequence"&gt;De Bruijn sequence&lt;/a&gt; with expected characters in an editor with the same font settings as your input image (Same text size, similar font, same colors).&lt;/li&gt; 
 &lt;li&gt;Make a screenshot of the sequence.&lt;/li&gt; 
 &lt;li&gt;Move that screenshot into a folder like &lt;code&gt;images/searchimages/&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Run Depix with the &lt;code&gt;-s&lt;/code&gt; flag set to the location of this screenshot.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Making a Pixelized Image&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Cut out the pixelized blocks exactly. See the &lt;code&gt;testimages&lt;/code&gt; for examples.&lt;/li&gt; 
 &lt;li&gt;It tries to detect blocks but it doesn't do an amazing job. Play with the &lt;code&gt;tool_show_boxes.py&lt;/code&gt; script and different cutouts if your blocks aren't properly detected.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Algorithm&lt;/h3&gt; 
&lt;p&gt;The algorithm uses the fact that the linear box filter processes every block separately. For every block it pixelizes all blocks in the search image to check for direct matches.&lt;/p&gt; 
&lt;p&gt;For some pixelized images Depix manages to find single-match results. It assumes these are correct. The matches of surrounding multi-match blocks are then compared to be geometrically at the same distance as in the pixelized image. Matches are also treated as correct. This process is repeated a couple of times.&lt;/p&gt; 
&lt;p&gt;After correct blocks have no more geometrical matches, it will output all correct blocks directly. For multi-match blocks, it outputs the average of all matches.&lt;/p&gt; 
&lt;h3&gt;Known limitations&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;The algorithm matches by integer block-boundaries. As a result, it has the underlying assumption that for all characters rendered (both in the de Brujin sequence and the pixelated image), the text positioning is done at pixel level. However, some modern text rasterizers position text &lt;a href="http://agg.sourceforge.net/antigrain.com/research/font_rasterization/"&gt;at sub-pixel accuracies&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;You need to know the font specifications and in some cases the screen settings with which the screenshot was taken. However, if there is enough plaintext in the original image you might be able to use the original as a search image.&lt;/li&gt; 
 &lt;li&gt;This approach doesn't work if additional image compression is performed, because it messes up the colors of a block.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Future development&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Implement more filter functions&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Create more averaging filters that work like some popular editors do.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Create a new tool that utilizes HMMs&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Still, anyone who is passionate about this type of depixelization is encouraged to implement their own HMM-based version and share it.&lt;/p&gt; 
&lt;h3&gt;Other sources and tools&lt;/h3&gt; 
&lt;p&gt;After creating this program, someone pointed me to a &lt;a href="https://www.researchgate.net/publication/305423573_On_the_Ineffectiveness_of_Mosaicing_and_Blurring_as_Tools_for_Document_Redaction"&gt;research document&lt;/a&gt; from 2016 where a group of researchers managed to create a similar tool. Their tool has better precision and works across many different fonts. While their original source code is not public, an open-source implementation exists at &lt;a href="https://github.com/JonasSchatz/DepixHMM"&gt;DepixHMM&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Edit 16 Feb '22: &lt;a href="https://bishopfox.com/authors/dan-petro"&gt;Dan Petro&lt;/a&gt; created the tool UnRedacter (&lt;a href="https://bishopfox.com/blog/unredacter-tool-never-pixelation"&gt;write-up&lt;/a&gt;, &lt;a href="https://github.com/BishopFox/unredacter"&gt;source&lt;/a&gt;) to crack a &lt;a href="https://labs.jumpsec.com/can-depix-deobfuscate-your-data/"&gt;challenge&lt;/a&gt; that was created as a response to Depix!&lt;/p&gt; 
&lt;p&gt;Edit 16 Apr '25: Jeff Geerling created a &lt;a href="https://www.jeffgeerling.com/blog/2025/its-easier-ever-de-censor-videos"&gt;challenge&lt;/a&gt; for depixelating pixelated folder content in a moving image. Three people were able to do it. &lt;a href="https://github.com/KoKuToru/de-pixelate_gaV-O6NPWrI"&gt;Here&lt;/a&gt; is a repo from KoKuToru showing how to do this with TensorFlow! Amazing!&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>