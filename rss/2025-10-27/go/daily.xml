<rss version="2.0">
  <channel>
    <title>GitHub Go Daily Trending</title>
    <description>Daily Trending of Go in GitHub</description>
    <pubDate>Sun, 26 Oct 2025 01:34:20 GMT</pubDate>
    <link>http://mshibanami.github.io/GitHubTrendingRSS</link>
    
    <item>
      <title>spf13/cobra</title>
      <link>https://github.com/spf13/cobra</link>
      <description>&lt;p&gt;A Commander for modern Go CLI interactions&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;a href="https://cobra.dev"&gt; &lt;img width="512" height="535" alt="cobra-logo" src="https://github.com/user-attachments/assets/c8bf9aad-b5ae-41d3-8899-d83baec10af8" /&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;p&gt;Cobra is a library for creating powerful modern CLI applications.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://cobra.dev"&gt;Visit Cobra.dev for extensive documentation&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Cobra is used in many Go projects such as &lt;a href="https://kubernetes.io/"&gt;Kubernetes&lt;/a&gt;, &lt;a href="https://gohugo.io"&gt;Hugo&lt;/a&gt;, and &lt;a href="https://github.com/cli/cli"&gt;GitHub CLI&lt;/a&gt; to name a few. &lt;a href="https://raw.githubusercontent.com/spf13/cobra/main/site/content/projects_using_cobra.md"&gt;This list&lt;/a&gt; contains a more extensive list of projects using Cobra.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/spf13/cobra/actions?query=workflow%3ATest"&gt;&lt;img src="https://img.shields.io/github/actions/workflow/status/spf13/cobra/test.yml?branch=main&amp;amp;longCache=true&amp;amp;label=Test&amp;amp;logo=github%20actions&amp;amp;logoColor=fff" alt="" /&gt;&lt;/a&gt; &lt;a href="https://pkg.go.dev/github.com/spf13/cobra"&gt;&lt;img src="https://pkg.go.dev/badge/github.com/spf13/cobra.svg?sanitize=true" alt="Go Reference" /&gt;&lt;/a&gt; &lt;a href="https://goreportcard.com/report/github.com/spf13/cobra"&gt;&lt;img src="https://goreportcard.com/badge/github.com/spf13/cobra" alt="Go Report Card" /&gt;&lt;/a&gt; &lt;a href="https://gophers.slack.com/archives/CD3LP1199"&gt;&lt;img src="https://img.shields.io/badge/Slack-cobra-brightgreen" alt="Slack" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;div align="center" markdown="1"&gt; 
 &lt;sup&gt;Supported by:&lt;/sup&gt; 
 &lt;br /&gt; 
 &lt;br /&gt; 
 &lt;a href="https://www.warp.dev/cobra"&gt; &lt;img alt="Warp sponsorship" width="400" src="https://github.com/user-attachments/assets/ab8dd143-b0fd-4904-bdc5-dd7ecac94eae" /&gt; &lt;/a&gt; 
 &lt;h3&gt;&lt;a href="https://www.warp.dev/cobra"&gt;Warp, the AI terminal for devs&lt;/a&gt;&lt;/h3&gt; 
 &lt;p&gt;&lt;a href="https://www.warp.dev/cobra"&gt;Try Cobra in Warp today&lt;/a&gt;&lt;br /&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h1&gt;Overview&lt;/h1&gt; 
&lt;p&gt;Cobra is a library providing a simple interface to create powerful modern CLI interfaces similar to git &amp;amp; go tools.&lt;/p&gt; 
&lt;p&gt;Cobra provides:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Easy subcommand-based CLIs: &lt;code&gt;app server&lt;/code&gt;, &lt;code&gt;app fetch&lt;/code&gt;, etc.&lt;/li&gt; 
 &lt;li&gt;Fully POSIX-compliant flags (including short &amp;amp; long versions)&lt;/li&gt; 
 &lt;li&gt;Nested subcommands&lt;/li&gt; 
 &lt;li&gt;Global, local and cascading flags&lt;/li&gt; 
 &lt;li&gt;Intelligent suggestions (&lt;code&gt;app srver&lt;/code&gt;... did you mean &lt;code&gt;app server&lt;/code&gt;?)&lt;/li&gt; 
 &lt;li&gt;Automatic help generation for commands and flags&lt;/li&gt; 
 &lt;li&gt;Grouping help for subcommands&lt;/li&gt; 
 &lt;li&gt;Automatic help flag recognition of &lt;code&gt;-h&lt;/code&gt;, &lt;code&gt;--help&lt;/code&gt;, etc.&lt;/li&gt; 
 &lt;li&gt;Automatically generated shell autocomplete for your application (bash, zsh, fish, powershell)&lt;/li&gt; 
 &lt;li&gt;Automatically generated man pages for your application&lt;/li&gt; 
 &lt;li&gt;Command aliases so you can change things without breaking them&lt;/li&gt; 
 &lt;li&gt;The flexibility to define your own help, usage, etc.&lt;/li&gt; 
 &lt;li&gt;Optional seamless integration with &lt;a href="https://github.com/spf13/viper"&gt;viper&lt;/a&gt; for 12-factor apps&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Concepts&lt;/h1&gt; 
&lt;p&gt;Cobra is built on a structure of commands, arguments &amp;amp; flags.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Commands&lt;/strong&gt; represent actions, &lt;strong&gt;Args&lt;/strong&gt; are things and &lt;strong&gt;Flags&lt;/strong&gt; are modifiers for those actions.&lt;/p&gt; 
&lt;p&gt;The best applications read like sentences when used, and as a result, users intuitively know how to interact with them.&lt;/p&gt; 
&lt;p&gt;The pattern to follow is &lt;code&gt;APPNAME VERB NOUN --ADJECTIVE&lt;/code&gt; or &lt;code&gt;APPNAME COMMAND ARG --FLAG&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;A few good real world examples may better illustrate this point.&lt;/p&gt; 
&lt;p&gt;In the following example, 'server' is a command, and 'port' is a flag:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;hugo server --port=1313
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;In this command we are telling Git to clone the url bare.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;git clone URL --bare
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Commands&lt;/h2&gt; 
&lt;p&gt;Command is the central point of the application. Each interaction that the application supports will be contained in a Command. A command can have children commands and optionally run an action.&lt;/p&gt; 
&lt;p&gt;In the example above, 'server' is the command.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://pkg.go.dev/github.com/spf13/cobra#Command"&gt;More about cobra.Command&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Flags&lt;/h2&gt; 
&lt;p&gt;A flag is a way to modify the behavior of a command. Cobra supports fully POSIX-compliant flags as well as the Go &lt;a href="https://golang.org/pkg/flag/"&gt;flag package&lt;/a&gt;. A Cobra command can define flags that persist through to children commands and flags that are only available to that command.&lt;/p&gt; 
&lt;p&gt;In the example above, 'port' is the flag.&lt;/p&gt; 
&lt;p&gt;Flag functionality is provided by the &lt;a href="https://github.com/spf13/pflag"&gt;pflag library&lt;/a&gt;, a fork of the flag standard library which maintains the same interface while adding POSIX compliance.&lt;/p&gt; 
&lt;h1&gt;Installing&lt;/h1&gt; 
&lt;p&gt;Using Cobra is easy. First, use &lt;code&gt;go get&lt;/code&gt; to install the latest version of the library.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;go get -u github.com/spf13/cobra@latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Next, include Cobra in your application:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;import "github.com/spf13/cobra"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;Usage&lt;/h1&gt; 
&lt;p&gt;&lt;code&gt;cobra-cli&lt;/code&gt; is a command line program to generate cobra applications and command files. It will bootstrap your application scaffolding to rapidly develop a Cobra-based application. It is the easiest way to incorporate Cobra into your application.&lt;/p&gt; 
&lt;p&gt;It can be installed by running:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;go install github.com/spf13/cobra-cli@latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For complete details on using the Cobra-CLI generator, please read &lt;a href="https://github.com/spf13/cobra-cli/raw/main/README.md"&gt;The Cobra Generator README&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;For complete details on using the Cobra library, please read &lt;a href="https://raw.githubusercontent.com/spf13/cobra/main/site/content/user_guide.md"&gt;The Cobra User Guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;License&lt;/h1&gt; 
&lt;p&gt;Cobra is released under the Apache 2.0 license. See &lt;a href="https://raw.githubusercontent.com/spf13/cobra/main/LICENSE.txt"&gt;LICENSE.txt&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>stretchr/testify</title>
      <link>https://github.com/stretchr/testify</link>
      <description>&lt;p&gt;A toolkit with common assertions and mocks that plays nicely with the standard library&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Testify - Thou Shalt Write Tests&lt;/h1&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] Testify is being maintained at v1, no breaking changes will be accepted in this repo.&lt;br /&gt; &lt;a href="https://github.com/stretchr/testify/discussions/1560"&gt;See discussion about v2&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;a href="https://github.com/stretchr/testify/actions/workflows/main.yml"&gt;&lt;img src="https://github.com/stretchr/testify/actions/workflows/main.yml/badge.svg?branch=master" alt="Build Status" /&gt;&lt;/a&gt; &lt;a href="https://goreportcard.com/report/github.com/stretchr/testify"&gt;&lt;img src="https://goreportcard.com/badge/github.com/stretchr/testify" alt="Go Report Card" /&gt;&lt;/a&gt; &lt;a href="https://pkg.go.dev/github.com/stretchr/testify"&gt;&lt;img src="https://pkg.go.dev/badge/github.com/stretchr/testify" alt="PkgGoDev" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Go code (golang) set of packages that provide many tools for testifying that your code will behave as you intend.&lt;/p&gt; 
&lt;p&gt;Features include:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/stretchr/testify/master/#assert-package"&gt;Easy assertions&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/stretchr/testify/master/#mock-package"&gt;Mocking&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/stretchr/testify/master/#suite-package"&gt;Testing suite interfaces and functions&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Get started:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Install testify with &lt;a href="https://raw.githubusercontent.com/stretchr/testify/master/#installation"&gt;one line of code&lt;/a&gt;, or &lt;a href="https://raw.githubusercontent.com/stretchr/testify/master/#staying-up-to-date"&gt;update it with another&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;For an introduction to writing test code in Go, see &lt;a href="https://go.dev/doc/code#Testing"&gt;https://go.dev/doc/code#Testing&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Check out the API Documentation &lt;a href="https://pkg.go.dev/github.com/stretchr/testify"&gt;https://pkg.go.dev/github.com/stretchr/testify&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Use &lt;a href="https://github.com/Antonboom/testifylint"&gt;testifylint&lt;/a&gt; (via &lt;a href="https://golangci-lint.run/"&gt;golangci-lint&lt;/a&gt;) to avoid common mistakes&lt;/li&gt; 
 &lt;li&gt;A little about &lt;a href="https://en.wikipedia.org/wiki/Test-driven_development"&gt;Test-Driven Development (TDD)&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;&lt;a href="https://pkg.go.dev/github.com/stretchr/testify/assert" title="API documentation"&gt;&lt;code&gt;assert&lt;/code&gt;&lt;/a&gt; package&lt;/h2&gt; 
&lt;p&gt;The &lt;code&gt;assert&lt;/code&gt; package provides some helpful methods that allow you to write better test code in Go.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Prints friendly, easy to read failure descriptions&lt;/li&gt; 
 &lt;li&gt;Allows for very readable code&lt;/li&gt; 
 &lt;li&gt;Optionally annotate each assertion with a message&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;See it in action:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;package yours

import (
	"testing"

	"github.com/stretchr/testify/assert"
)

func TestSomething(t *testing.T) {
	// assert equality
	assert.Equal(t, 123, 123, "they should be equal")

	// assert inequality
	assert.NotEqual(t, 123, 456, "they should not be equal")

	// assert for nil (good for errors)
	assert.Nil(t, object)

	// assert for not nil (good when you expect something)
	if assert.NotNil(t, object) {
		// now we know that object isn't nil, we are safe to make
		// further assertions without causing any errors
		assert.Equal(t, "Something", object.Value)
	}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;Every assert func takes the &lt;code&gt;testing.T&lt;/code&gt; object as the first argument. This is how it writes the errors out through the normal &lt;code&gt;go test&lt;/code&gt; capabilities.&lt;/li&gt; 
 &lt;li&gt;Every assert func returns a bool indicating whether the assertion was successful or not, this is useful for if you want to go on making further assertions under certain conditions.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;if you assert many times, use the below:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;package yours

import (
	"testing"

	"github.com/stretchr/testify/assert"
)

func TestSomething(t *testing.T) {
	assert := assert.New(t)

	// assert equality
	assert.Equal(123, 123, "they should be equal")

	// assert inequality
	assert.NotEqual(123, 456, "they should not be equal")

	// assert for nil (good for errors)
	assert.Nil(object)

	// assert for not nil (good when you expect something)
	if assert.NotNil(object) {
		// now we know that object isn't nil, we are safe to make
		// further assertions without causing any errors
		assert.Equal("Something", object.Value)
	}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;&lt;a href="https://pkg.go.dev/github.com/stretchr/testify/require" title="API documentation"&gt;&lt;code&gt;require&lt;/code&gt;&lt;/a&gt; package&lt;/h2&gt; 
&lt;p&gt;The &lt;code&gt;require&lt;/code&gt; package provides same global functions as the &lt;code&gt;assert&lt;/code&gt; package, but instead of returning a boolean result they terminate current test. These functions must be called from the goroutine running the test or benchmark function, not from other goroutines created during the test. Otherwise race conditions may occur.&lt;/p&gt; 
&lt;p&gt;See &lt;a href="https://pkg.go.dev/testing#T.FailNow"&gt;t.FailNow&lt;/a&gt; for details.&lt;/p&gt; 
&lt;h2&gt;&lt;a href="https://pkg.go.dev/github.com/stretchr/testify/mock" title="API documentation"&gt;&lt;code&gt;mock&lt;/code&gt;&lt;/a&gt; package&lt;/h2&gt; 
&lt;p&gt;The &lt;code&gt;mock&lt;/code&gt; package provides a mechanism for easily writing mock objects that can be used in place of real objects when writing test code.&lt;/p&gt; 
&lt;p&gt;An example test function that tests a piece of code that relies on an external object &lt;code&gt;testObj&lt;/code&gt;, can set up expectations (testify) and assert that they indeed happened:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;package yours

import (
	"testing"

	"github.com/stretchr/testify/mock"
)

/*
  Test objects
*/

// MyMockedObject is a mocked object that implements an interface
// that describes an object that the code I am testing relies on.
type MyMockedObject struct {
	mock.Mock
}

// DoSomething is a method on MyMockedObject that implements some interface
// and just records the activity, and returns what the Mock object tells it to.
//
// In the real object, this method would do something useful, but since this
// is a mocked object - we're just going to stub it out.
//
// NOTE: This method is not being tested here, code that uses this object is.
func (m *MyMockedObject) DoSomething(number int) (bool, error) {
	args := m.Called(number)
	return args.Bool(0), args.Error(1)
}

/*
  Actual test functions
*/

// TestSomething is an example of how to use our test object to
// make assertions about some target code we are testing.
func TestSomething(t *testing.T) {
	// create an instance of our test object
	testObj := new(MyMockedObject)

	// set up expectations
	testObj.On("DoSomething", 123).Return(true, nil)

	// call the code we are testing
	targetFuncThatDoesSomethingWithObj(testObj)

	// assert that the expectations were met
	testObj.AssertExpectations(t)
}

// TestSomethingWithPlaceholder is a second example of how to use our test object to
// make assertions about some target code we are testing.
// This time using a placeholder. Placeholders might be used when the
// data being passed in is normally dynamically generated and cannot be
// predicted beforehand (eg. containing hashes that are time sensitive)
func TestSomethingWithPlaceholder(t *testing.T) {
	// create an instance of our test object
	testObj := new(MyMockedObject)

	// set up expectations with a placeholder in the argument list
	testObj.On("DoSomething", mock.Anything).Return(true, nil)

	// call the code we are testing
	targetFuncThatDoesSomethingWithObj(testObj)

	// assert that the expectations were met
	testObj.AssertExpectations(t)

}

// TestSomethingElse2 is a third example that shows how you can use
// the Unset method to cleanup handlers and then add new ones.
func TestSomethingElse2(t *testing.T) {
	// create an instance of our test object
	testObj := new(MyMockedObject)

	// set up expectations with a placeholder in the argument list
	mockCall := testObj.On("DoSomething", mock.Anything).Return(true, nil)

	// call the code we are testing
	targetFuncThatDoesSomethingWithObj(testObj)

	// assert that the expectations were met
	testObj.AssertExpectations(t)

	// remove the handler now so we can add another one that takes precedence
	mockCall.Unset()

	// return false now instead of true
	testObj.On("DoSomething", mock.Anything).Return(false, nil)

	testObj.AssertExpectations(t)
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For more information on how to write mock code, check out the &lt;a href="https://pkg.go.dev/github.com/stretchr/testify/mock"&gt;API documentation for the &lt;code&gt;mock&lt;/code&gt; package&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;You can use the &lt;a href="https://vektra.github.io/mockery/latest/"&gt;mockery tool&lt;/a&gt; to autogenerate the mock code against an interface as well, making using mocks much quicker.&lt;/p&gt; 
&lt;h2&gt;&lt;a href="https://pkg.go.dev/github.com/stretchr/testify/suite" title="API documentation"&gt;&lt;code&gt;suite&lt;/code&gt;&lt;/a&gt; package&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!WARNING] The suite package does not support parallel tests. See &lt;a href="https://github.com/stretchr/testify/issues/934"&gt;#934&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;The &lt;code&gt;suite&lt;/code&gt; package provides functionality that you might be used to from more common object-oriented languages. With it, you can build a testing suite as a struct, build setup/teardown methods and testing methods on your struct, and run them with 'go test' as per normal.&lt;/p&gt; 
&lt;p&gt;An example suite is shown below:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;// Basic imports
import (
	"testing"

	"github.com/stretchr/testify/assert"
	"github.com/stretchr/testify/suite"
)

// Define the suite, and absorb the built-in basic suite
// functionality from testify - including a T() method which
// returns the current testing context
type ExampleTestSuite struct {
	suite.Suite
	VariableThatShouldStartAtFive int
}

// Make sure that VariableThatShouldStartAtFive is set to five
// before each test
func (suite *ExampleTestSuite) SetupTest() {
	suite.VariableThatShouldStartAtFive = 5
}

// All methods that begin with "Test" are run as tests within a
// suite.
func (suite *ExampleTestSuite) TestExample() {
	assert.Equal(suite.T(), 5, suite.VariableThatShouldStartAtFive)
}

// In order for 'go test' to run this suite, we need to create
// a normal test function and pass our suite to suite.Run
func TestExampleTestSuite(t *testing.T) {
	suite.Run(t, new(ExampleTestSuite))
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For a more complete example, using all of the functionality provided by the suite package, look at our &lt;a href="https://github.com/stretchr/testify/raw/master/suite/suite_test.go"&gt;example testing suite&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;For more information on writing suites, check out the &lt;a href="https://pkg.go.dev/github.com/stretchr/testify/suite"&gt;API documentation for the &lt;code&gt;suite&lt;/code&gt; package&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;Suite&lt;/code&gt; object has assertion methods:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;// Basic imports
import (
	"testing"

	"github.com/stretchr/testify/suite"
)

// Define the suite, and absorb the built-in basic suite
// functionality from testify - including assertion methods.
type ExampleTestSuite struct {
	suite.Suite
	VariableThatShouldStartAtFive int
}

// Make sure that VariableThatShouldStartAtFive is set to five
// before each test
func (suite *ExampleTestSuite) SetupTest() {
	suite.VariableThatShouldStartAtFive = 5
}

// All methods that begin with "Test" are run as tests within a
// suite.
func (suite *ExampleTestSuite) TestExample() {
	suite.Equal(suite.VariableThatShouldStartAtFive, 5)
}

// In order for 'go test' to run this suite, we need to create
// a normal test function and pass our suite to suite.Run
func TestExampleTestSuite(t *testing.T) {
	suite.Run(t, new(ExampleTestSuite))
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h1&gt;Installation&lt;/h1&gt; 
&lt;p&gt;To install Testify, use &lt;code&gt;go get&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;go get github.com/stretchr/testify
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This will then make the following packages available to you:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;github.com/stretchr/testify/assert
github.com/stretchr/testify/require
github.com/stretchr/testify/mock
github.com/stretchr/testify/suite
github.com/stretchr/testify/http (deprecated)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Import the &lt;code&gt;testify/assert&lt;/code&gt; package into your code using this template:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;package yours

import (
	"testing"

	"github.com/stretchr/testify/assert"
)

func TestSomething(t *testing.T) {
	assert.True(t, true, "True is true!")
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h1&gt;Staying up to date&lt;/h1&gt; 
&lt;p&gt;To update Testify to the latest version, use &lt;code&gt;go get -u github.com/stretchr/testify&lt;/code&gt;.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h1&gt;Supported go versions&lt;/h1&gt; 
&lt;p&gt;We currently support the most recent major Go versions from 1.19 onward.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h1&gt;Contributing&lt;/h1&gt; 
&lt;p&gt;Please feel free to submit issues, fork the repository and send pull requests!&lt;/p&gt; 
&lt;p&gt;When submitting an issue, we ask that you please include a complete test function that demonstrates the issue. Extra credit for those using Testify to write the test code that demonstrates it.&lt;/p&gt; 
&lt;p&gt;Code generation is used. &lt;a href="https://github.com/search?q=repo%3Astretchr%2Ftestify%20%22Code%20generated%20with%22&amp;amp;type=code"&gt;Look for &lt;code&gt;Code generated with&lt;/code&gt;&lt;/a&gt; at the top of some files. Run &lt;code&gt;go generate ./...&lt;/code&gt; to update generated files.&lt;/p&gt; 
&lt;p&gt;We also chat on the &lt;a href="https://gophers.slack.com"&gt;Gophers Slack&lt;/a&gt; group in the &lt;code&gt;#testify&lt;/code&gt; and &lt;code&gt;#testify-dev&lt;/code&gt; channels.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h1&gt;License&lt;/h1&gt; 
&lt;p&gt;This project is licensed under the terms of the MIT license.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>kagent-dev/kagent</title>
      <link>https://github.com/kagent-dev/kagent</link>
      <description>&lt;p&gt;Cloud Native Agentic AI | Discord: https://bit.ly/kagentdiscord&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://raw.githubusercontent.com/kagent-dev/kagent/main/img/icon-dark.svg" alt="kagent" width="400" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://raw.githubusercontent.com/kagent-dev/kagent/main/img/icon-light.svg" alt="kagent" width="400" /&gt; 
  &lt;img alt="kagent" src="https://raw.githubusercontent.com/kagent-dev/kagent/main/img/icon-light.svg?sanitize=true" /&gt; 
 &lt;/picture&gt; 
 &lt;div&gt; 
  &lt;a href="https://github.com/kagent-dev/kagent/releases"&gt; &lt;img src="https://img.shields.io/github/v/release/kagent-dev/kagent?style=flat&amp;amp;label=Latest%20version" alt="Release" /&gt; &lt;/a&gt; 
  &lt;a href="https://github.com/kagent-dev/kagent/actions/workflows/ci.yaml"&gt; &lt;img src="https://github.com/kagent-dev/kagent/actions/workflows/ci.yaml/badge.svg?sanitize=true" alt="Build Status" height="20" /&gt; &lt;/a&gt; 
  &lt;a href="https://opensource.org/licenses/Apache-2.0"&gt; &lt;img src="https://img.shields.io/badge/License-Apache2.0-brightgreen.svg?style=flat" alt="License: Apache 2.0" /&gt; &lt;/a&gt; 
  &lt;a href="https://github.com/kagent-dev/kagent"&gt; &lt;img src="https://img.shields.io/github/stars/kagent-dev/kagent.svg?style=flat&amp;amp;logo=github&amp;amp;label=Stars" alt="Stars" /&gt; &lt;/a&gt; 
  &lt;a href="https://discord.gg/Fu3k65f2k3"&gt; &lt;img src="https://img.shields.io/discord/1346225185166065826?style=flat&amp;amp;label=Join%20Discord&amp;amp;color=6D28D9" alt="Discord" /&gt; &lt;/a&gt; 
  &lt;a href="https://deepwiki.com/kagent-dev/kagent"&gt;&lt;img src="https://deepwiki.com/badge.svg?sanitize=true" alt="Ask DeepWiki" /&gt;&lt;/a&gt; 
  &lt;a href="https://codespaces.new/kagent-dev/kagent"&gt; &lt;img src="https://github.com/codespaces/badge.svg?sanitize=true" alt="Open in Github Codespaces" style="max-width: 100%;" height="20" /&gt; &lt;/a&gt; 
  &lt;a href="https://www.bestpractices.dev/projects/10723"&gt;&lt;img src="https://www.bestpractices.dev/projects/10723/badge" alt="OpenSSF Best Practices" /&gt;&lt;/a&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;strong&gt;kagent&lt;/strong&gt; is a Kubernetes native framework for building AI agents. Kubernetes is the most popular orchestration platform for running workloads, and &lt;strong&gt;kagent&lt;/strong&gt; makes it easy to build, deploy and manage AI agents in Kubernetes. The &lt;strong&gt;kagent&lt;/strong&gt; framework is designed to be easy to understand and use, and to provide a flexible and powerful way to build and manage AI agents.&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/kagent-dev/kagent/main/img/hero.png" alt="Autogen Framework" width="500" /&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Get started&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://kagent.dev/docs/kagent/getting-started/quickstart"&gt;Quick Start&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://kagent.dev/docs/kagent/introduction/installation"&gt;Installation guide&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;The kagent documentation is available at &lt;a href="https://kagent.dev/docs/kagent"&gt;kagent.dev/docs&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Core Concepts&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Agents&lt;/strong&gt;: Agents are the main building block of kagent. They are a system prompt, a set of tools and agents, and an LLM configuration represented with a Kubernetes custom resource called "Agent".&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;LLM Providers&lt;/strong&gt;: Kagent supports multiple LLM providers, including &lt;a href="https://kagent.dev/docs/kagent/supported-providers/openai"&gt;OpenAI&lt;/a&gt;, &lt;a href="https://kagent.dev/docs/kagent/supported-providers/azure-openai"&gt;Azure OpenAI&lt;/a&gt;, &lt;a href="https://kagent.dev/docs/kagent/supported-providers/anthropic"&gt;Anthropic&lt;/a&gt;, &lt;a href="https://kagent.dev/docs/kagent/supported-providers/google-vertexai"&gt;Google Vertex AI&lt;/a&gt;, &lt;a href="https://kagent.dev/docs/kagent/supported-providers/ollama"&gt;Ollama&lt;/a&gt; and any other &lt;a href="https://kagent.dev/docs/kagent/supported-providers/custom-models"&gt;custom providers and models&lt;/a&gt; accessible via AI gateways. Providers are represented by the ModelConfig resource.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;MCP Tools&lt;/strong&gt;: Agents can connect to any MCP server that provides tools. Kagent comes with an MCP server with tools for Kubernetes, Istio, Helm, Argo, Prometheus, Grafana, Cilium, and others. All tools are Kubernetes custom resources (ToolServers) and can be used by multiple agents.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Observability&lt;/strong&gt;: Kagent supports &lt;a href="https://kagent.dev/docs/kagent/getting-started/tracing"&gt;OpenTelemetry tracing&lt;/a&gt;, which allows you to monitor what's happening with your agents and tools.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Core Principles&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Kubernetes Native&lt;/strong&gt;: Kagent is designed to be easy to understand and use, and to provide a flexible and powerful way to build and manage AI agents.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Extensible&lt;/strong&gt;: Kagent is designed to be extensible, so you can add your own agents and tools.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Flexible&lt;/strong&gt;: Kagent is designed to be flexible, to suit any AI agent use case.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Observable&lt;/strong&gt;: Kagent is designed to be observable, so you can monitor the agents and tools using all common monitoring frameworks.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Declarative&lt;/strong&gt;: Kagent is designed to be declarative, so you can define the agents and tools in a YAML file.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Testable&lt;/strong&gt;: Kagent is designed to be tested and debugged easily. This is especially important for AI agent applications.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Architecture&lt;/h2&gt; 
&lt;p&gt;The kagent framework is designed to be easy to understand and use, and to provide a flexible and powerful way to build and manage AI agents.&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/kagent-dev/kagent/main/img/arch.png" alt="kagent" width="500" /&gt; 
&lt;/div&gt; 
&lt;p&gt;Kagent has 4 core components:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Controller&lt;/strong&gt;: The controller is a Kubernetes controller that watches the kagent custom resources and creates the necessary resources to run the agents.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;UI&lt;/strong&gt;: The UI is a web UI that allows you to manage the agents and tools.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Engine&lt;/strong&gt;: The engine runs your agents using &lt;a href="https://google.github.io/adk-docs/"&gt;ADK&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;CLI&lt;/strong&gt;: The CLI is a command-line tool that allows you to manage the agents and tools.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Roadmap&lt;/h2&gt; 
&lt;p&gt;&lt;code&gt;kagent&lt;/code&gt; is currently in active development. You can check out the full roadmap in the project Kanban board &lt;a href="https://github.com/orgs/kagent-dev/projects/3"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Local development&lt;/h2&gt; 
&lt;p&gt;For instructions on how to run everything locally, see the &lt;a href="https://raw.githubusercontent.com/kagent-dev/kagent/main/DEVELOPMENT.md"&gt;DEVELOPMENT.md&lt;/a&gt; file.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;For instructions on how to contribute to the kagent project, see the &lt;a href="https://raw.githubusercontent.com/kagent-dev/kagent/main/CONTRIBUTION.md"&gt;CONTRIBUTION.md&lt;/a&gt; file.&lt;/p&gt; 
&lt;h2&gt;Contributors&lt;/h2&gt; 
&lt;p&gt;Thanks to all contributors who are helping to make kagent better.&lt;/p&gt; 
&lt;a href="https://github.com/kagent-dev/kagent/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=kagent-dev/kagent" /&gt; &lt;/a&gt; 
&lt;h2&gt;Star History&lt;/h2&gt; 
&lt;a href="https://www.star-history.com/#kagent-dev/kagent&amp;amp;Date"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://api.star-history.com/svg?repos=kagent-dev/kagent&amp;amp;type=Date&amp;amp;theme=dark" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://api.star-history.com/svg?repos=kagent-dev/kagent&amp;amp;type=Date" /&gt; 
  &lt;img alt="Star history of kagent-dev/kagent over time" src="https://api.star-history.com/svg?repos=kagent-dev/kagent&amp;amp;type=Date" /&gt; 
 &lt;/picture&gt; &lt;/a&gt; 
&lt;hr /&gt; 
&lt;div align="center"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://raw.githubusercontent.com/cncf/artwork/refs/heads/main/other/cncf/horizontal/color-whitetext/cncf-color-whitetext.svg" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://raw.githubusercontent.com/cncf/artwork/refs/heads/main/other/cncf/horizontal/color/cncf-color.svg" /&gt; 
  &lt;img width="300" alt="Cloud Native Computing Foundation logo" src="https://raw.githubusercontent.com/cncf/artwork/refs/heads/main/other/cncf/horizontal/color-whitetext/cncf-color-whitetext.svg?sanitize=true" /&gt; 
 &lt;/picture&gt; 
 &lt;p&gt;kagent is a &lt;a href="https://cncf.io"&gt;Cloud Native Computing Foundation&lt;/a&gt; project.&lt;/p&gt; 
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>syncthing/syncthing</title>
      <link>https://github.com/syncthing/syncthing</link>
      <description>&lt;p&gt;Open Source Continuous File Synchronization&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href="https://syncthing.net/"&gt;&lt;img src="https://raw.githubusercontent.com/syncthing/syncthing/main/assets/logo-text-128.png" alt="Syncthing" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;a href="https://www.mozilla.org/MPL/2.0/"&gt;&lt;img src="https://img.shields.io/badge/license-MPLv2-blue.svg?style=flat-square" alt="MPLv2 License" /&gt;&lt;/a&gt; &lt;a href="https://bestpractices.coreinfrastructure.org/projects/88"&gt;&lt;img src="https://bestpractices.coreinfrastructure.org/projects/88/badge" alt="CII Best Practices" /&gt;&lt;/a&gt; &lt;a href="https://goreportcard.com/report/github.com/syncthing/syncthing"&gt;&lt;img src="https://goreportcard.com/badge/github.com/syncthing/syncthing" alt="Go Report Card" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Goals&lt;/h2&gt; 
&lt;p&gt;Syncthing is a &lt;strong&gt;continuous file synchronization program&lt;/strong&gt;. It synchronizes files between two or more computers. We strive to fulfill the goals below. The goals are listed in order of importance, the most important ones first. This is the summary version of the goal list - for more commentary, see the full &lt;a href="https://github.com/syncthing/syncthing/raw/main/GOALS.md"&gt;Goals document&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Syncthing should be:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Safe From Data Loss&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;Protecting the user's data is paramount. We take every reasonable precaution to avoid corrupting the user's files.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Secure Against Attackers&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;Again, protecting the user's data is paramount. Regardless of our other goals, we must never allow the user's data to be susceptible to eavesdropping or modification by unauthorized parties.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Easy to Use&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;Syncthing should be approachable, understandable, and inclusive.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Automatic&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;User interaction should be required only when absolutely necessary.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Universally Available&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;Syncthing should run on every common computer. We are mindful that the latest technology is not always available to every individual.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;For Individuals&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;Syncthing is primarily about empowering the individual user with safe, secure, and easy to use file synchronization.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Everything Else&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;There are many things we care about that don't make it on to the list. It is fine to optimize for these values, as long as they are not in conflict with the stated goals above.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;p&gt;Take a look at the &lt;a href="https://docs.syncthing.net/intro/getting-started.html"&gt;getting started guide&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;There are a few examples for keeping Syncthing running in the background on your system in &lt;a href="https://github.com/syncthing/syncthing/raw/main/etc"&gt;the etc directory&lt;/a&gt;. There are also several &lt;a href="https://docs.syncthing.net/users/contrib.html#gui-wrappers"&gt;GUI implementations&lt;/a&gt; for Windows, Mac, and Linux.&lt;/p&gt; 
&lt;h2&gt;Docker&lt;/h2&gt; 
&lt;p&gt;To run Syncthing in Docker, see &lt;a href="https://github.com/syncthing/syncthing/raw/main/README-Docker.md"&gt;the Docker README&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Getting in Touch&lt;/h2&gt; 
&lt;p&gt;The first and best point of contact is the &lt;a href="https://forum.syncthing.net/"&gt;Forum&lt;/a&gt;. If you've found something that is clearly a bug, feel free to report it in the &lt;a href="https://github.com/syncthing/syncthing/issues"&gt;GitHub issue tracker&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;If you believe that you’ve found a Syncthing-related security vulnerability, please report it by emailing &lt;a href="mailto:security@syncthing.net"&gt;security@syncthing.net&lt;/a&gt;. Do not report it in the Forum or issue tracker.&lt;/p&gt; 
&lt;h2&gt;Building&lt;/h2&gt; 
&lt;p&gt;Building Syncthing from source is easy. After extracting the source bundle from a release or checking out git, you just need to run &lt;code&gt;go run build.go&lt;/code&gt; and the binaries are created in &lt;code&gt;./bin&lt;/code&gt;. There's &lt;a href="https://docs.syncthing.net/dev/building.html"&gt;a guide&lt;/a&gt; with more details on the build process.&lt;/p&gt; 
&lt;h2&gt;Signed Releases&lt;/h2&gt; 
&lt;p&gt;Release binaries are GPG signed with the key available from &lt;a href="https://syncthing.net/security/"&gt;https://syncthing.net/security/&lt;/a&gt;. There is also a built-in automatic upgrade mechanism (disabled in some distribution channels) which uses a compiled in ECDSA signature. macOS and Windows binaries are also code-signed.&lt;/p&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;Please see the Syncthing &lt;a href="https://docs.syncthing.net/"&gt;documentation site&lt;/a&gt; &lt;a href="https://github.com/syncthing/docs"&gt;[source]&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;All code is licensed under the &lt;a href="https://github.com/syncthing/syncthing/raw/main/LICENSE"&gt;MPLv2 License&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>litmuschaos/litmus</title>
      <link>https://github.com/litmuschaos/litmus</link>
      <description>&lt;p&gt;Litmus helps SREs and developers practice chaos engineering in a Cloud-native way. Chaos experiments are published at the ChaosHub (https://hub.litmuschaos.io). Community notes is at https://hackmd.io/a4Zu_sH4TZGeih-xCimi3Q&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;&lt;a href="https://litmuschaos.io/"&gt;LitmusChaos&lt;/a&gt;&lt;/h1&gt; 
&lt;img alt="LitmusChaos" src="https://avatars.githubusercontent.com/u/49853472?s=200&amp;amp;v=4" width="200" align="left" /&gt; 
&lt;h3&gt;Open Source Chaos Engineering Platform&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://slack.litmuschaos.io"&gt;&lt;img src="https://img.shields.io/badge/Slack-Join-purple" alt="Slack Channel" /&gt;&lt;/a&gt; &lt;img src="https://github.com/litmuschaos/litmus/actions/workflows/push.yml/badge.svg?branch=master" alt="GitHub Workflow" /&gt; &lt;a href="https://hub.docker.com/r/litmuschaos/chaos-operator"&gt;&lt;img src="https://img.shields.io/docker/pulls/litmuschaos/chaos-operator.svg?sanitize=true" alt="Docker Pulls" /&gt;&lt;/a&gt; &lt;a href="https://github.com/litmuschaos/litmus/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/litmuschaos/litmus?style=social" alt="GitHub stars" /&gt;&lt;/a&gt; &lt;a href="https://github.com/litmuschaos/litmus/issues"&gt;&lt;img src="https://img.shields.io/github/issues/litmuschaos/litmus" alt="GitHub issues" /&gt;&lt;/a&gt; &lt;a href="https://twitter.com/LitmusChaos"&gt;&lt;img src="https://img.shields.io/twitter/follow/litmuschaos?style=social" alt="Twitter Follow" /&gt;&lt;/a&gt; &lt;a href="https://www.bestpractices.dev/projects/3202"&gt;&lt;img src="https://www.bestpractices.dev/projects/3202/badge" alt="OpenSSF Best Practices" /&gt;&lt;/a&gt; &lt;a href="https://app.fossa.io/projects/git%2Bgithub.com%2Flitmuschaos%2Flitmus?ref=badge_shield"&gt;&lt;img src="https://app.fossa.io/api/projects/git%2Bgithub.com%2Flitmuschaos%2Flitmus.svg?type=shield" alt="FOSSA Status" /&gt;&lt;/a&gt; &lt;a href="https://www.youtube.com/channel/UCa57PMqmz_j0wnteRa9nCaw"&gt;&lt;img src="https://img.shields.io/badge/YouTube-Subscribe-red" alt="YouTube Channel" /&gt;&lt;/a&gt; &lt;a href="https://gurubase.io/g/litmuschaos"&gt;&lt;img src="https://img.shields.io/badge/Gurubase-Ask%20LitmusChaos%20Guru-006BFF" alt="Gurubase" /&gt;&lt;/a&gt; &lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt; 
&lt;h4&gt;&lt;em&gt;Read this in &lt;a href="https://raw.githubusercontent.com/litmuschaos/litmus/master/translations/TRANSLATIONS.md"&gt;other languages&lt;/a&gt;.&lt;/em&gt;&lt;/h4&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/litmuschaos/litmus/master/translations/README-ko.md"&gt;🇰🇷&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/litmuschaos/litmus/master/translations/README-chn.md"&gt;🇨🇳&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/litmuschaos/litmus/master/translations/README-pt-br.md"&gt;🇧🇷&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/litmuschaos/litmus/master/translations/README-hi.md"&gt;🇮🇳&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Overview&lt;/h2&gt; 
&lt;p&gt;LitmusChaos is an open source Chaos Engineering platform that enables teams to identify weaknesses &amp;amp; potential outages in infrastructures by inducing chaos tests in a controlled way. Developers &amp;amp; SREs can practice Chaos Engineering with LitmusChaos as it is easy to use, based on modern Chaos Engineering principles &amp;amp; community collaborated. It is 100% open source &amp;amp; a CNCF project.&lt;/p&gt; 
&lt;p&gt;LitmusChaos takes a cloud-native approach to create, manage and monitor chaos. The platform itself runs as a set of microservices and uses Kubernetes custom resources (CRs) to define the chaos intent, as well as the steady state hypothesis.&lt;/p&gt; 
&lt;p&gt;At a high-level, Litmus comprises of:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Chaos Control Plane&lt;/strong&gt;: A centralized chaos management tool called chaos-center, which helps construct, schedule and visualize Litmus chaos workflows&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Chaos Execution Plane Services&lt;/strong&gt;: Made up of a chaos agent and multiple operators that execute &amp;amp; monitor the experiment within a defined target Kubernetes environment.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/litmuschaos/litmus/master/images/litmus-control-and-execution-plane-overview.png" alt="architecture summary" /&gt;&lt;/p&gt; 
&lt;p&gt;At the heart of the platform are the following chaos custom resources:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;ChaosExperiment&lt;/strong&gt;: A resource to group the configuration parameters of a particular fault. ChaosExperiment CRs are essentially installable templates that describe the library carrying out the fault, indicate permissions needed to run it &amp;amp; the defaults it will operate with. Through the ChaosExperiment, Litmus supports BYOC (bring-your-own-chaos) that helps integrate (optional) any third-party tooling to perform the fault injection.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;ChaosEngine&lt;/strong&gt;: A resource to link a Kubernetes application workload/service, node or an infra component to a fault described by the ChaosExperiment. It also provides options to tune the run properties and specify the steady state validation constraints using 'probes'. ChaosEngine is watched by the Chaos-Operator, which reconciles it (triggers experiment execution) via runners.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The ChaosExperiment &amp;amp; ChaosEngine CRs are embedded within a Workflow object that can string together one or more experiments in a desired order.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;ChaosResult&lt;/strong&gt;: A resource to hold the results of the experiment run. It provides details of the success of each validation constraint, the revert/rollback status of the fault as well as a verdict. The Chaos-exporter reads the results and exposes information as prometheus metrics. ChaosResults are especially useful during automated runs.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;ChaosExperiment CRs are hosted on &lt;a href="https://hub.litmuschaos.io" target="_blank"&gt;hub.litmuschaos.io&lt;/a&gt;. It is a central hub where the application developers or vendors share their chaos experiments so that their users can use them to increase the resilience of the applications in production.&lt;/p&gt; 
&lt;h2&gt;Use cases&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;For Developers&lt;/strong&gt;: To run chaos experiments during application development as an extension of unit testing or integration testing.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;For CI/CD pipeline builders&lt;/strong&gt;: To run chaos as a pipeline stage to find bugs when the application is subjected to fail paths in a pipeline.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;For SREs&lt;/strong&gt;: To plan and schedule chaos experiments into the application and/or surrounding infrastructure. This practice identifies the weaknesses in the deployment system and increases resilience.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Getting Started with Litmus&lt;/h2&gt; 
&lt;p&gt;To get started, check out the &lt;a href="https://docs.litmuschaos.io/docs/introduction/what-is-litmus" target="_blank"&gt;Litmus Docs&lt;/a&gt; and specifically the &lt;a href="https://docs.litmuschaos.io/docs/getting-started/installation#prerequisites" target="_blank"&gt;Installation section&lt;/a&gt; of the &lt;a href="https://docs.litmuschaos.io/docs/getting-started/installation" target="_blank"&gt;Getting Started with Litmus&lt;/a&gt; page.&lt;/p&gt; 
&lt;h2&gt;Contributing to Chaos Hub&lt;/h2&gt; 
&lt;p&gt;Check out the &lt;a href="https://github.com/litmuschaos/community-charts/raw/master/CONTRIBUTING.md" target="_blank"&gt;Contributing Guidelines for the Chaos Hub&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Community&lt;/h2&gt; 
&lt;h3&gt;Community Resources:&lt;/h3&gt; 
&lt;p&gt;Feel free to reach out if you have any queries,concerns, or feature requests&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Give us a star ⭐️ - If you are using LitmusChaos or think it is an interesting project, we would love a star ❤️&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Follow LitmusChaos on Twitter &lt;a href="https://twitter.com/LitmusChaos"&gt;@LitmusChaos&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Subscribe to the &lt;a href="https://www.youtube.com/channel/UCa57PMqmz_j0wnteRa9nCaw"&gt;LitmusChaos YouTube channel&lt;/a&gt; for regular updates &amp;amp; meeting recordings.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;To join our &lt;a href="https://slack.litmuschaos.io/"&gt;Slack Community&lt;/a&gt; and meet our community members, put forward your questions &amp;amp; opinions, join the #litmus channel on the &lt;a href="https://slack.k8s.io/"&gt;Kubernetes Slack&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Community Meetings&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Community Meetings&lt;/li&gt; 
&lt;/ol&gt; 
&lt;ul&gt; 
 &lt;li&gt;These will be hosted every 3rd Wednesday of every month at 5:30 PM GMT /6:30 PM CEST /10 PM IST&lt;/li&gt; 
 &lt;li&gt;These meetings cover community updates, new feature or release announcements, and user/adopter stories. Everyone in the community is welcome to join and participate in discussions.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Contributor Meetings&lt;/li&gt; 
&lt;/ol&gt; 
&lt;ul&gt; 
 &lt;li&gt;These will be hosted every second &amp;amp; last Thursday of every month at 2:30 PM GMT /3:30 PM CEST /7 PM IST&lt;/li&gt; 
 &lt;li&gt;These meetings focus on both technical and non-technical contributions to LitmusChaos. Maintainers, current contributors, and aspiring contributors are encouraged to join to discuss issues, fixes, enhancements, and future contributions.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Fill out the &lt;a href="https://forms.gle/qawjtFUeL431jmpv7"&gt;LitmusChaos Meetings invite form&lt;/a&gt; to get your Calendar invite!&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://hackmd.io/a4Zu_sH4TZGeih-xCimi3Q"&gt;Sync Up Agenda &amp;amp; Meeting Notes&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/litmuschaos/litmus/milestones"&gt;Release Tracker&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Videos&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=3mjGEh905u4&amp;amp;t=1s"&gt;What if Your System Experiences an Outage? Let's Build a Resilient Systems with Chaos Engineering&lt;/a&gt; @ &lt;a href="https://www.youtube.com/@cncf"&gt;CNCF&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://youtu.be/BelNIk4Bkng"&gt;Enhancing Cyber Resilience Through Zero Trust Chaos Experiments in Cloud Native Environments&lt;/a&gt; @ &lt;a href="https://www.youtube.com/@cncf"&gt;CNCF&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=ks2R57hhFZk&amp;amp;t=503s"&gt;LitmusChaos, with Karthik Satchitanand&lt;/a&gt; @ &lt;a href="https://www.youtube.com/@TheKubernetesPodcast"&gt;The Kubernetes Podcast from Google&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=WUXFKxgZRsk"&gt;Cultural Shifts: Fostering a Chaos First Mindset in Platform Engineering&lt;/a&gt; @ &lt;a href="https://www.youtube.com/@cncf"&gt;CNCF&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=xCDQp5E3VUs"&gt;Fire in the Cloud: Bringing Managed Services Under the Ambit of Cloud-Native Chaos Engineering&lt;/a&gt; @ &lt;a href="https://www.youtube.com/@cncf"&gt;CNCF&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=whCkvLKAw74"&gt;Security Controls for Safe Chaos Experimentation&lt;/a&gt; @ &lt;a href="https://www.youtube.com/@cncf"&gt;CNCF&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=BZL-ngvbpbU&amp;amp;t=751s"&gt;Chaos Engineering For Hybrid Targets With LitmusChaos&lt;/a&gt; @ &lt;a href="https://www.youtube.com/@cncf"&gt;CNCF&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://youtu.be/hOghvd9qCzI"&gt;Cloud Native Live: Litmus Chaos Engine and a microservices demo app&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://youtu.be/_x_7SiesjF0"&gt;Chaos Engineering hands-on - An SRE ideating Chaos Experiments and using LitmusChaos | July 2022&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://youtu.be/PQrmBHgk0ps"&gt;Achieve Digital Product Resiliency with Chaos Engineering&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://youtu.be/KSl-oKk6TPA"&gt;Case Study: Bringing Chaos Engineering to the Cloud Native Developers&lt;/a&gt; @ &lt;a href="https://www.youtube.com/@cncf"&gt;CNCF&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=ItUUqejdXr0"&gt;Cloud Native Chaos Engineering with LitmusChaos&lt;/a&gt; @ &lt;a href="https://www.youtube.com/@cncf"&gt;CNCF&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://youtu.be/mwu5eLgUKq4"&gt;How to create Chaos Experiments with Litmus | Litmus Chaos tutorial&lt;/a&gt; @ &lt;a href="https://www.youtube.com/c/IsitObservable"&gt;Is it Observable&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://youtu.be/pMWqhS-F3tQ"&gt;Cloud Native Chaos Engineering Preview With LitmusChaos&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://youtu.be/5CI8d-SKBfc"&gt;Get started with Chaos Engineering with Litmus&lt;/a&gt; @ &lt;a href="https://www.youtube.com/c/ContainersfromtheCouch"&gt;Containers from the Couch&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://youtu.be/B8DfYnDh2F4"&gt;Litmus 2 - Chaos Engineering Meets Argo Workflows&lt;/a&gt; @ &lt;a href="https://youtube.com/c/devopstoolkit"&gt;DevOps Toolkit&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://youtu.be/D0t3emVLLko"&gt;Hands-on with Litmus 2.0 | Rawkode Live&lt;/a&gt; @ &lt;a href="https://www.youtube.com/channel/UCrber_mFvp_FEF7D9u8PDEA"&gt;Rawkode Academy&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://youtu.be/97BiCNtJbDw"&gt;Introducing LitmusChaos 2.0 / Dok Talks #74&lt;/a&gt; @ &lt;a href="https://www.youtube.com/channel/UCUnXJbHQ89R2uSfKsqQwGvQ"&gt;DoK.community&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://youtu.be/LK0oDLQE4S8"&gt;Introduction to Cloud Native Chaos Engineering&lt;/a&gt; @ &lt;a href="https://www.youtube.com/channel/UCBGOUQHNNtNGcGzVq5rIXjw"&gt;Kunal Kushwaha&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://youtu.be/IiyrEiK4stQ"&gt;#EveryoneCanContribute cafe: Litmus - Chaos Engineering for your Kubernetes&lt;/a&gt; @ &lt;a href="https://www.youtube.com/channel/UCMtZ0sc1HHNtGGWZFDRTh5A"&gt;GitLab Unfiltered&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://youtu.be/rDQ9XKbSJIc"&gt;Litmus - Chaos Engineering for Kubernetes (CNCFMinutes 9)&lt;/a&gt; @ &lt;a href="https://www.youtube.com/channel/UCi-1nnN0eC9nRleXdZA6ncg"&gt;Saiyam Pathak&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://youtu.be/eyAG0svCsQA"&gt;Chaos Engineering with Litmus Chaos by Prithvi Raj || HACKODISHA Workshop&lt;/a&gt; @ &lt;a href="https://www.youtube.com/channel/UC9yM_PkV0QIIsPA3qPrp"&gt;Webwiz&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://www.youtube.com/channel/UCa57PMqmz_j0wnteRa9nCaw"&gt;And More....&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Blogs&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;CNCF: &lt;a href="https://www.cncf.io/blog/2020/08/28/introduction-to-litmuschaos/"&gt;Introduction to LitmusChaos&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Hackernoon: &lt;a href="https://hackernoon.com/solid-tips-on-how-to-manage-and-monitor-chaos-via-litmus-custom-resources-5g1s33m9"&gt;Manage and Monitor Chaos via Litmus Custom Resources&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://dev.to/ksatchit/observability-considerations-in-chaos-the-metrics-story-6cb"&gt;Observability Considerations in Chaos: The Metrics Story&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Community Blogs:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;LiveWyer: &lt;a href="https://livewyer.io/blog/2021/03/22/litmuschaos-showcase-chaos-experiments-in-a-helm-chart-test-suite/"&gt;LitmusChaos Showcase: Chaos Experiments in a Helm Chart Test Suite&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Jessica Cherry: &lt;a href="https://opensource.com/article/21/6/kubernetes-litmus-chaos"&gt;Test Kubernetes cluster failures and experiments in your terminal&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Yang Chuansheng(KubeSphere): &lt;a href="https://kubesphere.io/zh/blogs/litmus-kubesphere/"&gt;KubeSphere 部署 Litmus 至 Kubernetes 开启混沌实验&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Saiyam Pathak(Civo): &lt;a href="https://www.civo.com/learn/chaos-engineering-kubernetes-litmus"&gt;Chaos Experiments on Kubernetes using Litmus to ensure your cluster is production ready&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Andreas Krivas(Container Solutions):&lt;a href="https://blog.container-solutions.com/comparing-chaos-engineering-tools"&gt;Comparing Chaos Engineering Tools for Kubernetes Workloads&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Akram Riahi(WeScale):&lt;a href="https://blog.wescale.fr/2021/03/11/chaos-engineering-litmus-sous-tous-les-angles/"&gt;Chaos Engineering : Litmus sous tous les angles&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Prashanto Priyanshu(LensKart):&lt;a href="https://blog.lenskart.com/lenskarts-approach-to-chaos-engineering-part-2-6290e4f3a74e"&gt;Lenskart’s approach to Chaos Engineering-Part 2&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;DevsDay.ru(Russian):&lt;a href="https://devsday.ru/blog/details/40746"&gt;LitmusChaos at Kubecon EU '21&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Adopters&lt;/h2&gt; 
&lt;p&gt;Check out the &lt;a href="https://github.com/litmuschaos/litmus/raw/master/ADOPTERS.md" target="_blank"&gt;Adopters of LitmusChaos&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;(&lt;em&gt;Send a PR to the above page if you are using Litmus in your chaos engineering practice&lt;/em&gt;)&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Litmus is licensed under the Apache License, Version 2.0. See &lt;a href="https://raw.githubusercontent.com/litmuschaos/litmus/master/LICENSE"&gt;LICENSE&lt;/a&gt; for the full license text. Some of the projects used by the Litmus project may be governed by a different license, please refer to its specific license.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://app.fossa.io/projects/git%2Bgithub.com%2Flitmuschaos%2Flitmus?ref=badge_large"&gt;&lt;img src="https://app.fossa.io/api/projects/git%2Bgithub.com%2Flitmuschaos%2Flitmus.svg?type=large" alt="FOSSA Status" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Litmus Chaos is part of the CNCF Projects.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://landscape.cncf.io/?selected=litmus"&gt;&lt;img src="https://github.com/cncf/artwork/raw/main/other/cncf/horizontal/color/cncf-color.png" alt="CNCF" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Important Links&lt;/h2&gt; 
&lt;a href="https://docs.litmuschaos.io"&gt; Litmus Docs &lt;img src="https://avatars0.githubusercontent.com/u/49853472?s=200&amp;amp;v=4" alt="Litmus Docs" height="15" /&gt; &lt;/a&gt; 
&lt;br /&gt; 
&lt;a href="https://landscape.cncf.io/?selected=litmus"&gt; CNCF Landscape &lt;img src="https://landscape.cncf.io/images/cncf-landscape-horizontal-color.svg?sanitize=true" alt="Litmus on CNCF Landscape" height="15" /&gt; &lt;/a&gt;</description>
    </item>
    
    <item>
      <title>kubernetes/ingress-nginx</title>
      <link>https://github.com/kubernetes/ingress-nginx</link>
      <description>&lt;p&gt;Ingress NGINX Controller for Kubernetes&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Ingress NGINX Controller&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://bestpractices.coreinfrastructure.org/projects/5691"&gt;&lt;img src="https://bestpractices.coreinfrastructure.org/projects/5691/badge" alt="CII Best Practices" /&gt;&lt;/a&gt; &lt;a href="https://goreportcard.com/report/github.com/kubernetes/ingress-nginx"&gt;&lt;img src="https://goreportcard.com/badge/github.com/kubernetes/ingress-nginx" alt="Go Report Card" /&gt;&lt;/a&gt; &lt;a href="https://github.com/kubernetes/ingress-nginx/raw/main/LICENSE"&gt;&lt;img src="https://img.shields.io/github/license/kubernetes/ingress-nginx.svg?sanitize=true" alt="GitHub license" /&gt;&lt;/a&gt; &lt;a href="https://github.com/kubernetes/ingress-nginx/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/kubernetes/ingress-nginx.svg?sanitize=true" alt="GitHub stars" /&gt;&lt;/a&gt; &lt;a href="https://github.com/kubernetes/ingress-nginx/raw/main/CONTRIBUTING.md"&gt;&lt;img src="https://img.shields.io/badge/contributions-welcome-orange.svg?sanitize=true" alt="GitHub stars" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Overview&lt;/h2&gt; 
&lt;p&gt;ingress-nginx is an Ingress controller for Kubernetes using &lt;a href="https://www.nginx.org/"&gt;NGINX&lt;/a&gt; as a reverse proxy and load balancer.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://kubernetes.io/docs/concepts/services-networking/ingress/"&gt;Learn more about Ingress on the Kubernetes documentation site&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Get started&lt;/h2&gt; 
&lt;p&gt;See the &lt;a href="https://kubernetes.github.io/ingress-nginx/deploy/"&gt;Getting Started&lt;/a&gt; document.&lt;/p&gt; 
&lt;p&gt;Do not use in multi-tenant Kubernetes production installations. This project assumes that users that can create Ingress objects are administrators of the cluster. See the &lt;a href="https://kubernetes.github.io/ingress-nginx/faq/#faq"&gt;FAQ&lt;/a&gt; for more.&lt;/p&gt; 
&lt;h2&gt;Troubleshooting&lt;/h2&gt; 
&lt;p&gt;If you encounter issues, review the &lt;a href="https://raw.githubusercontent.com/kubernetes/ingress-nginx/main/docs/troubleshooting.md"&gt;troubleshooting docs&lt;/a&gt;, &lt;a href="https://github.com/kubernetes/ingress-nginx/issues"&gt;file an issue&lt;/a&gt;, or talk to us on the &lt;a href="https://kubernetes.slack.com/messages/ingress-nginx"&gt;#ingress-nginx channel&lt;/a&gt; on the Kubernetes Slack server.&lt;/p&gt; 
&lt;h2&gt;Changelog&lt;/h2&gt; 
&lt;p&gt;See &lt;a href="https://github.com/kubernetes/ingress-nginx/releases"&gt;the list of releases&lt;/a&gt; for all changes. For detailed changes for each release, please check the &lt;a href="https://raw.githubusercontent.com/kubernetes/ingress-nginx/main/changelog"&gt;changelog-$version.md&lt;/a&gt; file for the release version. For detailed changes on the &lt;code&gt;ingress-nginx&lt;/code&gt; helm chart, please check the changelog folder for a specific version. &lt;a href="https://raw.githubusercontent.com/kubernetes/ingress-nginx/main/charts/ingress-nginx/changelog"&gt;CHANGELOG-$current-version.md&lt;/a&gt; file.&lt;/p&gt; 
&lt;h3&gt;Supported Versions table&lt;/h3&gt; 
&lt;p&gt;Supported versions for the ingress-nginx project mean that we have completed E2E tests, and they are passing for the versions listed. Ingress-Nginx versions &lt;strong&gt;may&lt;/strong&gt; work on older versions, but the project does not make that guarantee.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="center"&gt;Supported&lt;/th&gt; 
   &lt;th&gt;Ingress-NGINX version&lt;/th&gt; 
   &lt;th&gt;k8s supported version&lt;/th&gt; 
   &lt;th&gt;Alpine Version&lt;/th&gt; 
   &lt;th&gt;Nginx Version&lt;/th&gt; 
   &lt;th&gt;Helm Chart Version&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;🔄&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;v1.13.3&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;1.33, 1.32, 1.31, 1.30, 1.29&lt;/td&gt; 
   &lt;td&gt;3.22.1&lt;/td&gt; 
   &lt;td&gt;1.27.1&lt;/td&gt; 
   &lt;td&gt;4.13.3&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;🔄&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;v1.13.2&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;1.33, 1.32, 1.31, 1.30, 1.29&lt;/td&gt; 
   &lt;td&gt;3.22.1&lt;/td&gt; 
   &lt;td&gt;1.27.1&lt;/td&gt; 
   &lt;td&gt;4.13.2&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;🔄&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;v1.13.1&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;1.33, 1.32, 1.31, 1.30, 1.29&lt;/td&gt; 
   &lt;td&gt;3.22.1&lt;/td&gt; 
   &lt;td&gt;1.27.1&lt;/td&gt; 
   &lt;td&gt;4.13.1&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;🔄&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;v1.13.0&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;1.33, 1.32, 1.31, 1.30, 1.29&lt;/td&gt; 
   &lt;td&gt;3.22.0&lt;/td&gt; 
   &lt;td&gt;1.27.1&lt;/td&gt; 
   &lt;td&gt;4.13.0&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;🔄&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;v1.12.7&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;1.32, 1.31, 1.30, 1.29, 1.28&lt;/td&gt; 
   &lt;td&gt;3.22.1&lt;/td&gt; 
   &lt;td&gt;1.25.5&lt;/td&gt; 
   &lt;td&gt;4.12.7&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;🔄&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;v1.12.6&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;1.32, 1.31, 1.30, 1.29, 1.28&lt;/td&gt; 
   &lt;td&gt;3.22.1&lt;/td&gt; 
   &lt;td&gt;1.25.5&lt;/td&gt; 
   &lt;td&gt;4.12.6&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;🔄&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;v1.12.5&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;1.32, 1.31, 1.30, 1.29, 1.28&lt;/td&gt; 
   &lt;td&gt;3.22.1&lt;/td&gt; 
   &lt;td&gt;1.25.5&lt;/td&gt; 
   &lt;td&gt;4.12.5&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;🔄&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;v1.12.4&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;1.32, 1.31, 1.30, 1.29, 1.28&lt;/td&gt; 
   &lt;td&gt;3.22.0&lt;/td&gt; 
   &lt;td&gt;1.25.5&lt;/td&gt; 
   &lt;td&gt;4.12.4&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;🔄&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;v1.12.3&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;1.32, 1.31, 1.30, 1.29, 1.28&lt;/td&gt; 
   &lt;td&gt;3.21.3&lt;/td&gt; 
   &lt;td&gt;1.25.5&lt;/td&gt; 
   &lt;td&gt;4.12.3&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;🔄&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;v1.12.2&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;1.32, 1.31, 1.30, 1.29, 1.28&lt;/td&gt; 
   &lt;td&gt;3.21.3&lt;/td&gt; 
   &lt;td&gt;1.25.5&lt;/td&gt; 
   &lt;td&gt;4.12.2&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;🔄&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;v1.12.1&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;1.32, 1.31, 1.30, 1.29, 1.28&lt;/td&gt; 
   &lt;td&gt;3.21.3&lt;/td&gt; 
   &lt;td&gt;1.25.5&lt;/td&gt; 
   &lt;td&gt;4.12.1&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;🔄&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;v1.12.0&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;1.32, 1.31, 1.30, 1.29, 1.28&lt;/td&gt; 
   &lt;td&gt;3.21.0&lt;/td&gt; 
   &lt;td&gt;1.25.5&lt;/td&gt; 
   &lt;td&gt;4.12.0&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;🔄&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;v1.12.0-beta.0&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;1.32, 1.31, 1.30, 1.29, 1.28&lt;/td&gt; 
   &lt;td&gt;3.20.3&lt;/td&gt; 
   &lt;td&gt;1.25.5&lt;/td&gt; 
   &lt;td&gt;4.12.0-beta.0&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td&gt;v1.11.8&lt;/td&gt; 
   &lt;td&gt;1.30, 1.29, 1.28, 1.27, 1.26&lt;/td&gt; 
   &lt;td&gt;3.22.0&lt;/td&gt; 
   &lt;td&gt;1.25.5&lt;/td&gt; 
   &lt;td&gt;4.11.8&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td&gt;v1.11.7&lt;/td&gt; 
   &lt;td&gt;1.30, 1.29, 1.28, 1.27, 1.26&lt;/td&gt; 
   &lt;td&gt;3.21.3&lt;/td&gt; 
   &lt;td&gt;1.25.5&lt;/td&gt; 
   &lt;td&gt;4.11.7&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td&gt;v1.11.6&lt;/td&gt; 
   &lt;td&gt;1.30, 1.29, 1.28, 1.27, 1.26&lt;/td&gt; 
   &lt;td&gt;3.21.3&lt;/td&gt; 
   &lt;td&gt;1.25.5&lt;/td&gt; 
   &lt;td&gt;4.11.6&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td&gt;v1.11.5&lt;/td&gt; 
   &lt;td&gt;1.30, 1.29, 1.28, 1.27, 1.26&lt;/td&gt; 
   &lt;td&gt;3.21.3&lt;/td&gt; 
   &lt;td&gt;1.25.5&lt;/td&gt; 
   &lt;td&gt;4.11.5&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td&gt;v1.11.4&lt;/td&gt; 
   &lt;td&gt;1.30, 1.29, 1.28, 1.27, 1.26&lt;/td&gt; 
   &lt;td&gt;3.21.0&lt;/td&gt; 
   &lt;td&gt;1.25.5&lt;/td&gt; 
   &lt;td&gt;4.11.4&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td&gt;v1.11.3&lt;/td&gt; 
   &lt;td&gt;1.30, 1.29, 1.28, 1.27, 1.26&lt;/td&gt; 
   &lt;td&gt;3.20.3&lt;/td&gt; 
   &lt;td&gt;1.25.5&lt;/td&gt; 
   &lt;td&gt;4.11.3&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td&gt;v1.11.2&lt;/td&gt; 
   &lt;td&gt;1.30, 1.29, 1.28, 1.27, 1.26&lt;/td&gt; 
   &lt;td&gt;3.20.0&lt;/td&gt; 
   &lt;td&gt;1.25.5&lt;/td&gt; 
   &lt;td&gt;4.11.2&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td&gt;v1.11.1&lt;/td&gt; 
   &lt;td&gt;1.30, 1.29, 1.28, 1.27, 1.26&lt;/td&gt; 
   &lt;td&gt;3.20.0&lt;/td&gt; 
   &lt;td&gt;1.25.5&lt;/td&gt; 
   &lt;td&gt;4.11.1&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td&gt;v1.11.0&lt;/td&gt; 
   &lt;td&gt;1.30, 1.29, 1.28, 1.27, 1.26&lt;/td&gt; 
   &lt;td&gt;3.20.0&lt;/td&gt; 
   &lt;td&gt;1.25.5&lt;/td&gt; 
   &lt;td&gt;4.11.0&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td&gt;v1.10.6&lt;/td&gt; 
   &lt;td&gt;1.30, 1.29, 1.28, 1.27, 1.26&lt;/td&gt; 
   &lt;td&gt;3.21.0&lt;/td&gt; 
   &lt;td&gt;1.25.5&lt;/td&gt; 
   &lt;td&gt;4.10.6&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td&gt;v1.10.5&lt;/td&gt; 
   &lt;td&gt;1.30, 1.29, 1.28, 1.27, 1.26&lt;/td&gt; 
   &lt;td&gt;3.20.3&lt;/td&gt; 
   &lt;td&gt;1.25.5&lt;/td&gt; 
   &lt;td&gt;4.10.5&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td&gt;v1.10.4&lt;/td&gt; 
   &lt;td&gt;1.30, 1.29, 1.28, 1.27, 1.26&lt;/td&gt; 
   &lt;td&gt;3.20.0&lt;/td&gt; 
   &lt;td&gt;1.25.5&lt;/td&gt; 
   &lt;td&gt;4.10.4&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td&gt;v1.10.3&lt;/td&gt; 
   &lt;td&gt;1.30, 1.29, 1.28, 1.27, 1.26&lt;/td&gt; 
   &lt;td&gt;3.20.0&lt;/td&gt; 
   &lt;td&gt;1.25.5&lt;/td&gt; 
   &lt;td&gt;4.10.3&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td&gt;v1.10.2&lt;/td&gt; 
   &lt;td&gt;1.30, 1.29, 1.28, 1.27, 1.26&lt;/td&gt; 
   &lt;td&gt;3.20.0&lt;/td&gt; 
   &lt;td&gt;1.25.5&lt;/td&gt; 
   &lt;td&gt;4.10.2&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td&gt;v1.10.1&lt;/td&gt; 
   &lt;td&gt;1.30, 1.29, 1.28, 1.27, 1.26&lt;/td&gt; 
   &lt;td&gt;3.19.1&lt;/td&gt; 
   &lt;td&gt;1.25.3&lt;/td&gt; 
   &lt;td&gt;4.10.1&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td&gt;v1.10.0&lt;/td&gt; 
   &lt;td&gt;1.29, 1.28, 1.27, 1.26&lt;/td&gt; 
   &lt;td&gt;3.19.1&lt;/td&gt; 
   &lt;td&gt;1.25.3&lt;/td&gt; 
   &lt;td&gt;4.10.0&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td&gt;v1.9.6&lt;/td&gt; 
   &lt;td&gt;1.29, 1.28, 1.27, 1.26, 1.25&lt;/td&gt; 
   &lt;td&gt;3.19.0&lt;/td&gt; 
   &lt;td&gt;1.21.6&lt;/td&gt; 
   &lt;td&gt;4.9.1&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td&gt;v1.9.5&lt;/td&gt; 
   &lt;td&gt;1.28, 1.27, 1.26, 1.25&lt;/td&gt; 
   &lt;td&gt;3.18.4&lt;/td&gt; 
   &lt;td&gt;1.21.6&lt;/td&gt; 
   &lt;td&gt;4.9.0&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td&gt;v1.9.4&lt;/td&gt; 
   &lt;td&gt;1.28, 1.27, 1.26, 1.25&lt;/td&gt; 
   &lt;td&gt;3.18.4&lt;/td&gt; 
   &lt;td&gt;1.21.6&lt;/td&gt; 
   &lt;td&gt;4.8.3&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td&gt;v1.9.3&lt;/td&gt; 
   &lt;td&gt;1.28, 1.27, 1.26, 1.25&lt;/td&gt; 
   &lt;td&gt;3.18.4&lt;/td&gt; 
   &lt;td&gt;1.21.6&lt;/td&gt; 
   &lt;td&gt;4.8.*&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td&gt;v1.9.1&lt;/td&gt; 
   &lt;td&gt;1.28, 1.27, 1.26, 1.25&lt;/td&gt; 
   &lt;td&gt;3.18.4&lt;/td&gt; 
   &lt;td&gt;1.21.6&lt;/td&gt; 
   &lt;td&gt;4.8.*&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td&gt;v1.9.0&lt;/td&gt; 
   &lt;td&gt;1.28, 1.27, 1.26, 1.25&lt;/td&gt; 
   &lt;td&gt;3.18.2&lt;/td&gt; 
   &lt;td&gt;1.21.6&lt;/td&gt; 
   &lt;td&gt;4.8.*&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td&gt;v1.8.4&lt;/td&gt; 
   &lt;td&gt;1.27, 1.26, 1.25, 1.24&lt;/td&gt; 
   &lt;td&gt;3.18.2&lt;/td&gt; 
   &lt;td&gt;1.21.6&lt;/td&gt; 
   &lt;td&gt;4.7.*&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td&gt;v1.7.1&lt;/td&gt; 
   &lt;td&gt;1.27, 1.26, 1.25, 1.24&lt;/td&gt; 
   &lt;td&gt;3.17.2&lt;/td&gt; 
   &lt;td&gt;1.21.6&lt;/td&gt; 
   &lt;td&gt;4.6.*&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td&gt;v1.6.4&lt;/td&gt; 
   &lt;td&gt;1.26, 1.25, 1.24, 1.23&lt;/td&gt; 
   &lt;td&gt;3.17.0&lt;/td&gt; 
   &lt;td&gt;1.21.6&lt;/td&gt; 
   &lt;td&gt;4.5.*&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td&gt;v1.5.1&lt;/td&gt; 
   &lt;td&gt;1.25, 1.24, 1.23&lt;/td&gt; 
   &lt;td&gt;3.16.2&lt;/td&gt; 
   &lt;td&gt;1.21.6&lt;/td&gt; 
   &lt;td&gt;4.4.*&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td&gt;v1.4.0&lt;/td&gt; 
   &lt;td&gt;1.25, 1.24, 1.23, 1.22&lt;/td&gt; 
   &lt;td&gt;3.16.2&lt;/td&gt; 
   &lt;td&gt;1.19.10†&lt;/td&gt; 
   &lt;td&gt;4.3.0&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td&gt;v1.3.1&lt;/td&gt; 
   &lt;td&gt;1.24, 1.23, 1.22, 1.21, 1.20&lt;/td&gt; 
   &lt;td&gt;3.16.2&lt;/td&gt; 
   &lt;td&gt;1.19.10†&lt;/td&gt; 
   &lt;td&gt;4.2.5&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;See &lt;a href="https://kubernetes.io/blog/2021/07/26/update-with-ingress-nginx/"&gt;this article&lt;/a&gt; if you want upgrade to the stable Ingress API.&lt;/p&gt; 
&lt;h2&gt;Get Involved&lt;/h2&gt; 
&lt;p&gt;Thanks for taking the time to join our community and start contributing!&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;This project adheres to the &lt;a href="https://git.k8s.io/community/code-of-conduct.md"&gt;Kubernetes Community Code of Conduct&lt;/a&gt;. By participating in this project, you agree to abide by its terms.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Contributing&lt;/strong&gt;: Contributions of all kinds are welcome!&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Read &lt;a href="https://raw.githubusercontent.com/kubernetes/ingress-nginx/main/CONTRIBUTING.md"&gt;&lt;code&gt;CONTRIBUTING.md&lt;/code&gt;&lt;/a&gt; for information about setting up your environment, the workflow that we expect, and instructions on the developer certificate of origin that we require.&lt;/li&gt; 
   &lt;li&gt;Join our Kubernetes Slack channel for developer discussion : &lt;a href="https://kubernetes.slack.com/archives/C021E147ZA4"&gt;#ingress-nginx-dev&lt;/a&gt;.&lt;/li&gt; 
   &lt;li&gt;Submit GitHub issues for any feature enhancements, bugs, or documentation problems. 
    &lt;ul&gt; 
     &lt;li&gt;Please make sure to read the &lt;a href="https://github.com/kubernetes/ingress-nginx/raw/main/CONTRIBUTING.md#issue-reporting-guidelines"&gt;Issue Reporting Checklist&lt;/a&gt; before opening an issue. Issues not conforming to the guidelines &lt;strong&gt;may be closed immediately&lt;/strong&gt;.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;Join our &lt;a href="https://groups.google.com/a/kubernetes.io/g/ingress-nginx-dev/c/ebbBMo-zX-w"&gt;ingress-nginx-dev mailing list&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Support&lt;/strong&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Join the &lt;a href="https://kubernetes.slack.com/messages/CANQGM8BA/"&gt;#ingress-nginx-users&lt;/a&gt; channel inside the &lt;a href="http://slack.kubernetes.io/"&gt;Kubernetes Slack&lt;/a&gt; to ask questions or get support from the maintainers and other users.&lt;/li&gt; 
   &lt;li&gt;The &lt;a href="https://github.com/kubernetes/ingress-nginx/issues"&gt;GitHub issues&lt;/a&gt; in the repository are &lt;strong&gt;exclusively&lt;/strong&gt; for bug reports and feature requests.&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Discuss&lt;/strong&gt;: Tweet using the &lt;code&gt;#IngressNginx&lt;/code&gt; hashtag or sharing with us &lt;a href="https://twitter.com/IngressNGINX"&gt;@IngressNginx&lt;/a&gt;.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://github.com/kubernetes/ingress-nginx/raw/main/LICENSE"&gt;Apache License 2.0&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>redis/go-redis</title>
      <link>https://github.com/redis/go-redis</link>
      <description>&lt;p&gt;Redis Go client&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Redis client for Go&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://github.com/redis/go-redis/actions"&gt;&lt;img src="https://github.com/redis/go-redis/actions/workflows/build.yml/badge.svg?sanitize=true" alt="build workflow" /&gt;&lt;/a&gt; &lt;a href="https://pkg.go.dev/github.com/redis/go-redis/v9?tab=doc"&gt;&lt;img src="https://pkg.go.dev/badge/github.com/redis/go-redis/v9" alt="PkgGoDev" /&gt;&lt;/a&gt; &lt;a href="https://redis.uptrace.dev/"&gt;&lt;img src="https://img.shields.io/badge/redis-documentation-informational" alt="Documentation" /&gt;&lt;/a&gt; &lt;a href="https://goreportcard.com/report/github.com/redis/go-redis/v9"&gt;&lt;img src="https://goreportcard.com/badge/github.com/redis/go-redis/v9" alt="Go Report Card" /&gt;&lt;/a&gt; &lt;a href="https://codecov.io/github/redis/go-redis"&gt;&lt;img src="https://codecov.io/github/redis/go-redis/graph/badge.svg?token=tsrCZKuSSw" alt="codecov" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://discord.gg/W4txy5AeKM"&gt;&lt;img src="https://img.shields.io/discord/697882427875393627.svg?style=social&amp;amp;logo=discord" alt="Discord" /&gt;&lt;/a&gt; &lt;a href="https://www.twitch.tv/redisinc"&gt;&lt;img src="https://img.shields.io/twitch/status/redisinc?style=social" alt="Twitch" /&gt;&lt;/a&gt; &lt;a href="https://www.youtube.com/redisinc"&gt;&lt;img src="https://img.shields.io/youtube/channel/views/UCD78lHSwYqMlyetR0_P4Vig?style=social" alt="YouTube" /&gt;&lt;/a&gt; &lt;a href="https://twitter.com/redisinc"&gt;&lt;img src="https://img.shields.io/twitter/follow/redisinc?style=social" alt="Twitter" /&gt;&lt;/a&gt; &lt;a href="https://stackoverflow.com/questions/tagged/go-redis"&gt;&lt;img src="https://img.shields.io/stackexchange/stackoverflow/t/go-redis?style=social&amp;amp;logo=stackoverflow&amp;amp;label=Stackoverflow" alt="Stack Exchange questions" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;go-redis is the official Redis client library for the Go programming language. It offers a straightforward interface for interacting with Redis servers.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Supported versions&lt;/h2&gt; 
&lt;p&gt;In &lt;code&gt;go-redis&lt;/code&gt; we are aiming to support the last three releases of Redis. Currently, this means we do support:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/redis/redis/7.2/00-RELEASENOTES"&gt;Redis 7.2&lt;/a&gt; - using Redis Stack 7.2 for modules support&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/redis/redis/7.4/00-RELEASENOTES"&gt;Redis 7.4&lt;/a&gt; - using Redis Stack 7.4 for modules support&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/redis/redis/8.0/00-RELEASENOTES"&gt;Redis 8.0&lt;/a&gt; - using Redis CE 8.0 where modules are included&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/redis/redis/8.2/00-RELEASENOTES"&gt;Redis 8.2&lt;/a&gt; - using Redis CE 8.2 where modules are included&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Although the &lt;code&gt;go.mod&lt;/code&gt; states it requires at minimum &lt;code&gt;go 1.18&lt;/code&gt;, our CI is configured to run the tests against all three versions of Redis and latest two versions of Go (&lt;a href="https://go.dev/doc/devel/release#go1.23.0"&gt;1.23&lt;/a&gt;, &lt;a href="https://go.dev/doc/devel/release#go1.24.0"&gt;1.24&lt;/a&gt;). We observe that some modules related test may not pass with Redis Stack 7.2 and some commands are changed with Redis CE 8.0. Please do refer to the documentation and the tests if you experience any issues. We do plan to update the go version in the &lt;code&gt;go.mod&lt;/code&gt; to &lt;code&gt;go 1.24&lt;/code&gt; in one of the next releases.&lt;/p&gt; 
&lt;h2&gt;How do I Redis?&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://university.redis.com/"&gt;Learn for free at Redis University&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://launchpad.redis.com/"&gt;Build faster with the Redis Launchpad&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://redis.com/try-free/"&gt;Try the Redis Cloud&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://developer.redis.com/"&gt;Dive in developer tutorials&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://redis.com/community/"&gt;Join the Redis community&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://redis.com/company/careers/jobs/"&gt;Work at Redis&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://redis.uptrace.dev"&gt;English&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://redis.uptrace.dev/zh/"&gt;简体中文&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Resources&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/redis/go-redis/discussions"&gt;Discussions&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://discord.gg/W4txy5AeKM"&gt;Chat&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pkg.go.dev/github.com/redis/go-redis/v9"&gt;Reference&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pkg.go.dev/github.com/redis/go-redis/v9#pkg-examples"&gt;Examples&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Ecosystem&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/go-redis/redismock"&gt;Redis Mock&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/bsm/redislock"&gt;Distributed Locks&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/go-redis/cache"&gt;Redis Cache&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/go-redis/redis_rate"&gt;Rate limiting&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;This client also works with &lt;a href="https://github.com/apache/incubator-kvrocks"&gt;Kvrocks&lt;/a&gt;, a distributed key value NoSQL database that uses RocksDB as storage engine and is compatible with Redis protocol.&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Redis commands except QUIT and SYNC.&lt;/li&gt; 
 &lt;li&gt;Automatic connection pooling.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/redis/go-redis/master/#1-streaming-credentials-provider-highest-priority"&gt;StreamingCredentialsProvider (e.g. entra id, oauth)&lt;/a&gt; (experimental)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://redis.uptrace.dev/guide/go-redis-pubsub.html"&gt;Pub/Sub&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://redis.uptrace.dev/guide/go-redis-pipelines.html"&gt;Pipelines and transactions&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://redis.uptrace.dev/guide/lua-scripting.html"&gt;Scripting&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://redis.uptrace.dev/guide/go-redis-sentinel.html"&gt;Redis Sentinel&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://redis.uptrace.dev/guide/go-redis-cluster.html"&gt;Redis Cluster&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://redis.uptrace.dev/guide/ring.html"&gt;Redis Ring&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://redis.uptrace.dev/guide/redis-performance-monitoring.html"&gt;Redis Performance Monitoring&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://redis.io/docs/data-types/probabilistic/"&gt;Redis Probabilistic [RedisStack]&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/redis/go-redis/master/#custom-buffer-sizes"&gt;Customizable read and write buffers size.&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;go-redis supports 2 last Go versions and requires a Go version with &lt;a href="https://github.com/golang/go/wiki/Modules"&gt;modules&lt;/a&gt; support. So make sure to initialize a Go module:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;go mod init github.com/my/repo
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then install go-redis/&lt;strong&gt;v9&lt;/strong&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;go get github.com/redis/go-redis/v9
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Quickstart&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;import (
    "context"
    "fmt"

    "github.com/redis/go-redis/v9"
)

var ctx = context.Background()

func ExampleClient() {
    rdb := redis.NewClient(&amp;amp;redis.Options{
        Addr:     "localhost:6379",
        Password: "", // no password set
        DB:       0,  // use default DB
    })

    err := rdb.Set(ctx, "key", "value", 0).Err()
    if err != nil {
        panic(err)
    }

    val, err := rdb.Get(ctx, "key").Result()
    if err != nil {
        panic(err)
    }
    fmt.Println("key", val)

    val2, err := rdb.Get(ctx, "key2").Result()
    if err == redis.Nil {
        fmt.Println("key2 does not exist")
    } else if err != nil {
        panic(err)
    } else {
        fmt.Println("key2", val2)
    }
    // Output: key value
    // key2 does not exist
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Authentication&lt;/h3&gt; 
&lt;p&gt;The Redis client supports multiple ways to provide authentication credentials, with a clear priority order. Here are the available options:&lt;/p&gt; 
&lt;h4&gt;1. Streaming Credentials Provider (Highest Priority) - Experimental feature&lt;/h4&gt; 
&lt;p&gt;The streaming credentials provider allows for dynamic credential updates during the connection lifetime. This is particularly useful for managed identity services and token-based authentication.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;type StreamingCredentialsProvider interface {
    Subscribe(listener CredentialsListener) (Credentials, UnsubscribeFunc, error)
}

type CredentialsListener interface {
    OnNext(credentials Credentials)  // Called when credentials are updated
    OnError(err error)              // Called when an error occurs
}

type Credentials interface {
    BasicAuth() (username string, password string)
    RawCredentials() string
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Example usage:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;rdb := redis.NewClient(&amp;amp;redis.Options{
    Addr: "localhost:6379",
    StreamingCredentialsProvider: &amp;amp;MyCredentialsProvider{},
})
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; The streaming credentials provider can be used with &lt;a href="https://github.com/redis/go-redis-entraid"&gt;go-redis-entraid&lt;/a&gt; to enable Entra ID (formerly Azure AD) authentication. This allows for seamless integration with Azure's managed identity services and token-based authentication.&lt;/p&gt; 
&lt;p&gt;Example with Entra ID:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;import (
    "github.com/redis/go-redis/v9"
    "github.com/redis/go-redis-entraid"
)

// Create an Entra ID credentials provider
provider := entraid.NewDefaultAzureIdentityProvider()

// Configure Redis client with Entra ID authentication
rdb := redis.NewClient(&amp;amp;redis.Options{
    Addr: "your-redis-server.redis.cache.windows.net:6380",
    StreamingCredentialsProvider: provider,
    TLSConfig: &amp;amp;tls.Config{
        MinVersion: tls.VersionTLS12,
    },
})
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;2. Context-based Credentials Provider&lt;/h4&gt; 
&lt;p&gt;The context-based provider allows credentials to be determined at the time of each operation, using the context.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;rdb := redis.NewClient(&amp;amp;redis.Options{
    Addr: "localhost:6379",
    CredentialsProviderContext: func(ctx context.Context) (string, string, error) {
        // Return username, password, and any error
        return "user", "pass", nil
    },
})
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;3. Regular Credentials Provider&lt;/h4&gt; 
&lt;p&gt;A simple function-based provider that returns static credentials.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;rdb := redis.NewClient(&amp;amp;redis.Options{
    Addr: "localhost:6379",
    CredentialsProvider: func() (string, string) {
        // Return username and password
        return "user", "pass"
    },
})
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;4. Username/Password Fields (Lowest Priority)&lt;/h4&gt; 
&lt;p&gt;The most basic way to provide credentials is through the &lt;code&gt;Username&lt;/code&gt; and &lt;code&gt;Password&lt;/code&gt; fields in the options.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;rdb := redis.NewClient(&amp;amp;redis.Options{
    Addr:     "localhost:6379",
    Username: "user",
    Password: "pass",
})
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Priority Order&lt;/h4&gt; 
&lt;p&gt;The client will use credentials in the following priority order:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Streaming Credentials Provider (if set)&lt;/li&gt; 
 &lt;li&gt;Context-based Credentials Provider (if set)&lt;/li&gt; 
 &lt;li&gt;Regular Credentials Provider (if set)&lt;/li&gt; 
 &lt;li&gt;Username/Password fields (if set)&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;If none of these are set, the client will attempt to connect without authentication.&lt;/p&gt; 
&lt;h3&gt;Protocol Version&lt;/h3&gt; 
&lt;p&gt;The client supports both RESP2 and RESP3 protocols. You can specify the protocol version in the options:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;rdb := redis.NewClient(&amp;amp;redis.Options{
    Addr:     "localhost:6379",
    Password: "", // no password set
    DB:       0,  // use default DB
    Protocol: 3,  // specify 2 for RESP 2 or 3 for RESP 3
})
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Connecting via a redis url&lt;/h3&gt; 
&lt;p&gt;go-redis also supports connecting via the &lt;a href="https://github.com/redis/redis-specifications/tree/master/uri/redis.txt"&gt;redis uri specification&lt;/a&gt;. The example below demonstrates how the connection can easily be configured using a string, adhering to this specification.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;import (
    "github.com/redis/go-redis/v9"
)

func ExampleClient() *redis.Client {
    url := "redis://user:password@localhost:6379/0?protocol=3"
    opts, err := redis.ParseURL(url)
    if err != nil {
        panic(err)
    }

    return redis.NewClient(opts)
}

&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Instrument with OpenTelemetry&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;import (
    "github.com/redis/go-redis/v9"
    "github.com/redis/go-redis/extra/redisotel/v9"
    "errors"
)

func main() {
    ...
    rdb := redis.NewClient(&amp;amp;redis.Options{...})

    if err := errors.Join(redisotel.InstrumentTracing(rdb), redisotel.InstrumentMetrics(rdb)); err != nil {
        log.Fatal(err)
    }
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Buffer Size Configuration&lt;/h3&gt; 
&lt;p&gt;go-redis uses 32KiB read and write buffers by default for optimal performance. For high-throughput applications or large pipelines, you can customize buffer sizes:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;rdb := redis.NewClient(&amp;amp;redis.Options{
    Addr:            "localhost:6379",
    ReadBufferSize:  1024 * 1024, // 1MiB read buffer
    WriteBufferSize: 1024 * 1024, // 1MiB write buffer
})
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Advanced Configuration&lt;/h3&gt; 
&lt;p&gt;go-redis supports extending the client identification phase to allow projects to send their own custom client identification.&lt;/p&gt; 
&lt;h4&gt;Default Client Identification&lt;/h4&gt; 
&lt;p&gt;By default, go-redis automatically sends the client library name and version during the connection process. This feature is available in redis-server as of version 7.2. As a result, the command is "fire and forget", meaning it should fail silently, in the case that the redis server does not support this feature.&lt;/p&gt; 
&lt;h4&gt;Disabling Identity Verification&lt;/h4&gt; 
&lt;p&gt;When connection identity verification is not required or needs to be explicitly disabled, a &lt;code&gt;DisableIdentity&lt;/code&gt; configuration option exists. Initially there was a typo and the option was named &lt;code&gt;DisableIndentity&lt;/code&gt; instead of &lt;code&gt;DisableIdentity&lt;/code&gt;. The misspelled option is marked as Deprecated and will be removed in V10 of this library. Although both options will work at the moment, the correct option is &lt;code&gt;DisableIdentity&lt;/code&gt;. The deprecated option will be removed in V10 of this library, so please use the correct option name to avoid any issues.&lt;/p&gt; 
&lt;p&gt;To disable verification, set the &lt;code&gt;DisableIdentity&lt;/code&gt; option to &lt;code&gt;true&lt;/code&gt; in the Redis client options:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;rdb := redis.NewClient(&amp;amp;redis.Options{
    Addr:            "localhost:6379",
    Password:        "",
    DB:              0,
    DisableIdentity: true, // Disable set-info on connect
})
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Unstable RESP3 Structures for RediSearch Commands&lt;/h4&gt; 
&lt;p&gt;When integrating Redis with application functionalities using RESP3, it's important to note that some response structures aren't final yet. This is especially true for more complex structures like search and query results. We recommend using RESP2 when using the search and query capabilities, but we plan to stabilize the RESP3-based API-s in the coming versions. You can find more guidance in the upcoming release notes.&lt;/p&gt; 
&lt;p&gt;To enable unstable RESP3, set the option in your client configuration:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;redis.NewClient(&amp;amp;redis.Options{
			UnstableResp3: true,
		})
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; When UnstableResp3 mode is enabled, it's necessary to use RawResult() and RawVal() to retrieve a raw data. Since, raw response is the only option for unstable search commands Val() and Result() calls wouldn't have any affect on them:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;res1, err := client.FTSearchWithArgs(ctx, "txt", "foo bar", &amp;amp;redis.FTSearchOptions{}).RawResult()
val1 := client.FTSearchWithArgs(ctx, "txt", "foo bar", &amp;amp;redis.FTSearchOptions{}).RawVal()
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Redis-Search Default Dialect&lt;/h4&gt; 
&lt;p&gt;In the Redis-Search module, &lt;strong&gt;the default dialect is 2&lt;/strong&gt;. If needed, you can explicitly specify a different dialect using the appropriate configuration in your queries.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Important&lt;/strong&gt;: Be aware that the query dialect may impact the results returned. If needed, you can revert to a different dialect version by passing the desired dialect in the arguments of the command you want to execute. For example:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;	res2, err := rdb.FTSearchWithArgs(ctx,
		"idx:bicycle",
		"@pickup_zone:[CONTAINS $bike]",
		&amp;amp;redis.FTSearchOptions{
			Params: map[string]interface{}{
				"bike": "POINT(-0.1278 51.5074)",
			},
			DialectVersion: 3,
		},
	).Result()
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can find further details in the &lt;a href="https://redis.io/docs/latest/develop/interact/search-and-query/advanced-concepts/dialects/"&gt;query dialect documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h4&gt;Custom buffer sizes&lt;/h4&gt; 
&lt;p&gt;Prior to v9.12, the buffer size was the default go value of 4096 bytes. Starting from v9.12, go-redis uses 32KiB read and write buffers by default for optimal performance. For high-throughput applications or large pipelines, you can customize buffer sizes:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;rdb := redis.NewClient(&amp;amp;redis.Options{
    Addr:            "localhost:6379",
    ReadBufferSize:  1024 * 1024, // 1MiB read buffer
    WriteBufferSize: 1024 * 1024, // 1MiB write buffer
})
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Important&lt;/strong&gt;: If you experience any issues with the default buffer sizes, please try setting them to the go default of 4096 bytes.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome contributions to the go-redis library! If you have a bug fix, feature request, or improvement, please open an issue or pull request on GitHub. We appreciate your help in making go-redis better for everyone. If you are interested in contributing to the go-redis library, please check out our &lt;a href="https://raw.githubusercontent.com/redis/go-redis/master/CONTRIBUTING.md"&gt;contributing guidelines&lt;/a&gt; for more information on how to get started.&lt;/p&gt; 
&lt;h2&gt;Look and feel&lt;/h2&gt; 
&lt;p&gt;Some corner cases:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;// SET key value EX 10 NX
set, err := rdb.SetNX(ctx, "key", "value", 10*time.Second).Result()

// SET key value keepttl NX
set, err := rdb.SetNX(ctx, "key", "value", redis.KeepTTL).Result()

// SORT list LIMIT 0 2 ASC
vals, err := rdb.Sort(ctx, "list", &amp;amp;redis.Sort{Offset: 0, Count: 2, Order: "ASC"}).Result()

// ZRANGEBYSCORE zset -inf +inf WITHSCORES LIMIT 0 2
vals, err := rdb.ZRangeByScoreWithScores(ctx, "zset", &amp;amp;redis.ZRangeBy{
    Min: "-inf",
    Max: "+inf",
    Offset: 0,
    Count: 2,
}).Result()

// ZINTERSTORE out 2 zset1 zset2 WEIGHTS 2 3 AGGREGATE SUM
vals, err := rdb.ZInterStore(ctx, "out", &amp;amp;redis.ZStore{
    Keys: []string{"zset1", "zset2"},
    Weights: []int64{2, 3}
}).Result()

// EVAL "return {KEYS[1],ARGV[1]}" 1 "key" "hello"
vals, err := rdb.Eval(ctx, "return {KEYS[1],ARGV[1]}", []string{"key"}, "hello").Result()

// custom command
res, err := rdb.Do(ctx, "set", "key", "value").Result()
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Run the test&lt;/h2&gt; 
&lt;p&gt;Recommended to use Docker, just need to run:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;make test
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;See also&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://bun.uptrace.dev"&gt;Golang ORM&lt;/a&gt; for PostgreSQL, MySQL, MSSQL, and SQLite&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://bun.uptrace.dev/postgres/"&gt;Golang PostgreSQL&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://bunrouter.uptrace.dev/"&gt;Golang HTTP router&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/uptrace/go-clickhouse"&gt;Golang ClickHouse ORM&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributors&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;The go-redis project was originally initiated by &lt;span&gt;⭐&lt;/span&gt; &lt;a href="https://github.com/uptrace/uptrace"&gt;&lt;strong&gt;uptrace/uptrace&lt;/strong&gt;&lt;/a&gt;. Uptrace is an open-source APM tool that supports distributed tracing, metrics, and logs. You can use it to monitor applications and set up automatic alerts to receive notifications via email, Slack, Telegram, and others.&lt;/p&gt; 
 &lt;p&gt;See &lt;a href="https://github.com/redis/go-redis/tree/master/example/otel"&gt;OpenTelemetry&lt;/a&gt; example which demonstrates how you can use Uptrace to monitor go-redis.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Thanks to all the people who already contributed!&lt;/p&gt; 
&lt;a href="https://github.com/redis/go-redis/graphs/contributors"&gt; &lt;img src="https://contributors-img.web.app/image?repo=redis/go-redis" /&gt; &lt;/a&gt;</description>
    </item>
    
    <item>
      <title>rcourtman/Pulse</title>
      <link>https://github.com/rcourtman/Pulse</link>
      <description>&lt;p&gt;A responsive monitoring platform for Proxmox VE, PBS, and Docker with real-time metrics across nodes and containers&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Pulse&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://github.com/rcourtman/Pulse/releases/latest"&gt;&lt;img src="https://img.shields.io/github/v/release/rcourtman/Pulse" alt="GitHub release" /&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/r/rcourtman/pulse"&gt;&lt;img src="https://img.shields.io/docker/pulls/rcourtman/pulse" alt="Docker Pulls" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/rcourtman/Pulse/main/LICENSE"&gt;&lt;img src="https://img.shields.io/github/license/rcourtman/Pulse" alt="License" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Real-time monitoring for Proxmox VE, Proxmox Mail Gateway, PBS, and Docker infrastructure with alerts and webhooks.&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Monitor your hybrid Proxmox and Docker estate from a single dashboard. Get instant alerts when nodes go down, containers misbehave, backups fail, or storage fills up. Supports email, Discord, Slack, Telegram, and more.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://demo.pulserelay.pro"&gt;Try the live demo →&lt;/a&gt;&lt;/strong&gt; (read-only with mock data)&lt;/p&gt; 
&lt;img width="2872" height="1502" alt="image" src="https://github.com/user-attachments/assets/41ac125c-59e3-4bdc-bfd2-e300109aa1f7" /&gt; 
&lt;h2&gt;Support Pulse Development&lt;/h2&gt; 
&lt;p&gt;Pulse is built by a solo developer in evenings and weekends. Your support helps:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Keep me motivated to add new features&lt;/li&gt; 
 &lt;li&gt;Prioritize bug fixes and user requests&lt;/li&gt; 
 &lt;li&gt;Ensure Pulse stays 100% free and open-source forever&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://github.com/sponsors/rcourtman"&gt;&lt;img src="https://img.shields.io/github/sponsors/rcourtman?style=social&amp;amp;label=Sponsor" alt="GitHub Sponsors" /&gt;&lt;/a&gt; &lt;a href="https://ko-fi.com/rcourtman"&gt;&lt;img src="https://ko-fi.com/img/githubbutton_sm.svg?sanitize=true" alt="ko-fi" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Not ready to sponsor?&lt;/strong&gt; Star the project or share it with your homelab community!&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Auto-Discovery&lt;/strong&gt;: Finds Proxmox nodes on your network, one-liner setup via generated scripts&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Cluster Support&lt;/strong&gt;: Configure one node, monitor entire cluster&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Enterprise Security&lt;/strong&gt;: 
  &lt;ul&gt; 
   &lt;li&gt;Credentials encrypted at rest, masked in logs, never sent to frontend&lt;/li&gt; 
   &lt;li&gt;CSRF protection for all state-changing operations&lt;/li&gt; 
   &lt;li&gt;Rate limiting (500 req/min general, 10 attempts/min for auth)&lt;/li&gt; 
   &lt;li&gt;Account lockout after failed login attempts&lt;/li&gt; 
   &lt;li&gt;Secure session management with HttpOnly cookies&lt;/li&gt; 
   &lt;li&gt;bcrypt password hashing (cost 12) - passwords NEVER stored in plain text&lt;/li&gt; 
   &lt;li&gt;API tokens stored securely with restricted file permissions&lt;/li&gt; 
   &lt;li&gt;Security headers (CSP, X-Frame-Options, etc.)&lt;/li&gt; 
   &lt;li&gt;Comprehensive audit logging&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Live monitoring of VMs, containers, nodes, storage&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Smart Alerts&lt;/strong&gt;: Email and webhooks (Discord, Slack, Telegram, Teams, ntfy.sh, Gotify) 
  &lt;ul&gt; 
   &lt;li&gt;Example: "VM 'webserver' is down on node 'pve1'"&lt;/li&gt; 
   &lt;li&gt;Example: "Storage 'local-lvm' at 85% capacity"&lt;/li&gt; 
   &lt;li&gt;Example: "VM 'database' is back online"&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Adaptive Thresholds&lt;/strong&gt;: Hysteresis-based trigger/clear levels, fractional network thresholds, per-metric search, reset-to-defaults, and Custom overrides with inline audit trail&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Alert Timeline Analytics&lt;/strong&gt;: Rich history explorer with acknowledgement/clear markers, escalation breadcrumbs, and quick filters for noisy resources&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Ceph Awareness&lt;/strong&gt;: Surface Ceph health, pool utilisation, and daemon status automatically when Proxmox exposes Ceph-backed storage&lt;/li&gt; 
 &lt;li&gt;Unified view of PBS backups, PVE backups, and snapshots&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Interactive Backup Explorer&lt;/strong&gt;: Cross-highlighted bar chart + grid with quick time-range pivots (24h/7d/30d/custom) and contextual tooltips for the busiest jobs&lt;/li&gt; 
 &lt;li&gt;Proxmox Mail Gateway analytics: mail volume, spam/virus trends, quarantine health, and cluster node status&lt;/li&gt; 
 &lt;li&gt;Optional Docker container monitoring via lightweight agent&lt;/li&gt; 
 &lt;li&gt;Config export/import with encryption and authentication&lt;/li&gt; 
 &lt;li&gt;Automatic stable updates with safe rollback (opt-in)&lt;/li&gt; 
 &lt;li&gt;Dark/light themes, responsive design&lt;/li&gt; 
 &lt;li&gt;Built with Go for minimal resource usage&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/SCREENSHOTS.md"&gt;Screenshots →&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Privacy&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Pulse respects your privacy:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;No telemetry or analytics collection&lt;/li&gt; 
 &lt;li&gt;No phone-home functionality&lt;/li&gt; 
 &lt;li&gt;No external API calls (except for configured webhooks)&lt;/li&gt; 
 &lt;li&gt;All data stays on your server&lt;/li&gt; 
 &lt;li&gt;Open source - verify it yourself&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Your infrastructure data is yours alone.&lt;/p&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;h3&gt;Install&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Recommended: Official installer (auto-detects Proxmox and creates container)
curl -fsSL https://raw.githubusercontent.com/rcourtman/Pulse/main/install.sh | bash

# Need to roll back to a previous release? Pass the tag you want
curl -fsSL https://raw.githubusercontent.com/rcourtman/Pulse/main/install.sh | bash -s -- --version v4.20.0

# Alternative: Docker
docker run -d -p 7655:7655 -v pulse_data:/data rcourtman/pulse:latest

# Testing: Install from main branch source (for testing latest fixes)
curl -fsSL https://raw.githubusercontent.com/rcourtman/Pulse/main/install.sh | bash -s -- --source

# Alternative: Kubernetes (Helm)
helm registry login ghcr.io
helm install pulse oci://ghcr.io/rcourtman/pulse-chart \
  --version $(curl -fsSL https://raw.githubusercontent.com/rcourtman/Pulse/main/VERSION) \
  --namespace pulse \
  --create-namespace
# Replace the VERSION lookup with a specific release if you need to pin. For local development, see docs/KUBERNETES.md.
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Proxmox users&lt;/strong&gt;: The installer detects PVE hosts and automatically creates an optimized LXC container. Choose Quick mode for one-minute setup.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/INSTALL.md"&gt;Advanced installation options →&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Updating&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Automatic Updates (New!):&lt;/strong&gt; Enable during installation or via Settings UI to stay current automatically&lt;br /&gt; &lt;strong&gt;Standard Install:&lt;/strong&gt; Re-run the installer&lt;br /&gt; &lt;strong&gt;Docker:&lt;/strong&gt; &lt;code&gt;docker pull rcourtman/pulse:latest&lt;/code&gt; then recreate container&lt;/p&gt; 
&lt;h3&gt;Initial Setup&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Option A: Interactive Setup (UI)&lt;/strong&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Open &lt;code&gt;http://&amp;lt;your-server&amp;gt;:7655&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Complete the mandatory security setup&lt;/strong&gt; (first-time only)&lt;/li&gt; 
 &lt;li&gt;Create your admin username and password&lt;/li&gt; 
 &lt;li&gt;Use &lt;strong&gt;Settings → Security → API tokens&lt;/strong&gt; to mint dedicated tokens for automation (issue one token per integration so you can revoke credentials individually)&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;Option B: Automated Setup (No UI)&lt;/strong&gt; For automated deployments, configure authentication via environment variables:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Start Pulse with auth pre-configured - skips setup screen
API_TOKENS="ansible-token,docker-agent-token" ./pulse

# Or use basic auth
PULSE_AUTH_USER=admin PULSE_AUTH_PASS=password ./pulse

# Plain text credentials are automatically hashed for security
# `API_TOKEN` is still accepted for back-compat, but `API_TOKENS` lets you manage multiple credentials
# You can also provide pre-hashed values if preferred
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/CONFIGURATION.md#automated-setup-skip-ui"&gt;Configuration Guide&lt;/a&gt; for details.&lt;/p&gt; 
&lt;h3&gt;Configure Nodes&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Two authentication methods available:&lt;/strong&gt;&lt;/p&gt; 
&lt;h4&gt;Method 1: Manual Setup (Recommended for interactive use)&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;After login, go to Settings → Nodes&lt;/li&gt; 
 &lt;li&gt;Discovered nodes appear automatically&lt;/li&gt; 
 &lt;li&gt;Click "Setup Script" next to any node&lt;/li&gt; 
 &lt;li&gt;Click "Generate Setup Code" button (creates a 6-character code valid for 5 minutes)&lt;/li&gt; 
 &lt;li&gt;Copy and run the provided one-liner on your Proxmox/PBS host&lt;/li&gt; 
 &lt;li&gt;Node is configured and monitoring starts automatically&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;Example:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -sSL "http://pulse:7655/api/setup-script?type=pve&amp;amp;host=https://pve:8006&amp;amp;auth_token=ABC123" | bash
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Method 2: Automated Setup (For scripts/automation)&lt;/h4&gt; 
&lt;p&gt;Use your permanent API token directly in the URL for automation:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# For Proxmox VE
curl -sSL "http://pulse:7655/api/setup-script?type=pve&amp;amp;host=https://pve:8006&amp;amp;auth_token=YOUR_API_TOKEN" | bash

# For Proxmox Backup Server
curl -sSL "http://pulse:7655/api/setup-script?type=pbs&amp;amp;host=https://pbs:8007&amp;amp;auth_token=YOUR_API_TOKEN" | bash
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Parameters:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;type&lt;/code&gt;: &lt;code&gt;pve&lt;/code&gt; for Proxmox VE, &lt;code&gt;pbs&lt;/code&gt; for Proxmox Backup Server&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;host&lt;/code&gt;: Full URL of your Proxmox/PBS server (e.g., &lt;a href="https://192.168.1.100:8006"&gt;https://192.168.1.100:8006&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;auth_token&lt;/code&gt;: Either a 6-character setup code (expires in 5 min) or your permanent API token&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;backup_perms=true&lt;/code&gt; (optional): Add backup management permissions&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;pulse_url&lt;/code&gt; (optional): Pulse server URL if different from where script is downloaded&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The script handles user creation, permissions, token generation, and registration automatically.&lt;/p&gt; 
&lt;h3&gt;Monitor Docker Containers (optional)&lt;/h3&gt; 
&lt;p&gt;Deploy the lightweight &lt;a href="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/DOCKER_MONITORING.md"&gt;Pulse Docker agent&lt;/a&gt; on any host running Docker to stream container status and resource data back to Pulse. Install the agent alongside your stack, point it at your Pulse URL and API token, and the &lt;strong&gt;Docker&lt;/strong&gt; workspace lights up with host summaries, restart loop detection, per-container CPU/memory charts, and quick filters for stacks and unhealthy workloads.&lt;/p&gt; 
&lt;h2&gt;Docker&lt;/h2&gt; 
&lt;h3&gt;Basic&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run -d \
  --name pulse \
  -p 7655:7655 \
  -v pulse_data:/data \
  --restart unless-stopped \
  rcourtman/pulse:latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Network Discovery&lt;/h3&gt; 
&lt;p&gt;Pulse automatically discovers Proxmox nodes on your network! By default, it scans:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;192.168.0.0/16 (home networks)&lt;/li&gt; 
 &lt;li&gt;10.0.0.0/8 (private networks)&lt;/li&gt; 
 &lt;li&gt;172.16.0.0/12 (Docker/internal networks)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;To scan a custom subnet instead:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run -d \
  --name pulse \
  -p 7655:7655 \
  -v pulse_data:/data \
  -e DISCOVERY_SUBNET="192.168.50.0/24" \
  --restart unless-stopped \
  rcourtman/pulse:latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Automated Deployment&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Deploy with authentication pre-configured
docker run -d \
  --name pulse \
  -p 7655:7655 \
  -v pulse_data:/data \
  -e API_TOKENS="ansible-token,docker-agent-token" \
  -e PULSE_AUTH_USER="admin" \
  -e PULSE_AUTH_PASS="your-password" \
  --restart unless-stopped \
  rcourtman/pulse:latest

# Plain text credentials are automatically hashed for security
# No setup required - API works immediately
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Docker Compose&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;services:
  pulse:
    image: rcourtman/pulse:latest
    container_name: pulse
    ports:
      - "7655:7655"
    volumes:
      - pulse_data:/data
    environment:
      # NOTE: Env vars override UI settings. Remove env var to allow UI configuration.
      
      # Network discovery (usually not needed - auto-scans common networks)
      # - DISCOVERY_SUBNET=192.168.50.0/24  # Only for non-standard networks
      
      # Ports
      # - PORT=7655                         # Backend port (default: 7655)
      # - FRONTEND_PORT=7655                # Frontend port (default: 7655)
      
      # Security (all optional - runs open by default)
      # - PULSE_AUTH_USER=admin             # Username for web UI login
      # - PULSE_AUTH_PASS=your-password     # Plain text or bcrypt hash (auto-hashed if plain)
      # - API_TOKENS=token-a,token-b        # Comma-separated tokens (plain or SHA3-256 hashed)
      # - API_TOKEN=legacy-token            # Optional single-token fallback
      # - ALLOW_UNPROTECTED_EXPORT=false    # Allow export without auth (default: false)
      
      # Security: Plain text credentials are automatically hashed
      # You can provide either:
      # 1. Plain text (auto-hashed): PULSE_AUTH_PASS=mypassword
      # 2. Pre-hashed (advanced): PULSE_AUTH_PASS='$$2a$$12$$...'
      #    Note: Escape $ as $$ in docker-compose.yml for pre-hashed values
      
      # Performance
      # - CONNECTION_TIMEOUT=10             # Connection timeout in seconds (default: 10)
      
      # CORS &amp;amp; logging
      # - ALLOWED_ORIGINS=https://app.example.com  # CORS origins (default: none, same-origin only)
      # - LOG_LEVEL=info                    # Log level: debug/info/warn/error (default: info)
    restart: unless-stopped

volumes:
  pulse_data:
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Security&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Authentication required&lt;/strong&gt; - Protects your Proxmox infrastructure credentials&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Quick setup wizard&lt;/strong&gt; - Secure your installation in under a minute&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Multiple auth methods&lt;/strong&gt;: Password authentication, API tokens, proxy auth (SSO), or combinations&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Proxy/SSO support&lt;/strong&gt; - Integrate with Authentik, Authelia, and other authentication proxies (&lt;a href="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/PROXY_AUTH.md"&gt;docs&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Enterprise-grade protection&lt;/strong&gt;: 
  &lt;ul&gt; 
   &lt;li&gt;Credentials encrypted at rest (AES-256-GCM)&lt;/li&gt; 
   &lt;li&gt;CSRF tokens for state-changing operations&lt;/li&gt; 
   &lt;li&gt;Rate limiting and account lockout protection&lt;/li&gt; 
   &lt;li&gt;Secure session management with HttpOnly cookies&lt;/li&gt; 
   &lt;li&gt;bcrypt password hashing (cost 12) - passwords NEVER stored in plain text&lt;/li&gt; 
   &lt;li&gt;API tokens stored securely with restricted file permissions&lt;/li&gt; 
   &lt;li&gt;Security headers (CSP, X-Frame-Options, etc.)&lt;/li&gt; 
   &lt;li&gt;Comprehensive audit logging&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Security by design&lt;/strong&gt;: 
  &lt;ul&gt; 
   &lt;li&gt;Frontend never receives node credentials&lt;/li&gt; 
   &lt;li&gt;API tokens visible only to authenticated users&lt;/li&gt; 
   &lt;li&gt;Export/import requires authentication when configured&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/SECURITY.md"&gt;Security Documentation&lt;/a&gt; for details.&lt;/p&gt; 
&lt;h2&gt;Updating&lt;/h2&gt; 
&lt;h3&gt;Update Notifications&lt;/h3&gt; 
&lt;p&gt;Pulse checks for updates and displays notifications in the UI when new versions are available. For security reasons, updates must be installed manually using the appropriate method for your deployment.&lt;/p&gt; 
&lt;h3&gt;Manual Installation (systemd)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Update to latest stable
curl -fsSL https://raw.githubusercontent.com/rcourtman/Pulse/main/install.sh | bash

# Update to latest RC/pre-release  
curl -fsSL https://raw.githubusercontent.com/rcourtman/Pulse/main/install.sh | bash -s -- --rc

# Install specific version
curl -fsSL https://raw.githubusercontent.com/rcourtman/Pulse/main/install.sh | bash -s -- --version v4.8.0-rc.1
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Docker Updates&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Latest stable
docker pull rcourtman/pulse:latest

# Latest RC
docker pull rcourtman/pulse:rc

# Specific version
docker pull rcourtman/pulse:v4.8.0-rc.1
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Configuration&lt;/h2&gt; 
&lt;p&gt;Quick start - most settings are in the web UI:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Settings → Nodes&lt;/strong&gt;: Add/remove Proxmox instances&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Settings → System&lt;/strong&gt;: Polling intervals, timeouts, update settings&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Settings → Security&lt;/strong&gt;: Authentication and API tokens&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Alerts&lt;/strong&gt;: Thresholds and notifications&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Apprise Notifications&lt;/h3&gt; 
&lt;p&gt;Pulse can broadcast grouped alerts through &lt;a href="https://github.com/caronc/apprise"&gt;Apprise&lt;/a&gt; using either the local CLI or a remote Apprise API gateway. Configure everything under &lt;strong&gt;Alerts → Notifications → Apprise&lt;/strong&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Local CLI&lt;/strong&gt; – Install Apprise on the Pulse host (for example &lt;code&gt;pip install apprise&lt;/code&gt;) and enter one Apprise URL per line in the delivery targets field. You can override the CLI path and timeout if the executable lives outside of &lt;code&gt;$PATH&lt;/code&gt;. Pulse skips CLI delivery automatically when no targets are configured.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Remote API&lt;/strong&gt; – Point Pulse at an Apprise API server by providing the base URL (such as &lt;code&gt;https://apprise-api.local:8000&lt;/code&gt;). Optionally include a configuration key (for &lt;code&gt;/notify/{key}&lt;/code&gt; routes), an API key header/value pair, and allow self-signed certificates for lab deployments. Targets remain optional in API mode—leave the list empty to let the Apprise server use its stored defaults.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For both modes, delivery targets accept any Apprise URL (Discord, Slack, email, SMS, etc.). The timeout applies to the CLI process or HTTP request respectively.&lt;/p&gt; 
&lt;h3&gt;Configuration Files&lt;/h3&gt; 
&lt;p&gt;Pulse uses three separate configuration files with clear separation of concerns:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;.env&lt;/code&gt; - Authentication credentials only&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;system.json&lt;/code&gt; - Application settings&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;nodes.enc&lt;/code&gt; - Encrypted node credentials&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/CONFIGURATION.md"&gt;docs/CONFIGURATION.md&lt;/a&gt; for detailed documentation on configuration structure and management.&lt;/p&gt; 
&lt;h3&gt;Email Alerts Configuration&lt;/h3&gt; 
&lt;p&gt;Configure email notifications in &lt;strong&gt;Settings → Alerts → Email Destinations&lt;/strong&gt;&lt;/p&gt; 
&lt;h4&gt;Supported Providers&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Gmail/Google Workspace&lt;/strong&gt;: Requires app-specific password&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Outlook/Office 365&lt;/strong&gt;: Requires app-specific password&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Custom SMTP&lt;/strong&gt;: Any SMTP server&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Recommended Settings&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Port 587 with STARTTLS&lt;/strong&gt; (recommended for most providers)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Port 465&lt;/strong&gt; for SSL/TLS&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Port 25&lt;/strong&gt; for unencrypted (not recommended)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Gmail Setup&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;Enable 2-factor authentication&lt;/li&gt; 
 &lt;li&gt;Generate app-specific password at &lt;a href="https://myaccount.google.com/apppasswords"&gt;https://myaccount.google.com/apppasswords&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Use your email as username and app password as password&lt;/li&gt; 
 &lt;li&gt;Server: smtp.gmail.com, Port: 587, Enable STARTTLS&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Outlook Setup&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;Generate app password at &lt;a href="https://account.microsoft.com/security"&gt;https://account.microsoft.com/security&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Use your email as username and app password as password&lt;/li&gt; 
 &lt;li&gt;Server: smtp-mail.outlook.com, Port: 587, Enable STARTTLS&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Alert Configuration&lt;/h3&gt; 
&lt;p&gt;Pulse provides two complementary approaches for managing alerts:&lt;/p&gt; 
&lt;h4&gt;Custom Alert Rules (Permanent Policy)&lt;/h4&gt; 
&lt;p&gt;Configure persistent alert policies in &lt;strong&gt;Settings → Alerts → Custom Rules&lt;/strong&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Define thresholds for specific VMs/containers based on name patterns&lt;/li&gt; 
 &lt;li&gt;Set different thresholds for production vs development environments&lt;/li&gt; 
 &lt;li&gt;Create complex rules with AND/OR logic&lt;/li&gt; 
 &lt;li&gt;Manage all rules through the UI with priority ordering&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Use for:&lt;/strong&gt; Long-term alert policies like "all database VMs should alert at 90%"&lt;/p&gt; 
&lt;h3&gt;HTTPS/TLS Configuration&lt;/h3&gt; 
&lt;p&gt;Enable HTTPS by setting these environment variables:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Systemd (service: pulse; legacy installs may use pulse-backend): sudo systemctl edit pulse
Environment="HTTPS_ENABLED=true"
Environment="TLS_CERT_FILE=/etc/pulse/cert.pem"
Environment="TLS_KEY_FILE=/etc/pulse/key.pem"

# Docker
docker run -d -p 7655:7655 \
  -e HTTPS_ENABLED=true \
  -e TLS_CERT_FILE=/data/cert.pem \
  -e TLS_KEY_FILE=/data/key.pem \
  -v pulse_data:/data \
  -v /path/to/certs:/data/certs:ro \
  rcourtman/pulse:latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For deployment overrides (ports, etc), use environment variables:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Systemd (service: pulse; legacy installs may use pulse-backend): sudo systemctl edit pulse
Environment="FRONTEND_PORT=8080"

# Docker: -e FRONTEND_PORT=8080
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/CONFIGURATION.md"&gt;Full Configuration Guide →&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;h3&gt;Backup/Restore&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Via UI (recommended):&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Settings → Security → Backup &amp;amp; Restore&lt;/li&gt; 
 &lt;li&gt;Export: Choose login password or custom passphrase for encryption&lt;/li&gt; 
 &lt;li&gt;Import: Upload backup file with passphrase&lt;/li&gt; 
 &lt;li&gt;Includes all settings, nodes, and custom console URLs&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Via CLI:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Export (v4.0.3+)
pulse config export -o backup.enc

# Import
pulse config import -i backup.enc
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Updates&lt;/h2&gt; 
&lt;p&gt;Pulse shows when updates are available and provides deployment-specific instructions:&lt;/p&gt; 
&lt;h3&gt;Docker&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker pull rcourtman/pulse:latest
docker stop pulse
docker rm pulse
# Run docker run command again with your settings
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Manual Install&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -fsSL https://raw.githubusercontent.com/rcourtman/Pulse/main/install.sh | bash
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The UI will detect your deployment type and show the appropriate update method when a new version is available.&lt;/p&gt; 
&lt;h2&gt;API&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Status
curl http://localhost:7655/api/health

# Metrics (default time range: 1h)
curl http://localhost:7655/api/charts

# With authentication (if configured)
curl -H "X-API-Token: your-token" http://localhost:7655/api/health
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/API.md"&gt;Full API Documentation →&lt;/a&gt;&lt;/strong&gt; - Complete endpoint reference with examples&lt;/p&gt; 
&lt;h2&gt;Reverse Proxy &amp;amp; SSO&lt;/h2&gt; 
&lt;p&gt;Using Pulse behind a reverse proxy? &lt;strong&gt;WebSocket support is required for real-time updates.&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;NEW: Proxy Authentication Support&lt;/strong&gt; - Integrate with Authentik, Authelia, and other SSO providers. See &lt;a href="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/PROXY_AUTH.md"&gt;Proxy Authentication Guide&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/REVERSE_PROXY.md"&gt;Reverse Proxy Configuration Guide&lt;/a&gt; for nginx, Caddy, Apache, Traefik, HAProxy, and Cloudflare Tunnel configurations.&lt;/p&gt; 
&lt;h2&gt;Troubleshooting&lt;/h2&gt; 
&lt;h3&gt;Authentication Issues&lt;/h3&gt; 
&lt;h4&gt;Cannot login after setting up security&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Docker&lt;/strong&gt;: Ensure bcrypt hash is exactly 60 characters and wrapped in single quotes&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Docker Compose&lt;/strong&gt;: MUST escape $ characters as $$ (e.g., &lt;code&gt;$$2a$$12$$...&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Example (docker run)&lt;/strong&gt;: &lt;code&gt;PULSE_AUTH_PASS='$2a$12$YTZXOCEylj4TaevZ0DCeI.notayQZ..b0OZ97lUZ.Q24fljLiMQHK'&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Example (docker-compose.yml)&lt;/strong&gt;: &lt;code&gt;PULSE_AUTH_PASS='$$2a$$12$$YTZXOCEylj4TaevZ0DCeI.notayQZ..b0OZ97lUZ.Q24fljLiMQHK'&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;If hash is truncated or mangled, authentication will fail&lt;/li&gt; 
 &lt;li&gt;Use Quick Security Setup in the UI to avoid manual configuration errors&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;.env file not created (Docker)&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Expected behavior&lt;/strong&gt;: When using environment variables, no .env file is created in /data&lt;/li&gt; 
 &lt;li&gt;The .env file is only created when using Quick Security Setup or password changes&lt;/li&gt; 
 &lt;li&gt;If you provide credentials via environment variables, they take precedence&lt;/li&gt; 
 &lt;li&gt;To use Quick Security Setup: Start container WITHOUT auth environment variables&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;VM Disk Stats Show "-"&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;VMs require QEMU Guest Agent to report disk usage (Proxmox API returns 0 for VMs)&lt;/li&gt; 
 &lt;li&gt;Install guest agent in VM: &lt;code&gt;apt install qemu-guest-agent&lt;/code&gt; (Linux) or virtio-win tools (Windows)&lt;/li&gt; 
 &lt;li&gt;Enable in VM Options → QEMU Guest Agent, then restart VM&lt;/li&gt; 
 &lt;li&gt;See &lt;a href="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/VM_DISK_MONITORING.md"&gt;VM Disk Monitoring Guide&lt;/a&gt; for setup&lt;/li&gt; 
 &lt;li&gt;Container (LXC) disk stats always work (no guest agent needed)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Connection Issues&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Check Proxmox API is accessible (port 8006/8007)&lt;/li&gt; 
 &lt;li&gt;Verify credentials have PVEAuditor role plus VM.GuestAgent.Audit (PVE 9) or VM.Monitor (PVE 8); the setup script applies these via the PulseMonitor role (adds Sys.Audit when available)&lt;/li&gt; 
 &lt;li&gt;For PBS: ensure API token has Datastore.Audit permission&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;High CPU/Memory&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Reduce polling interval in Settings&lt;/li&gt; 
 &lt;li&gt;Check number of monitored nodes&lt;/li&gt; 
 &lt;li&gt;Disable unused features (backups, snapshots)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Logs&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Docker
docker logs pulse

# Manual
journalctl -u pulse -f
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/DOCKER.md"&gt;Docker Guide&lt;/a&gt; - Complete Docker deployment guide&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/CONFIGURATION.md"&gt;Configuration Guide&lt;/a&gt; - Complete setup and configuration&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/VM_DISK_MONITORING.md"&gt;VM Disk Monitoring&lt;/a&gt; - Set up QEMU Guest Agent for accurate VM disk usage&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/PORT_CONFIGURATION.md"&gt;Port Configuration&lt;/a&gt; - How to change the default port&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/TROUBLESHOOTING.md"&gt;Troubleshooting&lt;/a&gt; - Common issues and solutions&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/API.md"&gt;API Reference&lt;/a&gt; - REST API endpoints and examples&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/WEBHOOKS.md"&gt;Webhook Guide&lt;/a&gt; - Setting up webhooks and custom payloads&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/PROXY_AUTH.md"&gt;Proxy Authentication&lt;/a&gt; - SSO integration with Authentik, Authelia, etc.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/REVERSE_PROXY.md"&gt;Reverse Proxy Setup&lt;/a&gt; - nginx, Caddy, Apache, Traefik configs&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/SECURITY.md"&gt;Security&lt;/a&gt; - Security features and best practices&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/FAQ.md"&gt;FAQ&lt;/a&gt; - Common questions and troubleshooting&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/MIGRATION.md"&gt;Migration Guide&lt;/a&gt; - Backup and migration procedures&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Security&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Mandatory authentication&lt;/strong&gt; protects your infrastructure&lt;/li&gt; 
 &lt;li&gt;Credentials stored encrypted (AES-256-GCM)&lt;/li&gt; 
 &lt;li&gt;API token support for automation&lt;/li&gt; 
 &lt;li&gt;Export/import requires authentication&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Setup script authentication&lt;/strong&gt;: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Setup codes&lt;/strong&gt;: Temporary 6-character codes for manual setup (expire in 5 minutes)&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;API tokens&lt;/strong&gt;: Permanent tokens for automation and scripting&lt;/li&gt; 
   &lt;li&gt;Use setup codes when giving access to others without sharing your API token&lt;/li&gt; 
   &lt;li&gt;Use API tokens for your own automation or trusted environments&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/SECURITY.md"&gt;Security Details →&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Development&lt;/h2&gt; 
&lt;h3&gt;Quick Start - Hot Reload (Recommended)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Launch Vite + Go with automatic frontend proxying
make dev-hot
# Frontend HMR: http://127.0.0.1:5173
# Backend API:   http://127.0.0.1:7655 (served via the Go app)
# Ports come from FRONTEND_PORT/PULSE_DEV_API_PORT (loaded from .env*. Override there if you need a different port.)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The backend now detects &lt;code&gt;FRONTEND_DEV_SERVER&lt;/code&gt; and proxies requests straight to the Vite dev server. Edit files under &lt;code&gt;frontend-modern/src/&lt;/code&gt; and the browser refreshes instantly—no manual rebuilds or service restarts required. Use &lt;code&gt;CTRL+C&lt;/code&gt; to stop both processes.&lt;/p&gt; 
&lt;h3&gt;Mock Mode - Develop Without Real Infrastructure&lt;/h3&gt; 
&lt;p&gt;Work on Pulse without needing Proxmox servers! Mock mode generates realistic test data and auto-reloads when toggled. The &lt;code&gt;mock.env&lt;/code&gt; configuration file is &lt;strong&gt;included in the repository&lt;/strong&gt;, so it works out of the box for all developers.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Enable mock mode with 7 nodes, ~90 guests
npm run mock:on

# Disable mock mode (use real infrastructure)
npm run mock:off

# Edit mock configuration
npm run mock:edit

# Create local overrides (not committed to git)
cp mock.env mock.env.local
# Edit mock.env.local with your personal preferences

# Data directories are isolated automatically:
# - Mock mode:   /opt/pulse/tmp/mock-data
# - Production:  /etc/pulse
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Backend auto-reloads when mock.env changes - no manual restarts!&lt;/strong&gt; The toggle scripts keep mock data isolated from &lt;code&gt;/etc/pulse&lt;/code&gt; so your real credentials stay untouched.&lt;/p&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/development/MOCK_MODE.md"&gt;docs/development/MOCK_MODE.md&lt;/a&gt; for full details.&lt;/p&gt; 
&lt;h3&gt;Production-like Development&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Watches files and rebuilds/embeds frontend into Go binary
./dev.sh
# Access at: http://localhost:7655
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Manual Development&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Frontend only
cd frontend-modern
npm install
npm run dev

# Backend only
go build -o pulse ./cmd/pulse
./pulse

# Or use make for full rebuild
make dev
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Visual Tour&lt;/h2&gt; 
&lt;p&gt;See Pulse in action with our &lt;a href="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/SCREENSHOTS.md"&gt;complete screenshot gallery →&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Core Features&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Dashboard&lt;/th&gt; 
   &lt;th&gt;Storage&lt;/th&gt; 
   &lt;th&gt;Backups&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/images/01-dashboard.png" alt="Dashboard" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/images/02-storage.png" alt="Storage" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/images/03-backups.png" alt="Backups" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;em&gt;Real-time monitoring of nodes, VMs &amp;amp; containers&lt;/em&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;em&gt;Storage pool usage across all nodes&lt;/em&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;em&gt;Unified backup management &amp;amp; PBS integration&lt;/em&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Alerts &amp;amp; Configuration&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Alert Configuration&lt;/th&gt; 
   &lt;th&gt;Alert History&lt;/th&gt; 
   &lt;th&gt;Settings&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/images/04-alerts.png" alt="Alerts" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/images/05-alert-history.png" alt="Alert History" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/images/06-settings.png" alt="Settings" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;em&gt;Configure thresholds &amp;amp; notifications&lt;/em&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;em&gt;Track patterns with visual timeline&lt;/em&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;em&gt;Manage nodes &amp;amp; authentication&lt;/em&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Mobile Experience&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Mobile Dashboard&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/images/08-mobile.png" alt="Mobile" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;em&gt;Fully responsive interface for monitoring on the go&lt;/em&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Links&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/rcourtman/Pulse/releases"&gt;Releases&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://hub.docker.com/r/rcourtman/pulse"&gt;Docker Hub&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/rcourtman/Pulse/issues"&gt;Issues&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;MIT - See &lt;a href="https://raw.githubusercontent.com/rcourtman/Pulse/main/LICENSE"&gt;LICENSE&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>seaweedfs/seaweedfs</title>
      <link>https://github.com/seaweedfs/seaweedfs</link>
      <description>&lt;p&gt;SeaweedFS is a fast distributed storage system for blobs, objects, files, and data lake, for billions of files! Blob store has O(1) disk seek, cloud tiering. Filer supports Cloud Drive, xDC replication, Kubernetes, POSIX FUSE mount, S3 API, S3 Gateway, Hadoop, WebDAV, encryption, Erasure Coding. Enterprise version is at seaweedfs.com.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;SeaweedFS&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://join.slack.com/t/seaweedfs/shared_invite/enQtMzI4MTMwMjU2MzA3LTEyYzZmZWYzOGQ3MDJlZWMzYmI0OTE4OTJiZjJjODBmMzUxNmYwODg0YjY3MTNlMjBmZDQ1NzQ5NDJhZWI2ZmY"&gt;&lt;img src="https://img.shields.io/badge/slack-purple" alt="Slack" /&gt;&lt;/a&gt; &lt;a href="https://twitter.com/intent/follow?screen_name=seaweedfs"&gt;&lt;img src="https://img.shields.io/twitter/follow/seaweedfs.svg?style=social&amp;amp;label=Follow" alt="Twitter" /&gt;&lt;/a&gt; &lt;a href="https://github.com/seaweedfs/seaweedfs/actions/workflows/go.yml"&gt;&lt;img src="https://img.shields.io/github/actions/workflow/status/seaweedfs/seaweedfs/go.yml" alt="Build Status" /&gt;&lt;/a&gt; &lt;a href="https://godoc.org/github.com/seaweedfs/seaweedfs/weed"&gt;&lt;img src="https://godoc.org/github.com/seaweedfs/seaweedfs/weed?status.svg?sanitize=true" alt="GoDoc" /&gt;&lt;/a&gt; &lt;a href="https://github.com/seaweedfs/seaweedfs/wiki"&gt;&lt;img src="https://img.shields.io/badge/docs-wiki-blue.svg?sanitize=true" alt="Wiki" /&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/r/chrislusf/seaweedfs/"&gt;&lt;img src="https://img.shields.io/docker/pulls/chrislusf/seaweedfs?maxAge=4800" alt="Docker Pulls" /&gt;&lt;/a&gt; &lt;a href="https://search.maven.org/search?q=g:com.github.chrislusf"&gt;&lt;img src="https://img.shields.io/maven-central/v/com.github.chrislusf/seaweedfs-client" alt="SeaweedFS on Maven Central" /&gt;&lt;/a&gt; &lt;a href="https://artifacthub.io/packages/search?repo=seaweedfs"&gt;&lt;img src="https://img.shields.io/endpoint?url=https://artifacthub.io/badge/repository/seaweedfs" alt="Artifact Hub" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/note/seaweedfs.png" alt="SeaweedFS Logo" /&gt;&lt;/p&gt; 
&lt;h2 align="center"&gt;&lt;a href="https://www.patreon.com/seaweedfs"&gt;Sponsor SeaweedFS via Patreon&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;SeaweedFS is an independent Apache-licensed open source project with its ongoing development made possible entirely thanks to the support of these awesome &lt;a href="https://github.com/seaweedfs/seaweedfs/raw/master/backers.md"&gt;backers&lt;/a&gt;. If you'd like to grow SeaweedFS even stronger, please consider joining our &lt;a href="https://www.patreon.com/seaweedfs"&gt;sponsors on Patreon&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Your support will be really appreciated by me and other supporters!&lt;/p&gt; 
&lt;!--
&lt;h4 align="center"&gt;Platinum&lt;/h4&gt;

&lt;p align="center"&gt;
  &lt;a href="" target="_blank"&gt;
    Add your name or icon here
  &lt;/a&gt;
&lt;/p&gt;
--&gt; 
&lt;h3&gt;Gold Sponsors&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://www.nodion.com"&gt;&lt;img src="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/note/sponsor_nodion.png" alt="nodion" /&gt;&lt;/a&gt; &lt;a href="https://www.piknik.com"&gt;&lt;img src="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/note/piknik.png" alt="piknik" /&gt;&lt;/a&gt; &lt;a href="https://www.keepsec.ca"&gt;&lt;img src="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/note/keepsec.png" alt="keepsec" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/releases/latest"&gt;Download Binaries for different platforms&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://join.slack.com/t/seaweedfs/shared_invite/enQtMzI4MTMwMjU2MzA3LTEyYzZmZWYzOGQ3MDJlZWMzYmI0OTE4OTJiZjJjODBmMzUxNmYwODg0YjY3MTNlMjBmZDQ1NzQ5NDJhZWI2ZmY"&gt;SeaweedFS on Slack&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://twitter.com/SeaweedFS"&gt;SeaweedFS on Twitter&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://t.me/Seaweedfs"&gt;SeaweedFS on Telegram&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.reddit.com/r/SeaweedFS/"&gt;SeaweedFS on Reddit&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://groups.google.com/d/forum/seaweedfs"&gt;SeaweedFS Mailing List&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki"&gt;Wiki Documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/SeaweedFS_Architecture.pdf"&gt;SeaweedFS White Paper&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.google.com/presentation/d/1tdkp45J01oRV68dIm4yoTXKJDof-EhainlA0LMXexQE/edit?usp=sharing"&gt;SeaweedFS Introduction Slides 2025.5&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.google.com/presentation/d/1DcxKWlINc-HNCjhYeERkpGXXm6nTCES8mi2W5G0Z4Ts/edit?usp=sharing"&gt;SeaweedFS Introduction Slides 2021.5&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.slideshare.net/chrislusf/seaweedfs-introduction"&gt;SeaweedFS Introduction Slides 2019.3&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Table of Contents&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#quick-start"&gt;Quick Start&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#quick-start-for-s3-api-on-docker"&gt;Quick Start for S3 API on Docker&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#quick-start-with-single-binary"&gt;Quick Start with Single Binary&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#quick-start-seaweedfs-s3-on-aws"&gt;Quick Start SeaweedFS S3 on AWS&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#introduction"&gt;Introduction&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#features"&gt;Features&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#additional-features"&gt;Additional Features&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#filer-features"&gt;Filer Features&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#example-using-seaweed-object-store"&gt;Example: Using Seaweed Object Store&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#object-store-architecture"&gt;Architecture&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#compared-to-other-file-systems"&gt;Compared to Other File Systems&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#compared-to-hdfs"&gt;Compared to HDFS&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#compared-to-glusterfs-ceph"&gt;Compared to GlusterFS, Ceph&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#compared-to-glusterfs"&gt;Compared to GlusterFS&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#compared-to-ceph"&gt;Compared to Ceph&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#compared-to-minio"&gt;Compared to Minio&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#dev-plan"&gt;Dev Plan&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#installation-guide"&gt;Installation Guide&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#disk-related-topics"&gt;Disk Related Topics&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#benchmark"&gt;Benchmark&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#enterprise"&gt;Enterprise&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#license"&gt;License&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Quick Start&lt;/h1&gt; 
&lt;h2&gt;Quick Start for S3 API on Docker&lt;/h2&gt; 
&lt;p&gt;&lt;code&gt;docker run -p 8333:8333 chrislusf/seaweedfs server -s3&lt;/code&gt;&lt;/p&gt; 
&lt;h2&gt;Quick Start with Single Binary&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Download the latest binary from &lt;a href="https://github.com/seaweedfs/seaweedfs/releases"&gt;https://github.com/seaweedfs/seaweedfs/releases&lt;/a&gt; and unzip a single binary file &lt;code&gt;weed&lt;/code&gt; or &lt;code&gt;weed.exe&lt;/code&gt;. Or run &lt;code&gt;go install github.com/seaweedfs/seaweedfs/weed@latest&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;export AWS_ACCESS_KEY_ID=admin ; export AWS_SECRET_ACCESS_KEY=key&lt;/code&gt; as the admin credentials to access the object store.&lt;/li&gt; 
 &lt;li&gt;Run &lt;code&gt;weed server -dir=/some/data/dir -s3&lt;/code&gt; to start one master, one volume server, one filer, and one S3 gateway.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Also, to increase capacity, just add more volume servers by running &lt;code&gt;weed volume -dir="/some/data/dir2" -mserver="&amp;lt;master_host&amp;gt;:9333" -port=8081&lt;/code&gt; locally, or on a different machine, or on thousands of machines. That is it!&lt;/p&gt; 
&lt;h2&gt;Quick Start SeaweedFS S3 on AWS&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Setup fast production-ready &lt;a href="https://aws.amazon.com/marketplace/pp/prodview-nzelz5gprlrjc"&gt;SeaweedFS S3 on AWS with cloudformation&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Introduction&lt;/h1&gt; 
&lt;p&gt;SeaweedFS is a simple and highly scalable distributed file system. There are two objectives:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;to store billions of files!&lt;/li&gt; 
 &lt;li&gt;to serve the files fast!&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;SeaweedFS started as an Object Store to handle small files efficiently. Instead of managing all file metadata in a central master, the central master only manages volumes on volume servers, and these volume servers manage files and their metadata. This relieves concurrency pressure from the central master and spreads file metadata into volume servers, allowing faster file access (O(1), usually just one disk read operation).&lt;/p&gt; 
&lt;p&gt;There is only 40 bytes of disk storage overhead for each file's metadata. It is so simple with O(1) disk reads that you are welcome to challenge the performance with your actual use cases.&lt;/p&gt; 
&lt;p&gt;SeaweedFS started by implementing &lt;a href="http://www.usenix.org/event/osdi10/tech/full_papers/Beaver.pdf"&gt;Facebook's Haystack design paper&lt;/a&gt;. Also, SeaweedFS implements erasure coding with ideas from &lt;a href="https://www.usenix.org/system/files/conference/osdi14/osdi14-paper-muralidhar.pdf"&gt;f4: Facebook’s Warm BLOB Storage System&lt;/a&gt;, and has a lot of similarities with &lt;a href="https://www.usenix.org/system/files/fast21-pan.pdf"&gt;Facebook’s Tectonic Filesystem&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;On top of the object store, optional &lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Directories-and-Files"&gt;Filer&lt;/a&gt; can support directories and POSIX attributes. Filer is a separate linearly-scalable stateless server with customizable metadata stores, e.g., MySql, Postgres, Redis, Cassandra, HBase, Mongodb, Elastic Search, LevelDB, RocksDB, Sqlite, MemSql, TiDB, Etcd, CockroachDB, YDB, etc.&lt;/p&gt; 
&lt;p&gt;For any distributed key value stores, the large values can be offloaded to SeaweedFS. With the fast access speed and linearly scalable capacity, SeaweedFS can work as a distributed &lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Filer-as-a-Key-Large-Value-Store"&gt;Key-Large-Value store&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;SeaweedFS can transparently integrate with the cloud. With hot data on local cluster, and warm data on the cloud with O(1) access time, SeaweedFS can achieve both fast local access time and elastic cloud storage capacity. What's more, the cloud storage access API cost is minimized. Faster and cheaper than direct cloud storage!&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Features&lt;/h1&gt; 
&lt;h2&gt;Additional Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Can choose no replication or different replication levels, rack and data center aware.&lt;/li&gt; 
 &lt;li&gt;Automatic master servers failover - no single point of failure (SPOF).&lt;/li&gt; 
 &lt;li&gt;Automatic Gzip compression depending on file MIME type.&lt;/li&gt; 
 &lt;li&gt;Automatic compaction to reclaim disk space after deletion or update.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Store-file-with-a-Time-To-Live"&gt;Automatic entry TTL expiration&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Any server with some disk space can add to the total storage space.&lt;/li&gt; 
 &lt;li&gt;Adding/Removing servers does &lt;strong&gt;not&lt;/strong&gt; cause any data re-balancing unless triggered by admin commands.&lt;/li&gt; 
 &lt;li&gt;Optional picture resizing.&lt;/li&gt; 
 &lt;li&gt;Support ETag, Accept-Range, Last-Modified, etc.&lt;/li&gt; 
 &lt;li&gt;Support in-memory/leveldb/readonly mode tuning for memory/performance balance.&lt;/li&gt; 
 &lt;li&gt;Support rebalancing the writable and readonly volumes.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Tiered-Storage"&gt;Customizable Multiple Storage Tiers&lt;/a&gt;: Customizable storage disk types to balance performance and cost.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Cloud-Tier"&gt;Transparent cloud integration&lt;/a&gt;: unlimited capacity via tiered cloud storage for warm data.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Erasure-coding-for-warm-storage"&gt;Erasure Coding for warm storage&lt;/a&gt; Rack-Aware 10.4 erasure coding reduces storage cost and increases availability.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Filer Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Directories-and-Files"&gt;Filer server&lt;/a&gt; provides "normal" directories and files via HTTP.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Filer-Stores"&gt;File TTL&lt;/a&gt; automatically expires file metadata and actual file data.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/FUSE-Mount"&gt;Mount filer&lt;/a&gt; reads and writes files directly as a local directory via FUSE.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Filer-Store-Replication"&gt;Filer Store Replication&lt;/a&gt; enables HA for filer meta data stores.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Filer-Active-Active-cross-cluster-continuous-synchronization"&gt;Active-Active Replication&lt;/a&gt; enables asynchronous one-way or two-way cross cluster continuous replication.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Amazon-S3-API"&gt;Amazon S3 compatible API&lt;/a&gt; accesses files with S3 tooling.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Hadoop-Compatible-File-System"&gt;Hadoop Compatible File System&lt;/a&gt; accesses files from Hadoop/Spark/Flink/etc or even runs HBase.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Async-Replication-to-Cloud"&gt;Async Replication To Cloud&lt;/a&gt; has extremely fast local access and backups to Amazon S3, Google Cloud Storage, Azure, BackBlaze.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/WebDAV"&gt;WebDAV&lt;/a&gt; accesses as a mapped drive on Mac and Windows, or from mobile devices.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Filer-Data-Encryption"&gt;AES256-GCM Encrypted Storage&lt;/a&gt; safely stores the encrypted data.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Data-Structure-for-Large-Files"&gt;Super Large Files&lt;/a&gt; stores large or super large files in tens of TB.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Cloud-Drive-Architecture"&gt;Cloud Drive&lt;/a&gt; mounts cloud storage to local cluster, cached for fast read and write with asynchronous write back.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Gateway-to-Remote-Object-Storage"&gt;Gateway to Remote Object Store&lt;/a&gt; mirrors bucket operations to remote object storage, in addition to &lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Cloud-Drive-Architecture"&gt;Cloud Drive&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Kubernetes&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs-csi-driver"&gt;Kubernetes CSI Driver&lt;/a&gt; A Container Storage Interface (CSI) Driver. &lt;a href="https://hub.docker.com/r/chrislusf/seaweedfs-csi-driver/"&gt;&lt;img src="https://img.shields.io/docker/pulls/chrislusf/seaweedfs-csi-driver.svg?maxAge=4800" alt="Docker Pulls" /&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs-operator"&gt;SeaweedFS Operator&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Example: Using Seaweed Object Store&lt;/h2&gt; 
&lt;p&gt;By default, the master node runs on port 9333, and the volume nodes run on port 8080. Let's start one master node, and two volume nodes on port 8080 and 8081. Ideally, they should be started from different machines. We'll use localhost as an example.&lt;/p&gt; 
&lt;p&gt;SeaweedFS uses HTTP REST operations to read, write, and delete. The responses are in JSON or JSONP format.&lt;/p&gt; 
&lt;h3&gt;Start Master Server&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;&amp;gt; ./weed master
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Start Volume Servers&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;&amp;gt; weed volume -dir="/tmp/data1" -max=5  -mserver="localhost:9333" -port=8080 &amp;amp;
&amp;gt; weed volume -dir="/tmp/data2" -max=10 -mserver="localhost:9333" -port=8081 &amp;amp;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Write File&lt;/h3&gt; 
&lt;p&gt;To upload a file: first, send a HTTP POST, PUT, or GET request to &lt;code&gt;/dir/assign&lt;/code&gt; to get an &lt;code&gt;fid&lt;/code&gt; and a volume server URL:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&amp;gt; curl http://localhost:9333/dir/assign
{"count":1,"fid":"3,01637037d6","url":"127.0.0.1:8080","publicUrl":"localhost:8080"}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Second, to store the file content, send a HTTP multi-part POST request to &lt;code&gt;url + '/' + fid&lt;/code&gt; from the response:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&amp;gt; curl -F file=@/home/chris/myphoto.jpg http://127.0.0.1:8080/3,01637037d6
{"name":"myphoto.jpg","size":43234,"eTag":"1cc0118e"}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To update, send another POST request with updated file content.&lt;/p&gt; 
&lt;p&gt;For deletion, send an HTTP DELETE request to the same &lt;code&gt;url + '/' + fid&lt;/code&gt; URL:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&amp;gt; curl -X DELETE http://127.0.0.1:8080/3,01637037d6
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Save File Id&lt;/h3&gt; 
&lt;p&gt;Now, you can save the &lt;code&gt;fid&lt;/code&gt;, 3,01637037d6 in this case, to a database field.&lt;/p&gt; 
&lt;p&gt;The number 3 at the start represents a volume id. After the comma, it's one file key, 01, and a file cookie, 637037d6.&lt;/p&gt; 
&lt;p&gt;The volume id is an unsigned 32-bit integer. The file key is an unsigned 64-bit integer. The file cookie is an unsigned 32-bit integer, used to prevent URL guessing.&lt;/p&gt; 
&lt;p&gt;The file key and file cookie are both coded in hex. You can store the &amp;lt;volume id, file key, file cookie&amp;gt; tuple in your own format, or simply store the &lt;code&gt;fid&lt;/code&gt; as a string.&lt;/p&gt; 
&lt;p&gt;If stored as a string, in theory, you would need 8+1+16+8=33 bytes. A char(33) would be enough, if not more than enough, since most uses will not need 2^32 volumes.&lt;/p&gt; 
&lt;p&gt;If space is really a concern, you can store the file id in your own format. You would need one 4-byte integer for volume id, 8-byte long number for file key, and a 4-byte integer for the file cookie. So 16 bytes are more than enough.&lt;/p&gt; 
&lt;h3&gt;Read File&lt;/h3&gt; 
&lt;p&gt;Here is an example of how to render the URL.&lt;/p&gt; 
&lt;p&gt;First look up the volume server's URLs by the file's volumeId:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&amp;gt; curl http://localhost:9333/dir/lookup?volumeId=3
{"volumeId":"3","locations":[{"publicUrl":"localhost:8080","url":"localhost:8080"}]}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Since (usually) there are not too many volume servers, and volumes don't move often, you can cache the results most of the time. Depending on the replication type, one volume can have multiple replica locations. Just randomly pick one location to read.&lt;/p&gt; 
&lt;p&gt;Now you can take the public URL, render the URL or directly read from the volume server via URL:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt; http://localhost:8080/3,01637037d6.jpg
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Notice we add a file extension ".jpg" here. It's optional and just one way for the client to specify the file content type.&lt;/p&gt; 
&lt;p&gt;If you want a nicer URL, you can use one of these alternative URL formats:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt; http://localhost:8080/3/01637037d6/my_preferred_name.jpg
 http://localhost:8080/3/01637037d6.jpg
 http://localhost:8080/3,01637037d6.jpg
 http://localhost:8080/3/01637037d6
 http://localhost:8080/3,01637037d6
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you want to get a scaled version of an image, you can add some params:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;http://localhost:8080/3/01637037d6.jpg?height=200&amp;amp;width=200
http://localhost:8080/3/01637037d6.jpg?height=200&amp;amp;width=200&amp;amp;mode=fit
http://localhost:8080/3/01637037d6.jpg?height=200&amp;amp;width=200&amp;amp;mode=fill
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Rack-Aware and Data Center-Aware Replication&lt;/h3&gt; 
&lt;p&gt;SeaweedFS applies the replication strategy at a volume level. So, when you are getting a file id, you can specify the replication strategy. For example:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;curl http://localhost:9333/dir/assign?replication=001
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The replication parameter options are:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;000: no replication
001: replicate once on the same rack
010: replicate once on a different rack, but same data center
100: replicate once on a different data center
200: replicate twice on two different data center
110: replicate once on a different rack, and once on a different data center
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;More details about replication can be found &lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Replication"&gt;on the wiki&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;You can also set the default replication strategy when starting the master server.&lt;/p&gt; 
&lt;h3&gt;Allocate File Key on Specific Data Center&lt;/h3&gt; 
&lt;p&gt;Volume servers can be started with a specific data center name:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt; weed volume -dir=/tmp/1 -port=8080 -dataCenter=dc1
 weed volume -dir=/tmp/2 -port=8081 -dataCenter=dc2
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;When requesting a file key, an optional "dataCenter" parameter can limit the assigned volume to the specific data center. For example, this specifies that the assigned volume should be limited to 'dc1':&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt; http://localhost:9333/dir/assign?dataCenter=dc1
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Other Features&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Failover-Master-Server"&gt;No Single Point of Failure&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Optimization#insert-with-your-own-keys"&gt;Insert with your own keys&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Optimization#upload-large-files"&gt;Chunking large files&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Optimization#collection-as-a-simple-name-space"&gt;Collection as a Simple Name Space&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Object Store Architecture&lt;/h2&gt; 
&lt;p&gt;Usually distributed file systems split each file into chunks, a central master keeps a mapping of filenames, chunk indices to chunk handles, and also which chunks each chunk server has.&lt;/p&gt; 
&lt;p&gt;The main drawback is that the central master can't handle many small files efficiently, and since all read requests need to go through the chunk master, so it might not scale well for many concurrent users.&lt;/p&gt; 
&lt;p&gt;Instead of managing chunks, SeaweedFS manages data volumes in the master server. Each data volume is 32GB in size, and can hold a lot of files. And each storage node can have many data volumes. So the master node only needs to store the metadata about the volumes, which is a fairly small amount of data and is generally stable.&lt;/p&gt; 
&lt;p&gt;The actual file metadata is stored in each volume on volume servers. Since each volume server only manages metadata of files on its own disk, with only 16 bytes for each file, all file access can read file metadata just from memory and only needs one disk operation to actually read file data.&lt;/p&gt; 
&lt;p&gt;For comparison, consider that an xfs inode structure in Linux is 536 bytes.&lt;/p&gt; 
&lt;h3&gt;Master Server and Volume Server&lt;/h3&gt; 
&lt;p&gt;The architecture is fairly simple. The actual data is stored in volumes on storage nodes. One volume server can have multiple volumes, and can both support read and write access with basic authentication.&lt;/p&gt; 
&lt;p&gt;All volumes are managed by a master server. The master server contains the volume id to volume server mapping. This is fairly static information, and can be easily cached.&lt;/p&gt; 
&lt;p&gt;On each write request, the master server also generates a file key, which is a growing 64-bit unsigned integer. Since write requests are not generally as frequent as read requests, one master server should be able to handle the concurrency well.&lt;/p&gt; 
&lt;h3&gt;Write and Read files&lt;/h3&gt; 
&lt;p&gt;When a client sends a write request, the master server returns (volume id, file key, file cookie, volume node URL) for the file. The client then contacts the volume node and POSTs the file content.&lt;/p&gt; 
&lt;p&gt;When a client needs to read a file based on (volume id, file key, file cookie), it asks the master server by the volume id for the (volume node URL, volume node public URL), or retrieves this from a cache. Then the client can GET the content, or just render the URL on web pages and let browsers fetch the content.&lt;/p&gt; 
&lt;p&gt;Please see the example for details on the write-read process.&lt;/p&gt; 
&lt;h3&gt;Storage Size&lt;/h3&gt; 
&lt;p&gt;In the current implementation, each volume can hold 32 gibibytes (32GiB or 8x2^32 bytes). This is because we align content to 8 bytes. We can easily increase this to 64GiB, or 128GiB, or more, by changing 2 lines of code, at the cost of some wasted padding space due to alignment.&lt;/p&gt; 
&lt;p&gt;There can be 4 gibibytes (4GiB or 2^32 bytes) of volumes. So the total system size is 8 x 4GiB x 4GiB which is 128 exbibytes (128EiB or 2^67 bytes).&lt;/p&gt; 
&lt;p&gt;Each individual file size is limited to the volume size.&lt;/p&gt; 
&lt;h3&gt;Saving memory&lt;/h3&gt; 
&lt;p&gt;All file meta information stored on a volume server is readable from memory without disk access. Each file takes just a 16-byte map entry of &amp;lt;64bit key, 32bit offset, 32bit size&amp;gt;. Of course, each map entry has its own space cost for the map. But usually the disk space runs out before the memory does.&lt;/p&gt; 
&lt;h3&gt;Tiered Storage to the cloud&lt;/h3&gt; 
&lt;p&gt;The local volume servers are much faster, while cloud storages have elastic capacity and are actually more cost-efficient if not accessed often (usually free to upload, but relatively costly to access). With the append-only structure and O(1) access time, SeaweedFS can take advantage of both local and cloud storage by offloading the warm data to the cloud.&lt;/p&gt; 
&lt;p&gt;Usually hot data are fresh and warm data are old. SeaweedFS puts the newly created volumes on local servers, and optionally upload the older volumes on the cloud. If the older data are accessed less often, this literally gives you unlimited capacity with limited local servers, and still fast for new data.&lt;/p&gt; 
&lt;p&gt;With the O(1) access time, the network latency cost is kept at minimum.&lt;/p&gt; 
&lt;p&gt;If the hot/warm data is split as 20/80, with 20 servers, you can achieve storage capacity of 100 servers. That's a cost saving of 80%! Or you can repurpose the 80 servers to store new data also, and get 5X storage throughput.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Compared to Other File Systems&lt;/h2&gt; 
&lt;p&gt;Most other distributed file systems seem more complicated than necessary.&lt;/p&gt; 
&lt;p&gt;SeaweedFS is meant to be fast and simple, in both setup and operation. If you do not understand how it works when you reach here, we've failed! Please raise an issue with any questions or update this file with clarifications.&lt;/p&gt; 
&lt;p&gt;SeaweedFS is constantly moving forward. Same with other systems. These comparisons can be outdated quickly. Please help to keep them updated.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Compared to HDFS&lt;/h3&gt; 
&lt;p&gt;HDFS uses the chunk approach for each file, and is ideal for storing large files.&lt;/p&gt; 
&lt;p&gt;SeaweedFS is ideal for serving relatively smaller files quickly and concurrently.&lt;/p&gt; 
&lt;p&gt;SeaweedFS can also store extra large files by splitting them into manageable data chunks, and store the file ids of the data chunks into a meta chunk. This is managed by "weed upload/download" tool, and the weed master or volume servers are agnostic about it.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Compared to GlusterFS, Ceph&lt;/h3&gt; 
&lt;p&gt;The architectures are mostly the same. SeaweedFS aims to store and read files fast, with a simple and flat architecture. The main differences are&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;SeaweedFS optimizes for small files, ensuring O(1) disk seek operation, and can also handle large files.&lt;/li&gt; 
 &lt;li&gt;SeaweedFS statically assigns a volume id for a file. Locating file content becomes just a lookup of the volume id, which can be easily cached.&lt;/li&gt; 
 &lt;li&gt;SeaweedFS Filer metadata store can be any well-known and proven data store, e.g., Redis, Cassandra, HBase, Mongodb, Elastic Search, MySql, Postgres, Sqlite, MemSql, TiDB, CockroachDB, Etcd, YDB etc, and is easy to customize.&lt;/li&gt; 
 &lt;li&gt;SeaweedFS Volume server also communicates directly with clients via HTTP, supporting range queries, direct uploads, etc.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;System&lt;/th&gt; 
   &lt;th&gt;File Metadata&lt;/th&gt; 
   &lt;th&gt;File Content Read&lt;/th&gt; 
   &lt;th&gt;POSIX&lt;/th&gt; 
   &lt;th&gt;REST API&lt;/th&gt; 
   &lt;th&gt;Optimized for large number of small files&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;SeaweedFS&lt;/td&gt; 
   &lt;td&gt;lookup volume id, cacheable&lt;/td&gt; 
   &lt;td&gt;O(1) disk seek&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;SeaweedFS Filer&lt;/td&gt; 
   &lt;td&gt;Linearly Scalable, Customizable&lt;/td&gt; 
   &lt;td&gt;O(1) disk seek&lt;/td&gt; 
   &lt;td&gt;FUSE&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GlusterFS&lt;/td&gt; 
   &lt;td&gt;hashing&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;FUSE, NFS&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Ceph&lt;/td&gt; 
   &lt;td&gt;hashing + rules&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;FUSE&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;MooseFS&lt;/td&gt; 
   &lt;td&gt;in memory&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;FUSE&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;MinIO&lt;/td&gt; 
   &lt;td&gt;separate meta file for each file&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Compared to GlusterFS&lt;/h3&gt; 
&lt;p&gt;GlusterFS stores files, both directories and content, in configurable volumes called "bricks".&lt;/p&gt; 
&lt;p&gt;GlusterFS hashes the path and filename into ids, and assigned to virtual volumes, and then mapped to "bricks".&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Compared to MooseFS&lt;/h3&gt; 
&lt;p&gt;MooseFS chooses to neglect small file issue. From moosefs 3.0 manual, "even a small file will occupy 64KiB plus additionally 4KiB of checksums and 1KiB for the header", because it "was initially designed for keeping large amounts (like several thousands) of very big files"&lt;/p&gt; 
&lt;p&gt;MooseFS Master Server keeps all meta data in memory. Same issue as HDFS namenode.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Compared to Ceph&lt;/h3&gt; 
&lt;p&gt;Ceph can be setup similar to SeaweedFS as a key-&amp;gt;blob store. It is much more complicated, with the need to support layers on top of it. &lt;a href="https://github.com/seaweedfs/seaweedfs/issues/120"&gt;Here is a more detailed comparison&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;SeaweedFS has a centralized master group to look up free volumes, while Ceph uses hashing and metadata servers to locate its objects. Having a centralized master makes it easy to code and manage.&lt;/p&gt; 
&lt;p&gt;Ceph, like SeaweedFS, is based on the object store RADOS. Ceph is rather complicated with mixed reviews.&lt;/p&gt; 
&lt;p&gt;Ceph uses CRUSH hashing to automatically manage data placement, which is efficient to locate the data. But the data has to be placed according to the CRUSH algorithm. Any wrong configuration would cause data loss. Topology changes, such as adding new servers to increase capacity, will cause data migration with high IO cost to fit the CRUSH algorithm. SeaweedFS places data by assigning them to any writable volumes. If writes to one volume failed, just pick another volume to write. Adding more volumes is also as simple as it can be.&lt;/p&gt; 
&lt;p&gt;SeaweedFS is optimized for small files. Small files are stored as one continuous block of content, with at most 8 unused bytes between files. Small file access is O(1) disk read.&lt;/p&gt; 
&lt;p&gt;SeaweedFS Filer uses off-the-shelf stores, such as MySql, Postgres, Sqlite, Mongodb, Redis, Elastic Search, Cassandra, HBase, MemSql, TiDB, CockroachCB, Etcd, YDB, to manage file directories. These stores are proven, scalable, and easier to manage.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;SeaweedFS&lt;/th&gt; 
   &lt;th&gt;comparable to Ceph&lt;/th&gt; 
   &lt;th&gt;advantage&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Master&lt;/td&gt; 
   &lt;td&gt;MDS&lt;/td&gt; 
   &lt;td&gt;simpler&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Volume&lt;/td&gt; 
   &lt;td&gt;OSD&lt;/td&gt; 
   &lt;td&gt;optimized for small files&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Filer&lt;/td&gt; 
   &lt;td&gt;Ceph FS&lt;/td&gt; 
   &lt;td&gt;linearly scalable, Customizable, O(1) or O(logN)&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Compared to MinIO&lt;/h3&gt; 
&lt;p&gt;MinIO follows AWS S3 closely and is ideal for testing for S3 API. It has good UI, policies, versionings, etc. SeaweedFS is trying to catch up here. It is also possible to put MinIO as a gateway in front of SeaweedFS later.&lt;/p&gt; 
&lt;p&gt;MinIO metadata are in simple files. Each file write will incur extra writes to corresponding meta file.&lt;/p&gt; 
&lt;p&gt;MinIO does not have optimization for lots of small files. The files are simply stored as is to local disks. Plus the extra meta file and shards for erasure coding, it only amplifies the LOSF problem.&lt;/p&gt; 
&lt;p&gt;MinIO has multiple disk IO to read one file. SeaweedFS has O(1) disk reads, even for erasure coded files.&lt;/p&gt; 
&lt;p&gt;MinIO has full-time erasure coding. SeaweedFS uses replication on hot data for faster speed and optionally applies erasure coding on warm data.&lt;/p&gt; 
&lt;p&gt;MinIO does not have POSIX-like API support.&lt;/p&gt; 
&lt;p&gt;MinIO has specific requirements on storage layout. It is not flexible to adjust capacity. In SeaweedFS, just start one volume server pointing to the master. That's all.&lt;/p&gt; 
&lt;h2&gt;Dev Plan&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;More tools and documentation, on how to manage and scale the system.&lt;/li&gt; 
 &lt;li&gt;Read and write stream data.&lt;/li&gt; 
 &lt;li&gt;Support structured data.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;This is a super exciting project! And we need helpers and &lt;a href="https://www.patreon.com/seaweedfs"&gt;support&lt;/a&gt;!&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Installation Guide&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Installation guide for users who are not familiar with golang&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Step 1: install go on your machine and setup the environment by following the instructions at:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://golang.org/doc/install"&gt;https://golang.org/doc/install&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;make sure to define your $GOPATH&lt;/p&gt; 
&lt;p&gt;Step 2: checkout this repo:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/seaweedfs/seaweedfs.git
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Step 3: download, compile, and install the project by executing the following command&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd seaweedfs/weed &amp;amp;&amp;amp; make install
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Once this is done, you will find the executable "weed" in your &lt;code&gt;$GOPATH/bin&lt;/code&gt; directory&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Disk Related Topics&lt;/h2&gt; 
&lt;h3&gt;Hard Drive Performance&lt;/h3&gt; 
&lt;p&gt;When testing read performance on SeaweedFS, it basically becomes a performance test of your hard drive's random read speed. Hard drives usually get 100MB/s~200MB/s.&lt;/p&gt; 
&lt;h3&gt;Solid State Disk&lt;/h3&gt; 
&lt;p&gt;To modify or delete small files, SSD must delete a whole block at a time, and move content in existing blocks to a new block. SSD is fast when brand new, but will get fragmented over time and you have to garbage collect, compacting blocks. SeaweedFS is friendly to SSD since it is append-only. Deletion and compaction are done on volume level in the background, not slowing reading and not causing fragmentation.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Benchmark&lt;/h2&gt; 
&lt;p&gt;My Own Unscientific Single Machine Results on Mac Book with Solid State Disk, CPU: 1 Intel Core i7 2.6GHz.&lt;/p&gt; 
&lt;p&gt;Write 1 million 1KB file:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Concurrency Level:      16
Time taken for tests:   66.753 seconds
Completed requests:      1048576
Failed requests:        0
Total transferred:      1106789009 bytes
Requests per second:    15708.23 [#/sec]
Transfer rate:          16191.69 [Kbytes/sec]

Connection Times (ms)
              min      avg        max      std
Total:        0.3      1.0       84.3      0.9

Percentage of the requests served within a certain time (ms)
   50%      0.8 ms
   66%      1.0 ms
   75%      1.1 ms
   80%      1.2 ms
   90%      1.4 ms
   95%      1.7 ms
   98%      2.1 ms
   99%      2.6 ms
  100%     84.3 ms
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Randomly read 1 million files:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Concurrency Level:      16
Time taken for tests:   22.301 seconds
Completed requests:      1048576
Failed requests:        0
Total transferred:      1106812873 bytes
Requests per second:    47019.38 [#/sec]
Transfer rate:          48467.57 [Kbytes/sec]

Connection Times (ms)
              min      avg        max      std
Total:        0.0      0.3       54.1      0.2

Percentage of the requests served within a certain time (ms)
   50%      0.3 ms
   90%      0.4 ms
   98%      0.6 ms
   99%      0.7 ms
  100%     54.1 ms
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Run WARP and launch a mixed benchmark.&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;make benchmark
warp: Benchmark data written to "warp-mixed-2023-10-16[102354]-l70a.csv.zst"                                                                                                                                                                                               
Mixed operations.
Operation: DELETE, 10%, Concurrency: 20, Ran 4m59s.
 * Throughput: 6.19 obj/s

Operation: GET, 45%, Concurrency: 20, Ran 5m0s.
 * Throughput: 279.85 MiB/s, 27.99 obj/s

Operation: PUT, 15%, Concurrency: 20, Ran 5m0s.
 * Throughput: 89.86 MiB/s, 8.99 obj/s

Operation: STAT, 30%, Concurrency: 20, Ran 5m0s.
 * Throughput: 18.63 obj/s

Cluster Total: 369.74 MiB/s, 61.79 obj/s, 0 errors over 5m0s.
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To see segmented request statistics, use the --analyze.v parameter.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;warp analyze --analyze.v warp-mixed-2023-10-16[102354]-l70a.csv.zst
18642 operations loaded... Done!
Mixed operations.
----------------------------------------
Operation: DELETE - total: 1854, 10.0%, Concurrency: 20, Ran 5m0s, starting 2023-10-16 10:23:57.115 +0500 +05
 * Throughput: 6.19 obj/s

Requests considered: 1855:
 * Avg: 104ms, 50%: 30ms, 90%: 207ms, 99%: 1.355s, Fastest: 1ms, Slowest: 4.613s, StdDev: 320ms

----------------------------------------
Operation: GET - total: 8388, 45.3%, Size: 10485760 bytes. Concurrency: 20, Ran 5m0s, starting 2023-10-16 10:23:57.12 +0500 +05
 * Throughput: 279.77 MiB/s, 27.98 obj/s

Requests considered: 8389:
 * Avg: 221ms, 50%: 106ms, 90%: 492ms, 99%: 1.739s, Fastest: 8ms, Slowest: 8.633s, StdDev: 383ms
 * TTFB: Avg: 81ms, Best: 2ms, 25th: 24ms, Median: 39ms, 75th: 65ms, 90th: 171ms, 99th: 669ms, Worst: 4.783s StdDev: 163ms
 * First Access: Avg: 240ms, 50%: 105ms, 90%: 511ms, 99%: 2.08s, Fastest: 12ms, Slowest: 8.633s, StdDev: 480ms
 * First Access TTFB: Avg: 88ms, Best: 2ms, 25th: 24ms, Median: 38ms, 75th: 64ms, 90th: 179ms, 99th: 919ms, Worst: 4.783s StdDev: 199ms
 * Last Access: Avg: 219ms, 50%: 106ms, 90%: 463ms, 99%: 1.782s, Fastest: 9ms, Slowest: 8.633s, StdDev: 416ms
 * Last Access TTFB: Avg: 81ms, Best: 2ms, 25th: 24ms, Median: 39ms, 75th: 65ms, 90th: 161ms, 99th: 657ms, Worst: 4.783s StdDev: 176ms

----------------------------------------
Operation: PUT - total: 2688, 14.5%, Size: 10485760 bytes. Concurrency: 20, Ran 5m0s, starting 2023-10-16 10:23:57.115 +0500 +05
 * Throughput: 89.83 MiB/s, 8.98 obj/s

Requests considered: 2689:
 * Avg: 1.165s, 50%: 878ms, 90%: 2.015s, 99%: 5.74s, Fastest: 99ms, Slowest: 8.264s, StdDev: 968ms

----------------------------------------
Operation: STAT - total: 5586, 30.2%, Concurrency: 20, Ran 5m0s, starting 2023-10-16 10:23:57.113 +0500 +05
 * Throughput: 18.63 obj/s

Requests considered: 5587:
 * Avg: 15ms, 50%: 11ms, 90%: 34ms, 99%: 80ms, Fastest: 0s, Slowest: 245ms, StdDev: 17ms
 * First Access: Avg: 14ms, 50%: 10ms, 90%: 33ms, 99%: 69ms, Fastest: 0s, Slowest: 203ms, StdDev: 16ms
 * Last Access: Avg: 15ms, 50%: 11ms, 90%: 34ms, 99%: 74ms, Fastest: 0s, Slowest: 203ms, StdDev: 17ms

Cluster Total: 369.64 MiB/s, 61.77 obj/s, 0 errors over 5m0s.
Total Errors:0.
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Enterprise&lt;/h2&gt; 
&lt;p&gt;For enterprise users, please visit &lt;a href="https://seaweedfs.com"&gt;seaweedfs.com&lt;/a&gt; for the SeaweedFS Enterprise Edition, which has a self-healing storage format with better data protection.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License. You may obtain a copy of the License at&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;http://www.apache.org/licenses/LICENSE-2.0
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.&lt;/p&gt; 
&lt;p&gt;The text of this page is available for modification and reuse under the terms of the Creative Commons Attribution-Sharealike 3.0 Unported License and the GNU Free Documentation License (unversioned, with no invariant sections, front-cover texts, or back-cover texts).&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Stargazers over time&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://starchart.cc/chrislusf/seaweedfs"&gt;&lt;img src="https://starchart.cc/chrislusf/seaweedfs.svg?sanitize=true" alt="Stargazers over time" /&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>pressly/goose</title>
      <link>https://github.com/pressly/goose</link>
      <description>&lt;p&gt;A database migration tool. Supports SQL migrations and Go functions.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;goose&lt;/h1&gt; 
&lt;img align="right" width="125" src="https://raw.githubusercontent.com/pressly/goose/main/assets/goose_logo.png" /&gt; 
&lt;p&gt;&lt;a href="https://github.com/pressly/goose/actions/workflows/ci.yaml"&gt;&lt;img src="https://github.com/pressly/goose/actions/workflows/ci.yaml/badge.svg?sanitize=true" alt="Goose CI" /&gt;&lt;/a&gt; &lt;a href="https://pkg.go.dev/github.com/pressly/goose/v3"&gt;&lt;img src="https://pkg.go.dev/badge/github.com/pressly/goose/v3.svg?sanitize=true" alt="Go Reference" /&gt;&lt;/a&gt; &lt;a href="https://goreportcard.com/report/github.com/pressly/goose/v3"&gt;&lt;img src="https://goreportcard.com/badge/github.com/pressly/goose/v3" alt="Go Report Card" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Goose is a database migration tool. Both a CLI and a library.&lt;/p&gt; 
&lt;p&gt;Manage your &lt;strong&gt;database schema&lt;/strong&gt; by creating incremental SQL changes or Go functions.&lt;/p&gt; 
&lt;h4&gt;Features&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Works against multiple databases: 
  &lt;ul&gt; 
   &lt;li&gt;Postgres, MySQL, SQLite, YDB, ClickHouse, MSSQL, and more.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Supports Go migrations written as plain functions.&lt;/li&gt; 
 &lt;li&gt;Supports &lt;a href="https://pkg.go.dev/embed/"&gt;embedded&lt;/a&gt; migrations.&lt;/li&gt; 
 &lt;li&gt;Out-of-order migrations.&lt;/li&gt; 
 &lt;li&gt;Seeding data.&lt;/li&gt; 
 &lt;li&gt;Environment variable substitution in SQL migrations.&lt;/li&gt; 
 &lt;li&gt;... and more.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Install&lt;/h1&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;go install github.com/pressly/goose/v3/cmd/goose@latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This will install the &lt;code&gt;goose&lt;/code&gt; binary to your &lt;code&gt;$GOPATH/bin&lt;/code&gt; directory.&lt;/p&gt; 
&lt;p&gt;Binary too big? Build a lite version by excluding the drivers you don't need:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;go build -tags='no_postgres no_mysql no_sqlite3 no_ydb' -o goose ./cmd/goose

# Available build tags:
#   no_clickhouse  no_libsql   no_mssql    no_mysql
#   no_postgres    no_sqlite3  no_vertica  no_ydb
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For macOS users &lt;code&gt;goose&lt;/code&gt; is available as a &lt;a href="https://formulae.brew.sh/formula/goose#default"&gt;Homebrew Formulae&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;brew install goose
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See &lt;a href="https://pressly.github.io/goose/installation/"&gt;installation documentation&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;h1&gt;Usage&lt;/h1&gt; 
&lt;details&gt; 
 &lt;summary&gt;Click to show &lt;code&gt;goose help&lt;/code&gt; output&lt;/summary&gt; 
 &lt;pre&gt;&lt;code&gt;Usage: goose [OPTIONS] DRIVER DBSTRING COMMAND

or

Set environment key
GOOSE_DRIVER=DRIVER
GOOSE_DBSTRING=DBSTRING
GOOSE_MIGRATION_DIR=MIGRATION_DIR

Usage: goose [OPTIONS] COMMAND

Drivers:
    postgres
    mysql
    sqlite3
    mssql
    redshift
    tidb
    clickhouse
    ydb
    starrocks

Examples:
    goose sqlite3 ./foo.db status
    goose sqlite3 ./foo.db create init sql
    goose sqlite3 ./foo.db create add_some_column sql
    goose sqlite3 ./foo.db create fetch_user_data go
    goose sqlite3 ./foo.db up

    goose postgres "user=postgres dbname=postgres sslmode=disable" status
    goose mysql "user:password@/dbname?parseTime=true" status
    goose redshift "postgres://user:password@qwerty.us-east-1.redshift.amazonaws.com:5439/db" status
    goose tidb "user:password@/dbname?parseTime=true" status
    goose mssql "sqlserver://user:password@hostname:1433?database=master" status
    goose clickhouse "tcp://127.0.0.1:9000" status
    goose ydb "grpcs://localhost:2135/local?go_query_mode=scripting&amp;amp;go_fake_tx=scripting&amp;amp;go_query_bind=declare,numeric" status
    goose starrocks "user:password@/dbname?parseTime=true&amp;amp;interpolateParams=true" status

    GOOSE_DRIVER=sqlite3 GOOSE_DBSTRING=./foo.db goose status
    GOOSE_DRIVER=sqlite3 GOOSE_DBSTRING=./foo.db goose create init sql
    GOOSE_DRIVER=postgres GOOSE_DBSTRING="user=postgres dbname=postgres sslmode=disable" goose status
    GOOSE_DRIVER=mysql GOOSE_DBSTRING="user:password@/dbname" goose status
    GOOSE_DRIVER=redshift GOOSE_DBSTRING="postgres://user:password@qwerty.us-east-1.redshift.amazonaws.com:5439/db" goose status
    GOOSE_DRIVER=clickhouse GOOSE_DBSTRING="clickhouse://user:password@qwerty.clickhouse.cloud:9440/dbname?secure=true&amp;amp;skip_verify=false" goose status

Options:

  -allow-missing
        applies missing (out-of-order) migrations
  -certfile string
        file path to root CA's certificates in pem format (only support on mysql)
  -dir string
        directory with migration files (default ".", can be set via the GOOSE_MIGRATION_DIR env variable).
  -h    print help
  -no-color
        disable color output (NO_COLOR env variable supported)
  -no-versioning
        apply migration commands with no versioning, in file order, from directory pointed to
  -s    use sequential numbering for new migrations
  -ssl-cert string
        file path to SSL certificates in pem format (only support on mysql)
  -ssl-key string
        file path to SSL key in pem format (only support on mysql)
  -table string
        migrations table name (default "goose_db_version"). If you use a schema that is not `public`, you should set `schemaname.goose_db_version` when running commands.
  -timeout duration
        maximum allowed duration for queries to run; e.g., 1h13m
  -v    enable verbose mode
  -version
        print version

Commands:
    up                   Migrate the DB to the most recent version available
    up-by-one            Migrate the DB up by 1
    up-to VERSION        Migrate the DB to a specific VERSION
    down                 Roll back the version by 1
    down-to VERSION      Roll back to a specific VERSION
    redo                 Re-run the latest migration
    reset                Roll back all migrations
    status               Dump the migration status for the current DB
    version              Print the current version of the database
    create NAME [sql|go] Creates new migration file with the current timestamp
    fix                  Apply sequential ordering to migrations
    validate             Check migration files without running them
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;p&gt;Commonly used commands:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/pressly/goose/main/#create"&gt;create&lt;/a&gt;&lt;span&gt;&amp;nbsp;•&amp;nbsp;&lt;/span&gt; &lt;a href="https://raw.githubusercontent.com/pressly/goose/main/#up"&gt;up&lt;/a&gt;&lt;span&gt;&amp;nbsp;•&amp;nbsp;&lt;/span&gt; &lt;a href="https://raw.githubusercontent.com/pressly/goose/main/#up-to"&gt;up-to&lt;/a&gt;&lt;span&gt;&amp;nbsp;•&amp;nbsp;&lt;/span&gt; &lt;a href="https://raw.githubusercontent.com/pressly/goose/main/#down"&gt;down&lt;/a&gt;&lt;span&gt;&amp;nbsp;•&amp;nbsp;&lt;/span&gt; &lt;a href="https://raw.githubusercontent.com/pressly/goose/main/#down-to"&gt;down-to&lt;/a&gt;&lt;span&gt;&amp;nbsp;•&amp;nbsp;&lt;/span&gt; &lt;a href="https://raw.githubusercontent.com/pressly/goose/main/#status"&gt;status&lt;/a&gt;&lt;span&gt;&amp;nbsp;•&amp;nbsp;&lt;/span&gt; &lt;a href="https://raw.githubusercontent.com/pressly/goose/main/#version"&gt;version&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;create&lt;/h2&gt; 
&lt;p&gt;Create a new SQL migration.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ goose create add_some_column sql
$ Created new file: 20170506082420_add_some_column.sql

$ goose -s create add_some_column sql
$ Created new file: 00001_add_some_column.sql
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Edit the newly created file to define the behavior of your migration.&lt;/p&gt; 
&lt;p&gt;You can also create a Go migration, if you then invoke it with &lt;a href="https://raw.githubusercontent.com/pressly/goose/main/#go-migrations"&gt;your own goose binary&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ goose create fetch_user_data go
$ Created new file: 20170506082421_fetch_user_data.go
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;up&lt;/h2&gt; 
&lt;p&gt;Apply all available migrations.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ goose up
$ OK    001_basics.sql
$ OK    002_next.sql
$ OK    003_and_again.go
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;up-to&lt;/h2&gt; 
&lt;p&gt;Migrate up to a specific version.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ goose up-to 20170506082420
$ OK    20170506082420_create_table.sql
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;up-by-one&lt;/h2&gt; 
&lt;p&gt;Migrate up a single migration from the current version&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ goose up-by-one
$ OK    20170614145246_change_type.sql
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;down&lt;/h2&gt; 
&lt;p&gt;Roll back a single migration from the current version.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ goose down
$ OK    003_and_again.go
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;down-to&lt;/h2&gt; 
&lt;p&gt;Roll back migrations to a specific version.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ goose down-to 20170506082527
$ OK    20170506082527_alter_column.sql
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or, roll back all migrations (careful!):&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ goose down-to 0
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;status&lt;/h2&gt; 
&lt;p&gt;Print the status of all migrations:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ goose status
$   Applied At                  Migration
$   =======================================
$   Sun Jan  6 11:25:03 2013 -- 001_basics.sql
$   Sun Jan  6 11:25:03 2013 -- 002_next.sql
$   Pending                  -- 003_and_again.go
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Note: for MySQL &lt;a href="https://github.com/go-sql-driver/mysql#parsetime"&gt;parseTime flag&lt;/a&gt; must be enabled.&lt;/p&gt; 
&lt;p&gt;Note: for MySQL &lt;a href="https://github.com/go-sql-driver/mysql?tab=readme-ov-file#multistatements"&gt;&lt;code&gt;multiStatements&lt;/code&gt;&lt;/a&gt; must be enabled. This is required when writing multiple queries separated by ';' characters in a single sql file.&lt;/p&gt; 
&lt;h2&gt;version&lt;/h2&gt; 
&lt;p&gt;Print the current version of the database:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ goose version
$ goose: version 002
&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;Environment Variables&lt;/h1&gt; 
&lt;p&gt;If you prefer to use environment variables, instead of passing the driver and database string as arguments, you can set the following environment variables:&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;1. Via environment variables:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;export GOOSE_DRIVER=DRIVER
export GOOSE_DBSTRING=DBSTRING
export GOOSE_MIGRATION_DIR=MIGRATION_DIR
export GOOSE_TABLE=TABLENAME
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;2. Via &lt;code&gt;.env&lt;/code&gt; files with corresponding variables. &lt;code&gt;.env&lt;/code&gt; file example&lt;/strong&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-env"&gt;GOOSE_DRIVER=postgres
GOOSE_DBSTRING=postgres://admin:admin@localhost:5432/admin_db
GOOSE_MIGRATION_DIR=./migrations
GOOSE_TABLE=custom.goose_migrations
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Loading from &lt;code&gt;.env&lt;/code&gt; files is enabled by default. To disable this feature, set the &lt;code&gt;-env=none&lt;/code&gt; flag. If you want to load from a specific file, set the &lt;code&gt;-env&lt;/code&gt; flag to the file path.&lt;/p&gt; 
&lt;p&gt;For more details about environment variables, see the &lt;a href="https://pressly.github.io/goose/documentation/environment-variables/"&gt;official documentation on environment variables&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;Migrations&lt;/h1&gt; 
&lt;p&gt;goose supports migrations written in SQL or in Go.&lt;/p&gt; 
&lt;h2&gt;SQL Migrations&lt;/h2&gt; 
&lt;p&gt;A sample SQL migration looks like:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sql"&gt;-- +goose Up
CREATE TABLE post (
    id int NOT NULL,
    title text,
    body text,
    PRIMARY KEY(id)
);

-- +goose Down
DROP TABLE post;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Each migration file must have exactly one &lt;code&gt;-- +goose Up&lt;/code&gt; annotation. The &lt;code&gt;-- +goose Down&lt;/code&gt; annotation is optional. If the file has both annotations, then the &lt;code&gt;-- +goose Up&lt;/code&gt; annotation &lt;strong&gt;must&lt;/strong&gt; come first.&lt;/p&gt; 
&lt;p&gt;Notice the annotations in the comments. Any statements following &lt;code&gt;-- +goose Up&lt;/code&gt; will be executed as part of a forward migration, and any statements following &lt;code&gt;-- +goose Down&lt;/code&gt; will be executed as part of a rollback.&lt;/p&gt; 
&lt;p&gt;By default, all migrations are run within a transaction. Some statements like &lt;code&gt;CREATE DATABASE&lt;/code&gt;, however, cannot be run within a transaction. You may optionally add &lt;code&gt;-- +goose NO TRANSACTION&lt;/code&gt; to the top of your migration file in order to skip transactions within that specific migration file. Both Up and Down migrations within this file will be run without transactions.&lt;/p&gt; 
&lt;p&gt;By default, SQL statements are delimited by semicolons - in fact, query statements must end with a semicolon to be properly recognized by goose.&lt;/p&gt; 
&lt;p&gt;By default, all migrations are run on the public schema. If you want to use a different schema, specify the schema name using the table option like &lt;code&gt;-table='schemaname.goose_db_version&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;More complex statements (PL/pgSQL) that have semicolons within them must be annotated with &lt;code&gt;-- +goose StatementBegin&lt;/code&gt; and &lt;code&gt;-- +goose StatementEnd&lt;/code&gt; to be properly recognized. For example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sql"&gt;-- +goose Up
-- +goose StatementBegin
CREATE OR REPLACE FUNCTION histories_partition_creation( DATE, DATE )
returns void AS $$
DECLARE
  create_query text;
BEGIN
  FOR create_query IN SELECT
      'CREATE TABLE IF NOT EXISTS histories_'
      || TO_CHAR( d, 'YYYY_MM' )
      || ' ( CHECK( created_at &amp;gt;= timestamp '''
      || TO_CHAR( d, 'YYYY-MM-DD 00:00:00' )
      || ''' AND created_at &amp;lt; timestamp '''
      || TO_CHAR( d + INTERVAL '1 month', 'YYYY-MM-DD 00:00:00' )
      || ''' ) ) inherits ( histories );'
    FROM generate_series( $1, $2, '1 month' ) AS d
  LOOP
    EXECUTE create_query;
  END LOOP;  -- LOOP END
END;         -- FUNCTION END
$$
language plpgsql;
-- +goose StatementEnd
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Goose supports environment variable substitution in SQL migrations through annotations. To enable this feature, use the &lt;code&gt;-- +goose ENVSUB ON&lt;/code&gt; annotation before the queries where you want substitution applied. It stays active until the &lt;code&gt;-- +goose ENVSUB OFF&lt;/code&gt; annotation is encountered. You can use these annotations multiple times within a file.&lt;/p&gt; 
&lt;p&gt;This feature is disabled by default for backward compatibility with existing scripts.&lt;/p&gt; 
&lt;p&gt;For &lt;code&gt;PL/pgSQL&lt;/code&gt; functions or other statements where substitution is not desired, wrap the annotations explicitly around the relevant parts. For example, to exclude escaping the &lt;code&gt;**&lt;/code&gt; characters:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sql"&gt;-- +goose StatementBegin
CREATE OR REPLACE FUNCTION test_func()
RETURNS void AS $$
-- +goose ENVSUB ON
BEGIN
	RAISE NOTICE '${SOME_ENV_VAR}';
END;
-- +goose ENVSUB OFF
$$ LANGUAGE plpgsql;
-- +goose StatementEnd
&lt;/code&gt;&lt;/pre&gt; 
&lt;details&gt; 
 &lt;summary&gt;Supported expansions (click here to expand):&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;code&gt;${VAR}&lt;/code&gt; or $VAR - expands to the value of the environment variable &lt;code&gt;VAR&lt;/code&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;${VAR:-default}&lt;/code&gt; - expands to the value of the environment variable &lt;code&gt;VAR&lt;/code&gt;, or &lt;code&gt;default&lt;/code&gt; if &lt;code&gt;VAR&lt;/code&gt; is unset or null&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;${VAR-default}&lt;/code&gt; - expands to the value of the environment variable &lt;code&gt;VAR&lt;/code&gt;, or &lt;code&gt;default&lt;/code&gt; if &lt;code&gt;VAR&lt;/code&gt; is unset&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;${VAR?err_msg}&lt;/code&gt; - expands to the value of the environment variable &lt;code&gt;VAR&lt;/code&gt;, or prints &lt;code&gt;err_msg&lt;/code&gt; and error if &lt;code&gt;VAR&lt;/code&gt; unset&lt;/li&gt; 
  &lt;li&gt;&lt;del&gt;&lt;code&gt;${VAR:?err_msg}&lt;/code&gt; - expands to the value of the environment variable &lt;code&gt;VAR&lt;/code&gt;, or prints &lt;code&gt;err_msg&lt;/code&gt; and error if &lt;code&gt;VAR&lt;/code&gt; unset or null.&lt;/del&gt; &lt;strong&gt;THIS IS NOT SUPPORTED&lt;/strong&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;See &lt;a href="https://github.com/mfridman/interpolate?tab=readme-ov-file#supported-expansions"&gt;mfridman/interpolate&lt;/a&gt; for more details on supported expansions.&lt;/p&gt; 
&lt;/details&gt; 
&lt;h2&gt;Embedded sql migrations&lt;/h2&gt; 
&lt;p&gt;Go 1.16 introduced new feature: &lt;a href="https://pkg.go.dev/embed/"&gt;compile-time embedding&lt;/a&gt; files into binary and corresponding &lt;a href="https://pkg.go.dev/io/fs/"&gt;filesystem abstraction&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;This feature can be used only for applying existing migrations. Modifying operations such as &lt;code&gt;fix&lt;/code&gt; and &lt;code&gt;create&lt;/code&gt; will continue to operate on OS filesystem even if using embedded files. This is expected behaviour because &lt;code&gt;io/fs&lt;/code&gt; interfaces allows read-only access.&lt;/p&gt; 
&lt;p&gt;Make sure to configure the correct SQL dialect, see &lt;a href="https://raw.githubusercontent.com/pressly/goose/main/dialect.go"&gt;dialect.go&lt;/a&gt; for supported SQL dialects.&lt;/p&gt; 
&lt;p&gt;Example usage, assuming that SQL migrations are placed in the &lt;code&gt;migrations&lt;/code&gt; directory:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;package main

import (
    "database/sql"
    "embed"

    "github.com/pressly/goose/v3"
)

//go:embed migrations/*.sql
var embedMigrations embed.FS

func main() {
    var db *sql.DB
    // setup database

    goose.SetBaseFS(embedMigrations)

    if err := goose.SetDialect("postgres"); err != nil {
        panic(err)
    }

    if err := goose.Up(db, "migrations"); err != nil {
        panic(err)
    }

    // run app
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Note that we pass &lt;code&gt;"migrations"&lt;/code&gt; as directory argument in &lt;code&gt;Up&lt;/code&gt; because embedding saves directory structure.&lt;/p&gt; 
&lt;h2&gt;Go Migrations&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;Create your own goose binary, see &lt;a href="https://raw.githubusercontent.com/pressly/goose/main/examples/go-migrations"&gt;example&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Import &lt;code&gt;github.com/pressly/goose&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Register your migration functions&lt;/li&gt; 
 &lt;li&gt;Include your &lt;code&gt;migrations&lt;/code&gt; package into Go build: in &lt;code&gt;main.go&lt;/code&gt;, &lt;code&gt;import _ "github.com/me/myapp/migrations"&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Run goose command, ie. &lt;code&gt;goose.Up(db *sql.DB, dir string)&lt;/code&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;A &lt;a href="https://raw.githubusercontent.com/pressly/goose/main/examples/go-migrations/00002_rename_root.go"&gt;sample Go migration 00002_users_add_email.go file&lt;/a&gt; looks like:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;package migrations

import (
	"database/sql"

	"github.com/pressly/goose/v3"
)

func init() {
	goose.AddMigration(Up, Down)
}

func Up(tx *sql.Tx) error {
	_, err := tx.Exec("UPDATE users SET username='admin' WHERE username='root';")
	if err != nil {
		return err
	}
	return nil
}

func Down(tx *sql.Tx) error {
	_, err := tx.Exec("UPDATE users SET username='root' WHERE username='admin';")
	if err != nil {
		return err
	}
	return nil
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Note that Go migration files must begin with a numeric value, followed by an underscore, and must not end with &lt;code&gt;*_test.go&lt;/code&gt;.&lt;/p&gt; 
&lt;h1&gt;Hybrid Versioning&lt;/h1&gt; 
&lt;p&gt;Please, read the &lt;a href="https://github.com/pressly/goose/issues/63#issuecomment-428681694"&gt;versioning problem&lt;/a&gt; first.&lt;/p&gt; 
&lt;p&gt;By default, if you attempt to apply missing (out-of-order) migrations &lt;code&gt;goose&lt;/code&gt; will raise an error. However, If you want to apply these missing migrations pass goose the &lt;code&gt;-allow-missing&lt;/code&gt; flag, or if using as a library supply the functional option &lt;code&gt;goose.WithAllowMissing()&lt;/code&gt; to Up, UpTo or UpByOne.&lt;/p&gt; 
&lt;p&gt;However, we strongly recommend adopting a hybrid versioning approach, using both timestamps and sequential numbers. Migrations created during the development process are timestamped and sequential versions are ran on production. We believe this method will prevent the problem of conflicting versions when writing software in a team environment.&lt;/p&gt; 
&lt;p&gt;To help you adopt this approach, &lt;code&gt;create&lt;/code&gt; will use the current timestamp as the migration version. When you're ready to deploy your migrations in a production environment, we also provide a helpful &lt;code&gt;fix&lt;/code&gt; command to convert your migrations into sequential order, while preserving the timestamp ordering. We recommend running &lt;code&gt;fix&lt;/code&gt; in the CI pipeline, and only when the migrations are ready for production.&lt;/p&gt; 
&lt;h2&gt;Credit&lt;/h2&gt; 
&lt;p&gt;The gopher mascot was designed by &lt;a href="https://reneefrench.blogspot.com/"&gt;Renée French&lt;/a&gt; / &lt;a href="https://creativecommons.org/licenses/by/3.0/"&gt;CC 3.0.&lt;/a&gt; For more info check out the &lt;a href="https://go.dev/blog/gopher"&gt;Go Blog&lt;/a&gt;. Adapted by Ellen.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Licensed under &lt;a href="https://raw.githubusercontent.com/pressly/goose/main/LICENSE"&gt;MIT License&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>chaitin/SafeLine</title>
      <link>https://github.com/chaitin/SafeLine</link>
      <description>&lt;p&gt;SafeLine is a self-hosted WAF(Web Application Firewall) / reverse proxy to protect your web apps from attacks and exploits.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/chaitin/SafeLine/main/images/banner.png" width="400" /&gt; &lt;/p&gt; 
&lt;h4 align="center"&gt; SafeLine - Make your web apps secure &lt;/h4&gt; 
&lt;p align="center"&gt; &lt;a target="_blank" href="https://ly.safepoint.cloud/laA8asp"&gt;🏠 Website&lt;/a&gt; &amp;nbsp; | &amp;nbsp; &lt;a target="_blank" href="https://ly.safepoint.cloud/w2AeHhb"&gt;📖 Docs&lt;/a&gt; &amp;nbsp; | &amp;nbsp; &lt;a target="_blank" href="https://ly.safepoint.cloud/hSMd4SH"&gt;🔍 Live Demo&lt;/a&gt; &amp;nbsp; | &amp;nbsp; &lt;a target="_blank" href="https://discord.gg/SVnZGzHFvn"&gt;🙋‍♂️ Discord&lt;/a&gt; &amp;nbsp; | &amp;nbsp; &lt;a target="_blank" href="https://raw.githubusercontent.com/chaitin/SafeLine/main/README_CN.md"&gt;中文版&lt;/a&gt; &lt;/p&gt; 
&lt;h2&gt;👋 INTRODUCTION&lt;/h2&gt; 
&lt;p&gt;SafeLine is a self-hosted &lt;strong&gt;&lt;code&gt;WAF(Web Application Firewall)&lt;/code&gt;&lt;/strong&gt; to protect your web apps from attacks and exploits.&lt;/p&gt; 
&lt;p&gt;A web application firewall helps protect web apps by filtering and monitoring HTTP traffic between a web application and the Internet. It typically protects web apps from attacks such as &lt;code&gt;SQL injection&lt;/code&gt;, &lt;code&gt;XSS&lt;/code&gt;, &lt;code&gt;code injection&lt;/code&gt;, &lt;code&gt;os command injection&lt;/code&gt;, &lt;code&gt;CRLF injection&lt;/code&gt;, &lt;code&gt;ldap injection&lt;/code&gt;, &lt;code&gt;xpath injection&lt;/code&gt;, &lt;code&gt;RCE&lt;/code&gt;, &lt;code&gt;XXE&lt;/code&gt;, &lt;code&gt;SSRF&lt;/code&gt;, &lt;code&gt;path traversal&lt;/code&gt;, &lt;code&gt;backdoor&lt;/code&gt;, &lt;code&gt;bruteforce&lt;/code&gt;, &lt;code&gt;http-flood&lt;/code&gt;, &lt;code&gt;bot abused&lt;/code&gt;, among others.&lt;/p&gt; 
&lt;h4&gt;💡 How It Works&lt;/h4&gt; 
&lt;img src="https://raw.githubusercontent.com/chaitin/SafeLine/main/images/how-it-works.png" width="800" /&gt; 
&lt;p&gt;By deploying a WAF in front of a web application, a shield is placed between the web application and the Internet. While a proxy server protects a client machine’s identity by using an intermediary, a WAF is a type of reverse-proxy, protecting the server from exposure by having clients pass through the WAF before reaching the server.&lt;/p&gt; 
&lt;p&gt;A WAF protects your web apps by filtering, monitoring, and blocking any malicious HTTP/S traffic traveling to the web application, and prevents any unauthorized data from leaving the app. It does this by adhering to a set of policies that help determine what traffic is malicious and what traffic is safe. Just as a proxy server acts as an intermediary to protect the identity of a client, a WAF operates in similar fashion but acting as a reverse proxy intermediary that protects the web app server from a potentially malicious client.&lt;/p&gt; 
&lt;p&gt;its core capabilities include:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Defenses for web attacks&lt;/li&gt; 
 &lt;li&gt;Proactive bot abused defense&lt;/li&gt; 
 &lt;li&gt;HTML &amp;amp; JS code encryption&lt;/li&gt; 
 &lt;li&gt;IP-based rate limiting&lt;/li&gt; 
 &lt;li&gt;Web Access Control List&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;⚡️ Screenshots&lt;/h4&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;&lt;img src="https://raw.githubusercontent.com/chaitin/SafeLine/main/images/screenshot-1.png" width="370" /&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;img src="https://raw.githubusercontent.com/chaitin/SafeLine/main/images/screenshot-2.png" width="370" /&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/chaitin/SafeLine/main/images/screenshot-3.png" width="370" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/chaitin/SafeLine/main/images/screenshot-4.png" width="370" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Get &lt;a href="https://demo.waf.chaitin.com:9443/"&gt;Live Demo&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;🔥 FEATURES&lt;/h2&gt; 
&lt;p&gt;List of the main features as follows:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;Block Web Attacks&lt;/code&gt;&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;It defenses for all of web attacks, such as &lt;code&gt;SQL injection&lt;/code&gt;, &lt;code&gt;XSS&lt;/code&gt;, &lt;code&gt;code injection&lt;/code&gt;, &lt;code&gt;os command injection&lt;/code&gt;, &lt;code&gt;CRLF injection&lt;/code&gt;, &lt;code&gt;XXE&lt;/code&gt;, &lt;code&gt;SSRF&lt;/code&gt;, &lt;code&gt;path traversal&lt;/code&gt; and so on.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;Rate Limiting&lt;/code&gt;&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Defend your web apps against &lt;code&gt;DoS attacks&lt;/code&gt;, &lt;code&gt;bruteforce attempts&lt;/code&gt;, &lt;code&gt;traffic surges&lt;/code&gt;, and other types of abuse by throttling traffic that exceeds defined limits.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;Anti-Bot Challenge&lt;/code&gt;&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Anti-Bot challenges to protect your website from &lt;code&gt;bot attacks&lt;/code&gt;, humen users will be allowed, crawlers and bots will be blocked.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;Authentication Challenge&lt;/code&gt;&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;When authentication challenge turned on, visitors need to enter the password, otherwise they will be blocked.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;Dynamic Protection&lt;/code&gt;&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;When dynamic protection turned on, html and js codes in your web server will be dynamically encrypted by each time you visit.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;🧩 Showcases&lt;/h4&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;&lt;/th&gt; 
   &lt;th&gt;Legitimate User&lt;/th&gt; 
   &lt;th&gt;Malicious User&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;&lt;code&gt;Block Web Attacks&lt;/code&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/chaitin/SafeLine/main/images/skeleton.png" width="270" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/chaitin/SafeLine/main/images/blocked-for-attack-detected.png" width="270" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;&lt;code&gt;Rate Limiting&lt;/code&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/chaitin/SafeLine/main/images/skeleton.png" width="270" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/chaitin/SafeLine/main/images/blocked-for-access-too-fast.png" width="270" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;&lt;code&gt;Anti-Bot Challenge&lt;/code&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/chaitin/SafeLine/main/images/captcha-1.gif" width="270" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/chaitin/SafeLine/main/images/captcha-2.gif" width="270" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;&lt;code&gt;Auth Challenge&lt;/code&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/chaitin/SafeLine/main/images/auth-1.gif" width="270" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/chaitin/SafeLine/main/images/auth-2.gif" width="270" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;&lt;code&gt;HTML Dynamic Protection&lt;/code&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/chaitin/SafeLine/main/images/dynamic-html-1.png" width="270" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/chaitin/SafeLine/main/images/dynamic-html-2.png" width="270" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;&lt;code&gt;JS Dynamic Protection&lt;/code&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/chaitin/SafeLine/main/images/dynamic-js-1.png" width="270" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/chaitin/SafeLine/main/images/dynamic-js-2.png" width="270" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;🚀 Quickstart&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!WARNING] 中国大陆用户安装国际版可能会导致无法连接云服务，请查看 &lt;a href="https://docs.waf-ce.chaitin.cn/zh/%E4%B8%8A%E6%89%8B%E6%8C%87%E5%8D%97/%E5%AE%89%E8%A3%85%E9%9B%B7%E6%B1%A0"&gt;中文版安装文档&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;📦 Installing&lt;/h4&gt; 
&lt;p&gt;Information on how to install SafeLine can be found in the &lt;a href="https://docs.waf.chaitin.com/en/GetStarted/Deploy"&gt;Install Guide&lt;/a&gt;&lt;/p&gt; 
&lt;h4&gt;⚙️ Protecting Web Apps&lt;/h4&gt; 
&lt;p&gt;to see &lt;a href="https://docs.waf.chaitin.com/en/GetStarted/AddApplication"&gt;Configuration&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;📋 More Informations&lt;/h2&gt; 
&lt;h4&gt;Effect Evaluation&lt;/h4&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Metric&lt;/th&gt; 
   &lt;th&gt;ModSecurity, Level 1&lt;/th&gt; 
   &lt;th&gt;CloudFlare, Free&lt;/th&gt; 
   &lt;th&gt;SafeLine, Balance&lt;/th&gt; 
   &lt;th&gt;SafeLine, Strict&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Total Samples&lt;/td&gt; 
   &lt;td&gt;33669&lt;/td&gt; 
   &lt;td&gt;33669&lt;/td&gt; 
   &lt;td&gt;33669&lt;/td&gt; 
   &lt;td&gt;33669&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Detection&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;69.74%&lt;/td&gt; 
   &lt;td&gt;10.70%&lt;/td&gt; 
   &lt;td&gt;71.65%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;76.17%&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;False Positive&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;17.58%&lt;/td&gt; 
   &lt;td&gt;0.07%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;0.07%&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;0.22%&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Accuracy&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;82.20%&lt;/td&gt; 
   &lt;td&gt;98.40%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;99.45%&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;99.38%&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h4&gt;Is SafeLine Production-Ready?&lt;/h4&gt; 
&lt;p&gt;Yes, SafeLine is production-ready.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Over 180,000 installations worldwide&lt;/li&gt; 
 &lt;li&gt;Protecting over 1,000,000 Websites&lt;/li&gt; 
 &lt;li&gt;Handling over 30,000,000,000 HTTP Requests Daily&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;🙋‍♂️ Community&lt;/h4&gt; 
&lt;p&gt;Join our &lt;a href="https://discord.gg/SVnZGzHFvn"&gt;Discord&lt;/a&gt; to get community support, the core team members are identified by the STAFF role in Discord.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;channel &lt;a href="https://discord.com/channels/1243085666485534830/1243120292822253598"&gt;#feedback&lt;/a&gt;: for new features discussion.&lt;/li&gt; 
 &lt;li&gt;channel &lt;a href="https://discord.com/channels/1243085666485534830/1263761679619981413"&gt;#FAQ&lt;/a&gt;: for FAQ.&lt;/li&gt; 
 &lt;li&gt;channel &lt;a href="https://discord.com/channels/1243085666485534830/1243115843919806486"&gt;#general&lt;/a&gt;: for any other questions.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Several contact options exist for our community, the primary one being Discord. These are in addition to GitHub issues for creating a new issue.&lt;/p&gt; 
&lt;p align="left"&gt; &lt;a target="_blank" href="https://discord.gg/SVnZGzHFvn"&gt;&lt;img src="https://img.shields.io/badge/Discord-5865F2?style=flat&amp;amp;logo=discord&amp;amp;logoColor=white" /&gt;&lt;/a&gt; &amp;nbsp; &lt;a target="_blank" href="https://x.com/safeline_waf"&gt;&lt;img src="https://img.shields.io/badge/X.com-000000?style=flat&amp;amp;logo=x&amp;amp;logoColor=white" /&gt;&lt;/a&gt; &amp;nbsp; &lt;a target="_blank" href="https://raw.githubusercontent.com/chaitin/SafeLine/main/images/wechat.png"&gt;&lt;img src="https://img.shields.io/badge/WeChat-07C160?style=flat&amp;amp;logo=wechat&amp;amp;logoColor=white" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;h4&gt;💪 PRO Edition&lt;/h4&gt; 
&lt;p&gt;Coming soon!&lt;/p&gt; 
&lt;h4&gt;📝 License&lt;/h4&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/chaitin/SafeLine/main/LICENSE.md"&gt;LICENSE&lt;/a&gt; for details.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>cli/cli</title>
      <link>https://github.com/cli/cli</link>
      <description>&lt;p&gt;GitHub’s official command line tool&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;GitHub CLI&lt;/h1&gt; 
&lt;p&gt;&lt;code&gt;gh&lt;/code&gt; is GitHub on the command line. It brings pull requests, issues, and other GitHub concepts to the terminal next to where you are already working with &lt;code&gt;git&lt;/code&gt; and your code.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://user-images.githubusercontent.com/98482/84171218-327e7a80-aa40-11ea-8cd1-5177fc2d0e72.png" alt="screenshot of gh pr status" /&gt;&lt;/p&gt; 
&lt;p&gt;GitHub CLI is supported for users on GitHub.com, GitHub Enterprise Cloud, and GitHub Enterprise Server 2.20+ with support for macOS, Windows, and Linux.&lt;/p&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;For &lt;a href="https://raw.githubusercontent.com/cli/cli/trunk/#installation"&gt;installation options see below&lt;/a&gt;, for usage instructions &lt;a href="https://cli.github.com/manual/"&gt;see the manual&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;If anything feels off or if you feel that some functionality is missing, please check out the &lt;a href="https://raw.githubusercontent.com/cli/cli/trunk/.github/CONTRIBUTING.md"&gt;contributing page&lt;/a&gt;. There you will find instructions for sharing your feedback, building the tool locally, and submitting pull requests to the project.&lt;/p&gt; 
&lt;p&gt;If you are a hubber and are interested in shipping new commands for the CLI, check out our &lt;a href="https://raw.githubusercontent.com/cli/cli/trunk/docs/working-with-us.md"&gt;doc on internal contributions&lt;/a&gt;&lt;/p&gt; 
&lt;!-- this anchor is linked to from elsewhere, so avoid renaming it --&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;h3&gt;&lt;a href="https://raw.githubusercontent.com/cli/cli/trunk/docs/install_macos.md"&gt;macOS&lt;/a&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/cli/cli/trunk/docs/install_macos.md#homebrew"&gt;Homebrew&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/cli/cli/trunk/docs/install_macos.md#precompiled-binaries"&gt;Precompiled binaries&lt;/a&gt; on &lt;a href="https://github.com/cli/cli/releases/latest"&gt;releases page&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For additional macOS packages and installers, see &lt;a href="https://raw.githubusercontent.com/cli/cli/trunk/docs/install_macos.md#community-unofficial"&gt;community-supported docs&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;a href="https://raw.githubusercontent.com/cli/cli/trunk/docs/install_linux.md"&gt;Linux &amp;amp; Unix&lt;/a&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/cli/cli/trunk/docs/install_linux.md#debian"&gt;Debian, Raspberry Pi, Ubuntu&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/cli/cli/trunk/docs/install_linux.md#rpm"&gt;Amazon Linux, CentOS, Fedora, openSUSE, RHEL, SUSE&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/cli/cli/trunk/docs/install_linux.md#precompiled-binaries"&gt;Precompiled binaries&lt;/a&gt; on &lt;a href="https://github.com/cli/cli/releases/latest"&gt;releases page&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For additional Linux &amp;amp; Unix packages and installers, see &lt;a href="https://raw.githubusercontent.com/cli/cli/trunk/docs/install_linux.md#community-unofficial"&gt;community-supported docs&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;a href="https://raw.githubusercontent.com/cli/cli/trunk/docs/install_windows.md"&gt;Windows&lt;/a&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/cli/cli/trunk/docs/install_windows.md#winget"&gt;WinGet&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/cli/cli/trunk/docs/install_windows.md#precompiled-binaries"&gt;Precompiled binaries&lt;/a&gt; on &lt;a href="https://github.com/cli/cli/releases/latest"&gt;releases page&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For additional Windows packages and installers, see &lt;a href="https://raw.githubusercontent.com/cli/cli/trunk/docs/install_windows.md#community-unofficial"&gt;community-supported docs&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Build from source&lt;/h3&gt; 
&lt;p&gt;See here on how to &lt;a href="https://raw.githubusercontent.com/cli/cli/trunk/docs/install_source.md"&gt;build GitHub CLI from source&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;GitHub Codespaces&lt;/h3&gt; 
&lt;p&gt;To add GitHub CLI to your codespace, add the following to your &lt;a href="https://docs.github.com/en/codespaces/setting-up-your-project-for-codespaces/adding-features-to-a-devcontainer-file"&gt;devcontainer file&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;"features": {
  "ghcr.io/devcontainers/features/github-cli:1": {}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;GitHub Actions&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://docs.github.com/en/actions/using-github-hosted-runners/about-github-hosted-runners"&gt;GitHub-hosted runners&lt;/a&gt; have the GitHub CLI pre-installed, which is updated weekly.&lt;/p&gt; 
&lt;p&gt;If a specific version is needed, your GitHub Actions workflow will need to install it based on the &lt;a href="https://raw.githubusercontent.com/cli/cli/trunk/#macos"&gt;macOS&lt;/a&gt;, &lt;a href="https://raw.githubusercontent.com/cli/cli/trunk/#linux--unix"&gt;Linux &amp;amp; Unix&lt;/a&gt;, or &lt;a href="https://raw.githubusercontent.com/cli/cli/trunk/#windows"&gt;Windows&lt;/a&gt; instructions above.&lt;/p&gt; 
&lt;p&gt;For information on all pre-installed tools, see &lt;a href="https://github.com/actions/runner-images"&gt;&lt;code&gt;actions/runner-images&lt;/code&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Verification of binaries&lt;/h3&gt; 
&lt;p&gt;Since version 2.50.0, &lt;code&gt;gh&lt;/code&gt; has been producing &lt;a href="https://github.blog/changelog/2024-06-25-artifact-attestations-is-generally-available/"&gt;Build Provenance Attestation&lt;/a&gt;, enabling a cryptographically verifiable paper-trail back to the origin GitHub repository, git revision, and build instructions used. The build provenance attestations are signed and rely on Public Good &lt;a href="https://www.sigstore.dev/"&gt;Sigstore&lt;/a&gt; for PKI.&lt;/p&gt; 
&lt;p&gt;There are two common ways to verify a downloaded release, depending on whether &lt;code&gt;gh&lt;/code&gt; is already installed or not. If &lt;code&gt;gh&lt;/code&gt; is installed, it's trivial to verify a new release:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Option 1: Using &lt;code&gt;gh&lt;/code&gt; if already installed:&lt;/strong&gt;&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;$ gh at verify -R cli/cli gh_2.62.0_macOS_arm64.zip
Loaded digest sha256:fdb77f31b8a6dd23c3fd858758d692a45f7fc76383e37d475bdcae038df92afc for file://gh_2.62.0_macOS_arm64.zip
Loaded 1 attestation from GitHub API
✓ Verification succeeded!

sha256:fdb77f31b8a6dd23c3fd858758d692a45f7fc76383e37d475bdcae038df92afc was attested by:
REPO     PREDICATE_TYPE                  WORKFLOW
cli/cli  https://slsa.dev/provenance/v1  .github/workflows/deployment.yml@refs/heads/trunk
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Option 2: Using Sigstore &lt;a href="https://github.com/sigstore/cosign"&gt;&lt;code&gt;cosign&lt;/code&gt;&lt;/a&gt;:&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;To perform this, download the &lt;a href="https://github.com/cli/cli/attestations"&gt;attestation&lt;/a&gt; for the downloaded release and use cosign to verify the authenticity of the downloaded release:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;$ cosign verify-blob-attestation --bundle cli-cli-attestation-3120304.sigstore.json \
      --new-bundle-format \
      --certificate-oidc-issuer="https://token.actions.githubusercontent.com" \
      --certificate-identity="https://github.com/cli/cli/.github/workflows/deployment.yml@refs/heads/trunk" \
      gh_2.62.0_macOS_arm64.zip
Verified OK
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Comparison with hub&lt;/h2&gt; 
&lt;p&gt;For many years, &lt;a href="https://github.com/github/hub"&gt;hub&lt;/a&gt; was the unofficial GitHub CLI tool. &lt;code&gt;gh&lt;/code&gt; is a new project that helps us explore what an official GitHub CLI tool can look like with a fundamentally different design. While both tools bring GitHub to the terminal, &lt;code&gt;hub&lt;/code&gt; behaves as a proxy to &lt;code&gt;git&lt;/code&gt;, and &lt;code&gt;gh&lt;/code&gt; is a standalone tool. Check out our &lt;a href="https://raw.githubusercontent.com/cli/cli/trunk/docs/gh-vs-hub.md"&gt;more detailed explanation&lt;/a&gt; to learn more.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>kubernetes-sigs/external-dns</title>
      <link>https://github.com/kubernetes-sigs/external-dns</link>
      <description>&lt;p&gt;Configure external DNS servers dynamically from Kubernetes resources&lt;/p&gt;&lt;hr&gt;&lt;hr /&gt; 
&lt;p&gt;hide:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;toc&lt;/li&gt; 
 &lt;li&gt;navigation&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/kubernetes-sigs/external-dns/master/docs/img/external-dns.png" width="40%" align="center" alt="ExternalDNS" /&gt; &lt;/p&gt; 
&lt;h1&gt;ExternalDNS&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://github.com/kubernetes-sigs/external-dns/actions"&gt;&lt;img src="https://github.com/kubernetes-sigs/external-dns/workflows/Go/badge.svg?sanitize=true" alt="Build Status" /&gt;&lt;/a&gt; &lt;a href="https://coveralls.io/github/kubernetes-sigs/external-dns"&gt;&lt;img src="https://coveralls.io/repos/github/kubernetes-sigs/external-dns/badge.svg?sanitize=true" alt="Coverage Status" /&gt;&lt;/a&gt; &lt;a href="https://github.com/kubernetes-sigs/external-dns/releases"&gt;&lt;img src="https://img.shields.io/github/release/kubernetes-sigs/external-dns.svg?sanitize=true" alt="GitHub release" /&gt;&lt;/a&gt; &lt;a href="https://godoc.org/github.com/kubernetes-sigs/external-dns"&gt;&lt;img src="https://godoc.org/github.com/kubernetes-sigs/external-dns?status.svg?sanitize=true" alt="go-doc" /&gt;&lt;/a&gt; &lt;a href="https://goreportcard.com/report/github.com/kubernetes-sigs/external-dns"&gt;&lt;img src="https://goreportcard.com/badge/github.com/kubernetes-sigs/external-dns" alt="Go Report Card" /&gt;&lt;/a&gt; &lt;a href="https://kubernetes-sigs.github.io/external-dns/"&gt;&lt;img src="https://img.shields.io/badge/docs-external--dns-blue" alt="ExternalDNS docs" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;ExternalDNS synchronizes exposed Kubernetes Services and Ingresses with DNS providers.&lt;/p&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;This README is a part of the complete documentation, available &lt;a href="https://kubernetes-sigs.github.io/external-dns/"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;What It Does&lt;/h2&gt; 
&lt;p&gt;Inspired by &lt;a href="https://github.com/kubernetes/dns"&gt;Kubernetes DNS&lt;/a&gt;, Kubernetes' cluster-internal DNS server, ExternalDNS makes Kubernetes resources discoverable via public DNS servers. Like KubeDNS, it retrieves a list of resources (Services, Ingresses, etc.) from the &lt;a href="https://kubernetes.io/docs/api/"&gt;Kubernetes API&lt;/a&gt; to determine a desired list of DNS records. &lt;em&gt;Unlike&lt;/em&gt; KubeDNS, however, it's not a DNS server itself, but merely configures other DNS providers accordingly—e.g. &lt;a href="https://aws.amazon.com/route53/"&gt;AWS Route 53&lt;/a&gt; or &lt;a href="https://cloud.google.com/dns/docs/"&gt;Google Cloud DNS&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;In a broader sense, ExternalDNS allows you to control DNS records dynamically via Kubernetes resources in a DNS provider-agnostic way.&lt;/p&gt; 
&lt;p&gt;The &lt;a href="https://raw.githubusercontent.com/kubernetes-sigs/external-dns/master/docs/faq.md"&gt;FAQ&lt;/a&gt; contains additional information and addresses several questions about key concepts of ExternalDNS.&lt;/p&gt; 
&lt;p&gt;To see ExternalDNS in action, have a look at this &lt;a href="https://www.youtube.com/watch?v=9HQ2XgL9YVI"&gt;video&lt;/a&gt; or read this &lt;a href="https://codemine.be/posts/20190125-devops-eks-externaldns/"&gt;blogpost&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;The Latest Release&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/kubernetes-sigs/external-dns/master/docs/release.md"&gt;current release process&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;ExternalDNS allows you to keep selected zones (via &lt;code&gt;--domain-filter&lt;/code&gt;) synchronized with Ingresses and Services of &lt;code&gt;type=LoadBalancer&lt;/code&gt; and nodes in various DNS providers:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://cloud.google.com/dns/docs/"&gt;Google Cloud DNS&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://aws.amazon.com/route53/"&gt;AWS Route 53&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.aws.amazon.com/cloud-map/"&gt;AWS Cloud Map&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://azure.microsoft.com/en-us/services/dns"&gt;AzureDNS&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.civo.com"&gt;Civo&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.cloudflare.com/dns"&gt;CloudFlare&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.digitalocean.com/products/networking"&gt;DigitalOcean&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://dnsimple.com/"&gt;DNSimple&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.powerdns.com/"&gt;PowerDNS&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://coredns.io/"&gt;CoreDNS&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.exoscale.com/dns/"&gt;Exoscale&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.cloud.oracle.com/iaas/Content/DNS/Concepts/dnszonemanagement.htm"&gt;Oracle Cloud Infrastructure DNS&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.linode.com/docs/networking/dns/"&gt;Linode DNS&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://tools.ietf.org/html/rfc2136"&gt;RFC2136&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://ns1.com/"&gt;NS1&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.transip.eu/domain-name/"&gt;TransIP&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.ovhcloud.com"&gt;OVHcloud&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.scaleway.com"&gt;Scaleway&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://learn.akamai.com/en-us/products/cloud_security/edge_dns.html"&gt;Akamai Edge DNS&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.godaddy.com"&gt;GoDaddy&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.gandi.net"&gt;Gandi&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.ibm.com/cloud/dns"&gt;IBM Cloud DNS&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.plural.sh/"&gt;Plural&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pi-hole.net/"&gt;Pi-hole&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.alibabacloud.com/help/en/dns"&gt;Alibaba Cloud DNS&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.myrasecurity.com/en/saasp/application-security/secure-dns/"&gt;Myra Security DNS&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;ExternalDNS is, by default, aware of the records it is managing, therefore it can safely manage non-empty hosted zones. We strongly encourage you to set &lt;code&gt;--txt-owner-id&lt;/code&gt; to a unique value that doesn't change for the lifetime of your cluster. You might also want to run ExternalDNS in a dry run mode (&lt;code&gt;--dry-run&lt;/code&gt; flag) to see the changes to be submitted to your DNS Provider API.&lt;/p&gt; 
&lt;p&gt;Note that all flags can be replaced with environment variables; for instance, &lt;code&gt;--dry-run&lt;/code&gt; could be replaced with &lt;code&gt;EXTERNAL_DNS_DRY_RUN=1&lt;/code&gt;.&lt;/p&gt; 
&lt;h2&gt;New providers&lt;/h2&gt; 
&lt;p&gt;No new provider will be added to ExternalDNS &lt;em&gt;in-tree&lt;/em&gt;.&lt;/p&gt; 
&lt;p&gt;ExternalDNS has introduced a webhook system, which can be used to add a new provider. See PR #3063 for all the discussions about it.&lt;/p&gt; 
&lt;p&gt;Some known providers using webhooks are the ones in the table below.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: The maintainers of ExternalDNS have not reviewed those providers, use them at your own risk and following the license and usage recommendations provided by the respective projects. The maintainers of ExternalDNS take no responsibility for any issue or damage from the usage of any externally developed webhook.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Provider&lt;/th&gt; 
   &lt;th&gt;Repo&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Abion&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/abiondevelopment/external-dns-webhook-abion"&gt;https://github.com/abiondevelopment/external-dns-webhook-abion&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Adguard Home Provider&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/muhlba91/external-dns-provider-adguard"&gt;https://github.com/muhlba91/external-dns-provider-adguard&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Anexia&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/anexia/k8s-external-dns-webhook"&gt;https://github.com/anexia/k8s-external-dns-webhook&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Bizfly Cloud&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/bizflycloud/external-dns-bizflycloud-webhook"&gt;https://github.com/bizflycloud/external-dns-bizflycloud-webhook&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ClouDNS&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/rwunderer/external-dns-cloudns-webhook"&gt;https://github.com/rwunderer/external-dns-cloudns-webhook&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;deSEC&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/michelangelomo/external-dns-desec-provider"&gt;https://github.com/michelangelomo/external-dns-desec-provider&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Dreamhost&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/asymingt/external-dns-dreamhost-webhook"&gt;https://github.com/asymingt/external-dns-dreamhost-webhook&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Efficient IP&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/EfficientIP-Labs/external-dns-efficientip-webhook"&gt;https://github.com/EfficientIP-Labs/external-dns-efficientip-webhook&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Gcore&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/G-Core/external-dns-gcore-webhook"&gt;https://github.com/G-Core/external-dns-gcore-webhook&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GleSYS&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/glesys/external-dns-glesys"&gt;https://github.com/glesys/external-dns-glesys&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Hetzner&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/mconfalonieri/external-dns-hetzner-webhook"&gt;https://github.com/mconfalonieri/external-dns-hetzner-webhook&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Huawei Cloud&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/setoru/external-dns-huaweicloud-webhook"&gt;https://github.com/setoru/external-dns-huaweicloud-webhook&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;IONOS&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/ionos-cloud/external-dns-ionos-webhook"&gt;https://github.com/ionos-cloud/external-dns-ionos-webhook&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Infoblox&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/AbsaOSS/external-dns-infoblox-webhook"&gt;https://github.com/AbsaOSS/external-dns-infoblox-webhook&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Mikrotik&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/mirceanton/external-dns-provider-mikrotik"&gt;https://github.com/mirceanton/external-dns-provider-mikrotik&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Myra Security&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/Myra-Security-GmbH/external-dns-myrasec-webhook"&gt;https://github.com/Myra-Security-GmbH/external-dns-myrasec-webhook&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Netcup&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/mrueg/external-dns-netcup-webhook"&gt;https://github.com/mrueg/external-dns-netcup-webhook&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Netic&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/neticdk/external-dns-tidydns-webhook"&gt;https://github.com/neticdk/external-dns-tidydns-webhook&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;OpenStack Designate&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/inovex/external-dns-designate-webhook"&gt;https://github.com/inovex/external-dns-designate-webhook&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;OpenWRT&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/renanqts/external-dns-openwrt-webhook"&gt;https://github.com/renanqts/external-dns-openwrt-webhook&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;RouterOS&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/benfiola/external-dns-routeros-provider"&gt;https://github.com/benfiola/external-dns-routeros-provider&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;SAKURA Cloud&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/sacloud/external-dns-sacloud-webhook"&gt;https://github.com/sacloud/external-dns-sacloud-webhook&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;STACKIT&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/stackitcloud/external-dns-stackit-webhook"&gt;https://github.com/stackitcloud/external-dns-stackit-webhook&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Unbound&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/guillomep/external-dns-unbound-webhook"&gt;https://github.com/guillomep/external-dns-unbound-webhook&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Unifi&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/kashalls/external-dns-unifi-webhook"&gt;https://github.com/kashalls/external-dns-unifi-webhook&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Volcengine Cloud&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/volcengine/external-dns-volcengine-webhook"&gt;https://github.com/volcengine/external-dns-volcengine-webhook&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Vultr&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/vultr/external-dns-vultr-webhook"&gt;https://github.com/vultr/external-dns-vultr-webhook&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Yandex Cloud&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/ismailbaskin/external-dns-yandex-webhook/"&gt;https://github.com/ismailbaskin/external-dns-yandex-webhook/&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Status of in-tree providers&lt;/h2&gt; 
&lt;p&gt;ExternalDNS supports multiple DNS providers which have been implemented by the &lt;a href="https://github.com/kubernetes-sigs/external-dns/graphs/contributors"&gt;ExternalDNS contributors&lt;/a&gt;. Maintaining all of those in a central repository is a challenge, which introduces lots of toil and potential risks.&lt;/p&gt; 
&lt;p&gt;This mean that &lt;code&gt;external-dns&lt;/code&gt; has begun the process to move providers out of tree. See #4347 for more details. Those who are interested can create a webhook provider based on an &lt;em&gt;in-tree&lt;/em&gt; provider and after submit a PR to reference it here.&lt;/p&gt; 
&lt;p&gt;We define the following stability levels for providers:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Stable&lt;/strong&gt;: Used for smoke tests before a release, used in production and maintainers are active.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Beta&lt;/strong&gt;: Community supported, well tested, but maintainers have no access to resources to execute integration tests on the real platform and/or are not using it in production.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Alpha&lt;/strong&gt;: Community provided with no support from the maintainers apart from reviewing PRs.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The following table clarifies the current status of the providers according to the aforementioned stability levels:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Provider&lt;/th&gt; 
   &lt;th&gt;Status&lt;/th&gt; 
   &lt;th&gt;Maintainers&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Google Cloud DNS&lt;/td&gt; 
   &lt;td&gt;Stable&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;AWS Route 53&lt;/td&gt; 
   &lt;td&gt;Stable&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;AWS Cloud Map&lt;/td&gt; 
   &lt;td&gt;Beta&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Akamai Edge DNS&lt;/td&gt; 
   &lt;td&gt;Beta&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;AzureDNS&lt;/td&gt; 
   &lt;td&gt;Stable&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Civo&lt;/td&gt; 
   &lt;td&gt;Alpha&lt;/td&gt; 
   &lt;td&gt;@alejandrojnm&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;CloudFlare&lt;/td&gt; 
   &lt;td&gt;Beta&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;DigitalOcean&lt;/td&gt; 
   &lt;td&gt;Alpha&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;DNSimple&lt;/td&gt; 
   &lt;td&gt;Alpha&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;PowerDNS&lt;/td&gt; 
   &lt;td&gt;Alpha&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;CoreDNS&lt;/td&gt; 
   &lt;td&gt;Alpha&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Exoscale&lt;/td&gt; 
   &lt;td&gt;Alpha&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Oracle Cloud Infrastructure DNS&lt;/td&gt; 
   &lt;td&gt;Alpha&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Linode DNS&lt;/td&gt; 
   &lt;td&gt;Alpha&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;RFC2136&lt;/td&gt; 
   &lt;td&gt;Alpha&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;NS1&lt;/td&gt; 
   &lt;td&gt;Alpha&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;TransIP&lt;/td&gt; 
   &lt;td&gt;Alpha&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;OVHcloud&lt;/td&gt; 
   &lt;td&gt;Beta&lt;/td&gt; 
   &lt;td&gt;@rbeuque74&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Scaleway DNS&lt;/td&gt; 
   &lt;td&gt;Alpha&lt;/td&gt; 
   &lt;td&gt;@Sh4d1&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GoDaddy&lt;/td&gt; 
   &lt;td&gt;Alpha&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Gandi&lt;/td&gt; 
   &lt;td&gt;Alpha&lt;/td&gt; 
   &lt;td&gt;@packi&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Plural&lt;/td&gt; 
   &lt;td&gt;Alpha&lt;/td&gt; 
   &lt;td&gt;@michaeljguarino&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Pi-hole&lt;/td&gt; 
   &lt;td&gt;Alpha&lt;/td&gt; 
   &lt;td&gt;@tinyzimmer&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Alibaba Cloud DNS&lt;/td&gt; 
   &lt;td&gt;Alpha&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Kubernetes version compatibility&lt;/h2&gt; 
&lt;p&gt;Breaking changes were introduced in external-dns in the following versions:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/kubernetes-sigs/external-dns/releases/tag/v0.10.0"&gt;&lt;code&gt;v0.10.0&lt;/code&gt;&lt;/a&gt;: use of &lt;code&gt;networking.k8s.io/ingresses&lt;/code&gt; instead of &lt;code&gt;extensions/ingresses&lt;/code&gt; (see &lt;a href="https://github.com/kubernetes-sigs/external-dns/pull/2281"&gt;#2281&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/kubernetes-sigs/external-dns/releases/tag/v0.18.0"&gt;&lt;code&gt;v0.18.0&lt;/code&gt;&lt;/a&gt;: use of &lt;code&gt;discovery.k8s.io/endpointslices&lt;/code&gt; instead of &lt;code&gt;endpoints&lt;/code&gt; (see &lt;a href="https://github.com/kubernetes-sigs/external-dns/pull/5493"&gt;#5493&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/kubernetes-sigs/external-dns/releases/tag/v0.19.0"&gt;&lt;code&gt;v0.19.0&lt;/code&gt;&lt;/a&gt;: expose external ipv6 by default (see &lt;a href="https://github.com/kubernetes-sigs/external-dns/pull/5575"&gt;#5575&lt;/a&gt; and disable legacy listeners on traefik.containo.us API Group (see &lt;a href="https://github.com/kubernetes-sigs/external-dns/pull/5565"&gt;#5565&lt;/a&gt;)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;ExternalDNS&lt;/th&gt; 
   &lt;th align="center"&gt;≤ 0.9.x&lt;/th&gt; 
   &lt;th align="center"&gt;≥ 0.10.x and ≤ 0.17.x&lt;/th&gt; 
   &lt;th align="center"&gt;≥ 0.18.x&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Kubernetes ≤ 1.18&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;span&gt;✅&lt;/span&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;span&gt;❌&lt;/span&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;span&gt;❌&lt;/span&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Kubernetes 1.19 and 1.20&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;span&gt;✅&lt;/span&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;span&gt;✅&lt;/span&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;span&gt;❌&lt;/span&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Kubernetes 1.21&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;span&gt;✅&lt;/span&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;span&gt;✅&lt;/span&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;span&gt;✅&lt;/span&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Kubernetes ≥ 1.22 and ≤ 1.32&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;span&gt;❌&lt;/span&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;span&gt;✅&lt;/span&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;span&gt;✅&lt;/span&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Kubernetes ≥ 1.33&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;span&gt;❌&lt;/span&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;span&gt;❌&lt;/span&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;span&gt;✅&lt;/span&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Running ExternalDNS&lt;/h2&gt; 
&lt;p&gt;The are two ways of running ExternalDNS:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Deploying to a Cluster&lt;/li&gt; 
 &lt;li&gt;Running Locally&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Deploying to a Cluster&lt;/h3&gt; 
&lt;p&gt;The following tutorials are provided:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/kubernetes-sigs/external-dns/master/docs/tutorials/akamai-edgedns.md"&gt;Akamai Edge DNS&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/kubernetes-sigs/external-dns/master/docs/tutorials/alibabacloud.md"&gt;Alibaba Cloud&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;AWS 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/kubernetes-sigs/external-dns/master/docs/tutorials/aws-load-balancer-controller.md"&gt;AWS Load Balancer Controller&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/kubernetes-sigs/external-dns/master/docs/tutorials/aws.md"&gt;Route53&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/kubernetes-sigs/external-dns/master/docs/tutorials/aws-public-private-route53.md"&gt;Same domain for public and private Route53 zones&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/kubernetes-sigs/external-dns/master/docs/tutorials/aws-sd.md"&gt;Cloud Map&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/kubernetes-sigs/external-dns/master/docs/tutorials/kube-ingress-aws.md"&gt;Kube Ingress AWS Controller&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/kubernetes-sigs/external-dns/master/docs/tutorials/azure.md"&gt;Azure DNS&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/kubernetes-sigs/external-dns/master/docs/tutorials/azure-private-dns.md"&gt;Azure Private DNS&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/kubernetes-sigs/external-dns/master/docs/tutorials/civo.md"&gt;Civo&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/kubernetes-sigs/external-dns/master/docs/tutorials/cloudflare.md"&gt;Cloudflare&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/kubernetes-sigs/external-dns/master/docs/tutorials/coredns.md"&gt;CoreDNS&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/kubernetes-sigs/external-dns/master/docs/tutorials/digitalocean.md"&gt;DigitalOcean&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/kubernetes-sigs/external-dns/master/docs/tutorials/dnsimple.md"&gt;DNSimple&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/kubernetes-sigs/external-dns/master/docs/tutorials/exoscale.md"&gt;Exoscale&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/kubernetes-sigs/external-dns/master/docs/tutorials/externalname.md"&gt;ExternalName Services&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Google Kubernetes Engine 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/kubernetes-sigs/external-dns/master/docs/tutorials/gke.md"&gt;Using Google's Default Ingress Controller&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/kubernetes-sigs/external-dns/master/docs/tutorials/gke-nginx.md"&gt;Using the Nginx Ingress Controller&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/kubernetes-sigs/external-dns/master/docs/tutorials/hostport.md"&gt;Headless Services&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/kubernetes-sigs/external-dns/master/docs/tutorials/ionoscloud.md"&gt;IONOS Cloud&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/kubernetes-sigs/external-dns/master/docs/sources/istio.md"&gt;Istio Gateway Source&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/kubernetes-sigs/external-dns/master/docs/tutorials/linode.md"&gt;Linode&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/kubernetes-sigs/external-dns/master/docs/tutorials/myra.md"&gt;Myra Security&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/kubernetes-sigs/external-dns/master/docs/tutorials/ns1.md"&gt;NS1&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/kubernetes-sigs/external-dns/master/docs/sources/ns-record.md"&gt;NS Record Creation with CRD Source&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/kubernetes-sigs/external-dns/master/docs/sources/mx-record.md"&gt;MX Record Creation with CRD Source&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/kubernetes-sigs/external-dns/master/docs/sources/txt-record.md"&gt;TXT Record Creation with CRD Source&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/kubernetes-sigs/external-dns/master/docs/tutorials/oracle.md"&gt;Oracle Cloud Infrastructure (OCI) DNS&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/kubernetes-sigs/external-dns/master/docs/tutorials/pdns.md"&gt;PowerDNS&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/kubernetes-sigs/external-dns/master/docs/tutorials/rfc2136.md"&gt;RFC2136&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/kubernetes-sigs/external-dns/master/docs/tutorials/transip.md"&gt;TransIP&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/kubernetes-sigs/external-dns/master/docs/tutorials/ovh.md"&gt;OVHcloud&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/kubernetes-sigs/external-dns/master/docs/tutorials/scaleway.md"&gt;Scaleway&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/kubernetes-sigs/external-dns/master/docs/tutorials/godaddy.md"&gt;GoDaddy&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/kubernetes-sigs/external-dns/master/docs/tutorials/gandi.md"&gt;Gandi&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/kubernetes-sigs/external-dns/master/docs/sources/nodes.md"&gt;Nodes as source&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/kubernetes-sigs/external-dns/master/docs/tutorials/plural.md"&gt;Plural&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/kubernetes-sigs/external-dns/master/docs/tutorials/pihole.md"&gt;Pi-hole&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Running Locally&lt;/h3&gt; 
&lt;p&gt;See the &lt;a href="https://raw.githubusercontent.com/kubernetes-sigs/external-dns/master/docs/contributing/dev-guide.md"&gt;contributor guide&lt;/a&gt; for details on compiling from source.&lt;/p&gt; 
&lt;h4&gt;Setup Steps&lt;/h4&gt; 
&lt;p&gt;Next, run an application and expose it via a Kubernetes Service:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;kubectl run nginx --image=nginx --port=80
kubectl expose pod nginx --port=80 --target-port=80 --type=LoadBalancer
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Annotate the Service with your desired external DNS name. Make sure to change &lt;code&gt;example.org&lt;/code&gt; to your domain.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;kubectl annotate service nginx "external-dns.alpha.kubernetes.io/hostname=nginx.example.org."
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Optionally, you can customize the TTL value of the resulting DNS record by using the &lt;code&gt;external-dns.alpha.kubernetes.io/ttl&lt;/code&gt; annotation:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;kubectl annotate service nginx "external-dns.alpha.kubernetes.io/ttl=10"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For more details on configuring TTL, see &lt;a href="https://raw.githubusercontent.com/kubernetes-sigs/external-dns/master/docs/advanced/ttl.md"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Use the internal-hostname annotation to create DNS records with ClusterIP as the target.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;kubectl annotate service nginx "external-dns.alpha.kubernetes.io/internal-hostname=nginx.internal.example.org."
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If the service is not of type Loadbalancer you need the --publish-internal-services flag.&lt;/p&gt; 
&lt;p&gt;Locally run a single sync loop of ExternalDNS.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;external-dns --txt-owner-id my-cluster-id --provider google --google-project example-project --source service --once --dry-run
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This should output the DNS records it will modify to match the managed zone with the DNS records you desire. It also assumes you are running in the &lt;code&gt;default&lt;/code&gt; namespace. See the &lt;a href="https://raw.githubusercontent.com/kubernetes-sigs/external-dns/master/docs/faq.md"&gt;FAQ&lt;/a&gt; for more information regarding namespaces.&lt;/p&gt; 
&lt;p&gt;Note: TXT records will have the &lt;code&gt;my-cluster-id&lt;/code&gt; value embedded. Those are used to ensure that ExternalDNS is aware of the records it manages.&lt;/p&gt; 
&lt;p&gt;Once you're satisfied with the result, you can run ExternalDNS like you would run it in your cluster: as a control loop, and &lt;strong&gt;not in dry-run&lt;/strong&gt; mode:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;external-dns --txt-owner-id my-cluster-id --provider google --google-project example-project --source service
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Check that ExternalDNS has created the desired DNS record for your Service and that it points to its load balancer's IP. Then try to resolve it:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;dig +short nginx.example.org.
104.155.60.49
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Now you can experiment and watch how ExternalDNS makes sure that your DNS records are configured as desired. Here are a couple of things you can try out:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Change the desired hostname by modifying the Service's annotation.&lt;/li&gt; 
 &lt;li&gt;Recreate the Service and see that the DNS record will be updated to point to the new load balancer IP.&lt;/li&gt; 
 &lt;li&gt;Add another Service to create more DNS records.&lt;/li&gt; 
 &lt;li&gt;Remove Services to clean up your managed zone.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The &lt;strong&gt;tutorials&lt;/strong&gt; section contains examples, including Ingress resources, and shows you how to set up ExternalDNS in different environments such as other cloud providers and alternative Ingress controllers.&lt;/p&gt; 
&lt;h1&gt;Note&lt;/h1&gt; 
&lt;p&gt;If using a txt registry and attempting to use a CNAME the &lt;code&gt;--txt-prefix&lt;/code&gt; must be set to avoid conflicts. Changing &lt;code&gt;--txt-prefix&lt;/code&gt; will result in lost ownership over previously created records.&lt;/p&gt; 
&lt;p&gt;If &lt;code&gt;externalIPs&lt;/code&gt; list is defined for a &lt;code&gt;LoadBalancer&lt;/code&gt; service, this list will be used instead of an assigned load balancer IP to create a DNS record. It's useful when you run bare metal Kubernetes clusters behind NAT or in a similar setup, where a load balancer IP differs from a public IP (e.g. with &lt;a href="https://metallb.universe.tf"&gt;MetalLB&lt;/a&gt;).&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Are you interested in contributing to external-dns? We, the maintainers and community, would love your suggestions, contributions, and help! Also, the maintainers can be contacted at any time to learn more about how to get involved.&lt;/p&gt; 
&lt;p&gt;We also encourage ALL active community participants to act as if they are maintainers, even if you don't have "official" write permissions. This is a community effort, we are here to serve the Kubernetes community. If you have an active interest and you want to get involved, you have real power! Don't assume that the only people who can get things done around here are the "maintainers". We also would love to add more "official" maintainers, so show us what you can do!&lt;/p&gt; 
&lt;p&gt;The external-dns project is currently in need of maintainers for specific DNS providers. Ideally each provider would have at least two maintainers. It would be nice if the maintainers run the provider in production, but it is not strictly required. Provider listed &lt;a href="https://github.com/kubernetes-sigs/external-dns#status-of-in-tree-providers"&gt;here&lt;/a&gt; that do not have a maintainer listed are in need of assistance.&lt;/p&gt; 
&lt;p&gt;Read the &lt;a href="https://raw.githubusercontent.com/kubernetes-sigs/external-dns/master/CONTRIBUTING.md"&gt;contributing guidelines&lt;/a&gt; and have a look at &lt;a href="https://raw.githubusercontent.com/kubernetes-sigs/external-dns/master/docs/contributing/dev-guide.md"&gt;the contributing docs&lt;/a&gt; to learn about building the project, the project structure, and the purpose of each package.&lt;/p&gt; 
&lt;p&gt;For an overview on how to write new Sources and Providers check out &lt;a href="https://raw.githubusercontent.com/kubernetes-sigs/external-dns/master/docs/contributing/sources-and-providers.md"&gt;Sources and Providers&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Heritage&lt;/h2&gt; 
&lt;p&gt;ExternalDNS is an effort to unify the following similar projects in order to bring the Kubernetes community an easy and predictable way of managing DNS records across cloud providers based on their Kubernetes resources:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Kops' &lt;a href="https://github.com/kubernetes/kops/tree/HEAD/dns-controller"&gt;DNS Controller&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Zalando's &lt;a href="https://github.com/linki/mate"&gt;Mate&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Molecule Software's &lt;a href="https://github.com/wearemolecule/route53-kubernetes"&gt;route53-kubernetes&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;User Demo How-To Blogs and Examples&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;A full demo on GKE Kubernetes. See &lt;a href="https://medium.com/@jpantjsoha/how-to-kubernetes-with-dns-management-for-gitops-31239ea75d8d"&gt;How-to Kubernetes with DNS management (ssl-manager pre-req)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Run external-dns on GKE with workload identity. See &lt;a href="https://blog.atomist.com/kubernetes-ingress-nginx-cert-manager-external-dns/"&gt;Kubernetes, ingress-nginx, cert-manager &amp;amp; external-dns&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://cloudchronicles.blog/blog/ExternalDNS-integration-with-Azure-DNS-using-workload-identity/"&gt;ExternalDNS integration with Azure DNS using workload identity&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>gruntwork-io/terragrunt</title>
      <link>https://github.com/gruntwork-io/terragrunt</link>
      <description>&lt;p&gt;Terragrunt is a flexible orchestration tool that allows Infrastructure as Code written in OpenTofu/Terraform to scale.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Terragrunt&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://gruntwork.io/?ref=repo_terragrunt"&gt;&lt;img src="https://img.shields.io/badge/maintained%20by-gruntwork.io-%235849a6.svg?sanitize=true" alt="Maintained by Gruntwork.io" /&gt;&lt;/a&gt; &lt;a href="https://goreportcard.com/report/github.com/gruntwork-io/terragrunt"&gt;&lt;img src="https://goreportcard.com/badge/github.com/gruntwork-io/terragrunt" alt="Go Report Card" /&gt;&lt;/a&gt; &lt;a href="https://godoc.org/github.com/gruntwork-io/terragrunt"&gt;&lt;img src="https://godoc.org/github.com/gruntwork-io/terragrunt?status.svg?sanitize=true" alt="GoDoc" /&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/badge/tofu-%3E%3D1.6.0-blue.svg?sanitize=true" alt="OpenTofu Version" /&gt; &lt;img src="https://img.shields.io/badge/tf-%3E%3D0.12.0-blue.svg?sanitize=true" alt="Terraform Version" /&gt;&lt;/p&gt; 
&lt;p&gt;Terragrunt is a flexible orchestration tool that allows Infrastructure as Code written in &lt;a href="https://opentofu.org"&gt;OpenTofu&lt;/a&gt;/&lt;a href="https://www.terraform.io"&gt;Terraform&lt;/a&gt; to scale.&lt;/p&gt; 
&lt;p&gt;Please see the following for more info, including install instructions and complete documentation:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://terragrunt.gruntwork.io"&gt;Terragrunt Website&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://terragrunt.gruntwork.io/docs/getting-started/quick-start/"&gt;Getting started with Terragrunt&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://terragrunt.gruntwork.io/docs"&gt;Terragrunt Documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://terragrunt.gruntwork.io/docs/community/contributing"&gt;Contributing to Terragrunt&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://gruntwork.io/support/"&gt;Commercial Support&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Join the Discord!&lt;/h2&gt; 
&lt;p&gt;Join &lt;a href="https://discord.gg/YENaT9h8jh"&gt;our community&lt;/a&gt; for discussions, support, and contributions:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://discord.gg/YENaT9h8jh"&gt;&lt;img src="https://dcbadge.limes.pink/api/server/https://discord.gg/YENaT9h8jh" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This code is released under the MIT License. See &lt;a href="https://raw.githubusercontent.com/gruntwork-io/terragrunt/main/LICENSE.txt"&gt;LICENSE.txt&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>minio/minio</title>
      <link>https://github.com/minio/minio</link>
      <description>&lt;p&gt;MinIO is a high-performance, S3 compatible object store, open sourced under GNU AGPLv3 license.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;MinIO Quickstart Guide&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://slack.min.io"&gt;&lt;img src="https://slack.min.io/slack?type=svg" alt="Slack" /&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/r/minio/minio/"&gt;&lt;img src="https://img.shields.io/docker/pulls/minio/minio.svg?maxAge=604800" alt="Docker Pulls" /&gt;&lt;/a&gt; &lt;a href="https://github.com/minio/minio/raw/master/LICENSE"&gt;&lt;img src="https://img.shields.io/badge/license-AGPL%20V3-blue" alt="license" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://min.io"&gt;&lt;img src="https://raw.githubusercontent.com/minio/minio/master/.github/logo.svg?sanitize=true" alt="MinIO" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;MinIO is a high-performance, S3-compatible object storage solution released under the GNU AGPL v3.0 license. Designed for speed and scalability, it powers AI/ML, analytics, and data-intensive workloads with industry-leading performance.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;S3 API Compatible – Seamless integration with existing S3 tools&lt;/li&gt; 
 &lt;li&gt;Built for AI &amp;amp; Analytics – Optimized for large-scale data pipelines&lt;/li&gt; 
 &lt;li&gt;High Performance – Ideal for demanding storage workloads.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;This README provides instructions for building MinIO from source and deploying onto baremetal hardware. Use the &lt;a href="https://github.com/minio/docs"&gt;MinIO Documentation&lt;/a&gt; project to build and host a local copy of the documentation.&lt;/p&gt; 
&lt;h2&gt;MinIO is Open Source Software&lt;/h2&gt; 
&lt;p&gt;We designed MinIO as Open Source software for the Open Source software community. We encourage the community to remix, redesign, and reshare MinIO under the terms of the AGPLv3 license.&lt;/p&gt; 
&lt;p&gt;All usage of MinIO in your application stack requires validation against AGPLv3 obligations, which include but are not limited to the release of modified code to the community from which you have benefited. Any commercial/proprietary usage of the AGPLv3 software, including repackaging or reselling services/features, is done at your own risk.&lt;/p&gt; 
&lt;p&gt;The AGPLv3 provides no obligation by any party to support, maintain, or warranty the original or any modified work. All support is provided on a best-effort basis through Github and our &lt;a href="https://raw.githubusercontent.com/minio/minio/master/https//slack.min.io"&gt;Slack&lt;/a&gt; channel, and any member of the community is welcome to contribute and assist others in their usage of the software.&lt;/p&gt; 
&lt;p&gt;MinIO &lt;a href="https://www.min.io/product/aistor"&gt;AIStor&lt;/a&gt; includes enterprise-grade support and licensing for workloads which require commercial or proprietary usage and production-level SLA/SLO-backed support. For more information, &lt;a href="https://min.io/pricing"&gt;reach out for a quote&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Source-Only Distribution&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Important:&lt;/strong&gt; The MinIO community edition is now distributed as source code only. We will no longer provide pre-compiled binary releases for the community version.&lt;/p&gt; 
&lt;h3&gt;Installing Latest MinIO Community Edition&lt;/h3&gt; 
&lt;p&gt;To use MinIO community edition, you have two options:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Install from source&lt;/strong&gt; using &lt;code&gt;go install github.com/minio/minio@latest&lt;/code&gt; (recommended)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Build a Docker image&lt;/strong&gt; from the provided Dockerfile&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;See the sections below for detailed instructions on each method.&lt;/p&gt; 
&lt;h3&gt;Legacy Binary Releases&lt;/h3&gt; 
&lt;p&gt;Historical pre-compiled binary releases remain available for reference but are no longer maintained:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;GitHub Releases: &lt;a href="https://github.com/minio/minio/releases"&gt;https://github.com/minio/minio/releases&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Direct downloads: &lt;a href="https://dl.min.io/server/minio/release/"&gt;https://dl.min.io/server/minio/release/&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;These legacy binaries will not receive updates.&lt;/strong&gt; We strongly recommend using source builds for access to the latest features, bug fixes, and security updates.&lt;/p&gt; 
&lt;h2&gt;Install from Source&lt;/h2&gt; 
&lt;p&gt;Use the following commands to compile and run a standalone MinIO server from source. If you do not have a working Golang environment, please follow &lt;a href="https://golang.org/doc/install"&gt;How to install Golang&lt;/a&gt;. Minimum version required is &lt;a href="https://golang.org/dl/#stable"&gt;go1.24&lt;/a&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;go install github.com/minio/minio@latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can alternatively run &lt;code&gt;go build&lt;/code&gt; and use the &lt;code&gt;GOOS&lt;/code&gt; and &lt;code&gt;GOARCH&lt;/code&gt; environment variables to control the OS and architecture target. For example:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;env GOOS=linux GOARCh=arm64 go build
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Start MinIO by running &lt;code&gt;minio server PATH&lt;/code&gt; where &lt;code&gt;PATH&lt;/code&gt; is any empty folder on your local filesystem.&lt;/p&gt; 
&lt;p&gt;The MinIO deployment starts using default root credentials &lt;code&gt;minioadmin:minioadmin&lt;/code&gt;. You can test the deployment using the MinIO Console, an embedded web-based object browser built into MinIO Server. Point a web browser running on the host machine to &lt;a href="http://127.0.0.1:9000"&gt;http://127.0.0.1:9000&lt;/a&gt; and log in with the root credentials. You can use the Browser to create buckets, upload objects, and browse the contents of the MinIO server.&lt;/p&gt; 
&lt;p&gt;You can also connect using any S3-compatible tool, such as the MinIO Client &lt;code&gt;mc&lt;/code&gt; commandline tool:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;mc alias set local http://localhost:9000 minioadmin minioadmin
mc admin info local
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/minio/minio/master/#test-using-minio-client-mc"&gt;Test using MinIO Client &lt;code&gt;mc&lt;/code&gt;&lt;/a&gt; for more information on using the &lt;code&gt;mc&lt;/code&gt; commandline tool. For application developers, see &lt;a href="https://docs.min.io/community/minio-object-store/developers/minio-drivers.html"&gt;https://docs.min.io/community/minio-object-store/developers/minio-drivers.html&lt;/a&gt; to view MinIO SDKs for supported languages.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] Production environments using compiled-from-source MinIO binaries do so at their own risk. The AGPLv3 license provides no warranties nor liabilites for any such usage.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Build Docker Image&lt;/h2&gt; 
&lt;p&gt;You can use the &lt;code&gt;docker build .&lt;/code&gt; command to build a Docker image on your local host machine. You must first &lt;a href="https://raw.githubusercontent.com/minio/minio/master/#install-from-source"&gt;build MinIO&lt;/a&gt; and ensure the &lt;code&gt;minio&lt;/code&gt; binary exists in the project root.&lt;/p&gt; 
&lt;p&gt;The following command builds the Docker image using the default &lt;code&gt;Dockerfile&lt;/code&gt; in the root project directory with the repository and image tag &lt;code&gt;myminio:minio&lt;/code&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;docker build -t myminio:minio .
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Use &lt;code&gt;docker image ls&lt;/code&gt; to confirm the image exists in your local repository. You can run the server using standard Docker invocation:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;docker run -p 9000:9000 -p 9001:9001 myminio:minio server /tmp/minio --console-address :9001
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Complete documentation for building Docker containers, managing custom images, or loading images into orchestration platforms is out of scope for this documentation. You can modify the &lt;code&gt;Dockerfile&lt;/code&gt; and &lt;code&gt;dockerscripts/docker-entrypoint.sh&lt;/code&gt; as-needed to reflect your specific image requirements.&lt;/p&gt; 
&lt;p&gt;See the &lt;a href="https://docs.min.io/community/minio-object-store/operations/deployments/baremetal-deploy-minio-as-a-container.html#deploy-minio-container"&gt;MinIO Container&lt;/a&gt; documentation for more guidance on running MinIO within a Container image.&lt;/p&gt; 
&lt;h2&gt;Install using Helm Charts&lt;/h2&gt; 
&lt;p&gt;There are two paths for installing MinIO onto Kubernetes infrastructure:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Use the &lt;a href="https://github.com/minio/operator"&gt;MinIO Operator&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Use the community-maintained &lt;a href="https://github.com/minio/minio/tree/master/helm/minio"&gt;Helm charts&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;See the &lt;a href="https://docs.min.io/community/minio-object-store/operations/deployments/kubernetes.html"&gt;MinIO Documentation&lt;/a&gt; for guidance on deploying using the Operator. The Community Helm chart has instructions in the folder-level README.&lt;/p&gt; 
&lt;h2&gt;Test MinIO Connectivity&lt;/h2&gt; 
&lt;h3&gt;Test using MinIO Console&lt;/h3&gt; 
&lt;p&gt;MinIO Server comes with an embedded web based object browser. Point your web browser to &lt;a href="http://127.0.0.1:9000"&gt;http://127.0.0.1:9000&lt;/a&gt; to ensure your server has started successfully.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] MinIO runs console on random port by default, if you wish to choose a specific port use &lt;code&gt;--console-address&lt;/code&gt; to pick a specific interface and port.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Test using MinIO Client &lt;code&gt;mc&lt;/code&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;mc&lt;/code&gt; provides a modern alternative to UNIX commands like ls, cat, cp, mirror, diff etc. It supports filesystems and Amazon S3 compatible cloud storage services.&lt;/p&gt; 
&lt;p&gt;The following commands set a local alias, validate the server information, create a bucket, copy data to that bucket, and list the contents of the bucket.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;mc alias set local http://localhost:9000 minioadmin minioadmin
mc admin info
mc mb data
mc cp ~/Downloads/mydata data/
mc ls data/
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Follow the MinIO Client &lt;a href="https://docs.min.io/community/minio-object-store/reference/minio-mc.html#quickstart"&gt;Quickstart Guide&lt;/a&gt; for further instructions.&lt;/p&gt; 
&lt;h2&gt;Explore Further&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.min.io/community/minio-object-store/index.html"&gt;The MinIO documentation website&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.min.io/community/minio-object-store/operations/concepts/erasure-coding.html"&gt;MinIO Erasure Code Overview&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.min.io/community/minio-object-store/reference/minio-mc.html"&gt;Use &lt;code&gt;mc&lt;/code&gt; with MinIO Server&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.min.io/community/minio-object-store/developers/go/minio-go.html"&gt;Use &lt;code&gt;minio-go&lt;/code&gt; SDK with MinIO Server&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contribute to MinIO Project&lt;/h2&gt; 
&lt;p&gt;Please follow MinIO &lt;a href="https://github.com/minio/minio/raw/master/CONTRIBUTING.md"&gt;Contributor's Guide&lt;/a&gt; for guidance on making new contributions to the repository.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;MinIO source is licensed under the &lt;a href="https://github.com/minio/minio/raw/master/LICENSE"&gt;GNU AGPLv3&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;MinIO &lt;a href="https://github.com/minio/minio/tree/master/docs"&gt;documentation&lt;/a&gt; is licensed under &lt;a href="https://creativecommons.org/licenses/by/4.0/"&gt;CC BY 4.0&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/minio/minio/raw/master/COMPLIANCE.md"&gt;License Compliance&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>kyverno/kyverno</title>
      <link>https://github.com/kyverno/kyverno</link>
      <description>&lt;p&gt;Cloud Native Policy Management&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Kyverno &lt;a href="https://twitter.com/intent/tweet?text=Cloud%20Native%20Policy%20Management.%20No%20new%20language%20required%1&amp;amp;url=https://github.com/kyverno/kyverno/&amp;amp;hashtags=kubernetes,devops"&gt;&lt;img src="https://img.shields.io/twitter/url/http/shields.io.svg?style=social" alt="Tweet" /&gt;&lt;/a&gt;&lt;/h1&gt; 
&lt;p&gt;&lt;strong&gt;Cloud Native Policy Management 🎉&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/kyverno/kyverno/actions"&gt;&lt;img src="https://github.com/kyverno/kyverno/actions/workflows/test.yml/badge.svg?sanitize=true" alt="Build Status" /&gt;&lt;/a&gt; &lt;a href="https://goreportcard.com/report/github.com/kyverno/kyverno"&gt;&lt;img src="https://goreportcard.com/badge/github.com/kyverno/kyverno" alt="Go Report Card" /&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/github/license/kyverno/kyverno?color=blue" alt="License: Apache-2.0" /&gt; &lt;a href="https://github.com/kyverno/kyverno/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/kyverno/kyverno" alt="GitHub Repo stars" /&gt;&lt;/a&gt; &lt;a href="https://bestpractices.coreinfrastructure.org/projects/5327"&gt;&lt;img src="https://bestpractices.coreinfrastructure.org/projects/5327/badge" alt="CII Best Practices" /&gt;&lt;/a&gt; &lt;a href="https://securityscorecards.dev/viewer/?uri=github.com/kyverno/kyverno"&gt;&lt;img src="https://api.securityscorecards.dev/projects/github.com/kyverno/kyverno/badge" alt="OpenSSF Scorecard" /&gt;&lt;/a&gt; &lt;a href="https://slsa.dev"&gt;&lt;img src="https://slsa.dev/images/gh-badge-level3.svg?sanitize=true" alt="SLSA 3" /&gt;&lt;/a&gt; &lt;a href="https://artifacthub.io/packages/search?repo=kyverno"&gt;&lt;img src="https://img.shields.io/endpoint?url=https://artifacthub.io/badge/repository/kyverno" alt="Artifact HUB" /&gt;&lt;/a&gt; &lt;a href="https://app.codecov.io/gh/kyverno/kyverno/branch/main"&gt;&lt;img src="https://codecov.io/gh/kyverno/kyverno/branch/main/graph/badge.svg?sanitize=true" alt="codecov" /&gt;&lt;/a&gt; &lt;a href="https://app.fossa.com/projects/git%2Bgithub.com%2Fkyverno%2Fkyverno?ref=badge_shield"&gt;&lt;img src="https://app.fossa.com/api/projects/git%2Bgithub.com%2Fkyverno%2Fkyverno.svg?type=shield" alt="FOSSA Status" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p align="center"&gt;&lt;a href="https://kyverno.io" rel="kyverno.io"&gt;&lt;img src="https://raw.githubusercontent.com/kyverno/kyverno/main/img/Kyverno_Horizontal.png" alt="Kyverno Logo" width="400" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;📑 Table of Contents&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/kyverno/kyverno/main/#about-kyverno"&gt;About Kyverno&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/kyverno/kyverno/main/#-documentation"&gt;Documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/kyverno/kyverno/main/#-demos--tutorials"&gt;Demos &amp;amp; Tutorials&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/kyverno/kyverno/main/#-popular-use-cases"&gt;Popular Use Cases&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/kyverno/kyverno/main/#-explore-the-policy-library"&gt;Explore the Policy Library&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/kyverno/kyverno/main/#-getting-help"&gt;Getting Help&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/kyverno/kyverno/main/#-contributing"&gt;Contributing&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/kyverno/kyverno/main/#software-bill-of-materials"&gt;Software Bill of Materials&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/kyverno/kyverno/main/#-community-highlights"&gt;Community Highlights&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/kyverno/kyverno/main/#contributors"&gt;Contributors&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/kyverno/kyverno/main/#license"&gt;License&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;About Kyverno&lt;/h2&gt; 
&lt;p&gt;Kyverno is a Kubernetes-native policy engine designed for platform engineering teams. It enables security, compliance, automation, and governance through policy-as-code. Kyverno can:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Validate, mutate, generate, and clean up resources using Kubernetes admission controls and background scans.&lt;/li&gt; 
 &lt;li&gt;Verify container image signatures for supply chain security.&lt;/li&gt; 
 &lt;li&gt;Operate with tools you already use — like &lt;code&gt;kubectl&lt;/code&gt;, &lt;code&gt;kustomize&lt;/code&gt;, and Git.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;a href="https://opensourcesecurityindex.io/" target="_blank" rel="noopener"&gt; &lt;img src="https://opensourcesecurityindex.io/badge.svg?sanitize=true" alt="Open Source Security Index badge" width="282" height="56" /&gt; &lt;/a&gt; 
&lt;h2&gt;📙 Documentation&lt;/h2&gt; 
&lt;p&gt;Kyverno installation and reference documentation is available at &lt;a href="https://kyverno.io"&gt;kyverno.io&lt;/a&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;👉 &lt;strong&gt;&lt;a href="https://kyverno.io/docs/introduction/#quick-start"&gt;Quick Start&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;👉 &lt;strong&gt;&lt;a href="https://kyverno.io/docs/installation/"&gt;Installation Guide&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;👉 &lt;strong&gt;&lt;a href="https://kyverno.io/policies/"&gt;Policy Library&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;🎥 Demos &amp;amp; Tutorials&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;▶️ &lt;a href="https://www.youtube.com/results?search_query=kyverno+tutorial"&gt;Getting Started with Kyverno – YouTube&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;🧪 &lt;a href="https://playground.kyverno.io/"&gt;Kyverno Playground&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;🎯 Popular Use Cases&lt;/h2&gt; 
&lt;p&gt;Kyverno helps platform teams enforce best practices and security standards. Some common use cases include:&lt;/p&gt; 
&lt;h3&gt;1. &lt;strong&gt;Security &amp;amp; Compliance&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Enforce Pod Security Standards (PSS)&lt;/li&gt; 
 &lt;li&gt;Require specific security contexts&lt;/li&gt; 
 &lt;li&gt;Validate container image sources and signatures&lt;/li&gt; 
 &lt;li&gt;Enforce CIS Benchmark policies&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;2. &lt;strong&gt;Operational Excellence&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Auto-label workloads&lt;/li&gt; 
 &lt;li&gt;Enforce naming conventions&lt;/li&gt; 
 &lt;li&gt;Generate default configurations (e.g., NetworkPolicies)&lt;/li&gt; 
 &lt;li&gt;Validate YAML and Helm manifests&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;3. &lt;strong&gt;Cost Optimization&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Enforce resource quotas and limits&lt;/li&gt; 
 &lt;li&gt;Require cost allocation labels&lt;/li&gt; 
 &lt;li&gt;Validate instance types&lt;/li&gt; 
 &lt;li&gt;Clean up unused resources&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;4. &lt;strong&gt;Developer Guardrails&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Require readiness/liveness probes&lt;/li&gt; 
 &lt;li&gt;Enforce ingress/egress policies&lt;/li&gt; 
 &lt;li&gt;Validate container image versions&lt;/li&gt; 
 &lt;li&gt;Auto-inject config maps or secrets&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;📚 Explore the Policy Library&lt;/h2&gt; 
&lt;p&gt;Discover hundreds of production-ready Kyverno policies for security, operations, cost control, and developer enablement.&lt;/p&gt; 
&lt;p&gt;👉 &lt;a href="https://kyverno.io/policies/"&gt;Browse the Policy Library&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;🙋 Getting Help&lt;/h2&gt; 
&lt;p&gt;We’re here to help:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;🐞 File a &lt;a href="https://github.com/kyverno/kyverno/issues"&gt;GitHub Issue&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;💬 Join the &lt;a href="https://slack.k8s.io/#kyverno"&gt;Kyverno Slack Channel&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;📅 Attend &lt;a href="https://kyverno.io/community/#community-meetings"&gt;Community Meetings&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;⭐️ &lt;a href="https://github.com/kyverno/kyverno/stargazers"&gt;Star this repository&lt;/a&gt; to stay updated&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;➕ Contributing&lt;/h2&gt; 
&lt;p&gt;Thank you for your interest in contributing to Kyverno!&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;✅ Read the &lt;a href="https://raw.githubusercontent.com/kyverno/kyverno/main/CONTRIBUTING.md"&gt;Contribution Guidelines&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;🧵 Join &lt;a href="https://github.com/kyverno/kyverno/discussions"&gt;GitHub Discussions&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;📖 Read the &lt;a href="https://raw.githubusercontent.com/kyverno/kyverno/main/DEVELOPMENT.md"&gt;Development Guide&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;🏁 Check &lt;a href="https://github.com/kyverno/kyverno/labels/good%20first%20issue"&gt;Good First Issues&lt;/a&gt; and request with &lt;code&gt;/assign&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;🌱 Explore the &lt;a href="https://kyverno.io/community/"&gt;Community page&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;🧾 Software Bill of Materials&lt;/h2&gt; 
&lt;p&gt;All Kyverno images include a Software Bill of Materials (SBOM) in &lt;a href="https://cyclonedx.org/"&gt;CycloneDX&lt;/a&gt; format. SBOMs are available at:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;👉 &lt;a href="https://github.com/orgs/kyverno/packages?tab=packages&amp;amp;q=sbom"&gt;&lt;code&gt;ghcr.io/kyverno/sbom&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;👉 &lt;a href="https://kyverno.io/docs/security/#fetching-the-sbom-for-kyverno"&gt;Fetching the SBOM&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;👥 Contributors&lt;/h2&gt; 
&lt;p&gt;Kyverno is built and maintained by our growing community of contributors!&lt;/p&gt; 
&lt;a href="https://github.com/kyverno/kyverno/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=kyverno/kyverno" alt="Contributors image" /&gt; &lt;/a&gt; 
&lt;p&gt;&lt;em&gt;Made with &lt;a href="https://contrib.rocks"&gt;contributors-img&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;h2&gt;📄 License&lt;/h2&gt; 
&lt;p&gt;Copyright 2025, the Kyverno project. All rights reserved.&lt;br /&gt; Kyverno is licensed under the &lt;a href="https://raw.githubusercontent.com/kyverno/kyverno/main/LICENSE"&gt;Apache License 2.0&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Kyverno is a &lt;a href="https://www.cncf.io/projects/"&gt;Cloud Native Computing Foundation (CNCF) Incubating project&lt;/a&gt; and was contributed by &lt;a href="https://nirmata.com/?utm_source=github&amp;amp;utm_medium=repository"&gt;Nirmata&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>smallstep/certificates</title>
      <link>https://github.com/smallstep/certificates</link>
      <description>&lt;p&gt;🛡️ A private certificate authority (X.509 &amp; SSH) &amp; ACME server for secure automated certificate management, so you can use TLS everywhere &amp; SSO for SSH.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;step-ca&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://github.com/smallstep/certificates/releases/latest"&gt;&lt;img src="https://img.shields.io/github/release/smallstep/certificates.svg?sanitize=true" alt="GitHub release" /&gt;&lt;/a&gt; &lt;a href="https://goreportcard.com/report/github.com/smallstep/certificates"&gt;&lt;img src="https://goreportcard.com/badge/github.com/smallstep/certificates" alt="Go Report Card" /&gt;&lt;/a&gt; &lt;a href="https://github.com/smallstep/certificates"&gt;&lt;img src="https://github.com/smallstep/certificates/actions/workflows/test.yml/badge.svg?sanitize=true" alt="Build Status" /&gt;&lt;/a&gt; &lt;a href="https://opensource.org/licenses/Apache-2.0"&gt;&lt;img src="https://img.shields.io/badge/License-Apache%202.0-blue.svg?sanitize=true" alt="License" /&gt;&lt;/a&gt; &lt;a href="https://cla-assistant.io/smallstep/certificates"&gt;&lt;img src="https://cla-assistant.io/readme/badge/smallstep/certificates" alt="CLA assistant" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;step-ca&lt;/code&gt; is an online certificate authority for secure, automated certificate management for DevOps. It's the server counterpart to the &lt;a href="https://github.com/smallstep/cli"&gt;&lt;code&gt;step&lt;/code&gt; CLI tool&lt;/a&gt; for working with certificates and keys. Both projects are maintained by &lt;a href="https://smallstep.com"&gt;Smallstep Labs&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;You can use &lt;code&gt;step-ca&lt;/code&gt; to:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Issue HTTPS server and client certificates that &lt;a href="https://smallstep.com/blog/step-v0-8-6-valid-HTTPS-certificates-for-dev-pre-prod.html"&gt;work in browsers&lt;/a&gt; (&lt;a href="https://tools.ietf.org/html/rfc5280"&gt;RFC5280&lt;/a&gt; and &lt;a href="https://cabforum.org/baseline-requirements-documents/"&gt;CA/Browser Forum&lt;/a&gt; compliance)&lt;/li&gt; 
 &lt;li&gt;Issue TLS certificates for DevOps: VMs, containers, APIs, database connections, Kubernetes pods...&lt;/li&gt; 
 &lt;li&gt;Issue SSH certificates: 
  &lt;ul&gt; 
   &lt;li&gt;For people, in exchange for single sign-on identity tokens&lt;/li&gt; 
   &lt;li&gt;For hosts, in exchange for cloud instance identity documents&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Easily automate certificate management: 
  &lt;ul&gt; 
   &lt;li&gt;It's an &lt;a href="https://smallstep.com/docs/step-ca/acme-basics/"&gt;ACME server&lt;/a&gt; that supports all &lt;a href="https://smallstep.com/docs/step-ca/acme-basics/#acme-challenge-types"&gt;popular ACME challenge types&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;It comes with a &lt;a href="https://raw.githubusercontent.com/smallstep/certificates/master/examples#user-content-basic-client-usage"&gt;Go wrapper&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;... and there's a &lt;a href="https://github.com/smallstep/cli"&gt;command-line client&lt;/a&gt; you can use in scripts!&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h3&gt;Comparison with Smallstep's commercial product&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;step-ca&lt;/code&gt; is optimized for a two-tier PKI serving common DevOps use cases.&lt;/p&gt; 
&lt;p&gt;As you design your PKI, if you need any of the following, &lt;a href="http://smallstep.com"&gt;consider our commerical CA&lt;/a&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Multiple certificate authorities&lt;/li&gt; 
 &lt;li&gt;Active revocation (CRL, OSCP)&lt;/li&gt; 
 &lt;li&gt;Turnkey high-volume, high availability CA&lt;/li&gt; 
 &lt;li&gt;An API for seamless IaC management of your PKI&lt;/li&gt; 
 &lt;li&gt;Integrated support for SCEP &amp;amp; NDES, for migrating from legacy Active Directory Certificate Services deployments&lt;/li&gt; 
 &lt;li&gt;Device identity — cross-platform device inventory and attestation using Secure Enclave &amp;amp; TPM 2.0&lt;/li&gt; 
 &lt;li&gt;Highly automated PKI — managed certificate renewal, monitoring, TPM-based attested enrollment&lt;/li&gt; 
 &lt;li&gt;Seamless client deployments of EAP-TLS Wi-Fi, VPN, SSH, and browser certificates&lt;/li&gt; 
 &lt;li&gt;Jamf, Intune, or other MDM for root distribution and client enrollment&lt;/li&gt; 
 &lt;li&gt;Web Admin UI — history, issuance, and metrics&lt;/li&gt; 
 &lt;li&gt;ACME External Account Binding (EAB)&lt;/li&gt; 
 &lt;li&gt;Deep integration with an identity provider&lt;/li&gt; 
 &lt;li&gt;Fine-grained, role-based access control&lt;/li&gt; 
 &lt;li&gt;FIPS-compliant software&lt;/li&gt; 
 &lt;li&gt;HSM-bound private keys&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;See our &lt;a href="https://smallstep.com/step-ca-vs-smallstep-certificate-manager/"&gt;full feature comparison&lt;/a&gt; for more.&lt;/p&gt; 
&lt;p&gt;You can &lt;a href="https://smallstep.com/signup"&gt;start a free trial&lt;/a&gt; or &lt;a href="https://go.smallstep.com/request-demo"&gt;set up a call with us&lt;/a&gt; to learn more.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;strong&gt;Questions? Find us in &lt;a href="https://github.com/smallstep/certificates/discussions"&gt;Discussions&lt;/a&gt; or &lt;a href="https://u.step.sm/discord"&gt;Join our Discord&lt;/a&gt;.&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://smallstep.com/certificates"&gt;Website&lt;/a&gt; | &lt;a href="https://smallstep.com/docs/step-ca"&gt;Documentation&lt;/a&gt; | &lt;a href="https://smallstep.com/docs/step-ca/installation"&gt;Installation&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/smallstep/certificates/master/CONTRIBUTING.md"&gt;Contributor's Guide&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;h3&gt;🦾 A fast, stable, flexible private CA&lt;/h3&gt; 
&lt;p&gt;Setting up a &lt;em&gt;public key infrastructure&lt;/em&gt; (PKI) is out of reach for many small teams. &lt;code&gt;step-ca&lt;/code&gt; makes it easier.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Choose key types (RSA, ECDSA, EdDSA) and lifetimes to suit your needs&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://smallstep.com/blog/passive-revocation.html"&gt;Short-lived certificates&lt;/a&gt; with automated enrollment, renewal, and passive revocation&lt;/li&gt; 
 &lt;li&gt;Can operate as &lt;a href="https://smallstep.com/docs/tutorials/intermediate-ca-new-ca"&gt;an online intermediate CA for an existing root CA&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://smallstep.com/docs/step-ca/configuration#databases"&gt;Badger, BoltDB, Postgres, and MySQL database backends&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;⚙️ Many ways to automate&lt;/h3&gt; 
&lt;p&gt;There are several ways to authorize a request with the CA and establish a chain of trust that suits your flow.&lt;/p&gt; 
&lt;p&gt;You can issue certificates in exchange for:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/smallstep/certificates/master/#your-own-private-acme-server"&gt;ACME challenge responses&lt;/a&gt; from any ACMEv2 client&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://smallstep.com/blog/easily-curl-services-secured-by-https-tls.html"&gt;OAuth OIDC single sign-on tokens&lt;/a&gt;, eg: 
  &lt;ul&gt; 
   &lt;li&gt;ID tokens from Okta, GSuite, Azure AD, Auth0.&lt;/li&gt; 
   &lt;li&gt;ID tokens from an OAuth OIDC service that you host, like &lt;a href="https://www.keycloak.org/"&gt;Keycloak&lt;/a&gt; or &lt;a href="https://github.com/dexidp/dex"&gt;Dex&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://smallstep.com/blog/embarrassingly-easy-certificates-on-aws-azure-gcp/"&gt;Cloud instance identity documents&lt;/a&gt;, for VMs on AWS, GCP, and Azure&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://smallstep.com/docs/step-ca/provisioners#jwk"&gt;Single-use, short-lived JWK tokens&lt;/a&gt; issued by your CD tool — Puppet, Chef, Ansible, Terraform, etc.&lt;/li&gt; 
 &lt;li&gt;A trusted X.509 certificate (X5C provisioner)&lt;/li&gt; 
 &lt;li&gt;A host certificate from your Nebula network&lt;/li&gt; 
 &lt;li&gt;A SCEP challenge (SCEP provisioner)&lt;/li&gt; 
 &lt;li&gt;An SSH host certificates needing renewal (the SSHPOP provisioner)&lt;/li&gt; 
 &lt;li&gt;Learn more in our &lt;a href="https://smallstep.com/docs/step-ca/provisioners"&gt;provisioner documentation&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;🏔 Your own private ACME server&lt;/h3&gt; 
&lt;p&gt;ACME is the protocol used by Let's Encrypt to automate the issuance of HTTPS certificates. It's &lt;em&gt;super easy&lt;/em&gt; to issue certificates to any ACMEv2 (&lt;a href="https://tools.ietf.org/html/rfc8555"&gt;RFC8555&lt;/a&gt;) client.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://smallstep.com/blog/private-acme-server/#local-development--pre-production"&gt;Use ACME in development &amp;amp; pre-production&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Supports the most popular &lt;a href="https://letsencrypt.org/docs/challenge-types/"&gt;ACME challenge types&lt;/a&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;For &lt;code&gt;http-01&lt;/code&gt;, place a token at a well-known URL to prove that you control the web server&lt;/li&gt; 
   &lt;li&gt;For &lt;code&gt;dns-01&lt;/code&gt;, add a &lt;code&gt;TXT&lt;/code&gt; record to prove that you control the DNS record set&lt;/li&gt; 
   &lt;li&gt;For &lt;code&gt;tls-alpn-01&lt;/code&gt;, respond to the challenge at the TLS layer (&lt;a href="https://caddy.community/t/caddy-supports-the-acme-tls-alpn-challenge/4860"&gt;as Caddy does&lt;/a&gt;) to prove that you control the web server&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Works with any ACME client. We've written examples for:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://smallstep.com/docs/tutorials/acme-protocol-acme-clients#certbot"&gt;certbot&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://smallstep.com/docs/tutorials/acme-protocol-acme-clients#acmesh"&gt;acme.sh&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://smallstep.com/docs/tutorials/acme-protocol-acme-clients#win-acme"&gt;win-acme&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://smallstep.com/docs/tutorials/acme-protocol-acme-clients#caddy-v2"&gt;Caddy&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://smallstep.com/docs/tutorials/acme-protocol-acme-clients#traefik"&gt;Traefik&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://smallstep.com/docs/tutorials/acme-protocol-acme-clients#apache"&gt;Apache&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://smallstep.com/docs/tutorials/acme-protocol-acme-clients#nginx"&gt;nginx&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Get certificates programmatically using ACME, using these libraries:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/go-acme/lego"&gt;&lt;code&gt;lego&lt;/code&gt;&lt;/a&gt; for Golang (&lt;a href="https://smallstep.com/docs/tutorials/acme-protocol-acme-clients#golang"&gt;example usage&lt;/a&gt;)&lt;/li&gt; 
   &lt;li&gt;certbot's &lt;a href="https://github.com/certbot/certbot/tree/master/acme"&gt;&lt;code&gt;acme&lt;/code&gt; module&lt;/a&gt; for Python (&lt;a href="https://smallstep.com/docs/tutorials/acme-protocol-acme-clients#python"&gt;example usage&lt;/a&gt;)&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/publishlab/node-acme-client"&gt;&lt;code&gt;acme-client&lt;/code&gt;&lt;/a&gt; for Node.js (&lt;a href="https://smallstep.com/docs/tutorials/acme-protocol-acme-clients#node"&gt;example usage&lt;/a&gt;)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Our own &lt;a href="https://github.com/smallstep/cli"&gt;&lt;code&gt;step&lt;/code&gt; CLI tool&lt;/a&gt; is also an ACME client!&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;See our &lt;a href="https://smallstep.com/docs/tutorials/acme-challenge"&gt;ACME tutorial&lt;/a&gt; for more&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;👩🏽‍💻 An online SSH Certificate Authority&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Delegate SSH authentication to &lt;code&gt;step-ca&lt;/code&gt; by using &lt;a href="https://smallstep.com/blog/use-ssh-certificates/"&gt;SSH certificates&lt;/a&gt; instead of public keys and &lt;code&gt;authorized_keys&lt;/code&gt; files&lt;/li&gt; 
 &lt;li&gt;For user certificates, &lt;a href="https://smallstep.com/blog/diy-single-sign-on-for-ssh/"&gt;connect SSH to your single sign-on provider&lt;/a&gt;, to improve security with short-lived certificates and MFA (or other security policies) via any OAuth OIDC provider.&lt;/li&gt; 
 &lt;li&gt;For host certificates, improve security, &lt;a href="https://smallstep.com/blog/use-ssh-certificates/"&gt;eliminate TOFU warnings&lt;/a&gt;, and set up automated host certificate renewal.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;🤓 A general purpose PKI tool, via &lt;a href="https://github.com/smallstep/cli"&gt;&lt;code&gt;step&lt;/code&gt; CLI&lt;/a&gt; &lt;a href="https://smallstep.com/docs/step-cli/reference/ca/"&gt;integration&lt;/a&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Generate key pairs where they're needed so private keys are never transmitted across the network&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://smallstep.com/docs/step-cli/reference/ca/certificate/"&gt;Authenticate and obtain a certificate&lt;/a&gt; using any provisioner supported by &lt;code&gt;step-ca&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Securely &lt;a href="https://smallstep.com/docs/step-cli/reference/ca/root/"&gt;distribute root certificates&lt;/a&gt; and &lt;a href="https://smallstep.com/docs/step-cli/reference/ca/bootstrap/"&gt;bootstrap&lt;/a&gt; PKI relying parties&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://smallstep.com/docs/step-cli/reference/ca/renew/"&gt;Renew&lt;/a&gt; and &lt;a href="https://smallstep.com/docs/step-cli/reference/ca/revoke/"&gt;revoke&lt;/a&gt; certificates issued by &lt;code&gt;step-ca&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://smallstep.com/docs/step-cli/reference/certificate/install/"&gt;Install root certificates&lt;/a&gt; on your machine and browsers, so your CA is trusted&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://smallstep.com/docs/step-cli/reference/certificate/inspect/"&gt;Inspect&lt;/a&gt; and &lt;a href="https://smallstep.com/docs/step-cli/reference/certificate/lint/"&gt;lint&lt;/a&gt; certificates&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;See our installation docs &lt;a href="https://smallstep.com/docs/step-ca/installation"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://smallstep.com/docs/step-ca"&gt;Official documentation&lt;/a&gt; is on smallstep.com&lt;/li&gt; 
 &lt;li&gt;The &lt;code&gt;step&lt;/code&gt; command reference is available via &lt;code&gt;step help&lt;/code&gt;, &lt;a href="https://smallstep.com/docs/step-cli/reference/"&gt;on smallstep.com&lt;/a&gt;, or by running &lt;code&gt;step help --http=:8080&lt;/code&gt; from the command line and visiting &lt;a href="http://localhost:8080"&gt;http://localhost:8080&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Feedback?&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Tell us what you like and don't like about managing your PKI - we're eager to help solve problems in this space. &lt;a href="https://u.step.sm/discord"&gt;Join our Discord&lt;/a&gt; or &lt;a href="https://github.com/smallstep/certificates/discussions"&gt;GitHub Discussions&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Tell us about a feature you'd like to see! &lt;a href="https://github.com/smallstep/certificates/issues/new?assignees=&amp;amp;labels=enhancement%2C+needs+triage&amp;amp;template=enhancement.md&amp;amp;title="&gt;Request a Feature&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>modelcontextprotocol/go-sdk</title>
      <link>https://github.com/modelcontextprotocol/go-sdk</link>
      <description>&lt;p&gt;The official Go SDK for Model Context Protocol servers and clients. Maintained in collaboration with Google.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;MCP Go SDK&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://codespaces.new/modelcontextprotocol/go-sdk"&gt;&lt;img src="https://github.com/codespaces/badge.svg?sanitize=true" alt="Open in GitHub Codespaces" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://pkg.go.dev/github.com/modelcontextprotocol/go-sdk"&gt;&lt;img src="https://pkg.go.dev/badge/github.com/modelcontextprotocol/go-sdk" alt="PkgGoDev" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;This repository contains an implementation of the official Go software development kit (SDK) for the Model Context Protocol (MCP).&lt;/p&gt; 
&lt;h2&gt;Package / Feature documentation&lt;/h2&gt; 
&lt;p&gt;The SDK consists of several importable packages:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;The &lt;a href="https://pkg.go.dev/github.com/modelcontextprotocol/go-sdk/mcp"&gt;&lt;code&gt;github.com/modelcontextprotocol/go-sdk/mcp&lt;/code&gt;&lt;/a&gt; package defines the primary APIs for constructing and using MCP clients and servers.&lt;/li&gt; 
 &lt;li&gt;The &lt;a href="https://pkg.go.dev/github.com/modelcontextprotocol/go-sdk/jsonrpc"&gt;&lt;code&gt;github.com/modelcontextprotocol/go-sdk/jsonrpc&lt;/code&gt;&lt;/a&gt; package is for users implementing their own transports.&lt;/li&gt; 
 &lt;li&gt;The &lt;a href="https://pkg.go.dev/github.com/modelcontextprotocol/go-sdk/auth"&gt;&lt;code&gt;github.com/modelcontextprotocol/go-sdk/auth&lt;/code&gt;&lt;/a&gt; package provides some primitives for supporting OAuth.&lt;/li&gt; 
 &lt;li&gt;The &lt;a href="https://pkg.go.dev/github.com/modelcontextprotocol/go-sdk/oauthex"&gt;&lt;code&gt;github.com/modelcontextprotocol/go-sdk/oauthex&lt;/code&gt;&lt;/a&gt; package provides extensions to the OAuth protocol, such as ProtectedResourceMetadata.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The SDK endeavors to implement the full MCP spec. The &lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/go-sdk/main/docs/"&gt;&lt;code&gt;docs/&lt;/code&gt;&lt;/a&gt; directory contains feature documentation, mapping the MCP spec to the packages above.&lt;/p&gt; 
&lt;h2&gt;Getting started&lt;/h2&gt; 
&lt;p&gt;To get started creating an MCP server, create an &lt;code&gt;mcp.Server&lt;/code&gt; instance, add features to it, and then run it over an &lt;code&gt;mcp.Transport&lt;/code&gt;. For example, this server adds a single simple tool, and then connects it to clients over stdin/stdout:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;package main

import (
	"context"
	"log"

	"github.com/modelcontextprotocol/go-sdk/mcp"
)

type Input struct {
	Name string `json:"name" jsonschema:"the name of the person to greet"`
}

type Output struct {
	Greeting string `json:"greeting" jsonschema:"the greeting to tell to the user"`
}

func SayHi(ctx context.Context, req *mcp.CallToolRequest, input Input) (
	*mcp.CallToolResult,
	Output,
	error,
) {
	return nil, Output{Greeting: "Hi " + input.Name}, nil
}

func main() {
	// Create a server with a single tool.
	server := mcp.NewServer(&amp;amp;mcp.Implementation{Name: "greeter", Version: "v1.0.0"}, nil)
	mcp.AddTool(server, &amp;amp;mcp.Tool{Name: "greet", Description: "say hi"}, SayHi)
	// Run the server over stdin/stdout, until the client disconnects.
	if err := server.Run(context.Background(), &amp;amp;mcp.StdioTransport{}); err != nil {
		log.Fatal(err)
	}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To communicate with that server, create an &lt;code&gt;mcp.Client&lt;/code&gt; and connect it to the corresponding server, by running the server command and communicating over its stdin/stdout:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;package main

import (
	"context"
	"log"
	"os/exec"

	"github.com/modelcontextprotocol/go-sdk/mcp"
)

func main() {
	ctx := context.Background()

	// Create a new client, with no features.
	client := mcp.NewClient(&amp;amp;mcp.Implementation{Name: "mcp-client", Version: "v1.0.0"}, nil)

	// Connect to a server over stdin/stdout.
	transport := &amp;amp;mcp.CommandTransport{Command: exec.Command("myserver")}
	session, err := client.Connect(ctx, transport, nil)
	if err != nil {
		log.Fatal(err)
	}
	defer session.Close()

	// Call a tool on the server.
	params := &amp;amp;mcp.CallToolParams{
		Name:      "greet",
		Arguments: map[string]any{"name": "you"},
	}
	res, err := session.CallTool(ctx, params)
	if err != nil {
		log.Fatalf("CallTool failed: %v", err)
	}
	if res.IsError {
		log.Fatal("tool failed")
	}
	for _, c := range res.Content {
		log.Print(c.(*mcp.TextContent).Text)
	}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The &lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/go-sdk/main/examples/"&gt;&lt;code&gt;examples/&lt;/code&gt;&lt;/a&gt; directory contains more example clients and servers.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome contributions to the SDK! Please see &lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/go-sdk/main/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; for details of how to contribute.&lt;/p&gt; 
&lt;h2&gt;Acknowledgements / Alternatives&lt;/h2&gt; 
&lt;p&gt;Several third party Go MCP SDKs inspired the development and design of this official SDK, and continue to be viable alternatives, notably &lt;a href="https://github.com/mark3labs/mcp-go"&gt;mcp-go&lt;/a&gt;, originally authored by Ed Zynda. We are grateful to Ed as well as the other contributors to mcp-go, and to authors and contributors of other SDKs such as &lt;a href="https://github.com/metoro-io/mcp-golang"&gt;mcp-golang&lt;/a&gt; and &lt;a href="https://github.com/ThinkInAIXYZ/go-mcp"&gt;go-mcp&lt;/a&gt;. Thanks to their work, there is a thriving ecosystem of Go MCP clients and servers.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the MIT License - see the &lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/go-sdk/main/LICENSE"&gt;LICENSE&lt;/a&gt; file for details.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>hibiken/asynq</title>
      <link>https://github.com/hibiken/asynq</link>
      <description>&lt;p&gt;Simple, reliable, and efficient distributed task queue in Go&lt;/p&gt;&lt;hr&gt;&lt;img src="https://user-images.githubusercontent.com/11155743/114697792-ffbfa580-9d26-11eb-8e5b-33bef69476dc.png" alt="Asynq logo" width="360px" /&gt; 
&lt;h1&gt;Simple, reliable &amp;amp; efficient distributed task queue in Go&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://godoc.org/github.com/hibiken/asynq"&gt;&lt;img src="https://godoc.org/github.com/hibiken/asynq?status.svg?sanitize=true" alt="GoDoc" /&gt;&lt;/a&gt; &lt;a href="https://goreportcard.com/report/github.com/hibiken/asynq"&gt;&lt;img src="https://goreportcard.com/badge/github.com/hibiken/asynq" alt="Go Report Card" /&gt;&lt;/a&gt; &lt;img src="https://github.com/hibiken/asynq/workflows/build/badge.svg?sanitize=true" alt="Build Status" /&gt; &lt;a href="https://opensource.org/licenses/MIT"&gt;&lt;img src="https://img.shields.io/badge/license-MIT-green.svg?sanitize=true" alt="License: MIT" /&gt;&lt;/a&gt; &lt;a href="https://gitter.im/go-asynq/community"&gt;&lt;img src="https://badges.gitter.im/go-asynq/gitter.svg?sanitize=true" alt="Gitter chat" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Asynq is a Go library for queueing tasks and processing them asynchronously with workers. It's backed by &lt;a href="https://redis.io/"&gt;Redis&lt;/a&gt; and is designed to be scalable yet easy to get started.&lt;/p&gt; 
&lt;p&gt;Highlevel overview of how Asynq works:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Client puts tasks on a queue&lt;/li&gt; 
 &lt;li&gt;Server pulls tasks off queues and starts a worker goroutine for each task&lt;/li&gt; 
 &lt;li&gt;Tasks are processed concurrently by multiple workers&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Task queues are used as a mechanism to distribute work across multiple machines. A system can consist of multiple worker servers and brokers, giving way to high availability and horizontal scaling.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Example use case&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://user-images.githubusercontent.com/11155743/116358505-656f5f80-a806-11eb-9c16-94e49dab0f99.jpg" alt="Task Queue Diagram" /&gt;&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Guaranteed &lt;a href="https://www.cloudcomputingpatterns.org/at_least_once_delivery/"&gt;at least one execution&lt;/a&gt; of a task&lt;/li&gt; 
 &lt;li&gt;Scheduling of tasks&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/hibiken/asynq/wiki/Task-Retry"&gt;Retries&lt;/a&gt; of failed tasks&lt;/li&gt; 
 &lt;li&gt;Automatic recovery of tasks in the event of a worker crash&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/hibiken/asynq/wiki/Queue-Priority#weighted-priority"&gt;Weighted priority queues&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/hibiken/asynq/wiki/Queue-Priority#strict-priority"&gt;Strict priority queues&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Low latency to add a task since writes are fast in Redis&lt;/li&gt; 
 &lt;li&gt;De-duplication of tasks using &lt;a href="https://github.com/hibiken/asynq/wiki/Unique-Tasks"&gt;unique option&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Allow &lt;a href="https://github.com/hibiken/asynq/wiki/Task-Timeout-and-Cancelation"&gt;timeout and deadline per task&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Allow &lt;a href="https://github.com/hibiken/asynq/wiki/Task-aggregation"&gt;aggregating group of tasks&lt;/a&gt; to batch multiple successive operations&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/hibiken/asynq/wiki/Handler-Deep-Dive"&gt;Flexible handler interface with support for middlewares&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hibiken/asynq/master/tools/asynq/README.md#pause"&gt;Ability to pause queue&lt;/a&gt; to stop processing tasks from the queue&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/hibiken/asynq/wiki/Periodic-Tasks"&gt;Periodic Tasks&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/hibiken/asynq/wiki/Automatic-Failover"&gt;Support Redis Sentinels&lt;/a&gt; for high availability&lt;/li&gt; 
 &lt;li&gt;Integration with &lt;a href="https://prometheus.io/"&gt;Prometheus&lt;/a&gt; to collect and visualize queue metrics&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hibiken/asynq/master/#web-ui"&gt;Web UI&lt;/a&gt; to inspect and remote-control queues and tasks&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hibiken/asynq/master/#command-line-tool"&gt;CLI&lt;/a&gt; to inspect and remote-control queues and tasks&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Stability and Compatibility&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Status&lt;/strong&gt;: The library relatively stable and is currently undergoing &lt;strong&gt;moderate development&lt;/strong&gt; with less frequent breaking API changes.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;☝️ &lt;strong&gt;Important Note&lt;/strong&gt;: Current major version is zero (&lt;code&gt;v0.x.x&lt;/code&gt;) to accommodate rapid development and fast iteration while getting early feedback from users (&lt;em&gt;feedback on APIs are appreciated!&lt;/em&gt;). The public API could change without a major version update before &lt;code&gt;v1.0.0&lt;/code&gt; release.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Redis Cluster Compatibility&lt;/h3&gt; 
&lt;p&gt;Some of the lua scripts in this library may not be compatible with Redis Cluster.&lt;/p&gt; 
&lt;h2&gt;Sponsoring&lt;/h2&gt; 
&lt;p&gt;If you are using this package in production, &lt;strong&gt;please consider sponsoring the project to show your support!&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;Quickstart&lt;/h2&gt; 
&lt;p&gt;Make sure you have Go installed (&lt;a href="https://golang.org/dl/"&gt;download&lt;/a&gt;). The &lt;strong&gt;last two&lt;/strong&gt; Go versions are supported (See &lt;a href="https://go.dev/dl"&gt;https://go.dev/dl&lt;/a&gt;).&lt;/p&gt; 
&lt;p&gt;Initialize your project by creating a folder and then running &lt;code&gt;go mod init github.com/your/repo&lt;/code&gt; (&lt;a href="https://blog.golang.org/using-go-modules"&gt;learn more&lt;/a&gt;) inside the folder. Then install Asynq library with the &lt;a href="https://golang.org/cmd/go/#hdr-Add_dependencies_to_current_module_and_install_them"&gt;&lt;code&gt;go get&lt;/code&gt;&lt;/a&gt; command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;go get -u github.com/hibiken/asynq
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Make sure you're running a Redis server locally or from a &lt;a href="https://hub.docker.com/_/redis"&gt;Docker&lt;/a&gt; container. Version &lt;code&gt;4.0&lt;/code&gt; or higher is required.&lt;/p&gt; 
&lt;p&gt;Next, write a package that encapsulates task creation and task handling.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;package tasks

import (
    "context"
    "encoding/json"
    "fmt"
    "log"
    "time"
    "github.com/hibiken/asynq"
)

// A list of task types.
const (
    TypeEmailDelivery   = "email:deliver"
    TypeImageResize     = "image:resize"
)

type EmailDeliveryPayload struct {
    UserID     int
    TemplateID string
}

type ImageResizePayload struct {
    SourceURL string
}

//----------------------------------------------
// Write a function NewXXXTask to create a task.
// A task consists of a type and a payload.
//----------------------------------------------

func NewEmailDeliveryTask(userID int, tmplID string) (*asynq.Task, error) {
    payload, err := json.Marshal(EmailDeliveryPayload{UserID: userID, TemplateID: tmplID})
    if err != nil {
        return nil, err
    }
    return asynq.NewTask(TypeEmailDelivery, payload), nil
}

func NewImageResizeTask(src string) (*asynq.Task, error) {
    payload, err := json.Marshal(ImageResizePayload{SourceURL: src})
    if err != nil {
        return nil, err
    }
    // task options can be passed to NewTask, which can be overridden at enqueue time.
    return asynq.NewTask(TypeImageResize, payload, asynq.MaxRetry(5), asynq.Timeout(20 * time.Minute)), nil
}

//---------------------------------------------------------------
// Write a function HandleXXXTask to handle the input task.
// Note that it satisfies the asynq.HandlerFunc interface.
//
// Handler doesn't need to be a function. You can define a type
// that satisfies asynq.Handler interface. See examples below.
//---------------------------------------------------------------

func HandleEmailDeliveryTask(ctx context.Context, t *asynq.Task) error {
    var p EmailDeliveryPayload
    if err := json.Unmarshal(t.Payload(), &amp;amp;p); err != nil {
        return fmt.Errorf("json.Unmarshal failed: %v: %w", err, asynq.SkipRetry)
    }
    log.Printf("Sending Email to User: user_id=%d, template_id=%s", p.UserID, p.TemplateID)
    // Email delivery code ...
    return nil
}

// ImageProcessor implements asynq.Handler interface.
type ImageProcessor struct {
    // ... fields for struct
}

func (processor *ImageProcessor) ProcessTask(ctx context.Context, t *asynq.Task) error {
    var p ImageResizePayload
    if err := json.Unmarshal(t.Payload(), &amp;amp;p); err != nil {
        return fmt.Errorf("json.Unmarshal failed: %v: %w", err, asynq.SkipRetry)
    }
    log.Printf("Resizing image: src=%s", p.SourceURL)
    // Image resizing code ...
    return nil
}

func NewImageProcessor() *ImageProcessor {
	return &amp;amp;ImageProcessor{}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;In your application code, import the above package and use &lt;a href="https://pkg.go.dev/github.com/hibiken/asynq?tab=doc#Client"&gt;&lt;code&gt;Client&lt;/code&gt;&lt;/a&gt; to put tasks on queues.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;package main

import (
    "log"
    "time"

    "github.com/hibiken/asynq"
    "your/app/package/tasks"
)

const redisAddr = "127.0.0.1:6379"

func main() {
    client := asynq.NewClient(asynq.RedisClientOpt{Addr: redisAddr})
    defer client.Close()

    // ------------------------------------------------------
    // Example 1: Enqueue task to be processed immediately.
    //            Use (*Client).Enqueue method.
    // ------------------------------------------------------

    task, err := tasks.NewEmailDeliveryTask(42, "some:template:id")
    if err != nil {
        log.Fatalf("could not create task: %v", err)
    }
    info, err := client.Enqueue(task)
    if err != nil {
        log.Fatalf("could not enqueue task: %v", err)
    }
    log.Printf("enqueued task: id=%s queue=%s", info.ID, info.Queue)


    // ------------------------------------------------------------
    // Example 2: Schedule task to be processed in the future.
    //            Use ProcessIn or ProcessAt option.
    // ------------------------------------------------------------

    info, err = client.Enqueue(task, asynq.ProcessIn(24*time.Hour))
    if err != nil {
        log.Fatalf("could not schedule task: %v", err)
    }
    log.Printf("enqueued task: id=%s queue=%s", info.ID, info.Queue)


    // ----------------------------------------------------------------------------
    // Example 3: Set other options to tune task processing behavior.
    //            Options include MaxRetry, Queue, Timeout, Deadline, Unique etc.
    // ----------------------------------------------------------------------------

    task, err = tasks.NewImageResizeTask("https://example.com/myassets/image.jpg")
    if err != nil {
        log.Fatalf("could not create task: %v", err)
    }
    info, err = client.Enqueue(task, asynq.MaxRetry(10), asynq.Timeout(3 * time.Minute))
    if err != nil {
        log.Fatalf("could not enqueue task: %v", err)
    }
    log.Printf("enqueued task: id=%s queue=%s", info.ID, info.Queue)
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Next, start a worker server to process these tasks in the background. To start the background workers, use &lt;a href="https://pkg.go.dev/github.com/hibiken/asynq?tab=doc#Server"&gt;&lt;code&gt;Server&lt;/code&gt;&lt;/a&gt; and provide your &lt;a href="https://pkg.go.dev/github.com/hibiken/asynq?tab=doc#Handler"&gt;&lt;code&gt;Handler&lt;/code&gt;&lt;/a&gt; to process the tasks.&lt;/p&gt; 
&lt;p&gt;You can optionally use &lt;a href="https://pkg.go.dev/github.com/hibiken/asynq?tab=doc#ServeMux"&gt;&lt;code&gt;ServeMux&lt;/code&gt;&lt;/a&gt; to create a handler, just as you would with &lt;a href="https://golang.org/pkg/net/http/"&gt;&lt;code&gt;net/http&lt;/code&gt;&lt;/a&gt; Handler.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;package main

import (
    "log"

    "github.com/hibiken/asynq"
    "your/app/package/tasks"
)

const redisAddr = "127.0.0.1:6379"

func main() {
    srv := asynq.NewServer(
        asynq.RedisClientOpt{Addr: redisAddr},
        asynq.Config{
            // Specify how many concurrent workers to use
            Concurrency: 10,
            // Optionally specify multiple queues with different priority.
            Queues: map[string]int{
                "critical": 6,
                "default":  3,
                "low":      1,
            },
            // See the godoc for other configuration options
        },
    )

    // mux maps a type to a handler
    mux := asynq.NewServeMux()
    mux.HandleFunc(tasks.TypeEmailDelivery, tasks.HandleEmailDeliveryTask)
    mux.Handle(tasks.TypeImageResize, tasks.NewImageProcessor())
    // ...register other handlers...

    if err := srv.Run(mux); err != nil {
        log.Fatalf("could not run server: %v", err)
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For a more detailed walk-through of the library, see our &lt;a href="https://github.com/hibiken/asynq/wiki/Getting-Started"&gt;Getting Started&lt;/a&gt; guide.&lt;/p&gt; 
&lt;p&gt;To learn more about &lt;code&gt;asynq&lt;/code&gt; features and APIs, see the package &lt;a href="https://godoc.org/github.com/hibiken/asynq"&gt;godoc&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Web UI&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://github.com/hibiken/asynqmon"&gt;Asynqmon&lt;/a&gt; is a web based tool for monitoring and administrating Asynq queues and tasks.&lt;/p&gt; 
&lt;p&gt;Here's a few screenshots of the Web UI:&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Queues view&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://user-images.githubusercontent.com/11155743/114697016-07327f00-9d26-11eb-808c-0ac841dc888e.png" alt="Web UI Queues View" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Tasks view&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://user-images.githubusercontent.com/11155743/114697070-1f0a0300-9d26-11eb-855c-d3ec263865b7.png" alt="Web UI TasksView" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Metrics view&lt;/strong&gt; &lt;img width="1532" alt="Screen Shot 2021-12-19 at 4 37 19 PM" src="https://user-images.githubusercontent.com/10953044/146777420-cae6c476-bac6-469c-acce-b2f6584e8707.png" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Settings and adaptive dark mode&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://user-images.githubusercontent.com/11155743/114697149-3517c380-9d26-11eb-9f7a-ae2dd00aad5b.png" alt="Web UI Settings and adaptive dark mode" /&gt;&lt;/p&gt; 
&lt;p&gt;For details on how to use the tool, refer to the tool's &lt;a href="https://github.com/hibiken/asynqmon#readme"&gt;README&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Command Line Tool&lt;/h2&gt; 
&lt;p&gt;Asynq ships with a command line tool to inspect the state of queues and tasks.&lt;/p&gt; 
&lt;p&gt;To install the CLI tool, run the following command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;go install github.com/hibiken/asynq/tools/asynq@latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Here's an example of running the &lt;code&gt;asynq dash&lt;/code&gt; command:&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/hibiken/asynq/master/docs/assets/dash.gif" alt="Gif" /&gt;&lt;/p&gt; 
&lt;p&gt;For details on how to use the tool, refer to the tool's &lt;a href="https://raw.githubusercontent.com/hibiken/asynq/master/tools/asynq/README.md"&gt;README&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We are open to, and grateful for, any contributions (GitHub issues/PRs, feedback on &lt;a href="https://gitter.im/go-asynq/community"&gt;Gitter channel&lt;/a&gt;, etc) made by the community.&lt;/p&gt; 
&lt;p&gt;Please see the &lt;a href="https://raw.githubusercontent.com/hibiken/asynq/master/CONTRIBUTING.md"&gt;Contribution Guide&lt;/a&gt; before contributing.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Copyright (c) 2019-present &lt;a href="https://github.com/hibiken"&gt;Ken Hibino&lt;/a&gt; and &lt;a href="https://github.com/hibiken/asynq/graphs/contributors"&gt;Contributors&lt;/a&gt;. &lt;code&gt;Asynq&lt;/code&gt; is free and open-source software licensed under the &lt;a href="https://github.com/hibiken/asynq/raw/master/LICENSE"&gt;MIT License&lt;/a&gt;. Official logo was created by &lt;a href="https://github.com/koddr"&gt;Vic Shóstak&lt;/a&gt; and distributed under &lt;a href="https://creativecommons.org/publicdomain/zero/1.0/"&gt;Creative Commons&lt;/a&gt; license (CC0 1.0 Universal).&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>maximhq/bifrost</title>
      <link>https://github.com/maximhq/bifrost</link>
      <description>&lt;p&gt;Fastest LLM gateway (50x faster than LiteLLM) with adaptive load balancer, cluster mode, guardrails, 1000+ models support &amp; &lt;100 µs overhead at 5k RPS.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Bifrost&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://goreportcard.com/report/github.com/maximhq/bifrost/core"&gt;&lt;img src="https://goreportcard.com/badge/github.com/maximhq/bifrost/core" alt="Go Report Card" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/exN5KAydbU"&gt;&lt;img src="https://dcbadge.limes.pink/api/server/https://discord.gg/exN5KAydbU?style=flat" alt="Discord badge" /&gt;&lt;/a&gt; &lt;a href="https://snyk.io/test/github/maximhq/bifrost"&gt;&lt;img src="https://snyk.io/test/github/maximhq/bifrost/badge.svg?sanitize=true" alt="Known Vulnerabilities" /&gt;&lt;/a&gt; &lt;a href="https://codecov.io/gh/maximhq/bifrost"&gt;&lt;img src="https://codecov.io/gh/maximhq/bifrost/branch/main/graph/badge.svg?sanitize=true" alt="codecov" /&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/docker/pulls/maximhq/bifrost" alt="Docker Pulls" /&gt; &lt;a href="https://app.getpostman.com/run-collection/31642484-2ba0e658-4dcd-49f4-845a-0c7ed745b916?action=collection%2Ffork&amp;amp;source=rip_markdown&amp;amp;collection-url=entityId%3D31642484-2ba0e658-4dcd-49f4-845a-0c7ed745b916%26entityType%3Dcollection%26workspaceId%3D63e853c8-9aec-477f-909c-7f02f543150e"&gt;&lt;img src="https://run.pstmn.io/button.svg?sanitize=true" alt="Run In Postman" style="width: 95px; height: 21px;" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/maximhq/bifrost/main/LICENSE"&gt;&lt;img src="https://img.shields.io/github/license/maximhq/bifrost" alt="License" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;The fastest way to build AI applications that never go down&lt;/h2&gt; 
&lt;p&gt;Bifrost is a high-performance AI gateway that unifies access to 12+ providers (OpenAI, Anthropic, AWS Bedrock, Google Vertex, and more) through a single OpenAI-compatible API. Deploy in seconds with zero configuration and get automatic failover, load balancing, semantic caching, and enterprise-grade features.&lt;/p&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/maximhq/bifrost/main/docs/media/getting-started.png" alt="Get started" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Go from zero to production-ready AI gateway in under a minute.&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Step 1:&lt;/strong&gt; Start Bifrost Gateway&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Install and run locally
npx -y @maximhq/bifrost

# Or use Docker
docker run -p 8080:8080 maximhq/bifrost
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Step 2:&lt;/strong&gt; Configure via Web UI&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Open the built-in web interface
open http://localhost:8080
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Step 3:&lt;/strong&gt; Make your first API call&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -X POST http://localhost:8080/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "openai/gpt-4o-mini",
    "messages": [{"role": "user", "content": "Hello, Bifrost!"}]
  }'
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;That's it!&lt;/strong&gt; Your AI gateway is running with a web interface for visual configuration, real-time monitoring, and analytics.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Complete Setup Guides:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.getbifrost.ai/quickstart/gateway/setting-up"&gt;Gateway Setup&lt;/a&gt; - HTTP API deployment&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.getbifrost.ai/quickstart/go-sdk/setting-up"&gt;Go SDK Setup&lt;/a&gt; - Direct integration&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Key Features&lt;/h2&gt; 
&lt;h3&gt;Core Infrastructure&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.getbifrost.ai/features/unified-interface"&gt;Unified Interface&lt;/a&gt;&lt;/strong&gt; - Single OpenAI-compatible API for all providers&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.getbifrost.ai/quickstart/gateway/provider-configuration"&gt;Multi-Provider Support&lt;/a&gt;&lt;/strong&gt; - OpenAI, Anthropic, AWS Bedrock, Google Vertex, Azure, Cohere, Mistral, Ollama, Groq, and more&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.getbifrost.ai/features/fallbacks"&gt;Automatic Fallbacks&lt;/a&gt;&lt;/strong&gt; - Seamless failover between providers and models with zero downtime&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.getbifrost.ai/features/fallbacks"&gt;Load Balancing&lt;/a&gt;&lt;/strong&gt; - Intelligent request distribution across multiple API keys and providers&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Advanced Features&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.getbifrost.ai/features/mcp"&gt;Model Context Protocol (MCP)&lt;/a&gt;&lt;/strong&gt; - Enable AI models to use external tools (filesystem, web search, databases)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.getbifrost.ai/features/semantic-caching"&gt;Semantic Caching&lt;/a&gt;&lt;/strong&gt; - Intelligent response caching based on semantic similarity to reduce costs and latency&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.getbifrost.ai/quickstart/gateway/streaming"&gt;Multimodal Support&lt;/a&gt;&lt;/strong&gt; - Support for text,images, audio, and streaming, all behind a common interface.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.getbifrost.ai/enterprise/custom-plugins"&gt;Custom Plugins&lt;/a&gt;&lt;/strong&gt; - Extensible middleware architecture for analytics, monitoring, and custom logic&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.getbifrost.ai/features/governance"&gt;Governance&lt;/a&gt;&lt;/strong&gt; - Usage tracking, rate limiting, and fine-grained access control&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Enterprise &amp;amp; Security&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.getbifrost.ai/features/governance"&gt;Budget Management&lt;/a&gt;&lt;/strong&gt; - Hierarchical cost control with virtual keys, teams, and customer budgets&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.getbifrost.ai/features/sso-with-google-github"&gt;SSO Integration&lt;/a&gt;&lt;/strong&gt; - Google and GitHub authentication support&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.getbifrost.ai/features/observability"&gt;Observability&lt;/a&gt;&lt;/strong&gt; - Native Prometheus metrics, distributed tracing, and comprehensive logging&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.getbifrost.ai/enterprise/vault-support"&gt;Vault Support&lt;/a&gt;&lt;/strong&gt; - Secure API key management with HashiCorp Vault integration&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Developer Experience&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.getbifrost.ai/quickstart/gateway/setting-up"&gt;Zero-Config Startup&lt;/a&gt;&lt;/strong&gt; - Start immediately with dynamic provider configuration&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.getbifrost.ai/features/drop-in-replacement"&gt;Drop-in Replacement&lt;/a&gt;&lt;/strong&gt; - Replace OpenAI/Anthropic/GenAI APIs with one line of code&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.getbifrost.ai/integrations/what-is-an-integration"&gt;SDK Integrations&lt;/a&gt;&lt;/strong&gt; - Native support for popular AI SDKs with zero code changes&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.getbifrost.ai/quickstart/gateway/provider-configuration"&gt;Configuration Flexibility&lt;/a&gt;&lt;/strong&gt; - Web UI, API-driven, or file-based configuration options&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Repository Structure&lt;/h2&gt; 
&lt;p&gt;Bifrost uses a modular architecture for maximum flexibility:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-text"&gt;bifrost/
├── npx/                 # NPX script for easy installation
├── core/                # Core functionality and shared components
│   ├── providers/       # Provider-specific implementations (OpenAI, Anthropic, etc.)
│   ├── schemas/         # Interfaces and structs used throughout Bifrost
│   └── bifrost.go       # Main Bifrost implementation
├── framework/           # Framework components for data persistence
│   ├── configstore/     # Configuration storages
│   ├── logstore/        # Request logging storages
│   └── vectorstore/     # Vector storages
├── transports/          # HTTP gateway and other interface layers
│   └── bifrost-http/    # HTTP transport implementation
├── ui/                  # Web interface for HTTP gateway
├── plugins/             # Extensible plugin system
│   ├── governance/      # Budget management and access control
│   ├── jsonparser/      # JSON parsing and manipulation utilities
│   ├── logging/         # Request logging and analytics
│   ├── maxim/           # Maxim's observability integration
│   ├── mocker/          # Mock responses for testing and development
│   ├── semanticcache/   # Intelligent response caching
│   └── telemetry/       # Monitoring and observability
├── docs/                # Documentation and guides
└── tests/               # Comprehensive test suites
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Getting Started Options&lt;/h2&gt; 
&lt;p&gt;Choose the deployment method that fits your needs:&lt;/p&gt; 
&lt;h3&gt;1. Gateway (HTTP API)&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Best for:&lt;/strong&gt; Language-agnostic integration, microservices, and production deployments&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# NPX - Get started in 30 seconds
npx -y @maximhq/bifrost

# Docker - Production ready
docker run -p 8080:8080 -v $(pwd)/data:/app/data maximhq/bifrost
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Features:&lt;/strong&gt; Web UI, real-time monitoring, multi-provider management, zero-config startup&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Learn More:&lt;/strong&gt; &lt;a href="https://docs.getbifrost.ai/quickstart/gateway/setting-up"&gt;Gateway Setup Guide&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;2. Go SDK&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Best for:&lt;/strong&gt; Direct Go integration with maximum performance and control&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;go get github.com/maximhq/bifrost/core
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Features:&lt;/strong&gt; Native Go APIs, embedded deployment, custom middleware integration&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Learn More:&lt;/strong&gt; &lt;a href="https://docs.getbifrost.ai/quickstart/go-sdk/setting-up"&gt;Go SDK Guide&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;3. Drop-in Replacement&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Best for:&lt;/strong&gt; Migrating existing applications with zero code changes&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-diff"&gt;# OpenAI SDK
- base_url = "https://api.openai.com"
+ base_url = "http://localhost:8080/openai"

# Anthropic SDK  
- base_url = "https://api.anthropic.com"
+ base_url = "http://localhost:8080/anthropic"

# Google GenAI SDK
- api_endpoint = "https://generativelanguage.googleapis.com"
+ api_endpoint = "http://localhost:8080/genai"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Learn More:&lt;/strong&gt; &lt;a href="https://docs.getbifrost.ai/integrations/what-is-an-integration"&gt;Integration Guides&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Performance&lt;/h2&gt; 
&lt;p&gt;Bifrost adds virtually zero overhead to your AI requests. In sustained 5,000 RPS benchmarks, the gateway added only &lt;strong&gt;11 µs&lt;/strong&gt; of overhead per request.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Metric&lt;/th&gt; 
   &lt;th&gt;t3.medium&lt;/th&gt; 
   &lt;th&gt;t3.xlarge&lt;/th&gt; 
   &lt;th&gt;Improvement&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Added latency (Bifrost overhead)&lt;/td&gt; 
   &lt;td&gt;59 µs&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;11 µs&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;-81%&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Success rate @ 5k RPS&lt;/td&gt; 
   &lt;td&gt;100%&lt;/td&gt; 
   &lt;td&gt;100%&lt;/td&gt; 
   &lt;td&gt;No failed requests&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Avg. queue wait time&lt;/td&gt; 
   &lt;td&gt;47 µs&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;1.67 µs&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;-96%&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Avg. request latency (incl. provider)&lt;/td&gt; 
   &lt;td&gt;2.12 s&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;1.61 s&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;-24%&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;Key Performance Highlights:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Perfect Success Rate&lt;/strong&gt; - 100% request success rate even at 5k RPS&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Minimal Overhead&lt;/strong&gt; - Less than 15 µs additional latency per request&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Efficient Queuing&lt;/strong&gt; - Sub-microsecond average wait times&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Fast Key Selection&lt;/strong&gt; - ~10 ns to pick weighted API keys&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Complete Benchmarks:&lt;/strong&gt; &lt;a href="https://docs.getbifrost.ai/benchmarking/getting-started"&gt;Performance Analysis&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Complete Documentation:&lt;/strong&gt; &lt;a href="https://docs.getbifrost.ai"&gt;https://docs.getbifrost.ai&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Quick Start&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.getbifrost.ai/quickstart/gateway/setting-up"&gt;Gateway Setup&lt;/a&gt; - HTTP API deployment in 30 seconds&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.getbifrost.ai/quickstart/go-sdk/setting-up"&gt;Go SDK Setup&lt;/a&gt; - Direct Go integration&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.getbifrost.ai/quickstart/gateway/provider-configuration"&gt;Provider Configuration&lt;/a&gt; - Multi-provider setup&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Features&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.getbifrost.ai/features/unified-interface"&gt;Multi-Provider Support&lt;/a&gt; - Single API for all providers&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.getbifrost.ai/features/mcp"&gt;MCP Integration&lt;/a&gt; - External tool calling&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.getbifrost.ai/features/semantic-caching"&gt;Semantic Caching&lt;/a&gt; - Intelligent response caching&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.getbifrost.ai/features/fallbacks"&gt;Fallbacks &amp;amp; Load Balancing&lt;/a&gt; - Reliability features&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.getbifrost.ai/features/governance"&gt;Budget Management&lt;/a&gt; - Cost control and governance&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Integrations&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.getbifrost.ai/integrations/openai-sdk"&gt;OpenAI SDK&lt;/a&gt; - Drop-in OpenAI replacement&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.getbifrost.ai/integrations/anthropic-sdk"&gt;Anthropic SDK&lt;/a&gt; - Drop-in Anthropic replacement&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.getbifrost.ai/integrations/genai-sdk"&gt;Google GenAI SDK&lt;/a&gt; - Drop-in GenAI replacement&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.getbifrost.ai/integrations/litellm-sdk"&gt;LiteLLM SDK&lt;/a&gt; - LiteLLM integration&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.getbifrost.ai/integrations/langchain-sdk"&gt;Langchain SDK&lt;/a&gt; - Langchain integration&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Enterprise&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.getbifrost.ai/enterprise/custom-plugins"&gt;Custom Plugins&lt;/a&gt; - Extend functionality&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.getbifrost.ai/enterprise/clustering"&gt;Clustering&lt;/a&gt; - Multi-node deployment&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.getbifrost.ai/enterprise/vault-support"&gt;Vault Support&lt;/a&gt; - Secure key management&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.getbifrost.ai/deployment/docker-setup"&gt;Production Deployment&lt;/a&gt; - Scaling and monitoring&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Need Help?&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://discord.gg/exN5KAydbU"&gt;Join our Discord&lt;/a&gt;&lt;/strong&gt; for community support and discussions.&lt;/p&gt; 
&lt;p&gt;Get help with:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Quick setup assistance and troubleshooting&lt;/li&gt; 
 &lt;li&gt;Best practices and configuration tips&lt;/li&gt; 
 &lt;li&gt;Community discussions and support&lt;/li&gt; 
 &lt;li&gt;Real-time help with integrations&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome contributions of all kinds! See our &lt;a href="https://docs.getbifrost.ai/contributing/setting-up-repo"&gt;Contributing Guide&lt;/a&gt; for:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Setting up the development environment&lt;/li&gt; 
 &lt;li&gt;Code conventions and best practices&lt;/li&gt; 
 &lt;li&gt;How to submit pull requests&lt;/li&gt; 
 &lt;li&gt;Building and testing locally&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For development requirements and build instructions, see our &lt;a href="https://docs.getbifrost.ai/contributing/building-a-plugins"&gt;Development Setup Guide&lt;/a&gt;.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the Apache 2.0 License - see the &lt;a href="https://raw.githubusercontent.com/maximhq/bifrost/main/LICENSE"&gt;LICENSE&lt;/a&gt; file for details.&lt;/p&gt; 
&lt;p&gt;Built with ❤️ by &lt;a href="https://github.com/maximhq"&gt;Maxim&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>prometheus/node_exporter</title>
      <link>https://github.com/prometheus/node_exporter</link>
      <description>&lt;p&gt;Exporter for machine metrics&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Node exporter&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://circleci.com/gh/prometheus/node_exporter"&gt;&lt;img src="https://circleci.com/gh/prometheus/node_exporter/tree/master.svg?style=shield" alt="CircleCI" /&gt;&lt;/a&gt; &lt;img src="https://github.com/prometheus/node_exporter/actions/workflows/bsd.yml/badge.svg?sanitize=true" alt="bsd workflow" /&gt; &lt;img src="https://github.com/prometheus/node_exporter/actions/workflows/golangci-lint.yml/badge.svg?sanitize=true" alt="golangci-lint workflow" /&gt; &lt;a href="https://quay.io/repository/prometheus/node-exporter"&gt;&lt;img src="https://quay.io/repository/prometheus/node-exporter/status" alt="Docker Repository on Quay" /&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/r/prom/node-exporter/"&gt;&lt;img src="https://img.shields.io/docker/pulls/prom/node-exporter.svg?maxAge=604800" alt="Docker Pulls" /&gt;&lt;/a&gt; &lt;a href="https://goreportcard.com/report/github.com/prometheus/node_exporter"&gt;&lt;img src="https://goreportcard.com/badge/github.com/prometheus/node_exporter" alt="Go Report Card" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Prometheus exporter for hardware and OS metrics exposed by *NIX kernels, written in Go with pluggable metric collectors.&lt;/p&gt; 
&lt;p&gt;The &lt;a href="https://github.com/prometheus-community/windows_exporter"&gt;Windows exporter&lt;/a&gt; is recommended for Windows users. To expose NVIDIA GPU metrics, &lt;a href="https://github.com/NVIDIA/dcgm-exporter"&gt;prometheus-dcgm &lt;/a&gt; can be used.&lt;/p&gt; 
&lt;h2&gt;Installation and Usage&lt;/h2&gt; 
&lt;p&gt;If you are new to Prometheus and &lt;code&gt;node_exporter&lt;/code&gt; there is a &lt;a href="https://prometheus.io/docs/guides/node-exporter/"&gt;simple step-by-step guide&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;The &lt;code&gt;node_exporter&lt;/code&gt; listens on HTTP port 9100 by default. See the &lt;code&gt;--help&lt;/code&gt; output for more options.&lt;/p&gt; 
&lt;h3&gt;Ansible&lt;/h3&gt; 
&lt;p&gt;For automated installs with &lt;a href="https://www.ansible.com/"&gt;Ansible&lt;/a&gt;, there is the &lt;a href="https://github.com/prometheus-community/ansible"&gt;Prometheus Community role&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Docker&lt;/h3&gt; 
&lt;p&gt;The &lt;code&gt;node_exporter&lt;/code&gt; is designed to monitor the host system. Deploying in containers requires extra care in order to avoid monitoring the container itself.&lt;/p&gt; 
&lt;p&gt;For situations where containerized deployment is needed, some extra flags must be used to allow the &lt;code&gt;node_exporter&lt;/code&gt; access to the host namespaces.&lt;/p&gt; 
&lt;p&gt;Be aware that any non-root mount points you want to monitor will need to be bind-mounted into the container.&lt;/p&gt; 
&lt;p&gt;If you start container for host monitoring, specify &lt;code&gt;path.rootfs&lt;/code&gt; argument. This argument must match path in bind-mount of host root. The node_exporter will use &lt;code&gt;path.rootfs&lt;/code&gt; as prefix to access host filesystem.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run -d \
  --net="host" \
  --pid="host" \
  -v "/:/host:ro,rslave" \
  quay.io/prometheus/node-exporter:latest \
  --path.rootfs=/host
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For Docker compose, similar flag changes are needed.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;---
version: '3.8'

services:
  node_exporter:
    image: quay.io/prometheus/node-exporter:latest
    container_name: node_exporter
    command:
      - '--path.rootfs=/host'
    network_mode: host
    pid: host
    restart: unless-stopped
    volumes:
      - '/:/host:ro,rslave'
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;On some systems, the &lt;code&gt;timex&lt;/code&gt; collector requires an additional Docker flag, &lt;code&gt;--cap-add=SYS_TIME&lt;/code&gt;, in order to access the required syscalls.&lt;/p&gt; 
&lt;h2&gt;Collectors&lt;/h2&gt; 
&lt;p&gt;There is varying support for collectors on each operating system. The tables below list all existing collectors and the supported systems.&lt;/p&gt; 
&lt;p&gt;Collectors are enabled by providing a &lt;code&gt;--collector.&amp;lt;name&amp;gt;&lt;/code&gt; flag. Collectors that are enabled by default can be disabled by providing a &lt;code&gt;--no-collector.&amp;lt;name&amp;gt;&lt;/code&gt; flag. To enable only some specific collector(s), use &lt;code&gt;--collector.disable-defaults --collector.&amp;lt;name&amp;gt; ...&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;Include &amp;amp; Exclude flags&lt;/h3&gt; 
&lt;p&gt;A few collectors can be configured to include or exclude certain patterns using dedicated flags. The exclude flags are used to indicate "all except", while the include flags are used to say "none except". Note that these flags are mutually exclusive on collectors that support both.&lt;/p&gt; 
&lt;p&gt;Example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-txt"&gt;--collector.filesystem.mount-points-exclude=^/(dev|proc|sys|var/lib/docker/.+|var/lib/kubelet/.+)($|/)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;List:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Collector&lt;/th&gt; 
   &lt;th&gt;Scope&lt;/th&gt; 
   &lt;th&gt;Include Flag&lt;/th&gt; 
   &lt;th&gt;Exclude Flag&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;arp&lt;/td&gt; 
   &lt;td&gt;device&lt;/td&gt; 
   &lt;td&gt;--collector.arp.device-include&lt;/td&gt; 
   &lt;td&gt;--collector.arp.device-exclude&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;cpu&lt;/td&gt; 
   &lt;td&gt;bugs&lt;/td&gt; 
   &lt;td&gt;--collector.cpu.info.bugs-include&lt;/td&gt; 
   &lt;td&gt;N/A&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;cpu&lt;/td&gt; 
   &lt;td&gt;flags&lt;/td&gt; 
   &lt;td&gt;--collector.cpu.info.flags-include&lt;/td&gt; 
   &lt;td&gt;N/A&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;diskstats&lt;/td&gt; 
   &lt;td&gt;device&lt;/td&gt; 
   &lt;td&gt;--collector.diskstats.device-include&lt;/td&gt; 
   &lt;td&gt;--collector.diskstats.device-exclude&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ethtool&lt;/td&gt; 
   &lt;td&gt;device&lt;/td&gt; 
   &lt;td&gt;--collector.ethtool.device-include&lt;/td&gt; 
   &lt;td&gt;--collector.ethtool.device-exclude&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ethtool&lt;/td&gt; 
   &lt;td&gt;metrics&lt;/td&gt; 
   &lt;td&gt;--collector.ethtool.metrics-include&lt;/td&gt; 
   &lt;td&gt;N/A&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;filesystem&lt;/td&gt; 
   &lt;td&gt;fs-types&lt;/td&gt; 
   &lt;td&gt;--collector.filesystem.fs-types-include&lt;/td&gt; 
   &lt;td&gt;--collector.filesystem.fs-types-exclude&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;filesystem&lt;/td&gt; 
   &lt;td&gt;mount-points&lt;/td&gt; 
   &lt;td&gt;--collector.filesystem.mount-points-include&lt;/td&gt; 
   &lt;td&gt;--collector.filesystem.mount-points-exclude&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;hwmon&lt;/td&gt; 
   &lt;td&gt;chip&lt;/td&gt; 
   &lt;td&gt;--collector.hwmon.chip-include&lt;/td&gt; 
   &lt;td&gt;--collector.hwmon.chip-exclude&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;hwmon&lt;/td&gt; 
   &lt;td&gt;sensor&lt;/td&gt; 
   &lt;td&gt;--collector.hwmon.sensor-include&lt;/td&gt; 
   &lt;td&gt;--collector.hwmon.sensor-exclude&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;interrupts&lt;/td&gt; 
   &lt;td&gt;name&lt;/td&gt; 
   &lt;td&gt;--collector.interrupts.name-include&lt;/td&gt; 
   &lt;td&gt;--collector.interrupts.name-exclude&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;netdev&lt;/td&gt; 
   &lt;td&gt;device&lt;/td&gt; 
   &lt;td&gt;--collector.netdev.device-include&lt;/td&gt; 
   &lt;td&gt;--collector.netdev.device-exclude&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;qdisk&lt;/td&gt; 
   &lt;td&gt;device&lt;/td&gt; 
   &lt;td&gt;--collector.qdisk.device-include&lt;/td&gt; 
   &lt;td&gt;--collector.qdisk.device-exclude&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;slabinfo&lt;/td&gt; 
   &lt;td&gt;slab-names&lt;/td&gt; 
   &lt;td&gt;--collector.slabinfo.slabs-include&lt;/td&gt; 
   &lt;td&gt;--collector.slabinfo.slabs-exclude&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;sysctl&lt;/td&gt; 
   &lt;td&gt;all&lt;/td&gt; 
   &lt;td&gt;--collector.sysctl.include&lt;/td&gt; 
   &lt;td&gt;N/A&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;systemd&lt;/td&gt; 
   &lt;td&gt;unit&lt;/td&gt; 
   &lt;td&gt;--collector.systemd.unit-include&lt;/td&gt; 
   &lt;td&gt;--collector.systemd.unit-exclude&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Enabled by default&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Name&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;OS&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;arp&lt;/td&gt; 
   &lt;td&gt;Exposes ARP statistics from &lt;code&gt;/proc/net/arp&lt;/code&gt;.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;bcache&lt;/td&gt; 
   &lt;td&gt;Exposes bcache statistics from &lt;code&gt;/sys/fs/bcache/&lt;/code&gt;.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;bonding&lt;/td&gt; 
   &lt;td&gt;Exposes the number of configured and active slaves of Linux bonding interfaces.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;btrfs&lt;/td&gt; 
   &lt;td&gt;Exposes btrfs statistics&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;boottime&lt;/td&gt; 
   &lt;td&gt;Exposes system boot time derived from the &lt;code&gt;kern.boottime&lt;/code&gt; sysctl.&lt;/td&gt; 
   &lt;td&gt;Darwin, Dragonfly, FreeBSD, NetBSD, OpenBSD, Solaris&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;conntrack&lt;/td&gt; 
   &lt;td&gt;Shows conntrack statistics (does nothing if no &lt;code&gt;/proc/sys/net/netfilter/&lt;/code&gt; present).&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;cpu&lt;/td&gt; 
   &lt;td&gt;Exposes CPU statistics&lt;/td&gt; 
   &lt;td&gt;Darwin, Dragonfly, FreeBSD, Linux, Solaris, OpenBSD&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;cpufreq&lt;/td&gt; 
   &lt;td&gt;Exposes CPU frequency statistics&lt;/td&gt; 
   &lt;td&gt;Linux, Solaris&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;diskstats&lt;/td&gt; 
   &lt;td&gt;Exposes disk I/O statistics.&lt;/td&gt; 
   &lt;td&gt;Darwin, Linux, OpenBSD&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;dmi&lt;/td&gt; 
   &lt;td&gt;Expose Desktop Management Interface (DMI) info from &lt;code&gt;/sys/class/dmi/id/&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;edac&lt;/td&gt; 
   &lt;td&gt;Exposes error detection and correction statistics.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;entropy&lt;/td&gt; 
   &lt;td&gt;Exposes available entropy.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;exec&lt;/td&gt; 
   &lt;td&gt;Exposes execution statistics.&lt;/td&gt; 
   &lt;td&gt;Dragonfly, FreeBSD&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;fibrechannel&lt;/td&gt; 
   &lt;td&gt;Exposes fibre channel information and statistics from &lt;code&gt;/sys/class/fc_host/&lt;/code&gt;.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;filefd&lt;/td&gt; 
   &lt;td&gt;Exposes file descriptor statistics from &lt;code&gt;/proc/sys/fs/file-nr&lt;/code&gt;.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;filesystem&lt;/td&gt; 
   &lt;td&gt;Exposes filesystem statistics, such as disk space used.&lt;/td&gt; 
   &lt;td&gt;Darwin, Dragonfly, FreeBSD, Linux, OpenBSD&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;hwmon&lt;/td&gt; 
   &lt;td&gt;Expose hardware monitoring and sensor data from &lt;code&gt;/sys/class/hwmon/&lt;/code&gt;.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;infiniband&lt;/td&gt; 
   &lt;td&gt;Exposes network statistics specific to InfiniBand and Intel OmniPath configurations.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ipvs&lt;/td&gt; 
   &lt;td&gt;Exposes IPVS status from &lt;code&gt;/proc/net/ip_vs&lt;/code&gt; and stats from &lt;code&gt;/proc/net/ip_vs_stats&lt;/code&gt;.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;loadavg&lt;/td&gt; 
   &lt;td&gt;Exposes load average.&lt;/td&gt; 
   &lt;td&gt;Darwin, Dragonfly, FreeBSD, Linux, NetBSD, OpenBSD, Solaris&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;mdadm&lt;/td&gt; 
   &lt;td&gt;Exposes statistics about devices in &lt;code&gt;/proc/mdstat&lt;/code&gt; (does nothing if no &lt;code&gt;/proc/mdstat&lt;/code&gt; present).&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;meminfo&lt;/td&gt; 
   &lt;td&gt;Exposes memory statistics.&lt;/td&gt; 
   &lt;td&gt;Darwin, Dragonfly, FreeBSD, Linux, OpenBSD&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;netclass&lt;/td&gt; 
   &lt;td&gt;Exposes network interface info from &lt;code&gt;/sys/class/net/&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;netdev&lt;/td&gt; 
   &lt;td&gt;Exposes network interface statistics such as bytes transferred.&lt;/td&gt; 
   &lt;td&gt;Darwin, Dragonfly, FreeBSD, Linux, OpenBSD&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;netisr&lt;/td&gt; 
   &lt;td&gt;Exposes netisr statistics&lt;/td&gt; 
   &lt;td&gt;FreeBSD&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;netstat&lt;/td&gt; 
   &lt;td&gt;Exposes network statistics from &lt;code&gt;/proc/net/netstat&lt;/code&gt;. This is the same information as &lt;code&gt;netstat -s&lt;/code&gt;.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;nfs&lt;/td&gt; 
   &lt;td&gt;Exposes NFS client statistics from &lt;code&gt;/proc/net/rpc/nfs&lt;/code&gt;. This is the same information as &lt;code&gt;nfsstat -c&lt;/code&gt;.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;nfsd&lt;/td&gt; 
   &lt;td&gt;Exposes NFS kernel server statistics from &lt;code&gt;/proc/net/rpc/nfsd&lt;/code&gt;. This is the same information as &lt;code&gt;nfsstat -s&lt;/code&gt;.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;nvme&lt;/td&gt; 
   &lt;td&gt;Exposes NVMe info from &lt;code&gt;/sys/class/nvme/&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;os&lt;/td&gt; 
   &lt;td&gt;Expose OS release info from &lt;code&gt;/etc/os-release&lt;/code&gt; or &lt;code&gt;/usr/lib/os-release&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;em&gt;any&lt;/em&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;powersupplyclass&lt;/td&gt; 
   &lt;td&gt;Exposes Power Supply statistics from &lt;code&gt;/sys/class/power_supply&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;pressure&lt;/td&gt; 
   &lt;td&gt;Exposes pressure stall statistics from &lt;code&gt;/proc/pressure/&lt;/code&gt;.&lt;/td&gt; 
   &lt;td&gt;Linux (kernel 4.20+ and/or &lt;a href="https://www.kernel.org/doc/html/latest/accounting/psi.html"&gt;CONFIG_PSI&lt;/a&gt;)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;rapl&lt;/td&gt; 
   &lt;td&gt;Exposes various statistics from &lt;code&gt;/sys/class/powercap&lt;/code&gt;.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;schedstat&lt;/td&gt; 
   &lt;td&gt;Exposes task scheduler statistics from &lt;code&gt;/proc/schedstat&lt;/code&gt;.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;selinux&lt;/td&gt; 
   &lt;td&gt;Exposes SELinux statistics.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;sockstat&lt;/td&gt; 
   &lt;td&gt;Exposes various statistics from &lt;code&gt;/proc/net/sockstat&lt;/code&gt;.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;softnet&lt;/td&gt; 
   &lt;td&gt;Exposes statistics from &lt;code&gt;/proc/net/softnet_stat&lt;/code&gt;.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;stat&lt;/td&gt; 
   &lt;td&gt;Exposes various statistics from &lt;code&gt;/proc/stat&lt;/code&gt;. This includes boot time, forks and interrupts.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;tapestats&lt;/td&gt; 
   &lt;td&gt;Exposes statistics from &lt;code&gt;/sys/class/scsi_tape&lt;/code&gt;.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;textfile&lt;/td&gt; 
   &lt;td&gt;Exposes statistics read from local disk. The &lt;code&gt;--collector.textfile.directory&lt;/code&gt; flag must be set.&lt;/td&gt; 
   &lt;td&gt;&lt;em&gt;any&lt;/em&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;thermal&lt;/td&gt; 
   &lt;td&gt;Exposes thermal statistics like &lt;code&gt;pmset -g therm&lt;/code&gt;.&lt;/td&gt; 
   &lt;td&gt;Darwin&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;thermal_zone&lt;/td&gt; 
   &lt;td&gt;Exposes thermal zone &amp;amp; cooling device statistics from &lt;code&gt;/sys/class/thermal&lt;/code&gt;.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;time&lt;/td&gt; 
   &lt;td&gt;Exposes the current system time.&lt;/td&gt; 
   &lt;td&gt;&lt;em&gt;any&lt;/em&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;timex&lt;/td&gt; 
   &lt;td&gt;Exposes selected adjtimex(2) system call stats.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;udp_queues&lt;/td&gt; 
   &lt;td&gt;Exposes UDP total lengths of the rx_queue and tx_queue from &lt;code&gt;/proc/net/udp&lt;/code&gt; and &lt;code&gt;/proc/net/udp6&lt;/code&gt;.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;uname&lt;/td&gt; 
   &lt;td&gt;Exposes system information as provided by the uname system call.&lt;/td&gt; 
   &lt;td&gt;Darwin, FreeBSD, Linux, OpenBSD&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;vmstat&lt;/td&gt; 
   &lt;td&gt;Exposes statistics from &lt;code&gt;/proc/vmstat&lt;/code&gt;.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;watchdog&lt;/td&gt; 
   &lt;td&gt;Exposes statistics from &lt;code&gt;/sys/class/watchdog&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;xfs&lt;/td&gt; 
   &lt;td&gt;Exposes XFS runtime statistics.&lt;/td&gt; 
   &lt;td&gt;Linux (kernel 4.4+)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;zfs&lt;/td&gt; 
   &lt;td&gt;Exposes &lt;a href="http://open-zfs.org/"&gt;ZFS&lt;/a&gt; performance statistics.&lt;/td&gt; 
   &lt;td&gt;FreeBSD, &lt;a href="http://zfsonlinux.org/"&gt;Linux&lt;/a&gt;, Solaris&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Disabled by default&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;node_exporter&lt;/code&gt; also implements a number of collectors that are disabled by default. Reasons for this vary by collector, and may include:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;High cardinality&lt;/li&gt; 
 &lt;li&gt;Prolonged runtime that exceeds the Prometheus &lt;code&gt;scrape_interval&lt;/code&gt; or &lt;code&gt;scrape_timeout&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Significant resource demands on the host&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;You can enable additional collectors as desired by adding them to your init system's or service supervisor's startup configuration for &lt;code&gt;node_exporter&lt;/code&gt; but caution is advised. Enable at most one at a time, testing first on a non-production system, then by hand on a single production node. When enabling additional collectors, you should carefully monitor the change by observing the &lt;code&gt; scrape_duration_seconds&lt;/code&gt; metric to ensure that collection completes and does not time out. In addition, monitor the &lt;code&gt;scrape_samples_post_metric_relabeling&lt;/code&gt; metric to see the changes in cardinality.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Name&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;OS&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;buddyinfo&lt;/td&gt; 
   &lt;td&gt;Exposes statistics of memory fragments as reported by /proc/buddyinfo.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;cgroups&lt;/td&gt; 
   &lt;td&gt;A summary of the number of active and enabled cgroups&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;cpu_vulnerabilities&lt;/td&gt; 
   &lt;td&gt;Exposes CPU vulnerability information from sysfs.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;devstat&lt;/td&gt; 
   &lt;td&gt;Exposes device statistics&lt;/td&gt; 
   &lt;td&gt;Dragonfly, FreeBSD&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;drm&lt;/td&gt; 
   &lt;td&gt;Expose GPU metrics using sysfs / DRM, &lt;code&gt;amdgpu&lt;/code&gt; is the only driver which exposes this information through DRM&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;drbd&lt;/td&gt; 
   &lt;td&gt;Exposes Distributed Replicated Block Device statistics (to version 8.4)&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ethtool&lt;/td&gt; 
   &lt;td&gt;Exposes network interface information and network driver statistics equivalent to &lt;code&gt;ethtool&lt;/code&gt;, &lt;code&gt;ethtool -S&lt;/code&gt;, and &lt;code&gt;ethtool -i&lt;/code&gt;.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;interrupts&lt;/td&gt; 
   &lt;td&gt;Exposes detailed interrupts statistics.&lt;/td&gt; 
   &lt;td&gt;Linux, OpenBSD&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ksmd&lt;/td&gt; 
   &lt;td&gt;Exposes kernel and system statistics from &lt;code&gt;/sys/kernel/mm/ksm&lt;/code&gt;.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;lnstat&lt;/td&gt; 
   &lt;td&gt;Exposes stats from &lt;code&gt;/proc/net/stat/&lt;/code&gt;.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;logind&lt;/td&gt; 
   &lt;td&gt;Exposes session counts from &lt;a href="http://www.freedesktop.org/wiki/Software/systemd/logind/"&gt;logind&lt;/a&gt;.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;meminfo_numa&lt;/td&gt; 
   &lt;td&gt;Exposes memory statistics from &lt;code&gt;/sys/devices/system/node/node[0-9]*/meminfo&lt;/code&gt;, &lt;code&gt;/sys/devices/system/node/node[0-9]*/numastat&lt;/code&gt;.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;mountstats&lt;/td&gt; 
   &lt;td&gt;Exposes filesystem statistics from &lt;code&gt;/proc/self/mountstats&lt;/code&gt;. Exposes detailed NFS client statistics.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;network_route&lt;/td&gt; 
   &lt;td&gt;Exposes the routing table as metrics&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;pcidevice&lt;/td&gt; 
   &lt;td&gt;Exposes pci devices' information including their link status and parent devices.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;perf&lt;/td&gt; 
   &lt;td&gt;Exposes perf based metrics (Warning: Metrics are dependent on kernel configuration and settings).&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;processes&lt;/td&gt; 
   &lt;td&gt;Exposes aggregate process statistics from &lt;code&gt;/proc&lt;/code&gt;.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;qdisc&lt;/td&gt; 
   &lt;td&gt;Exposes &lt;a href="https://en.wikipedia.org/wiki/Network_scheduler#Linux_kernel"&gt;queuing discipline&lt;/a&gt; statistics&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;slabinfo&lt;/td&gt; 
   &lt;td&gt;Exposes slab statistics from &lt;code&gt;/proc/slabinfo&lt;/code&gt;. Note that permission of &lt;code&gt;/proc/slabinfo&lt;/code&gt; is usually 0400, so set it appropriately.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;softirqs&lt;/td&gt; 
   &lt;td&gt;Exposes detailed softirq statistics from &lt;code&gt;/proc/softirqs&lt;/code&gt;.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;sysctl&lt;/td&gt; 
   &lt;td&gt;Expose sysctl values from &lt;code&gt;/proc/sys&lt;/code&gt;. Use &lt;code&gt;--collector.sysctl.include(-info)&lt;/code&gt; to configure.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;swap&lt;/td&gt; 
   &lt;td&gt;Expose swap information from &lt;code&gt;/proc/swaps&lt;/code&gt;.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;systemd&lt;/td&gt; 
   &lt;td&gt;Exposes service and system status from &lt;a href="http://www.freedesktop.org/wiki/Software/systemd/"&gt;systemd&lt;/a&gt;.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;tcpstat&lt;/td&gt; 
   &lt;td&gt;Exposes TCP connection status information from &lt;code&gt;/proc/net/tcp&lt;/code&gt; and &lt;code&gt;/proc/net/tcp6&lt;/code&gt;. (Warning: the current version has potential performance issues in high load situations.)&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;wifi&lt;/td&gt; 
   &lt;td&gt;Exposes WiFi device and station statistics.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;xfrm&lt;/td&gt; 
   &lt;td&gt;Exposes statistics from &lt;code&gt;/proc/net/xfrm_stat&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;zoneinfo&lt;/td&gt; 
   &lt;td&gt;Exposes NUMA memory zone metrics.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Deprecated&lt;/h3&gt; 
&lt;p&gt;These collectors are deprecated and will be removed in the next major release.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Name&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;OS&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ntp&lt;/td&gt; 
   &lt;td&gt;Exposes local NTP daemon health to check &lt;a href="https://raw.githubusercontent.com/prometheus/node_exporter/master/docs/TIME.md"&gt;time&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;em&gt;any&lt;/em&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;runit&lt;/td&gt; 
   &lt;td&gt;Exposes service status from &lt;a href="http://smarden.org/runit/"&gt;runit&lt;/a&gt;.&lt;/td&gt; 
   &lt;td&gt;&lt;em&gt;any&lt;/em&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;supervisord&lt;/td&gt; 
   &lt;td&gt;Exposes service status from &lt;a href="http://supervisord.org/"&gt;supervisord&lt;/a&gt;.&lt;/td&gt; 
   &lt;td&gt;&lt;em&gt;any&lt;/em&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Perf Collector&lt;/h3&gt; 
&lt;p&gt;The &lt;code&gt;perf&lt;/code&gt; collector may not work out of the box on some Linux systems due to kernel configuration and security settings. To allow access, set the following &lt;code&gt;sysctl&lt;/code&gt; parameter:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;sysctl -w kernel.perf_event_paranoid=X
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;2 allow only user-space measurements (default since Linux 4.6).&lt;/li&gt; 
 &lt;li&gt;1 allow both kernel and user measurements (default before Linux 4.6).&lt;/li&gt; 
 &lt;li&gt;0 allow access to CPU-specific data but not raw tracepoint samples.&lt;/li&gt; 
 &lt;li&gt;-1 no restrictions.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Depending on the configured value different metrics will be available, for most cases &lt;code&gt;0&lt;/code&gt; will provide the most complete set. For more information see &lt;a href="http://man7.org/linux/man-pages/man2/perf_event_open.2.html"&gt;&lt;code&gt;man 2 perf_event_open&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;By default, the &lt;code&gt;perf&lt;/code&gt; collector will only collect metrics of the CPUs that &lt;code&gt;node_exporter&lt;/code&gt; is running on (ie &lt;a href="https://golang.org/pkg/runtime/#NumCPU"&gt;&lt;code&gt;runtime.NumCPU&lt;/code&gt;&lt;/a&gt;. If this is insufficient (e.g. if you run &lt;code&gt;node_exporter&lt;/code&gt; with its CPU affinity set to specific CPUs), you can specify a list of alternate CPUs by using the &lt;code&gt;--collector.perf.cpus&lt;/code&gt; flag. For example, to collect metrics on CPUs 2-6, you would specify: &lt;code&gt;--collector.perf --collector.perf.cpus=2-6&lt;/code&gt;. The CPU configuration is zero indexed and can also take a stride value; e.g. &lt;code&gt;--collector.perf --collector.perf.cpus=1-10:5&lt;/code&gt; would collect on CPUs 1, 5, and 10.&lt;/p&gt; 
&lt;p&gt;The &lt;code&gt;perf&lt;/code&gt; collector is also able to collect &lt;a href="https://www.kernel.org/doc/html/latest/core-api/tracepoint.html"&gt;tracepoint&lt;/a&gt; counts when using the &lt;code&gt;--collector.perf.tracepoint&lt;/code&gt; flag. Tracepoints can be found using &lt;a href="http://man7.org/linux/man-pages/man1/perf.1.html"&gt;&lt;code&gt;perf list&lt;/code&gt;&lt;/a&gt; or from debugfs. And example usage of this would be &lt;code&gt;--collector.perf.tracepoint="sched:sched_process_exec"&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;Sysctl Collector&lt;/h3&gt; 
&lt;p&gt;The &lt;code&gt;sysctl&lt;/code&gt; collector can be enabled with &lt;code&gt;--collector.sysctl&lt;/code&gt;. It supports exposing numeric sysctl values as metrics using the &lt;code&gt;--collector.sysctl.include&lt;/code&gt; flag and string values as info metrics by using the &lt;code&gt;--collector.sysctl.include-info&lt;/code&gt; flag. The flags can be repeated. For sysctl with multiple numeric values, an optional mapping can be given to expose each value as its own metric. Otherwise an &lt;code&gt;index&lt;/code&gt; label is used to identify the different fields.&lt;/p&gt; 
&lt;h4&gt;Examples&lt;/h4&gt; 
&lt;h5&gt;Numeric values&lt;/h5&gt; 
&lt;h6&gt;Single values&lt;/h6&gt; 
&lt;p&gt;Using &lt;code&gt;--collector.sysctl.include=vm.user_reserve_kbytes&lt;/code&gt;: &lt;code&gt;vm.user_reserve_kbytes = 131072&lt;/code&gt; -&amp;gt; &lt;code&gt;node_sysctl_vm_user_reserve_kbytes 131072&lt;/code&gt;&lt;/p&gt; 
&lt;h6&gt;Multiple values&lt;/h6&gt; 
&lt;p&gt;A sysctl can contain multiple values, for example:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;net.ipv4.tcp_rmem = 4096	131072	6291456
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Using &lt;code&gt;--collector.sysctl.include=net.ipv4.tcp_rmem&lt;/code&gt; the collector will expose:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;node_sysctl_net_ipv4_tcp_rmem{index="0"} 4096
node_sysctl_net_ipv4_tcp_rmem{index="1"} 131072
node_sysctl_net_ipv4_tcp_rmem{index="2"} 6291456
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If the indexes have defined meaning like in this case, the values can be mapped to multiple metrics by appending the mapping to the --collector.sysctl.include flag: Using &lt;code&gt;--collector.sysctl.include=net.ipv4.tcp_rmem:min,default,max&lt;/code&gt; the collector will expose:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;node_sysctl_net_ipv4_tcp_rmem_min 4096
node_sysctl_net_ipv4_tcp_rmem_default 131072
node_sysctl_net_ipv4_tcp_rmem_max 6291456
&lt;/code&gt;&lt;/pre&gt; 
&lt;h5&gt;String values&lt;/h5&gt; 
&lt;p&gt;String values need to be exposed as info metric. The user selects them by using the &lt;code&gt;--collector.sysctl.include-info&lt;/code&gt; flag.&lt;/p&gt; 
&lt;h6&gt;Single values&lt;/h6&gt; 
&lt;p&gt;&lt;code&gt;kernel.core_pattern = core&lt;/code&gt; -&amp;gt; &lt;code&gt;node_sysctl_info{key="kernel.core_pattern_info", value="core"} 1&lt;/code&gt;&lt;/p&gt; 
&lt;h6&gt;Multiple values&lt;/h6&gt; 
&lt;p&gt;Given the following sysctl:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;kernel.seccomp.actions_avail = kill_process kill_thread trap errno trace log allow
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Setting &lt;code&gt;--collector.sysctl.include-info=kernel.seccomp.actions_avail&lt;/code&gt; will yield:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;node_sysctl_info{key="kernel.seccomp.actions_avail", index="0", value="kill_process"} 1
node_sysctl_info{key="kernel.seccomp.actions_avail", index="1", value="kill_thread"} 1
...
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Textfile Collector&lt;/h3&gt; 
&lt;p&gt;The &lt;code&gt;textfile&lt;/code&gt; collector is similar to the &lt;a href="https://github.com/prometheus/pushgateway"&gt;Pushgateway&lt;/a&gt;, in that it allows exporting of statistics from batch jobs. It can also be used to export static metrics, such as what role a machine has. The Pushgateway should be used for service-level metrics. The &lt;code&gt;textfile&lt;/code&gt; module is for metrics that are tied to a machine.&lt;/p&gt; 
&lt;p&gt;To use it, set the &lt;code&gt;--collector.textfile.directory&lt;/code&gt; flag on the &lt;code&gt;node_exporter&lt;/code&gt; commandline. The collector will parse all files in that directory matching the glob &lt;code&gt;*.prom&lt;/code&gt; using the &lt;a href="http://prometheus.io/docs/instrumenting/exposition_formats/"&gt;text format&lt;/a&gt;. &lt;strong&gt;Note:&lt;/strong&gt; Timestamps are not supported.&lt;/p&gt; 
&lt;p&gt;To atomically push completion time for a cron job:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;echo my_batch_job_completion_time $(date +%s) &amp;gt; /path/to/directory/my_batch_job.prom.$$
mv /path/to/directory/my_batch_job.prom.$$ /path/to/directory/my_batch_job.prom
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To statically set roles for a machine using labels:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;echo 'role{role="application_server"} 1' &amp;gt; /path/to/directory/role.prom.$$
mv /path/to/directory/role.prom.$$ /path/to/directory/role.prom
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Filtering enabled collectors&lt;/h3&gt; 
&lt;p&gt;The &lt;code&gt;node_exporter&lt;/code&gt; will expose all metrics from enabled collectors by default. This is the recommended way to collect metrics to avoid errors when comparing metrics of different families.&lt;/p&gt; 
&lt;p&gt;For advanced use the &lt;code&gt;node_exporter&lt;/code&gt; can be passed an optional list of collectors to filter metrics. The parameters &lt;code&gt;collect[]&lt;/code&gt; and &lt;code&gt;exclude[]&lt;/code&gt; can be used multiple times (but cannot be combined). In Prometheus configuration you can use this syntax under the &lt;a href="https://prometheus.io/docs/prometheus/latest/configuration/configuration/#%3Cscrape_config%3E"&gt;scrape config&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Collect only &lt;code&gt;cpu&lt;/code&gt; and &lt;code&gt;meminfo&lt;/code&gt; collector metrics:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;  params:
    collect[]:
      - cpu
      - meminfo
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Collect all enabled collector metrics but exclude &lt;code&gt;netdev&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;  params:
    exclude[]:
      - netdev
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This can be useful for having different Prometheus servers collect specific metrics from nodes.&lt;/p&gt; 
&lt;h2&gt;Development building and running&lt;/h2&gt; 
&lt;p&gt;Prerequisites:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://golang.org/dl/"&gt;Go compiler&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;RHEL/CentOS: &lt;code&gt;glibc-static&lt;/code&gt; package.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Building:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;git clone https://github.com/prometheus/node_exporter.git
cd node_exporter
make build
./node_exporter &amp;lt;flags&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To see all available configuration flags:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;./node_exporter -h
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Running tests&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;make test
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;TLS endpoint&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;EXPERIMENTAL&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;The exporter supports TLS via a new web configuration file.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;./node_exporter --web.config.file=web-config.yml
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See the &lt;a href="https://github.com/prometheus/exporter-toolkit/raw/master/docs/web-configuration.md"&gt;exporter-toolkit web-configuration&lt;/a&gt; for more details.&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>