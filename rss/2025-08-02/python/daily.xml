<rss version="2.0">
  <channel>
    <title>GitHub Python Daily Trending</title>
    <description>Daily Trending of Python in GitHub</description>
    <pubDate>Fri, 01 Aug 2025 01:36:28 GMT</pubDate>
    <link>http://mshibanami.github.io/GitHubTrendingRSS</link>
    
    <item>
      <title>9001/copyparty</title>
      <link>https://github.com/9001/copyparty</link>
      <description>&lt;p&gt;Portable file server with accelerated resumable uploads, dedup, WebDAV, FTP, TFTP, zeroconf, media indexer, thumbnails++ all in one file, no deps&lt;/p&gt;&lt;hr&gt;&lt;img src="https://github.com/9001/copyparty/raw/hovudstraum/docs/logo.svg?sanitize=true" width="250" align="right"&gt; 
&lt;h3&gt;💾🎉 copyparty&lt;/h3&gt; 
&lt;p&gt;turn almost any device into a file server with resumable uploads/downloads using &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#browser-support"&gt;&lt;em&gt;any&lt;/em&gt;&lt;/a&gt; web browser&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;server only needs Python (2 or 3), all dependencies optional&lt;/li&gt; 
 &lt;li&gt;🔌 protocols: &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#the-browser"&gt;http&lt;/a&gt; // &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#webdav-server"&gt;webdav&lt;/a&gt; // &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#ftp-server"&gt;ftp&lt;/a&gt; // &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#tftp-server"&gt;tftp&lt;/a&gt; // &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#smb-server"&gt;smb/cifs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;📱 &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#android-app"&gt;android app&lt;/a&gt; // &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#ios-shortcuts"&gt;iPhone shortcuts&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;👉 &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#quickstart"&gt;Get started&lt;/a&gt;!&lt;/strong&gt; or visit the &lt;strong&gt;&lt;a href="https://a.ocv.me/pub/demo/"&gt;read-only demo server&lt;/a&gt;&lt;/strong&gt; 👀 running on a nuc in my basement&lt;/p&gt; 
&lt;p&gt;📷 &lt;strong&gt;screenshots:&lt;/strong&gt; &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#the-browser"&gt;browser&lt;/a&gt; // &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#uploading"&gt;upload&lt;/a&gt; // &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#unpost"&gt;unpost&lt;/a&gt; // &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#thumbnails"&gt;thumbnails&lt;/a&gt; // &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#searching"&gt;search&lt;/a&gt; // &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#file-search"&gt;fsearch&lt;/a&gt; // &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#zip-downloads"&gt;zip-DL&lt;/a&gt; // &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#markdown-viewer"&gt;md-viewer&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;🎬 &lt;strong&gt;videos:&lt;/strong&gt; &lt;a href="https://a.ocv.me/pub/demo/pics-vids/up2k.webm"&gt;upload&lt;/a&gt; // &lt;a href="https://a.ocv.me/pub/demo/pics-vids/u2cli.webm"&gt;cli-upload&lt;/a&gt; // &lt;a href="https://a.ocv.me/pub/g/nerd-stuff/cpp/2024-0418-race-the-beam.webm"&gt;race-the-beam&lt;/a&gt; // 👉 &lt;strong&gt;&lt;a href="https://a.ocv.me/pub/demo/showcase-hq.webm"&gt;feature-showcase&lt;/a&gt;&lt;/strong&gt; (&lt;a href="https://www.youtube.com/watch?v=15_-hgsX2V0"&gt;youtube&lt;/a&gt;)&lt;/p&gt; 
&lt;p&gt;made in Norway 🇳🇴&lt;/p&gt; 
&lt;h2&gt;readme toc&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;top 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#quickstart"&gt;quickstart&lt;/a&gt; - just run &lt;strong&gt;&lt;a href="https://github.com/9001/copyparty/releases/latest/download/copyparty-sfx.py"&gt;copyparty-sfx.py&lt;/a&gt;&lt;/strong&gt; -- that's it! 🎉 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#at-home"&gt;at home&lt;/a&gt; - make it accessible over the internet&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#on-servers"&gt;on servers&lt;/a&gt; - you may also want these, especially on servers&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#features"&gt;features&lt;/a&gt; - also see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/docs/versus.md"&gt;comparison to similar software&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#testimonials"&gt;testimonials&lt;/a&gt; - small collection of user feedback&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#motivations"&gt;motivations&lt;/a&gt; - project goals / philosophy 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#notes"&gt;notes&lt;/a&gt; - general notes&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#bugs"&gt;bugs&lt;/a&gt; - roughly sorted by chance of encounter 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#not-my-bugs"&gt;not my bugs&lt;/a&gt; - same order here too&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#breaking-changes"&gt;breaking changes&lt;/a&gt; - upgrade notes&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#FAQ"&gt;FAQ&lt;/a&gt; - "frequently" asked questions&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#accounts-and-volumes"&gt;accounts and volumes&lt;/a&gt; - per-folder, per-user permissions 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#shadowing"&gt;shadowing&lt;/a&gt; - hiding specific subfolders&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#dotfiles"&gt;dotfiles&lt;/a&gt; - unix-style hidden files/folders&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#the-browser"&gt;the browser&lt;/a&gt; - accessing a copyparty server using a web-browser 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#tabs"&gt;tabs&lt;/a&gt; - the main tabs in the ui&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#hotkeys"&gt;hotkeys&lt;/a&gt; - the browser has the following hotkeys&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#navpane"&gt;navpane&lt;/a&gt; - switching between breadcrumbs or navpane&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#thumbnails"&gt;thumbnails&lt;/a&gt; - press &lt;code&gt;g&lt;/code&gt; or &lt;code&gt;田&lt;/code&gt; to toggle grid-view instead of the file listing&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#zip-downloads"&gt;zip downloads&lt;/a&gt; - download folders (or file selections) as &lt;code&gt;zip&lt;/code&gt; or &lt;code&gt;tar&lt;/code&gt; files&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#uploading"&gt;uploading&lt;/a&gt; - drag files/folders into the web-browser to upload 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#file-search"&gt;file-search&lt;/a&gt; - dropping files into the browser also lets you see if they exist on the server&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#unpost"&gt;unpost&lt;/a&gt; - undo/delete accidental uploads&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#self-destruct"&gt;self-destruct&lt;/a&gt; - uploads can be given a lifetime&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#race-the-beam"&gt;race the beam&lt;/a&gt; - download files while they're still uploading (&lt;a href="http://a.ocv.me/pub/g/nerd-stuff/cpp/2024-0418-race-the-beam.webm"&gt;demo video&lt;/a&gt;)&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#incoming-files"&gt;incoming files&lt;/a&gt; - the control-panel shows the ETA for all incoming files&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#file-manager"&gt;file manager&lt;/a&gt; - cut/paste, rename, and delete files/folders (if you have permission)&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#shares"&gt;shares&lt;/a&gt; - share a file or folder by creating a temporary link&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#batch-rename"&gt;batch rename&lt;/a&gt; - select some files and press &lt;code&gt;F2&lt;/code&gt; to bring up the rename UI&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#rss-feeds"&gt;rss feeds&lt;/a&gt; - monitor a folder with your RSS reader&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#recent-uploads"&gt;recent uploads&lt;/a&gt; - list all recent uploads&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#media-player"&gt;media player&lt;/a&gt; - plays almost every audio format there is 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#playlists"&gt;playlists&lt;/a&gt; - create and play &lt;a href="https://en.wikipedia.org/wiki/M3U"&gt;m3u8&lt;/a&gt; playlists&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#creating-a-playlist"&gt;creating a playlist&lt;/a&gt; - with a standalone mediaplayer or copyparty&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#audio-equalizer"&gt;audio equalizer&lt;/a&gt; - and &lt;a href="https://en.wikipedia.org/wiki/Dynamic_range_compression"&gt;dynamic range compressor&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#fix-unreliable-playback-on-android"&gt;fix unreliable playback on android&lt;/a&gt; - due to phone / app settings&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#textfile-viewer"&gt;textfile viewer&lt;/a&gt; - with realtime streaming of logfiles and such (&lt;a href="https://a.ocv.me/pub/demo/logtail/"&gt;demo&lt;/a&gt;)&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#markdown-viewer"&gt;markdown viewer&lt;/a&gt; - and there are &lt;em&gt;two&lt;/em&gt; editors 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#markdown-vars"&gt;markdown vars&lt;/a&gt; - dynamic docs with serverside variable expansion&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#other-tricks"&gt;other tricks&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#searching"&gt;searching&lt;/a&gt; - search by size, date, path/name, mp3-tags, ...&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#server-config"&gt;server config&lt;/a&gt; - using arguments or config files, or a mix of both 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#zeroconf"&gt;zeroconf&lt;/a&gt; - announce enabled services on the LAN (&lt;a href="https://user-images.githubusercontent.com/241032/215344737-0eae8d98-9496-4256-9aa8-cd2f6971810d.png"&gt;pic&lt;/a&gt;) 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#mdns"&gt;mdns&lt;/a&gt; - LAN domain-name and feature announcer&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#ssdp"&gt;ssdp&lt;/a&gt; - windows-explorer announcer&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#qr-code"&gt;qr-code&lt;/a&gt; - print a qr-code &lt;a href="https://user-images.githubusercontent.com/241032/194728533-6f00849b-c6ac-43c6-9359-83e454d11e00.png"&gt;(screenshot)&lt;/a&gt; for quick access&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#ftp-server"&gt;ftp server&lt;/a&gt; - an FTP server can be started using &lt;code&gt;--ftp 3921&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#webdav-server"&gt;webdav server&lt;/a&gt; - with read-write support 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#connecting-to-webdav-from-windows"&gt;connecting to webdav from windows&lt;/a&gt; - using the GUI&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#tftp-server"&gt;tftp server&lt;/a&gt; - a TFTP server (read/write) can be started using &lt;code&gt;--tftp 3969&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#smb-server"&gt;smb server&lt;/a&gt; - unsafe, slow, not recommended for wan&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#browser-ux"&gt;browser ux&lt;/a&gt; - tweaking the ui&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#opengraph"&gt;opengraph&lt;/a&gt; - discord and social-media embeds&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#file-deduplication"&gt;file deduplication&lt;/a&gt; - enable symlink-based upload deduplication&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#file-indexing"&gt;file indexing&lt;/a&gt; - enable music search, upload-undo, and better dedup 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#exclude-patterns"&gt;exclude-patterns&lt;/a&gt; - to save some time&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#filesystem-guards"&gt;filesystem guards&lt;/a&gt; - avoid traversing into other filesystems&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#periodic-rescan"&gt;periodic rescan&lt;/a&gt; - filesystem monitoring&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#upload-rules"&gt;upload rules&lt;/a&gt; - set upload rules using volflags&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#compress-uploads"&gt;compress uploads&lt;/a&gt; - files can be autocompressed on upload&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#chmod-and-chown"&gt;chmod and chown&lt;/a&gt; - per-volume filesystem-permissions and ownership&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#other-flags"&gt;other flags&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#database-location"&gt;database location&lt;/a&gt; - in-volume (&lt;code&gt;.hist/up2k.db&lt;/code&gt;, default) or somewhere else&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#metadata-from-audio-files"&gt;metadata from audio files&lt;/a&gt; - set &lt;code&gt;-e2t&lt;/code&gt; to index tags on upload&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#file-parser-plugins"&gt;file parser plugins&lt;/a&gt; - provide custom parsers to index additional tags&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#event-hooks"&gt;event hooks&lt;/a&gt; - trigger a program on uploads, renames etc (&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/bin/hooks/"&gt;examples&lt;/a&gt;) 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#zeromq"&gt;zeromq&lt;/a&gt; - event-hooks can send zeromq messages&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#upload-events"&gt;upload events&lt;/a&gt; - the older, more powerful approach (&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/bin/mtag/"&gt;examples&lt;/a&gt;)&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#handlers"&gt;handlers&lt;/a&gt; - redefine behavior with plugins (&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/bin/handlers/"&gt;examples&lt;/a&gt;)&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#ip-auth"&gt;ip auth&lt;/a&gt; - autologin based on IP range (CIDR)&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#identity-providers"&gt;identity providers&lt;/a&gt; - replace copyparty passwords with oauth and such&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#user-changeable-passwords"&gt;user-changeable passwords&lt;/a&gt; - if permitted, users can change their own passwords&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#using-the-cloud-as-storage"&gt;using the cloud as storage&lt;/a&gt; - connecting to an aws s3 bucket and similar&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#hiding-from-google"&gt;hiding from google&lt;/a&gt; - tell search engines you don't wanna be indexed&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#themes"&gt;themes&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#complete-examples"&gt;complete examples&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#listen-on-port-80-and-443"&gt;listen on port 80 and 443&lt;/a&gt; - become a &lt;em&gt;real&lt;/em&gt; webserver&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#reverse-proxy"&gt;reverse-proxy&lt;/a&gt; - running copyparty next to other websites 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#real-ip"&gt;real-ip&lt;/a&gt; - teaching copyparty how to see client IPs&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#reverse-proxy-performance"&gt;reverse-proxy performance&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#permanent-cloudflare-tunnel"&gt;permanent cloudflare tunnel&lt;/a&gt; - if you have a domain and want to get your copyparty online real quick&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#prometheus"&gt;prometheus&lt;/a&gt; - metrics/stats can be enabled&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#other-extremely-specific-features"&gt;other extremely specific features&lt;/a&gt; - you'll never find a use for these 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#custom-mimetypes"&gt;custom mimetypes&lt;/a&gt; - change the association of a file extension&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#GDPR-compliance"&gt;GDPR compliance&lt;/a&gt; - imagine using copyparty professionally...&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#feature-chickenbits"&gt;feature chickenbits&lt;/a&gt; - buggy feature? rip it out&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#feature-beefybits"&gt;feature beefybits&lt;/a&gt; - force-enable features with known issues on your OS/env&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#packages"&gt;packages&lt;/a&gt; - the party might be closer than you think 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#arch-package"&gt;arch package&lt;/a&gt; - &lt;code&gt;pacman -S copyparty&lt;/code&gt; (in &lt;a href="https://archlinux.org/packages/extra/any/copyparty/"&gt;arch linux extra&lt;/a&gt;)&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#fedora-package"&gt;fedora package&lt;/a&gt; - does not exist yet&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#nix-package"&gt;nix package&lt;/a&gt; - &lt;code&gt;nix profile install github:9001/copyparty&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#nixos-module"&gt;nixos module&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#browser-support"&gt;browser support&lt;/a&gt; - TLDR: yes&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#client-examples"&gt;client examples&lt;/a&gt; - interact with copyparty using non-browser clients 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#folder-sync"&gt;folder sync&lt;/a&gt; - sync folders to/from copyparty&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#mount-as-drive"&gt;mount as drive&lt;/a&gt; - a remote copyparty server as a local filesystem&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#android-app"&gt;android app&lt;/a&gt; - upload to copyparty with one tap&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#iOS-shortcuts"&gt;iOS shortcuts&lt;/a&gt; - there is no iPhone app, but&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#performance"&gt;performance&lt;/a&gt; - defaults are usually fine - expect &lt;code&gt;8 GiB/s&lt;/code&gt; download, &lt;code&gt;1 GiB/s&lt;/code&gt; upload 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#client-side"&gt;client-side&lt;/a&gt; - when uploading files&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#security"&gt;security&lt;/a&gt; - there is a &lt;a href="https://discord.gg/25J8CdTT6G"&gt;discord server&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#gotchas"&gt;gotchas&lt;/a&gt; - behavior that might be unexpected&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#cors"&gt;cors&lt;/a&gt; - cross-site request config&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#filekeys"&gt;filekeys&lt;/a&gt; - prevent filename bruteforcing 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#dirkeys"&gt;dirkeys&lt;/a&gt; - share specific folders in a volume&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#password-hashing"&gt;password hashing&lt;/a&gt; - you can hash passwords&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#https"&gt;https&lt;/a&gt; - both HTTP and HTTPS are accepted&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#recovering-from-crashes"&gt;recovering from crashes&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#client-crashes"&gt;client crashes&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#firefox-wsod"&gt;firefox wsod&lt;/a&gt; - firefox 87 can crash during uploads&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#HTTP-API"&gt;HTTP API&lt;/a&gt; - see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/docs/devnotes.md#http-api"&gt;devnotes&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#dependencies"&gt;dependencies&lt;/a&gt; - mandatory deps 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#optional-dependencies"&gt;optional dependencies&lt;/a&gt; - install these to enable bonus features 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#dependency-chickenbits"&gt;dependency chickenbits&lt;/a&gt; - prevent loading an optional dependency&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#optional-gpl-stuff"&gt;optional gpl stuff&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#sfx"&gt;sfx&lt;/a&gt; - the self-contained "binary" (recommended!) 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#copypartyexe"&gt;copyparty.exe&lt;/a&gt; - download &lt;a href="https://github.com/9001/copyparty/releases/latest/download/copyparty.exe"&gt;copyparty.exe&lt;/a&gt; (win8+) or &lt;a href="https://github.com/9001/copyparty/releases/latest/download/copyparty32.exe"&gt;copyparty32.exe&lt;/a&gt; (win7+)&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#zipapp"&gt;zipapp&lt;/a&gt; - another emergency alternative, &lt;a href="https://github.com/9001/copyparty/releases/latest/download/copyparty.pyz"&gt;copyparty.pyz&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#install-on-android"&gt;install on android&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#reporting-bugs"&gt;reporting bugs&lt;/a&gt; - ideas for context to include, and where to submit them&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#devnotes"&gt;devnotes&lt;/a&gt; - for build instructions etc, see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/docs/devnotes.md"&gt;./docs/devnotes.md&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;quickstart&lt;/h2&gt; 
&lt;p&gt;just run &lt;strong&gt;&lt;a href="https://github.com/9001/copyparty/releases/latest/download/copyparty-sfx.py"&gt;copyparty-sfx.py&lt;/a&gt;&lt;/strong&gt; -- that's it! 🎉&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;or install through &lt;a href="https://pypi.org/project/copyparty/"&gt;pypi&lt;/a&gt;: &lt;code&gt;python3 -m pip install --user -U copyparty&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;or if you cannot install python, you can use &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#copypartyexe"&gt;copyparty.exe&lt;/a&gt; instead&lt;/li&gt; 
 &lt;li&gt;or install &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#arch-package"&gt;on arch&lt;/a&gt; ╱ &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#nixos-module"&gt;on NixOS&lt;/a&gt; ╱ &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#nix-package"&gt;through nix&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;or if you are on android, &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#install-on-android"&gt;install copyparty in termux&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;or maybe you have a &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/docs/synology-dsm.md"&gt;synology nas / dsm&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;or if you have &lt;a href="https://docs.astral.sh/uv/"&gt;uv&lt;/a&gt; installed, run &lt;code&gt;uv tool run copyparty&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;or if your computer is messed up and nothing else works, &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#zipapp"&gt;try the pyz&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;or if your OS is dead, give the &lt;a href="https://a.ocv.me/pub/stuff/edcd001/enterprise-edition/"&gt;bootable flashdrive / cd-rom&lt;/a&gt; a spin&lt;/li&gt; 
 &lt;li&gt;or if you don't trust copyparty yet and want to isolate it a little, then... 
  &lt;ul&gt; 
   &lt;li&gt;...maybe &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/bin/prisonparty.sh"&gt;prisonparty&lt;/a&gt; to create a tiny &lt;a href="https://wiki.archlinux.org/title/Chroot"&gt;chroot&lt;/a&gt; (very portable),&lt;/li&gt; 
   &lt;li&gt;...or &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/bin/bubbleparty.sh"&gt;bubbleparty&lt;/a&gt; to wrap it in &lt;a href="https://github.com/containers/bubblewrap"&gt;bubblewrap&lt;/a&gt; (much better)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;or if you prefer to &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/scripts/docker/"&gt;use docker&lt;/a&gt; 🐋 you can do that too 
  &lt;ul&gt; 
   &lt;li&gt;docker has all deps built-in, so skip this step:&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;enable thumbnails (images/audio/video), media indexing, and audio transcoding by installing some recommended deps:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Alpine:&lt;/strong&gt; &lt;code&gt;apk add py3-pillow ffmpeg&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Debian:&lt;/strong&gt; &lt;code&gt;apt install --no-install-recommends python3-pil ffmpeg&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Fedora:&lt;/strong&gt; rpmfusion + &lt;code&gt;dnf install python3-pillow ffmpeg --allowerasing&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;FreeBSD:&lt;/strong&gt; &lt;code&gt;pkg install py39-sqlite3 py39-pillow ffmpeg&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;MacOS:&lt;/strong&gt; &lt;code&gt;port install py-Pillow ffmpeg&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;MacOS&lt;/strong&gt; (alternative): &lt;code&gt;brew install pillow ffmpeg&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Windows:&lt;/strong&gt; &lt;code&gt;python -m pip install --user -U Pillow&lt;/code&gt; 
  &lt;ul&gt; 
   &lt;li&gt;install &lt;a href="https://www.python.org/downloads/windows/"&gt;python&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#optional-dependencies"&gt;ffmpeg&lt;/a&gt; manually; do not use &lt;code&gt;winget&lt;/code&gt; or &lt;code&gt;Microsoft Store&lt;/code&gt; (it breaks $PATH)&lt;/li&gt; 
   &lt;li&gt;copyparty.exe comes with &lt;code&gt;Pillow&lt;/code&gt; and only needs &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#optional-dependencies"&gt;ffmpeg&lt;/a&gt; for mediatags/videothumbs&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#optional-dependencies"&gt;optional dependencies&lt;/a&gt; to enable even more features&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;running copyparty without arguments (for example doubleclicking it on Windows) will give everyone read/write access to the current folder; you may want &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#accounts-and-volumes"&gt;accounts and volumes&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;or see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#complete-examples"&gt;some usage examples&lt;/a&gt; for inspiration, or the &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/docs/examples/windows.md"&gt;complete windows example&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;some recommended options:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;-e2dsa&lt;/code&gt; enables general &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#file-indexing"&gt;file indexing&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-e2ts&lt;/code&gt; enables audio metadata indexing (needs either FFprobe or Mutagen)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-v /mnt/music:/music:r:rw,foo -a foo:bar&lt;/code&gt; shares &lt;code&gt;/mnt/music&lt;/code&gt; as &lt;code&gt;/music&lt;/code&gt;, &lt;code&gt;r&lt;/code&gt;eadable by anyone, and read-write for user &lt;code&gt;foo&lt;/code&gt;, password &lt;code&gt;bar&lt;/code&gt; 
  &lt;ul&gt; 
   &lt;li&gt;replace &lt;code&gt;:r:rw,foo&lt;/code&gt; with &lt;code&gt;:r,foo&lt;/code&gt; to only make the folder readable by &lt;code&gt;foo&lt;/code&gt; and nobody else&lt;/li&gt; 
   &lt;li&gt;see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#accounts-and-volumes"&gt;accounts and volumes&lt;/a&gt; (or &lt;code&gt;--help-accounts&lt;/code&gt;) for the syntax and other permissions&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;at home&lt;/h3&gt; 
&lt;p&gt;make it accessible over the internet by starting a &lt;a href="https://developers.cloudflare.com/cloudflare-one/connections/connect-networks/do-more-with-tunnels/trycloudflare/"&gt;cloudflare quicktunnel&lt;/a&gt; like so:&lt;/p&gt; 
&lt;p&gt;first download &lt;a href="https://developers.cloudflare.com/cloudflare-one/connections/connect-networks/downloads/"&gt;cloudflared&lt;/a&gt; and then start the tunnel with &lt;code&gt;cloudflared tunnel --url http://127.0.0.1:3923&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;as the tunnel starts, it will show a URL which you can share to let anyone browse your stash or upload files to you&lt;/p&gt; 
&lt;p&gt;but if you have a domain, then you probably want to skip the random autogenerated URL and instead make a &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#permanent-cloudflare-tunnel"&gt;permanent cloudflare tunnel&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;since people will be connecting through cloudflare, run copyparty with &lt;code&gt;--xff-hdr cf-connecting-ip&lt;/code&gt; to detect client IPs correctly&lt;/p&gt; 
&lt;h3&gt;on servers&lt;/h3&gt; 
&lt;p&gt;you may also want these, especially on servers:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/contrib/systemd/copyparty.service"&gt;contrib/systemd/copyparty.service&lt;/a&gt; to run copyparty as a systemd service (see guide inside)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/contrib/systemd/prisonparty.service"&gt;contrib/systemd/prisonparty.service&lt;/a&gt; to run it in a chroot (for extra security)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/contrib/openrc/copyparty"&gt;contrib/openrc/copyparty&lt;/a&gt; to run copyparty on Alpine / Gentoo&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/contrib/rc/copyparty"&gt;contrib/rc/copyparty&lt;/a&gt; to run copyparty on FreeBSD&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#nixos-module"&gt;nixos module&lt;/a&gt; to run copyparty on NixOS hosts&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/contrib/nginx/copyparty.conf"&gt;contrib/nginx/copyparty.conf&lt;/a&gt; to &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#reverse-proxy"&gt;reverse-proxy&lt;/a&gt; behind nginx (for better https)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;and remember to open the ports you want; here's a complete example including every feature copyparty has to offer:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;firewall-cmd --permanent --add-port={80,443,3921,3923,3945,3990}/tcp  # --zone=libvirt
firewall-cmd --permanent --add-port=12000-12099/tcp  # --zone=libvirt
firewall-cmd --permanent --add-port={69,1900,3969,5353}/udp  # --zone=libvirt
firewall-cmd --reload
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;(69:tftp, 1900:ssdp, 3921:ftp, 3923:http/https, 3945:smb, 3969:tftp, 3990:ftps, 5353:mdns, 12000:passive-ftp)&lt;/p&gt; 
&lt;h2&gt;features&lt;/h2&gt; 
&lt;p&gt;also see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/docs/versus.md"&gt;comparison to similar software&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;backend stuff 
  &lt;ul&gt; 
   &lt;li&gt;☑ IPv6 + unix-sockets&lt;/li&gt; 
   &lt;li&gt;☑ &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#performance"&gt;multiprocessing&lt;/a&gt; (actual multithreading)&lt;/li&gt; 
   &lt;li&gt;☑ volumes (mountpoints)&lt;/li&gt; 
   &lt;li&gt;☑ &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#accounts-and-volumes"&gt;accounts&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;☑ &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#ftp-server"&gt;ftp server&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;☑ &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#tftp-server"&gt;tftp server&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;☑ &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#webdav-server"&gt;webdav server&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;☑ &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#smb-server"&gt;smb/cifs server&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;☑ &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#qr-code"&gt;qr-code&lt;/a&gt; for quick access&lt;/li&gt; 
   &lt;li&gt;☑ &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#zeroconf"&gt;upnp / zeroconf / mdns / ssdp&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;☑ &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#event-hooks"&gt;event hooks&lt;/a&gt; / script runner&lt;/li&gt; 
   &lt;li&gt;☑ &lt;a href="https://github.com/9001/copyparty#reverse-proxy"&gt;reverse-proxy support&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;☑ cross-platform (Windows, Linux, Macos, Android, FreeBSD, arm32/arm64, ppc64le, s390x, risc-v/riscv64)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;upload 
  &lt;ul&gt; 
   &lt;li&gt;☑ basic: plain multipart, ie6 support&lt;/li&gt; 
   &lt;li&gt;☑ &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#uploading"&gt;up2k&lt;/a&gt;: js, resumable, multithreaded 
    &lt;ul&gt; 
     &lt;li&gt;&lt;strong&gt;no filesize limit!&lt;/strong&gt; even on Cloudflare&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;☑ stash: simple PUT filedropper&lt;/li&gt; 
   &lt;li&gt;☑ filename randomizer&lt;/li&gt; 
   &lt;li&gt;☑ write-only folders&lt;/li&gt; 
   &lt;li&gt;☑ &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#unpost"&gt;unpost&lt;/a&gt;: undo/delete accidental uploads&lt;/li&gt; 
   &lt;li&gt;☑ &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#self-destruct"&gt;self-destruct&lt;/a&gt; (specified server-side or client-side)&lt;/li&gt; 
   &lt;li&gt;☑ &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#race-the-beam"&gt;race the beam&lt;/a&gt; (almost like peer-to-peer)&lt;/li&gt; 
   &lt;li&gt;☑ symlink/discard duplicates (content-matching)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;download 
  &lt;ul&gt; 
   &lt;li&gt;☑ single files in browser&lt;/li&gt; 
   &lt;li&gt;☑ &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#zip-downloads"&gt;folders as zip / tar files&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;☑ &lt;a href="https://github.com/9001/copyparty/tree/hovudstraum/bin#partyfusepy"&gt;FUSE client&lt;/a&gt; (read-only)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;browser 
  &lt;ul&gt; 
   &lt;li&gt;☑ &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#navpane"&gt;navpane&lt;/a&gt; (directory tree sidebar)&lt;/li&gt; 
   &lt;li&gt;☑ file manager (cut/paste, delete, &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#batch-rename"&gt;batch-rename&lt;/a&gt;)&lt;/li&gt; 
   &lt;li&gt;☑ audio player (with &lt;a href="https://user-images.githubusercontent.com/241032/215347492-b4250797-6c90-4e09-9a4c-721edf2fb15c.png"&gt;OS media controls&lt;/a&gt; and opus/mp3 transcoding) 
    &lt;ul&gt; 
     &lt;li&gt;☑ play video files as audio (converted on server)&lt;/li&gt; 
     &lt;li&gt;☑ create and play &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#playlists"&gt;m3u8 playlists&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;☑ image gallery with webm player&lt;/li&gt; 
   &lt;li&gt;☑ &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#textfile-viewer"&gt;textfile browser&lt;/a&gt; with syntax hilighting 
    &lt;ul&gt; 
     &lt;li&gt;☑ realtime streaming of growing files (logfiles and such)&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;☑ &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#thumbnails"&gt;thumbnails&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;☑ ...of images using Pillow, pyvips, or FFmpeg&lt;/li&gt; 
     &lt;li&gt;☑ ...of videos using FFmpeg&lt;/li&gt; 
     &lt;li&gt;☑ ...of audio (spectrograms) using FFmpeg&lt;/li&gt; 
     &lt;li&gt;☑ cache eviction (max-age; maybe max-size eventually)&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;☑ multilingual UI (english, norwegian, chinese, &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/docs/rice/#translations"&gt;add your own&lt;/a&gt;))&lt;/li&gt; 
   &lt;li&gt;☑ SPA (browse while uploading)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;server indexing 
  &lt;ul&gt; 
   &lt;li&gt;☑ &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#file-search"&gt;locate files by contents&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;☑ search by name/path/date/size&lt;/li&gt; 
   &lt;li&gt;☑ &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#searching"&gt;search by ID3-tags etc.&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;client support 
  &lt;ul&gt; 
   &lt;li&gt;☑ &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#folder-sync"&gt;folder sync&lt;/a&gt; (one-way only; full sync will never be supported)&lt;/li&gt; 
   &lt;li&gt;☑ &lt;a href="https://user-images.githubusercontent.com/241032/215322619-ea5fd606-3654-40ad-94ee-2bc058647bb2.png"&gt;curl-friendly&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;☑ &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#opengraph"&gt;opengraph&lt;/a&gt; (discord embeds)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;markdown 
  &lt;ul&gt; 
   &lt;li&gt;☑ &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#markdown-viewer"&gt;viewer&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;☑ editor (sure why not)&lt;/li&gt; 
   &lt;li&gt;☑ &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#markdown-vars"&gt;variables&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;PS: something missing? post any crazy ideas you've got as a &lt;a href="https://github.com/9001/copyparty/issues/new?assignees=9001&amp;amp;labels=enhancement&amp;amp;template=feature_request.md"&gt;feature request&lt;/a&gt; or &lt;a href="https://github.com/9001/copyparty/discussions/new?category=ideas"&gt;discussion&lt;/a&gt; 🤙&lt;/p&gt; 
&lt;h2&gt;testimonials&lt;/h2&gt; 
&lt;p&gt;small collection of user feedback&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;good enough&lt;/code&gt;, &lt;code&gt;surprisingly correct&lt;/code&gt;, &lt;code&gt;certified good software&lt;/code&gt;, &lt;code&gt;just works&lt;/code&gt;, &lt;code&gt;why&lt;/code&gt;, &lt;code&gt;wow this is better than nextcloud&lt;/code&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;UI просто ужасно. Если буду описывать детально не смогу удержаться в рамках приличий&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;motivations&lt;/h1&gt; 
&lt;p&gt;project goals / philosophy&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;inverse linux philosophy -- do all the things, and do an &lt;em&gt;okay&lt;/em&gt; job 
  &lt;ul&gt; 
   &lt;li&gt;quick drop-in service to get a lot of features in a pinch&lt;/li&gt; 
   &lt;li&gt;some of &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/docs/versus.md"&gt;the alternatives&lt;/a&gt; might be a better fit for you&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;run anywhere, support everything 
  &lt;ul&gt; 
   &lt;li&gt;as many web-browsers and python versions as possible 
    &lt;ul&gt; 
     &lt;li&gt;every browser should at least be able to browse, download, upload files&lt;/li&gt; 
     &lt;li&gt;be a good emergency solution for transferring stuff between ancient boxes&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;minimal dependencies 
    &lt;ul&gt; 
     &lt;li&gt;but optional dependencies adding bonus-features are ok&lt;/li&gt; 
     &lt;li&gt;everything being plaintext makes it possible to proofread for malicious code&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;no preparations / setup necessary, just run the sfx (which is also plaintext)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;adaptable, malleable, hackable 
  &lt;ul&gt; 
   &lt;li&gt;no build steps; modify the js/python without needing node.js or anything like that&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;becoming rich is specifically &lt;em&gt;not&lt;/em&gt; a motivation, but if you wanna donate then see my &lt;a href="https://github.com/9001"&gt;github profile&lt;/a&gt; regarding donations for my FOSS stuff in general (also THANKS!)&lt;/p&gt; 
&lt;h2&gt;notes&lt;/h2&gt; 
&lt;p&gt;general notes:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;paper-printing is affected by dark/light-mode! use lightmode for color, darkmode for grayscale 
  &lt;ul&gt; 
   &lt;li&gt;because no browsers currently implement the media-query to do this properly orz&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;browser-specific:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;iPhone/iPad: use Firefox to download files&lt;/li&gt; 
 &lt;li&gt;Android-Chrome: increase "parallel uploads" for higher speed (android bug)&lt;/li&gt; 
 &lt;li&gt;Android-Firefox: takes a while to select files (their fix for ☝️)&lt;/li&gt; 
 &lt;li&gt;Desktop-Firefox: &lt;del&gt;may use gigabytes of RAM if your files are massive&lt;/del&gt; &lt;em&gt;seems to be OK now&lt;/em&gt;&lt;/li&gt; 
 &lt;li&gt;Desktop-Firefox: &lt;a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1792598"&gt;may stop you from unplugging USB flashdrives&lt;/a&gt; until you visit &lt;code&gt;about:memory&lt;/code&gt; and click &lt;code&gt;Minimize memory usage&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;server-os-specific:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;RHEL8 / Rocky8: you can run copyparty using &lt;code&gt;/usr/libexec/platform-python&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;server notes:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;pypy is supported but regular cpython is faster if you enable the database&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;bugs&lt;/h1&gt; 
&lt;p&gt;roughly sorted by chance of encounter&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;general:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;--th-ff-jpg&lt;/code&gt; may fix video thumbnails on some FFmpeg versions (macos, some linux)&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;--th-ff-swr&lt;/code&gt; may fix audio thumbnails on some FFmpeg versions&lt;/li&gt; 
   &lt;li&gt;if the &lt;code&gt;up2k.db&lt;/code&gt; (filesystem index) is on a samba-share or network disk, you'll get unpredictable behavior if the share is disconnected for a bit 
    &lt;ul&gt; 
     &lt;li&gt;use &lt;code&gt;--hist&lt;/code&gt; or the &lt;code&gt;hist&lt;/code&gt; volflag (&lt;code&gt;-v [...]:c,hist=/tmp/foo&lt;/code&gt;) to place the db and thumbnails on a local disk instead&lt;/li&gt; 
     &lt;li&gt;or, if you only want to move the db (and not the thumbnails), then use &lt;code&gt;--dbpath&lt;/code&gt; or the &lt;code&gt;dbpath&lt;/code&gt; volflag&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;all volumes must exist / be available on startup; up2k (mtp especially) gets funky otherwise&lt;/li&gt; 
   &lt;li&gt;probably more, pls let me know&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;python 3.4 and older (including 2.7):&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;many rare and exciting edge-cases because &lt;a href="https://peps.python.org/pep-0475/"&gt;python didn't handle EINTR yet&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;downloads from copyparty may suddenly fail, but uploads &lt;em&gt;should&lt;/em&gt; be fine&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;python 2.7 on Windows:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;cannot index non-ascii filenames with &lt;code&gt;-e2d&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;cannot handle filenames with mojibake&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;if you have a new exciting bug to share, see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#reporting-bugs"&gt;reporting bugs&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;not my bugs&lt;/h2&gt; 
&lt;p&gt;same order here too&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://bugs.chromium.org/p/chromium/issues/detail?id=1317069"&gt;Chrome issue 1317069&lt;/a&gt; -- if you try to upload a folder which contains symlinks by dragging it into the browser, the symlinked files will not get uploaded&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://bugs.chromium.org/p/chromium/issues/detail?id=1352210"&gt;Chrome issue 1352210&lt;/a&gt; -- plaintext http may be faster at filehashing than https (but also extremely CPU-intensive)&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://issues.chromium.org/issues/383568268"&gt;Chrome issue 383568268&lt;/a&gt; -- filereaders in webworkers can OOM / crash the browser-tab&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;copyparty has a workaround which seems to work well enough&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1790500"&gt;Firefox issue 1790500&lt;/a&gt; -- entire browser can crash after uploading ~4000 small files&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Android: music playback randomly stops due to &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#fix-unreliable-playback-on-android"&gt;battery usage settings&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;iPhones: the volume control doesn't work because &lt;a href="https://developer.apple.com/library/archive/documentation/AudioVideo/Conceptual/Using_HTML5_Audio_Video/Device-SpecificConsiderations/Device-SpecificConsiderations.html#//apple_ref/doc/uid/TP40009523-CH5-SW11"&gt;apple doesn't want it to&lt;/a&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;AudioContext&lt;/code&gt; will probably never be a viable workaround as apple introduces new issues faster than they fix current ones&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;iPhones: music volume goes on a rollercoaster during song changes&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;nothing I can do about it because &lt;code&gt;AudioContext&lt;/code&gt; is still broken in safari&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;iPhones: the preload feature (in the media-player-options tab) can cause a tiny audio glitch 20sec before the end of each song, but disabling it may cause worse iOS bugs to appear instead&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;just a hunch, but disabling preloading may cause playback to stop entirely, or possibly mess with bluetooth speakers&lt;/li&gt; 
   &lt;li&gt;tried to add a tooltip regarding this but looks like apple broke my tooltips&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;iPhones: preloaded awo files make safari log MEDIA_ERR_NETWORK errors as playback starts, but the song plays just fine so eh whatever&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;awo, opus-weba, is apple's new take on opus support, replacing opus-caf which was technically limited to cbr opus&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;iPhones: preloading another awo file may cause playback to stop&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;can be somewhat mitigated with &lt;code&gt;mp.au.play()&lt;/code&gt; in &lt;code&gt;mp.onpreload&lt;/code&gt; but that can hit a race condition in safari that starts playing the same audio object twice in parallel...&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Windows: folders cannot be accessed if the name ends with &lt;code&gt;.&lt;/code&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;python or windows bug&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Windows: msys2-python 3.8.6 occasionally throws &lt;code&gt;RuntimeError: release unlocked lock&lt;/code&gt; when leaving a scoped mutex in up2k&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;this is an msys2 bug, the regular windows edition of python is fine&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;VirtualBox: sqlite throws &lt;code&gt;Disk I/O Error&lt;/code&gt; when running in a VM and the up2k database is in a vboxsf&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;use &lt;code&gt;--hist&lt;/code&gt; or the &lt;code&gt;hist&lt;/code&gt; volflag (&lt;code&gt;-v [...]:c,hist=/tmp/foo&lt;/code&gt;) to place the db and thumbnails inside the vm instead 
    &lt;ul&gt; 
     &lt;li&gt;or, if you only want to move the db (and not the thumbnails), then use &lt;code&gt;--dbpath&lt;/code&gt; or the &lt;code&gt;dbpath&lt;/code&gt; volflag&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;also happens on mergerfs, so put the db elsewhere&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Ubuntu: dragging files from certain folders into firefox or chrome is impossible&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;due to snap security policies -- see &lt;code&gt;snap connections firefox&lt;/code&gt; for the allowlist, &lt;code&gt;removable-media&lt;/code&gt; permits all of &lt;code&gt;/mnt&lt;/code&gt; and &lt;code&gt;/media&lt;/code&gt; apparently&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;breaking changes&lt;/h1&gt; 
&lt;p&gt;upgrade notes&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;1.9.16&lt;/code&gt; (2023-11-04): 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;--stats&lt;/code&gt;/prometheus: &lt;code&gt;cpp_bans&lt;/code&gt; renamed to &lt;code&gt;cpp_active_bans&lt;/code&gt;, and that + &lt;code&gt;cpp_uptime&lt;/code&gt; are gauges&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;1.6.0&lt;/code&gt; (2023-01-29): 
  &lt;ul&gt; 
   &lt;li&gt;http-api: delete/move is now &lt;code&gt;POST&lt;/code&gt; instead of &lt;code&gt;GET&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;everything other than &lt;code&gt;GET&lt;/code&gt; and &lt;code&gt;HEAD&lt;/code&gt; must pass &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#cors"&gt;cors validation&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;1.5.0&lt;/code&gt; (2022-12-03): &lt;a href="https://github.com/9001/copyparty/commit/54e1c8d261df"&gt;new chunksize formula&lt;/a&gt; for files larger than 128 GiB 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;users:&lt;/strong&gt; upgrade to the latest &lt;a href="https://github.com/9001/copyparty/raw/hovudstraum/bin/u2c.py"&gt;cli uploader&lt;/a&gt; if you use that&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;devs:&lt;/strong&gt; update third-party up2k clients (if those even exist)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;FAQ&lt;/h1&gt; 
&lt;p&gt;"frequently" asked questions&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;CopyParty?&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;nope! the name is either copyparty (all-lowercase) or Copyparty -- it's &lt;a href="https://en.wiktionary.org/wiki/copyparty"&gt;one word&lt;/a&gt; after all :&amp;gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;can I change the 🌲 spinning pine-tree loading animation?&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/9001/copyparty/tree/hovudstraum/docs/rice#boring-loader-spinner"&gt;yeah...&lt;/a&gt; :-(&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;is it possible to block read-access to folders unless you know the exact URL for a particular file inside?&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;yes, using the &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#accounts-and-volumes"&gt;&lt;code&gt;g&lt;/code&gt; permission&lt;/a&gt;, see the examples there&lt;/li&gt; 
   &lt;li&gt;you can also do this with linux filesystem permissions; &lt;code&gt;chmod 111 music&lt;/code&gt; will make it possible to access files and folders inside the &lt;code&gt;music&lt;/code&gt; folder but not list the immediate contents -- also works with other software, not just copyparty&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;can I link someone to a password-protected volume/file by including the password in the URL?&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;yes, by adding &lt;code&gt;?pw=hunter2&lt;/code&gt; to the end; replace &lt;code&gt;?&lt;/code&gt; with &lt;code&gt;&amp;amp;&lt;/code&gt; if there are parameters in the URL already, meaning it contains a &lt;code&gt;?&lt;/code&gt; near the end&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;how do I stop &lt;code&gt;.hist&lt;/code&gt; folders from appearing everywhere on my HDD?&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;by default, a &lt;code&gt;.hist&lt;/code&gt; folder is created inside each volume for the filesystem index, thumbnails, audio transcodes, and markdown document history. Use the &lt;code&gt;--hist&lt;/code&gt; global-option or the &lt;code&gt;hist&lt;/code&gt; volflag to move it somewhere else; see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#database-location"&gt;database location&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;can I make copyparty download a file to my server if I give it a URL?&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;yes, using &lt;a href="https://github.com/9001/copyparty/raw/hovudstraum/bin/hooks/wget.py"&gt;hooks&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;firefox refuses to connect over https, saying "Secure Connection Failed" or "SEC_ERROR_BAD_SIGNATURE", but the usual button to "Accept the Risk and Continue" is not shown&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;firefox has corrupted its certstore; fix this by exiting firefox, then find and delete the file named &lt;code&gt;cert9.db&lt;/code&gt; somewhere in your firefox profile folder&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;the server keeps saying &lt;code&gt;thank you for playing&lt;/code&gt; when I try to access the website&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;you've gotten banned for malicious traffic! if this happens by mistake, and you're running a reverse-proxy and/or something like cloudflare, see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#real-ip"&gt;real-ip&lt;/a&gt; on how to fix this&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;copyparty seems to think I am using http, even though the URL is https&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;your reverse-proxy is not sending the &lt;code&gt;X-Forwarded-Proto: https&lt;/code&gt; header; this could be because your reverse-proxy itself is confused. Ensure that none of the intermediates (such as cloudflare) are terminating https before the traffic hits your entrypoint&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;thumbnails are broken (you get a colorful square which says the filetype instead)&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;you need to install &lt;code&gt;FFmpeg&lt;/code&gt; or &lt;code&gt;Pillow&lt;/code&gt;; see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#thumbnails"&gt;thumbnails&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;thumbnails are broken (some images appear, but other files just get a blank box, and/or the broken-image placeholder)&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;probably due to a reverse-proxy messing with the request URLs and stripping the query parameters (&lt;code&gt;?th=w&lt;/code&gt;), so check your URL rewrite rules&lt;/li&gt; 
   &lt;li&gt;could also be due to incorrect caching settings in reverse-proxies and/or CDNs, so make sure that nothing is set to ignore the query string&lt;/li&gt; 
   &lt;li&gt;could also be due to misbehaving privacy-related browser extensions, so try to disable those&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;i want to learn python and/or programming and am considering looking at the copyparty source code in that occasion&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;pre&gt;&lt;code class="language-bash"&gt; _|  _      __   _  _|_
(_| (_)     | | (_)  |_
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;accounts and volumes&lt;/h1&gt; 
&lt;p&gt;per-folder, per-user permissions - if your setup is getting complex, consider making a &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/docs/example.conf"&gt;config file&lt;/a&gt; instead of using arguments&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;much easier to manage, and you can modify the config at runtime with &lt;code&gt;systemctl reload copyparty&lt;/code&gt; or more conveniently using the &lt;code&gt;[reload cfg]&lt;/code&gt; button in the control-panel (if the user has &lt;code&gt;a&lt;/code&gt;/admin in any volume) 
  &lt;ul&gt; 
   &lt;li&gt;changes to the &lt;code&gt;[global]&lt;/code&gt; config section requires a restart to take effect&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;a quick summary can be seen using &lt;code&gt;--help-accounts&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;configuring accounts/volumes with arguments:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;-a usr:pwd&lt;/code&gt; adds account &lt;code&gt;usr&lt;/code&gt; with password &lt;code&gt;pwd&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-v .::r&lt;/code&gt; adds current-folder &lt;code&gt;.&lt;/code&gt; as the webroot, &lt;code&gt;r&lt;/code&gt;eadable by anyone 
  &lt;ul&gt; 
   &lt;li&gt;the syntax is &lt;code&gt;-v src:dst:perm:perm:...&lt;/code&gt; so local-path, url-path, and one or more permissions to set&lt;/li&gt; 
   &lt;li&gt;granting the same permissions to multiple accounts:&lt;br&gt; &lt;code&gt;-v .::r,usr1,usr2:rw,usr3,usr4&lt;/code&gt; = usr1/2 read-only, 3/4 read-write&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;permissions:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;r&lt;/code&gt; (read): browse folder contents, download files, download as zip/tar, see filekeys/dirkeys&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;w&lt;/code&gt; (write): upload files, move/copy files &lt;em&gt;into&lt;/em&gt; this folder&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;m&lt;/code&gt; (move): move files/folders &lt;em&gt;from&lt;/em&gt; this folder&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;d&lt;/code&gt; (delete): delete files/folders&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;.&lt;/code&gt; (dots): user can ask to show dotfiles in directory listings&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;g&lt;/code&gt; (get): only download files, cannot see folder contents or zip/tar&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;G&lt;/code&gt; (upget): same as &lt;code&gt;g&lt;/code&gt; except uploaders get to see their own &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#filekeys"&gt;filekeys&lt;/a&gt; (see &lt;code&gt;fk&lt;/code&gt; in examples below)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;h&lt;/code&gt; (html): same as &lt;code&gt;g&lt;/code&gt; except folders return their index.html, and filekeys are not necessary for index.html&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;a&lt;/code&gt; (admin): can see upload time, uploader IPs, config-reload&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;A&lt;/code&gt; ("all"): same as &lt;code&gt;rwmda.&lt;/code&gt; (read/write/move/delete/admin/dotfiles)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;examples:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;add accounts named u1, u2, u3 with passwords p1, p2, p3: &lt;code&gt;-a u1:p1 -a u2:p2 -a u3:p3&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;make folder &lt;code&gt;/srv&lt;/code&gt; the root of the filesystem, read-only by anyone: &lt;code&gt;-v /srv::r&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;make folder &lt;code&gt;/mnt/music&lt;/code&gt; available at &lt;code&gt;/music&lt;/code&gt;, read-only for u1 and u2, read-write for u3: &lt;code&gt;-v /mnt/music:music:r,u1,u2:rw,u3&lt;/code&gt; 
  &lt;ul&gt; 
   &lt;li&gt;unauthorized users accessing the webroot can see that the &lt;code&gt;music&lt;/code&gt; folder exists, but cannot open it&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;make folder &lt;code&gt;/mnt/incoming&lt;/code&gt; available at &lt;code&gt;/inc&lt;/code&gt;, write-only for u1, read-move for u2: &lt;code&gt;-v /mnt/incoming:inc:w,u1:rm,u2&lt;/code&gt; 
  &lt;ul&gt; 
   &lt;li&gt;unauthorized users accessing the webroot can see that the &lt;code&gt;inc&lt;/code&gt; folder exists, but cannot open it&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;u1&lt;/code&gt; can open the &lt;code&gt;inc&lt;/code&gt; folder, but cannot see the contents, only upload new files to it&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;u2&lt;/code&gt; can browse it and move files &lt;em&gt;from&lt;/em&gt; &lt;code&gt;/inc&lt;/code&gt; into any folder where &lt;code&gt;u2&lt;/code&gt; has write-access&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;make folder &lt;code&gt;/mnt/ss&lt;/code&gt; available at &lt;code&gt;/i&lt;/code&gt;, read-write for u1, get-only for everyone else, and enable filekeys: &lt;code&gt;-v /mnt/ss:i:rw,u1:g:c,fk=4&lt;/code&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;c,fk=4&lt;/code&gt; sets the &lt;code&gt;fk&lt;/code&gt; (&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#filekeys"&gt;filekey&lt;/a&gt;) volflag to 4, meaning each file gets a 4-character accesskey&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;u1&lt;/code&gt; can upload files, browse the folder, and see the generated filekeys&lt;/li&gt; 
   &lt;li&gt;other users cannot browse the folder, but can access the files if they have the full file URL with the filekey&lt;/li&gt; 
   &lt;li&gt;replacing the &lt;code&gt;g&lt;/code&gt; permission with &lt;code&gt;wg&lt;/code&gt; would let anonymous users upload files, but not see the required filekey to access it&lt;/li&gt; 
   &lt;li&gt;replacing the &lt;code&gt;g&lt;/code&gt; permission with &lt;code&gt;wG&lt;/code&gt; would let anonymous users upload files, receiving a working direct link in return&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;anyone trying to bruteforce a password gets banned according to &lt;code&gt;--ban-pw&lt;/code&gt;; default is 24h ban for 9 failed attempts in 1 hour&lt;/p&gt; 
&lt;p&gt;and if you want to use config files instead of commandline args (good!) then here's the same examples as a configfile; save it as &lt;code&gt;foobar.conf&lt;/code&gt; and use it like this: &lt;code&gt;python copyparty-sfx.py -c foobar.conf&lt;/code&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;[accounts]
  u1: p1  # create account "u1" with password "p1"
  u2: p2  #  (note that comments must have
  u3: p3  #   two spaces before the # sign)

[/]     # this URL will be mapped to...
  /srv  # ...this folder on the server filesystem
  accs:
    r: *  # read-only for everyone, no account necessary

[/music]       # create another volume at this URL,
  /mnt/music   # which is mapped to this folder
  accs:
    r: u1, u2  # only these accounts can read,
    rw: u3     # and only u3 can read-write

[/inc]
  /mnt/incoming
  accs:
    w: u1   # u1 can upload but not see/download any files,
    rm: u2  # u2 can browse + move files out of this volume

[/i]
  /mnt/ss
  accs:
    rw: u1  # u1 can read-write,
    g: *    # everyone can access files if they know the URL
  flags:
    fk: 4   # each file URL will have a 4-character password
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;shadowing&lt;/h2&gt; 
&lt;p&gt;hiding specific subfolders by mounting another volume on top of them&lt;/p&gt; 
&lt;p&gt;for example &lt;code&gt;-v /mnt::r -v /var/empty:web/certs:r&lt;/code&gt; mounts the server folder &lt;code&gt;/mnt&lt;/code&gt; as the webroot, but another volume is mounted at &lt;code&gt;/web/certs&lt;/code&gt; -- so visitors can only see the contents of &lt;code&gt;/mnt&lt;/code&gt; and &lt;code&gt;/mnt/web&lt;/code&gt; (at URLs &lt;code&gt;/&lt;/code&gt; and &lt;code&gt;/web&lt;/code&gt;), but not &lt;code&gt;/mnt/web/certs&lt;/code&gt; because URL &lt;code&gt;/web/certs&lt;/code&gt; is mapped to &lt;code&gt;/var/empty&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;the example config file right above this section may explain this better; the first volume &lt;code&gt;/&lt;/code&gt; is mapped to &lt;code&gt;/srv&lt;/code&gt; which means &lt;a href="http://127.0.0.1:3923/music"&gt;http://127.0.0.1:3923/music&lt;/a&gt; would try to read &lt;code&gt;/srv/music&lt;/code&gt; on the server filesystem, but since there's another volume at &lt;code&gt;/music&lt;/code&gt; mapped to &lt;code&gt;/mnt/music&lt;/code&gt; then it'll go to &lt;code&gt;/mnt/music&lt;/code&gt; instead&lt;/p&gt; 
&lt;h2&gt;dotfiles&lt;/h2&gt; 
&lt;p&gt;unix-style hidden files/folders by starting the name with a dot&lt;/p&gt; 
&lt;p&gt;anyone can access these if they know the name, but they normally don't appear in directory listings&lt;/p&gt; 
&lt;p&gt;a client can request to see dotfiles in directory listings if global option &lt;code&gt;-ed&lt;/code&gt; is specified, or the volume has volflag &lt;code&gt;dots&lt;/code&gt;, or the user has permission &lt;code&gt;.&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;dotfiles do not appear in search results unless one of the above is true, &lt;strong&gt;and&lt;/strong&gt; the global option / volflag &lt;code&gt;dotsrch&lt;/code&gt; is set&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;even if user has permission to see dotfiles, they are default-hidden unless &lt;code&gt;--see-dots&lt;/code&gt; is set, and/or user has enabled the &lt;code&gt;dotfiles&lt;/code&gt; option in the settings tab&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;config file example, where the same permission to see dotfiles is given in two different ways just for reference:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;[/foo]
  /srv/foo
  accs:
    r.: ed   # user "ed" has read-access + dot-access in this volume;
             # dotfiles are visible in listings, but not in searches
  flags:
    dotsrch  # dotfiles will now appear in search results too
    dots     # another way to let everyone see dotfiles in this vol
&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;the browser&lt;/h1&gt; 
&lt;p&gt;accessing a copyparty server using a web-browser&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://user-images.githubusercontent.com/241032/192042695-522b3ec7-6845-494a-abdb-d1c0d0e23801.png" alt="copyparty-browser-fs8"&gt;&lt;/p&gt; 
&lt;h2&gt;tabs&lt;/h2&gt; 
&lt;p&gt;the main tabs in the ui&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;[🔎]&lt;/code&gt; &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#searching"&gt;search&lt;/a&gt; by size, date, path/name, mp3-tags ...&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[🧯]&lt;/code&gt; &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#unpost"&gt;unpost&lt;/a&gt;: undo/delete accidental uploads&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[🚀]&lt;/code&gt; and &lt;code&gt;[🎈]&lt;/code&gt; are the &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#uploading"&gt;uploaders&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[📂]&lt;/code&gt; mkdir: create directories&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[📝]&lt;/code&gt; new-md: create a new markdown document&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[📟]&lt;/code&gt; send-msg: either to server-log or into textfiles if &lt;code&gt;--urlform save&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[🎺]&lt;/code&gt; audio-player config options&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[⚙️]&lt;/code&gt; general client config options&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;hotkeys&lt;/h2&gt; 
&lt;p&gt;the browser has the following hotkeys (always qwerty)&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;?&lt;/code&gt; show hotkeys help&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;B&lt;/code&gt; toggle breadcrumbs / &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#navpane"&gt;navpane&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;I/K&lt;/code&gt; prev/next folder&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;M&lt;/code&gt; parent folder (or unexpand current)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;V&lt;/code&gt; toggle folders / textfiles in the navpane&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;G&lt;/code&gt; toggle list / &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#thumbnails"&gt;grid view&lt;/a&gt; -- same as &lt;code&gt;田&lt;/code&gt; bottom-right&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;T&lt;/code&gt; toggle thumbnails / icons&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;ESC&lt;/code&gt; close various things&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;ctrl-K&lt;/code&gt; delete selected files/folders&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;ctrl-X&lt;/code&gt; cut selected files/folders&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;ctrl-C&lt;/code&gt; copy selected files/folders to clipboard&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;ctrl-V&lt;/code&gt; paste (move/copy)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;Y&lt;/code&gt; download selected files&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;F2&lt;/code&gt; &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#batch-rename"&gt;rename&lt;/a&gt; selected file/folder&lt;/li&gt; 
 &lt;li&gt;when a file/folder is selected (in not-grid-view): 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;Up/Down&lt;/code&gt; move cursor&lt;/li&gt; 
   &lt;li&gt;shift+&lt;code&gt;Up/Down&lt;/code&gt; select and move cursor&lt;/li&gt; 
   &lt;li&gt;ctrl+&lt;code&gt;Up/Down&lt;/code&gt; move cursor and scroll viewport&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;Space&lt;/code&gt; toggle file selection&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;Ctrl-A&lt;/code&gt; toggle select all&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;when a textfile is open: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;I/K&lt;/code&gt; prev/next textfile&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;S&lt;/code&gt; toggle selection of open file&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;M&lt;/code&gt; close textfile&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;when playing audio: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;J/L&lt;/code&gt; prev/next song&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;U/O&lt;/code&gt; skip 10sec back/forward&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;0..9&lt;/code&gt; jump to 0%..90%&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;P&lt;/code&gt; play/pause (also starts playing the folder)&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;Y&lt;/code&gt; download file&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;when viewing images / playing videos: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;J/L, Left/Right&lt;/code&gt; prev/next file&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;Home/End&lt;/code&gt; first/last file&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;F&lt;/code&gt; toggle fullscreen&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;S&lt;/code&gt; toggle selection&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;R&lt;/code&gt; rotate clockwise (shift=ccw)&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;Y&lt;/code&gt; download file&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;Esc&lt;/code&gt; close viewer&lt;/li&gt; 
   &lt;li&gt;videos: 
    &lt;ul&gt; 
     &lt;li&gt;&lt;code&gt;U/O&lt;/code&gt; skip 10sec back/forward&lt;/li&gt; 
     &lt;li&gt;&lt;code&gt;0..9&lt;/code&gt; jump to 0%..90%&lt;/li&gt; 
     &lt;li&gt;&lt;code&gt;P/K/Space&lt;/code&gt; play/pause&lt;/li&gt; 
     &lt;li&gt;&lt;code&gt;M&lt;/code&gt; mute&lt;/li&gt; 
     &lt;li&gt;&lt;code&gt;C&lt;/code&gt; continue playing next video&lt;/li&gt; 
     &lt;li&gt;&lt;code&gt;V&lt;/code&gt; loop entire file&lt;/li&gt; 
     &lt;li&gt;&lt;code&gt;[&lt;/code&gt; loop range (start)&lt;/li&gt; 
     &lt;li&gt;&lt;code&gt;]&lt;/code&gt; loop range (end)&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;when the navpane is open: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;A/D&lt;/code&gt; adjust tree width&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;in the &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#thumbnails"&gt;grid view&lt;/a&gt;: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;S&lt;/code&gt; toggle multiselect&lt;/li&gt; 
   &lt;li&gt;shift+&lt;code&gt;A/D&lt;/code&gt; zoom&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;in the markdown editor: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;^s&lt;/code&gt; save&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;^h&lt;/code&gt; header&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;^k&lt;/code&gt; autoformat table&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;^u&lt;/code&gt; jump to next unicode character&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;^e&lt;/code&gt; toggle editor / preview&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;^up, ^down&lt;/code&gt; jump paragraphs&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;navpane&lt;/h2&gt; 
&lt;p&gt;switching between breadcrumbs or navpane&lt;/p&gt; 
&lt;p&gt;click the &lt;code&gt;🌲&lt;/code&gt; or pressing the &lt;code&gt;B&lt;/code&gt; hotkey to toggle between breadcrumbs path (default), or a navpane (tree-browser sidebar thing)&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;[+]&lt;/code&gt; and &lt;code&gt;[-]&lt;/code&gt; (or hotkeys &lt;code&gt;A&lt;/code&gt;/&lt;code&gt;D&lt;/code&gt;) adjust the size&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[🎯]&lt;/code&gt; jumps to the currently open folder&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[📃]&lt;/code&gt; toggles between showing folders and textfiles&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[📌]&lt;/code&gt; shows the name of all parent folders in a docked panel&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[a]&lt;/code&gt; toggles automatic widening as you go deeper&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[↵]&lt;/code&gt; toggles wordwrap&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[👀]&lt;/code&gt; show full name on hover (if wordwrap is off)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;thumbnails&lt;/h2&gt; 
&lt;p&gt;press &lt;code&gt;g&lt;/code&gt; or &lt;code&gt;田&lt;/code&gt; to toggle grid-view instead of the file listing and &lt;code&gt;t&lt;/code&gt; toggles icons / thumbnails&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;can be made default globally with &lt;code&gt;--grid&lt;/code&gt; or per-volume with volflag &lt;code&gt;grid&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;enable by adding &lt;code&gt;?imgs&lt;/code&gt; to a link, or disable with &lt;code&gt;?imgs=0&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://user-images.githubusercontent.com/241032/129636211-abd20fa2-a953-4366-9423-1c88ebb96ba9.png" alt="copyparty-thumbs-fs8"&gt;&lt;/p&gt; 
&lt;p&gt;it does static images with Pillow / pyvips / FFmpeg, and uses FFmpeg for video files, so you may want to &lt;code&gt;--no-thumb&lt;/code&gt; or maybe just &lt;code&gt;--no-vthumb&lt;/code&gt; depending on how dangerous your users are&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;pyvips is 3x faster than Pillow, Pillow is 3x faster than FFmpeg&lt;/li&gt; 
 &lt;li&gt;disable thumbnails for specific volumes with volflag &lt;code&gt;dthumb&lt;/code&gt; for all, or &lt;code&gt;dvthumb&lt;/code&gt; / &lt;code&gt;dathumb&lt;/code&gt; / &lt;code&gt;dithumb&lt;/code&gt; for video/audio/images only&lt;/li&gt; 
 &lt;li&gt;for installing FFmpeg on windows, see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#optional-dependencies"&gt;optional dependencies&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;audio files are converted into spectrograms using FFmpeg unless you &lt;code&gt;--no-athumb&lt;/code&gt; (and some FFmpeg builds may need &lt;code&gt;--th-ff-swr&lt;/code&gt;)&lt;/p&gt; 
&lt;p&gt;images with the following names (see &lt;code&gt;--th-covers&lt;/code&gt;) become the thumbnail of the folder they're in: &lt;code&gt;folder.png&lt;/code&gt;, &lt;code&gt;folder.jpg&lt;/code&gt;, &lt;code&gt;cover.png&lt;/code&gt;, &lt;code&gt;cover.jpg&lt;/code&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;the order is significant, so if both &lt;code&gt;cover.png&lt;/code&gt; and &lt;code&gt;folder.jpg&lt;/code&gt; exist in a folder, it will pick the first matching &lt;code&gt;--th-covers&lt;/code&gt; entry (&lt;code&gt;folder.jpg&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;and, if you enable &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#file-indexing"&gt;file indexing&lt;/a&gt;, it will also try those names as dotfiles (&lt;code&gt;.folder.jpg&lt;/code&gt; and so), and then fallback on the first picture in the folder (if it has any pictures at all)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;enabling &lt;code&gt;multiselect&lt;/code&gt; lets you click files to select them, and then shift-click another file for range-select&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;multiselect&lt;/code&gt; is mostly intended for phones/tablets, but the &lt;code&gt;sel&lt;/code&gt; option in the &lt;code&gt;[⚙️] settings&lt;/code&gt; tab is better suited for desktop use, allowing selection by CTRL-clicking and range-selection with SHIFT-click, all without affecting regular clicking 
  &lt;ul&gt; 
   &lt;li&gt;the &lt;code&gt;sel&lt;/code&gt; option can be made default globally with &lt;code&gt;--gsel&lt;/code&gt; or per-volume with volflag &lt;code&gt;gsel&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;to show &lt;code&gt;/icons/exe.png&lt;/code&gt; and &lt;code&gt;/icons/elf.gif&lt;/code&gt; as the thumbnail for all &lt;code&gt;.exe&lt;/code&gt; and &lt;code&gt;.elf&lt;/code&gt; files respectively, do this: &lt;code&gt;--ext-th=exe=/icons/exe.png --ext-th=elf=/icons/elf.gif&lt;/code&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;optionally as separate volflags for each mapping; see config file example below&lt;/li&gt; 
 &lt;li&gt;the supported image formats are &lt;a href="https://developer.mozilla.org/en-US/docs/Web/Media/Guides/Formats/Image_types"&gt;jpg, png, gif, webp, ico&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;be careful with svg; chrome will crash if you have too many unique svg files showing on the same page (the limit is 250 or so) -- showing the same handful of svg files thousands of times is ok however&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;config file example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;[global]
  no-thumb   # disable ALL thumbnails and audio transcoding
  no-vthumb  # only disable video thumbnails

[/music]
  /mnt/nas/music
  accs:
    r: *     # everyone can read
  flags:
    dthumb   # disable ALL thumbnails and audio transcoding
    dvthumb  # only disable video thumbnails
    ext-th:  exe=/ico/exe.png  # /ico/exe.png is the thumbnail of *.exe
    ext-th:  elf=/ico/elf.gif  # ...and /ico/elf.gif is used for *.elf
    th-covers:  folder.png,folder.jpg,cover.png,cover.jpg  # the default
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;zip downloads&lt;/h2&gt; 
&lt;p&gt;download folders (or file selections) as &lt;code&gt;zip&lt;/code&gt; or &lt;code&gt;tar&lt;/code&gt; files&lt;/p&gt; 
&lt;p&gt;select which type of archive you want in the &lt;code&gt;[⚙️] config&lt;/code&gt; tab:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;name&lt;/th&gt; 
   &lt;th&gt;url-suffix&lt;/th&gt; 
   &lt;th&gt;description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;tar&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;?tar&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;plain gnutar, works great with &lt;code&gt;curl | tar -xv&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;pax&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;?tar=pax&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;pax-format tar, futureproof, not as fast&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;tgz&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;?tar=gz&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;gzip compressed gnu-tar (slow), for &lt;code&gt;curl | tar -xvz&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;txz&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;?tar=xz&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;gnu-tar with xz / lzma compression (v.slow)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;zip&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;?zip&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;works everywhere, glitchy filenames on win7 and older&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;zip_dos&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;?zip=dos&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;traditional cp437 (no unicode) to fix glitchy filenames&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;zip_crc&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;?zip=crc&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;cp437 with crc32 computed early for truly ancient software&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;ul&gt; 
 &lt;li&gt;gzip default level is &lt;code&gt;3&lt;/code&gt; (0=fast, 9=best), change with &lt;code&gt;?tar=gz:9&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;xz default level is &lt;code&gt;1&lt;/code&gt; (0=fast, 9=best), change with &lt;code&gt;?tar=xz:9&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;bz2 default level is &lt;code&gt;2&lt;/code&gt; (1=fast, 9=best), change with &lt;code&gt;?tar=bz2:9&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;hidden files (&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#dotfiles"&gt;dotfiles&lt;/a&gt;) are excluded unless account is allowed to list them 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;up2k.db&lt;/code&gt; and &lt;code&gt;dir.txt&lt;/code&gt; is always excluded&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;bsdtar supports streaming unzipping: &lt;code&gt;curl foo?zip | bsdtar -xv&lt;/code&gt; 
  &lt;ul&gt; 
   &lt;li&gt;good, because copyparty's zip is faster than tar on small files 
    &lt;ul&gt; 
     &lt;li&gt;but &lt;code&gt;?tar&lt;/code&gt; is better for large files, especially if the total exceeds 4 GiB&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;zip_crc&lt;/code&gt; will take longer to download since the server has to read each file twice 
  &lt;ul&gt; 
   &lt;li&gt;this is only to support MS-DOS PKZIP v2.04g (october 1993) and older 
    &lt;ul&gt; 
     &lt;li&gt;how are you accessing copyparty actually&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;you can also zip a selection of files or folders by clicking them in the browser, that brings up a selection editor and zip button in the bottom right&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://user-images.githubusercontent.com/241032/129635374-e5136e01-470a-49b1-a762-848e8a4c9cdc.png" alt="copyparty-zipsel-fs8"&gt;&lt;/p&gt; 
&lt;p&gt;cool trick: download a folder by appending url-params &lt;code&gt;?tar&amp;amp;opus&lt;/code&gt; or &lt;code&gt;?tar&amp;amp;mp3&lt;/code&gt; to transcode all audio files (except aac|m4a|mp3|ogg|opus|wma) to opus/mp3 before they're added to the archive&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;super useful if you're 5 minutes away from takeoff and realize you don't have any music on your phone but your server only has flac files and downloading those will burn through all your data + there wouldn't be enough time anyways&lt;/li&gt; 
 &lt;li&gt;and url-params &lt;code&gt;&amp;amp;j&lt;/code&gt; / &lt;code&gt;&amp;amp;w&lt;/code&gt; produce jpeg/webm thumbnails/spectrograms instead of the original audio/video/images (&lt;code&gt;&amp;amp;p&lt;/code&gt; for audio waveforms) 
  &lt;ul&gt; 
   &lt;li&gt;can also be used to pregenerate thumbnails; combine with &lt;code&gt;--th-maxage=9999999&lt;/code&gt; or &lt;code&gt;--th-clean=0&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;uploading&lt;/h2&gt; 
&lt;p&gt;drag files/folders into the web-browser to upload&lt;/p&gt; 
&lt;p&gt;dragdrop is the recommended way, but you may also:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;select some files (not folders) in your file explorer and press CTRL-V inside the browser window&lt;/li&gt; 
 &lt;li&gt;use the &lt;a href="https://github.com/9001/copyparty/tree/hovudstraum/bin#u2cpy"&gt;command-line uploader&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;upload using &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#client-examples"&gt;curl, sharex, ishare, ...&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;when uploading files through dragdrop or CTRL-V, this initiates an upload using &lt;code&gt;up2k&lt;/code&gt;; there are two browser-based uploaders available:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;[🎈] bup&lt;/code&gt;, the basic uploader, supports almost every browser since netscape 4.0&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[🚀] up2k&lt;/code&gt;, the good / fancy one&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;NB: you can undo/delete your own uploads with &lt;code&gt;[🧯]&lt;/code&gt; &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#unpost"&gt;unpost&lt;/a&gt; (and this is also where you abort unfinished uploads, but you have to refresh the page first)&lt;/p&gt; 
&lt;p&gt;up2k has several advantages:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;you can drop folders into the browser (files are added recursively)&lt;/li&gt; 
 &lt;li&gt;files are processed in chunks, and each chunk is checksummed 
  &lt;ul&gt; 
   &lt;li&gt;uploads autoresume if they are interrupted by network issues&lt;/li&gt; 
   &lt;li&gt;uploads resume if you reboot your browser or pc, just upload the same files again&lt;/li&gt; 
   &lt;li&gt;server detects any corruption; the client reuploads affected chunks&lt;/li&gt; 
   &lt;li&gt;the client doesn't upload anything that already exists on the server&lt;/li&gt; 
   &lt;li&gt;no filesize limit, even when a proxy limits the request size (for example Cloudflare)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;much higher speeds than ftp/scp/tarpipe on some internet connections (mainly american ones) thanks to parallel connections&lt;/li&gt; 
 &lt;li&gt;the last-modified timestamp of the file is preserved&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;it is perfectly safe to restart / upgrade copyparty while someone is uploading to it!&lt;br&gt; all known up2k clients will resume just fine 💪&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/docs/devnotes.md#up2k"&gt;up2k&lt;/a&gt; for details on how it works, or watch a &lt;a href="https://a.ocv.me/pub/demo/pics-vids/#gf-0f6f5c0d"&gt;demo video&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://user-images.githubusercontent.com/241032/129635371-48fc54ca-fa91-48e3-9b1d-ba413e4b68cb.png" alt="copyparty-upload-fs8"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;protip:&lt;/strong&gt; you can avoid scaring away users with &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/contrib/plugins/minimal-up2k.js"&gt;contrib/plugins/minimal-up2k.js&lt;/a&gt; which makes it look &lt;a href="https://user-images.githubusercontent.com/241032/118311195-dd6ca380-b4ef-11eb-86f3-75a3ff2e1332.png"&gt;much simpler&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;protip:&lt;/strong&gt; if you enable &lt;code&gt;favicon&lt;/code&gt; in the &lt;code&gt;[⚙️] settings&lt;/code&gt; tab (by typing something into the textbox), the icon in the browser tab will indicate upload progress -- also, the &lt;code&gt;[🔔]&lt;/code&gt; and/or &lt;code&gt;[🔊]&lt;/code&gt; switches enable visible and/or audible notifications on upload completion&lt;/p&gt; 
&lt;p&gt;the up2k UI is the epitome of polished intuitive experiences:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;"parallel uploads" specifies how many chunks to upload at the same time&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[🏃]&lt;/code&gt; analysis of other files should continue while one is uploading&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[🥔]&lt;/code&gt; shows a simpler UI for faster uploads from slow devices&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[🛡️]&lt;/code&gt; decides when to overwrite existing files on the server 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;🛡️&lt;/code&gt; = never (generate a new filename instead)&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;🕒&lt;/code&gt; = overwrite if the server-file is older&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;♻️&lt;/code&gt; = always overwrite if the files are different&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[🎲]&lt;/code&gt; generate random filenames during upload&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[🔎]&lt;/code&gt; switch between upload and &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#file-search"&gt;file-search&lt;/a&gt; mode 
  &lt;ul&gt; 
   &lt;li&gt;ignore &lt;code&gt;[🔎]&lt;/code&gt; if you add files by dragging them into the browser&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;and then theres the tabs below it,&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;[ok]&lt;/code&gt; is the files which completed successfully&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[ng]&lt;/code&gt; is the ones that failed / got rejected (already exists, ...)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[done]&lt;/code&gt; shows a combined list of &lt;code&gt;[ok]&lt;/code&gt; and &lt;code&gt;[ng]&lt;/code&gt;, chronological order&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[busy]&lt;/code&gt; files which are currently hashing, pending-upload, or uploading 
  &lt;ul&gt; 
   &lt;li&gt;plus up to 3 entries each from &lt;code&gt;[done]&lt;/code&gt; and &lt;code&gt;[que]&lt;/code&gt; for context&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[que]&lt;/code&gt; is all the files that are still queued&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;note that since up2k has to read each file twice, &lt;code&gt;[🎈] bup&lt;/code&gt; can &lt;em&gt;theoretically&lt;/em&gt; be up to 2x faster in some extreme cases (files bigger than your ram, combined with an internet connection faster than the read-speed of your HDD, or if you're uploading from a cuo2duo)&lt;/p&gt; 
&lt;p&gt;if you are resuming a massive upload and want to skip hashing the files which already finished, you can enable &lt;code&gt;turbo&lt;/code&gt; in the &lt;code&gt;[⚙️] config&lt;/code&gt; tab, but please read the tooltip on that button&lt;/p&gt; 
&lt;p&gt;if the server is behind a proxy which imposes a request-size limit, you can configure up2k to sneak below the limit with server-option &lt;code&gt;--u2sz&lt;/code&gt; (the default is 96 MiB to support Cloudflare)&lt;/p&gt; 
&lt;p&gt;if you want to replace existing files on the server with new uploads by default, run with &lt;code&gt;--u2ow 2&lt;/code&gt; (only works if users have the delete-permission, and can still be disabled with &lt;code&gt;🛡️&lt;/code&gt; in the UI)&lt;/p&gt; 
&lt;h3&gt;file-search&lt;/h3&gt; 
&lt;p&gt;dropping files into the browser also lets you see if they exist on the server&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://user-images.githubusercontent.com/241032/129635361-c79286f0-b8f1-440e-aaf4-6e929428fac9.png" alt="copyparty-fsearch-fs8"&gt;&lt;/p&gt; 
&lt;p&gt;when you drag/drop files into the browser, you will see two dropzones: &lt;code&gt;Upload&lt;/code&gt; and &lt;code&gt;Search&lt;/code&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;on a phone? toggle the &lt;code&gt;[🔎]&lt;/code&gt; switch green before tapping the big yellow Search button to select your files&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;the files will be hashed on the client-side, and each hash is sent to the server, which checks if that file exists somewhere&lt;/p&gt; 
&lt;p&gt;files go into &lt;code&gt;[ok]&lt;/code&gt; if they exist (and you get a link to where it is), otherwise they land in &lt;code&gt;[ng]&lt;/code&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;the main reason filesearch is combined with the uploader is cause the code was too spaghetti to separate it out somewhere else, this is no longer the case but now i've warmed up to the idea too much&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;unpost&lt;/h3&gt; 
&lt;p&gt;undo/delete accidental uploads using the &lt;code&gt;[🧯]&lt;/code&gt; tab in the UI&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://user-images.githubusercontent.com/241032/129635368-3afa6634-c20f-418c-90dc-ec411f3b3897.png" alt="copyparty-unpost-fs8"&gt;&lt;/p&gt; 
&lt;p&gt;you can unpost even if you don't have regular move/delete access, however only for files uploaded within the past &lt;code&gt;--unpost&lt;/code&gt; seconds (default 12 hours) and the server must be running with &lt;code&gt;-e2d&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;config file example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;[global]
  e2d            # enable up2k database (remember uploads)
  unpost: 43200  # 12 hours (default)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;self-destruct&lt;/h3&gt; 
&lt;p&gt;uploads can be given a lifetime, after which they expire / self-destruct&lt;/p&gt; 
&lt;p&gt;the feature must be enabled per-volume with the &lt;code&gt;lifetime&lt;/code&gt; &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#upload-rules"&gt;upload rule&lt;/a&gt; which sets the upper limit for how long a file gets to stay on the server&lt;/p&gt; 
&lt;p&gt;clients can specify a shorter expiration time using the &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#uploading"&gt;up2k ui&lt;/a&gt; -- the relevant options become visible upon navigating into a folder with &lt;code&gt;lifetimes&lt;/code&gt; enabled -- or by using the &lt;code&gt;life&lt;/code&gt; &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/docs/devnotes.md#write"&gt;upload modifier&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;specifying a custom expiration time client-side will affect the timespan in which unposts are permitted, so keep an eye on the estimates in the up2k ui&lt;/p&gt; 
&lt;h3&gt;race the beam&lt;/h3&gt; 
&lt;p&gt;download files while they're still uploading (&lt;a href="http://a.ocv.me/pub/g/nerd-stuff/cpp/2024-0418-race-the-beam.webm"&gt;demo video&lt;/a&gt;) -- it's almost like peer-to-peer&lt;/p&gt; 
&lt;p&gt;requires the file to be uploaded using up2k (which is the default drag-and-drop uploader), alternatively the command-line program&lt;/p&gt; 
&lt;h3&gt;incoming files&lt;/h3&gt; 
&lt;p&gt;the control-panel shows the ETA for all incoming files , but only for files being uploaded into volumes where you have read-access&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/fd275ffa-698c-4fca-a307-4d2181269a6a" alt="copyparty-cpanel-upload-eta-or8"&gt;&lt;/p&gt; 
&lt;h2&gt;file manager&lt;/h2&gt; 
&lt;p&gt;cut/paste, rename, and delete files/folders (if you have permission)&lt;/p&gt; 
&lt;p&gt;file selection: click somewhere on the line (not the link itself), then:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;space&lt;/code&gt; to toggle&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;up/down&lt;/code&gt; to move&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;shift-up/down&lt;/code&gt; to move-and-select&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;ctrl-shift-up/down&lt;/code&gt; to also scroll&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;shift-click another line for range-select&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;cut: select some files and &lt;code&gt;ctrl-x&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;copy: select some files and &lt;code&gt;ctrl-c&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;paste: &lt;code&gt;ctrl-v&lt;/code&gt; in another folder&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;rename: &lt;code&gt;F2&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;you can copy/move files across browser tabs (cut/copy in one tab, paste in another)&lt;/p&gt; 
&lt;h2&gt;shares&lt;/h2&gt; 
&lt;p&gt;share a file or folder by creating a temporary link&lt;/p&gt; 
&lt;p&gt;when enabled in the server settings (&lt;code&gt;--shr&lt;/code&gt;), click the bottom-right &lt;code&gt;share&lt;/code&gt; button to share the folder you're currently in, or alternatively:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;select a folder first to share that folder instead&lt;/li&gt; 
 &lt;li&gt;select one or more files to share only those files&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;this feature was made with &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#identity-providers"&gt;identity providers&lt;/a&gt; in mind -- configure your reverseproxy to skip the IdP's access-control for a given URL prefix and use that to safely share specific files/folders sans the usual auth checks&lt;/p&gt; 
&lt;p&gt;when creating a share, the creator can choose any of the following options:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;password-protection&lt;/li&gt; 
 &lt;li&gt;expire after a certain time; &lt;code&gt;0&lt;/code&gt; or blank means infinite&lt;/li&gt; 
 &lt;li&gt;allow visitors to upload (if the user who creates the share has write-access)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;semi-intentional limitations:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;cleanup of expired shares only works when global option &lt;code&gt;e2d&lt;/code&gt; is set, and/or at least one volume on the server has volflag &lt;code&gt;e2d&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;only folders from the same volume are shared; if you are sharing a folder which contains other volumes, then the contents of those volumes will not be available&lt;/li&gt; 
 &lt;li&gt;if you change &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#password-hashing"&gt;password hashing&lt;/a&gt; settings after creating a password-protected share, then that share will stop working&lt;/li&gt; 
 &lt;li&gt;related to &lt;a href="https://github.com/9001/copyparty/raw/hovudstraum/docs/idp.md#idp-volumes-are-forgotten-on-shutdown"&gt;IdP volumes being forgotten on shutdown&lt;/a&gt;, any shares pointing into a user's IdP volume will be unavailable until that user makes their first request after a restart&lt;/li&gt; 
 &lt;li&gt;no option to "delete after first access" because tricky 
  &lt;ul&gt; 
   &lt;li&gt;when linking something to discord (for example) it'll get accessed by their scraper and that would count as a hit&lt;/li&gt; 
   &lt;li&gt;browsers wouldn't be able to resume a broken download unless the requester's IP gets allowlisted for X minutes (ref. tricky)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;specify &lt;code&gt;--shr /foobar&lt;/code&gt; to enable this feature; a toplevel virtual folder named &lt;code&gt;foobar&lt;/code&gt; is then created, and that's where all the shares will be served from&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;you can name it whatever, &lt;code&gt;foobar&lt;/code&gt; is just an example&lt;/li&gt; 
 &lt;li&gt;if you're using config files, put &lt;code&gt;shr: /foobar&lt;/code&gt; inside the &lt;code&gt;[global]&lt;/code&gt; section instead&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;users can delete their own shares in the controlpanel, and a list of privileged users (&lt;code&gt;--shr-adm&lt;/code&gt;) are allowed to see and/or delet any share on the server&lt;/p&gt; 
&lt;p&gt;after a share has expired, it remains visible in the controlpanel for &lt;code&gt;--shr-rt&lt;/code&gt; minutes (default is 1 day), and the owner can revive it by extending the expiration time there&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;security note:&lt;/strong&gt; using this feature does not mean that you can skip the &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#accounts-and-volumes"&gt;accounts and volumes&lt;/a&gt; section -- you still need to restrict access to volumes that you do not intend to share with unauthenticated users! it is not sufficient to use rules in the reverseproxy to restrict access to just the &lt;code&gt;/share&lt;/code&gt; folder.&lt;/p&gt; 
&lt;h2&gt;batch rename&lt;/h2&gt; 
&lt;p&gt;select some files and press &lt;code&gt;F2&lt;/code&gt; to bring up the rename UI&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://user-images.githubusercontent.com/241032/128434204-eb136680-3c07-4ec7-92e0-ae86af20c241.png" alt="batch-rename-fs8"&gt;&lt;/p&gt; 
&lt;p&gt;quick explanation of the buttons,&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;[✅ apply rename]&lt;/code&gt; confirms and begins renaming&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[❌ cancel]&lt;/code&gt; aborts and closes the rename window&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[↺ reset]&lt;/code&gt; reverts any filename changes back to the original name&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[decode]&lt;/code&gt; does a URL-decode on the filename, fixing stuff like &lt;code&gt;&amp;amp;amp;&lt;/code&gt; and &lt;code&gt;%20&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[advanced]&lt;/code&gt; toggles advanced mode&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;advanced mode: rename files based on rules to decide the new names, based on the original name (regex), or based on the tags collected from the file (artist/title/...), or a mix of both&lt;/p&gt; 
&lt;p&gt;in advanced mode,&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;[case]&lt;/code&gt; toggles case-sensitive regex&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;regex&lt;/code&gt; is the regex pattern to apply to the original filename; any files which don't match will be skipped&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;format&lt;/code&gt; is the new filename, taking values from regex capturing groups and/or from file tags 
  &lt;ul&gt; 
   &lt;li&gt;very loosely based on foobar2000 syntax&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;presets&lt;/code&gt; lets you save rename rules for later&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;available functions:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;$lpad(text, length, pad_char)&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;$rpad(text, length, pad_char)&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;so,&lt;/p&gt; 
&lt;p&gt;say you have a file named &lt;a href="https://www.youtube.com/watch?v=-dtb0vDPruI"&gt;&lt;code&gt;meganeko - Eclipse - 07 Sirius A.mp3&lt;/code&gt;&lt;/a&gt; (absolutely fantastic album btw) and the tags are: &lt;code&gt;Album:Eclipse&lt;/code&gt;, &lt;code&gt;Artist:meganeko&lt;/code&gt;, &lt;code&gt;Title:Sirius A&lt;/code&gt;, &lt;code&gt;tn:7&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;you could use just regex to rename it:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;regex&lt;/code&gt; = &lt;code&gt;(.*) - (.*) - ([0-9]{2}) (.*)&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;format&lt;/code&gt; = &lt;code&gt;(3). (1) - (4)&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;output&lt;/code&gt; = &lt;code&gt;07. meganeko - Sirius A.mp3&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;or you could use just tags:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;format&lt;/code&gt; = &lt;code&gt;$lpad((tn),2,0). (artist) - (title).(ext)&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;output&lt;/code&gt; = &lt;code&gt;7. meganeko - Sirius A.mp3&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;or a mix of both:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;regex&lt;/code&gt; = &lt;code&gt;- ([0-9]{2})&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;format&lt;/code&gt; = &lt;code&gt;(1). (artist) - (title).(ext)&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;output&lt;/code&gt; = &lt;code&gt;07. meganeko - Sirius A.mp3&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;the metadata keys you can use in the format field are the ones in the file-browser table header (whatever is collected with &lt;code&gt;-mte&lt;/code&gt; and &lt;code&gt;-mtp&lt;/code&gt;)&lt;/p&gt; 
&lt;h2&gt;rss feeds&lt;/h2&gt; 
&lt;p&gt;monitor a folder with your RSS reader , optionally recursive&lt;/p&gt; 
&lt;p&gt;must be enabled per-volume with volflag &lt;code&gt;rss&lt;/code&gt; or globally with &lt;code&gt;--rss&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;the feed includes itunes metadata for use with podcast readers such as &lt;a href="https://antennapod.org/"&gt;AntennaPod&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;a feed example: &lt;a href="https://cd.ocv.me/a/d2/d22/?rss&amp;amp;fext=mp3"&gt;https://cd.ocv.me/a/d2/d22/?rss&amp;amp;fext=mp3&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;url parameters:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;pw=hunter2&lt;/code&gt; for password auth&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;recursive&lt;/code&gt; to also include subfolders&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;title=foo&lt;/code&gt; changes the feed title (default: folder name)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;fext=mp3,opus&lt;/code&gt; only include mp3 and opus files (default: all)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;nf=30&lt;/code&gt; only show the first 30 results (default: 250)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;sort=m&lt;/code&gt; sort by mtime (file last-modified), newest first (default) 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;u&lt;/code&gt; = upload-time; NOTE: non-uploaded files have upload-time &lt;code&gt;0&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;n&lt;/code&gt; = filename&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;a&lt;/code&gt; = filesize&lt;/li&gt; 
   &lt;li&gt;uppercase = reverse-sort; &lt;code&gt;M&lt;/code&gt; = oldest file first&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;recent uploads&lt;/h2&gt; 
&lt;p&gt;list all recent uploads by clicking "show recent uploads" in the controlpanel&lt;/p&gt; 
&lt;p&gt;will show uploader IP and upload-time if the visitor has the admin permission&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;global-option &lt;code&gt;--ups-when&lt;/code&gt; makes upload-time visible to all users, and not just admins&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;global-option &lt;code&gt;--ups-who&lt;/code&gt; (volflag &lt;code&gt;ups_who&lt;/code&gt;) specifies who gets access (0=nobody, 1=admins, 2=everyone), default=2&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;note that the &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#unpost"&gt;🧯 unpost&lt;/a&gt; feature is better suited for viewing &lt;em&gt;your own&lt;/em&gt; recent uploads, as it includes the option to undo/delete them&lt;/p&gt; 
&lt;p&gt;config file example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;[global]
  ups-when    # everyone can see upload times
  ups-who: 1  # but only admins can see the list,
              # so ups-when doesn't take effect
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;media player&lt;/h2&gt; 
&lt;p&gt;plays almost every audio format there is (if the server has FFmpeg installed for on-demand transcoding)&lt;/p&gt; 
&lt;p&gt;the following audio formats are usually always playable, even without FFmpeg: &lt;code&gt;aac|flac|m4a|mp3|ogg|opus|wav&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;some hilights:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;OS integration; control playback from your phone's lockscreen (&lt;a href="https://user-images.githubusercontent.com/241032/233213022-298a98ba-721a-4cf1-a3d4-f62634bc53d5.png"&gt;windows&lt;/a&gt; // &lt;a href="https://user-images.githubusercontent.com/241032/142711926-0700be6c-3e31-47b3-9928-53722221f722.png"&gt;iOS&lt;/a&gt; // &lt;a href="https://user-images.githubusercontent.com/241032/233212311-a7368590-08c7-4f9f-a1af-48ccf3f36fad.png"&gt;android&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;shows the audio waveform in the seekbar&lt;/li&gt; 
 &lt;li&gt;not perfectly gapless but can get really close (see settings + eq below); good enough to enjoy gapless albums as intended&lt;/li&gt; 
 &lt;li&gt;videos can be played as audio, without wasting bandwidth on the video&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;click the &lt;code&gt;play&lt;/code&gt; link next to an audio file, or copy the link target to &lt;a href="https://a.ocv.me/pub/demo/music/Ubiktune%20-%20SOUNDSHOCK%202%20-%20FM%20FUNK%20TERRROR!!/#af-1fbfba61&amp;amp;t=18"&gt;share it&lt;/a&gt; (optionally with a timestamp to start playing from, like that example does)&lt;/p&gt; 
&lt;p&gt;open the &lt;code&gt;[🎺]&lt;/code&gt; media-player-settings tab to configure it,&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;"switches": 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;[🔁]&lt;/code&gt; repeats one single song forever&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;[🔀]&lt;/code&gt; shuffles the files inside each folder&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;[preload]&lt;/code&gt; starts loading the next track when it's about to end, reduces the silence between songs&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;[full]&lt;/code&gt; does a full preload by downloading the entire next file; good for unreliable connections, bad for slow connections&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;[~s]&lt;/code&gt; toggles the seekbar waveform display&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;[/np]&lt;/code&gt; enables buttons to copy the now-playing info as an irc message&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;[📻]&lt;/code&gt; enables buttons to create an &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#playlists"&gt;m3u playlist&lt;/a&gt; with the selected songs&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;[os-ctl]&lt;/code&gt; makes it possible to control audio playback from the lockscreen of your device (enables &lt;a href="https://developer.mozilla.org/en-US/docs/Web/API/MediaSession"&gt;mediasession&lt;/a&gt;)&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;[seek]&lt;/code&gt; allows seeking with lockscreen controls (buggy on some devices)&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;[art]&lt;/code&gt; shows album art on the lockscreen&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;[🎯]&lt;/code&gt; keeps the playing song scrolled into view (good when using the player as a taskbar dock)&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;[⟎]&lt;/code&gt; shrinks the playback controls&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;"buttons": 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;[uncache]&lt;/code&gt; may fix songs that won't play correctly due to bad files in browser cache&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;"at end of folder": 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;[loop]&lt;/code&gt; keeps looping the folder&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;[next]&lt;/code&gt; plays into the next folder&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;"transcode": 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;[flac]&lt;/code&gt; converts &lt;code&gt;flac&lt;/code&gt; and &lt;code&gt;wav&lt;/code&gt; files into opus (if supported by browser) or mp3&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;[aac]&lt;/code&gt; converts &lt;code&gt;aac&lt;/code&gt; and &lt;code&gt;m4a&lt;/code&gt; files into opus (if supported by browser) or mp3&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;[oth]&lt;/code&gt; converts all other known formats into opus (if supported by browser) or mp3 
    &lt;ul&gt; 
     &lt;li&gt;&lt;code&gt;aac|ac3|aif|aiff|alac|alaw|amr|ape|au|dfpwm|dts|flac|gsm|it|m4a|mo3|mod|mp2|mp3|mpc|mptm|mt2|mulaw|ogg|okt|opus|ra|s3m|tak|tta|ulaw|wav|wma|wv|xm|xpk&lt;/code&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;"transcode to": 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;[opus]&lt;/code&gt; produces an &lt;code&gt;opus&lt;/code&gt; whenever transcoding is necessary (the best choice on Android and PCs)&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;[awo]&lt;/code&gt; is &lt;code&gt;opus&lt;/code&gt; in a &lt;code&gt;weba&lt;/code&gt; file, good for iPhones (iOS 17.5 and newer) but Apple is still fixing some state-confusion bugs as of iOS 18.2.1&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;[caf]&lt;/code&gt; is &lt;code&gt;opus&lt;/code&gt; in a &lt;code&gt;caf&lt;/code&gt; file, good for iPhones (iOS 11 through 17), technically unsupported by Apple but works for the most part&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;[mp3]&lt;/code&gt; -- the myth, the legend, the undying master of mediocre sound quality that definitely works everywhere&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;"tint" reduces the contrast of the playback bar&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;playlists&lt;/h3&gt; 
&lt;p&gt;create and play &lt;a href="https://en.wikipedia.org/wiki/M3U"&gt;m3u8&lt;/a&gt; playlists -- see example &lt;a href="https://a.ocv.me/pub/demo/music/?doc=example-playlist.m3u"&gt;text&lt;/a&gt; and &lt;a href="https://a.ocv.me/pub/demo/music/#m3u=example-playlist.m3u"&gt;player&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;click a file with the extension &lt;code&gt;m3u&lt;/code&gt; or &lt;code&gt;m3u8&lt;/code&gt; (for example &lt;code&gt;mixtape.m3u&lt;/code&gt; or &lt;code&gt;touhou.m3u8&lt;/code&gt; ) and you get two choices: Play / Edit&lt;/p&gt; 
&lt;p&gt;playlists can include songs across folders anywhere on the server, but filekeys/dirkeys are NOT supported, so the listener must have read-access or get-access to the files&lt;/p&gt; 
&lt;h3&gt;creating a playlist&lt;/h3&gt; 
&lt;p&gt;with a standalone mediaplayer or copyparty&lt;/p&gt; 
&lt;p&gt;you can use foobar2000, deadbeef, just about any standalone player should work -- but you might need to edit the filepaths in the playlist so they fit with the server-URLs&lt;/p&gt; 
&lt;p&gt;alternatively, you can create the playlist using copyparty itself:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;open the &lt;code&gt;[🎺]&lt;/code&gt; media-player-settings tab and enable the &lt;code&gt;[📻]&lt;/code&gt; create-playlist feature -- this adds two new buttons in the bottom-right tray, &lt;code&gt;[📻add]&lt;/code&gt; and &lt;code&gt;[📻copy]&lt;/code&gt; which appear when you listen to music, or when you select a few audiofiles&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;click the &lt;code&gt;📻add&lt;/code&gt; button while a song is playing (or when you've selected some songs) and they'll be added to "the list" (you can't see it yet)&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;at any time, click &lt;code&gt;📻copy&lt;/code&gt; to send the playlist to your clipboard&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;you can then continue adding more songs if you'd like&lt;/li&gt; 
   &lt;li&gt;if you want to wipe the playlist and start from scratch, just refresh the page&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;create a new textfile, name it &lt;code&gt;something.m3u&lt;/code&gt; and paste the playlist there&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;audio equalizer&lt;/h3&gt; 
&lt;p&gt;and &lt;a href="https://en.wikipedia.org/wiki/Dynamic_range_compression"&gt;dynamic range compressor&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;can also boost the volume in general, or increase/decrease stereo width (like &lt;a href="https://www.foobar2000.org/components/view/foo_dsp_meiercf"&gt;crossfeed&lt;/a&gt; just worse)&lt;/p&gt; 
&lt;p&gt;has the convenient side-effect of reducing the pause between songs, so gapless albums play better with the eq enabled (just make it flat)&lt;/p&gt; 
&lt;p&gt;not available on iPhones / iPads because AudioContext currently breaks background audio playback on iOS (15.7.8)&lt;/p&gt; 
&lt;h3&gt;fix unreliable playback on android&lt;/h3&gt; 
&lt;p&gt;due to phone / app settings, android phones may randomly stop playing music when the power saver kicks in, especially at the end of an album -- you can fix it by &lt;a href="https://user-images.githubusercontent.com/241032/235262123-c328cca9-3930-4948-bd18-3949b9fd3fcf.png"&gt;disabling power saving&lt;/a&gt; in the &lt;a href="https://user-images.githubusercontent.com/241032/235262121-2ffc51ae-7821-4310-a322-c3b7a507890c.png"&gt;app settings&lt;/a&gt; of the browser you use for music streaming (preferably a dedicated one)&lt;/p&gt; 
&lt;h2&gt;textfile viewer&lt;/h2&gt; 
&lt;p&gt;with realtime streaming of logfiles and such (&lt;a href="https://a.ocv.me/pub/demo/logtail/"&gt;demo&lt;/a&gt;) , and terminal colors work too&lt;/p&gt; 
&lt;p&gt;click &lt;code&gt;-txt-&lt;/code&gt; next to a textfile to open the viewer, which has the following toolbar buttons:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;✏️ edit&lt;/code&gt; opens the textfile editor&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;📡 follow&lt;/code&gt; starts monitoring the file for changes, streaming new lines in realtime 
  &lt;ul&gt; 
   &lt;li&gt;similar to &lt;code&gt;tail -f&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://a.ocv.me/pub/demo/logtail/?doc=lipsum.txt&amp;amp;tail"&gt;link directly&lt;/a&gt; to a file with tailing enabled by adding &lt;code&gt;&amp;amp;tail&lt;/code&gt; to the textviewer URL&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;markdown viewer&lt;/h2&gt; 
&lt;p&gt;and there are &lt;em&gt;two&lt;/em&gt; editors&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://user-images.githubusercontent.com/241032/115978057-66419080-a57d-11eb-8539-d2be843991aa.png" alt="copyparty-md-read-fs8"&gt;&lt;/p&gt; 
&lt;p&gt;there is a built-in extension for inline clickable thumbnails;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;enable it by adding &lt;code&gt;&amp;lt;!-- th --&amp;gt;&lt;/code&gt; somewhere in the doc&lt;/li&gt; 
 &lt;li&gt;add thumbnails with &lt;code&gt;!th[l](your.jpg)&lt;/code&gt; where &lt;code&gt;l&lt;/code&gt; means left-align (&lt;code&gt;r&lt;/code&gt; = right-align)&lt;/li&gt; 
 &lt;li&gt;a single line with &lt;code&gt;---&lt;/code&gt; clears the float / inlining&lt;/li&gt; 
 &lt;li&gt;in the case of README.md being displayed below a file listing, thumbnails will open in the gallery viewer&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;other notes,&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;the document preview has a max-width which is the same as an A4 paper when printed&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;markdown vars&lt;/h3&gt; 
&lt;p&gt;dynamic docs with serverside variable expansion to replace stuff like &lt;code&gt;{{self.ip}}&lt;/code&gt; with the client's IP, or &lt;code&gt;{{srv.htime}}&lt;/code&gt; with the current time on the server&lt;/p&gt; 
&lt;p&gt;see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/srv/expand/"&gt;./srv/expand/&lt;/a&gt; for usage and examples&lt;/p&gt; 
&lt;h2&gt;other tricks&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;you can link a particular timestamp in an audio file by adding it to the URL, such as &lt;code&gt;&amp;amp;20&lt;/code&gt; / &lt;code&gt;&amp;amp;20s&lt;/code&gt; / &lt;code&gt;&amp;amp;1m20&lt;/code&gt; / &lt;code&gt;&amp;amp;t=1:20&lt;/code&gt; after the &lt;code&gt;.../#af-c8960dab&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;enabling the audio equalizer can help make gapless albums fully gapless in some browsers (chrome), so consider leaving it on with all the values at zero&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;get a plaintext file listing by adding &lt;code&gt;?ls=t&lt;/code&gt; to a URL, or a compact colored one with &lt;code&gt;?ls=v&lt;/code&gt; (for unix terminals)&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;if you are using media hotkeys to switch songs and are getting tired of seeing the OSD popup which Windows doesn't let you disable, consider &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/contrib/#media-osd-bgoneps1"&gt;./contrib/media-osd-bgone.ps1&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;click the bottom-left &lt;code&gt;π&lt;/code&gt; to open a javascript prompt for debugging&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;files named &lt;code&gt;.prologue.html&lt;/code&gt; / &lt;code&gt;.epilogue.html&lt;/code&gt; will be rendered before/after directory listings unless &lt;code&gt;--no-logues&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;files named &lt;code&gt;descript.ion&lt;/code&gt; / &lt;code&gt;DESCRIPT.ION&lt;/code&gt; are parsed and displayed in the file listing, or as the epilogue if nonstandard&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;files named &lt;code&gt;README.md&lt;/code&gt; / &lt;code&gt;readme.md&lt;/code&gt; will be rendered after directory listings unless &lt;code&gt;--no-readme&lt;/code&gt; (but &lt;code&gt;.epilogue.html&lt;/code&gt; takes precedence)&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;and &lt;code&gt;PREADME.md&lt;/code&gt; / &lt;code&gt;preadme.md&lt;/code&gt; is shown above directory listings unless &lt;code&gt;--no-readme&lt;/code&gt; or &lt;code&gt;.prologue.html&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;README.md&lt;/code&gt; and &lt;code&gt;*logue.html&lt;/code&gt; can contain placeholder values which are replaced server-side before embedding into directory listings; see &lt;code&gt;--help-exp&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;searching&lt;/h2&gt; 
&lt;p&gt;search by size, date, path/name, mp3-tags, ...&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://user-images.githubusercontent.com/241032/129635365-c0ff2a9f-0ee5-4fc3-8bb6-006033cf67b8.png" alt="copyparty-search-fs8"&gt;&lt;/p&gt; 
&lt;p&gt;when started with &lt;code&gt;-e2dsa&lt;/code&gt; copyparty will scan/index all your files. This avoids duplicates on upload, and also makes the volumes searchable through the web-ui:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;make search queries by &lt;code&gt;size&lt;/code&gt;/&lt;code&gt;date&lt;/code&gt;/&lt;code&gt;directory-path&lt;/code&gt;/&lt;code&gt;filename&lt;/code&gt;, or...&lt;/li&gt; 
 &lt;li&gt;drag/drop a local file to see if the same contents exist somewhere on the server, see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#file-search"&gt;file-search&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;path/name queries are space-separated, AND'ed together, and words are negated with a &lt;code&gt;-&lt;/code&gt; prefix, so for example:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;path: &lt;code&gt;shibayan -bossa&lt;/code&gt; finds all files where one of the folders contain &lt;code&gt;shibayan&lt;/code&gt; but filters out any results where &lt;code&gt;bossa&lt;/code&gt; exists somewhere in the path&lt;/li&gt; 
 &lt;li&gt;name: &lt;code&gt;demetori styx&lt;/code&gt; gives you &lt;a href="https://www.youtube.com/watch?v=zGh0g14ZJ8I&amp;amp;list=PL3A147BD151EE5218&amp;amp;index=9"&gt;good stuff&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;the &lt;code&gt;raw&lt;/code&gt; field allows for more complex stuff such as &lt;code&gt;( tags like *nhato* or tags like *taishi* ) and ( not tags like *nhato* or not tags like *taishi* )&lt;/code&gt; which finds all songs by either nhato or taishi, excluding collabs (terrible example, why would you do that)&lt;/p&gt; 
&lt;p&gt;for the above example to work, add the commandline argument &lt;code&gt;-e2ts&lt;/code&gt; to also scan/index tags from music files, which brings us over to:&lt;/p&gt; 
&lt;h1&gt;server config&lt;/h1&gt; 
&lt;p&gt;using arguments or config files, or a mix of both:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;config files (&lt;code&gt;-c some.conf&lt;/code&gt;) can set additional commandline arguments; see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/docs/example.conf"&gt;./docs/example.conf&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/docs/example2.conf"&gt;./docs/example2.conf&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;kill -s USR1&lt;/code&gt; (same as &lt;code&gt;systemctl reload copyparty&lt;/code&gt;) to reload accounts and volumes from config files without restarting 
  &lt;ul&gt; 
   &lt;li&gt;or click the &lt;code&gt;[reload cfg]&lt;/code&gt; button in the control-panel if the user has &lt;code&gt;a&lt;/code&gt;/admin in any volume&lt;/li&gt; 
   &lt;li&gt;changes to the &lt;code&gt;[global]&lt;/code&gt; config section requires a restart to take effect&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;NB:&lt;/strong&gt; as humongous as this readme is, there is also a lot of undocumented features. Run copyparty with &lt;code&gt;--help&lt;/code&gt; to see all available global options; all of those can be used in the &lt;code&gt;[global]&lt;/code&gt; section of config files, and everything listed in &lt;code&gt;--help-flags&lt;/code&gt; can be used in volumes as volflags.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;if running in docker/podman, try this: &lt;code&gt;docker run --rm -it copyparty/ac --help&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;or see this (probably outdated): &lt;a href="https://ocv.me/copyparty/helptext.html"&gt;https://ocv.me/copyparty/helptext.html&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;or if you prefer plaintext, &lt;a href="https://ocv.me/copyparty/helptext.txt"&gt;https://ocv.me/copyparty/helptext.txt&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;zeroconf&lt;/h2&gt; 
&lt;p&gt;announce enabled services on the LAN (&lt;a href="https://user-images.githubusercontent.com/241032/215344737-0eae8d98-9496-4256-9aa8-cd2f6971810d.png"&gt;pic&lt;/a&gt;) -- &lt;code&gt;-z&lt;/code&gt; enables both &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#mdns"&gt;mdns&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#ssdp"&gt;ssdp&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;--z-on&lt;/code&gt; / &lt;code&gt;--z-off&lt;/code&gt; limits the feature to certain networks&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;config file example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;[global]
  z      # enable all zeroconf features (mdns, ssdp)
  zm     # only enables mdns (does nothing since we already have z)
  z-on: 192.168.0.0/16, 10.1.2.0/24  # restrict to certain subnets
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;mdns&lt;/h3&gt; 
&lt;p&gt;LAN domain-name and feature announcer&lt;/p&gt; 
&lt;p&gt;uses &lt;a href="https://en.wikipedia.org/wiki/Multicast_DNS"&gt;multicast dns&lt;/a&gt; to give copyparty a domain which any machine on the LAN can use to access it&lt;/p&gt; 
&lt;p&gt;all enabled services (&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#webdav-server"&gt;webdav&lt;/a&gt;, &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#ftp-server"&gt;ftp&lt;/a&gt;, &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#smb-server"&gt;smb&lt;/a&gt;) will appear in mDNS-aware file managers (KDE, gnome, macOS, ...)&lt;/p&gt; 
&lt;p&gt;the domain will be &lt;code&gt;partybox.local&lt;/code&gt; if the machine's hostname is &lt;code&gt;partybox&lt;/code&gt; unless &lt;code&gt;--name&lt;/code&gt; specifies something else&lt;/p&gt; 
&lt;p&gt;and the web-UI will be available at &lt;a href="http://partybox.local:3923/"&gt;http://partybox.local:3923/&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;if you want to get rid of the &lt;code&gt;:3923&lt;/code&gt; so you can use &lt;a href="http://partybox.local/"&gt;http://partybox.local/&lt;/a&gt; instead then see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#listen-on-port-80-and-443"&gt;listen on port 80 and 443&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;ssdp&lt;/h3&gt; 
&lt;p&gt;windows-explorer announcer&lt;/p&gt; 
&lt;p&gt;uses &lt;a href="https://en.wikipedia.org/wiki/Simple_Service_Discovery_Protocol"&gt;ssdp&lt;/a&gt; to make copyparty appear in the windows file explorer on all machines on the LAN&lt;/p&gt; 
&lt;p&gt;doubleclicking the icon opens the "connect" page which explains how to mount copyparty as a local filesystem&lt;/p&gt; 
&lt;p&gt;if copyparty does not appear in windows explorer, use &lt;code&gt;--zsv&lt;/code&gt; to see why:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;maybe the discovery multicast was sent from an IP which does not intersect with the server subnets&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;qr-code&lt;/h2&gt; 
&lt;p&gt;print a qr-code &lt;a href="https://user-images.githubusercontent.com/241032/194728533-6f00849b-c6ac-43c6-9359-83e454d11e00.png"&gt;(screenshot)&lt;/a&gt; for quick access, great between phones on android hotspots which keep changing the subnet&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;--qr&lt;/code&gt; enables it&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--qrs&lt;/code&gt; does https instead of http&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--qrl lootbox/?pw=hunter2&lt;/code&gt; appends to the url, linking to the &lt;code&gt;lootbox&lt;/code&gt; folder with password &lt;code&gt;hunter2&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--qrz 1&lt;/code&gt; forces 1x zoom instead of autoscaling to fit the terminal size 
  &lt;ul&gt; 
   &lt;li&gt;1x may render incorrectly on some terminals/fonts, but 2x should always work&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;it uses the server hostname if &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#mdns"&gt;mdns&lt;/a&gt; is enabled, otherwise it'll use your external ip (default route) unless &lt;code&gt;--qri&lt;/code&gt; specifies a specific ip-prefix or domain&lt;/p&gt; 
&lt;h2&gt;ftp server&lt;/h2&gt; 
&lt;p&gt;an FTP server can be started using &lt;code&gt;--ftp 3921&lt;/code&gt;, and/or &lt;code&gt;--ftps&lt;/code&gt; for explicit TLS (ftpes)&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;based on &lt;a href="https://github.com/giampaolo/pyftpdlib"&gt;pyftpdlib&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;needs a dedicated port (cannot share with the HTTP/HTTPS API)&lt;/li&gt; 
 &lt;li&gt;uploads are not resumable -- delete and restart if necessary&lt;/li&gt; 
 &lt;li&gt;runs in active mode by default, you probably want &lt;code&gt;--ftp-pr 12000-13000&lt;/code&gt; 
  &lt;ul&gt; 
   &lt;li&gt;if you enable both &lt;code&gt;ftp&lt;/code&gt; and &lt;code&gt;ftps&lt;/code&gt;, the port-range will be divided in half&lt;/li&gt; 
   &lt;li&gt;some older software (filezilla on debian-stable) cannot passive-mode with TLS&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;login with any username + your password, or put your password in the username field&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;some recommended FTP / FTPS clients; &lt;code&gt;wark&lt;/code&gt; = example password:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://winscp.net/eng/download.php"&gt;https://winscp.net/eng/download.php&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://filezilla-project.org/"&gt;https://filezilla-project.org/&lt;/a&gt; struggles a bit with ftps in active-mode, but is fine otherwise&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://rclone.org/"&gt;https://rclone.org/&lt;/a&gt; does FTPS with &lt;code&gt;tls=false explicit_tls=true&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;lftp -u k,wark -p 3921 127.0.0.1 -e ls&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;lftp -u k,wark -p 3990 127.0.0.1 -e 'set ssl:verify-certificate no; ls'&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;webdav server&lt;/h2&gt; 
&lt;p&gt;with read-write support, supports winXP and later, macos, nautilus/gvfs ... a great way to &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#mount-as-drive"&gt;access copyparty straight from the file explorer in your OS&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;click the &lt;a href="http://127.0.0.1:3923/?hc"&gt;connect&lt;/a&gt; button in the control-panel to see connection instructions for windows, linux, macos&lt;/p&gt; 
&lt;p&gt;general usage:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;login with any username + your password, or put your password in the username field (password field can be empty/whatever)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;on macos, connect from finder:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;[Go] -&amp;gt; [Connect to Server...] -&amp;gt; &lt;a href="http://192.168.123.1:3923/"&gt;http://192.168.123.1:3923/&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;in order to grant full write-access to webdav clients, the volflag &lt;code&gt;daw&lt;/code&gt; must be set and the account must also have delete-access (otherwise the client won't be allowed to replace the contents of existing files, which is how webdav works)&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;note: if you have enabled &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#identity-providers"&gt;IdP authentication&lt;/a&gt; then that may cause issues for some/most webdav clients; see &lt;a href="https://github.com/9001/copyparty/raw/hovudstraum/docs/idp.md#connecting-webdav-clients"&gt;the webdav section in the IdP docs&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;connecting to webdav from windows&lt;/h3&gt; 
&lt;p&gt;using the GUI (winXP or later):&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;rightclick [my computer] -&amp;gt; [map network drive] -&amp;gt; Folder: &lt;code&gt;http://192.168.123.1:3923/&lt;/code&gt; 
  &lt;ul&gt; 
   &lt;li&gt;on winXP only, click the &lt;code&gt;Sign up for online storage&lt;/code&gt; hyperlink instead and put the URL there&lt;/li&gt; 
   &lt;li&gt;providing your password as the username is recommended; the password field can be anything or empty&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;the webdav client that's built into windows has the following list of bugs; you can avoid all of these by connecting with rclone instead:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;win7+ doesn't actually send the password to the server when reauthenticating after a reboot unless you first try to login with an incorrect password and then switch to the correct password 
  &lt;ul&gt; 
   &lt;li&gt;or just type your password into the username field instead to get around it entirely&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;connecting to a folder which allows anonymous read will make writing impossible, as windows has decided it doesn't need to login 
  &lt;ul&gt; 
   &lt;li&gt;workaround: connect twice; first to a folder which requires auth, then to the folder you actually want, and leave both of those mounted&lt;/li&gt; 
   &lt;li&gt;or set the server-option &lt;code&gt;--dav-auth&lt;/code&gt; to force password-auth for all webdav clients&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;win7+ may open a new tcp connection for every file and sometimes forgets to close them, eventually needing a reboot 
  &lt;ul&gt; 
   &lt;li&gt;maybe NIC-related (??), happens with win10-ltsc on e1000e but not virtio&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;windows cannot access folders which contain filenames with invalid unicode or forbidden characters (&lt;code&gt;&amp;lt;&amp;gt;:"/\|?*&lt;/code&gt;), or names ending with &lt;code&gt;.&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;winxp cannot show unicode characters outside of &lt;em&gt;some range&lt;/em&gt; 
  &lt;ul&gt; 
   &lt;li&gt;latin-1 is fine, hiragana is not (not even as shift-jis on japanese xp)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;tftp server&lt;/h2&gt; 
&lt;p&gt;a TFTP server (read/write) can be started using &lt;code&gt;--tftp 3969&lt;/code&gt; (you probably want &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#ftp-server"&gt;ftp&lt;/a&gt; instead unless you are &lt;em&gt;actually&lt;/em&gt; communicating with hardware from the 90s (in which case we should definitely hang some time))&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;that makes this the first RTX DECT Base that has been updated using copyparty 🎉&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;based on &lt;a href="https://github.com/9001/partftpy"&gt;partftpy&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;no accounts; read from world-readable folders, write to world-writable, overwrite in world-deletable&lt;/li&gt; 
 &lt;li&gt;needs a dedicated port (cannot share with the HTTP/HTTPS API) 
  &lt;ul&gt; 
   &lt;li&gt;run as root (or see below) to use the spec-recommended port &lt;code&gt;69&lt;/code&gt; (nice)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;can reply from a predefined portrange (good for firewalls)&lt;/li&gt; 
 &lt;li&gt;only supports the binary/octet/image transfer mode (no netascii)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://datatracker.ietf.org/doc/html/rfc7440"&gt;RFC 7440&lt;/a&gt; is &lt;strong&gt;not&lt;/strong&gt; supported, so will be extremely slow over WAN 
  &lt;ul&gt; 
   &lt;li&gt;assuming default blksize (512), expect 1100 KiB/s over 100BASE-T, 400-500 KiB/s over wifi, 200 on bad wifi&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;most clients expect to find TFTP on port 69, but on linux and macos you need to be root to listen on that. Alternatively, listen on 3969 and use NAT on the server to forward 69 to that port;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;on linux: &lt;code&gt;iptables -t nat -A PREROUTING -i eth0 -p udp --dport 69 -j REDIRECT --to-port 3969&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;some recommended TFTP clients:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;curl (cross-platform, read/write) 
  &lt;ul&gt; 
   &lt;li&gt;get: &lt;code&gt;curl --tftp-blksize 1428 tftp://127.0.0.1:3969/firmware.bin&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;put: &lt;code&gt;curl --tftp-blksize 1428 -T firmware.bin tftp://127.0.0.1:3969/&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;windows: &lt;code&gt;tftp.exe&lt;/code&gt; (you probably already have it) 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;tftp -i 127.0.0.1 put firmware.bin&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;linux: &lt;code&gt;tftp-hpa&lt;/code&gt;, &lt;code&gt;atftp&lt;/code&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;atftp --option "blksize 1428" 127.0.0.1 3969 -p -l firmware.bin -r firmware.bin&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;tftp -v -m binary 127.0.0.1 3969 -c put firmware.bin&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;smb server&lt;/h2&gt; 
&lt;p&gt;unsafe, slow, not recommended for wan, enable with &lt;code&gt;--smb&lt;/code&gt; for read-only or &lt;code&gt;--smbw&lt;/code&gt; for read-write&lt;/p&gt; 
&lt;p&gt;click the &lt;a href="http://127.0.0.1:3923/?hc"&gt;connect&lt;/a&gt; button in the control-panel to see connection instructions for windows, linux, macos&lt;/p&gt; 
&lt;p&gt;dependencies: &lt;code&gt;python3 -m pip install --user -U impacket==0.11.0&lt;/code&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;newer versions of impacket will hopefully work just fine but there is monkeypatching so maybe not&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;some &lt;strong&gt;BIG WARNINGS&lt;/strong&gt; specific to SMB/CIFS, in decreasing importance:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;not entirely confident that read-only is read-only&lt;/li&gt; 
 &lt;li&gt;the smb backend is not fully integrated with vfs, meaning there could be security issues (path traversal). Please use &lt;code&gt;--smb-port&lt;/code&gt; (see below) and &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/bin/prisonparty.sh"&gt;prisonparty&lt;/a&gt; or &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/bin/bubbleparty.sh"&gt;bubbleparty&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;account passwords work per-volume as expected, and so does account permissions (read/write/move/delete), but &lt;code&gt;--smbw&lt;/code&gt; must be given to allow write-access from smb&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#shadowing"&gt;shadowing&lt;/a&gt; probably works as expected but no guarantees&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;and some minor issues,&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;clients only see the first ~400 files in big folders; 
  &lt;ul&gt; 
   &lt;li&gt;this was originally due to &lt;a href="https://github.com/SecureAuthCorp/impacket/issues/1433"&gt;impacket#1433&lt;/a&gt; which was fixed in impacket-0.12, so you can disable the workaround with &lt;code&gt;--smb-nwa-1&lt;/code&gt; but then you get unacceptably poor performance instead&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;hot-reload of server config (&lt;code&gt;/?reload=cfg&lt;/code&gt;) does not include the &lt;code&gt;[global]&lt;/code&gt; section (commandline args)&lt;/li&gt; 
 &lt;li&gt;listens on the first IPv4 &lt;code&gt;-i&lt;/code&gt; interface only (default = :: = 0.0.0.0 = all)&lt;/li&gt; 
 &lt;li&gt;login doesn't work on winxp, but anonymous access is ok -- remove all accounts from copyparty config for that to work 
  &lt;ul&gt; 
   &lt;li&gt;win10 onwards does not allow connecting anonymously / without accounts&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;python3 only&lt;/li&gt; 
 &lt;li&gt;slow (the builtin webdav support in windows is 5x faster, and rclone-webdav is 30x faster)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;known client bugs:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;on win7 only, &lt;code&gt;--smb1&lt;/code&gt; is much faster than smb2 (default) because it keeps rescanning folders on smb2 
  &lt;ul&gt; 
   &lt;li&gt;however smb1 is buggy and is not enabled by default on win10 onwards&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;windows cannot access folders which contain filenames with invalid unicode or forbidden characters (&lt;code&gt;&amp;lt;&amp;gt;:"/\|?*&lt;/code&gt;), or names ending with &lt;code&gt;.&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;the smb protocol listens on TCP port 445, which is a privileged port on linux and macos, which would require running copyparty as root. However, this can be avoided by listening on another port using &lt;code&gt;--smb-port 3945&lt;/code&gt; and then using NAT on the server to forward the traffic from 445 to there;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;on linux: &lt;code&gt;iptables -t nat -A PREROUTING -i eth0 -p tcp --dport 445 -j REDIRECT --to-port 3945&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;authenticate with one of the following:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;username &lt;code&gt;$username&lt;/code&gt;, password &lt;code&gt;$password&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;username &lt;code&gt;$password&lt;/code&gt;, password &lt;code&gt;k&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;browser ux&lt;/h2&gt; 
&lt;p&gt;tweaking the ui&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;set default sort order globally with &lt;code&gt;--sort&lt;/code&gt; or per-volume with the &lt;code&gt;sort&lt;/code&gt; volflag; specify one or more comma-separated columns to sort by, and prefix the column name with &lt;code&gt;-&lt;/code&gt; for reverse sort 
  &lt;ul&gt; 
   &lt;li&gt;the column names you can use are visible as tooltips when hovering over the column headers in the directory listing, for example &lt;code&gt;href ext sz ts tags/.up_at tags/Circle tags/.tn tags/Artist tags/Title&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;to sort in music order (album, track, artist, title) with filename as fallback, you could &lt;code&gt;--sort tags/Circle,tags/.tn,tags/Artist,tags/Title,href&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;to sort by upload date, first enable showing the upload date in the listing with &lt;code&gt;-e2d -mte +.up_at&lt;/code&gt; and then &lt;code&gt;--sort tags/.up_at&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/docs/rice"&gt;./docs/rice&lt;/a&gt; for more, including how to add stuff (css/&lt;code&gt;&amp;lt;meta&amp;gt;&lt;/code&gt;/...) to the html &lt;code&gt;&amp;lt;head&amp;gt;&lt;/code&gt; tag, or to add your own translation&lt;/p&gt; 
&lt;h2&gt;opengraph&lt;/h2&gt; 
&lt;p&gt;discord and social-media embeds&lt;/p&gt; 
&lt;p&gt;can be enabled globally with &lt;code&gt;--og&lt;/code&gt; or per-volume with volflag &lt;code&gt;og&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;note that this disables hotlinking because the opengraph spec demands it; to sneak past this intentional limitation, you can enable opengraph selectively by user-agent, for example &lt;code&gt;--og-ua '(Discord|Twitter|Slack)bot'&lt;/code&gt; (or volflag &lt;code&gt;og_ua&lt;/code&gt;)&lt;/p&gt; 
&lt;p&gt;you can also hotlink files regardless by appending &lt;code&gt;?raw&lt;/code&gt; to the url&lt;/p&gt; 
&lt;p&gt;if you want to entirely replace the copyparty response with your own jinja2 template, give the template filepath to &lt;code&gt;--og-tpl&lt;/code&gt; or volflag &lt;code&gt;og_tpl&lt;/code&gt; (all members of &lt;code&gt;HttpCli&lt;/code&gt; are available through the &lt;code&gt;this&lt;/code&gt; object)&lt;/p&gt; 
&lt;h2&gt;file deduplication&lt;/h2&gt; 
&lt;p&gt;enable symlink-based upload deduplication globally with &lt;code&gt;--dedup&lt;/code&gt; or per-volume with volflag &lt;code&gt;dedup&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;by default, when someone tries to upload a file that already exists on the server, the upload will be politely declined, and the server will copy the existing file over to where the upload would have gone&lt;/p&gt; 
&lt;p&gt;if you enable deduplication with &lt;code&gt;--dedup&lt;/code&gt; then it'll create a symlink instead of a full copy, thus reducing disk space usage&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;on the contrary, if your server is hooked up to s3-glacier or similar storage where reading is expensive, and you cannot use &lt;code&gt;--safe-dedup=1&lt;/code&gt; because you have other software tampering with your files, so you want to entirely disable detection of duplicate data instead, then you can specify &lt;code&gt;--no-clone&lt;/code&gt; globally or &lt;code&gt;noclone&lt;/code&gt; as a volflag&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;warning:&lt;/strong&gt; when enabling dedup, you should also:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;enable indexing with &lt;code&gt;-e2dsa&lt;/code&gt; or volflag &lt;code&gt;e2dsa&lt;/code&gt; (see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#file-indexing"&gt;file indexing&lt;/a&gt; section below); strongly recommended&lt;/li&gt; 
 &lt;li&gt;...and/or &lt;code&gt;--hardlink-only&lt;/code&gt; to use hardlink-based deduplication instead of symlinks; see explanation below&lt;/li&gt; 
 &lt;li&gt;...and/or &lt;code&gt;--reflink&lt;/code&gt; to use CoW/reflink-based dedup (much safer than hardlink, but OS/FS-dependent)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;it will not be safe to rename/delete files if you only enable dedup and none of the above; if you enable indexing then it is not &lt;em&gt;necessary&lt;/em&gt; to also do hardlinks (but you may still want to)&lt;/p&gt; 
&lt;p&gt;by default, deduplication is done based on symlinks (symbolic links); these are tiny files which are pointers to the nearest full copy of the file&lt;/p&gt; 
&lt;p&gt;you can choose to use hardlinks instead of softlinks, globally with &lt;code&gt;--hardlink-only&lt;/code&gt; or volflag &lt;code&gt;hardlinkonly&lt;/code&gt;, and you can choose to use reflinks with &lt;code&gt;--reflink&lt;/code&gt; or volflag &lt;code&gt;reflink&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;advantages of using reflinks (CoW, copy-on-write):&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;entirely safe (when your filesystem supports it correctly); either file can be edited or deleted without affecting other copies&lt;/li&gt; 
 &lt;li&gt;only linux 5.3 or newer, only python 3.14 or newer, only some filesystems (btrfs probably ok, maybe xfs too, but zfs had bugs)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;advantages of using hardlinks:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;hardlinks are more compatible with other software; they behave entirely like regular files&lt;/li&gt; 
 &lt;li&gt;you can safely move and rename files using other file managers 
  &lt;ul&gt; 
   &lt;li&gt;symlinks need to be managed by copyparty to ensure the destinations remain correct&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;advantages of using symlinks (default):&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;each symlink can have its own last-modified timestamp, but a single timestamp is shared by all hardlinks&lt;/li&gt; 
 &lt;li&gt;symlinks make it more obvious to other software that the file is not a regular file, so this can be less dangerous 
  &lt;ul&gt; 
   &lt;li&gt;hardlinks look like regular files, so other software may assume they are safe to edit without affecting the other copies&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;warning:&lt;/strong&gt; if you edit the contents of a deduplicated file, then you will also edit all other copies of that file! This is especially surprising with hardlinks, because they look like regular files, but that same file exists in multiple locations&lt;/p&gt; 
&lt;p&gt;global-option &lt;code&gt;--xlink&lt;/code&gt; / volflag &lt;code&gt;xlink&lt;/code&gt; additionally enables deduplication across volumes, but this is probably buggy and not recommended&lt;/p&gt; 
&lt;p&gt;config file example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;[global]
  e2dsa  # scan and index filesystem on startup
  dedup  # symlink-based deduplication for all volumes

[/media]
  /mnt/nas/media
  flags:
    hardlinkonly  # this vol does hardlinks instead of symlinks
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;file indexing&lt;/h2&gt; 
&lt;p&gt;enable music search, upload-undo, and better dedup&lt;/p&gt; 
&lt;p&gt;file indexing relies on two database tables, the up2k filetree (&lt;code&gt;-e2d&lt;/code&gt;) and the metadata tags (&lt;code&gt;-e2t&lt;/code&gt;), stored in &lt;code&gt;.hist/up2k.db&lt;/code&gt;. Configuration can be done through arguments, volflags, or a mix of both.&lt;/p&gt; 
&lt;p&gt;through arguments:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;-e2d&lt;/code&gt; enables file indexing on upload&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-e2ds&lt;/code&gt; also scans writable folders for new files on startup&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-e2dsa&lt;/code&gt; also scans all mounted volumes (including readonly ones)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-e2t&lt;/code&gt; enables metadata indexing on upload&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-e2ts&lt;/code&gt; also scans for tags in all files that don't have tags yet&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-e2tsr&lt;/code&gt; also deletes all existing tags, doing a full reindex&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-e2v&lt;/code&gt; verifies file integrity at startup, comparing hashes from the db&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-e2vu&lt;/code&gt; patches the database with the new hashes from the filesystem&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-e2vp&lt;/code&gt; panics and kills copyparty instead&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;the same arguments can be set as volflags, in addition to &lt;code&gt;d2d&lt;/code&gt;, &lt;code&gt;d2ds&lt;/code&gt;, &lt;code&gt;d2t&lt;/code&gt;, &lt;code&gt;d2ts&lt;/code&gt;, &lt;code&gt;d2v&lt;/code&gt; for disabling:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;-v ~/music::r:c,e2ds,e2tsr&lt;/code&gt; does a full reindex of everything on startup&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-v ~/music::r:c,d2d&lt;/code&gt; disables &lt;strong&gt;all&lt;/strong&gt; indexing, even if any &lt;code&gt;-e2*&lt;/code&gt; are on&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-v ~/music::r:c,d2t&lt;/code&gt; disables all &lt;code&gt;-e2t*&lt;/code&gt; (tags), does not affect &lt;code&gt;-e2d*&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-v ~/music::r:c,d2ds&lt;/code&gt; disables on-boot scans; only index new uploads&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-v ~/music::r:c,d2ts&lt;/code&gt; same except only affecting tags&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;note:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;upload-times can be displayed in the file listing by enabling the &lt;code&gt;.up_at&lt;/code&gt; metadata key, either globally with &lt;code&gt;-e2d -mte +.up_at&lt;/code&gt; or per-volume with volflags &lt;code&gt;e2d,mte=+.up_at&lt;/code&gt; (will have a ~17% performance impact on directory listings)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;e2tsr&lt;/code&gt; is probably always overkill, since &lt;code&gt;e2ds&lt;/code&gt;/&lt;code&gt;e2dsa&lt;/code&gt; would pick up any file modifications and &lt;code&gt;e2ts&lt;/code&gt; would then reindex those, unless there is a new copyparty version with new parsers and the release note says otherwise&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;config file example (these options are recommended btw):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;[global]
  e2dsa  # scan and index all files in all volumes on startup
  e2ts   # check newly-discovered or uploaded files for media tags
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;exclude-patterns&lt;/h3&gt; 
&lt;p&gt;to save some time, you can provide a regex pattern for filepaths to only index by filename/path/size/last-modified (and not the hash of the file contents) by setting &lt;code&gt;--no-hash '\.iso$'&lt;/code&gt; or the volflag &lt;code&gt;:c,nohash=\.iso$&lt;/code&gt;, this has the following consequences:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;initial indexing is way faster, especially when the volume is on a network disk&lt;/li&gt; 
 &lt;li&gt;makes it impossible to &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#file-search"&gt;file-search&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;if someone uploads the same file contents, the upload will not be detected as a dupe, so it will not get symlinked or rejected&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;similarly, you can fully ignore files/folders using &lt;code&gt;--no-idx [...]&lt;/code&gt; and &lt;code&gt;:c,noidx=\.iso$&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;NOTE: &lt;code&gt;no-idx&lt;/code&gt; and/or &lt;code&gt;no-hash&lt;/code&gt; prevents deduplication of those files&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;when running on macos, all the usual apple metadata files are excluded by default&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;if you set &lt;code&gt;--no-hash [...]&lt;/code&gt; globally, you can enable hashing for specific volumes using flag &lt;code&gt;:c,nohash=&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;to exclude certain filepaths from search-results, use &lt;code&gt;--srch-excl&lt;/code&gt; or volflag &lt;code&gt;srch_excl&lt;/code&gt; instead of &lt;code&gt;--no-idx&lt;/code&gt;, for example &lt;code&gt;--srch-excl 'password|logs/[0-9]'&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;config file example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;[/games]
  /mnt/nas/games
  flags:
    noidx: \.iso$  # skip indexing iso-files
    srch_excl: password|logs/[0-9]  # filter search results
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;filesystem guards&lt;/h3&gt; 
&lt;p&gt;avoid traversing into other filesystems using &lt;code&gt;--xdev&lt;/code&gt; / volflag &lt;code&gt;:c,xdev&lt;/code&gt;, skipping any symlinks or bind-mounts to another HDD for example&lt;/p&gt; 
&lt;p&gt;and/or you can &lt;code&gt;--xvol&lt;/code&gt; / &lt;code&gt;:c,xvol&lt;/code&gt; to ignore all symlinks leaving the volume's top directory, but still allow bind-mounts pointing elsewhere&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;symlinks are permitted with &lt;code&gt;xvol&lt;/code&gt; if they point into another volume where the user has the same level of access&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;these options will reduce performance; unlikely worst-case estimates are 14% reduction for directory listings, 35% for download-as-tar&lt;/p&gt; 
&lt;p&gt;as of copyparty v1.7.0 these options also prevent file access at runtime -- in previous versions it was just hints for the indexer&lt;/p&gt; 
&lt;h3&gt;periodic rescan&lt;/h3&gt; 
&lt;p&gt;filesystem monitoring; if copyparty is not the only software doing stuff on your filesystem, you may want to enable periodic rescans to keep the index up to date&lt;/p&gt; 
&lt;p&gt;argument &lt;code&gt;--re-maxage 60&lt;/code&gt; will rescan all volumes every 60 sec, same as volflag &lt;code&gt;:c,scan=60&lt;/code&gt; to specify it per-volume&lt;/p&gt; 
&lt;p&gt;uploads are disabled while a rescan is happening, so rescans will be delayed by &lt;code&gt;--db-act&lt;/code&gt; (default 10 sec) when there is write-activity going on (uploads, renames, ...)&lt;/p&gt; 
&lt;p&gt;note: folder-thumbnails are selected during filesystem indexing, so periodic rescans can be used to keep them accurate as images are uploaded/deleted (or manually do a rescan with the &lt;code&gt;reload&lt;/code&gt; button in the controlpanel)&lt;/p&gt; 
&lt;p&gt;config file example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;[global]
  re-maxage: 3600

[/pics]
  /mnt/nas/pics
  flags:
    scan: 900
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;upload rules&lt;/h2&gt; 
&lt;p&gt;set upload rules using volflags, some examples:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;:c,sz=1k-3m&lt;/code&gt; sets allowed filesize between 1 KiB and 3 MiB inclusive (suffixes: &lt;code&gt;b&lt;/code&gt;, &lt;code&gt;k&lt;/code&gt;, &lt;code&gt;m&lt;/code&gt;, &lt;code&gt;g&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;:c,df=4g&lt;/code&gt; block uploads if there would be less than 4 GiB free disk space afterwards&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;:c,vmaxb=1g&lt;/code&gt; block uploads if total volume size would exceed 1 GiB afterwards&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;:c,vmaxn=4k&lt;/code&gt; block uploads if volume would contain more than 4096 files afterwards&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;:c,nosub&lt;/code&gt; disallow uploading into subdirectories; goes well with &lt;code&gt;rotn&lt;/code&gt; and &lt;code&gt;rotf&lt;/code&gt;:&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;:c,rotn=1000,2&lt;/code&gt; moves uploads into subfolders, up to 1000 files in each folder before making a new one, two levels deep (must be at least 1)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;:c,rotf=%Y/%m/%d/%H&lt;/code&gt; enforces files to be uploaded into a structure of subfolders according to that date format 
  &lt;ul&gt; 
   &lt;li&gt;if someone uploads to &lt;code&gt;/foo/bar&lt;/code&gt; the path would be rewritten to &lt;code&gt;/foo/bar/2021/08/06/23&lt;/code&gt; for example&lt;/li&gt; 
   &lt;li&gt;but the actual value is not verified, just the structure, so the uploader can choose any values which conform to the format string 
    &lt;ul&gt; 
     &lt;li&gt;just to avoid additional complexity in up2k which is enough of a mess already&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;:c,lifetime=300&lt;/code&gt; delete uploaded files when they become 5 minutes old&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;you can also set transaction limits which apply per-IP and per-volume, but these assume &lt;code&gt;-j 1&lt;/code&gt; (default) otherwise the limits will be off, for example &lt;code&gt;-j 4&lt;/code&gt; would allow anywhere between 1x and 4x the limits you set depending on which processing node the client gets routed to&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;:c,maxn=250,3600&lt;/code&gt; allows 250 files over 1 hour from each IP (tracked per-volume)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;:c,maxb=1g,300&lt;/code&gt; allows 1 GiB total over 5 minutes from each IP (tracked per-volume)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;notes:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;vmaxb&lt;/code&gt; and &lt;code&gt;vmaxn&lt;/code&gt; requires either the &lt;code&gt;e2ds&lt;/code&gt; volflag or &lt;code&gt;-e2dsa&lt;/code&gt; global-option&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;config file example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;[/inc]
  /mnt/nas/uploads
  accs:
    w: *    # anyone can upload here
    rw: ed  # only user "ed" can read-write
  flags:
    e2ds       # filesystem indexing is required for many of these:
    sz: 1k-3m  # accept upload only if filesize in this range
    df: 4g     # free disk space cannot go lower than this
    vmaxb: 1g  # volume can never exceed 1 GiB
    vmaxn: 4k  # ...or 4000 files, whichever comes first
    nosub      # must upload to toplevel folder
    lifetime: 300   # uploads are deleted after 5min
    maxn: 250,3600  # each IP can upload 250 files in 1 hour
    maxb: 1g,300    # each IP can upload 1 GiB over 5 minutes
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;compress uploads&lt;/h2&gt; 
&lt;p&gt;files can be autocompressed on upload, either on user-request (if config allows) or forced by server-config&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;volflag &lt;code&gt;gz&lt;/code&gt; allows gz compression&lt;/li&gt; 
 &lt;li&gt;volflag &lt;code&gt;xz&lt;/code&gt; allows lzma compression&lt;/li&gt; 
 &lt;li&gt;volflag &lt;code&gt;pk&lt;/code&gt; &lt;strong&gt;forces&lt;/strong&gt; compression on all files&lt;/li&gt; 
 &lt;li&gt;url parameter &lt;code&gt;pk&lt;/code&gt; requests compression with server-default algorithm&lt;/li&gt; 
 &lt;li&gt;url parameter &lt;code&gt;gz&lt;/code&gt; or &lt;code&gt;xz&lt;/code&gt; requests compression with a specific algorithm&lt;/li&gt; 
 &lt;li&gt;url parameter &lt;code&gt;xz&lt;/code&gt; requests xz compression&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;things to note,&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;the &lt;code&gt;gz&lt;/code&gt; and &lt;code&gt;xz&lt;/code&gt; arguments take a single optional argument, the compression level (range 0 to 9)&lt;/li&gt; 
 &lt;li&gt;the &lt;code&gt;pk&lt;/code&gt; volflag takes the optional argument &lt;code&gt;ALGORITHM,LEVEL&lt;/code&gt; which will then be forced for all uploads, for example &lt;code&gt;gz,9&lt;/code&gt; or &lt;code&gt;xz,0&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;default compression is gzip level 9&lt;/li&gt; 
 &lt;li&gt;all upload methods except up2k are supported&lt;/li&gt; 
 &lt;li&gt;the files will be indexed after compression, so dupe-detection and file-search will not work as expected&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;some examples,&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;-v inc:inc:w:c,pk=xz,0&lt;/code&gt;&lt;br&gt; folder named inc, shared at inc, write-only for everyone, forces xz compression at level 0&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-v inc:inc:w:c,pk&lt;/code&gt;&lt;br&gt; same write-only inc, but forces gz compression (default) instead of xz&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-v inc:inc:w:c,gz&lt;/code&gt;&lt;br&gt; allows (but does not force) gz compression if client uploads to &lt;code&gt;/inc?pk&lt;/code&gt; or &lt;code&gt;/inc?gz&lt;/code&gt; or &lt;code&gt;/inc?gz=4&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;chmod and chown&lt;/h2&gt; 
&lt;p&gt;per-volume filesystem-permissions and ownership&lt;/p&gt; 
&lt;p&gt;by default:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;all folders are chmod 755&lt;/li&gt; 
 &lt;li&gt;files are usually chmod 644 (umask-defined)&lt;/li&gt; 
 &lt;li&gt;user/group is whatever copyparty is running as&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;this can be configured per-volume:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;volflag &lt;code&gt;chmod_f&lt;/code&gt; sets file permissions; default=&lt;code&gt;644&lt;/code&gt; (usually)&lt;/li&gt; 
 &lt;li&gt;volflag &lt;code&gt;chmod_d&lt;/code&gt; sets directory permissions; default=&lt;code&gt;755&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;volflag &lt;code&gt;uid&lt;/code&gt; sets the owner user-id&lt;/li&gt; 
 &lt;li&gt;volflag &lt;code&gt;gid&lt;/code&gt; sets the owner group-id&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;notes:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;gid&lt;/code&gt; can only be set to one of the groups which the copyparty process is a member of&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;uid&lt;/code&gt; can only be set if copyparty is running as root (i appreciate your faith)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;other flags&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;:c,magic&lt;/code&gt; enables filetype detection for nameless uploads, same as &lt;code&gt;--magic&lt;/code&gt; 
  &lt;ul&gt; 
   &lt;li&gt;needs &lt;a href="https://pypi.org/project/python-magic/"&gt;https://pypi.org/project/python-magic/&lt;/a&gt; &lt;code&gt;python3 -m pip install --user -U python-magic&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;on windows grab this instead &lt;code&gt;python3 -m pip install --user -U python-magic-bin&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;database location&lt;/h2&gt; 
&lt;p&gt;in-volume (&lt;code&gt;.hist/up2k.db&lt;/code&gt;, default) or somewhere else&lt;/p&gt; 
&lt;p&gt;copyparty creates a subfolder named &lt;code&gt;.hist&lt;/code&gt; inside each volume where it stores the database, thumbnails, and some other stuff&lt;/p&gt; 
&lt;p&gt;this can instead be kept in a single place using the &lt;code&gt;--hist&lt;/code&gt; argument, or the &lt;code&gt;hist=&lt;/code&gt; volflag, or a mix of both:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;--hist ~/.cache/copyparty -v ~/music::r:c,hist=-&lt;/code&gt; sets &lt;code&gt;~/.cache/copyparty&lt;/code&gt; as the default place to put volume info, but &lt;code&gt;~/music&lt;/code&gt; gets the regular &lt;code&gt;.hist&lt;/code&gt; subfolder (&lt;code&gt;-&lt;/code&gt; restores default behavior)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;by default, the per-volume &lt;code&gt;up2k.db&lt;/code&gt; sqlite3-database for &lt;code&gt;-e2d&lt;/code&gt; and &lt;code&gt;-e2t&lt;/code&gt; is stored next to the thumbnails according to the &lt;code&gt;--hist&lt;/code&gt; option, but the global-option &lt;code&gt;--dbpath&lt;/code&gt; and/or volflag &lt;code&gt;dbpath&lt;/code&gt; can be used to put the database somewhere else&lt;/p&gt; 
&lt;p&gt;if your storage backend is unreliable (NFS or bad HDDs), you can specify one or more "landmarks" to look for before doing anything database-related. A landmark is a file which is always expected to exist inside the volume. This avoids spurious filesystem rescans in the event of an outage. One line per landmark (see example below)&lt;/p&gt; 
&lt;p&gt;note:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;putting the hist-folders on an SSD is strongly recommended for performance&lt;/li&gt; 
 &lt;li&gt;markdown edits are always stored in a local &lt;code&gt;.hist&lt;/code&gt; subdirectory&lt;/li&gt; 
 &lt;li&gt;on windows the volflag path is cyglike, so &lt;code&gt;/c/temp&lt;/code&gt; means &lt;code&gt;C:\temp&lt;/code&gt; but use regular paths for &lt;code&gt;--hist&lt;/code&gt; 
  &lt;ul&gt; 
   &lt;li&gt;you can use cygpaths for volumes too, &lt;code&gt;-v C:\Users::r&lt;/code&gt; and &lt;code&gt;-v /c/users::r&lt;/code&gt; both work&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;config file example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;[global]
  hist: ~/.cache/copyparty  # put db/thumbs/etc. here by default

[/pics]
  /mnt/nas/pics
  flags:
    hist: -  # restore the default (/mnt/nas/pics/.hist/)
    hist: /mnt/nas/cache/pics/  # can be absolute path
    landmark: me.jpg  # /mnt/nas/pics/me.jpg must be readable to enable db
    landmark: info/a.txt^=ok  # and this textfile must start with "ok"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;metadata from audio files&lt;/h2&gt; 
&lt;p&gt;set &lt;code&gt;-e2t&lt;/code&gt; to index tags on upload&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;-mte&lt;/code&gt; decides which tags to index and display in the browser (and also the display order), this can be changed per-volume:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;-v ~/music::r:c,mte=title,artist&lt;/code&gt; indexes and displays &lt;em&gt;title&lt;/em&gt; followed by &lt;em&gt;artist&lt;/em&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;if you add/remove a tag from &lt;code&gt;mte&lt;/code&gt; you will need to run with &lt;code&gt;-e2tsr&lt;/code&gt; once to rebuild the database, otherwise only new files will be affected&lt;/p&gt; 
&lt;p&gt;but instead of using &lt;code&gt;-mte&lt;/code&gt;, &lt;code&gt;-mth&lt;/code&gt; is a better way to hide tags in the browser: these tags will not be displayed by default, but they still get indexed and become searchable, and users can choose to unhide them in the &lt;code&gt;[⚙️] config&lt;/code&gt; pane&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;-mtm&lt;/code&gt; can be used to add or redefine a metadata mapping, say you have media files with &lt;code&gt;foo&lt;/code&gt; and &lt;code&gt;bar&lt;/code&gt; tags and you want them to display as &lt;code&gt;qux&lt;/code&gt; in the browser (preferring &lt;code&gt;foo&lt;/code&gt; if both are present), then do &lt;code&gt;-mtm qux=foo,bar&lt;/code&gt; and now you can &lt;code&gt;-mte artist,title,qux&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;tags that start with a &lt;code&gt;.&lt;/code&gt; such as &lt;code&gt;.bpm&lt;/code&gt; and &lt;code&gt;.dur&lt;/code&gt;(ation) indicate numeric value&lt;/p&gt; 
&lt;p&gt;see the beautiful mess of a dictionary in &lt;a href="https://github.com/9001/copyparty/raw/hovudstraum/copyparty/mtag.py"&gt;mtag.py&lt;/a&gt; for the default mappings (should cover mp3,opus,flac,m4a,wav,aif,)&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;--no-mutagen&lt;/code&gt; disables Mutagen and uses FFprobe instead, which...&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;is about 20x slower than Mutagen&lt;/li&gt; 
 &lt;li&gt;catches a few tags that Mutagen doesn't 
  &lt;ul&gt; 
   &lt;li&gt;melodic key, video resolution, framerate, pixfmt&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;avoids pulling any GPL code into copyparty&lt;/li&gt; 
 &lt;li&gt;more importantly runs FFprobe on incoming files which is bad if your FFmpeg has a cve&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;code&gt;--mtag-to&lt;/code&gt; sets the tag-scan timeout; very high default (60 sec) to cater for zfs and other randomly-freezing filesystems. Lower values like 10 are usually safe, allowing for faster processing of tricky files&lt;/p&gt; 
&lt;h2&gt;file parser plugins&lt;/h2&gt; 
&lt;p&gt;provide custom parsers to index additional tags, also see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/bin/mtag/README.md"&gt;./bin/mtag/README.md&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;copyparty can invoke external programs to collect additional metadata for files using &lt;code&gt;mtp&lt;/code&gt; (either as argument or volflag), there is a default timeout of 60sec, and only files which contain audio get analyzed by default (see ay/an/ad below)&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;-mtp .bpm=~/bin/audio-bpm.py&lt;/code&gt; will execute &lt;code&gt;~/bin/audio-bpm.py&lt;/code&gt; with the audio file as argument 1 to provide the &lt;code&gt;.bpm&lt;/code&gt; tag, if that does not exist in the audio metadata&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-mtp key=f,t5,~/bin/audio-key.py&lt;/code&gt; uses &lt;code&gt;~/bin/audio-key.py&lt;/code&gt; to get the &lt;code&gt;key&lt;/code&gt; tag, replacing any existing metadata tag (&lt;code&gt;f,&lt;/code&gt;), aborting if it takes longer than 5sec (&lt;code&gt;t5,&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-v ~/music::r:c,mtp=.bpm=~/bin/audio-bpm.py:c,mtp=key=f,t5,~/bin/audio-key.py&lt;/code&gt; both as a per-volume config wow this is getting ugly&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;em&gt;but wait, there's more!&lt;/em&gt; &lt;code&gt;-mtp&lt;/code&gt; can be used for non-audio files as well using the &lt;code&gt;a&lt;/code&gt; flag: &lt;code&gt;ay&lt;/code&gt; only do audio files (default), &lt;code&gt;an&lt;/code&gt; only do non-audio files, or &lt;code&gt;ad&lt;/code&gt; do all files (d as in dontcare)&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;"audio file" also means videos btw, as long as there is an audio stream&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-mtp ext=an,~/bin/file-ext.py&lt;/code&gt; runs &lt;code&gt;~/bin/file-ext.py&lt;/code&gt; to get the &lt;code&gt;ext&lt;/code&gt; tag only if file is not audio (&lt;code&gt;an&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-mtp arch,built,ver,orig=an,eexe,edll,~/bin/exe.py&lt;/code&gt; runs &lt;code&gt;~/bin/exe.py&lt;/code&gt; to get properties about windows-binaries only if file is not audio (&lt;code&gt;an&lt;/code&gt;) and file extension is exe or dll&lt;/li&gt; 
 &lt;li&gt;if you want to daisychain parsers, use the &lt;code&gt;p&lt;/code&gt; flag to set processing order 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;-mtp foo=p1,~/a.py&lt;/code&gt; runs before &lt;code&gt;-mtp foo=p2,~/b.py&lt;/code&gt; and will forward all the tags detected so far as json to the stdin of b.py&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;option &lt;code&gt;c0&lt;/code&gt; disables capturing of stdout/stderr, so copyparty will not receive any tags from the process at all -- instead the invoked program is free to print whatever to the console, just using copyparty as a launcher 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;c1&lt;/code&gt; captures stdout only, &lt;code&gt;c2&lt;/code&gt; only stderr, and &lt;code&gt;c3&lt;/code&gt; (default) captures both&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;you can control how the parser is killed if it times out with option &lt;code&gt;kt&lt;/code&gt; killing the entire process tree (default), &lt;code&gt;km&lt;/code&gt; just the main process, or &lt;code&gt;kn&lt;/code&gt; let it continue running until copyparty is terminated&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;if something doesn't work, try &lt;code&gt;--mtag-v&lt;/code&gt; for verbose error messages&lt;/p&gt; 
&lt;p&gt;config file example; note that &lt;code&gt;mtp&lt;/code&gt; is an additive option so all of the mtp options will take effect:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;[/music]
  /mnt/nas/music
  flags:
    mtp: .bpm=~/bin/audio-bpm.py  # assign ".bpm" (numeric) with script
    mtp: key=f,t5,~/bin/audio-key.py  # force/overwrite, 5sec timeout
    mtp: ext=an,~/bin/file-ext.py  # will only run on non-audio files
    mtp: arch,built,ver,orig=an,eexe,edll,~/bin/exe.py  # only exe/dll
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;event hooks&lt;/h2&gt; 
&lt;p&gt;trigger a program on uploads, renames etc (&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/bin/hooks/"&gt;examples&lt;/a&gt;)&lt;/p&gt; 
&lt;p&gt;you can set hooks before and/or after an event happens, and currently you can hook uploads, moves/renames, and deletes&lt;/p&gt; 
&lt;p&gt;there's a bunch of flags and stuff, see &lt;code&gt;--help-hooks&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;if you want to write your own hooks, see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/docs/devnotes.md#event-hooks"&gt;devnotes&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;zeromq&lt;/h3&gt; 
&lt;p&gt;event-hooks can send zeromq messages instead of running programs&lt;/p&gt; 
&lt;p&gt;to send a 0mq message every time a file is uploaded,&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;--xau zmq:pub:tcp://*:5556&lt;/code&gt; sends a PUB to any/all connected SUB clients&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--xau t3,zmq:push:tcp://*:5557&lt;/code&gt; sends a PUSH to exactly one connected PULL client&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--xau t3,j,zmq:req:tcp://localhost:5555&lt;/code&gt; sends a REQ to the connected REP client&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;the PUSH and REQ examples have &lt;code&gt;t3&lt;/code&gt; (timeout after 3 seconds) because they block if there's no clients to talk to&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;the REQ example does &lt;code&gt;t3,j&lt;/code&gt; to send extended upload-info as json instead of just the filesystem-path&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;see &lt;a href="https://github.com/9001/copyparty/raw/hovudstraum/bin/zmq-recv.py"&gt;zmq-recv.py&lt;/a&gt; if you need something to receive the messages with&lt;/p&gt; 
&lt;p&gt;config file example; note that the hooks are additive options, so all of the xau options will take effect:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;[global]
  xau: zmq:pub:tcp://*:5556`  # send a PUB to any/all connected SUB clients
  xau: t3,zmq:push:tcp://*:5557`  # send PUSH to exactly one connected PULL cli
  xau: t3,j,zmq:req:tcp://localhost:5555`  # send REQ to the connected REP cli
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;upload events&lt;/h3&gt; 
&lt;p&gt;the older, more powerful approach (&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/bin/mtag/"&gt;examples&lt;/a&gt;):&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;-v /mnt/inc:inc:w:c,e2d,e2t,mte=+x1:c,mtp=x1=ad,kn,/usr/bin/notify-send
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;that was the commandline example; here's the config file example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;[/inc]
  /mnt/inc
  accs:
    w: *
  flags:
    e2d, e2t  # enable indexing of uploaded files and their tags
    mte: +x1
    mtp: x1=ad,kn,/usr/bin/notify-send
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;so filesystem location &lt;code&gt;/mnt/inc&lt;/code&gt; shared at &lt;code&gt;/inc&lt;/code&gt;, write-only for everyone, appending &lt;code&gt;x1&lt;/code&gt; to the list of tags to index (&lt;code&gt;mte&lt;/code&gt;), and using &lt;code&gt;/usr/bin/notify-send&lt;/code&gt; to "provide" tag &lt;code&gt;x1&lt;/code&gt; for any filetype (&lt;code&gt;ad&lt;/code&gt;) with kill-on-timeout disabled (&lt;code&gt;kn&lt;/code&gt;)&lt;/p&gt; 
&lt;p&gt;that'll run the command &lt;code&gt;notify-send&lt;/code&gt; with the path to the uploaded file as the first and only argument (so on linux it'll show a notification on-screen)&lt;/p&gt; 
&lt;p&gt;note that this is way more complicated than the new &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#event-hooks"&gt;event hooks&lt;/a&gt; but this approach has the following advantages:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;non-blocking and multithreaded; doesn't hold other uploads back&lt;/li&gt; 
 &lt;li&gt;you get access to tags from FFmpeg and other mtp parsers&lt;/li&gt; 
 &lt;li&gt;only trigger on new unique files, not dupes&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;note that it will occupy the parsing threads, so fork anything expensive (or set &lt;code&gt;kn&lt;/code&gt; to have copyparty fork it for you) -- otoh if you want to intentionally queue/singlethread you can combine it with &lt;code&gt;--mtag-mt 1&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;for reference, if you were to do this using event hooks instead, it would be like this: &lt;code&gt;-e2d --xau notify-send,hello,--&lt;/code&gt;&lt;/p&gt; 
&lt;h2&gt;handlers&lt;/h2&gt; 
&lt;p&gt;redefine behavior with plugins (&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/bin/handlers/"&gt;examples&lt;/a&gt;)&lt;/p&gt; 
&lt;p&gt;replace 404 and 403 errors with something completely different (that's it for now)&lt;/p&gt; 
&lt;p&gt;as for client-side stuff, there is &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/contrib/plugins/"&gt;plugins for modifying UI/UX&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;ip auth&lt;/h2&gt; 
&lt;p&gt;autologin based on IP range (CIDR) , using the global-option &lt;code&gt;--ipu&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;for example, if everyone with an IP that starts with &lt;code&gt;192.168.123&lt;/code&gt; should automatically log in as the user &lt;code&gt;spartacus&lt;/code&gt;, then you can either specify &lt;code&gt;--ipu=192.168.123.0/24=spartacus&lt;/code&gt; as a commandline option, or put this in a config file:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;[global]
  ipu: 192.168.123.0/24=spartacus
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;repeat the option to map additional subnets&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;be careful with this one!&lt;/strong&gt; if you have a reverseproxy, then you definitely want to make sure you have &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#real-ip"&gt;real-ip&lt;/a&gt; configured correctly, and it's probably a good idea to nullmap the reverseproxy's IP just in case; so if your reverseproxy is sending requests from &lt;code&gt;172.24.27.9&lt;/code&gt; then that would be &lt;code&gt;--ipu=172.24.27.9/32=&lt;/code&gt;&lt;/p&gt; 
&lt;h2&gt;identity providers&lt;/h2&gt; 
&lt;p&gt;replace copyparty passwords with oauth and such&lt;/p&gt; 
&lt;p&gt;you can disable the built-in password-based login system, and instead replace it with a separate piece of software (an identity provider) which will then handle authenticating / authorizing of users; this makes it possible to login with passkeys / fido2 / webauthn / yubikey / ldap / active directory / oauth / many other single-sign-on contraptions&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;the regular config-defined users will be used as a fallback for requests which don't include a valid (trusted) IdP username header&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;some popular identity providers are &lt;a href="https://www.authelia.com/"&gt;Authelia&lt;/a&gt; (config-file based) and &lt;a href="https://goauthentik.io/"&gt;authentik&lt;/a&gt; (GUI-based, more complex)&lt;/p&gt; 
&lt;p&gt;there is a &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/docs/examples/docker/idp-authelia-traefik"&gt;docker-compose example&lt;/a&gt; which is hopefully a good starting point (alternatively see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/docs/idp.md"&gt;./docs/idp.md&lt;/a&gt; if you're the DIY type)&lt;/p&gt; 
&lt;p&gt;a more complete example of the copyparty configuration options &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/docs/examples/docker/idp/copyparty.conf"&gt;look like this&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;but if you just want to let users change their own passwords, then you probably want &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#user-changeable-passwords"&gt;user-changeable passwords&lt;/a&gt; instead&lt;/p&gt; 
&lt;h2&gt;user-changeable passwords&lt;/h2&gt; 
&lt;p&gt;if permitted, users can change their own passwords in the control-panel&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;not compatible with &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#identity-providers"&gt;identity providers&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;must be enabled with &lt;code&gt;--chpw&lt;/code&gt; because account-sharing is a popular usecase&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;if you want to enable the feature but deny password-changing for a specific list of accounts, you can do that with &lt;code&gt;--chpw-no name1,name2,name3,...&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;to perform a password reset, edit the server config and give the user another password there, then do a &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#server-config"&gt;config reload&lt;/a&gt; or server restart&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;the custom passwords are kept in a textfile at filesystem-path &lt;code&gt;--chpw-db&lt;/code&gt;, by default &lt;code&gt;chpw.json&lt;/code&gt; in the copyparty config folder&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;if you run multiple copyparty instances with different users you &lt;em&gt;almost definitely&lt;/em&gt; want to specify separate DBs for each instance&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;if &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#password-hashing"&gt;password hashing&lt;/a&gt; is enabled, the passwords in the db are also hashed&lt;/p&gt; 
    &lt;ul&gt; 
     &lt;li&gt;...which means that all user-defined passwords will be forgotten if you change password-hashing settings&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;using the cloud as storage&lt;/h2&gt; 
&lt;p&gt;connecting to an aws s3 bucket and similar&lt;/p&gt; 
&lt;p&gt;there is no built-in support for this, but you can use FUSE-software such as &lt;a href="https://rclone.org/"&gt;rclone&lt;/a&gt; / &lt;a href="https://github.com/yandex-cloud/geesefs"&gt;geesefs&lt;/a&gt; / &lt;a href="https://juicefs.com/en/"&gt;JuiceFS&lt;/a&gt; to first mount your cloud storage as a local disk, and then let copyparty use (a folder in) that disk as a volume&lt;/p&gt; 
&lt;p&gt;if copyparty is unable to access the local folder that rclone/geesefs/JuiceFS provides (for example if it looks invisible) then you may need to run rclone with &lt;code&gt;--allow-other&lt;/code&gt; and/or enable &lt;code&gt;user_allow_other&lt;/code&gt; in &lt;code&gt;/etc/fuse.conf&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;you will probably get decent speeds with the default config, however most likely restricted to using one TCP connection per file, so the upload-client won't be able to send multiple chunks in parallel&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;before &lt;a href="https://github.com/9001/copyparty/releases/tag/v1.13.5"&gt;v1.13.5&lt;/a&gt; it was recommended to use the volflag &lt;code&gt;sparse&lt;/code&gt; to force-allow multiple chunks in parallel; this would improve the upload-speed from &lt;code&gt;1.5 MiB/s&lt;/code&gt; to over &lt;code&gt;80 MiB/s&lt;/code&gt; at the risk of provoking latent bugs in S3 or JuiceFS. But v1.13.5 added chunk-stitching, so this is now probably much less important. On the contrary, &lt;code&gt;nosparse&lt;/code&gt; &lt;em&gt;may&lt;/em&gt; now increase performance in some cases. Please try all three options (default, &lt;code&gt;sparse&lt;/code&gt;, &lt;code&gt;nosparse&lt;/code&gt;) as the optimal choice depends on your network conditions and software stack (both the FUSE-driver and cloud-server)&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;someone has also tested geesefs in combination with &lt;a href="https://nuetzlich.net/gocryptfs/"&gt;gocryptfs&lt;/a&gt; with surprisingly good results, getting 60 MiB/s upload speeds on a gbit line, but JuiceFS won with 80 MiB/s using its built-in encryption&lt;/p&gt; 
&lt;p&gt;you may improve performance by specifying larger values for &lt;code&gt;--iobuf&lt;/code&gt; / &lt;code&gt;--s-rd-sz&lt;/code&gt; / &lt;code&gt;--s-wr-sz&lt;/code&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;if you've experimented with this and made interesting observations, please share your findings so we can add a section with specific recommendations :-)&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;hiding from google&lt;/h2&gt; 
&lt;p&gt;tell search engines you don't wanna be indexed, either using the good old &lt;a href="https://www.robotstxt.org/robotstxt.html"&gt;robots.txt&lt;/a&gt; or through copyparty settings:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;--no-robots&lt;/code&gt; adds HTTP (&lt;code&gt;X-Robots-Tag&lt;/code&gt;) and HTML (&lt;code&gt;&amp;lt;meta&amp;gt;&lt;/code&gt;) headers with &lt;code&gt;noindex, nofollow&lt;/code&gt; globally&lt;/li&gt; 
 &lt;li&gt;volflag &lt;code&gt;[...]:c,norobots&lt;/code&gt; does the same thing for that single volume&lt;/li&gt; 
 &lt;li&gt;volflag &lt;code&gt;[...]:c,robots&lt;/code&gt; ALLOWS search-engine crawling for that volume, even if &lt;code&gt;--no-robots&lt;/code&gt; is set globally&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;also, &lt;code&gt;--force-js&lt;/code&gt; disables the plain HTML folder listing, making things harder to parse for &lt;em&gt;some&lt;/em&gt; search engines -- note that crawlers which understand javascript (such as google) will not be affected&lt;/p&gt; 
&lt;h2&gt;themes&lt;/h2&gt; 
&lt;p&gt;you can change the default theme with &lt;code&gt;--theme 2&lt;/code&gt;, and add your own themes by modifying &lt;code&gt;browser.css&lt;/code&gt; or providing your own css to &lt;code&gt;--css-browser&lt;/code&gt;, then telling copyparty they exist by increasing &lt;code&gt;--themes&lt;/code&gt;&lt;/p&gt; 
&lt;table&gt;
 &lt;tbody&gt;
  &lt;tr&gt;
   &lt;td width="33%" align="center"&gt;&lt;a href="https://user-images.githubusercontent.com/241032/165864907-17e2ac7d-319d-4f25-8718-2f376f614b51.png"&gt;&lt;img src="https://user-images.githubusercontent.com/241032/165867551-fceb35dd-38f0-42bb-bef3-25ba651ca69b.png"&gt;&lt;/a&gt; 0. classic dark&lt;/td&gt;
   &lt;td width="33%" align="center"&gt;&lt;a href="https://user-images.githubusercontent.com/241032/168644399-68938de5-da9b-445f-8d92-b51c74b5f345.png"&gt;&lt;img src="https://user-images.githubusercontent.com/241032/168644404-8e1a2fdc-6e59-4c41-905e-ba5399ed686f.png"&gt;&lt;/a&gt; 2. flat pm-monokai&lt;/td&gt;
   &lt;td width="33%" align="center"&gt;&lt;a href="https://user-images.githubusercontent.com/241032/165864901-db13a429-a5da-496d-8bc6-ce838547f69d.png"&gt;&lt;img src="https://user-images.githubusercontent.com/241032/165867560-aa834aef-58dc-4abe-baef-7e562b647945.png"&gt;&lt;/a&gt; 4. vice&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td align="center"&gt;&lt;a href="https://user-images.githubusercontent.com/241032/165864905-692682eb-6fb4-4d40-b6fe-27d2c7d3e2a7.png"&gt;&lt;img src="https://user-images.githubusercontent.com/241032/165867555-080b73b6-6d85-41bb-a7c6-ad277c608365.png"&gt;&lt;/a&gt; 1. classic light&lt;/td&gt;
   &lt;td align="center"&gt;&lt;a href="https://user-images.githubusercontent.com/241032/168645276-fb02fd19-190a-407a-b8d3-d58fee277e02.png"&gt;&lt;img src="https://user-images.githubusercontent.com/241032/168645280-f0662b3c-9764-4875-a2e2-d91cc8199b23.png"&gt;&lt;/a&gt; 3. flat light &lt;/td&gt;
   &lt;td align="center"&gt;&lt;a href="https://user-images.githubusercontent.com/241032/165864898-10ce7052-a117-4fcf-845b-b56c91687908.png"&gt;&lt;img src="https://user-images.githubusercontent.com/241032/165867562-f3003d45-dd2a-4564-8aae-fed44c1ae064.png"&gt;&lt;/a&gt; 5. &lt;a href="https://blog.codinghorror.com/a-tribute-to-the-windows-31-hot-dog-stand-color-scheme/"&gt;hotdog stand&lt;/a&gt;&lt;/td&gt;
  &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;p&gt;the classname of the HTML tag is set according to the selected theme, which is used to set colors as css variables ++&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;each theme &lt;em&gt;generally&lt;/em&gt; has a dark theme (even numbers) and a light theme (odd numbers), showing in pairs&lt;/li&gt; 
 &lt;li&gt;the first theme (theme 0 and 1) is &lt;code&gt;html.a&lt;/code&gt;, second theme (2 and 3) is &lt;code&gt;html.b&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;if a light theme is selected, &lt;code&gt;html.y&lt;/code&gt; is set, otherwise &lt;code&gt;html.z&lt;/code&gt; is&lt;/li&gt; 
 &lt;li&gt;so if the dark edition of the 2nd theme is selected, you use any of &lt;code&gt;html.b&lt;/code&gt;, &lt;code&gt;html.z&lt;/code&gt;, &lt;code&gt;html.bz&lt;/code&gt; to specify rules&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;see the top of &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/copyparty/web/browser.css"&gt;./copyparty/web/browser.css&lt;/a&gt; where the color variables are set, and there's layout-specific stuff near the bottom&lt;/p&gt; 
&lt;p&gt;if you want to change the fonts, see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/docs/rice/"&gt;./docs/rice/&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;complete examples&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/docs/examples/windows.md"&gt;running on windows&lt;/a&gt; for a fancy windows setup&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;or use any of the examples below, just replace &lt;code&gt;python copyparty-sfx.py&lt;/code&gt; with &lt;code&gt;copyparty.exe&lt;/code&gt; if you're using the exe edition&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;allow anyone to download or upload files into the current folder:&lt;br&gt; &lt;code&gt;python copyparty-sfx.py&lt;/code&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;enable searching and music indexing with &lt;code&gt;-e2dsa -e2ts&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;start an FTP server on port 3921 with &lt;code&gt;--ftp 3921&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;announce it on your LAN with &lt;code&gt;-z&lt;/code&gt; so it appears in windows/Linux file managers&lt;/p&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;anyone can upload, but nobody can see any files (even the uploader):&lt;br&gt; &lt;code&gt;python copyparty-sfx.py -e2dsa -v .::w&lt;/code&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;block uploads if there's less than 4 GiB free disk space with &lt;code&gt;--df 4&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;show a popup on new uploads with &lt;code&gt;--xau bin/hooks/notify.py&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;anyone can upload, and receive "secret" links for each upload they do:&lt;br&gt; &lt;code&gt;python copyparty-sfx.py -e2dsa -v .::wG:c,fk=8&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;anyone can browse (&lt;code&gt;r&lt;/code&gt;), only &lt;code&gt;kevin&lt;/code&gt; (password &lt;code&gt;okgo&lt;/code&gt;) can upload/move/delete (&lt;code&gt;A&lt;/code&gt;) files:&lt;br&gt; &lt;code&gt;python copyparty-sfx.py -e2dsa -a kevin:okgo -v .::r:A,kevin&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;read-only music server:&lt;br&gt; &lt;code&gt;python copyparty-sfx.py -v /mnt/nas/music:/music:r -e2dsa -e2ts --no-robots --force-js --theme 2&lt;/code&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;...with bpm and key scanning&lt;br&gt; &lt;code&gt;-mtp .bpm=f,audio-bpm.py -mtp key=f,audio-key.py&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;...with a read-write folder for &lt;code&gt;kevin&lt;/code&gt; whose password is &lt;code&gt;okgo&lt;/code&gt;&lt;br&gt; &lt;code&gt;-a kevin:okgo -v /mnt/nas/inc:/inc:rw,kevin&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;...with logging to disk&lt;br&gt; &lt;code&gt;-lo log/cpp-%Y-%m%d-%H%M%S.txt.xz&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;listen on port 80 and 443&lt;/h2&gt; 
&lt;p&gt;become a &lt;em&gt;real&lt;/em&gt; webserver which people can access by just going to your IP or domain without specifying a port&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;if you're on windows,&lt;/strong&gt; then you just need to add the commandline argument &lt;code&gt;-p 80,443&lt;/code&gt; and you're done! nice&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;if you're on macos,&lt;/strong&gt; sorry, I don't know&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;if you're on Linux,&lt;/strong&gt; you have the following 4 options:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;option 1:&lt;/strong&gt; set up a &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#reverse-proxy"&gt;reverse-proxy&lt;/a&gt; -- this one makes a lot of sense if you're running on a proper headless server, because that way you get real HTTPS too&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;option 2:&lt;/strong&gt; NAT to port 3923 -- this is cumbersome since you'll need to do it every time you reboot, and the exact command may depend on your linux distribution:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;iptables -t nat -A PREROUTING -p tcp --dport 80 -j REDIRECT --to-port 3923
iptables -t nat -A PREROUTING -p tcp --dport 443 -j REDIRECT --to-port 3923
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;option 3:&lt;/strong&gt; disable the &lt;a href="https://www.w3.org/Daemon/User/Installation/PrivilegedPorts.html"&gt;security policy&lt;/a&gt; which prevents the use of 80 and 443; this is &lt;em&gt;probably&lt;/em&gt; fine:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;setcap CAP_NET_BIND_SERVICE=+eip $(realpath $(which python))
python copyparty-sfx.py -p 80,443
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;option 4:&lt;/strong&gt; run copyparty as root (please don't)&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;reverse-proxy&lt;/h2&gt; 
&lt;p&gt;running copyparty next to other websites hosted on an existing webserver such as nginx, caddy, or apache&lt;/p&gt; 
&lt;p&gt;you can either:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;give copyparty its own domain or subdomain (recommended)&lt;/li&gt; 
 &lt;li&gt;or do location-based proxying, using &lt;code&gt;--rp-loc=/stuff&lt;/code&gt; to tell copyparty where it is mounted -- has a slight performance cost and higher chance of bugs 
  &lt;ul&gt; 
   &lt;li&gt;if copyparty says &lt;code&gt;incorrect --rp-loc or webserver config; expected vpath starting with [...]&lt;/code&gt; it's likely because the webserver is stripping away the proxy location from the request URLs -- see the &lt;code&gt;ProxyPass&lt;/code&gt; in the apache example below&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;when running behind a reverse-proxy (this includes services like cloudflare), it is important to configure real-ip correctly, as many features rely on knowing the client's IP. Look out for red and yellow log messages which explain how to do this. But basically, set &lt;code&gt;--xff-hdr&lt;/code&gt; to the name of the http header to read the IP from (usually &lt;code&gt;x-forwarded-for&lt;/code&gt;, but cloudflare uses &lt;code&gt;cf-connecting-ip&lt;/code&gt;), and then &lt;code&gt;--xff-src&lt;/code&gt; to the IP of the reverse-proxy so copyparty will trust the xff-hdr. Note that &lt;code&gt;--rp-loc&lt;/code&gt; in particular will not work at all unless you do this&lt;/p&gt; 
&lt;p&gt;some reverse proxies (such as &lt;a href="https://caddyserver.com/"&gt;Caddy&lt;/a&gt;) can automatically obtain a valid https/tls certificate for you, and some support HTTP/2 and QUIC which &lt;em&gt;could&lt;/em&gt; be a nice speed boost, depending on a lot of factors&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;warning:&lt;/strong&gt; nginx-QUIC (HTTP/3) is still experimental and can make uploads much slower, so HTTP/1.1 is recommended for now&lt;/li&gt; 
 &lt;li&gt;depending on server/client, HTTP/1.1 can also be 5x faster than HTTP/2&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;for improved security (and a 10% performance boost) consider listening on a unix-socket with &lt;code&gt;-i unix:770:www:/dev/shm/party.sock&lt;/code&gt; (permission &lt;code&gt;770&lt;/code&gt; means only members of group &lt;code&gt;www&lt;/code&gt; can access it)&lt;/p&gt; 
&lt;p&gt;example webserver / reverse-proxy configs:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/contrib/apache/copyparty.conf"&gt;apache config&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;caddy uds: &lt;code&gt;caddy reverse-proxy --from :8080 --to unix///dev/shm/party.sock&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;caddy tcp: &lt;code&gt;caddy reverse-proxy --from :8081 --to http://127.0.0.1:3923&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/contrib/haproxy/copyparty.conf"&gt;haproxy config&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/contrib/lighttpd/subdomain.conf"&gt;lighttpd subdomain&lt;/a&gt; -- entire domain/subdomain&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/contrib/lighttpd/subpath.conf"&gt;lighttpd subpath&lt;/a&gt; -- location-based (not optimal, but in case you need it)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/contrib/nginx/copyparty.conf"&gt;nginx config&lt;/a&gt; -- recommended&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/contrib/traefik/copyparty.yaml"&gt;traefik config&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;real-ip&lt;/h3&gt; 
&lt;p&gt;teaching copyparty how to see client IPs when running behind a reverse-proxy, or a WAF, or another protection service such as cloudflare&lt;/p&gt; 
&lt;p&gt;if you (and maybe everybody else) keep getting a message that says &lt;code&gt;thank you for playing&lt;/code&gt;, then you've gotten banned for malicious traffic. This ban applies to the IP address that copyparty &lt;em&gt;thinks&lt;/em&gt; identifies the shady client -- so, depending on your setup, you might have to tell copyparty where to find the correct IP&lt;/p&gt; 
&lt;p&gt;for most common setups, there should be a helpful message in the server-log explaining what to do, but see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/docs/xff.md"&gt;docs/xff.md&lt;/a&gt; if you want to learn more, including a quick hack to &lt;strong&gt;just make it work&lt;/strong&gt; (which is &lt;strong&gt;not&lt;/strong&gt; recommended, but hey...)&lt;/p&gt; 
&lt;h3&gt;reverse-proxy performance&lt;/h3&gt; 
&lt;p&gt;most reverse-proxies support connecting to copyparty either using uds/unix-sockets (&lt;code&gt;/dev/shm/party.sock&lt;/code&gt;, faster/recommended) or using tcp (&lt;code&gt;127.0.0.1&lt;/code&gt;)&lt;/p&gt; 
&lt;p&gt;with copyparty listening on a uds / unix-socket / unix-domain-socket and the reverse-proxy connecting to that:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;index.html&lt;/th&gt; 
   &lt;th&gt;upload&lt;/th&gt; 
   &lt;th&gt;download&lt;/th&gt; 
   &lt;th&gt;software&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;28'900 req/s&lt;/td&gt; 
   &lt;td&gt;6'900 MiB/s&lt;/td&gt; 
   &lt;td&gt;7'400 MiB/s&lt;/td&gt; 
   &lt;td&gt;no-proxy&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;18'750 req/s&lt;/td&gt; 
   &lt;td&gt;3'500 MiB/s&lt;/td&gt; 
   &lt;td&gt;2'370 MiB/s&lt;/td&gt; 
   &lt;td&gt;haproxy&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;9'900 req/s&lt;/td&gt; 
   &lt;td&gt;3'750 MiB/s&lt;/td&gt; 
   &lt;td&gt;2'200 MiB/s&lt;/td&gt; 
   &lt;td&gt;caddy&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;18'700 req/s&lt;/td&gt; 
   &lt;td&gt;2'200 MiB/s&lt;/td&gt; 
   &lt;td&gt;1'570 MiB/s&lt;/td&gt; 
   &lt;td&gt;nginx&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;9'700 req/s&lt;/td&gt; 
   &lt;td&gt;1'750 MiB/s&lt;/td&gt; 
   &lt;td&gt;1'830 MiB/s&lt;/td&gt; 
   &lt;td&gt;apache&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;9'900 req/s&lt;/td&gt; 
   &lt;td&gt;1'300 MiB/s&lt;/td&gt; 
   &lt;td&gt;1'470 MiB/s&lt;/td&gt; 
   &lt;td&gt;lighttpd&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;when connecting the reverse-proxy to &lt;code&gt;127.0.0.1&lt;/code&gt; instead (the basic and/or old-fasioned way), speeds are a bit worse:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;index.html&lt;/th&gt; 
   &lt;th&gt;upload&lt;/th&gt; 
   &lt;th&gt;download&lt;/th&gt; 
   &lt;th&gt;software&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;21'200 req/s&lt;/td&gt; 
   &lt;td&gt;5'700 MiB/s&lt;/td&gt; 
   &lt;td&gt;6'700 MiB/s&lt;/td&gt; 
   &lt;td&gt;no-proxy&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;14'500 req/s&lt;/td&gt; 
   &lt;td&gt;1'700 MiB/s&lt;/td&gt; 
   &lt;td&gt;2'170 MiB/s&lt;/td&gt; 
   &lt;td&gt;haproxy&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;11'100 req/s&lt;/td&gt; 
   &lt;td&gt;2'750 MiB/s&lt;/td&gt; 
   &lt;td&gt;2'000 MiB/s&lt;/td&gt; 
   &lt;td&gt;traefik&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;8'400 req/s&lt;/td&gt; 
   &lt;td&gt;2'300 MiB/s&lt;/td&gt; 
   &lt;td&gt;1'950 MiB/s&lt;/td&gt; 
   &lt;td&gt;caddy&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;13'400 req/s&lt;/td&gt; 
   &lt;td&gt;1'100 MiB/s&lt;/td&gt; 
   &lt;td&gt;1'480 MiB/s&lt;/td&gt; 
   &lt;td&gt;nginx&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;8'400 req/s&lt;/td&gt; 
   &lt;td&gt;1'000 MiB/s&lt;/td&gt; 
   &lt;td&gt;1'000 MiB/s&lt;/td&gt; 
   &lt;td&gt;apache&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;6'500 req/s&lt;/td&gt; 
   &lt;td&gt;1'270 MiB/s&lt;/td&gt; 
   &lt;td&gt;1'500 MiB/s&lt;/td&gt; 
   &lt;td&gt;lighttpd&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;in summary, &lt;code&gt;haproxy &amp;gt; caddy &amp;gt; traefik &amp;gt; nginx &amp;gt; apache &amp;gt; lighttpd&lt;/code&gt;, and use uds when possible (traefik does not support it yet)&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;if these results are bullshit because my config exampels are bad, please submit corrections!&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;permanent cloudflare tunnel&lt;/h2&gt; 
&lt;p&gt;if you have a domain and want to get your copyparty online real quick, either from your home-PC behind a CGNAT or from a server without an existing &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#reverse-proxy"&gt;reverse-proxy&lt;/a&gt; setup, one approach is to create a &lt;a href="https://developers.cloudflare.com/cloudflare-one/connections/connect-networks/get-started/"&gt;Cloudflare Tunnel&lt;/a&gt; (formerly "Argo Tunnel")&lt;/p&gt; 
&lt;p&gt;I'd recommend making a &lt;code&gt;Locally-managed tunnel&lt;/code&gt; for more control, but if you prefer to make a &lt;code&gt;Remotely-managed tunnel&lt;/code&gt; then this is currently how:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;cloudflare dashboard&lt;/code&gt; » &lt;code&gt;zero trust&lt;/code&gt; » &lt;code&gt;networks&lt;/code&gt; » &lt;code&gt;tunnels&lt;/code&gt; » &lt;code&gt;create a tunnel&lt;/code&gt; » &lt;code&gt;cloudflared&lt;/code&gt; » choose a cool &lt;code&gt;subdomain&lt;/code&gt; and leave the &lt;code&gt;path&lt;/code&gt; blank, and use &lt;code&gt;service type&lt;/code&gt; = &lt;code&gt;http&lt;/code&gt; and &lt;code&gt;URL&lt;/code&gt; = &lt;code&gt;127.0.0.1:3923&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;and if you want to just run the tunnel without installing it, skip the &lt;code&gt;cloudflared service install BASE64&lt;/code&gt; step and instead do &lt;code&gt;cloudflared --no-autoupdate tunnel run --token BASE64&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;NOTE: since people will be connecting through cloudflare, as mentioned in &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#real-ip"&gt;real-ip&lt;/a&gt; you should run copyparty with &lt;code&gt;--xff-hdr cf-connecting-ip&lt;/code&gt; to detect client IPs correctly&lt;/p&gt; 
&lt;p&gt;config file example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;[global]
  xff-hdr: cf-connecting-ip
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;prometheus&lt;/h2&gt; 
&lt;p&gt;metrics/stats can be enabled at URL &lt;code&gt;/.cpr/metrics&lt;/code&gt; for grafana / prometheus / etc (openmetrics 1.0.0)&lt;/p&gt; 
&lt;p&gt;must be enabled with &lt;code&gt;--stats&lt;/code&gt; since it reduces startup time a tiny bit, and you probably want &lt;code&gt;-e2dsa&lt;/code&gt; too&lt;/p&gt; 
&lt;p&gt;the endpoint is only accessible by &lt;code&gt;admin&lt;/code&gt; accounts, meaning the &lt;code&gt;a&lt;/code&gt; in &lt;code&gt;rwmda&lt;/code&gt; in the following example commandline: &lt;code&gt;python3 -m copyparty -a ed:wark -v /mnt/nas::rwmda,ed --stats -e2dsa&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;follow a guide for setting up &lt;code&gt;node_exporter&lt;/code&gt; except have it read from copyparty instead; example &lt;code&gt;/etc/prometheus/prometheus.yml&lt;/code&gt; below&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;scrape_configs:
  - job_name: copyparty
    metrics_path: /.cpr/metrics
    basic_auth:
      password: wark
    static_configs:
      - targets: ['192.168.123.1:3923']
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;currently the following metrics are available,&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;cpp_uptime_seconds&lt;/code&gt; time since last copyparty restart&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;cpp_boot_unixtime_seconds&lt;/code&gt; same but as an absolute timestamp&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;cpp_active_dl&lt;/code&gt; number of active downloads&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;cpp_http_conns&lt;/code&gt; number of open http(s) connections&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;cpp_http_reqs&lt;/code&gt; number of http(s) requests handled&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;cpp_sus_reqs&lt;/code&gt; number of 403/422/malicious requests&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;cpp_active_bans&lt;/code&gt; number of currently banned IPs&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;cpp_total_bans&lt;/code&gt; number of IPs banned since last restart&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;these are available unless &lt;code&gt;--nos-vst&lt;/code&gt; is specified:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;cpp_db_idle_seconds&lt;/code&gt; time since last database activity (upload/rename/delete)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;cpp_db_act_seconds&lt;/code&gt; same but as an absolute timestamp&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;cpp_idle_vols&lt;/code&gt; number of volumes which are idle / ready&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;cpp_busy_vols&lt;/code&gt; number of volumes which are busy / indexing&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;cpp_offline_vols&lt;/code&gt; number of volumes which are offline / unavailable&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;cpp_hashing_files&lt;/code&gt; number of files queued for hashing / indexing&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;cpp_tagq_files&lt;/code&gt; number of files queued for metadata scanning&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;cpp_mtpq_files&lt;/code&gt; number of files queued for plugin-based analysis&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;and these are available per-volume only:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;cpp_disk_size_bytes&lt;/code&gt; total HDD size&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;cpp_disk_free_bytes&lt;/code&gt; free HDD space&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;and these are per-volume and &lt;code&gt;total&lt;/code&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;cpp_vol_bytes&lt;/code&gt; size of all files in volume&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;cpp_vol_files&lt;/code&gt; number of files&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;cpp_dupe_bytes&lt;/code&gt; disk space presumably saved by deduplication&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;cpp_dupe_files&lt;/code&gt; number of dupe files&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;cpp_unf_bytes&lt;/code&gt; currently unfinished / incoming uploads&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;some of the metrics have additional requirements to function correctly,&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;cpp_vol_*&lt;/code&gt; requires either the &lt;code&gt;e2ds&lt;/code&gt; volflag or &lt;code&gt;-e2dsa&lt;/code&gt; global-option&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;the following options are available to disable some of the metrics:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;--nos-hdd&lt;/code&gt; disables &lt;code&gt;cpp_disk_*&lt;/code&gt; which can prevent spinning up HDDs&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--nos-vol&lt;/code&gt; disables &lt;code&gt;cpp_vol_*&lt;/code&gt; which reduces server startup time&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--nos-vst&lt;/code&gt; disables volume state, reducing the worst-case prometheus query time by 0.5 sec&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--nos-dup&lt;/code&gt; disables &lt;code&gt;cpp_dupe_*&lt;/code&gt; which reduces the server load caused by prometheus queries&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--nos-unf&lt;/code&gt; disables &lt;code&gt;cpp_unf_*&lt;/code&gt; for no particular purpose&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;note: the following metrics are counted incorrectly if multiprocessing is enabled with &lt;code&gt;-j&lt;/code&gt;: &lt;code&gt;cpp_http_conns&lt;/code&gt;, &lt;code&gt;cpp_http_reqs&lt;/code&gt;, &lt;code&gt;cpp_sus_reqs&lt;/code&gt;, &lt;code&gt;cpp_active_bans&lt;/code&gt;, &lt;code&gt;cpp_total_bans&lt;/code&gt;&lt;/p&gt; 
&lt;h2&gt;other extremely specific features&lt;/h2&gt; 
&lt;p&gt;you'll never find a use for these:&lt;/p&gt; 
&lt;h3&gt;custom mimetypes&lt;/h3&gt; 
&lt;p&gt;change the association of a file extension&lt;/p&gt; 
&lt;p&gt;using commandline args, you can do something like &lt;code&gt;--mime gif=image/jif&lt;/code&gt; and &lt;code&gt;--mime ts=text/x.typescript&lt;/code&gt; (can be specified multiple times)&lt;/p&gt; 
&lt;p&gt;in a config file, this is the same as:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;[global]
  mime: gif=image/jif
  mime: ts=text/x.typescript
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;run copyparty with &lt;code&gt;--mimes&lt;/code&gt; to list all the default mappings&lt;/p&gt; 
&lt;h3&gt;GDPR compliance&lt;/h3&gt; 
&lt;p&gt;imagine using copyparty professionally... &lt;strong&gt;TINLA/IANAL; EU laws are hella confusing&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;remember to disable logging, or configure logrotation to an acceptable timeframe with &lt;code&gt;-lo cpp-%Y-%m%d.txt.xz&lt;/code&gt; or similar&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;if running with the database enabled (recommended), then have it forget uploader-IPs after some time using &lt;code&gt;--forget-ip 43200&lt;/code&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;don't set it too low; &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#unpost"&gt;unposting&lt;/a&gt; a file is no longer possible after this takes effect&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;if you actually &lt;em&gt;are&lt;/em&gt; a lawyer then I'm open for feedback, would be fun&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;feature chickenbits&lt;/h3&gt; 
&lt;p&gt;buggy feature? rip it out by setting any of the following environment variables to disable its associated bell or whistle,&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;env-var&lt;/th&gt; 
   &lt;th&gt;what it does&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;PRTY_NO_DB_LOCK&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;do not lock session/shares-databases for exclusive access&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;PRTY_NO_IFADDR&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;disable ip/nic discovery by poking into your OS with ctypes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;PRTY_NO_IMPRESO&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;do not try to load js/css files using &lt;code&gt;importlib.resources&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;PRTY_NO_IPV6&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;disable some ipv6 support (should not be necessary since windows 2000)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;PRTY_NO_LZMA&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;disable streaming xz compression of incoming uploads&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;PRTY_NO_MP&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;disable all use of the python &lt;code&gt;multiprocessing&lt;/code&gt; module (actual multithreading, cpu-count for parsers/thumbnailers)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;PRTY_NO_SQLITE&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;disable all database-related functionality (file indexing, metadata indexing, most file deduplication logic)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;PRTY_NO_TLS&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;disable native HTTPS support; if you still want to accept HTTPS connections then TLS must now be terminated by a reverse-proxy&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;PRTY_NO_TPOKE&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;disable systemd-tmpfilesd avoider&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;example: &lt;code&gt;PRTY_NO_IFADDR=1 python3 copyparty-sfx.py&lt;/code&gt;&lt;/p&gt; 
&lt;h3&gt;feature beefybits&lt;/h3&gt; 
&lt;p&gt;force-enable features with known issues on your OS/env by setting any of the following environment variables, also affectionately known as &lt;code&gt;fuckitbits&lt;/code&gt; or &lt;code&gt;hail-mary-bits&lt;/code&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;env-var&lt;/th&gt; 
   &lt;th&gt;what it does&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;PRTY_FORCE_MP&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;force-enable multiprocessing (real multithreading) on MacOS and other broken platforms&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;PRTY_FORCE_MAGIC&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;use &lt;a href="https://pypi.org/project/python-magic/"&gt;magic&lt;/a&gt; on Windows (you will segfault)&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h1&gt;packages&lt;/h1&gt; 
&lt;p&gt;the party might be closer than you think&lt;/p&gt; 
&lt;p&gt;if your distro/OS is not mentioned below, there might be some hints in the &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#on-servers"&gt;«on servers»&lt;/a&gt; section&lt;/p&gt; 
&lt;h2&gt;arch package&lt;/h2&gt; 
&lt;p&gt;&lt;code&gt;pacman -S copyparty&lt;/code&gt; (in &lt;a href="https://archlinux.org/packages/extra/any/copyparty/"&gt;arch linux extra&lt;/a&gt;)&lt;/p&gt; 
&lt;p&gt;it comes with a &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/contrib/package/arch/copyparty.service"&gt;systemd service&lt;/a&gt; and expects to find one or more &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/docs/example.conf"&gt;config files&lt;/a&gt; in &lt;code&gt;/etc/copyparty.d/&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;after installing it, you may want to &lt;code&gt;cp /usr/lib/systemd/system/copyparty.service /etc/systemd/system/&lt;/code&gt; and then &lt;code&gt;vim /etc/systemd/system/copyparty.service&lt;/code&gt; to change what user/group it is running as (you only need to do this once)&lt;/p&gt; 
&lt;p&gt;NOTE: there used to be an aur package; this evaporated when copyparty was adopted by the official archlinux repos. If you're still using the aur package, please move&lt;/p&gt; 
&lt;h2&gt;fedora package&lt;/h2&gt; 
&lt;p&gt;does not exist yet; there are rumours that it is being packaged! keep an eye on this space...&lt;/p&gt; 
&lt;h2&gt;nix package&lt;/h2&gt; 
&lt;p&gt;&lt;code&gt;nix profile install github:9001/copyparty&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;requires a &lt;a href="https://nixos.wiki/wiki/Flakes"&gt;flake-enabled&lt;/a&gt; installation of nix&lt;/p&gt; 
&lt;p&gt;some recommended dependencies are enabled by default; &lt;a href="https://github.com/9001/copyparty/raw/hovudstraum/contrib/package/nix/copyparty/default.nix#L3-L22"&gt;override the package&lt;/a&gt; if you want to add/remove some features/deps&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;ffmpeg-full&lt;/code&gt; was chosen over &lt;code&gt;ffmpeg-headless&lt;/code&gt; mainly because we need &lt;code&gt;withWebp&lt;/code&gt; (and &lt;code&gt;withOpenmpt&lt;/code&gt; is also nice) and being able to use a cached build felt more important than optimizing for size at the time -- PRs welcome if you disagree 👍&lt;/p&gt; 
&lt;h2&gt;nixos module&lt;/h2&gt; 
&lt;p&gt;for this setup, you will need a &lt;a href="https://nixos.wiki/wiki/Flakes"&gt;flake-enabled&lt;/a&gt; installation of NixOS.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-nix"&gt;{
  # add copyparty flake to your inputs
  inputs.copyparty.url = "github:9001/copyparty";

  # ensure that copyparty is an allowed argument to the outputs function
  outputs = { self, nixpkgs, copyparty }: {
    nixosConfigurations.yourHostName = nixpkgs.lib.nixosSystem {
      modules = [
        # load the copyparty NixOS module
        copyparty.nixosModules.default
        ({ pkgs, ... }: {
          # add the copyparty overlay to expose the package to the module
          nixpkgs.overlays = [ copyparty.overlays.default ];
          # (optional) install the package globally
          environment.systemPackages = [ pkgs.copyparty ];
          # configure the copyparty module
          services.copyparty.enable = true;
        })
      ];
    };
  };
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;copyparty on NixOS is configured via &lt;code&gt;services.copyparty&lt;/code&gt; options, for example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-nix"&gt;services.copyparty = {
  enable = true;
  # directly maps to values in the [global] section of the copyparty config.
  # see `copyparty --help` for available options
  settings = {
    i = "0.0.0.0";
    # use lists to set multiple values
    p = [ 3210 3211 ];
    # use booleans to set binary flags
    no-reload = true;
    # using 'false' will do nothing and omit the value when generating a config
    ignored-flag = false;
  };

  # create users
  accounts = {
    # specify the account name as the key
    ed = {
      # provide the path to a file containing the password, keeping it out of /nix/store
      # must be readable by the copyparty service user
      passwordFile = "/run/keys/copyparty/ed_password";
    };
    # or do both in one go
    k.passwordFile = "/run/keys/copyparty/k_password";
  };

  # create a volume
  volumes = {
    # create a volume at "/" (the webroot), which will
    "/" = {
      # share the contents of "/srv/copyparty"
      path = "/srv/copyparty";
      # see `copyparty --help-accounts` for available options
      access = {
        # everyone gets read-access, but
        r = "*";
        # users "ed" and "k" get read-write
        rw = [ "ed" "k" ];
      };
      # see `copyparty --help-flags` for available options
      flags = {
        # "fk" enables filekeys (necessary for upget permission) (4 chars long)
        fk = 4;
        # scan for new files every 60sec
        scan = 60;
        # volflag "e2d" enables the uploads database
        e2d = true;
        # "d2t" disables multimedia parsers (in case the uploads are malicious)
        d2t = true;
        # skips hashing file contents if path matches *.iso
        nohash = "\.iso$";
      };
    };
  };
  # you may increase the open file limit for the process
  openFilesLimit = 8192;
};
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;the passwordFile at /run/keys/copyparty/ could for example be generated by &lt;a href="https://github.com/ryantm/agenix"&gt;agenix&lt;/a&gt;, or you could just dump it in the nix store instead if that's acceptable&lt;/p&gt; 
&lt;h1&gt;browser support&lt;/h1&gt; 
&lt;p&gt;TLDR: yes&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://user-images.githubusercontent.com/241032/118192791-fb31fe00-b446-11eb-9647-898ea8efc1f7.png" alt="copyparty-ie4-fs8"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;ie&lt;/code&gt; = internet-explorer, &lt;code&gt;ff&lt;/code&gt; = firefox, &lt;code&gt;c&lt;/code&gt; = chrome, &lt;code&gt;iOS&lt;/code&gt; = iPhone/iPad, &lt;code&gt;Andr&lt;/code&gt; = Android&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;feature&lt;/th&gt; 
   &lt;th&gt;ie6&lt;/th&gt; 
   &lt;th&gt;ie9&lt;/th&gt; 
   &lt;th&gt;ie10&lt;/th&gt; 
   &lt;th&gt;ie11&lt;/th&gt; 
   &lt;th&gt;ff 52&lt;/th&gt; 
   &lt;th&gt;c 49&lt;/th&gt; 
   &lt;th&gt;iOS&lt;/th&gt; 
   &lt;th&gt;Andr&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;browse files&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;thumbnail view&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;basic uploader&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;up2k&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;*1&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;*1&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;make directory&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;send message&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;set sort order&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;zip selection&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;file search&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;file rename&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;file cut/paste&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;unpost uploads&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;navpane&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;image viewer&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;video player&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;markdown editor&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;*2&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;*2&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;markdown viewer&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;*2&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;*2&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;*2&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;play mp3/m4a&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;play ogg/opus&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;*3&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;yep&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;= feature =&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;ie6&lt;/td&gt; 
   &lt;td&gt;ie9&lt;/td&gt; 
   &lt;td&gt;ie10&lt;/td&gt; 
   &lt;td&gt;ie11&lt;/td&gt; 
   &lt;td&gt;ff 52&lt;/td&gt; 
   &lt;td&gt;c 49&lt;/td&gt; 
   &lt;td&gt;iOS&lt;/td&gt; 
   &lt;td&gt;Andr&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;ul&gt; 
 &lt;li&gt;internet explorer 6 through 8 behave the same&lt;/li&gt; 
 &lt;li&gt;firefox 52 and chrome 49 are the final winxp versions&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;*1&lt;/code&gt; yes, but extremely slow (ie10: &lt;code&gt;1 MiB/s&lt;/code&gt;, ie11: &lt;code&gt;270 KiB/s&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;*2&lt;/code&gt; only able to do plaintext documents (no markdown rendering)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;*3&lt;/code&gt; iOS 11 and newer, opus only, and requires FFmpeg on the server&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;quick summary of more eccentric web-browsers trying to view a directory index:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;browser&lt;/th&gt; 
   &lt;th&gt;will it blend&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;links&lt;/strong&gt; (2.21/macports)&lt;/td&gt; 
   &lt;td&gt;can browse, login, upload/mkdir/msg&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;lynx&lt;/strong&gt; (2.8.9/macports)&lt;/td&gt; 
   &lt;td&gt;can browse, login, upload/mkdir/msg&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;w3m&lt;/strong&gt; (0.5.3/macports)&lt;/td&gt; 
   &lt;td&gt;can browse, login, upload at 100kB/s, mkdir/msg&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;netsurf&lt;/strong&gt; (3.10/arch)&lt;/td&gt; 
   &lt;td&gt;is basically ie6 with much better css (javascript has almost no effect)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;opera&lt;/strong&gt; (11.60/winxp)&lt;/td&gt; 
   &lt;td&gt;OK: thumbnails, image-viewer, zip-selection, rename/cut/paste. NG: up2k, navpane, markdown, audio&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;ie4&lt;/strong&gt; and &lt;strong&gt;netscape&lt;/strong&gt; 4.0&lt;/td&gt; 
   &lt;td&gt;can browse, upload with &lt;code&gt;?b=u&lt;/code&gt;, auth with &lt;code&gt;&amp;amp;pw=wark&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;ncsa mosaic&lt;/strong&gt; 2.7&lt;/td&gt; 
   &lt;td&gt;does not get a pass, &lt;a href="https://user-images.githubusercontent.com/241032/174189227-ae816026-cf6f-4be5-a26e-1b3b072c1b2f.png"&gt;pic1&lt;/a&gt; - &lt;a href="https://user-images.githubusercontent.com/241032/174189225-5651c059-5152-46e9-ac26-7e98e497901b.png"&gt;pic2&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;SerenityOS&lt;/strong&gt; (7e98457)&lt;/td&gt; 
   &lt;td&gt;hits a page fault, works with &lt;code&gt;?b=u&lt;/code&gt;, file upload not-impl&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;sony psp&lt;/strong&gt; 5.50&lt;/td&gt; 
   &lt;td&gt;can browse, upload/mkdir/msg (thx dwarf) &lt;a href="https://github.com/user-attachments/assets/9d21f020-1110-4652-abeb-6fc09c533d4f"&gt;screenshot&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;nintendo 3ds&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;can browse, upload, view thumbnails (thx bnjmn)&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p align="center"&gt;&lt;img src="https://github.com/user-attachments/assets/88deab3d-6cad-4017-8841-2f041472b853"&gt;&lt;/p&gt; 
&lt;h1&gt;client examples&lt;/h1&gt; 
&lt;p&gt;interact with copyparty using non-browser clients&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;javascript: dump some state into a file (two separate examples)&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;await fetch('//127.0.0.1:3923/', {method:"PUT", body: JSON.stringify(foo)});&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;var xhr = new XMLHttpRequest(); xhr.open('POST', '//127.0.0.1:3923/msgs?raw'); xhr.send('foo');&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;curl/wget: upload some files (post=file, chunk=stdin)&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;post(){ curl -F f=@"$1" http://127.0.0.1:3923/?pw=wark;}&lt;/code&gt;&lt;br&gt; &lt;code&gt;post movie.mkv&lt;/code&gt; (gives HTML in return)&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;post(){ curl -F f=@"$1" 'http://127.0.0.1:3923/?want=url&amp;amp;pw=wark';}&lt;/code&gt;&lt;br&gt; &lt;code&gt;post movie.mkv&lt;/code&gt; (gives hotlink in return)&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;post(){ curl -H pw:wark -H rand:8 -T "$1" http://127.0.0.1:3923/;}&lt;/code&gt;&lt;br&gt; &lt;code&gt;post movie.mkv&lt;/code&gt; (randomized filename)&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;post(){ wget --header='pw: wark' --post-file="$1" -O- http://127.0.0.1:3923/?raw;}&lt;/code&gt;&lt;br&gt; &lt;code&gt;post movie.mkv&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;chunk(){ curl -H pw:wark -T- http://127.0.0.1:3923/;}&lt;/code&gt;&lt;br&gt; &lt;code&gt;chunk &amp;lt;movie.mkv&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;bash: when curl and wget is not available or too boring&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;(printf 'PUT /junk?pw=wark HTTP/1.1\r\n\r\n'; cat movie.mkv) | nc 127.0.0.1 3923&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;(printf 'PUT / HTTP/1.1\r\n\r\n'; cat movie.mkv) &amp;gt;/dev/tcp/127.0.0.1/3923&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;python: &lt;a href="https://github.com/9001/copyparty/raw/hovudstraum/bin/u2c.py"&gt;u2c.py&lt;/a&gt; is a command-line up2k client &lt;a href="https://ocv.me/stuff/u2cli.webm"&gt;(webm)&lt;/a&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;file uploads, file-search, &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#folder-sync"&gt;folder sync&lt;/a&gt;, autoresume of aborted/broken uploads&lt;/li&gt; 
   &lt;li&gt;can be downloaded from copyparty: controlpanel -&amp;gt; connect -&amp;gt; &lt;a href="http://127.0.0.1:3923/.cpr/a/u2c.py"&gt;u2c.py&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/bin/README.md#u2cpy"&gt;./bin/README.md#u2cpy&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;FUSE: mount a copyparty server as a local filesystem&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;cross-platform python client available in &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/bin/"&gt;./bin/&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;able to mount nginx and iis directory listings too, not just copyparty&lt;/li&gt; 
   &lt;li&gt;can be downloaded from copyparty: controlpanel -&amp;gt; connect -&amp;gt; &lt;a href="http://127.0.0.1:3923/.cpr/a/partyfuse.py"&gt;partyfuse.py&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://rclone.org/"&gt;rclone&lt;/a&gt; as client can give ~5x performance, see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/docs/rclone.md"&gt;./docs/rclone.md&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;sharex (screenshot utility): see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/contrib/#sharexsxcu"&gt;./contrib/sharex.sxcu&lt;/a&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;and for screenshots on macos, see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/contrib/#ishareiscu"&gt;./contrib/ishare.iscu&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;and for screenshots on linux, see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/contrib/flameshot.sh"&gt;./contrib/flameshot.sh&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://f-droid.org/en/packages/com.nyx.custom_uploader/"&gt;Custom Uploader&lt;/a&gt; (an Android app) as an alternative to copyparty's own &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#android-app"&gt;PartyUP!&lt;/a&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;works if you set UploadURL to &lt;code&gt;https://your.com/foo/?want=url&amp;amp;pw=hunter2&lt;/code&gt; and FormDataName &lt;code&gt;f&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;contextlet (web browser integration); see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/contrib/#send-to-cppcontextletjson"&gt;contrib contextlet&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://iglooirc.com/"&gt;igloo irc&lt;/a&gt;: Method: &lt;code&gt;post&lt;/code&gt; Host: &lt;code&gt;https://you.com/up/?want=url&amp;amp;pw=hunter2&lt;/code&gt; Multipart: &lt;code&gt;yes&lt;/code&gt; File parameter: &lt;code&gt;f&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;copyparty returns a truncated sha512sum of your PUT/POST as base64; you can generate the same checksum locally to verify uploads:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;b512(){ printf "$((sha512sum||shasum -a512)|sed -E 's/ .*//;s/(..)/\\x\1/g')"|base64|tr '+/' '-_'|head -c44;}
b512 &amp;lt;movie.mkv
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;you can provide passwords using header &lt;code&gt;PW: hunter2&lt;/code&gt;, cookie &lt;code&gt;cppwd=hunter2&lt;/code&gt;, url-param &lt;code&gt;?pw=hunter2&lt;/code&gt;, or with basic-authentication (either as the username or password)&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;for basic-authentication, all of the following are accepted: &lt;code&gt;password&lt;/code&gt; / &lt;code&gt;whatever:password&lt;/code&gt; / &lt;code&gt;password:whatever&lt;/code&gt; (the username is ignored)&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;NOTE: curl will not send the original filename if you use &lt;code&gt;-T&lt;/code&gt; combined with url-params! Also, make sure to always leave a trailing slash in URLs unless you want to override the filename&lt;/p&gt; 
&lt;h2&gt;folder sync&lt;/h2&gt; 
&lt;p&gt;sync folders to/from copyparty&lt;/p&gt; 
&lt;p&gt;NOTE: full bidirectional sync, like what &lt;a href="https://docs.nextcloud.com/server/latest/user_manual/sv/files/desktop_mobile_sync.html"&gt;nextcloud&lt;/a&gt; and &lt;a href="https://syncthing.net/"&gt;syncthing&lt;/a&gt; does, will never be supported! Only single-direction sync (server-to-client, or client-to-server) is possible with copyparty&lt;/p&gt; 
&lt;p&gt;the commandline uploader &lt;a href="https://github.com/9001/copyparty/tree/hovudstraum/bin#u2cpy"&gt;u2c.py&lt;/a&gt; with &lt;code&gt;--dr&lt;/code&gt; is the best way to sync a folder to copyparty; verifies checksums and does files in parallel, and deletes unexpected files on the server after upload has finished which makes file-renames really cheap (it'll rename serverside and skip uploading)&lt;/p&gt; 
&lt;p&gt;alternatively there is &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/docs/rclone.md"&gt;rclone&lt;/a&gt; which allows for bidirectional sync and is &lt;em&gt;way&lt;/em&gt; more flexible (stream files straight from sftp/s3/gcs to copyparty, ...), although there is no integrity check and it won't work with files over 100 MiB if copyparty is behind cloudflare&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;starting from rclone v1.63, rclone is faster than u2c.py on low-latency connections&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;mount as drive&lt;/h2&gt; 
&lt;p&gt;a remote copyparty server as a local filesystem; go to the control-panel and click &lt;code&gt;connect&lt;/code&gt; to see a list of commands to do that&lt;/p&gt; 
&lt;p&gt;alternatively, some alternatives roughly sorted by speed (unreproducible benchmark), best first:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/docs/rclone.md"&gt;rclone-webdav&lt;/a&gt; (25s), read/WRITE (rclone v1.63 or later)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/docs/rclone.md"&gt;rclone-http&lt;/a&gt; (26s), read-only&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/bin/#partyfusepy"&gt;partyfuse.py&lt;/a&gt; (26s), read-only&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/docs/rclone.md"&gt;rclone-ftp&lt;/a&gt; (47s), read/WRITE&lt;/li&gt; 
 &lt;li&gt;davfs2 (103s), read/WRITE&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#webdav-server"&gt;win10-webdav&lt;/a&gt; (138s), read/WRITE&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#smb-server"&gt;win10-smb2&lt;/a&gt; (387s), read/WRITE&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;most clients will fail to mount the root of a copyparty server unless there is a root volume (so you get the admin-panel instead of a browser when accessing it) -- in that case, mount a specific volume instead&lt;/p&gt; 
&lt;p&gt;if you have volumes that are accessible without a password, then some webdav clients (such as davfs2) require the global-option &lt;code&gt;--dav-auth&lt;/code&gt; to access any password-protected areas&lt;/p&gt; 
&lt;h1&gt;android app&lt;/h1&gt; 
&lt;p&gt;upload to copyparty with one tap&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://f-droid.org/packages/me.ocv.partyup/"&gt;&lt;img src="https://ocv.me/fdroid.png" alt="Get it on F-Droid" height="50"&gt; '' &lt;img src="https://img.shields.io/f-droid/v/me.ocv.partyup.svg?sanitize=true" alt="f-droid version info"&gt;&lt;/a&gt; '' &lt;a href="https://github.com/9001/party-up"&gt;&lt;img src="https://img.shields.io/github/release/9001/party-up.svg?logo=github" alt="github version info"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;the app is &lt;strong&gt;NOT&lt;/strong&gt; the full copyparty server! just a basic upload client, nothing fancy yet&lt;/p&gt; 
&lt;p&gt;if you want to run the copyparty server on your android device, see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#install-on-android"&gt;install on android&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;iOS shortcuts&lt;/h1&gt; 
&lt;p&gt;there is no iPhone app, but the following shortcuts are almost as good:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.icloud.com/shortcuts/41e98dd985cb4d3bb433222bc1e9e770"&gt;upload to copyparty&lt;/a&gt; (&lt;a href="https://github.com/9001/copyparty/raw/hovudstraum/contrib/ios/upload-to-copyparty.shortcut"&gt;offline&lt;/a&gt;) (&lt;a href="https://user-images.githubusercontent.com/241032/226118053-78623554-b0ed-482e-98e4-6d57ada58ea4.png"&gt;png&lt;/a&gt;) based on the &lt;a href="https://www.icloud.com/shortcuts/ab415d5b4de3467b9ce6f151b439a5d7"&gt;original&lt;/a&gt; by &lt;a href="https://github.com/Daedren"&gt;Daedren&lt;/a&gt; (thx!) 
  &lt;ul&gt; 
   &lt;li&gt;can strip exif, upload files, pics, vids, links, clipboard&lt;/li&gt; 
   &lt;li&gt;can download links and rehost the target file on copyparty (see first comment inside the shortcut)&lt;/li&gt; 
   &lt;li&gt;pics become lowres if you share from gallery to shortcut, so better to launch the shortcut and pick stuff from there&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;performance&lt;/h1&gt; 
&lt;p&gt;defaults are usually fine - expect &lt;code&gt;8 GiB/s&lt;/code&gt; download, &lt;code&gt;1 GiB/s&lt;/code&gt; upload&lt;/p&gt; 
&lt;p&gt;below are some tweaks roughly ordered by usefulness:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;disabling HTTP/2 and HTTP/3 can make uploads 5x faster, depending on server/client software&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;-q&lt;/code&gt; disables logging and can help a bunch, even when combined with &lt;code&gt;-lo&lt;/code&gt; to redirect logs to file&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;--hist&lt;/code&gt; pointing to a fast location (ssd) will make directory listings and searches faster when &lt;code&gt;-e2d&lt;/code&gt; or &lt;code&gt;-e2t&lt;/code&gt; is set&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;and also makes thumbnails load faster, regardless of e2d/e2t&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;--dedup&lt;/code&gt; enables deduplication and thus avoids writing to the HDD if someone uploads a dupe&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;--safe-dedup 1&lt;/code&gt; makes deduplication much faster during upload by skipping verification of file contents; safe if there is no other software editing/moving the files in the volumes&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;--no-dirsz&lt;/code&gt; shows the size of folder inodes instead of the total size of the contents, giving about 30% faster folder listings&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;--no-hash .&lt;/code&gt; when indexing a network-disk if you don't care about the actual filehashes and only want the names/tags searchable&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;if your volumes are on a network-disk such as NFS / SMB / s3, specifying larger values for &lt;code&gt;--iobuf&lt;/code&gt; and/or &lt;code&gt;--s-rd-sz&lt;/code&gt; and/or &lt;code&gt;--s-wr-sz&lt;/code&gt; may help; try setting all of them to &lt;code&gt;524288&lt;/code&gt; or &lt;code&gt;1048576&lt;/code&gt; or &lt;code&gt;4194304&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;--no-htp --hash-mt=0 --mtag-mt=1 --th-mt=1&lt;/code&gt; minimizes the number of threads; can help in some eccentric environments (like the vscode debugger)&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;when running on AlpineLinux or other musl-based distro, try mimalloc for higher performance (and twice as much RAM usage); &lt;code&gt;apk add mimalloc2&lt;/code&gt; and run copyparty with env-var &lt;code&gt;LD_PRELOAD=/usr/lib/libmimalloc-secure.so.2&lt;/code&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;note that mimalloc requires special care when combined with prisonparty and/or bubbleparty/bubblewrap; you must give it access to &lt;code&gt;/proc&lt;/code&gt; and &lt;code&gt;/sys&lt;/code&gt; otherwise you'll encounter issues with FFmpeg (audio transcoding, thumbnails)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;-j0&lt;/code&gt; enables multiprocessing (actual multithreading), can reduce latency to &lt;code&gt;20+80/numCores&lt;/code&gt; percent and generally improve performance in cpu-intensive workloads, for example:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;lots of connections (many users or heavy clients)&lt;/li&gt; 
   &lt;li&gt;simultaneous downloads and uploads saturating a 20gbps connection&lt;/li&gt; 
   &lt;li&gt;if &lt;code&gt;-e2d&lt;/code&gt; is enabled, &lt;code&gt;-j2&lt;/code&gt; gives 4x performance for directory listings; &lt;code&gt;-j4&lt;/code&gt; gives 16x&lt;/li&gt; 
  &lt;/ul&gt; &lt;p&gt;...however it also increases the server/filesystem/HDD load during uploads, and adds an overhead to internal communication, so it is usually a better idea to don't&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;using &lt;a href="https://www.pypy.org/"&gt;pypy&lt;/a&gt; instead of &lt;a href="https://www.python.org/"&gt;cpython&lt;/a&gt; &lt;em&gt;can&lt;/em&gt; be 70% faster for some workloads, but slower for many others&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;and pypy can sometimes crash on startup with &lt;code&gt;-j0&lt;/code&gt; (TODO make issue)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;client-side&lt;/h2&gt; 
&lt;p&gt;when uploading files,&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;when uploading from very fast storage (NVMe SSD) with chrome/firefox, enable &lt;code&gt;[wasm]&lt;/code&gt; in the &lt;code&gt;[⚙️] settings&lt;/code&gt; tab to more effectively use all CPU-cores for hashing&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;don't do this on Safari (runs faster without)&lt;/li&gt; 
   &lt;li&gt;don't do this on older browsers; likely to provoke browser-bugs (browser eats all RAM and crashes)&lt;/li&gt; 
   &lt;li&gt;can be made default-enabled serverside with &lt;code&gt;--nosubtle 137&lt;/code&gt; (chrome v137+) or &lt;code&gt;--nosubtle 2&lt;/code&gt; (chrome+firefox)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;chrome is recommended (unfortunately), at least compared to firefox:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;up to 90% faster when hashing, especially on SSDs&lt;/li&gt; 
   &lt;li&gt;up to 40% faster when uploading over extremely fast internets&lt;/li&gt; 
   &lt;li&gt;but &lt;a href="https://github.com/9001/copyparty/raw/hovudstraum/bin/u2c.py"&gt;u2c.py&lt;/a&gt; can be 40% faster than chrome again&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;if you're cpu-bottlenecked, or the browser is maxing a cpu core:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;up to 30% faster uploads if you hide the upload status list by switching away from the &lt;code&gt;[🚀]&lt;/code&gt; up2k ui-tab (or closing it) 
    &lt;ul&gt; 
     &lt;li&gt;optionally you can switch to the lightweight potato ui by clicking the &lt;code&gt;[🥔]&lt;/code&gt;&lt;/li&gt; 
     &lt;li&gt;switching to another browser-tab also works, the favicon will update every 10 seconds in that case&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;unlikely to be a problem, but can happen when uploading many small files, or your internet is too fast, or PC too slow&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;security&lt;/h1&gt; 
&lt;p&gt;there is a &lt;a href="https://discord.gg/25J8CdTT6G"&gt;discord server&lt;/a&gt; with an &lt;code&gt;@everyone&lt;/code&gt; for all important updates (at the lack of better ideas)&lt;/p&gt; 
&lt;p&gt;some notes on hardening&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;set &lt;code&gt;--rproxy 0&lt;/code&gt; if your copyparty is directly facing the internet (not through a reverse-proxy) 
  &lt;ul&gt; 
   &lt;li&gt;cors doesn't work right otherwise&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;if you allow anonymous uploads or otherwise don't trust the contents of a volume, you can prevent XSS with volflag &lt;code&gt;nohtml&lt;/code&gt; 
  &lt;ul&gt; 
   &lt;li&gt;this returns html documents as plaintext, and also disables markdown rendering&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;when running behind a reverse-proxy, listen on a unix-socket for tighter access control (and more performance); see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#reverse-proxy"&gt;reverse-proxy&lt;/a&gt; or &lt;code&gt;--help-bind&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;safety profiles:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;option &lt;code&gt;-s&lt;/code&gt; is a shortcut to set the following options:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;--no-thumb&lt;/code&gt; disables thumbnails and audio transcoding to stop copyparty from running &lt;code&gt;FFmpeg&lt;/code&gt;/&lt;code&gt;Pillow&lt;/code&gt;/&lt;code&gt;VIPS&lt;/code&gt; on uploaded files, which is a &lt;a href="https://www.cvedetails.com/vulnerability-list.php?vendor_id=3611"&gt;good idea&lt;/a&gt; if anonymous upload is enabled&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;--no-mtag-ff&lt;/code&gt; uses &lt;code&gt;mutagen&lt;/code&gt; to grab music tags instead of &lt;code&gt;FFmpeg&lt;/code&gt;, which is safer and faster but less accurate&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;--dotpart&lt;/code&gt; hides uploads from directory listings while they're still incoming&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;--no-robots&lt;/code&gt; and &lt;code&gt;--force-js&lt;/code&gt; makes life harder for crawlers, see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#hiding-from-google"&gt;hiding from google&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;option &lt;code&gt;-ss&lt;/code&gt; is a shortcut for the above plus:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;--unpost 0&lt;/code&gt;, &lt;code&gt;--no-del&lt;/code&gt;, &lt;code&gt;--no-mv&lt;/code&gt; disables all move/delete support&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;--hardlink&lt;/code&gt; creates hardlinks instead of symlinks when deduplicating uploads, which is less maintenance 
    &lt;ul&gt; 
     &lt;li&gt;however note if you edit one file it will also affect the other copies&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;--vague-403&lt;/code&gt; returns a "404 not found" instead of "401 unauthorized" which is a common enterprise meme&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;-nih&lt;/code&gt; removes the server hostname from directory listings&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;option &lt;code&gt;-sss&lt;/code&gt; is a shortcut for the above plus:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;--no-dav&lt;/code&gt; disables webdav support&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;--no-logues&lt;/code&gt; and &lt;code&gt;--no-readme&lt;/code&gt; disables support for readme's and prologues / epilogues in directory listings, which otherwise lets people upload arbitrary (but sandboxed) &lt;code&gt;&amp;lt;script&amp;gt;&lt;/code&gt; tags&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;-lo cpp-%Y-%m%d-%H%M%S.txt.xz&lt;/code&gt; enables logging to disk&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;-ls **,*,ln,p,r&lt;/code&gt; does a scan on startup for any dangerous symlinks&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;other misc notes:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;you can disable directory listings by giving permission &lt;code&gt;g&lt;/code&gt; instead of &lt;code&gt;r&lt;/code&gt;, only accepting direct URLs to files 
  &lt;ul&gt; 
   &lt;li&gt;you may want &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#filekeys"&gt;filekeys&lt;/a&gt; to prevent filename bruteforcing&lt;/li&gt; 
   &lt;li&gt;permission &lt;code&gt;h&lt;/code&gt; instead of &lt;code&gt;r&lt;/code&gt; makes copyparty behave like a traditional webserver with directory listing/index disabled, returning index.html instead 
    &lt;ul&gt; 
     &lt;li&gt;compatibility with filekeys: index.html itself can be retrieved without the correct filekey, but all other files are protected&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;gotchas&lt;/h2&gt; 
&lt;p&gt;behavior that might be unexpected&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;users without read-access to a folder can still see the &lt;code&gt;.prologue.html&lt;/code&gt; / &lt;code&gt;.epilogue.html&lt;/code&gt; / &lt;code&gt;PREADME.md&lt;/code&gt; / &lt;code&gt;README.md&lt;/code&gt; contents, for the purpose of showing a description on how to use the uploader for example&lt;/li&gt; 
 &lt;li&gt;users can submit &lt;code&gt;&amp;lt;script&amp;gt;&lt;/code&gt;s which autorun (in a sandbox) for other visitors in a few ways; 
  &lt;ul&gt; 
   &lt;li&gt;uploading a &lt;code&gt;README.md&lt;/code&gt; -- avoid with &lt;code&gt;--no-readme&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;renaming &lt;code&gt;some.html&lt;/code&gt; to &lt;code&gt;.epilogue.html&lt;/code&gt; -- avoid with either &lt;code&gt;--no-logues&lt;/code&gt; or &lt;code&gt;--no-dot-ren&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;the directory-listing embed is sandboxed (so any malicious scripts can't do any damage) but the markdown editor is not 100% safe, see below&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;markdown documents can contain html and &lt;code&gt;&amp;lt;script&amp;gt;&lt;/code&gt;s; attempts are made to prevent scripts from executing (unless &lt;code&gt;-emp&lt;/code&gt; is specified) but this is not 100% bulletproof, so setting the &lt;code&gt;nohtml&lt;/code&gt; volflag is still the safest choice 
  &lt;ul&gt; 
   &lt;li&gt;or eliminate the problem entirely by only giving write-access to trustworthy people :^)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;cors&lt;/h2&gt; 
&lt;p&gt;cross-site request config&lt;/p&gt; 
&lt;p&gt;by default, except for &lt;code&gt;GET&lt;/code&gt; and &lt;code&gt;HEAD&lt;/code&gt; operations, all requests must either:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;not contain an &lt;code&gt;Origin&lt;/code&gt; header at all&lt;/li&gt; 
 &lt;li&gt;or have an &lt;code&gt;Origin&lt;/code&gt; matching the server domain&lt;/li&gt; 
 &lt;li&gt;or the header &lt;code&gt;PW&lt;/code&gt; with your password as value&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;cors can be configured with &lt;code&gt;--acao&lt;/code&gt; and &lt;code&gt;--acam&lt;/code&gt;, or the protections entirely disabled with &lt;code&gt;--allow-csrf&lt;/code&gt;&lt;/p&gt; 
&lt;h2&gt;filekeys&lt;/h2&gt; 
&lt;p&gt;prevent filename bruteforcing&lt;/p&gt; 
&lt;p&gt;volflag &lt;code&gt;fk&lt;/code&gt; generates filekeys (per-file accesskeys) for all files; users which have full read-access (permission &lt;code&gt;r&lt;/code&gt;) will then see URLs with the correct filekey &lt;code&gt;?k=...&lt;/code&gt; appended to the end, and &lt;code&gt;g&lt;/code&gt; users must provide that URL including the correct key to avoid a 404&lt;/p&gt; 
&lt;p&gt;by default, filekeys are generated based on salt (&lt;code&gt;--fk-salt&lt;/code&gt;) + filesystem-path + file-size + inode (if not windows); add volflag &lt;code&gt;fka&lt;/code&gt; to generate slightly weaker filekeys which will not be invalidated if the file is edited (only salt + path)&lt;/p&gt; 
&lt;p&gt;permissions &lt;code&gt;wG&lt;/code&gt; (write + upget) lets users upload files and receive their own filekeys, still without being able to see other uploads&lt;/p&gt; 
&lt;h3&gt;dirkeys&lt;/h3&gt; 
&lt;p&gt;share specific folders in a volume without giving away full read-access to the rest -- the visitor only needs the &lt;code&gt;g&lt;/code&gt; (get) permission to view the link&lt;/p&gt; 
&lt;p&gt;volflag &lt;code&gt;dk&lt;/code&gt; generates dirkeys (per-directory accesskeys) for all folders, granting read-access to that folder; by default only that folder itself, no subfolders&lt;/p&gt; 
&lt;p&gt;volflag &lt;code&gt;dky&lt;/code&gt; disables the actual key-check, meaning anyone can see the contents of a folder where they have &lt;code&gt;g&lt;/code&gt; access, but not its subdirectories&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;dk&lt;/code&gt; + &lt;code&gt;dky&lt;/code&gt; gives the same behavior as if all users with &lt;code&gt;g&lt;/code&gt; access have full read-access, but subfolders are hidden files (as if their names start with a dot), so &lt;code&gt;dky&lt;/code&gt; is an alternative to renaming all the folders for that purpose, maybe just for some users&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;volflag &lt;code&gt;dks&lt;/code&gt; lets people enter subfolders as well, and also enables download-as-zip/tar&lt;/p&gt; 
&lt;p&gt;if you enable dirkeys, it is probably a good idea to enable filekeys too, otherwise it will be impossible to hotlink files from a folder which was accessed using a dirkey&lt;/p&gt; 
&lt;p&gt;dirkeys are generated based on another salt (&lt;code&gt;--dk-salt&lt;/code&gt;) + filesystem-path and have a few limitations:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;the key does not change if the contents of the folder is modified 
  &lt;ul&gt; 
   &lt;li&gt;if you need a new dirkey, either change the salt or rename the folder&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;linking to a textfile (so it opens in the textfile viewer) is not possible if recipient doesn't have read-access&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;password hashing&lt;/h2&gt; 
&lt;p&gt;you can hash passwords before putting them into config files / providing them as arguments; see &lt;code&gt;--help-pwhash&lt;/code&gt; for all the details&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;--ah-alg argon2&lt;/code&gt; enables it, and if you have any plaintext passwords then it'll print the hashed versions on startup so you can replace them&lt;/p&gt; 
&lt;p&gt;optionally also specify &lt;code&gt;--ah-cli&lt;/code&gt; to enter an interactive mode where it will hash passwords without ever writing the plaintext ones to disk&lt;/p&gt; 
&lt;p&gt;the default configs take about 0.4 sec and 256 MiB RAM to process a new password on a decent laptop&lt;/p&gt; 
&lt;h2&gt;https&lt;/h2&gt; 
&lt;p&gt;both HTTP and HTTPS are accepted by default, but letting a &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#reverse-proxy"&gt;reverse proxy&lt;/a&gt; handle the https/tls/ssl would be better (probably more secure by default)&lt;/p&gt; 
&lt;p&gt;copyparty doesn't speak HTTP/2 or QUIC, so using a reverse proxy would solve that as well -- but note that HTTP/1 is usually faster than both HTTP/2 and HTTP/3&lt;/p&gt; 
&lt;p&gt;if &lt;a href="https://github.com/cloudflare/cfssl/releases/latest"&gt;cfssl&lt;/a&gt; is installed, copyparty will automatically create a CA and server-cert on startup&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;the certs are written to &lt;code&gt;--crt-dir&lt;/code&gt; for distribution, see &lt;code&gt;--help&lt;/code&gt; for the other &lt;code&gt;--crt&lt;/code&gt; options&lt;/li&gt; 
 &lt;li&gt;this will be a self-signed certificate so you must install your &lt;code&gt;ca.pem&lt;/code&gt; into all your browsers/devices&lt;/li&gt; 
 &lt;li&gt;if you want to avoid the hassle of distributing certs manually, please consider using a reverse proxy&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;recovering from crashes&lt;/h1&gt; 
&lt;h2&gt;client crashes&lt;/h2&gt; 
&lt;h3&gt;firefox wsod&lt;/h3&gt; 
&lt;p&gt;firefox 87 can crash during uploads -- the entire browser goes, including all other browser tabs, everything turns white&lt;/p&gt; 
&lt;p&gt;however you can hit &lt;code&gt;F12&lt;/code&gt; in the up2k tab and use the devtools to see how far you got in the uploads:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;get a complete list of all uploads, organized by status (ok / no-good / busy / queued):&lt;br&gt; &lt;code&gt;var tabs = { ok:[], ng:[], bz:[], q:[] }; for (var a of up2k.ui.tab) tabs[a.in].push(a); tabs&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;list of filenames which failed:&lt;br&gt; &lt;code&gt;​var ng = []; for (var a of up2k.ui.tab) if (a.in != 'ok') ng.push(a.hn.split('&amp;lt;a href=\"').slice(-1)[0].split('\"&amp;gt;')[0]); ng&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;send the list of filenames to copyparty for safekeeping:&lt;br&gt; &lt;code&gt;await fetch('/inc', {method:'PUT', body:JSON.stringify(ng,null,1)})&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;HTTP API&lt;/h1&gt; 
&lt;p&gt;see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/docs/devnotes.md#http-api"&gt;devnotes&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;dependencies&lt;/h1&gt; 
&lt;p&gt;mandatory deps:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;jinja2&lt;/code&gt; (is built into the SFX)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;optional dependencies&lt;/h2&gt; 
&lt;p&gt;install these to enable bonus features&lt;/p&gt; 
&lt;p&gt;enable &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#password-hashing"&gt;hashed passwords&lt;/a&gt; in config: &lt;code&gt;argon2-cffi&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;enable &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#ftp-server"&gt;ftp-server&lt;/a&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;for just plaintext FTP, &lt;code&gt;pyftpdlib&lt;/code&gt; (is built into the SFX)&lt;/li&gt; 
 &lt;li&gt;with TLS encryption, &lt;code&gt;pyftpdlib pyopenssl&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;enable &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#metadata-from-audio-files"&gt;music tags&lt;/a&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;either &lt;code&gt;mutagen&lt;/code&gt; (fast, pure-python, skips a few tags, makes copyparty GPL? idk)&lt;/li&gt; 
 &lt;li&gt;or &lt;code&gt;ffprobe&lt;/code&gt; (20x slower, more accurate, possibly dangerous depending on your distro and users)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;enable &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#thumbnails"&gt;thumbnails&lt;/a&gt; of...&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;images:&lt;/strong&gt; &lt;code&gt;Pillow&lt;/code&gt; and/or &lt;code&gt;pyvips&lt;/code&gt; and/or &lt;code&gt;ffmpeg&lt;/code&gt; (requires py2.7 or py3.5+)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;videos/audio:&lt;/strong&gt; &lt;code&gt;ffmpeg&lt;/code&gt; and &lt;code&gt;ffprobe&lt;/code&gt; somewhere in &lt;code&gt;$PATH&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;HEIF pictures:&lt;/strong&gt; &lt;code&gt;pyvips&lt;/code&gt; or &lt;code&gt;ffmpeg&lt;/code&gt; or &lt;code&gt;pyheif-pillow-opener&lt;/code&gt; (requires Linux or a C compiler)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;AVIF pictures:&lt;/strong&gt; &lt;code&gt;pyvips&lt;/code&gt; or &lt;code&gt;ffmpeg&lt;/code&gt; or &lt;code&gt;pillow-avif-plugin&lt;/code&gt; or pillow v11.3+&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;JPEG XL pictures:&lt;/strong&gt; &lt;code&gt;pyvips&lt;/code&gt; or &lt;code&gt;ffmpeg&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;enable sending &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#zeromq"&gt;zeromq messages&lt;/a&gt; from event-hooks: &lt;code&gt;pyzmq&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;enable &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#smb-server"&gt;smb&lt;/a&gt; support (&lt;strong&gt;not&lt;/strong&gt; recommended): &lt;code&gt;impacket==0.12.0&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;pyvips&lt;/code&gt; gives higher quality thumbnails than &lt;code&gt;Pillow&lt;/code&gt; and is 320% faster, using 270% more ram: &lt;code&gt;sudo apt install libvips42 &amp;amp;&amp;amp; python3 -m pip install --user -U pyvips&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;to install FFmpeg on Windows, grab &lt;a href="https://www.gyan.dev/ffmpeg/builds/ffmpeg-git-full.7z"&gt;a recent build&lt;/a&gt; -- you need &lt;code&gt;ffmpeg.exe&lt;/code&gt; and &lt;code&gt;ffprobe.exe&lt;/code&gt; from inside the &lt;code&gt;bin&lt;/code&gt; folder; copy them into &lt;code&gt;C:\Windows\System32&lt;/code&gt; or any other folder that's in your &lt;code&gt;%PATH%&lt;/code&gt;&lt;/p&gt; 
&lt;h3&gt;dependency chickenbits&lt;/h3&gt; 
&lt;p&gt;prevent loading an optional dependency , for example if:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;you have an incompatible version installed and it causes problems&lt;/li&gt; 
 &lt;li&gt;you just don't want copyparty to use it, maybe to save ram&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;set any of the following environment variables to disable its associated optional feature,&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;env-var&lt;/th&gt; 
   &lt;th&gt;what it does&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;PRTY_NO_ARGON2&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;disable argon2-cffi password hashing&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;PRTY_NO_CFSSL&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;never attempt to generate self-signed certificates using &lt;a href="https://github.com/cloudflare/cfssl"&gt;cfssl&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;PRTY_NO_FFMPEG&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;audio transcoding&lt;/strong&gt; goes byebye, &lt;strong&gt;thumbnailing&lt;/strong&gt; must be handled by Pillow/libvips&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;PRTY_NO_FFPROBE&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;audio transcoding&lt;/strong&gt; goes byebye, &lt;strong&gt;thumbnailing&lt;/strong&gt; must be handled by Pillow/libvips, &lt;strong&gt;metadata-scanning&lt;/strong&gt; must be handled by mutagen&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;PRTY_NO_MAGIC&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;do not use &lt;a href="https://pypi.org/project/python-magic/"&gt;magic&lt;/a&gt; for filetype detection&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;PRTY_NO_MUTAGEN&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;do not use &lt;a href="https://pypi.org/project/mutagen/"&gt;mutagen&lt;/a&gt; for reading metadata from media files; will fallback to ffprobe&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;PRTY_NO_PIL&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;disable all &lt;a href="https://pypi.org/project/pillow/"&gt;Pillow&lt;/a&gt;-based thumbnail support; will fallback to libvips or ffmpeg&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;PRTY_NO_PILF&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;disable Pillow &lt;code&gt;ImageFont&lt;/code&gt; text rendering, used for folder thumbnails&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;PRTY_NO_PIL_AVIF&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;disable Pillow avif support (internal and/or &lt;a href="https://pypi.org/project/pillow-avif-plugin/"&gt;plugin&lt;/a&gt;)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;PRTY_NO_PIL_HEIF&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;disable 3rd-party Pillow plugin for &lt;a href="https://pypi.org/project/pyheif-pillow-opener/"&gt;HEIF support&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;PRTY_NO_PIL_WEBP&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;disable use of native webp support in Pillow&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;PRTY_NO_PSUTIL&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;do not use &lt;a href="https://pypi.org/project/psutil/"&gt;psutil&lt;/a&gt; for reaping stuck hooks and plugins on Windows&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;PRTY_NO_VIPS&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;disable all &lt;a href="https://pypi.org/project/pyvips/"&gt;libvips&lt;/a&gt;-based thumbnail support; will fallback to Pillow or ffmpeg&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;example: &lt;code&gt;PRTY_NO_PIL=1 python3 copyparty-sfx.py&lt;/code&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;PRTY_NO_PIL&lt;/code&gt; saves ram&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;PRTY_NO_VIPS&lt;/code&gt; saves ram and startup time&lt;/li&gt; 
 &lt;li&gt;python2.7 on windows: &lt;code&gt;PRTY_NO_FFMPEG&lt;/code&gt; + &lt;code&gt;PRTY_NO_FFPROBE&lt;/code&gt; saves startup time&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;optional gpl stuff&lt;/h2&gt; 
&lt;p&gt;some bundled tools have copyleft dependencies, see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/bin/#mtag"&gt;./bin/#mtag&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;these are standalone programs and will never be imported / evaluated by copyparty, and must be enabled through &lt;code&gt;-mtp&lt;/code&gt; configs&lt;/p&gt; 
&lt;h1&gt;sfx&lt;/h1&gt; 
&lt;p&gt;the self-contained "binary" (recommended!) &lt;a href="https://github.com/9001/copyparty/releases/latest/download/copyparty-sfx.py"&gt;copyparty-sfx.py&lt;/a&gt; will unpack itself and run copyparty, assuming you have python installed of course&lt;/p&gt; 
&lt;p&gt;you can reduce the sfx size by repacking it; see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/docs/devnotes.md#sfx-repack"&gt;./docs/devnotes.md#sfx-repack&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;copyparty.exe&lt;/h2&gt; 
&lt;p&gt;download &lt;a href="https://github.com/9001/copyparty/releases/latest/download/copyparty.exe"&gt;copyparty.exe&lt;/a&gt; (win8+) or &lt;a href="https://github.com/9001/copyparty/releases/latest/download/copyparty32.exe"&gt;copyparty32.exe&lt;/a&gt; (win7+)&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://user-images.githubusercontent.com/241032/221445946-1e328e56-8c5b-44a9-8b9f-dee84d942535.png" alt="copyparty-exe-fs8"&gt;&lt;/p&gt; 
&lt;p&gt;can be convenient on machines where installing python is problematic, however is &lt;strong&gt;not recommended&lt;/strong&gt; -- if possible, please use &lt;strong&gt;&lt;a href="https://github.com/9001/copyparty/releases/latest/download/copyparty-sfx.py"&gt;copyparty-sfx.py&lt;/a&gt;&lt;/strong&gt; instead&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/9001/copyparty/releases/latest/download/copyparty.exe"&gt;copyparty.exe&lt;/a&gt; runs on win8 or newer, was compiled on win10, does thumbnails + media tags, and is &lt;em&gt;currently&lt;/em&gt; safe to use, but any future python/expat/pillow CVEs can only be remedied by downloading a newer version of the exe&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;on win8 it needs &lt;a href="https://www.microsoft.com/en-us/download/details.aspx?id=48145"&gt;vc redist 2015&lt;/a&gt;, on win10 it just works&lt;/li&gt; 
   &lt;li&gt;some antivirus may freak out (false-positive), possibly &lt;a href="https://www.virustotal.com/gui/file/52391a1e9842cf70ad243ef83844d46d29c0044d101ee0138fcdd3c8de2237d6/detection"&gt;Avast, AVG, and McAfee&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;dangerous: &lt;a href="https://github.com/9001/copyparty/releases/latest/download/copyparty32.exe"&gt;copyparty32.exe&lt;/a&gt; is compatible with &lt;a href="https://user-images.githubusercontent.com/241032/221445944-ae85d1f4-d351-4837-b130-82cab57d6cca.png"&gt;windows7&lt;/a&gt;, which means it uses an ancient copy of python (3.7.9) which cannot be upgraded and should never be exposed to the internet (LAN is fine)&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;dangerous and deprecated: &lt;a href="https://github.com/9001/copyparty/releases/download/v1.8.7/copyparty-winpe64.exe"&gt;copyparty-winpe64.exe&lt;/a&gt; lets you &lt;a href="https://user-images.githubusercontent.com/241032/205454984-e6b550df-3c49-486d-9267-1614078dd0dd.png"&gt;run copyparty in WinPE&lt;/a&gt; and is otherwise completely useless&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;meanwhile &lt;a href="https://github.com/9001/copyparty/releases/latest/download/copyparty-sfx.py"&gt;copyparty-sfx.py&lt;/a&gt; instead relies on your system python which gives better performance and will stay safe as long as you keep your python install up-to-date&lt;/p&gt; 
&lt;p&gt;then again, if you are already into downloading shady binaries from the internet, you may also want my &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/scripts/pyinstaller#ffmpeg"&gt;minimal builds&lt;/a&gt; of &lt;a href="https://ocv.me/stuff/bin/ffmpeg.exe"&gt;ffmpeg&lt;/a&gt; and &lt;a href="https://ocv.me/stuff/bin/ffprobe.exe"&gt;ffprobe&lt;/a&gt; which enables copyparty to extract multimedia-info, do audio-transcoding, and thumbnails/spectrograms/waveforms, however it's much better to instead grab a &lt;a href="https://www.gyan.dev/ffmpeg/builds/ffmpeg-git-full.7z"&gt;recent official build&lt;/a&gt; every once ina while if you can afford the size&lt;/p&gt; 
&lt;h2&gt;zipapp&lt;/h2&gt; 
&lt;p&gt;another emergency alternative, &lt;a href="https://github.com/9001/copyparty/releases/latest/download/copyparty.pyz"&gt;copyparty.pyz&lt;/a&gt; has less features, is slow, requires python 3.7 or newer, worse compression, and more importantly is unable to benefit from more recent versions of jinja2 and such (which makes it less secure)... lots of drawbacks with this one really -- but it does not unpack any temporary files to disk, so it &lt;em&gt;may&lt;/em&gt; just work if the regular sfx fails to start because the computer is messed up in certain funky ways, so it's worth a shot if all else fails&lt;/p&gt; 
&lt;p&gt;run it by doubleclicking it, or try typing &lt;code&gt;python copyparty.pyz&lt;/code&gt; in your terminal/console/commandline/telex if that fails&lt;/p&gt; 
&lt;p&gt;it is a python &lt;a href="https://docs.python.org/3/library/zipapp.html"&gt;zipapp&lt;/a&gt; meaning it doesn't have to unpack its own python code anywhere to run, so if the filesystem is busted it has a better chance of getting somewhere&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;but note that it currently still needs to extract the web-resources somewhere (they'll land in the default TEMP-folder of your OS)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;install on android&lt;/h1&gt; 
&lt;p&gt;install &lt;a href="https://termux.com/"&gt;Termux&lt;/a&gt; + its companion app &lt;code&gt;Termux:API&lt;/code&gt; (see &lt;a href="https://ocv.me/termux/"&gt;ocv.me/termux&lt;/a&gt;) and then copy-paste this into Termux (long-tap) all at once:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;yes | pkg upgrade &amp;amp;&amp;amp; termux-setup-storage &amp;amp;&amp;amp; yes | pkg install python termux-api &amp;amp;&amp;amp; python -m ensurepip &amp;amp;&amp;amp; python -m pip install --user -U copyparty &amp;amp;&amp;amp; { grep -qE 'PATH=.*\.local/bin' ~/.bashrc 2&amp;gt;/dev/null || { echo 'PATH="$HOME/.local/bin:$PATH"' &amp;gt;&amp;gt; ~/.bashrc &amp;amp;&amp;amp; . ~/.bashrc; }; }
echo $?
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;after the initial setup, you can launch copyparty at any time by running &lt;code&gt;copyparty&lt;/code&gt; anywhere in Termux -- and if you run it with &lt;code&gt;--qr&lt;/code&gt; you'll get a &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/#qr-code"&gt;neat qr-code&lt;/a&gt; pointing to your external ip&lt;/p&gt; 
&lt;p&gt;if you want thumbnails (photos+videos) and you're okay with spending another 132 MiB of storage, &lt;code&gt;pkg install ffmpeg &amp;amp;&amp;amp; python3 -m pip install --user -U pillow&lt;/code&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;or if you want to use &lt;code&gt;vips&lt;/code&gt; for photo-thumbs instead, &lt;code&gt;pkg install libvips &amp;amp;&amp;amp; python -m pip install --user -U wheel &amp;amp;&amp;amp; python -m pip install --user -U pyvips &amp;amp;&amp;amp; (cd /data/data/com.termux/files/usr/lib/; ln -s libgobject-2.0.so{,.0}; ln -s libvips.so{,.42})&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;reporting bugs&lt;/h1&gt; 
&lt;p&gt;ideas for context to include, and where to submit them&lt;/p&gt; 
&lt;p&gt;please get in touch using any of the following URLs:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/9001/copyparty/"&gt;https://github.com/9001/copyparty/&lt;/a&gt; &lt;strong&gt;(primary)&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://gitlab.com/9001/copyparty/"&gt;https://gitlab.com/9001/copyparty/&lt;/a&gt; &lt;em&gt;(mirror)&lt;/em&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://codeberg.org/9001/copyparty"&gt;https://codeberg.org/9001/copyparty&lt;/a&gt; &lt;em&gt;(mirror)&lt;/em&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;in general, commandline arguments (and config file if any)&lt;/p&gt; 
&lt;p&gt;if something broke during an upload (replacing FILENAME with a part of the filename that broke):&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;journalctl -aS '48 hour ago' -u copyparty | grep -C10 FILENAME | tee bug.log
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;if there's a wall of base64 in the log (thread stacks) then please include that, especially if you run into something freezing up or getting stuck, for example &lt;code&gt;OperationalError('database is locked')&lt;/code&gt; -- alternatively you can visit &lt;code&gt;/?stack&lt;/code&gt; to see the stacks live, so &lt;a href="http://127.0.0.1:3923/?stack"&gt;http://127.0.0.1:3923/?stack&lt;/a&gt; for example&lt;/p&gt; 
&lt;h1&gt;devnotes&lt;/h1&gt; 
&lt;p&gt;for build instructions etc, see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/docs/devnotes.md"&gt;./docs/devnotes.md&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;specifically you may want to &lt;a href="https://github.com/9001/copyparty/raw/hovudstraum/docs/devnotes.md#just-the-sfx"&gt;build the sfx&lt;/a&gt; or &lt;a href="https://github.com/9001/copyparty/raw/hovudstraum/docs/devnotes.md#build-from-scratch"&gt;build from scratch&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;see &lt;a href="https://raw.githubusercontent.com/9001/copyparty/hovudstraum/docs/TODO.md"&gt;./docs/TODO.md&lt;/a&gt; for planned features / fixes / changes&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>stanford-oval/storm</title>
      <link>https://github.com/stanford-oval/storm</link>
      <description>&lt;p&gt;An LLM-powered knowledge curation system that researches a topic and generates a full-length report with citations.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/stanford-oval/storm/main/assets/logo.svg?sanitize=true" style="width: 25%; height: auto;"&gt; &lt;/p&gt; 
&lt;h1&gt;STORM: Synthesis of Topic Outlines through Retrieval and Multi-perspective Question Asking&lt;/h1&gt; 
&lt;p align="center"&gt; | &lt;a href="http://storm.genie.stanford.edu"&gt;&lt;b&gt;Research preview&lt;/b&gt;&lt;/a&gt; | &lt;a href="https://arxiv.org/abs/2402.14207"&gt;&lt;b&gt;STORM Paper&lt;/b&gt;&lt;/a&gt;| &lt;a href="https://www.arxiv.org/abs/2408.15232"&gt;&lt;b&gt;Co-STORM Paper&lt;/b&gt;&lt;/a&gt; | &lt;a href="https://storm-project.stanford.edu/"&gt;&lt;b&gt;Website&lt;/b&gt;&lt;/a&gt; | &lt;/p&gt; **Latest News** 🔥 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;[2025/01] We add &lt;a href="https://github.com/BerriAI/litellm"&gt;litellm&lt;/a&gt; integration for language models and embedding models in &lt;code&gt;knowledge-storm&lt;/code&gt; v1.1.0.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;[2024/09] Co-STORM codebase is now released and integrated into &lt;code&gt;knowledge-storm&lt;/code&gt; python package v1.0.0. Run &lt;code&gt;pip install knowledge-storm --upgrade&lt;/code&gt; to check it out.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;[2024/09] We introduce collaborative STORM (Co-STORM) to support human-AI collaborative knowledge curation! &lt;a href="https://www.arxiv.org/abs/2408.15232"&gt;Co-STORM Paper&lt;/a&gt; has been accepted to EMNLP 2024 main conference.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;[2024/07] You can now install our package with &lt;code&gt;pip install knowledge-storm&lt;/code&gt;!&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;[2024/07] We add &lt;code&gt;VectorRM&lt;/code&gt; to support grounding on user-provided documents, complementing existing support of search engines (&lt;code&gt;YouRM&lt;/code&gt;, &lt;code&gt;BingSearch&lt;/code&gt;). (check out &lt;a href="https://github.com/stanford-oval/storm/pull/58"&gt;#58&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;[2024/07] We release demo light for developers a minimal user interface built with streamlit framework in Python, handy for local development and demo hosting (checkout &lt;a href="https://github.com/stanford-oval/storm/pull/54"&gt;#54&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;[2024/06] We will present STORM at NAACL 2024! Find us at Poster Session 2 on June 17 or check our &lt;a href="https://raw.githubusercontent.com/stanford-oval/storm/main/assets/storm_naacl2024_slides.pdf"&gt;presentation material&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;[2024/05] We add Bing Search support in &lt;a href="https://raw.githubusercontent.com/stanford-oval/storm/main/knowledge_storm/rm.py"&gt;rm.py&lt;/a&gt;. Test STORM with &lt;code&gt;GPT-4o&lt;/code&gt; - we now configure the article generation part in our demo using &lt;code&gt;GPT-4o&lt;/code&gt; model.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;[2024/04] We release refactored version of STORM codebase! We define &lt;a href="https://raw.githubusercontent.com/stanford-oval/storm/main/knowledge_storm/interface.py"&gt;interface&lt;/a&gt; for STORM pipeline and reimplement STORM-wiki (check out &lt;a href="https://raw.githubusercontent.com/stanford-oval/storm/main/knowledge_storm/storm_wiki"&gt;&lt;code&gt;src/storm_wiki&lt;/code&gt;&lt;/a&gt;) to demonstrate how to instantiate the pipeline. We provide API to support customization of different language models and retrieval/search integration.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://github.com/psf/black"&gt;&lt;img src="https://img.shields.io/badge/code%20style-black-000000.svg?sanitize=true" alt="Code style: black"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Overview &lt;a href="https://storm.genie.stanford.edu/"&gt;(Try STORM now!)&lt;/a&gt;&lt;/h2&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/stanford-oval/storm/main/assets/overview.svg?sanitize=true" style="width: 90%; height: auto;"&gt; &lt;/p&gt; STORM is a LLM system that writes Wikipedia-like articles from scratch based on Internet search. Co-STORM further enhanced its feature by enabling human to collaborative LLM system to support more aligned and preferred information seeking and knowledge curation. 
&lt;p&gt;While the system cannot produce publication-ready articles that often require a significant number of edits, experienced Wikipedia editors have found it helpful in their pre-writing stage.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;More than 70,000 people have tried our &lt;a href="https://storm.genie.stanford.edu/"&gt;live research preview&lt;/a&gt;. Try it out to see how STORM can help your knowledge exploration journey and please provide feedback to help us improve the system 🙏!&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;How STORM &amp;amp; Co-STORM works&lt;/h2&gt; 
&lt;h3&gt;STORM&lt;/h3&gt; 
&lt;p&gt;STORM breaks down generating long articles with citations into two steps:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Pre-writing stage&lt;/strong&gt;: The system conducts Internet-based research to collect references and generates an outline.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Writing stage&lt;/strong&gt;: The system uses the outline and references to generate the full-length article with citations.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/stanford-oval/storm/main/assets/two_stages.jpg" style="width: 60%; height: auto;"&gt; &lt;/p&gt; 
&lt;p&gt;STORM identifies the core of automating the research process as automatically coming up with good questions to ask. Directly prompting the language model to ask questions does not work well. To improve the depth and breadth of the questions, STORM adopts two strategies:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Perspective-Guided Question Asking&lt;/strong&gt;: Given the input topic, STORM discovers different perspectives by surveying existing articles from similar topics and uses them to control the question-asking process.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Simulated Conversation&lt;/strong&gt;: STORM simulates a conversation between a Wikipedia writer and a topic expert grounded in Internet sources to enable the language model to update its understanding of the topic and ask follow-up questions.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;CO-STORM&lt;/h3&gt; 
&lt;p&gt;Co-STORM proposes &lt;strong&gt;a collaborative discourse protocol&lt;/strong&gt; which implements a turn management policy to support smooth collaboration among&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Co-STORM LLM experts&lt;/strong&gt;: This type of agent generates answers grounded on external knowledge sources and/or raises follow-up questions based on the discourse history.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Moderator&lt;/strong&gt;: This agent generates thought-provoking questions inspired by information discovered by the retriever but not directly used in previous turns. Question generation can also be grounded!&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Human user&lt;/strong&gt;: The human user will take the initiative to either (1) observe the discourse to gain deeper understanding of the topic, or (2) actively engage in the conversation by injecting utterances to steer the discussion focus.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/stanford-oval/storm/main/assets/co-storm-workflow.jpg" style="width: 60%; height: auto;"&gt; &lt;/p&gt; 
&lt;p&gt;Co-STORM also maintains a dynamic updated &lt;strong&gt;mind map&lt;/strong&gt;, which organize collected information into a hierarchical concept structure, aiming to &lt;strong&gt;build a shared conceptual space between the human user and the system&lt;/strong&gt;. The mind map has been proven to help reduce the mental load when the discourse goes long and in-depth.&lt;/p&gt; 
&lt;p&gt;Both STORM and Co-STORM are implemented in a highly modular way using &lt;a href="https://github.com/stanfordnlp/dspy"&gt;dspy&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;To install the knowledge storm library, use &lt;code&gt;pip install knowledge-storm&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;You could also install the source code which allows you to modify the behavior of STORM engine directly.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Clone the git repository.&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;git clone https://github.com/stanford-oval/storm.git
cd storm
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Install the required packages.&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;conda create -n storm python=3.11
conda activate storm
pip install -r requirements.txt
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;API&lt;/h2&gt; 
&lt;p&gt;Currently, our package support:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Language model components: All language models supported by litellm as listed &lt;a href="https://docs.litellm.ai/docs/providers"&gt;here&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Embedding model components: All embedding models supported by litellm as listed &lt;a href="https://docs.litellm.ai/docs/embedding/supported_embedding"&gt;here&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;retrieval module components: &lt;code&gt;YouRM&lt;/code&gt;, &lt;code&gt;BingSearch&lt;/code&gt;, &lt;code&gt;VectorRM&lt;/code&gt;, &lt;code&gt;SerperRM&lt;/code&gt;, &lt;code&gt;BraveRM&lt;/code&gt;, &lt;code&gt;SearXNG&lt;/code&gt;, &lt;code&gt;DuckDuckGoSearchRM&lt;/code&gt;, &lt;code&gt;TavilySearchRM&lt;/code&gt;, &lt;code&gt;GoogleSearch&lt;/code&gt;, and &lt;code&gt;AzureAISearch&lt;/code&gt; as&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span&gt;🌟&lt;/span&gt; &lt;strong&gt;PRs for integrating more search engines/retrievers into &lt;a href="https://raw.githubusercontent.com/stanford-oval/storm/main/knowledge_storm/rm.py"&gt;knowledge_storm/rm.py&lt;/a&gt; are highly appreciated!&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Both STORM and Co-STORM are working in the information curation layer, you need to set up the information retrieval module and language model module to create their &lt;code&gt;Runner&lt;/code&gt; classes respectively.&lt;/p&gt; 
&lt;h3&gt;STORM&lt;/h3&gt; 
&lt;p&gt;The STORM knowledge curation engine is defined as a simple Python &lt;code&gt;STORMWikiRunner&lt;/code&gt; class. Here is an example of using You.com search engine and OpenAI models.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import os
from knowledge_storm import STORMWikiRunnerArguments, STORMWikiRunner, STORMWikiLMConfigs
from knowledge_storm.lm import LitellmModel
from knowledge_storm.rm import YouRM

lm_configs = STORMWikiLMConfigs()
openai_kwargs = {
    'api_key': os.getenv("OPENAI_API_KEY"),
    'temperature': 1.0,
    'top_p': 0.9,
}
# STORM is a LM system so different components can be powered by different models to reach a good balance between cost and quality.
# For a good practice, choose a cheaper/faster model for `conv_simulator_lm` which is used to split queries, synthesize answers in the conversation.
# Choose a more powerful model for `article_gen_lm` to generate verifiable text with citations.
gpt_35 = LitellmModel(model='gpt-3.5-turbo', max_tokens=500, **openai_kwargs)
gpt_4 = LitellmModel(model='gpt-4o', max_tokens=3000, **openai_kwargs)
lm_configs.set_conv_simulator_lm(gpt_35)
lm_configs.set_question_asker_lm(gpt_35)
lm_configs.set_outline_gen_lm(gpt_4)
lm_configs.set_article_gen_lm(gpt_4)
lm_configs.set_article_polish_lm(gpt_4)
# Check out the STORMWikiRunnerArguments class for more configurations.
engine_args = STORMWikiRunnerArguments(...)
rm = YouRM(ydc_api_key=os.getenv('YDC_API_KEY'), k=engine_args.search_top_k)
runner = STORMWikiRunner(engine_args, lm_configs, rm)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The &lt;code&gt;STORMWikiRunner&lt;/code&gt; instance can be evoked with the simple &lt;code&gt;run&lt;/code&gt; method:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;topic = input('Topic: ')
runner.run(
    topic=topic,
    do_research=True,
    do_generate_outline=True,
    do_generate_article=True,
    do_polish_article=True,
)
runner.post_run()
runner.summary()
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;do_research&lt;/code&gt;: if True, simulate conversations with difference perspectives to collect information about the topic; otherwise, load the results.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;do_generate_outline&lt;/code&gt;: if True, generate an outline for the topic; otherwise, load the results.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;do_generate_article&lt;/code&gt;: if True, generate an article for the topic based on the outline and the collected information; otherwise, load the results.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;do_polish_article&lt;/code&gt;: if True, polish the article by adding a summarization section and (optionally) removing duplicate content; otherwise, load the results.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Co-STORM&lt;/h3&gt; 
&lt;p&gt;The Co-STORM knowledge curation engine is defined as a simple Python &lt;code&gt;CoStormRunner&lt;/code&gt; class. Here is an example of using Bing search engine and OpenAI models.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from knowledge_storm.collaborative_storm.engine import CollaborativeStormLMConfigs, RunnerArgument, CoStormRunner
from knowledge_storm.lm import LitellmModel
from knowledge_storm.logging_wrapper import LoggingWrapper
from knowledge_storm.rm import BingSearch

# Co-STORM adopts the same multi LM system paradigm as STORM 
lm_config: CollaborativeStormLMConfigs = CollaborativeStormLMConfigs()
openai_kwargs = {
    "api_key": os.getenv("OPENAI_API_KEY"),
    "api_provider": "openai",
    "temperature": 1.0,
    "top_p": 0.9,
    "api_base": None,
} 
question_answering_lm = LitellmModel(model=gpt_4o_model_name, max_tokens=1000, **openai_kwargs)
discourse_manage_lm = LitellmModel(model=gpt_4o_model_name, max_tokens=500, **openai_kwargs)
utterance_polishing_lm = LitellmModel(model=gpt_4o_model_name, max_tokens=2000, **openai_kwargs)
warmstart_outline_gen_lm = LitellmModel(model=gpt_4o_model_name, max_tokens=500, **openai_kwargs)
question_asking_lm = LitellmModel(model=gpt_4o_model_name, max_tokens=300, **openai_kwargs)
knowledge_base_lm = LitellmModel(model=gpt_4o_model_name, max_tokens=1000, **openai_kwargs)

lm_config.set_question_answering_lm(question_answering_lm)
lm_config.set_discourse_manage_lm(discourse_manage_lm)
lm_config.set_utterance_polishing_lm(utterance_polishing_lm)
lm_config.set_warmstart_outline_gen_lm(warmstart_outline_gen_lm)
lm_config.set_question_asking_lm(question_asking_lm)
lm_config.set_knowledge_base_lm(knowledge_base_lm)

# Check out the Co-STORM's RunnerArguments class for more configurations.
topic = input('Topic: ')
runner_argument = RunnerArgument(topic=topic, ...)
logging_wrapper = LoggingWrapper(lm_config)
bing_rm = BingSearch(bing_search_api_key=os.environ.get("BING_SEARCH_API_KEY"),
                     k=runner_argument.retrieve_top_k)
costorm_runner = CoStormRunner(lm_config=lm_config,
                               runner_argument=runner_argument,
                               logging_wrapper=logging_wrapper,
                               rm=bing_rm)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The &lt;code&gt;CoStormRunner&lt;/code&gt; instance can be evoked with the &lt;code&gt;warmstart()&lt;/code&gt; and &lt;code&gt;step(...)&lt;/code&gt; methods.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# Warm start the system to build shared conceptual space between Co-STORM and users
costorm_runner.warm_start()

# Step through the collaborative discourse 
# Run either of the code snippets below in any order, as many times as you'd like
# To observe the conversation:
conv_turn = costorm_runner.step()
# To inject your utterance to actively steer the conversation:
costorm_runner.step(user_utterance="YOUR UTTERANCE HERE")

# Generate report based on the collaborative discourse
costorm_runner.knowledge_base.reorganize()
article = costorm_runner.generate_report()
print(article)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Quick Start with Example Scripts&lt;/h2&gt; 
&lt;p&gt;We provide scripts in our &lt;a href="https://raw.githubusercontent.com/stanford-oval/storm/main/examples"&gt;examples folder&lt;/a&gt; as a quick start to run STORM and Co-STORM with different configurations.&lt;/p&gt; 
&lt;p&gt;We suggest using &lt;code&gt;secrets.toml&lt;/code&gt; to set up the API keys. Create a file &lt;code&gt;secrets.toml&lt;/code&gt; under the root directory and add the following content:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;# ============ language model configurations ============ 
# Set up OpenAI API key.
OPENAI_API_KEY="your_openai_api_key"
# If you are using the API service provided by OpenAI, include the following line:
OPENAI_API_TYPE="openai"
# If you are using the API service provided by Microsoft Azure, include the following lines:
OPENAI_API_TYPE="azure"
AZURE_API_BASE="your_azure_api_base_url"
AZURE_API_VERSION="your_azure_api_version"
# ============ retriever configurations ============ 
BING_SEARCH_API_KEY="your_bing_search_api_key" # if using bing search
# ============ encoder configurations ============ 
ENCODER_API_TYPE="openai" # if using openai encoder
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;STORM examples&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;To run STORM with &lt;code&gt;gpt&lt;/code&gt; family models with default configurations:&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Run the following command.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python examples/storm_examples/run_storm_wiki_gpt.py \
    --output-dir $OUTPUT_DIR \
    --retriever bing \
    --do-research \
    --do-generate-outline \
    --do-generate-article \
    --do-polish-article
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;To run STORM using your favorite language models or grounding on your own corpus:&lt;/strong&gt; Check out &lt;a href="https://raw.githubusercontent.com/stanford-oval/storm/main/examples/storm_examples/README.md"&gt;examples/storm_examples/README.md&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Co-STORM examples&lt;/h3&gt; 
&lt;p&gt;To run Co-STORM with &lt;code&gt;gpt&lt;/code&gt; family models with default configurations,&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Add &lt;code&gt;BING_SEARCH_API_KEY="xxx"&lt;/code&gt; and &lt;code&gt;ENCODER_API_TYPE="xxx"&lt;/code&gt; to &lt;code&gt;secrets.toml&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Run the following command&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python examples/costorm_examples/run_costorm_gpt.py \
    --output-dir $OUTPUT_DIR \
    --retriever bing
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Customization of the Pipeline&lt;/h2&gt; 
&lt;h3&gt;STORM&lt;/h3&gt; 
&lt;p&gt;If you have installed the source code, you can customize STORM based on your own use case. STORM engine consists of 4 modules:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Knowledge Curation Module: Collects a broad coverage of information about the given topic.&lt;/li&gt; 
 &lt;li&gt;Outline Generation Module: Organizes the collected information by generating a hierarchical outline for the curated knowledge.&lt;/li&gt; 
 &lt;li&gt;Article Generation Module: Populates the generated outline with the collected information.&lt;/li&gt; 
 &lt;li&gt;Article Polishing Module: Refines and enhances the written article for better presentation.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;The interface for each module is defined in &lt;code&gt;knowledge_storm/interface.py&lt;/code&gt;, while their implementations are instantiated in &lt;code&gt;knowledge_storm/storm_wiki/modules/*&lt;/code&gt;. These modules can be customized according to your specific requirements (e.g., generating sections in bullet point format instead of full paragraphs).&lt;/p&gt; 
&lt;h3&gt;Co-STORM&lt;/h3&gt; 
&lt;p&gt;If you have installed the source code, you can customize Co-STORM based on your own use case&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Co-STORM introduces multiple LLM agent types (i.e. Co-STORM experts and Moderator). LLM agent interface is defined in &lt;code&gt;knowledge_storm/interface.py&lt;/code&gt; , while its implementation is instantiated in &lt;code&gt;knowledge_storm/collaborative_storm/modules/co_storm_agents.py&lt;/code&gt;. Different LLM agent policies can be customized.&lt;/li&gt; 
 &lt;li&gt;Co-STORM introduces a collaborative discourse protocol, with its core function centered on turn policy management. We provide an example implementation of turn policy management through &lt;code&gt;DiscourseManager&lt;/code&gt; in &lt;code&gt;knowledge_storm/collaborative_storm/engine.py&lt;/code&gt;. It can be customized and further improved.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Datasets&lt;/h2&gt; 
&lt;p&gt;To facilitate the study of automatic knowledge curation and complex information seeking, our project releases the following datasets:&lt;/p&gt; 
&lt;h3&gt;FreshWiki&lt;/h3&gt; 
&lt;p&gt;The FreshWiki Dataset is a collection of 100 high-quality Wikipedia articles focusing on the most-edited pages from February 2022 to September 2023. See Section 2.1 in &lt;a href="https://arxiv.org/abs/2402.14207"&gt;STORM paper&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;p&gt;You can download the dataset from &lt;a href="https://huggingface.co/datasets/EchoShao8899/FreshWiki"&gt;huggingface&lt;/a&gt; directly. To ease the data contamination issue, we archive the &lt;a href="https://github.com/stanford-oval/storm/tree/NAACL-2024-code-backup/FreshWiki"&gt;source code&lt;/a&gt; for the data construction pipeline that can be repeated at future dates.&lt;/p&gt; 
&lt;h3&gt;WildSeek&lt;/h3&gt; 
&lt;p&gt;To study users’ interests in complex information seeking tasks in the wild, we utilized data collected from the web research preview to create the WildSeek dataset. We downsampled the data to ensure the diversity of the topics and the quality of the data. Each data point is a pair comprising a topic and the user’s goal for conducting deep search on the topic. For more details, please refer to Section 2.2 and Appendix A of &lt;a href="https://www.arxiv.org/abs/2408.15232"&gt;Co-STORM paper&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;The WildSeek dataset is available &lt;a href="https://huggingface.co/datasets/YuchengJiang/WildSeek"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Replicate STORM &amp;amp; Co-STORM paper result&lt;/h2&gt; 
&lt;p&gt;For STORM paper experiments, please switch to the branch &lt;code&gt;NAACL-2024-code-backup&lt;/code&gt; &lt;a href="https://github.com/stanford-oval/storm/tree/NAACL-2024-code-backup"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;For Co-STORM paper experiments, please switch to the branch &lt;code&gt;EMNLP-2024-code-backup&lt;/code&gt; (placeholder for now, will be updated soon).&lt;/p&gt; 
&lt;h2&gt;Roadmap &amp;amp; Contributions&lt;/h2&gt; 
&lt;p&gt;Our team is actively working on:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Human-in-the-Loop Functionalities: Supporting user participation in the knowledge curation process.&lt;/li&gt; 
 &lt;li&gt;Information Abstraction: Developing abstractions for curated information to support presentation formats beyond the Wikipedia-style report.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;If you have any questions or suggestions, please feel free to open an issue or pull request. We welcome contributions to improve the system and the codebase!&lt;/p&gt; 
&lt;p&gt;Contact person: &lt;a href="mailto:shaoyj@stanford.edu"&gt;Yijia Shao&lt;/a&gt; and &lt;a href="mailto:yuchengj@stanford.edu"&gt;Yucheng Jiang&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Acknowledgement&lt;/h2&gt; 
&lt;p&gt;We would like to thank Wikipedia for its excellent open-source content. The FreshWiki dataset is sourced from Wikipedia, licensed under the Creative Commons Attribution-ShareAlike (CC BY-SA) license.&lt;/p&gt; 
&lt;p&gt;We are very grateful to &lt;a href="https://michelle123lam.github.io/"&gt;Michelle Lam&lt;/a&gt; for designing the logo for this project and &lt;a href="https://dekun.me"&gt;Dekun Ma&lt;/a&gt; for leading the UI development.&lt;/p&gt; 
&lt;p&gt;Thanks to Vercel for their support of &lt;a href="https://storm.genie.stanford.edu"&gt;open-source software&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Citation&lt;/h2&gt; 
&lt;p&gt;Please cite our paper if you use this code or part of it in your work:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bibtex"&gt;@inproceedings{jiang-etal-2024-unknown,
    title = "Into the Unknown Unknowns: Engaged Human Learning through Participation in Language Model Agent Conversations",
    author = "Jiang, Yucheng  and
      Shao, Yijia  and
      Ma, Dekun  and
      Semnani, Sina  and
      Lam, Monica",
    editor = "Al-Onaizan, Yaser  and
      Bansal, Mohit  and
      Chen, Yun-Nung",
    booktitle = "Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2024",
    address = "Miami, Florida, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.emnlp-main.554/",
    doi = "10.18653/v1/2024.emnlp-main.554",
    pages = "9917--9955",
}

@inproceedings{shao-etal-2024-assisting,
    title = "Assisting in Writing {W}ikipedia-like Articles From Scratch with Large Language Models",
    author = "Shao, Yijia  and
      Jiang, Yucheng  and
      Kanell, Theodore  and
      Xu, Peter  and
      Khattab, Omar  and
      Lam, Monica",
    editor = "Duh, Kevin  and
      Gomez, Helena  and
      Bethard, Steven",
    booktitle = "Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)",
    month = jun,
    year = "2024",
    address = "Mexico City, Mexico",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.naacl-long.347/",
    doi = "10.18653/v1/2024.naacl-long.347",
    pages = "6252--6278",
}
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>OpenPipe/ART</title>
      <link>https://github.com/OpenPipe/ART</link>
      <description>&lt;p&gt;Agent Reinforcement Trainer: train multi-step agents for real-world tasks using GRPO. Give your agents on-the-job training. Reinforcement learning for Qwen2.5, Qwen3, Llama, Kimi, and more!&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://art.openpipe.ai"&gt;
   &lt;picture&gt; 
    &lt;img alt="ART logo" src="https://github.com/openpipe/art/raw/main/assets/ART_logo.png" width="160px"&gt; 
   &lt;/picture&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p align="center"&gt; &lt;/p&gt;
 &lt;h1&gt;Agent Reinforcement Trainer&lt;/h1&gt; 
 &lt;p&gt;&lt;/p&gt; 
 &lt;p&gt; Train multi-step agents for real-world tasks using GRPO. &lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://github.com/openpipe/art/raw/main/CONTRIBUTING.md"&gt;&lt;img src="https://img.shields.io/badge/PRs-welcome-blue.svg?sanitize=true" alt="PRs-Welcome"&gt;&lt;/a&gt; &lt;a href="https://pypi.org/project/openpipe-art/"&gt;&lt;img src="https://img.shields.io/pypi/dm/openpipe-art?color=364fc7&amp;amp;logoColor=364fc7" alt="Downloads"&gt;&lt;/a&gt; &lt;a href="https://colab.research.google.com/github/openpipe/art/blob/main/examples/2048/2048.ipynb"&gt;&lt;img src="https://colab.research.google.com/assets/colab-badge.svg?sanitize=true" alt="Train Agent"&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://discord.gg/zbBHRUpwf4"&gt;&lt;img src="https://img.shields.io/badge/Join%20Discord-5865F2?style=plastic&amp;amp;logo=discord&amp;amp;logoColor=white" alt="Join Discord"&gt;&lt;/a&gt; &lt;a href="https://art.openpipe.ai"&gt;&lt;img src="https://img.shields.io/badge/Documentation-orange?style=plastic&amp;amp;logo=gitbook&amp;amp;logoColor=white" alt="Documentation"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;📏 RULER: Zero-Shot Agent Rewards&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;RULER&lt;/strong&gt; (Relative Universal LLM-Elicited Rewards) eliminates the need for hand-crafted reward functions by using an LLM-as-judge to automatically score agent trajectories. Simply define your task in the system prompt, and RULER handles the rest—&lt;strong&gt;no labeled data, expert feedback, or reward engineering required&lt;/strong&gt;.&lt;/p&gt; 
&lt;p&gt;✨ &lt;strong&gt;Key Benefits:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;2-3x faster development&lt;/strong&gt; - Skip reward function engineering entirely&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;General-purpose&lt;/strong&gt; - Works across any task without modification&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Strong performance&lt;/strong&gt; - Matches or exceeds hand-crafted rewards in 3/4 benchmarks&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Easy integration&lt;/strong&gt; - Drop-in replacement for manual reward functions&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# Before: Hours of reward engineering
def complex_reward_function(trajectory):
    # 50+ lines of careful scoring logic...
    pass

# After: One line with RULER
judged_group = await ruler_score_group(group, "openai/o3")
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;a href="https://art.openpipe.ai/fundamentals/ruler"&gt;📖 Learn more about RULER →&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;ART Overview&lt;/h2&gt; 
&lt;p&gt;ART is an open-source RL framework that improves agent reliability by allowing LLMs to &lt;strong&gt;learn from experience&lt;/strong&gt;. ART provides an ergonomic harness for integrating GRPO into any python application. For a quick hands-on introduction, run one of the notebooks below. When you're ready to learn more, check out the &lt;a href="https://art.openpipe.ai"&gt;docs&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;📒 Notebooks&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Agent Task&lt;/th&gt; 
   &lt;th&gt;Example Notebook&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Comparative Performance&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;ART•E [RULER]&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://colab.research.google.com/github/openpipe/art/blob/main/examples/art-e/art-e.ipynb"&gt;🏋️ Train agent&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Qwen 2.5 7B learns to search emails using RULER&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://github.com/openpipe/art/raw/main/assets/benchmarks/email_agent/accuracy-training-progress.svg?sanitize=true" height="72"&gt; &lt;a href="https://raw.githubusercontent.com/OpenPipe/ART/main/examples/art-e/art_e/evaluate/display_benchmarks.ipynb"&gt;benchmarks&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;2048&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://colab.research.google.com/github/openpipe/art/blob/main/examples/2048/2048.ipynb"&gt;🏋️ Train agent&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Qwen 2.5 3B learns to play 2048&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://github.com/openpipe/art/raw/main/assets/benchmarks/2048/accuracy-training-progress.svg?sanitize=true" height="72"&gt; &lt;a href="https://raw.githubusercontent.com/OpenPipe/ART/main/examples/2048/benchmark_2048.ipynb"&gt;benchmarks&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Temporal Clue&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://colab.research.google.com/github/openpipe/art/blob/main/examples/temporal_clue/temporal-clue.ipynb"&gt;🏋️ Train agent&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Qwen 2.5 7B learns to solve Temporal Clue&lt;/td&gt; 
   &lt;td&gt;[Link coming soon]&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Tic Tac Toe&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://colab.research.google.com/github/openpipe/art/blob/main/examples/tic_tac_toe/tic-tac-toe.ipynb"&gt;🏋️ Train agent&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Qwen 2.5 3B learns to play Tic Tac Toe&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://github.com/openpipe/art/raw/main/assets/benchmarks/tic-tac-toe-local/accuracy-training-progress.svg?sanitize=true" height="72"&gt; &lt;a href="https://raw.githubusercontent.com/OpenPipe/ART/main/examples/tic_tac_toe/benchmark_tic_tac_toe.ipynb"&gt;benchmarks&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Codenames&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://colab.research.google.com/github/openpipe/art/blob/main/examples/codenames/Codenames_RL.ipynb"&gt;🏋️ Train agent&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Qwen 2.5 3B learns to play Codenames&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://github.com/openpipe/art/raw/main/assets/benchmarks/codenames/win_rate_over_time.png" height="72"&gt; &lt;a href="https://raw.githubusercontent.com/OpenPipe/ART/main/examples/codenames/Codenames_RL.ipynb"&gt;benchmarks&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;AutoRL [RULER]&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://colab.research.google.com/github/openpipe/art/blob/main/examples/auto_rl.ipynb"&gt;🏋️ Train agent&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Train Qwen 2.5 7B to master any task&lt;/td&gt; 
   &lt;td&gt;[Link coming soon]&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;📰 ART News&lt;/h2&gt; 
&lt;p&gt;Explore our latest research and updates on building SOTA agents.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;🗞️ &lt;strong&gt;&lt;a href="https://x.com/mattshumer_/status/1950572449025650733"&gt;AutoRL: Zero-Data Training for Any Task&lt;/a&gt;&lt;/strong&gt; - Train custom AI models without labeled data using automatic input generation and RULER evaluation.&lt;/li&gt; 
 &lt;li&gt;🗞️ &lt;strong&gt;&lt;a href="https://openpipe.ai/blog/ruler-easy-mode-for-rl-rewards"&gt;RULER: Easy Mode for RL Rewards&lt;/a&gt;&lt;/strong&gt; is now available for automatic reward generation in reinforcement learning.&lt;/li&gt; 
 &lt;li&gt;🗞️ &lt;strong&gt;&lt;a href="https://openpipe.ai/blog/art-e-mail-agent"&gt;ART·E: How We Built an Email Research Agent That Beats o3&lt;/a&gt;&lt;/strong&gt; demonstrates a Qwen 2.5 14B email agent outperforming OpenAI's o3.&lt;/li&gt; 
 &lt;li&gt;🗞️ &lt;strong&gt;&lt;a href="https://openpipe.ai/blog/art-trainer"&gt;ART Trainer: A New RL Trainer for Agents&lt;/a&gt;&lt;/strong&gt; enables easy training of LLM-based agents using GRPO.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://openpipe.ai/blog"&gt;📖 See all blog posts →&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Why ART?&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;ART provides convenient wrappers for introducing RL training into &lt;strong&gt;existing applications&lt;/strong&gt;. We abstract the training server into a modular service that your code doesn't need to interface with.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Train from anywhere.&lt;/strong&gt; Run the ART client on your laptop and let the ART server kick off an ephemeral GPU-enabled environment, or run on a local GPU.&lt;/li&gt; 
 &lt;li&gt;Integrations with hosted platforms like W&amp;amp;B, Langfuse, and OpenPipe provide flexible observability and &lt;strong&gt;simplify debugging&lt;/strong&gt;.&lt;/li&gt; 
 &lt;li&gt;ART is customizable with &lt;strong&gt;intelligent defaults&lt;/strong&gt;. You can configure training parameters and inference engine configurations to meet specific needs, or take advantage of the defaults, which have been optimized for training efficiency and stability.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;ART agents can be trained from any client machine that runs python. To add to an existing project, run this command:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;pip install openpipe-art
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;🤖 ART•E Agent&lt;/h2&gt; 
&lt;p&gt;Curious about how to use ART for a real-world task? Check out the &lt;a href="https://openpipe.ai/blog/art-e-mail-agent"&gt;ART•E Agent&lt;/a&gt; blog post, where we detail how we trained Qwen 2.5 14B to beat o3 at email retrieval!&lt;/p&gt; 
&lt;img src="https://github.com/openpipe/art/raw/main/assets/ART_E_graphs.png" width="700"&gt; 
&lt;h2&gt;🔁 Training Loop Overview&lt;/h2&gt; 
&lt;p&gt;ART's functionality is divided into a &lt;strong&gt;client&lt;/strong&gt; and a &lt;strong&gt;server&lt;/strong&gt;. The OpenAI-compatible client is responsible for interfacing between ART and your codebase. Using the client, you can pass messages and get completions from your LLM as it improves. The server runs independently on any machine with a GPU. It abstracts away the complexity of the inference and training portions of the RL loop while allowing for some custom configuration. An outline of the training loop is shown below:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Inference&lt;/strong&gt;&lt;/p&gt; 
  &lt;ol&gt; 
   &lt;li&gt;Your code uses the ART client to perform an agentic workflow (usually executing several rollouts in parallel to gather data faster).&lt;/li&gt; 
   &lt;li&gt;Completion requests are routed to the ART server, which runs the model's latest LoRA in vLLM.&lt;/li&gt; 
   &lt;li&gt;As the agent executes, each &lt;code&gt;system&lt;/code&gt;, &lt;code&gt;user&lt;/code&gt;, and &lt;code&gt;assistant&lt;/code&gt; message is stored in a Trajectory.&lt;/li&gt; 
   &lt;li&gt;When a rollout finishes, your code assigns a &lt;code&gt;reward&lt;/code&gt; to its Trajectory, indicating the performance of the LLM.&lt;/li&gt; 
  &lt;/ol&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Training&lt;/strong&gt;&lt;/p&gt; 
  &lt;ol&gt; 
   &lt;li&gt;When each rollout has finished, Trajectories are grouped and sent to the server. Inference is blocked while training executes.&lt;/li&gt; 
   &lt;li&gt;The server trains your model using GRPO, initializing from the latest checkpoint (or an empty LoRA on the first iteration).&lt;/li&gt; 
   &lt;li&gt;The server saves the newly trained LoRA to a local directory and loads it into vLLM.&lt;/li&gt; 
   &lt;li&gt;Inference is unblocked and the loop resumes at step 1.&lt;/li&gt; 
  &lt;/ol&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;This training loop runs until a specified number of inference and training iterations have completed.&lt;/p&gt; 
&lt;h2&gt;🧩 Supported Models&lt;/h2&gt; 
&lt;p&gt;ART should work with most vLLM/HuggingFace-transformers compatible causal language models, or at least the ones supported by &lt;a href="https://docs.unsloth.ai/get-started/all-our-models"&gt;Unsloth&lt;/a&gt;. Gemma 3 does not appear to be supported for the time being. If any other model isn't working for you, please let us know on &lt;a href="https://discord.gg/zbBHRUpwf4"&gt;Discord&lt;/a&gt; or open an issue on &lt;a href="https://github.com/openpipe/art/issues"&gt;GitHub&lt;/a&gt;!&lt;/p&gt; 
&lt;h2&gt;🤝 Contributing&lt;/h2&gt; 
&lt;p&gt;ART is in active development, and contributions are most welcome! Please see the &lt;a href="https://raw.githubusercontent.com/OpenPipe/ART/main/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; file for more information.&lt;/p&gt; 
&lt;h2&gt;📖 Citation&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bibtex"&gt;@misc{hilton2025art,
  author = {Brad Hilton and Kyle Corbitt and David Corbitt and Saumya Gandhi and Angky William and Bohdan Kovalenskyi and Andie Jones},
  title = {ART: Agent Reinforcement Trainer},
  year = {2025},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/openpipe/art}}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;⚖️ License&lt;/h2&gt; 
&lt;p&gt;This repository's source code is available under the &lt;a href="https://raw.githubusercontent.com/OpenPipe/ART/main/LICENSE"&gt;Apache-2.0 License&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;🙏 Credits&lt;/h2&gt; 
&lt;p&gt;ART stands on the shoulders of giants. While we owe many of the ideas and early experiments that led to ART's development to the open source RL community at large, we're especially grateful to the authors of the following projects:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/unslothai/unsloth"&gt;Unsloth&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/vllm-project/vllm"&gt;vLLM&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/huggingface/trl"&gt;trl&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pytorch/torchtune"&gt;torchtune&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/skypilot-org/skypilot"&gt;SkyPilot&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Finally, thank you to our partners who've helped us test ART in the wild! We're excited to see what you all build with it.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>kijai/ComfyUI-WanVideoWrapper</title>
      <link>https://github.com/kijai/ComfyUI-WanVideoWrapper</link>
      <description>&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;ComfyUI wrapper nodes for &lt;a href="https://github.com/Wan-Video/Wan2.1"&gt;WanVideo&lt;/a&gt; and related models.&lt;/h1&gt; 
&lt;h1&gt;WORK IN PROGRESS (perpetually)&lt;/h1&gt; 
&lt;h1&gt;Why should I use custom nodes when WanVideo works natively?&lt;/h1&gt; 
&lt;p&gt;Short answer: Unless it's a model/feature not available yet on native, you shouldn't.&lt;/p&gt; 
&lt;p&gt;Long answer: Due to the complexity of ComfyUI core code, and my lack of coding experience, in many cases it's far easier and faster to implement new models and features to a standalone wrapper, so this is a way to test things relatively quickly. I consider this my personal sandbox (which is obviously open for everyone) to play with without having to worry about compability issues etc, but as such this code is always work in progress and prone to have issues. Also not all new models end up being worth the trouble to implement in core Comfy, though I've also made some patcher nodes to allow using them in native workflows, such as the &lt;a href="https://huggingface.co/bytedance-research/ATI"&gt;ATI&lt;/a&gt; node available in this wrapper. This is also the end goal, idea isn't to compete or even offer alternatives to everything available in native workflows. All that said (this is clearly not a sales pitch) I do appreciate everyone using these nodes to explore new releases and possibilities with WanVideo.&lt;/p&gt; 
&lt;h1&gt;Installation&lt;/h1&gt; 
&lt;ol&gt; 
 &lt;li&gt;Clone this repo into &lt;code&gt;custom_nodes&lt;/code&gt; folder.&lt;/li&gt; 
 &lt;li&gt;Install dependencies: &lt;code&gt;pip install -r requirements.txt&lt;/code&gt; or if you use the portable install, run this in ComfyUI_windows_portable -folder:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;code&gt;python_embeded\python.exe -m pip install -r ComfyUI\custom_nodes\ComfyUI-WanVideoWrapper\requirements.txt&lt;/code&gt;&lt;/p&gt; 
&lt;h2&gt;Models&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://huggingface.co/Kijai/WanVideo_comfy/tree/main"&gt;https://huggingface.co/Kijai/WanVideo_comfy/tree/main&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;fp8 scaled models (personal recommendation):&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://huggingface.co/Kijai/WanVideo_comfy_fp8_scaled"&gt;https://huggingface.co/Kijai/WanVideo_comfy_fp8_scaled&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Text encoders to &lt;code&gt;ComfyUI/models/text_encoders&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;Clip vision to &lt;code&gt;ComfyUI/models/clip_vision&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;Transformer (main video model) to &lt;code&gt;ComfyUI/models/diffusion_models&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;Vae to &lt;code&gt;ComfyUI/models/vae&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;You can also use the native ComfyUI text encoding and clip vision loader with the wrapper instead of the original models:&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/6a2fd9a5-8163-4c93-b362-92ef34dbd3a4" alt="image"&gt;&lt;/p&gt; 
&lt;p&gt;GGUF models can now be loaded in the main model loader as well.&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;Supported extra models:&lt;/p&gt; 
&lt;p&gt;SkyReels: &lt;a href="https://huggingface.co/collections/Skywork/skyreels-v2-6801b1b93df627d441d0d0d9"&gt;https://huggingface.co/collections/Skywork/skyreels-v2-6801b1b93df627d441d0d0d9&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;WanVideoFun: &lt;a href="https://huggingface.co/collections/alibaba-pai/wan21-fun-v11-680f514c89fe7b4df9d44f17"&gt;https://huggingface.co/collections/alibaba-pai/wan21-fun-v11-680f514c89fe7b4df9d44f17&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;ReCamMaster: &lt;a href="https://github.com/KwaiVGI/ReCamMaster"&gt;https://github.com/KwaiVGI/ReCamMaster&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;VACE: &lt;a href="https://github.com/ali-vilab/VACE"&gt;https://github.com/ali-vilab/VACE&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Phantom: &lt;a href="https://huggingface.co/bytedance-research/Phantom"&gt;https://huggingface.co/bytedance-research/Phantom&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;ATI: &lt;a href="https://huggingface.co/bytedance-research/ATI"&gt;https://huggingface.co/bytedance-research/ATI&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Uni3C: &lt;a href="https://github.com/alibaba-damo-academy/Uni3C"&gt;https://github.com/alibaba-damo-academy/Uni3C&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;MiniMaxRemover: &lt;a href="https://huggingface.co/zibojia/minimax-remover"&gt;https://huggingface.co/zibojia/minimax-remover&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;MAGREF: &lt;a href="https://huggingface.co/MAGREF-Video/MAGREF"&gt;https://huggingface.co/MAGREF-Video/MAGREF&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;FantasyTalking: &lt;a href="https://github.com/Fantasy-AMAP/fantasy-talking"&gt;https://github.com/Fantasy-AMAP/fantasy-talking&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;MultiTalk: &lt;a href="https://github.com/MeiGen-AI/MultiTalk"&gt;https://github.com/MeiGen-AI/MultiTalk&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;EchoShot: &lt;a href="https://github.com/D2I-ai/EchoShot"&gt;https://github.com/D2I-ai/EchoShot&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Examples:&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://github.com/KwaiVGI/ReCamMaster"&gt;ReCamMaster&lt;/a&gt;:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/c58a12c2-13ba-4af8-8041-e283dbef197e"&gt;https://github.com/user-attachments/assets/c58a12c2-13ba-4af8-8041-e283dbef197e&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;TeaCache (with the old temporary WIP naive version, I2V):&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Note that with the new version the threshold values should be 10x higher&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Range of 0.25-0.30 seems good when using the coefficients, start step can be 0, with more aggressive threshold values it may make sense to start later to avoid any potential step skips early on, that generally ruin the motion.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/504a9a50-3337-43d2-97b8-8e1661f29f46"&gt;https://github.com/user-attachments/assets/504a9a50-3337-43d2-97b8-8e1661f29f46&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Context window test:&lt;/p&gt; 
&lt;p&gt;1025 frames using window size of 81 frames, with 16 overlap. With the 1.3B T2V model this used under 5GB VRAM and took 10 minutes to gen on a 5090:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/89b393af-cf1b-49ae-aa29-23e57f65911e"&gt;https://github.com/user-attachments/assets/89b393af-cf1b-49ae-aa29-23e57f65911e&lt;/a&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;This very first test was 512x512x81&lt;/p&gt; 
&lt;p&gt;~16GB used with 20/40 blocks offloaded&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/fa6d0a4f-4a4d-4de5-84a4-877cc37b715f"&gt;https://github.com/user-attachments/assets/fa6d0a4f-4a4d-4de5-84a4-877cc37b715f&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Vid2vid example:&lt;/p&gt; 
&lt;p&gt;with 14B T2V model:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/ef228b8a-a13a-4327-8a1b-1eb343cf00d8"&gt;https://github.com/user-attachments/assets/ef228b8a-a13a-4327-8a1b-1eb343cf00d8&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;with 1.3B T2V model&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/4f35ba84-da7a-4d5b-97ee-9641296f391e"&gt;https://github.com/user-attachments/assets/4f35ba84-da7a-4d5b-97ee-9641296f391e&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>galaxyproject/galaxy</title>
      <link>https://github.com/galaxyproject/galaxy</link>
      <description>&lt;p&gt;Data intensive science for everyone.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;.. figure:: &lt;a href="https://galaxyproject.org/images/galaxy-logos/galaxy_project_logo.jpg"&gt;https://galaxyproject.org/images/galaxy-logos/galaxy_project_logo.jpg&lt;/a&gt; :alt: Galaxy Logo&lt;/p&gt; 
&lt;p&gt;The latest information about Galaxy can be found on the &lt;code&gt;Galaxy Community Hub &amp;lt;https://galaxyproject.org/&amp;gt;&lt;/code&gt;__.&lt;/p&gt; 
&lt;p&gt;Community support is available at &lt;code&gt;Galaxy Help &amp;lt;https://help.galaxyproject.org/&amp;gt;&lt;/code&gt;__.&lt;/p&gt; 
&lt;p&gt;.. image:: &lt;a href="https://img.shields.io/badge/chat-gitter-blue.svg"&gt;https://img.shields.io/badge/chat-gitter-blue.svg&lt;/a&gt; :target: &lt;a href="https://gitter.im/galaxyproject/Lobby"&gt;https://gitter.im/galaxyproject/Lobby&lt;/a&gt; :alt: Chat on gitter&lt;/p&gt; 
&lt;p&gt;.. image:: &lt;a href="https://img.shields.io/badge/chat-irc.freenode.net%23galaxyproject-blue.svg"&gt;https://img.shields.io/badge/chat-irc.freenode.net%23galaxyproject-blue.svg&lt;/a&gt; :target: &lt;a href="https://webchat.freenode.net/?channels=galaxyproject"&gt;https://webchat.freenode.net/?channels=galaxyproject&lt;/a&gt; :alt: Chat on irc&lt;/p&gt; 
&lt;p&gt;.. image:: &lt;a href="https://img.shields.io/badge/release-documentation-blue.svg"&gt;https://img.shields.io/badge/release-documentation-blue.svg&lt;/a&gt; :target: &lt;a href="https://docs.galaxyproject.org/en/master/"&gt;https://docs.galaxyproject.org/en/master/&lt;/a&gt; :alt: Release Documentation&lt;/p&gt; 
&lt;p&gt;.. image:: &lt;a href="https://travis-ci.org/galaxyproject/galaxy.svg?branch=dev"&gt;https://travis-ci.org/galaxyproject/galaxy.svg?branch=dev&lt;/a&gt; :target: &lt;a href="https://travis-ci.org/galaxyproject/galaxy"&gt;https://travis-ci.org/galaxyproject/galaxy&lt;/a&gt; :alt: Inspect the test results&lt;/p&gt; 
&lt;h1&gt;Galaxy Quickstart&lt;/h1&gt; 
&lt;p&gt;Galaxy requires Python 3.9 or higher. To check your Python version, run:&lt;/p&gt; 
&lt;p&gt;.. code:: console&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ python -V
Python 3.9.21
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Start Galaxy:&lt;/p&gt; 
&lt;p&gt;.. code:: console&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ sh run.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Once Galaxy completes startup, you should be able to view Galaxy in your browser at: &lt;a href="http://localhost:8080"&gt;http://localhost:8080&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;For more installation details please see: &lt;a href="https://getgalaxy.org/"&gt;https://getgalaxy.org/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Documentation is available at: &lt;a href="https://docs.galaxyproject.org/"&gt;https://docs.galaxyproject.org/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Tutorials on how to use Galaxy, perform scientific analyses with it, develop Galaxy and its tools, and admin a Galaxy server are at: &lt;a href="https://training.galaxyproject.org/"&gt;https://training.galaxyproject.org/&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Tools&lt;/h1&gt; 
&lt;p&gt;Tools can be either installed from the Tool Shed or added manually. For details please see the &lt;code&gt;tutorial &amp;lt;https://galaxyproject.org/admin/tools/add-tool-from-toolshed-tutorial/&amp;gt;&lt;/code&gt;__. Note that not all dependencies for the tools provided in the &lt;code&gt;tool_conf.xml.sample&lt;/code&gt; are included. To install them please visit "Manage dependencies" in the admin interface.&lt;/p&gt; 
&lt;h1&gt;Issues and Galaxy Development&lt;/h1&gt; 
&lt;p&gt;Please see &lt;code&gt;CONTRIBUTING.md &amp;lt;CONTRIBUTING.md&amp;gt;&lt;/code&gt;_ .&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Alibaba-NLP/WebAgent</title>
      <link>https://github.com/Alibaba-NLP/WebAgent</link>
      <description>&lt;p&gt;🌐 WebAgent for Information Seeking built by Tongyi Lab: WebWalker &amp; WebDancer &amp; WebSailor &amp; WebShaper https://arxiv.org/abs/2507.15061 https://arxiv.org/pdf/2507.02592&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;h2&gt;WebAgent for Information Seeking built by Tongyi Lab, Alibaba Group &lt;img src="https://raw.githubusercontent.com/Alibaba-NLP/WebAgent/main/assets/tongyi.png" width="30px" style="display:inline;"&gt;&lt;/h2&gt; 
&lt;/div&gt; 
&lt;p align="center"&gt; &lt;a href="https://trendshift.io/repositories/14217" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/14217" alt="Alibaba-NLP%2FWebAgent | Trendshift" style="width: 250px; height: 55px;" width="250" height="55"&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; 🤗 &lt;a href="https://huggingface.co/datasets/Alibaba-NLP/WebShaper" target="_blank"&gt;WebShaperQA&lt;/a&gt; ｜ &lt;img src="https://raw.githubusercontent.com/Alibaba-NLP/WebAgent/main/assets/tongyi.png" width="14px" style="display:inline;"&gt; &lt;a href="https://modelscope.cn/datasets/iic/WebShaper" target="_blank"&gt;WebShaperQA&lt;/a&gt; ｜ 🤗 &lt;a href="https://huggingface.co/Alibaba-NLP/WebSailor-3B" target="_blank"&gt;WebSailor-3B&lt;/a&gt; ｜ &lt;img src="https://raw.githubusercontent.com/Alibaba-NLP/WebAgent/main/assets/tongyi.png" width="14px" style="display:inline;"&gt; &lt;a href="https://modelscope.cn/models/iic/WebSailor-3B" target="_blank"&gt;ModelScope WebSailor-3B&lt;/a&gt; | &lt;/p&gt; 
&lt;p align="center"&gt; 🤗 &lt;a href="https://huggingface.co/Alibaba-NLP/WebDancer-32B" target="_blank"&gt;WebDancer-QwQ-32B&lt;/a&gt; | &lt;img src="https://raw.githubusercontent.com/Alibaba-NLP/WebAgent/main/assets/tongyi.png" width="14px" style="display:inline;"&gt; &lt;a href="https://modelscope.cn/models/iic/WebDancer-32B" target="_blank"&gt;ModelScope WebDancer-QwQ-32B&lt;/a&gt; | 🤗 &lt;a href="https://huggingface.co/datasets/callanwu/WebWalkerQA" target="_blank"&gt;WebWalkerQA&lt;/a&gt; &lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/Alibaba-NLP/WebAgent/main/assets/roadmap.png" width="100%" height="400%"&gt; &lt;/p&gt; 
&lt;/div&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;You can check the paper of &lt;a href="https://arxiv.org/pdf/2505.22648"&gt;WebDancer&lt;/a&gt; and &lt;a href="https://arxiv.org/pdf/2501.07572"&gt;WebWalker&lt;/a&gt; and &lt;a href="https://arxiv.org/pdf/2507.02592"&gt;WebSailor&lt;/a&gt; and &lt;a href="https://arxiv.org/pdf/2507.15061"&gt;WebShaper&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;💥 💥 💥 Stay tuned for more updates! We are working on building native agentic model based on the Browser and more open-domain environments!&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Alibaba-NLP/WebAgent/main/WebShaper"&gt;&lt;strong&gt;WebShaper&lt;/strong&gt;&lt;/a&gt; (Preprint 2025) - WebShaper: Agentically Data Synthesizing via Information-Seeking Formalization&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Alibaba-NLP/WebAgent/main/WebSailor"&gt;&lt;strong&gt;WebSailor&lt;/strong&gt;&lt;/a&gt; (Preprint 2025) - WebSailor: Navigating Super-human Reasoning for Web Agent&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Alibaba-NLP/WebAgent/main/WebDancer"&gt;&lt;strong&gt;WebDancer&lt;/strong&gt;&lt;/a&gt; (Preprint 2025) - WebDancer: Towards Autonomous Information Seeking Agency&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Alibaba-NLP/WebAgent/main/WebWalker"&gt;&lt;strong&gt;WebWalker&lt;/strong&gt;&lt;/a&gt; (ACL 2025) - WebWalker: Benchmarking LLMs in Web Traversal&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;📰 News and Updates&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;2025.07.22&lt;/code&gt; 🔥🔥🔥We release &lt;strong&gt;WebShaper&lt;/strong&gt;: Agentically Data Synthesizing via Information-Seeking Formalization.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;2025.07.11&lt;/code&gt; 🔥🔥🔥&lt;strong&gt;WebSailor-3B&lt;/strong&gt; is &lt;a href="https://huggingface.co/Alibaba-NLP/WebSailor-3B"&gt;released&lt;/a&gt;. You can deploy it with one click using &lt;img src="https://raw.githubusercontent.com/Alibaba-NLP/WebAgent/main/assets/aliyun.png" width="14px" style="display:inline;"&gt; &lt;a href="https://functionai.console.aliyun.com/template-detail?template=Alibaba-NLP-WebSailor-3B"&gt;Alibaba Cloud's FunctionAI&lt;/a&gt; in ten minutes!&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;2025.07.03&lt;/code&gt; 🔥🔥🔥We release &lt;strong&gt;WebSailor&lt;/strong&gt;, an agentic search model specialized in performing extremely complex information seeking tasks, achieving open-source SOTA on some of the most difficult browsing benchmarks. &lt;strong&gt;WebSailor&lt;/strong&gt; topped the HuggingFace &lt;a href="https://huggingface.co/papers/2507.02592"&gt;daily papers&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;2025.06.23&lt;/code&gt; 🔥🔥🔥The model, interactive demo, and some of the data of &lt;strong&gt;WebDancer&lt;/strong&gt; have been open-sourced. You're welcome to try them out!&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;2025.05.29&lt;/code&gt; 🔥🔥🔥We release &lt;strong&gt;WebDancer&lt;/strong&gt;, a native agentic search model towards autonomous information seeking agency and &lt;em&gt;Deep Research&lt;/em&gt;-like model.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;2025.05.15&lt;/code&gt; &lt;strong&gt;WebWalker&lt;/strong&gt; is accepted by ACL 2025 main conference.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;2025.01.14&lt;/code&gt; We release &lt;strong&gt;WebWalker&lt;/strong&gt;, a benchmark for LLMs in web traversal and a multi-agent framework for information seeking.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;💎 Results Showcase&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/Alibaba-NLP/WebAgent/main/assets/webagent-gaia.png" width="800%" height="400%"&gt; &lt;/p&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/Alibaba-NLP/WebAgent/main/assets/webagent-bc.png" width="800%" height="400%"&gt; &lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;💡 Features for WebShaper&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;A &lt;strong&gt;&lt;code&gt;formalization-driven&lt;/code&gt;&lt;/strong&gt; data synthesis method for information-seeking agents, grounded in our proposed task formalization. Leveraging this method, we construct the &lt;strong&gt;WebShaper&lt;/strong&gt; dataset, which enables systematic generation of IS instances.&lt;/li&gt; 
 &lt;li&gt;We propose an agentic Expander that iteratively generates and validates questions in alignment with the formalization.&lt;/li&gt; 
 &lt;li&gt;We conduct extensive experiments across multiple benchmarks to evaluate the effectiveness of WebShaper. We achieve new state-of-the-art results on &lt;strong&gt;GAIA&lt;/strong&gt; (&lt;strong&gt;60.19&lt;/strong&gt;) and &lt;strong&gt;WebWalkerQA&lt;/strong&gt; (&lt;strong&gt;52.50&lt;/strong&gt;) benchmarks.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;⛵️ Features for WebSailor&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;A complete post-training methodology enabling models to engage in extended thinking and information seeking, ultimately allowing them to successfully complete extremely complex tasks previously considered unsolvable.&lt;/li&gt; 
 &lt;li&gt;Introduces &lt;strong&gt;SailorFog-QA&lt;/strong&gt;, a scalable QA benchmark with high uncertainty and difficulty, curated with a novel data synthesis method through graph sampling and information obfuscation. Example SailorFog-QA data samples can be found at: &lt;a href="https://raw.githubusercontent.com/Alibaba-NLP/WebAgent/main/WebSailor/dataset/sailorfog-QA.jsonl"&gt;&lt;code&gt;WebSailor/dataset/sailorfog-QA.jsonl&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Effective post-training pipeline consisting of (1) high-quality reconstruction of concise reasoning from expert trajectories for clean supervision, (2) a two-stage training process involving an RFT cold start stage, followed by &lt;strong&gt;Duplicating Sampling Policy Optimization (DUPO)&lt;/strong&gt;, an efficient agentic RL algorithm excelling in effectiveness and efficiency.&lt;/li&gt; 
 &lt;li&gt;WebSailor-72B significantly outperforms all open-source agents and frameworks while closing the performance gap with leading proprietary systems, achieving a score of &lt;strong&gt;12.0%&lt;/strong&gt; on BrowseComp-en, &lt;strong&gt;30.1%&lt;/strong&gt; on BrowseComp-zh, and &lt;strong&gt;55.4%&lt;/strong&gt; on GAIA.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;The checkpoint is coming soon.&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;🌐 Features for WebDancer&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Native agentic search reasoning model using ReAct framework towards autonomous information seeking agency and &lt;em&gt;Deep Research&lt;/em&gt;-like model.&lt;/li&gt; 
 &lt;li&gt;We introduce a four-stage training paradigm comprising &lt;strong&gt;browsing data construction, trajectory sampling, supervised fine-tuning for effective cold start, and reinforcement learning for improved generalization&lt;/strong&gt;, enabling the agent to autonomously acquire autonomous search and reasoning skills.&lt;/li&gt; 
 &lt;li&gt;Our data-centric approach integrates trajectory-level supervision fine-tuning and reinforcement learning (DAPO) to develop a scalable pipeline for &lt;strong&gt;training agentic systems&lt;/strong&gt; via SFT or RL.&lt;/li&gt; 
 &lt;li&gt;WebDancer achieves a Pass@3 score of 64.1% on GAIA and 62.0% on WebWalkerQA.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;🚀 Quick Start&lt;/h2&gt; 
&lt;p&gt;You need to enter the &lt;a href="https://raw.githubusercontent.com/Alibaba-NLP/WebAgent/main/WebDancer"&gt;&lt;code&gt;WebDancer&lt;/code&gt;&lt;/a&gt; folder for the following commands.&lt;/p&gt; 
&lt;h3&gt;Step 0: Set Up the Environment&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;conda create -n webdancer python=3.12
pip install -r requirements.txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Step 1: Deploy the Model&lt;/h3&gt; 
&lt;p&gt;Download the WebDancer model from &lt;a href="https://huggingface.co/Alibaba-NLP/WebDancer-32B"&gt;🤗 HuggingFace&lt;/a&gt; and deploy it using the provided scripts with &lt;a href="https://github.com/sgl-project/sglang"&gt;sglang&lt;/a&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd scripts
bash deploy_model.sh WebDancer_PATH
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; Replace &lt;code&gt;WebDancer_PATH&lt;/code&gt; with the actual path to the downloaded model.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Step 2: Run the Demo&lt;/h3&gt; 
&lt;p&gt;Edit the following keys in &lt;a href="https://raw.githubusercontent.com/Alibaba-NLP/WebAgent/main/WebDancer/scripts/run_demo.sh"&gt;&lt;code&gt;WebDancer/scripts/run_demo.sh&lt;/code&gt;&lt;/a&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;GOOGLE_SEARCH_KEY&lt;/code&gt;, you can get it from &lt;a href="https://serper.dev/"&gt;serper&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;JINA_API_KEY&lt;/code&gt;, you can get it from &lt;a href="https://jina.ai/api-dashboard/"&gt;jina&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;DASHSCOPE_API_KEY&lt;/code&gt;, you can get it from &lt;a href="https://dashscope.aliyun.com/"&gt;dashscope&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Then, launch the demo with Gradio to interact with the WebDancer model:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd scripts
bash run_demo.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;🎥 WebSailor Demos&lt;/h2&gt; 
&lt;p&gt;We provide demos for BrowseComp-en, BrowseComp-zh and Daily Use. Our model can complete highly difficult and uncertain tasks requiring massive information acquisition and complex reasoning.&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;h3&gt;BrowseComp-en&lt;/h3&gt; 
 &lt;video src="https://github.com/user-attachments/assets/2dc0b03a-c241-4f70-bf11-92fda28020fa"&gt;&lt;/video&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;h3&gt;BrowseComp-zh&lt;/h3&gt; 
 &lt;video src="https://github.com/user-attachments/assets/f9aed746-ffc8-4b76-b135-715ec0eab544"&gt;&lt;/video&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;h3&gt;Daily Use&lt;/h3&gt; 
 &lt;video src="https://github.com/user-attachments/assets/1299c5a8-cee3-4a70-b68b-c5d227cf8055"&gt;&lt;/video&gt; 
&lt;/div&gt; 
&lt;h2&gt;🎥 WebDancer Demos&lt;/h2&gt; 
&lt;p&gt;We provide demos for WebWalkerQA, GAIA and Daily Use. Our model can execute the long-horizon tasks with &lt;strong&gt;multiple steps&lt;/strong&gt; and &lt;strong&gt;complex reasoning&lt;/strong&gt;, such as web traversal, information seeking and question answering.&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;h3&gt;WebWalkerQA&lt;/h3&gt; 
 &lt;video src="https://github.com/user-attachments/assets/0bbaf55b-897e-4c57-967d-a6e8bbd2167e"&gt;&lt;/video&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;h3&gt;GAIA&lt;/h3&gt; 
 &lt;video src="https://github.com/user-attachments/assets/935c668e-6169-4712-9c04-ac80f0531872"&gt;&lt;/video&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;h3&gt;Daily Use&lt;/h3&gt; 
 &lt;video src="https://github.com/user-attachments/assets/d1d5b533-4009-478b-bd87-96b86389327d"&gt;&lt;/video&gt; 
&lt;/div&gt; 
&lt;h2&gt;📃 License&lt;/h2&gt; 
&lt;p&gt;The content of this project itself is licensed under &lt;a href="https://raw.githubusercontent.com/Alibaba-NLP/WebAgent/main/LICENSE"&gt;LICENSE&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;🚩 Citation&lt;/h2&gt; 
&lt;p&gt;If this work is helpful, please kindly cite as:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bigquery"&gt;@misc{tao2025webshaper,
      title={WebShaper: Agentically Data Synthesizing via Information-Seeking Formalization},
      author={Zhengwei Tao and Jialong Wu and Wenbiao Yin and Junkai Zhang and Baixuan Li and Haiyang Shen and Kuan Li and Liwen Zhang and Xinyu Wang and Yong Jiang and Pengjun Xie and Fei Huang and Jingren Zhou},
      year={2025},
      eprint={2507.15061},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2507.15061},
}
@misc{li2025websailor,
      title={WebSailor: Navigating Super-human Reasoning for Web Agent},
      author={Kuan Li and Zhongwang Zhang and Huifeng Yin and Liwen Zhang and Litu Ou and Jialong Wu and Wenbiao Yin and Baixuan Li and Zhengwei Tao and Xinyu Wang and Weizhou Shen and Junkai Zhang and Dingchu Zhang and Xixi Wu and Yong Jiang and Ming Yan and Pengjun Xie and Fei Huang and Jingren Zhou},
      year={2025},
      eprint={2507.02592},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2507.02592},
}
@misc{wu2025webdancer,
      title={WebDancer: Towards Autonomous Information Seeking Agency},
      author={Jialong Wu and Baixuan Li and Runnan Fang and Wenbiao Yin and Liwen Zhang and Zhengwei Tao and Dingchu Zhang and Zekun Xi and Yong Jiang and Pengjun Xie and Fei Huang and Jingren Zhou},
      year={2025},
      eprint={2505.22648},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2505.22648},
}
@misc{wu2025webwalker,
      title={WebWalker: Benchmarking LLMs in Web Traversal},
      author={Jialong Wu and Wenbiao Yin and Yong Jiang and Zhenglin Wang and Zekun Xi and Runnan Fang and Deyu Zhou and Pengjun Xie and Fei Huang},
      year={2025},
      eprint={2501.07572},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2501.07572},
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;🌟 Misc&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://www.star-history.com/#Alibaba-NLP/WebAgent&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=Alibaba-NLP/WebAgent&amp;amp;type=Date" alt="Star History Chart"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;🚩 Talent Recruitment&lt;/h2&gt; 
&lt;p&gt;🔥🔥🔥 We are hiring! Research intern positions are open (based in Hangzhou、Beijing、Shanghai)&lt;/p&gt; 
&lt;p&gt;📚 &lt;strong&gt;Research Area&lt;/strong&gt;：Web Agent, Search Agent, Agent RL, MultiAgent RL, Agentic RAG&lt;/p&gt; 
&lt;p&gt;☎️ &lt;strong&gt;Contact&lt;/strong&gt;：&lt;a href=""&gt;yongjiang.jy@alibaba-inc.com&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Contact Information&lt;/h2&gt; 
&lt;p&gt;For communications, please contact Yong Jiang (&lt;a href="mailto:yongjiang.jy@alibaba-inc.com"&gt;yongjiang.jy@alibaba-inc.com&lt;/a&gt;).&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>google-deepmind/alphafold3</title>
      <link>https://github.com/google-deepmind/alphafold3</link>
      <description>&lt;p&gt;AlphaFold 3 inference pipeline.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/google-deepmind/alphafold3/main/docs/header.jpg" alt="header"&gt;&lt;/p&gt; 
&lt;h1&gt;AlphaFold 3&lt;/h1&gt; 
&lt;p&gt;This package provides an implementation of the inference pipeline of AlphaFold 3. See below for how to access the model parameters. You may only use AlphaFold 3 model parameters if received directly from Google. Use is subject to these &lt;a href="https://github.com/google-deepmind/alphafold3/raw/main/WEIGHTS_TERMS_OF_USE.md"&gt;terms of use&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Any publication that discloses findings arising from using this source code, the model parameters or outputs produced by those should &lt;a href="https://raw.githubusercontent.com/google-deepmind/alphafold3/main/#citing-this-work"&gt;cite&lt;/a&gt; the &lt;a href="https://doi.org/10.1038/s41586-024-07487-w"&gt;Accurate structure prediction of biomolecular interactions with AlphaFold 3&lt;/a&gt; paper.&lt;/p&gt; 
&lt;p&gt;Please also refer to the Supplementary Information for a detailed description of the method.&lt;/p&gt; 
&lt;p&gt;AlphaFold 3 is also available at &lt;a href="https://alphafoldserver.com"&gt;alphafoldserver.com&lt;/a&gt; for non-commercial use, though with a more limited set of ligands and covalent modifications.&lt;/p&gt; 
&lt;p&gt;If you have any questions, please contact the AlphaFold team at &lt;a href="mailto:alphafold@google.com"&gt;alphafold@google.com&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Obtaining Model Parameters&lt;/h2&gt; 
&lt;p&gt;This repository contains all necessary code for AlphaFold 3 inference. To request access to the AlphaFold 3 model parameters, please complete &lt;a href="https://forms.gle/svvpY4u2jsHEwWYS6"&gt;this form&lt;/a&gt;. Access will be granted at Google DeepMind’s sole discretion. We will aim to respond to requests within 2–3 business days. You may only use AlphaFold 3 model parameters if received directly from Google. Use is subject to these &lt;a href="https://github.com/google-deepmind/alphafold3/raw/main/WEIGHTS_TERMS_OF_USE.md"&gt;terms of use&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Installation and Running Your First Prediction&lt;/h2&gt; 
&lt;p&gt;See the &lt;a href="https://raw.githubusercontent.com/google-deepmind/alphafold3/main/docs/installation.md"&gt;installation documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Once you have installed AlphaFold 3, you can test your setup using e.g. the following input JSON file named &lt;code&gt;fold_input.json&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "name": "2PV7",
  "sequences": [
    {
      "protein": {
        "id": ["A", "B"],
        "sequence": "GMRESYANENQFGFKTINSDIHKIVIVGGYGKLGGLFARYLRASGYPISILDREDWAVAESILANADVVIVSVPINLTLETIERLKPYLTENMLLADLTSVKREPLAKMLEVHTGAVLGLHPMFGADIASMAKQVVVRCDGRFPERYEWLLEQIQIWGAKIYQTNATEHDHNMTYIQALRHFSTFANGLHLSKQPINLANLLALSSPIYRLELAMIGRLFAQDAELYADIIMDKSENLAVIETLKQTYDEALTFFENNDRQGFIDAFHKVRDWFGDYSEQFLKESRQLLQQANDLKQG"
      }
    }
  ],
  "modelSeeds": [1],
  "dialect": "alphafold3",
  "version": 1
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can then run AlphaFold 3 using the following command:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;docker run -it \
    --volume $HOME/af_input:/root/af_input \
    --volume $HOME/af_output:/root/af_output \
    --volume &amp;lt;MODEL_PARAMETERS_DIR&amp;gt;:/root/models \
    --volume &amp;lt;DATABASES_DIR&amp;gt;:/root/public_databases \
    --gpus all \
    alphafold3 \
    python run_alphafold.py \
    --json_path=/root/af_input/fold_input.json \
    --model_dir=/root/models \
    --output_dir=/root/af_output
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;There are various flags that you can pass to the &lt;code&gt;run_alphafold.py&lt;/code&gt; command, to list them all run &lt;code&gt;python run_alphafold.py --help&lt;/code&gt;. Two fundamental flags that control which parts AlphaFold 3 will run are:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;--run_data_pipeline&lt;/code&gt; (defaults to &lt;code&gt;true&lt;/code&gt;): whether to run the data pipeline, i.e. genetic and template search. This part is CPU-only, time consuming and could be run on a machine without a GPU.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--run_inference&lt;/code&gt; (defaults to &lt;code&gt;true&lt;/code&gt;): whether to run the inference. This part requires a GPU.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;AlphaFold 3 Input&lt;/h2&gt; 
&lt;p&gt;See the &lt;a href="https://raw.githubusercontent.com/google-deepmind/alphafold3/main/docs/input.md"&gt;input documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;AlphaFold 3 Output&lt;/h2&gt; 
&lt;p&gt;See the &lt;a href="https://raw.githubusercontent.com/google-deepmind/alphafold3/main/docs/output.md"&gt;output documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Performance&lt;/h2&gt; 
&lt;p&gt;See the &lt;a href="https://raw.githubusercontent.com/google-deepmind/alphafold3/main/docs/performance.md"&gt;performance documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Known Issues&lt;/h2&gt; 
&lt;p&gt;Known issues are documented in the &lt;a href="https://raw.githubusercontent.com/google-deepmind/alphafold3/main/docs/known_issues.md"&gt;known issues documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Please &lt;a href="https://github.com/google-deepmind/alphafold3/issues/new/choose"&gt;create an issue&lt;/a&gt; if it is not already listed in &lt;a href="https://raw.githubusercontent.com/google-deepmind/alphafold3/main/docs/known_issues.md"&gt;Known Issues&lt;/a&gt; or in the &lt;a href="https://github.com/google-deepmind/alphafold3/issues"&gt;issues tracker&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Citing This Work&lt;/h2&gt; 
&lt;p&gt;Any publication that discloses findings arising from using this source code, the model parameters or outputs produced by those should cite:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bibtex"&gt;@article{Abramson2024,
  author  = {Abramson, Josh and Adler, Jonas and Dunger, Jack and Evans, Richard and Green, Tim and Pritzel, Alexander and Ronneberger, Olaf and Willmore, Lindsay and Ballard, Andrew J. and Bambrick, Joshua and Bodenstein, Sebastian W. and Evans, David A. and Hung, Chia-Chun and O’Neill, Michael and Reiman, David and Tunyasuvunakool, Kathryn and Wu, Zachary and Žemgulytė, Akvilė and Arvaniti, Eirini and Beattie, Charles and Bertolli, Ottavia and Bridgland, Alex and Cherepanov, Alexey and Congreve, Miles and Cowen-Rivers, Alexander I. and Cowie, Andrew and Figurnov, Michael and Fuchs, Fabian B. and Gladman, Hannah and Jain, Rishub and Khan, Yousuf A. and Low, Caroline M. R. and Perlin, Kuba and Potapenko, Anna and Savy, Pascal and Singh, Sukhdeep and Stecula, Adrian and Thillaisundaram, Ashok and Tong, Catherine and Yakneen, Sergei and Zhong, Ellen D. and Zielinski, Michal and Žídek, Augustin and Bapst, Victor and Kohli, Pushmeet and Jaderberg, Max and Hassabis, Demis and Jumper, John M.},
  journal = {Nature},
  title   = {Accurate structure prediction of biomolecular interactions with AlphaFold 3},
  year    = {2024},
  volume  = {630},
  number  = {8016},
  pages   = {493–-500},
  doi     = {10.1038/s41586-024-07487-w}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Acknowledgements&lt;/h2&gt; 
&lt;p&gt;AlphaFold 3's release was made possible by the invaluable contributions of the following people:&lt;/p&gt; 
&lt;p&gt;Andrew&amp;nbsp;Cowie, Bella&amp;nbsp;Hansen, Charlie&amp;nbsp;Beattie, Chris&amp;nbsp;Jones, Grace&amp;nbsp;Margand, Jacob&amp;nbsp;Kelly, James&amp;nbsp;Spencer, Josh&amp;nbsp;Abramson, Kathryn&amp;nbsp;Tunyasuvunakool, Kuba&amp;nbsp;Perlin, Lindsay&amp;nbsp;Willmore, Max&amp;nbsp;Bileschi, Molly&amp;nbsp;Beck, Oleg&amp;nbsp;Kovalevskiy, Sebastian&amp;nbsp;Bodenstein, Sukhdeep&amp;nbsp;Singh, Tim&amp;nbsp;Green, Toby&amp;nbsp;Sargeant, Uchechi&amp;nbsp;Okereke, Yotam&amp;nbsp;Doron, and Augustin&amp;nbsp;Žídek (engineering lead).&lt;/p&gt; 
&lt;p&gt;We also extend our gratitude to our collaborators at Google and Isomorphic Labs.&lt;/p&gt; 
&lt;p&gt;AlphaFold 3 uses the following separate libraries and packages:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/abseil/abseil-cpp"&gt;abseil-cpp&lt;/a&gt; and &lt;a href="https://github.com/abseil/abseil-py"&gt;abseil-py&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.docker.com"&gt;Docker&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/PDB-REDO/dssp"&gt;DSSP&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/EddyRivasLab/hmmer"&gt;HMMER Suite&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/deepmind/dm-haiku"&gt;Haiku&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jax-ml/jax/"&gt;JAX&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jax-ml/jax-triton"&gt;jax-triton&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/patrick-kidger/jaxtyping"&gt;jaxtyping&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pdb-redo/libcifpp"&gt;libcifpp&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/numpy/numpy"&gt;NumPy&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pybind/pybind11"&gt;pybind11&lt;/a&gt; and &lt;a href="https://github.com/pybind/pybind11_abseil"&gt;pybind11_abseil&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/rdkit/rdkit"&gt;RDKit&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/deepmind/tree"&gt;Tree&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/triton-lang/triton"&gt;Triton&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tqdm/tqdm"&gt;tqdm&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;We thank all their contributors and maintainers!&lt;/p&gt; 
&lt;h2&gt;Get in Touch&lt;/h2&gt; 
&lt;p&gt;If you have any questions not covered in this overview, please contact the AlphaFold team at &lt;a href="mailto:alphafold@google.com"&gt;alphafold@google.com&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;We would love to hear your feedback and understand how AlphaFold 3 has been useful in your research. Share your stories with us at &lt;a href="mailto:alphafold@google.com"&gt;alphafold@google.com&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Licence and Disclaimer&lt;/h2&gt; 
&lt;p&gt;This is not an officially supported Google product.&lt;/p&gt; 
&lt;p&gt;Copyright 2024 DeepMind Technologies Limited.&lt;/p&gt; 
&lt;h3&gt;AlphaFold 3 Source Code and Model Parameters&lt;/h3&gt; 
&lt;p&gt;The AlphaFold 3 source code is licensed under the Creative Commons Attribution-Non-Commercial ShareAlike International License, Version 4.0 (CC-BY-NC-SA 4.0) (the "License"); you may not use this file except in compliance with the License. You may obtain a copy of the License at &lt;a href="https://github.com/google-deepmind/alphafold3/raw/main/LICENSE"&gt;https://github.com/google-deepmind/alphafold3/blob/main/LICENSE&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;The AlphaFold 3 model parameters are made available under the &lt;a href="https://github.com/google-deepmind/alphafold3/raw/main/WEIGHTS_TERMS_OF_USE.md"&gt;AlphaFold 3 Model Parameters Terms of Use&lt;/a&gt; (the "Terms"); you may not use these except in compliance with the Terms. You may obtain a copy of the Terms at &lt;a href="https://github.com/google-deepmind/alphafold3/raw/main/WEIGHTS_TERMS_OF_USE.md"&gt;https://github.com/google-deepmind/alphafold3/blob/main/WEIGHTS_TERMS_OF_USE.md&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Unless required by applicable law, AlphaFold 3 and its output are distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. You are solely responsible for determining the appropriateness of using AlphaFold 3, or using or distributing its source code or output, and assume any and all risks associated with such use or distribution and your exercise of rights and obligations under the relevant terms. Output are predictions with varying levels of confidence and should be interpreted carefully. Use discretion before relying on, publishing, downloading or otherwise using the AlphaFold 3 Assets.&lt;/p&gt; 
&lt;p&gt;AlphaFold 3 and its output are for theoretical modeling only. They are not intended, validated, or approved for clinical use. You should not use the AlphaFold 3 or its output for clinical purposes or rely on them for medical or other professional advice. Any content regarding those topics is provided for informational purposes only and is not a substitute for advice from a qualified professional. See the relevant terms for the specific language governing permissions and limitations under the terms.&lt;/p&gt; 
&lt;h3&gt;Third-party Software&lt;/h3&gt; 
&lt;p&gt;Use of the third-party software, libraries or code referred to in the &lt;a href="https://raw.githubusercontent.com/google-deepmind/alphafold3/main/#acknowledgements"&gt;Acknowledgements&lt;/a&gt; section above may be governed by separate terms and conditions or license provisions. Your use of the third-party software, libraries or code is subject to any such terms and you should check that you can comply with any applicable restrictions or terms and conditions before use.&lt;/p&gt; 
&lt;h3&gt;Mirrored and Reference Databases&lt;/h3&gt; 
&lt;p&gt;The following databases have been: (1) mirrored by Google DeepMind; and (2) in part, included with the inference code package for testing purposes, and are available with reference to the following:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://bfd.mmseqs.com/"&gt;BFD&lt;/a&gt; (modified), by Steinegger M. and Söding J., modified by Google DeepMind, available under a &lt;a href="https://creativecommons.org/licenses/by/4.0/deed.en"&gt;Creative Commons Attribution 4.0 International License&lt;/a&gt;. See the Methods section of the &lt;a href="https://www.nature.com/articles/s41586-021-03828-1"&gt;AlphaFold proteome paper&lt;/a&gt; for details.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://wwpdb.org"&gt;PDB&lt;/a&gt; (unmodified), by H.M. Berman et al., available free of all copyright restrictions and made fully and freely available for both non-commercial and commercial use under &lt;a href="https://creativecommons.org/publicdomain/zero/1.0/"&gt;CC0 1.0 Universal (CC0 1.0) Public Domain Dedication&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://ftp.ebi.ac.uk/pub/databases/metagenomics/peptide_database/2022_05/README.txt"&gt;MGnify: v2022_05&lt;/a&gt; (unmodified), by Mitchell AL et al., available free of all copyright restrictions and made fully and freely available for both non-commercial and commercial use under &lt;a href="https://creativecommons.org/publicdomain/zero/1.0/"&gt;CC0 1.0 Universal (CC0 1.0) Public Domain Dedication&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.uniprot.org/"&gt;UniProt: 2021_04&lt;/a&gt; (unmodified), by The UniProt Consortium, available under a &lt;a href="https://creativecommons.org/licenses/by/4.0/deed.en"&gt;Creative Commons Attribution 4.0 International License&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.uniprot.org/"&gt;UniRef90: 2022_05&lt;/a&gt; (unmodified) by The UniProt Consortium, available under a &lt;a href="https://creativecommons.org/licenses/by/4.0/deed.en"&gt;Creative Commons Attribution 4.0 International License&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.ncbi.nlm.nih.gov/nucleotide/"&gt;NT: 2023_02_23&lt;/a&gt; (modified) See the Supplementary Information of the &lt;a href="https://nature.com/articles/s41586-024-07487-w"&gt;AlphaFold 3 paper&lt;/a&gt; for details.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://rfam.org/"&gt;RFam: 14_4&lt;/a&gt; (modified), by I. Kalvari et al., available free of all copyright restrictions and made fully and freely available for both non-commercial and commercial use under &lt;a href="https://creativecommons.org/publicdomain/zero/1.0/"&gt;CC0 1.0 Universal (CC0 1.0) Public Domain Dedication&lt;/a&gt;. See the Supplementary Information of the &lt;a href="https://nature.com/articles/s41586-024-07487-w"&gt;AlphaFold 3 paper&lt;/a&gt; for details.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://rnacentral.org/"&gt;RNACentral: 21_0&lt;/a&gt; (modified), by The RNAcentral Consortium available free of all copyright restrictions and made fully and freely available for both non-commercial and commercial use under &lt;a href="https://creativecommons.org/publicdomain/zero/1.0/"&gt;CC0 1.0 Universal (CC0 1.0) Public Domain Dedication&lt;/a&gt;. See the Supplementary Information of the &lt;a href="https://nature.com/articles/s41586-024-07487-w"&gt;AlphaFold 3 paper&lt;/a&gt; for details.&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>SkyworkAI/SkyReels-V2</title>
      <link>https://github.com/SkyworkAI/SkyReels-V2</link>
      <description>&lt;p&gt;SkyReels-V2: Infinite-length Film Generative model&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/SkyworkAI/SkyReels-V2/main/assets/logo2.png" alt="SkyReels Logo" width="50%"&gt; &lt;/p&gt; 
&lt;h1 align="center"&gt;SkyReels V2: Infinite-Length Film Generative Model&lt;/h1&gt; 
&lt;p align="center"&gt; 📑 &lt;a href="https://arxiv.org/pdf/2504.13074"&gt;Technical Report&lt;/a&gt; · 👋 &lt;a href="https://www.skyreels.ai/home?utm_campaign=github_SkyReels_V2" target="_blank"&gt;Playground&lt;/a&gt; · 💬 &lt;a href="https://discord.gg/PwM6NYtccQ" target="_blank"&gt;Discord&lt;/a&gt; · 🤗 &lt;a href="https://huggingface.co/collections/Skywork/skyreels-v2-6801b1b93df627d441d0d0d9" target="_blank"&gt;Hugging Face&lt;/a&gt; · 🤖 &lt;a href="https://www.modelscope.cn/collections/SkyReels-V2-f665650130b144" target="_blank"&gt;ModelScope&lt;/a&gt; &lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;Welcome to the &lt;strong&gt;SkyReels V2&lt;/strong&gt; repository! Here, you'll find the model weights and inference code for our infinite-length film generative models. To the best of our knowledge, it represents the first open-source video generative model employing &lt;strong&gt;AutoRegressive Diffusion-Forcing architecture&lt;/strong&gt; that achieves the &lt;strong&gt;SOTA performance&lt;/strong&gt; among publicly available models.&lt;/p&gt; 
&lt;h2&gt;🔥🔥🔥 News!!&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Jun 1, 2025: 🎉 We published the technical report, &lt;a href="https://arxiv.org/pdf/2506.00830"&gt;SkyReels-Audio: Omni Audio-Conditioned Talking Portraits in Video Diffusion Transformers&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;May 16, 2025: 🔥 We release the inference code for &lt;a href="https://raw.githubusercontent.com/SkyworkAI/SkyReels-V2/main/#ve"&gt;video extension&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/SkyworkAI/SkyReels-V2/main/#se"&gt;start/end frame control&lt;/a&gt; in diffusion forcing model.&lt;/li&gt; 
 &lt;li&gt;Apr 24, 2025: 🔥 We release the 720P models, &lt;a href="https://huggingface.co/Skywork/SkyReels-V2-DF-14B-720P"&gt;SkyReels-V2-DF-14B-720P&lt;/a&gt; and &lt;a href="https://huggingface.co/Skywork/SkyReels-V2-I2V-14B-720P"&gt;SkyReels-V2-I2V-14B-720P&lt;/a&gt;. The former facilitates infinite-length autoregressive video generation, and the latter focuses on Image2Video synthesis.&lt;/li&gt; 
 &lt;li&gt;Apr 21, 2025: 👋 We release the inference code and model weights of &lt;a href="https://huggingface.co/collections/Skywork/skyreels-v2-6801b1b93df627d441d0d0d9"&gt;SkyReels-V2&lt;/a&gt; Series Models and the video captioning model &lt;a href="https://huggingface.co/Skywork/SkyCaptioner-V1"&gt;SkyCaptioner-V1&lt;/a&gt; .&lt;/li&gt; 
 &lt;li&gt;Apr 3, 2025: 🔥 We also release &lt;a href="https://github.com/SkyworkAI/SkyReels-A2"&gt;SkyReels-A2&lt;/a&gt;. This is an open-sourced controllable video generation framework capable of assembling arbitrary visual elements.&lt;/li&gt; 
 &lt;li&gt;Feb 18, 2025: 🔥 we released &lt;a href="https://github.com/SkyworkAI/SkyReels-A1"&gt;SkyReels-A1&lt;/a&gt;. This is an open-sourced and effective framework for portrait image animation.&lt;/li&gt; 
 &lt;li&gt;Feb 18, 2025: 🔥 We released &lt;a href="https://github.com/SkyworkAI/SkyReels-V1"&gt;SkyReels-V1&lt;/a&gt;. This is the first and most advanced open-source human-centric video foundation model.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;🎥 Demos&lt;/h2&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td align="center"&gt; 
    &lt;video src="https://github.com/user-attachments/assets/f6f9f9a7-5d5f-433c-9d73-d8d593b7ad25" width="100%"&gt;&lt;/video&gt; &lt;/td&gt; 
   &lt;td align="center"&gt; 
    &lt;video src="https://github.com/user-attachments/assets/0eb13415-f4d9-4aaf-bcd3-3031851109b9" width="100%"&gt;&lt;/video&gt; &lt;/td&gt; 
   &lt;td align="center"&gt; 
    &lt;video src="https://github.com/user-attachments/assets/dcd16603-5bf4-4786-8e4d-1ed23889d07a" width="100%"&gt;&lt;/video&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; The demos above showcase 30-second videos generated using our SkyReels-V2 Diffusion Forcing model. 
&lt;h2&gt;📑 TODO List&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://arxiv.org/pdf/2504.13074"&gt;Technical Report&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; Checkpoints of the 14B and 1.3B Models Series&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; Single-GPU &amp;amp; Multi-GPU Inference Code&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://huggingface.co/Skywork/SkyCaptioner-V1"&gt;SkyCaptioner-V1&lt;/a&gt;: A Video Captioning Model&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; Prompt Enhancer&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled&gt; Diffusers integration&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled&gt; Checkpoints of the 5B Models Series&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled&gt; Checkpoints of the Camera Director Models&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled&gt; Checkpoints of the Step &amp;amp; Guidance Distill Model&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;🚀 Quickstart&lt;/h2&gt; 
&lt;h4&gt;Installation&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;# clone the repository.
git clone https://github.com/SkyworkAI/SkyReels-V2
cd SkyReels-V2
# Install dependencies. Test environment uses Python 3.10.12.
pip install -r requirements.txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Model Download&lt;/h4&gt; 
&lt;p&gt;You can download our models from Hugging Face:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Type&lt;/th&gt; 
   &lt;th&gt;Model Variant&lt;/th&gt; 
   &lt;th&gt;Recommended Height/Width/Frame&lt;/th&gt; 
   &lt;th&gt;Link&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td rowspan="5"&gt;Diffusion Forcing&lt;/td&gt; 
   &lt;td&gt;1.3B-540P&lt;/td&gt; 
   &lt;td&gt;544 * 960 * 97f&lt;/td&gt; 
   &lt;td&gt;🤗 &lt;a href="https://huggingface.co/Skywork/SkyReels-V2-DF-1.3B-540P"&gt;Huggingface&lt;/a&gt; 🤖 &lt;a href="https://www.modelscope.cn/models/Skywork/SkyReels-V2-DF-1.3B-540P"&gt;ModelScope&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;5B-540P&lt;/td&gt; 
   &lt;td&gt;544 * 960 * 97f&lt;/td&gt; 
   &lt;td&gt;Coming Soon&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;5B-720P&lt;/td&gt; 
   &lt;td&gt;720 * 1280 * 121f&lt;/td&gt; 
   &lt;td&gt;Coming Soon&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;14B-540P&lt;/td&gt; 
   &lt;td&gt;544 * 960 * 97f&lt;/td&gt; 
   &lt;td&gt;🤗 &lt;a href="https://huggingface.co/Skywork/SkyReels-V2-DF-14B-540P"&gt;Huggingface&lt;/a&gt; 🤖 &lt;a href="https://www.modelscope.cn/models/Skywork/SkyReels-V2-DF-14B-540P"&gt;ModelScope&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;14B-720P&lt;/td&gt; 
   &lt;td&gt;720 * 1280 * 121f&lt;/td&gt; 
   &lt;td&gt;🤗 &lt;a href="https://huggingface.co/Skywork/SkyReels-V2-DF-14B-720P"&gt;Huggingface&lt;/a&gt; 🤖 &lt;a href="https://www.modelscope.cn/models/Skywork/SkyReels-V2-DF-14B-720P"&gt;ModelScope&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td rowspan="5"&gt;Text-to-Video&lt;/td&gt; 
   &lt;td&gt;1.3B-540P&lt;/td&gt; 
   &lt;td&gt;544 * 960 * 97f&lt;/td&gt; 
   &lt;td&gt;Coming Soon&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;5B-540P&lt;/td&gt; 
   &lt;td&gt;544 * 960 * 97f&lt;/td&gt; 
   &lt;td&gt;Coming Soon&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;5B-720P&lt;/td&gt; 
   &lt;td&gt;720 * 1280 * 121f&lt;/td&gt; 
   &lt;td&gt;Coming Soon&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;14B-540P&lt;/td&gt; 
   &lt;td&gt;544 * 960 * 97f&lt;/td&gt; 
   &lt;td&gt;🤗 &lt;a href="https://huggingface.co/Skywork/SkyReels-V2-T2V-14B-540P"&gt;Huggingface&lt;/a&gt; 🤖 &lt;a href="https://www.modelscope.cn/models/Skywork/SkyReels-V2-T2V-14B-540P"&gt;ModelScope&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;14B-720P&lt;/td&gt; 
   &lt;td&gt;720 * 1280 * 121f&lt;/td&gt; 
   &lt;td&gt;🤗 &lt;a href="https://huggingface.co/Skywork/SkyReels-V2-T2V-14B-720P"&gt;Huggingface&lt;/a&gt; 🤖 &lt;a href="https://www.modelscope.cn/models/Skywork/SkyReels-V2-T2V-14B-720P"&gt;ModelScope&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td rowspan="5"&gt;Image-to-Video&lt;/td&gt; 
   &lt;td&gt;1.3B-540P&lt;/td&gt; 
   &lt;td&gt;544 * 960 * 97f&lt;/td&gt; 
   &lt;td&gt;🤗 &lt;a href="https://huggingface.co/Skywork/SkyReels-V2-I2V-1.3B-540P"&gt;Huggingface&lt;/a&gt; 🤖 &lt;a href="https://www.modelscope.cn/models/Skywork/SkyReels-V2-I2V-1.3B-540P"&gt;ModelScope&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;5B-540P&lt;/td&gt; 
   &lt;td&gt;544 * 960 * 97f&lt;/td&gt; 
   &lt;td&gt;Coming Soon&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;5B-720P&lt;/td&gt; 
   &lt;td&gt;720 * 1280 * 121f&lt;/td&gt; 
   &lt;td&gt;Coming Soon&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;14B-540P&lt;/td&gt; 
   &lt;td&gt;544 * 960 * 97f&lt;/td&gt; 
   &lt;td&gt;🤗 &lt;a href="https://huggingface.co/Skywork/SkyReels-V2-I2V-14B-540P"&gt;Huggingface&lt;/a&gt; 🤖 &lt;a href="https://www.modelscope.cn/models/Skywork/SkyReels-V2-I2V-14B-540P"&gt;ModelScope&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;14B-720P&lt;/td&gt; 
   &lt;td&gt;720 * 1280 * 121f&lt;/td&gt; 
   &lt;td&gt;🤗 &lt;a href="https://huggingface.co/Skywork/SkyReels-V2-I2V-14B-720P"&gt;Huggingface&lt;/a&gt; 🤖 &lt;a href="https://www.modelscope.cn/models/Skywork/SkyReels-V2-I2V-14B-720P"&gt;ModelScope&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td rowspan="3"&gt;Camera Director&lt;/td&gt; 
   &lt;td&gt;5B-540P&lt;/td&gt; 
   &lt;td&gt;544 * 960 * 97f&lt;/td&gt; 
   &lt;td&gt;Coming Soon&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;5B-720P&lt;/td&gt; 
   &lt;td&gt;720 * 1280 * 121f&lt;/td&gt; 
   &lt;td&gt;Coming Soon&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;14B-720P&lt;/td&gt; 
   &lt;td&gt;720 * 1280 * 121f&lt;/td&gt; 
   &lt;td&gt;Coming Soon&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;After downloading, set the model path in your generation commands:&lt;/p&gt; 
&lt;h4&gt;Single GPU Inference&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Diffusion Forcing for Long Video Generation&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The &lt;a href="https://arxiv.org/abs/2407.01392"&gt;&lt;strong&gt;Diffusion Forcing&lt;/strong&gt;&lt;/a&gt; version model allows us to generate Infinite-Length videos. This model supports both &lt;strong&gt;text-to-video (T2V)&lt;/strong&gt; and &lt;strong&gt;image-to-video (I2V)&lt;/strong&gt; tasks, and it can perform inference in both synchronous and asynchronous modes. Here we demonstrate 2 running scripts as examples for long video generation. If you want to adjust the inference parameters, e.g., the duration of video, inference mode, read the Note below first.&lt;/p&gt; 
&lt;p&gt;synchronous generation for 10s video&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;model_id=Skywork/SkyReels-V2-DF-14B-540P
# synchronous inference
python3 generate_video_df.py \
  --model_id ${model_id} \
  --resolution 540P \
  --ar_step 0 \
  --base_num_frames 97 \
  --num_frames 257 \
  --overlap_history 17 \
  --prompt "A graceful white swan with a curved neck and delicate feathers swimming in a serene lake at dawn, its reflection perfectly mirrored in the still water as mist rises from the surface, with the swan occasionally dipping its head into the water to feed." \
  --addnoise_condition 20 \
  --offload \
  --teacache \
  --use_ret_steps \
  --teacache_thresh 0.3
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;asynchronous generation for 30s video&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;model_id=Skywork/SkyReels-V2-DF-14B-540P
# asynchronous inference
python3 generate_video_df.py \
  --model_id ${model_id} \
  --resolution 540P \
  --ar_step 5 \
  --causal_block_size 5 \
  --base_num_frames 97 \
  --num_frames 737 \
  --overlap_history 17 \
  --prompt "A graceful white swan with a curved neck and delicate feathers swimming in a serene lake at dawn, its reflection perfectly mirrored in the still water as mist rises from the surface, with the swan occasionally dipping its head into the water to feed." \
  --addnoise_condition 20 \
  --offload
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;If you want to run the &lt;strong&gt;image-to-video (I2V)&lt;/strong&gt; task, add &lt;code&gt;--image ${image_path}&lt;/code&gt; to your command and it is also better to use &lt;strong&gt;text-to-video (T2V)&lt;/strong&gt;-like prompt which includes some descriptions of the first-frame image.&lt;/li&gt; 
  &lt;li&gt;For long video generation, you can just switch the &lt;code&gt;--num_frames&lt;/code&gt;, e.g., &lt;code&gt;--num_frames 257&lt;/code&gt; for 10s video, &lt;code&gt;--num_frames 377&lt;/code&gt; for 15s video, &lt;code&gt;--num_frames 737&lt;/code&gt; for 30s video, &lt;code&gt;--num_frames 1457&lt;/code&gt; for 60s video. The number is not strictly aligned with the logical frame number for specified time duration, but it is aligned with some training parameters, which means it may perform better. When you use asynchronous inference with causal_block_size &amp;gt; 1, the &lt;code&gt;--num_frames&lt;/code&gt; should be carefully set.&lt;/li&gt; 
  &lt;li&gt;You can use &lt;code&gt;--ar_step 5&lt;/code&gt; to enable asynchronous inference. When asynchronous inference, &lt;code&gt;--causal_block_size 5&lt;/code&gt; is recommended while it is not supposed to be set for synchronous generation. REMEMBER that the frame latent number inputted into the model in every iteration, e.g., base frame latent number (e.g., (97-1)//4+1=25 for base_num_frames=97) and (e.g., (237-97-(97-17)x1+17-1)//4+1=20 for base_num_frames=97, num_frames=237, overlap_history=17) for the last iteration, MUST be divided by causal_block_size. If you find it too hard to calculate and set proper values, just use our recommended setting above :). Asynchronous inference will take more steps to diffuse the whole sequence which means it will be SLOWER than synchronous mode. In our experiments, asynchronous inference may improve the instruction following and visual consistent performance.&lt;/li&gt; 
  &lt;li&gt;To reduce peak VRAM, just lower the &lt;code&gt;--base_num_frames&lt;/code&gt;, e.g., to 77 or 57, while keeping the same generative length &lt;code&gt;--num_frames&lt;/code&gt; you want to generate. This may slightly reduce video quality, and it should not be set too small.&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;--addnoise_condition&lt;/code&gt; is used to help smooth the long video generation by adding some noise to the clean condition. Too large noise can cause the inconsistency as well. 20 is a recommended value, and you may try larger ones, but it is recommended to not exceed 50.&lt;/li&gt; 
  &lt;li&gt;Generating a 540P video using the 1.3B model requires approximately 14.7GB peak VRAM, while the same resolution video using the 14B model demands around 51.2GB peak VRAM.&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;span id="ve"&gt;Video Extention&lt;/span&gt;&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;model_id=Skywork/SkyReels-V2-DF-14B-540P
# video extention
python3 generate_video_df.py \
  --model_id ${model_id} \
  --resolution 540P \
  --ar_step 0 \
  --base_num_frames 97 \
  --num_frames 120 \
  --overlap_history 17 \
  --prompt ${prompt} \
  --addnoise_condition 20 \
  --offload \
  --use_ret_steps \
  --teacache \
  --teacache_thresh 0.3 \
  --video_path ${video_path}
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;When performing video extension, you need to pass the &lt;code&gt;--video_path ${video_path}&lt;/code&gt; parameter to specify the video to be extended.&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;span id="se"&gt;Start/End Frame Control&lt;/span&gt;&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;model_id=Skywork/SkyReels-V2-DF-14B-540P
# start/end frame control
python3 generate_video_df.py \
  --model_id ${model_id} \
  --resolution 540P \
  --ar_step 0 \
  --base_num_frames 97 \
  --num_frames 97 \
  --overlap_history 17 \
  --prompt ${prompt} \
  --addnoise_condition 20 \
  --offload \
  --use_ret_steps \
  --teacache \
  --teacache_thresh 0.3 \
  --image ${image} \
  --end_image ${end_image}
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;When controlling the start and end frames, you need to pass the &lt;code&gt;--image ${image}&lt;/code&gt; parameter to control the generation of the start frame and the &lt;code&gt;--end_image ${end_image}&lt;/code&gt; parameter to control the generation of the end frame.&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Text To Video &amp;amp; Image To Video&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;# run Text-to-Video Generation
model_id=Skywork/SkyReels-V2-T2V-14B-540P
python3 generate_video.py \
  --model_id ${model_id} \
  --resolution 540P \
  --num_frames 97 \
  --guidance_scale 6.0 \
  --shift 8.0 \
  --fps 24 \
  --prompt "A serene lake surrounded by towering mountains, with a few swans gracefully gliding across the water and sunlight dancing on the surface." \
  --offload \
  --teacache \
  --use_ret_steps \
  --teacache_thresh 0.3
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;When using an &lt;strong&gt;image-to-video (I2V)&lt;/strong&gt; model, you must provide an input image using the &lt;code&gt;--image ${image_path}&lt;/code&gt; parameter. The &lt;code&gt;--guidance_scale 5.0&lt;/code&gt; and &lt;code&gt;--shift 3.0&lt;/code&gt; is recommended for I2V model.&lt;/li&gt; 
  &lt;li&gt;Generating a 540P video using the 1.3B model requires approximately 14.7GB peak VRAM, while the same resolution video using the 14B model demands around 43.4GB peak VRAM.&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Prompt Enhancer&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The prompt enhancer is implemented based on &lt;a href="https://huggingface.co/Qwen/Qwen2.5-32B-Instruct"&gt;Qwen2.5-32B-Instruct&lt;/a&gt; and is utilized via the &lt;code&gt;--prompt_enhancer&lt;/code&gt; parameter. It works ideally for short prompts, while for long prompts, it might generate an excessively lengthy prompt that could lead to over-saturation in the generative video. Note the peak memory of GPU is 64G+ if you use &lt;code&gt;--prompt_enhancer&lt;/code&gt;. If you want to obtain the enhanced prompt separately, you can also run the prompt_enhancer script separately for testing. The steps are as follows:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;cd skyreels_v2_infer/pipelines
python3 prompt_enhancer.py --prompt "A serene lake surrounded by towering mountains, with a few swans gracefully gliding across the water and sunlight dancing on the surface."
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;code&gt;--prompt_enhancer&lt;/code&gt; is not allowed if using &lt;code&gt;--use_usp&lt;/code&gt;. We recommend running the skyreels_v2_infer/pipelines/prompt_enhancer.py script first to generate enhanced prompt before enabling the &lt;code&gt;--use_usp&lt;/code&gt; parameter.&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;Advanced Configuration Options&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Below are the key parameters you can customize for video generation:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="center"&gt;Parameter&lt;/th&gt; 
   &lt;th align="center"&gt;Recommended Value&lt;/th&gt; 
   &lt;th align="center"&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;--prompt&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;Text description for generating your video&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;--image&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;Path to input image for image-to-video generation&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;--resolution&lt;/td&gt; 
   &lt;td align="center"&gt;540P or 720P&lt;/td&gt; 
   &lt;td align="center"&gt;Output video resolution (select based on model type)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;--num_frames&lt;/td&gt; 
   &lt;td align="center"&gt;97 or 121&lt;/td&gt; 
   &lt;td align="center"&gt;Total frames to generate (&lt;strong&gt;97 for 540P models&lt;/strong&gt;, &lt;strong&gt;121 for 720P models&lt;/strong&gt;)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;--inference_steps&lt;/td&gt; 
   &lt;td align="center"&gt;50&lt;/td&gt; 
   &lt;td align="center"&gt;Number of denoising steps&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;--fps&lt;/td&gt; 
   &lt;td align="center"&gt;24&lt;/td&gt; 
   &lt;td align="center"&gt;Frames per second in the output video&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;--shift&lt;/td&gt; 
   &lt;td align="center"&gt;8.0 or 5.0&lt;/td&gt; 
   &lt;td align="center"&gt;Flow matching scheduler parameter (&lt;strong&gt;8.0 for T2V&lt;/strong&gt;, &lt;strong&gt;5.0 for I2V&lt;/strong&gt;)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;--guidance_scale&lt;/td&gt; 
   &lt;td align="center"&gt;6.0 or 5.0&lt;/td&gt; 
   &lt;td align="center"&gt;Controls text adherence strength (&lt;strong&gt;6.0 for T2V&lt;/strong&gt;, &lt;strong&gt;5.0 for I2V&lt;/strong&gt;)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;--seed&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;Fixed seed for reproducible results (omit for random generation)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;--offload&lt;/td&gt; 
   &lt;td align="center"&gt;True&lt;/td&gt; 
   &lt;td align="center"&gt;Offloads model components to CPU to reduce VRAM usage (recommended)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;--use_usp&lt;/td&gt; 
   &lt;td align="center"&gt;True&lt;/td&gt; 
   &lt;td align="center"&gt;Enables multi-GPU acceleration with xDiT USP&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;--outdir&lt;/td&gt; 
   &lt;td align="center"&gt;./video_out&lt;/td&gt; 
   &lt;td align="center"&gt;Directory where generated videos will be saved&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;--prompt_enhancer&lt;/td&gt; 
   &lt;td align="center"&gt;True&lt;/td&gt; 
   &lt;td align="center"&gt;Expand the prompt into a more detailed description&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;--teacache&lt;/td&gt; 
   &lt;td align="center"&gt;False&lt;/td&gt; 
   &lt;td align="center"&gt;Enables teacache for faster inference&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;--teacache_thresh&lt;/td&gt; 
   &lt;td align="center"&gt;0.2&lt;/td&gt; 
   &lt;td align="center"&gt;Higher speedup will cause to worse quality&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;--use_ret_steps&lt;/td&gt; 
   &lt;td align="center"&gt;False&lt;/td&gt; 
   &lt;td align="center"&gt;Retention Steps for teacache&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;Diffusion Forcing Additional Parameters&lt;/strong&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="center"&gt;Parameter&lt;/th&gt; 
   &lt;th align="center"&gt;Recommended Value&lt;/th&gt; 
   &lt;th align="center"&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;--ar_step&lt;/td&gt; 
   &lt;td align="center"&gt;0&lt;/td&gt; 
   &lt;td align="center"&gt;Controls asynchronous inference (0 for synchronous mode)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;--base_num_frames&lt;/td&gt; 
   &lt;td align="center"&gt;97 or 121&lt;/td&gt; 
   &lt;td align="center"&gt;Base frame count (&lt;strong&gt;97 for 540P&lt;/strong&gt;, &lt;strong&gt;121 for 720P&lt;/strong&gt;)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;--overlap_history&lt;/td&gt; 
   &lt;td align="center"&gt;17&lt;/td&gt; 
   &lt;td align="center"&gt;Number of frames to overlap for smooth transitions in long videos&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;--addnoise_condition&lt;/td&gt; 
   &lt;td align="center"&gt;20&lt;/td&gt; 
   &lt;td align="center"&gt;Improves consistency in long video generation&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;--causal_block_size&lt;/td&gt; 
   &lt;td align="center"&gt;5&lt;/td&gt; 
   &lt;td align="center"&gt;Recommended when using asynchronous inference (--ar_step &amp;gt; 0)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;--video_path&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;Path to input video for video extension&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;--end_image&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;Path to input image for end frame control&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h4&gt;Multi-GPU inference using xDiT USP&lt;/h4&gt; 
&lt;p&gt;We use &lt;a href="https://github.com/xdit-project/xDiT"&gt;xDiT&lt;/a&gt; USP to accelerate inference. For example, to generate a video with 2 GPUs, you can use the following command:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Diffusion Forcing&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;model_id=Skywork/SkyReels-V2-DF-14B-540P
# diffusion forcing synchronous inference
torchrun --nproc_per_node=2 generate_video_df.py \
  --model_id ${model_id} \
  --resolution 540P \
  --ar_step 0 \
  --base_num_frames 97 \
  --num_frames 257 \
  --overlap_history 17 \
  --prompt "A graceful white swan with a curved neck and delicate feathers swimming in a serene lake at dawn, its reflection perfectly mirrored in the still water as mist rises from the surface, with the swan occasionally dipping its head into the water to feed." \
  --addnoise_condition 20 \
  --use_usp \
  --offload \
  --seed 42
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Text To Video &amp;amp; Image To Video&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;# run Text-to-Video Generation
model_id=Skywork/SkyReels-V2-T2V-14B-540P
torchrun --nproc_per_node=2 generate_video.py \
  --model_id ${model_id} \
  --resolution 540P \
  --num_frames 97 \
  --guidance_scale 6.0 \
  --shift 8.0 \
  --fps 24 \
  --offload \
  --prompt "A serene lake surrounded by towering mountains, with a few swans gracefully gliding across the water and sunlight dancing on the surface." \
  --use_usp \
  --seed 42
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;When using an &lt;strong&gt;image-to-video (I2V)&lt;/strong&gt; model, you must provide an input image using the &lt;code&gt;--image ${image_path}&lt;/code&gt; parameter. The &lt;code&gt;--guidance_scale 5.0&lt;/code&gt; and &lt;code&gt;--shift 3.0&lt;/code&gt; is recommended for I2V model.&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Contents&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/SkyworkAI/SkyReels-V2/main/#abstract"&gt;Abstract&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/SkyworkAI/SkyReels-V2/main/#methodology-of-skyreels-v2"&gt;Methodology of SkyReels-V2&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/SkyworkAI/SkyReels-V2/main/#key-contributions-of-skyreels-v2"&gt;Key Contributions of SkyReels-V2&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/SkyworkAI/SkyReels-V2/main/#video-captioner"&gt;Video Captioner&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/SkyworkAI/SkyReels-V2/main/#reinforcement-learning"&gt;Reinforcement Learning&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/SkyworkAI/SkyReels-V2/main/#diffusion-forcing"&gt;Diffusion Forcing&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/SkyworkAI/SkyReels-V2/main/#high-quality-supervised-fine-tuning-sft"&gt;High-Quality Supervised Fine-Tuning(SFT)&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/SkyworkAI/SkyReels-V2/main/#performance"&gt;Performance&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/SkyworkAI/SkyReels-V2/main/#acknowledgements"&gt;Acknowledgements&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/SkyworkAI/SkyReels-V2/main/#citation"&gt;Citation&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr&gt; 
&lt;h2&gt;Abstract&lt;/h2&gt; 
&lt;p&gt;Recent advances in video generation have been driven by diffusion models and autoregressive frameworks, yet critical challenges persist in harmonizing prompt adherence, visual quality, motion dynamics, and duration: compromises in motion dynamics to enhance temporal visual quality, constrained video duration (5-10 seconds) to prioritize resolution, and inadequate shot-aware generation stemming from general-purpose MLLMs' inability to interpret cinematic grammar, such as shot composition, actor expressions, and camera motions. These intertwined limitations hinder realistic long-form synthesis and professional film-style generation.&lt;/p&gt; 
&lt;p&gt;To address these limitations, we introduce SkyReels-V2, the world's first infinite-length film generative model using a Diffusion Forcing framework. Our approach synergizes Multi-modal Large Language Models (MLLM), Multi-stage Pretraining, Reinforcement Learning, and Diffusion Forcing techniques to achieve comprehensive optimization. Beyond its technical innovations, SkyReels-V2 enables multiple practical applications, including Story Generation, Image-to-Video Synthesis, Camera Director functionality, and multi-subject consistent video generation through our &lt;a href="https://github.com/SkyworkAI/SkyReels-A2"&gt;Skyreels-A2&lt;/a&gt; system.&lt;/p&gt; 
&lt;h2&gt;Methodology of SkyReels-V2&lt;/h2&gt; 
&lt;p&gt;The SkyReels-V2 methodology consists of several interconnected components. It starts with a comprehensive data processing pipeline that prepares various quality training data. At its core is the Video Captioner architecture, which provides detailed annotations for video content. The system employs a multi-task pretraining strategy to build fundamental video generation capabilities. Post-training optimization includes Reinforcement Learning to enhance motion quality, Diffusion Forcing Training for generating extended videos, and High-quality Supervised Fine-Tuning (SFT) stages for visual refinement. The model runs on optimized computational infrastructure for efficient training and inference. SkyReels-V2 supports multiple applications, including Story Generation, Image-to-Video Synthesis, Camera Director functionality, and Elements-to-Video Generation.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/SkyworkAI/SkyReels-V2/main/assets/main_pipeline.jpg" alt="mainpipeline" width="100%"&gt; &lt;/p&gt; 
&lt;h2&gt;Key Contributions of SkyReels-V2&lt;/h2&gt; 
&lt;h4&gt;Video Captioner&lt;/h4&gt; 
&lt;p&gt;&lt;a href="https://huggingface.co/Skywork/SkyCaptioner-V1"&gt;SkyCaptioner-V1&lt;/a&gt; serves as our video captioning model for data annotation. This model is trained on the captioning result from the base model &lt;a href="https://huggingface.co/Qwen/Qwen2.5-VL-72B-Instruct"&gt;Qwen2.5-VL-72B-Instruct&lt;/a&gt; and the sub-expert captioners on a balanced video data. The balanced video data is a carefully curated dataset of approximately 2 million videos to ensure conceptual balance and annotation quality. Built upon the &lt;a href="https://huggingface.co/Qwen/Qwen2.5-VL-7B-Instruct"&gt;Qwen2.5-VL-7B-Instruct&lt;/a&gt; foundation model, &lt;a href="https://huggingface.co/Skywork/SkyCaptioner-V1"&gt;SkyCaptioner-V1&lt;/a&gt; is fine-tuned to enhance performance in domain-specific video captioning tasks. To compare the performance with the SOTA models, we conducted a manual assessment of accuracy across different captioning fields using a test set of 1,000 samples. The proposed &lt;a href="https://huggingface.co/Skywork/SkyCaptioner-V1"&gt;SkyCaptioner-V1&lt;/a&gt; achieves the highest average accuracy among the baseline models, and show a dramatic result in the shot related fields&lt;/p&gt; 
&lt;p align="center"&gt; &lt;/p&gt;
&lt;table align="center"&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;model&lt;/th&gt; 
   &lt;th&gt;&lt;a href="https://huggingface.co/Qwen/Qwen2.5-VL-7B-Instruct"&gt;Qwen2.5-VL-7B-Ins.&lt;/a&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;a href="https://huggingface.co/Qwen/Qwen2.5-VL-72B-Instruct"&gt;Qwen2.5-VL-72B-Ins.&lt;/a&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;a href="https://huggingface.co/omni-research/Tarsier2-Recap-7b"&gt;Tarsier2-Recap-7b&lt;/a&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;a href="https://huggingface.co/Skywork/SkyCaptioner-V1"&gt;SkyCaptioner-V1&lt;/a&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Avg accuracy&lt;/td&gt; 
   &lt;td&gt;51.4%&lt;/td&gt; 
   &lt;td&gt;58.7%&lt;/td&gt; 
   &lt;td&gt;49.4%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;76.3%&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;shot type&lt;/td&gt; 
   &lt;td&gt;76.8%&lt;/td&gt; 
   &lt;td&gt;82.5%&lt;/td&gt; 
   &lt;td&gt;60.2%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;93.7%&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;shot angle&lt;/td&gt; 
   &lt;td&gt;60.0%&lt;/td&gt; 
   &lt;td&gt;73.7%&lt;/td&gt; 
   &lt;td&gt;52.4%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;89.8%&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;shot position&lt;/td&gt; 
   &lt;td&gt;28.4%&lt;/td&gt; 
   &lt;td&gt;32.7%&lt;/td&gt; 
   &lt;td&gt;23.6%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;83.1%&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;camera motion&lt;/td&gt; 
   &lt;td&gt;62.0%&lt;/td&gt; 
   &lt;td&gt;61.2%&lt;/td&gt; 
   &lt;td&gt;45.3%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;85.3%&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;expression&lt;/td&gt; 
   &lt;td&gt;43.6%&lt;/td&gt; 
   &lt;td&gt;51.5%&lt;/td&gt; 
   &lt;td&gt;54.3%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;68.8%&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td colspan="5" style="text-align: center; border-bottom: 1px solid #ddd; padding: 8px;"&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;TYPES_type&lt;/td&gt; 
   &lt;td&gt;43.5%&lt;/td&gt; 
   &lt;td&gt;49.7%&lt;/td&gt; 
   &lt;td&gt;47.6%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;82.5%&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;TYPES_sub_type&lt;/td&gt; 
   &lt;td&gt;38.9%&lt;/td&gt; 
   &lt;td&gt;44.9%&lt;/td&gt; 
   &lt;td&gt;45.9%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;75.4%&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;appearance&lt;/td&gt; 
   &lt;td&gt;40.9%&lt;/td&gt; 
   &lt;td&gt;52.0%&lt;/td&gt; 
   &lt;td&gt;45.6%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;59.3%&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;action&lt;/td&gt; 
   &lt;td&gt;32.4%&lt;/td&gt; 
   &lt;td&gt;52.0%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;69.8%&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;68.8%&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;position&lt;/td&gt; 
   &lt;td&gt;35.4%&lt;/td&gt; 
   &lt;td&gt;48.6%&lt;/td&gt; 
   &lt;td&gt;45.5%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;57.5%&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;is_main_subject&lt;/td&gt; 
   &lt;td&gt;58.5%&lt;/td&gt; 
   &lt;td&gt;68.7%&lt;/td&gt; 
   &lt;td&gt;69.7%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;80.9%&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;environment&lt;/td&gt; 
   &lt;td&gt;70.4%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;72.7%&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;61.4%&lt;/td&gt; 
   &lt;td&gt;70.5%&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;lighting&lt;/td&gt; 
   &lt;td&gt;77.1%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;80.0%&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;21.2%&lt;/td&gt; 
   &lt;td&gt;76.5%&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;h4&gt;Reinforcement Learning&lt;/h4&gt; 
&lt;p&gt;Inspired by the previous success in LLM, we propose to enhance the performance of the generative model by Reinforcement Learning. Specifically, we focus on the motion quality because we find that the main drawback of our generative model is:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;the generative model does not handle well with large, deformable motions.&lt;/li&gt; 
 &lt;li&gt;the generated videos may violate the physical law.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;To avoid the degradation in other metrics, such as text alignment and video quality, we ensure the preference data pairs have comparable text alignment and video quality, while only the motion quality varies. This requirement poses greater challenges in obtaining preference annotations due to the inherently higher costs of human annotation. To address this challenge, we propose a semi-automatic pipeline that strategically combines automatically generated motion pairs and human annotation results. This hybrid approach not only enhances the data scale but also improves alignment with human preferences through curated quality control. Leveraging this enhanced dataset, we first train a specialized reward model to capture the generic motion quality differences between paired samples. This learned reward function subsequently guides the sample selection process for Direct Preference Optimization (DPO), enhancing the motion quality of the generative model.&lt;/p&gt; 
&lt;h4&gt;Diffusion Forcing&lt;/h4&gt; 
&lt;p&gt;We introduce the Diffusion Forcing Transformer to unlock our model’s ability to generate long videos. Diffusion Forcing is a training and sampling strategy where each token is assigned an independent noise level. This allows tokens to be denoised according to arbitrary, per-token schedules. Conceptually, this approach functions as a form of partial masking: a token with zero noise is fully unmasked, while complete noise fully masks it. Diffusion Forcing trains the model to "unmask" any combination of variably noised tokens, using the cleaner tokens as conditional information to guide the recovery of noisy ones. Building on this, our Diffusion Forcing Transformer can extend video generation indefinitely based on the last frames of the previous segment. Note that the synchronous full sequence diffusion is a special case of Diffusion Forcing, where all tokens share the same noise level. This relationship allows us to fine-tune the Diffusion Forcing Transformer from a full-sequence diffusion model.&lt;/p&gt; 
&lt;h4&gt;High-Quality Supervised Fine-Tuning (SFT)&lt;/h4&gt; 
&lt;p&gt;We implement two sequential high-quality supervised fine-tuning (SFT) stages at 540p and 720p resolutions respectively, with the initial SFT phase conducted immediately after pretraining but prior to reinforcement learning (RL) stage.This first-stage SFT serves as a conceptual equilibrium trainer, building upon the foundation model’s pretraining outcomes that utilized only fps24 video data, while strategically removing FPS embedding components to streamline thearchitecture. Trained with the high-quality concept-balanced samples, this phase establishes optimized initialization parameters for subsequent training processes. Following this, we execute a secondary high-resolution SFT at 720p after completing the diffusion forcing stage, incorporating identical loss formulations and the higher-quality concept-balanced datasets by the manually filter. This final refinement phase focuses on resolution increase such that the overall video quality will be further enhanced.&lt;/p&gt; 
&lt;h2&gt;Performance&lt;/h2&gt; 
&lt;p&gt;To comprehensively evaluate our proposed method, we construct the SkyReels-Bench for human assessment and leveraged the open-source &lt;a href="https://github.com/Vchitect/VBench"&gt;V-Bench&lt;/a&gt; for automated evaluation. This allows us to compare our model with the state-of-the-art (SOTA) baselines, including both open-source and proprietary models.&lt;/p&gt; 
&lt;h4&gt;Human Evaluation&lt;/h4&gt; 
&lt;p&gt;For human evaluation, we design SkyReels-Bench with 1,020 text prompts, systematically assessing three dimensions: Instruction Adherence, Motion Quality, Consistency and Visual Quality. This benchmark is designed to evaluate both text-to-video (T2V) and image-to-video (I2V) generation models, providing comprehensive assessment across different generation paradigms. To ensure fairness, all models were evaluated under default settings with consistent resolutions, and no post-generation filtering was applied.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Text To Video Models&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p align="center"&gt; &lt;/p&gt;
&lt;table align="center"&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Model Name&lt;/th&gt; 
   &lt;th&gt;Average&lt;/th&gt; 
   &lt;th&gt;Instruction Adherence&lt;/th&gt; 
   &lt;th&gt;Consistency&lt;/th&gt; 
   &lt;th&gt;Visual Quality&lt;/th&gt; 
   &lt;th&gt;Motion Quality&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://runwayml.com/research/introducing-gen-3-alpha"&gt;Runway-Gen3 Alpha&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;2.53&lt;/td&gt; 
   &lt;td&gt;2.19&lt;/td&gt; 
   &lt;td&gt;2.57&lt;/td&gt; 
   &lt;td&gt;3.23&lt;/td&gt; 
   &lt;td&gt;2.11&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/Tencent/HunyuanVideo"&gt;HunyuanVideo-13B&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;2.82&lt;/td&gt; 
   &lt;td&gt;2.64&lt;/td&gt; 
   &lt;td&gt;2.81&lt;/td&gt; 
   &lt;td&gt;3.20&lt;/td&gt; 
   &lt;td&gt;2.61&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://klingai.com"&gt;Kling-1.6 STD Mode&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;2.99&lt;/td&gt; 
   &lt;td&gt;2.77&lt;/td&gt; 
   &lt;td&gt;3.05&lt;/td&gt; 
   &lt;td&gt;3.39&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;2.76&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://hailuoai.video"&gt;Hailuo-01&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;3.0&lt;/td&gt; 
   &lt;td&gt;2.8&lt;/td&gt; 
   &lt;td&gt;3.08&lt;/td&gt; 
   &lt;td&gt;3.29&lt;/td&gt; 
   &lt;td&gt;2.74&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/Wan-Video/Wan2.1"&gt;Wan2.1-14B&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;3.12&lt;/td&gt; 
   &lt;td&gt;2.91&lt;/td&gt; 
   &lt;td&gt;3.31&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;3.54&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;2.71&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;SkyReels-V2&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;3.14&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;3.15&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;3.35&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;3.34&lt;/td&gt; 
   &lt;td&gt;2.74&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;p&gt;The evaluation demonstrates that our model achieves significant advancements in &lt;strong&gt;instruction adherence (3.15)&lt;/strong&gt; compared to baseline methods, while maintaining competitive performance in &lt;strong&gt;motion quality (2.74)&lt;/strong&gt; without sacrificing the &lt;strong&gt;consistency (3.35)&lt;/strong&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Image To Video Models&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p align="center"&gt; &lt;/p&gt;
&lt;table align="center"&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Model&lt;/th&gt; 
   &lt;th&gt;Average&lt;/th&gt; 
   &lt;th&gt;Instruction Adherence&lt;/th&gt; 
   &lt;th&gt;Consistency&lt;/th&gt; 
   &lt;th&gt;Visual Quality&lt;/th&gt; 
   &lt;th&gt;Motion Quality&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/Tencent/HunyuanVideo"&gt;HunyuanVideo-13B&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;2.84&lt;/td&gt; 
   &lt;td&gt;2.97&lt;/td&gt; 
   &lt;td&gt;2.95&lt;/td&gt; 
   &lt;td&gt;2.87&lt;/td&gt; 
   &lt;td&gt;2.56&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/Wan-Video/Wan2.1"&gt;Wan2.1-14B&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;2.85&lt;/td&gt; 
   &lt;td&gt;3.10&lt;/td&gt; 
   &lt;td&gt;2.81&lt;/td&gt; 
   &lt;td&gt;3.00&lt;/td&gt; 
   &lt;td&gt;2.48&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://hailuoai.video"&gt;Hailuo-01&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;3.05&lt;/td&gt; 
   &lt;td&gt;3.31&lt;/td&gt; 
   &lt;td&gt;2.58&lt;/td&gt; 
   &lt;td&gt;3.55&lt;/td&gt; 
   &lt;td&gt;2.74&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://klingai.com"&gt;Kling-1.6 Pro Mode&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;3.4&lt;/td&gt; 
   &lt;td&gt;3.56&lt;/td&gt; 
   &lt;td&gt;3.03&lt;/td&gt; 
   &lt;td&gt;3.58&lt;/td&gt; 
   &lt;td&gt;3.41&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://runwayml.com/research/introducing-runway-gen-4"&gt;Runway-Gen4&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;3.39&lt;/td&gt; 
   &lt;td&gt;3.75&lt;/td&gt; 
   &lt;td&gt;3.2&lt;/td&gt; 
   &lt;td&gt;3.4&lt;/td&gt; 
   &lt;td&gt;3.37&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;SkyReels-V2-DF&lt;/td&gt; 
   &lt;td&gt;3.24&lt;/td&gt; 
   &lt;td&gt;3.64&lt;/td&gt; 
   &lt;td&gt;3.21&lt;/td&gt; 
   &lt;td&gt;3.18&lt;/td&gt; 
   &lt;td&gt;2.93&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;SkyReels-V2-I2V&lt;/td&gt; 
   &lt;td&gt;3.29&lt;/td&gt; 
   &lt;td&gt;3.42&lt;/td&gt; 
   &lt;td&gt;3.18&lt;/td&gt; 
   &lt;td&gt;3.56&lt;/td&gt; 
   &lt;td&gt;3.01&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;p&gt;Our results demonstrate that both &lt;strong&gt;SkyReels-V2-I2V (3.29)&lt;/strong&gt; and &lt;strong&gt;SkyReels-V2-DF (3.24)&lt;/strong&gt; achieve state-of-the-art performance among open-source models, significantly outperforming HunyuanVideo-13B (2.84) and Wan2.1-14B (2.85) across all quality dimensions. With an average score of 3.29, SkyReels-V2-I2V demonstrates comparable performance to proprietary models Kling-1.6 (3.4) and Runway-Gen4 (3.39).&lt;/p&gt; 
&lt;h4&gt;VBench&lt;/h4&gt; 
&lt;p&gt;To objectively compare SkyReels-V2 Model against other leading open-source Text-To-Video models, we conduct comprehensive evaluations using the public benchmark &lt;a href="https://github.com/Vchitect/VBench"&gt;V-Bench&lt;/a&gt;. Our evaluation specifically leverages the benchmark’s longer version prompt. For fair comparison with baseline models, we strictly follow their recommended setting for inference.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;/p&gt;
&lt;table align="center"&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Model&lt;/th&gt; 
   &lt;th&gt;Total Score&lt;/th&gt; 
   &lt;th&gt;Quality Score&lt;/th&gt; 
   &lt;th&gt;Semantic Score&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/hpcaitech/Open-Sora"&gt;OpenSora 2.0&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;81.5 %&lt;/td&gt; 
   &lt;td&gt;82.1 %&lt;/td&gt; 
   &lt;td&gt;78.2 %&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/THUDM/CogVideo"&gt;CogVideoX1.5-5B&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;80.3 %&lt;/td&gt; 
   &lt;td&gt;80.9 %&lt;/td&gt; 
   &lt;td&gt;77.9 %&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/Tencent/HunyuanVideo"&gt;HunyuanVideo-13B&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;82.7 %&lt;/td&gt; 
   &lt;td&gt;84.4 %&lt;/td&gt; 
   &lt;td&gt;76.2 %&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/Wan-Video/Wan2.1"&gt;Wan2.1-14B&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;83.7 %&lt;/td&gt; 
   &lt;td&gt;84.2 %&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;81.4 %&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;SkyReels-V2&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;83.9 %&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;84.7 %&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;80.8 %&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;p&gt;The VBench results demonstrate that SkyReels-V2 outperforms all compared models including HunyuanVideo-13B and Wan2.1-14B, With the highest &lt;strong&gt;total score (83.9%)&lt;/strong&gt; and &lt;strong&gt;quality score (84.7%)&lt;/strong&gt;. In this evaluation, the semantic score is slightly lower than Wan2.1-14B, while we outperform Wan2.1-14B in human evaluations, with the primary gap attributed to V-Bench’s insufficient evaluation of shot-scenario semantic adherence.&lt;/p&gt; 
&lt;h2&gt;Acknowledgements&lt;/h2&gt; 
&lt;p&gt;We would like to thank the contributors of &lt;a href="https://github.com/Wan-Video/Wan2.1"&gt;Wan 2.1&lt;/a&gt;, &lt;a href="https://github.com/xdit-project/xDiT"&gt;XDit&lt;/a&gt; and &lt;a href="https://qwenlm.github.io/blog/qwen2.5/"&gt;Qwen 2.5&lt;/a&gt; repositories, for their open research and contributions.&lt;/p&gt; 
&lt;h2&gt;Citation&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bibtex"&gt;@misc{chen2025skyreelsv2infinitelengthfilmgenerative,
      title={SkyReels-V2: Infinite-length Film Generative Model}, 
      author={Guibin Chen and Dixuan Lin and Jiangping Yang and Chunze Lin and Junchen Zhu and Mingyuan Fan and Hao Zhang and Sheng Chen and Zheng Chen and Chengcheng Ma and Weiming Xiong and Wei Wang and Nuo Pang and Kang Kang and Zhiheng Xu and Yuzhe Jin and Yupeng Liang and Yubing Song and Peng Zhao and Boyuan Xu and Di Qiu and Debang Li and Zhengcong Fei and Yang Li and Yahui Zhou},
      year={2025},
      eprint={2504.13074},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2504.13074}, 
}
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>OSU-NLP-Group/HippoRAG</title>
      <link>https://github.com/OSU-NLP-Group/HippoRAG</link>
      <description>&lt;p&gt;[NeurIPS'24] HippoRAG is a novel RAG framework inspired by human long-term memory that enables LLMs to continuously integrate knowledge across external documents. RAG + Knowledge Graphs + Personalized PageRank.&lt;/p&gt;&lt;hr&gt;&lt;h1 align="center"&gt;HippoRAG 2: From RAG to Memory&lt;/h1&gt; 
&lt;p align="center"&gt; &lt;img src="https://github.com/OSU-NLP-Group/HippoRAG/raw/main/images/hippo_brain.png" width="55%" style="max-width: 300px;"&gt; &lt;/p&gt; 
&lt;p&gt;&lt;a href="https://colab.research.google.com/drive/1nuelysWsXL8F5xH6q4JYJI8mvtlmeM9O#scrollTo=TjHdNe2KC81K"&gt;&lt;img align="center" src="https://colab.research.google.com/assets/colab-badge.svg?sanitize=true"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://arxiv.org/abs/2502.14802"&gt;&lt;img align="center" src="https://img.shields.io/badge/arXiv-2502.14802%20HippoRAG%202-b31b1b"&gt;&lt;/a&gt; &lt;a href="https://huggingface.co/datasets/osunlp/HippoRAG_2/tree/main"&gt;&lt;img align="center" src="https://img.shields.io/badge/%F0%9F%A4%97%20Dataset-HippoRAG%202-yellow"&gt;&lt;/a&gt; &lt;a href="https://arxiv.org/abs/2405.14831"&gt;&lt;img align="center" src="https://img.shields.io/badge/arXiv-2405.14831%20HippoRAG%201-b31b1b"&gt;&lt;/a&gt; &lt;a href="https://github.com/OSU-NLP-Group/HippoRAG/tree/legacy"&gt;&lt;img align="center" src="https://img.shields.io/badge/GitHub-HippoRAG%201-blue"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;HippoRAG 2 is a powerful memory framework for LLMs that enhances their ability to recognize and utilize connections in new knowledge—mirroring a key function of human long-term memory.&lt;/h3&gt; 
&lt;p&gt;Our experiments show that HippoRAG 2 improves associativity (multi-hop retrieval) and sense-making (the process of integrating large and complex contexts) in even the most advanced RAG systems, without sacrificing their performance on simpler tasks.&lt;/p&gt; 
&lt;p&gt;Like its predecessor, HippoRAG 2 remains cost and latency efficient in online processes, while using significantly fewer resources for offline indexing compared to other graph-based solutions such as GraphRAG, RAPTOR, and LightRAG.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img align="center" src="https://github.com/OSU-NLP-Group/HippoRAG/raw/main/images/intro.png"&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;b&gt;Figure 1:&lt;/b&gt; Evaluation of continual learning capabilities across three key dimensions: factual memory (NaturalQuestions, PopQA), sense-making (NarrativeQA), and associativity (MuSiQue, 2Wiki, HotpotQA, and LV-Eval). HippoRAG 2 surpasses other methods across all categories, bringing it one step closer to true long-term memory. &lt;/p&gt; 
&lt;p align="center"&gt; &lt;img align="center" src="https://github.com/OSU-NLP-Group/HippoRAG/raw/main/images/methodology.png"&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;b&gt;Figure 2:&lt;/b&gt; HippoRAG 2 methodology. &lt;/p&gt; 
&lt;h4&gt;Check out our papers to learn more:&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://arxiv.org/abs/2405.14831"&gt;&lt;strong&gt;HippoRAG: Neurobiologically Inspired Long-Term Memory for Large Language Models&lt;/strong&gt;&lt;/a&gt; [NeurIPS '24].&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://arxiv.org/abs/2502.14802"&gt;&lt;strong&gt;From RAG to Memory: Non-Parametric Continual Learning for Large Language Models&lt;/strong&gt;&lt;/a&gt; [ICML '25].&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;conda create -n hipporag python=3.10
conda activate hipporag
pip install hipporag
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Initialize the environmental variables and activate the environment:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;export CUDA_VISIBLE_DEVICES=0,1,2,3
export HF_HOME=&amp;lt;path to Huggingface home directory&amp;gt;
export OPENAI_API_KEY=&amp;lt;your openai api key&amp;gt;   # if you want to use OpenAI model

conda activate hipporag
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;h3&gt;OpenAI Models&lt;/h3&gt; 
&lt;p&gt;This simple example will illustrate how to use &lt;code&gt;hipporag&lt;/code&gt; with any OpenAI model:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from hipporag import HippoRAG

# Prepare datasets and evaluation
docs = [
    "Oliver Badman is a politician.",
    "George Rankin is a politician.",
    "Thomas Marwick is a politician.",
    "Cinderella attended the royal ball.",
    "The prince used the lost glass slipper to search the kingdom.",
    "When the slipper fit perfectly, Cinderella was reunited with the prince.",
    "Erik Hort's birthplace is Montebello.",
    "Marina is bom in Minsk.",
    "Montebello is a part of Rockland County."
]

save_dir = 'outputs'# Define save directory for HippoRAG objects (each LLM/Embedding model combination will create a new subdirectory)
llm_model_name = 'gpt-4o-mini' # Any OpenAI model name
embedding_model_name = 'nvidia/NV-Embed-v2'# Embedding model name (NV-Embed, GritLM or Contriever for now)

#Startup a HippoRAG instance
hipporag = HippoRAG(save_dir=save_dir, 
                    llm_model_name=llm_model_name,
                    embedding_model_name=embedding_model_name) 

#Run indexing
hipporag.index(docs=docs)

#Separate Retrieval &amp;amp; QA
queries = [
    "What is George Rankin's occupation?",
    "How did Cinderella reach her happy ending?",
    "What county is Erik Hort's birthplace a part of?"
]

retrieval_results = hipporag.retrieve(queries=queries, num_to_retrieve=2)
qa_results = hipporag.rag_qa(retrieval_results)

#Combined Retrieval &amp;amp; QA
rag_results = hipporag.rag_qa(queries=queries)

#For Evaluation
answers = [
    ["Politician"],
    ["By going to the ball."],
    ["Rockland County"]
]

gold_docs = [
    ["George Rankin is a politician."],
    ["Cinderella attended the royal ball.",
    "The prince used the lost glass slipper to search the kingdom.",
    "When the slipper fit perfectly, Cinderella was reunited with the prince."],
    ["Erik Hort's birthplace is Montebello.",
    "Montebello is a part of Rockland County."]
]

rag_results = hipporag.rag_qa(queries=queries, 
                              gold_docs=gold_docs,
                              gold_answers=answers)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Example (OpenAI Compatible Embeddings)&lt;/h4&gt; 
&lt;p&gt;If you want to use LLMs and Embeddings Compatible to OpenAI, please use the following methods.&lt;/p&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;hipporag = HippoRAG(save_dir=save_dir, 
    llm_model_name='Your LLM Model name',
    llm_base_url='Your LLM Model url',
    embedding_model_name='Your Embedding model name',  
    embedding_base_url='Your Embedding model url')
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Local Deployment (vLLM)&lt;/h3&gt; 
&lt;p&gt;This simple example will illustrate how to use &lt;code&gt;hipporag&lt;/code&gt; with any vLLM-compatible locally deployed LLM.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Run a local &lt;a href="https://docs.vllm.ai/en/latest/getting_started/quickstart.html#quickstart-online"&gt;OpenAI-compatible vLLM server&lt;/a&gt; with specified GPUs (make sure you leave enough memory for your embedding model).&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;export CUDA_VISIBLE_DEVICES=0,1
export VLLM_WORKER_MULTIPROC_METHOD=spawn
export HF_HOME=&amp;lt;path to Huggingface home directory&amp;gt;

conda activate hipporag  # vllm should be in this environment

# Tune gpu-memory-utilization or max_model_len to fit your GPU memory, if OOM occurs
vllm serve meta-llama/Llama-3.3-70B-Instruct --tensor-parallel-size 2 --max_model_len 4096 --gpu-memory-utilization 0.95 
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Now you can use very similar code to the one above to use &lt;code&gt;hipporag&lt;/code&gt;:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;save_dir = 'outputs'# Define save directory for HippoRAG objects (each LLM/Embedding model combination will create a new subdirectory)
llm_model_name = # Any OpenAI model name
embedding_model_name = # Embedding model name (NV-Embed, GritLM or Contriever for now)
llm_base_url= # Base url for your deployed LLM (i.e. http://localhost:8000/v1)

hipporag = HippoRAG(save_dir=save_dir,
                    llm_model_name=llm_model,
                    embedding_model_name=embedding_model_name,
                    llm_base_url=llm_base_url)

# Same Indexing, Retrieval and QA as running OpenAI models above
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Testing&lt;/h2&gt; 
&lt;p&gt;When making a contribution to HippoRAG, please run the scripts below to ensure that your changes do not result in unexpected behavior from our core modules.&lt;/p&gt; 
&lt;p&gt;These scripts test for indexing, graph loading, document deletion and incremental updates to a HippoRAG object.&lt;/p&gt; 
&lt;h3&gt;OpenAI Test&lt;/h3&gt; 
&lt;p&gt;To test HippoRAG with an OpenAI LLM and embedding model, simply run the following. The cost of this test will be negligible.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;export OPENAI_API_KEY=&amp;lt;your openai api key&amp;gt; 

conda activate hipporag

python tests_openai.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Local Test&lt;/h3&gt; 
&lt;p&gt;To test locally, you must deploy a vLLM instance. We choose to deploy a smaller 8B model &lt;code&gt;Llama-3.1-8B-Instruct&lt;/code&gt; for cheaper testing.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;export CUDA_VISIBLE_DEVICES=0
export VLLM_WORKER_MULTIPROC_METHOD=spawn
export HF_HOME=&amp;lt;path to Huggingface home directory&amp;gt;

conda activate hipporag  # vllm should be in this environment

# Tune gpu-memory-utilization or max_model_len to fit your GPU memory, if OOM occurs
vllm serve meta-llama/Llama-3.1-8B-Instruct --tensor-parallel-size 2 --max_model_len 4096 --gpu-memory-utilization 0.95 --port 6578
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then, we run the following test script:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;CUDA_VISIBLE=1 python tests_local.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Reproducing our Experiments&lt;/h2&gt; 
&lt;p&gt;To use our code to run experiments we recommend you clone this repository and follow the structure of the &lt;code&gt;main.py&lt;/code&gt; script.&lt;/p&gt; 
&lt;h3&gt;Data for Reproducibility&lt;/h3&gt; 
&lt;p&gt;We evaluated several sampled datasets in our paper, some of which are already included in the &lt;code&gt;reproduce/dataset&lt;/code&gt; directory of this repo. For the complete set of datasets, please visit our &lt;a href="https://huggingface.co/datasets/osunlp/HippoRAG_v2"&gt;HuggingFace dataset&lt;/a&gt; and place them under &lt;code&gt;reproduce/dataset&lt;/code&gt;. We also provide the OpenIE results for both &lt;code&gt;gpt-4o-mini&lt;/code&gt; and &lt;code&gt;Llama-3.3-70B-Instruct&lt;/code&gt; for our &lt;code&gt;musique&lt;/code&gt; sample under &lt;code&gt;outputs/musique&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;To test your environment is properly set up, you can use the small dataset &lt;code&gt;reproduce/dataset/sample.json&lt;/code&gt; for debugging as shown below.&lt;/p&gt; 
&lt;h3&gt;Running Indexing &amp;amp; QA&lt;/h3&gt; 
&lt;p&gt;Initialize the environmental variables and activate the environment:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;export CUDA_VISIBLE_DEVICES=0,1,2,3
export HF_HOME=&amp;lt;path to Huggingface home directory&amp;gt;
export OPENAI_API_KEY=&amp;lt;your openai api key&amp;gt;   # if you want to use OpenAI model

conda activate hipporag
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Run with OpenAI Model&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;dataset=sample  # or any other dataset under `reproduce/dataset`

# Run OpenAI model
python main.py --dataset $dataset --llm_base_url https://api.openai.com/v1 --llm_name gpt-4o-mini --embedding_name nvidia/NV-Embed-v2
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Run with vLLM (Llama)&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;As above, run a local &lt;a href="https://docs.vllm.ai/en/latest/getting_started/quickstart.html#quickstart-online"&gt;OpenAI-compatible vLLM server&lt;/a&gt; with specified GPU.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;export CUDA_VISIBLE_DEVICES=0,1
export VLLM_WORKER_MULTIPROC_METHOD=spawn
export HF_HOME=&amp;lt;path to Huggingface home directory&amp;gt;

conda activate hipporag  # vllm should be in this environment

# Tune gpu-memory-utilization or max_model_len to fit your GPU memory, if OOM occurs
vllm serve meta-llama/Llama-3.3-70B-Instruct --tensor-parallel-size 2 --max_model_len 4096 --gpu-memory-utilization 0.95 
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Use another GPUs to run the main program in another terminal.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;export CUDA_VISIBLE_DEVICES=2,3  # set another GPUs while vLLM server is running
export HF_HOME=&amp;lt;path to Huggingface home directory&amp;gt;
dataset=sample

python main.py --dataset $dataset --llm_base_url http://localhost:8000/v1 --llm_name meta-llama/Llama-3.3-70B-Instruct --embedding_name nvidia/NV-Embed-v2
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Advanced: Run with vLLM offline batch&lt;/h4&gt; 
&lt;p&gt;vLLM offers an &lt;a href="https://docs.vllm.ai/en/latest/getting_started/quickstart.html#offline-batched-inference"&gt;offline batch mode&lt;/a&gt; for faster inference, which could bring us more than 3x faster indexing compared to vLLM online server.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Use the following command to run the main program with vLLM offline batch mode.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;export CUDA_VISIBLE_DEVICES=0,1,2,3 # use all GPUs for faster offline indexing
export VLLM_WORKER_MULTIPROC_METHOD=spawn
export HF_HOME=&amp;lt;path to Huggingface home directory&amp;gt;
export OPENAI_API_KEY=''
dataset=sample

python main.py --dataset $dataset --llm_name meta-llama/Llama-3.3-70B-Instruct --openie_mode offline --skip_graph
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;After the first step, OpenIE result is saved to file. Go back to run vLLM online server and main program as described in the &lt;code&gt;Run with vLLM (Llama)&lt;/code&gt; main section.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Debugging Note&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;/reproduce/dataset/sample.json&lt;/code&gt; is a small dataset specifically for debugging.&lt;/li&gt; 
 &lt;li&gt;When debugging vLLM offline mode, set &lt;code&gt;tensor_parallel_size&lt;/code&gt; as &lt;code&gt;1&lt;/code&gt; in &lt;code&gt;hipporag/llm/vllm_offline.py&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;If you want to rerun a particular experiment, remember to clear the saved files, including OpenIE results and knowledge graph, e.g.,&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;rm reproduce/dataset/openie_results/openie_sample_results_ner_meta-llama_Llama-3.3-70B-Instruct_3.json
rm -rf outputs/sample/sample_meta-llama_Llama-3.3-70B-Instruct_nvidia_NV-Embed-v2
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Custom Datasets&lt;/h3&gt; 
&lt;p&gt;To setup your own custom dataset for evaluation, follow the format and naming convention shown in &lt;code&gt;reproduce/dataset/sample_corpus.json&lt;/code&gt; (your dataset's name should be followed by &lt;code&gt;_corpus.json&lt;/code&gt;). If running an experiment with pre-defined questions, organize your query corpus according to the query file &lt;code&gt;reproduce/dataset/sample.json&lt;/code&gt;, be sure to also follow our naming convention.&lt;/p&gt; 
&lt;p&gt;The corpus and optional query JSON files should have the following format:&lt;/p&gt; 
&lt;h4&gt;Retrieval Corpus JSON&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;[
  {
    "title": "FIRST PASSAGE TITLE",
    "text": "FIRST PASSAGE TEXT",
    "idx": 0
  },
  {
    "title": "SECOND PASSAGE TITLE",
    "text": "SECOND PASSAGE TEXT",
    "idx": 1
  }
]
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;(Optional) Query JSON&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;
[
  {
    "id": "sample/question_1.json",
    "question": "QUESTION",
    "answer": [
      "ANSWER"
    ],
    "answerable": true,
    "paragraphs": [
      {
        "title": "{FIRST SUPPORTING PASSAGE TITLE}",
        "text": "{FIRST SUPPORTING PASSAGE TEXT}",
        "is_supporting": true,
        "idx": 0
      },
      {
        "title": "{SECOND SUPPORTING PASSAGE TITLE}",
        "text": "{SECOND SUPPORTING PASSAGE TEXT}",
        "is_supporting": true,
        "idx": 1
      }
    ]
  }
]
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;(Optional) Chunking Corpus&lt;/h4&gt; 
&lt;p&gt;When preparing your data, you may need to chunk each passage, as longer passage may be too complex for the OpenIE process.&lt;/p&gt; 
&lt;h2&gt;Code Structure&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;📦 .
│-- 📂 src/hipporag
│   ├── 📂 embedding_model          # Implementation of all embedding models
│   │   ├── __init__.py             # Getter function for get specific embedding model classes
|   |   ├── base.py                 # Base embedding model class `BaseEmbeddingModel` to inherit and `EmbeddingConfig`
|   |   ├── NVEmbedV2.py            # Implementation of NV-Embed-v2 model
|   |   ├── ...
│   ├── 📂 evaluation               # Implementation of all evaluation metrics
│   │   ├── __init__.py
|   |   ├── base.py                 # Base evaluation metric class `BaseMetric` to inherit
│   │   ├── qa_eval.py              # Eval metrics for QA
│   │   ├── retrieval_eval.py       # Eval metrics for retrieval
│   ├── 📂 information_extraction  # Implementation of all information extraction models
│   │   ├── __init__.py
|   |   ├── openie_openai_gpt.py    # Model for OpenIE with OpenAI GPT
|   |   ├── openie_vllm_offline.py  # Model for OpenIE with LLMs deployed offline with vLLM
│   ├── 📂 llm                      # Classes for inference with large language models
│   │   ├── __init__.py             # Getter function
|   |   ├── base.py                 # Config class for LLM inference and base LLM inference class to inherit
|   |   ├── openai_gpt.py           # Class for inference with OpenAI GPT
|   |   ├── vllm_llama.py           # Class for inference using a local vLLM server
|   |   ├── vllm_offline.py         # Class for inference using the vLLM API directly
│   ├── 📂 prompts                  # Prompt templates and prompt template manager class
|   │   ├── 📂 dspy_prompts         # Prompts for filtering
|   │   │   ├── ...
|   │   ├── 📂 templates            # All prompt templates for template manager to load
|   │   │   ├── README.md           # Documentations of usage of prompte template manager and prompt template files
|   │   │   ├── __init__.py
|   │   │   ├── triple_extraction.py
|   │   │   ├── ...
│   │   ├── __init__.py
|   |   ├── linking.py              # Instruction for linking
|   |   ├── prompt_template_manager.py  # Implementation of prompt template manager
│   ├── 📂 utils                    # All utility functions used across this repo (the file name indicates its relevant usage)
│   │   ├── config_utils.py         # We use only one config across all modules and its setup is specified here
|   |   ├── ...
│   ├── __init__.py
│   ├── HippoRAG.py          # Highest level class for initiating retrieval, question answering, and evaluations
│   ├── embedding_store.py   # Storage database to load, manage and save embeddings for passages, entities and facts.
│   ├── rerank.py            # Reranking and filtering methods
│-- 📂 examples
│   ├── ...
│   ├── ...
│-- 📜 README.md
│-- 📜 requirements.txt   # Dependencies list
│-- 📜 .gitignore         # Files to exclude from Git


&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Contact&lt;/h2&gt; 
&lt;p&gt;Questions or issues? File an issue or contact &lt;a href="mailto:jimenezgutierrez.1@osu.edu"&gt;Bernal Jiménez Gutiérrez&lt;/a&gt;, &lt;a href="mailto:shu.251@osu.edu"&gt;Yiheng Shu&lt;/a&gt;, &lt;a href="mailto:su.809@osu.edu"&gt;Yu Su&lt;/a&gt;, The Ohio State University&lt;/p&gt; 
&lt;h2&gt;Citation&lt;/h2&gt; 
&lt;p&gt;If you find this work useful, please consider citing our papers:&lt;/p&gt; 
&lt;h3&gt;HippoRAG 2&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;@misc{gutiérrez2025ragmemorynonparametriccontinual,
      title={From RAG to Memory: Non-Parametric Continual Learning for Large Language Models}, 
      author={Bernal Jiménez Gutiérrez and Yiheng Shu and Weijian Qi and Sizhe Zhou and Yu Su},
      year={2025},
      eprint={2502.14802},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2502.14802}, 
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;HippoRAG&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;@inproceedings{gutiérrez2024hipporag,
      title={HippoRAG: Neurobiologically Inspired Long-Term Memory for Large Language Models}, 
      author={Bernal Jiménez Gutiérrez and Yiheng Shu and Yu Gu and Michihiro Yasunaga and Yu Su},
      booktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems},
      year={2024},
      url={https://openreview.net/forum?id=hkujvAPVsg}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;TODO:&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; Add support for more embedding models&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; Add support for embedding endpoints&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled&gt; Add support for vector database integration&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Please feel free to open an issue or PR if you have any questions or suggestions.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>microsoft/mcp-for-beginners</title>
      <link>https://github.com/microsoft/mcp-for-beginners</link>
      <description>&lt;p&gt;This open-source curriculum introduces the fundamentals of Model Context Protocol (MCP) through real-world, cross-language examples in .NET, Java, TypeScript, JavaScript, and Python. Designed for developers, it focuses on practical techniques for building modular, scalable, and secure AI workflows from session setup to service orchestration.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/images/mcp-beginners.png" alt="MCP-for-beginners"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://GitHub.com/microsoft/mcp-for-beginners/graphs/contributors"&gt;&lt;img src="https://img.shields.io/github/contributors/microsoft/mcp-for-beginners.svg?sanitize=true" alt="GitHub contributors"&gt;&lt;/a&gt; &lt;a href="https://GitHub.com/microsoft/mcp-for-beginners/issues"&gt;&lt;img src="https://img.shields.io/github/issues/microsoft/mcp-for-beginners.svg?sanitize=true" alt="GitHub issues"&gt;&lt;/a&gt; &lt;a href="https://GitHub.com/microsoft/mcp-for-beginners/pulls"&gt;&lt;img src="https://img.shields.io/github/issues-pr/microsoft/mcp-for-beginners.svg?sanitize=true" alt="GitHub pull-requests"&gt;&lt;/a&gt; &lt;a href="http://makeapullrequest.com"&gt;&lt;img src="https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat-square" alt="PRs Welcome"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://GitHub.com/microsoft/mcp-for-beginners/watchers"&gt;&lt;img src="https://img.shields.io/github/watchers/microsoft/mcp-for-beginners.svg?style=social&amp;amp;label=Watch" alt="GitHub watchers"&gt;&lt;/a&gt; &lt;a href="https://GitHub.com/microsoft/mcp-for-beginners/fork"&gt;&lt;img src="https://img.shields.io/github/forks/microsoft/mcp-for-beginners.svg?style=social&amp;amp;label=Fork" alt="GitHub forks"&gt;&lt;/a&gt; &lt;a href="https://GitHub.com/microsoft/mcp-for-beginners/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/microsoft/mcp-for-beginners?style=social&amp;amp;label=Star" alt="GitHub stars"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://discord.com/invite/ByRwuEEgH4"&gt;&lt;img src="https://dcbadge.limes.pink/api/server/ByRwuEEgH4" alt="Microsoft Azure AI Foundry Discord"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Follow these steps to get started using these resources:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Fork the Repository&lt;/strong&gt;: Click &lt;a href="https://GitHub.com/microsoft/mcp-for-beginners/fork"&gt;&lt;img src="https://img.shields.io/github/forks/microsoft/mcp-for-beginners.svg?style=social&amp;amp;label=Fork" alt="GitHub forks"&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Clone the Repository&lt;/strong&gt;: &lt;code&gt;git clone https://github.com/microsoft/mcp-for-beginners.git&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://discord.com/invite/ByRwuEEgH4"&gt;&lt;strong&gt;Join The Azure AI Foundry Discord and meet experts and fellow developers&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;🌐 Multi-Language Support&lt;/h3&gt; 
&lt;h4&gt;Supported via GitHub Action (Automated &amp;amp; Always Up-to-Date)&lt;/h4&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/fr/README.md"&gt;French&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/es/README.md"&gt;Spanish&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/de/README.md"&gt;German&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/ru/README.md"&gt;Russian&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/ar/README.md"&gt;Arabic&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/fa/README.md"&gt;Persian (Farsi)&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/ur/README.md"&gt;Urdu&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/zh/README.md"&gt;Chinese (Simplified)&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/mo/README.md"&gt;Chinese (Traditional, Macau)&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/hk/README.md"&gt;Chinese (Traditional, Hong Kong)&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/tw/README.md"&gt;Chinese (Traditional, Taiwan)&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/ja/README.md"&gt;Japanese&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/ko/README.md"&gt;Korean&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/hi/README.md"&gt;Hindi&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/bn/README.md"&gt;Bengali&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/mr/README.md"&gt;Marathi&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/ne/README.md"&gt;Nepali&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/pa/README.md"&gt;Punjabi (Gurmukhi)&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/pt/README.md"&gt;Portuguese (Portugal)&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/br/README.md"&gt;Portuguese (Brazil)&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/it/README.md"&gt;Italian&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/pl/README.md"&gt;Polish&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/tr/README.md"&gt;Turkish&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/el/README.md"&gt;Greek&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/th/README.md"&gt;Thai&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/sv/README.md"&gt;Swedish&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/da/README.md"&gt;Danish&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/no/README.md"&gt;Norwegian&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/fi/README.md"&gt;Finnish&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/nl/README.md"&gt;Dutch&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/he/README.md"&gt;Hebrew&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/vi/README.md"&gt;Vietnamese&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/id/README.md"&gt;Indonesian&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/ms/README.md"&gt;Malay&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/tl/README.md"&gt;Tagalog (Filipino)&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/sw/README.md"&gt;Swahili&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/hu/README.md"&gt;Hungarian&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/cs/README.md"&gt;Czech&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/sk/README.md"&gt;Slovak&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/ro/README.md"&gt;Romanian&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/bg/README.md"&gt;Bulgarian&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/sr/README.md"&gt;Serbian (Cyrillic)&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/hr/README.md"&gt;Croatian&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/sl/README.md"&gt;Slovenian&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/uk/README.md"&gt;Ukrainian&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/my/README.md"&gt;Burmese (Myanmar)&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;🚀 Model Context Protocol (MCP) Curriculum for Beginners&lt;/h1&gt; 
&lt;h2&gt;&lt;strong&gt;Learn MCP with Hands-on Code Examples in C#, Java, JavaScript, Python, and TypeScript&lt;/strong&gt;&lt;/h2&gt; 
&lt;h2&gt;🧠 Overview of the Model Context Protocol Curriculum&lt;/h2&gt; 
&lt;p&gt;The &lt;strong&gt;Model Context Protocol (MCP)&lt;/strong&gt; is a cutting-edge framework designed to standardize interactions between AI models and client applications. This open-source curriculum offers a structured learning path, complete with practical coding examples and real-world use cases, across popular programming languages including C#, Java, JavaScript, TypeScript, and Python.&lt;/p&gt; 
&lt;p&gt;Whether you're an AI developer, system architect, or software engineer, this guide is your comprehensive resource for mastering MCP fundamentals and implementation strategies.&lt;/p&gt; 
&lt;h2&gt;🔗 Official MCP Resources&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;📘 &lt;a href="https://modelcontextprotocol.io/"&gt;MCP Documentation&lt;/a&gt; – Detailed tutorials and user guides&lt;/li&gt; 
 &lt;li&gt;📜 &lt;a href="https://modelcontextprotocol.io/docs/"&gt;MCP Specification&lt;/a&gt; – Protocol architecture and technical references&lt;/li&gt; 
 &lt;li&gt;📜 &lt;a href="https://spec.modelcontextprotocol.io/"&gt;Original MCP Specification&lt;/a&gt; – Legacy technical references (may contain additional details)&lt;/li&gt; 
 &lt;li&gt;🧑‍💻 &lt;a href="https://github.com/modelcontextprotocol"&gt;MCP GitHub Repository&lt;/a&gt; – Open-source SDKs, tools, and code samples&lt;/li&gt; 
 &lt;li&gt;🌐 &lt;a href="https://github.com/orgs/modelcontextprotocol/discussions"&gt;MCP Community&lt;/a&gt; – Join discussions and contribute to the community&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Join us for MCP Dev Days 29-30th July 2025&lt;/h2&gt; 
&lt;p&gt;Get ready for two days of deep technical insight, community connection, and hands-on learning at MCP Dev Days, a virtual event dedicated to the Model Context Protocol (MCP) — the emerging standard that bridges AI models and the tools they rely on.&lt;/p&gt; 
&lt;p&gt;➡️ &lt;a href="https://developer.microsoft.com/en-us/reactor/series/S-1563/"&gt;Register for MCP Dev Days&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;You can watch MCP Dev Days by registering on our event page: &lt;a href="https://aka.ms/mcpdevdays"&gt;https://aka.ms/mcpdevdays&lt;/a&gt;. From there, you’ll be able to join a live stream on YouTube or Twitch. All of the content is recorded and will be available afterwards on the Microsoft Developer YouTube channel. Source code for the demos will be available on GitHub too.&lt;/p&gt; 
&lt;h3&gt;Event Details&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Dates: July 29 (Day 1) &amp;amp; July 30 (Day 2)&lt;/li&gt; 
 &lt;li&gt;Time: 9:00 AM PST daily&lt;/li&gt; 
 &lt;li&gt;Where: Online – join from anywhere!&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Day 1: MCP Productivity, DevTools, &amp;amp; Community:&lt;/h4&gt; 
&lt;p&gt;Is all about empowering developers to use MCP in their developer workflow and celebrating the amazing MCP community. We’ll be joined with community members and partners such as Arcade, Block, Okta, and Neon to see how they are collaborating with Microsoft to shape an open, extensible MCP ecosystem. Real-world demos across VS Code, Visual Studio, GitHub Copilot, and popular community tools Practical, context-driven dev workflows Community-led sessions and insights Whether you’re just getting started with MCP or already building with it, Day 1 will set the stage with inspiration and actionable takeaways.&lt;/p&gt; 
&lt;h4&gt;Day 2: Build MCP Servers with Confidence&lt;/h4&gt; 
&lt;p&gt;Is for MCP builders. We’ll go deep into implementation strategies and best practices for creating MCP servers and integrating MCP into your AI workflows.&lt;/p&gt; 
&lt;h3&gt;Topics include:&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Building MCP Servers and integrating them into agent experiences&lt;/li&gt; 
 &lt;li&gt;Prompt-driven development&lt;/li&gt; 
 &lt;li&gt;Security best practices&lt;/li&gt; 
 &lt;li&gt;Using building blocks like Functions, ACA, and API Management&lt;/li&gt; 
 &lt;li&gt;Registry alignment and tooling (1P + 3P)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;If you’re a developer, tool builder, or AI product strategist, this day is packed with the insights you need to build scalable, secure, and future-ready MCP solutions.&lt;/p&gt; 
&lt;h2&gt;🧭 MCP Curriculum Overview&lt;/h2&gt; 
&lt;h3&gt;📚 Complete Curriculum Structure&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Module&lt;/th&gt; 
   &lt;th&gt;Topic&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Link&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Module 1-3: Fundamentals&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;00&lt;/td&gt; 
   &lt;td&gt;Introduction to MCP&lt;/td&gt; 
   &lt;td&gt;Overview of the Model Context Protocol and its significance in AI pipelines&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/00-Introduction/README.md"&gt;Read more&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;01&lt;/td&gt; 
   &lt;td&gt;Core Concepts Explained&lt;/td&gt; 
   &lt;td&gt;In-depth exploration of core MCP concepts&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/01-CoreConcepts/README.md"&gt;Read more&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;02&lt;/td&gt; 
   &lt;td&gt;Security in MCP&lt;/td&gt; 
   &lt;td&gt;Security threats and best practices&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/02-Security/README.md"&gt;Read more&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;03&lt;/td&gt; 
   &lt;td&gt;Getting Started with MCP&lt;/td&gt; 
   &lt;td&gt;Environment setup, basic servers/clients, integration&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/03-GettingStarted/README.md"&gt;Read more&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Module 3: Building Your First Server &amp;amp; Client&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;3.1&lt;/td&gt; 
   &lt;td&gt;First Server&lt;/td&gt; 
   &lt;td&gt;Create your first MCP server&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/03-GettingStarted/01-first-server/README.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;3.2&lt;/td&gt; 
   &lt;td&gt;First Client&lt;/td&gt; 
   &lt;td&gt;Develop a basic MCP client&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/03-GettingStarted/02-client/README.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;3.3&lt;/td&gt; 
   &lt;td&gt;Client with LLM&lt;/td&gt; 
   &lt;td&gt;Integrate large language models&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/03-GettingStarted/03-llm-client/README.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;3.4&lt;/td&gt; 
   &lt;td&gt;VS Code Integration&lt;/td&gt; 
   &lt;td&gt;Consume MCP servers in VS Code&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/03-GettingStarted/04-vscode/README.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;3.5&lt;/td&gt; 
   &lt;td&gt;SSE Server&lt;/td&gt; 
   &lt;td&gt;Create servers using Server-Sent Events&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/03-GettingStarted/05-sse-server/README.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;3.6&lt;/td&gt; 
   &lt;td&gt;HTTP Streaming&lt;/td&gt; 
   &lt;td&gt;Implement HTTP streaming in MCP&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/03-GettingStarted/06-http-streaming/README.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;3.7&lt;/td&gt; 
   &lt;td&gt;AI Toolkit&lt;/td&gt; 
   &lt;td&gt;Use AI Toolkit with MCP&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/03-GettingStarted/07-aitk/README.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;3.8&lt;/td&gt; 
   &lt;td&gt;Testing&lt;/td&gt; 
   &lt;td&gt;Test your MCP server implementation&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/03-GettingStarted/08-testing/README.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;3.9&lt;/td&gt; 
   &lt;td&gt;Deployment&lt;/td&gt; 
   &lt;td&gt;Deploy MCP servers to production&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/03-GettingStarted/09-deployment/README.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Module 4-5: Practical &amp;amp; Advanced&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;04&lt;/td&gt; 
   &lt;td&gt;Practical Implementation&lt;/td&gt; 
   &lt;td&gt;SDKs, debugging, testing, reusable prompt templates&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/04-PracticalImplementation/README.md"&gt;Read more&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;05&lt;/td&gt; 
   &lt;td&gt;Advanced Topics in MCP&lt;/td&gt; 
   &lt;td&gt;Multi-modal AI, scaling, enterprise use&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/05-AdvancedTopics/README.md"&gt;Read more&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;5.1&lt;/td&gt; 
   &lt;td&gt;Azure Integration&lt;/td&gt; 
   &lt;td&gt;MCP Integration with Azure&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/05-AdvancedTopics/mcp-integration/README.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;5.2&lt;/td&gt; 
   &lt;td&gt;Multi-modality&lt;/td&gt; 
   &lt;td&gt;Working with multiple modalities&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/05-AdvancedTopics/mcp-multi-modality/README.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;5.3&lt;/td&gt; 
   &lt;td&gt;OAuth2 Demo&lt;/td&gt; 
   &lt;td&gt;Implement OAuth2 authentication&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/05-AdvancedTopics/mcp-oauth2-demo/README.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;5.4&lt;/td&gt; 
   &lt;td&gt;Root Contexts&lt;/td&gt; 
   &lt;td&gt;Understand and implement root contexts&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/05-AdvancedTopics/mcp-root-contexts/README.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;5.5&lt;/td&gt; 
   &lt;td&gt;Routing&lt;/td&gt; 
   &lt;td&gt;MCP routing strategies&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/05-AdvancedTopics/mcp-routing/README.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;5.6&lt;/td&gt; 
   &lt;td&gt;Sampling&lt;/td&gt; 
   &lt;td&gt;Sampling techniques in MCP&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/05-AdvancedTopics/mcp-sampling/README.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;5.7&lt;/td&gt; 
   &lt;td&gt;Scaling&lt;/td&gt; 
   &lt;td&gt;Scale MCP implementations&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/05-AdvancedTopics/mcp-scaling/README.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;5.8&lt;/td&gt; 
   &lt;td&gt;Security&lt;/td&gt; 
   &lt;td&gt;Advanced security considerations&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/05-AdvancedTopics/mcp-security/README.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;5.9&lt;/td&gt; 
   &lt;td&gt;Web Search&lt;/td&gt; 
   &lt;td&gt;Implement web search capabilities&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/05-AdvancedTopics/web-search-mcp/README.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;5.10&lt;/td&gt; 
   &lt;td&gt;Realtime Streaming&lt;/td&gt; 
   &lt;td&gt;Build realtime streaming functionality&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/05-AdvancedTopics/mcp-realtimestreaming/README.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;5.11&lt;/td&gt; 
   &lt;td&gt;Realtime Search&lt;/td&gt; 
   &lt;td&gt;Implement realtime search&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/05-AdvancedTopics/mcp-realtimesearch/README.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;5.12&lt;/td&gt; 
   &lt;td&gt;Entra ID Auth&lt;/td&gt; 
   &lt;td&gt;Authentication with Microsoft Entra ID&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/05-AdvancedTopics/mcp-security-entra/README.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;5.13&lt;/td&gt; 
   &lt;td&gt;Foundry Integration&lt;/td&gt; 
   &lt;td&gt;Integrate with Azure AI Foundry&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/05-AdvancedTopics/mcp-foundry-agent-integration/README.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;5.14&lt;/td&gt; 
   &lt;td&gt;Context Engineering&lt;/td&gt; 
   &lt;td&gt;Techniques for effective context engineering&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/05-AdvancedTopics/mcp-contextengineering/README.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Module 6-10: Community &amp;amp; Best Practices&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;06&lt;/td&gt; 
   &lt;td&gt;Community Contributions&lt;/td&gt; 
   &lt;td&gt;How to contribute to the MCP ecosystem&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/06-CommunityContributions/README.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;07&lt;/td&gt; 
   &lt;td&gt;Insights from Early Adoption&lt;/td&gt; 
   &lt;td&gt;Real-world implementation stories&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/07-LessonsFromEarlyAdoption/README.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;08&lt;/td&gt; 
   &lt;td&gt;Best Practices for MCP&lt;/td&gt; 
   &lt;td&gt;Performance, fault-tolerance, resilience&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/08-BestPractices/README.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;09&lt;/td&gt; 
   &lt;td&gt;MCP Case Studies&lt;/td&gt; 
   &lt;td&gt;Practical implementation examples&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/09-CaseStudy/README.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;10&lt;/td&gt; 
   &lt;td&gt;Hands-on Workshop&lt;/td&gt; 
   &lt;td&gt;Building an MCP Server with AI Toolkit&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/10-StreamliningAIWorkflowsBuildingAnMCPServerWithAIToolkit/README.md"&gt;Lab&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;💻 Sample Code Projects&lt;/h3&gt; 
&lt;h4&gt;Basic MCP Calculator Samples&lt;/h4&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Language&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Link&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;C#&lt;/td&gt; 
   &lt;td&gt;MCP Server Example&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/03-GettingStarted/samples/csharp/README.md"&gt;View Code&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Java&lt;/td&gt; 
   &lt;td&gt;MCP Calculator&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/03-GettingStarted/samples/java/calculator/README.md"&gt;View Code&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;JavaScript&lt;/td&gt; 
   &lt;td&gt;MCP Demo&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/03-GettingStarted/samples/javascript/README.md"&gt;View Code&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Python&lt;/td&gt; 
   &lt;td&gt;MCP Server&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/03-GettingStarted/samples/python/mcp_calculator_server.py"&gt;View Code&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;TypeScript&lt;/td&gt; 
   &lt;td&gt;MCP Example&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/03-GettingStarted/samples/typescript/README.md"&gt;View Code&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h4&gt;Advanced MCP Implementations&lt;/h4&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Language&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Link&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;C#&lt;/td&gt; 
   &lt;td&gt;Advanced Sample&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/04-PracticalImplementation/samples/csharp/README.md"&gt;View Code&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Java&lt;/td&gt; 
   &lt;td&gt;Container App Example&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/04-PracticalImplementation/samples/java/containerapp/README.md"&gt;View Code&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;JavaScript&lt;/td&gt; 
   &lt;td&gt;Advanced Sample&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/04-PracticalImplementation/samples/javascript/README.md"&gt;View Code&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Python&lt;/td&gt; 
   &lt;td&gt;Complex Implementation&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/04-PracticalImplementation/samples/python/mcp_sample.py"&gt;View Code&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;TypeScript&lt;/td&gt; 
   &lt;td&gt;Container Sample&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/04-PracticalImplementation/samples/typescript/README.md"&gt;View Code&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;🎯 Prerequisites for Learning MCP&lt;/h2&gt; 
&lt;p&gt;To get the most out of this curriculum, you should have:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Basic knowledge of programming in at least one of the following languages: C#, Java, JavaScript, Python, or TypeScript&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Understanding of client-server model and APIs&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Familiarity with REST and HTTP concepts&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;(Optional) Background in AI/ML concepts&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Joining our community discussions for support&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;📚 Study Guide &amp;amp; Resources&lt;/h2&gt; 
&lt;p&gt;This repository includes several resources to help you navigate and learn effectively:&lt;/p&gt; 
&lt;h3&gt;Study Guide&lt;/h3&gt; 
&lt;p&gt;A comprehensive &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/study_guide.md"&gt;Study Guide&lt;/a&gt; is available to help you navigate this repository effectively. The guide includes:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;A visual curriculum map showing all topics covered&lt;/li&gt; 
 &lt;li&gt;Detailed breakdown of each repository section&lt;/li&gt; 
 &lt;li&gt;Guidance on how to use sample projects&lt;/li&gt; 
 &lt;li&gt;Recommended learning paths for different skill levels&lt;/li&gt; 
 &lt;li&gt;Additional resources to complement your learning journey&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Changelog&lt;/h3&gt; 
&lt;p&gt;We maintain a detailed &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/changelog.md"&gt;Changelog&lt;/a&gt; that tracks all significant updates to the curriculum materials, including:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;New content additions&lt;/li&gt; 
 &lt;li&gt;Structural changes&lt;/li&gt; 
 &lt;li&gt;Feature improvements&lt;/li&gt; 
 &lt;li&gt;Documentation updates&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;🛠️ How to Use This Curriculum Effectively&lt;/h2&gt; 
&lt;p&gt;Each lesson in this guide includes:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Clear explanations of MCP concepts&lt;/li&gt; 
 &lt;li&gt;Live code examples in multiple languages&lt;/li&gt; 
 &lt;li&gt;Exercises to build real MCP applications&lt;/li&gt; 
 &lt;li&gt;Extra resources for advanced learners&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;🌟 Community Thanks&lt;/h2&gt; 
&lt;p&gt;Thanks to Microsoft Valued Professional &lt;a href="https://www.linkedin.com/in/shivam2003/"&gt;Shivam Goyal&lt;/a&gt; for contributing important code samples.&lt;/p&gt; 
&lt;h2&gt;📜 License Information&lt;/h2&gt; 
&lt;p&gt;This content is licensed under the &lt;strong&gt;MIT License&lt;/strong&gt;. For terms and conditions, see the &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/LICENSE"&gt;LICENSE&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;🤝 Contribution Guidelines&lt;/h2&gt; 
&lt;p&gt;This project welcomes contributions and suggestions. Most contributions require you to agree to a Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us the rights to use your contribution. For details, visit &lt;a href="https://cla.opensource.microsoft.com"&gt;https://cla.opensource.microsoft.com&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;When you submit a pull request, a CLA bot will automatically determine whether you need to provide a CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions provided by the bot. You will only need to do this once across all repos using our CLA.&lt;/p&gt; 
&lt;p&gt;This project has adopted the &lt;a href="https://opensource.microsoft.com/codeofconduct/"&gt;Microsoft Open Source Code of Conduct&lt;/a&gt;. For more information see the &lt;a href="https://opensource.microsoft.com/codeofconduct/faq/"&gt;Code of Conduct FAQ&lt;/a&gt; or contact &lt;a href="mailto:opencode@microsoft.com"&gt;opencode@microsoft.com&lt;/a&gt; with any additional questions or comments.&lt;/p&gt; 
&lt;h2&gt;📂 Repository Structure&lt;/h2&gt; 
&lt;p&gt;The repository is organized as follows:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Core Curriculum (00-10)&lt;/strong&gt;: The main content organized in ten sequential modules&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;images/&lt;/strong&gt;: Diagrams and illustrations used throughout the curriculum&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;translations/&lt;/strong&gt;: Multi-language support with automated translations&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;translated_images/&lt;/strong&gt;: Localized versions of diagrams and illustrations&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;study_guide.md&lt;/strong&gt;: Comprehensive guide to navigating the repository&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;changelog.md&lt;/strong&gt;: Record of all significant changes to the curriculum materials&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;mcp.json&lt;/strong&gt;: Configuration file for MCP specification&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;CODE_OF_CONDUCT.md, LICENSE, SECURITY.md, SUPPORT.md&lt;/strong&gt;: Project governance documents&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;🎒 Other Courses&lt;/h2&gt; 
&lt;p&gt;Our team produces other courses! Check out:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/microsoft/ai-agents-for-beginners?WT.mc_id=academic-105485-koreyst"&gt;AI Agents For Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/microsoft/Generative-AI-for-beginners-dotnet?WT.mc_id=academic-105485-koreyst"&gt;Generative AI for Beginners using .NET&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/microsoft/generative-ai-with-javascript?WT.mc_id=academic-105485-koreyst"&gt;Generative AI for Beginners using JavaScript&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/microsoft/generative-ai-for-beginners?WT.mc_id=academic-105485-koreyst"&gt;Generative AI for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://aka.ms/ml-beginners?WT.mc_id=academic-105485-koreyst"&gt;ML for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://aka.ms/datascience-beginners?WT.mc_id=academic-105485-koreyst"&gt;Data Science for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://aka.ms/ai-beginners?WT.mc_id=academic-105485-koreyst"&gt;AI for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/microsoft/Security-101??WT.mc_id=academic-96948-sayoung"&gt;Cybersecurity for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://aka.ms/webdev-beginners?WT.mc_id=academic-105485-koreyst"&gt;Web Dev for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://aka.ms/iot-beginners?WT.mc_id=academic-105485-koreyst"&gt;IoT for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/microsoft/xr-development-for-beginners?WT.mc_id=academic-105485-koreyst"&gt;XR Development for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://aka.ms/GitHubCopilotAI?WT.mc_id=academic-105485-koreyst"&gt;Mastering GitHub Copilot for AI Paired Programming&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/microsoft/mastering-github-copilot-for-dotnet-csharp-developers?WT.mc_id=academic-105485-koreyst"&gt;Mastering GitHub Copilot for C#/.NET Developers&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/microsoft/CopilotAdventures?WT.mc_id=academic-105485-koreyst"&gt;Choose Your Own Copilot Adventure&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;™️ Trademark Notice&lt;/h2&gt; 
&lt;p&gt;This project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft trademarks or logos is subject to and must follow &lt;a href="https://www.microsoft.com/legal/intellectualproperty/trademarks/usage/general"&gt;Microsoft's Trademark &amp;amp; Brand Guidelines&lt;/a&gt;. Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship. Any use of third-party trademarks or logos is subject to those third-parties' policies.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>plotly/dash</title>
      <link>https://github.com/plotly/dash</link>
      <description>&lt;p&gt;Data Apps &amp; Dashboards for Python. No JavaScript Required.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Dash&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://circleci.com/gh/plotly/dash"&gt;&lt;img src="https://img.shields.io/circleci/project/github/plotly/dash/master.svg?sanitize=true" alt="CircleCI"&gt;&lt;/a&gt; &lt;a href="https://github.com/plotly/dash/raw/master/LICENSE"&gt;&lt;img src="https://img.shields.io/github/license/plotly/dash.svg?color=dark-green" alt="GitHub"&gt;&lt;/a&gt; &lt;a href="https://pypi.org/project/dash/"&gt;&lt;img src="https://img.shields.io/pypi/v/dash.svg?color=dark-green" alt="PyPI"&gt;&lt;/a&gt; &lt;a href="https://pypi.org/project/dash/"&gt;&lt;img src="https://img.shields.io/pypi/pyversions/dash.svg?color=dark-green" alt="PyPI - Python Version"&gt;&lt;/a&gt; &lt;a href="https://github.com/plotly/dash/graphs/contributors"&gt;&lt;img src="https://img.shields.io/github/commit-activity/y/plotly/dash.svg?color=dark-green" alt="GitHub commit activity"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h4&gt;&lt;em&gt;Dash is the most downloaded, trusted Python framework for building ML &amp;amp; data science web apps&lt;/em&gt;.&lt;/h4&gt; 
&lt;p&gt;Built on top of &lt;a href="https://github.com/plotly/plotly.js"&gt;Plotly.js&lt;/a&gt;, &lt;a href="https://reactjs.org/"&gt;React&lt;/a&gt; and &lt;a href="https://palletsprojects.com/p/flask/"&gt;Flask&lt;/a&gt;, Dash ties modern UI elements like dropdowns, sliders, and graphs directly to your analytical Python code. Read &lt;a href="https://dash.plotly.com/getting-started"&gt;our tutorial&lt;/a&gt; (proudly crafted ❤️ with Dash itself).&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://dash.plotly.com/getting-started"&gt;Docs&lt;/a&gt;: Create your first Dash app in under 5 minutes&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://dash.gallery"&gt;dash.gallery&lt;/a&gt;: Dash app gallery with Python &amp;amp; R code&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://dash.plotly.com/project-maintenance"&gt; &lt;img src="https://dash.plotly.com/assets/images/maintained-by-plotly.png" width="400px" alt="Maintained by Plotly"&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;h3&gt;Dash App Examples&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Dash App&lt;/th&gt; 
   &lt;th align="center"&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src="https://user-images.githubusercontent.com/1280389/30086128-9bb4a28e-9267-11e7-8fe4-bbac7d53f2b0.gif" alt="Sample Dash App"&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;Here’s a simple example of a Dash App that ties a Dropdown to a Plotly Graph. As the user selects a value in the Dropdown, the application code dynamically exports data from Google Finance into a Pandas DataFrame. This app was written in just &lt;strong&gt;43&lt;/strong&gt; lines of code (&lt;a href="https://gist.github.com/chriddyp/3d2454905d8f01886d651f207e2419f0"&gt;view the source&lt;/a&gt;).&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src="https://user-images.githubusercontent.com/1280389/30086123-97c58bde-9267-11e7-98a0-7f626de5199a.gif" alt="Crossfiltering Dash App"&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;Dash app code is declarative and reactive, which makes it easy to build complex apps that contain many interactive elements. Here’s an example with 5 inputs, 3 outputs, and cross filtering. This app was composed in just 160 lines of code, all of which were Python.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src="https://user-images.githubusercontent.com/1280389/30086299-768509d0-9268-11e7-8e6b-626ac9ca512c.gif" alt="Dash App with Mapbox map showing walmart store openings"&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;Dash uses &lt;a href="https://github.com/plotly/plotly.js"&gt;Plotly.js&lt;/a&gt; for charting. About 50 chart types are supported, including maps.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src="https://user-images.githubusercontent.com/2678795/161153710-57952401-6e07-42d5-ba3e-bab6419998c7.gif" alt="Financial report"&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;Dash isn't just for dashboards. You have full control over the look and feel of your applications. Here's a Dash App that's styled to look like a PDF report.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;To learn more about Dash, read the &lt;a href="https://medium.com/@plotlygraphs/introducing-dash-5ecf7191b503"&gt;extensive announcement letter&lt;/a&gt; or &lt;a href="https://plotly.com/dash"&gt;jump in with the user guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Dash OSS &amp;amp; Dash Enterprise&lt;/h3&gt; 
&lt;p&gt;With Dash Open Source, Dash apps run on your local laptop or workstation, but cannot be easily accessed by others in your organization.&lt;/p&gt; 
&lt;p&gt;Scale up with Dash Enterprise when your Dash app is ready for department or company-wide consumption. Or, launch your initiative with Dash Enterprise from the start to unlock developer productivity gains and hands-on acceleration from Plotly's team.&lt;/p&gt; 
&lt;p&gt;ML Ops Features: A one-stop shop for ML Ops: Horizontally scalable hosting, deployment, and authentication for your Dash apps. No IT or DevOps required.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://plotly.com/dash/app-manager/"&gt;&lt;strong&gt;App manager&lt;/strong&gt;&lt;/a&gt; Deploy &amp;amp; manage Dash apps without needing IT or a DevOps team. App Manager gives you point &amp;amp; click control over all aspects of your Dash deployments.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://plotly.com/dash/kubernetes/"&gt;&lt;strong&gt;Kubernetes scaling&lt;/strong&gt;&lt;/a&gt; Ensure high availability of Dash apps and scale horizontally with Dash Enterprise’s Kubernetes architecture. No IT or Helm required.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://plotly.com/dash/authentication/"&gt;&lt;strong&gt;No code auth&lt;/strong&gt;&lt;/a&gt; Control Dash app access in a few clicks. Dash Enterprise supports LDAP, AD, PKI, Okta, SAML, OpenID Connect, OAuth, SSO, and simple email authentication.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://plotly.com/dash/job-queue/"&gt;&lt;strong&gt;Job Queue&lt;/strong&gt;&lt;/a&gt; The Job Queue is the key to building scalable Dash apps. Move heavy computation from synchronous Dash callbacks to the Job Queue for asynchronous background processing.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Low-Code Features: Low-code Dash app capabilities that supercharge developer productivity.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://plotly.com/dash/design-kit/"&gt;&lt;strong&gt;Design Kit&lt;/strong&gt;&lt;/a&gt; Design like a pro without writing a line of CSS. Easily arrange, style, brand, and customize your Dash apps.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://plotly.com/dash/snapshot-engine/"&gt;&lt;strong&gt;Snapshot Engine&lt;/strong&gt;&lt;/a&gt; Save &amp;amp; share Dash app views as links or PDFs. Or, run a Python job through Dash and have Snapshot Engine email a report when the job is done.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://plotly.com/dash/toolkit/"&gt;&lt;strong&gt;Dashboard Toolkit&lt;/strong&gt;&lt;/a&gt; Drag &amp;amp; drop layouts, chart editing, and crossfilter for your Dash apps.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://plotly.com/dash/embedding/"&gt;&lt;strong&gt;Embedding&lt;/strong&gt;&lt;/a&gt; Natively embed Dash apps in an existing web application or website without the use of IFrames.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Enterprise AI Features: Everything that your data science team needs to rapidly deliver AI/ML research and business initiatives.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://plotly.com/dash/ai-and-ml-templates/"&gt;&lt;strong&gt;AI App Marketplace&lt;/strong&gt;&lt;/a&gt; Dash Enterprise ships with dozens of Dash app templates for business problems where AI/ML is having the greatest impact.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://plotly.com/dash/big-data-for-python/"&gt;&lt;strong&gt;Big Data for Pything&lt;/strong&gt;&lt;/a&gt; Connect to Python's most popular big data back ends: Dask, Databricks, NVIDIA RAPIDS, Snowflake, Postgres, Vaex, and more.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://plotly.com/dash/gpu-dask-acceleration/"&gt;&lt;strong&gt;GPU &amp;amp; Dask Acceleration&lt;/strong&gt;&lt;/a&gt; Dash Enterprise puts Python’s most popular HPC stack for GPU and parallel CPU computing in the hands of business users.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://plotly.com/dash/workspaces/"&gt;&lt;strong&gt;Data Science Workspaces&lt;/strong&gt;&lt;/a&gt; Be productive from Day 1. Write and execute Python, R, &amp;amp; Julia code from Dash Enterprise's onboard code editor.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;See &lt;a href="https://plotly.com/contact-us/"&gt;https://plotly.com/contact-us/&lt;/a&gt; to get in touch.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://user-images.githubusercontent.com/2678795/161155614-21c54a22-f821-4dda-b910-ee27e27fb5f2.png" alt="Dash Enterprise"&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>roboflow/supervision</title>
      <link>https://github.com/roboflow/supervision</link>
      <description>&lt;p&gt;We write your reusable computer vision tools. 💜&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;p&gt; &lt;a align="center" href="" target="https://supervision.roboflow.com"&gt; &lt;img width="100%" src="https://media.roboflow.com/open-source/supervision/rf-supervision-banner.png?updatedAt=1678995927529"&gt; &lt;/a&gt; &lt;/p&gt; 
 &lt;br&gt; 
 &lt;p&gt;&lt;a href="https://github.com/roboflow/notebooks"&gt;notebooks&lt;/a&gt; | &lt;a href="https://github.com/roboflow/inference"&gt;inference&lt;/a&gt; | &lt;a href="https://github.com/autodistill/autodistill"&gt;autodistill&lt;/a&gt; | &lt;a href="https://github.com/roboflow/multimodal-maestro"&gt;maestro&lt;/a&gt;&lt;/p&gt; 
 &lt;br&gt; 
 &lt;p&gt;&lt;a href="https://badge.fury.io/py/supervision"&gt;&lt;img src="https://badge.fury.io/py/supervision.svg?sanitize=true" alt="version"&gt;&lt;/a&gt; &lt;a href="https://pypistats.org/packages/supervision"&gt;&lt;img src="https://img.shields.io/pypi/dm/supervision" alt="downloads"&gt;&lt;/a&gt; &lt;a href="https://snyk.io/advisor/python/supervision"&gt;&lt;img src="https://snyk.io/advisor/python/supervision/badge.svg?sanitize=true" alt="snyk"&gt;&lt;/a&gt; &lt;a href="https://github.com/roboflow/supervision/raw/main/LICENSE.md"&gt;&lt;img src="https://img.shields.io/pypi/l/supervision" alt="license"&gt;&lt;/a&gt; &lt;a href="https://badge.fury.io/py/supervision"&gt;&lt;img src="https://img.shields.io/pypi/pyversions/supervision" alt="python-version"&gt;&lt;/a&gt; &lt;a href="https://colab.research.google.com/github/roboflow/supervision/blob/main/demo.ipynb"&gt;&lt;img src="https://colab.research.google.com/assets/colab-badge.svg?sanitize=true" alt="colab"&gt;&lt;/a&gt; &lt;a href="https://huggingface.co/spaces/Roboflow/Annotators"&gt;&lt;img src="https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Spaces-blue" alt="gradio"&gt;&lt;/a&gt; &lt;a href="https://discord.gg/GbfgXGJ8Bk"&gt;&lt;img src="https://img.shields.io/discord/1159501506232451173?logo=discord&amp;amp;label=discord&amp;amp;labelColor=fff&amp;amp;color=5865f2&amp;amp;link=https%3A%2F%2Fdiscord.gg%2FGbfgXGJ8Bk" alt="discord"&gt;&lt;/a&gt; &lt;a href="https://squidfunk.github.io/mkdocs-material/"&gt;&lt;img src="https://img.shields.io/badge/Material_for_MkDocs-526CFE?logo=MaterialForMkDocs&amp;amp;logoColor=white" alt="built-with-material-for-mkdocs"&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;div align="center"&gt; 
  &lt;a href="https://trendshift.io/repositories/124" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/124" alt="roboflow%2Fsupervision | Trendshift" style="width: 250px; height: 55px;" width="250" height="55"&gt;&lt;/a&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;h2&gt;👋 hello&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;We write your reusable computer vision tools.&lt;/strong&gt; Whether you need to load your dataset from your hard drive, draw detections on an image or video, or count how many detections are in a zone. You can count on us! 🤝&lt;/p&gt; 
&lt;h2&gt;💻 install&lt;/h2&gt; 
&lt;p&gt;Pip install the supervision package in a &lt;a href="https://www.python.org/"&gt;&lt;strong&gt;Python&amp;gt;=3.9&lt;/strong&gt;&lt;/a&gt; environment.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install supervision
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Read more about conda, mamba, and installing from source in our &lt;a href="https://roboflow.github.io/supervision/"&gt;guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;🔥 quickstart&lt;/h2&gt; 
&lt;h3&gt;models&lt;/h3&gt; 
&lt;p&gt;Supervision was designed to be model agnostic. Just plug in any classification, detection, or segmentation model. For your convenience, we have created &lt;a href="https://supervision.roboflow.com/latest/detection/core/#detections"&gt;connectors&lt;/a&gt; for the most popular libraries like Ultralytics, Transformers, or MMDetection.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import cv2
import supervision as sv
from ultralytics import YOLO

image = cv2.imread(...)
model = YOLO("yolov8s.pt")
result = model(image)[0]
detections = sv.Detections.from_ultralytics(result)

len(detections)
# 5
&lt;/code&gt;&lt;/pre&gt; 
&lt;details&gt; 
 &lt;summary&gt;👉 more model connectors&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;inference&lt;/p&gt; &lt;p&gt;Running with &lt;a href="https://github.com/roboflow/inference"&gt;Inference&lt;/a&gt; requires a &lt;a href="https://docs.roboflow.com/api-reference/authentication#retrieve-an-api-key"&gt;Roboflow API KEY&lt;/a&gt;.&lt;/p&gt; &lt;pre&gt;&lt;code class="language-python"&gt;import cv2
import supervision as sv
from inference import get_model

image = cv2.imread(...)
model = get_model(model_id="yolov8s-640", api_key=&amp;lt;ROBOFLOW API KEY&amp;gt;)
result = model.infer(image)[0]
detections = sv.Detections.from_inference(result)

len(detections)
# 5
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h3&gt;annotators&lt;/h3&gt; 
&lt;p&gt;Supervision offers a wide range of highly customizable &lt;a href="https://supervision.roboflow.com/latest/detection/annotators/"&gt;annotators&lt;/a&gt;, allowing you to compose the perfect visualization for your use case.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import cv2
import supervision as sv

image = cv2.imread(...)
detections = sv.Detections(...)

box_annotator = sv.BoxAnnotator()
annotated_frame = box_annotator.annotate(
  scene=image.copy(),
  detections=detections)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;a href="https://github.com/roboflow/supervision/assets/26109316/691e219c-0565-4403-9218-ab5644f39bce"&gt;https://github.com/roboflow/supervision/assets/26109316/691e219c-0565-4403-9218-ab5644f39bce&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;datasets&lt;/h3&gt; 
&lt;p&gt;Supervision provides a set of &lt;a href="https://supervision.roboflow.com/latest/datasets/core/"&gt;utils&lt;/a&gt; that allow you to load, split, merge, and save datasets in one of the supported formats.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import supervision as sv
from roboflow import Roboflow

project = Roboflow().workspace(&amp;lt;WORKSPACE_ID&amp;gt;).project(&amp;lt;PROJECT_ID&amp;gt;)
dataset = project.version(&amp;lt;PROJECT_VERSION&amp;gt;).download("coco")

ds = sv.DetectionDataset.from_coco(
    images_directory_path=f"{dataset.location}/train",
    annotations_path=f"{dataset.location}/train/_annotations.coco.json",
)

path, image, annotation = ds[0]
    # loads image on demand

for path, image, annotation in ds:
    # loads image on demand
&lt;/code&gt;&lt;/pre&gt; 
&lt;details close&gt; 
 &lt;summary&gt;👉 more dataset utils&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;load&lt;/p&gt; &lt;pre&gt;&lt;code class="language-python"&gt;dataset = sv.DetectionDataset.from_yolo(
    images_directory_path=...,
    annotations_directory_path=...,
    data_yaml_path=...
)

dataset = sv.DetectionDataset.from_pascal_voc(
    images_directory_path=...,
    annotations_directory_path=...
)

dataset = sv.DetectionDataset.from_coco(
    images_directory_path=...,
    annotations_path=...
)
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;split&lt;/p&gt; &lt;pre&gt;&lt;code class="language-python"&gt;train_dataset, test_dataset = dataset.split(split_ratio=0.7)
test_dataset, valid_dataset = test_dataset.split(split_ratio=0.5)

len(train_dataset), len(test_dataset), len(valid_dataset)
# (700, 150, 150)
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;merge&lt;/p&gt; &lt;pre&gt;&lt;code class="language-python"&gt;ds_1 = sv.DetectionDataset(...)
len(ds_1)
# 100
ds_1.classes
# ['dog', 'person']

ds_2 = sv.DetectionDataset(...)
len(ds_2)
# 200
ds_2.classes
# ['cat']

ds_merged = sv.DetectionDataset.merge([ds_1, ds_2])
len(ds_merged)
# 300
ds_merged.classes
# ['cat', 'dog', 'person']
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;save&lt;/p&gt; &lt;pre&gt;&lt;code class="language-python"&gt;dataset.as_yolo(
    images_directory_path=...,
    annotations_directory_path=...,
    data_yaml_path=...
)

dataset.as_pascal_voc(
    images_directory_path=...,
    annotations_directory_path=...
)

dataset.as_coco(
    images_directory_path=...,
    annotations_path=...
)
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;convert&lt;/p&gt; &lt;pre&gt;&lt;code class="language-python"&gt;sv.DetectionDataset.from_yolo(
    images_directory_path=...,
    annotations_directory_path=...,
    data_yaml_path=...
).as_pascal_voc(
    images_directory_path=...,
    annotations_directory_path=...
)
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;🎬 tutorials&lt;/h2&gt; 
&lt;p&gt;Want to learn how to use Supervision? Explore our &lt;a href="https://supervision.roboflow.com/develop/how_to/detect_and_annotate/"&gt;how-to guides&lt;/a&gt;, &lt;a href="https://github.com/roboflow/supervision/tree/develop/examples"&gt;end-to-end examples&lt;/a&gt;, &lt;a href="https://roboflow.github.io/cheatsheet-supervision/"&gt;cheatsheet&lt;/a&gt;, and &lt;a href="https://supervision.roboflow.com/develop/cookbooks/"&gt;cookbooks&lt;/a&gt;!&lt;/p&gt; 
&lt;br&gt; 
&lt;p align="left"&gt; &lt;a href="https://youtu.be/hAWpsIuem10" title="Dwell Time Analysis with Computer Vision | Real-Time Stream Processing"&gt;&lt;img src="https://github.com/SkalskiP/SkalskiP/assets/26109316/a742823d-c158-407d-b30f-063a5d11b4e1" alt="Dwell Time Analysis with Computer Vision | Real-Time Stream Processing" width="300px" align="left"&gt;&lt;/a&gt; &lt;a href="https://youtu.be/hAWpsIuem10" title="Dwell Time Analysis with Computer Vision | Real-Time Stream Processing"&gt;&lt;strong&gt;Dwell Time Analysis with Computer Vision | Real-Time Stream Processing&lt;/strong&gt;&lt;/a&gt; &lt;/p&gt;
&lt;div&gt;
 &lt;strong&gt;Created: 5 Apr 2024&lt;/strong&gt;
&lt;/div&gt; 
&lt;br&gt;Learn how to use computer vision to analyze wait times and optimize processes. This tutorial covers object detection, tracking, and calculating time spent in designated zones. Use these techniques to improve customer experience in retail, traffic management, or other scenarios.
&lt;p&gt;&lt;/p&gt; 
&lt;br&gt; 
&lt;p align="left"&gt; &lt;a href="https://youtu.be/uWP6UjDeZvY" title="Speed Estimation &amp;amp; Vehicle Tracking | Computer Vision | Open Source"&gt;&lt;img src="https://github.com/SkalskiP/SkalskiP/assets/26109316/61a444c8-b135-48ce-b979-2a5ab47c5a91" alt="Speed Estimation &amp;amp; Vehicle Tracking | Computer Vision | Open Source" width="300px" align="left"&gt;&lt;/a&gt; &lt;a href="https://youtu.be/uWP6UjDeZvY" title="Speed Estimation &amp;amp; Vehicle Tracking | Computer Vision | Open Source"&gt;&lt;strong&gt;Speed Estimation &amp;amp; Vehicle Tracking | Computer Vision | Open Source&lt;/strong&gt;&lt;/a&gt; &lt;/p&gt;
&lt;div&gt;
 &lt;strong&gt;Created: 11 Jan 2024&lt;/strong&gt;
&lt;/div&gt; 
&lt;br&gt;Learn how to track and estimate the speed of vehicles using YOLO, ByteTrack, and Roboflow Inference. This comprehensive tutorial covers object detection, multi-object tracking, filtering detections, perspective transformation, speed estimation, visualization improvements, and more.
&lt;p&gt;&lt;/p&gt; 
&lt;h2&gt;💜 built with supervision&lt;/h2&gt; 
&lt;p&gt;Did you build something cool using supervision? &lt;a href="https://github.com/roboflow/supervision/discussions/categories/built-with-supervision"&gt;Let us know!&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://user-images.githubusercontent.com/26109316/207858600-ee862b22-0353-440b-ad85-caa0c4777904.mp4"&gt;https://user-images.githubusercontent.com/26109316/207858600-ee862b22-0353-440b-ad85-caa0c4777904.mp4&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/roboflow/supervision/assets/26109316/c9436828-9fbf-4c25-ae8c-60e9c81b3900"&gt;https://github.com/roboflow/supervision/assets/26109316/c9436828-9fbf-4c25-ae8c-60e9c81b3900&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/roboflow/supervision/assets/26109316/3ac6982f-4943-4108-9b7f-51787ef1a69f"&gt;https://github.com/roboflow/supervision/assets/26109316/3ac6982f-4943-4108-9b7f-51787ef1a69f&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;📚 documentation&lt;/h2&gt; 
&lt;p&gt;Visit our &lt;a href="https://roboflow.github.io/supervision"&gt;documentation&lt;/a&gt; page to learn how supervision can help you build computer vision applications faster and more reliably.&lt;/p&gt; 
&lt;h2&gt;🏆 contribution&lt;/h2&gt; 
&lt;p&gt;We love your input! Please see our &lt;a href="https://github.com/roboflow/supervision/raw/main/CONTRIBUTING.md"&gt;contributing guide&lt;/a&gt; to get started. Thank you 🙏 to all our contributors!&lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/roboflow/supervision/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=roboflow/supervision"&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;br&gt; 
&lt;div align="center"&gt; 
 &lt;div align="center"&gt; 
  &lt;a href="https://youtube.com/roboflow"&gt; &lt;img src="https://media.roboflow.com/notebooks/template/icons/purple/youtube.png?ik-sdk-version=javascript-1.4.3&amp;amp;updatedAt=1672949634652" width="3%"&gt; &lt;/a&gt; 
  &lt;img src="https://raw.githubusercontent.com/ultralytics/assets/main/social/logo-transparent.png" width="3%"&gt; 
  &lt;a href="https://roboflow.com"&gt; &lt;img src="https://media.roboflow.com/notebooks/template/icons/purple/roboflow-app.png?ik-sdk-version=javascript-1.4.3&amp;amp;updatedAt=1672949746649" width="3%"&gt; &lt;/a&gt; 
  &lt;img src="https://raw.githubusercontent.com/ultralytics/assets/main/social/logo-transparent.png" width="3%"&gt; 
  &lt;a href="https://www.linkedin.com/company/roboflow-ai/"&gt; &lt;img src="https://media.roboflow.com/notebooks/template/icons/purple/linkedin.png?ik-sdk-version=javascript-1.4.3&amp;amp;updatedAt=1672949633691" width="3%"&gt; &lt;/a&gt; 
  &lt;img src="https://raw.githubusercontent.com/ultralytics/assets/main/social/logo-transparent.png" width="3%"&gt; 
  &lt;a href="https://docs.roboflow.com"&gt; &lt;img src="https://media.roboflow.com/notebooks/template/icons/purple/knowledge.png?ik-sdk-version=javascript-1.4.3&amp;amp;updatedAt=1672949634511" width="3%"&gt; &lt;/a&gt; 
  &lt;img src="https://raw.githubusercontent.com/ultralytics/assets/main/social/logo-transparent.png" width="3%"&gt; 
  &lt;a href="https://discuss.roboflow.com"&gt; &lt;img src="https://media.roboflow.com/notebooks/template/icons/purple/forum.png?ik-sdk-version=javascript-1.4.3&amp;amp;updatedAt=1672949633584" width="3%"&gt; &lt;img src="https://raw.githubusercontent.com/ultralytics/assets/main/social/logo-transparent.png" width="3%"&gt; &lt;/a&gt;
  &lt;a href="https://blog.roboflow.com"&gt; &lt;img src="https://media.roboflow.com/notebooks/template/icons/purple/blog.png?ik-sdk-version=javascript-1.4.3&amp;amp;updatedAt=1672949633605" width="3%"&gt; &lt;/a&gt;  
 &lt;/div&gt; 
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>nikmcfly/ANUS</title>
      <link>https://github.com/nikmcfly/ANUS</link>
      <description>&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;🍑 Anus: Autonomous Networked Utility System&lt;/h1&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/nikmcfly/ANUS/main/assets/anus_logo.png" alt="Anus AI Logo" width="200"&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/nikmcfly/ANUS/raw/main/LICENSE"&gt;&lt;img src="https://img.shields.io/badge/License-MIT-blue.svg?sanitize=true" alt="License: MIT"&gt;&lt;/a&gt; &lt;a href="https://www.python.org/downloads/"&gt;&lt;img src="https://img.shields.io/badge/python-3.11+-blue.svg?sanitize=true" alt="Python version"&gt;&lt;/a&gt; &lt;a href="https://github.com/psf/black"&gt;&lt;img src="https://img.shields.io/badge/code%20style-black-000000.svg?sanitize=true" alt="Code style: black"&gt;&lt;/a&gt; &lt;a href="https://github.com/nikmcfly/ANUS/raw/main/CONTRIBUTING.md"&gt;&lt;img src="https://img.shields.io/badge/contributions-welcome-brightgreen.svg?sanitize=true" alt="Contributions welcome"&gt;&lt;/a&gt; &lt;br&gt; &lt;a href="https://github.com/nikmcfly/ANUS/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/nikmcfly/ANUS.svg?style=social&amp;amp;label=Star" alt="GitHub stars"&gt;&lt;/a&gt; &lt;a href="https://github.com/nikmcfly/ANUS/network/members"&gt;&lt;img src="https://img.shields.io/github/forks/nikmcfly/ANUS.svg?style=social&amp;amp;label=Fork" alt="GitHub forks"&gt;&lt;/a&gt; &lt;a href="https://github.com/nikmcfly/ANUS/issues"&gt;&lt;img src="https://img.shields.io/github/issues/nikmcfly/ANUS.svg?sanitize=true" alt="GitHub issues"&gt;&lt;/a&gt; &lt;a href="https://makeapullrequest.com"&gt;&lt;img src="https://img.shields.io/badge/PRs-welcome-brightgreen.svg?sanitize=true" alt="PRs Welcome"&gt;&lt;/a&gt; &lt;a href="https://anus-ai.github.io/docs"&gt;&lt;img src="https://img.shields.io/badge/docs-latest-brightgreen.svg?sanitize=true" alt="Documentation Status"&gt;&lt;/a&gt; &lt;a href="https://t.me/goanus"&gt;&lt;img src="https://img.shields.io/badge/Telegram-blue?logo=telegram&amp;amp;logoColor=white" alt="Telegram"&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;h2&gt;Table of Contents&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/nikmcfly/ANUS/main/#-introduction"&gt;Introduction&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/nikmcfly/ANUS/main/#-why-anus"&gt;Why Anus?&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/nikmcfly/ANUS/main/#-features--capabilities"&gt;Features &amp;amp; Capabilities&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/nikmcfly/ANUS/main/#-installation"&gt;Installation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/nikmcfly/ANUS/main/#-quick-start"&gt;Quick Start&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/nikmcfly/ANUS/main/#-usage-examples"&gt;Usage Examples&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/nikmcfly/ANUS/main/#-documentation"&gt;Documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/nikmcfly/ANUS/main/#-contributing"&gt;Contributing&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/nikmcfly/ANUS/main/#-community"&gt;Community&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/nikmcfly/ANUS/main/#-license"&gt;License&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;🌟 Introduction&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Anus&lt;/strong&gt; (Autonomous Networked Utility System) is a powerful, flexible, and accessible open-source AI agent framework designed to revolutionize task automation. Built with modern AI technologies and best practices, Anus represents the next generation of AI agent frameworks, offering unparalleled capabilities and ease of use.&lt;/p&gt; 
&lt;p&gt;Anus empowers users to create AI agents that can:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Execute complex tasks through natural language instructions&lt;/li&gt; 
 &lt;li&gt;Collaborate in multi-agent environments to solve problems&lt;/li&gt; 
 &lt;li&gt;Interact with web services, documents, and code&lt;/li&gt; 
 &lt;li&gt;Process multimodal inputs including text, images, and audio&lt;/li&gt; 
 &lt;li&gt;Adapt to different domains and use cases&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Whether you're a developer looking to build AI-powered applications, a researcher exploring agent-based systems, or an enthusiast interested in the latest AI technologies, Anus provides the tools and flexibility you need to succeed.&lt;/p&gt; 
&lt;h2&gt;💡 Why Anus?&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Truly Open Source&lt;/strong&gt;: No barriers, no invite codes, just pure open-source goodness&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Hybrid Architecture&lt;/strong&gt;: Combines single-agent simplicity with multi-agent power&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Flexible Model Support&lt;/strong&gt;: Works with OpenAI models, open-source models, or your own&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Comprehensive Tool Ecosystem&lt;/strong&gt;: Web automation, document processing, code execution, and more&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Community-First Design&lt;/strong&gt;: Built for contributions and extensions&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Transparent Operation&lt;/strong&gt;: Clear explanations of all agent actions and decisions&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Cross-Platform&lt;/strong&gt;: Works across different operating systems and environments&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;✨ Features &amp;amp; Capabilities&lt;/h2&gt; 
&lt;h3&gt;🧠 Advanced AI Agent Architecture&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Hybrid Agent System&lt;/strong&gt;: Seamlessly switch between single-agent and multi-agent modes based on task complexity&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Dynamic Task Planning&lt;/strong&gt;: Sophisticated planning system that breaks down complex tasks into manageable steps&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Adaptive Resource Allocation&lt;/strong&gt;: Intelligently allocates computational resources based on task requirements&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Memory Management&lt;/strong&gt;: Short-term and long-term memory systems for context retention across conversations&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Explainable Actions&lt;/strong&gt;: Transparent reasoning and decision-making processes&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;🤝 Multi-Agent Collaboration&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Specialized Agent Roles&lt;/strong&gt;: Pre-defined roles like Researcher, Coder, Planner, and more&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Custom Role Creation&lt;/strong&gt;: Define your own agent roles with specific capabilities and knowledge&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Inter-Agent Communication&lt;/strong&gt;: Structured protocols for efficient agent-to-agent communication&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Consensus Mechanisms&lt;/strong&gt;: Collaborative decision-making through agent voting and consensus&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Conflict Resolution&lt;/strong&gt;: Sophisticated protocols for resolving disagreements between agents&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;🛠️ Comprehensive Tool Ecosystem&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Web Interaction&lt;/strong&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Full browser automation via Playwright&lt;/li&gt; 
   &lt;li&gt;Web scraping and data extraction&lt;/li&gt; 
   &lt;li&gt;Form filling and submission&lt;/li&gt; 
   &lt;li&gt;Authentication handling&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Information Retrieval&lt;/strong&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Search engine integration&lt;/li&gt; 
   &lt;li&gt;Wikipedia access&lt;/li&gt; 
   &lt;li&gt;News and current events sources&lt;/li&gt; 
   &lt;li&gt;Specialized knowledge bases&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Document Processing&lt;/strong&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;PDF parsing and analysis&lt;/li&gt; 
   &lt;li&gt;Office document handling (Word, Excel, PowerPoint)&lt;/li&gt; 
   &lt;li&gt;Image recognition and OCR&lt;/li&gt; 
   &lt;li&gt;Data extraction and transformation&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Code Execution&lt;/strong&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Secure Python execution sandbox&lt;/li&gt; 
   &lt;li&gt;Multiple language support&lt;/li&gt; 
   &lt;li&gt;Package management&lt;/li&gt; 
   &lt;li&gt;Output capture and analysis&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Multimodal Processing&lt;/strong&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Image analysis and generation&lt;/li&gt; 
   &lt;li&gt;Audio processing and transcription&lt;/li&gt; 
   &lt;li&gt;Video analysis and summarization&lt;/li&gt; 
   &lt;li&gt;Chart and graph interpretation&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;🔄 Flexible Model Integration&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;OpenAI API Support&lt;/strong&gt;: Seamless integration with GPT-4 and newer models&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Open-Source Models&lt;/strong&gt;: Support for Llama, Mistral, and other open-source models&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Local Deployment&lt;/strong&gt;: Run models locally for privacy and reduced costs&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Model Switching&lt;/strong&gt;: Automatically select the appropriate model based on task requirements&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Fallback Mechanisms&lt;/strong&gt;: Gracefully handle API issues by switching to alternative models&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;👥 User-Friendly Interfaces&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Command-Line Interface&lt;/strong&gt;: Simple and intuitive commands for terminal users&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Web Interface&lt;/strong&gt;: Optional browser-based dashboard for visual interaction&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;API Integration&lt;/strong&gt;: RESTful API for embedding Anus in other applications&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Conversation History&lt;/strong&gt;: Review and continue previous conversations&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Task Monitoring&lt;/strong&gt;: Track progress of long-running tasks&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;🔒 Privacy and Security&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Local Execution&lt;/strong&gt;: Process sensitive data locally without sending to external APIs&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;API Key Management&lt;/strong&gt;: Secure handling of API keys and credentials&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Permission System&lt;/strong&gt;: Fine-grained control over agent capabilities&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Audit Logging&lt;/strong&gt;: Comprehensive logging of all agent actions&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Sandboxed Execution&lt;/strong&gt;: Secure environment for running untrusted code&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;🧩 Extensibility&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Plugin System&lt;/strong&gt;: Easily extend functionality with custom plugins&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Custom Tools&lt;/strong&gt;: Create your own tools to expand agent capabilities&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Model Adapters&lt;/strong&gt;: Add support for new AI models&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Middleware&lt;/strong&gt;: Insert custom processing steps in the agent workflow&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Event Hooks&lt;/strong&gt;: React to specific events in the agent lifecycle&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;🔧 Installation&lt;/h2&gt; 
&lt;p&gt;Anus AI supports multiple installation methods to accommodate different user preferences and environments.&lt;/p&gt; 
&lt;h3&gt;Prerequisites&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Python 3.11 or higher&lt;/li&gt; 
 &lt;li&gt;pip (Python package installer)&lt;/li&gt; 
 &lt;li&gt;Git&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Method 1: Pip Installation (Recommended for Users)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Install from PyPI
pip install anus-ai

# Verify installation
anus --version
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Method 2: From Source (Recommended for Developers)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Clone the repository
git clone https://github.com/nikmcfly/ANUS.git
cd ANUS

# Create and activate a virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install in development mode
pip install -e .

# Verify installation
anus --version
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Method 3: Using Docker&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Pull the Docker image
docker pull anusai/anus:latest

# Run Anus in a container
docker run -it anusai/anus:latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Method 4: Using Conda&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Create a new conda environment
conda create -n anus python=3.11
conda activate anus

# Install Anus
pip install anus-ai
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Platform-Specific Instructions&lt;/h3&gt; 
&lt;h4&gt;Windows&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Install required system dependencies
pip install windows-curses

# If using browser automation
playwright install
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;macOS&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Install required system dependencies
brew install python@3.11

# If using browser automation
playwright install
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Linux&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Install required system dependencies
sudo apt-get update
sudo apt-get install -y python3.11 python3.11-venv

# If using browser automation
playwright install
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Optional Dependencies&lt;/h3&gt; 
&lt;p&gt;Anus has several optional features that require additional dependencies:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# For document processing
pip install anus-ai[documents]

# For browser automation
pip install anus-ai[browser]

# For code execution
pip install anus-ai[code]

# For all optional features
pip install anus-ai[all]
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Configuration&lt;/h3&gt; 
&lt;p&gt;After installation, you'll need to configure Anus with your API keys:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Create a configuration file:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;anus init
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Edit the generated &lt;code&gt;.anus/config.yaml&lt;/code&gt; file with your API keys:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;llm:
  provider: openai
  api_key: your_openai_api_key
  model: gpt-4o

# Optional: Configure other providers
anthropic:
  api_key: your_anthropic_api_key

# Optional: Configure tool-specific settings
browser:
  headless: true
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;🚀 Quick Start&lt;/h2&gt; 
&lt;p&gt;Once installed, you can start using Anus right away:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Run Anus with a simple task
anus run "Find the latest news about artificial intelligence"

# Run in interactive mode
anus interactive

# Run with a specific configuration file
anus run --config custom_config.yaml "Summarize this article: https://example.com/article"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;📋 Usage Examples&lt;/h2&gt; 
&lt;h3&gt;Basic Examples&lt;/h3&gt; 
&lt;h4&gt;Simple Question Answering&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from anus import Agent

# Create a single agent
agent = Agent()

# Ask a simple question
response = agent.run("What is the capital of France?")
print(response)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Web Search&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from anus import Agent
from anus.tools import SearchTool

# Create an agent with search capabilities
agent = Agent(tools=[SearchTool()])

# Search for information
response = agent.run("Find the latest research on quantum computing")
print(response)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Document Analysis&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from anus import Agent
from anus.tools import DocumentTool

# Create an agent with document processing capabilities
agent = Agent(tools=[DocumentTool()])

# Analyze a PDF document
response = agent.run("Summarize this PDF: /path/to/document.pdf")
print(response)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Advanced Examples&lt;/h3&gt; 
&lt;h4&gt;Multi-Agent Collaboration&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from anus import Society, Agent

# Create specialized agents
researcher = Agent(role="researcher")
analyst = Agent(role="analyst")
writer = Agent(role="writer")

# Create a society of agents
society = Society(agents=[researcher, analyst, writer])

# Execute a complex task with collaboration
response = society.run(
    "Research the impact of artificial intelligence on healthcare, " 
    "analyze the findings, and write a comprehensive report"
)
print(response)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Browser Automation&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from anus import Agent
from anus.tools import BrowserTool

# Create an agent with browser capabilities
agent = Agent(tools=[BrowserTool()])

# Perform a web task
response = agent.run(
    "Go to weather.com, check the weather forecast for New York City for the next 5 days, "
    "and create a summary table"
)
print(response)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Code Generation and Execution&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from anus import Agent
from anus.tools import CodeTool

# Create an agent with code execution capabilities
agent = Agent(tools=[CodeTool()])

# Generate and execute code
response = agent.run(
    "Create a Python script that generates a fractal tree visualization using matplotlib"
)
print(response)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Command-Line Interface Examples&lt;/h3&gt; 
&lt;h4&gt;Running Tasks&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Simple information retrieval
anus run "What is the population of Tokyo?"

# Web search with specific parameters
anus run --search-depth=3 "Find recent breakthroughs in fusion energy research"

# Document processing
anus run --file=/path/to/report.pdf "Extract all financial data from this report"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Interactive Mode&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Start interactive session
anus interactive

# In interactive mode, you can have a conversation:
# &amp;gt; Tell me about the history of artificial intelligence
# &amp;gt; Now create a timeline of major AI milestones
# &amp;gt; Generate a visualization of this timeline
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Multi-Agent Mode&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Run a complex task with multiple agents
anus run --mode=multi "Research, analyze, and summarize the current state of renewable energy technologies"

# Specify particular agent roles
anus run --mode=multi --roles=researcher,analyst,writer "Create a comprehensive market analysis for electric vehicles"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;API Usage&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from anus.api import AnusAPI

# Initialize the API client
api = AnusAPI(api_key="your_api_key")

# Send a request
response = api.process_task(
    task="Generate a business plan for a sustainable fashion startup",
    mode="multi",
    output_format="markdown"
)

# Print or save the response
print(response.result)
with open("business_plan.md", "w") as f:
    f.write(response.result)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Advanced Configuration&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from anus import Agent, Config

# Create a custom configuration
config = Config(
    llm={
        "provider": "anthropic",
        "model": "claude-3-opus",
        "temperature": 0.7,
    },
    memory={
        "type": "persistent",
        "path": "./agent_memory",
    },
    tools={
        "browser": {"headless": False},
        "code": {"sandbox": True},
    }
)

# Create an agent with custom configuration
agent = Agent(config=config)

# Run a task
response = agent.run("Create an interactive data visualization for climate change data")
print(response)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;📚 Documentation&lt;/h2&gt; 
&lt;p&gt;For detailed documentation, visit our &lt;a href="https://anus-ai.github.io/docs"&gt;Documentation Site&lt;/a&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://anus-ai.github.io/docs/installation"&gt;Installation Guide&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://anus-ai.github.io/docs/getting-started"&gt;Getting Started&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://anus-ai.github.io/docs/architecture"&gt;Architecture Overview&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://anus-ai.github.io/docs/api"&gt;API Reference&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://anus-ai.github.io/docs/examples"&gt;Examples&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://anus-ai.github.io/docs/contributing"&gt;Contributing Guide&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;👥 Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome contributions from the community! Anus is designed to be community-driven, and your input helps make it better for everyone.&lt;/p&gt; 
&lt;h3&gt;Ways to Contribute&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Code Contributions&lt;/strong&gt;: Implement new features, fix bugs, or improve performance&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Documentation&lt;/strong&gt;: Improve or expand documentation, add examples, fix typos&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Bug Reports&lt;/strong&gt;: Report bugs or suggest improvements&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Feature Requests&lt;/strong&gt;: Suggest new features or enhancements&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Community Support&lt;/strong&gt;: Help answer questions and support other users&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Getting Started with Contributing&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Fork the Repository&lt;/strong&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Fork the repository on GitHub, then clone your fork
git clone https://github.com/your-username/anus.git
cd anus
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;&lt;strong&gt;Set Up Development Environment&lt;/strong&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Create and activate a virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install development dependencies
pip install -e ".[dev]"
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt;&lt;strong&gt;Create a Branch&lt;/strong&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Create a branch for your contribution
git checkout -b feature/your-feature-name
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="4"&gt; 
 &lt;li&gt;&lt;strong&gt;Make Your Changes&lt;/strong&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;ul&gt; 
 &lt;li&gt;Follow the code style guidelines&lt;/li&gt; 
 &lt;li&gt;Add tests for new functionality&lt;/li&gt; 
 &lt;li&gt;Update documentation as needed&lt;/li&gt; 
&lt;/ul&gt; 
&lt;ol start="5"&gt; 
 &lt;li&gt;&lt;strong&gt;Run Tests&lt;/strong&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Run the test suite
pytest

# Run linting
flake8
mypy anus
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="6"&gt; 
 &lt;li&gt;&lt;strong&gt;Submit a Pull Request&lt;/strong&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;ul&gt; 
 &lt;li&gt;Push your changes to your fork&lt;/li&gt; 
 &lt;li&gt;Submit a pull request from your branch to our main branch&lt;/li&gt; 
 &lt;li&gt;Provide a clear description of the changes and any related issues&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Code Style Guidelines&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Follow &lt;a href="https://pep8.org/"&gt;PEP 8&lt;/a&gt; for Python code style&lt;/li&gt; 
 &lt;li&gt;Use type hints for all function parameters and return values&lt;/li&gt; 
 &lt;li&gt;Write docstrings for all functions, classes, and modules&lt;/li&gt; 
 &lt;li&gt;Keep functions focused and small (under 50 lines when possible)&lt;/li&gt; 
 &lt;li&gt;Use meaningful variable and function names&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Commit Message Guidelines&lt;/h3&gt; 
&lt;p&gt;We follow the &lt;a href="https://www.conventionalcommits.org/"&gt;Conventional Commits&lt;/a&gt; specification:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&amp;lt;type&amp;gt;(&amp;lt;scope&amp;gt;): &amp;lt;description&amp;gt;

[optional body]

[optional footer(s)]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Types include:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;feat&lt;/code&gt;: A new feature&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;fix&lt;/code&gt;: A bug fix&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;docs&lt;/code&gt;: Documentation changes&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;style&lt;/code&gt;: Code style changes (formatting, etc.)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;refactor&lt;/code&gt;: Code changes that neither fix bugs nor add features&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;test&lt;/code&gt;: Adding or modifying tests&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;chore&lt;/code&gt;: Changes to the build process or auxiliary tools&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Pull Request Process&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Update the README.md or documentation with details of changes if appropriate&lt;/li&gt; 
 &lt;li&gt;Update the CHANGELOG.md with details of changes&lt;/li&gt; 
 &lt;li&gt;The PR should work for Python 3.11 and above&lt;/li&gt; 
 &lt;li&gt;PRs require approval from at least one maintainer&lt;/li&gt; 
 &lt;li&gt;Once approved, a maintainer will merge your PR&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Code of Conduct&lt;/h3&gt; 
&lt;p&gt;Please note that this project is released with a &lt;a href="https://raw.githubusercontent.com/nikmcfly/ANUS/main/CODE_OF_CONDUCT.md"&gt;Contributor Code of Conduct&lt;/a&gt;. By participating in this project you agree to abide by its terms.&lt;/p&gt; 
&lt;h2&gt;🌐 Community&lt;/h2&gt; 
&lt;p&gt;Join our community to get help, share ideas, and contribute to the project:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://t.me/goanus"&gt;Telegram Channel&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;📝 License&lt;/h2&gt; 
&lt;p&gt;Anus is released under the &lt;a href="https://raw.githubusercontent.com/nikmcfly/ANUS/main/LICENSE"&gt;MIT License&lt;/a&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;MIT License

Copyright (c) 2025 Anus AI Team

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>jumpserver/jumpserver</title>
      <link>https://github.com/jumpserver/jumpserver</link>
      <description>&lt;p&gt;JumpServer is an open-source Privileged Access Management (PAM) tool that provides DevOps and IT teams with on-demand and secure access to SSH, RDP, Kubernetes, Database and RemoteApp endpoints through a web browser.&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;a name="readme-top"&gt;&lt;/a&gt; 
 &lt;a href="https://jumpserver.com" target="_blank"&gt;&lt;img src="https://download.jumpserver.org/images/jumpserver-logo.svg?sanitize=true" alt="JumpServer" width="300"&gt;&lt;/a&gt; 
 &lt;h2&gt;An open-source PAM tool (Bastion Host)&lt;/h2&gt; 
 &lt;p&gt;&lt;a href="https://www.gnu.org/licenses/gpl-3.0.html"&gt;&lt;img src="https://img.shields.io/github/license/jumpserver/jumpserver" alt=""&gt;&lt;/a&gt; &lt;a href="https://jumpserver.com/docs"&gt;&lt;img src="https://img.shields.io/badge/documentation-148F76" alt=""&gt;&lt;/a&gt; &lt;a href="https://deepwiki.com/jumpserver/jumpserver/"&gt;&lt;img src="https://img.shields.io/badge/deepwiki-devin?color=blue" alt=""&gt;&lt;/a&gt; &lt;a href="https://discord.com/invite/W6vYXmAQG2"&gt;&lt;img src="https://img.shields.io/discord/1194233267294052363?style=flat&amp;amp;logo=discord&amp;amp;logoColor=%23f5f5f5&amp;amp;labelColor=%235462eb&amp;amp;color=%235462eb" alt=""&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/u/jumpserver"&gt;&lt;img src="https://img.shields.io/docker/pulls/jumpserver/jms_all.svg?sanitize=true" alt=""&gt;&lt;/a&gt; &lt;a href="https://github.com/jumpserver/jumpserver/releases/latest"&gt;&lt;img src="https://img.shields.io/github/v/release/jumpserver/jumpserver" alt=""&gt;&lt;/a&gt; &lt;a href="https://github.com/jumpserver/jumpserver"&gt;&lt;img src="https://img.shields.io/github/stars/jumpserver/jumpserver?color=%231890FF&amp;amp;style=flat-square%C2%A0%C2%A0%C2%A0" alt=""&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/jumpserver/jumpserver/dev/README.md"&gt;English&lt;/a&gt; · &lt;a href="https://raw.githubusercontent.com/jumpserver/jumpserver/dev/readmes/README.zh-hans.md"&gt;中文(简体)&lt;/a&gt; · &lt;a href="https://raw.githubusercontent.com/jumpserver/jumpserver/dev/readmes/README.zh-hant.md"&gt;中文(繁體)&lt;/a&gt; · &lt;a href="https://raw.githubusercontent.com/jumpserver/jumpserver/dev/readmes/README.ja.md"&gt;日本語&lt;/a&gt; · &lt;a href="https://raw.githubusercontent.com/jumpserver/jumpserver/dev/readmes/README.pt-br.md"&gt;Português (Brasil)&lt;/a&gt; · &lt;a href="https://raw.githubusercontent.com/jumpserver/jumpserver/dev/readmes/README.es.md"&gt;Español&lt;/a&gt; · &lt;a href="https://raw.githubusercontent.com/jumpserver/jumpserver/dev/readmes/README.ru.md"&gt;Русский&lt;/a&gt; · &lt;a href="https://raw.githubusercontent.com/jumpserver/jumpserver/dev/readmes/README.ko.md"&gt;한국어&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;br&gt; 
&lt;h2&gt;What is JumpServer?&lt;/h2&gt; 
&lt;p&gt;JumpServer is an open-source Privileged Access Management (PAM) tool that provides DevOps and IT teams with on-demand and secure access to SSH, RDP, Kubernetes, Database and RemoteApp endpoints through a web browser.&lt;/p&gt; 
&lt;picture&gt; 
 &lt;source media="(prefers-color-scheme: light)" srcset="https://www.jumpserver.com/images/jumpserver-arch-light.png"&gt; 
 &lt;source media="(prefers-color-scheme: dark)" srcset="https://www.jumpserver.com/images/jumpserver-arch-dark.png"&gt; 
 &lt;img src="https://github.com/user-attachments/assets/dd612f3d-c958-4f84-b164-f31b75454d7f" alt="Theme-based Image"&gt; 
&lt;/picture&gt; 
&lt;h2&gt;Quickstart&lt;/h2&gt; 
&lt;p&gt;Prepare a clean Linux Server ( 64 bit, &amp;gt;= 4c8g )&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;curl -sSL https://github.com/jumpserver/jumpserver/releases/latest/download/quick_start.sh | bash
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Access JumpServer in your browser at &lt;code&gt;http://your-jumpserver-ip/&lt;/code&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Username: &lt;code&gt;admin&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Password: &lt;code&gt;ChangeMe&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=UlGYRbKrpgY" title="JumpServer Quickstart"&gt;&lt;img src="https://github.com/user-attachments/assets/0f32f52b-9935-485e-8534-336c63389612" alt="JumpServer Quickstart"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Screenshots&lt;/h2&gt; 
&lt;table style="border-collapse: collapse; border: 1px solid black;"&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td style="padding: 5px;background-color:#fff;"&gt;&lt;img src="https://github.com/jumpserver/jumpserver/assets/32935519/99fabe5b-0475-4a53-9116-4c370a1426c4" alt="JumpServer Console"&gt;&lt;/td&gt; 
   &lt;td style="padding: 5px;background-color:#fff;"&gt;&lt;img src="https://github.com/user-attachments/assets/7c1f81af-37e8-4f07-8ac9-182895e1062e" alt="JumpServer PAM"&gt;&lt;/td&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td style="padding: 5px;background-color:#fff;"&gt;&lt;img src="https://github.com/jumpserver/jumpserver/assets/32935519/a424d731-1c70-4108-a7d8-5bbf387dda9a" alt="JumpServer Audits"&gt;&lt;/td&gt; 
   &lt;td style="padding: 5px;background-color:#fff;"&gt;&lt;img src="https://github.com/jumpserver/jumpserver/assets/32935519/393d2c27-a2d0-4dea-882d-00ed509e00c9" alt="JumpServer Workbench"&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td style="padding: 5px;background-color:#fff;"&gt;&lt;img src="https://github.com/user-attachments/assets/eaa41f66-8cc8-4f01-a001-0d258501f1c9" alt="JumpServer RBAC"&gt;&lt;/td&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; 
   &lt;td style="padding: 5px;background-color:#fff;"&gt;&lt;img src="https://github.com/jumpserver/jumpserver/assets/32935519/3a2611cd-8902-49b8-b82b-2a6dac851f3e" alt="JumpServer Settings"&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td style="padding: 5px;background-color:#fff;"&gt;&lt;img src="https://github.com/jumpserver/jumpserver/assets/32935519/1e236093-31f7-4563-8eb1-e36d865f1568" alt="JumpServer SSH"&gt;&lt;/td&gt; 
   &lt;td style="padding: 5px;background-color:#fff;"&gt;&lt;img src="https://github.com/jumpserver/jumpserver/assets/32935519/69373a82-f7ab-41e8-b763-bbad2ba52167" alt="JumpServer RDP"&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td style="padding: 5px;background-color:#fff;"&gt;&lt;img src="https://github.com/jumpserver/jumpserver/assets/32935519/5bed98c6-cbe8-4073-9597-d53c69dc3957" alt="JumpServer K8s"&gt;&lt;/td&gt; 
   &lt;td style="padding: 5px;background-color:#fff;"&gt;&lt;img src="https://github.com/jumpserver/jumpserver/assets/32935519/b80ad654-548f-42bc-ba3d-c1cfdf1b46d6" alt="JumpServer DB"&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h2&gt;Components&lt;/h2&gt; 
&lt;p&gt;JumpServer consists of multiple key components, which collectively form the functional framework of JumpServer, providing users with comprehensive capabilities for operations management and security control.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Project&lt;/th&gt; 
   &lt;th&gt;Status&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/jumpserver/lina"&gt;Lina&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/jumpserver/lina/releases"&gt;&lt;img alt="Lina release" src="https://img.shields.io/github/release/jumpserver/lina.svg?sanitize=true"&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;JumpServer Web UI&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/jumpserver/luna"&gt;Luna&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/jumpserver/luna/releases"&gt;&lt;img alt="Luna release" src="https://img.shields.io/github/release/jumpserver/luna.svg?sanitize=true"&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;JumpServer Web Terminal&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/jumpserver/koko"&gt;KoKo&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/jumpserver/koko/releases"&gt;&lt;img alt="Koko release" src="https://img.shields.io/github/release/jumpserver/koko.svg?sanitize=true"&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;JumpServer Character Protocol Connector&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/jumpserver/lion"&gt;Lion&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/jumpserver/lion/releases"&gt;&lt;img alt="Lion release" src="https://img.shields.io/github/release/jumpserver/lion.svg?sanitize=true"&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;JumpServer Graphical Protocol Connector&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/jumpserver/chen"&gt;Chen&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/jumpserver/chen/releases"&gt;&lt;img alt="Chen release" src="https://img.shields.io/github/release/jumpserver/chen.svg?sanitize=true"&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;JumpServer Web DB&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/jumpserver/tinker"&gt;Tinker&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img alt="Tinker" src="https://img.shields.io/badge/release-private-red"&gt;&lt;/td&gt; 
   &lt;td&gt;JumpServer Remote Application Connector (Windows)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/jumpserver/Panda"&gt;Panda&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img alt="Panda" src="https://img.shields.io/badge/release-private-red"&gt;&lt;/td&gt; 
   &lt;td&gt;JumpServer EE Remote Application Connector (Linux)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/jumpserver/razor"&gt;Razor&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img alt="Chen" src="https://img.shields.io/badge/release-private-red"&gt;&lt;/td&gt; 
   &lt;td&gt;JumpServer EE RDP Proxy Connector&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/jumpserver/magnus"&gt;Magnus&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img alt="Magnus" src="https://img.shields.io/badge/release-private-red"&gt;&lt;/td&gt; 
   &lt;td&gt;JumpServer EE Database Proxy Connector&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/jumpserver/nec"&gt;Nec&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img alt="Nec" src="https://img.shields.io/badge/release-private-red"&gt;&lt;/td&gt; 
   &lt;td&gt;JumpServer EE VNC Proxy Connector&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/jumpserver/facelive"&gt;Facelive&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img alt="Facelive" src="https://img.shields.io/badge/release-private-red"&gt;&lt;/td&gt; 
   &lt;td&gt;JumpServer EE Facial Recognition&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Third-party projects&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/acerrah/jumpserver-grafana-dashboard"&gt;jumpserver-grafana-dashboard&lt;/a&gt; JumpServer with grafana dashboard&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Welcome to submit PR to contribute. Please refer to &lt;a href="https://github.com/jumpserver/jumpserver/raw/dev/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; for guidelines.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Copyright (c) 2014-2025 FIT2CLOUD, All rights reserved.&lt;/p&gt; 
&lt;p&gt;Licensed under The GNU General Public License version 3 (GPLv3) (the "License"); you may not use this file except in compliance with the License. You may obtain a copy of the License at&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.gnu.org/licenses/gpl-3.0.html"&gt;https://www.gnu.org/licenses/gpl-3.0.html&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an " AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.&lt;/p&gt; 
&lt;!-- JumpServer official link --&gt; 
&lt;!-- JumpServer Other link--&gt; 
&lt;!-- Shield link--&gt;</description>
    </item>
    
    <item>
      <title>camel-ai/camel</title>
      <link>https://github.com/camel-ai/camel</link>
      <description>&lt;p&gt;🐫 CAMEL: The first and the best multi-agent framework. Finding the Scaling Law of Agents. https://www.camel-ai.org&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;a href="https://www.camel-ai.org/"&gt; &lt;img src="https://raw.githubusercontent.com/camel-ai/camel/master/docs/images/banner.png" alt="Banner"&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;br&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://camel-ai.github.io/camel/index.html"&gt;&lt;img src="https://img.shields.io/badge/Documentation-EB3ECC" alt="Documentation"&gt;&lt;/a&gt; &lt;a href="https://discord.camel-ai.org/"&gt;&lt;img src="https://img.shields.io/discord/1082486657678311454?logo=discord&amp;amp;labelColor=%20%235462eb&amp;amp;logoColor=%20%23f5f5f5&amp;amp;color=%20%235462eb" alt="Discord"&gt;&lt;/a&gt; &lt;a href="https://x.com/CamelAIOrg"&gt;&lt;img src="https://img.shields.io/twitter/follow/CamelAIOrg?style=social" alt="X"&gt;&lt;/a&gt; &lt;a href="https://www.reddit.com/r/CamelAI/"&gt;&lt;img src="https://img.shields.io/reddit/subreddit-subscribers/CamelAI?style=plastic&amp;amp;logo=reddit&amp;amp;label=r%2FCAMEL&amp;amp;labelColor=white" alt="Reddit"&gt;&lt;/a&gt; &lt;a href="https://ghli.org/camel/wechat.png"&gt;&lt;img src="https://img.shields.io/badge/WeChat-CamelAIOrg-brightgreen?logo=wechat&amp;amp;logoColor=white" alt="Wechat"&gt;&lt;/a&gt; &lt;a href="https://huggingface.co/camel-ai"&gt;&lt;img src="https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-CAMEL--AI-ffc107?color=ffc107&amp;amp;logoColor=white" alt="Hugging Face"&gt;&lt;/a&gt; &lt;a href="https://github.com/camel-ai/camel/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/camel-ai/camel?label=stars&amp;amp;logo=github&amp;amp;color=brightgreen" alt="Star"&gt;&lt;/a&gt; &lt;a href="https://github.com/camel-ai/camel/raw/master/licenses/LICENSE"&gt;&lt;img src="https://img.shields.io/badge/License-Apache_2.0-blue.svg?sanitize=true" alt="Package License"&gt;&lt;/a&gt; &lt;a href="https://pypi.org/project/camel-ai"&gt;&lt;img src="https://img.shields.io/pypi/dm/camel-ai" alt="PyPI Download"&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://trendshift.io/repositories/649" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/649" alt="camel-ai/camel | Trendshift" style="width: 250px; height: 55px;" width="250" height="55"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;hr&gt; 
&lt;div align="center"&gt; 
 &lt;h4 align="center"&gt; &lt;p&gt;&lt;a href="https://github.com/camel-ai/camel#community"&gt;Community&lt;/a&gt; | &lt;a href="https://github.com/camel-ai/camel#installation"&gt;Installation&lt;/a&gt; | &lt;a href="https://github.com/camel-ai/camel/tree/HEAD/examples"&gt;Examples&lt;/a&gt; | &lt;a href="https://arxiv.org/abs/2303.17760"&gt;Paper&lt;/a&gt; | &lt;a href="https://github.com/camel-ai/camel#citation"&gt;Citation&lt;/a&gt; | &lt;a href="https://github.com/camel-ai/camel#contributing-to-camel-"&gt;Contributing&lt;/a&gt; | &lt;a href="https://www.camel-ai.org/"&gt;CAMEL-AI&lt;/a&gt;&lt;/p&gt; &lt;/h4&gt; 
 &lt;p style="line-height: 1.5; text-align: center;"&gt; 🐫 CAMEL is an open-source community dedicated to finding the scaling laws of agents. We believe that studying these agents on a large scale offers valuable insights into their behaviors, capabilities, and potential risks. To facilitate research in this field, we implement and support various types of agents, tasks, prompts, models, and simulated environments.&lt;/p&gt; 
 &lt;br&gt; 
 &lt;p&gt;Join us (&lt;a href="https://discord.camel-ai.org/"&gt;&lt;em&gt;Discord&lt;/em&gt;&lt;/a&gt; or &lt;a href="https://ghli.org/camel/wechat.png"&gt;&lt;em&gt;WeChat&lt;/em&gt;&lt;/a&gt;) in pushing the boundaries of finding the scaling laws of agents.&lt;/p&gt; 
 &lt;p&gt;🌟 Star CAMEL on GitHub and be instantly notified of new releases.&lt;/p&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/camel-ai/camel/master/docs/images/star.gif" alt="Star" width="186" height="60"&gt;  
&lt;/div&gt; 
&lt;br&gt; 
&lt;h2&gt;CAMEL Framework Design Principles&lt;/h2&gt; 
&lt;h3&gt;🧬&amp;nbsp;Evolvability&lt;/h3&gt; 
&lt;p&gt;The framework enables multi-agent systems to continuously evolve by generating data and interacting with environments. This evolution can be driven by reinforcement learning with verifiable rewards or supervised learning.&lt;/p&gt; 
&lt;h3&gt;📈&amp;nbsp;Scalability&lt;/h3&gt; 
&lt;p&gt;The framework is designed to support systems with millions of agents, ensuring efficient coordination, communication, and resource management at scale.&lt;/p&gt; 
&lt;h3&gt;💾&amp;nbsp;Statefulness&lt;/h3&gt; 
&lt;p&gt;Agents maintain stateful memory, enabling them to perform multi-step interactions with environments and efficiently tackle sophisticated tasks.&lt;/p&gt; 
&lt;h3&gt;📖&amp;nbsp;Code-as-Prompt&lt;/h3&gt; 
&lt;p&gt;Every line of code and comment serves as a prompt for agents. Code should be written clearly and readably, ensuring both humans and agents can interpret it effectively.&lt;/p&gt; 
&lt;br&gt; 
&lt;h2&gt;Why Use CAMEL for Your Research?&lt;/h2&gt; 
&lt;p&gt;We are a community-driven research collective comprising over 100 researchers dedicated to advancing frontier research in Multi-Agent Systems. Researchers worldwide choose CAMEL for their studies based on the following reasons.&lt;/p&gt; 
&lt;table style="width: 100%;"&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;✅&lt;/td&gt; 
   &lt;td align="left" style="font-weight: bold;"&gt;Large-Scale Agent System&lt;/td&gt; 
   &lt;td align="left"&gt;Simulate up to 1M agents to study emergent behaviors and scaling laws in complex, multi-agent environments.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;✅&lt;/td&gt; 
   &lt;td align="left" style="font-weight: bold;"&gt;Dynamic Communication&lt;/td&gt; 
   &lt;td align="left"&gt;Enable real-time interactions among agents, fostering seamless collaboration for tackling intricate tasks.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;✅&lt;/td&gt; 
   &lt;td align="left" style="font-weight: bold;"&gt;Stateful Memory&lt;/td&gt; 
   &lt;td align="left"&gt;Equip agents with the ability to retain and leverage historical context, improving decision-making over extended interactions.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;✅&lt;/td&gt; 
   &lt;td align="left" style="font-weight: bold;"&gt;Support for Multiple Benchmarks&lt;/td&gt; 
   &lt;td align="left"&gt;Utilize standardized benchmarks to rigorously evaluate agent performance, ensuring reproducibility and reliable comparisons.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;✅&lt;/td&gt; 
   &lt;td align="left" style="font-weight: bold;"&gt;Support for Different Agent Types&lt;/td&gt; 
   &lt;td align="left"&gt;Work with a variety of agent roles, tasks, models, and environments, supporting interdisciplinary experiments and diverse research applications.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;✅&lt;/td&gt; 
   &lt;td align="left" style="font-weight: bold;"&gt;Data Generation and Tool Integration&lt;/td&gt; 
   &lt;td align="left"&gt;Automate the creation of large-scale, structured datasets while seamlessly integrating with multiple tools, streamlining synthetic data generation and research workflows.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;br&gt; 
&lt;h2&gt;What Can You Build With CAMEL?&lt;/h2&gt; 
&lt;h3&gt;1. Data Generation&lt;/h3&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://github.com/camel-ai/camel/raw/master/camel/datagen/cot_datagen.py"&gt; &lt;img src="https://raw.githubusercontent.com/camel-ai/camel/master/docs/images/cot.png" alt="CoT Data Generation"&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://github.com/camel-ai/camel/tree/master/camel/datagen/self_instruct"&gt; &lt;img src="https://raw.githubusercontent.com/camel-ai/camel/master/docs/images/self_instruct.png" alt="Self-Instruct Data Generation"&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://github.com/camel-ai/camel/tree/master/camel/datagen/source2synth"&gt; &lt;img src="https://raw.githubusercontent.com/camel-ai/camel/master/docs/images/source2synth.png" alt="Source2Synth Data Generation"&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://github.com/camel-ai/camel/raw/master/camel/datagen/self_improving_cot.py"&gt; &lt;img src="https://raw.githubusercontent.com/camel-ai/camel/master/docs/images/self_improving.png" alt="Self-Improving Data Generation"&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;h3&gt;2. Task Automation&lt;/h3&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://github.com/camel-ai/camel/raw/master/camel/societies/role_playing.py"&gt; &lt;img src="https://raw.githubusercontent.com/camel-ai/camel/master/docs/images/role_playing.png" alt="Role Playing"&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://github.com/camel-ai/camel/tree/master/camel/societies/workforce"&gt; &lt;img src="https://raw.githubusercontent.com/camel-ai/camel/master/docs/images/workforce.png" alt="Workforce"&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://docs.camel-ai.org/cookbooks/advanced_features/agents_with_rag.html"&gt; &lt;img src="https://raw.githubusercontent.com/camel-ai/camel/master/docs/images/rag_pipeline.png" alt="RAG Pipeline"&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;h3&gt;3. World Simulation&lt;/h3&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://github.com/camel-ai/oasis"&gt; &lt;img src="https://raw.githubusercontent.com/camel-ai/camel/master/docs/images/oasis_case.png" alt="Oasis Case"&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;br&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;p&gt;Installing CAMEL is a breeze thanks to its availability on PyPI. Simply open your terminal and run:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install camel-ai
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Starting with ChatAgent&lt;/h3&gt; 
&lt;p&gt;This example demonstrates how to create a &lt;code&gt;ChatAgent&lt;/code&gt; using the CAMEL framework and perform a search query using DuckDuckGo.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Install the tools package:&lt;/strong&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install 'camel-ai[web_tools]'
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;&lt;strong&gt;Set up your OpenAI API key:&lt;/strong&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;export OPENAI_API_KEY='your_openai_api_key'
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt;&lt;strong&gt;Run the following Python code:&lt;/strong&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from camel.models import ModelFactory
from camel.types import ModelPlatformType, ModelType
from camel.agents import ChatAgent
from camel.toolkits import SearchToolkit

model = ModelFactory.create(
  model_platform=ModelPlatformType.OPENAI,
  model_type=ModelType.GPT_4O,
  model_config_dict={"temperature": 0.0},
)

search_tool = SearchToolkit().search_duckduckgo

agent = ChatAgent(model=model, tools=[search_tool])

response_1 = agent.step("What is CAMEL-AI?")
print(response_1.msgs[0].content)
# CAMEL-AI is the first LLM (Large Language Model) multi-agent framework
# and an open-source community focused on finding the scaling laws of agents.
# ...

response_2 = agent.step("What is the Github link to CAMEL framework?")
print(response_2.msgs[0].content)
# The GitHub link to the CAMEL framework is
# [https://github.com/camel-ai/camel](https://github.com/camel-ai/camel).
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For more detailed instructions and additional configuration options, check out the &lt;a href="https://github.com/camel-ai/camel/raw/master/docs/get_started/installation.md"&gt;installation section&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;After running, you can explore our CAMEL Tech Stack and Cookbooks at &lt;a href="https://docs.camel-ai.org"&gt;docs.camel-ai.org&lt;/a&gt; to build powerful multi-agent systems.&lt;/p&gt; 
&lt;p&gt;We provide a &lt;a href="https://colab.research.google.com/drive/1AzP33O8rnMW__7ocWJhVBXjKziJXPtim?usp=sharing"&gt;&lt;img src="https://colab.research.google.com/assets/colab-badge.svg?sanitize=true" alt="Google Colab"&gt;&lt;/a&gt; demo showcasing a conversation between two ChatGPT agents playing roles as a python programmer and a stock trader collaborating on developing a trading bot for stock market.&lt;/p&gt; 
&lt;p&gt;Explore different types of agents, their roles, and their applications.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.camel-ai.org/cookbooks/basic_concepts/create_your_first_agent.html"&gt;Creating Your First Agent&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.camel-ai.org/cookbooks/basic_concepts/create_your_first_agents_society.html"&gt;Creating Your First Agent Society&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.camel-ai.org/cookbooks/advanced_features/embodied_agents.html"&gt;Embodied Agents&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.camel-ai.org/cookbooks/advanced_features/critic_agents_and_tree_search.html"&gt;Critic Agents&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Seeking Help&lt;/h3&gt; 
&lt;p&gt;Please reach out to us on &lt;a href="https://discord.camel-ai.org/"&gt;CAMEL discord&lt;/a&gt; if you encounter any issue set up CAMEL.&lt;/p&gt; 
&lt;br&gt; 
&lt;h2&gt;Tech Stack&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://docs.camel-ai.org"&gt; &lt;img src="https://camel-ai.github.io/camel_asset/graphics/techstack.png" alt="TechStack"&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;h3&gt;Key Modules&lt;/h3&gt; 
&lt;p&gt;Core components and utilities to build, operate, and enhance CAMEL-AI agents and societies.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Module&lt;/th&gt; 
   &lt;th align="left"&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;&lt;a href="https://docs.camel-ai.org/key_modules/agents.html"&gt;Agents&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Core agent architectures and behaviors for autonomous operation.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;&lt;a href="https://docs.camel-ai.org/key_modules/society.html"&gt;Agent Societies&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Components for building and managing multi-agent systems and collaboration.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;&lt;a href="https://docs.camel-ai.org/key_modules/datagen.html"&gt;Data Generation&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Tools and methods for synthetic data creation and augmentation.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;&lt;a href="https://docs.camel-ai.org/key_modules/models.html"&gt;Models&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Model architectures and customization options for agent intelligence.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;&lt;a href="https://docs.camel-ai.org/key_modules/tools.html"&gt;Tools&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Tools integration for specialized agent tasks.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;&lt;a href="https://docs.camel-ai.org/key_modules/memory.html"&gt;Memory&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Memory storage and retrieval mechanisms for agent state management.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;&lt;a href="https://docs.camel-ai.org/key_modules/storages.html"&gt;Storage&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Persistent storage solutions for agent data and states.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;&lt;a href="https://github.com/camel-ai/camel/tree/master/camel/benchmarks"&gt;Benchmarks&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Performance evaluation and testing frameworks.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;&lt;a href="https://docs.camel-ai.org/key_modules/interpreters.html"&gt;Interpreters&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Code and command interpretation capabilities.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;&lt;a href="https://docs.camel-ai.org/key_modules/loaders.html"&gt;Data Loaders&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Data ingestion and preprocessing tools.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;&lt;a href="https://docs.camel-ai.org/key_modules/retrievers.html"&gt;Retrievers&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Knowledge retrieval and RAG components.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;&lt;a href="https://github.com/camel-ai/camel/tree/master/camel/runtime"&gt;Runtime&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Execution environment and process management.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;&lt;a href="https://docs.camel-ai.org/cookbooks/advanced_features/agents_with_human_in_loop_and_tool_approval.html"&gt;Human-in-the-Loop&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Interactive components for human oversight and intervention.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;hr&gt; 
&lt;h2&gt;Research&lt;/h2&gt; 
&lt;p&gt;We believe that studying these agents on a large scale offers valuable insights into their behaviors, capabilities, and potential risks.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Explore our research projects:&lt;/strong&gt;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://crab.camel-ai.org/"&gt; &lt;img src="https://raw.githubusercontent.com/camel-ai/camel/master/docs/images/crab.png" alt="CRAB"&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://agent-trust.camel-ai.org/"&gt; &lt;img src="https://raw.githubusercontent.com/camel-ai/camel/master/docs/images/agent_trust.png" alt="Agent Trust"&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://oasis.camel-ai.org/"&gt; &lt;img src="https://raw.githubusercontent.com/camel-ai/camel/master/docs/images/oasis.png" alt="OASIS"&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://emos-project.github.io/"&gt; &lt;img src="https://raw.githubusercontent.com/camel-ai/camel/master/docs/images/emos.png" alt="Emos"&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;blockquote&gt; 
 &lt;h3&gt;Research with US&lt;/h3&gt; 
 &lt;p&gt;We warmly invite you to use CAMEL for your impactful research.&lt;/p&gt; 
 &lt;p&gt;Rigorous research takes time and resources. We are a community-driven research collective with 100+ researchers exploring the frontier research of Multi-agent Systems. Join our ongoing projects or test new ideas with us, &lt;a href="mailto:camel-ai@eigent.ai"&gt;reach out via email&lt;/a&gt; for more information.&lt;/p&gt; 
 &lt;div align="center"&gt; 
  &lt;img src="https://raw.githubusercontent.com/camel-ai/camel/master/docs/images/partners.png" alt="Partners"&gt; 
 &lt;/div&gt; 
&lt;/blockquote&gt; 
&lt;br&gt; 
&lt;h2&gt;Synthetic Datasets&lt;/h2&gt; 
&lt;h3&gt;1. Utilize Various LLMs as Backends&lt;/h3&gt; 
&lt;p&gt;For more details, please see our &lt;a href="https://docs.camel-ai.org/key_modules/models.html#"&gt;&lt;code&gt;Models Documentation&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Data (Hosted on Hugging Face)&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Dataset&lt;/th&gt; 
   &lt;th&gt;Chat format&lt;/th&gt; 
   &lt;th&gt;Instruction format&lt;/th&gt; 
   &lt;th&gt;Chat format (translated)&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;AI Society&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/datasets/camel-ai/ai_society/blob/main/ai_society_chat.tar.gz"&gt;Chat format&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/datasets/camel-ai/ai_society/blob/main/ai_society_instructions.json"&gt;Instruction format&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/datasets/camel-ai/ai_society_translated"&gt;Chat format (translated)&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Code&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/datasets/camel-ai/code/blob/main/code_chat.tar.gz"&gt;Chat format&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/datasets/camel-ai/code/blob/main/code_instructions.json"&gt;Instruction format&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;x&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Math&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/datasets/camel-ai/math"&gt;Chat format&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;x&lt;/td&gt; 
   &lt;td&gt;x&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Physics&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/datasets/camel-ai/physics"&gt;Chat format&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;x&lt;/td&gt; 
   &lt;td&gt;x&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Chemistry&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/datasets/camel-ai/chemistry"&gt;Chat format&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;x&lt;/td&gt; 
   &lt;td&gt;x&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Biology&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/datasets/camel-ai/biology"&gt;Chat format&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;x&lt;/td&gt; 
   &lt;td&gt;x&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;2. Visualizations of Instructions and Tasks&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Dataset&lt;/th&gt; 
   &lt;th&gt;Instructions&lt;/th&gt; 
   &lt;th&gt;Tasks&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;AI Society&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://atlas.nomic.ai/map/3a559a06-87d0-4476-a879-962656242452/db961915-b254-48e8-8e5c-917f827b74c6"&gt;Instructions&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://atlas.nomic.ai/map/cb96f41b-a6fd-4fe4-ac40-08e101714483/ae06156c-a572-46e9-8345-ebe18586d02b"&gt;Tasks&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Code&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://atlas.nomic.ai/map/902d6ccb-0bbb-4294-83a8-1c7d2dae03c8/ace2e146-e49f-41db-a1f4-25a2c4be2457"&gt;Instructions&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://atlas.nomic.ai/map/efc38617-9180-490a-8630-43a05b35d22d/2576addf-a133-45d5-89a9-6b067b6652dd"&gt;Tasks&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Misalignment&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://atlas.nomic.ai/map/5c491035-a26e-4a05-9593-82ffb2c3ab40/2bd98896-894e-4807-9ed8-a203ccb14d5e"&gt;Instructions&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://atlas.nomic.ai/map/abc357dd-9c04-4913-9541-63e259d7ac1f/825139a4-af66-427c-9d0e-f36b5492ab3f"&gt;Tasks&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;br&gt; 
&lt;h2&gt;Cookbooks (Usecases)&lt;/h2&gt; 
&lt;p&gt;Practical guides and tutorials for implementing specific functionalities in CAMEL-AI agents and societies.&lt;/p&gt; 
&lt;h3&gt;1. Basic Concepts&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Cookbook&lt;/th&gt; 
   &lt;th align="left"&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;&lt;a href="https://docs.camel-ai.org/cookbooks/basic_concepts/create_your_first_agent.html"&gt;Creating Your First Agent&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;A step-by-step guide to building your first agent.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;&lt;a href="https://docs.camel-ai.org/cookbooks/basic_concepts/create_your_first_agents_society.html"&gt;Creating Your First Agent Society&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Learn to build a collaborative society of agents.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;&lt;a href="https://docs.camel-ai.org/cookbooks/basic_concepts/agents_message.html"&gt;Message Cookbook&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Best practices for message handling in agents.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;2. Advanced Features&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Cookbook&lt;/th&gt; 
   &lt;th align="left"&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;&lt;a href="https://docs.camel-ai.org/cookbooks/advanced_features/agents_with_tools.html"&gt;Tools Cookbook&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Integrating tools for enhanced functionality.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;&lt;a href="https://docs.camel-ai.org/cookbooks/advanced_features/agents_with_memory.html"&gt;Memory Cookbook&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Implementing memory systems in agents.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;&lt;a href="https://docs.camel-ai.org/cookbooks/advanced_features/agents_with_rag.html"&gt;RAG Cookbook&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Recipes for Retrieval-Augmented Generation.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;&lt;a href="https://docs.camel-ai.org/cookbooks/advanced_features/agents_with_graph_rag.html"&gt;Graph RAG Cookbook&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Leveraging knowledge graphs with RAG.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;&lt;a href="https://docs.camel-ai.org/cookbooks/advanced_features/agents_tracking.html"&gt;Track CAMEL Agents with AgentOps&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Tools for tracking and managing agents in operations.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;3. Model Training &amp;amp; Data Generation&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Cookbook&lt;/th&gt; 
   &lt;th align="left"&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;&lt;a href="https://docs.camel-ai.org/cookbooks/data_generation/sft_data_generation_and_unsloth_finetuning_Qwen2_5_7B.html"&gt;Data Generation with CAMEL and Finetuning with Unsloth&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Learn how to generate data with CAMEL and fine-tune models effectively with Unsloth.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;&lt;a href="https://docs.camel-ai.org/cookbooks/data_generation/data_gen_with_real_function_calls_and_hermes_format.html"&gt;Data Gen with Real Function Calls and Hermes Format&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Explore how to generate data with real function calls and the Hermes format.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;&lt;a href="https://docs.camel-ai.org/cookbooks/data_generation/distill_math_reasoning_data_from_deepseek_r1.html"&gt;CoT Data Generation and Upload Data to Huggingface&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Uncover how to generate CoT data with CAMEL and seamlessly upload it to Huggingface.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;&lt;a href="https://docs.camel-ai.org/cookbooks/data_generation/cot_data_gen_sft_qwen_unsolth_upload_huggingface.html"&gt;CoT Data Generation and SFT Qwen with Unsolth&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Discover how to generate CoT data using CAMEL and SFT Qwen with Unsolth, and seamlessly upload your data and model to Huggingface.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;4. Multi-Agent Systems &amp;amp; Applications&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Cookbook&lt;/th&gt; 
   &lt;th align="left"&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;&lt;a href="https://docs.camel-ai.org/cookbooks/applications/roleplaying_scraper.html"&gt;Role-Playing Scraper for Report &amp;amp; Knowledge Graph Generation&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Create role-playing agents for data scraping and reporting.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;&lt;a href="https://docs.camel-ai.org/cookbooks/multi_agent_society/workforce_judge_committee.html"&gt;Create A Hackathon Judge Committee with Workforce&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Building a team of agents for collaborative judging.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;&lt;a href="https://docs.camel-ai.org/cookbooks/applications/dyamic_knowledge_graph.html"&gt;Dynamic Knowledge Graph Role-Playing: Multi-Agent System with dynamic, temporally-aware knowledge graphs&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Builds dynamic, temporally-aware knowledge graphs for financial applications using a multi-agent system. It processes financial reports, news articles, and research papers to help traders analyze data, identify relationships, and uncover market insights. The system also utilizes diverse and optional element node deduplication techniques to ensure data integrity and optimize graph structure for financial decision-making.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;&lt;a href="https://docs.camel-ai.org/cookbooks/applications/customer_service_Discord_bot_using_SambaNova_with_agentic_RAG.html"&gt;Customer Service Discord Bot with Agentic RAG&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Learn how to build a robust customer service bot for Discord using Agentic RAG.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;&lt;a href="https://docs.camel-ai.org/cookbooks/applications/customer_service_Discord_bot_using_local_model_with_agentic_RAG.html"&gt;Customer Service Discord Bot with Local Model&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Learn how to build a robust customer service bot for Discord using Agentic RAG which supports local deployment.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;5. Data Processing&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Cookbook&lt;/th&gt; 
   &lt;th align="left"&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;&lt;a href="https://docs.camel-ai.org/cookbooks/data_processing/video_analysis.html"&gt;Video Analysis&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Techniques for agents in video data analysis.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;&lt;a href="https://docs.camel-ai.org/cookbooks/data_processing/ingest_data_from_websites_with_Firecrawl.html"&gt;3 Ways to Ingest Data from Websites with Firecrawl&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Explore three methods for extracting and processing data from websites using Firecrawl.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;&lt;a href="https://docs.camel-ai.org/cookbooks/data_processing/agent_with_chunkr_for_pdf_parsing.html"&gt;Create AI Agents that work with your PDFs&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Learn how to create AI agents that work with your PDFs using Chunkr and Mistral AI.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;br&gt; 
&lt;h2&gt;Real-World Usecases&lt;/h2&gt; 
&lt;p&gt;Real-world usecases demonstrating how CAMEL’s multi-agent framework enables real business value across infrastructure automation, productivity workflows, retrieval-augmented conversations, intelligent document/video analysis, and collaborative research.&lt;/p&gt; 
&lt;h3&gt;1 Infrastructure Automation&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Usecase&lt;/th&gt; 
   &lt;th align="left"&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;&lt;a href="https://github.com/camel-ai/camel/tree/master/examples/usecases/aci_mcp"&gt;ACI MCP&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Real-world usecases demonstrating how CAMEL’s multi-agent framework enables real business value across infrastructure automation, productivity workflows, retrieval-augmented conversations, intelligent document/video analysis, and collaborative research.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;&lt;a href="https://github.com/camel-ai/camel/tree/master/examples/usecases/cloudfare_mcp_camel"&gt;Cloudflare MCP CAMEL&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Intelligent agents manage Cloudflare resources dynamically, enabling scalable and efficient cloud security and performance tuning.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;2 Productivity &amp;amp; Business Workflows&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Usecase&lt;/th&gt; 
   &lt;th align="left"&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;&lt;a href="https://github.com/camel-ai/camel/tree/master/examples/usecases/airbnb_mcp"&gt;Airbnb MCP&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Coordinate agents to optimize and manage Airbnb listings and host operations.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;&lt;a href="https://github.com/camel-ai/camel/tree/master/examples/usecases/pptx_toolkit_usecase"&gt;PPTX Toolkit Usecase&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Analyze PowerPoint documents and extract structured insights through multi-agent collaboration.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;3 Retrieval-Augmented Multi-Agent Chat&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Usecase&lt;/th&gt; 
   &lt;th align="left"&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;&lt;a href="https://github.com/camel-ai/camel/tree/master/examples/usecases/chat_with_github"&gt;Chat with GitHub&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Query and understand GitHub codebases through CAMEL agents leveraging RAG-style workflows, accelerating developer onboarding and codebase navigation.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;&lt;a href="https://github.com/camel-ai/camel/tree/master/examples/usecases/chat_with_youtube"&gt;Chat with YouTube&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Conversational agents extract and summarize video transcripts, enabling faster content understanding and repurposing.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;4 Video &amp;amp; Document Intelligence&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Usecase&lt;/th&gt; 
   &lt;th align="left"&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;&lt;a href="https://github.com/camel-ai/camel/tree/master/examples/usecases/youtube_ocr"&gt;YouTube OCR&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Agents perform OCR on video screenshots to summarize visual content, supporting media monitoring and compliance.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;&lt;a href="https://github.com/camel-ai/camel/tree/master/examples/usecases/mistral_OCR"&gt;Mistral OCR&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;CAMEL agents use OCR with Mistral to analyze documents, reducing manual effort in document understanding workflows.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;5 Research &amp;amp; Collaboration&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Usecase&lt;/th&gt; 
   &lt;th align="left"&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;&lt;a href="https://github.com/camel-ai/camel/tree/master/examples/usecases/multi_agent_research_assistant"&gt;Multi-Agent Research Assistant&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Simulates a team of research agents collaborating on literature review, improving efficiency in exploratory analysis and reporting.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;br&gt; 
&lt;h2&gt;🗓️ Events&lt;/h2&gt; 
&lt;p&gt;We are actively involved in community events including:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;🎙️ &lt;strong&gt;Community Meetings&lt;/strong&gt; — Weekly virtual syncs with the CAMEL team&lt;/li&gt; 
 &lt;li&gt;🏆 &lt;strong&gt;Competitions&lt;/strong&gt; — Hackathons, Bounty Tasks and coding challenges hosted by CAMEL&lt;/li&gt; 
 &lt;li&gt;🤝 &lt;strong&gt;Volunteer Activities&lt;/strong&gt; — Contributions, documentation drives, and mentorship&lt;/li&gt; 
 &lt;li&gt;🌍 &lt;strong&gt;Ambassador Programs&lt;/strong&gt; — Represent CAMEL in your university or local tech groups&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Want to host or participate in a CAMEL event? Join our &lt;a href="https://discord.com/invite/CNcNpquyDc"&gt;Discord&lt;/a&gt; or want to be part of &lt;a href="https://www.camel-ai.org/ambassador"&gt;Ambassador Program&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Contributing to CAMEL&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;For those who'd like to contribute code, we appreciate your interest in contributing to our open-source initiative. Please take a moment to review our &lt;a href="https://github.com/camel-ai/camel/raw/master/CONTRIBUTING.md"&gt;contributing guidelines&lt;/a&gt; to get started on a smooth collaboration journey.🚀&lt;/p&gt; 
 &lt;p&gt;We also welcome you to help CAMEL grow by sharing it on social media, at events, or during conferences. Your support makes a big difference!&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;br&gt; 
&lt;h2&gt;Community &amp;amp; Contact&lt;/h2&gt; 
&lt;p&gt;For more information please contact &lt;a href="mailto:camel-ai@eigent.ai"&gt;camel-ai@eigent.ai&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;GitHub Issues:&lt;/strong&gt; Report bugs, request features, and track development. &lt;a href="https://github.com/camel-ai/camel/issues"&gt;Submit an issue&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Discord:&lt;/strong&gt; Get real-time support, chat with the community, and stay updated. &lt;a href="https://discord.camel-ai.org/"&gt;Join us&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;X (Twitter):&lt;/strong&gt; Follow for updates, AI insights, and key announcements. &lt;a href="https://x.com/CamelAIOrg"&gt;Follow us&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Ambassador Project:&lt;/strong&gt; Advocate for CAMEL-AI, host events, and contribute content. &lt;a href="https://www.camel-ai.org/community"&gt;Learn more&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;WeChat Community:&lt;/strong&gt; Scan the QR code below to join our WeChat community.&lt;/p&gt; 
  &lt;div align="center"&gt; 
   &lt;img src="https://raw.githubusercontent.com/camel-ai/camel/master/misc/wechat.jpeg" alt="WeChat QR Code" width="200"&gt; 
  &lt;/div&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;br&gt; 
&lt;h2&gt;Citation&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;@inproceedings{li2023camel,
  title={CAMEL: Communicative Agents for "Mind" Exploration of Large Language Model Society},
  author={Li, Guohao and Hammoud, Hasan Abed Al Kader and Itani, Hani and Khizbullin, Dmitrii and Ghanem, Bernard},
  booktitle={Thirty-seventh Conference on Neural Information Processing Systems},
  year={2023}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Acknowledgment&lt;/h2&gt; 
&lt;p&gt;Special thanks to &lt;a href="https://home.nomic.ai/"&gt;Nomic AI&lt;/a&gt; for giving us extended access to their data set exploration tool (Atlas).&lt;/p&gt; 
&lt;p&gt;We would also like to thank Haya Hammoud for designing the initial logo of our project.&lt;/p&gt; 
&lt;p&gt;We implemented amazing research ideas from other works for you to build, compare and customize your agents. If you use any of these modules, please kindly cite the original works:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;TaskCreationAgent&lt;/code&gt;, &lt;code&gt;TaskPrioritizationAgent&lt;/code&gt; and &lt;code&gt;BabyAGI&lt;/code&gt; from &lt;em&gt;Nakajima et al.&lt;/em&gt;: &lt;a href="https://yoheinakajima.com/task-driven-autonomous-agent-utilizing-gpt-4-pinecone-and-langchain-for-diverse-applications/"&gt;Task-Driven Autonomous Agent&lt;/a&gt;. [&lt;a href="https://github.com/camel-ai/camel/raw/master/examples/ai_society/babyagi_playing.py"&gt;Example&lt;/a&gt;]&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;PersonaHub&lt;/code&gt; from &lt;em&gt;Tao Ge et al.&lt;/em&gt;: &lt;a href="https://arxiv.org/pdf/2406.20094"&gt;Scaling Synthetic Data Creation with 1,000,000,000 Personas&lt;/a&gt;. [&lt;a href="https://github.com/camel-ai/camel/raw/master/examples/personas/personas_generation.py"&gt;Example&lt;/a&gt;]&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;Self-Instruct&lt;/code&gt; from &lt;em&gt;Yizhong Wang et al.&lt;/em&gt;: &lt;a href="https://arxiv.org/pdf/2212.10560"&gt;SELF-INSTRUCT: Aligning Language Models with Self-Generated Instructions&lt;/a&gt;. [&lt;a href="https://github.com/camel-ai/camel/raw/master/examples/datagen/self_instruct/self_instruct.py"&gt;Example&lt;/a&gt;]&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;The source code is licensed under Apache 2.0.&lt;/p&gt; 
&lt;br&gt;</description>
    </item>
    
    <item>
      <title>Pythagora-io/gpt-pilot</title>
      <link>https://github.com/Pythagora-io/gpt-pilot</link>
      <description>&lt;p&gt;The first real AI developer&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;h1&gt;🧑‍✈️ GPT PILOT 🧑‍✈️&lt;/h1&gt; 
&lt;/div&gt; 
&lt;hr&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://discord.gg/HaqXugmxr9"&gt;&lt;img src="https://dcbadge.vercel.app/api/server/HaqXugmxr9?style=flat" alt="Discord Follow"&gt;&lt;/a&gt; &lt;a href="https://github.com/Pythagora-io/gpt-pilot"&gt;&lt;img src="https://img.shields.io/github/stars/Pythagora-io/gpt-pilot?style=social" alt="GitHub Repo stars"&gt;&lt;/a&gt; &lt;a href="https://twitter.com/HiPythagora"&gt;&lt;img src="https://img.shields.io/twitter/follow/HiPythagora?style=social" alt="Twitter Follow"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;hr&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://www.ycombinator.com/" target="_blank"&gt;&lt;img src="https://s3.amazonaws.com/assets.pythagora.ai/yc/PNG/Black.png" alt="Pythagora-io%2Fgpt-pilot | Trendshift" style="width: 250px; height: 93px;"&gt;&lt;/a&gt; 
&lt;/div&gt; 
&lt;br&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://trendshift.io/repositories/466" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/466" alt="Pythagora-io%2Fgpt-pilot | Trendshift" style="width: 250px; height: 55px;" width="250" height="55"&gt;&lt;/a&gt; 
&lt;/div&gt; 
&lt;br&gt; 
&lt;br&gt; 
&lt;div align="center"&gt; 
 &lt;h3&gt;GPT Pilot doesn't just generate code, it builds apps!&lt;/h3&gt; 
&lt;/div&gt; 
&lt;hr&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://youtu.be/4g-1cPGK0GA"&gt;&lt;img src="https://i3.ytimg.com/vi/4g-1cPGK0GA/maxresdefault.jpg" alt="See it in action"&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;(click to open the video in YouTube) (1:40min)&lt;/p&gt; 
&lt;/div&gt; 
&lt;hr&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="vscode:extension/PythagoraTechnologies.gpt-pilot-vs-code" target="_blank"&gt;&lt;img src="https://github.com/Pythagora-io/gpt-pilot/assets/10895136/5792143e-77c7-47dd-ad96-6902be1501cd" alt="Pythagora-io%2Fgpt-pilot | Trendshift" style="width: 185px; height: 55px;" width="185" height="55"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;GPT Pilot is the core technology for the &lt;a href="https://marketplace.visualstudio.com/items?itemName=PythagoraTechnologies.pythagora-vs-code"&gt;Pythagora VS Code extension&lt;/a&gt; that aims to provide &lt;strong&gt;the first real AI developer companion&lt;/strong&gt;. Not just an autocomplete or a helper for PR messages but rather a real AI developer that can write full features, debug them, talk to you about issues, ask for review, etc.&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;📫 If you would like to get updates on future releases or just get in touch, join our &lt;a href="https://discord.gg/HaqXugmxr9"&gt;Discord server&lt;/a&gt; or you &lt;a href="http://eepurl.com/iD6Mpo"&gt;can add your email here&lt;/a&gt;. 📬&lt;/p&gt; 
&lt;hr&gt; 
&lt;!-- TOC --&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Pythagora-io/gpt-pilot/main/#-requirements"&gt;🔌 Requirements&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Pythagora-io/gpt-pilot/main/#how-to-start-using-gpt-pilot"&gt;🚦How to start using gpt-pilot?&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Pythagora-io/gpt-pilot/main/#-examples"&gt;🔎 Examples&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Pythagora-io/gpt-pilot/main/#-how-to-start-gpt-pilot-in-docker"&gt;🐳 How to start gpt-pilot in docker?&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Pythagora-io/gpt-pilot/main/#-cli-arguments"&gt;🧑‍💻️ CLI arguments&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Pythagora-io/gpt-pilot/main/#-how-gpt-pilot-works"&gt;🏗 How GPT Pilot works?&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Pythagora-io/gpt-pilot/main/#hows-gpt-pilot-different-from-smol-developer-and-gpt-engineer"&gt;🕴How's GPT Pilot different from &lt;em&gt;Smol developer&lt;/em&gt; and &lt;em&gt;GPT engineer&lt;/em&gt;?&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Pythagora-io/gpt-pilot/main/#-contributing"&gt;🍻 Contributing&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Pythagora-io/gpt-pilot/main/#-connect-with-us"&gt;🔗 Connect with us&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Pythagora-io/gpt-pilot/main/#-star-history"&gt;🌟 Star history&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;!-- TOC --&gt; 
&lt;hr&gt; 
&lt;p&gt;GPT Pilot aims to research how much LLMs can be utilized to generate fully working, production-ready apps while the developer oversees the implementation.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;The main idea is that AI can write most of the code for an app (maybe 95%), but for the rest, 5%, a developer is and will be needed until we get full AGI&lt;/strong&gt;.&lt;/p&gt; 
&lt;p&gt;If you are interested in our learnings during this project, you can check &lt;a href="https://blog.pythagora.ai/2024/02/19/gpt-pilot-what-did-we-learn-in-6-months-of-working-on-a-codegen-pair-programmer/"&gt;our latest blog posts&lt;/a&gt;.&lt;/p&gt; 
&lt;hr&gt; 
&lt;br&gt; 
&lt;div align="center"&gt; 
 &lt;h3&gt;&lt;strong&gt;&lt;a href="https://github.com/Pythagora-io/gpt-pilot/wiki/Apps-created-with-GPT-Pilot"&gt;👉 Examples of apps written by GPT Pilot 👈&lt;/a&gt;&lt;/strong&gt;&lt;/h3&gt; 
&lt;/div&gt; 
&lt;br&gt; 
&lt;hr&gt; 
&lt;h1&gt;🔌 Requirements&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Python 3.9+&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;🚦How to start using gpt-pilot?&lt;/h1&gt; 
&lt;p&gt;👉 If you are using VS Code as your IDE, the easiest way to start is by downloading &lt;a href="https://marketplace.visualstudio.com/items?itemName=PythagoraTechnologies.pythagora-vs-code"&gt;GPT Pilot VS Code extension&lt;/a&gt;. 👈&lt;/p&gt; 
&lt;p&gt;Otherwise, you can use the CLI tool.&lt;/p&gt; 
&lt;h3&gt;If you're new to GPT Pilot:&lt;/h3&gt; 
&lt;p&gt;After you have Python and (optionally) PostgreSQL installed, follow these steps:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;code&gt;git clone https://github.com/Pythagora-io/gpt-pilot.git&lt;/code&gt; (clone the repo)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;cd gpt-pilot&lt;/code&gt; (go to the repo folder)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;python3 -m venv venv&lt;/code&gt; (create a virtual environment)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;source venv/bin/activate&lt;/code&gt; (or on Windows &lt;code&gt;venv\Scripts\activate&lt;/code&gt;) (activate the virtual environment)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;pip install -r requirements.txt&lt;/code&gt; (install the dependencies)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;cp example-config.json config.json&lt;/code&gt; (create &lt;code&gt;config.json&lt;/code&gt; file)&lt;/li&gt; 
 &lt;li&gt;Set your key and other settings in &lt;code&gt;config.json&lt;/code&gt; file: 
  &lt;ul&gt; 
   &lt;li&gt;LLM Provider (&lt;code&gt;openai&lt;/code&gt;, &lt;code&gt;anthropic&lt;/code&gt; or &lt;code&gt;groq&lt;/code&gt;) key and endpoints (leave &lt;code&gt;null&lt;/code&gt; for default) (note that Azure and OpenRouter are suppored via the &lt;code&gt;openai&lt;/code&gt; setting)&lt;/li&gt; 
   &lt;li&gt;Your API key (if &lt;code&gt;null&lt;/code&gt;, will be read from the environment variables)&lt;/li&gt; 
   &lt;li&gt;database settings: sqlite is used by default, PostgreSQL should also work&lt;/li&gt; 
   &lt;li&gt;optionally update &lt;code&gt;fs.ignore_paths&lt;/code&gt; and add files or folders which shouldn't be tracked by GPT Pilot in workspace, useful to ignore folders created by compilers&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;python main.py&lt;/code&gt; (start GPT Pilot)&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;All generated code will be stored in the folder &lt;code&gt;workspace&lt;/code&gt; inside the folder named after the app name you enter upon starting the pilot.&lt;/p&gt; 
&lt;h1&gt;🔎 &lt;a href="https://github.com/Pythagora-io/gpt-pilot/wiki/Pythagora-App-Lab"&gt;Examples&lt;/a&gt;&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://github.com/Pythagora-io/gpt-pilot/wiki/Pythagora-App-Lab"&gt;Click here&lt;/a&gt; to see examples of apps created with Pythagora.&lt;/p&gt; 
&lt;h3&gt;PostgreSQL support&lt;/h3&gt; 
&lt;p&gt;GPT Pilot uses built-in SQLite database by default. If you want to use the PostgreSQL database, you need to additional install &lt;code&gt;asyncpg&lt;/code&gt; and &lt;code&gt;psycopg2&lt;/code&gt; packages:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install asyncpg psycopg2
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then, you need to update the &lt;code&gt;config.json&lt;/code&gt; file to set &lt;code&gt;db.url&lt;/code&gt; to &lt;code&gt;postgresql+asyncpg://&amp;lt;user&amp;gt;:&amp;lt;password&amp;gt;@&amp;lt;db-host&amp;gt;/&amp;lt;db-name&amp;gt;&lt;/code&gt;.&lt;/p&gt; 
&lt;h1&gt;🧑‍💻️ CLI arguments&lt;/h1&gt; 
&lt;h3&gt;List created projects (apps)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python main.py --list
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Note: for each project (app), this also lists "branches". Currently we only support having one branch (called "main"), and in the future we plan to add support for multiple project branches.&lt;/p&gt; 
&lt;h3&gt;Load and continue from the latest step in a project (app)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python main.py --project &amp;lt;app_id&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Load and continue from a specific step in a project (app)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python main.py --project &amp;lt;app_id&amp;gt; --step &amp;lt;step&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Warning: this will delete all progress after the specified step!&lt;/p&gt; 
&lt;h3&gt;Delete project (app)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python main.py --delete &amp;lt;app_id&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Delete project with the specified &lt;code&gt;app_id&lt;/code&gt;. Warning: this cannot be undone!&lt;/p&gt; 
&lt;h3&gt;Other command-line options&lt;/h3&gt; 
&lt;p&gt;There are several other command-line options that mostly support calling GPT Pilot from our VSCode extension. To see all the available options, use the &lt;code&gt;--help&lt;/code&gt; flag:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python main.py --help
&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;🏗 How GPT Pilot works?&lt;/h1&gt; 
&lt;p&gt;Here are the steps GPT Pilot takes to create an app:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;You enter the app name and the description.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Product Owner agent&lt;/strong&gt; like in real life, does nothing. :)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Specification Writer agent&lt;/strong&gt; asks a couple of questions to understand the requirements better if project description is not good enough.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Architect agent&lt;/strong&gt; writes up technologies that will be used for the app and checks if all technologies are installed on the machine and installs them if not.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Tech Lead agent&lt;/strong&gt; writes up development tasks that the Developer must implement.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Developer agent&lt;/strong&gt; takes each task and writes up what needs to be done to implement it. The description is in human-readable form.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Code Monkey agent&lt;/strong&gt; takes the Developer's description and the existing file and implements the changes.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Reviewer agent&lt;/strong&gt; reviews every step of the task and if something is done wrong Reviewer sends it back to Code Monkey.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Troubleshooter agent&lt;/strong&gt; helps you to give good feedback to GPT Pilot when something is wrong.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Debugger agent&lt;/strong&gt; hate to see him, but he is your best friend when things go south.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Technical Writer agent&lt;/strong&gt; writes documentation for the project.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;br&gt; 
&lt;h1&gt;🕴How's GPT Pilot different from &lt;em&gt;Smol developer&lt;/em&gt; and &lt;em&gt;GPT engineer&lt;/em&gt;?&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;GPT Pilot works with the developer to create a fully working production-ready app&lt;/strong&gt; - I don't think AI can (at least in the near future) create apps without a developer being involved. So, &lt;strong&gt;GPT Pilot codes the app step by step&lt;/strong&gt; just like a developer would in real life. This way, it can debug issues as they arise throughout the development process. If it gets stuck, you, the developer in charge, can review the code and fix the issue. Other similar tools give you the entire codebase at once - this way, bugs are much harder to fix for AI and for you as a developer. &lt;br&gt;&lt;br&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Works at scale&lt;/strong&gt; - GPT Pilot isn't meant to create simple apps but rather so it can work at any scale. It has mechanisms that filter out the code, so in each LLM conversation, it doesn't need to store the entire codebase in context, but it shows the LLM only the relevant code for the current task it's working on. Once an app is finished, you can continue working on it by writing instructions on what feature you want to add.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;🍻 Contributing&lt;/h1&gt; 
&lt;p&gt;If you are interested in contributing to GPT Pilot, join &lt;a href="https://discord.gg/HaqXugmxr9"&gt;our Discord server&lt;/a&gt;, check out open &lt;a href="https://github.com/Pythagora-io/gpt-pilot/issues"&gt;GitHub issues&lt;/a&gt;, and see if anything interests you. We would be happy to get help in resolving any of those. The best place to start is by reviewing blog posts mentioned above to understand how the architecture works before diving into the codebase.&lt;/p&gt; 
&lt;h2&gt;🖥 Development&lt;/h2&gt; 
&lt;p&gt;Other than the research, GPT Pilot needs to be debugged to work in different scenarios. For example, we realized that the quality of the code generated is very sensitive to the size of the development task. When the task is too broad, the code has too many bugs that are hard to fix, but when the development task is too narrow, GPT also seems to struggle in getting the task implemented into the existing code.&lt;/p&gt; 
&lt;h2&gt;📊 Telemetry&lt;/h2&gt; 
&lt;p&gt;To improve GPT Pilot, we are tracking some events from which you can opt out at any time. You can read more about it &lt;a href="https://raw.githubusercontent.com/Pythagora-io/gpt-pilot/main/docs/TELEMETRY.md"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;🔗 Connect with us&lt;/h1&gt; 
&lt;p&gt;🌟 &lt;strong&gt;If you find GPT Pilot useful, please consider &lt;a href="https://github.com/Pythagora-io/gpt-pilot"&gt;starring the repo&lt;/a&gt;!&lt;/strong&gt; It helps us grow and continue improving the project. 🌟&lt;/p&gt; 
&lt;p&gt;💬 &lt;strong&gt;Need help or have questions?&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Join our &lt;a href="https://discord.gg/HaqXugmxr9"&gt;Discord community&lt;/a&gt; to connect with other users and our team.&lt;/li&gt; 
 &lt;li&gt;Visit our &lt;a href="https://github.com/Pythagora-io/gpt-pilot/wiki/Contact-Us"&gt;Contact Us&lt;/a&gt; page for additional support.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;📖 &lt;strong&gt;Learn more about Pythagora &amp;amp; GPT Pilot:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Explore our &lt;a href="https://github.com/Pythagora-io/gpt-pilot/wiki"&gt;Wiki&lt;/a&gt; for in-depth documentation.&lt;/li&gt; 
 &lt;li&gt;Check out our &lt;a href="https://github.com/Pythagora-io/gpt-pilot/wiki/Frequently-Asked-Questions"&gt;FAQ&lt;/a&gt; for common questions and troubleshooting tips.&lt;/li&gt; 
 &lt;li&gt;Visit our &lt;a href="https://www.youtube.com/@pythagoraa"&gt;YouTube&lt;/a&gt; channel for demos and how-to videos.&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>tinygrad/tinygrad</title>
      <link>https://github.com/tinygrad/tinygrad</link>
      <description>&lt;p&gt;You like pytorch? You like micrograd? You love tinygrad! ❤️&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="/docs/logo_tiny_light.svg"&gt; 
  &lt;img alt="tiny corp logo" src="https://raw.githubusercontent.com/tinygrad/tinygrad/master/docs/logo_tiny_dark.svg?sanitize=true" width="50%" height="50%"&gt; 
 &lt;/picture&gt; 
 &lt;p&gt;tinygrad: For something between &lt;a href="https://github.com/pytorch/pytorch"&gt;PyTorch&lt;/a&gt; and &lt;a href="https://github.com/karpathy/micrograd"&gt;karpathy/micrograd&lt;/a&gt;. Maintained by &lt;a href="https://tinygrad.org"&gt;tiny corp&lt;/a&gt;.&lt;/p&gt; 
 &lt;h3&gt; &lt;p&gt;&lt;a href="https://github.com/tinygrad/tinygrad"&gt;Homepage&lt;/a&gt; | &lt;a href="https://docs.tinygrad.org/"&gt;Documentation&lt;/a&gt; | &lt;a href="https://discord.gg/ZjZadyC7PK"&gt;Discord&lt;/a&gt;&lt;/p&gt; &lt;/h3&gt; 
 &lt;p&gt;&lt;a href="https://github.com/tinygrad/tinygrad/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/tinygrad/tinygrad" alt="GitHub Repo stars"&gt;&lt;/a&gt; &lt;a href="https://github.com/tinygrad/tinygrad/actions/workflows/test.yml"&gt;&lt;img src="https://github.com/tinygrad/tinygrad/actions/workflows/test.yml/badge.svg?sanitize=true" alt="Unit Tests"&gt;&lt;/a&gt; &lt;a href="https://discord.gg/ZjZadyC7PK"&gt;&lt;img src="https://img.shields.io/discord/1068976834382925865" alt="Discord"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;hr&gt; 
&lt;p&gt;Despite tinygrad's size, it is a fully featured deep learning framework.&lt;/p&gt; 
&lt;p&gt;Due to its extreme simplicity, it is the easiest framework to add new accelerators to, with support for both inference and training. If XLA is CISC, tinygrad is RISC.&lt;/p&gt; 
&lt;p&gt;tinygrad is now beta software, we &lt;a href="https://geohot.github.io/blog/jekyll/update/2023/05/24/the-tiny-corp-raised-5M.html"&gt;raised some money&lt;/a&gt; to make it good. Someday, we will tape out chips.&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;h3&gt;LLaMA and Stable Diffusion&lt;/h3&gt; 
&lt;p&gt;tinygrad can run &lt;a href="https://raw.githubusercontent.com/tinygrad/tinygrad/master/docs/showcase.md#llama"&gt;LLaMA&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/tinygrad/tinygrad/master/docs/showcase.md#stable-diffusion"&gt;Stable Diffusion&lt;/a&gt;!&lt;/p&gt; 
&lt;h3&gt;Laziness&lt;/h3&gt; 
&lt;p&gt;Try a matmul. See how, despite the style, it is fused into one kernel with the power of laziness.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;DEBUG=3 python3 -c "from tinygrad import Tensor;
N = 1024; a, b = Tensor.empty(N, N), Tensor.empty(N, N);
(a.reshape(N, 1, N) * b.T.reshape(1, N, N)).sum(axis=2).realize()"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;And we can change &lt;code&gt;DEBUG&lt;/code&gt; to &lt;code&gt;4&lt;/code&gt; to see the generated code.&lt;/p&gt; 
&lt;h3&gt;Neural networks&lt;/h3&gt; 
&lt;p&gt;As it turns out, 90% of what you need for neural networks are a decent autograd/tensor library. Throw in an optimizer, a data loader, and some compute, and you have all you need.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from tinygrad import Tensor, nn

class LinearNet:
  def __init__(self):
    self.l1 = Tensor.kaiming_uniform(784, 128)
    self.l2 = Tensor.kaiming_uniform(128, 10)
  def __call__(self, x:Tensor) -&amp;gt; Tensor:
    return x.flatten(1).dot(self.l1).relu().dot(self.l2)

model = LinearNet()
optim = nn.optim.Adam([model.l1, model.l2], lr=0.001)

x, y = Tensor.rand(4, 1, 28, 28), Tensor([2,4,3,7])  # replace with real mnist dataloader

with Tensor.train():
  for i in range(10):
    optim.zero_grad()
    loss = model(x).sparse_categorical_crossentropy(y).backward()
    optim.step()
    print(i, loss.item())
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/tinygrad/tinygrad/master/examples/beautiful_mnist.py"&gt;examples/beautiful_mnist.py&lt;/a&gt; for the full version that gets 98% in ~5 seconds&lt;/p&gt; 
&lt;h2&gt;Accelerators&lt;/h2&gt; 
&lt;p&gt;tinygrad already supports numerous accelerators, including:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/tinygrad/tinygrad/master/tinygrad/runtime/ops_gpu.py"&gt;GPU (OpenCL)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/tinygrad/tinygrad/master/tinygrad/runtime/ops_cpu.py"&gt;CPU (C Code)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/tinygrad/tinygrad/master/tinygrad/runtime/ops_llvm.py"&gt;LLVM&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/tinygrad/tinygrad/master/tinygrad/runtime/ops_metal.py"&gt;METAL&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/tinygrad/tinygrad/master/tinygrad/runtime/ops_cuda.py"&gt;CUDA&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/tinygrad/tinygrad/master/tinygrad/runtime/ops_amd.py"&gt;AMD&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/tinygrad/tinygrad/master/tinygrad/runtime/ops_nv.py"&gt;NV&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/tinygrad/tinygrad/master/tinygrad/runtime/ops_qcom.py"&gt;QCOM&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/tinygrad/tinygrad/master/tinygrad/runtime/ops_webgpu.py"&gt;WEBGPU&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;And it is easy to add more! Your accelerator of choice only needs to support a total of ~25 low level ops.&lt;/p&gt; 
&lt;p&gt;To check default accelerator run: &lt;code&gt;python3 -c "from tinygrad import Device; print(Device.DEFAULT)"&lt;/code&gt;&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;The current recommended way to install tinygrad is from source.&lt;/p&gt; 
&lt;h3&gt;From source&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;git clone https://github.com/tinygrad/tinygrad.git
cd tinygrad
python3 -m pip install -e .
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Direct (master)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;python3 -m pip install git+https://github.com/tinygrad/tinygrad.git
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;Documentation along with a quick start guide can be found on the &lt;a href="https://docs.tinygrad.org/"&gt;docs website&lt;/a&gt; built from the &lt;a href="https://raw.githubusercontent.com/tinygrad/tinygrad/master/docs"&gt;docs/&lt;/a&gt; directory.&lt;/p&gt; 
&lt;h3&gt;Quick example comparing to PyTorch&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from tinygrad import Tensor

x = Tensor.eye(3, requires_grad=True)
y = Tensor([[2.0,0,-2.0]], requires_grad=True)
z = y.matmul(x).sum()
z.backward()

print(x.grad.tolist())  # dz/dx
print(y.grad.tolist())  # dz/dy
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The same thing but in PyTorch:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import torch

x = torch.eye(3, requires_grad=True)
y = torch.tensor([[2.0,0,-2.0]], requires_grad=True)
z = y.matmul(x).sum()
z.backward()

print(x.grad.tolist())  # dz/dx
print(y.grad.tolist())  # dz/dy
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;There has been a lot of interest in tinygrad lately. Following these guidelines will help your PR get accepted.&lt;/p&gt; 
&lt;p&gt;We'll start with what will get your PR closed with a pointer to this section:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;No code golf! While low line count is a guiding light of this project, anything that remotely looks like code golf will be closed. The true goal is reducing complexity and increasing readability, and deleting &lt;code&gt;\n&lt;/code&gt;s does nothing to help with that.&lt;/li&gt; 
 &lt;li&gt;All docs and whitespace changes will be closed unless you are a well-known contributor. The people writing the docs should be those who know the codebase the absolute best. People who have not demonstrated that shouldn't be messing with docs. Whitespace changes are both useless &lt;em&gt;and&lt;/em&gt; carry a risk of introducing bugs.&lt;/li&gt; 
 &lt;li&gt;Anything you claim is a "speedup" must be benchmarked. In general, the goal is simplicity, so even if your PR makes things marginally faster, you have to consider the tradeoff with maintainability and readability.&lt;/li&gt; 
 &lt;li&gt;In general, the code outside the core &lt;code&gt;tinygrad/&lt;/code&gt; folder is not well tested, so unless the current code there is broken, you shouldn't be changing it.&lt;/li&gt; 
 &lt;li&gt;If your PR looks "complex", is a big diff, or adds lots of lines, it won't be reviewed or merged. Consider breaking it up into smaller PRs that are individually clear wins. A common pattern I see is prerequisite refactors before adding new functionality. If you can (cleanly) refactor to the point that the feature is a 3 line change, this is great, and something easy for us to review.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Now, what we want:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Bug fixes (with a regression test) are great! This library isn't 1.0 yet, so if you stumble upon a bug, fix it, write a test, and submit a PR, this is valuable work.&lt;/li&gt; 
 &lt;li&gt;Solving bounties! tinygrad &lt;a href="https://docs.google.com/spreadsheets/d/1WKHbT-7KOgjEawq5h5Ic1qUWzpfAzuD_J06N1JwOCGs/edit?usp=sharing"&gt;offers cash bounties&lt;/a&gt; for certain improvements to the library. All new code should be high quality and well tested.&lt;/li&gt; 
 &lt;li&gt;Features. However, if you are adding a feature, consider the line tradeoff. If it's 3 lines, there's less of a bar of usefulness it has to meet over something that's 30 or 300 lines. All features must have regression tests. In general with no other constraints, your feature's API should match torch or numpy.&lt;/li&gt; 
 &lt;li&gt;Refactors that are clear wins. In general, if your refactor isn't a clear win it will be closed. But some refactors are amazing! Think about readability in a deep core sense. A whitespace change or moving a few functions around is useless, but if you realize that two 100 line functions can actually use the same 110 line function with arguments while also improving readability, this is a big win. Refactors should pass &lt;a href="https://raw.githubusercontent.com/tinygrad/tinygrad/master/#process-replay-tests"&gt;process replay&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Tests/fuzzers. If you can add tests that are non brittle, they are welcome. We have some fuzzers in here too, and there's a plethora of bugs that can be found with them and by improving them. Finding bugs, even writing broken tests (that should pass) with &lt;code&gt;@unittest.expectedFailure&lt;/code&gt; is great. This is how we make progress.&lt;/li&gt; 
 &lt;li&gt;Dead code removal from core &lt;code&gt;tinygrad/&lt;/code&gt; folder. We don't care about the code in extra, but removing dead code from the core library is great. Less for new people to read and be confused by.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Running tests&lt;/h3&gt; 
&lt;p&gt;You should install the pre-commit hooks with &lt;code&gt;pre-commit install&lt;/code&gt;. This will run the linter, mypy, and a subset of the tests on every commit.&lt;/p&gt; 
&lt;p&gt;For more examples on how to run the full test suite please refer to the &lt;a href="https://raw.githubusercontent.com/tinygrad/tinygrad/master/.github/workflows/test.yml"&gt;CI workflow&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Some examples of running tests locally:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;python3 -m pip install -e '.[testing]'  # install extra deps for testing
python3 test/test_ops.py                # just the ops tests
python3 -m pytest test/                 # whole test suite
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Process replay tests&lt;/h4&gt; 
&lt;p&gt;&lt;a href="https://github.com/tinygrad/tinygrad/raw/master/test/external/process_replay/README.md"&gt;Process replay&lt;/a&gt; compares your PR's generated kernels against master. If your PR is a refactor or speedup without any expected behavior change, It should include [pr] in the pull request title.&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>