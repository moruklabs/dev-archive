<rss version="2.0">
  <channel>
    <title>GitHub Python Weekly Trending</title>
    <description>Weekly Trending of Python in GitHub</description>
    <pubDate>Fri, 29 Aug 2025 01:47:23 GMT</pubDate>
    <link>http://mshibanami.github.io/GitHubTrendingRSS</link>
    
    <item>
      <title>HKUDS/DeepCode</title>
      <link>https://github.com/HKUDS/DeepCode</link>
      <description>&lt;p&gt;"DeepCode: Open Agentic Coding (Paper2Code &amp; Text2Web &amp; Text2Backend)"&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;table style="border: none; margin: 0 auto; padding: 0; border-collapse: collapse;"&gt; 
  &lt;tbody&gt;
   &lt;tr&gt; 
    &lt;td align="center" style="vertical-align: middle; padding: 10px; border: none; width: 250px;"&gt; &lt;img src="https://raw.githubusercontent.com/HKUDS/DeepCode/main/assets/logo.png" alt="DeepCode Logo" width="200" style="margin: 0; padding: 0; display: block;" /&gt; &lt;/td&gt; 
    &lt;td align="left" style="vertical-align: middle; padding: 10px 0 10px 30px; border: none;"&gt; &lt;pre style="font-family: 'Courier New', monospace; font-size: 16px; color: #0EA5E9; margin: 0; padding: 0; text-shadow: 0 0 10px #0EA5E9, 0 0 20px rgba(14,165,233,0.5); line-height: 1.2; transform: skew(-1deg, 0deg); display: block;"&gt;    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—
    â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â•â•â•
    â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—
    â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•  â–ˆâ–ˆâ•”â•â•â•  â–ˆâ–ˆâ•”â•â•â•â• â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•
    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘     â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—
    â•šâ•â•â•â•â•â• â•šâ•â•â•â•â•â•â•â•šâ•â•â•â•â•â•â•â•šâ•â•      â•šâ•â•â•â•â•â• â•šâ•â•â•â•â•â• â•šâ•â•â•â•â•â• â•šâ•â•â•â•â•â•â•&lt;/pre&gt; &lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt;
 &lt;/table&gt; 
 &lt;div align="center"&gt; 
  &lt;a href="https://trendshift.io/repositories/14665" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/14665" alt="HKUDS%2FDeepCode | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt; 
 &lt;/div&gt; 
 &lt;!-- &lt;img src="https://readme-typing-svg.herokuapp.com?font=Russo+One&amp;size=28&amp;duration=2000&amp;pause=800&amp;color=06B6D4&amp;background=00000000&amp;center=true&amp;vCenter=true&amp;width=800&amp;height=50&amp;lines=%E2%9A%A1+OPEN+AGENTIC+CODING+%E2%9A%A1" alt="DeepCode Tech Subtitle" style="margin-top: 5px; filter: drop-shadow(0 0 12px #06B6D4) drop-shadow(0 0 24px rgba(6,182,212,0.4));"/&gt; --&gt; 
 &lt;h1&gt;&lt;img src="https://github.com/Zongwei9888/Experiment_Images/raw/43c585dca3d21b8e4b6390d835cdd34dc4b4b23d/DeepCode_images/title_logo.svg?sanitize=true" alt="DeepCode Logo" width="32" height="32" style="vertical-align: middle; margin-right: 8px;" /&gt; DeepCode: Open Agentic Coding&lt;/h1&gt; 
 &lt;h3&gt;&lt;em&gt;Advancing Code Generation with Multi-Agent Systems&lt;/em&gt;&lt;/h3&gt; 
 &lt;!-- &lt;p align="center"&gt;
  &lt;img src="https://img.shields.io/badge/Version-1.0.0-00d4ff?style=for-the-badge&amp;logo=rocket&amp;logoColor=white" alt="Version"&gt;

  &lt;img src="https://img.shields.io/badge/License-MIT-4ecdc4?style=for-the-badge&amp;logo=opensourceinitiative&amp;logoColor=white" alt="License"&gt;
  &lt;img src="https://img.shields.io/badge/AI-Multi--Agent-9b59b6?style=for-the-badge&amp;logo=brain&amp;logoColor=white" alt="AI"&gt;
  &lt;img src="https://img.shields.io/badge/HKU-Data_Intelligence_Lab-f39c12?style=for-the-badge&amp;logo=university&amp;logoColor=white" alt="HKU"&gt;
&lt;/p&gt; --&gt; 
 &lt;p&gt; &lt;a href="https://github.com/HKUDS/DeepCode/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/HKUDS/DeepCode?color=00d9ff&amp;amp;style=for-the-badge&amp;amp;logo=star&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/badge/ğŸPython-3.13-4ecdc4?style=for-the-badge&amp;amp;logo=python&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt; &lt;a href="https://pypi.org/project/deepcode-hku/"&gt;&lt;img src="https://img.shields.io/pypi/v/deepcode-hku.svg?style=for-the-badge&amp;amp;logo=pypi&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e&amp;amp;color=ff6b6b" /&gt;&lt;/a&gt; &lt;/p&gt; 
 &lt;p&gt; &lt;a href="https://discord.gg/yF2MmDJyGJ"&gt;&lt;img src="https://img.shields.io/badge/ğŸ’¬Discord-Community-7289da?style=for-the-badge&amp;amp;logo=discord&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt;&lt;/a&gt; &lt;a href="https://github.com/HKUDS/DeepCode/issues/11"&gt;&lt;img src="https://img.shields.io/badge/ğŸ’¬WeChat-Group-07c160?style=for-the-badge&amp;amp;logo=wechat&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt;&lt;/a&gt; &lt;/p&gt; 
 &lt;div align="center"&gt; 
  &lt;div style="width: 100%; height: 2px; margin: 20px 0; background: linear-gradient(90deg, transparent, #00d9ff, transparent);"&gt;&lt;/div&gt; 
 &lt;/div&gt; 
 &lt;div align="center"&gt; 
  &lt;a href="https://raw.githubusercontent.com/HKUDS/DeepCode/main/#-quick-start" style="text-decoration: none;"&gt; &lt;img src="https://img.shields.io/badge/Quick%20Start-Get%20Started%20Now-00d9ff?style=for-the-badge&amp;amp;logo=rocket&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt; &lt;/a&gt; 
 &lt;/div&gt; 
 &lt;h3&gt;ğŸ–¥ï¸ &lt;strong&gt;Interface Showcase&lt;/strong&gt;&lt;/h3&gt; 
 &lt;table align="center" width="100%" style="border: none; border-collapse: collapse; margin: 30px 0;"&gt; 
  &lt;tbody&gt;
   &lt;tr&gt; 
    &lt;td width="50%" align="center" style="vertical-align: top; padding: 20px;"&gt; &lt;h4&gt;ğŸ–¥ï¸ &lt;strong&gt;CLI Interface&lt;/strong&gt;&lt;/h4&gt; &lt;p&gt;&lt;strong&gt;Terminal-Based Development&lt;/strong&gt;&lt;/p&gt; 
     &lt;div align="center"&gt; 
      &lt;img src="https://github.com/Zongwei9888/Experiment_Images/raw/8882a7313c504ca97ead6e7b36c51aa761b6a4f3/DeepCode_images/CLI.gif" alt="CLI Interface Demo" width="100%" style="border-radius: 10px; box-shadow: 0 8px 20px rgba(45,55,72,0.3); margin: 15px 0;" /&gt; 
      &lt;div style="background: linear-gradient(135deg, #2D3748 0%, #4A5568 100%); border-radius: 12px; padding: 15px; margin: 15px 0; color: white;"&gt; 
       &lt;strong&gt;ğŸš€ Advanced Terminal Experience&lt;/strong&gt;
       &lt;br /&gt; 
       &lt;small&gt;âš¡ Fast command-line workflow&lt;br /&gt;ğŸ”§ Developer-friendly interface&lt;br /&gt;ğŸ“Š Real-time progress tracking&lt;/small&gt; 
      &lt;/div&gt; 
      &lt;p&gt;&lt;em&gt;Professional terminal interface for advanced users and CI/CD integration&lt;/em&gt;&lt;/p&gt; 
     &lt;/div&gt; &lt;/td&gt; 
    &lt;td width="50%" align="center" style="vertical-align: top; padding: 20px;"&gt; &lt;h4&gt;ğŸŒ &lt;strong&gt;Web Interface&lt;/strong&gt;&lt;/h4&gt; &lt;p&gt;&lt;strong&gt;Visual Interactive Experience&lt;/strong&gt;&lt;/p&gt; 
     &lt;div align="center"&gt; 
      &lt;img src="https://github.com/Zongwei9888/Experiment_Images/raw/8882a7313c504ca97ead6e7b36c51aa761b6a4f3/DeepCode_images/UI.gif" alt="Web Interface Demo" width="100%" style="border-radius: 10px; box-shadow: 0 8px 20px rgba(14,165,233,0.3); margin: 15px 0;" /&gt; 
      &lt;div style="background: linear-gradient(135deg, #0EA5E9 0%, #00D4FF 100%); border-radius: 12px; padding: 15px; margin: 15px 0; color: white;"&gt; 
       &lt;strong&gt;ğŸ¨ Modern Web Dashboard&lt;/strong&gt;
       &lt;br /&gt; 
       &lt;small&gt;ğŸ–±ï¸ Intuitive drag-and-drop&lt;br /&gt;ğŸ“± Responsive design&lt;br /&gt;ğŸ¯ Visual progress tracking&lt;/small&gt; 
      &lt;/div&gt; 
      &lt;p&gt;&lt;em&gt;Beautiful web interface with streamlined workflow for all skill levels&lt;/em&gt;&lt;/p&gt; 
     &lt;/div&gt; &lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt;
 &lt;/table&gt; 
 &lt;hr /&gt; 
 &lt;div align="center"&gt; 
  &lt;h3&gt;ğŸ¬ &lt;strong&gt;Introduction Video&lt;/strong&gt;&lt;/h3&gt; 
  &lt;div style="margin: 20px 0;"&gt; 
   &lt;a href="https://youtu.be/PRgmP8pOI08" target="_blank"&gt; &lt;img src="https://img.youtube.com/vi/PRgmP8pOI08/maxresdefault.jpg" alt="DeepCode Introduction Video" width="75%" style="border-radius: 12px; box-shadow: 0 8px 25px rgba(0,0,0,0.15); transition: transform 0.3s ease;" /&gt; &lt;/a&gt; 
  &lt;/div&gt; 
  &lt;p&gt;&lt;em&gt;ğŸ¯ &lt;strong&gt;Watch our complete introduction&lt;/strong&gt; - See how DeepCode transforms research papers and natural language into production-ready code&lt;/em&gt;&lt;/p&gt; 
  &lt;p&gt; &lt;a href="https://youtu.be/PRgmP8pOI08" target="_blank"&gt; &lt;img src="https://img.shields.io/badge/â–¶ï¸_Watch_Video-FF0000?style=for-the-badge&amp;amp;logo=youtube&amp;amp;logoColor=white" alt="Watch Video" /&gt; &lt;/a&gt; &lt;/p&gt; 
 &lt;/div&gt; 
 &lt;hr /&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;&lt;em&gt;"Where AI Agents Transform Ideas into Production-Ready Code"&lt;/em&gt;&lt;/p&gt; 
 &lt;/blockquote&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ğŸ“‘ Table of Contents&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/DeepCode/main/#-key-features"&gt;ğŸš€ Key Features&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/DeepCode/main/#%EF%B8%8F-architecture"&gt;ğŸ—ï¸ Architecture&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/DeepCode/main/#-quick-start"&gt;ğŸš€ Quick Start&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/DeepCode/main/#-examples"&gt;ğŸ’¡ Examples&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/DeepCode/main/#-live-demonstrations"&gt;ğŸ¬ Live Demonstrations&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/DeepCode/main/#-star-history"&gt;â­ Star History&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/DeepCode/main/#-license"&gt;ğŸ“„ License&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ğŸš€ Key Features&lt;/h2&gt; 
&lt;br /&gt; 
&lt;table align="center" width="100%" style="border: none; table-layout: fixed;"&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td width="30%" align="center" style="vertical-align: top; padding: 20px;"&gt; 
    &lt;div style="height: 80px; display: flex; align-items: center; justify-content: center;"&gt; 
     &lt;h3 style="margin: 0; padding: 0;"&gt;ğŸš€ &lt;strong&gt;Paper2Code&lt;/strong&gt;&lt;/h3&gt; 
    &lt;/div&gt; 
    &lt;div align="center" style="margin: 15px 0;"&gt; 
     &lt;img src="https://img.shields.io/badge/ALGORITHM-IMPLEMENTATION-ff6b6b?style=for-the-badge&amp;amp;logo=algorithm&amp;amp;logoColor=white" alt="Algorithm Badge" /&gt; 
    &lt;/div&gt; 
    &lt;div style="height: 80px; display: flex; align-items: center; justify-content: center;"&gt; 
     &lt;p align="center"&gt;&lt;strong&gt;Automated Implementation of Complex Algorithms&lt;/strong&gt;&lt;/p&gt; 
    &lt;/div&gt; 
    &lt;div style="height: 60px; display: flex; align-items: center; justify-content: center;"&gt; 
     &lt;p align="center"&gt;Effortlessly converts complex algorithms from research papers into &lt;strong&gt;high-quality&lt;/strong&gt;, &lt;strong&gt;production-ready&lt;/strong&gt; code, accelerating algorithm reproduction.&lt;/p&gt; 
    &lt;/div&gt; &lt;/td&gt; 
   &lt;td width="30%" align="center" style="vertical-align: top; padding: 20px;"&gt; 
    &lt;div style="height: 80px; display: flex; align-items: center; justify-content: center;"&gt; 
     &lt;h3 style="margin: 0; padding: 0;"&gt;ğŸ¨ &lt;strong&gt;Text2Web&lt;/strong&gt;&lt;/h3&gt; 
    &lt;/div&gt; 
    &lt;div align="center" style="margin: 15px 0;"&gt; 
     &lt;img src="https://img.shields.io/badge/FRONTEND-DEVELOPMENT-4ecdc4?style=for-the-badge&amp;amp;logo=react&amp;amp;logoColor=white" alt="Frontend Badge" /&gt; 
    &lt;/div&gt; 
    &lt;div style="height: 80px; display: flex; align-items: center; justify-content: center;"&gt; 
     &lt;p align="center"&gt;&lt;strong&gt;Automated Front-End Web Development&lt;/strong&gt;&lt;/p&gt; 
    &lt;/div&gt; 
    &lt;div style="height: 60px; display: flex; align-items: center; justify-content: center;"&gt; 
     &lt;p align="center"&gt;Translates plain textual descriptions into &lt;strong&gt;fully functional&lt;/strong&gt;, &lt;strong&gt;visually appealing&lt;/strong&gt; front-end web code for rapid interface creation.&lt;/p&gt; 
    &lt;/div&gt; &lt;/td&gt; 
   &lt;td width="30%" align="center" style="vertical-align: top; padding: 20px;"&gt; 
    &lt;div style="height: 80px; display: flex; align-items: center; justify-content: center;"&gt; 
     &lt;h3 style="margin: 0; padding: 0;"&gt;âš™ï¸ &lt;strong&gt;Text2Backend&lt;/strong&gt;&lt;/h3&gt; 
    &lt;/div&gt; 
    &lt;div align="center" style="margin: 15px 0;"&gt; 
     &lt;img src="https://img.shields.io/badge/BACKEND-DEVELOPMENT-9b59b6?style=for-the-badge&amp;amp;logo=server&amp;amp;logoColor=white" alt="Backend Badge" /&gt; 
    &lt;/div&gt; 
    &lt;div style="height: 80px; display: flex; align-items: center; justify-content: center;"&gt; 
     &lt;p align="center"&gt;&lt;strong&gt;Automated Back-End Development&lt;/strong&gt;&lt;/p&gt; 
    &lt;/div&gt; 
    &lt;div style="height: 60px; display: flex; align-items: center; justify-content: center;"&gt; 
     &lt;p align="center"&gt;Generates &lt;strong&gt;efficient&lt;/strong&gt;, &lt;strong&gt;scalable&lt;/strong&gt;, and &lt;strong&gt;feature-rich&lt;/strong&gt; back-end code from simple text inputs, streamlining server-side development.&lt;/p&gt; 
    &lt;/div&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;br /&gt; 
&lt;h3&gt;ğŸ¯ &lt;strong&gt;Autonomous Multi-Agent Workflow&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;The Challenges&lt;/strong&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;ğŸ“„ &lt;strong&gt;Implementation Complexity&lt;/strong&gt;: Converting academic papers and complex algorithms into working code requires significant technical effort and domain expertise&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;ğŸ”¬ &lt;strong&gt;Research Bottleneck&lt;/strong&gt;: Researchers spend valuable time implementing algorithms instead of focusing on their core research and discovery work&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;â±ï¸ &lt;strong&gt;Development Delays&lt;/strong&gt;: Product teams experience long wait times between concept and testable prototypes, slowing down innovation cycles&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;ğŸ”„ &lt;strong&gt;Repetitive Coding&lt;/strong&gt;: Developers repeatedly implement similar patterns and functionality instead of building on existing solutions&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;DeepCode&lt;/strong&gt; addresses these workflow inefficiencies by providing reliable automation for common development tasks, streamlining your development workflow from concept to code.&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;pre&gt;&lt;code class="language-mermaid"&gt;flowchart LR
    A["ğŸ“„ Research Papers&amp;lt;br/&amp;gt;ğŸ’¬ Text Prompts&amp;lt;br/&amp;gt;ğŸŒ URLs &amp;amp; Document&amp;lt;br/&amp;gt;ğŸ“ Files: PDF, DOC, PPTX, TXT, HTML"] --&amp;gt; B["ğŸ§  DeepCode&amp;lt;br/&amp;gt;Multi-Agent Engine"]
    B --&amp;gt; C["ğŸš€ Algorithm Implementation &amp;lt;br/&amp;gt;ğŸ¨ Frontend Development &amp;lt;br/&amp;gt;âš™ï¸ Backend Development"]

    style A fill:#ff6b6b,stroke:#c0392b,stroke-width:2px,color:#000
    style B fill:#00d4ff,stroke:#0984e3,stroke-width:3px,color:#000
    style C fill:#00b894,stroke:#00a085,stroke-width:2px,color:#000
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ğŸ—ï¸ Architecture&lt;/h2&gt; 
&lt;h3&gt;ğŸ“Š &lt;strong&gt;System Overview&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;DeepCode&lt;/strong&gt; is an AI-powered development platform that automates code generation and implementation tasks. Our multi-agent system handles the complexity of translating requirements into functional, well-structured code, allowing you to focus on innovation rather than implementation details.&lt;/p&gt; 
&lt;p&gt;ğŸ¯ &lt;strong&gt;Technical Capabilities&lt;/strong&gt;:&lt;/p&gt; 
&lt;p&gt;ğŸ§¬ &lt;strong&gt;Research-to-Production Pipeline&lt;/strong&gt;&lt;br /&gt; Multi-modal document analysis engine that extracts algorithmic logic and mathematical models from academic papers. Generates optimized implementations with proper data structures while preserving computational complexity characteristics.&lt;/p&gt; 
&lt;p&gt;ğŸª„ &lt;strong&gt;Natural Language Code Synthesis&lt;/strong&gt;&lt;br /&gt; Context-aware code generation using fine-tuned language models trained on curated code repositories. Maintains architectural consistency across modules while supporting multiple programming languages and frameworks.&lt;/p&gt; 
&lt;p&gt;âš¡ &lt;strong&gt;Automated Prototyping Engine&lt;/strong&gt;&lt;br /&gt; Intelligent scaffolding system generating complete application structures including database schemas, API endpoints, and frontend components. Uses dependency analysis to ensure scalable architecture from initial generation.&lt;/p&gt; 
&lt;p&gt;ğŸ’ &lt;strong&gt;Quality Assurance Automation&lt;/strong&gt;&lt;br /&gt; Integrated static analysis with automated unit test generation and documentation synthesis. Employs AST analysis for code correctness and property-based testing for comprehensive coverage.&lt;/p&gt; 
&lt;p&gt;ğŸ”® &lt;strong&gt;CodeRAG Integration System&lt;/strong&gt;&lt;br /&gt; Advanced retrieval-augmented generation combining semantic vector embeddings with graph-based dependency analysis. Automatically discovers optimal libraries and implementation patterns from large-scale code corpus.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h3&gt;ğŸ”§ &lt;strong&gt;Core Techniques&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;ğŸ§  &lt;strong&gt;Intelligent Orchestration Agent&lt;/strong&gt;: Central decision-making system that coordinates workflow phases and analyzes requirements. Employs dynamic planning algorithms to adapt execution strategies in real-time based on evolving project complexity. Dynamically selects optimal processing strategies for each implementation step. &lt;br /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;ğŸ’¾ &lt;strong&gt;Efficient Memory Mechanism&lt;/strong&gt;: Advanced context engineering system that manages large-scale code contexts efficiently. Implements hierarchical memory structures with intelligent compression for handling complex codebases. This component enables instant retrieval of implementation patterns and maintains semantic coherence across extended development sessions. &lt;br /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;ğŸ” &lt;strong&gt;Advanced CodeRAG System&lt;/strong&gt;: Global code comprehension engine that analyzes complex inter-dependencies across repositories. Performs cross-codebase relationship mapping to understand architectural patterns from a holistic perspective. This module leverages dependency graphs and semantic analysis to provide globally-aware code recommendations during implementation.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h3&gt;ğŸ¤– &lt;strong&gt;Multi-Agent Architecture of DeepCode&lt;/strong&gt;:&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;ğŸ¯ Central Orchestrating Agent&lt;/strong&gt;: Orchestrates entire workflow execution and makes strategic decisions. Coordinates specialized agents based on input complexity analysis. Implements dynamic task planning and resource allocation algorithms. &lt;br /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;ğŸ“ Intent Understanding Agent&lt;/strong&gt;: Performs deep semantic analysis of user requirements to decode complex intentions. Extracts functional specifications and technical constraints through advanced NLP processing. Transforms ambiguous human descriptions into precise, actionable development specifications with structured task decomposition. &lt;br /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;ğŸ“„ Document Parsing Agent&lt;/strong&gt;: Processes complex technical documents and research papers with advanced parsing capabilities. Extracts algorithms and methodologies using document understanding models. Converts academic concepts into practical implementation specifications through intelligent content analysis. &lt;br /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;ğŸ—ï¸ Code Planning Agent&lt;/strong&gt;: Performs architectural design and technology stack optimization. Dynamic planning for adaptive development roadmaps. Enforces coding standards and generates modular structures through automated design pattern selection.&lt;br /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;ğŸ” Code Reference Mining Agent&lt;/strong&gt;: Discovers relevant repositories and frameworks through intelligent search algorithms. Analyzes codebases for compatibility and integration potential. Provides recommendations based on similarity metrics and automated dependency analysis. &lt;br /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;ğŸ“š Code Indexing Agent&lt;/strong&gt;: Builds comprehensive knowledge graphs of discovered codebases. Maintains semantic relationships between code components. Enables intelligent retrieval and cross-reference capabilities. &lt;br /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;ğŸ§¬ Code Generation Agent&lt;/strong&gt;: Synthesizes gathered information into executable code implementations. Creates functional interfaces and integrates discovered components. Generates comprehensive test suites and documentation for reproducibility.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h4&gt;ğŸ› ï¸ &lt;strong&gt;Implementation Tools Matrix&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;&lt;strong&gt;ğŸ”§ Powered by MCP (Model Context Protocol)&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;DeepCode leverages the &lt;strong&gt;Model Context Protocol (MCP)&lt;/strong&gt; standard to seamlessly integrate with various tools and services. This standardized approach ensures reliable communication between AI agents and external systems, enabling powerful automation capabilities.&lt;/p&gt; 
&lt;h5&gt;ğŸ“¡ &lt;strong&gt;MCP Servers &amp;amp; Tools&lt;/strong&gt;&lt;/h5&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;ğŸ› ï¸ &lt;strong&gt;MCP Server&lt;/strong&gt;&lt;/th&gt; 
   &lt;th&gt;ğŸ”§ &lt;strong&gt;Primary Function&lt;/strong&gt;&lt;/th&gt; 
   &lt;th&gt;ğŸ’¡ &lt;strong&gt;Purpose &amp;amp; Capabilities&lt;/strong&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;ğŸ” brave&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Web Search Engine&lt;/td&gt; 
   &lt;td&gt;Real-time information retrieval via Brave Search API&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;ğŸŒ bocha-mcp&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Alternative Search&lt;/td&gt; 
   &lt;td&gt;Secondary search option with independent API access&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;ğŸ“‚ filesystem&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;File System Operations&lt;/td&gt; 
   &lt;td&gt;Local file and directory management, read/write operations&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;ğŸŒ fetch&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Web Content Retrieval&lt;/td&gt; 
   &lt;td&gt;Fetch and extract content from URLs and web resources&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;ğŸ“¥ github-downloader&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Repository Management&lt;/td&gt; 
   &lt;td&gt;Clone and download GitHub repositories for analysis&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;ğŸ“‹ file-downloader&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Document Processing&lt;/td&gt; 
   &lt;td&gt;Download and convert files (PDF, DOCX, etc.) to Markdown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;âš¡ command-executor&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;System Commands&lt;/td&gt; 
   &lt;td&gt;Execute bash/shell commands for environment management&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;ğŸ§¬ code-implementation&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Code Generation Hub&lt;/td&gt; 
   &lt;td&gt;Comprehensive code reproduction with execution and testing&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;ğŸ“š code-reference-indexer&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Smart Code Search&lt;/td&gt; 
   &lt;td&gt;Intelligent indexing and search of code repositories&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;ğŸ“„ document-segmentation&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Smart Document Analysis&lt;/td&gt; 
   &lt;td&gt;Intelligent document segmentation for large papers and technical documents&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h5&gt;ğŸ”§ &lt;strong&gt;Legacy Tool Functions&lt;/strong&gt; &lt;em&gt;(for reference)&lt;/em&gt;&lt;/h5&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;ğŸ› ï¸ &lt;strong&gt;Function&lt;/strong&gt;&lt;/th&gt; 
   &lt;th&gt;ğŸ¯ &lt;strong&gt;Usage Context&lt;/strong&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;ğŸ“„ read_code_mem&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Efficient code context retrieval from memory&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;âœï¸ write_file&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Direct file content generation and modification&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;ğŸ execute_python&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Python code testing and validation&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;ğŸ“ get_file_structure&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Project structure analysis and organization&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;âš™ï¸ set_workspace&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Dynamic workspace and environment configuration&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;ğŸ“Š get_operation_history&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Process monitoring and operation tracking&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;hr /&gt; 
&lt;p&gt;ğŸ›ï¸ &lt;strong&gt;Multi-Interface Framework&lt;/strong&gt;&lt;br /&gt; RESTful API with CLI and web frontends featuring real-time code streaming, interactive debugging, and extensible plugin architecture for CI/CD integration.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;ğŸš€ Multi-Agent Intelligent Pipeline:&lt;/strong&gt;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;h3&gt;ğŸŒŸ &lt;strong&gt;Intelligence Processing Flow&lt;/strong&gt;&lt;/h3&gt; 
 &lt;table align="center" width="100%" style="border: none; border-collapse: collapse;"&gt; 
  &lt;tbody&gt;
   &lt;tr&gt; 
    &lt;td colspan="3" align="center" style="padding: 20px; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); border-radius: 15px; color: white; font-weight: bold;"&gt; ğŸ’¡ &lt;strong&gt;INPUT LAYER&lt;/strong&gt;&lt;br /&gt; ğŸ“„ Research Papers â€¢ ğŸ’¬ Natural Language â€¢ ğŸŒ URLs â€¢ ğŸ“‹ Requirements &lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt;
    &lt;td colspan="3" height="20"&gt;&lt;/td&gt;
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td colspan="3" align="center" style="padding: 15px; background: linear-gradient(135deg, #ff6b6b 0%, #ee5a24 100%); border-radius: 12px; color: white; font-weight: bold;"&gt; ğŸ¯ &lt;strong&gt;CENTRAL ORCHESTRATION&lt;/strong&gt;&lt;br /&gt; Strategic Decision Making â€¢ Workflow Coordination â€¢ Agent Management &lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt;
    &lt;td colspan="3" height="15"&gt;&lt;/td&gt;
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center" style="padding: 12px; background: linear-gradient(135deg, #3742fa 0%, #2f3542 100%); border-radius: 10px; color: white; width: 50%;"&gt; ğŸ“ &lt;strong&gt;TEXT ANALYSIS&lt;/strong&gt;&lt;br /&gt; &lt;small&gt;Requirement Processing&lt;/small&gt; &lt;/td&gt; 
    &lt;td width="10"&gt;&lt;/td&gt; 
    &lt;td align="center" style="padding: 12px; background: linear-gradient(135deg, #8c7ae6 0%, #9c88ff 100%); border-radius: 10px; color: white; width: 50%;"&gt; ğŸ“„ &lt;strong&gt;DOCUMENT ANALYSIS&lt;/strong&gt;&lt;br /&gt; &lt;small&gt;Paper &amp;amp; Spec Processing&lt;/small&gt; &lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt;
    &lt;td colspan="3" height="15"&gt;&lt;/td&gt;
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td colspan="3" align="center" style="padding: 15px; background: linear-gradient(135deg, #00d2d3 0%, #54a0ff 100%); border-radius: 12px; color: white; font-weight: bold;"&gt; ğŸ“‹ &lt;strong&gt;REPRODUCTION PLANNING&lt;/strong&gt;&lt;br /&gt; Deep Paper Analysis â€¢ Code Requirements Parsing â€¢ Reproduction Strategy Development &lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt;
    &lt;td colspan="3" height="15"&gt;&lt;/td&gt;
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center" style="padding: 12px; background: linear-gradient(135deg, #ffa726 0%, #ff7043 100%); border-radius: 10px; color: white; width: 50%;"&gt; ğŸ” &lt;strong&gt;REFERENCE ANALYSIS&lt;/strong&gt;&lt;br /&gt; &lt;small&gt;Repository Discovery&lt;/small&gt; &lt;/td&gt; 
    &lt;td width="10"&gt;&lt;/td&gt; 
    &lt;td align="center" style="padding: 12px; background: linear-gradient(135deg, #e056fd 0%, #f368e0 100%); border-radius: 10px; color: white; width: 50%;"&gt; ğŸ“š &lt;strong&gt;CODE INDEXING&lt;/strong&gt;&lt;br /&gt; &lt;small&gt;Knowledge Graph Building&lt;/small&gt; &lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt;
    &lt;td colspan="3" height="15"&gt;&lt;/td&gt;
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td colspan="3" align="center" style="padding: 15px; background: linear-gradient(135deg, #26de81 0%, #20bf6b 100%); border-radius: 12px; color: white; font-weight: bold;"&gt; ğŸ§¬ &lt;strong&gt;CODE IMPLEMENTATION&lt;/strong&gt;&lt;br /&gt; Implementation Generation â€¢ Testing â€¢ Documentation &lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt;
    &lt;td colspan="3" height="15"&gt;&lt;/td&gt;
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td colspan="3" align="center" style="padding: 20px; background: linear-gradient(135deg, #045de9 0%, #09c6f9 100%); border-radius: 15px; color: white; font-weight: bold;"&gt; âš¡ &lt;strong&gt;OUTPUT DELIVERY&lt;/strong&gt;&lt;br /&gt; ğŸ“¦ Complete Codebase â€¢ ğŸ§ª Test Suite â€¢ ğŸ“š Documentation â€¢ ğŸš€ Deployment Ready &lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt;
 &lt;/table&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;br /&gt; 
 &lt;h3&gt;ğŸ”„ &lt;strong&gt;Process Intelligence Features&lt;/strong&gt;&lt;/h3&gt; 
 &lt;table align="center" style="border: none;"&gt; 
  &lt;tbody&gt;
   &lt;tr&gt; 
    &lt;td align="center" width="25%" style="padding: 15px;"&gt; 
     &lt;div style="background: #f8f9fa; border-radius: 10px; padding: 15px; border-left: 4px solid #ff6b6b;"&gt; 
      &lt;h4&gt;ğŸ¯ Adaptive Flow&lt;/h4&gt; 
      &lt;p&gt;&lt;small&gt;Dynamic agent selection based on input complexity&lt;/small&gt;&lt;/p&gt; 
     &lt;/div&gt; &lt;/td&gt; 
    &lt;td align="center" width="25%" style="padding: 15px;"&gt; 
     &lt;div style="background: #f8f9fa; border-radius: 10px; padding: 15px; border-left: 4px solid #4ecdc4;"&gt; 
      &lt;h4&gt;ğŸ§  Smart Coordination&lt;/h4&gt; 
      &lt;p&gt;&lt;small&gt;Intelligent task distribution and parallel processing&lt;/small&gt;&lt;/p&gt; 
     &lt;/div&gt; &lt;/td&gt; 
    &lt;td align="center" width="25%" style="padding: 15px;"&gt; 
     &lt;div style="background: #f8f9fa; border-radius: 10px; padding: 15px; border-left: 4px solid #45b7d1;"&gt; 
      &lt;h4&gt;ğŸ” Context Awareness&lt;/h4&gt; 
      &lt;p&gt;&lt;small&gt;Deep understanding through CodeRAG integration&lt;/small&gt;&lt;/p&gt; 
     &lt;/div&gt; &lt;/td&gt; 
    &lt;td align="center" width="25%" style="padding: 15px;"&gt; 
     &lt;div style="background: #f8f9fa; border-radius: 10px; padding: 15px; border-left: 4px solid #96ceb4;"&gt; 
      &lt;h4&gt;âš¡ Quality Assurance&lt;/h4&gt; 
      &lt;p&gt;&lt;small&gt;Automated testing and validation throughout&lt;/small&gt;&lt;/p&gt; 
     &lt;/div&gt; &lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt;
 &lt;/table&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ğŸš€ Quick Start&lt;/h2&gt; 
&lt;h3&gt;ğŸ“¦ &lt;strong&gt;Step 1: Installation&lt;/strong&gt;&lt;/h3&gt; 
&lt;h4&gt;âš¡ &lt;strong&gt;Direct Installation (Recommended)&lt;/strong&gt;&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# ğŸš€ Install DeepCode package directly
pip install deepcode-hku

# ğŸ”‘ Download configuration files
curl -O https://raw.githubusercontent.com/HKUDS/DeepCode/main/mcp_agent.config.yaml
curl -O https://raw.githubusercontent.com/HKUDS/DeepCode/main/mcp_agent.secrets.yaml

# ğŸ”‘ Configure API keys (required)
# Edit mcp_agent.secrets.yaml with your API keys and base_url:
# - openai: api_key, base_url (for OpenAI/custom endpoints)
# - anthropic: api_key (for Claude models)

# ğŸ”‘ Configure search API keys for web search (optional)
# Edit mcp_agent.config.yaml to set your API keys:
# - For Brave Search: Set BRAVE_API_KEY: "your_key_here" in brave.env section (line ~28)
# - For Bocha-MCP: Set BOCHA_API_KEY: "your_key_here" in bocha-mcp.env section (line ~74)

# ğŸ“„ Configure document segmentation (optional)
# Edit mcp_agent.config.yaml to control document processing:
# - enabled: true/false (whether to use intelligent document segmentation)
# - size_threshold_chars: 50000 (document size threshold to trigger segmentation)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;ğŸ”§ &lt;strong&gt;Development Installation (From Source)&lt;/strong&gt;&lt;/h4&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;ğŸ“‚ Click to expand development installation options&lt;/strong&gt;&lt;/summary&gt; 
 &lt;h5&gt;ğŸ”¥ &lt;strong&gt;Using UV (Recommended for Development)&lt;/strong&gt;&lt;/h5&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# ğŸ”½ Clone the repository
git clone https://github.com/HKUDS/DeepCode.git
cd DeepCode/

# ğŸ“¦ Install UV package manager
curl -LsSf https://astral.sh/uv/install.sh | sh

# ğŸ”§ Install dependencies with UV
uv venv --python=3.13
source .venv/bin/activate  # On Windows: .venv\Scripts\activate
uv pip install -r requirements.txt

# ğŸ”‘ Configure API keys (required)
# Edit mcp_agent.secrets.yaml with your API keys and base_url:
# - openai: api_key, base_url (for OpenAI/custom endpoints)
# - anthropic: api_key (for Claude models)

# ğŸ”‘ Configure search API keys for web search (optional)
# Edit mcp_agent.config.yaml to set your API keys:
# - For Brave Search: Set BRAVE_API_KEY: "your_key_here" in brave.env section (line ~28)
# - For Bocha-MCP: Set BOCHA_API_KEY: "your_key_here" in bocha-mcp.env section (line ~74)

# ğŸ“„ Configure document segmentation (optional)
# Edit mcp_agent.config.yaml to control document processing:
# - enabled: true/false (whether to use intelligent document segmentation)
# - size_threshold_chars: 50000 (document size threshold to trigger segmentation)
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h5&gt;ğŸ &lt;strong&gt;Using Traditional pip&lt;/strong&gt;&lt;/h5&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# ğŸ”½ Clone the repository
git clone https://github.com/HKUDS/DeepCode.git
cd DeepCode/

# ğŸ“¦ Install dependencies
pip install -r requirements.txt

# ğŸ”‘ Configure API keys (required)
# Edit mcp_agent.secrets.yaml with your API keys and base_url:
# - openai: api_key, base_url (for OpenAI/custom endpoints)
# - anthropic: api_key (for Claude models)

# ğŸ”‘ Configure search API keys for web search (optional)
# Edit mcp_agent.config.yaml to set your API keys:
# - For Brave Search: Set BRAVE_API_KEY: "your_key_here" in brave.env section (line ~28)
# - For Bocha-MCP: Set BOCHA_API_KEY: "your_key_here" in bocha-mcp.env section (line ~74)

# ğŸ“„ Configure document segmentation (optional)
# Edit mcp_agent.config.yaml to control document processing:
# - enabled: true/false (whether to use intelligent document segmentation)
# - size_threshold_chars: 50000 (document size threshold to trigger segmentation)
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h4&gt;ğŸªŸ &lt;strong&gt;Windows Users: Additional MCP Server Configuration&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;If you're using Windows, you may need to configure MCP servers manually in &lt;code&gt;mcp_agent.config.yaml&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# 1. Install MCP servers globally
npm i -g @modelcontextprotocol/server-brave-search
npm i -g @modelcontextprotocol/server-filesystem

# 2. Find your global node_modules path
npm -g root
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then update your &lt;code&gt;mcp_agent.config.yaml&lt;/code&gt; to use absolute paths:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;mcp:
  servers:
    brave:
      command: "node"
      args: ["C:/Program Files/nodejs/node_modules/@modelcontextprotocol/server-brave-search/dist/index.js"]
    filesystem:
      command: "node"
      args: ["C:/Program Files/nodejs/node_modules/@modelcontextprotocol/server-filesystem/dist/index.js", "."]
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: Replace the path with your actual global node_modules path from step 2.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;ğŸ” &lt;strong&gt;Search Server Configuration (Optional)&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;DeepCode supports multiple search servers for web search functionality. You can configure your preferred option in &lt;code&gt;mcp_agent.config.yaml&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;# Default search server configuration
# Options: "brave" or "bocha-mcp"
default_search_server: "brave"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Available Options:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;ğŸ” Brave Search&lt;/strong&gt; (&lt;code&gt;"brave"&lt;/code&gt;):&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Default option with high-quality search results&lt;/li&gt; 
   &lt;li&gt;Requires BRAVE_API_KEY configuration&lt;/li&gt; 
   &lt;li&gt;Recommended for most users&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;ğŸŒ Bocha-MCP&lt;/strong&gt; (&lt;code&gt;"bocha-mcp"&lt;/code&gt;):&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Alternative search server option&lt;/li&gt; 
   &lt;li&gt;Requires BOCHA_API_KEY configuration&lt;/li&gt; 
   &lt;li&gt;Uses local Python server implementation&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;API Key Configuration in mcp_agent.config.yaml:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;# For Brave Search (default) - around line 28
brave:
  command: "npx"
  args: ["-y", "@modelcontextprotocol/server-brave-search"]
  env:
    BRAVE_API_KEY: "your_brave_api_key_here"

# For Bocha-MCP (alternative) - around line 74
bocha-mcp:
  command: "python"
  args: ["tools/bocha_search_server.py"]
  env:
    PYTHONPATH: "."
    BOCHA_API_KEY: "your_bocha_api_key_here"
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;ğŸ’¡ Tip&lt;/strong&gt;: Both search servers require API key configuration. Choose the one that best fits your API access and requirements.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;âš¡ &lt;strong&gt;Step 2: Launch Application&lt;/strong&gt;&lt;/h3&gt; 
&lt;h4&gt;ğŸš€ &lt;strong&gt;Using Installed Package (Recommended)&lt;/strong&gt;&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# ğŸŒ Launch web interface directly
deepcode

# The application will automatically start at http://localhost:8501
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;ğŸ› ï¸ &lt;strong&gt;Using Source Code&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;Choose your preferred interface:&lt;/p&gt; 
&lt;h5&gt;ğŸŒ &lt;strong&gt;Web Interface&lt;/strong&gt; (Recommended)&lt;/h5&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Using UV
uv run streamlit run ui/streamlit_app.py
# Or using traditional Python
streamlit run ui/streamlit_app.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://img.shields.io/badge/Access-localhost:8501-00d4ff?style=flat-square&amp;amp;logo=streamlit&amp;amp;logoColor=white" alt="Web Access" /&gt; 
&lt;/div&gt; 
&lt;h5&gt;ğŸ–¥ï¸ &lt;strong&gt;CLI Interface&lt;/strong&gt; (Advanced Users)&lt;/h5&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Using UV
uv run python cli/main_cli.py
# Or using traditional Python
python cli/main_cli.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://img.shields.io/badge/Mode-Interactive_Terminal-9b59b6?style=flat-square&amp;amp;logo=terminal&amp;amp;logoColor=white" alt="CLI Mode" /&gt; 
&lt;/div&gt; 
&lt;h3&gt;ğŸ¯ &lt;strong&gt;Step 3: Generate Code&lt;/strong&gt;&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ“„ Input&lt;/strong&gt;: Upload your research paper, provide requirements, or paste a URL&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ¤– Processing&lt;/strong&gt;: Watch the multi-agent system analyze and plan&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;âš¡ Output&lt;/strong&gt;: Receive production-ready code with tests and documentation&lt;/li&gt; 
&lt;/ol&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ğŸ’¡ Examples&lt;/h2&gt; 
&lt;h3&gt;ğŸ¬ &lt;strong&gt;Live Demonstrations&lt;/strong&gt;&lt;/h3&gt; 
&lt;table align="center"&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td width="33%" align="center"&gt; &lt;h4&gt;ğŸ“„ &lt;strong&gt;Paper2Code Demo&lt;/strong&gt;&lt;/h4&gt; &lt;p&gt;&lt;strong&gt;Research to Implementation&lt;/strong&gt;&lt;/p&gt; 
    &lt;div align="center"&gt; 
     &lt;a href="https://www.youtube.com/watch?v=MQZYpLkzsbw"&gt; &lt;img src="https://img.youtube.com/vi/MQZYpLkzsbw/maxresdefault.jpg" alt="Paper2Code Demo" width="100%" style="border-radius: 10px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);" /&gt; &lt;/a&gt; 
     &lt;p&gt;&lt;strong&gt;&lt;a href="https://www.youtube.com/watch?v=MQZYpLkzsbw"&gt;â–¶ï¸ Watch Demo&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
     &lt;p&gt;&lt;em&gt;Transform academic papers into production-ready code automatically&lt;/em&gt;&lt;/p&gt; 
    &lt;/div&gt; &lt;/td&gt; 
   &lt;td width="33%" align="center"&gt; &lt;h4&gt;ğŸ–¼ï¸ &lt;strong&gt;Image Processing Demo&lt;/strong&gt;&lt;/h4&gt; &lt;p&gt;&lt;strong&gt;AI-Powered Image Tools&lt;/strong&gt;&lt;/p&gt; 
    &lt;div align="center"&gt; 
     &lt;a href="https://www.youtube.com/watch?v=nFt5mLaMEac"&gt; &lt;img src="https://img.youtube.com/vi/nFt5mLaMEac/maxresdefault.jpg" alt="Image Processing Demo" width="100%" style="border-radius: 10px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);" /&gt; &lt;/a&gt; 
     &lt;p&gt;&lt;strong&gt;&lt;a href="https://www.youtube.com/watch?v=nFt5mLaMEac"&gt;â–¶ï¸ Watch Demo&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
     &lt;p&gt;&lt;em&gt;Intelligent image processing with background removal and enhancement&lt;/em&gt;&lt;/p&gt; 
    &lt;/div&gt; &lt;/td&gt; 
   &lt;td width="33%" align="center"&gt; &lt;h4&gt;ğŸŒ &lt;strong&gt;Frontend Implementation&lt;/strong&gt;&lt;/h4&gt; &lt;p&gt;&lt;strong&gt;Complete Web Application&lt;/strong&gt;&lt;/p&gt; 
    &lt;div align="center"&gt; 
     &lt;a href="https://www.youtube.com/watch?v=78wx3dkTaAU"&gt; &lt;img src="https://img.youtube.com/vi/78wx3dkTaAU/maxresdefault.jpg" alt="Frontend Demo" width="100%" style="border-radius: 10px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);" /&gt; &lt;/a&gt; 
     &lt;p&gt;&lt;strong&gt;&lt;a href="https://www.youtube.com/watch?v=78wx3dkTaAU"&gt;â–¶ï¸ Watch Demo&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
     &lt;p&gt;&lt;em&gt;Full-stack web development from concept to deployment&lt;/em&gt;&lt;/p&gt; 
    &lt;/div&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h3&gt;ğŸ†• &lt;strong&gt;Recent Updates&lt;/strong&gt;&lt;/h3&gt; 
&lt;h4&gt;ğŸ“„ &lt;strong&gt;Smart Document Segmentation (v1.2.0)&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Intelligent Processing&lt;/strong&gt;: Automatically handles large research papers and technical documents that exceed LLM token limits&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Configurable Control&lt;/strong&gt;: Toggle segmentation via configuration with size-based thresholds&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Semantic Analysis&lt;/strong&gt;: Advanced content understanding with algorithm, concept, and formula preservation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Backward Compatibility&lt;/strong&gt;: Seamlessly falls back to traditional processing for smaller documents&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;ğŸš€ &lt;strong&gt;Coming Soon&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;We're continuously enhancing DeepCode with exciting new features:&lt;/p&gt; 
&lt;h4&gt;ğŸ”§ &lt;strong&gt;Enhanced Code Reliability &amp;amp; Validation&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Automated Testing&lt;/strong&gt;: Comprehensive functionality testing with execution verification and error detection.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Code Quality Assurance&lt;/strong&gt;: Multi-level validation through static analysis, dynamic testing, and performance benchmarking.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Smart Debugging&lt;/strong&gt;: AI-powered error detection with automatic correction suggestions&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;ğŸ“Š &lt;strong&gt;PaperBench Performance Showcase&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Benchmark Dashboard&lt;/strong&gt;: Comprehensive performance metrics on the PaperBench evaluation suite.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Accuracy Metrics&lt;/strong&gt;: Detailed comparison with state-of-the-art paper reproduction systems.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Success Analytics&lt;/strong&gt;: Statistical analysis across paper categories and complexity levels.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;âš¡ &lt;strong&gt;System-wide Optimizations&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Performance Boost&lt;/strong&gt;: Multi-threaded processing and optimized agent coordination for faster generation.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Enhanced Reasoning&lt;/strong&gt;: Advanced reasoning capabilities with improved context understanding.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Expanded Support&lt;/strong&gt;: Extended compatibility with additional programming languages and frameworks.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;â­ Star History&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;em&gt;Community Growth Trajectory&lt;/em&gt;&lt;/p&gt; 
 &lt;a href="https://star-history.com/#HKUDS/DeepCode&amp;amp;Date"&gt; 
  &lt;picture&gt; 
   &lt;source media="(prefers-color-scheme: dark)" srcset="https://api.star-history.com/svg?repos=HKUDS/DeepCode&amp;amp;type=Date&amp;amp;theme=dark" /&gt; 
   &lt;source media="(prefers-color-scheme: light)" srcset="https://api.star-history.com/svg?repos=HKUDS/DeepCode&amp;amp;type=Date" /&gt; 
   &lt;img alt="Star History Chart" src="https://api.star-history.com/svg?repos=HKUDS/DeepCode&amp;amp;type=Date" style="border-radius: 15px; box-shadow: 0 0 30px rgba(0, 217, 255, 0.3);" /&gt; 
  &lt;/picture&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h3&gt;ğŸš€ &lt;strong&gt;Ready to Transform Development?&lt;/strong&gt;&lt;/h3&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt; &lt;a href="https://raw.githubusercontent.com/HKUDS/DeepCode/main/#-quick-start"&gt;&lt;img src="https://img.shields.io/badge/ğŸš€_Get_Started-00d4ff?style=for-the-badge&amp;amp;logo=rocket&amp;amp;logoColor=white" alt="Get Started" /&gt;&lt;/a&gt; &lt;a href="https://github.com/HKUDS"&gt;&lt;img src="https://img.shields.io/badge/ğŸ›ï¸_View_on_GitHub-00d4ff?style=for-the-badge&amp;amp;logo=github&amp;amp;logoColor=white" alt="View on GitHub" /&gt;&lt;/a&gt; &lt;a href="https://github.com/HKUDS/deepcode-agent"&gt;&lt;img src="https://img.shields.io/badge/â­_Star_Project-00d4ff?style=for-the-badge&amp;amp;logo=star&amp;amp;logoColor=white" alt="Star Project" /&gt;&lt;/a&gt; &lt;/p&gt; 
 &lt;hr /&gt; 
 &lt;h3&gt;ğŸ“„ &lt;strong&gt;License&lt;/strong&gt;&lt;/h3&gt; 
 &lt;img src="https://img.shields.io/badge/License-MIT-4ecdc4?style=for-the-badge&amp;amp;logo=opensourceinitiative&amp;amp;logoColor=white" alt="MIT License" /&gt; 
 &lt;p&gt;&lt;strong&gt;MIT License&lt;/strong&gt; - Copyright (c) 2025 Data Intelligence Lab, The University of Hong Kong&lt;/p&gt; 
 &lt;hr /&gt; 
 &lt;img src="https://visitor-badge.laobi.icu/badge?page_id=deepcode.readme&amp;amp;style=for-the-badge&amp;amp;color=00d4ff" alt="Visitors" /&gt; 
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>dataease/SQLBot</title>
      <link>https://github.com/dataease/SQLBot</link>
      <description>&lt;p&gt;åŸºäºå¤§æ¨¡å‹å’Œ RAG çš„æ™ºèƒ½é—®æ•°ç³»ç»Ÿã€‚Text-to-SQL Generation via LLMs using RAG.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt;&lt;img src="https://resource-fit2cloud-com.oss-cn-hangzhou.aliyuncs.com/sqlbot/sqlbot.png" alt="SQLBot" width="300" /&gt;&lt;/p&gt; 
&lt;h3 align="center"&gt;åŸºäºå¤§æ¨¡å‹å’Œ RAG çš„æ™ºèƒ½é—®æ•°ç³»ç»Ÿ&lt;/h3&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/dataease/SQLBot/releases/latest"&gt;&lt;img src="https://img.shields.io/github/v/release/dataease/SQLBot" alt="Latest release" /&gt;&lt;/a&gt; &lt;a href="https://github.com/dataease/SQLBot"&gt;&lt;img src="https://img.shields.io/github/stars/dataease/SQLBot?color=%231890FF&amp;amp;style=flat-square" alt="Stars" /&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/r/dataease/SQLbot"&gt;&lt;img src="https://img.shields.io/docker/pulls/dataease/sqlbot?label=downloads" alt="Download" /&gt;&lt;/a&gt;&lt;br /&gt; &lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;SQLBot æ˜¯ä¸€æ¬¾åŸºäºå¤§æ¨¡å‹å’Œ RAG çš„æ™ºèƒ½é—®æ•°ç³»ç»Ÿã€‚SQLBot çš„ä¼˜åŠ¿åŒ…æ‹¬ï¼š&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;å¼€ç®±å³ç”¨&lt;/strong&gt;: åªéœ€é…ç½®å¤§æ¨¡å‹å’Œæ•°æ®æºå³å¯å¼€å¯é—®æ•°ä¹‹æ—…ï¼Œé€šè¿‡å¤§æ¨¡å‹å’Œ RAG çš„ç»“åˆæ¥å®ç°é«˜è´¨é‡çš„ text2sqlï¼›&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;æ˜“äºé›†æˆ&lt;/strong&gt;: æ”¯æŒå¿«é€ŸåµŒå…¥åˆ°ç¬¬ä¸‰æ–¹ä¸šåŠ¡ç³»ç»Ÿï¼Œä¹Ÿæ”¯æŒè¢« n8nã€MaxKBã€Difyã€Coze ç­‰ AI åº”ç”¨å¼€å‘å¹³å°é›†æˆè°ƒç”¨ï¼Œè®©å„ç±»åº”ç”¨å¿«é€Ÿæ‹¥æœ‰æ™ºèƒ½é—®æ•°èƒ½åŠ›ï¼›&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;å®‰å…¨å¯æ§&lt;/strong&gt;: æä¾›åŸºäºå·¥ä½œç©ºé—´çš„èµ„æºéš”ç¦»æœºåˆ¶ï¼Œèƒ½å¤Ÿå®ç°ç»†ç²’åº¦çš„æ•°æ®æƒé™æ§åˆ¶ã€‚&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;å¿«é€Ÿå¼€å§‹&lt;/h2&gt; 
&lt;h3&gt;å®‰è£…éƒ¨ç½²&lt;/h3&gt; 
&lt;p&gt;å‡†å¤‡ä¸€å° Linux æœåŠ¡å™¨ï¼Œæ‰§è¡Œä»¥ä¸‹ä¸€é”®å®‰è£…è„šæœ¬ã€‚&lt;br /&gt; åœ¨è¿è¡Œ SQLBot å‰ï¼Œè¯·ç¡®ä¿å·²å®‰è£…å¥½ &lt;a href="https://docs.docker.com/get-docker/"&gt;Docker&lt;/a&gt; å’Œ &lt;a href="https://docs.docker.com/compose/install/"&gt;Docker Compose&lt;/a&gt;ã€‚&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# åˆ›å»ºç›®å½•
mkdir -p /opt/sqlbot
cd /opt/sqlbot

# ä¸‹è½½ docker-compose.yaml
curl -o docker-compose.yaml https://raw.githubusercontent.com/dataease/SQLBot/main/docker-compose.yaml

# å¯åŠ¨æœåŠ¡
docker compose up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;ä½ ä¹Ÿå¯ä»¥é€šè¿‡ &lt;a href="https://apps.fit2cloud.com/1panel"&gt;1Panel åº”ç”¨å•†åº—&lt;/a&gt; å¿«é€Ÿéƒ¨ç½² SQLBotã€‚&lt;/p&gt; 
&lt;p&gt;å¦‚æœæ˜¯å†…ç½‘ç¯å¢ƒï¼Œä½ å¯ä»¥é€šè¿‡ &lt;a href="https://community.fit2cloud.com/#/products/sqlbot/downloads"&gt;ç¦»çº¿å®‰è£…åŒ…æ–¹å¼&lt;/a&gt; éƒ¨ç½² SQLBotã€‚&lt;/p&gt; 
&lt;h3&gt;è®¿é—®æ–¹å¼&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€: http://&amp;lt;ä½ çš„æœåŠ¡å™¨IP&amp;gt;:8000/&lt;/li&gt; 
 &lt;li&gt;ç”¨æˆ·å: admin&lt;/li&gt; 
 &lt;li&gt;å¯†ç : SQLBot@123456&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;è”ç³»æˆ‘ä»¬&lt;/h3&gt; 
&lt;p&gt;å¦‚ä½ æœ‰æ›´å¤šé—®é¢˜ï¼Œå¯ä»¥åŠ å…¥æˆ‘ä»¬çš„æŠ€æœ¯äº¤æµç¾¤ä¸æˆ‘ä»¬äº¤æµã€‚&lt;/p&gt; 
&lt;img width="180" height="180" alt="contact_me_qr" src="https://github.com/user-attachments/assets/2594ff29-5426-4457-b051-279855610030" /&gt; 
&lt;h2&gt;UI å±•ç¤º&lt;/h2&gt;  
&lt;img alt="q&amp;amp;a" src="https://github.com/user-attachments/assets/55526514-52f3-4cfe-98ec-08a986259280" /&gt;  
&lt;h2&gt;Star History&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://www.star-history.com/#dataease/sqlbot&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=dataease/sqlbot&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;é£è‡´äº‘æ——ä¸‹çš„å…¶ä»–æ˜æ˜Ÿé¡¹ç›®&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/dataease/dataease/"&gt;DataEase&lt;/a&gt; - äººäººå¯ç”¨çš„å¼€æº BI å·¥å…·&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/1panel-dev/1panel/"&gt;1Panel&lt;/a&gt; - ç°ä»£åŒ–ã€å¼€æºçš„ Linux æœåŠ¡å™¨è¿ç»´ç®¡ç†é¢æ¿&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/1panel-dev/MaxKB/"&gt;MaxKB&lt;/a&gt; - å¼ºå¤§æ˜“ç”¨çš„ä¼ä¸šçº§æ™ºèƒ½ä½“å¹³å°&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jumpserver/jumpserver/"&gt;JumpServer&lt;/a&gt; - å¹¿å—æ¬¢è¿çš„å¼€æºå ¡å’æœº&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/halo-dev/halo/"&gt;Halo&lt;/a&gt; - å¼ºå¤§æ˜“ç”¨çš„å¼€æºå»ºç«™å·¥å…·&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/metersphere/metersphere/"&gt;MeterSphere&lt;/a&gt; - æ–°ä¸€ä»£çš„å¼€æºæŒç»­æµ‹è¯•å·¥å…·&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;æœ¬ä»“åº“éµå¾ª &lt;a href="https://raw.githubusercontent.com/dataease/SQLBot/main/LICENSE"&gt;FIT2CLOUD Open Source License&lt;/a&gt; å¼€æºåè®®ï¼Œè¯¥è®¸å¯è¯æœ¬è´¨ä¸Šæ˜¯ GPLv3ï¼Œä½†æœ‰ä¸€äº›é¢å¤–çš„é™åˆ¶ã€‚&lt;/p&gt; 
&lt;p&gt;ä½ å¯ä»¥åŸºäº SQLBot çš„æºä»£ç è¿›è¡ŒäºŒæ¬¡å¼€å‘ï¼Œä½†æ˜¯éœ€è¦éµå®ˆä»¥ä¸‹è§„å®šï¼š&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;ä¸èƒ½æ›¿æ¢å’Œä¿®æ”¹ SQLBot çš„ Logo å’Œç‰ˆæƒä¿¡æ¯ï¼›&lt;/li&gt; 
 &lt;li&gt;äºŒæ¬¡å¼€å‘åçš„è¡ç”Ÿä½œå“å¿…é¡»éµå®ˆ GPL V3 çš„å¼€æºä¹‰åŠ¡ã€‚&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;å¦‚éœ€å•†ä¸šæˆæƒï¼Œè¯·è”ç³» &lt;a href="mailto:support@fit2cloud.com"&gt;support@fit2cloud.com&lt;/a&gt; ã€‚&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Arindam200/awesome-ai-apps</title>
      <link>https://github.com/Arindam200/awesome-ai-apps</link>
      <description>&lt;p&gt;A collection of projects showcasing RAG, agents, workflows, and other AI use cases&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Awesome AI Apps &lt;a href="https://awesome.re"&gt;&lt;img src="https://awesome.re/badge.svg?sanitize=true" alt="Awesome" /&gt;&lt;/a&gt;&lt;/h1&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Arindam200/awesome-ai-apps/main/assets/banner_new.png" alt="Banner" /&gt;&lt;/p&gt; 
&lt;p&gt;This repository is a comprehensive collection of practical examples, tutorials, and recipes for building powerful LLM-powered applications. From simple chatbots to advanced AI agents, these projects serve as a guide for developers working with various AI frameworks and tools.&lt;/p&gt; 
&lt;p&gt;Powered by &lt;a href="https://dub.sh/nebius"&gt;Nebius AI Studio&lt;/a&gt; - your one-stop platform for building and deploying AI applications.&lt;/p&gt; 
&lt;h2&gt;ğŸš€ Featured AI Agent Frameworks&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://google.github.io/adk-docs/"&gt;&lt;img src="https://raw.githubusercontent.com/google/adk-python/main/assets/agent-development-kit.png" alt="Google ADK logo" width="20" height="20" /&gt; Google Agent Development Kit (ADK)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://openai.github.io/openai-agents-python/"&gt;&lt;img src="https://avatars.githubusercontent.com/u/14957082?s=200&amp;amp;v=4" alt="OpenAI Agents SDK logo" width="20" height="20" /&gt; OpenAI Agents SDK&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://python.langchain.com/"&gt;&lt;img src="https://cdn.simpleicons.org/langchain" alt="LangChain logo" width="25" height="25" /&gt; LangChain &lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.llamaindex.ai/"&gt;&lt;img src="https://avatars.githubusercontent.com/u/130722866?s=200&amp;amp;v=4" alt="Llamaindex logo" width="20" height="20" /&gt; LlamaIndex&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.agno.com/"&gt;&lt;img src="https://avatars.githubusercontent.com/u/104874993?s=48&amp;amp;v=4" alt="Agno logo" width="20" height="20" /&gt; Agno&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.crewai.com/"&gt;&lt;img src="https://cdn.prod.website-files.com/66cf2bfc3ed15b02da0ca770/66d07240057721394308addd_Logo%20(1).svg?sanitize=true" alt="CrewAI logo" width="35" height="25" /&gt; CrewAI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://strandsagents.com/"&gt;&lt;img src="https://avatars.githubusercontent.com/u/209155962?s=200&amp;amp;v=4" alt="AWS Strands Agents logo" width="20" height="20" /&gt; AWS Strands Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://ai.pydantic.dev/"&gt;&lt;img src="https://avatars.githubusercontent.com/u/110818415?s=200&amp;amp;v=4" alt="Pydantic AI logo" width="20" height="20" /&gt; Pydantic AI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.camel-ai.org/"&gt;&lt;img src="https://avatars.githubusercontent.com/u/134388954?s=200&amp;amp;v=4" alt="Camel AI logo" width="20" height="20" /&gt; CAMELâ€‘AI&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ğŸ§© Starter Agents&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Quick-start agents for learning and extending:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Arindam200/awesome-ai-apps/main/starter_ai_agents/agno_starter"&gt;Agno HackerNews Analysis&lt;/a&gt; - Agno-based agent for trend analysis on HackerNews.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Arindam200/awesome-ai-apps/main/starter_ai_agents/openai_agents_sdk"&gt;OpenAI SDK Starter&lt;/a&gt; - OpenAI Agents SDK based email helper &amp;amp; haiku writer.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Arindam200/awesome-ai-apps/main/starter_ai_agents/llamaindex_starter"&gt;LlamaIndex Task Manager&lt;/a&gt; - LlamaIndex-powered task assistant.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Arindam200/awesome-ai-apps/main/starter_ai_agents/crewai_starter"&gt;CrewAI Research Crew&lt;/a&gt; - Multi-agent research team.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Arindam200/awesome-ai-apps/main/starter_ai_agents/pydantic_starter"&gt;PydanticAI Weather Bot&lt;/a&gt; - Real-time weather info.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Arindam200/awesome-ai-apps/main/starter_ai_agents/langchain_langgraph_starter"&gt;LangChain-LangGraph Starter&lt;/a&gt; - LangChain + LangGraph starter.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Arindam200/awesome-ai-apps/main/starter_ai_agents/aws_strands_starter"&gt;AWS Strands Agent Starter&lt;/a&gt; - Weather report Agent.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Arindam200/awesome-ai-apps/main/starter_ai_agents/camel_ai_starter"&gt;Camel AI Starter&lt;/a&gt; - Performance benchmarking tool that compares the performance of various AI models.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ğŸª¶ Simple Agents&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Straightforward, practical use-cases:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Arindam200/awesome-ai-apps/main/simple_ai_agents/finance_agent"&gt;Finance Agent&lt;/a&gt; - Tracks live stock &amp;amp; market data.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Arindam200/awesome-ai-apps/main/simple_ai_agents/human_in_the_loop_agent"&gt;Human-in-the-Loop Agent&lt;/a&gt; - HITL actions for safe AI tasks.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Arindam200/awesome-ai-apps/main/simple_ai_agents/newsletter_agent"&gt;Newsletter Generator&lt;/a&gt; - AI newsletter builder with Firecrawl.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Arindam200/awesome-ai-apps/main/simple_ai_agents/reasoning_agent"&gt;Reasoning Agent&lt;/a&gt; - Financial reasoning step-by-step.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Arindam200/awesome-ai-apps/main/simple_ai_agents/agno_ui_agent"&gt;Agno UI Example&lt;/a&gt; - UI for web &amp;amp; finance agents.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Arindam200/awesome-ai-apps/main/simple_ai_agents/mastra_ai_weather_agent"&gt;Mastra Weather Bot&lt;/a&gt; - Weather updates with Mastra AI.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Arindam200/awesome-ai-apps/main/simple_ai_agents/cal_scheduling_agent"&gt;Calendar Assistant&lt;/a&gt; - Calendar scheduling with Cal.com.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Arindam200/awesome-ai-apps/main/simple_ai_agents/memory_agent"&gt;Memory Agent&lt;/a&gt; - Simple Memory Agent implementation with Agno.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Arindam200/awesome-ai-apps/main/simple_ai_agents/browser_agent"&gt;Web Automation Agent&lt;/a&gt; - Simple Browser Agent implementation with Nebius &amp;amp; browser use.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Arindam200/awesome-ai-apps/main/simple_ai_agents/nebius_chat"&gt;Nebius Chat&lt;/a&gt; - Nebius AI Studio Chat interface.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Arindam200/awesome-ai-apps/main/simple_ai_agents/talk_to_db"&gt;Talk to Your DB&lt;/a&gt; - Talk to your Database with GibsonAI &amp;amp; Langchain&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Arindam200/awesome-ai-apps/main/simple_ai_agents/blog_writing_agent"&gt;Blog Writing Agent&lt;/a&gt; - Personalized AI-powered blog writing agent.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Arindam200/awesome-ai-apps/main/simple_ai_agents/arxiv_researcher_agent_with_memori"&gt;arXiv Researcher Agent&lt;/a&gt; - AI research assistant built using OpenAI Agents and GibsonAI Memori.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ğŸ—‚ï¸ MCP Agents&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Examples using Model Context Protocol:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Arindam200/awesome-ai-apps/main/mcp_ai_agents/doc_mcp"&gt;Doc-MCP&lt;/a&gt; - Semantic RAG docs &amp;amp; Q&amp;amp;A.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Arindam200/awesome-ai-apps/main/mcp_ai_agents/langchain_langgraph_mcp_agent"&gt;LangGraph MCP Agent&lt;/a&gt; - LangChain ReAct agent with Couchbase.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Arindam200/awesome-ai-apps/main/mcp_ai_agents/github_mcp_agent"&gt;GitHub MCP Agent&lt;/a&gt; - Repo insights via MCP.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Arindam200/awesome-ai-apps/main/mcp_ai_agents/mcp_starter"&gt;MCP Starter&lt;/a&gt; - GitHub repo analyzer starter.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Arindam200/awesome-ai-apps/main/mcp_ai_agents/docs_qna_agent"&gt;Talk to your Docs&lt;/a&gt; - Documentation QnA Agent&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ğŸ“š RAG Applications&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Retrieve-augmented generation examples:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Arindam200/awesome-ai-apps/main/rag_apps/agentic_rag"&gt;Agentic RAG&lt;/a&gt; - Agentic RAG with Agno &amp;amp; GPT 5.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Arindam200/awesome-ai-apps/main/rag_apps/resume_optimizer"&gt;Resume Optimizer&lt;/a&gt; - Boost resumes with AI.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Arindam200/awesome-ai-apps/main/rag_apps/llamaIndex_starter"&gt;LlamaIndex RAG Starter&lt;/a&gt; - LlamaIndex + Nebius RAG starter.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Arindam200/awesome-ai-apps/main/rag_apps/pdf_rag_analyser"&gt;PDF RAG Analyzer&lt;/a&gt; - Chat with multiple PDFs.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Arindam200/awesome-ai-apps/main/rag_apps/qwen3_rag"&gt;Qwen3 RAG Chat&lt;/a&gt; - PDF chatbot with Streamlit.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Arindam200/awesome-ai-apps/main/rag_apps/chat_with_code"&gt;Chat with Code&lt;/a&gt; - Conversational code explorer.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Arindam200/awesome-ai-apps/main/rag_apps/gemma_ocr/"&gt;Gemma3 OCR&lt;/a&gt; - OCR-based document and image processor using Gemma3&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ğŸ”¬ Advanced Agents&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Complex pipelines for end-to-end workflows:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Arindam200/awesome-ai-apps/main/advance_ai_agents/deep_researcher_agent"&gt;Deep Researcher&lt;/a&gt; - Multi-stage research with Agno &amp;amp; Scrapegraph AI.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Arindam200/awesome-ai-apps/main/advance_ai_agents/candidate_analyser"&gt;Candilyzer&lt;/a&gt; - Analyze GitHub/LinkedIn profiles.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Arindam200/awesome-ai-apps/main/advance_ai_agents/job_finder_agent"&gt;Job Finder&lt;/a&gt; - LinkedIn job search with Bright Data.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Arindam200/awesome-ai-apps/main/advance_ai_agents/trend_analyzer_agent"&gt;AI Trend Analyzer&lt;/a&gt; - AI trend mining with Google ADK.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Arindam200/awesome-ai-apps/main/advance_ai_agents/conference_talk_abstract_generator"&gt;Conference Talk Generator&lt;/a&gt; - Draft talk abstracts with Google ADK &amp;amp; Couchbase.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Arindam200/awesome-ai-apps/main/advance_ai_agents/finance_service_agent"&gt;Finance Service Agent&lt;/a&gt; - FastAPI server for stock data and predictions with Agno.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Arindam200/awesome-ai-apps/main/advance_ai_agents/price_monitoring_agent"&gt;Price Monitoring Agent&lt;/a&gt; - Price monitoring and alerting Agent powered by CrewAi, Twilio &amp;amp; Nebius.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Arindam200/awesome-ai-apps/main/advance_ai_agents/startup_idea_validator_agent"&gt;Startup Idea Validator Agent&lt;/a&gt; - Agentic Workflow to validate and analyze startup ideas.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ğŸ“º Playlist of Demo Videos &amp;amp; Tutorials&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/playlist?list=PLMZM1DAlf0Lolxax4L2HS54Me8gn1gkz4"&gt;Build with MCP&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/playlist?list=PLMZM1DAlf0LqixhAG9BDk4O_FjqnaogK8"&gt;Build AI Agents&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/playlist?list=PL2ambAOfYA6-LDz0KpVKu9vJKAqhv0KKI"&gt;AI Agents, MCP and more...&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;h3&gt;Prerequisites&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Python 3.10 or higher&lt;/li&gt; 
 &lt;li&gt;Git&lt;/li&gt; 
 &lt;li&gt;pip (Python package manager) or uv&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Installation Steps&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Clone the repository&lt;/strong&gt;&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/Arindam200/awesome-ai-apps.git
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Navigate to the desired project directory&lt;/strong&gt;&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;cd awesome-ai-apps/starter_ai_agents/agno_starter
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Install the required dependencies&lt;/strong&gt;&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;pip install -r requirements.txt
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Follow project-specific instructions&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Each project has its own README.md with detailed setup and usage instructions&lt;/li&gt; 
   &lt;li&gt;Make sure to read the project-specific documentation before running the application&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;ğŸ¤ Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome contributions from the community! Whether you're a beginner or an expert, your examples and tutorials can help others learn and grow. Here's how you can contribute:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Submit a Pull Request with your LLM application example&lt;/li&gt; 
 &lt;li&gt;Add detailed documentation and setup instructions&lt;/li&gt; 
 &lt;li&gt;Include requirements.txt or environment.yml&lt;/li&gt; 
 &lt;li&gt;Share your experience and best practices&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;ğŸ“œ License&lt;/h2&gt; 
&lt;p&gt;This repository is licensed under the &lt;a href="https://raw.githubusercontent.com/Arindam200/awesome-ai-apps/main/LICENSE"&gt;MIT License&lt;/a&gt;. Feel free to use and modify the examples for your projects.&lt;/p&gt; 
&lt;h2&gt;Thank You for the Support! ğŸ™&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://www.star-history.com/#Arindam200/awesome-ai-apps&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=Arindam200/awesome-ai-apps&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>microsoft/BitNet</title>
      <link>https://github.com/microsoft/BitNet</link>
      <description>&lt;p&gt;Official inference framework for 1-bit LLMs&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;bitnet.cpp&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://opensource.org/licenses/MIT"&gt;&lt;img src="https://img.shields.io/badge/license-MIT-blue.svg?sanitize=true" alt="License: MIT" /&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/badge/version-1.0-blue" alt="version" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://huggingface.co/microsoft/BitNet-b1.58-2B-4T"&gt;&lt;img src="https://raw.githubusercontent.com/microsoft/BitNet/main/assets/header_model_release.png" alt="BitNet Model on Hugging Face" width="800" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Try it out via this &lt;a href="https://bitnet-demo.azurewebsites.net/"&gt;demo&lt;/a&gt;, or build and run it on your own &lt;a href="https://github.com/microsoft/BitNet?tab=readme-ov-file#build-from-source"&gt;CPU&lt;/a&gt; or &lt;a href="https://github.com/microsoft/BitNet/raw/main/gpu/README.md"&gt;GPU&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;bitnet.cpp is the official inference framework for 1-bit LLMs (e.g., BitNet b1.58). It offers a suite of optimized kernels, that support &lt;strong&gt;fast&lt;/strong&gt; and &lt;strong&gt;lossless&lt;/strong&gt; inference of 1.58-bit models on CPU and GPU (NPU support will coming next).&lt;/p&gt; 
&lt;p&gt;The first release of bitnet.cpp is to support inference on CPUs. bitnet.cpp achieves speedups of &lt;strong&gt;1.37x&lt;/strong&gt; to &lt;strong&gt;5.07x&lt;/strong&gt; on ARM CPUs, with larger models experiencing greater performance gains. Additionally, it reduces energy consumption by &lt;strong&gt;55.4%&lt;/strong&gt; to &lt;strong&gt;70.0%&lt;/strong&gt;, further boosting overall efficiency. On x86 CPUs, speedups range from &lt;strong&gt;2.37x&lt;/strong&gt; to &lt;strong&gt;6.17x&lt;/strong&gt; with energy reductions between &lt;strong&gt;71.9%&lt;/strong&gt; to &lt;strong&gt;82.2%&lt;/strong&gt;. Furthermore, bitnet.cpp can run a 100B BitNet b1.58 model on a single CPU, achieving speeds comparable to human reading (5-7 tokens per second), significantly enhancing the potential for running LLMs on local devices. Please refer to the &lt;a href="https://arxiv.org/abs/2410.16144"&gt;technical report&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;img src="https://raw.githubusercontent.com/microsoft/BitNet/main/assets/m2_performance.jpg" alt="m2_performance" width="800" /&gt; 
&lt;img src="https://raw.githubusercontent.com/microsoft/BitNet/main/assets/intel_performance.jpg" alt="m2_performance" width="800" /&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;The tested models are dummy setups used in a research context to demonstrate the inference performance of bitnet.cpp.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Demo&lt;/h2&gt; 
&lt;p&gt;A demo of bitnet.cpp running a BitNet b1.58 3B model on Apple M2:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/7f46b736-edec-4828-b809-4be780a3e5b1"&gt;https://github.com/user-attachments/assets/7f46b736-edec-4828-b809-4be780a3e5b1&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;What's New:&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;05/20/2025 &lt;a href="https://github.com/microsoft/BitNet/raw/main/gpu/README.md"&gt;BitNet Official GPU inference kernel&lt;/a&gt; &lt;img src="https://img.shields.io/badge/NEW-red" alt="NEW" /&gt;&lt;/li&gt; 
 &lt;li&gt;04/14/2025 &lt;a href="https://huggingface.co/microsoft/BitNet-b1.58-2B-4T"&gt;BitNet Official 2B Parameter Model on Hugging Face&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;02/18/2025 &lt;a href="https://arxiv.org/abs/2502.11880"&gt;Bitnet.cpp: Efficient Edge Inference for Ternary LLMs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;11/08/2024 &lt;a href="https://arxiv.org/abs/2411.04965"&gt;BitNet a4.8: 4-bit Activations for 1-bit LLMs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;10/21/2024 &lt;a href="https://arxiv.org/abs/2410.16144"&gt;1-bit AI Infra: Part 1.1, Fast and Lossless BitNet b1.58 Inference on CPUs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;10/17/2024 bitnet.cpp 1.0 released.&lt;/li&gt; 
 &lt;li&gt;03/21/2024 &lt;a href="https://github.com/microsoft/unilm/raw/master/bitnet/The-Era-of-1-bit-LLMs__Training_Tips_Code_FAQ.pdf"&gt;The-Era-of-1-bit-LLMs__Training_Tips_Code_FAQ&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;02/27/2024 &lt;a href="https://arxiv.org/abs/2402.17764"&gt;The Era of 1-bit LLMs: All Large Language Models are in 1.58 Bits&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;10/17/2023 &lt;a href="https://arxiv.org/abs/2310.11453"&gt;BitNet: Scaling 1-bit Transformers for Large Language Models&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Acknowledgements&lt;/h2&gt; 
&lt;p&gt;This project is based on the &lt;a href="https://github.com/ggerganov/llama.cpp"&gt;llama.cpp&lt;/a&gt; framework. We would like to thank all the authors for their contributions to the open-source community. Also, bitnet.cpp's kernels are built on top of the Lookup Table methodologies pioneered in &lt;a href="https://github.com/microsoft/T-MAC/"&gt;T-MAC&lt;/a&gt;. For inference of general low-bit LLMs beyond ternary models, we recommend using T-MAC.&lt;/p&gt; 
&lt;h2&gt;Official Models&lt;/h2&gt; 
&lt;table&gt;  
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;th rowspan="2"&gt;Model&lt;/th&gt; 
   &lt;th rowspan="2"&gt;Parameters&lt;/th&gt; 
   &lt;th rowspan="2"&gt;CPU&lt;/th&gt; 
   &lt;th colspan="3"&gt;Kernel&lt;/th&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;th&gt;I2_S&lt;/th&gt; 
   &lt;th&gt;TL1&lt;/th&gt; 
   &lt;th&gt;TL2&lt;/th&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td rowspan="2"&gt;&lt;a href="https://huggingface.co/microsoft/BitNet-b1.58-2B-4T"&gt;BitNet-b1.58-2B-4T&lt;/a&gt;&lt;/td&gt; 
   &lt;td rowspan="2"&gt;2.4B&lt;/td&gt; 
   &lt;td&gt;x86&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âŒ&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ARM&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âŒ&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h2&gt;Supported Models&lt;/h2&gt; 
&lt;p&gt;â—ï¸&lt;strong&gt;We use existing 1-bit LLMs available on &lt;a href="https://huggingface.co/"&gt;Hugging Face&lt;/a&gt; to demonstrate the inference capabilities of bitnet.cpp. We hope the release of bitnet.cpp will inspire the development of 1-bit LLMs in large-scale settings in terms of model size and training tokens.&lt;/strong&gt;&lt;/p&gt; 
&lt;table&gt;  
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;th rowspan="2"&gt;Model&lt;/th&gt; 
   &lt;th rowspan="2"&gt;Parameters&lt;/th&gt; 
   &lt;th rowspan="2"&gt;CPU&lt;/th&gt; 
   &lt;th colspan="3"&gt;Kernel&lt;/th&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;th&gt;I2_S&lt;/th&gt; 
   &lt;th&gt;TL1&lt;/th&gt; 
   &lt;th&gt;TL2&lt;/th&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td rowspan="2"&gt;&lt;a href="https://huggingface.co/1bitLLM/bitnet_b1_58-large"&gt;bitnet_b1_58-large&lt;/a&gt;&lt;/td&gt; 
   &lt;td rowspan="2"&gt;0.7B&lt;/td&gt; 
   &lt;td&gt;x86&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âŒ&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ARM&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âŒ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td rowspan="2"&gt;&lt;a href="https://huggingface.co/1bitLLM/bitnet_b1_58-3B"&gt;bitnet_b1_58-3B&lt;/a&gt;&lt;/td&gt; 
   &lt;td rowspan="2"&gt;3.3B&lt;/td&gt; 
   &lt;td&gt;x86&lt;/td&gt; 
   &lt;td&gt;âŒ&lt;/td&gt; 
   &lt;td&gt;âŒ&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ARM&lt;/td&gt; 
   &lt;td&gt;âŒ&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âŒ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td rowspan="2"&gt;&lt;a href="https://huggingface.co/HF1BitLLM/Llama3-8B-1.58-100B-tokens"&gt;Llama3-8B-1.58-100B-tokens&lt;/a&gt;&lt;/td&gt; 
   &lt;td rowspan="2"&gt;8.0B&lt;/td&gt; 
   &lt;td&gt;x86&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âŒ&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ARM&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âŒ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td rowspan="2"&gt;&lt;a href="https://huggingface.co/collections/tiiuae/falcon3-67605ae03578be86e4e87026"&gt;Falcon3 Family&lt;/a&gt;&lt;/td&gt; 
   &lt;td rowspan="2"&gt;1B-10B&lt;/td&gt; 
   &lt;td&gt;x86&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âŒ&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ARM&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âŒ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td rowspan="2"&gt;&lt;a href="https://huggingface.co/collections/tiiuae/falcon-edge-series-6804fd13344d6d8a8fa71130"&gt;Falcon-E Family&lt;/a&gt;&lt;/td&gt; 
   &lt;td rowspan="2"&gt;1B-3B&lt;/td&gt; 
   &lt;td&gt;x86&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âŒ&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ARM&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âŒ&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;h3&gt;Requirements&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;python&amp;gt;=3.9&lt;/li&gt; 
 &lt;li&gt;cmake&amp;gt;=3.22&lt;/li&gt; 
 &lt;li&gt;clang&amp;gt;=18 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;For Windows users, install &lt;a href="https://visualstudio.microsoft.com/downloads/"&gt;Visual Studio 2022&lt;/a&gt;. In the installer, toggle on at least the following options(this also automatically installs the required additional tools like CMake):&lt;/p&gt; 
    &lt;ul&gt; 
     &lt;li&gt;Desktop-development with C++&lt;/li&gt; 
     &lt;li&gt;C++-CMake Tools for Windows&lt;/li&gt; 
     &lt;li&gt;Git for Windows&lt;/li&gt; 
     &lt;li&gt;C++-Clang Compiler for Windows&lt;/li&gt; 
     &lt;li&gt;MS-Build Support for LLVM-Toolset (clang)&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;For Debian/Ubuntu users, you can download with &lt;a href="https://apt.llvm.org/"&gt;Automatic installation script&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;bash -c "$(wget -O - https://apt.llvm.org/llvm.sh)"&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;conda (highly recommend)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Build from source&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] If you are using Windows, please remember to always use a Developer Command Prompt / PowerShell for VS2022 for the following commands. Please refer to the FAQs below if you see any issues.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ol&gt; 
 &lt;li&gt;Clone the repo&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone --recursive https://github.com/microsoft/BitNet.git
cd BitNet
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Install the dependencies&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# (Recommended) Create a new conda environment
conda create -n bitnet-cpp python=3.9
conda activate bitnet-cpp

pip install -r requirements.txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt;Build the project&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Manually download the model and run with local path
huggingface-cli download microsoft/BitNet-b1.58-2B-4T-gguf --local-dir models/BitNet-b1.58-2B-4T
python setup_env.py -md models/BitNet-b1.58-2B-4T -q i2_s

&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;
usage: setup_env.py [-h] [--hf-repo {1bitLLM/bitnet_b1_58-large,1bitLLM/bitnet_b1_58-3B,HF1BitLLM/Llama3-8B-1.58-100B-tokens,tiiuae/Falcon3-1B-Instruct-1.58bit,tiiuae/Falcon3-3B-Instruct-1.58bit,tiiuae/Falcon3-7B-Instruct-1.58bit,tiiuae/Falcon3-10B-Instruct-1.58bit}] [--model-dir MODEL_DIR] [--log-dir LOG_DIR] [--quant-type {i2_s,tl1}] [--quant-embd]
                    [--use-pretuned]

Setup the environment for running inference

optional arguments:
  -h, --help            show this help message and exit
  --hf-repo {1bitLLM/bitnet_b1_58-large,1bitLLM/bitnet_b1_58-3B,HF1BitLLM/Llama3-8B-1.58-100B-tokens,tiiuae/Falcon3-1B-Instruct-1.58bit,tiiuae/Falcon3-3B-Instruct-1.58bit,tiiuae/Falcon3-7B-Instruct-1.58bit,tiiuae/Falcon3-10B-Instruct-1.58bit}, -hr {1bitLLM/bitnet_b1_58-large,1bitLLM/bitnet_b1_58-3B,HF1BitLLM/Llama3-8B-1.58-100B-tokens,tiiuae/Falcon3-1B-Instruct-1.58bit,tiiuae/Falcon3-3B-Instruct-1.58bit,tiiuae/Falcon3-7B-Instruct-1.58bit,tiiuae/Falcon3-10B-Instruct-1.58bit}
                        Model used for inference
  --model-dir MODEL_DIR, -md MODEL_DIR
                        Directory to save/load the model
  --log-dir LOG_DIR, -ld LOG_DIR
                        Directory to save the logging info
  --quant-type {i2_s,tl1}, -q {i2_s,tl1}
                        Quantization type
  --quant-embd          Quantize the embeddings to f16
  --use-pretuned, -p    Use the pretuned kernel parameters
&lt;/pre&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;h3&gt;Basic usage&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Run inference with the quantized model
python run_inference.py -m models/BitNet-b1.58-2B-4T/ggml-model-i2_s.gguf -p "You are a helpful assistant" -cnv
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;
usage: run_inference.py [-h] [-m MODEL] [-n N_PREDICT] -p PROMPT [-t THREADS] [-c CTX_SIZE] [-temp TEMPERATURE] [-cnv]

Run inference

optional arguments:
  -h, --help            show this help message and exit
  -m MODEL, --model MODEL
                        Path to model file
  -n N_PREDICT, --n-predict N_PREDICT
                        Number of tokens to predict when generating text
  -p PROMPT, --prompt PROMPT
                        Prompt to generate text from
  -t THREADS, --threads THREADS
                        Number of threads to use
  -c CTX_SIZE, --ctx-size CTX_SIZE
                        Size of the prompt context
  -temp TEMPERATURE, --temperature TEMPERATURE
                        Temperature, a hyperparameter that controls the randomness of the generated text
  -cnv, --conversation  Whether to enable chat mode or not (for instruct models.)
                        (When this option is turned on, the prompt specified by -p will be used as the system prompt.)
&lt;/pre&gt; 
&lt;h3&gt;Benchmark&lt;/h3&gt; 
&lt;p&gt;We provide scripts to run the inference benchmark providing a model.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;usage: e2e_benchmark.py -m MODEL [-n N_TOKEN] [-p N_PROMPT] [-t THREADS]  
   
Setup the environment for running the inference  
   
required arguments:  
  -m MODEL, --model MODEL  
                        Path to the model file. 
   
optional arguments:  
  -h, --help  
                        Show this help message and exit. 
  -n N_TOKEN, --n-token N_TOKEN  
                        Number of generated tokens. 
  -p N_PROMPT, --n-prompt N_PROMPT  
                        Prompt to generate text from. 
  -t THREADS, --threads THREADS  
                        Number of threads to use. 
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Here's a brief explanation of each argument:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;-m&lt;/code&gt;, &lt;code&gt;--model&lt;/code&gt;: The path to the model file. This is a required argument that must be provided when running the script.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-n&lt;/code&gt;, &lt;code&gt;--n-token&lt;/code&gt;: The number of tokens to generate during the inference. It is an optional argument with a default value of 128.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-p&lt;/code&gt;, &lt;code&gt;--n-prompt&lt;/code&gt;: The number of prompt tokens to use for generating text. This is an optional argument with a default value of 512.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-t&lt;/code&gt;, &lt;code&gt;--threads&lt;/code&gt;: The number of threads to use for running the inference. It is an optional argument with a default value of 2.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-h&lt;/code&gt;, &lt;code&gt;--help&lt;/code&gt;: Show the help message and exit. Use this argument to display usage information.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;python utils/e2e_benchmark.py -m /path/to/model -n 200 -p 256 -t 4  
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This command would run the inference benchmark using the model located at &lt;code&gt;/path/to/model&lt;/code&gt;, generating 200 tokens from a 256 token prompt, utilizing 4 threads.&lt;/p&gt; 
&lt;p&gt;For the model layout that do not supported by any public model, we provide scripts to generate a dummy model with the given model layout, and run the benchmark on your machine:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python utils/generate-dummy-bitnet-model.py models/bitnet_b1_58-large --outfile models/dummy-bitnet-125m.tl1.gguf --outtype tl1 --model-size 125M

# Run benchmark with the generated model, use -m to specify the model path, -p to specify the prompt processed, -n to specify the number of token to generate
python utils/e2e_benchmark.py -m models/dummy-bitnet-125m.tl1.gguf -p 512 -n 128
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Convert from &lt;code&gt;.safetensors&lt;/code&gt; Checkpoints&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;# Prepare the .safetensors model file
huggingface-cli download microsoft/bitnet-b1.58-2B-4T-bf16 --local-dir ./models/bitnet-b1.58-2B-4T-bf16

# Convert to gguf model
python ./utils/convert-helper-bitnet.py ./models/bitnet-b1.58-2B-4T-bf16
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;FAQ (Frequently Asked Questions)ğŸ“Œ&lt;/h3&gt; 
&lt;h4&gt;Q1: The build dies with errors building llama.cpp due to issues with std::chrono in log.cpp?&lt;/h4&gt; 
&lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt; This is an issue introduced in recent version of llama.cpp. Please refer to this &lt;a href="https://github.com/tinglou/llama.cpp/commit/4e3db1e3d78cc1bcd22bcb3af54bd2a4628dd323"&gt;commit&lt;/a&gt; in the &lt;a href="https://github.com/abetlen/llama-cpp-python/issues/1942"&gt;discussion&lt;/a&gt; to fix this issue.&lt;/p&gt; 
&lt;h4&gt;Q2: How to build with clang in conda environment on windows?&lt;/h4&gt; 
&lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt; Before building the project, verify your clang installation and access to Visual Studio tools by running:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;clang -v
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This command checks that you are using the correct version of clang and that the Visual Studio tools are available. If you see an error message such as:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;'clang' is not recognized as an internal or external command, operable program or batch file.
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;It indicates that your command line window is not properly initialized for Visual Studio tools.&lt;/p&gt; 
&lt;p&gt;â€¢ If you are using Command Prompt, run:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;"C:\Program Files\Microsoft Visual Studio\2022\Professional\Common7\Tools\VsDevCmd.bat" -startdir=none -arch=x64 -host_arch=x64
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;â€¢ If you are using Windows PowerShell, run the following commands:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Import-Module "C:\Program Files\Microsoft Visual Studio\2022\Professional\Common7\Tools\Microsoft.VisualStudio.DevShell.dll" Enter-VsDevShell 3f0e31ad -SkipAutomaticLocation -DevCmdArguments "-arch=x64 -host_arch=x64"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;These steps will initialize your environment and allow you to use the correct Visual Studio tools.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>EbookFoundation/free-programming-books</title>
      <link>https://github.com/EbookFoundation/free-programming-books</link>
      <description>&lt;p&gt;ğŸ“š Freely available programming books&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;List of Free Learning Resources In Many Languages&lt;/h1&gt; 
&lt;div align="center" markdown="1"&gt; 
 &lt;p&gt;&lt;a href="https://github.com/sindresorhus/awesome"&gt;&lt;img src="https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg?sanitize=true" alt="Awesome" /&gt;&lt;/a&gt;&amp;nbsp; &lt;a href="https://creativecommons.org/licenses/by/4.0/"&gt;&lt;img src="https://img.shields.io/badge/License-CC%20BY%204.0-lightgrey.svg?sanitize=true" alt="License: CC BY 4.0" /&gt;&lt;/a&gt;&amp;nbsp; &lt;a href="https://github.com/EbookFoundation/free-programming-books/pulls?q=is%3Apr+is%3Amerged+created%3A2023-10-01..2023-10-31"&gt;&lt;img src="https://img.shields.io/github/hacktoberfest/2023/EbookFoundation/free-programming-books?label=Hacktoberfest+2023" alt="Hacktoberfest 2023 stats" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;Search the list at &lt;a href="https://ebookfoundation.github.io/free-programming-books-search/"&gt;https://ebookfoundation.github.io/free-programming-books-search/&lt;/a&gt; &lt;a href="https://ebookfoundation.github.io/free-programming-books-search/"&gt;&lt;img src="https://img.shields.io/website?style=flat&amp;amp;logo=www&amp;amp;logoColor=whitesmoke&amp;amp;label=Dynamic%20search%20site&amp;amp;down_color=red&amp;amp;down_message=down&amp;amp;up_color=green&amp;amp;up_message=up&amp;amp;url=https%3A%2F%2Febookfoundation.github.io%2Ffree-programming-books-search%2F" alt="https://ebookfoundation.github.io/free-programming-books-search/" /&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;This page is available as an easy-to-read website. Access it by clicking on &lt;a href="https://ebookfoundation.github.io/free-programming-books/"&gt;&lt;img src="https://img.shields.io/website?style=flat&amp;amp;logo=www&amp;amp;logoColor=whitesmoke&amp;amp;label=Static%20site&amp;amp;down_color=red&amp;amp;down_message=down&amp;amp;up_color=green&amp;amp;up_message=up&amp;amp;url=https%3A%2F%2Febookfoundation.github.io%2Ffree-programming-books%2F" alt="https://ebookfoundation.github.io/free-programming-books/" /&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;form action="https://ebookfoundation.github.io/free-programming-books-search"&gt; 
  &lt;input type="text" id="fpbSearch" name="search" required placeholder="Search Book or Author" /&gt; 
  &lt;label for="submit"&gt; &lt;/label&gt; 
  &lt;input type="submit" id="submit" name="submit" value="Search" /&gt; 
 &lt;/form&gt; 
&lt;/div&gt; 
&lt;h2&gt;Intro&lt;/h2&gt; 
&lt;p&gt;This list was originally a clone of &lt;a href="https://web.archive.org/web/20140606191453/http://stackoverflow.com/questions/194812/list-of-freely-available-programming-books/392926"&gt;StackOverflow - List of Freely Available Programming Books&lt;/a&gt; with contributions from Karan Bhangui and George Stocker.&lt;/p&gt; 
&lt;p&gt;The list was moved to GitHub by Victor Felder for collaborative updating and maintenance. It has grown to become one of &lt;a href="https://octoverse.github.com/"&gt;GitHub's most popular repositories&lt;/a&gt;.&lt;/p&gt; 
&lt;div align="center" markdown="1"&gt; 
 &lt;p&gt;&lt;a href="https://github.com/EbookFoundation/free-programming-books/network"&gt;&lt;img src="https://img.shields.io/github/forks/EbookFoundation/free-programming-books?style=flat&amp;amp;logo=github&amp;amp;logoColor=whitesmoke&amp;amp;label=Forks" alt="GitHub repo forks" /&gt;&lt;/a&gt;&amp;nbsp; &lt;a href="https://github.com/EbookFoundation/free-programming-books/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/EbookFoundation/free-programming-books?style=flat&amp;amp;logo=github&amp;amp;logoColor=whitesmoke&amp;amp;label=Stars" alt="GitHub repo stars" /&gt;&lt;/a&gt;&amp;nbsp; &lt;a href="https://github.com/EbookFoundation/free-programming-books/graphs/contributors"&gt;&lt;img src="https://img.shields.io/github/contributors-anon/EbookFoundation/free-programming-books?style=flat&amp;amp;logo=github&amp;amp;logoColor=whitesmoke&amp;amp;label=Contributors" alt="GitHub repo contributors" /&gt;&lt;/a&gt;&lt;br /&gt; &lt;a href="https://github.com/sponsors/EbookFoundation"&gt;&lt;img src="https://img.shields.io/github/sponsors/EbookFoundation?style=flat&amp;amp;logo=github&amp;amp;logoColor=whitesmoke&amp;amp;label=Sponsors" alt="GitHub org sponsors" /&gt;&lt;/a&gt;&amp;nbsp; &lt;a href="https://github.com/EbookFoundation/free-programming-books/watchers"&gt;&lt;img src="https://img.shields.io/github/watchers/EbookFoundation/free-programming-books?style=flat&amp;amp;logo=github&amp;amp;logoColor=whitesmoke&amp;amp;label=Watchers" alt="GitHub repo watchers" /&gt;&lt;/a&gt;&amp;nbsp; &lt;a href="https://github.com/EbookFoundation/free-programming-books/archive/refs/heads/main.zip"&gt;&lt;img src="https://img.shields.io/github/repo-size/EbookFoundation/free-programming-books?style=flat&amp;amp;logo=github&amp;amp;logoColor=whitesmoke&amp;amp;label=Repo%20Size" alt="GitHub repo size" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;The &lt;a href="https://ebookfoundation.org"&gt;Free Ebook Foundation&lt;/a&gt; now administers the repo, a not-for-profit organization devoted to promoting the creation, distribution, archiving, and sustainability of free ebooks. &lt;a href="https://ebookfoundation.org/contributions.html"&gt;Donations&lt;/a&gt; to the Free Ebook Foundation are tax-deductible in the US.&lt;/p&gt; 
&lt;h2&gt;How To Contribute&lt;/h2&gt; 
&lt;p&gt;Please read &lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/docs/CONTRIBUTING.md"&gt;CONTRIBUTING&lt;/a&gt;. If you're new to GitHub, &lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/docs/HOWTO.md"&gt;welcome&lt;/a&gt;! Remember to abide by our adapted from &lt;img src="https://img.shields.io/badge/Contributor%20Covenant-1.3-4baaaa.svg?sanitize=true" alt="Contributor Covenant 1.3" /&gt; &lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/docs/CODE_OF_CONDUCT.md"&gt;Code of Conduct&lt;/a&gt; too (&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/#translations"&gt;translations&lt;/a&gt; also available).&lt;/p&gt; 
&lt;p&gt;Click on these badges to see how you might be able to help:&lt;/p&gt; 
&lt;div align="center" markdown="1"&gt; 
 &lt;p&gt;&lt;a href="https://github.com/EbookFoundation/free-programming-books/issues"&gt;&lt;img src="https://img.shields.io/github/issues/EbookFoundation/free-programming-books?style=flat&amp;amp;logo=github&amp;amp;logoColor=red&amp;amp;label=Issues" alt="GitHub repo Issues" /&gt;&lt;/a&gt;&amp;nbsp; &lt;a href="https://github.com/EbookFoundation/free-programming-books/issues?q=is%3Aopen+is%3Aissue+label%3A%22good+first+issue%22"&gt;&lt;img src="https://img.shields.io/github/issues/EbookFoundation/free-programming-books/good%20first%20issue?style=flat&amp;amp;logo=github&amp;amp;logoColor=green&amp;amp;label=Good%20First%20issues" alt="GitHub repo Good Issues for newbies" /&gt;&lt;/a&gt;&amp;nbsp; &lt;a href="https://github.com/EbookFoundation/free-programming-books/issues?q=is%3Aopen+is%3Aissue+label%3A%22help+wanted%22"&gt;&lt;img src="https://img.shields.io/github/issues/EbookFoundation/free-programming-books/help%20wanted?style=flat&amp;amp;logo=github&amp;amp;logoColor=b545d1&amp;amp;label=%22Help%20Wanted%22%20issues" alt="GitHub Help Wanted issues" /&gt;&lt;/a&gt;&lt;br /&gt; &lt;a href="https://github.com/EbookFoundation/free-programming-books/pulls"&gt;&lt;img src="https://img.shields.io/github/issues-pr/EbookFoundation/free-programming-books?style=flat&amp;amp;logo=github&amp;amp;logoColor=orange&amp;amp;label=PRs" alt="GitHub repo PRs" /&gt;&lt;/a&gt;&amp;nbsp; &lt;a href="https://github.com/EbookFoundation/free-programming-books/pulls?q=is%3Apr+is%3Amerged"&gt;&lt;img src="https://img.shields.io/github/issues-search/EbookFoundation/free-programming-books?style=flat&amp;amp;logo=github&amp;amp;logoColor=green&amp;amp;label=Merged%20PRs&amp;amp;query=is%3Amerged" alt="GitHub repo Merged PRs" /&gt;&lt;/a&gt;&amp;nbsp; &lt;a href="https://github.com/EbookFoundation/free-programming-books/pulls?q=is%3Aopen+is%3Aissue+label%3A%22help+wanted%22"&gt;&lt;img src="https://img.shields.io/github/issues-pr/EbookFoundation/free-programming-books/help%20wanted?style=flat&amp;amp;logo=github&amp;amp;logoColor=b545d1&amp;amp;label=%22Help%20Wanted%22%20PRs" alt="GitHub Help Wanted PRs" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;How To Share&lt;/h2&gt; 
&lt;div align="left" markdown="1"&gt; 
 &lt;a href="https://www.facebook.com/share.php?u=https%3A%2F%2Fgithub.com%2FEbookFoundation%2Ffree-programming-books&amp;amp;p%5Bimages%5D%5B0%5D=&amp;amp;p%5Btitle%5D=Free%20Programming%20Books&amp;amp;p%5Bsummary%5D="&gt;Share on Facebook&lt;/a&gt;
 &lt;br /&gt; 
 &lt;a href="http://www.linkedin.com/shareArticle?mini=true&amp;amp;url=https://github.com/EbookFoundation/free-programming-books&amp;amp;title=Free%20Programming%20Books&amp;amp;summary=&amp;amp;source="&gt;Share on LinkedIn&lt;/a&gt;
 &lt;br /&gt; 
 &lt;a href="https://toot.kytta.dev/?mini=true&amp;amp;url=https://github.com/EbookFoundation/free-programming-books&amp;amp;title=Free%20Programming%20Books&amp;amp;summary=&amp;amp;source="&gt;Share on Mastodon/Fediverse&lt;/a&gt;
 &lt;br /&gt; 
 &lt;a href="https://t.me/share/url?url=https://github.com/EbookFoundation/free-programming-books"&gt;Share on Telegram&lt;/a&gt;
 &lt;br /&gt; 
 &lt;a href="https://twitter.com/intent/tweet?text=https://github.com/EbookFoundation/free-programming-books%0AFree%20Programming%20Books"&gt;Share on ğ• (Twitter)&lt;/a&gt;
 &lt;br /&gt; 
&lt;/div&gt; 
&lt;h2&gt;Resources&lt;/h2&gt; 
&lt;p&gt;This project lists books and other resources grouped by genres:&lt;/p&gt; 
&lt;h3&gt;Books&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-langs.md"&gt;English, By Programming Language&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-subjects.md"&gt;English, By Subject&lt;/a&gt;&lt;/p&gt; 
&lt;h4&gt;Other Languages&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-ar.md"&gt;Arabic / al arabiya / Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-hy.md"&gt;Armenian / Õ€Õ¡ÕµÕ¥Ö€Õ¥Õ¶&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-az.md"&gt;Azerbaijani / ĞĞ·Ó™Ñ€Ğ±Ğ°Ñ˜Ò¹Ğ°Ğ½ Ğ´Ğ¸Ğ»Ğ¸ / Ø¢Ø°Ø±Ø¨Ø§ÙŠØ¬Ø§Ù†Ø¬Ø§ Ø¯ÙŠÙ„ÙŠ&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-bn.md"&gt;Bengali / à¦¬à¦¾à¦‚à¦²à¦¾&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-bg.md"&gt;Bulgarian / Ğ±ÑŠĞ»Ğ³Ğ°Ñ€ÑĞºĞ¸&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-my.md"&gt;Burmese / á€™á€¼á€”á€ºá€™á€¬á€˜á€¬á€á€¬&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-zh.md"&gt;Chinese / ä¸­æ–‡&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-cs.md"&gt;Czech / ÄeÅ¡tina / ÄeskÃ½ jazyk&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-ca.md"&gt;Catalan / catalan/ catalÃ &lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-da.md"&gt;Danish / dansk&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-nl.md"&gt;Dutch / Nederlands&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-et.md"&gt;Estonian / eesti keel&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-fi.md"&gt;Finnish / suomi / suomen kieli&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-fr.md"&gt;French / franÃ§ais&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-de.md"&gt;German / Deutsch&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-el.md"&gt;Greek / ÎµÎ»Î»Î·Î½Î¹ÎºÎ¬&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-he.md"&gt;Hebrew / ×¢×‘×¨×™×ª&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-hi.md"&gt;Hindi / à¤¹à¤¿à¤¨à¥à¤¦à¥€&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-hu.md"&gt;Hungarian / magyar / magyar nyelv&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-id.md"&gt;Indonesian / Bahasa Indonesia&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-it.md"&gt;Italian / italiano&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-ja.md"&gt;Japanese / æ—¥æœ¬èª&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-ko.md"&gt;Korean / í•œêµ­ì–´&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-lv.md"&gt;Latvian / LatvieÅ¡u&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-ml.md"&gt;Malayalam / à´®à´²à´¯à´¾à´³à´‚&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-no.md"&gt;Norwegian / Norsk&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-fa_IR.md"&gt;Persian / Farsi (Iran) / ÙØ§Ø±Ø³Ù‰&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-pl.md"&gt;Polish / polski / jÄ™zyk polski / polszczyzna&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-pt_BR.md"&gt;Portuguese (Brazil)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-pt_PT.md"&gt;Portuguese (Portugal)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-ro.md"&gt;Romanian (Romania) / limba romÃ¢nÄƒ / romÃ¢n&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-ru.md"&gt;Russian / Ğ ÑƒÑÑĞºĞ¸Ğ¹ ÑĞ·Ñ‹Ğº&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-sr.md"&gt;Serbian / ÑÑ€Ğ¿ÑĞºĞ¸ Ñ˜ĞµĞ·Ğ¸Ğº / srpski jezik&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-sk.md"&gt;Slovak / slovenÄina&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-es.md"&gt;Spanish / espaÃ±ol / castellano&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-sv.md"&gt;Swedish / Svenska&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-ta.md"&gt;Tamil / à®¤à®®à®¿à®´à¯&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-te.md"&gt;Telugu / à°¤à±†à°²à±à°—à±&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-th.md"&gt;Thai / à¹„à¸—à¸¢&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-tr.md"&gt;Turkish / TÃ¼rkÃ§e&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-uk.md"&gt;Ukrainian / Ğ£ĞºÑ€Ğ°Ñ—Ğ½ÑÑŒĞºĞ°&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-vi.md"&gt;Vietnamese / Tiáº¿ng Viá»‡t&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Cheat Sheets&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/more/free-programming-cheatsheets.md"&gt;All Languages&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Free Online Courses&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-ar.md"&gt;Arabic / al arabiya / Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-bn.md"&gt;Bengali / à¦¬à¦¾à¦‚à¦²à¦¾&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-bg.md"&gt;Bulgarian / Ğ±ÑŠĞ»Ğ³Ğ°Ñ€ÑĞºĞ¸&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-my.md"&gt;Burmese / á€™á€¼á€”á€ºá€™á€¬á€˜á€¬á€á€¬&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-zh.md"&gt;Chinese / ä¸­æ–‡&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-en.md"&gt;English&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-fi.md"&gt;Finnish / suomi / suomen kieli&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-fr.md"&gt;French / franÃ§ais&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-de.md"&gt;German / Deutsch&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-el.md"&gt;Greek / ÎµÎ»Î»Î·Î½Î¹ÎºÎ¬&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-he.md"&gt;Hebrew / ×¢×‘×¨×™×ª&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-hi.md"&gt;Hindi / à¤¹à¤¿à¤‚à¤¦à¥€&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-id.md"&gt;Indonesian / Bahasa Indonesia&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-it.md"&gt;Italian / italiano&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-ja.md"&gt;Japanese / æ—¥æœ¬èª&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-kn.md"&gt;Kannada/à²•à²¨à³à²¨à²¡&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-kk.md"&gt;Kazakh / Ò›Ğ°Ğ·Ğ°Ò›ÑˆĞ°&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-km.md"&gt;Khmer / á—á¶áŸá¶ááŸ’á˜áŸ‚áš&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-ko.md"&gt;Korean / í•œêµ­ì–´&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-ml.md"&gt;Malayalam / à´®à´²à´¯à´¾à´³à´‚&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-mr.md"&gt;Marathi / à¤®à¤°à¤¾à¤ à¥€&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-ne.md"&gt;Nepali / à¤¨à¥‡à¤ªà¤¾à¤²à¥€&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-no.md"&gt;Norwegian / Norsk&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-fa_IR.md"&gt;Persian / Farsi (Iran) / ÙØ§Ø±Ø³Ù‰&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-pl.md"&gt;Polish / polski / jÄ™zyk polski / polszczyzna&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-pt_BR.md"&gt;Portuguese (Brazil)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-pt_PT.md"&gt;Portuguese (Portugal)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-ru.md"&gt;Russian / Ğ ÑƒÑÑĞºĞ¸Ğ¹ ÑĞ·Ñ‹Ğº&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-si.md"&gt;Sinhala / à·ƒà·’à¶‚à·„à¶½&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-es.md"&gt;Spanish / espaÃ±ol / castellano&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-sv.md"&gt;Swedish / svenska&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-ta.md"&gt;Tamil / à®¤à®®à®¿à®´à¯&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-te.md"&gt;Telugu / à°¤à±†à°²à±à°—à±&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-th.md"&gt;Thai / à¸ à¸²à¸©à¸²à¹„à¸—à¸¢&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-tr.md"&gt;Turkish / TÃ¼rkÃ§e&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-uk.md"&gt;Ukrainian / Ğ£ĞºÑ€Ğ°Ñ—Ğ½ÑÑŒĞºĞ°&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-ur.md"&gt;Urdu / Ø§Ø±Ø¯Ùˆ&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-vi.md"&gt;Vietnamese / Tiáº¿ng Viá»‡t&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Interactive Programming Resources&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/more/free-programming-interactive-tutorials-zh.md"&gt;Chinese / ä¸­æ–‡&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/more/free-programming-interactive-tutorials-en.md"&gt;English&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/more/free-programming-interactive-tutorials-de.md"&gt;German / Deutsch&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/more/free-programming-interactive-tutorials-ja.md"&gt;Japanese / æ—¥æœ¬èª&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/more/free-programming-interactive-tutorials-ru.md"&gt;Russian / Ğ ÑƒÑÑĞºĞ¸Ğ¹ ÑĞ·Ñ‹Ğº&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Problem Sets and Competitive Programming&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/more/problem-sets-competitive-programming.md"&gt;Problem Sets&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Podcast - Screencast&lt;/h3&gt; 
&lt;p&gt;Free Podcasts and Screencasts:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-ar.md"&gt;Arabic / al Arabiya / Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-my.md"&gt;Burmese / á€™á€¼á€”á€ºá€™á€¬á€˜á€¬á€á€¬&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-zh.md"&gt;Chinese / ä¸­æ–‡&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-cs.md"&gt;Czech / ÄeÅ¡tina / ÄeskÃ½ jazyk&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-nl.md"&gt;Dutch / Nederlands&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-en.md"&gt;English&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-fi.md"&gt;Finnish / Suomi&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-fr.md"&gt;French / franÃ§ais&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-de.md"&gt;German / Deutsch&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-he.md"&gt;Hebrew / ×¢×‘×¨×™×ª&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-id.md"&gt;Indonesian / Bahasa Indonesia&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-fa_IR.md"&gt;Persian / Farsi (Iran) / ÙØ§Ø±Ø³Ù‰&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-pl.md"&gt;Polish / polski / jÄ™zyk polski / polszczyzna&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-pt_BR.md"&gt;Portuguese (Brazil)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-pt_PT.md"&gt;Portuguese (Portugal)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-ru.md"&gt;Russian / Ğ ÑƒÑÑĞºĞ¸Ğ¹ ÑĞ·Ñ‹Ğº&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-si.md"&gt;Sinhala / à·ƒà·’à¶‚à·„à¶½&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-es.md"&gt;Spanish / espaÃ±ol / castellano&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-sv.md"&gt;Swedish / Svenska&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-tr.md"&gt;Turkish / TÃ¼rkÃ§e&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-uk.md"&gt;Ukrainian / Ğ£ĞºÑ€Ğ°Ñ—Ğ½ÑÑŒĞºĞ°&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Programming Playgrounds&lt;/h3&gt; 
&lt;p&gt;Write, compile, and run your code within a browser. Try it out!&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/more/free-programming-playgrounds-zh.md"&gt;Chinese / ä¸­æ–‡&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/more/free-programming-playgrounds.md"&gt;English&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/more/free-programming-playgrounds-de.md"&gt;German / Deutsch&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Translations&lt;/h2&gt; 
&lt;p&gt;Volunteers have translated many of our Contributing, How-to, and Code of Conduct documents into languages covered by our lists.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;English 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/docs/CODE_OF_CONDUCT.md"&gt;Code of Conduct&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/docs/CONTRIBUTING.md"&gt;Contributing&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/docs/HOWTO.md"&gt;How-to&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;... &lt;em&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/docs/README.md#translations"&gt;More languages&lt;/a&gt;&lt;/em&gt; ...&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;You might notice that there are &lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/docs/README.md#translations"&gt;some missing translations here&lt;/a&gt; - perhaps you would like to help out by &lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/docs/CONTRIBUTING.md#help-out-by-contributing-a-translation"&gt;contributing a translation&lt;/a&gt;?&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Each file included in this repository is licensed under the &lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/LICENSE"&gt;CC BY License&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>QuentinFuxa/WhisperLiveKit</title>
      <link>https://github.com/QuentinFuxa/WhisperLiveKit</link>
      <description>&lt;p&gt;Real-time &amp; local speech-to-text, translation, and speaker diarization. With server &amp; web UI.&lt;/p&gt;&lt;hr&gt;&lt;h1 align="center"&gt;WhisperLiveKit&lt;/h1&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/QuentinFuxa/WhisperLiveKit/refs/heads/main/demo.png" alt="WhisperLiveKit Demo" width="730" /&gt; &lt;/p&gt; 
&lt;p align="center"&gt;&lt;b&gt;Real-time, Fully Local Speech-to-Text with Speaker Identification&lt;/b&gt;&lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://pypi.org/project/whisperlivekit/"&gt;&lt;img alt="PyPI Version" src="https://img.shields.io/pypi/v/whisperlivekit?color=g" /&gt;&lt;/a&gt; &lt;a href="https://pepy.tech/project/whisperlivekit"&gt;&lt;img alt="PyPI Downloads" src="https://static.pepy.tech/personalized-badge/whisperlivekit?period=total&amp;amp;units=international_system&amp;amp;left_color=grey&amp;amp;right_color=brightgreen&amp;amp;left_text=installations" /&gt;&lt;/a&gt; &lt;a href="https://pypi.org/project/whisperlivekit/"&gt;&lt;img alt="Python Versions" src="https://img.shields.io/badge/python-3.9--3.13-dark_green" /&gt;&lt;/a&gt; &lt;a href="https://github.com/QuentinFuxa/WhisperLiveKit/raw/main/LICENSE"&gt;&lt;img alt="License" src="https://img.shields.io/badge/License-MIT/Dual Licensed-dark_green" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p&gt;Real-time speech transcription directly to your browser, with a ready-to-use backend+server and a simple frontend. âœ¨&lt;/p&gt; 
&lt;h4&gt;Powered by Leading Research:&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ufal/SimulStreaming"&gt;SimulStreaming&lt;/a&gt; (SOTA 2025) - Ultra-low latency transcription with AlignAtt policy&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ufal/whisper_streaming"&gt;WhisperStreaming&lt;/a&gt; (SOTA 2023) - Low latency transcription with LocalAgreement policy&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://arxiv.org/abs/2507.18446"&gt;Streaming Sortformer&lt;/a&gt; (SOTA 2025) - Advanced real-time speaker diarization&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/juanmc2005/diart"&gt;Diart&lt;/a&gt; (SOTA 2021) - Real-time speaker diarization&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/snakers4/silero-vad"&gt;Silero VAD&lt;/a&gt; (2024) - Enterprise-grade Voice Activity Detection&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Why not just run a simple Whisper model on every audio batch?&lt;/strong&gt; Whisper is designed for complete utterances, not real-time chunks. Processing small segments loses context, cuts off words mid-syllable, and produces poor transcription. WhisperLiveKit uses state-of-the-art simultaneous speech research for intelligent buffering and incremental processing.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Architecture&lt;/h3&gt; 
&lt;img alt="Architecture" src="https://raw.githubusercontent.com/QuentinFuxa/WhisperLiveKit/refs/heads/main/architecture.png" /&gt; 
&lt;p&gt;&lt;em&gt;The backend supports multiple concurrent users. Voice Activity Detection reduces overhead when no voice is detected.&lt;/em&gt;&lt;/p&gt; 
&lt;h3&gt;Installation &amp;amp; Quick Start&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install whisperlivekit
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;FFmpeg is required&lt;/strong&gt; and must be installed before using WhisperLiveKit&lt;/p&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;OS&lt;/th&gt; 
    &lt;th&gt;How to install&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;Ubuntu/Debian&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;sudo apt install ffmpeg&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;MacOS&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;brew install ffmpeg&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;Windows&lt;/td&gt; 
    &lt;td&gt;Download .exe from &lt;a href="https://ffmpeg.org/download.html"&gt;https://ffmpeg.org/download.html&lt;/a&gt; and add to PATH&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;Quick Start&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Start the transcription server:&lt;/strong&gt;&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;whisperlivekit-server --model base --language en
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Open your browser&lt;/strong&gt; and navigate to &lt;code&gt;http://localhost:8000&lt;/code&gt;. Start speaking and watch your words appear in real-time!&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;blockquote&gt; 
 &lt;ul&gt; 
  &lt;li&gt;See &lt;a href="https://github.com/QuentinFuxa/WhisperLiveKit/raw/main/whisperlivekit/simul_whisper/whisper/tokenizer.py"&gt;tokenizer.py&lt;/a&gt; for the list of all available languages.&lt;/li&gt; 
  &lt;li&gt;For HTTPS requirements, see the &lt;strong&gt;Parameters&lt;/strong&gt; section for SSL configuration options.&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;Optional Dependencies&lt;/h4&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Optional&lt;/th&gt; 
   &lt;th&gt;&lt;code&gt;pip install&lt;/code&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Speaker diarization with Sortformer&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;git+https://github.com/NVIDIA/NeMo.git@main#egg=nemo_toolkit[asr]&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Speaker diarization with Diart&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;diart&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Original Whisper backend&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;whisper&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Improved timestamps backend&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;whisper-timestamped&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Apple Silicon optimization backend&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;mlx-whisper&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;OpenAI API backend&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;openai&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;See &lt;strong&gt;Parameters &amp;amp; Configuration&lt;/strong&gt; below on how to use them.&lt;/p&gt; 
&lt;h3&gt;Usage Examples&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Command-line Interface&lt;/strong&gt;: Start the transcription server with various options:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Use better model than default (small)
whisperlivekit-server --model large-v3

# Advanced configuration with diarization and language
whisperlivekit-server --host 0.0.0.0 --port 8000 --model medium --diarization --language fr
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Python API Integration&lt;/strong&gt;: Check &lt;a href="https://github.com/QuentinFuxa/WhisperLiveKit/raw/main/whisperlivekit/basic_server.py"&gt;basic_server&lt;/a&gt; for a more complete example of how to use the functions and classes.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from whisperlivekit import TranscriptionEngine, AudioProcessor, parse_args
from fastapi import FastAPI, WebSocket, WebSocketDisconnect
from fastapi.responses import HTMLResponse
from contextlib import asynccontextmanager
import asyncio

transcription_engine = None

@asynccontextmanager
async def lifespan(app: FastAPI):
    global transcription_engine
    transcription_engine = TranscriptionEngine(model="medium", diarization=True, lan="en")
    yield

app = FastAPI(lifespan=lifespan)

async def handle_websocket_results(websocket: WebSocket, results_generator):
    async for response in results_generator:
        await websocket.send_json(response)
    await websocket.send_json({"type": "ready_to_stop"})

@app.websocket("/asr")
async def websocket_endpoint(websocket: WebSocket):
    global transcription_engine

    # Create a new AudioProcessor for each connection, passing the shared engine
    audio_processor = AudioProcessor(transcription_engine=transcription_engine)    
    results_generator = await audio_processor.create_tasks()
    results_task = asyncio.create_task(handle_websocket_results(websocket, results_generator))
    await websocket.accept()
    while True:
        message = await websocket.receive_bytes()
        await audio_processor.process_audio(message)        
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Frontend Implementation&lt;/strong&gt;: The package includes an HTML/JavaScript implementation &lt;a href="https://github.com/QuentinFuxa/WhisperLiveKit/raw/main/whisperlivekit/web/live_transcription.html"&gt;here&lt;/a&gt;. You can also import it using &lt;code&gt;from whisperlivekit import get_web_interface_html&lt;/code&gt; &amp;amp; &lt;code&gt;page = get_web_interface_html()&lt;/code&gt;&lt;/p&gt; 
&lt;h2&gt;Parameters &amp;amp; Configuration&lt;/h2&gt; 
&lt;p&gt;An important list of parameters can be changed. But what &lt;em&gt;should&lt;/em&gt; you change?&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;the &lt;code&gt;--model&lt;/code&gt; size. List and recommandations &lt;a href="https://github.com/QuentinFuxa/WhisperLiveKit/raw/main/available_models.md"&gt;here&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;the &lt;code&gt;--language&lt;/code&gt;. List &lt;a href="https://github.com/QuentinFuxa/WhisperLiveKit/raw/main/whisperlivekit/simul_whisper/whisper/tokenizer.py"&gt;here&lt;/a&gt;. If you use &lt;code&gt;auto&lt;/code&gt;, the model attempts to detect the language automatically, but it tends to bias towards English.&lt;/li&gt; 
 &lt;li&gt;the &lt;code&gt;--backend&lt;/code&gt; ? you can switch to &lt;code&gt;--backend faster-whisper&lt;/code&gt; if &lt;code&gt;simulstreaming&lt;/code&gt; does not work correctly or if you prefer to avoid the dual-license requirements.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--warmup-file&lt;/code&gt;, if you have one&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--host&lt;/code&gt;, &lt;code&gt;--port&lt;/code&gt;, &lt;code&gt;--ssl-certfile&lt;/code&gt;, &lt;code&gt;--ssl-keyfile&lt;/code&gt;, if you set up a server&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--diarization&lt;/code&gt;, if you want to use it.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The rest I don't recommend. But below are your options.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Parameter&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Default&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--model&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Whisper model size.&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;small&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--language&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Source language code or &lt;code&gt;auto&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;auto&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--task&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;transcribe&lt;/code&gt; or &lt;code&gt;translate&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;transcribe&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--backend&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Processing backend&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;simulstreaming&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--min-chunk-size&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Minimum audio chunk size (seconds)&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;1.0&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--no-vac&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Disable Voice Activity Controller&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;False&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--no-vad&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Disable Voice Activity Detection&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;False&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--warmup-file&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Audio file path for model warmup&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;jfk.wav&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--host&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Server host address&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;localhost&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--port&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Server port&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;8000&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--ssl-certfile&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Path to the SSL certificate file (for HTTPS support)&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;None&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--ssl-keyfile&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Path to the SSL private key file (for HTTPS support)&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;None&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;WhisperStreaming backend options&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Default&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--confidence-validation&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Use confidence scores for faster validation&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;False&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--buffer_trimming&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Buffer trimming strategy (&lt;code&gt;sentence&lt;/code&gt; or &lt;code&gt;segment&lt;/code&gt;)&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;segment&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;SimulStreaming backend options&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Default&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--frame-threshold&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;AlignAtt frame threshold (lower = faster, higher = more accurate)&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;25&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--beams&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Number of beams for beam search (1 = greedy decoding)&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;1&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--decoder&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Force decoder type (&lt;code&gt;beam&lt;/code&gt; or &lt;code&gt;greedy&lt;/code&gt;)&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;auto&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--audio-max-len&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Maximum audio buffer length (seconds)&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;30.0&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--audio-min-len&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Minimum audio length to process (seconds)&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;0.0&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--cif-ckpt-path&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Path to CIF model for word boundary detection&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;None&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--never-fire&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Never truncate incomplete words&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;False&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--init-prompt&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Initial prompt for the model&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;None&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--static-init-prompt&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Static prompt that doesn't scroll&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;None&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--max-context-tokens&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Maximum context tokens&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;None&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--model-path&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Direct path to .pt model file. Download it if not found&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;./base.pt&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--preloaded-model-count&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Optional. Number of models to preload in memory to speed up loading (set up to the expected number of concurrent users)&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;1&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Diarization options&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Default&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--diarization&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Enable speaker identification&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;False&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--diarization-backend&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;diart&lt;/code&gt; or &lt;code&gt;sortformer&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;sortformer&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--segmentation-model&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Hugging Face model ID for Diart segmentation model. &lt;a href="https://github.com/juanmc2005/diart/tree/main?tab=readme-ov-file#pre-trained-models"&gt;Available models&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;pyannote/segmentation-3.0&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--embedding-model&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Hugging Face model ID for Diart embedding model. &lt;a href="https://github.com/juanmc2005/diart/tree/main?tab=readme-ov-file#pre-trained-models"&gt;Available models&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;speechbrain/spkrec-ecapa-voxceleb&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;For diarization using Diart, you need access to pyannote.audio models:&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/pyannote/segmentation"&gt;Accept user conditions&lt;/a&gt; for the &lt;code&gt;pyannote/segmentation&lt;/code&gt; model&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/pyannote/segmentation-3.0"&gt;Accept user conditions&lt;/a&gt; for the &lt;code&gt;pyannote/segmentation-3.0&lt;/code&gt; model&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/pyannote/embedding"&gt;Accept user conditions&lt;/a&gt; for the &lt;code&gt;pyannote/embedding&lt;/code&gt; model&lt;/li&gt; 
  &lt;li&gt;Login with HuggingFace: &lt;code&gt;huggingface-cli login&lt;/code&gt;&lt;/li&gt; 
 &lt;/ol&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;ğŸš€ Deployment Guide&lt;/h3&gt; 
&lt;p&gt;To deploy WhisperLiveKit in production:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Server Setup&lt;/strong&gt;: Install production ASGI server &amp;amp; launch with multiple workers&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;pip install uvicorn gunicorn
gunicorn -k uvicorn.workers.UvicornWorker -w 4 your_app:app
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Frontend&lt;/strong&gt;: Host your customized version of the &lt;code&gt;html&lt;/code&gt; example &amp;amp; ensure WebSocket connection points correctly&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Nginx Configuration&lt;/strong&gt; (recommended for production):&lt;/p&gt; &lt;pre&gt;&lt;code class="language-nginx"&gt;server {
   listen 80;
   server_name your-domain.com;
    location / {
        proxy_pass http://localhost:8000;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "upgrade";
        proxy_set_header Host $host;
}}
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;HTTPS Support&lt;/strong&gt;: For secure deployments, use "wss://" instead of "ws://" in WebSocket URL&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;ğŸ‹ Docker&lt;/h2&gt; 
&lt;p&gt;Deploy the application easily using Docker with GPU or CPU support.&lt;/p&gt; 
&lt;h3&gt;Prerequisites&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Docker installed on your system&lt;/li&gt; 
 &lt;li&gt;For GPU support: NVIDIA Docker runtime installed&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Quick Start&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;With GPU acceleration (recommended):&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker build -t wlk .
docker run --gpus all -p 8000:8000 --name wlk wlk
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;CPU only:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker build -f Dockerfile.cpu -t wlk .
docker run -p 8000:8000 --name wlk wlk
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Advanced Usage&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Custom configuration:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Example with custom model and language
docker run --gpus all -p 8000:8000 --name wlk wlk --model large-v3 --language fr
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Memory Requirements&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Large models&lt;/strong&gt;: Ensure your Docker runtime has sufficient memory allocated&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Customization&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;--build-arg&lt;/code&gt; Options: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;EXTRAS="whisper-timestamped"&lt;/code&gt; - Add extras to the image's installation (no spaces). Remember to set necessary container options!&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;HF_PRECACHE_DIR="./.cache/"&lt;/code&gt; - Pre-load a model cache for faster first-time start&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;HF_TKN_FILE="./token"&lt;/code&gt; - Add your Hugging Face Hub access token to download gated models&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ğŸ”® Use Cases&lt;/h2&gt; 
&lt;p&gt;Capture discussions in real-time for meeting transcription, help hearing-impaired users follow conversations through accessibility tools, transcribe podcasts or videos automatically for content creation, transcribe support calls with speaker identification for customer service...&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>MODSetter/SurfSense</title>
      <link>https://github.com/MODSetter/SurfSense</link>
      <description>&lt;p&gt;Open Source Alternative to NotebookLM / Perplexity, connected to external sources such as Search Engines, Slack, Linear, Jira, ClickUp, Confluence, Notion, YouTube, GitHub, Discord and more. Join our discord: https://discord.gg/ejRNvftDp9&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/e236b764-0ddc-42ff-a1f1-8fbb3d2e0e65" alt="new_header" /&gt;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://discord.gg/ejRNvftDp9"&gt; &lt;img src="https://img.shields.io/discord/1359368468260192417" alt="Discord" /&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;h1&gt;SurfSense&lt;/h1&gt; 
&lt;p&gt;While tools like NotebookLM and Perplexity are impressive and highly effective for conducting research on any topic/query, SurfSense elevates this capability by integrating with your personal knowledge base. It is a highly customizable AI research agent, connected to external sources such as Search Engines (Tavily, LinkUp), Slack, Linear, Jira, ClickUp, Confluence, Gmail, Notion, YouTube, GitHub, Discord, Google Calendar and more to come.&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://trendshift.io/repositories/13606" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/13606" alt="MODSetter%2FSurfSense | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt; 
&lt;/div&gt; 
&lt;h1&gt;Video&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/d9221908-e0de-4b2f-ac3a-691cf4b202da"&gt;https://github.com/user-attachments/assets/d9221908-e0de-4b2f-ac3a-691cf4b202da&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Podcast Sample&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/a0a16566-6967-4374-ac51-9b3e07fbecd7"&gt;https://github.com/user-attachments/assets/a0a16566-6967-4374-ac51-9b3e07fbecd7&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Key Features&lt;/h2&gt; 
&lt;h3&gt;ğŸ’¡ &lt;strong&gt;Idea&lt;/strong&gt;:&lt;/h3&gt; 
&lt;p&gt;Have your own highly customizable private NotebookLM and Perplexity integrated with external sources.&lt;/p&gt; 
&lt;h3&gt;ğŸ“ &lt;strong&gt;Multiple File Format Uploading Support&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;Save content from your own personal files &lt;em&gt;(Documents, images, videos and supports &lt;strong&gt;50+ file extensions&lt;/strong&gt;)&lt;/em&gt; to your own personal knowledge base .&lt;/p&gt; 
&lt;h3&gt;ğŸ” &lt;strong&gt;Powerful Search&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;Quickly research or find anything in your saved content .&lt;/p&gt; 
&lt;h3&gt;ğŸ’¬ &lt;strong&gt;Chat with your Saved Content&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;Interact in Natural Language and get cited answers.&lt;/p&gt; 
&lt;h3&gt;ğŸ“„ &lt;strong&gt;Cited Answers&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;Get Cited answers just like Perplexity.&lt;/p&gt; 
&lt;h3&gt;ğŸ”” &lt;strong&gt;Privacy &amp;amp; Local LLM Support&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;Works Flawlessly with Ollama local LLMs.&lt;/p&gt; 
&lt;h3&gt;ğŸ  &lt;strong&gt;Self Hostable&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;Open source and easy to deploy locally.&lt;/p&gt; 
&lt;h3&gt;ğŸ™ï¸ Podcasts&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Blazingly fast podcast generation agent. (Creates a 3-minute podcast in under 20 seconds.)&lt;/li&gt; 
 &lt;li&gt;Convert your chat conversations into engaging audio content&lt;/li&gt; 
 &lt;li&gt;Support for local TTS providers (Kokoro TTS)&lt;/li&gt; 
 &lt;li&gt;Support for multiple TTS providers (OpenAI, Azure, Google Vertex AI)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;ğŸ“Š &lt;strong&gt;Advanced RAG Techniques&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Supports 100+ LLM's&lt;/li&gt; 
 &lt;li&gt;Supports 6000+ Embedding Models.&lt;/li&gt; 
 &lt;li&gt;Supports all major Rerankers (Pinecode, Cohere, Flashrank etc)&lt;/li&gt; 
 &lt;li&gt;Uses Hierarchical Indices (2 tiered RAG setup).&lt;/li&gt; 
 &lt;li&gt;Utilizes Hybrid Search (Semantic + Full Text Search combined with Reciprocal Rank Fusion).&lt;/li&gt; 
 &lt;li&gt;RAG as a Service API Backend.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;â„¹ï¸ &lt;strong&gt;External Sources&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Search Engines (Tavily, LinkUp)&lt;/li&gt; 
 &lt;li&gt;Slack&lt;/li&gt; 
 &lt;li&gt;Linear&lt;/li&gt; 
 &lt;li&gt;Jira&lt;/li&gt; 
 &lt;li&gt;ClickUp&lt;/li&gt; 
 &lt;li&gt;Confluence&lt;/li&gt; 
 &lt;li&gt;Notion&lt;/li&gt; 
 &lt;li&gt;Gmail&lt;/li&gt; 
 &lt;li&gt;Youtube Videos&lt;/li&gt; 
 &lt;li&gt;GitHub&lt;/li&gt; 
 &lt;li&gt;Discord&lt;/li&gt; 
 &lt;li&gt;Google Calendar&lt;/li&gt; 
 &lt;li&gt;and more to come.....&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ğŸ“„ &lt;strong&gt;Supported File Extensions&lt;/strong&gt;&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: File format support depends on your ETL service configuration. LlamaCloud supports 50+ formats, Unstructured supports 34+ core formats, and Docling (core formats, local processing, privacy-focused, no API key).&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Documents &amp;amp; Text&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;LlamaCloud&lt;/strong&gt;: &lt;code&gt;.pdf&lt;/code&gt;, &lt;code&gt;.doc&lt;/code&gt;, &lt;code&gt;.docx&lt;/code&gt;, &lt;code&gt;.docm&lt;/code&gt;, &lt;code&gt;.dot&lt;/code&gt;, &lt;code&gt;.dotm&lt;/code&gt;, &lt;code&gt;.rtf&lt;/code&gt;, &lt;code&gt;.txt&lt;/code&gt;, &lt;code&gt;.xml&lt;/code&gt;, &lt;code&gt;.epub&lt;/code&gt;, &lt;code&gt;.odt&lt;/code&gt;, &lt;code&gt;.wpd&lt;/code&gt;, &lt;code&gt;.pages&lt;/code&gt;, &lt;code&gt;.key&lt;/code&gt;, &lt;code&gt;.numbers&lt;/code&gt;, &lt;code&gt;.602&lt;/code&gt;, &lt;code&gt;.abw&lt;/code&gt;, &lt;code&gt;.cgm&lt;/code&gt;, &lt;code&gt;.cwk&lt;/code&gt;, &lt;code&gt;.hwp&lt;/code&gt;, &lt;code&gt;.lwp&lt;/code&gt;, &lt;code&gt;.mw&lt;/code&gt;, &lt;code&gt;.mcw&lt;/code&gt;, &lt;code&gt;.pbd&lt;/code&gt;, &lt;code&gt;.sda&lt;/code&gt;, &lt;code&gt;.sdd&lt;/code&gt;, &lt;code&gt;.sdp&lt;/code&gt;, &lt;code&gt;.sdw&lt;/code&gt;, &lt;code&gt;.sgl&lt;/code&gt;, &lt;code&gt;.sti&lt;/code&gt;, &lt;code&gt;.sxi&lt;/code&gt;, &lt;code&gt;.sxw&lt;/code&gt;, &lt;code&gt;.stw&lt;/code&gt;, &lt;code&gt;.sxg&lt;/code&gt;, &lt;code&gt;.uof&lt;/code&gt;, &lt;code&gt;.uop&lt;/code&gt;, &lt;code&gt;.uot&lt;/code&gt;, &lt;code&gt;.vor&lt;/code&gt;, &lt;code&gt;.wps&lt;/code&gt;, &lt;code&gt;.zabw&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Unstructured&lt;/strong&gt;: &lt;code&gt;.doc&lt;/code&gt;, &lt;code&gt;.docx&lt;/code&gt;, &lt;code&gt;.odt&lt;/code&gt;, &lt;code&gt;.rtf&lt;/code&gt;, &lt;code&gt;.pdf&lt;/code&gt;, &lt;code&gt;.xml&lt;/code&gt;, &lt;code&gt;.txt&lt;/code&gt;, &lt;code&gt;.md&lt;/code&gt;, &lt;code&gt;.markdown&lt;/code&gt;, &lt;code&gt;.rst&lt;/code&gt;, &lt;code&gt;.html&lt;/code&gt;, &lt;code&gt;.org&lt;/code&gt;, &lt;code&gt;.epub&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Docling&lt;/strong&gt;: &lt;code&gt;.pdf&lt;/code&gt;, &lt;code&gt;.docx&lt;/code&gt;, &lt;code&gt;.html&lt;/code&gt;, &lt;code&gt;.htm&lt;/code&gt;, &lt;code&gt;.xhtml&lt;/code&gt;, &lt;code&gt;.adoc&lt;/code&gt;, &lt;code&gt;.asciidoc&lt;/code&gt;&lt;/p&gt; 
&lt;h3&gt;Presentations&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;LlamaCloud&lt;/strong&gt;: &lt;code&gt;.ppt&lt;/code&gt;, &lt;code&gt;.pptx&lt;/code&gt;, &lt;code&gt;.pptm&lt;/code&gt;, &lt;code&gt;.pot&lt;/code&gt;, &lt;code&gt;.potm&lt;/code&gt;, &lt;code&gt;.potx&lt;/code&gt;, &lt;code&gt;.odp&lt;/code&gt;, &lt;code&gt;.key&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Unstructured&lt;/strong&gt;: &lt;code&gt;.ppt&lt;/code&gt;, &lt;code&gt;.pptx&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Docling&lt;/strong&gt;: &lt;code&gt;.pptx&lt;/code&gt;&lt;/p&gt; 
&lt;h3&gt;Spreadsheets &amp;amp; Data&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;LlamaCloud&lt;/strong&gt;: &lt;code&gt;.xlsx&lt;/code&gt;, &lt;code&gt;.xls&lt;/code&gt;, &lt;code&gt;.xlsm&lt;/code&gt;, &lt;code&gt;.xlsb&lt;/code&gt;, &lt;code&gt;.xlw&lt;/code&gt;, &lt;code&gt;.csv&lt;/code&gt;, &lt;code&gt;.tsv&lt;/code&gt;, &lt;code&gt;.ods&lt;/code&gt;, &lt;code&gt;.fods&lt;/code&gt;, &lt;code&gt;.numbers&lt;/code&gt;, &lt;code&gt;.dbf&lt;/code&gt;, &lt;code&gt;.123&lt;/code&gt;, &lt;code&gt;.dif&lt;/code&gt;, &lt;code&gt;.sylk&lt;/code&gt;, &lt;code&gt;.slk&lt;/code&gt;, &lt;code&gt;.prn&lt;/code&gt;, &lt;code&gt;.et&lt;/code&gt;, &lt;code&gt;.uos1&lt;/code&gt;, &lt;code&gt;.uos2&lt;/code&gt;, &lt;code&gt;.wk1&lt;/code&gt;, &lt;code&gt;.wk2&lt;/code&gt;, &lt;code&gt;.wk3&lt;/code&gt;, &lt;code&gt;.wk4&lt;/code&gt;, &lt;code&gt;.wks&lt;/code&gt;, &lt;code&gt;.wq1&lt;/code&gt;, &lt;code&gt;.wq2&lt;/code&gt;, &lt;code&gt;.wb1&lt;/code&gt;, &lt;code&gt;.wb2&lt;/code&gt;, &lt;code&gt;.wb3&lt;/code&gt;, &lt;code&gt;.qpw&lt;/code&gt;, &lt;code&gt;.xlr&lt;/code&gt;, &lt;code&gt;.eth&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Unstructured&lt;/strong&gt;: &lt;code&gt;.xls&lt;/code&gt;, &lt;code&gt;.xlsx&lt;/code&gt;, &lt;code&gt;.csv&lt;/code&gt;, &lt;code&gt;.tsv&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Docling&lt;/strong&gt;: &lt;code&gt;.xlsx&lt;/code&gt;, &lt;code&gt;.csv&lt;/code&gt;&lt;/p&gt; 
&lt;h3&gt;Images&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;LlamaCloud&lt;/strong&gt;: &lt;code&gt;.jpg&lt;/code&gt;, &lt;code&gt;.jpeg&lt;/code&gt;, &lt;code&gt;.png&lt;/code&gt;, &lt;code&gt;.gif&lt;/code&gt;, &lt;code&gt;.bmp&lt;/code&gt;, &lt;code&gt;.svg&lt;/code&gt;, &lt;code&gt;.tiff&lt;/code&gt;, &lt;code&gt;.webp&lt;/code&gt;, &lt;code&gt;.html&lt;/code&gt;, &lt;code&gt;.htm&lt;/code&gt;, &lt;code&gt;.web&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Unstructured&lt;/strong&gt;: &lt;code&gt;.jpg&lt;/code&gt;, &lt;code&gt;.jpeg&lt;/code&gt;, &lt;code&gt;.png&lt;/code&gt;, &lt;code&gt;.bmp&lt;/code&gt;, &lt;code&gt;.tiff&lt;/code&gt;, &lt;code&gt;.heic&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Docling&lt;/strong&gt;: &lt;code&gt;.jpg&lt;/code&gt;, &lt;code&gt;.jpeg&lt;/code&gt;, &lt;code&gt;.png&lt;/code&gt;, &lt;code&gt;.bmp&lt;/code&gt;, &lt;code&gt;.tiff&lt;/code&gt;, &lt;code&gt;.tif&lt;/code&gt;, &lt;code&gt;.webp&lt;/code&gt;&lt;/p&gt; 
&lt;h3&gt;Audio &amp;amp; Video &lt;em&gt;(Always Supported)&lt;/em&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;.mp3&lt;/code&gt;, &lt;code&gt;.mpga&lt;/code&gt;, &lt;code&gt;.m4a&lt;/code&gt;, &lt;code&gt;.wav&lt;/code&gt;, &lt;code&gt;.mp4&lt;/code&gt;, &lt;code&gt;.mpeg&lt;/code&gt;, &lt;code&gt;.webm&lt;/code&gt;&lt;/p&gt; 
&lt;h3&gt;Email &amp;amp; Communication&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Unstructured&lt;/strong&gt;: &lt;code&gt;.eml&lt;/code&gt;, &lt;code&gt;.msg&lt;/code&gt;, &lt;code&gt;.p7s&lt;/code&gt;&lt;/p&gt; 
&lt;h3&gt;ğŸ”– Cross Browser Extension&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;The SurfSense extension can be used to save any webpage you like.&lt;/li&gt; 
 &lt;li&gt;Its main usecase is to save any webpages protected beyond authentication.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;FEATURE REQUESTS AND FUTURE&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;SurfSense is actively being developed.&lt;/strong&gt; While it's not yet production-ready, you can help us speed up the process.&lt;/p&gt; 
&lt;p&gt;Join the &lt;a href="https://discord.gg/ejRNvftDp9"&gt;SurfSense Discord&lt;/a&gt; and help shape the future of SurfSense!&lt;/p&gt; 
&lt;h2&gt;ğŸš€ Roadmap&lt;/h2&gt; 
&lt;p&gt;Stay up to date with our development progress and upcoming features!&lt;br /&gt; Check out our public roadmap and contribute your ideas or feedback:&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;View the Roadmap:&lt;/strong&gt; &lt;a href="https://github.com/users/MODSetter/projects/2"&gt;SurfSense Roadmap on GitHub Projects&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;How to get started?&lt;/h2&gt; 
&lt;h3&gt;Installation Options&lt;/h3&gt; 
&lt;p&gt;SurfSense provides two installation methods:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://www.surfsense.net/docs/docker-installation"&gt;Docker Installation&lt;/a&gt;&lt;/strong&gt; - The easiest way to get SurfSense up and running with all dependencies containerized.&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Includes pgAdmin for database management through a web UI&lt;/li&gt; 
   &lt;li&gt;Supports environment variable customization via &lt;code&gt;.env&lt;/code&gt; file&lt;/li&gt; 
   &lt;li&gt;Flexible deployment options (full stack or core services only)&lt;/li&gt; 
   &lt;li&gt;No need to manually edit configuration files between environments&lt;/li&gt; 
   &lt;li&gt;See &lt;a href="https://raw.githubusercontent.com/MODSetter/SurfSense/main/DOCKER_SETUP.md"&gt;Docker Setup Guide&lt;/a&gt; for detailed instructions&lt;/li&gt; 
   &lt;li&gt;For deployment scenarios and options, see &lt;a href="https://raw.githubusercontent.com/MODSetter/SurfSense/main/DEPLOYMENT_GUIDE.md"&gt;Deployment Guide&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://www.surfsense.net/docs/manual-installation"&gt;Manual Installation (Recommended)&lt;/a&gt;&lt;/strong&gt; - For users who prefer more control over their setup or need to customize their deployment.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Both installation guides include detailed OS-specific instructions for Windows, macOS, and Linux.&lt;/p&gt; 
&lt;p&gt;Before installation, make sure to complete the &lt;a href="https://www.surfsense.net/docs/"&gt;prerequisite setup steps&lt;/a&gt; including:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;PGVector setup&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;File Processing ETL Service&lt;/strong&gt; (choose one): 
  &lt;ul&gt; 
   &lt;li&gt;Unstructured.io API key (supports 34+ formats)&lt;/li&gt; 
   &lt;li&gt;LlamaIndex API key (enhanced parsing, supports 50+ formats)&lt;/li&gt; 
   &lt;li&gt;Docling (local processing, no API key required, supports PDF, Office docs, images, HTML, CSV)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Other required API keys&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Screenshots&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Research Agent&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/e22c5d86-f511-4c72-8c50-feba0c1561b4" alt="updated_researcher" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Search Spaces&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/e254c38c-f937-44b6-9e9d-770db583d099" alt="search_spaces" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Manage Documents&lt;/strong&gt; &lt;img src="https://github.com/user-attachments/assets/7001e306-eb06-4009-89c6-8fadfdc3fc4d" alt="documents" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Podcast Agent&lt;/strong&gt; &lt;img src="https://github.com/user-attachments/assets/6cb82ffd-9e14-4172-bc79-67faf34c4c1c" alt="podcasts" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Agent Chat&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/bb352d52-1c6d-4020-926b-722d0b98b491" alt="git_chat" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Browser Extension&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/1f042b7a-6349-422b-94fb-d40d0df16c40" alt="ext1" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/a9b9f1aa-2677-404d-b0a0-c1b2dddf24a7" alt="ext2" /&gt;&lt;/p&gt; 
&lt;h2&gt;Tech Stack&lt;/h2&gt; 
&lt;h3&gt;&lt;strong&gt;BackEnd&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;FastAPI&lt;/strong&gt;: Modern, fast web framework for building APIs with Python&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;PostgreSQL with pgvector&lt;/strong&gt;: Database with vector search capabilities for similarity searches&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;SQLAlchemy&lt;/strong&gt;: SQL toolkit and ORM (Object-Relational Mapping) for database interactions&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Alembic&lt;/strong&gt;: A database migrations tool for SQLAlchemy.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;FastAPI Users&lt;/strong&gt;: Authentication and user management with JWT and OAuth support&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;LangGraph&lt;/strong&gt;: Framework for developing AI-agents.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;LangChain&lt;/strong&gt;: Framework for developing AI-powered applications.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;LLM Integration&lt;/strong&gt;: Integration with LLM models through LiteLLM&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Rerankers&lt;/strong&gt;: Advanced result ranking for improved search relevance&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Hybrid Search&lt;/strong&gt;: Combines vector similarity and full-text search for optimal results using Reciprocal Rank Fusion (RRF)&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Vector Embeddings&lt;/strong&gt;: Document and text embeddings for semantic search&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;pgvector&lt;/strong&gt;: PostgreSQL extension for efficient vector similarity operations&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Chonkie&lt;/strong&gt;: Advanced document chunking and embedding library&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Uses &lt;code&gt;AutoEmbeddings&lt;/code&gt; for flexible embedding model selection&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;LateChunker&lt;/code&gt; for optimized document chunking based on embedding model's max sequence length&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h3&gt;&lt;strong&gt;FrontEnd&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Next.js 15.2.3&lt;/strong&gt;: React framework featuring App Router, server components, automatic code-splitting, and optimized rendering.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;React 19.0.0&lt;/strong&gt;: JavaScript library for building user interfaces.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;TypeScript&lt;/strong&gt;: Static type-checking for JavaScript, enhancing code quality and developer experience.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Vercel AI SDK Kit UI Stream Protocol&lt;/strong&gt;: To create scalable chat UI.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Tailwind CSS 4.x&lt;/strong&gt;: Utility-first CSS framework for building custom UI designs.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Shadcn&lt;/strong&gt;: Headless components library.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Lucide React&lt;/strong&gt;: Icon set implemented as React components.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Framer Motion&lt;/strong&gt;: Animation library for React.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Sonner&lt;/strong&gt;: Toast notification library.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Geist&lt;/strong&gt;: Font family from Vercel.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;React Hook Form&lt;/strong&gt;: Form state management and validation.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Zod&lt;/strong&gt;: TypeScript-first schema validation with static type inference.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;@hookform/resolvers&lt;/strong&gt;: Resolvers for using validation libraries with React Hook Form.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;@tanstack/react-table&lt;/strong&gt;: Headless UI for building powerful tables &amp;amp; datagrids.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;strong&gt;DevOps&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Docker&lt;/strong&gt;: Container platform for consistent deployment across environments&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Docker Compose&lt;/strong&gt;: Tool for defining and running multi-container Docker applications&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;pgAdmin&lt;/strong&gt;: Web-based PostgreSQL administration tool included in Docker setup&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;strong&gt;Extension&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;Manifest v3 on Plasmo&lt;/p&gt; 
&lt;h2&gt;Future Work&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Add More Connectors.&lt;/li&gt; 
 &lt;li&gt;Patch minor bugs.&lt;/li&gt; 
 &lt;li&gt;Document Chat &lt;strong&gt;[REIMPLEMENT]&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;Document Podcasts&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contribute&lt;/h2&gt; 
&lt;p&gt;Contributions are very welcome! A contribution can be as small as a â­ or even finding and creating issues. Fine-tuning the Backend is always desired.&lt;/p&gt; 
&lt;p&gt;For detailed contribution guidelines, please see our &lt;a href="https://raw.githubusercontent.com/MODSetter/SurfSense/main/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; file.&lt;/p&gt; 
&lt;h2&gt;Star History&lt;/h2&gt; 
&lt;a href="https://www.star-history.com/#MODSetter/SurfSense&amp;amp;Date"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://api.star-history.com/svg?repos=MODSetter/SurfSense&amp;amp;type=Date&amp;amp;theme=dark" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://api.star-history.com/svg?repos=MODSetter/SurfSense&amp;amp;type=Date" /&gt; 
  &lt;img alt="Star History Chart" src="https://api.star-history.com/svg?repos=MODSetter/SurfSense&amp;amp;type=Date" /&gt; 
 &lt;/picture&gt; &lt;/a&gt;</description>
    </item>
    
    <item>
      <title>willccbb/verifiers</title>
      <link>https://github.com/willccbb/verifiers</link>
      <description>&lt;p&gt;Verifiers for LLM Reinforcement Learning&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;p align="center"&gt; &lt;/p&gt;
 &lt;h1&gt;Verifiers&lt;/h1&gt; 
 &lt;p&gt;&lt;/p&gt; 
 &lt;p&gt; Environments for LLM Reinforcement Learning &lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;Overview&lt;/h2&gt; 
&lt;p&gt;Verifiers is a library of modular components for creating RL environments and training LLM agents. Verifiers includes an async GRPO implementation built around the &lt;code&gt;transformers&lt;/code&gt; Trainer, is supported by &lt;code&gt;prime-rl&lt;/code&gt; for large-scale FSDP training, and can easily be integrated into any RL framework which exposes an OpenAI-compatible inference client. In addition to RL training, Verifiers can be used directly for building LLM evaluations, creating synthetic data pipelines, and implementing agent harnesses.&lt;/p&gt; 
&lt;p&gt;Full documentation is available &lt;a href="https://verifiers.readthedocs.io/en/latest/"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Setup&lt;/h2&gt; 
&lt;p&gt;We recommend using &lt;code&gt;verifiers&lt;/code&gt; with along &lt;a href="https://docs.astral.sh/uv/getting-started/installation/"&gt;uv&lt;/a&gt; for dependency management in your own project:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -LsSf https://astral.sh/uv/install.sh | sh
uv init # create a fresh project
source .venv/bin/activate
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For local (CPU) development and evaluation with API models, do:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uv add verifiers # uv add 'verifiers[dev]' for Jupyter + testing support
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For training on GPUs with &lt;code&gt;vf.GRPOTrainer&lt;/code&gt;, do:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uv add 'verifiers[all]' &amp;amp;&amp;amp; uv pip install flash-attn --no-build-isolation
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To use the latest &lt;code&gt;main&lt;/code&gt; branch, do:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uv add verifiers @ git+https://github.com/willccbb/verifiers.git
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To use with &lt;code&gt;prime-rl&lt;/code&gt;, see &lt;a href="https://github.com/PrimeIntellect-ai/prime-rl"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;To install &lt;code&gt;verifiers&lt;/code&gt; from source for core library development, do:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/willccbb/verifiers.git
cd verifiers
uv sync --all-extras &amp;amp;&amp;amp; uv pip install flash-attn --no-build-isolation
uv run pre-commit install
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;In general, we recommend that you build and train Environments &lt;em&gt;with&lt;/em&gt; &lt;code&gt;verifiers&lt;/code&gt;, not &lt;em&gt;in&lt;/em&gt; &lt;code&gt;verifiers&lt;/code&gt;. If you find yourself needing to clone and modify the core library in order to implement key functionality for your project, we'd love for you to open an issue so that we can try and streamline the development experience. Our aim is for &lt;code&gt;verifiers&lt;/code&gt; to be a reliable toolkit to build on top of, and to minimize the "fork proliferation" which often pervades the RL infrastructure ecosystem.&lt;/p&gt; 
&lt;h2&gt;Environments&lt;/h2&gt; 
&lt;p&gt;Environments in Verifiers are installable Python modules which can specify dependencies in a &lt;code&gt;pyproject.toml&lt;/code&gt;, and which expose a &lt;code&gt;load_environment&lt;/code&gt; function for instantiation by downstream applications (e.g. trainers). See &lt;code&gt;environments/&lt;/code&gt; for examples.&lt;/p&gt; 
&lt;p&gt;To initialize a blank Environment module template, do:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;vf-init vf-environment-name # -p /path/to/environments (defaults to "./environments")
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To an install an Environment module into your project, do:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;vf-install vf-environment-name # -p /path/to/environments (defaults to "./environments") 
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To install an Environment module from this repo's &lt;code&gt;environments&lt;/code&gt; folder, do:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;vf-install vf-math-python --from-repo # -b branch_or_commit (defaults to "main")
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Once an Environment module is installed, you can create an instance of the Environment using &lt;code&gt;load_environment&lt;/code&gt;, passing any necessary args:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import verifiers as vf
vf_env = vf.load_environment("vf-environment-name", **env_args)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To run a quick evaluation of your Environment with an API-based model, do:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;vf-eval vf-environment-name # vf-eval -h for config options; defaults to gpt-4.1-mini, 5 prompts, 3 rollouts for each
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The core elements of Environments in are:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Datasets: a Hugging Face &lt;code&gt;Dataset&lt;/code&gt; with a &lt;code&gt;prompt&lt;/code&gt; column for inputs, and either &lt;code&gt;answer (str)&lt;/code&gt; or &lt;code&gt;info (dict)&lt;/code&gt; columns for evaluation&lt;/li&gt; 
 &lt;li&gt;Rollout logic: interactions between models and the environment (e.g. &lt;code&gt;env_response&lt;/code&gt; + &lt;code&gt;is_completed&lt;/code&gt; for any &lt;code&gt;MultiTurnEnv&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;Rubrics: an encapsulation for one or more reward functions&lt;/li&gt; 
 &lt;li&gt;Parsers: optional; an encapsulation for reusable parsing logic&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;We support both &lt;code&gt;/v1/chat/completions&lt;/code&gt;-style and &lt;code&gt;/v1/completions&lt;/code&gt;-style inference via OpenAI clients, though we generally recommend &lt;code&gt;/v1/chat/completions&lt;/code&gt;-style inference for the vast majority of applications. Both the included &lt;code&gt;GRPOTrainer&lt;/code&gt; as well as &lt;code&gt;prime-rl&lt;/code&gt; support the full set of &lt;a href="https://docs.vllm.ai/en/v0.6.0/dev/sampling_params.html"&gt;SamplingParams&lt;/a&gt; exposed by vLLM (via their OpenAI-compatible &lt;a href="https://docs.vllm.ai/en/latest/serving/openai_compatible_server.html"&gt;server&lt;/a&gt; interface), and leveraging this will often be the appropriate way to implement rollout strategies requiring finer-grained control, such as interrupting and resuming generations for interleaved tool use, or enforcing reasoning budgets.&lt;/p&gt; 
&lt;p&gt;The primary constraint we impose on rollout logic is that token sequences must be &lt;em&gt;increasing&lt;/em&gt;, i.e. once a token has been added to a model's context in a rollout, it must remain as the rollout progresses. Note that this causes issues with some popular reasoning models such as the Qwen3 and DeepSeek-R1-Distill series; see &lt;a href="https://raw.githubusercontent.com/willccbb/verifiers/main/#footguns"&gt;Footguns&lt;/a&gt; for guidance on adapting these models to support multi-turn rollouts.&lt;/p&gt; 
&lt;h3&gt;SingleTurnEnv&lt;/h3&gt; 
&lt;p&gt;For tasks requiring only a single response from a model for each prompt, you can use &lt;code&gt;SingleTurnEnv&lt;/code&gt; directly by specifying a Dataset and a Rubric. Rubrics are sets of reward functions, which can be either sync or async.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from datasets import load_dataset
import verifiers as vf

dataset = load_dataset("my-account/my-dataset", split="train")

def reward_A(prompt, completion, info) -&amp;gt; float:
	# reward fn, e.g. correctness
	...

def reward_B(parser, completion) -&amp;gt; float:
	# auxiliary reward fn, e.g. format
	...

async def metric(completion) -&amp;gt; float:
	# non-reward metric, e.g. proper noun count
	...

rubric = vf.Rubric(funcs=[reward_A, reward_B, metric], weights=[1.0, 0.5, 0.0])

vf_env = SingleTurnEnv(
	dataset=dataset,
	rubric=rubric
)
results = vf_env.evaluate(client=OpenAI(), model="gpt-4.1-mini", num_examples=100, rollouts_per_example=1)
vf_env.make_dataset(results) # HF dataset format
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Datasets should be formatted with columns for:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;'prompt' (List[ChatMessage])&lt;/code&gt; OR &lt;code&gt;'question' (str)&lt;/code&gt; fields 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;ChatMessage&lt;/code&gt; = e.g. &lt;code&gt;{'role': 'user', 'content': '...'}&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;if &lt;code&gt;question&lt;/code&gt; is set instead of &lt;code&gt;prompt&lt;/code&gt;, you can also pass &lt;code&gt;system_prompt (str)&lt;/code&gt; and/or &lt;code&gt;few_shot (List[ChatMessage])&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;answer (str)&lt;/code&gt; AND/OR &lt;code&gt;info (dict)&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;task (str)&lt;/code&gt;: optional, used by &lt;code&gt;EnvGroup&lt;/code&gt; and &lt;code&gt;RubricGroup&lt;/code&gt; for orchestrating composition of Environments and Rubrics&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The following named attributes available for use by reward functions in your Rubric:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;prompt&lt;/code&gt;: sequence of input messages&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;completion&lt;/code&gt;: sequence of messages generated during rollout by model and Environment&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;answer&lt;/code&gt;: primary answer column, optional if &lt;code&gt;info&lt;/code&gt; is used&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;state&lt;/code&gt;: can be modified during rollout to accumulate any metadata (&lt;code&gt;state['responses']&lt;/code&gt; includes full OpenAI response objects by default)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;info&lt;/code&gt;: auxiliary info needed for reward computation (e.g. test cases), optional if &lt;code&gt;answer&lt;/code&gt; is used&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;task&lt;/code&gt;: tag for task type (used by &lt;code&gt;EnvGroup&lt;/code&gt; and &lt;code&gt;RubricGroup&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;parser&lt;/code&gt;: the parser object declared. Note: &lt;code&gt;vf.Parser().get_format_reward_func()&lt;/code&gt; is a no-op (always 1.0); use &lt;code&gt;vf.ThinkParser&lt;/code&gt; or a custom parser if you want a real format adherence reward.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For tasks involving LLM judges, you may wish to use &lt;code&gt;vf.JudgeRubric()&lt;/code&gt; for managing requests to auxiliary models.&lt;/p&gt; 
&lt;p&gt;Note on concurrency: environment APIs accept &lt;code&gt;max_concurrent&lt;/code&gt; to control parallel rollouts. The &lt;code&gt;vf-eval&lt;/code&gt; CLI currently exposes &lt;code&gt;--max-concurrent-requests&lt;/code&gt;; ensure this maps to your environmentâ€™s concurrency as expected.&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;vf-eval&lt;/code&gt; also supports specifying &lt;code&gt;sampling_args&lt;/code&gt; as a JSON object, which is sent to the vLLM inference engine:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;vf-eval vf-environment-name --sampling-args '{"reasoning_effort": "low"}'
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Use &lt;code&gt;vf-eval -s&lt;/code&gt; to save outputs as dataset-formatted JSON, and view all locally-saved eval results with &lt;code&gt;vf-tui&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;ToolEnv&lt;/h3&gt; 
&lt;p&gt;For many applications involving tool use, you can use &lt;code&gt;ToolEnv&lt;/code&gt; to leverage models' native tool/function-calling capabilities in an agentic loop. Tools can be specified as generic Python functions (with type hints and docstrings), which will then be passed in JSON schema form to each inference request.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import verifiers as vf
vf_env = vf.ToolEnv(
	dataset= ... # HF Dataset with 'prompt'/'question' + 'answer'/'info' columns
	rubric= ... # Rubric object; vf.ToolRubric() can be optionally used for counting tool invocations in each rollout
	tools=[search_tool, read_article_tool, python_tool], # python functions with type hints + docstrings
	max_turns=10
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;In cases where your tools require heavy computational resources, we recommend hosting your tools as standalone servers (e.g. MCP servers) and creating lightweight wrapper functions to pass to &lt;code&gt;ToolEnv&lt;/code&gt;. Parallel tool call support is enabled by default.&lt;/p&gt; 
&lt;p&gt;For training, or self-hosted endpoints, you'll want to enable auto tool choice in &lt;a href="https://docs.vllm.ai/en/stable/features/tool_calling.html#automatic-function-calling"&gt;vLLM&lt;/a&gt; with the appropriate parser. If your model does not support native tool calling, you may find the &lt;code&gt;XMLParser&lt;/code&gt; abstraction useful for rolling your own tool call parsing on top of &lt;code&gt;MultiTurnEnv&lt;/code&gt;; see &lt;code&gt;environments/xml_tool_env&lt;/code&gt; for an example.&lt;/p&gt; 
&lt;h3&gt;MultiTurnEnv&lt;/h3&gt; 
&lt;p&gt;Both &lt;code&gt;SingleTurnEnv&lt;/code&gt; and &lt;code&gt;ToolEnv&lt;/code&gt; are instances of &lt;code&gt;MultiTurnEnv&lt;/code&gt;, which exposes an interface for writing custom Environment interaction protocols. The two methods you must override are&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from typing import Tuple
import verifiers as vf
from verifiers.types import Messages, State
class YourMultiTurnEnv(vf.MultiTurnEnv):
    def __init__(self,
                 dataset: Dataset,
                 rubric: Rubric,
				 max_turns: int,
                 **kwargs):
	
  async def is_completed(self, messages: Messages, state: State, **kwargs) -&amp;gt; bool:
    # return whether or not a rollout is completed

  async def env_response(self, messages: Messages, state: State, **kwargs) -&amp;gt; Tuple[Messages, State]:
    # return new environment message(s) + updated state
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If your application requires more fine-grained control than is allowed by &lt;code&gt;MultiTurnEnv&lt;/code&gt;, you may want to inherit from the base &lt;code&gt;Environment&lt;/code&gt; functionality directly and override the &lt;code&gt;rollout&lt;/code&gt; method.&lt;/p&gt; 
&lt;h2&gt;Training&lt;/h2&gt; 
&lt;h3&gt;GRPOTrainer&lt;/h3&gt; 
&lt;p&gt;The included trainer (&lt;code&gt;vf.GRPOTrainer&lt;/code&gt;) supports running GRPO-style RL training via Accelerate/DeepSpeed, and uses vLLM for inference. It supports both full-parameter finetuning, and is optimized for efficiently training dense transformer models on 2-16 GPUs.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# install environment
vf-install vf-wordle (-p /path/to/environments | --from-repo)

# quick eval
vf-eval vf-wordle -m (model_name in configs/endpoints.py) -n NUM_EXAMPLES -r ROLLOUTS_PER_EXAMPLE

# inference (shell 0)
CUDA_VISIBLE_DEVICES=0,1,2,3,4,5 vf-vllm --model willcb/Qwen3-1.7B-Wordle \
    --data-parallel-size 7 --enforce-eager --disable-log-requests

# training (shell 1)
CUDA_VISIBLE_DEVICES=6,7 accelerate launch --num-processes 2 \
    --config-file configs/zero3.yaml examples/grpo/train_wordle.py --size 1.7B
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Alternatively, you can train environments with the external &lt;code&gt;prime-rl&lt;/code&gt; project (FSDP-first orchestration). See the &lt;code&gt;prime-rl&lt;/code&gt; README for installation and examples. For example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# orchestrator config (prime-rl)
[environment]
id = "vf-math-python"  # or your environment ID
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# run (prime-rl)
uv run rl \
  --trainer @ configs/your_exp/train.toml \
  --orchestrator @ configs/your_exp/orch.toml \
  --inference @ configs/your_exp/infer.toml
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Troubleshooting&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Ensure your &lt;code&gt;wandb&lt;/code&gt; and &lt;code&gt;huggingface-cli&lt;/code&gt; logins are set up (or set &lt;code&gt;report_to=None&lt;/code&gt; in &lt;code&gt;training_args&lt;/code&gt;). You should also have something set as your &lt;code&gt;OPENAI_API_KEY&lt;/code&gt; in your environment (can be a dummy key for vLLM).&lt;/li&gt; 
 &lt;li&gt;If using high max concurrency, increase the number of allowed open sockets (e.g. &lt;code&gt;ulimit -n 4096&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;On some setups, inter-GPU communication can &lt;a href="https://github.com/huggingface/trl/issues/2923"&gt;hang&lt;/a&gt; or crash during vLLM weight syncing. This can usually be alleviated by setting (or unsetting) &lt;code&gt;NCCL_P2P_DISABLE=1&lt;/code&gt; in your environment (or potentially &lt;code&gt;NCCL_CUMEM_ENABLE=1&lt;/code&gt;). Try this as your first step if you experience NCCL-related issues.&lt;/li&gt; 
 &lt;li&gt;If problems persist, please open an &lt;a href="https://github.com/willccbb/verifiers/issues"&gt;issue&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Resource Requirements&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;GRPOTrainer&lt;/code&gt; is optimized for setups with at least 2 GPUs, scaling up to multiple nodes. 2-GPU setups with sufficient memory to enable small-scale experimentation can be &lt;a href="https://app.primeintellect.ai/dashboard/create-cluster?image=ubuntu_22_cuda_12"&gt;rented&lt;/a&gt; for &amp;lt;$1/hr.&lt;/p&gt; 
&lt;h3&gt;PRIME-RL&lt;/h3&gt; 
&lt;p&gt;If you do not require LoRA support, you may want to use the &lt;code&gt;prime-rl&lt;/code&gt; trainer, which natively supports Environments created using &lt;code&gt;verifiers&lt;/code&gt;, is more optimized for performance and scalability via FSDP, includes a broader set of configuration options and user experience features, and has more battle-tested defaults. Both trainers support asynchronous rollouts, and use a one-step off-policy delay by default for overlapping training and inference. See the &lt;code&gt;prime-rl&lt;/code&gt; &lt;a href="https://github.com/PrimeIntellect-ai/prime-rl"&gt;docs&lt;/a&gt; for usage instructions.&lt;/p&gt; 
&lt;h2&gt;Further Documentation&lt;/h2&gt; 
&lt;p&gt;See the full &lt;a href="https://verifiers.readthedocs.io/en/latest/"&gt;docs&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;h2&gt;Contributions&lt;/h2&gt; 
&lt;p&gt;Verifiers warmly welcomes community contributions! Please open an issue or PR if you encounter bugs or other pain points during your development, or start a discussion for more open-ended questions.&lt;/p&gt; 
&lt;p&gt;Please note that the core &lt;code&gt;verifiers/&lt;/code&gt; library is intended to be a relatively lightweight set of reusable components rather than an exhaustive catalog of RL environments. For &lt;em&gt;applications&lt;/em&gt; of &lt;code&gt;verifiers&lt;/code&gt; (e.g. "an Environment for XYZ task"), you are welcome to submit a PR for a self-contained module that lives within &lt;code&gt;environments/&lt;/code&gt; if it serves as a canonical example of a new pattern. Stay tuned for more info shortly about our plans for supporting community Environment contributions ğŸ™‚&lt;/p&gt; 
&lt;h2&gt;Citation&lt;/h2&gt; 
&lt;p&gt;If you use this code in your research, please cite:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bibtex"&gt;@misc{brown_verifiers_2025,
  author       = {William&amp;nbsp;Brown},
  title        = {{Verifiers}: Reinforcement Learning with LLMs in Verifiable Environments},
  howpublished = {\url{https://github.com/willccbb/verifiers}},
  note         = {Commit abcdefg â€¢ accessed DDâ€¯Monâ€¯YYYY},
  year         = {2025}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Roadmap&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;A community Environments hub for crowdsourcing, sharing, and discovering new RL environments built with &lt;code&gt;verifiers&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Default patterns for hosted resources such as code sandboxes, auxiliary models, and MCP servers&lt;/li&gt; 
 &lt;li&gt;Multimodal input support&lt;/li&gt; 
 &lt;li&gt;Non-increasing token sequences via REINFORCE&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>Fosowl/agenticSeek</title>
      <link>https://github.com/Fosowl/agenticSeek</link>
      <description>&lt;p&gt;Fully Local Manus AI. No APIs, No $200 monthly bills. Enjoy an autonomous agent that thinks, browses the web, and code for the sole cost of electricity. ğŸ”” Official updates only via twitter @Martin993886460 (Beware of fake account)&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;AgenticSeek: Private, Local Manus Alternative.&lt;/h1&gt; 
&lt;p align="center"&gt; &lt;img align="center" src="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/media/agentic_seek_logo.png" width="300" height="300" alt="Agentic Seek Logo" /&gt; &lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;English | &lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_CHS.md"&gt;ä¸­æ–‡&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_CHT.md"&gt;ç¹é«”ä¸­æ–‡&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_FR.md"&gt;FranÃ§ais&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_JP.md"&gt;æ—¥æœ¬èª&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_PTBR.md"&gt;PortuguÃªs (Brasil)&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_ES.md"&gt;EspaÃ±ol&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;A &lt;strong&gt;100% local alternative to Manus AI&lt;/strong&gt;, this voice-enabled AI assistant autonomously browses the web, writes code, and plans tasks while keeping all data on your device. Tailored for local reasoning models, it runs entirely on your hardware, ensuring complete privacy and zero cloud dependency.&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://fosowl.github.io/agenticSeek.html"&gt;&lt;img src="https://img.shields.io/static/v1?label=Website&amp;amp;message=AgenticSeek&amp;amp;color=blue&amp;amp;style=flat-square" alt="Visit AgenticSeek" /&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/badge/license-GPL--3.0-green" alt="License" /&gt; &lt;a href="https://discord.gg/8hGDaME3TC"&gt;&lt;img src="https://img.shields.io/badge/Discord-Join%20Us-7289DA?logo=discord&amp;amp;logoColor=white" alt="Discord" /&gt;&lt;/a&gt; &lt;a href="https://x.com/Martin993886460"&gt;&lt;img src="https://img.shields.io/twitter/url/https/twitter.com/fosowl.svg?style=social&amp;amp;label=Update%20%40Fosowl" alt="Twitter" /&gt;&lt;/a&gt; &lt;a href="https://github.com/Fosowl/agenticSeek/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/Fosowl/agenticSeek?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Why AgenticSeek ?&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;ğŸ”’ Fully Local &amp;amp; Private - Everything runs on your machine â€” no cloud, no data sharing. Your files, conversations, and searches stay private.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;ğŸŒ Smart Web Browsing - AgenticSeek can browse the internet by itself â€” search, read, extract info, fill web form â€” all hands-free.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;ğŸ’» Autonomous Coding Assistant - Need code? It can write, debug, and run programs in Python, C, Go, Java, and more â€” all without supervision.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;ğŸ§  Smart Agent Selection - You ask, it figures out the best agent for the job automatically. Like having a team of experts ready to help.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;ğŸ“‹ Plans &amp;amp; Executes Complex Tasks - From trip planning to complex projects â€” it can split big tasks into steps and get things done using multiple AI agents.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;ğŸ™ï¸ Voice-Enabled - Clean, fast, futuristic voice and speech to text allowing you to talk to it like it's your personal AI from a sci-fi movie. (In progress)&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;strong&gt;Demo&lt;/strong&gt;&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;em&gt;Can you search for the agenticSeek project, learn what skills are required, then open the CV_candidates.zip and then tell me which match best the project&lt;/em&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/b8ca60e9-7b3b-4533-840e-08f9ac426316"&gt;https://github.com/user-attachments/assets/b8ca60e9-7b3b-4533-840e-08f9ac426316&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Disclaimer: This demo, including all the files that appear (e.g: CV_candidates.zip), are entirely fictional. We are not a corporation, we seek open-source contributors not candidates.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;ğŸ› âš ï¸ï¸ &lt;strong&gt;Active Work in Progress&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;ğŸ™ This project started as a side-project and has zero roadmap and zero funding. It's grown way beyond what I expected by ending in GitHub Trending. Contributions, feedback, and patience are deeply appreciated.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Prerequisites&lt;/h2&gt; 
&lt;p&gt;Before you begin, ensure you have the following software installed:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Git:&lt;/strong&gt; For cloning the repository. &lt;a href="https://git-scm.com/downloads"&gt;Download Git&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Python 3.10.x:&lt;/strong&gt; We strongly recommend using Python version 3.10.x. Using other versions might lead to dependency errors. &lt;a href="https://www.python.org/downloads/release/python-3100/"&gt;Download Python 3.10&lt;/a&gt; (pick a 3.10.x version).&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Docker Engine &amp;amp; Docker Compose:&lt;/strong&gt; For running bundled services like SearxNG. 
  &lt;ul&gt; 
   &lt;li&gt;Install Docker Desktop (which includes Docker Compose V2): &lt;a href="https://docs.docker.com/desktop/install/windows-install/"&gt;Windows&lt;/a&gt; | &lt;a href="https://docs.docker.com/desktop/install/mac-install/"&gt;Mac&lt;/a&gt; | &lt;a href="https://docs.docker.com/desktop/install/linux-install/"&gt;Linux&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;Alternatively, install Docker Engine and Docker Compose separately on Linux: &lt;a href="https://docs.docker.com/engine/install/"&gt;Docker Engine&lt;/a&gt; | &lt;a href="https://docs.docker.com/compose/install/"&gt;Docker Compose&lt;/a&gt; (ensure you install Compose V2, e.g., &lt;code&gt;sudo apt-get install docker-compose-plugin&lt;/code&gt;).&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;1. &lt;strong&gt;Clone the repository and setup&lt;/strong&gt;&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;git clone https://github.com/Fosowl/agenticSeek.git
cd agenticSeek
mv .env.example .env
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;2. Change the .env file content&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;SEARXNG_BASE_URL="http://127.0.0.1:8080"
REDIS_BASE_URL="redis://redis:6379/0"
WORK_DIR="/Users/mlg/Documents/workspace_for_ai"
OLLAMA_PORT="11434"
LM_STUDIO_PORT="1234"
CUSTOM_ADDITIONAL_LLM_PORT="11435"
OPENAI_API_KEY='optional'
DEEPSEEK_API_KEY='optional'
OPENROUTER_API_KEY='optional'
TOGETHER_API_KEY='optional'
GOOGLE_API_KEY='optional'
ANTHROPIC_API_KEY='optional'
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Update the &lt;code&gt;.env&lt;/code&gt; file with your own values as needed:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;SEARXNG_BASE_URL&lt;/strong&gt;: Leave unchanged&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;REDIS_BASE_URL&lt;/strong&gt;: Leave unchanged&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;WORK_DIR&lt;/strong&gt;: Path to your working directory on your local machine. AgenticSeek will be able to read and interact with these files.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;OLLAMA_PORT&lt;/strong&gt;: Port number for the Ollama service.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;LM_STUDIO_PORT&lt;/strong&gt;: Port number for the LM Studio service.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;CUSTOM_ADDITIONAL_LLM_PORT&lt;/strong&gt;: Port for any additional custom LLM service.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;API Key are totally optional for user who choose to run LLM locally. Which is the primary purpose of this project. Leave empty if you have sufficient hardware&lt;/strong&gt;&lt;/p&gt; 
&lt;h3&gt;3. &lt;strong&gt;Start Docker&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;Make sure Docker is installed and running on your system. You can start Docker using the following commands:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;On Linux/macOS:&lt;/strong&gt;&lt;br /&gt; Open a terminal and run:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-sh"&gt;sudo systemctl start docker
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Or launch Docker Desktop from your applications menu if installed.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;On Windows:&lt;/strong&gt;&lt;br /&gt; Start Docker Desktop from the Start menu.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;You can verify Docker is running by executing:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;docker info
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you see information about your Docker installation, it is running correctly.&lt;/p&gt; 
&lt;p&gt;See the table of &lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#list-of-local-providers"&gt;Local Providers&lt;/a&gt; below for a summary.&lt;/p&gt; 
&lt;p&gt;Next step: &lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#start-services-and-run"&gt;Run AgenticSeek locally&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;See the &lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#troubleshooting"&gt;Troubleshooting&lt;/a&gt; section if you are having issues.&lt;/em&gt; &lt;em&gt;If your hardware can't run LLMs locally, see &lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#setup-to-run-with-an-api"&gt;Setup to run with an API&lt;/a&gt;.&lt;/em&gt; &lt;em&gt;For detailed &lt;code&gt;config.ini&lt;/code&gt; explanations, see &lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#config"&gt;Config Section&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Setup for running LLM locally on your machine&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Hardware Requirements:&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;To run LLMs locally, you'll need sufficient hardware. At a minimum, a GPU capable of running Magistral, Qwen or Deepseek 14B is required. See the FAQ for detailed model/performance recommendations.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Setup your local provider&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Start your local provider, for example with ollama:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;ollama serve
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See below for a list of local supported provider.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Update the config.ini&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Change the config.ini file to set the provider_name to a supported provider and provider_model to a LLM supported by your provider. We recommend reasoning model such as &lt;em&gt;Magistral&lt;/em&gt; or &lt;em&gt;Deepseek&lt;/em&gt;.&lt;/p&gt; 
&lt;p&gt;See the &lt;strong&gt;FAQ&lt;/strong&gt; at the end of the README for required hardware.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;[MAIN]
is_local = True # Whenever you are running locally or with remote provider.
provider_name = ollama # or lm-studio, openai, etc..
provider_model = deepseek-r1:14b # choose a model that fit your hardware
provider_server_address = 127.0.0.1:11434
agent_name = Jarvis # name of your AI
recover_last_session = True # whenever to recover the previous session
save_session = True # whenever to remember the current session
speak = False # text to speech
listen = False # Speech to text, only for CLI, experimental
jarvis_personality = False # Whenever to use a more "Jarvis" like personality (experimental)
languages = en zh # The list of languages, Text to speech will default to the first language on the list
[BROWSER]
headless_browser = True # leave unchanged unless using CLI on host.
stealth_mode = True # Use undetected selenium to reduce browser detection
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Warning&lt;/strong&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;The &lt;code&gt;config.ini&lt;/code&gt; file format does not support comments. Do not copy and paste the example configuration directly, as comments will cause errors. Instead, manually modify the &lt;code&gt;config.ini&lt;/code&gt; file with your desired settings, excluding any comments.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Do &lt;em&gt;NOT&lt;/em&gt; set provider_name to &lt;code&gt;openai&lt;/code&gt; if using LM-studio for running LLMs. Set it to &lt;code&gt;lm-studio&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Some provider (eg: lm-studio) require you to have &lt;code&gt;http://&lt;/code&gt; in front of the IP. For example &lt;code&gt;http://127.0.0.1:1234&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;List of local providers&lt;/strong&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Provider&lt;/th&gt; 
   &lt;th&gt;Local?&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ollama&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Run LLMs locally with ease using ollama as a LLM provider&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;lm-studio&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Run LLM locally with LM studio (set &lt;code&gt;provider_name&lt;/code&gt; to &lt;code&gt;lm-studio&lt;/code&gt;)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;openai&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Use openai compatible API (eg: llama.cpp server)&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Next step: &lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#Start-services-and-Run"&gt;Start services and run AgenticSeek&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;See the &lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#troubleshooting"&gt;Troubleshooting&lt;/a&gt; section if you are having issues.&lt;/em&gt; &lt;em&gt;If your hardware can't run LLMs locally, see &lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#setup-to-run-with-an-api"&gt;Setup to run with an API&lt;/a&gt;.&lt;/em&gt; &lt;em&gt;For detailed &lt;code&gt;config.ini&lt;/code&gt; explanations, see &lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#config"&gt;Config Section&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt; 
&lt;h2&gt;Setup to run with an API&lt;/h2&gt; 
&lt;p&gt;This setup uses external, cloud-based LLM providers. You'll need an API key from your chosen service.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;1. Choose an API Provider and Get an API Key:&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Refer to the &lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#list-of-api-providers"&gt;List of API Providers&lt;/a&gt; below. Visit their websites to sign up and obtain an API key.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2. Set Your API Key as an Environment Variable:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Linux/macOS:&lt;/strong&gt; Open your terminal and use the &lt;code&gt;export&lt;/code&gt; command. It's best to add this to your shell's profile file (e.g., &lt;code&gt;~/.bashrc&lt;/code&gt;, &lt;code&gt;~/.zshrc&lt;/code&gt;) for persistence.&lt;/p&gt; &lt;pre&gt;&lt;code class="language-sh"&gt;export PROVIDER_API_KEY="your_api_key_here" 
# Replace PROVIDER_API_KEY with the specific variable name, e.g., OPENAI_API_KEY, GOOGLE_API_KEY
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Example for TogetherAI:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-sh"&gt;export TOGETHER_API_KEY="xxxxxxxxxxxxxxxxxxxxxx"
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Windows:&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Command Prompt (Temporary for current session):&lt;/strong&gt; &lt;pre&gt;&lt;code class="language-cmd"&gt;set PROVIDER_API_KEY=your_api_key_here
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;PowerShell (Temporary for current session):&lt;/strong&gt; &lt;pre&gt;&lt;code class="language-powershell"&gt;$env:PROVIDER_API_KEY="your_api_key_here"
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Permanently:&lt;/strong&gt; Search for "environment variables" in the Windows search bar, click "Edit the system environment variables," then click the "Environment Variables..." button. Add a new User variable with the appropriate name (e.g., &lt;code&gt;OPENAI_API_KEY&lt;/code&gt;) and your key as the value.&lt;/li&gt; 
  &lt;/ul&gt; &lt;p&gt;&lt;em&gt;(See FAQ: &lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#how-do-i-set-api-keys"&gt;How do I set API keys?&lt;/a&gt; for more details).&lt;/em&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;3. Update &lt;code&gt;config.ini&lt;/code&gt;:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-ini"&gt;[MAIN]
is_local = False
provider_name = openai # Or google, deepseek, togetherAI, huggingface
provider_model = gpt-3.5-turbo # Or gemini-1.5-flash, deepseek-chat, mistralai/Mixtral-8x7B-Instruct-v0.1 etc.
provider_server_address = # Typically ignored or can be left blank when is_local = False for most APIs
# ... other settings ...
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;em&gt;Warning:&lt;/em&gt; Make sure there are no trailing spaces in the &lt;code&gt;config.ini&lt;/code&gt; values.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;List of API Providers&lt;/strong&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Provider&lt;/th&gt; 
   &lt;th&gt;&lt;code&gt;provider_name&lt;/code&gt;&lt;/th&gt; 
   &lt;th&gt;Local?&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;API Key Link (Examples)&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;OpenAI&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;openai&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;Use ChatGPT models via OpenAI's API.&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://platform.openai.com/signup"&gt;platform.openai.com/signup&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Google Gemini&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;google&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;Use Google Gemini models via Google AI Studio.&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aistudio.google.com/keys"&gt;aistudio.google.com/keys&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Deepseek&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;deepseek&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;Use Deepseek models via their API.&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://platform.deepseek.com"&gt;platform.deepseek.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Hugging Face&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;huggingface&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;Use models from Hugging Face Inference API.&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/settings/tokens"&gt;huggingface.co/settings/tokens&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;TogetherAI&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;togetherAI&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;Use various open-source models via TogetherAI API.&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://api.together.ai/settings/api-keys"&gt;api.together.ai/settings/api-keys&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;em&gt;Note:&lt;/em&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;We advise against using &lt;code&gt;gpt-4o&lt;/code&gt; or other OpenAI models for complex web browsing and task planning as current prompt optimizations are geared towards models like Deepseek.&lt;/li&gt; 
 &lt;li&gt;Coding/bash tasks might encounter issues with Gemini, as it may not strictly follow formatting prompts optimized for Deepseek.&lt;/li&gt; 
 &lt;li&gt;The &lt;code&gt;provider_server_address&lt;/code&gt; in &lt;code&gt;config.ini&lt;/code&gt; is generally not used when &lt;code&gt;is_local = False&lt;/code&gt; as the API endpoint is usually hardcoded in the respective provider's library.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Next step: &lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#Start-services-and-Run"&gt;Start services and run AgenticSeek&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;See the &lt;strong&gt;Known issues&lt;/strong&gt; section if you are having issues&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;See the &lt;strong&gt;Config&lt;/strong&gt; section for detailed config file explanation.&lt;/em&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Start services and Run&lt;/h2&gt; 
&lt;p&gt;By default AgenticSeek is run fully in docker.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Option 1:&lt;/strong&gt; Run in Docker, use web interface:&lt;/p&gt; 
&lt;p&gt;Start required services. This will start all services from the docker-compose.yml, including: - searxng - redis (required by searxng) - frontend - backend (if using &lt;code&gt;full&lt;/code&gt; when using the web interface)&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;./start_services.sh full # MacOS
start start_services.cmd full # Window
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Warning:&lt;/strong&gt; This step will download and load all Docker images, which may take up to 30 minutes. After starting the services, please wait until the backend service is fully running (you should see &lt;strong&gt;backend: "GET /health HTTP/1.1" 200 OK&lt;/strong&gt; in the log) before sending any messages. The backend services might take 5 minute to start on first run.&lt;/p&gt; 
&lt;p&gt;Go to &lt;code&gt;http://localhost:3000/&lt;/code&gt; and you should see the web interface.&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;Troubleshooting service start:&lt;/em&gt; If these scripts fail, ensure Docker Engine is running and Docker Compose (V2, &lt;code&gt;docker compose&lt;/code&gt;) is correctly installed. Check the output in the terminal for error messages. See &lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#faq-troubleshooting"&gt;FAQ: Help! I get an error when running AgenticSeek or its scripts.&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Option 2:&lt;/strong&gt; CLI mode:&lt;/p&gt; 
&lt;p&gt;To run with CLI interface you would have to install package on host:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;./install.sh
./install.bat # windows
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Start required services. This will start some services from the docker-compose.yml, including: - searxng - redis (required by searxng) - frontend&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;./start_services.sh # MacOS
start start_services.cmd # Window
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Use the CLI: &lt;code&gt;uv run cli.py&lt;/code&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;p&gt;Make sure the services are up and running with &lt;code&gt;./start_services.sh full&lt;/code&gt; and go to &lt;code&gt;localhost:3000&lt;/code&gt; for web interface.&lt;/p&gt; 
&lt;p&gt;You can also use speech to text by setting &lt;code&gt;listen = True&lt;/code&gt; in the config. Only for CLI mode.&lt;/p&gt; 
&lt;p&gt;To exit, simply say/type &lt;code&gt;goodbye&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Here are some example usage:&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;em&gt;Make a snake game in python!&lt;/em&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;em&gt;Search the web for top cafes in Rennes, France, and save a list of three with their addresses in rennes_cafes.txt.&lt;/em&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;em&gt;Write a Go program to calculate the factorial of a number, save it as factorial.go in your workspace&lt;/em&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;em&gt;Search my summer_pictures folder for all JPG files, rename them with todayâ€™s date, and save a list of renamed files in photos_list.txt&lt;/em&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;em&gt;Search online for popular sci-fi movies from 2024 and pick three to watch tonight. Save the list in movie_night.txt.&lt;/em&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;em&gt;Search the web for the latest AI news articles from 2025, select three, and write a Python script to scrape their titles and summaries. Save the script as news_scraper.py and the summaries in ai_news.txt in /home/projects&lt;/em&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;em&gt;Friday, search the web for a free stock price API, register with &lt;a href="mailto:supersuper7434567@gmail.com"&gt;supersuper7434567@gmail.com&lt;/a&gt; then write a Python script to fetch using the API daily prices for Tesla, and save the results in stock_prices.csv&lt;/em&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;em&gt;Note that form filling capabilities are still experimental and might fail.&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;After you type your query, AgenticSeek will allocate the best agent for the task.&lt;/p&gt; 
&lt;p&gt;Because this is an early prototype, the agent routing system might not always allocate the right agent based on your query.&lt;/p&gt; 
&lt;p&gt;Therefore, you should be very explicit in what you want and how the AI might proceed for example if you want it to conduct a web search, do not say:&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;Do you know some good countries for solo-travel?&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;Instead, ask:&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;Do a web search and find out which are the best country for solo-travel&lt;/code&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;&lt;strong&gt;Setup to run the LLM on your own server&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;If you have a powerful computer or a server that you can use, but you want to use it from your laptop you have the options to run the LLM on a remote server using our custom llm server.&lt;/p&gt; 
&lt;p&gt;On your "server" that will run the AI model, get the ip address&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;ip a | grep "inet " | grep -v 127.0.0.1 | awk '{print $2}' | cut -d/ -f1 # local ip
curl https://ipinfo.io/ip # public ip
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Note: For Windows or macOS, use ipconfig or ifconfig respectively to find the IP address.&lt;/p&gt; 
&lt;p&gt;Clone the repository and enter the &lt;code&gt;server/&lt;/code&gt;folder.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;git clone --depth 1 https://github.com/Fosowl/agenticSeek.git
cd agenticSeek/llm_server/
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Install server specific requirements:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;pip3 install -r requirements.txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Run the server script.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;python3 app.py --provider ollama --port 3333
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You have the choice between using &lt;code&gt;ollama&lt;/code&gt; and &lt;code&gt;llamacpp&lt;/code&gt; as a LLM service.&lt;/p&gt; 
&lt;p&gt;Now on your personal computer:&lt;/p&gt; 
&lt;p&gt;Change the &lt;code&gt;config.ini&lt;/code&gt; file to set the &lt;code&gt;provider_name&lt;/code&gt; to &lt;code&gt;server&lt;/code&gt; and &lt;code&gt;provider_model&lt;/code&gt; to &lt;code&gt;deepseek-r1:xxb&lt;/code&gt;. Set the &lt;code&gt;provider_server_address&lt;/code&gt; to the ip address of the machine that will run the model.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;[MAIN]
is_local = False
provider_name = server
provider_model = deepseek-r1:70b
provider_server_address = http://x.x.x.x:3333
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Next step: &lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#Start-services-and-Run"&gt;Start services and run AgenticSeek&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Speech to Text&lt;/h2&gt; 
&lt;p&gt;Warning: speech to text only work in CLI mode at the moment.&lt;/p&gt; 
&lt;p&gt;Please note that currently speech to text only work in english.&lt;/p&gt; 
&lt;p&gt;The speech-to-text functionality is disabled by default. To enable it, set the listen option to True in the config.ini file:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;listen = True
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;When enabled, the speech-to-text feature listens for a trigger keyword, which is the agent's name, before it begins processing your input. You can customize the agent's name by updating the &lt;code&gt;agent_name&lt;/code&gt; value in the &lt;em&gt;config.ini&lt;/em&gt; file:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;agent_name = Friday
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For optimal recognition, we recommend using a common English name like "John" or "Emma" as the agent name&lt;/p&gt; 
&lt;p&gt;Once you see the transcript start to appear, say the agent's name aloud to wake it up (e.g., "Friday").&lt;/p&gt; 
&lt;p&gt;Speak your query clearly.&lt;/p&gt; 
&lt;p&gt;End your request with a confirmation phrase to signal the system to proceed. Examples of confirmation phrases include:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;"do it", "go ahead", "execute", "run", "start", "thanks", "would ya", "please", "okay?", "proceed", "continue", "go on", "do that", "go it", "do you understand?"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Config&lt;/h2&gt; 
&lt;p&gt;Example config:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;[MAIN]
is_local = True
provider_name = ollama
provider_model = deepseek-r1:32b
provider_server_address = http://127.0.0.1:11434 # Example for Ollama; use http://127.0.0.1:1234 for LM-Studio
agent_name = Friday
recover_last_session = False
save_session = False
speak = False
listen = False

jarvis_personality = False
languages = en zh # List of languages for TTS and potentially routing.
[BROWSER]
headless_browser = False
stealth_mode = False
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Explanation of &lt;code&gt;config.ini&lt;/code&gt; Settings&lt;/strong&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;[MAIN]&lt;/code&gt; Section:&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;is_local&lt;/code&gt;: &lt;code&gt;True&lt;/code&gt; if using a local LLM provider (Ollama, LM-Studio, local OpenAI-compatible server) or the self-hosted server option. &lt;code&gt;False&lt;/code&gt; if using a cloud-based API (OpenAI, Google, etc.).&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;provider_name&lt;/code&gt;: Specifies the LLM provider. 
    &lt;ul&gt; 
     &lt;li&gt;Local options: &lt;code&gt;ollama&lt;/code&gt;, &lt;code&gt;lm-studio&lt;/code&gt;, &lt;code&gt;openai&lt;/code&gt; (for local OpenAI-compatible servers), &lt;code&gt;server&lt;/code&gt; (for the self-hosted server setup).&lt;/li&gt; 
     &lt;li&gt;API options: &lt;code&gt;openai&lt;/code&gt;, &lt;code&gt;google&lt;/code&gt;, &lt;code&gt;deepseek&lt;/code&gt;, &lt;code&gt;huggingface&lt;/code&gt;, &lt;code&gt;togetherAI&lt;/code&gt;.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;provider_model&lt;/code&gt;: The specific model name or ID for the chosen provider (e.g., &lt;code&gt;deepseekcoder:6.7b&lt;/code&gt; for Ollama, &lt;code&gt;gpt-3.5-turbo&lt;/code&gt; for OpenAI API, &lt;code&gt;mistralai/Mixtral-8x7B-Instruct-v0.1&lt;/code&gt; for TogetherAI).&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;provider_server_address&lt;/code&gt;: The address of your LLM provider. 
    &lt;ul&gt; 
     &lt;li&gt;For local providers: e.g., &lt;code&gt;http://127.0.0.1:11434&lt;/code&gt; for Ollama, &lt;code&gt;http://127.0.0.1:1234&lt;/code&gt; for LM-Studio.&lt;/li&gt; 
     &lt;li&gt;For the &lt;code&gt;server&lt;/code&gt; provider type: The address of your self-hosted LLM server (e.g., &lt;code&gt;http://your_server_ip:3333&lt;/code&gt;).&lt;/li&gt; 
     &lt;li&gt;For cloud APIs (&lt;code&gt;is_local = False&lt;/code&gt;): This is often ignored or can be left blank, as the API endpoint is usually handled by the client library.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;agent_name&lt;/code&gt;: Name of the AI assistant (e.g., Friday). Used as a trigger word for speech-to-text if enabled.&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;recover_last_session&lt;/code&gt;: &lt;code&gt;True&lt;/code&gt; to attempt to restore the previous session's state, &lt;code&gt;False&lt;/code&gt; to start fresh.&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;save_session&lt;/code&gt;: &lt;code&gt;True&lt;/code&gt; to save the current session's state for potential recovery, &lt;code&gt;False&lt;/code&gt; otherwise.&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;speak&lt;/code&gt;: &lt;code&gt;True&lt;/code&gt; to enable text-to-speech voice output, &lt;code&gt;False&lt;/code&gt; to disable.&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;listen&lt;/code&gt;: &lt;code&gt;True&lt;/code&gt; to enable speech-to-text voice input (CLI mode only), &lt;code&gt;False&lt;/code&gt; to disable.&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;work_dir&lt;/code&gt;: &lt;strong&gt;Crucial:&lt;/strong&gt; The directory where AgenticSeek will read/write files. &lt;strong&gt;Ensure this path is valid and accessible on your system.&lt;/strong&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;jarvis_personality&lt;/code&gt;: &lt;code&gt;True&lt;/code&gt; to use a more "Jarvis-like" system prompt (experimental), &lt;code&gt;False&lt;/code&gt; for the standard prompt.&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;languages&lt;/code&gt;: A comma-separated list of languages (e.g., &lt;code&gt;en, zh, fr&lt;/code&gt;). Used for TTS voice selection (defaults to the first) and can assist the LLM router. Avoid too many or very similar languages for router efficiency.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;[BROWSER]&lt;/code&gt; Section:&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;headless_browser&lt;/code&gt;: &lt;code&gt;True&lt;/code&gt; to run the automated browser without a visible window (recommended for web interface or non-interactive use). &lt;code&gt;False&lt;/code&gt; to show the browser window (useful for CLI mode or debugging).&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;stealth_mode&lt;/code&gt;: &lt;code&gt;True&lt;/code&gt; to enable measures to make browser automation harder to detect. May require manual installation of browser extensions like anticaptcha.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;This section summarizes the supported LLM provider types. Configure them in &lt;code&gt;config.ini&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Local Providers (Run on Your Own Hardware):&lt;/strong&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Provider Name in &lt;code&gt;config.ini&lt;/code&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;code&gt;is_local&lt;/code&gt;&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Setup Section&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;ollama&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;True&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Use Ollama to serve local LLMs.&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#setup-for-running-llm-locally-on-your-machine"&gt;Setup for running LLM locally&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;lm-studio&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;True&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Use LM-Studio to serve local LLMs.&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#setup-for-running-llm-locally-on-your-machine"&gt;Setup for running LLM locally&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;openai&lt;/code&gt; (for local server)&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;True&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Connect to a local server that exposes an OpenAI-compatible API (e.g., llama.cpp).&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#setup-for-running-llm-locally-on-your-machine"&gt;Setup for running LLM locally&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;server&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;False&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Connect to the AgenticSeek self-hosted LLM server running on another machine.&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#setup-to-run-the-llm-on-your-own-server"&gt;Setup to run the LLM on your own server&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;API Providers (Cloud-Based):&lt;/strong&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Provider Name in &lt;code&gt;config.ini&lt;/code&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;code&gt;is_local&lt;/code&gt;&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Setup Section&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;openai&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;False&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Use OpenAI's official API (e.g., GPT-3.5, GPT-4).&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#setup-to-run-with-an-api"&gt;Setup to run with an API&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;google&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;False&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Use Google's Gemini models via API.&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#setup-to-run-with-an-api"&gt;Setup to run with an API&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;deepseek&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;False&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Use Deepseek's official API.&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#setup-to-run-with-an-api"&gt;Setup to run with an API&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;huggingface&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;False&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Use Hugging Face Inference API.&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#setup-to-run-with-an-api"&gt;Setup to run with an API&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;togetherAI&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;False&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Use TogetherAI's API for various open models.&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#setup-to-run-with-an-api"&gt;Setup to run with an API&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Troubleshooting&lt;/h2&gt; 
&lt;p&gt;If you encounter issues, this section provides guidance.&lt;/p&gt; 
&lt;h1&gt;Known Issues&lt;/h1&gt; 
&lt;h2&gt;ChromeDriver Issues&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Error Example:&lt;/strong&gt; &lt;code&gt;SessionNotCreatedException: Message: session not created: This version of ChromeDriver only supports Chrome version XXX&lt;/code&gt;&lt;/p&gt; 
&lt;h3&gt;Root Cause&lt;/h3&gt; 
&lt;p&gt;ChromeDriver version incompatibility occurs when:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Your installed ChromeDriver version doesn't match your Chrome browser version&lt;/li&gt; 
 &lt;li&gt;In Docker environments, &lt;code&gt;undetected_chromedriver&lt;/code&gt; may download its own ChromeDriver version, bypassing the mounted binary&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Solution Steps&lt;/h3&gt; 
&lt;h4&gt;1. Check Your Chrome Version&lt;/h4&gt; 
&lt;p&gt;Open Google Chrome â†’ &lt;code&gt;Settings &amp;gt; About Chrome&lt;/code&gt; to find your version (e.g., "Version 134.0.6998.88")&lt;/p&gt; 
&lt;h4&gt;2. Download Matching ChromeDriver&lt;/h4&gt; 
&lt;p&gt;&lt;strong&gt;For Chrome 115 and newer:&lt;/strong&gt; Use the &lt;a href="https://googlechromelabs.github.io/chrome-for-testing/"&gt;Chrome for Testing API&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Visit the Chrome for Testing availability dashboard&lt;/li&gt; 
 &lt;li&gt;Find your Chrome version or the closest available match&lt;/li&gt; 
 &lt;li&gt;Download the ChromeDriver for your OS (Linux64 for Docker environments)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;For older Chrome versions:&lt;/strong&gt; Use the &lt;a href="https://chromedriver.chromium.org/downloads"&gt;legacy ChromeDriver downloads&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/media/chromedriver_readme.png" alt="Download ChromeDriver from Chrome for Testing" /&gt;&lt;/p&gt; 
&lt;h4&gt;3. Install ChromeDriver (Choose One Method)&lt;/h4&gt; 
&lt;p&gt;&lt;strong&gt;Method A: Project Root Directory (Recommended for Docker)&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Place the downloaded chromedriver binary in your project root
cp path/to/downloaded/chromedriver ./chromedriver
chmod +x ./chromedriver  # Make executable on Linux/macOS
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Method B: System PATH&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Linux/macOS
sudo mv chromedriver /usr/local/bin/
sudo chmod +x /usr/local/bin/chromedriver

# Windows: Place chromedriver.exe in a folder that's in your PATH
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;4. Verify Installation&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Test the ChromeDriver version
./chromedriver --version
# OR if in PATH:
chromedriver --version
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Docker-Specific Notes&lt;/h3&gt; 
&lt;p&gt;âš ï¸ &lt;strong&gt;Important for Docker Users:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;The Docker volume mount approach may not work with stealth mode (&lt;code&gt;undetected_chromedriver&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Solution&lt;/strong&gt;: Place ChromeDriver in the project root directory as &lt;code&gt;./chromedriver&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;The application will automatically detect and use this binary&lt;/li&gt; 
 &lt;li&gt;You should see: &lt;code&gt;"Using ChromeDriver from project root: ./chromedriver"&lt;/code&gt; in the logs&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Troubleshooting Tips&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Still getting version mismatch?&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Verify the ChromeDriver is executable: &lt;code&gt;ls -la ./chromedriver&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;Check the ChromeDriver version: &lt;code&gt;./chromedriver --version&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;Ensure it matches your Chrome browser version&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Docker container issues?&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Check backend logs: &lt;code&gt;docker logs backend&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;Look for the message: &lt;code&gt;"Using ChromeDriver from project root"&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;If not found, verify the file exists and is executable&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Chrome for Testing versions&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Use the exact version match when possible&lt;/li&gt; 
   &lt;li&gt;For version 134.0.6998.88, use ChromeDriver 134.0.6998.165 (closest available)&lt;/li&gt; 
   &lt;li&gt;Major version numbers must match (134 = 134)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Version Compatibility Matrix&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Chrome Version&lt;/th&gt; 
   &lt;th&gt;ChromeDriver Version&lt;/th&gt; 
   &lt;th&gt;Status&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;134.0.6998.x&lt;/td&gt; 
   &lt;td&gt;134.0.6998.165&lt;/td&gt; 
   &lt;td&gt;âœ… Works&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;133.0.6943.x&lt;/td&gt; 
   &lt;td&gt;133.0.6943.141&lt;/td&gt; 
   &lt;td&gt;âœ… Works&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;132.0.6834.x&lt;/td&gt; 
   &lt;td&gt;132.0.6834.159&lt;/td&gt; 
   &lt;td&gt;âœ… Works&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;em&gt;For the latest compatibility, check the &lt;a href="https://googlechromelabs.github.io/chrome-for-testing/"&gt;Chrome for Testing dashboard&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;Exception: Failed to initialize browser: Message: session not created: This version of ChromeDriver only supports Chrome version 113 Current browser version is 134.0.6998.89 with binary path&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;This happen if there is a mismatch between your browser and chromedriver version.&lt;/p&gt; 
&lt;p&gt;You need to navigate to download the latest version:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://developer.chrome.com/docs/chromedriver/downloads"&gt;https://developer.chrome.com/docs/chromedriver/downloads&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;If you're using Chrome version 115 or newer go to:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://googlechromelabs.github.io/chrome-for-testing/"&gt;https://googlechromelabs.github.io/chrome-for-testing/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;And download the chromedriver version matching your OS.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/media/chromedriver_readme.png" alt="alt text" /&gt;&lt;/p&gt; 
&lt;p&gt;If this section is incomplete please raise an issue.&lt;/p&gt; 
&lt;h2&gt;connection adapters Issues&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;Exception: Provider lm-studio failed: HTTP request failed: No connection adapters were found for '127.0.0.1:1234/v1/chat/completions'` (Note: port may vary)
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Cause:&lt;/strong&gt; The &lt;code&gt;provider_server_address&lt;/code&gt; in &lt;code&gt;config.ini&lt;/code&gt; for &lt;code&gt;lm-studio&lt;/code&gt; (or other similar local OpenAI-compatible servers) is missing the &lt;code&gt;http://&lt;/code&gt; prefix or is pointing to the wrong port.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Solution:&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Ensure the address includes &lt;code&gt;http://&lt;/code&gt;. LM-Studio typically defaults to &lt;code&gt;http://127.0.0.1:1234&lt;/code&gt;.&lt;/li&gt; 
   &lt;li&gt;Correct &lt;code&gt;config.ini&lt;/code&gt;: &lt;code&gt;provider_server_address = http://127.0.0.1:1234&lt;/code&gt; (or your actual LM-Studio server port).&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;SearxNG Base URL Not Provided&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;raise ValueError("SearxNG base URL must be provided either as an argument or via the SEARXNG_BASE_URL environment variable.")
ValueError: SearxNG base URL must be provided either as an argument or via the SEARXNG_BASE_URL environment variable.`
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;FAQ&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Q: What hardware do I need?&lt;/strong&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Model Size&lt;/th&gt; 
   &lt;th&gt;GPU&lt;/th&gt; 
   &lt;th&gt;Comment&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;7B&lt;/td&gt; 
   &lt;td&gt;8GB Vram&lt;/td&gt; 
   &lt;td&gt;âš ï¸ Not recommended. Performance is poor, frequent hallucinations, and planner agents will likely fail.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;14B&lt;/td&gt; 
   &lt;td&gt;12 GB VRAM (e.g. RTX 3060)&lt;/td&gt; 
   &lt;td&gt;âœ… Usable for simple tasks. May struggle with web browsing and planning tasks.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;32B&lt;/td&gt; 
   &lt;td&gt;24+ GB VRAM (e.g. RTX 4090)&lt;/td&gt; 
   &lt;td&gt;ğŸš€ Success with most tasks, might still struggle with task planning&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;70B+&lt;/td&gt; 
   &lt;td&gt;48+ GB Vram&lt;/td&gt; 
   &lt;td&gt;ğŸ’ª Excellent. Recommended for advanced use cases.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;Q: I get an error what do I do?&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Ensure local is running (&lt;code&gt;ollama serve&lt;/code&gt;), your &lt;code&gt;config.ini&lt;/code&gt; matches your provider, and dependencies are installed. If none work feel free to raise an issue.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Q: Can it really run 100% locally?&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Yes with Ollama, lm-studio or server providers, all speech to text, LLM and text to speech model run locally. Non-local options (OpenAI or others API) are optional.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Q: Why should I use AgenticSeek when I have Manus?&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Unlike Manus, AgenticSeek prioritizes independence from external systems, giving you more control, privacy and avoid api cost.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Q: Who is behind the project ?&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;The project was created by me, along with two friends who serve as maintainers and contributors from the open-source community on GitHub. Weâ€™re just a group of passionate individuals, not a startup or affiliated with any organization.&lt;/p&gt; 
&lt;p&gt;Any AgenticSeek account on X other than my personal account (&lt;a href="https://x.com/Martin993886460"&gt;https://x.com/Martin993886460&lt;/a&gt;) is an impersonation.&lt;/p&gt; 
&lt;h2&gt;Contribute&lt;/h2&gt; 
&lt;p&gt;Weâ€™re looking for developers to improve AgenticSeek! Check out open issues or discussion.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/docs/CONTRIBUTING.md"&gt;Contribution guide&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Sponsors:&lt;/h2&gt; 
&lt;p&gt;Want to level up AgenticSeek capabilities with features like flight search, trip planning, or snagging the best shopping deals? Consider crafting a custom tool with SerpApi to unlock more Jarvis-like capabilities. With SerpApi, you can turbocharge your agent for specialized tasks while staying in full control.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://serpapi.com/"&gt;&lt;img src="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/media/banners/sponsor_banner_serpapi.png" height="350" alt="SerpApi Banner" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/docs/CONTRIBUTING.md"&gt;Contributing.md&lt;/a&gt; to learn how to integrate custom tools!&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;Patron sponsor&lt;/strong&gt;:&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tatra-labs"&gt;tatra-labs&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Maintainers:&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;a href="https://github.com/Fosowl"&gt;Fosowl&lt;/a&gt; | Paris Time&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;a href="https://github.com/antoineVIVIES"&gt;antoineVIVIES&lt;/a&gt; | Taipei Time&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Special Thanks:&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;a href="https://github.com/tcsenpai"&gt;tcsenpai&lt;/a&gt; and &lt;a href="https://github.com/plitc"&gt;plitc&lt;/a&gt; For helping with backend dockerization&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;a href="https://www.star-history.com/#Fosowl/agenticSeek&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=Fosowl/agenticSeek&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>HunxByts/GhostTrack</title>
      <link>https://github.com/HunxByts/GhostTrack</link>
      <description>&lt;p&gt;Useful tool to track location or mobile number&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;GhostTrack&lt;/h1&gt; 
&lt;p&gt;Useful tool to track location or mobile number, so this tool can be called osint or also information gathering&lt;/p&gt; 
&lt;img src="https://github.com/HunxByts/GhostTrack/raw/main/asset/bn.png" /&gt; 
&lt;p&gt;New update : &lt;code&gt;Version 2.2&lt;/code&gt;&lt;/p&gt; 
&lt;h3&gt;Instalation on Linux (deb)&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;sudo apt-get install git
sudo apt-get install python3
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Instalation on Termux&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;pkg install git
pkg install python3
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Usage Tool&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;git clone https://github.com/HunxByts/GhostTrack.git
cd GhostTrack
pip3 install -r requirements.txt
python3 GhostTR.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Display on the menu &lt;code&gt;IP Tracker&lt;/code&gt;&lt;/p&gt; 
&lt;img src="https://github.com/HunxByts/GhostTrack/blob/main/asset/ip.png " /&gt; 
&lt;p&gt;on the IP Track menu, you can combo with the seeker tool to get the target IP&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;span&gt;âš¡&lt;/span&gt; Install Seeker :&lt;/summary&gt; - 
 &lt;strong&gt;&lt;a href="https://github.com/thewhiteh4t/seeker"&gt;Get Seeker&lt;/a&gt;&lt;/strong&gt; 
&lt;/details&gt; 
&lt;p&gt;Display on the menu &lt;code&gt;Phone Tracker&lt;/code&gt;&lt;/p&gt; 
&lt;img src="https://github.com/HunxByts/GhostTrack/raw/main/asset/phone.png" /&gt; 
&lt;p&gt;on this menu you can search for information from the target phone number&lt;/p&gt; 
&lt;p&gt;Display on the menu &lt;code&gt;Username Tracker&lt;/code&gt;&lt;/p&gt; 
&lt;img src="https://github.com/HunxByts/GhostTrack/raw/main/asset/User.png" /&gt; on this menu you can search for information from the target username on social media 
&lt;details&gt; 
 &lt;summary&gt;&lt;span&gt;âš¡&lt;/span&gt; Author :&lt;/summary&gt; - 
 &lt;strong&gt;&lt;a href="https://github.com/HunxByts"&gt;HunxByts&lt;/a&gt;&lt;/strong&gt; 
&lt;/details&gt;</description>
    </item>
    
    <item>
      <title>microsoft/qlib</title>
      <link>https://github.com/microsoft/qlib</link>
      <description>&lt;p&gt;Qlib is an AI-oriented Quant investment platform that aims to use AI tech to empower Quant Research, from exploring ideas to implementing productions. Qlib supports diverse ML modeling paradigms, including supervised learning, market dynamics modeling, and RL, and is now equipped with https://github.com/microsoft/RD-Agent to automate R&amp;D process.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href="https://pypi.org/project/pyqlib/#files"&gt;&lt;img src="https://img.shields.io/pypi/pyversions/pyqlib.svg?logo=python&amp;amp;logoColor=white" alt="Python Versions" /&gt;&lt;/a&gt; &lt;a href="https://pypi.org/project/pyqlib/#files"&gt;&lt;img src="https://img.shields.io/badge/platform-linux%20%7C%20windows%20%7C%20macos-lightgrey" alt="Platform" /&gt;&lt;/a&gt; &lt;a href="https://pypi.org/project/pyqlib/#history"&gt;&lt;img src="https://img.shields.io/pypi/v/pyqlib" alt="PypI Versions" /&gt;&lt;/a&gt; &lt;a href="https://pypi.org/project/pyqlib/"&gt;&lt;img src="https://github.com/microsoft/qlib/workflows/Upload%20Python%20Package/badge.svg?sanitize=true" alt="Upload Python Package" /&gt;&lt;/a&gt; &lt;a href="https://github.com/microsoft/qlib/actions"&gt;&lt;img src="https://github.com/microsoft/qlib/workflows/Test/badge.svg?branch=main" alt="Github Actions Test Status" /&gt;&lt;/a&gt; &lt;a href="https://qlib.readthedocs.io/en/latest/?badge=latest"&gt;&lt;img src="https://readthedocs.org/projects/qlib/badge/?version=latest" alt="Documentation Status" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/LICENSE"&gt;&lt;img src="https://img.shields.io/pypi/l/pyqlib" alt="License" /&gt;&lt;/a&gt; &lt;a href="https://gitter.im/Microsoft/qlib?utm_source=badge&amp;amp;utm_medium=badge&amp;amp;utm_campaign=pr-badge&amp;amp;utm_content=badge"&gt;&lt;img src="https://badges.gitter.im/Microsoft/qlib.svg?sanitize=true" alt="Join the chat at https://gitter.im/Microsoft/qlib" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;&lt;span&gt;ğŸ“°&lt;/span&gt; &lt;strong&gt;What's NEW!&lt;/strong&gt; &amp;nbsp; &lt;span&gt;ğŸ’–&lt;/span&gt;&lt;/h2&gt; 
&lt;p&gt;Recent released features&lt;/p&gt; 
&lt;h3&gt;Introducing &lt;a href="https://github.com/microsoft/RD-Agent"&gt;&lt;img src="https://raw.githubusercontent.com/microsoft/qlib/main/docs/_static/img/rdagent_logo.png" alt="RD_Agent" style="height: 2em" /&gt;&lt;/a&gt;: LLM-Based Autonomous Evolving Agents for Industrial Data-Driven R&amp;amp;D&lt;/h3&gt; 
&lt;p&gt;We are excited to announce the release of &lt;strong&gt;RD-Agent&lt;/strong&gt;ğŸ“¢, a powerful tool that supports automated factor mining and model optimization in quant investment R&amp;amp;D.&lt;/p&gt; 
&lt;p&gt;RD-Agent is now available on &lt;a href="https://github.com/microsoft/RD-Agent"&gt;GitHub&lt;/a&gt;, and we welcome your starğŸŒŸ!&lt;/p&gt; 
&lt;p&gt;To learn more, please visit our &lt;a href="https://rdagent.azurewebsites.net/"&gt;â™¾ï¸Demo page&lt;/a&gt;. Here, you will find demo videos in both English and Chinese to help you better understand the scenario and usage of RD-Agent.&lt;/p&gt; 
&lt;p&gt;We have prepared several demo videos for you:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Scenario&lt;/th&gt; 
   &lt;th&gt;Demo video (English)&lt;/th&gt; 
   &lt;th&gt;Demo video (ä¸­æ–‡)&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Quant Factor Mining&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://rdagent.azurewebsites.net/factor_loop?lang=en"&gt;Link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://rdagent.azurewebsites.net/factor_loop?lang=zh"&gt;Link&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Quant Factor Mining from reports&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://rdagent.azurewebsites.net/report_factor?lang=en"&gt;Link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://rdagent.azurewebsites.net/report_factor?lang=zh"&gt;Link&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Quant Model Optimization&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://rdagent.azurewebsites.net/model_loop?lang=en"&gt;Link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://rdagent.azurewebsites.net/model_loop?lang=zh"&gt;Link&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;ul&gt; 
 &lt;li&gt;ğŸ“ƒ&lt;strong&gt;Paper&lt;/strong&gt;: &lt;a href="https://arxiv.org/abs/2505.15155"&gt;R&amp;amp;D-Agent-Quant: A Multi-Agent Framework for Data-Centric Factors and Model Joint Optimization&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;ğŸ‘¾&lt;strong&gt;Code&lt;/strong&gt;: &lt;a href="https://github.com/microsoft/RD-Agent/"&gt;https://github.com/microsoft/RD-Agent/&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-BibTeX"&gt;@misc{li2025rdagentquant,
    title={R\&amp;amp;D-Agent-Quant: A Multi-Agent Framework for Data-Centric Factors and Model Joint Optimization},
    author={Yuante Li and Xu Yang and Xiao Yang and Minrui Xu and Xisen Wang and Weiqing Liu and Jiang Bian},
    year={2025},
    eprint={2505.15155},
    archivePrefix={arXiv},
    primaryClass={cs.AI}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/3198bc10-47ba-4ee0-8a8e-46d5ce44f45d" alt="image" /&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Feature&lt;/th&gt; 
   &lt;th&gt;Status&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://arxiv.org/abs/2505.15155"&gt;R&amp;amp;D-Agent-Quant&lt;/a&gt; Published&lt;/td&gt; 
   &lt;td&gt;Apply R&amp;amp;D-Agent to Qlib for quant trading&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BPQP for End-to-end learning&lt;/td&gt; 
   &lt;td&gt;ğŸ“ˆComing soon!(&lt;a href="https://github.com/microsoft/qlib/pull/1863"&gt;Under review&lt;/a&gt;)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ğŸ”¥LLM-driven Auto Quant FactoryğŸ”¥&lt;/td&gt; 
   &lt;td&gt;ğŸš€ Released in &lt;a href="https://github.com/microsoft/RD-Agent"&gt;â™¾ï¸RD-Agent&lt;/a&gt; on Aug 8, 2024&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;KRNN and Sandwich models&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;ğŸ“ˆ&lt;/span&gt; &lt;a href="https://github.com/microsoft/qlib/pull/1414/"&gt;Released&lt;/a&gt; on May 26, 2023&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Release Qlib v0.9.0&lt;/td&gt; 
   &lt;td&gt;&lt;img alt="octocat" src="https://github.githubassets.com/images/icons/emoji/octocat.png?v8" /&gt;) &lt;a href="https://github.com/microsoft/qlib/releases/tag/v0.9.0"&gt;Released&lt;/a&gt; on Dec 9, 2022&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;RL Learning Framework&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;ğŸ”¨&lt;/span&gt; &lt;span&gt;ğŸ“ˆ&lt;/span&gt; Released on Nov 10, 2022. &lt;a href="https://github.com/microsoft/qlib/pull/1332"&gt;#1332&lt;/a&gt;, &lt;a href="https://github.com/microsoft/qlib/pull/1322"&gt;#1322&lt;/a&gt;, &lt;a href="https://github.com/microsoft/qlib/pull/1316"&gt;#1316&lt;/a&gt;,&lt;a href="https://github.com/microsoft/qlib/pull/1299"&gt;#1299&lt;/a&gt;,&lt;a href="https://github.com/microsoft/qlib/pull/1263"&gt;#1263&lt;/a&gt;, &lt;a href="https://github.com/microsoft/qlib/pull/1244"&gt;#1244&lt;/a&gt;, &lt;a href="https://github.com/microsoft/qlib/pull/1169"&gt;#1169&lt;/a&gt;, &lt;a href="https://github.com/microsoft/qlib/pull/1125"&gt;#1125&lt;/a&gt;, &lt;a href="https://github.com/microsoft/qlib/pull/1076"&gt;#1076&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;HIST and IGMTF models&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;ğŸ“ˆ&lt;/span&gt; &lt;a href="https://github.com/microsoft/qlib/pull/1040"&gt;Released&lt;/a&gt; on Apr 10, 2022&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Qlib &lt;a href="https://github.com/microsoft/qlib/tree/main/examples/tutorial"&gt;notebook tutorial&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;ğŸ“– &lt;a href="https://github.com/microsoft/qlib/pull/1037"&gt;Released&lt;/a&gt; on Apr 7, 2022&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Ibovespa index data&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;ğŸš&lt;/span&gt; &lt;a href="https://github.com/microsoft/qlib/pull/990"&gt;Released&lt;/a&gt; on Apr 6, 2022&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Point-in-Time database&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;ğŸ”¨&lt;/span&gt; &lt;a href="https://github.com/microsoft/qlib/pull/343"&gt;Released&lt;/a&gt; on Mar 10, 2022&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Arctic Provider Backend &amp;amp; Orderbook data example&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;ğŸ”¨&lt;/span&gt; &lt;a href="https://github.com/microsoft/qlib/pull/744"&gt;Released&lt;/a&gt; on Jan 17, 2022&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Meta-Learning-based framework &amp;amp; DDG-DA&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;ğŸ“ˆ&lt;/span&gt; &lt;span&gt;ğŸ”¨&lt;/span&gt; &lt;a href="https://github.com/microsoft/qlib/pull/743"&gt;Released&lt;/a&gt; on Jan 10, 2022&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Planning-based portfolio optimization&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;ğŸ”¨&lt;/span&gt; &lt;a href="https://github.com/microsoft/qlib/pull/754"&gt;Released&lt;/a&gt; on Dec 28, 2021&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Release Qlib v0.8.0&lt;/td&gt; 
   &lt;td&gt;&lt;img alt="octocat" src="https://github.githubassets.com/images/icons/emoji/octocat.png?v8" /&gt;) &lt;a href="https://github.com/microsoft/qlib/releases/tag/v0.8.0"&gt;Released&lt;/a&gt; on Dec 8, 2021&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ADD model&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;ğŸ“ˆ&lt;/span&gt; &lt;a href="https://github.com/microsoft/qlib/pull/704"&gt;Released&lt;/a&gt; on Nov 22, 2021&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ADARNN model&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;ğŸ“ˆ&lt;/span&gt; &lt;a href="https://github.com/microsoft/qlib/pull/689"&gt;Released&lt;/a&gt; on Nov 14, 2021&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;TCN model&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;ğŸ“ˆ&lt;/span&gt; &lt;a href="https://github.com/microsoft/qlib/pull/668"&gt;Released&lt;/a&gt; on Nov 4, 2021&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Nested Decision Framework&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;ğŸ”¨&lt;/span&gt; &lt;a href="https://github.com/microsoft/qlib/pull/438"&gt;Released&lt;/a&gt; on Oct 1, 2021. &lt;a href="https://github.com/microsoft/qlib/raw/main/examples/nested_decision_execution/workflow.py"&gt;Example&lt;/a&gt; and &lt;a href="https://qlib.readthedocs.io/en/latest/component/highfreq.html"&gt;Doc&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Temporal Routing Adaptor (TRA)&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;ğŸ“ˆ&lt;/span&gt; &lt;a href="https://github.com/microsoft/qlib/pull/531"&gt;Released&lt;/a&gt; on July 30, 2021&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Transformer &amp;amp; Localformer&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;ğŸ“ˆ&lt;/span&gt; &lt;a href="https://github.com/microsoft/qlib/pull/508"&gt;Released&lt;/a&gt; on July 22, 2021&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Release Qlib v0.7.0&lt;/td&gt; 
   &lt;td&gt;&lt;img alt="octocat" src="https://github.githubassets.com/images/icons/emoji/octocat.png?v8" /&gt;) &lt;a href="https://github.com/microsoft/qlib/releases/tag/v0.7.0"&gt;Released&lt;/a&gt; on July 12, 2021&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;TCTS Model&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;ğŸ“ˆ&lt;/span&gt; &lt;a href="https://github.com/microsoft/qlib/pull/491"&gt;Released&lt;/a&gt; on July 1, 2021&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Online serving and automatic model rolling&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;ğŸ”¨&lt;/span&gt; &lt;a href="https://github.com/microsoft/qlib/pull/290"&gt;Released&lt;/a&gt; on May 17, 2021&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;DoubleEnsemble Model&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;ğŸ“ˆ&lt;/span&gt; &lt;a href="https://github.com/microsoft/qlib/pull/286"&gt;Released&lt;/a&gt; on Mar 2, 2021&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;High-frequency data processing example&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;ğŸ”¨&lt;/span&gt; &lt;a href="https://github.com/microsoft/qlib/pull/257"&gt;Released&lt;/a&gt; on Feb 5, 2021&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;High-frequency trading example&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;ğŸ“ˆ&lt;/span&gt; &lt;a href="https://github.com/microsoft/qlib/pull/227"&gt;Part of code released&lt;/a&gt; on Jan 28, 2021&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;High-frequency data(1min)&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;ğŸš&lt;/span&gt; &lt;a href="https://github.com/microsoft/qlib/pull/221"&gt;Released&lt;/a&gt; on Jan 27, 2021&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Tabnet Model&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;ğŸ“ˆ&lt;/span&gt; &lt;a href="https://github.com/microsoft/qlib/pull/205"&gt;Released&lt;/a&gt; on Jan 22, 2021&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Features released before 2021 are not listed here.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/microsoft/qlib/main/docs/_static/img/logo/1.png" /&gt; &lt;/p&gt; 
&lt;p&gt;Qlib is an open-source, AI-oriented quantitative investment platform that aims to realize the potential, empower research, and create value using AI technologies in quantitative investment, from exploring ideas to implementing productions. Qlib supports diverse machine learning modeling paradigms, including supervised learning, market dynamics modeling, and reinforcement learning.&lt;/p&gt; 
&lt;p&gt;An increasing number of SOTA Quant research works/papers in diverse paradigms are being released in Qlib to collaboratively solve key challenges in quantitative investment. For example, 1) using supervised learning to mine the market's complex non-linear patterns from rich and heterogeneous financial data, 2) modeling the dynamic nature of the financial market using adaptive concept drift technology, and 3) using reinforcement learning to model continuous investment decisions and assist investors in optimizing their trading strategies.&lt;/p&gt; 
&lt;p&gt;It contains the full ML pipeline of data processing, model training, back-testing; and covers the entire chain of quantitative investment: alpha seeking, risk modeling, portfolio optimization, and order execution. For more details, please refer to our paper &lt;a href="https://arxiv.org/abs/2009.11189"&gt;"Qlib: An AI-oriented Quantitative Investment Platform"&lt;/a&gt;.&lt;/p&gt; 
&lt;table&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Frameworks, Tutorial, Data &amp;amp; DevOps&lt;/th&gt; 
   &lt;th&gt;Main Challenges &amp;amp; Solutions in Quant Research&lt;/th&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/#plans"&gt;&lt;strong&gt;Plans&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/#framework-of-qlib"&gt;Framework of Qlib&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/#quick-start"&gt;Quick Start&lt;/a&gt;&lt;/li&gt; 
    &lt;ul dir="auto"&gt; 
     &lt;li type="circle"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/#installation"&gt;Installation&lt;/a&gt; &lt;/li&gt; 
     &lt;li type="circle"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/#data-preparation"&gt;Data Preparation&lt;/a&gt;&lt;/li&gt; 
     &lt;li type="circle"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/#auto-quant-research-workflow"&gt;Auto Quant Research Workflow&lt;/a&gt;&lt;/li&gt; 
     &lt;li type="circle"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/#building-customized-quant-research-workflow-by-code"&gt;Building Customized Quant Research Workflow by Code&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt; &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/#quant-dataset-zoo"&gt;&lt;strong&gt;Quant Dataset Zoo&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/#learning-framework"&gt;Learning Framework&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/#more-about-qlib"&gt;More About Qlib&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/#offline-mode-and-online-mode"&gt;Offline Mode and Online Mode&lt;/a&gt; 
     &lt;ul&gt; 
      &lt;li type="circle"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/#performance-of-qlib-data-server"&gt;Performance of Qlib Data Server&lt;/a&gt;&lt;/li&gt;
     &lt;/ul&gt; &lt;/li&gt;&lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/#related-reports"&gt;Related Reports&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/#contact-us"&gt;Contact Us&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/#contributing"&gt;Contributing&lt;/a&gt;&lt;/li&gt; &lt;/td&gt; 
   &lt;td valign="baseline"&gt; &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/#main-challenges--solutions-in-quant-research"&gt;Main Challenges &amp;amp; Solutions in Quant Research&lt;/a&gt; 
     &lt;ul&gt; 
      &lt;li type="circle"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/#forecasting-finding-valuable-signalspatterns"&gt;Forecasting: Finding Valuable Signals/Patterns&lt;/a&gt; 
       &lt;ul&gt; 
        &lt;li type="disc"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/#quant-model-paper-zoo"&gt;&lt;strong&gt;Quant Model (Paper) Zoo&lt;/strong&gt;&lt;/a&gt; 
         &lt;ul&gt; 
          &lt;li type="circle"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/#run-a-single-model"&gt;Run a Single Model&lt;/a&gt;&lt;/li&gt; 
          &lt;li type="circle"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/#run-multiple-models"&gt;Run Multiple Models&lt;/a&gt;&lt;/li&gt; 
         &lt;/ul&gt; &lt;/li&gt; 
       &lt;/ul&gt; &lt;/li&gt; 
      &lt;li type="circle"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/#adapting-to-market-dynamics"&gt;Adapting to Market Dynamics&lt;/a&gt;&lt;/li&gt; 
      &lt;li type="circle"&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/#reinforcement-learning-modeling-continuous-decisions"&gt;Reinforcement Learning: modeling continuous decisions&lt;/a&gt;&lt;/li&gt; 
     &lt;/ul&gt; &lt;/li&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h1&gt;Plans&lt;/h1&gt; 
&lt;p&gt;New features under development(order by estimated release time). Your feedbacks about the features are very important.&lt;/p&gt; 
&lt;!-- | Feature                        | Status      | --&gt; 
&lt;!-- | --                      | ------    | --&gt; 
&lt;h1&gt;Framework of Qlib&lt;/h1&gt; 
&lt;div style="align: center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/microsoft/qlib/main/docs/_static/img/framework-abstract.jpg" /&gt; 
&lt;/div&gt; 
&lt;p&gt;The high-level framework of Qlib can be found above(users can find the &lt;a href="https://qlib.readthedocs.io/en/latest/introduction/introduction.html#framework"&gt;detailed framework&lt;/a&gt; of Qlib's design when getting into nitty gritty). The components are designed as loose-coupled modules, and each component could be used stand-alone.&lt;/p&gt; 
&lt;p&gt;Qlib provides a strong infrastructure to support Quant research. &lt;a href="https://qlib.readthedocs.io/en/latest/component/data.html"&gt;Data&lt;/a&gt; is always an important part. A strong learning framework is designed to support diverse learning paradigms (e.g. &lt;a href="https://qlib.readthedocs.io/en/latest/component/rl.html"&gt;reinforcement learning&lt;/a&gt;, &lt;a href="https://qlib.readthedocs.io/en/latest/component/workflow.html#model-section"&gt;supervised learning&lt;/a&gt;) and patterns at different levels(e.g. &lt;a href="https://qlib.readthedocs.io/en/latest/component/meta.html"&gt;market dynamic modeling&lt;/a&gt;). By modeling the market, &lt;a href="https://qlib.readthedocs.io/en/latest/component/strategy.html"&gt;trading strategies&lt;/a&gt; will generate trade decisions that will be executed. Multiple trading strategies and executors in different levels or granularities can be &lt;a href="https://qlib.readthedocs.io/en/latest/component/highfreq.html"&gt;nested to be optimized and run together&lt;/a&gt;. At last, a comprehensive &lt;a href="https://qlib.readthedocs.io/en/latest/component/report.html"&gt;analysis&lt;/a&gt; will be provided and the model can be &lt;a href="https://qlib.readthedocs.io/en/latest/component/online.html"&gt;served online&lt;/a&gt; in a low cost.&lt;/p&gt; 
&lt;h1&gt;Quick Start&lt;/h1&gt; 
&lt;p&gt;This quick start guide tries to demonstrate&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;It's very easy to build a complete Quant research workflow and try your ideas with &lt;em&gt;Qlib&lt;/em&gt;.&lt;/li&gt; 
 &lt;li&gt;Though with &lt;em&gt;public data&lt;/em&gt; and &lt;em&gt;simple models&lt;/em&gt;, machine learning technologies &lt;strong&gt;work very well&lt;/strong&gt; in practical Quant investment.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Here is a quick &lt;strong&gt;&lt;a href="https://terminalizer.com/view/3f24561a4470"&gt;demo&lt;/a&gt;&lt;/strong&gt; shows how to install &lt;code&gt;Qlib&lt;/code&gt;, and run LightGBM with &lt;code&gt;qrun&lt;/code&gt;. &lt;strong&gt;But&lt;/strong&gt;, please make sure you have already prepared the data following the &lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/#data-preparation"&gt;instruction&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;This table demonstrates the supported Python version of &lt;code&gt;Qlib&lt;/code&gt;:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;&lt;/th&gt; 
   &lt;th align="center"&gt;install with pip&lt;/th&gt; 
   &lt;th align="center"&gt;install from source&lt;/th&gt; 
   &lt;th align="center"&gt;plot&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Python 3.8&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;span&gt;âœ”&lt;/span&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;span&gt;âœ”&lt;/span&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;span&gt;âœ”&lt;/span&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Python 3.9&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;span&gt;âœ”&lt;/span&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;span&gt;âœ”&lt;/span&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;span&gt;âœ”&lt;/span&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Python 3.10&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;span&gt;âœ”&lt;/span&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;span&gt;âœ”&lt;/span&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;span&gt;âœ”&lt;/span&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Python 3.11&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;span&gt;âœ”&lt;/span&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;span&gt;âœ”&lt;/span&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;span&gt;âœ”&lt;/span&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Python 3.12&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;span&gt;âœ”&lt;/span&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;span&gt;âœ”&lt;/span&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;span&gt;âœ”&lt;/span&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Conda&lt;/strong&gt; is suggested for managing your Python environment. In some cases, using Python outside of a &lt;code&gt;conda&lt;/code&gt; environment may result in missing header files, causing the installation failure of certain packages.&lt;/li&gt; 
 &lt;li&gt;Please pay attention that installing cython in Python 3.6 will raise some error when installing &lt;code&gt;Qlib&lt;/code&gt; from source. If users use Python 3.6 on their machines, it is recommended to &lt;em&gt;upgrade&lt;/em&gt; Python to version 3.8 or higher, or use &lt;code&gt;conda&lt;/code&gt;'s Python to install &lt;code&gt;Qlib&lt;/code&gt; from source.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Install with pip&lt;/h3&gt; 
&lt;p&gt;Users can easily install &lt;code&gt;Qlib&lt;/code&gt; by pip according to the following command.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;  pip install pyqlib
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: pip will install the latest stable qlib. However, the main branch of qlib is in active development. If you want to test the latest scripts or functions in the main branch. Please install qlib with the methods below.&lt;/p&gt; 
&lt;h3&gt;Install from source&lt;/h3&gt; 
&lt;p&gt;Also, users can install the latest dev version &lt;code&gt;Qlib&lt;/code&gt; by the source code according to the following steps:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Before installing &lt;code&gt;Qlib&lt;/code&gt; from source, users need to install some dependencies:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;pip install numpy
pip install --upgrade cython
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Clone the repository and install &lt;code&gt;Qlib&lt;/code&gt; as follows.&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/microsoft/qlib.git &amp;amp;&amp;amp; cd qlib
pip install .  # `pip install -e .[dev]` is recommended for development. check details in docs/developer/code_standard_and_dev_guide.rst
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Tips&lt;/strong&gt;: If you fail to install &lt;code&gt;Qlib&lt;/code&gt; or run the examples in your environment, comparing your steps and the &lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/.github/workflows/test_qlib_from_source.yml"&gt;CI workflow&lt;/a&gt; may help you find the problem.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Tips for Mac&lt;/strong&gt;: If you are using Mac with M1, you might encounter issues in building the wheel for LightGBM, which is due to missing dependencies from OpenMP. To solve the problem, install openmp first with &lt;code&gt;brew install libomp&lt;/code&gt; and then run &lt;code&gt;pip install .&lt;/code&gt; to build it successfully.&lt;/p&gt; 
&lt;h2&gt;Data Preparation&lt;/h2&gt; 
&lt;p&gt;â— Due to more restrict data security policy. The official dataset is disabled temporarily. You can try &lt;a href="https://github.com/chenditc/investment_data/releases"&gt;this data source&lt;/a&gt; contributed by the community. Here is an example to download the latest data.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;wget https://github.com/chenditc/investment_data/releases/latest/download/qlib_bin.tar.gz
mkdir -p ~/.qlib/qlib_data/cn_data
tar -zxvf qlib_bin.tar.gz -C ~/.qlib/qlib_data/cn_data --strip-components=1
rm -f qlib_bin.tar.gz
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The official dataset below will resume in short future.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;Load and prepare data by running the following code:&lt;/p&gt; 
&lt;h3&gt;Get with module&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# get 1d data
python -m qlib.cli.data qlib_data --target_dir ~/.qlib/qlib_data/cn_data --region cn

# get 1min data
python -m qlib.cli.data qlib_data --target_dir ~/.qlib/qlib_data/cn_data_1min --region cn --interval 1min

&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Get from source&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# get 1d data
python scripts/get_data.py qlib_data --target_dir ~/.qlib/qlib_data/cn_data --region cn

# get 1min data
python scripts/get_data.py qlib_data --target_dir ~/.qlib/qlib_data/cn_data_1min --region cn --interval 1min

&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This dataset is created by public data collected by &lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/scripts/data_collector/"&gt;crawler scripts&lt;/a&gt;, which have been released in the same repository. Users could create the same dataset with it. &lt;a href="https://github.com/microsoft/qlib/tree/main/scripts/data_collector#description-of-dataset"&gt;Description of dataset&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;Please pay &lt;strong&gt;ATTENTION&lt;/strong&gt; that the data is collected from &lt;a href="https://finance.yahoo.com/lookup"&gt;Yahoo Finance&lt;/a&gt;, and the data might not be perfect. We recommend users to prepare their own data if they have a high-quality dataset. For more information, users can refer to the &lt;a href="https://qlib.readthedocs.io/en/latest/component/data.html#converting-csv-format-into-qlib-format"&gt;related document&lt;/a&gt;&lt;/em&gt;.&lt;/p&gt; 
&lt;h3&gt;Automatic update of daily frequency data (from yahoo finance)&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;This step is &lt;em&gt;Optional&lt;/em&gt; if users only want to try their models and strategies on history data.&lt;/p&gt; 
 &lt;p&gt;It is recommended that users update the data manually once (--trading_date 2021-05-25) and then set it to update automatically.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: Users can't incrementally update data based on the offline data provided by Qlib(some fields are removed to reduce the data size). Users should use &lt;a href="https://github.com/microsoft/qlib/tree/main/scripts/data_collector/yahoo#automatic-update-of-daily-frequency-datafrom-yahoo-finance"&gt;yahoo collector&lt;/a&gt; to download Yahoo data from scratch and then incrementally update it.&lt;/p&gt; 
 &lt;p&gt;For more information, please refer to: &lt;a href="https://github.com/microsoft/qlib/tree/main/scripts/data_collector/yahoo#automatic-update-of-daily-frequency-datafrom-yahoo-finance"&gt;yahoo collector&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Automatic update of data to the "qlib" directory each trading day(Linux)&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;use &lt;em&gt;crontab&lt;/em&gt;: &lt;code&gt;crontab -e&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;set up timed tasks:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;* * * * 1-5 python &amp;lt;script path&amp;gt; update_data_to_bin --qlib_data_1d_dir &amp;lt;user data dir&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;strong&gt;script path&lt;/strong&gt;: &lt;em&gt;scripts/data_collector/yahoo/collector.py&lt;/em&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Manual update of data&lt;/p&gt; &lt;pre&gt;&lt;code&gt;python scripts/data_collector/yahoo/collector.py update_data_to_bin --qlib_data_1d_dir &amp;lt;user data dir&amp;gt; --trading_date &amp;lt;start date&amp;gt; --end_date &amp;lt;end date&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;em&gt;trading_date&lt;/em&gt;: start of trading day&lt;/li&gt; 
   &lt;li&gt;&lt;em&gt;end_date&lt;/em&gt;: end of trading day(not included)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Checking the health of the data&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;We provide a script to check the health of the data, you can run the following commands to check whether the data is healthy or not. &lt;pre&gt;&lt;code&gt;python scripts/check_data_health.py check_data --qlib_dir ~/.qlib/qlib_data/cn_data
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;Of course, you can also add some parameters to adjust the test results, such as this. &lt;pre&gt;&lt;code&gt;python scripts/check_data_health.py check_data --qlib_dir ~/.qlib/qlib_data/cn_data --missing_data_num 30055 --large_step_threshold_volume 94485 --large_step_threshold_price 20
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;If you want more information about &lt;code&gt;check_data_health&lt;/code&gt;, please refer to the &lt;a href="https://qlib.readthedocs.io/en/latest/component/data.html#checking-the-health-of-the-data"&gt;documentation&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;!-- 
- Run the initialization code and get stock data:

  ```python
  import qlib
  from qlib.data import D
  from qlib.constant import REG_CN

  # Initialization
  mount_path = "~/.qlib/qlib_data/cn_data"  # target_dir
  qlib.init(mount_path=mount_path, region=REG_CN)

  # Get stock data by Qlib
  # Load trading calendar with the given time range and frequency
  print(D.calendar(start_time='2010-01-01', end_time='2017-12-31', freq='day')[:2])

  # Parse a given market name into a stockpool config
  instruments = D.instruments('csi500')
  print(D.list_instruments(instruments=instruments, start_time='2010-01-01', end_time='2017-12-31', as_list=True)[:6])

  # Load features of certain instruments in given time range
  instruments = ['SH600000']
  fields = ['$close', '$volume', 'Ref($close, 1)', 'Mean($close, 3)', '$high-$low']
  print(D.features(instruments, fields, start_time='2010-01-01', end_time='2017-12-31', freq='day').head())
  ```
 --&gt; 
&lt;h2&gt;Docker images&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;Pulling a docker image from a docker hub repository &lt;pre&gt;&lt;code class="language-bash"&gt;docker pull pyqlib/qlib_image_stable:stable
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;Start a new Docker container &lt;pre&gt;&lt;code class="language-bash"&gt;docker run -it --name &amp;lt;container name&amp;gt; -v &amp;lt;Mounted local directory&amp;gt;:/app qlib_image_stable
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;At this point you are in the docker environment and can run the qlib scripts. An example: &lt;pre&gt;&lt;code class="language-bash"&gt;&amp;gt;&amp;gt;&amp;gt; python scripts/get_data.py qlib_data --name qlib_data_simple --target_dir ~/.qlib/qlib_data/cn_data --interval 1d --region cn
&amp;gt;&amp;gt;&amp;gt; python qlib/cli/run.py examples/benchmarks/LightGBM/workflow_config_lightgbm_Alpha158.yaml
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;Exit the container &lt;pre&gt;&lt;code class="language-bash"&gt;&amp;gt;&amp;gt;&amp;gt; exit
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;Restart the container &lt;pre&gt;&lt;code class="language-bash"&gt;docker start -i -a &amp;lt;container name&amp;gt;
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;Stop the container &lt;pre&gt;&lt;code class="language-bash"&gt;docker stop &amp;lt;container name&amp;gt;
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;Delete the container &lt;pre&gt;&lt;code class="language-bash"&gt;docker rm &amp;lt;container name&amp;gt;
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;If you want to know more information, please refer to the &lt;a href="https://qlib.readthedocs.io/en/latest/developer/how_to_build_image.html"&gt;documentation&lt;/a&gt;.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Auto Quant Research Workflow&lt;/h2&gt; 
&lt;p&gt;Qlib provides a tool named &lt;code&gt;qrun&lt;/code&gt; to run the whole workflow automatically (including building dataset, training models, backtest and evaluation). You can start an auto quant research workflow and have a graphical reports analysis according to the following steps:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Quant Research Workflow: Run &lt;code&gt;qrun&lt;/code&gt; with lightgbm workflow config (&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/benchmarks/LightGBM/workflow_config_lightgbm_Alpha158.yaml"&gt;workflow_config_lightgbm_Alpha158.yaml&lt;/a&gt; as following.&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;  cd examples  # Avoid running program under the directory contains `qlib`
  qrun benchmarks/LightGBM/workflow_config_lightgbm_Alpha158.yaml
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;If users want to use &lt;code&gt;qrun&lt;/code&gt; under debug mode, please use the following command:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;python -m pdb qlib/cli/run.py examples/benchmarks/LightGBM/workflow_config_lightgbm_Alpha158.yaml
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The result of &lt;code&gt;qrun&lt;/code&gt; is as follows, please refer to &lt;a href="https://qlib.readthedocs.io/en/latest/component/strategy.html#result"&gt;docs&lt;/a&gt; for more explanations about the result.&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;
'The following are analysis results of the excess return without cost.'
                       risk
mean               0.000708
std                0.005626
annualized_return  0.178316
information_ratio  1.996555
max_drawdown      -0.081806
'The following are analysis results of the excess return with cost.'
                       risk
mean               0.000512
std                0.005626
annualized_return  0.128982
information_ratio  1.444287
max_drawdown      -0.091078
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Here are detailed documents for &lt;code&gt;qrun&lt;/code&gt; and &lt;a href="https://qlib.readthedocs.io/en/latest/component/workflow.html"&gt;workflow&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Graphical Reports Analysis: First, run &lt;code&gt;python -m pip install .[analysis]&lt;/code&gt; to install the required dependencies. Then run &lt;code&gt;examples/workflow_by_code.ipynb&lt;/code&gt; with &lt;code&gt;jupyter notebook&lt;/code&gt; to get graphical reports.&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;Forecasting signal (model prediction) analysis&lt;/p&gt; 
    &lt;ul&gt; 
     &lt;li&gt;Cumulative Return of groups &lt;img src="https://github.com/microsoft/qlib/raw/main/docs/_static/img/analysis/analysis_model_cumulative_return.png" alt="Cumulative Return" /&gt;&lt;/li&gt; 
     &lt;li&gt;Return distribution &lt;img src="https://github.com/microsoft/qlib/raw/main/docs/_static/img/analysis/analysis_model_long_short.png" alt="long_short" /&gt;&lt;/li&gt; 
     &lt;li&gt;Information Coefficient (IC) &lt;img src="https://github.com/microsoft/qlib/raw/main/docs/_static/img/analysis/analysis_model_IC.png" alt="Information Coefficient" /&gt; &lt;img src="https://github.com/microsoft/qlib/raw/main/docs/_static/img/analysis/analysis_model_monthly_IC.png" alt="Monthly IC" /&gt; &lt;img src="https://github.com/microsoft/qlib/raw/main/docs/_static/img/analysis/analysis_model_NDQ.png" alt="IC" /&gt;&lt;/li&gt; 
     &lt;li&gt;Auto Correlation of forecasting signal (model prediction) &lt;img src="https://github.com/microsoft/qlib/raw/main/docs/_static/img/analysis/analysis_model_auto_correlation.png" alt="Auto Correlation" /&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;Portfolio analysis&lt;/p&gt; 
    &lt;ul&gt; 
     &lt;li&gt;Backtest return &lt;img src="https://github.com/microsoft/qlib/raw/main/docs/_static/img/analysis/report.png" alt="Report" /&gt;&lt;/li&gt; 
    &lt;/ul&gt; 
    &lt;!-- 
- Score IC
![Score IC](docs/_static/img/score_ic.png)
- Cumulative Return
![Cumulative Return](docs/_static/img/cumulative_return.png)
- Risk Analysis
![Risk Analysis](docs/_static/img/risk_analysis.png)
- Rank Label
![Rank Label](docs/_static/img/rank_label.png)
--&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;a href="https://qlib.readthedocs.io/en/latest/component/report.html"&gt;Explanation&lt;/a&gt; of above results&lt;/p&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Building Customized Quant Research Workflow by Code&lt;/h2&gt; 
&lt;p&gt;The automatic workflow may not suit the research workflow of all Quant researchers. To support a flexible Quant research workflow, Qlib also provides a modularized interface to allow researchers to build their own workflow by code. &lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/workflow_by_code.ipynb"&gt;Here&lt;/a&gt; is a demo for customized Quant research workflow by code.&lt;/p&gt; 
&lt;h1&gt;Main Challenges &amp;amp; Solutions in Quant Research&lt;/h1&gt; 
&lt;p&gt;Quant investment is a very unique scenario with lots of key challenges to be solved. Currently, Qlib provides some solutions for several of them.&lt;/p&gt; 
&lt;h2&gt;Forecasting: Finding Valuable Signals/Patterns&lt;/h2&gt; 
&lt;p&gt;Accurate forecasting of the stock price trend is a very important part to construct profitable portfolios. However, huge amount of data with various formats in the financial market which make it challenging to build forecasting models.&lt;/p&gt; 
&lt;p&gt;An increasing number of SOTA Quant research works/papers, which focus on building forecasting models to mine valuable signals/patterns in complex financial data, are released in &lt;code&gt;Qlib&lt;/code&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/benchmarks"&gt;Quant Model (Paper) Zoo&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;Here is a list of models built on &lt;code&gt;Qlib&lt;/code&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/benchmarks/XGBoost/"&gt;GBDT based on XGBoost (Tianqi Chen, et al. KDD 2016)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/benchmarks/LightGBM/"&gt;GBDT based on LightGBM (Guolin Ke, et al. NIPS 2017)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/benchmarks/CatBoost/"&gt;GBDT based on Catboost (Liudmila Prokhorenkova, et al. NIPS 2018)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/benchmarks/MLP/"&gt;MLP based on pytorch&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/benchmarks/LSTM/"&gt;LSTM based on pytorch (Sepp Hochreiter, et al. Neural computation 1997)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/benchmarks/GRU/"&gt;GRU based on pytorch (Kyunghyun Cho, et al. 2014)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/benchmarks/ALSTM"&gt;ALSTM based on pytorch (Yao Qin, et al. IJCAI 2017)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/benchmarks/GATs/"&gt;GATs based on pytorch (Petar Velickovic, et al. 2017)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/benchmarks/SFM/"&gt;SFM based on pytorch (Liheng Zhang, et al. KDD 2017)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/benchmarks/TFT/"&gt;TFT based on tensorflow (Bryan Lim, et al. International Journal of Forecasting 2019)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/benchmarks/TabNet/"&gt;TabNet based on pytorch (Sercan O. Arik, et al. AAAI 2019)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/benchmarks/DoubleEnsemble/"&gt;DoubleEnsemble based on LightGBM (Chuheng Zhang, et al. ICDM 2020)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/benchmarks/TCTS/"&gt;TCTS based on pytorch (Xueqing Wu, et al. ICML 2021)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/benchmarks/Transformer/"&gt;Transformer based on pytorch (Ashish Vaswani, et al. NeurIPS 2017)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/benchmarks/Localformer/"&gt;Localformer based on pytorch (Juyong Jiang, et al.)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/benchmarks/TRA/"&gt;TRA based on pytorch (Hengxu, Dong, et al. KDD 2021)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/benchmarks/TCN/"&gt;TCN based on pytorch (Shaojie Bai, et al. 2018)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/benchmarks/ADARNN/"&gt;ADARNN based on pytorch (YunTao Du, et al. 2021)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/benchmarks/ADD/"&gt;ADD based on pytorch (Hongshun Tang, et al.2020)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/benchmarks/IGMTF/"&gt;IGMTF based on pytorch (Wentao Xu, et al.2021)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/benchmarks/HIST/"&gt;HIST based on pytorch (Wentao Xu, et al.2021)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/benchmarks/KRNN/"&gt;KRNN based on pytorch&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/benchmarks/Sandwich/"&gt;Sandwich based on pytorch&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Your PR of new Quant models is highly welcomed.&lt;/p&gt; 
&lt;p&gt;The performance of each model on the &lt;code&gt;Alpha158&lt;/code&gt; and &lt;code&gt;Alpha360&lt;/code&gt; datasets can be found &lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/benchmarks/README.md"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Run a single model&lt;/h3&gt; 
&lt;p&gt;All the models listed above are runnable with &lt;code&gt;Qlib&lt;/code&gt;. Users can find the config files we provide and some details about the model through the &lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/benchmarks"&gt;benchmarks&lt;/a&gt; folder. More information can be retrieved at the model files listed above.&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;Qlib&lt;/code&gt; provides three different ways to run a single model, users can pick the one that fits their cases best:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Users can use the tool &lt;code&gt;qrun&lt;/code&gt; mentioned above to run a model's workflow based from a config file.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Users can create a &lt;code&gt;workflow_by_code&lt;/code&gt; python script based on the &lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/workflow_by_code.py"&gt;one&lt;/a&gt; listed in the &lt;code&gt;examples&lt;/code&gt; folder.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Users can use the script &lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/run_all_model.py"&gt;&lt;code&gt;run_all_model.py&lt;/code&gt;&lt;/a&gt; listed in the &lt;code&gt;examples&lt;/code&gt; folder to run a model. Here is an example of the specific shell command to be used: &lt;code&gt;python run_all_model.py run --models=lightgbm&lt;/code&gt;, where the &lt;code&gt;--models&lt;/code&gt; arguments can take any number of models listed above(the available models can be found in &lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/benchmarks/"&gt;benchmarks&lt;/a&gt;). For more use cases, please refer to the file's &lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/run_all_model.py"&gt;docstrings&lt;/a&gt;.&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: Each baseline has different environment dependencies, please make sure that your python version aligns with the requirements(e.g. TFT only supports Python 3.6~3.7 due to the limitation of &lt;code&gt;tensorflow==1.15.0&lt;/code&gt;)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Run multiple models&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;Qlib&lt;/code&gt; also provides a script &lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/run_all_model.py"&gt;&lt;code&gt;run_all_model.py&lt;/code&gt;&lt;/a&gt; which can run multiple models for several iterations. (&lt;strong&gt;Note&lt;/strong&gt;: the script only support &lt;em&gt;Linux&lt;/em&gt; for now. Other OS will be supported in the future. Besides, it doesn't support parallel running the same model for multiple times as well, and this will be fixed in the future development too.)&lt;/p&gt; 
&lt;p&gt;The script will create a unique virtual environment for each model, and delete the environments after training. Thus, only experiment results such as &lt;code&gt;IC&lt;/code&gt; and &lt;code&gt;backtest&lt;/code&gt; results will be generated and stored.&lt;/p&gt; 
&lt;p&gt;Here is an example of running all the models for 10 iterations:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;python run_all_model.py run 10
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;It also provides the API to run specific models at once. For more use cases, please refer to the file's &lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/run_all_model.py"&gt;docstrings&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Break change&lt;/h3&gt; 
&lt;p&gt;In &lt;code&gt;pandas&lt;/code&gt;, &lt;code&gt;group_key&lt;/code&gt; is one of the parameters of the &lt;code&gt;groupby&lt;/code&gt; method. From version 1.5 to 2.0 of &lt;code&gt;pandas&lt;/code&gt;, the default value of &lt;code&gt;group_key&lt;/code&gt; has been changed from &lt;code&gt;no default&lt;/code&gt; to &lt;code&gt;True&lt;/code&gt;, which will cause qlib to report an error during operation. So we set &lt;code&gt;group_key=False&lt;/code&gt;, but it doesn't guarantee that some programmes will run correctly, including:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;qlib\examples\rl_order_execution\scripts\gen_training_orders.py&lt;/li&gt; 
 &lt;li&gt;qlib\examples\benchmarks\TRA\src\dataset.MTSDatasetH.py&lt;/li&gt; 
 &lt;li&gt;qlib\examples\benchmarks\TFT\tft.py&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/benchmarks_dynamic"&gt;Adapting to Market Dynamics&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Due to the non-stationary nature of the environment of the financial market, the data distribution may change in different periods, which makes the performance of models build on training data decays in the future test data. So adapting the forecasting models/strategies to market dynamics is very important to the model/strategies' performance.&lt;/p&gt; 
&lt;p&gt;Here is a list of solutions built on &lt;code&gt;Qlib&lt;/code&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/benchmarks_dynamic/baseline/"&gt;Rolling Retraining&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/benchmarks_dynamic/DDG-DA/"&gt;DDG-DA on pytorch (Wendi, et al. AAAI 2022)&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Reinforcement Learning: modeling continuous decisions&lt;/h2&gt; 
&lt;p&gt;Qlib now supports reinforcement learning, a feature designed to model continuous investment decisions. This functionality assists investors in optimizing their trading strategies by learning from interactions with the environment to maximize some notion of cumulative reward.&lt;/p&gt; 
&lt;p&gt;Here is a list of solutions built on &lt;code&gt;Qlib&lt;/code&gt; categorized by scenarios.&lt;/p&gt; 
&lt;h3&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/rl_order_execution"&gt;RL for order execution&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://qlib.readthedocs.io/en/latest/component/rl/overall.html#order-execution"&gt;Here&lt;/a&gt; is the introduction of this scenario. All the methods below are compared &lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/rl_order_execution"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/rl_order_execution/exp_configs/backtest_twap.yml"&gt;TWAP&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/rl_order_execution/exp_configs/backtest_ppo.yml"&gt;PPO: "An End-to-End Optimal Trade Execution Framework based on Proximal Policy Optimization", IJCAL 2020&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/rl_order_execution/exp_configs/backtest_opds.yml"&gt;OPDS: "Universal Trading for Order Execution with Oracle Policy Distillation", AAAI 2021&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Quant Dataset Zoo&lt;/h1&gt; 
&lt;p&gt;Dataset plays a very important role in Quant. Here is a list of the datasets built on &lt;code&gt;Qlib&lt;/code&gt;:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Dataset&lt;/th&gt; 
   &lt;th&gt;US Market&lt;/th&gt; 
   &lt;th&gt;China Market&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/qlib/contrib/data/handler.py"&gt;Alpha360&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;âˆš&lt;/td&gt; 
   &lt;td&gt;âˆš&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/qlib/contrib/data/handler.py"&gt;Alpha158&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;âˆš&lt;/td&gt; 
   &lt;td&gt;âˆš&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;a href="https://qlib.readthedocs.io/en/latest/advanced/alpha.html"&gt;Here&lt;/a&gt; is a tutorial to build dataset with &lt;code&gt;Qlib&lt;/code&gt;. Your PR to build new Quant dataset is highly welcomed.&lt;/p&gt; 
&lt;h1&gt;Learning Framework&lt;/h1&gt; 
&lt;p&gt;Qlib is high customizable and a lot of its components are learnable. The learnable components are instances of &lt;code&gt;Forecast Model&lt;/code&gt; and &lt;code&gt;Trading Agent&lt;/code&gt;. They are learned based on the &lt;code&gt;Learning Framework&lt;/code&gt; layer and then applied to multiple scenarios in &lt;code&gt;Workflow&lt;/code&gt; layer. The learning framework leverages the &lt;code&gt;Workflow&lt;/code&gt; layer as well(e.g. sharing &lt;code&gt;Information Extractor&lt;/code&gt;, creating environments based on &lt;code&gt;Execution Env&lt;/code&gt;).&lt;/p&gt; 
&lt;p&gt;Based on learning paradigms, they can be categorized into reinforcement learning and supervised learning.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;For supervised learning, the detailed docs can be found &lt;a href="https://qlib.readthedocs.io/en/latest/component/model.html"&gt;here&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;For reinforcement learning, the detailed docs can be found &lt;a href="https://qlib.readthedocs.io/en/latest/component/rl.html"&gt;here&lt;/a&gt;. Qlib's RL learning framework leverages &lt;code&gt;Execution Env&lt;/code&gt; in &lt;code&gt;Workflow&lt;/code&gt; layer to create environments. It's worth noting that &lt;code&gt;NestedExecutor&lt;/code&gt; is supported as well. This empowers users to optimize different level of strategies/models/agents together (e.g. optimizing an order execution strategy for a specific portfolio management strategy).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;More About Qlib&lt;/h1&gt; 
&lt;p&gt;If you want to have a quick glance at the most frequently used components of qlib, you can try notebooks &lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/examples/tutorial/"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;The detailed documents are organized in &lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/docs/"&gt;docs&lt;/a&gt;. &lt;a href="http://www.sphinx-doc.org"&gt;Sphinx&lt;/a&gt; and the readthedocs theme is required to build the documentation in html formats.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd docs/
conda install sphinx sphinx_rtd_theme -y
# Otherwise, you can install them with pip
# pip install sphinx sphinx_rtd_theme
make html
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can also view the &lt;a href="http://qlib.readthedocs.io/"&gt;latest document&lt;/a&gt; online directly.&lt;/p&gt; 
&lt;p&gt;Qlib is in active and continuing development. Our plan is in the roadmap, which is managed as a &lt;a href="https://github.com/microsoft/qlib/projects/1"&gt;github project&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;Offline Mode and Online Mode&lt;/h1&gt; 
&lt;p&gt;The data server of Qlib can either deployed as &lt;code&gt;Offline&lt;/code&gt; mode or &lt;code&gt;Online&lt;/code&gt; mode. The default mode is offline mode.&lt;/p&gt; 
&lt;p&gt;Under &lt;code&gt;Offline&lt;/code&gt; mode, the data will be deployed locally.&lt;/p&gt; 
&lt;p&gt;Under &lt;code&gt;Online&lt;/code&gt; mode, the data will be deployed as a shared data service. The data and their cache will be shared by all the clients. The data retrieval performance is expected to be improved due to a higher rate of cache hits. It will consume less disk space, too. The documents of the online mode can be found in &lt;a href="https://qlib-server.readthedocs.io/"&gt;Qlib-Server&lt;/a&gt;. The online mode can be deployed automatically with &lt;a href="https://qlib-server.readthedocs.io/en/latest/build.html#one-click-deployment-in-azure"&gt;Azure CLI based scripts&lt;/a&gt;. The source code of online data server can be found in &lt;a href="https://github.com/microsoft/qlib-server"&gt;Qlib-Server repository&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Performance of Qlib Data Server&lt;/h2&gt; 
&lt;p&gt;The performance of data processing is important to data-driven methods like AI technologies. As an AI-oriented platform, Qlib provides a solution for data storage and data processing. To demonstrate the performance of Qlib data server, we compare it with several other data storage solutions.&lt;/p&gt; 
&lt;p&gt;We evaluate the performance of several storage solutions by finishing the same task, which creates a dataset (14 features/factors) from the basic OHLCV daily data of a stock market (800 stocks each day from 2007 to 2020). The task involves data queries and processing.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;&lt;/th&gt; 
   &lt;th&gt;HDF5&lt;/th&gt; 
   &lt;th&gt;MySQL&lt;/th&gt; 
   &lt;th&gt;MongoDB&lt;/th&gt; 
   &lt;th&gt;InfluxDB&lt;/th&gt; 
   &lt;th&gt;Qlib -E -D&lt;/th&gt; 
   &lt;th&gt;Qlib +E -D&lt;/th&gt; 
   &lt;th&gt;Qlib +E +D&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Total (1CPU) (seconds)&lt;/td&gt; 
   &lt;td&gt;184.4Â±3.7&lt;/td&gt; 
   &lt;td&gt;365.3Â±7.5&lt;/td&gt; 
   &lt;td&gt;253.6Â±6.7&lt;/td&gt; 
   &lt;td&gt;368.2Â±3.6&lt;/td&gt; 
   &lt;td&gt;147.0Â±8.8&lt;/td&gt; 
   &lt;td&gt;47.6Â±1.0&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;7.4Â±0.3&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Total (64CPU) (seconds)&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;8.8Â±0.6&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;4.2Â±0.2&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;+(-)E&lt;/code&gt; indicates with (out) &lt;code&gt;ExpressionCache&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;+(-)D&lt;/code&gt; indicates with (out) &lt;code&gt;DatasetCache&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Most general-purpose databases take too much time to load data. After looking into the underlying implementation, we find that data go through too many layers of interfaces and unnecessary format transformations in general-purpose database solutions. Such overheads greatly slow down the data loading process. Qlib data are stored in a compact format, which is efficient to be combined into arrays for scientific computation.&lt;/p&gt; 
&lt;h1&gt;Related Reports&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://analyticsindiamag.com/qlib/"&gt;Guide To Qlib: Microsoftâ€™s AI Investment Platform&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://mp.weixin.qq.com/s/47bP5YwxfTp2uTHjUBzJQQ"&gt;å¾®è½¯ä¹ŸæAIé‡åŒ–å¹³å°ï¼Ÿè¿˜æ˜¯å¼€æºçš„ï¼&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://mp.weixin.qq.com/s/vsJv7lsgjEi-ALYUz4CvtQ"&gt;å¾®çŸ¿Qlibï¼šä¸šå†…é¦–ä¸ªAIé‡åŒ–æŠ•èµ„å¼€æºå¹³å°&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Contact Us&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;If you have any issues, please create issue &lt;a href="https://github.com/microsoft/qlib/issues/new/choose"&gt;here&lt;/a&gt; or send messages in &lt;a href="https://gitter.im/Microsoft/qlib"&gt;gitter&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;If you want to make contributions to &lt;code&gt;Qlib&lt;/code&gt;, please &lt;a href="https://github.com/microsoft/qlib/compare"&gt;create pull requests&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;For other reasons, you are welcome to contact us by email(&lt;a href="mailto:qlib@microsoft.com"&gt;qlib@microsoft.com&lt;/a&gt;). 
  &lt;ul&gt; 
   &lt;li&gt;We are recruiting new members(both FTEs and interns), your resumes are welcome!&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Join IM discussion groups:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;&lt;a href="https://gitter.im/Microsoft/qlib"&gt;Gitter&lt;/a&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src="https://github.com/microsoft/qlib/raw/main/docs/_static/img/qrcode/gitter_qr.png" alt="image" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h1&gt;Contributing&lt;/h1&gt; 
&lt;p&gt;We appreciate all contributions and thank all the contributors! &lt;a href="https://github.com/microsoft/qlib/graphs/contributors"&gt;&lt;img src="https://contrib.rocks/image?repo=microsoft/qlib" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Before we released Qlib as an open-source project on Github in Sep 2020, Qlib is an internal project in our group. Unfortunately, the internal commit history is not kept. A lot of members in our group have also contributed a lot to Qlib, which includes Ruihua Wang, Yinda Zhang, Haisu Yu, Shuyu Wang, Bochen Pang, and &lt;a href="https://github.com/evanzd/evanzd"&gt;Dong Zhou&lt;/a&gt;. Especially thanks to &lt;a href="https://github.com/evanzd/evanzd"&gt;Dong Zhou&lt;/a&gt; due to his initial version of Qlib.&lt;/p&gt; 
&lt;h2&gt;Guidance&lt;/h2&gt; 
&lt;p&gt;This project welcomes contributions and suggestions.&lt;br /&gt; &lt;strong&gt;Here are some &lt;a href="https://raw.githubusercontent.com/microsoft/qlib/main/docs/developer/code_standard_and_dev_guide.rst"&gt;code standards and development guidance&lt;/a&gt; for submiting a pull request.&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Making contributions is not a hard thing. Solving an issue(maybe just answering a question raised in &lt;a href="https://github.com/microsoft/qlib/issues"&gt;issues list&lt;/a&gt; or &lt;a href="https://gitter.im/Microsoft/qlib"&gt;gitter&lt;/a&gt;), fixing/issuing a bug, improving the documents and even fixing a typo are important contributions to Qlib.&lt;/p&gt; 
&lt;p&gt;For example, if you want to contribute to Qlib's document/code, you can follow the steps in the figure below.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://github.com/demon143/qlib/raw/main/docs/_static/img/change%20doc.gif" /&gt; &lt;/p&gt; 
&lt;p&gt;If you don't know how to start to contribute, you can refer to the following examples.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Type&lt;/th&gt; 
   &lt;th&gt;Examples&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Solving issues&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/microsoft/qlib/issues/749"&gt;Answer a question&lt;/a&gt;; &lt;a href="https://github.com/microsoft/qlib/issues/765"&gt;issuing&lt;/a&gt; or &lt;a href="https://github.com/microsoft/qlib/pull/792"&gt;fixing&lt;/a&gt; a bug&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Docs&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/microsoft/qlib/pull/797/files"&gt;Improve docs quality&lt;/a&gt; ; &lt;a href="https://github.com/microsoft/qlib/pull/774"&gt;Fix a typo&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Feature&lt;/td&gt; 
   &lt;td&gt;Implement a &lt;a href="https://github.com/microsoft/qlib/projects"&gt;requested feature&lt;/a&gt; like &lt;a href="https://github.com/microsoft/qlib/pull/754"&gt;this&lt;/a&gt;; &lt;a href="https://github.com/microsoft/qlib/pull/539/files"&gt;Refactor interfaces&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Dataset&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/microsoft/qlib/pull/733"&gt;Add a dataset&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Models&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/microsoft/qlib/pull/689"&gt;Implement a new model&lt;/a&gt;, &lt;a href="https://github.com/microsoft/qlib/tree/main/examples/benchmarks#contributing"&gt;some instructions to contribute models&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;a href="https://github.com/microsoft/qlib/labels/good%20first%20issue"&gt;Good first issues&lt;/a&gt; are labelled to indicate that they are easy to start your contributions.&lt;/p&gt; 
&lt;p&gt;You can find some impefect implementation in Qlib by &lt;code&gt;rg 'TODO|FIXME' qlib&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;If you would like to become one of Qlib's maintainers to contribute more (e.g. help merge PR, triage issues), please contact us by email(&lt;a href="mailto:qlib@microsoft.com"&gt;qlib@microsoft.com&lt;/a&gt;). We are glad to help to upgrade your permission.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Most contributions require you to agree to a Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us the right to use your contribution. For details, visit &lt;a href="https://cla.opensource.microsoft.com"&gt;https://cla.opensource.microsoft.com&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;When you submit a pull request, a CLA bot will automatically determine whether you need to provide a CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions provided by the bot. You will only need to do this once across all repos using our CLA.&lt;/p&gt; 
&lt;p&gt;This project has adopted the &lt;a href="https://opensource.microsoft.com/codeofconduct/"&gt;Microsoft Open Source Code of Conduct&lt;/a&gt;. For more information see the &lt;a href="https://opensource.microsoft.com/codeofconduct/faq/"&gt;Code of Conduct FAQ&lt;/a&gt; or contact &lt;a href="mailto:opencode@microsoft.com"&gt;opencode@microsoft.com&lt;/a&gt; with any additional questions or comments.&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>